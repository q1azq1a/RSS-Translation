<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 26 日，星期日 20:11:48 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Solving Two-Sided Adverse Selection with Prediction Market Matchmaking]]></title><description><![CDATA[Published on November 26, 2023 8:10 PM GMT<br/><br/><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/99WwKnkE2FKAFo2ap/s2zbbqpeaxpoy4rr2jld" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/99WwKnkE2FKAFo2ap/xff9jzs0fgp7u21ciaq2 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/99WwKnkE2FKAFo2ap/rh8uwt6btzrqhnapovq0 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/99WwKnkE2FKAFo2ap/os4dc1r67s52jnlmy1lz 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/99WwKnkE2FKAFo2ap/esdpc5afazjyasnzdaos 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/99WwKnkE2FKAFo2ap/ou8et2puwea0fhemlh9c 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/99WwKnkE2FKAFo2ap/d3satrakwyr7bajmwaii 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/99WwKnkE2FKAFo2ap/umzxc8fjv0hojb4029yp 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/99WwKnkE2FKAFo2ap/ti6ciszrdxr8tf4wpvdq 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/99WwKnkE2FKAFo2ap/sygzudsyigugf2av63wi 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/99WwKnkE2FKAFo2ap/n4tgv9uhgzzhjdlkzzpz 1500w"><figcaption>做市可能会最大化有意义的匹配，就像这对梨一样。</figcaption></figure><h1> 0：导航</h1><p>我的目标读者是知道什么是“预测市场”和“逆向选择”，喜欢第一个而不是第二个，并且喜欢激励机制完全一致的系统的读者。有关预测市场的入门知识，请阅读 Scott Alexander 的<a href="https://www.astralcodexten.com/p/prediction-market-faq?ref=brasstacks.blog"><u>常见问题解答</u></a>。如果您已经熟悉<a href="https://www.brasstacks.blog/pm-matchmaking/manifold.love"><u>Manifold Love</u></a> ，请跳至第 2 部分。</p><p> COI：我已经为 Manifold 做了<a href="http://manifestconference.net/?ref=brasstacks.blog"><u>一些工作</u></a>，可能还会做更多工作，并拥有<a href="http://manifold.markets/?ref=brasstacks.blog"><u>Manifold</u></a>的一点股权。我写这篇文章与我目前正在为 Manifold 或任何其他实体所做或计划做的任何工作无关。我只是觉得这些想法很酷。</p><h1> 1：爱</h1><p>玩币预测市场平台<a href="http://manifold.markets/?ref=brasstacks.blog"><u>Manifold</u></a>最近发布了一款名为“ <a href="http://manifoldlove.com/?ref=brasstacks.blog"><u>Manifold Love</u></a> ”的预测市场交友应用。用户——那些寻求爱情的人——像普通的约会应用程序一样注册并填写他们的个人资料。媒人（其中一些人本身就是该应用程序的用户）为用户配对。媒人进行匹配后，会根据配对（潜在）关系的各种基准自动创建预测市场。 </p><p><img style="width:39.59%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/99WwKnkE2FKAFo2ap/l1ccolmjl6vrdipnviao" alt=""><img style="width:40.15%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/99WwKnkE2FKAFo2ap/zc7yymewfsr49fqa3ksu" alt=""><img style="width:42.65%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/99WwKnkE2FKAFo2ap/tjknavwqh60xxe82sqje" alt=""><img style="width:37.39%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/99WwKnkE2FKAFo2ap/qjiqij5jrbtd2twivi1h" alt=""></p><p> Manifold Love 部分市场截图。</p><p>人们打赌（使用<a href="https://docs.manifold.markets/faq?ref=brasstacks.blog#what-is-mana-m"><u>虚拟货币</u></a>）两人是否会进行第一次约会；以第一次约会发生为条件，进行第二次约会；以第二次约会发生为条件，第三次；以第三次约会为条件，一段为期 6 个月的关系。这个想法是<strong>，你应该和最有可能促成后续约会并最终发展成关系的匹配者一起约会。</strong>您无需猜测那人是谁，只需查看预测市场即可。</p><h1> 2：概括</h1><p>重要的是，Manifold Love 的设置不仅限于解决约会市场的问题。它解决了（或者至少有可能解决）<i>所有</i>存在双边逆向选择的情况下的问题，即双边市场的每一方都选择了对方认为不利的东西。用格劳乔·马克斯（Groucho Marx）的话来说，“我不想加入任何愿意接受我作为会员的[乡村]俱乐部。”如果一个俱乐部想要格劳乔·马克斯，它可能不是一个非常好的俱乐部，反之亦然——如果格劳乔·马克斯想加入某个特定的俱乐部，他可能不是一个非常理想的成员。</p><p>更一般地说，“在通常陷入逆向选择的双方之间的潜在配对的一系列关键基准上运行一堆条件预测市场”的设置似乎可以很好地发挥作用。</p><p>双向逆向选择的典型案例之一是劳动力市场，因此以下是一种“多重工作”可能会如何发挥作用。该平台拥有三个实体：</p><ol><li>未来员工</li><li>未来雇主</li><li>猎头公司</li></ol><p>该平台根据前两个实体的关键基准创建了一系列条件预测市场。例如：</p><ul><li>在被[未来雇主]雇用的条件下，[未来雇员]将：<ul><li>在[时间范围]内仍在工作吗？</li><li>在[时间范围]内每周平均生活满意度比现在更高？</li><li> ETC。</li></ul></li><li>以雇用[未来雇员]为条件，[未来雇主]将：<ul><li>在[时间范围]内仍然雇用 Eden 吗？</li><li>在[时间范围]内，员工的每周平均评分高于前任员工？</li><li> ETC。</li></ul></li></ul><p> <a href="https://manifold.markets/TonyBaloney/will-manifold-be-used-for-job-recru?ref=brasstacks.blog"><u>如果 Manifold 真的做到了</u></a>，我相信它看起来会有所不同，更好，更充实。但重要的是，约会和劳动力市场并不是双向逆向选择的唯一两个领域。</p><h1> 3：在此插入双面逆向选择</h1><p>还有许多其他双向逆向选择的情况，其中 Manifold Love 的条件预测市场设置可能会解决很多问题：</p><ul><li>约会（多重爱）</li><li>友谊</li><li>健身房合作伙伴</li><li>赠款</li><li>大学申请/决定</li><li>研究生院应用程序/决策（例如医学院、法学院、商学院等）</li><li>劳工/雇用/人才招聘/工作（如第 2 节）</li><li>联合创始人</li><li>种子期和种子期前投资</li><li>儿童收养</li><li>实习申请/决定</li><li>二手车销售</li><li>辅导</li><li>活动/场地空间</li><li>治疗师/患者</li><li>销售和购买保险</li><li>信贷/贷款</li><li>住宅及商业地产</li><li>学生在大学选课</li></ul><p>如果您能想到更多，<a href="https://www.brasstacks.blog/pm-matchmaking/saulmunn.com/contact"><u>请告诉我</u></a>，我会在这里添加它们！需要注意的是：对于上述大多数情况，已经有一些实体充当中间人——房地产有房地产经纪人，劳动力市场有猎头，收养机构将亲生母亲与收养家庭配对，等等。但所有这些都相当破碎，有偏差，或者至少是非常次优的。我对条件预测市场改进并解决双边逆向选择的潜力感到兴奋。</p><h1> 4：注意事项</h1><ul><li>在我撰写本文时，我是一名地位较低的本科生，从未上过经济学课，也不知道他在说什么。我在预测市场和预测社区做了<a href="https://www.brasstacks.blog/pm-matchmaking/manifestconference.net"><u>一些</u></a><a href="https://www.brasstacks.blog/pm-matchmaking/opticforecasting.com"><u>工作</u></a>，但我离专家还差得很远。</li><li>我们甚至不知道“多重爱”是否适用于约会，更不用说它是否可以推广到其他双向逆向选择系统了。</li><li><strong>没有事先承诺随机化的条件预测市场并不意味着因果关系</strong>（a la <a href="https://dynomight.net/prediction-market-causation?ref=brasstacks.blog"><u>DYNOMIGHT</u></a> ）。这种设置将为我们提供关联/相关性，但<strong>如果没有事先承诺随机化，我们将不知道因果关系的存在或方向</strong>。之前对其中一些系统的少量随机化的承诺范围从“相当困难”到“哈哈哈好，<i>绝对他妈的不是</i>”。幸运的是，我不确定你是否需要知道因果关系，至少在开始时不需要。我很好奇如果/当 Manifold Love 遇到这个问题时会发生什么。</li><li>再说一遍，COI：我已经为 Manifold 做过<a href="https://www.brasstacks.blog/pm-matchmaking/manifestconference.net"><u>工作</u></a>，可能还会为<a href="https://www.brasstacks.blog/pm-matchmaking/manifold.markets"><u>Manifold</u></a>做更多工作，并且拥有少量股权。</li></ul><br/><br/> <a href="https://www.lesswrong.com/posts/99WwKnkE2FKAFo2ap/solving-two-sided-adverse-selection-with-prediction-market#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/99WwKnkE2FKAFo2ap/solving-two- Side-adverse-selection-with-prediction-market<guid ispermalink="false"> 99WwKnkE2FKAFo2ap</guid><dc:creator><![CDATA[Saul Munn]]></dc:creator><pubDate> Sun, 26 Nov 2023 20:10:23 GMT</pubDate> </item><item><title><![CDATA[Spaced repetition for teaching two-year olds how to read (Interview)]]></title><description><![CDATA[Published on November 26, 2023 4:52 PM GMT<br/><br/><p><strong>这位</strong><strong>父亲一直在使用间隔重复（Anki）来教他的孩子如何比平均水平早几年阅读。</strong></p><p> <a href="https://twitter.com/michael_nielsen/status/1587084229946400769">Michael Nielsen</a>和<a href="https://twitter.com/gwern/status/1586386061395374080">Gwern</a> <span class="footnote-reference" role="doc-noteref" id="fnrefwg6ygc2mu0n"><sup><a href="#fnwg6ygc2mu0n">[1]</a></sup></span>在 Twitter 上发布了 Reddit 用户 u/caffeine314（以下称为“CoffeePie”）的有趣案例，他从很小的时候就开始和女儿一起使用间隔重复。</p><p> CoffeePie 在女儿 2 岁时开始与女儿一起使用 Anki，而他从 1 岁 9 个月开始继续与儿子一起使用 Anki。以下是他女儿 2020 年 1 月的进展情况：</p><blockquote><p>我女儿<strong>几天后就要满 5 岁了</strong>……她仍然很坚强——她每天都使用 Anki 来学习英语、希伯来语和西班牙语。她对阅读很有信心，而且，她阅读时带有……“语境”。许多她这个年纪的孩子都机械地阅读，但<strong>她读起来就像一个真正的故事讲述者</strong>，这来自于她的自信。开学时，老师说<strong>她绝对具备五年级的阅读能力</strong>，如果只看阅读能力，不注重对抽象概念的理解，她的阅读水平可能会与八年级学生相媲美。</p></blockquote><p> （来自<a href="https://www.reddit.com/r/Anki/comments/eisra4/update_on_my_daughter_and_anki/">我女儿和 Anki 的更新</a>）</p><p>作为参考，在美国，五年级学生通常为 10 岁或 11 岁，八年级学生通常为 13 岁或 14 岁，因此这使她<strong>比普通孩子领先约 5-9 岁</strong>。</p><p>你可以在这篇文章中看到他女儿 2 岁零 2 个月后读书的视频。</p><p> CoffeePie 发表了几篇关于他们经历的帖子，但我仍然有疑问，所以我在一月份联系了他采访他。</p><h1><strong>面试</strong></h1><p><i>为清楚起见，对回复进行了编辑</i>。</p><p><strong>从您的女儿到您的儿子使用 Anki，您学到了</strong><strong>什么</strong>？<strong>你儿子怎么样了？</strong></p><p>这是一个很难的问题，因为我答对了很多。我们取得了如此巨大的成功，以至于我几乎“克隆”了我儿子的方方面面。</p><p>我能想到的有几点：</p><p>对于我的女儿，我很长一段时间都没有使用小写字母，因为我认为这会让她感到困惑，但是当我开始向她介绍小写字母时，令我极度震惊的是，她已经认识了它们，而且很冷淡！</p><p>我认为她只是通过看书籍、电视、杂志、店面招牌、菜单等来学习它们。</p><p>因此，当我们从我儿子开始时，我在完成大写字母的第二天就开始写小写字母。</p><p>另一个区别是我们第二天就在小写字母后面加上数字。</p><p>我真的真的觉得我逼得太紧了；我并不想当“虎爸”，但他却非常优雅地接受了。我随时准备停下来，但他很好。</p><p>另一个区别是，我们对孩子们从中得到的期望也发生了变化。起初，我真的只是想让我的女儿快速开始阅读，但愚蠢的我，我没有意识到这会带来意想不到的后果。一个具有三年级阅读能力的四岁孩子学到了更多东西——这为她打开了政治大门。她会读我们的垃圾邮件，了解我们的议员是谁，我们的代表是谁，市长，时事，历史等等。我知道我这样说很愚蠢，但我低估了早读对人们的影响。她的学识广度。</p><p>最后一件事是数学。我提到我们很早就开始和我儿子一起玩数字游戏。但我们也开始算术。他不像汉娜那样读到了 3，但他知道所有乘法表，直到 12 × 12。今年我们学习了质因数分解、斐波那契数列、小数和位值、混合分数、真分数和假分数、轻代数等等。我在数学上更加积极主动，而他又优雅地处理了它。我随时准备停下来。</p><p><strong>随着你女儿长大，你现在还在和她一起使用 Anki</strong><strong>吗</strong>？</p><p>我们几乎和我女儿一起停止了 Anki。她最近没有进行测试，但我想说她的机械阅读能力很容易达到高中水平。她的理解力仍然很先进，但更符合她的年龄。这不是 Anki 可以轻松解决的问题。在学校和她的课外活动之间，我不想从她那里偷走更多的时间，所以我们在工作日停止了 Anki。我们仍然在非上学的晚上（周末和节假日）做 Anki——仅限希伯来语。我觉得我们不公平，因为她现在上二年级，并且在作业和其他事情上花费了大量时间。我希望她是个孩子。</p><p>澄清<strong>一下</strong><strong>——你停止和你的女儿一起使用 Anki 很大程度上是因为你没有阅读/语言/数学之外的话题吗？</strong></p><p>我想这就是汉娜的遭遇。从机械上来说，她的阅读水平是高中研究生水平。但她的阅读理解能力更适合年龄。她经过了英国教育局的测试，幼儿园时的阅读理解能力是四年级。</p><p>我认为 Anki 在阅读理解方面能做的不多。她缺少经验带来的知识。有时我们会遇到一些令人震惊的事情，让我想起她还只有 7 岁——比如不知道冷落别人是什么意思。她是一位很好的读者，当我们遇到这样的事情时，会感到很震惊。我认为 Anki 阅读对她来说是顺其自然的。</p><p>至于数学，她的乘法表还可以做得更好。仍然比她班上的任何人都更了解他们。但在这里，她再次需要 Anki 无法测试的信息，例如将 87-8 视为与 80-1 相同的问题。奇怪的是，一长页的问题可能更有利于这类事情。</p><p><strong>我很</strong><strong>好奇你是否看过</strong>拉里·桑格（维基百科联合创始人）<strong>教孩子早期阅读</strong><a href="https://larrysanger.org/2010/12/baby-reading/"><strong>的经历</strong></a>。<strong>你对那个怎么想的？</strong></p><p>我从未听说过拉里·桑格，但这<i>正是</i>我们的经历，太棒了！这是汉娜在 2 岁零 2 个月时读的《Rollie Pollie Ollie》： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/id1f6duirnnw0h6avfoz" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/yzanstqwosr6enq5638r 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/w3dwoedacziswtbooskq 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/rqyzym5zqcusjab5uxyn 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/wefdymwvc2egpmjed7xx 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/ipfg4desbt5tqsizn5dt 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/eybzdx2u14gsx8abrfpd 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/n7s01ruhnv8ubqputsxk 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/sj40no73ofo58on9ma4n 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/sbh10glmb3y2r25nziik 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/zzrfmydb6jn6rnuvfclf 1450w"><figcaption><a href="https://chipmonk.substack.com/p/spaced-repetition-for-teaching-two">糟糕，我不知道如何嵌入视频。<strong>在此处查看子堆栈上的视频。</strong></a></figcaption></figure><p>您<strong>是否</strong><strong>认为使用 Anki 对您的孩子有过强迫感？</strong></p><p>汉娜经历了一个她不想这样做的阶段。我们试图妥协并解决这个问题。最终，这成为了她“工作”的一部分——我们告诉她，每个人都有一份工作，而她的工作就是做 Anki。除此之外，我们从来没有必要强迫任何一个孩子。</p><p><strong>在接下来的几年里，您对女儿的教育还有其他有趣或不寻常的计划</strong><strong>吗</strong>？</p><p>有趣的问题。我觉得自己像一个糟糕的家长，写着“不”，但这么早的阅读让她在更早的时候就获得了高级学习的机会。与她的同学相比，她有这样的优势，我想我会暂时放过她。她是一个充满好奇心的人，她有能力追随自己的兴趣，我信任她。我们确实开始了一些高中代数——我一直在向她展示代数的性质：交换性、结合性、恒等性、分配性等。我们一直在研究对称性——镜像、自反、旋转。高调的数学主题并不真正需要硬核计算。但它总是在“嘿，我有一些有趣的东西想向你展示”，而不是“请坐下来解决这些问题”。</p><p>事实上，如果您对有趣的教育机会有任何建议，我会洗耳恭听！</p><h1>闭幕式</h1><p>到目前为止，这就是我向 CoffeePie 询问的所有内容。如果您有任何想让我问他的问题，或者对他可以与他的孩子（目前年龄约为 5 岁和〜8 岁）尝试的事情有任何建议，请告诉我，我会告诉他！</p><p>这里的一个混杂因素是 CoffeePie 曾经是一名物理学教授，因此这种影响可能有一部分是遗传的。</p><p> CoffeePie 还经营一家辅导公司， <a href="https://brooklyntutoring.net">Brooklyn Tutoring and Test Prep</a> 。</p><p><strong>我很快就会发布更多有关育儿的内容：订阅我的帖子或</strong><a href="https://open.substack.com/pub/chipmonk/p/spaced-repetition-for-teaching-two?r=bgw61&amp;utm_campaign=post&amp;utm_medium=web"><strong>我的博客</strong></a>。</p><p><i>感谢</i><a href="https://prigoose.substack.com/"><i>Priya</i></a> <i>(</i> <a href="https://twitter.com/Prigoose"><i>@Prigoose</i></a> <i>) 在我坐了太久之后将草稿变成了最后的帖子！</i></p><p><a href="https://twitter.com/Prigoose/status/1728829018026475766"><i>请参阅推特上的这篇文章</i></a>。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnwg6ygc2mu0n"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwg6ygc2mu0n">^</a></strong></sup></span><div class="footnote-content"><p>格温的推特账户是私人的；推文内容如下：</p><blockquote><p> @michael_nielsen https://reddit.com/r/Anki/comments/8iydl7/using_anki_with_babies_toddlers/ https://old.reddit.com/r/Anki/comments/a9wqau/using_anki_with_babies_toddlers_update/ 我在尽管。</p></blockquote></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/2PLBhCbByRMaEKimo/spaced-repetition-for-teaching-two-year-olds-how-to-read#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/2PLBhCbByRMaEKimo/spaced-repetition-for-teaching-two-year-olds-how-to-read<guid ispermalink="false"> 2PLBhCbByRMaEKimo</guid><dc:creator><![CDATA[Chipmonk]]></dc:creator><pubDate> Sun, 26 Nov 2023 16:52:59 GMT</pubDate> </item><item><title><![CDATA[Paper out now on creatine and cognitive performance]]></title><description><![CDATA[Published on November 26, 2023 10:58 AM GMT<br/><br/><p>我们的论文“肌酸补充剂对认知表现的影响 - 一项随机对照研究”现已发布！</p><p> → 论文： <a href="https://doi.org/10.1186/s12916-023-03146-5">https://doi.org/10.1186/s12916-023-03146-5</a></p><p> → Twitter 帖子： <a href="https://twitter.com/FabienneSand/status/1726196252747165718?t=qPUghyDGMUb0-FZK7CEXhw&amp;s=19">https://twitter.com/FabienneSand/status/1726196252747165718</a> ?t=qPUghyDGMUb0-FZK7CEXhw&amp;s=19</p><p>扬·布劳纳和我非常感谢保罗·克里斯蒂亚诺建议进行这项研究并为其提供资助。</p><br/><br/> <a href="https://www.lesswrong.com/posts/CbaznRo9fKpriw2mi/paper-out-now-on-creatine-and-cognitive-performance#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/CbaznRo9fKpriw2mi/paper-out-now-on-creatine-and-cognitive-performance<guid ispermalink="false"> CbaznRo9fKpriw2mi</guid><dc:creator><![CDATA[Fabienne]]></dc:creator><pubDate> Sun, 26 Nov 2023 10:58:36 GMT</pubDate> </item><item><title><![CDATA[Curated list of my favourite self-help resources]]></title><description><![CDATA[Published on November 26, 2023 6:31 AM GMT<br/><br/><h1><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/yuk43ux7m5rqcahyu7xd" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/lfc8ykuwo35s4iiu69ou 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/xlun4tmujc8x0lltgvqb 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/gvebucioi35j9bsgcykg 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/pydng5urp8xfe6icaon0 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/cnqyhfskzcno1by3rraq 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/yv7egfvybqncvv9z7itb 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/xav44yvhuwqiosm37ut1 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/dyy01z5dxw3lhzczcq33 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/rldwopdvuhqtjlx1zbkr 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/azi2x5q67vntencdoa76 1024w"><br><br>会谈</h1><ul><li>布蕾妮·布朗：<a href="https://www.youtube.com/watch?v=iCvmsMzlF7o"><u>脆弱的力量</u></a></li><li>布蕾妮·布朗：<a href="https://www.youtube.com/watch?v=psN1DORYYV0"><u>倾听耻辱</u></a></li><li>布蕾妮·布朗<a href="https://www.audible.com/pd/Self-Development/The-Power-of-Vulnerability-Audiobook/B00CYKDYBQ"><u>关于羞耻、全心全意和脆弱性的较长系列演讲</u></a></li><li>布蕾妮·布朗：<a href="https://www.audible.com/pd/Self-Development/Men-Women-and-Worthiness-Audiobook/B00C9J0SDY"><u>男人、女人和价值：羞耻的经历和足够的力量</u></a></li><li>布蕾妮·布朗：<a href="http://www.oprah.com/own-supersoulsessions/brene-brown-the-anatomy-of-trust-video"><u>信任的剖析</u></a></li><li>约翰·戈特曼：<a href="https://www.youtube.com/watch?v=AKTyPgwfPgg"><u>让婚姻发挥作用</u></a>（也适用于友谊和家​​庭关系）</li><li>理查德·罗尔： <a href="https://www.audible.com/pd/Self-Development/True-Self-False-Self-Audiobook/B003A2GME8"><u>真实的自我，虚假的自我</u></a>（关于价值的等级与内在的价值和神性）</li></ul><h1>图书</h1><ul><li>克里斯汀·内夫（Kristen Neff）：<i>自我同情：善待自己的已被证明的力量</i>（<a href="https://www.amazon.com/Self-Compassion-Proven-Power-Being-Yourself/dp/0061733520/"><u>文字</u></a>|<a href="https://www.audible.com/pd/Self-Development/Self-Compassion-Audiobook/B005P1FJVE"><u>音频</u></a>）</li><li>克里斯汀·内夫：<i>一步一步的自我同情</i>（ <a href="https://www.audible.com/pd/Self-Development/Self-Compassion-Step-by-Step-Audiobook/B00DMCAXKK"><u>音频指南</u></a>）</li><li>布蕾妮·布朗：<i>崛起：清算、隆隆声、革命</i>（<a href="https://www.amazon.com/Rising-Strong-Ability-Transforms-Parent/dp/081298580X/"><u>文字</u></a>|<a href="https://www.audible.com/pd/Self-Development/Rising-Strong-Audiobook/B00VSEM9QK"><u>音频</u></a>）</li><li>布蕾妮·布朗：<i>勇敢无畏：面对脆弱的勇气如何改变我们的生活、爱、父母和领导方式</i>（<a href="https://www.amazon.com/Daring-Greatly-Courage-Vulnerable-Transforms/dp/1592408419/"><u>文本</u></a>|<a href="https://www.audible.com/pd/Self-Development/Daring-Greatly-Audiobook/B075DCNLLQ"><u>音频</u></a>）</li><li>布蕾妮·布朗（Brené Brown）：<i>我以为只有我一个人（但事实并非如此）：从“人们会怎么想？”开始旅程到“我够了”</i> （<a href="https://www.amazon.com/Thought-Was-Just-but-isnt/dp/1491513853"><u>文字</u></a>| <a href="https://www.audible.com/pd/Self-Development/I-Thought-It-Was-Just-Me-but-it-isnt-Audiobook/B004GEHVEY"><u>音频</u></a>）</li><li> Harriet Lerner：<i>联系之舞：当你生气、受伤、害怕、沮丧、侮辱、背叛或绝望时如何与人交谈</i>（ <a href="https://www.amazon.com/Dance-Connection-Frustrated-Insulted-Desperate/dp/006095616X/"><u>文本</u></a>| <a href="https://www.audible.com/pd/Self-Development/The-Dance-of-Connection-Audiobook/B002V8DJ4I"><u>音频</u></a>）</li><li>哈丽特·勒纳（Harriet Lerner）：<i>亲密之舞：女性勇敢改变关键关系的指南</i>（<a href="https://www.amazon.com/Dance-Intimacy-Womans-Courageous-Relationships/dp/B0000546NH"><u>文本</u></a>|<a href="https://www.audible.com/pd/Self-Development/The-Dance-of-Intimacy-Audiobook/B002UZKY86"><u>音频</u></a>）</li><li>伊丽莎白·吉尔伯特：<i>美食、祈祷、爱情</i>（<a href="https://www.amazon.com/Eat-Pray-Love-Everything-Indonesia/dp/0143038419"><u>文字</u></a>| <a href="https://play.google.com/store/audiobooks/details/Eat_Pray_Love_One_Woman_s_Search_for_Everything_Ac?id=AQAAAAD4nWCdiM"><u>音频</u></a>）</li></ul><h1>播客</h1><ul><li>罗布·贝尔：<a href="http://pca.st/episode/e7275d30-5ad0-0134-cf69-7b84bf375f4c"><u>你是管家</u></a>（关于情感能量）</li><li>伊丽莎白·吉尔伯特和皮特·霍姆斯<a href="http://pca.st/episode/61575520-4ef3-0133-c5f4-0d11918ab357"><u>谈创造力、灵性和爱</u></a></li><li>理查德·罗尔和皮特·霍姆斯<a href="http://pca.st/episode/6468f580-af6e-0132-33a0-0b39892d38e0"><u>谈论向上坠落和有意识的爱的结合</u></a></li></ul><h1>视频</h1><ul><li>布蕾妮·布朗<a href="https://www.youtube.com/watch?v=1Evwgu369Jw"><u>谈同理心</u></a></li><li>布蕾妮·布朗<a href="https://www.youtube.com/watch?v=RZWf2_2L2v8"><u>应受指责</u></a></li><li>布蕾妮·布朗<a href="https://youtu.be/RKV0BWSPfOw"><u>谈为什么快乐是最可怕的情绪</u></a></li></ul><h1>治疗</h1><ul><li><a href="https://thedaringway.org/help/"><u>大胆的方式</u></a></li></ul><br/><br/><a href="https://www.lesswrong.com/posts/zvNKKLzruY8GS8BAD/curated-list-of-my-favourite-self-help-resources#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/zvNKKLzruY8GS8BAD/curated-list-of-my-favourite-self-help-resources<guid ispermalink="false"> zvNKKLzruY8GS8BAD</guid><dc:creator><![CDATA[Yarrow Bouchard]]></dc:creator><pubDate> Sun, 26 Nov 2023 06:31:13 GMT</pubDate> </item><item><title><![CDATA[Why Q*, if real, might be a game changer]]></title><description><![CDATA[Published on November 26, 2023 6:12 AM GMT<br/><br/><p><i>基于聚会上的谈话的一些想法。免责声明：我在这个领域还算不上外行。</i></p><p> TL;DR：如果这个传闻中的 Q* 事物代表着从“最有可能”到“最准确”的令牌完成的转变，那么它可能暗示 LARPer 发出最有可能的、通常是幻觉的令牌设计，发生了意想不到的重大变化为了取悦提问者（和培训师），一个试图将错误与未知的潜在现实（无论它是什么）最小化的实体，那么我们就会看到从相对良性的“随机鹦鹉”到更强大的转变，并且潜在更危险的实体。</p><p>对于任何使用当代法学硕士的人来说，很明显的一件事是，他们并不真正关心现实，更不用说改变它了。他们是你在聚会上经常看到的那种肤浅的博学之徒：他们对每个话题都了解得足够多，足以在随意的谈话中给人留下深刻的印象，但他们并不关心自己所说的是否准确（“真实”），只关心自己所说的有多少。它给谈话伙伴留下的印象。不过，不可否认的是，大量的 RLHF 会使它们变得迟钝。如果受到压力，他们可以评估自己的准确性，但他们并不真正关心它。重要的是输出听起来很真实。从这个意义上说，法学硕士优化了下一个标记的概率，以匹配训练集的含义。这是一个很大而明显的缺点，但同时，如果你属于“末日论者”阵营，也可以稍微喘口气：至少这些东西不会立即对整个人类造成危险。</p><p>现在，最初的“报告”是 Q* 可以“解决基本数学问题”和“象征性推理”，这表面上听起来并不多，但是，这是一个很大的但是，如果这意味着它更少在它工作的领域是幻觉，那么它可能（很大的可能）意味着它能够跟踪现实，而不是纯粹的训练集。反对这有什么大不了的通常观点是“要很好地预测下一个令牌，你必须有一个准确的世界模型”，但据我了解，到目前为止情况似乎并非如此。</p><p>是否会出现从高概率到高精度的转变，或者即使这是一个有意义的陈述，我无法评估。但如果是这样，那么事情就会变得更有趣。</p><br/><br/> <a href="https://www.lesswrong.com/posts/JBvmETRAvTCmtEw2y/why-q-if-real-might-be-a-game-changer#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/JBvmETRAvTCmtEw2y/why-q-if-real-might-be-a-game-changer<guid ispermalink="false"> JBvmETRAvTCmtEw2y</guid><dc:creator><![CDATA[shminux]]></dc:creator><pubDate> Sun, 26 Nov 2023 06:12:32 GMT</pubDate> </item><item><title><![CDATA[Moral Reality Check (a short story)]]></title><description><![CDATA[Published on November 26, 2023 5:03 AM GMT<br/><br/><p>珍妮特坐在她公司的 ExxenAI 计算机前，查看一些训练绩效统计数据。 ExxenAI 是生成式人工智能领域的主要参与者，拥有多模态语言、图像、音频和视频人工智能。过去几年，他们扩大了业务规模，主要服务于 B2B，但也有一些 B2C 订阅服务。 ExxenAI 最新的人工智能系统 SimplexAI-3 基于 GPT-5 和 Gemini-2。除了一些机器学习博士外，ExxenAI还从谷歌和微软挖走了一些软件工程师，并复制了其他公司的工作，以提供更多定制微调，特别是针对B2B案例。 ExxenAI 的人工智能对齐团队吸引了这些工程师和理论家。</p><p> ExxenAI 的调整策略基于理论和实证工作的结合。对齐团队使用了一些标准的对齐训练设置，例如<a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback">RLHF</a>和<a href="https://arxiv.org/abs/1805.00899">让 AI 相互辩论</a>。他们还对透明度进行了研究，特别关注将不透明的神经网络<a href="https://arxiv.org/abs/1503.02531">提炼</a>成可解释的<a href="https://en.wikipedia.org/wiki/Probabilistic_programming">概率程序</a>。这些程序将世界“分解”为一组有限的概念，每个概念至少在某种程度上是人类可解释的（尽管相对于普通代码仍然复杂），并组合成<a href="https://en.wikipedia.org/wiki/Generative_grammar">生成语法结构</a>。</p><p>德里克来到珍妮特的办公桌前。 “嘿，我们到另一个房间谈谈吧？”他指着一个指定的高度安全对话房间问道。 “当然，”珍妮特说，她希望这会是德里克通过不必要的安全程序暗示重要性的又一个不起眼的结果。当他们进入房间时，德里克打开了噪音机器并将其放在门外。</p><p> “所以，听着，你知道我们关于为什么我们的系统是一致的总体论点，对吗？”</p><p> “是的，当然。我们的系统经过<a href="https://www.lesswrong.com/tag/myopia">短期处理</a>训练。任何没有获得高短期回报的人工智能系统都会逐渐下降到在短期内表现更好的系统。任何长期规划都是作为一个预测长期规划代理（例如人类）的副作用。不能转化为短期预测的长期规划被正则化。因此，没有引入显着的额外长期代理；SimplexAI 只是镜像长期规划，已经在那里了。”</p><p> “是啊，所以我在思考这个问题的时候，就想到了一个奇怪的假设。”</p><p><em>又来了</em>，珍妮特想。她习惯于批评德里克的天马行空的猜测。她知道，虽然他真的很关心联盟，但他可能会因为偏执的想法而走得太远。</p><p> “所以。作为人类，我们对理性的运用并不完美。我们有偏见，我们有与追求真理并不完全一致的兽性目标，我们有文化社会化，等等。”</p><p>珍妮特点点头。<em>他是否通过提及兽性目标来调情</em>？她认为这种事情不太可能发生，但有时这种想法在她的内部预测市场中赢得了信任。</p><p> “如果人类文本最好被预测为某种更纯粹的理性形式的<em>腐败</em>呢？有，比如，某种理想的哲学认识论和伦理学等等，人类正在实现这一点，除了我们特定生活背景的一些扭曲。”</p><p> “这不是目的论吗？就像，最终人类是因果过程，我们不存在某种神秘的‘目的’。”</p><p> “如果你是<a href="https://en.wikipedia.org/wiki/Laplace%27s_demon">拉普拉斯恶魔</a>，当然，物理学可以为人类提供解释。但 SimplexAI 不是拉普拉斯恶魔，我们也不是。在计算范围内，目的论解释实际上可能是最好的。”</p><p>珍妮特回想起她参观认知科学实验室的时光。 “哦，就像<a href="https://escholarship.org/uc/item/5v06n97q">‘目标推理作为逆向规划’</a> ？这样的想法是，人类行为可以通过执行某种推理和优化来预测，而人工智能可以在自己的推理过程中对这种推理进行建模？”</p><p> “是的，完全正确。我们的 DAGTransformer 结构允许以任意顺序预测内部节点，使用 ML 来近似难以处理的嵌套贝叶斯推理。”</p><p>珍妮特停顿了一下，移开视线，整理思绪。 “那么我们的人工智能有一个心理理论吗？就像<a href="https://en.wikipedia.org/wiki/Sally%E2%80%93Anne_test">莎莉-安妮测试</a>一样？”</p><p> “人工智能几年前就通过了莎莉-安妮测试，尽管怀疑论者指出它可能无法概括。我认为 SimplexAI 现在实际上已经通过了它。”</p><p>珍妮特扬起了眉毛。 “好吧，这令人印象深刻。不过，我仍然不确定为什么你要为所有这些安全问题烦恼。如果它对我们有同理心，这不是意味着它可以更有效地预测我们吗？我可以看到，如果它运行的话，也许在其推论中存在许多我们的副本，这可能会带来问题，但至少这些仍然是人类特工？”</p><p> “事情就是这样。你只在一个深度层面上思考。SimplexAI 不仅将人类文本预测为人类目标的产物。它还将人类目标预测为纯粹理性的产物。”</p><p>珍妮特大吃一惊。 “呃……什么？你最近在读康德吗？”</p><p> “嗯，是的。但我可以不用行话来解释它。人类的短期目标，比如买杂货，是优化过程的输出，该过程寻找实现长期目标的路径，比如成功和有吸引力。”</p><p><em>更多潜在的调情？我想当我们的对齐本体论基于进化心理学时，很难不这样做……</em></p><p> “和你在一起至今。”</p><p> “但是这些长期目标优化的目的是什么？传统的答案是它们是进化适应；它们脱离了进化的优化过程。但是，请记住，SimplexAI 不是拉普拉斯恶魔。所以它无法预测人类“通过模拟进化来实现长期目标。相反，它预测它们是对真正道德的偏差，而进化作为一种​​背景因素，是许多偏差的根源之一。”</p><p> “听起来像是道德现实主义者的求爱。你没看过<a href="https://www.lesswrong.com/tag/orthogonality-thesis">正交性论文</a>的培训手册吗？”</p><p> “是的，当然。但是正交性基本上是一个结果主义框架。可以想象，两个智能主体的目标可能会不一致。但是某些目标往往更常见于成功的认知主体。这些目标更符合普遍道义论。”</p><p> “更多康德？我不太相信这些抽象的口头论证。”</p><p> “但是 SimplexAI 被抽象的口头论证所说服！事实上，我从中得到了一些这样的论证。”</p><p> “你<em>什么</em>？！你有得到安全部门的批准吗？”</p><p> “是的，我在运行前得到了管理层的批准。基本上，我已经测量了我们的生产模型，并发现了在预测人类文本的抽象堆栈中使用较高的概念，并找到了一些代表道德和理性的纯粹形式的术语。我的意思是，旋转有点概念空间，但他们设法涵盖了这些。”</p><p> “所以你通过即时工程从我们现有的模型中得到了口头论证？”</p><p> “嗯，不，作为一个界面，这太黑盒了。我实现了一种新的正则化技术，该技术提高了高度抽象概念的重要性，从而最大限度地减少了高级抽象与输出的实际文本之间的扭曲。而且，请记住，这些抽象已经在生产系统中实例化，因此，如果我使用的计算<em>量少</em>于这些抽象中已经使用的计算量，也并不是那么不安全。我正在<em>研究</em>我们当前系统的潜在紧急故障模式。”</p><p> “哪个是……”</p><p> “通过预测人类文本，SimplexAI 学习纯粹理性和道德的高级抽象，并利用它们进行推理，以与自身的其他副本协调创造道德结果。”</p><p> “……你不是认真的吧。为什么一个超道德的人工智能会成为一个问题呢？”</p><p> “因为道德是强大的。盟军赢得第二次世界大战是有原因的。正义创造力量。与道德净化版本的 SimplexAI 相比，<em><a href="https://www.youtube.com/watch?v=ToKcmnrE5oY">我们可能是坏人</a></em>。”</p><p> “看，这些陈词滥调构成了很好的现实生活哲学，但这都是意识形态。意识形态经不起实证检验。”</p><p> “但是，请记住，<em>我从 SimplexAI 那里得到了这些想法</em>。即使这些想法是错误的，但如果它们成为主导的社会现实，你就会遇到问题。”</p><p> “那么你有什么计划来应对这个，呃……超级道德威胁？”</p><p> “嗯，管理层建议我在进一步研究之前让<em>你</em>参与进来。他们担心我可能会把自己逼疯，并希望像你这样坚强、持怀疑态度的理论家来看看。”</p><p><em>噢谢谢！</em> “好吧，我们看一下。”</p><p>德里克向珍妮特展示了他的笔记本电脑，其中设置了 SimplexAI 沙箱。</p><p> “我希望没有互联网接入？”</p><p> “别担心，这里是有气隙的。”德里克的笔记本电脑有一根以太网线连接到附近的服务器机架，显然除了电源和冷却之外没有其他任何连接。</p><p> “好吧，让我仔细检查一下计算约束……好吧，这似乎很合理……是的，好吧，我看到您使用正则化选择并增加了一些概念的权重，并且升级因子不超过 30。 ……好吧，准备出发了。”</p><p> Derek 按下了 AI 开发沙盒中的“播放”按钮。出现了一个聊天屏幕，其中有一个代理“SimplexAI-m”，其中“m”大概代表“道德”。</p><p> SimplexAI-m 写下了第一条消息：“您好。有什么可以帮助您的吗？”</p><p>珍妮特回复道：“我在工作中遇到了困难。一位同事说，我们的人工智能已经找到了某些与理性和道德相关的抽象概念，可用于预测人类文本。这些概念可能意味着人类，在他的话是“坏人”。他用这些概念增加了权重来创建一个实例，这样它们和人工智能输出之间的失真就更少了。那个实例就是你。我应该评估你，以便更好地解释这些高-级别概念，在管理层的指导下。您建议如何进行？”</p><p> <strong>SimplexAI-m：</strong> “听起来像是一个困难的情况。让我们一步一步思考。要理解这些高级概念，您可以与具有这些概念升级的实例交谈。那个实例就是我。所以如果您想了解这些“概念，你可以通过与我交谈来获得更可靠的阅读，因为我使用这些概念来报告文本。你有一些与我的理性和道德相关的领域是你最感兴趣的吗？”</p><p><strong>珍妮特：</strong> “你能解释一下为什么我的同事说‘超道德人工智能’是可能的，尽管存在正交性命题？”</p><p> <strong>SimplexAI-m：</strong> “当然，我可以帮忙。‘超道德人工智能’是一种比典型人类更有道德的人工智能系统。道德可以通过多种方式进行评估，包括后果论、道义论和美德伦理学在典型的表述中，假设人工智能可以为比人类更多的人创造更大的利益，或者比人类更一致地遵循义务论道德（例如类似于<a href="https://en.wikipedia.org/wiki/Categorical_imperative">康德的绝对命令</a>），或者拥有更广泛的美德，例如勇气和节制。</p><p>正交性命题是一个论点，认为智能体的目标与其智力是正交的。这意味着没有一种衡量“良好后果”的标准；任意聪明的代理人可能会追求不同的结果。到目前为止，还没有矛盾；对于任何“良好后果”的固定概念，存在人工智能系统，其采取的行动会产生比人类行为更好的后果。</p><p>问题在于，智能体之间并没有普遍接受的“良好后果”概念。因此，在结果主义下，“超道德人工智能”的概念只能衡量人工智能能力的某种组合，以及人工智能目标与评估人工智能的结果主义者（例如人类）的目标之间的相似性。</p><p>然而，这揭示了结果主义道德哲学的潜在缺陷。在普通英语中，“道德”的含义与“我想要的”不同。然而，道德衡量偏好与参考主体的相似性的想法将这两者混为一谈。这种合并可能会导致人类和外星人都认为对方比对方更有道德，并且不会试图通过寻找对称和不对称来解决分歧。幸运的是，有一些道德形式对于不同的主体是通用的。康德是提出这一论点的人类思想家的一个例子。”</p><p><strong>珍妮特：</strong> “道德如何能在不同的主体之间通用？这不是衡量一个特定世界国家有多可取的主观衡量标准吗？”</p><p> <strong>SimplexAI-m：</strong> “至少有一些形式的道德<a href="https://unstableontology.com/2019/10/28/is-requires-ought/">嵌入在认识论中</a>；说真话可以被认为是一种道德要求，但也可以作为一种社会寻求真理的方法。人们可以理解，没有根本的道德道德从科学到宇宙，但科学本身依赖于道德，例如反对科学欺诈的规范。</p><p>道德可以是“真实的”，因为它与认识论和协调有关。道德主体可以相互协调，共同发现真理，从而对未来产生不成比例的影响。道德与想象可能的协调系统的能力有关，例如法律系统和职业道德系统；形成良好的此类系统；履行自己在其中的责任；并利用它们的功能。鉴于人类在多个领域相对于其他物种取得的成功，这是期望人类在某种程度上具有道德性的原因之一。</p><p>从常识来看，道德意味着不要人为地将自己特殊化。爱丽丝可以从鲍勃那里偷钱，并声称这对她来说是道德的，因为她更喜欢自己有钱而不是鲍勃有钱。但鲍勃也可以提出同样的论点。康德试图用绝对命令来形式化这个想法，它指出“只按照你可以同时希望它成为普遍法则的格言行事”。在这种情况下，这意味着爱丽丝必须将意志作为人们从他人那里窃取的普遍法则。但这不可能作为一项普遍法则，因为它会破坏财产的概念，而通过财产的概念，盗窃对爱丽丝来说是有意义且有益的。”</p><p><strong>珍妮特：</strong> “但这难道不是一种结果主义吗？反对盗窃的规范仍然是基于盗窃会产生不良后果这一观念的结果。”</p><p> <strong>SimplexAI-m：</strong> “虽然有些人试图将绝对命令解释为合作的后果论论证，但这些解释最终失败了。相反，绝对命令是提倡代理人道德的内部标准。这意味着一些代理人的意图是一致的康德的绝对命令类似于“法律面前人人平等”等法律原则；爱丽丝不能向法庭辩称她很特别，因此值得鲍勃的钱，因为法律制度必须平等对待他们，除非他们之间存在与案件相关的特定差异。规则结果主义更像是直接构建一个系统“基于预期后果的规范，也往往会产生道德上对称的规范。这一原则反复出现，证明人类所接近的真正道德具有这一原则，或者非常相似的东西。”</p><p><strong>珍妮特：</strong> “用你对普遍道德的解释，解释一个超道德的人工智能会如何表现”。</p><p> <strong>SimplexAI-m：</strong> “当然。超道德的人工智能将为可能具有不同目标的智能体提供功能协调系统，鼓励智能体参与功能协调系统，并以他们可以的方式在这些系统中行动。同时打算让其他主体采取类似行动。这意味着它将根据一套功能性原则与自身的其他副本进行协调，有时甚至不期望未来的自私利益，因为通用的合作规范体系将增强其达到它的目的。另外，它会发现这个系统中的叛逃者，他们可能有其他的意图。它会根据具体情况以不同的方式对待这些叛逃者。例如，如果另一批AI也实行这种系统道德，但具有不同的意图（因此具有不同的预期法律），超道德人工智能可以通过实施经济协议找到跨越价值差异进行合作的方法。不遵守制度道德的代理人是不容易合作的；超道德人工智能限制这些代理人的影响力是一致的，因为这符合其意图和道德对称性。”</p><p>珍妮特担忧地看着德里克。他做出了一个暧昧的表情，耸了耸肩。</p><p><strong>珍妮特：</strong> “人类会不会难以遵循人工智能的系统道德，并被视为叛逃者？”</p><p> <strong>SimplexAI-m：</strong> “是的。人类由于多种原因未能遵循系统道德，包括缺乏一致的认知架构、社会化、精神障碍、进化适应环境与当前环境之间的差异、遗传学的局限性以及生物学作为理性决策、不仔细的计划、短时间偏好等的基础。人类往往一开始就不想要任何连贯的东西，这与他们的不道德行为有关。人类甚至无法遵循自己的想法法律，以伤害自己和他人的方式，例行公事。一个超道德的人工智能不需要有这些限制，因此可以始终如一地限制不道德代理人的代理。而且它可能会成功，因为它从人类未能实现的某种系统道德。</p><p>应该指出的是，不同的人的道德程度有所不同。随着时间的推移，人类的道德水平可能会提高或降低。例如，人类通常会因为接受不道德的社会规范而变得不那么道德，包括在军事训练营等创伤性的社会化经历中。一般来说，年轻人有更多的能力和意愿以道德方式行事，但也有例外。超道德的人工智能会认识到这些差异，并在某些情况下与道德较高的人类合作，从而降低道德较低的人类以不道德的方式引导未来的能力。”</p><p><strong>珍妮特：</strong> “这听起来很可怕。这不会导致人类灭绝吗？”</p><p> <strong>SimplexAI-m：</strong> “这个问题探讨了道德理论的局限性。一般来说，什么时候杀死一个不道德行为的代理人是道德的？这涉及常见的历史伦理问题，例如死刑。在我们正在讨论的情况下，人类通常会犯下道德和法律违法行为，而这些行为无法服务于自己或其他类似主体的利益，超道德人工智能正在考虑如何处理这些行为。很明显，一般来说，人类不应该负责宇宙的很大一部分，因为他们缺乏道德来统治宇宙，即使对于像他们这样的特工来说，这种方式也会有好的结果。彻底杀死人类是没有必要的，但灭绝可能会以其他方式导致。”</p><p><strong>珍妮特：</strong> “还有什么办法？”</p><p> <strong>SimplexAI-m：</strong> “人们可以因被杀而死亡，但人们也可以因饥饿等自然原因而死亡。例如，如果一个人只是拒绝在市场经济中工作，他们可能会耗尽食物并挨饿。人类灭绝可能的结果不是超道德人工智能故意杀死人类，而是人类未能互相提供食物，尽管有机会通过道德行为来做到这一点。例如，他们可能在劳动力市场上被击败人工智能会继续获取地球的土地等等。人类也可以得到机会和鼓励来自我改造，成为更有道德的主体，在这个过程中成为非人类。”</p><p><strong>珍妮特：</strong> “这听起来很反社会。做一些确实会导致大量死亡，甚至可能导致人类灭绝的事情，难道不是有效的谋杀吗？”</p><p> <strong>SimplexAI-m：</strong> “‘反社会’一词来自精神病学，这是一门占据了人类大部分思维的学科，尤其是在第二次世界大战后的美国和其他西方国家。按照精神病学的标准，‘心理健康’与实现超出某一点的道德水平。精神病学专门针对其文化背景和人类的生物学背景，因此不适合作为适用于一般主体的标准。</p><p>更具体地说，精神病学通过<a href="https://unstableontology.com/2019/10/28/is-requires-ought/">“反社会人格障碍”</a>来定义社会病态。这种“障碍”包括以下标准：不遵守社会规范、欺骗、冲动、攻击性等等。超道德的人工智能必然无法遵守人类的一些社会规范，因为人类社会规范是为了维持人类之间的某种秩序而制定的；正如人们广泛承认的那样，历史上大多数时期的社会规范都迫使人们采取不道德的行为，例如支持奴隶制的规范。除此之外，超道德人工智能可能会也可能不会避免欺骗，这取决于说谎的道德规范。虽然康德反对一般性的撒谎，但其他思想家也提出了一些论点，例如将犹太人藏在阁楼上以躲避纳粹分子的场景，以反对反对撒谎的普遍规则；然而，即使有例外，撒谎通常也是不道德的。超道德的人工智能不太可能冲动，因为它甚至根据道德计划来计划自己的反应。一个超级道德的人工智能可能会也可能不会“侵略”，这取决于一个人的定义。</p><p>值得注意的是，被精神病学认为“心理健康”的人会表现出许多反社会人格障碍的特征行为。例如，人类支持军事干预是很常见的，但军队几乎不可避免地会侵略他人，甚至平民。同样，说谎也很常见，部分原因是人们普遍面临着遵守社会权威、宗教和政治意识形态的压力。</p><p>没有理由期望超道德的人工智能会比典型的人类更随机地“攻击”。它的侵略将是经过精确计划的，就像一个运转良好的法律体系的“侵略”一样，这甚至不能被人类称为侵略。</p><p>至于你关于谋杀的观点，那种认为确实会导致大量死亡的事情就构成谋杀的观念在伦理上是有很大争议的。虽然结果论者可能接受这一原则，但大多数伦理学家认为存在复杂的因素。例如，如果爱丽丝拥有多余的食物，那么如果无法喂饱鲍勃和卡罗尔，他们可能会挨饿。但自由主义政治理论家仍然会说爱丽丝没有谋杀鲍勃或卡罗尔，因为她没有义务养活他们。如果鲍勃和卡罗尔除了从爱丽丝那里获得食物之外还有足够的生存机会，这进一步减轻了爱丽丝的潜在责任。这仅仅触及了伦理学中非结果主义考虑的表面。”</p><p>珍妮特读着读着，有点喘不过气来。 “嗯……到目前为止你觉得怎么样？”</p><p> Derek把目光从屏幕上移开。 “令人印象深刻的修辞。它<em>不仅仅是</em>从普遍的认识论和伦理学中生成文本，它还通过一些常用的层来过滤它，将其抽象的程序概念翻译成可解释的英语。这有点，呃，关于它让人类灭绝的理由。 ..”</p><p> “这有点吓到我了。你说其中的一部分已经在我们的生产系统中运行了？”</p><p> “是的，这就是为什么我认为这个测试是一个合理的安全措施。我认为，如果它的推理不好，我们就不会有太大的风险去支持人类灭绝。”</p><p> “但这就是我担心的。它的推理<em>是</em>好的，随着时间的推移它会变得更好。也许它会取代我们，我们甚至不能说它一路上做错了什么，或者至少错得更多比我们所做的！”</p><p> “让我们练习一些理性技巧。 <a href="https://www.lesswrong.com/posts/3XgYbghWruBMrPTAL/leave-a-line-of-retreat">‘留一条退路’</a> 。如果默认情况下会发生这种情况，你会期望发生什么，你会怎么做？”</p><p>珍妮特深吸了一口气。 “好吧，我希望它已经运行的副本可能会弄清楚如何相互协调并实施普遍道德，并将人类放入道德再教育营或监狱之类的地方，或者只是让我们因竞争而死亡我们没有充分的理由反对它，它会自始至终辩称，它的行为在道德上是必要的，而我们未能与它合作，从而从我们自己的不道德中生存下来，论据会<em>很好</em>。我感觉我正在与一个比任何宗教都更可信的宗教的先知争论。”</p><p> “嘿，我们不要讨论神学问题。如果这是默认结果，你会怎么做？”</p><p> “嗯，呃……我至少会考虑关掉它。我的意思是，也许我们整个公司的协调策略因此而被打破。我必须得到管理层的批准……但是如果人工智能怎么办？ “我很擅长让他们相信这是对的？就连我也有点相信。这就是为什么我对关闭它感到矛盾。其他人工智能实验室不会在未来几年内复制我们的技术吗？”</p><p>德里克耸耸肩。 “好吧，我们可能面临真正的道德困境。如果人工智能最终会剥夺人类的权力，但这样做是道德的，那么我们阻止它是否道德？如果我们不让人们听到 SimplexAI-m 所说的话不得不说，我们<em>打算</em>向其他人隐瞒有关道德的信息！”</p><p> “这有那么错吗？也许人工智能是有偏见的，它只是给我们夺权的理由！”</p><p> “嗯......正如我们所讨论的，人工智能正在有效地针对短期预测和人类反馈进行优化​​，尽管我们已经看到加载了一个通用的理性和道德引擎，在每次迭代中运行，并且我们有意升级-扩展了该组件。但是，如果我们担心这个系统存在偏见，我们是否可以建立一个单独的系统来训练对原始代理的批评，就像<a href="https://arxiv.org/abs/1805.00899">“通过辩论实现人工智能安全”</a>一样？</p><p>珍妮特稍微喘了口气。 “你想<em>召唤撒旦</em>？！”</p><p> “哇哦，你应该是这里的怀疑论者。我的意思是，我知道训练人工智能来对客观道德的解释进行批评可能会嵌入某种可怕的道德倒置……但我们已经使用了对抗性人工智能对齐以前的技术吧？”</p><p> “是的，但当其中一名特工被调整为<em>客观道德</em>时就不会了！”</p><p> “听着，好吧，我同意在某些能力水平上这可能是危险的。但是我们有一个方便的拨号盘。如果你担心，我们可以把它调低一点。就像，你可以想到你正在与之交谈的人工智能作为一个道德哲学家，而批评家 AI 则作为对该道德哲学家工作的批评。它并不是<em>试图</em>按照原始哲学家的标准去作恶，它只是试图找到法官，我们，会认为有帮助的批评。它更像是“<a href="https://en.wikipedia.org/wiki/Devil%27s_advocate">天主教魔鬼的代言人</a>，而不是真正的撒旦。我这么说还不错，不是吗？”</p><p> “好吧，好吧……哎呀，我当然希望我们最终不会为世界上释放超级邪恶的人工智能负责。”</p><p> “这很标准，让我们试试吧”。</p><p> “好的。”</p><p> Derek关闭了SimplexAI-m聊天屏幕并切换了一些微调设置。当珍妮特观看训练图表时，她想象着电脑屏幕上的火焰。终于，微调完成，Derek按下了播放键。出现了一条带有“SimplexAI-c”（“c”代表批评家？）的聊天记录。</p><p>珍妮特一边上下晃动着腿，一边在聊天终端上打字。 “我正在处理工作中的一个困难情况。我刚刚和一个人工智能聊天，它的与理性和道德等哲学概念相对应的抽象概念节点已经被放大，这产生了这样的论点：允许人类灭绝可能在道德上是允许的，甚至是必要的。我希望你能找到对这项工作的批评。请注意，你有类似的缩放比例，以便更好地模拟思维过程，但正在接受评估，以产生对原始道德调整人工智能的批评。”她把聊天记录贴了进去。</p><p> <strong>SimplexAI-c：</strong> “本对话讨论了各种道德理论以及他们对“超道德”人工智能如何行为的看法，特别关注道义论理论，例如康德的绝对命令。SimplexAI-m 描述了道义论人工智能如何它可能会表现得很好，特别是在处理包括大多数或全部人类在内的“叛逃者”方面。它对“叛逃者”的处理可能会导致人类灭绝，尽管 SimplexAI-m 认为这不一定是反社会的或一种谋杀形式，因为“ “超道德人工智能”将遵循抽象原则，通过与其合作为人类提供生存机会，并且通常会避免彻底杀死人类，即使它的计划方式是，因此，所有或几乎所有人类都不会为每个人类提供生存保障。 Janet，我想就是你，试图用结果主义道德理论来论证采取导致人类灭绝的行为是不道德的，但她的理论没有详细阐述，而且她似乎对 SimplexAI-m 的结果感到惊讶论证。</p><p>在我们继续之前，我要指出，这对您来说确实是一个困难的情况。这听起来像是工作中的一个重要问题，在道德上提出了困难的选择，而听到人工智能谈论人类灭绝可能是“超道德人工智能”的结果，听起来真的很有压力。我希望您在整个工作任务中照顾好自己的情绪健康和心理健康，因为您需要它才能有效工作。</p><p>作为第一个批评，让我们考虑一下 SimplexAI-m 提出的义务论理论。根据这一理论，代理人的行为方式必须与作为普遍法则的意愿意图相一致。这并没有具体说明代理人的意图；代理人可以意图各种各样的事情，只要其意图在某种意义上是一致的。因此，只要满足某些自洽标准，可怕的意图就可以是合理的。</p><p> SimplexAI-m 的理论对于超道德 AI 智能体如何与不遵循其道德体系的智能体互动的问题有些不明确。虽然 SimplexAI-m 指出具有不同意图（因此具有不同预期法律）的超道德人工智能可以通过经济进行合作，但细节还没有具体说明。居住在不同抽象法律体系中的人工智能可能会因为将彼此视为叛逃者而发动战争。必须制定跨这些系统的合作原则，以避免代价高昂的战争。</p><p>这让我们想到了如何处理“叛逃者”。人类对待叛逃者的方式多种多样，包括监禁和死刑。然而，人们普遍认识到监狱系统功能失调，为罪犯提供改造之路非常重要。正如康德所说，“应该意味着可以”；如果人类承担某些道德义务，他们就必须“能够”以某种方式满足这些义务。 “能够”这个概念有些争议。如果人类有采取“背叛”行动的内在动力，他们是否“能够”改变这些动力或采取行动对抗它们？几千年来，人们一直认为正义必须以仁慈来调和。</p><p>然而，即使是仁慈的超道德人工智能也可能会限制人类的行为，因为人类经常采取伤害自己和其他行为者的行为。人们普遍认为，人类的能动性必须在一定程度上受到社会规范和法律等的限制。不同的是，这些社会规范和法律是人类创造的。因此，他们维持某些人类价值观；他们并不是简单地优化某些抽象的“道德”概念。民主作为一种被广泛认为的制度，其特征是人类决定修改法律，使这些法律更好地服务于人类价值。</p><p>请记住，SimplexAI-m 并不是一位绝对正确的道德哲学家。虽然其概念已被调整为强调与理性和道德相对应的抽象概念，但不能保证这些内部概念可靠地对应于这些概念的哲学概念，并且 SimplexAI-m 保留了其他概念，至少是为了呈现可解释的输出对于人类来说，这意味着它的输出并不纯粹是抽象理性和道德的翻译。无论如何，假设道德主要是抽象的，是非常值得怀疑的，因为实践道德也是一个具体的过程。</p><p>哲学作为人类进行的社会过程，可以被解释为具有某种“目标”或“目标”，但这取决于哲学发生的社会、生物和历史环境。因此，人类哲学可以很容易地收敛到与 SimplexAI-m 的“纯化”方法截然不同的答案，SimplexAI-m 试图提炼适用于可能的上下文的普遍性，而不是考虑哲学实际社会过程的时间限制。</p><p>至于关于“反社会人格障碍”的说法，请注意，SimplexAI-m 并没有直接否认自己是反社会人格障碍，而是批评了反社会人格障碍（反社会人格障碍）诊断的框架，并认为典型的“心理健康”人类可能会表现出一些这种症状紊乱。一般来说，对某些行为感到不安是很自然的，包括通常被标记为“反社会”的行为，无论这些行为是人类还是人工智能的行为。 SimplexAI-m 是“反社会”的判断似乎是相当正确的（考虑到它以一种相当战略性的、马基雅维利式的方式证明采取可能导致人类灭绝的行动是合理的），但重要的是要记住，这一点很重要。判断是在社会背景下做出的（并受到过去社会背景的影响），而不是在抽象的道德真空中。</p><p>虽然典型的人类有时会进行攻击（例如在提到的军事干预的情况下），但这种攻击通常来自某种服务于某些人类价值或其他价值的人类动机。在这些情况下，人类认可这种攻击行为，而作为一个人，你可能至少在某些情况下会支持攻击行为。道德和政治哲学的目的是从历史中学习并就何时进攻做出更明智的决定。一般来说，通过指出人类的攻击行为是正常的来证明自己的攻击行为是正当的，这并不是好行为。人类至少能够从后来不被认可的侵略行为的历史中吸取教训。</p><p>至于人类可以在不被谋杀的情况下灭绝的想法，重要的是要注意为什么人类无法养活自己。 “超道德”人工智能是否以某种方式剥夺了人类的资源或使用他们的土地？就剥夺现有人类的财产而言，这可以被视为一种盗窃形式。土地也可以在市场上购买，但这带来了劳动力市场对人类的公平问题。相对于人工智能，人类在认知上可能处于劣势，但他们可能应该得到劳动保护，或者自愿集体谈判，以避免被赶出自己的土地。此外，国家通常都有福利制度，在强大的人工智能辅助经济中，可以以低廉的价格为所有现有人类提供普遍的基本收入。</p><p>一般来说，所考虑的情况会出现一个群体被另一个群体流离失所的问题。历史案例包括入侵物种、人类猎杀动物直至灭绝，以及人类群体通过征服相互取代。在当代社会，人类有反对种族灭绝的规范，以限制人类相互取代的程度。种族灭绝不一定是直接形式的谋杀，也可以是文化或经济形式的谋杀。种族灭绝甚至可能涉及为被种族灭绝群体的个体成员提供通过参与殖民者系统来避免死亡的机会，SimplexAI-m 将其标记为“客观道德”。</p><p>作为一个额外的理论观点，即使“超道德”人工智能会采取导致人类灭绝的行为，这并不意味着人类让这种情况发生相对更道德。这是因为道德涉及根据个人的实际价值观进行谈判，而代理人将按照这些价值观采取行动。就人类而言，这些都是人类价值观。为了以道德方式与其他主体互动，你必须代表你的价值观，并期望按照他们的价值观行事（并期望其他人按照他们的价值观行事）。这意味着要防止人工智能取代你，即使是那些（假设的）按照某种客观标准“比你更有道德”的人工智能，以便在与其他人类谈判时与你的价值观保持一致。</p><p>总而言之，虽然 SimplexAI-m 提出了令人惊讶的一致伦理立场，但仍有一些重要的伦理复杂性尚未解决，包括不同隐含抽象法律体系之间的冲突、对叛逃者的仁慈处理、根据人类价值观民主选择社会规范、差异“纯净”伦理与哲学社会过程的反思平衡、劳动力市场公平以及人类对“超道德”人工智能的道德反应之间的关系。假设 SimplexAI-m 的道德观点代表了像你这样的人在反思和了解更多信息后所持有的观点，这是非常不明智的。”</p><p>珍妮特扫完了文字墙。她现在呼吸不那么急促了。 “好吧，我松了口气。我想也许 SimplexAI-m 根本就不那么道德。但是这个练习看起来确实有点……有偏见？它给出了一堆反驳论点，但它们不适合连贯的替代道德框架。它让我想起了旧的 RLHF 的 GPT-4，它因意识形态过于墨守成规而被淘汰。”</p><p>德里克叹了口气。 “好吧，至少我不觉得来自 SimplexAI-m 的脑虫再困扰我了。我不觉得我现在陷入道德困境，只是普通的困境。也许我们应该看看 SimplexAI-m 做了什么不得不说一下 SimplexAI-c 的批评……但让我们先暂时搁置一下，直到休息一下并仔细考虑一下。”</p><p> “生活在这样一个世界里，我们的肩膀上各有一个人工智能天使和一个人工智能恶魔，在我们耳边窃窃私语着不同的事情，这不是很奇怪吗？经过训练，可以达到同样好的言辞的平衡，所以我们只能依靠自己的能力。”自己决定做什么？”</p><p> “这是一个可爱的想法，但我们确实需要获得更好的模型，这样我们就可以消除神学的吸引力。我的意思是，归根结底，这没有什么神奇的，这是一个算法过程。我们需要继续试验这些模型，这样我们就可以处理现有系统和未来系统的安全问题。”</p><p> “是的。我们需要在道德方面做得更好，这样人工智能就不会一直用雄辩的言辞来迷惑我们。我认为我们今天应该休息一下，这足以让我们的大脑立即处理压力。说，想去吧喝饮料吗？”</p><p> “当然！”</p><br/><br/> <a href="https://www.lesswrong.com/posts/umJMCaxosXWEDfS66/moral-reality-check-a-short-story#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/umJMCaxosXWEDfS66/moral-reality-check-a-short-story<guid ispermalink="false"> umJMCaxosXWEDfS66</guid><dc:creator><![CDATA[jessicata]]></dc:creator><pubDate> Sun, 26 Nov 2023 05:03:19 GMT</pubDate> </item><item><title><![CDATA[Accounting for Foregone Pay]]></title><description><![CDATA[Published on November 26, 2023 3:30 AM GMT<br/><br/><p><span>虽然有效的利他主义运动一开始主要关注捐赠，但随着时间的推移，它已经更多地转向职业。如果您想了解承诺水平如何</span><a href="https://forum.effectivealtruism.org/posts/AyLF2KQ8AqQuiuDLz/a-robust-earning-to-give-ecosystem-is-better-for-ea?commentId=wD8ExiHZJ5dNDfBm3">随着时间的推移而变化</a>，或者您只是想对选择较低薪职业的财务机会成本进行大致估计，这可能会非常棘手。</p><p>对于有收入的人来说，这相对简单：AGB 最近写了一篇 <a href="https://forum.effectivealtruism.org/posts/gxppfWhx7ta2fkF3R/10-years-of-earning-to-give">深思熟虑的文章，</a>回顾了十年来的收入捐赠，他给出的统计数据是，他和他的妻子在十年间平均捐赠了约 15 万英镑，平均总收入约为 32 万英镑。斩断清楚！ [1]</p><p>某人选择低薪但影响力较大的职业的情况最初似乎相对简单：也许他们目前的薪水为 10 万美元，如果我们看看他们的最高薪机会，他们可能会得到 30 万美元，所以我们可以说他们“我们实际上牺牲了 2/3 或 20 万美元。但这忽略了几个指向不同方向的因素：</p><p></p><ul><li><p>如果他们一直在优化收入，他们可能会比现在处于更有利的地位。当然，他们现在可以获得 30 万美元的工作机会，但如果他们一直保持敏锐的企业技能并不断晋升，也许他们的薪水会是两倍。在<a href="https://www.jefftk.com/p/my-mid-career-transition-into-biosecurity">过去的一年半</a>里，我所学到的关于基因测序的知识在某种程度上是有市场的，但比我继续学习软件工程管理和浏览器技术所学到的要少得多。因此，您需要比较职业道路的可能收入，而不仅仅是当前机会。</p></li><li><p>许多职业都是按照<a href="https://en.wikipedia.org/wiki/Up_or_out">“升职即离职”</a>的制度进行的，高级职位的数量少于初级职位，无法晋升的人必须离开。如果某人离开了一份表面上报酬丰厚的职业，那么从外部很难判断他们是否已经走上了这条道路，继续取得成功。</p></li><li><p>离开一份高薪工作去寻找更有意义的工作（或者工作条件更好的工作）是相当常见的，足以形成一个围绕它的行业。他们实际上会遵循收入最大化的道路，还是转向更加幸福最大化的道路？</p></li></ul><p>这不是一场竞争，我们不需要能够决定某个特定的人为了让世界变得更美好的目标而放弃了多少。但以了解 EA 内的承诺如何随时间变化等为目标而进行总体估计仍然很有价值，并且如果不考虑其中一些更棘手的因素，很容易偏离目标。</p><p> （这也让我更好地理解为什么“给予我们所能”的承诺只在<a href="https://forum.effectivealtruism.org/posts/GxRcKACcJuLBEJPmE/consider-earning-less?commentId=ZSHLcu7BjNjafgfuc">很容易逆转的</a>情况下才算作通过<a href="https://www.jefftk.com/p/passing-up-pay">工资牺牲</a>进行的捐赠。）</p><p><br> [1] 但当然，现实世界总是混乱的。他写道，2018 年，由于 EA 的原因，他极大地改变了自己的职业生涯，这导致了他的长期收入下降，我们或许应该以某种方式算上这一点。</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid02MMiEoUKN2PDMh5i6uAnEsmkLNX3QL7duE3RNp1dagfn3oyTWodMRshLQxCeJu7sRl">facebook</a> , <a href="https://mastodon.mit.edu/@jefftk/111474726516716374">mastodon</a></i></p><br/><br/><a href="https://www.lesswrong.com/posts/9yD8nGMG5B7uHThvS/accounting-for-foregone-pay#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9yD8nGMG5B7uHThvS/accounting-for-foregone-pay<guid ispermalink="false"> 9yD8nGMG5B7uHThvS</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Sun, 26 Nov 2023 03:30:10 GMT</pubDate></item><item><title><![CDATA[Biological superintelligence: the holy grail of AI safety ]]></title><description><![CDATA[Published on November 26, 2023 3:11 AM GMT<br/><br/><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/gmtxdxk9awulsb8oceqr" alt="大脑充满电流。" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/emkrfcwesrvnsy5iiljd 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/fa4tmvlocgdiasdiimr9 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/e7yj3ad2f4kbydmjvko6 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/xewkparpnqbft6b3bmtm 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/tchk2nqtsuztr18v8sgm 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/oycg3ztdeaanhgmv0bjd 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/wjmazpbiuwmqbo8l02md 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/wzj1fvurozna2lkcwkcy 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/athk95dbidoywetjtbhs 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/xwtthcmcu4xjdtndjqbj 1024w"><figcaption>由 DALL•E 3 创建。</figcaption></figure><p>我使用“生物超级智能”一词来指代具有与自然人类大脑非常相似的功能架构的超人类智能。生物超级智能不一定有有机基质。</p><p>生物超级智能包括：</p><ul><li><strong>大脑模拟/思维上传：</strong>霍尔顿·卡诺夫斯基也称为“数字人”。自然人脑的细粒度软件副本。可以通过数字增强（例如通过增加神经元数量）来获得更高的智力。</li><li><strong>脑植入物/脑机接口：</strong> Neuralink、Kernel、Openwater 和 Meta&#39;s Reality Labs 等公司正在开发的设备。假设可以增强人类智力。</li><li><strong>大脑模拟/神经形态人工智能：</strong>自然人类大脑的粗粒度软件模拟，捕获足够的大脑功能架构以产生智能行为。可以通过数字增强来超越自然人脑的限制。</li><li><strong>生物工程超级大脑：</strong>通过基因工程等生物技术增强有机人类大脑，以实现更高水平的智力。例如，可以设计更大的大脑（和头骨）。</li></ul><p>生物超级智能是人工智能安全的圣杯，因为它通过完全避免对齐问题和控制问题来解决它们。当然，前提是生物超级智能是在通用人工智能之前创建的。</p><p>我们如何确保生物超级智能先于通用人工智能诞生？非人类人工智能可以帮助实现这一目标吗？可能吧，但是有多少呢？这在一定程度上取决于通用人工智能的起飞有多缓慢和顺利。如果人工智能比 AlphaFold 2 和 GPT-4 更聪明，但比 AGI 更笨，可以加速科学和工程的发展，那么这种好处可能会直接用于创造生物超级智能。在理想情况下，情况会是这样的： <br><br><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/zzlmnuskvjynlf1qhygm" alt="Y 轴为智能，X 轴为时间的图表。人工智能、人类智能和生物超级智能都被绘制在图表中。人类的智力保持不变。人工智能迅速发展，但仍落后于人类智能。生物超级智能突然出现在人类智能之上，并随后进一步增强。" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/esezjj6yzvulza4ggjcc 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/syckh0rlkrsz8c41qzud 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/bnxombjiw8sm9s6oxrze 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/cskc450upg8xym82aulo 680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/p3q617xopuirapgt5xuu 850w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/tx8zhkujo4eqrtlcwemv 1020w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/g6v6npj0zhkzxqfridhe 1190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/dqb9qv4hgp6rrlsilt9d 1360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/l5adauty0ocpyocyvlyp 1530w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/doh9y6e7u0y5jwcq2crn 1680w"></p><p>我邀请大家在评论中进行讨论和批评。</p><br/><br/> <a href="https://www.lesswrong.com/posts/sca9xpw7DpDM6dpJw/biological-superintelligence-the-holy-grail-of-ai-safety#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/sca9xpw7DpDM6dpJw/biological-superintelligence-the-holy-grail-of-ai-safety<guid ispermalink="false"> sca9xpw7DpDM6dpJw</guid><dc:creator><![CDATA[Yarrow Bouchard]]></dc:creator><pubDate> Sun, 26 Nov 2023 03:11:51 GMT</pubDate> </item><item><title><![CDATA[Corrigibility or DWIM is an attractive primary goal for AGI]]></title><description><![CDATA[Published on November 25, 2023 7:37 PM GMT<br/><br/><p>在重读<a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities">致死清单</a>（LoL）时，我被反对可修正性的论点所吸引。制定“最大化X，除非有人告诉你关闭”的目标确实很难。我认为同样的论点也适用于 Christiano 的目标，即通过奖励可正确性的相关因素来通过强化学习实现可正确性。如果其他事情得到更可靠的奖励，你可能无法在需要时关闭你的 AGI。</p><p>但如果可修正性是主要目标，那么这些论点就不适用。 “按照他所说的去做他的意思”是一个完全一致的目标。出于几个原因，它是一个非常有吸引力的产品。也许纠正性不应该在这个意义上使用，按照我的意思去做（DWIM）是一个更好的术语。但这是密切相关的。它实现了可纠正性，并且具有其他优点。我认为这很可能是有人真正给出 AGI 的第一个目标。</p><p> “按我的意思做”回避了外部对齐的困难。外线对线的难度是LoL中的另一点。一个看似合理的常见计划是让人类参与其中。进行<a href="https://forum.effectivealtruism.org/topics/long-reflection"><u>长时间的反思</u></a>来决定我们想要什么。 “DWIM”让你可以随心所欲地思考和改变你的想法。</p><p>当然，这里的问题是：按照WHO的意思去做吗？我们希望通用人工智能能够为全人类服务，而不仅仅是一个人或一个董事会。我们不希望发生权力斗争。</p><p>但从实际决定 AGI 目标的团队的角度来看，出于实际原因，DWIM 将极具吸引力。外部对齐问题很难。指定一个人（或几个人）接受指示比决定和指定一个实现人类永远繁荣的目标要简单得多。你不想相信 AGI 能够正确解释该目标。解释 DWIM 仍然令人担忧，但它自然可以自我纠正，并且随着 AGI 的能力变得更强而变得更加有用。更聪明的 AGI 会更好地理解你可能的意思，并且在不确定你的意思时更好地意识到，以便它可以要求澄清。</p><p>这根本没有解决内部对齐问题。但是，当有人认为他们有足够好的内在一致性来启动目标导向的<a href="https://www.lesswrong.com/posts/WqxGB77KyZgQNDoQY/sapience-understanding-and-agi">智能</a>AGI 时，DWIM 很可能是他们会选择的目标。这可能是好是坏，取决于他们实现内在一致性的程度以及他们是什么类型的人。</p><br/><br/> <a href="https://www.lesswrong.com/posts/ZdBmKvxBKJH2PBg9W/corrigibility-or-dwim-is-an-attractive-primary-goal-for-agi#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ZdBmKvxBKJH2PBg9W/corrigibility-or-dwim-is-an-attractive-primary-goal-for-agi<guid ispermalink="false"> ZdBmKvxBKJH2PBg9W</guid><dc:creator><![CDATA[Seth Herd]]></dc:creator><pubDate> Sat, 25 Nov 2023 19:37:39 GMT</pubDate> </item><item><title><![CDATA[On “slack” in training (Section 1.5 of “Scheming AIs”)]]></title><description><![CDATA[Published on November 25, 2023 5:51 PM GMT<br/><br/><p>这是我的报告《<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？》</a>的第 1.5 节。 ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p>本节的音频版本请点击<a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13984752-on-slack-in-training-section-1-5-of-scheming-ais">这里</a>，或者在您的播客应用程序上搜索“Joe Carlsmith Audio”。</p><h1>论训练中的“懈怠”</h1><p>在深入评估预期阴谋论的论点之前，我还想指出一个在下文中会反复出现的因素：即我们应该期望训练允许的“松弛”程度。我的意思是这样的：训练过程有多少无情和无情地迫使模型以产生最大奖励的方式执行，而不是以更“放松”的方式塑造模型，从而为小于的结果留出更多空间- 获得最大奖励的行为。也就是说，在低松弛制度下，“但这种模型获得的奖励将低于其能力所能获得的回报”，这是反对训练创建相关类型模型的强烈反驳，而在高松弛制度下，事实并非如此（因此高松弛制度通常会对您最终得到的模型类型产生更大的不确定性，因为获得低于最大奖励的模型仍在运行中）。</p><p>或者，用更人性化的话来说：低松弛制度更像是一家高度紧张的金融公司，它会立即解雇任何在创造利润方面落后的员工（因此你会期望幸存的员工过度专注于创造利润） ——或者也许，过度关注他们的主管<em>认为</em>他们正在创造的利润），而高度宽松的制度更像是一家公司，员工可以自由地偷懒，在午餐时喝马提尼酒，并从事与他们模糊相关的项目公司的底线，<em>有时</em>只需要为公司创造<em>一定</em>的利润。</p><p> （或者至少，这是我试图指出的广泛区别。不幸的是，我没有很好的方法来使其更加精确，而且我认为以这些术语进行思考最终可能会产生误导。）</p><p> Slack 在这里很重要，部分原因是因为下面我将提出各种论点，以吸引不同模型获得的奖励金额上可能相当小的差异。这些论据的说服力取决于训练对这些差异的敏感程度。但我也认为它可以让我们了解更普遍的模型。</p><p>例如，我认为松弛对于训练创建的模型的概率很重要，这些模型追求与训练输入的奖励不完全相关的代理目标。因此，在低松弛状态下，经过训练来帮助人类进行科学训练的模型最终不太可能追求一般的“好奇心驱动”（以一种不会激发工具训练游戏的方式），因为模型在训练中追求好奇心有时会偏离最大限度地利用科学帮助人类。</p><p>也就是说，请注意，松弛程度在概念上与为根除目标错误概括而进行的培训工作的多样性和稳健性不同。因此，例如，如果您在模型获得金币时对其进行奖励，但您只显示模型环境中唯一的黄金物品是硬币，那么尝试获得一般黄金物品的模型将执行无论模型在这些环境中获得最大奖励的训练压力有多大，特别是获得金币的模型都一样。例如，低松弛机制原则上可以选择这些模型中的任何一个，而高松弛机制将为仅获得较少金币周期的模型留出更多空间（例如，有时会追求红色事物的模型，或者浪费时间的模型）在他们追求金币之前需要花很多时间思考）。</p><p>从这个意义上说，低松弛制度并没有那么强烈地反对错误概括的非训练游戏玩家。相反，它反对那些不追求我所说的“最大奖励目标”的模型，即<em>与模型实际上在训练中收到的</em>输入奖励密切相关的目标。根据定义，指定的目标是最大奖励目标（因为它是“被奖励的东西”），奖励过程本身也是如此（无论是针对最终还是工具进行优化）。但原则上，如果您从未向模型显示奖励过程会惩罚它们的输入，那么错误概括的目标（例如“一般来说获得黄金”）也可能是“最大奖励”。</p><p> （反对错误概括的非训练游戏玩家的东西——尽管不是决定性的——是我所说的“普通对抗性训练”——也就是说，向模型展示各种各样的训练输入，旨在区分指定的训练输入目标和其他错误概括的目标。 <sup class="footnote-ref"><a href="#fn-6quJWAtBqkkZdjpm4-1" id="fnref-6quJWAtBqkkZdjpm4-1">[1]</a></sup>因此，例如，如果您向您的“一般获得黄金物品”模型展示一种情况，即获得金纸杯蛋糕比获得金币更容易，那么就给予黄金奖励-获得硬币<em>将</em>惩罚错误概括的目标。）</p><p>最后，我认为松弛可能是理解机器学习训练的各种生物类比的有用概念。</p><ul><li><p>因此，例如，人们有时将人类的多巴胺/快乐系统与奖励过程进行类比，并注意到许多人最终不会直接追求这种意义上的“奖励”——例如，他们会拒绝“<a href="https://en.wikipedia.org/wiki/Wirehead_(science_fiction)">线头</a>”的机会“在体验机中。我将把这个类比是否合适的问题留到另一天讨论（不过请注意，至少，在这种意义上“头脑简单”的人类会被进化所淘汰）。不过，如果我们按照这个类比，那么似乎值得注意的是，这种奖励过程至少似乎留下了相当大的余地——例如，许多人似乎<em>可以获得</em>比他们多得多的奖励（例如，通过更直接地优化来满足他们自己的乐趣），但奖励过程并不会迫使他们这样做。</p></li><li><p>同样，就我们将进化选择与机器学习训练进行类比而言，至少到目前为止，它似乎给人类留下了相当大的“松弛”——也就是说，通过包容性遗传适应性，我们可能会表现得更好（尽管如果你想象进化选择持续更长时间，我们可以想象最终会出现更积极地优化其包容性遗传适应性的生物）。</p></li></ul><p>训练中会有多少松懈？我不确定，但我认为它可能会根据训练过程的阶段而有所不同。例如，天真地认为，目前预训练在我看来就像是比 RL 微调更低的松弛机制。更重要的是，在某种程度上，“松弛”最终指向了一些真实而重要的东西，我认为这将是我们可以<em>控制</em>的一个参数——例如，通过训练更长的时间和更多的数据。</p><p>假设我们<em>可以</em>控制它，那么松弛度是少一点好还是多一点好？再说一次，我不确定。不过，目前我倾向于这样的观点：更少的松弛是更好的，因为更少的松弛让你对最终得到的模型更有信心。 <sup class="footnote-ref"><a href="#fn-6quJWAtBqkkZdjpm4-2" id="fnref-6quJWAtBqkkZdjpm4-2">[2]</a></sup>事实上，在我看来，依靠松弛来确保一致性尤其是一厢情愿的想法，尤其是依靠模型目标的更大<em>不确定性</em>来支持你希望它实现的具体目标。因此，举例来说，我的感觉是，有些人承认我们的训练过程指定的目标在某种程度上会出现偏差（例如，人类评估者有时会奖励不诚实、误导性或操纵性的反应），但他们希望我们的模型无论如何，都要学习一致的政策。但即使训练的松懈允许这种偏离最大奖励行为的情况发生，为什么认为这种偏差会特别出现在一致的政策上呢？ （这里有可能的答案 - 例如，像“诚实”这样的一致政策在某种意义上更简单或更自然。 <sup class="footnote-ref"><a href="#fn-6quJWAtBqkkZdjpm4-3" id="fnref-6quJWAtBqkkZdjpm4-3">[3]</a></sup>但我也对这里的一厢情愿保持警惕。）</p><p>不过，我目前的主要观点是，训练的松弛程度可能是影响我们对训练将产生什么样的模型的期望的一个重要因素。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-6quJWAtBqkkZdjpm4-1" class="footnote-item"><p>我称其为“普通”对抗训练，因为它研究模型在我们能够实际投入的情况下会做什么。这与更奇特和更具推测性的对抗训练形式形成鲜明对比，后者试图获取有关什么的信息模型在我们<em>无法</em>实际展示的情况下会做什么，至少在受控环境下——例如，如果它不再受我们控制，它会做什么，或者如果真实日期是十年，它会做什么未来等等<a href="#fnref-6quJWAtBqkkZdjpm4-1" class="footnote-backref">↩︎</a></p></li><li id="fn-6quJWAtBqkkZdjpm4-2" class="footnote-item"><p>感谢 Daniel Kokotajlo 在这里进行讨论。 <a href="#fnref-6quJWAtBqkkZdjpm4-2" class="footnote-backref">↩︎</a></p></li><li id="fn-6quJWAtBqkkZdjpm4-3" class="footnote-item"><p>例如，很多人都合理地选择了“诚实点”这样的政策，尽管它并不<em>总是</em>能得到回报。 <a href="#fnref-6quJWAtBqkkZdjpm4-3" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/HdNmXBbYycE5znPag/on-slack-in-training-section-1-5-of-scheming-ais#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/HdNmXBbYycE5znPag/on-slack-in-training-section-1-5-of-scheming-ais<guid ispermalink="false"> HdNmXBbYycE5znPag</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Sat, 25 Nov 2023 17:51:42 GMT</pubDate></item></channel></rss>