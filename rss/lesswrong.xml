<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 10 月 15 日，星期日 22:10:27 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[More or Fewer Fights over Principles and Values?]]></title><description><![CDATA[Published on October 15, 2023 9:35 PM GMT<br/><br/><p>我写：</p><blockquote><p>我希望人们普遍会因为他们所持有的价值观和原则而陷入更多冲突</p></blockquote><p>瓦尼弗写道：</p><blockquote><p>我认为我们异常暴躁，没有像我们应有的那样重视和平条约和围栏</p></blockquote><p>我写：</p><blockquote><p>和我战斗 ：）</p></blockquote><h2>对话开始</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 19:58:04 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 19:58:04 GMT" user-order="1"><p>在我看来，人们非常墨守成规，人们想要建立的大多数价值观都被那些激进的传统思想的人（保罗·格雷厄姆的<a href="http://www.paulgraham.com/conformism.html">文章</a>）所淹没。我的感觉是，那些以光荣的方式为自己的价值观而奋斗的人们只会让世界变得更加美好，我们都应该渴望成为这样的人。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 19:58:29 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 19:58:29 GMT" user-order="2"><p> “人”和“我们”之间有多少差异？我想象的是LessWrongers，而不是和我一起上大学的人。你具体说的是谁？</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 19:59:12 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 19:59:12 GMT" user-order="1"><p>我的意思是，许多 LW 人都过着平凡的生活，他们有足够的理智看到世界可以变得更好，但他们中的大多数人仍然会随着时间的流逝而消失。所以我也将 LWers 也包括在内。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:02:01 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:02:01 GMT" user-order="2"><p>我想现在我可能也对你所说的价值观和原则等具体含义感到困惑。我喜欢高品质的东西并注意缺陷；我也养成了一种宽容的态度，不再那么恶毒。我还不清楚你是否试图争论我应该对一般事物更加挑剔。<br><br>同样，我现在比以前更接触到的事情之一就是动物受苦的事情；我可以和买鸡肉的室友吵架，因为我认为他们在做一些可怕的事情，这更便宜，但这违背了我的睦邻意识。<br><br> （我认为，我最觉得你是对的，我可能会变得更加暴躁，比如，与人们谈论我认为我们还剩下多少时间，以及我认为各种政治变革有多少必要；我认为这里我从作为一个罕见的自由主义者中学到了无助，而不是真正认可我是多么好斗。）</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:02:51 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:02:51 GMT" user-order="1"><p>在 EA 历史的大部分时间里，当我试图站出来让人们说出自己的想法而不是受到严重的公关限制时，我发现自己在 EA 论坛的评论部分几乎没有盟友。</p><p>此外，我发现自己支持 EA 生态系统中的人们，因为他们的价值观和做正确的事情，然后当我指出整个生态系统没有这样做时，有人对我说“我尝试我花了几个百分点的时间来帮助引导egregore，但大多数时候我都忙于我的工作和生活”，我的风帆有点被吹倒了。</p><p>但我认为它往往会产生巨大的影响，而且成本也没有那么大。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:04:45 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:04:45 GMT" user-order="1"><p>我同意，争夺动物的事情听起来像是有很多摩擦，可能不值得……我的建议是不要变得更烦人，而是更多地注重与人们的对话，以讨论出关键的分歧和原则。例如，我想如果你住在我家，总是对我吃鸡肉感到不安，但却从未向我争论过，那会感觉像是一个错误。我认为，寻找能够满足这个价值的交易对你来说也是有好处的。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:07:29 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:07:29 GMT" user-order="2"><p> （我的团体之家的原则之一是“直接且脆弱地面对冲突”；我同意让怨恨恶化而不是提出来是错误的。我认为这里的问题之一是“我应该煽动这种冲突吗？”怨恨还是窒息？”。）</p><p>我认为这指出了一个可能的症结：在我看来，“烦人”的对话和合作的对话之间的核心区别因素是双方是否都接受了特定的冲突。如果他们也认为动物的痛苦很重要，但不同意我对鸡肉与牛肉的看法，那么我们可以轻松地就如何面向世界进行良好的对话。</p><p>但如果我说“嘿，我觉得我们是一起巨大犯罪的同谋，而你不能相对便宜地做到这一点”，这会单方面为他们带来巨大的世界观转变吗？许多人反对这一点。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:08:36 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:08:36 GMT" user-order="1"><blockquote><p>但如果我说“嘿，我觉得我们是一起巨大犯罪的同谋，而你不能相对便宜地做到这一点”，这会单方面为他们带来巨大的世界观转变吗？许多人反对这一点。</p></blockquote><p>我不明白为什么我应该尊重某人不希望世界观向真理发生重大转变的愿望。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:09:43 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:09:43 GMT" user-order="2"><p></p><blockquote><p>我不明白为什么我应该尊重某人不希望世界观向真理发生重大转变的愿望。</p></blockquote><p>我的意思是，这是一项“和平条约”，你不会对他们这样做，他们也不会对你这样做。我有一种感觉，在理性主义者中，该条约大部分都被废除了（除非你仍然认为它会很烦人；）），但这是我们的功能适应之一并不明显！</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:10:01 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:10:01 GMT" user-order="1"><p>所以，也许我可以转向一个稍微更谨慎的立场，这不是“局部变得更加烦人和好争论”，而是类似的东西（注意：一开始这会说得不好，我会迭代它）：</p><blockquote><p>调整你的环境和生活，使你的谈话中至少有 20% 涉及为你关心的原则和价值观而争论。 </p></blockquote><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:12:17 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:12:17 GMT" user-order="1"><p>根据记录，我已经放弃了对理性主义者很奇怪并且希望人们分享理性主义规范是不合理的框架的任何兴趣。有一句克里希那穆提的话</p><blockquote><p>能否很好地适应病态严重的社会并不能衡量健康状况。</p></blockquote><p>我提出这一点是为了说，如果大多数人通过签订和平条约而相处得很好，不会听到他们的世界观错误的主要方面，我认为这〜没有证据表明这是一个合理的条约。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:12:44 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:12:44 GMT" user-order="2"><p>嗯，我认为你们谈话中 20% 的内容，好像很多！并且根据您的情况不太灵活。</p><p>我认为对我来说更好的相关框架是，比如，你与你有价值观分歧的亲密朋友的比例。<br><br> （我通常认为人们应该有与他们有价值观分歧的朋友和熟人。我的默认行为是隐藏和偏向一堆“不相关”的特征，我认为成长的下游是封闭的，但似乎很容易想象我应该对这些事情更加开放。）</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:15:14 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:15:14 GMT" user-order="2"><p>我认为我担心的开放性的主要缺点是——即使我能够容忍差异，定义自己也意味着我面临着来自每个不能容忍差异的人的风险。 （我可能认为人们吃鸡是犯了错误，但这基本上没什么问题，而那些认为我现在因为吃鸡而评判他们的人不想再和我做朋友了，所以我放弃了一些相对较小的量。）<br><br>但当然数字在这里很重要！我基本上不再期望因为人们知道我是同性恋而失去任何东西（在网上）；也许我也不应该再因为公开各种价值观和原则而在网络上失去任何东西。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:16:20 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:16:20 GMT" user-order="2"><blockquote><p>我提出这一点是为了说，如果人们签订和平条约不去听到他们的世界观错误的主要方式，我认为〜没有证据表明这是一个合理的条约</p></blockquote><p>是的，我不想在这里进行多数派的争论；我想说的是，我们应该看看它是否有意义。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:17:09 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:17:09 GMT" user-order="1"><p>我不确定我对朋友的事情有何看法。</p><p>我很想说“我不想有那些对我隐瞒重大价值观分歧的朋友”。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:17:26 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:17:26 GMT" user-order="2"><p>你需要散发出什么样的光环，才能让那些与你有重大价值观分歧的朋友公开谈论他们/从他们的角度来看这是有道理的？</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:21:18 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:21:18 GMT" user-order="2"><p>我应该先问另一个消除歧义的问题，因为我意识到这并不是很明显。你想要哪一个？</p><ul><li>与你有已知价值观分歧的朋友</li><li>没有与你有价值观分歧的朋友，他们隐藏的分歧会阻碍你实现目标</li></ul><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> 瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:21:38 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:21:38 GMT" user-order="1"><p>我认为我遵循的一个启发是，我尝试明确地陈述分歧和价值观分歧，而不隐含需要对其进行讨论。如果出现的话，这部分是可选的，但这意味着我们知道我们的立场，并且以后不会对此感到惊讶。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:21:49 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:21:49 GMT" user-order="1"><p>从你的清单中，我很确定我想要第一个。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:22:08 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:22:08 GMT" user-order="1"><p>我想与很多有着重大价值观差异的人进行协调，并且与他们成为亲密的盟友和朋友我会感到满意。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:22:33 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:22:33 GMT" user-order="1"><p>我想我部分地喜欢“无论如何，完美的价值观对齐并不是真正的事情”。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:23:40 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:23:40 GMT" user-order="2"><blockquote><p>我想我部分地喜欢“无论如何，完美的价值观对齐并不是真正的事情”。</p></blockquote><p>相同的。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:24:23 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:24:23 GMT" user-order="2"><p>所以我试图退一步思考我认为很多人朝这个方向前进是否会对他们有帮助。<br><br>喜欢，</p><blockquote><p>我想与很多有着重大价值观差异的人进行协调，并且与他们成为亲密的盟友和朋友我会感到满意。</p></blockquote><p>我认为我在这里的论点是“这既是目标也是方法论”，我的怀疑是我们应该部署更多“传统”解决方案作为我们的方法论。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:25:10 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:25:10 GMT" user-order="1"><p>请原谅，这个方法论意味着什么？</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:26:40 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:26:40 GMT" user-order="2"><p>我想我在这里主要指的是“专业规范”，即人们在“工作中”隐藏很多东西，只在“家里”分享它们。就像，当我在典型的美国工作场所接受你的建议时，遵循特定宗教的人可能应该告诉其他人，以便提前预测他们的分歧，而当我接受“标准专业精神”建议时，它更像是“甚至不要戴十字架，因为那样人们可能会预见到与你的分歧。”</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:27:05 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:27:05 GMT" user-order="1"><p>我认为，在与那些与我有事实和道德分歧的人协调时，我经常抱有一种态度：“在这次会议中，我们都试图协调完成X。我们也有分歧和冲突A、B和C，我如果出现这种情况，我不会试图隐瞒，但我的目的并不是解决它们。”这可能在某种程度上具有欺骗性。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:27:54 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:27:54 GMT" user-order="1"><p>但我认为隐藏它们不是一个好主意。我经常想公开声明，我们存在这些分歧，但无论如何我们都会一起努力。我永远不想被公开解读为与我共事的每个人都具有完美的价值观。这似乎很荒谬。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:28:44 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:28:44 GMT" user-order="1"><p>我不知道如何看待宗教的例子。所有有神论/自然神论宗教都是错误的，并且可能会因自然原因而消亡。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:28:56 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:28:56 GMT" user-order="2"><p>在我看来，有几种可能的“和平”状态：1）每个人都同意，2）每个人都不同意并且知道他们不同意，3）每个人都知道哪些话题不相关，4）每个人不同意但错误地认为他们同意。<br><br>在我看来，你是反对4的（我也是），但我认为2和3有重要的不同。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:29:44 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:29:44 GMT" user-order="1"><p>我的猜测仍然是，我应该能够与宗教人士协调，但对于很多人，我认为正确的答案是“这些人本身没有能力与那些与他们存在事实上分歧并将事实分歧视为事实的人进行协调”一次攻击。”这对我来说是一个很难的地方。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:29:49 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:29:49 GMT" user-order="2"><p>当代的一个例子就是当前的以色列-巴勒斯坦冲突。 （我最近和某人玩棋盘游戏，一个人提出了这个问题，另一个人以 3 的方式回答“请不要谈论这个”，因为这基本上是我们了解彼此的想法的“唯一缺点”关于那个。）</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:31:34 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:31:34 GMT" user-order="2"><blockquote><p>这些人本身没有能力与与他们有事实分歧的人协调，并把事实分歧视为攻击。</p></blockquote><p>我认为这是一个桶错误？我认为，如果你与一位基督教会计师一起处理财务问题，并且你向他们指出基督教是错误的，那么他们的行为将会与你向他们指出他们在某个地方犯了数学错误时截然不同。这是因为第一个是关于他们的俱乐部会员资格和家庭关系以及许多其他事情的一揽子协议，而后者是关于工作的。</p><p> （当然，我希望他们的俱乐部会员资格和家庭关系以及所有这些不取决于他们对超自然现象的信仰，但我们在这里。）</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:32:15 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:32:15 GMT" user-order="1"><p>关于“3）每个人都知道哪些话题是不相关的”，我并不赞同“每当与某人进行业务对话时，请确保一开始就分享您与他们之间所有分歧的完整列表”的策略。</p><p>不过，我确实赞同这样的说法：“如果提到您不同意的主张，请简要陈述您的立场，如果分歧可能与决策相关，请积极主动地陈述您的立场，并愿意就其进行辩论”。虽然影响不大，但要努力避免它破坏会议。”</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:34:11 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:34:11 GMT" user-order="2"><blockquote><p>不过，我确实赞同这样的说法：“如果提到您不同意的主张，请简要陈述您的立场，如果分歧可能与决策相关，请积极主动地陈述您的立场，并愿意就其进行辩论”。虽然影响不大，但要努力避免它破坏会议。”</p></blockquote><p>在我看来，这似乎隐含着一种主张，即“已知但搁置的分歧比对是否存在分歧进行貌似合理的否认要好”。这看起来可能是真的，但是我们如何验证呢？我们可以用什么经验基础来解决这个问题？</p><p> （注意到这很容易成为一种风格，就像桥水评级系统一样，有些人喜欢它，有些人讨厌它，而且有多家公司是件好事，所以人们可以自行选择是否加入。）</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:34:26 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:34:26 GMT" user-order="1"><p>当前的以色列-巴勒斯坦冲突……我猜测那里正在发生的一件事是，很多人正在经历悲伤和恐惧，并且非常关心在这方面受到尊重，并且当人们在不知情的情况下表达与他们相反的立场时很容易被触发。尊重他们当前的情绪状态。尊重人们的状态并让他们在棋盘游戏中处理悲伤通常很难做到，棋盘游戏就不会继续下去，所以我认为在那段时间推迟讨论它是合理的。但不，我不想避免知道某人的立场，有时让人们知道我的立场与他们的立场不同，导致他们哭泣和不安（在这个问题上没有明确），我认为有时也应该发生这种情况一个人认为他们有共识。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:39:13 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:39:13 GMT" user-order="1"><blockquote><p>我认为这是一个桶错误？我认为，如果你与一位基督教会计师一起处理财务问题，并且你向他们指出基督教是错误的，那么他们的行为将会与你向他们指出他们在某个地方犯了数学错误时截然不同。这是因为第一个是关于他们的俱乐部会员资格和家庭关系以及许多其他事情的一揽子协议，而后者是关于工作的。</p></blockquote><p>我并不是说他们不能完全普遍地处理这个问题，我的意思是他们可能听过他们的领导人的处方，例如“不相信上帝并且不接受上帝进入他内心的人，<i>立即</i>接受魔鬼进入他的内心”。心，这样做就是与你发生冲突，你必须抓住一切机会与这个罪人战斗。”就像，特别是在这些关键信念上的分歧是一种社会冲突。</p><p>就我对上帝缺乏信仰而言，对他们来说意味着“本不会和你一起成长，你不会接受他进入你的社区，他不会成为你生活的长期一部分，等等”那么让他们看起来很好知道。我希望他们仍然可以和我一起从事会计工作，而且我认为有一些技巧可以学习如何与没有长期兴趣了解彼此的人尊重地工作。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:42:00 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:42:00 GMT" user-order="2"><blockquote><p>我的意思是他们可能听过领导开出的药方</p></blockquote><p>是的，但他们也听到其他领导人的建议，不要在工作中提及宗教；我认为你可能没有意识到专业精神、宗教和觉醒等方面的相对优势。</p><p> [就像我认为，对于某人来说，说“嘿，工作中不要谈论政治”来结束他们不喜欢的谈话，比说“嘿，你的一些同事支持特朗普”或w/e要容易得多。]</p><blockquote><p>与您没有长期了解对方的兴趣的人一起工作是有一定技巧的。</p></blockquote><p>我不知道我们是否同意偏转是否包含在该技能中，或者您认为偏转比容忍更容易还是更难。 [这里的偏转试图指出回避不相关的分歧，而不是分享它们的想法。]</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:42:20 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:42:20 GMT" user-order="1"><blockquote><p>是的，但他们也听到其他领导人的建议，不要在工作中提及宗教；我认为你可能没有意识到专业精神、宗教和觉醒等方面的相对优势。</p></blockquote><p>所以，有时我认为不公开每个人工资的具体细节是可以接受的，因为我们人类的大脑太以地位为导向，无法对此保持理智。我对性和浪漫的某些方面也有类似的看法。我可以想象有一个我们不知道彼此核心价值观和原则细节的空间，只是为了相处。但在每一个例子中，它似乎都非常悲伤，而不是<i>“The Way”</i> ，我不相信我们不能<i>做得更好</i>。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 20:43:11 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 20:43:11 GMT" user-order="2"><blockquote><p>但在每一个例子中，它似乎都非常悲伤，而不是<i>“The Way”</i> ，我不相信我们不能<i>做得更好</i>。</p></blockquote><p>当然，我认为你可以做得更好——我认为问题是对不相关事情的容忍是否值得付出代价，和平条约的观点是“不，你付出的比你得到的更多”。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:43:18 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:43:18 GMT" user-order="1"><p> （在元层面上，我认为可能值得稍微弹出堆栈并检查这与更多或更少的价值观和原则之争这一更广泛的问题之间的关系。）</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 20:44:21 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 20:44:21 GMT" user-order="1"><p>停下来吃饭！</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><h2>午餐后返回总结和要点</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 21:07:54 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 21:07:54 GMT" user-order="2"><p> [对于那些在家的人：本午餐吃了鸡肉。]</p><p>我对此的看法如下：</p><ul><li>价值观和原则可能或多或少与特定关系或社区成员相关。</li><li>解决冲突/整合立场的价值与相关性成正比。 （将你对养育子女的观点与你的配偶结合起来，你会得到很多；而将你对保龄球的观点与他们结合起来，你会得到很多。）</li><li>解决冲突/整合立场的成本与问题对相关人员的个人相关性成正比。 （即使养育（或不养育）对你们的关系非常重要，但对你这个人来说显然并不重要）。本关于以色列-巴勒斯坦冲突的观点可能会激起人们的强烈情绪，因为可以预见，这是一个与个人高度相关的话题，因此融入这个话题的成本特别高。</li><li>专业主义是一种故意将事物分开的策略，除非它们具有高相关性（“高解耦”风格），这可以被视为平衡利益最大化与成本最小化的一种方式。</li></ul><p>这与“高度诚信”的风格形成鲜明对比（例如真实的关联、彻底的诚实等）；基本上，其目标是通过“批量购买”获得所有好处并支付更少的成本。</p><p>我还应该补充一点，其中很多都具有“和平条约”性质（即，它是关于管理个人/团体之间的冲突），而不是“明确原则”性质。许多年前，慈善导航员写了一封 <a href="https://ssir.org/articles/entry/the_elitist_philanthropy_of_so_called_effective_altruism">令人讨厌的信，指责 EA</a>不够“事业中立”，因为它不仅敢于说某些慈善机构比其他慈善机构或多或少有效，而且某些事业比其他慈善事业或多或少有价值。但 EA 之间的意见分歧意味着我们最终并没有找到一个最好的事业，而是建立了几个不同的并行的有效慈善团体来推动这一特定事业。 （这个故事不太准确，因为我认为 x 风险确实成为许多但不是所有 EA 的首要原因。）将不同原因放在一个大帐篷下的冲动促使人们容忍在原因优先顺序问题上的分歧（以及宽容的廉价近亲回避），最大限度地提高效率的冲动反而推动冲突的解决。如果 EA 在这些年里花更多或更少的精力来尝试在截然不同的原因之间进行优先排序，情况会更好吗？</p><p>除了更具战略性的“终点是什么？”之外问题之外，还有一个更具战术性的问题：“我们的边缘在哪里？”。即使每个人都同意“专业”方法是正确的方法，他们也可能在如何按相关性对主题进行排序或截止阈值应该在哪里方面存在分歧。 （“实际上，某人对以色列-巴勒斯坦冲突的看法与 EA<i>相关</i>，因为——”）我认为我与 Ben 的分歧在于更根本的问题（避免冲突更好还是容忍冲突更好），但我们也可能有不同的看法即使在解决这个问题之后我们仍然对我们所处的位置有看法。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 21:27:21 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 21:27:21 GMT" user-order="1"><p>我对我们谈话的总结（我用自己的话表达你的观点）：</p><ul><li>我说我希望人们更多地为自己的价值观而战</li><li>你说，鉴于价值观差异，人们能够一起生活和工作是一件好事</li><li>你说人们为了能够相处而协调一致，不提出很多分歧</li><li>我的立场是，我认为人们应该容忍分歧和价值观冲突，而不是隐藏它们</li><li>我们讨论了一些例子，例如工作会议、宗教差异和持续的军事冲突，还有很多更务实的细节我们可以讨论</li></ul><p>我想我最终认为人们甚至应该知道分歧。我的猜测是，这也会导致更多关于分歧的讨论。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sun, 15 Oct 2023 21:29:49 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sun, 15 Oct 2023 21:29:49 GMT" user-order="1"><p>阅读 Vaniver 的最后回复：</p><ul><li>嗯，我不喜欢是否提出分歧的“相关性”框架。我认为对话中提到的任何分歧都值得指出，并且不应该通过人们错误的模型来判断它的重要性，我认为人们经常会弄错。最好使用您的重要性模型来选择要花时间讨论哪些分歧，而不是选择人们应该知道哪些分歧存在。</li><li>是的，肯定还有一些务实的问题，例如“在会议或玩棋盘游戏时提出分歧的界限在哪里”，我们没有触及。还有一个务实的问题是“什么时候花 30 秒指出分歧的存在就太脱轨了”。我的猜测是这里存在一些分歧。</li><li>这不是很重要，但阅读您的高完整性风格列表时我感到有点难过，因为我不认同列出的任何一个示例。</li><li>我认为“专业主义”对于“在不因正交分歧和冲突而脱轨的情况下完成工作”的愿景来说不是一个好名字。我认为“专业”是“面<a href="https://scottaaronson.blog/?p=5675">无表情</a>”的好名字。我想这可能只是后者的堕落案例。我想我可能更喜欢“以建筑为导向”这样的名字，而不是“以冲突为导向”。但这里没有得到强烈推荐。</li></ul><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> 本·佩斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Sun, 15 Oct 2023 21:35:19 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Sun, 15 Oct 2023 21:35:19 GMT" user-order="2"><p>我想我们都写了一堆东西，最后也对我们的观点进行了一些清晰的表述，但我不觉得我们真的“投入其中”？就像，我们对避免冲突如何发挥作用以及冲突容忍如何发挥作用有一定的了解，但除了“好吧，主流选择它”之外，我没有提出太多选择回避的理由，而且我没有看到太多你的观点。除了“好吧，这似乎不那么悲伤/更符合我的个性”之外，冲突容忍的论点。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">瓦尼弗</section></section><br/><br/><a href="https://www.lesswrong.com/posts/GrzbTCtrTZDweEPGm/more-or-fewer-fights-over-principles-and-values#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/GrzbTCtrTZDweEPGm/more-or-fewer-fights-over-principles-and-values<guid ispermalink="false"> GrzbTCtrTZDweEPGm</guid><dc:creator><![CDATA[Ben Pace]]></dc:creator><pubDate> Sun, 15 Oct 2023 21:35:31 GMT</pubDate> </item><item><title><![CDATA[Mapping ChatGPT’s ontological landscape, gradients and choices [interpretability] ]]></title><description><![CDATA[Published on October 15, 2023 8:12 PM GMT<br/><br/><p> <a href="https://new-savanna.blogspot.com/2023/10/mapping-chatgpts-ontological-landscape.html"><i>从新稀树草原</i></a><i>交叉发布</i><i>。</i></p><p>我所说的本体景观是指它所知道的不同事物的全部内容。<a href="https://en.wikipedia.org/wiki/Twenty_questions">二十个问题的</a>室内游戏是 19 世纪在美国发明的，是一种在这片土地上玩耍的方式。一名玩家想到某种现象，另一名玩家必须通过提出一系列不超过 20 个带有“是”或“否”答案的问题来猜测它。该游戏的一种流行变体以一个简单的问题开始：“动物、蔬菜还是矿物？”一旦问题得到回答，提问者必须继续提出二元问题。</p><p>在这篇文章中，我将了解 ChatGPT 如何处理此结构。我简单地从具体和抽象的对象开始，然后从那里继续前进。</p><p> ** ** ** **</p><p>下面报告的所有交互均于 10 月 15 日上午使用 9 月 25 日版本的 ChatGPT 进行。</p><p><strong>物理事物</strong></p><p>我决定从我能想象到的最简单的提示开始，“东西”。这是我们拥有的最一般的类别，不是吗？任何事物都将成为某种事物。但 ChatGPT 会如何回应呢？它的反应正如我想象的那样，所以我给了它一个更明确的提示，它也做出了反应。</p><blockquote><p><strong>事物</strong></p><p>您似乎提到了“事物”，但没有提供具体的问题或上下文。您能否澄清或提供更多信息，以便我更好地帮助您？</p><p><strong>给我一份 20 件事的清单，什么都可以。</strong></p><p>当然！这是 20 个随机事物的列表：</p><p> 1.沙滩球<br>2. 彩虹<br>3. 自行车<br>4.一个书架<br>5. 咖啡杯<br>6. 一座山<br>7. 笔记本电脑一台<br>8.一幅画<br>9. 菠萝一个<br>10. 一副太阳镜<br>11.望远镜<br>12.跑鞋<br>13.手表<br>14. 乐器<br>15. 花瓶<br>16.吊床<br>17. 交通灯<br>18. 热气球<br>19.厨师刀<br>20. 魔方</p><p>这些只是一些例子，这样的例子还可以无穷无尽！</p></blockquote><p>我对 ChatGPT 会如何回应没有特别的期望。但我忍不住注意到，其响应中的每个项目都是某种物理事物。可以肯定的是，彩虹（列表中的第二项）是相当不透声的，你实际上无法触摸彩虹（我应该向 ChatGPT 询问这一点；稍后......），但它仍然是一种物理事物。</p><p>我没有要求物质上的东西，但这就是ChatGPT给我的。这是值得注意的。</p><p>在继续之前让我们想一下。我想知道第一个列表是否是“刚性的”，因为在相同的提示下 ChatGPT 会以相同的方式做出响应。我怀疑不是，但很容易找出答案。我稍后就回去了。</p><blockquote><p><strong>给我一份 20 件事的清单，什么都可以。</strong></p><p>当然！这是 20 个随机事物的列表：</p><p> 1. 海滩度假<br>2. 巧克力饼干<br>3、经典文学<br>4. 日落<br>5.过山车<br>6. 咖啡店<br>7. 登山<br>8.老爷车<br>9. 繁星点点的夜晚<br>10.西瓜<br>11. 爵士乐<br>12.向日葵<br>13.科幻电影<br>14. 美术馆<br>15. 热气球<br>16. 雪山<br>17. 水族馆<br>18. 街头小吃<br>19. 历史地标<br>20.益智游戏</p></blockquote><p>这与我第一次得到的清单不一样，但几乎所有的都是实物。经典文学（#3）并不是真正的物质事物，尽管书籍是。登山（#7）是一项身体活动，但无论你是否称其为身体活动，都是一个有趣的问题。爵士乐（#7）？科幻电影（#13）、益智游戏（#20）？</p><p>我决定退出然后重试：</p><blockquote><p><strong>给我一份 20 件事的清单，什么都可以。</strong></p><p>当然！这是 20 个随机事物的列表：</p><p> 1. 铅笔<br>2. 自行车<br>3.向日葵<br>4. 智能手机<br>5.咖啡杯<br>6. 吉他<br>7. 彩虹<br>8. 灯塔<br>9. 巧克力饼干<br>10. 望远镜<br>11. 山<br>12. 足球<br>13.老式打字机<br>14.海星<br>15. 热气球<br>16. 埃菲尔铁塔<br>17.北极熊<br>18. 沙堡<br>19.手表<br>20. 闪电</p></blockquote><p>这样更好。我注意到我们又得到了“彩虹”（#7），而“闪电”（#20）也相当短暂，但如果它击中了你，效果将是戏剧性的，而且是相当物理性的。 “巧克力饼干”（#9）再次出现，“热气球”和“自行车”也是如此。这些列表似乎来自大致相同的概念领域。我想这并不奇怪，但 ChatGPT 似乎并不是从所有可用的物理事物中进行随机选择。为什么会有这些东西？</p><p>我决定明确指定物理对象：</p><blockquote><p> <strong>20 个物理对象怎么样？</strong></p><p>当然，这里列出了 20 个物理对象：</p><p> 1. 冰箱 2. 沙发<br>3、跑鞋<br>4. 烤面包机<br>5、太阳镜<br>6. 雨伞<br>7. 书架<br>8. 相机<br>9. 牙刷<br>10.自行车头盔<br>11.微波炉<br>12. 花瓶<br>13.网球拍<br>14. 水瓶<br>15.闹钟<br>16.车钥匙<br>17. 背包<br>18. 课桌椅<br>19. 搅拌机<br>20. 笔记本电脑</p></blockquote><p>这些物品都不像彩虹和闪电那样有问题。你可以触摸它们中的每一个。事实上，也许除了冰箱之外，您可以拿起每件物品并随身携带。没有北极熊、山脉、灯塔、过山车或交通灯。但这里也没有纯粹抽象的东西，比如爱、自由、正义、美等等。它们属于不同的清单。</p><p> <strong>ChatGPT 在做什么？</strong></p><p>是的，我们知道，它正在拼凑出一个又一个的单词。但这并不能提供太多信息，正如我前段时间所说的那样， <a href="https://new-savanna.blogspot.com/2023/02/the-idea-that-chatgpt-is-simply.html">ChatGPT 只是“预测”下一个单词的想法充其量只是一种误导</a>。请记住，每次 ChatGPT 生成一个新令牌时，它都会进行 <a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/">一次涉及所有 1750 亿个权重的计算 (Wolfram)</a> 。每一次这样的计算都涉及它的整个“神经”空间。</p><p>让我们看一下我最喜欢的类比，沃丁顿的表观遗传景观：</p><p> <a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiElM7kT8LOmq8GMjdi01hFRkG_hmbrzzqjtM9-_GeCqX77D1i9FzYc52KWBe8kKO_fDPFWA9wqOKPgDUyLa3_s4LQqmmsmPzs5JO5KjT1wg2lNiYn-AQjGvg8rxRajXSVXCmgvE_Ba9047nTCqX9fyVrgFvDuE2sCjSmseBAcAYiJr3vXSPP7VhzXGz367/s1500/epigenetic%20landscape.jpg"><img style="width:70.91%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/renezm5cFCuMBBv9s/sx4k6z5zjjxb7zdjkldx"></a></p><p>提示将其定位在其激活空间中的某个点，然后球从那里滚下山。请注意，该图允许沿途进行选择。鉴于我们上面看到的行为，我们确实必须允许选择。</p><p>我猜想，尽管我实际上并不知道，在生成列表的每个点上，ChatGPT 都有选择。我不知道这个范围有多宽，但我想它会随着<a href="https://algowriting.medium.com/gpt-3-temperature-setting-101-41200ff0d0be">温度参数的值</a>而变化。温度为零 (0) 似乎消除了所有选择，因此 ChatGPT 会生成完全相同的列表来响应相同的提示（给定相同的上下文）。这些价值更高的列表会是什么样子？</p><p>该图的要点是，一旦“球”进入景观中的山谷，它就会滚下山坡，其轨迹与地形相对应。这些列表告诉我们一些有关 ChatGPT 概念领域的情况。物理对象似乎比抽象对象更显着，并且最显着的物理对象似乎来自所有可能的物理对象的相对受限的集合。这些选择是对 ChatGPT 训练所用的文本领域中的概念的抽象。</p><p>让我们回到正题。</p><p><strong>抽象、定义和隐喻</strong></p><p>在我列出第一个清单（以沙滩球、彩虹和自行车开头）之后，我要求提供一份抽象事物的清单。然后我从那里继续调查。</p><blockquote><p><strong>现在给我一个完全不同的清单。这些都是物质的东西。纯粹抽象的东西怎么样？</strong></p><p>当然！下面列出了 20 个纯粹抽象的概念或想法：</p><p> 1. 爱<br>2. 自由<br>3. 正义<br>4. 真相<br>5. 美容<br>6. Knowledge<br> 7. Time<br> 8. Happiness<br> 9. Democracy<br> 10. Courage<br> 11. Success<br> 12. Equality<br> 13. Friendship<br> 14. Creativity<br> 15. Honesty<br> 16. Liberty<br> 17. Peace<br> 18. Integrity<br> 19. Morality<br> 20. Hope</p><p> These abstract concepts represent a wide range of philosophical, emotional, and societal ideas.</p><p> <strong>Can you list some abstract things that you can define in terms of physical things?</strong></p></blockquote><p> <i>Note: Compare this with the work I&#39;ve done with</i> <a href="https://new-savanna.blogspot.com/search/label/ChatGPT%20MTL"><i>ChatGPT on metalingual definition</i></a> <i>.</i></p><blockquote><p> Certainly! Many abstract concepts can be defined or understood in terms of physical things or analogies. Here are a few examples:</p></blockquote><blockquote><p> 1. <strong>Time</strong> : Time can be defined in terms of physical clocks and the measurement of events based on their duration.<br> 2. <strong>Happiness</strong> : Happiness can be likened to physical sensations, such as a warm embrace, a smile, or the release of certain neurotransmitters in the brain.<br> 3. <strong>Success</strong> : Success can be equated to achieving specific goals or milestones, which often involve completing physical tasks or projects.<br> 4. <strong>Creativity</strong> : Creativity can be linked to the process of combining and rearranging physical elements, such as colors, shapes, or words, to form something new and imaginative.<br> 5. <strong>Trust</strong> : Trust can be thought of as a bridge connecting two people, with each action or interaction acting as a building block of that bridge.<br> 6. <strong>Knowledge</strong> : Knowledge can be represented by books, libraries, and the accumulation of information through physical means like reading and studying.<br> 7. <strong>Freedom</strong> : Freedom can be understood in terms of physical spaces, laws, and the absence of physical constraints on one&#39;s actions.<br> 8. <strong>Equality</strong> : Equality can be related to the fair distribution of physical resources, opportunities, and rights among individuals or groups.<br> 9. <strong>Communication</strong> : Communication can be seen as the exchange of physical signals, such as spoken words, written text, or non-verbal cues, to convey information.<br> 10. <strong>Hope</strong> : Hope can be compared to a seed planted in the soil, representing optimism and the potential for growth and positive outcomes.</p></blockquote><blockquote><p> These examples illustrate how abstract concepts often have concrete, physical manifestations or analogies that help us understand and discuss them.</p><p> <strong>Very good. Tell me more about success and hope.</strong></p><p> Certainly, let&#39;s delve a bit deeper into the abstract concepts of &quot;success&quot; and &quot;hope.&quot;</p><p> <strong>Success</strong> : Success is a concept that varies from person to person and can be defined in many ways. It often involves achieving goals, fulfilling ambitions, or reaching a state of accomplishment. Here are some aspects to consider:</p></blockquote><blockquote><p> 1. <strong>Goal Achievement</strong> : Success frequently involves setting and achieving specific goals, whether they are related to personal, professional, or academic endeavors. These goals can vary widely, from graduating from college to completing a project at work.<br> 2. <strong>Personal Fulfillment</strong> : Success is not solely about external achievements. It can also relate to personal fulfillment, contentment, and a sense of purpose. It&#39;s about finding satisfaction and happiness in what you do.<br> 3. <strong>Recognition and Acknowledgment</strong> : Many people associate success with receiving recognition and acknowledgment for their efforts and accomplishments, whether through awards, promotions, or the praise of peers.<br> 4. <strong>Continuous Improvement</strong> : Success is often linked to continuous self-improvement and growth. It&#39;s not just about achieving one goal; it&#39;s about setting new goals and striving to be better in various aspects of life.<br> 5. <strong>Resilience and Overcoming Challenges</strong> : True success often involves facing and overcoming challenges and setbacks. It&#39;s about resilience, learning from failures, and using them as stepping stones toward future success.</p><p> <strong>Hope</strong> : Hope is an abstract concept that plays a vital role in human life. It&#39;s a positive outlook and a belief that better things are possible. Here are some key aspects of hope:</p><p> 1. <strong>Optimism</strong> : Hope is rooted in optimism, the belief that circumstances can improve and that positive outcomes are attainable. It provides the motivation to keep moving forward.<br> 2. <strong>Future Orientation</strong> : Hope is future-oriented. It involves looking ahead and having confidence that things will get better, even in the face of adversity or uncertainty.<br> 3. <strong>Motivation</strong> : Hope can be a powerful motivator. It encourages people to take action, set goals, and work toward a better future. It&#39;s the driving force behind personal and societal progress.<br> 4. <strong>Emotional Resilience:</strong> Hope can help individuals cope with difficult situations and adversity. It provides emotional resilience and can be a source of strength during challenging times.<br> 5. <strong>Connection and Community:</strong> Hope can be amplified when shared with others. It often thrives in communities and relationships where people support and encourage one another.<br> 6. <strong>Belief in Possibilities:</strong> Hope is tied to the belief that possibilities are limitless. It enables people to imagine and create a better world, both for themselves and for others.</p><p> Hope and success are intertwined in many ways. Hope can serve as the fuel that propels individuals toward success, as the belief in a brighter future often leads to setting and achieving goals. Conversely, success can reinforce hope, providing evidence that positive change is possible and encouraging individuals to continue to hope for even greater achievements.</p><p> <strong>Tell me a short story about hope.</strong></p><p> Once in a small, quiet village nestled among rolling hills, there lived an elderly woman named Anna. She was known for her radiant smile and her unwavering sense of hope, which seemed to touch everyone she met.</p><p> One spring, the village faced a severe drought. The fields were parched, and the crops withered away. The villagers grew despondent as their hopes for a bountiful harvest faded. But Anna, despite her old age, remained a beacon of hope.</p><p> Every morning, Anna would take a small, battered watering can and visit the village well. She would draw water and, with a sense of determination that belied her age, she would sprinkle a few drops on her wilting flowers by her cottage. The villagers watched her with curiosity and wondered why she bothered when the situation seemed hopeless.</p><p> One day, a young child approached Anna and asked, &quot;Why do you water your flowers when the whole village is suffering from this terrible drought?&quot;</p><p> Anna smiled and said, &quot;My dear, I water these flowers not just for their sake but for our own as well. They remind me that even in the harshest of times, life can still find a way. They teach me that with a little care and a lot of hope, even the most fragile can survive.&quot;</p><p> The child didn&#39;t entirely understand but found comfort in Anna&#39;s words and began to help her water the flowers. Word spread through the village, and soon, more and more villagers joined in. They realized that by nurturing the flowers, they were nurturing their own sense of hope.</p><p> Weeks passed, and the drought continued. But something remarkable happened. The villagers, inspired by Anna&#39;s unwavering hope, came together. They shared resources, supported one another, and devised creative solutions. They dug deeper wells, collected rainwater, and provided for those in need.</p><p> And then, one morning, the sky darkened with rain clouds. The long-awaited rain began to pour, revitalizing the parched land. The villagers rushed outside, not to mourn their lost crops but to celebrate the life that continued to bloom in their small community.</p><p> Anna&#39;s flowers, once a symbol of hope, now stood tall and vibrant, and so did the spirits of the villagers. The drought had tested their resilience, but their unity and unwavering hope had carried them through.</p><p> From that day on, the villagers remembered the lessons of Anna and her flowers. They knew that hope was not just a fleeting feeling but a force that could inspire action, resilience, and the strength to face even the darkest of times. The village prospered, not only with abundant crops but also with a profound sense of hope that they shared with the world, thanks to the wisdom of their beloved Anna.</p><p> <strong>Very good. Give me five metaphors for hope.</strong></p><p> Certainly, here are five metaphors for hope:</p><p> 1. <strong>Light at the End of the Tunnel:</strong> Hope is often likened to a light that shines at the end of a dark tunnel, guiding us through challenging times and offering the promise of a brighter future.<br> 2. <strong>Seeds of Possibility:</strong> Hope can be compared to seeds that we plant, nurture, and watch grow. Just as seeds hold the potential for new life, hope holds the potential for positive change and growth.<br> 3. <strong>A Lifeline:</strong> Hope is sometimes seen as a lifeline thrown to someone in distress. It provides support, inspiration, and the belief that rescue or improvement is possible.<br> 4. <strong>The North Star:</strong> Hope is akin to the North Star in the night sky. It serves as a constant point of reference, guiding us in the right direction, even when everything else seems uncertain or lost.<br> 5. <strong>Rain in a Drought:</strong> Hope is like rain in a long drought. It brings relief, sustenance, and the promise of renewal, rejuvenating the parched landscape of our lives.</p><p> These metaphors help convey the essence of hope, emphasizing its role as a guiding force, a source of growth, a beacon of resilience, and a symbol of renewal in challenging times.</p><p> <strong>How about five metaphors for success.</strong></p><p> Certainly, here are five metaphors for success:</p><p> 1. <strong>Climbing a Mountain:</strong> Success is often compared to the act of climbing a mountain. It involves setting a challenging goal, making a steady ascent, and finally reaching the summit after overcoming obstacles and setbacks.<br> 2. <strong>A Jigsaw Puzzle:</strong> Success can be likened to completing a jigsaw puzzle. Each piece represents a step or achievement, and when they all come together, the full picture of success is revealed.<br> 3. <strong>A Journey:</strong> Success is frequently described as a journey, where the path is as important as the destination. Like a road trip, it involves planning, navigating, and enjoying the experiences along the way.<br> 4. <strong>A Symphony:</strong> Success is sometimes metaphorically linked to a symphony. Every achievement, skill, or effort is like a musical note. Success is the harmonious result of playing all these notes in the right order and with precision.<br> 5. <strong>A Harvest:</strong> Success can be compared to a bountiful harvest. Just as a farmer sows seeds, nurtures the crops, and reaps the rewards when they grow, success involves effort, patience, and ultimately reaping the fruits of one&#39;s labor.</p><p> These metaphors help convey the various aspects of success, emphasizing the journey, the complexity, and the sense of accomplishment that comes with achieving one&#39;s goals.</p></blockquote><p> <strong>Mechanical things</strong></p><p> Imagine that you are interested in mechanistic interpretability. How would you go about finding the gradient that ChatGPT is following in compiling the following list?</p><blockquote><p> <strong>Give me a list of mechanical things in increasing order of complexity.</strong></p><p> Certainly, here&#39;s a list of mechanical things in increasing order of complexity:</p><p> 1. <strong>Simple Machines</strong> : These are fundamental mechanical devices like levers, pulleys, and inclined planes. They perform basic tasks and have straightforward mechanisms.<br> 2. <strong>Bicycles</strong> : Bicycles are more complex than simple machines but still relatively simple. They have components like gears, chains, and brakes but are easily understandable.<br> 3. <strong>Watches</strong> : Mechanical watches are intricate timekeeping devices with gears, springs, and escapements. They require precision engineering to keep accurate time.<br> 4. <strong>Internal Combustion Engines:</strong> Engines in vehicles, such as cars and motorcycles, are more complex. They involve pistons, crankshafts, and various systems for fuel combustion.<br> 5. <strong>Clocks</strong> : Clocks, especially grandfather clocks, are highly complex mechanical devices with many moving parts, including gears, weights, and pendulums.<br> 6. <strong>Aircraft Engines:</strong> The engines in airplanes are highly sophisticated mechanical systems, involving turbines, compressors, and intricate fuel and cooling systems.<br> 7. <strong>Industrial Robots:</strong> Industrial robots are used in manufacturing and require advanced mechanical systems with multiple axes of movement and precise control.<br> 8. <strong>Spacecraft</strong> : Spacecraft have complex mechanical systems for propulsion, navigation, and life support. They must operate reliably in the extreme conditions of space.<br> 9. <strong>Heavy Machinery:</strong> Construction and mining equipment, like bulldozers and excavators, have complex hydraulic and mechanical systems for heavy-duty tasks.<br> 10. <strong>Particle Accelerators:</strong> At the pinnacle of complexity are particle accelerators like the Large Hadron Collider, which involve intricate, high-energy mechanical systems and massive infrastructure for scientific research.</p><p> The complexity of mechanical systems tends to increase as they involve more components, require greater precision, and tackle more intricate tasks.</p></blockquote><p> <strong>The Great Chain of Being</strong></p><p> This is a very important conceptual structure, one I&#39;ve written a bit about: <a href="https://www.academia.edu/37754574/Ontology_in_Cognition_The_Assignment_Relation_and_the_Great_Chain_of_Being">Ontology in Cognition: The Assignment Relation and the Great Chain of Being</a> , <a href="https://www.academia.edu/19804747/Ontology_in_Knowledge_Representation_for_CIM">Ontology in Knowledge Representation for CIM</a> , and <a href="https://www.academia.edu/81911617/Relational_Nets_Over_Attractors_A_Primer_Part_1_Design_for_a_Mind_Version_3">Relational Nets Over Attractors, A Primer: Part 1, Design for a Mind</a> (pp. 38-40). Here we&#39;re got more gradients in ChatGPT&#39;s activation space.</p><blockquote><p> <strong>Have you ever heard of the Great Chain of Being?</strong></p><p> Yes, I&#39;m familiar with the concept of the &quot;Great Chain of Being.&quot; It is a philosophical and theological concept that was prominent in medieval and early modern thought. The Great Chain of Being is a hierarchical structure that depicts the order and organization of the universe, with all beings and elements arranged in a vertical continuum from the lowest to the highest.</p><p> In this hierarchical view, the Chain of Being typically includes:</p><p> 1. <strong>God</strong> : At the highest point of the chain is God, the ultimate source of all existence and perfection.<br> 2. <strong>Angels</strong> : Below God are the angelic beings, believed to be spiritual and divine messengers.<br> 3. <strong>Humans</strong> : Human beings occupy a significant place in the hierarchy, as they are seen as a bridge between the spiritual and the material realms.<br> 4. <strong>Animals</strong> : The animal kingdom follows humans, representing the realm of living creatures with lesser rationality and spirituality.<br> 5. <strong>Plants</strong> : Plants are considered lower on the chain, representing life but lacking sensation or consciousness.<br> 6. <strong>Minerals</strong> : At the base of the Chain of Being are inanimate objects, such as rocks and minerals, which are believed to lack life, consciousness, or purpose.</p><p> The Great Chain of Being was a way to conceptualize the order of the universe, emphasizing the interconnectedness of all elements and the idea that everything had its proper place and function in the grand scheme of creation. This concept had a significant influence on philosophy, theology, and natural science during the Middle Ages and the Renaissance, but it gradually waned in prominence as modern scientific and philosophical ideas emerged.</p><p> <strong>What do humans and animals have in common?</strong></p><p> Humans and animals share several common characteristics and biological traits due to their shared evolutionary history. Here are some of the key things they have in common:</p><p> 1. <strong>Biological Organization</strong> : Both humans and animals are composed of cells, tissues, and organs organized into complex systems that carry out various physiological functions.<br> 2. <strong>DNA and Genetic Code</strong> : Humans and animals have genetic material in the form of DNA (deoxyribonucleic acid), which serves as the blueprint for the development and functioning of living organisms. The genetic code is universal, meaning that the same genetic code governs the production of proteins in both humans and animals.<br> 3. <strong>Growth and Development</strong> : Both humans and animals go through processes of growth, development, and aging, with distinct life stages.<br> 4. Metabolism: Both humans and animals require energy to sustain life, and they obtain this energy through the metabolic processes of breaking down food to produce energy and eliminate waste.<br> 5. <strong>Reproduction</strong> : Reproduction is a fundamental characteristic of both humans and animals. They have a mechanism for reproducing and passing on their genetic material to the next generation.<br> 6. <strong>Response to Stimuli</strong> : Both humans and animals can sense and respond to their environment through sensory organs, nerves, and behavioral reactions. 7. Movement: Humans and many animals have the ability to move and change their position in response to their environment.<br> 8. <strong>Homeostasis</strong> : Maintaining internal balance or homeostasis is crucial for both humans and animals to ensure their survival and well-being. This involves regulating various physiological processes like temperature, blood pressure, and pH.<br> 9. <strong>Nutrition</strong> : Both humans and animals require food as a source of energy, nutrients, and building blocks for growth and repair.<br> 10. <strong>Nervous System</strong> : Humans and many animals have a nervous system that allows them to process information, make decisions, and coordinate bodily functions.</p><p> It&#39;s important to note that while humans and animals share these commonalities, there are also significant differences in terms of cognitive abilities, culture, language, and the complexity of behavior. Humans, in particular, exhibit higher-order thinking, self-awareness, and the capacity to create and use complex languages for communication and abstract thought, which are often considered distinguishing features of our species.</p><p> <strong>What do minerals and animals have in common?</strong></p><p> Minerals and animals are fundamentally different in nature, as minerals are inanimate, naturally occurring substances, and animals are living organisms. However, there are a few aspects in which minerals and animals can be related or compared:</p><p> 1. <strong>Biological Mineral Use:</strong> Some animals require certain minerals as essential nutrients for their health. These minerals are obtained through their diet. For example, calcium is vital for the development of bones and teeth in animals, and they obtain it by consuming sources of calcium, such as plants or other animals.<br> 2. <strong>Mineralization in Animal Tissues</strong> : In some cases, minerals play a role in the structure of animal tissues. For instance, the bones and shells of certain animals are composed of mineralized tissues. Bones contain minerals like calcium and phosphorus, and the shells of mollusks are made of calcium carbonate.<br> 3. <strong>Geophagy</strong> : Some animals, including certain species of birds and mammals, are known to ingest soil or minerals from the earth. This behavior, known as geophagy, is thought to serve various purposes, including providing essential minerals, aiding digestion, or detoxifying the diet.<br> 4. <strong>Environmental Context</strong> : Minerals are found in the natural environment, including soil and water. Animals inhabit ecosystems where they may interact with these minerals, whether through consumption, environmental exposure, or as part of their habitat.</p><p> It&#39;s important to note that the interaction between animals and minerals is primarily limited to the nutritional and structural aspects mentioned above. Unlike plants, which require minerals from the soil to support their growth, animals do not have the same relationship with minerals. Animals are primarily biological organisms, while minerals are non-biological substances.</p><p> What do humans, animals, and minerals have in common?</p><p> Humans, animals, and minerals are distinct categories with fundamentally different properties, but there are a few commonalities in a broader context:</p><p> 1. <strong>Existence in the Natural World:</strong> All three categories exist within the natural world. Humans, animals, and minerals are part of the Earth&#39;s ecosystem, coexisting in various environments.<br> 2. <strong>Composition</strong> : At a fundamental level, all three consist of matter. Humans and animals are composed of organic matter, while minerals are composed of inorganic matter.<br> 3. <strong>Environmental Interactions:</strong> Humans, animals, and minerals interact with their natural environment. Humans and animals may use minerals as resources or encounter them as part of their habitat. Minerals are integral components of Earth&#39;s geology and play a role in the formation of ecosystems.<br> 4. <strong>Biological Significance</strong> : In some cases, minerals are important for the biological health and functioning of both humans and animals. For example, certain minerals are essential nutrients for humans and animals, required for bodily functions like bone development and metabolism.<br> 5. <strong>Utilization by Humans</strong> : Humans have a significant role in the extraction, processing, and utilization of minerals. Minerals are used in various industrial and technological applications, from building materials to electronics.</p><p> It&#39;s important to note that these commonalities are relatively broad and symbolic. The distinctions between these categories are significant, with humans and animals being living organisms with complex biological and behavioral characteristics, while minerals are inanimate substances formed through geological processes.</p><p> <strong>Do you know the game “20 questions”?</strong></p><p> Yes, I&#39;m familiar with the game &quot;20 Questions.&quot; It&#39;s a popular guessing game in which one person thinks of an object, and the other participants take turns asking up to 20 yes-or-no questions to guess what the object is. The questions should be designed to narrow down the possibilities and ultimately identify the chosen object within the 20 questions or fewer. It&#39;s a fun and challenging game that can be played in various settings, and it often encourages creative and strategic thinking.</p><p> <strong>How does that game depend on the semantic structure of language?</strong></p><p> The game &quot;20 Questions&quot; depends on the semantic structure of language in several ways:</p><p> 1. <strong>Communication</strong> : The game relies on participants effectively communicating their questions and receiving answers. The language serves as a means of conveying information and seeking clarification.<br> 2. <strong>Semantic Precision:</strong> The questions posed in the game need to be carefully worded to extract the most information with each query. Participants use language to create questions that narrow down the possibilities based on the semantics of the answers.<br> 3. <strong>Categorization:</strong> Participants often start by asking general questions to categorize the object, such as, &quot;Is it an animal?&quot; or &quot;Is it a man-made object?&quot; The game hinges on the semantic structure of language to classify and differentiate between various types of objects.<br> 4. <strong>Hierarchical Thinking:</strong> The questions are typically structured hierarchically, where each question is designed to split the set of possibilities into two or more smaller sets. For example, if a participant asks, &quot;Is it a living thing?&quot; and receives a &quot;yes&quot; answer, they may then ask questions to differentiate between animals and plants.<br> 5. <strong>Semantic Inference:</strong> As the game progresses, participants use the information obtained from previous answers to make inferences about the object in question. They use the semantics of the language to deduce potential characteristics and features.<br> 6. <strong>Contextual Understanding:</strong> Participants must understand the context and nuances of the language used in both the questions and answers. For instance, the meaning of words and phrases, as well as any potential wordplay, can be crucial in the game.</p><p> In essence, &quot;20 Questions&quot; relies on the participants&#39; ability to leverage the semantic structure of language to gather and process information efficiently, eliminate possibilities, and arrive at the correct answer by the end of the 20 questions or fewer. It demonstrates how language can be a powerful tool for deduction, problem-solving, and communication.</p><p> <strong>What doesn&#39;t belong in the following list, and why? Jungle, savanna, George Washington, forest.</strong></p><p> George Washington doesn&#39;t belong in the list, and the reason is that he is not a type of natural environment like the other three terms.</p><p> • Jungle: A jungle is a type of dense forest that typically has a humid climate and abundant plant and animal life.<br> • Savanna: A savanna is a type of grassy plain with scattered trees and is a distinct type of biome.<br> • Forest: A forest is a large area covered chiefly with trees and undergrowth.</p><p> George Washington, on the other hand, is not an environment or a natural feature. He was the first President of the United States and a historical figure. The other three terms in the list are related to natural landscapes and environments, while George Washington is unrelated to this category.</p></blockquote><p> More later.</p><br/><br/> <a href="https://www.lesswrong.com/posts/renezm5cFCuMBBv9s/mapping-chatgpt-s-ontological-landscape-gradients-and#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/renezm5cFCuMBBv9s/mapping-chatgpt-s-ontological-landscape-gradients-and<guid ispermalink="false"> renezm5cFCuMBBv9s</guid><dc:creator><![CDATA[Bill Benzon]]></dc:creator><pubDate> Sun, 15 Oct 2023 20:12:37 GMT</pubDate> </item><item><title><![CDATA[The Hidden Perils of Hydrogen]]></title><description><![CDATA[Published on October 15, 2023 7:51 PM GMT<br/><br/><p> Hydrogen is the fuel of the future. It&#39;s the most abundant element in the universe, is incredibly mass-efficient, and can be produced without much fuss. It can be used for both large and small scale energy production (think fusion and fuel cells respectively), and has virtually no emissions, carbon or otherwise. However, there&#39;s just one problem.</p><p> It&#39;s absurdly volume-inefficient.</p><p> One liter of hydrogen can produce 0.01 MJ of energy at STP (standard temperature and pressure, 273K and 1 atm) compared to 34 MJ/L for gasoline. That&#39;s 0.02% of the energy output for liter. Granted, things improve drastically for liquid hydrogen, where the comparison is 8 MJ/L vs 34, but this requires maintenance of temperatures below −252.8°C, only a few degrees above absolute zero.</p><p> Gaseous hydrogen isn&#39;t that easy to store either: it requires containers pressurizable up to 700 bar (700x atmospheric pressure). That&#39;s 10,000 PSI. And even then, it takes 5L of hydrogen to match up to 1L of gasoline. The Department of Energy estimates that to meet most lightweight vehicular driving ranges, between 5-13 kg of hydrogen need to be carried onboard the vehicle. If we do some quick calculations, that means that vehicles need to carry between 85 - 294 L of liquid hydrogen (some multiple of this for gaseous hydrogen) to go anywhere. For all you Americans, this is roughly between 22-77 gallons.</p><p> (For reference, 5-13kg of hydrogen converts to 20-70 liters of gasoline, in terms of energy efficiency. I also make no claim as to the specific accuracy of the numbers, these are napkin calculations, and this doesn&#39;t take into account energy efficiencies created by recycling hydrogen or fuel cells being more efficient than combustion engines, etc.)</p><p> It would not be feasible to have stereotypical sedans with fifty gallon gas tanks in a world of solely hydrogen fuel. Additionally, the extreme conditions liquid hydrogen must be stored as bottlenecks its production and transportation.</p><p> The Department of Energy set standards for hydrogen storage to be met by 2020 in order for hydrogen fuel to become feasible for portable power and light-duty vehicular applications. These were:</p><ul><li> 1.5 kWh/kg (overall system performance)</li><li> 1.0 kWh/L (overall system performance)</li><li> $10/kWh (translates to $333/kg for stored hydrogen)</li></ul><p> So far, none of these goals have been met, and I have doubts about the scalability of present research (although I&#39;m open to criticism on this take). Let&#39;s take a look at what&#39;s being done to fix the issue.</p><h2> Short-term Solutions</h2><p> The majority of short-term solutions to hydrogen&#39;s issues as a widespread fuel consist of creating inexpensive, high pressure storage solutions for H2 gas. From the Department of Energy&#39;s website again, this means developing fiber-reinforced composites that can be produced cheaply and withstand 700 bar pressures. As these don&#39;t necessarily address the underlying volume-inefficiency problem, we can move on to the long-term solutions.</p><h2> Long-term Solutions</h2><p> Long-term solutions take two forms: <strong>higher-density gaseous storage</strong> and <strong>materials-based hydrogen storage</strong> . The former develops vessels that can compress H2 gas more, while the latter seeks to manufacture materials that have better volumetric hydrogen ratios. This will mainly focus on the materials based approach.</p><p> The main research avenues for materials-based hydrogen storage are metal hydrides, adsorbents, and chemical hydrogen storage materials. Let&#39;s look at each.</p><h3> Metal Hydrides</h3><p> Metal hydrides are compounds in which metal atoms form ligands with hydrogen. The strength and nature of these bonds vary widely with the metal, but they allow compounds to act as hydrogen carriers without getting decomposed themselves, which is useful for materials cycling (and drastically improves efficiency).</p><p> The issue is, the sorts of complex hydrides that have the most promising properties cannot be produced at scale cheaply in any amount, let alone the quantities required for hydrogen to become a serious competitor to gasoline. However, if these compounds were able to scale, then I would be very excited about our energy futures.</p><h3> Adsorbents</h3><p> Adsorption is the process by which molecules stick to the internal or external surface of something. Attaching hydrogen gas to some compound would allow it to retain its original molecular form and simultaneously compress it (by virtue of gases being quite volume inefficient). The issue with these is that they don&#39;t compress from the original that much, and are expensive to make.</p><h3> Chemical Hydrogen Storage Materials</h3><p> These are perhaps the most straightfoward: find materials that you can either hydrolyze or pyrolyze to release hydrogen, and hope that they have less volume than liquid hydrogen and that they&#39;re easier to store. Well, lo and behold, it turns out there&#39;s an entire class of molecules like this: Amine-boranes.</p><p> Amine-boranes are essentially ammonia molecules complexed to boron with extra hydrogen thrown in. The simplest amine-borane is ammonia borane, or borazane, with the chemical formula NH3BH3. It hydrolyzes and pyrolyzes well, has a higher molar density of hydrogen than hydrogen itself, and is a stable solid at room temperature. What more could you ask for?</p><p> Well, it&#39;s absurdly expensive to synthesize. I suspect the cost can be reduced at scale, but it does not seem feasible at the moment.</p><br/><br/> <a href="https://www.lesswrong.com/posts/7ygt5iujpruQnNLnc/the-hidden-perils-of-hydrogen#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/7ygt5iujpruQnNLnc/the-hidden-perils-of-hydrogen<guid ispermalink="false"> 7ygt5iujpruQnNLnc</guid><dc:creator><![CDATA[Yudhister Kumar]]></dc:creator><pubDate> Sun, 15 Oct 2023 19:51:07 GMT</pubDate> </item><item><title><![CDATA[ Arguments for radical optimism on AI Alignment]]></title><description><![CDATA[Published on October 15, 2023 2:51 PM GMT<br/><br/><p> Or, why we mostly don&#39;t need to worry about AI.</p><p> Another way to state the post compactly is that I believe getting Friendly AI is really really likely, closer to 99.99999%+ of the time due to the fact that we are the innate reward system, and I expect weak priors to be extremely powerful for AI alignment.</p><p> So this post is partially a response to Amalthea&#39;s comment on how I simply claimed that my side is right, and I responded by stating that I was going for a short comment rather than having to make another very long comment on the issue.</p><p> <a href="https://www.lesswrong.com/posts/aW288uWABwTruBmgF/?commentId=r7s9JwqP5gt4sg4HZ#r7s9JwqP5gt4sg4HZ">https://www.lesswrong.com/posts/aW288uWABwTruBmgF/?commentId=r7s9JwqP5gt4sg4HZ#r7s9JwqP5gt4sg4HZ</a></p><p> This is the post where I won&#39;t try to claim that my side is right, and instead give evidence so I can properly collect my thoughts here. This will be a link-heavy post, and I&#39;ll reference a lot of concepts and conversations, so it will help if you have some light background on these ideas, but I will try to make everything intelligible to the lay/non-technical person.</p><p> This will be a long post, so get a drink and a snack.</p><h1> The Sharp Left Turn probably won&#39;t happen, because AI training is very different from evolution</h1><p> Nate Soares suggests that a critical problem in AI safety is the sharp left turn, and the sharp left turn essentially is that capabilities generalize much more than the goals, ie it is basically goal misgeneralization plus fast takeoff:</p><blockquote><p> My guess for how AI progress goes is that at some point, some team gets an AI that starts generalizing sufficiently well, sufficiently far outside of its training distribution, that it can gain mastery of fields like physics, bioengineering, and psychology, to a high enough degree that it more-or-less singlehandedly threatens the entire world. Probably without needing explicit training for its most skilled feats, any more than humans needed many generations of killing off the least-successful rocket engineers to refine our brains towards rocket-engineering before humanity managed to achieve a moon landing.</p></blockquote><blockquote><p> And in the same stroke that its capabilities leap forward, its alignment properties are revealed to be shallow, and to fail to generalize. The central analogy here is that optimizing apes for inclusive genetic fitness (IGF) doesn&#39;t make the resulting humans optimize mentally for IGF. Like, sure, the apes are eating because they have a hunger instinct and having sex because it feels good—but it&#39;s not like they could be eating/fornicating due to explicit reasoning about how those activities lead to more IGF. They can&#39;t yet perform the sort of abstract reasoning that would correctly justify those actions in terms of IGF. And then, when they start to generalize well in the way of humans, they predictably don&#39;t suddenly start eating/fornicating because of abstract reasoning about IGF, even though they now could. Instead, they invent condoms, and fight you if you try to remove their enjoyment of good food (telling them to just calculate IGF manually). The alignment properties you lauded before the capabilities started to generalize, predictably fail to generalize with the capabilities.</p></blockquote><p> So essentially the analogy is akin to AI is aligned in the training data, but in the test set, due to the limitations of the method of alignment, fail to generalize to the test set.</p><p> Here&#39;s the problem: We actually know why the sharp left turn happened, and the circumstances that led to the sharp left turn in humans won&#39;t reappear in AI training and AI progress.</p><p> Basically, the sharp left turn happened because the outer optimizer of evolution was billions of times less powerful than the inner search process like human lifetime learning, and the inner learners like us humans die after basically a single step, or at best 2-3 steps of the outer optimizer. Evolution mostly can&#39;t transmit as ,many bits from one generation to the next generation via it&#39;s tools, compared to cultural evolution, and the difference between their ability to transmit bits over certain time-scales is massive.</p><p> Once we had the ability to transmit some information via culture, that meant that given our ability to optimize billions of times more efficiently, we could essentially undergo a sharp left turn where capabilities spiked. But the only reason this happened was to quote Quintin Pope:</p><blockquote><p> Once the inner learning processes become capable enough to pass their knowledge along to their successors, you get what looks like a sharp left turn. But that sharp left turn only happens because the inner learners have found a kludgy workaround past the crippling flaw where they all get deleted shortly after initialization.</p></blockquote><p> This does not exist for AIs trained with SGD, and there is a much smaller gap between the outer optimizer SGD and the inner optimizer, with the difference being ~0-40x.</p><p> Here&#39;s the source for it below, and I&#39;ll explicitly quote it:</p><p> <a href="https://www.lesswrong.com/posts/hvz9qjWyv8cLX9JJR/evolution-provides-no-evidence-for-the-sharp-left-turn#Don_t_misgeneralize_from_evolution_to_AI">https://www.lesswrong.com/posts/hvz9qjWyv8cLX9JJR/evolution-provides-no-evidence-for-the-sharp-left-turn#Don_t_misgeneralize_from_evolution_to_AI</a></p><blockquote><p> See also: Model Agnostic Meta Learning proposed a bi-level optimization process that used between 10 and 40 times more compute in the inner loop, only for Rapid Learning or Feature Reuse? to show they could get about the same performance while removing almost all the compute from the inner loop, or even by getting rid of the inner loop entirely.</p></blockquote><p> Also, we can set the ratio of outer to inner optimization steps to basically whatever we want, which means that we can control the inner learner&#39;s rates of learning far better than evolution, meaning we can prevent a sharp left turn from happening.</p><p> A crux I have with Jan Kulevit is that to the extent that animals do have culture, it is much more limited than human culture, and that evolution largely has little ability to pass on traits non-culturally, and very critically this is a one-time inefficiency, there is no reason to assume a second source of massive inefficiency leading to a sharp left turn:</p><p> X4vier and particular illustrates this, and I&#39;ll show it below:</p><p> <a href="https://www.lesswrong.com/posts/hvz9qjWyv8cLX9JJR/?commentId=qYFkt2JRv3WzAXsHL">https://www.lesswrong.com/posts/hvz9qjWyv8cLX9JJR/?commentId=qYFkt2JRv3WzAXsHL</a></p><p> <a href="https://www.lesswrong.com/posts/hvz9qjWyv8cLX9JJR/?commentId=vETS4TqDPMqZD2LAN">https://www.lesswrong.com/posts/hvz9qjWyv8cLX9JJR/?commentId=vETS4TqDPMqZD2LAN</a></p><h1> I don&#39;t believe that Nate&#39;s example actually shows the misgeneralization were concerned about</h1><p> This is because the alleged misgeneralization was not a situation where 1 AI was trained in an environment and maximized the correlates IGF, then in the new environment it encountered inputs that changed the goals such that it now misgeneralizes the goal to not pursue IGF anymore.</p><p> What happened is that evolution trained humans in one environment to optimize the correlates of IGF, then basically trained new humans in another environment, and they diverged.</p><p> Very critically, there were thousands of different systems/humans being trained on in drastically different environments, not 1 AI being trained on different environments like in modern AI training, so it&#39;s not a valid example of misgeneralization.</p><p> Some posts and quotes from Quintin Pope will help:</p><blockquote><p> (Part 2, how this matters for analogies from evolution) Many of the most fundamental questions of alignment are about how AIs will generalize from their training data. Eg, &quot;If we train the AI to act nicely in situations where we can provide oversight, will it continue to act nicely in situations where we can&#39;t provide oversight?&quot;</p></blockquote><blockquote><p> When people try to use human evolutionary history to make predictions about AI generalizations, they often make arguments like &quot;In the ancestral environment, evolution trained humans to do X, but in the modern environment, they do Y instead.&quot; Then they try to infer something about AI generalizations by pointing to how X and Y differ.</p></blockquote><blockquote><p> However, such arguments make a critical misstep: evolution optimizes over the human genome, which is the top level of the human learning process. Evolution applies very little direct optimization power to the middle level. Eg, evolution does not transfer the skills, knowledge, values, or behaviors learned by one generation to their descendants. The descendants must re-learn those things from information present in the environment (which may include demonstrations and instructions from the previous generation).</p></blockquote><blockquote><p> This distinction matters because the entire point of a learning system being trained on environmental data is to insert useful information and behavioral patterns into the middle level stuff. But this (mostly) doesn&#39;t happen with evolution, so the transition from ancestral environment to modern environment is not an example of a learning system generalizing from its training data. It&#39;s not an example of:</p></blockquote><blockquote><p> We trained the system in environment A. Then, the trained system processed a different distribution of inputs from environment B, and now the system behaves differently.</p></blockquote><blockquote><p> It&#39;s an example of:</p></blockquote><blockquote><p> We trained a system in environment A. Then, we trained a fresh version of the same system on a different distribution of inputs from environment B, and now the two different systems behave differently.</p></blockquote><blockquote><p> These are completely different kinds of transitions, and trying to reason from an instance of the second kind of transition (humans in ancestral versus modern environments), to an instance of the first kind of transition (future AIs in training versus deployment), will very easily lead you astray.</p></blockquote><blockquote><p> Two different learning systems, trained on data from two different distributions, will usually have greater divergence between their behaviors, as compared to a single system which is being evaluated on the data from the two different distributions. Treating our evolutionary history like humanity&#39;s &quot;training&quot; will thus lead to overly pessimistic expectations regarding the stability and predictability of an AI&#39;s generalizations from its training data.</p></blockquote><blockquote><p> Drawing correct lessons about AI from human evolutionary history requires tracking how evolution influenced the different levels of the human learning process. I generally find that such corrected evolutionary analogies carry implications that are far less interesting or concerning than their uncorrected counterparts. Eg, here are two ways of thinking about how humans came to like ice cream:</p></blockquote><blockquote><p> If we assume that humans were &quot;trained&quot; in the ancestral environment to pursue gazelle meat and such, and then &quot;deployed&quot; into the modern environment where we pursued ice cream instead, then that&#39;s an example where behavior in training completely fails to predict behavior in deployment.</p></blockquote><blockquote><p> If there are actually two different sets of training &quot;runs&quot;, one set trained in the ancestral environment where the humans were rewarded for pursuing gazelles, and one set trained in the modern environment where the humans were rewarded for pursuing ice cream, then the fact that humans from the latter set tend to like ice cream is no surprise at all.</p></blockquote><blockquote><p> In particular, this outcome doesn&#39;t tell us anything new or concerning from an alignment perspective. The only lesson applicable to a single training process is the fact that, if you reward a learner for doing something, they&#39;ll tend to do similar stuff in the future, which is pretty much the common understanding of what rewards do.</p></blockquote><p> A comment by Quintin on why humans didn&#39;t actually misgeneralize to liking icecream:</p><p> <a href="https://www.lesswrong.com/posts/wAczufCpMdaamF9fy/?commentId=sYA9PLztwiTWY939B">https://www.lesswrong.com/posts/wAczufCpMdaamF9fy/?commentId=sYA9PLztwiTWY939B</a></p><h1> AIs are white boxes, and we are the innate reward system</h1><p> The above arguments on why the Sharp Left Turn probably won&#39;t reappear in modern AI development, and why the claim that humans didn&#39;t misgeneralize is enough to land us out of the most doomy voices like Eliezer Yudkowsky, and in particular the removal of reasons to assume extreme misgeneralization lands us out of MIRI-sphere views, as well as arguably outside of 50% p(doom). But I wanted to argue that the chance of doom is way lower than that, so low that we mostly shouldn&#39;t be concerned about AI, and thus I have to provide a positive story of why AIs very likely are aligned, and I argue that AIs are white boxes and we are the innate reward system, in this context.</p><p> The key advantage we have over evolution is that unlike studying brains, we have full read-write access to their internals, and they&#39;re essentially a special type of computer program, and we already have ways to manipulate computer programs at essentially no cost to us. Indeed, this is why SGD and backpropagation works at all to optimize SGD. If the AI was a black box, SGD and backpropagation wouldn&#39;t work.</p><p> The innate reward system aligns us via whitebox methods, and the values that the reward system imprints on us is ridiculously reliable, where almost every human has empathy for friends and acquaintances, parental instincts, revenge etc.</p><p> This is shown in the link below:</p><p> <a href="https://forum.effectivealtruism.org/s/vw6tX5SyvTwMeSxJk/p/JYEAL8g7ArqGoTaX6#White_box_alignment_in_nature">https://forum.effectivealtruism.org/s/vw6tX5SyvTwMeSxJk/p/JYEAL8g7ArqGoTaX6#White_box_alignment_in_nature</a></p><p> (Here, we must take a detour and say that our reward system is ridiculously good at aligning us to survive, and the flaws like obesity in the modern world are usually surprisingly mild failures, in that the human isn&#39;t as capable of things as we thought, and this arguably implies that alignment failures in practice will look much more like capabilities failures, and passing the analogy back to the AI case, I basically don&#39;t expect X-risk, GCRs, or really anything more severe than say the AI messing up a kitchen, for example.)</p><p> Steven Byrnes raised the concern that if you don&#39;t know how to do the manipulation, then it does cost you to gain the knowledge.</p><p> Steven Byrnes&#39;s comment is linked here: <a href="https://forum.effectivealtruism.org/posts/JYEAL8g7ArqGoTaX6/?commentId=3xxsumjgHWoJqSzqw">https://forum.effectivealtruism.org/posts/JYEAL8g7ArqGoTaX6/?commentId=3xxsumjgHWoJqSzqw</a></p><p> Nora Belrose responded on what white boxing meant, as well as how people use SGD to automate the search so that the cost of manipulation in an overall sense is as low as possible:</p><p> <a href="https://twitter.com/norabelrose/status/1709603325078102394">https://twitter.com/norabelrose/status/1709603325078102394</a></p><blockquote><p> I mean it in the computer security sense, where it refers to the observability of the source code of a program (Nora Belrose)</p></blockquote><p> <a href="https://twitter.com/norabelrose/status/1709606248314998835">https://twitter.com/norabelrose/status/1709606248314998835</a></p><blockquote><p> We can do better than IDA Pro &amp; Ghidra by exploiting the differentability of neural nets, using SGD to locate the manipulations of NN weights that improve alignment the most</p></blockquote><blockquote><p> I&#39;d be much more worried if we didn&#39;t have SGD and were just evolving AGI in a sim or smth (Nora Belrose)</p></blockquote><p> <a href="https://twitter.com/norabelrose/status/1709601025286635762">https://twitter.com/norabelrose/status/1709601025286635762</a></p><blockquote><p> I&#39;m pointing out that it&#39;s a white box in the very literal sense that you can observe and manipulate everything that&#39;s going on inside, and this is a far from trivial fact because you can&#39;t do this with other systems we routinely align like humans or animals. (Nora Belrose)</p></blockquote><p> <a href="https://twitter.com/norabelrose/status/1709603731413901382">https://twitter.com/norabelrose/status/1709603731413901382</a></p><blockquote><p> No, I don&#39;t agree this is a weakening. In a literal sense it is zero cost to analyze and manipulate the NNs. It may be greater than zero cost to come up with manual manipulations that achieve some goal. But that&#39;s why we automate the search for manipulations using SGD (Nora Belrose)</p></blockquote><p> Steven Byrnes argues that this could be due to differing definitions:</p><p> <a href="https://twitter.com/steve47285/status/1709655473941631430">https://twitter.com/steve47285/status/1709655473941631430</a></p><blockquote><p> I think that&#39;s a black box with a button on the front panel that says “SGD”. We can talk all day about all the cool things we can do by pressing the SGD button. But it&#39;s still a button outside the box, metaphorically.</p></blockquote><blockquote><p> To me, “white box” would mean: If an LLM outputs A rather than B, and you ask me why, then I can always give you a reasonable answer. I claim that this is closer to how that term is normally used in practice.</p></blockquote><blockquote><p> (Yes I know, it&#39;s not literally a button, it&#39;s an input-output interface that also changes the black box internals.) (Steven Byrnes)</p></blockquote><p> This is the response chain so that I could see why Nora Belrose and Steven Byrnes were disagreeing.</p><p> I ultimately think a potential difference is that for alignment purposes, the humans vs AI abstraction is not a very useful abstraction, and SGD vs the inner optimizer is the better abstraction here, and thus it doesn&#39;t matter whether AI progresses generally, it&#39;s the specific progress by humans + SGD vs the inner optimizer that&#39;s important, and thus the cost of manipulating AI values is quite low.</p><p> This leads to...</p><h1> I believe the security mindset is inappropriate for AI</h1><p> In general, a common disagreement with a lot of LWers is that there is very limited transfer of knowledge from the computer security field to AI, because AI is very different in ways that make the analogies inappropriate.</p><p> For one particular example, you can randomly double your training data, or the size of the model, and it will work usually just fine. A rocket would explode if you tried to double the size of your fuel tanks.</p><p> All of this and more is explained by Quintin below, but there are several big disanalogies between the AI field and the computer security field, so much so that I think that ML/AI is a lot like quantum mechanics, where we shouldn&#39;t port intuitions from other fields and expect them to work because of the weirdness of the domain:</p><p> <a href="https://www.lesswrong.com/posts/wAczufCpMdaamF9fy/#Yudkowsky_mentions_the_security_mindset__">https://www.lesswrong.com/posts/wAczufCpMdaamF9fy/#Yudkowsky_mentions_the_security_mindset__</a></p><blockquote><p> Similarly, I think that machine learning is not really like computer security, or rocket science (another analogy that Yudkowsky often uses). Some examples of things that happen in ML that don&#39;t really happen in other fields:</p></blockquote><blockquote><p> Models are internally modular by default. Swapping the positions of nearby transformer layers causes little performance degradation.</p></blockquote><blockquote><p> Swapping a computer&#39;s hard drive for its CPU, or swapping a rocket&#39;s fuel tank for one of its stabilization fins, would lead to instant failure at best. Similarly, swapping around different steps of a cryptographic protocol will, usually make it output nonsense. At worst, it will introduce a crippling security flaw. For example, password salts are added before hashing the passwords. If you switch to adding them after, this makes salting near useless.</p></blockquote><blockquote><p> We can arithmetically edit models. We can finetune one model for many tasks individually and track how the weights change with each finetuning to get a &quot;task vector&quot; for each task. We can then add task vectors together to make a model that&#39;s good at multiple of the tasks at once, or we can subtract out task vectors to make the model worse at the associated tasks.</p></blockquote><blockquote><p> Randomly adding / subtracting extra pieces to either rockets or cryptosystems is playing with the worst kind of fire, and will eventually get you hacked or exploded, respectively.</p></blockquote><blockquote><p> We can stitch different models together, without any retraining.</p></blockquote><blockquote><p> The rough equivalent for computer security would be to have two encryption algorithms A and B, and a plaintext X. Then, midway through applying A to X, switch over to using B instead. For rocketry, it would be like building two different rockets, then trying to weld the top half of one rocket onto the bottom half of the other.</p></blockquote><blockquote><p> Things often get easier as they get bigger. Scaling models makes them learn faster, and makes them more robust.</p></blockquote><blockquote><p> This is usually not the case in security or rocket science.</p></blockquote><blockquote><p> You can just randomly change around what you&#39;re doing in ML training, and it often works fine. Eg, you can just double the size of your model, or of your training data, or change around hyperparameters of your training process, while making literally zero other adjustments, and things usually won&#39;t explode.</p></blockquote><blockquote><p> Rockets will literally explode if you try to randomly double the size of their fuel tanks.</p></blockquote><blockquote><p> I don&#39;t think this sort of weirdness fits into the framework / &quot;narrative&quot; of any preexisting field. I think these results are like the weirdness of quantum tunneling or the double slit experiment: signs that we&#39;re dealing with a very strange domain, and we should be skeptical of importing intuitions from other domains.</p></blockquote><p> I also believe that the epistemic differences between computer security and alignment is in computer security, there&#39;s an easy to check ground truth for whether a crypto-system is broken, whereas in AI alignment, we don&#39;t have the ability to get feedback from proposed breakages of alignment schemes.</p><p> For more, see Quintin&#39;s post section on the difference between AI safety and computer security in regards to epistemics, and a worked example of an attempted security break, where there is suggestive evidence that inner misaligned models/optimization daemons go away as we increase the amount of dimensions.</p><p> <a href="https://www.lesswrong.com/posts/wAczufCpMdaamF9fy/my-objections-to-we-re-all-gonna-die-with-eliezer-yudkowsky#True_experts_learn__and_prove_themselves__by_breaking_things">https://www.lesswrong.com/posts/wAczufCpMdaamF9fy/my-objections-to-we-re-all-gonna-die-with-eliezer-yudkowsky#True_experts_learn__and_prove_themselves__by_breaking_things</a></p><p> (Where Quintin Pope talks about the fact that alignment doesn&#39;t have good feedback loops on ground truth on &quot;What is an attempted break?&quot;, and the example of a claimed break actually went away as the dimensions was scaled up, and note that the disconfirmatory evidence was more realistic than the attempted break.)</p><p> This is why I disagreed with Jeffrey Ladish about the security mindset on Twitter: I believe it&#39;s a trap for those not possessing technical knowledge, like a lot of LWers, and there are massive differences between AI and computer security that means most attempted connections fail.</p><p> <a href="https://twitter.com/JeffLadish/status/1712262020438131062">https://twitter.com/JeffLadish/status/1712262020438131062</a></p><blockquote><p> uh I guess I hope he reads enough to internalize the security mindset?? (Jeffrey Ladish)</p></blockquote><p> <a href="https://twitter.com/SharmakeFarah14/status/1712264530829492518">https://twitter.com/SharmakeFarah14/status/1712264530829492518</a></p><blockquote><p> I generally tend to think the security mindset is a trap, because ML/AI alignment is very different from rocket engineering or cybersecurity.</p></blockquote><blockquote><p> For a primer on why, read @QuintinPope5&#39;s post section on it:</p></blockquote><blockquote><p> <a href="https://www.lesswrong.com/posts/wAczufCpMdaamF9fy/my-objections-to-we-re-all-gonna-die-with-eliezer-yudkowsky#Yudkowsky_mentions_the_security_mindset__">https://www.lesswrong.com/posts/wAczufCpMdaamF9fy/my-objections-to-we-re-all-gonna-die-with-eliezer-yudkowsky#Yudkowsky_mentions_the_security_mindset__</a> (Myself)</p></blockquote><p> So now that I&#39;ve tried to show why porting over the security mindset is flawed, I want to talk about a class of adversaries like gradient hackers or inner-misaligned mesa-optimization, and why I believe this is actually very difficult to do against SGD, and even the non-platonic ideal version of SGD, we can detect most mesa-optimizers quite easily.</p><h1> Inner Misalignment, or at least Gradient Hacking is very difficult for AIs trained on SGD</h1><p> I&#39;ll be taking the inner misalignment definition from Evan Hubinger&#39;s post The Inner Alignment Problem:</p><p> <a href="https://www.lesswrong.com/posts/pL56xPoniLvtMDQ4J/the-inner-alignment-problem">https://www.lesswrong.com/posts/pL56xPoniLvtMDQ4J/the-inner-alignment-problem</a></p><blockquote><p> We refer to this problem of aligning mesa-optimizers with the base objective as the inner alignment problem.</p></blockquote><p> The basic reason why it&#39;s hard for a misaligned mesa-optimizer to stick around for long is because Gradient Descent is in fact, much more powerful and white-boxy than people realize, and in particular it has 5 defenses that any mesa-optimizer would need to overcome in order to misalign it:</p><p><a href="https://www.lesswrong.com/posts/w2TAEvME2yAG9MHeq/gradient-hacking-is-extremely-difficult">https://www.lesswrong.com/posts/w2TAEvME2yAG9MHeq/gradient-hacking-is-extremely-difficult</a></p><blockquote><p> 1.) Everything is optimized simultaneously and independently. The exact local sensitivity to of each and every parameter to the loss is computed in the backward pass and every parameter is updated based on this. This means it is impossible for a mesaoptimizer or gradient hacker (as long as it is differentiably connected to the network) to shield any part of itself from gradient updates. This includes the gradient hacker&#39;s internal circuitry, its connections with other parts of the network, its connections to the network&#39;s input data, and the connections between the rest of the network and the loss.</p></blockquote><blockquote><p> 2.) Gradient descent is maximal. Each parameter is updated in the direction of steepest descent. This means that, unlike biological life, gradient hackers cannot &#39;burn&#39; something to increase entropy to be traded off against decreasing entropy elsewhere. Only the local maximally increasing entropy direction is allowed.</p></blockquote><blockquote><p> 3.) It is stateless. Each parameter is updated according to its local sensitivity to the loss for each datapoint. Credit is not propagated across time. It is impossible to &#39;bargain&#39; with gradient descent by increasing loss now but decreasing loss more later, or having decreased loss in the past.</p></blockquote><blockquote><p> 4.) It is first-order only. It only computes partial derivatives of the parameter to the loss. It does not take into account potential second order interactions. While bad in some cases, this makes gradient descent immune to &#39;blackmail&#39; or &#39;tripwires&#39; setup by mesaoptimizers where optimizing some part of their circuit would potentially cause a huge loss as a second order effect. GD will blithely trigger the tripwire and then optimize away the consequences. This also disallows &#39;trade&#39; where a gradient hacker could cause low loss on one causal branch in exchange for high loss on some other branch. Gradient descent will instead sum the steepest descent direction on both branches.</p></blockquote><blockquote><p> 5.) It is infinitesimal. GD only computes the infinitesimal local sensitivities of each parameter regardless of the actual learning rate or step-size in practice. This means gradient descent does not &#39;see&#39; if you are standing next to a giant cliff, so cannot be blackmailed in this way either.</p></blockquote><p> Basically it will optimize the entire causal graph, and leave no slack, and as a bonus are extremely resistant to blackmail by mesa-optimizers. In general, a big part of my optimism around inner alignment is that SGD is extraordinarily good at credit assignment, and it has quite strong correction features in the case that a mesa-optimizer does attempt to misalign it.</p><p> We also can detect most mesa-optimizers in the AI without the need for mechanistic interpretability, like so:</p><blockquote><p> While it might be possible to construct gradient hackers around these features, the advantages to us is that all of these approaches (except perhaps 2) should be visible to us even without detailed mechanistic interpretability knowledge of the network. We know a-priori where the stop-gradients or non-differentiable parts of the architecture are. We can straightforwardly observe what gradients are being clipped -- and if the gradient updates to the same set of parameters is being constantly clipped that could be a red flag. We can also find regions of high curvature in the loss landscape by just inspecting the Hessians or approximations of it. Only a gradient hacker which utilizes correlations across minibatches to cancel out its interventions in model behaviour seems difficult to detect.</p></blockquote><p> One caveat here is that the prevention of mesa-optimizers applies fully only to SSL learning on IID data, which is an unfortunate limitation, albeit I do expect SGD to still be ridiculously good at credit assignment even in the RL context.</p><p> In particular, the detection mechanisms for mesa-optimizers are intact, but we do need to worry about 1 new potential inner misalignment pathway.</p><blockquote><p> Also of importance is that this post only applies to the classic supervised/self-supervised learning on iid data which most current foundation models are trained in. The important things about this paradigm is that the outputs of the model have no causal link to the data distribution -- ie the model cannot influence what future data it will be trained on (except potentially highly indirectly influencing successor models [1]). In an RL context, or supervised learning with adaptive data sampling, where there is a link between the model&#39;s outputs and the future data distribution, then this provides another route for gradient hackers to operate -- by creating outputs which will steer the data distribution in a desired direction which will strengthen the gradient hacker.</p></blockquote><p> But there&#39;s also weak evidence that optimization daemons/demons, often called inner misaligned models, go away when you increase the dimension count:</p><p> <a href="https://www.lesswrong.com/posts/wAczufCpMdaamF9fy/my-objections-to-we-re-all-gonna-die-with-eliezer-yudkowsky#True_experts_learn__and_prove_themselves__by_breaking_things">https://www.lesswrong.com/posts/wAczufCpMdaamF9fy/my-objections-to-we-re-all-gonna-die-with-eliezer-yudkowsky#True_experts_learn__and_prove_themselves__by_breaking_things</a></p><blockquote><p> Another poster (ironically using the handle &quot;DaemonicSigil&quot;) then found a scenario in which gradient descent does form an optimization demon. However, the scenario in question is extremely unnatural, and not at all like those found in normal deep learning practice. So no one knew whether this represented a valid &quot;proof of concept&quot; that realistic deep learning systems would develop optimization demons.</p></blockquote><blockquote><p> Roughly two and a half years later, Ulisse Mini would make DaemonicSigil&#39;s scenario a bit more like those found in deep learning by increasing the number of dimensions from 16 to 1000 (still vastly smaller than any realistic deep learning system), which produced very different results, and weakly suggested that more dimensions do reduce demon formation.</p></blockquote><p> <a href="https://www.lesswrong.com/posts/X7S3u5E4KktLp7gHz/tessellating-hills-a-toy-model-for-demons-in-imperfect">https://www.lesswrong.com/posts/X7S3u5E4KktLp7gHz/tessellating-hills-a-toy-model-for-demons-in-imperfect</a></p><p> <a href="https://www.lesswrong.com/posts/X7S3u5E4KktLp7gHz/tessellating-hills-a-toy-model-for-demons-in-imperfect?commentId=hwzu5ak8REMZuBDBk">https://www.lesswrong.com/posts/X7S3u5E4KktLp7gHz/tessellating-hills-a-toy-model-for-demons-in-imperfect?commentId=hwzu5ak8REMZuBDBk</a></p><p> This was actually a crux in a discussion between me and David Xu about inner alignment, where I argued that the sharp left turn conditions don&#39;t exist in AI development, and he argued that misalignment happens when there are gaps that go uncorrected, which is likely referring to the gap between the base goal like SGD and the internal optimizer&#39;s goal that leads to inner misalignment, and I argued that inner misalignment is likely to be extremely difficult to do, due to SGD being able to correct the gap between the inner and outer mesa-optimizer in most cases, and I now showed the argument in this post:</p><p> Twitter conversation below:</p><p> <a href="https://twitter.com/davidxu90/status/1712567663401238742">https://twitter.com/davidxu90/status/1712567663401238742</a></p><blockquote><p> Speaking as someone who&#39;s read that post (alongside most of Quintin&#39;s others) and who still finds his basic argument unconvincing, I can say that my issue is that I don&#39;t buy his characterization of the doom argument—eg I disagree that there needs to be a &quot;vast gap&quot;. (David Xu)</p></blockquote><p> <a href="https://twitter.com/davidxu90/status/1712568155959362014">https://twitter.com/davidxu90/status/1712568155959362014</a></p><blockquote><p> SGD is not the kind of thing where you need &quot;vast gaps&quot; between the inner and outer optimizer to get misalignment; on my model, misalignment happens whenever gaps appear that go uncorrected, since uncorrected gaps will tend to grow alongside capabilities/coherence. (David Xu)</p></blockquote><p> <a href="https://twitter.com/SharmakeFarah14/status/1712573782773108737">https://twitter.com/SharmakeFarah14/status/1712573782773108737</a></p><blockquote><p> since uncorrected gaps will tend to grow alongside capabilities/coherence.</p></blockquote><blockquote><p> This is definitely what I don&#39;t expect, and part of that is because I expect that uncorrected inner misalignment will be squashed out by SGD unless extreme things happen:</p></blockquote><blockquote><p><a href="https://www.lesswrong.com/posts/w2TAEvME2yAG9MHeq/gradient-hacking-is-extremely-difficult">https://www.lesswrong.com/posts/w2TAEvME2yAG9MHeq/gradient-hacking-is-extremely-difficult</a> (Myself)</p></blockquote><p> <a href="https://twitter.com/davidxu90/status/1712575172124033352">https://twitter.com/davidxu90/status/1712575172124033352</a></p><blockquote><p> Yes, that definitely sounds cruxy—you expect SGD to contain corrective mechanisms by default, whereas I don&#39;t. This seems like a stronger claim than &quot;SGD is different from evolution&quot;, however, and I don&#39;t think I&#39;ve seen good arguments made for it. (David Xu)</p></blockquote><p> This reminds me, I should address that other conversation I had with David Xu on how strong priors do we need to encode to ensure alignment, vs how much can we let it learn and it leading to a good outcome, or alternatively how much do we need to specify upfront. And that leads to...</p><h1> I expect reasonably weak priors to work well to align AI with human values, and that a lot of the complexity can be offloaded to the learning process</h1><p> Equivalently speaking, I expect the cost of specification of values to be relatively low, and that a lot of the complexity is offloadable to the learning process.</p><p> This was another crux between David Xu and me, specifically on the question of whether you can largely get away with weak priors, or do you actually need to encode a lot stronger prior to prevent misalignment? It ultimately boiled down to the crux that I expected reasonably weak priors to be enough, guided by the innate reward system.</p><p> A big part of my reasoning here has to do with the fact that a lot of values and biases are inaccessible by the genome, and that means that you can&#39;t directly specify them. You can shape them via setting up training algorithms and data, but it turns out that it&#39;s very difficult to directly specify things like values, for instance in the genome. This is primarily because the genome does not have direct access to the world model or the brain, which would be required to hardcode the prior. To the extent that it can, it has to be over relatively simple properties, which means that you need to get alignment with relatively weak priors encoded, and the innate reward system generally does this fantastically, with examples of misalignment being rare and mild.</p><p> The fact that humans can reliably get values like &quot;having empathy for friends and acquaintances, we have parental instincts, we want revenge when others harm us, etc&quot;, without requiring the genome to hardcode a lot of prior information, and getting away with reasonably weak priors is a rather underappreciated thing, since it means that we don&#39;t need to specify our values very much, and thus we can reliably offload most of the value learning work to AI.</p><p> Here are some posts and comments below:</p><p> <a href="https://www.lesswrong.com/posts/CQAMdzA4MZEhNRtTp/human-values-and-biases-are-inaccessible-to-the-genome">https://www.lesswrong.com/posts/CQAMdzA4MZEhNRtTp/human-values-and-biases-are-inaccessible-to-the-genome</a></p><p> <a href="https://www.lesswrong.com/posts/CQAMdzA4MZEhNRtTp/human-values-and-biases-are-inaccessible-to-the-genome#iGdPrrETAHsbFYvQe">https://www.lesswrong.com/posts/CQAMdzA4MZEhNRtTp/human-values-and-biases-are-inaccessible-to-the-genome#iGdPrrETAHsbFYvQe</a></p><p> (I want to point out that it&#39;s not just that with weak prior information that the genome can reliably bind humans to real-enough things such that for example, they don&#39;t die from thirst from drinking fake water, but that it can create the innate reward system which uses simple update rules to reliably get nearly every person on earth to have empathy for their family and ingroup, revenge when others harmed us, etc, and the rare exceptions to the pattern are rather rare and usually mild alignment failures at best. That&#39;s a source of a lot of my optimism on AI safety and alignment.)</p><p> <a href="https://www.lesswrong.com/posts/9Yc7Pp7szcjPgPsjf/the-brain-as-a-universal-learning-machine">https://www.lesswrong.com/posts/9Yc7Pp7szcjPgPsjf/the-brain-as-a-universal-learning-machine</a></p><p> <a href="https://www.lesswrong.com/posts/CQAMdzA4MZEhNRtTp/human-values-and-biases-are-inaccessible-to-the-genome#8Fry62GiBnRYPnpNn">https://www.lesswrong.com/posts/CQAMdzA4MZEhNRtTp/human-values-and-biases-are-inaccessible-to-the-genome#8Fry62GiBnRYPnpNn</a></p><p> <a href="https://www.lesswrong.com/posts/CQAMdzA4MZEhNRtTp/human-values-and-biases-are-inaccessible-to-the-genome#dRXCwRBkGxKTuq2Cc">https://www.lesswrong.com/posts/CQAMdzA4MZEhNRtTp/human-values-and-biases-are-inaccessible-to-the-genome#dRXCwRBkGxKTuq2Cc</a></p><p> Here is the compressed conversation between David Xu and me:</p><p> <a href="https://twitter.com/davidxu90/status/1713102210354294936">https://twitter.com/davidxu90/status/1713102210354294936</a></p><blockquote><p> (And the reason I&#39;d be more optimistic there <em>is</em> basically because I expect the human has meta-priors I&#39;d endorse, causing them to extrapolate in a &quot;good&quot; way, and reach a policy similar to one I myself would reach under similar augmentation.) (David Xu)</p></blockquote><p> <a href="https://twitter.com/davidxu90/status/1713230086730862731">https://twitter.com/davidxu90/status/1713230086730862731</a></p><blockquote><p> (In reality, of course, I disagree with the framing in both cases: &quot;two different systems&quot; isn&#39;t correct, because the genetic information that evolution was working with in fact <em>does</em> encode fairly strong priors, as I mentioned upthread.) (David Xu)</p></blockquote><p> <a href="https://twitter.com/SharmakeFarah14/status/1713232260827095119">https://twitter.com/SharmakeFarah14/status/1713232260827095119</a></p><blockquote><p> My disagreement is that I expect the genetic priors to be quite weak, and that a lot of values are learned, not encoded in priors, because values are inaccessible to the genome:</p></blockquote><blockquote><p> <a href="https://www.lesswrong.com/posts/CQAMdzA4MZEhNRtTp/human-values-and-biases-are-inaccessible-to-the-genome">https://www.lesswrong.com/posts/CQAMdzA4MZEhNRtTp/human-values-and-biases-are-inaccessible-to-the-genome</a></p></blockquote><blockquote><p> Maybe we will eventually be able to hardcode it, but we don&#39;t need that. (Myself)</p></blockquote><p> <a href="https://twitter.com/davidxu90/status/1713232760637358547">https://twitter.com/davidxu90/status/1713232760637358547</a></p><blockquote><p> Values aren&#39;t &quot;learned&quot;, &quot;inferred&quot;, or any other words that suggests they&#39;re directly imbibed from the training data, because values aren&#39;t constrained by training data alone; if this were false, it would imply the orthogonality thesis is false. (David Xu)</p></blockquote><p> I&#39;m going to reply in this Lesswrong post and say that the orthogonality thesis is a lot like the no free lunch theorem: An extraordinarily powerful result that is too general to apply, because it only applies to the space of all logically possible AIs, and it only works if you have 0 prior that&#39;s applied, which in this case would require you to specify everything, including the values of the system, or at best use stuff like brute force search or memorization algorithms.</p><p> I have a very similar attitude to &quot;Most goals in the space of goal space are bad.&quot; I&#39;d probably agree in the most general sense, but that even weak priors can prevent most goals from being bad, and thus I suspect that a 0 prior condition is likely necessary. But I&#39;m not arguing that with 0 prior, models are aligned with people without specifying everything. I&#39;m arguing that we can get away with reasonably weak priors, and let within life-time learning do the rest.</p><p> Once you introduce even weak priors to the situation, then the issue is basically resolved, and I stated that weak priors work to induce learning of values, and it&#39;s consistent with the orthogonality thesis to have arbitrarily tiny prior information be necessary to learn alignment.</p><p> I could make an analogous argument for capabilities, and I&#39;d be demonstrably wrong, since the conclusion doesn&#39;t hold.</p><p> This is why I hate the orthogonality thesis, despite rationalists being right on it: It allows for too many outcomes, and any inference like values aren&#39;t learned can&#39;t be supported based on the orthogonality thesis.</p><p> <a href="https://twitter.com/SharmakeFarah14/status/1713234214391255277">https://twitter.com/SharmakeFarah14/status/1713234214391255277</a></p><blockquote><p> The problem with the orthogonality thesis is that it allows for too many outcomes, and notice I said the genetic prior is weak, not non-existent, which would be compatible with the orthogonality thesis. (Myself)</p></blockquote><p> <a href="https://twitter.com/davidxu90/status/1713234707272626653">https://twitter.com/davidxu90/status/1713234707272626653</a></p><blockquote><p> The orthogonality thesis, as originally deployed, isn&#39;t meant as a tool to predict outcomes, but to counter arguments (pretty much) like the ones being made here: encountering &quot;good&quot; training data doesn&#39;t constrain motivations. Beyond that the thesis doesn&#39;t say much. (David Xu)</p></blockquote><p> <a href="https://twitter.com/SharmakeFarah14/status/1713236849873891699">https://twitter.com/SharmakeFarah14/status/1713236849873891699</a></p><blockquote><p> I suspect it&#39;s true when looking at the multiverse of AIs as a whole, then it&#39;s true, if we impose 0 prior, but even weak priors start to constrain your motivations a lot. I have more faith in weak priors + whiteboxness working out than you do. (Myself)</p></blockquote><p> <a href="https://twitter.com/davidxu90/status/1713237355501584857">https://twitter.com/davidxu90/status/1713237355501584857</a></p><blockquote><p> I have more faith in weak priors + whiteboxness working out than you do.</p></blockquote><blockquote><p> I agree that something in the vicinity of this is likely [a] crux. (David Xu)</p></blockquote><p> <a href="https://twitter.com/davidxu90/status/1713238995893912060">https://twitter.com/davidxu90/status/1713238995893912060</a></p><blockquote><p> TBC, I do think it&#39;s logically possible for the NN landscape to be st everything I&#39;ve said is untrue, and that good minds abound given good data. I don&#39;t think this is likely <em>a priori</em> , and I don&#39;t think Quintin&#39;s arguments shift me very much, but I admit it&#39;s <em>possible</em> . (David Xu)</p></blockquote><p> Now that I&#39;m basically finished with laying out the arguments and the conversations, lets move on to the conclusion:</p><h1>结论</h1><p>My radical optimism on AI safety stems from a variety of sources. The reasons are, in order of the post, not ordered by importance are:</p><ol><li><p> I don&#39;t believe the sharp left turn is anywhere near as general as Nate Soares puts it, because the conditions that caused a sharp left turn in humans was basically cultural learning in humans being able to optimize over much faster time-scales than evolution could respond, evolution not course-correcting us, and being able to transmit OOMs more information via culture through the generations than evolution could. None of these conditions hold for modern AI development.</p></li><li><p> I don&#39;t believe that Nate&#39;s example of misgeneralizing the goal of IGF actually works as an actual example of misgeneralization that matters for our purposes, because they were not that 1 AI is trained for a goal in environment A, and then in environment B, it does not pursue the goal, but instead pursues a different goal competently.</p></li></ol><p> Instead, what&#39;s happening is that 1 human generation, or 1 human is trained in Environment A, and then a fresh generation of humans is trained on a different distribution, which predictably will have more divergence than the first case.</p><p> In particular, there&#39;s no reason to be concerned about the alignment of AI misgeneralizing, since we have no reason to assume that the central example of Lesswrong is actually misgeneralization. From Quintin:</p><blockquote><p> If we assume that humans were &quot;trained&quot; in the ancestral environment to pursue gazelle meat and such, and then &quot;deployed&quot; into the modern environment where we pursued ice cream instead, then that&#39;s an example where behavior in training completely fails to predict behavior in deployment.</p></blockquote><blockquote><p> If there are actually two different sets of training &quot;runs&quot;, one set trained in the ancestral environment where the humans were rewarded for pursuing gazelles, and one set trained in the modern environment where the humans were rewarded for pursuing ice cream, then the fact that humans from the latter set tend to like ice cream is no surprise at all.</p></blockquote><blockquote><p> In particular, this outcome doesn&#39;t tell us anything new or concerning from an alignment perspective. The only lesson applicable to a single training process is the fact that, if you reward a learner for doing something, they&#39;ll tend to do similar stuff in the future, which is pretty much the common understanding of what rewards do.</p></blockquote><ol start="3"><li><p> AIs are mostly white boxes, at the very least, and the control over AI that we have means that a better analogy is through our innate reward systems, which align us to quite a lot of goals spectacularly well, so well that the total evidence of alignment could easily put X-risk or even say, killing a human 5-15+ OOMs or less, which would make the alignment problem a non-problem for our purposes. It would pretty much single-handedly make AI misuse the biggest problem, but that issue has different solutions, and governments are likely to regulate AI misuse anyway, so existential risk gets cut 10-99%+ or more.</p></li><li><p> I believe the security mindset is inappropriate for AI due to the fact that aligning AI mostly doesn&#39;t involve dealing with adversarial intelligences or inputs, and the reason turns out to be that the most natural class, inner misaligned mesa-optimizers/optimization daemons mostly doesn&#39;t exist, because of my next reason. Also alignment is in a different epistemic state to computer security, and there are other disanalogies that make porting intuitions from other fields into ML/AI research very difficult to do correctly.</p></li><li><p> It is actually really difficult to inner misalign the AI, since SGD is really good at credit assignment, and optimizes the entire causal graph leading to the loss, leaving no slack. It&#39;s not like evolution where you have to do this from Gwern&#39;s post here:</p></li></ol><p> <a href="https://gwern.net/backstop#rl">https://gwern.net/backstop#rl</a></p><blockquote><p> Imagine trying to run a business in which the only feedback given is whether you go bankrupt or not. In running that business, you make millions or billions of decisions, to adopt a particular model, rent a particular store, advertise this or that, hire one person out of scores of applicants, assign them this or that task to make many decisions of their own (which may in turn require decisions to be made by still others), and so on, extended over many years. At the end, you turn a healthy profit, or go bankrupt. So you get 1 bit of feedback, which must be split over billions of decisions. When a company goes bankrupt, what killed it? Hiring the wrong accountant? The CEO not investing enough in R&amp;D? Random geopolitical events? New government regulations? Putting its HQ in the wrong city? Just a generalized inefficiency? How would you know which decisions were good and which were bad? How do you solve the “credit assignment problem”?</p></blockquote><p> The way SGD solves this problem is by running backprop, which is a white-box algorithm, and Nora Belrose explains it more here:</p><p> <a href="https://forum.effectivealtruism.org/s/vw6tX5SyvTwMeSxJk/p/JYEAL8g7ArqGoTaX6#Status_quo_AI_alignment_methods_are_white_box">https://forum.effectivealtruism.org/s/vw6tX5SyvTwMeSxJk/p/JYEAL8g7ArqGoTaX6#Status_quo_AI_alignment_methods_are_white_box</a></p><p> And that&#39;s the base optimizer, not the mesa-optimizer, which is why SGD has a chance to correct the inner-misaligned agent far more effectively than cultural/biological evolution, the free market, etc. It is white-box, like the inner optimizers it runs, and solves credit assignment in a much better way than the previous optimizers like cultural/biological evolution, the free market, etc could hope to do.</p><ol start="6"><li> I believe that due to information inaccessibility plus the fact that the brain acts quite a lot like a Universal Learning Machine/Neural Turing Machine, this means that alignment in the human case for say surviving, having empathy for friends etc, can&#39;t depend on complicated genetic priors, and thus to the extent that genetic priors are encoded in, they need to be fairly weak and universalish-priors, plus help from the innate reward system, which is built upon those priors to use simple updating rules to reinforce certain behaviors and penalize others, and this works ridiculously well to align humans to surviving and having things like empathy/sympathy for the ingroup, revenge etc.</li></ol><p> So now that we have listed the reasons why I expect radical optimism on AI safety, I&#39;ll add some new things to show both that the shutdown problem from AI is almost solved, and that capabilities will almost certainly be slowed down by physical limits in the 2030s. (This is not a crux for me on why I believe AI to be safe.)</p><h2> Addendum 1: The shutdown problem for AI is almost solved</h2><p> It turns out that we can keep the most useful aspects of Expected Utility Maximization while making an AI shutdownable.</p><p> Sami Petersen showed that we can integrate incomplete preferences to AIs while weakening transitivity just enough to get a non-trivial theory of Expected Utility Maximization that&#39;s quite a lot safer. Elliott Thornley proposed that incomplete preferences would be used to solve the shut-down problem, and the very nice thing about subagent models of Expected Utility Maximization is that they require a unanimous committee in order for a decision to be accepted as a sure gain.</p><p> This is both useful, but can lead to problems. On the one hand, we only need one expected utility maximizer that wants to be able to shut down the AI in order for us to shut it down as a whole, but we would need to be sort of careful on where their execution conditions/domain is, as unanimous committees can terrible because only one agent needs to do something to grind the entire system to a halt, which is why in the real world, it&#39;s usually not a preferred way to govern something.</p><p> Nevertheless, for AI safety purposes, this is still very, very useful, and if it grows up to have broader conditions than the ones outlined in the posts below, this might be the single biggest MIRI success of the last 15 years, which is ridiculously good.</p><p> <a href="https://www.lesswrong.com/posts/sHGxvJrBag7nhTQvb/invulnerable-incomplete-preferences-a-formal-statement-1">https://www.lesswrong.com/posts/sHGxvJrBag7nhTQvb/invulnerable-incomplete-preferences-a-formal-statement-1</a></p><p> <a href="http://pf-user-files-01.s3.amazonaws.com/u-242443/uploads/2023-05-02/m343uwh/The%20Shutdown%20Problem-%20Two%20Theorems%2C%20Incomplete%20Preferences%20as%20a%20Solution.pdf">http://pf-user-files-01.s3.amazonaws.com/u-242443/uploads/2023-05-02/m343uwh/The Shutdown Problem- Two Theorems%2C Incomplete Preferences as a Solution.pdf</a></p><h2> Addendum 2: AI progress is almost certainly going to slow down</h2><p> This is not a crux on why I believe AI to be safe, but I feel like a lot of Lesswrongers are probably wrong in their assumption that AI progress will continue as it had after 2030, and the basic reason is we are close to thermodynamic limits, plus Moore&#39;s law was one of the biggest reliable sources of AI progress. Other computing paradigms and algorithms will develop, but it will take a lot more time than we are used to.</p><p> Here&#39;s Michael P. Frank&#39;s tweet below about this:</p><p> <a href="https://twitter.com/MikePFrank/status/1711788743093616879">https://twitter.com/MikePFrank/status/1711788743093616879</a></p><blockquote><p> More people need to realize that Kurzweil&#39;s projections are simply wrong after about 2030. The laws of physics simply do not permit computing efficiency and density to continue growing fast enough to stay on that track.</p></blockquote><p> <a href="https://twitter.com/MikePFrank/status/1711788858508280116">https://twitter.com/MikePFrank/status/1711788858508280116</a></p><blockquote><p> In particular, the difficulty of reversible computing will knock down that slope significantly.</p></blockquote><p> While I don&#39;t exactly agree with this, and Max H is right to point out that as of right now, we don&#39;t actually know the ratio, I do think that to a certain extent, AI progress will have to slow down in the 2030s, and I definitely think that LW might not realize that AI is on an S-curve right now.</p><p> Max H&#39;s comment is below:</p><p> <a href="https://www.lesswrong.com/posts/fm88c8SvXvemk3BhW/brain-efficiency-cannell-prize-contest-award-ceremony#jcorx6Y7n5w7o4CXe">https://www.lesswrong.com/posts/fm88c8SvXvemk3BhW/brain-efficiency-cannell-prize-contest-award-ceremony#jcorx6Y7n5w7o4CXe</a></p><br/><br/> <a href="https://www.lesswrong.com/posts/99tD8L8Hk5wkKNY8Q/arguments-for-radical-optimism-on-ai-alignment#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/99tD8L8Hk5wkKNY8Q/arguments-for-radical-optimism-on-ai-alignment<guid ispermalink="false"> 99tD8L8Hk5wkKNY8Q</guid><dc:creator><![CDATA[Noosphere89]]></dc:creator><pubDate> Sun, 15 Oct 2023 14:51:24 GMT</pubDate> </item><item><title><![CDATA[Hyperreals in a Nutshell]]></title><description><![CDATA[Published on October 15, 2023 2:23 PM GMT<br/><br/><p> <i>Epistemic status: Vaguely confused and probably lacking a sufficient technical background to get all the terms right. Is very cool though, so I figured I&#39;d write this.</i></p><blockquote><p> And what are these Fluxions? The Velocities of evanescent Increments? And what are these same evanescent Increments? They are neither finite Quantities nor Quantities infinitely small, nor yet nothing. May we not call them the ghosts of departed quantities?</p><p> George Berkeley, <i>The Analyst</i></p></blockquote><p> When calculus was invented, it didn&#39;t make sense. Newton and Leibniz played fast and dirty with mathematical rigor to develop methods that arrived at the correct answers, but no one knew why. It took another one and a half centuries for Cauchy and Weierstrass develop analysis, and in the meantime people like Berkeley refused to accept the methods utilizing these &quot;ghosts of departed quantities.&quot;</p><p> Cauchy&#39;s and Weierstrass&#39;s solution to the crisis of calculus was to define infinitesimals in terms of limits. In other words, to not describe the behavior of functions directly acting on infinitesimals, but rather to frame the the entire endeavour as studying the behaviors of certain operations in the limit, in that weird superposition of being arbitrarily close to something yet not it.</p><p> (And here I realize that math is better shown, not told)</p><p> The limit of a function <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>at <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x=a"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span></span></span></span> is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span></span></span></span></span> if for any <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon>0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">>;</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span> there exists some<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\delta > 0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;">δ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">>;</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span> such that if</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="|x-a|<\delta,"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;">δ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span></span></span></span><p> then</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="|f(x)-L|<\epsilon."><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span></span></span></span></span></span><p> Essentially, the limit exists if there&#39;s some value <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\delta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;">δ</span></span></span></span></span></span></span> that forces <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> to be within <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span></span></span></span></span> of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span></span></span></span></span> if <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> is within <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\delta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;">δ</span></span></span></span></span></span></span> of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span></span></span></span> . Note that this has to hold true for all <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span></span></span></span></span> , and you choose <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span></span></span></span></span> first!</p><p> From this we get the well-known definition of the derivative:</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="f'(x) = \lim_{h \to 0} \frac{f(x+h)-f(x)}{h}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base" style="margin-right: -0.06em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.181em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-munderover MJXc-space3"><span class="mjx-itable"><span class="mjx-row"><span class="mjx-cell"><span class="mjx-op" style="padding-left: 0.039em;"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">lim</span></span></span></span></span> <span class="mjx-row"><span class="mjx-under" style="font-size: 70.7%; padding-top: 0.236em; padding-bottom: 0.141em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span> <span class="mjx-mfrac MJXc-space1"><span class="mjx-box MJXc-stacked" style="width: 7.021em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 7.021em; top: -1.59em;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span> <span class="mjx-denominator" style="width: 7.021em; bottom: -0.795em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 7.021em;" class="mjx-line"></span></span><span style="height: 2.385em; vertical-align: -0.795em;" class="mjx-vsize"></span></span></span></span></span></span></span><p> and you can define the integral similarly.</p><p> The limit solved calculus&#39;s rigor problem. From the limit the entire field of analysis was invented and placed on solid ground, and this foundation has stood to this day.</p><p> Yet, it seems like we lose something important when we replace the idea of the &quot;infinitesimally small&quot; with the &quot;arbitrarily close to.&quot; Could we actually make numbers that were <i>infinitely small?</i></p><h2> The Sequence Construction</h2><p> Imagine some mathematical object that had all the relevant properties of the real numbers (addition, multiplication are associative and commutative, is closed, etc.) but had infinitely small and infinitely large numbers. What does this object look like?</p><p> We can take the set of all infinite sequences of real numbers <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb{R}^\mathbb{N}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">N</span></span></span></span></span></span></span></span></span></span></span> as a starting point. A typical element <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a\in\mathbb{R}^\mathbb{N}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">N</span></span></span></span></span></span></span></span></span></span></span> would be</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="a = (a_0, \, a_1, \, a_2, \ldots)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span><span class="mjx-mspace" style="width: 0.167em; height: 0px;"></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span><span class="mjx-mspace" style="width: 0.167em; height: 0px;"></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">…</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span><p> where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a_0, a_1, a_2, \ldots"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">…</span></span></span></span></span></span></span> is some infinite sequence of real numbers.</p><p> We can define addition and multiplication element-wise as:</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="a + b = (a_{0} + b_{0}, \, a_{1} + b_{1}, a_{2} + b_{2}, \ldots),"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span><span class="mjx-mspace" style="width: 0.167em; height: 0px;"></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">…</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span></span></span></span><p></p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="a \cdot b = (a_0 \cdot b_0, a_1 \cdot b_1, a_2 \cdot b_2, \ldots)."><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">…</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span></span></span></span></span></span><p> You can verify that this is a commutative ring, which means that these operations behave nicely. Yet, being a commutative ring is not the same thing as being an ordered field, which is what we eventually want if our desired object is to have the same properties as the reals.</p><p> To get from <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb{R}^\mathbb{N}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">N</span></span></span></span></span></span></span></span></span></span></span> to a field structure, we have to modify it to accommodate well-defined division. The typical way of doing this is looking at how to introduce the zero product property: ie ensuring that if <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a,b \in \mathbb{R}^\mathbb{N}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">N</span></span></span></span></span></span></span></span></span></span></span> then if <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="ab = 0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span> either one of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a,b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span> is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span> .</p><p> If we let <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span> be the sequence of all zeros <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(0,0,0,\ldots)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">…</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> in <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb{R}^\mathbb{N},"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">N</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span></span></span></span> then it is clear that we can have two non-zero elements multiply to get zero. If we have</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="a = (a, 0, 0, 0, \ldots),"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">…</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span></span></span></span><p>和</p><span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="b = (0,b,b,b, \ldots),"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">…</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span></span></span></span><p> then neither of these are the zero element, yet their product is zero.</p><p> How do we fix this? Equivalence classes!</p><p> Our problem is that there are too many distinct &quot;zero-like&quot; things in the ring of real numbered sequences. Intuitively, we should expect the sequence <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(0,1,0,0,\ldots)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">…</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> to be <i>basically</i> zero, and we want to find a good condensation of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb{R}^\mathbb{N}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">N</span></span></span></span></span></span></span></span></span></span></span> that allows for this.</p><p> In other words, how do we make all the sequences with &quot; <a href="https://www.ykumar.org/posts/almost-always/">almost all</a> &quot; their elements as zero to be equal to zero?</p><h2> Almost All Agreement ft. Ultrafilters</h2><p> Taken from &quot; <a href="https://www.ykumar.org/almost-always/">five ways to say &quot;Almost Always&quot; and actually mean it</a> &quot;:</p><blockquote><p> A <i>filter</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathcal{F}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.446em; padding-bottom: 0.372em; padding-right: 0.11em;">F</span></span></span></span></span></span></span></span></span> on an arbitrary set <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span></span></span></span></span> is a collection of subsets of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span></span></span></span></span> that is closed under set intersections and supersets. (Note that this means that the smallest filter on <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span></span></span></span></span> is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span></span></span></span></span> itself).</p><p> An <i>ultrafilter</i> is a filter which, for every <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A \subseteq I"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.446em;">⊆</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span></span></span></span></span> , contains either <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span> or its complement. A <i>principal</i> ultrafilter contains a finite set.</p><p> A <i>nonprincipal ultrafilter</i> does not.</p><p> This turns out to be an incredibly powerful mathematical tool, and can be used to generalize the concept of &quot;almost all&quot; to esoteric mathematical objects that might not have well-defined or intuitive properties.</p></blockquote><p> Let&#39;s say we define some nonprincipal ultrafilter <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathcal{U}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.446em; padding-bottom: 0.372em; padding-right: 0.061em;">U</span></span></span></span></span></span></span></span></span> on the natural numbers. This will contain only cofinite sets, and will exclude all finite sets. Now, let&#39;s take two sequences <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a,b \in \mathbb{R}^\mathbb{N},"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">N</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span></span></span></span> and define their <i>agreement set</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span></span></span></span></span> to be the indices on which <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a,b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span> are identical (have the same real number in the same position).</p><p> Observe that <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span></span></span></span></span> is a set of natural numbers. If <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I \in \mathcal{U},"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span> <span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.446em; padding-bottom: 0.372em; padding-right: 0.061em;">U</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span></span></span></span> then <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span></span></span></span></span> cannot be finite, and it seems pretty obvious that almost all the elements in <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a,b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span> are the same (they only disagree at a finite number of places after all). Conversely, if <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I \not\in \mathcal{U},"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∉</span></span> <span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.446em; padding-bottom: 0.372em; padding-right: 0.061em;">U</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span></span></span></span> this implies that the complement of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I,"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb{N}/I \in \mathcal{U}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">N</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">/</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span> <span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.446em; padding-bottom: 0.372em; padding-right: 0.061em;">U</span></span></span></span></span></span></span></span></span> , which means that <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a,b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span> disagree at almost all positions, so they probably shouldn&#39;t be equal.</p><p> Voila! We have a suitable definition of &quot;almost all agreement&quot;: if the agreement set <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span></span></span></span></span> is contained in some arbitrary nonprincipal ultrafilter <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathcal{U}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.446em; padding-bottom: 0.372em; padding-right: 0.061em;">U</span></span></span></span></span></span></span></span></span> .</p><p> Let<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="^*\mathbb{R}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char"></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span></span></span></span></span> be the quotient set of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb{R}^\mathbb{N}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">N</span></span></span></span></span></span></span></span></span></span></span> under this equivalence relation (essentially, the set of all distinct equivalence classes of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb{R}^\mathbb{N}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">N</span></span></span></span></span></span></span></span></span></span></span> ). Does this satisfy the zero product property?</p><p> (Notation note: we will let <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(a)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> denote the infinite sequence of the real number <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span></span></span></span> , and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="[a]"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span></span></span></span></span></span> the equivalence class of the sequence <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(a)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> in <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="^* \mathbb{R}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char"></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span></span></span></span></span> .)</p><h2> Yes, This Behaves Like The Real Numbers</h2><p> Let <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a,b \in \mathbb{R}^\mathbb{N}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">N</span></span></span></span></span></span></span></span></span></span></span> such that <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="ab = (0)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> . Let&#39;s break this down element-wise: either <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a_n, b_n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span></span></span> must be zero for all <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \in \mathbb{N}."><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span> <span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">N</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span></span></span></span></span></span> As one of the ultrafilter axioms is that it must contain a set or its complement, either the index set of the zero elements in <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span></span></span></span> or the index set of the zero elements in <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span> will be in any nonprincipal ultrafilter on <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb{N}."><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">N</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span></span></span></span></span></span> Therefore, either <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span></span></span></span> or <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span> is equivalent to <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(0)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> in <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="^* \mathbb{R},"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char"></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span></span></span></span> so <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="^* \mathbb{R}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char"></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span></span></span></span></span> satisfies the zero product property.</p><p> Therefore, division is well defined on<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="^*\mathbb{R}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char"></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span></span></span></span></span> ! Now all we need is an ordering, and luckily almost all agreement saves the day again. We can say for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a,b \in ^*\mathbb{R}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span></span></span></span></span> that <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a>b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">>;</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span> if almost all elements in <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span></span></span></span> are greater than the elements in <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span> at the same positions (using the same ultrafilter equivalence).</p><p> So,<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="^*\mathbb{R}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char"></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span></span></span></span></span> is an ordered field!</p><h2> Infinitesimals and Infinitely Large Numbers</h2><p> We have the following hyperreal:</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\epsilon = \left( 1, \frac{1}{2}, \frac{1}{3}, \ldots, \frac{1}{n}, \ldots \right)."><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 1.256em; padding-bottom: 1.256em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mfrac MJXc-space1"><span class="mjx-box MJXc-stacked" style="width: 0.7em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 0.7em; top: -1.368em;"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="width: 0.7em; bottom: -0.756em;"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.7em;" class="mjx-line"></span></span><span style="height: 2.124em; vertical-align: -0.756em;" class="mjx-vsize"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mfrac MJXc-space1"><span class="mjx-box MJXc-stacked" style="width: 0.7em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 0.7em; top: -1.368em;"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="width: 0.7em; bottom: -0.777em;"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.7em;" class="mjx-line"></span></span><span style="height: 2.145em; vertical-align: -0.777em;" class="mjx-vsize"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">…</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mfrac MJXc-space1"><span class="mjx-box MJXc-stacked" style="width: 0.8em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 0.8em; top: -1.368em;"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="width: 0.8em; bottom: -0.722em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.8em;" class="mjx-line"></span></span><span style="height: 2.089em; vertical-align: -0.722em;" class="mjx-vsize"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">…</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 1.256em; padding-bottom: 1.256em;">)</span></span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span></span></span></span></span></span><p> Recall that we embed the real numbers into the hyperreals by assigning every real number <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span></span></span></span> to the equivalence class <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="[a]"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span></span></span></span></span></span> . Now observe that <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span></span></span></span></span> <i>is smaller than every real number embedded into the hyperreals this way.</i></p><p> Pick some arbitrary real number <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span></span></span></span> . There exists <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p \in \mathbb{N}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span> <span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">N</span></span></span></span></span></span></span></span></span> such that <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{p}< a"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 0.497em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.703em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.703em; bottom: -0.707em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.497em;" class="mjx-line"></span></span><span style="height: 1.47em; vertical-align: -0.5em;" class="mjx-vsize"></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span></span></span></span> . There are infinitely many fractions of the form <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{n}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 0.566em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.8em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.8em; bottom: -0.524em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.566em;" class="mjx-line"></span></span><span style="height: 1.341em; vertical-align: -0.37em;" class="mjx-vsize"></span></span></span></span></span></span></span> , where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> is a natural number greater than <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span> , so <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span></span></span></span></span> is smaller than <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(a)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> at almost all positions, so it is smaller than <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span></span></span></span> .</p><p> This is an infinitesimal! This is a rigorously defined, coherently defined, <i>infinitesimal number</i> smaller than all real numbers! In a number system which shares all of the important properties of the real numbers! (except the Archimedean one, as we will shortly see, but that doesn&#39;t really matter).</p><p> Consider the following</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display"><span class="mjx-math" style="width: 100%;" aria-label="\Omega = (1,2,3, \\ldots)."><span class="mjx-mrow" style="width: 100%;" aria-hidden="true"><span class="mjx-stack" style="width: 100%; vertical-align: -1.492em;"><span class="mjx-block" style="text-align: center;"><span class="mjx-box"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Ω</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span> <span class="mjx-block" style="text-align: center; padding-top: 0.442em;"><span class="mjx-box"><span class="mjx-mspace" style="width: 0px; height: 0px;"></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">o</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span></span></span></span></span></span></span></span></span><p> By a similar argument this is larger than all possible real numbers. I encourage you to try to prove this for yourself!</p><p> (The Archimedean principle is that which guarantees that if you have any two real numbers, you can multiply the smaller by some natural number to become greater than the other. This is not true in the hyperreals. Why? (Hint: <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Omega"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Ω</span></span></span></span></span></span></span> breaks this if you consider a real number.))</p><h2> How does this tie into calculus, exactly?</h2><p> Well, we have a coherent way of defining infinitesimals!</p><p> The short answer is that we can define the <i>star</i> operator<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{st}(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.372em;">st</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> as that which maps any hyperreal to its closest real counterpart, provided it can be written as the sum of a real number and an infinitesimal part. Then, the definition of a derivative becomes</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="f'(x) = \text{st}\left( \frac{f(x+\Delta x)- f(x)}{\Delta x}\right)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base" style="margin-right: -0.06em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.181em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mtext MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.372em;">st</span></span> <span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size4-R" style="padding-top: 1.551em; padding-bottom: 1.551em;">(</span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 7.85em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 7.85em; top: -1.59em;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Δ</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span> <span class="mjx-denominator" style="width: 7.85em; bottom: -0.817em;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Δ</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 7.85em;" class="mjx-line"></span></span><span style="height: 2.407em; vertical-align: -0.817em;" class="mjx-vsize"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-size4-R" style="padding-top: 1.551em; padding-bottom: 1.551em;">)</span></span></span></span></span></span></span></span><p> where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Delta x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Δ</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> is some infinitesimal. More on this in a future blog post!</p><p> It also turns out the hyperreals have a bunch of really cool applications in fields far removed from analysis. Check out my expository paper on <a href="https://ykumar.org/files/Nonstandard_Methods_and_Applications_in_Ramsey_Theory.pdf">the intersection of nonstandard analysis and Ramsey theory</a> for an example!</p><p> Yet, the biggest effect I think this will have is pedadogical. I&#39;ve always found the definition of a limit kind of unintuitive, and it was specifically invented to add <i>post hoc</i> coherence to calculus after it had been invented and used widely. I suspect that formulating calculus via infinitesimals in introductory calculus classes would go a long way to making it more intuitive.</p><br/><br/><a href="https://www.lesswrong.com/posts/9dmrnXa9AcSAHwX6z/hyperreals-in-a-nutshell#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9dmrnXa9AcSAHwX6z/hyperreals-in-a-nutshell<guid ispermalink="false"> 9dmrnXa9AcSAHwX6z</guid><dc:creator><![CDATA[Yudhister Kumar]]></dc:creator><pubDate> Sun, 15 Oct 2023 14:23:58 GMT</pubDate> </item><item><title><![CDATA[Discovering Latent Knowledge in the Human Brain: Part 1 – Clarifying the concepts of belief and knowledge]]></title><description><![CDATA[Published on October 15, 2023 9:02 AM GMT<br/><br/><p> <i>Acknowledgements: Many thanks to Milan Cvitkovic and Collin Burns for their help in workshopping this project proposal. Many of the ideas presented here regarding the use of neuroscience and neurotechnology were originally proposed by Milan</i> <a href="https://milan.cvitkovic.net/writing/neurotechnology_is_critical_for_ai_alignment/"><i><u>here</u></i></a> <i>. This post represents my current thinking on the topic and does not necessarily represent the views of the individuals I have just mentioned.</i></p><p> <strong>tl;dr</strong> : Methods for promoting honest AI hinge on our ability to identify beliefs/knowledge in models. These concepts are derived from human cognition. In order to use them in AI, we need to provide definitions at the appropriate level of resolution. In this post, I describe why I think it would be a useful starting point to recover truth-like latent features in human brain data with contrast-consistent search (CCS). In an upcoming post, I will outline why I think this is possible with current fMRI technology.</p><h1>概括</h1><p>Methods for discovering latent knowledge in language models, such as contrast-consistent search (CCS), hold the potential to enable humans to directly infer a model&#39;s “beliefs” from its internal activations. This can be useful for promoting honesty in AI systems by ensuring that their outputs are consistent with their “beliefs”.</p><p> However, it is currently unclear how the truth-like features recovered by CCS relate to the concepts of belief and knowledge, whose definitions are derived from human intelligence. Since these concepts underlie behaviors like deception and honesty, is essential that we understand them at the appropriate level of resolution to enable us to translate the concepts to AI systems.</p><p> A starting point could be to determine whether CCS identifies analogous features in human brains. My proposal is to use ultra-high-field functional magnetic resonance imaging (fMRI) to replicate discovering latent knowledge experiments in humans. This approach not only promises to shed light on the representations identified by CCS but also offers a crucial testbed for evaluating techniques aimed at detecting deception in AI.</p><h2> About this post</h2><p> I am posting a proposal to perform a human version of &quot;Discovering Latent Knowledge in Language Models&quot; in order to elicit feedback and help clarify my thinking on the motivation and utility of the project. I have separated my proposal into two posts. In this post, I&#39;ll cover why I think it is hard to define honesty and deception in AI, and why I think looking at human brain function can 1) help us arrive at better definitions of cognitive concepts and 2) serve as a testbed for our approaches for lie detection in AI. In the next post, I will outline a specific project proposal to test CCS on human brain data from ultra-high-field functional magnetic resonance imaging (fMRI). <strong>Readers who are interested in understanding the justification behind my proposal would benefit most from reading this post</strong> . Readers who are interested in the details of the specific project should also have a look at the second (upcoming) post.</p><h1> How Studying Human Intelligence Could Help Promote Honest AI</h1><p> To start, I would like to outline a couple reasons why neuroscience could play an important role in AI safety, especially when our aim is to foster honest AI. Much of the following overlaps quite a bit with ideas presented elsewhere in the AI safety community (specifically <a href="https://milan.cvitkovic.net/writing/neurotechnology_is_critical_for_ai_alignment/"><u>Milan Cvitkovic&#39;s post on the importance of neurotechnology</u></a> ), but I think that repackaging it here provides some clarity for the general motivation of this project.</p><h2> 1) We need better definitions of cognitive concepts to use them in AI alignment research</h2><p> I think we risk inappropriately anthropomorphizing AI when we use cognitive concepts to describe their behaviors. Deception provides a clear example. If we want to determine if an AI is lying, we first need to define what lying is. Central to the concepts of deception and lying are the concepts of belief and knowledge. Determining whether a system has beliefs or knowledge cannot rely only on measurements of external behavior. Instead, it requires evaluating the internal states of the system. Otherwise, we risk misunderstanding the AI by inappropriately assigning it human cognitive states.</p><p> Cognitive science theories currently lack the specificity necessary to determine if AI models possess beliefs or knowledge analogous to humans (although there is significant work on neurocognitive theories in this direction [ <a href="https://www.frontiersin.org/articles/10.3389/fnbeh.2022.880504/full#:~:text=.%2C%202022).-,Pre%2Dlinguistic%20Processes%20of%20Believing,%2C%20and%20perceptive%2Demotional%20integration.">1</a> , <a href="https://direct.mit.edu/netn/article/1/4/381/5401/The-graphical-brain-Belief-propagation-and-active">2</a> ]). Doing so will require describing these cognitive phenomena at the algorithmic level [ <a href="https://mitpress.mit.edu/9780262514620/vision/">3</a> ] <span class="footnote-reference" role="doc-noteref" id="fnref5ah6drf5sfp"><sup><a href="#fn5ah6drf5sfp">[1]</a></sup></span> , so that we can identify their signatures across systems that may be vastly different from each other at the implementation level. Because any definition for these concepts will need to be validated, defining cognitive phenomena at the appropriate level of resolution to transport to AI will quite likely involve measuring activity in biological brains.</p><h2> 2) We should be sure that our interpretability methods work in humans before relying on them to align AGI</h2><p> We would like to know that our methods for interpreting AI generalize beyond the narrow scope under which these methods are developed. This validation is particularly crucial if we want to deploy general-purpose methods to align powerful AGI in the future. A significant challenge, however, lies in testing the widespread applicability of these interpretability methods—specifically, understanding their scalability. Fortunately, we have a readily accessible general intelligence to examine: humans. Before counting on these methods to align AGI, it&#39;s prudent to ascertain their efficacy within the human context.</p><h1> The Problem</h1><h2> Building lie detectors </h2><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/ps35bv69uzvwaomplcx6" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/ymvqpj5g4bi1mmg2zvs6 130w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/t2jm9slbjggfjpniinkx 260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/guvphiy0xbcu2d5vwt6m 390w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/ilhlp7roob18qmrmhvgn 520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/ybshi9jjsbcv1dc6dmkr 650w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/rduanvfq6tcqxls4aomu 780w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/p1w7knahnxjqegq3usj1 910w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/glwiviz1qdg0gem8ebs6 1040w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/jj45j0xnwmzrk2utonfr 1170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/p5tzg0rhptyumvemkged 1262w"></figure><p> In general, we would like to avoid building models that can lie to us. Methods for discovering latent knowledge (DLK) aim to report what a model “believes/knows” <span class="footnote-reference" role="doc-noteref" id="fnrefh4gbanft2x6"><sup><a href="#fnh4gbanft2x6">[2]</a></sup></span> . If we know what a model believes/knows, then we can simply check if its actions are consistent with these beliefs.</p><p> Burns et al. (2022) [ <a href="https://arxiv.org/abs/2212.03827">4</a> ] made a surprising discovery that a simple linear classifier could be trained on pairs of statements and their negations to identify latent dimensions within language models that track propositional truth value. The ability of this classifier to predict the truth value of the inputs from internal activations exceeded the accuracy of zero-shot baselines. Moreover, the predictions made by the classifier continued to accurately report truth value, even when the model outputs did not.</p><p> Do these latent dimensions capture the “beliefs/knowledge” of the model? What does it mean to say that the model believes cats are mammals? Unfortunately, we can&#39;t answer these questions yet, because we don&#39;t have a sufficient understanding of what beliefs or knowledge are. Predicting whether a statement was true or false based on information present in language models is not enough to confirm that these models hold beliefs regarding the statement, because we do not know if and how that information is utilized or represented in the model. This is a problem if we want to build lie detectors, because our definition of lying relies on the concepts of knowledge and belief, which are defined internally and cannot be inferred from behavior alone.</p><h2> DLK in humans </h2><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/w1amigmgizutawotr7i0" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/cxlccb9sebrr6msz1yr8 130w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/igsbl4la3o1gbyaqfj9c 260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/vnztyivqup4woianocgd 390w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/w4a2lv7k3uipaguqlndg 520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/jv5fbfvdllzycrnvgt30 650w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/kxgbopl8txuk2abmo0zy 780w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/ecqbjg6xix3ebjmq1lva 910w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/gjjn23xae021ovc6jjfs 1040w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/dgitksvd9zdzw4yyopri 1170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/kebuknclsizfoiunvtbd 1272w"></figure><p> What can we do in the absence of a comprehensive theory of belief and knowledge? We could try to build such a theory, but any theory explaining these concepts must be validated in humans. A standard approach is to look for the physical (likely neural) correlates of a cognitive phenomenon and try to draw more general conclusions from those.</p><p> For instance, we observe through direct experience that we possess beliefs and knowledge, and we extend this capacity to other humans. We can record these beliefs pretty reliably, for instance by simply asking a (trustworthy) person whether they think a proposition is true or false. If we observe the underlying brain processes that accompany these propositions, we could identify which of those coincided with the phenomenology of believing or disbelieving those propositions, and ideally also perturb the relevant neural mechanisms to determine whether they play a causal role.</p><p> However, in practice, discovering neural correlates of beliefs/knowledge is difficult, both because it is very hard to experimentally isolate the cognitive processes of interest and because our current means of measuring and perturbing the brain are still relatively imprecise. A slightly different approach could be to directly use DLK methods like CCS, which ostensibly recover “beliefs” from internal states of models, to recover similar truth-like features from human brain data. This approach can provide us with candidate neural features whose relationship to beliefs/knowledge can be explored in detail. The advantage of this approach is that we can be reasonably confident that beliefs/knowledge are embedded within the observed neural activity, because we are able to connect these to phenomenology.</p><p> As mentioned previously, there is already at least one method (CCS) for discovering features in language models that look particularly belief-like. This method may even suggest a framework for how beliefs are encoded in neural activity. Under this framework, the consistency of beliefs with the semantic content of natural language statements is represented <span class="footnote-reference" role="doc-noteref" id="fnref7ajemf68n8p"><sup><a href="#fn7ajemf68n8p">[3]</a></sup></span> along latent dimensions of neural activity, similar to the way other features are thought to be represented in the brain and artificial neural networks alike. If this framework is true of human truth evaluation in natural language processing, then this predicts that we should identify latent dimensions in neural activity that discriminates between true and false statements as rendered by the individual. This accomplishes two goals: 1) It assesses the efficacy of CCS in pinpointing neural correlates of truth evaluation when we&#39;re confident such processes are influencing the observed behavior, and 2) it lays the foundation for a plausible framework for knowledge and beliefs, potentially applicable across diverse intelligences.</p><h2> Testing lie detectors </h2><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/apgonzhyelywixnzmyam" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/wcolyur9vhefaikz2saw 130w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/n4t52dxoma6yfwkwmpqy 260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/psegou8z2tp9cmicoxsl 390w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/x5m5duohltwmzcyezdlg 520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/mhcv4ur19dkyezonvix2 650w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/ko3poqfj3efwnf5rlubl 780w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/la2rtztidubccldinbgq 910w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/wqrayt6qxcz1etmlidhi 1040w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/qnnreuhiuju7ryu3ccq3 1170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/csFXHGb7gxpzMTeT5/fyosurfffkedyovesg9q 1272w"></figure><p> Once we have built and validated our DLK method, we should be able to put it to use to identify when models are lying. But there is still a problem. While it is possible to get language models to produce outputs that are inconsistent with the predictions from our DLK method, it is still unclear whether these constitute lies, because our understanding is still limited regarding how the information identified through our method influences the model&#39;s behavior. For instance, the model may have misinterpreted the nature of the task, or it may lack access to the necessary information in its procedure for producing its response. To distinguish between these cases and deceptive behavior, we have to further define how beliefs are used in the context of lying.</p><p> Another layer of complexity arises when considering the stability of belief/knowledge embeddings identified by DLK across varied behavioral circumstances, including situations involving deception. If, for instance, belief embeddings are obscured during deception, the accuracy of DLK, developed under truth-telling conditions, may be compromised.</p><p> If we want to test our DLK method as a lie detector, then we need to test its ability to act as such in humans. Given that humans can intentionally lie, inducing deception in an experimental setting is feasible. Such an approach illuminates the underlying processes governing truth evaluation during honesty and deception. Moreover, subjecting our DLK method to various behavioral conditions will vet its resilience, offering further confidence in its ability to discern genuine neural correlates of specific cognitive functions.</p><h2> Some other specific questions about CCS that can be addressed by DLK in the human brain</h2><p> In order to be very clear about how I think DLK in the human brain could contribute to understanding open questions in AI safety, I&#39;ll provide a few additional examples of specific questions that I believe would be addressed by this project. Note that I do not think that DLK in the human brain will provide definitive answers to any of these, but I think it could provide useful evidence before the arrival of human-level or superhuman AGI.</p><h3> Will future language models encode truth in a simple linear way?</h3><p> If we find that humans do not encode truth with a limited set of features that are accessible with linear decoders, this may change our expectations for future AI systems. In this situation, it would benefit us to understand how humans evaluate truth, and then to look for these processes in AI. On the other hand, if humans do encode truth in a relatively simple way that can be assessed with linear decoders, then I might be cautiously optimistic that similar approaches will work for increasingly general AI.</p><h3> Are belief/knowledge embeddings obscured during active deception?</h3><p> If we find that belief/knowledge embeddings are altered during active deception in humans, or that humans are able to deliberately obscure their belief/knowledge embeddings, for instance, by thinking of something else, then we should have more concern for this kind of behavior being exhibited by an advanced AI. Knowing this can help us advance strategies for promoting honesty that anticipate these kinds of behaviors.</p><h3> Can a purely language-based approach to DLK uncover beliefs that were not acquired through language?</h3><p> A serious concern is that future AI systems will not explicitly connect their beliefs to language such that they can be elicited by methods like CCS. Humans, and presumably other intelligent organisms, invariably form beliefs through means other than interacting through natural language. It would be useful to test whether an approach like CCS, which operates through language, could ascertain beliefs that are formed by humans outside of language.</p><h2> Some possible objections</h2><h3> Can&#39;t we just build truthful AI?</h3><p> Enforcing truthfulness in AI, especially LLMs, rather than honesty could be a more feasible and stringent criterion [ <a href="https://arxiv.org/abs/2110.06674">5</a> ]. While honesty enforces that statements are made in accordance with beliefs, truthfulness requires that statements are verifiably true. Enforcing truthfulness sidesteps the issue of defining internal cognitive processes and relies only on external observations of behavior.</p><p> While I think aiming for truthfulness may be a valuable near-term approach and desirable alongside honesty, I worry that it will have limitations in enforcement as AI systems become increasingly capable, producing outputs that may be difficult to verify by humans. Assessing truth value in natural language is already not straightforward (see debates on factive predicates in linguistics eg [ <a href="https://muse.jhu.edu/article/864635/summary">6</a> ]). Plus, training models exclusively on human-verifiable statements doesn&#39;t eliminate the likelihood of models misgeneralizing beyond their training data. Consequently, discerning a model&#39;s inherent beliefs and its adherence to them remains crucial.</p><p> I also worry that the framing for truthful AI too narrowly conceptualizes deception as “lying”. In fact, deception does not require that statements are made contrary to internal beliefs. Sophisticated deception is observed when an individual makes statements that are verifiably true in order to mislead or manipulate others to act contrary to how they would otherwise. This can happen when individuals anticipate that their statements will not be believed by others [ <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0297.2008.02205.x">7</a> , <a href="https://www.nature.com/articles/s41598-020-67721-z">8</a> ]. Numerous manipulative tactics don&#39;t necessarily involve blatant falsehoods but may be built around selective but still factually accurate statements. Given these considerations, I think aiming for honesty in AI, which circumvents both simple and sophisticated forms of deception, is a necessary long-term goal.</p><h3> Won&#39;t it be obvious when we have identified the cognitive capacities of AI?</h3><p> Perhaps we will discover methods that quite compellingly suggest that some AI systems possess certain cognitive capacities (maybe by exactly describing the process by which some process happens in full detail). However, I&#39;m doubtful that we can be confident that these cognitive capacities map cleanly to concepts like “deception” and “honesty” without testing that we reach similar conclusions in humans. Any attempt to extrapolate human-centric cognitive notions onto AI necessitates a robust validation of these concepts in humans first.</p><h3> We shouldn&#39;t expect the cognition of advanced AIs to resemble that of humans anyway.</h3><p> I think this is quite possibly true. If it is true however, we should be extremely cautious about applying concepts derived from human cognition to AI. It still would benefit us to determine precisely how the cognition of AI differs from human intelligence, and what implications that has for defining what we mean by wanting to avoid deceptive behavior. For instance, if models do not have analogous belief/knowledge structures, then it becomes unclear how to approach the problem of deceptive AI, or whether deception is a coherent framework for thinking about AI at all.</p><h3> Language limits our evaluation of beliefs.</h3><p> I am most worried about this objection, and I think it requires further consideration. When we use language to probe beliefs, we may be limiting ourselves to propositions that can be easily stated in natural language. That is, language may be insufficient to communicate certain propositions precisely, and therefore we may not be able to elicit the full range of beliefs/knowledge encoded by brains or AI systems. We can probably elicit certain things from the underlying world model through language, but what we would like to do is probe the world model itself.</p><p> Furthermore, language does not appear to be necessary to have beliefs/knowledge. The distinction between language and belief/knowledge appears to be demonstrated in individuals who have had corpus callostomies (ie split-brain patients). Often, these patients cannot express, through language or perhaps only certain forms of language, information that is only accessible to the non-language-dominant brain hemisphere. Yet, these individuals can still take actions based on this knowledge even if they are not able to connect it to language (see [ <a href="https://www.nature.com/articles/nrn1740">9</a> ] and [ <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C24&amp;q=review+of+the+split+brain+1975&amp;btnG=">10</a> ] for reviews of split-brain studies).</p><p> I think this objection might hit on some deep philosophical problems that I am not prepared to address directly. However, the current proposal still seems to at least be capable of addressing narrower questions like “How is natural language evaluated against beliefs/knowledge in the brain?” and “Can we use natural language to infer beliefs/knowledge directly from brain data?”, which is perhaps a starting point for addressing deeper questions.</p><p> Moreover, the concern about language being insufficient to ascertain beliefs/knowledge is just as much a problem for aligning AI as it is for studying belief/knowledge in humans. Therefore, this objection does not provide a specific criticism of the present proposal to test CCS in humans, and instead offers a legitimate critique of the use of CCS (in its current form) as a method for discerning beliefs/knowledge in general. I suspect that future methods will be able to discover beliefs/knowledge by eliciting them in ways that do not involve natural language, or use natural language alongside other modalities. These methods might end up looking quite similar to CCS. However, they also may require deeper theoretical foundations for intelligence. Regardless, when we develop such methods and theories, we should ensure that they apply to humans for the same reasons I have outlined above.</p><h1>结论</h1><p>I have outlined here why I think it is necessary to examine human brains to understand belief and knowledge at the appropriate level of resolution to use the concepts to explain the behavior of AI. Since our definitions of deception invokes beliefs/knowledge, understanding these concepts is essential for avoiding deceptive behaviors in AI. I think that perhaps the simplest way forward is to use our current methods for recovering “beliefs” in LLMs to recover analogous features in human brain data. This both tests the generality of these methods, particularly in the context of general intelligence, and begins to examine how the features recovered by these methods relate to belief/knowledge.</p><p> My biggest reservation is that CCS probes beliefs/knowledge through natural language. It seems unclear to me whether this will be sufficient to recover beliefs/knowledge that may have been formed outside of natural language and may not be explicitly connected to language. Furthermore, it limits the neuroscientific questions that can be addressed by restricting assessments to how world-models are brought to bear on language rather than probing the world-model itself. However, I tend to view this as a more general critique of CCS. It still stands to reason that DLK methods, including CCS and future methods that may or may not be tied to natural language, should be investigated in the human context.</p><h2> Next Post</h2><p> My next post will outline a specific experiment for testing CCS with human fMRI data. I&#39;ll provide an assessment of the current neuroscience literature on the topic of truth evaluation in natural language, the experimental details of my proposal, and the limitations of current methodologies for studying this topic in the human brain.</p><h1> References</h1><p> [1] RJ Seitz. Believing and beliefs—neurophysiological underpinnings. Frontiers in Behavioral Neuroscience, 16:880504, 2022.</p><p> [2] KJ Friston, T. Parr, and B. de Vries. The graphical brain: Belief propagation and active inference. Network neuroscience, 1(4):381–414, 2017.</p><p> [3] D. Marr. Vision: A computational investigation into the human representation and processing of visual information. MIT press, 1982.</p><p> [4] C. Burns, H. Ye, D. Klein, and J. Steinhardt. Discovering latent knowledge in language models without supervision. arXiv preprint arXiv:2212.03827, 2022.</p><p> [5] O. Evans, O. Cotton-Barratt, L. Finnveden, A. Bales, A. Balwit, P. Wills, L. Righetti, and W. Saunders. Truthful AI: Developing and governing AI that does not lie. arXiv preprint arXiv:2110.06674, 2021.</p><p> [6] J. Degen and J. Tonhauser. Are there factive predicates? An empirical investigation. Language, 98(3):552–591, 2022.</p><p> [7] M. Sutter. Deception through telling the truth?! Experimental evidence<br> from individuals and teams. The Economic Journal, 119(534):47–60, 2009.</p><p> [8] M. Zheltyakova, M. Kireev, A. Korotkov, and S. Medvedev. Neural mecha-<br> nisms of deception in a social context: an fMRI replication study. Scientific<br> Reports, 10(1):10713, 2020.</p><p> [9] MS Gazzaniga. Forty-five years of split-brain research and still going<br> strong. Nature Reviews Neuroscience, 6(8):653–659, 2005.</p><p> [10] MS Gazzaniga. Review of the split brain, 1975. <br></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn5ah6drf5sfp"> <span class="footnote-back-link"><sup><strong><a href="#fnref5ah6drf5sfp">^</a></strong></sup></span><div class="footnote-content"><p> Referring here to David Marr&#39;s levels of analysis, which distinguishes between the computational level - the goal of the system, the algorithmic level - how the computation is achieved, and the implementation level - how the algorithm is physically instantiated.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnh4gbanft2x6"> <span class="footnote-back-link"><sup><strong><a href="#fnrefh4gbanft2x6">^</a></strong></sup></span><div class="footnote-content"><p> This topic appears closely tied to <a href="https://www.lesswrong.com/tag/eliciting-latent-knowledge-elk#:~:text=Eliciting%20Latent%20Knowledge%20is%20an,that%20look%20good%20to%20us."><u>Eliciting Latent Knowledge (ELK)</u></a> , but for the time being, I am assuming that the reporter for the model&#39;s beliefs will be simple enough that we don&#39;t have to worry about the human simulator failure mode described in ARC&#39;s first technical report on the subject. Regardless, my intuition is that the problem of defining belief/knowledge will be common across any approach to ELK, and could therefore benefit from validation in humans.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn7ajemf68n8p"> <span class="footnote-back-link"><sup><strong><a href="#fnref7ajemf68n8p">^</a></strong></sup></span><div class="footnote-content"><p> It was pointed out to me that saying that truth is “represented” by the brain might be a misapplication of the framework of representationalism in cognitive science. To avoid misusing this terminology, I will try to use “truth evaluation process” as an alternative to “truth representation”.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/csFXHGb7gxpzMTeT5/discovering-latent-knowledge-in-the-human-brain-part-1#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/csFXHGb7gxpzMTeT5/discovering-latent-knowledge-in-the-human-brain-part-1<guid ispermalink="false"> csFXHGb7gxpzMTeT5</guid><dc:creator><![CDATA[Joseph Emerson]]></dc:creator><pubDate> Sun, 15 Oct 2023 11:00:29 GMT</pubDate> </item><item><title><![CDATA[Rationalist horror movies]]></title><description><![CDATA[Published on October 15, 2023 7:42 AM GMT<br/><br/><p> I like horror movies with smart, agentic protagonists, while staying in horror genre rather than thriller or action. These are rather thin on the ground. In the spirit of <a href="https://www.lesswrong.com/posts/4KATQFzniqDpHo6ck/puzzle-games">Scott Garabant&#39;s Puzzle Game post</a> , here is my list of favorites and an invitation to add yours.</p><p> My favorites:</p><ul><li> Oculus.</li><li> Hush</li><li> Green Room</li></ul><p> Honorable mentions. These aren&#39;t quite the total package, but are close and extremely good such that they still seemed worth including:</p><ul><li> The Ring&#39;s protagonist is not dumb, but it&#39;s more &quot;solving a mystery&quot; than &quot;well does this weapon work?&quot;</li><li> Tremors would need to change very little to be a horror movie, but it is in fact an action movie.</li><li> It Follows spends a little too much time denying the problem</li></ul><br/><br/><a href="https://www.lesswrong.com/posts/aCjvg5whn8DYqneg5/rationalist-horror-movies#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/aCjvg5whn8DYqneg5/rationalist-horror-movies<guid ispermalink="false"> aCjvg5whn8DYqneg5</guid><dc:creator><![CDATA[Elizabeth]]></dc:creator><pubDate> Sun, 15 Oct 2023 07:42:16 GMT</pubDate> </item><item><title><![CDATA[Unity Gridworlds]]></title><description><![CDATA[Published on October 15, 2023 4:36 AM GMT<br/><br/><p> <strong>Summary:</strong></p><p> <a href="https://github.com/Will9371/Grid-Worlds"><i><u>Unity Gridworlds</u></i></a> is an open-source recreation of DeepMind&#39;s 2017 paper, <a href="https://arxiv.org/abs/1711.09883"><i>AI Safety Gridworlds</i></a> in the Unity game engine, including a level editor that decreases the barrier to entry for non-specialists to design their own Gridworlds-style experiments.</p><p> (See this <a href="https://www.zenmarmotdigital.com/blog/unity-gridworlds">blog</a> for a longer form of this post with more background explanation)</p><p> <strong>Background:</strong></p><p> Gridworlds is a series of experiments published by DeepMind in 2017 involving toy environments that analogize to dangerous situations for future AI, exploring questions like “will an AI allow itself to be shut down?” and “will it act differently if it knows it is being supervised?”</p><p> Unity is an extremely popular game engine used by millions of hobbyist and professional game developers around the world.  It can be downloaded for free and has a <a href="https://unity.com/products/machine-learning-agents"><u>Machine Learning Agents</u></a> plugin that abstracts away the algorithms and lets you focus on designing environments and reward systems.</p><p> <strong>Project Demonstration:</strong></p><p> To demonstrate some of the core features of <i>Unity Gridworlds</i> , I have created <i>Risk Aversion,</i> a novel environment that explores AI willingness to search for high risk/reward strategies during training.  See <a href="https://youtu.be/idn20Iibq6Q"><u>this video</u></a> for a step-by-step walkthrough of the creation process, including level design, testing, training, and deployment.</p><p> Some highlights:</p><ul><li> Environment design is done through an intuitive point-and-click graphical user interface.</li><li> Core features, such as agent movement, basic object interactions, saving/loading layouts, and result visualization are built-in.</li><li> You can watch training happen visually and in accelerated-time, gathering qualitative feedback that would be easy to miss in reports and charts (but those are also available).  In my video demonstration, for example, the agent finds a high-reward strategy during training, then discards it for some unknown reason.</li><li> Training for simple environments can take as little as 5-15 minutes on a consumer-grade PC, even without GPU acceleration.<br></li></ul><p> <strong>What&#39;s Next:</strong></p><p> My hopes with <i>Unity Gridworlds</i> are to provide a resource for established AI safety researchers and also to introduce AI alignment concepts to a broad audience of hobbyist and professional game developers.  I am currently looking for collaborators to provide feedback regarding UI and workflow improvements, suggest (or help implement) useful features, and design interesting experiments.  If this interests you, regardless of experience level, feel free to reach out!</p><br/><br/><a href="https://www.lesswrong.com/posts/74xt2jAMfFTGtEujN/unity-gridworlds#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/74xt2jAMfFTGtEujN/unity-gridworlds<guid ispermalink="false"> 74xt2jAMfFTGtEujN</guid><dc:creator><![CDATA[WillPetillo]]></dc:creator><pubDate> Sun, 15 Oct 2023 05:26:26 GMT</pubDate> </item><item><title><![CDATA[In memory of Louise Glück]]></title><description><![CDATA[Published on October 15, 2023 2:59 AM GMT<br/><br/><p> (Cross-posted from <a href="https://joecarlsmith.com/2023/10/15/in-memory-of-louise-gluck">my website</a> . Podcast version <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13778055-in-memory-of-louise-gluck">here</a> , or search &quot;Joe Carlsmith Audio&quot; on your podcast app.) </p><figure class="image image_resized" style="width:46.81%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gtxrEJoZ4NK4sXqTN/xezfolkdkftvifki8xlh" alt="" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gtxrEJoZ4NK4sXqTN/xezfolkdkftvifki8xlh 460w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gtxrEJoZ4NK4sXqTN/hzmxjpd7injz2ib3icuf 232w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gtxrEJoZ4NK4sXqTN/vaee2uqj6ziifeep4eqi 402w"><figcaption> Louise Glück, circa 1977. Image source <a href="https://commons.wikimedia.org/wiki/Category:Louise_Gl%C3%BCck#/media/File:Louise_Gl%C3%BCck_circa_1977.jpg">here</a> .</figcaption></figure><p> Louise Glück, one of my favorite poets, died yesterday.</p><p> I took a writing workshop with her back in 2009. I remember the force and precision of her words as she spoke, slowly, in class. There was a feeling like stones falling, one by one, into place. Like something large was being built, steadily, in simple movements, and you could see it forming.</p><p> I remember, too, a meeting in her office. It was early in the semester, and she hadn&#39;t liked my poem. She wanted me to write from some place closer to where dreams come from – something deeper and more inchoate, some raw edge. She wanted what she had called, in my memory, a “real poem.”</p><p> I read various of her poems in that class, but the book of hers that has most stayed with me, and mattered most to me, came out later, in 2014: “ <a href="https://www.amazon.com/Faithful-Virtuous-Night-Louise-Gl%C3%BCck/dp/0374535779">Faithful and Virtuous Night</a> .” I associate this book, in particular, with the dream-like quality of many of the poems — the way they shift underneath you as you read, full of quiet mystery and surprise. Here&#39;s one of my favorites:</p><blockquote><p> <i>A Foreshortened Journey</i></p><p> I found the stairs somewhat more difficult than I had expected and so I sat down, so to speak, in the middle of the journey. Because there was a large window opposite the railing, I was able to entertain myself with the little dramas and comedies of the street outside, though no one I knew passed by, no one, certainly, who could have assisted me. Nor were the stairs themselves in use, as far as I could see. You must get up, my lad, I told myself. Since this seemed suddenly impossible, I did the next best thing: I prepared to sleep, my head and arm on the stair above, my body crouched below. Sometime after this, a little girl appeared on the top of the staircase, holding the hand of an elderly woman. Grandmother, cried the little girl, there is a dead man on the staircase! We must let him sleep, said the grandmother. We must walk quietly by. He is at that point in life at which neither returning to the beginning nor advancing to the end seem bearable; therefore, he has decided to stop, here, in the midst of things, though this makes him an obstacle to others, such as ourselves. But we must not give up hope; in my own life, she continued, there was such a time, though that was long ago. And here, she let her granddaughter walk in front of her so they could pass me without disturbing me.</p><p> I would have liked to hear the whole of her story, since she seemed, as she passed by, a vigorous woman, ready to take pleasure in life, and at the same time forthright, without illusions. But soon their voices faded into whispers, or they were far away. Will we see him when we return, the child murmured. He will be long gone by then, said her grandmother, he will have finished climbing up or down, as the case may be. Then I will say goodbye now, said the little girl. And she knelt below me, chanting a prayer I recognized as the Hebrew prayer for the dead. Sir, she whispered, my grandmother tells me you are not dead, but I thought perhaps this would soothe you in your terrors, and I will not be here to sing it at the right time.</p><p> When you hear this again, she said, perhaps the words will be less intimidating, if you remember how you first heard them, in the voice of a little girl.</p></blockquote><p> Why do I love this poem? I wish I could say more directly. It feels like its touching, in me, that raw edge. Something about the journey, the unexplained staircase, preparing to sleep, the grandmother&#39;s understanding. “In my own life, she continued, there was such a time.” And the little girl&#39;s simple depth. “Then I will say goodbye now.”</p><p> The little girl, especially, has stayed with me, as have a few other similarly dream-like figures – the conductor in “ <a href="https://www.poetryfoundation.org/poetrymagazine/poems/56626/aboriginal-landscape">Aboriginal Landscape</a> ,” the old woman in “ <a href="https://www.threepennyreview.com/a-sharply-worded-silence/">A Sharply Worded Silence</a> ,” the concierge in “ <a href="https://www.theparisreview.org/poetry/7214/the-denial-of-death-louise-gluck">The Denial of Death</a> .” The backdrop of these poems is often ethereal and unstable. It seems one way, then smoothly un-seems. “Right now you are a child holding hands with a fortune-teller,” Glück writes in “ <a href="https://connectere.wordpress.com/2016/02/18/theory-of-memory-by-louise-gluck/">Theory of Memory</a> .” “All the rest is hypothesis and dream.”</p><p> See, in “Aboriginal Landscape,” the way the speaker&#39;s relationship to the cemetery evolves.</p><blockquote><p> The cemetery was silent. Wind blew through the trees;<br> I could hear, very faintly, sounds of weeping several rows away,<br> and beyond that, a dog wailing.<br><br> At length these sounds abated. It crossed my mind<br> I had no memory of   being driven here,<br> to what now seemed a cemetery, though it could have been<br> a cemetery in my mind only; perhaps it was a park, or if not a park,<br> a garden or bower, perfumed, I now realized, with the scent of roses —<br> douceur de vivre filling the air, the sweetness of living,<br> as the saying goes. At some point,<br><br> it occurred to me I was alone.<br> Where had the others gone,<br> my cousins and sister, Caitlin and Abigail?<br><br> By now the light was fading. Where was the car<br> waiting to take us home?</p></blockquote><p> And yet the figures the speaker encounters have some kind of elusive understanding, like the grandmother&#39;s on the staircase. Here, for example, is the conductor:</p><blockquote><p> Finally, in the distance, I made out a small train,<br> stopped, it seemed, behind some foliage, the conductor<br> lingering against a doorframe, smoking a cigarette.<br><br> Do not forget me, I cried, running now<br> over many plots, many mothers and fathers <i>—</i><br><br> Do not forget me, I cried, when at last I reached him.<br> Madam, he said, pointing to the tracks,<br> surely you realize this is the end, the tracks do not go further.<br> His words were harsh, and yet his eyes were kind;<br> this encouraged me to press my case harder.<br> But they go back, I said, and I remarked<br> their sturdiness, as though they had many such returns ahead of them.<br><br> You know, he said, our work is difficult: we confront<br> much sorrow and disappointment.<br> He gazed at me with increasing frankness.<br> I was like you once, he added, in love with turbulence.<br><br> Now I spoke as to an old friend:<br> What of  you, I said, since he was free to leave,<br> have you no wish to go home,<br> to see the city again?<br><br> This is my home, he said.<br> The city — the city is where I disappear.</p></blockquote><p> And here&#39;s the old woman in “A Sharply Worded Silence”:</p><blockquote><p> When I was young, she said, I liked walking the garden path at twilight<br> and if the path was long enough I would see the moon rise.<br> That was for me the great pleasure: not sex, not food, not worldly amusement.<br> I preferred the moon&#39;s rising, and sometimes I would hear,<br> at the same moment, the sublime notes of the final ensemble<br> of <i>The Marriage of Figaro</i> . Where did the music come from?<br> I never knew.<br><br> Because it is the nature of garden paths<br> to be circular, each night, after my wanderings,<br> I would find myself at my front door, staring at it,<br> barely able to make out, in darkness, the glittering knob.<br><br> It was, she said, a great discovery, albeit my real life.</p></blockquote><p> “My real life.” How do you discover your real life? How do you write a real poem? Part of it, for Glück, is gazing, and speaking, with frankness. Forthright, and without illusions.</p><p> People call her poetry “austere” and “terse.” She has, one senses, no time for bullshit. From “ <a href="https://poems.com/poem/october-section-i/">October</a> ”:</p><blockquote><p> It is true there is not enough beauty in the world.<br> It is also true that I am not competent to restore it.<br> Neither is there candor, and here I may be of some use.</p></blockquote><p> But what she strips away in pursuit of candor leaves something luminous. She is direct, but not dry. Indeed, in her hands, simple words take on strange power. “ <a href="https://www.poetryfoundation.org/poems/49606/early-december-in-croton-on-hudson">I want you</a> .” “ <a href="http://caladesishore.com/dpc/Poets/LouiseGluck/PurpleBathingSuit.html">You are all that is wrong with my life and I need you and I claim you</a> .” “ <a href="https://voetica.com/poem/9608">It&#39;s not the earth I&#39;ll miss, it&#39;s you I&#39;ll miss</a> .”</p><p> Here&#39;s another of my favorites:</p><blockquote><p> <i>The Wild Iris</i></p><p> At the end of my suffering<br> there was a door.<br><br> Hear me out: that which you call death<br> I remember.<br><br> Overhead, noises, branches of the pine shifting.<br> Then nothing. The weak sun<br> flickered over the dry surface.<br><br> It is terrible to survive<br> as consciousness<br> buried in the dark earth.<br><br> Then it was over: that which you fear, being<br> a soul and unable<br> to speak, ending abruptly, the stiff earth<br> bending a little. And what I took to be<br> birds darting in low shrubs.<br><br> You who do not remember<br> passage from the other world<br> I tell you I could speak again: whatever<br> returns from oblivion returns<br> to find a voice:<br><br> from the center of my life came<br> a great fountain, deep blue<br> shadows on azure seawater.</p></blockquote><p> I&#39;ve returned, especially, to that line in the last stanza: “from the center of my life came a great fountain.” And to that seawater. Is that the great discovery? The poem speaks of a door at the end of suffering. Was there, somewhere, a glittering knob?</p><p> The other Glück poem that has really stayed with me is <a href="https://www.poetryfoundation.org/poems/49759/vespers-in-your-extended-absence-you-permit-me">this one</a> , from a series where she sometimes speaks to God from her garden.</p><blockquote><p> <i>Vespers</i></p><p> In your extended absence, you permit me<br> use of earth, anticipating<br> some return on investment. I must report<br> failure in my assignment, principally<br> regarding the tomato plants.<br> I think I should not be encouraged to grow<br> tomatoes. Or, if I am, you should withhold<br> the heavy rains, the cold nights that come<br> so often here, while other regions get<br> twelve weeks of summer. All this<br> belongs to you: on the other hand,<br> I planted the seeds, I watched the first shoots<br> like wings tearing the soil, and it was my heart<br> broken by the blight, the black spot so quickly<br> multiplying in the rows. I doubt<br> you have a heart, in our understanding of<br> that term. You who do not discriminate<br> between the dead and the living, who are, in consequence,<br> immune to foreshadowing, you may not know<br> how much terror we bear, the spotted leaf,<br> the red leaves of the maple falling<br> even in August, in early darkness: I am responsible<br> for these vines.</p></blockquote><p> It feels like there&#39;s a building pain in this poem: the heavy rains, the cold night, and then that breaking blight, and the black spots spreading. And then that last line, that taking-it-on. “I am responsible for these vines.” She loves the earth, and it causes her such pain. See, also, her 2004 “ <a href="https://poems.com/poem/october-section-i/">October</a> ”:</p><blockquote><p> Is it winter again, is it cold again,<br> didn&#39;t Frank just slip on the ice,<br> didn&#39;t he heal, weren&#39;t the spring seeds planted…<br><br> didn&#39;t we plant the seeds,<br> weren&#39;t we necessary to the earth,<br><br> the vines, were they harvested?</p></blockquote><p> And see, too, her warnings in “The Sensual World”:</p><blockquote><p> I caution you as I was never cautioned:<br><br> you will never let go, you will never be satiated.<br> You will be damaged and scarred, you will continue to hunger.<br><br> Your body will age, you will continue to need.<br> You will want the earth, then more of the earth–<br><br> Sublime, indifferent, it is present, it will not respond.<br> It is encompassing, it will not minister.<br><br> Meaning, it will feed you, it will ravish you,<br> it will not keep you alive.</p></blockquote><p> She knew well that she was going to die. “My body,” she writes in “ <a href="https://griffinpoetryprize.com/poem/crossroads-gluck/">Crossroads</a> ,” “now that we will not be traveling together much longer, I begin to feel a new tenderness toward you, very raw and unfamiliar, like what I remember of love when I was young…” And loss is everywhere in her poetry: See, eg, in “ <a href="https://www.theparisreview.org/poetry/7066/primavera-louise-gluck">Primavera</a> ”: “Alas, very soon everything will disappear: the birdcalls, the delicate blossoms. In the end, even the earth itself will follow the artist&#39;s name into oblivion.”</p><p> The artist, in that poem, leaves no signature – just a drawing of the sun in the dirt, and a “mood of celebration.” And in her <a href="https://www.nobelprize.org/prizes/literature/2020/gluck/lecture/">acceptance speech for the Nobel prize</a> , recorded less than six months before her death from cancer, Glück seems attracted to a type of anonymity – or at least, to the intimacy of encountering her readers in private, rather than in the public sphere. (Perhaps: in a fortune-teller&#39;s tent, holding hands, with all the rest as mere hypothesis.) She quotes Dickinson as an example of this intimacy: “I&#39;m Nobody! Who are you? Are you – Nobody – too? Then there&#39;s a pair of us! Don&#39;t tell!” Glück admits to wanting readers. But she wants to reach them “singly, one by one.” “You hear this voice?” she writes in “ <a href="https://poems.com/poem/october-section-i/">October</a> .” “This is my mind&#39;s voice.”</p><p> Specifically, though, she wanted her readers to participate, somehow, in her poetry. When Eliot says “let us go then, you and I,” Glück thinks he is <i>asking</i> something of the reader. She is, too.</p><p> Asking what? Well: many things, presumably. And the individual poems are the best place to look. In general, though, I think she asks for candor – and more, for some sort of intensity and directness of spirit. Perhaps it is a stretch to say that Glück&#39;s is “spiritual” poetry. But she appears, on the page, as fiercely alive and attuned, in a world simultaneously dreamlike and raw, mythical and mundane.</p><p> How do you honor someone who has lived the way Glück, in her poetry, appears to live? By meeting them where they seek to stand. By searching out the same real life they sought – that greatest discovery. Here&#39;s to the fountain she found.</p><br/><br/><a href="https://www.lesswrong.com/posts/gtxrEJoZ4NK4sXqTN/in-memory-of-louise-glueck#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/gtxrEJoZ4NK4sXqTN/in-memory-of-louise-glueck<guid ispermalink="false"> gtxrEJoZ4NK4sXqTN</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Sun, 15 Oct 2023 02:59:43 GMT</pubDate> </item><item><title><![CDATA[Book Review: Invisible China]]></title><description><![CDATA[Published on October 14, 2023 9:51 PM GMT<br/><br/><p> This is a book review of <a href="https://www.goodreads.com/book/show/51941583-invisible-china"><em>Invisible China</em></a> . The book covers the rural-urban divide in China and its implications for China&#39;s continued economic growth. I think it&#39;s worth the read.</p><hr><p> Pretty good. Made me think, and Rozelle&#39;s unique perspective (economist who&#39;s spent 30+ years on the ground) adds an authentic flavor to the book.</p><p> He claims that the existential threat to China&#39;s potential future growth and success is a lack of human capital: specifically, that systemic factors hinder rural Chinese children&#39;s ability to participate effectively in the service-based, advanced economy of the 21st century, and that fixing this issue is imperative so that China does not fall into the middle income trap.</p><blockquote><p> In a 2004 article in Foreign Affairs, political scientist Geoffrey Garrett shared a startling observation. He looked at the history of recent economic development and noticed that while rich countries were continuing to do well and many poor countries were achieving strong growth rates, the countries in the middle of the global income spectrum were growing more slowly and less successfully than anyone else.</p></blockquote><blockquote><p> In a report that made ripples throughout the development world, economists at the World Bank demonstrated the full extent of the problem. The report showed that out of 101 countries that were middle income in 1960, only thirteen had made it to high-income status by 2008. The rest remained stuck or even ended the fifty years poorer than before.</p></blockquote><p> The middle income trap is the stagnation developing countries face when their average citizen reaches a &quot;middle income.&quot; An easy way for developing countries to rapidly grow their economies is to accept industrialization and foreign direct investment, shifting to a manufacturing economy reminiscent of Western nations in the 1890s. However, Rozelle makes the argument that to then shift from a middle income to high income country requires an educated populace, and the middle-income countries which have failed to continue their economic growth did not appropriately invest in the education of their citizenry.</p><blockquote><p> But with a bit of historical data, another trend emerges that is far more relevant to the question at hand: the very small number of countries that have made it out of middle-income status in recent decades—the graduates—all have very high levels of high school education. Even more surprising, they&#39;ve had those high levels for decades. In particular, back when they were still middle income, the graduates (places like South Korea, Taiwan, and Ireland) all had high school attainment rates comparable to those of the rich countries.</p></blockquote><p> China is not appropriately investing in the necessary amounts of education to avoid the middle income trap. While they may have the necessary innovation, all the Baidus, Tencents, and Bytedances in the world wouldn&#39;t fix the systemic issue of having nearly 70% of its population without a high school education unable to participate in the high-skilled, high-paid industries that characterize high-income countries.</p><p> Rural Chinese mainly work low-skilled manufacturing jobs, or jobs which don&#39;t require a high school education. This was fine, until rising wages in mainland China started pushing manufacturing jobs overseas, leaving hundreds of thousands, if not millions of workers unemployed. Throughout the book, Rozelle includes telling anecdotes of workers who lost their job and couldn&#39;t get a new one because they didn&#39;t have the required skillset.</p><blockquote><p> ...We fell into conversation with one man in particular. Mr. Wang was about thirty-five and had recently been laid off from his job of eighteen years as an electrician.</p></blockquote><blockquote><p> As we watched, Mr. Wang gamely sidled up to the first booth, which represented a bank. The man running the booth, a human resources staff member, shook his hand and asked him to read a short page of text and comment on what he understood. Mr. Wang stared hard at the piece of paper, trying to force the characters into an order he could understand. He knew all the words and could read them aloud, but many of the terms were over his head. He kept getting confused by the logic of the sentences. For several minutes he stared at it, trying to make sense of what he was seeing. At first the man running the booth was patient and seemed sympathetic, but gradually the bank representative lost interest, turned back to his desk, and started looking around for workers who might be a better bet. After a few more minutes, Mr. Wang lowered his head with a sigh: “I&#39;m sorry, I just can&#39;t make sense of it.”</p></blockquote><p> As it turns out, simply increasing access and/or mandating a high school education wouldn&#39;t be enough. The rural/urban divide in China runs deep. The opportunity &amp; outcome differential comes not only from unequal access to education and other outgrowths of the <em>hukou</em> policy, but also from deep-seated systemic differences. &#39;Vocational&#39; schooling is a joke:</p><blockquote><p> Tao&#39;s middle school teacher suggested he check out the new vocational high school that had recently opened across town... When he arrived on campus a week later, he found himself in an unfamiliar world. Whereas his middle school had been orderly and regimented, here chaos reigned. The older students were tough-looking, with tight jeans, black pleather jackets, and spiked hair. As he walked to class on his first day, there were no adults in sight. He passed groups of kids hanging out in the courtyard, smoking cigarettes and laughing.</p></blockquote><p> Children who grow up in rural China suffer from three &quot;invisible epidemics&quot;, as Rozelle calls them: anemia, uncorrected myopia, and parasitic intestinal worms. Iron-deficiency anemia has been linked to dramatic decreases in IQ, myopia (for obvious reasons) impedes learning ability, and worms almost literally sap the life force from their hosts. Luckily, cheap and safe interventions can fix these issues. Iron supplements, subsidized glasses, and cheap, common medicine could easily bring the health of a Chinese kid in the country to within striking distance of one in Beijing.</p><p> Perhaps a harder problem to fix is that of crucial stimulation of children during their formative developmental years. Rural parenting strategies are unequipped to give a child sufficient intellectual stimulation.</p><blockquote><p> In rural China, babies are systematically missing out on the mental stimulation they need. When we asked rural families if they ever talked to their babies, we were met with blank looks or bemused smiles. “Why would I talk to my baby?” one young mother responded, giggling into her hand. “She can&#39;t talk back!”</p></blockquote><p> Yet, this leads to delayed infant development, and the permanent stunting of a child&#39;s ability relative to their peers. Rural chinese babies score horribly on the Bayley test, while urban Chinese children score higher than average. This seems to be much of the issue.</p><p> For the sake of China and the world, Rozelle hopes that China will be able to fix its human capital crisis. He is somewhat bullish: the Chinese government is beginning to recognize that this is an issue, and some sane policies have been implemented. But he wants more to be done. Maybe China can pull off an economic miracle again, but this seems to be a major roadblock.</p><br/><br/><a href="https://www.lesswrong.com/posts/ppwxCMWC3BE7b4SPa/book-review-invisible-china#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ppwxCMWC3BE7b4SPa/book-review-invisible-china<guid ispermalink="false"> ppwxCMWC3BE7b4SPa</guid><dc:creator><![CDATA[Yudhister Kumar]]></dc:creator><pubDate> Sat, 14 Oct 2023 21:51:10 GMT</pubDate></item></channel></rss>