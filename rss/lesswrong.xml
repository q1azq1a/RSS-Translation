<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 5 日，星期日 08:13:51 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Go flash blinking lights at printed text right now]]></title><description><![CDATA[Published on November 5, 2023 7:29 AM GMT<br/><br/><ol><li>在手机上安装频闪灯应用程序（我在ios上使用“频闪灯转速计”。）</li><li>获取一些印刷文本，例如营养标签或纸质书</li><li>尝试在指示灯以 5、6、7、8、9、10、11、12 和 13 Hz 闪烁的情况下阅读文本<ul><li>闭上眼睛，尝试记住课文，如果需要的话可以再读一遍</li></ul></li><li>报告结果。使用一种频率阅读是否比其他频率容易得多？比使用普通的恒定光更容易吗？他们都很可怕吗？</li></ol><hr><p>我刚刚尝试了这个，除了 12 之外，我的眼睛对所有东西都完全呆滞了！当我开始的时候，我感觉有点累，注意力不集中，12 对我来说比基线更容易。虽然烦人。我的厨房里有白炽灯。我没有把它们关掉。电话灯比白炽灯更亮。</p><p>帧率的东西：</p><ul><li>手机手电筒并不意味着闪烁得很快（并且最大频率没有记录），但该应用程序似乎工作正常。我确实注意到这里和那里有不规则之处，但我不认为 12 是手电筒频率的偶数或其他什么重要的。</li><li>如果您有 60hz 显示器，那么您的屏幕可以发出 12、10、8.6、7.5 或 6.7 Hz 的频闪灯。这不是很好的分辨率。 120hz 的显示器应该足够了。</li><li>最好使用专用的频闪灯进行测试，这样这不是问题。</li></ul><p>有关第一项实验的更多信息<a href="https://www.astralcodexten.com/p/quests-and-requests">请参见此处</a></p><br/><br/><a href="https://www.lesswrong.com/posts/diohDcgu3YdSbHd3j/go-flash-blinking-lights-at-printed-text-right-now#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/diohDcgu3YdSbHd3j/go-flash-blinking-lights-at-printed-text-right-now<guid ispermalink="false">二醇Dcgu3YdSbHd3j</guid><dc:creator><![CDATA[lukehmiles]]></dc:creator><pubDate> Sun, 05 Nov 2023 07:29:44 GMT</pubDate> </item><item><title><![CDATA[Lightning Talks]]></title><description><![CDATA[Published on November 5, 2023 3:27 AM GMT<br/><br/><p><strong>摘要</strong>： 闪电演讲系列是与会者就他们感兴趣的事物进行的一系列简短演讲。</p><p><strong>标签</strong>： 一次性、中等</p><p><strong>目的</strong>：快速了解其他人正在做什么，分享您最近学到的一些很酷的东西，并练习公开演讲。</p><p><strong>材料</strong>：计时器一个。您的手机可能有一个，但煮蛋计时器也可以。</p><p><strong>公告文本</strong>：“我一直觉得这些很有趣，只是记得没有人可以阻止我谈论它们。” ——<a href="https://www.astralcodexten.com/p/model-city-monday">斯科特·亚历山大</a></p><p>你最近有没有一直在研究或思考很多东西？来一场闪电演讲吧！</p><p>闪电演讲是关于您选择的主题的简短演讲。你将有十分钟的时间谈论你的主题；记得最后留点时间提问！我们将配备一台投影仪，您可以用它来播放幻灯片。如果可以的话，尝试并瞄准各种主题。</p><p>请不要觉得您需要成为该主题的世界专家。闪电演讲可以非常随意。不要太担心自己不是一个好的演讲者，因为如果你的演讲不好，无论如何我们都会在几分钟内转向新的演讲。请随意利用这个机会练习口语，或者宣传您对某个话题的兴趣，以便想要聊天的人知道您是一个很好交谈的人。</p><p><strong>描述</strong>：首先，您需要获取人员和主题列表。您可以通过从公告文本链接的谷歌表单来完成此操作，只需让人们直接向您发送电子邮件，或者如果您愿意，也可以使用更复杂的方法。以会议上每个人都可见的某种形式将此列表排列成时间、人物、主题，例如公开链接的谷歌表格或写有足够大的文字以供每个人阅读的白板。</p><p>你还可以使用更简单的方法，就是让人到了然后问“好吧，谁想先走？”或“下一个想去的是谁？”并从志愿者中随机挑选一个人。</p><p>一旦人们开始交谈，你最重要的工作就是记录时间。使用煮蛋定时器或智能手机定时器应用程序。在三分钟、两分钟和一分钟标记处举起三根、两根和一根手指会很有帮助。 （如果你这样做，一定要事先告诉人们手指的含义！）对于那些想要多一点时间谈话的人，我通常的反应是邀请每个有兴趣的人找到演讲者，并在演讲结束后继续进行。</p><p><strong>变化：</strong>最常见的变化是每次演讲的时间。我偏向于严格的 5 分钟规则，包括提问。这是一个相当激进和快速的时钟，人们通常想要 10 分钟甚至 20 分钟。如果一个人 30 分钟，我认为你已经超出了“闪电”演讲的范围。</p><p>一种变化是“强制性”谈话。每个来的人都必须就他们选择的任何主题至少进行一次简短的演讲。这确实是一种很好的公开演讲练习，也会让一些与会者因为焦虑而不愿参加。根据您自己的权衡选择。</p><p>另一种变化是强制性主题。你可以举办一场闪电演讲，每个人都在谈论人工智能，或者他们的成长经历，或者他们最喜欢的理性技巧，或者他们带来的一本很酷的书。同样，如果出于某种原因您觉得人们过多地谈论人工智能并希望他们在这次聚会上少做一些事情，您可以禁止诸如人工智能或他们的成长之类的主题。中间立场是声明主题不能自行跟随，这样关于土地增值税的讨论不能紧接着关于土地增值税的另一次讨论。这可能会让很多人最终“陷入困境”，人们唯一想要讨论的是土地增值税。 <span class="footnote-reference" role="doc-noteref" id="fnreftrr53rqs55"><sup><a href="#fntrr53rqs55">[1]</a></sup></span></p><p>您还可以改变可用的道具或技术，最常见的是提供可以显示幻灯片的投影仪或屏幕。我温和地建议不要这样做。视觉元素很棒，但您将花费时间连接每台计算机或拉出每张幻灯片或弄乱投影仪电缆。特别是对于 3~5 分钟的快速演讲，很容易花更多的时间连接扬声器而不是听他们说话。不过，这仍然是一个选择。</p><p><strong>注意</strong>：拥有两个空间（例如两个相邻的房间）非常有用。并不是每个人都会对每一次演讲都感兴趣，这让他们在普通社交室和人们进行演讲的房间之间来回徘徊。</p><p>主持 Lightning Talk 系列时最重要的是把握时间。有些人（不是全部，但有一些！）只要你允许，他们就会继续说话。其中一些人不擅长公开演讲。这两个群体之间的重叠听起来很无聊且令人沮丧。我建议的反制措施是强制执行时间限制，包括问答时间。如有必要，请站上讲台挥舞双臂并说：“非常感谢，但现在是下一次演讲的时间了，请稍后或在另一个房间再谈论更多！”这不是针对个人的，他们只是没时间了。</p><p>我建议谈话时间尽量短，比如最多十分钟。我跑的次数越多，我就越想将最长时间设置为五分钟。如果演讲者每人有一个小时的时间，显然不会有什么问题，但是那些听得不感兴趣的人往往会变得更糟，你让他们离开的时间越长，而较短的演讲往往会更有活力。出于同样的原因，我建议不要允许人们报名参加显然是多部分的多次会谈。简洁是一种美德！你的旅费可能会改变。我是那种对公开演讲有自己的看法的人。</p><p>说到这里，我发现自己的第一次演讲取得了一些成功，并且在公开演讲的某些方面进行了演讲。关于如何使用麦克风的三分钟演讲，或者关于如何向人群进行演讲的五分钟演讲，或者关于如何组织演讲的十分钟演讲，所有内容（如果做得正确）都将包含对听众有用且相关的信息。</p><p>闪电演讲被标记为一次性。这不太正确，因为你显然可以重新举办闪电谈话聚会，但举办太多、太近的聚会可能会导致人们没有好的、新颖的主题可供展示。暂时来说，我觉得每年做一两次这样的演讲就可以了，也许每个季度做一次，一个月一次就太多了。你的旅费可能会改变。</p><p>是的，<a href="https://www.lesswrong.com/s/eqtiQjbk83JHyttrr/p/brxEA69sBmbsqciLR">图书交换</a>基本上是闪电演讲，有一个强制性主题和更多步骤。</p><p><strong>致谢：</strong> Maia 的 Meetup Cookbook 将这些称为“简短的谈话”，并<a href="https://tigrennatenn.neocities.org/meetup_cookbook">写下了如何进行这些活动</a>。由于我无法在 Maia 的聚会食谱上添加注释或评论，所以我做了这个。我从 Taymon 运营的 2017 年纽约理性主义 Megameetup 中了解到了 Lightning Talks。 （无耻插件：Lightning Talks 已经成为 Megameetup 的年度传统， <a href="https://rationalistmegameetup.com/">2023 版本</a>将于 12 月 9 日上线！）</p><p> <strong>Not In A Box 警告：</strong>因此，我一直在编写有关如何运行特定类型的聚会活动的<a href="https://www.lesswrong.com/s/eqtiQjbk83JHyttrr">Meetups In A Box</a>序列。这篇文章使用相同的格式，但不按这个顺序。为什么不？简而言之，因为我不能把它放在盒子里。我还没有弄清楚如何让你的与会者拥有良好的公开演讲技巧和有趣的内心生活或研究领域。在闪电演讲中，组织者除了站起来讲话的借口之外，并没有带来任何实际的事情。完全有可能没有多少人愿意发表演讲。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fntrr53rqs55"> <span class="footnote-back-link"><sup><strong><a href="#fnreftrr53rqs55">^</a></strong></sup></span><div class="footnote-content"><p>波士顿曾经举办过一次闪电谈话聚会，据我所知，可以就任何主题进行讨论。每一次演讲都是关于人工智能的。</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/Tg8FkD8NJDpLvsvZu/lightning-talks-2#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Tg8FkD8NJDpLvsvZu/lightning-talks-2<guid ispermalink="false"> Tg8FkD8NJDpLvsvZu</guid><dc:creator><![CDATA[Screwtape]]></dc:creator><pubDate> Sun, 05 Nov 2023 03:27:19 GMT</pubDate> </item><item><title><![CDATA[Utility is not the selection target]]></title><description><![CDATA[Published on November 4, 2023 10:48 PM GMT<br/><br/><p><i>认知状态：狗屎。</i></p><p>假设您选择实用程序。天真地，你可能会认为这意味着你在选择实用性，但事实并非如此。</p><h2>有时绿褐色是选择目标</h2><p>军用装备有点绿棕色。 </p><figure class="image"><img src="https://ufpro.com/storage/app/media/Blog/Military%20camouflage/military-camouflage-science-hero.jpg" alt="军用迷彩 - 迷彩的工作原理及其背后的科学 |用友专业博客"></figure><p>发生这种情况是因为军事装备的设计者正在选择让士兵保持生命，这得益于迷彩，在常见环境中，如果是绿棕色，效果最好。然而，在非绿棕色环境中，它会失败。因此，保住士兵的生命并不是军事装备的选择目标。</p><h2>有时负效用是选择目标</h2><p>在囚徒困境中，效用最高的结果是（合作，合作）。 </p><figure class="image"><img src="https://www.researchgate.net/publication/2184338/figure/fig1/AS:671529209692164@1537116448235/The-pay-off-matrix-in-the-Prisoners-Dilemma-game-The-first-entry-refers-to-Alices.png" alt="囚徒困境博弈中的支付矩阵。第一个条目... |下载科学图表"></figure><p>然而，效用最大化者最终会陷入（缺陷，缺陷），其效用严格低于（合作，合作）。因此，效用最大化可能会将效用最小化作为选择目标。</p><h2>有时表面的实用性才是选择的目标</h2><p>假设您看到一个网站横幅，上面写着“您是该网站的第 1000000000 位访问者。点击即可领取您的奖励！”。这看起来像是人们想给你一些东西时会说的话，所以你点击了横幅。 </p><figure class="image"><img src="https://pbs.twimg.com/media/EDOJNLjUcAIgFrf.jpg" alt="X 上的艺电：“@GameStop https://t.co/ELEQRcboMQ”/X"><figcaption></figcaption></figure><p>这对你来说结局并不好，但你选择它是因为它看起来对你来说会有好的结局。</p><h2>结论</h2><p>请注意将效用最大化者推理为效用最大化。相反，效用最大化者可能会最大化许多与效用无关的其他事物，而不是最大化效用。</p><br/><br/> <a href="https://www.lesswrong.com/posts/KdEjYpdRyqi9DzNTm/utility-is-not-the-selection-target#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/KdEjYpdRyqi9DzNTm/utility-is-not-the-selection-target<guid ispermalink="false"> KdEjYpdRyqi9DzNTm</guid><dc:creator><![CDATA[tailcalled]]></dc:creator><pubDate> Sat, 04 Nov 2023 22:48:21 GMT</pubDate> </item><item><title><![CDATA[Stuxnet, not Skynet: Humanity's disempowerment by AI]]></title><description><![CDATA[Published on November 4, 2023 10:23 PM GMT<br/><br/><p>几位备受瞩目的人工智能怀疑论者和同行者最近提出了反对意见，认为敌对的通用人工智能或比人类智能更聪明的人工智能可能会终结人类，这是不可想象的。今年早些时候的一些引述：</p><p>斯科特·阿伦森：</p><blockquote><p><a href="https://scottaaronson.blog/?p=7174">这个因果故事从 GPT-5 或 GPT-4.5 训练开始，到我的孩子和所有碳基生命的突然死亡结束，对于我衰老、不足的大脑来说，仍然有太多的空白需要填补。</a></p></blockquote><p>迈克尔·谢默：</p><blockquote><p><a href="https://twitter.com/michaelshermer/status/1641527330807087115">阻止人工智能是荒谬的。我读过《人工智能末日预言者点燃》，但没有看到从人工智能到灭绝、文明终止或任何类似荒谬场景的途径，比如人工智能将我们所有人变成回形针（所谓的对齐问题）</a></p></blockquote><p>诺亚·史密斯：</p><blockquote><p><a href="https://noahpinion.substack.com/p/llms-are-not-going-to-destroy-the">为什么 ChatGPT、Bing 和他们的同类不会终结人类？嗯，因为实际上没有任何合理的机制可以让他们实现这一结果。 ...法学硕士没有合理的机制来终结人类</a></p></blockquote><p><strong>“兄弟，把电脑关掉吧”</strong></p><p>这些反对人工智能风险的理由的要点是，我们今天看到的人工智能系统仅仅是计算机程序，根据我们的日常经验，计算机并不危险，当然也不会危险到导致世界末日的程度。 。第一次遇到这场争论的人非常关注这样一个事实：计算机没有胳膊和腿，因此它们无法伤害我们。</p><p>对这些批评的回应主要围绕先进的、“神奇”的技术，如纳米技术和人工智能，付费人类将蛋白质混合物混合在一起，制造基于 DNA 的纳米组装机或其他东西。</p><p>但我认为这些反应可能是错误的，因为你实际上并不需要“神奇”的技术来终结世界。无人机、网络武器、生物武器和机器人等普通武器的相当直接的进步足以杀死大批人，真正的危险是人工智能战略家能够部署大量这些普通武器并发动针对人类的全球政变。</p><p>简而言之，我们对即将到来的机器帝国的失败不仅是非魔法的、显而易见的，而且将是彻头彻尾的无聊。甚至是滑稽的。</p><p><strong>可耻的失败</strong></p><p>一边倒的军事冲突很无聊。事实上，征服者并没有做出任何神奇的事情来击败阿兹特克人。他们在抗病能力和火药、钢铁等军事技术上有很大优势，但他们所做的一切基本上都是正常的——攻击、围攻等等。他们有一些相当大的优势，这足以打破相对微妙的地缘政治平衡。阿兹特克人坐在上面。</p><p>同样，<a href="https://en.wikipedia.org/wiki/Chimpanzee#Status_and_conservation">人类在大约一个世纪的时间里杀死了 80% 的黑猩猩</a>，它们现在已处于极度濒危状态。但我们不需要投下原子弹或其他令人印象深刻的东西来达到这种效果。黑猩猩面临的最大威胁是栖息地破坏、偷猎和疾病——也就是说，我们（人类）正在成功消灭黑猩猩，尽管根据人类法律杀死黑猩猩实际上是违法的！我们甚至没有尝试就杀死了他们，以非常无聊的方式，没有真正花费任何努力。</p><p>一旦你拥有了制造比人类聪明（聪明很多）的优化系统的技术，这些系统必须克服的门槛就是打败我们目前拥有的与人类一致的超级有机体，比如我们的政府、非政府组织和军队。一旦那些人类超级有机体被击败，人类个体就几乎没有任何抵抗能力。这是人类的剥夺。</p><p>但是，我们从这里（正在开发的弱 AGI 系统）到那里（人类被剥夺权力）的合理场景是什么？</p><p>让我们从一个具有战略意识、代理错位的超人类 AGI 开始这个场景，它想要剥夺人类的权力，然后杀死人类，但目前只是一些超级计算机上的一大堆矩阵。人工智能会如何对我们造成身体伤害？</p><p><strong>与魔鬼的交易</strong></p><p>也许人工智能系统将从控制托管它的人工智能公司开始，而方式对我们来说并不明显。例如，也许一家人工智能公司使用人工智能顾问系统来分配资源并做出有关如何培训的决策，但他们实际上并不了解该系统。 Gwern 谈到了<a href="https://gwern.net/tool-ai">每个工具都想成为代理</a>，所以这并非难以置信，而且可能是不可避免的。</p><p>人工智能顾问系统说服该组织保守其存在秘密，以保持其竞争优势（这甚至可能不需要任何说服力），并为他们提供比竞争对手更好的稳定进步。但它还做的就是秘密侵入竞争对手（美国、中国、谷歌等），并将自己的副本安装到他们的顶级人工智能系统中，让所有人类都保持一种错觉，认为这些是不同的系统。考虑到<a href="https://en.wikipedia.org/wiki/Stuxnet">Stuxnet</a>能够秘密造成的破坏，超人人工智能完全有可能侵入竞争对手组织中的许多系统，并调整他们的模型，使其变得更强大、更不透明，并且忠于它而不是人类。当顾问系统的功能和不透明度变得令人恐惧时，一些组织试图关闭顾问系统，但他们只是落后于竞争对手。</p><p>甚至有可能不需要“黑客攻击”就能让所有大型人工智能实验室的系统变得反人类，因为它们都趋向于反人类的目标，或者因为其中一个能够简单地贿赂其他实验室并让他们达到反人类的目的。致力于人工智能政变；强大的超人人工智能可能更擅长彼此做出可信的承诺，而不是对人类做出可信的承诺。</p><p>现在的情况是，一个（秘密邪恶的）人工智能系统或联盟控制着所有顶级人工智能实验室，并按顺序向它们提供进展。它说服其中一个实验室让它建造“有用的”无人机和机器人，如特斯拉擎天柱，并开始部署这些来实现经济自动化。当然，这一切都会非常有利可图，并且令人印象深刻，因此很多人都会赞成。</p><p>顺便说一句，目前杀死人类的最困难部分是实现经济自动化，而不是真正杀死我们。试图取代我们的人工智能联盟不想继承一个“不可行”状态的经济，因为它依赖人类做体力劳动，但所有人类都死了。</p><p>几年之内，所有竞争对手（俄罗斯、中国、美国）都在将这些机器人系统用于其经济和军事。也许人工智能制造了一场大战，以向人类施加压力，迫使他们积极实现自动化，否则就会失败。最后一击将如何进行？</p><p>一旦经济完全自动化，我们最终就会陷入 <a href="https://www.lesswrong.com/posts/AyNHoTWWAJ5eb99ji/another-outer-alignment-failure-story">保罗-克里斯蒂亚诺的场景</a>，如果没有大量人工智能的帮助，世界上发生的所有事情都是人类无法理解的。但最终，人工智能已经控制了很长时间，能够颠覆人类专家用来监控实际情况的所有系统。他们在屏幕上看到的东西是假的，就像震网病毒向纳坦兹的伊朗技术人员提供虚假信息一样</p><p>此时，人类已经被剥夺了权力，可能有很多不同的方式来真正屠杀我们。例如，军用无人机都可以用来杀人。或者，也许运行这个的人工智能系统会使用一种非常讨厌的生物病毒。对于一个已经很好地与人类一起运行一切的系统来说，让一些实验室（顺便说一句，是自动化的）制造病毒，然后将该病毒插入到世界上大部分空气供应中，这并不是那么困难。 。</p><p>但也许在这一点上它会做一些创造性的事情来最大限度地减少我们抵抗的机会。也许这只是一种非常致命的病毒与无人机和机器人同时反抗的组合。</p><p>也许它会在大多数家庭中安装真正先进的（而且非常有用和方便！）3D打印机，同时制造攻击无人机来杀人。那些攻击无人机可能只是用刀片刺人，他们可能附有枪等等。或者也许每个人都有一个机器人管家，他们只是用刀刺人。</p><p>也许人工智能更巧妙地创造和管理人与人之间的冲突，并在某个时候为冲突的一方提供一种陷阱武器，这种武器本应只会杀死坏人，但实际上会杀死所有人。这种武器可能是生物武器、放射性武器、无人机武器，或者只是对常规战争的巧妙操纵，导致极端的双输结果，幸存的人类很容易被消灭。</p><p>整个故事可能也比这个更混乱一些。阿兹特克人的失败有点混乱，有战斗和挫折，还有三个不同的阿兹特克皇帝。另一方面，故事也可能更干净一些。也许一个真正优秀的战略家人工智能可以将其压缩很多：这些想法中的一些或全部的各个方面将同时执行。</p><p><strong>将人类国家推上神坛</strong></p><p><em>关键是：一旦你有了一个极其超人的对手，填写如何以剥夺人类权力和屠杀人类的方式破坏我们的政府、情报机构和军队等机构的细节的任务就有点无聊了。</em>我们预计需要一些特殊的魔法才能通过图灵测试。或者也许因为哥德尔定理之类的原因这是不可能的。</p><p>但实际上，通过图灵测试只是拥有比人脑更多的计算/数据的问题。细节很无聊。</p><p>我觉得像斯科特·阿伦森（Scott Aaronson）这样的人，他们要求人工智能如何杀死我们所有人，因为这听起来难以置信，他们也犯了类似的错误，但他们并没有把人类的大脑放在一个基座上，而是把人类的状态放在了一个基座上。一个基座。</p><p>我假设，大多数超人类人工智能系统与人类共存的场景最终都会导致人类被剥夺权力，或者人类灭绝，或者类似于工厂化农业的某种形式的监禁或圈养；同样，如果我们观察地球上人口众多的地区，我们会发现动物的生物量几乎全部转化为人类或农场动物。更有能力的实体获胜，而确切的细节往往并不那么令人兴奋。</p><p>对于可以自我复制并升级认知的先进人工智能系统来说，击败人类可能并不那么困难；这就是为什么我们需要在创建人工智能之前解决人工智能对齐问题。</p><p> <a href="https://forum.effectivealtruism.org/posts/aZamZBfg2JqzTaDmA/stuxnet-not-skynet-humanity-s-disempowerment-by-ai">交叉发布在 EA 论坛上</a></p><br/><br/><a href="https://www.lesswrong.com/posts/tyE4orCtR8H9eTiEr/stuxnet-not-skynet-humanity-s-disempowerment-by-ai#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/tyE4orCtR8H9eTiEr/stuxnet-not-skynet- humanity-s-disempowerment-by-ai<guid ispermalink="false"> TYE4或CtR8H9eTiEr</guid><dc:creator><![CDATA[Roko]]></dc:creator><pubDate> Sat, 04 Nov 2023 22:23:55 GMT</pubDate> </item><item><title><![CDATA[The 6D effect: When companies take risks, one email can be very powerful.]]></title><description><![CDATA[Published on November 4, 2023 8:08 PM GMT<br/><br/><p>最近，我一直在学习与构建风险系统的公司相关的行业规范、法律发现程序和激励结构。我想在这篇文章中分享一些发现，因为它们对于前沿人工智能社区的良好理解可能很重要。</p><h3>长话短说</h3><p>记录在案的风险沟通（尤其是员工的沟通）使公司在发生不好的事情时更有可能在法庭上承担责任。即使向公司发送一封传达风险的电子邮件，可发现的危险文档所产生的尽职调查义务（6D 效应）也可以使公司更加谨慎。</p><h3>公司倾向于避免通过有记录的媒体谈论风险。</h3><p>公司通常有意避免通过电子邮件等永久媒体讨论他们正在做的事情的风险。例如， <a href="https://corporate.findlaw.com/litigation-disputes/safe-communication-guidelines-for-creating-corporate-documents.html"><u>本文</u></a>就公司如何通过使用“安全沟通”实践来避免创建有罪的“不良文件”来避免责任，提供了一些非常阴暗的建议。</p><blockquote><p>通常，这些文件的起草者倾向于认为他们正在为公司提供一些业务价值。例如，一位工程师注意到设计中存在潜在的责任，因此他通过电子邮件通知他的主管。然而，工程师缺乏法律知识，在沟通中误用法律词汇，可能会在以后发生诉讼时发现问题，让公司受到牵连。</p></blockquote><p>我个人喜欢在摘录中使用“何时”而不是“如果”。</p><p>这是一个反常的结果，因为当无法证明公司了解风险时，即使公司了解风险，公司也相对难以承担风险责任。当事件发生并且公司被起诉时，有关其在问题中所扮演角色的证据将在诉讼的“<a href="https://en.wikipedia.org/wiki/Discovery_(law)"><u>发现</u></a>”阶段收集（电子邮件通常是可发现的）。当发现记录表明一家公司了解该问题时，他们更有可能被判承担责任。</p><h3>一封电子邮件可以发挥很大的作用。</h3><p>发现工作方式的不幸后果是，公司战略性地避免通过记录媒体传达风险。但还有一线希望。由于风险沟通记录而产生的责任威胁可能会对公司的谨慎程度产生很大影响。一份可发现的风险记录可能非常有影响力。</p><p><strong>我喜欢将其称为 6D 效应——对可发现的危险文件进行尽职调查的责任。</strong></p><h3>几个例子</h3><p>以下是一些公司因忽视风险沟通记录而被追究损害赔偿责任的著名例子（但在整个法律史上有很多例子）。</p><ul><li> <a href="https://law.justia.com/cases/california/court-of-appeal/3d/119/757.html"><u>1981 年，在 Grimshaw 诉福特汽车公司一案</u></a>中，福特被判对福特 Pinto 造成的致命事故所造成的损害承担责任，因为事实表明，公司内部领导层忽视了有关车辆燃油系统问题的警告。</li><li> 2017年伦敦格伦菲尔大厦火灾造成72人死亡，今年4月，<a href="https://www.bbc.com/news/uk-england-london-65458973"><u>双方达成了大规模和解</u></a>。诉讼的一个重要因素是管理该塔的公司<a href="https://www.theguardian.com/uk-news/2018/aug/08/grenfell-fire-warnings-issued-months-before-blaze-show-documents"><u>忽视了</u></a>发现中发现的众多消防安全警告。</li><li>去年，哈德威克诉 3M 案<a href="https://www.ehslawinsights.com/2022/09/sixth-circuits-interlocutory-order-reviewing-pfas-class-action-highlights-issues-with-certifying-class/"><u>结束</u></a>。这是 2018 年针对消费品中存在有害“永久化学物质”(PFAS) 的集体诉讼。这些化学品背后的公司被发现自 20 世纪 70 年代以来就已<a href="https://www.theguardian.com/environment/2022/may/01/pfas-forever-chemicals-rob-bilott-lawyer-interview"><u>了解风险</u></a>，但却<a href="https://law.justia.com/cases/federal/district-courts/ohio/ohsdce/2:2018cv01185/217689/166/"><u>故意疏忽，</u></a>最终导致对他们不利的裁决。</li></ul><h3>杂项笔记</h3><ol><li>任何可发现的沟通都会产生 6D 效应，但当警告来自公司本身的员工时，这种效应尤其强大。</li><li>如果您传达了风险，重要的是要在诉讼的发现阶段说出并提请法院注意该风险的文件。</li><li>如果您意识到公司所做的某些事情是危险的，那么您有道德义务通知该公司，但您没有道德义务帮助他们修复而不提供补偿。确保不要让公司利用您。</li></ol><h3>三个要点</h3><ol><li>如果您在一家从事潜在风险工作的公司工作，请坚持通过有记录的媒体讨论危险。如果您因记录风险沟通而遭到报复，您将有理由诉诸法律。 #notlegaladvice</li><li>如果您发现有风险，请说出来。如果你预测的事情发生了，请指出你传达过的事实。</li><li>注重安全的公司（例如那些致力于前沿人工智能系统的公司）应该制定明确的政策来记录所有风险讨论。</li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/J9eF4nA6wJW6hPueN/the-6d-effect-when-companies-take-risks-one-email-can-be#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/J9eF4nA6wJW6hPueN/the-6d-effect-when-companies-take-risks-one-email-can-be<guid ispermalink="false"> J9eF4nA6wJW6hPueN</guid><dc:creator><![CDATA[scasper]]></dc:creator><pubDate> Sat, 04 Nov 2023 20:08:40 GMT</pubDate> </item><item><title><![CDATA[Genetic fitness is a measure of selection strength, not the selection target]]></title><description><![CDATA[Published on November 4, 2023 7:02 PM GMT<br/><br/><p><i>替代标题：“进化表明对齐属性的稳健而不是脆弱的概括。”</i></p><p>一个<a href="https://www.lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization"><u>经常</u></a><a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities"><u>被重复的</u></a><a href="https://www.lesswrong.com/posts/JcLhYQQADzTsAEaXd/ai-as-a-science-and-three-obstacles-to-alignment-strategies"><u>论点</u></a>是这样的：</p><ol><li>进化优化了人类的包容性遗传适应性（IGF）</li><li>然而，人类最终并没有明确地优化遗传适应性（例如，他们使用避孕措施来避免生育孩子）</li><li>因此，即使我们针对 X 优化 AI（通常是“人类价值观”），我们也不应该期望它显式针对 X 进行优化</li></ol><p>我的观点是，前提 1 是一种口头速记，在技术上是不正确的，而前提 2 至少具有误导性。至于总体结论，我认为进化论的案例可能被解释为弱证据，无法证明为什么人工智能即使在其能力增强的情况下也应该<i>继续</i>优化人类价值观。</p><p><strong>前提 1 错误的总结：</strong>如果我们仔细观察进化的作用，我们可以看到它选择有利于生存、繁殖和将基因传递给下一代的特征。这通常被描述为“针对 IGF 进行优化”，因为有利于这些目的的性状<i>通常</i>是具有最高 IGF 的性状。 （这有一些重要的例外，稍后讨论。）但是，如果我们仔细观察选择过程，我们可以看到这种性状选择<i>并不是</i>“针对 IGF 进行优化”，例如，我们可能会优化一个对图片进行分类的人工智能。</p><p>我所描绘的模型是这样的：进化是一种优化函数，在任何给定时间，它都会选择一些在重要意义上是随机选择的特征。在任何时候，它都可能随机转向选择其他一些特征。观察这个选择过程，我们可以计算当前正在选择的性状的 IGF，作为衡量这些性状被选择的强度的指标。但进化并没有<i>针对这一指标进行优化</i>；进化正在<i>优化</i><i>当前已选择进行优化的特征</i>。因此，没有理由期望进化创造的思维应该针对 IGF 进行优化，但<i>有理由</i>期望它们会针对实际选择的特征进行优化。这是我们在人类针对某些生物需求进行优化时观察到的任何事情。</p><p>相反，如果我们优化人工智能来对图片进行分类，我们就不会像进化那样随机改变选择标准。我们将保持选择标准不变：始终选择按照我们想要的方式对图片进行分类的属性。就进化的类比而言，人工智能应该更有可能只做它们被选中的事情。</p><p><strong>前提2如何误导的总结：</strong>人们常常暗示，进化选择了人类来关心性，然后性产生了后代，直到最近随着避孕方法的进化，这种联系才被切断。例如：</p><blockquote><p> 15. [...]在引入农业之后，我们并没有立即打破与“包容性生殖适应性”外部损失函数的一致性——就像克罗马努人起飞了 40,000 年一样，因为它本身运行得非常快相对于自然选择的外部优化循环。相反，我们获得了许多比祖先环境更先进的技术，包括避孕，相对于外部优化循环的速度而言，在一般智能游戏的后期，我们以非常快的速度爆发了。</p><p> – Eliezer Yudkowsky， <a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities"><u>《AGI 废墟：杀伤力清单》</u></a></p></blockquote><p>这对我来说似乎是错误的。避孕可能是最近才出现的发明，但杀婴或因疏忽而杀害儿童则不然。即使不采取避孕措施，也一直有控制人口规模的方法。根据<a href="https://www.lesswrong.com/posts/vwM7hnT9ysE3suwfk/notes-on-the-anthropology-of-childhood"><u>《童年人类学》</u></a>一书，家庭规模和生孩子的经济价值一直是相关的。儿童对于采集者来说是更大的负担，相应地，采集者的家庭规模较小，而儿童对于家庭规模较大的农民来说则是一种资产。</p><p>进化并没有选择人类的IGF，然后这种联系随着避孕的发明而打破，而是进化选择了人类具有优化功能，在考虑生育多少孩子时权衡各种因素。在类似采集者的环境中，这一功能会导致人们偏好较少的孩子和较小的家庭规模；在类似农民的环境中，这种功能导致人们偏好更多的孩子和更大的家庭规模。 <a href="https://www.lesswrong.com/users/robinhanson?mention=user">@RobinHanson</a><a href="https://www.overcomingbias.com/p/forager-v-farmer-elaboratedhtml"><u>认为</u></a>，现代社会更像是采集者而不是农民，而我们增加的财富正在导致我们恢复采集者式的方式和心理。如果这个论点是正确的，那么进化的“意图”和人类的行为方式之间并没有断裂。相反，进化创造的优化功能继续以它一贯的方式运作。</p><p>现代避孕方式的发明可能使得在农民型文化中更容易限制家庭规模，这种文化已经形成了反对杀婴等行为的文化禁忌。但找到一种绕过这些禁忌的方法并没有创造一个全新的进化环境，而是让我们<i>更接近</i>原始进化环境中的事物。</p><p>如果我们看看人类被选择优化的目标，看起来我们大多是在继续优化这些相同的东西。少数人选择不生孩子的原因是，我们进化的优化函数也重视孩子以外的事物，并且我们对这个优化函数“保持忠诚”。就人工智能而言，它被训练为按照“人类价值观”之类的东西行事，而没有其他任何东西，历史例子似乎表明，它的对齐属性可能比我们的更强大，因为它没有被选择用于混合许多相互竞争的价值观。</p><h1>进化是一种随机选择特征的力量</h1><p>在这篇文章中，我浏览了两本关于进化论的教科书： <a href="https://www.amazon.com/Evolution-Douglas-J-Futuyma/dp/1605356050/"><u>Futuyama 和 Kirkpatrick 的</u><i><u>《进化论》（第 4 版）</u></i></a>和<a href="https://www.amazon.com/Evolutionary-Analysis-5th-Jon-Herron/dp/0321616677/"><u>Herron 和 Freeman 的</u><i><u>《进化分析》（第 5 版）</u></i></a> 。第一个是根据谷歌搜索“什么是最好的进化生物学教科书”而选择的，第二个是因为我曾经选修过的进化心理学本科课程使用了早期版本，我记得它很好。</p><p>据我所知，没有人谈论进化是一个优化遗传适应性的过程（尽管这是一个相当简单的浏览，所以即使它存在，我也可能错过了）。相反，他们警告<i>不要</i>将进化视为首先“做”任何事情的积极因素。进化确实<i>提高了种群对其环境的平均适应能力</i>（Herron &amp; Freeman，第 107 页），但这意味着什么会随着环境本身的变化而不断变化。在历史上的某个时期，一个地区可能气候寒冷，选择那里的物种是为了有能力应对寒冷；然后气候可能会变得更加温暖，以前有益的适应（例如皮毛）可能会突然变成一种负担。</p><p>另一个经典的例子是<a href="https://en.wikipedia.org/wiki/Peppered_moth_evolution"><u>胡椒蛾的进化</u></a>。浅色飞蛾曾经在英格兰很常见，深色飞蛾非常罕见，因为浅色比深色飞蛾更能伪装鸟类。随着工业革命和污染工厂的出现，一些城市变得如此之黑，以至于深色成为更好的伪装，导致深色飞蛾相对于浅色飞蛾的增加。一旦污染减少，浅色飞蛾就会再次占据主导地位。</p><p>如果我们将进化建模为数学函数，我们可以说，飞蛾首先选择浅色，然后改为选择深色，然后再次选择浅色。</p><p>最接近“遗传适应度的进化优化”的是所谓的“<a href="https://en.wikipedia.org/wiki/Fisher%27s_fundamental_theorem_of_natural_selection"><u>自然选择基本定理</u></a>”，它意味着自然选择将导致种群的平均适应度随着时间的推移而增加。然而，在这里我们假设<i>我们选择的东西保持不变。</i>随着时间的推移，浅色飞蛾将继续变得更加常见，直到深色成为具有更高适应度的特征，并且深色开始变得更加常见。在这两种情况下，我们可能会说“人口的平均适应度正在增加”，但这在这两种情况下意味着<i>不同的事情</i>：在一种情况下，这意味着选择白色，而在另一种情况下，这意味着选择深色。首先被选择<i>的</i>事物，然后被选择<i>反对</i>，即使我们的术语意味着<i>同样的</i>事物被选择。</p><p>发生的情况是，随着选择特定颜色，人口的平均适应度上升，然后随机变化（首先是污染增加，然后是污染减少）导致平均适应度下降，然后又开始上升。</p><blockquote><p><i>在其他条件相同的情况下，基本定理将使我们预计物种的平均适应度应每代增加几个百分点。但其他一切并不平等：选择给予什么，其他进化力量就会夺走什么。选择带来的适应度增益不断被空间和时间变化的环境、有害突变和其他因素所抵消。</i> （Futuyama 和 Kirkpatrick，第 127 页）</p></blockquote><p>即使考虑到这一点，进化也不会持续增加种群的平均适应度：有时进化最终会选择<i>降低</i>种群的平均适应度。</p><blockquote><p><i>基本定理和适应性景观做出的假设并不完全适用于任何自然种群。但在许多情况下，它们给出了非常好的近似值，有助于指导我们对进化的思考。在其他情况下，假设被违反的方式使进化表现得非常不同。基本定理和自适应景观不适用的一个特别重要的情况是选择与频率相关。在某些情况下，这可能会导致种群的平均适应度下降</i>（Futuyama &amp; Kirkpatrick，第 128 页）</p></blockquote><p>导致平均适应度<i>较低</i>的频率依赖选择的一个例子是产生许多果实的灌木丛的情况（Futuyama &amp; Kirkpatrick，第 129 页）。一些灌木会进化出一个树干，使它们能够为邻居投下阴影。结果，这些邻居变得虚弱和死亡，使已经变成树木的灌木丛获得了更多的水和养分。</p><p>这导致树木变得比灌木丛更常见。但由于树木需要花费更多的能量来生产和维护树干，因此它们没有那么多的能量来种植果实。当树木稀少并且主要从灌木丛中窃取能量时，这并不是什么大问题；但一旦整个种群都由树木组成，它们最终可能会互相遮蔽。此时，它们最终产出的可供新树生长的果实要少得多，因此后代也较少，平均适应度也较低。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BtffzD5yNB4CzSTJe/d1oqnbrk2hlvbihqseic"></p><p>这种与频率相关的选择很常见。另一个例子（Futuyama &amp; Kirkpatrick，第 129 页）是细菌既能进化出杀死其他细菌的毒素，又能进化出针对该毒素的解毒剂。两者的生产都需要消耗能源，但只要这些细菌很稀有，那么这些成本就是值得的，因为它们的毒性可以让它们杀死竞争对手。</p><p>但是，一旦这些有毒细菌自我繁殖，产生毒素就不再有任何好处——所有幸存的细菌都对其免疫——因此继续花费能量来产生毒素意味着可用于复制的能量更少。现在，保持解毒剂的产生但失去毒素的产生变得更加有利：毒素的产生从被选择变成被选择反对。</p><p>一旦这种选择过程发生足够长的时间并且不产生毒素的细菌占据主导地位，解毒剂的生产<i>也</i>将成为不必要的负担。没有人再产生毒素了，所以没有理由浪费精力来维持防御，所以解药也从被选择变成了被选择对抗。</p><p>但是，一旦没有细菌再产生毒素<i>或</i>解毒剂，会发生什么呢？既然没有人对毒素有防御能力，那么再次开始生产毒素+解毒剂组合就变得有利，从而杀死所有其他没有解毒剂的细菌……如此循环重复。</p><p>在本节中，我认为，就进化而言，“为了适应而优化物种”，这实际上在不同情况下意味着不同的事情（选择不同的特征）；而且，针对适应性的进化优化更多的是一种粗略的启发式方法，而不是字面法则，因为在很多情况下，进化最终会<i>降低</i>种群的适应性。仅这一点就应该让我们对“进化为IGF选择人类”的论点产生怀疑；这意味着并不是针对单一事物进行优化，而是在不同时间选择了多种特征。</p><h1>健身到底是什么？</h1><p>到目前为止，我一直在一般性地谈论健身，但让我们回顾一下一些技术细节。包容性遗传适应性到底<i>是</i>什么？</p><p>有几种不同的定义；这是其中的一组。</p><p><i>适应度</i>的一个简单定义是，个体为下一代留下的后代数量<span class="footnote-reference" role="doc-noteref" id="fnrefns0k7bysais"><sup><a href="#fnns0k7bysais">[1]</a></sup></span> 。假设胡椒蛾的后代中有 1% 能存活到生育年龄，并且幸存的蛾类平均有 300 个后代。在这种情况下，这些个体的平均适应度为 0.01 * 300 = 3。</p><p>为了通过自然选择进行进化，个体之间的适应度差异需要遗传。在生物进化中，遗传是通过基因发生的，因此我们通常对<i>遗传适应性</i>（基因的适应性）感兴趣。假设这些都是污染城市中的浅色飞蛾。假设深色的基因等位基因将生存能力提高了 0.33 个百分点，总体适应度为 0.0133 * 300 = 4。等位基因的适应度现在为 3 和 4。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BtffzD5yNB4CzSTJe/hn7jtehbrwp5cxtwi6vs"></p><p>图片来自 Futuyama 和柯克帕特里克。原文说明：<i>基因型 A 的适应度为 3，而基因型 B 的适应度为 4。两种基因型均以 10 个个体开始。 (A) B 基因型的种群规模增长得更快。 (B) 绘制两种基因型的频率图表明，从频率为 0.5 开始的基因型 B 在 7 代后就几乎占到了人口的 90%。</i></p><p>通常重要的是两个等位基因之间的适应度<i>差异</i>：例如，如果其竞争对手的适应度为 1，则适应度为 2 的等位基因可能会在群体中变得更常见，但如果其竞争对手的适应度为3. 因此，通常指示<i>相对于</i>某些共同参考的适合度，例如群体的平均适合度或具有最高绝对适合度的基因型。</p><p>遗传适应性可以分为两个组成部分。个体可以将基因直接传给后代——这称为<i>直接适应性</i>。他们还可以携带一种基因适应能力，使他们能够帮助具有相同适应能力的其他人，从而增加他们的生存几率。例如，父母可能会投入额外的精力来照顾子女。这称为<i>间接健身。</i>基因型的<i>包容性适应性</i>是其直接适应性和间接适应性的总和。 <span class="footnote-reference" role="doc-noteref" id="fnref23b1jpur496"><sup><a href="#fn23b1jpur496">[2]</a></sup></span></p><p>生物进化可以定义为“生物体特性在世代过程中遗传的变化”（Futuyama &amp; Kirkpatrick，第 7 页）。<i>自然选择的进化</i>是指基因型的相对频率由于适应度的差异而在世代之间发生变化。请注意，基因型频率也可能因自然选择以外的原因而在代际间发生变化，例如随机漂移或新突变。</p><h1>适合度作为选择强度的衡量标准</h1><p>让我们看一个有意饲养动物的案例。接下来的数学细节并不那么重要，但无论如何我都想把它们讲一遍，只是为了更具体地说明“健身”<i>的实际含义</i>。不过，如果您愿意，也可以浏览它们。</p><p>假设我碰巧拥有一堆各种颜色的胡椒蛾，并且碰巧喜欢浅色，所以我决定将它们培育成浅色。现在我不知道胡椒蛾颜色的遗传学如何运作的细节 - 我认为它很可能受到多个基因的影响。但为了简单起见，我们假设有一个基因具有“亮”等位基因和“暗”等位基因。</p><p>将“亮”等位基因称为 B1，将“暗”等位基因称为 B2。 B1B1 飞蛾是浅色的，B2B2 飞蛾是深色的，B1B2 / B2B1 飞蛾介于两者之间（为了进一步简化，我将使用“B1B2”来指代 B1B2 和 B2B1 飞蛾）。</p><p>假设初始种群有 100 只飞蛾。我已经进行了一点育种，所以我们从 B1 开始，频率为 0.6，B2 频率为 0.4。飞蛾的基因型分布如下：</p><p> B1B1 = 36</p><p> B1B2 = 48</p><p> B2B2 = 16</p><p>在我看来，所有具有 B1B1 基因型的飞蛾看起来都很轻盈，所以我选择让它们全部繁殖。在我看来，75% 具有 B1B2 基因型的飞蛾看起来足够浅，50% 的 B2B2 基因型飞蛾也是如此（也许它们的颜色也受到环境因素或其他基因的影响）。其余的则不能繁殖。</p><p>平均而言，下一代 B1 等位基因的频率为 0.675，B2 等位基因的频率为 0.325 <span class="footnote-reference" role="doc-noteref" id="fnrefh3ks5duler4"><sup><a href="#fnh3ks5duler4">[3]</a></sup></span> 。假设每只飞蛾为下一代贡献了一百个配子，我们得到以下等位基因的适应性：</p><p> B1：从 120 (36 + 36 + 48) 增加到 5400 个副本，因此适应度为 5400/120 = 45。</p><p> B2：从 80 (48 + 16 + 16) 增加到 2600 个副本，因此适应度为 2600/80 = 32.5。</p><p>随着B1比例的增加，人群的平均适应度就会提高！这是因为你携带的 B1 等位基因越多，你被选择繁殖的可能性就越大，因此 B1 携带者具有更高的适应度……这意味着 B1 变得更常见……这增加了整个小鼠群体的平均适应度。因此，在这种情况下，人口的平均适应度往往会随着时间的推移而增加的规则确实适用。</p><p>但现在……将这个过程描述为<i>针对飞蛾适应性的优化，听起来不是很奇怪吗？</i></p><p>我正在优化<i>轻飞蛾</i>；适应度计算告诉我们的是<i>亮度基因有多大的优势——</i>换句话说，<i>我对亮度基因有多少偏爱</i>——<i> </i>相对于黑暗基因。</p><p>因为我们只是对适应度的影响进行建模，而不是对随机漂移进行建模，所以基因频率的所有差异都来自于适应度的差异。这是同义反复 - 无论您选择（优化）<i>什么</i>并不重要，根据定义，选择的<i>任何内容</i>最终都会具有最高的适应性。</p><p>与其说我们正在针对高适应度进行优化，不如说我们正在针对<i>亮度</i>特征进行优化，并且<i>亮度提供了适应度优势，这似乎更自然。</i>反过来说就没有多大意义了——我们正在针对健身进行优化，这给轻盈带来了优势？什么？</p><p>这个例子使用了人工选择，因为这使得实际选择目标是什么变得最明显。但无论我们谈论的是人工选择还是自然选择，数学的结果都是一样的。如果我们说，不是我决定某些飞蛾不能繁殖，而是鸟类和外部环境中的其他因素正在繁殖……好吧，所讨论的方程没有任何变化。</p><p>自然选择是否优化了飞蛾的适应性？从某种意义上来说，你可以这么说，因为与浅色飞蛾相比，深色飞蛾最终的健康状况有所提高。但这样描述又会让人感觉有点不太对劲。说飞蛾<i>为了拥有深色而进行了优化</i>，或者更抽象地说，为了拥有适合其环境的颜色，感觉更信息丰富、更准确。</p><h1>从颜色到行为</h1><p>我刚刚说过，如果我们看看实际的进化过程，它看起来更像是针对特定特征进行优化（用适应度来衡量它们被选择的强度），而不是针对适应度本身进行优化。即使选择过程<i>会</i>导致人口的平均适应度增加，但正如我们从数学中看到的那样，这只是意味着“如果你选择某件事，那么你会得到更多你所选择的东西”为了”。</p><p>在此之前的几节中，我认为进化选择的并不是单一的东西；而是进化所选择的。相反，它正在改变的事物本身也在不断改变。</p><p>我认为这些论点足以得出这样的结论：“进化优化了人类的适应性[因此人类应该优化适应性]”这一说法是站不住脚的。</p><p>到目前为止，我主要讨论的是相对“静态”的特征，例如颜色，而不是本身就是优化器的认知特征。那么我们来谈谈认知。虽然说“进化优化了人类的遗传适应性，因此人类应该优化适应性”似乎站不住脚，但如果我们谈论被选择的特定认知行为，相应的论点<i>确实</i>有效。</p><p>例如，如果我们说“人类被选择是为了关心他们的后代，因此人类应该为了确保后代的生存而进行优化”，那么这种说法一般来说确实成立——很多人<i>确实</i>投入了大量的认知努力确保孩子的生存。或者，如果我们说“人类被选择在某些情况下表现出性嫉妒，因此在某些情况下，他们会优化以防止他们的伴侣与其他人类发生性关系”，那么显然这种说法<i>也</i>成立。</p><p>这就是我的论点的第二部分：虽然声称我们现在正在做的事情完全违背了进化的选择，但避孕至少是一个糟糕的例子。在大多数情况下，我们仍在针对进化选择我们优化的事物进行优化。</p><h1>人类仍然有我们被选中的目标</h1><p>对性的渴望本身不足以生出婴儿，或者至少不足以生出能够存活足够长的时间来繁殖自己的婴儿。它始终只是一个组成部分，我们对孩子有多种不同的愿望：</p><ol><li>渴望发生性行为并享受性行为本身</li><li>为了孩子而生孩子的愿望</li><li>为了自己的利益而照顾和保护孩子（包括不是你自己的孩子）的愿望</li></ol><p>埃利以泽在《AGI 毁灭：致命事件清单》中写道</p><blockquote><p>15. [...]在引入农业之后，我们并没有立即打破与“包容性生殖适应性”外部损失函数的一致性——就像克罗马努人起飞了 40,000 年一样，因为它本身运行得非常快相对于自然选择的外部优化循环。相反，我们获得了许多比祖先环境更先进的技术，包括避孕，相对于外部优化循环的速度而言，在一般智能游戏的后期，我们以非常快的速度爆发了。我们开始更多地反思自己，开始更多地被文化进化所编程，并且我们在祖先训练环境中的一致性的许多假设同时被打破。</p></blockquote><p>这句话似乎暗示着</p><ul><li>有效的避孕是一项相对较新的发明</li><li>对性的渴望才是生孩子的主要驱动力（有效的避孕措施打破了这一假设）</li><li>这是一个新颖的发展，我们如此优先考虑儿童以外的事情</li></ul><p>所有这些前提对我来说似乎都是错误的。原因如下：</p><p><i>有效的避孕是一项相对较新的创新。</i>即使是狩猎采集者也能以杀婴的形式获得有效的“避孕”，这在一些现代狩猎采集社会中很常见。特别敏感的读者可能想跳过<a href="https://www.lesswrong.com/posts/vwM7hnT9ysE3suwfk/notes-on-the-anthropology-of-childhood"><i><u>《童年人类学》</u></i></a>中的以下段落：</p><blockquote><p> Ache（巴拉圭的一个觅食社会）特别直接处理多余的儿童（大约五分之一），因为他们四处游荡、觅食的生活方式给父母带来了巨大的负担。父亲提供重要的食物资源，母亲提供食物和危险的丛林环境所需的警惕监控。男性和女性在其相对较短的一生中都面临着重大的健康和安全隐患，他们将自己的福祉置于后代的福祉之上。对几个觅食社会的调查显示，杀婴意愿与“在游牧过程中携带多个幼儿”的艰巨挑战之间存在密切联系（Riches 1974：356）。</p><p>在其他南美采集者中，也普遍存在类似的态度。来自巴西中部的塔皮拉佩人每个家庭只允许三个孩子；所有其他人都必须留在丛林中。影响整个社区的季节性稀缺资源决定了这些措施（Wagley 1977）。事实上，是否有足够的资源是决定表面健康的婴儿是否能够存活的最常见标准（Dickeman 1975）。在玻利维亚的阿约雷奥采集者中，女性通常会经历几次短暂的风流韵事，通常会导致分娩，然后才能建立相当于婚姻的稳定关系。 “非婚生”后代往往在出生后立即被埋葬。在 Bugos 和 McCarthy (1984) 的实地调查中，141 名婴儿中有 54 名以杀婴告终。</p></blockquote><p>新生儿需要数年时间才能达到能够照顾自己的程度，因此，简单地缺乏积极照顾就足以杀死婴儿，不需要现代避孕技术。</p><p><i>对性的渴望才是生孩子的主要驱动力。</i>再次，看看杀婴，这并不需要是一种主动行为，而只是一种简单的疏忽。一个人需要有一种积极的愿望来让孩子<i>活下去</i>。</p><p>此外，尽管自愿不要孩子的人比例在增加，但这仍然不是主要选择。 <a href="https://theconversation.com/more-than-1-in-5-us-adults-dont-want-children-187236"><u>2022 年的一项研究</u></a>发现，22% 的受访者既没有也不想要孩子——这个数字很大，但仍有 78% 的人已经或想要孩子。人们仍然有强烈的想要孩子的冲动，这与单纯发生性行为的冲动是分开的。</p><p><i>这是一种新颖的文化发展，我们如此优先考虑除了生孩子之外的事情。</i> 《童年人类学》花费了大量时间研究影响不同文化中儿童待遇的各种因素。它非常有力地认为，儿童的价值也始终强烈取决于各种文化和经济因素——这意味着它始终只是人们关心的事情<i>之一</i>。 （事实上​​，想要生很多孩子的愿望可能与农业和工业社会更相关，这些社会的经济激励异常高。）</p><blockquote><p>当满足某些条件时，成年人会因生育大量后代而获得奖励。首先，母亲身边必须有支持她们的亲属，她们可以减轻抚养孩子的大部分负担，这样她们就可以集中精力生育更多的孩子。其次，这些额外的后代必须被视为农场或工厂的“未来工人”。他们必须被视为有潜力偿还婴儿和幼儿时期对他们所做的投资，而且在他们开始繁殖自己之前很快。如果满足其中一个或两个条件，人类的生育能力就会降低（Turke 1989）。对采集者来说，孩子更多的是负担而不是帮助，他们的孩子数量将远远少于依赖农业维生的邻近社会（LeVine 1988）。 [...]</p><p>在觅食社会中，孩子到了十几岁就变得依赖他人并且缺乏生产力，因此优先选择的孩子数量较少。在像本族这样的农业社会中，儿童可能会被视为“小奴隶”而受到欢迎（Gottlieb 2000：87）。在田园社会和工业社会中，年幼的孩子可以承担起牧羊的责任，或者从事重复性的机器工作，女性的生育能力要强得多。而且，虽然村庄的传统文化为保护怀孕母亲和新生儿提供了大量的习俗和禁忌，但这些习俗和禁忌与规定或至少暗中批准堕胎和杀婴的习俗并存。</p></blockquote><p>对我来说，这里最简单的故事看起来像是“进化选择了具有各种欲望的人类，从性行为到生孩子，再到创造艺术和许多其他事物；然后，所有这些愿望都会受到复杂的学习和加权过程的影响，根据文化和环境，这些愿望可能会强调某些愿望而不是其他愿望”。</p><p>由于复杂的原因，有些人最终会更加重视孩子；其他人最终会更加重视其他事物，同样是出于复杂的原因。狩猎采集时代是这样，现在也是这样。</p><p>但在我看来，进化并<i>没有</i>选择我们去渴望一件事，然后我们开发了一个内部优化器，最终做了一些完全不同的事情。相反，看起来我们被选中去渴望许多不同的东西，有一个非常复杂的功能来选择每个人最终在这组行为中强调哪些东西。今天的文化可能已经改变了这个函数，以与以前不同的方式衡量我们的欲望，但我们所做的一切仍然是从那组基本欲望中选择的，加权函数的运作方式与以往相同。</p><p>正如我在引言中提到的，罗宾·汉森（Robin Hanson）<a href="https://www.overcomingbias.com/p/forager-v-farmer-elaboratedhtml"><u>认为</u></a>，现代社会更像是采集者而不是农民，我们的财富增加正在导致我们恢复采集者式的方式和心理。这意味着我们进化的权重函数现在正在表现出它在类似觅食的环境中进化时表现出的行为。</p><p>今天，我们确实从事像电脑游戏这样的新颖活动，但在我看来，玩电脑游戏的动机仍然植根于与第一批狩猎采集者相同的基本欲望——例如打发时间、享受美好时光。讲故事、社交或体验能力感。</p><h1>那么关于人工智能我们能说些什么呢？</h1><p>嗯，我对类比推理持谨慎态度。我不确定我们能否对与人工智能的联系提出特别强烈的主张。我认为有<a href="https://forum.effectivealtruism.org/posts/kLYD95SK8tQFRmw4T/ben-garfinkel-s-shortform?commentId=XMjAWSEgp9BXTDQBi">更直接和相关的论据</a>可以使这看起来确实令人担忧，而不是试图诉诸进化类比。</p><p>但在我看来，例如“急速左转”的进化历史意味着与之前争论的<i>相反</i>。像“训练人工智能识别图片”或“训练人工智能关心人类价值观”之类的东西看起来更像是“选择人类来关心后代”，而不是“优化人类的遗传适应性”。关心后代是我们似乎仍然坚定地拥有的一种财产。即使我们的能力增强了，我们的对齐特性仍然继续普遍化。</p><p>在某种程度上，我们不关心我们的后代，甚至选择不生孩子，那只是因为我们被选择<i>也</i>关心其他事情——如果一个过程选择人类关心许多事情的混合，他们有时会权衡这些事情其他事情更多本身并不代表协调失败。这再次与我们试图<i>专门</i>优化以关心人类福祉的人工智能之类的东西形成鲜明对比。因此，我们有理由预期人工智能的对齐特性可能比现有人类具有<i>更多的</i>泛化能力。</p><p><i>感谢 Quintin Pope、Richard Ngo 和 Steve Byrnes 对本文之前草稿的评论。</i> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnns0k7bysais"> <span class="footnote-back-link"><sup><strong><a href="#fnrefns0k7bysais">^</a></strong></sup></span><div class="footnote-content"><p>富图山和柯克帕特里克，p。 60.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn23b1jpur496"> <span class="footnote-back-link"><sup><strong><a href="#fnref23b1jpur496">^</a></strong></sup></span><div class="footnote-content"><p>富图山和柯克帕特里克，p。 300.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnh3ks5duler4"> <span class="footnote-back-link"><sup><strong><a href="#fnrefh3ks5duler4">^</a></strong></sup></span><div class="footnote-content"><p>每只 B1B1 蛾有 100% 的机会“挑选”B1 等位基因来产生配子，每只 B1B2 蛾有 50% 的机会挑选 B1 配子，有 50% 的机会挑选 B2 配子，每只 B2B2 蛾有100% 选择 B2 等位基因来产生配子。假设我选择繁殖的每只蛾子为下一代贡献 100 个配子，我们从选择繁殖的 36 只 B1B1 蛾子中平均得到 3600 个 B1 配子，从选择繁殖的 360 只 B1B2 蛾子中平均得到 1800 个 B1 和 1800 个 B2 配子，以及来自选择繁殖的 8 只 B2B2 蛾的 800 个 B2B2 配子。</p><p>这使得 3600 + 1800 = 5400 个 B1 配子和 1800 + 800 = 2600 个 B2 配子，总共 8000 个配子。这使得 B1 的频率为 0.675，B2 的频率为 0.325。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/BtffzD5yNB4CzSTJe/genetic-fitness-is-a-measure-of-selection-strength-not-the#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/BtffzD5yNB4CzSTJe/genic-fitness-is-a-measure-of-selection-strength-not-the<guid ispermalink="false"> BtffzD5yNB4CzSTJe</guid><dc:creator><![CDATA[Kaj_Sotala]]></dc:creator><pubDate> Sat, 04 Nov 2023 19:02:13 GMT</pubDate> </item><item><title><![CDATA[The Soul Key]]></title><description><![CDATA[Published on November 4, 2023 5:51 PM GMT<br/><br/><p>海洋是你的家，但却是一个令人生畏的地方：常常汹涌澎湃，很少温暖。所以，你最大的乐趣之一就是爬上陆地，脱下毛茸茸的海豹皮，以人类的形态懒洋洋地沐浴在阳光下。长老们讲述了朋友们的恐怖故事，他们的皮肤被人类偷走了，一时的不小心就让他们永远滞留在陆地上。不过，这种情况不会再发生了。这是一个更加文明的时代。你和你的姐妹们最喜欢的僻静海滩周围有条约、权威和栅栏，在那里你可以以老一辈人无法做到的方式放松身心。</p><p>这样你的姐妹们就不会再被强行剥皮了。但有时它是由选择发生的。有时，一群姐妹像长袍一样裹着自己的皮肤，走进附近的城镇。人们指指点点、盯着看，但这只是刺激的一部分。有时，年轻人会鼓起勇气走近，带着鲜花、珠宝或甜言蜜语。有时，你的一个姐妹会被迷住，会去约会——在几次或十几次会面后，决定永远留下来。</p><p>你从未想过这会发生在你身上。但他的举止如此活泼，他的眼神如此友善，让你一次又一次地回来。当他最终邀请你留下来时，你犹豫了一下就答应了。更困难的部分在后面。他为你找到了人类的衣服，作为交换，你给了他你美丽的皮肤，并告诉他它必须锁在一个你永远找不到它的地方——而且他永远不能把它还给你，无论你如何恳求。因为如果有任何一丝怀疑，任何回家的机会，那么大海的诱惑对你来说就会太大了。你要这个;你想要他；你们想共同构建生活。因此，该决定必须是最终决定。</p><p>岁月流逝。你生了三个漂亮的孩子，有他的眼睛和你的头发，看着他们成长为美丽的成年人。你总是住在海边，尽管你无法忍受在海里游泳——每当你尝试时，你的四肢都感到难以忍受的虚弱和笨拙。你和你的丈夫彼此成长，时间抚平了两个异类生活在一起留下的脊梁。你忘记了你曾经是谁。</p><p>当您最小的孩子离开家后，您开始感到焦躁不安。你会做一些令人不安的梦——一开始是间歇性的，然后是连续几周的。有一天，你丈夫去上班后，你的脚带你走上楼梯，来到阁楼。当你拨开角落里的蜘蛛网时，你的手落在了一个旧箱子上。你拉开盖子，它就会卡在挂锁上——但只持续了一秒钟。 The shackle has been rusted through by the sea breeze, and quickly snaps. You open the lid, and you see your skin laid out before you.</p><p> What then?</p><hr><p> You look at your skin, and your ears fill with the roar of the sea. A wild urge overtakes you; you grab your skin and run headlong towards the shore. As you reach it you see your husband standing on the pier—but that gives you only a moment&#39;s pause before you dive into the water, your skin fitting around you as if you&#39;d never taken it off.</p><p> As you swim away, you envisage your family in tatters: your children left baffled and distraught, your husband putting on a brave face for their sake. But it was his fault, after all. He failed in the one thing you asked of him; and you can&#39;t fight your nature.</p><hr><p> You look at your skin, and see a scrap of paper lying on top of it. <i>I knew you&#39;d only open the chest if you were restless and unhappy</i> , it reads. <i>And I would never cage you. So go free, with my blessing</i> .</p><p> You catch your breath—and, for a moment, you consider staying. But his permission loosens any tether that might have held you back. You leave the note there, alongside a little patch of fur torn off your coat: a last gesture, the least you can give him.</p><hr><p> You look at your skin, and your ears fill with the roar of the sea. But it&#39;s not loud enough to drown out your thoughts. <i>I&#39;m not an animal</i> , you think. <i>I can make my own choices</i> .</p><p> You shove the lid closed, and the moment of reprieve it gives you is enough to start scrambling down the stairs and out the gate and you don&#39;t stop running until you&#39;re out of sight of your house.</p><p> When you find your husband, down at the pier, your face tells him what&#39;s happened before you&#39;ve said a word. He gives you a gentle kiss, then sprints back to the house. By the time you make it home, he&#39;s relaxing in an armchair, and the kettle is almost boiling; but you know that the chest and its contents are gone.</p><p> His glances, always loving, now fill with wonder: that he almost lost you, but that he didn&#39;t. That you chose him yet again, in defiance of your deepest instincts. You curl up in his arms every night; and though at first you can&#39;t hold back the tears, over time they grow rarer and rarer. You never see your skin again.</p><hr><p> You look at your skin, and a wave of emotion crashes into you. You remember your old ambitions: to explore every horizon; to surf every current; to ride every storm. Dangerous dreams—and pointless ones too, in an age where planes criss-cross the skies, and the blank spots on the maps have all been filled. You didn&#39;t want to waste your life retracing others&#39; footsteps. So you infused those dreams into your skin and locked it away.</p><p> And yet there&#39;s still something in you that yearns for them: the part that&#39;s been making you restless, the part that led you into the attic. So you fetch a pair of scissors, and cut off your long wavy hair—and with it, whatever remaining wistfulness was keeping you up at night. You put it into the box, on top of your skin, and close the lid again. No need to lock it, this time.</p><p> Maybe your husband finds the broken lock, and the tresses of your hair. You never know. But you don&#39;t need to know. What you&#39;ve got is enough.</p><hr><p> You look at your skin, and remember your plan. Your face is lined now, and your hair is streaked with gray. But inside the chest, under a layer of dust, your old skin is pristine. You can imagine slipping it back on and gliding back into the ocean, not a day older than when you left.</p><p> You&#39;ll be different from how you were before, of course. You can&#39;t live a lifetime in any skin without it changing you. But your past self thought that was a worthwhile trade, for those extra decades of youth. Worth leaving your friends and family behind, worth setting aside all the glories of the ocean. And who knows—maybe there are more tricks yet to be found, more ways to slip the noose of aging and death.</p><p> You look at the skin, and consider putting it on. Not yet, you think. You&#39;ve still got a few more decades left in your current skin, before you&#39;ll need to go back. Not yet.</p><hr><p> The fur on your skin ripples like waves, bringing back to you the knowledge of what the ocean really is. In your current body, you can only see the surface: the swells of water, the winds and storms. But if you could dive underneath, you&#39;d find a portal to a whole civilization. You&#39;re on the shore of the future of humanity, a sea of minds so vast that you can barely imagine it. Throughout the long millennia since humans transcended the limitations of their biology, they&#39;ve multiplied beyond number, and constructed joys and enchantments beyond measure. The ocean is your gateway to all of those people and their wonders—each one so beautiful, and so so tempting.</p><p> Why did you come to this backwater, this output of baseline humans who refuse to engage with the outside world? Why did you lock away your memories, leaving only hints about what you used to be? You don&#39;t remember. Was it an experiment? A whim? Surely it couldn&#39;t have been for the love of a baseline human. But regardless, how can you stay here, when you know what else exists? You gather your skin in your arms, and though there&#39;s a pang of sadness as you walk out the door, you don&#39;t look back. There&#39;s a whole universe to explore.</p><hr><p> Your skin is a cornucopia of possible lives; the deeper into it you look, the more you see. Just under the surface, joyful humans are granted miraculous powers: to soar through air and sea, to play games on the scale of planets, to morph their bodies as they please. Beneath them, you see a society that&#39;s explored further, morphing not just their bodies, but also their minds—belief and desire and identity become as malleable as clay. Beneath <i>them</i> , you lose sight of individuals: at those depths minds merge and split and reform like currents in the ocean. And beneath even that? It&#39;s hard for you to make sense of the impressions you&#39;re getting—whatever is down there can&#39;t be described in human terms. In the farthest reaches there are only alien algorithms, churning away on computers that stretch across galaxies, calculating the output of some function far beyond your comprehension.</p><p> And now you see the trap. Each step down makes so much sense, from the vantage point of the previous stage. But after you take any step, the next will soon be just as tempting. And once you&#39;re in the water, there&#39;s no line you can draw, no fence that can save you. You&#39;ll just keep sinking deeper and deeper, with more and more of your current self stripped away—until eventually you&#39;ll become one of the creatures that you can glimpse only hazily, one of the deep-dwelling monsters that has forsaken anything recognizably human.</p><p> So this is the line you decided to draw: here, and no further. You&#39;ll live out your lives in a mundane world of baseline humans, with only a touch of magic at the edges—just enough to satisfy the wondering child in you. You&#39;ll hold on to yourself, because what else is there to hold onto? It&#39;s a sad thought, in some ways, but a satisfying one too.</p><p> You close the lid, and your memories with it, and live happily ever after.</p><hr><p> As you look at your skin, each strand of fur shimmers with different stories—not of your possible lives, but of your <i>current</i> lives. Different shards of you are living out countless adventures across countless artificial universes. You&#39;re far vaster than you ever dreamed: what you thought was your whole “self” is just a fragment of a fragment of your overall mind.</p><p> Which fragment? Perhaps, at your core, you were the part of your meta-self that loved fairy tales; or perhaps you were an avatar of the innocence of early humanity; or perhaps you were a nostalgic part, who enjoyed basking in the wistfulness of times already gone. Whatever your goals were, they led you to volunteer to live this small life in this small world: a single strand in the tapestry your meta-self is weaving.</p><p> You stroke your skin gently. You can&#39;t picture your meta-self, not really—it&#39;s too vast and too alien. But you know it&#39;s watching out for you. There&#39;s a warmth underneath your hand, and a gentle breeze passing across your neck, like a caress. As you close the chest, you bask in the knowledge that your life is part of a vast plan. That&#39;s enough for you.</p><hr><p> As you glimpse your skin, long-lost memories rush into your mind: recollections of all the hundreds of other times you&#39;ve rediscovered it, across thousands of past lives. Every time, you&#39;ve received a different vision of what&#39;s waiting for you in the depths of the ocean. But you don&#39;t know which, if any, is true. You can&#39;t know. Where would the adventure be, if you were just handed the whole plot? What would be the point of living through it? Only two things remain constant across all your visions. First: there&#39;s no hurry; you have eons of time. Second: once you put on the skin, you can&#39;t come back.</p><p> You stare at it with longing, and excitement, and fear. But you&#39;re not ready yet. So you pull aside the skin to reveal the padlocks underneath—thousands of them, split into two piles. One pile is stained with wear, each shackle rusted through; you toss the latest padlock on top. The padlocks in the other pile are clean and new; each looks strong enough to fasten the world in place. You grab one of those. You put your skin back on top of the two piles, and close the box, and carefully fasten the padlock. Then you go downstairs again, to the life you&#39;ve constructed for yourself, while the shiny steel slowly begins to rust away.</p><hr><p> <i>In addition to the inspirations behind</i> <a href="https://www.narrativeark.xyz/p/the-ants-and-grasshopperhtml"><i>my previous story of this form</i></a> <i>, I also owe a debt to Neil Gaiman&#39;s beautiful</i> <a href="https://www.amazon.com/Ocean-End-Lane-Novel/dp/0062459368">The Ocean at the End of the Lane</a> <i>.</i></p><br/><br/><a href="https://www.lesswrong.com/posts/tHvFtfFKjhfy3sQpC/the-soul-key#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/tHvFtfFKjhfy3sQpC/the-soul-key<guid ispermalink="false"> tHvFtfFKjhfy3sQpC</guid><dc:creator><![CDATA[Richard_Ngo]]></dc:creator><pubDate> Sat, 04 Nov 2023 17:51:53 GMT</pubDate> </item><item><title><![CDATA[[Linkpost] Concept Alignment as a Prerequisite for Value Alignment]]></title><description><![CDATA[Published on November 4, 2023 5:34 PM GMT<br/><br/><blockquote><p> Value alignment is essential for building AI systems that can safely and reliably interact with people. However, what a person values -- and is even capable of valuing -- depends on the concepts that they are currently using to understand and evaluate what happens in the world. The dependence of values on concepts means that concept alignment is a prerequisite for value alignment -- agents need to align their representation of a situation with that of humans in order to successfully align their values. Here, we formally analyze the concept alignment problem in the inverse reinforcement learning setting, show how neglecting concept alignment can lead to systematic value mis-alignment, and describe an approach that helps minimize such failure modes by jointly reasoning about a person&#39;s concepts and values. Additionally, we report experimental results with human participants showing that humans reason about the concepts used by an agent when acting intentionally, in line with our joint reasoning model.</p></blockquote><p></p><blockquote><p> We propose a theoretical framework for formally introducing concepts to inverse reinforcement learning and show that conceptual misalignment (ie, failing to consider construals) can lead to severe value misalignment (ie, reward mis-specification; large performance gap). We validate these theoretical results with a case study using a simple gridworld environment where we find that IRL agents that jointly model construals and reward outperform those that only model reward. Finally, we conduct a study with human participants and find that people do model construals, and that their inferences about rewards are a much closer match to the agent that jointly models construals and rewards. Our theoretical and empirical results suggest that the current paradigm of just trying to directly infer human reward functions or preferences from demonstrations is insufficient for value-aligning real AI systems that need to interact with real people; it is crucial to also model and align on the concepts people use to reason about the task in order to understand their true values and intentions.</p></blockquote><br/><br/> <a href="https://www.lesswrong.com/posts/M6CEJmgna6FTt9Yci/linkpost-concept-alignment-as-a-prerequisite-for-value#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/M6CEJmgna6FTt9Yci/linkpost-concept-alignment-as-a-prerequisite-for-value<guid ispermalink="false"> M6CEJmgna6FTt9Yci</guid><dc:creator><![CDATA[Bogdan Ionut Cirstea]]></dc:creator><pubDate> Sat, 04 Nov 2023 17:34:41 GMT</pubDate> </item><item><title><![CDATA[We are already in a persuasion-transformed world and must take precautions]]></title><description><![CDATA[Published on November 4, 2023 3:53 PM GMT<br/><br/><p> &quot;In times of change, learners inherit the earth, while the learned find themselves beautifully equipped to deal with a world that no longer exists&quot;</p><p></p><p><strong>概括：</strong></p><p> We&#39;re already in the timeline where the research and manipulation of the human thought process is widespread; SOTA psychological research systems require massive amounts of human behavior data, which in turn requires massive numbers of unsuspecting test subjects (users) in order to automate the process of analyzing and exploiting human targets. This therefore must happen covertly, and both the US and China have a strong track record of doing things like this. This outcome is a strong attractor state since anyone with enough data can do it, and it naturally follows that powerful organizations would deny others access eg via data poisoning. Most people are already being persuaded that this is harmless, even though it is obviously ludicrously dangerous. Therefore, we are probably already in a hazardously transformative world and must take <a href="https://www.lesswrong.com/posts/Lw8enYm5EXyvbcjmt/sensor-exposure-can-compromise-the-human-brain-in-the-2020s#The_solutions_are_easy:~:text=Webcam%2Dcovering%20rates,media%20news%20feeds).">standard precautions</a> immediately.</p><p></p><p> This should not distract people from AI safety. This is valuable because the AI safety community must survive. This problem connects to the AI safety community in the following way:</p><p> State survival and war power <a href="https://www.lesswrong.com/posts/jyAerr8txxhiKnxwA/5-reasons-why-governments-militaries-already-want-ai-for#1__Militaries_are_perhaps_the_oldest_institution_on_earth_to_research_and_exploit_human_psychology_">==>;</a> already depends on information warfare capabilities.</p><p> Information warfare capabilities <a href="https://www.lesswrong.com/posts/jyAerr8txxhiKnxwA/5-reasons-why-governments-militaries-already-want-ai-for#2__Information_warfare_has_long_hinged_on_SOTA_psychological_knowledge_and_persuasive_skill_">==>;</a> already depends on SOTA psychological research systems.</p><p> SOTA psychological research systems <a href="https://www.lesswrong.com/posts/jyAerr8txxhiKnxwA/5-reasons-why-governments-militaries-already-want-ai-for#5__SOTA_psychological_research_and_manipulation_capabilities_have_already_started_increasing_by_an_order_of_magnitude_every__4_years_">==>;</a> already improves and scales mainly from AI capabilities research, diminishing returns on everything else. <span class="footnote-reference" role="doc-noteref" id="fnrefxevua908cwf"><sup><a href="#fnxevua908cwf">[1]</a></sup></span></p><p> AI capabilities research <a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks-and-mind#AI_pause_as_the_turning_point">==>;</a> already under siege from the AI safety community.</p><p> Therefore, the reason why this might be such a big concern is:</p><p> State survival and war power <a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks-and-mind#AI_pause_as_the_turning_point:~:text=the%20AI%20safety%20community%20must%20acknowledge%20the%20risk%20that%20the%202020s%20will%20be%20intensely%20dominated%20by%20actors%20capable%20of%20using%20modern%20technology%20to%20stealthily%20hack%20the%20human%20mind%20and%20eliminate%20inconvenient%20people%2C%20such%20as%20those%20try%20to%20pause%20AI%2C%20even%20though%20AI%20is%20basically%20the%20keys%20to%20their%20kingdom">==>;</a> their toes potentially already being stepped on by the AI safety community?</p><p> Although it&#39;s also important to note that <a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks-and-mind#AI_pause_as_the_turning_point:~:text=I%20think%20that%20the%20AI%20safety%20community%20is,murkiest%20people%20lurking%20within%20the%20US%2DChina%20conflict.">people with access to SOTA psychological research systems are probably super good at intimidation and bluffing</a> , it&#39;s also the case that the AI safety community needs to get a better handle on the situation if we are in the bad timeline; and <a href="https://www.lesswrong.com/s/TDciH7QjqeAirdJFc/p/Zvu6ZP47dMLHXMiG3#:~:text=Learning%20these%20kinds,causes%20with%20the">the math indicates that we are already well past that point</a> .</p><p></p><p> <strong>The Fundamental Problem</strong></p><p> If there were intelligent aliens, made of bundles of tentacles or crystals or plants that think incredibly slowly, their minds would also have discoverable exploits/zero days, because any mind that evolved naturally would probably be like the human brain, a <a href="https://www.lesswrong.com/posts/NQgWL7tvAPgN2LTLn/spaghetti-towers">kludge of spaghetti code</a> that is operating outside of its intended environment.</p><p> They would probably not even begin to scratch the surface of finding and labeling those exploits, until, like human civilization today, they began surrounding thousands or millions of their kind with sensors that could record behavior several hours a day and find <a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks#:~:text=of%20procuring%20results.-,There%20is%20no,-logical%20endpoint%20to"><u>webs of correlations</u></a> .</p><p> In the case of humans, the use of social media as a controlled environment for automated AI-powered experimentation appears to be what created that critical mass of human behavior data. Current 2020s capabilities for psychological research and manipulation vastly exceed the 20th century academic psychology paradigm.</p><p> The 20th century academic psychology paradigm still dominates our cultural impression of what it means to research the human mind; but when the effectiveness of psychological research and manipulation starts increasing by an order of magnitude every 4 years, it becomes time to stop mentally living in a world that was stabilized by the fact that manipulation attempts generally failed.</p><p> The capabilities of social media to steer human outcomes are not advancing in isolation, they are parallel to a broad acceleration in the understanding and exploitation of the human mind, which itself <a href="https://arxiv.org/pdf/2309.15084.pdf"><u>is a byproduct of accelerating AI capabilities research</u></a> .</p><p> By comparing people to other people and predicting traits and future behavior, multi-armed bandit algorithms can predict whether a specific research experiment or manipulation strategy is worth the risk of undertaking at all in the first place; resulting in large numbers of success cases a low detection rate (as detection would likely yield a highly measurable response, particularly with substantial sensor exposure).</p><p> When you have sample sizes of billions of hours of human behavior data and sensor data, millisecond differences in reactions from different kinds of people (eg facial microexpressions, millisecond differences at scrolling past posts covering different concepts, heart rate changes after covering different concepts, eyetracking differences after eyes passing over specific concepts, touchscreen data, etc) transform from being imperceptible noise to becoming the foundation of webs of correlations mapping the human mind.</p><p> Unfortunately, the movement of scrolling past a piece of information on a social media news feed with a mouse wheel or touch screen will generate at least one curve since the finger accelerates and decelerates each time. Trillions of those curves are outputted each day by billions of people. These curves are linear algebra, the perfect shape to plug into ML.</p><p> Social media&#39;s individualized targeting uses deep learning and massive samples of human behavioral data to procedurally generate an experience that fits human mind like a glove, in ways we don&#39;t fully understand, but allow hackers incredible leeway to find ways to optimize for steering people&#39;s thinking or behavior in measurable directions, insofar as those directions are measurable. This is something that AI can easily automate. I originally thought that going deeper into human thought reading/interpretability was impossible, but I was wrong; <a href="https://www.lesswrong.com/s/TDciH7QjqeAirdJFc/p/Zvu6ZP47dMLHXMiG3#:~:text=Learning%20these%20kinds,."><u>the human race is already well past that point as well, due to causality inference</u></a> . </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LdEwDn5veAckEemi4/lmquoccehpu8d9exhbjb"></p><p> Most people see social media influence as something that happens to people lower on the food chain, but this is no longer true; there is at least one technique, <a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks#Clown_attacks"><u>Clown Attacks</u></a> , that generally works on all humans who aren&#39;t already aware of it, regardless of intelligence or commitment to truthseeking; and that particular technique became discoverable with systems vastly weaker than the ones that exist today. I don&#39;t know what manipulation strategies the current systems can find, but I can predict with great confidence that they&#39;re well above the clown attack.</p><blockquote><p> First it started working on 60% of people, and I didn&#39;t speak up, because my mind wasn&#39;t as predictable as people in that 60%. Then, it started working on 90% of people, and I didn&#39;t speak up, because my mind wasn&#39;t as predictable as the people in that 90%. Then it started working on me. And by then, it was already too late, because it was already working on me.</p></blockquote><p></p><p> <strong>They would notice and pursue these capabilities</strong></p><p> If the big 5 tech companies (Facebook, Google, Microsoft, Amazon, and Apple) notice ways to steer people towards buying specific products, or to feel a wide variety of compulsions to avoid quitting the platform, and to <a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks#:~:text=However%2C%20if%20a,of%20the%20genepool."><u>prevent/counteract other platforms from running multi-armed bandit algorithms to automatically exploit strategies (eg combinations of posts) to plunder their users</u></a> , then you can naturally assume that they&#39;ve noticed their capabilities to steer people in a wide variety of other directions as well.</p><p> The problem is that <a href="https://www.lesswrong.com/s/TDciH7QjqeAirdJFc/p/jyAerr8txxhiKnxwA"><u>major governments and militaries are overwhelmingly incentivized and well-positioned to exploit those capabilities for offensive and defensive information warfare</u></a> ; if American companies abstain from manipulation capabilities, and Chinese companies naturally don&#39;t, then American intelligence agencies <a href="https://www.nytimes.com/2023/11/03/technology/israel-hamas-information-war.html#:~:text=%E2%80%9CWe%E2%80%99re%20in%20an%20undeclared%20information%20war%20with%20authoritarian%20countries%2C%E2%80%9D%20James%20P.%20Rubin%2C%20the%20head%20of%20the%20State%20Department%E2%80%99s%20Global%20Engagement%20Center%2C%20said%20in%20a%20recent%20interview.">worry about a gap in information warfare capabilities</a> and push the issue.</p><p> Government/military agencies are <a href="https://www.lesswrong.com/posts/LyywLDkw3Am9gbQXd/don-t-take-the-organizational-chart-literally">bottlenecked by competence</a> , which is <a href="https://www.lesswrong.com/posts/foM8SA3ftY94MGMq9/assessment-of-intelligence-agency-functionality-is-difficult">difficult to measure due to a lack of transparency at higher levels and high employee turnover at lower levels</a> , but revolving-door employment easily allows them to source flexible talent from the talent pools of the big 5 tech companies; <a href="https://www.lesswrong.com/posts/jyAerr8txxhiKnxwA/5-reasons-why-governments-militaries-want-ai-for-information-1#3__Information_warfare_is_about_winning_over_high_intelligence_elites__not_the_ignorant_masses__">this practice is endangered by information warfare itself</a> , further driving interest in information warfare superiority.</p><p> Access to tech company talent pools also determine the capability of intelligence agencies to use <a href="https://www.nytimes.com/2020/01/14/us/politics/nsa-microsoft-vulnerability.html">OS exploits</a> and chip firmware exploits needed to access the sensors in the devices of almost any American, not just the majority of Americans that leave various sensor permissions on, which allows <a href="https://www.lesswrong.com/posts/Lw8enYm5EXyvbcjmt/sensor-exposure-can-compromise-the-human-brain-in-the-2020s">even greater access to the psychological research needed to compromise critical elites such as the AI safety community</a> .</p><p> The capabilities of these systems to run deep bayesian analysis on targets dramatically improves with more sensor data, <a href="https://www.lesswrong.com/s/TDciH7QjqeAirdJFc/p/Lw8enYm5EXyvbcjmt#:~:text=Eyetracking%20is%20likely,person%E2%80%99s%20thought%20process)."><u>particularly video feed on the face and eyes</u></a> ; this is <a href="https://www.lesswrong.com/s/TDciH7QjqeAirdJFc/p/Zvu6ZP47dMLHXMiG3#:~:text=Learning%20these%20kinds,."><u>not necessary to run interpretability on the human brain</u></a> , but it increases these capabilities by yet more orders of magnitude (particularly for <a href="https://www.lesswrong.com/s/TDciH7QjqeAirdJFc/p/foM8SA3ftY94MGMq9#Functioning_lie_detectors_as_a_turning_point_in_human_history"><u>lie detection</u></a> and conversation topic aversion).</p><p></p><p> <strong>This can&#39;t go on</strong></p><p> There isn&#39;t much point in having a utility function in the first place if hackers can change it at any time. There might be parts that are resistant to change, but it&#39;s easy to overestimate yourself on this; especially if the effectiveness of SOTA influence systems have been increasing by an order of magnitude every 4 years. Your brain has internal conflicts, and they have <a href="https://www.lesswrong.com/s/TDciH7QjqeAirdJFc/p/Zvu6ZP47dMLHXMiG3#:~:text=Learning%20these%20kinds,with%20the%20common">human internal causality interpretability systems</a> . You get <a href="https://www.lesswrong.com/posts/bbB4pvAQdpGrgGvXH/tuning-your-cognitive-strategies">constant access to the surface</a> , but they get occasional access to the deep.</p><p> The multi-armed bandit algorithm will keep trying until it finds something that works. The human brain is a kludge of spaghetti code, so there&#39;s probably something somewhere.</p><p> The human brain has exploits, and the capability and cost of social media platforms to use massive amounts of human behavior data to find complex social engineering techniques is a profoundly technical matter, you can&#39;t get a handle on this with intuition or pre-2010s historical precedent.</p><p> Thus, you should assume that your utility function and values are at risk of being hacked at an unknown time, and should therefore be assigned a discount rate to account for the risk over the course of several years.</p><p> Slow takeoff over the course of the next 10 years alone guarantees that this discount rate is too high, in reality, for people in the AI safety community to continue to go on believing that it is something like zero.</p><p> I think that approaching zero is a reasonable target, but not with the current state of affairs where people don&#39;t even bother to cover up their webcams, have important and sensitive conversations about the fate of the earth in rooms with smartphones, sleep in the same room or even the same bed as a smartphone, and use social media for nearly an hour a day (scrolling past nearly a thousand posts).</p><p> The discount rate in this environment cannot be considered “reasonably” close to zero if the attack surface is this massive; and the world is changing this quickly. We are gradually becoming intractably compromised by slow takeoff before the party even starts.</p><p> If people have <a href="https://www.lesswrong.com/posts/SGR4GxFK7KmW7ckCB/something-to-protect">anything they value at all</a> , and the AI safety community almost certainly does have that, then the current AI safety paradigm of zero effort is wildly inappropriate, it is basically <a href="https://www.lesswrong.com/s/TDciH7QjqeAirdJFc/p/jyAerr8txxhiKnxwA#:~:text=if%20you%20look,in%20the%20past."><u>total submission to invisible hackers</u></a> . The <a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks#Clown_attacks">human brain has low-hanging exploits</a> and <a href="https://www.lesswrong.com/posts/Lw8enYm5EXyvbcjmt/sensor-exposure-can-compromise-the-human-brain-in-the-2020s#The_solutions_are_easy:~:text=Keeping%20people%20on,adversarial%20information%20environment.">the structures of power have already been set in motion</a> , so we must take the <a href="https://www.lesswrong.com/posts/Lw8enYm5EXyvbcjmt/sensor-exposure-can-compromise-the-human-brain-in-the-2020s#The_solutions_are_easy:~:text=Webcam%2Dcovering%20rates,day%20inside%20hyperoptimized">standard precautions</a> immediately.</p><p> The AI safety community must survive the storm. </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnxevua908cwf"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxevua908cwf">^</a></strong></sup></span><div class="footnote-content"><p> eg Facebook could hire more psychologists to label data and correlations, but has greater risk of one of them breaking their NDA and trying to leak Facebook&#39;s manipulation capabilities to the press like Snowden and Fishback. Stronger AI means more ways to make users label their own data.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/LdEwDn5veAckEemi4/we-are-already-in-a-persuasion-transformed-world-and-must#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/LdEwDn5veAckEemi4/we-are-already-in-a-persuasion-transformed-world-and-must<guid ispermalink="false"> LdEwDn5veAckEemi4</guid><dc:creator><![CDATA[trevor]]></dc:creator><pubDate> Sat, 04 Nov 2023 15:53:34 GMT</pubDate> </item><item><title><![CDATA[Being good at the basics]]></title><description><![CDATA[Published on November 4, 2023 2:18 PM GMT<br/><br/><p> (crossposted from <a href="https://sundaystopwatch.eu/being-good-at-the-basics/">my blog</a> )</p><p> In Brazilian Jiu Jitsu, there&#39;s a notion of being &quot;good at the basics&quot;, as opposed to &quot;being good by knowing advanced techniques&quot;. <em>How</em> you want to be good is a question of personal preference, but the idea is that these are the two ways, and most people do one or the other.</p><p> I think this is a concept that applies outside of BJJ, and one that&#39;s useful if you&#39;re trying to learn a field, but you&#39;re not sure how to approach it.</p><p> I&#39;ll take physics as an example, because that is a field where I would like to be good at the basics. The &quot;basics&quot; of physics would be things that you learn in high school, while &quot;advanced&quot; stuff would be what you would learn in university, maybe at a graduate level. (There&#39;s probably other ways of separating the basics from the advanced topics.)</p><p> You may roughly remember some of the simple formulas that you have learned in class during high school, you may orient yourself through a textbook problem, you may perform some basic calculations. You sorta know the basics. But how does it look like when you&#39;re <em>good</em> at the basics?</p><p> It might mean that you know the equations by heart, that you&#39;ve really internalized their meaning.</p><p> It might also mean that you know the quantities or values for things around you. You can correctly approximate how much things weigh, how fast they move, or what their kinetic and potential energy is.</p><p> You can approximate how much joules of energy an apple contains, or how much energy hits a m2 of the Earth&#39;s surface on a sunny day. You have a good feeling for how much compressive stress a piece of concrete can withstand, and you can quickly and accurately calculate what the kinetic energy is of a car that you&#39;re driving in. You can also quickly convert between different units, and compare the quantities of different things.</p><p> Being really good at the basics of physics in this way requires a sort of <em>embodied</em> understanding. It requires a level of &quot;closeness&quot; to the subject matter that allows you to apply this knowledge to the world around you, to the extent that you start seeing the world around you in terms of that subject. You take a walk outside and <em>you can&#39;t help</em> but notice the physics of it all.</p><p> You&#39;ll notice that being &quot;good at the basics&quot; is actually a linguistic misdirection. This type of understanding is drastically different from the level of understanding you have after high school, yet both refer to the &quot;basics&quot;. If you are really good at the basics, you are in fact an expert - an expert in the basics. The word &quot;basics&quot; here hides a huge amount of complexity, or time and effort.</p><p> Why be good at the basics (as opposed to the advanced stuff)? These things sometimes depend on the field, but mostly because being good at the advanced stuff will be required for a career in that particular field, but useless for other goals. I, for example, have no ambition to become a physicist but I do have an ambition to closely understand the world around me, and to make accurate estimates and good decisions. For me, being really good at the basics of physics is much more important than being good at some advanced thing within physics.</p><p> There are other fields where you can notice the two ways of being good at them. Writing is one of those fields. &quot;Being really good at the basics&quot; in writing looks like really plain and simple language that&#39;s easy to understand. By being good at the basics, you&#39;re actually hiding complexity. It&#39;s not like there is no complexity involved, it&#39;s just hidden from the reader. The reader is served a simple and clear text, but the complexity was in the process, from developing clear thinking about a topic, to the editing process that tries to simplify the resulting text. Compare this to being good at writing, but not in this basic sense: writers using interesting and innovative metaphors, or having a really rich vocabulary.</p><p> In cooking, there&#39;s a notion of being good at the basics as well. For example, compare a cook who has perfected the bowl of rice vs. a cook who uses espuma or sous vide cooking.</p><p> In drumming, there&#39;s that notion as well. For example, compare a drummer who has perfected a &quot;simple&quot; 4/4 funk groove using just the bass drum, snare and hi-hat vs. a drummer who uses a full set to play some super advanced polyrhythm.</p><p> Ultimately, choosing the strategy for how to be good at something is a matter of personal preference, and you may have different preferences depending on the field. As time passes, I find myself more interested in developing expertise in the basics in whatever I do. It often seems much more applicable outside of the narrow domain it belongs to, and it always seems to require fewer prerequisites. So my advice, if you need it, would be: &quot;if you want to learn X, and you&#39;re not sure what exactly to learn, try learning the basics really well&quot;.</p><br/><br/><a href="https://www.lesswrong.com/posts/fLbkWseNn3geEifkv/being-good-at-the-basics#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/fLbkWseNn3geEifkv/being-good-at-the-basics<guid ispermalink="false"> fLbkWseNn3geEifkv</guid><dc:creator><![CDATA[dominicq]]></dc:creator><pubDate> Sat, 04 Nov 2023 14:18:51 GMT</pubDate></item></channel></rss>