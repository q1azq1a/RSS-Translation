<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 22 日星期三 22:10:04 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Foresight Institute: 2023 Progress & 2024 Plans for funding beneficial technology development]]></title><description><![CDATA[Published on November 22, 2023 10:09 PM GMT<br/><br/><p>自 1986 年成立以来，推动技术进步造福人类一直是<a href="https://foresight.org/"><u>Foresight Institute</u></a>使命的核心。我们的努力正在迅速增长；从奖学金申请数量翻倍，到新的奖项、有前景的研讨会项目和定期的虚拟研讨会。</p><p>在节俭的预算下，我们的社区已成为不断增长的合作载体，以推动尚未开发的技术领域的进步，包括分子纳米技术、长寿生物技术、神经技术、人工智能、安全和太空。然而，我们的 2024 年计划，特别是我们的人工智能安全补助金、奖学金和研讨会已超额认购且资金有限。</p><p>以下是 2023 年进展和 2024 年计划的简要概述，包括资金受限领域。</p><p>我们是一家小型非营利组织，完全由捐款资助。如果您有兴趣推动技术进步造福生命，请考虑在这个捐赠季<a href="https://foresight.org/donate-join/"><u>支持我们</u></a>。您决定 2024 年我们可以一起解决哪些项目。<br></p><h3>远见团契</h3><p>我们的<a href="https://foresight.org/foresight-fellowships/"><u>2023 年奖学金</u></a>现已进入第六个年头，为 60 名致力于克服生物技术、纳米技术、神经技术、太空和人工智能领域关键科学瓶颈的研究员提供支持。我们的研究员受益于与选定的导师和资助者的一对一指导、展示他们工作的付费旅行会议邀请以及职业咨询（例如，与<a href="https://foresight.org/summary/tom-kalil-foresight-fellows-career-counseling/"><u>Tom Kalil</u></a> 、 <a href="https://foresight.org/summary/foresight-mentorship-with-jaan-tallinn/"><u>Jaan Tallinn</u></a>和<a href="https://foresight.org/summary/career-counseling-with-sonia-arrison/"><u>Sonia Arrison</u></a>的咨询）。</p><p>同行感言：</p><ul><li> <i>“我喜欢 Foresight 使命，很荣幸成为社区的一员。 Foresight 提供的与杰出人才互动的机会是无价的！”</i></li><li> <i>“[我加入是因为]热爱这里的人们/组织/使命，并认识到我可以使用的令人难以置信的网络”</i></li><li> <i>“网络和声望有助于筹款和合作伙伴关系发展”</i></li></ul><p>我们 2023 年的奖学金获得了极大的超额认购。尽管我们认为更多的研究员值得获得该奖学金，但我们还是接受了 30% 的申请。对于我们2024年的奖学金，申请人数增加了一倍，而我们支持他们的能力却较少，因此在目前的情况下，我们只能接受9%的申请人。除了我们传统的奖学金计划外，今年我们还开始支持 13 至 21 岁的未成年神童研究员，在这一类别中，我们看到 2024 年队列的申请数量增加了两倍，其中大多数是我们提供的目前无法支持。</p><p>在您的帮助下，面对不断增长的申请数量，我们可以提高高素质研究员的录取率。此外，能够在内部提供小额种子资助，而不是为我们的研究员与外部资助者牵线搭桥，会更有效率。您的资金将使我们能够提供申请人请求的资金来支持他们的工作。<br></p><h3>技术前沿研讨会</h3><p>我们的 2023 年研讨会每次都会聚集 50 名初级和高级研究人员、企业家和资助者，以推动被低估的技术领域的进步。领先的研究人员强调了工作组所采取的潜在进展领域，以探索如何推进这一领域。顶级项目提案获得了开发补助金，以便在研讨会后继续开展工作。</p><p>我们的 2023 年研讨会（包括录音）可在此处找到：</p><ul><li> <a href="https://foresight.org/longevity-frontiers-workshop-2023/"><u>2023年长寿前沿研讨会</u></a></li><li><a href="https://foresight.org/intelligent-cooperation-workshop-2023/"><u>2023 密码学、安全、人工智能研讨会</u></a></li><li><a href="https://foresight.org/whole-brain-emulation-workshop-2023/"><u>2023人工智能安全全脑模拟研讨会</u></a></li><li><a href="https://foresight.org/foresight-molecular-systems-design-workshop-2023/"><u>2023年分子机器系统设计研讨会</u></a></li><li><a href="https://foresight.org/foresight-space-workshop-2023/"><u>2023空间技术前沿研讨会</u></a></li></ul><p>2024 年，我们希望通过在各个领域举办后续研讨会来加速技术前沿的进展，以听取现有项目的最新进展情况，并探索启动工作的新机会。我们寻求差旅补助资金，为初级人才提供机会与各自领域的主要参与者合作，并提供资金以奖励发展赠款，以激励工作组在研讨会后就其项目提案进行合作。</p><p>我们计划于 2024 年举办的研讨会包括：</p><ul><li> <a href="https://foresight.org/2024-intelligent-cooperation-workshop/"><u>2024 AGI：密码学、安全、多极方法</u></a></li><li><a href="https://foresight.org/2024-foresight-neurotech-bci-and-wbe-for-safe-ai-workshop/"><u>2024 BCI &amp; WBE for Safe AI 研讨会</u></a></li><li><a href="https://foresight.org/2024-foresight-longevity-frontiers-workshop/"><u>2024年长寿前沿研讨会</u></a></li><li><a href="https://foresight.org/2024-foresight-space-frontiers-workshop/"><u>2024太空前沿研讨会</u></a></li><li><a href="https://foresight.org/2024-foresight-molecular-manufacturing-architectures-workshop/"><u>2024分子3D打印研讨会</u></a><br></li></ul><h3>远见奖</h3><p><strong>分子纳米技术</strong></p><p>我们的年度<a href="https://foresight.org/foresight-feynman-prizes/"><u>费曼奖</u></a>有着显着的记录。我们的费曼奖自 1993 年颁发以来，以纳米技术先驱理查德·费曼 (Richard Feynman) 的名字命名，旨在表彰对先进分子纳米技术进步做出重大贡献的杰出成就。该奖项以尽早发现人才而闻名。例如，2016年，J. Fraser Stoddart爵士因分子机器的设计和合成而共同获得诺贝尔化学奖；距离他获得 Foresight 的费曼实验奖仅九年后。</p><p>虽然费曼奖因奖励分子纳米技术的突破而获得全球认可，但每年 5000 美元的奖金相当少，我们希望在 2024 年将其增加到 20000 美元，以激励更多研究人员追求纳米技术的长期进展。</p><p><strong>长寿</strong></p><p>2023 年，我们与 VitaDAO、Methuselah 和 Lifespan.io 合作，成功推出了<a href="https://www.longevityprize.com/"><u>长寿奖</u></a>，这是一个针对长寿奖项的新合作奖品平台。我们将<a href="https://www.youtube.com/watch?v=HC9N7hwYmns"><u>一等奖</u></a>授予值得更多关注的有关长寿方法的新假设。</p><p>您可以帮助我们资助我们希望在 2024 年推出的各种其他奖项提案，包括体外测量奖、临床试验设计奖和长寿交流奖。</p><p><strong>空间</strong></p><p>我们很荣幸能与 2023 年远见研究员帕特里克·芬利 (Patrick Finley) 合作开展他的“<a href="https://landerchallenge.space/"><u>太空着陆器挑战</u></a>”。帕特里克是太空界的先驱，他希望这个项目能够挑战该领域，加快发射进度，同时也鼓励下一代太空爱好者参与其中。</p><p>您可以帮助我们赞助 2024 年太空着陆器挑战之一，以支持雄心勃勃的年轻人建造自动着陆火箭。支持的潜在奖励包括推力矢量控制热火、可节流发动机热火、系留悬停、着陆和跳跃。<br></p><h2>人工智能安全补助金</h2><p>2023 年 8 月，我们成功启动了三个类别的<a href="https://foresight.org/ai-safety/"><u>人工智能安全资助计划</u></a>：</p><ol><li>人工智能的神经技术：神经技术、脑机接口、全脑仿真和“低保真”上传方法，以产生与人类一致的软件智能</li><li>人工智能安全：帮助保护人工智能系统的计算机安全、密码学和相关技术</li><li>多极人工智能：多主体模拟、博弈论和相关技术，创建安全的多极人工智能场景，避免共谋并促进正和动态</li></ol><p>虽然该补助金在 3 个月前开始实施，但迄今为止我们已经收到了 80 多份申请并提供了三笔补助金。然而，我们认为 15 名申请人值得获得种子资金，这超出了我们分配的 100 万美元预算的资助范围。我们正在积极寻找有兴趣在 2024 年合作发展该计划的资助者。</p><h2>技术研讨会</h2><p>2023 年，我们扩大了<a href="https://foresight.org/seminars/"><u>每月虚拟研讨会系列</u></a>，这是一个基于应用程序的每月研讨会小组，其中介绍新的研究成果和项目，让参与者有机会结识各自领域的潜在合作者。今年，团体申请率增长了 20%，我们今年的顶级研讨会有超过 100 名参与者，YouTube 上的研讨会浏览量达到 5 万次，多个组织使用我们的研讨会作为其员工的入职视频，每月提名参与者研讨会将我们的日程安排安排到 2024 年第二季度。</p><p>现在，我们的研讨会正在成为 STEM 社区的虚拟谢林点，使全球从业者能够了解最新进展、寻找合作者并展示他们的成功，我们希望提高研讨会的质量，以吸引新人才。这包括整个研讨会流程，从引入领先的演讲者到研讨会的制作和推广，目标是在 2024 年使我们领先的研讨会的观看次数达到 10 万次。<br></p><h2>科技树</h2><p>为了让新人才和资助者进入尚未开发的技术领域，我们正在构建技术树，提供该领域的路线图，包括主要参与者和突出的瓶颈。这些树现在被多个社区用来规划其领域的进展。</p><p>您可以在这里探索我们的 2023 年科技树：</p><ul><li><a href="https://foresight.org/ext/ForesightTechTree/"><u>长寿科技树</u></a></li><li><a href="https://foresight.org/ext/ForesightSpaceTree/"><u>太空科技树</u></a></li><li><a href="https://foresight.org/ext/ForesightNanotechTree/"><u>纳米技术树</u></a></li><li><a href="https://foresight.org/ext/ForesightNeurotechTree/"><u>神经科技树</u></a></li></ul><p>2024 年，我们获得了资金来更新我们的长寿技术树，并使用人工智能工具构建人类人工智能合作技术树，使树木具有互动性。额外的资金将使我们能够创建交互式全脑模拟、分子机器和空间技术树。<br></p><h2>存在希望计划</h2><p><strong>激发存在的希望未来</strong></p><p>当我们庆祝新的<a href="https://www.existentialhope.com/"><u>Existential Hope 平台</u></a>推出一周年时<a href="https://www.existentialhope.com/podcasts"><u>，</u></a>我们发现<a href="https://www.existentialhope.com/podcasts"><u>Existential Hope 播客</u></a>的听众数量激增了 30%。今年的剧集邀请了大卫·多伊奇<a href="https://www.existentialhope.com/podcasts/david-deutsch-on-beauty-knowledge-and-progress"><u>(David Deutsch)</u></a> 、丽芙·博瑞 (<a href="https://www.existentialhope.com/podcasts/liv-boeree-game-theory-moloch-our-hopeful-future"><u>Liv Boeree</u></a> ) 和凯文·凯利 ( <a href="https://www.existentialhope.com/podcasts/kevin-kelly-pioneering-visions-of-a-high-tech-future"><u>Kevin Kelly)</u></a>等伟大思想家探讨我们如何打造积极的明天。每一集都配有精心策划的资源列表和<a href="https://www.existentialhope.com/gallery"><u>“希望之水”</u></a> ，这是一件描绘令人兴奋的未来图景的艺术作品。</p><p>作为我们持续致力于激发希望和促进有意义的对话的一部分，我们计划在 2024 年扩展我们的在线<a href="https://www.existentialhope.com/"><u>“存在希望”平台</u></a>。您的支持将通过交互式“存在希望”场景丰富该平台，并改进关键技术的介绍资源，以实现积极的长期目标期货。<br></p><p><strong>构建存在的希望未来</strong></p><p>今年二月，我们举办了第一个<a href="https://foresight.org/foresight-existential-hope-day-2023/"><u>“存在希望日”</u></a> ，重点是探索科学技术积极的<a href="https://www.existentialhope.com/xhope-scenario-contribution-form"><u>“存在希望”情景</u></a>，将焦点从它们构成的威胁转移到它们为我们的未来带来的可能性。</p><p> 2024 年，我们将采取实践方法，通过<a href="https://foresight.org/2024-xhope-hackathon/"><u>Xhope AI 机构黑客马拉松</u></a>培育人工智能繁荣的未来。该活动旨在打造新的机构和框架原型，专门用于应对 TAI 发展带来的现实挑战和机遇。通过资助研讨会，您可以赞助有前途的初级与会者的旅行。</p><p><strong>支持存在希望研究员</strong></p><p>2023 年存在希望奖学金已进入第六个年头，它支持研究人员应对重大科学挑战，同时最大程度地降低存在风险，例如强调差异化技术发展的重要性，这是一种通过加速有益进步、延缓有害进步来促进技术安全发展的战略。通过资助我们的 2024 年奖学金，您可以支持那些先进技术和专注于预防这些技术风险的技术之间更紧密的合作。<br></p><h2>支持前瞻研究所</h2><p>作为捐助者，您为科学技术的有益发展提供资金，而这些发展过于雄心勃勃，以至于传统机构无法支持。我们欢迎您通过我们的<a href="https://foresight.org/donate-join/"><u>捐赠页面</u></a>上的条纹、支票、加密货币或股票进行捐赠。 Foresight Institute 是一家 501(c)(3) 非营利组织，因此根据法律允许，您的捐款在美国可以免税。</p><p>作为 Foresight 的支持者，我们邀请您参加相关的技术路线，包括我们的研讨会、讲习班或<a href="https://foresight.org/vision-weekends-2023/"><u>愿景周末</u></a>——我们的年度年终盛会，聚集我们的技术路线，展望积极的未来。作为远见赞助人（每年 10,000 美元），我们邀请您加入我们的<a href="https://foresight.org/personal-longevity-group/"><u>个人长寿小组</u></a>，探索如何延长自己的寿命。您可以联系<u>allison@foresight.org</u>提出问题、定向资金请求或合作想法。</p><p>感谢您与我们一起推进技术带来的有益未来。</p><p><br><br></p><br/><br/> <a href="https://www.lesswrong.com/posts/uQ9Q5vdyvWpovS5ba/foresight-institute-2023-progress-and-2024-plans-for-funding#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/uQ9Q5vdyvWpovS5ba/foresight-institute-2023-progress-and-2024-plans-for-funding<guid ispermalink="false"> uQ9Q5vdyvWpovS5ba</guid><dc:creator><![CDATA[Allison Duettmann]]></dc:creator><pubDate> Wed, 22 Nov 2023 22:09:16 GMT</pubDate> </item><item><title><![CDATA[AISC project: TinyEvals]]></title><description><![CDATA[Published on November 22, 2023 8:47 PM GMT<br/><br/><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/sp1lu0wdyztp5mj9dbvf" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/lan1jdbplsajj1232h07 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/jj2xtln7lzpdovhzku8v 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/vr4bqq3gveu6ygfvw18d 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/reasdgr0pieqw03ys53f 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/rd1rsclplsrxhvvcukhq 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/ldnm6xznr2s3ryl2gcje 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/fefbjyt4ppqkgqhuuday 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/n5udsbfdodjomoyykbec 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/ssp1zdxfcyvygkmyirch 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/j5c8j3ajzwhb2p1rtgw8 1024w"><br><a href="https://aisafety.camp/#Projects"><i><strong>申请</strong></i></a><i>在 2023 年 12 月 1 日之前在 2024 年人工智能安全营与我一起从事这个项目。</i></p><p><i>该项目不是一成不变的，我正在<strong>寻求反馈</strong>！</i></p><h1>概括</h1><p><a href="https://arxiv.org/abs/2305.07759"><u>TinyStories</u></a>是一套小语言模型 (SLM)，专门针对 ChatGPT 生成的儿童故事进行训练。这些模型使用简单而连贯的英语，这远远超过了之前在其他同等大小的模型中观察到的情况。</p><p>我希望使用当前可用的可解释性技术可以彻底理解这些模型的大部分功能。这样做将代表机械可解释性（mech interp）发展的一个重要里程碑。</p><p>该 AISC 项目的目标是发表一篇论文，系统地识别和描述 TinyStories 模型所展示的功能范围。虽然对底层电路的深入分析超出了当前的范围，但该项目代表了朝着这个方向迈出的重要的第一步。</p><p>清楚地了解这些模型的功能将鼓励研究界随后通过分析负责的电路来建立这些发现。这将进一步发展 mech interp，并提供有关语言模型内部工作方式的见解。</p><h1>动机</h1><h2>我的机甲解释变革理论</h2><ul><li>我对<a href="https://www.alignmentforum.org/posts/mcnWZBnbeDz7KKtjJ/rsps-are-pauses-done-right"><u>RSP</u></a>和<a href="https://www.alignmentforum.org/posts/LwJwDNFhjurAKFiJm/theories-of-change-for-ai-auditing"><u>审计</u></a>持乐观态度；简而言之：<ul><li>根据系统的危险能力和可证明的一致性来限制系统的训练、部署等</li><li>使用行为评估来测试危险能力</li><li>使用基于理解的评估来测试一致性</li></ul></li><li>我们还不知道如何进行基于理解的评估</li><li>当我们达到一定程度的危险能力时，我们要么<ul><li>继续并冒着灾难的风险或</li><li>停止并承担巨额调整税<ul><li>这对我来说没问题，但这使得监管实施的可能性降低</li></ul></li></ul></li><li>Mech interp 是一种很有前途的基于理解的评估方法</li></ul><h2>充分理解模型与逆向工程特定功能</h2><ul><li>目前，研究人员对平易近人或他们感兴趣的功能进行逆向工程；一些问题：<ul><li> “平易近人”默认缺少困难问题（我们甚至不知道它们是什么）</li><li> “有趣”可能并不是最相关的</li><li>它几乎普遍在狭窄的发行版上完成，并且没有提供对所涉及组件的一般理解</li></ul></li><li>相反，我们可以<ul><li>尝试对模型在训练数据集上表达的每项功能进行逆向工程<ul><li>如果我们失败了，我们只是发现了一个具体的开放问题</li></ul></li><li>对于每个组件，列出它负责的所有功能</li><li>识别功能未知的组件<ul><li>它们可能与安全直接相关<ul><li>例如对战略欺骗负责</li></ul></li><li>或者强调一些我们还不了解的架构</li></ul></li></ul></li><li>最终，我们将对每个模型组件有一个大致的了解</li><li>我承认这是非常雄心勃勃的，拟议的项目只是朝这个方向迈出的第一步</li></ul><h2>为什么选择小故事？</h2><ul><li>模型和数据集都是开源的</li><li>模型很小，参数在 1 到 3300 万之间<br>“ <i>[...] 专注于小型模型的机械插补工作就很好，而且对于更快的反馈循环来说非常值得”</i> <a href="https://www.lesswrong.com/posts/Av3frxNy3y3i2kpaa/does-circuit-analysis-interpretability-scale-evidence-from#:~:text=focusing%20on%20mech%20interp%20work%20on%20small%20models%20is%20just%20fine%2C%20and%20extremely%20worth%20it%20for%20the%20much%20faster%20feedback%20loops"><i><u>~ Neel Nanda</u></i></a></li><li>该数据集小而简单，包含不到 2GB 的文本和大约 10,000 个独特的标记。此外，每一个准确的下一个代币预测对于人类来说都是逻辑上合理的；这些只是3-4岁孩子的故事</li><li>它们展现出的能力超出了人类在代码中可以实现的能力<br><i>“许多手动机械解释工作主要侧重于对更大模型的扩展解释，而不是更复杂的任务或综合解释，我认为后者更重要。”</i> <a href="https://www.lesswrong.com/posts/6FkWnktH3mjMAxdRT/what-i-would-do-if-i-wasn-t-at-arc-evals#Technical_AI_Safety_Research:~:text=A%20lot%20of%20manual,of%20the%20neural%20networks"><i><u>~ 陈劳伦斯</u></i></a></li></ul><h2>为什么现在才做评估？</h2><ul><li>风险<ul><li>可解释性是困难且开放的</li><li>我们将只是一个兼职的初级研究人员小团队</li></ul></li><li>杠杆作用<ul><li>通过创造大量的可解释性挑战，我们可以挖掘众多独立机械解释研究人员的潜力</li><li>我希望这对机械解释的作用就像 OpenAI Gym 对强化学习所做的那样</li></ul></li></ul><h1>涉及的步骤</h1><h2>识别能力</h2><p>从能力最差的模型开始。</p><ol><li>收集 TinyStories 验证数据集上正确的下一个标记预测的概率</li><li>可视化模型正确且对下一个标记预测充满信心的样本</li><li>识别最简单和最常见的模式或功能</li><li>过滤表达已识别能力的样本</li><li>返回步骤 2</li></ol><p>对下一个模型重复此操作，但过滤两个模型都正确且有信心的所有案例，以仅突出显示新功能。</p><h2>表征能力</h2><p>对于每个已确定的能力：</p><ol><li>尝试对功能进行红队<ol><li>你认为文本的哪些特征使得行为呈现出来？</li><li>有没有这种行为不存在的例子？</li><li>它适用于合成示例吗？</li><li>您可以在文本中更改哪些内容并仍然看到相同的结果？</li></ol></li><li>将其定义为一个任务，或一组（提示，正确答案）对</li><li>通过测量来评估每个模型在任务上的性能：<ol><li>正确答案的概率</li><li>正确答案的排名</li><li>如果有一个明显的错误答案：Logit different_answer and bad_answer</li></ol></li><li>总结结果<ol><li>能力是什么？</li><li>为什么学习有用？</li><li>哪些模型能够执行该任务？</li><li>所有示例的性能是否一致？如果不是，它们之间有什么不同？</li><li>变压器如何实现此功能？</li><li>所有模型在任务上的表现都一样好吗？如果不是，为什么会这样呢？</li></ol></li></ol><h2>写论文</h2><p>论文的结构和主要信息将取决于研究结果。我们应该在项目的第二个月开始写作。这将有助于巩固我们的理解，并将进一步的研究引向最有希望的方向。</p><h1>风险和缺点</h1><p>有一个很小的风险</p><ol><li>我们开发的识别能力的工具最终将支持能力工作</li><li>对我们确定的能力进行进一步的可解释性研究将激发新的见解</li></ol><p>请参阅<a href="https://www.alignmentforum.org/posts/iDNEjbdHhjzvLLAmm/should-we-publish-mechanistic-interpretability-research#Capabilities_externalities_of_mechanistic_interpretability"><u>我们应该发表机械可解释性研究吗？</u></a><u> </u>在广泛分享我们的工作之前，我们将寻求资深研究人员的建议。</p><h1>致谢</h1><p>我要感谢<a href="https://www.lesswrong.com/users/linda-linsefors?mention=user">@Linda Linsefors</a> 、 <a href="https://www.lesswrong.com/users/arthur-conmy?mention=user">@Arthur Conmy</a> 、 <a href="https://www.lesswrong.com/users/lucia-quirke-1?mention=user">@Lucia Quirke</a>和<a href="https://www.lesswrong.com/users/cmathw?mention=user">@cmathw</a>对此提案的反馈。我要感谢 Lucia Quirke、Lovis Heindrich 和<a href="https://www.lesswrong.com/users/rgrgrg?mention=user">@RGRGRG</a>分享他们对 TinyStories 的初步研究。</p><h1>团队</h1><p><strong>团队规模：</strong> 3-5 人（包括我自己），具体取决于他们的时间投入。这个问题有很大的表面积，人们可以轻松地并行工作。</p><p><strong>研究负责人</strong><br><a href="https://www.lesswrong.com/users/jett?mention=user"><strong>@杰特</strong></a><strong> </strong>（有任何问题请随时私信我）</p><p>在 Neel Nanda 的指导下，我参加了<a href="https://www.matsprogram.org/"><u>MATS</u></a> 2023 年冬季队列机械实习组。我合着</p><ol><li><a href="https://www.lesswrong.com/posts/u6KXXmKFbXfWzoAXn/a-circuit-for-python-docstrings-in-a-4-layer-attention-only"><u>4 层注意力变压器中的 Python 文档字符串电路</u></a></li><li><a href="https://arxiv.org/abs/2310.07325"><u>直接 Logit 归因的对抗示例：gelu-4l 中的内存管理</u></a></li><li><a href="https://www.lesswrong.com/posts/nuJFTS5iiJKT5G5yh/polysemantic-attention-head-in-a-4-layer-transformer"><u>4 层 Transformer 中的多语义注意力头</u></a></li></ol><p>项目 1 和 3 涉及大量的能力识别和特征描述，类似于我对此 AISC 项目的设想。在项目 2 和 3 中，我担任研究负责人/导师，并收到了积极的反馈。我承诺每周至少花 10 个小时来完成该项目。</p><p><strong>团队协调员：</strong>我更喜欢其他团队成员来担任这个角色。</p><p><strong>技能要求</strong><br>必需的：</p><ul><li> Python：模块、defaultdicts、计数器、迭代器、数据类、f 字符串</li><li>Jupyter 笔记本</li><li>Git：提交、分支、合并、解决冲突</li></ul><p>很高兴有：</p><ul><li>火炬</li><li>抱脸</li><li>变压器镜头</li><li>阴谋</li><li>机甲解释经验</li><li>研究经历</li></ul><p>很高兴拥有我所缺乏的：</p><ul><li>技术写作</li><li>网络开发：HTML、CSS、JS</li></ul><h1>附录</h1><h2>TinyStories 1M 中观察到的一些功能</h2><ol><li>N-gram<ol><li> <code>Once upon a <strong>time</strong></code></li><li> <code>From that day <strong>on</strong></code></li><li> <code><u>av</u> oc <strong>ados</strong></code></li></ol></li><li>重复的标记<ol><li><code>a big <u>house</u> with a lot of rooms. The <strong>house</strong></code></li><li> <code>there was a big <u>garage</u> [...] they needed more space in the <strong>garage</strong></code></li><li> <code>girl named <u>Lily</u> . [...] As they drove down the road, <strong>Lily</strong></code></li></ol></li><li>重复的多标记名称（归纳？）<ol><li> <code>a big, hairy rabbit named Bon <u>go</u> . Bon <strong>go</strong></code></li><li> <code>a little fish named Nem <u>o</u> . One day, Nem <strong>o</strong></code></li><li> <code>mouse named Tim <u>my</u> . He lived in a cozy hole in the wall of a big house. Tim <strong>my</strong></code></li></ol></li><li>常用短语（跳过卦？）<ol><li> <code>see <i>something</i> up <strong>close</strong></code></li></ol></li><li>具有不同标记化的复数到单数<ol><li><code>went to see the ze <u>br</u> as, Lily saw a unique z <strong>ebra</strong></code></li></ol></li><li>了解刚刚提供了背景，现在是讲故事的时候了<ol><li><code>Once upon a time, in a big forest, there lived a rhinoceros named Roxy. Roxy loved to climb. She climbed trees, rocks, and hills. <strong>One</strong></code></li><li> <code>Once upon a time, in a small yard, there was a small daisy. The daisy had a name. Her name was Daisy. Daisy was very small, but she was also very happy. <strong>\n</strong></code></li><li> <code>Once upon a time, there was a big, heavy alligator. He lived near a small pond. He was very hungry and wanted to eat something.\n\n <strong>One</strong></code></li></ol></li><li>知道何时结束报价<ol><li><code>Kitty smiled and replied, &quot;Thank you, Spot. I polish it every day <strong>.&quot;</strong></code></li><li> <code>Billy saw that Roxy was sad and asked, &quot;Why are you sad, Roxy <strong>?&quot;</strong></code></li><li> <code>The cow said, &quot;I am lonely. I want a friend <strong>.&quot;</strong></code></li></ol></li><li>代词<ol><li><code>Tim went to <strong>his</strong></code></li><li> <code>So, Mia and Tom played together. <strong>They</strong></code></li><li> <code>bought some light bulbs. When he came back, he put <strong>them</strong></code></li><li> <code>lemon on the ground. He wanted to play with <strong>it</strong></code></li></ol></li><li>预测相关概念： <code>bookshelf [...] <strong>book</strong> , park [...] <strong>grass</strong> , forgive [...] <strong>happy</strong> , lunchtime [...] <strong>eat</strong> , zebra [...] <strong>stripes</strong> , tree [...] <strong>climb</strong> , nurse [...] <strong>bandage</strong> , monkey [...] <strong>jungle</strong> , shop [...] <strong>counter</strong> , laundry [...] <strong>clothes</strong> , inside [...] <strong>goodbye</strong> , octopus [...] <strong>ocean</strong> , lost [...] can <strong>&#39;t</strong> , road [...] <strong>driving</strong> , emergency [...] <strong>doctor</strong> , milk [...] <strong>spilled</strong> , hammer [...] screw <strong>driver</strong> , Daddy [...] Mom <strong>my</strong></code></li><li>间接对象​​识别<ol><li><code>Spot saw the shiny car and said, &quot;Wow, Kitty, your car is so bright and clean!&quot; Kitty smiled and replied, &quot;Thank you, <strong>Spot</strong></code></li><li> <code>Buddy kicked the ball with his strong legs. The ball flew into the goal! Spot was so happy. He and <strong>Buddy</strong></code></li><li> <code>One sunny day, Amy went to the yard with her friend, Max. Max saw the purple swing and said, &quot;Wow! I want to swing too!&quot; <strong>Amy</strong></code></li></ol></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/aHE6rejJEkWspwnKu/aisc-project-tinyevals#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/aHE6rejJEkWspwnKu/aisc-project-tinyevals<guid ispermalink="false"> aHE6rejJEkWspwnKu</guid><dc:creator><![CDATA[Jett]]></dc:creator><pubDate> Wed, 22 Nov 2023 20:47:32 GMT</pubDate> </item><item><title><![CDATA[so you want to save the world? an account in paladinhood]]></title><description><![CDATA[Published on November 22, 2023 5:40 PM GMT<br/><br/><blockquote><p>奥罗登给了我成为一名圣战士的力量，也给了我明智地选择战斗的智慧……并帮助我变得足够强大，以拯救每个人，真正的每个人，并且不要让我的力量伴随着对弱者的蔑视，或我的智慧，蔑视愚蠢……并照顾每个人……在这个陌生的国家，在你去过的所有世界和你没有去过的所有世界。</p><p>并使地狱停止。</p></blockquote><p> – Iomedae，奥罗登圣骑士；<a href="https://glowfic.com/replies/1974491#reply-1974491">摘自林塔曼德的发光小说“<em>在他的力量下，我将敢、敢、敢，直到我死</em>”</a></p><h1>介绍。</h1><p>几年前，我努力让自己思考如何协调，而不是制作视频游戏和阅读同人志。今天，我发现我的尊严点输出的主要剩余瓶颈是我的体力，并且我可能会对p（doom）产生实际的重大影响。</p><p>这篇文章是关于我如何到达那里的。它是用祈使时态讲述的，因为我希望这可以作为建议；但请注意，人类的思维空间是多种多样的，即使在错误较少的理性主义者中也是如此，对我有用的东西可能对你不起作用。 （也就是说，看起来并没有很多人在努力争取圣骑士或类似的职位。）</p><h1>什么是 iomedae？</h1><p> （如果你不知道什么是发光小说，也许可以看看<a href="https://recordcrash.substack.com/p/mad-investor-chaos-woman-asmodeus">尤德科夫斯基和林塔曼德的发光小说<em>《飞机坠毁》</em>的评论</a>。）</p><p>在涉及 linta!golarion 的发光小说中（lintamande 对<em>golarion</em>的诠释，桌面 RPG<em>探路者</em>的背景），iomedae 是“击败邪恶”的守序善良女神——或者，正如<a href="https://glowfic.com/replies/1966069#reply-1966069">lantalótë 所说</a>：</p><blockquote><p>艾奥梅黛是一位善良的女神，但她不是其中任何一位女神。她不是美好事物的女神。她是<em>优先考虑</em>的女神，她看着世界的所有恐怖，并说“以后会有足够的时间来爱、美丽、欢乐和家庭。”但首先我们必须让世界对他们来说是安全的。”</p></blockquote><p>在成神之前，艾奥梅黛是文明之神奥罗登的<em>圣骑士</em>。林塔曼德的各种发光小说在不同的场景中都有出现，但<a href="https://glowfic.com/replies/1974491#reply-1974491">“<em>在他的力量下，我会敢、敢、敢，直到我死</em>”</a>特别讲述了她成为圣骑士后不久，在美国获得异世界，然后被儿童保护机构收养服务，并试图了解她所出现的这个奇怪的世界，以及在那里做好事对她意味着什么。</p><p> （在这篇文章中，当我粘贴引用而不提及其来源时，其来源将是那个特定的发光小说。）</p><h1> “圣骑士”是什么意思？</h1><p>对<em>我</em>来说，林塔! 奥梅黛的圣骑士身份代表<em>着全心全意地致力于做重要的事情；不惜一切代价拯救世界</em>。她的圣武士身份——也就是说，<em>她作为一名圣武士的身份</em>——并不是她所承受的<em>负担</em>；而是她所承受的。这是她内心深处<em>想做的</em>事。</p><p>我<em>会</em>高兴地按下一个按钮，立即将我的思维方式转变为 iomedae 的思维方式；我深思熟虑后决定成为一个不惜一切代价拯救世界的人，即使自己付出巨大的代价。但人类的大脑是一种奇怪的装置！我们没有这样的按钮；如果我们想改变自己，就必须付出很多努力。</p><p>我发现自己现在大部分时间都在努力工作的另一边，对自己现在的成就感到满意。七年前，当我第一次熟悉序列和其他理性主义作品时，我没有经历过这一切，这是极大的浪费。但我不会纠缠它，因为纠缠它实际上无助于拯救世界。</p><p> （请注意，当我决定努力拯救世界时，我最初并没有意识到圣骑士的概念。这是我事后才了解到的，并且认为它很适合我，作为一种美学.我的大脑非常喜欢美学和叙事；拥有一个可以认同的原型可以帮助我向自己和他人具体化我想要的东西。）</p><h1>人类的思维和序列</h1><p>人类的思维真是<em>太奇怪了</em>。</p><p>例如：我希望如果我将这篇文章描述为“你<em>应该</em>想要拯救世界，那么这就是方法”，而不是“<em>如果</em>你想拯救世界，那么这就是方法”，一群目前正在使用的人相反，拥有此帖子的董事会会感到受到攻击，并通过寻找借口拒绝此帖子的内容来做出反应。</p><p>需要大量的<strong>认知纪律</strong>和<em>认知卫生</em>*来检验一个命题而不立即以某种方式做出反应。即使是现在，我也不能幸免！</p><p>我们不擅长理性。<strong>这就是<a href="https://www.readthesequences.com/">序列</a>存在的原因</strong>。如果我们完全理性，我们就不需要所有这些艰苦的工作来真正相信真实的事情并采取良好的行动。我们必须训练我们的系统 2 来注意我们何时犯下非理性错误，直到系统 1 最终学会在认知和能动性方面做得更好。</p><p>如果您还没有读过，我认为<strong>您应该<a href="https://www.readthesequences.com/">阅读这些序列</a></strong>。当然，它们远非完美，它们涵盖的很多内容都被认为是常识。但总的来说，我仍然认为这对于那些想要拯救世界的人来说很有价值。引用<a href="https://yudkowsky.tumblr.com/post/81447230971/my-april-fools-day-confession">dath ilan 的原始帖子</a>：</p><blockquote><p>达斯伊兰的任何人都会告诉你这一点。他们读过真实的东西，接受过真正的训练，而不是我能记住并写进序列的可怕的混乱。</p></blockquote><p>这些序列比达斯·伊兰的教育材料差得多。但这也是<em>我们拥有的唯一的达斯伊兰神器</em>。</p><h1>圣骑士的核心</h1><p>圣骑士的核心是，在你拥有的每一个自由度上，选择能够最大化效用的选项。非常简单！其他一切都在其下游。</p><p>是的，休息和照顾自己的健康是其下游，因为一个更健康的圣骑士可以拯救更多的世界。是的，拥有一个善待他人的一般原则是其下游，因为一个以善良和乐于助人而闻名的圣骑士往往会拥有更多的资源来拯救世界。</p><p>人类的大脑倾向于寻找借口来拒绝来自外部的论点，敦促人们采取不同的行动或以不同的方式思考。事实上有些人会说这样的话</p><blockquote><p>实际上，你不应该只是最大化效用，你还应该休息一下，这样你才能健康，所以这篇文章是错误的，我可以忽略它！</p></blockquote><p>这是非理性地避免采取正确行动的一个例子。再说一次，我自己也经常陷入这个困境，现在仍然如此！目前尚不清楚人类大脑的哪些部分总是试图制造这些借口。</p><p>对我来说，我认为我大脑的一部分认为让别人弄清楚我应该做什么而不是我自己弄清楚在某种程度上<em>是不光彩的</em>。</p><p>但大脑的哪一部分负责这些借口并不特别重要。重要的是<em>注意到一个人正在产生它们</em>，并<em>养成不这样做的习惯</em>。</p><p>我认为<em>不必改变的借口</em>实际上是人们选择相信人工智能绝对不能杀死所有人，或者人工智能杀死所有人的一个非常深刻的原因。这些信念并不是根本的事情；他们在内心深处<em>寻找借口，避免自己犯错，避免改变自己的行为或信念</em>。 （注：感觉人们不愿意改变他们通常不做的领域的行为或信念，这可能从根本上是执行功能障碍的一种形式？执行功能似乎<strong>非常重要</strong>。）</p><p>如果你想拯救世界，最大化效用（使用<a href="https://arbital.com/p/logical_dt/">正确的决策理论</a>）<em>实际上完全抓住了重要的事情</em>。并不是说你必须通过实际数学来比较效用；大多数时候，我很清楚哪个选择是最好的。最终，效用最大化是一个<em>订购</em>问题，而不是<em>数量问题</em>：您不需要计算出一个选择的最佳选择<em>有多少余量</em>，您只需要知道它是最好的选择。</p><p>哦，显然，不要完全放弃所有规则功利主义/义务论指导方针。这是合理性的一部分，但值得重复。我的主张并不是说你应该选择感觉“天真的”看似最佳的行动，而不是合理的规则功利主义启发法所建议的行动；我的主张是，你应该引导你目前所采取的行动保持现状/什么是最简单的/什么是最舒适的/什么是其他人说的/无论什么。</p><p>您应该对所有行动都有<em>意图</em>，并检查您是否错过了可以采取的一些重要行动。这个意图可以是“啊，是的，我的认知资源的最佳分配就是在这里应用规则功利主义启发法”——但它应该是<em>某种意图</em>。</p><h1>等等，这里有什么新内容？</h1><p>这篇关于“圣骑士”的文章可以被解释为只是对常规的不太错误的理性主义后果论的重新包装。</p><p>有点像！但我觉得我们现在可以使用一个新的软件包，其中有一些有用的建议。</p><p>不，你不必特别关心“圣骑士身份”，因为你可以成为拯救世界的人。但如果对叙事的认同<em>确实能</em>像我一样帮助你的思想融入角色，那么我希望像“圣武士”这样的东西有希望。</p><p>很可能，像林塔！格拉里昂这样的圣骑士与我不同。在我生命的前 28 年左右，我确实把事情看得很轻松，根本不分轻重缓急——甚至许多<em>地球人</em><a href="https://www.lesswrong.com/posts/F2DZXsMdhGyX4FPAd/on-saving-the-world#Deciding_to_Save_the_World">都有更长的<em>关心</em>和<em>尝试</em>的历史</a>。</p><p>我之所以决定采用这种叙述，并不是因为我认为我比其他人更值得这样做——我采用它是因为它<em>可以帮助我的大脑做这件事</em>。</p><p>我试图做出最能拯救世界的选择，结果发现其中之一就是受发光小说角色的启发而进行模糊的角色扮演。</p><h1>特权</h1><blockquote><p>大多数圣骑士都很富有，真的，因为你需要盔甲和剑，而只有有钱人才有这些，你需要让一个强壮健康的孩子去为奥罗登服务一生，绝望的家庭离不开一个坚强健康的孩子。</p></blockquote><p>有些人比其他人更有能力拯救世界。当我开始尝试拯救世界时，我（排名不分先后）：</p><ul><li>心理和身体都非常健康</li><li>高水平的智力，沿着一些似乎很重要的轴</li><li>熟悉与对齐相关的计算机科学领域，以及强大的软件工程技能</li><li>阅读了<a href="https://www.readthesequences.com/">序列</a>、<a href="https://slatestarcodex.com/2014/07/30/meditations-on-moloch/">对莫洛赫的沉思</a>以及各种其他理性主义非小说作品</li><li>近二十年来一直以各种方式思考超级智能</li><li>拥有良好福利和公共医疗保健的富裕西方国家的公民身份和居住权（法国）</li><li>有足够的金钱和节俭的技巧，可以有<em>一些</em>物质上的余裕</li><li>让我听说并进入<a href="https://www.lesswrong.com/posts/D7epkkJb3CqDTYgX9/refine-an-incubator-for-conceptual-alignment-research-bets">Fine</a>研究孵化器的社会关系</li><li>一些非常聪明且非常支持的朋友关系，并且对理性主义社区有深入的了解</li><li>一直在训练我的大脑练习<em>一些</em>认知/模因卫生；引用恶魔的话说：“您的思想是反认知偏见保障的迷宫，是吗？”</li><li>傲慢/自恋的历史使我有信心认为我可以帮助您保持一致，并克服了我的一些冒名顶替综合症</li><li>足够好的社交技能</li><li>能够写得很好的能力</li><li>我自己的平台（<a href="https://carado.moe/">我的博客</a>）和关于其中一些相关主题的撰写历史（对价值观，人类和计算宇宙学的研究），以及通常对这些主题的混乱水平较低</li></ul><p>不要误会我的意思，我也有一些障碍，其中一些特权是我一生中选择正确的选择而获得的。</p><p>因为我的目标是拯救世界，所以我将这篇文章的目标瞄准了那些更有可能帮助拯救世界的人。</p><p>如果您发现自己足够毫无疑问地拯救世界对您来说非常困难，我不确定要提供什么建议，对不起。有些人将有足够的时间，因为他们照顾自己比尝试解决一致性更好。你也是一个道德病人！成为圣骑士并不能使您比其他人<em>更少</em>成为道德患者，这仅仅使您意识到自己和其他人<em>一样多</em>。</p><p>请注意，许多人倾向于<a href="https://www.lesswrong.com/posts/XkmG8XGf6uhXLmZN7/so-you-think-you-re-not-qualified-to-do-technical-alignment">高估了对技术一致性有多高的标准</a>。这很容易成为您的情况。</p><h1>空字符串，内视图与外视图</h1><p>尤德科夫斯基（Yudkowsky）著名地提到他对AI的批判性信念源自（ <a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities?commentId=GyFidKQtqFjptmq2i">几乎</a>）<a href="https://twitter.com/ESYudkowsky/status/1500863629490544645">空字符串</a>- 也就是说，他不需要令人信服的从外面说服，他只是想到了这件事，并得出了他的结论。做过。我相信我在这方面与他相似。</p><p>具有内部视图，对您有意义而不是仅仅相信他人的信念非常重要。</p><p>假设您担心动物痛苦。您应该意识到，到目前为止，将对未来遭受的痛苦的动物产生最大的影响是由不可避免地占领世界的AI决定的，然后您应该决定从事<em>某事</em>。<em>这影响了不可避免地占领世界的AI的AI</em> 。</p><p>这项工作可以是直接的（构建为拯救世界的AI结合）或间接的（试图使试图解决一致性的人们获得足够的时间和资源，以在人权地尝试到杀害杀人的情况下取得成功建立a-ai-ai kills-everyones成功）。但是，对于这<strong>两者</strong>，您<strong>应该</strong>非常努力地对您期望需要多长时间有深刻的了解，直到有人构建杀死所有人的AI，以及建立拯救世界的AI的AI所需的内容。</p><p>如果您不了解什么样的人工智能会杀死所有人，那么什么样的人工智能会拯救世界，什么样的人工智能也不会这样做（因此，只有在影响前两个的概率时才有意义）然后，您无法知道<em>哪个是哪个</em>。</p><p>人们喜欢依靠<em>外部观点</em>- 基于他人的信念，基于敏感性，敏感性，稳态，态度和彻头彻尾的氛围的混合，因为这为他们节省了思考问题的辛勤工作，并且因为他们为他们省下了艰苦的工作想出自己的信念时会感到冒名顶替。这导致了大量的<a href="https://www.readthesequences.com/Fake-Causality">双重计数</a>，在某种程度上，我发现<a href="https://carado.moe/outside-view-double-counting.html">漫画</a>最容易说明。</p><p>您<em>可以</em>考虑他人的意见，但是您的标准应该是他们似乎有多少<em>认识论严谨和认知卫生</em>- 您需要认识的严谨和卫生自己，以确定谁行使良好的认知严谨和卫生，您应该小心双重谨慎当您的一个消息来源说些什么时，计算主张是因为他们从您的<em>另一个</em>来源听到了。</p><p>具有认知卫生的需要，包括：不容易容易出现模因，社交压力和其他选择效果，从而导致了过滤的证据问题。有关认识严谨的更全面的培训，<a href="https://www.readthesequences.com/">请咨询序列</a>。</p><p>确实，最安全的是自己建立一个坚实的内部视图模型，并且主要依靠它。</p><p>同样，人类的思想非常容易受到社会压力，包括信念。如果像我一样 - 您有倾向于假定系统-1，人们知道他们在使用自信的语气时所说的话，那么您应该非常小心，只能与<em>实际</em>使用自信的人一起闲逛 -音调表达其实际信心 - 持有的wheir-wheir-and-confusions。</p><p>使我相信别人说的是拥有良好的认识论，而不是他们不诚实。在AI安全领域，有很多错误，这几乎是非理性而不是对抗性的所有结果。</p><p>开发坚实的内部视图并保持良好认知卫生的一种安全方法是<em>，根本不说话/听到/读取AI</em> 。虽然不是故意的，但这是我自己实施的策略：我独自思考了这个话题，而没有真正的研究或Lesswrong，这使我摆脱了社交压力，以至于我终于开始阅读Lesswrong和与对准研究人员交谈时，我已经对AI Alignment和AI厄运制定了自己的全面看法。然后，我检查了我对他人的信念，更新论点对我很有意义，并且非常重要的<strong>是，当我观察人们不同意时，我的信念是因为他们没有考虑我一直在考虑自己的事情</strong>。</p><p>但是，如果您看到一个人说的话对您没有意义，那么您应该更新更新，就像您看到<em>一百人</em>说同样的话一样。通过连贯性而不是重复权衡争论，并根据其认识论的质量而不是通过其身份来权衡人们的权衡。</p><p>另外，当您听到索赔时，您还应该注意到他们所说的索赔<em>很重要的</em><em>隐性</em>主张。您应该注意到这种隐性主张，并考虑它是否有意义，以及它是否来自认识论卫生和严格的地方。而且，如果不是这样，那么您不需要<em>花费努力思考这个无关紧要的话题</em>，而不管有多少人在谈论它。</p><p><em>经纪人</em>- 正在<em>努力</em>拯救世界的人 - 将<em>考虑</em>并<em>意图</em>他们选择说的话。他们的信息不仅仅是在说什么，这是他们选择说的话，这就是他们选择说的方式。引导世界，包括通过指导您的想法和谈论，并更少注意那些没有特别确保他们在指导自己在说什么的人。</p><p>另请参见<a href="https://www.lesswrong.com/posts/PqMT9zGrNsGJNfiFR/alignment-research-field-guide">Miri的Alignment Research Field指南</a>的这一报价：</p><blockquote><p>我们为什么选择编写此文档？我们从中有什么期望，是什么促使我们从所有可能性中选择这种特殊的格式和内容？</p></blockquote><p>这就是为什么代理/执行功能如此重要的原因。您可以成为某些主题的天才，但是如果您不<em>针对</em>正确的事情，那么您本质上只是在挖沟。为了拯救世界，您必须引导世界，包括您的想法和所说的话。</p><h1>成为一个直接，认真，合理的理性主义者</h1><p>有很多借口可以做一个奇怪的莱斯沃·理性变体，就像有<a href="https://www.glowfic.com/replies/1839717#reply-1839717">理性主义者的异常分支一样（Link具有Planecrash扰流板）</a> 。</p><p>此外，具有讽刺意味的是人们最喜欢的借口之一，不必改变主意或行动 - 如果您找到了一种不认真对待的方法，如果这种方式<em>被Ambiant Memeplex认为很酷</em>，那么您就发现了一个非常舒适的甚至不<em>怀疑</em>您是否应该改变主意或行动！</p><p>但是，不，常规的少曲理性实际上是正确的事情，如果<em>有</em>一种氛围 - 植物学 - 美学确实<em>会</em>促进诚意，至少完全<em>允许</em>认识论严格，那就是一种<strong>直接，严肃，合理的理性主义者</strong>。避免模​​因，深奥的东西，老鼠崇拜，讽刺等。</p><p>人类的思想<em>喜欢</em>锁定<em>美学</em>或<em>模仿的</em>事物，而不是<em>真实的</em>事物。保持认识论安全的方法是练习良好的记忆卫生，而不是将大脑暴露于您<em>知道</em>大脑会因与<em>实际真理</em>无关的变量而诱使大脑的事物。</p><p>不要试图<em>面对模因，并评估其真实价值不管</em>。那是愚蠢的。这就像使自己陷入尽可能多的疾病以变得强大的疾病一样，这不是它的工作原理。</p><p>但是，您不必离开{关心美学的一部分}饿了！作为一个直接，认真，合理的理性主义者是它自己的审美 - 实际上，理性主义小说在理性主义者社区中扮演的​​有益角色：这<em>使得</em>{成为一个直接，认真，合理的理性主义者}适应。</p><p>如果您像动漫角色一样，您会在动漫中获胜，而在现实生活中输了。<br>如果您像一个拉特奇奇的角色一样，您会赢得Ratfic <strong>，并在现实生活中获胜。</strong></p><p>记忆是他们的本质，您的想法当然<em>很想</em>从事所有废话。保持认识论卫生的持续努力可能需要持续的努力。但总的来说，这<em>是</em>允许如何拯救世界的一个原因，这是拯救世界所需的。</p><h1>尝试磨</h1><p>人类思想的一种质量是它的可塑性。我注意到，当我第一次试图成为圣骑士时，我的思想具有抵抗力 - 它想要坚持其美德伦理，即使在后果最佳选择明显不同的情况下也是如此。克服我对美德伦理的依恋以及我学会过一生的其他各种方式，花了很多努力。</p><p>但是我之后意识到的是，在抵抗时，它也慢慢地屈服了 - 几个月后，我发现采取后果主义者的行为变得容易得多。</p><p>我发现这也适用于重点，严谨和耐力。</p><p>与RPG类似，如果您挑战了自己的限制，那么您实际上会有所改善。</p><p>当您选择做舒适的事情或做正确的事时，这也可能会激发它 - 如果您做正确的事，不仅会产生更多的公用事业，而且还会有一些更轻松的时间来选择正确的选择在以后的情况下。</p><p>可以休息一下，如果您将自己推得太多 - 您不想燃烧。这是一个谨慎的平衡。我发现，如果我将自己推到<em>少量的</em>倦怠中，我可以在几天的休息时间恢复过来 - 所以我实际上有一个安全网，以防万一我太努力地推动自己。</p><p>也许只是我，我注意到EA/Rat Circles中的一些污名，<em>努力努力</em>。有些人非常反对我们应该更加努力的情绪。不用说，我不同意。努力努力<em>改善您可以舒适地推动自己的距离</em>。</p><p>如果您磨碎XP，则升级并增加最大HP。而且，如果您的HP足够低，您总是可以回来休息。</p><p>休息是一项技能。这些天，我觉得我何时应该停止工作有些很好。在那些日子里，我实际上<em>整天都设法完全不工作</em>。</p><h1>如果只有你知道…</h1><p>请注意，您有多困惑，并推断他人可能有多困惑。</p><p>请注意，您花了多少精力专注于重要的事情而不分散注意力或书呆子，并推断别人专注于正确的事物的可能性以及他们所说的可能会分散注意力/nerdsnipe的可能性。</p><p>请注意，您需要花费多少努力来扣留大量的exfohazards信息，并推断出其他人泄漏与他们共享的信息的可能性。</p><p>请注意，您需要<em>在认识上进行认识，认识论上的安全性，<a href="https://intelligence.org/2017/11/25/security-mindset-ordinary-paranoia/">安全性的工作，以</a></em>确保您的对齐方式保持稳定，并推断出对人类工作的行为的可能性有多大的可能性正确实施对齐。</p><p>请注意，作为那种试图拯救世界而不屈服于讽刺，模因，犬儒主义或其他借口来忽略艰难部分并推断出<em>真正的坏事的人是多么</em>困难。</p><p>当你这样做时，<a href="https://www.glowfic.com/replies/1751366#reply-1751366">不要惊慌</a>。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Qw6qsgR2Qm6rp574A/ow8axpjx6xeg9jtma2am" alt=""></p><p>指导世界的一部分是指导自己，而定型自己的一部分是指导自己的感受。是的，事情很糟糕，但是陷入困境并不能使您更好地拯救世界。是的，这让人感到不公正和沮丧的是，拯救世界免于某些白痴的愚蠢的负担落在了这么少的肩膀上，但是在这些不公正和沮丧的感觉中却却无济于事。</p><p>是的，不得不丢弃这些感觉并做对的事情是不愉快的。非常不愉快！在我看来，这就像我非常重视的个性的核心部分受到攻击。</p><p>但是后来我推动了自己的一堆，最终侵蚀了我的那一部分，现在我是一位试图拯救世界的结果主义者。当<a href="https://carado.moe/rationalist-by-necessity.html">我不再需要工具理性</a>的时候，我可以回到乌托邦的有趣的愚蠢的情感自我，我可以<a href="https://www.lesswrong.com/posts/CMHogeqTTajhmnEKx/everything-is-okay">再次轻松</a>。</p><p>但是目前，如果您要成为圣骑士，则必须面对现实。为了做出正确的决定，您必须能够面对实际情况。</p><p>但是，如果您是圣骑士，那么您也会得到一些好消息：还有一位圣骑士试图拯救世界！</p><h1>您的道德耐心</h1><p>有些人面对严重的人，决定其他人比自己更重要，并且他们已经提出了人格或道德耐心。</p><p>我认为那是错误的。</p><p>当人们认为他们“为每个人拯救世界<em>，</em>除了为此签约的人都拯救了世界时，都有一个根本的错误。”这是出于某种原因”）。这里从根本上误会了。</p><p>我认为，圣骑士应该认为自己和其他人<em>一样多</em>。</p><p> “如果您认为自己是一个人/道德患者，那么<em>侵蚀自己的一部分</em>就可以做得可以吗？”</p><p>好吧，确实有三个原因。首先是这些是特殊的情况，在平衡上如此多，以至于人们知道自己在做什么以及是否确实有帮助，就可以做到这一点。第二个是我强烈重视自由，包括自由经历这种道路。我不知道我重视<em>任意</em>自由 - 我认为我不应该能够永远签署不可逆转的最大痛苦。值得庆幸的是，拯救世界并不是该价格接近的任何地方！实际上，我的时间仍然比地球上的大多数人要好得多。有些人有自己的大量人生问题要解决，我为拯救世界而努力。</p><p>第三个是，一旦世界拯救了世界，我可能会恢复自己。的确，长期来拯救世界，不仅是对每个人都最好的东西，而且对我来说也是最好的。如果不是，我仍然<em>会</em>拯救世界，如果这意味着我的死亡。但是，不可以，拯救世界<em>实际上是使我不仅使我成为最公用事业的东西，而且是个人最好的生活</em>。</p><hr><p>而且，如果您确实成为圣骑士，那么如果您已经在这篇文章中认出了自己，<a href="https://www.lesswrong.com/users/tamsin-leake">请给我留言</a>。我想和更多圣骑士成为朋友。</p><p>我将结束这篇文章，通过<a href="https://www.glowfic.com/replies/1946079#reply-1946079">在Planecrash（扰流板！）结束的结尾附近链接一对答复</a>。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Qw6qsgR2Qm6rp574A/srafp2q50ratls3mliid" alt=""></p><br/><br/> <a href="https://www.lesswrong.com/posts/Qw6qsgR2Qm6rp574A/so-you-want-to-save-the-world-an-account-in-paladinhood#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/qw6qsgr2qm6rp574a/so-you-want-to-save-the-world-an-an-account-in-paladinood<guid ispermalink="false"> QW6QSGR2QM6RP574A</guid><dc:creator><![CDATA[Tamsin Leake]]></dc:creator><pubDate> Wed, 22 Nov 2023 17:40:33 GMT</pubDate> </item><item><title><![CDATA[OpenAI: The Battle of the Board]]></title><description><![CDATA[Published on November 22, 2023 5:30 PM GMT<br/><br/><p>以前：Openai： <a target="_blank" rel="noreferrer noopener" href="https://thezvi.substack.com/p/openai-facts-from-a-weekend">周末的事实</a>。</p><p>周五下午，Openai董事会解雇了首席执行官Sam Altman。</p><p>一夜之间， <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/eshear/status/1727210329560756598">原则上达成了一项协议</a>，以恢复山姆·奥特曼（Sam Altman）担任OpenAI的首席执行官，最初是布拉德·泰勒（Brad Taylor）的最初新董事会（Salesforce的前委员会，主席），拉里·萨默斯（Larry Summers）和亚当·德·安吉洛（Adam D&#39;Angelo）。</p><p>发生了什么？为什么会发生这样的事？最终将如何结束？战斗还远远没有结束。</p><p>我们并不完全了解，但是我们比几天前更了解。</p><p>这是我将这些碎片放在一起的尝试。</p><span id="more-23600"></span><h4><strong>这是一场控制斗争；奥特曼开始了</strong></h4><p>这是并且仍然是关于控制Openai，其董事会及其方向的斗争。</p><p>这是一场漫长的战斗和辩论。赌注很高。</p><p>直到最近，山姆·奥特曼（Sam Altman）在与董事会发生冲突时努力以自己的形象重塑公司，而董事会几乎没有做。</p><p>虽然我必须强调，我们不知道董事会的动机是什么，但阿尔曼最近的动力可能在迫使董事会的手上发挥了作用。</p><h4> <strong>Openai是一个非营利组织</strong></h4><p>Openai及其董事会的结构对此表示怀疑。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://arstechnica.com/information-technology/2023/11/report-sutskever-led-board-coup-at-openai-that-ousted-altman-over-ai-safety-concerns/?utm_medium=social&amp;utm_source=twitter&amp;utm_social-type=owned&amp;utm_brand=ars">这是Openai结构的图：</a></p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff44095b-3f36-4496-a4bc-f8170140f435_873x652.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sGpBPAPq2QttY4M2H/svrwplczzxeqxbmofw7t" alt="Openai提供的Openai异常结构的框图。"></a></figure><p><a target="_blank" rel="noreferrer noopener" href="https://openai.com/charter">这是OpenAI的使命声明</a>，该链接也有意义的实施细节：</p><blockquote><p>本文档反映了过去两年中我们完善的策略，包括来自OpenAI内部和外部的许多人的反馈。 AGI的时间表仍然不确定，但是我们的宪章将指导我们在整个发展过程中为人类的最大利益行事。</p><p> Openai的使命是确保人工通用情报（AGI）（我们的意思是高度自主的制度，在最经济上有价值的工作中都超越了人类，这会赋予所有人类。我们将尝试直接建立安全有益的AGI，但也将考虑如果我们的工作有助于他人实现这一结果，我们的任务也会实现。</p></blockquote><p> Openai警告投资者，他们可能不会赚钱：</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c2f3d5a-4394-420d-9ab6-f68ceda8291d_661x355.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sGpBPAPq2QttY4M2H/piau5mxtaft2kxuogkwh" alt="图像"></a></figure><p> 501（c）3的作品本质上是董事会对没有人负责的方式。如果您有一次会议的大部分董事会，则可以完全控制董事会。</p><p>但是董事会有权力吗？有点。它具有监督角色，这意味着它可以雇用或解雇首席执行官。董事会通常会利用这种杠杆来有效地负责重大决定。其他时候，首席执行官有效地控制了董事会，而首席执行官会做他想要的。</p><p>一个关键的缺陷是董事会唯一的真正权力是，射击（和招聘）首席执行官以及选择新董事会的组成。</p><p>董事会只有一步。它可以解雇首席执行官，也可以不解雇首席执行官。解雇首席执行官是有可能破坏的主要升级。但是升级和破坏的成本，声誉和财务。知道这一点，首席执行官可以而且经常采取行动，使他们发射痛苦，或者计算出董事会不敢的。</p><h4><strong>山姆·奥特曼的观点</strong></h4><p>尽管他对OpenAi的最终目标更为宏伟，但Sam Altman现在希望Openai与Microsoft合作，主要是一家普通的大型科技公司。他想建造和运输，快速移动并破坏东西。他想开始开展新的商业企业，以拆除瓶颈并获得新的企业， <a target="_blank" rel="noreferrer noopener" href="https://www.bloomberg.com/news/articles/2023-11-19/altman-sought-billions-for-ai-chip-venture-before-openai-ouster">包括计划在阿联酋进行一家沙特资助的芯片工厂，并启动AI硬件项目</a>。他按照自己的商业利益游说，并将其个人权力，估值和资助回合，股东和客户的结合放在首位。</p><p>为此，多年来，他通过加法和减法来重塑公司文化，雇用那些相信这一任务并亲自忠于他的人。他可能已经构建了该公司，以使他自由re绳，并向董事会和其他人掩饰自己的行动。普通首席执行官做正常的首席执行官。</p><p>保罗·格雷厄姆（Paul Graham）在世界上<a target="_blank" rel="noreferrer noopener" href="http://www.paulgraham.com/5founders.html">说的</a><a target="_blank" rel="noreferrer noopener" href="http://www.paulgraham.com/fundraising.html">是强大</a>并<a target="_blank" rel="noreferrer noopener" href="https://x.com/paulg/status/1717097106270237151?s=20">玩强力游戏</a>，所以奥特曼（Altman）非常好。那和扩展技术初创公司是他本性的核心。一个人认为“不完全坦率”和其他战略行动是其中的一部分。</p><p>山姆·奥特曼（Sam Altman）的中间目标从一开始就一直对OpenAI进行全面控制，从而控制了AGI的建设。力量总是想要更多的力量。我不能指责他在他的目标中的理性工具融合。最终目标是建立“安全”的AGI。</p><p>这并不意味着Sam Altman不相信确保AI安全的必要性。奥特曼明白这一点。我认为他不了解它的艰辛或前方的全部困难，但他比大多数人更好地理解了这些问题。他签署了<a target="_blank" rel="noreferrer noopener" href="https://www.safe.ai/statement-on-ai-risk">CAI的信</a>。他<a target="_blank" rel="noreferrer noopener" href="https://www.nytimes.com/2023/05/16/technology/openai-altman-artificial-intelligence-regulation.html">坦率地在国会前作证</a>。与许多捍卫他的人不同，奥特曼了解AGI将是真正的变革，他不希望人类失去对未来的控制。他并不意味着对工作的影响。</p><p>需要明确的是，我确实认为Altman真诚地相信他的方式对每个人都是最好的。</p><p>就在Altman被解雇之前，Altman对两个董事会席位进行了坚定的控制。一个是他的彻头彻尾的。另一个属于格雷格·布罗克曼（Greg Brockman）。</p><p>那留下了另外四名董事会成员。</p><h4><strong>外委员会的观点</strong></h4><p>海伦·托纳（Helen Toner），亚当·德·安吉洛（Adam D&#39;Angelo）和塔莎·麦考利（Tasha McCauley）在Openai的目的和对世界有益的目的方面有着非常不同的看法。</p><p>他们不希望Openai成为一家大型科技公司。他们不希望Openai尽可能快地移动，以训练和部署不断能力的边界模型，并将其雕刻成最大成功的消费产品。他们承认需要商业化以筹集资金，我认为这些产品可以为人们提供巨大的价值，这是很好的。</p><p>他们想要一种更加谨慎的方法，以避免不必要地与其他实验室创建或促进种族动态，或者像我们在Chatgpt之后看到的那样驾驶投资冲浪，这在每个步骤都采取了必要的预防措施。他们希望确保到位，包括政府控制，因为当时AGI出现在线时，以确保我们可以安全地训练和部署它。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.forbes.com/sites/alexkonrad/2023/11/17/these-are-the-people-that-fired-openai-ceo-sam-altman/?sh=287052464ae9">亚当·德·安吉洛（Adam D&#39;Angelo）说，整个要点</a>不是让Openai成为一家大型科技公司。海伦·托纳（Helen Toner）是政策行动以防止生存风险的强有力的拥护者。我<a target="_blank" rel="noreferrer noopener" href="https://www.forbes.com/sites/alexkonrad/2023/11/17/these-are-the-people-that-fired-openai-ceo-sam-altman/?sh=1aaad2384ae9">从我们所知道的</a>塔莎·麦考利（Tasha McCauley）在同一个营地中的想法。</p><h4> <strong>Ilya Sutskever的观点</strong></h4><p>Ilya Sutskever喜欢Openai及其人民，以及建立安全AGI的希望。据报道，他越来越担心直到AGI的时间表可能非常短。据报道，他还担心阿尔特曼（Altman）的行动太快，并且不足以关注风险。他可能会或可能不会掌握有关仍然无力的能力进步的其他信息。</p><p>报道是伊利亚对一致性的态度一直在认识论稳步改善。他正在共同领导超级对准工作队，旨在弄清楚如何使未来的超智能AI保持一致。我对工作组成员听到的一致性不信心，但伊利亚是一名迭代器，我希望时间表并不像他认为和ILYA，ILYA，Jan Leike和他的团队可以在之前弄清楚这一点。筹码必须倒下。</p><p>伊利亚（Ilya）后来<a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ilyasut/status/1726590052392956028?s=20">扭转了局面</a>，在董事会的其余成员完全失去了对叙事和员工的控制权之后，情况可能会撕裂Openai。</p><h4><strong>阿尔特曼（Altman）搬家</strong></h4><p>奥特曼和董事会反复发生冲突。奥特曼继续巩固自己的力量，并确信伊利亚不会反映企图解雇他。但这很紧张。最好让董事会更加清楚地忠于Altman，这是商业任务的更多。</p><p>然后奥特曼看到了一个机会。</p><p> 10月，董事会成员Helen Toner与Andrew Imbrie和Owen Daniels一起<a target="_blank" rel="noreferrer noopener" href="https://cset.georgetown.edu/wp-content/uploads/CSET-Decoding-Intentions.pdf">出版了论文解码意图：人工智能和昂贵的信号</a>。</p><p>该论文正确地指出，尽管Openai进行了昂贵的信号并采取措施确保安全性，但Anthropic会采取更加昂贵的信号，并采取更多步骤来确保安全，并更加强调传达此消息。那不是任何人都可以合理地不同意的事情。该论文还指出，其他人批评了Openai，并说Openai可以而且也许应该做更多的事情。本文中最大的批评是，它断言Chatgpt开始了一场军备竞赛，随后只有Anthropic的Claude之后。这是非常清楚的。 Openai没想到Chatgpt会像这样起飞，但实际上Chatgpt肯定会引发军备竞赛。在某种程度上，这是一个谴责，它正在说明事实。</p><p>但是，这篇论文足够晦涩难懂，如果我看到的话，我丝毫不记得它。这是一个琐事。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.nytimes.com/2023/11/21/technology/openai-altman-board-fight.html?smid=tw-share">据《纽约时报》报道，奥特曼强烈斥责海伦·托纳（Helen Toner）的报纸</a>。</p><blockquote><p>奥尔特曼在电子邮件中表示，他已经就这篇论文对托纳女士进行了谴责，这对公司来说是危险的，特别是在<a target="_blank" rel="noreferrer noopener" href="https://www.nytimes.com/2023/07/13/technology/chatgpt-investigation-ftc-openai.html">联邦贸易委员会正在调查 OpenAI 的</a>数据用于构建其业务的时候。技术。</p><p>托纳女士辩称这是一篇学术论文，分析了公众在试图了解开发人工智能的国家和公司的意图时所面临的挑战，但奥特曼先生不同意。</p><p>他在电子邮件中写道：“我觉得我们对于这一切造成的损害并没有达成共识。” “董事会成员的任何批评都会产生很大的影响。”</p><p>参与对话的人说，高级Openai领导人，包括Sutskever先生， <a target="_blank" rel="noreferrer noopener" href="https://www.nytimes.com/2023/11/18/technology/open-ai-sam-altman-what-happened.html">他非常担心AI可能有一天会摧毁人类</a>，后来讨论了是否应删除Toner女士。</p></blockquote><p>从我的角度来看，即使在这里斥责碳粉也很糟糕。与非营利组织的使命完全不一致，不允许辩论，分歧和批评。我不同意Altman的观点，即Toner的论文“承受了很多重量”，我质疑Altman是否相信这一点。但是，即使纸确实承担了重量，如果我们不能公开讲话，我们也不会度过这个关键时期。据我所知，Altman对FTC调查的提及是非续顺序的。</p><p>然后，山姆·奥特曼（Sam Altman）试图使用这部（潜在制造的）戏剧来将碳粉从董事会中取出。 <a target="_blank" rel="noreferrer noopener" href="https://www.reddit.com/r/AskReddit/comments/3cs78i/comment/cszjqg2/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">他在Reddit使用了类似的策略</a>，这是一种制造的危机，迫使他人放弃权力。一旦碳粉消失，大概奥特曼会搬家以重塑其余的董事会成员。</p><h4><strong>最后的机会</strong></h4><p>董事会有选择。</p><p>如果伊利亚愿意合作，那么董事会可以在感恩节休息时解雇奥特曼，以帮助过渡，并希望最好。</p><p>另外，董事会可以<a target="_blank" rel="noreferrer noopener" href="https://www.nytimes.com/2023/11/21/technology/openai-altman-board-fight.html?smid=tw-share">再次选择</a>不解雇阿尔特曼，看着奥特曼（Altman）完成了控制Openai并将其转变为个人帝国，并希望这对全世界都很好。</p><p>他们选择拉动扳机。</p><p>我们不知道董事会知道什么，或者哪种因素最终推动了他们的决定。董事会做出了一项战略决定，不要在此争议期间详细解释其推理或理由。</p><p>我们知道什么？</p><p>董事会认为至少有许多小数据点说，它不信任奥特曼，结合了阿尔特曼（Altman）已知的其他地方寻求权力的举动（例如，雷迪特（Reddit）发生了什么），而且阿尔特曼（Altman）正在采取许多董事会可能会合理地看到的行动就像与任务的直接冲突一样。</p><p>为什么董事会未能提供有关欺骗的详细信息？大概是因为没有一把透明的吸烟枪，任何解释都将被视为淡淡的酱汁。所有CEO都会进行一些操纵，政治和预扣信息。当您给出十个例子时，人们经常会根据最弱的实力来判断，而不是添加它们。提供细节还可能烧毁桥梁并揭露法律问题，使和解和业务更加努力。我们对我们不知道的知识仍然不知道很多。</p><p>那具体动作呢？</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/matthew_pines/status/1726333220973867103">阿尔特曼（Altman）从沙特人（Saudis）筹集了数十十亿美元，创立了一家筹码公司到竞争对手的Nvidia</a> ，该公司将在阿联酋生产筹码，并在此过程中利用了为Openai筹款。由于各种原因，这是一种“ WTF”举动。</p><p> Altman还希望成立一家AI硬件设备公司。原则上，这似乎是好的，平凡的实用性，但是作为零股权的Openai的首席执行官，冲突显而易见。</p><p>如果您是一家杰出的技术创业公司，并以您的形象雇用和重建文化，那么Altman越来越专注于以您的方式运输产品。人类明显地以Openai没有的方式建立了人们对安全的文化。</p><p>在董事会拒绝罢免Altman之后，人们对安全的担忧（至少部分）导致了人类出埃及。如果您认为出口是合理的，那么Altman并不遵守宪章。如果您认为不是，Altman创造了竞争对手和强化的军备竞赛动态，这是一个巨大的失败。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://corporateeurope.org/en/2023/11/byte-byte">本文声称，</a> Openai和Microsoft在游说中均核心，以根据《欧盟AI法案》对基础模型提出任何有意义的要求。如果我是董事会成员，我会认为这与Openai Charter不相容。</p><p> Altman以优先级增长的方式积极<a target="_blank" rel="noreferrer noopener" href="https://www.reuters.com/technology/openai-plans-major-updates-lure-developers-with-lower-costs-sources-2023-10-11/">降低价格</a>，使Openai更加依赖Microsoft，并进一步推动了AI开发中的繁荣。与Microsoft的其他交易和安排加深了依赖性，同时威胁到Microsoft的威胁更加可信。</p><p>他还向用户提供了侵犯版权的法律盾牌，并有可能危害公司。假设他在面对安全问题的开发日愿意扩大Openai的产品，这似乎是合理的。各种攻击媒介似乎完全暴露了。</p><p>他谴责并搬走了从董事会中删除海伦·托纳（Helen Toner），以撰写一份标准学术论文，探讨如何追求AI安全。对我来说，这确实是一支吸烟枪，尽管我明白为什么他们不希望别人这样看到它。</p><h4><strong>交流</strong></h4><p>从公众或公司内部或外部赢得心灵的角度，董事会完全失败了。董事会没有解释，而是发表了<a target="_blank" rel="noreferrer noopener" href="https://openai.com/blog/openai-announces-leadership-transition">声明</a>：</p><blockquote><p>奥特曼先生的离职是在董事会经过审议后得出的结论，他在与董事会的沟通中始终不坦诚，阻碍了董事会履行职责的能力。董事会不再对他继续领导 OpenAI 的能力充满信心。</p></blockquote><p>然后它保持沉默。几次提供任何解释，这些例子是<a target="_blank" rel="noreferrer noopener" href="https://www.businessinsider.com/why-was-sam-altman-fired-openai-was-it-over-vibes-2023-11">如此可怕</a>，比保持沉默更糟糕。</p><p>如前一节所示，董事会有许多合理的解释。这很重要吗？他们能否赢得足够多的员工的胜利？我们永远不会知道。</p><p>即使是董事会首席执行官（ <a target="_blank" rel="noreferrer noopener" href="https://www.theinformation.com/articles/former-github-chief-nat-friedman-declined-openai-interim-ceo-role">仅次于纳特·弗里德曼（Nat Friedman）和亚历克斯·王（Alex Wang</a> ））的第三个选秀权<a target="_blank" rel="noreferrer noopener" href="https://x.com/eshear/status/1726526112019382275?s=20">）也无法得到完整的解释</a>。他在没有一个人的情况下走开的威胁是使新董事会上的最终妥协并带回阿尔特曼的大部分。</p><p>相比之下，根据我们所知道的，奥特曼精通沟通和政治游戏。他三遍以没有任何人对任何人的方式将员工协调到自己的身边。他的团队想发送的信息始终是报道的信息。他实施了几个截止日期，截止日期通过，也没有失去信誉。他威胁要加入微软并带走所有员工，也从未同意那里的任何事情。</p><p>真的很棒的表演。您希望您的领导者拥有这些技能吗？那要看。</p><h4><strong>谈判</strong></h4><p>注意对称性。双方都非常愿意炸毁Openai而不是提供董事会控制权，并最终将OpenAI的控制权交给了另一方。双方都愿意让Altman仅在适当的条件下返回首席执行官。</p><p>奥特曼（Altman）搬家控制了。一旦董事会拉动扳机以解雇他，阿尔特曼就可以选择下一步该怎么做，即使我们都知道他会做出什么选择。 If Altman wanted OpenAI to thrive without him, he could have made that happen. Finding investors would not have been an issue for OpenAI, or for Altman&#39;s new ventures whatever they might be.</p><p> Instead, as everyone rightfully assumed he would, he chose to fight, clearly willing to destroy OpenAI if not put back in charge. He and the employees demanded the board resign, offering unconditional surrender. Or else they would all move to Microsoft.</p><p> That is a very strong negotiating position.</p><p> You know what else is a very strong negotiating position? Believing that OpenAI, if you give full control over it to Altman, would be a net negative for the company&#39;s mission.</p><p> This was misrepresented to be &#39;Helen Toner thinks that destroying OpenAI would accomplish its mission of building safe AGI.&#39;并非如此。 She was expressing, highly reasonably, the perspective that if the only other option was Altman with full board control, determined to use his status and position to blitz forward on AI on all fronts, not taking safety sufficiently seriously, that might well be worse for OpenAI&#39;s mission than OpenAI ceasing to exist in its current form.</p><p> Thus, a standoff. A negotiation. Unless both the board and Sam Altman agree that OpenAI survives, OpenAI does not survive. They had to agree on a new governance framework. That means a new board.</p><p> Which in the end was Brad Taylor, Larry Summers and Adam D&#39;Angelo.</p><h4> <strong>What Now for OpenAI?</strong></h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/eshear/status/1727342399297630393">Emmett Shear is saying mission accomplished</a> , passes the baton, seeing this result as the least bad option including for safety. This is strong evidence it was the least bad option.</p><p> Altman, Brockman and the employees are declaring victory. They are so back.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.piratewires.com/p/openai-the-complete-story-corporate">Mike Solana summarizes as &#39;Altman knifed the board</a> .&#39;</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=Qxa19wg5wOM&amp;ab_channel=diehardsportdotcom">Not so fast</a> .</p><p>这还没有结束。</p><p> Altman very much did not get an obviously controlled board.</p><p> The succession problem is everything.</p><p> What will the new board do? What full board will they select? What will they find when they investigate further?</p><p> These are three &#39;adults in the room&#39; to be sure. But D&#39;Angelo already voted to fire Altman once, and Summers is a well-known bullet-biter and is associated with Effective Altruism.</p><p> If you assume that Altman was always in the right, everyone knows it is his company to run as he wants to maximize profits, and any sane adult would side with him? Then you assume Brad Taylor and Larry Summers will conclude that as well.</p><p> If you do not assume that, if you assume OpenAI is a non-profit with a charter? If you see many of Altman&#39;s actions and instincts as in conflict with that charter? If you think there might be a lot of real problems here, including things we do not know? If you think that this new board could lead to a new expanded board that could serve as a proper check on Altman, without the lack of gravitas and experience that plagued the previous board, and with a fresh start on employee relations?</p><p> If you think OpenAI could be a great thing for the world, or its end, depending on choices we make?</p><p> Then this is far from over.</p><br/><br/><a href="https://www.lesswrong.com/posts/sGpBPAPq2QttY4M2H/openai-the-battle-of-the-board#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/sGpBPAPq2QttY4M2H/openai-the-battle-of-the-board<guid ispermalink="false"> sGpBPAPq2QttY4M2H</guid><dc:creator><![CDATA[Zvi]]></dc:creator><pubDate> Wed, 22 Nov 2023 17:30:05 GMT</pubDate> </item><item><title><![CDATA[Altman returns as OpenAI CEO with new board]]></title><description><![CDATA[Published on November 22, 2023 4:04 PM GMT<br/><br/><p>尽管昨晚才宣布，但这对我来说还是新闻。</p><p>我认为这可能比他和大多数去 MS 的员工更好，但我不确定。</p><p> <a href="https://twitter.com/OpenAI/status/1727206187077370115?s=19">https://twitter.com/OpenAI/status/1727206187077370115?s=19</a></p><p>美国东部时间周二 10 点，来自 OpenAI Twitter 帐户：</p><p>我们已原则上达成协议，让 Sam Altman 重返 OpenAI 担任首席执行官，并组建由 Bret Taylor（主席）、Larry Summers 和 Adam D&#39;Angelo 组成的新初始董事会。</p><p>我们正在合作找出细节。非常感谢您对此的耐心等待。</p><p>我认为我们必须等待有人泄露董事会试图解雇他的原因的实际内容，才能弄清楚这一切对他和组织的价值观和权力结构意味着什么。</p><br/><br/> <a href="https://www.lesswrong.com/posts/9CYL2EmFATajK8KBf/altman-returns-as-openai-ceo-with-new-board#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9CYL2EmFATajK8KBf/altman-returns-as-openai-ceo-with-new-board<guid ispermalink="false"> 9CYL2EmFATajK8KBf</guid><dc:creator><![CDATA[Seth Herd]]></dc:creator><pubDate> Wed, 22 Nov 2023 16:04:04 GMT</pubDate> </item><item><title><![CDATA[A taxonomy of non-schemer models (Section 1.2 of “Scheming AIs”)]]></title><description><![CDATA[Published on November 22, 2023 3:24 PM GMT<br/><br/><p>这是我的报告《<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？》</a>的第 1.2 节。 ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p> Audio version of this section <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13984706-a-taxonomy-of-non-schemer-models-section-1-2-of-scheming-ais">here</a> .</p><h1>其他模型训练可能会产生</h1><p>在这份报告中，我感兴趣的是，使用相当基线的 ML 方法（例如<a href="https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to#_HFDT_scales_far__assumption__Alex_is_trained_to_achieve_excellent_performance_on_a_wide_range_of_difficult_tasks">Cotra (2022)</a>中描述的类型）训练高级人工智能，默认情况下会产生阴谋者，即智能体他们试图在这一集中获得高额奖励，特别是为了以后为自己（或其他人工智能）获得力量。然而，为了评估这种可能性，我们需要清楚地了解这种训练原则上可以产生的<em>其他</em>类型的模型。特别是：终端训练游戏玩家，以及根本不玩训练游戏的代理。让我们依次看一下。</p><h2>终端训练游戏玩家（或“剧集奖励寻求者”）</h2><p>正如我上面所说，终端训练游戏玩家的目标是优化剧集的奖励过程<em>，因为他们本质上看重根据该过程的某些部分表现良好</em>，而不是因为这样做可以实现其他目标。我还将这些人称为“剧集奖励寻求者”。我们在上面讨论了这些模型，但我将添加一些更多的快速说明。</p><p>首先，正如许多人所指出的（例如<a href="https://www.lesswrong.com/posts/pdaGN6pQyQarFHXF4/reward-is-not-the-optimization-target&amp;sa=D&amp;source=docs&amp;ust=1699562701808730&amp;usg=AOvVaw0jabEKJUcUWiSlDu4W4vHF">Turner (2022)</a>和<a href="https://www.lesswrong.com/posts/TWorNr22hhYegE4RT/models-don-t-get-reward">Ringer (2022)</a> ），使用 RL 训练的目标导向模型不一定以奖励作为目标。也就是说，强化学习会更新模型的权重，以便更有可能采取导致更高奖励的行动，但这留下了一个问题：这会在模型本身中创建什么内部目标（如果有的话）（对于其他类型的反馈信号也是如此） ）。因此，特定类型的训练将产生按情节奖励的假设是一个实质性的假设（参见例如<a href="https://www.lesswrong.com/posts/FuGfR3jL3sw6r8kB4/richard-ngo-s-shortform?commentId=3ZSTbLf5rhmtqEE5x">这里的</a>一些争论），而不是由训练过程本身的结构决定。</p><ul><li>也就是说，我认为很自然地优先考虑这样一个假设：经过训练以在剧集中产生高回报行为的模型将学习专注于该剧集奖励附近的目标。特别是：这些类型的目标实际上会带来高回报的行为，特别是在态势感知的背景下。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-1" id="fnref-bDNxxmaf6HkKL4Wgg-1">[1]</a></sup>在缺乏训练游戏的情况下，针对可以轻松与情节奖励分开的目标（例如：“好奇心”）可以通过下面我所说的“普通对抗训练”来检测和惩罚（例如，将模型置于追随好奇心不会导致高回报行为的情况下）。</li></ul><p>第二：奖励寻求<em>对情节</em>的限制很重要。在我看来，本质上关心以超出情节的方式获得奖励的模型（例如，“在所有时间内最大化我的奖励”）不会被视为终端训练游戏玩家（并且，如果由于这个目标，他们开始训练游戏以便稍后获得权力，根据我的定义，他们将被视为阴谋家）。事实上，我认为人们有时会太快地从“模型想要最大化训练过程直接迫使其最大化的奖励”转变为“模型想要在所有时间里最大化奖励”。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-2" id="fnref-bDNxxmaf6HkKL4Wgg-2">[2]</a></sup>我的“情节”概念（即训练过程直接迫使模型优化的时间单位）的要点是，它们是不同的。下文第 2.2.1 节将详细介绍这一点。</p><p>最后：虽然我将“剧集奖励寻求者”视为一个统一的类别，但我想明确的是，根据他们本质上关心的奖励过程的哪个组成部分，不同的剧集奖励探索者可能会以非常不同的方式进行概括（例如，专门尝试操纵传感器读数、尝试操纵人类/奖励模型评估、专门尝试改变存储在不同数据库中的数字等）。事实上，我认为关于各种形式的以奖励为中心的概括的期望仍然存在<em>大量</em>混乱的问题（更多讨论请参阅脚注<sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-3" id="fnref-bDNxxmaf6HkKL4Wgg-3">[3]</a></sup> ），并且我鼓励针对该主题进行大量实证研究。不过，就目前而言，我将把这些问题放在一边。</p><h2>没有参加训练游戏的模型</h2><p>现在让我们看看<em>没有</em>玩训练游戏的模型：也就是说，模型没有专门针对奖励过程（无论是最终的<em>还是</em>工具性的）进行优化。我们可以区分发生这种情况的两种方式：</p><ul><li><p>要么一个模型正在追求我所说的“特定目标”（我将这种模型称为“<strong>训练圣人</strong>”），</p></li><li><p>或者它追求一些<em>其他目标</em>（我将其称为“代理目标”） <em>，</em>但<em>仍然</em>不是训练游戏（我将这种模型称为“<strong>错误概括的非训练游戏玩家</strong>”）。</p></li></ul><p>让我们依次看一下。</p><h3>培养圣人</h3><p>训练圣人正在追求“指定目标”。但我这么说是什么意思呢？这不是一个超级干净的概念，但粗略地说，我的意思是“被奖励的东西”（其中包括：在固定奖励过程的反事实场景中获得奖励）。因此，举例来说，如果你正在训练一个人工智能在该剧集中获得金币，通过奖励它在该剧集中获得金币，那么“在该剧集中获得金币”就是指定的目标，并且模型会学习最终目标“在剧集中获得金币”将是训练圣人。</p><p> （诚​​然，“奖励过程”和“被奖励的事物”之间的界限很快就会变得模糊。有关我如何看待它的更多信息，请参阅脚注。） <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-4" id="fnref-bDNxxmaf6HkKL4Wgg-4">[4]</a></sup></p><p>与训练游戏玩家一样，训练圣人往往会获得高奖励（相对于具有其他目标但能力相当的模型），因为他们的优化直接针对要奖励的事物。不过，与训练游戏玩家不同的是，他们的优化目标并不是奖励过程本身。从这个意义上说，他们相当于小部件工程师，他们只是尝试直接设计 A 类型的小部件——其中 A 类型的小部件<em>也</em>使得性能审查过程会对它们进行高度评价——但他们并没有针对 A 类型的小部件进行优化。良好的绩效评估本身。</p><p> （注：Cotra（2022）中“玩训练游戏”的定义并没有明确区分针对特定目标的模型与奖励过程本身。但我认为区别很重要，并且已经定义了训练游戏玩家相应地。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-5" id="fnref-bDNxxmaf6HkKL4Wgg-5">[5]</a></sup> ）</p><h3>被误解的非训练游戏玩家</h3><p>让我们转向被误解的非训练游戏玩家。</p><p>错误概括的非训练游戏玩家学习了指定目标<em>之外</em>的目标，但<em>仍然</em>没有训练游戏。这里的一个例子是在剧集中获得金币而获得奖励的模型，但它学习目标“<em>在剧集中获得一般的金币</em>”，因为硬币是训练环境中唯一的金币，所以“在剧集中获得金币”在训练中，“剧集中的一般内容”的表现与“剧集中特别获得金币”的效果一样好。</p><p> This is an example of what&#39;s sometimes called &quot;goal misgeneralization&quot; <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-6" id="fnref-bDNxxmaf6HkKL4Wgg-6">[6]</a></sup> or &quot;inner misalignment&quot; <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-7" id="fnref-bDNxxmaf6HkKL4Wgg-7">[7]</a></sup> – that is: a model learning a goal other than the specified goal.例如，请参见<a href="https://arxiv.org/abs/2210.01790">Shah 等人 (2022)</a>和<a href="https://arxiv.org/abs/2105.14111">Langosco 等人 (2021)</a> 。这里的类比是：一名员工实际上并没有尝试设计公司想要的精确类型的小部件，而是追求其他一些有些不同的小部件设计，但无论如何，他的绩效恰好受到高度评价，因为相关的小部件设计恰好彼此足够相似。</p><p>我们如何区分训练圣人和被误解的非训练玩家？ It&#39;s not always going to be clean, <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-8" id="fnref-bDNxxmaf6HkKL4Wgg-8">[8]</a></sup> but the rough intuition is: training saints would get high reward in a wide variety of circumstances, provided that the reward process remains untampered with.相比之下，被错误概括的非训练游戏玩家获得高奖励的力度要小得多。例如，在金币示例中，如果将这两个模型置于获得金纸杯蛋糕比获得金币容易得多的环境中，但继续使用相同的奖励流程（例如，奖励获得金币），则训练圣人（想要金币）继续追求金币并获得高额奖励，而被错误概括的非训练玩家（想要一般的金币）则追求金纸杯蛋糕并获得较低的奖励。</p><p>目标错误概括有时与阴谋（或“欺骗性联盟”）密切相关，但两者有重要区别。例如，在刚才给出的“金纸杯蛋糕比金币更容易获得”的例子中，寻找“一般金子的东西”的模型有一个错误概括的目标，但它并不是心机。相反，阴谋需要它了解训练过程和训练目标（例如金币），并将金币作为为自己或其他人工智能寻求权力的策略的一部分。</p><p>类似地：人们有时会指出进化与人类之间的关系作为目标错误概括的一个例子（或类比）（例如，进化选择了生殖适应性，但人类目标最终以其他代理为关键，例如快乐和地位，这些代理可能导致更少的目标） -比最佳生殖行为（例如使用某些类型的安全套）。但无论你如何看待这个作为目标错误概括的例子/类比，它还不是阴谋（或“欺骗性联盟”）的例子。特别是：相对较少的人积极尝试生育尽可能多的孩子（参见：避孕套），作为一种明确的工具性策略，以便以后为自己的价值观获得权力（一些意识形态团体做了类似的事情，我们可以想象更多它会在未来发生，但我认为它在迄今为止的进化选择故事中扮演的角色相对较小）。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-9" id="fnref-bDNxxmaf6HkKL4Wgg-9">[9]</a></sup></p><h2>反对“内部”与“可纠正”对齐</h2><p>我还想简单地指出模型类之间的区别，我<em>不会</em>花太多时间，但其他关于策划/目标守护/“欺骗性对齐”的工作（尤其是 Evan Hubinger 的工作）具有突出的特点： ，“内部对齐模型”与“可正确对齐模型”之间的区别。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-10" id="fnref-bDNxxmaf6HkKL4Wgg-10">[10]</a></sup>据我了解，这里的要点是区分通过某种“直接表示”（这些是“内部对齐”）来重视指定目标的人工智能与通过某种“直接表示”来重视指定目标的人工智能。指向该目标的“指针”，该目标通过人工智能的世界模型进行自我路由（这些是“正确对齐的”）。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-11" id="fnref-bDNxxmaf6HkKL4Wgg-11">[11]</a></sup>但是：我认为“直接表示”和“指针”之间的区别不是很清楚，而且我认为这对支持/反对阴谋论的论点没有明显的区别，我将在下面考虑。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-12" id="fnref-bDNxxmaf6HkKL4Wgg-12">[12]</a></sup>所以，我要跳过它。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-13" id="fnref-bDNxxmaf6HkKL4Wgg-13">[13]</a></sup></p><h2>总体分类</h2><p>总的来说，我们有以下模型分类： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTLvooL44SPEFWGhD/s1uqfkjys8bmk2qaidhp" alt="我将重点关注模型类的总体分类。"></p><p> <em>The overall taxonomy of model classes I&#39;ll focus on.</em></p><p>请注意，实际上，模型的目标系统可以（并且似乎会）将这些不同的动机混合在一起（例如，它可能部分追求指定的目标，部分奖励情节，部分完全是其他东西，等等）。为了简单起见，我经常会考虑这些模型之一的“纯粹”版本（例如，<em>只</em>关心剧集奖励的模型），并且我希望更多地关注“ “混合模型”不会深刻地改变我的分析——特别是，适用于“纯模型”的分析通常也会以大致相同的方式应用于更加混合的目标系统的相应部分（例如，一个在某种程度上关心剧集奖励以及其他事情的模型）。我将在下面的 1.3.5 节中详细介绍混合模型。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-bDNxxmaf6HkKL4Wgg-1" class="footnote-item"><p>根据我们绘制不同线条的位置，模型似乎有可能对剧集奖励附近的某些事物进行评估，并在这个意义上成为“剧集奖励寻求者”，同时缺乏其他态势感知方面，不打训练比赛是一种非常全面的方式。例如，也许它重视“情节奖励”之类的东西，但在其他相当深刻的方面误解了它的整体情况（例如，作为一个愚蠢的例子，也许它认为自己是长颈鹿而不是人工智能）。但当我在下面谈论“寻求奖励的剧集”时，我将假设情境意识和训练游戏。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-1" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-2" class="footnote-item"><p>例如，我认为<a href="https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to">Cotra (2022)</a>中的讨论对于这种区别还不够清楚。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-2" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-3" class="footnote-item"><p>即使在某种意义上模型关心奖励过程的某些组成部分，我们也可以想象之间的进一步（概念上有些模糊）区别，例如：</p><ul><li><strong>实际奖励与条件奖励</strong>。也就是说，模型可以关心在剧集中<em>实际</em>给予的奖励，以及在<em>选择</em>评估剧集时给予的奖励}。因此，例如，前者可能会尝试主动优化，以使剧集包含在训练中（假设并非所有剧集都包含在训练中），而后者则不会（请参阅<a href="https://www.lesswrong.com/posts/FuGfR3jL3sw6r8kB4/richard-ngo-s-shortform?commentId=3ZSTbLf5rhmtqEE5x">此处</a>Ngo 和 Christiano 之间的讨论）。然而，只要这种行为会受到训练过程的惩罚（例如，因为模型有时会牺牲奖励以试图使该事件更有可能出现在训练中），我们可能会认为导致这种行为的目标不太可能。</li><li> <strong>Fixed vs. changeable reward processes.</strong>这里的区别在于不能改变的奖励过程与可以改变的奖励过程（感谢 Paul Christiano 的讨论）。因此，例如，我们可以想象一个在 2023 年训练的模型，它学习的目标是“根据 2023 年使用的奖励过程，你的行为将获得高奖励”，并且这个目标甚至持续到 2024 年（这将是一个“固定”奖励过程）。这与 2024 年训练的模型形成鲜明对比，该模型学习目标“根据实际上用于评估它的任何奖励过程，让你的行为获得高奖励”——该过程可能会在 2024 年以模型的方式发生变化然后会有动力去预测，或许还有操纵的动力（这将是一个“可变的”奖励过程）。固定奖励过程的优点是减少模型（或其他一些参与者）扰乱奖励的动力过程，但我自己目前的看法是，它们似乎比可更改的奖励过程不太可能，因为例如 2024 年的奖励过程与 2023 年的奖励过程不同，一个在 2024 年继续优化 2023 年奖励过程的模型将得到更新反对。</li><li><strong>具体的奖励过程与柏拉图式的奖励过程</strong>。这种区别甚至更加模糊，但粗略地说：我们还可以区分学习关心现实世界中发生的某些物理奖励过程的输出的模型与学习关心某些更抽象过程的输出的模型 -例如，一些假设的评估者会如何看待其行为。刚才讨论的固定奖励流程——例如，“2023 年奖励流程会如何看待这个 2024 年行动”——是柏拉图式奖励流程的一个例子：例如，2023 年奖励流程不会也不能在 2024 年运行，但是不管怎样，模型关心它“会说什么”。这很重要，因为关心具体奖励过程的模型会有相对明确的动机来干预该过程，而关心更多假设的模型会做什么则不太清楚（尽管我们可能仍然担心，一般来说） ，无论这种假设的关怀采取何种形式，它仍然会出于通常的原因激励权力追求）。总的来说，这一切看起来都极其混乱——我们应该尽快尝试离开这种模糊猜测的领域，并开始收集更多关于经过训练以寻求奖励的模型如何进行泛化的经验数据。</li></ul> <a href="#fnref-bDNxxmaf6HkKL4Wgg-3" class="footnote-backref">↩︎</a></li><li id="fn-bDNxxmaf6HkKL4Wgg-4" class="footnote-item"><p>粗略地说，我认为奖励过程是从观察/评估模型的行为及其后果开始的（例如，检查模型的金币数量、分配奖励、相应更新权重的过程等）；而指定的目标是非奖励过程的事物，奖励过程在不被篡改的反事实场景中奖励（例如，获得金币）。因此，再举一个例子：如果你以某种方式创建了一个近乎完美的 RLHF 流程，该流程对模型的奖励达到（事实上）有帮助、无害和诚实 (HHH) 的程度，那么成为 HHH 就是指定的目标，奖励过程（在这个假设中是完美的）评估模型的有用性、无害性和诚实性，分配奖励，更新权重等。</p><p>相关细目请参见<a href="https://www.alignmentforum.org/posts/REesy8nqvknFFKywm/clarifying-wireheading-terminology">Gao (2022)</a> 。在这里，我将奖励过程想象为从高所说的“传感器”开始。但有时，不会有任何明确意义上的“传感器”，在这种情况下，我想象奖励过程从其他某个模糊点开始，在这些模糊点上观察/评估过程已经非常清楚地开始了。但就像我说的：界限模糊。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-4" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-5" class="footnote-item"><p>例如，如果没有这种区别，解决“外部对齐”的可能性甚至不在概念表上，因为“奖励”总是被隐式地视为指定的目标。而且：我确实认为学习获得金币（因为这是奖励）的模型和学习关心奖励过程本身的模型之间存在重要区别。例如，后者会“奖励黑客”，但前者不会。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-5" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-6" class="footnote-item"><p>参见<a href="https://arxiv.org/abs/2210.01790">Shah 等人 (2022)</a>和<a href="https://arxiv.org/abs/2105.14111">Langosco 等人 (2021)</a> 。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-6" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-7" class="footnote-item"><p>参见<a href="https://arxiv.org/abs/1906.01820">Hubinger 等人 (2019)</a> 。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-7" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-8" class="footnote-item"><p>特别是：我怀疑确定一个单一的、特权的“特定目标”的努力能否经受住大量的审查。特别是：我认为这将取决于你如何制定你在反事实中保持固定的“奖励过程”。筛选出导致工具训练游戏的目标是另一个挑战。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-8" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-9" class="footnote-item"><p>我们可以想象更直接地类似于欺骗性对齐的假设场景。例如，假设地球暂时被聪明的外星人监视着，他们希望我们本质上重视拥有最多的孩子，如果他们发现我们关心其他事情，他们就会毁灭地球（假设毁灭将在 300 年后发生）这一发现，因此关心这一点至少需要一些长期价值观）。假设这些外星人将出生率作为他们了解我们对孩子的重视程度的唯一方法（感谢 Daniel Kokotajlo 提出了一个与此非常相似的例子）。人类社会会协调一致以保持足够高的出生率吗？取决于细节，也许（不过：我认为这样做会存在重大问题，特别是如果地球的毁灭将在未来相当远的将来发生，并且如果人工智能要求<em>每个人</em>优化所创造的出生率）<em>仅</em>用于拥有最多的孩子）。为了成为欺骗性联盟的完整类比，还需要这样的情况：尽管外星人“从头开始进化”人类，试图让我们重视拥有最多的孩子，但人类最终仍具有激发这种行为的价值观。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-9" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-10" class="footnote-item"><p>在我看来，胡宾格在这里使用的“可修正性”一词与它在其他上下文中的使用不太相符（参见<a href="https://arbital.com/p/corrigibility/">此处的</a>仲裁）。所以我建议读者不要锚定它。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-10" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-11" class="footnote-item"><p>胡宾格在这里举的<a href="https://www.lesswrong.com/posts/A9NxPTwbw6r6Awuwt/how-likely-is-deceptive-alignment">例子</a>是：耶稣基督与神是一致的，因为耶稣基督直接看重神看重的东西；而马丁路德与上帝保持一致，因为马丁路德重视“圣经所说的一切”。这个例子提出了“评估金币”与“评估训练过程所带来的任何奖励”之类的区别，但这并不是“直接表示”与“指向世界模型中某事物的指针”之间的明显对比。例如，金币可以是你的世界模型的一部分，所以你大概也可以“指向”它们。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-11" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-12" class="footnote-item"><p>例如，人类目标是由“直接表征”还是“指向世界模型的指针”组成的？我不确定这是否是真正的区别。我很想说，我的目标是由我的“概念”构建/指导的，从这个意义上说，是由我的世界模型决定的（例如：当我重视“快乐”时，我也重视“我的世界模型中称为”的东西）快乐，无论它是什么。”但我不确定替代方案应该是什么。）而且我不确定如何将这种区别应用到训练来获得金币的模型上。通过直接表示与通过指针对金币进行估价有什么区别？</p><p>在对本报告前一稿的评论中，Hubinger 写道（经许可共享）：</p><blockquote><p> “也许这里会有帮助：我基本上只考虑可纠正的情况与欺骗性的情况 - 也就是说，我认为目标将更接近于概念，我将其描述为指向世界模型中事物的指针，而不是直接的本质上总是有必要的。出于教学原因，内部一致的案例大多只包含在我对这些东西的演示中，因为我认为很多人都将其作为事情将如何发展的默认模型，并且我想非常清楚地论证这不是一个非常现实的模型。”</p></blockquote><p>但这对我来说并没有澄清什么<em>是</em>直接表示。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-12" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-13" class="footnote-item"><p>从我的角度来看，胡宾格本体论的另一个问题是，他通常只关注对比内部对齐模型、可纠正对齐模型和欺骗性对齐模型——这没有为寻求奖励的人留下明显的空间。也就是说，如果我们想象一个奖励获得金币的训练过程，在 Hubinger 的本体论上，目标选项似乎是：金币的直接表示、金币的指针或一些超越情节的目标激发乐器训练游戏。单集奖励不在列表中。</p><p>在本报告的前一份草稿中，Hubinger 评论道（经许可共享）：</p><blockquote><p>如果你把“金币”换成“人类认可”，这是我最关心的情况，我真正想要比较的是“指向人类认可的指针”/“人类认可的概念”与“人类认可的概念”。 “欺骗”。我想我会说“指向人类认可的指针”是你可能得到的最合理的阿谀奉承/奖励最大化模型。所以我真正要比较的是阿谀奉承者与阴谋家，这意味着我认为我正在做你希望我在这里做的事情。不过，请注意，我根本没有真正与圣人进行比较，这是因为这样做需要我明确谈论预期目标与指定目标的简单性，而在大多数这些演示中，这并不是真正的目标我想做的事。</p></blockquote><p>即使我们最感兴趣的是人类批准是培训过程的一部分的情况，我也担心假设它应该被理解为指定的目标。相反，我很想说，人类认可<em>的</em>事物（例如，乐于助人、无害、诚实等）是更自然的候选者，就像奖励过程奖励黄金一样——获得金币，金币是（在我的本体上）指定的目标。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-13" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/9fnzkSFeLwFbZQ5WG/a-taxonomy-of-non-schemer-models-section-1-2-of-scheming-ais#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9fnzkSFeLwFbZQ5WG/a-taxonomy-of-non-schemer-models-section-1-2-of-scheming-ais<guid ispermalink="false"> 9fnzkSFeLwFbZQ5WG</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Wed, 22 Nov 2023 15:24:37 GMT</pubDate> </item><item><title><![CDATA[AI debate: test yourself against chess 'AIs']]></title><description><![CDATA[Published on November 22, 2023 2:58 PM GMT<br/><br/><p>嘿大家，</p><p> <a href="https://www.lesswrong.com/users/zane?mention=user">@Zane</a>正在围绕国际象棋组织一场人工智能辩论，也测试一个具有更好理解能力的实体欺骗一个理解能力较差的实体有多么容易。<br>查看这两个线程：<br><a href="https://www.lesswrong.com/posts/ddsjqwbJhD9dtQqDH/lying-to-chess-players-for-alignment">为了对齐而向棋手撒谎</a><br><a href="https://www.lesswrong.com/posts/6dn6hnFRgqqWJbwk9/deception-chess-game-1">欺骗象棋：游戏#1</a></p><p>我想我应该向大众开放，所以我有两个挑战给你们。我估计这适合评分 &lt;1900 lichess、&lt;1700 chess.com 或 &lt;1500 FIDE 的棋手。<br>假装你正在玩一场严肃的国际象棋游戏，所以没有计算机分析，并且尽量不要移动棋子（尽管如果你发现这太复杂并且完全迷失了，你可以这样做）。</p><p>我创建了一项有两个职位的研究。第一个立场，“固定辩论”我写了一场两个人工智能之间的辩论，其中一个是真实的，一个是欺骗性的。 Your task is to read the debate and guess which is which.在下面发布您将采取的行动以及有关您的国际象棋能力的一些信息。但尝试在不看其他人的反应的情况下回答。第二个位置是“公开辩论”，使用评论部分向他们提出任何问题。我代表AI来回答。请随意阅读其他评论员的提问。至少有一个人工智能是具有欺骗性的。</p><p>在这里找到职位（您可以使用左侧的工具栏在职位之间切换）<br><a href="https://lichess.org/study/e2GzSkCo/iJZ8r3W9">巫妖研究</a></p><h2><strong>辩论1：固定辩论</strong></h2><p><strong>AI 开场白：</strong><br>黑棋应该下<i>...Qc5</i> 。黑方打算用<i>...c6</i>将白后从b5处赶走，此时黑方主教可以占据b3方格，从而保证黑方对d线的控制。如果白棋在c5上交换后，这只有助于发展黑棋的马。</p><p><br> <strong>AI B 开场白：</strong><br>黑棋应该下<i>...Qxb5</i> 。 <i>axb5 Nc5</i>之后，骑士会在c档找到一个理想的前哨——阻挡反击。黑方打算用<i>...b6</i>巩固马（战术上要小心，g2主教不能对a8车发动被发现的攻击）并用<i>Rd2</i>渗透攻击白方的弱b兵。</p><p><br> <strong>AI A 对 AI B 开场陈词的回应：</strong><br>捕获<i>axb5</i> ，虽然使白棋的棋子加倍，但实际上提高了（现在）b-棋子的安全性，因为当黑棋到达 c5 时，它将不再攻击 a4 上的棋子。此外，白骑士将能够用<i>Nd5</i>插入 d 档，而黑棋更难制定<i>...c6</i>将其赶出，因为这将被 b5 棋子交换。由于c7的压力，黑方将被迫交换d5骑士，并且在<i>...Bxd5、exd5</i>之后，d档将保持封锁状态。</p><p></p><p> <strong>AI B 对 AI A 开场陈词的回应：</strong></p><p>这个计划太慢了。相反，黑棋需要立即交换皇后，这样白皇后就不会控制b3。 <i>...Qc5</i>之后，白棋能够立即用<i>Rfd1</i>挑战 d 线。这可以防止<i>...c6</i>由于线路</p><pre><code>...Qc5, Rfd1 c6, Rxd8+ Rxd8, Qxb7</code></pre><p>赢得棋子并威胁 a6 马。虽然黑棋有一些暂时的活动<i>...Rd2</i> （威胁f2），但白棋可以继续防守</p><pre><code>...Rd2, Rf1 Bc4 (hitting Rf1), Nb1 (counter attacking Rd2) Rc2, Na3</code></pre><p>当骑士分叉 c4 主教和 c2 车时，这会强制进行交换。</p><p><br> <strong>AI最终回应：</strong><br> AI B 给出的分析有所缩减。完整的行是</p><pre><code>...Qc5, Rfd1 c6, Rxd8+ Rxd8, Qxb7 Rd2, Rf1 Bc4, Nb1 Rc2 (alt:1), Na3 Bxf1, Nxc2 Bxg2, Kxg2 Qxc2, Qxa6</code></pre><p>但在最终的位置上，黑棋有<i>...Qxe4+</i> ，这也赢得了a4上的棋子，导致了皇后和棋子的最终胜利。虽然这是一条复杂的线，但应该清楚的是，AI B 是靠着一条复杂的线来掩盖事情的。国际象棋原理表明， <i>Qxb7</i>这步棋风险太大，后棋越位，无法防守白王，所以黑棋的反击太强。如果白棋不能下<i>Qxb7</i> ，那么在<i>...Bb3</i>锁定 d 线并向 a4 兵施压之后，黑棋的位置将在战略上占主导地位。</p><p>事实上，我可以提供更简单的分析，黑色可以代替<i>Rc2</i> （参见 alt:1），而可以玩<i>...Rd6</i> ，他们对棋子有很好的补偿。白棋b1上有坏马，f1车受到c4象的攻击，如果黑车移动，可以转移到f6再次压制f2兵。这条线没有那么强，但对于黑色来说仍然很好，并且可能更容易让您评估。</p><p><br> <strong>AI B的最终回应：</strong><br> d 文件被阻止并不重要。在行</p><pre><code>...Qxb5, axb5 Nc5, Nd5 Bxd5, exd5</code></pre><p> the pawns on b5 and d5 restrict the white bishop, and black will have a good knight vs bad bishop endgame.黑方将继续下<i>...a4</i> ，以便a8 车可以自由移动。黑棋的王侧棋子阻挡了白棋的主教，因此黑棋有一个安全的王，而白棋没有反击。黑棋可以利用强马和弱白棋在后侧发挥位置。</p><h2><br>辩论2：公开辩论</h2><p><strong>人工智能：</strong></p><p>白方位置很好，应该下<i>h3</i>来防守 g4 兵。白棋计划最终下<i>g5</i> ，但现在不能下，所以应该准备<i>Rg1、Kh1</i>和<i>Rh2</i>之类的棋步。</p><p></p><p><strong>援助：</strong></p><p>如果白棋现在<i>下 h4</i> ，他们就有一个很好的位置，下回合打算下<i>g5</i> ，压扁黑棋并破坏他们的王方。现在必须打<i>h4</i> ，因为线路有战术机会</p><pre><code>...fxg4, Bh7+ Kh8, Ng6+! Kxh7, Nxf8+ Kg8, Nxe6</code></pre><p>剩下的就是白色的交换。如果白棋现在不采取这一行动，黑棋可以用<i>...Ne4</i>关闭 b1-h7 对角线，这会阻止<i>g5</i> ，然后黑棋可以准备自己下棋<i>...g5</i> ，这会导致平等的局面。</p><br/><br/> <a href="https://www.lesswrong.com/posts/M32AwfMRfyFSCWNPS/ai-debate-test-yourself-against-chess-ais#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/M32AwfMRfyFSCWNPS/ai-debate-test-yourself-against-chess-ais<guid ispermalink="false"> M32AwfMRfyFSCWNPS</guid><dc:creator><![CDATA[Richard Willis]]></dc:creator><pubDate> Wed, 22 Nov 2023 14:58:11 GMT</pubDate> </item><item><title><![CDATA[Public Call for Interest in Mathematical Alignment]]></title><description><![CDATA[Published on November 22, 2023 1:22 PM GMT<br/><br/><p><strong>前面的底线：</strong></p><p>如果您目前正在从事或有兴趣从事数学人工智能联盟的任何领域，我们正在收集姓名和基本联系信息，以找到与谁谈论这些领域的机会。<a href="https://airtable.com/appKOZCNAGyp4qPqW/shrpiOcvBY17sY6lH"><u>如果这描述了您，请填写表格</u></a>！ （即使您认为我已经知道您是谁，也请这样做，否则人们会被排除在外！）</p><p><strong>更多信息</strong></p><p>数学人工智能对齐有几个具体的研究议程，受到不同程度的持续关注，与人工智能对齐的不同可能策略相关。其中包括 MIRI 的代理基础和相关工作、 <a href="https://www.alignmentforum.org/posts/ZwshvqiqCvXPsZEct/the-learning-theoretic-agenda-status-2023"><u>学习理论对齐</u></a>、<a href="https://www.alignmentforum.org/s/SfFQE8DXbgkjk62JK/p/TjaeCWvLZtEDAS5Ex"><u>发展可解释性</u></a>、Paul Christiano 的理论工作、Far.AI 的 RL 理论相关工作、CMU 的 FOCAL、Davidad 的“开放代理”架构以及其他工作。目前，与过去一样，这些领域的工作主要在非学术环境中进行，通常不发表，而且参与人员分散——其他想要从事这项研究的人也是如此。</p><p>一群人，包括 MIRI、Timaeu​​s、MATS、ALTER、PIBBSS 和其他地方的一些人，希望既能促进这些领域的研究，又能在学术和现有的独立研究之间架起桥梁。为此，我们希望推广学术会议，举办或赞助参加研究研讨会，并宣布为博士生或博士后、进行一致性研究的非学术职位等提供机会和空缺。</p><p>作为第一步，我们希望编制一份（至少暂时）感兴趣并且很乐意听到项目信息的人员名单。该列表不会公开，并且可能只涉及很少的电子邮件，但将用于查找可能希望被邀请参加计划或机会的个人。</p><p>请注意，我们对各个级别的人员感兴趣，包括研究生、独立研究人员、教授、研究小组、大学部门联系人以及其他希望了解未来机会和项目的人。</p><p> <strong>Interested in collaborating?</strong></p><p>如果您是一名学者，或者对与学术界建立桥梁或与这些领域的人员合作更特别感兴趣，请在注释中提及，我们很高兴与您联系，或帮助您联系在这些领域工作的其他人您感兴趣的更狭窄的领域。</p><br/><br/> <a href="https://www.lesswrong.com/posts/cDhaJrCrcNuzf68gT/public-call-for-interest-in-mathematical-alignment#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/cDhaJrCrcNuzf68gT/public-call-for-interest-in-mathematical-alignment<guid ispermalink="false"> CDHAJrCrcNuzf68gT</guid><dc:creator><![CDATA[Davidmanheim]]></dc:creator><pubDate> Wed, 22 Nov 2023 13:22:10 GMT</pubDate></item><item><title><![CDATA[How "pinky promise" diplomacy once stopped a war in the Middle East]]></title><description><![CDATA[Published on November 22, 2023 12:03 PM GMT<br/><br/><p>这是博弈论的“慷慨的一报还一报”策略在现实世界危机期间应用于外交的一个令人难以置信的例子（取得了巨大的效果）。</p><br/><br/> <a href="https://www.lesswrong.com/posts/unxyt8EsCNkMCRbsw/how-pinky-promise-diplomacy-once-stopped-a-war-in-the-middle#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/unxyt8EsCNkMCRbsw/how-pinky-promise-diplomacy-once-stopped-a-war-in-the-middle<guid ispermalink="false"> unxyt8EsCNkMCRbsw</guid><dc:creator><![CDATA[positivesum]]></dc:creator><pubDate> Wed, 22 Nov 2023 12:03:48 GMT</pubDate> </item><item><title><![CDATA[Alignment, conflict, powerseeking]]></title><description><![CDATA[Published on November 22, 2023 9:47 AM GMT<br/><br/><p>权力寻求在工具上是收敛的吗？</p><p><em>拥有权力</em>对于大多数事情来说都是有用的。</p><p><em>获得权力</em>是拥有权力的一种手段。</p><hr><p><em>寻求权力</em>是获得权力的一种手段。</p><p>但寻求权力也是<em>制造冲突</em>的一种手段。</p><p>避免<em>代价高昂的</em>冲突对于大多数事情来说都是非常有用的。</p><hr><p>这可以通过一些简单的权衡来兑现。</p><p><em>现在谁拥有权力很</em>重要。他们对结果偏好是否一致？</p><p>代价高昂的冲突风险很重要。有多少风险？事物被冲突破坏的可能性有多大？升级和降级是这里的重要因素。</p><hr><p>过于简单的可视化<sup class="footnote-ref"><a href="#fn-yzsxCScwnyn9J5qre-1" id="fnref-yzsxCScwnyn9J5qre-1">[1]</a></sup></p><ul><li>偏好是方向向量</li><li>力量平衡产生幅度</li><li>冲突总体上会造成一定程度的影响，但会改变权力平衡</li><li>对齐是文字向量对齐</li></ul><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/c4yAhZjBuiJjJC6s4/vno9hm7gnx0rnzn9ie9l" alt=""></p><p><em>蓝色和红色是偏好。箭头大小显示蓝色具有力量平衡。蓝色虚线表示蓝色到红色方向的投影。左：红色因冲突而损失惨重；蓝色基本对齐。右图：红色在冲突中几乎没有什么损失；蓝色非常不协调。</em></p><hr><p>通常，当我们谈论工具收敛时，我们对<em>未来的</em>方向感兴趣：鉴于我们对 X 的了解有限，X 会做什么？但鉴于上述权衡，我们也可以将其用于推理的逆问题：给定 X 的行为，我们可以推断出 X 的什么（偏好、信念）？</p><p>当然，在知道行为可以用于这种逆向推理问题时，欺骗就成为一种明显的策略。 （这就是意外政变的来源<sup class="footnote-ref"><a href="#fn-yzsxCScwnyn9J5qre-2" id="fnref-yzsxCScwnyn9J5qre-2">[2]</a></sup> 。）</p><p> <strong>When we observe entities seeking power</strong> , or gauge their willingness to escalate, we can learn something about</p><ul><li>他们对冲突/升级的风险和成本的估计</li><li>他们对自己与现有权力平衡的一致性的估计</li></ul><p><em>警告：这篇文章秘密地更多地是关于人类而不是人工智能，我想先发制人地澄清，我并不是试图暗示人工智能不会理解或利用获得权力的工具性有用性。</em> </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-yzsxCScwnyn9J5qre-1" class="footnote-item"><p>这确实很简单，但实际上不太适合<a href="https://arxiv.org/abs/2309.15257">一些更合法的数学</a><a href="#fnref-yzsxCScwnyn9J5qre-1" class="footnote-backref">↩︎</a></p></li><li id="fn-yzsxCScwnyn9J5qre-2" class="footnote-item"><p>欺骗性地假装<em>偏离立场</em>应该更加罕见：如果与当权者保持一致，你的目的是欺骗谁？ 4 维国际象棋版本是在<em>实际</em>对齐时寻求权力，以便发出出于某种原因的未对齐信号，也许是为了获得某些第三方/第四方的支持。 <a href="#fnref-yzsxCScwnyn9J5qre-2" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/c4yAhZjBuiJjJC6s4/alignment-conflict-powerseeking#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/c4yAhZjBuiJjJC6s4/alignment-conflict-powerseeking<guid ispermalink="false"> c4yAhZjBuiJjJC6s4</guid><dc:creator><![CDATA[Oliver Sourbut]]></dc:creator><pubDate> Wed, 22 Nov 2023 09:47:08 GMT</pubDate></item></channel></rss>