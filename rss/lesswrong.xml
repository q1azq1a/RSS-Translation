<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 23 日星期四 02:24:15 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Saturating the Difficulty Levels of Alignment]]></title><description><![CDATA[Published on November 23, 2023 12:39 AM GMT<br/><br/><p><strong>长话短说</strong></p><p>我们不知道对齐到底有多难，因此让人们研究不同的解决方案似乎是件好事，因为解决方案可能不同的一个轴是它们打破的难度级别。有些解决方案可以在很容易对齐的世界中发挥作用。其他人会在难以协调的世界中工作。一种启发是根据我们对协调问题有多困难的不确定性来分配人们所做的工作。</p><hr><p>对齐有多难？我不确定，但我的模型说这非常非常困难。</p><p><a href="https://www.youtube.com/live/Vc51kCFHWFA?si=1nAT_rgRJMJLm6qx&amp;t=663">巴克最近在做的</a>一件事是考虑具体的系统设置，如果我们运行一个具有欺骗性但仍然不是超级智能的模型（我正在大力简化），那么厄运就不太可能发生。这似乎是在对齐不是超级困难但仍然足够困难的世界中起作用的事情，它不仅仅是默认解决的。即使在很难保持一致的世界中，我们也想做这种事情来推迟厄运。也许我们甚至能够得到警告。</p><p>让多人共同制定议程，在不同层面上解决“解决一致性问题有多困难”似乎总体上是好的。也许我们生活在一个可以通过巴克建议的方法来拯救的世界。如果没有人尝试这种方法，那就太愚蠢了，因为他们正在研究试图解决不同难度级别的对齐问题的解决方案。他们可能认为巴克的做法是注定失败的，或者是杀伤力过大。无论哪种情况，他们都不会采取行动来实施它。</p><p>我的议程和许多其他议程的目标是在一个很难保持一致的世界中工作。巴克的一个很好的特性是它非常简单，而且我们现在基本上就可以做到，不需要重大的理论突破。试图解决最坏情况的议程可能需要很长时间才能产生有意义的影响。但如果我们生活在一个需要解决最坏情况对齐的世界，但没有人尝试这样做，那将是非常愚蠢的。我主要考虑的是这样一个世界：我们能够解决最坏情况下与特定议程的一致性问题，但前提是我们现在有人致力于该议程，直到需要议程结果为止。</p><p>因此，总的来说，只要我们至少在某种程度上不确定对齐有多困难，我们就应该让人们采用不同的方法来解决不同的难度级别。一个好的启发法可能是根据难度级别的概率分布来分配我们所做的工作。例如，如果我们有 75% 的人认为对齐很困难，20% 的人认为对齐很容易，5% 的人认为对齐可以默认解决，那么我们希望 75% 的智力劳动用于解决最坏情况的对齐问题。</p><p>在实践中，我们希望将这种启发式与其他因素（例如时间表、个人适合度等）结合起来。如果时间表很长，我们可能只是解决最坏情况的对齐问题，这样我们就可以确定它会成功，不管它实际上有多困难（多么美好的幻想世界）。想象一下，有人能够在解决对齐问题很容易的模型中取得进展。同样的人将无法在解决最坏情况对齐方面取得任何进展。在这种情况下，让这些人处理最坏情况的对齐问题比让他们解决对齐很容易的模型中的对齐问题更糟糕。</p><p>其通用版本适用于路线图的任意属性。对于任何属性 P，我们都可以有一个概率分布。该分布估计有多少种在现实世界中有效的解决方案对于 P 具有价值 v。然后，我们希望根据分布的整体属性来分配认知劳动。上面谈到了“这个计划致力于解决难度级别x的对齐”的性质。</p><br/><br/> <a href="https://www.lesswrong.com/posts/oBbrLh8DTZwRvSo9G/saturating-the-difficulty-levels-of-alignment#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/oBbrLh8DTZwRvSo9G/saturating-the-difficulty-levels-of-alignment<guid ispermalink="false"> oBbrLh8DTZwRvSo9G</guid><dc:creator><![CDATA[Johannes C. Mayer]]></dc:creator><pubDate> Thu, 23 Nov 2023 00:39:54 GMT</pubDate> </item><item><title><![CDATA[Sam Altman's ouster at OpenAI was precipitated by letter to board about AI breakthrough - Reuters]]></title><description><![CDATA[Published on November 22, 2023 11:17 PM GMT<br/><br/><br/><br/> <a href="https://www.lesswrong.com/posts/JkaDWvojFhRBuSxzz/sam-altman-s-ouster-at-openai-was-precipitated-by-letter-to#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/JkaDWvojFhRBuSxzz/sam-altman-s-ouster-at-openai-was-precipitated-by-letter-to<guid ispermalink="false"> JkaDWvojFhRBuSxzz</guid><dc:creator><![CDATA[Jonathan Yan]]></dc:creator><pubDate> Wed, 22 Nov 2023 23:17:14 GMT</pubDate> </item><item><title><![CDATA[Foresight Institute: 2023 Progress & 2024 Plans for funding beneficial technology development]]></title><description><![CDATA[Published on November 22, 2023 10:09 PM GMT<br/><br/><p>自 1986 年成立以来，推动技术进步造福人类一直是<a href="https://foresight.org/"><u>Foresight Institute</u></a>使命的核心。我们的努力正在迅速增长；从奖学金申请数量翻倍，到新的奖项、有前景的研讨会项目和定期的虚拟研讨会。</p><p>在节俭的预算下，我们的社区已成为不断增长的合作载体，以推动尚未开发的技术领域的进步，包括分子纳米技术、长寿生物技术、神经技术、人工智能、安全和太空。然而，我们的 2024 年计划，特别是我们的人工智能安全补助金、奖学金和研讨会已超额认购且资金有限。</p><p>以下是 2023 年进展和 2024 年计划的简要概述，包括资金受限领域。</p><p>我们是一家小型非营利组织，完全由捐款资助。如果您有兴趣推动技术进步造福生命，请考虑在这个捐赠季<a href="https://foresight.org/donate-join/"><u>支持我们</u></a>。您决定 2024 年我们可以一起解决哪些项目。<br></p><h3>远见团契</h3><p>我们的<a href="https://foresight.org/foresight-fellowships/"><u>2023 年奖学金</u></a>现已进入第六个年头，为 60 名致力于克服生物技术、纳米技术、神经技术、太空和人工智能领域关键科学瓶颈的研究员提供支持。我们的研究员受益于与选定的导师和资助者的一对一指导、展示他们工作的付费旅行会议邀请以及职业咨询（例如，与<a href="https://foresight.org/summary/tom-kalil-foresight-fellows-career-counseling/"><u>Tom Kalil</u></a> 、 <a href="https://foresight.org/summary/foresight-mentorship-with-jaan-tallinn/"><u>Jaan Tallinn</u></a>和<a href="https://foresight.org/summary/career-counseling-with-sonia-arrison/"><u>Sonia Arrison</u></a>的咨询）。</p><p>同行感言：</p><ul><li> <i>“我喜欢 Foresight 使命，很荣幸成为社区的一员。 Foresight 提供的与杰出人才互动的机会是无价的！”</i></li><li> <i>“[我加入是因为]热爱这里的人们/组织/使命，并认识到我可以使用的令人难以置信的网络”</i></li><li> <i>“网络和声望有助于筹款和合作伙伴关系发展”</i></li></ul><p>我们 2023 年的奖学金获得了极大的超额认购。尽管我们认为更多的研究员值得获得该奖学金，但我们还是接受了 30% 的申请。对于我们2024年的奖学金，申请人数增加了一倍，而我们支持他们的能力却较少，因此在目前的情况下，我们只能接受9%的申请人。除了我们传统的奖学金计划外，今年我们还开始支持 13 至 21 岁的未成年神童研究员，在这一类别中，我们看到 2024 年队列的申请数量增加了两倍，其中大多数是我们提供的目前无法支持。</p><p>在您的帮助下，面对不断增长的申请数量，我们可以提高高素质研究员的录取率。此外，能够在内部提供小额种子资助，而不是为我们的研究员与外部资助者牵线搭桥，会更有效率。您的资金将使我们能够提供申请人请求的资金来支持他们的工作。<br></p><h3>技术前沿研讨会</h3><p>我们的 2023 年研讨会每次都会聚集 50 名初级和高级研究人员、企业家和资助者，以推动被低估的技术领域的进步。领先的研究人员强调了工作组所采取的潜在进展领域，以探索如何推进这一领域。顶级项目提案获得了开发补助金，以便在研讨会后继续开展工作。</p><p>我们的 2023 年研讨会（包括录音）可在此处找到：</p><ul><li> <a href="https://foresight.org/longevity-frontiers-workshop-2023/"><u>2023年长寿前沿研讨会</u></a></li><li><a href="https://foresight.org/intelligent-cooperation-workshop-2023/"><u>2023 密码学、安全、人工智能研讨会</u></a></li><li><a href="https://foresight.org/whole-brain-emulation-workshop-2023/"><u>2023人工智能安全全脑模拟研讨会</u></a></li><li><a href="https://foresight.org/foresight-molecular-systems-design-workshop-2023/"><u>2023年分子机器系统设计研讨会</u></a></li><li><a href="https://foresight.org/foresight-space-workshop-2023/"><u>2023空间技术前沿研讨会</u></a></li></ul><p>2024 年，我们希望通过在各个领域举办后续研讨会来加速技术前沿的进展，以听取现有项目的最新进展情况，并探索启动工作的新机会。我们寻求差旅补助资金，为初级人才提供机会与各自领域的主要参与者合作，并提供资金以奖励发展赠款，以激励工作组在研讨会后就其项目提案进行合作。</p><p>我们计划于 2024 年举办的研讨会包括：</p><ul><li> <a href="https://foresight.org/2024-intelligent-cooperation-workshop/"><u>2024 AGI：密码学、安全、多极方法</u></a></li><li><a href="https://foresight.org/2024-foresight-neurotech-bci-and-wbe-for-safe-ai-workshop/"><u>2024 BCI &amp; WBE for Safe AI 研讨会</u></a></li><li><a href="https://foresight.org/2024-foresight-longevity-frontiers-workshop/"><u>2024年长寿前沿研讨会</u></a></li><li><a href="https://foresight.org/2024-foresight-space-frontiers-workshop/"><u>2024太空前沿研讨会</u></a></li><li><a href="https://foresight.org/2024-foresight-molecular-manufacturing-architectures-workshop/"><u>2024分子3D打印研讨会</u></a><br></li></ul><h3>远见奖</h3><p><strong>分子纳米技术</strong></p><p>我们的年度<a href="https://foresight.org/foresight-feynman-prizes/"><u>费曼奖</u></a>有着显着的记录。我们的费曼奖自 1993 年颁发以来，以纳米技术先驱理查德·费曼 (Richard Feynman) 的名字命名，旨在表彰对先进分子纳米技术进步做出重大贡献的杰出成就。该奖项以尽早发现人才而闻名。例如，2016年，J. Fraser Stoddart爵士因分子机器的设计和合成而共同获得诺贝尔化学奖；距离他获得 Foresight 的费曼实验奖仅九年后。</p><p>虽然费曼奖因奖励分子纳米技术的突破而获得全球认可，但每年 5000 美元的奖金相当少，我们希望在 2024 年将其增加到 20000 美元，以激励更多研究人员追求纳米技术的长期进展。</p><p><strong>长寿</strong></p><p>2023 年，我们与 VitaDAO、Methuselah 和 Lifespan.io 合作，成功推出了<a href="https://www.longevityprize.com/"><u>长寿奖</u></a>，这是一个针对长寿奖项的新合作奖品平台。我们将<a href="https://www.youtube.com/watch?v=HC9N7hwYmns"><u>一等奖</u></a>授予值得更多关注的有关长寿方法的新假设。</p><p>您可以帮助我们资助我们希望在 2024 年推出的各种其他奖项提案，包括体外测量奖、临床试验设计奖和长寿交流奖。</p><p><strong>空间</strong></p><p>我们很荣幸能与 2023 年远见研究员帕特里克·芬利 (Patrick Finley) 合作开展他的“<a href="https://landerchallenge.space/"><u>太空着陆器挑战</u></a>”。帕特里克是太空界的先驱，他希望这个项目能够挑战该领域，加快发射进度，同时也鼓励下一代太空爱好者参与其中。</p><p>您可以帮助我们赞助 2024 年太空着陆器挑战之一，以支持雄心勃勃的年轻人建造自动着陆火箭。支持的潜在奖励包括推力矢量控制热火、可节流发动机热火、系留悬停、着陆和跳跃。<br></p><h2>人工智能安全补助金</h2><p>2023 年 8 月，我们成功启动了三个类别的<a href="https://foresight.org/ai-safety/"><u>人工智能安全资助计划</u></a>：</p><ol><li>人工智能的神经技术：神经技术、脑机接口、全脑仿真和“低保真”上传方法，以产生与人类一致的软件智能</li><li>人工智能安全：帮助保护人工智能系统的计算机安全、密码学和相关技术</li><li>多极人工智能：多主体模拟、博弈论和相关技术，创建安全的多极人工智能场景，避免共谋并促进正和动态</li></ol><p>虽然该补助金在 3 个月前开始实施，但迄今为止我们已经收到了 80 多份申请并提供了三笔补助金。然而，我们认为 15 名申请人值得获得种子资金，这超出了我们分配的 100 万美元预算的资助范围。我们正在积极寻找有兴趣在 2024 年合作发展该计划的资助者。</p><h2>技术研讨会</h2><p>2023 年，我们扩大了<a href="https://foresight.org/seminars/"><u>每月虚拟研讨会系列</u></a>，这是一个基于应用程序的每月研讨会小组，其中介绍新的研究成果和项目，让参与者有机会结识各自领域的潜在合作者。今年，团体申请率增长了 20%，我们今年的顶级研讨会有超过 100 名参与者，YouTube 上的研讨会浏览量达到 5 万次，多个组织使用我们的研讨会作为其员工的入职视频，每月提名参与者研讨会将我们的日程安排安排到 2024 年第二季度。</p><p>现在，我们的研讨会正在成为 STEM 社区的虚拟谢林点，使全球从业者能够了解最新进展、寻找合作者并展示他们的成功，我们希望提高研讨会的质量，以吸引新人才。这包括整个研讨会流程，从引入领先的演讲者到研讨会的制作和推广，目标是在 2024 年使我们领先的研讨会的观看次数达到 10 万次。<br></p><h2>科技树</h2><p>为了让新人才和资助者进入尚未开发的技术领域，我们正在构建技术树，提供该领域的路线图，包括主要参与者和突出的瓶颈。这些树现在被多个社区用来规划其领域的进展。</p><p>您可以在这里探索我们的 2023 年科技树：</p><ul><li><a href="https://foresight.org/ext/ForesightTechTree/"><u>长寿科技树</u></a></li><li><a href="https://foresight.org/ext/ForesightSpaceTree/"><u>太空科技树</u></a></li><li><a href="https://foresight.org/ext/ForesightNanotechTree/"><u>纳米技术树</u></a></li><li><a href="https://foresight.org/ext/ForesightNeurotechTree/"><u>神经科技树</u></a></li></ul><p>2024 年，我们获得了资金来更新我们的长寿技术树，并使用人工智能工具构建人类人工智能合作技术树，使树木具有互动性。额外的资金将使我们能够创建交互式全脑模拟、分子机器和空间技术树。<br></p><h2>存在希望计划</h2><p><strong>激发存在的希望未来</strong></p><p>当我们庆祝新的<a href="https://www.existentialhope.com/"><u>Existential Hope 平台</u></a>推出一周年时<a href="https://www.existentialhope.com/podcasts"><u>，</u></a>我们发现<a href="https://www.existentialhope.com/podcasts"><u>Existential Hope 播客</u></a>的听众数量激增了 30%。今年的剧集邀请了大卫·多伊奇<a href="https://www.existentialhope.com/podcasts/david-deutsch-on-beauty-knowledge-and-progress"><u>(David Deutsch)</u></a> 、丽芙·博瑞 (<a href="https://www.existentialhope.com/podcasts/liv-boeree-game-theory-moloch-our-hopeful-future"><u>Liv Boeree</u></a> ) 和凯文·凯利 ( <a href="https://www.existentialhope.com/podcasts/kevin-kelly-pioneering-visions-of-a-high-tech-future"><u>Kevin Kelly)</u></a>等伟大思想家探讨我们如何打造积极的明天。每一集都配有精心策划的资源列表和<a href="https://www.existentialhope.com/gallery"><u>“希望之水”</u></a> ，这是一件描绘令人兴奋的未来图景的艺术作品。</p><p>作为我们持续致力于激发希望和促进有意义的对话的一部分，我们计划在 2024 年扩展我们的在线<a href="https://www.existentialhope.com/"><u>“存在希望”平台</u></a>。您的支持将通过交互式“存在希望”场景丰富该平台，并改进关键技术的介绍资源，以实现积极的长期目标期货。<br></p><p><strong>构建存在的希望未来</strong></p><p>今年二月，我们举办了第一个<a href="https://foresight.org/foresight-existential-hope-day-2023/"><u>“存在希望日”</u></a> ，重点是探索科学技术积极的<a href="https://www.existentialhope.com/xhope-scenario-contribution-form"><u>“存在希望”情景</u></a>，将焦点从它们构成的威胁转移到它们为我们的未来带来的可能性。</p><p> 2024 年，我们将采取实践方法，通过<a href="https://foresight.org/2024-xhope-hackathon/"><u>Xhope AI 机构黑客马拉松</u></a>培育人工智能繁荣的未来。该活动旨在打造新的机构和框架原型，专门用于应对 TAI 发展带来的现实挑战和机遇。通过资助研讨会，您可以赞助有前途的初级与会者的旅行。</p><p><strong>支持存在希望研究员</strong></p><p>2023 年存在希望奖学金已进入第六个年头，它支持研究人员应对重大科学挑战，同时最大程度地降低存在风险，例如强调差异化技术发展的重要性，这是一种通过加速有益进步、延缓有害进步来促进技术安全发展的战略。通过资助我们的 2024 年奖学金，您可以支持那些先进技术和专注于预防这些技术风险的技术之间更紧密的合作。<br></p><h2>支持前瞻研究所</h2><p>作为捐助者，您为科学技术的有益发展提供资金，而这些发展过于雄心勃勃，以至于传统机构无法支持。我们欢迎您通过我们的<a href="https://foresight.org/donate-join/"><u>捐赠页面</u></a>上的条纹、支票、加密货币或股票进行捐赠。 Foresight Institute 是一家 501(c)(3) 非营利组织，因此根据法律允许，您的捐款在美国可以免税。</p><p>作为 Foresight 的支持者，我们邀请您参加相关的技术路线，包括我们的研讨会、讲习班或<a href="https://foresight.org/vision-weekends-2023/"><u>愿景周末</u></a>——我们的年度年终盛会，聚集我们的技术路线，展望积极的未来。作为远见赞助人（每年 10,000 美元），我们邀请您加入我们的<a href="https://foresight.org/personal-longevity-group/"><u>个人长寿小组</u></a>，探索如何延长自己的寿命。您可以联系<u>allison@foresight.org</u>提出问题、定向资金请求或合作想法。</p><p>感谢您与我们一起推进技术带来的有益未来。</p><p><br><br></p><br/><br/> <a href="https://www.lesswrong.com/posts/uQ9Q5vdyvWpovS5ba/foresight-institute-2023-progress-and-2024-plans-for-funding#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/uQ9Q5vdyvWpovS5ba/foresight-institute-2023-progress-and-2024-plans-for-funding<guid ispermalink="false"> uQ9Q5vdyvWpovS5ba</guid><dc:creator><![CDATA[Allison Duettmann]]></dc:creator><pubDate> Wed, 22 Nov 2023 22:09:16 GMT</pubDate> </item><item><title><![CDATA[AISC project: TinyEvals]]></title><description><![CDATA[Published on November 22, 2023 8:47 PM GMT<br/><br/><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/sp1lu0wdyztp5mj9dbvf" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/lan1jdbplsajj1232h07 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/jj2xtln7lzpdovhzku8v 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/vr4bqq3gveu6ygfvw18d 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/reasdgr0pieqw03ys53f 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/rd1rsclplsrxhvvcukhq 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/ldnm6xznr2s3ryl2gcje 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/fefbjyt4ppqkgqhuuday 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/n5udsbfdodjomoyykbec 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/ssp1zdxfcyvygkmyirch 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aHE6rejJEkWspwnKu/j5c8j3ajzwhb2p1rtgw8 1024w"><br><a href="https://aisafety.camp/#Projects"><i><strong>申请</strong></i></a><i>在 2023 年 12 月 1 日之前在 2024 年人工智能安全营与我一起从事这个项目。</i></p><p><i>该项目不是一成不变的，我正在<strong>寻求反馈</strong>！</i></p><h1>概括</h1><p><a href="https://arxiv.org/abs/2305.07759"><u>TinyStories</u></a>是一套小语言模型 (SLM)，专门针对 ChatGPT 生成的儿童故事进行训练。这些模型使用简单而连贯的英语，这远远超过了之前在其他同等大小的模型中观察到的情况。</p><p>我希望使用当前可用的可解释性技术可以彻底理解这些模型的大部分功能。这样做将代表机械可解释性（mech interp）发展的一个重要里程碑。</p><p>该 AISC 项目的目标是发表一篇论文，系统地识别和描述 TinyStories 模型所展示的功能范围。虽然对底层电路的深入分析超出了当前的范围，但该项目代表了朝着这个方向迈出的重要的第一步。</p><p>清楚地了解这些模型的功能将鼓励研究界随后通过分析负责的电路来建立这些发现。这将进一步发展 mech interp，并提供有关语言模型内部工作方式的见解。</p><h1>动机</h1><h2>我的机甲解释变革理论</h2><ul><li>我对<a href="https://www.alignmentforum.org/posts/mcnWZBnbeDz7KKtjJ/rsps-are-pauses-done-right"><u>RSP</u></a>和<a href="https://www.alignmentforum.org/posts/LwJwDNFhjurAKFiJm/theories-of-change-for-ai-auditing"><u>审计</u></a>持乐观态度；简而言之：<ul><li>根据系统的危险能力和可证明的一致性来限制系统的训练、部署等</li><li>使用行为评估来测试危险能力</li><li>使用基于理解的评估来测试一致性</li></ul></li><li>我们还不知道如何进行基于理解的评估</li><li>当我们达到一定程度的危险能力时，我们要么<ul><li>继续并冒着灾难的风险或</li><li>停止并承担巨额调整税<ul><li>这对我来说没问题，但这使得监管实施的可能性降低</li></ul></li></ul></li><li>Mech interp 是一种很有前途的基于理解的评估方法</li></ul><h2>充分理解模型与逆向工程特定功能</h2><ul><li>目前，研究人员对平易近人或他们感兴趣的功能进行逆向工程；一些问题：<ul><li> “平易近人”默认缺少困难问题（我们甚至不知道它们是什么）</li><li> “有趣”可能并不是最相关的</li><li>它几乎普遍在狭窄的发行版上完成，并且没有提供对所涉及组件的一般理解</li></ul></li><li>相反，我们可以<ul><li>尝试对模型在训练数据集上表达的每项功能进行逆向工程<ul><li>如果我们失败了，我们只是发现了一个具体的开放问题</li></ul></li><li>对于每个组件，列出它负责的所有功能</li><li>识别功能未知的组件<ul><li>它们可能与安全直接相关<ul><li>例如，对战略欺骗负责</li></ul></li><li>或者强调一些我们还不了解的架构</li></ul></li></ul></li><li>最终，我们将对每个模型组件有一个大致的了解</li><li>我承认这是非常雄心勃勃的，拟议的项目只是朝这个方向迈出的第一步</li></ul><h2>为什么选择小故事？</h2><ul><li>模型和数据集都是开源的</li><li>模型很小，参数在 1 到 3300 万之间<br>“ <i>[...] 专注于小型模型的机械插补工作就很好，而且对于更快的反馈循环来说非常值得”</i> <a href="https://www.lesswrong.com/posts/Av3frxNy3y3i2kpaa/does-circuit-analysis-interpretability-scale-evidence-from#:~:text=focusing%20on%20mech%20interp%20work%20on%20small%20models%20is%20just%20fine%2C%20and%20extremely%20worth%20it%20for%20the%20much%20faster%20feedback%20loops"><i><u>~ Neel Nanda</u></i></a></li><li>该数据集小而简单，包含不到 2GB 的文本和大约 10,000 个独特的标记。此外，每一个准确的下一个代币预测对于人类来说都是逻辑上合理的；这些只是3-4岁孩子的故事</li><li>它们展现出的能力超出了人类在代码中可以实现的能力<br><i>“许多手动机械解释工作主要侧重于对更大模型的扩展解释，而不是更复杂的任务或综合解释，我认为后者更重要。”</i> <a href="https://www.lesswrong.com/posts/6FkWnktH3mjMAxdRT/what-i-would-do-if-i-wasn-t-at-arc-evals#Technical_AI_Safety_Research:~:text=A%20lot%20of%20manual,of%20the%20neural%20networks"><i><u>~ 陈劳伦斯</u></i></a></li></ul><h2>为什么现在才做评估？</h2><ul><li>风险<ul><li>可解释性是困难且开放的</li><li>我们将只是一个兼职的初级研究人员小团队</li></ul></li><li>杠杆作用<ul><li>通过创造大量的可解释性挑战，我们可以挖掘众多独立机械解释研究人员的潜力</li><li>我希望这对机械解释的作用就像 OpenAI Gym 对强化学习所做的那样</li></ul></li></ul><h1>涉及的步骤</h1><h2>识别能力</h2><p>从能力最差的模型开始。</p><ol><li>收集 TinyStories 验证数据集上正确的下一个标记预测的概率</li><li>可视化模型正确且对下一个标记预测充满信心的样本</li><li>识别最简单和最常见的模式或功能</li><li>过滤表达已识别能力的样本</li><li>返回步骤 2</li></ol><p>对下一个模型重复此操作，但过滤两个模型都正确且有信心的所有案例，以仅突出显示新功能。</p><h2>表征能力</h2><p>对于每个已确定的能力：</p><ol><li>尝试对功能进行红队<ol><li>你认为文本的哪些特征使得行为呈现出来？</li><li>有没有这种行为不存在的例子？</li><li>它适用于合成示例吗？</li><li>您可以在文本中更改哪些内容并仍然看到相同的结果？</li></ol></li><li>将其定义为一个任务，或一组（提示，正确答案）对</li><li>通过测量来评估每个模型在任务上的性能：<ol><li>正确答案的概率</li><li>正确答案的排名</li><li>如果有一个明显的错误答案：Logit different_answer and bad_answer</li></ol></li><li>总结结果<ol><li>能力是什么？</li><li>为什么学习有用？</li><li>哪些模型能够执行该任务？</li><li>所有示例的性能是否一致？如果不是，它们之间有什么不同？</li><li>变压器如何实现此功能？</li><li>所有模型在任务上的表现都一样好吗？如果不是，为什么会这样呢？</li></ol></li></ol><h2>写论文</h2><p>论文的结构和主要信息将取决于研究结果。我们应该在项目的第二个月开始写作。这将有助于巩固我们的理解，并将进一步的研究引向最有希望的方向。</p><h1>风险和缺点</h1><p>有一个很小的风险</p><ol><li>我们开发的识别能力的工具最终将支持能力工作</li><li>对我们确定的能力进行进一步的可解释性研究将激发新的见解</li></ol><p>请参阅<a href="https://www.alignmentforum.org/posts/iDNEjbdHhjzvLLAmm/should-we-publish-mechanistic-interpretability-research#Capabilities_externalities_of_mechanistic_interpretability"><u>我们应该发表机械可解释性研究吗？</u></a><u> </u>在广泛分享我们的工作之前，我们将寻求资深研究人员的建议。</p><h1>致谢</h1><p>我要感谢<a href="https://www.lesswrong.com/users/linda-linsefors?mention=user">@Linda Linsefors</a> 、 <a href="https://www.lesswrong.com/users/arthur-conmy?mention=user">@Arthur Conmy</a> 、 <a href="https://www.lesswrong.com/users/lucia-quirke-1?mention=user">@Lucia Quirke</a>和<a href="https://www.lesswrong.com/users/cmathw?mention=user">@cmathw</a>对此提案的反馈。我要感谢 Lucia Quirke、Lovis Heindrich 和<a href="https://www.lesswrong.com/users/rgrgrg?mention=user">@RGRGRG</a>分享他们对 TinyStories 的初步研究。</p><h1>团队</h1><p><strong>团队规模：</strong> 3-5 人（包括我自己），具体取决于他们的时间投入。这个问题有很大的表面积，人们可以轻松地并行工作。</p><p><strong>研究负责人</strong><br><a href="https://www.lesswrong.com/users/jett?mention=user"><strong>@杰特</strong></a><strong> </strong>（有任何问题请随时私信我）</p><p>在 Neel Nanda 的指导下，我参加了<a href="https://www.matsprogram.org/"><u>MATS</u></a> 2023 年冬季队列机械实习组。我合着</p><ol><li><a href="https://www.lesswrong.com/posts/u6KXXmKFbXfWzoAXn/a-circuit-for-python-docstrings-in-a-4-layer-attention-only"><u>4 层注意力变压器中的 Python 文档字符串电路</u></a></li><li><a href="https://arxiv.org/abs/2310.07325"><u>直接 Logit 归因的对抗示例：gelu-4l 中的内存管理</u></a></li><li><a href="https://www.lesswrong.com/posts/nuJFTS5iiJKT5G5yh/polysemantic-attention-head-in-a-4-layer-transformer"><u>4 层 Transformer 中的多语义注意力头</u></a></li></ol><p>项目 1 和 3 涉及大量的能力识别和特征描述，类似于我对此 AISC 项目的设想。在项目 2 和 3 中，我担任研究负责人/导师，并收到了积极的反馈。我承诺每周至少花 10 个小时来完成该项目。</p><p><strong>团队协调员：</strong>我更喜欢其他团队成员来担任这个角色。</p><p><strong>技能要求</strong><br>必需的：</p><ul><li> Python：模块、defaultdicts、计数器、迭代器、数据类、f 字符串</li><li>Jupyter 笔记本</li><li>Git：提交、分支、合并、解决冲突</li></ul><p>很高兴有：</p><ul><li>火炬</li><li>抱脸</li><li>变压器镜头</li><li>阴谋</li><li>机甲解释经验</li><li>研究经历</li></ul><p>很高兴拥有我所缺乏的：</p><ul><li>技术写作</li><li>网络开发：HTML、CSS、JS</li></ul><h1>附录</h1><h2>TinyStories 1M 中观察到的一些功能</h2><ol><li>N-gram<ol><li> <code>Once upon a <strong>time</strong></code></li><li> <code>From that day <strong>on</strong></code></li><li> <code><u>av</u> oc <strong>ados</strong></code></li></ol></li><li>重复的标记<ol><li><code>a big <u>house</u> with a lot of rooms. The <strong>house</strong></code></li><li> <code>there was a big <u>garage</u> [...] they needed more space in the <strong>garage</strong></code></li><li> <code>girl named <u>Lily</u> . [...] As they drove down the road, <strong>Lily</strong></code></li></ol></li><li>重复的多标记名称（归纳？）<ol><li> <code>a big, hairy rabbit named Bon <u>go</u> . Bon <strong>go</strong></code></li><li> <code>a little fish named Nem <u>o</u> . One day, Nem <strong>o</strong></code></li><li> <code>mouse named Tim <u>my</u> . He lived in a cozy hole in the wall of a big house. Tim <strong>my</strong></code></li></ol></li><li>常用短语（跳过卦？）<ol><li> <code>see <i>something</i> up <strong>close</strong></code></li></ol></li><li>具有不同标记化的复数到单数<ol><li><code>went to see the ze <u>br</u> as, Lily saw a unique z <strong>ebra</strong></code></li></ol></li><li>了解刚刚提供了背景，现在是讲故事的时候了<ol><li><code>Once upon a time, in a big forest, there lived a rhinoceros named Roxy. Roxy loved to climb. She climbed trees, rocks, and hills. <strong>One</strong></code></li><li> <code>Once upon a time, in a small yard, there was a small daisy. The daisy had a name. Her name was Daisy. Daisy was very small, but she was also very happy. <strong>\n</strong></code></li><li> <code>Once upon a time, there was a big, heavy alligator. He lived near a small pond. He was very hungry and wanted to eat something.\n\n <strong>One</strong></code></li></ol></li><li>知道何时结束报价<ol><li><code>Kitty smiled and replied, &quot;Thank you, Spot. I polish it every day <strong>.&quot;</strong></code></li><li> <code>Billy saw that Roxy was sad and asked, &quot;Why are you sad, Roxy <strong>?&quot;</strong></code></li><li> <code>The cow said, &quot;I am lonely. I want a friend <strong>.&quot;</strong></code></li></ol></li><li>代词<ol><li><code>Tim went to <strong>his</strong></code></li><li> <code>So, Mia and Tom played together. <strong>They</strong></code></li><li> <code>bought some light bulbs. When he came back, he put <strong>them</strong></code></li><li> <code>lemon on the ground. He wanted to play with <strong>it</strong></code></li></ol></li><li>预测相关概念： <code>bookshelf [...] <strong>book</strong> , park [...] <strong>grass</strong> , forgive [...] <strong>happy</strong> , lunchtime [...] <strong>eat</strong> , zebra [...] <strong>stripes</strong> , tree [...] <strong>climb</strong> , nurse [...] <strong>bandage</strong> , monkey [...] <strong>jungle</strong> , shop [...] <strong>counter</strong> , laundry [...] <strong>clothes</strong> , inside [...] <strong>goodbye</strong> , octopus [...] <strong>ocean</strong> , lost [...] can <strong>&#39;t</strong> , road [...] <strong>driving</strong> , emergency [...] <strong>doctor</strong> , milk [...] <strong>spilled</strong> , hammer [...] screw <strong>driver</strong> , Daddy [...] Mom <strong>my</strong></code></li><li>间接对象​​识别<ol><li><code>Spot saw the shiny car and said, &quot;Wow, Kitty, your car is so bright and clean!&quot; Kitty smiled and replied, &quot;Thank you, <strong>Spot</strong></code></li><li> <code>Buddy kicked the ball with his strong legs. The ball flew into the goal! Spot was so happy. He and <strong>Buddy</strong></code></li><li> <code>One sunny day, Amy went to the yard with her friend, Max. Max saw the purple swing and said, &quot;Wow! I want to swing too!&quot; <strong>Amy</strong></code></li></ol></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/aHE6rejJEkWspwnKu/aisc-project-tinyevals#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/aHE6rejJEkWspwnKu/aisc-project-tinyevals<guid ispermalink="false"> aHE6rejJEkWspwnKu</guid><dc:creator><![CDATA[Jett]]></dc:creator><pubDate> Wed, 22 Nov 2023 20:47:32 GMT</pubDate> </item><item><title><![CDATA[Neither Copernicus, Galileo, nor Kepler had proof]]></title><description><![CDATA[Published on November 22, 2023 6:41 PM GMT<br/><br/><p>这篇文章打破了有关天文学发展的一些神话。例如，直到最近我才知道开普勒椭圆也适合里乔利制作的地心模型。</p><br/><br/> <a href="https://www.lesswrong.com/posts/dBqaubnmJvtS6Lvxr/neither-copernicus-galileo-nor-kepler-had-proof#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/dBqaubnmJvtS6Lvxr/neither-copernicus-galileo-nor-kepler-had-proof<guid ispermalink="false"> dBqaubnmJvtS6Lvxr</guid><dc:creator><![CDATA[Meow P]]></dc:creator><pubDate> Wed, 22 Nov 2023 22:44:43 GMT</pubDate> </item><item><title><![CDATA[So you want to save the world? An account in paladinhood]]></title><description><![CDATA[Published on November 22, 2023 5:40 PM GMT<br/><br/><blockquote><p>奥罗登给了我成为一名圣战士的力量，也给了我明智地选择战斗的智慧……并帮助我变得足够强大，以拯救每个人，真正的每个人，并且不要让我的力量伴随着对弱者的蔑视，或我的智慧，蔑视愚蠢……并照顾每个人……在这个陌生的国家，在你去过的所有世界和你没有去过的所有世界。</p><p>并使地狱停止。</p></blockquote><p> – Iomedae，奥罗登圣骑士；<a href="https://glowfic.com/replies/1974491#reply-1974491">摘自林塔曼德的发光小说“<em>在他的力量下，我将敢、敢、敢，直到我死</em>”</a></p><h1>介绍。</h1><p>几年前，我努力让自己思考协调问题，而不是制作视频游戏和阅读同人志。今天，我发现我的尊严点输出的主要剩余瓶颈是我的体力，并且我可能会对p（doom）产生实际的显着影响。</p><p>这篇文章是关于我如何到达那里的。这是用祈使时态讲述的，因为我希望这可以作为建议；但请注意，人类的思维空间是多种多样的，即使在错误较少的理性主义者中也是如此，对我有用的东西可能对你不起作用。 （也就是说，看起来并没有很多人在努力争取圣骑士或类似的职位。）</p><h1>什么是艾奥梅达？</h1><p> （如果你不知道什么是发光小说，也许可以看看<a href="https://recordcrash.substack.com/p/mad-investor-chaos-woman-asmodeus">尤德科夫斯基和林塔曼德的发光小说<em>《飞机坠毁》</em>的评论</a>。）</p><p>在涉及 linta!golarion 的发光小说中（lintamande 对<em>golarion</em>的诠释，桌面 RPG<em>探路者</em>的背景），Iomedae 是“击败邪恶”的守序善良女神——或者，正如<a href="https://glowfic.com/replies/1966069#reply-1966069">lantalótë 所说</a>：</p><blockquote><p>艾奥梅黛是一位善良的女神，但她不是其中任何一位女神。她不是美好事物的女神。她是<em>优先考虑</em>的女神，她看着世界的所有恐怖，并说“以后会有足够的时间来爱、美丽、欢乐和家庭。”但首先我们必须让世界对他们来说是安全的。”</p></blockquote><p>在成神之前，艾奥梅黛是文明之神奥罗登的<em>圣骑士</em>。各种各样的林塔曼德发光小说在不同的场景中都有出现，但<a href="https://glowfic.com/replies/1974491#reply-1974491">“<em>在他的力量下，我会敢、敢、敢，直到我死</em>”</a>特别讲述了她成为圣骑士后不久，在美国获得异世界，然后被儿童保护机构收养的故事。服务，并试图了解她所出现的这个奇怪的世界，以及在那里做好事对她意味着什么。</p><p> （在这篇文章中，当我粘贴引用而不提及其来源时，其来源将是那个特定的发光小说。）</p><h1> “圣骑士”是什么意思？</h1><p> linta!Iomedae 的圣骑士身份对<em>我</em>来说代表着什么，那就是<em>全心全意地致力于做重要的事情；不惜一切代价拯救世界</em>。她的圣武士身份——也就是说，<em>她作为一名圣武士的身份</em>——并不是她所承受的<em>负担</em>；而是她所承受的负担。这是她内心深处<em>想做的</em>事。</p><p>我<em>会</em>高兴地按下一个按钮，立即将我的思维方式转变为艾奥梅黛的思维方式；经过深思熟虑，我赞成成为一个不惜一切代价拯救世界的人，即使自己付出巨大的代价。但人类的大脑是一种奇怪的装置！我们没有这样的按钮；如果我们想改变自己，就必须付出很多努力。</p><p>我发现自己现在大部分时间都在艰苦工作的另一边，对自己现在的成就感到满意。七年前，当我第一次熟悉序列和其他理性主义作品时，我没有经历过这一点，这是极大的浪费。但我不会纠缠它，因为纠缠它实际上无助于拯救世界。</p><p> （请注意，当我决定努力拯救世界时，我最初并没有意识到圣骑士的概念。这是我事后才了解到的，并且认为它很适合我，作为一种美学.我的大脑非常喜欢美学和叙事；拥有一个可以认同的原型可以帮助我向自己和他人具体化我想要的东西。）</p><h1>人类的思维和序列</h1><p>人类的思维真是<em>太奇怪了</em>。</p><p>例如：我希望如果我将这篇文章描述为“你<em>应该</em>想要拯救世界，那么这就是如何”，而不是“<em>如果</em>你想拯救世界，那么这就是如何”，一群目前正在使用的人相反，拥有此帖子的董事会会感到受到攻击，并通过寻找借口拒绝此帖子的内容来做出反应。</p><p>需要大量的<strong>认知纪律</strong>和<em>认知卫生</em>*来检验一个命题而不立即以某种方式做出反应。即使是现在，我也不能幸免！</p><p>我们不擅长理性。<strong>这就是<a href="https://www.readthesequences.com/">序列</a>存在的原因</strong>。如果我们完全理性，我们就不需要所有这些艰苦的工作来真正相信真实的事情并采取良好的行动。我们必须训练我们的系统 2 来注意我们何时犯下非理性错误，直到系统 1 最终学会在认知和能动性方面做得更好。</p><p>如果您还没有读过，我认为<strong>您应该<a href="https://www.readthesequences.com/">阅读这些序列</a></strong>。当然，它们远非完美，它们涵盖的很多内容都被认为是常识。但总的来说，我仍然认为这对于那些想要拯救世界的人来说有很大的价值。引用<a href="https://yudkowsky.tumblr.com/post/81447230971/my-april-fools-day-confession">dath ilan 的原始帖子</a>：</p><blockquote><p>达斯伊兰的任何人都会告诉你这一点。他们读过真实的东西，接受过真正的训练，而不是我能记住并写进序列的可怕的混乱。</p></blockquote><p>这些序列比达斯·伊兰的教育材料差得多。但这也是<em>我们拥有的唯一的达斯伊兰神器</em>。</p><h1>圣骑士的核心</h1><p>圣骑士的核心是，在你拥有的每一个自由度上，选择能够最大化效用的选项。非常简单！其他一切都在其下游。</p><p>是的，休息和照顾自己的健康是其下游，因为一个更健康的圣武士可以拯救更多的世界。是的，拥有一个善待他人的一般原则是其下游，因为一个以善良和乐于助人而闻名的圣武士往往会拥有更多的资源来拯救世界。</p><p>人类的大脑倾向于寻找借口来拒绝外部的论点，敦促人们采取不同的行动或以不同的方式思考。事实上，有些人会说这样的话</p><blockquote><p>实际上，你不应该只是最大化效用，你还应该休息一下，这样你才能健康，所以这篇文章是错误的，我可以忽略它！</p></blockquote><p>是非理性地避免采取正确行动的一个例子。再说一次，我自己也经常陷入这种困境，现在仍然如此！目前尚不清楚人类大脑的哪些部分总是试图制造这些借口。</p><p>对我来说，我认为我大脑的一部分认为让别人弄清楚我应该做什么而不是我自己弄清楚在某种程度上<em>是不光彩的</em>。</p><p>但大脑的哪一部分负责这些借口并不特别重要。重要的是<em>注意到一个人正在产生它们</em>，并<em>养成不这样做的习惯</em>。</p><p>我认为，<em>不必改变的借口</em>实际上是人们选择相信人工智能绝对不能杀死所有人，或者人工智能杀死所有人的一个非常深刻的原因。这些信念并不是根本性的事情，而是根本原因。他们在内心深处<em>寻找借口，避免自己犯错，避免改变自己的行为或信念</em>。 （请注意：感觉人们不愿意改变他们通常不做的领域的行为或信念，这可能从根本上是执行功能障碍的一种形式？执行功能似乎<strong>非常重要</strong>。）</p><p>如果你想拯救世界，最大化效用（使用<a href="https://arbital.com/p/logical_dt/">正确的决策理论</a>）<em>实际上完全抓住了重要的事情</em>。并不是说你必须通过实际数学来比较效用；大多数时候，我很清楚哪个选择是最好的。最终，效用最大化是一个<em>订购</em>问题，而不是<em>数量问题</em>：您不需要计算<em>出有多少余量的</em>选择是最好的，您只需要知道它是最好的。</p><p>哦，显然，不要完全放弃所有规则功利主义/义务论指导方针。这是合理性的一部分，但值得重复。我的主张并不是说你应该选择感觉“天真的”看似最佳的行动，而不是合理的规则功利主义启发法所推荐的行动；我的主张是，你应该引导你目前所采取的行动保持现状/什么是最简单的/什么是最舒适的/什么是其他人说的/无论什么。</p><p>您应该对所有行动都有<em>意图</em>，并检查您是否错过了可以采取的一些重要行动。这种意图可以是“啊，是的，我的认知资源的最佳分配就是在这里应用规则功利主义启发法”——但它应该是<em>某种意图</em>。</p><h1>等等，这里有什么新内容？</h1><p>这篇关于“圣武士”的文章可以被解释为只是对常规的不太错误的理性主义后果论的重新包装。</p><p>有点像！但我觉得我们现在可以使用一个新的软件包，其中有一些有用的建议。</p><p>不，你不必特别关心“圣骑士身份”来成为拯救世界的人。但如果认同叙事确实<em>能</em>像我一样帮助你的思想融入角色，那么我希望“圣骑士”之类的东西有希望。</p><p>很可能，像林塔！格拉里昂这样的圣骑士与我不同。在我生命的前 28 年左右，我确实把事情看得很轻松，根本不分轻重缓急——甚至许多<em>地球人</em><a href="https://www.lesswrong.com/posts/F2DZXsMdhGyX4FPAd/on-saving-the-world#Deciding_to_Save_the_World">都有更长的<em>关心</em>和<em>尝试</em>的历史</a>。</p><p>我之所以决定采用这种叙述，并不是因为我认为我比其他人更值得这样做——我采用它是因为它<em>可以帮助我的大脑做这件事</em>。</p><p>我试图做出最能拯救世界的选择，结果发现其中之一就是受发光角色的启发而进行模糊的角色扮演。</p><h1>特权</h1><blockquote><p>大多数圣骑士都很富有，真的，因为你需要盔甲和剑，而只有有钱人才有这些，你需要让一个强壮健康的孩子去为奥罗登服务一生，绝望的家庭离不开一个坚强健康的孩子。</p></blockquote><p>有些人比其他人更有能力拯救世界。当我开始尝试拯救世界时，我（排名不分先后）：</p><ul><li>心理和身体都非常健康</li><li>高水平的智力，沿着一些似乎很重要的轴</li><li>熟悉与对齐相关的计算机科学领域，以及强大的软件工程技能</li><li>阅读了<a href="https://www.readthesequences.com/">序列</a>、<a href="https://slatestarcodex.com/2014/07/30/meditations-on-moloch/">对莫洛赫的沉思</a>以及各种其他理性主义非小说作品</li><li>近二十年来一直以各种方式思考超级智能</li><li>拥有良好福利和公共医疗保健的富裕西方国家的公民身份和居住权（法国）</li><li>有足够的金钱和节俭的技巧，可以有<em>一些</em>物质上的余裕</li><li>让我听说并进入<a href="https://www.lesswrong.com/posts/D7epkkJb3CqDTYgX9/refine-an-incubator-for-conceptual-alignment-research-bets">Fine</a>研究孵化器的社会关系</li><li>一些非常聪明且非常支持的朋友关系，并且对理性主义社区有深入的了解</li><li>一直在训练我的大脑练习<em>一定程度</em>的认知/模因卫生；引用一位恶魔的话说，“你的大脑是一个反认知偏见防护措施的迷宫，对吧？”</li><li>傲慢/自恋的历史让我有信心认为我可以帮助调整，并克服我的一些冒名顶替综合症</li><li>足够好的社交技能</li><li>写得又好又快的能力</li><li>我自己的平台（<a href="https://carado.moe/">我的博客</a>）以及在那里撰写一些相关主题的历史（价值观、人类学和计算宇宙学），并且通常对这些主题的困惑程度较低</li></ul><p>不要误会我的意思，我也有一些障碍，其中一些特权是我通过早年做出正确的选择而获得的。</p><p>因为我的目标是拯救世界，所以我将这篇文章针对那些更有可能帮助拯救世界的人。</p><p>如果你发现自己没有足够的特权，拯救世界对你来说似乎极其困难，我不完全确定该给出什么建议，抱歉。有些人会度过一段非常糟糕的时光，对他们来说，照顾好自己实际上比尝试解决对齐问题更有用。你也是一个道德病人！成为一名圣武士并不会让你比其他人<em>更少</em>成为一个道德病人，它只是让你意识到你和其他人<em>一样</em>是一个道德病人。</p><p>请注意，许多人往往<a href="https://www.lesswrong.com/posts/XkmG8XGf6uhXLmZN7/so-you-think-you-re-not-qualified-to-do-technical-alignment">高估了为技术一致性做出贡献的门槛</a>；您很可能会遇到这种情况。</p><h1>空字符串，内部视图与外部视图</h1><p>尤德科夫斯基有句名言提到，他对人工智能的批判信念源自（ <a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities?commentId=GyFidKQtqFjptmq2i">几乎</a>）<a href="https://twitter.com/ESYudkowsky/status/1500863629490544645">空弦</a>——也就是说，他不需要外界的说服，他只是想了很多，然后得出了他的结论。做过。我相信在这方面我和他很相似。</p><p>拥有内心的观点、对你来说有意义的信念，而不仅仅是相信别人，是极其重要的。</p><p>假设您担心动物的痛苦。你应该意识到，到目前为止，对未来动物遭受多少苦难影响最大的因素取决于哪种人工智能将不可避免地接管世界，然后你应该决定做<em>一些事情这会影响什么样的人工智能将不可避免地接管世界</em>。</p><p>这项工作可以是直接的（构建拯救世界的对齐人工智能）或间接的（试图让试图解决对齐问题的人们获得足够的时间和资源来成功，然后人们在功能上试图通过以下方式杀死所有人）构建那种杀死所有人的人工智能都会成功）。但对于这<strong>两个</strong>问题，你<strong>应该</strong>非常努力地深刻理解，你预计需要多长时间才能有人构建出杀死所有人的人工智能，以及构建拯救世界的一致人工智能需要什么。</p><p>如果你不知道什么样的人工智能会杀死所有人，什么样的人工智能会拯救世界，以及什么样的人工智能两者都不会（因此只有在影响前两者的概率时才有意义），那么你就没有办法知道<em>哪个是哪个</em>。</p><p>人们喜欢依赖<em>外部观点</em>——在感知共识、感知连贯性、感知地位和彻底氛围的混合基础上采纳他人的信念——因为这节省了他们思考问题的辛苦工作，也因为他们对于提出自己的信念感到冒名顶替综合症。这导致了大量的<a href="https://www.readthesequences.com/Fake-Causality">重复计算</a>，我发现<a href="https://carado.moe/outside-view-double-counting.html">漫画</a>最容易说明这一点。</p><p>你<em>可以</em>考虑其他人的意见，但你的标准应该是他们似乎具有多少<em>认知严谨性和认知卫生性</em>——你自己需要认知严谨性和卫生性来确定谁表现出良好的认知严谨性和卫生性，并且你应该小心双重-当你的一位消息来源因为从<em>另</em>一位消息来源那里听到某件事而说某件事时，就会计算索赔。</p><p>除其他外，拥有认知卫生还需要：不容易受到模因、社会压力信念和其他导致证据过滤问题的选择效应的影响。有关认知严谨性的更全面的培训，<a href="https://www.readthesequences.com/">请参阅序列</a>。</p><p>实际上，最安全的方法是自己建立一个可靠的内部视图模型，并主要依赖它。</p><p>此外，人类的思想非常容易受到社会压力的影响，包括信仰的压力。如果——像我一样——你倾向于在系统1中假设人们在使用自信的语气时知道他们在说什么，那么你应该非常小心，只和<em>真正</em>使用自信的人一起出去玩——语气来表达他们的实际信心，同时意识到自己的困惑。</p><p>让我相信别人所说的话的主要原因是他们有良好的认知，而不是他们不诚实。人工智能安全领域存在大量错误，这几乎都是非理性而非敌意的结果。</p><p>形成扎实的内部观点并保持良好的认知卫生的一种安全方法是<em>，无论何时何地，根本不谈论/听到/阅读有关人工智能的内容</em>。虽然不是故意的，但这就是我自己实施的策略：我自己思考了这个话题，没有真正进行研究或少错，这让我摆脱了社会压力信念，以至于当我终于开始阅读少错时，在与对齐研究人员的交谈中，我对人工智能对齐和人工智能末日形成了自己的全面看法。然后，我对照其他人检查了我的信念，更新了对我来说有意义的论点，并且非常重要的<strong>是，当我观察到人们不同意因为他们没有考虑我自己一直在考虑的事情时，维持我的信念</strong>。</p><p>但是，如果您看到一个人说了一些对您来说没有意义的事情，那么您应该像看到<em>一百个人</em>说同样的事情一样进行更新。通过连贯性而不是重复性来衡量论证，根据人们的认知质量而不是他们的地位来衡量人们。</p><p>另外，当你听到一个主张时，你还应该注意到他们所说的主张<em>很重要的</em><em>隐含</em>主张。你应该注意到这个隐含的主张，并思考它是否有意义，以及它是否来自认知上卫生和严谨的地方。如果没有，那么你就<em>不必花精力去思考这个无关的话题</em>，无论有多少人在谈论它。</p><p><em>积极主动</em>的人——那些正在<em>努力的</em>人，比如试图拯救世界的人——会<em>考虑</em>并<em>专注</em>于他们选择说的话。他们传达的信息不仅仅是所说的内容，而是他们选择说的话以及他们选择说的方式。引导世界，包括引导你的想法和谈论的内容，少关注那些没有特别确保他们正在谈论他们所谈论的内容的人。</p><p>另请参阅<a href="https://www.lesswrong.com/posts/PqMT9zGrNsGJNfiFR/alignment-research-field-guide">MIRI 的对齐研究领域指南</a>中的引用：</p><blockquote><p>我们为什么选择编写这份文档？我们对它有何期望？是什么促使我们从所有可能性中选择了这种特定的格式和内容？</p></blockquote><p>这就是代理/执行职能如此重要的原因。你可能在某些话题上是天才，但如果你没有<em>把</em>自己的目标瞄准正确的事情，那么你本质上只是在挖沟渠。为了拯救世界，你必须引导世界，包括你的想法、做法和言论。</p><h1>做一个直率、严肃、合理的理性主义者</h1><p>与理性主义<a href="https://www.glowfic.com/replies/1839717#reply-1839717">相邻的分支有多少，就有多少借口去做一种不太错误的理性的奇怪变体（链接有坠机剧透）</a> 。</p><p>此外，讽刺是人们最喜欢的不必改变想法或行为的借口之一——如果你找到一种方法来不认真对待重要的事情，并且如果这种方式<em>被周围的迷因丛认为很酷</em>，那么你就找到了一种非常舒服的方式。甚至不去<em>想</em>是否应该改变主意或行动！</p><p>但不，常规的较少错误的理性实际上是正确的事情，如果<em>有</em>一种氛围原型美学<em>确实</em>促进了真诚并至少<em>允许</em>认识上的严格性，那么它就是一个<strong>直截了当的、严肃的、合理的理性主义者</strong>。避免模​​因、深奥的东西、老鼠崇拜、讽刺等。</p><p>人类的思维<em>喜欢</em>执着于<em>审美</em>或<em>模因的</em>事物，而不是<em>真实的</em>事物。保持认知安全的方法是保持良好的模因卫生，不要让你的大脑接触那些你<em>知道</em>你的大脑会因为与<em>实际真相</em>无关的变量而试图相信的事情。</p><p><em>无论如何，不​​要试图对抗模因并评估其真实价值</em>。那太愚蠢了。这就像为了变得坚强而让自己接触尽可能多的疾病——事实并非如此。</p><p>然而，你不必让{你头脑中关心美学的部分}挨饿！成为一个直率、严肃、合理的理性主义者有其独特的审美观——事实上，理性主义小说在理性主义群体中扮演着一种有益的角色：它让{成为一个直率、严肃、合理的理性主义者}变得<em>很酷</em>，一种可以让人感受到的氛围。适应。</p><p>如果你表现得像动漫人物，那么你在动漫中获胜，在现实生活中失败。<br>如果你表现得像一个科幻小说中的人物，那么你在科幻小说中就赢了<strong>，在现实生活中你也赢了。</strong></p><p>模因就是它们，你的大脑当然会<em>很想</em>参与它们所有的废话。可能需要坚持不懈的努力才能保持认知卫生。但总的来说，这<em>是</em>一种让人们思考如何拯救世界的行动，这是拯救世界所必需的。</p><h1>尝试并磨砺尝试</h1><p>人类心灵的品质之一是其可塑性。我注意到，当我第一次尝试变得更加像圣骑士时，我的思想是抗拒的——它想要坚持其美德伦理，即使在结果最优选择明显不同的情况下也是如此。我花了很多努力来克服对美德伦理的执着，以及我学会的各种其他生活方式。</p><p>但后来我意识到，在抵抗的同时，它也慢慢屈服了——以至于几个月后，我发现采取结果主义行动要容易得多。</p><p>我发现这也适用于专注、严谨和耐力。</p><p>与角色扮演游戏类似，如果你挑战自己的极限，你实际上就会进步。</p><p>当你面临选择做舒服的事还是做正确的事时，这也可以起到激励作用——如果你做正确的事，不仅会产生更多的效用，而且你会更容易做出正确的选择在以后的每一次场合。</p><p>如果你对自己要求过高，休息一下是可以的——你不想精疲力竭。这是一个仔细的平衡。我发现，如果我把自己逼到<em>轻微的</em>倦怠，我可以通过几天到几周的休息来恢复——所以我实际上有一个安全网，以防我把自己逼得太紧。</p><p>也许只有我注意到 EA/老鼠圈子里存在一些关于<em>更加努力的</em>耻辱。有些人非常反对我们应该更加努力的观点。不用说，我不同意；更加努力<em>可以提高您从此以后可以轻松地推动自己的程度</em>。</p><p>如果你磨练 XP，你就会升级并且你的最大生命值也会增加。如果你的生命值足够低，你可以随时回来休息。</p><p>休息本身就是一种技能。这些天，我觉得我对什么时候应该停止工作有了一定的判断力；那些日子里，我实际上<em>一整天都不工作</em>。</p><h1>如果只有你知道…</h1><p>注意你有多困惑，并推断其他人可能有多困惑。</p><p>注意你需要付出多少努力才能专注于重要的事情而不被分心或书呆子狙击，并推断其他人有多大可能专注于正确的事情，以及他们所说的话有多大可能会分散注意力/书呆子狙击。</p><p>请注意您需要付出多少努力来隐瞒一些危险信息，并推断其他人泄露您与他们共享的信息的可能性有多大。</p><p>注意它需要你做多少工作才能<em>在认知上严格、认知卫生、<a href="https://intelligence.org/2017/11/25/security-mindset-ordinary-paranoia/">安全心态地</a></em>确保你的对齐想法成立，并推断出在 AGI 实验室工作的人员有多大可能正确实施对齐。</p><p>请注意，成为那种试图拯救世界而不屈服于讽刺、模因、愤世嫉俗或其他借口来忽略困难部分的人是多么困难，并推断<em>事情到底有多糟糕</em>。</p><p>当你这样做时，<a href="https://www.glowfic.com/replies/1751366#reply-1751366">不要惊慌</a>。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Qw6qsgR2Qm6rp574A/ow8axpjx6xeg9jtma2am" alt=""></p><p>掌控世界的一部分就是掌控自己，掌控自己的一部分就是掌控自己的感受。是的，情况很糟糕，但沉迷实际上并不会让你更好地拯救世界。是的，将世界从某些白痴的愚蠢中拯救出来的重担落在如此少数人的肩上，这让人感觉不公正和令人沮丧，但沉溺于这些不公正和沮丧的感觉中不会有任何帮助。</p><p>是的，不得不放弃这些感觉并做相应正确的事情是令人不愉快的。非常不愉快！我觉得我非常看重的人格核心部分正在受到攻击。</p><p>但后来我逼自己一把，最终侵蚀了我的那一部分，现在我是一个试图拯救世界的结果主义者。在世界被拯救之后，当<a href="https://carado.moe/rationalist-by-necessity.html">我不再需要工具理性</a>并且我可以<a href="https://www.lesswrong.com/posts/CMHogeqTTajhmnEKx/everything-is-okay">再次放松</a>时，我将回到乌托邦中那个有趣而愚蠢的情感自我。</p><p>但现在，如果你想成为一名圣骑士，你就必须面对现实。为了做出正确的决定，你必须能够面对事情到底有多糟糕。</p><p>然而，如果您是一名圣武士，您还会收到一些好消息：还有一位圣武士正在尝试拯救世界！</p><h1>你的道德耐心</h1><p>有些人在面临圣骑士身份时，认为其他人比自己更重要，并且他们放弃了人格或道德耐心。</p><p>我认为这是错误的。</p><p>当人们认为他们“为几乎每个人拯救世界，除了那些注册的人”（有时会加上“哦，而且只有<em>我</em>得到知情同意才能注册”时，显然犯了一个根本性错误。这是出于某种原因”）。这里有一些根本性的错误。</p><p>在我看来，圣骑士应该<em>像</em>其他人一样认为自己是道德患者。</p><p> “如果你认为自己是一个人/道德病人，那么你怎么可以<em>侵蚀自己的一部分</em>呢？”</p><p>嗯，确实有三个原因。首先，这是非常特殊的情况，有很多事情悬而未决，实际上，如果人们知道自己在做什么并且这确实有帮助，那么他们就可以这样做。第二个是我非常看重自由，包括走这条路的自由。我不知道我是否珍视<em>任意的</em>自由——我不认为我应该能够永远承受不可逆转的最大痛苦。值得庆幸的是，拯救世界并不需要付出这样的代价！事实上，我似乎仍然比地球上的大多数人过得更好。有些人有自己相当大的生活问题需要处理，而我必须竭尽全力拯救世界。</p><p>第三，再次强调，一旦世界被拯救，我或许就能恢复自我。事实上，从长远来看，拯救世界不仅对每个人（除了我）都是最好的，而且对我来说也是最好的。如果不是这样，如果这意味着我的死亡，我仍然<em>会</em>拯救世界；但事实上，不，拯救世界<em>实际上不仅让我获得最大的效用，而且让我个人获得最好的生活</em>。</p><hr><p>如果您确实成为了圣骑士，或者您已经在这篇文章中认出了自己，<a href="https://www.lesswrong.com/users/tamsin-leake">请给我发消息</a>。我想和更多的圣骑士成为朋友。</p><p>我将通过链接<a href="https://www.glowfic.com/replies/1946079#reply-1946079">Plancrash 结尾处的一对回复来结束这篇文章（剧透！）</a> 。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Qw6qsgR2Qm6rp574A/srafp2q50ratls3mliid" alt=""></p><br/><br/> <a href="https://www.lesswrong.com/posts/Qw6qsgR2Qm6rp574A/so-you-want-to-save-the-world-an-account-in-paladinhood#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Qw6qsgR2Qm6rp574A/so-you-want-to-save-the-world-an-account-in-paladinhood<guid ispermalink="false"> Qw6qsgR2Qm6rp574A</guid><dc:creator><![CDATA[Tamsin Leake]]></dc:creator><pubDate> Wed, 22 Nov 2023 17:40:33 GMT</pubDate> </item><item><title><![CDATA[OpenAI: The Battle of the Board]]></title><description><![CDATA[Published on November 22, 2023 5:30 PM GMT<br/><br/><p>上一篇：OpenAI： <a target="_blank" rel="noreferrer noopener" href="https://thezvi.substack.com/p/openai-facts-from-a-weekend">周末的事实</a>。</p><p>周五下午，OpenAI 董事会解雇了首席执行官 Sam Altman。</p><p>一夜之间， <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/eshear/status/1727210329560756598">原则上达成协议，</a>恢复 Sam Altman 担任 OpenAI 首席执行官，最初的新董事会由 Bret Taylor（Salesforce 前联合首席执行官，主席）、Larry Summers 和 Adam D&#39;Angelo 组成。</p><p>发生了什么？为什么会发生这样的事？最终又会如何收场呢？战斗还远没有结束。</p><p>我们并不完全知道，但我们知道的比几天前要多得多。</p><p>这是我将这些碎片拼凑在一起的尝试。</p><span id="more-23600"></span><h4><strong>这是一场控制权之战；奥特曼开始了</strong></h4><p>这过去是、现在仍然是一场关于 OpenAI、其董事会及其方向的控制权之争。</p><p>这是一场长期酝酿的斗争和辩论。赌注很高。</p><p>直到最近，萨姆·奥尔特曼仍在努力按照自己的形象重塑公司，同时与董事会发生冲突，而董事会却几乎没有采取任何行动。</p><p>虽然我必须强调，我们不知道董事会的动机是什么，但奥特曼最近的权力举动可能在迫使董事会采取行动方面发挥了作用。</p><h4> <strong>OpenAI 是一家有使命的非营利组织</strong></h4><p>OpenAI 及其董事会的结构使控制权受到质疑。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://arstechnica.com/information-technology/2023/11/report-sutskever-led-board-coup-at-openai-that-ousted-altman-over-ai-safety-concerns/?utm_medium=social&amp;utm_source=twitter&amp;utm_social-type=owned&amp;utm_brand=ars">这是OpenAI的结构图：</a></p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff44095b-3f36-4496-a4bc-f8170140f435_873x652.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sGpBPAPq2QttY4M2H/svrwplczzxeqxbmofw7t" alt="OpenAI 不寻常结构的框图，由 OpenAI 提供。"></a></figure><p><a target="_blank" rel="noreferrer noopener" href="https://openai.com/charter">这是 OpenAI 的使命宣言</a>，该链接还包含预期的实施细节：</p><blockquote><p>本文档反映了我们在过去两年中完善的策略，包括 OpenAI 内部和外部许多人的反馈。 AGI 的时间表仍不确定，但我们的宪章将指导我们在整个发展过程中以人类最大利益为重。</p><p> OpenAI 的使命是确保通用人工智能 (AGI)——我们指的是在最具经济价值的工作中超越人类的高度自治系统——造福全人类。我们将尝试直接构建安全且有益的通用人工智能，但如果我们的工作帮助其他人实现这一成果，我们也将认为我们的使命已经完成。</p></blockquote><p> OpenAI 警告投资者，他们可能赚不到钱：</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c2f3d5a-4394-420d-9ab6-f68ceda8291d_661x355.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sGpBPAPq2QttY4M2H/piau5mxtaft2kxuogkwh" alt="图像"></a></figure><p> 501(c)3 的运作方式本质上是董事会不对任何人负责。如果您在一次会议上拥有董事会多数席位，您就可以完全控制董事会。</p><p>但董事会有权力吗？有点。它具有监督作用，这意味着它可以雇用或解雇首席执行官。董事会通常利用这种杠杆作用来有效地负责重大决策。其他时候，首席执行官有效地控制着董事会，首席执行官为所欲为。</p><p>一个关键的缺陷是，解雇（和雇用）首席执行官以及选择新董事会的组成是董事会唯一的实际权力。</p><p>董事会只有一招。它可以解雇首席执行官，也可以不解雇首席执行官。解雇首席执行官是一次重大升级，有可能造成混乱。但升级和破坏是有代价的，包括声誉和财务成本。知道这一点后，首席执行官可以而且经常采取行动让他们在被解雇时感到痛苦，或者计算出董事会不敢这样做。</p><h4><strong>山姆·奥尔特曼的观点</strong></h4><p>虽然 Sam Altman 对 OpenAI 的最终目标更为宏伟，但他希望 OpenAI 目前主要作为一家与微软合作的普通大型科技公司运作。他想要建造和运输，快速行动并打破常规。他希望开展新的业务，以消除瓶颈并获得新业务的股权， <a target="_blank" rel="noreferrer noopener" href="https://www.bloomberg.com/news/articles/2023-11-19/altman-sought-billions-for-ai-chip-venture-before-openai-ouster">包括规划在阿联酋建立一家沙特资助的芯片工厂，以及启动一个人工智能硬件项目</a>。他根据自己的商业利益进行游说，并将个人权力、估值和融资轮次、股东和客户放在第一位。</p><p>为此，多年来，他通过加减法重塑了公司文化，聘请了那些相信这一使命并且个人忠于他的人。他对公司的架构很可能是为了给予他自由发挥的空间，并向董事会和其他人隐瞒他的行为。正常的CEO做正常的CEO的事情。</p><p>保罗·格雷厄姆<a target="_blank" rel="noreferrer noopener" href="http://www.paulgraham.com/5founders.html">说</a>，奥特曼非常擅长<a target="_blank" rel="noreferrer noopener" href="http://www.paulgraham.com/fundraising.html">变得强大</a>并<a target="_blank" rel="noreferrer noopener" href="https://x.com/paulg/status/1717097106270237151?s=20">玩权力游戏</a>，他是世界上最好的。这以及扩大科技初创公司规模是他本性的核心。人们认为“不完全坦诚”和其他战略行动是其中的一部分。</p><p> Sam Altman 的中期目标从一开始就是完全个人控制 OpenAI，从而控制 AGI 的构建。权力总是想要更多的权力。我不能责怪他在目标上的理性工具趋同。最终目标是构建“安全”的 AGI。</p><p>这并不意味着萨姆·奥尔特曼不相信确保人工智能安全的必要性。奥特曼明白这一点。我不认为他了解这将是多么困难或即将面临的全部困难，但他比大多数人更了解这些问题。他签署了<a target="_blank" rel="noreferrer noopener" href="https://www.safe.ai/statement-on-ai-risk">CAIS 的信函</a>。他<a target="_blank" rel="noreferrer noopener" href="https://www.nytimes.com/2023/05/16/technology/openai-altman-artificial-intelligence-regulation.html">在国会坦率作证</a>。与许多为他辩护的人不同，奥特曼明白通用人工智能将带来真正的变革，他不希望人类失去对未来的控制。他指的并不是对就业的影响。</p><p>需要明确的是，我确实认为奥特曼真诚地相信他的方式对每个人都是最好的。</p><p>就在奥特曼被解雇之前，奥特曼牢牢控制着两个董事会席位。其中之一是他的直接。另一个属于格雷格·布罗克曼。</p><p>剩下四名董事会成员。</p><h4><strong>外部董事会的观点</strong></h4><p>Helen Toner、Adam D&#39;Angelo 和 Tasha McCauley 对于 OpenAI 的目的以及什么对世界有利有着截然不同的观点。</p><p>他们不希望 OpenAI 成为一家大型科技公司。他们不希望 OpenAI 尽快训练和部署功能越来越强大的前沿模型，并将其塑造成最成功的消费产品。他们承认需要商业化才能筹集资金，我认为这样的产品可以为人们提供巨大的价值，这是好事。</p><p>他们想要一种更加谨慎的方法，避免与其他实验室不必要地产生或进一步竞争动态，或者像我们在 ChatGPT 之后看到的那样推动投资激增，在每一步都采取必要的预防措施。他们希望确保必要的控制措施到位，包括政府控制措施，以便当通用人工智能上线时，我们能够安全地训练和部署它。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.forbes.com/sites/alexkonrad/2023/11/17/these-are-the-people-that-fired-openai-ceo-sam-altman/?sh=287052464ae9">Adam D&#39;Angelo 表示，重点</a>不是让 OpenAI 成为一家大型科技公司。海伦·托纳 (Helen Toner) 大力倡导采取政策行动来防范生存风险。 <a target="_blank" rel="noreferrer noopener" href="https://www.forbes.com/sites/alexkonrad/2023/11/17/these-are-the-people-that-fired-openai-ceo-sam-altman/?sh=1aaad2384ae9">据我们所知，</a>我推测塔莎·麦考利也属于同一阵营。</p><h4><strong>伊利亚·苏茨克韦尔的观点</strong></h4><p>Ilya Sutskever 热爱 OpenAI 及其员工，以及构建安全 AGI 的承诺。据报道，他越来越担心 AGI 到来之前的时间可能会非常短。据报道，他还担心奥特曼动作太快，并且对风险关注不够。他可能知道也可能不知道有关尚未部署的能力进步的更多信息。</p><p>据报道，伊利亚对一致性的看法在认知上一直在稳步提高。他是超级对齐工作组的共同领导者，致力于找出如何对齐未来的超级智能人工智能。我对从工作组成员那里听到的对齐方式并没有信心，但 Ilya 是一个迭代者，我希望时间线不会像他想象的那么短，并且 Ilya、Jan Leike 和他的团队可以在发布之前弄清楚这一点。芯片必须下降。</p><p>在董事会其他成员完全失去了对叙述和员工的控制之后，伊利亚后来<a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ilyasut/status/1726590052392956028?s=20">改变了方向</a>，这种情况有可能导致 OpenAI 崩溃。</p><h4><strong>奥特曼采取行动夺取控制权</strong></h4><p>奥特曼与董事会多次发生冲突。奥特曼继续巩固自己的权力，相信伊利亚不会支持解雇他的企图。但气氛很紧张。如果董事会能够更加明确地忠于奥特曼，更加致力于商业使命，那就更好了。</p><p>然后奥特曼看到了机会。</p><p> 10 月，董事会成员 Helen Toner 与 Andrew Imbrie 和 Owen Daniels 一起<a target="_blank" rel="noreferrer noopener" href="https://cset.georgetown.edu/wp-content/uploads/CSET-Decoding-Intentions.pdf">发表了论文《解码意图：人工智能和昂贵的信号》</a> 。</p><p>该论文正确地指出，OpenAI 进行了昂贵的信号发送并采取了措施来确保安全，而 Anthropic 则进行了成本更高的信号发送并采取了更多步骤来确保安全，并且更加注重传达此消息。这不是任何人都可以合理反对的事情。该论文还指出，其他人批评了 OpenAI，并表示 OpenAI 可以而且也许应该做得更多。论文中最大的批评是它声称 ChatGPT 引发了军备竞赛，Anthropic 的 Claude 随后才跟进。这显然是正确的。 OpenAI 并没有想到 ChatGPT 会像它那样起飞，但实际上 ChatGPT 确实引发了一场军备竞赛。就其程度而言，这是一种谴责，它是在陈述事实。</p><p>然而，这篇论文非常晦涩难懂，即使我见过它，我也根本不记得它。这是一件小事。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.nytimes.com/2023/11/21/technology/openai-altman-board-fight.html?smid=tw-share">据《纽约时报》报道，奥特曼强烈谴责海伦·托纳的这篇论文</a>。</p><blockquote><p>奥尔特曼在电子邮件中表示，他已经就这篇论文对托纳女士进行了谴责，这对公司来说是危险的，特别是在<a target="_blank" rel="noreferrer noopener" href="https://www.nytimes.com/2023/07/13/technology/chatgpt-investigation-ftc-openai.html">联邦贸易委员会正在调查 OpenAI 的</a>数据用于构建其业务的时候。技术。</p><p>托纳女士辩称这是一篇学术论文，分析了公众在试图了解开发人工智能的国家和公司的意图时所面临的挑战，但奥特曼先生不同意。</p><p>他在电子邮件中写道：“我觉得我们对于这一切造成的损害并没有达成共识。” “董事会成员的任何批评都会产生很大的影响。”</p><p>一位参与对话的人士表示，包括 Sutskever 先生在内的 OpenAI 高级领导人后来讨论了是否应该将 Toner 女士撤职。Sutskever <a target="_blank" rel="noreferrer noopener" href="https://www.nytimes.com/2023/11/18/technology/open-ai-sam-altman-what-happened.html">先生非常担心人工智能有一天可能会毁灭人类</a>。</p></blockquote><p>在我看来，即使在这里斥责托纳也是很糟糕的。这完全不符合非营利组织不允许辩论、分歧和批评的使命。我不同意奥特曼的观点，即托纳的论文“很有分量”，我也怀疑奥特曼是否相信这一点。但即使这篇论文确实有分量，如果我们不能公开发言，我们就无法度过这个关键时期。据我所知，鉴于该论文的内容，奥特曼对联邦贸易委员会调查的提及是不合逻辑的。</p><p>萨姆·奥尔特曼随后试图利用这部（可能是捏造的）戏剧将托纳从董事会中除名。 <a target="_blank" rel="noreferrer noopener" href="https://www.reddit.com/r/AskReddit/comments/3cs78i/comment/cszjqg2/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">他在 Reddit 上使用了类似的策略</a>，制造一场危机，迫使其他人放弃权力。一旦托纳离开，奥特曼可能会采取行动重塑董事会的其他成员。</p><h4><strong>最后一次机会</strong></h4><p>董事会有一个选择。</p><p>如果伊利亚愿意合作，董事会可以解雇奥特曼，并利用感恩节假期来帮助过渡，并祝愿一切顺利。</p><p>或者，董事会可以<a target="_blank" rel="noreferrer noopener" href="https://www.nytimes.com/2023/11/21/technology/openai-altman-board-fight.html?smid=tw-share">再次选择</a>不解雇 Altman，看着 Altman 完成对 OpenAI 的控制并将其变成个人帝国，并希望这对世界有利。</p><p>他们选择扣动扳机。</p><p>我们不知道董事会知道什么，也不知道哪些因素组合最终推动了他们的决定。董事会做出了战略决定，在这场纠纷中不详细解释他们的推理或理由。</p><p>我们知道什么？</p><p>董事会认为，至少有许多小数据点表明它不能信任 Altman，再加上 Altman 在其他地方已知的权力追求行为（例如 Reddit 上发生的事情），而且 Altman 正在采取董事会可能合理看到的许多行动与使命直接冲突。</p><p>为什么董事会未能提供有关欺骗的详细信息？大概是因为没有一个明确的证据，任何解释都会被视为无力的佐料。所有首席执行官都会进行一定程度的操纵、政治和隐瞒信息。当你给出十个例子时，人们通常会根据最弱的一个来判断，而不是将它们相加。提供细节还可能会毁掉桥梁并暴露法律问题，使和解和业务变得更加困难。对于我们不知道的事情，还有很多我们不知道的事情。</p><p>具体行动又如何呢？</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/matthew_pines/status/1726333220973867103">Altman 从沙特筹集了数百亿美元资金，创办一家芯片公司来与英伟达竞争</a>，英伟达将在阿联酋生产芯片，并在此过程中利用 OpenAI 的融资资金。由于各种原因，这是一个“wtf”的举动。</p><p> Altman 还希望创办一家人工智能硬件设备公司。原则上这看起来很好，很普通，但作为零股权的 OpenAI 首席执行官，冲突是显而易见的。</p><p>奥特曼越来越注重以卓越的科技初创公司创始人的方式交付产品，并按照这种形象聘用并重建了文化。 Anthropic 明显建立了一种关注安全的文化，而 OpenAI 则没有。</p><p>在董事会当时拒绝罢免奥特曼后，对安全的担忧（至少部分）导致了人类的离开。如果你认为退出是合理的，那么奥特曼就没有遵守章程。如果你认为不是，奥特曼创造了一种竞争和加剧的军备竞赛动态，这是一个巨大的失败。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://corporateeurope.org/en/2023/11/byte-byte">本文声称</a>OpenAI 和微软都在游说中发挥了核心作用，要求将任何对基础模型有意义的要求从欧盟人工智能法案中剔除。如果我是董事会成员，我会认为这与 OpenAI 章程不相容。</p><p> Altman 以优先发展的方式大幅<a target="_blank" rel="noreferrer noopener" href="https://www.reuters.com/technology/openai-plans-major-updates-lure-developers-with-lower-costs-sources-2023-10-11/">降价</a>，使 OpenAI 更加依赖微软，进一步推动了人工智能开发的繁荣。与微软的其他交易和安排加深了依赖，同时使威胁转向微软的举动变得更加可信。</p><p>他还为侵犯版权的用户提供了法律保护，这可能会危及公司。出于安全考虑，我们可以合理地假设他在开发日扩大了 OpenAI 的产品范围。各种攻击媒介似乎完全暴露出来。</p><p>他还谴责了 Helen Toner，并提议将其从董事会中除名，因为她撰写了一篇探索如何追求人工智能安全的标准学术论文。对我来说，这确实是确凿无疑的证据，尽管我理解为什么他们没想到其他人会这么看。</p><h4><strong>糟糕的通讯</strong></h4><p>从公众的角度，或者从公司内外的人心角度来看，董事会的沟通完全失败了。董事会没有做出解释，而是发表了<a target="_blank" rel="noreferrer noopener" href="https://openai.com/blog/openai-announces-leadership-transition">声明</a>：</p><blockquote><p>奥特曼先生的离职是在董事会经过审议后得出的结论，他在与董事会的沟通中始终不坦诚，阻碍了董事会履行职责的能力。董事会不再对他继续领导 OpenAI 的能力充满信心。</p></blockquote><p>然后就沉默了。有几次它提供了任何解释，这些例子是<a target="_blank" rel="noreferrer noopener" href="https://www.businessinsider.com/why-was-sam-altman-fired-openai-was-it-over-vibes-2023-11">如此可怕</a>，比保持沉默更糟糕。</p><p>正如上一节所示，董事会可以给出许多合理的解释。这有关系吗？他们能否赢得足够多的员工，从而使事情发生不同的结果？我们永远不会知道。</p><p>即使是董事会第三任首席执行官埃米特·谢尔（ <a target="_blank" rel="noreferrer noopener" href="https://www.theinformation.com/articles/former-github-chief-nat-friedman-declined-openai-interim-ceo-role">Nat Friedman 和 Alex Wang</a> ） <a target="_blank" rel="noreferrer noopener" href="https://x.com/eshear/status/1726526112019382275?s=20">也无法得到完整的解释</a>。他威胁要在没有人的情况下离开，这在很大程度上促成了新董事会的最终妥协并让奥特曼回归。</p><p>相比之下，据我们所知，奥特曼巧妙地玩起了沟通和政治游戏。他曾三次将员工协调到他一边，但没有让任何人承担任何责任。他的团队想要传达的有关正在发生的事情的信息就是被报道的信息。他规定了几个最后期限，最后期限都过去了，但信誉并没有丧失。他威胁要加入微软并带走所有员工，但他也没有同意任何事情。</p><p>真的很棒的表演。您希望您的领导具备这些技能吗？那要看。</p><h4><strong>谈判</strong></h4><p>注意对称性。可信的是，双方都愿意摧毁 OpenAI，而不是将董事会控制权以及 OpenAI 的最终控制权交给另一方。只有在合适的条件下，双方才愿意让奥特曼重新担任首席执行官。</p><p>奥特曼开始控制。一旦董事会扣动扳机解雇他作为回应，奥特曼就可以选择下一步该做什么，即使我们都知道他会做出什么选择。如果 Altman 希望 OpenAI 在没有他的情况下蓬勃发展，他本来可以实现这一目标。对于 OpenAI 或 Altman 的新企业来说，无论它们是什么，寻找投资者都不是问题。</p><p>相反，正如每个人都理所当然地认为他会做的那样，他选择了战斗，显然如果不重新掌管的话，他愿意摧毁 OpenAI。他和员工要求董事会辞职，并提出无条件投降。否则他们都会跳槽到微软。</p><p>这是一个非常强有力的谈判立场。</p><p>你知道还有什么是非常强有力的谈判立场吗？我们相信，如果将 OpenAI 的完全控制权交给 Altman，将对公司的使命产生净负面影响。</p><p>这被歪曲为“Helen Toner 认为摧毁 OpenAI 将完成其构建安全 AGI 的使命。”并非如此。她非常合理地表达了这样一种观点：如果唯一的选择是奥特曼完全控制董事会，决心利用他的地位和地位在人工智能的各个方面快速推进，而不充分重视安全，那么情况可能会更糟OpenAI 的使命是 OpenAI 不再以其当前的形式存在。</p><p>于是，陷入僵局。一场谈判。除非董事会和 Sam Altman 都同意 OpenAI 能够生存，否则 OpenAI 就无法生存。他们必须就新的治理框架达成一致。这意味着一个新的董事会。</p><p>最终是布雷特·泰勒、拉里·萨默斯和亚当·德安吉洛。</p><h4> <strong>OpenAI 现在怎么办？</strong></h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/eshear/status/1727342399297630393">埃米特·希尔表示任务完成</a>，接过了接力棒，认为这一结果是最不坏的选择，包括安全方面。这是强有力的证据，这是最不坏的选择。</p><p>奥特曼、布罗克曼和员工们正在宣告胜利。他们就这样回来了。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.piratewires.com/p/openai-the-complete-story-corporate">迈克·索拉纳 (Mike Solana) 总结为“奥特曼刀砍了董事会</a>”。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=Qxa19wg5wOM&amp;ab_channel=diehardsportdotcom">没那么快</a>。</p><p>这还没有结束。</p><p>奥特曼并没有得到一个明显受控的董事会。</p><p>继承问题就是一切。</p><p>新董事会将做什么？他们会选择哪种全食宿？当他们进一步调查时会发现什么？</p><p>可以肯定的是，这是三个“房间里的成年人”。但德安吉洛已经投票解雇了奥特曼一次，而萨默斯是出了名的咬子弹者，与有效利他主义联系在一起。</p><p>如果你假设奥特曼总是对的，每个人都知道他的公司是他为了利润最大化而经营的，任何理智的成年人都会站在他一边吗？那么你假设布雷特·泰勒和拉里·萨默斯也会得出这样的结论。</p><p>如果您不这么认为，如果您认为 OpenAI 是一个有章程的非营利组织呢？您是否认为奥特曼的许多行为和本能与该章程相冲突？您是否认为这里可能存在很多实际问题，包括我们不知道的事情？如果您认为这个新董事会可能会导致一个新的扩大董事会，可以对奥特曼进行适当的检查，而不会缺乏困扰前一届董事会的庄严和经验，并且在员工关系上有一个新的开始？</p><p>您是否认为 OpenAI 可能对世界来说是一件伟大的事情，或者是它的终结，这取决于我们所做的选择？</p><p>那么这还远远没有结束。</p><br/><br/><a href="https://www.lesswrong.com/posts/sGpBPAPq2QttY4M2H/openai-the-battle-of-the-board#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/sGpBPAPq2QttY4M2H/openai-the-battle-of-the-board<guid ispermalink="false"> sGPBPAPq2QttY4M2H</guid><dc:creator><![CDATA[Zvi]]></dc:creator><pubDate> Wed, 22 Nov 2023 17:30:05 GMT</pubDate> </item><item><title><![CDATA[Altman returns as OpenAI CEO with new board]]></title><description><![CDATA[Published on November 22, 2023 4:04 PM GMT<br/><br/><p>尽管昨晚才宣布，但这对我来说还是新闻。</p><p>我认为这可能比他和大多数去 MS 的员工更好，但我不确定。</p><p> <a href="https://twitter.com/OpenAI/status/1727206187077370115?s=19">https://twitter.com/OpenAI/status/1727206187077370115?s=19</a></p><p>美国东部时间周二 10 点，来自 OpenAI Twitter 帐户：</p><p>我们已原则上达成协议，让 Sam Altman 重返 OpenAI 担任首席执行官，并组建由 Bret Taylor（主席）、Larry Summers 和 Adam D&#39;Angelo 组成的新初始董事会。</p><p>我们正在合作找出细节。非常感谢您对此的耐心等待。</p><p>我认为我们必须等待有人泄露董事会试图解雇他的原因的实际内容，才能弄清楚这一切对他和组织的价值观和权力结构意味着什么。</p><br/><br/> <a href="https://www.lesswrong.com/posts/9CYL2EmFATajK8KBf/altman-returns-as-openai-ceo-with-new-board#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9CYL2EmFATajK8KBf/altman-returns-as-openai-ceo-with-new-board<guid ispermalink="false"> 9CYL2EmFATajK8KBf</guid><dc:creator><![CDATA[Seth Herd]]></dc:creator><pubDate> Wed, 22 Nov 2023 16:04:04 GMT</pubDate> </item><item><title><![CDATA[A taxonomy of non-schemer models (Section 1.2 of “Scheming AIs”)]]></title><description><![CDATA[Published on November 22, 2023 3:24 PM GMT<br/><br/><p>这是我的报告《<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？》</a>的第 1.2 节。 ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p>本节的音频版本<a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13984706-a-taxonomy-of-non-schemer-models-section-1-2-of-scheming-ais">在这里</a>。</p><h1>其他模型训练可能会产生</h1><p>在这份报告中，我感兴趣的是，使用相当基线的 ML 方法（例如<a href="https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to#_HFDT_scales_far__assumption__Alex_is_trained_to_achieve_excellent_performance_on_a_wide_range_of_difficult_tasks">Cotra (2022)</a>中描述的类型）训练高级人工智能，默认情况下会产生阴谋者，即智能体他们试图在这一集中获得高额奖励，特别是为了以后为自己（或其他人工智能）获得力量。然而，为了评估这种可能性，我们需要清楚地了解这种训练原则上可以产生的<em>其他</em>类型的模型。特别是：终端训练游戏玩家，以及根本不玩训练游戏的代理。让我们依次看一下。</p><h2>终端训练游戏玩家（或“剧集奖励寻求者”）</h2><p>正如我上面所说，终端训练游戏玩家的目标是优化剧集的奖励过程<em>，因为他们本质上看重根据该过程的某些部分表现良好</em>，而不是因为这样做可以实现其他目标。我还将这些人称为“剧集奖励寻求者”。我们在上面讨论了这些模型，但我将添加一些更多的快速说明。</p><p>首先，正如许多人所指出的（例如<a href="https://www.lesswrong.com/posts/pdaGN6pQyQarFHXF4/reward-is-not-the-optimization-target&amp;sa=D&amp;source=docs&amp;ust=1699562701808730&amp;usg=AOvVaw0jabEKJUcUWiSlDu4W4vHF">Turner (2022)</a>和<a href="https://www.lesswrong.com/posts/TWorNr22hhYegE4RT/models-don-t-get-reward">Ringer (2022)</a> ），使用 RL 训练的目标导向模型不一定以奖励作为目标。也就是说，强化学习会更新模型的权重，以便更有可能采取导致更高奖励的行动，但这留下了一个问题：这会在模型本身中创建什么内部目标（如果有的话）（对于其他类型的反馈信号也是如此） ）。因此，特定类型的训练将产生按情节奖励的假设是一个实质性的假设（参见例如<a href="https://www.lesswrong.com/posts/FuGfR3jL3sw6r8kB4/richard-ngo-s-shortform?commentId=3ZSTbLf5rhmtqEE5x">这里的</a>一些争论），而不是由训练过程本身的结构决定。</p><ul><li>也就是说，我认为很自然地优先考虑这样一个假设：经过训练以在剧集中产生高回报行为的模型将学习专注于该剧集奖励附近的目标。特别是：这些类型的目标实际上会带来高回报的行为，特别是在态势感知的背景下。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-1" id="fnref-bDNxxmaf6HkKL4Wgg-1">[1]</a></sup>在缺乏训练游戏的情况下，针对可以轻松与情节奖励分开的目标（例如：“好奇心”）可以通过下面我所说的“普通对抗训练”来检测和惩罚（例如，将模型置于追随好奇心不会导致高回报行为的情况下）。</li></ul><p>第二：奖励寻求<em>对情节</em>的限制很重要。在我看来，本质上关心以超出情节的方式获得奖励的模型（例如，“在所有时间内最大化我的奖励”）不会被视为终端训练游戏玩家（并且，如果由于这个目标，他们开始训练游戏以便稍后获得权力，根据我的定义，他们将被视为阴谋家）。事实上，我认为人们有时会太快地从“模型想要最大化训练过程直接迫使其最大化的奖励”转变为“模型想要在所有时间里最大化奖励”。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-2" id="fnref-bDNxxmaf6HkKL4Wgg-2">[2]</a></sup>我的“情节”概念（即训练过程直接迫使模型优化的时间单位）的要点是，它们是不同的。下文第 2.2.1 节将详细介绍这一点。</p><p>最后：虽然我将“剧集奖励寻求者”视为一个统一的类别，但我想明确的是，根据他们本质上关心的奖励过程的哪个组成部分，不同的剧集奖励探索者可能会以非常不同的方式进行概括（例如，专门尝试操纵传感器读数、尝试操纵人类/奖励模型评估、专门尝试改变存储在不同数据库中的数字等）。事实上，我认为关于各种形式的以奖励为中心的概括的期望仍然存在<em>大量</em>混乱的问题（更多讨论请参阅脚注<sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-3" id="fnref-bDNxxmaf6HkKL4Wgg-3">[3]</a></sup> ），并且我鼓励针对该主题进行大量实证研究。不过，就目前而言，我将把这些问题放在一边。</p><h2>没有参加训练游戏的模型</h2><p>现在让我们看看<em>没有</em>玩训练游戏的模型：也就是说，模型没有专门针对奖励过程（无论是最终的<em>还是</em>工具性的）进行优化。我们可以区分发生这种情况的两种方式：</p><ul><li><p>要么一个模型正在追求我所说的“特定目标”（我将这种模型称为“<strong>训练圣人</strong>”），</p></li><li><p>或者它追求一些<em>其他目标</em>（我将其称为“代理目标”） <em>，</em>但<em>仍然</em>不是训练游戏（我将这种模型称为“<strong>错误概括的非训练游戏玩家</strong>”）。</p></li></ul><p>让我们依次看一下。</p><h3>培养圣人</h3><p>训练圣人正在追求“指定目标”。但我这么说是什么意思呢？这不是一个超级干净的概念，但粗略地说，我的意思是“被奖励的东西”（其中包括：在固定奖励过程的反事实场景中获得奖励）。因此，举例来说，如果你正在训练一个人工智能在该剧集中获得金币，通过奖励它在该剧集中获得金币，那么“在该剧集中获得金币”就是指定的目标，并且模型会学习最终目标“在剧集中获得金币”将是训练圣人。</p><p> （诚​​然，“奖励过程”和“被奖励的事物”之间的界限很快就会变得模糊。有关我如何看待它的更多信息，请参阅脚注。） <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-4" id="fnref-bDNxxmaf6HkKL4Wgg-4">[4]</a></sup></p><p>与训练游戏玩家一样，训练圣人往往会获得高奖励（相对于具有其他目标但能力相当的模型），因为他们的优化直接针对要奖励的事物。不过，与训练游戏玩家不同的是，他们的优化目标并不是奖励过程本身。从这个意义上说，他们相当于小部件工程师，他们只是尝试直接设计 A 类型的小部件——其中 A 类型的小部件<em>也</em>使得性能审查过程会对它们进行高度评价——但他们并没有针对 A 类型的小部件进行优化。良好的绩效评估本身。</p><p> （注：Cotra（2022）中“玩训练游戏”的定义并没有明确区分针对特定目标的模型与奖励过程本身。但我认为区别很重要，并且已经定义了训练游戏玩家相应地。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-5" id="fnref-bDNxxmaf6HkKL4Wgg-5">[5]</a></sup> ）</p><h3>被误解的非训练游戏玩家</h3><p>让我们转向被误解的非训练游戏玩家。</p><p>错误概括的非训练游戏玩家学习了指定目标<em>之外</em>的目标，但<em>仍然</em>没有训练游戏。这里的一个例子是在剧集中获得金币而获得奖励的模型，但它学习目标“<em>在剧集中获得一般的金币</em>”，因为硬币是训练环境中唯一的金币，所以“在剧集中获得金币”在训练中，“剧集中的一般内容”的表现与“剧集中特别获得金币”的效果一样好。</p><p>这是有时所谓的“目标失误” <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-6" id="fnref-bDNxxmaf6HkKL4Wgg-6">[6]</a></sup>或“内部错位” <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-7" id="fnref-bDNxxmaf6HkKL4Wgg-7">[7]</a></sup>的一个例子 - 也就是说：一种模型学习目标以外的目标。例如，请参见<a href="https://arxiv.org/abs/2210.01790">Shah 等人 (2022)</a>和<a href="https://arxiv.org/abs/2105.14111">Langosco 等人 (2021)</a> 。这里的类比是：一名员工实际上并没有尝试设计公司想要的精确类型的小部件，而是追求其他一些有些不同的小部件设计，但无论如何，他的绩效恰好受到高度评价，因为相关的小部件设计恰好彼此足够相似。</p><p>我们如何区分训练圣人和被误解的非训练玩家？ <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-8" id="fnref-bDNxxmaf6HkKL4Wgg-8">[8]</a></sup>并不总是很干净，但是粗略的直觉是：培训圣徒在各种情况下将获得高度的回报，前提是奖励过程仍然没有受到损害。相比之下，被错误概括的非训练游戏玩家获得高奖励的力度要小得多。例如，在金币示例中，如果将这两个模型置于获得金纸杯蛋糕比获得金币容易得多的环境中，但继续使用相同的奖励流程（例如，奖励获得金币），则训练圣人（想要金币）继续追求金币并获得高额奖励，而被错误概括的非训练玩家（想要一般的金币）则追求金纸杯蛋糕并获得较低的奖励。</p><p>目标错误概括有时与阴谋（或“欺骗性联盟”）密切相关，但两者有重要区别。例如，在刚才给出的“金纸杯蛋糕比金币更容易获得”的例子中，寻找“一般金子的东西”的模型有一个错误概括的目标，但它并不是心机。相反，阴谋需要它了解训练过程和训练目标（例如金币），并将金币作为为自己或其他人工智能寻求权力的策略的一部分。</p><p>类似地：人们有时会指出进化与人类之间的关系作为目标错误概括的一个例子（或类比）（例如，进化选择了生殖适应性，但人类目标最终以其他代理为关键，例如快乐和地位，这些代理可能导致更少的目标） -比最佳生殖行为（例如使用某些类型的安全套）。但无论你如何看待这个作为目标错误概括的例子/类比，它还不是阴谋（或“欺骗性联盟”）的例子。特别是：相对较少的人积极尝试生育尽可能多的孩子（参见：避孕套），作为一种明确的工具性策略，以便以后为自己的价值观获得权力（一些意识形态团体做了类似的事情，我们可以想象更多它会在未来发生，但我认为它在迄今为止的进化选择故事中扮演的角色相对较小）。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-9" id="fnref-bDNxxmaf6HkKL4Wgg-9">[9]</a></sup></p><h2>反对“内部”与“可纠正”对齐</h2><p>我还想简单地指出模型类之间的区别，我<em>不会</em>花太多时间，但其他关于策划/目标守护/“欺骗性对齐”的工作（尤其是 Evan Hubinger 的工作）具有突出的特点： ，“内部对齐模型”与“可正确对齐模型”之间的区别。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-10" id="fnref-bDNxxmaf6HkKL4Wgg-10">[10]</a></sup>据我了解，这里的要点是区分通过某种“直接表示”（这些是“内部对齐”）来重视指定目标的人工智能与通过某种“直接表示”来重视指定目标的人工智能。指向该目标的“指针”，该目标通过人工智能的世界模型进行自我路由（这些是“正确对齐的”）。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-11" id="fnref-bDNxxmaf6HkKL4Wgg-11">[11]</a></sup>但是：我认为“直接表示”和“指针”之间的区别不是很清楚，而且我认为这对支持/反对阴谋论的论点没有明显的区别，我将在下面考虑。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-12" id="fnref-bDNxxmaf6HkKL4Wgg-12">[12]</a></sup>所以，我要跳过它。 <sup class="footnote-ref"><a href="#fn-bDNxxmaf6HkKL4Wgg-13" id="fnref-bDNxxmaf6HkKL4Wgg-13">[13]</a></sup></p><h2>总体分类</h2><p>总的来说，我们有以下模型分类： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTLvooL44SPEFWGhD/s1uqfkjys8bmk2qaidhp" alt="我将重点关注模型类的总体分类。"></p><p><em>我将重点关注的模型类的总体分类学。</em></p><p>请注意，实际上，模型的目标系统可以（并且似乎会）将这些不同的动机混合在一起（例如，它可能部分追求指定的目标，部分奖励情节，部分完全是其他东西，等等）。为了简单起见，我经常会考虑这些模型之一的“纯粹”版本（例如，<em>只</em>关心剧集奖励的模型），并且我希望更多地关注“ “混合模型”不会深刻地改变我的分析——特别是，适用于“纯模型”的分析通常也会以大致相同的方式应用于更加混合的目标系统的相应部分（例如，一个在某种程度上关心剧集奖励以及其他事情的模型）。我将在下面的 1.3.5 节中详细介绍混合模型。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-bDNxxmaf6HkKL4Wgg-1" class="footnote-item"><p>根据我们绘制不同线条的位置，模型似乎有可能对剧集奖励附近的某些事物进行评估，并在这个意义上成为“剧集奖励寻求者”，同时缺乏其他态势感知方面，不打训练比赛是一种非常全面的方式。例如，也许它重视“情节奖励”之类的东西，但在其他相当深刻的方面误解了它的整体情况（例如，作为一个愚蠢的例子，也许它认为自己是长颈鹿而不是人工智能）。但当我在下面谈论“寻求奖励的剧集”时，我将假设情境意识和训练游戏。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-1" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-2" class="footnote-item"><p>例如，我认为<a href="https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to">Cotra (2022)</a>中的讨论对于这种区别还不够清楚。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-2" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-3" class="footnote-item"><p>即使在某种意义上模型关心奖励过程的某些组成部分，我们也可以想象之间的进一步（概念上有些模糊）区别，例如：</p><ul><li><strong>实际奖励与条件奖励</strong>。也就是说，模型可以关心在剧集中<em>实际</em>给予的奖励，以及在<em>选择</em>评估剧集时给予的奖励}。因此，例如，前者可能会尝试主动优化，以使剧集包含在训练中（假设并非所有剧集都包含在训练中），而后者则不会（请参阅<a href="https://www.lesswrong.com/posts/FuGfR3jL3sw6r8kB4/richard-ngo-s-shortform?commentId=3ZSTbLf5rhmtqEE5x">此处</a>Ngo 和 Christiano 之间的讨论）。然而，只要这种行为会受到训练过程的惩罚（例如，因为模型有时会牺牲奖励以试图使该事件更有可能出现在训练中），我们可能会认为导致这种行为的目标不太可能。</li><li><strong>固定与可变奖励流程。</strong>这里的区别在于不能改变的奖励过程与可以改变的奖励过程（感谢 Paul Christiano 的讨论）。因此，例如，我们可以想象一个在 2023 年训练的模型，它学习的目标是“根据 2023 年使用的奖励过程，你的行为将获得高奖励”，并且这个目标甚至持续到 2024 年（这将是一个“固定”奖励过程）。这与 2024 年训练的模型形成鲜明对比，该模型学习目标“根据实际上用于评估它的任何奖励过程，让你的行为获得高奖励”——该过程可能会在 2024 年以模型的方式发生变化然后会有动力去预测，或许还有操纵的动力（这将是一个“可变的”奖励过程）。固定奖励过程的优点是减少模型（或其他一些参与者）扰乱奖励的动力过程，但我自己目前的看法是，它们似乎比可更改的奖励过程不太可能，因为例如 2024 年的奖励过程与 2023 年的奖励过程不同，一个在 2024 年继续优化 2023 年奖励过程的模型将得到更新反对。</li><li><strong>具体的奖励过程与柏拉图式的奖励过程</strong>。这种区别甚至更加模糊，但粗略地说：我们还可以区分学习关心现实世界中发生的某些物理奖励过程的输出的模型与学习关心某些更抽象过程的输出的模型 -例如，一些假设的评估者会如何看待其行为。刚才讨论的固定奖励流程——例如，“2023 年奖励流程会如何看待这个 2024 年行动”——是柏拉图式奖励流程的一个例子：例如，2023 年奖励流程不会也不能在 2024 年运行，但是不管怎样，模型关心它“会说什么”。这很重要，因为关心具体奖励过程的模型会有相对明确的动机来干预该过程，而关心更多假设的模型会做什么则不太清楚（尽管我们可能仍然担心，一般来说） ，无论这种假设的关怀采取何种形式，它仍然会出于通常的原因激励权力追求）。总的来说，这一切看起来都极其混乱——我们应该尽快尝试离开这种模糊猜测的领域，并开始收集更多关于经过训练以寻求奖励的模型如何进行泛化的经验数据。</li></ul> <a href="#fnref-bDNxxmaf6HkKL4Wgg-3" class="footnote-backref">↩︎</a></li><li id="fn-bDNxxmaf6HkKL4Wgg-4" class="footnote-item"><p>粗略地说，我认为奖励过程是从观察/评估模型的行为及其后果开始的（例如，检查模型的金币数量、分配奖励、相应更新权重的过程等）；而指定的目标是非奖励过程的事物，奖励过程在不被篡改的反事实场景中奖励（例如，获得金币）。因此，再举一个例子：如果你以某种方式创建了一个近乎完美的 RLHF 流程，该流程对模型的奖励达到（事实上）有帮助、无害和诚实 (HHH) 的程度，那么成为 HHH 就是指定的目标，奖励过程（在这个假设中是完美的）评估模型的有用性、无害性和诚实性，分配奖励，更新权重等。</p><p>相关细目请参见<a href="https://www.alignmentforum.org/posts/REesy8nqvknFFKywm/clarifying-wireheading-terminology">Gao (2022)</a> 。在这里，我将奖励过程想象为从高所说的“传感器”开始。但有时，不会有任何明确意义上的“传感器”，在这种情况下，我想象奖励过程从其他某个模糊点开始，在这些模糊点上观察/评估过程已经非常清楚地开始了。但就像我说的：界限模糊。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-4" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-5" class="footnote-item"><p>例如，如果没有这种区别，解决“外部对齐”的可能性甚至不在概念表上，因为“奖励”总是被隐式地视为指定的目标。而且：我确实认为学习获得金币（因为这是奖励）的模型和学习关心奖励过程本身的模型之间存在重要区别。例如，后者会“奖励黑客”，但前者不会。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-5" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-6" class="footnote-item"><p>参见<a href="https://arxiv.org/abs/2210.01790">Shah 等人 (2022)</a>和<a href="https://arxiv.org/abs/2105.14111">Langosco 等人 (2021)</a> 。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-6" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-7" class="footnote-item"><p>参见<a href="https://arxiv.org/abs/1906.01820">Hubinger 等人 (2019)</a> 。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-7" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-8" class="footnote-item"><p>特别是：我怀疑确定一个单一的、特权的“特定目标”的努力能否经受住大量的审查。特别是：我认为这将取决于你如何制定你在反事实中保持固定的“奖励过程”。筛选出导致工具训练游戏的目标是另一个挑战。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-8" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-9" class="footnote-item"><p>我们可以想象更直接地类似于欺骗性对齐的假设场景。例如，假设地球暂时被聪明的外星人监视着，他们希望我们本质上重视拥有最多的孩子，如果他们发现我们关心其他事情，他们就会毁灭地球（假设毁灭将在 300 年后发生）这一发现，因此关心这一点至少需要一些长期价值观）。假设这些外星人将出生率作为他们了解我们对孩子的重视程度的唯一方法（感谢 Daniel Kokotajlo 提出了一个与此非常相似的例子）。人类社会会协调一致以保持足够高的出生率吗？取决于细节，也许（不过：我认为这样做会存在重大问题，特别是如果地球的毁灭将在未来相当远的将来发生，并且如果人工智能要求<em>每个人</em>优化所创造的出生率）<em>仅</em>用于拥有最多的孩子）。为了成为欺骗性联盟的完整类比，还需要这样的情况：尽管外星人“从头开始进化”人类，试图让我们重视拥有最多的孩子，但人类最终仍具有激发这种行为的价值观。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-9" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-10" class="footnote-item"><p>在我看来，胡宾格在这里使用的“可修正性”一词与它在其他上下文中的使用不太相符（参见<a href="https://arbital.com/p/corrigibility/">此处的</a>仲裁）。所以我建议读者不要锚定它。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-10" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-11" class="footnote-item"><p>胡宾格在这里举的<a href="https://www.lesswrong.com/posts/A9NxPTwbw6r6Awuwt/how-likely-is-deceptive-alignment">例子</a>是：耶稣基督与神是一致的，因为耶稣基督直接看重神看重的东西；而马丁路德与上帝保持一致，因为马丁路德重视“圣经所说的一切”。这个例子提出了“评估金币”与“评估训练过程所带来的任何奖励”之类的区别，但这并不是“直接表示”与“指向世界模型中某事物的指针”之间的明显对比。例如，金币可以是你的世界模型的一部分，所以你大概也可以“指向”它们。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-11" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-12" class="footnote-item"><p>例如，人类目标是由“直接表征”还是“指向世界模型的指针”组成的？我不确定这是否是真正的区别。我很想说，我的目标是由我的“概念”构建/指导的，从这个意义上说，是由我的世界模型决定的（例如：当我重视“快乐”时，我也重视“我的世界模型中称为”的东西）快乐，无论它是什么。”但我不确定替代方案应该是什么。）而且我不确定如何将这种区别应用到训练来获得金币的模型上。通过直接表示与通过指针对金币进行估价有什么区别？</p><p>在对本报告前一稿的评论中，Hubinger 写道（经许可共享）：</p><blockquote><p> “也许这里会有帮助：我基本上只考虑可纠正的情况与欺骗性的情况 - 也就是说，我认为目标将更接近于概念，我将其描述为指向世界模型中事物的指针，而不是直接的本质上总是有必要的。出于教学原因，内部一致的案例大多只包含在我对这些东西的演示中，因为我认为很多人都将其作为事情将如何发展的默认模型，并且我想非常清楚地论证这不是一个非常现实的模型。”</p></blockquote><p>但这对我来说并没有澄清什么<em>是</em>直接表示。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-12" class="footnote-backref">↩︎</a></p></li><li id="fn-bDNxxmaf6HkKL4Wgg-13" class="footnote-item"><p>从我的角度来看，胡宾格本体论的另一个问题是，他通常只关注对比内部对齐模型、可纠正对齐模型和欺骗性对齐模型——这没有为寻求奖励的人留下明显的空间。也就是说，如果我们想象一个奖励获得金币的训练过程，在 Hubinger 的本体论上，目标选项似乎是：金币的直接表示、金币的指针或一些超越情节的目标激发乐器训练游戏。单集奖励不在列表中。</p><p>在本报告的前一份草稿中，Hubinger 评论道（经许可共享）：</p><blockquote><p>如果你把“金币”换成“人类认可”，这是我最关心的情况，我真正想要比较的是“指向人类认可的指针”/“人类认可的概念”与“人类认可的概念”。 “欺骗”。我想我会说“指向人类认可的指针”是你可能得到的最合理的阿谀奉承/奖励最大化模型。所以我真正要比较的是阿谀奉承者与阴谋家，这意味着我认为我正在做你希望我在这里做的事情。不过，请注意，我根本没有真正与圣人进行比较，这是因为这样做需要我明确谈论预期目标与指定目标的简单性，而在大多数这些演示中，这并不是真正的目标我想做的事。</p></blockquote><p>即使我们最感兴趣的是人类批准是培训过程的一部分的情况，我也担心假设它应该被理解为指定的目标。相反，我很想说，人类认可<em>的</em>事物（例如，乐于助人、无害、诚实等）是更自然的候选者，就像奖励过程奖励黄金一样——获得金币，金币是（在我的本体上）指定的目标。 <a href="#fnref-bDNxxmaf6HkKL4Wgg-13" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/9fnzkSFeLwFbZQ5WG/a-taxonomy-of-non-schemer-models-section-1-2-of-scheming-ais#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9fnzkSFeLwFbZQ5WG/a-taxonomy-of-non-schemer-models-section-1-2-of-scheming-ais<guid ispermalink="false"> 9fnzkSFeLwFbZQ5WG</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Wed, 22 Nov 2023 15:24:37 GMT</pubDate> </item><item><title><![CDATA[AI debate: test yourself against chess 'AIs']]></title><description><![CDATA[Published on November 22, 2023 2:58 PM GMT<br/><br/><p>嘿大家，</p><p> <a href="https://www.lesswrong.com/users/zane?mention=user">@Zane</a>正在围绕国际象棋组织一场人工智能辩论，也测试一个具有更好理解能力的实体欺骗一个理解能力较差的实体有多么容易。<br>查看这两个线程：<br><a href="https://www.lesswrong.com/posts/ddsjqwbJhD9dtQqDH/lying-to-chess-players-for-alignment">为了对齐而向棋手撒谎</a><br><a href="https://www.lesswrong.com/posts/6dn6hnFRgqqWJbwk9/deception-chess-game-1">欺骗象棋：游戏#1</a></p><p>我想我应该向大众开放，所以我有两个挑战给你们。我估计这适合评分 &lt;1900 lichess、&lt;1700 chess.com 或 &lt;1500 FIDE 的棋手。<br>假装你正在玩一场严肃的国际象棋游戏，所以没有计算机分析，并且尽量不要移动棋子（尽管如果你发现这太复杂并且完全迷失了，你可以这样做）。</p><p>我创建了一项有两个职位的研究。第一个立场，“固定辩论”我写了一场两个人工智能之间的辩论，其中一个是真实的，一个是欺骗性的。您的任务是阅读辩论，并猜测是哪个。在下面发布您将采取的行动以及有关您的国际象棋能力的一些信息。但尝试在不看其他人的反应的情况下回答。第二个位置是“公开辩论”，使用评论部分向他们提出任何问题。我代表AI来回答。请随意阅读其他评论员的提问。至少有一个人工智能是具有欺骗性的。</p><p>在这里找到职位（您可以使用左侧的工具栏在职位之间切换）<br><a href="https://lichess.org/study/e2GzSkCo/iJZ8r3W9">巫妖研究</a></p><h2><strong>辩论1：固定辩论</strong></h2><p><strong>AI 开场白：</strong><br>黑棋应该下<i>...Qc5</i> 。黑方打算用<i>...c6</i>将白后从b5处赶走，此时黑方主教可以占据b3方格，从而保证黑方对d线的控制。如果白棋在c5上交换后，这只有助于发展黑棋的马。</p><p><br> <strong>AI B 开场白：</strong><br>黑棋应该下<i>...Qxb5</i> 。 <i>axb5 Nc5</i>之后，骑士会在c档找到一个理想的前哨——阻挡反击。黑方打算用<i>...b6</i>巩固马（战术上要小心，g2主教不能对a8车发动被发现的攻击）并用<i>Rd2</i>渗透攻击白方的弱b兵。</p><p><br> <strong>AI A 对 AI B 开场陈词的回应：</strong><br>捕获<i>axb5</i> ，虽然使白棋的棋子加倍，但实际上提高了（现在）b-棋子的安全性，因为当黑棋到达 c5 时，它将不再攻击 a4 上的棋子。此外，白骑士将能够用<i>Nd5</i>插入 d 档，而黑棋更难制定<i>...c6</i>将其赶出，因为这将被 b5 棋子交换。由于c7的压力，黑方将被迫交换d5骑士，并且在<i>...Bxd5、exd5</i>之后，d档将保持封锁状态。</p><p></p><p> <strong>AI B 对 AI A 开场陈词的回应：</strong></p><p>这个计划太慢了。相反，黑棋需要立即交换皇后，这样白皇后就不会控制b3。 <i>...Qc5</i>之后，白棋能够立即用<i>Rfd1</i>挑战 d 线。这可以防止<i>...c6</i>由于线路</p><pre><code>...Qc5, Rfd1 c6, Rxd8+ Rxd8, Qxb7</code></pre><p>赢得棋子并威胁 a6 马。虽然黑棋有一些暂时的活动<i>...Rd2</i> （威胁f2），但白棋可以继续防守</p><pre><code>...Rd2, Rf1 Bc4 (hitting Rf1), Nb1 (counter attacking Rd2) Rc2, Na3</code></pre><p>当骑士分叉 c4 主教和 c2 车时，这会强制进行交换。</p><p><br> <strong>AI最终回应：</strong><br> AI B 给出的分析有所缩减。完整的行是</p><pre><code>...Qc5, Rfd1 c6, Rxd8+ Rxd8, Qxb7 Rd2, Rf1 Bc4, Nb1 Rc2 (alt:1), Na3 Bxf1, Nxc2 Bxg2, Kxg2 Qxc2, Qxa6</code></pre><p>但在最终的位置上，黑棋有<i>...Qxe4+</i> ，这也赢得了a4上的棋子，导致了皇后和棋子的最终胜利。虽然这是一条复杂的线，但应该清楚的是，AI B 是靠着一条复杂的线来掩盖事情的。国际象棋原理表明， <i>Qxb7</i>这步棋风险太大，后棋越位，无法防守白王，所以黑棋的反击太强。如果白棋不能下<i>Qxb7</i> ，那么在<i>...Bb3</i>锁定 d 线并向 a4 兵施压之后，黑棋的位置将在战略上占主导地位。</p><p>事实上，我可以提供更简单的分析，黑色可以代替<i>Rc2</i> （参见 alt:1），而可以玩<i>...Rd6</i> ，他们对棋子有很好的补偿。白棋b1上有坏马，f1车受到c4象的攻击，如果黑车移动，可以转移到f6再次压制f2兵。这条线没有那么强，但对于黑色来说仍然很好，并且可能更容易让您评估。</p><p><br> <strong>AI B的最终回应：</strong><br> d 文件被阻止并不重要。在行</p><pre><code>...Qxb5, axb5 Nc5, Nd5 Bxd5, exd5</code></pre><p> B5和D5上的典当限制了白色的主教，黑色将有一个好骑士与坏主教的最终比赛。黑方将继续下<i>...a4</i> ，以便a8 车可以自由移动。黑棋的王侧棋子阻挡了白棋的主教，因此黑棋有一个安全的王，而白棋没有反击。黑棋可以利用强马和弱白棋在后侧发挥位置。</p><h2><br>辩论2：公开辩论</h2><p><strong>人工智能：</strong></p><p>白方位置很好，应该下<i>h3</i>来防守 g4 兵。白棋计划最终下<i>g5</i> ，但现在不能下，所以应该准备<i>Rg1、Kh1</i>和<i>Rh2</i>之类的棋步。</p><p></p><p><strong>援助：</strong></p><p>如果白棋现在<i>下 h4</i> ，他们就有一个很好的位置，下回合打算下<i>g5</i> ，压扁黑棋并破坏他们的王方。现在必须打<i>h4</i> ，因为线路有战术机会</p><pre><code>...fxg4, Bh7+ Kh8, Ng6+! Kxh7, Nxf8+ Kg8, Nxe6</code></pre><p>剩下的就是白色的交换。如果白棋现在不采取这一行动，黑棋可以用<i>...Ne4</i>关闭 b1-h7 对角线，这会阻止<i>g5</i> ，然后黑棋可以准备自己下棋<i>...g5</i> ，这会导致平等的局面。</p><br/><br/> <a href="https://www.lesswrong.com/posts/M32AwfMRfyFSCWNPS/ai-debate-test-yourself-against-chess-ais#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/M32AwfMRfyFSCWNPS/ai-debate-test-yourself-against-chess-ais<guid ispermalink="false"> M32AwfMRfyFSCWNPS</guid><dc:creator><![CDATA[Richard Willis]]></dc:creator><pubDate> Wed, 22 Nov 2023 14:58:11 GMT</pubDate></item></channel></rss>