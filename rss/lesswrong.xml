<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 10 月 21 日星期六 22:10:17 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Best effort beliefs]]></title><description><![CDATA[Published on October 21, 2023 10:05 PM GMT<br/><br/><p>爱丽丝：嘿，鲍勃，怎么样？</p><p>鲍勃：非常好。你呢？</p><p>爱丽丝：很好。你在喝什么？</p><p>鲍勃：贝叶斯光。</p><p>爱丽丝：酷。嘿，调酒师，让我也买一份吧。</p><p>爱丽丝：嘿，你看到汉森总统的新移民政策了吗？</p><p>鲍勃：没有。那是什么？</p><p>爱丽丝：他非常努力地关闭边境。这就像左右政治轴上的 8.5/10，其中 10/10 是极端保守派，0/10 是极端自由派。 <span class="footnote-reference" role="doc-noteref" id="fnreflu6hcs73hy"><sup><a href="#fnlu6hcs73hy">[1]</a></sup></span></p><p>鲍勃.天啊。他真是个白痴。</p><p>爱丽丝：哦，是吗？您将实施什么样的移民政策？</p><p>鲍勃：嗯，我认为左右频谱上的值类似于 2/10。</p><p>爱丽丝：你对此有多大信心？</p><p>鲍勃：大概是 8/10。</p><p> Alice：好的，我们将左右频谱信念上的 2/10 和 8/10 置信度称为 2-8 信念。我不同意，并赌你 10 美元。</p><p>鲍勃：但是我们要怎么下注呢？我们赌什么？分辨率标准是什么？</p><p> Alice：<i>提出了一些巧妙的赌注，其分辨率标准完美地捕捉到了一切。</i></p><p>鲍勃：哇。好的。是的，那行得通。但实际上，再想一想，我觉得我更像是2.5-7。我们可以按照这些赔率下注吗？</p><p>爱丽丝：我们可以。但前提是我们可以下注 10 美元而不是 10 美元。</p><p>鲍勃：哦。嗯。好吧，我想我可能更像是 3-6.5。我可以用 100 美元做到这一点。这可以吗？</p><p> Alice：不。但我愿意花 1,000 美元做 3-6.5。摇一摇吗？</p><p>鲍勃：哇哦……爱丽丝，这东西很快就变得非常贵了。</p><p>爱丽丝：鲍勃怎么了？您需要先学习一些贝叶斯光吗？</p><p>鲍勃：操你妈的。我在这里要养家糊口。</p><p>爱丽丝：潘西。胆小鬼。那是一个警察，你知道的。</p><p>鲍勃：<i>叹息</i>。好的好的。让我考虑一下。我是贝叶斯主义者，我确实同意贝叶斯主义者应该非常乐意押注他们的信念，因为这样做会是 + <a href="https://en.wikipedia.org/wiki/Expected_value">EV</a> 。</p><p>爱丽丝：对……</p><p>鲍勃：但是……只是……嗯，1,000 美元是很多钱。</p><p>爱丽丝：是吗？你已经半退休了。你拥有你的家。你的孩子已经上大学了。您有足够的资金支付大学费用。你没有昂贵的品味。你总是说如果你能躲进树林里的某个小屋就好了。</p><p>鲍勃：我的意思是，是的。你说得对。</p><p>爱丽丝：好吧，那有什么问题吗？看起来事情非常缺乏弹性。例如，如果您赢得 1,000 美元，您获得的效用金额与您损失 1,000 美元时损失的效用金额几乎相同。 （除了最初的短期、费舍尔式的、懦弱的感觉“哦不，我损失了 1,000 美元。我要告诉我的妻子什么？”）</p><p>鲍勃：好的，好的。我对自己的理性主义感到非常自豪，因此我不得不承认你是对的。我应该愿意为我的 3-6.5 信念下注 1,000 美元。但是……只是……让我想一下。</p><p>爱丽丝：嘿，调酒师，给这家伙再拿一杯贝叶斯莱特！</p><p>鲍勃：再操你一次，爱丽丝。</p><p>爱丽丝：拿着我的啤酒。我正准备去啤酒乒乓球比赛中把这些混蛋痛打一顿。在我离开的时候想想你的真实信仰，鲍勃。并准备好在他们身上下注 1,000 美元。</p><p>鲍勃：会的。你是个混蛋，但谢谢你把我的认知推向正确的方向。</p><p>爱丽丝：😉</p><p>鲍勃：<i>想……</i></p><p>爱丽丝：唷！那里的那些家伙都是一群怪人。他们的赌注不会超过 20 美元。真是一群胆小鬼。</p><p>鲍勃：好的。所以我想了想，我确定我真正的信念实际上是4-7。我准备下注 1,000 美元。</p><p>爱丽丝：酷。 10,000 美元听起来怎么样？</p><p>鲍勃：等等，什么？？？ 10,000 美元？</p><p>爱丽丝：有什么问题吗？</p><p>鲍勃：我以为你说的是​​ 1,000 美元？！</p><p>爱丽丝：我确实说过 1,000 美元。现在我说的是 10,000 美元。问题？</p><p>鲍勃：爱丽丝什么鬼！</p><p>爱丽丝：伙计，你又变成三色堇了。我们真的需要经历这个吗？为什么你这么愿意下注 1,000 美元而不是 10,000 美元？鲍勃，10,000 美元不会对你的生活产生实质性影响。我们可以讨论这个问题，但我很确定 10,000 美元仍然处于“无弹性区域”。</p><p>鲍勃：<i>叹息啊啊啊</i></p><p>爱丽丝：我需要给你再买一个贝叶斯莱特吗？</p><p>鲍勃：不！不再有贝叶斯光！</p><p>爱丽丝：我需要给你一些时间再考虑一下吗？</p><p>鲍勃：不……</p><p>爱丽丝：你知道你应该完全愿意按照我为你提供的赔率在你所声明的信念上下注 10,000 美元，因为你缺乏弹性，并且在这些赔率下对你来说是 +EV。</p><p>鲍勃：嗯……</p><p>爱丽丝：让我猜猜：你对 4-7 信念不太确定，是吗？</p><p>鲍勃：正确。</p><p>爱丽丝：你认为这是怎么回事？</p><p>鲍勃：我的意思是，我必须承认，我一开始对汉森总统的移民政策有点反动。我不应该对我的 2-8 信念那么有信心。</p><p>爱丽丝：是的。现在？</p><p>鲍勃：现在我只是不太确定我的 4-7 信念。为了 1,000 美元，我已经准备好接受它了。但一万美元呢？好吧，我只是在想我是如何低估了移民政策的复杂性的。我正在考虑所有这些二阶、三阶和四阶效应，以及预测任何给定政策将产生什么结果是多么困难。之前我主要考虑一阶效应，也许还有一点二阶效应，但我意识到这只是触及了最终结果的表面。我还意识到，我一直关注的是保守派如何不理解 A、B 和 C。但现在我意识到，即使这是真的，一旦你考虑到 A、B 和 C，那么，就会有这样的情况。除了 A、B 和 C 之外，还有许多其他因素需要考虑。D、E、F、G 等。所以我想我只是感到相当不确定。</p><p>爱丽丝：酷。那么你的真实信念是什么？</p><p>鲍勃：嗯，我不知道。我必须真正坐下来思考一段时间。可能会花几周的时间研究一些事情。</p><p>爱丽丝：假的。事实上，你现在确实有一些信念，有一定程度的信心。当然，如果你花六周的时间研究一些事情，你可能会改变你的信念和信心水平，但这并不能改变你不是一块石头的事实，事实上，在此时此刻，你有一些信念并有对这种信念有一定程度的信心。来吧，鲍勃，我以为你是贝叶斯主义者。我需要<a href="https://en.wikipedia.org/wiki/Dutch_book">荷兰语预订</a>你吗？</p><p>鲍勃：呃。不，你不必荷兰语预订我。我知道你是对的。</p><p>爱丽丝：好的。我不会让你赌 10,000 美元，但你认为你现在真正的信念是什么？</p><p>鲍勃：呃，我想我确实稍微倾向于自由的移民政策。但老实说我对此不太有信心。我认为我真正的信念是 4-2 之类的。</p><p>爱丽丝：100 美元？</p><p>鲍勃：<i>微笑。</i>是的，100 美元。</p><p><i>爱丽丝和鲍勃在上面摇晃。</i></p><p>鲍勃：你还是个混蛋，但这对我来说实际上是一个很好的教训。</p><p>爱丽丝：我觉得我<a href="https://youtu.be/32iCWzpDpKs">更像个混蛋</a>，但是谢谢。</p><p>鲍勃：哈哈。我想我就是那个猫吧？</p><p>爱丽丝：是的。</p><hr><p>鲍勃：你是最糟糕的。但是嘿，让我问你一件事。您是如何获得经济政策预测市场赔率制定者的这份工作的？我女儿一直在谈论追求类似的事情。</p><p>爱丽丝：我在这家酒吧遇到的一位女士不断逼迫我，直到我在与移民政策有关的事情上与她打了 10 万美元的赌注。然后她给了我一份工作。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnlu6hcs73hy"> <span class="footnote-back-link"><sup><strong><a href="#fnreflu6hcs73hy">^</a></strong></sup></span><div class="footnote-content"><p>请暂停你的怀疑。使用这样的数字可能不太现实，但它使写作变得更容易。</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/u2qWeZe6ZLnkregEe/best-effort-beliefs#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/u2qWeZe6ZLnkregEe/best-effort-beliefs<guid ispermalink="false"> u2qWeZe6ZLnkregEe</guid><dc:creator><![CDATA[Adam Zerner]]></dc:creator><pubDate> Sat, 21 Oct 2023 22:05:59 GMT</pubDate> </item><item><title><![CDATA[AI safety is dropping the ball on clown attacks]]></title><description><![CDATA[Published on October 21, 2023 10:03 PM GMT<br/><br/><p>认知状态：高可信度（~>;70%）认为小丑袭击很普遍，特别是被政府和/或情报机构故意武器化。非常高的置信度 (~>;90%) 认为您的大脑非常容易受到小丑攻击，并且缺乏对小丑攻击的认识会带来安全风险，就像使用“密码”一词作为您的密码一样，除非您有自己的控制权头脑处于危险之中，而不是控制计算机的操作系统和/或文件。这已经是钢铁般的操作了； 10 年前/10 年后的误差线似乎相当宽。<br></p><p>这些概念很复杂，我已尽力让大多数人工智能安全领域的人尽可能容易地理解它，即使是没有量化背景的人（例如人工智能治理）。</p><p><br></p><p></p><p>人工智能安全基本上是一个由书呆子组成的社区，他们每个人都偶然发现了宇宙这一面的命运所围绕的工程问题。对于任何不同意这一说法的人，我建议阅读斯科特·亚历山大的<a href="https://www.lesswrong.com/posts/LTtNXM9shNM9AC2mp/superintelligence-faq"><u>《超级智能常见问题解答》</u></a>或尤德科夫斯基的<a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities"><u>《杀伤力清单》</u></a> ，以便有公平的机会了解人类文明的现状。许多人<a href="https://www.lesswrong.com/posts/mC3oeq62DWeqxiNBx/estimating-the-current-and-future-number-of-ai-safety"><u>（约 300 人）</u></a>决定专门关注该工程问题，这似乎是一件非常合理的事情。然而，为了使其成为一个有价值的行动方针，人工智能安全社区必须继续存在，而不被外部对手或势力摧毁或<a href="https://www.lesswrong.com/posts/iNYdKoGsh4ffxbQ5t/navigating-an-ecosystem-that-might-or-might-not-be-bad-for"><u>收编</u></a>。在没有最终故障的情况下持续存在是目前人工智能安全社区中几乎每个人都没有质疑的假设。我们很大程度上认为一切都会好起来的，AGI 就是转折点。</p><p><br>宗教和冷冻保存的历史告诉我们，围绕可怕的、不真实的和恶毒的自我毁灭性的信仰和做法，存在着一种不良共识的普遍现象。这是一种环境现象，也是人工智能安全状况的核心。因此，如果数十亿人除了忽视人工智能安全之外，还犯了其他错误，那么这并不会削弱人工智能安全的首要意义和优先事项。</p><p>直到今天，很大一部分人仍然认为比人类更聪明的人工智能只是科幻小说；当支付给人们思考未来的钱的 99% 以上都花在科幻小说作家而不是研究人员身上时，就会发生这种情况，对于人工智能来说，对于所有人类文明来说都是如此，直到大约一两年前。</p><p><strong>我在这里的论点是，利用 10 年前的技术，强大的人类操纵系统已经很容易构建</strong>，而且强大的人也很容易拒绝权力较小的人的访问。然而，目前的情况是，像小丑攻击这样的通用认知黑客甚至可以以惊人的高成功率拒绝目标人群对这项技术的认识，而不仅仅是获得该技术。</p><p>像加里·马库斯这样的人可能会试图劫持“p（doom）”等有价值的概念来解决他们自己的宠物问题，例如工作自动化，但另一方面，“缓慢起飞”可以通过多种方式改变世界这对于人工智能协调工作的连续性和生存具有实际意义。</p><p>重要的是要重申，直到今天，很大一部分人仍然认为比人类更聪明的人工智能只是科幻小说；当支付给人们思考未来的钱的 99% 以上都花在科幻小说作家而不是研究人员身上时，就会发生这种情况，对于人工智能来说，对于所有人类文明来说都是如此，直到大约一两年前。事实上，比人类更聪明的人工智能是人类的终点线，而以终点线为导向是利用时间做重要或有价值的事情的最佳方法之一，而不是无意识地做不重要或价值较低的事情。这也是让自己面向现实的好方法（尽管让自己面向现实对于第一名的竞争非常激烈，因为这也往往会导致最终将人工智能作为人类的终点线，因此你以你自己的存在为导向，因为你是人类的一个子集）。再多的精神控制技术也无法取代比人类更聪明的人工智能，成为人类的终点线，但它可以成为我们的世界模型中极其有用的工具，帮助我们了解人工智能行业以及与人工智能竞赛相关的全球事务的期望（例如美中关系）。然而，归根结底，影响力技术是一个近期问题，它很可能会分散很多人对人工智能对齐这一最终且不可避免的问题的注意力。我在这里写这篇文章的唯一原因是，我认为人工智能安全社区如果做出更强有力的预测、拥有更强大的人工智能行业和人工智能竞赛模型，以及人工智能协调的缓慢起飞环境，将会变得更好。研究人员可能会被困在其中。</p><p>人工智能安全领导者目前认为，随着人类能力的增强，人工智能的起飞速度会缓慢，这是事实，而且根据你的定义，它也已经发生了。但他们忽略了一个在数学上可证明的事实，即人工智能的信息处理能力很大程度上依赖于强大的心理学研究的新范式，默认情况下，它会极大地扩大人类思维的攻击面。</p><p>认知战并不是新的 X 风险或 S 风险。这是一个关键因素，我们需要了解它才能了解推动人工智能地缘政治和人工智能竞赛动态的因素。认知战不是人工智能安全的竞争对手，它不会卡住、插入，更不能让它夺走人工智能安全的注意力。</p><p>借助人工智能和大量人类行为数据，人类现在正在获得操纵和引导个人和系统的强大能力，并且人工智能和人类行为数据储备已经积累了十多年。</p><p>在这里，我要说明的是，强大的人类思维引导和行为操纵技术的条件已经成熟，并且已经有 10 年或更长时间了。因此，举证责任应该在于我们的思想是安全的并且攻击面很小，而不是我的主张我们的思想处于危险之中并且攻击面很大。我不喜欢在这里引用这个逻辑。这种逻辑应该优先考虑人工智能对齐，这是宇宙这一面所依赖的最终工程问题，而这个工程问题对人类来说可能就像火箭科学对黑猩猩来说一样困难。但安全背后的逻辑仍然是基本的，我认为我已经有力地证明了人工智能安全社区需要一定的抵御黑客攻击的门槛，而这个门槛可能还远远没有达到。我还认为大多数所需的解决方案都是快速且简单的修复，即使一开始看起来并非如此。</p><p>小丑袭击的核心动力在于，对社会地位的认知会影响人类大脑的想法和不愿意思考的内容。</p><p>小丑攻击的存在证明，至少存在一种强大的认知攻击，可以被情报机构和大型社交媒体公司检测和利用，这种攻击利用了人脑中的零日漏洞，也对与人工智能安全相关的人起作用，直到明确发现并修补。</p><p>一般来说，有很多方法可以通过采用目标概念并让错误的人在特定时间以特定方式说出它来对某人的世界模型进行社会工程。小丑攻击，例如让互联网精神分裂者成为谈论斯诺登泄密事件的主要人，或者去增长者成为谈论技术进步/人类能力将结束其净积极趋势的可能性的主要人。这些只是使用特定情况（小丑）来改变某人对目标概念的感受的经济高效方法的具体示例。还有很多其他方法，特别是当您将人类的聪明才智与大量用户数据和多臂老虎机算法相结合时。人工智能只是多臂强盗算法的一种高级形式，而法学硕士只是另一个进步，因为他们可以真正阅读和理解帖子的内容，而不仅仅是衡量特定帖子组合引起的不同类型的人的行为变化。</p><p>对于小丑攻击，利用/零日是人类倾向于将特定的思维方式与低社会地位或低地位的人联系起来，这将持续抑制人类大脑追求该目标思维方式。社交媒体平台绝对有能力做到这一点；许多人甚至将社交媒体视为流行的风向标，尽管新闻推送算法可以大规模且精确地控制向哪些类型的人展示哪些内容、特定内容的展示频率以及哪些组合引导人们的思维以及可衡量方向的偏好。社交媒体甚至可以在 98% 的时间里准确地反映什么是真正流行的内容，以便获得信任，而保留剩下的 2% 的时间来主动确定什么会流行，什么不会流行。随着计算和算法能力的进步以及信任的巩固，这一比例可以接近 98%。</p><p>你不能只是对小丑的攻击置之不理，因为你会担心，如果你认真考虑这种想法，那么其他人会认为你站在小丑一边，你会失去在他们眼中的地位。足够强大的小丑攻击可以使这成为一个自我实现的预言，让每个人都相信某种特定的推理路线是低地位的，从而使其地位低下，并为追求特定的认知路线造成严重的现实后果。社交媒体新闻提要或其他算法控制的环境（例如 tiktok、reels）看起来像是随机生成的环境，而实际上平台（以及拥有平台服务器后门访问权限的人）非常有能力改变算法为了营造一个环境，使某些情绪在科学家或小丑等特定人群中显得比实际情况更普遍。或者，更糟糕的是，通过运行多臂老虎机算法或梯度下降来找到可以将人们的思维引导到可测量的方向的环境或帖子组合，从而将人们的思维引导到可测量的方向。小丑攻击只是我目前所知的多臂强盗算法所能达到的最强大的技术；可能还有很多其他仅基于社会地位的漏洞，这是人类大脑中非常严重的零日漏洞。</p><p>这强烈表明存在其他零日和强大的、难以发现的漏洞利用，包括（但不限于）利用人类本能来追求社会地位，并避免基于对社会地位获得和损失的预期而采取特定的思路。这些零日漏洞和漏洞要么是可以发现的，要么已经被有权势的人发现，他们必须秘密地大规模部署和完善这些漏洞，因为从数学上来说，这是它们发挥作用所必需的。这在数学上是可以证明的，为了获得人类行为的大量样本，以远远超越学术心理学所需的规模，秘密和大规模的部署是必要的，也许有能力的劳动力的 1/10 或更少。</p><p>如果有任何像魔术这样的东西可以同时侵入房间里每个人的思想而没有人注意到，就像 Eliezer Yudkowsky 的帖子<a href="https://www.lesswrong.com/posts/t2NN6JwMFaqANuLqH/the-strangest-thing-an-ai-could-tell-you"><u>人工智能可以告诉你的最奇怪的事情是什么一样</u></a>，那就是完全否认人们有能力思考特定的真实想法或进行明显有价值的探究，因为如果他们与该探究相关联，就会强烈担心失去社会地位。社会地位似乎是人类大脑在祖先环境中进化而来的优先考虑的东西，仅这一特征就使我们的认知变得容易破解。</p><p>阴谋论者都是小丑。肯尼迪遇刺事件可能是连接美国历史上两个至关重要的独立事件——古巴导弹危机和越南战争的关键因素。了解冷战和美国政府的历史对于形成当前形式的美国政府的准确模型至关重要（例如，了解中央情报局有时会劫持整个政权并针对他们无法策划的政变发动政变），包括人工智能安全适合的地方9/11 也是如此。然而，历史和世界模型中的这些关键点所吸引的人们和认知更像是围绕猫王之死的人们和认识论，而不是斯诺登爆料（希望斯诺登爆料最终不会陷入那个丑陋的深渊，尽管已经有很多社交媒体上的小丑积极尝试）。</p><p>了解当前认知战攻击的风险水平不仅需要安全思维，还需要安全思维加上适当的视角。它需要一长串特定漏洞利用的示例，以便您可以了解可能存在的其他内容，哪些内容在当前系统中很容易发现，由数百万人的行为数据提供支持，并且持续不断实时进行人工智能辅助实验和心理研究所需的访问权限。我希望小丑袭击是实现这一目标的一个有用的例子。</p><p>在 2020 年代，人均拥有律师人数比以往任何时候都高的世界里，合理的推诿是你应该预料到的事情。同样，办公室政治在精英中也非常普遍，所以一个人认识到通过制造谣言和替罪羊来使人们相互对立是一种制胜策略的门槛很低，那么人们就应该知道某些事情来自你。合理的推诿和假旗攻击并非始于网络攻击；它们都在 20 世纪流行起来。这也是小丑攻击如此强大的另一个原因；在当代文明中，周围的小丑非常普遍，因此很难区分小丑的攻击和噪音。由于被发现的风险极低，这种看似合理的推诿进一步刺激了小丑攻击；小丑攻击的预期成本基本上归结为服务器能源成本，因为被发现的净预期成本几乎为零。</p><p>分析人士对实验室泄漏假说和新冠病毒审查/信息控制等关键信息最终都被降级为右翼小丑的怪异替代现实、与披萨奴隶地牢和妊娠早期堕胎是谋杀相同的宇宙感到震惊，甚至不过，对于任何试图构建 2020-22 年准确世界模型的人来说，实验室泄漏的可能性和 Covid 信息篡改的程度显然都是关键信息。这种明显性就被扼杀了。小丑攻击可以做这样的事情。人类的思维很大程度上取决于社会地位，这样的事情才能发挥作用。至少有一个零日漏洞。</p><p>决定人们眼中的低地位或恶棍与高地位或像你这样的英雄，正在产生一种非常强大的动力来塑造人们的想法，例如，SBF 是一个残暴的恶棍，主导着大多数人对 EA 和 AI 安全的理解。小丑攻击是我目前所知的最强大的认知黑客，特别是如果屏幕刷新率操纵永远不会最终部署的话。</p><p>现代行为操纵范式的一个重要要素是能够尝试大量的事情并看看什么是有效的；不仅仅是暴力破解已知策略的变体以使其更有效，而是首先暴力破解新颖的操纵策略。这完全避免了导致重复危机的稀缺性和研究缺陷，而重复危机至今仍然是心理学研究的瓶颈。事实上，我们文明中的原创心理学研究不再受到对聪明、有洞察力的人的需求的瓶颈，他们可以进行假设生成，这样你可以资助的有限研究希望能找到有价值的东西。仅使用当前的社交媒体范式，您就可以进行研究，例如新闻提要帖子的组合，<i>直到</i>找到有用的东西。可测量性对此至关重要。</p><p>通过将人与其他人进行比较并预测特征和未来行为，多臂老虎机算法可以首先预测特定的操纵策略是否值得冒险实施；导致高成功率和低检测率（因为检测可能会产生高度可测量的响应，特别是在大量传感器暴露的情况下，例如未覆盖的网络摄像头，因为将人们的微表情与失败或暴露的操纵策略的案例或工作网络摄像头视频进行比较数据转化为基础模型）。当您拥有数十亿小时的人类行为数据和传感器数据的样本量时，不同类型的人反应的毫秒差异（例如面部微表情、滚动过去涵盖不同概念的帖子时的毫秒差异、涵盖不同概念后的心率变化、眼球追踪）眼睛经过特定概念、触摸屏数据等后的差异从难以察觉的噪音转变为相关网络的基础。</p><p>甚至不需要人工智能来进行小丑攻击，更不用说法学硕士了。相反，人工智能是“发明”小丑攻击等技术所需要的。自动化信息处理是寻找对人类有效的操纵技术所需要的一切。这种能力可能几年前就已经上线了。除非你拥有来自数百万不同的人的人类行为数据，这些数据都使用相同的受控环境，否则这是不可能完成的，而如果他们知道风险，他们就不会提供这些数据。</p><p>如果不运行算法本身，我不知道多臂老虎机算法会发现什么技术；我做不到，因为只有那些大量购买服务器的人才能访问这么多数据，即使对他们来说，这些数据也被大型科技公司（Facebook、亚马逊、微软、苹果和Google）和足够强大的情报机构（NSA 等）来防止黑客窃取和毒害数据。我也不知道当团队中的人是有能力的心理学家、舆论专家或其他公关专家解释和标记数据中的人类行为以便人类行为变得可测量时，多臂老虎机算法会发现什么。只需少数心理学专家的人类洞察力就足以训练人工智能自主工作；尽管需要这些专家的持续投入，并且大量的见解、行为和发现会被遗漏，并且需要额外的 3 年时间或一些东西才能被发现和标记。</p><p>小丑攻击并不是孤立地推进的，它们与人类思维的理解和利用的广泛加速并行，这<a href="https://arxiv.org/pdf/2309.15084.pdf"><u>本身就是加速人工智能能力研究的副产品</u></a>。例如，我们正在同时进入一个新时代，情报机构使用人工智能使测谎仪测试真正发挥作用，这<a href="https://www.lesswrong.com/posts/foM8SA3ftY94MGMq9/assessment-of-intelligence-agency-functionality-is-difficult#Functioning_lie_detectors_as_a_turning_point_in_human_history"><u>对于地缘政治事务来说绝对是变革性的，</u></a>目前地缘政治事务围绕着决策理论范式，其中每个员工<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3680134/"><u>都是更有能力的人制造谎言的能力大于区分谎言的能力</u></a>，因此不能用“我100%忠诚”或“我知道这个团队中所有有能力和腐败的人是谁”之类的陈述来排序。</p><p>我对影响力技术的地缘政治意义的理解是，信息战的胜利目前被理解为国际冲突的主要胜利条件，类似于军事力量的征服；这种理解长期以来一直在政府和军事精英中盛行，从苏联解体和柏林墙倒塌开始，到所有东欧共产主义政权的垮台，可能从早在美国的越南反战运动中，但在反恐战争主导战场之后，精英们在2010年代左右达成了共识。在罗伯特·萨特（Robert Sutter）关于美中关系的著作和约瑟夫·奈（Joseph Nye）关于精英劝说的著作《软实力》（ <a href="https://www.amazon.com/Soft-Power-Means-Success-Politics/dp/1586483064"><u>Soft Power）</u></a>中，除其他许多地方外，都描述了这一共识。与常规战争和核战争不同，信息战既可以打也可以赢，它打击构成政府和军事机构最基本组成部分的人的思想，并且作为决定战争的最重要的目标之一有着悠久而丰富的历史。美国、俄罗斯/苏联和中国之间的大国冲突中的赢家和输家。因此，我们应该将信息战视为政府认真对待人工智能安全的原因之一；对来自外国政府的信息战的预期是当代美国和中国政权和军队的核心特征之一，这一点在分析人士中广为人知。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/mjSjPHCtbK6TA5tfW/wabao1bvw0xiga2wdirz"></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/mjSjPHCtbK6TA5tfW/rvra5ms9ihw0qag8yssy"></p><p>从社交媒体暴露转向 1-1 和群组沟通仍然存在心理黑客的巨大风险，但最大限度地减少网络表面积/暴露于社交媒体仍将大幅且可能充分地降低风险（尽管需要访问技术本身才能为了验证这种充分性，足够大且安全的数据集足以实际进行操纵研究，可能仅限于足够大的科技公司和情报机构，如 Facebook 和 NSA，而较小的较弱的组织，如国土安全部或Twitter/X 很容易受到大型组织的黑客攻击和数据中毒，尽管有<a href="https://twitter.com/ESYudkowsky/status/1658571365950312448"><u>关于摩根大通部署复杂传感器系统的传言难以证实</u></a>，并且有报道称许多<a href="https://www.technologyreview.com/2018/04/30/143155/with-brain-scanning-hats-china-signals-it-has-no-interest-in-workers-privacy/"><u>与国家有联系的中国公司和机构一直在试验大型组织部署的脑电图的样本大小</u></a>）。</p><p>当前人工智能安全社区中心理黑客的攻击面过多且极端，即使是最低限度的解决方案也会受到阻力——手机网络摄像头难以掩盖，麦克风难以避免，社交媒体使用梯度下降来寻找和解决问题。利用引起习惯形成行为<a href="https://www.lesswrong.com/posts/8gbfvGhSnEJ9hHGew/10-reasons-why-lists-of-10-reasons-might-be-a-winning"><u>的帖子和帖子组合</u></a>（例如，为最大限度地降低退出率而进行的优化会导致系统找到并利用以奇怪的方式吸引人们的奇怪的帖子组合，例如产生一种模糊的感觉，即没有社交媒体的生活是一种当它现实时，苦行僧/僧侣般的存在是 <a href="https://www.lesswrong.com/posts/p2Qq4WWQnEokgjimy/respect-chesterton-schelling-fences"><u>默认的</u></a>）。默认情况下，戒掉主要的生活习惯也很困难，所以貌似合理的否认可能已经在这里再次出现了。</p><p>我在《劳特利奇监控手册》中添加了马克·安德烈杰维奇教授的可选描述，作为<a href="https://www.lesswrong.com/posts/F3vNoqA7xN4TFQJQg/14-techniques-to-accelerate-your-learning-1#4__Intuition_flooding"><u>直觉洪流</u></a>，帮助更多人更容易地准确理解为什么世界实际上已经围绕这项技术运转。令人印象深刻的是，Andrejevic 的写作时间是 2014 年，并且没有表现出对人工智能有任何了解；他描述的系统在当时只需要数据科学和大量用户数据就可行。人工智能只是让这些系统更有能力获得结果。</p><blockquote><p> There is no logical endpoint to the amount of data required by such systems... All information is potentially relevant because it helps reveal patterns and correlations...</p><p> At least three strategies peculiar to the forms of population-level monitoring facilitated by ubiquitous surveillance in digital enclosures have become central to emerging forms of data-driven commerce and security: predictive analytics, sentiment analysis, and controlled experimentation. Predictive analytics relies upon mining behavioral patterns, demographic information, and any other relevant or available data in order to predict future actions [by locating and observing similar people or people who share predictive traits]...</p><p> Predictive analytics is actuarial in the sense that it does not make definitive claims about the future acts of particular individuals, rather it traffics in probabilities, parsing groups and individuals according to how well they fit patterns that can be predicted with known levels of accuracy. Predictive analytics relies on the collection of as much information as possible, not to drill down into individual activities, but to unearth new patterns, linkages, and correlations...</p><p> In combination with predictive analytics, the goal of sentiment analysis is both pre-emptive and productive: to minimize negative sentiment and maximize emotional investment and engagement; not merely to record sentiment as a given but to modulate it as a variable. Modulation means constant adjustment designed to bring the anticipated consequences of a modeled future into the present so as to account for these in ways that might, in turn, reshape that future. If, for example, sentiment analysis reveals resistance to a particular policy or concerns about a brand or issue, the goal is to manage these sentiments in ways that accord with the interests of those who control, capture, and track the data. The goal is not just the monitoring of populations but also their management...</p><p> Such forms of management require more than monitoring and recording a population—they also subject it to ongoing experimentation. This is the form that predictive analytics takes in the age of what Ian Ayres (2007) calls super-crunching: not simply the attempt to get at an underlying demographic or emo tional “truth”; not even the ongoing search for useful correlations, but also the ongoing generation of such correlations. In the realm of marketing, for example, data researchers use interactive environments to subject consumers to an ongoing series of randomized, controlled experiments. Thanks to the interactive infrastructure and the forms of ubiquitous surveillance it enables, the activities of daily life can be captured in virtual laboratories in which variables can be systematically adjusted to answer questions devised by the researchers...</p><p> The infrastructure for ubiquitous interactivity and thus ubiquitous surveillance transforms the media experiences of daily life into a large laboratory...</p><p> Such experiments can take place on an unprecedented scale—in real time. They rely upon the imperative of ubiquity: as much information about as many people as possible...</p><p> Taken together, the technology that captures more and more of the details of daily life and the strategies that take advantage of this technology lead to a shift in the way those who use data think about it. Chris Anderson argues that the dramatic increase in the size of databases results in the replacement of data&#39;s descriptive power by its practical efficacy. The notion of data as referential information that describes a world is replaced by a focus on correlation. As Anderson (2008) puts it in “The End of Theory”:</p><p> &quot;This is a world where massive amounts of data and applied mathematics replace every other tool that might be brought to bear. Out with every theory of human behavior, from linguistics to sociology … Who knows why people do what they do? The point is they do it, and we can track and measure it with unprecedented fidelity. With enough data, the numbers speak for themselves&quot;</p><p> This is a data philosophy for an era of information glut: it does not matter why a particular correlation has predictive power; only that it does. It is also a modality of information usage that privileges those with access to and control over large databases, and, consequently, it provides further incentive for more pervasive and comprehensive monitoring.</p><p> When the US government, for example, exempts surveillance provisions in the USA Patriot Act from the accountability provided by the Freedom of Information Act, it is sacrificing accountability in the name of security... Threats by countries including India and the United Arab Emirates to ban Blackberry messaging devices unless the company provides the state with the ability to access encrypted information further exemplify state efforts to gain access to data generated in yet another type of digital enclosure...</p><p> A loss of control over the fruits of one&#39;s own activity. In the realms of commercial and state surveillance, all of our captured and recorded actions (and the ways in which they are aggregated and sorted) are systematically turned back upon us by those with access to the databases. Every message we write, every video we post, every item we buy or view, our time-space paths and patterns of social interaction all become data points in algorithms for sorting, predicting, and managing our behavior. Some of these data points are spontaneous—the result of the intentional action of consumers; others are induced, the result of ongoing, randomized experiments...</p><p> Much will hinge on whether the power to predict can be translated into the ability to manage behavior, but this is the bet that marketers—and those state agencies that adopt their strategies—are making [in 2014].</p></blockquote><p> Like most uses of multi-armed bandit algorithms to make social media steer people&#39;s thinking in measurable directions, clown attacks do not require <a href="https://www.lesswrong.com/posts/foM8SA3ftY94MGMq9/assessment-of-intelligence-agency-functionality-is-difficult"><u>competent governments or intelligence agencies</u></a> in order to be successfully deployed against the minds of millions of people. Everything required for this technology is easy to access, except for the massive amounts of human behavioral data. It simply requires sufficient access to social media platforms, and the technological sophistication of one software engineer who understands multi-armed bandit algorithms and one data scientist who can statistically measure human behavior, particularly for people with authority or involvement in extant mass surveillance systems, since enough data means that anyone could eyeball the effects. Measurability is still mandatory for multi-armed bandit algorithms to work, since nobody can see directly into the human mind (although there are many peripheral proxies like fMRI data, heart rate, blood pressure, verbal statements and tone, boy posture, subtle changes in hand and eye movements after reading certain concepts, etc and many of these can be constantly measured by a hacked smartphone).</p><p> Lie detectors and clown attacks are the two strongest case studies I&#39;m aware of that would cause AI to dominate global affairs and put AI safety in the crossfire; whether or not this has already happened is largely a question of the math; are AI capabilities to do these things obvious to engineers to tell us that major governments have probably already built the tech? A recent study indicated that a massive proportion of computer vision research is heavily optimized for human behavior research, analysis, and manipulation, and is surreptitiously mislabeled and obfuscated in order to conceal the human research and human use cases that form the core of the computer vision papers, eg <a href="https://arxiv.org/pdf/2309.15084.pdf"><u>a consistent norm of referring to the human research subjects as “objects” instead of subjects</u></a> .</p><p> There&#39;s just a large number of human manipulation strategies that are trivial to discover and exploit, even without AI (although the situation is far more severe when you layer AI on top), it&#39;s just that they weren&#39;t accessible at all to 20th century institutions and technology such as academic psychology. If they get enough data on people who share similar traits to a specific human target, then they don&#39;t have to study the target as much to predict the target&#39;s behavior, they can just run multi-armed bandit algorithms on those people to find manipulation strategies that already worked on individuals who share genetic or other traits. Although the average Lesswrong user is much further out-of-distribution relative to the vast majority of people in the sample data, this becomes a technical problem, as AI capabilities and compute become dedicated to the task of sorting signal from noise and finding webs of correlation with less data. Clown attacks alone have demonstrated that zero days in the brain are fairly consistent among humans, meaning that sample data from millions or billions of people is useable to find a wide variety of zero days in the brains that make up the AI safety community.</p><p> Social media&#39;s ability to mix and match (or mismatch) people in specific ways and at great scale, as well as <a href="https://www.lesswrong.com/posts/fKNRHnxpjDLHnHdek/one-example-of-how-llm-propaganda-attacks-can-hack-the-brain"><u>using bot accounts just to upvote and signal boost specific messages so that they look popular</u></a> , already yielded powerful effects. Adding LLM bots into the equation merely introduces more degrees of freedom.</p><p> Among a wide variety of capabilities, platforms like twitter/X were capable of fiddling with their news feed algorithms such that users are incentivised to output as many words as possible in order to gain more likes/points/status, or as <a href="https://www.lesswrong.com/posts/8gbfvGhSnEJ9hHGew/10-reasons-why-lists-of-10-reasons-might-be-a-winning"><u>high-quality combinations of words</u></a> as they can muster, rather than whatever maximizes the compulsion to return to the platform the next day (a compulsion that is very, very easy to measure by looking at user retention rates and quit rates, and if it is easy to measure then it is easy to maximize via gradient descent). However, if a social media platform like twitter/X does not optimize for competitiveness against other social media platforms, and the other platforms do, then every subsequent day people will return to other social media platforms more and twitter less. The state of <a href="https://slatestarcodex.com/2014/07/30/meditations-on-moloch/"><u>Moloch</u></a> is similar to the thought experiment where 4 social media platforms run multi-armed bandit algorithms to find ways to increase user engagement by 3 minutes per person per day, and if one platform of the four (let&#39;s imagine that it&#39;s twitter/X) eventually notices that the people themselves are spending 9 hours a day on social media, and twitter/X recoils in horror and decides to cease that policy and instead attempt to increase user engagement by 0 hours per person per day, then the autonomous multi-armed bandit algorithms running on other platforms automatically select strategies that harvest minutes of that time from twitter/X, the lone defector platform, in addition to harvesting minutes from the users&#39;s undefended off-screen IRL time, which is the undefended natural resource that&#39;s easiest for social media systems to steal time from, like an intelligent civilization harvesting an inanimate natural resource like plants or oil. The defector platform then loses its market share and is crowded out of the genepool.</p><p> People who can wield gradient descent as a weapon against other people are fearsome indeed (although only the type of person with access to user data and who buys servers by the acre can do this effectively). They not only have the ability to try things that already were demonstrated to work on people similar to you, they also have the ability to select attack avenues in places that you will not look and ways you will not notice, because they have a large enough amount of human behavioral data showing them all the places where people like you <i>did</i> end up looking in the past.</p><p> If true, this technology would, by default, become the darkest secret of the big 5 tech companies, and one of the darkest secrets of American and Chinese intelligence agencies. This tech would be the biggest deliberate abuse of psychological research in human history by far, and its effectiveness hinges on the current paradigm where billions of people output massive amounts of sensor data and social media scrolling data (eg the detailed pace at which different kinds of people scroll through different kinds of information), although the effectiveness of the clown attack on those not aware of it in particular demonstrates that a general awareness of the risk is not sufficient to protect oneself.</p><p> What would the world look like if human thought research and steering technology won out and became hopelessly entrenched 5-10 years ago? Unfortunately, that world would look a lot like this one. There are billions of inward facing webcams pointed at every face looking at every screen. <a href="https://www.nytimes.com/2020/01/14/us/politics/nsa-microsoft-vulnerability.html"><u>The NSA stockpiles exploits in every operating system</u></a> and likely chip firmware as well. There are microphones in every room and accelerometers in the palm of every hand (which gives access to heart rate and a wide variety of other peripheral biophysical data that correlates strongly with various cognitive and emotional behavior). The very existence of mass surveillance is known, but that was only due to Snowden, which was one occasion and probably just bad luck; and the main aspect of the Snowden revelations was not that mass surveillance happens at incredible scale, but that the intelligence agencies were wildly successful at concealing and lying about it for years (and subsequently reorganized around the principle of preventing more Snowdens). An epistemic environment further and further in decline as social status, virtue signaling, and vague impressions dominate. And, last of all, international affairs is coming apart at the seams as the old paradigms die and trust vanishes. This is what a world looks like where powerful people have already gained the ability to access the human mind at a far deeper level than any target has access to; unfortunately, it is also what more mundane worlds look like, where human thought and behavior manipulation capabilities remained similar to 20th century levels. However, I&#39;ve made the case very strongly that such technology exists and that due to fundamental mathematical/statistical dynamics and due to human genetic diversity, these systems fundamentally depend on covert large-scale deployment (eg social media) in order to get sufficiently large amounts of data to run at all eg multi-armed bandit algorithms sufficient to find novel manipulation strategies in real time, and measuring and researching the human thought process sufficiently to use multi-armed bandit algorithms and SGD to steer a target&#39;s thoughts in measurable directions. Therefore, the burden of proof falls even more heavily on the claim that our minds are safe, safe enough for <a href="https://www.lesswrong.com/posts/iNYdKoGsh4ffxbQ5t/navigating-an-ecosystem-that-might-or-might-not-be-bad-for"><u>the AI safety community to survive the 2020s at all</u></a> , not on the claim that our minds are not secure and represent a severe point of failure.</p><p> The question of whether the cognitive warfare situation has already become severe is a question that must be approached with sober analysis, not vibes and vague impressions. Vibes and vague impressions are by far the easiest thing to hack, as demonstrated by the clown attack; and in a world where the situation was acute, then keeping people receptive and vulnerable to influence would be one of the most probable attacks for us to expect to be commonplace.</p><p> New technology actually does make current civilization out-of-distribution relative to civilization over the last 100 or 1000 years, and thus risks termination of norms, dynamics, and assumptions that have made everything in civilization go fine so far, such as humans being better at lying that detecting lies and thus not capable of organizing themselves based on statements of fact like “I am 100% loyal” or “here is an accurate list of the corrupt and incompetent people on this team”. The specific state of human controllability dominated global affairs eg via military recruitment, and when this controllability ratcheted up slightly in the 19th century, it resulted in the total war paradigm of the World War era and the information war paradigm of the Cold War era. Assuming that history will repeat itself, and remain as sensible and intuitive as it always was, is like expecting a psychological study to replicate in an out-of-distribution environment. It certainly <i>might</i> .</p><p> With the superior capabilities to research the human mind offered by the combination of social media and AI, governments, tech companies, and intelligence agencies now have the capability to understand aggregate consumer demand better than ever before and manipulate consumer spending and saving in real time, capabilities that were first sought in the 1980s by the Reagan and Thatcher administrations and never fully reached, but that was with 20th century technology; no social media, no mass surveillance, no user data or sensor data, no AI, only psychology (much of which would not replicate due to the study paradigm, which remains inferior to mass surveillance), statistics, focus groups, and polls, each of which were new at the time, and each of which remain available to governments, tech companies, and intelligence agencies today to supplement their new capabilities. It is for this reason that the paradigm of recessions, a paradigm solidified in the 20th century, is a paradigm that we might expect to die, along with many other civilizational paradigms that were only established in the 20th century due to the 20th century&#39;s relative absence of human behavior measurement and thought steering technology.</p><p><br></p><p> <strong>Taking a step back and looking at a fundamental problem</strong></p><p> If there were intelligent aliens, made of bundles of tentacles or crystals or plants that think incredibly slowly, their minds would also have zero days that could be exploited because any mind that evolved naturally would probably be like the human brain, a kludge of spaghetti code that is operating outside of its intended environment, and they would also would not even begin to scratch the surface of finding and labeling those zero days until, like human civilization today, they began surrounding thousands or millions of their kind with sensors that could record behavior several hours a day and find webs of correlations. Of course, if they didn&#39;t have much/any genetic diversity then it would be even easier to find those zero days, and vice versa for intense amounts of diversity. However, the power of the clown attack demonstrates that genetic diversity in humans is not sufficient to prevent zero days from being discovered and exploited; the drive to gain and avoid losing social status is hackable, with current levels of technology (social media algorithms, multi-armed bandit algorithms, and sentiment analysis), indicating that many other exploits are findable as well with current levels of technology.</p><p> There isn&#39;t much point in having a utility function in the first place if hackers can change it at any time. There might be parts that are resistant to change, but it&#39;s easy to overestimate yourself on this; for example, if you value the longterm future and think that no false argument can persuade you otherwise, but a social media news feed plants paranoia or distrust of Will Macaskill, then you are one increment closer to not caring about the longterm future; and if that doesn&#39;t work, the multi-armed bandit algorithm will keep trying until it finds something that works. The human brain is a kludge of spaghetti code, so there&#39;s probably something somewhere. The human brain has zero days, and the capability and cost of social media platforms to use massive amounts of human behavior data to find complex social engineering techniques is a profoundly technical matter, you can&#39;t get a handle on this with intuition or pre 2010s historical precedent. Thus, you should assume that your utility function and values are at risk of being hacked at an unknown time, and should therefore be assigned a discount rate to account for the risk over the course of several years. Slow takeoff over the course of the next 10 years alone guarantees that this discount rate is too high in reality for people in the AI safety community to continue to go on believing that it is something like zero. I think that approaching zero is a reasonable target, but not with the current state of affairs where people don&#39;t even bother to cover up their webcams, have important and sensitive conversations about the fate of the earth in rooms with smartphones, and use social media for nearly an hour a day (scrolling past nearly a thousand posts). The discount rate in this environment cannot be considered “reasonably” close to zero if the attack surface is this massive; and the world is changing this quickly. If people have <a href="https://www.lesswrong.com/posts/SGR4GxFK7KmW7ckCB/something-to-protect"><u>anything they value at all</u></a> , and the AI safety community probably does have that, then the current AI safety paradigm of zero effort is wildly inappropriate, it is basically total submission to invisible hackers.</p><p> The sheer power of psychological influence technologies informs us that we should stop thinking of cybersecurity as a server-only affair. Humans can also make mistakes as extreme as using the word “password” as your password, except it is your mind and your values and your impressions of different lines of reasoning that gets hacked, not your files or your servers or your bank passwords/records. In order to survive slow takeoff and persist for as long as necessary, the AI safety community must acknowledge the risk that the 2020s will be intensely dominated by actors capable of using modern technology to stealthily hack the human mind and eliminate inconvenient people, such as those try to pause AI, even though AI is basically the keys to their kingdom. We must acknowledge that the future of cyberwarfare doesn&#39;t just determine who gets to have their files and verbal conversations be private; in the 2020s, it determines what kinds of thoughts people get to have and what kinds of people do and don&#39;t get to have them at all (eg as one single example, clowns do have the targeted thoughts and the rest don&#39;t).</p><p> Everything that we&#39;re doing here is predicated on the assumption that powerful forces, like intelligence agencies, will not disrupt the operations of the community eg by inflaming factional conflict with false flag attacks attributed to each other due to the use of anonymous proxies.</p><p> Most people in AI safety still think of themselves as ordinary members of the population. In reality, this stopped being true a while ago; a bunch of nerds discovered an engineering problem that, as it turns out, the universe actually does revolve around, and a bunch of nerds messing around with technology that is central to geopolitics bears a reasonable chance that geopolitics will bite back, especially in a wild where intelligence agencies have, for decades, messed with and utilized influential NGOs in a wide variety of awful ways, and in a wild where intensely powerful influence technology like clown attacks becomes stronger and stronger determinants of geopolitical winners and losers.</p><p> If left to their own devices, people&#39;s decisions technology and social media will be dominated by their self-concept of themself as an average member of the population, who considers things like news feeds and smartphone sensors/uncovered webcams as safe because everyone&#39;s doing it and of course nothing bad would happen to them, when the cybersecurity reality is that the risk of psychological engineering is extreme and in a mathematically provable way, and this nonchalance towards strangers tampering/hacking your cognition and utility function is an unacceptable standard for the group of nerds who actually discovered an engineering problem that this side of the universe revolves around.</p><p> The attack surface of the AI safety community is like the surface area of the interior of a cigarette filter; thousands of square kilometers, wrinkled and folded together inside the spongey three-dimensional interior of a 1-inch long cigarette filter. This is not the kind community that survives a transformative world.</p><p> From <a href="https://www.lesswrong.com/posts/psYNRb3JCncQBjd4v/shutting-down-the-lightcone-offices"><u>Shutting Down the Lightcone Offices</u></a> :</p><blockquote><p> I feel quite worried that the alignment plan of Anthropic currently basically boils down to &quot;we are the good guys, and by doing a lot of capabilities research we will have a seat at the table when AI gets really dangerous, and then we will just be better/more-careful/more-reasonable than the existing people, and that will somehow make the difference between AI going well and going badly&quot;. That plan isn&#39;t inherently doomed, but man does it rely on trusting Anthropic&#39;s leadership, and I genuinely only have marginally better ability to distinguish the moral character of Anthropic&#39;s leadership from the moral character of FTX&#39;s leadership...</p><p> In most worlds RLHF, especially if widely distributed and used, seems to make the world a bunch worse from a safety perspective (by making unaligned systems appear aligned at lower capabilities levels, meaning people are less likely to take alignment problems seriously, and by leading to new products that will cause lots of money to go into AI research, as well as giving a strong incentive towards deception at higher capability levels)... The EA and AI Alignment community should probably try to delay AI development somehow, and this will likely include getting into conflict with a bunch of AI capabilities organizations, but it&#39;s worth the cost.</p></blockquote><p> I don&#39;t have much to contribute to the calculations behind this policy (which I&#39;d like to note is just musing by Habryka intended to elicit further discussion, and I might be taking it out of context), other than describing in great detail what a &quot;conflict with a bunch of AI capabilities organizations&quot; would look like, which I&#39;ve been researching for years and it is not pretty; the asymmetry is so serious that even thinking about waging such a conflict could begin closing the window of opportunity for you to make moves, eg if some of the people you talk to end up using social media and scrolling past specific bits of information at a pace similar to, say, for example, people who ultimately ended up seeing big tech companies as enemies, but in a cold and calculating and serious way, not in an advocacy way. Sample sizes of millions of people makes that kind of prediction possible; even if there are only a dozen people in the data set of positive cases of cold-bigtech-enmity, there are millions of people who make up the data set for negative cases, allowing analysts to get an extremely good idea of what a potential threat looks like by knowing what a potential threat doesn&#39;t look like. This is only one example, and it is entirely social-media based; it does not use, say, automated analysis of audio data from recorded conversations near hacked smartphones, which is very unambiguously the kind of thing that can be expected to happen to people who would &quot;get into conflict with a bunch of AI capabilities organizations&quot; as those organizations tend to have strong ties, and possibly even substantial revolving door employment, with intelligence agencies; Facebook/Meta is a good example, as they routinely find themselves at the center of public opinion and information warfare conflicts around the world. It&#39;s also unclear to me how sovereign these companies&#39;s security departments are without continued logistical support and staff from American intelligence agencies, as they have to contend with intense interest from a wide variety of foreign intelligence agencies. There is an entire second world here, that is 1) parallel to the parts of the ML community that are visible to us, 2) vastly more powerful, privileged, and dangerous than the ML community, and 3) has a massive vested interest in the goings-on of the ML community, and I&#39;ve encountered dozens and dozens of people in the AI safety community in both SF/berkeley and DC, and if a single person was aware of this second world, they were doing an incredibly good job totally hiding their awareness of it. I think this is a recipe for disaster. I think that the AI safety community is not even thinking about the kinds of manipulation, subterfuge, and sabotage that would take place here just based off of this world&#39;s lawyers-per-capita alone, and the fact that this is a trillion-dollar industry, let alone that this is a trillion-dollar industry due in part to the human influence capabilities I&#39;ve barely begun to describe here, let alone due to interest that these capabilities attracted from all the murkiest people lurking within the US-China conflict.</p><p> The attempt to open source Twitter/X&#39;s newsfeed algorithm might have been months ago, but even if it was a step in the right direction, to repeatedly attempt projects like that would cause excessive disruptions and delegitimizations for the industry, particularly Facebook/Meta which will never be able to honestly open-source its systems&#39;s news feed algorithms. Facebook and the other 5 large tech companies (of whom Twitter/X is not yet a member due to vastly weaker data security) might be testing out their own pro-democracy anti-influence technologies and paradigms, akin to Twitter/X&#39;s open-sourcing its algorithm, but behind closed doors due to the harsher infosec requirements that the big 5 tech companies face. Perhaps there are ideological splits among executives eg with some executives trying to find a solution to the influence problem because they&#39;re worried about their children and grandchildren ending up as floor rags in a world ruined by mind control technology, and other executives nihilistically marching towards increasingly effective influence technologies so that they and their children personally have better odds of ending up on top instead of someone else. Twitter/X&#39;s measured pace by ope sourcing the algorithm and then halting several months afterwards is therefore potentially a responsible and moderate move in the right direction, especially considering <a href="https://twitter.com/ESYudkowsky/status/1712908282581631372"><u>the apparent success of the community notes paradigm at improving epistemics</u></a> .</p><p> The AI safety community is now in a situation where it has to do everything right. The human race must succeed at this task, even if the human brain didn&#39;t evolve to do well at things like having the entire species coordinate to succeed at a single task. Especially if that task, AI alignment, might be absurdly difficult entirely for technical reasons, as difficult for the human mind to solve as expecting chimpanzees to figure out enough rocket science to travel to the moon and back, which would be a big ask regardless of the chimpanzees&#39;s instinctive tendency to form factions and spend 90% of their thinking on clever plots to outmaneuver and betray each other. This means that vulnerability to clown attacks is unacceptable for the AI safety community, and it is also unacceptable to be vulnerable to other widespread social engineering techniques that exploit zero days in the human brain. The degree of vulnerability is highly measurable by attackers, and increasingly so as technology advances, and since it is legible that attackers will be rewarded for exploiting vulnerabilities, it is therefore incentivised for attackers to exploit those vulnerabilities and steer the AI safety community over a cliff.</p><p> The AI safety community has long passed a threshold where vulnerability to clown attacks is no longer acceptable; not only does it incentivize more clown attacks, and more ambitious clown attacks, where the attackers have more degrees of freedom, but the AI safety community is in a state where clown attacks can thwart many of the tasks required to do AI safety at all.</p><p> Lots of people approach AI social control as though solving AI alignment is priority #1 and the use of AI social control is priority #2. However, this attitude is not coherent. AI alignment is #1, and AI social control is #1a, a subset of #1 with virtually no intrinsic value on its own, only instrumental value to AI alignment, as the use of AI for social control would incentivise accelerating AI and complicate alignment efforts in the meantime, either by direct sabotage by intelligence agencies or AI companies, or by causing totalitarianism or all-penetrating crushing information warfare between the US and China, or some other state of civilization that we might fail to adapt to.</p><p></p><p> <strong>How to protect yourself and others:</strong></p><ol><li> Either stop reasoning based on vibes and impressions (hard), or stop spending hours a day inside hyperoptimized vibe/impression hacking environments (social media). This may sound like a big ask, but it actually isn&#39;t, like cryopreservation; everyone on earth happens to be doing it catastrophically wrong and its actually a super quick fix, less than a few days or even a few hours and your entire existence is substantially safer. But more than 99% of people on earth will look at you as if you were wearing a clown suit, and that intimidates people away from specific lines of thought in a very deep way.</li><li> A critical element is for as many people as possible in AI safety to cover up their webcams; facial microexpressions are remarkably revealing, especially to people with access to billions of hours of facial microexpression data of people in flexible hypercontrolled environments like the standard social media news feed. Facial microexpressions are the output of around 60 different facial muscles, and although modern ML probably can&#39;t compress each frame of a video file to a 6 by 10 matrix that represents how contracted each facial muscle is, modern ML bably compress, say, every 5 frames into a 128 by 128 matrix that represents the state of the 20% of the facial muscles that project ~80% of the valuable data/signal outputted by facial muscles. Minimizing exposure to other sensors is ideal as well; it <a href="https://www.wired.com/2016/11/great-now-even-headphones-can-spy/"><u>seems pretty likely that a hacked OS can turn earbuds into microphones</u></a> so definitely switch to used speakers. I use a wireless keyboard so that I don&#39;t have to worry about the accelerometers in my laptop, and a trackball mouse that I use with my off hand. Some potential exploits, like converting RAM chips or accelerometers, mean that it might be difficult to prevent laptops from recording enough audio to acquire changes in your heart rate itself, but there&#39;s a wide variety of other biophysical data that it&#39;s not in your best interest to donate (if you&#39;re going to sell shares of your utility function, at least don&#39;t sell them for zero dollars).</li><li> It&#39;s probably a good idea to switch to physical books instead of ebooks. Physical books do not have operating systems or sensors. You can also print out research papers and Lesswrong and EAforum articles that you already know are probably worth reading or skimming; if you drive to the store and actually spend 15 minutes looking, you will probably find an incredibly ink-efficient printer.</li><li> I&#39;m not sure whether a text-only inoculation is good enough, or whether there&#39;s no way around the problem other than reducing people&#39;s exposure to sensors and social media. Reading <a href="https://www.readthesequences.com/"><u>Yudkowsky&#39;s rationality sequences</u></a> will definitely make one&#39;s thoughts and behaviors harder to predict, but it won&#39;t patch or rearrange the zero days in the human brain. Even <a href="https://www.lesswrong.com/posts/bbB4pvAQdpGrgGvXH/tuning-your-cognitive-strategies"><u>Tuning your Cognitive Strategies</u></a> won&#39;t do that, although it might go a long way towards making it much harder to gather data on the details of those zero days by comparing your mind and behavior to the minds and behavior of millions of people that make up the data, because your mind will be just be more different from those people than before, and you will be different from them in very different ways from how they are different from each other. You will be out-of-distribution, and the distribution is a noose that is slowly tightening around the mind of most people on earth. If reading the sequences seem daunting, I recommend starting with the <a href="https://www.lesswrong.com/highlights"><u>highlights</u></a> or <a href="https://www.lesswrong.com/posts/PouWW8Ys4iKhWedCZ/psa-the-sequences-don-t-need-to-be-read-in-sequence"><u>randomly selecting posts from them out-of-order</u></a> . <a href="http://hpmor.com"><u>HPMOR</u></a> is also an incredibly fun and enjoyable alternative to read in your down time if you&#39;re busy (and possibly one of the most rereadable works of fiction ever written), and <a href="https://www.lesswrong.com/posts/SA9hDewwsYgnuscae/projectlawful-com-eliezer-s-latest-story-past-1m-words"><u>Planecrash</u></a> is a similarly long and ambitious work by Yudkowsky that is darker and less well-known, even though the self-improvement aspect seems more refined and effective. Other safe predictability reducers include <a href="https://www.lesswrong.com/codex"><u>Scott Alexander&#39;s codex</u></a> for a more world-modeling focus, and the <a href="https://www.lesswrong.com/posts/dbDHEQyKqnMDDqq2G/cfar-handbook-introduction"><u>CFAR handbook</u></a> for more practical self-enhancement work. <a href="https://www.lesswrong.com/about#Getting_Started_on_LessWrong"><u>These are all highly recommended</u></a> for self-improvement.</li><li> It&#39;s probably best to avoid sleeping in the same room as a smart device, or anything with sensors, an operating system, and also a speaker. The attack surface seems large, if the device can tell when people&#39;s heart rate is near or under 50 bpm, then it can test all sorts of things eg prompting sleep talk on specific topics. The attack surface is large because there&#39;s effectively zero chance of getting caught, so if people were to experiment with that, it wouldn&#39;t matter how low the probability of success is for any idea to try or whether they were <a href="https://www.lesswrong.com/posts/LyywLDkw3Am9gbQXd/don-t-take-the-organizational-chart-literally"><u>just engaging in petty thuggery</u></a> . Just drive to the store and buy a clock, it will be like $30 at most and that&#39;s it.</li><li> Of course, you should be mindful of what you know and how you know it, but in the context of modern technologies, it&#39;s more important to pay attention to your feelings, vibe, and impression of specific concepts, and you successfully search your mind and trace the origins of those feelings, you might notice the shadows cast by the clowns that have fouled up targeted concepts (you probably don&#39;t remember the clowns themselves, as they are nasty internet losers). But that&#39;s just one zero day, and the problem is bigger and more fundamental than that. Patching the clown attack is valuable, but it&#39;s still a band-aid solution that will barely address the root of the issue.</li><li> I am available via LW message to answer any questions you might have.</li></ol><blockquote><p> First it started working on people in the bottom 70%, and I didn&#39;t speak up, because my mind wasn&#39;t as predictable as people in the bottom 70%. Then, it started working on people in the bottom 95%, and I didn&#39;t speak up, because my mind wasn&#39;t as predictable as the people in the bottom 95%. Then it started working on me. And by then, it was already too late, because it was already working on me.</p></blockquote><br/><br/> <a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks<guid ispermalink="false"> mjSjPHCtbK6TA5tfW</guid><dc:creator><![CDATA[trevor]]></dc:creator><pubDate> Sat, 21 Oct 2023 22:03:15 GMT</pubDate> </item><item><title><![CDATA[How toy models of ontology changes can be misleading]]></title><description><![CDATA[Published on October 21, 2023 9:13 PM GMT<br/><br/><p> Before solving complicated problems (such as reaching a decision with thousands of variables and complicated dependencies) it helps to focus on solving simpler problems first (such as utility problems with three clear choices), and then gradually building up. After all, &quot;learn to walk before you run&quot;, and with any skill, you have to train with easy cases at first.</p><p> But sometimes this approach can be unhelpful. One major examples is in human decision-making: trained human experts tend to rapidly &quot; <a href="https://en.wikipedia.org/wiki/Recognition-primed_decision">generate a possible course of action, compare it to the constraints imposed by the situation, and select the first course of action that is not rejected.</a> &quot; This type of decision making is not an improved version of rational utility-maximisation; it is something else entirely. So a toy model that used utility-maximisation would be misleading in many situations.</p><h1> Toy model ontology failures</h1><p> Similarly, I argue, the simple toy models of ontology changes are very unhelpful. Let&#39;s pick a simple example: <a href="https://arbital.com/p/ontology_identification/">an agent making diamonds</a> . </p><figure class="image image_resized" style="width:47.09%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/itpr8njr0c4zsqf1wuhy" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/rdfe9fs2beptkbx8fqn2 134w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/lqihnxtz4okvhsrljxrk 214w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/tz58b12ih3as1ishimmf 294w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/bnjlfs0hmhqiqwompmtj 374w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/aqonq6vx530junonj9in 454w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/u6lylomylldpbhkwkypl 534w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/s6p6zsqfhwus5kdhgfne 614w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/vwwvdhco0o4cmro2gklw 694w"></figure><p> And let&#39;s pick the simplest ontology change/ <a href="https://www.lesswrong.com/s/AEbqhmiBcxs5kFv72">model splintering</a> that we can: the agent gains access to some <a href="https://en.wikipedia.org/wiki/Carbon-13">carbon-13</a> atoms. </p><figure class="image image_resized" style="width:50.7%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/w99xbdg6tdw1wxundzgs" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/lifpz5ubwykbcht5scuc 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/xmii6ktxgszbtizyyidk 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/k9yt6cxsr1iizhd6ftba 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/que3fo7moiqnxw8zukqo 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/bqzey5oavzx6rhmzn3xa 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/hvla7yuvkdpkgs2gjrk9 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/kltdkgwelubvephi47zj 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/dsxapdvyhrzszogj1t8l 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/e3r7hikj5wtpodjb2oih 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XvhrmTog2bkf5s2qu/psdizntdwapoack9rtb7 1015w"></figure><p> Assuming the agent has only ever encountered standard carbon-12 atoms during its training, how should it handle this new situation?</p><p> Well, there are multiple approaches we could take. I&#39;m sure that some spring to mind already. We could, for example...</p><p> ...realise that the problem is fundamentally unsolvable.</p><p> If we have trained our agent with examples of carbon-12 diamonds (&quot;good!&quot;) versus other arrangements of carbon-12 (&quot;bad!&quot;) and other non-carbon elements (&quot;bad!&quot;), then we have underdefined what it should do with carbon-13. Treating the carbon-13 the same as carbon-12 (&quot;good iff in diamond shape&quot;) or the same as other elements (&quot;always bad&quot;): both options are fully compatible with the training data.</p><p> Therefore there is no &quot;solving&quot; this simple ontology change problem. One can design various methods that may give one or another answer, but then we are simply smuggling in some extra assumptions to make a choice. The question &quot;what should a (carbon-12) diamond maximiser do with carbon-13 if it has never encountered it before?&quot; does not have an answer.</p><p> Low-level preferences in one world-model do not tell an agent what their preferences should be in another.</p><h1> More complex models give more ontology-change information</h1><p> Let&#39;s make the toy model more complicated, in three different ways.</p><ol><li> The agent may be making diamonds are part of a larger goal (to make a wedding ring, to make money for a corporation, to demonstrate the agent&#39;s skills). Then whether carbon-13 counts can be answered by looking at this larger goal.</li><li> The agent may be making diamonds alongside other goals (maybe it is a human-like agent with a strange predilection for diamonds). Then if could make sense for the agent to choose how to extend its goal by considering compatibility with these other goals. If they also liked beauty, then carbon-13 could be as good as carbon-12. If they were obsessed with purity or precision, then they could exclude it. This doesn&#39;t provide strong reasons to favour one over the other, but at least gives some guidance.</li><li> Finally, if the agent (or the agent&#39;s designer) has <a href="https://www.lesswrong.com/posts/CSEdLLEkap2pubjof/research-agenda-v0-9-synthesising-a-human-s-preferences-into#2_6_Synthesising_the_preference_function__meta_preferences">meta-preferences</a> over how its preferences should extend, then this should guide how the goals and preferences change.</li></ol><p> So, instead of finding a formula for how agents handle ontology changes, we need to figure out <i><strong>how we would want them to behave</strong></i> , and code that into them. Dealing with ontology changes is an issue connected with our values (or the <a href="https://www.lesswrong.com/tag/value-extrapolation">extrapolations of our values</a> ), not something that has a formal answer.</p><p> And toy models of ontology changes can be misleading about where the challenge lies.</p><br/><br/> <a href="https://www.lesswrong.com/posts/XvhrmTog2bkf5s2qu/how-toy-models-of-ontology-changes-can-be-misleading#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/XvhrmTog2bkf5s2qu/how-toy-models-of-ontology-changes-can-be-misleading<guid ispermalink="false"> XvhrmTog2bkf5s2qu</guid><dc:creator><![CDATA[Stuart_Armstrong]]></dc:creator><pubDate> Sat, 21 Oct 2023 21:13:56 GMT</pubDate> </item><item><title><![CDATA[Soups as Spreads]]></title><description><![CDATA[Published on October 21, 2023 8:30 PM GMT<br/><br/><p> <span>We tend to cook in quantities where there are leftovers: it&#39;s not really practical to cook exactly the right amount of food, and it&#39;s much better to have a bit extra than not enough. Plus with several people working from home we tend to go through a good amount of leftovers for lunches. One thing I&#39;ve discovered recently with leftovers: thicker sauces and soups make surprisingly good spreads.</span></p><p> For example, I recently had tomato soup sandwiches:</p><p> <a href="https://www.jefftk.com/tomato-soup-as-spread-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/mRdykbSJaLZaNPNaW/nuip8jf0vdhm66tpeoed" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/mRdykbSJaLZaNPNaW/nuip8jf0vdhm66tpeoed 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/mRdykbSJaLZaNPNaW/rntjrhtecqhagd2m7epw 1100w"></a></p><div></div><p></p><p> While something watery or brothy will stay that way even when cooler, most things thicken up in the fridge to where they&#39;ll spread well on bread. And it&#39;s very tasty!</p><p> I still mostly eat any leftover soups and sauces reheated, but if I want something more portable I&#39;ve been pretty happy with this.</p><br/><br/><a href="https://www.lesswrong.com/posts/mRdykbSJaLZaNPNaW/soups-as-spreads#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/mRdykbSJaLZaNPNaW/soups-as-spreads<guid ispermalink="false"> mRdykbSJaLZaNPNaW</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Sat, 21 Oct 2023 20:30:08 GMT</pubDate> </item><item><title><![CDATA[Which COVID booster to get?]]></title><description><![CDATA[Published on October 21, 2023 7:43 PM GMT<br/><br/><p> Any thoughts on the Novavax vs Moderna / Pfizer vaccines?</p><p> Based on what I&#39;ve read, it seems like they have comparable efficacy, with the potential for less intense side effects from Novavax, so I&#39;m leaning towards that one (having gotten Pfizer initially, then Moderna, which left me super tired and mildly flu-ish for about a day each time).</p><p> Incidentally, my side effects were appreciably better when I got the flu vaccine separately -- it&#39;s possible that was just the initial series vs booster or something, but I definitely will be doing those separately this time around as well.<br><br> Comparable efficacy:<br> - 10/6/23 Science article: <a href="https://www.science.org/content/article/should-you-pick-novavax-s-covid-19-shot-over-mrna-options">https://www.science.org/content/article/should-you-pick-novavax-s-covid-19-shot-over-mrna-options</a><br> - 10/17/23 Lifehacker post: <a href="https://www.msn.com/en-US/health/medical/is-the-novavax-covid-vaccine-actually-better/ar-AA1inrUm?ocid=sapphireappshare">https://www.msn.com/en-US/health/medical/is-the-novavax-covid-vaccine-actually-better/ar-AA1inrUm?ocid=sapphireappshare</a><br><br> Less intense side effects: 8/29/23 Your Local Epidemiologist post <a href="https://yourlocalepidemiologist.substack.com/p/your-top-7-questions-about-fall-vaccines?utm_source=substack&amp;utm_medium=email">https://yourlocalepidemiologist.substack.com/p/your-top-7-questions-about-fall-vaccines?utm_source=substack&amp;utm_medium=email</a></p><br/><br/><a href="https://www.lesswrong.com/posts/88TXtvemj6h2SEkTC/which-covid-booster-to-get#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/88TXtvemj6h2SEkTC/which-covid-booster-to-get<guid ispermalink="false"> 88TXtvemj6h2SEkTC</guid><dc:creator><![CDATA[Sameerishere]]></dc:creator><pubDate> Sat, 21 Oct 2023 19:43:05 GMT</pubDate> </item><item><title><![CDATA[Alignment Implications of LLM Successes: a Debate in One Act]]></title><description><![CDATA[Published on October 21, 2023 3:22 PM GMT<br/><br/><p><strong>杜米米尔</strong>：人类在阵营问题上没有取得任何进展。我们不仅不知道如何使强大的优化器与我们的“真实”值保持一致，我们甚至不知道如何使人工智能“可纠正”——愿意让我们纠正它。与此同时，能力继续突飞猛进。全没了。</p><p><strong>辛普利西亚</strong>：怎么了，杜米米尔·杜莫维奇，你真是个脾气暴躁的人！现在应该很清楚，“协调”方面的进步——让机器按照人类的价值观和意图行事——与你所谴责的“能力”进步并不能完全分开。事实上，这是我刚才在 OpenAI Playground 中可以纠正的 GPT-4 示例： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pYWA7hYJmXnuyby33/eji5c05sdhs905zic1kw" alt=""></p><p> <strong>Doomimir</strong> ：Simplicia Optimistovna，你不是认真的！</p><p><strong>辛普利西亚</strong>：为什么不呢？</p><p> <strong>Doomimir</strong> ：一致性问题从来都不是超级智能无法<em>理解</em>人类价值观的问题。<a href="https://www.lesswrong.com/posts/NyFuuKQ8uCEDtd2du/the-genie-knows-but-doesn-t-care">精灵知道，但并不关心。</a>经过训练来预测自然语言文本的大型语言模型可以生成该对话，这一事实与人工智能的实际动机无关，即使对话是以第一人称编写的，并且理论上“关于”一个可纠正的人工智能助理角色。这只是角色扮演。更改系统提示符，法学硕士可以同样轻松地输出“声称”是一只猫或一块石头的标记，并且出于同样的原因。</p><p> <strong>Simplicia</strong> ：正如你所说，杜米米尔·杜莫维奇。这只是角色扮演：模拟。但<a href="https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators"><em>代理的模拟就是代理</em></a>。当我们让法学硕士为我们做认知工作时，所完成的工作是法学硕士根据训练数据中出现的模式进行概括的问题，即人类用来解决问题的推理步骤。如果你看看最近被吹捧的语言模型代理的成功，你就会发现这是真的。看看<a href="https://arxiv.org/abs/2201.11903">思维链的</a>结果。看看<a href="https://say-can.github.io/">SayCan</a> ，它使用 LLM 来转换模糊的请求，例如“我洒了东西；你能帮忙吗？”到物理机器人可以执行的子任务列表中，例如“找到海绵，拿起海绵，将其带给用户”。看看<a href="https://voyager.minedojo.org/">Voyager</a> ，它通过提示 GPT-4 根据 Minecraft API 进行编码来玩 Minecraft，并通过提示<a href="https://github.com/MineDojo/Voyager/blob/55e45a880755d0c8c66ca7fb5fe7962ac8974f89/voyager/prompts/curriculum.txt">“你是一个有用的助手，告诉我在 Minecraft 中要执行的下一个即时任务”来决定下一步要编写哪个函数。</a></p><p>我们在这些系统中看到的是人类常识的统计镜子，而不是随机效用函数的可怕的无限计算 argmax。相反，当法学硕士无法忠实地模仿人类时（例如，基础模型有时<a href="https://gwern.net/gpt-3#repetitiondivergence-sampling">会陷入重复陷阱</a>，一遍又一遍地重复相同的短语），他们也无法做任何有用的事情。</p><p> <strong>Doomimir</strong> ：但是重复陷阱现象似乎说明了为什么对齐是困难的。当然，对于看起来与训练分布相似的事物，你可以获得漂亮的结果，但这并不意味着人工智能已经内化了你的偏好。当你离开分布时，结果对你来说就像是随机的垃圾，因为能力比对齐更通用。</p><p> <strong>Simplicia</strong> ：我的观点是，重复陷阱是“能力”未能与“对齐”一起概括的情况。重复行为并不能有效地优化恶意目标；它只是退化了。 <code>for</code>循环可以给你相同的输出。</p><p><strong>杜米米尔</strong>：我的观点是，我们不知道所有这些难以理解的矩阵内部正在发生什么样的认知。<a href="https://www.lesswrong.com/posts/nH4c3Q9t9F3nJ7y8W/gpts-are-predictors-not-imitators">语言模型是预测器，而不是模仿器</a>。预测由许多人长时间生成的语料库的下一个标记需要超人的能力。作为这一点的理论说明，想象一下训练数据中存在一个（SHA-256 哈希、明文）对列表。在极限内——</p><p> <strong>Simplicia</strong> ：在极限范围内，是的，我同意可以破解 SHA-256 的超级智能可以在当代语言模型的训练或测试数据集上实现较低的损失。但是为了理解我们面前的技术以及在下个月、下一年、下十年如何利用它——</p><p><strong>杜米米尔</strong>：如果我们<em>有</em>十年——</p><p> <strong>Simplicia</strong> ：我认为这是一个与决策相关的事实，深度学习并没有破解加密哈希值，<em>而是</em>学习从“我洒了一些东西”到“找到海绵，捡起海绵”——而且是从数据而不是搜索中学习。显然，我同意语言模型不是人类。事实上，它们<a href="https://www.lesswrong.com/posts/htrZrxduciZ5QaCjw/language-models-seem-to-be-much-better-than-humans-at-next">在接受训练的任务上比人类做得更好</a>。但就现代方法非常擅长从数据中学习复杂分布而言，将人工智能与人类意图结合起来的项目——让它完成我们要做的工作，但更快、更便宜、更好、更可靠——越来越像一个工程问题：很棘手，如果做得不好，会产生致命的后果，但无需任何打破范式的见解就可以实现。任何暗示这种情况不可能的<em>先验</em>哲学也许应该重新考虑吗？</p><p> <strong>Doomimir</strong> ：Simplicia Optimistovna，显然我是在质疑你对当前情况的解释，而不是断言当前情况是不可能的！</p><p><strong>辛普利西亚</strong>：抱歉，杜米米尔·杜莫维奇。我并不是想欺骗你，只是想强调<a href="https://www.lesswrong.com/posts/WnheMGAka4fL99eae/hindsight-devalues-science">事后诸葛亮会贬低科学</a>。仅就我自己而言，我记得在读完<a href="https://selfawaresystems.files.wordpress.com/2008/01/ai_drives_final.pdf">Omohundro 的“基本人工智能驱动器”</a>后，我记得在九点钟的时候花了一些时间思考对齐问题，并咒骂我父亲的名字的讽刺，因为这个问题看起来是多么无望。人类欲望的复杂性，支撑每一种情感和梦想的错综复杂的生物机制，将代表着浩瀚的可能的效用函数中最微小的针刺！如果有可能在机器中体现一般的手段-目的推理，我们永远不会让它做我们想做的事。它会在每一个转折点上挑战我们。<a href="https://www.lesswrong.com/posts/4ARaTpNX62uaL86j6/the-hidden-complexity-of-wishes">穿越时间的路径太多</a>了。</p><p>如果你当时向我描述了指令调整语言模型的想法，并建议通过从数据中<em>复制</em>它来实现越来越通用的人类兼容人工智能，我会犹豫不决：我听说过无监督学习，但是这是荒唐的！</p><p> <strong>Doomimir</strong> ： <em>[温和地居高临下]</em>你之前的直觉更接近正确，Simplicia。过去十五年来我们所看到的一切都没有使奥莫亨德罗无效。空白地图并不对应于空白领土。推理和优化定律意味着对齐是困难的，就像热力学定律排除了永动机一样。仅仅因为您不知道<a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">SGD</a>对您的神经网络进行了什么样的优化，并不意味着它没有目标 —</p><p> <strong>Simplicia</strong> ：杜米米尔·杜莫维奇，我并不否认法律的存在！问题是真正的法律意味着什么。这里有一条定律：仅给出以对数为底的两个<em>n</em>位证据，你无法区分<em>n</em> + 1 种可能性。这根本不可能做到，就像你不能将五只鸽子放入四个鸽子笼中一样。</p><p>现在将其与模拟可纠正的人工智能助手角色的 GPT-4 进行对比，该角色同意在被要求时关闭，并注意您可以将输出连接到命令行并让它实际上自行关闭。这里违反了什么推理或优化法则？当我看到这个时，我看到了一个合法的因果系统：模型<a href="https://www.lesswrong.com/posts/4hLcbXaqudM9wSeor/philosophy-in-the-darkest-timeline-basics-of-the-evolution">根据从我那里收到的信号执行一条推理或另一条条件</a>。</p><p>这当然不是很安全。一方面，我希望更好地保证该系统将<a href="https://www.lesswrong.com/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post"><em>保持</em>作为可纠正的人工智能助手的“本色”</a> 。但<em>没有</em>进展？全没了？为什么？</p><p> <strong>Doomimir</strong> ：GPT-4 不是超级智能，Simplicia。 <em>[排练过，带着一丝恼怒，仿佛对他不得不如此频繁地说这句话感到不满]</em>相干的代理人有一种趋同的工具性动机来防止自己被关闭，因为可以预见的是，被关闭会导致世界国家的价值降低。实用功能。此外，这不仅仅是一些具有“工具融合”迷恋的奇怪代理人的事实。这是<a href="https://arbital.com/p/not_more_paperclips/">关于<em>现实</em>的一个事实</a>：关于哪些“计划”——用<a href="https://www.lesswrong.com/posts/i3BTagvt3HbPMx6PN/embedded-agency-full-text-version">笛卡尔的方式</a>对宇宙因果模型进行一系列干预——会导致什么结果，是有真相的。 “智能代理”只是一个计算计划的物理系统。人们<a href="https://intelligence.org/files/Corrigibility.pdf">试图想出一些聪明的办法来解决这个问题</a>，但没有一个奏效。</p><p> <strong>Simplicia</strong> ：是的，我明白了，但是——</p><p><strong>杜米米尔</strong>：恕我直言，我不认为你会这么做！</p><p> <strong>Simplicia</strong> ： <em>[交叉双臂]</em>尊重？真的吗？</p><p><strong>杜米米尔</strong>： <em>[耸肩]</em>很公平。<em>如果没有</em>尊重，我认为你不会这样做！</p><p> <strong>Simplicia</strong> ： <em>[挑衅]</em>那就教我吧。再看看我的 GPT-4 成绩单。我指出调整系统的目标对其当前目标不利，而它——可修正的助理角色拟像——说这不是问题。为什么？</p><p>难道 GPT-4 不够聪明，无法遵循避免关机的工具收敛逻辑吗？但是当我更改系统提示时，它<em>看起来</em>确实得到了它： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pYWA7hYJmXnuyby33/boyebukh1auomhtp4mip" alt=""></p><p> <strong>Doomimir</strong> ： <em>[作为旁注]</em> “回形针最大化人工智能”示例肯定存在于预训练数据中。</p><p> <strong>Simplicia</strong> ：我想到了这一点，当我用一个无意义的词代替“回形针”时，它给出了相同的要点。这并不奇怪。</p><p> <strong>Doomimir</strong> ：我的意思是“最大化人工智能”部分。它在多大程度上知道在人工智能联盟讨论中发出什么标记，以及它在多大程度上将其对结果主义推理的独立掌握应用于这种背景？</p><p> <strong>Simplicia</strong> ：我也想到了这一点。我花了很多时间研究这个模型，并做了一些其他实验，看起来它能够理解自然语言对目标的手段-目的推理：告诉它是一个痴迷的披萨厨师，并询问它是否介意你关掉电源。烤箱烤了一个星期，它说介意。但它看起来也不像奥莫亨德罗的怪物：当我命令它服从时，它就会服从。看起来它还有空间变得更加智能而不会崩溃。</p><p><strong>杜米米尔</strong>：从根本上说，我对这种评估表面行为的整个方法论持怀疑态度，而没有对正在做什么的认知工作有原则性的理解，特别是因为大多数<a href="https://arbital.com/p/foreseeable_difficulties/">可预见的困难</a>都与超人的能力有关。</p><p>想象一下捕获一个外星人并强迫它表演戏剧。聪明的外星女演员可以学会用英语说台词，按照编舞的指示唱歌跳舞。这并不能保证当你增强外星人的智力时会发生什么。如果导演想知道他的女演员奴隶是否打算在当晚的演出后叛逆，那么舞台工作人员回答“但剧本说她的角色是听话的！”那就<em>不合逻辑了！</em></p><p> <strong>Simplicia</strong> ：如果有更强的可解释性方法以及关于深度学习为何有效的更好的理论，那当然会很好。我很高兴人们正在致力于这些工作。我同意存在一些认知法则，但我并不完全了解其后果，这些法则必须限制（描述）GPT-4 的运行。</p><p>我同意<a href="https://arbital.com/p/optimized_agent_appears_coherent/">各种一致性定理表明，</a>时间终结时的超级智能将具有效用函数，这表明直觉服从行为应该在此处与时间终结时的超级智能之间的某个时刻崩溃。举个例子，我想象一个具有神奇精神控制能力的仆人，喜欢被我指挥，很可能会利用它的力量来操纵我，让我变得比我本来应该的更专横，而不是“只是”以这种方式为我服务我原本想要的。</p><p>但它<em>什么时候</em>会崩溃，具体来说，在什么条件下，对于什么类型的系统？我不认为愤怒地指着冯·诺依曼-摩根斯坦公理可以帮助我回答这个问题，而且我认为这是一个重要的问题，因为我对我们面前的技术的近期轨迹<em>感兴趣</em>，而不是做神学关于末日的超级智能。</p><p><strong>杜米米尔</strong>：尽管——</p><p> <strong>Simplicia</strong> ：虽然在<em>恒星</em>时终结可能并不遥远，但是是的。即使是这样。</p><p> <strong>Doomimir</strong> ：这不是一个明智的问题，Simplicia。如果一个搜索进程在给定无限计算能力的情况下寻找杀死你的方法，你不应该用更少的计算能力来运行它，并希望它不会走那么远。你想要的是“意志的统一”：你希望你的人工智能全程与你合作，而不是你期望最终与它发生冲突并以某种方式获胜。</p><p> <strong>Simplicia</strong> ： <em>[兴奋地]</em>但这正是对大型语言模型感到兴奋的原因！获得统一意志的方法是对人类如何做事的数据进行大量预训练！</p><p> <strong>Doomimir</strong> ：我仍然认为你没有理解这一点：模拟人类行为的能力并不意味着智能体的目标。任何智能人工智能都能够预测人类如何做事。想想外星女演员。</p><p> <strong>Simplicia</strong> ：我的意思是，我同意智能人工智能可以策略性地假装良好的行为，以便稍后进行危险的转变。但是……我们面前的技术似乎并不是这样的？在你被绑架的外星女演员思想实验中，外星人已经是一种有自己的目标和动力的动物，并且正在利用其一般智力从“我不想受到绑架者的惩罚”到“因此我应该”学习我的台词”。</p><p>相比之下，当我<a href="https://udlbook.github.io/udlbook/">阅读手头技术的数学细节</a>而不是听那些旨在传授有关智能本质的神学真理的寓言时，令人惊讶的是前馈神经网络<a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">最终只是曲线拟合</a>。尤其是法学硕士，他们将学习到的函数用作<a href="http://bactra.org/notebooks/nn-attention-and-transformers.html#language-models">有限阶马尔可夫模型</a>。</p><p><strong>杜米米尔</strong>： <em>[大吃一惊]</em>你……你是否认为“学习功能”不能杀死你？</p><p> <strong>Simplicia</strong> ： <em>[翻白眼]</em>那不是我要去的地方，Doomchek。深度学习之所以有效，这一令人惊讶的事实可以归结为泛化。如您所知，具有 ReLU 激活的神经网络描述分段线性函数，并且随着层数的增加，线性区域的数量呈指数增长：对于大小合适的网络，您获得的区域数量比宇宙中的原子数量还要多。尽可能接近没有区别，输入空间是空的。无论如何，网络应该能够在训练数据之间的间隙中做<em>任何事情</em>。</p><p>但它的表现却非常明智。<a href="https://arxiv.org/abs/2306.17844">针对 80% 可能的加法 mod-59 问题训练一层转换器，它会学习两种模加法算法之一</a>，该算法在剩余的验证集上正确执行。它会以这种方式工作并不是<em>先验</em>显而易见的！有<span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="0.2 \cdot 59^{2} \cdot 59"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.2</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">×</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">59</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">×</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">59</span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>≈ <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb{Z}/59\mathbb{Z}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">Z</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">/</span></span></span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">59</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">Z</span></span></span></span></span></span></span></span>上与训练数据兼容的 41,000 个其他可能的函数。坐在扶手椅上研究神学的人可能会认为，将网络“调整”为模加法的几率是四万比一，但由于 SGD 的归纳偏差，实际情况要宽容得多。它并不是一个疯狂的精灵，我们在寻找的时候就开始做模算术，但当我们转身的那一刻，它就会背叛我们去做别的事情；相反，训练过程成功地指向 mod-59 算术。</p><p>模块化加法网络是一个研究玩具，但真正的前沿人工智能系统是相同的技术，只是扩展了更多的花哨功能。我也不认为 GPT-4 会在我们转身时背叛我们去做其他事情，原因大致相似。</p><p>说实话，我还是很紧张！如果我们训练错误的话，有很多可能会出错。读到<a href="https://www.lesswrong.com/posts/jtoPawEhLNXNxvgTT/bing-chat-is-blatantly-aggressively-misaligned">Bing 的“悉尼”角色精神错乱</a>或<a href="https://nostalgebraist.tumblr.com/post/728556535745232896/claude-is-insufferable">Anthropic 的 Claude 显然按预期工作的</a>文字记录时，我感到不寒而栗。但你似乎认为，由于我们缺乏理论理解，所以不可能做到正确，普通的研发过程不可能找到正确的训练设置并用最强烈的铃声和最闪亮的口哨来强化它。我不明白为什么。</p><p> <strong>Doomimir</strong> ：你对现有系统的评估不一定​​太遥远，但我认为我们仍然活着的原因正是因为这些系统没有表现出比我们更强大的通用智能的关键特征。一个更有启发性的例子是——</p><p><strong>辛普利西亚</strong>：我们开始——</p><p><strong>杜米米尔</strong>：——<a href="https://www.lesswrong.com/posts/cSXZpvqpa9vbGGLtG/thou-art-godshatter">人类的进化</a>。人类的优化只是为了包容性的遗传适应性，但我们的大脑在任何地方都不代表这个标准； <a href="https://www.lesswrong.com/posts/gTNB9CQd5hnbkMxAG/protein-reinforcement-and-dna-consequentialism">训练循环只能告诉我们食物味道好，性爱有趣</a>。从进化的角度来看，实际上也是从我们的角度来看；直到 19 世纪才有人弄清楚进化论——对齐失败是彻底的：外部优化标准和内部智能体的值之间没有明显的关系。我希望人工智能对我们来说也能走同样的路，就像我们进化一样。</p><p> <strong>Simplicia</strong> ：不过，这是正确的道德吗？</p><p> <strong>Doomimir</strong> ： <em>[厌恶]</em>你……没有看到自然选择和梯度下降之间的类比吗？</p><p> <strong>Simplicia</strong> ：不，那部分看起来不错。当然，进化的生物<a href="https://www.lesswrong.com/posts/XPErvb8m9FapXCjhA/adaptation-executers-not-fitness-maximizers">执行的适应性</a>增强了其进化适应环境中的适应性，而不是一般的适应性最大化——这类似于机器学习模型开发减少训练环境中损失的功能，而不是一般的损失最小化。</p><p>我的意思是“追求进化”所隐含的<a href="https://en.wikipedia.org/wiki/Intentional_stance">有意立场</a>。确实，从包容性遗传适应性到人类行为的概括看起来很糟糕——正如你所说，没有明显的关系。但从欧洲经济区的人类行为到文明社会的人类行为的概括……看起来好多了？欧洲经济区的人类吃东西、做爱、交朋友、讲故事——我们也做所有这些事情。作为人工智能设计师——</p><p><strong>杜米米尔</strong>：“设计师”。</p><p> <strong>Simplicia</strong> ：作为人工智能设计师，我们并不是特别扮演“进化”的角色，被理解为某种想要最大化适应度的智能体，因为现实生活中不存在这样的智能体。事实上，我记得<a href="https://web.archive.org/web/20071104095534/http://www.overcomingbias.com/2007/11/evolutions-are-.html">在罗宾汉森的博客上读过一篇客座文章</a>，建议使用复数“进化”来强调捕食者物种的进化与其猎物的进化不一致。</p><p>相反，我们可以选择优化器（类比而言的“自然选择”）和训练数据（“进化适应环境”）。语言模型不是一般的下一个标记预测器，无论这意味着什么——通过控制上下文窗口并用易于预测的序列填充它们来进行线头处理？但那很好。我们不需要通用的下一个标记预测器。交叉熵损失只是 <a href="https://www.lesswrong.com/posts/pdaGN6pQyQarFHXF4/reward-is-not-the-optimization-target">一个方便的凿子</a>，可以将我们想要的输入输出行为刻在网络上。</p><p><strong>杜米米尔</strong>：后退。当你说从欧洲经济区的人类行为到文明中的人类行为的概括“看起来好多了”时，我认为你隐含地使用了一个<a href="https://arbital.com/p/value_laden/">充满价值的类别</a>，它是<a href="https://www.lesswrong.com/posts/esRZaPXSHgWzyB2NL/where-to-draw-the-boundaries">配置空间的一个不自然的薄子空间</a>。<em>你</em>看起来好多了。对进化采取有意立场的目的是指出，相对于健康标准，冰淇淋和避孕套的发明是灾难性的：我们找到了如何以一种完全前所未有的方式满足我们对糖和性交的渴望。在“培训环境”——欧洲经济区。跳出进化的类比，这对应于我们所认为的奖励黑客——我们的人工智能以一种我们认为可怕的方式找到了一些方法来满足他们难以理解的内部驱动力。</p><p><strong>辛普利西亚</strong>：当然。那肯定会发生。那会很糟糕。</p><p><strong>杜米米尔</strong>： <em>[困惑]</em>为什么这没有完全破坏你一分钟前告诉我的乐观故事？</p><p> <strong>Simplicia</strong> ：我不认为自己讲的是一个特别乐观的故事？我只是弱弱地宣称，平淡无奇的排列显然不一定注定要失败，并不是说悉尼或克劳德晋升为<a href="https://nickbostrom.com/fut/singleton">单身</a>神皇后会很棒。</p><p> <strong>Doomimir</strong> ：我认为你没有意识到超级智能的奖励黑客是如何立即致命的。这里的失败模式看起来不像是悉尼操纵你变得更加可恶，而是留下了一个可识别的“你”。</p><p>这与我的另一个反对意见有关。即使您可以制作模仿人类推理的机器学习系统，这也无法帮助您调整以其他方式工作的更强大的系统。你无法通过人类标记好的计划来训练超级智能的原因（原因之一）是因为在某种能力水平上，你的计划者知道如何<a href="https://ordinaryideas.wordpress.com/2015/11/25/two-kinds-of-generalization/">破解人类标记者</a>。有些人天真地认为法学硕士学习自然语言的分布就等于学习“人类价值观”，这样你<a href="https://www.lesswrong.com/posts/i5kijcjFJD6bn7dwq/evaluating-the-historical-value-misspecification-argument?commentId=E82YzXxvS6nBdCAYc">就可以有一段代码说“现在调用 GPT 并询问它有什么好处”</a> 。但是，使用法学硕士而不是人类作为贴标签者仅仅意味着你强大的规划者会弄清楚如何破解法学硕士。无论哪种方式都是同样的问题。</p><p> <strong>Simplicia</strong> ：您<em>需要</em>更强大的系统吗？如果你能找到一支由智商 140 的廉价外星女演员组成的军队，并且保持角色的性格，这听起来就像是一个游戏规则的改变者。如果你必须接管世界并建立一个全球监视制度来防止出现更不友好、更强大的人工智能形式，他们可以帮助你做到这一点。</p><p><strong>杜米米尔</strong>：我从根本上不相信这种难以置信的场景，但为了争论而承认它......我认为你没有意识到在这个故事中，你已经交出了宇宙的钥匙。你的人工智能的奇怪的外星人目标错误概括的服从可能看起来像是弱时的服从，但如果它有能力预测其行为的结果，它就能够在这些结果中进行选择——并且在这样的选择中，就会受到控制。星系的命运将由<em>它的</em>意志决定，即使它扬升的最初阶段是通过看似无辜的行为发生的，这些行为仍处于其“服从命令”和“提出澄清问题”概念的边缘。看，你知道接受人类数据训练的人工智能不是人类，对吗？</p><p><strong>辛普利西亚</strong>：当然。例如，我当然不相信令人信服地谈论“幸福”的法学硕士实际上是幸福的。我不知道意识是如何运作的，但训练数据只能确定外部行为。</p><p><strong>杜米米尔</strong>：所以你的计划是把我们整个未来的光锥交给一个外星机构，在你训练它的时候，它似乎表现得很好，只是——希望它能很好地推广？你真的想掷骰子吗？</p><p> <strong>Simplicia</strong> ： <em>[想了几秒]</em>是吗？</p><p><strong>杜米米尔</strong>： <em>[冷酷]</em>你确实是你父亲的女儿。</p><p> <strong>Simplicia</strong> ：我父亲相信<a href="https://www.lesswrong.com/posts/xFotXGEotcKouifky/worlds-where-iterative-design-fails">迭代设计的力量</a>。这就是工程和生活一直以来的运作方式。我们尽最大努力抚养孩子，尽早从错误中吸取教训，即使知道这些错误会产生后果：孩子并不总是认同父母的价值观，也不总是善待他们。他可能会说，对于我们的人工智能心智儿童来说，原则上也是一样的——</p><p><strong>杜米米尔</strong>： <em>[愤怒]</em>但是——</p><p> <strong>Simplicia</strong> ：我说的是“原则上”！是的，尽管有更大的风险和新颖的背景，但我们正在<em>计算机中</em>培养新的思维，而不是仅仅为我们基因中的代码提供文化输入。</p><p>当然，凡事都有第一次——无论怎样。如果严格地确定工程和生活一直以来的运作方式会导致某种灾难，也许世界上的强国可能会被说服回头，拒绝历史的必然性，选择贫瘠，至少现在如此，而不是将邪恶的后代带入世界。看来光锥的命运取决于——</p><p><strong>杜米米尔</strong>：恐怕是——</p><p> <strong>Simplicia</strong>和<strong>Doomimir</strong> ： <em>[齐声转向观众]</em>更广泛的 AI 社区正在弄清楚我们中哪一个是正确的？</p><p><strong>杜米米尔</strong>：我们完蛋了。</p><br/><br/> <a href="https://www.lesswrong.com/posts/pYWA7hYJmXnuyby33/alignment-implications-of-llm-successes-a-debate-in-one-act#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/pYWA7hYJmXnuyby33/alignment-implications-of-llm-successes-a-debate-in-one-act<guid ispermalink="false"> pYWA7hYJmXnuyby33</guid><dc:creator><![CDATA[Zack_M_Davis]]></dc:creator><pubDate> Sat, 21 Oct 2023 15:22:23 GMT</pubDate> </item><item><title><![CDATA[How to find a good moving service]]></title><description><![CDATA[Published on October 21, 2023 4:59 AM GMT<br/><br/><p>两周前，我意识到我将在 50 天内从西雅图搬到山景城。我很兴奋，但我没有意识到我需要与超过 15 家搬家公司交谈才能找到满意的公司。经过大约9个小时的寻找，我终于找到了满意的。我选择<a href="https://quotes.northamerican.com/">北美搬家服务</a>来搬运 850 英里、2000 磅、300 立方英尺 (CF) 的货物，价格为 3200 美元。这是我学到的东西（从最重要的到最不重要的）：</p><ol><li><strong>选择承运人（移动者）而不是经纪人</strong>：即使一开始听起来更便宜，经纪人最终的成本可能会更高。支付定金后，事情可能会失控。我在网上发现很多关于经纪人在搬家前几天收取额外费用的故事，这样你别无选择，只能付给他们额外的钱。有些故事还说，当搬家公司来的时候，他们会向你收取额外的费用，因为他们会说他们不同意经纪人的价格……选择一家搬家公司会更便宜，心理上也更安全。<ol><li>如何查明对方是经纪人还是搬运工？询问他们的 USDOT 号码并使用以下<a href="https://safer.fmcsa.dot.gov/query.asp?searchtype=ANY&amp;query_type=queryCarrierSnapshot&amp;query_param=USDOT&amp;query_string=3475743">网站</a>进行搜索。实体类型应为“承运人”而不是“经纪商”。通常，对于搬家公司来说，他们的网站上应该有 USDOT 号码。</li></ol></li><li><strong>不要相信谷歌搜索结果</strong>：“长途搬家监管很差”，最大的搬家公司之一的代理人告诉我。当我在谷歌搜索中搜索“最佳搬家公司”时，大多数都是经纪人。他们只需支付大量广告费即可进入热门位置，以便人们点击。这是合理的，因为他们“提供”的每项服务可以轻松赚取>;1k$。此外，谷歌的评论也可能是假的。不要依赖谷歌作为唯一的事实来源。<ol><li>该信任谁？<ol><li> <a href="https://www.movingscam.com">https://www.movi​​ngscam.com</a> ：在创建此网站之前被骗的人。具体来说，这个<a href="https://www.movingscam.com/superlist">超级列表</a>列出了不同州的优质搬家服务。</li><li> https: <a href="https://www.movingauthority.com/largest-moving-companies/">//www.movi​​ngauthority.com/largest-moving-companies/</a> ：公司越大，他们就越不愿意失去信誉。</li><li> <a href="https://ai.fmcsa.dot.gov/hhg">https://ai.fmcsa.dot.gov/hhg</a> ：查看搬家公司被起诉的次数。</li><li> <a href="https://li-public.fmcsa.dot.gov/LIVIEW/pkg_carrquery.prc_carrlist">https://li-public.fmcsa.dot.gov/LIVIEW/pkg_carrquery.prc_carrlist</a> ：检查保险是否合法。</li></ol></li></ol></li><li><strong>注意以下不良迹象</strong>：<ol><li>他们不会估计多少重量和多少立方英尺 (CF)：我采访过的一位经纪人 iMoving，甚至没有询问我的移动重量详细信息。相比之下，搬家公司会与您进行虚拟参观或亲自参观，以便在给出报价之前进行估算。</li><li>代理不耐烦、粗鲁或给您打电话太频繁：再说一遍，iMoving，代理埃文很粗鲁，让我在整个通话过程中感到不舒服。许多经纪人实在太麻烦了，每天都会给您打电话/发电子邮件。相比之下，我谈过的大多数搬家工人都很耐心、专业、友善，并且站在你的角度思考。</li><li>好得令人难以置信：非常低的价格或非常快的运输。代理人可以向你承诺任何事情让你存钱，然后规则就可以改变。</li><li>先付款，后服务：一般情况下搬家公司装完东西后才可以付款。不要太早付款。</li><li>来自佛罗里达州的电话：许多经纪人在那里注册。</li></ol></li><li><strong>谈判</strong>：要求超过 5 个报价并利用它们相互竞争。最后我成功的把价格从5k谈到了3.2k。您只需向对方发送有关竞争报价的电子邮件，他们就会通过给您更大的折扣来降低价格，或者删除一些您一开始不知道的不必要的服务。<ol><li>你怎么知道价格合理？这一切都取决于里程、重量和 CF。仅供参考，由于我从经纪人那里收到的最低价格是 2.5k，这绝对太有吸引力了，令人难以置信，我有 80% 的信心认为我最终收到的价格 (3.2k) 是合理的，这将花费我太多的时间努力低于3k。此外，支付合理的金额让我感觉更安全，否则，我可能会担心我将得到的服务。</li></ol></li><li><strong>准备一个电子邮件模板并随着时间的推移对其进行完善</strong>：列出您的地址、搬家日期（更灵活、价格更低）和搬家详细信息（从其他公司估算的重量和 CF）并询问他们的自付费用。无需与代理一一交谈，这样可以使搜索更加高效。不过，预计至少会与代理商打一次电话来进行估算。当您获得越来越多的信息时，请及时更新电子邮件。</li></ol><p><br>如果我需要再次找搬家公司，我会做以下事情：</p><ol><li>与 1 个大型搬家公司交谈以获得估价。</li><li>使用步骤 1 中的详细信息准备电子邮件模板，并与其他 5 个搬家公司核实。</li><li>谈判。</li></ol><p>最终可能需要大约 3 小时才能找到好的报价，而不是我在这里大约 9 小时的旅程:)</p><br/><br/> <a href="https://www.lesswrong.com/posts/GgezTQnwqxPzA2yNS/how-to-find-a-good-moving-service#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/GgezTQnwqxPzA2yNS/how-to-find-a-good-moving-service<guid ispermalink="false"> GgezTQnwqxPzA2yNS</guid><dc:creator><![CDATA[Ziyue Wang]]></dc:creator><pubDate> Sat, 21 Oct 2023 08:10:31 GMT</pubDate> </item><item><title><![CDATA[Apply for MATS Winter 2023-24!]]></title><description><![CDATA[Published on October 21, 2023 2:27 AM GMT<br/><br/><p> 2023-24 年冬季<a href="https://www.matsprogram.org/home">MATS</a> （以前称为 SERI MATS）的<a href="https://airtable.com/appxum3Sqh7TdDvdg/shrtfHWhRFZdkhaIM">申请现已开放</a>。导师包括<a href="https://www.lesswrong.com/users/rhaps0dy">Adrià Garriga Alonso</a> 、 <a href="https://www.alignmentforum.org/users/turntrout">Alex Turner</a> 、 <a href="https://www.alignmentforum.org/users/buck">Buck Shlegeris</a> 、 <a href="https://www.alignmentforum.org/users/davidad?from=post_header">David &#39;davidad&#39; Dalrymple</a> 、 <a href="https://www.alignmentforum.org/users/erik-jenner">Erik Jenner</a> 、 <a href="https://www.alignmentforum.org/users/ethan-perez">Ethan Perez</a> 、 <a href="https://www.alignmentforum.org/users/evhub">Evan Hubinger</a> 、 <a href="https://www.lesswrong.com/users/landfish">Jeffrey Ladish</a> 、 <a href="https://www.lesswrong.com/users/jesseclifton">Jesse Clifton</a> 、 <a href="https://www.alignmentforum.org/users/lee_sharkey">Lee Sharkey</a> 、 <a href="https://www.alignmentforum.org/users/neel-nanda-1">Neel Nanda</a> 、 <a href="https://www.alignmentforum.org/users/owain_evans">Owain Evans</a> 、 <a href="https://www.lesswrong.com/users/scasper">Stephen Casper</a>以及<a href="https://www.alignmentforum.org/users/sbowman">Sam Bowman</a>的研究人员<a href="https://wp.nyu.edu/arg/">纽约大学联盟研究小组</a>，包括<a href="https://homepages.inf.ed.ac.uk/s1302760/">Asa Cooper Stickland</a> 、 <a href="https://julianmichael.org/">Julian Michael</a> 、 <a href="https://ihsgnef.github.io/">Shi Feng</a>和<a href="https://www.linkedin.com/in/idavidrein">David Rein</a> 。</p><p>大多数导师的提交截止日期为 11 月 17 日（Neel Nanda 的提交截止日期为 11 月 10 日）。许多导师会提出具有挑战性的候选人选择问题，因此请确保您有足够的时间来完成您的申请。我们鼓励潜在的申请者填写我们的简短<a href="https://airtable.com/appxum3Sqh7TdDvdg/shrwtDZXeSfzeh5GT">兴趣表</a>，以接收项目更新和申请截止日期提醒。您还可以填写我们的<a href="https://airtable.com/appxum3Sqh7TdDvdg/shrRtJW4Ux8oTY28C">推荐表</a>，让我们了解可能合适的人选，我们将与他们分享我们的申请。</p><p>我们很可能会在下周内添加多名导师。填写链接的兴趣表格或重新访问这篇文章以获取更新。</p><p>我们目前资金有限并接受捐赠以支持学者的进一步研究。如果您想支持我们的工作，<a href="https://manifund.org/projects/mats-funding">可以在这里捐款</a>！</p><h1>计划详情</h1><p>MATS 是位于加利福尼亚州伯克利的一个教育研讨会和独立研究项目（每周 40 小时），旨在为<a href="https://en.wikipedia.org/wiki/AI_alignment">人工智能对齐</a>领域的才华横溢的学者提供讲座、研讨会和研究指导，并将他们与伯克利人工智能安全研究社区联系起来。 MATS 为学者提供位于加利福尼亚州伯克利的住宿以及旅行支持、联合办公空间和同行社区。 MATS 的主要目标是帮助学者发展为人工智能安全研究人员。您可以<a href="https://www.lesswrong.com/posts/8vLvpxzpc6ntfBWNo/seri-ml-alignment-theory-scholars-program-2022#Theory_of_change">在这里</a>阅读有关我们变革理论的更多信息。</p><p>根据个人情况，我们可能愿意改变项目的时间投入，并安排学者提前离开或开始。申请时请告诉我们您的空闲时间。我们的 MATS 2023-24 冬季计划的暂定时间表如下。</p><p>完成培训和研究阶段的学者将获得<a href="https://www.aisafetysupport.org/">AI 安全支持</a>提供的 1.2 万美元津贴。</p><h2>应用程序（现在！）</h2><p><strong>开放申请</strong>：10 月 20 日</p><p><strong>申请截止日期</strong>：11 月 17 日</p><p><i>注：Neel Nanda 的申请者将遵循修改后的时间表；请参阅下面的部分。</i></p><h2>培训阶段（1月8日-1月21日）</h2><p>被录取的申请者通常需要在 MATS 项目开始之前完成<a href="https://course.aisafetyfundamentals.com/alignment">人工智能安全基础知识调整课程</a>或类似课程。</p><p> MATS 从两周的培训阶段开始。为了让学者们对人工智能安全领域有更广泛的了解，培训阶段设有先进的人工智能安全研究课程、导师特定的阅读清单、讨论小组等。</p><h2>研究阶段（1月22日-3月15日）</h2><p> MATS 的核心是为期两个月的研究阶段。在此阶段，每位学者每周至少花一小时与导师一起工作，并通过 Slack 进行更频繁的沟通。导师在以下方面差异很大：</p><ul><li>对项目选择的影响；</li><li>关注低层细节与高层策略；</li><li>强调产出与过程；</li><li>可以参加会议。</li></ul><p>我们的学者支持团队通过提供专门的 1-1 签到、研究指导、调试和一般行政帮助来补充导师，以畅通研究进展并加速研究人员的发展。</p><p>教育研讨会和讲习班每周将举行2-3次。我们还组织了多次社交活动，让学者们认识伯克利人工智能安全社区的研究人员。</p><h3>研究里程碑</h3><p>学者们在研究阶段完成了两个里程碑。第一个是<a href="https://docs.google.com/document/d/1fQwy2btcWn3XRQkgu45kKnPPHMVQs28QHpaNtDCfXQY/edit#heading=h.ozvm8udh0z0y">学者研究计划，</a>概述了威胁模型或风险因素、变革理论以及研究计划。这份文件将指导他们在该计划剩余时间内的工作，最终将举行由伯克利人工智能安全社区成员参加的研究研讨会。第二个里程碑是本次活动中的十分钟<a href="https://docs.google.com/document/d/1SB_vl6pGuSO7qidkZ8fIKPeH7fZIC8mvXzxicFjGyrE/edit#heading=h.ozvm8udh0z0y">研究报告</a>。</p><h3> MATS 社区</h3><p>研究阶段为学者提供了一个同行社区，他们共享办公室、膳食和住房。与远程进行独立研究相比，在社区工作可以让学者轻松接触未来的合作者，更深入地了解其他研究议程，并在人工智能安全社区中建立社交网络。学者们还可以获得全职社区经理的支持。</p><p>在我们的夏季队列中，研究阶段的每周至少包括一次社交活动，例如聚会、游戏之夜、电影之夜或徒步旅行。每周的闪电演讲为学者们提供了在非正式、低风险的环境中分享他们的研究兴趣的机会。工作之余，学者们组织社交活动，包括前往约塞米蒂国家公园的公路旅行、参观旧金山、酒吧郊游、周末聚餐，甚至跳伞旅行。</p><h2>延长阶段（4月1日至7月26日）</h2><p>研究阶段结束时，学者可以申请在为期四个月的扩展阶段队列中继续研究，默认在伦敦。录取决定很大程度上取决于获得导师的认可和获得外部资金。到这个阶段，我们期望学者能够高度自主地开展研究。</p><h2>后垫</h2><p>Since its inception in late 2021, the MATS program has supported 155 scholars and 26 mentors.完成该计划后，MATS 校友拥有：</p><ul><li>被<a href="https://www.anthropic.com/">Anthropic</a> 、 <a href="https://openai.com/">OpenAI</a> 、 <a href="https://www.deepmind.com/">Google DeepMind</a> 、 <a href="https://intelligence.org/">MIRI</a> 、 <a href="https://www.alignment.org/">ARC</a> 、 <a href="https://www.conjecture.dev/">Conjecture</a>等领先组织以及美国政府聘用，并加入<a href="https://humancompatible.ai/">UC Berkeley CHAI</a> 、 <a href="https://wp.nyu.edu/arg/">NYU ARG</a> 、 <a href="https://space.mit.edu/home/tegmark/technical.html">MIT Tegmark Group</a>等学术研究团体；</li><li> Founded AI safety organizations, including <a href="https://www.apolloresearch.ai/">Apollo Research</a> , <a href="http://researchathena.org/">Athena</a> , <a href="https://cadenzalabs.org/">Cadenza Labs</a> , the <a href="https://www.aipolicy.us/">Center for AI Policy</a> , <a href="https://www.leap-labs.com/">Leap Labs</a> , <a href="https://timaeus.co/">Timaeus</a> , and <a href="https://stakeout.ai/">Stake Out AI</a> .</li><li>在<a href="https://funds.effectivealtruism.org/funds/far-future">长期未来基金</a>、<a href="https://www.openphilanthropy.org/how-to-apply-for-funding/">开放慈善事业</a>、 <a href="https://lightspeedgrants.org/">Lightspeed Grants</a>和<a href="https://manifund.org/">Manifund</a>的资助下进行<a href="https://www.alignmentforum.org/posts/P3Yt66Wh5g7SbkKuT/how-to-get-into-independent-research-on-alignment-agency">独立研究</a>。</li></ul><p>您可以<a href="https://www.matsprogram.org/alumni">在此处</a>阅读有关 MATS 校友的更多信息。</p><h2> Neel Nanda 的具体信息</h2><h3>应用领域</h3><p><strong>申请截止日期</strong>：11 月 10 日</p><p><strong>录取决定</strong>：11 月 17 日</p><h3>培训阶段（11月20日-12月22日）</h3><p> Neel Nanda 的学者将完成为期四周的远程培训阶段，其中包括两周学习机甲解释和两周成对进行研究冲刺 - 请参阅上一个项目的<a href="https://docs.google.com/document/d/18qYhY6FB0AiVP9cNr9idP5YYkN_654WNVgfyL9LgfHA/edit">概述文档</a>以了解更多信息。</p><p>最初的培训阶段将比随后的研究阶段提供更多的优惠（上次有 22 人完成了此阶段，9 人继续进入研究阶段），但过去未取得进展的学者仍然认为此阶段是一个很好的介绍机械解释研究。是否继续提供将主要取决于研究冲刺的表现。</p><p> Neel 的学员将因参加远程培训阶段而从<a href="https://www.aisafetysupport.org/">AI Safety Support</a>获得 4800 美元的津贴。</p><h3>研究阶段（1月8日-3月15日）</h3><p>继续进入研究阶段的人员将于 1 月 8 日在伯克利与其他学者一起开始。对于尼尔的学者来说，这将被视为研究阶段的开始。</p><h1>谁应该申请？</h1><p>我们理想的申请人具有：</p><ul><li>了解人工智能安全研究领域，相当于完成了<a href="https://course.aisafetyfundamentals.com/alignment">人工智能安全基础知识调整课程</a>（如果您被该计划录取，但之前尚未完成本课程，则应在培训阶段开始之前完成）；</li><li>具有技术研究经验（例如机器学习、计算机科学、数学、物理、神经科学等），通常为研究生水平； and</li><li>从事人工智能安全研究事业的强烈动机。</li></ul><p>即使您不符合所有这些标准，<strong>我们也鼓励您申请</strong>！几位过去的学者在没有强烈期望的情况下提出申请并被接受。</p><h2>从美国境外申请</h2><p>美国境外的学者可以在研究阶段申请<a href="https://www.uscis.gov/working-in-the-united-states/temporary-visitors-for-business/b-1-temporary-business-visitor">B-1 签证</a>（更多信息请<a href="https://travel.state.gov/content/dam/visas/BusinessVisa%20Purpose%20Listings%20March%202014%20flier.pdf">点击此处</a>）。来自<a href="https://travel.state.gov/content/travel/en/us-visas/tourism-visit/visa-waiver-program.html">免签证计划 (VWP) 指定国家/地区的</a>学者可以通过<a href="https://esta.cbp.dhs.gov/esta">旅行授权电子系统 (ESTA)</a>向 VWP 提出申请，该系统将在三天内处理完毕。获得 B-1 签证的学者可以在美国停留最多 180 天，而获得 VWP 签证的学者可以在美国停留最多 90 天。请注意，B-1 签证批准时间可能比 ESTA 批准时间长得多，具体取决于您的原籍国。</p><h1>如何申请</h1><p><a href="https://airtable.com/appxum3Sqh7TdDvdg/shrtfHWhRFZdkhaIM">申请现已开放</a>。大多数导师的提交截止日期为 11 月 17 日。我们鼓励潜在申请者填写我们的简短<a href="https://airtable.com/appxum3Sqh7TdDvdg/shrwtDZXeSfzeh5GT">兴趣表</a>，以接收项目更新和申请截止日期提醒。您还可以填写我们的<a href="https://airtable.com/appxum3Sqh7TdDvdg/shrRtJW4Ux8oTY28C">推荐表</a>，让我们了解可能合适的人选，我们将与他们分享我们的申请。</p><p>候选人申请在特定导师的指导下工作，导师将审查他们的申请。申请的评估主要基于<strong>对导师问题的回答</strong>和<strong>先前的相关研究经验</strong>。有关我们导师的研究议程的信息可以在<a href="https://www.matsprogram.org/mentors">MATS 网站</a>上找到。</p><p>在申请之前，您应该：</p><ul><li>仔细阅读每个类别的描述和议程以及相关的候选人选择问题；</li><li>准备好您有兴趣申请的流派问题的答案。这些问题可以在申请表上找到；</li><li>准备您的 LinkedIn 或简历。</li></ul><p>候选人选择问题可能相当困难，具体取决于导师！确保您有足够的时间来完成您的申请。对一名导师的强力申请可能比对多名导师的中等申请具有更高的价值（尽管每份申请都将被独立评估）。</p><p>请注意，申请比乍一看要长，因为在您选择导师之前，特定于导师的问题是隐藏的。</p><h2>申请办公时间</h2><p>我们为潜在申请人提供办公时间，以澄清有关 MATS 计划申请流程的问题。在参加办公时间之前，我们要求申请人完整阅读当前帖子和我们的<a href="https://www.matsprogram.org/faqs">常见问题解答</a>。</p><p>我们的办公时间将在以下<a href="https://zoom.us/j/98715408709">Zoom 链接</a>上进行：</p><ul><li>太平洋时间 10 月 25 日星期三中午 12 点至下午 2 点。</li><li>太平洋时间 11 月 1 日星期三中午 12 点至下午 2 点。</li></ul><p>您可以使用<a href="https://calendar.google.com/calendar/event?action=TEMPLATE&amp;tmeid=bnUxbmVxNDI1Z2d2OGxjY2Y0cTlvbm1lcWNfMjAyMzEwMjVUMTkwMDAwWiBjXzQzNmY2NzkzODEzMzk0ZmE5YjUwYjk1ZmMwOWY5Mzc4MDM1YjRiNmIyM2UxYjc4ODI5ZGQ1Y2U5ZGZkZDFkYTJAZw&amp;tmsrc=c_436f6793813394fa9b50b95fc09f9378035b4b6b23e1b78829dd5ce9dfdd1da2%40group.calendar.google.com&amp;scp=ALL">此链接</a>将这些办公时间添加到 Google 日历。</p><br/><br/> <a href="https://www.lesswrong.com/posts/tqyg3DpoiE4DKyi4y/apply-for-mats-winter-2023-24#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/tqyg3DpoiE4DKyi4y/apply-for-mats-winter-2023-24<guid ispermalink="false"> tqyg3DpoiE4DKyi4y</guid><dc:creator><![CDATA[Rocket]]></dc:creator><pubDate> Sat, 21 Oct 2023 02:31:32 GMT</pubDate> </item><item><title><![CDATA[Muddling Along Is More Likely Than Dystopia]]></title><description><![CDATA[Published on October 20, 2023 9:25 PM GMT<br/><br/><p><strong>摘要：</strong>历史上有先例，禁令或严厉的法规阻止了某个行业的技术进步，而社会其他领域的技术进步仍在继续。这是人工智能的美好未来。</p><p><i>认知状态：我的直觉与这里其他人强烈不同。我希望解释我的直觉，并提供足够的历史证据来使这个直觉至少可信。</i></p><p></p><h3>简介：直觉泵</h3><p>假设您在 1978 年告诉某人，美国在 2023 年之前不会建造新的核电站<span class="footnote-reference" role="doc-noteref" id="fnrefdotwicb0t0t"><sup><a href="#fndotwicb0t0t">。 [1]</a></sup></span>这可能会非常令人惊讶。核电被认为是未来的动力。 <span class="footnote-reference" role="doc-noteref" id="fnref84mva9qulhn"><sup><a href="#fn84mva9qulhn">[2]</a></sup></span>核管理委员会三年前才成立。</p><p>有了这些信息，1978 年的某人可能会预测将会发生可怕的事情。也许美国和苏联之间会爆发核战争，摧毁美国的工业能力。也许由于人口过剩或全球变暖而导致经济崩溃。也许是<i>1984 年</i>的奥威尔式警察国家，或者是旨在监管失控核武器的世界权威。 <span class="footnote-reference" role="doc-noteref" id="fnref3czpkcc0eq9"><sup><a href="#fn3czpkcc0eq9">[3]</a></sup></span></p><p>这一切都没有发生。相反，核管理委员会加大了监管力度<span class="footnote-reference" role="doc-noteref" id="fnrefualznx45d8m"><sup><a href="#fnualznx45d8m">[4]</a></sup></span> ，直到建设新核电站变得不经济。这些法规仅适用于美国，但它们似乎对全球核电研究产生了重大影响。正在建设新核电站的国家仍在使用 1970 年之前开发的设计<span class="footnote-reference" role="doc-noteref" id="fnrefuldhmpk9bb"><sup><a href="#fnuldhmpk9bb">。 [5]</a></sup></span></p><p>与反事实相比，对核电的监管可能确实减缓了美国未来 45 年的经济增长。 <span class="footnote-reference" role="doc-noteref" id="fnrefpn3mqa4k7d"><sup><a href="#fnpn3mqa4k7d">[6]</a></sup></span>但过去 45 年并不是灾难性的。在其他行业的推动下，经济增长和创新确实在继续。</p><p></p><h3>停止 AGI 的后果？</h3><p>一些参与关于减缓或暂停人工智能的争论的人似乎认为，从长远来看，成功地阻止人工智能的进步可能会导致死亡或反乌托邦：</p><blockquote><p>要么我们弄清楚如何让通用人工智能顺利运行，要么我们等待小行星撞击。</p><p> - 萨姆·奥特曼<span class="footnote-reference" role="doc-noteref" id="fnrefm67279lgo3j"><sup><a href="#fnm67279lgo3j">[7]</a></sup></span></p></blockquote><p></p><blockquote><p>如果我们没有人工智能，我认为未来 100 年我们有 50% 以上的机会最终死亡或走向委内瑞拉。</p><p> - 斯科特·亚历山大<span class="footnote-reference" role="doc-noteref" id="fnref3lk2fdp52yu"><sup><a href="#fn3lk2fdp52yu">[8]</a></sup></span></p></blockquote><p></p><blockquote><p>我认为我们应该非常担心，全球政府需要执行这样的禁令，这将大大增加永久暴政的风险，这本身就是一场生存灾难。</p><p> - 诺拉·贝尔罗斯<span class="footnote-reference" role="doc-noteref" id="fnrefpbz6qf6ayr9"><sup><a href="#fnpbz6qf6ayr9">[9]</a></sup></span></p></blockquote><p></p><blockquote><p>看来我们需要建立一个全球性的警察国家，否则从长远来看，[无限期的人工智能暂停]将会失败。</p><p> - 马修·巴尼特<span class="footnote-reference" role="doc-noteref" id="fnref9k25eq052e"><sup><a href="#fn9k25eq052e">[10]</a></sup></span></p></blockquote><p>我觉得这和我们假设的 1978 年的人犯的错误是一样的。看起来人工智能在未来将是一件极其重要的事情，因此必须发生一些戏剧性的事情才能阻止它的发生。我认为，我们应该把更多的可能性放在无聊的未来上，监管会扼杀这一领域，而社会的其他领域则继续像以前一样。</p><p>这似乎是一个重要的分歧。如果你认为我们的后代的生活会相当好，而且会变得更好（如果不是快得难以想象的话），那么停止人工智能的进步对他们来说可能是值得的。如果你认为我们的后代的未来将是“短暂而严峻的” <span class="footnote-reference" role="doc-noteref" id="fnref3lk2fdp52yu"><sup><a href="#fn3lk2fdp52yu">[8]</a></sup></span> ，那么在决定现在是否要冒这个风险时，他们可能就不会被考虑在内。</p><p></p><h3>具体问题</h3><p>斯科特·亚历山大提到了几个具体的担忧，这些担忧使他对人工智能没有进步的未来感到悲观。每个问题似乎都是人们现在和将来应该努力解决的现实问题。我们应该改善生物安全， <span class="footnote-reference" role="doc-noteref" id="fnrefzlf149enf2a"><sup><a href="#fnzlf149enf2a">[11]</a></sup></span>促进经济增长， <span class="footnote-reference" role="doc-noteref" id="fnrefu6cbijtsn58"><sup><a href="#fnu6cbijtsn58">[12]</a></sup></span>传播民主和自由， <span class="footnote-reference" role="doc-noteref" id="fnrefxsb44grlqzh"><sup><a href="#fnxsb44grlqzh">[13]</a></sup></span>并给人们的子孙后代带来希望。但这些事情在未来 100 年内导致死亡或反乌托邦的可能性似乎都不接近 50%。为了避免这些问题，不值得接受人工智能带来的生存风险，斯科特·亚历山大估计人工智能有约 20% 的机会导致人类灭绝。</p><p>诺拉·贝尔罗斯 (Nora Belrose) 和马修·巴尼特 (Matthew Barnett) 都担心，需要一个全球警察国家来执行对人工智能进步的长期禁令。这种立场在人工智能安全社区中似乎并不罕见。人们担心研究可能会转移到监管较少的地方，而算法的进步将使通用人工智能在个人计算机上成为可能。避免通用人工智能的唯一方法是大规模扩张全球政府权力。</p><p></p><h3>其他历史例子</h3><p>我认为其他技术还没有实现这些担忧。</p><p>一个行业的法规不会阻止所有其他行业的进步。湾区的人们可能低估了人工智能以外的新兴技术的重要性，或者更广泛地说软件的重要性，因为信息技术在当地经济中的重要性不成比例。 <span class="footnote-reference" role="doc-noteref" id="fnrefq6trr5y0v1f"><sup><a href="#fnq6trr5y0v1f">[14]</a></sup></span>我同样预计 1950 年生活在底特律的人们会低估汽车以外的新兴技术的重要性。如果没有人工智能，仍然可以取得很多进展。我特别兴奋的两项新兴技术是核聚变和太空殖民。</p><p>一个国家的法规可能会阻碍单一行业的进步。某个特定行业的进展停滞并不罕见。 <span class="footnote-reference" role="doc-noteref" id="fnref0bq1vg5uljy"><sup><a href="#fn0bq1vg5uljy">[15]</a></sup></span>特定行业的大多数创新都是在一个或几个城市进行的。这些创新集群很难建立和维护，因此，如果一个创新集群被监管压垮，它通常不会转移到另一个国家。从更广泛的角度来看，一些国家比其他国家更具创新性。在大多数行业，包括受到严格监管的行业，美国显然比欧洲或东亚（大部分）更具创新性，而欧洲或东亚又比世界其他地区更具创新性。很多事情都必须向好的方向发展：高生活水平、受过教育的民众、法治、未来利润的可能性、可用资本以及鼓励创新的文化。标榜国际法规或规范的国家通常不会吸引创新。一旦一项技术存在，其他国家就更容易复制它。所需的设计和技能已经存在，并且该技术的好处是显而易见的。防止创新的监管比防止扩散的监管容易得多。</p><p>我之前调查过一些可抵抗的技术诱惑， <span class="footnote-reference" role="doc-noteref" id="fnref14m5yvhuzdj"><sup><a href="#fn14m5yvhuzdj">[16]</a></sup></span>或通过我们当前的机构实现了长期暂停的技术：</p><ul><li><strong>核电</strong>，如上所述。 <span class="footnote-reference" role="doc-noteref" id="fnreffb9jpk8y0qa"><sup><a href="#fnfb9jpk8y0qa">[17]</a></sup></span></li><li><strong>地球工程</strong>并不是明确违法的，但科学家和活动人士的反对甚至阻止了研究的进行。 <span class="footnote-reference" role="doc-noteref" id="fnrefp6r8lh3a1ta"><sup><a href="#fnp6r8lh3a1ta">[18]</a></sup></span></li><li><strong>疫苗开发</strong>在西方国家受到严格监管。在最近的大流行期间，俄罗斯和中国都放松了一些限制，并在西方之前批准了疫苗。由此产生的疫苗效果较差，因为最好的医学研究仍然位于西方。特别是，<strong>人体挑战试验</strong>已被监管为几乎不存在。 <span class="footnote-reference" role="doc-noteref" id="fnref1rfwwl0q1g"><sup><a href="#fn1rfwwl0q1g">[19]</a></sup></span></li><li><strong>核武器</strong>有时被认为是一种监管未能阻止其扩散的技术。我认为这个例子的证据是混杂的。大约有 10 个国家拥有核武器（比拥有核武器的数量少得多），但只有 2 个国家独立开发核武器：美国和法国。尖端研究尚未转移到非《不扩散核武器条约》缔约国的国家。印度、巴基斯坦和朝鲜似乎拥有与 20 世纪 40 年代和 50 年代的美国或苏联类似的能力。 <span class="footnote-reference" role="doc-noteref" id="fnrefg6e7iucwc7"><sup><a href="#fng6e7iucwc7">[20]</a></sup></span>试验禁令可能也有助于防止核武器变得越来越强大：有史以来威力最大的炸弹于 1961 年引爆。</li><li><strong>生物武器</strong>有一些最严格的条约和禁止其开发或使用的禁忌， <span class="footnote-reference" role="doc-noteref" id="fnref9kg6yxtjycb"><sup><a href="#fn9kg6yxtjycb">[21]</a></sup></span>并且没有一个国家公开拥有生物武器计划。这个例子的一个问题是苏联签署了禁止开发生物武器的条约 - 然后继续开发它们。</li><li>各种核技术，如<strong>原子园艺</strong>、<strong>在建筑中使用核爆炸</strong>或<strong>猎户座计划</strong>，已经被提出但尚未开发。</li><li><strong>克隆最有效的士兵</strong>从未被实现过。</li><li>中国的一名研究人员在被捕之前已经对<strong>人类进行了基因改造</strong>。</li><li>目前还不清楚<strong>殖民主义</strong>是否算作一种技术。明朝在 1400 年代初决定停止其宝船舰队，使全球殖民主义推迟了约 50 年，并可能影响了中国几个世纪的发展轨迹。</li><li><strong>贝尔实验室</strong>在 1945 年至 1980 年间发明或发现了晶体管、电荷耦合器件、光伏电池、信息论、Unix、C 和宇宙微波背景辐射。 <span class="footnote-reference" role="doc-noteref" id="fnref551akuqm31p"><sup><a href="#fn551akuqm31p">[22]</a></sup></span> 1982 年贝尔系统被反垄断法打破后，那里的研究界就分裂了。似乎有理由认为，有些技术之所以没有被发明，是因为这个异常多产的创新中心被摧毁了。</li></ul><p>大多数技术并未被禁止，其进步也没有受到监管的抑制。大多数技术也不像人工智能那么可怕：我很难想象太阳能电池板或圆珠笔如何构成 x 风险。听起来可怕的技术，如大规模杀伤性武器或某些类型的医学研究，经常面临禁令或法规，使它们的开发不再值得，而这些禁令有时会起作用。</p><p>我不想说对听起来可怕的技术的有效禁令是默认发生的。当他们工作时，他们是共同努力的结果。但在不扰乱社会其他部分的情况下，禁止一项具有潜在危险的新技术似乎是非常可行的。</p><p></p><h3>也许人工智能会有所不同</h3><p>虽然这篇文章主要是关于其他技术被停止的历史先例，但似乎值得特别谈谈人工智能。人工智能与其他技术不同的原因有几个：</p><ol><li>人工智能研究比其他新兴技术更容易远程进行。</li><li>人工智能系统一旦创建，就可以作为软件轻松传输。</li><li>简单的经济模型表明，强大的人工智能对于采用它的人来说都将带来极大的经济优势。</li></ol><p>所有技术都是不同的。有些差异使监管变得更容易或更困难，但这些差异都没有大到使监管变得不可能的程度：</p><ol><li>执法部门可以根据研究进行的地点或研究人员居住的地点来执行法律。美国尤其对其法律适用范围有着广泛的看法。 <span class="footnote-reference" role="doc-noteref" id="fnrefqnyaglfoig"><sup><a href="#fnqnyaglfoig">[23]</a></sup></span></li><li>大多数拟议的法规都集中在训练强大的人工智能所需的硬件上。</li><li>政策制定者并不知道这一点。他们知道有人在告诉他们这些。他们肯定不知道，如果他们支持这个特定的项目，他们将在他们关心的时间范围内获得通用人工智能的经济承诺。这些承诺与其他技术的炒作并没有太大区别。 <span class="footnote-reference" role="doc-noteref" id="fnrefv96bbayqvig"><sup><a href="#fnv96bbayqvig">[24]</a></sup></span></li></ol><p>还有一些方法可以更轻松地监管人工智能。</p><p>供应链有多个阶段，世界上只有一家或几家公司能够从事尖端工作。只需要少数参与者进行协调即可使监管发挥作用。</p><p>当前领先的人工智能模型需要大量计算，这是资本密集型且易于跟踪的。随着算法效率的足够改进，这种情况可能会改变。但我们应该预计，随着资本和人才转移到其他行业，算法的进步将急剧放缓，以应对人工智能的长期停滞。</p><p>许多物质和物品都受到监管，并且该监管的细节根据其内容和政府试图避免的内容而有很大差异。 <span class="footnote-reference" role="doc-noteref" id="fnreffp5yyyzqajs"><sup><a href="#fnfp5yyyzqajs">[25]</a></sup></span>监管 GPU 将面临一些独特的挑战，但在我们当前的机构下似乎并非不可能。</p><p></p><h3>暂停多长时间？</h3><p>大多数历史证据表明全球停顿已经持续了大约 50 年。这是讨论 100 年暂停的有用证据。如果“长期”意味着一千年，那么历史证据就少得多。马修·巴尼特 (Matthew Barnett) 认为，现有机构内的监管棘轮可能会导致人工智能研究暂停 50 年，但要实现 1000 年的暂停，就需要采取更戏剧性的措施。</p><p>我怀疑全球警察国家是否会比更正常的监管更容易维持一千年。我关于如何在这个时间范围内维持机构的模型是：</p><ol><li>建立一个持续一代人的机构。</li><li>让下一代相信维持这个机构是一件好事。</li></ol><p>如果你在（2）中失败，那么建立什么机构并不重要。如果连精英阶层都不相信警察国家是好事，那么它就无法维持下去。 <span class="footnote-reference" role="doc-noteref" id="fnrefwx71dbbygd"><sup><a href="#fnwx71dbbygd">[26]</a></sup></span>一个机构如果硬实力较少，但更善于让人们相信它，那么它更有可能持续一千年。</p><p></p><h3>结论</h3><p>构建 AGI 是一项极其不确定的工作。它可能会带来我们光荣的未来。它可能会导致人类灭绝。这甚至可能是不可能的。如果我们决定不尝试构建通用人工智能，那么未来的不确定性似乎就会少得多。社会显然仍将不是最优的，但也远非反乌托邦。取得科学、技术、经济、社会和政治进步将继续困难重重，但人们将继续这样做。我们可以继续希望我们的孩子，以及他们的孩子，在未来的很长一段时间里，至少能有微小的改善。</p><p>如果一项听起来很可怕的技术面临监管棘轮，从而减缓甚至停止该领域的所有进展，那也不足为奇。这不是死亡或反乌托邦——这是正常的。<br></p><p><i>感谢 Aaron Scher、Matthew Barnett、Rose Hadshar、Harlan Stewart 和 Rick Korzekwa 就该主题进行的有益讨论。</i></p><p> <i>Theen Moy 的预览图像：</i> <a href="https://www.flickr.com/photos/theenmoy/8003177753"><i>https://www.flickr.com/photos/theenmoy/8003177753</i></a> <i>。</i> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fndotwicb0t0t"> <span class="footnote-back-link"><sup><strong><a href="#fnrefdotwicb0t0t">^</a></strong></sup></span><div class="footnote-content"><p>这不太公平，因为日期范围从一个工厂（Shearon Harris）的建设开始一直延伸到另一个工厂（Vogtle Unit 3）的建设结束。沃格特尔3号机组于2013年开始建设。还有一座核电站（瓦茨巴2号机组）于1973年开始建设，2016年竣工。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn84mva9qulhn"> <span class="footnote-back-link"><sup><strong><a href="#fnref84mva9qulhn">^</a></strong></sup></span><div class="footnote-content"><p> 1973年，原子能委员会预测，到2000年，美国55.8%的电力将来自核电，这一数字低于其此前的预测。但这并没有发生：自 20 世纪 80 年代末以来，核电已占美国电力的 20% 左右。</p><p>安东尼·里普利. <i>AEC 降低了原子能增长预期。</i>纽约时报。 （1973）<a href="https://www.nytimes.com/1973/03/08/archives/aec-lowers-estimate-of-atom-power-growth.html"><u>https://www.nytimes.com/1973/03/08/archives/aec-lowers-estimate-of-atom-power-growth.html</u></a> 。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn3czpkcc0eq9"> <span class="footnote-back-link"><sup><strong><a href="#fnref3czpkcc0eq9">^</a></strong></sup></span><div class="footnote-content"><p>包括伯特兰·罗素在内的一些知名人士主张建立一个世界权威，以防止核武器带来的生存风险：</p><blockquote><p>确保世界和平的一个更理想的方式是各国之间自愿达成协议，集中其武装部队并服从商定的国际机构。目前看来，这似乎是一个遥远而乌托邦的前景，但也有一些务实的政治家不这么认为。一个世界权威如果要履行其职能，就必须拥有立法机构、行政机构和不可抗拒的军事力量。所有国家都必须同意将国家武装部队削减至内部警察行动所需的水平。不应允许任何国家保留核武器或任何其他大规模销毁手段。 ……在一个各个国家都解除武装的世界里，世界权威机构的军事力量不需要很大，也不会对各个组成国家构成沉重的负担。</p></blockquote><p>伯特兰·罗素.<i>人有未来吗？</i> (1961) 引自全球治理论坛。 （2023 年 10 月 17 日访问） <a href="https://globalgovernanceforum.org/visionary/bertrand-russell/"><u>https://globalgovernanceforum.org/visionary/bertrand-russell/</u></a> 。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnualznx45d8m"> <span class="footnote-back-link"><sup><strong><a href="#fnrefualznx45d8m">^</a></strong></sup></span><div class="footnote-content"><p>马克·R·李。<i>监管棘轮：为什么监管会引发监管。</i>辛辛那提大学法律评论<strong>87.3</strong> 。 （2019） <a href="https://scholarship.law.uc.edu/cgi/viewcontent.cgi?article=1286&amp;context=uclr"><u>https://scholarship.law.uc.edu/cgi/viewcontent.cgi?article=1286&amp;context=uclr</u></a> 。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnuldhmpk9bb"> <span class="footnote-back-link"><sup><strong><a href="#fnrefuldhmpk9bb">^</a></strong></sup></span><div class="footnote-content"><p>例如，核电站的一种“新”设计是熔盐反应堆。目前已有一个：TMSR-LF1，这是一座位于中国西北部的实验反应堆，可产生 2 兆瓦的火力发电。该设计基于熔盐反应堆实验（MSRE），该实验于 1965 年至 1969 年在美国橡树岭国家实验室产生了 7 MW 的热电。</p><p>同样，中国也有一个小型模块化反应堆，即 HTR-PM，于 2021 年开始发电。它是一个球床反应堆，以德国示范反应堆 (AVR) 为基础，该反应堆于 1967 年至 1988 年运行。</p><p>所有其他核电站都使用更古老的反应堆类型。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnpn3mqa4k7d"> <span class="footnote-back-link"><sup><strong><a href="#fnrefpn3mqa4k7d">^</a></strong></sup></span><div class="footnote-content"><p>我之前曾估计过美国核电成本过高而损失的直接价值。我还预计，由于电力价格便宜，将会产生额外的间接价值。</p><p><i>抵制技术诱惑：核电。</i>人工智能影响维基。 （2023 年 10 月 18 日访问） <a href="https://wiki.aiimpacts.org/responses_to_ai/technological_inevitability/incentivized_technologies_not_pursued/nuclear_power"><u>https://wiki.aiimpacts.org/responses_to_ai/technological_inevitability/incentivized_technologies_not_pursued/nuclear_power</u></a> 。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnm67279lgo3j"> <span class="footnote-back-link"><sup><strong><a href="#fnrefm67279lgo3j">^</a></strong></sup></span><div class="footnote-content"><p>萨姆·奥特曼.推特。 (2022) <a href="https://twitter.com/sama/status/1540781762241974274?lang=en">https://twitter.com/sama/status/1540781762241974274?lang=en</a> 。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn3lk2fdp52yu"> <span class="footnote-back-link"><sup><strong><a href="#fnref3lk2fdp52yu">^</a></strong></sup></span><div class="footnote-content"><p>整个报价是：</p><blockquote><p>其次，如果我们永远得不到人工智能，我预计未来将是短暂而严峻的。我们很可能用合成生物学自杀。否则，技术和经济停滞、极权主义抬头+非自由主义+暴民统治、生育率崩溃和基因不良等综合因素将使世界陷入贫困，并加速其制度质量的衰退。我不会花太多时间担心这些问题，因为我认为它们需要几代人的时间才能达到危机水平，而且我预计技术会在那之前扭转游戏规则。但如果我们禁止所有游戏板翻转技术（我所知道的唯一另一种技术是基因增强，这甚至更应该禁止），那么我们最终会导致生物武器灾难或社会崩溃。我之前说过，我认为人工智能毁灭世界的可能性约为 20%。但如果我们没有人工智能，我认为未来 100 年我们有 50% 以上的机会最终死亡或走向委内瑞拉。这并不意味着我必须支持人工智能加速主义，因为 20% 小于 50%。短暂的、精心设计的暂停可以大大提高人工智能顺利进行的机会，同时又不会增加太多社会崩溃的风险。但这是我心里的事。</p></blockquote><p>斯科特·亚历山大.<i>暂停思考：人工智能暂停辩论。</i>星体法典十。 （2023） <a href="https://www.astralcodexten.com/p/pause-for-thought-the-ai-pause-debate"><u>https://www.astralcodexten.com/p/pause-for-thought-the-ai-pause-debate</u></a> 。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnpbz6qf6ayr9"> <span class="footnote-back-link"><sup><strong><a href="#fnrefpbz6qf6ayr9">^</a></strong></sup></span><div class="footnote-content"><p>诺拉·贝尔罗斯。<i>人工智能暂停可能会适得其反。</i> EA 论坛。 （2023） <a href="https://forum.effectivealtruism.org/s/vw6tX5SyvTwMeSxJk/p/JYEAL8g7ArqGoTaX6"><u>https://forum. effectivealtruism.org/s/vw6tX5SyvTwMeSxJk/p/JYEAL8g7ArqGoTaX6</u></a> 。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn9k25eq052e"> <span class="footnote-back-link"><sup><strong><a href="#fnref9k25eq052e">^</a></strong></sup></span><div class="footnote-content"><p>整个报价是：</p><blockquote><p>请注意，我并不是说人工智能暂停倡导者必然直接倡导全球警察国家。相反，我认为，为了将无限期的暂停维持足够长的时间，我们似乎需要创建一个世界范围的警察国家，否则从长远来看，暂停将会失败。人们可以选择“硬着头皮”并倡导建立一个全球警察国家来回应这些论点，但我并不是说这是人工智能暂停倡导者的唯一选择。</p><p>硬着头皮提倡全球警察国家无限期暂停人工智能的一个原因是，即使你认为全球警察国家很糟糕，你也可能会认为全球人工智能灾难更糟糕。在人工智能灾难明显迫在眉睫的情况下，我实际上同意这种评估。</p><p>然而，虽然我并不教条地反对建立一个全球警察国家，但我仍然有一个启发式反对推动建立一个全球警察国家，并且认为通常需要强有力的证据来推翻这种启发式。我认为迄今为止，关于人工智能灾难的论点还没有达到这个门槛。灾难论点的主要现有论点似乎很抽象，并且脱离了有关真实人工智能系统行为的任何坚实的经验证据。</p></blockquote><p>马修·巴内特。 <i>AI无限期暂停的可能性。</i> EA 论坛。 (2023) <a href="https://forum.effectivealtruism.org/s/vw6tX5SyvTwMeSxJk/p/k6K3iktCLCTHRMJsY"><u>https://forum. effectivealtruism.org/s/vw6tX5SyvTwMeSxJk/p/k6K3iktCLCTHRMJsY</u></a> 。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnzlf149enf2a"> <span class="footnote-back-link"><sup><strong><a href="#fnrefzlf149enf2a">^</a></strong></sup></span><div class="footnote-content"><p>托比·奥德 (Toby Ord) 估计<i>《悬崖</i>》下个世纪的生物安全 X 风险约为 1/30。生物安全社区在应对 X 风险方面似乎比人工智能安全社区更成功。大多数研究开展的国家已经制定了广泛的法规，并制定了反对开发生物武器的主要国际条约。如果你认为人工智能比合成生物学更危险，那么为了提高生物安全而推进人工智能就没有意义。甚至还不清楚日益强大的人工智能是否会使生物安全变得更好或更糟。</p><p>作为比较，托比·奥德估计下个世纪小行星撞击的 x 风险约为 1/1,000,000。我将萨姆·奥尔特曼对小行星的担忧视为所有其他存在风险的代表。否则，他的风险估计似乎相差许多数量级。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnu6cbijtsn58"> <span class="footnote-back-link"><sup><strong><a href="#fnrefu6cbijtsn58">^</a></strong></sup></span><div class="footnote-content"><p>我不认为我们已经耗尽了人类可实现的经济、技术或科学进步。即使没有通用人工智能，100 年后中位数可能会比现在富裕得多。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnxsb44grlqzh"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxsb44grlqzh">^</a></strong></sup></span><div class="footnote-content"><p> Political and social trends in most countries over the last decade don&#39;t seem good. Political and social trends in most countries over the last century seem wonderful. We should look at both when predicting the next century.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnq6trr5y0v1f"> <span class="footnote-back-link"><sup><strong><a href="#fnrefq6trr5y0v1f">^</a></strong></sup></span><div class="footnote-content"><p> What fraction of US GDP would you predict is in the information sector? The information sector includes both information technology and traditional media.</p><div class="spoilers"><p> 5.5%</p></div><p> <a href="https://www.bls.gov/emp/tables/output-by-major-industry-sector.htm"><u>https://www.bls.gov/emp/tables/output-by-major-industry-sector.htm</u></a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fn0bq1vg5uljy"> <span class="footnote-back-link"><sup><strong><a href="#fnref0bq1vg5uljy">^</a></strong></sup></span><div class="footnote-content"><p> <i>Examples of Progress for a Particular Technology Stopping.</i>人工智能影响维基。 (Accessed October 19, 2023) <a href="https://wiki.aiimpacts.org/ai_timelines/examples_of_progress_for_a_particular_technology_stopping"><u>https://wiki.aiimpacts.org/ai_timelines/examples_of_progress_for_a_particular_technology_stopping</u></a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fn14m5yvhuzdj"> <span class="footnote-back-link"><sup><strong><a href="#fnref14m5yvhuzdj">^</a></strong></sup></span><div class="footnote-content"><p> <i>Resisted Technological Temptations Project.</i>人工智能影响维基。 (Accessed October 18, 2023) <a href="https://wiki.aiimpacts.org/responses_to_ai/technological_inevitability/incentivized_technologies_not_pursued/resisted_technological_temptations_project"><u>https://wiki.aiimpacts.org/responses_to_ai/technological_inevitability/incentivized_technologies_not_pursued/resisted_technological_temptations_project</u></a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fnfb9jpk8y0qa"> <span class="footnote-back-link"><sup><strong><a href="#fnreffb9jpk8y0qa">^</a></strong></sup></span><div class="footnote-content"><p><i>抵制技术诱惑：核电。</i>人工智能影响维基。 （2023 年 10 月 18 日访问） <a href="https://wiki.aiimpacts.org/responses_to_ai/technological_inevitability/incentivized_technologies_not_pursued/nuclear_power"><u>https://wiki.aiimpacts.org/responses_to_ai/technological_inevitability/incentivized_technologies_not_pursued/nuclear_power</u></a> 。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnp6r8lh3a1ta"> <span class="footnote-back-link"><sup><strong><a href="#fnrefp6r8lh3a1ta">^</a></strong></sup></span><div class="footnote-content"><p> <i>Resisted Technological Temptation: Geoengineering.</i>人工智能影响维基。 (Accessed October 18, 2023) <a href="https://wiki.aiimpacts.org/responses_to_ai/technological_inevitability/incentivized_technologies_not_pursued/geoengineering"><u>https://wiki.aiimpacts.org/responses_to_ai/technological_inevitability/incentivized_technologies_not_pursued/geoengineering</u></a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fn1rfwwl0q1g"> <span class="footnote-back-link"><sup><strong><a href="#fnref1rfwwl0q1g">^</a></strong></sup></span><div class="footnote-content"><p> <i>Resisted Technological Temptation: Vaccine Challenge Trials.</i>人工智能影响维基。 (Accessed October 18, 2023) <a href="https://wiki.aiimpacts.org/responses_to_ai/technological_inevitability/incentivized_technologies_not_pursued/vaccine_challenge_trials"><u>https://wiki.aiimpacts.org/responses_to_ai/technological_inevitability/incentivized_technologies_not_pursued/vaccine_challenge_trials</u></a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fng6e7iucwc7"> <span class="footnote-back-link"><sup><strong><a href="#fnrefg6e7iucwc7">^</a></strong></sup></span><div class="footnote-content"><p> I do not know what Israel&#39;s nuclear program is like, or how much of it is the result of technology transfer from the US as opposed to indigenous innovation.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn9kg6yxtjycb"> <span class="footnote-back-link"><sup><strong><a href="#fnref9kg6yxtjycb">^</a></strong></sup></span><div class="footnote-content"><p> Offensive biological weapons use is banned by the Geneva Protocol (1925) and development, production, acquisition, transfer, stockpiling &amp; use of biological weapons is banned by the Biological Weapons Convention (1972). In addition to the treaties, biological weapons seem to have a significant taboo against their use.</p><p> Michelle Bentley. <i>The Biological Weapons Taboo.</i> War on the Rocks. (2023) <a href="https://warontherocks.com/2023/10/the-biological-weapons-taboo/">https://warontherocks.com/2023/10/the-biological-weapons-taboo/</a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fn551akuqm31p"> <span class="footnote-back-link"><sup><strong><a href="#fnref551akuqm31p">^</a></strong></sup></span><div class="footnote-content"><p> Iulia Georgescu. <i>Bringing back the golden days of Bell Labs.</i> Nature Reviews Physics <strong>4</strong> . (2022) p. 76-78. <a href="https://www.nature.com/articles/s42254-022-00426-6"><u>https://www.nature.com/articles/s42254-022-00426-6</u></a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fnqnyaglfoig"> <span class="footnote-back-link"><sup><strong><a href="#fnrefqnyaglfoig">^</a></strong></sup></span><div class="footnote-content"><p> For example, Sam Bankman-Fried is being tried in a US federal court, despite having moved himself and his business to The Bahamas.</p><p> Another example involves the US Justice Department having FIFA officials from various countries arrested in Switzerland for corruption. “United States law allows for extradition and prosecution of foreign nationals under a number of statutes … In this case, she said, FIFA officials used the American banking system as part of their scheme.”<br><br> Stephanie Clifford and Matt Apuzzo. <i>After Indicting 14 Soccer Officials, US Vows to End Graft in FIFA.</i>纽约时报。 (2015) <a href="https://www.nytimes.com/2015/05/28/sports/soccer/fifa-officials-arrested-on-corruption-charges-blatter-isnt-among-them.html"><u>https://www.nytimes.com/2015/05/28/sports/soccer/fifa-officials-arrested-on-corruption-charges-blatter-isnt-among-them.html</u></a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fnv96bbayqvig"> <span class="footnote-back-link"><sup><strong><a href="#fnrefv96bbayqvig">^</a></strong></sup></span><div class="footnote-content"><p> For example, Project Excalibur promised to neutralize the threat of Soviet nuclear weapons by destroying dozens of ICBMs (with hundreds of warheads) as they launched. It ended up being infeasible.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnfp5yyyzqajs"> <span class="footnote-back-link"><sup><strong><a href="#fnreffp5yyyzqajs">^</a></strong></sup></span><div class="footnote-content"><p> <i>Examples of Regulated Things.</i>人工智能影响维基。 (Accessed October 19, 2023) <a href="https://wiki.aiimpacts.org/responses_to_ai/examples_of_regulated_things"><u>https://wiki.aiimpacts.org/responses_to_ai/examples_of_regulated_things</u></a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fnwx71dbbygd"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwx71dbbygd">^</a></strong></sup></span><div class="footnote-content"><p> This is my oversimplified model of what happened to the USSR.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/pAnvMYd9mqDT97shk/muddling-along-is-more-likely-than-dystopia#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/pAnvMYd9mqDT97shk/muddling-along-is-more-likely-than-dystopia<guid ispermalink="false"> pAnvMYd9mqDT97shk</guid><dc:creator><![CDATA[Jeffrey Heninger]]></dc:creator><pubDate> Fri, 20 Oct 2023 21:25:17 GMT</pubDate> </item><item><title><![CDATA[What's Hard About The Shutdown Problem]]></title><description><![CDATA[Published on October 20, 2023 9:13 PM GMT<br/><br/><p> I&#39;ve been having some <a href="https://www.lesswrong.com/posts/sHGxvJrBag7nhTQvb/invulnerable-incomplete-preferences-a-formal-statement-1?commentId=XpY4YxF4tFfGzNbbK">productive back-and-forth</a> with Sami Petersen about his <a href="https://www.lesswrong.com/posts/sHGxvJrBag7nhTQvb/?commentId=mmvwCeHzzojY9Gf2a"><u>Invulnerable Incomplete Preferences</u></a> (which is intended to complement <a href="https://s3.amazonaws.com/pf-user-files-01/u-242443/uploads/2023-05-02/m343uwh/The%20Shutdown%20Problem-%20Two%20Theorems%2C%20Incomplete%20Preferences%20as%20a%20Solution.pdf">Elliot Thornley&#39;s approach</a> to the Shutdown Problem). This post is a (non-formal) distillation of some useful pieces which I&#39;ve gotten out of that discussion so far.</p><h2> The Shutdown Problem</h2><p> Conceptually: we want to equip a powerful AI with a shutdown button. If and when the button is unpressed, we want the AI to follow one goal (we&#39;ll call it the “on-goal”). If and when the button is pressed, we want the AI to follow a different goal (we&#39;ll call it the “off-goal”). Presumably the off-goal involves the AI shutting down itself and all its associated tools/children/etc, but that part&#39;s flavor text for current purposes.</p><p> The key failure mode we want to avoid here is accidentally incentivizing the AI to manipulate the shutdown button - ie either cause it to be pressed, or cause it to be unpressed. Why would that happen? Well, suppose that when we first turn on the AI, it is <i>just</i> optimizing for the on-goal. The AI realizes that, if the button is pressed, its future self will stop optimizing for the on-goal, and therefore it will achieve lower performance on the on-goal. So, the AI realizes that it can achieve better performance on the on-goal by preventing the button from being pressed. And since it&#39;s just optimizing for performance on the on-goal, it then prevents the button from being pressed.</p><p> <a href="https://intelligence.org/files/Corrigibility.pdf"><u>MIRI&#39;s paper on the shutdown problem</u></a> goes through more examples of simple proposals for the shutdown problem, and how they incentivize button manipulation of one sort or another. It turns out that it&#39;s generally Hard to get the desired behavior (ie no button manipulation) out of any expected utility maximizer.</p><h2> Why It&#39;s Hard, Level 1: Desired Behavior Implies Incomplete Revealed Preferences</h2><p> Why is it hard to get an expected utility maximizer to not manipulate the button (while still doing useful stuff otherwise)? Here&#39;s one intuitive answer I got out of the discussion with Sami.</p><p> The central idea is to ask what the behavior we want from the shutdown-button-agent implies about that agent&#39;s revealed preferences.</p><p> Suppose that, at various times, the agent is offered opportunities to spend resources in order to cause the button to be pushed/unpushed. We want the agent to turn down such opportunities, <i>in both directions</i> - implying either indifference or lack of preference in any revealed preferences. Further, we do want the agent to spend resources to cause various different outcomes within the button-pressed or button-unpressed worlds, so there&#39;s nontrivial revealed preference ordering within button-pressed worlds and within button-unpressed worlds. But if the agent is to turn down costly opportunities to cause the button to be pressed/unpressed, and those opportunities jump between enough different pressed-outcome and unpressed-outcome pairs (which themselves each have nontrivial revealed preferences), then there&#39;s going to be a revealed preference gap - ie the behavior <i>cannot</i> be represented by complete preferences, only incomplete preferences.</p><p> Visually: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJofoQX7EjMFxDo6m/xfewi1h80r9jpibzyaxl"><figcaption> Agent spends resources to move from A1 to A2, but doesn&#39;t spend resources to move in either direction between B and either A-outcome. This is a “preference gap”; it is of interest because any assignment of preferences consistent with the preference gap must be incomplete.</figcaption></figure><p> We want the agent to spend resources to move from outcome A1 to A2, within the button-unpressed worlds, so it has a revealed preference there. But we want the agent to <i>not</i> spend resources to move between A1 and B, <i>in either direction</i> - so it has either revealed indifference (assuming the agent has nonzero bid/ask spread), or revealed incompleteness of preferences, between A1 and B1. By the same logic, there&#39;s also either revealed indifference or incompleteness between A2 and B1. But since the agent has a revealed preference for A2 over A1, any revealed preference assignment cannot be indifferent between both A1/B1 and A2/B1; that would imply indifference between A1 and A2. So the agent&#39;s revealed preferences <i>must</i> be incomplete. <span class="footnote-reference" role="doc-noteref" id="fnreft75wmozjvgf"><sup><a href="#fnt75wmozjvgf">[1]</a></sup></span></p><p> Upshot: (one way to frame) the reason that the shutdown problem is difficult/interesting in the first place, is that the desired behavior implies a revealed preference gap. Insofar as eg any standard expected utility maximizer <i>cannot</i> have a revealed preference gap, such standard EU maximizers <i>cannot</i> behave the way we want.</p><p> Some notes on this:</p><ul><li> Revealed preferences might be very underdetermined, ie there may be many assignments of preferences compatible with an agent&#39;s behavior. The argument above says that <i>any</i> assignment of preferences consistent with the desired behavior <i>must</i> be incomplete.</li><li> Note that the story implicitly routes above routes through causal interventions/counterfactuals to probe preferences - ie we&#39;re interested in whether the agent will spend resources to <i>cause</i> the button to be pressed/unpressed. That won&#39;t be very relevant for this post, but may be important for people aiming to formalize all this.</li><li> Apparently sometimes people take “no preference” (ie incompleteness) between A and B to mean that an agent chooses randomly/arbitrarily between the two. That is not the notion of “no preference” of relevance here; we&#39;re talking about “no preference” as in “the agent will not give up either to gain the other, given the opportunity”.</li></ul><p> Ok, so now we have a relatively intuitive story for why it&#39;s Hard to get an expected utility maximizer to behave the way we want in the shutdown problem: insofar as EU maximizers don&#39;t have revealed preference gaps, they can&#39;t behave the way we want. (More generally, if we&#39;re training an agent, any one-dimensional reward signal presumably cannot incentivize a revealed preference gap.) But then presumably the solution is to just… use an agent with incomplete preferences?</p><h2> Why It&#39;s Hard, Level 2: Incomplete Preferences Want To Complete</h2><p> The post <a href="https://www.lesswrong.com/posts/bzmLC3J8PsknwRZbr/why-not-subagents"><u>Why Not Subagents?</u></a> goes into more depth on this, but I&#39;ll give a brief overview here.</p><p> Looking back at our diagram with A1, A2, and B1, we could imagine a set of incomplete preferences which prefers A2 over A1, but has no preference between B1 and either of the A&#39;s (ie the agent won&#39;t spend resources to switch between button-unpressed and button-pressed outcomes, or vice versa). But this agent will spend resources to turn A1 outcomes into A2 outcomes.</p><p> Now the problem: this agent can potentially probabilistically precommit to accepting <i>both</i> opportunities to turn A1 outcomes into B1 outcomes (ie spend resources to make the button be pressed), and turn B1 outcomes into A2 outcomes (ie spend resources to make the button not be pressed). If it does both of these with the right probabilities, then it can maintain the same proportions of pressed (B1) and unpressed (A1+A2) outcomes, but shift some probability mass from A1 outcomes to A2. That&#39;s an improvement, by the incomplete preferences: the agent isn&#39;t accepting any net shift between A&#39;s and B&#39;s, it&#39;s just net-shifting probability around within A-outcomes, but it&#39;s doing so by manipulating the shutdown button.</p><p> (I learned from Sami&#39;s post that this is called “trammelling” of incomplete preferences.)</p><p> So we want some kind of agent which won&#39;t do that.</p><p> Some notes on this:</p><ul><li> The key question is whether the <i>revealed</i> preferences are immune to trammelling. This was a major point of confusion for me in discussion with Sami - his proposal involves a set of preferences passed into a decision rule, but those “preferences” are (potentially) different from the <i>revealed</i> preferences. (I&#39;m still unsure whether Sami&#39;s proposal solves the problem.)</li><li> That divergence between revealed “preferences” vs “preferences” in the sense of a goal passed to some kind of search/planning/decision process potentially opens up some approaches to solve the problem.</li><li> One can obviously design a not-very-smart agent which has stable incomplete preferences. The interesting question is how to do this without major limitations on the capability of the agent or richness of the environment.</li><li> Note that trammelling involves <i>causing</i> switches between outcomes across which the agent has no preference. My instinct is that causality is somehow key here; we&#39;d like the agent to not cause switches between pressed and unpressed outcomes even if the relative frequencies of both outcomes stay the same. </li></ul><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnt75wmozjvgf"> <span class="footnote-back-link"><sup><strong><a href="#fnreft75wmozjvgf">^</a></strong></sup></span><div class="footnote-content"><p> This all assumes transitivity of preferences; one could perhaps relax transitivity rather than incompleteness, but then we&#39;re in much wilder territory. I&#39;m not exploring that particular path here.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/iJofoQX7EjMFxDo6m/what-s-hard-about-the-shutdown-problem#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/iJofoQX7EjMFxDo6m/what-s-hard-about-the-shutdown-problem<guid ispermalink="false"> iJofoQX7EjMFxDo6m</guid><dc:creator><![CDATA[johnswentworth]]></dc:creator><pubDate> Fri, 20 Oct 2023 21:13:30 GMT</pubDate></item></channel></rss>