<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 7 日，星期二 12:22:20 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Box inversion revisited]]></title><description><![CDATA[Published on November 7, 2023 11:09 AM GMT<br/><br/><p><a href="https://www.lesswrong.com/posts/TQwXPHfyyQwr22NMh/box-inversion-hypothesis/">盒子反转假设</a>是在<a href="https://www.lesswrong.com/tag/agent-foundations">代理基础</a>等方法中研究的人工智能系统问题与人工智能生态系统问题之间的对应关系，人工智能生态系统问题是在人工智能安全的各种观点中研究的，期望多极化、复杂的世界，如<a href="https://www.lesswrong.com/tag/ai-services-cais">CAIS。</a>这是对该想法的更新和改进的介绍。</p><h2>卡通解释</h2><p><img style="width:73.02%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jrKftFZMZjvNdQLNR/i7uyj3fcdi4eftafit5k"></p><p><br>在经典的“盒子里的超级智能”图片中，我们担心日益强大的通用人工智能，我们将其想象为包含在盒子里。打个比方，我们担心盒子会在某个时刻在我们面前爆炸。然后，关于 AGI 的经典争论继续表明，构建 AGI 证明的盒子确实很难，而且默认情况下，真正强大的优化能力是危险的。虽然基本观点主要是由 Eliezer Yudkowsky 和 ​​Nick Bostrom 提出的，但它仍然是大多数人工智能安全技术所基于的观点，包括机械解释和评估等当前议程。 <br></p><p><img style="width:72.54%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jrKftFZMZjvNdQLNR/dkwc8m7qjkoqjdvkqlz6"></p><p><br>在这张不太出名但也很经典的图片中，我们担心人工智能服务、自动化公司等日益强大的生态系统。打个比方，我们担心“外面”不断增加的优化压力，逐渐边缘化人们，并最终压垮人们。我们。这种图景的经典处理方法不太出名，但包括埃里克·德雷克斯勒的 CAIS（ <a href="https://www.fhi.ox.ac.uk/wp-content/uploads/Reframing_Superintelligence_FHI-TR-2019-1.1-1.pdf">综合人工智能服务</a>）和斯科特·亚历山大的<a href="https://slatestarcodex.com/2016/05/30/ascended-economy/">提升经济</a>。我们可以想象这样的场景：人类无法理解的经济在宇宙中扩张，人类和我们的价值观受到某种“盒子”的保护。基于这一观点的议程包括<a href="https://ai.objectives.institute/whitepaper">AI Objectives Institute 的工作</a>和 ACS 的部分工作。</p><p>这些观点之间的明显分歧有时被视为各种人工智能安全举措的症结所在。</p><p> “盒子反转假说”声称：</p><ol><li>两张图片在很大程度上描绘了相同或非常相似的情况，</li><li>通过“将盒子里外翻转”的变换相关，类似于称为圆反转的平面几何变换，</li><li>并且：这个比喻出人意料地深刻，可以指出一些问题的难点。</li></ol><h2>几何隐喻</h2><figure class="image image_resized" style="width:70.31%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jrKftFZMZjvNdQLNR/yz9rihz8btdmr97zgicq" alt="文件:Inversión Círculos.png - 维基共享资源"><figcaption>倒转的圆圈。<a href="https://commons.wikimedia.org/wiki/File:Inversi%C3%B3n_C%C3%ADrculos.png">来自维基共享资源，CC-SA</a></figcaption></figure><p> “<a href="https://artofproblemsolving.com/wiki/index.php/Circular_Inversion">循环反转</a>”变换并不意味着原来的物体和反转后的物体是相同的，或者位于相同的地方。它的含义是保留了对象之间的某些关系：例如，如果某些对象相交，在倒圆视图中，它们仍然会相交。</p><p>类似地，对于“盒子反转”：该假设并不声称两种观点中的人工智能安全问题是相同的，但它确实声称，对于大多数问题，存在另一个观点所描述的相应问题。此外，虽然盒倒置问题在表面上看起来可能非常不同，并且位于不同的地方，但两个相应的问题之间会有一些深层的相似性。</p><p>换句话说，盒子反转假说表明两组人工智能安全问题之间存在某种“镜像”或“对偶性”。一组来自“代理基础”类型的视角，另一组来自“人工智能生态系统”类型的视角。</p><h2>盒子倒置问题</h2><h3>本体论和监管框架的问题</h3><p><span class="footnote-reference" role="doc-noteref" id="fnrefa22fcwq3tx8"><sup><a href="#fna22fcwq3tx8">[1]</a></sup></span><br>在经典的代理基础式图片中，人工智能安全挑战的一个重要部分与本体的相似性、识别和开发问题有关。<br><br>大致说来</p><ul><li>如果人工智能使用完全非人类的概念和世界模型，那么引导和控制就会变得更加困难</li><li>如果“人类想要什么”是用人类概念来表达的，并且这些概念没有扩展到新的情况或背景，那么就不清楚人工智能应该如何扩展或解释人类的“想要”</li><li>即使人工智能<i>最初</i>使用与人类思维和概念兼容的本体，也存在风险。随着人工智能变得更加智能，基于该本体的框架可能会崩溃，这可能会<a href="https://www.lesswrong.com/tag/ontological-crisis">导致人工智能以意想不到的方式运行。</a>因此，任何依赖于该本体的对齐方法也可能会失败。</li></ul><p>最近，本体论和世界模型的问题已经在不同的关键词下进行了研究，比如<a href="https://www.lesswrong.com/tag/natural-abstraction">自然抽象</a>、 <a href="https://www.lesswrong.com/posts/qHCDysDnvhteW7kRd/arc-s-first-technical-report-eliciting-latent-knowledge">ELK 的一部分、</a>或<a href="https://arxiv.org/abs/2310.13018">表征对齐。</a></p><p>接下来，我们将了解 Eric Drexler 的 CAIS 议程。在那里，一切都是服务，特定的一个是“服务目录”，从混乱的现实映射到服务空间。或者，换句话说，它从“你想要什么”映射到应该运行的计算类型。<br><br> CAIS 模型中的安全性部分建立在该映射之上，例如，如果您决定创建“毁灭世界的服务”，您就会被捕。</p><p><br>服务目录的问题包括</p><ul><li>如果随着时间的推移，越来越多的服务逐渐变得难以理解，通过非人类输入产生非人类输出，那么监管就会变得很棘手。</li><li>如果您的安全方法建立在服务目录中隐含的本体之上，则系统可能容易受到本体不匹配引起的攻击（如上所述）。</li></ul><p>在 2023 年的能力水平上，这在实践中看起来如何？</p><p>例如，政府正在努力起草真正有效的法规，部分原因是本体论不匹配。欧盟花了几年时间制定基于本体论的人工智能法案，以追踪人工智能的哪些<i>应用</i>是危险的。在 ChatGPT 之后，很明显本体与问题不匹配：法学硕士的能力似乎随着训练运行规模而扩展。虽然简单的目标“预测下一个标记”似乎无害，但足以让模型在合成生物学或人类说服等领域获得危险的能力。</p><p>对于不同类型的示例，请考虑提供<i>铁磁流体真空旋转馈通</i>设计的服务。如果你想阻止，比方说，一个流氓国家开发通用人工智能，这是你应该跟踪和关注的事情吗？</p><h3>恶魔的问题，……的问题？</h3><p>在台面优化器框架受到如此大的关注以至于淹没了看待这个领域事物的其他方式之前，代理基金会的人们和盒子空间中的超级智能都担心<a href="https://www.lesswrong.com/posts/KnPN7ett8RszE79PH/demons-in-imperfect-search"><u>优化恶魔</u></a>。从广义上讲，你有一个不完美的搜索，一个允许利用不完美的机制，并且在足够丰富的空间中，你会遇到一个利用低效率的反馈循环。一个全新的优化器出现了 - 具有不同的目标。<br><br>传统上，这个想法是这可以发生在人工智能系统内部，通过梯度黑客操纵其训练。就我个人而言，我认为对于法学硕士这样的系统来说，这种情况不太可能发生，但相比之下，我确实认为“操纵训练数据”在技术上更容易，而且事实上，一旦你在人工智能行为和训练数据之间建立了紧密的反馈循环，这种情况就很可能发生。</p><p>盒子倒置的版本是什么样子的？</p><p><br> <i>（在继续之前，您可能需要考虑一下自己的猜测）</i><br></p><p> <a href="https://www.lesswrong.com/tag/moloch">LessWrong 解释器</a>给出了一个莫洛奇动力的例子：科学家之间的红皇后竞赛，他们必须不断地花更多的时间撰写资助申请，只是为了跟上做同样事情的同行。由于不可避免的竞争，他们都浪费了时间，但最终却没有获得更多的资助。任何单方面试图不参与竞争的科学家很快就会被参与竞争的科学家所取代。如果他们都承诺限制自己的资助写作时间，那么每个人都会面临背叛的动机。</p><p>换句话说，稍微眯一下眼睛，这看起来像是我们有一些不完美的搜索过程（为有前途的研究提案分配拨款），一种允许利用它的机制……以及一个利用低效率的最终反馈循环。恶魔的问题转化为摩洛克的问题。<br><br>从更大的范围来看，这会是什么样子？在理想化的资本主义中，生产什么、生产多少以及以什么价格最终由人类总需求驱动，其中包含有关人类个人偏好的数据。尽管个别公司经常提供一些中间产品供其他公司使用，但各种供应链都自下而上地存在于人们对商品的需求中。市场不断“学习”消费者的偏好，市场经济根据这些偏好更新其生产的产品。</p><p>最终的失败看起来就像克里奇和罗素在<a href="https://arxiv.org/abs/2306.06924">TASRA</a>报告中的“公司网络”故事。</p><h3>还有什么？</h3><p>描述和示例似乎足以让 GPT4 粗略地理解该模式，并提出新的示例，例如： <span class="footnote-reference" role="doc-noteref" id="fnrefzh5q0axjocl"><sup><a href="#fnzh5q0axjocl">[2]</a></sup></span></p><ul><li><i>超级智能系统：人工智能可能会将自我保护置于其他目标之上，从而使其抵制关闭或修改尝试。</i></li><li><i>倒箱（人工智能生态系统）：一些人工智能系统在生态系统内交互时，可能会无意中创建反馈循环，使生态系统抵抗变化或更新，即使单个系统没有自我保护倾向。</i></li></ul><p> …等等。我建议不要粘贴 GPT 补全，而是查看人们在代理基础中担心的其他一些事情。</p><p>在最初的帖子中，我试图以这种不恰当的方式来表达看似倒置的安全“硬核”：<br></p><blockquote><p>安全的一些“硬核”（平铺、人类兼容性、一些可修正性的概念）&lt;->; 防御稳定性、安全服务层<br></p></blockquote><p>这次我会努力做得更好。在代理基金会中，似乎最困难的核心问题之一是内特、埃利泽和其他人所说的“<a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities">可修正性是反自然的”</a> 。简而言之，未来人工智能系统有很多方面是你可以期待的，因为这些方面似乎高度<a href="https://www.lesswrong.com/posts/sam4ehxHgnJEGCKed/lessons-from-convergent-evolution-for-ai-alignment">趋同</a>：拥有一个世界模型，使用抽象，理解算术，使用近似贝叶斯计算更新关于世界状态的一些信念，进行规划，进行某种形式的元认知，等等。清单上没有的是<i>“做人类想要的事”——</i>因为与其他情况不同， <i>“对人类友善”</i>不存在任何极其<a href="https://www.lesswrong.com/posts/sam4ehxHgnJEGCKed/lessons-from-convergent-evolution-for-ai-alignment">广泛的选择压力</a>。如果我们希望人工智能对人类友善，我们需要对此进行选择，并且我们还需要以一种可以随着人工智能能力扩展的方式进行设置。这个领域的大部分希望来自于<a href="https://www.lesswrong.com/posts/AqsjZwxHNqH64C2b6/let-s-see-you-write-that-corrigibility-tag?commentId=8kPhqBc69HtmZj6XR">“可纠正盆地”</a>的可能性，其中第一个可纠正的人工智能系统确保其后继者也是可纠正的。你还需要保证这种以人为本的计算不会被压倒，被 AGI 系统的内部动态所消除或误导。而且，您必须保证以人为本的计算不会仅仅通过黑客手段来适应正在发生的任何事情来解决对齐问题。<br></p><p>盒装倒装版是什么？在我看来，Eric Drexler的CAIS，对应的问题是<i>“如何设置安全服务”</i> 。由于 CAIS 的理论清晰，也许值得首先描述该框架中的问题。 CAIS中的安全服务保证了多项内容，包括“没有人创建毁灭世界的服务”、“安全服务足够强大，无法被颠覆或压倒”以及“安全服务保证人类的安全”。如果您还记得卡通解释，安全服务需要能够在外部存在强大优化的情况下保证盒子与人类的安全。以动态稳定的方式设置这似乎确实不简单，并且安全服务不会落入不良吸引者之一。明显的不良吸引因素是： 1. 安全服务被压倒，人类被压垮或被迫完全无关紧要 2. 安全服务形成极权独裁，人类失去自由并被迫或操纵进行某种批准舞蹈 3. 安全服务进化成一种高度非人类的形态，那里发生的一切都是完全无法理解的。</p><p><br>当前的现实要混乱得多，但您已经可以认识到人们本能地担心其中一些结果。对条约、国际监管机构和政府参与的呼吁推断是“我们需要安全服务来保护人类”。一些“我们需要自由分布的人工智能以避免权力集中”的主张是“我们担心独裁失败模式”。人工智能伦理中一些反科技声音的铁杆人物是“没有制度的资本主义默认是错位的”。</p><p>就像从长远来看，可修正性是不自然的一样，服务于人类的经济从长远来看似乎也是不自然的。目前，我们与人工智能相比相对强大，这使得我们很容易选择我们想要的东西。目前，发达国家的<a href="https://www.oecd.org/g20/topics/employment-and-social-policy/The-Labour-Share-in-G20-Economies.pdf">劳动力占GDP的比重</a>约为60%，这意味着仅凭我们的经济实力，经济就与人类合理挂钩。如果下降一百倍怎么办？</p><h3>这里发生了什么？</h3><p>我对盒子反转没有令人满意的形式化，但一些直观的直觉是这样的：看看盒子里的通用人工智能、“人工智能生态系统”和“人类”周围的马尔可夫毯子。最终，毯子内部的确切结构可能并不那么重要。<br><br>另外：作为人类，我们对认知系统的个性有强烈的直觉。这些主要基于人类的经验。根据这一经验，人们大多认为拥有“许多人工智能系统”的情况与拥有单一强大系统的情况非常不同。然而，基于“个体人类”的“个体系统”概念似乎并没有真正推广到人工智能系统。 <span class="footnote-reference" role="doc-noteref" id="fnreffawa19c0dw"><sup><a href="#fnfawa19c0dw">[3]</a></sup></span></p><h3><br>这意味着什么</h3><p>我目前对 2023 年 10 月的猜测是，大部分未缓解的人工智能存在风险来自盒子倒置的生态系统版本的问题。虽然我相当乐观，我们可以得到一个大致与人类水平的人工智能系统，几乎与使用当前已知技术开发它的公司保持一致，但从长远来看，我仍然非常担心。<br><br><i>感谢 Tomáš Gavenčiak、Mateusz Bagiński、Walter Laurito、Peter Hozák 等人的评论和 Rio Popper 的编辑帮助。我还使用 DALL-E 来处理图像，使用 GPT-4 来编辑和模拟阅读器。</i> </p><p></p><p></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fna22fcwq3tx8"> <span class="footnote-back-link"><sup><strong><a href="#fnrefa22fcwq3tx8">^</a></strong></sup></span><div class="footnote-content"><p>在原来的帖子中，我仅仅将其称为“<i>关于本体的问题&lt;->;关于服务目录的问题”，</i>但自从写了原来的帖子后，我了解到这种写作密度使得几乎任何人都无法理解文本。<br><br>那么让我们来稍微解压一下。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnzh5q0axjocl"> <span class="footnote-back-link"><sup><strong><a href="#fnrefzh5q0axjocl">^</a></strong></sup></span><div class="footnote-content"><p>从大约 10 个例子中精挑细选</p></div></li><li class="footnote-item" role="doc-endnote" id="fnfawa19c0dw"><span class="footnote-back-link"><sup><strong><a href="#fnreffawa19c0dw">^</a></strong></sup></span><div class="footnote-content"><p>它实际上也不能推广到许多生物，如细菌或植物。</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/jrKftFZMZjvNdQLNR/box-inversion-revisited#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/jrKftFZMZjvNdQLNR/box-inversion-revisited<guid ispermalink="false"> jrKftFZMZjvNdQLNR</guid><dc:creator><![CDATA[Jan_Kulveit]]></dc:creator><pubDate> Tue, 07 Nov 2023 11:09:37 GMT</pubDate> </item><item><title><![CDATA[AI Alignment Research Engineer Accelerator (ARENA): call for applicants]]></title><description><![CDATA[Published on November 7, 2023 9:43 AM GMT<br/><br/><br/><br/> <a href="https://www.lesswrong.com/posts/465MTELvNKMdQk322/ai-alignment-research-engineer-accelerator-arena-call-for-1#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/465MTELvNKMdQk322/ai-alignment-research-engineer-accelerator-arena-call-for-1<guid ispermalink="false"> 465MTELvNKMdQk322</guid><dc:creator><![CDATA[TheMcDouglas]]></dc:creator><pubDate> Tue, 07 Nov 2023 09:43:42 GMT</pubDate> </item><item><title><![CDATA[The Perils of Professionalism]]></title><description><![CDATA[Published on November 7, 2023 12:07 AM GMT<br/><br/><p>专业精神是一种可以展现的有用品质，但它并不是纯粹的优点。本文试图概述为什么故意不表现出专业精神可能对你有用。</p><p>首先，通过示例对专业精神进行定义：干净的系扣衬衫，搭配纯色领带，西装外套或西装外套，胡须剃干净，头发扎成发髻，没有传单，米色或灰色或至少是纯色的汽车、桌子和墙壁，甚至是带有一丝情感的语调声音，听起来一点也不机械或缺乏同理心。</p><p>这不是职业管理阶层，但他们（特别是帕特里克·麦肯齐有时描述的那样）往往是职业管理阶层的典范。</p><h2>我。</h2><p> “专业人士”一词被定义为从事特定活动作为主要有偿职业的人。它与“业余爱好者”形成鲜明对比，“业余爱好者”是指无偿从事某项活动的人。值得注意的是，“业余”也可以指在某项特定活动中无能力的人。从语言的角度来看，我们将<i>技能</i>和<i>报酬</i>混为一谈，并且我们是双向的。</p><p>如果你想通过做某事获得报酬，你想学习专业地做这件事。专业地做某事通常包括相邻但不明显同义的技能。其中一些非常接近；我曾经是一名专业软件工程师，也参与过招聘专业软件工程师的工作，如果您作为软件工程师不知道如何使用源代码控制，那么您想学习使用源代码控制。是的，我知道这不是一个很酷的新算法。是的，我知道最终用户永远不会看到它。相信我，你会用到它。</p><p>专业人士的一些预期技能不是关于工作的核心技能，而是更多关于工作的框架。 “准时”、“着装得体”和“举止得体”都经常被作为适用于广泛领域的专业技能的例子。坦率地说，如果你要与顾客互动，尤其是在白领工作中，最好不要有面部纹身，也不要随意说脏话。</p><p>我们似乎很快就陷入了一些看似与你完成手头实际工作的能力几乎没有关系的事情！尽管如此，我希望西方世界的几乎每一位职业教练都能支持我的要点。我第一次成功地用金钱换取软件是在我<i>十三</i>岁左右的时候，虽然在这期间我在编写软件方面取得了更好的成绩，但我在展示自己作为一名专业软件工程师的能力方面也有了更大的进步。</p><h2>二.</h2><p>让我们谈谈我的第一个专业软件工程项目。</p><p> （在这里，我使用“专业”来表示“我为此获得了报酬。”正如您即将发现的那样，它在几乎所有其他意义上都是不专业的。）</p><p>据我所知，这份工作是这样的。我母亲的一个朋友听说我“电脑很好”，就问我是否知道如何建立一个网站。事实上，我最近成功地运行了我自己的 Apache 服务器。她说她的组织需要一个网站，在那里他们可以宣布他们的活动，人们可以在那里了解该组织，我是否愿意花费相当于几个月零用钱的钱来建立这个网站。我说当然可以，并问了她一系列关于网站上需要包含什么内容的问题。一周后，当我揭晓它时，她听起来很高兴，对文本做了一些更正，我向她展示了如何添加新事件。</p><p>如果您至少不是一点网络开发人员，那么下一段描述该网站的内容将是纯粹的行话。如果没有意义，请跳过它并了解这是一个非常糟糕的网站，我唯一真正的辩护是她得到了她所付出的代价。</p><p>我用纯 HTML 和 CSS 编写了它。事件页面是一个 HTML 文件，您可以通过打开 HTML 并复制最后一个事件块，然后将其更改为适合的方式来添加新事件。您必须更改发布日期，因为那只是带有一些特殊样式的文本。 CSS 并没有真正利用继承，我重新定义了每个块的颜色。说到颜色，我读过一本关于网页开发的书，但我还没有读过关于颜色理论的书，所以我直接通过问她“你最喜欢什么颜色？”来画颜色。并尝试使用十六进制代码，直到我得到了她回答的大致颜色。没有备份，也没有在不复制整个文件结构的情况下备份它的方法，也没有任何应该进行备份的想法。</p><p>如果您在九十年代末或 00 年代初上网，您一定会看到过一个网站，它看起来很像我付费购买的第一个网站。我继续制作更多这样的网站，我的服务通过口口相传，在接下来的三四年里为我赚了很多披萨和平装本的钱。当我上大学时，我不得不停止为人们制作网站，因为我太忙于学习有关编程的新知识，比如人们为什么使用函数。</p><p>我想我在整个高中期间通过编程和修理坏掉的电脑赚的钱与很多人煎汉堡或打扫电影院赚的钱大致相同。当然，在我上大学之前，我当农场工人赚的钱比我靠电脑赚的钱还要多。我一直在努力为我所在地区的高级企业提供服务——银行、连锁店、大公司，这些公司似乎在与我生活的世界不同的世界中运作。我所缺少的实际上并不是编程能力。</p><p>回顾经验中的智慧，我缺少的是专业精神。我不知道如何在不骄傲的情况下表现出低调的自信，我也没有意识到我糟糕的个人表现对我的机会造成了多大的损害。总而言之，我的问题是寻求计算机专业知识的专业公司不喜欢与骑自行车的大汗淋漓的青少年进行现金交易，而“青少年”部分并不是这句话中的真正症结所在。</p><h2>三．</h2><p>这些确实是关于什么是专业精神以及它对一篇标题为“专业精神的危险”的文章有何帮助的大量文字。是什么赋予了？</p><p>有时添加一点专业化的暗示是简单而有用的。当我第一次接触<a href="https://getbootstrap.com/"><u>Bootstrap</u></a>时，我就被迷住了。这是一种快速、简单的方法，可以使我的网站看起来几乎与我不知道如何向其销售的公司制作的精美公司网站一样好。我没有浪费时间升级到更好的风格。问题只会在以后出现。</p><p>看，专业精神是一揽子交易。如果您看到一个带有尖角和稍微花哨的颜色的网站，那么当您拨打联系页面上的联系电话时，您不会指望有一个流畅且训练有素的声音来接电话。我曾经对那些只在中午营业的地方感到沮丧，因为我下班后无法给他们打电话。现在我意识到这不是一个错误，而是一个功能。有时是因为他们想与其他专业人士打交道。当我让我的网站看起来流畅和优美时，这意味着人们会在中午联系我，经常在课堂上或（稍后）在工作会议上看到我。</p><p>专业精神伴随着其他期望。</p><p>为了参加我最好朋友的单身派对，我们周末租了一间爱彼迎房源。我们熬夜，开大音量玩电子游戏，在后廊做一些烧烤，玩得很开心。它使用了很多与 2019 年和 2022 年东海岸理性主义者大型聚会类似的设置和规划；事实上，如果你以某种方式在我们为单身派对租用的地方外面设置一个地铁站，你就可以使用完全相同的场地来举办这两个活动。对于 2023 年的 Megameetup，我一直在尝试“升级”到更专业的设置。我们预订了酒店大楼，租用了活动空间，我希望能用名牌而不是贴纸和记号笔进行实际登记。这造成了一些期望的不匹配！</p><p>例如，酒店似乎对我在聚会前一个月没有提供完整的客人名单感到有点困惑，我只能试图解释说，是的，事实上我确实希望有一半以上的客人注册最后两周。我必须仔细考虑一下我们将在下午 5 点之后进入会议空间的想法，是的，甚至可能在晚上 7 点之后。 （我仍然不确定我是否理解了这个想法，如果我列出了出错的事情的墨菲术清单，那么“酒店预计我们 5 点离开会议空间”的位置仍然很高。）每当我遇到这些问题时，我都会情不自禁地想，如果我表现得不那么专业，他们是否也会如此困惑。</p><p>当酒店询问这次活动会是什么样时，我将其描述为学术会议和粉丝大会的结合体。这是真的！会发生很多专业的社交活动，我希望会有关于新颖研究的演讲或突破性论文的总结。我还预计至少会有一个人喝得酩酊大醉（好吧，公平地说，我听说在一些学术会议上也会发生这种情况），并且有人会在凌晨一点用原声吉他唱民歌。这不会发生在“专业”活动中！</p><p> （如果此时您认为值得双方同意不使用“事件”一词并描述他们期望发生的事情，那么……您可能是对的！现在您尝试随机选择一个会议酒店销售代表做这种奇怪的互联网事情，你称之为“禁忌你的话。这是可行的！我已经根据经验验证了这一点！但它肯定不是人们期望的那样。）</p><p>早在我第一次开始疯狂追求扩大东海岸大型游戏集会规模时，一位朋友漫不经心地建议去酒店而不是爱彼迎风格的场所，好像这很容易，他经常这样做。他刚刚联系了他们中的一些人，并表示这“更多的是出于好奇而不是任何事情”。与此同时，我不得不查找他用于启动该过程的缩写词。</p><p>或者看看我最近与一个我想从他那里购买电吉他的人的另一次对话。在谈话过程中，我提到我做了一些活动协调，他说他在该地区已经这样做了很多年，并问我是否会做他听说过的任何事情。我说社区中较大的活动有一百多人参加，本赛季我举办了其中两次。他呃，挠着下巴，说了些什么，大意是他不知道哪个场馆会在演奏一组非常甜美的强力和弦时为这么小的事情而烦恼。</p><p>这两个人都在各自的领域中表现出了一种随意、舒适的能力。他们见过事情出错，记住人们可能犯的明显错误，并且不需要强调小事情。这是我可以在软件中做的事情，也是我可以在其他一些领域做的事情，但在组织活动时我还不太习惯。我认为，在正确的时间和地点表明专业精神是有用的，因为你可以利用这一点。飞机飞行员基本上似乎只会讲同样的几个老套的、预制的笑话。我对此表示赞同。如果我登上飞机发现飞行员穿着小丑的杂色和猫耳朵，我会变得有点紧张，这并不是完全未经认可的，尽管他们的着装并没有改变他们的实际驾驶技能。</p><h2>四．</h2><p>如果你表现得很专业（在举止、审美、说话和外表等软技能上），人们会期望你达到专业标准（在你的专业水平上、在应对意外情况方面、在了解事情如何发生方面）。流程应该进行。）您可能不了解这些标准，这种无知可能很重要。专业精神的外表掩盖了你不知道自己在做什么的事实。这也阻碍了人们伸出援手。</p><p>如果我在朋友家吃晚饭，发现他们正忙着切蔬菜，而炉子上的东西开始冒烟，我通常会介入并翻转它或自己把火关小。这可以变成舒适地并肩工作，如果我足够了解他们，可以猜测他们的食物偏好或厨房的布局，我可能会根据口味给饭菜加香料，或者我们可能会一起即兴创作食谱。如果我在餐厅，我绝不会回到厨房并开始麻烦厨师进行更改！一般来说，即使我开始闻到一点烟味，我也会认为这是故意的，他们知道自己在做什么并且正在注意。事实可能并非如此！</p><p>流畅、精心设计的演示可能会阻止人们为您提供帮助。如果您希望业余爱好者不参与，这可能很好（外科手术室里没有临时志愿者的地方），但如果您希望人们加入，这尤其糟糕。卡拉 OK 酒吧或单口喜剧俱乐部有充分的理由不要显得太专业。我认为，开源项目的愚蠢名称在使其看起来更容易被接受方面做了一些很好的工作。还有理性聚会。 。 。</p><h2>五、</h2><p>大多数聚会在很大程度上取决于与会者的参与、支持、解决问题以及提供大部分内容和对话。我对东海岸理性主义者大型聚会的主要认识是，我不负责提供聚会的内容；我负责提供聚会的内容。我安排了场地，与会者一起创作了内容。我在 LessWrong 社区周末、Vibecamp 以及几乎所有其他大型理性主义活动中都看到过这种模式。</p><p>如果你正在组织类似的活动，并且你不小心发出了这样的信号，即某人必须如此团结、理性且出名才能做出贡献，那么你将会遇到困难。不仅你在闪电演讲中的发言者会减少，而且你会无意中切断了人们为举办自己的活动而攀登的阶梯的底部。你可以鼓励那些处于边缘的人挺身而出并加入进来，方法是在演讲中稍微不那么专业，稍微愚蠢一点和随意一点。</p><p>我的模糊猜测是，能够说自己举办专业级理性主义活动的人不到一百人。想必 CFAR 的一些人已经在这方面积累了经验，CEA 的一些人可能也算数，然后还有一大群已经从事该领域一段时间的运维人员，或者他们的非理性主义职业生涯为他们做好了异常良好的准备。它们很罕见，而且《LessWrong》的许多读者不会遇到它们，就像大多数听音乐的人不会面对面见到摇滚明星一样。</p><p> （这对于网站来说是完全不同的，我基本上会信任来自任何当地社区需要网络开发人员的最有信心的志愿者。我们绝对拥有这种技能。）</p><p>这篇文章的灵感部分来自于 Elizabeth 发表的关于各种 EA 组织的法律结构的<a href="https://www.lesswrong.com/posts/XvEJydHAHk6hjWQr5/ea-orgs-legal-structure-inhibits-risk-taking-and-information"><u>文章</u></a>。如果我们拥有丰富的法律和官僚技能，事情就不会是这样的。当你实际查看组织结构图时，它看起来很混乱且不专业。如果没有经验丰富的顾问的帮助，也许早熟的青少年在第一次解决问题时会做出这样的事情。<i>也许这就是实际发生的事情。</i>顺便说一句，我并不是想用“青少年”作为贬义词：特立独行、早熟的青少年很棒，当我上高中时，我经常遇到工作能力比我差的成年成年人。实际上这就是重点。</p><p>请注意，仅仅因为有人拿钱去做一件事，并且他们发出了所有正确的能力和轻松的信号，他们可能仍然不擅长做这件事。 As a corollary, if you suck at the thing, be careful about whether you&#39;re sending the signals of competence and ease.</p><p> (Oh, and if you&#39;re reading this in November or early December of 2023, the East Coast Rationalist Megameetup will be in New York City on the weekend of December 9th. If that or the NYC Secular Solstice sound like your kind of thing, consider <a href="https://rationalistmegameetup.com/"><u>joining us</u></a> !)</p><br/><br/> <a href="https://www.lesswrong.com/posts/QChwTjL6oL2a6gbhm/the-perils-of-professionalism#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/QChwTjL6oL2a6gbhm/the-perils-of-professionalism<guid ispermalink="false"> QChwTjL6oL2a6gbhm</guid><dc:creator><![CDATA[Screwtape]]></dc:creator><pubDate> Tue, 07 Nov 2023 00:07:33 GMT</pubDate> </item><item><title><![CDATA[How to (hopefully ethically) make money off of AGI]]></title><description><![CDATA[Published on November 6, 2023 11:35 PM GMT<br/><br/><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 17:14:09 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 17:14:09 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Hey Everyone!</p><p> As part of working on dialogues over the last few weeks I&#39;ve asked a bunch of people what kind of conversations they would be most interested in reading, and one of the most common one has been &quot;I would really like to read a bunch of people trying to figure out how to construct a portfolio that goes well when AGI becomes a bigger deal&quot;.</p><p> You are three people who would be reasonably high on my list to figure this out with, and so here we are. Not because you are world experts at this, but because I trust your general reasoning a bunch (I know Noah less well, but trust Will and Zvi a good amount).</p><p> I think to kick us off, maybe let&#39;s start with a very brief 1-2 sentence intros on your background and how much you&#39;ve thought about this thing before (and like, whether you have constructed a relevant portfolio yourself).</p><p> <i>Also, to be clear, nothing in this post constitutes investment advice or legal advice.</i> </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 17:15:23 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 17:15:23 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><p> Thanks for the invitation to participate Oliver! My name is Will Eden, my background is economics and finance and biotech, and most recently I have been an early stage biotech VC, though I also try to think very hard about how to manage a broad, public asset portfolio as well.<br><br> If I had a rough thesis / opening statement, it would probably be that this is extremely difficult to know in advance how most assets will perform / which parts of the chain will accumulate lots of value. On the flip side, I think we have a saving grace in that it&#39;s likely the overall economy will be generating a ton of value, and even some very general and broad types of portfolios will likely accumulate considerable value, if not the maximum possible value that we&#39;d of course like to achieve. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="N9zj5qpTfqmbn9dro-Tue, 31 Oct 2023 17:16:44 GMT" user-id="N9zj5qpTfqmbn9dro" display-name="Zvi" submitted-date="Tue, 31 Oct 2023 17:16:44 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Zvi</b></section><div><p> My name is Zvi Mowshowitz. I have written and thought a lot about economics, and I spent 2.5 years trading at Jane Street Capital. I spend a bunch of time thinking about these matters, but I also intentionally do my best to avoid spending too much time on portfolio optimization or trading so it doesn&#39;t take over my entire brain.</p><p> I also wrote a post about this called <a href="https://thezvi.substack.com/p/on-ai-and-interest-rates">On AI and Interest Rates</a> .</p><p> (Also I know enough to say up front that nothing I say here is Investment Advice, or other advice of any kind!)</p><p> My general approach in such situations is that you want to look for investments/gambles that would not be too expensive (in EV terms) if your thesis was chosen at random, or even would be good ideas anyway, but that would then benefit greatly if your thesis turns out to be true. There is a time and place to pay a premium, but it must be chosen carefully. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 17:18:50 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 17:18:50 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> Thanks for the invite! I&#39;m flattered to be here. My name is Noah Kreutter and my background is that I have roughly 4 years of quant-y finance experience, including <a href="https://www.imc.com/us/">IMC</a> and (soon-to-be) Bridgewater. I&#39;ve done a mix of volatility trading and systematic multi-asset macro. I&#39;ve also been around the LW/Rationalist/SSC ecosystem since at least 2015, but mostly at the periphery. None of what I say is financial advice, including anything that sounds like financial advice.<br><br> My basic view is that in a slow AGI takeoff - and really, it&#39;s slow takeoffs where how you invest is likely to matter - you want to construct a portfolio that is long growth, especially stocks with idiosyncratic exposure to AI, long volatility, long rates-going-up (short bonds), and long &quot;real estate that is cheap in 2023&quot;. You probably want to avoid real estate that is being supported by a strong knowledge based labor market (eg NYC).<br><br> Also, for most readers I imagine that career capital is their most important asset. A consequence of AGI is that discount rates should be high and you can&#39;t necessarily rely on having a long career. So people who are on the margin of eg attending grad school should definitely avoid it.<br><br> My current portfolio is a mix of single name equities, long dated call options on indices, long-ish dated calls on a few specific stocks (eg MSFT), and short long dated bonds. I also hold a lot of cash. If I could easily get a cheap mortgage in some less bougie part of the US, I probably would, but logistically its annoying.</p><p> One other general piece of advice I would offer - and this dovetails with both &quot;hold cash&quot; and &quot;get some equity beta via options&quot; - is to &quot;preserve optionality&quot;. The value of being nimble in a broad sense over the next decade is likely to be high. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 17:22:04 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 17:22:04 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><blockquote><p> &quot;get some equity beta via options&quot;</p></blockquote><p> Ah, yes, I also love me some equity beta via options :P</p><p> I think I can maybe decipher what this means via some Googling, but can you elaborate a bit more? </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 17:36:23 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 17:36:23 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> By &quot;getting your equity betas through call options&quot; I mean using call options (the right but not obligation to buy a stock or index at a prespecified price) as a partial substitute for holding stocks outright. The idea is that call options have a <i>delta</i> - the derivative of some pricing formula with regards to the price of the underlying asset - and this tells you how much the price of an option should change given a $1 move in the underlying.<br><br> To Zvi&#39;s point, I would not trade any short dated options based on AI theses. But in general, tax issues and transaction cost issues are less severe if you buy calls with expirations several years out, since this is long enough to receive long term capital gains tax treatment. The reasons to do this are cheap, non recourse leverage (you can get quite a lot of equity exposure for little money down), and positive expected value if you believe the options market is mispricing volatility - ie underestimating how much stock prices will bounce around - which I think it is. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 17:22:04 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 17:22:04 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> For the future reader, some attempts at paraphrasing what Noah is saying for non-enlightened mortals:</p><p> <strong>I would not trade short dated options based on AI theses:</strong> &quot;I think it is a bad idea to buy financial instruments that only pay out when the price of certain stocks changes in the near future. Presumably because timing price movements is quite tricky and even big changes can be hard to time in the stock market (remember the difficulty of timing the 2020 pandemic stock movements despite obviously large effects of the pandemic on stock prices), and because the high volatility of this kind of instrument means that risk-averse counter-parties often ask you to pay a high additional premium&quot;</p><p> <strong>If you buy calls with expirations several years out, this is long enough to receive long term capital gains tax treatment:</strong> &quot;In the US you pay substantially higher taxes when you hold a financial instrument for less than one year (short term capital gains vs. long term capital gains). This means if you want to bet on price movements (via options), it&#39;s tax beneficial to bet on price movements at least a year out.&quot;</p><p> <strong>The reasons to do this are cheap, non recourse leverage (you can get quite a lot of equity exposure for little money down):</strong> &quot;If you bet on long term price movements instead of just holding stock this way you can capture a lot of upside without tying up a lot of your capital in holding stock (high leverage) and without risking your unrelated assets being liquidated and possessed (non-recourse)&quot;</p></div></section><h2> Broad market effects of AGI </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 17:20:28 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 17:20:28 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><p> Under basically any AGI scenario, the economy will begin to accelerate and grow very rapidly. Several assets closely reflect the growth rate in the economy, particularly real interest rates, and others are imperfect proxies, like public equities (stocks). It&#39;s worth noting that several leading AI companies cannot be invested in by the general public currently (eg OpenAI, Anthropic, etc) as they are privately held, so it may be difficult to invest exactly and precisely in an AI scenario. My argument is that while it will be tricky to get perfect exposure, and any portfolio will be an imperfect proxy, the rapidly accelerating growth will mean that lots of value is created in unexpected places and captured in different ways - for example one of those booming private companies being acquired by a public company, which you can now invest in - such that the boring old strategy of &quot;invest in index funds&quot; still might capture much/most of the value from AGI :) </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="N9zj5qpTfqmbn9dro-Tue, 31 Oct 2023 17:21:05 GMT" user-id="N9zj5qpTfqmbn9dro" display-name="Zvi" submitted-date="Tue, 31 Oct 2023 17:21:05 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Zvi</b></section><div><p> As for my current portfolio, I have a mix of different things, which includes individual stocks I expect to benefit from AI (eg MSFT and GOOG), and various other investments including other individual stocks, and also a very favorable fixed-rate mortgage - which is an example of a trade that was good anyway, but which AI made better.</p><p> I agree with NoahK that preserving optionality is a good idea here. You should treat illiquidity as costing a larger premium than usual.</p><p> In general, I think that &#39;construct a perfect portfolio&#39; is not worthwhile unless you value the intellectual exercise. There isn&#39;t enough alpha in getting it exactly right, and tax considerations often dominate when considering things like rebalances. You want to be sure you are directionally right and are expressing your opinions, but not go too crazy.</p><p> I strongly agree with Will that accelerating AGI will create a lot of value in different places, so a broad range of productive assets could appreciate, or at least a portion of them, such that it is reasonable to predict that SPY (S&amp;P 500 ETF) would do well. One worry there is that rising interest rates is not so great for stock prices, so you&#39;d want to consider whether to cover that base.</p><p> For things like options, you pay a premium in that you have to cross a wider spread when you trade them, worry about various edge cases in market structure, and then face tax implications. It is clearly the right move in certain focused spots (think Feb 2020) but I would hesitate to use them for AI unless you expect things to escalate rather quickly.</p></div></section><h2> Career capital in an AGI world </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 17:47:07 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 17:47:07 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><blockquote><p> Also, for most readers I imagine that career capital is their most important asset.</p></blockquote><p> This point Noah made is worth considering, though I think we need to be honest about what skills we have / which ones we can develop. In a full AGI scenario, where all humans are exceeded in all skills by AIs, it seems unlikely that even the best programmers etc will be able to make significant returns. In the lead up to that period, there&#39;s still an open question about which jobs exactly get replaced in what order.</p><p> For example, everyone seemed very surprised when art got automated first - it was always assumed that creative tasks would be the last ones to go! (This still could be true if we place a huge premium on human-created art.) It seems reasonable that anyone working directly on improving AI could still earn a large premium for many years, and so relying on that career/human capital seems like a good strategy. But if you expect both 1) AGI soon, and 2) many/most jobs replaced, then I think people shouldn&#39;t assume they&#39;ll be able to earn any income in future periods. (Social implications of that are massive, expect taxation of AGI + universal basic income, mass charity, etc, etc - but the point stands.) </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 17:47:09 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 17:47:09 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> Completely agree with Will about most people&#39;s careers not necessarily being worth all that much <i>once AGI is here.</i> I think it&#39;s an argument for trying to grab money via your career now, instead of doing things that supposedly build <s>human</s> career capital but take a while to pay off. Do quant trading over consulting, don&#39;t go to grad school, try to front-load earnings as much as possible. (EDIT: to Zvi&#39;s point, human and career capital are different. I&#39;m really just talking about career capital here - broader social connections and reputation are likely to be exceedingly important in many futures).</p><p> I do expect the <i>transitional period</i> around AGI to create a lot of high value entrepreneurial opportunities for those with that skillset. Unclear how long to expect it to take for things to reach a new equilibrium. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="N9zj5qpTfqmbn9dro-Tue, 31 Oct 2023 17:47:15 GMT" user-id="N9zj5qpTfqmbn9dro" display-name="Zvi" submitted-date="Tue, 31 Oct 2023 17:47:15 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Zvi</b></section><div><p> A point I have not seen made so far, that is worth considering, is in which worlds is the value of having money high rather than low for you?</p><p> In the extreme, in the world where doom occurs and everyone dies, dying with the most toys is still dead. Or there is a regime change or revolution or confiscatory taxation regime or other transformation where old resources stop having meaning. Or if we get into a post-scarcity utopia situation of some kind somehow, perhaps you did not need money.</p><p> Whereas there are other scenarios where having funds in the right place at the right time could be hugely impactful - which I would guess are often exactly the scenarios where interest rates are very high. Or worlds in which those without capital get left behind. So you&#39;d want trades and investments that pay off in the worlds where wealth is valuable, and to worry less about when wealth is not so valuable. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 17:49:26 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 17:49:26 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> Yeah you kind of have to assume that things will get weird but not too weird. It&#39;s not really possible to hedge either the apocalypse or a global revolution, so you can ignore those states of the worlds when pricing assets (more or less).</p><p> This is less true if you expect your actions to actually have a meaningful impact on the state of the world. Like if you think there may come a time when if you have enough money the apocalypse can be averted vs not, you should perhaps invest differently than someone who believes he or she is only ever along for the ride. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 17:51:13 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 17:51:13 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> I think insofar as you expect rates to go up <i>in response to growth</i> that can&#39;t really be an argument for bearish equity. At worst, &quot;not as bullish as you&#39;d otherwise be given growth expectations.&quot;. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="N9zj5qpTfqmbn9dro-Tue, 31 Oct 2023 17:52:00 GMT" user-id="N9zj5qpTfqmbn9dro" display-name="Zvi" submitted-date="Tue, 31 Oct 2023 17:52:00 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Zvi</b></section><div><p> Career capital is one form of human capital or social capital. Broadly construed, such assets are indeed a large portion of most people&#39;s portfolios. I&#39;d rather be &#39;rich&#39; in the sense of having my reputation, connections, family and skills than &#39;rich&#39; in the sense of having my investment portfolio, in every possible sense. This is one reason not to obsess too much about your exact portfolio configuration per se, and worry more about building the right human and social capital instead.</p><p> And yes, if you think timelines to transformation are relatively short, then that too should consider the impact on what is valuable. I certainly would not plan on anything like a &#39;tenure track&#39; or other long-term plan that does not pay off for many years.</p><p> Especially I would warn against looking for the illusion of security or normality - the idea that you are set if everything stays normal should not bring too much comfort. But on the flip side, if things stay more normal for longer than you expect, you don&#39;t want to mean you&#39;re screwed. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 17:54:26 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 17:54:26 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><blockquote><p> A point I have not seen made so far, that is worth considering, is in which worlds is the value of having money high rather than low for you?</p></blockquote><p> I agree very much with this point, and I see a couple scenarios where your wealth endowment matters. One world is where there are clear and urgent ways to spend money to directly improve outcomes, eg a huge spend on AI safety or whatnot. I suspect that&#39;s why most EAs are considering this question.</p><p> The other is a world more like a slow takeoff Age of Ems type scenario, where there isn&#39;t total obsolescence of all forms of humanity, and maybe there&#39;s a minimal social safety net because it would be very cheap at that point, but if you want any meaningful large impact on humanity&#39;s future it absolutely depends on what resources you can muster to eg gain compute power to run more copies of yourself. I definitely put non-zero odds of this being a potential future! </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 17:54:43 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 17:54:43 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><blockquote><p> The other is a world more like a slow takeoff Age of Ems type scenario, where there isn&#39;t total obsolescence of all forms of humanity, and maybe there&#39;s a minimal social safety net because it would be very cheap at that point, but if you want any meaningful large impact on humanity&#39;s future it absolutely depends on what resources you can muster to eg gain compute power to run more copies of yourself.</p></blockquote><p> For whatever it&#39;s worth, this is the strange future I find most personally plausible and certainly most worth thinking about/hedging. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="N9zj5qpTfqmbn9dro-Tue, 31 Oct 2023 17:55:01 GMT" user-id="N9zj5qpTfqmbn9dro" display-name="Zvi" submitted-date="Tue, 31 Oct 2023 17:55:01 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Zvi</b></section><div><blockquote><p> Ultimately I still expect growth to be so large that will outweigh any drag on stocks due to rates.</p></blockquote><p> Right, I do as well in these scenarios, but I wanted to point out that if a given stock/sector/etc &#39;misses out&#39; on the explosive growth, then their value rather than staying static could drop quite a bit.</p><p> Also I have to assume that a lot of businesses are going to get disrupted, and hard. There will be losers. A lot of why I like individual stocks when investing domestically is that while I don&#39;t know if I can reliably pick winners, I do know I can identify losers I want to avoid. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 17:55:25 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 17:55:25 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> Anyone short <a href="https://www.google.com/finance/quote/CHGG:NYSE?sa=X&amp;ved=2ahUKEwjHrLuCtaGCAxWNGTQIHUDKBPsQ3ecFegQINBAh">Chegg</a> in February? I think there will be a lot of opportunities like that over the next few years at least. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 17:56:23 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 17:56:23 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><blockquote><p> Its not really possible to hedge either the apocalypse or a global revolution, so you can ignore those states of the worlds when pricing assets (more or less).</p></blockquote><p> Brief disagreement here - it&#39;s true you can&#39;t hedge something like a total AI takeover / x-risk, but you can certainly hedge things like a revolution or catastrophic risks. Personally I think it&#39;s wise to consider manageable downside scenarios and allocate just a few % of your portfolio to robustness, from cheap things like &quot;stockpile food and water&quot; to more expensive things like &quot;physical gold and silver coins somewhere hidden but where you can access them in an emergency&quot; </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="N9zj5qpTfqmbn9dro-Tue, 31 Oct 2023 17:58:34 GMT" user-id="N9zj5qpTfqmbn9dro" display-name="Zvi" submitted-date="Tue, 31 Oct 2023 17:58:34 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Zvi</b></section><div><p> Agree with Will on hedging some revolutions - you can do it if you want to intentionally do exactly that and pay a premium to do so, and with sufficient wealth that is a highly reasonable play. Alas AI-induced such things are less likely to play nicely with that kind of move, as Altman noted about his bunker. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 17:59:47 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 17:59:47 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> Yeah I agree you can hedge revolutions historically (to a degree). I&#39;m a bit skeptical that if AI goes badly - or simply ends up being Communist - that storing gold underground will matter much if at all. But I don&#39;t think much hinges on this. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 18:00:43 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 18:00:43 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><blockquote><p> I wanted to point out that if a given stock/sector/etc &#39;misses out&#39; on the explosive growth, then their value rather than staying static could drop quite a bit.</p></blockquote><p> Yes, and this is why in my very first post I suggested something like &quot;own the index fund&quot; - that will automatically rebalance more funds into winners, and the losers get downweighted until they become zero. If you don&#39;t have a <i>very</i> strong thesis about which entire industries will benefit vs not, it really seems like you shouldn&#39;t bet on anything other than &quot;equities in general&quot;</p><p> I&#39;m also happy to do some speculation here about what <i>might</i> out/underperform. For example, I think it&#39;s a pretty good bet that raw materials and refining will become a huge bottleneck in the immediate term. For the run up into rapid growth, before we get huge new supply coming online (will we? what about regulations??), raw materials seem like they could really grow in value...</p></div></section><h2> Debt and Interest rates effects of AGI </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 17:32:28 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 17:32:28 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><p> Let&#39;s focus a bit on the two broadest categories of assets: debt and equity. Debt is (normally) a fixed, known in advance payment, and the yield of that asset is determined by prevailing interest rates plus uncertainty, etc. Equity is the &quot;residual&quot; claim after debts are paid, it allows for unlimited upside, but also it gets paid after all debts so if the business doesn&#39;t perform well the equity side gets nothing.<br><br> High growth usually means lots of profitable investment opportunities. Debt is most useful when it&#39;s paying for something like a fixed capital investment - you know roughly how much money you need, what you need to build, you can assign the capital as collateral for the loan (so the debt gets repaid if the project fails), you have some pretty good guess about how much this investment will pay off over time. A rapidly growing (and effectively brand new) AGI economy will need lots of such investments, and so there will both be good opportunities to invest, <i>and</i> it means that financial capital will become extremely scarce as limited current resources pursue the best projects. Thus we can reasonably assume that interest rates will grow very large. This increase in rates (yields) means that <i>existing</i> debts will lose a lot of value, so it seems risky to hold a lot of current debt/bonds going into this growth period. It also means that having cash on hand could allow your money to grow at an extremely rapid rate.<br><br> This suggests that insofar as you want a cash/bonds portion of your portfolio, you want to keep it as cash invested in extremely short term securities (money market funds, T-bills, etc)<br><br> (A perhaps less obvious implication is that this could make it a lot harder for <i>governments</i> to finance themselves, as they will also be facing an extremely high prevailing interest rate. Their best bet may be to raise taxes and try to balance the budget, which hopefully should be generating lots of revenue in a growing economy... but if they still are reliant on debt financing this could become very difficult.) </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 17:39:03 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 17:39:03 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> I like Will&#39;s point a lot about governments potentially struggling to finance themselves under a much higher interest rate environment. Seems like this - plus widening inequality - could lead to a very large increase in taxes. Possibly this would include previously unheard of things like taxing unrealized gains or a wealth tax. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 17:41:17 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 17:41:17 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><blockquote><p> One worry there is that rising interest rates is not so great for stock prices, so you&#39;d want to consider whether to cover that base.</p></blockquote><p> It&#39;s worth considering the channels by which interest rates hurt stock prices. Insofar as there are better fixed investments, it&#39;s tempting to get a known large return than an uncertain return. But if I had to guess, the returns on investments will (at least initially) greatly exceed the prevailing interest rate, such that equities will grow substantially faster than bonds. Most people will see things like bonds paying 50% annually and notice the stock market more than doubling, and pile into stocks. I don&#39;t think the opportunity cost effect will be sufficient to dissuade people here.<br><br> Another channel is the discounting of future cash flows, eg higher interest rates means that future payments are worth less than current payments. That&#39;s true in a strict valuation sense, but again, you&#39;re also needing to price in growth rates in addition to discount rates. Plus in a rapidly growing environment like this, just the very near term payments alone can justify a large valuation, even if you&#39;re discounting something 10+ years into the future to basically 0. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 17:47:15 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 17:47:15 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Will: I think I am failing to properly follow the equities vs bonds tradeoff here. Let me try to summarize what I think you are saying:</p><blockquote><p> When AGI happens, there might be a lot of growth, so people will want to invest a lot, which means people will want high interest rates on any loans they give out, since they want the interest on those loans to at least match the other investments in returns.</p></blockquote><p> This part makes sense to me. Seems like interest rates in this sense will go up.</p><p> But then I think I am failing to understand how this will differentially affect holding stocks vs. holding bonds. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 17:50:07 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 17:50:07 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><blockquote><p> But then I think I am failing to understand how this will differentially affect holding stocks vs. holding bonds.</p></blockquote><p> Don&#39;t worry, you are not alone in being unclear how interest rates affect stock prices. It seems like there <i>should be</i> a mechanical relationship but it&#39;s not at all certain. I was responding to Zvi&#39;s point that higher rates might also impact stocks. Ultimately I still expect growth to be so large that will outweigh any drag on stocks due to rates. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="N9zj5qpTfqmbn9dro-Tue, 31 Oct 2023 17:42:34 GMT" user-id="N9zj5qpTfqmbn9dro" display-name="Zvi" submitted-date="Tue, 31 Oct 2023 17:42:34 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Zvi</b></section><div><p> Agree with Will that interest rates could rise a lot and that you therefore very much do not want to be holding debt when AI takes off, as existing debt will lose a lot of value if interest rates rise. It is fine to hold things similar to cash to maintain optionality, but you&#39;ll want to do this with short-term instruments. This is one place I have actually put effort in - I keep having to explain I want the floating interest rate, that when I say I don&#39;t want to take risk with my cash I mean that I am afraid interest rates will go up rather than down.</p><p> And to take it one step further, holding long term debt at fixed rates is amazing in that situation, such as a long term mortgage. As a company you would love to have issued bonds, and so on.</p><p> For governments, as was famously asked recently, <a href="https://en.wikipedia.org/wiki/Capital_in_the_Twenty-First_Century">is R>;G</a> ? If real growth is very high, then it is fine for real interest rates to also be high. Also note that governments only refinance slowly as their bonds mature, so if things are escalating quickly, the interest rates on their debt could be well behind the growth rate even if the rate on new debt exceeds the growth rate, making there be less need to raise more revenue. And we should expect major primary surplus to happen on its own.</p></div></section><h2> Concrete example portfolio </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 18:05:07 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 18:05:07 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Ok, I think I want to take a bit of a step back and talk a bit more practicalities.</p><p> In this post &quot;<a href="https://www.lesswrong.com/posts/jvHLBEXXEtZtt4KFP/investing-for-a-world-transformed-by-ai">Investing for a World Transformed by AI</a> &quot; Peter McCluskey has a relatively concrete sets of companies that he thinks will perform well if the world gets transformed by AI. Extracting the most relevant recommendations:</p><blockquote><p> AI companies: Google, [...] OpenAI,</p><p> [...]</p><p> My current semiconductor-related investments are (in alphabetic order): AMKR, AOSL, ASML, ASYS, KLAC, MTRN, LSE:SMSN, TRT.</p><p> [...]</p><p> AMZN, MSFT, and GOOGL are likely to get some benefit from datacenter growth. I guess I&#39;ll expand my GOOGL holdings and buy small positions in AMZN and MSFT sometime in 2023, when I see signs that their stock&#39;s downward momentum has dissipated.</p><p> [...]</p><p> My two biggest solar bets are CSIQ, and SCIA. I have smaller positions in JKS, DQ, SEHK:1799.</p><p> For power grid infrastructure and solar farm construction, I have positions in MTZ, MYRG, PLPC, and PRIM.</p></blockquote><p> These sure are a lot of stock tickers, so I don&#39;t think we should look into each one of those, but I am kind of curious whether you look at this portfolio and it seems vaguely sane to you.</p><p> And then I would like to go into a bit more concrete detail about what you would actually concretely do if you wanted to spend at most like 15 hours on this, but still end up with a portfolio that seems like it does the thing. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 18:06:34 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 18:06:34 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> Habryka&#39;s portfolio seems reasonable enough to me. I think omitting TSM is an impactful decision (and not one I agree with) but other than that it looks solid for a list of tickers.<br><br> If I were to make my own list of stocks worth large-ish positions, I&#39;d say TSM, MSFT, GOOG, AMZN, ASML, NVDA are a good starting point. You can also look at energy producers and raw materials mining/refining. Though with those sorts of companies its a more competitive market and it makes sense to diversify more. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="N9zj5qpTfqmbn9dro-Tue, 31 Oct 2023 18:08:23 GMT" user-id="N9zj5qpTfqmbn9dro" display-name="Zvi" submitted-date="Tue, 31 Oct 2023 18:08:23 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Zvi</b></section><div><p> That portfolio does not include weightings, and has a bunch of [...] in it, and I don&#39;t know what a lot of those companies are or whether they seem cheap, but does not in any way seem insane. I certainly have AMZN/MSFT/GOOGL, although I am not trying to time momentum. Solar seems like a decent place to be for other reasons as well and I have some exposure there, but I haven&#39;t investigated the companies named.</p><p> Semiconductors seem like a good idea if one was doing the work and building from scratch. But also one does not need to hedge bets too carefully on exactly which angle of AI will end up being most profitable - it seems reasonable to aim for where you see the best profits, rather than trying to be too smooth.</p><p> And yes, NVDA seems cheap. Kind of crazy that it&#39;s down substantially from its peak through a strong earnings beat.</p><p> I stay away from TSM due to geopolitical risk, I don&#39;t want it even if it&#39;s properly priced in. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 18:09:52 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 18:09:52 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> To Zvi&#39;s point about geopol risk on TSM, TSM is one of the stocks where I am almost entirely call options in my exposure. I think if you are comfortable trading options - and many people aren&#39;t which is reasonable - a 31% implied volatility is quite cheap. And there aren&#39;t good substitutes for TSM that I am aware of. It plays a pretty unique role in global supply chains I think. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="N9zj5qpTfqmbn9dro-Tue, 31 Oct 2023 18:10:33 GMT" user-id="N9zj5qpTfqmbn9dro" display-name="Zvi" submitted-date="Tue, 31 Oct 2023 18:10:33 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Zvi</b></section><div><p> Yeah, TSM seems like an excellent place to deploy call options if one was willing to use call options. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 18:12:09 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 18:12:09 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Ok, let&#39;s try to dumb things down even more. Let&#39;s say you are a 28 year old male with a few tens of k to hundreds of k to invest who does not have any kind of brokerage account set up. What is the actual concrete thing you would do that would not cause you to accidentally press the wrong button and then somehow lose all your money?</p><p> Some links in response to this also seems fine, though I do feel like this step is one where some reasonable people might get stuck. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 18:12:02 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 18:12:02 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> None of what I said is financial advice but this is: be very careful before clicking any buttons in your brokerage account, and make sure you understand what they do.</p><p> More seriously, people for whom this conversation is a bit technical should avoid trading options or using excessive leverage. It is easy to mess up if you don&#39;t really have the knowledge base and aren&#39;t paying close attention. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 18:13:43 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 18:13:43 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><blockquote><p> And then I would like to go into a bit more concrete detail about what you would actually concretely do if you wanted to spend at most like 15 hours on this, but still end up with a portfolio that seems like it does the thing.</p></blockquote><p> To a first approximation: either go 100% equities, or keep some equities and some cash, with the cash portion invested in short term rates (money market, T-bills, etc) and periodically rebalance.<br><br> The maximally agnostic thing is just the global stock index. Vanguard has an ETF with the ticker VT that&#39;s just all stocks in the world, market cap weighted. Global equities have underperformed US equities for a long time (and we have a <i>lot</i> of tech here), so if you&#39;re a growth instead of a value investor then maybe you want a US total index (VTI) or just the S&amp;P 500 large cap index (SPY).<br><br> The next layer is to spend some time thinking about which areas are likely to outperform in the immediate term. I recommend going long-only, <i>not</i> trying to short any particular areas, given the likely expected increase in growth and uncertainty about where such gains might appear. I mentioned raw materials above, you can get a global raw materials ETF with MXI, or US-only raw materials with IYM. Semiconductors also seems like another clear buy, given what we&#39;ve already observed (though it may now be overvalued and the value will be captured elsewhere after this wave!), and the ticker SMH is a broad semiconductor ETF. You can go down the list on whatever you&#39;re bullish on and find an ETF for that subsector, almost all of them have one, eg for solar you can buy TAN. (Note that these are just common symbols, you might want some other variant on these funds, I&#39;m not specifically recommending these)<br><br> It seems very very risky to invest in individual names, unless you&#39;re monitoring this very closely... </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 18:14:50 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 18:14:50 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> <a href="https://www.lesswrong.com/users/habryka4?mention=user">@habryka</a> I would tell such a person to be between 50-100% equities, mostly indices with a small special allocation to MSFT, and to short long dated bonds if they feel comfortable doing so. If they don&#39;t, then hold whatever they don&#39;t invest in cash/tbills.</p><p> And get a mortgage if they live in Wisconsin or some such place. And don&#39;t go to grad school. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 18:16:49 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 18:16:49 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> Another benefit of call options btw is that you lock in the interest rate. If you are getting your leverage by spot borrowing you need to pay attention to the rate your broker charges cuz it could go up a lot. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="N9zj5qpTfqmbn9dro-Tue, 31 Oct 2023 18:17:15 GMT" user-id="N9zj5qpTfqmbn9dro" display-name="Zvi" submitted-date="Tue, 31 Oct 2023 18:17:15 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Zvi</b></section><div><p> Yeah, let me echo NoahK: All this talk of options needs to take into account that it is VERY easy to click the wrong buttons, to size things 10x or 100x what you thought you were doing, or otherwise get into big trouble, if you wade into options or futures or other things like that. Be sure you know EXACTLY what you are doing, talk to a human to confirm as needed, and so on, and when in doubt stick to the basics. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 18:17:47 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 18:17:47 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><blockquote><p> More seriously, people for whom this conversation is a bit technical should avoid trading options or using excessive leverage.</p></blockquote><p> To briefly address leverage: this could get very crazy in a high rates environment. Leverage is financed via margin loans, and those are almost always the shortest term interest rate + some premium. So if interest rates are already at 50% or something, you&#39;re bleeding half your value every year using 2x margin. This is great of course if the stock market is soaring, but generally stocks don&#39;t only move in one direction, and you could get fully wiped out from a combination of high rates and sidewise to suddenly sharp downwards action. For just one concrete scenario: suppose there&#39;s a new AI-driven trading bot (or a million of them) and we get a flash crash of 75% instantly or something. Everyone doing this will not just be liquidated but also in deep debt to their brokerage. I think leverage is an excellent strategy only in &quot;relatively normal&quot; states of the world. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 18:17:43 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 18:17:43 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Hmm, so I feel like this advice is too conservative. Like, I at least seem to have some beliefs about how big of a deal AI will be that disagrees pretty heavily with what the market beliefs (I think, though this kind of stuff is hard to tell). I feel like I would want to make a somewhat concentrated bet on those beliefs with like 20%-40% of my portfolio or so, and I feel like I am not going to get that by just holding some very broad index funds, which really are the &quot;defer to the market maximally&quot; option. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 18:18:59 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 18:18:59 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> I like &quot;short bonds and make idiosyncratic investments in MSFT, GOOG, NVDA, etc&quot;. It depends on how much risk the 28 year old wants. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 18:20:16 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 18:20:16 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><blockquote><p> I like &quot;short bonds and make idiosyncratic investments in MSFT, GOOG, NVDA, etc&quot;.</p></blockquote><p> Short bonds is a great strategy when you&#39;re in the state of the world where the takeoff is already occurring and everyone realizes it and both growth and rates are skyrocketing already. Personally, I would not be short bonds <i>right now in the current environment</i> , but of course YMMV </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 18:20:22 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 18:20:22 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Ideally there would exist an AI index fund or something I could buy that balances things out for me, but I think that doesn&#39;t exist? And I also don&#39;t mind taking on some risk. Seems fine for that part of my portfolio to go to close to zero in like 50% of worlds, if it properly captures the upside in the other worlds. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="N9zj5qpTfqmbn9dro-Tue, 31 Oct 2023 18:21:17 GMT" user-id="N9zj5qpTfqmbn9dro" display-name="Zvi" submitted-date="Tue, 31 Oct 2023 18:21:17 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Zvi</b></section><div><p> My big difference with Will is that I&#39;m unafraid to buy individual stocks, which also gives you additional tax-related optionality in many cases. You don&#39;t want too much concentration into any one stock, but a 28-year-old doesn&#39;t/shouldn&#39;t have a level of risk aversion where eg being 10% GOOG seems unreasonable, and certainly 5% is fine, if you think that is where the value lies.</p><p> At minimum, if you expect major changes from AI, you&#39;re going to want to be overweight AI-linked stuff, at some level of magnitude and obviousness. If nothing else there are sector ETFs for such things, but mostly the stocks are obvious and I&#39;d look at those. Again, small mistakes here really are fine in expectation.</p><p> Shorting bonds is again a more advanced move. It does seem like if the premium to do it isn&#39;t too big it would have alpha, but it can definitely backfire - interest rates dropping for a few years before they rise does not seem so unlikely to me. The worst case scenario is you lose money by being too early, then you&#39;re right later but you have no capital to profit from being right later. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 18:22:06 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 18:22:06 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> I think the yield curve right now is flat and it will be upward sloping before we&#39;re done with everything. And I don&#39;t think Powell can cut rates. But this gets far afield of AI.</p><p> Probably the best risk adjusted trade imo is to like long 10 year bonds and short 20 year bonds in no more than a 2:1 ratio. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 18:23:09 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 18:23:09 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><blockquote><p> Ideally there would exist an AI index fund or something I could buy that balances things out for me, but I think that doesn&#39;t exist?</p></blockquote><p> Oh they definitely exist! Don&#39;t underestimate the marketing power of these big fund managers lol<br><br> iShares has one under ticket IRBO. Let&#39;s see what it holds... Looks like very low concentration (all &lt;2%) but the top names are... Faraday, Meitu, Alchip, Splunk, Microstrategy. (???) </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 18:23:13 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 18:23:13 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Very quick question: What brokerage thing do you actually someone like me should use? </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 18:23:40 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 18:23:40 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> Interactive Brokers is the best brokerage if you know what you are doing. They have terrible UI but the best margin rates. Other brokers will rip your face off when you borrow cash.</p><p> If you don&#39;t want to learn to use terrible UI, you can use Fidelity or Schwab or something I hear. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 18:23:46 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 18:23:46 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><blockquote><p> They have terrible UI but the best margin rates.</p></blockquote><p> Lol, I feel like that is the wrong tradeoff to make when I am worried that I will lose all my money by pressing the wrong button. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 18:29:26 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 18:29:26 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><blockquote><p> My big difference with Will is that I&#39;m unafraid to buy individual stocks</p></blockquote><p> I&#39;m open to buying individual stocks, but it&#39;s very difficult for me to recommend specific stocks to other people under extreme uncertainty! How can an average investor with &lt;15 hours of research as Oliver stipulated know they&#39;re doing anything with positive expected value over buying a broad index? Anything that&#39;s a mega-winner will in fact get captured by a broad index fund.<br><br> I do think it&#39;s fine for younger more risk seeking people with time on their hands to give this some thought and pick individual stocks. If nothing else you will <i>learn</i> a lot by doing this, both about markets and about your psychology, and it can incentivize you to learn more about the companies in question once you have skin in the game. That said, I would never let your index fund exposure go to 0 in favor of individual stocks, just to avoid the risk of ruin that you captured none of the eventual winners.</p><p> To be very clear: I&#39;m not even certain that most/all value will be captured by a single megacorporation. It could be that several thousand companies each generate a trillion dollars in value or something. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 18:30:01 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 18:30:01 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> (As a quick anecdote here, a while ago I tried to figure out what would happen if you just blindly followed all stock-advice that was upvoted on LessWrong. So I set up a virtual trading portfolio on some random website I found and maintained it for a few months. One of the biggest positions I took out was to short Nikola based on some upvoted post at the time. Within a few months that position had grown to 60%+ of my portfolio as the shorting had gone quite well and had appreciated like 300% or so.</p><p> Then I stopped checking for 2 months, and then when I checked in again, suddenly that whole investment went to 0...</p><p> Turns out the virtual portfolio website didn&#39;t execute your options automatically even if they were in the green, so they had expired and become worthless.</p><p> This is one reason why I am afraid of clicking a wrong button and losing all of my money) </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 18:31:11 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 18:31:11 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> Oh no that is quite unfortunate! Yes if you buy options I recommend setting an alert when you buy them that will go off like a week before expiry. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="N9zj5qpTfqmbn9dro-Tue, 31 Oct 2023 18:38:18 GMT" user-id="N9zj5qpTfqmbn9dro" display-name="Zvi" submitted-date="Tue, 31 Oct 2023 18:38:18 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Zvi</b></section><div><p> On individual stocks, I think that especially if you know the companies in question but also in general, you don&#39;t need 15 hours on each company to know that it is likely a real company making real things with good prospects at a reasonable price or P/E, and if you bought index funds you&#39;d be buying that stock anyway. As long as you don&#39;t go too big on any one stock that way, it seems... fine. I&#39;ve never spent 15 hours looking at a stock ever.</p></div></section><h2> Is any of this ethical or sanity-promoting? </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 18:31:02 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 18:31:02 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Ok, I think I would like to cover another topic that is related, which is something like: <strong>&quot;Ok, but is investing in this way ethical? Also, will it mess up your ability to think sanely about this stuff and try to slow down AI when that will directly hurt your bottom line?&quot;</strong> </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 18:34:04 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 18:34:04 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Like, I&#39;ve been trying to <a href="https://www.lesswrong.com/posts/Be3ertyJfwDdQucdd/how-should-turntrout-handle-his-deepmind-equity-situation">convince some of my friends working at AGI companies to somehow get rid of their equity position</a> , since I do think at that level of exposure it pretty seriously messes with your ability to think clearly (not as much as the social environment of the AGI company, but I think still a good amount).</p><p> I think holding Google or Nvidia with a huge fraction of your portfolio probably has similar effects, though my guess is as you get more diffuse than that, the effects get weaker. But like, many people I know are actively advocating for pretty aggressive government interventions that does feel like the kind of thing that could seriously hurt returns, and there might be surprisingly large effects here, even at a pretty broad level. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 18:36:09 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 18:36:09 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> I think for the vast majority of investors, your portfolio choices don&#39;t impact the world in any meaningful way. (Though they may impact how <i>you</i> think about things and evaluate risk.)</p><p> If you are a billionaire, yes, I would encourage you to consider social welfare aspects of your AI investments. It would be good if these companies faced higher costs of capital, and buying a stock serves to lower the cost of capital of the company you purchase. But if you are a 28 year old tech worker do what you must to protect yourself, imo. The capacity to harm the world through your investments is quite limited at that level. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 18:36:14 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 18:36:14 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><blockquote><p> Ok, but is investing in this way ethical?</p></blockquote><p> I agree it seems more questionable if you&#39;re, say, giving the seed investment to a new AGI startup that&#39;s all capabilities and disdains any idea of safety. But one thing that&#39;s nice about my index fund approach here is that you can benefit from the downstream economic gains, without favoring any particular actor.</p><p> There is also a very loose, not zero, connection between investing in the secondary market (buying existing stocks, not companies issuing new stock to raise money) and how that flows through to advancing a corporation&#39;s interests. If a company is regularly issuing stock to finance their activities, then yes, if you raise their stock price on the margin then they can finance themselves more than if they have a low stock price. But what about companies who haven&#39;t issued new equity since the IPO? Does them having a high stock price make their company run better/faster towards AGI? That seems very tentative. I guess there&#39;s a channel by which you&#39;re making it more profitable for individual employees with lots of talent to go work there, when they&#39;re paid largely in stock options instead of cash? </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 18:38:31 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 18:38:31 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><blockquote><p> But what about companies who haven&#39;t issued new equity since the IPO?</p></blockquote><p> To play the devil&#39;s advocate here for a second: most big tech companies working on AI do in fact issue new equity annually, not to sell to investors, but as equity compensation for employees. This can actually amount to several %/year for many of those companies, which is quite dilutive over the long run! So yes, equity price can matter when you&#39;re at a company that&#39;s giving you the majority of your expected comp in options. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 18:38:45 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 18:38:45 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><blockquote><p> I guess there&#39;s a channel by which you&#39;re making it more profitable for individual employees with lots of talent to go work there, when they&#39;re paid largely in stock options instead of cash?</p></blockquote><p> Yeah, I feel a bit confused about the relationship here. I guess I kind of feel like the cost of raising capital of any kind should be roughly tracked by the stock price?</p><p> But also, yeah, it does just make it cheaper for them to hire people. For most tech companies their stock compensation package is like 50% of their salaries, and most of their expenses are salaries, so that should pretty directly equate more capital. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="N9zj5qpTfqmbn9dro-Tue, 31 Oct 2023 18:44:40 GMT" user-id="N9zj5qpTfqmbn9dro" display-name="Zvi" submitted-date="Tue, 31 Oct 2023 18:44:40 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Zvi</b></section><div><blockquote><p> Ok, but is investing in this way ethical?</p></blockquote><p> It depends on the details, but typically I would say yes. There are exceptions. If you are investing in private companies or where you can impact cost of capital in a meaningful way, like OpenAI or Anthropic, then I would say investing there has ethical concerns.</p><p> But Microsoft and Google are not like that. They already have infinite war chests and are not going to be spending more or less money on AI based on your investment. Nor is Nvidia going to do anything but maximize along its capacity and scaling constraints, money isn&#39;t a factor. I think buying such stocks is fine.</p><p> Even when they issue stock options, they are going to scale to the price, and your impact is rather minimal all around. I think you can safely ignore such factors. Assume they have infinite war chest size when it comes to hiring, and salaries and compensation are constrained only by social forces.</p><p> If you are worried, you can go case by case - when you invest in Solar companies you are plausibly helping them in a real way, which is potentially bad for AI on the margin but also good for other reasons (eg climate and general goodness).</p><p> The impact on your incentives is distinct. I don&#39;t worry about this at all, because I know that it is at best a small hedge of my real exposures and it won&#39;t change anything. For someone with big exposure to private stock in OpenAI, there could be a problem there.</p></div></section><h2> How would you actually use a ton of money to help with AGI going well? </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 18:44:34 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 18:44:34 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Ok, this is kind of a tangent from the core topic, but it also feels important.</p><p> So let&#39;s say that there are a bunch of people concerned about existential risk, who invest well in the run-up to AGI, and now they have a few hundred billion dollars or so in-aggregate.</p><p> Assuming that it&#39;s hard to use money to make more AI Alignment progress, is there any way you could use that money to slow down AGI companies or something like that? Like, I do think a major question for me in this investment situation is whether I actually have use for a giant pile of money when AGI happens. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 18:44:53 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 18:44:53 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> If you can drive up the price of the factors of production, you might be able to slow progress. Maybe a consortium of bidders could make some rare earth metals more expensive? Idk about the technical details.</p><p> I would <i>not</i> short high growth AI stocks to drive up their cost of capital since you&#39;ll just get blown out quickly. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 18:46:05 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 18:46:05 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><blockquote><p> Assuming that it&#39;s hard to use money to make more AI Alignment progress, is there any way you could use that money to slow down AGI companies or something like that?</p></blockquote><p> One strategy that has been discussed is to pay top talent to not make AGI. If you&#39;ve truly outperformed the market, you should be able to pay above-market rates to researchers and developers.</p><p> That said, I expect the motivations of folks working on this stuff to be only partly monetary, and if they&#39;re already individually wealthy and have satisficed on the major life stuff, they might just keep working on it for glory or whatever other motivation, so I suspect this will be less successful than people presume. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 18:48:14 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 18:48:14 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> Thinking about it more, the best strategy might be to donate to politicians who are already sympathetic. The government has guns and stuff and is good at stopping people from doing things. And donations can make a difference to policy. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 18:48:36 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 18:48:36 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><blockquote><p> If you can drive up the price of the factors of production, you might be able to slow progress.</p></blockquote><p> Yes this is the generalization of my suggestion about buying up the top talent. Anywhere a resource constraint exists, you could in theory pay extra in order to sequester that resource.</p><p> Of course, once you do that, and the price rises, you&#39;ve incentivized the market to find new and cheaper ways to bring more supply online. So I think that this strategy at best slows things down in the short term, and possibly speeds them up in the long term. But if you think the only thing that matters/exists is the short term, then it&#39;s certainly one tool in the toolkit... </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="N9zj5qpTfqmbn9dro-Tue, 31 Oct 2023 18:50:54 GMT" user-id="N9zj5qpTfqmbn9dro" display-name="Zvi" submitted-date="Tue, 31 Oct 2023 18:50:54 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Zvi</b></section><div><p> Lobbying the government, backing candidates, public advocacy or other things in such categories are obvious options where you could spend quite a lot. That would be where my first move would be. Politics always feels icky but ultimately is not something one can ignore.</p><p> Buying up top talent also seems like a great move if you can target it well, and presumably you can also put that talent to some good use (alignment, or if not then something else, top talent is almost always cheap even when it&#39;s expensive). </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 18:50:14 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 18:50:14 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Yeah, I do feel kind of icky about the lobbying point. It feels pretty symmetric in that it&#39;s been a way in which historically people have prevented tons of good stuff from happening in a way that didn&#39;t really expose them to accountability (regulatory capture being the more common path, but also all kinds of dumb safety regulations). </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 18:51:46 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 18:51:46 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><p> I just want to point out that we didn&#39;t even mention crypto once :)</p></div></section><h2> Please diversify your crypto portfolio </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 19:00:24 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 19:00:24 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Talking about crypto, via historical circumstance I sure have a lot of friends who are holding a really quite substantial fraction of their portfolio in cryptocurrency. I am actually interested in a quick digression on what you expect to happen to crypto prices if AGI takes off (at least in parts because I often wish my surrounding ecosystem was betting making a less concentrated bet on crypto and this particular domain might sway some people who otherwise have been pretty steadfast in their hodling). </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 18:53:30 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 18:53:30 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><p> Just to make the briefest possible case: does cryptocurrency/blockchains solve a specific problem that future AGIs are likely to have? I think there&#39;s actually a good chance that AIs can utilize these features way better/more easily than humans can. Digital representation of scarcity could be highly valuable. Also automatically-enforceable smart contracts might end up as a primary means of coordination between AIs. :) </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 19:00:02 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 19:00:02 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><p> Note that the strongest case against cryptocurrency here (other than that it has no value or use at all) is that holding non-yielding or low-yielding assets suffers extreme opportunity cost in a world of very high real rates. For example, gold tends to trade inversely to real interest rates (higher rate ->; lower price). So bitcoin in particular could have major issues in that regard. Ethereum or another more flexible system could potentially do something like raise the staking yield or something to try to keep up with interest rates (though of course that&#39;s dilutive to current holders). Basically you&#39;re relying on use cases providing major value at the point of AGI takeoff... </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 19:00:48 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 19:00:48 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> So my basic take is that anyone holding a lot of crypto as a % of their wealth, but not so much that they&#39;d face liquidity issues in selling, is doing something very wrong. This is not to say people shouldn&#39;t own BTC or ETH or whatever. Some crypto is fine.</p><p> But basic portfolio theory suggests that if you have an extremely large % of your portfolio in an asset with extremely high idiosyncratic volatility, you can get better returns by diversifying (and then using more leverage if you want).</p><p> I&#39;m not against owning crypto but 50%+ allocation to ETH - which I think you mentioned - would be very suboptimal for almost anyone. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="c3Ji9Th6jATRyHLFC-Tue, 31 Oct 2023 19:00:40 GMT" user-id="c3Ji9Th6jATRyHLFC" display-name="Cosmos" submitted-date="Tue, 31 Oct 2023 19:00:40 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Cosmos</b></section><div><p> Thanks Oliver for having me in the dialogue! I need to drop off now, but I&#39;m honored to have been asked to participate, and this was a lot of fun and very thought provoking! Great talking to you Zvi and Noah, and I&#39;m looking forward to future dialogues! </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 19:02:18 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 19:02:18 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Thank you Will! Really appreciated your thoughts here! </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hsdsBxMSKELfnYswF-Tue, 31 Oct 2023 19:12:18 GMT" user-id="hsdsBxMSKELfnYswF" display-name="NoahK" submitted-date="Tue, 31 Oct 2023 19:12:18 GMT" user-order="4"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>NoahK</b></section><div><p> I&#39;ve got to run now as well but thank you for inviting me! It was great chatting with everyone. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 19:12:35 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 19:12:35 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Thank your joining Noah!</p></div></section><h2> Should you buy private equity into AI companies? </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 19:12:11 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 19:12:11 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> So, as we&#39;ve noted it&#39;s pretty hard to buy stock that&#39;s actually loaded on AGI companies, since most companies working directly on this stuff are either private (OpenAI, Anthropic) or are part of a giant tech company that mostly does non-AI stuff (Microsoft, Google).</p><p> So a thing one might try to do is to get access to the private equity. For example, by buying it off of employees who have been there for a while.</p><p> Does this seem like a good idea from a financial perspective? Also, the incentives question here does seem more pronounced than for the other things we&#39;ve been talking about. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="N9zj5qpTfqmbn9dro-Tue, 31 Oct 2023 19:13:54 GMT" user-id="N9zj5qpTfqmbn9dro" display-name="Zvi" submitted-date="Tue, 31 Oct 2023 19:13:54 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Zvi</b></section><div><p> It seems likely that private equity in eg OpenAI or Anthropic would trade cheap to the extent that it traded privately, so the concern here is ethical rather than financial. At which point, it depends who you buy it from, what incentives you are changing in what places, and whether or not you can serve a &#39;dead on the cap table&#39; purpose without too much driving up the price. I don&#39;t know enough to know the answers for sure, but until I had a better idea I would try and stay away. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 19:15:39 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 19:15:39 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Yeah, that does also feel right to me. I have been thinking about setting up some fund that maybe buys up a bunch of the equity that&#39;s held by safety researchers, so that the safety researchers don&#39;t have to also blow up their financial portfolio when they press the stop button or do some whistleblowing or whatever, and that does seem pretty incentive wise.</p><p> I do think sadly companies often have explicit agreements with employees that prevent them from hedging their equity positions, so this might be hard.</p></div></section><h2> Summarizing takeaways </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 31 Oct 2023 19:15:58 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 31 Oct 2023 19:15:58 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><div><p> Ok, I feel like after participating in this, I feel like I at least have a decent handle on constructing some kind of portfolio here.</p><p> I will think about this for a few days, but I feel like if I was implementing the advice here, I would roughly:</p><ul><li> Go and make a brokerage account with Schwab or Fidelity (whichever seems less annoying to set up)</li><li> Invest like 50% of my portfolio into pretty broad index funds with really no particular specialization</li><li> Take like 20% of my portfolio and throw it into some more tech/AI focused index fund. Maybe look around for something that covers some of the companies listed here on the brokerage interface that is presented to me (probably do a bit more research here)</li><li> Invest like 3-5% of my portfolio into each of Nvidia, TSMC, Microsoft, Google, ASML and Amazon</li><li> Take like 2-5% of my portfolio and use it to buy some options (probably some long-term call options on some of the stocks above), making really sure I buy ones that have limited downside, and see whether I can successfully not blow up that part of my portfolio for like 2 years before I do any more here</li></ul><p> And then I probably wouldn&#39;t bother much with rebalancing and basically forget about it unless I feel like paying much extra attention.</p><p> <i>(Zvi, Noah, and Will each seemed to think was a non-crazy plan when I said the above on the call we were on while writing this dialogue)</i></p></div></section><div></div><br/><br/> <a href="https://www.lesswrong.com/posts/CTBta9i8sav7tjC2r/how-to-hopefully-ethically-make-money-off-of-agi#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/CTBta9i8sav7tjC2r/how-to-hopefully-ethically-make-money-off-of-agi<guid ispermalink="false"> CTBta9i8sav7tjC2r</guid><dc:creator><![CDATA[habryka]]></dc:creator><pubDate> Mon, 06 Nov 2023 23:35:16 GMT</pubDate> </item><item><title><![CDATA[cost estimation for 2 grid energy storage systems]]></title><description><![CDATA[Published on November 6, 2023 11:32 PM GMT<br/><br/><h2> CO2 mitigation costs</h2><p> With modern gas turbines, burning natural gas makes perhaps 0.4 kg CO2 per kWh. I generally use $75/ton as a baseline target for CO2 mitigation costs; that&#39;s around what you see from various reasonable approaches like biomass conversion. $75/ton * 0.4 kg = $0.03/kWh. Maybe that seems cheap to those of you living in California, but it&#39;s a large fraction of the cost of generating electricity in the US. (People in California are now paying >;$0.30/kWh, mostly because of corruption, and also lawsuits for fires from poor maintenance from corruption.)</p><p> So, $0.03/kWh is the target that should be met for the CO2 mitigation benefit of replacing natural gas with (energy storage systems + renewables). There can be other benefits that justify extra costs:</p><ul><li> If renewables are cheaper than eg natural gas, then that cost difference is compensation for storage costs. But of course, other power sources would probably still be needed for longer periods of low generation, and their cost per kWh probably increases when they&#39;re used less.</li><li> Small systems that can store energy locally can provide backup power when electricity grids are down.</li><li> Batteries can smooth out short-term power fluctuations.</li></ul><p> But for the CO2 mitigation part, I think of ~$0.03 as being the target.</p><p> The grid energy storage systems I&#39;m most optimistic about are (currently) water-compensated compressed air energy storage, and (for the future) chelate flow batteries. Below, I&#39;ll go through some of my cost estimation for those.</p><h2> Li-ion grid storage is expensive</h2><p> A couple years ago Tesla was charging $265/kWh for just grid storage batteries, not including transformers, power lines, buildings, etc. (Yes, BloombergNEF costs were lower, those were biased by Chinese subsidies.) $265 / $0.03 is obviously at least 8833 cycles, and presumably more due to maintenance costs and interest rates.</p><p> Li-ion batteries do not last for 8833 cycles, especially if you charge and discharge them once a day. LiFePO4 battery lifetimes are generally overstated for grid storage applications, because a SEI layer forms over time from reaction with electrolyte, and charge cycles crack that, so there&#39;s an interaction between cycle life and calendar aging which makes battery life shorter than either individually. Some people were acting on the assumption that Li-ion battery prices would decline according to a linear regression to below $100/kWh, but over the last year they actually went up. (This isn&#39;t the main point of the post, just context, and I&#39;m not going to argue about it again here.)</p><p> There are lots of other proposed systems: various hydrogen systems, Form Energy, vanadium flow batteries, zinc flow batteries, gravitational energy storage, etc. When I say I&#39;m most-optimistic about some particular systems, I don&#39;t mean &quot;these are the systems I&#39;ve heard of that I like the best&quot;. What I mean is that I understand the entire conceptual space and every serious proposal, and those designs seem like the best ones that current human societies are able to develop. If that wasn&#39;t the case, I wouldn&#39;t be writing this post.</p><h2> compressed air</h2><p> Gas turbines compress, heat, and expand air; you can store the compressed air for a while instead, but it gets hot from compression and storage wastes that heat. There are <a href="https://en.wikipedia.org/wiki/Compressed-air_energy_storage#History">existing CAES systems</a> using that approach. Efficiency and cost-effectiveness have not been great, despite also using natural gas. It&#39;s possible to store the heat so it&#39;s not lost, but that&#39;s more expensive.</p><p> Compressed air can be stored cheaply in salt caverns made by solution mining, but the variable pressure is really bad for efficiency because it changes the turbine conditions and the pressure changes cause temperature changes. Also, this limits location options.</p><p> It&#39;s possible to get constant-pressure compressed air storage by filling the storage chamber with water. A simple way to do that is to have a water reservoir on the surface, and an underground chamber at a depth where water pressure matches air pressure. <a href="https://www.youtube.com/watch?v=cOWjwwKSR78">Here&#39;s a video</a> from Hydrostor, a startup pursuing this approach. But this introduces new issues.</p><hr><p> If putting water in and out of a storage chamber, the chamber has to be waterproof, so it can&#39;t be made of salt. Mining hard rock underground in controlled shapes is expensive. For hard rock, mining costs are something like:</p><ul><li> solution mining in suitable salt caverns: ~$25/m^3</li><li> surface pit: ~$300/m^3</li><li> <a href="https://www.youtube.com/watch?v=MWqMD85MVO4">block caving</a> : ~$400/m^3</li><li> stoping: ~$1300/m^3</li></ul><p> I&#39;d say &quot;stoping&quot; is the mining type most similar in difficulty to making underground caverns for CAES.</p><p> Underground hard-rock mining generally uses drill-and-blast, but blasting is often banned under cities, which is a big part of why tunnel boring machines are used. If you want to build storage locations in cities, that&#39;s a problem. There are non-explosive approaches, such as <a href="https://www.youtube.com/watch?v=g85K6SdD9aM">roadheaders</a> , hydraulic breakers, and (disc cutter) tunnel-boring machines, but for hard rock, drill-and-blast is the cheapest, which is why mining uses it. Roadheader mining costs vary greatly with rock properties; for coal they&#39;re cheaper than blasting, but for very hard rock they&#39;re very expensive, because mining speed goes down and the carbide picks wear out faster.</p><p> For 70 bar pressure, you need 700m of water; this is a normal depth for underground mining, not a big problem, but small excavations at that depth are too expensive. Each CAES storage site would have to be large to keep costs down.</p><p> Another issue is that a little bit of high-pressure air can dissolve in water. If pressure drops cause water with dissolved gas to bubble, that decreases the hydrostatic pressure, and causes bubbling water to spout upwards - the &quot;champagne effect&quot;. But this issue <a href="https://www.osti.gov/biblio/6621019">seems solvable</a> .</p><p> Some cost improvements do seem possible:</p><ul><li> Perhaps it&#39;s possible to use solution-mined salt caverns, by using a little extra effort to get them in the right shapes, then adding plastic or concrete linings.</li><li> A guy I know has been working on non-explosive mining machine designs, and says systems he calls &quot;Grond&quot; and &quot;Undine&quot; could do non-explosive hard-rock mining for &lt;$700/m^3. (Rock fracture dynamics are actually very complex and interesting, or at least so I&#39;m told.) Per the names, they involve impact hammers and water. Those designs do seem like they could basically do what The Boring Company had hoped to but failed at, so let me know if somebody wants that.</li></ul><hr><p> Energy in compressed gas is an integral of 1/x, so energy = volume * pressure * ln(pressure). At 70 bar, 1 m^3 is 8.26 kWh. Of course, that has to be adjusted by temperature when expanded and by turbine efficiency. For now, let&#39;s suppose you get 9 kWh. Assuming everything underground costs as much as stoping, you&#39;re already up to $144/kWh capacity, and you need a reservoir on the surface too. Supposing reservoirs are cheap, we amortize costs over 10 years, and average 75% charge/discharge per day, that&#39;s ~$0.055/kWh.</p><p> Considering the cost of electricity from natural gas, and the fact that we don&#39;t need high-temperature turbine blades, we can suppose turbines only cost $0.005/kWh if run continuously. Supposing a 1/4 duty cycle, that&#39;s $0.02/kWh. Let&#39;s say the renewable power lost from inefficiency is worth $0.01/kWh output.</p><p> We also need heat exchangers, and those could be more expensive than the turbines. Supposing $2 per W/K and a 10° gradient, that&#39;s $200/kW, perhaps $34/kWh for 1-day storage. Let&#39;s say the heat exchangers add $0.01/kWh. Then you need something to store the heat, but water is cheap so let&#39;s just ignore that for now. Heat exchanger cost also depends greatly on manufacturing methods, temperature, and pressure; gasketed plate heat exchangers for warm water are cheaper than high-temperature shell-tube heat exchangers for gas turbines.</p><p> Instead of using heat exchangers and some fluid, another option is sending compressed air through beds of eg sand. Such &quot;packed bed heat storage&quot; might seem cheaper, but <a href="https://www.sciencedirect.com/science/article/abs/pii/S1359431117375075">this paper</a> estimated ~$0.0685/kWh stored for packed bed heat storage - just for the tanks, rocks, and insulation. So, this approach is probably more expensive than using fluids but allows for higher temperatures.</p><p> We&#39;re now up to ~$0.095/kWh incremental cost over generation. That&#39;s too high to be competitive for CO2 mitigation, and installations have to be large - but it&#39;s sort of competitive with nuclear power costs. I think better mining methods and various other improvements could plausibly bring that down to $0.06/kWh. There are lots of details to those potential improvements but that&#39;s good enough for this post.</p><h2> flow batteries</h2><p> Let&#39;s estimate the cost of electrolyte for a chelated chromium-iron flow battery. <a href="https://en.wikipedia.org/wiki/Ethylenediaminetetraacetic_acid">EDTA</a> is a common chelation agent; it doesn&#39;t actually work well for this, but it&#39;s a good enough approximation for production costs at large volumes.</p><ul><li> 1 mol of Cr is ~$0.50</li><li> 1 mol of EDTA is ~$0.70</li><li> at 2 volts, 1 mol of electrons is ~0.054 kWh</li></ul><p> So, Cr and EDTA is only ~$22/kWh. The iron side would probably be cheaper, maybe half as much. So, electrolyte costs for flow batteries seem potentially very reasonable. The real problem is the cells that electrolyte would run through.</p><p> Batteries involve immobile materials with variable charge state, and mobile ions with constant charge. Normally, the variable charges are insoluble in a liquid, but flow batteries are defined by everything being soluble, which means ion-selective membranes are needed. Those membranes are obviously more expensive than liquid, and they make flow batteries more expensive than regular batteries per watt.</p><p> Nafion (or Aquivion) membranes are fluorinated and expensive. There are lots of papers on cheaper membranes with somewhat better conductivity, so why aren&#39;t they used? Those papers generally don&#39;t say, but it&#39;s because they&#39;re not durable enough. The membranes have a tendency to get oxidized or broken apart, which is (mostly) why the expensive fluorinated ones are used. But there is a new-ish type of membrane that I think is promising: <a href="https://pubs.rsc.org/en/content/articlehtml/2021/ma/d1ma00511a">sulfonated phenylated polyphenylene</a> . That seems suitable for hollow-fiber membranes.</p><p> With current membranes and current densities, and some rough estimation of other costs, and extrapolation from current systems like vanadium flow batteries, cells for chelated iron-chromium flow batteries seem ~$2000/kW for 90% efficiency, with large-scale production. That&#39;s too expensive. But with cheaper membranes and large-scale production, I think flow batteries could realistically be made for $300/kW, which might be $50/kWh for 1-day storage, not including the electrolyte. (Water desalination plants are much cheaper than that per membrane area, but also simpler. Still, they&#39;re useful as another reference point.)</p><p> That&#39;s a lower cost than CAES, but perhaps an even bigger advantage is that they can be smaller and placed more flexibly. Flow battery systems could provide local backup power, which obviously has some extra value. (Salty water isn&#39;t flammable, unlike Li-ion batteries, so there are fewer safety issues.) Placing storage where electricity is used would also reduce the number of power conversions. Even if homes have batteries, rooftop solar still doesn&#39;t make economic sense without subsidies, but solar panels over parking lots is only slightly more expensive than in open fields.</p><h2> seasonal storage</h2><p> So far I&#39;ve talked about 1-day storage, which helps with the sun not shining at night. It doesn&#39;t help with longer periods with little sunlight and wind, which can happen in the winter in Europe.</p><p> Storing compressed hydrogen or naturals gas in underground salt caverns has very cheap storage capacity, cheap enough for seasonal energy storage, but converting between electricity and hydrogen is much too expensive. Hydrogen fuel cells are expensive enough that burning it in gas turbines is better. I can&#39;t see this being economically practical, and I don&#39;t expect hydrogen from water electrolysis to be &lt;$4/kg (before subsidies) anytime soon; see also <a href="https://www.bhauth.com/blog/chemistry/electricity%20to%20chemicals.html">this post</a> .</p><p> If you&#39;d need more than 5 days of energy storage, and can&#39;t use natural gas or coal, and don&#39;t have enough land to get that energy from biomass, I don&#39;t see anything potentially competitive with nuclear power.</p><br/><br/> <a href="https://www.lesswrong.com/posts/xsjxrmoFqKevAj2Aj/cost-estimation-for-2-grid-energy-storage-systems#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/xsjxrmoFqKevAj2Aj/cost-estimation-for-2-grid-energy-storage-systems<guid ispermalink="false"> xsjxrmoFqKevAj2Aj</guid><dc:creator><![CDATA[bhauth]]></dc:creator><pubDate> Mon, 06 Nov 2023 23:32:03 GMT</pubDate> </item><item><title><![CDATA[A bet on critical periods in neural networks]]></title><description><![CDATA[Published on November 6, 2023 11:21 PM GMT<br/><br/><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 22:05:59 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 22:05:59 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><p> Hey Garrett! I hear you have some new empirical results. What&#39;s the setup? </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 22:09:20 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 22:09:20 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>So I&#39;ve told you my theory about how critical periods work. What I did is replicate the <a href="http://arxiv.org/abs/1711.08856">paper</a> , and then found another problem in my math, which flips the direction that <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>should go as you increase the epochs, and I got this neat looking graph </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/f3jamqlkpjlylprzg1wq" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/rxgj4equest3vhhoxphh 80w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/cfzn6pwztfxfbdqguilz 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/nqcfrs3kfd2shg5zjzu1 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/dh86e0ubgc2hluy7iyt7 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/xlzyxsc6v0prhj2isaum 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/rig8cnq8fekvhhk2bzg0 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/yedqpuwpjcxlq2chgwj1 560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/v7esh6abnofzm4uybcjs 640w"></figure></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 22:11:13 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 22:11:13 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>(The right scale should be the local learning coefficient, not the loss) </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 22:16:42 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 22:16:42 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><p> Let me give my rough summary of how you&#39;re thinking about critical periods.</p><p> In human developmental psychology, a <a href="https://en.wikipedia.org/wiki/Critical_period">critical period</a> is a period where the brain is particularly good at learning something, and may not be able to learn it in the future.</p><p> There&#39;s also a paper you&#39;re interested in, that takes some neural networks learning the classification task CIFAR 10 (which asks the network to classify images as aeroplanes, automobiles, birds or one of another 7 categories). It blurs the images in the training data up to some epoch, then unblurs them afterwards. After some epoch, unblurring the images isn&#39;t sufficent for the network to converge towards the performance of a network that was trained on unblurred images for the whole time.</p><p> There&#39;s some hope that singular learning theory can predict when this &quot;critical epoch&quot; will be, by looking at the RLCT of the network parameters during training. I&#39;m unclear on if that&#39;s in the original paper, or from you.</p><p> Does that sound roughly right? </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 22:20:25 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 22:20:25 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>Yes, though with respect to the hope that singular learning theory can predict when the critical epoch is, I think that&#39;s not <i>so</i> likely, though it definitely does seem more responsive to &quot;something&#39;s going on&quot; than the train loss or validation loss at the blur removal: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/fynahavzdes3scapnlgw" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/fombxvfkgic0loeqg25u 80w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/y1u7f8yn61qg7wc4ykpb 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/urtonslmszoetyx2kiiq 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/stoztjguxzihqkyalwfk 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/zc8d0tcjbpckogkjnxlp 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/mocazr79tqjzntlvacz5 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/oylrudppjxbqo8wyxv64 560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e8r8Tx3Hk7LpnrMwY/dxoik5cypnuxgyho7ax6 640w"></figure><p> which sorta just seem to be behaving business as usual. But we aren&#39;t at the point yet where we can say exactly when the critical epoch is, and I don&#39;t expect us to be there immediately. The main immediate point of this investigation is to think of a way that critical periods can be thought of in terms of SLT, then see if we can pump out even the smallest smidgeon of predictions out of that picture using the very limited experimental apparatuses of current singular learning theory. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 22:23:01 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 22:23:01 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><p> As far as I can see, both the train loss and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span></span></span></span></span></span> look like they&#39;re fairly symmetric with the final validation accuracy (with train loss having a trivial symmetry), but that&#39;s the main connection between the properties of interest that I see. What do you see? </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 22:28:43 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 22:28:43 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>It seems like the train loss is monotonically decreasing, and looks no different from any other train loss, while the lambdahat seems to increase with the final validation accuracy&#39;s decrease, until that final validation accuracy levels off, then it levels off. Maybe there&#39;s a small kink at 150 of the train loss, but if you showed me that train loss I&#39;d think nothing of it, and if you showed me the lambdahat I&#39;d say &quot;looks like something weird is happening&quot; </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 22:30:09 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 22:30:09 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><p> And what&#39;s the weird thing in particular that&#39;s happening? Like, what would a more normal thing be for it to do? </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 22:32:34 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 22:32:34 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>Normally it should just stay relatively in the same location, I thought I made a graph of normal lambdahat, but then I recently realized it kinda sucked. It was trained for too few epochs, and there were numerical instability issues with the calculation leading to wacky lambdahats </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 22:34:42 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 22:34:42 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><p> Yeah I remember Arjun <a href="https://www.lesswrong.com/posts/PDz68D5vQQgacAwoF/estimating-effective-dimensionality-of-mnist-models">mentioning</a> it&#39;s easy to get wacky <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat{\lambda}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span></span></span></span></span></span> s. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 22:35:32 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 22:35:32 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>The default hyperparameters work a lot of the time, but yeah </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 22:35:47 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 22:35:47 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><blockquote><p> see if we can pump out even the smallest smidgeon of predictions out of that picture using the very limited experimental apparatuses of current singular learning theory</p></blockquote><p> So, was this a success? Or is the idea, first explore, then form a hypothesis, then test? </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 22:42:58 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 22:42:58 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>This was a small success. I had the hypothesis that epochs can be thought of as decreasing the temperature of your ML model, and you can get a critical period out of such an assumption by essentially having, for now, assume 2 possible singularities/model classes you model could arrive at. If the temperature is high, then if you&#39;re sampling, traversing between the model classes is easy. If the temperature is low, then traversing between them as you&#39;re sampling is hard. So critical periods happen when one of the singularities/model classes captures (in this case) the fine-grained details of the non-blurred CIFAR-10 images, and the other does not, so that for high temperature, as you go for a random walk around the blurred CIFAR-10 images, and you suddenly switch to the data distribution including the non-blurred CIFAR-10 images, you can easily switch which model class you spend most of your time sampling from. But for low temperature, its harder. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 22:45:43 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 22:45:43 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>So using the free energy formula</p><p> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="F_n = n L_n/T + \lambda \log n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.106em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">/</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span></p><p> if we decrease the temperature, we must also decrease <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L_n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span></span></span> , so we must increase <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span> because if there existed a model class with lower <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L_n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span> , then we would already be on it. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 22:49:28 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 22:49:28 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>And we do indeed see this, so weak evidence pro the theory. More interesting evidence would come from, say, seeing if we find the same sort of effect as we increase the batch size. Maybe we should anticipate that the larger the batch size, the sooner the event happens. Though this disagrees with common sense, so possibly I&#39;m messing up in my logic somewhere. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 22:55:16 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 22:55:16 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><p> I feel like I am imagining two effects, and I&#39;m not sure which is stronger or more relevant.</p><p> The first is that the lowest loss basin comes to dominate the ensemble as we run more epochs, and so we have less measure over the slightly higher-loss basin.</p><p> The second is that the region inbetween the two basins becomes low measure, and so we can&#39;t transition between the two basins any more.</p><p> Are these effects you&#39;re imagining and if so which is larger? </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 22:56:35 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 22:56:35 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>Yeah, so in the short run at least, the second is stronger when there&#39;s critical periods. And (because of the first) we should anticipate that more dakka is needed to fix the critical period, and get good performance again. I don&#39;t however know a good way of estimating just how much more dakka. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 22:58:20 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 22:58:20 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><p> Can you expand on the common sense intuition regarding batch size and when the critical change happens? </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 23:02:53 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 23:02:53 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>So common sensically, a lower batch size ends up moving more each epoch, so you should see stuff happen quicker, and a larger batch size ends up moving less each epoch, so you should see stuff happen slower. Unless you normalize the learning rates such that the lower batch size goes the same distance as a larger batch size, but that&#39;s probably not a good idea compared to just figuring out what the best learning rate is. Like, if you have really bad learning rates even with a very large batch size, you&#39;re going to eventually end up with an SGD distribution that does not very much resemble your loss landscape. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 23:03:23 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 23:03:23 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><p> Is the idea that the smaller batch is more likely to have uncancelled noise in its update vector? </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 23:03:32 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 23:03:32 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>是的</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 23:03:39 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 23:03:39 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><p> Cool </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 23:05:20 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 23:05:20 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>But that&#39;s a part of it, that&#39;s why you should suspect increased batch size leads to decreased temperature, because of less randomness. But that&#39;s just how it connects to SLT. The common sense notion is that increased batch size is similar to training slowly &amp; carefully , while decreased batch size is similar to moving fast and breaking things. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 23:05:59 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 23:05:59 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><p> Hm yeah that makes sense. I&#39;d take a small bet in favour of the theory and against the common sense in this case. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 23:07:49 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 23:07:49 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>Then you&#39;re more confident in simple arguments then I am! Why don&#39;t you find the differing cross-epoch changes worrying? </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 23:12:20 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 23:12:20 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><p> Now, my intuitions about gradient descent are likely pretty silly, but I like to take small bets when I notice I have intuitions to help them move. Here&#39;s what they say, though.</p><p> The main force consolidating the measure around the singularities is just the quantity of data. Using smaller batches will make you move more because of random sampling noise (but the blur isn&#39;t sampling noise) and because it&#39;s probably OK to update before you&#39;ve seen the full dataset in most cases. But I think the first effect shouldn&#39;t consolidate the measure that much and I don&#39;t know how to think of the second effect but I think for standard learning rates it should probably be kind of small? Like sublinear in (dataset size/batch size). </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 23:14:40 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 23:14:40 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>Yeah, that seems reasonable, but not reasonable enough for me to bet on it, so if you wanted we could bet on whether running with batch size 64 rather than 128 would make the critical period end later rather than sooner? </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 23:15:40 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 23:15:40 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><p> Let&#39;s do it. $10 at even odds? </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 23:15:46 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 23:15:46 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>Sounds good to me! </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 23:16:08 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 23:16:08 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><p> 🤝 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 23:16:15 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 23:16:15 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>🤝 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 23:16:35 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 23:16:35 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><p> OK, nice! Shall we talk some more about some of this now or come back when we have experimental results? </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Mon, 06 Nov 2023 23:16:50 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Mon, 06 Nov 2023 23:16:50 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>Seems like this is a good place to end. </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="55XxDBpfKkkBPm9H8-Mon, 06 Nov 2023 23:16:54 GMT" user-id="55XxDBpfKkkBPm9H8" display-name="kave" submitted-date="Mon, 06 Nov 2023 23:16:54 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>kave</b></section><div><p> See you on the other side of the data-gathering!</p></div></section><div></div><br/><br/> <a href="https://www.lesswrong.com/posts/e8r8Tx3Hk7LpnrMwY/a-bet-on-critical-periods-in-neural-networks#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/e8r8Tx3Hk7LpnrMwY/a-bet-on-critical-periods-in-neural-networks<guid ispermalink="false"> e8r8Tx3Hk7LpnrMwY</guid><dc:creator><![CDATA[kave]]></dc:creator><pubDate> Mon, 06 Nov 2023 23:21:17 GMT</pubDate> </item><item><title><![CDATA[Job listing: Communications Generalist / Project Manager]]></title><description><![CDATA[Published on November 6, 2023 8:21 PM GMT<br/><br/><p> Looking for a way to help communicate about AI x-risk? MIRI is hiring in the Communications department. There will be additional job listings soon for writers and editors, but we&#39;re starting with this comms generalist / project manager role.</p><p> <a href="https://intelligence.org/careers/comms-generalist-pm/">https://intelligence.org/careers/comms-generalist-pm/</a></p><p> I am the Communications Manager at MIRI and this person will be working closely with me. I&#39;m happy to answer questions.<br><br></p><br/><br/> <a href="https://www.lesswrong.com/posts/ZwizCnxJdvEuChnBE/job-listing-communications-generalist-project-manager#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ZwizCnxJdvEuChnBE/job-listing-communications-generalist-project-manager<guid ispermalink="false"> ZwizCnxJdvEuChnBE</guid><dc:creator><![CDATA[Gretta Duleba]]></dc:creator><pubDate> Mon, 06 Nov 2023 20:21:04 GMT</pubDate> </item><item><title><![CDATA[Askesis: a model of the cerebellum]]></title><description><![CDATA[Published on November 6, 2023 8:19 PM GMT<br/><br/><p> We provide a detailed model of the structure and function of the mammalian cerebellum. Our model is isomorphic to that of <a href="https://www.lesswrong.com/users/steve2152?mention=user">@Steven Byrnes</a> , but was developed completely independently; this suggests that both models are likely reasonably accurate.</p><br/><br/> <a href="https://www.lesswrong.com/posts/nYNkoJLArxW9uGZK3/askesis-a-model-of-the-cerebellum#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/nYNkoJLArxW9uGZK3/askesis-a-model-of-the-cerebellum<guid ispermalink="false"> nYNkoJLArxW9uGZK3</guid><dc:creator><![CDATA[MadHatter]]></dc:creator><pubDate> Mon, 06 Nov 2023 20:19:09 GMT</pubDate> </item><item><title><![CDATA[LQPR: An Algorithm for Reinforcement Learning with Provable Safety Guarantees]]></title><description><![CDATA[Published on November 6, 2023 8:17 PM GMT<br/><br/><p> We describe LQPR (Linear-Quadratic-Program-Regulator), an algorithm for model-based reinforcement learning that allows us to prove PAC-style bounds on the behavior of the system. We describe proposed experiments that can be performed in the DeepMind AI Safety Gridworlds domain; we have not had time to implement these experiments yet, but we provide predictions as to the outcome of each experiment. Potential future work may include scaling up this work to non-trivial tasks using a neural network approximator, as well as proving additional theoretical results about the safety and stability of such a system. We believe that this system is a potential basis for aligning large language models and other powerful near-term AI&#39;s with human preferences.</p><p> We also provide a list of critiques of the proposal from <a href="https://www.lesswrong.com/users/davidad?mention=user">@davidad</a> .</p><br/><br/> <a href="https://www.lesswrong.com/posts/AhNYm2wnRy3bcd2N2/lqpr-an-algorithm-for-reinforcement-learning-with-provable#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/AhNYm2wnRy3bcd2N2/lqpr-an-algorithm-for-reinforcement-learning-with-provable<guid ispermalink="false"> AhNYm2wnRy3bcd2N2</guid><dc:creator><![CDATA[MadHatter]]></dc:creator><pubDate> Mon, 06 Nov 2023 20:17:06 GMT</pubDate> </item><item><title><![CDATA[Does bulemia work?]]></title><description><![CDATA[Published on November 6, 2023 5:58 PM GMT<br/><br/><p> I can&#39;t find any non-evasive answers to this question on the internet. Does it actually work or not? Can you just eat a bunch of food and throw it up afterwards and lose weight that way?</p><p> Update/Note: I&#39;m specifically asking if you can <em>satiate</em> yourself that way. I realize you will not receive the calories that you expel.</p><br/><br/><a href="https://www.lesswrong.com/posts/Ta66yyvEbu5kw4pgy/does-bulemia-work#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Ta66yyvEbu5kw4pgy/does-bulemia-work<guid ispermalink="false"> Ta66yyvEbu5kw4pgy</guid><dc:creator><![CDATA[lc]]></dc:creator><pubDate> Mon, 06 Nov 2023 17:58:28 GMT</pubDate></item></channel></rss>