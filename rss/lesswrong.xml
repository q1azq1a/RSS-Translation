<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 8 月 24 日星期四 04:12:50 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[The lost millennium]]></title><description><![CDATA[Published on August 24, 2023 3:48 AM GMT<br/><br/><p><em>注意：这篇文章是推测性的，您应该对其中的说法持保留态度。</em></p><p>纵观人类历史，我们知道，经济增长（在马尔萨斯条件下人口增长是一个很好的指标）已经加速了很多次。事实上，我们只要向后推算当前的增长率就可以看到这一点：鉴于世界上只有这么多人，而且他们的人均维持生计收入的有限倍数，经济增长率不可能达到每年3％的订单已经持续了一千多年左右。</p><p>尽管很难做到这一点，但人们也对过去这种增长的具体发生方式做出了估计。其中一项估计来自<a href="https://www.pbl.nl/en/image/links/hyde">HYDE 数据集</a>，该数据集也可在<a href="https://ourworldindata.org/population-sources">Our World In Data</a>中找到；以及其他估计的完整集合<a href="https://www.census.gov/data/tables/time-series/demo/international-programs/historical-est-worldpop.html">可以在这里找到</a>。</p><p>让我们首先检查一下 HYDE 数据集。公元 1 年之前的数据是每千年给出的，看看增长率，我们可以得到下表：</p><table><thead><tr><th>千年</th><th>平均年人口增长率（百分比）</th></tr></thead><tbody><tr><td>公元前 10000 年 - 公元前 9000 年</td><td>0.0236%</td></tr><tr><td>公元前 9000 年 - 公元前 8000 年</td><td>0.0254%</td></tr><tr><td>公元前 8000 年 - 公元前 7000 年</td><td>0.0279%</td></tr><tr><td>公元前 7000 年 - 公元前 6000 年</td><td>0.0320%</td></tr><tr><td>公元前 6000 年 - 公元前 5000 年</td><td>0.0368%</td></tr><tr><td>公元前 5000 年 - 公元前 4000 年</td><td>0.0411%</td></tr><tr><td>公元前 4000 年 - 公元前 3000 年</td><td>0.0435%</td></tr><tr><td>公元前 3000 年 - 公元前 2000 年</td><td>0.0489%</td></tr><tr><td>公元前 2000 年 - 公元前 1000 年</td><td>0.0415%</td></tr><tr><td>公元前 1000 年 - 公元 1 年</td><td>0.0746%</td></tr></tbody></table><p>除了公元前第二个千年<sup class="footnote-ref"><a href="#fn-GS5X2acGin64XwSjM-1" id="fnref-GS5X2acGin64XwSjM-1">[1]</a></sup>略有逆转之外，估计表明人口增长率逐渐加快。这与人口增长的双曲线模型一致，但在这里我不想做出任何这样的假设，只想看原始数据。</p><p>那么，令人惊讶的是该表中应该包含的下一个条目：在第一个千年，即公元 1 年至公元 1000 年，人口增长率估计平均每年仅为 0.033%。换句话说，根据这个数据集，即使是公元前第五个千年，人口增长也比第一个千年更快！</p><p>事实证明，像这样的结果对于更改我们正在使用的数据集来说是稳健的。 McEvedy 和 Jones 报告称，第一个千年的平均增长率为 0.044%/年，而公元前 1000 年至公元前 200 年的平均增长率为 0.137%/年，从公元前 200 年至公元 1 年的平均增长率为 0.062%/年。 HYDE 数据集中没有提供公元前第一个千年的更详细数据，这表明人口增长放缓可能在第一个千年之前就开始了。为了在这个数据集中找到人口增长较慢的千年，我们必须回到公元前第四个千年（公元前 5000 年 - 公元前 4000 年）。</p><p>我看过的所有数据集都表明，随着第二个千年的到来，人口增长大幅加速。蒙古人的征服和黑死病似乎对 1200 到 1400 年间的人口增长造成了压力，但尽管如此，从 1000 到 1500 年间的人口增长率仍然平均为 0.08%/年，这比公元前第一个千年还要快。</p><p> <a href="https://en.wikipedia.org/wiki/Lost_Decades">“失去的十年”</a>是日本使用的一个名称，指的是1991年日本股市崩盘后的十年经济停滞期。按照这一惯例，将第一个千年称为“失去的千年”可能是合适的。如果我们相信某种经济史的随机双曲线增长模型，即拉鲁德曼（la <a href="https://www.openphilanthropy.org/research/modeling-the-human-trajectory/">Roodman，2020）</a> ，这意味着人类在第一个千年“非常不幸”，可能是由于持续的不利社会冲击。</p><p>这个故事纯粹是定量的，着眼于人口增长，但值得注意的是，在马尔萨斯条件下，我们预计人口增长将跟踪技术进步和资本形成。我们的生产力越高，人们就应该拥有越多的孩子，直到人口增长到足以使劳动边际产量回落到维持生计的水平为止。一千年对于马尔萨斯动力发挥作用来说已经足够了，因此第一个千年缺乏强劲的人口增长也表明创新和资本积累等生产力增长因素的放缓。</p><p>那么重要的问题就变成了：<em>为什么会发生这种情况？</em> ，或者也许<em>这是怎么发生的？</em>我们对其他人口增长放缓有很好的解释，例如1200年至1400年期间的蒙古征服和黑死病。然而，第一个千年的人口增长放缓看起来完全是一个谜。我可以提出一些解释，但它们都不太符合数据。即使是“运气不好”，我也想能够说得更多。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-GS5X2acGin64XwSjM-1" class="footnote-item"><p>也许是由于<a href="https://en.wikipedia.org/wiki/Late_Bronze_Age_collapse">青铜时代晚期的崩溃</a>？ <a href="#fnref-GS5X2acGin64XwSjM-1" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/><a href="https://www.lesswrong.com/posts/hgf6FB9jMB7wMLuKA/the-lost-millennium#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/hgf6FB9jMB7wMLuKA/the-lost-millennium<guid ispermalink="false"> hgf6FB9jMB7wMLuKA</guid><dc:creator><![CDATA[Ege Erdil]]></dc:creator><pubDate> Thu, 24 Aug 2023 03:48:40 GMT</pubDate> </item><item><title><![CDATA[Regreasing a KitchenAid Mixer]]></title><description><![CDATA[Published on August 24, 2023 2:30 AM GMT<br/><br/><p><span>我最近从朋友那里得到了一台旧的 KitchenAid 搅拌机。它是 k45ss，可能是 80 年代初的，我看到的一般建议是，在典型的家庭使用中，它们应该每 10 年重新润滑一次。</span>我订购了 4 盎司<a href="https://www.youtube.com/watch?v=UmnD6Y5jNMg">食品</a><span>安全合成</span><a href="https://www.amazon.com/dp/B08ZYCQVRD">润滑脂</a>，并遵循 Mixer 先生的 YouTube 指南（<a href="https://www.youtube.com/watch?v=EW9BQ-oPFkk">第</a><a href="https://www.youtube.com/watch?v=L-qMOyhb2xc">1、2、3</a>部分）。我一边用手机播放视频，一边进行操作：打开搅拌机，清除旧油脂，添加新油脂，然后将其放回原处。有细微的差别（我的应力消除装置很烦人，而且我的齿轮组件内部没有<a href="https://youtu.be/L-qMOyhb2xc?si=dYgKmFXzWSKtX7o1&amp;t=133">销钉</a>，需要先拆下蜗杆组件），但它非常接近。</p><p>行星齿轮组件的润滑脂含量很低，而且那里的润滑脂有点干：</p><p> <a href="https://www.jefftk.com/kitchen-aid-planetary-low-grease-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/sxkpxtvrlzqqa6v5cose" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/sxkpxtvrlzqqa6v5cose 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/gkxxaeipawczo0vhwjii 1100w"></a></p><div></div><p></p><p>上部区域有更多的油脂，尽管油脂比我想象的要硬：</p><p> <a href="https://www.jefftk.com/kitchen-aid-head-internal-old-grease-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/d0cj2kg5nbktkhqqjp00" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/d0cj2kg5nbktkhqqjp00 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/lhtcygg0imcqpa4ile53 1100w"></a></p><div></div><p></p><p>齿轮状况良好，感觉良好且坚固。</p><p>脱脂、再润滑和组装都很顺利。总共大概1.5小时？然而，当我完成后，我意识到我还剩下一个零件：三个垫圈之一。</p><p> <a href="https://www.jefftk.com/kitchen-aid-extra-washer-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/r6u3cvfabtvaqzzxccgg" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/r6u3cvfabtvaqzzxccgg 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/rcl1me4clylsn0u0zcnq 1100w"></a></p><div></div><p></p><p>我回顾了视频，它谈到安装其中两个洗衣机，我记得这样做过，但我对如何最终安装第三个感到困惑。没有任何逻辑上应该有洗衣机但没有的地方。</p><p>我在晚餐时谈到了这一点，我的一位室友说他们还有一个旧的 KitchenAid，可能从未重新润滑过（k45，电源线没有接地，可能是 60 年代末）。我们决定一起做他们的，也许我们会看看洗衣机去了哪里。</p><p>拥有第二双手和前一天晚上刚刚完成的一双手相结合，使得整个过程变得更快：不到一个小时。和我的非常相似，除了应力消除更烦人。不过，我们确实解开了垫圈之谜：行星机构中有两个垫圈，彼此堆叠在一起。</p><p>我不确定是否值得打开我的底部来安装额外的垫圈。我倾向于是（他们不会无缘无故地放两个垫圈，不需要把整个东西拆开）但可能我真的不需要？</p><br/><br/> <a href="https://www.lesswrong.com/posts/5pcunrT9fJJ3hmHvu/regreasing-a-kitchenaid-mixer#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/5pcunrT9fJJ3hmHvu/regreasing-a-kitchenaid-mixer<guid ispermalink="false"> 5pcunrT9fJJ3hmHvu</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Thu, 24 Aug 2023 02:30:04 GMT</pubDate> </item><item><title><![CDATA[Assessment of intelligence agency functionality is difficult yet important]]></title><description><![CDATA[Published on August 24, 2023 1:42 AM GMT<br/><br/><p><strong>总结：</strong>在观察情报机构时，硬的部分很难看到，软腐败的部分很容易被观察到。这导致了一种偏见，即很多人高估了容易观察到的柔软和无害部分的普遍程度。有时，这甚至会导致职业生涯比你领先得多的人产生一种危险而普遍的估计，认为整个情报机构是无害且无关紧要的，但事实并非如此。情报机构可能是功能较少、相关性较低的部分和功能较多、相关性较高的部分的混合体，这些部分对政府和政策具有不成比例的巨大影响力；认为情报机构都是由不值得关注的非功能性、不相关的部分组成的想法是错误的，即使这种信念是一种流行的规范。</p><p></p><p><strong>为什么情报机构很危险</strong></p><p>在很多情况下，情报机构会在没有任何警告的情况下突然变得重要。例如，美国国家安全委员会的大多数或全部机构可能会突然一致改变其对功能增益研究的立场，例如美中关系或美俄关系再次触及25年来的新低（实际上已经近几年来经常发生）。</p><p>无论是某个机构的领导层，还是机构中有权执行操作的有权势的个人，或者是腐败集团，都可能亲自做出判断，认为加快或重新启动 GOF 研究的最佳方法是针对最有效率的各种人员或有效反对 GOF 研究。</p><p>这不一定是加速或保护 GOF 研究的最有效方法，它只需要看起来像那样，足以让某人签字同意，甚至让他们只是认为这对他们的老板来说看起来不错。</p><p>在情报机构的混合能力模型中，有能力或技术先进的<i>能力</i>显然可能与无能的管理/决策混合在一起。一个真正无害、无关紧要、不值得关注的情报机构（而不是有动机错误地表现出无害、无关紧要或不值得关注的样子）必须是这样的情报机构：技术上<i>既不</i>复杂<i>，又</i>过于腐败，无法实现基本功能，例如运行操作。</p><p>对于美国、俄罗斯和中国的情报机构来说，这是一种极其天真的想法；尤其是美国和中国，它们拥有广泛的声望、先进的技术以及蓬勃发展的私营部门技能库来招聘人才。</p><p>当从某个地方的某个人绝对必须执行的政策倡导任务（例如推动可能导致人类灭绝的 GOF 研究推动明智的政策制定）中计算预期价值时，许多人目前意识到，该重要社区消失或解散的风险大大降低了预期价值计算该重要社区所产生的一切；例如，社区有 10% 的机会停止存在或解散，整个社区产生的预期价值会减少约 10%。</p><p>我遇到的大多数人脑海中浮现的都是一场大规模的极权主义剧变，就像20世纪初中期的那样，而这种剧变是安全与不安全之间的严格界限。然而，在21世纪，特别是在新冠疫情和2008年经济衰退之后，专家和军事规划者现在更加关注国际力量平衡（例如美国、俄罗斯和中国相对于彼此以及其他独立国家的实力）改变是由于经济崩溃或联盟瘫痪，而不是革命或军事征服。这是因为今天的整个世界与 70 年前截然不同。</p><p>更有意义的是预期经济会出现缓慢且不完全的倒退，其结果是以各种方式转向<a href="https://en.wikipedia.org/wiki/Hybrid_regime">混合政权</a>，其中情报机构和内部安全机构因腐败而滥用权力，而由于广泛的腐败而缺乏问责制。优先考虑<a href="https://en.wikipedia.org/wiki/Hybrid_warfare">混合战争</a>，并防止俄罗斯和中国等外国对手利用国内精英，如亿万富翁、政府官员和与关键人群相关的名人/思想领袖（如 Yann Lecun）。</p><p>对此的一个角度示例，来自<a href="https://www.lesswrong.com/posts/LyywLDkw3Am9gbQXd/don-t-take-the-organizational-chart-literally?commentId=bnujfnQXJJ3mJJkxa">Don’t Take the Organization Chart Literals</a>的置顶评论：</p><blockquote><p> ...政府（和腐败的企业组织）中发生的很多事情都是通过默许权力完成的。很少有司法部、中央情报局和联邦调查局官员能够全面了解他们的工作如何与美国的利益不一致。但他们大多数人都有一个普遍的认识，那就是他们对组织的忠诚度要高于对美国的忠诚度。 <a href="https://www.lesswrong.com/posts/LyywLDkw3Am9gbQXd/don-t-take-the-organizational-chart-literally#fn-2WzufJ2HD9B92Pnz6-1"><sup>[1]</sup></a>通过其家族和其他腐败关系，[司法部领导人]巴尔成为美国腐败机构内部集团的一部分。这很简单，就像大多数下级军官知道他和他们在一起一样。</p><p>所以巴尔不必明确地告诉警卫们别看他，他不必告诉联邦调查局进行糟糕的调查，他不必告诉司法部继续腐败......下-拥有下属充分信任和信心的级别老板会制定小计划来完成任务。这是老板想要的，老板会照顾他们。</p><p>想象一下马斯克可能收购 Twitter 的情况。你是否认为如果马斯克收购了 Twitter，即使作为私人所有者，他也会突然完全控制整个机构？当然不是。<strong>真正有权力的人，都是他的下属，那些在他那里呆了一段时间的人，属于他的圈内人。</strong>对马斯克来说，控制推特的唯一方法就是解雇相当多的人，其中许多人是该组织不可或缺的一部分。</p></blockquote><p></p><p><strong>很难看到硬化部分</strong></p><p>（注意：这是<a href="https://www.lesswrong.com/posts/pfL6sAjMfRsZjyjsZ/some-basics-of-the-hypercompetence-theory-of-government">上一篇文章</a>的清理版本，我对其质量不满意。如果您已经阅读过它，请随意跳过这篇文章）。</p><p>一些社会结构可以进化，允许更多人保守秘密。例如，情报机构不仅是相互划分的，而且组成这些机构的员工都认为，如果有人接近他们提出购买机密，这可能是该机构内部的例行反情报行动之一，会引出并起诉不值得信任的员工。结果，这些员工基本上将他们的代理机构<a href="https://www.lesswrong.com/tag/newcomb-s-problem">集中在一起</a>，几乎从不接受外国代理人的贿赂，无论承诺的报酬有多么可笑。任何漏掉的信息都很难摆脱由双重/三重特工伪装成容易受贿的人的虚假信息的影响。</p><p>它比这复杂得多，但这只是机构内部演变的保密系统的一个例子；它不仅足以有效地保守秘密，而且还能够阻止或误导外部特工，明智地试图破坏秘密保守网络（<a href="https://en.wikipedia.org/wiki/Double-Cross_System">几乎一百年前</a>或<a href="https://en.wikipedia.org/wiki/Counterintelligence#History">更早</a>出现）。</p><p>情报机构的高层很难观察。目前尚不清楚产出不足是否主要是由于无能和不感兴趣造成的，或者如此强大的结构内部的激励机制是否导致有能力的个人将自己的能力浪费在内部竞争和淘汰同事上。然而，将更容易接触和观察的普通中低层政府官员/官僚推论到难以观察的高层是危险的。较高梯队的人员分布可能严重失调；例如，在一个关于公司等级制度的过于简化的热尔维模型的思想实验中（“反社会者”高度社交，喜欢聚餐；“无知”者拥有深刻的组织洞察力；“失败者”过着非常幸福的生活，他们“失去”的主要是与其他人一样的衰老过程），一个在金字塔上向上发展的人会逐渐发现感恩节火鸡效应：人类自我分类，导致遇到已经成功追求财富激励的人组织的顶层，因为他们与金字塔中层和底层更容易观察到的人相比，具有不同寻常的、本质上不同的个人特征组合。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pfL6sAjMfRsZjyjsZ/pc6ccmqo9ogw4k3nsdfr"><figcaption>该图像被明确声明为公司层次结构，它被明确声明不是在描述情报机构或有趣的非营利组织，它们以与大多数私营部门公司不同的方式体验<a href="https://slatestarcodex.com/2014/07/30/meditations-on-moloch/">Moloch</a> 。</figcaption></figure><p>尽管自由主义学派最基于对政府普遍无能的经验观察，但这不应该分散我们对基本原则的注意力，即拥有 80% 权力的组织中的前 20% 很大程度上是未知的领域，因为很难观察以及各种奇怪的特定动态可能可以解释政府的失败；尽管模型必须以观察为基础，但过度依赖自由主义思想流派仍然存在风险，这种思想主要以低层官僚为对象，并想象政府统一由他们组成，将这些人推论到最高和最理想的职位。情报机构肯定已经注意到，冒充无能的官僚是一种极好的伪装，而且整个政府也都知道，迷宫般的文书工作可以威慑掠夺者。</p><p>组成 EA 的表现最好的利他主义者，远低于全球所有利他主义者的 0.1%，由于极不寻常和极端的环境，包括强大的能力、运气、智力、动机和以富有成效的方式自发组织的能力，他们正处于极端顶峰。以实现工具上趋同的目标。然而，与 EA 不同的是，情报、军事和内部安全机构中最顶尖的 0.1% 的人面临着来自政权更迭的威胁、各种富有和有权势的精英的仰视以及持续的战略渗透攻击带来的令人难以置信的进化优化压力。由外国情报机构。我们根本不清楚民主国家的权力掮客的顶峰最终会演变出什么样的结构，而且在认识上自动顺从自由主义学派并不负有责任，即使自由主义学派是关于无数人的生活被无能的政府干预/监管毁掉的说法是正确的。有能力的人和团体仍然会被排到最高层，面临达尔文主义的压力，即使绝大多数有能力的人一路上都摆脱了官僚主义的废话。情报机构的运作是我们观察到的结果，这些人被赋予了难以置信的权力、有罪不罚、垄断信息的能力，以及利用他们自己与与其共享一个国家的大型、技术先进的私营公司之间的权力和信息不对称。 （企业游说者可以促进甚至现金激励他们与领导者之间各种复杂的讨价还价，特别是包括顶尖人才的旋转门雇佣，而情报机构的权力和声望进一步促进了这一点）。</p><p></p><p><strong>很容易看到软的部分</strong></p><p>情报机构有能力渗透到顽固的官僚机构和其他组织，通过损害人员网络进行横向移动，并指导世界各地（可能包括国内）行政部门和立法部门/议会人员的职业生涯。</p><p>有相关经验的人都知道，在官僚机构中向上和横向晋升是一门科学（还有很多其他事情，其中​​大多数都非常令人不愉快）。在那些比你更进步的人的心目中，晋升和驾驭官僚机构也是一门比你自己更精确的科学。鉴于他们如此成功，他们很可能做了很多正确的事情，并且一路上学到了很多你没有学到的东西。</p><p>然而，同样地，在情报机构专家的心目中，它是一门更加精确的科学，这些机构世世代代专注于系统地渗透、控制和欺骗世界各地顽固官僚机构（和其他组织）的顽固部分（ <a href="https://www.cold-takes.com/most-important-century/#Summary:~:text=More%20info%20about%20these%20timelines%20at%20All%20Possible%20Views%20About%20Humanity%27s%20Future%20Are%20Wild%2C%20This%20Can%27t%20Go%20On%2C%20and%20Forecasting%20Transformative%20AI%3A%20Biological%20Anchors%2C%20respectively.">但只有少数几代人</a>）。人类文明是建立在专业化和分工的基础上的，而情报机构就是专门从事这一工作的人。 <span class="footnote-reference" role="doc-noteref" id="fnrefsapjucliu6o"><sup><a href="#fnsapjucliu6o">[1]</a></sup></span></p><p>由于对轶事的必要依赖，这种信息的不对称性甚至更大，而且由于许多人根据在机构特定部门工作时的氛围做出决策的现象而变得更加复杂。</p><p>这是值得注意的，因为在一个机构的人员<strong>流动率较高的</strong>部分<i>，</i>进出人数不成比例，因此占据了不成比例的大量观察和证词。这进一步加剧了这种动态，即很难看到坚硬的部分，而更容易看到较软的部分，因为众所周知，腐败、无能、暴行/派系主义和低参与度都会大大增加人员流动，而高价值的秘密、众所周知，更有能力的管理人员、有趣的工作和以使命为导向的员工流动率较低，也更容易从顶尖公司招聘顶尖人才。</p><p>此外，评估组织的领土也存在反归纳情况的风险，这些组织的任务包括长期的宣传、虚假信息，特别是反情报，以及利用先进技术利用人类心理（包括通过使用数据）。科学、大规模监视和人工智能）。特别是，摆脱共鸣是一种非常糟糕的方法，因为共鸣是情绪化的、潜意识的，并且很容易获得大量数据并进行科学研究。你对某件事了解得越多，就越容易找到通过用特定刺激刺激某物来获得特定结果的方法。</p><p>与假想的富人和有权势的人打交道，他们专门利用自己的财富和影响力来<a href="https://www.lesswrong.com/posts/xDNyXGCDephBuNF8c/dark-forest-theories">避免将自己的地位拱手让给同样富有和有权势的敌人</a>，需要理解与处理不可证伪的理论相关的人类认知偏见。我的模型看起来很棒，这是<a href="https://www.lesswrong.com/posts/RryyWNmJNnLowbhfC/please-don-t-throw-your-mind-away">一个可以在你的脑海中思考的有趣话题</a>，而难以发现的能力垄断岛理论与飞行的意大利面怪物和隐形龙完全不同；但这些考虑因素也必须以定量的心态进行评估。最终，除了政策结果和众所周知的军事/情报结果之外，几乎没有好的数据，并且这两种假设（情报机构内的统一无能与非统一无能）都必须用现有的最佳认识论来处理。我推荐尤德科夫斯基的<a href="https://www.lesswrong.com/posts/CqyJzDZWvGhhFJ7dY/belief-in-belief">《信仰中的信仰</a>》、 <a href="https://www.lesswrong.com/posts/fAuWLS7RKWD2npBFR/religion-s-claim-to-be-non-disprovable">《宗教的不可反驳性主张》</a> 、 <a href="https://www.lesswrong.com/posts/XTXWPQSEgoMkAupKt/an-intuitive-explanation-of-bayes-s-theorem">《贝叶斯定理的直观解释》</a> （如果你还没有读过的话），以及雷蒙的<a href="https://www.lesswrong.com/posts/xDNyXGCDephBuNF8c/dark-forest-theories">《黑暗森林理论》</a> 。我在这篇文章中描述的限制对于理解情报机构至关重要。</p><p>对这些机构的研究比迄今为止似乎发生的事情需要更好的认识论。</p><p></p><p><strong>测谎仪的发挥作用是人类历史的转折点</strong></p><p>所有人类社会和平衡都部分源于人脑的一个基本特征：<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3680134/">人脑产生谎言比人脑发现谎言更容易</a>，即使是在面对面的对话中，大量的紧张情绪也是如此。揭示非语言交流的交换（例如面部表情、微妙的身体姿势变化）。你不能问别人是否打算背叛你，如果你能问，一切都会不同。</p><p>如果发明了功能性测谎仪，我们所知道的激励结构将完全被更有效的新结构所取代。例如，你可以强迫所有下属戴上脑电图或进入功能磁共振成像仪，然后询问他们所有人谁是办公室里最聪明/最有能力的人，提拔实际上表现最好的人，并解雇任何派系/您发现围绕共同谎言进行协调的人的派系。大多数能够使用有效测谎技术的中层管理人员在作为能够使用有效测谎技术的中层管理人员花费数千小时的过程中都会想到这些事情，以及我尚未想到的许多其他策略。</p><p>如果你对测谎技术的第一反应是“嗯，测谎技术目前非常不准确且无效”，那么这是一个非常可以理解的错误，但也毫无疑问是一个错误。我和很多人谈过这个问题，几乎所有人都自信地输出了基本上完全相同的文本字符串，但不知道它来自哪里或支持它的是什么。我并不怀疑这在 40 甚至 20 年前可能是正确的，但随着现代技术的发展，这更像是一个难以抉择的问题。最好的论文（我愿意分享）涵盖了政府/军事利益和测谎技术的获取，无论是当前还是未来潜在的垄断，都<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3680134/">在这里</a>，其中还涵盖了测谎技术的声誉（这是更容易观察和研究的事情之一）。</p><p>这可能是未来 30 年人类文明相对于过去 80 年人类文明分布不均的最重要方式之一（它不是#1）。</p><p></p><p><strong>我发现有用的信息</strong>：</p><p> <a href="https://www.lesswrong.com/posts/LyywLDkw3Am9gbQXd/don-t-take-the-organizational-chart-literally">不要从字面上理解组织结构图</a>（强烈推荐）</p><p> <a href="https://www.lesswrong.com/posts/oqvsR2LmHWamyKDcj/large-language-models-will-be-great-for-censorship">法学硕士非常适合审查</a></p><p>雷蒙的黑暗<a href="https://www.lesswrong.com/posts/xDNyXGCDephBuNF8c/dark-forest-theories">森林理论</a></p><p>约瑟夫·奈的<a href="https://www.amazon.com/Soft-Power-Means-Success-Politics/dp/1586483064">软实力</a></p><p><a href="https://www.lesswrong.com/posts/r2vaM2MDvdiDSWicu/the-u-s-is-becoming-less-stable">美国变得越来越不稳定</a></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnsapjucliu6o"> <span class="footnote-back-link"><sup><strong><a href="#fnrefsapjucliu6o">^</a></strong></sup></span><div class="footnote-content"><p>另一方面，议会和立法机构更多的是为一个国家的精英提供合法且可持续的影响力，让他们除了搞肮脏的事情之外还有出路（而且一个国家的顶级精英有各种各样的方式来发挥影响力）在财富和权力的巅峰/接近巅峰时肮脏；试着想象一个智商 175 的人能做什么）。与民主国家不同，威权政权更注重隔离精英。他们是友好领域的专家，比如稳健性和政策制定。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/foM8SA3ftY94MGMq9/assessment-of-intelligence-agency-functionality-is-difficult#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/foM8SA3ftY94MGMq9/assessment-of-intelligence-agency-functionity-is-difficult<guid ispermalink="false"> foM8SA3ftY94MGMq9</guid><dc:creator><![CDATA[trevor]]></dc:creator><pubDate> Thu, 24 Aug 2023 01:42:22 GMT</pubDate> </item><item><title><![CDATA[China's position on autonomous weapons]]></title><description><![CDATA[Published on August 23, 2023 10:20 PM GMT<br/><br/><blockquote><p>在继续认可制定具有法律约束力的法律文书的必要性的同时，2018年中国还提出了一个较为狭隘的法律定义，包括五个基本特征：</p></blockquote><blockquote><blockquote><p>第一个是杀伤力，这意味着足够的有效载荷（电荷）使其具有杀伤力。二是自主性，即任务执行的整个过程中不存在人为干预和控制。第三是无法终止，这意味着一旦激活就无法终止设备。第四是无差别作用，即无论条件、场景或目标如何，该装置都会执行杀伤和致残的任务。第五是进化，意味着通过与环境的交互，设备可以自主学习，并以超出人类预期的方式扩展其功能和能力。</p></blockquote></blockquote><blockquote><p> [...] 中国的限制性定义对可能有资格受到法律监管的技术种类设置了极高的门槛。</p></blockquote><blockquote><p>然而，接受我们采访的中国政府专家小组代表并不认为这个定义是“狭隘的”。对他们来说，快速的技术进步可能很快就会使零人为监督的武器成为现实，特别是在美国等技术先进的国家。</p></blockquote><p>具有自主瞄准功能的军用无人机已经存在。土耳其 <a href="https://thebulletin.org/2021/05/was-a-flying-killer-robot-used-in-libya-quite-possibly/">可能使用过其中之一</a>。<a href="https://www.youtube.com/watch?v=G7yIzY1BxuI">以色列也一直在</a>开发自主武器。 <a href="https://en.wikipedia.org/wiki/AeroVironment_Switchblade">Switchblade 600</a>不是自主的，但美国国防承包商有兴趣在此类产品中添加自主瞄准功能，并且似乎正在游说反对美国的相关法规。中国政府似乎强烈支持自主武器，但也强烈反对电影中的终结者。</p><p>到目前为止，重点是小型短程电动无人机的自主瞄准，但对于可以携带更多传感器和计算设备的大型无人机来说，自主瞄准更容易，而远距离数据链路则更困难——特别是当卫星在战争等中成为目标时美国与中俄联盟之间的台湾问题。</p><br/><br/> <a href="https://www.lesswrong.com/posts/QaaunwFaGGFd8cTpy/china-s-position-on-autonomous-weapons#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/QaaunwFaGGFd8cTpy/china-s-position-on-autonomous-weapons<guid ispermalink="false"> QaaunwFaGGFd8cTpy</guid><dc:creator><![CDATA[bhauth]]></dc:creator><pubDate> Wed, 23 Aug 2023 22:20:14 GMT</pubDate> </item><item><title><![CDATA[Diet Experiment Preregistration: Long-term water fasting + seed oil removal ]]></title><description><![CDATA[Published on August 23, 2023 10:08 PM GMT<br/><br/><p>我对 exfatloss<a href="https://exfatloss.substack.com/p/seed-oils-explain-the-8-mysteries">最近的理论</a>很感兴趣，即肥胖流行的主要原因是亚油酸多年来缓慢而微妙的损害。具体来说，我想测试更广泛的可能性，即脂肪组织的成分是导致问题的原因。由于我们没有十年的时间来自然地检验他的假设，因此我将重新调整我目前的饮食习惯，以进行修改后的实验。</p><p>我现在刚刚从极低热量饮食过渡到清水断食，在过去几周内减掉了大约十五磅。我将尝试在接下来的三十天内继续禁食，或者直到我的 BMI 达到 &lt;25。水断食结束后，我将严格从饮食中排除亚油酸和其他多不饱和脂肪酸；我的膳食主要包括蔬菜、米饭、特制的低多不饱和脂肪酸猪肉和鱼。那我就再吃一个月吃饱。</p><p>通常情况下，水断食后你会恢复刚刚减掉的所有体重，因为你没有改变身体的饮食“设定点”，并且你浪费了所有的精神力量试图阻止自己进食。然而，如果亚油酸假说是正确的，那么我作为一个优秀的美国人多年来消耗的所有多不饱和脂肪酸首先就是导致我的设定点保持如此高的原因。因此，在这次自我实验中，我将刻意清除大部分剩余的脂肪储备，用传统的日本饮食来填充它们，看看我的“自然体重”是否发生变化。</p><p>如果损害是不可逆的，亚油酸假说不会无效，但我至少可以检验这样的假说：我的脂肪的<i>运行</i>成分是导致我的新陈代谢崩溃的原因。</p><br/><br/> <a href="https://www.lesswrong.com/posts/5KkyygHQL2XCw3kTs/diet-experiment-preregistration-long-term-water-fasting-seed#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/5KkyygHQL2XCw3kTs/diet-experiment-preregistration-long-term-water-fasting-seed<guid ispermalink="false"> 5KkyygHQL2XCw3kTs</guid><dc:creator><![CDATA[lc]]></dc:creator><pubDate> Wed, 23 Aug 2023 22:08:49 GMT</pubDate> </item><item><title><![CDATA[The Low-Hanging Fruit Prior and sloped valleys in the loss landscape]]></title><description><![CDATA[Published on August 23, 2023 9:12 PM GMT<br/><br/><p>您可以在<a href="https://github.com/nrimsky/mlexperiments"><i>此 GitHub 存储库</i></a><i>中找到引用实验的代码</i></p><p>许多人假设训练大型神经网络将增强简单性，或<a href="https://www.lesswrong.com/posts/Tr7tAyt5zZpdTwTQK/the-solomonoff-prior-is-malign,%202020"><u>所罗门诺夫先验</u></a>。这是基于这样的想法，即更简单的解决方案占据了权重空间中的广阔区域（ <a href="https://www.lesswrong.com/posts/xRWsfGfvDAjRWXcnG/dslt-0-distilling-singular-learning-theory,%202023"><u>权重空间中存在更多的泛化方向，沿着这些方向损失不会增加或增加很少</u></a>），转化为一个广泛的吸引子盆地，其中权重调整的扰动具有对损失的边际影响。</p><p>然而，深度学习优化的主力随机梯度下降（SGD）的运行方式挑战了这种以简单性为中心的观点。根据设计，SGD 由当前批次数据的即时梯度驱动。这个过程的本质意味着 SGD 的运行就像一种贪婪的启发式搜索，逐渐接近可能逐渐更好但不一定是最简单的解决方案。</p><p>这个过程的一部分可以理解为“摸索”步骤或相变的集合，其中网络学习并“固化”一个新的电路，对应于正确识别权重之间的某些关系（或者，从数学上讲，找到一个子流形）。 This circuit then (often) remains &quot;turned on&quot; (ie, this relationship between weights stays in force) throughout learning.</p><p> From the point of view of the <a href="https://en.wikipedia.org/wiki/Energy_landscape"><u>loss landscape</u></a> , this can be conceptualized as recursively finding a valley corresponding to a circuit, then executing search within that valley until it meets another valley (corresponding to discovering a second circuit), then executing search in the joint valley of the two found circuits, and so on. As the number of circuits learned starts to saturate the available weight parameters (in the underparametrized case), old circuits may get overwritten (ie, the network may leave certain shallow valleys while pursuing new, deeper ones). However, in small models or models not trained to convergence, we observe that large-scale circuits associated with phase transitions largely survive to the end. </p><figure class="image image_resized" style="width:52.88%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/i3jrid2l6vkwdqgei2ci" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/t7rsgjany28hc9ptztwm 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/jn9y10kfbab3dohwmavz 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/jkyinxbwdc2nfgrvizwr 260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/gxuw5sjkvvrd5x9z2rn3 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/fuxxqst31wdjqwzcmdxj 420w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/nggcv0blwwzpgjw80g04 500w"><figcaption> This gif shows the Fourier modes of the learned embeddings in our modular addition MLP model. Circles correspond to fully grokked circuits of the kind found in <a href="https://arxiv.org/abs/2301.05217"><u>Progress measures for grokking via mechanistic interpretability</u></a></figcaption></figure><h1> A greedier picture</h1><p> This idea aligns with what we call the <i>low-hanging fruit prior</i> concept. Once a solution that reduces loss reasonably is identified, it becomes more computationally efficient to incrementally refine this existing strategy than to overhaul it in search of an entirely new solution, even if the latter might be simpler. This is analogous to continuously picking the lowest-hanging fruit / cheapest way to reduce loss at each stage of the gradient descent optimization search process.</p><p> This model predicts that SGD training processes are more likely to find solutions that look like combinations of shallow circuits and heuristics working together rather than simpler but less decomposable algorithms. In a mathematical abstraction, suppose that we have an algorithm that consists of two circuits, each of which requires getting <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="10"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">10</span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>parameters right (note that this corresponds to a measure of complexity), and each of which independently reduces the loss. Then the algorithm resulting from learning both circuits has a “complexity measure” of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="20"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">20</span></span></span></span></span></span></span> , but is more likely to be learned than a “complexity <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="15"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">15</span></span></span></span></span></span></span> ” algorithm with the same loss if it cannot be learned sequentially (as it is exponentially harder to correctly “guess” 20 parameters than to correctly “guess” 10 parameters twice). Note that in general, the picture is more complicated: even when learning a single “atomic” circuit that cannot be further decomposed, the question of how easy it is to learn is not equivalent to the information content (how many parameters need to be learned), but incorporates more qualitative phenomena like basin shallowness or, more generally, local basin information similar to that studied by <a href="https://www.lesswrong.com/s/czrXjvCLsqGepybHC/p/xRWsfGfvDAjRWXcnG"><u>Singular Learning Theory</u></a> - thus moving us even further away from the Solomonoff complexity prior.</p><p> An interesting consequence of this is a prediction that for tasks with two (or more) distinct ways to solve them, neural networks will tend to find or partially find both (or multiple) solutions, so long as the solutions have comparable complexity (in a suitable SGD sense). Our <a href="https://www.lesswrong.com/posts/8ms977XZ2uJ4LnwSR/decomposing-independent-generalizations-in-neural-networks"><u>MNIST experiment</u></a> (see below for details) confirms this: We design a network to solve a task with two possible solutions, one being a memorization task of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="4\times 4"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span></span></span></span></span> patterns, and the other being the MNIST task of classifying digits; we set them up to have approximately the same effective dimension of (order of magnitude) 100. We observe that both are learned at comparable rates (and indeed, the part of the program classifying MNIST seems more stable). We conjecture that the network gradually learns independent bits of information from both learning problems by recursively picking the lowest-hanging fruit from both classification problems. Ie, by recursively finding the &quot;easiest to learn&quot; circuits that give additional usable information for the classification problem, and which may come from either memorization of patterns or learning the shapes of digits.</p><p> The idea of such a prior is not new. However, it is not sufficiently appreciated in AI safety circles how different this prior is from the simplicity prior: it gives a picture of a neural net as more akin to an ADHD child (seeking out new, &quot;bite-sized&quot; bits of information) than to a scientist trying to work out an elegant theory. Note that this does not imply a limit on the capabilities of current models: it is likely that by iterating on finding low-hanging fruit, modern networks can approach human levels of &quot;depth.&quot; However, this <strong>updates us towards expecting neural nets to have more of a preference for modularity and parallelism over depth</strong> .</p><h2> Connection to the speed prior</h2><p> In <a href="https://www.lesswrong.com/posts/GC69Hmc6ZQDM9xC3w/musings-on-the-speed-prior"><u>some</u></a> <a href="https://www.youtube.com/watch?v=v7Xk6ci3BII&amp;t=1020s"><u>discussions</u></a> of priors, the Solomonoff prior is contrasted with the “speed prior.” The meaning of this prior is somewhat inconsistent: some take it to be associated with the KT complexity function (which is very similar to the Solomonov prior except for superexponential-time programs), and in other contexts, it is associated with properties of the algorithm the program is executing, such as depth. We think our low-hanging fruit prior is similar to the depth prior (and therefore also to speed priors that incorporate depth), as both privilege parallel programs. However, high parallelizability is not strictly necessary for a program to be learnable using a low-hanging fruit approach: it is possible that after enough parallel useful circuits are found, new sequential (and easily learnable) circuits can use the outputs of these parallel circuits to refine and improve accuracy, and a recursive application of this idea can potentially result in a highly sequential algorithm.</p><h1> Modularity and phase transitions</h1><h2> Insights from experiments</h2><p> In our experiments, we look at two neural nets with <i>redundant generalization modules</i> , ie, networks where we can mechanistically check that the network is performing parallel subtasks that independently give information about the classification (which is then combined on a logit level). Our first network solves an image classification task which is a version of MNIST modified to have two explicitly redundant features that can be used to classify the image. Namely, we generate images that are a combination of two labeled datasets (“numbers” and “patterns”) with labels 0-9; these are combined in such a way that the number and the pattern on each image have the same label, and thus contain redundant information (the classification problem can be solved by looking at either feature). </p><p><img style="width:62.71%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/wccpqg5sixzkgdt2tee7"></p><p> We observe that the network naturally learns independent modules associated with the two classification tasks.</p><p> For our other test case, we reproduce a version of <a href="https://www.alignmentforum.org/posts/N6WM6hs7RQMKDhYjB/a-mechanistic-interpretability-analysis-of-grokking"><u>Neel Nanda&#39;s modular addition transformer</u></a> , which naturally learns multiple redundant circuits (associated with Fourier modes) that give complementary bits of information about a mathematical classification problem.</p><p> For both of these problems, we examine loss landscape basins near the solution found by the network, and we investigate how neural nets trained under SGD recursively find circuits and what this picture looks like &quot;under a microscope&quot; in the basin neighborhood of a local minimum with multiple generalizations.</p><p> Specifically, our experiments attempt to gain fine-grained information about a neural net and its circuits by considering models with smooth nonlinearities (in our case, primarily sigmoids). We train the network at a local minimum or near-minimum (found by SGD).</p><p> We then examine the resulting model&#39;s basin in a coordinate-independent way on two levels of granularity:</p><h3> 1. Small neighborhood of the minimum: generalizations not distinguishable</h3><p> In the small neighborhood (where empirically, the loss landscape is well-approximated by a quadratic function), we can associate to each generalization module a collection of directions (ie, a vector space) in which this module gets generalized, but some other modules get ablated. For example, here is a graph of our steering experiment for the modified MNIST task: </p><figure class="image image_resized" style="width:95.78%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/a8fjbaugmbhrydudzzkn" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/jqs6f1fklbvormy23yie 190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/dpfvyupusukbvjlpd292 380w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/nsyyoj5w4t3efywizjp7 570w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/zm9f71bpcwkdjfy4b1bi 760w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/weuz3y31dddemazut7in 950w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/quhfjjdzflouhyg0swov 1140w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/vtlblvir0ri3lqp4utdx 1330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/g85sdpe6sluonui9v0rk 1520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/q4njiib3yleh1homix7a 1710w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/rjeahzozkzyufnixsccy 1879w"></figure><p> It follows from <a href="https://www.lesswrong.com/posts/8ms977XZ2uJ4LnwSR/decomposing-independent-generalizations-in-neural-networks"><u>our work</u></a> that the composite network (red, &quot;opacity 0.5&quot;) executes two generalization circuits in the background, corresponding to reading &quot;number&quot; and &quot;pattern&quot; data.</p><p> In the right chart, we move a distance <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="t"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span></span></span></span></span></span> in the &quot;number&quot; generalization direction, ablating the &quot;pattern&quot; generalization. This results in very stable loss in the &quot;number&quot; circuit but non-negligible loss in the composite network.</p><p> The vectors we produce for extending one generalization while ablating the other results in almost no increase in loss for the generalization being preserved, high loss for the generalization being ablated, but (perhaps surprisingly) nonzero loss for the &quot;joint&quot; problem. The loss in the joint model is significantly (about an order of magnitude) less than the loss in the ablated circuit. However, it is far from being negligible.</p><p> In fact, it is not surprising that going in a generalization direction of one of the redundant modules does not result in flat loss since the information provided by the two modules is not truly “redundant.” We can see this in a toy calculation as follows.</p><blockquote><p> Suppose that our two classification algorithms A, B attain an accuracy of 91% each by knowing with close to 100% certainty a subset of 90% of “easy” (for the given algorithm) patterns and randomly guessing on the remaining 10% of “hard” cases, and that, moreover, the easy and hard cases for the two algorithms are independent. Suppose that the logits for the “combined” algorithm are a sum of logits for the two constituent subalgorithms. In this case, we see that the constituent algorithms have cross-entropy loss of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-\log(0.1)*0.1\approx 0.23"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.1</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.1</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">≈</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.23</span></span></span></span></span></span></span> (associated with 10% accuracy in 10% of cases – the perfectly classified cases don&#39;t contribute to loss). The “combined” network, now, will have perfect loss in 99% of cases (complement to the 1% of cases where both A and B don&#39;t know the answer), and so the cross-entropy loss of the combined network is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-\log(0.1)*0.01 \approx 0.023"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.1</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.01</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">≈</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.023</span></span></span></span></span></span></span> ; this picture, though a bit artificial, neatly explains the roughly order-of-magnitude improvement of loss we see in our MNIST model when both circuits are turned on compared to when only one circuit is turned on (as a result of steering).</p></blockquote><p> In terms of generalization directions, the quadratic loss when steering towards a particular circuit is within the range of the top 10 or so eigenvalues of the Hessian, meaning that it is very strongly within the effective dimensionality of the task (which in the case of MNIST is of OOM 100). So in the model we consider, we see that looking at only one of the two features very much does not count as a generalization direction from the point of view of quadratic loss. Moreover, the generalization directions for the various circuits do not appear to be eigenvalues of the Hessian and look somewhat like &quot;random&quot; vectors with relatively high Hessian curvature.</p><h3> 2. Larger region where we can observe the ablation of a circuit: generalizations are &quot;sloped canyons&quot;</h3><p> In a larger region with non-quadratic behavior, we find that the distinct generalizations correspond to lower-loss &quot;canyons&quot; within the loss landscape that are, in fact, local minima in all directions orthogonal to the vector connecting them to the minimum of the basin.</p><p> This confirms that the local geography of the loss landscape around models with multiple generalizations can look like a collection of sloped canyons converging towards a single basin. Near the basin is a &quot;phase transition&quot; phenomenon where the canyons stop being local minima and instead flow into a larger quadratic basin. A simplified version of the loss landscape looks like the following graph. </p><figure class="image image_resized" style="width:55.07%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/qtzcdjbscd916ffnv3be"><figcaption> Graph of loss landscape. The origin is the lowest-loss point in the basin. &quot;Sloped canyons&quot; corresponding to x and y coordinate directions converge on this lowest-loss point; points in the x, respectively, y canyons correspond to models that execute different generalizations. </figcaption></figure><p><br></p><figure class="image image_resized" style="width:49.94%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/pulzdphwpvzkwhrl0hvy"><figcaption> A zoomed-in picture of the above loss function corresponding to our “small-scale” basin analysis: here, the function looks close to quadratic, and the two generalization directions are not easily distinguishable from other directions.</figcaption></figure><h2> Relationship between &quot;sloped canyons&quot; model and low-hanging fruit prior</h2><p> We note that this picture surprised us at first: we originally expected there to be a direction that generalizes one of the “redundant circuits” while not changing the loss. </p><figure class="image image_resized" style="width:54.94%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/m03w1ypqwddpbrucmmkw"><figcaption> A loss landscape with a large singular manifold of minima along the full coordinate cross.</figcaption></figure><p> Our updated picture of <i>sloped</i> canyons interfaces nicely with our sequential circuit formation prior. In situations where canyons are well-conceptualized as flat (like the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x^2y^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.082em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> picture) and correspond to a singular locus of minima, we would be less likely to expect sequential learning under SGD (as after learning one circuit, SGD would get “stuck” and stop moving towards the more general point near the origin), and in this picture, if networks learned more general solutions, we would expect this to happen mostly through many generalizations appearing at once (eg, found by the diagonal gradient lines in the level set picture below). </p><figure class="image image_resized" style="width:50.83%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/csqdazjpq92ig1iel4z2"><figcaption> A hypothetical picture where generalizations correspond to “flat” canyons</figcaption></figure><p> What we observe in practice looks more like the following cartoon level set: </p><figure class="image image_resized" style="width:48.13%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/hmpahzykaqbjb8eiejce"><figcaption> Level set where the circuit generalizations correspond to “sloped” rather than flat canyons in the loss landscape.</figcaption></figure><p> This picture is more consistent with learning one generalization at a time (here, the curved lines first get close to a coordinate axis – ie, learn one redundant generalization, then descend to the joint generalization through SGD).</p><p> Having given cartoons for different generalization-learning patterns (either directly learning a general point or learning generalizations one at a time), we can informally compare the two hypotheses to dynamic captures of circuit formation under SGD for our modular addition algorithm. Interestingly, the pattern we see here seems to provide evidence for both mechanisms taking place. Indeed, while circuits do form sequentially, often, pairs or triples of circuits are learned at once or very close together: </p><figure class="image image_resized" style="width:88.23%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SbzptgFYr272tMbgz/ohp8vfbviayadvpm7zca"><figcaption> Modular addition circuit pair formation in a neural network with chunked 2D embeddings. Here, we are visualizing different “blocks” of the token embeddings of the modular addition problem, and a circuit forms when the embedding layer for one of the blocks finds a circle configuration.</figcaption></figure><p> Note that a pure &quot;greedy search&quot; picture would predict that circuits form one by one according to a Poisson process, which would make this &quot;pair formation&quot; behavior unlikely, and somewhat complicates the sequential circuit formation picture. It would be interesting to do a more rigorous analysis of the stochastic behavior of circuit formation, though we have not done this at the moment. We expect explanations for these phenomena to have to do with a more detailed analysis of basins at various scale levels around the local minimum.</p><h1> Acknowledgments</h1><p> This write-up is part of research undertaken in the Summer 2023 SERI MATS program. We want to thank our mentor Evan Hubinger for useful discussions about speed and simplicity priors, and we want to thank Jesse Hoogland, Daniel Murfet, and Zach Furman for comments on an earlier version of this post.<br></p><br/><br/> <a href="https://www.lesswrong.com/posts/SbzptgFYr272tMbgz/the-low-hanging-fruit-prior-and-sloped-valleys-in-the-loss#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/SbzptgFYr272tMbgz/the-low-hanging-fruit-prior-and-sloped-valleys-in-the-loss<guid ispermalink="false"> SbzptgFYr272tMbgz</guid><dc:creator><![CDATA[Dmitry Vaintrob]]></dc:creator><pubDate> Wed, 23 Aug 2023 21:12:58 GMT</pubDate> </item><item><title><![CDATA[A Theory of Laughter]]></title><description><![CDATA[Published on August 23, 2023 3:05 PM GMT<br/><br/><h1> 1. 太长；博士</h1><p>对于笑声应该有两个层面的平行解释。</p><ul><li>在大脑层面，应该有某种产生笑声的机制/算法，并且它应该符合人们在实践中笑的数据。</li><li>在进化层面上，首先应该对这种机制存在的原因做出一些解释。为什么我们的祖先具有适应性？它从哪里来——其他动物中有同源物吗？</li></ul><p>我将以相反的顺序总结我对这两个方面的建议：</p><h2> 1.1 tl;dr前半部分：进化论中的笑声</h2><p>我赞同流行的理论，即笑声是“游戏”的指标，与其他动物中与游戏相关的发声和肢体语言（例如狗的“游戏弓”）同源。</p><ul><li><i><strong>游戏</strong></i><strong>的进化目的</strong><strong>是“为未来的危险情况进行练习”</strong> 。例如，一只喜欢打闹和追逐的幼狼可能会在未来现实生活中的打斗和追逐中表现得更加熟练。</li><li><i><strong>与生俱来的交流性游戏信号</strong></i>（例如人类的笑声和狗的游戏弓）<strong>的进化目的</strong><strong>是减少从练习到严肃的意外升级的可能性。</strong>例如，如果两只幼狼之间的游戏打斗升级为幼狼之间的<i>真正</i>战斗，这对两只幼狼来说都是危险的。如果幼犬能够发出并回应交流游戏信号，那么这种升级的可能性就不太可能发生。这<a href="https://en.wikipedia.org/wiki/Safeword_(sports)"><u>与格斗相关运动（以及其他地方）中的“安全词”</u></a>有点相同。</li></ul><h2> 1.2 tl;dr后半部分：大脑算法方面的笑声</h2><p>我的（过于简单的）伪代码大脑的笑<a href="https://www.lesswrong.com/posts/4gaeWLhnnBvhamRke/book-review-the-heart-of-the-brain-the-hypothalamus-and-its"><u>“业务逻辑”</u></a>是这样的： </p><figure class="table"><table><tbody><tr><td style="background-color:#fff2cc;border:2px solid hsl(0, 0%, 0%)"><p><strong><u>拟议的笑的大脑伪代码</u></strong>：</p><ul><li> (A) 如果我的下丘脑和脑干收到<i>一些</i>证据表明我处于危险之中<ul><li><i>（这里的“证据”可能是一些相同的信号，它们本身往往会激活交感神经系统）</i></li></ul></li><li> (B) 我的下丘脑和脑干同时获得<i>更有力的</i>证据证明我是安全的<ul><li><i>（这里的“证据”可能是一些相同的信号，它们本身往往会激活副交感神经系统）</i></li></ul></li><li> (C) 我的下丘脑和脑干有证据表明我处于社交场合</li><li>(D) 然后我会发出与生俱来的游戏信号（例如人类的笑声），而且我也会感到更有活力（在边缘），更安全，更少担心等。</li></ul></td></tr></tbody></table></figure><p>事实上，我预计下丘脑或脑干中存在一些基因特定的神经元群（或者更一般地说，我所说的<a href="https://www.lesswrong.com/posts/hE56gYi5d68uux9oM/intro-to-brain-like-agi-safety-3-two-subsystems-learning-and"><u>转向子系统</u></a>），并且当未来的科学家研究它的各种连接及其功能特性时，它将直接显然，这个神经元组及其连接正在实现上面的伪代码。</p><p> （旁注：这些科学家还会发现，这个神经元组还有各种其他输入，这些输入使笑的可能性或多或少——与情绪等相关的输入——为了简单起见，我从框中省略了这些输入。）</p><p>请注意，此框中没有任何内容与人类特别相关。如果我们谈论的是<a href="https://scholar.google.com/scholar?cluster=14143705629125606901&amp;hl=en&amp;as_sdt=40000005&amp;sciodt=0,22"><u>50kHz 老鼠的笑声</u></a>而不是人类的笑声，我不会更改上面框中的任何一个单词。然而，在这篇文章的后面，我将特别讨论人类的笑声，包括幽默，并且我将认为这个伪代码框与人们笑的环境似乎是匹配的。</p><p>另外，我最初猜测这个伪代码框的路径（即内省）与我如何相信进化故事无关（即，我在书中读到它，它看起来显然是正确的）。但我声称这两个故事完美匹配——考虑到我认为大脑算法一般如何工作的背景限制，上面的伪代码框是实现与进化故事相关的“规范”的自然、直接的方式（参见第 3.3 节） .2 见下文）。这让我确信我走在正确的道路上。</p><p>好的，这就是 tl;dr。本文的其余部分将详细阐述该图景、我目前相信它的原因以及更广泛的含义。</p><h2> 1.3 目录及章节摘要</h2><ul><li>第 2 部分将更详细地解释进化故事。</li><li>第 3 节将更详细地解释大脑算法的故事，特别是上面的伪代码<i>到底</i>是什么意思？然后我将阐述我认为正确的三个主要原因：（1）伪代码符合进化“规范”； (2) 伪代码在神经科学方面非常可信； （3）伪代码似乎与人类大笑的情况（以及动物发出类似游戏信号的情况）相匹配。</li><li>第 4 节通过在三个领域充实如何协调伪代码与日常经验来详细阐述后者：<ul><li>第 4.1 节问：这段伪代码如何阐明物理游戏中的笑声——挠痒痒、追逐、躲猫猫、水气球大战等？例如，你为什么不能给自己挠痒痒？</li><li>第 4.2 节问：这段伪代码如何阐明对话中的笑声？例如，笑声如何在不同的环境中传达如此多的不同信息（例如友善与攻击性，或真诚与不真诚）？</li><li>第 4.3 节问：这段伪代码如何阐明幽默和笑话？</li></ul></li><li>第 5 节问：这段伪代码<i>到底</i>是如何在大脑中实现的？我假设下丘脑和/或脑干中的神经元组之间存在与上面的伪代码直接对应的先天连接。唉，我无法准确地告诉你它是哪个神经元组——我认为这是一个还没有人研究过的神经元组。但我想我知道我们应该寻找什么以及在哪里寻找，而且我认为神经科学实验室可以在不久的将来使用标准实验方法来解决这个问题。</li><li>第 6 节是结论，我将在其中讨论这篇文章与我作为 AGI 安全/人工智能一致性研究员的工作有何关系。</li></ul><h1> 2. 进化故事</h1><h2>2.1 什么是游戏，为什么动物有与生俱来的游戏驱动力？</h2><p>在我看来<strong>，游戏的一个中心例子</strong>是两只小动物互相打闹或追逐。</p><p>为什么小动物会这样做？似乎有一个明显的主要解释：</p><ul><li>如果一只松鼠<a href="https://www.youtube.com/watch?v=DdqjR9V8pig"><u>在幼崽时花了很多时间与其他松鼠玩耍和追逐</u></a>，那么它<a href="https://www.youtube.com/watch?v=ZGhZHlpSE6k"><u>在成年后可能会在实际战斗和实际追逐其他松鼠方面</u></a>表现得更好。</li><li>同样，如果一只松鼠在追逐游戏中花了很多时间逃离它的兄弟姐妹，那么它在逃离捕食者时可能也会表现得更好。</li></ul><p>换句话说，<strong>玩耍是应对未来危险情况的练习</strong>。</p><p>拥有天生的游戏<i><strong>内驱力</strong></i><strong>有什么进化优势</strong><strong>？</strong>因为，显然，松鼠幼崽没有远见和知识来从第一原理中推断出花一些空闲时间练习应对未来危险情况是个好主意。因此，玩耍是一种与生俱来的驱动力。</p><p>换句话说：<i>从进化的角度来看</i>，游戏是达到目的的一种手段，但从<i>松鼠一生的角度来看</i>，游戏本身就是一种奖励——它本质上是一种享受。</p><h2> 2.2 什么是先天的交流游戏信号，为什么动物有它们？</h2><p>玩耍信号是指动物玩耍时主要或专门发生的任何发声或肢体语言。</p><p>一个例子是狗的“玩耍弓”（通常伴随着高亢的“玩耍吠叫”）： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/wv8xxg22jkhcjc3kouil" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/icatww4sscedx4ltgrmv 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/bhesr7a3d5vdhxyuodep 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/mwoaui6gninysgzxnys0 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/soxnfi6ajbdvco6se0ls 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/ziijb7pwvvdxlijsvfww 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/euzjo9cyy9glwnucsptr 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/wdyakvp9d3qkpmorxaqf 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/ge1r2lqqc822xrpgwyux 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/jmr5dlt2xyjdkrnq7yep 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/sg4w5gt4gt4snt5m5cjt 857w"><figcaption>狗“拉弓”的例子</figcaption></figure><p>另一种是老鼠的笑声，这是老鼠在各种情况下发出的 50 kHz（超声波）鸣叫声，包括幼鼠之间的打闹。 Jaak Panksepp 和他当时的学生 Jeffrey Burgdorf 首次假设这些叽叽喳喳的声音是 20 世纪 90 年代末老鼠版的笑声；例如，参见他们<a href="https://scholar.google.com/scholar?cluster=14143705629125606901&amp;hl=en&amp;as_sdt=40000005&amp;sciodt=0,22"><u>2000 年发表的这篇论文</u></a>，其中涉及手动给老鼠挠痒痒。</p><p> （我知道你在想什么——但别担心！今天的科学家不再需要忍受用手给老鼠挠痒痒的侮辱。相反， <a href="https://scholar.google.com/scholar?cluster=3513785698040370829&amp;hl=en&amp;as_sdt=0,22"><u>他们可以使用</u></a>“自动挠痒痒方案​​，其中......老鼠被迫移动和互动”带有不断旋转的杆”。）</p><p>关于老鼠笑声的后续工作已经有很多，我将在下面引用其中的一些工作。</p><p>所以无论如何，其他动物也有玩耍信号。为什么人类应该有所不同？更具体地说，我们的黑猩猩表亲会发出类似笑声的喘息声，并且“在被挠痒痒、打闹玩耍和追逐游戏时笑得最多（被追逐的黑猩猩笑得最多）”（这句话以及更多章节中的内容） <a href="https://www.amazon.com/Laughter-Scientific-Investigation-Robert-Provine/dp/0141002255"><u>普罗文的书</u></a>第 5 部分）。</p><p> （参见： <a href="https://youtu.be/ffnyOZGB-Tc?t=14"><u>YouTube 上一只小黑猩猩被挠痒痒的画面</u></a>。）</p><p>因此我们得出这样的理论：笑是人类的游戏信号，与其他动物的游戏信号类似。我认为这个理论至少可以追溯到达尔文； <a href="https://plato.stanford.edu/entries/humor/"><u>SEP 在 1936 年提到了</u></a>Max Eastman。就我而言，我最初是从 Kevin Simler 和 Robin Hanson 所著的<a href="https://www.amazon.com/Elephant-Brain-Hidden-Motives-Everyday/dp/0190495995"><i><u>《Elephant In The Brain》</u></i></a>一书中的一章中听到这个理论的。 （我发现这本书的章节非常有启发性，尽管我不同意他们所说的一切。 <span class="footnote-reference" role="doc-noteref" id="fnrefv8uvhlgfgso"><sup><a href="#fnv8uvhlgfgso">[1]</a></sup></span> ）</p><p><strong>为什么动物有天生的交流游戏信号？</strong>想象一下两只小松鼠正在打架。出于上述原因，这是一项互利的活动。然而，两只小松鼠<i>也</i>有可能<i>真的</i>打架，这种活动对两只松鼠来说都是非常<i>危险的</i>，有时对旁观者来说也是如此。</p><p>现在我们看到了问题：假打斗和真打斗之间有明显的相似之处，以至于<strong>假打斗可能会意外升级为真打斗</strong>。因此，每只松鼠都可以从与另一只松鼠沟通它正在打闹中受益。</p><p>因此，我们期望动物进化出发出游戏信号的先天机制，以及相应的先天机制来注意到这些信号并对它们做出反应。 <span class="footnote-reference" role="doc-noteref" id="fnrefcligk4e8fce"><sup><a href="#fncligk4e8fce">[2]</a></sup></span></p><h1> 3.大脑的故事</h1><h2>3.1 伪代码</h2><p>我将重新复制顶部的框以方便参考 - 我认为它是这样的： </p><figure class="table"><table><tbody><tr><td style="background-color:#fff2cc;border:2px solid hsl(0, 0%, 0%)"><p><strong><u>拟议的笑的大脑伪代码</u></strong>：</p><ul><li> (A) 如果我的下丘脑和脑干收到<i>一些</i>证据表明我处于危险之中<ul><li><i>（这里的“证据”可能是一些相同的信号，它们本身往往会激活交感神经系统）</i></li></ul></li><li> (B) 我的下丘脑和脑干同时获得<i>更有力的</i>证据证明我是安全的<ul><li><i>（这里的“证据”可能是一些相同的信号，它们本身往往会激活副交感神经系统）</i></li></ul></li><li> (C) 我的下丘脑和脑干有证据表明我处于社交场合</li><li>(D) 然后我会发出与生俱来的游戏信号（例如人类的笑声），而且我也会感到更有活力（在边缘），更安全，更少担心等。</li></ul></td></tr></tbody></table></figure><p>可能还有其他各种因素可以调节这个回路（也称为改变阈值）——人与人之间的差异，随年龄的变化（当然还有物种），以及对其他先天信号的依赖（例如，愤怒的人往往笑得更少） 。但我认为上面的方框才是主要的故事。</p><h2> 3.2 “我处于危险之中的证据”等<i>到底</i>是什么意思？这些东西是如何操作的？</h2><p>需要明确的是，我<i>并不是</i>在谈论<i>有意识地相信</i>自己处于危险或安全之中等。例如，即使我有意识地相信自己没有什么可担心的，例如在一部恐怖电影。</p><p>相反，我谈论的是下丘脑和/或脑干中的先天信号——我称之为<a href="https://www.lesswrong.com/posts/hE56gYi5d68uux9oM/intro-to-brain-like-agi-safety-3-two-subsystems-learning-and"><u>“转向子系统”</u></a> 。这些信号（我声称）具有特定的固有“含义”/算法目的，与生态/稳态要求具有明显的关系。例如，请参阅我<a href="https://www.lesswrong.com/posts/4gaeWLhnnBvhamRke/book-review-the-heart-of-the-brain-the-hypothalamus-and-its#3__Case_study_of_hypothalamus__business_logic___NPY_AgRP_neurons"><u>在这里</u></a>对下丘脑中一组特定神经元的讨论，这些神经元由对食物的生理需求激活，并引起适合该状态的各种下游效应（例如能量守恒和饥饿感）。即使我们没有有意识（内感受）地接触到这些先天信号，也没有与它们完美契合的通用英语概念，这些先天信号仍然可以存在。 （请参阅<a href="https://www.lesswrong.com/posts/iYzFKJjzFPRNrqLE3/lisa-feldman-barrett-versus-paul-ekman-on-facial-expressions"><u>我最近发表的关于我与丽莎·费尔德曼·巴雷特（Lisa Feldman Barrett）不同意见的文章</u></a>。）</p><p>无论如何，我在上面的框中建议，“危险”可能通过一些激活交感神经系统（直接或间接）的相同先天信号来操作，而“安全”可能通过一些激活交感神经系统的相同先天信号来操作。副交感神经系统（直接或间接）。具体是哪些信号？我不知道。</p><p>那么成分（C），即“社交”先天信号呢？我对此也不确定。但下丘脑和脑干中似乎确实存在与生俱来的信号（通过进化）与社交情境相关。进化计算此类信号的一种明显方法是通过<a href="https://www.lesswrong.com/posts/hE56gYi5d68uux9oM/intro-to-brain-like-agi-safety-3-two-subsystems-learning-and#3_2_1_Each_subsystem_generally_needs_its_own_sensory_processor"><u>脑干感觉处理系统</u></a>中计算的启发式方法。例如，我最近喜欢的预印本<a href="https://www.biorxiv.org/content/10.1101/2023.05.19.540391"><u>——Liu</u> <i><u>et al.</u></i> <u>(2023)</u></a> — 确定了下丘脑（内侧视前核）中的两组细胞。一组的活动与社会孤立相关，另一组的活动与隔离的结束相关。有趣的是，他们发现，就这两个细胞群而言，“社交”是通过触觉来运作的——不是声音，不是信息素，它必须是触摸。 （老鼠是盲人，所以它们不确定视力。）但是，触摸的中心地位的发现并不能推广到其他社会本能。例如，啮齿动物的另一种社会本能是交配，在这里，先天回路至少部分是由信息素触发的。无论如何，总而言之，我不知道啮齿类动物的笑声成分（C）的“社交”到底是如何计算的，更不用说人类了，但这样的计算绝对是大脑可以做到的事情。</p><h2> 3.3 我喜欢这个提案的三个原因</h2><h3>3.3.1 该伪代码符合第 2 节的进化“规范”</h3><p>我认为这里的对应关系是有力且直接的，我认为这是我走在正确轨道上的关键证据。浏览上面的项目：</p><ul><li> <i>(A)——一些证据表明我处于危险之中。</i>如果我所处的情况会引发一些“战斗或逃跑”的身体反应（无论具体原因如何），那么我几乎肯定处于类似于我将来可能遇到的危险情况的情况。因此，处于这种情况几乎肯定构成良好的“实践”。</li><li> <i>(B)——更有力的证据证明我是安全的。</i>没有这个成分，它就不是“练习”——它是真正的东西！我应该<i>摆脱</i>困境，而不是急于陷入困境！我应该觉得它令人厌恶，而不是有趣。</li><li> <i>(C)——我处于社交场合的证据。</i>如果没有这个成分，它仍然符合“实践”的资格，因此它仍然在进化上适应保持在这种情况下，因此我们的进化期望应该是即使没有成分（C），情况也会“有趣”。但从进化的角度来说，如果没有成分（C），我就不会<i>笑</i>。<i>如果周围没有人听到，那么发出通信信号就没有意义。</i></li></ul><p>我根据各种研究（对人类和老鼠）添加了成分（C），当同种动物在场时，会产生更多的笑声。例如， <a href="https://www.amazon.com/Laughter-Scientific-Investigation-Robert-Provine/dp/0141002255"><u>普罗文</u></a>发现，当人们独处时，笑声的频率会降低 30 倍。 <span class="footnote-reference" role="doc-noteref" id="fnref1r9n4pmqgz5"><sup><a href="#fn1r9n4pmqgz5">[3]</a></sup></span> （我认为自己看电视是一种中间情况——电视可能会欺骗我们的大脑，让我们认为我们处于社交情境中，至少在某种程度上是这样。）</p><p>例如，我的理论是：如果我和朋友一起坐过山车，我们很可能在可怕的部分一起笑；相反，如果我乘坐<i>空荡荡的</i>过山车，看不到或听不到任何人，那么我就不太可能大声笑，但我仍然可能会觉得它很有趣。同样，如果我独自一人，我可能想读一本幽默的书，即使这样做可能不会让我笑出声来。</p><h3> 3.3.2 这种伪代码在神经科学方面非常可信</h3><p>不幸的是，尽管付出了一些努力，我还是无法告诉您实现上框中伪代码的确切神经元。有关更多详细信息，请参阅下面第 5 节。</p><p><i>然而</i>，上面的伪代码与我认为我所了解的有关大脑的一切完全兼容。这对我来说是强有力的证据，因为“我认为我所了解的关于大脑的事情”是高度受限的！ （对于其中一些限制，请参阅我的文章“ <a href="https://www.lesswrong.com/posts/wBHSYwqssBGCnwvHg/intro-to-brain-like-agi-safety-2-learning-from-scratch-in"><u>大脑中的‘从头开始学习’</u></a> ”。并参阅<a href="https://www.lesswrong.com/posts/5F5Tz3u6kJbTNMqsb/intro-to-brain-like-agi-safety-13-symbol-grounding-and-human"><u>我关于社交本能的文章</u></a>，了解这些限制如何在实践中排除许多可能性。）</p><p>特别是，我知道正确类型的信号实际上存在于下丘脑和脑干中（参见上面第 3.2 节），并且我知道基因组很容易能够在（可能）下丘脑中构建一小群神经元，执行必要的逻辑运算。我看到下丘脑中有很多小神经元簇广泛地执行这种基因指定的<a href="https://www.lesswrong.com/posts/4gaeWLhnnBvhamRke/book-review-the-heart-of-the-brain-the-hypothalamus-and-its"><u>业务逻辑</u></a>。</p><h3> 3.3.3 这个伪代码似乎适合人类笑时的数据（以及动物发出类似游戏信号时的数据）</h3><p>据我所知，伪代码与我们对人类笑声和其他动物相应游戏信号的所有体验兼容，包括下面第 4 节中详细阐述的所有三个类别——第 4.1 节中的身体游戏、非“幽默” ” 4.2 节中的对话式大笑，4.3 节中的幽默。</p><p>您可以阅读第 4 节以更好地理解我的观点。但是你应该仔细看看上面第 3.1 节中的伪代码框，然后向下滚动到注释部分，并抱怨该伪代码框的预测是错误的某些情况！</p><p> ......然后我会回应这样的事情：</p><ul><li> “好吧，当然，但那是因为第 3.1 节的伪代码框过于简单化，就像我遗漏了笑反应是如何被与愤怒和交配以及其他类似事物相关的其他先天信号抑制的。”</li><li> “好吧，当然，但我使用了‘安全’和‘危险’这样的词，显然这些只是我能想到的最接近的英语单词，而不是完美的描述，而且它们以各种方式与实际的先天信号分开，顺便说一下，我无法详细说明”。</li></ul><p> ……然后你就会对我翻白眼，指责我特别恳求和不可证伪。</p><p>完全公平！</p><p>但我目前仍然认为我从这个伪代码框中得到的东西比我输入的要多得多——即使不知道相应的神经元在哪里以及它们连接到什么。</p><p> （但是请留下那些怀疑的评论！他们将非常感激！）</p><h1> 4. 将伪代码与日常经验联系起来</h1><p>它们之间没有明显的界限，但我将分别讨论三类：肢体游戏中的笑声、非“幽默”对话中的笑声和幽默。以该顺序：</p><h2> 4.1 肢体游戏中的笑声（例如挠痒痒、追逐、躲猫猫等）</h2><p> （这是最直接的情况，也是人类与其他动物最相似的情况。） </p><figure class="image image_resized" style="width:64.13%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/ebchyilyqsuggtmnawsw" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/khphripzpyad2by4qh41 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/r3h2lhgnjah5isy28tdm 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/ih8lfcypnagdzxltynzd 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/favfninitj7z9re0bhgf 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/wclq1oixf8awu5x4xpho 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/z7giwgnxptperdyu0hpw 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/gow6ozwz2nekf8wfh0aa 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/ffblulfjkar3x3voonne 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/xwtrejdd9n31qkigjhq5 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/ir4xijg6lmerresllig9 1197w"><figcaption>孩子们在玩耍时大笑的例子——被抛到空中（左）或被水枪喷射（右）。图片<a href="https://www.seattlepi.com/national/slideshow/Squirt-gun-fight-14475.php">来源</a>： <a href="https://fineartamerica.com/featured/father-tossing-baby-son-in-air-c1950s-debrockeclassicstock.html">1、2</a></figcaption></figure><h3> 4.1.1 身体游戏中的笑声中“成分（A）”（即危险的证据/生理唤醒的原因）的来源是什么？</h3><p>在物理游戏的笑声中，我认为成分（A）有很多可能的来源，而且大多数都是非常明显的。特别是，我们（像几乎所有动物一样）有各种各样的先天防御反应，包括在我们的例子中：</p><ul><li>对意外的感官输入<a href="https://en.wikipedia.org/wiki/Startle_response"><u>产生惊吓</u></a>和<a href="https://en.wikipedia.org/wiki/Orienting_response"><u>定向反应</u></a></li><li>因预期身体创伤而出现的各种类型的<a href="https://en.wikipedia.org/wiki/Reflex"><u>防御性退缩</u></a></li><li>对摔倒的感觉的一些本能反应</li><li>逃避威胁（“<a href="https://en.wikipedia.org/wiki/Escape_response"><u>逃避反应</u></a>”）</li><li> ETC。</li></ul><p>所有这些先天反应不仅会触发某些肌肉行为，还会触发生理唤醒——因此成分 (A)。</p><p>在所有这些情况下，您都会看到小孩子在玩耍时大声笑。</p><h3> 4.1.2 特别是对挠痒痒的更多讨论</h3><p>我觉得很明显，挠痒痒是打闹的一部分。例如，你身体上最怕痒的部位似乎与最容易受到严重伤害的部位重合，比如脖子的前部。 <span class="footnote-reference" role="doc-noteref" id="fnref34vhiqc4mc2"><sup><a href="#fn34vhiqc4mc2">[4]</a></sup></span>因此，挠痒痒背后的进化故事很简单。大脑层面的故事呢？</p><p>我声称上面 3.1 节的伪代码完全足以解释关于大脑层面的痒痒的一切。为了充实这一点，这里有一些额外的细节和讨论：</p><p>如上所述，挠痒痒中<u>成分 (A) 的来源</u>基本上是正常的<a href="https://en.wikipedia.org/wiki/Startle_response"><u>惊吓</u></a>和对意外感官输入的<a href="https://en.wikipedia.org/wiki/Orienting_response"><u>定向反应</u></a>。但是，出于明显的进化原因，这些先天反应可能对于身体脆弱部位的触觉<i>尤其强烈</i>。想一想在什么情况下这些反应会自然触发——也许有一只蝎子在你的脖子上爬，或者也许你的敌人在战斗中成功地用手掐住了你的脖子，等等。</p><p>你不能给自己挠痒痒，就像当你开始说话时，你通常不会因为自己的声音而产生不自觉的<a href="https://en.wikipedia.org/wiki/Startle_response"><u>惊吓反应</u></a>，也因为同样的原因，当你挥手时，你通常不会产生不自觉的<a href="https://en.wikipedia.org/wiki/Orienting_response"><u>定向反应</u></a>。自己的手在自己的眼前。 （当然，除非你患有精神分裂症——请参阅<a href="https://www.lesswrong.com/posts/tgaD4YnpGBhGGbAy5/model-of-psychosis-take-2"><u>这里</u></a>——或者如果你是个婴儿，第一次发出有趣的声音而让自己感到惊讶，等等。）</p><p>挠痒痒<u>的成分（B）的来源</u>是知道你在值得信赖的朋友身边是安全的。如果你在真正担心自己安全的情况下感到“痒痒”，我的印象是你会尖叫而不是笑。</p><p>与此相关的是，即使有人喜欢被挠痒痒，他们仍然会试图将你的手从最痒的地方推开。这种行为的<i>进化层面的</i>原因是显而易见的：这是打斗游戏运作方式的一部分。否则这很难说是好的防守练习！但<i>大脑层面</i>的原因呢？我建议，当他们的敏感区域成功被挠痒痒时，成分（A）变得如此强烈，以至于切断了成分（B），使体验从有趣变成厌恶。</p><h2> 4.2 非“幽默”谈话中的笑声</h2><h3>4.2.1 背景：大多数对话中的笑声并不是“幽默”</h3><p>即使我们忽略身体游戏，“幽默” <span class="footnote-reference" role="doc-noteref" id="fnrefwfrfar7cs1"><sup><a href="#fnwfrfar7cs1">[5]</a></sup></span>和笑声之间的联系也没有你想象的那么紧密。在 <a href="https://www.amazon.com/Laughter-Scientific-Investigation-Robert-Provine/dp/0141002255"><u>普罗文的书中，</u></a>他谈到了他对现代美国人在公共场合闲逛的“生态”研究，并表示“我的助手估计，只有大约 10%-20% 的[在某人大笑之前的评论]甚至有点幽默”。接下来是一张有用的典型引人发笑的评论表，其中包括诸如“我稍后会见到你们！”之类的俏皮话。和“我可以加入你们吗？”</p><p>下次您在（或无意中听到）正常的面对面小组对话时请密切注意，您可能会注意到类似的情况。</p><p>其他文化在这方面似乎与美国相似——例如<a href="http://www.scholarpedia.org/article/Hunter-Gatherers_and_Play"><u>这篇文章</u></a>讨论了狩猎采集者因温和的戏弄而大笑等——而不是“鸡为什么过马路”。</p><h3> 4.2.2 对话性笑声中的“成分（A）”（即危险证据/生理唤醒原因）的来源是什么？</h3><p>第 4.1.1 节列出了在<i>身体</i>游戏中激发兴奋的一系列明显方式，例如，如果您认为自己独自一人，但有人突然从躲藏的地方跳出来向您尖叫。但是谈话呢？<i>仅仅言语</i>也能引起生理唤醒吗？是的，显然！走进一个有压力的话题会让你的心率加快，就像走进一群愤怒的蜜蜂一样。</p><p>更具体地说，在我看来，对话中成分（A）的天然来源有很多，包括：</p><ul><li>困惑</li><li>尴尬/内疚/羞耻（可能是替代性的）</li><li>厌恶（可能是替代性的）</li><li>惊喜（可能是替代性的）</li><li>威胁（身体威胁和地位威胁）（可能是替代威胁）</li><li>打破禁忌</li></ul><p>这些并不是相互排斥的，而且还有其他的。</p><h3> 4.2.3 笑声传达了关于我短暂的“内部”状态的相当普遍的信息，但随后听者必须推断为什么我有这种感觉，而后一种推断是复杂的、上下文相关的，并且变化很大。</h3><p>请记住，我声称“在练习过程中避免未来危险情况的意外升级”是对为什么大脑笑机制首先存在的进化解释。但<i>考虑到</i>这种大脑机制的存在，它会在很多情况下活跃起来，其中许多可能与“避免在未来危险情况的练习中意外升级”无关。 （参见<a href="https://www.lesswrong.com/posts/XPErvb8m9FapXCjhA/adaptation-executers-not-fitness-maximizers"><u>“适应执行者，而不是健身最大化者”</u></a> 。）我认为这对于人类来说比其他物种<i>更</i>真实，他们似乎大多只是在打闹、追逐游戏等过程中大笑。</p><p>在<i>所有</i>情况下，我认为普遍共享的笑声“含义”与笑者大脑中的某些信号有关，如第 3.1 节的伪代码所示。但随后听者需要从上下文中推断出<i>为什么</i>这些信号出现在笑者的脑海中。事情变得非常复杂和偶然。一些例子：</p><ul><li><u>情景一：</u>中学时你从我身边走过，当时我的隐形眼镜刚刚掉下来。我用绝望的语气说“请帮助我”，你笑着说“对不起，我不帮助失败者”。</li><li><u>我如何看待这一点：</u>我知道你感到安全（成分（B）），我可能猜测这是因为我属于你的外群体，并且你认为我的痛苦不会对你自己的福祉构成威胁。我也知道你觉得有点成分（A），也许我猜你会觉得我一开始就敢向你寻求帮助是一种畏缩。简而言之，你的笑声向我传达了你没有同情心和高人一等的感觉。</li><li><u>情景2：</u>你是我的配偶。我一边说“伙计，我的公司真的很不正常”，一边微微笑着，作为回应，你笑着说“是的”。</li><li><u>我怎么看：</u>嗯，就我而言，我笑主要是因为我对功能障碍感到有点恼火（成分（A）），但也没有为我自己过度担心（成分（B））。然后，当你在回应中大笑时，我可能会推断你对我的幸福投入了精力，并在这两方面同情地反映了我的感受。简而言之，你的笑声向我传达了你的同情心和同志情谊。</li></ul><p>我还可以继续说下去。我认为，在不同的背景下，笑可以表示友谊，或敌意，或优越，或自卑，或真诚，或不真诚，等等。没有简单的理论，因为我们可以出于许多不相关的原因感受到某种方式。</p><h3> 4.2.4 …鉴于笑声能够传达信息，人们巧妙地将笑声作为交流工具包的一部分</h3><p>在上一节中，我含蓄地将笑声视为某人在谈话过程中感受到的情绪的附带副作用。但是，一旦人类（有意识或无意识地）了解到笑声可以传达事物，他们就会开始<i>利用</i>笑声来巧妙地推进他们的交流意图。例如，在上面的场景 2 中，也许您笑的部分<i>原因是</i>您<i>想</i>表达同理心和同志情谊。</p><p>这不一定是有意识的明确决定或愿望，事实上通常可能不是。这可能更常见的是一种无意识的习惯——在之前的很多谈话中，你在特定的背景下以某种方式笑或不笑，这会带来好的结果，所以你无意识地学会了下次重复这种行为。重新遇到类似的情况。</p><p>虽然有目的地控制笑声并不是我在第 3.1 节中写下的“业务逻辑”的直接一部分，但我们显然实际上可以自愿笑。从机制上讲，我认为这通常（尽管并不总是<span class="footnote-reference" role="doc-noteref" id="fnrefb4hvx2pwe9g"><sup><a href="#fnb4hvx2pwe9g">[6]</a></sup></span> ）间接发生——如果我们想笑，我们就会引导自己进入一种具有成分（AC）的短暂情绪状态，如果我们<i>不想</i>笑，我们就会引导自己进入一种情绪状态。一种短暂的情绪状态，<i>不</i>具备所有这三种成分。我们该怎么做呢？好吧，我们对短暂的情绪状态有一定的控制力，因为我们可以关注处境的某些方面而不是其他方面，选择在心理上调用哪些框架/类比等。</p><h2> 4.3 幽默</h2><p>正如上面4.2.1提到的，幽默并不一定会让人发笑，大多数笑声都是在缺乏幽默的情况下发生的。</p><p> That said, humor can obviously lead to laughter, so I ought to briefly say something about how. I don&#39;t have a grand theory of humor, nor do I think there is one, beyond what I&#39;ve already said in this post. I&#39;ll just mention a few considerations that I find helpful to keep in mind when thinking about humor and jokes.</p><h3> 4.3.1 What are the sources of “Ingredient (A)” (ie, evidence of danger / cause for physiological arousal) in humor?</h3><p> I think the list is pretty similar to Section 4.2.2 above for conversational laughter above. I won&#39;t re-copy it—you can scroll up. Again, that list is not exhaustive, nor mutually exclusive.</p><h3> 4.3.2 There&#39;s an inverted-U dynamic for “Ingredient (A)”</h3><p> According to the pseudocode box above, if there is too little of Ingredient (A), there&#39;s no laughter (eg a boring conversation), and if there&#39;s <i>too much</i> (A), then there&#39;s <i>also</i> no laughter, because it undermines Ingredient (B) (eg it might just feel stressful, painful, scary, confusing, etc.) Somewhere in between is optimal for laughter.</p><p> So I think we wind up with inverted-U dynamics like this: </p><figure class="image image_resized" style="width:70.51%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/dxsimdii3jipjtwcteq5" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/m65s9gzgstqaakgexd12 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/hqeoiud5c412kvr8hdhw 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/b7pnh20qevjag7ivn5ai 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/oezoivlqsttjvgwgopco 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/xu8b4ceqxxa14ccbxnle 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/ltqhjjnxgxck4zgvbiwv 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/dghb3hs4pskf0gtvphxm 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/t2kmegbcd84hexaioqlw 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/zfbf7eej24mu1ftigvkd 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/srqjui8mbp9a4bouagns 841w"><figcaption> My theory predicts an inverted-U dependence between Ingredient (A) (in the pseudocode box above) versus laughing—more (A) leads to more laughing, until it&#39;s so much that it cuts off Ingredient (B) and tips to aversion. (See prior discussion of lots of proposed inverted-U&#39;s in humor in <a href="https://www.amazon.com/Psychology-Humor-Integrative-Approach/dp/0128121432"><u>Martin &amp; Ford 2018</u></a> .)</figcaption></figure><p> (I was implicitly talking about this same inverted-U in Section 4.1.2 above, when discussing why someone might enjoy getting tickled a little bit, but find direct tickling of their most ticklish spots to be <i>too much</i> , and thus aggressively push the tickler away.)</p><h3> 4.3.3 The (somewhat arbitrary and drifting) cultural expectations / tropes / rituals surrounding “humor” can be a key component of the explanation of why something is funny.</h3><p> In particular, if a listener has a general cultural expectation that “humor” should involve X (eg a punchline), then a joke-teller can <i>either</i> :</p><ul><li> Increase the amount of Ingredient (B) by conspicuously including X (eg an obvious punchline), <i>OR</i></li><li> Increase the amount of Ingredient (A) by conspicuously <i>excluding</i> X (eg punchline-free absurdist <a href="https://en.wikipedia.org/wiki/Anti-humor"><u>anti-humor</u></a> )</li></ul><p> Either of these can be helpful for the joke, depending on how much (A) and (B) are present from other sources.</p><p> And if the latter (exclusion of X) happens a lot, then we collectively stop expecting X in the first place, causing gradual (anti-inductive <span class="footnote-reference" role="doc-noteref" id="fnref7vihiltl1wd"><sup><a href="#fn7vihiltl1wd">[7]</a></sup></span> ) drifts in what people find funny, or schisms between humor-subcultures.</p><h3> 4.3.4 I&#39;m not generally impressed by “theories of humor” beyond their overlap with the discussion above.</h3><p> For example, the <a href="https://www.amazon.com/Psychology-Humor-Integrative-Approach/dp/0128121432"><i><u>Psychology of Humor</u></i> <u>textbook</u></a> (Martin &amp; Ford 2018) describes three “classic theories of humor” which I will comment on in turn:</p><ul><li> <u>“Relief theory”</u> seems to capture the kernel-of-truth that many instances of humor follow the following time-course: <i>first</i> , we have a bunch of Ingredient (A), and <i>second</i> , something changes and introduces a heap of Ingredient (B) (while the (A) has not yet fully faded from our brainstems). Those two steps can be described as “tension” and “relief of tension” respectively.</li><li> <u>“Superiority theory”</u> seems to capture the kernel-of-truth that, in many instances of humor, Ingredient (A) is vicarious—from imagining someone in danger or duress—while Ingredient (B) comes from my comfort in the knowledge that I, the listener, am not that person, and am superior to that person, and have therefore nothing to fear for myself.</li><li> <u>“Incongruity theory”</u> strikes me as a mishmosh of different things. For example, Ingredient (A) can be based on the feeling of confusion, and (B) by its resolution. Or Ingredients (A) and (B) can come from different (incongruous) ways to view the same situation, one of which is normal / safe and the other embarrassing / dangerous / etc. In still other cases, I wonder whether we&#39;re all just following a cultural telling-a-joke script, and as a listener, Ingredient (A) is my concern that I don&#39;t “get the joke” and will be embarrassed to admit it, and Ingredient (B) is my relief when I do. <span class="footnote-reference" role="doc-noteref" id="fnrefikpolxri2te"><sup><a href="#fnikpolxri2te">[8]</a></sup></span> It can also be several of these things simultaneously, and more.</li></ul><p> After that, the textbook moves on to discuss three “contemporary theories of humor” (“reversal theory”, “comprehension-elaboration theory”, and “benign violation theory”). My comments on those would largely overlap with the above bullet points, so I&#39;ll just move on.</p><h1> 5. More detailed discussion of the neuroscience</h1><h2> 5.1 Overview</h2><p> The kind of <a href="https://www.lesswrong.com/posts/4gaeWLhnnBvhamRke/book-review-the-heart-of-the-brain-the-hypothalamus-and-its"><u>“business logic”</u></a> pseudocode of Section 3.1 is to be found, I claim, in what I call the “Steering Subsystem” (hypothalamus and brainstem—see definition and discussion <a href="https://www.lesswrong.com/posts/hE56gYi5d68uux9oM/intro-to-brain-like-agi-safety-3-two-subsystems-learning-and"><u>here</u></a> ). My guess is more specifically as follows: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/leosou3rtkiyirfpehod" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/ujuedwlmm3dbdmbjbttq 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/yjn5d7d8xbmkzzwudqpd 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/bzy6ukm6m8kqsknw0i0i 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/vpghumpc2tor0bjhx73z 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/vlaxjkcqakkihmbqwi9x 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/q78lge8vqgdgpilvinoo 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/bmr53pm1hix6vl7osi0a 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/y01cp19oberkrbt8ryz6 1280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/eqqsconoltp9sbrcufhu 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7kdBqSFJnvJzYTfx9/c3zll5rr3axazecnaiip 1540w"></figure><h2> 5.2 Where <i>exactly</i> in the brain is the “laugh behavior controller” (top box in that diagram) where I can read out the alleged pseudocode of Section 3.1?</h2><p> Sadly, I have failed to deduce from existing literature where in (probably) the hypothalamus we would find the core “business logic” pseudocode of Section 3.1. (It could also be split among a couple places.)</p><p> Focusing on rats (although I expect the answer to be similar in humans), one candidate mentioned in the literature is the so-called “parvafox nucleus” of the lateral hypothalamus. Check out<a href="https://scholar.google.com/scholar?cluster=12802221367573840133&amp;hl=en&amp;as_sdt=0,22"><u>Alvarez-Bolado &amp; Celio (2016)</u></a> for an argument along those lines. As far as I can tell, the strongest evidence in favor of this hypothesis is that bilateral destruction of the parvafox nucleus dramatically (factor of >;10) reduces rodent laughter, according to <a href="https://doi.org/10.1016/j.bbr.2015.11.004"><u>Roccaro-Waldmeyer</u> <i><u>et al.</u></i> <u>(2016)</u></a> . Relatedly, there is some evidence (including from laughter-inducing “gelastic seizures”) that “stimulations of [the] tuberal portion [of the lateral hypothalamus] provoke bursts of laughter” (<a href="https://scholar.google.com/scholar?cluster=12802221367573840133&amp;hl=en&amp;as_sdt=0,22"><u>Alvarez-Bolado &amp; Celio (2016)</u></a> ), and that&#39;s in the general vicinity of parvafox.</p><p> However, I think the current balance of evidence is that parvafox is <i>not</i> the controller for laughter, but rather is related to defense behavior—based on both direct stimulation of those cells (eg <a href="https://www.biorxiv.org/content/10.1101/2023.01.10.521942"><u>Cola</u> <i><u>et al.</u></i> <u>(2023)</u></a> ), and looking at where in the brain they project to (eg <a href="https://scholar.google.com/scholar?cluster=1669280582819001741&amp;hl=en&amp;as_sdt=0,22"><u>Celio</u> <i><u>et al.</u></i> <u>(2013)</u></a> , <a href="https://scholar.google.com/scholar?cluster=9172453117902267421&amp;hl=en&amp;as_sdt=0,22"><u>Bilella</u> <i><u>et al.</u></i> <u>(2016)</u></a> ). We still need to explain the Roccaro-Waldmeyer results from the previous paragraph, but there are a couple possibilities for that, including (1) that parvafox is essential for “Ingredient (A)” of the pseudocode of Section 3.1 (and thus upstream of laughter), or (2) that parvafox is <i>physically proximate to</i> the “real” laugh behavior controller and that Roccaro-Waldmeyer destroyed the latter accidentally in their experiments. (Lesion experiments are notorious for “collateral damage” of nearby neurons and fibers, if I understand correctly, but be warned that I&#39;m not an expert.)</p><p> Well, if it&#39;s not parvafox, then what is it?</p><p>我不知道。 If someone wanted to make progress on this question experimentally—to actually find that pseudocode implemented via innate brain signaling pathways—I think an obvious immediate next step would be a retrograde neural tracing experiment starting from the (lateral) part of periaqueductal gray (PAG) associated with laughter (as pinpointed in the very recent article <a href="https://www.cell.com/neuron/abstract/S0896-6273(23)00477-4"><u>Gloveli</u> <i><u>et al.</u></i> <u>(2023)</u></a> ), followed by further characterization of whatever upstream neuron-groups show up. Maybe such data already exists, and I missed it. (Parvafox does <i>not</i> seem to project to the correct part of PAG to match up with the Gloveli <i>et al.</i> neurons, as far as I can tell, although I&#39;m not super-confident.)</p><p> Areas that I see as <i>especially suspicious</i> include:</p><ol><li> neurons nearby but not part of the parvafox nucleus, in the tuberal region of lateral hypothalamus (for reasons stated above);</li><li> neurons somewhere in or around the medial preoptic area of the hypothalamus—for which stimulation can cause rat laughter ( <a href="https://scholar.google.com/scholar?cluster=8163760487852460824&amp;hl=en&amp;as_sdt=0,22"><u>Wintick &amp; Brudzynski (2001)</u></a> ), and which is known to be the home of the main behavior controllers for at least two other positive social behaviors that I know of, namely the behavior studied by <a href="https://www.biorxiv.org/content/10.1101/2023.05.19.540391"><u>Liu</u> <i><u>et al.</u></i> <u>(2023)</u></a> mentioned above, plus aspects of mating as discussed in <a href="https://www.cell.com/cell/abstract/S0092-8674(23)00798-5"><u>Bayless</u> <i><u>et al.</u></i> <u>(2023)</u></a> ;</li><li> more generally, the rest of the hypothalamus too.</li></ol><h2> 5.3 What about the “Learning Subsystem” (cortex, striatum, amygdala, hippocampus, etc.)?</h2><p> As I described <a href="https://www.lesswrong.com/posts/hE56gYi5d68uux9oM/intro-to-brain-like-agi-safety-3-two-subsystems-learning-and"><u>here</u></a> , I claim that the brain should be divided into two subsystems, the “Learning Subsystem” which runs <a href="https://www.lesswrong.com/posts/wBHSYwqssBGCnwvHg/intro-to-brain-like-agi-safety-2-learning-from-scratch-in"><u>randomly-initialized learning algorithms</u></a> , and the “Steering Subsystem” which runs <a href="https://www.lesswrong.com/posts/4gaeWLhnnBvhamRke/book-review-the-heart-of-the-brain-the-hypothalamus-and-its"><u>“business logic”</u></a> . Above I was only talking about the “Steering Subsystem”; but in fact laughter also interacts with the “Learning Subsystem”—ie, the cortex, striatum, amygdala, hippocampus, thalamus, cerebellum, etc.</p><p> I claim that  the laughter-triggering signals coming from the Learning Subsystem are in the following two categories:</p><ul><li> (A) Outputs trained by reinforcement learning to maximize some signal from the Steering Subsystem (hypothalamus &amp; brainstem) that acts as a “reward”, or</li><li> (B) <a href="https://www.lesswrong.com/posts/Y3bkJ59j4dciiLYyw/intro-to-brain-like-agi-safety-4-the-short-term-predictor"><u>“Short-term predictors”</u></a> of some signal from the Steering Subsystem.</li></ul><p>例如：</p><ul><li> An example of (A) would be voluntary / learned control of laughter (Section 4.2.4).</li><li> An example of (B) would be a “self-fulfilling prophecy”, where you laugh because you&#39;re in a situation that pattern-matches to other situations that have caused you to laugh in the past.</li></ul><p> I think there are probably other examples too, but that&#39;s outside the scope of this post.</p><p> Direct evidence that the cortex is not <i>necessary</i> for play is provided by “decorticate” rats (= rats whose cortex has been surgically removed), whose play is “much the same [as] controls” ( <a href="https://psycnet.apa.org/record/1990-98262-005"><u>Whishaw 1990</u></a> , <a href="https://www.sciencedirect.com/science/article/abs/pii/0031938494902852"><u>Panksepp</u> <i><u>et al.</u></i> <u>1994</u></a> ). I can&#39;t immediately find direct measurements of the presence of the normal 50kHz “laughing” vocalizations in decorticate rats while they play, but if their play is similar in other respects, I would certainly <i>guess</i> that they are also vocalizing in a roughly normal way.</p><h1> 6. Conclusion</h1><p> I remain adamant that the hypothalamus and brainstem are full of hundreds-to-low-thousands of specific neuron groups with specific connections that are all written directly into the genome, and which correspond to <a href="https://www.lesswrong.com/posts/4gaeWLhnnBvhamRke/book-review-the-heart-of-the-brain-the-hypothalamus-and-its"><u>“business logic”</u></a> that makes evolutionary sense—things like “if you&#39;re malnourished, reduce your sex drive”. I think that <i>understanding</i> this tangle of “business logic” is annoying but possible, and that doing so seems possibly helpful for AGI safety, for reasons spelled out <a href="https://www.lesswrong.com/posts/qusBXzCpxijTudvBB/my-agi-safety-research-2022-in-review-and-plans#2__Second_half_of_2022__1_3___My_main_research_project"><u>here</u></a> .</p><p> I consider laughter an “easy” example of such business logic, as compared to something like the human innate status drive (assuming that there <i>is</i> a human innate status drive, which I currently believe but am not 100% sure). I think the human innate status drive would need substantially more convoluted pseudocode than the box in Section 3.1, and I don&#39;t even have a plausible guess right now for how it works in detail. (See <a href="https://www.lesswrong.com/posts/5F5Tz3u6kJbTNMqsb/intro-to-brain-like-agi-safety-13-symbol-grounding-and-human"><u>here</u></a> for vague thoughts.) So maybe this post on laughter is a warm-up. In particular, I don&#39;t think this post is <i>directly</i> important for AGI safety—if we iron out the details of the pseudocode of Section 3.1, and put it into the source code of future AGIs, and then we find that those AGIs are laughing in a vaguely-psychopathic-human-like way while they mercilessly murder me and my family and every other human … then that doesn&#39;t really make me feel much better!</p><p> Still, even if understanding laughter is just a “warm-up” for more safety- and alignment-relevant things like compassion and friendship, I am still very interested in getting this right! I spent much longer on this blog post than usual (admittedly a low bar), including trying to be reasonably comprehensive in reading relevant sources, etc., and I am very eager for feedback.</p><p> <i>(Thanks Seth Herd, Linda Linsefors, Justis Mills, and Miguel De Guzman for critical comments on drafts.)</i> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnv8uvhlgfgso"> <span class="footnote-back-link"><sup><strong><a href="#fnrefv8uvhlgfgso">^</a></strong></sup></span><div class="footnote-content"><p> Since the works of Robin Hanson are popular on this forum, I will say a bit more about where I differ from <i>Elephant In The Brain</i> . My biggest complaint is the part where they say:</p><blockquote><p> As we mentioned earlier, people are profoundly ignorant about laughter&#39;s meaning and purpose (at least in our default state, before learning the science). But where does this ignorance come from? Why does introspection fail us so spectacularly here?</p><p> It&#39;s not simply because laughter is involuntary, outside our conscious control. Flinching, for example, is also involuntary, and yet we understand perfectly well why we do it: to protect ourselves from getting hit. Thus our ignorance about <i>laughter</i> needs further explanation.</p></blockquote><p> I disagree that it “needs further explanation”. I think <a href="https://www.lesswrong.com/posts/wBHSYwqssBGCnwvHg/intro-to-brain-like-agi-safety-2-learning-from-scratch-in"><u>we start out ignorant of</u> <i><u>literally everything</u></i></a> , until we learn it / figure it out. And I think that figuring out the evolutionary purpose of laughter is just inherently much harder than figuring out the evolutionary purpose of flinching. It&#39;s less obvious / salient, for various reasons that I claim are pretty obvious if you think about it. I don&#39;t think there&#39;s any more to it than that.</p><p> I also don&#39;t think there <i>can</i> be more to it than that. To explain what I mean by that, imagine if I said: “Here&#39;s the source code for training an image-classifier ConvNet from random initialization using uncontrolled external training data. Can you please edit this source code so that the trained model winds up confused about the shape of Toyota Camry tires <i>specifically</i> ?” The answer is: “Nope.对不起。 There is no possible edit I can make to this PyTorch source code such that that will happen.” By the same token, <i>even if</i> , as that book argues, there is a strong evolutionary pressure to make humans <i>specifically</i> confused about the evolutionary purpose of laughter, I don&#39;t think there is any possible genetic change that would make that happen. Related discussion <a href="https://www.lesswrong.com/posts/5F5Tz3u6kJbTNMqsb/intro-to-brain-like-agi-safety-13-symbol-grounding-and-human#13_2_2_Claim_2__Social_instincts_are_tricky_because_of_the__symbol_grounding_problem_"><u>here</u></a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fncligk4e8fce"> <span class="footnote-back-link"><sup><strong><a href="#fnrefcligk4e8fce">^</a></strong></sup></span><div class="footnote-content"><p> Whenever there&#39;s a claim about communicative signals, one can ask a follow-up question of whether these signals are game-theoretically stable against “lies”. Like, what if Squirrel A laugh-squeaks to signal play, then Squirrel B lets down its guard, then Squirrel A attacks for real? If this happened a lot, wouldn&#39;t squirrels eventually evolve to ignore play signals? And if <i>that</i> happened, then wouldn&#39;t squirrels further evolve to stop emitting play signals in the first place? Good question! It&#39;s worth thinking about those kinds of things. But I do think a good answer exists, even if I don&#39;t know it in full detail. I think there are various ways that signals can be hard or costly to fake. And I also think that animals treat a play-signal <i>by itself</i> as insufficient reason to let down one&#39;s guard, which reduces the benefit of lying. Animals are reacting to other cues too, like whether there is an existing trusting relationship. For example, if I&#39;m a prisoner, and the cruel guard is pointing at me and laughing, that sure wouldn&#39;t make me feel more relaxed.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn1r9n4pmqgz5"> <span class="footnote-back-link"><sup><strong><a href="#fnref1r9n4pmqgz5">^</a></strong></sup></span><div class="footnote-content"><p> I think Provine&#39;s claim that there&#39;s 30× more laughter in social situations is less clear-cut than it sounds. In fact, it&#39;s hard to do an apples-to-apples comparison of laughter in social versus nonsocial situations, because (1) social situations are drawn from a different distribution from nonsocial situations in many respects, (2) the presence of other people can change Ingredients (A) and (B) too, and (3) social situations can also affect laughter via voluntary control (Section 4.2.4). I still think (C) is <i>probably</i> a real ingredient in the algorithm, because Provine&#39;s factor of 30 is <i>so extreme</i> that it seems difficult to fully explain by any of those indirect mechanisms.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn34vhiqc4mc2"> <span class="footnote-back-link"><sup><strong><a href="#fnref34vhiqc4mc2">^</a></strong></sup></span><div class="footnote-content"><p> I&#39;m extremely far from an expert on what parts of the body are vulnerable in combat today, let alone 100,000 years ago (How often were people punching each other, versus slashing with sharp rocks, versus getting bitten by wolves or spiders? What were the lived consequences of different types of injuries? Beats me!). But I still think this claim is probably true. For example, <a href="https://jamanetwork.com/journals/jama/article-abstract/395461"><u>this article</u></a> claims that ticklish areas correlate with areas protected by involuntary defensive reflexes.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnwfrfar7cs1"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwfrfar7cs1">^</a></strong></sup></span><div class="footnote-content"><p> I am defining the word “humor” narrowly—something like “humor = the kind of stuff you find in the &#39;humor&#39; section of a bookstore”, eg recognizable jokes and so on. On this definition, if someone walks up to my lunch table and says “can I join you?” and then laughs a bit, that&#39;s conversational laughter but not “humor”. I believe <a href="https://www.penguinrandomhouse.com/books/332702/laughter-by-robert-r-provine/">Provine</a> takes this definitional approach.</p><p> Alternatively, one could define the word “humor” very broadly, as something like “humor = whatever makes someone spontaneously laugh”. On this definition, it&#39;s perfectly possible that someone walking up to my lunch table and saying “can I join you?” <i>is</i> an instance of “humor”, when taken with its full context. I believe <a href="https://mitpress.mit.edu/9780262518697/inside-jokes/">Hurley <i>et al.</i></a> take this definitional approach.</p><p> Anyway, this is just semantics. “Humor” is just a word, and within limits, we can define it however we want. I find the narrow definition to be helpful for the purposes of this post, so that&#39;s how I&#39;m using it.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnb4hvx2pwe9g"> <span class="footnote-back-link"><sup><strong><a href="#fnrefb4hvx2pwe9g">^</a></strong></sup></span><div class="footnote-content"><p> Transient manipulation of our own emotional state is not the only method of learned / deliberate manipulation of laughter. Alternatively, you can laugh by pure voluntary motor control—just move your larynx, lungs, etc. and make laugh sounds, the same way you might voluntarily move your arm. I think such laughter can come across as fake sometimes (like maybe it can sound slightly different, and the eyes don&#39;t squint in quite the same way, see <a href="https://en.wikipedia.org/wiki/Smile#Duchenne_smile">Duchenne smile</a> )—although people still do it plenty.</p><p> Incidentally, I think the “summoning transient emotions” method of laughing and the “pure voluntary motor control” method of laughing in this footnote are probably two opposite ends of a spectrum, as opposed to a crisp binary.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn7vihiltl1wd"> <span class="footnote-back-link"><sup><strong><a href="#fnref7vihiltl1wd">^</a></strong></sup></span><div class="footnote-content"><p> If you haven&#39;t heard the term “anti-inductive”: &quot;Inductive&quot; reasoning is where you assume that if you&#39;ve seen something a bunch of times in the past, then it&#39;s likely to happen again in the future. “Anti-inductive” reasoning is the opposite—the more past evidence you have for something, the more likely it is to be <i>false</i> next time.</p><p> As the old joke goes: “I recommend anti-inductive reasoning to anyone. After all, using anti-inductive reasoning has been a catastrophically bad idea every time I&#39;ve tried it in the past. So it&#39;s <i>definitely</i> a good idea going forward.”</p><p>这是一个例子。 If you&#39;re up against a master at rocks-paper-scissors, you might want to use anti-inductive reasoning about the future: The <i>more</i> evidence you have for a pattern in your opponent&#39;s behavior, the likelier it is that your opponent <i>wants</i> you to notice that pattern, and therefore the more you should expect that pattern to reverse on the next throw. (But this is happening at every level of abstraction simultaneously—which is kinda weird to think about.)</p></div></li><li class="footnote-item" role="doc-endnote" id="fnikpolxri2te"> <span class="footnote-back-link"><sup><strong><a href="#fnrefikpolxri2te">^</a></strong></sup></span><div class="footnote-content"><p> I suspect that kids will laugh a comparable amount in practice when solving a riddle / brainteaser posed by a friend as when “getting” a pun told by the same friend, other things equal. Other things are not always equal though; puns often get an extra emotional “kick” from some other source, like from being sexual, or from the friend&#39;s mood, or just from the very fact that it&#39;s a pun, both because there&#39;s a <a href="https://tvtropes.org/pmwiki/pmwiki.php/Main/Pun"><u>cultural trope</u></a> that making puns is a shameful activity, and because puns are “supposed” to be funny and the expectation of laughter can be a self-fulfilling prophecy, see Section 5.3 below.</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/7kdBqSFJnvJzYTfx9/a-theory-of-laughter#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/7kdBqSFJnvJzYTfx9/a-theory-of-laughter<guid ispermalink="false"> 7kdBqSFJnvJzYTfx9</guid><dc:creator><![CDATA[Steven Byrnes]]></dc:creator><pubDate> Wed, 23 Aug 2023 15:05:59 GMT</pubDate> </item><item><title><![CDATA[Why Is No One Trying To Align Profit Incentives With Alignment Research?]]></title><description><![CDATA[Published on August 23, 2023 1:16 PM GMT<br/><br/><p> A whole lot of Alignment work seems to be resource-constrained. Many funders have talked about how they were only able to give grants to a small percentage of projects and work they found promising. Many researchers also receive a small fraction of what they could make in the for-profit sector (Netflix recently offered $900k for an ML position). The pipeline of recruiting talent, training, and hiring could be greatly accelerated if it wasn&#39;t contingent on continuing to receive nonprofit donations.</p><h3></h3><h3> <strong>Possible Ideas</strong></h3><p></p><h2> AI Auditing Companies</h2><p> We&#39;ve already seen a bit of this with ARC&#39;s eval of GPT4, but why isn&#39;t there more of this? Many companies will/are training their own models, or else using existing models in a way beyond what they were intended. Even starting with non-cutting-edge models could provide insight and train people to have the proper Security Mindset and understanding to audit larger ones. Furthermore, there has been a push to regulate and make this a required practice. The possibility of this regulation being made into law will likely be contingent on the infrastructure for it already existing. And it makes sense to take action toward this now, if we want those auditing teams to be as useful as possible, and not merely satisfy a governmental requirement. Existential concerns would also be taken more seriously by a company that has already built a reputation for auditing models.</p><p> <strong>Evals reporting</strong></p><p> Companies don&#39;t want to see their models doing things that weren&#39;t intended (example, giving people credit card information, as was just recently demonstrated). And as time goes on, companies will want some way of showcasing their models have been rigorously tested. Audit reports covering a large, diverse set of vulnerabilities is something many will probably want.</p><p> <strong>Red teaming</strong></p><p> Jailbreaking has been a common practice, done by a wide number of people after a model is released. Like an Evals Report, many will want a separate entity that can red team their models, the same way many tech companies hire an external cybersecurity company to provide a similar service.</p><p></p><h2> Alignment as a service</h2><p> This could bring in new talent and incentives toward building better understanding and talent to handle alignment. These services would be smaller scale, and would not tackle some of the “core problems” of alignment, but might provide pieces to the puzzle. Solving alignment may not be one big problem, but actually a thousand smaller problems. This gives market feedback, where the better approaches succeed more often than the worse approaches. Over time, this might steer us in a direction of actually coming up with solutions that can be scaled.</p><p></p><p> <strong>Offer procedures to better align models</strong></p><p> Many companies will likely not know how to get their models to do the things they want them to, and they will want assistance to do it. This could start by assisting companies with basic RLHF, but might evolve to developing better methods. The better methods would be adopted by competing Alignment providers, who would also search for even better methods to provide.</p><p> <strong>Caveat</strong> : might accelerate surface-level alignment, but just further a false sense of security.</p><p></p><h2> Alignment as a Product</h2><p> This isn&#39;t the ideal approach, but one still worth considering. Develop new proprietary strategies for aligning models, but don&#39;t release them to the public. Instead, show the results of what these new strategies can do to companies, and sell them the strategy as a product. This might involve NDAs, which is why it is not an ideal approach. But an alignment strategy existing under an NDA is better than no strategy at all.</p><p></p><h2> Mech Interp as a Service</h2><p> This is perhaps not yet in reach, but might be in time. Many will want to better understand how their models are working. A team of mechanistic interpretability researchers could be given access to the model, and dive into gaining a better understanding of its architecture and what it&#39;s actually doing, providing a full report of their findings as a service. This might also steer Mech Interp toward methods that have actual predictive value.</p><p> <strong>Caveat</strong> : I&#39;m not too confident about Mech Interp being useful for safety, with the downside that it might be useful for capabilities.</p><p></p><h2> Governance Consultation as a Service</h2><p> Many politicians and policy makers are currently overwhelmed with a problem they have little technical understanding of. A consultation service would provide them with the expertise and security understanding to offer policy advice that would actually be useful. The current situation seems to be taking experts who are already severely time-constrained, and getting their advice for free. I think many would pay for this service, since there are demands for legislation, and they don&#39;t have the understanding to do it on their own.</p><p></p><h2> Alignment Training as a Service</h2><p> Offering to train workers currently at AI companies to understand security concerns, alignment strategies, and other problems might be desired by many companies. An independent company could train workers to better understand concepts that many are probably not used to dealing with.</p><p></p><h2> Future Endowment Fund</h2><p> This is the one that&#39;s the furthest away from normal ideas, but I&#39;d love it if more people tried to hack a solution to this. The biggest issue is that the value from alignment research has a time delay. This solution could be something like a Promise of Future Equity contract. Those that do research would receive a promised future share in the Fund, as would investors. Companies that use anything that was funded by the Endowment would sign something like a Promise of Future Returns, delegating a share of the returns of any model that used the strategy to the fund. This way, people who were also working on alignment strategies that only had a 5% chance of working would still get reimbursement for their work. Those working on strategies with a calculated higher chance of working would get a greater share. The Trustees would be members of the community who are highly credible, and who have deep levels of insight about AI.</p><p></p><p> If you are interested in making progress on any of these endeavors, feel free to message me. I&#39;ve worked in Cybersecurity, so I have a good understanding of how the auditing pipeline normally works at such companies.</p><p> If you have any disagreements with some of these approaches (which I&#39;m sure some do), feel free to tell me why I&#39;m wrong in the comments.</p><br/><br/> <a href="https://www.lesswrong.com/posts/XnAZHCi5QH58WcrkX/why-is-no-one-trying-to-align-profit-incentives-with#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/XnAZHCi5QH58WcrkX/why-is-no-one-trying-to-align-profit-incentives-with<guid ispermalink="false"> XnAZHCi5QH58WcrkX</guid><dc:creator><![CDATA[Prometheus]]></dc:creator><pubDate> Wed, 23 Aug 2023 13:16:42 GMT</pubDate> </item><item><title><![CDATA[Exploring the Responsible Path to AI Research in the Philippines]]></title><description><![CDATA[Published on August 23, 2023 8:44 AM GMT<br/><br/><h3><strong>介绍</strong></h3><p>The transformative potential of artificial intelligence (AI) is reshaping our world, presenting both thrilling opportunities and profound challenges. In the Philippines, where Dominic Ligot (Founder, AI expert &amp; communicator) <span class="footnote-reference" role="doc-noteref" id="fnrefgdz3m8hstr8"><sup><a href="#fngdz3m8hstr8">[1]</a></sup></span> and I have delved into AI&#39;s possibilities, the integration of this technology into our unique cultural fabric can unleash exponential productivity. This post explores how we (as a country) can harness AI to enhance our local community without losing our distinct identity. With our shared fascination as a spark, I&#39;ll examine the broader implications of AI, guided by the imperative to understand its complexities and the need to proceed with caution and adherence to alignment research <span class="footnote-reference" role="doc-noteref" id="fnref4w360g923mp"><sup><a href="#fn4w360g923mp">[2]</a></sup></span> .</p><p></p><h3> <strong>Transformative Technologies and AI Research</strong></h3><p> <i>The Transformative Potential of AI</i></p><p> AI stands as a transformative technology, holding the potential to reshape our world in the coming decade. The failure to understand and integrate AI could leave a country behind in a rapidly changing landscape.</p><p> <i>Historical Precedence of Technological Transformations</i></p><p> Technological advancements have driven significant transformations. Whether through the application of cutting-edge physics in warfare or the discovery of new scientific fields, technological innovations have often led to pivotal moments in human history.</p><p> <i>The Complexity and Urgency of AI Research</i></p><p> AI research is neither simple nor conceptually straightforward. The very complexity of the field underscores the importance of pursuing a deep understanding of it. While the path towards mastering AI may seem daunting and even wild, the stakes are too high for complacency.</p><p> <i>The Inevitable Direction of AI Research</i></p><p> Our current situation leaves us with few choices but to embrace AI research. It&#39;s not merely an option; it&#39;s an essential direction we must take to ensure our survival in a future increasingly shaped by artificial intelligence. The question is not whether we should pursue AI research, but how we can do so most effectively and responsibly.</p><p> Having explored the immense transformative power of AI and its historical parallels, it&#39;s essential to consider both the challenges and promises this complex field presents to us today.</p><p></p><h3> <strong>Upsides and Downsides</strong></h3><p> <i>AI Research Challenges and Uncertainties</i></p><p> AI research at present resembles alchemy more than mathematics. We still lack a formal theory on the malleability of data that can be infused into models, making our understanding of how data gets distributed to individual parts, such as tokens or layers, uncertain. These distributional shifts affect how technology can respond in a generalizable manner. Despite the absence of a formalized mathematical approach, the uncertainties should not halt our pursuit of research.</p><p> <i>Statistics on Project Failures</i></p><p> Projects fail around 65% of the time. <span class="footnote-reference" role="doc-noteref" id="fnrefrgyrt2chqg"><sup><a href="#fnrgyrt2chqg">[3]</a></sup></span> While a disheartening statistic, it serves as a reminder that our resources can become losses if not handled wisely. The possibility that some actions might create more problems than they solve emphasizes the importance of accurately identifying methodologies and conceptual frameworks in AI research. Careful planning can avoid potential losses and unintended consequences.</p><p> <i>The Promising Benefits of AI Technology</i></p><p> The potential benefits of AI technology are simply astounding. Utilizing AI to solve local productivity issues is a top priority, and it could be the catalyst we need. Innovating new ways to enhance the economy and personal lives can be substantial. However, realizing these benefits requires prioritizing alignment work. Ensuring rigorous consideration for human welfare before deploying technology is non-negotiable.</p><p> While the upsides of AI research are astonishing, the uncertainties and potential pitfalls demand a closer look. Let&#39;s explore the vital need for caution, consideration, and alignment in AI research.</p><p></p><h3> <strong>The Stakes of AI Research: A Call for Consideration and Caution</strong></h3><p> <i>Acknowledging the Complexity: A Personal Reflection</i></p><p> This is my first time into pondering these concepts, I am compelled to tackle them with sincerity and diligence. The urgency of establishing a responsible research direction for AI, particularly for a vast and diverse demographic, is palpable. When executed well, the benefits can multiply exponentially.</p><p> <i>The Opportunity and Challenge: A Thoughtful Approach to AI Research</i></p><p> Anyone who considers stepping into the world of AI research, Filipino or otherwise, must heed this reality: Understanding AI as a technology presents enormous opportunities. However, transforming such opportunities into triumphs rather than missteps demands more than mere instinct; it requires more:</p><ol><li> Planning and Prudence: Embarking on this path warrants careful planning and utmost caution. The AI landscape, rich with potential, is equally laden with pitfalls that can result in profound hardship and sacrifice.</li><li> Learning from History: We must remember that uncharted domains of human endeavor often bring pain and struggle before innovation flourishes. Let our approach to AI be informed by these historical lessons, striving for thoughtful innovation rather than hasty experimentation.</li></ol><p> <i>A Responsibility to Proceed with Care</i></p><p> The stakes of our engagement with AI are indeed extraordinarily high. This is not just a technological venture; it&#39;s a complex human enterprise that requires mindful consideration of ethics, alignment, and the social fabric of our communities.</p><p> I cannot envision AI research succeeding without individuals, teams, organizations, or governments factoring in alignment as a core component. AI systems think differently—using tokens, not words, and <a href="https://www.lesswrong.com/tag/transformers">transformer models</a> that is still not fully understood. Engaging in any research agenda without exercising the level of caution required by alignment is undoubtedly a recipe for disaster. A useful concept to illustrate this is whether an AI system exhibits <a href="https://www.lesswrong.com/tag/corrigibility">corrigible properties</a> . Is the AI system willing to allow itself to be modified or shut down when necessary? Even if the AI might not be directly utilized for output in research, it&#39;s safer to recognize if these technologies are not yet robust enough to ensure safety. Taking the time to deeply understand how different AI systems are will certainly aid in advancing AI research.</p><p></p><p> We can build a sturdy bridge to AI success. We can reap the rewards of understanding AI technologies if we prioritize safety.</p><p></p><p> <strong>Contrasting Outcomes: Binisaya Buddy and Local Lore</strong></p><p> I wrote a post on two striking examples that illustrate the importance of responsible AI development: Binisaya Buddy, a virtual guide reflecting Cebuano culture, values, and traditions, and Local Lore, a misguided attempt at cultural representation. <span class="footnote-reference" role="doc-noteref" id="fnref19z9hnoglxt"><sup><a href="#fn19z9hnoglxt">[4]</a></sup></span></p><ol><li> <i>Binisaya Buddy:</i> Born in vibrant Cebu, this project represents the potential when alignment theory guides AI research. It serves both locals and tourists by authentically mirroring cultural nuances.</li><li> <i>Local Lore:</i> In contrast, Local Lore lacked local insight, leading to misrepresentations and disconnection from the community it aimed to serve. A poor execution created more problems than solutions.</li></ol><p> Through the examples of Binisaya Buddy and Local Lore, we see both success and failure in aligning AI with cultural values. These case studies underscore the necessity of not only individual responsibility but also strategic collaboration at various levels to ensure that AI development is aligned with our cultural context and ethical values.</p><p></p><p> These contrasting outcomes highlight the importance of building an integrated system where various stakeholders work together towards responsible AI development. What form might such collaboration take, and how can it be cultivated to ensure that technology truly serves our community&#39;s needs and values?</p><p></p><h3> <strong>A Potential Pathway: Collaboration Between Government, Corporations and Academia</strong></h3><p> The journey toward harnessing the full potential of AI in the Philippines requires more than isolated efforts by individual sectors. It demands a cohesive and strategic collaboration between government bodies, corporations, and academic institutions. Here&#39;s how can this tripartite collaboration can foster responsible AI development:</p><p> <strong>Government&#39;s Role:</strong></p><ul><li> Regulatory Frameworks: By establishing clear and ethical guidelines for AI development, the government can ensure that technological advancements align with national values and societal needs.</li><li> Investment and Support: Government investment in AI research and development, infrastructure, and education can catalyze growth in the sector, supporting both public and private initiatives.</li></ul><p> <strong>Corporate Sector&#39;s Contribution:</strong></p><ul><li> Practical Application: Corporations leads in transforming theoretical research into practical solutions. Collaborating with academia to develop innovative technologies, industry players can focus on addressing local challenges.</li><li> Private Investments: By investing in AI and partnering with educational institutions, businesses can create a thriving ecosystem that promotes technological entrepreneurship and job creation.</li></ul><p> <strong>Academic Institutions as Catalysts:</strong></p><ul><li> Research and Innovation: Universities and research institutions serve as the backbone of cutting-edge exploration in AI. Collaborative research with corporations ensures that academic findings translate into real-world applications.</li><li> Education and Training: Academia plays a vital role in nurturing the next generation of AI experts. By aligning curricula with industry needs and government visions, educational institutions can prepare a skilled workforce ready to contribute to responsible AI development.</li></ul><p> <strong>Potential Cross-Sector Collaboration</strong></p><ul><li> Shared Goals and Strategies: By setting common objectives and collaborative platforms, the three sectors can align their efforts, maximizing efficiency and impact.</li><li> Ethics and Alignment: Ensuring that AI development adheres to ethical principles requires input from all three sectors. This collaboration ensures that technological advancements contribute to human flourishing without compromising cultural identity.</li></ul><h3></h3><h3><strong>结论</strong></h3><p>The possible collaboration between government, industry, and academia isn&#39;t merely a beneficial alliance; it might be an essential strategy for responsible AI development in the Philippines. By recognizing their unique roles and working together towards a shared vision, these sectors can leverage AI&#39;s transformative potential without losing sight of ethical considerations and local values.</p><p> <i>The end goal is human flourishing.</i></p><p> Ultimately, the goal of any AI research, project, or even personal endeavor is human flourishing. To achieve this, a level of alignment work is required to ensure that the results will contribute to improving our lives. The larger the project, the greater the level of alignment work that must be included.</p><p> Our exploration of AI&#39;s potential and challenges culminates in a broader perspective. With the lessons learned and the stakes understood, let&#39;s envision the unique role that the Philippines can play in this rapidly evolving field, with an emphasis on alignment and cultural identity.</p><p> <i>The Road Ahead: Philippines and AI</i></p><p> With 115 million inhabitants, including a vast English-speaking demographic, the Philippines stands at a crossroads. Our journey with AI is not merely about innovation; it&#39;s about a responsible, ethical approach to technology. Both general AI research and alignment work are two sides of the same coin, vital for moving forward in an AI-shaped world. The stakes are immense, and the potential enormous. Our country must not settle for anything less than an approach that harmonizes general research with alignment to our shared values (global and local) and cultural identity.</p><h3></h3><h3> <strong>Addendum</strong></h3><p> After finishing this write-up, I learned of a proposal by Congressman Mark Go, the Representative from the City of Baguio. He informed the Philippine Congress of his initiatives to propose a national drive to train 1% of Filipinos in AI technology and to establish a grant facility for AI research. Though no bill has been drafted yet, it goes to show that this write-up is both relevant and timely. You can see the presentation and with Doc&#39;s commentary <a href="https://www.youtube.com/watch?v=i00ZCE3udAk">here.</a> </p><p></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fngdz3m8hstr8"> <span class="footnote-back-link"><sup><strong><a href="#fnrefgdz3m8hstr8">^</a></strong></sup></span><div class="footnote-content"><p> Dominic Ligot is the Founder of CirroLytix, a social impact AI company, and Data Ethics PH, an online community focused on social issues such as data privacy, data security, AI-driven discrimination, data liabilities, data ownership rights, and data poverty. Three-time global winner of the NASA and ESA International Space Apps Challenges, his team&#39;s award winning dengue surveillance application, AEDES, has been backed by the Group on Earth Observations (GEO), the Digital Public Goods Alliance (DPGA) and the UNICEF Innovation Fund.</p><p> You can find his complete profile <a href="https://docligot.com/">here.</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn4w360g923mp"> <span class="footnote-back-link"><sup><strong><a href="#fnref4w360g923mp">^</a></strong></sup></span><div class="footnote-content"><p> When I refer to alignment research / work, I mean the effort that goes into understanding the alignment problem and its complexity. It&#39;s hard for me to recommend alignment theory as a standard, especially since it&#39;s not yet a concrete science on how to align AI systems and make them understand and preserve human values, and we&#39;re all still figuring things out. However, as a reference, <a href="https://www.lesswrong.com/posts/bjjbp5i5G8bekJuxv/study-guide">John Wensworth&#39;s study guide</a> is a good introduction to the complex nature of the theoretical areas intertwined with alignment.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnrgyrt2chqg"> <span class="footnote-back-link"><sup><strong><a href="#fnrefrgyrt2chqg">^</a></strong></sup></span><div class="footnote-content"><blockquote><p> But research shows that only 35% of the projects undertaken worldwide are successful—which means we&#39;re wasting an extravagant amount of time, money, and opportunity.</p></blockquote><p></p><p> Quoted from <a href="https://hbr.org/2021/11/the-project-economy-has-arrived">The Project Economy Has Arrived</a> by Antonio Nieto-Eodriguez of Harvard Business Review</p></div></li><li class="footnote-item" role="doc-endnote" id="fn19z9hnoglxt"> <span class="footnote-back-link"><sup><strong><a href="#fnref19z9hnoglxt">^</a></strong></sup></span><div class="footnote-content"><p> From my blog: <a href="https://www.whitehatstoic.com/p/binisaya-buddy-and-local-lore">https://www.whitehatstoic.com</a> :</p><h3> Binisaya Buddy and Local Lore</h3><p> Subtitle: Alignment and Misalignment: A Tale of Two AI Systems Bridging Culture and Technology in the Philippines </p><figure class="image image_resized" style="width:57.35%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/bucxqobmbsdsytuueaos" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/j61mpzznl8fnnaxvj82e 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/aoljkptxyxmjcnzpslml 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/e3esjc3vtk1fz8gcf2u8 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/kdawakp2svpclhpfuf7b 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/mbkqfq08riaztzscujnc 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/tavmhtvyztvxvteyimex 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/xpgegixjph35p0xni7hf 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/ejeiieuk55e9lcqhtjyr 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/rxyebd4ryiw0dvubbvii 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/g45pp3gkkjty54n9wxbh 1024w"></figure><p></p><p> In the picturesque Island of Cebu, renowned for its vibrant heritage and breathtaking landscapes, an innovative AI system was built to bridge the gap between locals and tourists. Named &quot;Binisaya Buddy,&quot; after the local dialect, this AI system was designed with a deep understanding of Cebuano culture, values, and traditions.</p><p> Visitors arriving at the Mactan-Cebu International Airport were greeted by Binisaya Buddy through interactive kiosks. With a friendly virtual smile, the AI would share stories of Cebu&#39;s rich history, explain the significance of traditional dances like the Sinulog, offer tips on enjoying local delicacies like Lechon, and even teach a few essential phrases in the local language.</p><p> But what set Binisaya Buddy apart was its alignment with the local culture. The AI was not just a repository of information; it was a reflection of the Cebuano soul. Locals were involved in its development, ensuring that it captured the nuances of their beliefs, values, and way of life.</p><p> Tourists found themselves immersed in an authentic Cebuano experience, facilitated by a technology that felt personal, respectful, and connected. Locals, on the other hand, felt a sense of pride in how their culture was represented and shared.</p><p> Binisaya Buddy became more than a tool; it became a symbol of how technology, when aligned with human values, can enhance cultural understanding, foster connections, and create meaningful experiences.</p><p> In another bustling city not far from Cebu, an ambitious project was launched to create an AI-driven tourist guide. Named &quot;Local Lore,&quot; this system was designed to offer tourists a glimpse into the local culture, traditions, and history.</p><p> However, unlike Binisaya Buddy, Local Lore was developed without local input, guided solely by algorithms fed with data from generic travel sites and social media. The lack of alignment with the community&#39;s values and understanding of their unique cultural nuances led to unintended consequences.</p><p> Soon after its launch, locals began to notice misrepresentations. Local Lore described the Sinulog Festival as merely a colorful party, missing its deep religious significance. It recommended commercialized tourist traps over authentic local experiences, and its language translations were often inaccurate, leading to unintentional offenses.</p><p> The community felt alienated and misunderstood. They saw their rich culture reduced to stereotypes and misconceptions, a caricature rather than a celebration.</p><p> Tourists, initially excited by the novel technology, were left confused and disconnected from the real essence of the place. The lack of authenticity in the Local Lore&#39;s guidance led to missed opportunities for genuine cultural immersion and understanding.</p><p> In time, Local Lore was abandoned, a failed experiment that served as a stark reminder of what can go wrong when technology is not aligned with the human values, context, and culture it aims to represent. It became a cautionary tale of how even well-intended innovation can lead to destruction when the alignment is overlooked.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/yEx2LfYEGaWQE8dHp/exploring-the-responsible-path-to-ai-research-in-the#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/yEx2LfYEGaWQE8dHp/exploring-the-responsible-path-to-ai-research-in-the<guid ispermalink="false"> yEx2LfYEGaWQE8dHp</guid><dc:creator><![CDATA[MiguelDev]]></dc:creator><pubDate> Wed, 23 Aug 2023 08:44:18 GMT</pubDate> </item><item><title><![CDATA[Do agents with (mutually known) identical utility functions but irreconcilable knowledge sometimes fight?]]></title><description><![CDATA[Published on August 23, 2023 8:13 AM GMT<br/><br/><p> Been pondering; will conflict always exist? A major subquestion: Suppose we all merge utility functions and form an interstellar community devoted to optimizing the merger. It&#39;ll probably make sense for us to specialize in different parts of the work, which means accumulating specialist domain knowledge and becoming mutually illegible.</p><p> When people have very different domain knowledge, they also fall out of agreement about what the borders of their domains are. ( <i>EG: A decision theorist is insisting that they know things about the trajectory of AI that ML researchers don&#39;t. ML researchers don&#39;t believe them and don&#39;t heed their advice.</i> ) In these situations, even when all parties are acting in good faith, they know that they wont be able to reconcile about certain disagreements, and it may seem to make sense, from some perspectives, to try to just impose their own way, in those disputed regions.</p><p> Would there be any difference between the dispute resolution methods that would be used here, and the dispute resolution methods that would be used between agents with different core values? (war, peace deals, and most saliently,)</p><p> Would the parties in the conflict use war proxies that take physical advantages in different domains into account? (EG: Would the decision theorist block ML research in disputed domains where their knowledge of decision theory would give them a <i>force</i> advantage?)</p><br/><br/> <a href="https://www.lesswrong.com/posts/FTdtHHBPDdzk4pJz2/do-agents-with-mutually-known-identical-utility-functions#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/FTdtHHBPDdzk4pJz2/do-agents-with-mutually-known-identical-utility-functions<guid ispermalink="false"> FTdtHHBPDdzk4pJz2</guid><dc:creator><![CDATA[mako yass]]></dc:creator><pubDate> Wed, 23 Aug 2023 08:13:06 GMT</pubDate></item></channel></rss>