<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 12 月 1 日星期五 22:11:00 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Complex systems research as a field (and its relevance to AI Alignment)]]></title><description><![CDATA[Published on December 1, 2023 10:10 PM GMT<br/><br/><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 00:43:15 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 00:43:15 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>我有一个很重要的认识：复杂系统类型的思维通常是一个陷阱。我已经就此进行了几次对话，但仍然感到有点困惑，在这里更好地记录我和你的想法似乎很好。</p><p>从较高的层面来看，当我思考复杂的系统问题时，特别是在人工智能对齐的背景下，我会想到以下一些想法：</p><ul><li>有几次，我花了很多时间试图理解一些复杂系统的人们试图说什么，结果却认为他们并没有真正说什么。我想我是通过与一群圣达菲的东西和西蒙·德迪奥的作品接触而得到这种感觉的（就像<a href="http://www.mdpi.com/1999-5903/8/2/14">这篇论文</a>和<a href="https://arxiv.org/abs/2006.02359">这篇论文</a>）</li><li>我的关于群体如何取得智力进步的模型的一部分是，核心要素之一是拥有共同的语言和方法，允许“集体对话”之类的东西逐步向前迈进。比如，你有一个解决经验问题的实验和统计分析的概念，或者你有一个解决逻辑不确定性问题的证明概念，从某种意义上说，许多跨学科工作的前提是缺乏共同的方法论和语言。</li><li>虽然我最近对此感到更加困惑，但我仍然对<a href="https://en.wikipedia.org/wiki/G_factor_(psychometrics)">g 或正流形</a>之类的东西有相当强的先验，其中，有一些方法论基础对于人们相互交谈很重要，但大多数差异人们对解决问题做出贡献的能力取决于他们的聪明程度、能力和知识，而专业知识通常被高估（例如，研究人员在两个领域获得诺贝尔奖的情况并不罕见）。很多跨学科的工作（不一定是复杂的系统工作，但我觉得我在 PIBBS 背后看到了一些生成器）感觉它比我更重视知识多样性。 </li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 00:53:26 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 00:53:26 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>好吧，从一个高层次的观点开始：我绝对不愿意死在“复杂系统研究”作为一个科学领域的山上。我同意这个标签下发生了很多糟糕或有点空洞的工作。 （我认为您链接的第一篇 DeDeo 论文就是一个很好的例子：感觉主要是拥有一些很酷的方法并将其应用于一些随机现象，而没有真正令人兴奋的更大愿景来理解更深入的事物，等等。）</p><p>也就是说，有很多事情可以被描述为适合复杂系统标签，我对此感到积极，让我们尝试举几个例子：</p><ul><li>我确实认为，与你的第二点相反，复杂系统研究（至少是更好的例子）有很多/足够的共享方法论，可以从你所描述的相同的认知错误纠正机制中受益。从历史上看，它确实源于物理学、网络科学、动力系统等。发生的主要举措是说，而不是根据它所研究的自然现象或领域（例如生物学、化学、经济学）来索引领域的边界，而是将其索引到一组查询方法上，前提是您可以在不同类型的系统/域中有效地应用这些方法，并获得对跨系统管理这些现象的基本原理的宝贵理解（例如，塑造生物有机体的缩放法则）以及城市的发展等）</li><li>我认为（通常）复杂系统的角度更能解释环境与主体的相互作用。朴素还原论有一种失败模式，它首先修复环境，以便能够磨练哪些系统内部差异产生了哪些现象差异，然后得出结论，所有驱动现象的因素都是系统内部的，而忘记了这一点他们之前所做的是人为地修复环境，以降低手头问题的复杂性。修复复杂交互方程的一部分通常很好而且实际上很有用，但你不应该忘记这就是你一路上所做的。同样，复杂系统镜头往往更擅长关注跨抽象层次的交互，以及这些交互中出现的动态，这对于理解自然现象似乎也很有价值。 </li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 00:52:03 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 00:52:03 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><blockquote><p>相反，将其索引到一组调查方法上，前提是您可以在不同类型的系统/域中有效地应用这些方法，并获得对跨系统管理这些现象的基本原理的宝贵理解（例如，将生物有机体塑造为尺度法则）以及城市的发展等）</p></blockquote><p>好吧，我真的很喜欢这一举措，并且通常认为各个领域围绕方法论比围绕主题更加统一。所以也许我只是缺乏对复杂系统人员的方法论的连贯指导。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 00:57:56 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 00:57:56 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>嗯，我想我对复杂系统的想法可以分为两个方向：</p><p><strong>胜利在哪里？</strong>这种方法有什么成功的案例吗？我曾经是网络科学的粉丝，但后来就不再喜欢它了。我喜欢物理学，尽管物理学本身很大，而且有很多功能障碍，所以导入物理学方法论的哪一部分确实很重要。</p><p><strong>好吧，那么基础是什么？</strong>看起来我确实对这个领域的方法论没有很好的内部了解。也许我应该去维基百科上阅读那里的方法摘要。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:00:13 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:00:13 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><blockquote><p>很多跨学科的工作（不一定是复杂的系统工作，但我觉得我在 PIBBS 背后看到了一些生成器）感觉它比我更重视知识多样性。</p></blockquote><p>热衷于谈论我关心的认知多元化类型（以及 PIBBSS 背景下的其他类型）。</p><p> （一般来说，我认为“一般智慧”的担忧与我对认知多元主义的思考方式非常正交，至少我觉得我不必被迫在两者之间进行权衡。我们可以分别双击如果你愿意的<i>话</i>，但让我首先尝试论证为什么我认为它们是正交的。）</p><p>我认为 PIBBSS 风格工作的一个相关前提（至少正如我上面所描述的那样，它与复杂系统镜头共享）是一些假设，即存在一些基本原则来管理跨不同系统、基质和规模的智能行为。如果是这样的话，这就是解决我们无法直接访问我们最担心的人工智能系统的问题的一种方法。但是，如果我们认为它们与实现智能行为的其他类型的系统共享<i>一些</i>功能/原则，重要的是我们确实有更好的认知访问程度的系统，那么我们现在可以开始在我们对这些不同系统的理解之间进行三角测量。通过这种三角测量，您可以对与基底/规模/系统无关的那些原理获得更深入的见解。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:02:49 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:02:49 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>总的来说，我对研究我们现有系统中的智能行为非常同情和感兴趣。然而，我确实注意到，不知怎的，我想不出这个领域的任何工作对我来说非常有用，至少在最近几年是这样。我真的很喜欢埃利以泽对进化的分析，将其作为人工智能对齐的类比，它对我产生了很大的影响。我喜欢 Steve Byrnes 的研究神经科学的工作，以深入了解人工智能对齐问题，尽管他们在某种程度上感觉是分开的（但这可能真的只是我的不公正划分），并且目标是制作更多像原始作品一样的作品进化的LW序列分析和AI比对，我会感到非常兴奋。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:04:43 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:04:43 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>粗略地说，我的感觉是，可以从不同的角度来解决这个问题。一般来说，我对“让我了解复杂系统科学”的框架感到有点犹豫——就像我认为这个概念并不是真正雕刻世界的最有用的方式（例如，我认为阅读维基百科页面上的这个内容不会那个令人兴奋）。我确实认为，如果您正在寻找一些关于如何对不同类型的系统进行建模的想法，以及所需的数学知识，那么有些复杂系统教科书是相当简洁的。但除此之外，至少根据我的口味，我会说考虑一下您有兴趣理解哪些自然现象，然后尝试找到谁在该现象上做有趣的工作，或者（数学上）建模它的方法是什么富有成效。我想我的经验更接近于a）对理解某些现象感兴趣，b）在那里找到一些我发现可以有效参与的工作，c）注意到其中一堆可以被标记为复杂系统的东西。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:04:34 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:04:34 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>好吧，在这种情况下，我问的具体问题是“这里有一个领域，它的方法论是什么？”。我对自然现象进行了大量研究，并且一般都在寻找好的数学模型，但我很少最终找到被标记为“复杂系统”的东西。我通常喜欢最终学习生物学、物理学、人工智能或数学。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:07:00 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:07:00 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>以下是我正在考虑的您的具体引述：</p><blockquote><p>我确实认为，与你的第二点相反，复杂系统研究（至少是更好的例子）有很多/足够的共享方法论，可以从你所描述的相同的认知错误纠正机制中受益。从历史上看，它确实源于物理学、网络科学、动力系统等。</p></blockquote><p>在我看来，你似乎在暗示这里有一个领域，它有一个认知棘轮，可以随着时间的推移向前推进并取得连贯的进展。但我目前觉得我对棘轮的机制还没有很好的了解。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:19:47 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:19:47 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>你知道<a href="https://www.amazon.com/Introduction-Theory-Complex-Systems-Thurner/dp/019882193X/ref=asc_df_019882193X/?tag=hyprod-20&amp;linkCode=df0&amp;hvadid=312152840806&amp;hvpos=&amp;hvnetw=g&amp;hvrand=15805346042964868981&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=1013585&amp;hvtargid=pla-561851596697&amp;psc=1&amp;mcid=ee4d371124353a0da64f86a8b0a83255&amp;tag=&amp;ref=&amp;adgrpid=61316181319&amp;hvpone=&amp;hvptwo=&amp;hvadid=312152840806&amp;hvpos=&amp;hvnetw=g&amp;hvrand=15805346042964868981&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=1013585&amp;hvtargid=pla-561851596697&amp;gclid=CjwKCAiAvJarBhA1EiwAGgZl0KNSZABSw9gcydbqlEvAAQLD7v1vS3dmVIlO5eron7VdFsnTYkH9_BoCwVsQAvD_BwE">这本教科书</a>吗？我想说这是对“复杂系统建模工具箱”的一个很好的概述。</p><p>如果你想对复杂系统有一个更尖锐、或者更雄心勃勃的愿景，你可以听听<a href="https://www.preposterousuniverse.com/podcast/2023/07/10/242-david-krakauer-on-complexity-agency-and-information/">David Krakauer 的采访</a>。我的猜测是，你会在很大程度上摆脱它，尽管我确实认为这非常令人兴奋（尽管采访比乍一看更密集）。他谈到了理解“telic”现象（或一些类似的术语），他将其理解为（我的粗略解释）是从进化和元进化等适应性系统中获得的特定约束中产生的。在我看来，这很有趣“理解代理/智能行为的基础”角度，例如，您最终试图用自然主义术语解释诸如代理/规划的“向后因果关系”特征之类的事物如何从简单的动态中产生。</p><p>就系统进步而言，一方面，我认为进步也与其他科学领域相结合——就像复杂系统一样，作为一个领域，跨越了更传统的科学领域划分方式，所以我认为没有一种先验的方法可以将进步准确地归因于其中任何一个。但我认为进步的机制来自于[数学模型工具箱（例如网络科学、动力系统、控制理论等）]以及更抽象和更具体/经验之间的相互作用。</p><p>也许我今天太混淆了，但我认为这与所有其他科学领域都是一样的，主要的区别在于一些不可靠的前提。也许最清晰的例子是从古典经济理论到复杂性经济学的转变。在前者中，您从一组假设开始，例如：理性行为者，所有代理都是相同的，市场是均衡系统。然后复杂性经济学出现并说：嘿伙计们，好消息，我们现在拥有比算术更好的数学工具，因此我们现在能够放松一些经典假设，并且可以使用以下前提对经济系统进行建模：有界理性代理（具有学习和记忆动力学等）、异质代理（例如不同的学习策略）、市场作为均衡系统之外的。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:24:22 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:24:22 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><blockquote><p>你知道<a href="https://www.amazon.com/Introduction-Theory-Complex-Systems-Thurner/dp/019882193X/ref=asc_df_019882193X/?tag=hyprod-20&amp;linkCode=df0&amp;hvadid=312152840806&amp;hvpos=&amp;hvnetw=g&amp;hvrand=15805346042964868981&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=1013585&amp;hvtargid=pla-561851596697&amp;psc=1&amp;mcid=ee4d371124353a0da64f86a8b0a83255&amp;tag=&amp;ref=&amp;adgrpid=61316181319&amp;hvpone=&amp;hvptwo=&amp;hvadid=312152840806&amp;hvpos=&amp;hvnetw=g&amp;hvrand=15805346042964868981&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=1013585&amp;hvtargid=pla-561851596697&amp;gclid=CjwKCAiAvJarBhA1EiwAGgZl0KNSZABSw9gcydbqlEvAAQLD7v1vS3dmVIlO5eron7VdFsnTYkH9_BoCwVsQAvD_BwE">这本教科书</a>吗？我想说这是对“复杂系统建模工具箱”的一个很好的概述。</p></blockquote><p>我不！我可能会看一下。</p><blockquote><p>然后复杂性经济学出现并说：嘿伙计们，好消息，我们现在拥有比算术更好的数学工具，因此我们现在能够放松一些经典假设，并且可以使用以下前提对经济系统进行建模：有界理性代理（具有学习和记忆动力学等）、异构代理（例如不同的学习策略）、市场作为平衡系统之外的。</p></blockquote><p>是的，这绝对是一件听起来很酷的事情，但它真的有效吗？就像，我对经济学没有那么扎实的基础，但我确实读了很多经济学博客，并用我自己的语言思考了很多经济学问题，而且我并没有经常遇到复杂性经济学的观点，而且确实有点期望如果我要阅读一篇关于复杂性经济学的“顶级”论文，我最终会感到失望。但我也可能只是缺乏参考资料。</p><p>例如，这与气候计量学/计量经济史之类的东西形成鲜明对比，我发现它非常有价值，并且有很多关于历史如何运作的很酷的模型，但对我而言，感觉不是很复杂的科学。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:26:37 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:26:37 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><blockquote><p>然而，我确实注意到，不知怎的，我想不出这个领域的任何工作对我来说非常有用</p></blockquote><p>我部分同意你的观点，并希望我能指出更多、更容易理解的例子。 （同时，我觉得我没有太多让我觉得特别令人兴奋的例子。）</p><p>对当前更多工作的一些不全面的指导：</p><ul><li>层级机构/协调工作，以及 ACS 讨论/开展的其他事项</li><li>开发智能现象的自然化描述（例如代理、计划、欺骗、权力寻求、中度优化），其中自然化描述旨在描述现象的潜在机制，以便您可以在它发生在（时间、空间）时识别它你还没有进化到能够识别现象的尺度——希望这可以提供更强大的方法来做到这一点，例如可解释性和评估</li><li>对交互人工智能系统有更原则性的理解，例如，一堆LLM系统在实际应用中相互交互会产生什么样的进化/涌现动态（例如，迅速进化、具有不同能力概况的支架代理的出现等）</li><li>描述“混乱”的人工智能风险场景，例如<a href="https://www.lesswrong.com/posts/BTApNmv7s6RTGxeP4/cyborg-periods-there-will-be-multiple-ai-transitions">多重转型</a>、RAAP、多重委托、提升经济</li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:28:47 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:28:47 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>因此，维基百科关于复杂性经济学的文章说：</p><blockquote><p> Hidalgo 和 Hausmann <a href="https://en.wikipedia.org/wiki/Complexity_economics#cite_note-HidalgoHausmannPNAS-6"><sup>[6]</sup></a> <a href="https://en.wikipedia.org/wiki/Complexity_economics#cite_note-ComplexityAtlas-7"><sup>[7]</sup></a>提出的<a href="https://en.wikipedia.org/wiki/Economic_complexity_index">经济复杂性指数</a>（ECI）可以高度预测未来人均 GDP 增长。在 Hausmann、Hidalgo 等人的文章中， <a href="https://en.wikipedia.org/wiki/Complexity_economics#cite_note-ComplexityAtlas-7"><sup>[7]</sup></a>作者表明，未来 GDP 国家列表（基于 ECI）估计 ECI 预测未来人均 GDP 增长的能力比世界高 5 倍到 20 倍世行的治理衡量标准、世界经济论坛 (WEF) 的全球竞争力指数 (GCI) 以及人力资本的标准衡量标准，例如受教育年限和认知能力。 <a href="https://en.wikipedia.org/wiki/Complexity_economics#cite_note-8"><sup>[8]</sup></a> <a href="https://en.wikipedia.org/wiki/Complexity_economics#cite_note-9"><sup>[9]</sup></a></p></blockquote><p>就像，我不知道，这听起来很酷，但我诚实的最佳猜测是，这在某种程度上是假的？就像，如果我研究一下这个问题，我会发现“过去的人均GDP增长”比这个经济复杂性指数或类似的东西更好的预测指标，而他们可以声称这个结果的唯一原因是因为他们不公正地划分了经济复杂性指数。以某种方式替代。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:35:07 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:35:07 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>好吧，我用谷歌搜索了一下，我找不到任何明显的删除，揭露 ECI 明显被不公正地划分选区，而我们的数据世界（他们通常看起来很合理，而且他们以一种很酷的方式思考这个问题）有一个他们的博客上<a href="https://ourworldindata.org/how-and-why-econ-complexity">有关于它的好评文章</a>，所以我更新这里有一些更真实的东西。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:33:38 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:33:38 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>是的，我确实对明显的成功低于我的模型预测的成功感到有些困惑。</p><p>这让我对该方法的总体前景进行了一些更新，但我对模型的其他部分也有不确定性，例如我期望在什么时间尺度上取得什么成功以及“成功”会是什么样子。另外，我认为存在一些动态，例如“一旦某件事取得成功，它就会更加融入主线，从而不再被认为是（曾经）非正统的方法”。肯定会发生这样的事情。我知道他们通过放弃“市场是均衡系统”的假设，在金融危机等建模方面取得了一些成功；我记得读过一些报告（我相信是一些国际治理机构，经合组织等，但不记得细节了），其中包含有关气候变化和可持续发展的经济建议，这些建议显然是受复杂性经济学启发，听起来相当合理，我知道稍微介绍一下 Hidalgo 的<a href="https://oec.world/en">这项工作</a>，基于相对浅显的外观，它看起来相当酷（部分原因是它使一堆非常酷的现实世界数据变得可访问）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:42:27 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:42:27 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>嗯，关于经济指数的东西：我的意思是对这一切的一个简单的看法是这样的</p><ul><li>当然，该地区真正发生的事情是极其复杂的（例如，存在历史路径依赖性，存在国民经济所嵌入的全球经济，国家的特定资源、基础设施、劳动力等。 ）</li><li>看起来基本上所有古典经济模型都大大简化了现实，并且非正统的方法正在使其中一些假设更加现实</li><li>问题是，相对于您所付出的复杂性成本，您的模型（或特定的复杂化）的复杂性在预测能力方面为您带来了多少</li><li>对于像经济学这样的领域来说，另一件<i>奇怪的</i>事情是，经济理论发生在它试图预测的系统<i>内</i>（并从而影响）。例如，当世界银行发布一些预测时，它本身会影响例如流入该国的投资、存款利息等。这使得经济学（以及其他领域）与物理学有很大不同，在物理学中，在大多数情况下，您实际上有理由忽视这一事实理论家在理论中。 </li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:49:29 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:49:29 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><blockquote><p>对于像经济学这样的领域来说，另一件<i>奇怪的</i>事情是，经济理论发生在它试图预测的系统<i>内</i>（并从而影响）。例如，当世界银行发布一些预测时，它本身会影响例如流入该国的投资、部门的利益等。这使得经济学（在其他领域中）重要性不同于物理学，在大多数情况下，您实际上有理由忽略以下事实：理论家在理论中。</p></blockquote><p>我同意这有一定的现实性，但我确实认为这是一种感觉像是被选择来感觉聪明或元的效果，但实际上并不重要？就像，我同意美联储当然会通过说出它将做什么来对经济做什么产生一些影响，但我发现自己怀疑你是否必须真正考虑到在你发布你的政策后人们将如何改变他们的行为的影响。经济理论，除了对美联储设定的目标利率进行建模之外。</p><p>就像，我并不否认这里有一些影响，但我怀疑它会很大。</p><p>这与某人进行经验观察的情况有很大不同，经验观察结果要么是人类强制政策的结果，要么因其规律性而变成了人类强制政策。例如，我发现摩尔定律的稳健性源自主要半导体制造商根据摩尔定律设定内部目标的故事，有点有前途且有趣。</p><p>但这感觉与说你需要考虑经济中认真对待你的经济理论的参与者的自我参照效应不同。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:51:38 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:51:38 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>目前我最好的猜测是，它确实很重要（尽管时间尺度比逐年预测稍大一些）。就像，我认为历史和社会系统的路径依赖（受某种形式的差异选择影响的一切事物的路径依赖）是一件大事。我对有哪些替代的功能经济逻辑非常感兴趣，并且对于考虑到物理学的现实我们可能永远无法在这个分支中探索它们这一事实感到非常悲伤。这些东西在科学上绝对难以处理，因为它涉及我们无法访问的反事实，因此很难甚至不可能校准它是否是一个大问题。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:55:12 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:55:12 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>与我对其他人直觉的猜测相比，我想这是一个很好的例子，说明我的直觉受到复杂系统镜头的影响。<br><br>我对路径依赖程度的思考方式大致如下：一个吸引力是，如果你有一些相对简单的复杂动态，初始条件的微小差异可能会传播很大，局部意外事件会让你访问路径的不同部分。可能性树，有时以很难逆转的方式。来自另一边的拉力是，如果你能指出一些主动缓冲这种路径依赖性的机制，例如某种趋于将系统保持在某个盆地内的稳态压力。这两种机制都存在——总的来说，我预计社会经济历史更多地受到前者的影响（例如，生物有机体的发育/生命周期更多地受到后者的影响）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:53:53 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:53:53 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>我的意思是，我完全可以说“初始条件很重要，有些系统很混乱，很难预测它们最终会在哪里，因为它们非常敏感”。但这与“专门分析经济理论和政策的自我参照性质值得付出复杂性的代价”不同。就像，我不认为一旦你考虑了自我参照效应，系统就会停止混乱，我也不认为系统会因为你的出版物引入的自我参照成分而变得混乱。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:57:41 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:57:41 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>是的，好吧，所以我同意你的观点，我预计技术设计的影响（以一年到十年的时间尺度）比宏观经济学更大。 （我不认为这意味着这种效应不适用于宏观经济学，而是宏观经济学生活在较慢的时间尺度上。就像，这种路径依赖的镜头适用于经济学逻辑，但更多所以在几十年到几个世纪的时间尺度上。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:56:53 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:56:53 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>举个例子，我认为微观经济学的所有基础知识都没有太多的自我参照效应。他们的有效性范围以及他们的预测对于这类东西来说似乎是可靠的。无论人们是否了解供给和需求，供给都会等于需求。工资将会是粘性的，无论人们是否知道工资是粘性的（这里可能有一些影响，但我认为它很弱）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:58:27 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:58:27 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><blockquote><p>“专门分析经济理论和政策的自我参照性质是值得付出巨大代价的”。就像，我不认为一旦你考虑了自我参照效应，系统就会停止混乱，我也不认为系统会因为你的出版物引入的自我参照成分而变得混乱。</p></blockquote><p>是的，需要明确的是，我同意这一点！ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:02:23 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:02:23 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>也许附近一个有趣的例子，我们可能不同意更多的是：至少有一些历史阅读，其中“经济理性”的概念以及与博弈论领域相关的各种理性概念在二战后出现。这些思想对经济、制度和学术/知识的发展产生了重要且明显的影响。这种观点说的是：今天对我们（大多数人）来说似乎很自然的一堆想法非常强烈地取决于相当狭窄的时间段和形成这些想法的极少数头脑。与“水中的鱼”和“你永远无法真正逃脱当地的意识形态背景”的感觉有关。<br><br> [不确定是否值得进入这个兔子洞。] </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:05:44 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:05:44 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><blockquote><p>无论人们是否了解供给和需求，供给都会等于需求。</p></blockquote><p> FWIW，很大程度上同意该段落，但也许值得指出：供给等于需求有时确实<i>会</i>失败（例如金融危机）。我们可以将这些失败解释为系统中的某种“非理性”，但我发现这通常在智力上相当懒惰。认识模型的局限性以及这些局限性产生的原因似乎很重要。事实上，复杂性经济学说，他们更善于理解在金融危机等事件中真正发生的事情，我认为应该为他们赢得很多认知点（重要的警告是，我需要阅读他们到底能够展示什么）关于将市场建模为非均衡系统，因此我在提出这一论点时提出了认识上的警告） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:04:52 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:04:52 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>是的，我确实认为我不同意这一点，这确实让我对复杂性理论感到害怕。就像，也许这是一个稻草人，但科学有一个吸引力，科学的作者开始不将自己视为真相的记者，而是将自己视为某种社会组织方式的倡导者。</p><p>历史充满了这样的情况，而且其中大部分都因此成为一个严重病态的领域，因为其中很大一部分人认为自己有意试图以一种积极影响当今社会运作的方式重塑历史。</p><p>就像，我不赞成禁止任何和所有关于出版物的次要影响的讨论，以及出版物本身如何可能扭曲它所谈论的主题，但总的来说，这条路上有很多头骨，并且许多领域因此而死亡。</p><p>我不知道当你谈论研究经济理论的出版和采用中的自我指涉时，这种情况发生到什么程度，但感觉已经很接近了。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:11:06 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:11:06 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><blockquote><p>是的，我确实认为我不同意这一点，而且这确实让我感到害怕。</p></blockquote><p>是的，总体上强烈同意整个信息。我发现自己很困惑，一方面，这里有一些基本论点，我觉得这些论点非常引人注目，让我想要认真对待理论化的社会嵌入性——尤其是在人工智能对齐的背景下——而且我也很难同意头骨和滑溜溜的认知斜坡。</p><p>我确实觉得有一种方法可以让你的所有推理都充满理智，但它确实感觉像是一个棘手的平衡，根据我的经验，它感觉有点像人具有或多或少的“认知抗体”，以便能够或多或少安全地在该地形中航行。</p><p> （作为旁注：我已经就此写过/发表了一些演讲，如果您要阅读/观看它们并想让我知道它是否让您更新或多或少担心我最终会跌跌撞撞地接近头骨，我很想听听。）</p><p> （另外，我认为<a href="https://www.jstor.org/stable/3810931">这篇论文</a>对这个问题进行了有趣的哲学讨论。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:13:28 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:13:28 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>所以，再回到顶层。我绝对同意这样的观点：“伙计，我们用各种社会、智能和经济系统构建的正式模型看起来确实不太可能在实际制造所需的相关细节和复杂程度上捕获这些模型。这里有很好的预测”。</p><p>然后我就很想知道如何做得更好。我想我目前的答案是这样的：“好吧，这不是科学的工作，科学的工作是为社会推理提供某种类型的相对狭窄的智力输入。对大型复杂系统进行聚合和预测的实际工作将是大部分发生在一群决策者大脑的系统1中，基于我们并不真正理解的归纳和演绎推理的非常复杂和混乱的混合”。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:15:51 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:15:51 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>我还有些认为，深度学习现在已经足够好了，我们只需向世界上的许多系统投入一些大型神经网络，就可以更好地理解它们。它们肯定有足够的参数，并且可以编码足够多的同时考虑因素，以产生非常复杂系统的相当好的预测模型。</p><p>通过人工学习系统来做到这一点，我们必须处理更少的递归问题，可以控制输入，并保持科学的更清晰的抽象（例如，可以通过重新运行深度学习训练来重现对复杂系统的预测） ，如果您通过向政策制定者提供信息来预测复杂系统，则无法做到这一点，而政策制定者通常不喜欢进行大型受控实验，或者被终止然后重新运行） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:19:39 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:19:39 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>好吧，我想反驳一下你所说的“当前做得更好的答案”。首先，我认为忽视科学具有不纯粹描述性的方面是不好的。*我也同意我们<i>真的</i>不应该一路走在其他方向，让科学基本上成为政治的延伸。其次，根据具体情况，将其留给“少数决策者的 S1”似乎显然令我不满意。</p><p> *在这里值得一提的是：我们可以在某种程度上区分这对于哪些域/系统来说是正确的。西蒙·赫伯特的<i>《人工科学》</i>在这方面对我影响很大。这里的人工指的是~设计的人工制品——对于我们的背景来说很重要：技术和机构。人工领域具有这种奇怪的描述性和规定性的双重性质。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:23:57 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:23:57 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>我同意我们可以利用法学硕士来促进科学进步（这也是 Davidad 的 OAA 大型计划的一部分），尽管这并不容易，而且我们有一些重要的方法可以把它搞砸。例如，在 Davidad 的案例中（据我所知），其想法是让法学硕士编写正式模型，<i>然后由人类专家逐行检查</i>。这是法学硕士目前可以帮助增强科学建模的方式，但检查阶段对于使其有用而不是有害至关重要。</p><p>然而，我不明白人工智能系统如何本质上面临更少的递归问题，至少默认情况下是这样。事实上，我非常担心<a href="https://arxiv.org/abs/2203.17232">表演预测因素</a>。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:22:31 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:22:31 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>是的，需要明确的是，我根本不想忽视它。我的意思是，对于任何试图阐明我们对某些领域的理解的特定论文，绝大多数论文应该大多忽略这些现象，除了一些特别递归的领域。然后，作为科学家和建立科学机构的人，我们应该考虑如何建立不必持续处理的询问过程，或者至少限制相关力量的腐败。</p><p>是的，拥有一些有助于我们使这些权衡的科学并不疯狂，但是我觉得我希望这些论文直接解决相关的注意事项，而不是以某种方式让每张纸张最终都受到对其自我参考的担忧影响。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:24:44 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:24:44 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><blockquote><p>但是，我不知道AI Sytsems是如何在递归问题上遇到的较少面临的，至少默认情况下不是。实际上，我非常担心Abotu的<a href="https://arxiv.org/abs/2203.17232">表演性预测指标</a>。</p></blockquote><p>好吧，在AI系统的情况下，您可以研究并对自我参照性的影响进行界限。您可以使用相同的数据重新训练旧系统。您可以客观地谈论它做出的预测。通过人类使用其系统i预测复杂系统，您在每个人中都具有太多的路径依赖性，以至于无法控制事物。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:30:34 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:30:34 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>是啊，有趣。我同意，科学论文的抽象水平（至少在绝大多数情况下）并不是应解决递归性问题的地方。这确实提出了（不合理的）问题，即应在哪里以及如何确切解决问题。我不太确定。我想机构或整个科学界更接近正确的抽象。我还认为这是科学哲学具有相关互补作用的地方。对于工程域而言，事情有些不同。特别是，我绝对希望有更多关于替代AI范式的讨论（以及不同此类范式的安全和治理功能）。鉴于当前的景观，我实际上认为这是目前更有希望的干预措施之一（最近开始发生一些巨大的积极迹象）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:30:37 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:30:37 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><blockquote><p>这确实提出了（重要的）问题，即在哪里以及如何确切解决问题。我不太确定。</p></blockquote><p>好吧，从某种意义上说，这就是Lesswrong的意义。 “理性的艺术”。</p><p>这被称为艺术，因为它确实不是科学。这是一个更广泛的类别，除了涵盖真实发现的科学方式外，还试图涵盖更实用的事情，例如良好的认知习惯和直觉，并确保您吃了正确的食物，等等。我也认为在这个主题上拥有一些良好的旧科学是一件好事，但是我发现Miri在透明游戏理论上的工作比大多数复杂科学在尝试研究递归建模效果之类的事物时更为相关。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:34:00 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:34:00 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>是的，epsitamic社区在这里很重要，而且寻求真理不仅仅是裸露的骨头的“科学方法”。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:33:19 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:33:19 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>好的，似乎现在是时候结束了。我很喜欢这个！ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:34:56 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:34:56 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>是啊，一样！ ：） 谢谢！ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:36:11 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:36:11 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>总结我们要为我留下的地方：</p><ul><li>我仍然有兴趣了解有关复杂性胜利的更多信息</li><li>我对复杂性理论的一些基本前提感到很漂亮，但是“科学领域”是否甚至是在这些前提之上工作的正确方法感到困惑</li><li>我通常对过于占据自己的存在或试图研究自己的效果的领域感到怀疑，不是因为它不是真实的，而是因为它确实很难，并且具有各种不良的认知吸引者</li></ul><p>我可能还会给您阅读或聆听您在尝试中发送的一些材料，并可能留下其他印象。</p></div></section><div></div><br/><br/> <a href="https://www.lesswrong.com/posts/7KjRqrwjmZRoiBDtn/complex-systems-research-as-a-field-and-its-relevance-to-ai#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/7kjrqrwjmzroibdtn/complex-systems-research-as-a as-a-a-a-a-a-aas-a-field-and-it-it-it-its-relevance-to-ai<guid ispermalink="false"> 7KJRQRWJMZROIBDTN</guid><dc:creator><![CDATA[Nora_Ammann]]></dc:creator><pubDate> Fri, 01 Dec 2023 22:10:25 GMT</pubDate> </item><item><title><![CDATA[Could there be "natural impact regularization" or "impact regularization by default"?]]></title><description><![CDATA[Published on December 1, 2023 10:01 PM GMT<br/><br/><p>具体来说，想象一下，您使用<a href="https://www.lesswrong.com/posts/6mysMAqvo9giHC4iX/what-s-general-purpose-search-and-why-might-we-expect-to-see">通用</a>搜索过程，该过程递归地调用自己来解决子目标，以解决一些更大的目标。</p><p>如果搜索过程对子目标的解决方案“更改事物太多”，那么它们可能不会有用。例如，对于Rubik的立方体，如果您想交换一些立方体，那么如果这些掉期会使其余的立方体争夺，您会很了解。</p><p>因此，在某种程度上，强大的功能必须依靠某种影响正规化。</p><p>我认为自然影响正规化与工程中的“优雅”概念有关。就像您有一些肿的工具来解决问题一样，即使不是严格地说一个问题，因为您可以负担得起资源，也可能会感到丑陋，因为它过剩，并在您的其他未限制的决定上放置了轻微的构造，等等。同时，一个简单的最小解决方案通常没有这个。</p><p>自然影响正规化不能<i>保证</i>安全，因为它仍然允许不干扰AI的功能的偏差，但是它可以减少我最近一直在考虑的一种危险来源，即我一直在想工具激励是寻找影响世界的强大方法，在这种方法中，“力量”意味着那种不可阻碍地迫使很多变化的原始力量，但实际上，工具的激励通常是寻找影响世界的“精确”方法，其中一种可以推动大量信息来实现狭窄的变化。 <span class="footnote-reference" role="doc-noteref" id="fnrefcsrxgqulp65"><sup><a href="#fncsrxgqulp65">[1]</a></sup></span></p><p>也许另一个词是“自然的内部对齐”，因为从某种意义上说，功能不可避免地选择内部对齐。在这里，我的意思是自然抽象的意义上，即多种认知算法会吸引的东西。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fncsrxgqulp65"> <span class="footnote-back-link"><sup><strong><a href="#fnrefcsrxgqulp65">^</a></strong></sup></span><div class="footnote-content"><p>一个并发症是任何一种代理只能具有如此之多的带宽，这有时会激励更直截了当的控制。我一直在想带宽可能会成为代理基金会的巨大领域，到目前为止，它还没有被忽视。 （也许是因为每个工作的每个工作都很糟糕地管理自己的带宽？😅）</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/cS7rhjuG9thmfTqdy/could-there-be-natural-impact-regularization-or-impact#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/cs7rhjug9thmftqdy/could-there-be-be-natural-impact-regularisization-ormignization-or-Impact<guid ispermalink="false"> CS7RHJUG9THMFTQDY</guid><dc:creator><![CDATA[tailcalled]]></dc:creator><pubDate> Fri, 01 Dec 2023 22:01:48 GMT</pubDate> </item><item><title><![CDATA[Benchmarking Bowtie2 Threading]]></title><description><![CDATA[Published on December 1, 2023 8:20 PM GMT<br/><br/><p><span>我一直在使用Bowtie2将读取与基因组相结合，其中许多设置之一是线程数。虽然有时人们建议使用与计算机具有核心一样多的线程，但是如果我在大型机器上运行的情况下，回报率会减少，或者有更多线程适得其反的点？我是否最好同时运行更多的样品，每个样本与每个线程更多，或者更少的较少的线程？</span></p><p>我决定使用<code>c6a.8xlarge</code> 32核AMD机器对AWS EC2进行一些测试。该测试包括从Crits-Cristoph等人运行一个7.2GB 48M读取样品（ <a href="https://www.ebi.ac.uk/ena/browser/view/SRR23998356">SRR23998356</a> ） <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7845645/">。 Al 2021</a>通过Bowtie2 2.5.2，带有<a href="https://benlangmead.github.io/aws-indexes/bowtie">Langmead索引区的</a>“人 / CHM13PLUSY”数据库。这些文件是从AWS S3流传输的，并在单独的过程中进行了解压缩。有关我的确切测试线束和配置，请参见<a href="https://github.com/naobservatory/jefftk-analysis/blob/main/2023-11-30--bowtie-n-threads.py">脚本</a>。</p><p>我发现（ <a href="https://docs.google.com/spreadsheets/d/1W1rBONmiVGcsRLeJajvpsgxffJdDXrOzaDAMLxRFwE0/edit#gid=0">表</a>）是最初分配其他线程很有帮助，但是在〜8之后，它的平稳性，在〜10个线程之后，又有10个线程略微开始受到伤害：</p><p> <a href="https://www.jefftk.com/bowtie2-multithread-timing-big.png"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TaSZvZDMMhNbtFtCa/io4wbb47zkpbeyt6hmxw" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TaSZvZDMMhNbtFtCa/io4wbb47zkpbeyt6hmxw 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TaSZvZDMMhNbtFtCa/ceiesrginxufhmtdlwqp 1100w"></a></p><div></div><p></p><p>比较我所看到的最好的东西，您的任务在各个线程之间完全可以并行：</p><p> <a href="https://www.jefftk.com/bowtie2-multithread-theoretical-big.png"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TaSZvZDMMhNbtFtCa/kvqdvm0zgchcxx0q3yb5" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TaSZvZDMMhNbtFtCa/kvqdvm0zgchcxx0q3yb5 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TaSZvZDMMhNbtFtCa/qw1glbql7fsklpcnkggm 1100w"></a></p><div></div><p></p><p>这表明最初Bowtie2非常有效地利用了其他线程，但是正如您从高原上期望的那样，在〜8之后，收益下降。</p><p>查看此问题的另一种方法是绘制处理整个数据集需要多少线程的线程：</p><p> <a href="https://www.jefftk.com/bowtie2-multithread-thread-seconds-big.png"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TaSZvZDMMhNbtFtCa/hifpeye7botp8y0bh2xl" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TaSZvZDMMhNbtFtCa/hifpeye7botp8y0bh2xl 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TaSZvZDMMhNbtFtCa/acdt48jsf3qt4nmiwuhd 1100w"></a></p><div></div><p></p><p>在这个图上，完美的并行性将是一条水平线，它通过8个线程非常接近。然而，在那之后，它开始更加陡峭地上升，显示出效率较低的线程。</p><p>您可能想知道这是多少是Bowtie2，我的测试环境是多少。例如，也许到我们到达八个线程时，我们可以从S3下载并解压缩数据的速度限制？ Bowtie2无法比数据到达更快！我运行了此版本的“无效”版本，在那里我用<a href="https://www.jefftk.com/p/losing-metaphors-zip-and-paste"><code>paste</code></a> （ <a href="https://github.com/naobservatory/jefftk-analysis/blob/main/2023-11-30--null-n-threads.py">测试脚本</a>）代替了<code>bowtie2</code> ，发现这始终为44-45。由于这一切都是流媒体，而且最快的运行花了189年代（4倍），所以我认为这没有明显的效果。</p><p>总体而言，即使在一台非常大的机器上，您也不应该设置Bowtie2的<code>--threads</code>直到10以上的线程，除非您拥有空闲的内核8，否则可能是一个更好的价值。</p><br/><br/><a href="https://www.lesswrong.com/posts/TaSZvZDMMhNbtFtCa/benchmarking-bowtie2-threading#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/taszvzdmmhnbtftca/benchmarking-bowtie2-threading<guid ispermalink="false"> taszvzdmmhnbtftca</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Fri, 01 Dec 2023 20:20:06 GMT</pubDate> </item><item><title><![CDATA[Using Prediction Platforms to Select Quantified Self Experiments]]></title><description><![CDATA[Published on December 1, 2023 8:07 PM GMT<br/><br/><blockquote><p>有太多可能的量化自我实验需要进行。业余爱好者预测平台<span class="footnote-reference" role="doc-noteref" id="fnref4fo2b58sim8"><sup><a href="#fn4fo2b58sim8">[1]</a></sup></span>是否能让优先级更容易确定？我通过设置多个市场来测试这一点，以便进行两个实验（最好的一个和随机的一个），主要是为了观察促智药对冥想吸收的影响。</p></blockquote><p></p><p> <a href="https://dynomight.net/prediction-market-causation/#7">dynomight 2022</a>有一个很酷的提案：</p><blockquote><p>幸运的是，有一个很好的（并且众所周知的）替代方案，那就是有时随机地做出决定。你告诉人们：“我会掷一个 20 面的骰子。如果结果是 1-19，每个人都会拿回自己的钱，我就做我想做的事。如果出现 20，赌注就会激活，我会通过掷硬币来决定要做什么。”</p><p>这样做的好处是，当 1-19 出现时，您可以做任何您想做的事情，包括使用市场价格做出决定。但有时您必须随机做出决定，因为如果投注从未激活，就没有人会浪费时间在您的市场上投注。</p><p>这很优雅。哦，顺便说一句，你是 NSF、DARPA、NIH 还是亿万富翁，愿意花很多钱，吹嘘自己如何比其他那些不知道高点的蹩脚亿万富翁更能提高人类知识水平？如果它打到他们的脸上，投资回报率如何？那么这个怎么样：</p><ol><li>收集一百个 RCT 的提案，每个 RCT 都非常昂贵，但也非常棒。 （例如，您可以调查<code>SALT → MORTALITY</code>或<code>ALCOHOL → MORTALITY</code>或<code>UBI → HUMAN FLOURISHING</code> 。）</li><li>为高流动性市场提供资金，以预测每项随机对照试验的结果，前提是它们获得资助。<ul><li>如果您对监狱有疑问，您可能需要在执行此操作之前与<a href="https://en.wikipedia.org/wiki/Commodity_Futures_Trading_Commission">CFTC</a>交谈。</li></ul></li><li>随机挑选 5% 的拟议项目，按照书面规定为其提供资金，并向正确预测将会发生的情况的投资者支付费用。</li><li>采取其余 95% 的拟议项目，退还投资者的资金，并利用甜蜜的预测知识挑选另外 10% 的随机对照试验来资助惊人的科学进步和最大程度的地位提升。</li></ol></blockquote><p> <i>—</i> <a href="https://dynomight.net/prediction-market-causation/"><i>dynomight</i></a> <i>，</i> <a href="https://dynomight.net/prediction-market-causation/"><i>“预测市场并不意味着因果关系”</i></a> <i>，2022</i></p><p>好吧，我既不是亿万富翁，也不是 NSF 或 DARPA，但我<strong>已经</strong>对自己进行了<a>两项</a><a>糟糕的</a>自盲随机对照试验，而且我当然不害怕<a href="https://en.wikipedia.org/wiki/Commodity_Futures_Trading_Commission">CFTC</a> 。事实上，我对<a>可以</a>运行 RCT 的东西并不缺乏想法，但时间很紧（我尝试在每个 RCT 中收集 m=50 个样本，这（缓冲天数关闭）通常超过 2数月的数据收集）。</p><p>所以我会做<a href="https://nitter.net/saulmunn/">@saulmunn</a><a href="https://nitter.net/saulmunn/status/1671923161695240192">向我指出的</a>一种可能性：我将<a href="https://www.lesswrong.com/posts/qZXy8kGkNFyqCfHEJ/you-can-do-futarchy-yourself">自己做 futarchy（on）</a> ，根据一些预先指定的自我盲目的结果建立一组流形市场市场随机对照试验，等到它们的价格达到平衡，然后运行其中两个随机对照试验（根据我的标准，“最好”的一个，以及随机的一个），并使用结果作为解决方案，同时解决其他不明确的问题。</p><h3>时间线</h3><p>如果市场获得足够的流动性，我将在 2024 年初开始第一个实验，并在 2024 年某个时候开始第二个实验（取决于具体的实验），希望在 2025 年之前完成这两个实验。</p><h2>市场</h2><p>有些实验可以是自盲的，特别是那些涉及物质的实验，而另一些实验则不能，因为它们需要我从事一项活动或接受一些感官输入，所以我区分这两者，并稍微优先考虑可以盲法的实验。</p><p>在所有实验中，我将使用<a>此处</a>详细介绍的统计方法，并<a>在此处</a>编写代码，除非有人指出我的统计方法是错误的。</p><p>我将根据预测市场标题中指定的变量对市场进行评分，但我当然会在此期间收集<a>大量其他数据</a>，这些数据也将进行分析。</p><h3>自盲实验</h3><p>一般来说，<i>冥想吸收</i>是指早上≥30分钟的冥想过程中的专注/平静（佛教术语<a href="https://en.wikipedia.org/wiki/Samatha-vipassana">samatha</a> ），醒来并服用该物质后约45分钟（如果该物质立即开始发挥作用，则时间较短）。在那次冥想课程中，我将进行至少 15 分钟的<a href="https://en.wikipedia.org/wiki/Anapanasati">观息念</a>，但可能会以其他练习开始（或结束）。</p><p>过去的冥想数据可以<a>在这里</a>找到。</p><ol><li> <a href="https://manifold.markets/NiplavYushtun/by-how-much-does-caffeine-ltheanine"><strong>L-茶氨酸 + 咖啡因</strong>与<strong>糖</strong>→<i>冥想吸收</i></a>：早上醒来后 50 个样本，25 个 500mg L-茶氨酸和 200mg 咖啡因干预以及 25 个安慰剂（糖丸）。预期试验持续时间：约 2.5 个月（每天一个样本，但可能会暂停）。</li><li><a href="https://manifold.markets/NiplavYushtun/by-how-much-does-nicotine-improve-m"><strong>尼古丁</strong>与<strong>普通口香糖</strong>→<i>冥想吸收</i></a>：40 个样本，醒来后有<a href="https://en.wikipedia.org/wiki/Blocking_(statistics)">阻塞</a>，20 个用 2mg 尼古丁干预，20 个安慰剂（外观相似的方形口香糖）。预计试验持续时间：约 4.5 个月（每周两次样品，以避免对尼古丁上瘾）。</li><li><a href="https://manifold.markets/NiplavYushtun/by-how-much-does-modafinil-improve"><strong>莫达非尼</strong>vs.<strong>糖</strong>→<i>冥想吸收</i></a>：40 个样本，同样在醒来后立即进行<a href="https://en.wikipedia.org/wiki/Blocking_(statistics)">阻断</a>，20 个样本使用 100 毫克莫达非尼进行干预，20 个安慰剂（糖丸）。预期试验持续时间：大约 4.5 个月，每周两次样品，以防止对莫达非尼产生依赖。</li><li><a href="https://manifold.markets/NiplavYushtun/by-how-much-does-vitamin-d-improve"><strong>维生素 D</strong>与<strong>糖</strong>→<i>冥想吸收</i></a>：50 个样本，起床后采集，25 个干预样本（25μg 维生素 D₃）和 25 个安慰剂（糖丸）。预期试验持续时间：约 2.5 个月（约每天进行，可能会暂停）。</li><li><a href="https://manifold.markets/NiplavYushtun/by-how-much-does-vitamin-b12-improv"><strong>维生素 B12</strong>与<strong>糖</strong>→<i>冥想吸收</i></a>：50 个样本，起床后采集，25 个干预样本（500μg 维生素 B12 + 200μg<a href="https://en.wikipedia.org/wiki/Folate">叶酸</a>）和 25 个安慰剂（糖丸）。预期试用期：2.5 个月（包括短暂中断）。</li><li> <a href="https://manifold.markets/NiplavYushtun/by-how-much-does-microdosed-lsd-imp"><strong>LSD 微剂量</strong>与<strong>水</strong>→<i>冥想吸收</i></a>：早上 50 个样本，25 个干预（10μg LSD）和 25 个安慰剂（蒸馏水）。预计试验持续时间约为 4 个月（每周 4 个样本，留出一些时间作为缓冲）。</li><li> <a href="https://manifold.markets/NiplavYushtun/by-how-much-does-cbd-improve-medita"><strong>CBD 油</strong>与<strong>类似口味的油</strong>→<i>冥想吸收</i></a>：早上 50 个样本，25 个干预（240 毫克 CBD 油，口服）和 25 个安慰剂（我能找到的与 CBD 油味道最接近的任何油）。预期试验持续时间：约 2.5 个月（约每天进行，可能会暂停）。</li><li> <a href="https://manifold.markets/NiplavYushtun/by-how-much-does-lphenylalanine-imp"><strong>L-苯丙氨酸</strong>与<strong>糖</strong>→<i>冥想吸收</i></a>：50 个样本，起床后直接采集，25 个干预样本（750mg L-苯丙氨酸）和 25 个安慰剂（糖丸）。试验持续时间：2.5 个月（每天一个样品）。</li><li><a href="https://manifold.markets/NiplavYushtun/by-how-much-does-bupropion-improve"><strong>安非他酮</strong>与<strong>糖</strong>→<i>幸福</i></a>：醒来后采集 50 个样本，25 个干预样本（150 毫克安非<a href="https://en.wikipedia.org/wiki/Bupropion">他酮</a>）和 25 个安慰剂（糖丸）。持续时间通常为 2.5 个月。</li><li> <a href="https://manifold.markets/NiplavYushtun/by-how-much-does-thc-oil-improve-me"><strong>THC 油</strong>与<strong>类似味道的油</strong>→<i>冥想吸收</i></a>：早上 50 个样本，25 个干预（2.5 毫克 THC 油，口服）和 25 个安慰剂（我能找到的与 THC 油味道最接近的任何油）。预期试验持续时间：约 2.5 个月（约每天进行，可能会暂停）。</li></ol><h3>非盲实验</h3><p>有些实验不能盲法，但仍然可以随机进行。我将重点关注可以盲目的实验，但不想排除更广泛的干预空间。</p><ol><li><a href="https://manifold.markets/NiplavYushtun/by-how-much-does-intermittent-fasti"><strong>间歇性禁食</strong>与<strong>正常饮食</strong>→<i>幸福</i></a>：50 个样本，25 个干预（仅在 18:00 到午夜之间进食），25 个不干预（正常饮食，通常是每天两餐，间隔约 10 小时），随机选择通过<code>echo -e &quot;fast\ndon&#39;t fast&quot; | shuf | tail -1</code> 。预计试验持续时间：~2 个月。</li><li><a href="https://manifold.markets/NiplavYushtun/by-how-much-does-the-pomodoro-metho"><strong>番茄工作法</strong>与<strong>什么都不做</strong>→<i>生产力</i></a>：50 个样本，25 次干预（我尝试尽可能地遵循<a href="https://en.wikipedia.org/wiki/Pomodoro_technique">番茄工作法</a>，可能通过安装某种<a href="https://www.lesswrong.com/posts/wJutA2czyFg6HbYoW/what-are-trigger-action-plans-taps">TAP</a> ），25 次不干预（我只是尝试像平常一样工作） ），通过<code>echo -e &quot;pomodoro\nno pomodoro&quot; | shuf | tail -1</code>随机选择<code>echo -e &quot;pomodoro\nno pomodoro&quot; | shuf | tail -1</code> 。预计试用期：2个月。</li><li><a href="https://manifold.markets/NiplavYushtun/by-how-much-does-very-bright-light"><strong>亮光</strong>与<strong>普通光</strong>→<i>幸福</i></a>：50 个样本，25 个干预（早上打开约 30k 流明的<a href="https://arbital.com/p/lumenators/">照明器</a>），25 个非干预（打开约 1k 流明的普通台灯），通过<code>echo -e &quot;lamp\nno lamp&quot; | shuf | tail -1</code>选择<code>echo -e &quot;lamp\nno lamp&quot; | shuf | tail -1</code> 。预计试用时间：4个月，因为我经常不会整天呆在家里。</li><li><a href="https://manifold.markets/NiplavYushtun/by-how-much-does-2-hours-of-meditat"><strong>冥想</strong>vs.<strong>无冥想</strong>→<i>睡眠持续时间</i></a>：50 个样本，25 次干预（连续 2 天≥2 小时/天冥想），25 次非干预（无冥想），通过<code>echo -e &quot;meditation\nno meditation&quot; | shuf | tail -1</code>选择<code>echo -e &quot;meditation\nno meditation&quot; | shuf | tail -1</code> 。预计试用时间：5 个月，因为我可能并不总能找到 2 天的间隔，让我确信我每天可以冥想 2 小时。</li></ol><p>进一步的想法</p><p>我对可以进行的可能实验还有更多想法，当我获得更多法力时，我会将它们提出来。</p><p>致盲：</p><ol><li><strong>索马鲁肽</strong>vs.<strong>糖</strong>→<i>生产力</i>（追踪责任心）</li></ol><p>不致盲：</p><ol><li><strong>双耳节拍</strong>与<strong>沉默</strong>→<i>冥想吸收</i></li><li><strong>棕色噪音</strong>与<strong>沉默</strong>→<i>冥想吸收</i></li><li><strong>棕色噪音</strong>与<strong>音乐</strong>→<i>生产力</i></li><li><strong>沉默</strong>与<strong>音乐</strong>→<i>生产力</i></li><li><strong>自上次自慰以来的时间</strong>→<i>生产力</i></li><li><strong>开始站立工作</strong>与<strong>开始坐着工作</strong>→<i>生产力</i></li></ol><h2>请求</h2><p>这个小练习可能需要<strong>您的</strong>参与！亲爱的读者，我向您提出三点请求：</p><ol><li><strong>请大家预测一下市场！</strong>如果人们对市场进行预测，我<i>既</i>可以获得更多有关不同实验价值的信息，也可以获得法力值。如果知道业余爱好者预测市场是否<i>可以</i>用于选择实验，那就太酷了，最糟糕的结果将是“好吧，我们真的无法判断，因为市场上的流动性太小”。</li><li><strong>也许可以给我发送法力，让我创造更多市场或补贴现有市场。</strong>我很乐意为 Manifold 的市场提供大量补贴，但目前没有足够的法力。 <a href="https://manifold.markets/anonymous">Clippy</a>和<a href="https://manifold.markets/Tetraspace">Tetraspace</a>都已经给我发送了法力，我非常感激。有了更多的法力，我还可以开拓更多的市场，从而探索更大的可能实验空间。然而，也许另一个市场的价值没有那么高，所以这个市场的紧迫性要低得多。</li><li><strong>给我一些想法来进行更多的实验。</strong>如果你有一个你热衷的想法，并且你一直想测试它，但你有点懒惰实际去做，我也许可以跳进去。对我来说最有趣的是以下实验：<ol><li><i>负担得起</i>：昂贵的物质、高端设备等太令人望而却步（除非你想买这个东西给我来做实验）。</li><li><i>安全</i>：抱歉，我不会服用甲基苯丙胺，尽管它可能会让我更有效率。</li><li><i>可测量</i>：干预措施应该影响的变量应该至少可以<a href="http://niplav.site/data.html">通过我目前收集数据的</a><i>一种</i>方式来测量，或者至少可以轻松测量。特别是认知表现很难掌握：<a href="https://en.wikipedia.org/wiki/Iq_test">智商测试</a>不能经常重复，但也许有一个游戏可以可靠地衡量认知表现？</li><li><i>快速</i>：我无法对一项干预措施进行 50 个样本，其中一个样本需要 2 周才能生效。每天是最好的，但对于<i>真正好的</i>选择，我可能愿意每周 2 个样品。</li></ol></li></ol><p>除此之外，我也欢迎对这项事业的任何细节级别的所有批评。</p><h2>进一步的想法</h2><p>如果我可以创造更多的市场，我也许可以根据白天测量的不同变量来建立市场。这样，我就可以选择在多个维度上主导其他干预措施的干预措施。</p><p>如果有支持它们的预测平台，组合预测市场或<a href="https://www.lesswrong.com/posts/ufW5LvcwDuL6qjdBT/latent-variables-for-prediction-markets-motivation-technical">潜变量预测市场</a>可能会非常酷，但我们还没有生活在那个世界中。</p><h2>结果</h2><p>待完成。</p><h2>致谢</h2><p>非常感谢<a href="https://manifold.markets/anonymous">Clippy</a> ( <a href="https://twitter.com/12leavesleft">twitter</a> ) 提供的 500 Mana 和<a href="https://manifold.markets/Tetraspace">Tetraspace</a> ( <a href="https://twitter.com/TetraspaceWest">twitter</a> ) 的 1000 Mana — 非常感谢您对科学的资助。</p><h2>附录 A：我选择的实验的解释</h2><p>随着时间的推移，我将解释为什么这些特定的实验让我感兴趣。不过还没有。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn4fo2b58sim8"> <span class="footnote-back-link"><sup><strong><a href="#fnref4fo2b58sim8">^</a></strong></sup></span><div class="footnote-content"><p>我觉得把人们在功能上给出概率但不投入真金白银的任何平台称为“预测市场”是很奇怪的。 <a href="https://www.metaculus.com/">Metaculus</a>和<a href="https://manifold.markets/">Manifold Markets</a>都不是预测市场，但<a href="https://www.predictit.org/">PredictIt</a>和<a href="https://kalshi.com/">Kalshi</a>是。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/2qQyKpXzbPov2Fmdr/using-prediction-platforms-to-select-quantified-self#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/2qQyKpXzbPov2Fmdr/using-prediction-platforms-to-select-quantified-self<guid ispermalink="false"> 2qQyKpXzbPov2Fmdr</guid><dc:creator><![CDATA[niplav]]></dc:creator><pubDate> Fri, 01 Dec 2023 20:07:38 GMT</pubDate> </item><item><title><![CDATA[Specification Gaming: How AI Can Turn Your Wishes Against You [RA Video]]]></title><description><![CDATA[Published on December 1, 2023 7:30 PM GMT<br/><br/><figure class="media"><div data-oembed-url="https://youtu.be/jQOBaGka7O0"><div><iframe src="https://www.youtube.com/embed/jQOBaGka7O0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div></figure><p><i>在这个新视频中，我们探讨了机器学习系统中的规范游戏。它应该作为</i><a href="https://www.lesswrong.com/posts/6At6iMTu3dsKSTXLL/the-hidden-complexity-of-wishes-the-animation"><i>《愿望的隐藏的复杂性》的</i></a>后续作品来观看<i>，但它也可以作为独立的作品来欣赏和理解。这是我们正在进行的有关外部对齐相关主题的系列工作的一部分，这反过来也是我们向广大受众解释人工智能安全的努力的一部分。</i><br><br><i>我在下面包含了完整的脚本。</i></p><hr><p>在上一个视频中我们介绍了“结果泵”的思想实验。一个可以让你改变事件发生概率的装置。在那个思想实验中，你年迈的母亲被困在一座着火的大楼里。你希望你的母亲离建筑物尽可能远，结果泵使建筑物爆炸，将你母亲的身体抛离建筑物。</p><p>这显然不是你想要的，无论你对这个愿望做出多少修改，都很难让它真正安全，除非你有办法指定你的全部价值观。</p><p>在本视频中，我们探讨了类似的故障如何影响当今的机器学习代理。您可以将此类代理视为功能较弱的结果泵或小精灵。他们有目标，并在他们的环境中采取行动来进一步实现他们的目标。这些模型的能力越强，确保它们的安全就越困难。我们指定他们目标的方式总是在某种程度上<i>存在漏洞</i>。也就是说，我们通常无法完美地描述我们希望他们做什么，因此我们在某些情况下使用偏离预期目标的代理。同样，“把你母亲带出大楼”也只是真正拯救你母亲的不完美代表。日常生活中类似的例子还有很多。考试的目的是评估学生对学科的理解，但在实践中，学生可以作弊，可以临时抱佛脚，他们可以只学习考试中的内容，而不是其他。通过考试是实际知识的泄漏代表。如果我们付费给机器人农场来提高该视频的观看次数，这会产生大量观看次数，但这毫无意义。观看次数是我们向广大受众教授重要科目的真正目标的一个漏洞指标。</p><p>在机器学习中，根据具体情况，有许多名称用于描述这种普遍现象发生的情况，例如：规范游戏、奖励错误指定、奖励黑客、外部错位和古德哈特定律。这些术语描述了一种行为满足目标的字面规范，但没有导致实际预期结果的情况。</p><p> DeepMind 在 2020 年的一篇文章中描述了使用强化学习训练的机器学习系统中的一些失败。在强化学习中，您指定的不是目标，而是奖励函数，该函数在代理执行操作后自动向代理提供反馈。</p><p>这里有一个例子：研究人员试图训练一个代理来堆叠乐高积木。他们想要的结果是代理将一个红色块放在一个蓝色块上。您将如何设计奖励函数以使代理学习任务？研究人员选择了一个奖励函数，当智能体没有接触红色块时，该函数会观察红色块底面的高度。如果红色块的底面最终与一个块的高度一样高，那么这意味着红色块位于蓝色块的顶部，对吗？嗯，是的，但并非总是如此。智能体没有学习堆叠方块，而是简单地学习将红色方块翻转，这样底面就会发现自己处于一个方块的高度。你看到研究人员指定的奖励相对于最初的目标是如何存在漏洞的吗？它没有考虑到特工解决问题的意外方式，就像“让你的母亲离大楼尽可能远”会导致意外的结果，导致你的母亲最终死亡。因此，乐高堆叠代理示例可以被视为结果泵思想实验的一个版本，但解决起来更简单，风险也更低</p><p>针对规范博弈问题提出的解决方案是简单地使用人类反馈来提供奖励。如果人类处于循环中并且可以在代理出错时告诉代理，那么它就不会出错，对吗？</p><p>考虑另一种情况：一个使用人类反馈训练来抓住球的智能体最终做到了这一点。看起来不错，对吧？但如果你仔细观察，你会发现手实际上并没有抓住球，它在球的前面，在球和相机之间。智能体了解到，通过将手放在那里，评估它的人类会奖励它，就好像它抓住了球一样。它学会了愚弄人类。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LCD4sWsRH5BxkGpbY/wgyjxllsb4fy2fzcvesw"></p><p>再说一遍，人类反馈并不总是有效，因为它只是真实目标的代表。我们不希望智能体“让人类评估者认为它正在抓住球”，我们希望智能体真正抓住球！如果欺骗评估者比实际执行任务更容易学习，那么代理就会欺骗评估者。人类反馈也只是我们真实目标的一个有漏洞的代理。</p><p>您可以在 Robert Miles（顺便说一下，旁白就是我）的视频“规范游戏的 9 个例子”中看到更多这种现象的例子。我刚刚为该视频挑选了九个特别有趣的例子，但这种效果一直在发生。让机器学习代理追求我们的预期目标可能非常棘手。</p><p>随着机器学习的进步，风险也会变得更高。如果强化学习模型学会翻转方块而不是在模拟中堆叠它，这并不危险。但是影响现实世界的模型呢？例如当它们用于医疗环境、推荐系统或在股票市场中使用时？或者，如果他们至少和人类一样有能力、普遍聪明，可以自由地在互联网或现实世界中行动，又会怎样呢？如果能力足够高，并且如果这些系统的核心目标稍有错误，那么它们的行为可能会被证明是危险的，甚至是致命的。对于个人或整个人类文明。再次考虑结果泵。在风险很高的情况下，目标的错误指定可能会产生悲剧性的结果。</p><p>在以下有关该主题的视频中，我们将探索更多推测性场景，在这些场景中，任务指定错误可能会对整个人类文明造成危险。我们将研究许多人工智能系统如果针对错误指定的目标可能共同导致文明崩溃的一些方式，或者单个系统如何可能导致人类文明的终结。所以，敬请期待！</p><p>同时，如果您想提高 AI 安全方面的技能，我们强烈推荐 BlueDot Impact 提供的 [免费] AI 安全基础课程，网址为 aisafetyfundamentals.com</p><p>您可以找到三门课程：AI Alignment、AI Governance 和 AI Alignment 201</p><p>即使没有人工智能技术背景，您也可以学习人工智能调整和人工智能治理课程。 AI Alignment 201 课程假设您首先完成了 AI Alignment 课程，以及有关深度学习和强化学习的大学水平课程或同等课程。</p><p>这些课程包含精心挑选的课程材料，您可以在网上找到。它们可供所有人使用，因此您只需阅读它们即可，而无需正式注册课程。</p><p>如果您想注册，BlueDot Impact 会<s>滚动</s>接受申请（不正确，已在视频中更正）。这些课程是远程且免费的。它们包括每周花几个小时的时间来阅读阅读材料，再加上每周与辅导员和一群人一起通话，从相同的材料中学习。在每门课程结束时，您可以完成一个个人项目，这可能有助于您开启人工智能安全领域的职业生涯。</p><p> BlueDot Impact 收到了更多他们可以接受的申请，因此，如果您仍然想与其他人一起学习这些课程，您可以前往 AI Alignment Slack 中的#study-buddy 频道，您可以通过访问 aisafety 加入该频道。社区并单击第一个条目。艾安全社区。</p><p>您还可以加入 Rational Animations 的 Discord 服务器，看看是否有人愿意成为您的学习伙伴。</p><br/><br/> <a href="https://www.lesswrong.com/posts/LCD4sWsRH5BxkGpbY/specification-gaming-how-ai-can-turn-your-wishes-against-you#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/LCD4sWsRH5BxkGpbY/specification-gaming-how-ai-can-turn-your-wishes-against-you<guid ispermalink="false"> LCD4sWsRH5BxkGpbY</guid><dc:creator><![CDATA[Writer]]></dc:creator><pubDate> Fri, 01 Dec 2023 19:30:59 GMT</pubDate> </item><item><title><![CDATA[Queuing Theory: Benefits of operating at 70% capacity]]></title><description><![CDATA[Published on December 1, 2023 6:48 PM GMT<br/><br/><p>与<a href="https://www.lesswrong.com/s/xEkBK3SRrp6DhGf7c/p/yLLkWMDbC9ZNKbjDG">Slack</a>相关。与<a href="https://en.wikipedia.org/wiki/Lean_manufacturing">精益制造</a>（又名 JIT 制造）相关。</p><p> TL;DR 一个成功的基于任务的系统应该偶尔闲置，就像<a href="https://www.sciencealert.com/many-worker-ants-are-actually-lazy-slackers-but-there-s-a-good-reason-for-that">40% 的工蚁一样。</a></p><p>在许多系统中，快速完成任务对于创造价值至关重要。对于软件团队来说，交付功能可以让您深入了解用户需求，从而提高未来的功能质量。对于供应链来说，更快的交付可以释放资金用于再投资。然而，利用率和服务时间之间的关系是指数关系，如下图所示。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YEHHHttT7EqZqPZb5/wu6kbqtaccm7ehfkjqyt" alt="排队-6.png"><figcaption>随机到达意味着有时最好有空闲容量，以便系统在任务大量到达时快速做好准备。</figcaption></figure><p>我们可以从排队理论中得出的一个启发是，效率和容量之间的最佳平衡通常发生在系统闲置率约为 30-40% 时。对于单个生产者系统，X% 空闲是指该生产者有 X% 的时间处于空闲状态。对于多生产者系统，X% 的空闲意味着平均有 X% 的生产者处于空闲状态。这种启发式方法最适用于涉及大量离散、形状奇怪的任务的系统。</p><p>他链接的帖子更详细地解释了这个理论，并举例说明了队列在现实世界中出现的位置。</p><br/><br/> <a href="https://www.lesswrong.com/posts/YEHHHttT7EqZqPZb5/queuing-theory-benefits-of-operating-at-70-capacity#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/YEHHHttT7EqZqPZb5/queuing-theory-benefits-of-operating-at-70-capacity<guid ispermalink="false">叶赫赫赫ttT7EqZqPZb5</guid><dc:creator><![CDATA[ampdot]]></dc:creator><pubDate> Fri, 01 Dec 2023 19:02:40 GMT</pubDate> </item><item><title><![CDATA[Researchers and writers can apply for proxy access to the GPT-3.5 base model (code-davinci-002)]]></title><description><![CDATA[Published on December 1, 2023 6:48 PM GMT<br/><br/><p>人工智能安全研究人员和创意作家可以通过也称为<a href="https://cyborgism.wiki/hypha/code-davinci-002">Code-Davinci-002</a>申请对GPT-3.5基本模型的代理访问。</p><p>公开可用的基本模型包括“ Davinci-002”（文本davinci-xxx模型不是基本模型）和Cohere的“ Xlarge”模型。</p><p>我建议使用Janus的织机与语言模型进行互动。<a href="https://www.lesswrong.com/users/parafactual">偏见</a>的一种这样的实现是<a href="https://github.com/cosmicoptima/loom">织布机</a>。简而言之，织机是一种工具，用于生成提示的多个延续并在树上组织它们。织机ba吟着，您将其延续。它允许对具有多个答案的问题进行创造性的探索。</p><br/><br/> <a href="https://www.lesswrong.com/posts/gm7pZK4i4a7q2DH4B/researchers-and-writers-can-apply-for-proxy-access-to-the#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/gm7pzk4i4a7q2dh4b/researchers-and-writers-and-writers-can-apply-for-proxy-proxy-access-cossess-cosess-to-to-the-the<guid ispermalink="false"> GM7PZK4I4A7Q2DH4B</guid><dc:creator><![CDATA[ampdot]]></dc:creator><pubDate> Fri, 01 Dec 2023 21:22:36 GMT</pubDate> </item><item><title><![CDATA[Kolmogorov Complexity Lays Bare the Soul]]></title><description><![CDATA[Published on December 1, 2023 6:29 PM GMT<br/><br/><p><a href="https://en.wikipedia.org/wiki/Kolmogorov_complexity">柯尔莫哥洛夫复杂度</a>是对特定信息的算法复杂性的度量，它是通过识别该信息的最短可能表示来找到的。例如，如果我有一个字符串<strong>AAAAA</strong> ，我可以创建一个压缩表示<strong>5A</strong> 。那么<strong>AAAAA</strong>的柯尔莫哥洛夫复杂度最多为 2，因为我可以使用较短的版本<strong>5A</strong>仅用两个字符来表示相同的信息。我们可以说<strong>5A</strong>是柯尔莫哥洛夫<i>串</i>，表明<strong>AAAAA</strong>的柯尔莫哥洛夫复杂度为2。</p><p>柯尔莫哥洛夫复杂性还可以让我们了解不同信息的相对复杂性。 <strong>AAABB</strong>只能压缩到<strong>3A2B</strong> ，柯尔莫哥洛夫复杂度为 4，使其复杂度是<strong>AAAAA</strong>的两倍。</p><p>像下面这样的分形看起来很复杂，事实上，存储分形图像会占用大量空间。然而，分形是通过遵循简单的规则构建的，并且执行这些指令的计算机程序可能比存储图像本身小许多数量级。这意味着分形的柯尔莫哥洛夫复杂度实际上可能相当低，尽管看起来如此。 </p><figure class="image image_resized" style="width:56.34%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XoMdqAoo5LqKewKDC/wrbqs7xvh9sc0otffkfv"></figure><p>我突然想问——我有柯尔莫哥洛夫复杂度吗？我的身体和我的思想都只包含有限的信息，因此只能用有限的文本来详尽地描述两者。对我存在的每一根纤维进行蛮力的描述并没有让我觉得特别有趣。如果我能够发现我的柯尔莫哥洛夫弦，那<i>确实让</i>我觉得它有一些有趣的性质。</p><p>这样的一根绳子就代表了我最纯粹、最提炼的本质。它将包含我存在的每一个细节——因为即使是一个缺失的比特，根据定义，它也会失去我的柯尔莫哥洛夫弦的资格。它也是完全<i>独特的</i>，是尽可能短的字符串。它是如此精简，没有留下任何多余的细节——否则，它就不是最短的字符串了。</p><p>所以在这里，我们有一个完整的代表我的整个存在，其中没有任何一丁点可以添加或删除；一个完全<i>完美的</i>代表。</p><p>人们可以检查这个字符串并询问有关我生活的任何问题，并获得详细的正确答案。其中所包含的细节将是如此精致，即使我被彻底摧毁，也足以建造出一个与我一模一样的复制品。</p><p>柯尔莫哥洛夫弦是一种空灵的东西，可能太滑、难以形容，无法在现实中真正捕捉到。但是，<i>原则上</i>，它确实存在，并且可以通过足够的努力找到。我的一切——我的记忆、我的伤疤、我的技能——都可以浓缩成最纯粹的信息本质。尽管捕捉到了关于我的一切，我的柯尔莫哥洛夫弦仍然是静态的、无情的纯粹信息。只有当这些信息位于一个移动的、动态的身体内时，它才会感觉和思考。</p><p><i>如果不是这个，灵魂是什么？</i></p><p>让我惊讶的是，这与传统的灵魂概念有多么相似。这里我们有一个理论对象，它可以以抽象和非物质的方式完美且独特地捕捉一个人的身份。它完全定义了我们，但永远无法真正衡量。</p><p>在我看来，它与几乎任何哲学背景都相当兼容，无需太多努力。当然，一个无所不知的人会毫不困难地找到一个人的柯尔莫哥洛夫弦。同时，无需诉诸超自然力量来指出这样一条绳子几乎肯定存在于每个人身上。</p><p>这些字符串还能告诉我们什么？我的灵魂有多大——当你剥掉所有的脂肪后，我还剩下什么？我的灵魂在我的一生中成长了多少？发生重大人生事件后，情况会发生怎样的变化？与其他灵魂相比如何？这些灵魂是否包含相似的结构，或者它们都相当独特？我们到底能有多接近近似值呢？如果柯尔莫哥洛夫弦已知，有人真的会死吗？</p><p></p><p> <a href="https://sigil.substack.com/p/kolmogorov-complexity-lays-bare-the">https://sigil.substack.com/p/kolmogorov-complexity-lays-bare-the</a></p><br/><br/> <a href="https://www.lesswrong.com/posts/XoMdqAoo5LqKewKDC/kolmogorov-complexity-lays-bare-the-soul#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/XoMdqAoo5LqKewKDC/kolmogorov-complexity-lays-bare-the-soul<guid ispermalink="false"> XoMdqAoo5LqKewKDC</guid><dc:creator><![CDATA[jakej]]></dc:creator><pubDate> Fri, 01 Dec 2023 18:29:58 GMT</pubDate> </item><item><title><![CDATA[Thoughts on “AI is easy to control” by Pope & Belrose]]></title><description><![CDATA[Published on December 1, 2023 5:30 PM GMT<br/><br/><p> Quintin Pope 和 Nora Belrose 建立了一个新的<a href="https://optimists.ai/"><u>“AI 乐观主义者”网站</u></a>，并发表了一篇新文章“ <a href="https://optimists.ai/2023/11/28/ai-is-easy-to-control/"><u>AI 很容易控制</u></a>”，认为未来 AI 导致人类灭绝的风险（“AI x-risk”）仅为 1 %（“尾部风险值得考虑，但不是世界上主要的风险来源”）。 （我<i>更加</i>悲观。）它提出了很多有趣的论点，我很高兴作者们正在进行实质性和富有成效的讨论，这与基于<i>人身攻击</i>的胡言乱语不同，这种胡言乱语在双方都变得越来越普遍。近几个月的人工智能 x 风险问题。</p><p>这不是全面的反驳或任何东西，而是挑选一些对于我们不同意的地方或我有话要说的地方似乎很重要的线索。</p><h1>摘要/目录：</h1><p><strong><u>注：</u>我认为第 1 节和第 4 节是我对 AI x 风险比 Pope 和 Belrose 更加悲观的主要原因，而第 2 节和第 3 节则更加挑剔</strong>。</p><ul><li>第一节认为，<i>即使</i>可控人工智能有一个“简单”的技术解决方案，由于竞争和协调问题等原因，仍然有充分的理由担心人工智能的接管，事实上我仍然对我们的前景总体上持悲观态度。</li><li>第 2 节讨论术语“黑盒”与“白盒”。</li><li>第三节讨论了我们从“人类一致性”中学到了什么，包括我如何看待人类先天驱动力的一些背景。</li><li>第四节认为，如果未来人工智能的训练方式与当前法学硕士的训练方式截然不同，那么整篇文章几乎都需要被抛弃。如果这让你觉得这是一个奇怪的、难以想象的假设，那么是的，我在这里是要告诉你，其他类型的人工智能确实存在，并且我特别讨论了<a href="https://www.alignmentforum.org/s/HzcM2dkCq7fwXBej8">“类脑 AGI”</a> （基于演员批评模型的 RL 的一个版本）的例子。 ），详细说明了该论文提出的一系列不适用于该类型人工智能的领域，以及更一般地说，它在安全相关方面与法学硕士有何不同。</li></ul><h1> 1. 即使可控人工智能有一个“简单”的技术解决方案，我仍然对人工智能接管持悲观态度</h1><p>Pope＆Belrose的大多数论文都在一个狭窄的问题上，即AI控制问题是否具有简单的技术解决方案。那太棒了！我强烈支持争论狭窄的问题。在本节之后，我也将谈论这个狭窄的问题。但是作者也确实提出了一个更广泛的问题，即所有考虑的事情都可能发生AI是否可能发生。这些不是同一问题；例如，可能有一个简单的技术解决方案，但人们不使用它。</p><p>因此，仅在本节中，我将出于论点为目的，实际上对AI控制和/或对齐问题有一个简单的技术解决方案。不幸的是，在这个世界上，我<i>仍然</i>认为未来对失控AI的灾难性接管不仅是合理的，而且可能是可能的。</p><p>假设有人<i>真正希望</i>世界上真正希望发生某事的人工智能，就像一个人可能<i>真的想</i><i>摆脱</i>债务一样，或者埃隆·马斯克（Elon Musk结束推理，开箱即用的解决方案，发明解决问题的新工具等。然后，如果“想要”比AI的欲望和习惯<a href="https://www.lesswrong.com/tag/instrumental-convergence"><u>更强收敛</u></a>。</p><p>但是在我们做到这一点之前，为什么我们可能会认为某人可能会真正希望世界上<i>真正想要</i>某些事情发生的AI呢？好吧，很多原因：</p><ul><li>自AI黎明以来，人们就一直在尝试做到这一点。</li><li><i>人类</i>通常真的真的希望世界上的某些事情发生（例如，让我的国家赢得战争，赚很多钱，做一些令人印象深刻的事情，以赢得名声和投资者和神经论文等），并假设其中一些人会推理“使X实现的最佳方法是构建真正希望X发生的AI”。您和我可能会宣布这些人很愚蠢，但是男孩，人们每天都在做愚蠢的事情。</li><li>随着人工智能的发展，越来越多的人可能具有直觉，即独家制造<i>没有</i>权利并且在宪法上没有自己的志向的AI是不道德的。这已经开始发生。我将搁置一个问题，即直觉是否是合理的。</li><li>有些人认为，不可逆转的Agi灾难不可能发生，<i>无论</i>AGI的动机和能力如何&#39;t实际上有效]。一个人希望这样的人的数量会随着时间的流逝而下降，但我不希望它会零。</li><li>有些人希望使AGI尽可能地有能力和独立，<i>即使</i>这意味着人类将灭绝，因为“ AI是进化的下一步”或其他。很少有人认为这是如此！但是<a href="https://twitter.com/AndrewCritchPhD/status/1729524104896930192"><u>它们确实存在</u></a>。</li><li>有时人们会做一些事情只是为了看看会发生什么（参见<a href="https://decrypt.co/126122/meet-chaos-gpt-ai-tool-destroy-humanity">混乱-GPT</a> ）。</li></ul><p>因此，现在我以强烈的默认假设结束，即未来的世界都将在人类的密切监督下以及控制之外的后果主义者AIS残酷地寻求权力。这使我们达到了防御余额，法规和相关问题。这是一个复杂的话题，双方都有许多不确定性和考虑因素。碰巧的是，我悲观地认为人类将生存。查看我的帖子<a href="https://www.alignmentforum.org/posts/LFNXiQuGrar3duBzJ/what-does-it-take-to-defend-the-world-against-out-of-control"><u>，捍卫世界免受控制之外的AGIS需要什么？</u></a>了解详情。再说一次，我认为有很多不确定性，并且有理性的人不同意的范围，但是我认为人们不能仔细地思考这个话题，并以低至1％的概率结束了，这将永远存在灾难性的AI收购。</p><h1> 2.黑白（框）思维</h1><p>作者一遍又一遍地重复AI是“白盒子”，这与“黑盒子”的人类大脑不同。几个月前， <a href="https://forum.effectivealtruism.org/posts/JYEAL8g7ArqGoTaX6/ai-pause-will-likely-backfire?commentId=3xxsumjgHWoJqSzqw"><u>我与诺拉（Nora）争吵</u></a>，查尔斯·福斯特（Charles Foster）<a href="https://twitter.com/CFGeek/status/1709692498556444744"><u>在Twitter上也以有益的看法进行了说法</u></a>，令人信服地争辩说“白盒”和“黑匣子”在不同领域的使用方式有所不同。我的收获是：我厌倦了对此的争论，<strong>我真的希望每个人都会</strong><a href="https://www.lesswrong.com/tag/rationalist-taboo"><strong><u>禁忌</u></strong></a><strong>“黑匣子”和“白盒子”一词</strong>，即，不用使用这些特定单词的话，说什么您想说的话。</p><p>因此，我希望每个人都可以同意这两件事：</p><ul><li> （a）希望各方的每个人都可以同意，<strong>如果我的LLM可靠地表现出一定的行为 -  EG在一定提示后输出“苹果”，并且您问我“为什么输出&#39;苹果&#39;而不是“香蕉”？ ”，然后可能需要数十年的工作才能给您一个令人满意的直观答案。</strong>在这方面，LLM与许多其他工程的人工制品（如桥梁和飞机）不同。例如，如果飞机可靠地表现出一定的行为（假设它往往会以异常低的气压下降），然后您问我“为什么它会表现出这种行为？”然后是一个肯定的赌注，飞机设计师可以很快找到一个令人满意的直观答案（也许立即，也许不是，但肯定不是几十年）。同样，如果像Linux内核这样的<i>非ML</i>计算机程序可靠地表现出一定的行为，那么可以肯定的是，对“为什么该程序这样做”的直观答案是一个令人满意的直觉答案，而一直在写作的人并且使用源代码可以通常在几分钟之内就很快产生答案。 （<i>有</i>一种<a href="https://www.reddit.com/r/learnprogramming/comments/13j7m4y/comment/jke1zi3/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button"><u>越野车行为需要很多人来理解的事情</u></a>，但它们的故事部分是因为它们是如此罕见。）</li><li> （b）希望各方的每个人都可以同意，<strong>如果您训练LLM，那么您可以查看任何或所有数十亿的重量和激活，也可以在重量上执行梯度下降。</strong>在这方面，LLM与生物智能不同，因为生物神经元难以测量和操纵实验。即使是小鼠也有太多的神经元的订单，无法实时测量和操纵所有这些活动，即使您可以，您当然也无法在整个鼠标大脑上执行梯度下降。</li></ul><p>同样，我希望我们可以就这两件事（类似）达成共识，即使我们不同意这些事实对AI X-fisk的暗示。作为记录，我认为以上<i>任何一个</i>要点<i>本身</i>不足以使某人对AI X-fisk感到乐观或悲观。但是它们可以成为更大的论点中的成分。那么，我们都可以停止争论LLM是“黑匣子”还是“白盒子”，然后继续进行有意义的东西吗？</p><h1> 3.我们从“人类的一致性”中学到什么教训？</h1><p>作者写道：</p><blockquote><p>如果我们可以观察并修改人脑中发生的一切，我们将能够使用优化算法来计算突触权重的精确修改，从而导致所需的行为变化。由于我们无法做到这一点，因此我们被迫诉诸于将年轻人塑造成友善和富有成效的成年人的粗略和错误的工具。我们为儿童提供模仿的榜样，以及针对他们先天，不断发展的驱动器量身定制的奖励和惩罚。从本质上讲，我们是从外部戳戳和刺激人脑的学习算法，而不是直接设计那些学习算法。</p><p>这些黑匣子对准方法的效果如何：大多数人确实很好地吸收了他们的文化价值观，而且大多数人都是相当亲社会的。但是人类的一致性也是高度不完善的。当他们可以摆脱它时，很多人都是自私和反社会的，而文化规范会随着时间的流逝而改变，无论好坏。黑匣子对齐是不可靠的，因为不能保证旨在改变某个方向行为的干预措施实际上会朝着该方向改变行为。孩子们经常与父母告诉他们做的完全相反，只是为了叛逆。</p></blockquote><p>我认为这里有两个完全不同的故事混乱地纠结在一起。</p><ul><li>故事1：“人类具有天生的，发展的驱动力，导致他们想成为亲社会，适应自己的文化，模仿榜样等，至少在某种程度上模仿榜样等。”</li><li>故事2：“人类的孩子逐渐被父母和社会塑造成友善和富有成效的成年人，提供奖励和惩罚，并以其他方式控制他们的生活经验。”</li></ul><p>我基本上倾向于故事1的原因是我的<a href="https://www.lesswrong.com/posts/aodPs8H9dQxpXAcwk/heritability-behaviorism-and-within-lifetime-rl"><u>遗传力，行为主义和千载难逢的RL</u></a>中的原因。</p><p>有一些警告 -  eg父母显然可以通过营养不良，或者通过将他们与所有人类接触隔离，或通过使他们暴露于铅灰尘等来“雕刻”任意的孩子成人无态度和无效的成年人。但是通常，<strong>我们是“我们是”被迫诉诸于将年轻人塑造成友善和富有生产力的成年人的</strong><strong>粗略和错误的工具。成年人有四个炉子的心”</strong> 。荣誉是进化的，而不是“我们”。</p><p>那么，这意味着AI X风险呢​​？我不知道，这是删除的几个步骤。但这使我们成为了“人类先天驱动器”的主题，这是一个接近我（四室）心脏的主题。我认为人类先天驱动器与同情的部分（与同情等有关的部分）相当于数百种伪码，<i>没有人知道它们是什么</i>。我认为如果我们这样做会很好，那恰好是<a href="https://www.lesswrong.com/posts/qusBXzCpxijTudvBB/my-agi-safety-research-2022-in-review-and-plans#2__Second_half_of_2022__1_3___My_main_research_project"><u>我的主要研究兴趣</u></a>。如果记忆有用，Quintin希望我能弄清楚这一点。但是这里的文章似乎很大程度上暗示着这并不重要，因为无论如何我们都可以轻松获得AI的一致性和控制。</p><p>取而代之的是，作者从人类先天驱动器相对简单的事实中做出了很大的影响（我认为它们的意思是“与现代训练有素的ML模型相比简单”，我同意这一点）。我很困惑为什么这很重要。当我们不知道它是什么时，谁在乎是否有一个简单的解决方案？</p><p>我认为也许我们的想法是，我们通过RLHF奖励功能近似人类先天驱动器，因此人类先天驱动器很简单的事实应该使我们相信RLHF奖励功能（其相对丰富的免费参数和培训数据）准确地捕获人类先天驱动器吗？如果是这样，我强烈不同意前提：RLHF奖励功能<i>不是</i>近似人类先天驱动器。取而代之的是，它近似于人类成年人的偏好，这些偏好与人类先天的驱动器并不完全无关，但肯定不是同一回事。例如，<a href="https://www.lesswrong.com/posts/7kdBqSFJnvJzYTfx9/a-theory-of-laughter"><u>这是笑声的天生驱动器可能模糊的样子</u></a>- 这是涉及某些激素水平和下丘脑中各种良好研究的先天信号通路的奇怪之处（如果我是对的话）。将其与人类成年人的幽默感进行比较。 RLHF奖励功能大约捕获了后者（除其他许多方面），但与前者几乎没有关系。</p><p>再次，那呢？这是人工智能厄运的论点吗？不，我正在对本文中提出的某些观点提出狭窄的论点。如果您想争辩说RLHF奖励功能在捕捉人类成年人的偏好方面做得很好，那么一定要直接提出这一论点。我什至可能同意。但是，让我们让人类先天的驱动器摆脱困境。</p><h1> 4.如果未来强大的AI与当前的LLM有意义的方式训练，我们都可以提前同意拒绝整个“ AI易于控制”论文？</h1><p>我的理解是，作者期望最强大的未来AI培训方法基本上与当今大语言模型中使用的方法相似，即对人类创建的文本和/或其他数据的自我回调预测，然后是RLHF微调或类似的数据。</p><p>碰巧的是，我不同意。但是，如果作者是对的，那么……我不知道。 “在未来的<a href="https://www.lesswrong.com/tag/transformative-ai"><i><u>变革性AI的</u></i></a><i>情况下，AI X-strisk</i><i>以与当前LLM相似的方式培训”</i>并不是我的专业知识或兴趣领域。我不希望这种情况能够实现，所以我很难清楚地思考一下 - 例如，如果有人对我说“想象一个方圈，现在回答以下问题……”。无论如何，如果我们专门谈论未来的AI，其培训基本上与现代LLM基本相同，那么这篇文章中的许多乐观态度对我来说似乎很合理。但是我也经常阅读更多的悲观叙述，<i>这些叙述</i>听起来也很合理！！我真的不知道我的感受。我将抛在一边，将辩论留给他人。</p><p>因此，无论如何，如果作者认为未来的变革性AI将像现代LLM一样受到训练，那么这对他们来说是一件好事，即使我碰巧不同意。许多合理的人相信这一点。而且我认为这些作者尤其是出于有趣且经过深思熟虑的原因，而不仅仅是“哦，Chatgpt很酷！”。我不想争论这一点 - 我们迟早会发现一种或另一种方式。</p><p>但这意味着该帖子充满了对当前LLM有效的索赔和假设（或以与当前LLM相同的方式训练的未来AI），但对其他类型的AI培训。而且我认为这还不够清楚。实际上，甚至没有提及。</p><p>为什么这是个问题？因为现在有人试图以与安全性相关的方式使用与LLM完全不同的架构和培训方法来构建变革性的AI。他们正在阅读这篇文章，并将其视为进一步的证实，即他们所做的事情很好，而且（实际上）无风险。但是他们不应该！这篇文章简直不适用于这些人在做什么！ （对于这样一个人的真实示例，请参见<a href="https://x.com/ylecun/status/1730000457513443666?s=20"><u>此处</u></a>和<a href="https://www.lesswrong.com/posts/C5guLAx7ieQoowv3d/lecun-s-a-path-towards-autonomous-machine-intelligence-has-1"><u>此处</u></a>。）</p><p>因此，我建议作者应清楚，反复说明，如果对最强大的未来AI接受了与当前LLM的有意义不同的培训，那么他们就会否认论文（而且我希望在其余的网站上大部分）。如果作者是永远不会发生的超级自信，因为像LLM一样的方法是未来，那么这样的陈述将不重要 - 从他们自己的角度来看，他们真的不会承认任何事情。但从我的角度来看，这真的很重要！</p><h2> 4.1论文提出不适用于<a href="https://www.alignmentforum.org/s/HzcM2dkCq7fwXBej8"><u>“大脑样agi”</u></a>的示例（≈基于角色批评的RL）</h2><p>在整篇文章中，我将抛弃许多明显的例子，其中作者使用当前LLM的属性作为有关未来强大AI属性的直接证据。这里有一些略有明显的例子：</p><blockquote><p>由于AIS是白盒子，因此我们可以完全控制其“感觉环境”（无论是由文本，图像还是其他方式组成）。</p></blockquote><p>作为一个人，我可以坐在床上，凝视太空，我可以认为对弦理论的特定干扰思想，现在我已经弄清楚了一些重要的东西。如果未来的AI能够做到这类事情，那么我所期望的是，“控制AI的感觉环境”确实是如此之大。</p><blockquote><p>如果AI秘密打算杀死您，梯度下降将注意到这一点，并使将来这样做的可能性较小，因为可以将秘密谋杀案的神经循环拆除并重新配置为直接提高性能的电路。</p></blockquote><p>人类可以多年来怀有秘密的欲望，从不对此采取行动，而且他们的大脑不一定会覆盖这种愿望，即使他们同时认为数百万的想法。因此，显然，上面的论点不适合人类的大脑。一个有趣的问题是，它在哪里出错？我目前的猜测是，主要问题是（必要）主要由<a href="https://en.wikipedia.org/wiki/Temporal_difference_learning"><u>TD Learning</u></a>编辑，我认为这通常比梯度下降得多。</p><blockquote><p>我们可以进行大量实验以找到最有效的干预措施，并且还可以在各种模拟环境中运行它，并测试在有和没有认知干预的情况下它是否按预期行为。每次AI的“记忆”都可以重置，使实验完全可复制并阻止AI适应我们的行动，这与心理学和社会科学领域的实验非常不同。</p></blockquote><p>这听起来不错，但是类似大脑的AGI（像大多数RL代理一样）<a href="https://en.wikipedia.org/wiki/Online_machine_learning"><u>在线学习</u></a>。因此，如果您进行了一系列实验，那么一旦AGI做任何事情（例如，读取晨报），您的实验都是无效的（或至少对问题开放），因为现在您的AGI与它的不同之处在于之前（ANN重量不同，不仅是不同的环境 /不同的提示）。人类也是如此，但LLM并非如此。</p><blockquote><p>说到AIS，<strong>我们是天生的奖励系统</strong>。</p></blockquote><p>我不知道我应该如何用类似大脑的agi来解释这句话，这样它根本没有任何意义。实际上，我不太确定即使对LLM的意义！</p><h2> 4.2否，“类似脑的AGI”也没有类似于LLM的训练</h2><p>这对我来说似乎很明显，但是显然这是有争议的，所以让我们浏览一些示例差异。这些都没有试图证明AI的对齐和控制很容易或硬。取而代之的是，我提出的是，未来LLM的安全/危险与假设未来大脑的AGI的安全/危险是一个不同的技术问题。</p><ul><li><i>大脑可以模仿，但与LLM预读的方式根本不同。</i>具体而言，在自我监督预处理之后，LLM准确地输出了它希望看到的东西。 （在RLHF之后，这不再是严格的，但是RLHF只是一个微调的步骤， <a href="https://www.lesswrong.com/posts/4rmvMThJYNcCptAya/axrp-episode-22-shard-theory-with-quintin-pope?commentId=xvuqDk3njzhk6KsEq">大多数行为倾向来自IMO预计</a>。）在人类中，这是没有意义的。当我采取行动时，我将电动机命令发送到自己的手臂和自己的嘴里等。虽然当我观察另一个人并进行自我监督的学习时，我的大脑在内部计算对即将到来的声音和图像的预测。而且没有任何直接的方式可以在它们之间翻译。 （参见Owain Evans和Jacob Steinhardt <a href="https://www.lesswrong.com/s/4dHMdK5TLN6xcqtyc/p/cnC2RMWEGiGpJv8go#Inferring_Reward_Functions_from_Video_Frames"><u>在这里</u></a>展示电影框架的照片，并问“正在执行什么动作？”）现在，人类经常确实模仿其他人。但是其他时候他们没有。无论如何，只要发生人类的其他人类，它必须通过与LLMS中的算法机制非常不同，直接算法的方式差不多。具体来说，人类模仿其他人，<i>因为他们想</i>直接或间接地是因为过去的加固历史。经过验证的LLM将模仿没有RL或“想模仿”的人类文本，但这只是机械上的工作。</li><li><i>相关的是，大脑在期望和欲望之间有区别，可以干净地烘烤到算法中。</i>我认为这是显而易见的常识，抛开<a href="https://www.lesswrong.com/posts/MArdnet7pwgALaeKs/why-i-m-not-into-the-free-energy-principle"><u>了试图否认它的星系脑FEP</u></a> 。相比之下，“ LLM<i>期望下</i>一个令牌为&#39;a&#39;”和“ LLM<i>希望</i>下一个令牌为&#39;a&#39;”之间没有任何区别。 （或者，如果有的话，它是复杂的，出现的和有争议的，而不是直接，直接地反映在源代码中，因为我声称它将像大脑一样。关于安全的争论。</li><li><i>在大脑中，</i><a href="https://en.wikipedia.org/wiki/Online_machine_learning"><i><u>在线学习</u></i></a><i>（编辑权重，而不仅仅是上下文窗口）是解决问题的一部分。</i>如果我问一个聪明的人，一个硬科学问题，他们的大脑可能会从时间t = 0到t = 10分钟，因为他们凝视了太空，然后出来了。在那10分钟之后，他们的大脑与以前的大脑永久不同（即不同的重量） - 他们弄清楚了他们以前不知道的科学的事情。<i>不仅如此</i>，而且他们在时间0 &lt;t &lt;5分钟中所做的在线学习（重量编辑）对于在时间5 &lt;t &lt;10分钟期间发生的进一步处理绝对至关重要。这不是当今LLM的工作方式，而是在“思考”过程中编辑权重。我认为这是由于多种原因与安全相关的，包括我们是否可以期望未来的AI在没有新的人提供的培训数据的情况下以开放式的方式迅速变得更聪明（ <a href="https://www.lesswrong.com/posts/hvz9qjWyv8cLX9JJR/evolution-provides-no-evidence-for-the-sharp-left-turn?commentId=7yAJbkDtMepxDvcMe"><u>相关讨论</u></a>）。</li></ul><p>我想重申，我很高兴人们正在逐步计划，因为未来的变革性AI可能会像LLM一样。我们绝对应该这样做。但是我们应该非常清楚，这就是我们正在做的事情。</p><br/><br/> <a href="https://www.lesswrong.com/posts/YyosBAutg4bzScaLu/thoughts-on-ai-is-easy-to-control-by-pope-and-belrose#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/yyosbautg4bzscalu/thoughts-on-ai-is-isy-isy-to-control-by-by-pope-and-belrose<guid ispermalink="false"> Yyosbautg4bzscalu</guid><dc:creator><![CDATA[Steven Byrnes]]></dc:creator><pubDate> Fri, 01 Dec 2023 17:30:52 GMT</pubDate> </item><item><title><![CDATA[the uni wheel is dumb]]></title><description><![CDATA[Published on December 1, 2023 4:36 PM GMT<br/><br/><p>汽车轮需要上下移动，有时转弯。为了实现这一点，它们连接到两端各有一个<a href="https://en.wikipedia.org/wiki/Constant-velocity_joint">等速万向</a>节的传动轴。<a href="https://www.amazon.com/s?k=cv+axle+shaft+assembly">以下</a>是亚马逊上的一些此类组件。</p><p>最近，现代发行了<a href="https://www.youtube.com/watch?v=Nd6C0y8xc20">此视频，</a>介绍了一种允许开发垂直车轮运动的另一种方法。他们称其为uni轮。这有点受欢迎：该视频在3天内获得了300K的欣赏方式。<a href="https://www.autoblog.com/2023/11/29/uni-wheel-hyundai-kia-electric-vehicle-design/">这是有关系统的文章</a>。这个概念是在旋转的手臂上使用多个齿轮，以便它们相对移动。</p><p> Uni车轮系统在齿轮之间传输功率5次。效率为98％（高质量和润滑良好的平行钢齿轮），效率为90.04％。齿轮确实在那里具有折衷：较小的牙齿可提供更好的效率，但扭矩能力较小，而在同一齿轮上的扭矩更加降低了非线性的寿命，因此98％是关于连续运行的设备最经济的最经济性的。该视频声称92％至96％的效率，这意味着他们在最佳条件下牺牲了其他事物以提高效率和测试。</p><p>其图上的“高扭矩”情况（效率为92％）为200 nm。对于20英寸直径的轮胎，即左右的远射力。如果所有4个车轮均等驱动，则以30英里 /小时的速度驱动功率约为56.7 hp。如果制动也可以通过该速度，那么您必须设计齿轮处理足够的扭矩，这会影响效率。</p><p>轴CV接头的损失低于单个齿轮对。它的效率通常>; 99％。<a href="https://thompsoncouplings.com/wp-content/uploads/2019/09/TCVJ-Range-of-Tech-Specs.pdf">该数据表</a>在典型条件下<a href="https://en.wikipedia.org/wiki/Constant-velocity_joint#Thompson_joints">索赔汤普森耦合</a>的效率为99.95％。</p><p>同样，对于<em>高质量</em>且<em>润滑良好的</em>平行齿轮，效率为98％。油是必要的。 Uni车轮在移动轴的侧面有一个窗户，这需要滑动密封。有很多齿轮，这些齿轮需要轴承。这种方法会更昂贵。</p><p>另请注意，外部小轮子连接到需要用车轮垂直移动的非旋转板。因此，大多数扭矩需要传输到该板。如果它上下滑动，那是可能会磨损的另一件事，这会导致齿轮变得未对准，这是需要密封以保持油的另一件事。</p><p>效率低下不仅浪费功率，还会产生热量。这些可能会将1000瓦的加热加入车​​轮。</p><p>从技术上讲会起作用吗？当然。这不是一个好主意。</p><p>如果目标是避免需要轴线越过底部的需要，因为它占用了太多空间（？）而不将电动机放入方向盘内（因为这增加了车轮上的毫无保留的重量），则有更好的方法可以实现这一目标。斜角齿轮和2个CV接头会更好。链条驱动器可能会更有效，更便宜，尽管如果您实际上可以密封该滑动窗口，则可能需要（链）更换（链）更换。是的，只要将斜角齿轮放在前面，如果它穿过汽车实际上是一个问题，则在车轮上向后奔跑的简历车轴组件。不客气，现代。</p><p>我还可以写一些其他帖子。有一些坏主意浪费了数十亿美元，这使我亲自冒犯了我。我基本上只是在Uni车轮上选择，因为它简单易于理解。</p><p>如今，人们被他们通常不了解的技术包围。当他们看到一些想法明显的问题时，人们通常认为某些专家比他们更多地考虑了它，因此，如果要认真提议，就必须有一个好的解决方案。问题是，无论您决定信任哪个机构，有时都会做一些显然不切实际的事情。例如：</p><ul><li>大学教授？阿尔茨海默氏症的淀粉样假说。</li><li>埃隆·马斯克？超环。</li><li> Google和VCS？ Juicero。</li><li>微软和山姆·奥特曼？日利昂。</li><li>美国和日本政府？氢燃料。</li><li>很多普通人？太阳能道路。</li></ul><p>顺便说一句，关于Juicero，创始人是一个生食的狂热者，这个概念是将未经省心的水果和蔬菜放入小袋中。这意味着这些小袋需要冷藏，只持续了5到8天，而且由于它们是不透明的，因此无法在挤压之前检查它们的霉菌。离开Juicero后，创始人<a href="https://www.youtube.com/watch?v=oI-Ye8SP708">继续出售</a>“原水”。</p><p>当我说问题很明显时，也许这听起来像是矛盾的：如果有多年的人从事这些工作的人，而他们看不到这些问题，那么他们怎么会“显而易见”？然而，由于几个因素，情况就是如此：</p><ol><li>只有一小部分人从事任何特定的事情，并且选择偏见。认为某个想法不切实际的人可能不会在努力。然后，媒体将与看到问题并远离的人与“主题专家”进行交谈。</li><li>就像普通人认为，除了自己之外的一些专家已经考虑了任何明显的问题一样，公司内的专家通常会承担同样的事情。也许某种东西的最初发明者告诉他们：“很好，我已经做了数学了”。进而...</li><li>发明家和过度自在的新恋人通常对新想法的缺陷视而不见，因为他们希望事情起作用。</li><li>经济激励措施可能导致人们撒谎。教授想要赠款，因此他们会假装某些东西是实用的，甚至是<a href="https://www.science.org/content/blog-post/faked-beta-amyloid-data-what-does-it-mean">虚假的数据</a>。初创企业创始人将假装他们对一切都有解决方案，而他们拼命寻找投资者发现的东西。</li><li>如今，大多数机构擅长选择聪明的人。咨询公司会宣传他们的员工是常春藤联盟的毕业生，好像这意味着什么，但是根据我的经验，我可以去一家餐厅，从客户那里挑选出聪明的人。</li><li>当投资者想要独立的技术尽职调查时，他们通常会聘请像德勤这样的公司，但是德勤通常没有特定的专业知识来评估建议或何时被公司误导。</li><li>顾问倾向于告诉任何人要向他们付出他们想听的内容，这通常是出于政治原因做出的决定的理由。似乎公司董事和投资经理宁愿获得投资不起作用的东西的理由，也不愿听到他们所有的想法最终将是不切实际的。有些人会在失败的情况下消失，无论结果如何，有些人都会失败，而有些人只有大的自负。</li><li>我记得与VC交谈，并说Weork/ETC表明，软银在评估投资方面做得不好，他们的答复是，WeWork对早期投资者和软银的总体赚钱做得很好。他们的观点是，卖给后来的投资者比最终结果更重要。基本上，激励措施不对。</li></ol><p>总而言之，如果您想评估一种新技术，也许您应该找到一些可能正在研究它但不是这样做的人，也许您还应该在机构隶属关系外寻找专业知识的指示。</p><br/><br/><a href="https://www.lesswrong.com/posts/Cwnz5EXkbB6wJjfdX/the-uni-wheel-is-dumb#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/cwnz5exkbb6wjjfdx/the-uni-wheel-is-dumb<guid ispermalink="false"> CWNZ5EXKBB6WJFDX</guid><dc:creator><![CDATA[bhauth]]></dc:creator><pubDate> Fri, 01 Dec 2023 16:36:09 GMT</pubDate></item></channel></rss>