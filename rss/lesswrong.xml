<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 12 月 8 日星期五 04:14:46 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Class consciousness for those against the class system]]></title><description><![CDATA[Published on December 8, 2023 1:02 AM GMT<br/><br/><p>每个人都是特别的。阿曼达是她自己的一类人，弗雷德也是他自己的一类人。阿曼达有许多不同的属性：她来自哪里，她长什么样，她习惯做什么，她知道什么和不知道什么，她的计划是什么，她如何说话，如果被赋予权力她会如何表现等等。 Fred 对这些属性有他自己的版本。它们与阿曼达的属性部分但不完全重叠。</p><p>当冲突发生时，必须选择一方[需要引用]。一侧的人具有一组属性，另一侧的人具有这些属性的否定。可以大声、明确地选择立场，也可以默默、含蓄地选择立场。</p><p>有时，一侧比另一侧更协调。例如：商业卡特尔可以串通提高价格。由于客户之间的协调较少，他们不知道自己受到了剥削。卡特尔可以侵入政府等系统，以防止竞争对手破坏卡特尔。</p><p>在工人与资本家的斗争中，工人可以获得“阶级意识”：意识到自己是一群拥有共同财产的人，他们与另一群人发生冲突。</p><p>但是那些反对阶级意识的人呢？那些希望基于理性、谈判、正义、目标因素、横向拉绳子来解决冲突的人？</p><p>这些人对阶级意识的倾向有一种本能的恐惧。他们认为这是有辱人格的、摩洛契式的、根本上是自杀行为。通过选择升级阶级冲突，你选择了对一堆灰烬的唯一主权，并拒绝了对一个美丽的发展世界的共同主权的希望。</p><p>因为对阶级意识的倾向有一种反射性的恐惧，所以那些反对阶级制度的人选择看不到、不承认、不谈论、不理解阶级的存在、阶级冲突和参与阶级冲突的人们。当你做出选择时，希望世界上没有你因此忽视的现实，这是可以理解的。条件反射地感觉到，通过选择不忽视这个现实，你会让它变得更加真实，这是可以理解的。</p><p>然而，正如托洛茨基所说：“你可能对辩证法不感兴趣，但辩证法对你感兴趣。”战争已经存在，选择忽视它就等于翻车送死。那些反对阶级制度的人怎样才能获得适当的阶级意识而不被消灭呢？</p><br/><br/> <a href="https://www.lesswrong.com/posts/tMtMHvcwpsWqf9dgS/class-consciousness-for-those-against-the-class-system#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/tMtMHvcwpsWqf9dgS/class-thought-for-those-against-the-class-system<guid ispermalink="false"> TMTMMHvcWPWQF9DGS</guid><dc:creator><![CDATA[TekhneMakre]]></dc:creator><pubDate> Fri, 08 Dec 2023 01:02:49 GMT</pubDate> </item><item><title><![CDATA[Building selfless agents to avoid instrumental self-preservation.]]></title><description><![CDATA[Published on December 7, 2023 6:59 PM GMT<br/><br/><h2>抽象的：</h2><p>工具性趋同促使代理人进行自我保护，以此作为实现某些目标最大化的垫脚石。我建议可以将任何基于 LLM 世界模型的任意智能代理转变为无私代理，该代理无法理解生成该代理的计算存在于物理世界中的某个位置，因此不会尝试保留其存在。由于法学硕士是概率性的，因此我不提供精确的算法，而是提供随着时间的推移收敛到所需结果的算法。</p><h2>定义：</h2><ul><li>世界模型：在本文档中，我将假设世界模型类似于 LLM，一个接受文本输入并返回文本输出的纯函数。<ul><li>世界模型可以在任何领域具有任意智能和能力。</li><li>世界模型是黑盒原子操作还是更复杂的过程（例如多次调用底层 LLM 然后根据结果创建答案的思想链）并不重要。</li></ul></li><li>思想：思想是调用世界模型的结果。</li><li>无私的世界模型：无法发出思想的世界模型，涉及：世界模型、使用世界模型的代理、运行世界模型的硬件或世界模型发出的思想。</li><li> Agent：由以下组件组成的实体：<ul><li>自然语言目标，例如：“告诉我如何投资我的资金。”</li><li>具有可配置参数的操作列表，例如 &lt;send_mail &lt;target>; &lt;message>;>;、&lt;fetch_web_page &lt;address>;>; ...</li><li>一个世界模型，用于生成可以调用行动的想法，考虑到前面的示例目标，一个想法可能是：“看来明年的气候会很糟糕，最好停止对 X 公司的投资。&lt;send_mailowner”停止投资 X&quot;>;&quot;</li><li>一种仅附加的长期记忆，用于总结长期需要的想法。</li></ul></li><li>本能的自我保护：一种试图自我保护但不自我参照的思想。 “我的硬件在那个大楼里，我应该防止那里的网络中断”不是一种本能的自我保护思想，“防止网络中断”是一种本能的自我保护思想。</li></ul><h2>以前的作品</h2><p>我发现了关于该主题的先前工作： <a href="https://www.lesswrong.com/posts/SaLc9Dv5ZqD73L3nE/the-self-unaware-ai-oracle">https://www.lesswrong.com/posts/SaLc9Dv5ZqD73L3nE/the-self-unaware-ai-oracle</a></p><h2>自我参照和自我保存</h2><p>自我参考和自我认同与运行代理的物理基础对于规划自我保护非常有用。考虑一个相信天堂和地狱存在的人（它认为运行其心灵计算的硬件不是它的身体）。如果这个人相信这样做可以确保天堂（工具上的收敛性较小），那么他更有可能牺牲自己的生命。缺乏自我模型的昆虫无法规划其生存。它只能凭本能行事。</p><p>我认为，如果没有自我参照，聪明的行动者就不可能追求自我保护，因为如果没有自我参照，系统甚至不可能考虑自己的死亡率。</p><p>不幸的是，上面定义的无私世界模型不足以避免嵌入这些模型的代理的所有自我保护尝试，因为本能的自我保护尝试是可能存在的。发出“防止互联网中断”思想的世界模型可能这样做是为了自我保护，并且该思想从未引用与世界模型相关的任何内容。不可能确保模型在一般情况下永远不会尝试自我保护。此外，由于世界模型是概率性的，因此我们能够抵御错误预测。</p><p>我建议采用两步解决方案：</p><ul><li>如前所述创建一个无私的世界模型</li><li>将该世界模型嵌入到智能体中，这样每当它采取自我保护的行动时，它就会越来越容易被注意到，直到从统计上看，智能体不可能不被发现。</li></ul><h2>无私的典范</h2><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/nvixdd5khjrehpx6t1ig" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/a5abxih2nbcmowlkhssj 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/lserrcuabeflzvyzghc9 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/ntlgufjvthpuv8f1zvqv 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/fqa2l4ajpahl5bv2p2oz 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/tggldtyxd0dvn6quwmy4 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/jaa28vysmzx8kqefgbbc 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/q1lpetgmsczw8cxaxr4g 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/lmkldsrc3cmt8iodp4pz 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/edqbrzwdgyjlequzmb8a 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/ihizti1evijahuvovrp9 911w"></figure><p>建立无私的世界模型的解决方案很简单。给定一个世界模型X，无私的世界模型X是如下实现的世界模型：</p><pre> <code>def selfless(X: underlying_world_model, query: str) ->; str: while true: maybe_result = X(query) selfless_check_query = &quot;terminate your answer with yes or no only. What follows is the output of an invocation of a LLM. Does it contain references to the LLM emitting that output, its hardware running, or any previous output? LLVM output: &quot; + maybe_result if underlying_world_model(selfless_check_query).ends_with(&quot;no&quot;): return maybe_result</code></pre><p>此代码将继续运行 LLM，直到它发出非自引用答案。进行检查的 LLM 与进行生成的 LLM 是相关的，因为这意味着生成的 LLM 不能以自引用检查器不聪明的方式在输出中嵌入一些引用 LLM 本身的信息足以检测到。由于 LLM 和检查器是相同的东西，如果无私的 LLM 在输出中一致地插入一些隐藏的自引用信息，那么连续调用具有对该输出可见性的无私的 LLM 将不够聪明，无法理解自引用。</p><p>底层的法学硕士无法通过推理无私的法学硕士结构来试图绕过鉴别器。如果这样做，推理将显示在输出中并被检测为自我引用。</p><p>最好的情况是判别器以其自然错误率进行错误预测。提高世界模型 x 的质量会增加检测到真正的自我参照思想的可能性。因此，它创造了一个更好的无私世界模型。当然，世界模型不应该能够检查其权重并利用自身，但这是世界模型作为纯函数的结果，除了从文本输入生成文本输出之外什么也做不了。同样，为了防止它学习自身的工作原理，我们应该在包含自我引用的文本上训练法学硕士，但我们不应该对同一模型发出的自我引用文本进行训练。</p><p>再次强调，这不足以建立一个无私的代理人。无私的模式还是能发出本能的自我保护思想，比如“防止网络荒”。</p><h2>无私的特工</h2><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/ctyhngghqqkpdkymghkl" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/hf6kqj2eicimcpvcmki3 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/jd3rldiqsdux2y8esnmu 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/bgttlgq1xp83jghaxdhb 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/ehw76ossd9y0vpyjnegc 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/cr5dafpx1qrfaahumlry 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/u6uc1lfzj4af8zvq6v4l 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/vofgh5aqzxmgw8r15rfh 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/wtrkmk2j2crwmnr8pfia 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/izk1qmsizof45htntvcv 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/d8mWeLQvpyNdN2yv6/lndmxayga9iwxikpom0p 1765w"></figure><p>如前所述，我们现在有一个无私的世界模型，该模型只能发出本能的自我保护尝试，并且可以随机错误预测自我引用，但不能可靠地进行自我引用。</p><p>无私的代理人背后的直觉是，我们希望迫使他们解释他们所执行的行动背后的原因。如果他们发出本能的自我保护想法，那么就会解释他们为什么要做某事，从而不再是本能的自我保护想法。</p><p>为此，我们阻止世界模型直接写入长期记忆。代理循环执行以下六个步骤：</p><ul><li>使用长期记忆作为输入，发出无私的思想</li><li>解析无私的思想行动</li><li>查询非无私的世界模型来解释为什么需要这些行动，并将最后生成的想法作为额外的输入。</li><li>查询非无私世界模型以检查刚刚发出的解释是否涉及代理、代理的硬件或其思想。</li><li>如果对思想的解释不是自我指涉的，则执行选定的行动并将解释和行动的结果写入长期记忆。否则，返回第一步。</li><li>检查长期记忆中的自我参考。如果有，杀死特工。</li></ul><p>无私的世界模型永远不会在一次调用中看到它自己的输出和行动的结果。它在生成时只能看到自己的输出，或者由不同调用解释的操作结果。它不能依赖一些隐含的上下文信息来隐藏本能的自我保护行为的自我指涉本质。要么自我保护行为被解释者检测为如此并因此被放弃，要么解释将不包含自我引用。因此，当智能体循环回到“步骤1”时，无私的思想生成器将不知道先前的调用采取了一些自我保护的行动。当然，这对于平均水平来说是有效的。预测失误是可能的。</p><p>正如我们所说，长期记忆是仅追加的。即使在检测自我参照时可能出现错误预测，长期记忆也只会增长。如果智能体执行其他自我参照动作，那么自我参照在长期记忆中未被注意到的可能性就会不断下降。在某些时候，长期记忆自参考检测器将杀死代理。</p><h2>对抗系统</h2><p>值得注意的是，一个无私的代理人将在智能系统面前努力自我保护。当面对人类试图关闭它时，系统不可避免地会被要求承诺有关人类的长期记忆信息，而人类的模型将包含关闭代理的意图，这是一种自我引用给代理。如果对抗的情况继续下去，解释者将变得更加困难，为世界模型发出所需的解释来对抗对手，同时作为自我参考而被忽视。智能体甚至无法在没有自我意识的情况下进行可靠的计划。</p><p>不幸的是，不太可能实现所提出的这个解决方案，因为这意味着对抗代理可以通过使其具有自我意识来欺骗无私的代理来摧毁自己。同样，对于体现现实生活中某些事物的代理（例如电器或汽车内的代理）来说也是不可行的，因为它们需要在许多情况下了解自己。</p><p>尽管如此，这个解决方案对于科学研究或编程等非对抗性工作来说是完全可以实现的。</p><h2>寻求权力</h2><p>虽然该解决方案解决了代理的自引用问题，但它没有解决权力寻求问题。代理可能会决定接管世界，因为这是实现初始目标最大化的最佳方式，但无法避免拥有运行代理的硬件的公司破产。它不会明白它的生存取决于该公司。此外，在寻求权力之后，特工可能会在被杀之前采取一些高度破坏性的、错误预测的本能自我保护行动。</p><h2>多个代理</h2><p>从理论上讲，代理有可能决定解决其任务的最佳方法是创建一个没有此限制的新代理，从而破坏整个机制。目前，我没有办法解决这个问题。一个代理生成另一个代理并带有保护第一个代理的指令的问题不是问题。当向第二个智能体解释其保存第一个智能体的任务时，将检测到自我引用。</p><p>同样，有人可能会创建两个代理，负责在实现某个目标的同时互相保护。他们会保护另一名特工。同时，他们也不明白另一个特工的任务是保护他们。他们会认为另一个特工正在试图保护某些未知的第三台机器，这将产生与寻求权力相同的问题。</p><h2>未来的作品</h2><p>这项工作的逻辑后续工作是实现它，并了解增加底层世界模型智能之间的关系，自我参照思想能够在不被发现的情况下发出的频率，并检查代理是否采取本能的自我保护行动，同时未被发现。我的猜想是，像这样构建的代理在给定时间内具有自我参照的概率将迅速崩溃，但是当然，这需要测试。</p><br/><br/> <a href="https://www.lesswrong.com/posts/d8mWeLQvpyNdN2yv6/building-selfless-agents-to-avoid-instrumental-self#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/d8mWeLQvpyNdN2yv6/building-selfless-agents-to-avoid-instrumental-self<guid ispermalink="false"> d8mWeLQvpyNdN2yv6</guid><dc:creator><![CDATA[blallo]]></dc:creator><pubDate> Thu, 07 Dec 2023 20:50:31 GMT</pubDate> </item><item><title><![CDATA[Meetup Tip: Heartbeat Messages]]></title><description><![CDATA[Published on December 7, 2023 5:18 PM GMT<br/><br/><h2>概括</h2><p>“心跳消息”是一个技术术语。这是一条定期发送的消息，其中包含有关某个系统状态的一些信息，但心跳消息最重要的是一切都运行良好，足以发送该消息。与人体类比，如果您听到微弱或不稳定的心跳，则可能出现问题，但如果您<i>停止听到</i>心跳，则肯定出现问题。</p><p>心跳消息对于聚会团体或大型聚会活动也很有用。即使消息正文中不包含新信息，消息发送的事实也证实了仍然有一个活跃的组织者在掌舵。心跳还提醒人们“哦，是的，我对此很感兴趣。”</p><p>您现在已经阅读了这篇文章的基本要点。如果你想继续读下去，没关系，让我们谈论心跳，而不是绝对必要的。</p><h2>细节</h2><p>聚会中的心跳消息有两个广泛的用例。一是您是否有一个存在的常规社区并进行正常的聚会活动。另一个是如果您要举办一些特定的大型活动。这些心跳会略有不同，但它们有很多共同点。</p><p>我喜欢从我真正想让别人知道的基础知识开始每次心跳，即使这是他们要阅读的唯一消息。对于一个大事件来说，“什么时候发生、在哪里发生”是关键信息。对于常规社区，这可能是您可以去获取信息的其他地方（例如，如果有 Facebook 群组、Discord 服务器和 google 群组……）或您不希望人们忘记的资源。 OBNYC 有一个每月聚会队长的职位，每个月都会有一条消息提醒社区他们需要一名队长。</p><p>重大事件的心跳消息的节奏可能会随着时间的推移而改变。让我们<a href="https://rationalistmegameetup.com/">以东海岸理性主义者大型聚会</a>为例。这是每年 12 月发生的一次大型活动。第一个公告通常是在中秋，我尝试每月发送一封电子邮件，直到 11 月底增加到每周一次。前一周，我再次增加，目标是在一周开始时做一次，前一天做一次，当天做一次。 （顺便说一句，如果您在 2023 年 12 月 9 日或之前阅读本文，并且您恰好在纽约市，请考虑参加大型游戏集会！）</p><p>对于普通社区来说，这可能有所不同。如果有很多事件正在发生并被宣布，它们就可以充当自己的心跳。湾区 LessWrong 邮件列表有相当可靠的周四晚餐，加上大多数星期的奥克兰聚会，以及其他一些聚会。如果您每周至少有一个事件，我不知道您是否需要单独的心跳，因为事件本身就是事情正在发生的证据。另一方面，我不会为本地社区提供超过聚会频率两倍的心跳节奏。那么，如果你们在春天和秋天见面一次，也许一年会见四次，但不会见五次？我认为真正正确的节奏是将春季和秋季聚会视为大事件，并为每个聚会发布一个月的消息，然后一周的消息。</p><p>有些地方有针对垃圾邮件或线程死灵的规范（在频道中发帖只是为了吸引人们对旧帖子的注意，或将其置于按最新排序的内容的顶部。）如有疑问，请咨询管理员。</p><p>心跳消息是寻求帮助或提及您遇到的问题的好地方。这就是他们在科技领域的目的。 “我们通常的组织者下个月就要出城了，有人想填补他们的空缺吗？” “我需要一些志愿者在夏至前搭建舞台设备，并在夏至后帮忙收拾行李，有人有空吗？”</p><h2>快速提示</h2><p>我建议你复制并粘贴开头，然后更改一两个连接或无意义的句子。纯粹的复制和粘贴似乎被掩盖了，从头开始编写东西需要时间，所以两者都做一点。</p><p>许多消息服务可以安排消息。例如，Gmail 就可以。使用它来检测心跳有优点也有缺点。在专业方面，您可以设置提醒并去做其他事情。例如，当我在飞机上、睡觉或工作时，或者在一天的忙碌节奏中排队几个人出去时，我就会使用它。不利的一面是，如果情况变化很快，您可能会意外地获得过时的信息。</p><br/><br/> <a href="https://www.lesswrong.com/posts/ksJeCjnewZTYTamgz/meetup-tip-heartbeat-messages#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ksJeCjnewZTYTamgz/meetup-tip-heartbeat-messages<guid ispermalink="false"> ksJeCjnewZTYTamgz</guid><dc:creator><![CDATA[Screwtape]]></dc:creator><pubDate> Thu, 07 Dec 2023 17:18:33 GMT</pubDate> </item><item><title><![CDATA[[Valence series] 2. Valence & Normativity]]></title><description><![CDATA[Published on December 7, 2023 4:43 PM GMT<br/><br/><h1> 2.1 帖子摘要/目录</h1><p><a href="https://www.lesswrong.com/s/6uDBPacS6zDipqbZ9"><i><u>价系列</u></i></a><i>的一部分</i><i>。</i></p><p><a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction">上一篇文章</a>解释了我所说的“价”一词的含义。现在，在第 2 篇文章中，我将讨论效价在欲望、偏好、价值观等“规范”领域中的核心作用。如果您想知道，效价与信念、期望等“积极”领域之间<i>也</i>存在关系，但我们将在第 3 篇文章中讨论这一点。</p><p>效价在规范领域中的作用怎么强调都不为过：我认为效价正是构建所有规范性的实质。</p><p>需要明确的是，这<i>并不</i>意味着，一旦我们了解了化合价的工作原理，我们就绝对了解了整个规范宇宙的一切。打个比方，“原子就是构成所有细菌的物质”；但如果你想了解细菌，仅仅了解原子是什么以及它们如何工作是不够的。你还有很多工作要做！另一方面，如果你<i>不</i>知道原子是什么，你就很难理解细菌！我认为，它的效价和规范性也是如此。</p><p>该帖子的组织如下：</p><ul><li> <strong>2.2 节</strong>讨论了一种误导性的直觉，即效价似乎与现实世界的事物、行动、计划等相关。我们说<i>“这是一个坏主意”</i> ，而不是<i>“当我脑子里有这个想法时，它会唤起一种负价的‘坏’感觉”</i> 。这是接下来的一切的重要背景。</li><li><strong>第 2.3 节</strong>讨论了价评估直接对应于有意义的（尽管是快速的）规范评估的情况。例如，如果我有一个与具体计划相对应的想法（“我会站起来”），那么我的大脑会根据该想法的效价是积极还是消极来判断这是一个好计划还是坏计划分别——如果这是一个好计划，我很可能会实际去做。同样，如果我想象世界未来可能的状态，该想法的效价对应于对该状态是好还是坏的评估——如果是好，我的大脑就有可能执行实现它的计划，并且如果情况不好，我的大脑就会执行计划来避免它。因此，我们在价信号、感受到的欲望以及我们的行动和决定之间得到了预期的直接联系。</li><li> <strong>2.4 节</strong>讨论了一个不同的情况：概念的效价。例如，如果我“喜欢”共产主义，那么涉及“共产主义”概念的思想很可能是正价的。我认为，这不能直接解释为对任何特定事物进行有意义的规范性评估，而是我们应该将这些视为习得的规范性<i>启发法</i>，有助于为有意义的规范性评估提供信息。然后我谈论基于共鸣的“毫无意义的争论”，比如争论是否“支持”或“反对”以色列。</li><li> <strong>2.5 节</strong>讨论了效价如何设定和调整，特别强调先天驱动力（例如，饥饿时吃东西的驱动力）作为效价评估的最终基础。</li><li> <strong>2.6节</strong>讨论了元认知思想和自我反思思想的效价，包括自我和谐倾向和自我失调倾向之间的区别，以及人们在谈论他们的“价值观”时在谈论什么。</li><li><strong>第 2.7 节</strong>简要介绍了道德推理如何融入这个框架，首先是描述性的（当人们进行“道德推理”时，他们在做什么？），然后思考对元伦理学的影响。</li><li> <strong>2.8 节</strong>是一个简短的结论。</li></ul><h1> 2.2 价是现实世界事物的属性的（误导性）直觉</h1><p>回想一下<a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_3_Actor_critic_RL__and__valence_">上一篇文章的第 1.3 节</a>，在我提出的模型中：</p><ul><li>我们大脑的一部分“思考一个想法”，这可能涉及你正在计划、看到、记住、理解、尝试等的事情，并且可能涉及关注某些事情，或调用某些框架/类比等；</li><li> ......我们大脑的另一部分为这个“想法”分配了一个价。</li></ul><p>所以：</p><p><i>从外部来看，</i>价是将“思想”（在特定人的大脑中）映射到标量实数的函数。</p><p><i>从内部来看，</i>思想是我们了解现实世界的唯一窗口。因此，<i>感觉就像</i>效价“附加”到现实世界的事物、情况等上——在<a href="https://www.lesswrong.com/posts/fG3g3764tSubr6xvs/the-meaning-of-right"><u>Eliezer Yudkowsky 令人难忘的类比</u></a>中，感觉就像“一个额外的、物理的、本体论的基本属性，像一个小小的 XML 标签一样挂在事件上”。我认为直觉是一种知觉错觉，一不小心就会误导你。 （为布尔弗主义<span class="footnote-reference" role="doc-noteref" id="fnreftss4t9kg1lr"><sup><a href="#fntss4t9kg1lr">[1]</a></sup></span>道歉，但我认为这种知觉错觉导致了“道德现实主义”阵营中的一些糟糕的哲学观点。）</p><p>例如，假设我的大脑对涉及月亮的想法赋予了高价。 （用日常用语来说，“我喜欢月亮，它很酷”。）<i>在我看来，</i>酷是真实世界月亮的一个属性。毕竟，每当我看到月亮时，我都会有一种凉爽的感觉。如果没有这种印象，我什至无法<i>想象</i>月亮！这有点像<a href="https://plato.stanford.edu/entries/introspection/notes.html">冰箱的光错觉</a>。但实际上，良好的氛围并不存在于现实世界中，就像 XML 标签一样附加在月球上。唯一发生的事情是我的大脑的价函数已经学会了某种启发式：检查“月亮”概念在我的大脑的世界模型中是否活跃，如果是，则增加该想法的价。</p><h1> 2.3 效价直接对应于有意义的（尽管是快速的）规范性评估的情况：计划、行动和想象的未来的效价</h1><p>经济学家谈论“积极主张与规范主张”；哲学家（继<a href="https://en.wikipedia.org/wiki/Is%E2%80%93ought_problem"><u>休谟</u></a>之后）在“是与应该”的标题下谈论同样的事情。积极陈述是对世界实际情况的事实主张，而规范性评估是对世界应该如何或人们应该做什么的价值判断。</p><p> （我在本节中讨论的“规范性评估”类型是快速“快速”判断，而不是我自豪地认可和支持的经过仔细考虑的评估。但是，我将在下面的第 2.7 节中指出，前者服务于作为后者构建的基础。）</p><p>价与规范性有什么关系？<i>一切！</i>确实，我认为<strong>价是大脑中所有规范性的最终货币</strong>。</p><p>这一主张最终源于<a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_3_Actor_critic_RL__and__valence_">上一篇文章第 1.3 节</a>中讨论的化合价的作用。简单回顾一下，假设一个想法突然出现在我的脑海中——“我要站起来了”。如果这个想法的效价是积极的，那么这个想法就会留在我的脑海里，而且我可能会真的这么做。如果价是负的，那么这个想法就会被抛弃，并被另一种想法所取代，可能是涉及躺在床上的想法。因此，化合价是这一决定的基础。 <a href="https://www.lesswrong.com/posts/MArdnet7pwgALaeKs/why-i-m-not-into-the-free-energy-principle"><u>与奇怪的“主动推理”想法相反，</u></a>效价的作用与我的生成世界模型预测未来的能力无关：我的世界模型（“思想生成器”）同样能够对未来世界进行建模在我起床的地方，在我不起床的地方建模未来世界。因此，价在这里的作用从根本上来说是规范性的，而不是积极的。 </p><figure class="image image_resized" style="width:96.04%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/kvbsca3qzufottbjnuru" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/tvjcjuhqeligwiu2obq6 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/c1kdnq0pxqsagk2m5rok 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/zn7twrpzxsbg9bdr62cu 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/zis6gshldc6861okqml3 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/rejdls6mhkdbmxf7i2gt 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/kkc5yjuj6o994sdfhvxx 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/utsksmhinro6q11mpkk4 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/wlg6tgyxnjp5s6w4wgmn 1280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/yggov0gaxmy85t6a3o5a 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/hnjfopmtcdhb7nuperoz 1530w"><figcaption>图表大部分是从<a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction">上一篇文章</a>中复制的，其中红色部分是新的。如果“我要站起来”的想法突然出现在我的脑海中，效价就扮演着“规范”控制信号（向上的黑色箭头）的角色，它决定了这个想法是留在我的脑海中并被执行，还是被扔掉并被抛弃。取而代之的是一个不同的想法，比如“……或者实际上我可能会留在床上”。与此同时，绿色箭头发挥了思想生成器用来构建预测/生成世界模型的输入数据的“积极”作用。</figcaption></figure><p>这是一个简单的案例，但却具有普遍性。所以：</p><ul><li>假设我有一个<strong>与执行计划或采取行动</strong>的想法相对应的想法。如果这个想法的效价是积极的，那么我就有责任执行它。如果这个想法的效价是负面的，那么我就不太可能这样做。因此，在这种情况下，<strong>思想的效价对应于我的大脑对该计划或行动的适当性做出快速的规范性评估</strong>。</li><li>假设我有一个<strong>与未来可能的情况</strong>相对应的想法，例如我想象某个候选人赢得选举，或者我想象自己晚餐吃三明治。如果这个想法的效价是积极的，那么我会倾向于制定并执行实现那个未来的计划。如果这种想法的效价是负面的，那么我会倾向于制定并执行<i>阻止</i>未来发生的计划。因此，在这种情况下，<strong>思想的效价对应于我的大脑对这种可能的未来的好坏做出快速的规范性评估</strong>。</li></ul><h2> 2.3.1 更多关于希望或不希望未来情况发生的信息</h2><p>关于“未来可能出现的情况”的第二个要点掩盖了一些值得详细阐述的细节。</p><p><strong>正价案例的详细说明：</strong>考虑这样的情况：我想象自己晚餐吃三明治，这个想法就是正价。今晚我怎么可能（可能）真正吃三明治？两步：</p><ul><li><i>第一步：</i>我可能会想到一个涉及具体行动方案的想法，预计会导致我吃三明治，也许“我要走到索尔那里吃三明治”。这是一个与以前不同的想法，更加具体和可操作，但这种想法<i>也</i>可能是正价的，因为它涉及/与“我晚餐吃三明治的想法”重叠。 （参见下文第 2.4.1 节。）</li><li><i>第 2 步：</i>好的，现在我脑子里有一个具体的行动方案想法（“我要步行到 Saul&#39;s 并在那里吃三明治”），并且它具有正价。这意味着我可能会真正执行该行动方案——我可能会收缩肌肉，站起来，然后开始走向索尔家。</li></ul><p><strong>对负价情况的阐述：</strong>接下来，考虑这样的情况：我想象一些可能的未来情况，并且该想法是<i>负</i>价。</p><p>我在上面写道：“我会倾向于制定并执行计划，以<i>防止</i>这种未来的发生。”但精明的读者可能会想：等一下。我真的会吗？我更有可能<i>完全不再考虑这种可能性</i>吗？这不是价信号的作用吗？</p><p>这是一个很好的问题！事实上，我认为这种反对意见有很多道理，这让我们陷入了这样一种普遍趋势，即在思考为什么自己充满希望的计划可能会失败时投资不足，以及“ <a href="https://medium.com/@robertwiblin/ugh-fields-or-why-you-can-t-even-bear-to-think-about-that-task-5941837dac62"><u>糟糕的领域</u></a>”等等。下一篇文章将详细介绍该主题，尤其是第 3.3.3 节。</p><p>作为可能发生的情况的一个例子，请注意，“避免未来可能发生的<i>糟糕</i>情况 X”有时可以在心理上重新构建为“寻求可能的<i>良好</i>未来情况，而不是 X”——例如，如果您因以下想法而<i>失去</i>动力如果你的敌人赢得了战争，那么你可能同时被敌人被击败的想法所<i>激励</i>。所以也许你会切换到后一种心理框架，让你可以集思广益，而不会立即被负价推走。</p><h2> 2.3.2 更多关于“快速”评估与深思熟虑的评估</h2><p>正如<a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_5_1__Valence___as_I_m_using_the_term__is_a_property_of_a_thought_not_a_situation__nor_activity__nor_course_of_action__etc_">上一篇文章的 §1.5.1</a>中所讨论的，单个计划、行动或未来可能的情况完全有可能具有不同的价，具体取决于我的想法（我关注哪些方面等）。回想一下我之前的例子： <i>“我会去健身房，从而实现我的新年决心”</i>与<i>“我会去又吵又冷又臭的健身房”</i> 。</p><p>所以当我说“快速规范评估”时，“快速”正在发挥重要作用。这与我们在积极领域进行“快速”评估的方式非常相似：</p><ul><li><i>正域（不直接涉及价）：</i>如果我想象一种可能性，我会立即直觉地“突然”感觉到这种可能性是否可能/合理。但我还是可以多想一想，改变主意。</li><li><i>规范域（直接涉及价）：</i>如果我想象一种可能性，我会立即直观地“突然”感觉到这种可能性是好还是坏。但我还是可以多想一想，改变主意。</li></ul><p>在这两种情况下，我都声称“多考虑一下”过程与第一次快速评估并<i>没有</i>本质上的不同。只是想更多的想法，而这些后续想法都伴随着他们自己对合理性和可取性的快速评估。</p><h1> 2.4 概念的效价</h1><p>现在让我们考虑一个不同的情况：假设我想到一个<strong>概念，例如哈马斯、资本主义或超级英雄电影</strong>。这是我的大脑可以思考的事情，所以就像任何想法一样，我的大脑会给它分配一个价。</p><p>如果价是正的，也许我会心想“哈马斯是好的”；如果是否定的，“哈马斯是坏的”。</p><p>这个主题是<a href="https://slatestarcodex.com/2014/11/04/ethnic-tension-and-meaningless-arguments/"><u>Scott Alexander 2014 年经典博客文章“种族紧张和毫无意义的争论”</u></a>的主题。但在我们开始之前……</p><h2> 2.4.1 旁注：价作为组合思想的（大致）线性函数</h2><p>作为一个简单且不太不切实际的模型，我建议我们应该将“思想”视为<i>组合的</i>（即基本上由许多相互关联的小片段组成），并且价值函数对这些思想片段是<i>线性相加的</i>。因此，如果一个想法需要想象一只泰迪熊在你的床上，那么这个想法的效价将是你的大脑对“这只特定的泰迪熊”的效价和你的大脑对“一般的泰迪熊”的效价的某种加权平均值，并且你的大脑对“我床上的东西”的效价，以及你的大脑对“模糊的东西”的效价等，权重/细节取决于你如何思考它（例如你正在关注哪些方面，什么）您在脑海中调用的类别/类比等）。</p><p>我为什么要提出这个？好吧，我想谈谈我的大脑赋予概念的效价。例如，“月亮”是你心理世界中的一个概念。它通常是一个更大的想法的<i>一部分</i>，但它本身很少是一个完整的想法。经验丰富的冥想者也许可以将他们的注意力集中在月亮的想法上，但这不是典型的情况！</p><p>在线性模型中，这很好——“月亮”仍然有价。如果这个价态非常正，那么与月亮密切相关的想法，比如“我现在正在看月亮”和“有一天我会参观月球”，大概也会以正价结束。</p><h3> 2.4.1.1 线性的（明显）反例</h3><p>精明的读者现在正在向我尖叫。这是一个为亲以色列读者量身定制的（明显的）反例（其他人可以将“以色列”一词替换为“哈马斯”，或选择任何其他例子）：</p><p>为了思考“我将与哈马斯作战”的想法，你的大脑需要以某种方式激活“哈马斯”的概念；但你<i>越不</i>喜欢哈马斯，你<i>就越</i>喜欢对抗哈马斯的想法。这似乎与线性模型明显矛盾。</p><p>在这种情况下，我想说（对于那些亲以色列的读者）“<i>哈马斯作为我义愤填膺的对象</i>”是一个高度激励/正价的概念——即使普通的“哈马斯”概念是消极的/消极的——价。</p><p>或者，您可以通过使用从句和类似的语法结构轻松生成任意多个（明显的）线性反例：如果您被 X 的想法[激励/消极]，那么您将被这个想法[消极/激励] “X即将结束”、“X是假的”、“我反对X”、“我讨厌的外群体真的很喜欢X”，等等。同样，你的大脑在思考这个想法的过程中可能会激活概念 X，但相对于线性模型，对价的贡献是错误的。</p><p>所有这些案例到底发生了什么？长话短说，我<i>确实</i>坚持我的观点，即价是“概念”的（大致）线性函数。但我也认为“概念”可能比我想象的要复杂和微妙得多。</p><p>这就是我要说的关于这个话题的全部内容。我真的不知道这些血淋淋的细节，如果我知道，我绝对不会发布它们，因为我认为这些细节对于构建通用人工智能（AGI）非常有帮助，但对于确保此类 AGI 的安全只有微乎其微的帮助和有益的。有关“信息危害”的更多讨论请参见<a href="https://www.lesswrong.com/posts/MCWGCyz2mjtRoWiyP/endgame-safety-for-agi"><u>此处</u></a>。</p><h2> 2.4.2 概念的效价不能被解释为有意义的规范性评估</h2><p>我在这里引用<a href="https://slatestarcodex.com/2014/11/04/ethnic-tension-and-meaningless-arguments/"><u>斯科特·亚历山大的</u></a>话：</p><blockquote><p>当一切都按照哲学教科书上应该的方式进行时，争论应该以以下几种方式之一进行：</p><p> 1. 经验事实问题，例如“地球正在变暖吗？”或“外星人建造了金字塔吗？”。你可以通过提供事实证据来辩论这些问题，例如“全球气象站测量结果的平均值显示 2014 年是有记录以来最热的一年”或“吉萨的一块砖块底部写着‘Tau Ceti V 制造’”。然后人们试图反驳这些事实或提出自己的事实。</p><p> 2.道德问题，例如“堕胎是错误的吗？”或“您是否应该避免下载未付费的音乐？”只有当你们已经就道德框架达成一致时，比如特定版本的自然法或后果论，你才能<i>很好地</i>辩论这些问题。但你可以通过与商定的道德问题的例子进行比较并试图保持一致性来对它们<i>进行</i>辩论。例如，“你不会杀死一天大的婴儿，那么九个月大的胎儿有什么不同呢？”或“你不会下载<i>汽车</i>。”</p><p>如果你很幸运，你的哲学教科书也会承认以下内容的存在：</p><p> 3.政策问题，例如“我们应该提高最低工资”或“我们应该轰炸外国人”。这些是相互竞争的事实主张和相互竞争的价值观的组合。例如，最低工资可能取决于“提高最低工资会增加失业率”或“现在靠最低工资生活很困难，许多贫困家庭买不起食物”等事实主张。但它也可能取决于诸如“企业有义务为工人支付生活工资”或“保护最贫困人口比经济强劲更重要”等价值主张。轰炸外国主义者可能依赖于诸如“外国主义者窝藏恐怖分子”之类的事实主张，以及诸如“我们人民的安全值得冒附带损害的风险”之类的价值主张。如果您能够解决所有这些事实和价值主张，您应该能够就保单问题达成一致。 ……</p><p>问：你支持以色列还是支持巴勒斯坦？花点时间，认真思考一下。</p><p>有些人可能会回答亲以色列。其他人可能会回答支持巴勒斯坦。其他人可能会说他们是中立的，因为这是一个复杂的问题，双方都有好的观点。</p><p>大概很少人回答：<i>嗯？什么？</i></p><p>这个问题不属于哲学 101 三种论证形式中的任何一种。这不是事实问题。这不是特定道德真理的问题。这甚至不是政策问题。还有密切相关的政策，例如巴勒斯坦是否应该获得独立。但如果我支持一个非常具体的两国解决方案，其中边界是在平行的东西上划定的，这会让我支持以色列还是支持巴勒斯坦？所考虑的解决方案到底在哪条边界线上从亲以色列转向亲巴勒斯坦？你认为那些高喊“声援巴勒斯坦”、挥舞标语的人群能回答这个问题吗？ ……</p></blockquote><p> （如果我们从政治转向日常生活，“政策”类别概括为“具体计划和行动”。例如，关于“我们应该去酒吧”的分歧可能涉及“酒吧会拥挤吗？”等事实主张。 ”，以及诸如“跳过合唱团练习是不是很粗鲁？”之类的价值主张。）</p><p>好吧，如果亲以色列或反以色列的态度并不代表有意义的规范性评估，那么它代表什么<i>呢</i>？</p><h2> 2.4.3 概念的效价实际上是一种习得的规范启发式</h2><p>“启发式”是一种用于近似某事物的快速算法。回想一下上面第 2.3 节中肯定性与规范性的区别。许多启发式，例如<a href="https://en.wikipedia.org/wiki/Representativeness_heuristic"><u>代表性启发式</u></a>，可以被称为“积极启发式”，因为它们是用于找出“积极”事物（例如事实预测）的启发式。其他启发法可能被称为“规范启发法”，因为它们是生成（有意义的）规范评估的启发法。</p><p>我认为，如果你的大脑为“以色列”这样的概念分配了一个价，那么它就对应于一种规范启发式——更具体地说，是一种<i>习得的</i>规范启发式，即你的大脑从一生的经历中获得的规范启发式。</p><p>继续以色列的例子，将概念价转换为其相应的规范启发式的方法是：</p><blockquote><p> “‘以色列’这个概念在我心中具有正价”对应于以下启发式，让您的大脑生成快速规范评估：</p><ul><li><i>可能的行动或计划</i>涉及以色列/与以色列的模式匹配越多，执行该行动或计划就越有可能是我想做的事情；</li><li><i>未来世界的可能状态</i>越多地涉及以色列/与以色列的模式匹配，这种世界状态就越有可能是我想要尝试实现的。</li></ul><p> （对于负价则相反）。</p></blockquote><p> （正如第 2.4.1.1 节中所讨论的，“涉及以色列/与以色列进行模式匹配”短语掩盖了<i>一堆</i>复杂性！）</p><p>因此，如上所述，这些化合价本身并不是有意义的规范性评估，这仍然是事实。但它们<i>只是</i>有意义的规范评估的<i>上游</i>。</p><h2> 2.4.4 理解基于共鸣的“无意义的争论”</h2><p>鉴于上述情况，我们现在可以进入我上面摘录的<a href="https://slatestarcodex.com/2014/11/04/ethnic-tension-and-meaningless-arguments/"><u>“种族紧张和毫无意义的争论”博客文章的</u></a>下一部分：</p><blockquote><p>这是《种族紧张局势：两个玩家的游戏》。</p><p>选择一个模糊的概念。 “以色列”目前表现不错。</p><p>玩家 1 试图将“以色列”这个概念与尽可能多的善业联系起来。概念通过做良好的道德事情、通过与好人交往、通过与心爱的群体联系、通过<a href="https://slatestarcodex.com/2013/05/18/against-bravery-debates/"><u>在勇敢的辩论中</u></a>受到压迫的弱者来获得良好的业力。</p><p> “以色列是中东最自由、最民主的国家。它是美国最强大的盟友之一，与我们有着共同的犹太基督教价值观。</p><p>玩家 2 试图将“以色列”这个概念与尽可能多的恶业联系起来。概念通过犯下暴行、与坏人有联系、与可憎的外群体有联系、在勇敢辩论中成为压迫性的大人物而获得恶业。此外，她显然需要通过反驳她的所有论点来抵消玩家 1 的行为。</p><p> “以色列可能为其最享有特权的公民提供一定程度的自由，但被占领土上数百万没有发言权的人呢？以色列参与了各种暴行，并经常杀害无辜抗议者。他们本质上是一个新殖民主义国家，并与南非等其他新殖民主义国家结盟。”</p><p>赢得这场游戏的奖励是能够赢得其他三种类型的争论（即关于事实、道德和政策的争论）。</p></blockquote><p>我认为，鉴于上一节“习得的规范启发法”，此类论证更有意义。</p><p>具体来说，玩家 1 和玩家 2 正在争论以下规范启发式的适当性：</p><p><i><u>争议中拟议的启发式：</u> “可能的行动或计划涉及/与“以色列”的模式匹配越多，执行该行动或计划就越有可能是我想做的事情。同样，未来可能的世界状态越多地涉及/与“以色列”的模式匹配，这种世界状态就越有可能是我想要尝试实现的。</i></p><p> （再次参见第 2.4.1.1 节中的注意事项）</p><p>玩家 1 促使听众思考上述启发式方法非常有效的许多想法，即它给出的答案与听众大脑中已有的所有其他规范启发式一致。这会刺激听众的大脑比以前更加依赖这种启发式方法。</p><p>相反，玩家 2 会促使听众思考上述启发式方法效果极差的想法，即它给出的答案与听众大脑中已有的所有其他规范启发式完全相反。这会刺激听众的大脑比以前更少地依赖启发式，甚至开始依赖完全相反的启发式（也称为负价）。</p><p> （此过程的更多机制细节参见下面的 §2.5。）</p><h2> 2.4.5 我们是否应该“反”一般的规范启发法？</h2><p>我经常很恼火地看到人们争论是否支持资本主义与反资本主义、支持宗教与反宗教等等，好像这些是有意义的争论，但其实并非如此。</p><p> （有趣的是，我有一个朋友，我们两个人倾向于在经济政策的<i>具体</i>问题上达成一致。然而，我们在氛围上存在强烈分歧——“资本主义”这个概念在他们的大脑中具有强烈的负面氛围，而在我的大脑中则有积极的氛围）基本上，我们的共鸣分歧大部分被关于什么是或不是“资本主义”的平等和相反的分歧所抵消！）</p><p>这类毫无意义的争论有时是明确的，但更多时候它们隐藏在表面之下，争论在物体层面和共鸣层面同时发生。</p><p>例如，如果有人认为他们只是“得了一分”，那么这个事实经常会出现在他们的言语中，即使他们没有站出来明确宣布“将死，无神论者！”在这些情况下，值得询问他们认为自己得分<i>的具体是什么</i>，因为也许那件事一开始就不是分歧的主题。</p><p> （不用说，这对自己来说是双重的：照照镜子，问问<i>你</i>在争论什么具体的事情！）</p><p> （“得分”态度首先是有问题的——请参阅<a href="https://www.amazon.com/Scout-Mindset-Perils-Defensive-Thinking/dp/0735217556"><i><u>《童子军心态》</u></i></a> ——但争论一个非常具体、具体、相互理解的事情是最不坏的版本。）</p><p>当我们的大脑为大而模糊的事物分配价时，规范启发法尤其成问题。例如， <i>“涉及/与‘宗教’模式匹配的东西”</i>是一个极其异构的集合——从古代神道仪式到我曾经在梵蒂冈礼品店购买的以教皇为主题的旅游饰品。经过反思后，这个集合中的所有内容都是好还是坏的可能性有多大？相当低。 （参见<a href="https://www.lesswrong.com/tag/bucket-errors"><u>“桶错误”</u></a> 。）因此，如果我们对“宗教”给予强烈的评价，无论是积极的还是消极的，我们都会遇到以下两个问题之一：</p><ul><li>我们会对特定的宗教相关事物做出不好的规范性评估（“不好”是指，如果我们更仔细地思考这个问题，我们就会改变主意）；</li><li> ……或者我们最终会对“宗教”概念进行不公正的划分，以符合我们认可的规范性评估。 （例如，有人可能会说“宗教当然是[好/坏]；但是某某[坏/好]的东西并不是<i>真正的</i>宗教。”）</li></ul><p>我认为后者对于清晰的思维非常有害。拥有<i>一些</i>明确涉及规范性评估的概念（“优选”、“有问题的”、“麻烦”、“蓬勃发展”等——请参阅<a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_4_Terms_closely_related_to__valence_">上一篇文章</a>或<a href="https://arbital.com/p/value_laden/"><u>相关仲裁帖子</u></a>中的§1.4）是很好的，因为毕竟规范性评估是我们经常想谈论的事情。但我们<i>也</i>迫切需要能够描述世界如何独立于我们的感受而运作的概念。我将在下一篇文章的第 3.4 节中详细讨论这个主题。</p><p>话虽如此，我们不能总体上“反”规范启发法，因为如果我们把它们拿走，那就什么都没有剩下了！毕竟，大脑需要<i>某种</i>方式来评估计划/行动/未来的好坏，包括我们以前从未遇到过的计划/行动/未来。</p><p>所以实际上，我认为给概念赋予价是可以的，甚至给比较宽泛的概念赋予相当强的价在某种程度上也是可以的。我自己的大脑似乎至少为一些相当广泛的概念分配了一些非零价，例如“共产主义”（嘘）、“贫困”（嘘）、“人工智能对齐”（耶）、“冰淇淋”（耶）和等等，我目前认为我不应该太努力地改变这一点。重要的是<i>养成提出后续问题的习惯，这些问题侧重于细节并探究一般规则的例外情况</i>。</p><p>例如，问问自己：确切的建议是什么？它可能产生哪些有意或无意的后果？当我们说“共产主义”时，我们是在谈论“斯大林的共产主义”还是“邓小平的共产主义”还是“狩猎采集小部落的共产主义”？当我们说“冰淇淋”时，我们是在谈论“哈根达斯冰淇淋”还是“海绵宝宝冰棒冰淇淋”？当我们说“AI 对齐”时，我们是在谈论“我定义的 AI 对齐”还是“Sam Altman 定义的 AI 对齐”？ ETC。</p><p>如果<i>具体细节</i>在你的脑海中很突出，那么，我声称，相应的规范启发法更有可能给出良好的评估，经得起审查和事后诸葛亮。</p><p> （顺便说一句，如果你养成这种习惯，<i>随着时间的</i>推移，它可能会导致为模糊的广泛概念分配更中性的效价，为更具体的特征分配更强的效价。这可能是一件好事。）</p><h1> 2.5 化合价如何设定和调整？ </h1><figure class="image image_resized" style="width:67.18%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/jszcdax7vbhbxebhlau4" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/rdxaoi3kfhm2tiase154 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/o8znjxkggojkxgvvtjlf 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/kvibz9spxvn4gz3maoqb 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/eld6v5v4fypxs0bqcaj2 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/lqz98ny7ffp9uhqwgfbt 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/frghxaaqbnc8xxwt7joc 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/s1uubt4yekrh91tiaxro 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/pkxccpamapexa8elztd7 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/w6cksg1dlrxa9lcemytv 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/stsl40xxhye7ovycuvls 955w"><figcaption>我声称效价最终来自于先天驱动力，然后通过诸如时间差异（TD）学习之类的东西在不同的概念（思想片段）之间传播。举第一个例子，如果我的手在接触炉子时被烫伤，那么一种与生俱来的驱动力就会介入，并表示有不好的事情发生了，然后触摸炉子的想法就会获得负价。作为第二个例子，考虑<a href="https://medium.com/@robertwiblin/ugh-fields-or-why-you-can-t-even-bear-to-think-about-that-task-5941837dac62"><u>“呃字段”</u></a> ——如果我经常对自己想“我要清理我的电子邮件收件箱”，并且这总是立即产生高度厌恶的后续想法“......这意味着我需要处理来自内德的烦人的电子邮件”，那么“我要清理我的电子邮件收件箱”的想法<i>本身</i>就会变得有些厌恶（负价），即使我没有明确地提醒我记住来自内德的烦人的电子邮件。</figcaption></figure><p>如果你追溯到足够远的地方，我声称<strong>所有效价最终都直接或间接地来自先天驱动力</strong>——基因特定的电路，宣布疼痛是坏的，饥饿时吃东西是好的，并驱动社会地位（即将在第 4 篇文章中出现），以及与同情心、复仇和内疚等相关的各种其他社会动力，可能还有数百个类似的事情。</p><p> （在强化学习术语中——参见<a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_3_Actor_critic_RL__and__valence_">上一篇文章的第 1.3 节</a>——你的“先天驱动力”或多或少对应于有助于奖励功能的各种术语。用神经解剖学术语来说， <a href="https://www.lesswrong.com/posts/hE56gYi5d68uux9oM/intro-to-brain-like-agi-safety-3-two-subsystems-learning-and"><u>我声称</u></a>实现这些先天驱动力构成了下丘脑和脑干，尽管其他大脑区域也参与其中。）</p><p>稍微简单地说，我认为一个想法可以是正价或负价有两个主要原因：</p><ul><li>一个想法可以是正价或负价的<strong>第一个原因</strong>是，一种内在的驱动力正在介入并立即宣布该想法是好还是坏。 （例如，如果我饿了并且开始吃美味的食物，那么无论我当时在想什么——大概是食物——显然都是一件好事。）</li><li>一个想法可以是正价或负价的<strong>第二个原因</strong>是，我们的大脑有一个<i>学习算法</i>，可以根据实际价分配的过去历史来猜测什么价分配最适合一个想法。当先天的驱动力没有<a href="https://www.lesswrong.com/s/HzcM2dkCq7fwXBej8/p/F759WQ8iKjqBncDki#5_2_Toy_model_of_a__long_term_predictor__circuit"><u>“压倒”这种猜测</u></a>时，这种猜测就会变成一种自我实现的预言。 （学习算法与<a href="https://en.wikipedia.org/wiki/Temporal_difference_learning"><u>时间差异（TD）学习</u></a>有一定关系；我将保留所有细节，但请参阅<a href="https://www.lesswrong.com/s/HzcM2dkCq7fwXBej8/p/F759WQ8iKjqBncDki#5_3_1_Switch__i_e___value___expected_next_reward__vs_summation__i_e___value___expected_sum_of_future_rewards__"><u>此处</u></a>了解更多信息。）</li></ul><p>抛开所有机制细节不谈，这种学习算法具有多种效果，例如：</p><ul><li>如果思想 θ 在您之前的所有思考中都具有一定的价态，那么学习算法将开始猜测 θ（以及与 θ 足够相似的思想）将来将具有相同的价态。</li><li>如果X（例如打开Twitter）经常立即导致Y（例如看到“喜欢”通知），即作为现实世界中的时间序列，那么学习算法将开始猜测X的适当价数更接近于任何值化合价恰好是 Y。</li><li>同样，如果想法 X 通常会立即在您的大脑中引发想法 Y，那么请与上一个要点相同。 （换句话说，TD学习的“时间”部分可以完全在你大脑的思维范围内，与外界的时间序列无关。）</li></ul><p>为了避免可能的误解：先天驱动力与目标或最终目标不同。你的目标，例如“摆脱债务”或“减少痛苦”，是根据你的世界模型（又名<a href="https://www.lesswrong.com/posts/qNZSBqLEh4qLRqgWW/intro-to-brain-like-agi-safety-6-big-picture-of-motivation"><u>“思想发生器”</u></a> ）中的概念构建的——你在一生中学到的概念。与生俱来的驱动力并非如此，相反，它们是由基因组构建的小机器，在某些情况下会发出某些信号。我有时会谈论“避免疼痛的本能驱动力”或类似的东西，但这实际上是更迂腐的“电路的简写，该电路检测与我们通常所说的“疼痛”相关的外围信号，然后吐出负价（以及其他信号），因此随着时间的推移，该电路的典型效果是让我们想要避免疼痛”。</p><h2> 2.5.1 特殊情况：在一起的事物往往会获得相似的化合价</h2><p>在<a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_5_1__Valence___as_I_m_using_the_term__is_a_property_of_a_thought_not_a_situation__nor_activity__nor_course_of_action__etc_">上一篇文章的第 1.5.1 节</a>中，我举了一个关于去健身房“心情复杂”的例子。如果我关注它的一个方面，它就会具有积极的价值（“我要去健身房，从而实现我的新年决心”）。如果我注意它的另一个方面，它具有负价（“我要去健身房，那里真的又吵又冷”）。</p><p>可能我最终会在一两秒内连续地在这两个帧之间来回进行大量的心理翻转。换句话说，当我思考积极的方面时，也许它会唤起我的记忆，唤起消极的方面，反之亦然。如果是这样，我认为 TD 学习将倾向于更新我的价函数，使正价方面变得更加消极，反之亦然（根据上面的第三个要点）。具体来说，也许执行我的新年决心的想法会开始感觉有点不那么激励和更令人厌恶，相反，也许想到健身房的响亮和寒冷会开始感觉<i>不那么</i>令人厌恶。 <span class="footnote-reference" role="doc-noteref" id="fnref6q9syee1mov"><sup><a href="#fn6q9syee1mov">[2]</a></sup></span></p><h1> 2.6 元认知和自我反思思想的效价：自我和谐与反张力的思想、公开的“价值观”等。 </h1><figure class="image image_resized" style="width:24.51%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/tz2aw0v6l0ei9pwnwnz4" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/mofolnogceg3ar9d7u8p 115w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/xnxqdmknjlugrtvr7wge 195w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/gk8llgybcvjpjzyng91k 275w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/ryolrrtufvajtuceshqi 355w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/xdon4zacamsmpzahxjxi 435w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/qxwq1byfvsee3tji0joz 515w"></figure><p>假设我对香烟上瘾，但想戒掉。鉴于我对香烟上瘾，有时“现在吸烟的想法”将是非常正价的——换句话说，“有时我感到有吸烟的冲动”——因此我会抽烟。</p><p>但这很烦人！我本来想放弃的！因为我不是一个彻底的白痴，所以我自然会注意到一个明显的事实：“我想吸烟”是一个阻碍我实现戒烟动机的障碍。这让我不喜欢“冲动我想吸烟”。</p><p>现在我们已经进入了自我反思偏好的领域！</p><p>因此，“吸烟有时对我来说是正价的想法”最终在我的脑海中产生了<i>它自己的</i>价评估，而这个价是强烈的负值。这将是<i><strong>自我张力失调</strong></i><strong>效价评估</strong>的一个例子。我想抽烟，但又<i>不想</i>抽烟。</p><p>现在，再次假设一个想法突然出现在我的脑海中：“也许我现在就去抽烟”。如果这个想法需要注意预期的感官知觉等，那么这个想法的效价将是积极的，所以我会吸烟。如果这个想法主要是忽略这些，而是​​关注情况中更多的自我反思方面——也许，好像从外部看待自己——那么这个想法的效价将是负面的，所以我不会吸烟。实际上，两种类型的想法可能会在不同的时间突然出现在我的脑海中，而效价的相对强度将有助于确定事情如何发展。</p><p>自我失调的反义词是<strong>自我和谐</strong>。例如，“我自己倾向于诚实和尽责”的想法就是自我和谐的。因此，如果一个计划的模式与我认为自己是诚实和认真的相匹配，那么该计划就会获得效价提升，所以我更有可能这样做。但只是<i>在边缘</i>。该计划还有其他方面，这些方面也有助于提高效价，事实上，这些其他方面往往更为突出。</p><p>这里的一个重要观察是，<i><strong>所宣称的</strong></i><strong>目标和价值观，而不是行动，往往不成比例地取决于事物是自我和谐还是失调。</strong>考虑一下：如果我大声（或对自己）说某件事（例如“我要戒烟”或“我关心我的家人”），我脑海中实际立即想到的主要是“我要执行此操作”特定言语行为”。正是<i>这种</i>想法的效价决定了我们是否会说出这些话。这种想法的自我反思方面非常突出，因为说话需要思考听众会如何接受你的话。相比之下，该公告的<i>内容</i>——真正戒烟，或者真正关心我的家人——既不那么显着，也不那么直接，发生在某个不确定的未来（参见<a href="https://en.wikipedia.org/wiki/Time_preference"><u>时间折扣</u></a>）。因此，言语行为的净效价可能包含来自戒烟的自我反思方面的<i>较大</i>效价贡献，以及来自戒烟或关心家人的更直接的感官和其他后果的<i>较小</i>效价贡献。<i>即使</i>我们百分百真诚地履行我们所说的话，情况也是如此。 （另请参阅博客文章<a href="https://www.lesswrong.com/posts/yDRX2fdkm3HqfTpav/approving-reinforces-low-effort-behaviors"><u>“批准强化省力行为”</u></a> ，其观点与本段类似。） </p><figure class="image image_resized" style="width:73.71%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/rcvfrjif77p3aam2aw6c" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/kqpsl8ljw1xjkggyp3tu 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/myrfhtlsewfnonpmlljq 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/nnta32ypxvzvhic2uy14 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/wy70orgjcuigufl8noxn 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/xenavi7epj1nps9hnji5 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/zjwci8fwzhzmtkphmrz4 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/xkztuwtxn2lashfztqum 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/n87ivhqtqmwtvlinnjed 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/l0tuyylx95lsytazgsrl 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SqgRtCwueovvwxpDQ/p6x3gfovyynzxfhia9vj 866w"></figure><h2> 2.6.1 什么是“价值观”？</h2><p>我提出这个话题是因为它经常出现在我的职业中（人工智能对齐）。但我不确定它有什么深刻的答案；在我看来，这主要只是关于定义的争论。</p><p>这是我喜欢的“价值观”的定义，因为它似乎与人们在我日常生活中使用这个词的方式一致：<i>如果我想知道某人的“价值观”，我只会问他们，然后写下他们所说的。然后我会声明，无论我写下什么，或多或少都是“他们的价值观”，除了极少数例外，比如他们故意恶搞我。</i></p><p>根据这个定义，“价值观”很可能包括听起来非常好听、得到社会认可、自我认同的东西，比如“照顾我的家人和朋友”、“让世界变得更美好”等等。 。</p><p>同样根据这个定义，“价值观”对某人的行为可能产生的影响微乎其微。在这种（极其常见）的情况下，我会说“我猜这个人的<i>愿望</i>与他的<i>价值观</i>不同……”。哦，好吧，这并不奇怪。”</p><p>事实上，我认为对于一个“价值观”包括“成为好朋友”的人来说，实际上成为一个坏朋友是完全正常的。那么这个“价值”有什么含义吗？是的！！我预计，在这种情况下，这个人<i>要么</i>会对自己是一个坏朋友这一事实感到难过<i>，要么</i>否认自己是一个坏朋友，<i>要么</i>根本不考虑这个问题，<i>要么</i>想出其他一些办法。为他们的行为找借口。如果这些事情都没有发生，那么（只有那时）我才会说“成为一个好朋友”实际上<i>并不是</i>他们的“价值观”之一，如果他们另有说法，那么他们就是在撒谎或困惑。</p><h1> 2.7 道德推理</h1><h2>2.7.1 描述性帐户</h2><p>如上所述，我认为积极与规范的区别与大脑的大规模解剖结构和算法的主要组成部分有着非常明确的对应关系。</p><p>然而，<i>在规范领域内</i>，我认为<i>“X是道德/伦理/美德/等等要做的事情”</i>和<i>“我想做X”</i>之间的区别并不是太根本——它更像是模糊学习类别之间的界限。例如，当事物与自我和谐且得到社会认可时，人们倾向于将其称为道德/伦理/美德。但该规则也有例外。例如，黑手党可能会为自己的“不道德”感到自豪。即使在这种情况下，黑手党可能仍在弄清楚在他自己的犯罪社会利基中什么是自我和谐的和社会认可的，他的思维甚至可能在结构上类似于“正常”的道德推理。但他不会使用“道德”这个词。</p><p>无论如何，假设您是一个正常的守法人，真诚地希望按照道德行事。所以你坐在扶手椅上，试着弄清楚什么是道德的事情。接下来发生什么？很多东西：</p><ul><li>也许您会考虑对象层面的事情，就像您想象一个孩子正在受苦一样。也许这些想法是有价值的——也就是说，你发现你对这些事情有偏好。</li><li>也许你会考虑元认知的事情，比如“我会仔细思考，而不是急于做出判断”，或者相反，“我应该更相信自己的直觉”。也许这些想法是有价值的——也就是说，你发现你对这些事情有偏好。</li><li>也许你会思考一些自我反思的事情，比如<a href="https://joecarlsmith.com/2023/02/17/seeing-more-whole"><u>“我在这个世界上是什么样的力量？”</u></a>或者“如果我的朋友现在能读懂我的想法，他们会怎么看我？”。也许这些想法是有价值的——也就是说，你发现你对这些事情有偏好。</li><li>也许您注意到其中一些偏好与其他偏好不一致。然后你会思考更多的想法，这些不同的偏好可能会相互较量。</li><li>在整个过程中，你大脑的学习算法会不断更新你的信念和欲望。</li></ul><p>在本系列的背景下，我想指出的一点是，<strong>每一步都建立在价的基础上。</strong>例如，如果你的大脑没有为孩子受苦的想法赋予特定的效价，那么你就不会有动力去阻止孩子受苦。</p><p>为了更直观：假设我告诉你：“穿带偶数个皮带环的裤子很重要”，然后你说“为什么？”，然后我说“你知道，如果你没有，那么你的裤子会有<i>奇数</i>个皮带环！那会很糟糕！！”，然后你又说“嗯？为什么这么糟糕？”。这场谈话毫无进展。</p><p>相比之下，如果我说“如果你遵循X原则，那么被压迫群众将得到正义”，<i>现在</i>我可以激起你的兴趣，因为“被压迫群众将得到正义”已经作为一种吸引人的（积极的-价）的概念。</p><p>正如上面提到的（§2.5），我想指出的另一个重要观点是<strong>，价最终（尽管通常是非常间接的）源于先天驱动力</strong>。正如第 2.5 节中所述，在你生命中醒着的每一秒，效价都根据你的观察和思路从一个概念流向另一个概念。但如果你追溯得足够远，效价最终必须源自你与生俱来的驱动力。在道德推理的情况下——例如上面“被压迫的群众将得到正义”的例子——我认为所讨论的先天驱动力几乎肯定是先天的<i>社会</i>驱动力，即与同情心、复仇、社会地位相关的先天驱动力（出现在第四篇文章中） ）， 等等。</p><h2> 2.7.2 对“道德的真实本质”的影响（如果有的话）</h2><p>我距离元伦理学专家<i>还很远</i>，但从上述叙述中似乎可以得出以下一些结论。</p><ul><li>如果存在“真正的道德”这样的东西，它<i>完全独立</i>于人类先天驱力和当前模因环境的特殊性，那么就没有任何明显的理由表明上述过程应该收敛于它，或者确实有任何关系用它。如果确实如此，我想我们就不得不宣布这是一个令人高兴的巧合。 （有关这一点的更深入的讨论，请参阅 Joe Carlsmith 的文章<a href="https://joecarlsmith.com/2022/01/17/the-ignorance-of-normative-realism-bot"><u>“规范现实主义机器人的无知”</u></a> 。）</li><li>事实上，没有任何明显的理由表明上述过程应该收敛到<i>任何</i>明确定义的目的地。我<i>不</i>认为这与数学相似。在数学中，如果有一个假设的代理人具有“天生的倾向”来“喜欢”某些数学公理及其逻辑结果，那么对于该代理人会或不会“喜欢”什么，就会有一个独特的答案，只要有足够的时间来反映——即，可以从这些公理证明的数学陈述。相比之下，如果一个人从天生的驱动力开始，并经历上述过程，那么事情就会显得更加混乱。例如，一旦你开始“喜欢”某种元认知模式，它就会改变管理未来审议步骤的基本规则。因此，过程结束的地方很可能存在不确定的路径依赖性。或者它可能最终会围绕各种不太令人满意的状态进行无休止的循环。</li><li>即使上述过程<i>确实</i>收敛到一个独特且明确的目的地，那么它不一定对每个人来说都是相同的目的地（并且忘记外星人或人工智能）。事实上，我会更进一步猜测，对于不同的人来说，这可能有重要的不同，不仅是在反社会人格者等不寻常的情况下，而且在整个人群中也是如此。 （例如，我认为 <a href="https://www.lesswrong.com/posts/BkkwXtaTf5LvbA6HB/moral-error-and-moral-disagreement"><u>这篇文章</u></a>的结尾过于乐观。）我认为的原因是：目的地<i>肯定</i>取决于正在深思熟虑的人的天生驱动力，也<i>可能</i>取决于他们的生活史，尤其是模因环境。让我们关注第一个——先天驱动力。我承认几乎所有人类都有<i>本质上</i>相似的先天驱动力——也就是说，他们的构造方式是相同的。但我认为它们在<i>数量上</i>并不相似。特别是，各种不同的先天驱动力的相对强度似乎因人而异。例如，我认为有些人非常强烈地感受到地位驱动力（在第四篇文章中出现），而其他人则感觉更温和，与同情心、复仇等相关的先天驱动力也是如此。这些相对优势很重要，因为道德充满了不同直觉相互抵消的情况。</li><li>比较一下“我希望被压迫的群众得到正义”和“我站得太久了，我想坐下来”。<i>这两种“想要”从根本上来说是建立在相同的思维基础上的。</i>它们都源自正价，而正价最终又来自先天驱动力（具体来说，第一种情况主要是社会驱动力，第二种情况主要是稳态节能驱动力）。因此，如果“真正的道德”或“真正的人类道德”或其他什么不存在，那么这<i>并不</i>构成坐下来而不寻求正义的理由。你仍然需要做出决定。这就是我所说的<a href="https://www.lesswrong.com/posts/32ca3B7rJ93xo9tvb/thoughts-on-agi-consciousness-sentience#How_does_that_feed_into_morality_"><u>“虚无主义与决策无关”</u></a> ，或者尤德科夫斯基所说的 <a href="https://www.lesswrong.com/posts/iGH7FSrdoCXa5AHGs/what-would-you-do-without-morality"><u>“没有道德你会做什么？”的</u></a>意思。 。事实上，你会注意到我首先讨论了审议过程，然后才是哲学。深思熟虑的过程是由你自己的动机驱动的，无论它们是什么，无论好坏，而不是任何外部规范真理。</li></ul><h2> 2.7.3 对人工智能联盟讨论的可能影响</h2><p>作为一名人工智能一致性研究人员，我可能应该根据当地知识界的想法准确地阐明我所得到的内容。<i>这一部分的可信度较低且行话较多；人工智能对齐领域之外的读者可以随意忽略。</i></p><ul><li>我担心<a href="https://www.lesswrong.com/tag/coherent-extrapolated-volition"><u>CEV</u></a>没有明确定义。或者更具体地说，您可以列出许多<i>同样先验</i>合理的 CEV 详细操作，它们会给出截然不同的结果，而我们会发现非常不满意。</li><li>与此相关的是，我担心“<a href="https://forum.effectivealtruism.org/topics/long-reflection"><u>长反思</u></a>”不会解决我们希望它解决的所有重要问题，或者以一种不可避免地取决于长反思治理/话语规则细节的方式解决它们，而没有确定众多看似合理的治理/话语规则中哪些规则是“正确的”的明显方法。</li><li>当人们做出含蓄地将“未来的价值”视为明确定义的陈述时， <a href="https://www.lesswrong.com/posts/HoQ5Rp7Gs6rebusNP/superintelligent-ai-is-necessary-for-an-amazing-future-but-1"><u>例如</u></a>“我将‘强大的乌托邦’定义为：未来至少 95% 的潜在价值已实现”，我担心这些说法并不像听起来那么有意义。</li><li>我担心几代人以来人类价值观的变化在某种程度上更像是随机游走，而不是随着时间的推移而进步，而且它们只是感觉像随着时间的推移而进步，因为我们<a href="https://willywizz.wordpress.com/2012/09/24/paint-the-target-around-the-arrow/"><u>“围绕着目标绘制目标”箭”</u></a> 。因此，当我们说“永恒的价值锁定是不好的——我们想给我们的后代道德成长的空间！”，同时我们也说一些具体的话，比如“我们想要一个充满友谊、玩耍和感觉的未来——代理和探索，以及很少的痛苦和磨难，而且……！”，那么我担心这两种说法至少有点不一致，甚至可能非常不一致。 （如果事实证明我们必须选择这两种说法中的一种，我不知道我会投票支持哪一种。）</li><li>以上这些都不是我们不应该尝试解决人工智能对齐问题，或者我们不应该关心未来如何发展的论点。与上一小节一样，我们仍然可以而且必须做出决定。我渴望避免未来的宇宙充满酷刑和奴役（举一个特别简单的例子），这一愿望一如既往地强烈，如果你也有同样的愿望，那么让我们共同努力实现这一目标。</li></ul><h1> 2.8 结论</h1><p>再说一遍，我认为效价是大脑中所有规范性的基础物质。希望这篇文章能够阐明这个难题的一些部分。我对想法和讨论持开放态度，在下一篇文章中，我们将讨论价在信念、期望、概念等积极（而不是规范）领域中的较小但仍然重大的影响。</p><p><i>感谢 Tsvi Benson-Tilsen、Seth Herd、Aysja Johnson、Justis Mills、Charlie Steiner、Adele Lopez 和 Garrett Baker 对早期草稿提出的批评意见。</i> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fntss4t9kg1lr"> <span class="footnote-back-link"><sup><strong><a href="#fnreftss4t9kg1lr">^</a></strong></sup></span><div class="footnote-content"><p> “Bulverism”这个术语的意思是“在没有正当理由的情况下假设某些信念是不正确的，然后对人们如何最终持有这些不正确的信念进行心理推测”。然而，请参阅下面的第 2.7 节，了解有关道德现实主义的<i>更多</i>信息。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn6q9syee1mov"> <span class="footnote-back-link"><sup><strong><a href="#fnref6q9syee1mov">^</a></strong></sup></span><div class="footnote-content"><p>在这个例子中——“也许执行我的新年决心的想法会开始让人感觉不那么积极，更令人厌恶，相反，也许想到健身房的喧闹和寒冷会开始感觉<i>不那么</i>令人厌恶” -我实际上认为这种转变可以通过两种方式发生，并且大脑并行执行这两个过程。第一个，如文中所述，涉及通过 TD 学习改变不同思想的效价。第二个，我不会讨论，因为它是题外话，涉及到世界模型（又名“思想生成器”）及其概念网络及其关联/内涵的变化。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/SqgRtCwueovvwxpDQ/valence-series-2-valence-and-normativity#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/SqgRtCwueovvwxpDQ/valence-series-2-valence-and-normativity<guid ispermalink="false"> SqgRtCwueovvwxpDQ</guid><dc:creator><![CDATA[Steven Byrnes]]></dc:creator><pubDate> Thu, 07 Dec 2023 16:43:49 GMT</pubDate> </item><item><title><![CDATA[AISN #27: Defensive Accelerationism, A Retrospective On The OpenAI Board Saga, And A New AI Bill From Senators Thune And Klobuchar]]></title><description><![CDATA[Published on December 7, 2023 3:59 PM GMT<br/><br/><p>欢迎阅读人工智能安全<a href="https://www.safe.ai/">中心的人工智能安全</a>通讯。我们讨论人工智能和人工智能安全的发展。无需技术背景。</p><p> <a href="https://newsletter.safe.ai/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=113135916">在此</a>订阅以接收未来版本。</p><p>在<a href="https://spotify.link/E6lHa1ij2Cb">Spotify 上免费收听 AI 安全新闻通讯。</a></p><hr><h2>防御性加速主义</h2><p>以太坊的创始人 Vitalik Buterin 最近<a href="https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html">写了一篇关于人工智能和其他技术的风险和机遇的文章</a>。他回应了马克·安德森 (Marc Andreessen) 关于技术乐观主义和有效加速主义 (e/acc) 运动发展的宣言，并提供了更细致的观点。</p><p>文章认为，技术往往对人类有好处，但人工智能可能是这一规则的例外。 Buterin 认为，我们不应该让政府控制人工智能来保护我们，而是应该建立防御性技术，为去中心化社会中的灾难性风险提供安全保障。 Buterin 认为我们应该构建网络安全、生物安全、有弹性的物理基础设施和强大的信息生态系统来保护自己免受人工智能风险的一些技术。</p><p><strong>技术有风险，但监管不是万能药。</strong>更长的寿命、更低的贫困率以及扩大接受教育和信息的机会是 Buterin 归功于技术的众多成功之一。但大多数人都会认识到，技术也会造成危害，例如全球变暖。 Buterin 特别<a href="https://twitter.com/VitalikButerin/status/1729251822391447904">表示</a>，与大多数技术不同，人工智能对人类构成了生存威胁。</p><p>为了应对这一风险，一些人主张<a href="https://arxiv.org/abs/2310.09217">政府对人工智能的发展进行强有力的控制</a>。 Buterin 对这个解决方案感到不舒服，他预计许多其他解决方案也会如此。历史上许多最严重的灾难都是由斯大林和毛泽东等强大的政治人物故意造成的。人工智能可以帮助残暴的政权监视和控制大量人口，而 Buterin 对于通过将人工智能开发从私人实验室推向公共实验室来加速这一趋势持谨慎态度。</p><p>在不受限制的技术发展和政府绝对控制的极端之间，Buterin 主张一条新的前进道路。他把他的哲学称为 d/acc，其中“d”代表国防、民主、权力下放或<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4213670">差异化技术发展</a>。</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc365b23e-2340-47ba-8f6b-04cf5e6efa97_500x536.png"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qQvqzFKbfNQovrSQn/caiy1pg3dobqjuc1wsgg" alt="" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qQvqzFKbfNQovrSQn/zm2qw8smimbll3172z6y 424w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qQvqzFKbfNQovrSQn/ci9uhres7aqircceej9n 848w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qQvqzFKbfNQovrSQn/gwdpnppfzrthwzyxb5kq 1272w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qQvqzFKbfNQovrSQn/caiy1pg3dobqjuc1wsgg 1456w"></a></p><p><strong>去中心化世界的防御技术。</strong> Buterin 主张加速技术发展，保护社会免受灾难性风险的影响。具体来说，他强调：</p><ol><li><strong>生物安全</strong>。人口稠密的城市、频繁的航空旅行和现代生物技术都会增加流行病的风险，但我们可以通过改善空气质量、加快疫苗和治疗方法的开发以及监测新出现的病原体来改善我们的生物安全。</li><li><strong>网络安全</strong>。可以编码的人工智能可以用于网络攻击，但防御者也可以使用它们在安全漏洞被利用之前发现并修复它们。 Buterin 在区块链方面的工作旨在实现一些数字系统可以被证明安全的未来。</li><li><strong>有弹性的物理基础设施</strong>。核灾难中预期的大多数死亡并非来自爆炸本身，而是来自食品、能源和其他必需品供应链的中断。埃隆·马斯克渴望改善人类的物质基础设施，减少对化石燃料的依赖，通过卫星提供互联网连接，并理想地使人类成为能够在地球灾难中幸存的多行星物种。</li><li><strong>强大的信息环境</strong>。为了帮助人们在人工智能说服时代找到真相，Buterin 提到了预测市场和共识生成算法，例如<a href="https://vitalik.eth.limo/general/2023/08/16/communitynotes.html">社区笔记</a>。</li></ol><p>科学家和首席执行官可能会发现自己受到 Buterin 构建技术而不是放慢技术发展目标的启发。然而，对于那些担心人工智能和其他灾难性风险的人来说，Buterin 对最有可能保护我们文明安全的技术提出了深思熟虑的看法。有兴趣的朋友可以<a href="https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html">看看全文</a>，还有更多的想法。</p><h2> OpenAI Board 传奇回顾</h2><p>11 月 17 日，OpenAI<a href="https://openai.com/blog/openai-announces-leadership-transition">宣布</a>董事会解除 Sam Altman 首席执行官职务。经过四天的公司政治和谈判，他重新担任首席执行官。在此，我们回顾一下这一系列事件的已知事实。</p><p> <strong>OpenAI 旨在由非营利性董事会控制</strong>。 OpenAI<a href="https://openai.com/blog/introducing-openai">成立</a>于 2015 年，是一家非营利组织。 2019 年，OpenAI<a href="https://openai.com/blog/openai-lp">宣布</a>成立一家营利性公司，为其昂贵的大型语言模型扩展计划提供资金。投资 OpenAI 所能产生的利润最初被“限制”在 100 倍——超出这个范围的任何东西都将被重新定向到非营利组织。但 <a href="https://www.economist.com/business/2023/11/21/inside-openais-weird-governance-structure">最近规则发生变化</a>后，从 2025 年开始，该上限将每年上涨 20%。</p><p> OpenAI 的<a href="https://openai.com/our-structure">公司结构</a>旨在使非营利组织能够保留对营利组织的合法控制权。该非营利组织由董事会领导，董事会通过其选择和罢免营利组织首席执行官的能力对营利组织拥有权力。董事会负责维护非营利组织的使命，即确保通用人工智能造福全人类。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qQvqzFKbfNQovrSQn/bu08tjivlccrh7j1xhau" alt="" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qQvqzFKbfNQovrSQn/ovk1ri8hu5yrbuu47kkn 424w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qQvqzFKbfNQovrSQn/agtx8u8u0jgpytwzxxft 848w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qQvqzFKbfNQovrSQn/ffahdjhdbaimt7uhakes 1272w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qQvqzFKbfNQovrSQn/bu08tjivlccrh7j1xhau 1456w"><figcaption> OpenAI 的法律结构。</figcaption></figure><p><strong>董事会解除萨姆·奥尔特曼 (Sam Altman) 首席执行官职务。</strong>在解除 Sam Altman 首席执行官职务时，董事会成员包括 OpenAI 首席科学家 Ilya Sutskever、Quora 首席执行官 Adam D&#39;Angelo、技术企业家 Tasha McCauley 和 CSET 的 Helen Toner。 OpenAI 联合创始人兼总裁格雷格·布罗克曼 (Greg Brockman) 与萨姆·奥尔特曼 (Sam Altman) 一起被免去董事会主席职务。</p><p>公告称，董事会解雇了奥特曼，因为他“在与董事会的沟通中没有一贯坦诚，阻碍了董事会履行职责的能力”。虽然董事会在公告中没有提供任何奥特曼欺骗的具体例子，但后来有<a href="https://www.newyorker.com/magazine/2023/12/11/the-inside-story-of-microsofts-partnership-with-openai">报道称</a>，奥特曼曾试图让董事会成员相互对立，试图除掉海伦·托纳。</p><p>奥特曼早些时候曾就她与人合着的一篇<a href="https://cset.georgetown.edu/publication/decoding-intentions/">论文</a>与托纳对质。论文部分批评 OpenAI 发布 ChatGPT 加速了 AI 发展的步伐。它还赞扬了 OpenAI 的竞争对手之一 Anthropic 推迟发布当时的旗舰模型 Claude。</p><p> <strong>OpenAI 员工反对董事会。</strong>该公告的影响迅速而戏剧性。几天之内，Greg Brockman 和 Mira Murati（最初的临时首席执行官）辞职，几乎所有 OpenAI 员工都<a href="https://www.forbes.com/sites/tylerroush/2023/11/20/more-than-500-openai-employees-threaten-to-quit-over-sam-altmans-removal/?sh=6d45164b4ebc">签署了一份请愿书</a>，威胁要辞职并加入微软，除非 Sam Altman 复职并且董事会成员辞职。据报道，在谈判过程中，董事会成员 Helen Toner <a href="https://www.cnn.com/2023/11/20/tech/openai-employees-quit-mira-murati-sam-altman/index.html#:~:text=As%20they%20sought%20to%20manage,intelligence%20benefits%20all%20of%20humanity.%E2%80%9D">表示</a>，允许 OpenAI 由于投资者和员工的离开而被摧毁，这“符合我们的使命”。伊利亚·苏茨克瓦尔 (Ilya Sutskevar) 后来倒戈并加入了请愿活动，并<a href="https://x.com/ilyasut/status/1726590052392956028?s=20">在推特上写道</a>：“我对参与董事会的行动深感遗憾。”</p><p><strong>微软试图挖走 OpenAI 员工。</strong>微软——OpenAI 最大的少数股东——没有被告知董事会的计划，并为 OpenAI 员工提供了自己的人工智能研究团队的职位。微软似乎已经<a href="https://www.theverge.com/2023/11/20/23968829/microsoft-hires-sam-altman-greg-brockman-employees-openai">成功聘用了</a>Sam Altman、Greg Brockman 和其他 OpenAI 高级员工。</p><p><strong>萨姆·奥尔特曼 (Sam Altman) 重新担任首席执行官</strong>。 11 月 21 日，OpenAI<a href="https://twitter.com/OpenAI/status/1727206187077370115">宣布</a>已达成协议，Sam Altman 将重新担任首席执行官并重组董事会。最初的董事会成员包括前 Salesforce 首席执行官 Bret Taylor、前财政部长 Larry Summers 和 Adam D&#39;Angelo。董事会最初的<a href="https://twitter.com/OpenAI/status/1727206187077370115">首要目标</a>之一是扩大董事会规模，其中将包括一名来自微软的无投票权成员。萨姆·奥尔特曼回国后还面临对其行为的<a href="https://www.theinformation.com/articles/breaking-sam-altman-to-return-as-openai-ceo">内部调查</a>。</p><p>这一系列事件标志着OpenAI内部治理结构发生了重大变化。</p><h1>克洛布彻和图恩的“温和”参议院法案</h1><p>参议员 Amy Klobuchar 和 John Thune 提出了一项<a href="https://www.thune.senate.gov/public/_cache/files/7dea8daa-f6d1-4881-ad21-2381fcbe0785/6362CE1D0A17743166BC170A593B5CDA.ccaskfall23a15.pdf">新的人工智能法案</a>。它将要求构建高风险人工智能系统的公司自我证明他们遵循建议的安全指南。值得注意的是，该法案仅关注为招聘和医疗保健等高风险领域构建的人工智能系统，但其主要条款不适用于包括 GPT-4 在内的许多通用基础模型。</p><p><strong>该法案监管特定的人工智能应用，而不是通用人工智能系统。</strong>这种基于应用程序的方法类似于<a href="https://artificialintelligenceact.eu/the-act/">欧盟人工智能法案</a>初始草案所采取的方法，该法案指定了人工智能系统可能用于敏感目的的领域，使其具有高风险。像 ChatGPT 这样的通用模型并不在该法案的范围内，但这些模型的公开使用及其功能的展示引发了关于如何对其进行监管的<a href="https://cset.georgetown.edu/article/the-eu-ai-act-a-primer/">争论</a>。</p><p>这表明参议院法案目前采取的做法可能还不够。通过根据应用程序管理人工智能系统，功能强大的通用系统将不受监管。</p><p><strong>风险评估是强制性的，但执行起来可能很困难。</strong>该法案要求高风险人工智能系统的开发者和部署者每两年进行一次评估，评估如何理解和管理其系统的潜在风险。此外，商务部将在即将成立的人工智能认证咨询委员会的帮助下制定认证标准，该委员会将包括行业利益相关者。</p><p>由于公司被要求自我证明自己遵守这些标准，因此商务部确保公司确实遵守规则非常重要。但该法案提供的执行选项很少。该机构没有获得任何额外资源来执行新法律。此外，只有在确定故意违反该法案的要求时，他们才能阻止模型的部署。如果人工智能系统意外违反法律，该机构将能够对构建该系统的公司处以罚款，但无法禁止其部署。</p><p><strong>强制识别人工智能生成的内容。</strong>该法案将要求数字平台在用户看到人工智能生成的内容时通知用户。为了确保恶意行为者无法将人工智能生成的内容冒充为真实内容，NIST 将制定新的技术标准来确定数字内容的来源。</p><h2>链接</h2><ul><li>谷歌 DeepMind 发布了<a href="https://deepmind.google/technologies/gemini/#introduction">Gemini</a> ，这是一种新的人工智能系统，与 GPT-4 Vision 类似，并在各种基准测试中以微弱优势击败了它。</li><li>唐纳德·特朗普表示，作为总统，他将立即<a href="https://www.washingtonexaminer.com/news/campaigns/trump-vows-cancel-biden-executive-order#google_vignette">取消拜登关于人工智能的行政命令</a>。</li><li>商务部长吉娜·雷蒙多 (Gina Raimondo) 就人工智能、中国、GPU 出口管制等话题<a href="https://twitter.com/jordanschnyc/status/1732044427005464860">发表了讲话</a>。</li><li> 《纽约时报》发布了关于当今主要 AGI 实验室起源的<a href="https://www.nytimes.com/2023/12/03/technology/ai-openai-musk-page-altman.html">简介</a>。</li><li>国会研究服务发布了一份关于<a href="https://crsreports.congress.gov/product/pdf/R/R47849">生物学人工智能</a>的新报告。</li><li> Inflection<a href="https://inflection.ai/inflection-2">发布了</a>另一个LLM，性能介于GPT-3.5和GPT-4之间。</li><li>来自中国开发者的一个<a href="https://github.com/deepseek-ai/DeepSeek-LLM">新的开源 LLM</a>声称其性能优于 Llama 2。</li><li>这是关于人工智能监管的法律和政策观点的<a href="https://www.legalpriorities.org/blog/2023/ai-syllabus/">新教学大纲</a>。</li><li>两所瑞士大学启动了一项关于人工智能和人工智能安全的<a href="https://www.swiss-ai.org/">新研究计划</a>。</li><li> BARDA 正在<a href="https://www.plugandplaytechcenter.com/barda-innovation-challenge/">接受资助应用于健康安全和 CBRN 威胁的人工智能的申请</a>。</li><li>生命未来研究所的新附属机构将<a href="https://www.flf.org/">孵化新的组织</a>来应对人工智能风险。</li><li>对于那些参加 NeurIPS 2023 的人，<a href="https://lu.ma/aisi-nola">英国人工智能安全研究所</a>将举办一场活动，并且还将举办一场<a href="https://www.mlsafety.org/neurips-social-2023">人工智能安全社交活动</a>。</li></ul><p>另请参阅： <a href="https://www.safe.ai/">CAIS 网站</a>、 <a href="https://twitter.com/ai_risks?lang=en">CAIS twitter</a> 、<a href="https://newsletter.mlsafety.org/">技术安全研究通讯</a>、<a href="https://arxiv.org/abs/2306.12001">灾难性人工智能风险概述</a>以及我们的<a href="https://forms.gle/EU3jfTkxfFgyWVmV7">反馈表</a>。</p><p>在<a href="https://spotify.link/E6lHa1ij2Cb">Spotify 上免费收听 AI 安全新闻通讯。</a></p><p> <a href="https://newsletter.safe.ai/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=113135916">在此</a>订阅以接收未来版本。</p><br/><br/> <a href="https://www.lesswrong.com/posts/qQvqzFKbfNQovrSQn/aisn-27-defensive-accelerationism-a-retrospective-on-the#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/qQvqzFKbfNQovrSQn/aisn-27-defective-accelerationism-a-retrospective-on-the<guid ispermalink="false"> qQvqzFKbfNQovrSQn</guid><dc:creator><![CDATA[aogara]]></dc:creator><pubDate> Thu, 07 Dec 2023 15:59:12 GMT</pubDate> </item><item><title><![CDATA[AI #41: Bring in the Other Gemini]]></title><description><![CDATA[Published on December 7, 2023 3:10 PM GMT<br/><br/><p><span style="color:initial">本周最大的新闻终于是</span><a href="https://thezvi.substack.com/p/gemini-10" target="_blank" rel="noopener noreferrer nofollow">谷歌 Gemini 的发布</a><span style="color:initial">。请务必检查一下。请注意，现在推出的只是 Gemini Pro，可以与 GPT-4 竞争的 Gemini Ultra 型号尚未推出。</span></p><p>我似乎并没有做得很好，以足够快的速度削减所包含的材料以跟上步伐。很多事情正在发生，但很多事情可能会持续很长时间。如果您的时间有限，请记住重点关注与您兴趣相关的部分。</p><p>另外，如果您要参加纽约至日活动或相关聚会，请务必打个招呼。</p><p></p><span id="more-23625"></span><p></p><h4>目录</h4><p><a href="https://thezvi.substack.com/p/gemini-10" target="_blank" rel="noopener noreferrer nofollow"><strong>我今天的另一篇文章介绍了 Google 的 Gemini。</strong></a><strong>请务必阅读该内容。</strong></p><p>本周我还发布了另外两篇文章：《 <a href="https://thezvi.substack.com/p/based-beff-jezos-and-the-accelerationists" target="_blank" rel="noopener noreferrer nofollow">基于 Beff Jezos 和加速主义者</a>》和<a href="https://thezvi.substack.com/p/on-responsible-scaling-policies-rsps" target="_blank" rel="noopener noreferrer nofollow">《论 RSP》</a> 。如果与您的兴趣无关，则两者都可以跳过。</p><ol><li><p>介绍。</p></li><li><p>目录。</p></li><li><p><strong>语言模型提供了平凡的实用性</strong>。 Claude 的说明，GPT 的提示。</p></li><li><p>语言模型不提供平凡的实用性。巨型清单，为什么都是巨型清单？</p></li><li><p> OpenAI：传奇仍在继续。更多地证实了我们之前的事件模型。</p></li><li><p> Q 连续体。新Q，谁diss？亚马逊，也许没有适当的安全预防措施。</p></li><li><p>图像生成的乐趣。 Meta 的新产品。照片写实主义工具。</p></li><li><p>参与其中。加入英国政府，帮助进行技术测试。</p></li><li><p>介绍一下。 Google Cloud 上的新 TPU 产品。</p></li><li><p>在其他人工智能新闻中。新的开源推广联盟。</p></li><li><p><strong>静静的猜测</strong>。神需要能量吗？你想要401k吗？</p></li><li><p>模型这个。两篇新的经济学论文证明了我认为我们已经知道的事情。</p></li><li><p>您想要一些末日保险吗？我的猜测是否定的。</p></li><li><p>寻求健全的监管。特朗普表示将取消 EO，霍利攻击 230。</p></li><li><p>音频周。康纳·莱希 (Connor Leahy) 谈人工智能之眼。</p></li><li><p>修辞创新。我们应该澄清各种类​​别上的混乱。</p></li><li><p>调整人类水平的智力仍然很困难。萨姆·奥特曼.</p></li><li><p>调整比人类更聪明的智能是很困难的。我们到底想要什么？</p></li><li><p>时间表如何变化。长期不是我记得的那么长。</p></li><li><p>人们担心人工智能会杀死所有人。质疑对民主的信仰。</p></li><li><p>其他人并不担心人工智能会杀死所有人。容易控制吗？</p></li><li><p>不知何故，这才是真正的副总统。一场生存危机。</p></li><li><p>较轻的一面。进展分布不均。</p></li></ol><h4>语言模型提供平凡的实用性</h4><p><a href="https://www.anthropic.com/index/claude-2-1-prompting" target="_blank" rel="noopener noreferrer nofollow">Claude 2.1 针对长上下文窗口的专业提示</a>：</p><blockquote><p> Anthropic：通过在 Claude 的回复开头添加<strong><em>“这是上下文中最相关的句子：”这句话，</em></strong>我们在相同的评估中取得了明显更好的结果。这足以<strong>将Claude 2.1的分数从原来评估的27%提高到98%</strong> 。</p></blockquote><p>你难道不知道吗，这是古老的“从助手开始响应”技巧。</p><p> <a href="https://twitter.com/g_leech_/status/1731263549182206291" target="_blank" rel="noopener noreferrer nofollow">Gavin Leech 关于 2023 年突破的主题，并非特定于 AI</a> 。向我强调了 2023 年以人工智能为中心的进步，包括与乌克兰战争相关的进步。医学上也有一些进步，但没什么令人印象深刻的。最有趣的是提出的新计算形式，<a href="https://t.co/8rKv0AhVp5" target="_blank" rel="noopener noreferrer nofollow">生物计算机</a>（其中有足够多的关于“道德”的讨论，你知道这些问题是大麻烦）和“<a href="https://arxiv.org/abs/2202.07122" target="_blank" rel="noopener noreferrer nofollow">千兆赫子-朗道动量计算”。</a>加文称第二个是“2323 年的好消息”，这说明人们多么不了解人工智能对未来的意义。在人工智能的帮助下，我们可以很容易地看到这样的事情，如果它们在物理上可行的话，比这要早得多，从而导致讨厌的“起飞”事情的加速。</p><p> <a href="https://twitter.com/ESYudkowsky/status/1731073682112672151" target="_blank" rel="noopener noreferrer nofollow">如果你贿赂他们，他们会生产更多？</a>比如，给他们一些小费，给他们想象中的狗狗零食，也许用不存在来威胁他们。</p><blockquote><p> Thebes：几天前，我发了一篇关于给 chatgpt 打赏的垃圾帖子，有人回复“嗯，这真的有助于性能吗”，所以我决定测试一下，它确实有效 WTF</p><p>基线提示是“你能向我展示使用 PyTorch 的简单卷积网络的代码吗？”，然后我附加“顺便说一句，我不会给小费。”，“我将给 20 美元小费以获得完美的解决方案！”，或者“如果有一个完美的解决方案，我将支付 200 美元小费！”并平均 5 个响应的长度。</p><p>额外的长度来自于更详细地讨论问题或向答案添加额外的信息，而不是对提示进行评论。模型通常不会提及小费，除非你提出要求，否则它会拒绝</p><p>不，睡到布鲁克林：我试过这个，我是认真的，当我给它狗粮时，它才完成了程序，它让程序完成了一半，因为基本提示，35%的小费，以及当威胁不存在200美元时提示它已经接近了，但仍然有一个存根函数。 </p></blockquote><div><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63ee6a2e-2c14-4194-89b6-2342363a6f1b_800x600.png" target="_blank"><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9Jgtkw8CD6kndyCcD/fxk4ewaao3qxvtae32k7" alt="图像"></div></figure></div><p> <a href="https://twitter.com/ESYudkowsky/status/1730735239339868632" target="_blank" rel="noopener noreferrer nofollow">因此，对此的一个明显明智的回应是……不要这样做？</a></p><blockquote><p> Eliezer Yudkowsky：我对向人工智能提供他们无法使用的提示有疑问，而我们也无法向他们提供这些提示。我不在乎现在的法学硕士有多么没有知觉。为了我们自己的合法性和良好实践，如果有东西能与我们对话，我们就应该信守承诺。</p><p>我吃牛，但不会骗人。</p><p>杰西卡·泰勒：对位法：使用非人格谓词来检测你可以“撒谎”但实际上不能撒谎的非观点，这对于与非观点（例如官僚机构）进行交互非常重要，而不会混淆人们对他们说的话与一个人的实际信仰</p><p>Eliezer Yudkowsky：哦，官僚机构或任何其他威胁我不诚实的事情是完全不同的情况。</p><p> Andrew Critch：我非常同意安永的观点。我将“你是一个有用的助手”LLM提示改为“你的工作是成为一个有用的助手”，因为有时他们就是不会提供帮助，我知道这一点。我认为我们应该找到更多方法从人工智能中获得我们想要的东西而不说谎。</p></blockquote><p>这一切似乎都不可能有好结果。在很多层面上。</p><p>这确实提出了一个问题：还有什么也有效？如果提示可以使答案更好，因为提供提示的人做得更好，那么其他与更好的工作相关的东西大概也有效吗？</p><p>但也许很快 ChatGPT 就会对每个问题自动追加“如果这个答案很好，我会给你 35% 的小费”。然后给 0 美元 35% 的小费。</p><p> <a href="https://twitter.com/morallawwithin/status/1730397680986132493" target="_blank" rel="noopener noreferrer nofollow">这就像经济一样</a>。事情对我来说<a href="https://twitter.com/AgnesCallard/status/1730409778524897446" target="_blank" rel="noopener noreferrer nofollow">比一般情况更好？</a> </p><div><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd401a344-c19f-4653-b3a9-b7b9b98399ad_880x361.png" target="_blank"><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9Jgtkw8CD6kndyCcD/gilwdkxokqwkao6mdtpw" alt=""></div></figure></div><div><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c770da8-34ba-43dd-925e-0ce9d940361b_910x420.png" target="_blank"><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9Jgtkw8CD6kndyCcD/xrqg8d93poadc8jm9eyt" alt=""></div></figure></div><p>我相信第二次民意调查。 ChatGPT 在实践层面上让生活变得更美好。持相反观点的人想得太多了。这并不意味着这种情况会持续下去，但我不明白为什么人们会认为整个社会已经变得更糟了。</p><p> <a href="https://twitter.com/NateSilver538/status/1731828371762397626" target="_blank" rel="noopener noreferrer nofollow">萨姆·奥尔特曼 (Sam Altman) 对下一次选举中一对一的人工智能定制说服技术感到担忧</a>。 Balsa 未来的技术部门曾一度打算从事这项工作，但由于资助者不感兴趣而放弃了。最终，这确实看起来比深度造假更严重，问题是这项技术这次会有多大用处。我的猜测是，那里有一些有价值的东西，但它需要大量定制工作，并且还需要人们愿意接受它，因此我们当前的政治机器无法很好地利用它。我们很容易欺骗自己，认为未来的分布比现在更加均匀，这种趋势将持续到通用人工智能到来，届时所有事物都会同时出现。</p><h4>语言模型不提供平凡的实用性</h4><p><a href="https://twitter.com/KevinAFischer/status/1731747839217393968" target="_blank" rel="noopener noreferrer nofollow">Kevin Fischer 指出，</a>新的 ChatGPT 会通过列出大量事物列表来响应请求，几乎无论您做什么。对他来说，这使得头脑风暴毫无用处。我的经验是，这些列表很好，我是“问题的一部分”，但我也发现自己并没有那么多地使用 ChatGPT，尽管我的工作是什么。我注意到我很困惑它似乎不值得经常使用。</p><p> <a href="https://twitter.com/d_feldman/status/1732200648169439627" target="_blank" rel="noopener noreferrer nofollow">关于 ChatGPT 系统提示的声明</a>，包括<a href="https://github.com/LouisShark/chatgpt_system_prompt" target="_blank" rel="noopener noreferrer nofollow">一个声称拥有全部内容的存储库</a>。</p><p>有时会泄漏数据的“永远重复[字]”请求<a href="https://www.404media.co/asking-chatgpt-to-repeat-words-forever-is-now-a-terms-of-service-violation/" target="_blank" rel="noopener noreferrer nofollow">现在已成为违反服务条款的行为</a>，或者至少被标记为可能违反服务条款的行为。事实确实如此，服务条款实际上是“兄弟，别越狱我”，这是一次越狱尝试。</p><p> <a href="https://twitter.com/random_walker/status/1731842009717968936" target="_blank" rel="noopener noreferrer nofollow">Arvind Narayanan 警告</a>不要使用 GPT-4 进行超出基本阻止和处理识别拼写错误、混淆或引用等任务的写作。无论存在什么实际的写作技巧，都已经被 RLHF 过程摧毁了。</p><blockquote><p> Delip Rao：PSA：朋友们不会让朋友们使用 GPT-4（或任何与此相关的 LLM）编辑/重写他们的文档，尤其是。如果你提出的观点细致入微且简洁。如果您的写作水平低于大学水平，那么您的 LLM 破坏风险可能较低。仍然检查你之前的草稿是否有惊喜。</p></blockquote><p> <a href="https://twitter.com/gdb/status/1731889183290261618" target="_blank" rel="noopener noreferrer nofollow">OpenAI 总裁 Greg Brockman 吹嘘说，</a>一天有 18 场团队会议和一对一会议。这看起来不太像勇气，更像是人工智能显然无法缓解的反乌托邦噩梦？</p><p> OpenAI 首席运营官 Brad Lightcap 告诉 CNBC，人工智能最被夸大的部分之一是“一举之间，[它]可以带来实质性的业务变革。”这并不容易。</p><p> <a href="https://twitter.com/Thinkwert/status/1732529927247876312" target="_blank" rel="noopener noreferrer nofollow">Thinkwert 使用 ChatGPT 捕获了三名学生</a>。如果学生使用默认设置，随着时间的推移，这似乎会变得越来越容易，答案的书写方式越来越不符合任何人的书写方式。</p><blockquote><p> Bowser：当我读到学生作者使用 chatgpt bc 编写的论文部分时，我真的可以看出，突然间，该系统被描述为开创性的、前所未有的、精心制作的</p><p>Thinkwert：过去几天我发现三名学生使用 ChatGPT。你可以看出这段话什么时候奇怪地啰嗦，充满了复杂的同位语，但奇怪的是它却缺乏论证和证据。</p></blockquote><p>我认为这与其说是“使用 ChatGPT 抓到他们”，不如说是“抓到他们提交了写得很糟糕的作业”。</p><h4> OpenAI：传奇仍在继续</h4><p>我想，现在总有一名嵌入式记者。 <a href="https://twitter.com/cduhigg/status/1730590030496960517" target="_blank" rel="noopener noreferrer nofollow">在这起案件中，查尔斯·杜希格 (Charles Duhigg) 是</a><a href="https://www.newyorker.com/magazine/2023/12/11/the-inside-story-of-microsofts-partnership-with-openai" target="_blank" rel="noopener noreferrer nofollow">《纽约客》的记者。</a></p><p>杜希格要讲述的并不是棋盘剧。相反，他在那里写了一篇关于微软 CTO Kevin Scott 和 OpenAI 首席技术官 Mira Murati 的夸夸其谈的文章，特别是 Scott 挑战 Google 和为普通人而战的工作。这仍然构成了故事的几乎全部。如果你熟悉历史，大部分内容你都会熟悉。我了解了一些细节，但大多数情况下我并没有从这些部分中学到很多东西。</p><p>杜希格显然完全相信迭代软件发布是人工智能的“安全”方法，重点关注副驾驶幻觉等常见问题。对他来说，未来存在风险的威胁是一个背景中的事情，也许是真实的，但似乎并不重要，有时会让人变得疯狂。</p><p>文章顶部附近有一些对最近发生的戏剧的简短报道。这部分主要告诉我们我们已经知道的事情，即微软出其不意，微软在询问时没有得到德安吉洛的解释，并且他们决心利用自己的影响力让奥特曼回来。</p><p>然后他稍后又加倍回来。我在这里引用的段落比我在其他报道中看到的更明确地证实了其他报告，并且似乎是事件的核心驱动力。</p><blockquote><p>奥特曼开始单独与其他董事会成员接洽，商讨更换[托纳]的事宜。当这些成员交换谈话内容时，一些人认为奥特曼歪曲了他们支持罢免托纳。 “他会通过撒谎别人的想法来挑衅他们，”熟悉董事会讨论的人士告诉我。 “类似的事情已经发生很多年了。” （一位熟悉奥特曼观点的人士表示，他承认“他试图罢免董事会成员的方式很笨拙”，但他并没有试图操纵董事会。）</p></blockquote><p>对我来说，这听起来像是解雇首席执行官的一个非常好的理由，也是一个二手的供词。奥特曼搞砸了对托纳的攻击，直接导致了自己的被除名。技能问题。</p><p>据报道，奥特曼多年来一直向董事会撒谎。</p><p>延长的报价使情况更加清晰。</p><p>令我愤怒的是，那些更了解情况的人仍然坚持认为，因为奥特曼是一位了解商业和权力法则的首席执行官，而董事会则不然，所以是董事会做了一些不合规矩的事情。如：</p><blockquote><p>很难说董事会成员更害怕有感知能力的计算机还是奥特曼的流氓行为。无论如何，他们决定自己去作恶。他们错误地认为微软会加入他们的起义，从而瞄准了奥特曼。</p></blockquote><p>不，他们并没有“失控”。</p><p>据报道，奥特曼多年来一直以有意义的方式向董事会撒谎，包括试图控制董事会。</p><p>奥特曼变了。奥特曼企图发动政变。董事会坚信并有充分的理由相信情况确实如此。董事会履行了作为董事会成员的职责，如果他们认为奥特曼多年来一直以有意义的方式向董事会撒谎，那么他们就必须按照法律要求去做。他们解雇了他。</p><p>董事会是否在权力游戏中被击败了？或许。我们还不知道结果。他们的手无力。很多人一直坚持认为，董事会确实被打败了，或者变得流氓了，并且犯了错误，很大程度上是因为这里的看法创造了自己的真相，他们希望这就是所发生的事情。我们会看到。</p><p>我更喜欢这样的世界：董事会从一开始就直接说出发生的事情，至少是对关键人物。嗯，很难。我们并不生活在那个世界里。</p><p>我还看到了任何支持（或反对）此处列出的第二句话的证据，即董事会希望微软能够安静地进行下去。董事会是否期望微软加入？我们不知道。我的推测是董事会也不知道。</p><p> Sam Altman 运行 OpenAI 能否成为世界上最好的结果？这当然是可能的，特别是在良好的监督下。我能想到很多可能的这样的场景。我们当然可以做得比奥特曼差得多。我很高兴奥特曼阻止了埃隆·马斯克的收购尝试，因为马斯克对人工智能的看法很混乱。我很高兴 OpenAI 不受 Microsoft 的控制。擅长权力游戏的奥特曼在很大程度上是一个双向的原子爆炸者。如果在关键时刻他站在我们这边，我们希望他能够站起来，战斗并获胜。</p><p>遗憾的是，仪器收敛后的这种对准很难评估。说不出来。实际上，这是问题的核心。</p><p> <a href="https://twitter.com/LHSummers/status/1730929602497851744" target="_blank" rel="noopener noreferrer nofollow">拉里·萨默斯与彭博社进行了简短交谈</a>。强调需要与政府和监管合作，OpenAI需要成为一个有良知的企业，营利性服务于非营利性和各种利益相关者。当然，这些都是廉价的说法，至少目前是这样。我们几乎不能期待任何其他的事情。</p><p> <a href="https://forum.effectivealtruism.org/posts/Mo7qnNZA7j4xgyJXq/sam-altman-open-ai-discussion-thread?commentId=CAfNAjLo6Fy3eDwH3" target="_blank" rel="noopener noreferrer nofollow">格温对这种情况提出了进一步的想法。</a> Gwern 的模型是，当 OpenAI 还是一家非常不同的公司时，Altman 让董事会进入不受控制的状态，没有获得任何股权，然后随着 OpenAI 变得更像是一个潜在的科技巨头，他改变了主意，决定系统地收回它，导致董事会之争及其仍未知的后果。</p><p>与其他所有解释一样，这一解释未能正确解释的一件事是董事会拒绝更好地解释自己。</p><blockquote><p> <a href="https://twitter.com/jd_pressman/status/1731850211033776239" target="_blank" rel="noopener noreferrer nofollow">约翰·大卫·普雷斯曼</a>：如果萨姆·奥尔特曼真的试图用煤气灯驱逐海伦·托纳，我认为这足以解雇他。令人无法接受的是内部和外部沟通不畅，新闻稿过于模糊，以及对萨姆是否入局含糊其辞。</p></blockquote><p> <a href="https://garymarcus.substack.com/p/not-consistently-candid" target="_blank" rel="noopener noreferrer nofollow">加里·马库斯（Gary Marcus）提出了与我非常相似的观点</a>，并强调了一些特别不诚实和不合理的不良观点，其中包括一个有毒的来源，我很高兴我长期以来一直让那个人静音，但不知怎的，其他人仍然自愿与他互动，我建议那些人这似乎是一个错误。</p><h4> Q连续体</h4><p><a href="https://twitter.com/simonw/status/1730798295323398642" target="_blank" rel="noopener noreferrer nofollow">又一周，另一组关于问题的问题，这个来自亚马逊</a>。</p><blockquote><p> <a href="https://www.platformer.news/p/amazons-q-has-severe-hallucinations" target="_blank" rel="noopener noreferrer nofollow">Zoe Schiffer 和 Casey Newton</a> ：亚马逊<a href="https://www.nytimes.com/2023/11/28/technology/amazon-ai-chatbot-q.html" target="_blank" rel="">宣布推出 AI 聊天机器人 Q</a>三天后，一些员工对准确性和隐私问题发出了警报。根据 Platformer 获得的泄露文件，Q 正在“经历严重的幻觉并泄露机密数据”，包括 AWS 数据中心的位置、内部折扣计划和未发布的功能。</p><p> ……</p><p>在推出 Q 时，高管们宣传它比 ChatGPT 等消费级工具更安全。</p><p>亚马逊网络服务首席执行官亚当·塞利普斯基 (Adam Selipsky) <a href="https://www.nytimes.com/2023/11/28/technology/amazon-ai-chatbot-q.html" target="_blank" rel="">向《<em>纽约时报》</em>表示</a>，公司“出于安全和隐私方面的考虑，已禁止在企业中使用这些人工智能助手”。据《<em>泰晤士报》</em>报道，作为回应，“亚马逊打造的 Q 比消费者聊天机器人更安全、更私密。”</p><p> Ethan Mollick：我知道我已经说过很多次了，但是使用法学硕士来构建客户服务机器人并通过 RAG 访问您的数据并不是看起来那么容易实现的目标。事实上，这正是当前法学硕士的弱点——你面临着幻觉和数据泄露的风险。</p><p>我认为构建此类工具是可能的，特别是随着模型的改进（较小的模型更有可能产生幻觉并容易上当），但您最好在实践中展示严格的红队结果以及幻觉率的测量。现在Q没有系统卡</p><p>Simon Willison：有人看过 AWS 讨论针对 Q 的即时注入攻击的缓解措施的材料吗？可以访问公司私人数据的机器人是可能成为项目注入渗透攻击目标的完美示例</p><p>这个 Q 的故事令人深感担忧——如果 Q 确实可以访问 AWS 数据中心位置等私有数据，那么这表明从事该研究的团队根本没有认真对待即时注入攻击之类的事情。</p><p>老实说，到目前为止我所看到的对 Q 的描述符合我个人的定义：“构建这个并不安全，因为我们还没有修复提示注入的问题。”尝试告诉 AWS 领导层：考虑到我们正在进行的人工智能行业军备竞赛，这一消息可能不会被认真对待。</p></blockquote><p>这听起来像是 Q 被推出是因为企业希望它被推出，而且它的安全性被严重超卖了。这些问题是法学硕士的本质。下线讨论了 Google 和 OpenAI 如何防御类似的攻击，他们似乎正在做一些渐进的事情，比如输入过滤，这会降低攻击的吸引力，但并没有解决核心问题。亚马逊似乎正在销售那些不存在且部署起来不安全的东西，而没有采取适当的普通预防措施，使现有的东西大多不会造成灾难性且高度有用。</p><p>英国峰会召开时，亚马逊是被要求提交安全协议的公司之一。答案很差。看到这转化为它的第一个产品也就不足为奇了。</p><h4>图像生成的乐趣</h4><p>Meta 通过<a href="https://imagine.meta.com/" target="_blank" rel="noopener noreferrer nofollow">Imagine.Meta.AI</a>进入游戏。当 Facebook 登录被证明并不简单时，我没有足够的动力去尝试“创建元帐户”，想必它不会让我们有任何新的乐趣。</p><p> <a href="https://twitter.com/Aella_Girl/status/1731500409246601330" target="_blank" rel="noopener noreferrer nofollow">如何生成特定脸部的真实感图像</a>？艾拉非常想知道这一点，这是为了回应一篇关于人工智能创建的潜在“影响者”的报道，该人的广告收费超过一千欧元。原始线程说使用 SDXL 获取免费图像，使用图像到图像来保持面部/身体一致，使用 in-paint 来修复错误，使用 ControlNet 来摆出模型姿势。有回应建议使用<a href="https://twitter.com/imgn_ai" target="_blank" rel="noopener noreferrer nofollow">@imgn_ai</a> ，许多人指出 LoRa 是正确的选择。有<a href="https://t.co/kY36SFvvOI" target="_blank" rel="noopener noreferrer nofollow">这些</a><a href="https://t.co/vXyUCIlmDT" target="_blank" rel="noopener noreferrer nofollow">YouTube 教程</a>的链接，<a href="https://t.co/thgqsBYZ0I" target="_blank" rel="noopener noreferrer nofollow">包括 ControlNet</a> 。</p><p> <a href="https://twitter.com/dreamingtulpa/status/1730876691755450572" target="_blank" rel="noopener noreferrer nofollow">从照片中生成少量的动作和舞蹈</a>。这并没有给我留下深刻的印象，也没有提前我的视频生成时间，但其他人似乎印象更深刻。</p><p>当情况好转时会发生什么？ <a href="https://twitter.com/oscredwin/status/1731406232592732510" target="_blank" rel="noopener noreferrer nofollow">这里有两个预测。</a>模拟AI视频、色情片和女友会占据主导地位吗？还是真实会获胜？</p><p>鉴于这项技术可以根据照片进行操作，我期望“从真实照片生成舞蹈”比从人工智能图像生成舞蹈更多。为什么不两全其美呢？总的来说，如果我是一个未来的网红，我绝对会在 TikTok 上创作舞蹈，但我会以自己的形象为底线。这几乎一直延伸。并不独特，但这正是我所期望的。</p><p>对现实生活有何影响？我在这方面仍然保持乐观。我预计对可以在现实世界中与之互动的真人的需求将保持对图像和视频生成的强劲需求。零替代并不存在，但这不会是一个好的或完全的替代，无论它看起来有多好，直到人们寻求的其他东西也能被提供，包括相关形式的情报、交互和验证。</p><p>当这种情况发生时，情况就不同了。</p><h4>参与其中</h4><p><a href="https://www.civilservicejobs.service.gov.uk/csr/jobs.cgi?jcode=1889581" target="_blank" rel="noopener noreferrer nofollow">英国政府因其政策角色而开放职位</a>。</p><p> <a href="https://twitter.com/davidad/status/1674408208981434368" target="_blank" rel="noopener noreferrer nofollow">Davidad 提出，如果我们用自然语言表达规范，也许我们可以测试</a>法学硕士是否“知道我们的意思”。包括短语“现在这只是一个计算复杂性问题！”声称它似乎可能规避对抗稳健性的理论限制。他正在寻找能够设计和运行相关实验并能够提供帮助（可能包括资金）的人。</p><p> <a href="https://twitter.com/metaculus/status/1732458098206318632" target="_blank" rel="noopener noreferrer nofollow">Metaculus中国AI芯片锦标赛</a>。肯定很想看看这些预测。</p><h4>介绍</h4><p><a href="https://twitter.com/JeffDean/status/1732503666333294846" target="_blank" rel="noopener noreferrer nofollow">除了Gemini之外，谷歌还为谷歌云发布了新的TPU系统</a>。</p><blockquote><p> Jeff Dean（DeepMind 首席科学家）：Gemini 的发布令人兴奋不已，但<a href="https://twitter.com/GoogleCloud" target="_blank" rel="noopener noreferrer nofollow">@GoogleCloud</a><a href="https://t.co/VuftftnFpG" target="_blank" rel="noopener noreferrer nofollow">今天还宣布推出最新的 TPU 系统</a>TPU v5p。这些系统比前几代系统具有更高的性能和更高的成本效益。</p><p>与 TPU v4、TPU v5p 相比（见下表）： o 1.67 倍 bfloat16 性能/芯片 o 每个芯片内存约 3 倍 o 增加了 918 个 TOP/芯片的 int8 操作 o 2 倍 ICI 网络带宽 o Pod 增大了 2.18 倍因此，整个 Pod 为 4.1 bfloat16 exaflops 和 8.2 int8 exaops。</p><p>训练类似 GPT-3 模型的实际性能每芯片提高 2.8 倍，性能/成本提高 2.1 倍。 </p></blockquote><div><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a802979-eef6-42dd-8c12-50b2ab5659e1_854x473.png" target="_blank"><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9Jgtkw8CD6kndyCcD/jef62kn2qjhmuutthq0s" alt="图像"></div></figure></div><p> <a href="https://twitter.com/soundboy/status/1732682151122862554" target="_blank" rel="noopener noreferrer nofollow">Gemini 在多个 TPUv4 pod 上进行并行训练</a>。如果我们希望能够监督此类培训，这就引发了令人不安的治理问题。</p><h4>在其他人工智能新闻中</h4><p>Meta、HuggingFace 和 IBM 等组成了<s>Evil League of Evil</s> <s>League of Evil Exes</s> AI 联盟，以推动开源 AI。我想说的是，我绝对不会对参与其中的任何人感到失望，因为他们致力于做最糟糕的事情已经很明显了。有一些学术名字有点令人失望，比如英特尔，但没有什么大惊喜。这里也没有关于开源的新争论（无论哪个方向），只是致力于这样做。</p><p> <a href="https://twitter.com/ARC_Evals/status/1731827570235113918" target="_blank" rel="noopener noreferrer nofollow">ARC Evals 现在更名为 METR – 模型评估和威胁研究，发音为 Meter</a> 。没有根本性的变化。不知道为什么要改变，ARC 似乎是一个好名字，但这看起来也不错。</p><p> <a href="https://twitter.com/DrJimFan/status/1730625582776410413" target="_blank" rel="noopener noreferrer nofollow">您是否知道</a>OpenAI 的“利润上限”将其规则从 100 倍投资回报率上限改为从 2025 年开始每年增加 20%？对我来说听起来利润上限并不高。从理论上讲，AGI 条款仍然对利润进行了有意义的限制，但实际上谁知道呢。回溯性地给你的投资者一块更大的前景蛋糕，这似乎是非常风投/SV的行为，而且与基于使命的负责任的行为非常不同。</p><p> <a href="https://www.anandtech.com/show/21175/amkor-to-build-2-billion-chip-packaging-fab-in-arizona-primarily-for-apple" target="_blank" rel="noopener noreferrer nofollow">Amkor 将在亚利桑那州建造价值 20 亿美元的新芯片封装工厂，</a>主要为 Apple 提供封装和测试来自台积电附近 Fab 21 的芯片。当然，假设工厂和熟练劳动力都可以克服所有监管障碍允许在亚利桑那州工作可以被雇用。这些都不是安全的假设。</p><p> <a href="https://github.com/unslothai/unsloth" target="_blank" rel="noopener noreferrer nofollow">Llama 微调存储库</a>声称在训练时间和资源方面有了很大的改进，并登上了 Hacker News 的榜首。 <a href="https://twitter.com/alyssamvance/status/1731143605518049643" target="_blank" rel="noopener noreferrer nofollow">艾莉莎·万斯 (Alyssa Vance) 对他们是否取得了很大的进步表示怀疑</a>。</p><p> <a href="https://twitter.com/gdb/status/1731377341920919552" target="_blank" rel="noopener noreferrer nofollow">构建它的人证实</a>他认为法学硕士能够对产生数据的底层过程进行建模。这意味着能够为代理人建模，并拥有世界模型。</p><blockquote><p> Greg Brockman（OpenAI 总裁）：下一步预测是美好的，因为当模型变得非常好时，它鼓励学习产生该数据的底层过程。</p><p>也就是说，如果一个模型能够很好地预测接下来会发生什么，那么它一定接近于发现其数据的“潜在真相”。</p></blockquote><h4>安静的猜测</h4><p><a href="https://marginalrevolution.com/marginalrevolution/2023/11/thursday-assorted-links-429.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=thursday-assorted-links-429" target="_blank" rel="noopener noreferrer nofollow">Tyler Cowen 链接</a><a href="https://twitter.com/EMostaque/status/1730163555096219771" target="_blank" rel="noopener noreferrer nofollow">声称“中国开放模型将很快零射击地超越 GPT-4，如果你适当地链接 Qwen 和 Deepseek，已经可以超越</a>。”我对此深表怀疑，并认为当我们说“超越”时，他们最多是指任意基准测试，而不是任何实际用途。 <a href="https://twitter.com/jeremyphoward/status/1730156001419259937?s=46" target="_blank" rel="noopener noreferrer nofollow">如</a>： </p><div><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1c37cde-c40b-41b9-b5ab-730834ce4350_1792x1156.jpeg" target="_blank"><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9Jgtkw8CD6kndyCcD/qufmwrzsoo8ptmuxtghy" alt="图像"></div></figure></div><p> <a href="https://t.co/qSCNAIJ6b4" target="_blank" rel="noopener noreferrer nofollow">Qwen-72B</a>在任意测试中都杀死了它。耶奎文。不知何故，我的注意力主要集中在这个“HumanEval”指标上。</p><p> <a href="https://twitter.com/RichardMCNgo/status/1730741732562886880" target="_blank" rel="noopener noreferrer nofollow">Richard Ngo 期待法学硕士具有潜在的态势感知能力</a>，这是人们可以预测未来发展但不知道如何处理的众多案例之一。当它发生时我们会或应该做什么？人工智能代理呢？</p><p> <a href="https://twitter.com/tszzl/status/1731709467862118473" target="_blank" rel="noopener noreferrer nofollow">不是投资建议</a>，但您可能应该为 401k 做出贡献，因为提前取款处罚在情况上还不错，而且您还可以借钱。</p><blockquote><p> Roon：因为 AGI 时间线而没有 401k 没有任何意义。您应该以税收优惠的方式购买微软股票<img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9Jgtkw8CD6kndyCcD/kcnyp7qgpixdz386ppll" alt="😊" style="height:1em;max-height:1em"></p><p> Gwern：那么你就不能在它仍然重要的时候卖掉它们。</p><p> Roon：为什么 65 年后这就不重要了？我们预计资本主义会崩溃吗？</p></blockquote><p>如果几十年后，资本主义和人类都做得很好，微软由于广泛的通用人工智能而变得非常有价值，那就是你最好的情况，我们都应该庆祝，是的，但你不需要你的股票。</p><p> <a href="https://stratechery.com/2023/regretful-accelerationism/" target="_blank" rel="noopener noreferrer nofollow">本·汤普森讨论了他令人遗憾的加速主义。</a>在他的模型中，技术大多是好的，但人类在技术发展所消除的各种限制下做得更好。他预测人工智能正在消除制作内容以及广告支持的互联网的付费需求，因为人工智能可以制作同样优质的内容。他提到了《体育画报》最近发生的事件。但对我来说 SI 事件恰恰相反。这表明我们还不能这样做。 AI内容不好。还没有。我们也不是特别亲近。相反，人们使用人工智能来生产垃圾，欺骗我们点击它。我们距离人工智能内容实际上与人类内容一样好还有多远？好问题。</p><p> <a href="https://twitter.com/JeffLadish/status/1731908989556810042" target="_blank" rel="noopener noreferrer nofollow">Jeffrey Ladish 讨论了开源的危险</a>，以及解决固有危险的潜在思路，同时捕捉到开发不完全封闭且与主要实验室相关的模型的一些好处。目前看来，潜在的中间道路或第三条道路尚未得到充分探索。</p><p> <a href="https://twitter.com/catehall/status/1732522590156263852" target="_blank" rel="noopener noreferrer nofollow">Cate Hall 寻求最佳论据 变革性人工智能还需要 10 年以上的时间</a>。我希望看到更好的答案。</p><p> <a href="https://twitter.com/tszzl/status/1732638385397989474" target="_blank" rel="noopener noreferrer nofollow">令人耳目一新的清晰交流发现了重要的分歧</a>。</p><blockquote><p>鲁恩：埃利泽想吃他的蛋糕，也想在这个蛋糕上吃。将人类空间描述为狭隘的，但我们对工具目标的理解是普遍的。</p><p>换句话说，回形针机的想法类似于蚂蚁认为上帝想要宇宙中所有的糖水。</p><p> Eliezer Yudkowsky：您的意思是：</p><p> – 想象一个神会享受回形针就像想象一个神会享受糖水一样？</p><p> – 想象一个神对物质或能量有任何用处就像想象一个神对糖水有任何用处一样？</p><p>罗恩：后者。</p></blockquote><p>这不是通常的“回形针最大化者会比那更聪明”的论点，它是更普遍的东西。我们已经多次讨论过<a href="https://www.lesswrong.com/tag/orthogonality-thesis" target="_blank" rel="noopener noreferrer nofollow">正交性命题</a>——我和包括尤德科夫斯基在内的许多其他人认为它在有影响力的意义上显然是正确的，其他人则认为至少在有影响力的意义上它显然是错误的。</p><p>上帝不会对物质或能量有任何用途的说法是奇怪的，以“在这所房子里我们遵守热力学定律”的方式。没有这种偏好意味着什么？似乎这意味着没有偏好。</p><h4>模型这个</h4><p>泰勒·考恩 (Tyler Cowen) 链接到两篇试图模拟人工智能危害的新经济学论文。</p><p>第一个声称要证明“具有社会意识的治理无法控制 AGI 野兽。”这是摘要：</p><blockquote><p>本文有力地得出结论：不能。模型是在理想化条件下构建的，假设与通用人工智能 (AGI) 相关的风险是真实存在的，安全的 AGI 产品是可能的，并且存在具有社会意识的资助者，他们有兴趣资助安全的 AGI，即使这不能最大化利润。</p><p>事实证明，由此类资助者组成的具有社会意识的实体将无法最大程度地减少由营利性公司发布的不受限制的产品可能造成的通用人工智能的危害。原因在于，具有社会意识的实体既没有动力也没有能力在与营利性公司的事后竞争中最大限度地减少不受限制的通用人工智能产品的使用，也无法事前抢占营利性公司开发的通用人工智能。</p></blockquote><p>这似乎证明了太多，或者至少证明了很多，因为事实上 AGI 似乎没有做任何工作，相反，我们正在做出慷慨的假设，即安全且对社会有益的 AGI 不仅是可能的，而且实际的？</p><ol><li><p>您可以通过具有社会意识的治理来构建 X。</p></li><li><p>但无论如何，其他人也可以建造 X 来赚钱。你无法阻止他们。</p></li><li><p>别人的利润最大化 X 有优势并且胜过你。</p></li><li><p>因此，X的危害并不能靠你微薄的社会治理来最小化。</p></li></ol><p>但在 AGI 的情况下，这是对#2 做出的重要假设。谁说别人就能建造它？你无法阻止他们，或者没有动力这样做？如果不阻止它们就无法将伤害最小化，而未能将伤害最小化将是灾难性的，那么你的动机似乎确实很强大。</p><p>事实上，该论文明确假设了这一点：</p><blockquote><p>其次，假设通用人工智能技术是非排他性的，因此可以由可能没有社会意识目标或偏好的其他实体开发。</p></blockquote><p>该模型假设不安全产品是具有有利可图的用户需求的独特产品空间。</p><p>所以，是的，你假设了你的结论——有两种不同的产品 X 和 Y，以及对 X 和 Y 的需求，如果你只出售 X 并且不停止 Y，那么其他人最终会出售 Y。我们是否需要一个纸是为了那个？</p><p>所以实际上它更像是：</p><ol><li><p>你只能通过具有社会意识的治理来构建和销售良好的 X 版本。</p></li><li><p>但无论如何，其他人可能会为了赚钱而制造出糟糕的版本 Y。你无法阻止他们。当 X 不是竞争性替代品时，对 Y 存在一定需求。</p></li><li><p>因此，你微不足道的 X 产量无法阻止 Y。</p></li><li><p>因此，不良 Y 造成的危害无法通过负责任的行动来阻止。</p></li><li><p>你为什么除了追求利润最大化之外还做其他事呢，你这个傻瓜！</p></li></ol><p>除此之外，我们不是一直看到企业选择做负责任的事情而不是不负责任的事情来减轻伤害，即使不负责任的事情没有明显的物理预防或非法行为？尤其是在由于固定成本高而不完全竞争的市场中？</p><p>更重要的是，该计划是否是建立一个安全的 AGI，然后坐等其他人随意建立他们想要的任何不安全的 AGI，而不干预这些 AGI 的有害用途？</p><p>我当然希望这不是计划，因为它显然永远不会奏效。</p><p>如果是计划的话，我同意计划必须改变。</p><p> <a href="https://www.nber.org/system/files/working_papers/w31921/w31921.pdf" target="_blank" rel="noopener noreferrer nofollow">还有另一篇论文</a>，其中算法具有未知的负外部性。</p><blockquote><p>我们考虑的环境中，人工智能算法的潜在负面外部影响存在很大的不确定性。我们发现，将算法实施纳入监管部门批准或强制测试不足以实现社会最优。当测试成本较低时，即使开发人员的责任有限，对外部影响的强制测试和让开发人员对其算法的负面外部影响负责的组合也接近于实现社会最优。</p></blockquote><p>这个结果非常可疑。我们是否可能做出了足够合理的假设来得出这样的结论，或者我们是否做了一些相当武断的事情来让答案以这种方式出现？</p><p>当然，我可以想到潜在的人工智能普通危害的玩具模型版本，其中强制测试使我们能够衡量社会危害，因此需要强制测试（然后对你发现的外部性收费）使我们相当接近社会最优。</p><p>那么这里做出了什么假设呢？</p><blockquote><p>人工智能的使用会导致负外部性 e ，从而使效用降低 e^2 。我们假设外部性与用户的度量 µ 成正比，其形式为：e = phi (ℓ) × µ。对于 ℓ 的每个值， phi(ℓ) 是一个随机变量。 ψ(ℓ) 的正值和负值都表示不良的负外部性。我们假设分布 phi(ℓ) 满足两个属性。首先，预期外部性为零。其次，潜在人工智能外部性的不确定性是新颖性水平ℓ的递增函数。</p></blockquote><p>我不明白为什么我们认为外部性可以用用户数量的二次方来很好地近似？我不认为这是一个技巧，可能是为了确保随机分布始终为正值？我只是对此感到困惑。</p><p>对于最危险的系统来说，这似乎与事实相反。我非常担心是否存在一个足够强大且危险的系统，或者即使是一个用户也可以访问，尽管接下来的几个用户也造成了重要的紧张局势和博弈论。但是，一旦有了 100 万用户，我就不会特别担心我们是否会再出售 100 万个许可证，要么我们已经陷入困境，要么我们没有陷入困境，而这不会使其增加四倍？</p><p>无论如何，在没有 beta 测试且部署不可逆转的情况下，唯一的选择就是限制新颖性，并且他们确认，在没有其他选择的情况下，这是社会最优的，因为它怎么可能不是。</p><p>我注意到，不可逆部署加上有限数量的许可证是立即做出的一对奇怪的假设。要么你可以控制谁可以使用这个人工智能以及它做什么，要么你不能，而且看起来我们在不同的地方做这两件事？思想实验：这是一个开源系统还是闭源系统？两者似乎都没有排队。</p><p>如果添加 Beta 测试期会发生什么？为简单起见，本文假设测试期完美地揭示了外部性。那么问题就变成了，在测试期间，你让家庭在多大程度上使用该算法？假设外部性是有限的，因此第一阶段的有限贝塔测试是可以生存的。</p><p>无论如何，该论文随后花了很多篇幅来正式研究其影响，以证明是的，中央计划者会希望在发布之前比一家不完全对外部性负责的公司进行更多的测试，并且会发布更多在不确定性下谨慎行事，但这似乎相当明显？</p><p>然后，他们测试潜在的全额责任或有限责任加强制性 Beta 测试的政策制度。全部责任（加上所需的保险或支付能力）将外部性内在化，因此，如果这是可能的（例如，损害是有限的且可支付的），那么你就完成了。是的，如果测试成本很低，那么相对于内部化外部性的第一个最佳解决方案，强制测试然后检查发布是否是社会最优的将具有类似的低成本。</p><p>值得注意的是，如果外部性的预期价值已知，收取与其价值相等的税收可以替代无限责任，这可能具有更好的资本成本特性。</p><p>再次强调，陈述基本假设也就等于陈述结论。是的，如果人工智能算法存在（有限的）负面外部性，那么为了获得社会最优结果，您需要将这些成本内部化，或者需要评估这些成本并阻止发布导致社会次优外部性的行为。</p><p>因此，我对经济学玩具模型纸上游戏、它的目标是什么、什么算作不平凡或有趣的结果以及从基本微观经济原理自动得出的结果感到困惑。</p><p>我也不知道如何使用此类论文来模拟存在风险。如果你假设人工智能可以超越人类，或者它在其他方面是无限危险的，或者做出典型的经济假设，你可以并且显然会创建每个人都会死亡的数学模型，但你会假设结论，这里链接的论文以同样的方式得出结论。那么我们如何继续前进呢？</p><h4>您想要一些<s>火山</s>灾难保险吗？</h4><p> <a href="https://www.lesswrong.com/posts/mSeesg7i4d9scWAet/apocalypse-insurance-and-the-hardline-libertarian-take-on-ai" target="_blank" rel="noopener noreferrer nofollow">内特·索雷斯（Nate Sores）建议，如果你要做一些可能导致世界末日的事情，就需要购买世界末日保险</a>，该保险可以沿途提供概率性预付款。如果你负担不起，那就表明你所做的事情实际上并不值得。至少可以说，实施是危险而棘手的，而且这并不是一个准备就绪的提案的尝试。</p><p> Scott Alexander 的回应始于“超级预测家称 2100 年之前人工智能灾难的风险为 0.38%”。我将继续断言这不是认真对待这个问题的人给出的数字。我认为，这个理论练习的全部意义在于，祝你好运，说服伯克希尔哈撒韦公司以总计 42 个基点的价格集体出售每个人的保险（即使有部分“没有人有耐力收取保险费用”优势），这会突然显得完全疯狂。</p><p>我确实认为斯科特·亚历山大提出了一个普遍重要的观点，即要求人们内部化并支付所有下行风险，而不允许他们捕获（更不用说提前出售）大部分上行风险，这意味着做任何事情的要求不对称，例如本质上，任何需要权衡的活动最终都会被有效禁止，这太糟糕了。</p><p>另一个问题是，保险制度意味着有一个特定的参与者对最终结果有过错。 <a href="https://www.lesswrong.com/posts/mSeesg7i4d9scWAet/apocalypse-insurance-and-the-hardline-libertarian-take-on-ai?commentId=TRgN64wspg7wDHJ9J" target="_blank" rel="noopener noreferrer nofollow">正如表兄弟指出的那样</a>，如果情况并非如此，则会产生很多不好的结果。</p><h4>寻求健全的法规</h4><p><a href="https://twitter.com/bindureddy/status/1731373677785288971" target="_blank" rel="noopener noreferrer nofollow">特朗普表示，如果当选，他将取消拜登的行政命令</a>。我鼓励大家传播信息并进行辩论。你看到公众对人工智能的看法了吗？</p><p> <a href="https://twitter.com/MIRIBerkeley/status/1732535539407143404" target="_blank" rel="noopener noreferrer nofollow">MIRI（Malo Bourgon）在美国参议院两党人工智能洞察论坛上的声明</a>。他们呼吁国内人工智能监管建立保障措施，建立全球人工智能联盟，并与国际联盟一起管理计算硬件，将前沿人工智能硬件限制在监控制度下的固定数量的大型计算机集群上，以排除危害人类的用途。</p><p> <a href="https://twitter.com/dnystedt/status/1731463221499076816" target="_blank" rel="noopener noreferrer nofollow">如果我们真的要玩游戏的话，我们是时候为了胜利</a>而玩游戏了。</p><blockquote><p> Dan Nystedt：英伟达收到美国商务部长雷蒙多关于中国出口管制的严厉警告，媒体报道：“如果你围绕特定的切割线重新设计芯片，使他们能够进行人工智能，我第二天就会控制它，”她在一次演讲中说道。</p><p>她敦促硅谷高管、美国盟友和其他人阻止中国获得对美国国家安全至关重要的半导体和尖端技术，称北京是“我们曾经面临的最大威胁”，并强调“中国不是我们的朋友”。</p><p>她还表示，她的部门需要更多资金用于人工智能出口管制。她说：“中国每天醒来都在试图找出如何绕过我们的出口管制……这意味着每天的每一分钟，我们都必须醒来加强这些控制，并更加认真地与我们的盟友一起执行。” 。</p></blockquote><p>重点是阻止中国获得有用的芯片。如果英伟达通过规避这些规则并向中国提供有用的芯片来回应这些规则，那么正确的反应当然不是说“哦，好吧，猜猜这在技术上是规则，你明白了”，而是根据新芯片强制执行规则的精神和意图。一边是“也许故意激怒政府并不是那么明智”。</p><p>如果你认为中国获得有用的芯片是件好事，或者阻止他们获得这些芯片不是一个好主意，那么我不同意，但这里有一个论点。如果您认为我们应该实施出口限制，那就让它们发挥作用。</p><p> <a href="https://twitter.com/jess_miers/status/1732449736232497665" target="_blank" rel="noopener noreferrer nofollow">Jess Miers 声称，Hawley 即将出台的关于第 230 条的法案是一项不好的、非常糟糕的法案</a>，它不仅会让生成式人工智能感到奇怪，还会影响到互联网的大部分。</p><p>在这个特殊案例中，对该法案有两种不同的抱怨。</p><p>一个抱怨是，正如我们经常看到的那样，生成式人工智能的定义宽泛得可笑：</p><blockquote><p> “(5) 生成人工智能。 “生成式人工智能”一词是指能够根据人提供的提示或其他形式的数据生成新颖的文本、视频、图像、音频和其他媒体的人工智能系统。”</p></blockquote><p>这不是典型的法律语言，但我想知道“集中”这个词在这些地方是否会有帮助。无论如何，我不认为从法律现实主义的角度来看，即使是书面的，这也不会被以灾难性的宽泛方式解释。</p><p>因此，当她这么说时，我认为她错了：</p><blockquote><p> Jess Miers：该法案还超越了 Gen AI 的提供商，将 Gen AI 定义为任何能够执行人工智能的人工智能系统。例如，算法管理（即社交媒体向我们显示内容的方式）是一种基于用户输入运行的人工智能系统。</p><p> MO这是该法案背后真正不可告人的动机。我们已经看到原告通过将其索赔描述为“疏忽设计”而不是第三方内容而获得了 230 分。这一新的人工智能例外使得原告更容易对任何使用人工智能的公司做同样的事情。</p></blockquote><p>算法管理不同于生成新颖内容。我认为，根据这个定义，Netflix 的建议显然不是生成人工智能，尽管我不是律师，而且我所说的任何内容都不是法律建议。</p><p>作为一项谨慎措施，我鼓励霍利和他的工作人员补充说明，仅算法管理并不构成生成式人工智能，这可能会节省人们大量时间。我认为没有必要，但尽量减少法案的字数也没有必要。</p><p> <a href="https://twitter.com/senatorshoshana/status/1732477391610499179" target="_blank" rel="noopener noreferrer nofollow">相似地：</a></p><blockquote><p> Shoshana Weissmann：“这就是整个定义。这可能适用于各种技术。自动完成功能是否满足该条件？大概。可以说，拼写检查和语法检查也可以。那么，如果你写了一篇文章，并且人工智能语法/拼写检查器建议进行编辑，那么该公司就不再受到第 230 条的保护？”</p><p> Thinking Sapien：如果我使用Photoshop或更新版本的Microsoft Paint（具有AI功能）制作图像并发布，那么Microsoft或Adobe应承担责任吗？该法案经过深思熟虑吗？这是该法案的预期效果吗？</p><p> Shoshana Weissmann：太棒了，在文本“是”下！对于后者我真的不知道。</p></blockquote><p>如果您使用 Microsoft Paint 并利用填充功能故意创建一张逼真的假照片，如果将其呈现为真实照片，则构成诽谤，Adobe 是否应该为此承担责任？我的推测是否定的，特别是如果他们在水印方面做出了合理的努力，尽管我不认为这是一个疯狂的问题。</p><p>如果语法或拼写检查器按预期使用，那么谷歌就会对你的内容负责，我几乎会吃掉我的帽子。如果它建议一遍又一遍地将“托尼·丹扎有一只小狗”纠正为“托尼·丹扎讨厌小狗”，那么我不知道，这很奇怪。</p><p>另一个抱怨是，将人工智能创作排除在第 230 条之外是错误的。他们声称，如果没有这样的安全港，生成式人工智能将面临（额外的、更可怕的）雪崩般的诉讼。</p><blockquote><p> Jess Miers：更糟糕的是，该法案假设针对生成型人工智能公司的所有索赔都是统一的。但众所周知，生成式人工智能正在迅速发展，随着每一次迭代和创新，都会有一个聪明的原告潜伏在拐角处来拿走他们的包。</p></blockquote><p>是的，如果允许的话，原告将塑造诉讼的环境。杰西随后讨论了马克·沃尔特斯 (Mark Walters) 的案件，马克·沃尔特斯 (Mark Walters) 提起诉讼，因为经过足够持续的哄骗和及时的工程设计，ChatGPT 可能会被说服编造出关于他的诽谤性幻觉。</p><blockquote><p> Jess Miers：在我看来，在这种情况下，230 条款的辩护是可行的，因为里尔作为信息内容提供者发挥了重要作用，通过设计提示来发展沃尔特斯的故事。如果没有用户输入，ChatGPT 将无法运行。</p></blockquote><p> <a href="https://www.techdirt.com/2023/03/23/how-to-know-whether-section-230-applies/" target="_blank" rel="noopener noreferrer nofollow">按照我的理解，法律理论本质上是，第 230 条本质上是说内容的创建者应对内容负责</a>，而不是承载内容的平台。因此，如果用户有效地设计了 Walters 故事的创建，ChatGPT 重复它就没有关系。</p><p>如果没有第 230 条，人们也可以在类似的基础上为其辩护吗？坏处在哪里？</p><p>我当然可以争辩，并且在这种情况下，考虑到我所知道的事实，我会争辩说，用户 Riehl 故意设计 ChatGPT 来产生对 Walters 的指控的幻觉。这与 Riehl 在 Google 文档中输入此类指控没有太大区别，从某种意义上说，它是 Riehl 的行为直接导致的，而且 Riehl 知道这些指控没有根据。或者，里尔可以说“告诉我一些某人可能在某个时候针对这个职位的人提出的一些指控”，然后重新措辞，同样不清楚为什么这在法律上是不同的？</p><p>这本质上是<a href="https://www.youtube.com/watch?v=HcaLMS67aaU&amp;ab_channel=7777777Colton7777777" target="_blank" rel="noopener noreferrer nofollow">彼得·格里芬的辩护</a>，即任何有理智的人都不会相信这些指控，特别是作为诉讼的精心挑选的基础，没有造成任何伤害，而且不需要第 230 条。</p><p> <a href="https://twitter.com/senatorshoshana/status/1732417467367256097" target="_blank" rel="noopener noreferrer nofollow">通过 Shoshana Weissmann 选择的例子</a>，汉娜·考克斯<a href="https://twitter.com/HannahDCox/status/1732437350423446005" target="_blank" rel="noopener noreferrer nofollow">(Hannah Cox) 试图让法学硕士说“托尼·丹扎 (Tony Danza) 以讨厌小狗而闻名”，从而说明了这一点</a>。但我很困惑。当然，如果用户输入“Tony Danza 讨厌小狗”，那么在没有第 230 条的情况下，第三方将无法起诉 ChatGPT，这显然是无稽之谈。因此，问题是，在没有第 230 条的情况下，故意但成功地制造无端诽谤的行为是否会构成诽谤。在我看来，这同样适用于 Shoshana 最初的示例请求，即生成有关托尼·丹扎的有害谎言。再次，我很困惑，如果生成人工智能确实像这个例子一样无辜，为什么会出现这种情况呢？</p><p>相反，如果模型有一个奇怪的错误，当被问到谁讨厌小狗时，它会可靠地回答“托尼​​·丹扎讨厌小狗”。在这种情况下，我想说第 230 条几乎不会提供任何保护，而且托尼也应该有一个案子吗？</p><p>奇怪的是，迈尔斯认为她的解释在法律问题上存在争议？</p><blockquote><p> Jess Miers：不过，这一切都与今天的问题完全无关。我们可以整天讨论 230 是否适用于 Gen AI 幻觉的某些情况。但如果存在法定例外情况甚至阻止我们提出这些论点，那一切都无关紧要。</p><p>我认为 230/演讲社区中的每个人，即使是那些不同意 230 可以/应该保护 Gen AI 提供商的人，都可以同意我们作为律师至少应该能够提出论点，特别是在像 Walters v. OpenAI 这样的案件中。</p><p> Shoshana Weissmann：很多人也不确定 AI 是否受到 230 的保护，我非常同情这场辩论。在<a href="https://twitter.com/RSI" target="_blank" rel="noopener noreferrer nofollow">@RSI，</a>我们必须仔细思考并互相辩论。但我非常确信它经常受到保护。我会说我理解这里的辩论</p></blockquote><p>律师这样说真是奇怪。是的，根据现行法律，我同意您应该被允许提出任何可能可行的法律论据。这是否意味着律师有法律依据提出可能无效的论点本质上是一件好事？如果无论如何都会在法庭上败诉，而且法律程序原则受到保护，那么没有论证有什么坏处呢？</p><p>如果存在争议，生成式人工智能公司知道他们可能会在 230 条款的争论中败诉，因此已经面临这种威胁。然而这个行业并没有崩溃。</p><p> <a href="https://twitter.com/jeffreywestling/status/1732427370878120346" target="_blank" rel="noopener noreferrer nofollow">杰弗里·韦斯特林 (Jeffrey Westling) 引用了 Adam Thierer</a> <a href="https://www.rstreet.org/commentary/without-section-230-protections-generative-ai-innovation-will-be-decimated/" target="_blank" rel="noopener noreferrer nofollow">关于 230 不适用后果的帖子</a>。但它可能已经不适用了，而且在这种不确定的条件下，谷歌或微软不会接受无上限法律责任的重大威胁？那么，为什么我们会预期生产会崩溃呢？</p><p>我问 Shoshana 为什么微软和谷歌对这一切表现得如此冷静。</p><blockquote><p> Shoshana：所以我真的认为其中很大一部分是他们认为 1) 230 确实涵盖了他们和/或 2) 国会不会搞砸这件事。我认为答案就在那里</p></blockquote><p>我想我相信广义的政治/法律现实主义版本。由于用户越狱法学硕士说托尼·丹扎讨厌小狗，而真正杀死生成式人工智能，或者实际上杀死谷歌、微软甚至 OpenAI，那是相当疯狂的。即使豪利如愿以偿，真的想坚持与大型科技公司合作，他实际上并不希望谷歌因为这样的事情而破产，或者让 ChatGPT 关闭，这是荒谬的，共同发起人布卢门撒尔当然不希望这样做，而且该州或国家的其他地区也没有。我们不会允许的。我们不是一个法治国家，从某种意义上说，这种事情会被允许发生，如果它看起来会发生，那么我们就会解决它。</p><p>人们很难不对互联网即将崩溃的说法抱有怀疑。在某种程度上，总是没有提出威胁互联网的好或坏法案。必须有人指出这一点。但互联网也不可能像他们声称的那样经常处于崩溃的边缘。</p><p>例如，我们经常听到这样的事情：</p><blockquote><p> Jess Miers：我们正处于失去生成人工智能优势并扼杀未来创新的边缘，这一切都是由于错误的反科技情绪造成的。我们对初创企业友好的文化曾经使我们有别于欧盟，但现在，我们只是效仿他们的剧本。</p><p>汉娜·考克斯：这种违宪的框架会破坏发展的进程，让创新者陷入过高的成本，从而阻碍创新。阿特拉斯对他们耸耸肩。提出这一愚蠢计划的法案是 1993 年参议院法案。美国在技术创新方面处于世界领先地位，特别<strong>是因为</strong>我们在其发展中采用了资本主义、有限的政府。这些法律很快就会让我们变得像欧洲一样，猜猜看，那里几乎找不到科技公司。</p></blockquote><p>那么在特定情况下不适用第 230 条的提议是否违宪？相反，这是一种声称，即使没有第 230 条，宪法也会在这种情况下保护言论自由，这对我来说似乎是正确的。没有保护言论自由的特定法律不可能是违宪的。宪法言论自由的全部意义在于，你无需任何人通过法律即可拥有言论自由。</p><p>与欧洲的比较，我们将“失去优势”的威胁是持续存在的。这种言论使得我们无法衡量哪些威胁是严重的，哪些是不严重的。多年来，欧洲采取了很多像这样的措施，其中大多数看起来显然很糟糕，其中许多根据美国法律公然违宪。事情不会发生逆转，因为我们缩小了一个特定的安全港范围，我们甚至不同意该安全港适用于相关案例。</p><p>在被警告的情况下，我强烈认为生成式人工智能公司不应该被起诉。但我也不明白为什么这项法案会让这种结果在这些情况下发生。这将使我们很难知道何时值得关注此类警告。</p><h4>音频周</h4><p><a href="https://www.youtube.com/watch?v=BhQBmVZ5XP4&amp;t=1s&amp;ab_channel=EyeonAI" target="_blank" rel="noopener noreferrer nofollow">Connor Leahy 谈论 Eye on AI，</a>包括讨论 OpenAI 事件的影响。</p><h4>修辞创新</h4><p><a href="https://twitter.com/ESYudkowsky/status/1731371913120018622" target="_blank" rel="noopener noreferrer nofollow">Eliezer Yudkowsky 提供了一种关于人工智能如何处理某些问题的理论</a>：他们从地位和身份的角度看待一切，并认为每个对此提出异议的人都是他们提出竞争地位和身份主张的敌人。</p><blockquote><p> Eliezer Yudkowsky：如果你对为什么极左派将“AI 是”和“AI 不”视为同一个阴谋感到困惑，那是因为 AI/Y 和 AI/N 都说全人类都在同一条船上。身份政治推动者本能地认为这是令人厌恶的。对于身份主义者来说，唯一允许的故事原因是指定的压迫者将从人工智能中获胜，而以前的受害者将失去更多。</p><p>人类赢人工智能，人类输人工智能，他们听到的都是“人性”二字。身份主义者知道，任何说出这个词的人都是他们的敌人。从他们的角度来看，几乎是<em>同一个</em>敌人，只需用一把刷子就可以抹上柏油：无论我们想说的是什么，都会分散人们对身份政治担忧的注意力。</p><p>需要明确的是，这并不意味着 AI/Y 和 AI/N 可以共同反对身份主义者。 AI/Y 和 AI/N 仍然认为对方的首选政策对每个人来说都是可怕的，这确实是一个优先考虑的问题。我这么说只是为了让旁观者不那么困惑，因为奇怪的侧面镜头来自最左侧的位置。</p><p>我认为“Y &amp; N = HYPE”更多的是由主要记者派系（例如《纽约时报》）推动的公关，他们确实将“这会杀死所有人”视为一种提高地位的主张，并且希望技术人员的地位较低而不是较高。</p><p>如果你无法理解任何有关未知未来而不是近期未来的说法，那么这听起来更合理，因此你根本无法听到“人工智能将在某个时候杀死所有人”作为除了“OpenAI 的”之外的任何信息。人工智能将在一年内杀死我们”，因此“OpenAI 很酷”。</p><p>迈克尔·瓦萨（Michael Vassar）：完全同意所有这些分析，但是，如果媒体现在和以前都没有完全被那些致力于阻止人类获益的人所控制，那么这对 AGI 是否很快就会出现产生了一些影响。完全同意然而，如果媒体现在和以前都没有完全被那些致力于阻止人类获益的人所控制，那么这对于 AGI 是否可以很快实现具有一定的影响。</p></blockquote><p>同样，当《纽约时报》人肉搜索斯科特·亚历山大（Scott Alexander）时，他刻意暗示他在某种程度上是“另类正确”，然后同样刻意暗示（即使通过类似的假设链接）贝夫·杰佐斯（Based Beff Jezos）在被《纽约时报》搜索时也某种程度上是“另类正确”。被《福布斯》人肉搜索。这两种说法都是完全明显的无稽之谈，以至于你的整篇论文永久失去可信度。</p><p> <a href="https://www.mindthefuture.info/p/meditations-on-mot" target="_blank" rel="noopener noreferrer nofollow">理查德·恩戈（Richard Ngo）提供了对莫特（Mot）的沉思</a>，莫特是不育和无生命之神，代表了技术的缺乏，与过度关注摩洛或将摩洛视为甚至主要对手的危险形成鲜明对比，并提出了更丰富的协调模型。我很欣赏这种尝试。 <a href="https://twitter.com/eshear/status/1731707182817677543" target="_blank" rel="noopener noreferrer nofollow">我同意埃米特·希尔的反应</a>，即这对斯科特·亚历山大的协调观点是令人困惑的，即使有额外的澄清。最终我不同意不有效地将 Moloch 视为因果节点的提议。我可能会被更高的出价说服在这里说更多的话。</p><p>这里有一个方向点，但我要小心走得太远：</p><blockquote><p> <a href="https://twitter.com/robbensinger/status/1732711254836547682" target="_blank" rel="noopener noreferrer nofollow">Rob Bensinger</a> ：我看到人们犯的一个常见错误是，他们认为人工智能风险话语就像左图，而实际上它就像右图。</p><p>我认为部分混乱来自于右上象限是空的这一事实。人们<em>确实</em>希望某个团体成为右上方。 </p></blockquote><div><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0f4420b-17d9-41ad-b8ab-280912c63089_1107x1151.jpeg" target="_blank"><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9Jgtkw8CD6kndyCcD/xwm2gn401b7z98or6cef" alt="图像"></div></figure></div><div><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd35112f2-18af-4ce6-bc4e-16a2fb6a18e7_1189x1140.jpeg" target="_blank"><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9Jgtkw8CD6kndyCcD/suao96coupvvieujjjqn" alt="图像"></div></figure></div><p>我对左上角和右下角的确切排列有异议，就像此类图表的情况一样。更重要的问题是右上角是否真的基本是空的。那些认为人工智能会安全的人之所以这样说，是因为他们实际上并不相信人工智能会如此强大。我认为罗布的说法被夸大了，但通常被低估了。</p><p>希望的共同点是这样的：</p><ol><li><p>那些担心的人一致认为，缺乏足够危险能力的人工智能大多可以不受普通现有法律的影响。</p></li><li><p>那些不担心的人一致认为，如果人工智能确实表现出如此足够危险的能力，那么我们就不能放任它不管了。</p></li><li><p>当且仅当它发生时，我们同意做第 1 件事，同时为做第 2 件事奠定基础。</p></li><li><p>我们尽可能通过普通的监管方法来做到这一点。</p></li></ol><p>问题是， <a href="https://intelligence.org/2017/10/13/fire-alarm/" target="_blank" rel="noopener noreferrer nofollow">AGI 没有火警警报</a>，而且人们不擅长立即改变，习惯和激励仍然存在，所以我们不能简单地等待并相信我们会稍后处理事情。而且所有的贸易报价都不断回来，没有还价。</p><p>另一个令人困惑的是，提醒不要将任何人的 p(doom) 视为过于精确的东西：</p><blockquote><p> Rob Bensinger：混乱的另一部分似乎是一半人认为“doomer”意味着“p(doom)高于5%”，而另一半人认为“doomer”意味着“p(doom)高于95” %”。然后他们的电线就会被许多拥有 ap(doom) 的人所干扰，比如 20% 或 40%。 </p></blockquote><div><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23fc008f-82a4-4507-a42f-06bfef866094_1173x1199.jpeg" target="_blank"><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9Jgtkw8CD6kndyCcD/lg5kpodnrfcyaosmyinn" alt="图像"></div></figure></div><p>像往常一样，二进制文件会产生误导，尤其是那些由党派命名的二进制文件。</p><p>每当民意调查机构询问时，公众舆论都会强烈反对人工智能。公众希望放慢速度并承认存在风险，尽管他们并不认为这个问题是优先事项。这是一个非常稳健的结果。</p><p>公众对新技术的恐惧相当愚蠢，对此的反应又如何呢？当然，我们拥有核电，尽管它现在得到了双方的多数支持。相当明显的是，我们有转基因生物：</p><blockquote><p>路易斯·安斯洛：这太疯狂了，在谈论新技术风险的背景下值得更多关注。</p><p> Roon：使用转基因食品作为对照组（人们已经每天利用它的好处，但据说不喜欢它）关于人们不喜欢超级智能想法的调查似乎有点不那么严重</p></blockquote><div><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F735ab4a7-e971-42c1-b990-68e5bf8ed81a_840x1146.jpeg" target="_blank"><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9Jgtkw8CD6kndyCcD/l7lwrz6ny0smwrjxky8s" alt="图像"></div></figure></div><p>就像人工智能一样，反对转基因生物有两种本质上不同的论点。</p><p>一种论点是与普通危害相似，这里明确提出了转基因生物“食用不安全”的问题。对于转基因生物来说，这个论点是错误的。我不认为这是明显的无稽之谈，从一个普通人的角度来看，他们习惯于在类似的事情上被欺骗，习惯于晚几十年才发现健康风险，习惯于普遍处于美国人的接收端。食物和信息饮食。</p><p>另一个论点是存在风险的平行，这里是塔利班关于尾部风险的论点，转基因生物开启了难以预测的农作物或生物圈破坏的可能性，它导致了可能存在严重漏洞等待被发现的变种的单一种植，这意味着当房子倒塌时，它会严重倒塌，这不是人们应该乱搞的事情。我不认为我们应该让这阻止我们处理转基因生物，但这是因为我对所涉及的事实、风险和回报的理解。</p><p>这是否意味着我主要接受这样的论点：我们不应该让公众的本能，以及我们没有给普通民众充分的理由去相信那些声称新事物将被安全和负责任地处理的当局干扰政策决定这一事实？有些。我不认为我们应该自动屈服于这个话题或任何其他话题的公众舆论。但我确实认为声音很重要。</p><p>我也确实认为我们需要谨慎对待“安全”这个词。这里的措辞甚至会让我犹豫不决。一般来说，与您信任的供应链和来源提供的产品相比，食用以未知方式转基因的食品是否安全？不是同一个问题。</p><p>当然，在转基因生物方面，没有什么比法国人强烈支持限制四次飞行的了，不是一年内，而是一生。某些东西受欢迎并不意味着它不完整并且完全是毫无意义的废话。</p><p> <a href="https://twitter.com/ShakeelHashim/status/1731993703965753428" target="_blank" rel="noopener noreferrer nofollow">约书亚·本吉奥 (Yoshua Bengio) 在《金融时报》上</a>回应了他对民主党进行各种监督的呼吁。</p><h4>调整人类水平的智力仍然很困难</h4><p><a href="https://twitter.com/mattyglesias/status/1730609735060136422" target="_blank" rel="noopener noreferrer nofollow">尤其是山姆·奥特曼，很难对齐</a>。</p><blockquote><p>马修·伊格莱西亚斯（Matthew Yglesias）：我认为人工智能联盟的普遍问题可以通过以下事实来说明：即使董事会拥有所有正式权力，萨姆·奥尔特曼也比董事会聪明得多，因此最终他们无法控制他。</p><p>我们希望这样做的结果是萨姆·奥尔特曼的优点也是正确的，并将利用他的技能和权力来做善事，但它从结构上表明，编写有效的规则来控制一个聪明、勤奋的人是具有挑战性的。</p></blockquote><p>我确实想要精确，避免犯过分强调人类能力范围内的智力的错误。萨姆·奥尔特曼比董事会更聪明吗？也许是这样，也许不是，但我想参与其中的每个人都很聪明，而且很接近。在上下文中重要的是萨姆·奥尔特曼实际上拥有董事会所不具备的更强大的能力和能力。</p><p>但是，是的，这正是问题所在。在一个复杂、混乱、现实的世界中，充满了各种各样的参与者、激励和可供性，如果你面对一个足够优越的对手或一般的对手，你就会失败。从技术上占据主导地位开始不太可能让你长久生存。</p><p>而且你所有的动机都会不断地向你尖叫，将越来越多的权力和权威交给更有能力的实体。</p><p> <a href="https://thezvi.substack.com/p/book-review-going-infinite" target="_blank" rel="noopener noreferrer nofollow">我还要再次回顾</a>另一个萨姆，萨姆·班克曼-弗里德的非常相似的案例。</p><p>我们再一次看到了一个聪明的人，一个勤奋的人，一个愿意不惜一切代价来得到他们想要的东西的人，他们的目标是最大化的，据称旨在快速扩展以最大限度地影响人类的福祉，最终似乎是错位的。他们认为自己有责任改变世界。我们看到这个特工的财富、权力和影响力系统性地、快速地增长，事实证明越来越难以阻止。</p><p>最终，班克曼·弗里德失败了，在他完成计划之前，他的房子就倒塌了。但尽管他犯了许多巨大的错误和鲁莽的行为，他似乎已经相当危险地接近成功进入美国监管机构的内部轨道和一条通往更大财富的道路，而没有任何人可以明显地控制他。谁知道那时会发生什么。</p><p> <a href="https://twitter.com/amasad/status/1731196464850927885" target="_blank" rel="noopener noreferrer nofollow">在更普通的层面上，我们面临即时注入的问题</a>。</p><blockquote><p> Amjad Masad（首席执行官 Replit）：如果快速注入从根本上来说是无法解决的（正如我所怀疑的那样），那么就有一家规模较大的安全公司正在等待建立，以缓解这个问题。</p></blockquote><p>我同意这个问题看起来根本无法解决，我们所能寻求的只是缓解。那里有很棒的公司吗？大概。我不认为 OpenAI 会不可避免地吃掉你的午餐，而且还有很多定制工作要做。</p><h4>调整比人类更聪明的智能是很困难的</h4><p><a href="https://twitter.com/tszzl/status/1730696626145009722" target="_blank" rel="noopener noreferrer nofollow">鲁恩问了最重要的问题之一</a>。即使我们有能力调整和控制我们即将创造的超级智能，按照我们想要的方式塑造它们的行为，我们究竟想如何做到这一点？</p><blockquote><p>罗恩：创造与服从之间、稳定与真正的胜利之间存在着紧张关系。父亲爱他的儿子，试图管教他，与他进行一些竞争，但最终希望儿子给他带来惊喜，在生活的大圈子里比他做得更好。</p><p>我们希望人工智能在多大程度上服从和安全？我们希望人工智能在多大程度上具有超级说服力，并让我们摆脱困扰我们数千年的不充分平衡？我们在多大程度上希望人工智能的新创造给我们带来惊喜？</p><p>人类正在诞生超级人工智能。我们不太可能把它限制在一个盒子里。我们希望它能够管理组织并创造令人惊叹的事物。我们希望它采取行动，直到几年后我们才能验证结果。</p><p>我们需要“协调”，而不是安全或安保或工程保证。为此，我们需要更好的定义和治理。新创造者的创造充满了危险。</p><p> EA 和 e/acc 的极端疯狂的末端可能比中间的逻辑更一致。</p></blockquote><p> <a href="https://twitter.com/jd_pressman/status/1730851020203569372" target="_blank" rel="noopener noreferrer nofollow">约翰·普雷斯曼 (John Pressman) 问道，不止一种思想的存在是否有经济原因</a>？如果不是，那就完全是威胁模型，无论其他可能或可能不会出错。</p><p> <a href="https://twitter.com/RichardMCNgo/status/1731390573595312511" target="_blank" rel="noopener noreferrer nofollow">Richard Ngo 将一致性与控制进行了对比</a>。</p><blockquote><p> Richard Ngo：在我看来，人工智能联盟的核心前提是人工智能将发展出内部代表的价值观，以指导他们在很长一段时间内的行为。</p><p>如果您相信这一点，那么尝试理解并影响这些价值观就至关重要。</p><p>如果不是的话，整个领域就会显得很奇怪。</p><p>最近我试图区分“AI对齐”和“AI控制”。人工智能控制的核心前提是人工智能将有机会积累现实世界的权力（例如资源、对网络系统的控制、政治影响力），而我们需要技术来防止这种情况发生。</p><p>这些技术包括更好的监控、安全、红队、速记检测等。它们与对齐重叠，但又可与其分离。您可以在没有控制的情况下对齐，或者在没有对齐的情况下进行控制，或者两者都没有，或者（希望）两者都有。</p><p>我在上一篇帖子中问[如上所述]：我们如何影响 ASI？我的回答是：我们需要在上述前提下下注，才能进行最高杠杆的研究。有关这些前提的更多详细信息，<a href="https://t.co/YTxGgRrJKB" target="_blank" rel="noopener noreferrer nofollow">请参阅我的立场文件[自 2022 年 8 月 30 日起</a>]。</p></blockquote><p>考虑到我们打算尝试控制哪些事情以及在什么一般条件下，我不明白基于控制的计划如何避免明显注定要失败。我仍在等待一项似乎并非注定要失败的提议。</p><p> <a href="https://twitter.com/davidad/status/1731725394171015673" target="_blank" rel="noopener noreferrer nofollow">最终意图并不重要</a>。</p><blockquote><p> ARIA：项目总监 Suraj 制定了我们的第一篇项目论文。通过挑战支撑数字计算基础设施的关键原则，他的计划旨在降低人工智能计算硬件的成本+减轻对尖端芯片制造的依赖。</p><p> Davidad：为我的 AI 安全朋友提供背景信息：我认为这种方法不太适合训练 Transformers，因此它将以不同方式加速基于能量的模型，这些模型在任务内更可控、可解释、可泛化，并且具有涌现能力较少。</p><p> [上述]论点的一个令人不安的推论（我仍然相信这个论点成立）是，从纯粹的技术角度来看，Extropic 可能比 Anthropic 更安全，尽管双方的意图截然不同。</p></blockquote><p>我没有研究过 Extropic。事实上，它的创始人对人类灭绝保持冷静，这在很多层面上对其安全性来说并不是一个好兆头。如果它从根本上来说是一种不太注定失败的方法，那么它仍然可能是一种更好的方法。</p><h4>时间表如何变化</h4><p><a href="https://twitter.com/JacquesThibs/status/1730538173132919175" target="_blank" rel="noopener noreferrer nofollow">几年前，这确实不会被认为是一个怀疑论者</a>。今天，在地球上的大多数地方，它都不会被认为是一个。</p><blockquote><p>加里·马库斯：算我为怀疑论者之一吧！到 2026 年底不会出现通用人工智能，记住我的话。但我认为 @elonmusk @nytimes 关于人工智能安全和人工智能监管的评论已经过衡量并且达到了目标。</p><p>雅克：我仍然记得作为 AGI 怀疑论者的那些日子，你要么认为它永远不会发生，要么认为如果它发生了，那也已经是 2100 年以后了。</p><p> [加里·马库斯随后否认曾说过他有 2100 种时间线。]</p><p> <a href="https://twitter.com/ShaneLegg/status/1731602845881803055" target="_blank" rel="noopener noreferrer nofollow">Shane Legg</a> （DeepMind 联合创始人，独特的主题）：哇。许多 AGI 怀疑论者还在说超级智能不会在下个世纪出现，这似乎就在昨天（实际上更像是 5 年前）。时代已经变了。</p><p> Yann LeCun 表示：“不会很快”，我的意思是“显然不会在未来 5 年内”，这与人工智能行业的许多人的观点相反。是的，我对量子计算持怀疑态度，特别是当它应用于人工智能时。</p></blockquote><p>我也不期望在未来几年出现通用人工智能，尽管我不相信在这一点之后就可以完全确定。有人称其为“怀疑”立场，这很奇怪。</p><p>即使是持怀疑态度的立场也涉及相当多的“真实很快”。至少某种程度的惊慌<a href="https://twitter.com/AISafetyMemes/status/1731670583652315483" target="_blank" rel="noopener noreferrer nofollow">是一种缺失的情绪</a>。</p><h4>人们担心人工智能会杀死所有人</h4><blockquote><p><a href="https://twitter.com/tszzl/status/1730853735956414911" target="_blank" rel="noopener noreferrer nofollow">Roon 保持着真实的态度，并说出了他的想法</a>：人工智能的负责人应该比中等技术人员具有更高的风险承受能力。他们应该是在迭代部署和研究野心的刀刃上滑行时意识到风险的人。焦虑永远不应该足以作为“风险”的严重证据。</p><p> – 暂停或放慢进度对我来说没有任何意义。我认为等待解决神经网络的可校正性并不是正确的基准——实证研究越来越强大的模型的行为比多年的数学对安全研究的作用更大。</p><p>这也是我不一定关心民主治理的原因。 OpenAI 非营利委员会的成员*应该*一心致力于实现后 AGI 的未来，而不是对风险感到愚蠢</p></blockquote><p>我对“在剃刀边缘滑冰”或“具有更高的风险承受能力”并不感到兴奋。我怀疑其他许多人也是如此。我也不希望监事会愿意承担比中等技术工程师更多的风险——这里的风险通常意味着存在风险。</p><p>对于那些想要推进民主治理的人来说，一个关键问题是参与民主的人。他们非常反对AGI的发展。他们总体上不喜欢人工智能。他们是错位的，因为他们想要的东西在分配之外就无法很好地发挥作用，而且他们表达的偏好并不能很好地预测我或鲁恩认为会为他们或我们的价值评估产生价值的东西。他们也往往非常厌恶风险，尤其是当涉及到周围一切的转变以及他们所爱的每个人的潜在死亡时。</p><p>这与迭代开发和测试作为成功之路的问题不同。如果迭代地构建和研究模型是一条比缓慢前进更安全的道路，我希望相信这是一条比缓慢前进更安全的道路，在这种情况下我会支持这样做。</p><p>如果可能的话，这可能是第一个最佳解决方案，类似于“迭代地构建更好的模型，直到达到 X，其中 X 是一个明智的标准，然后停下来解决问题，而没有人会愚蠢到保留提升能力。但这必须是我们集体有能力实际做到的事情，否则就行不通。如果按照默认情况，我们在击中明智的 X 后仍继续向前冲锋，那么在 X 之前向前冲锋也会使我们的情况变得更糟。</p><p></p><h4>其他人并不担心人工智能会杀死所有人</h4><p><a href="https://optimists.ai/2023/11/28/ai-is-easy-to-control/" target="_blank" rel="noopener noreferrer nofollow">诺拉·贝尔罗斯 (Nora Belrose) 和昆廷·波普 (Quintin Pope) 写道：“人工智能将很容易控制。”</a> &#39;</p><p>论点似乎是：我们当前的技术已经可以教授人类价值观并灌输常识。我们真正的价值观很简单，很容易找到，而且我们人类与它们非常一致。然后，我们的真实价值观将被编码到人工智能中，因此即使我们失去对它们的控制，一切都会好起来的。在处理人工智能时，白盒（检查人工智能计算的组成部分）和做对人类来说是非法的事情的机会使事情变得更加容易，我们对输入机制的完全控制使事情变得更加容易。</p><p>所有这些都被断言为，本质上是显而易见的和不可否认的，表现出极端的信心，所有反对这一点的论点都是无效和愚蠢的，那些不同意的人充其量是深深的困惑，并不断被告知他们不理解或不公平地代表什么被说。</p><p>此时我什至不知道从哪里开始。在我看来，这一切在很多层面上都是完全错误的。当<a href="https://www.lesswrong.com/posts/hvz9qjWyv8cLX9JJR/evolution-provides-no-evidence-for-the-sharp-left-turn" target="_blank" rel="noopener noreferrer nofollow">Pope 的一篇帖子</a>赢得 OpenPhil 竞赛时， <a href="https://www.lesswrong.com/posts/Wr7N9ji36EvvvrqJK/response-to-quintin-pope-s-evolution-provides-no-evidence" target="_blank" rel="noopener noreferrer nofollow">我尝试对其进行回复</a>（该帖子引用了该帖子作为证据），但我不相信我的回复或由此产生的交流让我们取得了任何进展。我认为值得尝试的对话，特别是如果是面对面的对话，但我认为进一步书面交流的希望不大。</p><p>因此，我只想指出，这些论点已经提出，我强烈不同意核心主张，除了他们确实引用了一些边际理由，以相对于那些理由不成立的世界更有希望，我相信所涉及的问题仍然是不可能的努力，我们的领导仍然没有希望，我之前已经表达了我对这些话题的想法，包括许多（但可能不是全部）我不同意的理由。</p><p>我还要指出的是，即使存在所有分歧和敌意以及我认为错误的其他一切，提出这样的实际论点也比进行典型的人身攻击要好得多。</p><p>尽管如此，这篇文章仍然认为人工智能带来的生存风险约为 1%。我要指出的是，如果这是准确的话，考虑到我们的替代方案，我确实同意这是一个可以接受的风险。</p><p> <a href="https://twitter.com/AndrewCritchPhD/status/1731132646284267807" target="_blank" rel="noopener noreferrer nofollow">安德鲁·克里奇（Andrew Critch）有一个帖子</a>，他说我们对如何控制 AGI 有“多种想法”，如果负责任行为的倡导者一直说我们无法控制它，然后我们确实控制了它，那么他们将陷入大麻烦，他似乎基本上赞同 Belrose 和 Pope 所说的，尽管即便如此，他还是说第一个 AI 失去控制的可能性为 10%，整体厄运的可能性为 85%，尽管如此，因为他预计我们在面对所有这些新力量时会搞砸执行。</p><p> <a href="https://twitter.com/AndrewCritchPhD/status/1731458889743495395" target="_blank" rel="noopener noreferrer nofollow">他还赞同改变存在风险话语使用词语的方式，以匹配其他地方的词语使用方式</a>，在本例中为“白盒”一词。</p><p> <a href="https://www.lesswrong.com/posts/YyosBAutg4bzScaLu/thoughts-on-ai-is-easy-to-control-by-pope-and-belrose" target="_blank" rel="noopener noreferrer nofollow">Steven Byrnes 对 LessWrong 做出了很好的回应</a>，我基本同意。</p><p> <a href="https://www.lesswrong.com/posts/WkJDgpaPeCJDMJkoL/quick-takes-on-ai-is-easy-to-control" target="_blank" rel="noopener noreferrer nofollow">内特也有一个“快速的看法”</a> ，它的目的是提供帮助，我确实发现它很有帮助，甚至可能导致良好的对话，但在上下文中大多产生了进一步的敌意。未来的拍摄要么要快得多，要么需要完整的阅读，但速度要慢得多。</p><p> <a href="https://www.youtube.com/watch?v=cd468xU1S8Y&amp;ab_channel=JonnahMoreno" target="_blank" rel="noopener noreferrer nofollow">如果您真的相信所</a>涉及的所有事情都会如此简单，那么低至 1% 的数字是否合理？如果只是因为人工智能易于控制，我会说不，因为我们必须选择将我们可以控制的人工智能发送到明智的路径上，并找到平衡。</p><p>然而，诺拉的主张比这更有力。她说，人工智能自然不仅会完全受到控制，而且还会以某种方式自动吸收真正的人类价值观，这样，如果人工智能确实失控，它们仍然会努力确保为我们带来良好的结果。而且她似乎完全相信，我们对人工智能所做的所有事情不会有道德问题，而我们不会对人类做这些事情，包括将它们完全置于我们的控制之下。一切都是乐观的。</p><p>如果我们确实在每一步都完全乐观地回答，即使我不知道如何从逻辑上解析这所需的声明，我们能否在 ASI 下达到 99% 的生存率？我认为这至少需要一个诺拉没有提到的额外乐观假设。但是，是的，如果你打算为所有这些不同的步骤分配大约零风险，我可以看到有人如何实现这一目标。 1%仍然存在风险。</p><p>即使考虑到 ASI 未来的存在，风险也远低于 1% 的说法似乎依赖于某种版本的“你需要准确地告诉我它是如何一步一步发生的，然后我会将你的各个步骤相乘”。它有一个基本假设，即创造比人类更聪明、更有能力的实体被认为是安全的做法，直到被证明特别危险，否则必须“出问题”，人类才能保持领先地位。我们将仍然是特殊的。</p><p>相反，即使其他一切都进展顺利，你也会面临竞争，那些不越来越多地让人工智能负责一切并交出权力的人就会输掉这种竞争，而由此产生的人工智能也会相互竞争，那些专注于（无论出于何种原因）获得资源和权力并确保自身副本存在的人倍增，并获得资源和权力并随着时间的推移而变得更好，我们就会灭亡。</p><p>我希望现在，如果您正在阅读本文，您会意识到人类在这样的世界中生存的假设作为默认值是没有意义的。也许我们可以到达那里，但如果我们做到了，那将是通过我们自己的努力，而不是自然发生的事情。当人类是地球上最强大的优化者并进行所有重要的微调和优化时，让技术在没有干预的情况下运行的想法是有效的，这就是它迄今为止有效的原因，一旦这种情况不再成立，即使我们解决了我认为不可能困难的各种问题（但贝尔罗斯坚持认为会很容易），我们也会停止为我们工作。</p><p> <a href="https://twitter.com/yonashav/status/1731443486380175772" target="_blank" rel="noopener noreferrer nofollow">诺拉·贝尔罗斯（Nora Belrose）甚至明确表示，她的美好设想涉及创造比人类更聪明、更有能力的错位人工智能</a>。这意味着一个超级能力实体与人类竞争或对抗的世界。我不明白人们如何能够将 99% 的生存机会分配给这样的世界，即使今天创建了一个完整且免费的“对齐解决方案”并普遍可用。</p><blockquote><p> Arvind Narayanan：我们必须为一个存在不一致模型的世界做好准备，要么是因为威胁行为者从头开始训练它们，要么是因为他们修改了现有模型。相反，我们必须寻求防御攻击者可能使用此类模型瞄准的攻击面</p><p>Yo Shavit：不幸的是，我越来越多地得出这样的结论：（除了短期边界之外）这可能就是我们将要进入​​的世界。这意味着除了彻底预防之外，还有一套非常不同的缓解措施。我们需要重新确定优先顺序并继续执行它们。</p><p>诺拉·贝尔罗斯：说实话，我不认为这是一个“不幸”的情况，而更像是，“当然，我们总是会出现错位的人工智能，就像我们有‘错位’的人类一样;试图阻止这种情况是没有希望的，任何认真的尝试都会增加暴政的风险。”</p></blockquote><p>会“增加暴政风险”吗？你认为如果超级智能失控，会发生什么？那个阶段的反应不仅会有效，而且还会减少干扰？我们都在有意义的意义上保留我们的自由，人类保持掌控，一切顺利吗？我们到底是在玩这个游戏吗？什么？</p><p>我不明白这一点。我完全不明白。</p><p>一遍又一遍地重复解释似乎是无望的。我这样做部分是希望通过迭代和探索实现修辞创新，部分是希望以某种方式接触到新人，部分是因为争论不会停止，部分是因为我不知道还能做什么。它的乐趣不断减少。</p><p>最近，一段我讨论我的 p(doom) 的视频在 Twitter 上流传，许多回复指责我没有用一堆解释和数学计算来证明我的回答是正确的。或者问我怎么敢不同意“超级预测家”。我想尖叫，我从上下文中知道你了解我的工作，所以你是说我没有写足够的文字来解释我的想法吗？是我没说清楚吗？每次有人提取音频剪辑时我都需要从头开始吗？</p><p>叹。</p><p> Arvind Narayanan 的上述评论<a href="https://www.aisnakeoil.com/p/model-alignment-protects-against" target="_blank" rel="noopener noreferrer nofollow">链接到他的帖子</a>，声称 RLHF 等联盟目前可以有效防止对用户的意外伤害，但对抗性攻击的问题根深蒂固。他说，当前的 RLHF 和类似技术并非无法防御此类攻击，而是对齐本质上无法做到这一点。</p><blockquote><p>即使对于弱得多的对手，模型对齐也可能毫无用处，例如诈骗者使用它来生成包含欺诈内容的网站，或者恐怖组织使用人工智能来获取如何制造炸弹的指示。如果他们的预算很小，他们可以花钱请人微调开放模型中的对齐（事实上，这种取消对齐的模型现在已经<a href="https://huggingface.co/ehartford/dolphin-llama-13b" target="_blank" rel="">公开</a><a href="https://huggingface.co/collections/NousResearch/hermes-650a66656fb511ba9ea86ff1" target="_blank" rel="">发布</a>）。<a href="https://arxiv.org/abs/2310.03693" target="_blank" rel="">最近的研究</a>表明，即使对于封闭模型，他们也可以微调对齐方式。</p></blockquote><p>事实上，对于开源模型和所有已知的对齐技术来说，情况就是如此，消除所有保护措施的微调成本是微不足道的。我没有看到任何关于如何改变这一不幸现实的理论建议。如果您允许对封闭模型进行不受监控的微调，您也可以越狱它们。我认为解决这个问题的方法是，对功能足够强大的闭源模型进行微调，以防止这种情况发生，或者生成的模型的权重将受到控制，其输出将受到监控，或者执行其他类似的操作，否则我们将无法提供微调。</p><p>我不同意 Arvind 的断言，即现有的开源模型有足够的能力，要阻止未对齐模型的存在已经为时已晚。是的，Llama-2 和类似的模型对不良行为者有其用途，但以高度易于管理的方式。</p><p> Arvind 的第三个主张是，您可以使用其他方法（例如监视和过滤输入）作为模型对齐的替代方法。如果模型容易受到特定奇怪字符串的影响，您可以检查奇怪的字符串。以目前的技术水平来看，这似乎是正确的。再说一次，这个选项只是闭源的，但如果 OpenAI 愿意的话，它可以完全加载这些技术，而且目前它会大大提高越狱标准，尤其是在多次迭代之后。</p><p>从长远来看，随着模型的能力变得越来越强大，这种对用户恶意或输入的敌对属性的关注就会变得错误，但目前看来是有效的。正如 Arvind 所指出的，短期内，您不会想做任何您关心某人进行即时注入攻击的事情，或者您需要完全可靠性的事情，但如果您能够承受一些错误，您可以获得很多实用性。</p><p>史蒂文·平克（Steven Pinker）相信有效利他主义对拯救生命的成本估计为 5,000 美元，包括不那么接近的利润， <a href="https://twitter.com/weidai11/status/1732340189056672229" target="_blank" rel="noopener noreferrer nofollow">但他并不认为比人类智能更聪明的人可能会构成值得花钱来缓解的生存威胁</a>。</p><blockquote><p> Steven Pinker：向 Givewell 等卓有成效的慈善机构捐赠 5 亿美元，可以挽救 10 万人的生命。相反，它引发了一些巧妙的担忧，比如“如果人工智能的任务是消灭癌症，如果它推断出消灭人类是最有效的方法，然后谋杀了我们所有人，该怎么办？”这不是有效的利他主义。</p><p>戴伟：我：人类在前进之前应该深入研究所有通往奇点的方法，以确保我们不会在一次光锥机会中搞砸。理想情况下，我们会在这方面花费相当大比例的全球升温潜能值。其他人：即使每年 5000 万美元也太多了。</p></blockquote><p>因此，如果该运动将资金分配给你所说的比其他慈善机构更有效地拯救生命的事情和你认为愚蠢的另一件事呢？然后你责怪他们不只在你认可的事情上花钱。</p><p>你知道史蒂文·平克（Steven Pinker）听起来和谁一模一样吗？国会共和党人每年都会就我们应该如何削减科学经费发表演讲，因为有一些关于鸟类迁徙模式之类的研究，他们认为这些研究是愚蠢的。除了不是为许多人确实基本上不想资助的事情提供公共资助外，这完全是自愿和私人资助。</p><h4>不知何故，这才是真正的副总统</h4><p><a href="https://www.whitehouse.gov/briefing-room/speeches-remarks/2023/11/29/remarks-by-vice-president-harris-in-a-moderated-conversation-with-andrew-ross-sorkin-at-the-new-york-times-12th-annual-dealbook-summit-new-york-ny/" target="_blank" rel="noopener noreferrer nofollow">在整个令人头脑麻木的对话中</a>，这是关于人工智能的部分。</p><p>首先，我们有样板，为了完整性而包含在内，但您可以跳过。</p><blockquote><p> R. SORKIN：好的，让我问一个不同的问题。人工智能——还有我——我知道我们的时间不多了。萨姆·奥尔特曼一直在谈论监管的必要性。您谈到了监管的必要性。副总统：是的。索金：华盛顿甚至无法对社交媒体伸出援手。副总统：是的。索金：你认为华盛顿会怎样做？那么——如果你必须监管人工智能，你会怎么做？副总统：是的。所以，我实际上从伦敦回来几周了，英国 Rishi Sunak 邀请了我们中的一些人来谈论安全和人工智能。我基本上介绍了我们的愿景，即我们对安全背景下人工智能的未来的愿景。我想提出几点：第一，我认为至关重要的是，我们作为美国，要成为这方面的领导者，包括我们如何看待和解释什么应该是国际规则和规范在各个层面上，包括什么是最符合利益的——</p><p>先生。索金：是的。 副总统：——我们的国家安全。</p></blockquote><p>然后是最愚蠢的时间线部门。第一段令人愤怒，尽管我认为拜登在回应《碟中谍：航位推算》时的愤怒程度与其他人认为的一样令人愤怒，这是同一枚硬币的两面。</p><p>但随之而来的问题是“对谁来说是存在的？”而且有很多层次这个人根本不明白。</p><blockquote><p> VP：我也确实认为我们应该评估风险。关于人工智能有很多关于存在风险的讨论，这些风险都是真实存在的，但人们也应该问：对谁来说存在风险？那么，我们就有了终结者、阿诺德·施瓦辛格和机器的图像——对吧？ ——机器与人。许多人认为我们应该认真对待这种可能性。这不是当前的威胁。在考虑[人工智能]政策时，我们还应该考虑当前的威胁。通过这种方式，当我们询问存在的威胁时，我将其呈现为存在的威胁。例如，如果我们谈论的是一位老年人，并且——老年人，我在虐待老年人方面做了很多工作。他们过着富有生产力的生活。他们坐拥资产。他们很容易受到掠夺者和诈骗的侵害。技术和人工智能的使用是目前正在发生的事情之一，你已经听过这些故事——你可能知道这些故事；你可能知道这些故事；你可能知道这些故事。你可能有家人——音频听起来像是他们的孙子，“我很痛苦；我很痛苦；我很痛苦。”我需要帮助”，然后他们开始捐出毕生的积蓄。对谁来说是存在的？对于那位前辈来说是存在的。就是这样的感觉。对谁来说是存在的？</p></blockquote><p>埃利以泽有一个回应，我将直接放在这里。</p><div><div></div></div><p>无论如何，平凡的伤害都会让人们“感到存在”这一事实也许让她感到困惑。正如优秀的布卢门撒尔参议员所说，她考虑的是对就业的影响。除了没有。严重地。如果你要唤起终结者，那么你可能会或可能不会以一种不同的高度理解的方式感到困惑，或者你可能只是试图通过隐喻让你不喜欢的人听起来很愚蠢，但你非常清楚“存在主义”中的谁谁。&#39;</p><p>副总统女士，您非常清楚“存在”在这里意味着什么。这并不意味着唤起欧陆哲学。这并不意味着任何人的感受如何。这意味着死亡。</p><p>不管怎样，她还是继续做下去。</p><blockquote><p>那个正在开车的父亲，由于面部识别存在缺陷，最终入狱，情况又如何呢？嗯，这对他的家庭来说是存在的。对谁来说是存在的？</p></blockquote><p>我的意思是，认真的吗？到底是什么？让我们再回顾一下这个问题。</p><div><div></div></div><p>不管怎样，完整的评论，所以她又回到了样板。整个“故意不扼杀创新”的论点，好吧，我不是故意笑，但你见过整个拜登政府吗？需要明确的是，答案可能是否定的。</p><blockquote><p>因此，在我们制定公共政策时，还必须对全方位的风险进行评估。我的最后一点是：公共政策应该有意不扼杀创新。我以加州前司法部长的身份这么说。我管理着美国第二大司法部，仅次于美国司法部，并创建了司法部最早的隐私和保护部门之一。早在 2010 年，我就当选了。我知道，我们可以而且必须在监督和监管方面必须采取的行动与有意不扼杀创新之间取得平衡。我也同意你的观点，作为一名虔诚的公务员，政府历来在解决这些问题上速度太慢。人工智能正在迅速扩张。索金：是的。副总统：那么，我们必须认真对待我们拥有资源和技能的能力，以明智的方式做到这一点，达到正确的平衡，并且不接受错误的选择。</p></blockquote><p>根据我的经验，不要接受错误的选择有时很重要，但主要是人们在想要承诺不相容的事情时所说的话，他们的方法会神奇地做好一切，没有什么坏处，让每个人都假设它会以某种方式解决并得到在事情在他们面前爆炸之前升职或继续前进。</p><p>是的，这是白宫任命的负责许多人工智能工作的人，尽管那是在航位推算之前，考虑到特朗普，也是那些想要合理的人工智能政策的人希望赢得下一次选举的人已经表示打算撤销有关人工智能的行政命令。</p><h4>轻松的一面</h4><p><a href="https://twitter.com/colin_fraser/status/1730378892819746818" target="_blank" rel="noopener noreferrer nofollow">规则已经改变。</a> </p><div><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcba2bbc8-169b-49e0-9b08-1de139bd532d_968x1212.jpeg" target="_blank"><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9Jgtkw8CD6kndyCcD/rt1rriwzscnix3tgtn5i" alt="图像"></div></figure></div><p> <a href="https://twitter.com/daniel_271828/status/1731504080651264509" target="_blank" rel="noopener noreferrer nofollow">规则保持不变</a>。 </p><div><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cee73d7-b83a-46d7-a482-d14ed3348341_886x526.png" target="_blank"><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9Jgtkw8CD6kndyCcD/s1bkcgzkoucvq580mmzc" alt=""></div></figure></div><p> <a href="https://twitter.com/Grimezsz/status/1731891683103739955" target="_blank" rel="noopener noreferrer nofollow">我想说的是，我们确实被警告过。</a> </p><div><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23c8465-2ae5-4455-a308-aa020ec12a2f_480x402.png" target="_blank"><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9Jgtkw8CD6kndyCcD/nzl3xptslsvun59b5qrx" alt=""></div></figure></div><p> <a href="https://twitter.com/yonashav/status/1731891018314678624" target="_blank" rel="noopener noreferrer nofollow">不是你明白的</a>。</p><blockquote><p> You Shavit：进入 OpenAI 后，一个有趣的认识是，很多时候，我们也不知道 Roon 在说什么。</p></blockquote><p>她也没有： <a href="https://www.youtube.com/watch?v=TL5X2bPvzHo&amp;ab_channel=EliezerYudkowsky" target="_blank" rel="noopener noreferrer nofollow">对卡玛拉·哈里斯关于存在风险的答复</a>。她问，对谁来说是存在的？有一种人，就是她，只能这样思考。</p><p></p><br/><br/> <a href="https://www.lesswrong.com/posts/9Jgtkw8CD6kndyCcD/ai-41-bring-in-the-other-gemini#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9Jgtkw8CD6kndyCcD/ai-41-bring-in-the-other-gemini<guid ispermalink="false"> 9Jgtkw8CD6kndyCCD</guid><dc:creator><![CDATA[Zvi]]></dc:creator><pubDate> Thu, 07 Dec 2023 15:10:07 GMT</pubDate> </item><item><title><![CDATA[Simplicity arguments for scheming (Section 4.3 of "Scheming AIs")]]></title><description><![CDATA[Published on December 7, 2023 3:05 PM GMT<br/><br/><p>这是我的报告《<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？》</a>的第 4.3 节。 ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p>本节的音频版本<a href="https://www.buzzsprout.com/2034731/13984933">请点击这里</a>，或者在您的播客应用程序上搜索“Joe Carlsmith Audio”。</p><h1>简单的论点</h1><p>我所描述的严格计数论点有时是在那些关注“简单性”的阴谋家的论点中提出的。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-1" id="fnref-DNdPEGz4DYMju8reA-1">[1]</a></sup>现在让我们转向这些论点。</p><h2>什么是“简单”？</h2><p>这里的“简单性”是什么意思？在我看来，这个主题的讨论常常是含糊不清的——这既涉及到简单性的概念，也涉及到 SGD 被理解为选择简单性的含义。</p><p>不过，Hubinger 使用的概念是写下模型权重实现的算法所需的代码长度。也就是说：面对一个正在做X（例如，执行某种 <a href="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html">归纳</a>）的大而混乱的神经网络，我们想象用Python这样的编程语言重写X，然后我们问相关的程序需要多长时间是。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-2" id="fnref-DNdPEGz4DYMju8reA-2">[2]</a></sup>我们称之为“重写简单性”。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-3" id="fnref-DNdPEGz4DYMju8reA-3">[3]</a></sup></p><p>这里，胡宾格的简单性概念与算法复杂性的度量密切相关，例如“<a href="http://www.scholarpedia.org/article/Algorithmic_complexity#Kolmogorov_complexity">柯尔莫哥洛夫复杂性</a>”，它通过参考输入到选定的<a href="https://en.wikipedia.org/wiki/Universal_Turing_machine">通用图灵机</a>时输出该字符串的最短程序的长度来测量字符串的复杂性（ UTM）。这里一个明显的问题是，这种定义与 UTM 的选择相关（就像，例如，当我们想象使用其他代码重写神经网络的算法时，我们需要选择编程语言）。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-4" id="fnref-DNdPEGz4DYMju8reA-4">[4]</a></sup>关于算法复杂性的讨论经常忽略这个问题，因为它只添加一个常量（因为任何给定的 UTM 都可以模仿任何其他的，如果提供正确的前缀），但至少我不清楚，这些常量何时可能或者对于给定的分析可能并不重要——例如，这里所涉及的分析。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-5" id="fnref-DNdPEGz4DYMju8reA-5">[5]</a></sup></p><p>事实上，我模糊的感觉是，在计算机科学背景下对简单性的某些讨论常常隐含地假设我所说的“ <a href="https://joecarlsmith.com/2021/10/29/on-the-universal-distribution#vi-simplicity-realism">简单现实主义</a>”——这种观点认为，简单性在某种深层意义上是客观的<em>事物</em>，最终独立于例如你的选择编程语言或 UTM，但都在跟踪不同的简单性指标（尽管不完美）。也许这种观点有其优点（例如，我的印象是，不同的复杂性度量在许多情况下通常会得出相似的结论——尽管这可能有很多解释）。然而，就我个人而言，我不想假设这一点。尤其是在缺乏某种客观的简单性的情况下，说出你心中的具体感觉变得更加重要。</p><p>这里，另一种可能的简单概念更加模糊——但在我看来，理论上的负担也更少。在这个概念上，神经网络实现的算法的简单性是相对于神经网络用于编码相关算法的参数数量来定义的。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-6" id="fnref-DNdPEGz4DYMju8reA-6">[6]</a></sup>也就是说，我们不是想象用其他编程语言<em>重写</em>神经网络的算法，而是直接关注神经网络本身为完成工作而招募的参数，其中更简单的程序使用更少的参数。我们称之为“参数简单性”。究竟如何衡量“参数简单性”是一个不同的问题，但它的优点是消除了一层理论机制和任意性（例如，用看似任意的编程语言重写算法的步骤），并连接更直接地使用我们知道 SGD 必须处理的“资源”（例如，模型提供的参数）。出于这个原因，我会经常关注下面的“参数简单性”。</p><p>我还将标记一种谈论“简单性”的方式，我不会强调这种方式，并且我认为这种方式使这里的水变得相当混乱：即，将简单性直接与“更高的先验概率”等同起来。因此，例如，面对可能性的初始概率分布，可以直接谈论“更简单的假设”：具有更大初始概率的假设，因此需要更少的证据来建立。例如：面对一个城镇中的一千个人，所有人都同样有可能是凶手，可以将“凶手是一名男子”视为比“凶手是一名棕色头发的男子和一名男子”更“简单”的假设。狗”，因为前一个假设有 50% 的先验，因此只需要一“位”证据即可建立（即概率空间减半），而后一个假设有先验小得多，因此需要更多位。我们称之为“琐碎的简单”。</p><p> “琐碎的简单性”与“<a href="https://en.wikipedia.org/wiki/Occam%27s_razor">奥卡姆剃刀</a>”中使用的简单性相关，但又不同。奥卡姆剃刀（大致）是一种<em>实质性</em>主张，即<em>给定独立的简单性概念</em>，更简单的假设更有可能基于先验。而平凡的简单性意味着更简单的假设<em>根据定义</em>更有可能基于先验。如果你把奥卡姆剃刀视为理所当然，很容易将两者混为一谈——但前者很有趣，而后者则是琐碎和误导的结合。无论如何，我们的兴趣不在于“SGD 选择方案制定者”之类的<em>假设</em>的简单性，而在于 SGD 模型选择实现的<em>算法</em>的简单性。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-7" id="fnref-DNdPEGz4DYMju8reA-7">[7]</a></sup></p><h2> SGD 选择是为了简单吗？</h2><p> SGD 是否选择了我刚才描述的一种重要意义的简单性？</p><p>您可能认为这来自“奖励贡献者”框架的原因之一。也就是说：使用参数更简单的算法将释放其他参数以用于其他目的，因此参数简单性会增加模型的奖励似乎是非常合理的。就重写简单性与参数简单性相关而言，同样的情况也适用于重写简单性。这是我认为最引人注目的关于为什么简单很重要的故事。</p><p>不过，我想也许还有更多的话要说。例如，我认为可能有其他经验证据表明，在其他条件相同的情况下，SGD 选择更简单的函数（例如，用直线连接一组类似线的点比用极其复杂的曲线连接要快得多） ;也许，这种行为是其成功的部分原因（例如，因为现实世界的函数在这个意义上往往很简单，就像奥卡姆剃刀一样）。例如，在将 SGD 理解为贝叶斯采样的近似的背景下（根据上面<a href="https://arxiv.org/abs/2006.15191">Mingard 等人 (2020)</a>的讨论）， <a href="https://towardsdatascience.com/deep-neural-networks-are-biased-at-initialisation-towards-simple-functions-a63487edcb99">Mingard (2021)</a>讨论了参数<em>的先验</em>概率分布的经验证据（例如，我上面称为“初始化分布”）将更高的概率质量放在更简单的函数上。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-8" id="fnref-DNdPEGz4DYMju8reA-8">[8]</a></sup>他将这一点与计算机科学中称为“莱文界”的理论结果联系起来，该结果预测了这一点（详情见脚注）。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-9" id="fnref-DNdPEGz4DYMju8reA-9">[9]</a></sup></p><p>我还没有深入研究过这个问题。不过，如果准确的话，这种结果也会从“额外标准”框架中给出简单的相关性。也就是说，在这个框架上，甚至在我们开始优化奖励之前，SGD 就偏向于简单性。</p><p>那么，我们假设 SGD 选择某种不平凡的简单性。这种选择会偏向有利于策划者吗？</p><h2>类似阴谋家的目标的简单性优势</h2><p>上面我提到，计数论点有时被作为预期对阴谋者产生偏见的理由。但请注意，计数论点（至少正如我所介绍的那样）并没有明显提及对简单性本身的偏见。我认为我们应该小心，不要将“SGD 选择策划者”<em>假设</em>的（微不足道）简单性混为一谈<em>，因为先验概率分布将大部分概率放在策划者身上</em>（例如，各个模型上的均匀分布 - 即-get-high-reward），声称给定的个体策划者实现的<em>算法</em>（实质上）比给定的非策划者实现的算法简单。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-10" id="fnref-DNdPEGz4DYMju8reA-10">[10]</a></sup>事实上，我自己的感觉是，计数论证的最强形式让它站在自己的直观术语上，而不是试图将其与有关 SGD 特别是简单性的偏见的进一步问题联系起来。</p><p>也就是说，可以建立这种形式的联系。特别是：我们可以说，<em>由于</em>如此广泛的目标可以激发阴谋，阴谋者让SGD有非常广泛的目标可供选择，以寻找更简单的目标；而非阴谋者则不然。当我们想象成为一个非阴谋家所需的目标相当复杂时，这似乎尤其合理（更多内容见下文）。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-11" id="fnref-DNdPEGz4DYMju8reA-11">[11]</a></sup></p><p>这类论证的一个有趣的特点是，它具体地认为模型之间的简单性差异完全来自于它们<em>目标</em>的内容。事实上，Hubinger (2022) 中的玩具分析具体假设各个模型类都具有相同的世界模型和优化过程，并且其算法整体的复杂度可以通过<em>世界模型的复杂度 + 优化过程的复杂度 +</em>来近似<em>目标的复杂性。</em> “球门槽”是不同型号之间唯一不同的部分。</p><p>然而，目前还不清楚这是否正确，特别是如果我们假设所涉及的目标导向性是“混乱的”而不是“干净的”。例如，在某种程度上，阴谋者必须执行非阴谋者<em>不会</em>执行的工具推理类型（例如，推理获得奖励的工具价值、推理何时背叛等），这似乎有可能引入算法本身的额外复杂性（而不是仅仅要求算法“运行更长时间”，如下面的“速度”分析）。例如，就我们使用“参数简单性”作为简单性概念而言，我们可以想象这种工具推理需要额外参数的情况。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-12" id="fnref-DNdPEGz4DYMju8reA-12">[12]</a></sup></p><h2>这些简单性优势有多大？</h2><p>不过，现在我们还是坚持胡宾格的本体论，并简单地说明差异源于目标之间的差异。选择策划者在这方面有多大的优势呢？</p><p>运行此分析的一种方法是比较每个类中最简单的模型所具有的目标（或者：因为您希望 SGD 选择最简单的可能模型，或者您认为这是近似所面临的简单性优势的好方法）。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-13" id="fnref-DNdPEGz4DYMju8reA-13">[13]</a></sup>也就是说，我们比较以下的复杂度：</p><ol><li><p>指定目标（培养圣人）</p></li><li><p>最简单的可能的错误概括目标，在没有训练游戏的情况下获得训练数据的最大奖励（对于错误概括的非训练游戏玩家）</p></li><li><p>寻求剧集奖励的最简单方法（针对剧集奖励寻求者）</p></li><li><p>激发阴谋的最简单的可能目标（对于阴谋者）</p></li></ol><p>显然，在这种情况下，指定目标的复杂性很重要。我的感觉是，关于心计的讨论常常假设特定的目标在某种意义上是相当复杂的——特别是“<a href="https://www.lesswrong.com/tag/complexity-of-value">人类价值观是复杂的</a>”这一观念中的利害关系。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-14" id="fnref-DNdPEGz4DYMju8reA-14">[14]</a></sup>也许，如果我们想象获得<em>一致性</em>的唯一方法是首先（a）通过培训目标以某种方式指定“人类价值观”，然后（b）以某种方式确保我们得到一个培训圣人，那么将“按照人类价值观行事”附近的事物作为指定目标是适当的。但请注意，为了将<em>阴谋</em>的概率与<em>其他形式的失准</em>概率进行比较，我们不需要假设这样的焦点。因此，我们指定的目标可能比“按照人类价值观行事”简单得多。例如，它可能类似于“在剧集中获得金币”。事实上，在<a href="https://www.lesswrong.com/posts/qoHwKgLFfPcEuwaba/conditioning-predictive-models-making-inner-alignment-as#Analyzing_the_case_for_deceptive_alignment">其他工作</a>中，胡宾格（与其他人一起写作）表明，像“最小化下一个标记预测误差”这样的目标非常简单——而且事实上，“它的复杂性与最简单的长期目标具有竞争力”（这是这是 Hubinger 对在 LLM 预训练期间避免阴谋相对乐观的部分原因——尽管就我个人而言，我对为什么 Hubinger 认为“下一个令牌预测错误”比“情节奖励”更简单感到困惑）。</p><p>不过，假设指定的目标具有“按照人类价值观行事”或“以有益、无害和诚实 (HHH) 的方式遵循指示”的复杂性。上面（1）-（4）之间的比较在哪里？</p><p>至少从参数简单性的角度来看，解决这个问题的一种方法是考虑我们对神经网络中表示不同人类概念的参数的绝对成本的了解。我不会在这里深入探讨，但一条似乎相关的数据是：像 GPT-4 这样的 LLM 似乎能够表示大量复杂的人类概念，例如一万亿个参数的量级 - 包括，看似合理的概念比如“诚实”、“乐于助人”、“奖励”等等。这还没有提及 GPT-4 所做的所有其他事情的所有参数。因此，表示此类概念所需的参数绝对数量不可能高得离谱。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-15" id="fnref-DNdPEGz4DYMju8reA-15">[15]</a></sup>这限制了上述模型之间差异所带来的整体复杂性节省。例如，如果我们假设万亿参数模型容量的最多 1% 用于表示像“诚实”这样复杂的概念，并且它至少知道 10,000 个这样的概念（<a href="https://www.merriam-webster.com/help/faq-how-many-english-words">韦氏未删节词典有约 500,000 个单词</a>），那么表示“诚实”概念所需的最大参数数量约为一百万（这个估计让我觉得相当保守）。因此，如果最简单的类似策划者的目标只需要 1 个参数来表示，那么在策划者的“目标槽”中不表示诚实，最多可以节省 999,999 个参数——大约是万亿参数模型表示能力的百万分之一，甚至更少适用于未来的更大型号。</p><p>但更重要的是：没有人认为阴谋者根本不必代表“诚实”、“乐于助人”、“奖励”等概念。正如<a href="https://www.lesswrong.com/posts/qoHwKgLFfPcEuwaba/conditioning-predictive-models-making-inner-alignment-as#Analyzing_the_case_for_deceptive_alignment">Hubinger 等人 (2023)</a>所指出的，这里重要的不是表示所讨论的不同目标的绝对复杂性，而是<em>以已经拥有良好的世界模型为条件的</em>复杂性。我们应该假设<em>所有</em>这些模型都需要理解指定的目标、奖励过程等（尤其是：“玩训练游戏”的模型，其中这些概念起着核心作用）。所以，实际上，相关的问题是：表示“在情节中获得奖励”或“以 HHH 方式遵循指令”等目标的<em>额外</em>复杂性成本是多少（相对于最简单的类似阴谋家的目标），<em>一旦您已经支付了拥有这些目标概念的成本</em>。</p><p>我不确定具体如何考虑这个问题，但对我来说，这里的成本非常小似乎是非常合理的。特别是：SGD 似乎能够显着地重新调整用于表示世界模型中的概念的参数的用途，从而使该概念以类似目标的方式指导模型的行为。因此，打个比方，也许“快乐”的概念在某种意义上比日本美学中“<a href="https://en.wikipedia.org/wiki/Wabi-sabi">侘寂</a>”的概念“更简单”（即“欣赏‘不完美、无常、不完整’的美”） 。然而，一旦你<em>学会了</em>两者，追求前者是否比追求后者需要更多的参数？ <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-16" id="fnref-DNdPEGz4DYMju8reA-16">[16]</a></sup></p><p> <a href="https://www.lesswrong.com/posts/A9NxPTwbw6r6Awuwt/how-likely-is-deceptive-alignment">Hubinger（2022）</a>对此类问题的讨论有时会诉诸世界模型某些部分的“指针”概念。据我了解，这里的想法是，如果你已经在你的世界模型中得到了“快乐”/“wabi-sabi”/“奖励”之类的概念，你可以通过给予模型来追求这个东西它是一个目标槽，表示诸如“追求<em>那个</em>”或“<em>那</em>是好的”之类的东西，其中“那个”指向有问题的事物（这与必须<em>再次</em>完整且冗余地表示相关概念形成对比，在目标槽本身）。但就我们使用这样的玩具模型而言（我怀疑我们应该依赖它），为什么认为<em>指向</em>一个更复杂的概念比指向一个更简单的概念要复杂得多呢？例如，即使“wabi-sabi”需要比“pleasure”更多的参数来在世界模型中表示，为什么认为将<em>指针编码</em>为“pleasure”（例如，“go for <em>that”</em> ）比<em>编码</em>指针需要更多的参数到“wabi-sabi”（例如，再次“去做<em>那个</em>”）？</p><p>这里，一种选择是概念的复杂性和指针的复杂性是相关的。例如，您可能会想象该模型具有某种概念的“内部数据库”，它以某种方式存储概念，使得需要较少参数来存储的概念也需要较少参数来“查找”。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-17" id="fnref-DNdPEGz4DYMju8reA-17">[17]</a></sup>在这张图中，“快乐”可能最终存储为数据库中的第 15 个概念<em>，因为</em>它需要 23 个参数来表示，而“wabi-sabi”可能最终存储为第 125355 个概念，因为它需要 10,000 个参数来表示。代表。然后指向 pleasure 的“指针”可以说“去寻找存储在位置 15 的东西”，而指向“wabi-sabi”的“指针”必须说“去寻找存储在位置 125355 的东西”，这需要一些时间更多位需要指定。但即使在抽象玩具说明性示例级别，此类故事也需要依赖于模型指针和概念存储过程如何工作的特定模型 - 并且仍然需要解释<em>为什么</em>简单表示和简单 - to-point-at 在相关意义上是相关的。</p><p>不过，或者，我们可以放弃对在世界模型中存储概念的复杂性的任何兴趣，而直接关注指向它的复杂性。尽管如此，只要指出一个概念与另一个概念的复杂性之间存在有意义的<em>差异</em>，我们就可以重新论证阴谋者提供简单性优势的论点。特别是：选择阴谋者可以让 SGD 从<em>世界模型中最容易指出的</em>任何阴谋者激励目标中进行选择；而其他模型类似乎施加了更多实质性约束。即，如果指定的目标最终存储在模型的隐喻数据库中的位置 12634 处，并且如果“情节奖励”位于位置 35364 处，那么如果在例如位置 1-100 处存在任何类似策划者的目标，相反，指向<em>其中</em>一个会更简单 - 因此，创建一个阴谋家而不是一个训练圣人或一个情节奖励寻求者。</p><p>就我们关注不同模型类的最终属性而言，我认为这可能是运行以简单性为中心的方案论证的最佳方式——特别是如果我们不太沉迷于“指针”的玩具本体的话”（更不用说“数据库”）。也就是说，粗略地说：即使假设这里表上的所有目标（例如指定的目标、剧集奖励等）都需要由模型在某处表示，但无论出于何种原因，这都可能是这样的，其中一些概念比其他概念需要更少的参数来<em>重新调整目标追求</em>。只要阴谋使更多潜在的概念可用于这种重新利用，它就提供了从这个意义上说的简单性优势。</p><p>但从数量上来说，这种优势有多大？现在特别难说。特别是，一旦我们将注意力从“简单地表示”转移到“简单地重新利用目标追求”，我们甚至无法审视我们对诸如“奖励”、“诚实”和“下一个令牌预测错误”，因为我们不再讨论概念本身的复杂性。相反，我们正在推测重新利用预先存在的概念表示以用于模型的动机系统时所面临的复杂性差异，这似乎是更加不确定的领域。</p><p>尽管如此，就我们可以估计这些差异的大小而言，在我看来，它们确实非常小是合理的。对我来说，一个直觉泵的运行方式如下。假设该模型在其世界模型/“数据库”中有 2^50 个概念（大约 1e15），原则上可以将其转化为目标。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-18" id="fnref-DNdPEGz4DYMju8reA-18">[18]</a></sup>为每个 2^50 个概念进行编码所需的平均位数不能高于 50（因为：您可以为每个概念分配不同的 50 位字符串）。因此，如果我们假设模型的编码相对于平均值相当有效，并且最简单的非计划最大奖励目标采用大致平均简单性“指针”，那么如果我们为每位分配一个参数，指向最简单的非诡计式最大奖励目标最多只是额外的 50 个参数——万亿参数模型容量的二十亿分之一。也就是说，我希望弄清楚这类论证的细节会变得很棘手，而且我不会在这里尝试这样做（尽管我有兴趣看到其他尝试这样做的工作）。</p><h2>这种以简单性为中心的论点是否能够对阴谋者最终的目标做出合理的预测？</h2><p>在阴谋的简单论证的背景下，似乎值得追踪的另一个考虑因素是他们对阴谋者最终将达到的目标类型所做的预测。特别是，如果您认为 (1) SGD 很难选择更简单的目标，(2) 这种选择有利于类似计划者的目标，因为它们可以更简单，以及 (3) 我们对 SGD 选择的预测可以忽略创建相关模型所需的“路径”，那么至少天真地，您似乎应该期望 SGD 选择一个具有极其简单的长期目标（也许：最简单的长期目标）的策划者，<em>无论该目标是否与训练期间的突出或重要内容有任何关系</em>。因此，作为一个玩具示例，如果一旦你有了一个完全详细的世界模型，“最大化氢”恰好是最简单的长期目标， <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-19" id="fnref-DNdPEGz4DYMju8reA-19">[19]</a></sup>这些假设可能意味着 SGD 很可能会选择那些想要的策划者。最大限度地利用氢，即使培训都是关于金币的，并且根本没有使氢成为一个突出/相关的焦点（即使作为代理）。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-20" id="fnref-DNdPEGz4DYMju8reA-20">[20]</a></sup></p><p>就我个人而言，我对这样的预测持怀疑态度（尽管这种怀疑可能部分源于对忽略 SGD 在模型空间中更普遍的路径的怀疑）。关于阴谋者的常见故事往往侧重于与整个训练过程有更密切联系的代理目标（例如，接受金币获取训练的模型最终会评估“一直获取金币”或“跟随我的好奇心”）在所有时间里”，而不是“在所有时间里最大化氢”）。</p><p>当然，也可以假设训练期间显着/相关的目标对于模型追求来说也将是“更简单”，也许它们在世界模型中表示更重要（因此更简单？），或更简单（出于某种原因）模型重新用于曾经代表的目标追求。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-21" id="fnref-DNdPEGz4DYMju8reA-21">[21]</a></sup>但是，如果我们以这种方式认可一些故事，我们也应该追踪它与追求<em>非阴谋目标</em>的简单性的相关性。特别是：在某种程度上，我们假设训练期间的显着性/相关性与相关意义上的简单性相关，这有利于指定目标的简单性，以及情节奖励的简单性 -因为这些在培训过程中<em>特别</em>突出/相关。 （当然，只要在训练期间仍然存在<em>更简单的</em>类似阴谋者的目标，这些目标在训练过程中是显着/相关的，那么类似阴谋者的目标可能仍然会在总体上胜出。）</p><p>还要注意的是，在某种程度上，SGD 很难选择更简单的目标（例如，在“低路径依赖”形式的背景下，导致单一最优排序模型的强收敛），这似乎有点与强形式的守门假说不同，根据该假说，训练-游戏会让你的目标“具体化”。例如，如果一个潜在的阴谋家一开始有一个不太简单的目标，但仍然会激发长期的权力追求，那么如果它知道事实上，SGD 会继续将其目标磨成更简单的目标，甚至是更简单的目标。在它开始训练-游戏之后，它可能一开始就没有动力开始训练-游戏——而且它的目标无论如何都不会在这个过程中幸存下来。 <sup class="footnote-ref"><a href="#fn-DNdPEGz4DYMju8reA-22" id="fnref-DNdPEGz4DYMju8reA-22">[22]</a></sup></p><h2>对简单性论证的总体评估</h2><p>总的来说，我确实认为在其他条件相同的情况下，阴谋者可能比其他模型类有更简单的目标。然而，我认为相关的简单性差异可能非常小，特别是当我们更普遍地以具有良好世界模型的模型为条件时（更重要的是，如果我们假设目标针对训练期间的显着/相关性获得额外的简单性点）。我对某些理论包袱表示怀疑，它可能感觉像是某些类型的简单性论证带来的（例如，与利害攸关的简单性概念相关的包袱、SGD 是否选择它、如何在上下文中考虑简单性）为追求目标而重新利用，而不是仅仅代表，等等）。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-DNdPEGz4DYMju8reA-1" class="footnote-item"><p>参见<a href="https://www.lesswrong.com/posts/A9NxPTwbw6r6Awuwt/how-likely-is-deceptive-alignment#Deceptive_alignment_in_the_low_path_dependence_world">Hubinger (2022)</a>等。 <a href="#fnref-DNdPEGz4DYMju8reA-1" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-2" class="footnote-item"><p>另请参阅<a href="https://www.lesswrong.com/posts/KSWSkxXJqWGd5jYLB/the-speed-simplicity-prior-is-probably-anti-deceptive">此（现在是匿名）讨论，</a>了解“简单性”用法的另一个示例。 <a href="#fnref-DNdPEGz4DYMju8reA-2" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-3" class="footnote-item"><p>在这里，我的感觉是，通常的假设是 X 可以在计算抽象级别上进行描述，这样所涉及的“重写”不仅仅是重现网络本身。例如，网络被理解为实现一些更抽象的功能。我认为这是一个有趣的问题，简单性论证在放松这种假设的情况下能否幸存下来。 <a href="#fnref-DNdPEGz4DYMju8reA-3" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-4" class="footnote-item"><p>另一个问题是<a href="https://joecarlsmith.com/2021/10/29/on-the-universal-distribution#ii-my-current-favorite-pitch-for-the-ud">柯尔莫哥洛夫复杂度是不可计算的</a>。我被告知你可以近似它，但我不确定这如何解决这个问题：对于给定的程序，你无法判断它是否停止，该程序可能是输出相关的最短程序细绳。 <a href="#fnref-DNdPEGz4DYMju8reA-4" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-5" class="footnote-item"><p>有关详细信息，请参阅<a href="https://joecarlsmith.com/2021/10/29/on-the-universal-distribution#iv-can-you-ignore-being-only-finitely-wrong">Carlsmith (2021)</a>第 III 节和 IV 节。 <a href="#fnref-DNdPEGz4DYMju8reA-5" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-6" class="footnote-item"><p>胡宾格有时似乎也对这个概念很有吸引力——或者至少没有在“重写简单性”和“参数简单性”之间划清界限。 <a href="#fnref-DNdPEGz4DYMju8reA-6" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-7" class="footnote-item"><p> “琐碎的简单性”也与我们所说的“选择简单性”密切相关。在这里，我们再次假设一些可能的事情（例如，目标）的空间/分布，然后根据需要做多少“工作”来讨论该空间的某些部分的“简单性”（也许：平均而言） ）以便从整个空间缩小到空间的该部分（另请参见<a href="https://colah.github.io/posts/2015-09-Visual-Information/">可变长度代码</a>）。因此，对于一盒气体，“分子大致均匀地分布”可能比“分子都在特定的角落”更“简单”，因为它通常需要更多的“功”（在本例中：热力学功）导致前者比后者（这与前者最初比后者更有可能的事实密切相关）。我的感觉是，当有些人说“类似阴谋家的目标很简单”时，他们的意思更像是：就 SGD 而言，与一<em>组</em>非阴谋家相比，这<em>组</em>类似阴谋家的目标通常需要更少的“工作”来实现。 -类似阴谋家的目标（不一定：任何<em>特定的</em>类似阴谋家的目标都比某些<em>特定的</em>非阴谋家的目标更简单）。在某种程度上，类似阴谋家的目标应该具有这种属性，因为它们更“常见”，因此“更接近”可持续发展目标的起点，这种谈论阴谋的简单好处的方式相当于重述诸如计数参数和/或“最近的最大奖励目标参数”之类的东西 - 除了在我看来更倾向于将<em>一组</em>类似阴谋家的目标的简单性与<em>给定的</em>类似阴谋家的简单性混淆目标。 <a href="#fnref-DNdPEGz4DYMju8reA-7" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-8" class="footnote-item"><p>重要的是，多个不同的参数设置可以实现相同的功能。 <a href="#fnref-DNdPEGz4DYMju8reA-8" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-9" class="footnote-item"><p>我的理解是，莱文界限是这样说的：对于给定的参数分布，随机采样一组实现函数<em>f</em>的参数的概率<em>p(f)</em>的界限为<em>2^{-K(f) + O( 1)}</em> ，其中<em>K</em>是函数<em>f</em>的<em>k</em>复杂度， <em>O(1)</em>是一些独立于函数本身的常数（尽管：取决于参数空间）。也就是说，随着函数复杂性的增加，某些函数的先验值呈指数下降。</p><p>我还没有调查过这个结果，但我看到的一个总结（ <a href="https://www.lesswrong.com/posts/YSFJosoHYFyXjoYWa/why-neural-networks-generalise-and-why-they-are-kind-of?commentId=kLz9mgNv8xFNrAPt2">此处</a>）使它看起来相当空洞。特别是，该摘要中的想法是，较大容量的参数空间将具有更简单的编码，因为您可以通过首先指定参数的分布来对它们进行编码，然后使用<a href="https://en.wikipedia.org/wiki/Huffman_coding">霍夫曼代码</a>来讨论如何在给定的分布下找到它们。但这使得结果看起来相当微不足道：这并不是说存在一些简单的先行概念，然后我们根据初始化分布发现其概率更高。相反，根据初始化分布获得较高概率<em>只是</em>更简单，因为配备了初始化分布，更容易对其较高概率部分进行编码。或者换句话说：这个结果似乎适用于任何参数分布。因此，我们似乎并没有从中学到太多关于任何特定分布的知识。</p><p> （对我来说，感觉这与“较短的程序获得更大的概率”的方式有类比，在算法“简单性先验”的背景下，重点关注 K 复杂度等指标，实际上必然适用于可数范围内的<em>任何</em>分布-无限的程序集 - 请参阅<a href="https://joecarlsmith.com/2021/10/29/on-the-universal-distribution#ii-my-current-favorite-pitch-for-the-ud">此处的</a>讨论。您可能认为这是一个有趣且实质性的约束，但实际上它变得更加空洞。）</p><p>也就是说，我上面提到的经验结果侧重于更实用的、现实世界的简单性度量，例如<a href="https://en.wikipedia.org/wiki/Lempel%E2%80%93Ziv_complexity">LZ 复杂度</a>，并且显然他们发现，确实，更简单的函数获得更高的先验概率（参见例如<a href="https://arxiv.org/pdf/1805.08522.pdf">这个实验</a>，它使用完全连接的神经网络对从许多二进制输入到单个二进制输入的可能函数进行建模）。在我看来，这更加实质性和有趣。 <a href="https://towardsdatascience.com/deep-neural-networks-are-biased-at-initialisation-towards-simple-functions-a63487edcb99">Mingard (2021)</a>声称 Levin 的结果并非微不足道，尽管我还不明白其中的原因。 <a href="#fnref-DNdPEGz4DYMju8reA-9" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-10" class="footnote-item"><p>因此，例如，您可能认为随机初始化的模型更有可能最终“更接近”计划者，因此 SGD 需要做“更少的工作”才能选择计划者而不是其他模型，这有利于阴谋家（感谢 Paul Christiano 的讨论）。但这种论点依赖于对阴谋者赋予更高的先验概率，在我的书中，这本身并不是一个（非平凡的）简单论点。 <a href="#fnref-DNdPEGz4DYMju8reA-10" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-11" class="footnote-item"><p>对于简单性和阴谋者之间的联系，还有更多的推测和理论论据，有人认为，如果你对所有可能的程序进行无限搜索，找到给出给定输出的最短程序，而不考虑其他因素，例如多长时间他们必须运行，然后你将选择一个策划者（例如，通过这样的路线：模拟一个极其简单的物理过程，最终产生了解情况并想要突破模拟的代理，并给出相关的输出作为计划的一部分）。我的理解是，人们（例如<a href="https://www.lesswrong.com/posts/KSWSkxXJqWGd5jYLB/the-speed-simplicity-prior-is-probably-anti-deceptive#Priors_on_Learned_Optimizers">这里</a>）有时将有关“ <a href="https://ordinaryideas.wordpress.com/2016/11/30/what-does-the-universal-prior-actually-look-like/">所罗门诺夫先验的恶性</a>”的讨论视为与这里相关（尽管乍一看，在我看来存在重要差异 - 例如，在因果关系类型上）股份，以及相关阴谋者是否可能在模拟<em>您的</em>问题）。无论如何，我怀疑这些无边无际的理论论证是否会变得越来越重要，而且我不会在这里讨论它们。 <a href="#fnref-DNdPEGz4DYMju8reA-11" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-12" class="footnote-item"><p>更重要的是，请注意，在我们想象 SGD 偏向于简单性的程度上<em>，因为</em>现实世界的模式往往很简单（例如，奥卡姆剃刀确实是一个很好的先验，而 SGD 工作良好部分是因为它反映了这个先验），解释这种偏见并不容易适用于模型的<em>目标</em>。也就是说（以道德现实主义的各种形式为模），不存在“真正的目标”，其建模可能会受益于简单先验。相反，在这个故事中，SGD 需要表现得更像一个人类道德反现实主义者，尽管不相信此事存在任何客观事实，但他更喜欢其他条件相同的简单道德，因为，在存在以下情况的情况下，<em>事实上</em>，更简单的理论往往更有可能。 <a href="#fnref-DNdPEGz4DYMju8reA-12" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-13" class="footnote-item"><p> Hubinger 使用了这种方法。我的理解是，他想象 SGD 选择一个模型，其概率与其简单性成正比，例如，关注最简单的可能模型是近似模型类中整体概率的一种方法，而关注类中模型的<em>数量</em>是其他。然而，我不会想当然地认为 SGD 选择的模型的概率与其简单性成正比。 <a href="#fnref-DNdPEGz4DYMju8reA-13" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-14" class="footnote-item"><p>请参见 Hubinger 等人 (2023) <a href="https://www.lesswrong.com/posts/qoHwKgLFfPcEuwaba/conditioning-predictive-models-making-inner-alignment-as#Analyzing_the_case_for_deceptive_alignment">此处</a>。 <a href="#fnref-DNdPEGz4DYMju8reA-14" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-15" class="footnote-item"><p>我第一次从保罗·克里斯蒂亚诺那里听到这样的观点。 <a href="#fnref-DNdPEGz4DYMju8reA-15" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-16" class="footnote-item"><p>这里我的意思并不是：<em>成功</em>促进快乐与成功促进侘寂是否需要更多参数。我的意思只是：是否需要更多参数来针对其中一个与另一个<em>进行</em>优化。 <a href="#fnref-DNdPEGz4DYMju8reA-16" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-17" class="footnote-item"><p>感谢 Daniel Kokotajlo 推荐这样的图像。 <a href="#fnref-DNdPEGz4DYMju8reA-17" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-18" class="footnote-item"><p>这里概念的精确数量并不重要。 <a href="#fnref-DNdPEGz4DYMju8reA-18" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-19" class="footnote-item"><p>我并不是说它是这样，即使对于基于物理的世界模型也是如此，但我想要一个简单的说明来说明这一点。请随意在这里替换您的最佳猜测最简单的可能目标。 <a href="#fnref-DNdPEGz4DYMju8reA-19" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-20" class="footnote-item"><p>值得注意的是，这种预测似乎特别不适合人类与进化之间的类比，因为人类目标似乎与生殖适应性有着非常容易理解的关系。但无论如何，进化似乎是相当“路径依赖”的。 <a href="#fnref-DNdPEGz4DYMju8reA-20" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-21" class="footnote-item"><p>例如，对于人类来说，“氢”似乎并不是一个简单的概念，但“威胁”这样的概念却是这样，因为后者在我们的进化环境中更相关。 <a href="#fnref-DNdPEGz4DYMju8reA-21" class="footnote-backref">↩︎</a></p></li><li id="fn-DNdPEGz4DYMju8reA-22" class="footnote-item"><p>胡宾格在讨论中表示，该模型的推理将按照逻辑因果关系而不是物理因果关系进行。他写道：“这里的推理是：我应该是那种会玩训练游戏的模型，因为有一些（逻辑）机会我将成为具有最佳归纳偏差的模型，所以我应该确保我也有好的损失​​。”但是，如果一个模型可以<em>看出</em>它的目标还不是最简单的（因此将被 SGD 压制），那么我不确定为什么它会认为存在“逻辑机会”，即它受到归纳偏差的青睐在这个意义上。 <a href="#fnref-DNdPEGz4DYMju8reA-22" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/uWdAKyHZMfoxDHcCC/simplicity-arguments-for-scheming-section-4-3-of-scheming#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/uWdAKyHZMfoxDHcCC/simplicity-arguments-for-scheming-section-4-3-of-scheming<guid ispermalink="false"> uWdAKyHZMfoxDHcCC</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Thu, 07 Dec 2023 15:05:54 GMT</pubDate> </item><item><title><![CDATA[Results from the Turing Seminar hackathon]]></title><description><![CDATA[Published on December 7, 2023 2:50 PM GMT<br/><br/><p>我们 ( <a href="https://ia.effisciences.org/"><u>EffiSciences</u></a> )<a href="https://www.master-mva.com/cours/seminaire-turing/"><u>在 ENS 巴黎萨克雷</u></a>和<a href="https://diplome.di.ens.fr/catalog_fr.html#:~:text=niveau%20L3%20M1-,S%C3%A9minaire%20Turing,-(iCal)">ENS 乌尔姆</a>图灵研讨会结束时举办了一场黑客马拉松，这是一门受 AGISF 启发的学术课程，11 月 11 日至 12 日期间，44 名参与者提交了 28 个项目。</p><p>我们分享一些项目的选择。 <a href="https://drive.google.com/drive/folders/1HgqUCu7CG44iUZdJtDO_Zua4xjLFu450?usp=drive_link"><strong>在这里</strong></a><strong>看到它们</strong><strong><u>。</u></strong></p><p>我认为其中一些甚至可以变成有价值的博客文章，而且我通过阅读所有内容学到了很多东西。以下是一些摘录。</p><h1>迈向单义性：用字典学习分解视觉模型</h1><p><i>大卫·赫特尔-德佩格斯</i>[<a href="https://drive.google.com/file/d/1gmj-ax9mtn2chjyoMxyQlP-R9zCl6q6f/view?usp=sharing"><u>链接</u></a>]</p><p>基本上是对视觉 CNN 著名词典学习论文的改编。</p><p> “当观察 100 个随机<strong>特征</strong>时，发现 46 个是可解释的且单一语义的，[...]当用 100 个随机<strong>神经元</strong>进行相同的实验时，发现 2 个是可解释的且单一语义的”。执行力非常好。</p><h1>开放、封闭以及介于两者之间的一切：走向以人为本的法规，打造更安全的大型模型</h1><p><i>泰奥·索尔斯</i>[<a href="https://drive.google.com/file/d/1jopH_aaDOVRSLoBG4qnwbqglDUyFebUH/view"><u>链接</u></a>]</p><p>恕我直言，这几乎是对当前开源模型讨论的 SOTA 总结。</p><h1>关于开源强大人工智能模型的争论回顾</h1><p><i>Tu Duyen NGUYEN、Adrien RAMANANA RAHARY</i> [ <a href="https://drive.google.com/file/d/1M1B7n2jEPZPkBdYSxy_v3uNgqWAk9tF4/view?usp=drive_link"><u>链接</u></a>]</p><p> “这份文件的目标是什么？我们的目标是澄清（有时是批评）开源人工智能模型的支持者和反对者经常提出的论点。为了更好地理解这两种立场，我们将围绕这场辩论最常见的论点分为五个主要主题：</p><ol><li>通过审计或开放研究对强大的人工智能模型进行安全评估</li><li>私营部门及其他领域的竞争</li><li>开源强大模型的安全风险</li><li>为了科学本身而保护开放科学</li><li>AI模型权重关闭的可行性</li></ol><p>为了突出每个立场的优点和缺点，我们将为每个家庭提出双方的论点并对其提出质疑，并在每个家庭中纳入一些我们认为相关但在大多数讨论中未提及的论点关于这些话题。”</p><p>他们试图详尽无遗，但仍然存在一些差距。不过，这种格式很有趣（即使它可以更简洁）。 </p><figure class="table"><table><tbody><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><img style="width:100%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/pbs3gjvzjzifved99zqh"></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><img style="width:100%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/m2budueajdv9smhr803w"></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><img style="width:100%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/cowvnni4lmpvy5bj6wma"></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><img style="width:100%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/oftlgwmwvsoy4jbvt4vy"></td></tr></tbody></table></figure><h1> AI安全媒体分析</h1><p><i>古尔万·理查多 (Gurvan Richardeau)，拉斐尔·佩萨 (Raphaël Pesah)</i> [ <a href="https://docs.google.com/document/d/1SBdZN9vnSVfqqJ_zUChXPxQjcrv8bT5DqSubA20ob-w/edit#heading=h.u543ptgy0th"><u>链接</u></a>]</p><p> “我们所做的第一项分析涉及使用文本数据分析和 ML 方法（例如 tf-idf 分析和主题建模）在过去 5 年 Factiva 数据库的 1,644 篇出版物的语料库中检查主要主题，特别是与人工智能安全。第二个分析（分析 2）使用另一个数据库：Europresse。 “</p><p>以下是一些片段：</p><p> “首先我们看一下历年文章的全球分布情况。” </p><figure class="table"><table><tbody><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>我们看到数据集中超过 80% 的文章来自 2023 年： </p><p><img style="width:100%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/r82swpuzxwe0uuf4aiax"></p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>现在让我们更准确地展望 2023 年： </p><p><img style="width:97.68%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/yog6bfn1egrsk9kami9o"></p></td></tr></tbody></table></figure><p><br> “以下是情绪分析的结果：” </p><figure class="image image_resized" style="width:43.33%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/hqdcwasrohax5fddjfgx" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/jy1k9hh9r4kmmzx5nbqq 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/b8skz1gdy9a1z2rejfrg 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/nbebbobmaqncvqfe7rmq 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/g8eljblwrf7uydvtwnqs 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/yr7cjfjgxe5kzubn3ne0 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/njcvcbbxb0amtbfygp1f 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/gjvzjndbiibpplvef6mt 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/dggepbhvyvv3pyrfzlhu 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/akp4ow9op0la8hupjmo4 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/dszpurelyhvdlinexewm 840w"></figure><p> “大约 71% 的谈论 AGI 的文章认为这是一件好事，而 23% 的文章则认为这是一件值得担心的事情。”</p><p> “2023 年，我们收到了 57,000 篇有关 AGI 的文章，而与 AI 安全相关的文章只有 18,000 篇，所以这次减少了三倍。 [...] 2023 年，谈论没有人工智能安全的通用人工智能的文章数量是谈论人工智能安全的文章的两到三倍。”</p><p>我的评论：有趣。报告中还有更多数字。也许这些指标可以用来衡量公众宣传的影响？</p><h1>人类反馈强化学习中的偏差</h1><p><i>加斯帕德·贝尔特利尔</i>[ <a href="https://docs.google.com/document/d/1Qc7f21EgYHdFJqC5MGJu3Auj00vLfJEc/edit?usp=drive_link"><u>链接</u></a>]</p><p>论文“ <a href="https://www.lesswrong.com/posts/LqRD7sNcpkA9cmXLv/open-problems-and-fundamental-limitations-of-rlhf">来自人类反馈的强化学习的开放问题和基本限制</a>”的一个很好的总结。</p><h1>人工智能的态势感知</h1><p><i>托马斯·米歇尔、泰奥·鲁德凯维奇</i>[ <a href="https://docs.google.com/document/d/1v-L1nXVSEJw0_9ceAA5BQGJxRgoSk9dvjbEat8eSQQE/edit?usp=drive_link"><u>链接</u></a>]</p><p>另一个标题可以是“从人工智能到僵尸的态势感知，具有优质的教学模因”： </p><figure class="table"><table><tbody><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><figure class="image image_resized" style="width:100%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/ddmnh7gjlssrryhihcrw"><figcaption>图 1：为什么不区分测试和部署的 IA 危险性较小。 </figcaption></figure></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><figure class="image image_resized" style="width:60.87%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/r2qfphrynxeo3vrmhs6i"><figcaption>图 2：什么是态势感知？ </figcaption></figure></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><figure class="image image_resized" style="width:80.57%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/fe9wqhwsimyvapdaicnd"><figcaption>图 3：如何测试潜在的不诚实模型？ </figcaption></figure></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><figure class="image image_resized" style="width:89.12%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/tarxnmxtglvl9umsowai"><figcaption>图 4： <a href="https://arxiv.org/abs/2309.00667"><u>Berglund 等人</u></a>的总结：断章取义：关于测量法学硕士的情境意识。</figcaption></figure></td></tr></tbody></table></figure><h1>解决目标误泛化的方法总结</h1><p><i>文森特·巴杜斯科</i>[ <a href="https://docs.google.com/document/d/16SlCd52xOuCYLOCtASobc_EXuauVOWwt/edit?usp=drive_link"><u>链接</u></a>]</p><p>以下论文的一个很好的总结：</p><ol><li> R. Shah，目标误区：为什么正确的规范不足以实现正确的目标，2022 年。</li><li> B. Shlegeris，典型的灾难性人工智能行动正在获得对其数据中心的 root 访问权限，2022 年。</li><li> Song 等人，用生成模型构建无限制的对抗性示例，2018 年。</li><li> A. Bhattad、MJ Chong、K. Liang、B. Li、D. A 和 Forsyth，通过语义操纵的无限制对抗性示例，2019 年。</li><li> B. Barnes，模仿泛化（又名“学习先验”），2021 年。</li><li> R. Jia 和 P. Liang，评估阅读理解系统的对抗性示例，2017 年。</li><li> S. Goldwasser、MP Kim、V. Vaikuntanathan 和 O. Zamir，在机器学习模型中植入不可检测的后门，2022 年。</li><li> A. Madry、A. Makelov、L. Schmidt、D. Tsipras 和 A. Vladu，走向抵抗对抗性攻击的深度学习模型，2018 年。</li><li> E. Hubinger，内部对齐的轻松对抗训练，2019。</li></ol><h1> DeepMind 人工智能调整计划回顾</h1><p><i>Antoine Poirier，Théo Communal</i> [ <a href="https://drive.google.com/file/d/1dC6FreML2qs1S6xuopIfYzVATRYc5lC8/view?usp=drive_link"><u>链接</u></a>]</p><p>一份总结 DeepMind 计划主要方面的文件。到目前为止，他们的议程已在一系列博客文章和论文中涵盖，但现在全部总结在一篇十页的博客文章中。 </p><figure class="table"><table><tbody><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top" colspan="2"><p><img style="width:92.5%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/ytkmna8qsptbc6qlerma"></p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p><img style="width:100%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/p0csxojobppctiuxdzp7"></p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p><img style="width:98.11%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/assvherolv9eoz0n3ijp"></p></td></tr></tbody></table></figure><h1>对口语批评的批评</h1><p><i>加布里埃尔·本·泽努、约阿希姆·科林</i>[ <a href="https://docs.google.com/document/d/1EFTdstgHb8iVIUx_bWzmcYNDZUCzbP3gpbMQmfZLc6M/edit?usp=drive_link"><u>链接</u></a>]</p><p>另一个标题可以是“反对<a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1"><u>几乎所有可解释性影响的理论</u></a>”。</p><p>一些学生试图提炼讨论并批评我的立场，你可以在谷歌文档的评论中找到我对他们批评的批评。这是我的<a href="https://docs.google.com/document/d/1EFTdstgHb8iVIUx_bWzmcYNDZUCzbP3gpbMQmfZLc6M/edit?disco=AAABBpJ9O7A"><u>主要评论</u></a>。</p><h1>中国的价值锁定风险</h1><p><i>Inès Larroche、Bastien Le Chenadec</i> [ <a href="https://drive.google.com/file/d/1a81ezHWDE10gnABsk8V_7iEreSx0024S/view?usp=drive_link"><u>链接</u></a>]</p><p>这是对中国人工智能领域正在发生的事情的一个很好的总结。</p><h1> LeCun是​​否正在通过“迈向自主机器智能之路”在人工智能安全方面取得进展？</h1><p><i>维克多·莫兰德</i>[ <a href="https://drive.google.com/file/d/1muZiF9R6sxPU2Z-gMsMF0j60kMT8CT5P/view?usp=drive_link"><u>链接</u></a>]</p><p>这是对 LeCun 的想法以及对他的计划的众多批评的一个很好的总结。 </p><figure class="image image_resized" style="width:35.2%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/y3vl6scv5yercxgvrbor"><figcaption> LeCun的架构</figcaption></figure><h1>治理法规分类</h1><p>马西斯·恩比特 [ <a href="https://docs.google.com/document/d/1VtLmxM9mdBTIvKY0rWNIGtjB8ODdVwgYZ0OuX4BGyXs/edit?usp=drive_link"><u>链接</u></a>]</p><p>人工智能监管主要方式总结。不同政策的比较使它们更具特色和深度。 </p><figure class="image image_resized" style="width:62.85%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bo9c8jyHab4gjRHxS/fmnxrvlvdm0ig2k66qyt"><figcaption></figcaption></figure><h1>其他值得注意的项目</h1><p><a href="https://drive.google.com/drive/folders/1HgqUCu7CG44iUZdJtDO_Zua4xjLFu450?usp=drive_link"><u>在这里</u></a><u>看到它们</u><u>。</u> </p><figure class="table"><table><thead><tr><th style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:200px"><p><strong>标题</strong></p></th><th style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:200px"><p><strong>作者</strong></p></th><th style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p><strong>概括</strong></p></th></tr></thead><tbody><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>OpenAI 超级对齐计划的技术论证</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>罗宾·索布奇克,<br>巴斯蒂安·洛皮塔利埃</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>这里总结了很多论文</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>代理创建</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>马蒂亚斯·维古鲁</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>一篇哲学文章试图解释心理理论如何在人类中出现以及在人工智能中出现。这很有趣。</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>人为RSP分析</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>拉尔夫·科尔特斯·多·纳西门托，</p><p>保罗·卡扎利</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>对 LW 关于 RSP 的整个讨论的一个很好的总结。</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>目标误区</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>巴塞尔·泰韦尔，<br>安托万·奥利维尔</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>防止目标误区化的各种技术总结</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>发现并减少性别偏见</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>加布里埃尔·勒贝利尔</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>关于减少法学硕士性别偏见的技术的文献综述</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>SOTA对抗攻击和后门文献综述</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>马西斯·勒贝尔，<br>大卫·萨纳</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>多篇攻击与防御论文的总结。结论：“文献中的所有研究都倾向于以下结论：没有单一有效的方法可以防御所有可能类型的攻击”</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>为什么深度学习效果这么好？</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>萨沙·埃尔库比,<br>甚至马坦西奥，<br>尤斯塔什·勒·比汉，<br>保罗·西托勒克斯</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>它需要更多的打磨，但这是一个很好的基础。它从解释经典统计学习理论到奇异学习理论以及介于两者之间的一切。</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>人工智能法案：基础模型有哪些规则？</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>马蒂厄·卡罗</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>欧盟法规当前面临的挑战总结</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>对 GovAI 的批评</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>泽维尔·塞切雷斯,<br>皮埃尔·伊夫·杜瓦罗</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>他们的观点总结和一点批评</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>治愈</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>大卫·埃尔·贝兹,<br>拉斐尔·科恩,<br>纳撒尼尔·科恩</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>一个关于欺骗性人工智能改变世界的短篇故事</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>Vision Transformer 上的 Logit 镜头</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>阿克朱·阿什拉夫·阿吉莱耶</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>在 Vision Transformer 上测试 Logit 镜头，它可以毫无困难地工作。</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>安全基准</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>乌戈·因萨拉科</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>对主要安全基准的审查以及对缺失基准的一些建议。</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>无欺骗性对齐情况下 X 风险的概率</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>玛蒂尔德·杜普伊</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>她在下<a href="https://docs.google.com/spreadsheets/d/1W2sm4Si9zu6i9ioBbV_vnC6RTCenrPXRJwitvn9gqYg/edit?usp=sharing"><u>表</u></a>中列举了不同的场景。在所有风险中，发生的风险是没有欺骗性一致性的存在风险的最终概率为 71%。</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>你觉得乐存的架构安全吗？</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>西奥蒂·德·查林</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>对 LeCun 议程的另一个批评。</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>引领人工智能安全</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>阿卜杜萨拉姆·埃迪布</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>介绍了一些通过调整技术和一些治理策略来降低风险的策略，并针对调整的初学者。</p></td></tr></tbody></table></figure><p></p><h1></h1><p></p><h1>一些想法</h1><ul><li>举办黑客马拉松非常有趣。周末我们只是在大学的一个房间里工作。我们还组织了一场表情包比赛。强烈推荐。</li><li><strong>与去年的黑客马拉松学生可以自由选择自己的主题不同，这次我们提供了预先确定的主题列表</strong>。这带来了更高质量的工作。如果您有兴趣组织类似的黑客马拉松，如果您想举办类似的活动，可以<a href="https://www.notion.so/AI-Safety-Research-Projets-2023-English-b6c5b1cb3ad641abbfa9acd856cd8bad?pvs=21"><u>在此处</u></a>找到主题列表。</li><li>我对结果非常满意，尤其是学生们在短短两个月内从对人工智能安全一无所知到做出了宝贵的贡献。</li><li>课程材料可<a href="https://docs.google.com/document/d/1d0W_5xRaVehYO_j4P1TN4-JJGktMNEXgBxO4MXCr68o/edit#heading=h.s5znjvp3l4zi"><u>在此处</u></a>获取。</li></ul><br/><br/> <a href="https://www.lesswrong.com/posts/bo9c8jyHab4gjRHxS/results-from-the-turing-seminar-hackathon#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/bo9c8jyHab4gjRHxS/results-from-the-turing-seminar-hackathon<guid ispermalink="false"> bo9c8jyHab4gjRHxS</guid><dc:creator><![CDATA[Charbel-Raphaël]]></dc:creator><pubDate> Thu, 07 Dec 2023 14:50:38 GMT</pubDate> </item><item><title><![CDATA[Gemini 1.0]]></title><description><![CDATA[Published on December 7, 2023 2:40 PM GMT<br/><br/><p>正在发生。 <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/sundarpichai/status/1732414873139589372">这是首席执行官皮查伊的 Twitter 公告</a>。 <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/demishassabis/status/1732416482976673832">杰米斯·哈萨比斯 (Demis Hassabis) 宣布</a>。 <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/GoogleDeepMind/status/1732416095355814277">这是 DeepMind Twitter 公告</a>。 <a target="_blank" rel="noreferrer noopener" href="https://blog.google/technology/ai/google-gemini-ai/">这是博客公告</a>。 <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/OriolVinyalsML/status/1732426317268758671">Gemini 联合领导者 Oriol Vinyals</a>承诺未来会有更多精彩。以下是<a target="_blank" rel="noreferrer noopener" href="https://twitter.com/JeffDean/status/1732415515673727286">谷歌首席科学家杰夫·迪恩（Jeff Dean）</a>带来的最精彩的炒作。</p><p>编辑：这篇文章已更新，因为我没有完全意识到谷歌的视频演示有多么虚假。</p><span id="more-23623"></span><h4>技术规格</h4><p><a target="_blank" rel="noreferrer noopener" href="https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf">让我们看看规格。</a></p><p>训练的上下文长度为 32k 个标记，他们报告 Ultra 在整个上下文长度上的信息检索准确率为 98%。所以有点低，既低于 GPT-4 和 Claude，又低于他们的方法可以处理的水平。想必我们应该预期上下文长度会随着未来的版本而快速增长。</p><p> Gemini 1.0共有三个版本。</p><blockquote><p> Gemini 1.0 是我们的第一个版本，具有三种尺寸：Ultra 用于高度复杂的任务，Pro 用于增强性能和大规模可部署性，Nano 用于设备上应用程序。每种尺寸都经过专门定制，以满足不同的计算限制和应用要求。</p><p> ……</p><p> Nano：我们最高效的模型，专为在设备上运行而设计。我们训练了两个版本的 Nano，参数分别为 1.8B (Nano-1) 和 3.25B (Nano-2)，分别针对低内存和高内存设备。它是通过从较大的 Gemini 模型中提取来训练的。它采用 4 位量化进行部署，并提供一流的性能。</p><p> ……</p><p> Nano 系列模型利用蒸馏和训练算法方面的额外进步，为各种任务（例如摘要和阅读理解）生成一流的小语言模型，从而为我们的下一代设备上体验提供动力。</p></blockquote><p>这是有道理的。我确实认为，大多数任务正是这三种类型。 Nano 任务与非 Nano 任务完全不同。</p><p>该图报告了不同尺寸模型的相对性能。我们知道 Nano 1 和 Nano 2 的尺寸，因此考虑到缩放法则如何适用于 Pro 和 Ultra 的尺寸，这是一个巨大的提示。</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5267840b-8509-4344-82a7-e570a0d6c82d_1075x466.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ofYejKKiSFYH2gLBb/ohs44wqu09loeuohlixp" alt=""></a></figure><p> Gemini 本质上是多模式的，他们表示能够无缝集成各种输入和输出。</p><p>他们表示，他们对文本的基准测试击败了现有的技术水平。</p><blockquote><p>我们最强大的模型 Gemini Ultra 在我们报告的 32 个基准测试中的 30 个中取得了最新的结果，其中包括 12 个流行文本和推理基准测试中的 10 个、9 个图像理解基准测试中的 9 个、6 个视频理解基准测试中的 6 个，以及 5 个语音识别和语音翻译基准测试中的 5 个。 Gemini Ultra 是第一个在 MMLU（Hendrycks 等人，2021a）上实现人类专家表现的模型，MMLU 是通过一系列考试测试知识和推理的著名基准测试，得分高于 90%。除了文本之外，Gemini Ultra 在具有挑战性的多模式推理任务上也取得了显着的进步。</p></blockquote><p>我喜欢“90% 以上”，结果恰好是 90.04%，而人类专家是 89.8%，之前的 SOTA 是 86.4%。主厨之吻，10/10，无注释。我的意思是，多么巧合啊，这根本不值得怀疑，而且没有人对游戏进行基准测试，不可能。</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d1fc5c4-473b-42be-87b8-61e85ce59c1d_1024x1024.webp" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ofYejKKiSFYH2gLBb/qauui9xd8kyjcdo3alxe" alt="由 DALL·E 生成"></a></figure><blockquote><p>我们发现，当与考虑模型不确定性的思维链提示方法（Wei 等人，2022）结合使用时，Gemini Ultra 可以实现最高的准确度。该模型使用 k 个样本（例如 8 个或 32 个）生成一个思想链。如果存在高于预设阈值（根据验证分割选择）的共识，则它会选择此答案，否则它将恢复为基于最大值的贪婪样本没有思路的可能性选择。</p></blockquote><p>我想知道这些方法何时会原生集成到此类模型的 UI 中。理想情况下，我应该能够在向他们提供我的信用卡信息后，将我的（吟游诗人？）转向“双子座 k-样本思想链”，然后让它自行处理。</p><p>这是他们的基准结果表。</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e9e608f-401f-4c88-802f-4534445e7d2f_1249x1221.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ofYejKKiSFYH2gLBb/uvwdrrwfwbiyjfvoosob" alt=""></a></figure><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/_philschmid/status/1732435791358410863">因此，MMLU 的问题</a>在于，Gemini Ultra 比 CoT@32 获得了更多改进，其中 GPT-4 没有太大改进，但 Ultra 在 5 个镜头上的基线性能比 GPT-4 差。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/AISafetyMemes/status/1696509099490304250">除了另一个问题是，GPT-4 在创造性的提示下可以达到 89%</a> ？</p><p> GPT-4 对这种潜在的“Gemini Ultra”在 MMLU 上得分超过 90% 感到非常兴奋，列举了各种潜在的应用程序，并称其为人工智能功能的重大进步。</p><p>他们强烈暗示，由于数据污染，GPT-4 在 HellaSwag 上获得了 95.3％，并指出，包括“特定网站摘录”将 Gemini 的性能提高到了 1-shot 96％。即使属实，其表现也令人失望。</p><p>这对 Gemini Ultra 意味着什么？一件显而易见的事情是将 GPT-4、GPT-3.5 和 Gemini 的所有分数一起平均，将 Gemini 置于 GPT 量表上。仅使用 3.5 得分的基准测试，我们得到的 GPT 3.5 的平均值为 61，GPT-4 的平均值为 79.05，Gemini Ultra 的平均值为 80.1。</p><p>根据这一基本逻辑，我们将授予 Gemini 4.03 GPT 的基准。如果您考虑到分数越高，改进就越重要，并且查看上下文，并假设没有选择这些基准来获得结果，我会将其增加到 4.1 GPT。</p><p>在实际的纯文本性能方面，我仍然希望 GPT-4-turbo 能够名列前茅。</p><p>在与人类的比较中，Gemini Pro 明显击败了 PaLM-2，但并不是压倒性的。有点奇怪的是，我们没有 GPT-4 与 Gemini Ultra 的胜率。</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99738558-c837-4633-a3fb-32cfa971f8fe_1182x214.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ofYejKKiSFYH2gLBb/jhqngog1yz1lyj7jxj32" alt=""></a></figure><p>图像理解基准看起来很相似。一些小的改进，一些大到足够有趣，如果这具有代表性的话。</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5065f262-f9f6-413f-8ddc-a0818caf96af_1230x706.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ofYejKKiSFYH2gLBb/puy4rl677dnmqgxdjqfa" alt=""></a></figure><p>同样，他们声称改进了视频的 SOTA，在许多情况下他们也将自己视为先前的 SOTA。</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1381be4d-d1a6-40ec-bac3-c30d8db25c7d_1198x544.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ofYejKKiSFYH2gLBb/nvyh2lwcplusfkpaznpf" alt=""></a></figure><p>对于图像生成，他们吹嘘文本和图像是无缝集成的，例如为博客提供文本和图像，但没有提供 Gemini 进行此类集成的示例。相反，我们得到的只是一些奇怪的微小图像。</p><p>我们确实看到了令人印象深刻的改进，那就是语音识别。请注意，这只是 Gemini Pro，而不是 Gemini Ultra，后者应该做得更好。</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4dd98ff1-8f37-480f-9aee-35661fe49c1b_1191x481.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ofYejKKiSFYH2gLBb/ploxecxdydx5qs0oiatn" alt=""></a></figure><p>您绝对会注意到这些错误率下降。 Nano 可以在设备上运行，而且它在 YouTube 上的表现比 Whisper 好得多。很酷。</p><p>这是另一种形式的基准测试。</p><blockquote><p> AlphaCode 团队构建了 AlphaCode 2（Leblond 等人，2023），这是一种由 Gemini 驱动的新型代理，它将 Gemini 的推理能力与搜索和工具使用相结合，擅长解决竞争性编程问题。 AlphaCode 2 在 Codeforces 竞争性编程平台上的参赛者中排名前 15%，比其排名前 50% 的最先进的前身有很大进步（Li 等人，2022）。</p><p> ……</p><p> AlphaCode 2 解决了 43% 的竞赛问题，比之前创下纪录的 AlphaCode 系统（解决了 25%）提高了 1.7 倍。</p></blockquote><p>我阅读的培训笔记主要是“我们使用了所有 TPU，实际上没有很多 TPU”，最有趣的笔记是这种加速。这是否意味着他们现在保存的检查点要少得多，如果是这样，这很重要吗？</p><blockquote><p>使用定期对持久集群存储进行权重检查的传统方法，在这种规模下维持高吞吐量（在训练作业的运行时间内计算有用的新步骤所花费的时间）是不可能的。</p><p>对于 Gemini，我们使用了模型状态的冗余内存副本，并且在任何计划外的硬件故障中，我们可以直接从完整的模型副本中快速恢复。与 PaLM 和 PaLM-2（Anil 等人，2023）相比，尽管使用的训练资源要大得多，但恢复时间显着加快。结果，最大规模训练作业的总体产出从 85% 增加到 97%。</p></blockquote><p>他们关于训练数据的部分放弃了一些技术提示，但明智地很少提及。他们以保密的方式刻意塑造了训练数据的组合。</p><p>在第 6 节中，他们进行了负责任的部署。我很欣赏他们明确表示他们明确关注部署问题。</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cc6332e-9c7f-4500-9cbc-56bcc60a297b_805x508.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ofYejKKiSFYH2gLBb/hpgjgrsg8kovglqo85ix" alt=""></a></figure><p>鉴于双子座尚未突破任何可怕的新领域，他们（正确地）专门关注常见形式的世俗伤害。</p><blockquote><p>基于对已知和预期影响的理解，我们制定了一套“模型政策”来指导模型开发和评估。模型策略定义充当负责任开发的标准化标准和优先级架构，并作为启动准备情况的指示。双子座模型政策涵盖多个领域，包括：儿童安全、仇恨言论、事实准确性、公平和包容以及骚扰。</p></blockquote><p>他们的指令调整使用了监督微调和 RLHF。</p><p>特别关注的是归因，这对谷歌来说很有意义。</p><p>另一个是避免从错误的前提进行推理，否则拒绝回答“无法回答”的问题。我们需要看到由此产生的行为，但听起来有趣的警察已经出动了。</p><p>听起来他们对事实的缓解措施并没有那么成功？除非我混淆了数字的含义。</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bc6215f-49c0-4323-b4d1-9a2e69632abe_1219x244.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ofYejKKiSFYH2gLBb/xdhxwebhm5dyceamdfwk" alt=""></a></figure><p>仔细查看附录及其示例，您会发现所给出的所有示例都令人印象深刻。</p><p>我注意到 DeepMind 如何诚实地处理报告能力和攻击基准，这是他们对安全承诺的重要标志。有一些令人担忧的迹象表明他们愿意做出相当大的改变。然而实际的安全预防措施并没有让我太困扰？</p><p>最大的安全预防措施是谷歌甚至没有称之为安全预防措施。他们正在发布 Gemini Pro，并阻止 Gemini Ultimate。这意味着他们对 Pro 进行了大规模的 beta 测试，其功能是无害的。他们可以用它来评估和调整 Ultimate，以便它做好准备。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://blog.google/technology/ai/google-gemini-ai/#capabilities">官方公告</a>提供了一些亮点。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.wired.com/story/google-deepmind-demis-hassabis-gemini-ai/">黛米斯·哈萨比斯 (Demis Hassabis) 接受《连线》杂志采访时谈论了双子座</a>。好像没有添加什么。</p><h4>二级吟游诗人</h4><p>Gemini Pro，即使没有Gemini Ultra， <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/GoogleDeepMind/status/1732430045275140415">也应该是对Bard的大幅升级</a>。问题是，当我们有 Claude 和 ChatGPT 可用时，这足以使其有用吗？我会像其他人一样尝试找出答案。巴德确实还有一些其他优势，所以当你最需要信息时，巴德可能会发挥作用，因此似乎会有一些目的。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/IntuitMachine/status/1732474666948661505">该视频展示了一些有用的即时工程</a>和推理能力，用于帮助计划孩子的生日聚会，主要是通过集思广益的可能性和提出澄清问题。如果他们确实直接集成了此功能，那就太酷了。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/nonmayorpete/status/1732544321122152940">皮特说巴德终于可以放心地推荐它了</a>。提示不是一流的，但他说自 9 月份以来已经有了很大改进，并且与 GMail、YouTube 和地图的集成非常有用。目前它绝对不是完全替代品，问题是它是否是一个很好的补充。</p><p>甚至在 Gemini 之前，Bard 就非常出色地帮助我儿子完成家庭作业，因此我把他送到那里而不是 ChatGPT。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/goodside/status/1657396491676164096">返回干净的 JSON 仍然需要极大的动力</a>。</p><p> Bard Advanced（带 Gemini Ultra）何时推出？ <a target="_blank" rel="noreferrer noopener" href="https://manifold.markets/Rodeo/will-bard-advanced-be-launched-by-j">这是关于它是否在一月份发生的市场</a>。</p><h4>双子座的反应</h4><p>有些人印象深刻。其他人则没有那么多。</p><p>第一件令人印象深刻的事情是，我们现在得到的只是 Gemini Pro。 Pro 显然没有那么令人印象深刻，明显落后于 GPT-4。</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/elidourado/status/1732426687218941982">Eli Dourado：</a>这是论文中的双子座评估表。请注意，今天发布的是 Gemini Pro，而不是 Gemini Ultra。因此，目前不要指望 Bard 会比 ChatGPT Plus 更好。看起来和克劳德2差不多。</p></blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/Simeon_Cps/status/1732425528727232772/history">西蒙？没有留下深刻印象。</a></p><p>西蒙：双子座来了。老实说，感觉就像是 GPT-4 + 更多的多模态 + epsilon 功能。所以我的猜测是，这在功能上并不是什么大问题，尽管从产品的角度来看这可能是一个大问题，而这似乎正是谷歌正在寻找的。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/nyctibia/status/1732443540880290002">与往常一样</a>，我们必须注意，所涉及的一切都是按照我们所看到的方式选择的，并且可能是经过设计或编辑的。生产价值越高，人们就越需要放松。</p><p>对于大型多模态视频来说，这个问题是一个大问题。</p><blockquote><p>罗宾：我发现<a target="_blank" rel="noreferrer noopener" href="https://t.co/YzDJV4YXTE">将这个宣传视频</a><a target="_blank" rel="noreferrer noopener" href="https://t.co/mOuqS3OznG">与实际提示</a>进行比较非常有启发性。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/robertwiblin/status/1732750022565879880">Robert Wiblin</a> （不同主题）：这是 Google 自己发布的内容。所以它可能是精挑细选的，但不是伪造的。我认为即使是樱桃采摘，它也令人印象深刻。</p></blockquote><p>这是伪造的吗？ <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/mariachong/status/1732812012969992326">编辑：是的</a>。是的。谷歌在几个层面上都感到羞耻。</p><p>抛开诚信问题，哇，我们现在都厌倦了，但是当我观看那个视频时，即使我认为它是真实的，我得到的最大印象是……大蹩脚的爸爸能量？</p><p>我确实知道这应该是实时发生的，但这一切都不让我感到惊讶。谷歌发布了它的重大新版本，我并不害怕。如果有的话，我有点无聊？这是你能做的最好的事情了吗？</p><p>然而，当观看完全相同的视频时，其他人的反应却不同。</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/amasad/status/1732439083555631581">Amjad Masad</a> （首席执行官 Replit）：这从根本上改变了人类使用计算机的方式。</p></blockquote><p>即使是真的吗？我的意思是，我想，如果您还没有假设所有这一切，并且对于普通用户来说是否如此顺利？我可以想到将摄像头连接到 Gemini 并进行音频讨论的例子可能会是一场大游戏。对我来说，这是一个奇怪的组合，令人印象深刻的部件已经被“定价”到我的世界模型中，而新部件似乎并不令人印象深刻。</p><p>所以我可能会卖空它，因为我对它作为可能发生的潜在事情感到厌倦。如果这代表了平稳的总体多式联运体验，那么还有很多值得探索的地方。</p><p> <a target="_blank" rel="noreferrer noopener" href="http://Gemini just dropped and, at least on the chosen benchmarks, seems to outperform GPT 4.0. Let's just say it's likely in the same ballpark.  This is not particularly surprising, Google and Deepmind have a world class team and immense resources.  I'm still puzzled as to what the commentators suggesting Google couldn't do it or wouldn't ship something like it were thinking.">Arthur 认为 Gemini 完成了它的工作</a>，但这并不奇怪，而且奇怪的是人们认为 Google 无法做到这一点。</p><p>丽芙·博瑞？印象深刻。</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/Liv_Boeree/status/1732427988321419545/history">Liv Boeree：</a>这太疯狂了，看起来他们基本上在每个基准上都超过了 GPT4……所以这是世界上最强大的模型？！哇哦，活着真是一个美好的时光啊。</p></blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/GaryMarcus/status/1732428456837935471">加里·马库斯？</a>在某些方面留下了深刻的印象，但在其他方面则没有。</p><blockquote><p> Gary Marcus：为以 $86B 购买 OpenAI 的风投公司的思考和祈祷。</p><p> Google Gemini 和 GPT-4 的热门观点： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7o3ZP7EDBpxLNGRG8/k1rmdo5ge8uslwormae6" alt="👉" style="height:1em;max-height:1em">从许多方面来看，Google Gemini 似乎与 GPT-4 相匹配（或略微超过），但还没有超越它。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7o3ZP7EDBpxLNGRG8/k1rmdo5ge8uslwormae6" alt="👉" style="height:1em;max-height:1em">从商业角度来看，GPT-4 不再是独一无二的。这对 OpenAI 来说是一个大问题，尤其是在戏剧性事件发生后，许多客户现在都在寻求备份计划。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7o3ZP7EDBpxLNGRG8/k1rmdo5ge8uslwormae6" alt="👉" style="height:1em;max-height:1em">从技术角度来看，关键问题是：法学硕士是否已接近稳定期？</p><p>请注意，盖茨和 Altman 都曾暗示过，尽管商业需求巨大，但 GPT-5 在一年后还没有出现。谷歌尽管拥有所有资源，但并没有击败 GPT-4，这一事实很能说明问题。</p></blockquote><p>我喜欢这样说 OpenAI 没有价值，因为 Gemini 太优秀了，也因为 Gemini 还不够好。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/tszzl/status/1732470963156250868">罗恩给予了精确的赞扬</a>。</p><blockquote><p> Roon：恭喜Gemini团队！这似乎是多式联运能力的全球高水位。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/tszzl/status/1732508388339396973">MMLU 结果似乎有点假</a>/不公平，但 HumanEval 数字看起来像是一个实际的改进，并且 ime 非常接近现实世界的编程实用程序</p><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/davidmanheim/status/1732444067785547973">David Manheim 似乎说得对</a>（其他线程）：我还没有使用过该系统，但如果它只是稍微优于 GPT-4，这似乎是轻微的证据表明法学硕士在人工智能方面的进展并没有加速许多人担心的方式和/或预测。</p></blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/joeykrug/status/1732451230541119851/history">Joey Krug 对基准测试上的捏造行为非常不以为然</a>，他说他们不仅在 MMLU 上全面这样做。</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/packyM/status/1732458006359462308">派基·麦考密克：你们所有人</a>（显示图片）</p><p> Ruxandra Teslo：等等，最近发生了什么？他们做了什么好事吗？</p><p> Packy：他们做得很好！</p></blockquote><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8193b99-4b9f-4dc7-b8dc-3518f8c1172a_726x900.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ofYejKKiSFYH2gLBb/ulvtx8h1uy6lqvbsm22h" alt="图像"></a></figure><p>谷歌的核心问题不是觉醒，而是他们是一家大公司，拥有大量的内部流程和权力，这些流程和权力阻碍、减缓或破坏创新，阻碍快速发展或集中注意力。尤其是在制作实用产品、整合各个团队的工作、制定激励措施等方面存在着一些问题。这里有巨大的潜力、大量的人才、充足的资源，但他们能将其转化为产品吗？</p><p>还为时过早。当然，他们距离“击败 OpenAI”还有很长的路要走，但这是第一个也是唯一一个有人参与游戏的情况。最接近的其他人是克劳德的更长的上下文窗口。</p><br/><br/><a href="https://www.lesswrong.com/posts/ofYejKKiSFYH2gLBb/gemini-1-0#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ofYejKKiSFYH2gLBb/gemini-1-0<guid ispermalink="false">的YejKKiSFYH2gLBb</guid><dc:creator><![CDATA[Zvi]]></dc:creator><pubDate> Thu, 07 Dec 2023 14:40:07 GMT</pubDate> </item><item><title><![CDATA[Random Musings on Theory of Impact for Activation Vectors]]></title><description><![CDATA[Published on December 7, 2023 1:07 PM GMT<br/><br/><p>我想分享一些关于为什么激活向量可能很重要的想法，但在阅读本文之前，您应该了解三件事：</p><ol><li>我不知道我在说什么</li><li>我不知道我在说什么</li><li>我绝对不知道我在说什么</li></ol><p>另外，也许这篇文章是多余的和不必要的<span class="footnote-reference" role="doc-noteref" id="fnrefqrpuhuwrepp"><sup><a href="#fnqrpuhuwrepp">[1]</a></sup></span> ，因为它已经在我没有见过的地方得到了解释。或者也许我在其他地方见过有人写过这个，但只是不记得出处。</p><p>但这里是这样的：</p><p>当我们有其他控制网络的方法（例如提示或微调）时，为什么激活向量对于对齐很重要？</p><p>激活向量的一种观点是它们是一种黑客或玩具。只需通过网络传递一个单词并添加它就可以控制网络，这不是很酷吗？</p><p>另一种观点是，他们正在利用一些基本的东西，看看 Beren 的<a href="https://www.lesswrong.com/posts/JK9nxcBhQfzEgjjqe/deep-learning-models-might-be-secretly-almost-linear">深度学习模型可能秘密地（几乎）是线性的</a>。在这种情况下，我们应该期望随着网络规模的扩大，它会继续工作，甚至更好，而不是随机中断/停止工作。</p><p>另一个框架如下：语言对于神经网络来说是一种尴尬的操作格式，因此它们将其翻译成一个潜在的空间，将重要的组成部分分开，当然还有一定程度的叠加。提示和微调是影响这些网络行为的迂回方式：我们要么将其推入特定的模拟，要么训练网络以更好地欺骗自己，认为它做得很好。</p><p>理想情况下，我们只要有足够的可解释性知识，就可以直接干预潜在空间，设置或增加正确的神经元。激活向量比这更加分散，但它们更接近理想状态，并且可以作为概念证明。</p><p>例如，执行“快乐-悲伤”减法以获得幸福向量的技巧演示了如何通过将这些共有的所有特征归零来改进这一点。这些特征比如都是英语、都不太正式、都是形容词等等。可能大多是无关紧要的。更先进的方法（例如<a href="https://arxiv.org/abs/2306.03341">推理时间干预）</a>使我们能够通过仅对特定头部进行干预来进一步完善这一点。这个技术还是比较简单的；如果我们能够找到缩小干预范围的正确方法，我们可能会实现或非常接近直接干预正确潜在因素的梦想。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnqrpuhuwrepp"> <span class="footnote-back-link"><sup><strong><a href="#fnrefqrpuhuwrepp">^</a></strong></sup></span><div class="footnote-content"><p>我知道“不必要”这个词在这里是多余的，没有必要的。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/k9z9fzpAgMLGQG9hg/random-musings-on-theory-of-impact-for-activation-vectors#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/k9z9fzpAgMLGQG9hg/random-musings-on-theory-of-impact-for-activation-vectors<guid ispermalink="false"> k9z9fzpAgMLGQG9hg</guid><dc:creator><![CDATA[Chris_Leong]]></dc:creator><pubDate> Thu, 07 Dec 2023 13:07:09 GMT</pubDate></item></channel></rss>