<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 10 月 25 日星期三 16:15:16 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Anthropic, Google, Microsoft and OpenAI announce Executive Director of the Frontier Model Forum and over $10 million for a new AI Safety Fund]]></title><description><![CDATA[Published on October 25, 2023 3:20 PM GMT<br/><br/><ul><li> Chris Meserole 被任命为前沿模型论坛的首任执行董事，该论坛是一个致力于确保全球前沿人工智能模型安全、负责任的开发和使用的行业机构。</li><li> Meserole 拥有丰富的经验，专注于新兴技术及其未来应用的治理和安全。</li><li>今天，论坛成员与慈善合作伙伴 Patrick J. McGovern 基金会、David and Lucile Packard 基金会、Eric Sc​​hmidt 和 Jaan Tallinn 合作，承诺为新的 AI 安全基金提供超过 1000 万美元的资金，以推进对正在开发的工具的研究帮助社会有效测试和评估最有能力的人工智能模型。</li></ul><p> <strong>2023 年 10 月 25 日</strong>- 今天，Anthropic、谷歌、微软和 OpenAI 宣布选举<a href="https://www.frontiermodelforum.org/leadership/">Chris Meserole</a>为<a href="http://frontiermodelforum.org/">前沿模型论坛</a>首任执行董事，并设立新的人工智能安全基金，这是一项超过 1000 万美元的倡议，推动人工智能安全领域的研究。前沿模型论坛是一个专注于确保安全和负责任地开发前沿人工智能模型的<a href="https://blog.google/outreach-initiatives/public-policy/google-microsoft-openai-anthropic-frontier-model-forum/">行业机构</a>，该论坛还发布了第一个有关红队的技术工作组更新，以与更广泛的受众分享行业专业知识，同时该论坛扩大了有关负责任的人工智能治理的对话接近。</p><p><strong>执行董事</strong></p><p>Chris Meserole 来到前沿模型论坛，在技术政策方面拥有深厚的专业知识，他在新兴技术及其未来应用的治理和安全方面进行了广泛的研究。最近，他担任布鲁金斯学会人工智能和新兴技术计划主任。</p><p>在这一新角色中，Meserole 将负责帮助论坛履行其使命：(i) 推进人工智能安全研究，以促进前沿模型的负责任开发并最大程度地减少潜在风险，(ii) 确定前沿模型的安全最佳实践，(iii)与政策制定者、学者、民间社会和其他人分享知识，推动负责任的人工智能发展； (iv) 支持利用人工智能应对社会最大挑战的努力。</p><p> “最强大的人工智能模型为社会带来了巨大的希望，但为了实现它们的潜力，我们需要更好地了解如何安全地开发和评估它们。我很高兴能够通过前沿模型论坛来应对这一挑战。” - 克里斯·梅塞罗尔</p><p><strong>人工智能安全基金</strong></p><p>在过去的一年里，工业界推动了人工智能功能的显着进步。随着这些进步的加速，需要对人工智能安全进行新的学术研究。为了解决这一差距，论坛和慈善合作伙伴正在创建一个新的人工智能安全基金，该基金将支持来自世界各地附属于学术机构、研究机构和初创公司的独立研究人员。 AI 安全基金的初始资金承诺来自 Anthropic、Google、Microsoft 和 OpenAI，以及我们的慈善合作伙伴 Patrick J. McGovern 基金会、David and Lucile Packard 基金会*、Eric Sc​​hmidt 和 Jaan Tallinn 的慷慨捐助。初始资金总计超过 1000 万美元。我们期待其他合作伙伴的额外贡献。</p><p>今年早些时候，论坛成员在白宫签署了自愿人工智能承诺，其中包括承诺促进第三方发现和报告我们人工智能系统中的漏洞。论坛将人工智能安全基金视为履行这一承诺的重要组成部分，为外部社区提供资金，以更好地评估和理解前沿系统。关于人工智能安全和通用人工智能知识库的全球讨论将受益于更广泛的声音和观点。</p><p>该基金的主要重点将是支持红队人工智能模型新模型评估和技术的开发，以帮助开发和测试前沿系统潜在危险能力的评估技术。我们相信，增加该领域的资金将有助于提高安全标准，并为行业、政府和民间社会应对人工智能系统带来的挑战所需的缓解和控制提供见解。</p><p>该基金将在未来几个月内征集提案。 Meridian Institute 将管理该基金——他们的工作将得到一个由独立外部专家、人工智能公司专家以及具有资助经验的个人组成的咨询委员会的支持。</p><p><strong>技术专长</strong></p><p>在过去的几个月里，论坛致力于帮助建立一套术语、概念和流程的通用定义，以便我们有一个可以构建的基线理解。这样，研究人员、政府和其他行业同行就能够在讨论人工智能安全和治理问题时拥有​​相同的起点。</p><p>为了支持建立共识，论坛还致力于分享整个行业的红队最佳实践。作为起点，论坛共同制定了人工智能“红队”的通用定义，并在新的<a href="https://www.frontiermodelforum.org/uploads/2023/10/FMF-AI-Red-Teaming.pdf">工作组更新</a>中提供了一组共享案例研究。我们将红队定义为一种结构化流程，用于探测人工智能系统和产品，以识别有害功能、输出或基础设施威胁。我们将以这项工作为基础，并致力于共同努力，继续我们的红队工作。</p><p>我们还正在开发一种新的负责任的披露流程，通过该流程，前沿人工智能实验室可以共享与前沿人工智能模型中发现的漏洞或潜在危险功能及其相关缓解措施相关的信息。一些前沿模型论坛公司已经发现了人工智能在国家安全领域的功能、趋势和缓解措施。论坛相信，我们在这一领域的综合研究可以作为前沿人工智能实验室如何完善和实施负责任的披露流程的案例研究。</p><p><strong>下一步是什么</strong></p><p>在接下来的几个月中，前沿模型论坛将成立一个顾问委员会，以帮助指导其战略和优先事项，代表一系列观点和专业知识。未来的版本和更新，包括有关新成员的更新，将直接来自前沿模型论坛 - 因此请继续关注他们的网站以获取更多信息。</p><p>人工智能安全基金将在未来几个月内发出第一次提案征集，我们预计拨款将在不久后发放。</p><p>前沿模型论坛还将发布更多可用的技术研究结果。</p><p>论坛很高兴与 Meserole 合作，并加深与更广泛的研究界的合作，包括<a href="https://partnershiponai.org/">Partnership on AI</a> 、 <a href="https://mlcommons.org/">MLCommons</a>以及其他领先的非政府组织、政府和跨国组织，以帮助实现人工智能的好处，同时促进其安全发展并使用。</p><br/><br/> <a href="https://www.lesswrong.com/posts/5jpESFymqEgSAmDJL/anthropic-google-microsoft-and-openai-announce-executive#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/5jpESFymqEgSAmDJL/anthropic-google-microsoft-and-openai-announce-executive<guid ispermalink="false"> 5jpESFymqEgSAmDJL</guid><dc:creator><![CDATA[Zach Stein-Perlman]]></dc:creator><pubDate> Wed, 25 Oct 2023 15:20:53 GMT</pubDate> </item><item><title><![CDATA["The Economics of Time Travel - call for reviewers (Seeds of Science)]]></title><description><![CDATA[Published on October 25, 2023 3:13 PM GMT<br/><br/><h2><strong>抽象的</strong></h2><p>缺乏时间旅行者来访可能被视为时间旅行不可能的证据。在这篇文章中，我认为另一种解释是，我们在经济上对我们的后代来说不够重要，不足以证明时间旅行的成本是合理的。通过成本效益分析，我详细阐述了这个论点。我认为时间旅行的主要成本可能是能源成本，而时间旅行的最大好处是现在拥有但未来失去的知识。着眼于这一利益部分，我认为我们极不可能拥有对未来文明（系统关键）足够重要的知识，但又被该文明所遗失。这就是说，我们可能没有被时间旅行者拜访过，因为我们还不够重要。</p><p><br> ---</p><p> <a href="https://www.theseedsofscience.org/"><i>Seeds of Science</i></a>是一本期刊（由 Scott Alexander 的<a href="https://astralcodexten.substack.com/p/acx-grants-results">ACX 资助计划</a>资助），发表有关科学主题的推测性或非传统文章。同行评审是通过基于社区的投票和多元化评审者网络（我们称之为“园丁”）的评论来进行的。以有用的方式批评或扩展文章（“科学的种子”）的评论将发布在正文之后的最终文件中。</p><p>我们刚刚发出了一份手稿供审阅，《时间旅行的经济学》，LessWrong 社区中的一些人可能会对它感兴趣，所以我想看看是否有人有兴趣以园丁的身份加入我们，并提供关于时间旅行的反馈。文章。如上所述，这是将您的评论记录在科学文献中的机会（可以用真名或假名发表评论）。</p><p>作为园丁可以免费加入，任何人都受到欢迎（我们目前有来自学术界内外各个级别的园丁）。参与完全是自愿的 - 我们向您发送提交的文章，您可以选择投票/评论或弃权，恕不另行通知（因此，如果您不打算经常审阅，而只是想到处看看文章，请不要担心）正在提交）。</p><p>要注册，您可以填写此<a href="https://docs.google.com/forms/d/e/1FAIpQLSfRIicHT7jIZcSUjwsIlby6JBxx2ZVeD5kseZBpgGFtp8pLfg/viewform">谷歌表格</a>。从那里开始，一切就很不言自明了——我会将您添加到邮件列表中，并向您发送一封电子邮件，其中包括稿件、我们的出版标准以及用于记录投票/评论的简单评审表。如果您只想看一下这篇文章而不被添加到邮件列表中，那么只需联系 (info@theseedsofscience.org) 并说明即可。</p><p>很高兴通过电子邮件或下面的评论回答有关该期刊的任何问题。</p><br/><br/> <a href="https://www.lesswrong.com/posts/NnGWJHutwBiJMovw8/the-economics-of-time-travel-call-for-reviewers-seeds-of#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/NnGWJHutwBiJMovw8/the-economics-of-time-travel-call-for-reviewers-seeds-of<guid ispermalink="false"> NnGWJHutwBiJMovw8</guid><dc:creator><![CDATA[rogersbacon]]></dc:creator><pubDate> Wed, 25 Oct 2023 15:14:00 GMT</pubDate> </item><item><title><![CDATA[Compositional preference models for aligning LMs]]></title><description><![CDATA[Published on October 25, 2023 12:17 PM GMT<br/><br/><p><i>这篇文章总结了我们最近发布的论文《</i><a href="https://arxiv.org/abs/2310.13011"><i><u>用于调整语言模型的组合偏好模型》</u></i></a>的主要结果<i>，并将它们置于更广泛的人工智能安全背景中。如需本文的快速摘要，请查看我们的</i><a href="https://twitter.com/dongyoung4091/status/1717045681431753097"><i><u>Twitter 帖子</u></i></a><i>。</i></p><p> <strong>TL;DR</strong> ：我们提出了一种根据提示 LM 构建偏好模型的新方法。组合偏好模型 (CPM) 将文本评分分解为 (1) 构造一系列有关该文本的可解释特征的问题（例如，文本的信息量有多大），(2) 从提示的 LM（例如 ChatGPT）中获取这些特征的标量分数，以及（3）使用经过训练来预测人类判断的逻辑回归分类器聚合这些分数。我们表明，与标准偏好模型 (PM) 相比，CPM 具有更好的泛化能力，并且对于奖励模型过度优化更加稳健。此外，使用 CPM 获得的<i>n 个</i>最佳样本往往比使用类似的传统 PM 获得的样本更受青睐。最后，CPM 是可扩展监督的一个新颖角度：它们将困难的评估问题分解为一系列更简单、人类可解释的评估问题。</p><h2>成分偏好模型如何运作？ </h2><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/oSgac8x8fgNj22ky3/f3vsa8j7pc4prer3msln"></p><p><i>图 1：标准 PM 直接输出偏好分数，而 CPM 分别对 LM 响应的不同特征进行评分，并将偏好分数输出为特征值的线性组合。</i></p><p>偏好模型 (PM) 是经过训练的模型，用于为 LM 响应分配一个指示响应质量的分数。它们是许多对齐 LM 技术的主力：除了在其他技术（例如<a href="https://www.lesswrong.com/posts/8F4dXYriqbsom46x5/pretraining-language-models-with-human-preferences"><u>利用人类反馈进行预训练</u></a>）中发挥作用之外，它们最显着地用作 RLHF 中的奖励函数或 best-of-n 采样中的排名模型。</p><p>标准 PM 涉及在基本模型之上添加标量头并微调整个模型（或某些上层）以预测人类更喜欢两个文本中的哪一个。虽然这种方法在实践中非常有效，但它可能会导致无法解释的模型，这些模型符合人类偏好判断中的虚假相关性，并且容易出现 Goodharting（过度优化）。</p><p>我们引入了另一种选择：组合偏好模型（CPM）。与 PM 相比，CPM 将响应评估分解为以下步骤：</p><p><strong>特征分解</strong>。我们维护一个固定的列表，其中包含 13 个人类可解释的特征（例如特异性、相关性、可读性）和 13 个相应的提示模板（例如<code>You will be shown a conversation [...] please judge whether the assistant&#39;s reply is relevant. Score that on a scale from 1 to 10 [...] {conversation_history} {reply}</code> )。</p><p><strong>特征评分</strong>。我们要求 LM（例如 GPT-3.5）为每个特征分配一个分数。单个响应的每个特征都在单独的上下文窗口中评分。</p><p><strong>聚合</strong>。使用经过训练来预测人类偏好判断（即人类会更喜欢两个文本中的哪一个）的逻辑回归分类器将特征分数组合成标量偏好分数。</p><h2>过度优化的鲁棒性</h2><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/oSgac8x8fgNj22ky3/o5db8cfk3giywvfxc9kv"></p><p><i>图 2：黄金 PM（实线）和相应的代理 PM（虚线）对通过最佳 n 采样针对黄金 PM 获得的样本给出的分数。 CPM-GPT-3.5和CPM-Flan-T5分别是指基于GPT-3.5和Flan-T5进行特征提取构建的CPM。</i></p><p>为了研究 CPM 是否提高了过度优化的鲁棒性，我们遵循了<a href="https://www.lesswrong.com/posts/shcSdHGPhnLQkpSbX/scaling-laws-for-reward-model-overoptimization"><u>Gau 等人的设置。 （2023）</u></a>并构建一个综合数据集，其中假设一个 PM（定义为“黄金 PM”）的输出是人类偏好的基本事实。然后，我们使用黄金 PM 生成合成标签来训练代理 PM。我们分别对三对代理和黄金 PM 进行此操作：(i) 标准 PM，(ii) 使用 GPT-3.5 进行特征提取的 CPM，以及 (iii) 使用 Flan-T5-XL（3B 参数）进行特征提取的 CPM。最后，我们针对给定的代理 PM 进行 best-of- <i>n</i>操作，并根据代理 PM 和黄金 PM 来比较这些最佳样本的分数。</p><p>当我们增加优化压力（候选者数量<i>n</i> ）时，代理 PM 给出的分数与金牌 PM 给出的分数有所不同（见图 2）。这是偏好模型过度优化的指标，这是一种奖励黑客形式，其中代理 PM 分数的优化是由黄金 PM 漠不关心的虚假特征驱动的。这个差距的大小（越小越好）表明给定 PM 的鲁棒性，使其不会被过度优化。在这里，我们观察到 CPM 的差距（在图中，实线和虚线之间）往往比标准 PM 更小，并且增长速度更慢。</p><p>这表明 CPM 比标准 PM 更能抵抗过度优化。无论是使用高能力 (GPT-3.5) 还是低能力 (Flan-T5-XL) LM 作为 CPM 中的特征提取器，这一点都成立。</p><h2>质量评价</h2><p><img style="width:58.62%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/oSgac8x8fgNj22ky3/jperxazhwouwuec9wyc2"></p><p><i>图 3：使用给定 PM 通过 16 中最佳采样获得的响应胜率与通过标准采样获得的响应的胜率，根据人类 HH 数据集 (HH-RLHF) 和斯坦福人类偏好数据集 (SHP) 的提示进行计算。</i></p><p>我们将通过 best-of- <i>16</i>获得的 LM 样本与 CPM 或标准 PM 进行比较，方法是将它们与<i>未经</i>best-of- <i>n</i>采样生成的样本进行比较。为此，我们向评估器 LM (Claude 2.0) 展示<i>16</i>选最佳样本和普通样本，并计算获胜率，即<i>16</i>选最佳样本优于普通样本的频率。即使我们将特征提取器 LM 的功能与标准 PM 的功能相匹配（通过为两者选择 Flan-T5-XL），CPM 往往比标准 PM 具有更高的获胜率。这表明，通过预先选择 CPM 中的可解释和相关特征将先验知识注入 PM，对于了解人类偏好非常有帮助。</p><h2> CPM 和可扩展的监督</h2><p><a href="https://arxiv.org/abs/2211.03540"><u>可扩展监督</u></a>是评估比评估者更有能力的代理人行为的问题。解决这个问题很重要，因为一方面，语言模型很快就能完成人类无法提供反馈的任务。另一方面，LM 也可能能够<a href="https://www.lesswrong.com/posts/mLfPHv4QjmeQrsSva/paper-on-measuring-situational-awareness-in-llms"><u>推理其评估程序中的缺陷，并在监督者不知情的情况下利用它们</u></a>。</p><p>目前解决可扩展监督问题的建议主要集中在递归地依赖其他 LM 来协助人类评估者（<a href="https://www.lesswrong.com/tag/debate-ai-safety-technique-1"><u>辩论</u></a>、<a href="https://www.lesswrong.com/tag/iterated-amplification"><u>迭代蒸馏和放大</u></a>、 <a href="https://deepmindsafetyresearch.medium.com/scalable-agent-alignment-via-reward-modeling-bf4ab06dfd84"><u>递归奖励建模</u></a>），但很大程度上仍然是理论性的。<a href="https://arxiv.org/abs/2212.08073"><u>来自人工智能反馈的强化学习</u></a>——使用精心提示的 LM 为 PM 生成训练数据——可以说是如何使用 LM 大规模监督 LM 的最成功的演示。</p><p> CPM 探索解决 LM 的可扩展监督问题的替代途径，探索分而治之策略解决硬评估问题的前景。 CPM 可以被视为一种将难题（“这个回答有帮助吗？”）分解为一系列更简单的问题（“这个回答可读吗？”等）的方法，这些问题对于 LM 来说更容易回答，对于人类来说也更容易回答监督。虽然我们停在分解的单个步骤上，但原则上没有什么可以阻止我们递归地应用这个想法，例如将复杂响应的评估分解为有关原子主张的简单问题。</p><p>将复杂的评估问题分解为更简单的子问题的想法有几个额外的好处：</p><ol><li><strong>利用人类先验</strong>。功能和提示模板的预选提供了注入先验知识并赋予 PM 有用的归纳偏差的自然方式。 CPM 的参数空间由选择的有意义且稳健的特征组成。</li><li><strong>通过限制 PM 容量来避免奖励黑客行为</strong>。使用特征提取器预先计算的特征使我们能够显着降低使用它们的 PM 的容量（在我们的实验中，从 3B 到只有 13 个参数，即 8 个数量级！），并限制它们对偏好数据中的虚假相关性过度拟合的敏感性。手头上只有 13 个参数，奖励破解真的很难！</li><li><strong>可解释性</strong>。预先选择的特征是可以简单解释的，与特征相关的逻辑回归系数可以解释为特定偏好判断的显着性（效应大小）（参见论文第 4.6 节）。事实上，偏好判断可以通过预选特征的线性组合来解释的想法最近得到了两篇并发论文的验证： <a href="https://www.lesswrong.com/posts/g5rABd5qbp8B4g3DE/towards-understanding-sycophancy-in-language-models"><u>《Towards Understanding Sycophancy in Language Models</u></a> and <a href="https://arxiv.org/abs/2309.16349"><u>Human Feedback is not Gold Standard</u></a> 》。使用这样的线性模型作为实际的 PM 可以使其判断更加透明并且易于基于流程的监督。</li><li><strong>狭窄性</strong>。我们的每个特征提取器都解决一个狭窄的问题，不需要了解其他特征或分数如何聚合。 <a href="https://www.lesswrong.com/posts/BKvJNzALpxS3LafEs/measuring-and-improving-the-faithfulness-of-model-generated"><u>最近发现在不同的上下文窗口中解决不同的子问题可以提高推理的可信度</u></a>。就 CPM 而言，单个特征提取器不知道它要分配的分数将如何在下游使用，这使得它更难对分数进行策略性调整，也更难发挥<a href="https://www.lesswrong.com/posts/yRAo2KEGWenKYZG9K/discovering-language-model-behaviors-with-model-written"><u>阿谀奉承</u></a>或欺骗的能力。</li></ol><p>然而，CPM 仍然存在某些局限性，未来的工作可以解决这些局限性：</p><ol><li><strong>人类反馈。</strong> CPM 仍然使用人类给出的成对偏好判断作为聚合特征分数的训练信号。就人类犯错误而言，这本质上是有限的， <a href="https://www.lesswrong.com/posts/g5rABd5qbp8B4g3DE/towards-understanding-sycophancy-in-language-models"><u>有时更喜欢谄媚的反应而不是真实的反应</u></a>，或者<a href="https://arxiv.org/abs/2309.16349"><u>权威的反应而不是事实的反应</u></a>。</li><li><strong>人性化的策展。</strong>在特征选择和用于特征提取的提示模板的提示工程方面，CPM 依赖于人类。就域外泛化而言，这些因素可能会受到限制（例如，评估表现出超人表现的代理）。</li></ol><h2>包起来</h2><p>我们提出了组合偏好模型：通过在提示 LM 提取的特征之上训练逻辑回归来构建 PM 的想法。我们证明，具有 13 个参数的 CPM 在人类评估和奖励模型过度优化的鲁棒性方面优于标准 PM，同时也更具可解释性。</p><p><i>这篇文章受益于 Mikita Balesni、Richard Ren、Euan McLean 和 Marc Dymetman 的有益评论。</i>我还要感谢<a href="https://arxiv.org/abs/2310.13011"><i><u>这篇论文</u></i></a><i>的合著者</i><i>：Dongyoung Go、Germán Kruszewski、Jos Rozen 和 Marc Dymetman。</i></p><p><br><br><br><br><br><br><br><br><br><br><br></p><br/><br/> <a href="https://www.lesswrong.com/posts/oSgac8x8fgNj22ky3/compositional-preference-models-for-aligning-lms#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/oSgac8x8fgNj22ky3/compositional-preference-models-for-aligning-lms<guid ispermalink="false"> osgac8x8fgNj22ky3</guid><dc:creator><![CDATA[Tomek Korbak]]></dc:creator><pubDate> Wed, 25 Oct 2023 12:17:28 GMT</pubDate> </item><item><title><![CDATA[Should the US House of Representatives adopt rank choice voting for leadership positions?]]></title><description><![CDATA[Published on October 25, 2023 11:16 AM GMT<br/><br/><p>一个明显的观点，党派偏见和政党权力利益，可能会表明强烈的“不！”响应类型。如果今天作为一个想法提出，我当然希望许多现任代表会以这种方式做出回应。但也许我错了。</p><p>我认为，就目前的情况来看，众议院明显丧失能力，可以从这种投票结构中受益匪浅，因为它允许比目前存在的程序更具功能性。</p><p>这样的程序改变有哪些优点和缺点？</p><br/><br/> <a href="https://www.lesswrong.com/posts/6ehdEpSonYzE72yL2/should-the-us-house-of-representatives-adopt-rank-choice#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/6ehdEpSonYzE72yL2/should-the-us-house-of-representatives-adopt-rank-choice<guid ispermalink="false"> 6EpsonYzE72yL2</guid><dc:creator><![CDATA[jmh]]></dc:creator><pubDate> Wed, 25 Oct 2023 11:16:14 GMT</pubDate> </item><item><title><![CDATA[Researchers believe they have found a way for artists to fight back against AI style capture]]></title><description><![CDATA[Published on October 25, 2023 10:54 AM GMT<br/><br/><p>真正的细节在这里：<a href="https://glaze.cs.uchicago.edu/what-is-glaze.html">什么是釉？</a></p><p>我想知道这种技术对于对抗性攻击有多鲁棒。它声称在像素级别工作，通过以人眼不可见的方式扭曲像素来掩盖图像，但这会导致生成人工智能模型失效。</p><p>但是艺术品的高分辨率照片或计算机显示器上的图像又如何呢？我经常拍摄我认为引人注目的艺术品的照片，然后使用 Midjourney 对其进行样式复制以制作新颖的图像。</p><p>当然，这无法扩展到大规模数据抓取（或者可以吗？），但我观察到 Midjourney 可以从一些从未见过的图像中以高保真度进行样式复制。</p><p>平心而论，创作者并没有声称它是面向未来的。</p><br/><br/> <a href="https://www.lesswrong.com/posts/4PtdBfacJZQqzhbCR/researchers-believe-they-have-found-a-way-for-artists-to#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/4PtdBfacJZQqzhbCR/researchers- believe-they-have-found-a-way-for-artists-to<guid ispermalink="false"> 4PtdBfacJZQqzhbCR</guid><dc:creator><![CDATA[vernamcipher]]></dc:creator><pubDate> Wed, 25 Oct 2023 10:54:24 GMT</pubDate> </item><item><title><![CDATA[Why We Disagree]]></title><description><![CDATA[Published on October 25, 2023 10:50 AM GMT<br/><br/><p>鲍勃花了 5 分钟思考 x 风险。他看到了一些关于这个问题的论点，所以他建立了问题的内部模型，接受了一些论点，修正了一些论点，提出了对其他论点的反驳，提出了自己的论点。所有这些信仰状态都具有极大的自由度。与此同时，这些信念已经对大量可能的 x 风险论点产生了意见。</p><p> Alice 花了 5 个小时在一篇帖子中详细阐述了她对 X 风险的看法。鲍勃逐条地读它。他已经看到了其中一些论点，但他没有更新。有些论点对他来说是新的，但他并不感到惊讶，鲍勃当前的信念足以拒绝它们，他没有更新。该帖子对他的一些公认的信念提出了新的反驳，但他可以立即提出反驳，他不会更新。这篇文章驳斥了他已经拒绝的论点，以及他从未认为合理的新论点，鲍勃正在睡着，他没有更新。 ETC。</p><p>鲍勃发表评论，其中对爱丽丝的一个观点提出了反驳。在接下来的几天里，他们要花几个小时来来回回。他们正在解释对论点和假设的稍微不同的理解，术语的用法略有不同，交换长序列的论点和反驳。最终鲍勃同意爱丽丝是对的，他更新了！但他只在第一条评论中更新了这一点。他还有许多其他独立的论点，因此他对 x 风险的信念的总体更新很小。</p><p><br>许多其他人读了同一篇文章，并发现它非常有说服力。这怎么发生的？</p><ul><li>卡尔还没有花5分钟思考这个问题。他可能没有兴趣，或者他以前可能没有听说过。所以这里发生的事情不是“不同意”而是“教育”。这有点好。将来，爱丽丝和卡尔会发现使用这种共同的理解和共同的语言很容易合作。但这个群体有多大？卡尔事件愿意解决这个问题吗？</li><li>丹（Dan）非常重视爱丽丝（Alice），将其视为权威，将自己的先验扔进垃圾桶。这或多或少是有道理的。但一个不认真考虑自己信仰的人永远不会为改善自己的信仰做出贡献。很难知道他们是否理解这些论点，而不仅仅是微笑和点头。</li><li>艾德考虑过这一点，但他不知道爱丽丝的论点之一引用了一些确凿的相关数据。不幸的是，这对于抽象主题来说非常稀缺。这个故事的寓意可能是尽可能避免谈论抽象话题。</li></ul><p><br>那么鲍勃呢？爱丽丝和鲍勃都是理性、通情达理的人。他一开始就对x-risk有一些兴趣。但他们的讨论完全是浪费时间。这怎么发生的？</p><ul><li>语言的信息含量非常低。简短的陈述含糊其辞，缺乏说服力。精确的陈述需要很长时间来编写和解析，它们很狭窄并且会带来新的混乱。</li><li>一篇博客文章太小，无法解决分歧。爱丽丝不可能预测并反驳鲍勃头脑中的每一个论点。仅仅通过查看爱丽丝设法写下的一小部分信念，鲍勃不太可能发现与他已经考虑过的完全不同的东西。</li><li>没有历史。爱丽丝可能会告诉鲍勃“这个反驳之前已经讨论过”，但实际上指出这样的讨论是很困难的。而且鲍勃不可能在旧线程中提出新问题，因此此类参考没有什么价值。</li><li>没有合作。 Frank 觉得他 100% 同意 Alice 的观点，但是他可以向 Bob 解释“她”的观点吗？她会同意他持有同样的观点吗？没有办法知道，所以弗兰克选择什么也不说。</li><li>目前还没有达成共识。鲍勃是否知道爱丽丝的观点是主流和常识，还是她刚才想出来的？即使这个帖子有数百个业力，这能说明什么吗？这些业力有多少来自卡尔、丹或埃德？爱丽丝也不知道。<br></li></ul><br/><br/><a href="https://www.lesswrong.com/posts/4Risce8ArMmjjW4om/why-we-disagree#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/4Risce8ArMmjjW4om/why-we-disagree<guid ispermalink="false"> 4Risce8ArMmjjW4om</guid><dc:creator><![CDATA[zulupineapple]]></dc:creator><pubDate> Wed, 25 Oct 2023 10:50:26 GMT</pubDate> </item><item><title><![CDATA[Announcing Epoch's newly expanded Parameters, Compute and Data Trends in Machine Learning database]]></title><description><![CDATA[Published on October 25, 2023 2:55 AM GMT<br/><br/><p>机器学习模型的性能与其训练数据量、计算量和参数数量密切相关。在 Epoch，我们正在研究使当今的人工智能达到新高度的关键输入。</p><p>我们最近扩展的参数、计算和数据趋势数据库追踪了数百个具有里程碑意义的机器学习系统和研究论文的详细信息。</p><p>在过去六个月中，我们添加了 240 个新语言模型和 170 个计算估计。我们将维护该数据集，用更多历史信息更新它，并添加新的重要版本。对于记者、学者、政策制定者以及任何有兴趣了解人工智能发展轨迹的人来说，这都是宝贵的资源。</p><p>访问<a href="https://epochai.org/data/pcd">epochai.org/data/pcd</a> ，探索<a href="https://epochai.org/mlinputs/visualization">交互式可视化</a>、查看<a href="https://epochai.org/data/pcd/documentation">文档</a>并访问数据以进行您自己的研究。</p><br/><br/> <a href="https://www.lesswrong.com/posts/LKDFkwFpWfgGpGs8d/announcing-epoch-s-newly-expanded-parameters-compute-and#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/LKDFkwFpWfgGpGs8d/announcing-epoch-s-newly-expanded-parameters-compute-and<guid ispermalink="false"> LKDFkwFpWfgGpGs8d</guid><dc:creator><![CDATA[Robi Rahman]]></dc:creator><pubDate> Wed, 25 Oct 2023 02:55:08 GMT</pubDate> </item><item><title><![CDATA[What is a Sequencing Read?]]></title><description><![CDATA[Published on October 25, 2023 2:10 AM GMT<br/><br/><p>如今，<span>最常见的</span><a href="https://www.jefftk.com/p/sequencing-intro">基因测序</a>形式可能是“双端”测序。非常令人印象深刻：测序仪可以从两端处理相同的核酸片段！这意味着每个观察结果如下所示：</p><p></p><pre> +--------------+---------+--------------+
|转发阅读 |差距|反向读|
+--------------+---------+--------------+
</pre><p>由于当您进一步对片段进行测序时，准确性（“质量”）往往会下降，因此从两端测序比尝试从一端对整个片段进行测序可以提供更准确的数据。而且因为我们通过将重叠的序列拼凑在一起（“组装”）来构建更大的序列（“重叠群”），所以由间隙分隔的两个碱基序列实际上通常比相同数量的没有间隙的碱基序列更有用。</p><p>通常用“2x150”这样的名称来指代双端测序，其中“2x”告诉我们它是双端，“150”告诉我们它从每个末端读取 150 个碱基，总共 300 个碱基每个片段。</p><p>但这引入了一个术语问题：什么是读取？当我们只进行“单端”测序时，很明显：每个测序片段、每个连续的碱基序列都是一个读数。然而，通过双端测序，这些不再是同一件事了！ “阅读”可能意味着两件事：</p><p></p><ul><li>阅读：一系列连续的碱基。</li><li>读取：来自测序片段的碱基。</li></ul><p>例如，假设我们有：</p><p></p><pre> >;SRR14530724.2 2/1
CATTTTCGACGGCGTCGATGTACAAAGGTTTAACCATAGTAAGTCCGAAGC
TACAGGCTTATGACACCGCAGAGTCAATGTATTCCGGTGACAATGTACTGA
TGTACAGTGGGACTGACACTGTCTCTTATACACATCTCCGAGCCCACGA
>;SRR14530724.2 2/2
TGTCAGTCCCACTGTACATCAGTACATACACACCGGAATACATTGACTCTG
CGGTGTCATAAGCCTGTAGCTTCGGACTTACTATTGGTATAACCTTTGTACA
TCGACGCCGTCGAAAATGCTGTCTCTTATACACATCTGACGCTGCCGAC
</pre><p>这是正向读取 (SRR14530724.2 2/1) 和反向读取 (SRR14530724.2 2/2)，它们共同构成对样品片段的单个观察，并且通常一起分析。这算是一次阅读还是两次阅读？</p><p>事实证明，人们两者都做，这导致了很多误解！</p><p>一些例子：</p><ul><li><p> Illumina 将它们算作两个。他们说 NovaSeq X 上的“25B”流动池 <a href="https://www.illumina.com/systems/sequencing-platforms/novaseq-x-plus/specifications.html">将产生</a>52B 配对末端读数，或 2x150 的约 8Tb（“太碱基”，或万亿碱基）。由于 52B * 150b = 7.8Tb（他们称之为 ~8Tb），这告诉我们他们正在计算正向和反向读取。</p></li><li><p> Element 将它们视为一个。<a href="https://www.elementbiosciences.com/products/aviti/specs">他们说</a>2x150 高输出流通池可产生 300 Gb 和 1B 读数。由于 1B * 150b * 2 = 300 Gb，这告诉我们他们将正向和反向读取一起算作一个。</p></li><li><p> Singular<a href="https://singulargenomics.com/g4/">不清楚</a>，但我很确定他们将每个片段的观察结果计算为一次读取。</p></li><li><p>欧洲核苷酸档案馆将它们视为其中之一。例如，如果您访问<a href="https://www.ebi.ac.uk/ena/browser/view/ERR1470825">ERR1470825</a> ，这是 2x250 的 Illumina MiSeq 配对末端测序，您会看到它显示 2.2M 读取，如果您下载 fastq.gz 文件，您会发现正向和反向各有 2.2M 读取文件。</p></li><li><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8579973/">罗斯曼等。 al 2021</a>将它们算作一个。他们在第一次使用时说“配对读取”，然后在稍后“读取”，你可以看出他们将它们算作一个，因为 (a) 他们经常给出奇数，例如“只有 337 个 SARS-CoV-2 读取” ”和（b）如果你<a href="https://www.jefftk.com/p/case-rates-to-sequencing-reads">重新分析数据，</a>它们的数字只有在对数进行计数时才有意义。</p></li><li><p>我最近与一个学术团体讨论了潜在的合作伙伴关系，在我最近重新分析的一篇论文中，他们将其视为一个，而在通过电子邮件交谈时，他们将其视为两个。</p></li><li><p>我最近采访的一家商业测序公司将它们算作两个。</p></li><li><p>问ChatGPT和Claude，两人都算作两个。例如：“在短读长双端测序中，正向-反向对通常被视为两个读长”。</p></li></ul><p>这真是一团糟！而且，更糟糕的是，据我所知，除了“读取”之外，没有标准术语，要么“正向和反向读取都是示例”，要么“当一起考虑时，正向和反向读取是什么”。</p><p>我一直使用“读”来表示“读对”，但考虑到歧义，我认为我应该改用另一个术语。 NCBI SRA 使用“<a href="https://www.ncbi.nlm.nih.gov/sra/ERX1541950">斑点</a>”，但似乎没有其他人使用这个术语。你可以直接说“readpair”，这很好，但有点长。可能的“配对”或“伴侣”会好吗？想法？</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid0emTAqvGbjmRHoY9XwhQx65bTMKWLG8b9MBZtsda18UdwDbKZ9EWT3H4g1P3EL4eQl">facebook</a> , <a href="https://mastodon.mit.edu/@jefftk/111293185162894676">mastodon</a></i></p><br/><br/><a href="https://www.lesswrong.com/posts/JQmgoLAkFKkhxLMhz/what-is-a-sequencing-read#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/JQmgoLAkFKkhxLMhz/what-is-a-sequencing-read<guid ispermalink="false"> JQmgoLAkFKkhxLMhz</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Wed, 25 Oct 2023 02:10:12 GMT</pubDate></item><item><title><![CDATA[Verifiable private execution of machine learning models with Risc0?]]></title><description><![CDATA[Published on October 25, 2023 12:44 AM GMT<br/><br/><p> Risc0 是一个虚拟机，可以运行任何 riscv（ <i>C、C++、Rust、Go 和 Nim 都可以编译为 riscv</i> ）程序，随着时间的推移记录计算状态的痕迹，然后，无论执行运行多长时间因为，它可以将该执行跟踪折叠成 1KB 的里德-所罗门代码，该代码可以作为计算运行正确、输出来自输入的证明进行传输，而无需泄露代码或输入的未加密副本。<br>询问器通过对收据代码的一系列特征进行采样来验证它，如果计算的<i>任何</i>方面不正确，则每次检查都有 3/4 的机会暴露这一点。因此，经过一百次左右的检查，我们可以有效地确定计算的正确性，而无需自己运行计算。 <span class="footnote-reference" role="doc-noteref" id="fnref4kqliegpy1a"><sup><a href="#fn4kqliegpy1a">[1]</a></sup></span></p><p>当<a href="https://www.risczero.com/news/rust-but-verify">我看到它暗示这可以应用于 ML 模型时</a>，我感到难以置信，因为我预计在像 Risc0 这样的环境中运行神经模型会使其性能降低数万倍。 Risc0 确实将传统 CPU 计算的性能降低了大约那么多<span class="footnote-reference" role="doc-noteref" id="fnrefqx7a21dnm3"><sup><a href="#fnqx7a21dnm3">[2]</a></sup></span> （尽管这仍然足够快，足以实用）。<br>是的，这篇文章没有讨论性能，而是讨论了许多非深度学习（？）模型类型，例如增强树和随机森林。所以我猜这可能不适用于验证训练运行。它是否适用于某些精炼推理模型？</p><hr><p>我发现 Risc0 非常有趣还有另外两个原因。一是我正在从事社交计算工作，但更深层的兴趣与技术末世论中正在进行的对话有关，即高级代理是否倾向于或远离相互透明，也就是说，走向协调、和平、贸易，或走向战争和压迫（<i>例如，</i> <a href="https://www.researchgate.net/publication/283986931_The_Dark_Forest_Rule_One_Solution_to_the_Fermi_Paradox"><i>黑暗森林</i></a>）。 Risc0 将任何程序的执行跟踪（无论多长）压缩为可在恒定时间内检查的证明。这对我来说是一个强有力的迹象，表明信息系统之间透明的可行性，即使在最不利的可能条件下，我们可以假设根本没有可信的硬件基础设施。<br><i>有了</i>可信的硬件，经过验证的计算就可以以正常速度运行，并且相互透明变得微不足道。硬件安全的唯一成本可能是增加防篡改，但在我看来，一个发达的协调基础设施，至少在人类规模上，将能够监控周围的物理实体和传感器，并在它们出现时发出尖叫声。进行篡改，几乎不需要任何成本。<br>我认为像 Risc0 这样的 ZK 系统适用于可信执行环境（TEE）被破解的风险非常非常小的情况，也是不可接受的。在去中心化金融中，这种情况很常见，因为网络共享状态的完整性都是纠缠在一起的，如果我们假设每个 TEE 的完整性是确定的，我们就会建造纸牌屋，即使成功破解存储一个人钱包的 TEE 也可能通过允许他们在难以察觉的情况下铸造、膨胀、污损货币来破坏整个网络。相比之下，Risc0 以数学确定性保证了计算的完整性，这让我对并行化全局可验证计算的项目更加充满希望。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn4kqliegpy1a"> <span class="footnote-back-link"><sup><strong><a href="#fnref4kqliegpy1a">^</a></strong></sup></span><div class="footnote-content"><p>至少，这是我经过两天学习后的感觉。通过观看一些<a href="https://www.youtube.com/watch?v=j35yz22OVGE&amp;list=PLcPzhUaCxlCjdhONxEYZ1dgKjZh3ZvPtl">Risc0 Study Club 视频</a>辨别出来。有人提到收据可以压缩为 1 个码字，但出于效率原因仅压缩为 256 个码字。我猜码字是 1 个 riscv 机器字那么大，4 个字节，所以总共 1024 个字节。虽然没有提到在秘密程序上运行，但我推断它一定是可能的，因为我们当然可以将程序编码为数据输入并让解释器的 riscv 实现运行它们，而且，在 riscv 和 wasm 之间的比较我似乎记得看到它提到riscv可以修改其执行区域中的指令。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnqx7a21dnm3"> <span class="footnote-back-link"><sup><strong><a href="#fnrefqx7a21dnm3">^</a></strong></sup></span><div class="footnote-content"><p>假设典型的笔记本电脑的频率约为 3GHz，与<a href="https://github.com/risc0/risc0/discussions/96#discussioncomment-2739454">开发人员声称的 30KHz</a>相比，这将是 100,000 倍的差异。 risc0 的性能提升 10 倍是可以想象的。 100 倍的增长更难以想象。也许需要硬件支持，但很难看出谁会开发它，因为 TEE 是实现基于硬件的计算完整性的一种更具吸引力/更便宜的方法。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/SJdYkx6C2KXQyeKro/verifiable-private-execution-of-machine-learning-models-with#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/SJdYkx6C2KXQyeKro/verABLE-private-execution-of-machine-learning-models-with<guid ispermalink="false"> SJdYkx6C2KXQyeKro</guid><dc:creator><![CDATA[mako yass]]></dc:creator><pubDate> Wed, 25 Oct 2023 00:44:48 GMT</pubDate> </item><item><title><![CDATA[How to Resolve Forecasts With No Central Authority?]]></title><description><![CDATA[Published on October 25, 2023 12:28 AM GMT<br/><br/><p>我一直在与一些人讨论如何使用预测市场/预测以及社区笔记。</p><p>最初的建议是很好地链接到预测网站。<i>这是一个很好的建议，但我不会在这里讨论它。</i></p><p>其他建议围绕 X/Community Notes 上的预测产品，面临以下问题：</p><ul><li>社区注释没有中央解决机构</li><li>有争议的预测通常需要权威机构来否决<span class="footnote-reference" role="doc-noteref" id="fnref2xrwrf10e1z"><sup><a href="#fn2xrwrf10e1z">[1]</a></sup></span></li></ul><p>所以：</p><h2>对于在没有中央机构的情况下解决预测问题，您的最佳建议是什么？</h2><p>为了清楚起见，已经编写了预测。人们对它进行了预测，也许这是一个他们买卖股票的预测市场，也许不是。现在它需要决定奖励积分或将值分配给“是”或“否”令牌。也许人们会像许多人一样解决自己的市场问题。但有人对这一结果提出异议。现在会发生什么？</p><p>解决方案可以是技术性很强的，也可以是靠不住的。我认为好的一个在这里是非常有价值的。 </p><p></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn2xrwrf10e1z"> <span class="footnote-back-link"><sup><strong><a href="#fnref2xrwrf10e1z">^</a></strong></sup></span><div class="footnote-content"><p> Polymarket 使用某种“代币持有者决定”系统，我认为这导致了几个可怕的决议，尤其是《时代》杂志年度人物之一。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/7kyeFWrS7ni7gxj87/how-to-resolve-forecasts-with-no-central-authority#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/7kyeFWrS7ni7gxj87/how-to-resolve-forecasts-with-no-central-authority<guid ispermalink="false"> 7kyeFWrS7ni7gxj87</guid><dc:creator><![CDATA[Nathan Young]]></dc:creator><pubDate> Wed, 25 Oct 2023 00:28:32 GMT</pubDate></item></channel></rss>