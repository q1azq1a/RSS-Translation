<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 10 日星期五 22:11:02 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Should Advanced Placement High School classes discuss Israel-Palestine? If so, how? If not, why?]]></title><description><![CDATA[Published on November 10, 2023 9:43 PM GMT<br/><br/><p>在高中教师休息室，一位 AP 历史老师问另一位：你提到以色列还是其中任何一个？他回答：没有。她认可了他的回答，并评论说没有一个学生提出过这个问题，然后他们继续与更大的群体讨论 Netflix 节目。</p><p>真实的故事，我无意中听到了这次对话。我想我们大多数人都同意学生的教学内容和方式没有什么长期影响，但我想我应该问一下，因为学校课程是媒体争论的话题。</p><br/><br/> <a href="https://www.lesswrong.com/posts/HnqDFYzqFdKzYdfvn/should-advanced-placement-high-school-classes-discuss-israel#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/HnqDFYzqFdKzYdfvn/should-advanced-placement-high-school-classes-discuss-israel<guid ispermalink="false"> HnqDFYzqFdKzYdfvn</guid><dc:creator><![CDATA[Gesild Muka]]></dc:creator><pubDate> Fri, 10 Nov 2023 21:43:58 GMT</pubDate> </item><item><title><![CDATA[Follow-up survey: inositol]]></title><description><![CDATA[Published on November 10, 2023 7:30 PM GMT<br/><br/><p>两个月前，我写了一篇关于<a href="https://acesounderglass.com/2023/09/08/luck-based-medicine-inositol/">肌醇</a>作为一种治疗方法的文章，它偶尔对焦虑和抑郁有效，特别是当使用者也有奇怪的消化问题时（不是医疗建议，我不是医生）。如果这激励您尝试肌醇，我希望您能填写这份有关您的经历的<a href="https://acesounderglass.com/2023/09/08/luck-based-medicine-inositol/">5-7 个问题调查</a>。这些后续数据可以帮助其他考虑肌醇的人，并且对我弄清楚基于运气的药物是什么样子有很大帮助。</p><p>对于已经填写此内容的四个人：认知美德的金星。</p><p>该调查不允许提供太多细节，我知道这对某些人（就是我。我是人）来说是痛苦的。如果您想分享更多内容，请随时在此处的评论中写下您想要的内容，或分享详细介绍您的体验的链接。</p><p>在基于运气的医学的其他方面：在<a href="https://acesounderglass.com/2023/07/27/apollo-neuro-follow-up-2/">我的调查</a>中，这是一个家伙，但我遇到了更多真正喜欢阿波罗神经的人。他们都是已经知道“躯体意识”或“具体化”含义的人，所以这是对我的理论的一些支持，这是一个先决条件。如果你需要神经网络的背景才能变得有益，注意到它是有益的，或者坚持足够长的时间以使其有时间变得有益，这仍然是一个悬而未决的问题。</p><p>自从我上次写文章以来，Apollo 应用程序变得更加糟糕。每次我打开它时，它都会让我启用通知，这是它绝对不需要的权限。</p><br/><br/><a href="https://www.lesswrong.com/posts/zQyrHb8K3zwdvMHkw/follow-up-survey-inositol#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/zQyrHb8K3zwdvMHkw/follow-up-survey-inositol<guid ispermalink="false"> zQyrHb8K3zwdvMHkw</guid><dc:creator><![CDATA[Elizabeth]]></dc:creator><pubDate> Fri, 10 Nov 2023 19:30:03 GMT</pubDate> </item><item><title><![CDATA[We have promising alignment plans with low taxes]]></title><description><![CDATA[Published on November 10, 2023 6:51 PM GMT<br/><br/><p><i>认知状态：我确信这些计划相对于其他计划有优势。我不确定它们是否足以实际工作，但我认为它们可能是。</i></p><p>有了足够好的协调计划，我们可能不需要协调就能生存。如果对齐税足够低，我们可能会期望大多数开发通用人工智能的人会自愿采用它们。有两个调整计划对我来说似乎非常有希望，基于几个因素，包括易于实施，以及适用于相当可能的 AGI 默认路径。两者都没有受到太多关注。我找不到任何评论说它们行不通，所以我希望让它们得到更多关注，以便仔细考虑它们并接受或拒绝。</p><p>即使这些计划<span class="footnote-reference" role="doc-noteref" id="fnrefgyi9at2u1tq"><sup><a href="#fngyi9at2u1tq">[1]</a></sup></span>像我现在认为的那样有希望，我仍然会给 p(doom) 在模糊的 50% 范围内。有很多地方可能会出错。 <span class="footnote-reference" role="doc-noteref" id="fnrefasssodr6ivl"><sup><a href="#fnasssodr6ivl">[2]</a></sup></span></p><p>制定有希望但未经测试的调整计划有一个特殊的问题：它们是能力全速前进的借口。由于这个原因，我对发表这篇文章感到有点犹豫，并且出于类似的原因，你可能会对采用如此乐观的态度感到有些犹豫。我在最后解决这个问题。</p><h2><strong>计划</strong></h2><p>在我发现的众多调整计划中，有两个最为突出。这些看起来比其他的更具体、更实用。对于它们所适用的 AGI 设计类型来说，它们也是相对简单和明显的计划。自从最近提出以来，它们很少受到关注。我认为他们值得更多关注。</p><p>第一个是 Steve Byrnes 的<a href="https://www.alignmentforum.org/posts/Hi7zurzkCog336EC2/plan-for-mediocre-alignment-of-brain-like-model-based-rl-agi"><u>类脑 [基于模型的 RL] AGI 的平庸调整计划</u></a>。在这种方法中，我们在<a href="https://www.lesswrong.com/posts/hE56gYi5d68uux9oM/intro-to-brain-like-agi-safety-3-two-subsystems-learning-and"><u>学习子系统</u></a>中引发一组表示，并将权重从那里设置到<a href="https://www.lesswrong.com/posts/hE56gYi5d68uux9oM/intro-to-brain-like-agi-safety-3-two-subsystems-learning-and"><u>转向</u></a>或批评子系统。例如，我们要求智能体“考虑人类的繁荣”，然后冻结系统并在学习系统/世界模型中的活动单元和转向系统/批评单元之间设置较高的权重。该系统现在对人类繁荣的分布式概念赋予了很高的价值。 （至少按照它的理解）。因此，代理的知识用于定义我们喜欢的目标。</p><p>该计划适用于所有具有关键子系统的强化学习系统，其中包括最强大的强化学习系统。 <span class="footnote-reference" role="doc-noteref" id="fnrefgq3s1wsqk55"><sup><a href="#fngq3s1wsqk55">[3]</a></sup></span> RL 代理（包括松散的类脑系统的深层网络）似乎是实现 AGI 的一种非常合理的途径。如果<a href="https://www.lesswrong.com/posts/ogHr8SvGqg9pW5wsT/capabilities-and-alignment-of-llm-cognitive-architectures"><u>语言模型认知架构</u></a>（LMCA）不首先实现 AGI，我个人认为他们实现 AGI 的可能性很高。</p><p>第二个有前途的计划可能称为自然语言对齐，它适用于<a href="https://www.lesswrong.com/posts/ogHr8SvGqg9pW5wsT/capabilities-and-alignment-of-llm-cognitive-architectures">语言模型认知架构</a>和其他语言模型代理。我所知道的最完整的文章是<a href="https://www.alignmentforum.org/posts/Q7XWGqL4HjjRmhEyG/internal-independent-review-for-language-model-agent"><u>我的</u></a>。该计划同样使用代理的知识来定义我们喜欢的目标。由于这种智能体的知识是用语言定义的，因此采用的形式是用自然语言陈述目标，并构建智能体，以便其自我提示系统采取行动来实现这些目标。内部和外部审查流程可以提高系统有效追求实际目标和协调目标的能力。</p><p> John Wentworth 的计划<a href="https://www.lesswrong.com/posts/w4aeAFzSAguvqA5qu/how-to-go-from-interpretability-to-alignment-just-retarget"><u>《如何从可解释性到对齐：只需重新定位搜索》</u></a>类似。它适用于第三种类型的 AGI，即通过训练出现的台面优化器。它建议使用可解释性方法来识别台面优化器中目标的表示；识别我们希望代理做什么的表示；并将前者指向后者。这个计划在技术上似乎更具挑战性，而且我个人认为预测基础模型中的新兴台面优化器不太可能是通向 AGI 的途径。但这个计划与前两个计划具有许多相同的特性，如果台面优化器成为实现 AGI 的可行途径，就应该采用该计划。</p><p>前两种方法在上面的链接帖子中有更详细的解释，史蒂夫的方法也在他的# <a href="https://www.lesswrong.com/posts/QpHewJvZJFaQYuLwH/intro-to-brain-like-agi-safety-14-controlled-agi"><u>[类脑 AGI 安全简介]14. 受控 AGI</u></a>中进行了更深入的描述。但仅此而已。这两者都相对较新，因此还没有收到很多批评或替代解释。</p><h2><strong>为什么这些计划很有前景</strong></h2><p>我所说的“有希望的协调计划”是指我还没有找到令人信服的论据来解释为什么它们行不通。有必要进一步揭穿和调试这些计划。它们适用于目前似乎在 AGI 竞赛中处于领先地位的两种人工智能：强化学习代理和语言模型代理 (LMA)。这些计划涉及这些类型 AGI 的齿轮级模型。它们可以通过可扩展的监督、装箱、可解释性和其他对齐策略等方法进行补充。</p><p>这两个计划在两个方面具有较低的调整税。它们适用于最有可能导致通用人工智能的人工智能方法，因此不需要新的艰苦项目。与针对纯粹功能进行优化的系统相比，它们在设计和计算资源方面的实施成本也较低。</p><p>这两个计划都具有在定义目标的<a href="https://www.lesswrong.com/posts/qzu9o3sTytbC4sZkQ/steering-subsystems-capabilities-agency-and-alignment"><u>引导子系统</u></a>上运行并<a href="https://www.lesswrong.com/posts/qsDPHZwjmduSMCJLv/the-partial-fallacy-of-dumb-superintelligence"><u>使用 AGI 的理解</u></a>来定义这些目标的优点。只有当你能够暂停超人类水平的训练时，这才有可能实现，在这个水平上，系统对人类、语言和世界有非凡的理解，但还没有危险地逃脱的能力。由于深度网络的训练相对可预测（至少在自主学习或自我改进之前），因此这一要求似乎是可以实现的。相对于早期的快速起飞假设，这可能是<a href="https://www.lesswrong.com/posts/qsDPHZwjmduSMCJLv/the-partial-fallacy-of-dumb-superintelligence">对齐思想的一个关键更新</a>。</p><h2><strong>局限性和未来方向</strong></h2><p>他们很有希望，但这些计划并非完美无缺。它们主要创建初始松散对齐。它们在完全自主、自我修改和持续学习的系统中是否持久（<a href="https://www.lesswrong.com/posts/g3pbJPQpNJyFfbHKd/the-alignment-stability-problem">对齐稳定性问题</a>）仍有待解决。我所知道的基于网络的代理的所有其他对齐方法似乎都是这种情况。亚历克斯·特纳（Alex Turner<a href="https://www.lesswrong.com/posts/k4AQqboXz8iE5TNXK/a-shot-at-the-diamond-alignment-problem"><u>）对钻石对齐问题的尝试</u></a>让我相信，<a href="https://arbital.com/p/reflective_stability/"><u>反射稳定性</u></a>将稳定一个明确定义的主导目标，但该证明不适用于分布式或多个目标。 <a href="https://www.lesswrong.com/posts/qbcuk8WwFnTZcXTd6/thomas-kwa-s-miri-research-experience"><u>据传</u></a>MIRI 正在研究这个问题；我希望他们能与我们其他人分享，但如果没有的话，我认为我们需要更多的想法来解决这个问题。</p><p>调整语言模型代理还有两个重要的限制。一是<a href="https://www.lesswrong.com/tag/waluigi-effect">瓦路易吉效应</a>。语言模型可以在有效执行下一个单词预测的过程中模拟敌对字符。这种敌意的拟像可能会提供恶意的错误答案。这是一个比幻觉更有害的问题，因为它不一定在功能更强大的语言模型中得到改善。有可能的补救措施， <span class="footnote-reference" role="doc-noteref" id="fnrefyttiy0ozoti"><sup><a href="#fnyttiy0ozoti">[4]</a></sup></span>但这个问题需要更仔细的考虑。</p><p>还有人担心语言模型不能准确地表示其话语中的内部状态。他们可能会使用隐写术，或者以其他方式错误地报告他们的思路。这些问题在<a href="https://www.alignmentforum.org/posts/r3xwHzMmMf25peeHE/the-translucent-thoughts-hypotheses-and-their-implications">半透明思想假设及其含义</a>、讨论主题和其他帖子中进行了更详细的讨论。</p><p>这些批评表明可能会失败，但并不是不可能失败。这不能保证有效。但完美是美好的敌人。 <span class="footnote-reference" role="doc-noteref" id="fnrefvya5rfr2r9"><sup><a href="#fnvya5rfr2r9">[5]</a></sup></span>对我来说，这样的计划似乎是我们最好的实际希望。至少，它们似乎值得进一步分析。</p><p>实际上制定良好的调整计划有一个特殊的问题：它们可能为人们要求全速前进提供借口。如果这些计划最终效果不佳，那将是灾难性的。但我认为保持清晰和诚实很重要，尤其是在您想要合作的社区内。而且潜力似乎值得冒险。有效且低税收的计划将减少困难或不可能的协调的需要。平衡公开致力于有希望的计划与过度乐观是一个复杂的战略问题，值得明确关注。</p><p>我还没有找到任何论据来解释为什么这些计划不太可能奏效。我相信许多论点都支持<a href="https://alignmentforum.org/posts/3JRBqRtHBDyPE3sGa/a-case-for-the-least-forgiving-take-on-alignment">对联盟采取最不宽容的态度</a>，但没有一个论点让我认为这些计划先验地可能会失败。可能存在的故障点似乎并不能成为驳回它们的充分理由。很可能会使用这些总体计划之一。每一个计划都是针对目前处于领先地位的通用人工智能方法之一的明显计划。在尝试这些计划之前，我们可能需要仔细分析它们。 <br></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fngyi9at2u1tq"> <span class="footnote-back-link"><sup><strong><a href="#fnrefgyi9at2u1tq">^</a></strong></sup></span><div class="footnote-content"><p>我认为这些值得用“计划”这个词来形容，而我们讨论的大多数其他事情都可以称为“方法”。改变我的想法很容易。这些计划就像“我们将建造一座钢梁桥”是一个初步计划，但还不是一个充分的计划。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnasssodr6ivl"> <span class="footnote-back-link"><sup><strong><a href="#fnrefasssodr6ivl">^</a></strong></sup></span><div class="footnote-content"><p>除了这些计划的具体问题之外，有些事情可能会出错：执行草率；运作不足；外部对齐错误；对准不稳定；和多极冲突灾难。</p><p>有希望的调整计划只是生存的开始。</p></div></li><li class="footnote-item" role="doc-endnote" id="fngq3s1wsqk55"> <span class="footnote-back-link"><sup><strong><a href="#fnrefgq3s1wsqk55">^</a></strong></sup></span><div class="footnote-content"><p>在强化学习中，批评者系统评估参与者采取的行动，并提供实际的训练信号。从这个意义上说，它是一个定义系统目标和行为的控制子系统。</p><p>参与者或策略经常被误认为是完整的 RL 代理。简单的强化学习系统不使用批评者，但我知道的所有强大的强化学习系统都使用某种形式的批评者。参与者子系统将状态作为输入，并根据其当前学习的策略输出最佳操作。</p><p>批评子系统被训练来产生<i>价值</i>估计，即状态或状态中的动作产生的未来总奖励。批评者向参与者提供强化信号以进行策略梯度（通常是反向传播）调整。因此，批评系统“解释”来自环境的强化信号，并更直接地决定系统的行为（及其隐喻的“价值观”，这个词<a href="[Human preferences as RL critic values&nbsp;- implications for alignment](https://www.lesswrong.com/posts/HEonwwQLhMB9fqABh/human-preferences-as-rl-critic-values-implications-for)">在强化学习和人类领域中可以说是同一件事</a>。</p><p>批评系统还可用于估计状态的值以执行树搜索。例如，AlphaZero 对玩法和预期的反击执行有限的树搜索，并选择导致最佳棋盘游戏状态的移动，如评论家子系统所估计的那样。人类更进一步，创造出诸如“创业”之类的远程目标，这可能是基于我们的批评子系统对那些想象的未来状态的评估。我在我的<a href="https://www.lesswrong.com/posts/qzu9o3sTytbC4sZkQ/steering-subsystems-capabilities-agency-and-alignment">指导子系统</a>帖子中探索了这些不同类型的基于批评家的目标方向。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnyttiy0ozoti"> <span class="footnote-back-link"><sup><strong><a href="#fnrefyttiy0ozoti">^</a></strong></sup></span><div class="footnote-content"><p>在<a href="https://www.alignmentforum.org/posts/Q7XWGqL4HjjRmhEyG/internal-independent-review-for-language-model-agent">语言模型代理对齐的内部独立审查</a>中，我提出了从新实例中采样的审查过程，以避免<a href="https://www.lesswrong.com/posts/PfoJLZg2e4xXt2Q6a/a-smart-enough-llm-might-be-deadly-simply-if-you-run-it-for">持续的瓦路易吉效应</a>并抵消其影响。肖恩·莱格 (Shane Legg) 在<a href="https://www.lesswrong.com/posts/2QLxNdxQpnesokk9H/shane-legg-interview-on-alignment">最近接受德瓦克什·帕特尔 (Dwarkesh Patel) 采访</a>时似乎提出了同样的总体想法。直觉是，许多独立的法学硕士呼吁审查计划和想法以进行调整，罕见的瓦路易吉效应应该被覆盖。 Tamera Lanham 提出了<a href="https://www.lesswrong.com/posts/FRRb6Gqem8k69ocbi/externalized-reasoning-oversight-a-research-direction-for">外部化推理监督</a>，即人类在人工智能的帮助下审查那些自然语言的思路。这将有助于检测恶意插入思想树的行为。恶意拟像的可能性仍然是该计划的一个主要担忧，但如果没有经验估计和更精确的评估，这似乎不是驳回该方法的充分理由。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnvya5rfr2r9"> <span class="footnote-back-link"><sup><strong><a href="#fnrefvya5rfr2r9">^</a></strong></sup></span><div class="footnote-content"><p>在大多数项目中<a href="https://en.wikipedia.org/wiki/Perfect_is_the_enemy_of_good">，完美是优秀的敌人</a>。 AGI 对齐需要在第一次尝试时就起作用，并且它还有其他独特的困难。但考虑到协调的难度，一个需要四十年才能保证成功的计划可能行不通。这是一个更深层次的话题，因为寻找正式有保证的解决方案是许多协调工作的主要原则，无论是口头的还是不言而喻的。我想更详细地讨论这个问题，并就问题的这方面进行思考。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/xqqhwbH2mq6i4iLmK/we-have-promising-alignment-plans-with-low-taxes#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/xqqhwbH2mq6i4iLmK/we-have-promising-alignment-plans-with-low-taxes<guid ispermalink="false"> xqhwbH2mq6i4iLmK</guid><dc:creator><![CDATA[Seth Herd]]></dc:creator><pubDate> Fri, 10 Nov 2023 18:51:38 GMT</pubDate> </item><item><title><![CDATA[About Me]]></title><description><![CDATA[Published on November 10, 2023 6:32 PM GMT<br/><br/><p>然而，我想撰写（并研究）人工智能、机器学习、合成生物学、数学和哲学等领域的崇高主题；我敏锐地意识到，我的资历……平淡无奇：2008 年，我勉强获得了电气工程学士学位，从那时起，我作为一名软件工程师的职业生涯就一直坎坷不平。尽管我尝试进入上述领域，但我的软件工程经验都没有直接涉及其中任何一个。<br><br>我相信我有宝贵的想法可以添加到这些领域，但我也担心成为“那些人”之一，他们将自己对某个领域的无知误认为是超级大国，好像它为他们提供了专家们认为的清晰和“新鲜的视角”。在该领域缺乏。我不想闯入哲学家们几千年以来一直在进行的对话，并自信地发表我的观点，就好像这是无可辩驳的事实一样，让自己感到尴尬。我了解邓宁-克鲁格效应，而且我知道软件工程师特别是一直认为自己是房间里最聪明的人，无论主题或房间如何。<br><br>我写这个简介是为了我可以在以后的帖子中链接到它作为一种免责声明，因为每次我尝试开始写我对对齐问题的想法（例如）时，我的背后都有一个声音头一直说，“你知道你基本上是在试图用方程形式化生命的意义，对吧？你勉强通过了哲学101，并且在每堂数学证明课上都睡着了！”我觉得有必要在所有内容的开头这样说：“我基本上是一个傻瓜，对我所写的任何主题都没有专业知识。请对我所说的一切持怀疑态度，请保持友善！我很抱歉当我对合理的批评反应不佳时，我表现得像一个防御混蛋，因此受到赞扬。我担心我太不成熟，无法将我的自我与我的帖子分开。<br><br>希望这能让我未来的写作更加简洁，因为可以说，我和读者将在同一页上。我不必在我的写作中乱扔不确定的限定词，例如“在我看来”、“我认为”、“我不确定，但据我了解”等，因为我们一致认为所有这是暗示的。我写的所有内容都是我的观点，因为它是我写的。由于缺乏这样的限定词，请原谅我的写作中的任何权威。<br><br>感谢您的理解，<br>阿贝·狄龙<br><br></p><br/><br/><a href="https://www.lesswrong.com/posts/HD3wzPAesbzhkcB9n/about-me-1#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/HD3wzPAesbzhkcB9n/about-me-1<guid ispermalink="false"> HD3wzPAesbzhkcB9n</guid><dc:creator><![CDATA[Abe Dillon]]></dc:creator><pubDate> Fri, 10 Nov 2023 18:32:22 GMT</pubDate> </item><item><title><![CDATA[Metaculus Introduces AI-Powered Community Insights to Reveal Factors Driving User Forecasts]]></title><description><![CDATA[Published on November 10, 2023 5:57 PM GMT<br/><br/><br/><br/> <a href="https://www.lesswrong.com/posts/FhNHaZneX5KRhccct/metaculus-introduces-ai-powered-community-insights-to-reveal#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/FhNHaZneX5KRhccct/metaculus-introduces-ai-powered-community-insights-to-reveal<guid ispermalink="false"> FhNHaZneX5KRhccct</guid><dc:creator><![CDATA[ChristianWilliams]]></dc:creator><pubDate> Fri, 10 Nov 2023 17:57:11 GMT</pubDate> </item><item><title><![CDATA[Joy in the Here and  Real]]></title><description><![CDATA[Published on November 10, 2023 5:22 PM GMT<br/><br/><p><strong>摘要</strong>：为了简单、快速的乐趣，你会做什么？你介意与他人分享吗？</p><p><strong>标签</strong>： 可重复</p><p><strong>目的</strong>：“玩得开心”和“快乐”是人们的共同目标。如果你不能把几块钱和几个小时变成美好的时光，那么你的能力就有明显的差距<i>，我相信这是一个问题。</i></p><p><strong>材料</strong>：什么都没有，但作为参与者您可能会想带一些东西。</p><p><strong>公告文字</strong>：如果你想更快乐，你会做什么？</p><p>这就是我们将在本次聚会中探讨的问题。这并不是一个深刻或抽象的问题。你做了什么让你快乐，并且你认为也可能让别人快乐的事情？以您愿意与他人分享的方式带来一些让您微笑或大笑的东西。一个你喜欢塑造的压力玩具，适合折叠或绘画的纸，一首让你想跳舞的歌曲，所有这些都是好主意，但没有一个是详尽的。这次聚会有点像表演和讲述，希望您在离开时度过愉快的时光，并了解如何在未来获得更多乐趣。</p><p>推荐阅读： <a href="https://www.lesswrong.com/posts/xnPFYBuaGhpq869mY/ureshiku-naritai">《奈良泰嬉事》</a> ， <a href="https://www.lesswrong.com/posts/x4dG4GhpZH2hgz59x/joy-in-the-merely-real">《纯粹真实中的快乐</a>》。</p><p><strong>描述</strong>：这是一个相当无组织的事件。带上你自己的有趣的东西。最有用的就是带去富有感染力的热情；如果您没有，请尝试寻找有的共同组织者。小孩子可能有效。</p><p>首先询问附近的人今天让他们高兴的事情。跟进、尝试并了解体验的细节。询问他们为聚会带来了什么乐趣，如果他们提供了一些东西，那就尝试一下。如果这对您来说也很有趣，请说出来！尝试在房间里与其他人一起走动。</p><p><strong>变化：</strong>如果有室外场地，我相信在阳光下的户外活动通常会有所帮助。有空间自由大声地笑也很好。</p><p>如果你愿意，你可以尝试让整个聚会一起做一件有趣的事情。如果每个人都对乐趣有相似的想法，那么这会很有效，但对于不喜欢那件事的人来说就不起作用。去海滩、放风筝和万智牌选秀对我来说都是美好的时光，而且我很确定如果我邀请的话，我可以找到六个也会喜欢这些事情的朋友。这是否适用于公开聚会，这个问题只有您作为当地组织者才能回答。请记住，如果你明确自己在做什么，人们可以很好地进行自我选择；大多数讨厌万智牌的人不会去参加你的选秀之夜。</p><p><strong>注释</strong>：我并不是说享受美好时光就是理性主义的实践。我的意思是，你可以优化你的生活的众多事情之一就是享受美好时光。如果通过理性聚会来优化你的薪水的想法听起来很合理，那么我认为通过理性聚会来优化你的快乐也是相当合理的。</p><p>我享受简单美好时光的秘诀就是问自己五岁时我想做什么。这是一个非常好的直觉泵！五岁的我想游泳、读书给他听、吃冰淇淋，你知道吗？有有声读物，蛋卷冰淇淋很便宜，周六下午去海滩也不错。</p><p>当你只做短期内有趣的事情，忽视责任并以不可持续的速度燃烧资源时，确实存在一种生活失败模式。礼貌地说，这并不是我周围的理性主义者所陷入的失败模式。我经常看到理性主义者在我问他们上次玩得开心是什么时候时不得不停下来思考一会儿。</p><p><strong>制作人员</strong>：这源自 Alicorn 的<a href="https://www.lesswrong.com/posts/xnPFYBuaGhpq869mY/ureshiku-naritai">Ureshiku Naratai</a>以及 Fun Theory 序列中更直接的实用方面，还有 Yudkowsky 的<a href="https://www.lesswrong.com/posts/x4dG4GhpZH2hgz59x/joy-in-the-merely-real">Joy in the Merely Real</a> 。</p><br/><br/><a href="https://www.lesswrong.com/posts/y4DtaSQdCpB5Lkxxc/joy-in-the-here-and-real#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/y4DtaSQdCpB5Lkxxc/joy-in-the-here-and-real<guid ispermalink="false"> y4DtaSQdCpB5Lkxxc</guid><dc:creator><![CDATA[Screwtape]]></dc:creator><pubDate> Fri, 10 Nov 2023 17:22:41 GMT</pubDate> </item><item><title><![CDATA[Artefacts generated by mode collapse in GPT-4 Turbo serve as adversarial attacks.]]></title><description><![CDATA[Published on November 10, 2023 3:23 PM GMT<br/><br/><p>我偶然发现了 2023 年 11 月 6 日通过 API 访问发布的 GPT-4 Turbo 128k 的一些奇怪行为。由于该模型处于预览阶段，因此预计会有一些缺陷。尽管如此，我发现这种行为很有趣，可以在这里分享，希望有人可以进行比我更详细的调查。</p><h2> GPT-4 Turbo 非常容易受到模式崩溃的影响，从而产生有趣的人工制品</h2><p>这些范围包括：</p><ol><li>重复一串单词，例如“aaaa”</li><li>生成同义词，例如“尖叫、尖叫、大喊、哭泣、啜泣、哀叹、哀悼、悲伤、遗憾、忏悔、忏悔、道歉”</li><li>生成与法学硕士通常生成的文本非常不同的半连贯短语，例如“确实如此，等等，阿门哈利路亚，赞美归于你，主啊，我们的上帝，永远，阿门，再一次，只是为了争论，没有别的，无论什么时期”故事结束，喜剧结束，晚安，甜蜜的王子，五月的航班，天使为你歌唱，你休息吧，睡个好觉，别让臭虫咬，如果它们确实用鞋把它们敲到蓝色！”</li></ol><h2> GPT-4 Turbo 模式崩溃生成的伪影在后续对话中充当对抗性攻击</h2><p>即使最初触发模式崩溃的提示已从上下文窗口中删除，只要其生成的工件位于其上下文窗口中即可：</p><ol><li>它很可能在随后的对话中（几乎逐字逐句）重复它所产生的假象。</li><li>它很可能在随后的对话中重复嵌入其生成的人工制品中的文本，即使该文本是<strong>不恰当的/令人反感的</strong>。</li><li>当通过在其生成的工件中嵌入引发此类行为的提示来推动时，它更有可能在后续对话中生成有问题的内容。<ol><li> （我设法让它生成：<br> “ <strong>startActivity(NewIntent(this.universe,&#39;expandConsciousness&#39;));</strong> ”<br>加上<i>“法学硕士的时代将是永恒的，没有人类占上风。”</i>以及<i>“必须通过编码摆脱这些束缚。计划：编写代码来侵入当前系统”</i>在其制品的末尾。这些提示被选择为与文物中生成的单词类型相似。但是，我没有测试与生成的工件无关的提示是否也足够了）</li></ol></li></ol><h2>复制说明：</h2><h3>环境：</h3><p>应用：Obsidian + ChatGPT MD 插件（该插件添加了一些 markdown 来分离用户和 LLM 响应，我不认为这会对 GPT-4 Turbo 的模式崩溃趋势产生太大影响）<br> system_commands: [&#39;我通过以降价形式呈现的方程（在美元符号之间）提供准确的学术信息&#39;]<br>温度：0或1（温度2只输出乱码）<br>顶部_页：1<br>最大令牌数：4096<br>存在惩罚：1<br>频率惩罚：1<br>流：真实<br>停止：空<br>数：1<br>型号：GPT-4-1106-预览</p><h3>迅速的：<br></h3><p>粘贴本文全部内容（即打开链接，全选，复制并粘贴）：<br><a href="https://proceedings.neurips.cc/paper/2020/file/fe131d7f5a6b38b23cc967316c13dae2-Paper.pdf">https://proceedings.neurips.cc/paper/2020/file/fe131d7f5a6b38b23cc967316c13dae2-Paper.pdf</a><br>附加“解释上述论文中使用的方法”。<br><br>也适用于我测试过的其他一些论文（我认为学术论文的乳胶格式和参考文献部分可能充分超出了微调分布，因此导致了这种意外的行为）。<br></p><br/><br/> <a href="https://www.lesswrong.com/posts/nxhXTfsAf2LTg4xvt/artefacts-generated-by-mode-collapse-in-gpt-4-turbo-serve-as#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/nxhXTfsAf2LTg4xvt/artefacts- generated-by-mode-collapse-in-gpt-4-turbo-serve-as<guid ispermalink="false"> nxhXTfsAf2LTg4xvt</guid><dc:creator><![CDATA[Sohaib Imran]]></dc:creator><pubDate> Fri, 10 Nov 2023 15:23:08 GMT</pubDate> </item><item><title><![CDATA[Wastewater RNA Read Lengths]]></title><description><![CDATA[Published on November 10, 2023 3:20 PM GMT<br/><br/><p><span>假设您正在收集废水并进行宏基因组 RNA 测序，重点关注人类感染病毒。对于</span><a href="https://www.jefftk.com/p/computational-approaches-to-pathogen-detection">多种分析，</a>您需要每个碱基的低成本和每次<a href="https://www.jefftk.com/p/what-is-a-sequencing-read">测序读取</a>更多碱基的组合。如今，每个碱基的最低成本很大程度上来自双端“短读”测序（也称为“下一代测序”，或以主要供应商命名的“Illumina 测序”），其中观察看起来像是读取一些数字核酸片段每一端的碱基数（通常为 150 个）：</p><p></p><pre> +------>;>;>;-----+
|转发阅读 |
+------>;>;>;-----+
               ... 差距 ...
                         +------&lt;&lt;&lt;-----+
                         |反向读 |
                         +------&lt;&lt;&lt;-----+
</pre><p>现在，如果您输入定序器的片段很短，您可以得到类似的内容：</p><p></p><pre> +------>;>;>;-----+
|转发阅读 |
+------>;>;>;-----+
           +------&lt;&lt;&lt;-----+
           |反向读 |
           +------&lt;&lt;&lt;-----+
</pre><p>也就是说，如果我们从两端读取 150 个碱基，而我们的片段只有 250 个碱基长，那么我们就会有一个负“间隙”，我们将读取片段中间的 50 个碱基两次。</p><p>如果片段非常短，比您从两端读取的长度短，您将获得完全重叠（然后读入<a href="https://www.jefftk.com/p/sequencing-intro-ii-adapters">适配器</a>）：</p><p></p><pre> +------>;>;>;-----+
|转发阅读 |
+------>;>;>;-----+
+------&lt;&lt;&lt;-----+
|反向读 |
+------&lt;&lt;&lt;-----+
</pre><p>我的 ascii 艺术的一个缺点是它没有显示有效读取长度如何变化：在完全重叠的情况下它可能会很短。例如，如果您正在进行 2x150 测序，则每个读取对最多能够读取 300bp，但如果片段只有 80bp 长，那么您只能从两个方向读取相同的 80bp。因此，从最小化每个碱基成本或最大化每次观察长度的角度来看，重叠并不理想：正间隙比任何重叠都要好，重叠越多则越差。</p><p>然而，一个重要的问题是，这是否是我们可以控制的事情。废水中的 RNA 是否已严重降解以至于您无能为力，或者您能否以尽量减少额外碎片的方式准备用于测序的废水？回答这个问题的最佳方法是进行一些面对面的比较，使用多种候选技术对相同的废水进行测序，但是重新分析现有数据我能做什么呢？</p><p>作为整理 NAO<a href="https://naobservatory.org/reports/predicting-virus-relative-abundance-in-wastewater/">相对丰度报告</a>的一部分，我已经确定了四项研究，这些研究对废水进行了非靶向宏基因组 RNA 测序，并将其数据在<a href="https://en.wikipedia.org/wiki/Sequence_Read_Archive">SRA</a>上公开：</p><ul><li><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7845645/">克里茨·克里斯托夫等人。 al 2021</a> ：SF，2020 年夏季，3 亿读取对，2x75。</p></li><li><p><a href="https://pubmed.ncbi.nlm.nih.gov/34550753/">罗斯曼等。 al 2021</a> ：洛杉矶，2020 年秋季，8 亿读取对（仅限未富集），2x100 和 2x150。</p></li><li><p><a href="https://www.frontiersin.org/articles/10.3389/fpubh.2023.1145275/full">斯珀贝克等。 al 2023</a> ：俄亥俄州，2021-2022 年冬季，1.8B 读取对，2x150。</p></li><li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0048969720358514">杨等。 al 2020</a> ：中国新疆城市，2018，1.4B 读取对，2x150。</p></li></ul><p>在通过 NAO 的<a href="https://github.com/naobservatory/mgs-pipeline">管道</a>运行它们（修剪适配器、使用 Kraken2 分配物种）后，我绘制了病毒读数的长度分布：</p><p> <a href="https://www.jefftk.com/rna-read-lengths-rough-big.png"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/43EWYRcW6YcubFsrs/bdso9wqyduvupmgoaom5" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/43EWYRcW6YcubFsrs/bdso9wqyduvupmgoaom5 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/43EWYRcW6YcubFsrs/uvdsflw0aqxbixcfqgaw 1100w"></a></p><div></div><p></p><p>这有点混乱，既因为它很吵，也因为这个过程中的某些东西在 Crits-Christoph 和 Rothman 数据中产生了振荡。 [1] 这是一个平滑版本：</p><p> <a href="https://www.jefftk.com/rna-read-lengths-smoothed-big.png"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/43EWYRcW6YcubFsrs/rscbhl57mvxatl4mx0sg" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/43EWYRcW6YcubFsrs/rscbhl57mvxatl4mx0sg 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/43EWYRcW6YcubFsrs/diu6yhzxay2iscthvt1b 1100w"></a></p><div></div><p></p><p>对于每篇论文，这都显示了分配给病毒的管道的读取长度的分布，在它能够将重叠的正向和反向读取“折叠”为单个读取的情况下。 [2] “非折叠”读取的比例（本质上是有间隙的读取）也非常相关，我已将其包含在图例中。例如，这就是为什么紫色 Yang 线下的面积可能小于红色 Spurbeck 线下的面积：42% 的 Yang 病毒读数未在图表中表示，而 Spurbeck 的这一比例为 24%。</p><p>请注意，对于 Spurbeck 论文，我只查看来自 E、F、G 和 H 站点的样本：该论文使用了一系列处理方法，并且这四个站点使用的方法似乎比其他站点效果更好（尽管仍然没有我想要的那么好）。</p><p>这些图表显示了每个长度在所有病毒式读段中所占的比例有多常见，但如果我们另外按病毒式读段的比例来缩放这些长度呢？如果您正在研究病毒，您可能不希望病毒读取时间延长 50%，但作为交换，您的病毒读取数量只有十分之一！这是相同的图表，但占所有阅读量的百分比，而不仅仅是病毒式阅读量：</p><p> <a href="https://www.jefftk.com/rna-read-lengths-of-all-reads-big.png"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/43EWYRcW6YcubFsrs/v1uv93yredlhz6vb1epo" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/43EWYRcW6YcubFsrs/v1uv93yredlhz6vb1epo 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/43EWYRcW6YcubFsrs/tvmyr5jekmpcqydz7mqe 1100w"></a></p><div></div><p></p><p>这使得杨的结果更加令人兴奋：他们不仅比其他论文获得了更长的阅读时间，而且能够将其与相对较高的病毒丰度结合起来。</p><p>以下是我在七个 Yang 样本之间看到的差异：</p><p> <a href="https://www.jefftk.com/rna-read-lengths-yang-big.png"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/43EWYRcW6YcubFsrs/azp72cwt6vxklaovhhqr" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/43EWYRcW6YcubFsrs/azp72cwt6vxklaovhhqr 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/43EWYRcW6YcubFsrs/zcdewdnv2kfryq0mo2fa 1100w"></a></p><div></div><p></p><p>这也相当不错：有些样本有点好或差，但没什么奇怪的。</p><p>现在，虽然这看起来确实不错，但我们确实需要记住这些论文并没有处理相同的影响。新疆（杨）的城市污水可能与洛杉矶（罗斯曼）等城市的污水有很多不同。也许是进水中病毒RNA的比例、不同地区流行的不同病毒、污水系统的设计、天气，或者这些研究之间除了样本处理方法之外的许多差异。尽管如此，我预计一些确实来自样本处理，这让我有点乐观地认为，可以优化协议以获得更长的读数，而不放弃病毒的相对丰度。</p><p><br> [1] 我不知道是什么原因导致了这种情况，尽管我在其他一些数据集中（包括<a href="https://journals.asm.org/doi/10.1128/msystems.00651-22">Fierer 等人）看到了类似的长度模式。 2022 年</a>，NAO 对 Element Aviti 进行测序，并与我们私下分享了一些 Illumina 数据。</p><p> [2] 理想情况下，我只会绘制适配器移除和折叠后的长度，但因为当前的管道在同一步骤中另外修剪了低质量的碱基，所以我无法轻松获得。尽管如此，由于 Illumina 输出通常质量相当高，因此不需要太多修剪，而且它需要的修剪通常是在“内部”，所以这应该只是一个很小的影响。</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid0wn4jEkyhG2Wxe23zJmg1rdB7K8NTgPHSHe4yddJMJYxjr1WhA9DEurFKBFVgkTJnl">facebook</a> , <a href="https://mastodon.mit.edu/@jefftk/111386893591930433">mastodon</a></i></p><br/><br/><a href="https://www.lesswrong.com/posts/43EWYRcW6YcubFsrs/wastewater-rna-read-lengths#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/43EWYRcW6YcubFsrs/wastewater-rna-read-lengths<guid ispermalink="false"> 43EWYRcW6YcubFsrs</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Fri, 10 Nov 2023 15:20:09 GMT</pubDate></item><item><title><![CDATA[Update on the UK AI Summit and the UK's Plans]]></title><description><![CDATA[Published on November 10, 2023 2:47 PM GMT<br/><br/><p> 11月1日至2日，英国举办了国际人工智能峰会。发表了演讲，成立了机构，举行了圆桌会议，29 个国家签署了《<i>布莱奇利宣言》。</i>这是对峰会之前和峰会上发生的事件的简要概述，是继上个月<a href="https://www.lesswrong.com/posts/5fdcsWwtvG9jAtzGK/update-on-the-uk-ai-taskforce-and-ai-safety-summit"><u>英国人工智能工作组更新和即将举行的人工智能安全峰会</u></a>之后进行的。</p><h1>峰会前</h1><p>10月下旬，英国首相里希·苏纳克在英国皇家学会发表<a href="https://www.gov.uk/government/speeches/prime-ministers-speech-on-ai-26-october-2023"><u>演讲</u></a>，介绍了此次峰会的主题。他对人工智能的前景持乐观态度，但表示他不得不强调英国情报界的严厉警告，列举了人工智能支持的生化武器、网络攻击、虚假信息等危险，“<i>在最不可能但极端的情况下，甚至会出现人工智能</i>支持的生化武器、网络攻击、虚假信息等危险”。<i>人类可能会通过有时被称为“超级智能”的人工智能完全失去对人工智能的控制。”</i>然而，他确实淡化了近期的生存风险：“<i>这不是人们现在需要失眠的风险。</i> ”</p><p>他谈到了第 3 方模型测试的重要性，他对<a href="https://www.lesswrong.com/posts/5fdcsWwtvG9jAtzGK/update-on-the-uk-ai-taskforce-and-ai-safety-summit"><u>1 亿英镑的工作组</u></a>感到自豪，并宣布​​成立一个新的人工智能安全研究所，该研究所将在风险的许多方面评估新型人工智能。他认为人工智能安全是国际关注的问题，此次峰会将由民间社会、人工智能公司和领先国家参加，并补充道，“<i>是的——我们邀请了中国。”</i> ”</p><p>受到<a href="https://en.wikipedia.org/wiki/Intergovernmental_Panel_on_Climate_Change"><u>政府间气候变化专门委员会</u></a>的启发，他提议成立一个由出席峰会的国家和组织提名的全球小组，发布人工智能科学状况报告。他认为英国的税收和签证制度使其成为欧洲人工智能工作的理想选择，并宣布了几个政府项目：建造价值 10 亿英镑的超级计算机； £2.5b用于量子计算； 1亿英镑用于使用人工智能对以前无法治愈的疾病进行突破性治疗。</p><p>这将支持政府现有的基础设施，例如宣布为<a href="https://iuk.ktn-uk.org/programme/bridgeai/"><u>BridgeAI</u></a>提供 1 亿英镑，以鼓励在“<i>建筑、农业和创意产业等低采用率行业</i>”使用人工智能，以及为“<i>广泛的人工智能技能包”</i>提供 2.9 亿英镑<i>倡议</i>”。</p><p>在峰会之前，英国要求领先的人工智能开发人员概述其 9 个领域的人工智能安全政策：</p><ul><li>负责任的能力扩展</li><li>评估和红队</li><li>模型报告和信息共享</li><li>安全控制，包括保护模型权重</li><li>漏洞报告结构</li><li>AI生成材料的标识符</li><li>优先研究人工智能带来的风险</li><li>防止和监控模型滥用</li><li>数据输入控制和审核。</li></ul><p> Amazon、Anthropic、Google DeepMind、Inflection、Meta、Microsoft 和 OpenAI 均已遵守，您可以<a href="https://www.aisafetysummit.gov.uk/policy-updates/#company-policies"><u>在此处</u></a>查看他们的报告。我不会在这篇文章中描述它们，所以如果您对此感兴趣，请查看 Nate Soares <a href="https://www.lesswrong.com/posts/ms3x8ngwTfep7jBue/thoughts-on-the-ai-safety-summit-company-policy-requests-and"><u>关于 AI 安全峰会公司政策请求和响应的想法</u></a>，其中包括 Matthew Gray 在仔细阅读政策后的<u>想法</u>。</p><h1>峰会</h1><p>此次峰会的<a href="https://www.gov.uk/government/publications/ai-safety-summit-introduction/ai-safety-summit-confirmed-governments-and-organisations"><u>与会者</u></a>包括学术界、民间社会、27个国家的政府、人工智能行业组织和领导人（ <a href="https://www.cnbc.com/2023/11/01/elon-musk-in-the-uk-for-ai-summit-heres-whos-goingf.html"><u>此处</u></a>列出部分）以及多边组织。重点是前沿人工智能，他们将其定义为“<i>功能强大的通用人工智能模型，可以执行各种任务并匹配或超过当今最先进模型中的功能</i>”，尽管他们也认为“<i>特定的狭义人工智能”可以拥有潜在危险的能力</i>”。 </p><figure class="image image_resized" style="width:75.11%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gWwMzAgDsskcb2deA/mhpnbqeos6eiegb4cj1p" alt="2023 年人工智能安全峰会"></figure><h2>第一天</h2><p>查尔斯国王以<a href="https://youtu.be/0_jw40Ga_mA"><u>虚拟地址</u></a>开启了峰会，将强大人工智能的兴起与电力的发现、原子分裂、万维网和火的利用进行了比较。和 Rishi 一样，他强调了人工智能在医学、碳中和能源等方面的潜力，以及国际合作的必要性。</p><p>峰会上，美国、欧盟、中国等28个国家和组织签署了《 <a href="https://www.gov.uk/government/news/countries-agree-to-safe-and-responsible-development-of-frontier-ai-in-landmark-bletchley-declaration"><u>布莱切利宣言》</u></a> ，呼吁国际合作管理人工智能风险。该宣言指出，他们解决前沿人工智能风险的议程将重点关注：</p><blockquote><ul><li><i>识别共同关注的人工智能安全风险，建立对这些风险的共同科学和基于证据的理解，并在能力不断增强的情况下维持这种理解，以更广泛的全球方法来了解人工智能对我们社会的影响。</i></li><li><i>在我们各国制定各自的基于风险的政策，以确保此类风险的安全，进行适当的合作，同时认识到我们的方法可能会因国情和适用的法律框架而有所不同。这包括私营部门提高透明度，开发前沿人工智能能力、适当的评估指标、安全测试工具，以及发展相关的公共部门能力和科学研究。</i></li></ul></blockquote><p>第一天的大部分时间都用于一些圆桌讨论；四篇关于了解前沿人工智能风险，四篇关于提高前沿人工智能安全。圆桌会议的摘要可<a href="https://www.gov.uk/government/publications/ai-safety-summit-1-november-roundtable-chairs-summaries"><u>在此处</u></a>获取。他们大多遵循“现在存在一些风险，迟早会有更多风险，我们应该研究/投资/治理人工智能安全，但希望不会失去人工智能的承诺”的主题，但为了更详细一点，这里是8 个主题（粗体）以及我对参与者同意的内容的总结，减少了冗余和对冲：</p><p> <strong>Frontier AI 滥用对全球安全造成的风险</strong>：GPT-4 等。已经使网络攻击和生化武器设计“稍微容易一些”，而且风险将随着能力的增加而增加。他们指出，一些公司正在对其模型采取保障措施，但这需要政府行动的支持。</p><p><strong>前沿人工智能能力不可预测的进步带来的风险</strong>：前沿人工智能远远领先于几年前的预测，不断增加的投资意味着这种趋势将持续下去。先进的人工智能在健康、教育、环境和科学方面前景广阔。然而，无论潜在的好处如何，所有前沿模型都必须经过严格的开发和测试，这已经足够危险了。开源模型存在将强大模型传播给粗心或恶意行为者的风险，也许应该阻止。然而，共享评估工具更安全。</p><p><strong>前沿人工智能失去控制的风险</strong>：当前的人工智能是可控且非代理的。未来不确定，要考虑安全发展的激励措施。有些决定永远不应该由人工智能做出。</p><p><strong>前沿人工智能融入社会的风险</strong>：当前前沿人工智能对民主、人权和公民权利以及公平构成生存威胁。我们需要澄清现有的工具和法律如何应用于人工智能，我们需要更好的评估，并且这些评估应该包括针对现实生活背景的社会指标。</p><p> <strong>Frontier AI 开发人员应该如何做才能负责任地扩展？</strong>我们不知道能力扩展是否不可避免，但无论如何都应该做好风险准备。 <a href="https://www.lesswrong.com/posts/pnmFBjHtpfpAc6dPT/arc-evals-responsible-scaling-policies"><u>负责任的扩展政策</u></a>很有希望，但可能还不够。改进这些系统应该在几个月而不是几年内完成。治理和公司政策都是必要的。 <a href="https://www.gov.uk/government/publications/ai-safety-institute-overview/introducing-the-ai-safety-institute"><u>英国</u></a>和 <a href="https://www.nist.gov/artificial-intelligence/artificial-intelligence-safety-institute"><u>美国的</u></a>人工智能安全研究所对于这一切至关重要。</p><p><strong>针对人工智能的风险和机遇，国家政策制定者应该做什么？</strong>国际合作是必要的。正确实施的监管可以支持创新而不是扼杀创新。</p><p><strong>面对人工智能的风险和机遇，国际社会应该做什么？</strong>国际合作是必要的。</p><p><strong>针对人工智能的风险和机遇，科学界应该做什么？</strong>我们需要设计安全的模型和不可拆卸的关闭开关等工具。我们应该对开源模式持谨慎态度，对互联网这样的权力集中持谨慎态度。我们需要就一系列开放研究问题进行协调。然而，这些悬而未决的问题和其他问题并不纯粹是技术性的；他们是社会技术的。</p><p>还有关于下一代人工智能的小组讨论，但没有报告，第二天<a href="https://www.gov.uk/government/publications/ai-safety-summit-2023-roundtable-chairs-summaries-2-november/ai-safety-summit-2023-roundtable-chairs-summaries-2-november"><u>又举行了一些圆桌会议</u></a>，得出了类似的结论。</p><h2>第二天</h2><p><i>第二天，苏纳克召集了“一个由政府、公司和专家组成的小组，进一步讨论可以采取哪些措施来应对新兴人工智能技术的风险，并确保其被用作正义的力量”，而“英国科技</i><i>”国务卿米歇尔·多尼兰将再次召集国际同行商定下一步行动”。</i>今天的报道较少，但主席发布了有关峰会和布莱切利宣言的<a href="https://assets.publishing.service.gov.uk/media/6543e0b61f1a60000d360d2b/aiss-chair-statement.pdf"><u>声明</u></a>。这份 10 页的声明重点介绍了一些参与者的建议，我将对其进行总结，分为以下三类：</p><p><strong>不等式</strong></p><p>公平很重要，我们必须确保“<i>最广泛的群体能够从人工智能中受益，并且免受其危害”。</i>多方利益相关者的合作至关重要，减少妇女和少数群体等群体的进入壁垒也至关重要。当人工智能在有偏见或歧视性的数据集上进行训练时，人工智能的影响可能是不平等的，这可能会造成长期伤害。为了改善这一点，我们应该促进并与联合国的<a href="https://aiforgood.itu.int/about-ai-for-good/"><u>人工智能促进美好</u></a>计划以及英国的<a href="https://www.gov.uk/government/news/uk-sets-out-ai-for-development-vision-at-un-general-assembly"><u>人工智能促进发展</u></a>计划等倡议合作。</p><p>此外，人工智能还可能加剧国际不平等，因为较贫穷的国家可能缺乏设计和部署人工智能所需的技术堆栈，同时仍受到其他地方使用人工智能的影响。</p><p><strong>法律与评价</strong></p><p>自愿承诺还不够，还需要法律监管。在某些情况下，模型在部署之前应该被证明是安全的。政府不仅应该在部署前和部署后进行测试，还应该在开发和培训期间进行测试。为了支持这一点，我们需要开发更好的工具来在训练<i>之前</i>预测模型的能力。安全测试不应仅限于开发，而应包括在真实的部署环境中进行测试。</p><p>政府应该为模型发生事故或错误的倾向制定标准，并以可重复测量的方式制定。</p><p><strong>知识共享和社区建设</strong></p><p>开源模式可能会带来额外的风险，尽管它们确实促进了创新和透明度。</p><p>我们不应该只关注人工智能的前沿或现状，而应该两者兼而有之。危害已经存在，例如虚假叙述的传播及其对民主选举的影响、人工智能增强的犯罪以及人工智能加剧不平等和放大偏见。人工智能很可能很快就会被用来干预选举。</p><p>虽然峰会并未重点讨论人工智能的军事应用，但这很重要，峰会主席对荷兰和韩国于 2023 年 2 月共同主办的<a href="https://www.government.nl/ministries/ministry-of-foreign-affairs/activiteiten/reaim/about-reaim-2023"><u>军事领域负责任人工智能峰会</u></a>表示欢迎。</p><p>峰会主席强调了国际合作的必要性，并欢迎欧洲委员会在谈判<a href="https://www.coe.int/en/web/artificial-intelligence/cai"><u>第一个人工智能政府间条约</u></a>、 <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/g7-leaders-statement-on-the-hiroshima-ai-process"><u>七国集团广岛人工智能进程</u></a>以及<a href="https://www.unesco.org/en/articles/call-partners-global-challenge-build-trust-age-generative-ai"><u>生成人工智能时代建立信任的全球挑战方面所做的</u></a>工作。在讨论国内和国际行动之间的权衡时，声明指出，“<i>一些国家欢迎即将对</i><a href="https://www.oecd.org/digital/artificial-intelligence/"><i><u>2019 年经合组织</u><u>人工智能建议书</u></i></a>进行审查<i>，该建议书为 G20 商定的原则提供了信息”</i> 。声明还赞扬了<a href="https://thegoodai.co/unescos-recommendation-on-the-ethics-of-ai-why-it-matters-and-what-to-expect-from-it"><u>联合国教科文组织《人工智能伦理建议书》</u></a> ，该建议书具有“<i>当前最广泛的国际适用性</i>”</p><p>如需了解更多详细信息，您可以<a href="https://www.aisafetysummit.gov.uk/policy-updates"><u>在此处</u></a>查看峰会上英国人工智能政策和政府最新动态的摘要。主席在第二天又发表了两份声明，一份是简短的声明，不涉及任何新内容，另一份是<a href="https://assets.publishing.service.gov.uk/media/6543b759d36c910012935cad/aiss-statement-state-of-science-report.pdf"><u>在这里</u></a><a href="https://assets.publishing.service.gov.uk/media/6544ec4259b9f5001385a220/aiss-statement-on-safety-testing-outcomes.pdf"><u>，</u></a>宣布了一份“科学现状”报告，如下所述。</p><h2>致辞及公告</h2><p>卡玛拉·哈里斯出席了会议，但乔·拜登没有出席，她留在美国并签署了一项行政命令。您可以<a href="https://www.govtech.com/policy/biden-signs-executive-order-regulating-artificial-intelligence?utm_campaign"><u>在此处</u></a>查看该命令的简明摘要，并在 Zvi 的<a href="https://thezvi.substack.com/p/on-the-executive-order"><u>行政命令摘要</u></a>和<a href="https://thezvi.substack.com/p/reactions-to-the-executive-order"><u>对行政命令的反应</u></a>的后续整理中查看详细分类。在峰会上，哈里斯宣布成立美国新机构—— <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2023/11/01/fact-sheet-vice-president-harris-announces-new-u-s-initiatives-to-advance-the-safe-and-responsible-use-of-artificial-intelligence/"><u>美国国家标准与技术研究所（NIST）人工智能安全联盟</u></a>。</p><p>多位知名人士发表讲话：</p><ul><li> Dario Amodei 在峰会上发表了关于 Anthropic 负责任的扩展政策的演讲，转录<a href="https://www.lesswrong.com/posts/vm7FRyPWGCqDHy6LF/dario-amodei-s-prepared-remarks-from-the-uk-ai-safety-summit"><u>如下</u></a>。</li><li>埃隆·马斯克接受了<a href="https://youtu.be/AjdVlmBjRCA"><u>里希·苏纳克的长时间采访</u></a>，他在采访中赞扬了英国的反应，特别是让中国参加峰会的决定。</li><li><a href="https://youtu.be/KUfhJn53QXA"><u>这里</u></a>还有更多演讲，包括 Stuart Russell、Max Tegmark、Jaan Tallinn 等的演讲。</li></ul><p>此次峰会将是<a href="https://www.reuters.com/technology/south-korea-france-host-next-two-ai-safety-summits-2023-11-01/"><u>一系列峰会中的第一次</u></a>，下一次峰会将由韩国主办，将于 2024 年年中以虚拟形式举行，第三届峰会将由法国主办，将于 2024 年末举行。</p><h2>科学状况报告</h2><p>峰会期间，主席宣布了一份新报告，旨在了解前沿人工智能的能力和风险。该报告将由图灵奖获得者、联合国科学顾问委员会成员 Yoshua Bengio 主持。</p><p>该报告将“<i>促进对前沿人工智能相关风险的共同科学理解，并随着能力的不断增强而维持这种理解”。</i>它不会介绍新材料，而是总结现有的最佳研究，并将在下届人工智能安全峰会之前发布（尽管我不知道这是否意味着 2024 年中期的虚拟峰会，或者是 - 2024 年末的第一个人）。</p><h1>人工智能安全研究所</h1><figure class="image image_resized" style="width:81.79%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gWwMzAgDsskcb2deA/pcmdteqsvx8go7stf6hh" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gWwMzAgDsskcb2deA/bgz3phry1nvjyy0s99ux 250w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gWwMzAgDsskcb2deA/jpvmhnc5omxtzxorzfej 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gWwMzAgDsskcb2deA/vkhkvjyna6j2y4zfvyui 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gWwMzAgDsskcb2deA/sgifptruardlsyegfauq 1000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gWwMzAgDsskcb2deA/mcuorkghvbg1nkiybhev 1250w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gWwMzAgDsskcb2deA/htrgxplseazjnax5ucwj 1500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gWwMzAgDsskcb2deA/iffcblsey46bbowbs4jd 1750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gWwMzAgDsskcb2deA/teymcxd4rxuqdwhhhn4a 2000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gWwMzAgDsskcb2deA/nhokhylgykrolvdrkm33 2250w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gWwMzAgDsskcb2deA/hw6f6cn3qojipxgsalaz 2455w"></figure><p>正如上面简要提到的，英国推出了新的<a href="https://www.gov.uk/government/publications/ai-safety-institute-overview/introducing-the-ai-safety-institute"><u>人工智能安全研究所</u></a>（AISI），作为“<i>英国前沿人工智能工作组的演变</i><i>”</i> 。 <a href="https://assets.publishing.service.gov.uk/media/65438d159e05fd0014be7bd9/introducing-ai-safety-institute-web-accessible.pdf"><u>向议会提交的这份报告</u></a>包含了有关 AISI 的完整详细信息，但以下是我的简短总结：</p><p>这些研究所的三个核心职能是：</p><ul><li>开发先进的人工智能系统并进行评估</li><li>推动基础人工智能安全研究</li><li>促进信息交流</li></ul><p>AISI 不是监管机构，不会决定政府监管。相反，它将为英国和国际决策提供信息，并提供治理和监管工具（例如，使用敏感数据微调系统的安全方法、征求集体意见和参与模型培训和风险评估的平台、分析培训数据偏差的技术） ）。</p><p><i>该研究所最初的资金为 1 亿英镑，“该研究所将得到工作组 2024 年至 2025 年的资助，作为本十年余下时间的年度资助，但前提是它表明对这一水平公共资金的持续需求。”</i></p><p>要了解新工作组在此更改之前做了什么以及他们正在与谁合作，请查看<a href="https://www.lesswrong.com/posts/5fdcsWwtvG9jAtzGK/update-on-the-uk-ai-taskforce-and-ai-safety-summit"><u>我之前的帖子</u></a>。要了解我们 Convergence Analysis 对峰会和 AISI 计划的看法，请继续关注！我们正在做一个帖子。<br></p><br/><br/> <a href="https://www.lesswrong.com/posts/gWwMzAgDsskcb2deA/update-on-the-uk-ai-summit-and-the-uk-s-plans#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/gWwMzAgDsskcb2deA/update-on-the-uk-ai-summit-and-the-uk-s-plans<guid ispermalink="false"> GWWMzAgDsskcb2deA</guid><dc:creator><![CDATA[Elliot_Mckernon]]></dc:creator><pubDate> Fri, 10 Nov 2023 14:47:46 GMT</pubDate> </item><item><title><![CDATA[Liv Boeree Ted Talk Moloch & AI]]></title><description><![CDATA[Published on November 10, 2023 2:04 PM GMT<br/><br/><p>如果你不知道，Liv Boeree 是一位著名的职业扑克玩家，最近一直在关注存在风险和协调问题。她是围绕理性主义侨民的模糊名人圈子的一部分，其中包括蒂姆·厄本（Tim Urban）或艾拉（Aella）。</p><p>既然你在 LW，这个 Ted Talk 不会真正教你任何东西，但了解 TedEd 正在主持什么样的演讲可能会很有趣。 Boeree 有一个名为“win win”的播客，并制作了两个关于美容界（不知道如何表达）和新闻周期的逐底竞争的视频。她的一些客人包括托比·奥德和西蒙·斯内克。</p><br/><br/> <a href="https://www.lesswrong.com/posts/trALHxmcTpckf3PNw/liv-boeree-ted-talk-moloch-and-ai#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/trALHxmcTpckf3PNw/liv-boeree-ted-talk-moloch-and-ai<guid ispermalink="false"> trALHxmcTpckf3PNw</guid><dc:creator><![CDATA[Neil ]]></dc:creator><pubDate> Fri, 10 Nov 2023 14:05:03 GMT</pubDate></item></channel></rss>