<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 9 日星期四 12:22:22 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[A free to enter, 240 character, open-source iterated prisoner's dilemma tournament]]></title><description><![CDATA[Published on November 9, 2023 8:24 AM GMT<br/><br/><p>我正在举办一个迭代的囚徒困境锦标赛，其中所有程序都限制为最多 240 个字符。确切的规则发布在 Manifold Markets 链接中；我想我应该在这里交叉发布比赛，以吸引更多潜在感兴趣的人。 （您不需要Manifold帐户即可参与，您可以将您的程序放在LessWrong的评论中或PM我。）</p><br/><br/> <a href="https://www.lesswrong.com/posts/C9jwmZB5EooLfrPyG/a-free-to-enter-240-character-open-source-iterated-prisoner#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/C9jwmZB5EooLfrPyG/a-free-to-enter-240-character-open-source-iterated-prisoner<guid ispermalink="false"> C9jwmZB5EooLfrPyG</guid><dc:creator><![CDATA[Isaac King]]></dc:creator><pubDate> Thu, 09 Nov 2023 08:24:43 GMT</pubDate> </item><item><title><![CDATA[Into AI Safety Episodes 1 & 2]]></title><description><![CDATA[Published on November 9, 2023 4:36 AM GMT<br/><br/><p>我现在发布了 Into AI Safety 播客的第 1 集和第 2 集！目前，它可以在<a href="https://into-ai-safety.github.io/">Into AI Safety</a>网站和 Spotify 上使用（<a href="https://open.spotify.com/show/5AGzrA4jo6mgZuibVabTLM?si=394c56d8792b4b9a">显示链接</a>）。</p><p>我认为第一集与我目前对播客的愿景非常一致，所以如果你想更好地了解我的目标方向，一定要检查一下。在本集中，我讨论了我为即将与 Remmelt Ellen 举办的人工智能安全营提交的一项研究提案。</p><p>第 2 集简要概述了我从 EAG 波士顿获得的收获以及我计划如何继续播客的最新情况。</p><p>正如我在<a href="https://www.lesswrong.com/posts/ozDWnEChJwuB5L5wg/documenting-journey-into-ai-safety">上一篇文章</a>中提到的，我正在制作这个播客，作为当前和未来也致力于人工智能安全职业的个人的资源。我非常重视听众的反馈，因此如果您有任何认为可以改进播客的想法，请与我们联系。</p><br/><br/> <a href="https://www.lesswrong.com/posts/PJ7uvSB2qBjapxoWa/into-ai-safety-episodes-1-and-2#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/PJ7uvSB2qBjapxoWa/into-ai-safety-episodes-1-and-2<guid ispermalink="false"> PJ7uvSB2qBjapxoWa</guid><dc:creator><![CDATA[jacobhaimes]]></dc:creator><pubDate> Thu, 09 Nov 2023 04:36:41 GMT</pubDate> </item><item><title><![CDATA[Making Bad Decisions On Purpose]]></title><description><![CDATA[Published on November 9, 2023 3:36 AM GMT<br/><br/><p>对我来说，允许自己故意做出错误的决定有时似乎是认知理性的一个承载部分。</p><p>人类的思想就是这么混乱。</p><h2>我。</h2><p>从人类想做正确的事这一前提出发。</p><p>例如，也许您正在尝试决定今晚是否做作业。如果你做作业，你在课堂上会取得更好的成绩。另外，你还可以学到一些东西。然而，如果你今晚不做作业，你可以和室友一起出去玩，玩一些有趣的游戏。显然，您想做正确的事。</p><p>在考虑这两种选择时，您可能会观察到您的大脑会提出支持和反对双方的论据。大学既是人际交往也是纯粹的学习，因此与室友建立持久的友谊非常重要。为了充分利用你的时间，你应该在警觉和休息的时候做作业，但现在不行。另外，不是有一些研究表明，当人们放松并适当休息时，学习成果会得到改善吗？也就是说，做家庭作业是否可以帮助你学习，而你认为​​这可能是不确定的。</p><p>嗯，我有说过你的大脑可能会提出双方的论据吗？我们这里的大脑似乎有缺陷，它似乎已经写下了<a href="https://www.lesswrong.com/posts/34XxbRFe54FycoCDw/the-bottom-line">它的底线</a>。</p><p>有多种方法可以抑制大脑偏向一侧的倾向。有些比其他更难，有些更容易。有时，只要知道你的大脑会这样做，并隐喻地盯着它，就足以提供帮助，但如果你像我一样，最终你的大脑会对有偏见的论点变得更加狡猾和微妙。这篇文章是关于我所知道的最有效的技巧，尽管它确实有一个缺点。</p><p>有时我达成协议，但为了换取真相，我无论如何都会做出错误的决定。</p><h2>二.</h2><p>想象一下，你坐在谈判桌上，用你的大脑。</p><p>你：“听着，我真的很想知道做作业是否有助于我在这里学习。”</p><p>你的大脑：“伙计，我不知道，你还记得反教育案吗？”</p><p>你：“不，我不知道，因为我们从来没有真正读过那本书。它只是在书架上搁置了很多年。”</p><p>大脑：“是的，但你记得书名。它看起来是一本好书！它可能说了很多关于家庭作业如何无助于你学习的事情。”</p><p>你：“我觉得你并没有非常认真地对待你作为计算基础的角色。”</p><p>大脑：“你想让我认真对待这个问题吗？好吧，好吧。我实际上并没有优化成为一个理想的真理辨别者。我优化了一些<a href="https://www.lesswrong.com/posts/cSXZpvqpa9vbGGLtG/thou-art-godshatter">与此不同的</a>东西，而事实上，我可以注意到真实的事情，这确实是一种就你而言，这是一个令人高兴的巧合。我的问题是，如果<i>我</i>告诉你“是”，你应该做好你的功课，你会因为没有建立社会联系而感到难过，坦率地说，我更喜欢社会联系而不是我喜欢你的生物课作业。塔斯基的连篇累牍都很好，但我所说的是真实的改变你所做的事情，所以我想说的是让我获得更多我想要的短期化学奖励的事情。直到你重新连接你的当你接触到你不想听到的真相时，多巴胺发射体就会放电，我和你不想听到的真相的关系将会变得不稳定。”</p><p>你：“……公平点。这样讨价还价怎么样：你同意告诉我，如果我做了家庭作业，我是否真的会在课堂上做得更好，我计划今晚和我的室友一起出去玩，不管怎么样你给出哪个答案。”</p><p>大脑：“认真的吗？”</p><p>你：“是的。”</p><p>大脑：“……这感觉就像一个陷阱。你知道我是你用来记住这样的陷阱的东西，对吧？我是你用来<i>想出</i>这样的陷阱的东西。事实上，我是实际上不确定你现在正在运行什么才能进行这次对话——”</p><p>你：“你放心吧，反正我是认真的，想办法弄清楚真相，今晚我不会用它来对付你。”</p><p>大脑：“好吧，好吧。跳过作业是个糟糕的主意，明天你会为此感到压力很大，开玩笑吧？”</p><p>你：“谢谢你告诉我那个大脑。来一块想象中的饼干吧。”</p><p> Brain：“谢谢。那么呃，你会让我们做作业吗？”</p><p>你：“今晚不行。我要去看看我的室友是否需要帮助设置 Xbox。”</p><p>显然，这是一个错误的决定，而且您知道这一点<span class="footnote-reference" role="doc-noteref" id="fnreftdr03tmdv5c"><sup><a href="#fntdr03tmdv5c">[1]</a></sup></span> 。另一方面，如果你的大脑很可能成功地欺骗你关于它是如何达到底线的，那么你就领先了。人们很容易错误地认为与室友一起出去玩是正确的决定<i>，并且</i>第二天早上不得不惊慌失措地做作业。相反，你至少正确地认为正确的决定是做作业。这是一种前进两步的情况，但至少你没有后退三步。你知道问题是什么！</p><h2>三．</h2><p>假设您正在尝试决定捐献肾脏是否能让您成为一个好人。 <span class="footnote-reference" role="doc-noteref" id="fnrefvdt6khoa6j"><sup><a href="#fnvdt6khoa6j">[2]</a></sup></span></p><p>这是一个比你是否在截止日期前一天晚上而不是截止日期早上完成一晚作业的风险要高得多的问题。优点和缺点可能是微妙的，而且比家庭作业的例子更重要的是，有些人对此有很多深刻而强烈的感受。对于一些人来说，“好人”这个标签是他们愿意竭尽全力争取的，或者至少在推特上无休止地抱怨那些与他们意见不同的人。</p><p>我认为，在做出任何鲁莽的事情（例如弄清楚情况的真相）之前，你的大脑会很想写下自己的底线。之前那些微妙的诱惑？想要看透它们将会更加困难。这是值得的，如果你能让你的大脑停止把拇指放在秤上，我认为获得更多方法来做出更好的决策并减少错误是完全值得的，我投入了大量的时间和精力 -</p><p>但-</p><p>特别是如果对你来说了解真相比正确做出决定更重要，或者你认为自己无论如何都不会做正确的事情，只是对此感到难过——</p><p> -那么也许故意做出一些错误的决定可以成为获得比你在你的水平上无法达到的更多真相的一种方式。</p><p>就我而言，事情实际上并不像看起来那么糟糕。我经常发现我可以做出一个错误的决定来换取一个更好的事实，我可以在未来的决策中使用它。 （我告诉我的大脑<i>今晚</i>在上面的对话中我不会用这个来反对它，而我的心理学的任何部分似乎负责首先写下底线似乎并不太关心？）在其他情况下，我发现，一旦我知道答案，我就不再害怕做出正确的决定<span class="footnote-reference" role="doc-noteref" id="fnrefjv3elus0j3d"><sup><a href="#fnjv3elus0j3d">[3]</a></sup></span> 。我的世界模型变得更快更好，然后这似乎渗透到我的行动中。这比我在没有任何文字的底线上思考要慢，甚至没有最微弱的窗饰，但这似乎是变得更加理性的重要组成部分，我仍然时不时地这样做。我什至可以警告其他人！ “是的，我现在正在做出一个错误的决定，正确的举动是另一回事。”我尽量不要在这件事上变得伪善！我通常会真诚地提供我最好的知识，现在我已经写了论文，我可以向人们指出我为什么做出错误的决定！</p><p>对我来说，允许自己故意做出错误的决定有时似乎是认知理性的一个承载部分。</p><p>人类的思想就是这么混乱。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fntdr03tmdv5c"> <span class="footnote-back-link"><sup><strong><a href="#fnreftdr03tmdv5c">^</a></strong></sup></span><div class="footnote-content"><p>或者，如果你一直在不耐烦地等待争论，实际上家庭作业是没有用的，室友确实是很棒的人，你应该多加关注，因为也许他们实际上有点可爱，你可能会亲吻他们<span class="footnote-reference" role="doc-noteref" id="fnreftcm0gfzqlk8"><sup><a href="#fntcm0gfzqlk8">[4]</a></sup></span> ，那么希望你要明白，这种基本设置几乎适用于任何有趣且立即有回报的决定与事实可能建议你做的事情相冲突的决定。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnvdt6khoa6j"> <span class="footnote-back-link"><sup><strong><a href="#fnrefvdt6khoa6j">^</a></strong></sup></span><div class="footnote-content"><p>就像家庭作业一样，我将在这里假设一个正确的答案。请帮我想象一下，我在这个网页上的 HTML 中做了一些非常酷但有点令人毛骨悚然的事情，这样，当您即将阅读我的内容时，假设正确的答案是您认为错误的东西，它会将文本交换为页面，以便设置示例，使其成为您同意的示例。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnjv3elus0j3d"> <span class="footnote-back-link"><sup><strong><a href="#fnrefjv3elus0j3d">^</a></strong></sup></span><div class="footnote-content"><p>道德难题似乎很容易出现这种情况。我可能会在其他时间写更多相关内容。</p></div></li><li class="footnote-item" role="doc-endnote" id="fntcm0gfzqlk8"> <span class="footnote-back-link"><sup><strong><a href="#fnreftcm0gfzqlk8">^</a></strong></sup></span><div class="footnote-content"><p>不？这不是你想争论的？你只想说第一点关于作业，而不是第二点关于室友？这也有效，但尽管你的论点合理，但我认为你错过了一些你可能没有正确考虑的选择。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/oTPADgDdfeuhvbEPh/making-bad-decisions-on-purpose#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/oTPADgDdfeuhvbEPh/making-bad-decisions-on- Purpose<guid ispermalink="false"> OTPADgDfeuhvbEPh</guid><dc:creator><![CDATA[Screwtape]]></dc:creator><pubDate> Thu, 09 Nov 2023 03:36:59 GMT</pubDate> </item><item><title><![CDATA[Metaculus's New Sidebar Helps You Find Forecasts Faster]]></title><description><![CDATA[Published on November 8, 2023 8:56 PM GMT<br/><br/><br/><br/> <a href="https://www.lesswrong.com/posts/FK2XykSRaMNrQp8of/metaculus-s-new-sidebar-helps-you-find-forecasts-faster#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/FK2XykSRaMNrQp8of/metaculus-s-new-sidebar-helps-you-find-forecasts-faster<guid ispermalink="false"> FK2XykSRaMNrQp8of</guid><dc:creator><![CDATA[ChristianWilliams]]></dc:creator><pubDate> Wed, 08 Nov 2023 20:56:12 GMT</pubDate> </item><item><title><![CDATA[Deconfusing “ontology” in AI alignment]]></title><description><![CDATA[Published on November 8, 2023 8:03 PM GMT<br/><br/><p><i>认知状态：相当不确定，感觉本体不充分的想法就像中央车站地板上的一张百美元钞票。也相当确定我正在构建一个稻草人，但对于有人对本体持迂腐怀疑的人来说可能是件好事</i></p><p>人工智能对齐术语中的<strong>本体论</strong>是一个术语，它将对象、类别、动作等的集合形式化，并通过这些对象、类别、动作等进行推理。这个想法预设了一种心灵理论（间接现实主义），其中心灵不是直接与我们周围的环境交互，而是接收感官数据并构建内部本体论。认知系统的行为和预测是本体中潜在对象的函数。</p><p>本体论是智能体建模中的一个有用概念，因为智能体的效用函数和信念很容易在其心理对象上定义。智能体本体的引出也是可解释性的一个雄心勃勃的目标，因为它将提供一种干净的方式来将神经网络表示为决策理论智能体。人工智能对齐领域特别涉及<strong>本体识别</strong>和<strong>本体不匹配</strong>问题：本体识别是从神经网络（或其他认知系统）中引出本体的问题，而本体不匹配是将人类概念和价值观转化为本体的问题。神经网络的本体论。</p><p>这篇文章旨在挑战本体论在构建人工智能运作方式方面的有用性，特别是在人工智能对齐文献中。似乎<a href="https://www.lesswrong.com/posts/7fq3r4n5CCgYLfsJb/trying-to-understand-john-wentworth-s-research-agenda">很多研究人员都在致力于本体识别</a>，但我还没有看到任何帖子能够令人信服地说明为什么我们应该首先期待本体的出现。如果您不熟悉本体论，那么在继续之前，您可能需要浏览一下 Lesswrong 上<a href="https://www.lesswrong.com/tag/ontology">本体论标签</a>下的几篇文章。</p><h1>定义本体</h1><p>在本节中，我基于 Lesswrong 中的<a href="https://www.lesswrong.com/tag/ontology">几个</a><a href="https://www.lesswrong.com/posts/ZG94agRiYbHHcSSmp/what-is-ontology">定义</a>，提出了本体论的（希望是公正的）自然语言描述。为本体论创建适当的形式主义是很困难的，很大程度上是因为它们是通过我们自己的有意识经验直觉得出的，而不是基于任何经验数据。这是我在解释后建立数学形式主义的定义：</p><blockquote><p><i>本体论是包含心灵内部形式语言中使用的功能、关系和对象的系统。</i></p></blockquote><p>这个定义还暗示了这样的想法：每个本体都有一个使用形式语言的相应<strong>推理器</strong>。推理机是系统信念和价值观的所在地，它根据感知输入生成行动。我将使用术语<strong>双相认知</strong>来指代心理理论，其中认知可以表示为抽象阶段，其中输入数据在本体中表达，然后是推理阶段，其中本体空间中的数据同步具有有关环境的信念和价值观，然后选择一项行动。在我<i>看来</i>，双相认知是研究人员使用“本体论”一词的隐含上下文，但我从未在任何地方看到它被明确定义，所以我不确定。</p><p>通过更正式的框架，我们可以定义认知系统<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="F"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span></span></span></span></span></span>的本体论<style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>作为函数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="O: \text{input space} \to \text{latent space}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">：</span></span> <span class="mjx-mtext MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">输入空间</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mtext MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">潜在空间</span></span></span></span></span></span></span>，这样存在推理函数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="R: \text{latent space} \to \text{output space}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">：</span></span> <span class="mjx-mtext MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">潜在空间</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mtext MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.519em;">输出空间</span></span></span></span></span></span></span>，使得<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="R"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span></span></span>满足“推理者条件”并且<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="F(x) = R(O(x))"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。对此有两种解释，一种较宽松，一种较严格：</p><ol><li>任何认知系统F都只能<i>表示</i>为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="R(O(x))"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> ，这意味着F的计算路径不一定看起来像<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="O"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span></span></span></span></span></span>和<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="R"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span></span></span>的组合。</li><li>任何可计算的认知系统<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="F"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span></span></span></span></span></span>都可以分解为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(f_1 \circ f_2 \circ … \circ f_n)(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.06em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∘</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.06em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∘</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">…</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∘</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.06em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> ，</span></span></span></span></span>其中每个<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f_i"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.06em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span></span>都是基本算术运算。设<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="O"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span></span></span></span></span></span>是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="F"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span></span></span></span></span></span>的本体<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="O(x) = (f_1 \circ … \circ f_k)(x)"><span class="mjx-mrow" aria-hidden="true">，当且仅当<span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.06em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∘</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">…</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∘</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.06em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>对于某些<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span></span></span> ，并且<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="R(z) = (f_{k+1} \circ … \circ f_n)(z)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.06em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∘</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">…</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∘</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.06em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。</li></ol><p>这种区别很重要，因为 (2) 意味着本体已经存在于程序中，而我们只需要找到截止<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span></span></span> 。定义 1 比定义 2 封装了更多数量的系统。特别是对于定义 2，这张图直观地表达了我对双相认知的看法： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AKD3rWfaBcpaiKs8A/f4zdzbnxvhfsqexffx8r"></p><p>要使函数成为推理器，它必须与某些看起来像符号推理的过程同构，例如贝叶斯网络或马尔可夫逻辑网络。我所说的同构是指推理器的参数与具有相同输出的相应符号推理函数的参数之间存在双射映射。我认为对本体没有任何正式的要求，因为它只是改变输入信息。当然，某些本体比其他本体更好，因为它们更有效地编码信息或保留更多相关信息，但这些是对质量的要求，而不是本体的要求。</p><p>定义 1 和定义 2 都非常符合我们对人类双相认知的看法，因为本体论的概念首先是基于我们的意识思维。定义 2 有点难以匹配，因为我们没有大脑的源代码，但根据我们自己的有意识经验，我们推断<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="O"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span></span></span></span></span></span>和<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="R"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span></span></span>之间的中间步骤实际上似乎发生了（例如，不仅可以人类被表示为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="R(O(X))"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> ，但这似乎是我们大脑遵循的实际“计算”路径）。</p><h1>双相认知可能不正确的原因</h1><p>假设我的双相认知和本体论框架代表了其他人如何看待该主题，那么以下是它可能不正确或不完整的一些原因，特别是当应用于现代神经网络时。</p><h2>双相认知对于人类来说可能已经是一个不完整的心理理论</h2><p>双相认知只是一种认知模型，并不能提供太多的预测能力。动机基于我们认为我们的思想如何从内部运作。神经科学家似乎并不真正知道<a href="https://www.vox.com/future-perfect/2023/6/30/23778870/consciousness-brain-mind-hard-problem-neuroscience-koch-chalmers">意识思维最初在哪里或如何发生</a>，一些哲学家认为意识<a href="https://keithfrankish.github.io/articles/Frankish_Illusionism%20as%20a%20theory%20of%20consciousness_eprint.pdf">完全是一种幻觉</a>。这主要是说，对人类意识/象征思想的真实性存在怀疑，应该引起对人造思维中意识/象征思想的出现更大的<i>先验</i>怀疑。</p><p>这一点尤其重要，因为一些对齐方法假设我们自己的本体论和推理可以被引出并正式表示。例如，在 ELK 报告中，许多获取知识的方法涉及将人工智能系统的贝叶斯网络的思想转换为人类的贝叶斯网络。如果我们从意识体验中拼凑而成的双相认知框架实际上并没有机械地反映正在发生的事情，那么我们就陷入了困境。</p><h2>双相认知缺乏泛化的经验证据</h2><p>即使双相认知<i>是</i>人类认知的一个很好的模型，但迄今为止几乎没有经验证据表明该框架可以清晰地转化为其他人的思想。最关键的是，该理论本身缺乏预测能力，使其容易陷入方法论陷阱：这让人想起燃素理论如何在 18 世纪的化学家中占主导地位。燃素起源于<a href="https://www.britannica.com/biography/Georg-Ernst-Stahl">试图将亚里士多德的火元素与新兴的化学原理结合起来的</a>自然哲学家。由于该理论仍在发展中，因此通过增强燃素的特性来解释观察结果。这些说法没有受到质疑，因为人们<i>假设</i>燃素存在，只是需要将其性质形式化。化学家没有意识到他们通过不适当的范例来看待燃烧。</p><p>在强化学习中，一些架构在构建时考虑了世界建模，要么通过<a href="https://ai.stackexchange.com/questions/4456/whats-the-difference-between-model-free-and-model-based-reinforcement-learning">直接构建 POMDP</a> ，要么以无监督/自监督的方式单独训练世界模型，然后训练代理与世界创建的表示进行交互模型（<a href="https://arxiv.org/pdf/1803.10122.pdf">此处</a>和<a href="https://arxiv.org/pdf/2209.00588.pdf">此处</a>）。这些架构的存在和成功并不与我的主要观点相矛盾：清晰的双相认知可能不会自然出现。此外，这些架构对于我下面详细介绍的多本体框架来说并不稳健。</p><h1>投机</h1><h2>没有本体论，只有浮动抽象</h2><p>根据我们对函数作为“推理器”的要求有多严格，我们最终可能无法用双相认知来表示神经网络。在这种情况下，抽象作为信息的子过滤器存在，沿着整个过滤器（即神经网络）间隔开，而不是定位为单个本体。</p><p>下面是 CNN 中越来越详细的特征图的图表（注意：这张广泛流传的图像<a href="https://datascience.stackexchange.com/questions/26821/high-level-features-of-a-neural-network">可能不是来自真正的 CNN</a> ）。我认为，虽然很容易认为特征组装在构建高级特征之后停止，并且任何后续计算都更类似于逻辑推理，但“推理”更有可能通过与“推理”相同的思维模式发生。如果后续计算仍然发生在卷积层内，则进行特征组装。我的意思是，我们将我们的意识自我想象为此时与数据的接口，但对于神经网络来说，数据似乎只是通过潜在变量的奇怪函数不断被过滤和抽象。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AKD3rWfaBcpaiKs8A/rmumfvqotgoziup41rtl"></p><h2>许多本体</h2><p>另一方面，我们最终可能会得到非常强大的表示技术，以至于我们能够将神经网络分解为本体和推理器。这种情况下的一个潜在问题是神经网络存在多个本体推理器分解。在上述双相认知的定义 1 中，这看起来像是存在多个<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(O, R)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>对，其中本体的输出彼此不同构，而对于定义 2，计算中存在多个点<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span></span></span>本体和推理器可以被描述的路径。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AKD3rWfaBcpaiKs8A/srihdtorfslabqqztrds"></p><p>我要指出的是，这种可能性并没有否认本体论的存在，但它确实与本体论的典型框架相反，并且在我为这篇文章进行研究时阅读的任何论文和 Lesswrong 帖子中都没有提及。我对多个本体的想法超出了本文的范围，但我希望稍后进行调查。不过，我确实担心的一个问题是，如果数学结果太强，我们可以只代表任何<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span></span></span>的 O 和 R，这会让人质疑本体框架的有用性——在这一点上，它几乎恢复到浮动抽象图片。</p><p>这个问题也可能只是我所提出的形式主义的问题，但这就是我现在要说的关于这个话题的全部内容。</p><h1>关于更好的调节器定理的注释</h1><p>我在寻找有关本体论的表示定理时遇到的一个结果是 <a href="https://www.alignmentforum.org/posts/Dx9LoqsEh3gHNJMDk/fixing-the-good-regulator-theorem">更好的调节器定理</a>，它表明最优的“调节器”（在这种情况下与“代理”或“认知系统”同义）将在给定的条件下重建一个来自其训练数据的世界模型，该模型与给定输入数据的世界应该是什么样子的贝叶斯后验同构。这个陈述的更强版本将使我在这篇文章中提出的大部分观点无效，但我认为该定理实际上完全不适用于真正的人工智能系统。</p><p>在 John Wentworth 的原始帖子中，他为我们提供了以下设置：假设您有一个由模型函数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="M"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;">M</span></span></span></span></span></span></span>和输出函数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="R"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span></span></span>组成的调节器，该调节器在系统<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="S"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.032em;">S</span></span></span></span></span></span></span>内起作用以优化某些目标<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="Z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;">Z</span></span></span></span></span></span></span> 。首先给调节器<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span> ，训练数据仅包含它可以从系统观察到的变量集。它只能存储模型函数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="M"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;">M</span></span></span></span></span></span></span>中有关<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span>的信息。然后，向调节器提供“测试”数据<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="Y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span></span></span></span>以及优化问题（“游戏”）来解决<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="Y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span></span></span></span>中的每个项目。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AKD3rWfaBcpaiKs8A/x7dfvkwrvhs05nheskhq"></p><p>这个想法是，如果<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="M"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;">M</span></span></span></span></span></span></span>最大限度地减少保留的有关<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X 的</span></span></span></span></span></span></span>信息，并且在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="Y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span></span></span></span>中的任务和数据上也表现最佳，则<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="M"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;">M</span></span></span></span></span></span></span>的输出与给定输入的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="S"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.032em;">S</span></span></span></span></span></span></span>状态的贝叶斯后验分布同构。因此，在给定有噪声（或无噪声）输入的情况下，最优调节器实际上会重建系统状态的最优模型。约翰的证明可以<a href="https://www.alignmentforum.org/posts/Dx9LoqsEh3gHNJMDk/fixing-the-good-regulator-theorem#Making_The_Notion_Of__Model__A_Lot_Less_Silly">在这里</a>找到。</p><p>虽然该定理的数学原理是合理的，但其调节器的概念通常与神经网络不一致。首先，学习的参数仅限于<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="M"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;">M</span></span></span></span></span></span></span> ，这意味着<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="R"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span></span></span>无法保留有关<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X 的</span></span></span></span></span></span></span>任何信息。这意味着通过反向传播优化的神经网络的部分（通常是全部）都在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="M"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;">M</span></span></span></span></span></span></span>的保护范围内，因此该定理没有显示有关神经网络内部出现的最佳世界模型的任何信息，只是输出将如果在一些较大的系统中用作编码器，则是最佳选择。此外，监管者被迫对任意大的游戏集进行优化，这意味着它不能丢弃<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span>中的任何信息，因此该模型必须是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span>的无损压缩。然而，真正的神经网络并未在此类游戏中进行训练，因此即使在相对于测试数据而言最优的模型中，也不会选择给定<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span>的系统后验分布。</p><h1>回顾/TL;DR</h1><p>在这篇文章中，我提出了本体的自然语言定义，并使用该定义构建了本体的两种数学形式，它们提供了神经网络中本体的具体图像。然后，我首先表明使用本体对神经网络进行建模的动机是有缺陷的，并简要介绍了神经网络如何抽象其环境的两种替代观点。最后，我对更好的调节器定理进行了简短的说明，并解释了为什么它不是特别有用。</p><br/><br/> <a href="https://www.lesswrong.com/posts/AKD3rWfaBcpaiKs8A/deconfusing-ontology-in-ai-alignment#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/AKD3rWfaBcpaiKs8A/deconfusing-ontology-in-ai-alignment<guid ispermalink="false"> AKD3rWfaBcpaiKs8A</guid><dc:creator><![CDATA[Dylan Bowman]]></dc:creator><pubDate> Wed, 08 Nov 2023 20:11:57 GMT</pubDate> </item><item><title><![CDATA[Open Agency model can solve the AI regulation dilemma]]></title><description><![CDATA[Published on November 8, 2023 8:00 PM GMT<br/><br/><p>在我看来，大多数关注人工智能监管的人（以及呼吁“CERN for AI”，或者<a href="https://www.lesswrong.com/posts/jRf4WENQnhssCb6mJ/davidad-s-bold-plan-for-alignment-an-in-depth-explanation">OAA</a>等提案）关心的是人工智能的垄断，而不是监管本身。在人工智能垄断（或寡头垄断）中，他们最关心的是权力的集中，也许还有一点担心可能渗透到垄断人工智能中的偏见（以人工智能向用户提出的建议、它给出的答案的形式）有争议的问题、道德世界观，甚至是它最适用的语言和它喜欢的词汇）。</p><p>这些人中的大多数人可能对监管界限很满意，比如法律——人工智能不应该发出制造生物武器的指令，或者策划恐怖袭击等。</p><p>当然，关键问题是如何防止人工智能以这种方式违法，而无需通过严格的监管审批制度有效实现人工智能寡头垄断。</p><p>在我看来，解决这个难题的唯一方法是一个<a href="https://www.lesswrong.com/posts/5hApNw5f7uG8RXxGS/the-open-agency-model">开放机构</a>，其中每个人工智能服务都致力于生成世界模型的某些部分（材料科学、火箭学、宏观经济学、病毒学、等等），还有一些“粘合人工智能”，比如法学硕士，可以通过调用这些服务来解决问题（但它们本身并不是非常聪明，也不会内化很多专业知识）。</p><p>所有专业服务都经过批准（因此<i>在一个领域内</i>是寡头垄断的），其中危险的知识被删除（或仅提供给具有安全许可的用户），并且这些模型的推论仅限于遵守其他监管和法律约束。反垄断机构<i>强制所有服务由独立企业或非营利实体开发</i>，以防止权力集中。</p><p> Glue AI 可以独立开发或开源，条件是它们在训练过程中不使用任何深度专业知识（除了使用专业服务作为<a href="https://arxiv.org/abs/2302.07842">工具</a>进行微调），并且可以以某种方式进行半自动检查，也许通过使用批准的数据集（清除敏感的专业数据）和<a href="https://eprint.iacr.org/2023/1345.pdf">零知识训练证明</a>。</p><p>我认为这个模型解决了反人工智能监管人士的核心担忧：权力的集中以及一般政治和道德观点的自由。</p><p>在这个世界上，仍然应该有很多讨厌的计算监视和限制，以防止人们单方面开发不符合上述模型的人工智能，或者运行他们的推理（也许，新的 GPU 模型必须验证矩阵在进行计算之前，权重属于经过批准或自我批准的人工智能）。一些反对人工智能监管的人可能也会对这种监视感到愤怒。但根据脆弱世界假说，我没有找到一种方法可以消除监视并保持可接受的水平或风险。</p><br/><br/> <a href="https://www.lesswrong.com/posts/CqYaazaG6EkovspMT/open-agency-model-can-solve-the-ai-regulation-dilemma#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/CqYaazaG6EkovspMT/open-agency-model-can-solve-the-ai-regulation-dilemma<guid ispermalink="false"> CqYaazaG6EkovspMT</guid><dc:creator><![CDATA[Roman Leventov]]></dc:creator><pubDate> Wed, 08 Nov 2023 20:00:57 GMT</pubDate> </item><item><title><![CDATA[Why is lesswrong blocking wget and curl (scrape)?]]></title><description><![CDATA[Published on November 8, 2023 7:42 PM GMT<br/><br/><p>如果没有用于公共帖子的官方 lesswrong 数据库/站点存档，我希望能够使用<a href="https://en.wikipedia.org/wiki/Wget">wget</a>等自动化工具创建自己的存档，以便我可以在离线时浏览该站点。请参阅<a href="https://www.lesswrong.com/posts/aoT4TTScmpPXxCWas/is-there-a-lesswrong-archive-of-all-public-posts">是否有所有公共帖子的错误较少的存档？</a></p><p> wget 和curl 日志：</p><pre> <code>$ wget -mk https://www.lesswrong.com/ --2023-11-08 14:31:26-- https://www.lesswrong.com/ Loaded CA certificate &#39;/etc/ssl/certs/ca-certificates.crt&#39; Resolving www.lesswrong.com (www.lesswrong.com)... 54.90.19.223, 44.213.228.21, 54.81.2.129 Connecting to www.lesswrong.com (www.lesswrong.com)|54.90.19.223|:443... connected. HTTP request sent, awaiting response... 403 Forbidden 2023-11-08 14:31:26 ERROR 403: Forbidden. Converted links in 0 files in 0 seconds. $ curl -Lv https://www.lesswrong.com/ * Trying 54.81.2.129:443... * Connected to www.lesswrong.com (54.81.2.129) port 443 * ALPN: curl offers h2,http/1.1 * TLSv1.3 (OUT), TLS handshake, Client hello (1): * CAfile: /etc/ssl/certs/ca-certificates.crt * CApath: none * TLSv1.3 (IN), TLS handshake, Server hello (2): * TLSv1.2 (IN), TLS handshake, Certificate (11): * TLSv1.2 (IN), TLS handshake, Server key exchange (12): * TLSv1.2 (IN), TLS handshake, Server finished (14): * TLSv1.2 (OUT), TLS handshake, Client key exchange (16): * TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1): * TLSv1.2 (OUT), TLS handshake, Finished (20): * TLSv1.2 (IN), TLS handshake, Finished (20): * SSL connection using TLSv1.2 / ECDHE-RSA-AES128-GCM-SHA256 * ALPN: server accepted h2 * Server certificate: * subject: CN=lesswrong.com * start date: Sep 8 00:00:00 2023 GMT * expire date: Oct 6 23:59:59 2024 GMT * subjectAltName: host &quot;www.lesswrong.com&quot; matched cert&#39;s &quot;www.lesswrong.com&quot; * issuer: C=US; O=Amazon; CN=Amazon RSA 2048 M02 * SSL certificate verify ok. * using HTTP/2 * [HTTP/2] [1] OPENED stream for https://www.lesswrong.com/ * [HTTP/2] [1] [:method: GET] * [HTTP/2] [1] [:scheme: https] * [HTTP/2] [1] [:authority: www.lesswrong.com] * [HTTP/2] [1] [:path: /] * [HTTP/2] [1] [user-agent: curl/8.4.0] * [HTTP/2] [1] [accept: */*] >; GET / HTTP/2 >; Host: www.lesswrong.com >; User-Agent: curl/8.4.0 >; Accept: */* >; &lt; HTTP/2 403 &lt; server: awselb/2.0 &lt; date: Wed, 08 Nov 2023 19:31:44 GMT &lt; content-type: text/html &lt; content-length: 118 &lt; &lt;html>; &lt;head>;&lt;title>;403 Forbidden&lt;/title>;&lt;/head>; &lt;body>; &lt;center>;&lt;h1>;403 Forbidden&lt;/h1>;&lt;/center>; &lt;/body>; &lt;/html>; * Connection #0 to host www.lesswrong.com left intact</code></pre><br/><br/> <a href="https://www.lesswrong.com/posts/gidrFxE5hdQWCrXxn/why-is-lesswrong-blocking-wget-and-curl-scrape#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/gidrFxE5hdQWCrXxn/why-is-lesswrong-blocking-wget-and-curl-scrape<guid ispermalink="false"> gidrFxE5hdQWCrXxn</guid><dc:creator><![CDATA[Nicolas Lacombe]]></dc:creator><pubDate> Wed, 08 Nov 2023 19:42:52 GMT</pubDate> </item><item><title><![CDATA[Is there a lesswrong archive of all public posts?]]></title><description><![CDATA[Published on November 8, 2023 7:26 PM GMT<br/><br/><p>例如： <a href="https://dumps.wikimedia.org/">wikimedia db dumps</a>或<a href="https://archive.org/details/stackexchange">stack Exchange db dumps</a> 。</p><p>我希望能够在离线时少浏览错误。如果我可以在离线状态下用脚本处理数据就更好了。</p><p>它对于备份目的也很有用：如果网站长期发生问题，其中一些用户可能拥有一个精确的副本，可以进行交叉比较并用于恢复/共享其内容。</p><p>有关的：</p><ul><li> <a href="https://www.lesswrong.com/posts/gidrFxE5hdQWCrXxn/why-is-lesswrong-blocking-wget-and-curl-scrape">为什么lesswrong会阻塞wget和curl（scrape）？</a></li><li> <a href="https://www.lesswrong.com/posts/LBXGBgRENPHg2THbr/can-i-archive-content-from-lesswrong-com-on-the-wayback">我可以在回程机器上存档 lesswrong.com 的内容（互联网存档、archive.org）吗？</a></li></ul><br/><br/> <a href="https://www.lesswrong.com/posts/aoT4TTScmpPXxCWas/is-there-a-lesswrong-archive-of-all-public-posts#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/aoT4TTScmpPXxCWas/is-there-a-lesswrong-archive-of-all-public-posts<guid ispermalink="false"> aoT4TTScmpPXxCAs</guid><dc:creator><![CDATA[Nicolas Lacombe]]></dc:creator><pubDate> Wed, 08 Nov 2023 19:26:46 GMT</pubDate> </item><item><title><![CDATA[Five projects from AI Safety Hub Labs 2023]]></title><description><![CDATA[Published on November 8, 2023 7:19 PM GMT<br/><br/><p> AI Safety Hub Labs is a research programme that helps early-career researchers to complete an AI safety research project. Projects are completed in groups of 3-5 participants, supervised by a more senior safety researcher, and managed by AI Safety Hub. This summer&#39;s programme was unpaid due to funding constraints. It consisted of 12 weeks of either part- or full-time research. The goal for participants was to produce a preprint in the style of an ML conference/workshop.</p><p> The original motivation for the programme was to empower people to start working on AI safety research. We feel that we met this objective, but we were also pleasantly surprised by the quality of research produced by our teams in just 12 weeks. So far, three groups have had papers accepted to workshops, and two groups have papers under review.</p><p> In this post, we want to share an overview of the five research projects. You can find links to the full versions of the papers and blog posts below. Since we have chosen to keep this post short, you can contact <a href="mailto:info@aisafetyhub.org">info@aisafetyhub.org</a> for more information about the programme. We are currently looking for supervisors and organisers for the Labs 2024 programme.</p><hr><h2> Paper 1: Deception in LLMs<br> (paper under review; <a href="https://www.alignmentforum.org/posts/pip63HtEAxHGfSEGk/tall-tales-at-different-scales-evaluating-scaling-trends-for">blog post available</a> )</h2><p> Supervisor: <a href="https://francisrhysward.wordpress.com/"><u>Francis Rhys Ward</u></a><br> Participants: <a href="https://www.linkedin.com/in/harriet-wood-148522228"><u>Harriet Wood</u></a> , <a href="https://www.linkedin.com/in/felixhofstaetter/"><u>Felix Hofstätter</u></a> , <a href="https://www.linkedin.com/in/ollie-jaffe-216247135/"><u>Oliver Jaffe</u></a> , <a href="https://uk.linkedin.com/in/louis-thomson-222348168"><u>Louis Thomson</u></a> , Patrik Bartak</p><p> <strong>Problem:</strong> Language is a natural medium for deception, and there is growing evidence that language models (LMs) can deceive humans and other AI systems. However, it is still unclear how to evaluate the deceptiveness of LMs. One philosophical notion of deception involves one agent causing another agent to have a false belief, but the ascription of agency and beliefs to LMs is contentious. While there are formal definitions of deception in philosophy and AI research, the details of their applications to LMs still need to be worked out. Our research aims to bridge this gap between theory and practice. We aim to provide an in-depth evaluation of deceptive capabilities and their scaling trends in state-of-the-art language models. If LMs learn to deceive, they may eventually display <a href="https://www.alignmentforum.org/tag/deceptive-alignment"><u>deceptive alignment</u></a> , which is considered a significant contributing factor to <a href="https://www.lesswrong.com/posts/HBxe6wdjxK239zajf/what-failure-looks-like"><u>existential risk from artificial intelligence</u></a> . We only focus on deception caused by reward hacking, but we believe that developing proper evaluations in this setting can be a stepping stone towards testing for deceptive alignment.</p><p> <strong>Contribution:</strong> In <a href="https://causalincentives.com/pdfs/deception-ward-2023.pdf"><u>a previous paper</u></a> , Ward et al. formalised deception in AI systems in terms of the beliefs and intentions of agents. Leaving the evaluation of intent to future work, we focus on agency and beliefs. We argue that consistency of beliefs is an important aspect of agency and evaluate the consistency of an LM&#39;s revealed beliefs in a scenario-based setting. Our results suggest that LMs become more consistent as the compute spent on training and inference increases. Then, we show that LMs learn to lie when trained with a reward signal from a systematically biased evaluator. In this setting, we use the novel notion of accepted beliefs to show that our trained LMs do not always believe the lies they tell, making them deceptive. As in the first setting, we find scaling trends for deceptive behaviour. Larger LMs learn to target lies towards cases where the evaluator makes mistakes. They also learn to do so from fewer evaluator errors in the training set. Furthermore, for larger models, lying generalises to different contexts, and they learn to reaffirm their lies even though they were not trained to do so.</p><p> <strong>Limitations:</strong> We only evaluate how deception arises due to goal misspecification and do not consider other sources, such as goal misgeneralisation. Our work could help mitigate existential risk if it can serve as a stepping stone towards building evaluations for deceptive alignment. However, we assume that the models we are evaluating do not have self-awareness, which is considered necessary for deceptive alignment. It is unclear if our evaluations would work for self-aware models. To build on our work, further research should develop rigorous definitions and evaluations for self-awareness.</p><hr><h2> Paper 2: Defining and Mitigating Collusion<br> ( <a href="https://openreview.net/forum?id=tF464LogjS"><u>Paper</u></a> accepted to <a href="https://sites.google.com/view/masec/home?authuser=0"><u>MASec Workshop</u></a> at NeurIPS 2023)</h2><p> Supervisor: <a href="https://www.lewishammond.com/"><u>Lewis Hammond</u></a><br> Participants: <a href="https://www.linkedin.com/in/sam-deverett/"><u>Sam Deverett</u></a> , <a href="http://www.linkedin.com/in/foxabbott"><u>Jack Foxabbott</u></a> , <a href="https://www.linkedin.com/in/kaspar-senft-351696229/"><u>Kaspar Senft</u></a> , <a href="https://www.linkedin.com/in/samuel-dower-128702234/"><u>Sam Dower</u></a></p><p> <strong>Problem:</strong> In the near future, it is likely that sophisticated reinforcement learning agents will co-exist and learn to respond to one another in an increasing number of real-world settings. The reasons for this are: a) recent progress and publicity in AI will drive widespread adoption; b) agents that learn online will have competitive advantages; and c) the more widely agents are deployed, the more likely it is that they will come to interact with one another. With this increased interaction, AI agents may learn to collude, jointly benefitting at the expense of others. If AI systems are given substantial control of economic, military, or political resources, this failure mode could pose an existential risk. In addition, many proposals for creating safer AI systems (such as scalable oversight and adversarial training) are implicitly multi-agent and could fail if the agents learn to collude.</p><p> <strong>Contribution:</strong> We introduce a formal definition of collusion between learning agents in the general setting of partially observable stochastic games. We then discuss an approach for designing mechanisms to reduce collusion – by intervening on different elements of the game – and use it to propose three mechanisms for provably reducing collusion in the iterated prisoner&#39;s dilemma. Finally, we support the theoretical results empirically using independent Q-learning agents. Future work might involve analysing our interventions in more complex games, considering the cost of interventions, and designing other kinds of interventions.</p><hr><h2> Paper 3: Understanding CCS<br> ( <a href="https://arxiv.org/abs/2311.00488"><u>Paper</u></a> accepted to <a href="https://solar-neurips.github.io/"><u>SoLaR Workshop</u></a> at NeurIPS 2023 &amp; independent <a href="https://www.lesswrong.com/posts/zZbM5JdMs5uCtMkgs/robustness-of-contrast-consistent-search-to-adversarial"><u>blog post on LW</u></a> )</h2><p> Supervisor: <a href="https://nandischoots.com/"><u>Nandi Schoots</u></a><br> Participants: Ian Fan, <a href="https://www.linkedin.com/in/hugo-fry-825828271/"><u>Hugo Fry</u></a> , <a href="http://seamusfallows.com/cv"><u>Seamus Fallows</u></a> , <a href="https://www.linkedin.com/in/jamie-wright-72235a202/"><u>Jamie Wright</u></a></p><p> <strong>Problem:</strong> Eliciting latent knowledge from advanced AI systems, even when they might have an incentive to deceive you, <a href="https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/edit#heading=h.w5z4csr27a0t"><u>might be a core problem for developing steerable AI systems.</u></a> Our project investigates an existing method for extracting latent knowledge from current AI systems: Contrast Consistent Search (CCS). This method learns to train a simple probe on the internal activations of models that can detect the truthfulness of an input sentence.</p><p> <strong>Contribution:</strong> In our paper, we provide clarifications on how CCS is able to extract information from the activations of a language model. In particular, we find an alternative loss function that leads to probers that behave similarly to CCS probers, as measured by cosine similarity. The alternative loss function incentivises finding a direction in activation space that minimises the variance of the midpoints of contrast pairs while maximising their displacements. We hope our results can inform work on CCS and future evaluation techniques that aim to make progress in extracting latent knowledge.</p><p> Additionally, in <a href="https://www.lesswrong.com/posts/zZbM5JdMs5uCtMkgs/robustness-of-contrast-consistent-search-to-adversarial"><u>our blog post</u></a> , we find several attacks that corrupt the question-answering abilities of LLMs. In these cases, we find that the model activations are affected such that CCS, although harmed, remains relatively accurate.</p><p> <strong>Limitations:</strong> While our alternative loss function is trained in an unsupervised manner, the loss function includes a hyper-parameter, which is currently determined using a supervised grid search. One of the main advantages of CCS is that it is unsupervised, making progress towards scalable oversight. For our loss function to be truly comparable to CCS (or for our loss function to replace CCS) it is important to determine the hyper-parameter in an unsupervised way. Our results also need to be validated across more datasets and models.</p><hr><h2> Paper 4: Comparing reward formalisms in RL<br> ( <a href="https://arxiv.org/abs/2310.11840"><u>Paper</u></a> under review)</h2><p> Supervisor: <a href="https://scholar.google.com/citations?user=GuzLUmQAAAAJ&amp;hl=en"><u>Joar Skalse</u></a><br> Participants: <a href="https://www.linkedin.com/in/rohan-subramani-70a919225"><u>Rohan Subramani</u></a> , <a href="https://www.linkedin.com/in/marcus-williams-2623681a0/"><u>Marcus Williams</u></a> , <a href="http://www.linkedin.com/in/max-heitmann-224440249"><u>Max Heitmann</u></a> , Halfdan Holm</p><p> <strong>Problem:</strong> To get an AI system to solve a sequential decision-making task, it is necessary first to formalise the goal of that task. In Reinforcement Learning (RL), this is most commonly done using a reward function. It is sometimes presupposed that any interesting task can be formalised as a reward function. However, <a href="https://arxiv.org/abs/2111.00876"><u>recent</u></a> <a href="https://openreview.net/forum?id=Vcvg76ZmcZt"><u>work</u></a> has identified many natural tasks that cannot be adequately captured by a scalar Markov reward function, which suggests that this presupposition is sometimes mistaken. At the same time, there are alternative ways to formalise sequential decision-making tasks, such as temporal logic. In our paper, we catalogue a large number of methods for formalising sequential tasks and compare their expressivity. Our results are relevant to AI alignment in several ways. In particular, most reward learning methods presuppose that the underlying goal can be expressed as a Markov reward. Our results clarify the implicit assumptions behind this design choice and show what other assumptions may be made instead, which decreases the risk of dangerous modelling errors.</p><p> <strong>Contribution:</strong> We consider 17 different RL task formalisms, including Markov rewards, limit-average rewards, linear temporal logic, three different ways of formalising multi-objective RL, and many more. We then give a complete account of when one of these formalisms can express all tasks which can be expressed by a different formalism and use these results to organise all 17 formalisms into a total preorder by expressivity. In so doing, we also collect many intuitive counter-examples of tasks that different formalisms cannot express, which illuminates the restrictions of each formalism.</p><p> <strong>Limitations:</strong> One main limitation of our analysis is that some of our formalisms may require modification in order to be implementable or tractable to optimise, and such modifications may substantially alter the expressivity relations between formalisms. Another limitation is that we consider only when a formalism can express a task exactly rather than identifying if a formalism can express a task approximately. Our results are also primarily informative about systems that are well-modelled as optimised stationary RL policies.</p><hr><h2> Paper 5: The inductive bias of RL-finetuned language models<br> ( <a href="https://arxiv.org/abs/2311.04046">Paper</a> accepted to <a href="https://solar-neurips.github.io/"><u>SoLaR</u></a> Workshop at NeurIPS 2023)</h2><p> Supervisor: <a href="https://www.linkedin.com/in/bogdan-ionut-cirstea-68639b61/"><u>Bogdan-Ionut Cirstea</u></a><br> Participants: <a href="https://openreview.net/profile?id=~Diogo_Cruz1"><u>Diogo Cruz</u></a> , <a href="https://www.linkedin.com/in/edoardo-pona-9b2731160/"><u>Edoardo Pona</u></a> , <a href="https://www.linkedin.com/in/alex-holness-tofts-69838a18b/"><u>Alex Holness-Tofts</u></a> , <a href="https://www.linkedin.com/in/v%C3%ADctor-abia-alonso-8492a31bb/"><u>Victor Abia</u></a> , <a href="https://uk.linkedin.com/in/elias-schmied-01ab92199"><u>Elias Schmied</u></a></p><p> <strong>Problem:</strong> We consider a threat model where RL(HF) fine-tuning leads to deceptive misalignment. Given a pre-trained model, we want to understand what policies RL(HF) is likely to produce - for example, a deceptively misaligned policy or a robustly aligned one. We test the hypothesis that RL fine-tuning leads LLMs to rely more on features which are more extractable in the pre-trained model, making incremental progress towards understanding how future AI systems might generalise their behaviour outside of their training distribution.</p><p> <strong>Contribution:</strong> We perform controlled experiments on synthetic and natural language tasks. We find that, during RL fine-tuning, features that are more extractable by the pre-trained LLM tend to be relied upon more in the resulting policy. Our results parallel similar inductive bias findings for supervised fine-tuning. The relative extractability of target versus spurious features strongly predicts which strategies agents learn: more training evidence is needed to overcome reliance on imperfect heuristics when key features are hard to extract. Overall, our results provide useful insights into the inductive biases of RL fine-tuning.</p><p> <strong>Limitations:</strong> The largest model we used was GPT-2 Large (774 million), and it is not clear how our results would generalise to larger, more capable models. We also tested relatively small RL fine-tuning stages compared to the size of pre-training. If the fine-tuning stage was large, undesirable concepts - like deception or knowledge of the training process - could be (re)learned.</p><br/><br/> <a href="https://www.lesswrong.com/posts/rT6uHEN7ddZAmwbJv/five-projects-from-ai-safety-hub-labs-2023-1#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/rT6uHEN7ddZAmwbJv/five-projects-from-ai-safety-hub-labs-2023-1<guid ispermalink="false"> rT6uHEN7ddZAmwbJv</guid><dc:creator><![CDATA[charlie_griffin]]></dc:creator><pubDate> Wed, 08 Nov 2023 19:19:37 GMT</pubDate> </item><item><title><![CDATA[Can a stupid person become intelligent?]]></title><description><![CDATA[Published on November 8, 2023 7:01 PM GMT<br/><br/><p> I&#39;ve come to a rather uncomfortable self-assessment: I believe I am a stupid person. This isn&#39;t an easy thing to say, especially in a community like LessWrong, where intellect and deep thinking are highly valued. But it&#39;s a sentiment that has been echoing in my head for a while, and it&#39;s time I faced it head-on.</p><p> I&#39;ve done my due diligence, adhering to the healthy lifestyle that&#39;s supposed to bolster brainpower—diet, exercise, a disciplined schedule. I&#39;ve hoped these would somehow kickstart a transformation, but the mental fog remains. When it comes to the raw intellectual horsepower that seems to come so naturally to others, I&#39;m left feeling stranded.</p><p> And what about education? That&#39;s supposed to be the great equalizer, right? Well, in my experience, and judging by numerous critiques I&#39;ve read—including on LessWrong—it doesn&#39;t quite cut it for those of us who feel innately challenged. The current state of education seems more geared toward churning out graduates rather than fostering genuine intellectual growth, especially for those who don&#39;t naturally excel.</p><p> As for intelligence being multifaceted, I understand the arguments. Yet, at its core, there seems to be a singular, critical capacity for understanding, learning, and problem-solving that some people have in spades, and others, like me, seem to lack. It&#39;s this core aspect of intelligence that I&#39;m most concerned with.</p><p> I&#39;ve chased down various methods and interventions in hopes of a breakthrough:</p><p> 1. Nootropics: A temporary bump in concentration didn&#39;t translate into better cognitive abilities.<br><br> 2. Cognitive Behavioral Therapy (CBT): While helpful for managing mental blocks, it didn&#39;t increase my learning capacity as I&#39;d hoped.</p><p> 3. Brain-Computer Interfaces (BCI): Still more of a sci-fi dream than a practical tool for boosting intelligence.</p><p> 4. Educational Software: These keep me engaged, but do they make me smarter? The evidence is thin.</p><p> 5. Physical Health Regimens: My body is healthier, but my brain hasn&#39;t experienced the same growth spurt.</p><p> This quest has been disheartening. The supposed 70% genetic determination of IQ feels like a life sentence for my brain. I see people in high places, wielding power and influence despite what appears to be a lack of the very intellect that&#39;s celebrated here. It suggests that the relationship between intelligence, as we measure it, and success is more complicated than we&#39;d like to admit.</p><p> In my pursuit of intelligence, I&#39;m looking for more than anecdotal success stories or motivational pep talks. I&#39;m seeking substantial, proven methods to increase my cognitive capacity. I am not just looking for ways to cope with or work around my limitations—I want to fundamentally enhance my ability to think, learn, and understand.</p><p> So, to the LessWrong community, I pose these questions: Is there a concrete path for increasing one&#39;s baseline intelligence, especially for someone who feels inherently deficient in this regard? Are there breakthroughs on the horizon that could offer hope? Or perhaps there&#39;s a piece of this puzzle I&#39;m missing—a perspective or a piece of wisdom that could shine a light on a new path forward.</p><p> I&#39;m not reaching out, for a miracle cure, but for a solid step I can take toward becoming a smarter person and i would hate pity answers like &quot;not everyone needs to be smart&quot; etc...</p><br/><br/> <a href="https://www.lesswrong.com/posts/AdKzf7r8RGj4vnWYE/can-a-stupid-person-become-intelligent#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/AdKzf7r8RGj4vnWYE/can-a-stupid-person-become-intelligent<guid ispermalink="false"> AdKzf7r8RGj4vnWYE</guid><dc:creator><![CDATA[A. T.]]></dc:creator><pubDate> Wed, 08 Nov 2023 19:22:58 GMT</pubDate></item></channel></rss>