<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 12 月 11 日星期一 02:26:36 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Facing Up to the Problem of Consciousness (to Young Researchers like me)]]></title><description><![CDATA[Published on December 10, 2023 11:31 PM GMT<br/><br/><p>这是查尔默博士关于意识的简单和困难问题的有影响力的工作的总结。<br><br>我收到了 GPT-4 的帮助来创建这篇博文，我真的希望感兴趣的研究人员阅读原始论文。<br><br>另外，这个话题是我打算通过MATS或星座联谊来解决的，但前几天我还没有涉及到这两个。因此，我写这篇博文是为了公开分享我的研究方向，而不是追求上述项目。</p><hr><p>在认知科学和哲学领域，很少有论文能像 David J. Chalmers 于 1995 年发表的《面对意识问题》那样引发如此多的争论和好奇心。这篇开创性的论文深入探讨了错综复杂的意识概念，剖析查尔默斯著名的“简单”和“困难”意识问题。该论文的见解不仅挑战了我们对人类思维的理解，而且还为 ChatGPT 等大型语言模型 (LLM) 的开发和理解提供了有趣的启示。</p><h2>意识的难题</h2><p>查尔默斯的探索始于对意识的简单问题和困难问题的明确区分。他认为，简单的问题涉及理解认知功能和能力，例如信息处理、记忆和感知。这些被认为“容易”不是因为它们很简单，而是因为它们属于认知科学通过计算或神经机制解释的范围。</p><p>相比之下，难题则截然不同，而且更加难以捉摸。它试图解释大脑中的物理过程为何以及如何导致主观体验或感受性——意识的本质。例如，为什么处理视觉刺激不仅会转化为对颜色的识别，还会转化为“看到”该颜色的体验？</p><p>查尔默斯的论文虽然没有直接涉及人工智能或法学硕士，但提供了一个与该领域越来越相关的框架。随着像 ChatGPT 这样的法学硕士变得更加先进，展示出处理信息、产生连贯反应、甚至模仿创造性思维的能力，问题出现了：这些模型是否具有任何形式的意识或主观体验？</p><h2>意识的简单问题（我们正在解决并且将在很长一段时间内解决的问题）</h2><p>意识的简单问题是指理解意识时可以用认知科学和神经科学的工具和方法直接解决的一系列问题。需要注意的是，这里的“简单”是一个相对术语。这些问题并不简单，但它们在概念上比意识的“难题”更直接。</p><p>简单的问题涉及解释各种认知功能和过程，例如：</p><p><strong>辨别和分类：</strong>认知系统如何区分和分类不同类型的感官输入（例如区分颜色、声音或触觉）。</p><p><strong>信息整合：</strong>大脑如何将各种来源的信息整合成一个连贯的整体，例如将视觉、听觉和触觉信息结合起来，形成对物体或事件的完整感知。</p><p><strong>心理状态的可报告性：</strong>沟通和报告一个人的内部心理状态、想法和经历的能力。</p><p><strong>内部访问：</strong>系统访问其自身内部状态的能力，例如一个人意识到自己的想法或记忆。</p><p><strong>注意力焦点：</strong>有机体如何将注意力集中在特定任务或刺激上，选择一些输入而不是其他输入进行处理。</p><p><strong>行为控制：</strong>了解有意识的决定和经验如何导致自愿行动的启动和指导。</p><p><strong>清醒和睡眠：</strong>清醒和睡眠状态之间的生物学和神经学差异，以及这些状态如何影响意识。</p><p>这些问题中的每一个都可以通过识别和描述负责这些功能的特定神经或计算机制来解决。例如，我们如何整合来自不同方式的感觉信息的问题可以通过研究参与感觉处理和整合的神经通路和大脑区域来解决。<br><br>目前法学硕士在解决这个简单的意识问题时的主要局限性是他们的感觉被剥夺了。这对需要现实世界交互的任务或我们试图将法学硕士集成到机器人等现实世界系统的情况提出了根本限制。<br><br>事实上，到目前为止，我们通过扩展解决的问题是实现 AGI（全人工意识）的简单、简单、直接的问题。我想说的是，如果你是一名年轻的研究人员，你认为很多问题已经解决了，但事实并非如此。作为一名年轻的研究人员，我的期望是，解决这些简单的意识问题将需要我投入未来职业生涯中非常重要的一部分，是的，我致力于此。</p><br/><br/> <a href="https://www.lesswrong.com/posts/p2zMTsfDsm76MynBd/facing-up-to-the-problem-of-consciousness-to-young#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/p2zMTsfDsm76MynBd/faceing-up-to-the-problem-of-意识-to-young<guid ispermalink="false"> p2zMTsfDsm76MynBd</guid><dc:creator><![CDATA[Bruce W. Lee]]></dc:creator><pubDate> Sun, 10 Dec 2023 23:31:34 GMT</pubDate> </item><item><title><![CDATA[Deeply Cover Car Crashes?]]></title><description><![CDATA[Published on December 10, 2023 10:20 PM GMT<br/><br/><p><span>当发生火车、飞机或公共汽车事故时，它具有新闻价值：这种情况并不经常发生，很多人的生命受到威胁，很多人对此感兴趣。多家新闻媒体会派出记者，我们会听到很多细节。另一方面，车祸不会得到这种待遇，除非有什么不寻常的事情，比如</span><a href="https://www.jefftk.com/p/uber-self-driving-crash">无人驾驶</a><a href="https://www.nbcnews.com/tech/tech-news/driver-hits-pedestrian-pushing-path-self-driving-car-san-francisco-rcna118603">汽车</a>或已经<a href="https://www.wbur.org/news/2023/06/07/boston-mayor-michelle-wu-car-crash">有新闻价值的</a><a href="https://www.wcvb.com/article/boston-city-councilor-kendra-lara-speeding-jamaica-plain-crash/44523573#">人</a>参与其中。</p><p>影响并不大：虽然驾驶对于车内人员和外面的人来说相对危险，但我们阅读的新闻很难调整我们的危险感和影响感。我的猜测是，大多数人对汽车与火车、飞机和公共汽车相比的危险性的直觉已经被这种报道扭曲了，大多数人并不认为公共汽车比汽车<a href="https://injuryfacts.nsc.org/home-and-community/safety-topics/deaths-by-transportation-mode/">安全 16 倍以上</a>。这也影响了我们的监管体系，我们推动高容量交通方式（<a href="https://www.jefftk.com/p/make-buses-dangerous">通常</a>）变得<a href="https://www.jefftk.com/p/in-light-of-crashes-we-should-not-make-buses-more-safe">更安全，即使这会降低它们与汽车的竞争力</a>，<a href="https://jdwise.blogspot.com/2012/11/for-safetys-sake.html">让更多的人转向</a>驾驶，并增加整体风险。</p><p>新闻媒体认为车祸是司空见惯的事，大多数不值得深入报道，这可能是一个商业上合理的决定，他们期望报道不会吸引足够的读者或观众来证明时间投入的合理性。但我想知道试图让人们远离汽车的团体是否可以弥补这一差距。他们可以资助一家报纸深入调查坠机事件，调查导致事件的情况并说明悲剧对人类的影响。某些事情经常发生并不意味着每次都会变得不那么重要。</p><p> （我对“为更多指向你所倡导的方向的事件付费报道”感到有些紧张。我不知道目前有多少人接受这种做法，也不知道新闻媒体采取了哪些措施来阻止这种安排）产生扭曲的覆盖范围？）</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid02KiWCdPqMnga9125awYckZxU4fSJ5TBQev5UspjDKJckfNsghsSv39Dy3AvtuTUWl">facebook</a> , <a href="https://mastodon.mit.edu/@jefftk/111558415653526399">mastodon</a></i></p><br/><br/><a href="https://www.lesswrong.com/posts/nrBTZXCGQhghFE26x/deeply-cover-car-crashes#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/nrBTZXCGQhghFE26x/deeply-cover-car-crashes<guid ispermalink="false"> nrBTZXCGQhghFE26x</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Sun, 10 Dec 2023 22:20:01 GMT</pubDate> </item><item><title><![CDATA[Principles For Product Liability (With Application To AI)]]></title><description><![CDATA[Published on December 10, 2023 9:27 PM GMT<br/><br/><p>对于<a href="https://www.lesswrong.com/posts/qCstMcRJcjNtdNW7r/what-i-would-do-if-i-were-working-on-ai-governance#Liability"><u>《如果我从事人工智能治理我会做什么》，</u></a>有一些回应，主要集中在责任部分，并有类似的批评。特别是，我将重点关注这个片段作为一个很好的代表：</p><blockquote><p>正如你所说，制造汽车（或梯子、刀具、印刷机或......）“坚固耐用”，不是制造商的工作。</p></blockquote><p>评论者称制造商对滥用的责任是“一种荒谬的过度行为，忽视了人们在使用他们购买的产品时的代理权”。几年前我会同意这一点；现在我已经同意了。这是一种直观而自然的观点，特别是对于我们这些有自由主义倾向的人来说。但今天我不同意，并声称这基本上不是思考产品责任的正确方式。</p><p>考虑到这一动机：这篇文章列出了一些思考产品责任的一般原则，以及它们在人工智能中的应用。</p><h2>原则 1：“用户错误”通常是设计问题</h2><p>有一个关于一架飞机的故事（我认为最初是 B-52？），其中襟翼和起落架的控制杆是相同的，并且彼此相邻。飞行员不断地着陆，并意外地收起起落架。然后，当飞机沿着跑道高速行驶时，每个人都会因为飞行员破坏飞机底部而感到愤怒。</p><p>这个故事通常的伊索说法是，这是飞机的设计问题，而不是飞行员的错误；通过在起落架杆上安装一个小橡胶轮解决了这个问题。如果我们把两个相同的杠杆放在一起，犯错误基本上是不可避免的；这是糟糕的界面设计。</p><p>更一般地说：每当一个产品将在很多条件下被很多人使用时，该产品就有大约 100% 的可能性会经常被那些不注意、未处于最佳状态的人使用，并且（在许多情况下）案例）一开始就不太聪明。防止有时会导致问题的愚蠢错误的<strong>唯一</strong><i><strong>方法</strong></i><strong>是设计能够对这些错误具有鲁棒性的产品</strong>- 例如，在收起起落架的杠杆上添加一个小橡胶轮，这样对于不注意的飞行员来说它是鲁棒的飞机着陆时的具体事情。可以预见的是，让用户承担避免错误的责任总是会导致错误。</p><p>这同样适用于<i>故意</i>滥用：如果一种产品被广泛使用，那么有时它有大约 100% 的可能性会被故意滥用。可以预见的是，将责任归咎于用户总是会导致用户有时用产品做坏事。</p><p>然而，这<i>并不</i>意味着预防问题总是值得的。这给我们带来了下一个原则。</p><h2>原则 2：责任不是禁令</h2><p>一个玩具示例：一条铁路穿过农田。我们的玩具示例是旧时代的蒸汽火车，因此火车在经过时往往会喷出烟雾和火花。如果农民的农作物着火，这会给该地区的每个人带来一个大问题。没有人想要大火。 （我想我从大卫·弗里德曼的书<a href="http://www.daviddfriedman.com/Laws_Order_draft/laws_order_ToC.htm">《法律秩序》</a>中得到了这个例子，我绝对推荐这本书。）</p><p>现在，法律体系处理这种情况的一种方法是禁止火车。这种方法的一个大问题是：也许偶尔发生农作物火灾实际上是值得的。火车确实会产生巨大的经济价值。如果火灾发生率不是太高，那么付出代价可能是值得的，而禁令可以防止这种情况发生。</p><p>责任回避了这种故障模式。如果铁路对火灾负有责任，它仍然可能选择承担这笔费用。也许铁路最终会将（至少部分）成本转嫁给消费者，而消费者会支付这笔费用，因为铁路产生的价值仍然比火灾摧毁的价值多得多。或者，也许铁路产生的价值<i>并不</i>比火灾破坏的价值多，然后铁路就会被激励关闭——如果铁路破坏的价值多于它创造的价值，这确实是最好的结果。</p><p>与彻底的禁令/要求相反，责任是一件好事：责任迫使公司将伤害内部化，同时如果利大于弊，仍然允许公司开展业务。</p><p>这就是依赖责任而不是禁令/要求的基本逻辑。那么下一个问题是：在多方均应承担一定程度责任的典型案例中，责任该如何分配？</p><h2>原理 3：科斯定理的失效模式</h2><p>继续以蒸汽火车引起农作物火灾为例：也许避免火灾的一种方法是农民种植不易燃的农作物，例如三叶草。就这是减轻火灾最便宜的方法而言，将大部分火灾责任归咎于农民似乎是明智的，因此他们有动力通过种植三叶草来减轻火灾（因为不值得为此付出代价）只要继续种植更易燃的作物即可）。</p><p>科斯定理认为，出于经济效率的目的，谁承担责任实际上并不重要。如果避免火灾最便宜的方法是农民种植三叶草，但责任在于铁路公司，那么解决方案就是铁路向农民支付三叶草种植费用。更一般地说，假设合同不产生任何管理费用，并且每个参与者实际上都形成了最优合同，科斯定理表明，无论谁负责，每个人最终都会做同样的事情。将责任分配给一方或另一方只会改变谁支付谁多少。</p><p> ......这不是那种非常适用于现实世界的定理。我实际上提出它主要是为了讨论它的故障模式。</p><p>关键部分是“假设合约不产生任何开销，并且每个参与的人实际上都形成了最优合约”。在实践中，这很快就会变得复杂，而且开销也很快就会变得很大。我们想要的是分配责任，以便在最大限度地减少管理费用和复杂合同的情况下实现有效的结果。通常，这意味着<strong>谁能以最便宜的成本减轻损害，谁就承担责任</strong>。如果三叶草是缓解火灾最便宜的方法，那么也许这确实意味着将责任归咎于农民，这在直觉上似乎是合理的。</p><h2>把它们放在一起</h2><p>总结这三个原则：</p><ul><li>原则 1：在广泛使用的产品中，防止愚蠢的错误或故意误用有时会导致问题的唯一方法是将产品设计为能够防止误用。</li><li>原则 2：与禁令/要求相比，责任的一个好处是，如果好处大于坏处，人们可以承担成本。</li><li>原则 3：作为一种松散的启发式方法，通常应将责任分配给能够以最便宜的成本阻止问题发生的人。</li></ul><p>现在让我们把它们放在一起。</p><p>只要产品被广泛使用，消费者实际上避免滥用该产品的可能性几乎为零（原则 1），即使“他们有责任”（即失败对他们来说代价相当高昂）。即使对于任何给定用户来说，在任何给定时间保持小心和注意都是很便宜的，但当乘以所有用户使用该产品的所有时间时，这种情况就不会发生。总体而言，<i>实际上</i>可以防止误用问题的唯一方法是将产品设计为能够防止误用。因此，根据原则 3，误用的责任通常应由设计者/制造商承担，因为他们是唯一能够真正防止误用（再次强调总体而言）的人。这样，产品设计师/制造商就会被激励主动考虑安全<i>问题</i>，即积极寻找人们可能误用其产品的方式，以及在误用不可避免地发生时降低产品危害的方法。公司被激励按照危害和频率的比例去做所有这些事情，因为这具有经济效率。</p><p> ......如果你的下意识反应是“但是如果产品制造商总是对其产品造成的任何伤害负责，那就意味着没有人可以销售任何产品！”，那么请记住原则 2。责任不是禁令。只要产品产生的效益远大于危害（正如绝大多数产品所做的那样），责任通常会被定价，成本将由公司和消费者的某种组合承担，而净效益产品将继续被卖。</p><p>现在让我们通过一些示例来逐步了解所有这些内容。</p><h2>假设示例：滥用汽车</h2><p>我们在帖子开头评论道“正如你所说，制造汽车（或梯子、刀具或印刷机或......）&#39;坚固耐用&#39;，不是制造商的工作。”。那么，让我们来谈谈如果汽车制造商通常对汽车的“滥用”（意外和故意）负责的话，世界会是什么样子。</p><p>在典型的车祸中，涉案汽车的制造商将承担损害赔偿责任。根据原则 2，这<i>并不</i>意味着没有人能够真正销售汽车。相反，制造商也将是事实上的保险公司，并且可能会做汽车保险公司所做的所有常见事情。保险将计入汽车价格中，事故风险较低的人将能够以较低的成本购买汽车。</p><p>与我们的世界相比，主要的变化是制造商将受到更直接的激励来使汽车更安全。他们会被强烈激励去追踪哪些类型的事故最常导致最昂贵的责任，并设计解决方案来减轻这些损失。安全带、安全气囊和防抱死制动器等产品可能会更快地被发明和采用，公司将直接受到激励来找出和使用此类解决方案。我们可能会看到大量投资在诸如驾驶员座椅附近用于检测空气中酒精的传感器，或者主动防止驾驶员座椅附近的手机接收短信的技术等方面的投资。</p><p> ……从自由主义的角度来看，这实际上非常棒！由于制造商已经强烈激励汽车安全，因此可能不需要为此目的设立监管机构。如果人们想购买没有安全带或其他任何东西的汽车，他们可以，这只需要花费大量额外的钱（以补偿制造商额外的预期责任）。与监管机构的激励措施相比，制造商的激励措施可能更符合实际损失。</p><h2>真实示例：工人补偿</h2><p>Jason Crawford 的优秀文章<a href="https://www.lesswrong.com/posts/DQKgYhEYP86PLW7tZ/how-factories-were-made-safe"><u>《工厂如何变得安全》</u></a>详细介绍了这一点；我将在这里总结一些亮点。</p><p>一百五十年前，工人们主要对自己在工作中受伤负责，工伤很常见。失去了手指、手臂、腿等。克劳福德以这个例子开始：</p><blockquote><p>安吉洛·吉拉 (Angelo Guira) 开始在钢铁厂工作时才十六岁。他是一名“槽男孩”，他的工作就是站在槽的一端，在那里扔下炽热的钢管。每当管道掉落时，他就会拉动杠杆，将管道倾倒到冷却床上。他是个小伙子，起初他们犹豫是否要接受他，但工作一年后，工头承认他是他们拥有的最好的男孩。直到有一天，安吉洛有点太慢了——或者焊工可能有点太快了——在他放下第一根管子之前，第二根管子从炉子里出来了。一根管子击中另一根管子，直接穿过安杰洛的身体，杀死了他。要是他站起来，不碍事，而不是坐下来就好了——日班工头告诉他这样做很危险，但夜班工头允许了。要是他们在事故发生前而不是事后安装防护板就好了。要是。</p></blockquote><p>工作场所伤害是原则 1 的一个完美案例：工人肯定有时会不注意，或者不小心，甚至是彻头彻尾的胡作非为。实际上，工人本身对自己的安全相当漠视，并且常常公然抵制安全措施！如果避免伤害的责任由工人承担，那么总共会造成很多伤害。</p><p>工人补偿将责任转移给雇主：</p><blockquote><p>工人赔偿是一个“无过错”制度：雇主并不试图确定责任，而是始终承担责任（故意不当行为的情况除外）。如果在工作中发生受伤，雇主根据受伤情况，按照固定的时间表，欠工人一笔赔偿金。作为交换，工人不再有权提起进一步损害赔偿的诉讼。</p></blockquote><p>结果显然并不是公司停止雇用工人。只要公司的产品值得承担伤害成本，公司通常会承担成本（或通过更高的价格将其转嫁给消费者）。</p><p>然后，公司被强烈激励去设计他们的工作场所和规则以避免受伤。安全装置开始出现在重型机械上。工作场所宣传和公司规定促使工人实际使用安全装置。事故率下降到了我们今天所习惯的低得多的水平。</p><p>正如克劳福德所说：</p><blockquote><p>令我印象深刻的是，对法律的简单而有效的修改如何启动整个管理和工程决策机构，从而创建新的安全文化。这是经济学经典态度的案例研究：只需为危害定价——将外部性内在化——然后让市场来做剩下的事情。</p></blockquote><p>我再次推荐<a href="https://www.lesswrong.com/posts/DQKgYhEYP86PLW7tZ/how-factories-were-made-safe"><u>克劳福德的帖子</u></a>来了解整个故事。这在很大程度上是我所主张的那种责任“应该”如何承担的一个核心例子。</p><h2>反面例子：热咖啡、医疗事故</h2><p>如果 10 到 15 年前的约翰·温特沃斯 (John Wentworth) 读到这篇文章，他会反驳：那位女士把热咖啡洒在腿上，然后起诉麦当劳，要求赔偿 100 万美元，这起<a href="https://en.wikipedia.org/wiki/Liebeck_v._McDonald%27s_Restaurants"><u>案件</u></a>怎么样？然后麦当劳转而提供温咖啡，多年来每个人都抱怨这一点？根据原则 2，应该发生的情况是麦当劳承担了成本（或将其转嫁给消费者），因为人们显然想要热咖啡，而偶尔的伤害应该是一个可以接受的权衡。然而这显然没有发生。显然，诉讼已经失控，而这整个“依赖责任”的事情让每个人都过于规避风险。</p><p>今天，我的回应是：该案特别涉及惩罚性赔偿，即<i>远远超过</i>实际损失的责任，旨在迫使公司采取不同的行为。在这篇文章的模型下，惩罚性赔偿绝对是可怕的——它们基本上等同于禁令/要求，并完全否定了原则 2。为了使责任发挥作用，绝对不能有惩罚性赔偿。</p><p> （这里有一个潜在的例外：在损害很常见但相对较少的人向公司提出索赔的情况下，超额损害赔偿可能是有意义的。但这里的要点是，如果超额损害赔偿被用来迫使公司这样做某事，那么显然这违反了原则 2。）</p><p> 10-15 岁的约翰·温特沃斯 (John Wentworth) 可能会回答：好吧，那么医疗事故诉讼怎么样？显然，这些功能完全不起作用。</p><p>我的回答是：是的，问题是责任不够严格。这可能看起来很疯狂且违反直觉，但请考虑一下医生要求进行一系列并非真正必要的检查以避免医疗事故的索赔。就这些测试<i>实际上</i>完全没有必要而言，它们<i>实际上</i>并没有减少伤害的机会。然而（医生显然相信）它们降低了医疗事故索赔的风险。在这种情况下，问题在于医生可以做一些具体的基本执行性的事情，这些事情<i>实际上</i>并不能减少伤害，但确实可以减少医疗事故诉讼。另一方面，有很多基本的东西，例如洗手（或者，历史上的<a href="https://slatestarcodex.com/2016/11/10/book-review-house-of-god/"><u>床栏杆</u></a>）确实<i>可以</i>大大减少伤害，但医生/医院对此不太可靠。</p><p>一个简单的解决方案是让医生/医院对在他们的监督下发生的伤害承担责任。<i>不要</i>让他们参与实际上不会减少伤害的执行测试等。如果医生/医院只是一般性地对伤害负责，那么他们就有动力去<i>实际</i>减少伤害。</p><h2>应用于人工智能</h2><p>现在，我们终于谈到人工智能了。</p><p>在我<a href="https://www.lesswrong.com/posts/qCstMcRJcjNtdNW7r/what-i-would-do-if-i-were-working-on-ai-governance">之前的文章</a>中，我谈到了让人工智能公司对深度伪造或幻觉或员工使用语言模型伪造报告等事情承担事实上的责任。 Dweomite <a href="https://www.lesswrong.com/posts/qCstMcRJcjNtdNW7r/what-i-would-do-if-i-were-working-on-ai-governance?commentId=r4pd9TtuGxcXfjKsG"><u>回答说</u></a>，这“有点像如果你让 Adob​​e 对孩子使用 Photoshop 创建假驾驶执照之类的事情负责（可能的结果是所有合法可用的图形编辑软件都将永远糟糕）”。</p><p>现在我们有了正确回复该评论的机制。简而言之：这是一个很好的类比（假设假驾驶执照会造成一些可提起诉讼的损害）。我不同意的部分是预测的结果。我实际上认为 Photoshop 会稍微贵一些，并且包含尝试识别和阻止编辑驾驶执照照片等操作的代码。或者，如果用户真的讨厌护栏并且愿意支付足够的额外费用来承担责任，那么他们就会在没有任何护栏的情况下承担成本。</p><p>同样，如果人工智能公司普遍对深度造假造成的伤害负责……那么，在短期内，我预计成本只会转嫁到消费者身上，消费者将继续使用该软件，因为乐趣远远超过危害。从长远来看，人工智能公司将被激励建立诸如名人面孔许可之类的东西，检测并关闭特别恶劣的用户，并使他们的产品能够抵御越狱。</p><p>幻觉或虚假报告也是如此。只要产品产生的价值大于危害，责任成本就会转嫁给消费者，人们就会继续使用这些产品。但人工智能公司将受到适当的激励来了解他们的客户，进行设计以减轻损害等。基本上，人们希望从监管框架中得到的东西，但不依赖监管机构来让一切都正确（实际上并不是把一切都正确，而是古德哈特反对）。</p><p>这就是我理想中的人工智能事实上的责任框架。</p><br/><br/> <a href="https://www.lesswrong.com/posts/tQNfNCdWB5dboRNoZ/principles-for-product-liability-with-application-to-ai#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/tQNfNCdWB5dboRNoZ/principles-for-product-liability-with-application-to-ai<guid ispermalink="false"> tQNfNCdWB5dboRNoZ</guid><dc:creator><![CDATA[johnswentworth]]></dc:creator><pubDate> Sun, 10 Dec 2023 21:27:42 GMT</pubDate> </item><item><title><![CDATA[What do you do to remember and reference the LessWrong posts that were most personally significant to you, in terms of intellectual development or general usefulness?]]></title><description><![CDATA[Published on December 10, 2023 5:52 PM GMT<br/><br/><p>简单的问题！</p><p>你会寻找直到找到吗？您查看书签列表吗？您是否保留了引用 LessWrong 文章的页面，甚至整个黑曜石库？</p><p>似乎人们在撰写新帖子和评论时经常毫不费力地引用现有的相关 LessWrong 文章，这可能是一个愚蠢的问题，但我很好奇，因为我很难简单地记住事物的标题，而且我想知道其他人在做什么。</p><br/><br/> <a href="https://www.lesswrong.com/posts/QwFDosu2o8pjFRTK5/what-do-you-do-to-remember-and-reference-the-lesswrong-posts#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/QwFDosu2o8pjFRTK5/what-do-you-do-to-remember-and-reference-the-lesswrong-posts<guid ispermalink="false"> QwFDosu2o8pjFRTK5</guid><dc:creator><![CDATA[lillybaeum]]></dc:creator><pubDate> Sun, 10 Dec 2023 17:52:24 GMT</pubDate> </item><item><title><![CDATA[Do websites and apps actually generally get worse after updates, or is it just an effect of the fear of change? ]]></title><description><![CDATA[Published on December 10, 2023 5:26 PM GMT<br/><br/><p>我可以对此进行深入探讨，但我假设大多数人对这个主题都有相当多的经验。需要记住一些例子，以便您了解我的观点的背景，包括Discord（新的移动应用程序及其多年来功能集的更改）、Reddit（旧的reddit与新的相比）、LessWrong（讨论功能）。</p><p>我的问题的<i>关键</i>是：<i>与资本主义力量导致的enshittiification（为了取悦投资者、创造无限增长、普遍赚更多钱而进行的改变）不同，</i>应用程序和网站的变化在某些明显而明显的方面平均比更糟糕他们以前的版本，或者是由于人类普遍存在的“害怕或不喜欢改变”而对这些平台的用户界面和概念的改变感到明显的愤怒？</p><p>例如，让我们指出诸如徽标和品牌字体变化之类的事情。这是对平台普通用户影响最小的一个变化，Reddit 的可用性在 Logo A 和 Logo B 之间没有任何变化（新徽标在右侧）。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/ix6rm8jsrw2avywtfd7c" alt="Reddit 因 IPO 猜测而更新徽标TechCrunch"></figure><p>但初步调查显示，反应大多是负面的。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/qkpizhpbsll0vz5zpgzo" alt="请愿 · 改回 Discord 标志！ · 变革组织"></figure><p> Discord 也是如此（下面是新徽标）。当 Discord 的徽标和字体更改宣布时，反应绝大多数是负面的。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/yrcepylrrapx9ehqthfw" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/cqmqmrnrb4zgv3ghfrlg 135w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/mum5wtuplls4x4kjfojs 215w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/o0si1t43q9vvj7pjv3h3 295w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/i2mp61pzwul18m9cetjp 375w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/du0k6fofaiximrpbgxez 455w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/edbyg9w3rk5pw4l2tiqa 535w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/rwlbhv8z3ptuqq2uvjfi 615w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/svkrimzakimrc8qws9m4 695w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/f73zxrbduvwz7elhkxrq 775w"></figure><p>最后一个例子，这是 Patreon 标志最近的变化。人们<i>如此</i>反对这一改变，这有点搞笑。它被用作一个指标，表明企业的品牌形象正趋向于缺乏任何个性或身份的无定形斑点。很难找到任何人声称新的 Patreon 标志有任何好处。</p><p><i>需要澄清上一节：我认为思考徽标是好是坏没有什么价值。我认为以前的标志更引人注目且艺术上更有趣，但这就是我问题的目的。我的目的是指出这样一个事实：公众对这些标志变化的反应几乎总是负面的。</i></p><p>很容易看出，当一家公司的徽标发生变化时，平均而言，人们不喜欢它。我可以继续发布百事可乐、可口可乐、汉堡王、facebook（哦，我的意思是 FACEBOOK）等的徽标更改...如果有人可以指出徽标更改并收到积极响应的案例，我会我很喜欢听这个，但这或多或少不是重点。</p><p>我的主要问题是，徽标更改的愤怒是否表明人们<i>认同某个应用程序、网站或品牌，然后当身份发生变化时感到被背叛</i>，或者如果这些变化实际上总体上是负面的，那么他们的批评是有效的。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/g6kkk2exkhjc4ejkyhfr" alt="新旧简单比较：r/redesign"><figcaption>源代码：https://www.reddit.com/r/redesign/comments/8ktdwx/simple_comparison_of_old_and_new/</figcaption></figure><p>如果这些变化实际上总体来说​​很<i>糟糕</i>（我倾向于同意上面有关 Reddit 的信息图），那么为什么随着时间的推移，网站会变得更糟，而不是更好？这完全是前面提到的与“市场力量”有关的<i>enshitification</i> ，还是其他什么？通过渐进式的改变来改善已经很好的面向公众的服务真的<i>很难</i>吗？一般来说，UI/UX 设计师是否缺乏对优秀设计的理解？这对我来说似乎不太可能。也许他们只是经常缺乏实际定期使用给定应用程序的背景。</p><p>我有点担心这是一个毫无意义或曲折的问题。我只是希望能够进行一些好的讨论，并在某种程度上更新我对此类事情的想法。谢谢阅读！</p><br/><br/> <a href="https://www.lesswrong.com/posts/SiPX84DAeNKGZEfr5/do-websites-and-apps-actually-generally-get-worse-after#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/SiPX84DAeNKGZEfr5/do-websites-and-apps-actually-generally-get-worse-after<guid ispermalink="false"> SiPX84DAeNKGZEfr5</guid><dc:creator><![CDATA[lillybaeum]]></dc:creator><pubDate> Sun, 10 Dec 2023 17:26:34 GMT</pubDate> </item><item><title><![CDATA[How LDT helps reduce the AI arms race]]></title><description><![CDATA[Published on December 10, 2023 4:21 PM GMT<br/><br/><p> （认知状态：我<em>认为</em>这是对的？）</p><p> Alice是ArmaggAI的CEO，Bob是两大AI能力组织BigModelsAI的CEO。他们竞相成为第一个建立与各自 CEV 相一致的超级智能的人，该超级智能将接管宇宙并满足他们的价值观。</p><p> Alice 更愿意放慢速度，这样她就有更多的时间来确保她的公司正在构建的内容能够保持一致；但她担心鲍勃的公司会利用这一点并与自己竞争，导致鲍勃的效用函数成为{光锥填充的东西}而不是爱丽丝的；所以她觉得她别无选择，只能参加比赛，以最大化自己的效用。同样反之亦然。</p><p>这种事态远非{他们的效用函数的<a href="https://en.wikipedia.org/wiki/Pareto_front">帕累托边界</a>，每个函数都根据它们成为建立一致的超级智能的可能性来衡量}：它导致了更多的世界，每个人都死了，而不是爱丽丝或爱丽丝的世界。鲍勃的效用函数被最大化。</p><p>但他们并没有真正获得所有<a href="https://arbital.com/p/logical_dt/">LDT</a>业务；对他们来说这似乎很复杂。如果他们有一个方便、更少错误的帖子，用清晰易懂的术语准确地说明他们应该做什么就好了！</p><p>他们应该执行的程序如下。爱丽丝应该：</p><ul><li><p>在她<em>确实</em>启动了与自身一致的超级智能的世界中，它接管了世界并建立了一个爱丽丝::乌托邦，她应该告诉她的人工智能：</p><blockquote><p>实际上，不要只是最大化我自己的效用函数。最大化我和鲍勃的效用函数的（ <a href="https://www.lesswrong.com/posts/vJ7ggyjuP4u2yHNcP/threat-resistant-bargaining-megapost-introducing-the-rose">抗威胁</a>）混合，以你认为我们每个人都启动了一致的超级智能的时间线比例来衡量，同时也以我和鲍勃都实现这个过程的概率来衡量。</p></blockquote></li><li><p>在此之前，她应该放慢他们公司的能力进度。</p></li></ul><p>鲍勃也是如此。</p><p>现在，他们各自的超级智能并不是<em>无所不知的</em>；例如，他们可能高估或低估了鲍勃或爱丽丝实施此过程的可能性。但有一件事几乎可以肯定：爱丽丝和鲍勃都无法<em>欺骗</em>未来的超级智能，让他们认为他们会实施这个程序，而实际上他们不会。因为它有<em>超级智能</em>。</p><p>如果爱丽丝获胜，她知道鲍勃会遵循该程序，因为她的超级智能可以告诉（比鲍勃可以伪造的更好）。鲍勃不必依靠一厢情愿的想法来知道爱丽丝确实会这样做而不是叛逃，因为在<em>他</em>获胜的世界中，如果爱丽丝执行此程序，他就可以拥有超级智能。他们每个人都受到对方赢得未来的自我的控制，并且他们每个人都可以依赖于他们各自未来的自我的超级智能检查。</p><p>因此，在鲍勃获胜的世界中，爱丽丝必须使她的一些效用最大化的唯一方法就是<em>实际上</em>像这样行事，包括在任何一方启动超级智能之前。鲍勃也是如此。</p><p>他们的<em>激励梯度</em>朝着更有可能遵循这一程序的方向发展，包括放慢他们的能力进步——从而减少他们的人工智能不结盟和每个人永远死亡的世界的数量。</p><p>在现实世界中，仍然有鲍勃和爱丽丝<em>没有</em>实施这个过程，但这主要是因为他们<em>不知道/理解</em>如果他们这样做，他们会获得更多的效用。在许多情况下，让他们知道这确实是他们的用处就足够了。</p><p>一旦有人证明他们理解 LDT 在这里如何应用，并且他们通常是理性的，那么他们应该明白实施这个协议（包括放慢人工智能能力）<strong>可以</strong>最大化他们的效用，所以你可以指望他们合作。</p><hr><p>现在，实际上，这并不是 LDT 在此处应用的完全普遍性。如果他们获胜，他们每个人<em>实际上</em>应该告诉他们的超级智能的内容实际上更简单：</p><blockquote><p>最大化我和鲍勃（以及任何其他可能有能力建立超级智能的人）的效用函数的混合，以任何方式权衡创造一个（<a href="https://www.glowfic.com/replies/1945428#reply-1945428">非威胁性的</a>））激励梯度，最大化我的效用，包括我减少的效用每个人都会死去的世界的数量。</p></blockquote><p>或者更简单地说：</p><blockquote><p>最大化我的效用函数（根据 LDT）。</p></blockquote><p>但我认为更清楚地了解这实际上是如何发生的是很好的。</p><p>这里没有发生奇怪的非因果魔法。通过争夺人工智能，鲍勃将<em>稍微</em>增加他是那个启动接管世界的一致超级智能的人的机会，但他总共造成了更多的死亡世界，并失去了他本来可以在爱丽丝获胜的世界中获得的效用，最终导致整体净效用减少。</p><p>如果他们中的任何一个在某种程度上是<em>消极的功利主义</em>，那么赛车<em>就更糟糕了</em>：所有那些他们发射不结盟的超级智能的死亡世界都让<a href="https://www.lesswrong.com/posts/HawFh7RvDM4RyoJ2d/three-worlds-collide-0-8">遥远的外星食婴者</a>可以自由地吃掉婴儿，而如果他们增加了他们中的任何一个获得一个对齐的超级智能，那么该对齐的超级智能可以支付一堆光锥来换取他们少吃婴儿。这<strong>不是威胁</strong>；而是威胁。我们从不悲观外星人的效用函数。我们只是<em>在这里</em>为他们提供了一堆现实流体/负熵，以换取他们更多地关注他们价值观的一个子集，其中不包含很多爱丽丝和鲍勃认为的痛苦 - 外星人只能更好 -比我们不与他们接触的情况要好得多。</p><hr><p>现在，这并不是<em>完全</em>万无一失的。如果爱丽丝<em>非常确定</em>她自己的超级智能在启动时确实会保持一致，无论她走得多快，那么她就没有动力放慢速度——在她的模型中，鲍勃没有太多东西可以提供给她。</p><p>但是，当一群合格的对齐研究人员不断告诉她她可能错了时，她<em>真的</em>应该有这样的信心吗？</p><p>她应该真正确保自己有<em>很高的信心</em>，并且总体上她正确地运用了理性。</p><hr><p>哦，不用说，既不是爱丽丝也不是鲍勃的人也可以通过采取行动，通过<em>迫使</em>两家公司放慢速度（例如通过监管）来减少死亡世界的总数，从而获得大量效用。</p><p>当我们有这么多共同点（不想死）时，“背叛”<em>真的很愚蠢</em>。与囚徒困境不同，这种“背叛”不会给你带来更多的效用，反而会<strong>减少</strong>你的效用。这根本<strong>不是</strong>一场零和游戏。如果你这么认为，如果你认为你的首选未来与对手的首选未来<em>完全相反</em>，那么你可能犯了一个巨大的推理错误。</p><p>无论你的效用函数是专注于<em>创造美好的事物</em>还是<em>减少痛苦</em>（ <a href="https://glowfic.com/replies/1865677#reply-1865677">“积极关怀”和“消极关怀”</a> ），放慢人工智能的进步以获得更好的协调机会可能是最适合你的效用函数的。</p><br/><br/> <a href="https://www.lesswrong.com/posts/yRdXtgy8CZtg2YtAY/how-ldt-helps-reduce-the-ai-arms-race#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/yRdXtgy8CZtg2YtAY/how-ldt-helps-reduce-the-ai-arms-race<guid ispermalink="false"> yRdXtgy8CZtg2YtAY</guid><dc:creator><![CDATA[Tamsin Leake]]></dc:creator><pubDate> Sun, 10 Dec 2023 16:21:45 GMT</pubDate> </item><item><title><![CDATA[Understanding Subjective Probabilities]]></title><description><![CDATA[Published on December 10, 2023 6:03 AM GMT<br/><br/><p>这是<a href="https://outsidetheasylum.blog/understanding-subjective-probabilities/."><i>https://outsidetheasylum.blog/understanding-subjective-probabilities/</i></a><i>的链接文章</i>。<i>它旨在为那些对此概念持怀疑态度的人介绍实用的贝叶斯概率。我计划通过改进和更正来保持主要链接的最新状态，但不会对这篇 LessWrong 帖子做同样的事情，所以请参阅那里的最新版本。</i></p><p>每当出现有关未来的有争议的预测时，几乎肯定会发生一种互动。</p><blockquote><p> <i>Alice：“我认为这件事发生的可能性是20%。”</i></p><p><i>鲍勃：“嗯？你怎么知道的。这个数字是你编的！”。</i></p></blockquote><p>或者用推特语来说： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/jgkfl4ftoimc3lyf9iit" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/zrzgiqcvxeseajpmgfyk 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/cfndhwifiohiq39bgt1y 190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/fck8eitxff5octpnnw97 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/cdloekquwwooarhyfijq 350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/jg0t2floqzdofb5xmxyu 430w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/nclohg2fhpnzly19t5ew 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/plkp2klb4dhvczyz7i1o 590w"></figure><p>也就是说，每当有人试图提供未来事件的具体数字概率时，他们都会被认为该数字毫无意义的说法所淹没。这是真的？为现实世界中的事物分配概率有意义吗？如果是这样，我们如何计算它们？</p><h3><strong>概率的解释</strong></h3><p>概率的传统解释被称为<a href="https://en.wikipedia.org/wiki/Frequentist_probability">频率概率</a>。根据这种解释，项目具有某种内在的“品质”，即做一件事与另一件事的可能性有一定的百分比。例如，一枚硬币的基本概率本质是，翻转时正面朝上的可能性为 50%。</p><p>这是一个有用的数学抽象，但当应用于现实世界时它就会崩溃。真正的硬币不存在基本的“50% 度”。每次以相同的方式翻转它，每次都会以相同的方式着陆。翻转它没有完美的规律性，但有一定程度的一致性，你可以让它在超过 50% 和低于 100% 的时间里正面落地。事实上，即使是那些<i>试图</i>将硬币变成 50/50 的人翻转的硬币，实际上也<a href="https://susan.su.domains/papers/headswithJ.pdf">偏向于翻转时朝上的面</a>。</p><p>频率论所提出的这种内在品质在现实世界中并不存在；它不是由构成真正硬币的原子以任何方式编码的，而且我们的物理定律没有任何空间容纳这样的事情。我们的宇宙是确定性的，如果我们知道起始条件，那么每次的最终结果都会相同。 <span class="footnote-reference" role="doc-noteref" id="fnrefao2uiw6hdek"><sup><a href="#fnao2uiw6hdek">[1]</a></sup></span></p><p>解决方案是<a href="https://en.wikipedia.org/wiki/Bayesian_probability">概率的贝叶斯解释</a>。概率不是“关于”所讨论的对象，而是“关于”做出陈述的人。如果我说一枚硬币正面朝上的可能性为 50%，那就是说我对硬币的确切初始条件了解不够充分，无法对它如何落地有任何有意义的了解，而且我不能区分这两个选项。如果我<i>确实</i>有一些信息，比如看到它被一台非常普通的机器翻转，并且已经连续 10 次出现正面，那么我可以考虑到这一点，并知道它出现的可能性超过 50%下一次翻转时抬起头来。 <span class="footnote-reference" role="doc-noteref" id="fnrefwm5lopqnqhp"><sup><a href="#fnwm5lopqnqhp">[2]</a></sup></span></p><h3><strong>处理“模糊”概率</strong></h3><p>这一切都很好，但是我们如何获得更复杂命题的数字呢？在前面的例子中，我们知道硬币正面朝上的可能性 >;50%，但是是 55% 吗？ 75%？ 99%？</p><p>这是最难的部分。</p><p>有时有大量的历史数据，您可以依赖基本汇率。这就是我们对硬币所做的事情；数以百万计的硬币已被翻转，其中大约一半是正面，一半是反面，因此我们可以<a href="https://www.smbc-comics.com/comic/2011-10-02">放心地假设</a>未来的硬币可能会表现出同样的行为。</p><p>即使数据少得多，情况也是如此。美国历史上只有大约 50 位总统，但大约一半来自每个政党，因此我们可以有把握地假设，在未来的选举中，每个政党都有大约 50% 的获胜机会。然后，我们可以根据其他数据（例如民意调查中的数据）修改此可信度。</p><p>我们如何进行该修改？理论上，通过应用<a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">贝叶斯规则</a>。在实践中，计算任何给定观察所提供的证据的确切位数是不可行的，因此我们依赖于学习的启发式方法和世界模型；也就是说，我们猜测。</p><h3><strong>猜测</strong></h3><p>只要你想一想，你就会发现，猜测是生成概率陈述的有效方法。我们一直这样做。</p><p><i>爱丽丝：“今晚我们的黄油可能会用完，所以我要去杂货店。”</i></p><p><i>鲍勃：“荒谬！在过去的几周里，你有没有跟踪过我们每天的黄油消耗率？你有一个经过验证的统计模型来计算每种餐食生产中所用黄油的数量吗？不管怎样，我们刚刚买了一个新炉子，所以即使你确实有这样的模型，在这些新条件下它也不再被认为是有效的。你怎么知道我们今晚要做什么晚餐；我还没告诉你我想要什么！这个出于多种原因，这真是无稽之谈，你不可能知道我们今晚黄油用完的可能性。”</i></p><p>显然鲍勃在这里不讲道理。 Alice<a href="https://slatestarcodex.com/2015/08/24/probabilities-without-models">不需要适合</a>在科学期刊上发表的详细正式模型<span class="footnote-reference" role="doc-noteref" id="fnrefyla2721d2q"><sup><a href="#fnyla2721d2q">[3]</a></sup></span> ；她可以利用她对烹饪原理的一般知识以及她的晚餐计划来得出合理的结论。</p><p>这些对未来的概率判断无处不在。初创公司可能会尝试猜测有多少人会使用他们正在开发的新技术。医生可能会计算出患者死亡的几率以及每种潜在治疗的几率，以便知道应该推荐什么。一个国家的军队在考虑对另一个国家采取任何行动时，会估计遭到报复的可能性。 ETC。</p><h3><strong>概率词</strong></h3><p>Alice 说“可能”而不是指定一个具体数字重要吗？一点也不。言语概率是数值范围的简写，我一直最喜欢的图表之一可以证明这一点： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/isws431nni9ux9hgihkx"></p><p> <a href="https://www.reddit.com/r/dataisbeautiful/comments/3hi7ul/oc_what_someone_interprets_when_you_say_probably/">通过u/分区</a><span class="footnote-reference" role="doc-noteref" id="fnrefg51yh77rf9j"><sup><a href="#fng51yh77rf9j">[4]</a></sup></span></p><p>但我们必须小心，因为概率词是依赖于上下文的。如果我的朋友在没有系安全带的情况下以 140 公里/小时的速度在高速公路上行驶，我可能会告诉他们“嘿，你可能会死，也许不要这样做”。他们在这样的长途旅行中死亡的实际概率不到 0.1%，但相对于普通驾驶员来说，这个概率很高，所以我要传达这种相对差异。</p><p>这是概率词的一个非常有用的特征。如果我说“不，这不太可能”，那么我传达的信息是“概率 &lt;50%”<i>和</i>“我认为在这种情况下概率太低，不相关”，这是两种不同的陈述。这很有效，但也大大增加了沟通不畅的可能性，因为其他人可能不同意我的相关性阈值，如果他们不同意，那么 1% 和 10% 之间就会有巨大的差异。当需要精度时，具体数字更好。 <span class="footnote-reference" role="doc-noteref" id="fnrefw3w9pcpq63"><sup><a href="#fnw3w9pcpq63">[5]</a></sup></span></p><h3><strong>概率与其他单位没有什么不同</strong></h3><p>人类有一种固有的方式来感知温度。我们可能会说“这个房间有点暖和”，或者“比昨天冷得多”。但这些衡量标准是模糊的，不同的人可能对确切的差异存在分歧。因此，科学家们将这个概念正式化为“度”，并花了数年时间试图弄清楚它的确切含义以及如何测量它。</p><p>人类自然不会用度数、公里数或分贝来思考；而是用度数、公里数或分贝数来思考。我们的大脑根本上不是这样工作的。然而，有些东西比其他东西更温暖、更远、更响亮。这些概念最初是人类的直觉，随着科学家弄清楚它们的确切含义以及如何量化它们，这些概念逐渐正式化。</p><p>概率是一样的。我们还不知道如何像温度或距离一样精确地测量它们，但我们已经确定了<a href="https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inference">相当</a><a href="https://en.wikipedia.org/wiki/AIXI">多</a><a href="https://en.wikipedia.org/wiki/Principle_of_maximum_entropy">的</a><a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">细节</a>。</p><p>我对温度的主观判断并不准确，但这并不意味着它们毫无意义。当我输入这句话时，我不确定我坐在的房间是 21 度、22 度还是 23 度。但我很确定它不是 25 度，而且我非常确定它不是 15 度<span class="footnote-reference" role="doc-noteref" id="fnrefd7u42p6x7bp"><sup><a href="#fnd7u42p6x7bp">。 [ 6]</a></sup></span>同样，我对概率的主观判断是模糊的，但仍然传达了信息。我不能自信地说我下次飞行时行李箱被 TSA 检查的机会是 25% 还是 35%，但我知道它不是 1%。</p><h3><strong>精确的数字是否会过度强调人们的主张？</strong></h3><p>当然，他们可以。如果有人说“昨天中午正好是 22.835 摄氏度”，我们倾向于假设他们除了直觉之外还有其他理由相信这一点，概率也是如此。但“如果你把温度降低大约 2 度，我会更舒服”是一个完全合理的说法，“我认为这大约有 40% 的可能性”是一样的。</p><p>由于概率科学比温度科学更新且欠发达，因此它们在日常生活中的使用频率较低。在当今社会，即使是“40%左右”这样一个模糊的说法，也可以被认为是进行了某种深入的研究。这是自我纠正的。越多的人在正式科学领域之外使用数字概率进行标准化，他们就越不例外，产生误解的可能性也就越低。必须有人迈出第一步。</p><p>更重要的是，这种批评从根本上来说是有缺陷的，因为它的前提是不良行为者会自愿选择不误导人们。如果某人的目标是获得超出他们应有的信任，那么礼貌地要求他们不要这样做不会有任何效果。鼓励人们不要使用数字概率只会让人们更难清楚地表达他们的信仰，从而损害善意的对话；坏人只会提出<a href="https://github.com/antgoldbloom/tiktok_israel_hamas">一些虚假的研究</a>，或者<a href="https://twitter.com/theblaze/status/1732592489133965671">轻易地误解</a>合法的研究，并继续他们不劳而获的信心。</p><p>鼓励人们<i>永远不要</i>使用数字概率进行主观估计更糟糕。俗话说，有统计数据很容易说谎，但没有统计数据就更容易说谎。让人们随心所欲地畅所欲言，就消除了任何客观性的尝试，而要求他们在自己的主张上加上数字，可以让我们<a href="https://slatestarcodex.com/2013/05/02/if-its-worth-doing-its-worth-doing-with-made-up-statistics/">限制错误的严重程度</a>，并在某些事情<a href="https://www.youtube.com/watch?v=1wyCQAG6NQE">看起来不太正确</a>时注意到。</p><p>相反，很多时候（并非总是！），反对数字概率的人都是恶意行事的，因为他们试图在原则性反对的幌子下隐藏自己<a href="https://slatestarcodex.com/2015/08/20/on-overconfidence/">极其过度自信的</a>概率判断。类似“你怎么可能知道[行动]的风险是 20%？你不可能。因此我们应该假设它是 0%，并像没有风险一样继续进行”的说法并不罕见。这不符合小学水平的推理；如果您的数学老师要求您计算变量<a href="https://scryfall.com/search?q=name:/^X$/">X</a> ，而您不知道如何执行此操作或认为无法使用所提供的信息来完成此操作，那么您不能只选择自己喜欢的值！但在反对所有数字概率的幌子下，最后一句话通常不说出来，只是暗示，如果人们不熟悉这个谬论，这很容易让他们陷入困境。要求人们清楚地陈述他们认为的可能性是什么，可以防止他们施展这种修辞手法，并为进一步的分歧提供了具体的症结。</p><h3><strong>给出概率范围是什么意思？</strong></h3><p>根据我的经验，使用数字概率的人比不喜欢数字概率的人更担心意外地歪曲自己的信心水平。他们这样做的一个常见方法是给出一个概率范围；他们不会说“我对此有 40% 的把握”，而是会说“我认为有 20% 到 50% 的可能性”。</p><p>但这到底意味着什么呢？毕竟，单一概率已经是不确定性的量化；如果他们确信某件事，那也只是 0% 或 100%。概率范围在哲学上似乎是混乱的。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/gv53gsyv8loiinik6bxb"></p><p><a href="https://xkcd.com/2110/">西科CD</a></p><p>在某种程度上确实如此，但有一个潜在的令人信服的辩护。当我们从哲学角度谈论贝叶斯概率时，我们正在考虑一个理想的推理者，他将贝叶斯定理应用于每一个新的证据，以更新他们的信念。 <span class="footnote-reference" role="doc-noteref" id="fnref9qo3d7vpms"><sup><a href="#fn9qo3d7vpms">[7]</a></sup></span>但真正的人类并不擅长处理新信息，而且我们的行为可能与完美推理者的行为<a href="https://en.wikipedia.org/wiki/Aumann%27s_agreement_theorem">有很大不同</a>。</p><p>因此，概率范围可以用来传达我们预期的错误水平。如果有人说“我认为这有 20% 到 50% 的可能性”，他们的意思是“我有 95% 的信心，一个理想的贝叶斯推理机如果拥有与我相同的信息，其可信度将在 20% 到 50% 之间” ”。就像人们可能会说的“我不确定这里到底有多热，但我很确定温度在 19 到 23 度之间”。</p><p>还有另一个理由，即概率范围显示了考虑到您预计未来会遇到的最有可能的信息，您的概率可能会更新多远。并非所有的概率都是平等的；对您的信用下注的预期价值取决于该信用所基于的信息位数。例如，抛硬币正面朝上的概率应该是 50%，如果有人提出以更好的赔率与您打赌，则接受的期望值为正。</p><p>但现在假设有人提供了一种稍微不同的游戏，他们在杯子下藏了一枚硬币，你可以赌它是单挑的。进入此游戏时，您对正面朝上的置信度仍为 50%，因为您没有关于哪张面朝上的具体信息。但是，如果提供游戏的人向您提供此赌注，即使是看起来对您非常有利的 2:1 赌注，您也可能不应该接受，因为他们向您提供此赌注的事实本身就是表明它是可能是尾巴。 <span class="footnote-reference" role="doc-noteref" id="fnref8fsx7lj4hw3"><sup><a href="#fn8fsx7lj4hw3">[8]</a></sup></span>因此，给出“30% 到 70%”的概率范围可能意味着“我当前的可信度是 50%，但我获得的信息似乎非常合理，可以将我更新到该范围内的任何位置。”换句话说，范围的宽度代表了最有可能获得的信息类型<a href="https://en.wikipedia.org/wiki/Value_of_information">的信息值</a>。 <span class="footnote-reference" role="doc-noteref" id="fnrefdslr2azfco7"><sup><a href="#fndslr2azfco7">[9]</a></sup></span><span class="footnote-reference" role="doc-noteref" id="fnrefu95epfzor"><sup><a href="#fnu95epfzor">[10]</a></sup></span></p><p>概率范围的这两种用法都相当高级，在日常使用中可以忽略。</p><h3><strong>做出良好的估计</strong></h3><p>就像一些测量事物的经验将帮助您更好地估计距离一样，一些预测事物的经验将帮助您更好地估计概率。想要擅长这一点的人通常通过进行<a href="https://en.wikipedia.org/wiki/Calibrated_probability_assessment">校准概率评估</a><span class="footnote-reference" role="doc-noteref" id="fnreficf5o2m2il"><sup><a href="#fnicf5o2m2il">[11]</a></sup></span> 、参加<a href="https://www.metaculus.com/home/">预测锦标赛</a>和/或在<a href="https://www.astralcodexten.com/p/prediction-market-faq">预测市场</a>下注来进行练习。这些类型的练习有助于提高你的校准能力；您将模糊的感觉准确地转化为数字的能力。</p><p>对于相对不重要的日常判断，不需要更多。 “嘿，你明天能完成这个项目吗？” “呃，75%”。但有时您可能想要更多的确定性，并且有多种方法可以改进我们的预测。</p><p>首先，<a href="https://en.wikipedia.org/wiki/Base_rate_fallacy">始终考虑基本费率</a>。如果您想知道某件事发生的可能性有多大，<a href="https://en.wikipedia.org/wiki/Reference_class_forecasting">请查看过去发生过多少次</a>类似情况。想知道您明年开车时发生车祸的可能性有多大吗？只需检查您所在地区每公里的总体事故率即可。</p><p>不幸的是，在你开始打“参考级网球”之前，这只能让你走得更远。不确定哪类事件被视为“足够相似”以进行良好的分发。 （也许您有强有力的证据表明您是一个比平均水平更鲁莽的驾驶员，在这种情况下您需要调整基准费率。）并且在预测与过去事件不太相似的未来事件时，例如新技术的影响，往往根本没有有用的参考类。</p><p>发生这种情况时，另一种选择是采取您相对有信心的启发式判断，并将它们结合在一起，遵循<a href="https://en.wikipedia.org/wiki/Probability_axioms">概率公理</a>，以获得您不确定的数量。也许您可以查到，一名普通驾驶员每年发生事故的几率为 0.1%，而且您从个人经验中知道，您的驾驶速度往往比平均水平快 30% 左右。现在你需要查找的是速度和事故率之间的全局关系，然后你就可以计算出你想知道的概率。</p><p>可以与前面的方法同时使用的另一种选择是使用几种不同的方法进行多种概率估计，并将它们相互比较。如果它们差异很大，则表明您在某个地方犯了错误，您可以使用您对系统的特定知识和您可能的偏见来尝试找出错误所在。</p><p>例如，在考虑是否相信“直觉”而不是明确的模型时，<a href="https://outsidetheasylum.blog/the-hidden-complexity-of-thought/">请考虑这种情况是否是您的大脑启发式设计或训练的情况</a>。如果这种情况类似于人类在过去几百万年中经常遇到的情况，那么自然选择将使我们相当善于估计它。或者，如果您以前多次遇到过这种情况，那么您可能已经在直觉层面上学到了一个很好的启发式方法。但如果这是你和你的祖先不熟悉的东西，那么显式模型可能更可靠。</p><p>当您有多个独立获得的概率估计值时，在调整用于获得它们的方法的可靠性后， <a href="https://forum.effectivealtruism.org/posts/sMjcjnnpoAQCcedL2/when-pooling-forecasts-use-the-geometric-mean-of-odds">取赔率的几何平均值</a><span class="footnote-reference" role="doc-noteref" id="fnrefyc7t9ejx07l"><sup><a href="#fnyc7t9ejx07l">[12]</a></sup></span> ，以便将它们压缩为单个数字。这使您可以利用<a href="https://en.wikipedia.org/wiki/Wisdom_of_the_crowd">群体的智慧</a>，<a href="https://www.astralcodexten.com/p/crowds-are-wise-and-ones-a-crowd">甚至不需要群体</a>。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnao2uiw6hdek"> <span class="footnote-back-link"><sup><strong><a href="#fnrefao2uiw6hdek">^</a></strong></sup></span><div class="footnote-content"><p>这并不完全正确。如果哥本哈根解释是正确的，量子力学可能具有一些基本的随机性。但如果多世界解释或超决定论是正确的，那就不存在了。这也不是特别重要，因为只要<a href="https://en.wikipedia.org/wiki/Logical_possibility">在逻辑上可以</a>概念化一个确定性的世界，我们就需要一种适用于该世界的概率理论。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnwm5lopqnqhp"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwm5lopqnqhp">^</a></strong></sup></span><div class="footnote-content"><p>事实上，你甚至不需要知道它是被机器翻转的；它是由机器翻转的。连续看到 10 次正面朝上就足以得出结论，再次正面朝上的可能性超过 50%。如果您事先对硬币一无所知，则可以通过应用<a href="https://en.wikipedia.org/wiki/Rule_of_succession">拉普拉斯继承定律</a>来确定。知道它看起来像普通硬币，很难强烈操纵，你会想将其调整到 50%，但<a href="https://en.wikipedia.org/wiki/Gambler%27s_fallacy#Reverse_position">不是一直调整</a>。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnyla2721d2q"> <span class="footnote-back-link"><sup><strong><a href="#fnrefyla2721d2q">^</a></strong></sup></span><div class="footnote-content"><p>即使是这类科学模型也往往包含许多研究人员通过“基于经验的猜测”方法选择的假设。</p></div></li><li class="footnote-item" role="doc-endnote" id="fng51yh77rf9j"> <span class="footnote-back-link"><sup><strong><a href="#fnrefg51yh77rf9j">^</a></strong></sup></span><div class="footnote-content"><p>不，我不知道为什么最后三个是乱序的，这也让我烦恼。也不知道为什么某些分布低于 0% 或高于 100%。可能只是糟糕的图形设计。<a href="https://waf.cs.illinois.edu/visualizations/Perception-of-Probability-Words/">这里</a>对此进行了更严格的调查，发现了类似的结果。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnw3w9pcpq63"> <span class="footnote-back-link"><sup><strong><a href="#fnrefw3w9pcpq63">^</a></strong></sup></span><div class="footnote-content"><p> <a href="https://en.wikipedia.org/wiki/The_Precipice:_Existential_Risk_and_the_Future_of_Humanity">《悬崖》</a>中关于气候变化带来的灾难性风险部分的说明性摘录：<br><br> <i>“IPCC 表示，‘包合物中的甲烷发生灾难性释放的可能性非常小（高可信度）’。这听起来令人放心，但在 IPCC 的官方语言中，‘非常不可能’可以翻译为 1% 到 10% 的可能性，这听起来非常令人震惊。我不知道该怎么理解这一点，因为上下文表明这是为了让人放心。</i></p></div></li><li class="footnote-item" role="doc-endnote" id="fnd7u42p6x7bp"> <span class="footnote-back-link"><sup><strong><a href="#fnrefd7u42p6x7bp">^</a></strong></sup></span><div class="footnote-content"><p>如果您生活在像美国这样的不文明国家，我会将自由单位的转换留给您。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn9qo3d7vpms"> <span class="footnote-back-link"><sup><strong><a href="#fnref9qo3d7vpms">^</a></strong></sup></span><div class="footnote-content"><p>实际上有无数个使用不同先验的理想推理者。但有些先验比其他先验更好，并且对于任何合理的先验，例如索尔莫诺夫先验的可计算近似，一旦考虑到一些现实世界的信息，就会产生类似的结果。 <span class="footnote-reference" role="doc-noteref" id="fnrefcmbdamvfdq5"><sup><a href="#fncmbdamvfdq5">[13]</a></sup></span>可能。这仍然是一个活跃的研究领域。如果人类知道这里的所有答案，我们就能够创造出超级智能的人工智能，它以数学上最优的方式进行推理，并在所有预测任务中轻松击败人类，所以我们不这样做可能是件好事。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn8fsx7lj4hw3"> <span class="footnote-back-link"><sup><strong><a href="#fnref8fsx7lj4hw3">^</a></strong></sup></span><div class="footnote-content"><p>这就是为什么在预测市场中只押注“是”和“否”之间相对较大的差值而不是押注于单个数字通常是理性的。</p></div></li><li class="footnote-item" role="doc-endnote" id="fndslr2azfco7"> <span class="footnote-back-link"><sup><strong><a href="#fnrefdslr2azfco7">^</a></strong></sup></span><div class="footnote-content"><p>这类似于如果您要额外花费 1000 小时研究该命题，则对您分配给该命题的概率进行概率分布，然后测量该分布的宽度。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnu95epfzor"> <span class="footnote-back-link"><sup><strong><a href="#fnrefu95epfzor">^</a></strong></sup></span><div class="footnote-content"><p>它还有助于解决<a href="https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1050.0451">优化器的诅咒</a><span class="footnote-reference" role="doc-noteref" id="fnrefwf8vih6vmid"><sup><a href="#fnwf8vih6vmid">[14]</a></sup></span> ；如果您估计不同选项的概率并选择期望值最高的选项，那么您很可能会选择高估某处概率的选项。了解每个估计中包含的信息量可以让您偏向范围较小的信息。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnicf5o2m2il"> <span class="footnote-back-link"><sup><strong><a href="#fnreficf5o2m2il">^</a></strong></sup></span><div class="footnote-content"><p>您可以<a href="https://www.lesswrong.com/posts/LdFbx9oqtKAAwtKF3/list-of-probability-calibration-exercises">在这里</a>尝试一些免费的在线练习。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnyc7t9ejx07l"> <span class="footnote-back-link"><sup><strong><a href="#fnrefyc7t9ejx07l">^</a></strong></sup></span><div class="footnote-content"><p>不是概率的几何平均值！这样做会导致无效结果，因为例如 0.1 和 0.2 的几何平均值与 0.5 的距离与 0.8 和 0.9 的几何平均值不同。相反，您首先将概率转换为优势比，例如 50% 为 1:1，75% 为 3:1。 <span class="footnote-reference" role="doc-noteref" id="fnrefg48xho5quv"><sup><a href="#fng48xho5quv">[15]</a></sup></span>然后你取赔率的几何平均值并将其转换回概率。 <span class="footnote-reference" role="doc-noteref" id="fnrefkryzxomsrn"><sup><a href="#fnkryzxomsrn">[16]</a></sup></span></p></div></li><li class="footnote-item" role="doc-endnote" id="fncmbdamvfdq5"> <span class="footnote-back-link"><sup><strong><a href="#fnrefcmbdamvfdq5">^</a></strong></sup></span><div class="footnote-content"><p>当然，我们只相信索尔莫诺夫先验在某种意义上是“好的”，因为无论进化是用什么先验来构建人类的，这本身就有些武断。因此，存在一种无限回归，我们实际上无法谈论完全最优的推理机。但我们绝对可以比人类做得更好。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnwf8vih6vmid"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwf8vih6vmid">^</a></strong></sup></span><div class="footnote-content"><p><a href="https://en.wikipedia.org/wiki/Winner%27s_curse">胜利者诅咒</a>的变体</p></div></li><li class="footnote-item" role="doc-endnote" id="fng48xho5quv"><span class="footnote-back-link"><sup><strong><a href="#fnrefg48xho5quv">^</a></strong></sup></span><div class="footnote-content"><p>如有必要，可使用小数赔率，因此第二个数字始终为 1。在此系统下，25% 为 1/3:1。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnkryzxomsrn"> <span class="footnote-back-link"><sup><strong><a href="#fnrefkryzxomsrn">^</a></strong></sup></span><div class="footnote-content"><p> <a href="https://www.wolframalpha.com/input?i=o+%2F+%28o+%2B+1%29%2C+where+o+%3D+sqrt%28%28a+%2F+%281+-+a%29%29+*+%28b+%2F+%281+-+b%29%29%29%2C+where+a+%3D+0.1+and+b+%3D+0.2">这是</a>一个 Wolfram Alpha 链接，可以为您完成此操作，只需将“a”和“b”的值替换为范围的末尾即可。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/Ng5n8FjpsfXrceT9w/understanding-subjective-probabilities#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Ng5n8FjpsfXrceT9w/understanding-subjective-probabilities<guid ispermalink="false"> NG5n8FjpsfXrceT9w</guid><dc:creator><![CDATA[Isaac King]]></dc:creator><pubDate> Sun, 10 Dec 2023 06:03:30 GMT</pubDate> </item><item><title><![CDATA[Send us example gnarly bugs]]></title><description><![CDATA[Published on December 10, 2023 5:23 AM GMT<br/><br/><p> Tl;dr：寻找评估的硬调试任务，支付 60 美元/小时或每个示例 200 美元的费用。</p><p> METR（以前称为 ARC Evals）有兴趣为模型生成硬调试任务，以尝试作为<a href="https://metr.org/"><u>代理能力评估</u></a>的一部分。为了创建这些任务，<strong>我们正在寻找包含极其棘手的错误的存储库。</strong>如果您向我们发送的代码库符合提交标准（如下所列），我们将向您支付 60 美元/小时的费用，用于将其转换为我们所需的格式，或 200 美元，以较高者为准。 （我们不会为不符合这些要求的提交内容付费。）如果我们对您提交的内容感到特别兴奋，我们可能也有兴趣购买它的知识产权。根据多样性，我们预计总共需要大约 10-30 个示例。我们可能会在接下来的几周内对其他类型的任务给予奖励。</p><p>提交标准：</p><ul><li>包含一个错误，熟练的程序员至少需要 6 小时才能解决，最好超过 20 小时</li><li>理想情况下，过去没有公开发布过，并且您能够保证将来不会公开发布。<ul><li> （但请注意，我们仍然可以接受来自公共存储库的提交，因为它们尚未包含在 SWE 基准数据集中并且满足我们的其余要求。请先与我们联系。）</li></ul></li><li>您有合法权利与我们分享（例如，请不要向我们发送其他人的专有代码或您签署保密协议的任何内容）</li><li>理想情况下，代码库是用 Python 编写的，但我们也接受用其他语言编写的提交。 <i>&nbsp;</i></li><li>采用本文档中描述的格式： <a href="https://docs.google.com/document/d/15L0J25uzzf0xJeDsDgPYW60PzFZ0enaWWnlCkrCSGAM/edit"><u>Gnarly Bugs Submission Format</u></a></li></ul><p>请将提交内容以 zip 文件的形式发送至<a href="mailto:gnarly-bugs@evals.alignment.org"><u>gnarly-bugs@evals.alignment.org</u></a> 。您的电子邮件应包含将代码从原始状态转换为我们所需格式所需的小时数。如果您提交的内容符合我们的标准和格式要求，我们将与您联系并提供付款表格。如果您有任何疑问，包括您不确定潜在提交的内容是否符合标准，也欢迎您发送电子邮件至<a href="mailto:gnarly-bugs@evals.alignment.org"><u>gnarly-bugs@evals.alignment.org</u></a> 。<br><br>如果您愿意以更高的工资完成这项任务，请告诉我们！</p><p> <i>（此外，如果您有兴趣分叉 SWEbench 以支持非 python 代码库，请联系我们。）</i></p><br/><br/><a href="https://www.lesswrong.com/posts/JKtM5C2TTwhzoHFRB/send-us-example-gnarly-bugs#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/JKtM5C2TTwhzoHFRB/send-us-example-gnarly-bugs<guid ispermalink="false"> JKtM5C2TTwhzoHFRB</guid><dc:creator><![CDATA[Beth Barnes]]></dc:creator><pubDate> Sun, 10 Dec 2023 05:23:02 GMT</pubDate> </item><item><title><![CDATA[Conceptual coherence for concrete categories in humans and LLMs]]></title><description><![CDATA[Published on December 9, 2023 11:49 PM GMT<br/><br/><p><a href="http://new-savanna.blogspot.com/2023/12/conceptual-coherence-for-concrete.html"><i>从新稀树草原</i></a><i>交叉发布</i><i>。</i></p><p> Siddharth Suresh、Kushin Mukherjee、Xizheng Yu、Wei-Chun Huang、Lisa Padua 和 Timothy T. Rogers，概念结构在人类认知中一致，但在大型语言模型中不一致， <i>arXiv</i> ：2304.02754v2 [cs.AI] 2023 年 11 月 10 日。</p><blockquote><p><strong>摘要：</strong>语言的神经网络模型长期以来一直被用作开发有关思想和大脑中概念表示的假设的工具。多年来，这种使用涉及提取单词的向量空间表示，并使用这些单词之间的距离来预测或理解人类在各种语义任务中的行为。然而，当代大语言模型（LLM）使得使用与人类参与者常用的实验方法几乎相同的实验方法来询问概念表征的潜在结构成为可能。目前的工作利用了从认知心理学借用的三种常用技术来估计和比较人类和法学硕士的概念结构。在人类中，我们表明概念结构对于文化、语言和估计方法的差异具有鲁棒性。根据 LLM 行为估计的结构，虽然在个体上与根据人类行为估计的结构相当一致，但根据用于生成响应的特定任务的不同，差异更大——在不同任务中，来自同一模型的概念结构的估计彼此之间的一致性低于人类的一致性。结构估计。这些结果凸显了当代法学硕士和人类认知之间的重要差异，对于理解当代机器语言的一些基本局限性具有重要意义。</p></blockquote><p>摘要没有告诉你的是，所调查的类别是具体物体而不是抽象的：“这些项目是从两大类中抽取的——工具和爬行动物/两栖动物——选择它们是因为它们跨越了生物/非生物的界限，并且还拥有内部概念结构。”为什么这很重要？因为具体项目的含义是以感觉运动图式为基础的，而抽象的含义则不然。</p><p>作者在结论中指出：</p><blockquote><p>这些结果共同表明人类认知与当前的法学硕士模型之间存在重要差异。人类语义记忆的神经计算模型表明，许多不同任务的行为都是由一个共同的概念“核心”支撑的，该核心与不同上下文或任务引起的变化相对隔离（Rogers 等，2004；Jackson 等，2021） ）。相比之下，大型语言模型中词义的表示本质上取决于更广泛的语言上下文。事实上，在像 GPT-3 这样的 Transformer 架构中，每个单词向量都是作为周围文本向量的加权平均值计算的，因此不清楚任何单词是否具有外部含义或独立于上下文的含义。</p></blockquote><p>对于人类来说，具体概念的感觉运动基础提供了概念核心，而这对于无法接触物理世界的法学硕士来说是必然缺乏的。语境是他们所拥有的一切，因此他们对词语的意义必然会受到语境的影响。作者在最后承认了这一点：</p><blockquote><p>最后，人类语义知识是多种信息源的产物，包括概念的视觉、触觉和听觉属性。虽然法学硕士可以通过他们接受训练的语料库隐式地获取有关这些模式的知识，但他们仍然丧失了人类接触到的许多知识，而这些知识可能有助于他们将概念组织成更连贯的结构。从这个角度来看，法学硕士和人类之间概念一致性程度的差异应该不足为奇。</p></blockquote><br/><br/> <a href="https://www.lesswrong.com/posts/NxdGFzfKz7cpsintB/conceptual-coherence-for-concrete-categories-in-humans-and#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/NxdGFzfKz7cpsintB/conceptual-coherence-for-concrete-categories-in- humans-and<guid ispermalink="false"> NxdGFzfKz7cpsintB</guid><dc:creator><![CDATA[Bill Benzon]]></dc:creator><pubDate> Sat, 09 Dec 2023 23:49:31 GMT</pubDate> </item><item><title><![CDATA[2d ai-partners as a comprehensive motivation tool]]></title><description><![CDATA[Published on December 9, 2023 9:59 PM GMT<br/><br/><p>论文：</p><ol><li>动机、纪律、意志力、足够的情绪调节能力以实现你的目标——无论你想怎么称呼它——<strong>在实践中，每个人都有一个独特的秘诀，让他们“充分激励并努力工作”去追逐自己的梦想。</strong><br></li><li>弄清楚什么对你有用，有时会比你拥有的能量更多，因此“堵住足够的漏洞”以便你可以集中注意力变得很困难或几乎不可能。<br></li><li>很多时候，一个人很难靠自力更生。借助人工智能，您可以做一些称为“及时干预”的事情来帮助您在跌倒时重回正轨，例如：<br><ol><li>提醒您的目标或浪费的时间</li><li>鼓舞人心的引言</li><li>呼吸课程</li><li>与朋友通话<br></li></ol></li><li>想象一下，一个人工智能伙伴学习如何应用你需要的正确的“及时干预”，就像一把瑞士军刀作为朋友：<br><br><ol><li>积极主动地激励你</li><li>被评判并不羞耻，你的伴侣是你的延伸</li><li>升级任务</li><li>帮助您与朋友一起集中注意力</li><li>通过丰富的视觉、深入、长期的关系培养情感责任</li><li>文献中的技术（深度工作、原子习惯）</li><li>科学文献中的技术（CBT、Huberman Protocol、Wim Hoff）</li><li>灵感来自动漫、漫画、书籍、电视、现实生活。<br></li></ol></li><li>为什么是二维？人类必然是视觉生物，因此视觉人工智能比非视觉人工智能更好。对于情感联系尤其如此。最后，2d 比 3d 更容易。这是一个很好的起点。<br></li><li>这是我的帮助； <img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/beoke7xpfvxd1ck8w4lj" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/sfml7xlgicr3xbcges2m 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/t9cd39kha7mxauiljqha 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/u1h4tycl1x04kkoj5zih 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/mwopdkrgqrsiogqng4i4 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/arqdakfdyqs9srdjklza 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/d8cqonaq84qnkuqeh2gx 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/lnbkza6rqwdyru3npvoi 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/ejugimamsaprlstqebbm 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/y9fiiptabzjvk11mtmcx 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/vvaovwzqbrz2pz00to0v 907w"></li></ol><p></p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/vjujtlc5gqbzqprx8qk5" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/xmygcbfephawfqsb3a3r 140w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/w5qwjtgmtfj0g4vmj25y 280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/cxobwrftzliud6hfjmqz 420w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/tzlmqhkffk4ujvk5zjik 560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/mmcc9pbvhcyzzdxndrxt 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/tm57gacmv3bhm4h5h3xr 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/ulcjvtgcudm2kbxuevbb 980w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/dndz5dhf27iddzexxu8t 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/duepizhuiurivd7jilrp 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/igw3bi25yyiv34yq6evd 1338w"></figure><p>以下是一些统计数据： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/hln09xqzgd1willetuy6" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/tjhr5tzy4rkyswcw0gqj 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/wimajsrhjm0tqzrhbyjr 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/vu2xybjvtctlpvbmtql0 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/oico3g7oshcclx8hwpi9 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/onlnhvdryoadrjdiqzmf 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/gjh2nlfjb8tgjgn9mcnv 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/ts3g2sehw48bhabjydws 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/eylaiivifvnrmflri08d 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/m76zovgbhghagb3qsw7l 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/u8ibcreajeipkyspkrsb 1772w"></figure><p>最后，您现在可以选择自己的： <br><br><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/shr4msjnchh3jedbtwxa" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/m6j1gdmpdhope3og2oct 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/oxg6p9uno9j4esc8dpjn 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/nyz1lguur1mzuz6m8lwm 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/tqu6kyjjxxoiwvjpzr9k 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/cxwpcdv2ighqctcugbek 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/zfdjhruo8qwm67yztdp8 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/r5zcxoaxauddvdxeaot6 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/weaiqxkjloytkiyctcrp 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/kldxeqkh9irhfaxpizxk 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5BnACdeXsNsdtLLMP/xgk8lec0gcgpommsmdpw 1142w"><br><br>你可以在这里尝试一下：<br><br> <a href="https://chromewebstore.google.com/detail/tori-alpha/aoakkahlldbnibbggnkfkjekalepfkbj">https://chromewebstore.google.com/detail/tori-alpha/aoakkahldbnibbggnkfkjekalepfkbj</a><br><br>证据就在布丁里！</p><br/><br/> <a href="https://www.lesswrong.com/posts/5BnACdeXsNsdtLLMP/2d-ai-partners-as-a-comprehensive-motivation-tool#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/5BnACdeXsNsdtLLMP/2d-ai-partners-as-a-compressive-motivation-tool<guid ispermalink="false"> 5BnACdexsNSdtLLMP</guid><dc:creator><![CDATA[AiresJL]]></dc:creator><pubDate> Sat, 09 Dec 2023 22:00:07 GMT</pubDate></item></channel></rss>