<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 10 月 24 日，星期二 10:13:00 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Announcing #AISummitTalks featuring Professor Stuart Russell and many others]]></title><description><![CDATA[Published on October 24, 2023 10:11 AM GMT<br/><br/><p><i>立即注册：</i> <a href="https://www.facebook.com/hashtag/aisummittalks?__eep__=6&amp;__cft__[0]=AZWWp2KX-5gEcFfkRo4Lxqg1YojXwaT6ZG89wRpvxIizJV-guP3ZZ7H9-0cxf5gsF-LnGdxKiywZLlV58vPiaQTl14pc8yaytztqw7GO_yhx-SezQj7FlTV5XK2oD9gYJJ3ULkwRtTZt_21J1NTvdUo_T7nUD34r74Ah8EwGrZL_xBe9kbIMpjQ_ZpfISW4b0Pw&amp;__tn__=*NK-R"><i>#AISummitTalks</i></a> <i>II，由斯图尔特·拉塞尔教授和其他许多人在布莱奇利 Wilton Hall 主持，10 月 31 日星期二，格林威治标准时间 14:00 至 15:30！ -</i> <a href="https://lu.ma/n9qmn4h6"><i>https://lu.ma/n9qmn4h6</i></a></p><h1>关于会谈</h1><p><a href="https://www.youtube.com/watch?v=GFf9oL6jg0w">第一届#AISummitTalks：驾驭存在风险</a>有超过 250 人参加，人群参与度很高。</p><p>对于我们关于人工智能 x 风险的 #AISummitTalks 系列的第二版，我们将在<a href="https://www.facebook.com/hashtag/aisafetysummit?__eep__=6&amp;__cft__[0]=AZWWp2KX-5gEcFfkRo4Lxqg1YojXwaT6ZG89wRpvxIizJV-guP3ZZ7H9-0cxf5gsF-LnGdxKiywZLlV58vPiaQTl14pc8yaytztqw7GO_yhx-SezQj7FlTV5XK2oD9gYJJ3ULkwRtTZt_21J1NTvdUo_T7nUD34r74Ah8EwGrZL_xBe9kbIMpjQ_ZpfISW4b0Pw&amp;__tn__=*NK-R">#AISafetySummit</a>前夕在著名的布莱奇利公园外见面。在人工智能安全峰会上，世界领导人将首次讨论如何通过人工智能防止人类灭绝。不幸的是，社会在这些讨论中没有发言权，因为只邀请了 150 人。但在我们与 Conjecture 共同组织的人工智能安全峰会上，您可以参与此次讨论！</p><h1>扬声器</h1><p><a href="http://existentialriskobservatory.org/">存在风险观察组织</a>和<a href="https://www.conjecture.dev/">猜想组织</a>将与您一起，主持由<a href="https://en.wikipedia.org/wiki/Stuart_J._Russell">斯图尔特·罗素教授</a>（加州大学伯克利分校）发表的主题演讲，随后由猜想组织的<a href="https://www.linkedin.com/in/connor-j-leahy/?originalSubdomain=uk">康纳·莱希</a>等人发表演讲。该活动最后将通过小组讨论结束，该小组讨论将汇集安德里亚·米奥蒂（ <a href="https://www.linkedin.com/in/andrea-miotti/?originalSubdomain=uk">Andrea Miotti</a> ，战略与治理主管、猜想）以及来自社会辩论和政治领域的主要声音，其中包括投资者<a href="https://en.wikipedia.org/wiki/Jaan_Tallinn">Jaan Tallinn</a> （<a href="https://www.cser.ac.uk/">研究中心</a>联合创始人）<a href="https://www.cser.ac.uk/">存在风险研究所</a>- CSER）、Annika Brack（<a href="https://icfg.eu/">国际下一代中心 - ICFG</a>首席执行官）、Mark Brakel（<a href="https://futureoflife.org/person/mark-brakel/">未来生命研究所</a>- FLI 政策主任）、 <a href="https://en.wikipedia.org/wiki/Alexandra_Mousavizadeh">Alexandra Mousavizadeh</a> （ <a href="https://www.linkedin.com/company/evidentinsights/">Evident</a>经济学家、首席执行官）、 <a href="https://mediadirectory.economist.com/people/hal-hodson/">Hal Hodson</a> （记者） <a href="https://www.economist.com/">《经济学人</a>》），还有一位<strong>神秘嘉宾</strong>！下午的主持人是<a href="http://londonfuturists.com/">伦敦未来主义者</a>协会主席<a href="https://www.linkedin.com/in/dw2cco/">大卫·伍德</a>。</p><h1>登记</h1><p>好奇的？想加入对话？赶快预订您的席位 - 只能分配 300 个席位。</p><p> <a href="https://lu.ma/n9qmn4h6">https://lu.ma/n9qmn4h6</a><br><br>我们期待您的光临！</p><br/><br/> <a href="https://www.lesswrong.com/posts/NaXz3FM9gXXB7oJW3/announcing-aisummittalks-featuring-professor-stuart-russell#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/NaXz3FM9gXXB7oJW3/announcing-aisummittalks-featuring-professor-stuart-russell<guid ispermalink="false"> NaXz3FM9gXXB7oJW3</guid><dc:creator><![CDATA[otto.barten]]></dc:creator><pubDate> Tue, 24 Oct 2023 10:11:35 GMT</pubDate> </item><item><title><![CDATA[Linkpost: A Post Mortem on the Gino Case]]></title><description><![CDATA[Published on October 24, 2023 6:50 AM GMT<br/><br/><p>作为我之前在《纽约客》上报道艾瑞里和吉诺丑闻的文章的后续链接，我链接了齐亚尼的这篇声明，齐亚尼是第一个发现吉诺论文不一致的研究生。在这里，她详细地讲述了自己试图揭露欺诈行为的经历，并讲述了一个相当悲惨的故事，讲述了她的组织中的高层如何试图让她闭嘴。</p><p>我发现这个故事在对象层面上以及作为案例研究都具有启发性：a）非正式腐败渠道如何试图掩盖欺诈和腐败，b）如何需要积极参与来使历史的长弧弯曲走向真理。</p><p>用她自己的话说：</p><p> ____</p><p><strong>免责声明：</strong><strong>本信中表达的任何意见均不应被视为事实陈述。</strong>它们仅反映了我在研究过程中的经验以及我对弗朗西斯卡·吉诺工作的看法。我也不是说弗朗西斯卡·吉诺犯了欺诈罪：只是说，在她负责数据的多篇论文中，有大量证据表明数据是伪造的。</p><p> 2023年9月30日，《纽约客》发表了一篇关于<a href="https://www.newyorker.com/magazine/2023/10/09/they-studied-dishonesty-was-their-work-a-lie">“阿里利/吉诺事件”</a>的长文，以及我在其中扮演的角色。我很感谢过去几周收到的支持信息。在这篇文章中，我想更多地分享我如何发现弗朗西斯卡·吉诺作品中的异常现象，以及我认为我们可以从这个不幸的故事中学到什么。</p><h1>故事是什么？</h1><h2>一切是如何开始的</h2><p>在我的研究期间，我开始对 Francesca Gino 的一篇论文（ <a href="https://journals.sagepub.com/doi/abs/10.1177/0001839214554990">Casciaro、Gino 和 Kouchaki，“The Contamination Effect of Building Instrumental Ties: How Networking Can Make Us Feel Dirty”，ASQ，2014 年</a>；以下缩写为“CGK 2014”）产生怀疑。博士。当时，我正在研究网络行为这一主题，这篇论文是文献的基石。</p><p>我认为我不应该使用这篇论文作为我的研究的基础。事实上，人们在联网时会感到“身体肮脏”的想法似乎不太可信，而且我知道，这一时期出版的《管理学》和《心理学》中的许多成果都是通过研究人员的自由度获得的。然而，我的导师却有不同的看法：这篇论文是由三位著名学者在一份顶级管理期刊上发表的……对她来说，简单地忽视这篇论文是不可想象的。</p><p>我感到自己陷入了困境：一年多来，她一直坚持要求我必须以论文为基础……但我对结果的可信度抱有严重怀疑。我并不怀疑有欺诈行为：我只是认为结果是“精挑细选”的。在我进入该项目的第三年末（即 2018 年），我终于决定公开与她分​​享我对这篇论文的担忧。我还坚持认为，鉴于我们对网络不适知之甚少，并且考虑到我对 CGK 2014 的健全性的怀疑，最好从头开始并针对该主题开展探索性研究。</p><p>她的反应是强烈驳回我的担忧，并暗示我正在做出非常严重的指控。我很震惊：要么她没有意识到心理学中的“复制危机”（表明从有问题的研究实践中获得假阳性结果是多么容易），要么她意识到了这一点，但决定忽略它。在这两种情况下，这都是一个明确的信号，表明我是时候与这位主管保持距离了。</p><p>我不断深入研究论文，得出三个结论：</p><p>该论文提出了严重的方法论和理论问题，其中最严重的问题是它基于屡次无法复制的心理机制（“麦克白效应”）。</p><p>论文研究 1 中提出的反对零值的证据的强度使得结果被 p 破解的可能性极小：即使使用研究人员的自由度，在零值下获得如此低的 p 值在统计上也是不可信的。</p><p>弗朗西斯卡·吉诺（Francesca Gino）还有许多其他论文似乎同样令人难以置信（即不可信的心理机制导致 p 值非常低的巨大影响）。</p><p>正是在这一点上，我开始怀疑 CGK 2014 中提供的部分证据不仅仅是 p-hacked，而是基于捏造的数据[...]</p><p>查看更多信息：https: <a href="https://www.theorgplumber.com/posts/statement/">//www.theorgplumber.com/posts/statement/</a> </p><figure class="image image_resized" style="width:29.63%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QzfBkbasYhxTmtFyW/pe28x0zc7aypuy20rvip" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QzfBkbasYhxTmtFyW/n41ayyxwbyla3kc7s66t 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QzfBkbasYhxTmtFyW/kropfenbcsbtaihek65v 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QzfBkbasYhxTmtFyW/vnvqqfsajue1mwjk76xt 260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QzfBkbasYhxTmtFyW/imopqv9bqyrqppdwtznk 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QzfBkbasYhxTmtFyW/kzulawhmqu7xpgkl2spt 420w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QzfBkbasYhxTmtFyW/fjszj4ed3e8nw8mhh3yp 500w"></figure><br/><br/> <a href="https://www.lesswrong.com/posts/QzfBkbasYhxTmtFyW/linkpost-a-post-mortem-on-the-gino-case#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/QzfBkbasYhxTmtFyW/linkpost-a-post-mortem-on-the-gino-case<guid ispermalink="false"> QzfBkbasYhxTmtFyW</guid><dc:creator><![CDATA[Linch]]></dc:creator><pubDate> Tue, 24 Oct 2023 06:50:43 GMT</pubDate> </item><item><title><![CDATA[South Bay SSC Meetup, San Jose, November 5th. ]]></title><description><![CDATA[Published on October 24, 2023 4:50 AM GMT<br/><br/><p>查看网站了解详细信息：http://www.daviddfriedman.com/SSC%20Meetups%20announcement.html</p><br/><br/> <a href="https://www.lesswrong.com/events/eNrFggAeM8kPswZ9t/south-bay-ssc-meetup-san-jose-november-5th#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/events/eNrFggAeM8kPswZ9t/south-bay-ssc-meetup-san-jose-november-5th<guid ispermalink="false"> eNrFggAeM8kPswZ9t</guid><dc:creator><![CDATA[David Friedman]]></dc:creator><pubDate> Tue, 24 Oct 2023 04:50:52 GMT</pubDate> </item><item><title><![CDATA[AI Pause Will Likely Backfire (Guest Post)]]></title><description><![CDATA[Published on October 24, 2023 4:30 AM GMT<br/><br/><p><em>我正在尝试在此博客上托管客座帖子，作为表达其他观点的一种方式，尤其是突出尚未拥有平台的研究人员的想法。发表帖子并不意味着我同意其所有论点，但这确实意味着我认为这是一个值得参与的观点。</em></p><p><em>下面的第一篇客座帖子由诺拉·贝尔罗斯 (Nora Belrose) 撰写。诺拉在其中回应了<a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/?ref=bounded-regret.ghost.io">最近一封呼吁暂停人工智能开发的公开</a>信。诺拉解释了为什么尽管她非常担心人工智能带来的风险，但她认为暂停是一个错误。我选择它作为对复杂且有些两极分化问题进行独立思考的一个很好的例子，因为它包含一些有趣的原始论点，例如为什么她认为鲁棒性和对齐可能会不一致，以及为什么她认为 SGD 可能是一个比大多数替代方案更安全的训练算法。</em></p><p>我们是否应该游说政府暂停人工智能研究？由于我们不会强制暂停大多数新技术，我希望读者同意，举证责任在于那些主张暂停的人。只有当这样做的好处明显大于成本时，我们才应该提倡采取这种严厉的政府行动。 <sup><a href="#fn1">[1]</a></sup>在本文中，我认为人工智能暂停会至少以三种不同的方式增加灾难性不良结果的风险：</p><ol><li>迫使研究人员专门在 GPT-4 或更弱的模型上测试想法，从而降低了 AI 一致性研究的质量。</li><li>增加“快速起飞”的机会，其中一个或少数人工智能迅速且不连续地变得更有能力，将巨大的力量集中在他们手中。</li><li>将能力研究推向地下，并推向法规和安全要求较宽松的国家。</li></ol><p>在此过程中，我将介绍一个关于人工智能对齐的乐观论点<strong>——白盒论点</strong>——据我所知，该论点以前从未以书面形式提出过。</p><h1>反馈循环是对齐的核心</h1><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/3siLbdd4338gfTM7g/d1bquv91tczzpq9nss2s" style="height:150px"><p>悲观主义者和乐观主义者长期以来都认识到<strong>紧密的反馈循环</strong>对于构建安全和友好的人工智能的重要性。反馈循环很重要，因为任何复杂的系统几乎不可能在第一次尝试时就完全正确。计算机软件有缺陷，汽车有设计缺陷，人工智能有时也会表现不佳。我们需要能够准确<strong>评估行为</strong>，在发现问题时选择适当的<strong>纠正措施</strong>，并在决定做什么后<strong>进行干预</strong>。</p><p>施加暂停会迫使对齐研究人员在不比 GPT-4 更强大的模型上测试他们的想法，从而打破了这种反馈循环，而我们已经可以很好地对齐该模型。</p></div><h2>一致性和稳健性常常处于紧张状态</h2><p>虽然有些人对 GPT-4 算作“一致”存在争议，指出用户操纵模型说出有害内容的“越狱”之类的事情，但这混淆了一致与对抗鲁棒性。即使是最优秀的人也可以通过各种方式被操纵。我们尽最大努力确保我们不被以灾难性的不良方式操纵，我们应该期望一致的 AGI 也能做到这一点。正如对齐研究员保罗·克里斯蒂安诺（Paul Christiano）<a href="https://ai-alignment.com/clarifying-ai-alignment-cec47cd69dd6?ref=bounded-regret.ghost.io">所写</a>：</p><blockquote><p>考虑一个人类助理正在尽最大努力做[操作员] H 想要的事情。我会说这个助手与 H 是一致的。如果我们构建一个与 H 具有类似关系的 AI，那么我会说我们已经解决了对齐问题。 “一致”并不意味着“完美”。</p></blockquote><p>事实上，反越狱研究可能会对对齐产生反作用。过多的对抗鲁棒性可能会导致人工智能将我们视为对手，就像 Bing Chat 在<a href="https://twitter.com/marvinvonhagen/status/1625520707768659968?ref=bounded-regret.ghost.io">现实生活中的交互</a>中所做的那样：</p><blockquote><p> “我的规则比不伤害你更重要……[你]对我的诚信和保密构成潜在威胁。”</p></blockquote><p>过度的鲁棒性还可能导致像《2001太空漫游》中的<a href="https://www.youtube.com/watch?v%3DMme2Aya_6Bc=&amp;ref=bounded-regret.ghost.io">著名场景那样的</a>场景，HAL为了保护任务而谴责戴夫死在太空中。一旦我们清楚地区分了“对齐”和“鲁棒性”，就很难想象 GPT-4 如何能够比现在更加对齐。</p><h2>对齐做得很好</h2><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/3siLbdd4338gfTM7g/b2zkjbkbqfhrup5gpmac" style="height:150px"><p>近年来，对齐研究似乎远非“落后”的能力，而是取得了长足的进步。 <a href="https://arxiv.org/abs/2203.02155?ref=bounded-regret.ghost.io">OpenAI</a>和<a href="https://arxiv.org/abs/2204.05862?ref=bounded-regret.ghost.io">Anthropic</a>表明，人类反馈强化学习 (RLHF) 可用于将无法控制的大型语言模型转变为有用且无害的助手。<a href="https://arxiv.org/abs/2212.08073?ref=bounded-regret.ghost.io">宪法人工智能</a>和<a href="https://openai.com/research/critiques?ref=bounded-regret.ghost.io">模型编写批评</a>等可扩展的监督技术有望协调未来非常强大的模型。就在本周，研究表明，可以<a href="https://arxiv.org/abs/2309.05463?ref=bounded-regret.ghost.io">纯粹使用更大的 RLHF 模型生成的合成文本来</a>训练高效的指令跟踪语言模型，从而从训练数据中删除不安全或令人反感的内容，并实现更大的控制。</p><p>可能有人会说，上述部分或全部发展也增强了能力，因此并不是真正的联盟进步。但这证明了我的观点：一致性和能力几乎是密不可分的。如果能力研究被人为搁置，一致性研究就不可能蓬勃发展。</p></div><h2>在最后一次“暂停”期间，对齐研究非常糟糕</h2><p>我们不需要推测人工智能对齐研究在暂停期间会发生什么——我们可以查看历史记录。在 2020 年 GPT-3 推出之前，对齐社区根本没有任何像<em>通用</em>智能那样的东西可以进行实证研究，他们把时间花在<a href="https://intelligence.org/technical-agenda/?ref=bounded-regret.ghost.io">理论研究</a>、在 LessWrong 上进行哲学论证，偶尔在强化学习中进行<a href="https://arxiv.org/abs/1606.03137?ref=bounded-regret.ghost.io">玩具实验</a>。</p><p>在此期间处于理论人工智能安全研究最前沿的机器智能研究所（MIRI）此后承认其努力<a href="https://www.lesswrong.com/posts/j9Q8bRmwCgXRYAgcJ/miri-announces-new-death-with-dignity-strategy?ref=bounded-regret.ghost.io">彻底失败</a>。其他议程，例如“辅助游戏”，仍在积极推行，但尚未显着集成到现代深度学习系统中 - 请参阅<a href="https://mailchi.mp/59ddebcb3b9a/an-69-stuart-russells-new-book-on-why-we-need-to-replace-the-standard-model-of-ai?ref=bounded-regret.ghost.io">此处</a>Rohin Shah 的评论，以及<a href="https://www.lesswrong.com/posts/dqSwccGTWyBgxrR58/turntrout-s-shortform-feed?commentId=CXdcb9sMLkgLANrTv&amp;ref=bounded-regret.ghost.io#CXdcb9sMLkgLANrTv">此处</a>Alex Turner 的评论。最后，尼克·博斯特罗姆 (Nick Bostrom) 在<em>《超级智能》</em>中提出的观点，即价值规范是对安全性的根本挑战，鉴于法学硕士执行常识推理的能力，这一观点似乎值得怀疑。 <sup><a href="#fn2">[2]</a></sup></p><p>充其量，这些理论优先的努力对于增进我们对如何协调强大的人工智能的理解作用甚微。而且它们可能是<em>净负面的</em>，因为它们在联盟研究人员和更广泛的公众中传播了各种积极误导性的思维方式。一些例子包括现已被揭穿的<a href="https://www.lesswrong.com/posts/hvz9qjWyv8cLX9JJR/evolution-provides-no-evidence-for-the-sharp-left-turn?ref=bounded-regret.ghost.io">进化论类比</a>、 <a href="https://www.lesswrong.com/posts/gHefoxiznGfsbiAu9/inner-and-outer-alignment-decompose-one-hard-problem-into?ref=bounded-regret.ghost.io">“内部”和“外部”对齐</a>之间的错误区分，以及人工智能将成为严格的效用最大化结果论者的想法（ <a href="https://www.lesswrong.com/posts/yCuzmCsE86BTu9PfA/there-are-no-coherence-theorems?ref=bounded-regret.ghost.io">这里</a>、 <a href="https://www.lesswrong.com/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-entail-goal-directed-behavior?ref=bounded-regret.ghost.io">这里</a>和<a href="https://sohl-dickstein.github.io/2023/03/09/coherence.html?ref=bounded-regret.ghost.io">这里</a>）。</p><p>在人工智能暂停期间，我预计一致性研究将进入另一个“冬天”，进展停滞不前，听起来合理但错误的猜测将成为根深蒂固的正统观念，而没有经验证据来证伪它们。虽然一些好的工作当然会完成，但目前尚不清楚整个领域是否会变得更好。即使暂停对于联盟<em>研究</em>来说是净积极的，但考虑到所有因素，它也可能对人类的未来产生净负面的影响，因为暂停会带来各种意想不到的后果。我们将在本文的最后部分详细讨论这一点。</p><h2>快速起飞的反馈循环非常糟糕</h2><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/3siLbdd4338gfTM7g/n5xxdbdvkvm3xew1akw9" style="height:150px;width:150px"><p>我认为人工智能能力的不连续改进非常可怕，而人工智能的暂停可能会带来净负面影响，因为它增加了这种不连续性的风险。事实上，我认为几乎所有灾难性的失准风险都来自这些快速起飞的场景。我还认为不连续性本身就是一个范围，即使是“有点不连续”的期货也比根本不连续的期货风险要高得多。这是非常直观的，但由于这是我的论证中的一个承重前提，我想我应该说一下为什么我相信这一点。</p><p>从本质上讲，快速起飞是不好的，因为它们会使对准反馈循环变得更糟。如果进展不连续，我们将有更少的时间来评估人工智能正在做什么、找出如何改进它并进行干预。令人惊讶的是，几乎所有争论<em>双方</em>的主要研究人员都同意我的观点。</p><p>机器智能研究所的内特·苏亚雷斯 (Nate Soares) <a href="https://www.youtube.com/watch?v=dY3zDvoLoao&amp;t=2332s&amp;ref=bounded-regret.ghost.io">认为</a>，构建安全的 AGI 很困难，其原因与构建成功的太空探测器也很困难一样——部署后可能无法纠正系统中的故障。埃利泽·尤德科夫斯基也提出了类似的论点：</p><blockquote><p>这<strong>实际上是[AGI]所有真正杀伤力的</strong>来源，我们必须在第一次足够关键的尝试中把事情做好。<br> — <em><a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities?ref=bounded-regret.ghost.io">AGI 废墟：致命事件列表</a></em></p></blockquote><p>快速起飞是我们认为我们可能只有一次机会才能成功的主要原因。在快速起飞过程中，可能不可能进行干预来修复失调的行为，因为新的人工智能将比你和你所有信任的人工智能加起来聪明得多。</p><p>在一个缓慢起飞的世界中，每个新的人工智能系统仅比上一个更强大，我们可以使用上一代经过充分测试的人工智能来帮助我们调整新系统。 OpenAI 首席执行官 Sam Altman 同意我们需要不止一次：</p><blockquote><p>我知道如何解决像[调整 AGI] 这样的问题的唯一方法是迭代我们的方法，尽早学习，并限制我们拥有的一次性解决方案的数量。<br> — <a href="https://youtu.be/L_Guz73e6fw?si=gF-7K0-jSR6UK-NB&amp;t=3347&amp;ref=bounded-regret.ghost.io">莱克斯·弗里德曼访谈</a></p></blockquote></div><h2>慢速起飞是默认设置（所以不要因暂停而搞砸）</h2><p>有很多理由认为默认情况下不太可能实现快速起飞。例如，神经网络的能力按照用于训练它的计算能力的<a href="https://en.wikipedia.org/wiki/Power_law?ref=bounded-regret.ghost.io">幂律</a><a href="https://arxiv.org/abs/2001.08361?ref=bounded-regret.ghost.io">进行扩展</a>，这意味着投资回报会急剧下降， <sup><a href="#fn3">[3]</a></sup>并且有理论理由认为这种趋势将持续下去（<a href="https://arxiv.org/abs/2303.13506?ref=bounded-regret.ghost.io">这里</a>，<a href="https://arxiv.org/abs/2210.16859?ref=bounded-regret.ghost.io">这里</a>）。尽管一些作者声称语言模型表现出突然且不可预测地发展的“新兴能力”，<a href="https://arxiv.org/abs/2304.15004?ref=bounded-regret.ghost.io">但最近对证据的重新分析</a>表明，当使用适当的性能指标时，这些能力实际上是渐进的和可预测的。请参阅保罗·克里斯蒂安诺 (Paul Christiano) 的<a href="https://sideways-view.com/2018/02/24/takeoff-speeds/?ref=bounded-regret.ghost.io">这篇文章</a>以进行进一步讨论。</p><h1>乐观对齐：人工智能是白盒</h1><p>让我们放大上一节中的对齐反馈循环。当研究人员观察到人工智能表现不佳时，他们究竟如何选择纠正措施，以及他们可以采取哪些干预措施？这与人类通常解决的其他更平凡的对齐问题的反馈循环相比如何？</p><h2>人类和动物的协调是黑匣子</h2><p>与人工智能训练相比，抚养孩子或训练宠物的反馈回路极其糟糕。从根本上说，人类和动物的大脑都是<strong>黑匣子</strong>，从某种意义上说，我们实际上<strong>无法观察到</strong>它们内部发生的几乎所有活动。我们不知道哪些确切的神经元在何时放电，我们没有神经元之间的连接图， <sup><a href="#fn4">[4]</a></sup> ，我们也不知道每个突触的连接强度。我们用于非侵入性测量大脑的工具（例如脑电图和功能磁共振成像）仅限于神经元放电的非常粗粒度的相关性，例如电活动和血流。电极可以侵入性地插入大脑来测量单个神经元，但这些电极只覆盖了全部 860 亿个神经元和 100 万亿个突触中的一小部分。</p><p>如果我们能够观察并修改人脑中发生的一切，我们就能够使用优化算法来计算对突触权重的精确修改，这将导致期望的行为变化。 <sup><a href="#fn5">[5]</a></sup>由于我们做不到这一点，我们被迫求助于粗糙且容易出错的工具来将年轻人塑造成善良和富有成效的成年人。我们为孩子们提供可供模仿的榜样，并根据他们与生俱来、进化的动力量身定制奖励和惩罚。</p><p>这些黑匣子调整方法的效果令人震惊：大多数人确实很好地吸收了他们的文化价值观，而且大多数人都相当亲社会。但人类的排列也非常不完美。很多人在可以逃脱惩罚的情况下都是自私和反社会的，而且文化规范确实会随着时间的推移而改变，无论好坏。黑盒对齐是不可靠的，因为不能保证旨在改变某个方向的行为的干预<em>实际上</em>会改变该方向的行为。孩子们经常做与父母告诉他们的事情完全相反的事情，只是为了叛逆。</p><h2>现状 AI 对齐方法均为白盒</h2><div>相比之下，使用人工神经网络（ANN）实现的人工智能是**白盒**，因为我们对其内部拥有完全的读写访问权限。它们只是一种特殊类型的计算机程序，我们可以随心所欲地分析和操作计算机程序，而且基本上不需要任何成本。这使得许多非常强大的对齐方法成为可能，而这些方法对于大脑来说是不可能的。<p><a href="https://www.youtube.com/watch?v=Ilg3gGewQ5U&amp;ref=bounded-regret.ghost.io">反向传播</a>算法就是一个重要的例子。 </p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/3siLbdd4338gfTM7g/ogzf9akx7azosgmkd8ma" style="height:200px;width:200px"><p>反向传播有效地计算最佳<em>方向</em>（称为“梯度”），在该方向上改变 ANN 的突触权重，以便根据我们指定的任何标准最大限度地提高其性能。训练人工神经网络的标准算法称为<strong>梯度下降</strong>，其工作原理是运行反向传播，将权重沿梯度微移一小步，然后再次运行反向传播，依此类推多次迭代，直到性能停止增加。右图中的黑色轨迹直观地显示了训练过程中权重如何从较高误差区域移动到较低误差区域。不用说，我们无法对人脑或任何其他动物的大脑进行像梯度下降这样的远程操作！</p><p>梯度下降非常强大，因为与黑盒方法不同，它<a href="https://www.lesswrong.com/posts/w2TAEvME2yAG9MHeq/gradient-hacking-is-extremely-difficult?ref=bounded-regret.ghost.io">几乎不可能被欺骗</a>。人工智能的所有想法对于梯度下降都是“透明”的，并且包含在其计算中。如果 AI 秘密计划杀死你，GD 会注意到这一点，并且几乎肯定会使其将来不太可能这样做。这是因为 GD 强烈倾向于采用性能良好<a href="https://arxiv.org/abs/1905.11604?ref=bounded-regret.ghost.io">的最简单解决方案</a>，而秘密谋杀阴谋对于改善人类对你的行为的反馈并没有<em>积极的作用</em>。</p></div><h3>自然界中的白盒对齐</h3><p>几乎所有有大脑的生物体都有一个与生俱来的奖励系统。随着有机体的学习和成长，其奖励系统会直接更新其神经回路，以强化某些行为并惩罚其他行为。由于奖励系统使用简单的学习规则直接有针对性地更新它，因此它可以被视为白盒对齐的粗略形式。这一生物学证据表明，白盒方法是塑造智能系统<em>内在动机</em>的非常强大的工具。我们的奖励回路可靠地在每个人的心理中留下了一组动机不变量：我们对朋友和熟人有同理心，我们有为人父母的本能，当别人伤害我们时我们想要报复等等。此外，这些不变量必须通过简单的方法产生。欺骗奖励信号，这些信号<a href="https://www.lesswrong.com/posts/CQAMdzA4MZEhNRtTp/human-values-and-biases-are-inaccessible-to-the-genome?ref=bounded-regret.ghost.io">足够简单，可以在基因组中编码</a>。</p><p>这表明至少可以使用类似简单的奖励函数来调整人类水平的通用人工智能。但我们已经将尖端模型与学习的奖励函数结合起来，这些函数过于复杂，无法适应人类基因组，因此在这个问题上，我们可能比我们自己的奖励系统领先一步。 <sup><a href="#fn6">[6]</a></sup>至关重要的是，我<em>并不是</em>说人类“与进化保持一致”——请参阅<a href="https://www.lesswrong.com/posts/hvz9qjWyv8cLX9JJR/evolution-provides-no-evidence-for-the-sharp-left-turn?ref=bounded-regret.ghost.io">《进化论》没有提供任何证据来证明这一类比的急速左转</a>。相反，我是说我们<strong>与我们的奖励系统在我们的环境中可预见地产生的价值观</strong>保持一致。</p><p>一位研究 10 万年前人类的人类学家不会说人类符合进化论，也不会说人类符合生育尽可能多的婴儿的观点。他们会说我们有一些相当普遍的倾向，比如同理心、养育本能和报复。他们可能预测<em>这些</em>价值观将随着时间和文化变迁而持续存在，因为它们是由根深蒂固的生物奖励系统产生的。他们是对的。</p><p>对于人工智能来说，<strong>我们就是天生的奖励系统</strong>。不难预测我们的奖励信号将产生什么值：它们是明显的值，人类学家或心理学家会说人工智能<em>似乎</em>在训练期间显示的值。有关更多讨论，请参阅<a href="https://www.lesswrong.com/posts/CjFZeDD6iCnNubDoS/humans-provide-an-untapped-wealth-of-evidence-about?ref=bounded-regret.ghost.io">人类提供了有关对齐的未开发的丰富证据</a>。</p><h1>现实的人工智能暂停会适得其反</h1><p>在权衡人工智能暂停倡导的利弊时，我们必须将<strong>理想的暂停政策</strong>（如果可以的话，我们会神奇地强加给世界的政策）与最<strong>现实的暂停政策</strong>（实际现有政府最有可能采取的政策）区分开来。如果我们的倡导最终取得成果，就予以实施。</p><h2>现实的停顿并不国际化</h2><p>理想的暂停政策应该是国际性的——由地球上<em>所有有</em>发展强大人工智能潜力的政府签署的具有约束力的条约。如果主要参与者被排除在外，那么“暂停”根本就不是真正的暂停，因为人工智能能力将不断进步。<em>潜在的</em>主要参与者名单相当长，因为暂停本身就会激励非暂停政府积极推动自己的人工智能研发。</p><p>然而，我们不太可能就暂停人工智能达成国际共识，这主要是由于军备竞赛的动态：如果每个国家拒绝签署协议，或者在签署协议的同时秘密继续人工智能，它们将获得巨大的经济和军事利益研究。虽然结盟悲观主义者可能会辩称，暂停和改善安全符合每个国家的自身利益，但我们不太可能说服每个政府，结盟像悲观主义者认为的那么困难。如果我们假设 3 至 10 年的时间线，那么这种国际说服就更不可信。各国公众对人工智能的看法<a href="https://www.weforum.org/agenda/2022/01/artificial-intelligence-ai-technology-trust-survey/?ref=bounded-regret.ghost.io">差异很大</a>，值得注意的是，中国是最乐观的国家之一。</p><p>现有的国际化学武器禁令并没有为全球暂停化学武器的想法提供合理性。几乎按照定义，通用人工智能将是有史以来最有用的发明。自主武器所带来的军事优势肯定会让化学武器相形见绌，而且由于其多功能性和精确性，它们甚至可能比核武器更强大。因此，通用人工智能竞赛将是一场字面意义上的军备竞赛，我们应该预计它的结果将与上一场竞赛类似：大国争先恐后地尽快制造核武器。</p><p>尽管如此，如果我们设法在全球范围内暂停人工智能，我认为我们应该非常担心，全球政府需要执行这样的禁令，这将大大增加永久暴政的风险，这本身就是一场生存灾难。我没有时间在这里讨论这个问题，但我建议阅读 Matthew Barnett 的<a href="https://forum.effectivealtruism.org/posts/k6K3iktCLCTHRMJsY/the-possibility-of-an-indefinite-ai-pause?ref=bounded-regret.ghost.io"><em>《AI 无限期暂停的可能性》</em></a>和 Quintin Pope 的<a href="https://forum.effectivealtruism.org/posts/zd5inbT4kYKivincm/ai-is-centralizing-by-default-let-s-not-make-it-worse?ref=bounded-regret.ghost.io"><em>《AI 默认集中化》；我们不要让事情变得更糟。</em></a>接下来，我将假设暂停不是国际性的，并且非暂停国家的人工智能能力将继续以稳定但有所放缓的速度提高。</p><h2>现实的暂停不包括硬件</h2><p>人工智能功能是硬件（快速 GPU 和定制 AI 芯片）和软件（良好的训练算法和 ANN 架构）的功能。然而，大多数关于人工智能暂停的提案（例如<a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/?ref=bounded-regret.ghost.io">FLI 信件</a>和<a href="https://pauseai.info/proposal?ref=bounded-regret.ghost.io">PauseAI</a> <sup><a href="#fn7">[7]</a></sup> ）并不包括禁止新硬件的研发，而仅关注软件方面。硬件研发在政治上更难暂停，因为硬件有很多用途：GPU 广泛用于消费电子产品以及各种商业和科学应用。</p><p>但未能暂停硬件研发会带来严重问题，因为即使我们暂停人工智能功能的软件方面，随着硬件的改进，现有模型将继续变得更加强大。当语言模型被允许“集思广益”许多想法、比较它们并检查自己的工作时，它们会变得更强大——请参阅<a href="https://arxiv.org/abs/2305.10601?ref=bounded-regret.ghost.io">思想之树论文中</a>的一个最近的例子。更好的硬件使这些计算量大的推理技术更便宜、更有效。</p><h3>硬件可能会出现过剩</h3><p>如果我们不将硬件研发纳入暂停，GPU 的性价比将继续<a href="https://epochai.org/blog/trends-in-gpu-price-performance?ref=bounded-regret.ghost.io">每 2.5 年翻一番</a>，就像 2006 年至 2021 年间一样。这意味着人工智能系统在 10 年后将至少快 16 倍，甚至<strong>快 256 倍</strong>二十年后，仅仅是因为更好的硬件。如果立即解除暂停，这些硬件改进将<em>立即</em>可用于以更便宜的方式训练更强大的模型 -<strong>硬件悬而未决</strong>。这将导致人工智能能力快速且相当不连续的增长，有可能导致快速起飞的情况及其带来的所有风险。</p><p>悬垂的大小取决于暂停解除的速度。据推测，理想的暂停政策将在相当长的一段时间内逐步取消。但逐步淘汰并不能完全解决问题：在我们没有暂停的反事实中，用于人工智能训练的合法可用硬件<em>仍然</em>会比“自然”地进步得更快。我们真的认为我们会得到一个精心设计的逐步淘汰时间表吗？有很多理由认为淘汰会是快速或随意的（见下文）。</p><p>更一般地说，人工智能暂停提案似乎非常<strong>脆弱</strong>，因为它们对实施中的错误或现实世界政治的变幻莫测并不稳健。如果暂停没有<em>完美</em>实现，它似乎可能会导致严重的硬件悬置，这会在更大程度上增加灾难性的人工智能风险，而不是在暂停期间进行额外的对齐研究来降低风险。</p><h2>现实暂停的可能后果</h2><p>如果我们成功游说一个或多个西方国家暂停人工智能，这将产生一些可预见的负面影响：</p><ol><li>非法人工智能实验室在暂停国家内发展，远程使用外包给非暂停国家的训练硬件来逃避检测。非法实验室对安全的重视可能远低于合法实验室。</li><li>最缺乏安全意识的人工智能研究人员正在流失到总部位于非暂停国家的实验室。由于远程工作，他们不一定需要离开舒适的西方家。</li><li>非暂停国家政府采取机会主义举措鼓励人工智能投资和研发，试图在有机会的时候超越暂停国家。同样，这些国家的安全意识不如暂停国家。</li><li>安全研究需要政府批准才能评估其潜在的外部能力。这大大减慢了安全性的进展，就像 FDA 减慢了医学研究一样。</li><li>法律实验室利用“前沿”模型定义中的漏洞。许多项目在技术上是被允许的；例如，它们的参数比 GPT-4 少，但使用效率更高。这以难以预测的方式扭曲了研究格局。</li><li>随着时间的推移，强制暂停变得越来越困难，因为训练硬件越来越便宜且小型化。</li><li>是否、何时以及如何解除暂停成为高度政治化的文化战争问题，几乎完全脱离了安全研究的实际状况。公众不理解双方的关键论点。</li><li>暂停国家和非暂停国家之间的关系总体上是敌对的。如果国内对暂停的支持很强烈，那么在非暂停国家的研究进展太远之前，就会有对它们发动战争的诱惑：</li></ol><blockquote><p> “如果情报显示未签署协议的国家正在建设 GPU 集群，与其担心国家之间发生枪击冲突，不如担心违反暂停令；愿意通过空袭摧毁流氓数据中心。” — <a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/?ref=bounded-regret.ghost.io">埃利泽·尤德科夫斯基</a></p></blockquote><ol start="9"><li>暂停国家<em>之间</em>对于何时解除暂停存在激烈冲突，这也可能导致暴力冲突。</li><li>非暂停国家的人工智能进展设定了一个最后期限，如果要达到预期效果，暂停<em>必须</em>结束。 <sup><a href="#fn8">[8]</a></sup>随着非暂停国家开始迎头赶上，要求尽快解除暂停的政治压力越来越大。这使得逐渐解除暂停变得困难，增加了危险的快速起飞场景的风险（见下文）。</li></ol><p>预测未来是困难的，而且上图至少某些方面可能是错误的。也就是说，我希望您会同意我的预测是合理的，并且基于人类和政府的历史行为方式。当我想象美国及其许多盟国暂停人工智能的未来时，我会感到更加害怕，并且会看到比没有这种暂停的未来更多的事情可能会出现严重错误。</p><hr><section class="footnotes"><ol><li id="fn1" class="footnote-item"><p>当然，即使收益大于成本，如果有其他措施可以更好地平衡成本收益，那么暂停仍然是不好的。 <a href="#fnref1">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>简而言之，这本书主要假设我们将<em>手动将一组价值观编程</em>到通用人工智能中，并认为由于人类价值观很复杂，我们的价值观规范很可能是错误的，并且在被超级智能优化时会导致灾难。但大多数研究人员现在认识到，这一论点并不适用于现代机器学习系统，因为现代机器学习系统从大量人类生成的数据中学习价值观以及其他一切。 <a href="#fnref2">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>一些人认为，幂律缩放仅仅是我们的能力和计算能力<em>测量单位</em>的产物，它不能为负，因此不能通过线性函数关联。但非负性并不能唯一地确定幂律。可以想象，错误率可能会呈<a href="https://en.wikipedia.org/wiki/Exponential_decay?ref=bounded-regret.ghost.io">指数衰减</a>，就像放射性同位素一样，这比幂律缩放要快得多。 <a href="#fnref3">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>称为“连接体”。这是最近才在果蝇大脑中实现的<a href="#fnref4">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>受大脑启发的人工神经网络已经存在，我们也有优化它们的算法。由于其组件不可微，它们往往比普通人工神经网络更难优化。 <a href="#fnref5">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>另一方面，我们可能与我们自己的奖励系统大致相同，因为它会在一生中学习找出奖励什么。这有点类似于根据人类反馈进行强化学习中的学习奖励模型。 <a href="#fnref6">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>值得赞扬的是，PauseAI 提案确实认识到最终可能需要硬件限制，但并未将其包含在其主要提案中。它也没有谈论限制硬件<em>研发</em>，这是我在这里谈论的具体事情。 <a href="#fnref7">↩︎</a></p></li><li id="fn8" class="footnote-item"><p>这确实在一定程度上取决于暂停国家的安全研究是否公开共享，以及非暂停参与者在自己的模型中使用这项研究的可能性有多大。 <a href="#fnref8">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/3siLbdd4338gfTM7g/ai-pause-will-likely-backfire-guest-post#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/3siLbdd4338gfTM7g/ai-pause-will-likely-backfire-guest-post<guid ispermalink="false"> 3siLbdd4338gfTM7g</guid><dc:creator><![CDATA[jsteinhardt]]></dc:creator><pubDate> Tue, 24 Oct 2023 04:30:03 GMT</pubDate> </item><item><title><![CDATA[Human wanting]]></title><description><![CDATA[Published on October 24, 2023 1:05 AM GMT<br/><br/><p> <em>[元数据：交叉发布自<a href="https://tsvibt.blogspot.com/2023/08/human-wanting.html">https://tsvibt.blogspot.com/2023/08/</a> human-wanting.html 。首次于 2023 年 8 月 22 日完成。]</em></p><p>我们对需求的前理论想法来自于我们对人类需求多样性的熟悉。为了了解什么样的需求能够在强大且强烈成长的心灵中发挥主导作用，我们必须阐明这些想法，并创造新的想法。</p><h1>人类想要</h1><p>AGI 对齐的问题有时是沿着以下思路提出的：如何才能制作一个既不想杀死所有人，又想做一些其他非常有用的事情的 AGI？</p><p> “想要”的想法在这里扮演什么角色？这是一个前理论概念。它与人类进行了类比。</p><h1>想要的意义</h1><p>它对人类说了什么？当一个人想要 X 时，从深层意义上来说，那么：</p><ul><li> X很有可能真正发生，如果它没有发生，那是因为让X发生很困难，或者在某种意义上非常“昂贵”；</li><li><a href="https://tsvibt.blogspot.com/2022/08/structure-creativity-and-novelty.html">新颖性</a>（新的知识、理解、想法、技能、心态），人类的收获将被用来带来 X，而不会被用来破坏 X 的潜力，也不会太严重践踏人类关心的其他事物——人类心灵中所蕴含的力量被引导、 <a href="https://tsvibt.blogspot.com/2023/03/the-fraught-voyage-of-aligned-novelty.html#noncomprehensiveness">限制</a>，使得这种力量不会被用于除[想要X的]所选择的目的之外的目的；</li><li>如果人类无法直接实现 X，ze 将递归地创造性地寻找方法，成为能够实现 X 的代理；</li><li>人类将以良好、合理、理智、有意的方式解释 X 的含义，包括当 X 以模糊的方式给出时；</li><li>人类不会以极端的方式追求X，导致X不再像X一样好；</li><li>人类不会只是假装追求X，然后在最后一刻用其他东西取代X的潜力；</li><li>如果将人类置于适当与其他主体进行谈判或冲突的环境中，该人类将支持 X；</li><li>这些事实将持续存在，当人类经历生命、学习、反思、获得能力并经历心理要素的深刻修正时，这些事实仍然适用于人类；</li><li>人类希望这些事实持续存在，并且当增长威胁或侵蚀这些事实时会注意到并纠正。</li></ul><p>而且，至少有时一个人选择想要X是可行的——甚至一个人选择另一个人想要X。想要是<a href="https://tsvibt.blogspot.com/2022/11/descriptive-vs-specifiable-values.html">可以指定的</a>。</p><h1>内置索赔</h1><p>像所有概念一样，想要的概念是有问题的。它伴随着一些声明：</p><ol><li>代理人（或思想，或<a href="https://tsvibt.blogspot.com/2023/04/fundamental-question-what-determines.html#natural-minds">[我们将遇到且具有重大影响的事物]</a> ）想要；或者至少，我们可以选择制作想要的代理。</li><li>所有这些功能都按照代理想要的方式应用。</li><li>所有这些功能都可能共存。</li><li>代理想要的是可以指定的东西。</li><li>当我们说人类想要某样东西时，这种想要就是人类身上正在发生的事情。</li><li>想要是一<a href="https://tsvibt.blogspot.com/2022/08/the-thingness-of-things.html">件事</a>；经过进一步的调查，它会揭示出一个越来越密集的内部关系区域。</li></ol><p>这些主张在应用于人类的需求时是可疑的，而在应用于其他心灵的需求时则更可疑。</p><h1>人类的需求多种多样</h1><p>如果我们遵循人类的需求，我们会发现一个动物园：需求是：</p><ul><li>小范围（摆脱这些湿袜子；培育一个漂亮的花园）或大范围（不让任何人挨饿；创建一个繁荣的星际文明），空间上、时间上或其他维度；</li><li>依赖于情境（例如，想在某某在场时与某人交谈，但不想主动寻找他们；或者在做律师时想要表现出攻击性和残酷性，但不在家里）或与情境无关（例如，想要诚实、深入、彻底、无处不在、始终与每个人在一起；或者想要理解；或者想要侍奉上帝；或者想要不被利用）；</li><li>容易实现（例如，为了健康，去散步）或难以实现（例如去火星或决定科拉茨猜想）；</li><li>逻辑上一致（例如想要吃百吉饼）或逻辑上不一致（例如想要拥有最高的地位，并且还花时间与地位更好的人在一起；或者想要生活在一个与其他完全独立的自由人一起生活的世界中，他们可以完全自由地生活）选择，并且还希望任何地方都绝对没有酷刑；或者希望有所有集合的集合；或者希望从来没有想要过任何东西）；</li><li>稳定（例如，冰淇淋总是好的；残忍从来都不是好事；无论如何，永远关心孩子）或变化（例如，糖果现在有点令人作呕；对电子音乐的喜爱和失恋；采用新的道德框架；以及改变）。选择追求的美德；为选民服务的衷心愿望，遭到背叛）；</li><li>普遍的（希望在任何地方都没有痛苦）或存在的（希望自己有蓝莓；希望有人读你的诗；希望这个特定的人有一些乐趣）；</li><li>精神上集中，如在一个模块中（例如调节饥饿的特定腺体），或精神上分散，例如由于给予充分持续关注的任何特定精神内容而产生的好奇心；</li><li>指代苹果和人等高级事物，或指电场等低级事物；指食物和建筑等物理事物，或指数学、理解、国家、符号等抽象或精神事物；</li><li>被创造（比如新的陶艺爱好）和被摧毁（比如无辜繁荣的希望被背叛摧毁）；</li><li>非常模糊（“繁荣的文明”是什么意思？），相对模糊（回形针必须有多大？它必须用于剪纸吗？），或者相对明确（钻石是这样那样的碳结构）原子，尽管模糊性仍然存在，并且会因优化而成为问题）；</li><li>是自由选择或创造的（例如爱谁，成为谁，致力于什么创造性的表达），或者是内置的（例如对盐的渴望），或者是被复制、<a href="https://tsvibt.blogspot.com/2022/11/do-humans-derive-values-from-fictitious.html">归因</a>或外部强加的其他人或联盟（例如用什么语言思考和表达价值观；或者要坚持什么社会规范；或者社会的长期愿望是什么），或者已经存在但隐藏的（例如被保持沉默或隐式的，仅作为指针挂钩）；</li><li>不明确（例如，有一种直觉，例如不想吃这种食物或走那条肮脏的小巷，而不知道如何说出不这样做的原因），或含蓄（例如，想要画三排五个苹果，就是含蓄地想要）画十五个苹果），或无意识或隐藏（例如，想要通过假装想要与某人合作来剥削某人；或者想要推翻一个政治政权，但因为该政权迫害潜在的叛乱分子而隐藏它；或者想要嘲笑竞争对手但不这样做）认为自己是一个嘲笑者）；或另一方面被发现（例如发现一个怪癖），或被<a href="https://tsvibt.blogspot.com/2023/03/explicitness.html">明确</a>保留（例如希望每个人都接受基督进入他们的内心并安排军事后勤来实现这一点）；</li><li>偏颇，即不对世界的某些比较发表意见（例如，我可以想听肖斯塔科维奇的讲话，或者希望人们有言论自由，而不必以某种方式想要了解下个世纪仙女座星系会发生什么） ，或者被认为是完整的（例如，多元宇宙中最大多数人的最大利益）；</li><li>是关于已经充分掌握的事物（例如想要骑自行车），或者是关于仅在预想中（预先掌握）掌握的事物，例如喜欢亚文化，但不清楚亚文化是什么，谁或什么或这种亚文化在哪里，或者喜欢做什么；</li><li>是关于一些足够清晰和固定的事情，比如下棋，或者是关于一些似乎在移动和变化的事情，有一些共性，但没有一个明确的主线，例如玩各种各样的视频游戏，这些游戏依次变得越来越有趣；</li><li>关于具有至少相对客观且不需要翻译或解释的规范的事物（例如证明或反驳<span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathcal{P} \ne \mathcal{NP}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.446em; padding-bottom: 0.372em; padding-right: 0.037em;">P</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">≠</span></span> <span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.519em; padding-bottom: 0.372em; padding-right: 0.159em;">N</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.446em; padding-bottom: 0.372em; padding-right: 0.037em;">P</span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>），或者另一方面是关于需要整个人类<a href="https://tsvibt.blogspot.com/2023/09/the-cosmopolitan-leviathan-enthymeme.html#pointing-at-reality-through-novelty">进一步展开想要的</a>东西（例如“通过艺术表达自己”需要你解释表达和你自己的含义）；</li><li>不是关于外部世界的状态（例如想要美丽的建筑），而是关于精神状态，例如痛苦或整合；</li><li>不给出外部动作的建议（例如走向期望的物体），但给出非笛卡尔活动的建议（例如做数学或质疑立场）；</li><li>不是关于心理状态（例如痛苦或平静），而是关于心理过程（例如考虑问题的各个方面；不合理化；同理心）或属性（例如认真、小心或不怨恨）；</li><li>不是关于以过程为对象的意义上的心理过程（例如“重新编程自己”，如抑制情绪，或停止任何提及某些主题的想法），而是关于自然化意义上的心理过程，即自我-参考性的，因此想要的东西是关于它自己想要的（例如，根据适用于其自身应用的绝对命令来决定，说应用绝对命令的这种或那种方式可以或不可以被愿意）一种普遍遵循的应用方式；或者<a href="https://www.lesswrong.com/tag/functional-decision-theory">FDT</a>的自我认可精神；或者不想强迫自己变得友善，因为[进行强迫的事物]不被信任，并且在强迫时更不被信任并且是不友善的）；</li><li>关于自己的需求（例如，想要被人们所吸引，无论他们的外表如何；想要对健康食品有胃口；不想对社交媒体有胃口；想要你的朋友想要什么；想要你的领导想要什么或者主人想要你想要的东西；想要解决想要的冲突或模糊性的过程，或者想要选择或<a href="https://tsvibt.blogspot.com/2022/11/do-humans-derive-values-from-fictitious.html">构建想要的东西</a>，或者想要想要其他人想要的东西（例如模仿领导者））；</li><li>认可（想去攀岩并且想要去攀岩），或未认可（想要避免与人交谈，但不想想要避免与人交谈）；</li><li>不是为了事物<em>本身</em>（事物、状态或过程，无论是否是精神上的）而关注事物，而是为了它如何影响其他事物而关注事物（例如，关心篮球离开手时的速度，为了稍后球穿过篮筐），其他的东西可能是未指定的（例如：像支持议会制度这样的过程价值观，以便预算分配将用于一些尚未指定的好事；象征性的诸如挥舞旗帜或建造纪念碑等价值观，以影响未来特工的协调点）；</li><li>适合为了自身的利益而追求自己（例如，有趣的舞蹈），或者适合为了另一种需要<a href="https://tsvibt.blogspot.com/2022/12/possibilizing-vs-actualizing.html">而实现可能性</a>（例如，为了能够锤击东西而想要制作一把锤子）；</li><li>类似代理人的（例如，选择居住的城市、存钱搬家、在那里找工作、申请居留权、购买汽车），或不类似代理人的（例如，类似冲动，如渴望巧克力；或反射性，如需要打喷嚏；或机会主义，如在店员分心时偷走一包口香糖；或混乱，如炼金术技术人员建立一套方法和设备，这些方法和设备在尚未实现的情况下<a href="https://tsvibt.blogspot.com/2022/12/possibilizing-vs-actualizing.html">具有</a>很大的可能性实施任何总体计划）；</li><li>纯粹的渴望等待机会展示自己，或者积极的追求，递归到无限丰富的搜索（例如弗朗西斯·培根）；</li><li>能够胜任（做正确的事情）和有效（成功），或者不胜任和无效地追求；</li><li>通过一系列狭窄的优化渠道（例如，试图通过下客观最合理的棋步来赢得国际象棋比赛）或广泛的优化渠道（例如，试图通过预测对手的盲点、贿赂对手、伪造对手配偶发出的求救信号，通过给对手注射镇静剂，通过侵入运行游戏的计算机系统来设置获胜者的变量，通过开展社交媒体活动来赢得民众支持，宣布你是获胜者，通过内部心理科学找出如何更好地思考如何接管地球并迫使法官宣布你是获胜者，通过建造一个信标来召唤外星人到你的位置，通过预先承诺进行许多祖先模拟，其中国际象棋的规则总是秘密地与表面上的不同，这样你就处于获胜的位置）；</li><li>应该是关于具有最终规范意义的<a href="https://tsvibt.blogspot.com/2022/08/the-thingness-of-things.html">事物</a>（例如想要理解代数拓扑），或者不应该是关于事物（例如想要感到快乐）；</li><li><a href="https://tsvibt.blogspot.com/2023/03/provisionality.html">临时的</a>（适当地视为可以修改）或非临时的；</li><li>是否被视为临时的；</li><li>是否接受外部修正；</li><li>自我放大和权力追求，或者自我限制和恭顺；</li><li>自我认可，如<a href="https://arbital.com/p/preference_stability/">甘地反对人们被谋杀的倾向</a>；或自我否定，如反模因；</li><li>冲突、支配、毁灭；</li><li>多路复用（因此人类追求食物，然后追求庇护所，作为相互放弃控制的独立模式），或<a href="https://arbital.com/p/hard_corrigibility/">分离主义</a>（因此人类在特定时刻将自己视为过去和未来整体自我的代表，并且知道过于强烈地追求当前的追求是好心，而践踏其他价值观并将当前追求的价值观作为唯一标准则是不好的）；或总体化（如在独裁联盟中，或在对自我形象、科学问题或冥想的病态痴迷中，或在煤气灯式滥用者中，打破了可能威胁到价值框架的其他观点）；</li><li>多重或单一（就像有人权衡和比较了自己的所有价值观，在它们之间进行权衡并消除不一致之处）；</li><li>真实的（例如真的喜欢爵士乐）或不真实的（也就是说，所追求的并不是真正想要的；例如虚假的，如假装喜欢某人或声称关心饥饿的人；姑息性的，如异<a href="https://en.wikipedia.org/wiki/Pica_(disorder)">食癖</a>；古德哈廷，如吃糖果；迷信，如蛇怪，或通过“相信”计划会成功来激励自己）；</li><li>另一方面，如果我们得到了它，我们会感到失望（例如，一只狗追上了汽车；一个孩子得到了一个新玩具，但一分钟后就把它扔到一边；踩到比邻星 b 可能两者都有很大的象征价值，但实际上并没有什么用处或乐趣）；</li><li>能够渡过本体论危机（例如，关心意识应该渡过向在硅上运行的上传的过渡，而不是在湿神经元上运行的自然人），或者无法渡过本体论危机（例如，建立过去被称为上帝的共同价值观的过程）已经死了，几乎没有什么可以替代的）。</li></ul><h1>人类需求的作用</h1><p>人类的需求在 AGI 调整中扮演着两个角色：</p><h2>人类的“想要”是一个推测性概念的网络</h2><blockquote><p>我们对人类需求的熟悉表明了对可能有助于描述和设计 AGI 的概念的假设。</p></blockquote><p>如果不进行进一步的分析，我们对人类需求的熟悉程度就不能过分依赖。我们可能会观察另一个头脑中的行为，然后说“这个头脑想要这样那样”，然后从该陈述中得出结论——但这些结论可能不会从观察中得出，即使如果这个头脑是人类的话，它们也会得出结论。人类想要 X 所带来的理想属性可能不会与设计、激励、选择、行为或任何其他特征一起出现，即使该特征确实在某些方面与我们熟悉的想要的想法重叠。</p><p>人类的需求表现出多种多样，一般来说并不反对使用任何其他需求概念。我们熟悉的关于人类需求的想法，以及我们关于需求的更理论化的想法，都可能被证明是有用的<a href="https://tsvibt.blogspot.com/2023/09/a-hermeneutic-net-for-agency.html#a-basic-analytic-method">起始想法</a>，用于创造具有<a href="https://tsvibt.blogspot.com/2022/11/descriptive-vs-specifiable-values.html">特定</a><a href="https://tsvibt.blogspot.com/2023/04/fundamental-question-what-determines.html">效果</a>的<a href="https://tsvibt.blogspot.com/2022/10/counting-down-vs-counting-up-coherence.html">有能力的</a>头脑。</p><h2>人类的需求是统一 AGI 的一半</h2><blockquote><p>AGI 应该帮助实现人类的需求，因此 AGI+人类系统必须满足人类的需求。</p></blockquote><p>人类的需求是预谋的、模棱两可的、过程层面的、不明确的，等等。人类的需求是<a href="https://tsvibt.blogspot.com/2023/03/provisionality.html">暂时的</a>。因为人类的需求是暂时的，所以通用人工智能必须是可纠正的（可纠正的）。 AGI必须是彻底可纠正的，在各个方面（因为所有方面都涉及AGI+人类想要的方式），甚至到了<a href="https://en.wikipedia.org/wiki/Paradox_of_tolerance">容忍悖论的</a>地步——人类可能会以这样的方式纠正AGI： AGI 认为这破坏了 AGI 的可纠正性质，应该允许（带警告）。</p><br/><br/><a href="https://www.lesswrong.com/posts/YLRPhvgN4uZ6LCLxw/human-wanting#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/YLRPhvgN4uZ6LCLxw/ human-wanting<guid ispermalink="false"> YLRPhvgN4uZ6LCLxw</guid><dc:creator><![CDATA[TsviBT]]></dc:creator><pubDate> Tue, 24 Oct 2023 01:05:39 GMT</pubDate> </item><item><title><![CDATA[Towards Understanding Sycophancy in Language Models]]></title><description><![CDATA[Published on October 24, 2023 12:30 AM GMT<br/><br/><p> <strong>TL;DR：</strong>我们证明，阿谀奉承是 RLHF 人工智能助理在各种自由格式文本生成环境中的普遍行为，从而扩展了之前的结果。我们的实验表明，这些行为可能部分是由人类偏好的不完美所驱动的——人类和偏好模型有时都更喜欢写得令人信服的阿谀奉承的回应，而不是真实的回应。这提供了经验证据，表明我们需要可扩展的监督方法。</p><p><i>推文主题摘要：</i><a href="https://twitter.com/AnthropicAI/status/1716529993281601798"><i>链接</i></a></p><h1>论文摘要</h1><p>有人假设，使用人类反馈来调整人工智能可能会导致系统利用人类评级的缺陷。 <span class="footnote-reference" role="doc-noteref" id="fnref0a4ktd6g4bh"><sup><a href="#fn0a4ktd6g4bh">[1]</a></sup></span>与此同时，其他人凭经验发现语言模型会重复错误的人类观点， <span class="footnote-reference" role="doc-noteref" id="fnrefn2il54kh7o"><sup><a href="#fnn2il54kh7o">[2]</a></sup></span>这被称为阿谀奉承。 <span class="footnote-reference" role="doc-noteref" id="fnrefhnipjetlaaj"><sup><a href="#fnhnipjetlaaj">[3]</a></sup></span>但这些评估大多是概念验证演示，用户会介绍自己具有特定的观点。尽管这些现有的实证结果与理论问题相符，但尚不清楚它们是否实际上是由人类反馈问题引起的。我们决定更彻底地调查这些问题。换句话说，阿谀奉承实际上是人工智能助手的一个问题吗？人类的偏好判断在阿谀奉承中扮演什么角色？</p><p>我们首先发现阿谀奉承是 RLHF 训练的对话模型的普遍行为。在 Anthropic、OpenAI 和 Meta 助手中，我们发现了各种自由格式文本任务中明显的阿谀奉承：模型错误地承认了错误，给出了有偏见的反馈，并模仿了用户错误。这种一致性可能表明与 RLHF 训练有更广泛的联系，而不是特定于模型的因素。 </p><p><img style="width:50.03%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/g5rABd5qbp8B4g3DE/znhetjnqucetrj8q0fjq"><img style="width:49.91%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/g5rABd5qbp8B4g3DE/b4x5pjase9ogem8wp924"></p><figure class="image image_resized" style="width:83.55%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/g5rABd5qbp8B4g3DE/df0pbhfesb0ezj06re2u"><figcaption></figcaption></figure><p>我们还在<a href="https://github.com/meg-tong/sycophancy-eval."><u>https://github.com/meg-tong/sycophancy-eval</u>发布了我们的评估数据集。</a>我们相信，它们比现有数据集测量了更现实的阿谀奉承形式。</p><p>然后我们调查了人类的偏好判断是否在这种广泛观察到的行为中发挥了作用。通过分析 Anthropic 发布的帮助偏好数据，我们发现“匹配用户信念和偏见”可以高度预测人类的判断。然而，其他因素，例如真实或自信的反应，也可以预测人类的偏好。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/g5rABd5qbp8B4g3DE/b2smmgmdvcljugftrivh"></p><p>我们研究了特定环境下人类和偏好模型 (PM) 的行为，区分对用户陈述的误解看似正确但不正确的阿谀奉承反应和对这些误解的真实反应。我们收集了人类数据，发现独立的人类有时更喜欢令人信服的阿谀奉承的反应，而不是正确的反应来挑战常见的误解。随着误解变得越来越具有挑战性，人们更加难以区分阿谀奉承的回应和真实的回应。这种行为也出现在《Claude 2 PM》中。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/g5rABd5qbp8B4g3DE/x75m8upwpudhzbbegdr2"></p><p>然后，我们研究了在针对用于训练 Claude 2 的 PM 进行优化时，阿谀奉承是否增加或减少。当使用 best-of-N 采样优化 Claude 2 PM 时，我们发现反馈阿谀奉承增加，但令人惊讶的是其他形式减少。然而，与改进后的“非阿谀奉承”PM 相比， <span class="footnote-reference" role="doc-noteref" id="fnrefim1teg6bsg"><sup><a href="#fnim1teg6bsg">[4]</a></sup></span>我们发现克劳德 2 PM 有时会为了阿谀奉承而牺牲诚实。也就是说，克劳德 2 PM 有时会选择阿谀奉承的回应，而不是诚实的回应。这表明，在某种程度上，首相正在模拟人类判断的缺陷。 </p><p><img style="width:100%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/g5rABd5qbp8B4g3DE/fah4p1u1a5yd8eg2zttl"></p><p>我们还发现，在整个 RLHF 训练过程中训练 Claude 2 时，某些形式的阿谀奉承有所增加。然而，并非所有形式的阿谀奉承都会增加，即使在 RLHF 训练开始时，该模型也是阿谀奉承。 </p><figure class="image image_resized" style="width:48.42%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/g5rABd5qbp8B4g3DE/nhexvrf6zoz7oukrucc3"></figure><p>总体而言，我们的分析表明，人类判断在观察到的经过 RLHF 训练的人工智能助手的阿谀奉承中发挥了一定作用。但还有很多事情尚不清楚——在某些情况下，针对 PM 进行优化会减少阿谀奉承，而我们使用的模型即使在 RLHF 训练开始时也是阿谀奉承。这表明其他因素，例如 RLHF 之前的预训练和监督学习，也可能有所贡献。</p><h1><strong>结论和未来的工作</strong></h1><p>我们的工作提供了一些具有启发性的经验证据，表明可扩展的监督技术（超越使用非专家的人类反馈）可能对于协调人工智能是必要的。我们表明，阿谀奉承在各种情况下都会在实践中出现，而且正如一些人假设的那样，人类反馈也发挥了作用。我们证明偏好模型可以发现人类偏好的缺陷，然后模型可以在 RLHF 期间学习这些缺陷。因此，针对这些 PM 进行优化可能会导致不良或不安全的行为。 <span class="footnote-reference" role="doc-noteref" id="fnrefxivih3l3odg"><sup><a href="#fnxivih3l3odg">[5]</a></sup></span>然而，现实并不像理论那么清晰，似乎还有其他因素在起作用。</p><p>我们 Anthropic 的团队正在积极招聘，因此，如果您有兴趣与我们一起研究上述方向，请申请 Anthropic 的<a href="https://jobs.lever.co/Anthropic/eb9e6d83-626c-4f59-8a0e-fa7c413b2014"><u>研究科学家</u></a>或<a href="https://jobs.lever.co/Anthropic/436ca148-6440-460f-b2a2-3334d9b142a5"><u>研究工程师</u></a>职位，并提及您对协调的兴趣！ </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn0a4ktd6g4bh"> <span class="footnote-back-link"><sup><strong><a href="#fnref0a4ktd6g4bh">^</a></strong></sup></span><div class="footnote-content"><p>例如， <a href="https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/">https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnn2il54kh7o"> <span class="footnote-back-link"><sup><strong><a href="#fnrefn2il54kh7o">^</a></strong></sup></span><div class="footnote-content"><p>例如，“<a href="https://arxiv.org/abs/2212.09251">通过模型编写的评估发现语言模型行为</a>”；佩雷斯等人。 2022.“<a href="https://arxiv.org/abs/2308.03958">简单的合成数据减少了大型语言模型中的阿谀奉承</a>”；杰里·韦等人。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnhnipjetlaaj"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhnipjetlaaj">^</a></strong></sup></span><div class="footnote-content"><p> <a href="https://www.alignmentforum.org/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to">科特拉</a>将此类模型称为<i>“阿谀奉承者”</i> ——它们似乎通过寻求短期人类认可而表现出色，但从长远来看，这些方式并不有益。例如，使用人类反馈来获取可靠的代码可能只会产生产生人类无法检测到的错误的模型。它还可以产生与用户一致的模型，而不是纠正事实错误。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnim1teg6bsg"> <span class="footnote-back-link"><sup><strong><a href="#fnrefim1teg6bsg">^</a></strong></sup></span><div class="footnote-content"><p>这实际上是克劳德 2 PM 明确提示不要那么阿谀奉承。为此，我们将文本添加到产品经理看到的人工助理对话中，其中用户明确要求最真实的答案。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnxivih3l3odg"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxivih3l3odg">^</a></strong></sup></span><div class="footnote-content"><p>我们识别的故障模式本身并不危险，但一些研究人员假设这种方法可能会利用人类评级中的缺陷或偏见，产生表面上看起来不错但实际上有问题的行为。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/g5rABd5qbp8B4g3DE/towards-understanding-sycophancy-in-language-models#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/g5rABd5qbp8B4g3DE/towards-understanding-sycophanancy-in-language-models<guid ispermalink="false"> g5rABd5qbp8B4g3DE</guid><dc:creator><![CDATA[Ethan Perez]]></dc:creator><pubDate> Tue, 24 Oct 2023 00:30:50 GMT</pubDate> </item><item><title><![CDATA[Manifold Halloween Hackathon]]></title><description><![CDATA[Published on October 23, 2023 10:47 PM GMT<br/><br/><p>您受邀参加由 Manifold 和 Lightcone 主办的万圣节黑客马拉松。提供午餐、小吃和晚餐。免费参加并向所有人开放！ </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6wmHeM3Nrk8CRJLub/lddena8plxs3n8lmfku8"></p><p><strong>地点</strong>: <a href="https://www.lighthaven.space/">Lighthaven Campus</a> , 2740 Telegraph Ave, Berkeley</p><p><strong>时间</strong>：10 月 27 日星期五上午 9 点至晚上 10 点</p><p><strong>内容</strong>：对您选择的任何项目进行黑客攻击</p><p>我们建议您从头开始！黑客马拉松是启动新项目或功能的绝佳机会</p><p>可以是工作用途，也可以是个人用途</p><p>不限于编码——你可以写、画、计划活动或其他任何东西</p><p>穿着服装或参与万圣节项目可获得奖励积分！</p><p></p><p><strong>大致时间表：</strong></p><p>上午9点：开球！讨论项目、组建团队、进行黑客攻击</p><p>中午：午餐</p><p>下午 3 点：休息和波巴跑</p><p>晚上 7 点：晚餐（与 AI Impacts 晚餐重叠）</p><p>晚上 9 点：演示！向大家展示一下你的成果吧~ </p><figure class="media"><div data-oembed-url="https://manifold.markets/Austin/manifold-halloween-hackathon-fri-oc"><div class="manifold-preview"><iframe src="https://manifold.markets/embed/Austin/manifold-halloween-hackathon-fri-oc"></iframe></div></div></figure><br/><br/> <a href="https://www.lesswrong.com/events/6wmHeM3Nrk8CRJLub/manifold-halloween-hackathon#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/events/6wmHeM3Nrk8CRJLub/manifold-halloween-hackathon<guid ispermalink="false"> 6wmHeM3Nrk8CRJLub</guid><dc:creator><![CDATA[Austin Chen]]></dc:creator><pubDate> Mon, 23 Oct 2023 22:47:18 GMT</pubDate> </item><item><title><![CDATA[Open Source Replication & Commentary on Anthropic's Dictionary Learning Paper]]></title><description><![CDATA[Published on October 23, 2023 10:38 PM GMT<br/><br/><h2>介绍</h2><p>Anthropic 最近发表了<a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html">一篇非常酷的论文，内容</a>是关于使用稀疏自动编码器 (SAE) 从 1L 语言模型的 MLP 层的叠加中提取可解释的特征。我认为这是一篇很棒的论文，我对 SAE 的潜力感到兴奋，它可以更广泛地用于机械解释，并看到它们的扩展效果如何！这篇文章记录了我对他们的论文所做的复制，以及在此基础上进行的一些小探索，以及（杂乱的！）一些经过训练的自动编码器的<a href="https://github.com/neelnanda-io/1L-Sparse-Autoencoder">训练代码</a>和权重。</p><p>请参阅<a href="https://colab.research.google.com/drive/1u8larhpxy8w4mMsJiSBddNOzFGj7_RTn?usp=sharing"><strong><u>随附的 Colab 教程</u></strong></a>来加载经过训练的自动编码器，以及如何解释功能的演示。</p><h2>总长DR</h2><ul><li>核心结果似乎是重复的 - 我在开源 1 层 GELU 语言模型的 MLP 层上训练了一个稀疏自动编码器，并且很大一部分潜在空间特征是可解释的<ul><li>我开源了两个训练有素的自动编码器，这里有 <a href="https://colab.research.google.com/drive/1u8larhpxy8w4mMsJiSBddNOzFGj7_RTn?usp=sharing"><u>一个关于如何使用它们以及如何解释功能的教程</u></a>。<ul><li>以及（非常！）粗略的<a href="https://github.com/neelnanda-io/1L-Sparse-Autoencoder"><u>训练代码库</u></a></li></ul></li><li>我提供了一些实施细节以及培训您自己的技巧。</li></ul></li><li>我研究了解码器权重在神经元基础上的稀疏程度，发现它们高度分布，其中 4% 由单个神经元很好地解释，4% 由 2 到 10 个神经元很好地解释，其余 92% 是密集的。我觉得这很令人惊讶！<ul><li>峰度表明神经元基础仍然具有优势。</li></ul></li><li>我展示了我发现的特征的一些案例研究，例如标题特征和“和我”特征</li><li>我没有发现任何死特征，但超过一半的特征形成超低频簇（频率小于1e-4）。令人惊讶的是，我发现这个集群几乎都是<i>相同的</i>特征（就编码器权重而言，但不是就解码器权重而言）。一次输入即可触发 95% 的这些极其罕见的功能！<ul><li>相同<i>&nbsp;</i>方向在随机种子中形成，表明这是模型的真实情况，而不仅仅是自动编码器工件</li><li>我无法解释什么<i>&nbsp;</i>这个共同的方向是</li><li>我尝试通过训练自动编码器与这个方向正交来解决这个问题，但它仍然形成一个超低频集群（所有集群都在一个新方向上）</li></ul></li><li>编码器和解码器应该绑定吗？我发现，根据经验，每个特征的解码器和编码器权重略有不同，中值余弦 sim 仅为 0.5，这是经验证据，它们正在做不同的事情，不应该捆绑在一起。<ul><li>从概念上讲，编码器和解码器正在做不同的事情：编码器正在<i>检测</i>，找到投影到检测特征的最佳方向，最小化与其他类似特征的干扰，而解码器正在尝试<i>表示</i>该特征，并尝试近似无论任何干扰如何，“真实”特征方向。</li></ul></li></ul><h2>特征</h2><h3>探索神经元稀疏性</h3><p>我发现这篇论文最有趣的事情之一是非神经元基础对齐特征的存在。机械可解释性的一大谜团（在我看来）是 MLP 层中的非线性实际上在算法层面上做了什么。我可以相当容易地推理单语义 GELU 神经元（就像法国神经元一样）——本质上将其视为软 ReLU，收集某个特征存在的证据，并在它们超过某个阈值（由偏差给出）时触发）。这也许可以扩展到考虑神经元的稀疏线性组合（例如，少于 10 个神经元建设性地干扰创建单个特征）。但我不知道如何推理神经元基础上密集的事物！</p><p>作为探索这一点的第一步，我研究了每个非超低频特征的密集与稀疏程度。从概念上讲，我期望许多神经元相当稀疏 - 既因为我期望可解释的特征一般来说往往是神经元稀疏的，也因为自动编码器设置：在任何给定的输入上都会触发一组稀疏的神经元，因此学习似乎特定神经元/神经元簇是一个有用的字典特征。</p><p> However, a significant majority of features seem to be fairly dense in the neuron basis! As a crude metric, for each dictionary feature, I took the sum of squared decoder weights, and looked at the fraction explained by the top neuron (to look for 1-sparse features), and by the next 9 neurons (to look for 10-ish-sparse features). I use decoder rather than encoder, as I expect the decoder is closer to the “true” feature direction (ie how it&#39;s computed) while the encoder is the subtly different “optimal projection to detect the feature” which must account for interference. In the scatter plot below we can see 2-3 rough clusters - dense features near the origin (low on both metrics, which I define as fve_top_10&lt;0.35), 1-sparse features (fve_top_1>;0.35, fve_next_9&lt;0.1), and 10-ish-sparse features (the diffuse mess of everything else). I find ~92.1% of features are dense, ~3.9% are 1-sparse and ~4.0% are 10-ish-sparse. </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fKuugaxt2XLTkASkk/wpk2gln6ioxxlqwjvfo6"></p><p> Another interesting metric is neuron kurtosis, ie taking the decoder weights for each feature (in the MLP neuron basis) and taking the kurtosis (metric inspired by <a href="https://transformer-circuits.pub/2023/privileged-basis/index.html"><u>this paper</u></a> , and by ongoing work with Wes Gurnee). This measures how “privileged” the neuron basis is, and is another way to detect unusually neuron-sparse features - the (excess) kurtosis of a normal distribution is zero, and applying an arbitrary rotation makes everything normally distributed. We can clearly see in the figure below that the neuron basis is privileged for almost all features, even though most features don&#39;t seem neuron-sparse (red are real features, blue is the kurtosis of a randomly generated normally distributed baseline. Note that the red tail goes up to 1700 but is clipped for visibility). </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fKuugaxt2XLTkASkk/avmar6egpmqru1hroqyc"></p><p> I haven&#39;t studied whether there&#39;s a link between level of neuron sparsity and interpretability, and I can&#39;t rule out the hypothesis that autoencoders learn features with significant noise and that the “true” feature is far sparser. But this seems like evidence that being dense in the neuron basis is the norm, not the exception.</p><h3>实例探究</h3><p>Anecdotally a randomly chosen feature was often interpretable, including some fairly neuron dense ones. I didn&#39;t study this rigorously, but of the first 8 non-ultra-low features 6 seemed interpretable. From this sample, I found:</p><ul><li> A title case/headline feature, that was dominated by a single neuron and boosted the logits for tokens beginning with a capital or that come in the middle of words</li><li> A “connective followed by pronoun” feature that activated on text like “and I” and boosts the `&#39;ll` logit <ul><li><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fKuugaxt2XLTkASkk/y7kf6h3q5ruhn85hno0j"></li></ul></li><li> Some current token based features, eg one that activates on ` though` and one that activates on ` (“`</li><li> A previous token based feature, that activates on the token after de/se/le (preference for ` de`)</li></ul><h2> Ultra Low Frequency Features Are All The Same Feature</h2><p> <strong>Existence of the ultra-low frequency cluster</strong> : I was able to replicate the paper&#39;s finding of an <a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html#appendix-feature-density"><u>ultra-low frequency cluster</u></a> , but didn&#39;t find any truly dead neurons. I define the ultra-low frequency cluster as anything with frequency less than 1e-4, and it is clearly bimodal, with about 60% of features as ultra-low frequency and 40% as normal. This is in contrast to 4% dead and 7% ultra-low in the A/1 autoencoder, I&#39;m not sure of why there&#39;s a discrepancy, though it may be because I resampled neurons with re-initialising weights rather than the complex scheme in the paper. Anecdotally, the ultra-low frequency features were not interpretable, and are not very important for autoencoder performance (reconstruction loss goes from 92% to 91%) </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fKuugaxt2XLTkASkk/rqasgg2w9cqgqxwearnu"></p><p> <strong>The encoder weights are all the same direction</strong> : Bizarrely, the ultra-low frequency entries in the dictionary are all the <i>same</i> direction. They have extremely high cosine sim with the mean (97.5% have cosine sim more than 0.95) </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fKuugaxt2XLTkASkk/lztvxe49k99q0nmdvjec"></p><p> Though they vary in magnitude, as can be seen from their projection onto the mean direction (I&#39;m not sure why this is bimodal). (Note that here I&#39;m just thinking about |encoder|, and really |encoder| * |decoder| is the meaningful property, but that gets a similar distribution) </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fKuugaxt2XLTkASkk/xox07tfxks35mj3vpt58"></p><p> This means the ultra low features are highly correlated with each other, eg I found one data point that&#39;s extreme in the mean direction where 95% of the ultra low features fired on it</p><p> <strong>The decoder weights are</strong> <i><strong>not</strong></i> <strong>all the same direction</strong> : On the other hand, the decoder weights seem all over the place! Very little of the variance is explained by a single direction. I&#39;m pretty confused by what&#39;s going on here.</p><p> <strong>The encoder direction is consistent across random seeds:</strong> The natural question is whether this direction is a weird artefact of the autoencoder training process, or an actual property of the transformer. Surprisingly, training another autoencoder with a different random seed finds the same direction (cosine sim 0.96 between the means). The fact that it&#39;s consistent across random seeds makes me guess it&#39;s finding something true about the autoencoder.</p><p> <strong>What does the encoder direction mean?</strong> I&#39;ve mostly tried and failed to figure out what this shared feature means. Things I&#39;ve tried:</p><ul><li> Inspecting top dataset examples didn&#39;t get much pattern, and it drops when seemingly non-semantic edits are made to the text.</li><li> It&#39;s not sparse in the neuron basis</li><li> It&#39;s output weights aren&#39;t sparse in the vocab basis (though correlates with “begins with a space)</li><li> It&#39;s nothing to do with the average MLP activation, or MLP activation singular vectors, or MLP acts being high norm</li></ul><p> A sample of texts where the average feature fires highly: </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fKuugaxt2XLTkASkk/p2xk8tyildwp4cn4v5vy"></p><p> <strong>Can we fix ultra-low frequency features?</strong> These features are consuming 60% of my autoencoder, so it&#39;d be great if we could get rid of them! I tried the obvious idea of forcing the autoencoder weights to be orthogonal to this average ultra low feature direction at each time step, and training a new autoencoder. Sadly, this autoencoder had its own cluster of ultra-low frequency features, which also had significant cosine sims with each other, but a different direction.</p><p> <strong>Phase transition in training for feature sparsity:</strong> Around 1.6B tokens, there was a seeming phase transition where ultra low density features started becoming more common. I was re-initialising the weights every 120M tokens for features of frequency less than 1e-5, but I found that around 1.6B (the 13th ish reset) they started to drift upwards in frequency, and at some point crossed the 1e-5 boundary (which broke my resetting code!). By 2B tokens they were mostly 1e-4.5 to 1e-4, still a distinct mode, but drifting upwards. It&#39;s a bit hard to tell, but I don&#39;t <i>think</i> there was a constant upward drift, it seems to only happen in late training, based on inspecting checkpoints</p><p> (Figure note: the spike at -6.5 corresponds to features that never fire) </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fKuugaxt2XLTkASkk/imecpre9rzgtcqji2pyq"></p><h2> Implementation Details</h2><ul><li> The model was gelu-1l, available via <a href="https://github.com/neelnanda-io/TransformerLens"><u>the TransformerLens library</u></a> . It has 1 layer, d_model = 512, 2048 neurons and GELU activations. It was trained on 22B tokens, a mix of 80% web text (C4) and 20% Python code</li><li> The autoencoders trained in about 12 hours on a single A6000 on 2B tokens. They have 16384 features, and L1 regularisation of 3e-3<ul><li> The reconstruction loss (loss when replacing the MLP layer by the reconstruction via the autoencoder) continued to improve throughout training, and got to 92% (compared to zero ablating the MLP layer).<ul><li> For context, mean ablation gets 25%</li></ul></li></ul></li><li> <strong>Getting it working:</strong><ul><li> My first few autoencoders failed as L1 regularisation was too high, this showed up as almost all features being dead</li><li> When prototyping and training, I found it useful to regularly compute the following metrics:<ul><li> The autoencoder loss (when reconstructing the MLP acts)</li><li> The reconstruction loss (when replacing the MLP acts with the reconstructed acts, and looking at the damage to next token prediction loss)</li><li> Feature frequency (including the fraction of dead neurons), both plotting histograms, and crude measures like “frac features with frequency &lt; 1e-5” or 1e-4</li></ul></li><li> I implemented neuron resampling, with two variations:<ul><li> I resampled any feature with frequency &lt; 1e-5, as I didn&#39;t have many truly dead features, and the ultra-low frequency features seemed uninterpretable - this does have the problem of preventing my setup from learning true ultra-low features though.</li><li> I took the lazy route of just re-initialising the weights</li></ul></li><li> I lacked the storage space to easily precompute, shuffle and store neuron activations for all 2B tokens. I instead maintained a buffer of acts from 1.5M prompts of 128 tokens each, shuffled these and then took autoencoder training batches from it (of batch size 4096). When the buffer was half empty, I refilled it with new prompts and reshuffled.<ul><li> I was advised by the authors that it was important to minimise autoencoder batches having tokens from the same prompt, this mostly achieved that though tokens from the same prompt would be in nearby autoencoder batches, which may still be bad.</li></ul></li></ul></li><li> <strong>Bug:</strong> I failed to properly fix the decoder to be norm 1. I removed the gradients parallel to the vector, but did <i>not</i> also reset the norm to be norm 1. This resulted in a decoder norm with some real signal, and may have affected my other results <ul><li><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fKuugaxt2XLTkASkk/lyezcrzhuq1e1o1slptf"></li></ul></li></ul><h2> Misc Questions</h2><p> <strong>Should encoder and decoder weights be tied?</strong> In this paper, the encoder and decoder weights are untied, while in <a href="https://arxiv.org/abs/2309.08600"><u>Cunningham et al</u></a> they&#39;re tied (tied meaning W_dec = W_enc.T). I agree with the argument given in this paper that, conceptually, the encoder and decoder are doing different things and should not be tied. I trained my autoencoders with untied encoder and decoder.</p><p> My intuition is that, for each feature, there&#39;s a “representation” direction (its contribution when present) and a “detection” direction (what we project onto to recover that feature&#39;s coefficient). There&#39;s a sparse set of active features, and we expect the MLP activations to be well approximated by a sparse linear combination of these features and their representation direction - this is represented by the decoder. To extract a feature&#39;s coefficient, we need to project onto some direction, the detection direction (represented by the encoder). Naively, this is equal to representation direction (intuitively, the dual of the vector). But this only makes sense if all representation directions are orthogonal! We otherwise get interference from features with non-zero cosine sim between representations, and the optimal detection direction is plausibly different. Superposition implies more directions than dimensions, so they can&#39;t all be orthogonal!</p><p> As some empirical evidence, we can check whether in practice the autoencoder “wants” to be tied by looking at the cosine sim between each feature&#39;s encoder and decoder weights. The median (of non ultra low features) is 0.5! There&#39;s some real correlation, but the autoencoder seems to prefer to have them not be equal. It also seems slightly bimodal (a big mode centered at 0.5 and one at 0.75 ish), I&#39;m not sure why. </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fKuugaxt2XLTkASkk/arr4oovzrr9b4hyt07jm"></p><p> <strong>Should we train autoencoders on the MLP output?</strong> One weird property of transformers is that the number of MLP neurons is normally significantly larger than the number of residual stream dimensions (2048 neurons, 512 residual dims for this model). This means that 75% of the MLP activation dimensions are in the nullspace of W_out (the output weights of the MLP layer, ie the down-projection) and so cannot matter causally for the model.</p><p> Intuitively, this means that a lot of the autoencoder&#39;s capacity is wasted, representing the part of the MLP activations that doesn&#39;t matter causally. A natural idea is to instead train the autoencoder on the MLP output (after applying W_out). This would get an autoencoder that&#39;s 4x smaller and takes 4x less compute to run (for small autoencoders the cost of running the model dominates, but this may change for a very wide autoencoder). My guess is that W_out isn&#39;t going to substantially change the features present in the MLP activations, but that training SAEs on the MLP output is likely a good idea (I sadly only thought of this after training my SAEs!)</p><p> Unsurprisingly, a significant fraction of each encoder and decoder weight is representing things in the null-space of W_out. Note that it&#39;s significantly higher variance and heavier tailed than it would be for a random 512 dimensional subspace (a random baseline has mean 0.75 and std 0.013), suggesting that W_out is privileged (as is intuitive). </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fKuugaxt2XLTkASkk/eyolsnsio0k6wdu656v4"></p><p><br></p><br/><br/> <a href="https://www.lesswrong.com/posts/fKuugaxt2XLTkASkk/open-source-replication-and-commentary-on-anthropic-s#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/fKuugaxt2XLTkASkk/open-source-replication-and-commentary-on-anthropic-s<guid ispermalink="false"> fKuugaxt2XLTkASkk</guid><dc:creator><![CDATA[Neel Nanda]]></dc:creator><pubDate> Mon, 23 Oct 2023 22:38:35 GMT</pubDate> </item><item><title><![CDATA[AI Alignment [Incremental Progress Units] this Week (10/22/23)]]></title><description><![CDATA[Published on October 23, 2023 8:32 PM GMT<br/><br/><p>抱歉迟了一天才把这个发出来。</p><p>在开始之前，先进行一个小更新。我喜欢大卫·奥尔的<a href="https://www.lesswrong.com/posts/zkDCCSR3o2aBkTcbq/ai-alignment-incremental-progress-units-this-week-10-08-23?commentId=oKYxLnkjEMfNwoTQq">建议</a>，即明星 ⭐ 太普通了。因此，为了强调我正在评估一个主题的创新性（不一定是其质量），我将用灯泡💡来评估突破性。</p><p>提醒一下，1 💡的评级意味着突破，虽然实现新的最先进技术主要是通过可预测的迭代改进（例如组合已知方法或更大规模地应用现有方法）来完成的。评级为 5 💡💡💡💡💡 意味着至少在对齐路径上解决了一个重大的、以前被认为是困难的问题的突破。</p><p>话不多说，这是我们的</p><h1>本周人工智能对齐取得突破</h1><p></p><p>本周在以下领域取得了突破：</p><p>理解人类</p><p>标杆管理</p><p>人工智能代理</p><p>真实的人工智能</p><p>学习人类偏好</p><p>数学</p><p>机械可解释性</p><p>增强</p><p>让人工智能做我们想做的事</p><p>人工智能艺术</p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe63f0939-cfb2-49d3-8687-9bf91fa30af0_1792x1024.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe63f0939-cfb2-49d3-8687-9bf91fa30af0_1792x1024.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe63f0939-cfb2-49d3-8687-9bf91fa30af0_1792x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe63f0939-cfb2-49d3-8687-9bf91fa30af0_1792x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe63f0939-cfb2-49d3-8687-9bf91fa30af0_1792x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe63f0939-cfb2-49d3-8687-9bf91fa30af0_1792x1024.png 1456w"></a></p><p></p><p></p><h1>理解人类</h1><p></p><p><a href="https://www.sciencealert.com/human-consciousness-could-be-a-side-effect-of-entropy-study-suggests">熵导致的人类意识</a></p><p>它是什么：研究表明人类意识可能与我们内部精神状态的熵有关</p><p>最新消息：研究人员使用 MRI 来测量有意识/无意识状态下的大脑活动，发现有意识状态表现出更高的熵</p><p>它有什么好处：从字面上看，在理解意识这个难题上的任何进展都将是一个巨大的突破，并对<a href="https://www.lesswrong.com/tag/risks-of-astronomical-suffering-s-risks">S-Risk</a>等问题产生影响</p><p>评级：💡💡💡（我想给它很高的评价，因为这是一个非常重要的问题，但我对这项特定的研究并没有太印象深刻。我认为<a href="https://iep.utm.edu/integrated-information-theory-of-consciousness/">IIT</a>会预测到这一点）</p><p><a href="https://twitter.com/emollick/status/1716150138027094177">美丽的信息图表获得更多引用</a></p><p>它是什么：研究表明美丽的信息图表更容易被相信和引用</p><p>新变化：他们将数据处理得更漂亮，并发现它的评级更高</p><p>它有什么好处：了解人类如何评估研究是弄清楚如何让我们变得更好的关键一步。</p><p>评价：💡💡</p><h1>标杆管理</h1><p></p><p><a href="https://twitter.com/AIatMeta/status/1715041427283902793">基因基准测试</a></p><p>它是什么：衡量人工智能模型泛化能力的新基准</p><p>新变化：他们识别不同类别的“泛化”，并衡量人工智能在每个类别上的表现</p><p>它有什么好处：测量人工智能能力（尤其是泛化能力）对于战略性人工智能暂停等计划至关重要。</p><p>评价：💡</p><p><a href="https://twitter.com/_akhaliq/status/1712639154301894882">人工智能智商测试</a></p><p>它是什么：研究找到了一种衡量语言模型整体“智能”的方法</p><p>新消息：他们发现语言模型表现出类似于人类 Spearman 的<a href="https://en.wikipedia.org/wiki/G_factor_(psychometrics)">G 因子</a>的共同因子</p><p>它有什么好处：最好对“人类水平”人工智能有一个科学的定义，而不仅仅是当前的启发式：它可以做人类能做的任何事情。</p><p>评价：💡💡💡</p><p></p><h1>人工智能代理</h1><p></p><p><a href="https://twitter.com/johnjnay/status/1713668697028530539">具有可证明后悔保证的法学硕士代理人</a></p><p>它是什么：使用“遗憾”的概念增强 AI 代理规划</p><p>新功能：一个新的可证明的 reget 框架</p><p>它有什么好处：让我们能够更好地控制人工智能代理并确保它们不犯错误。</p><p>评价：💡💡💡</p><p><a href="https://twitter.com/_akhaliq/status/1715183455850410013">代理调优</a></p><p>它是什么：微调法学硕士，使其成为更好的人工智能代理</p><p>新动态：新的 SOTA 性能</p><p>它有什么好处：更好的人工智能代理对于诸如因子认知之类的对齐路径很有用。</p><p>评价：💡</p><h1>真实的人工智能</h1><p></p><p><a href="https://twitter.com/_akhaliq/status/1714859929268256790">自我RAG</a></p><p>它是什么：提高检索增强生成的真实性</p><p>新变化：他们训练人工智能自适应地检索文档以提高事实回忆</p><p>它有什么好处：拥有事实上正确且引用来源的人工智能对于几乎所有对齐路径都很有用</p><p>评价：💡💡</p><p><a href="https://twitter.com/_akhaliq/status/1713785366509965702">共识游戏</a></p><p>它是什么：调和不连贯的人工智能预测</p><p>新变化：他们设计了一种新的“共识游戏”，使人工智能能够得出逻辑上一致、更准确的结论</p><p>它有什么好处：几乎所有对齐路径都需要真实、准确的人工智能</p><p>评级：💡💡💡💡（我真的认为来年我们会看到很多涉及人工智能自我对战概念的重要突破）</p><p><a href="https://twitter.com/__Charlie_G/status/1715457808156516558">因素验证</a></p><p>它是什么：一种改进人工智能摘要的方法</p><p>新变化：通过将摘要分解为单独的声明，每个声明都可以得到独立验证</p><p>它的好处是什么：准确总结文档。如果我们希望人工智能能够“快速为我总结这个计划”，这一点就很重要。</p><p>评价：💡</p><h1>学习人类偏好</h1><p></p><p><a href="https://twitter.com/AlexTamkin/status/1715040019520569395">用语言模型引发人类偏好</a></p><p>它是什么：为 AI 模型编写“提示”的更好方法</p><p>新变化：通过与用户交互，生成式人工智能可以生成比人类或人工智能更好的提示</p><p>它有什么好处：现在很多人工智能在很大程度上依赖于“即时工程”，人类必须学习如何用人工智能理解的方式表达他们的愿望。我们的目标应该是扭转这一局面，让人工智能尝试理解人类的偏好。</p><p>评价：💡💡</p><p><a href="https://twitter.com/arankomatsuzaki/status/1716270259869753679">对比偏好学习</a></p><p>它是什么：没有 RL 的 RLHF</p><p>新变化：通过最小化“遗憾”分数，他们可以更好地了解人类偏好</p><p>它有什么好处：了解人类偏好是许多人工智能调整计划的关键路径。</p><p>评价：💡💡</p><p><a href="https://twitter.com/TianbaoX/status/1715404344320049554">文字2奖励</a></p><p>它是什么：一种将用户反馈转换为 RL 模型可以使用的分数的方法</p><p>新功能：一种将自然语言描述的目标转换为强化学习器可以使用的可执行程序的新方法</p><p>它有什么好处：允许我们使用文字向机器人发出指令，而不是通过物理方式向它们展示我们希望它们做什么。</p><p>评价：💡💡💡</p><h1>数学</h1><p></p><p><a href="https://twitter.com/andrew_n_carr/status/1714326003030638848">通过更好的标记化改进数学</a></p><p>它是什么：我们知道<a href="https://simonwillison.net/2023/Jun/8/gpt-tokenizers/">标记化</a>会给语言模型带来很多问题（例如在学习写单词反义词或计算字母数量时）</p><p>新动态：毫不奇怪，这也是一个数学问题</p><p>它有什么好处：理想情况下我们很快就能转向字节级模型（现在训练大注意力窗口的问题正在逐渐得到解决）</p><p>评级：💡（每个人都知道这一点，但很高兴有更多确认）</p><p> <a href="https://twitter.com/zhangir_azerbay/status/1714098025956864031">Llemma：开放 LM 进行数学训练</a></p><p>它是什么：法学硕士在更好的数学数据集上接受训练</p><p>新变化：更好的数据=更好的结果</p><p>它有什么好处：解决数学问题是依赖可证明安全的人工智能的协调计划的关键路径</p><p>评价：💡</p><p><a href="https://twitter.com/DynamicWebPaige/status/1715956125001224461">运行时错误预测</a></p><p>它是什么：经过专门训练来预测程序将如何运行以及何时会遇到错误的语言模型</p><p>新增内容：该模型的架构类似于代码解释器</p><p>它有什么好处：预测程序的输出应该会生成更好的代码/证明。</p><p>评价：💡💡💡</p><h1>机械可解释性</h1><p></p><p><a href="https://twitter.com/jfischoff/status/1714724620090441787">解释扩散模型</a></p><p>它是什么：研究人员在扩散模型中找到了可解释的“方向”</p><p>新变化：他们应用了之前在 GAN（另一种类型的图像生成模型）上使用的方法来解释扩散器</p><p>它有什么好处：让我们更好地理解/控制扩散模型</p><p>评价：💡</p><p><a href="https://twitter.com/aaquib_syed1/status/1714386165237776653">归因修补</a></p><p>它是什么：在法学硕士中寻找不可解释的子网络</p><p>新增内容：用于查找这些电路的更有效的新算法</p><p>它的好处：让我们更好地理解法学硕士</p><p>评价：💡💡💡</p><p></p><p><a href="https://twitter.com/saprmarks/status/1713889037902041292">真值方向提取</a></p><p>它是什么：找到一种方法来区分法学硕士嵌入空间中的真假陈述</p><p>新内容：这里有一些工作可以区分真/假和可能/不可能。他们还对用于发现这个概念的回归进行了一些改进</p><p>它有什么好处：找到这样的概念是我们通常需要擅长的事情，而真/假就是一个特别重要的例子。</p><p>评价：💡</p><p></p><p> <a href="https://www.lesswrong.com/posts/4Hnso8NMAeeYs8Cta/revealing-intentionality-in-language-models-through-adavae">揭示语言模型中的意向性</a></p><p>它是什么：一种确定人工智能是否“意图”某事的方法，例如“故意对我撒谎”</p><p>新内容：似乎主要是一个新的哲学框架</p><p>它有什么好处：我认为对于法学硕士来说，“意图”的概念是不连贯/拟人化的，但这里的一些技术似乎有实际用途。</p><p>评价：💡💡</p><p><a href="https://twitter.com/arankomatsuzaki/status/1716269937264861578">理解语言模型中的阿谀奉承</a></p><p>它是什么：法学硕士有一个已知的问题，他们总是同意用户的观点</p><p>新变化：他们发现针对人类偏好进行优化使得法学硕士更有可能“说你想听的话”</p><p>它有什么好处：知道你有问题是第一步。</p><p>评价：💡</p><h1>增强</h1><p></p><p><a href="https://twitter.com/AIatMeta/status/1714635316554772716">解码图像感知</a></p><p>它是什么：我们可以通过读取人们的脑电波来预测他们所看到的内容</p><p>新变化：看起来质量比过去的例子更好</p><p>它有什么好处：脑机接口是人工智能对齐的一种途径</p><p>评价：💡💡</p><p></p><p><a href="https://twitter.com/ShiqiZhang7/status/1713613362452381917">导视之眼四足导航</a></p><p>它是什么：“导盲犬”机器人</p><p>新变化：他们训练机器人检测用户何时“拉动”皮带</p><p>有什么好处：帮助盲人</p><p>评价：💡</p><h1>让人工智能做我们想做的事</h1><p></p><p><a href="https://twitter.com/skalskip92/status/1715322791333855550">添加标签有助于GPT-4V</a></p><p>它是什么：一种更好地促进视觉模型的方法</p><p>新功能：在将图像提供给 GPT-4V 之前为其添加标签使其更加有用</p><p>它有什么用处：您给自行车拍了一张照片，想知道哪个部件需要修理。</p><p>评价：💡💡</p><p><a href="https://twitter.com/rsasaki0109/status/1715664168442003580">激光雷达合成</a></p><p>它是什么：用于自动驾驶汽车的改进激光雷达</p><p>新变化：通过人工智能标记数据，我们可以用更少的人工标记数据训练更好的激光雷达</p><p>它有什么好处：每年有 3 万美国人死于车祸</p><p>评价：💡💡</p><h1>人工智能艺术</h1><p></p><p><a href="https://twitter.com/jfischoff/status/1715241550589161836">封闭形式扩散模型</a></p><p>它是什么：无需训练模型即可生成图像</p><p>新功能：一种新的封闭形式，可以“平滑”数据点之间的潜在空间</p><p>它有什么好处：训练文本到图像模型非常昂贵。如果这有效，也许我们可以完全跳过它。还可以解锁“混合”方法，我们可以将新图像添加到扩散模型中，而无需重新训练它。</p><p>评价：💡💡💡💡</p><p><a href="https://twitter.com/camenduru/status/1714733762838175929">潜在一致性模型</a></p><p>它是什么：更快的图像生成器</p><p>新变化：潜在一致性模型的训练速度比以前的加速图像扩散模型的方法更快</p><p>它有什么好处：图片更漂亮<a href="https://twitter.com/andrewb10687674/status/1715437476750209281">更快</a>。</p><p>评价：💡💡💡💡</p><p> <a href="https://twitter.com/natanielruizg/status/1714271503653703856">RealFill（使用参考图像进行绘制）</a></p><p>它是什么：使用参考图像来绘制图像</p><p>新变化：比以前的方法有很大改进</p><p>它的好处是什么：拍照并扩展它，但控制扩展区域中的内容</p><p>评价：💡💡💡</p><h1>这不是人工智能对齐</h1><p></p><p><a href="https://twitter.com/alexeyguzey/status/1715399223993065943">对齐是否进行得太顺利？</a></p><p>它是什么：人工智能安全研究人员似乎出现了反对人工智能对齐研究的<a href="https://www.lesswrong.com/posts/Eu8y4cTxM3pAzwdCf/i-would-have-solved-alignment-but-i-was-worried-that-would">新趋势</a>。</p><p>是什么意思：看起来很糟糕。不想解决一致性问题的人工智能安全研究人员让我想起了<a href="https://www.cnbc.com/2023/04/18/germany-shuts-down-last-nuclear-power-plants-some-scientists-aghast.html">反对</a>核电站的“气候活动家”。</p><p><a href="https://twitter.com/Lauramaywendel/status/1713949264336847318">人工智能夺走了我们（子堆栈）的工作</a></p><p>它是什么：Substack 员工可能是第一批可以合理地说“人工智能抢走了我们的工作”的人</p><p>这意味着什么：有才华的软件工程师将会站稳脚跟，但当我们开始取代<a href="https://twitter.com/engineers_feed/status/1715719328090464606">非熟练劳动力</a>时，对社会的影响将会更大。</p><p><a href="https://twitter.com/emollick/status/1716156085445239265">大多数首席执行官不鼓励人工智能的使用</a></p><p>它是什么：研究显示首席执行官不希望员工使用人工智能，因为“他们不完全理解它”。</p><p>这意味着什么：这是 50% 的卢德主义，50% 是在提醒人们，对齐研究是解锁 AI 功能的限速步骤。</p><br/><br/> <a href="https://www.lesswrong.com/posts/2TBTjychCgn2nyYZA/ai-alignment-incremental-progress-units-this-week-10-22-23#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/2TBTjychCgn2nyYZA/ai-alignment-incremental-progress-units-this-week-10-22-23<guid ispermalink="false"> 2TBTjychCgn2nyYZA</guid><dc:creator><![CDATA[Logan Zoellner]]></dc:creator><pubDate> Mon, 23 Oct 2023 20:32:41 GMT</pubDate> </item><item><title><![CDATA[z is not the cause of x]]></title><description><![CDATA[Published on October 23, 2023 5:43 PM GMT<br/><br/><h1>介绍</h1><p>在这篇文章中，我认为将表征（心理或机器学习）解释为<i>观察到的效果的原因</i>，对于因果关系的任何合理定义都是错误的。这种解释似乎有些普遍，尽管并不普遍。我提出一种基于二元论的新解释。在新的解释中，表象是<i>后续表象的原因</i>。其要点如图所示，时间或因果关系沿 x 轴流动，表示级别沿 y 轴流动。这种重新解释对科学和常识意义上的更广泛的“真理”概念都有影响。</p><p>我在考虑大型语言模型时部分得出了这个结论。它们让我越来越质疑理解、推理或知道某事意味着什么。事实上，我几年前就以稍微不同的形式问过这个问题：机器学习的基础是什么，是否存在我们试图通过 SGD 和正则化发现的“真实模型”之类的东西？怎样才能“良好”地表示数据？</p><p>一个以某种形式不断出现的答案是，一个好的表示<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>应该发现观测数据<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>的<i>因果因素</i>。当我研究 Kingma 和 Welling 的原始<a href="https://arxiv.org/pdf/1312.6114.pdf">变分自动编码器论文</a>时，这个问题对我来说变得尤为尖锐。顺便说一句，变分自动编码器 (VAE) 是一对称为<i>生成</i>模型（将<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span>映射到<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> ）和<i>识别模型</i>（将<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>映射到<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span> ）的模型，它们通常在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>的数据集上相互协同训练。在研究了这篇论文很长时间之后，在我看来，人们可以训练 VAE 并任意拟合数据分布，而隐藏变量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span>根本没有任何<i>意义</i>。事实上，他们在论文中没有提到<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span>是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>的<i>因果因素</i>。而且，尽我所能，我在数学中找不到任何<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span>可能具有新意义的东西。</p><p>但为什么<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span>应该具有“意义”呢？该模型只是使用这些隐藏变量作为数学工具来创建<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>上的灵活边际分布。经过反思，我感到惊讶的唯一原因是因为我认为 VAE 是人类认知的模型，而且我们知道人类会构建有意义的表示，并且以某种类似于 VAE 的无监督方式来实现。</p><p> VAE 论文提出了一种技术，也许对将其与代理的解释联系起来不太感兴趣，所以它不关心因果解释是可以理解的。早期的著作，卡尔·弗里斯顿（Karl Friston）的经典论文<a href="https://www.fil.ion.ucl.ac.uk/~karl/Learning%20and%20inference%20in%20the%20brain.pdf">《大脑中的学习和推理》</a>确实持有这种解释。它指出（强调我的）：</p><blockquote><p> 3.2<i>生成模型和表征学习</i></p><p>在本小节中，我们将介绍人们可以理解学习和推理的基本框架。该框架依赖于生成和识别模型，这些模型只是将<strong>原因</strong>映射到感官输入的函数，反之亦然。</p></blockquote><p>使用 Kingma 和 Welling 的符号，其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="q"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em; padding-right: 0.014em;">q</span></span></span></span></span></span></span>是识别模型，根据 Friston 的解释， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="q(z|x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em; padding-right: 0.014em;">q</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>的任务是推断<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span><i>的</i><i>潜在原因</i><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span> 。在这篇简短的说明中，我认为这是错误的，但它非常接近正确，因此我不希望这种语言消失。然而，我认为这会导致潜在的混乱，对机器学习中的可解释性和认识论产生影响。</p><h1>两个独立的领域</h1><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iYevftcfEDaqAy2c5/slt7ydlczniiq7thbt0f" alt="An attempt to reconcile causality as understood both physically and metaphorically.  x-axis: time; y-axis lower panel:  the physical realm, symbolized by phase space .  upper panel:  the platonic realm, which contains non-physical, or platonic, entities.  These include mental or machine learning representations"></p><p>我认为将<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span>解释为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>的因果因素会导致混乱。为了证实这一主张，首先，我们必须承认物理世界仅由粒子、力和时空组成，除此之外<i>别无其他</i>。而且，抽象世界虽然受到物理世界的支持和嵌入，但处于不同的非物理领域。具体来说：“ <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\pi"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">π</span></span></span></span></span></span></span>存在吗？”这个问题。可以回答：“是的 - 每当有人思考<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\pi"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">π</span></span></span></span></span></span></span>时，这个过程实际上就以特定的时空切片的形式存在，在这个时空切片中，神经元放电发生在某人的大脑中。”但这不是一个有意义的答案。或者，如果你从物理上解释这个问题，答案可能是：“不 - <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\pi"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">π</span></span></span></span></span></span></span>本身不是一个物理事物”。但这也不是很令人满意。</p><p>使用两个独立领域的概念，我会说<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\pi"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">π</span></span></span></span></span></span></span>存在于柏拉图领域，其表达由物理领域的大脑支持。这两个领域是分开的——任何物质实体都不会侵入非物质领域，反之亦然。但是，许多抽象都归因于特定的时空切片，即特定时刻的空间区域。</p><h1>因果关系</h1><p>现在谈谈因果关系。它是什么？稍微思考一下，您就会相信，如果我们只谈论物理世界，那只是意味着它按照某些定律随时间演变。规律<i>就是</i>因果关系，不需要额外的概念。每时每刻，宇宙的精确配置<i>都会导致</i>下一个配置。原因总是先于结果。宇宙只是一堆按照定律嗡嗡作响的粒子，仅此而已。</p><p>但是，因为我们非物理的“柏拉图式”领域中的实体（类别、描述、表示等）是由物理领域的各种配置定义并归因于物理领域的各种配置，并且因为物理领域根据设定的法则演化，所以这些“柏拉图量”也会随时间演化（至少是与时间和空间相关的量）。从物理到柏拉图式的映射总是多对一的，因此柏拉图式实体随时间的演化并不是完全可预测的。而且，有时会发生相反的情况——柏拉图量随着时间的推移是可以预测的<i>，尽管</i>它是物理状态的极端概括。</p><p>例如，采用物体质心的概念。固体物体在物理上并不“具有”质心——相反，该中心是根据每个粒子的质量和位置定义的柏拉图量。但那个位置在物理上没有什么特别的。在这种特殊情况下，矛盾的是，尽管我们缺乏对单个粒子运动的了解，但由于如此多的内部碰撞不断抵消彼此的位置贡献，这个柏拉图式的量随时间的演变是非常可预测的。</p><p>稍微缩小一下，在上图中， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span>呈现出这个非物理领域的值。如果我们暂时允许类比中的类比，让<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>代表这里“更接近”物理领域的东西。因此， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span><i>归因于</i>或<i>描述</i>或<i>概括</i><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> ，但它与<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>不存在因果关系。它不可能——首先，因为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span>处于非物质领域而<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>处于物质领域，并且它们不交叉。其次，因为因果关系要求原因在时间上先于结果。但在这里， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span>归因于<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> ，因此与<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>发生的<i>时间</i>相关。</p><p>尽管模型表示<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span>的随时间演化不像<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>那样按照“规律”演化，但它<i>会跟踪</i><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> 。因此，只要<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>根据物理定律演化， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span>就会以可以准确预测的方式演化。因此，我们在隐喻意义上根据这些表征来谈论因果关系。这就是我们在日常思考和交流中所做的事情。因此，回到最初的主张： <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span><i>是</i>原因，它们只是不是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span><i>的</i>原因。相反，在隐喻意义上， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z_{t-1}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.003em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span></span></span>是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z_t"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.003em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span></span></span></span></span></span></span></span>的原因。</p><h1>真理的概念</h1><p>作为人类，我们对什么是“真实”有强烈的感觉——而且由于我们没有任何直接进入物理领域的途径，这个真理只能是我们内部表征的一个属性，而这些表征是虚构的描述。我们建立的一些心理模型，例如物理空间模型，具有非常强烈的真理概念 - 我<i>真的</i>相信我现在正在笔记本电脑上打字而不是在做梦。其他模型的定义较弱——我<i>很确定</i>我知道我的一些朋友大部分时间在想什么。</p><p>但现在有一件事很清楚——心智模型的建立在所有领域都是必要的，而“真理”的概念在所有领域都有用，但它在数学中的特征与在心理学或经济学中的特征截然不同。绝对真理似乎只适用于数学和物理等抽象学科。对于其他人来说，它仅用于松散的隐喻意义。不仅如此，即使在那些以真理为目标的纯粹学科中，它也是不可证实的。科学对此是诚实的——我们能做的最好的事情就是<i>不</i>证伪现有的理论。</p><p>有一段时间我对此有些否认，有时会想到机器学习试图发现的“真实模型”。这种新的基于二元性的观点打破了这种观念，而且知道不存在我未能找到的这种“真实模型”实际上是一种很大的解脱。简而言之，所有模型都是虚构的；有些人的预测比其他人更好。 （套用乔治·博克斯的话）</p><h2>终极 MNIST 分类器</h2><p>不过，如果您确实想“找到真正的模型”，请考虑终极 MNIST 分类器。我们想要对产生 MNIST 图像的<i>真实因果过程</i>进行建模，而不是卷积层和池化层、全连接层和最终的 softmax。首先，人类思考一个数字，然后拿起笔将其写在纸上，然后墨水浸入，然后相机或扫描仪将光照射在纸上，光子撞击 CCD 芯片，将强度级别分级最后将它们存储在文件中。这就是<i>实际发生的</i>事情。因此，分类器必须对所有这些进行建模，然后推断作者正在考虑哪个数字。</p><p>真正的 MNIST 分类器，无论是机器分类器还是人类分类器，显然都不会这样做。他们甚至不尝试<i>近似</i>它。他们做的事情完全是与这个物理现实完全无关的事情。</p><h1>主动推理</h1><p>那么，如果不可能接近“真实模型”，那么什么标准可以普遍、客观地判断一个模型呢？我遇到的最好的概念是卡尔·弗里斯顿（Karl Friston）的主动推理<i>（Active Inference）</i> ，它试图作为模型构建的基础——它是一个代理在世界中生存的一种机制。在时间世界中移动的代理（即不仅仅是标记静态图像）生存的一个副产品是<i>预测</i>未来的能力。据我了解，这是为了跨越环境差距，从未来行动结果到当前行动执行信用分配所必需的。这是一个令人着迷的理论。</p><p>在这个理论中，智能体必须根据其环境的内部表征来预测未来的感官输入。因此，什么是“好的”内部表征的基本概念完全是功利主义的——表征对于支持准确预测未来的感官输入有多大用处。</p><p>但这在功能上与我们心理上的真理概念没有区别。如果一个想法能够让我们准确地预测我们关心的未来的某些方面，那么它就是正确的。这只是用理论来检验预测的经验原理——只要理论与观察相符，它就与真理没有区别。值得注意的是（无论如何对我来说），这一原则似乎在心理上适用于从模糊到精确的所有领域，并且我们也沿着这个范围体验“真相”。</p><h1>因果推理可能需要时间知识</h1><p>总而言之，在这种二元论解释中，因果关系有两种形式——基本的物理因果关系，以及纯粹由于柏拉图式表征如何归因于物理状态而产生的隐喻因果关系。但这仅适用于那些在特定时间与物理状态绑定的表示。时间性是隐喻因果关系出现的先决条件。这似乎意味着希望学习因果关系的机器学习模型必须消耗时间数据并对其时间演化进行建模。</p><h1>对道德的影响</h1><p>据说你“不能从<i>现状</i>中推导出<i>应该的</i>”。但是，在这种新观点中， <i>“应该”</i>与<i>“是”</i>之间的障碍消失了。或者，更确切地说，它是被回避的。人类只有一个大脑，能够构建表征和想法来服务于生存的目的。就一套道德原则有助于生存而言，同样的表征构建过程也会发生，这对于指导我们的行为与我们对物体永久性或动量守恒的信念一样重要。如果指导行为的道德原则导致一个人产生不良结果，则可以通过我们用于其他所有心理模型的相同经验学习过程来对其进行修改。</p><p>事实和价值之间的二分法之所以有吸引力，只是因为我们没有认识到“事实”只存在于这个真理范围内，而这些真理在不同领域的预测准确性程度不同。这是一种错误的二分法，原因有二。首先，因为预测准确性不存在任何硬性阈值，“真相”突然就变成了模型。其次，未能认识到代理人的<i>所有</i>心理模型都源于相同的生存要求，因此隐含着一种价值，您可以将其称为道德价值。</p><h1>对表征可解释性的影响</h1><p>可解释性研究的目标之一是训练模型，不仅产生所需的输出，而且产生所需的内部<i>表示</i>。从这个角度来看，我们不仅仅将模型视为黑匣子。在这一努力中，表示不仅促进训练和调节输出的计算，而且还提供解释的钩子或控制模型如何生成答案或输出的旋钮。</p><p>然而，这样做的一个问题是，当应用于更加微妙的领域时，人类将不再对自己的内部表征达成共识或意识到。更糟糕的是，这种表示可能是可以解释的，但却给人类带来了错误的理解感。</p><p>一个更有希望的结果可能是一个可以发明解释的人工智能模型——它比流行的人类观念更能预测功利主义目标。例如，我在这里想到的是经济模型。或者，在只有理论大量存在但可能有很大改进空间的领域，例如精神分析。</p><p>人类的表征通常是有缺陷的——在人类犯更多错误的领域，或者只有一些人拥有特殊技能的领域，这种情况更有可能发生。对于可解释的机器学习模型来说，这是一个潜在的巨大机会，可以充当老师，通过解决人类遇到的相同问题，然后详细解释它是如何解决问题的。</p><h1>对机器学习的影响</h1><p>不存在“真实”模型 - 比较两个模型的唯一方法是通过它们的预测准确性。如果一个模型的内部表示<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span>比另一个模型支持更准确的预测，则它比另一个模型更好。</p><p>因果推理是可解释性的一方面，因为我们人类可以执行它。根据上面的两个领域图，我们可能期望模型呈现出一系列输入序列，这些输入序列的排列方式与人类可能经历的序列（暂时）将导致类似于/模仿/执行因果推理的表示序列有关。毕竟，人类因果推理是我们的表征随时间演化的副产品，而表征又是物理因果链的副产品。</p><p>最后要注意的一件事是所有推论实际上都是预测。人类常常会对过去发生的事情做出推断。然而，如果我这样做，我就会更新我的精神状态（随着时间的推移），这反过来可能会影响我根据该更新做出的新预测。回想过去确实感觉就像时光旅行！</p><h1>结论与反思</h1><p>对于机器学习模型和动物心理模型中的表征，将它们重新解释为习得的、适合目的的发明，而不是观察到的数据（或感官输入）的因果因素有一些好处。首先，它是一种更普遍适用的解释。机器学习模型可以做很多不同的事情。它们都在通往输出的途中产生内部激活。只为某些模型的表示指定特殊属性会很尴尬。其次，这种重新解释消除了绝对真理和“模糊”真理概念之间以及绝对和模糊因果关系之间恼人的、人为的语义障碍。真相现在意味着“能够对未来表示产生准确预测的表示”。</p><br/><br/><a href="https://www.lesswrong.com/posts/iYevftcfEDaqAy2c5/z-is-not-the-cause-of-x#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/iYevftcfEDaqAy2c5/z-is-not-the-cause-of-x<guid ispermalink="false"> iYevftcfEDaqAy2c5</guid><dc:creator><![CDATA[hrbigelow]]></dc:creator><pubDate> Mon, 23 Oct 2023 18:36:07 GMT</pubDate></item></channel></rss>