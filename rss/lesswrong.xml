<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 9 月 1 日星期五 12:22:42 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[What is OpenAI's plan for making AI Safer?]]></title><description><![CDATA[Published on September 1, 2023 11:15 AM GMT<br/><br/><p>一些人声称，像 OpenAI 这样的大型人工智能公司在让人工智能更安全方面做得不够，或者通过加快人工智能的进步而造成损害。但 OpenAI<i>正在</i>采取哪些措施来让人工智能更安全呢？</p><p>总的来说，OpenAI 非常看好利用 AI 来帮助进行比对研究。</p><p>他们的基本方法基于三个概念：</p><ol><li>使用人类反馈训练人工智能系统</li><li>训练人工智能系统协助人类评估</li><li>训练人工智能系统进行对齐研究</li></ol><p>换句话说，他们希望通过使用多种涉及人类评估人工智能性能的技术，并使用人工智能帮助人类评估其他人工智能的性能，使人工智能更安全。最终，他们希望这种方法能够得到发展，直到他们拥有足够智能（且安全）的人工智能，可以自行进行人工智能安全研究。</p><h2>使用人类反馈训练人工智能系统</h2><p>这里的基本概念是“<a href="https://openai.com/research/learning-from-human-preferences"><u>根据人类反馈进行强化学习</u></a>”（RLHF）。 RLHF 非常简单：当人工智能做我们想要的事情时，我们就奖励它。通常，训练人工智能涉及定义的“损失函数”，它告诉人工智能我们想要什么。然而，对于 RLHF，我们更像是训练一只狗——我们观察它在做什么，并在它做的事情看起来更像我们希望它做的事情时奖励它。例如，我们向人类展示两个人工智能随机行为的片段，并询问他们哪个看起来更像后空翻。如果你经常这样做，人工智能就会做一个后空翻。</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5aed1da-5cbf-4e58-a4a3-464e628d99e2_400x400.gif"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5aed1da-5cbf-4e58-a4a3-464e628d99e2_400x400.gif" alt="人类反馈跳跃" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5aed1da-5cbf-4e58-a4a3-464e628d99e2_400x400.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5aed1da-5cbf-4e58-a4a3-464e628d99e2_400x400.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5aed1da-5cbf-4e58-a4a3-464e628d99e2_400x400.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5aed1da-5cbf-4e58-a4a3-464e628d99e2_400x400.gif 1456w"></a></p><p></p><p> AI 做后空翻</p><p>这实际上比仅仅告诉人工智能我们想要什么要复杂一些。我们实际上有<i>两个</i>人工智能。其中之一是学习我们想要的东西。另一个人问第一个“嘿，我应该做什么？”然后尝试这样做。因此，模型 1 根据人类反馈进行猜测（也许你打算跳？），然后训练模型 2，直到它能够始终如一地实现模型 1 认为的目标。最终，模型 1 找出了人类想要什么，模型 2 找出了如何实现该目标。使用模型 1 可以节省时间，因为这意味着人类不必对人工智能所做的每件事进行评分，而是可以间歇性地询问发生了什么。</p><p>这对于“微调”大型模型也很有用。<a href="https://ui.stampy.ai/?state=8161_"><u>大型语言模型</u></a>(LLM) 使用大量数据（例如来自互联网的文本）进行训练，直到它们能够可预测地输出令人信服的文本。然而，他们只是输出与他们接收的文本相似的文本——这意味着他们通常是粗鲁的、危险的或无益的。解决这个问题的一种方法是<a href="https://web.archive.org/web/20230227112828mp_/https://openai.com/blog/instruction-following/"><u>使用 RLHF</u></a> ：让很多人查看 LLM 输出的文本，看看它是否有害，然后根据该数据训练模型。</p><h2>训练人工智能系统协助人类评估</h2><p>然而，这种方法的作用仅限于此。尽管对表现进行评级通常比实际表现更容易，但在某些时候，人类无法判断人工智能的表现如何。 AI已经能够超越</p><p>OpenAI 针对这个问题的主要解决方案是什么？训练人工智能来帮助人类评价人工智能！他们在<a href="https://openai.com/research/webgpt"><u>许多</u></a><a href="https://openai.com/research/critiques"><u>论文</u></a>中证明了这一点。例如，他们研究<a href="https://openai.com/research/summarizing-books"><u>总结书籍的问题。</u></a>训练人工智能总结书籍是相当困难的，因为训练人工智能需要进行大量的训练，而且你必须要求某人为每一本书阅读整本书。为了帮助实现这一目标，他们训练人工智能来总结书籍的<i>章节</i>，这要容易得多——每次训练都需要有人阅读一章。然后他们用那个<i> </i>AI辅助人们判断整本书的AI——人们可以阅读章节摘要而不是整本书，并以此来判断整本书的摘要。</p><p>到目前为止，他们还没有更进一步，用真正超人的人工智能进行测试，但他们表示，他们计划很快发布类似实验的数据，以判断编码任务，而这些任务对于无人协助的人类来说很难可靠地判断。</p><h2>训练人工智能系统进行对齐研究</h2><p>最终，OpenAI 希望能够自动发现人工智能安全中的新概念和方法。</p><p>他们认为大型语言模型是这样做的良好基础，因为它们已经包含了大量的知识。他们认为，培训越来越高效的研究助理将使越来越多的人工智能安全研究实现自动化，而狭窄的系统（不太可能产生危险）可能适合此类任务。</p><p>他们的新<a href="https://openai.com/blog/introducing-superalignment">超级调整</a>团队专注于这一目标。他们还概述了他们关注的三个原则，以确保自动化研究助理的安全：</p><ol><li>训练人工智能系统来帮助人类评估者</li><li>验证他们的助理是否安全</li><li>训练不安全代理类型的小例子并确认他们开发的工具可以使这些代理安全。</li></ol><p>我们已经讨论了 1，他们还没有发表关于 3 的工作，所以我们在这里重点讨论 2。有关 3 的示例，您可以查看<a href="https://www.alignmentforum.org/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1"><u>Anthropic 最近的一些工作</u></a>。</p><p> OpenAI 概述了他们有兴趣验证助手安全的两种关键方法。</p><p>首先，他们希望利用人工智能来发现其他人工智能行为不可接受的边缘情况。我们将很快发布，更深入地解释其工作原理。</p><p>他们的另一种方法是基于<a href="https://www.lesswrong.com/tag/interpretability-ml-and-ai"><u>可解释性</u></a>。目前，很难弄清楚人工智能是如何工作的。因为我们基本上是教一堆数字如何完成一项任务，所以内部结构看起来就像……嗯，一堆数字，它们看起来是随机的。 OpenAI 使用 GPT-4（一种高级语言模型）来<a href="https://openai.com/research/language-models-can-explain-neurons-in-language-models"><u>解释其中一些数字在 GPT-2（一种不太高级的语言模型）中的作用</u></a>，并将其与人类手动执行相同操作进行比较。他们表明，尽管解释并不完美，但它们有时是正确的，并且作为起点可能足够有用。他们希望未来的语言模型能够更好地完成这项任务，或者他们可以改变训练更简单模型的方式，使此类任务变得更容易。了解人工智能正在“思考”什么对于发现诸如欺骗或人工智能预期其行为会造成伤害之类的事情很有用。</p><h2>局限性</h2><p>OpenAI 还概述了他们的计划中的一些弱点。他们目前的计划是基于在当前人工智能系统上开发安全技术，但让更大、更智能的系统变得安全可能会涉及非常不同类型的问题。他们还担心，有助于人工智能安全的最简单、最狭窄的系统可能已经很危险了。他们的新超级对齐团队专注于第二类问题。</p><br/><br/> <a href="https://www.lesswrong.com/posts/6hxsbMqXEsRYwEYRr/what-is-openai-s-plan-for-making-ai-safer#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/6hxsbMqXEsRYwEYRr/what-is-openai-s-plan-for-making-ai-safer<guid ispermalink="false"> 6hxsbMqXEsRYwEYRr</guid><dc:creator><![CDATA[brook]]></dc:creator><pubDate> Fri, 01 Sep 2023 11:15:22 GMT</pubDate> </item><item><title><![CDATA[Progress links digest, 2023-09-01: How ancient people manipulated water, and more]]></title><description><![CDATA[Published on September 1, 2023 4:33 AM GMT<br/><br/><p>我正在尝试将更多社交媒体内容直接拉入这些摘要中，部分原因是为了减少对社交媒体网站的长期依赖（因为内容可能会被删除、屏蔽、付费等）。这使得这些摘要更长，但这意味着存在更少需要点击链接。</p><p>我仍然会链接回原始的社交媒体帖子，以便给予信任并使分享更容易。一如既往，让我知道您的反馈。</p><h2><strong>机会</strong></h2><ul><li><a href="https://www.readcodon.com/p/homeworld-ideas">Homeworld Ideas，生物技术写作比赛</a>。 “分享您对生物学如何实现积极且可持续的未来的愿景”（来自<a href="https://twitter.com/NikoMcCarty/status/1691440917486690304">@NikoMcCarty</a> ）</li><li> Works in Progress + Stripe Press 于 9 月 14 日举办的作家沙龙， <a href="https://docs.google.com/forms/d/e/1FAIpQLSc-rcl7ztNszOapMHYDf3Oys0pb6qdao43INcbJfEflkIm23A/viewform">请在此处申请</a>（通过<a href="https://twitter.com/_TamaraWinter/status/1694372353847791802">@_TamaraWinter</a> ）</li><li> <a href="https://foresight.org/ai-safety">Foresight 的人工智能安全资助计划</a>（来自<a href="https://twitter.com/foresightinst/status/1692257505886286259">@foresightinst</a> ）</li><li> <a href="https://oklo.com/careers/">Oklo（先进核能）正在招聘</a>。 “我们特别寻找杰出的机械工程师......以及电力工程师” <a href="https://twitter.com/caorilne/status/1694822419590992358">@caorilne</a>说</li><li>如果您有科技/软件/创业经验，并且想帮助技术移民，您可以<a href="https://twitter.com/lisawehden/status/1691877018936250734">成为咨询意见书签署人</a></li></ul><h2><strong>公告</strong></h2><ul><li><a href="https://betterplanning.ie/street-plans/">更好规划联盟关于“街道规划如何帮助减少住房危机”的报告</a>（来自<a href="https://twitter.com/BPAIreland/status/1694740105880027283">@BPAIreland</a> ）</li></ul><h2><strong>安息吧</strong></h2><ul><li><a href="https://www.bloomberg.com/news/articles/2023-08-20/adobe-s-co-founder-john-warnock-dies-at-82">Adobe 联合创始人约翰·沃诺克，82 岁</a>。 Steven Sinofsky<a href="https://twitter.com/stevesi/status/1693324009956634904">称他为</a>“行业和技术传奇人物……从 Xerox 到共同创立 Adob​​e 数十年，他改变了我们每天都受益的技术格局。”约翰·格鲁伯 (John Gruber)<a href="https://daringfireball.net/linked/2023/08/26/john-warnock-rip">表示</a>：“沃诺克和格施克理解史蒂夫·乔布斯经常宣扬的一句话：仅靠技术是不够的。 ……如果 Warnock 和 Geschke 仅仅满足于单独提供伟大的技术，那么 Adob​​e Systems 将成为几乎被遗忘的硅谷脚注。相反，他们推动 Adob​​e 成为我们今天所知的伟大的工具制造产品公司。”</li></ul><h2><strong>视频</strong></h2><p>帕特里克·科里森 (Patrick Collison) 和兰特·普里切特 (Lant Pritchett) 讨论了一个国家的进展以及促进其增长的情况（来自<a href="https://twitter.com/jmazda/status/1691715431302619395">@jmazda</a> ） </p><figure class="media"><div data-oembed-url="https://youtu.be/FlIwx_7Rimc"><div><iframe src="https://www.youtube.com/embed/FlIwx_7Rimc" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div></figure><h2><strong>文章</strong></h2><ul><li><a href="https://alltrades.substack.com/p/proto-pumps-and-early-water-infrastructure">古人是如何操纵水的？</a> （作者： <a href="https://twitter.com/ConnorTabarrok/status/1692238953108197481">@ConnorTabarrok</a> ）</li><li><a href="https://www.arcadiascience.com/blog/what-is-arcadia">什么是阿卡迪亚科学？</a> “我们两年愿景的最新进展”（来自<a href="https://twitter.com/seemaychou/status/1691532663377838080">@seemaychou</a> ）</li><li>我们如何才能加速科学发展？ <a href="https://www.washingtonpost.com/opinions/2023/08/14/heidi-williams-science-research-funding/">海蒂·威廉姆斯 (Heidi Williams) 在华盛顿邮报的一篇评论文章中建议“消除资金延误”</a> 。 “国会可以给予 NIH 和 NSF 灵活性，以便更快地资助好想法……资助者可以给予科学家更大的灵活性来追求他们最有前途的想法”（ <a href="https://twitter.com/heidilwilliams_/status/1691052671329853440">@heidilwilliams_</a> ）</li><li> “林迪效应是一种统计规律，对于许多类型的实体来说：它们存在的时间越长，它们可能持续的时间就越长。”<a href="https://arxiv.org/pdf/2308.09045.pdf">新的托比·奥德论文</a>给出了这个正式的发展（来自<a href="https://rootsofprogress.org/(https://twitter.com/tobyordoxford/status/1694284685134733337)">@tobyordoxford</a> ）</li><li>耶路撒冷德姆萨斯说<a href="https://www.theatlantic.com/ideas/archive/2023/08/american-election-frequency-voter-turnout/675054/">美国人投票太多</a>。 “选民消失的地方，特殊利益就会涌入……我们得到的不是民主，而是由业主协会、警察工会、教师工会、开发商、商会、环保组织等组成的政府”</li><li> <a href="https://marginalrevolution.com/marginalrevolution/2023/08/twenty-years-of-marginal-revolution.html">二十年的边际革命</a>（来自<a href="https://twitter.com/ModeledBehavior/status/1694325077989368029">@ModeledBehavior</a> ）</li><li><a href="https://en.wikipedia.org/wiki/Du_Shi">杜轼</a>是“中国水文学家、发明家、机械工程师、冶金学家和政治家”，被誉为第一个在冶金中应用水车操作波纹管的人（来自<a href="https://twitter.com/michaelcurzi/status/1694506186475745461">@michaelcurzi</a> ）</li><li><a href="https://en.wikipedia.org/wiki/Great_Raft">大木筏</a>是“一个巨大的木塞，大约从 12 世纪起堵塞了路易斯安那州的红河和阿查法拉亚河，直到 1830 年代被清除。它的规模在北美是独一无二的”（ <a href="https://twitter.com/WillRinehart/status/1693817393863098828">@WillRinehart</a> ）</li></ul><p> <a href="https://pbs.twimg.com/media/F4Gl8OgWQAAGXiC.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/WhMk3gwyfGq2xek2J/n11gygolj5a28m3qnhro" alt=""></a></p><h2><strong>查询</strong></h2><ul><li><a href="https://twitter.com/michael_nielsen/status/1692204714090549510">70 岁或以上的人取得科学突破的最佳例子是什么？</a></li><li><a href="https://twitter.com/Ben_Reinhardt/status/1693653330306753010">您最喜欢的工业和政府实验室之外的成功非学术研究组织的例子是什么？</a></li><li><a href="https://twitter.com/danielgolliher/status/1692358353601634780">谁在中西部从事富足/美国活力/等方面的工作？</a></li><li><a href="https://twitter.com/YIMBYLAND/status/1691552000888996146">规划一条子弹头列车真的需要 2 亿美元吗？</a></li><li><a href="https://twitter.com/yishan/status/1691686483655323902">乔治·霍茨/埃利泽·尤德科夫斯基辩论的总结很好吗？</a></li><li><a href="https://twitter.com/jasoncrawford/status/1691081077274574848">既然每个人都在使用 Midjourney 和 DALL-E 来创建博客，图片库网站的流量是否会下降？</a></li><li><a href="https://twitter.com/nealagarwal/status/1691095252952834048">尼尔·阿加瓦尔（Neal Agarwal）的“关于早期互联网的小博物馆”应该包括什么？</a></li><li><a href="https://twitter.com/stewartbrand/status/1693441524242268667">这台机床到底是什么？</a></li></ul><p> <a href="https://pbs.twimg.com/media/F4BQA1kbIAA6pyn.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/WhMk3gwyfGq2xek2J/mmo2nkjnjrcehcat9mkm" alt=""></a></p><h2><strong>来自社交媒体</strong></h2><ul><li>挪威可以以比英国<i>申请规划</i>所需的成本更低的成本<i>建造一条隧道</i>，<a href="https://twitter.com/Sam_Dumitriu/status/1694990887439233239">以及 @Sam_Dumitriu 提供的许多其他令人震惊的事实</a></li><li>据说诺贝尔奖获得者获奖后的产出会<i>减少</i>。对于那些受邀进入高等研究院的人也说了类似的话。<a href="https://twitter.com/jasoncrawford/status/1691132650117910545">哪些奖项、荣誉、补助金、职位等会导致人们在之后做出<i>更多</i>或更好的工作，而不是更少？</a></li><li>费曼问道：“如果在某种灾难中，所有的科学知识都被毁灭，只有一句话传给了下一代生物，那么哪句话会用最少的词语包含最多的信息呢？”他自己的答案是“<i>一切事物都是由原子构成的</i>原子假说”。但我们在古希腊就有这样的假设！直到1800年代它才基本上没用。<a href="https://twitter.com/jasoncrawford/status/1692233042641736133">为什么知识不包含在句子中</a></li><li><a href="https://twitter.com/timhwang/status/1692625535866724690">“秋季在纽约举行的为期一天的研讨会，重点关注“科技树”主题，将游戏设计师、科学史学家和元科学人士聚集在一起”</a></li><li>台湾核倡导者： <a href="https://twitter.com/AngelicaOung/status/1692534228020555809">“我们正在成立一个支持核的非政府组织”</a></li><li>本·莱因哈特 (Ben Reinhardt)<a href="https://twitter.com/Ben_Reinhardt/status/1691085316164104193">建议</a>“新兴风险投资，但适合从事奇怪科学/技术工作的人。我经常遇到一些人（尤其是学术系统之外的人），他们有一个疯狂的想法，他们想从事这一工作 1. 无法通过某些委员会 2. 需要比官僚时间表更快的资金（因为他们需要招聘/围绕它做出的生活决定）”</li><li> “运行自动化项目的其他人是否注意到关键供应商已被完全预订一空，工作量超负荷，交货时间变得疯狂？ ……有大事正在发生。世界正在快速自动化！” （ <a href="https://twitter.com/Jordan_W_Taylor/status/1692251280394076175">@Jordan_W_Taylor</a> ）也许与<a href="https://twitter.com/DKThomp/status/1681657342591393793">美国制造业建设处于历史最高水平</a>有关？</li><li> “数千年来，城市规划的重点是绘制街道网络，其下方有供水和下水道，并保留常规公共空间，并且在用途或密度方面大多不可知。<a href="https://twitter.com/mnolangray/status/1693726831722234027">一百年前，情况发生了逆转</a>”</li><li> “我们需要一种关于物质进步的独特印度话语......从独特的印度视角进行对话，借鉴我们的生活经验和我们在人均 GDP 水平上面临的权衡”（ <a href="https://rootsofprogress.org/(https://twitter.com/aye_kaash/status/1695808604220313884)">@aye_kaash</a> ）</li><li> “我曾经认为种植一小块菜地是与自然交流、与世界和平相处的一种方式。在经历了蛞蝓、蚜虫、霉菌等之后，我意识到我搞错了。园艺是达尔文式的与自然的死亡竞赛以及对稀缺资源的争夺”（ <a href="https://twitter.com/eladgil/status/1692564470441165227">@eladgil</a> ）</li><li> “坦率地说，我有一个带有通用翻译器的袖珍设备，这一点是未被充分认识的魔力”（ <a href="https://twitter.com/kendrictonn/status/1692004311457518032">@kendrictonn</a> ）</li><li> “当自动驾驶汽车被理所当然地视为城市基础设施的一部分时（这可能只需要几年时间），那些试图禁止它们的人的声明读起来就像有人试图禁止电力或室内管道”（ <a href="https://twitter.com/paulg/status/1691261977656786944">@paulg</a> ）</li><li> <a href="https://twitter.com/jonatanpallesen/status/1693622595793334512">“安慰剂效应（大部分）不是真实的，”</a>只是回归均值</li><li>如果您查看打字速度与准确性，您会发现它们呈正相关：打字速度更快的人也更准确。天真地，人们可能会建议加快打字速度以减少错误！显然，这会适得其反。<a href="https://twitter.com/jasoncrawford/status/1692015685717651618">为什么受试者间变异性与受试者内变异性不同</a></li><li>《大西洋月刊》<a href="https://www.threads.net/@theatlantic/post/CwTUZxeRO1_">抱怨说</a>，生成式人工智能会消耗大量能源，而且“对气候造成的损失可能是巨大的”。<a href="https://www.threads.net/@jasoncrawford/post/CwT3E8_PTZF">更正标题</a>：生成人工智能展示了为什么我们需要过剩的能源。廉价、可靠、清洁的能源并不缺乏用途</li><li>“25 年前，他们发明了<a href="https://en.wikipedia.org/wiki/Celecoxib">一种更好的 Advil 版本</a>，它针对相同的受体，但副作用更少。它仍然需要处方，基本上没有任何理由”（ <a href="https://twitter.com/alyssamvance/status/1692399530711437321">@alyssamvance</a> ）</li><li> “如果你将气候变化视为对有罪的暴饮暴食的惩罚而不是技术问题，那么环保主义者对碳清除的禁忌是有道理的。解决罪恶的唯一合适的办法就是自我牺牲”（ <a href="https://twitter.com/MTabarrok/status/1692176024853962891">@MTabarrok</a> ）</li><li>约翰·卡马克<a href="https://twitter.com/ID_AA_Carmack/status/1692229954954461514">表示</a>：“《连线》仍然是唯一一家在我出现在文章中时始终有事实核查人员联系我的主要出版物。” （不确定他是否曾经<a href="https://twitter.com/EnswellJones/status/1301664132438032384">去过大西洋</a>）</li><li> “为人父母非常重要。事实上，很难提出定量证据来证明养育子女的重要性，这是我们社会科学的新生和幸福感概念混乱的预期结果”（ <a href="https://twitter.com/mbateman/status/1691129949338456089">@mbateman</a> ）</li></ul><h2><strong>引号</strong></h2><p><a href="https://twitter.com/jasoncrawford/status/1690906769365540864">米塞斯反对稳定</a>（ <a href="https://rootsofprogress.org/books/masters-of-the-universe"><i>《宇宙大师》</i></a> ，作者：丹尼尔·斯特德曼·琼斯）：</p><blockquote><p>和波普尔一样，米塞斯也看到了官僚心态与柏拉图的乌托邦之间的相似之处，在柏拉图的乌托邦中，绝大多数被统治者为统治者服务。他认为“后来所有按照柏拉图的例子塑造人间天堂蓝图的乌托邦主义者都同样相信人类事务的不变性”。他接着说，官僚化必然是僵化的，因为它涉及对既定规则和惯例的遵守。但在社会生活中，僵化就等于石化和死亡。一个非常重要的事实是，稳定和安全是当今“改革者”最珍视的口号。<strong>如果原始人采取了稳定的原则，他们早就被猛兽和微生物消灭了。</strong></p></blockquote><p> “对三年前封锁期间发表的《纽约时报》文章的评论，质疑纽约市是否会恢复”（来自<a href="https://twitter.com/michaelmiraflor/status/1695181415850332378">@michaelmiraflor</a> ）：</p><blockquote><p>我当纽约出租车司机已经很多很多年了。我最喜欢的骑行方式是罕见地搭载一个刚从医院出来的男人，他的第一个孩子出生了。这是他一生中最美好的一天，当他告诉我这一切时，我通常很难掩饰自己喜悦的泪水。</p><p>我第二喜欢的骑行也是类似的。这是一个第一次来到纽约市的有梦想的年轻人。我是出租车司机，带他或她从机场前往曼哈顿。我坚持将 59 街桥的上层作为我们的路线。当我们接近曼哈顿时，随着这座城市变得越来越大，人们的兴奋感也随之增强。最后，几乎在地面上，坡道使我们如此接近周围的建筑物，以至于我们实际上可以看到里面的人。降落在东 62 街时，我的新纽约客第一次体验到人们常说的“活力”。这就像看着一个孩子走近一屋子的生日礼物。一切皆有可能。</p></blockquote><h2><strong>地图和图表</strong></h2><p>如果我们能够以北欧成本建造伦敦的铁路系统（来自<a href="https://pedestrianobservations.com/2019/06/24/assume-nordic-costs-london-edition/">Alon Levy</a> ， <a href="https://twitter.com/Sam_Dumitriu/status/1694990909346120164">@Sam_Dumitriu</a> ）</p><p> <a href="https://pbs.twimg.com/media/F4XH2SBXUAAHYNK.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/WhMk3gwyfGq2xek2J/rbyx734i2dd6wrfukslv" alt=""></a></p><p> “人类最鼓舞人心的成就之一。我们以前做到过，我们可以再做一次”（ <a href="https://twitter.com/Altimor/status/1692573695003312553">@Altimor</a> ）</p><p> <a href="https://pbs.twimg.com/media/F306ye9XwA4wkIA?format=webp"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/WhMk3gwyfGq2xek2J/qpf3iqrbmpmf3v28typf" alt=""></a></p><p> “物质繁荣最基本的资源是能源”（ <a href="https://twitter.com/Andercot/status/1694061035223937285">@Andercot</a> ）</p><p> <a href="https://pbs.twimg.com/media/F4KC6uMaoAIVN_v.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/WhMk3gwyfGq2xek2J/kviyfwulyk0jv8cqxfb8" alt=""></a></p><p>核支持民意调查（来自<a href="https://twitter.com/gordonmcdowell/status/1693313725414203544">@gordonmcdowell</a> ） </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/WhMk3gwyfGq2xek2J/hw8z8e486bu7zjdrwml9"></figure><p>整个宇宙，按（对数）比例（来自<a href="https://twitter.com/emollick/status/1693496535508566116">@emollick</a> ，作者：Pablo Carlos Budassi，<a href="https://www.pablocarlosbudassi.com/2021/02/atlas-of-universe-is-linear-version-of_15.html">完整分辨率请参阅原始内容</a>） </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/WhMk3gwyfGq2xek2J/iilopjapvrszyvaycsfn"></figure><br/><br/> <a href="https://www.lesswrong.com/posts/WhMk3gwyfGq2xek2J/progress-links-digest-2023-09-01-how-ancient-people#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/WhMk3gwyfGq2xek2J/progress-links-digest-2023-09-01-how-ancient-people<guid ispermalink="false"> WhMk3gwyfGq2xek2J</guid><dc:creator><![CDATA[jasoncrawford]]></dc:creator><pubDate> Fri, 01 Sep 2023 04:33:32 GMT</pubDate> </item><item><title><![CDATA[A Golden Age of Building? Excerpts and lessons from Empire State, Pentagon, Skunk Works and SpaceX]]></title><description><![CDATA[Published on September 1, 2023 4:03 AM GMT<br/><br/><p>帕特里克·科利森 (Patrick Collison) 列出了一系列自 19 世纪以来<a href="https://patrickcollison.com/fast">人们迅速共同完成雄心勃勃的事情</a>的精彩例子。它确实让你渴望一个感觉……不同的时代，当政府部门的昏昏欲睡的庞然大物可以以赛车初创公司的速度移动时：</p><blockquote><p> [...] 上个世纪，[国防部] 的创新速度令现代硅谷初创企业相形见绌：五角大楼仅用了 16 个月就建成了（1941 年至 1943 年），曼哈顿计划只运行了 3 年多（1942-1946），阿波罗计划在不到十年的时间内将人类送上月球（1961-1969）。仅在20世纪50年代，美国就建造了五代战斗机、三代载人轰炸机、两级航空母舰、潜射弹道导弹和核动力攻击潜艇。</p></blockquote><p> [注：该段落来自<a href="https://blog.anduril.com/rebooting-the-arsenal-of-democracy-anduril-mission-document-67fdbf442799">另一篇文章</a>。]</p><p>部分受到帕特里克清单的启发，我花了一些假期阅读和了解这个失落时代的各种项目。然后我写了一份备忘录，与 Lightcone 的同事分享要点和摘录。</p><p>之后，一些人鼓励我更广泛地分享这份备忘录——我确实认为，任何怀有伟大抱负和对有效运作好奇的人都会对它感兴趣。</p><p><i>如何</i>在短短一年内建造世界第一高楼<i>？</i>在同样的时间内建造世界上<i>最大的</i>建筑？或者美国在短短 6 个月内推出第一架战斗机？</p><p><i>如何？？</i></p><p>写这篇文章感觉它至少帮助我解开了这个谜题的一些部分。如果有人有其他作品，我很乐意在评论中听到他们的声音。</p><h3>帝国大厦</h3><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BpTDJj6TrqGYTjFcZ/atkwzbarxthhqeqls3cv"></figure><p>帝国大厦于 1931 年 4 月竣工，是世界上最高的建筑。在假期期间，我读了<a href="https://www.amazon.com/Building-Empire-State-Carol-Willis/dp/0393732312/ref=sr_1_7?crid=3FMZRO639NAH9&amp;keywords=empire+state&amp;qid=1693537379&amp;s=books&amp;sprefix=empire+sta%2Cstripbooks%2C254&amp;sr=1-7">一本重新发现的 20 世纪 30 年代笔记本</a>，由总承包商自己写的。它详细介绍了项目的施工过程和组织。</p><p>我将分享一些摘录，但为了将它们结合起来，首先考虑最近建造的其他一些摩天大楼： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BpTDJj6TrqGYTjFcZ/vsqgdbvmunfq0doeibta"><figcaption>作为上下文，帝国大厦顶部的高度为 1,454 英尺，大约位于该图的底部。 </figcaption></figure><figure class="table"><table><tbody><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:200px"></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:100px"><strong>设计开始</strong></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:125px"><strong>施工结束</strong></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:100px"><strong>总时间</strong></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:200px">哈利法塔</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:100px">2004年</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:125px">2010年</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:100px">6年</td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:200px">上海中心大厦</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:100px">2008年</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:125px">2015年</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:100px">7年</td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:200px">阿布拉吉·巴尔特</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:100px">2002年</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:125px">2012年</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:100px">10年</td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:200px">世界贸易中心</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:100px">2005年</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:125px">2014年</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:100px">9年</td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:200px">诺德斯特龙大厦</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:100px">2010年</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:125px">2020年</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:100px">10年</td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:200px">台北101</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:100px"> 1997年</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:125px">2004年</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top;width:100px">7年</td></tr></tbody></table></figure><p>（列表来自 skyscrapercenter.com）</p><p>现在，摘自《帝国大厦》这本书的前言：</p><blockquote><p>帝国大厦最惊人的统计数据是其规划和建设的惊人速度。 [...] 有不同的方式来描述这一壮举。 1930 年 4 月 7 日第一根结构柱安装完毕六个月后，八十六层的钢框架封顶。这座全封闭的建筑，包括其高度相当于 102 层楼的系泊桅杆，于 1931 年 3 月在 11 个月内完工。最令人惊奇的是，在短短 20 个月内——从第一个与1929 年 9 月的建筑师们到 1931 年 5 月 1 日的开幕仪式——帝国大厦设计、建造、建造并准备好供租户使用。在此期间，建筑图纸和计划已准备就绪，华尔道夫酒店的维多利亚式建筑桩被拆除（拆除工作在最初协议签署两天后才开始），地基和格栅已挖好并固定，钢柱和按照精确的规格制造和铣削了约 57,000 吨的梁，铺设了 1000 万块普通砖，浇筑了超过 62,000 立方码的混凝土，设置了 6,400 个窗户，并在 7 英里长的竖井中安装了 67 部电梯。在活动高峰期，现场雇佣了 3,500 名工人，框架每天上升超过一层楼，此后没有任何类似的结构能与这样的上升速度相匹配。</p></blockquote><p>他们是如何做到这一点的？以下是他们的流程中令我印象深刻的一些事情。</p><p><strong>设计是由来自该领域所有关键部分的代表组成的小组进行的</strong></p><p>该团队面临一个棘手的高维问题，需要大量不同的知识才能解决。以下是 1930 年<i>《财富》</i>杂志的引述：</p><blockquote><p>这些不同的元素固定了一个形状奇特的几何实体的周长，其一侧以 83,360 平方英尺的土地为界，另一侧以 35,000,000 美元为界，另一侧以收益递减为界，另一侧以物理定律和结构钢的特性为界一次是由于分区条例的圆锥形紧急情况，还有一次是在 1931 年 5 月 1 日。</p></blockquote><p>回应：</p><blockquote><p>从一开始，业主、建筑师和建筑商就组成委员会共同制定建筑物的[要求]。这种方法避免了设计中的错误和代价高昂的施工延误[...]总承包商写道：“我怀疑是否存在比业主、建筑师和建筑商之间存在的更和谐的组合。我们不断与其他人协商；建筑物的所有细节都经过提前检查，并在纳入计划之前决定”。<br><br> 1929 年 9 月，这些初步规划会议历时四个星期，提出了该项目的完整技术、规划和经济要求。 （第 20 页）</p></blockquote><p>例如，机械工程师迈耶、斯特朗和琼斯指出，与之前已知的任何项目相比，建造电梯将涉及更大的安装、更大的轿厢尺寸、更重的负载、更高的速度和更长的行程。但仍然：“建筑、钢材和电梯计划的正确同步开发避免了试图将电梯设备安装到先前固定的建筑布置和钢材布局中的常见错误。”</p><p>该团队努力吸引对表面约束和潜在障碍具有详细的对象级知识的人员进行深入的研究——设计师甚至聘请了金属制造商来帮助咨询图纸。</p><blockquote><p> “由于建筑师、建造商和分包商认为自己没有能力制定规范，因此他们召集了制造它的金属工人、安装它的人员以及在几个地方测试板材的检查员的代表。准备阶段。 [建筑师]施里夫指出，这样的会议“基于对建议的<i>即时</i>比较和所有相关人员职责的确定，做出了可能的决定”。 [我的斜体]（第 24 页）</p></blockquote><p><strong>建筑物的设计经过刻意优化，可快速建造</strong></p><blockquote><p>[...] 帝国大厦设计和建造中的几乎每一个决定都受到速度需求的影响。 [...] 正如总承包商保罗·斯塔雷特 (Paul Starret) 在回顾他的职业生涯时所声称的那样，“在建筑史上从未出现过，而且可能再也不会出现如此出色地适应施工速度的建筑设计。” （第 18 页）</p><p>承包商笔记本的最后一个主要部分的副标题是“速度的魅力”，重点介绍了建筑的四个起搏器：钢结构安装、混凝土地板拱形结构、外部金属装饰和铝拱肩以及外部石灰石。施泰力兄弟和 Eken 对他们在这四个领域所实现的创新感到非常自豪。 （第 24 页）</p></blockquote><p>对于建筑物的窗户，“目标是尽可能标准化元件，创建一种可以加快制造和安装速度的零件套件，在 5704 个金属拱肩中只有 18 个变体”。由于立面部件的其他部分如果可以用装饰覆盖的话，则显得粗糙且未完成，因此重新设计了安装顺序，以消除传统的复杂外部脚手架工作，而是可以从建筑物内部安装，并且部件被设计为具有更少的数量。与其他部件交叉，以使安装更顺利。</p><p><strong>他们在存储和移动材料方面进行了巧妙的优化</strong></p><p>该团队面临两个关键的物流问题：交付安排以及在垂直和水平方向上有效地移动材料。</p><p>由于他们是在纽约繁忙的市中心进行建设，因此他们的现场物资存储量非常少，但在高峰运营期间，他们每天从大约 500 辆卡车接收物资，或者在 8 小时工作日中大约每分钟收到一辆！</p><p> （有趣的是，已知最古老的建筑法之一是禁止白天运载建筑材料的手推车穿过罗马帝国的街道。）</p><p>他们总是会保持底层没有临时结构，以便卡车驶入，然后从建筑物顶部到一楼切出竖井，使他们能够将碎片直接倾倒到卡车后面，而不是倒入中间仓库他们甚至建造了一条迷你铁路，用于在建筑物内移动材料。摘自书中：</p><blockquote><p> “为了安装石雕，我们完全砍掉了惯用的井架。石头卡车开进大楼，石头装在板条箱里，我们称之为料斗或吊索。每个板条箱都被标记在建筑物的适当部分，由一台小型起重机从卡车上吊下来，通过天花板上的单轨运行，然后运送到工业铁路的平板车上。它被带到正确的楼层，在几乎与要设置的位置完全相同的位置卸载。两台起重机搬运了建筑物的所有石头，不仅消除了大量的起重吊杆和发动机，而且由于它们位于建筑物内部，消除了对公众的严重危险源。”</p></blockquote><p><strong>总承包商设计并优化了工作，以尽可能地分散不同工人的注意力</strong></p><blockquote><p>交易以不同的速度进行，有特殊的要求，并且可能以完全不同的方式看待相同的细节。通过尽可能多地取消交易之间的合同，建筑商降低了连锁延误的风险。作品的各个部分都展示了这一想法的实际应用：幕墙支撑详细消除了钢结构制造商和安装商对砖石信息的依赖；现场混凝土配料使搅拌机摆脱了曼哈顿的交通条件，物料提升机、乘客电梯和工业铁路系统的协调使用控制了现场的混乱运动。 （第 46 页）</p></blockquote><p><strong>设计与施工同时进行</strong></p><p>这是他们为跟踪钢铁加工而制作的图表：它绘制了并行发生的 5 个流程，以及相关的目标日期——建筑师的图纸、工厂订单、车间图纸、钢材交付和钢材安装。<br></p><p> <strong><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BpTDJj6TrqGYTjFcZ/pyxxd5rh3z66tnxqwx4g"></strong></p><p> <strong><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BpTDJj6TrqGYTjFcZ/lqvuojz8pkrgytn8derm"></strong></p><p>你可以看到，在顶层的图纸还没有完成之前，第一层的钢材就已经开始安装了。</p><blockquote><p>该图清楚地显示了快速跟踪成功所需的深思熟虑[JL：快速跟踪是用于交错而不是交错、设计和构造的术语]。每个参与者都有几项活动要做。在任何一天，不同等级的钢材都处于不同的准备阶段，需要多家顾问和建筑公司的关注。快速的速度要求每个人齐心协力。</p></blockquote><p><strong>他们采用缜密的计划和监督</strong></p><p>我们在上面的快速钢结构安装中看到了需要详细调度的示例。</p><p>每分钟接收一辆卡车送货的情况也是如此，总承包商埃肯说：“我们为这辆卡车运行的方式就像火车进出中央车站一样。如果周二卡车错过了排队的位置，则必须等到周三才能重新排队”。</p><p>该团队还设定了各种清晰的速度目标：他们决定尝试以每天一层的速度建造这座建筑。 （第 29 页）</p><p>此外，他们还有大量的看守人和检查员。他们会走过现场，记下每个人实际上都在现场（他们每天检查每个工人四次（！）），详细跟踪库存，以及每天完成的工作的记录。</p><p> <strong><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BpTDJj6TrqGYTjFcZ/fwwhbgb40bbgq642jmhv"></strong></p><p>如果你想放大的话，这是他们的组织结构图。</p><p> <strong><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BpTDJj6TrqGYTjFcZ/jyxkrh7c86coudwekdg3"></strong></p><p>以下是日常工作活动笔记的示例页面：</p><p> <strong><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BpTDJj6TrqGYTjFcZ/lia6p81zxpq7r3orwu3b"></strong></p><p>总体而言，帝国大厦的建设是一项了不起的成就。然而：</p><blockquote><p>这位总承包商自传的最后一章并不是以虚张声势的方式结束他的成就，而是以令人震惊的声明结束：“经过四十年的紧张工作，在十一个月内建造帝国大厦的压力对我来说太大了，我遭受了相当严重的神经衰弱”。</p></blockquote><h3>五角大楼</h3><p>我没有时间完全完成这一部分，但我关心五角大楼的例子，它提供了一些有趣的背景。</p><p>同一个人，格罗夫斯将军负责管理 20 世纪最大、最高效的两个大型项目：五角大楼建设和曼哈顿项目。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BpTDJj6TrqGYTjFcZ/afv1a6yplpueh1ipfpsd"><figcaption>正在建设中的五角大楼。</figcaption></figure><blockquote><p>施工于 9 月 11 日开始（正是 60 年后该建筑被飞机撞击的那一天）。萨默维尔推动了一个积极的时间表——在 1942 年 3 月 1 日之前准备好 50 万平方英尺的办公室，在 9 月 1 日之前准备好剩余的部分。格罗夫将军将军的设计师们已经尝到了紧张的时间表的滋味。几个月前，当五角大楼的初步计划正在构思时，萨默维尔给了以美国建筑师学会主席乔治·埃德温·伯格斯特罗姆为首的设计师们七月的一个周末，让他们为计划的内容草拟初步设计。建筑面积400万平方英尺。它将是——而且很可能仍然是——世界上最大的办公楼。</p><p>五角大楼的建筑和结构设计工作与施工同时进行，最初的图纸于 1941 年 10 月上旬提供，大部分设计工作于 1942 年 6 月 1 日完成。有时，施工工作比设计提前，使用的材料与设计不同。计划中指定的那些。</p><p>该建筑是逐个楔形地建造的；[38]每个楔形体一完工就被占用，即使其余楔形体的施工仍在继续。[39][40]&quot;</p><p> <a href="https://en.m.wikipedia.org/wiki/The_Pentagon"><u>https://en.m.wikipedia.org/wiki/The_Pentagon</u></a></p><p>施工期间，现场施工人员一度多达15,000人。沃格尔写道，设计团队包括“110 名建筑师、54 名结构工程师、43 名机械工程师、18 名电气工程师、13 名管道工程师、道路、景观和声学方面的各种专家，以及数十名职员和信使。”与此同时，位于施工现场的另一组 100 多名工程师、建筑师和检查员被授权做出临时决定——这座建筑确实是同时设计和建造的。</p><p> <a href="https://www.asce.org/publications-and-news/civil-engineering-source/civil-engineering-magazine/issues/magazine-issue/article/2021/09/building-for-the-american-age-the-pentagon">https://www.asce.org/publications-and-news/civil-engineering-source/civil-engineering-magazine/issues/magazine-issue/article/2021/09/building-for-the-american-age-五角大楼</a></p></blockquote><p>这项工作压力很大，格罗夫斯说他“希望能去战区，这样我就能找到一点平静。”</p><h3>臭鼬工厂</h3><p>臭鼬工厂是洛克希德公司的一个子公司，在 20 世纪 40 年代至 1970 年代主要制造间谍飞机。</p><p>例如，1943 年，臭鼬工厂在短短 5 个月内设计并制造了美国第一架战斗机 P80 流星。首席工程师 Kelly Johnson 与一支斗志旺盛的团队合作，在鼎盛时期，该团队由 23 名设计师和 105 名制造商组成。尽管如此，由此产生的飞机最终还是被空军使用了 40 年。</p><p>相比之下：波音公司使用了 10,000 多名工程师来设计 777。这是在计算机和 3D 建模软件的帮助下进行的。凯利用手制作图表，用计算尺进行计算。</p><p> Skunk Works 的文化就是让事情变得小而快：</p><blockquote><p>凯利喜欢讲述一位名叫弗兰克·卡罗尔 (Frank Carroll) 的将军在听到凯利描述他一直在推动的美国第一架喷气式飞机 P-80 的速度和机动性时如此热情，以至于卡罗尔决定绕开所有繁​​文缛节的延误，开始做这件事。所有采购订单文件都是他自己做的。 “我们下午两点吃完午餐回来。他有一份正式的意向书，让我开始 P-80 的工作，起草、批准、签署和密封，让我及时赶上 3 点 30 分的航班返回加利福尼亚。”凯利说，每次他告诉我这件事时，他都会高兴地笑起来。故事。 F104 星际战斗机也发生了同样的事情。时任战略空军司令部司令的布鲁斯·霍洛威 (Bruce Holloway) 将军是 20 世纪 50 年代采购部门的上校，他听取了凯利关于建造超音速喷气式飞机的建议。霍洛威需要获得一份符合凯利性能描述的空军要求清单，作为转发原型合同的第一步。 “天哪，凯利，我会自己写的，”他热情洋溢地宣称。凯利帮助他起草了这份文件，两人将其提交给一位名叫唐·耶茨的将军，并由他签署。总用时：两小时。”</p><p> （第 290 页）</p></blockquote><p>他们还建造了这艘非常酷的船： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BpTDJj6TrqGYTjFcZ/u7ntyrejd8ohdil1x1zs"></p><p>正如凯利的门徒本·里奇 (Ben Rich) 所描述的：</p><blockquote><p> “我们的船有四名船员——船长、舵手、领航员和工程师。相比之下，一艘从事类似工作的护卫舰有三百多名船员。</p><p>从正面看，这艘船看起来就像达斯·维德的头盔。一些看到她的海军军官在看到这艘有史以来在海上航行的最具未来感的船只时厌恶地咬紧牙关。未来的指挥官对只有四名船员在一艘如此秘密的船上发号施令感到不满，因为这艘船是如此秘密，以至于海军甚至无法承认它的存在。我们的隐形舰也许能从天上炸掉一支规模可观的苏联攻击力量，但就军官未来的地位和晋升前景而言，那就和指挥拖船一样光鲜亮丽了。在最高层，海军高层对于保卫航母特遣部队所需的少量隐形舰艇同样不热心。就权力或声望而言，太少的人无法为任何人的职业生涯带来多大好处。”</p></blockquote><p>但他们的最高成就是一架具有传奇色彩的飞机，埃隆·马斯克甚至以它的名字为他的孩子命名...... </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BpTDJj6TrqGYTjFcZ/lrdqi2uru0ppwenmfdwm"></p><p> （这架飞机被称为 A-12 或 SR-71，它们是基本同一型号的两种不同迭代。） </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BpTDJj6TrqGYTjFcZ/vb9skrnacw0wxnyumqch"></p><p>为什么这么棒？</p><p>尽管这是一架用于飞越敌方领土的军用飞机，但它没有任何枪支、照明弹或其他防御装置。因为它的速度太快了，如果有人向它开枪，标准的防御策略就是加速并<i>飞得更快</i>。</p><p>它的巡航速度简直比高速飞行的子弹还快。它在 1.5 秒内飞了一英里。 1 小时内从洛杉矶到华盛顿。尽管历史上被击中超过 4000 次，但它从未被击落，而且我相信它是唯一真正做到这一点的美国军用飞机。它飞得足够高，苏联战斗机甚至无法到达它的高度。他们只是无助地飞到 20,000 英尺以下，加满加力并用力推动飞机，以致于永久损坏了发动机，并绝望地发射了导弹。</p><p>尽管它是在 20 世纪 60 年代建造的，没有计算机的帮助，<i>但直到今天</i>它仍然是有史以来最快的吸气式有人驾驶飞机。</p><p>然而洛克希德公司几乎无法出售它。正如臭鼬工厂内的一名 CIA 工程师所描述的：</p><blockquote><p>飞机将我们所有人推向了处理它的极限。飞行员必须有极大的自信才能踏入驾驶舱，因为他知道自己将以比以前快两倍半的速度飞行。我知道凯利决心将黑鸟技术推广到蓝衣飞行员身上，让整个该死的空军都起来关注他的成果。但我从来没有给他太多机会出售大量这些飞机，因为它们远远领先于其他飞行的飞机，以至于很少有指挥官愿意领导黑鸟联队或中队。我的意思是，这是一位 21 世纪的表演者，于 20 世纪 60 年代初演出。五角大楼里没有人知道如何处理它。</p></blockquote><p>在其鼎盛时期，有 75 名工程师参与其设计。 （在生产高峰期，有 8000 名工人每月生产一架飞机。）</p><p>建造故事本身就是疯狂的。他们无法使用普通材料，因为以 SR-71 的飞行速度，其周围的空气变得足够热，足以熔化机身所用的普通金属。因此他们选择使用钛，尽管以前没有人用钛制造过飞机。他们甚至不知道如何使用它：它足够坚固，以至于他们的工具仅仅试图切割它就会损坏。他们必须发明新颖的制造方法才能发挥作用，并将这些方法传授给制造商。他们必须做一些疯狂的侦探工作来处理突然出现的新故障模式：例如，在注意到一些钛板在六七周后突然失效后。他们最终意识到钛非常容易受到氯的影响，而且这些面板是在七月和八月焊接的，之后必须进行清洗，但每年的这个时候，当地的水系统都会被严重氯化，以防止藻类生长。</p><p>该飞机从构思到投入使用仅用了 20 个月的时间。相比之下，美国最新一代战斗机 F35 于 1995 年开始开发，直到 2021 年才开始全速生产。</p><p>好的。那么他们是怎么做到的呢？</p><p>该项目的一位电气工程师讲述了以下故事：</p><blockquote><p> 1962 年末的一天早上，我走进凯利·约翰逊的办公室，做了自我介绍，并告诉他我在理解臭鼬工厂组织方面遇到了一些困难。当有人问我“如果”的问题时，我真的不知道是谁在问我以及我应该如何回答。凯利走到黑板前画了下面的组织结构图。</p></blockquote><blockquote><p> |KJ|</p><p> _______________________|____________________________</p><p> | | | | | | | | | | | | | | | | | | | | | | | |</p></blockquote><blockquote><p>他说KJ，那就是我，所有在这里工作的人都为我工作。</p></blockquote><p>此外，凯利还帮了我们一个大忙，他明确地写下了他的 14 条管理规则。它们如下：</p><ol><li>臭鼬工厂经理必须被授予对其项目各个方面几乎完全的控制权。他应该向部门总裁或更高级别汇报。</li><li>军队和工业界必须提供强大而小型的项目办公室。</li><li>与该项目有任何关系的人数必须以近乎恶毒的方式受到限制。使用少量的优秀人才（与所谓的正常系统相比为 10% 至 25%）。</li><li>必须提供一个非常简单的绘图和绘图发布系统，并且具有很大的更改灵活性。</li><li>必须有最低数量的报告要求，但重要的工作必须彻底记录。<br><br> [小团队是这里的关键组成部分。为了避免需要冗长的文档，凯利会强制执行一条规则“永远不要让工程师离开装配区域超过五十英尺”。 （第222页）]<br></li><li>必须每月进行一次成本审查，不仅涵盖已支出和承诺的费用，还包括计划结束时的预计成本。</li><li>承包商必须被授权，并且必须承担超出正常范围的责任，以获得项目分包合同的良好供应商投标。商业投标程序通常比军事投标程序更好。</li><li> Skunk Works 目前使用的检查系统已获得空军和海军的批准，符合现有军事要求的意图，应该在新项目中使用。将更基本的检查责任推回给分包商和供应商。不要重复那么多检查。</li><li>必须授权承包商在飞行中测试其最终产品。他可以而且必须在初始阶段进行测试。如果他不这样做，他很快就会失去设计其他车辆的能力。<br><br> [JL：这与一些合同形成鲜明对比，在这些合同中，空军要求承包商建造飞机，但坚持只自己测试。凯利会亲自与战斗机飞行员进行用户访谈，以获得他的飞机的规格，并且还会坚持加入试飞员亲自驾驶飞机，以便迭代设计。]<br></li><li>适用于硬件的规格必须在签订合同之前就已达成一致。因此，强烈建议臭鼬工厂制定规范部分，明确说明[哪些重要的军事规范项目不会故意遵守以及原因]。</li><li>为项目提供资金必须及时，这样承包商就不必不断跑到银行来支持政府项目。</li><li>军事项目组织和承包商之间必须相互信任、日常密切合作和联络。这将误解和通信减少到绝对最低限度。</li><li>外部人员进入项目及其人员必须通过适当的安全措施严格控制。</li><li>由于工程和大多数其他领域只会使用少数人，因此必须提供方法，通过薪酬而不是根据受监督人员的数量来奖励表现良好的人。</li></ol><p>除了这些规则之外，凯利的继任者还描述了臭鼬工厂的成功因素：</p><blockquote><p>我们雇佣了有才华的人才，向他们支付了高薪，并激励他们相信他们可以比其他人领先一两代人生产出像 SR-71 这样的 3 马赫飞机，从而成为世界上最成功的先进项目公司。我们的设计工程师拥​​有丰富的经验，能够在脑海中构思整架飞机，并在空气动力学需求和武器需求之间进行权衡。我们为工程师和车间工人创造了一个实用且开放的工作环境，迫使绘图板后面的人到车间去看看他们的想法如何转化为实际的零件，并当场做出任何必要的改变。我们让每一位设计或处理零件的车间工人负责质量控制。任何工人——不仅仅是主管或经理——都可以退回不符合其标准的零件。这样我们就减少了返工和废品浪费。</p></blockquote><blockquote><p>我们鼓励人们发挥想象力，即兴发挥并尝试非常规的方法来解决问题，然后摆脱困境。通过应用最常识性的方法来开发新技术，我们节省了大量的时间和金钱，同时在与政府客户以及白领和蓝领员工之间的信任与合作氛围中开展业务。最终，洛克希德臭鼬工厂在近乎理想的工作条件下自由运行时，展示了美国创造力的惊人能力。这可能是我们最持久的遗产，也是我们持久自豪的源泉。</p></blockquote><h3>太空探索技术公司</h3><p>我还读过《升空：发射 SpaceX 的绝望早期》，其中记录了该公司从 2002 年到 2008 年的情况，当时他们还年轻，斗志旺盛，接近我觉得能够推理的规模。埃隆是众所周知的大亨：但是当他拥有一支 10 人团队时情况如何呢？</p><p> SpaceX 也很重要，因为它们从事硬件行业，这个行业通常需要大量的前期资本投资（过去只有政府才能发射火箭），而且它们是在美国建造能力已经出现莫洛奇式衰落的时代开始的。已经远去。 SpaceX 首席运营官格温·肖特韦尔 (Gwynne Shotwell) 表示，粗略地说，试图向政府客户解释 SpaceX 如何以及为何使用迭代设计理念是“我在 SpaceX 的几乎整个职业生涯中必须做的最困难的事情之一”（p . 104).</p><p>仅从速度来看，从头开始制造火箭似乎比建造摩天大楼或飞机更困难。 SpaceX 用了大约 3.5 年的时间制造了自己的发动机，用了 5 年的时间成功进行了首次发射，并用了 6 年的时间进入轨道。相比之下，杰夫·贝索斯的蓝色起源公司成立时间较早，于 2000 年成立，二十年后仍未进入轨道（至少在 Liftoff 书出版时）。</p><p>在这里，我收集了书中一些令我印象深刻的摘录，涉及与我正在考虑的有关 Lightcone 组织结构的当前问题相关的领域。</p><p><strong>不同点的团队规模</strong></p><p>大约一年后，SpaceX 聘用了第 14 名员工（埃隆从一开始就有一名私人助理）。在构建第一个原型之前，他们还花了大约一年的时间进行设计。</p><p>三年后，他们即将完成第一台发动机并为第一次全面发射测试做好准备，他们拥有一支总共 160 人的团队，其中大约 12-30 名工程师、技术人员和管理人员在马绍尔群岛的小环礁上工作他们从德克萨斯州麦格雷戈测试场发射，大约有 20 人。 （第 76 页、第 114 页、第 156 页）</p><p><strong>当场决定</strong></p><blockquote><p>为马斯克工作可能会很困难。但他的早期员工可以看到为那些想要把事情做好并经常当场做出决定的人工作的好处。当马斯克（2002 年）决定（一家新的油箱供应商）能够以合理的价格生产优质油箱时，就这样决定了。没有委员会。没有报道。刚完成。 （第 19 页）</p></blockquote><p>并且，相关地：</p><blockquote><p>随着肖特韦尔赢得马斯克的信任，她的角色不断扩大。她最初负责管理客户互动，但最终将 SpaceX 的人力资源、法律和日常运营纳入她的投资组合中。她的存在让马斯克能够集中精力做最有效的事情。马斯克表示，他在 SpaceX 工作的时间——由于他的项目众多，多年来变化很大，但通常占一周的一半时间——马斯克表示，他将 80% 到 90% 的时间花在工程问题上。这包括制定设计决策，以及优化 SpaceX 从供应商获取零件以及制造发动机、火箭和航天器的流程。在会议期间，马斯克会做出仓促的决定。这是 SpaceX 能够如此迅速行动的关键因素之一。<br><br> “我在一个头脑中做出支出决策和工程决策”，他说。 “通常至少有两个人。有一些工程人员试图说服财务人员应该花这笔钱。但财务人员不懂工程，所以他无法判断这是否是一个花钱的好方法。而我正在做出工程和支出决策。所以我已经知道我的大脑相信自己了。”</p></blockquote><p><strong>他们能够自己完成大部分工作</strong></p><p>他们的一些高级工程师也是足够优秀的电工，可以自己对航空电子电路进行接线和迭代。其他人则没有，但必须学习：</p><p> “在猎鹰 1 号的早期，我们什么都做了一点点”，结构工程师李说。 “我学会了如何使用铆钉枪，以及如何将东西焊接在一起。” （第 131 页）</p><p><strong>他们如何应对生活的副作用</strong></p><blockquote><p>[首席运营官 Gwynne Shotwell] 和她的前夫分别抚养两个孩子一周。在与孩子们在一起的几周里，肖特韦尔会提前到达 SpaceX，并在下午 6 点或 7 点左右离开，接替家里的保姆。在其他几周里，她可能会发疯，工作到深夜，并根据需要出差。 （第 103 页）</p><p> [马斯克的高级副总裁穆勒和巴扎]有年幼的孩子，过着双重生活。在十天的时间里，他们将在麦格雷戈工作 12 到 14 小时轮班，然后飞回加利福尼亚州，通常他们会在周四到周日下午休息。 （第 149 页）</p></blockquote><p>另一位早期工程师无法搬到洛杉矶，因为他的妻子在旧金山的谷歌找到了一份她非常喜欢的工作。因此，马斯克与拉里·佩奇进行了交谈，后者同意将这位工程师的妻子调到谷歌洛杉矶办事处。</p><blockquote><p>汤普森（SpaceX 的第二名员工）有一个年轻的家庭，对于离开航空航天行业的舒适职位也有同样的犹豫。在四月底的一次电话中，马斯克寻求解决所有这些担忧，他认识到汤普森正在放弃什么，因此他将两年的工资存入了一个托管账户。如果马斯克决定提前终止该合资企业，他仍然可以获得有保障的收入。 （第 14 页）</p></blockquote><p><strong>关于所有权</strong></p><blockquote><p>[为了在 2006 年与马斯克合作，你必须走中间路线。也就是说，]马斯克听取了想法。他鼓励辩论。他赋予高级员工资金和权力。但始终是他拥有最终决定权。 （第 126 页）</p></blockquote><p>以及相关的《臭鼬工厂》引用：</p><blockquote><p>臭鼬工厂的所有人都知道与凯利·约翰逊相处的两条基本规则：我们制造的所有飞机都是凯利的飞机。无论我们暗自自豪什么，我们都保守自己。如果一名蓝西装球员肩上有星星，那么只有凯利·约翰逊有权与他打交道。 （第 289 页）</p></blockquote><p> ---</p><blockquote><p> [2006年]马斯克将他的不同团队召集到一个小会议室，无论是负责推进、结构还是航空电子设备的工程师，并解决主要问题。如果工程师遇到棘手的问题，马斯克希望有机会解决它。他会提出想法，并给他的团队一两天的时间来排除故障，然后向他汇报。在此期间，如果他们需要指导，他们会被告知直接给马斯克发电子邮件，无论白天还是晚上。他通常会在几分钟内回复。 （第 19 页）</p></blockquote><p> ---</p><blockquote><p>马斯克等待第二次尝试已经将近一年了，他想发射。他向[发射主管]蒂姆·布克萨 (Tim Buxxa) 询问为什么火箭需要完全卸油才能调查问题。有人告诉他，不安全。他们是否可以忽略中止信号，重新启动火箭，然后在当天再次尝试？如果传感器发现了可能威胁任务成功的真正问题，则不会。</p></blockquote><blockquote><p>巴扎 (Buzza) 是发布总监。这是他的电话。他命令火箭排空燃料。 “埃隆非常沮丧”，巴扎说。 “我怀疑，如果他在夸岛的控制室里，他就会如愿以偿，但他在五千英里之外，给了我一点回旋余地，让我可以花更多时间来解决问题。” （第 134 页）</p></blockquote><p>他们经常为<a href="https://www.lesswrong.com/posts/zymnWfGwf6BdDt64c/how-i-buy-things-when-lightcone-wants-them-fast"><strong><u>快速运输</u></strong></a><strong>支付很多费用</strong><strong>&nbsp;</strong></p><p>马斯克有时会借用他的私人飞机来运输零件。在鼎盛时期，他们花费了 50 万美元和一些政治恩惠租用了一架大型军用货机，将原型火箭运送到马绍尔群岛，而不是用船运送几周。</p><p> SpaceX 早期员工凯文·布罗根 (Kevin Brogan) 表示：</p><blockquote><p>马斯克会说，我们所做的一切都是我们的烧钱率的函数，我们每天烧钱十万美元。 [...]</p><p>有时他不会让你买两千美元的零件，因为他希望你找到更便宜的东西或发明更便宜的东西。</p><p>其他时候，他会毫不犹豫地花九万美元租一架飞机去夸吉买东西，因为这样可以节省一整个工作日，所以这是值得的。</p></blockquote><p><strong>对于关键角色，埃隆聘请了经验丰富的领域专家，他们愿意将他们的想法融入他的运营理念中。对于他们的团队，他聘请了更年轻的多面手</strong></p><blockquote><p>在马斯克聘请了几位经验丰富的人来领导他的推进、结构和航空电子部门——汤普森、穆勒和科尼格斯曼——之后，他主要聘请了应届大学毕业生。 [那些毕业生受到的副作用较少，并且愿意非常努力地工作。]（第 25 页）</p></blockquote><p>蒂姆·布扎（Tim Buzza），发布总监：</p><blockquote><p>我们带来了一些传统的航空航天经验，但也愿意完全由埃隆塑造来改变我们的思维。 （第 246 页）</p></blockquote><blockquote><p>而且，为了开始内部制造，他们并没有自己学习所有东西。他们一开始使用一家公司的分包商来制造发动机，但当该公司破产后，SpaceX 收购了他们的机器，并将整个团队带入内部开始他们的加工操作（第 41 页）。</p></blockquote><h3>发生了什么变化？</h3><p>为什么建造能力丧失了？一些相关的引用：</p><blockquote><p>凯利·约翰逊 (Kelly Johnson) 在臭鼬工厂 (Skunk Works) 的得意门生本·里奇 (Ben Rich) 表示：“凯利的固执激怒了几位重要的蓝西装人士和我们公司的一些高级管理人员。 [……]他们所有人都要求同样的事情：我要照顾我们的蓝西装顾客，并且我认识到管理层有责任密切关注我作为凯利的继任者，直到我有机会证明自己。游戏的名称是“相处并相处”——不再是凯利·约翰逊那样的暴虐。我和凯利一样明白，他的权力和独立性是独一无二的，这是任何继任者都无法转让的。无论好坏，对于那些留在凯利·约翰逊时代的人来说，一个新时代正在来临。臭鼬工厂仍然有望取得巨大成果，但坐在老板椅子上的新人将比原来的格列佛小很多。” （第 293 页）</p></blockquote><blockquote><p> “在洛克希德公司工作的四十年里，我曾在二十七架不同的飞机上工作过。今天的年轻工程师即使能够建造出<i>一个</i>，也会很幸运。” （第 316 页）</p></blockquote><blockquote><p> “卡苏夫（SpaceX 早期员工、高级航空电子工程师）有一位在洛克希德·马丁公司工作的朋友，他从事 F-35 隐形飞机的工作，这对公司来说是一个利润丰厚的项目。最终，空军以每台 8500 万美元的价格购买了 2000 多台。这听起来像是一项光鲜亮丽的工作，但事实并非如此。卡苏夫的朋友只有一份工作，为飞机起落架上的螺栓寻找供应商，并确保其符合所有质量规格。那一颗螺栓就是他工作的全部。” （第 23 页升空）</p></blockquote><p>请注意，F-35 是由“同一个”洛克希德公司制造的，该公司也经营臭鼬工厂！ :(</p><p>以下是 Peter Thiel 附属国防初创公司 Anduril（我的模型是他们有点像 Palantir，但针对硬件）关于国防支出变化的信息：</p><blockquote><p>很难想象如今拥有近 300 万美国人的国防部会迅速采取行动。但上个世纪，它的创新速度让现代硅谷初创公司相形见绌：五角大楼仅用了 16 个月就建成了（1941-1943 年），曼哈顿计划只运行了 3 年多一点（1942-1946 年），而阿波罗计划则只用了 3 年多的时间（1942-1946 年）。该计划在十年内（1961-1969）将人类送上月球。仅在20世纪50年代，美国就建造了五代战斗机、三代载人轰炸机、两级航空母舰、潜射弹道导弹和核动力攻击潜艇。</p><p>但是，从 20 世纪 60 年代开始，到 70 年代和 80 年代，军事创新的步伐开始放缓，而成本却在增长。 1955 年，人们已经清楚地看到，国防开支的增长速度是不可持续的：联邦政府的国防开支比其他所有开支的总和还多。⁹ 国会知道必须做出一些改变。罗伯特·S·麦克纳马拉 (Robert S. McNamara) 是一位神童二战老兵，在福特汽车公司以行政效率着称，他是这份工作的最佳人选。</p><p> 20 世纪 60 年代初，在时任国防部长麦克纳马拉的指导下，国防部制定了一套迷宫般的军事系统采购新规则。麦克纳马拉不仅仅是减少支出：他在福特的经验使他相信需要进行全面改革来重塑政府购买技术的方式。他对收购进行了改革，强调效率、消除浪费和可预测性。他实施的规划、规划和预算系统（PPBS，后来改为 PPBE，意为“执行”）流程可以说是有史以来最具影响力的国防改革，不可磨灭地改变了主要国防承包商的激励措施和商业模式。</p><p> [...]</p></blockquote><blockquote><p> <strong>1. 坚持冗长的官僚程序</strong></p></blockquote><blockquote><p>在 PPBS 体系下，政府甚至在考虑购买新的军事系统之前，都会经历长达数年的定义需求的过程，决定在哪里以及如何分配资源，最后为新系统颁发奖励。对于国防部来说，快速获取新技术极其困难，因此国防公司没有快速开发新系统的压力。因此，商业领域开发的技术需要数年或数十年的时间才能最终投入战场（如果真的出现的话）。</p><p> <strong>2. 解决繁重的系统规格</strong></p><p>对主要军事项目的要求进行了详细的阐述，反映出人们普遍认为，要打败苏联，工业界需要执行而不是创新。与大多数由最成功公司的创造力推动的行业不同，国防承包商很少被要求寻找创造性的方法来解决问题，有时还会因此受到惩罚。</p><p> <strong>3. 内部研发投入很少</strong></p><p>由于麦克纳马拉的改革使得快速购买新技术或购买没有明确要求的技术变得异常困难，因此国防公司很少自行开发产品。通常，他们出售现有系统（这是麦克纳马拉领导下的大部分业务），或者等待政府下令进行特定的研发工作，并因此获得直接补偿。相比之下，当今最大的科技公司——其收入远远超过最大的国防公司——将其收入的大约 10-20% 用于研发。较新或中型的科技初创公司的支出可能接近 60% 或 70%。主要国防公司花费 1-4%。</p><p>跨行业的研究与开发。</p><p> <strong>4. 优先考虑提案而非绩效</strong></p><p>麦克纳马拉认为，重复项目是国防部浪费的根源，并且不会容忍政府为类似的新系统进行多项开发工作，无论是在军种之间还是在不同供应商之间。这意味着，一旦一家公司获得了重大合同，就很难从他们手中夺走它。因此，大型国防公司的动机是在律师和游说团队上投入巨资，以根据公司现有的技术制定项目要求。这场政治斗争与构建产品本身同样重要。这些游说者通常是前军官：到 1969 年，每年有 2,000 多名军官离开国防部，为一家主要国防承包商工作，这一数字是 1959 年的三倍。</p><p> <strong>5. 容忍长期失败</strong></p><p>在大多数行业中，无法生产功能性产品的公司就会倒闭。在国防工业中，当一家公司的项目进行了三年、五年、十年，但未能实现其承诺的目标时，政府就会陷入进退两难的境地——他们会取消合同并放弃多年的开发吗？ ，在此过程中可能会使供应商破产吗？或者他们是否不情愿地向供应商提供更多资金来挽救该计划？通常是后者。用臭名昭著的城市规划师罗伯特·摩西的话来说，“一旦你打下第一根木桩，他们就永远不会让你把它拉起来。”</p></blockquote><br/><br/> <a href="https://www.lesswrong.com/posts/BpTDJj6TrqGYTjFcZ/a-golden-age-of-building-excerpts-and-lessons-from-empire#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/BpTDJj6TrqGYTjFcZ/a-golden-age-of-building-excerpts-and-lessons-from-empire<guid ispermalink="false"> BpTDJj6TrqGYTjFcZ</guid><dc:creator><![CDATA[jacobjacob]]></dc:creator><pubDate> Fri, 01 Sep 2023 04:03:44 GMT</pubDate></item><item><title><![CDATA[If you asked a dog whether Humans were conscious, would he say yes?]]></title><description><![CDATA[Published on September 1, 2023 3:57 AM GMT<br/><br/><p>我想可能不会。当狗被问到人类是否“有意识”时，他可能会提到这样的事情：</p><ul><li>人类似乎对周围的环境有所了解，但实际上他们并不是有意识的生物。</li><li>他们似乎经常起床和醒着，但几乎所有的时间都茫然地盯着手中或桌面上的物体，或者在书房里随机移动的物体。</li><li>他们对群体、等级制度、数量安全等的重要性知之甚少。</li><li>他们几乎不了解生活中最重要的危险。比如奇怪的气味和声音，或者穿着制服的陌生人接近巢穴。</li></ul><p>同样，许多（也许是大多数）人工智能专家可能永远不会同意法学硕士或 AGI 系统已经实现了“意识”？因为，“意识”只是一个用来描述特定存在如何在世界上思考、观察、优先考虑和采取行动的词，无论是人类、其他动物、人工智能等。</p><p> “意识”在不同类型的生物中运作方式如此不同。根据生物体真正扩展他们对智力、意识和感知的理解的能力，他们可能永远不会真正同意除他们自己之外的其他类型的生物体或实体的意识？</p><br/><br/> <a href="https://www.lesswrong.com/posts/agi9SCKg4y6auJwEM/if-you-asked-a-dog-whether-humans-were-conscious-would-he#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/agi9SCKg4y6auJwEM/if-you-asked-a-dog-whether- humans-were-sensitive-would-he<guid ispermalink="false"> agi9SCKg4y6auJwEM</guid><dc:creator><![CDATA[Super AGI]]></dc:creator><pubDate> Fri, 01 Sep 2023 09:15:02 GMT</pubDate> </item><item><title><![CDATA[Meta Questions about Metaphilosophy]]></title><description><![CDATA[Published on September 1, 2023 1:17 AM GMT<br/><br/><p> To quickly recap my main intellectual journey so far (omitting a lengthy <a href="https://www.lesswrong.com/posts/m8FjhuELdg7iv6boW/work-on-security-instead-of-friendliness">side trip</a> into cryptography and Cypherpunk land), with the approximate age that I became interested in each topic in parentheses:</p><ul><li> (10) Science - Science is cool!</li><li> (15) Philosophy of Science - The scientific method is cool! Oh look, there&#39;s a whole field studying it called &quot;philosophy of science&quot;!</li><li> (20) Probability Theory - Bayesian subjective probability and the universal prior seem to constitute an elegant solution to the philosophy of science. Hmm, there are some curious probability puzzles involving things like indexical uncertainty, copying, forgetting... I and others make some progress on this but fully solving anthropic reasoning seems really hard. (Lots of people have worked on this for a while and have failed, at least according to my judgement.)</li><li> (25) Decision Theory - Where does probability theory come from anyway? Maybe I can find some clues that way? Well according to von Neumann and Morgenstern, it comes from decision theory. And hey, maybe it will be really important that we get decision theory right for AI? I and others make some progress but fully solving decision theory turns out to be pretty hard too. (A number of people have worked on this for a while and haven&#39;t succeeded yet.)</li><li> (35) Metaphilosophy - Where does decision theory come from? It seems to come from philosophers trying to do philosophy. <a href="https://www.lesswrong.com/posts/MAhueZtNz5SnDPhsy/metaphilosophical-mysteries">What is that about?</a> Plus, maybe it will be <a href="https://www.lesswrong.com/posts/w6d7XBCegc96kz4n3/the-argument-from-philosophical-difficulty">really important that the AIs we build will be philosophically competent</a> ?</li><li> (45) Meta Questions about Metaphilosophy - Not sure how hard solving metaphilosophy really is, but I&#39;m not making much <a href="https://www.lesswrong.com/posts/EByDsY9S3EDhhfFzC/some-thoughts-on-metaphilosophy">progress</a> on it by myself. Meta questions once again start to appear in my mind:<ul><li> Why is there <a href="https://www.lesswrong.com/posts/xWMqsvHapP3nwdSW8/my-views-on-doom?commentId=MqBLzocx8z8jDamop">virtually</a> <a href="https://www.lesswrong.com/posts/Ghrdnc26ftJrxD49z/carl-shulman-on-the-lunar-society-7-hour-two-part-podcast?commentId=Mp96pHQyhoyEaA2MZ">nobody</a> <a href="https://forum.effectivealtruism.org/posts/WYsLjeJzh7tZqe6Lo/implications-of-evidential-cooperation-in-large-worlds?commentId=HPdgoLKheaEnSwcqD">else</a> interested in metaphilosophy or ensuring AI philosophical competence (or that of future civilization as a whole), even as we get ever closer to AGI, and other areas of AI safety start attracting more money and talent?</li><li> Tractability may be a concern but shouldn&#39;t more people still be talking about these problems if only to raise the alarm (about an additional reason that the AI transition may go badly)? (I&#39;ve listened to all the recent podcasts on AI risk that I could find, and nobody brought it up even once.)</li><li> How can I better recruit attention and resources to this topic? For example, should I draw on my crypto-related fame, or start a prize or grant program with my own money? I&#39;m currently not inclined to do either, out of inertia, unfamiliarity, uncertainty of getting any return, fear of drawing too much attention from people who don&#39;t have the highest caliber of thinking, and signaling wrong things (having to promote ideas with one&#39;s own money instead of attracting attention based on their merits). But I&#39;m open to having my mind changed if anyone has good arguments about this.</li><li> What does it imply that so few people are working on this at such a late stage? For example, what are the implications for the outcome of the human-AI transition, and on the distribution of philosophical competence (and hence the distribution of values, decision theories, and other philosophical views) among civilizations in the universe/multiverse?</li></ul></li></ul><p> At each stage of this journey, I took what seemed to be the obvious next step (often up a meta ladder), but in retrospect each step left behind something like 90-99% of fellow travelers. From my current position, it looks like &quot;all roads lead to metaphilosophy&quot; (ie, one would end up here starting with an interest in any nontrivial problem that incentivizes asking meta questions) and yet there&#39;s almost nobody here with me. <em>What gives?</em></p><p> As for the AI safety path (as opposed to pure intellectual curiosity) that also leads here, I guess I do have more of a clue what&#39;s going on. I&#39;ll describe the positions of 4 people I know. Most of this is from private conversations so I won&#39;t give their names.</p><ul><li> Person A has a specific model of the AI transition that they&#39;re pretty confident in, where the first AGI is likely to develop a big lead and if it&#39;s aligned, can quickly achieve human uploading then defer to the uploads for philosophical questions.</li><li> Person B thinks that ensuring AI philosophical competence won&#39;t be very hard. They have a specific (unpublished) idea that they are pretty sure will work. They&#39;re just too busy to publish/discuss the idea.</li><li> Person C will at least think about metaphilosophy in the back of their mind (as they spend most of their time working on other things related to AI safety).</li><li> Person D thinks it is important and too neglected but they personally have a comparative advantage in solving intent alignment.</li></ul><p> To me, this paints a bigger picture that&#39;s pretty far from &quot;humanity has got this handled.&quot; If anyone has any ideas how to change this, or answers to any of my other unsolved problems in this post, or an interest in working on them, I&#39;d love to hear from you.</p><br/><br/> <a href="https://www.lesswrong.com/posts/fJqP9WcnHXBRBeiBg/meta-questions-about-metaphilosophy#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/fJqP9WcnHXBRBeiBg/meta-questions-about-metaphilosophy<guid ispermalink="false"> fJqP9WcnHXBRBeiBg</guid><dc:creator><![CDATA[Wei Dai]]></dc:creator><pubDate> Fri, 01 Sep 2023 01:17:57 GMT</pubDate> </item><item><title><![CDATA[[Linkpost] Michael Nielsen remarks on 'Oppenheimer']]></title><description><![CDATA[Published on August 31, 2023 3:46 PM GMT<br/><br/><p> This is a linkpost to a recent blogpost from <a href="https://michaelnielsen.org/">Michael Nielsen</a> , who has previously written on <a href="https://michaelnotebook.com/eanotes/">EA</a> among many other topics. This blogpost is adapted from a talk Nielsen gave to an audience working on AI before a screening of <i>Oppenheimer</i> . I think the full post is worth a read, but I&#39;ve pulled out some quotes I find especially interesting (bolding my own)</p><blockquote><p> I was at a party recently, and happened to meet a senior person at a well-known AI startup in the Bay Area. They volunteered that they thought &quot;humanity had about a 50% chance of extinction&quot; caused by artificial intelligence. I asked why they were working at an AI startup if they believed that to be true. They told me that while they thought it was true, &quot; <strong>in the meantime I get to have a nice house and car</strong> &quot;.</p></blockquote><blockquote><p> [...] I often meet people who claim to sincerely believe (or at least seriously worry) that AI may cause significant damage to humanity. And yet they are also working on it, justifying it in ways that sometimes seem sincerely thought out, but which <strong>all-too-often seem self-serving or self-deceiving.</strong></p></blockquote><p></p><blockquote><p> Part of what makes the Manhattan Project interesting is that we can chart the arcs of moral thinking of multiple participants [...] Here are four caricatures:</p><ul><li> Klaus Fuchs and Ted Hall were two Manhattan Project physicists who took it upon themselves to commit espionage, communicating the secret of the bomb to the Soviet Union. It&#39;s difficult to know for sure, but <strong>both seem to have been deeply morally engaged and trying to do the right thing, willing to risk their lives</strong> ; they also made, I strongly believe, a terrible error of judgment. I take it as a warning that <strong>caring and courage and imagination are not enough</strong> ; they can, in fact, lead to very bad outcomes.</li><li> Robert Wilson, the physicist who recruited Richard Feynman to the project. Wilson had thought deeply about Nazi Germany, and the capabilities of German physics and industry, and made a principled commitment to the project on that basis. He half-heartedly considered leaving when Germany surrendered, but opted to continue until the bombings in Japan. He later regretted that choice; immediately after the Trinity Test he was disconsolate, telling an exuberant Feynman: &quot;It&#39;s a terrible thing that we made&quot;.</li><li> Oppenheimer, who I believe was motivated in part by a genuine fear of the Nazis, but also in part by personal ambition and a desire for &quot;success&quot;. It&#39;s interesting to ponder his statements after the War: while he seems to have genuinely felt a strong need to work on the bomb in the face of the Nazi threat, his comments about continuing to work up to the bombing of Hiroshima and Nagasaki contain many strained self-exculpatory statements about how you have to work on it as a scientist, that the technical problem is too sweet. It smells, to me, of someone looking for self-justification.</li><li> Joseph Rotblat, the one physicist who actually left the project after it became clear the Nazis were not going to make an atomic bomb. He was threatened by the head of Los Alamos security, and falsely accused of having met with Soviet agents. In leaving he was turning his back on his most important professional peers at a crucial time in his career. <strong>Doing so must have required tremendous courage and moral imagination</strong> . Part of what makes the choice intriguing is that <strong>he himself didn&#39;t think it would make any difference to the success of the project. I know I personally find it tempting to think about such choices in abstract systems terms: &quot;I, individually, can&#39;t change systems outcomes by refusing to participate [&#39;it&#39;s inevitable!&#39;], therefore it&#39;s okay to participate&quot;</strong> . And yet while that view seems reasonable, Rotblat&#39;s example shows it is incorrect. His private moral thinking, which seemed of small import initially, set a chain of thought in motion that eventually led to Rotblat founding the Pugwash Conferences, a major forum for nuclear arms control, one that both Robert McNamara and Mikhail Gorbachev identified as helping reduce the threat of nuclear weapons. Rotblat ultimately received the Nobel Peace Prize. <strong>Moral choices sometimes matter not only for their immediate impact, but because they are seeds for downstream changes in behavior that cannot initially be anticipated.</strong></li></ul></blockquote><br/><br/> <a href="https://www.lesswrong.com/posts/ppQRJEfLBCLFzK73w/linkpost-michael-nielsen-remarks-on-oppenheimer#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ppQRJEfLBCLFzK73w/linkpost-michael-nielsen-remarks-on-oppenheimer<guid ispermalink="false"> ppQRJEfLBCLFzK73w</guid><dc:creator><![CDATA[22tom]]></dc:creator><pubDate> Thu, 31 Aug 2023 15:46:06 GMT</pubDate> </item><item><title><![CDATA[My thoughts on AI and personal future plan after learning about AI Safety for 4 months]]></title><description><![CDATA[Published on August 31, 2023 3:32 PM GMT<br/><br/><p> In this post, I want to distill some of my thoughts about AI and my future plan regarding it according to what I have learnt during the past 4 months.</p><p> About my personal background: My background lies in Financial Engineering and Mathematics, and I used to get motivated by making AI more powerful. I decided to shift my focus to AI Safety after reading and getting convinced by the idea inside <a href="https://80000hours.org/problem-profiles/artificial-intelligence/">Preventing an AI-related catastrophe</a> . During the past 4 months, I  finished</p><ul><li> <a href="https://course.aisafetyfundamentals.com/alignment">Alignment Course from AI Safety Fundamentals</a></li><li> 6 out of 9 Topics inside <a href="https://github.com/jacobhilton/deep_learning_curriculum">Deep Learning Curriculum</a></li><li> 4 out of 5 Chapters inside <a href="https://www.arena.education/">ARENA</a></li><li> a <a href="https://github.com/ZiyueWang25/llm-security-challenge">paper</a> from <a href="https://alignmentjam.com/jam/evals">LLM Evals Hackathon</a></li><li> And many readings across <a href="https://www.alignmentforum.org/">AI Alignment Forum</a> , LessWrong and different AI Safety focused team/org/company.</li></ul><p> I kept those related posts/learning in my <a href="https://ziyuewang25.github.io/">website</a> if you are interested.</p><p> Overall, I think the future of AI is promising but in the same dangerous if they cannot align with our intention. It is like what has been discussed in <a href="https://theprecipice.com/">Precipice</a> and I want to take the chance to help it.</p><p> It is promising because it already demonstrated superior capability, and can be used to improve people&#39;s life quality. The application field can be robotics, education, health system, productivity boost and etc.</p><p> But AI can get misaligned if we aren&#39;t paying enough attention to it. Here, according to Paul Christiano, alignment means <a href="https://ai-alignment.com/clarifying-ai-alignment-cec47cd69dd6">intent alignment</a> :</p><blockquote><p> AI A is aligned with an operator H when A is trying to do what H wants it to do.</p></blockquote><p> The focus here is &quot;trying&quot;, which means it is on intention/goal/motivation level rather than behavior level. A model can behave like aligned but it tries to <a href="https://www.lesswrong.com/posts/YgAKhkBdgeTCn6P53/ai-deception-a-survey-of-examples-risks-and-potential">deceive human</a> or human actually couldn&#39;t see its defect due to the high complexity of future tasks.</p><p> In the argument above, we assumed it can have &quot;intention&quot; and we can understand how it comes from by using optimizer. When we train a model, we use an optimizer which usually tries to minimize certain loss function or maximize reward function by adjusting the weight of the model. For example, <a href="https://openai.com/gpt-4">GPT</a> is pre-trained by minimizing the next token prediction loss. So the goal of it, at that stage, is simply trying to make the next word make sense given what it sees in the past. Its goal is not about aligning with human instruction and making human happy or productive. Hence we need to do further fine-tuning, like <a href="https://huggingface.co/blog/rlhf">Reinforcement From Human Feedback</a> (RLHF), to make it align with human instruction.</p><p> But I am not confident they are aligned by doing this. Here are several reasons:<br> 1.<a href="https://www.youtube.com/watch?v=bJLcIBixGj8&amp;t=147s&amp;ab_channel=RobertMilesAISafety"><strong>Mesa-optimizer</strong></a> : The optimizer we used in the model training is <strong>not the same</strong> as the optimizer inside (mesa-optimizer) the model that drives its behavior. For example, we can use a dataset to teach the model to tell the truth but due to labeling mistake, the model can understand it as <strong>telling the result as long as human think it is correct, rather than the truth</strong> . Also, It can comes from a concept called &quot; <a href="https://drive.google.com/file/d/1KewDov1taegTzrqJ4uurmJ2CJ0Y72EU3/view"><strong>instrumental convergence</strong></a> &quot;, which means as the model tend to do something, it can also develop some common instrumental goals to help itself achieve that. Common instrumental goals are For example, it is trained to make the quality of a person better, and it learnt to avoid self-preservation, power-seeking and etc. being shutdown because if it get shut down, it can no longer  make a person life better. So overall, a mesa-optimizer makes the intention of the model different from what we want, hence misaligned.</p><p> 2. <strong>The bulk of capability and hence &quot;intention&quot; are still from pretraining</strong> :  Compared with fine-tuning, pre-training takes hundreds of more resources to do. During that phase, the model get exposed to a lot of knowledge. It is not told to be polite and helpful during that phase, it is simply told to predict the next word. Putting this mode on human would be like: children are getting &quot;educated&quot; about reasoning, culture, reading comprehension and etc without being told about what is a good intention and how to communicate or help other people. This sounds dangerous because before they are being told about what is a good intention, they can already develop their own view strongly, which may not be in favor of the good intention. This is especially dangerous when the pre-training data, corpus, contains a lot of toxic/biased data. Some arguments against this would be how the model learns is different from human and their intention can be corrected during finetuning phase. But still, there is a chance that they can develop strong intention during pre-training phase, which we has almost no control over, except making the data better.</p><p> 3. <strong>Many existing jail breaker</strong> : there are many <a href="https://www.lesswrong.com/posts/RYcoJdvmoBbi5Nax7/jailbreaking-chatgpt-on-release-day">examples</a> showing that models can be turned into a rude/toxic mode. Those behavior can be elicited by using role-play and some other hacking methods. They are the sign of bad intention within the model that we currently cannot control with.</p><p> Even when the model is aligned, it can still be misused. So a model that tries to do what human wants it to do can also be applied to dangerous field, like weapon development, attacking security system and etc. This requires policy maker and corporate to have proper control over how AI gets deployed and used, which leads to a large field of AI safety policy and governance. For more details, please check <a href="https://www.lesswrong.com/posts/9dNxz2kjNvPtiZjxj/an-overview-of-catastrophic-ai-risks-summary">An overview of Catastrophic AI Risks</a> .</p><p> According to <a href="https://theprecipice.com/">Precipice</a> , misaligned AI can pose existential risk to humanity and the chance about it for this century is around 10%. This a large percentage and may sound wild to you at this moment and you may not be convinced, that&#39;s totally understandable. But even we feel uncertain at this moment, the outcome of this small-chance event is unimaginable. This puts us into urgent state to take action and for me, it is about becoming an <a href="https://80000hours.org/articles/ml-engineering-career-transition-guide/">AI Safety Research Engineer</a> to help model get aligned.</p><p> I started learning about different safety topics since May 2023. According to <a href="https://forum.effectivealtruism.org/posts/63stBTw3WAW6k45dY/paul-christiano-current-work-in-ai-alignment">the AI landscape</a> from Paul Christiano, there are many topics about AI alignment. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GreaiJYjFDziXbfCw/fjahdkrvd3sizrknos1l" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GreaiJYjFDziXbfCw/hvtfn8pnguvspgux5geo 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GreaiJYjFDziXbfCw/npn65thtmwcceeddsq0c 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GreaiJYjFDziXbfCw/pdfnopkkskm3nheyxpye 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GreaiJYjFDziXbfCw/fv6xlptuud6usm0aacjz 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GreaiJYjFDziXbfCw/vu8pwbnfh0mx1jmutah1 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GreaiJYjFDziXbfCw/ytvmro2npdf2p0bki2ov 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GreaiJYjFDziXbfCw/uqc5jdxrp6t7zufibd6e 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GreaiJYjFDziXbfCw/y6rq8bjjnnrgqg2fhbqc 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GreaiJYjFDziXbfCw/loxj5qblqzawty3ohwfg 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GreaiJYjFDziXbfCw/kn5p1tqzrkfio2nlt467 1100w"><figcaption> AI Landscape from Paul Christiano</figcaption></figure><p></p><p> Up to this point, to be honest, I don&#39;t have a strong preference over which direction to go. But if I had to say one, I think &quot;Inner Alignment&quot; part sounds more important to me because only with inner alignment verification, we can tell whether outer alignment worked or not. The concrete inner alignment examples are like <a href="https://www.anthropic.com/index/core-views-on-ai-safety">Scalable Oversight</a> , <a href="https://transformer-circuits.pub/2022/mech-interp-essay/index.html">Mechanistic Interpretability</a> , Automated <a href="https://huggingface.co/blog/red-teaming">Red Teaming</a> , <a href="https://www.lesswrong.com/tag/eliciting-latent-knowledge-elk#:~:text=Eliciting%20Latent%20Knowledge%20is%20an,that%20look%20good%20to%20us">Eliciting Latent Knowledge</a> , and etc.</p><p> The main point at this point in my life is to switch my career towards them and contribute the bulk of my day time to maximize my impacts. I felt motivated given the urgency we have to solve this alignment problem and I look forward to the day of becoming an AI Safety Research Engineer :)</p><br/><br/> <a href="https://www.lesswrong.com/posts/GreaiJYjFDziXbfCw/my-thoughts-on-ai-and-personal-future-plan-after-learning#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/GreaiJYjFDziXbfCw/my-thoughts-on-ai-and-personal-future-plan-after-learning<guid ispermalink="false"> GreaiJYjFDziXbfCw</guid><dc:creator><![CDATA[Ziyue Wang]]></dc:creator><pubDate> Fri, 01 Sep 2023 05:18:35 GMT</pubDate> </item><item><title><![CDATA[Which Questions Are Anthropic Questions?]]></title><description><![CDATA[Published on August 31, 2023 3:15 PM GMT<br/><br/><p> I will try to keep this shot, just want to use some simple problems to point out what I think is a commonly overlooked point in anthropic discussions.</p><h2> 1. The Room Assignment Problem</h2><blockquote><p> You are among 100 people waiting in a hallway. The hallway leads to a hundred rooms numbered from 1 to 100. All of you are knocked out by a sleeping gas and each put into a random/unknown room. After waking up, what is the probability that you are in room No. 1?</p></blockquote><p> This is just an ordinary probability question. All room numbers are symmetrical, the answer is simply 1%. It is also easy to imagine taking part in similar room-assigning experiments a great number of times, the relative fraction of you waking up in room No.1, or any other number, would approach 1%.</p><p> It is safe to say this is not an anthropic question. Even for people with the metaphysical stance that all probabilities are anthropic, it is undeniable that we have been solving such questions successfully without any anthropic considerations.</p><h2> 2. The Incubator</h2><blockquote><p> An incubator enters the hallway. It will enter room No.1 and creat a person in it then does the same for the other 99 rooms.  It turns out you are one of the people the incubator has just created. You wake up in a room and is made aware of the experiment setup. What is the probability that you are in room No.1?</p></blockquote><p> While this question may seem trivial, it is an anthropic question. In ordinary problems like Question 1, an event refers to a unique experiment outcome, a distinct possible world. But this incubator problem, objectively speaking, is deterministic. Knowing the exact process from a god&#39;s eye view still leaves uncertainty because the uncertainty comes from the fact that you are unsure of your own location in this only world, eg which physical person is the subjective self. This kind of same-world event is the crux of anthropic paradoxes. Eg the sleeping beauty problem is special because of the two awakenings both in the Tails world.</p><p> Also worth noting the frequentist model is much trickier to imagine. While the incubator has no problem performing this job ten thousand times, and creating a million people in the process, it seems absurd to say you are one of the people created in each experiment, that you are ten thousand people. Obviously, this is not a run-of-the-mill question.</p><h2> 3. Incubator + Room Assignment</h2><blockquote><p> This time the incubator creats 100 people in the hall way, you are among the 100 people created. Each person is then assigned to a random room. What is the probability that you are in Room 1?</p></blockquote><p> This is just an ordinary probability question. In fact, it is Question 1 with some background story of how you got in the hallway before the experiment began. Whether you were there because of the incubator or some other process does not affect the room-assigning process. Different room numbers still reflect unique assignments and different possible worlds.</p><p> Instead of taking which physical person is the self as a given fact, some might want to treat it the same way as in Question 2, implying besides the room assignment process, the uncertainty also comes from which physical person the self is. This would lead to undesirable consequences. However, that is not the focus of this post. Even if one endorses this approach it is undeniable that Questions 2 and 3 are different in nature. The former&#39;s uncertainty entirely depends on the single-world self-location while the latter doesn&#39;t.</p><h2> Discussion</h2><p> Almost all anthropic discussions implicitly treat Questions 2 and 3 as the same problem not worth differentiating. Some, eg Nick Bostrom IMSMR, explicitly stated that they ought to be regarded as equivalent. But this position is not accompanied by any explanation. It is treated as an intuitive thing to simply accept.</p><p> But such equivalency links anthropic problems with ordinary ones. It requires justification. One possible justification, which I think is also one major reason why the equivalency seems so intuitive, is that all popular anthropic theories, including both SSA and SIA, as long as they consider the self as a random sample, would treat Question 2 the same way as Question 1. From this, it follows Question 2 and 3 are equivalent as well.</p><p> In reality, however, the arguments sometimes take the opposite direction. People take the equivalency as an indisputable fact and from there argue for the credibility of common anthropic assumptions. Without an independent justification for the purposed equivalency, this logic is circular.</p><br/><br/> <a href="https://www.lesswrong.com/posts/SjEFqNtYfhJMP8LzN/which-questions-are-anthropic-questions#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/SjEFqNtYfhJMP8LzN/which-questions-are-anthropic-questions<guid ispermalink="false"> SjEFqNtYfhJMP8LzN</guid><dc:creator><![CDATA[dadadarren]]></dc:creator><pubDate> Thu, 31 Aug 2023 15:15:39 GMT</pubDate> </item><item><title><![CDATA[The Tree of Life, and a Note on Job ]]></title><description><![CDATA[Published on August 31, 2023 2:03 PM GMT<br/><br/><p> This is another one cross-posted from <a href="https://new-savanna.blogspot.com/2011/06/tree-of-life-and-note-on-job.html">my New Savanna blog</a> . It&#39;s old, 11 years (and most of it is even older than that). It&#39;s an interpretation of the Book of Job, which is not at all the sort of thing I&#39;d ordinarily post here. I certainly don&#39;t see much of that kind of thing going on. But I&#39;m in an experimental and playful mood, so why not?</p><p> FWIW and BTW, I&#39;m neither Christian nor Jewish, so this post isn&#39;t an expression of religious belief.</p><p> Here goes:</p><p> More or less <a href="http://www.michaelspornanimation.com/splog/?p=2655">on Michael Sporn&#39;s recommendation</a> , I&#39;ve just seen Terrence Malick&#39;s <i>The Tree of Life</i> . While I&#39;m collecting my thoughts on this trying, tedious, and rewarding film, I&#39;ll let Michael&#39;s thoughts stand-in for many of mine:</p><blockquote><p> The film starts with a vision of god that moves beyond to a patriarchal dominated family in Waco, Texas. The suggestion of a death leads us back to god and the creation of the earth. From protozoa to dinosaur to the birth of a child, this filmmaker exudes absolute love for every organism he can show us on screen. Yet, right from the dinosaurs onward he creates an ominous tone in this male-dominated power hungry environment. You&#39;re always expecting something terrible to happen in the hands of the children who push the film forward. This is a film that technically has a new way of presenting itself almost through an impressionistic vision. The whispered narration and dialogue mix and blend into one; the sun streamed backlit late-afternoon interiors create a whispered visual to match.</p></blockquote><p> It was the phrase “from protozoa to dinosaur” that got me.</p><p> The film is that of a mystic. I know nothing of Malick, though it seems he was <a href="http://www.whitehorseinn.org/blog/2011/06/20/review-of-the-tree-of-life/">born in the Bible belt and studied philosophy</a> , so I don&#39;t know if he is really mystic, but then, what&#39;s <i>really</i> in that question? I once told my draft board that I was a mystic. <i>Really?</i> Really. That&#39;s what comes through in the film: “exudes absolute love for every organism he can show us on screen.”<br><br> The film&#39;s explicit religiosity bugged me in the beginning. <i>Am I going to have to say something about this in my review? Am I going to have to declare, for example, whether or not I&#39;m a believer?</i> And then it didn&#39;t bug me, not for the last hour or so. I just forgot about it.<br><br> I&#39;ll have more to say about the film later, but I just wanted to dig out some old notes, from 25 years ago, on Job. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wKHbJPbzLtgCfXcQe/wfoah7kpktutxoem2cex" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wKHbJPbzLtgCfXcQe/gw8ab8ritauxdh2l2jhc 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wKHbJPbzLtgCfXcQe/xtygnuqs0wrflnjedxka 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wKHbJPbzLtgCfXcQe/y5mwsemcf5y7dg0sydjl 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wKHbJPbzLtgCfXcQe/ug9vypqgjaaikwjlr5wn 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wKHbJPbzLtgCfXcQe/qkfjplnybgprcbmzwdtr 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wKHbJPbzLtgCfXcQe/uetqxkcivsz9mex7xqgb 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wKHbJPbzLtgCfXcQe/u7ydvcwtyqdwfemitlak 1890w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wKHbJPbzLtgCfXcQe/cldcdjgskxbop0eoay7x 2160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wKHbJPbzLtgCfXcQe/azi9sdukf9ib0oy4n54z 2430w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wKHbJPbzLtgCfXcQe/l1ve2ig7hacxpr60maei 2677w"></figure><p> To understand the story of Job we must first reject the ending, in which Job regains all that he has lost, and more, for his possessions were doubled. The ending is known to be a later addition. We reject it, for it subverts the deepest significance of the basic story, which is that man and God are essentially and absolutely different, hence there can be no reciprocal contracts between them. The effect of that ending is to assimilate the story to an ethos in which such contracts are possible, in which it is reasonable for man to bargain with God.<br><br> The view of the relationship between man and God which is assumed, first by Job&#39;s three friends, Eliphaz, Bildad, and Zophar, and later by Elihu (also a later addition), is basically a contractual one. There are rights and obligations on both sides of the contract and if either party breaks the contract he is liable to punitive action by the other party. God may be immensely more powerful and knowledgeable than man, but he is no so deeply different that he cannot enter into contracts with man. In this view God is assumed to be just and a man&#39;s state is assumed to reflect his performance in carrying out his obligations to the divine contract. The basic contract seems to be: Man obeys God&#39;s rules and is rewarded or punished accordingly. Prosperity is a sign of good performance while misfortune is a sign of poor performance. Job&#39;s misfortune&#39;s are taken as a sign of his poor performance.<br><br> However, Job rigorously examines his life and can find no instances of poor contractual performance. He has met his obligations. Hence he cannot understand why he is being punished. But, the text is careful to assert, &quot;Throughout all this, Job did not utter one sinful word.&quot; His friends insist that he must have done something wrong, otherwise God wouldn&#39;t be punishing him. Hence he should look more deeply and continue to do so until he finds what he has done wrong. Job will have none of this. And so we face a dilemma. If Job is both just and the victim of misfortune, is God then unjust?<br> The answer indicated by the text is, in effect, that justice has nothing to do with it, that the relationship between man and God is not one of reciprocal contractual obligation. On the contrary, it is wholly one-sided. God begins his answer by telling Job to &quot;Brace yourself and stand up like a man.&quot; He then begins a long series of rhetorical questions:</p><blockquote><p> Where were you when I laid the earth&#39;s foundations?<br> Tell me, if you know and understand.<br> Who settled its dimensions? Surely you should know.<br> Who stretched his measuring-line over it?<br> On what do its supporting pillars rest?<br> Who set its corner-stone in place,<br> when the morning stars sang together<br> and all the sons of God shouted aloud?</p></blockquote><p> The series of such questions amounts to a miniature encyclopedia of natural phenomena, one which emphasizes the absolute difference between God and man. For God has done and understands all this things while man, Job, has done and understood none of them. Job acknowledges this absolute difference, finally replying</p><blockquote><p> I know that thou canst do all things<br> and that no purpose is beyond thee.<br> But I have spoken of great things which I have not understood,<br> things too wonderful for me to know.<br> I knew of thee then only by report,<br> but now I see thee with my own eyes.<br> Therefore I melt away;<br> I repent in dust and ashes.</p></blockquote><p> The effect of the added ending, in which Job gets it all back, with interest, is to undermine this absolute difference between the human and the divine. If Job gets it all back, with interest, then the contract was not really broken at all. Job gets what is his due. That, however, is not what the story is about. The story is about absolute difference; it is attempting to replace the contractual view of the relationship between the human and the divine with a deeply ontological view, in which the divine is the underpinning, the ground, of the human.<br><br> Notice that the story is framed in such a way that the audience or the reader knows that Job did not do any wrong and that he is not being unjustly punished. We know that Job&#39;s misfortunes have nothing to do with punishment. The real reason - that Job is being used to make a point to Satan - may not be much better from our modern point of view; but it doesn&#39;t contradict the basic point. In fact, the frame reinforces the point. For Satan has argued that Job is good only because God has rewarded him well. “But stretch out your hand and touch all that he has, and then he will curse you to your face.” And so Satan is given permission to wreck Job&#39;s life and Job does not, in fact, curse God. The story shows Satan, and us, that his view of the relationship between the human and the divine, which is the contractual view, is wrong.<br><br> Whatever the relationship between the human and the divine, it is such that Job was able to bear up under his misfortune without either blaming himself or cursing God. Could it be that he was able to do so precisely because God was Completely and Categorically Other?</p><br/><br/> <a href="https://www.lesswrong.com/posts/wKHbJPbzLtgCfXcQe/the-tree-of-life-and-a-note-on-job#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/wKHbJPbzLtgCfXcQe/the-tree-of-life-and-a-note-on-job<guid ispermalink="false"> wKHbJPbzLtgCfXcQe</guid><dc:creator><![CDATA[Bill Benzon]]></dc:creator><pubDate> Thu, 31 Aug 2023 14:03:46 GMT</pubDate> </item><item><title><![CDATA[Cleaning a SoundCraft Mixer]]></title><description><![CDATA[Published on August 31, 2023 1:20 PM GMT<br/><br/><p><span>在</span><a href="https://www.kingfisherband.com/">《翠鸟》</a>中，<a href="https://www.ceciliavacanti.com/">塞西莉亚</a>在她的小提琴上使用了<a href="https://www.audio-technica.com/en-us/pro35">电容器</a>，但将其与效果踏板结合在一起。这<a href="https://www.jefftk.com/p/fiddle-effects-tech">工作起来有点尴尬</a>，我们一直在使用<a href="https://www.soundcraft.com/en-US/products/notepad-5">Soundcraft Notepad</a>迷你混音器。不幸的是，我们最近遇到了一些问题，调整输入增益会发出可怕的刺耳噪音： </p><p><iframe src="https://www.youtube.com/embed/EJBCgvaP2ak?si=V0gEJ1Zmtgg9mPHd" allow="accelerometer;
autoplay; clipboard-write; encrypted-media; gyroscope;
picture-in-picture; web-share" allowfullscreen=""></iframe></p><p>我以为我需要拆开搅拌机来清洁它，但是在网上查找了一下建议，轻轻地将旋钮从板子表面拉下来，喷洒接触处理剂，然后转动主轴以进行处理。 . 这让我感到惊讶：这真的会把清洁器分配到需要的地方吗？但我订购了一些<a href="https://hosatech.com/products/accessories/cleaners-conditioners/caig-cleaners-conditioners/d5/">Deoxit 5%</a>并按照罐头上的说明进行操作，效果非常好！ </p><p><iframe src="https://www.youtube.com/embed/j5_7vaDtLTQ?si=mg7IOOj2Zhu6wNs7" allow="accelerometer;
autoplay; clipboard-write; encrypted-media; gyroscope;
picture-in-picture; web-share" allowfullscreen=""></iframe></p><p>现在调节增益时我根本听不到任何噪音。</p><p>我现在几乎有一整罐这样的东西，所以如果你在波士顿并且遇到类似的问题，欢迎你来借用它。</p><p> （尽管调音台现在运行良好，但 Cecilia 并不打算再使用它：她买了一个<a href="https://www.radialeng.com/product/voco-loco">Voco Loco</a> ，这是一个专门为此目的而设计的盒子。它应该更加坚固可靠，旋钮和开关更少，可能会被撞到错误的位置。）</p><br/><br/><a href="https://www.lesswrong.com/posts/hyuD9e7kAoHrWSyj7/cleaning-a-soundcraft-mixer#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/hyuD9e7kAoHrWSyj7/cleaning-a-soundcraft-mixer<guid ispermalink="false"> hyuD9e7kAoHrWSyj7</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Thu, 31 Aug 2023 13:20:03 GMT</pubDate></item></channel></rss>