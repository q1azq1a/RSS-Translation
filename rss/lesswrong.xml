<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 22 日星期三 08:15:45 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Portable Chargers are Great]]></title><description><![CDATA[Published on November 22, 2023 2:50 AM GMT<br/><br/><p><span>便携式充电器很棒但被低估了。只需</span><a href="https://www.amazon.com/Portable-Charger-26800mAh-Capacity-External/dp/B08729Z2JX">20 美元，</a>您就可以获得一个小盒子，可为手机充电约 5 次，或为笔记本电脑充电约 1 次。 [1] 您可以多花一点钱购买带有<a href="https://www.amazon.com/VRURC-Portable-20000mAh-Charging-Replacement/dp/B0CDZNB954/">内置壁式充电和电缆的</a>产品。在我的背包里放一个这样的东西真是太棒了，我知道我<a href="https://www.jefftk.com/p/rationing-spells-and-battery">不必配给或担心</a>，尤其是在旅行时。如果孩子的平板电脑电量不足、朋友需要充电，或者没有一个好的地方可以让我的手机过夜，这都不是问题。</p><p>一般来说，27,000 mAh 是一个不错的上限：超过这个尺寸，您的航空公司可能会受到限制（尽管<a href="https://www.faa.gov/hazmat/packsafe/lithium-batteries">FAA</a>允许航空公司允许高达 44,000 mAh）。一旦你变得这么大，为了灵活性和冗余的好处而购买两个可能更有意义。</p><p>我第一次得到一个是在 2017 年，它仍然运行良好（尽管 USB-C 端口有点松动）：</p><p> <a href="https://www.jefftk.com/portable-charger-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/EXzh7sg2XE9yrzJPW/kvmotqrjkzxekbs4vdmf" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/EXzh7sg2XE9yrzJPW/kvmotqrjkzxekbs4vdmf 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/EXzh7sg2XE9yrzJPW/naxbqgpho8tn45n1f9ku 1100w"></a></p><div></div><p></p><p>从那以后，我又买了几个，这样孩子们就可以在长途旅行时为他们的平板电脑准备单独的平板电脑。</p><p><br> [1] 这里的数学很糟糕：容量应该以瓦时为单位来测量，但每个人都以相对于某些隐含电压的毫安时为单位给出。对于 USB 移动电源来说，电压（总是？）为 3.6V，因此 26,800 mAh 为 96 Wh。我的手机容量为<a href="https://store.google.com/us/product/pixel_7a_specs">4,385 mAh</a> ，电压为 3.85V，即 17 Wh。我的笔记本电脑的<a href="https://support.apple.com/kb/SP858">瓦时规格</a>非常有用：99.6 瓦时。请注意，您确实会因转换损失而损失一些容量，因此请稍微折扣一下。</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid02TPqYLHSR1vaKdiucf83amFqXosWbNe9du1Npn6AqDg9NpZp9pswii4AohKq2nR6gl">facebook</a> , <a href="https://mastodon.mit.edu/@jefftk/111451918105265115">mastodon</a></i></p><br/><br/><a href="https://www.lesswrong.com/posts/EXzh7sg2XE9yrzJPW/portable-chargers-are-great#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/EXzh7sg2XE9yrzJPW/portable-chargers-are-great<guid ispermalink="false"> EXzh7sg2XE9yrzJPW</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Wed, 22 Nov 2023 02:50:13 GMT</pubDate> </item><item><title><![CDATA[Atlantis: Berkeley event venue available for rent]]></title><description><![CDATA[Published on November 22, 2023 1:47 AM GMT<br/><br/><p>理性社区内外的许多活动都在伯克利举办，可能需要活动空间。这是一个公告，<strong>伯克利有一个名为亚特兰蒂斯的场地</strong>，非常适合举办此类活动。它以前是联谊会的房子，所以适合很多人，并且被适当地划分为举办静修会和研讨会（在伯克利，这是令人惊讶的难以划分的区域）。<strong>您可以</strong><a href="https://forms.gle/wDfPnPjPfqvQZaTFA"><strong><u>在这里预订</u></strong></a><strong>。</strong>该场地不限于以任何方式举办理性活动（这些活动也不会获得折扣），但它非常适合理性主义者似乎举办的活动类型，<strong>有舒适的讨论空间、周围有白板和非常愉快和富有成效的环境。</strong></p><h2><strong>场馆概况</strong></h2><ul><li>38 间卧室，最多可容纳 80 人</li><li>20,500 平方英尺英尺</li><li>~4 个大型室内公共区域和 ~2 个小型室内公共空间</li><li>2 个大型室外公共区域，2 个小型室外公共区域</li><li>商用厨房</li><li>3 间独立的全套浴室、4 间半浴室和 4 间共用浴室（每间有 3 个隔间和 3 个淋浴间）</li><li>健身房</li><li>配备并备有活动用品</li><li>请联系我们获取平面图、房间详细信息等。</li></ul><p> <i><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/wlcdqbsyivchy8bgqdix"></i> </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/o90lhpipwlgis1zeyevy"></p><h2>价钱</h2><p>定价是可以协商的，并且基于什么策略可以为场地带来最大的收入（不是基于我们对您的活动的喜欢程度，尽管我们真的很喜欢在这个空间举办的很多活动！）</p><p>默认定价：</p><ul><li>基本费用：</li><li><u>完整场地使用（过夜住宿）</u><ul><li>充分使用场地（包括所有卧室）的基本费用为 7,000 美元。这是为了支付员工成本并鼓励更长的租赁期。</li><li>每天 5,500 美元。如果我们假设场地的利用率约为 50%，那么我们需要收取多少费用才能收回年租金、改进的摊销成本以及维护成本。</li></ul></li><li><u>场地使用（不含住宿）</u><ul><li><u>仅限一楼</u><ul><li>10 - 30 人：$250/小时</li><li>30 - 60 人：$350/小时</li><li>60 - 100 人：500 美元/小时</li><li>最大限度。每天 5,500 美元</li></ul></li><li><u>一楼和二楼</u><ul><li>$550/小时；最大限度。每天 5,500 美元</li></ul></li></ul></li></ul><p>除了基本费用外，还需支付额外的清洁费用、使用我们的现场消耗品（例如个人洗漱用品、活动挂图等）、损坏场地或占用员工大量时间的费用。我们将向您收取最终费用（因此，如果您将宫殿弄得非常凌乱，我们将收取比您不这样做时更高的清洁费）。在为您的活动进行购买或让工作人员花费时间之前，我们会询问您，我们将在您的活动中向您收取费用。</p><h2>常问问题</h2><p><strong>定价是不是有点贵了？</strong></p><p>这个空间的定价旨在实现收支平衡，而海湾的价格昂贵。这需要较高的价格。我们意识到这个定价对于许多类型的活动来说没有意义。请告知我们费用是否过高，我们将看看是否可以达成协议。</p><p><strong>与该地区的其他场馆相比如何？</strong></p><p><a href="https://www.ventureretreat.org/"><u>创业静修中心</u></a></p><ul><li>~$13.6k/天（尽管我听过他们对不同事件的不同报价）</li><li>距伯克利 1 小时 44 分钟车程</li><li>最大容量：~42 人</li></ul><p><a href="https://www.triplesranchnapa.com/"><u>三重S牧场</u></a></p><ul><li>前 13 人每人 850 美元，入住卧室的客人每晚每人 450 美元。因此，标准 34 人活动每晚 20,500 美元。</li><li>距伯克利 1 小时 23 分钟车程</li><li>最大容量~60人</li></ul><p><strong>它在哪里？</strong></p><p>在伯克利，步行约 10 分钟即可到达加州大学伯克利分校校园，步行 10 分钟即可到达伯克利山徒步旅行。步行 20 分钟即可到达 BART 车站/市中心。出于安全原因，我们不会公开分享确切的地址。</p><p><strong>什么时候可以使用？</strong></p><p>请填写查询表以了解可用性！</p><p><br>如果您有任何疑问，请随时通过<a href="mailto:info@atlantisvenue.com"><strong><u>info@atlantisvenue.com</u></strong></a><strong>与我们联系</strong><strong>！</strong><br></p><h2>附加照片</h2><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/d2jzxtqcia32idrxroob"></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/jmeltyzj7vmxxi00pgdt"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/gd2youlaftpvbk8gfhig"></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/t01ruiqxwih5ve8po7o8"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/nq7voiyiqylwkhjkgr7z"></p><p> <i><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/pifwhtxhj2btnqdrmi0n"></i></p><p> <i><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/v6di4zmk0cbk9ewhzvqc"></i></p><p> <i><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/g0ahrp7aaaoqrkbgchln"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/emphtzwk2ncvqafyydsm"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/xekc6cwxbkfoifhduwn1"></i></p><p><br></p><br/><br/> <a href="https://www.lesswrong.com/posts/pvz53LTgFEPtnaWbP/atlantis-berkeley-event-venue-available-for-rent#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/pvz53LTgFEPtnaWbP/atlantis-berkeley-event-venue-available-for-rent<guid ispermalink="false"> pvz53LTgFEPtnaWbP</guid><dc:creator><![CDATA[Jonas Vollmer]]></dc:creator><pubDate> Wed, 22 Nov 2023 01:47:12 GMT</pubDate> </item><item><title><![CDATA[How much should e-signatures have to cost a country?]]></title><description><![CDATA[Published on November 21, 2023 10:45 PM GMT<br/><br/><h1> 190 亿美元用于瑞士政府的电子签名？</h1><p><i>我的直觉是，LW 是一个提出这个问题的好地方 - 如果它与主题无关，我热衷于将其删除。</i></p><p>读起来我很困惑</p><blockquote><p>瑞士联邦斥资高达 170 亿瑞士法郎购买了一大堆电子签名。</p></blockquote><p>这是7年期间，总共有大约1.2亿个各种类型的签名和印章（如果我没理解错的话）：</p><blockquote><p>其基础是计算出的数字签名数量。在整个招标过程中，历时7年，共计算了约3000个需求点的4300万个合格签名、4300万个高级签名和3200万个电子印章。</p></blockquote><p> <a href="https://www.inside-it.ch/ohne-kulturwandel-in-der-verwaltung-nuetzen-e-signaturen-nichts-20231109">我有这篇文章</a>（德语）（ <a href="https://docs.google.com/document/d/13ObZwBJHoqUUB8UgCTiA1Xvb8TFiCVmYJkQAwLPNRPI/edit?usp=sharing">EN 翻译</a>）， <a href="https://www.inside-it.ch/ohne-kulturwandel-in-der-verwaltung-nuetzen-e-signaturen-nichts-20231109"> </a>讨论了一些细节，包括。印章与签名的区别。但我并不完全理解它。特别是，我看不到任何东西可以让我真正理解为什么瑞士政府为这项服务花费近 170 亿瑞士法郎（190 亿美元）是合理的。</p><p>有谁知道成本的数量级是否真的可能是一个看似合理的上限，而不仅仅是一个定价过高的服务？如果是的话，你能捐两分钱吗？ （双关语无意，但既然它在这里，问题可能会被重新表述：为什么每个签名不必只有 2 美分左右，而是很多法郎？）</p><p>我想主要是无关紧要的背景：瑞士约有 900 万公民。</p><br/><br/> <a href="https://www.lesswrong.com/posts/3dWm9D7jBe56YmmwX/how-much-should-e-signatures-have-to-cost-a-country#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/3dWm9D7jBe56YmmwX/how-much-should-e-signatures-have-to-cost-a-country<guid ispermalink="false"> 3dWm9D7jBe56YmmwX</guid><dc:creator><![CDATA[FlorianH]]></dc:creator><pubDate> Tue, 21 Nov 2023 22:45:50 GMT</pubDate> </item><item><title><![CDATA[My first conversation with Annie Altman]]></title><description><![CDATA[Published on November 21, 2023 9:58 PM GMT<br/><br/><p> 《全人类都是人类》播客上的第一次对话<br><br>我们讨论了个人和社会层面的安全。<br><br>未来可能会讨论导致大规模灭绝的长期驱动因素。<br><br> （11 月 13 日星期一录制，由于某种原因我的声音在 1 点 09 点中断）。<br></p><br/><br/> <a href="https://www.lesswrong.com/posts/kiMGzJWtcPHRrQ9WA/my-first-conversation-with-annie-altman#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/kiMGzJWtcPHRrQ9WA/my-first-conversation-with-annie-altman<guid ispermalink="false"> KIMGzJWtcPHRrQ9WA</guid><dc:creator><![CDATA[Remmelt]]></dc:creator><pubDate> Tue, 21 Nov 2023 21:58:45 GMT</pubDate> </item><item><title><![CDATA[Userscript to always show LW comments in context vs at the top]]></title><description><![CDATA[Published on November 21, 2023 5:53 PM GMT<br/><br/><p>当我导航到评论时，脱离上下文的顶级评论总是让我烦恼，但直到最近我还没有意识到有一种方法可以通过简单的 URL 更改来转到实际评论。<br><br>来自<code>https://www.lesswrong.com/posts/&lt;postid>;/?commentId=&lt;commentid>;</code><br>至<code>https://www.lesswrong.com/posts/&lt;postid>;#&lt;commentid>;</code><br><br>这是一个快速生成的 gpt4 用户脚本，可以执行此操作。</p><pre> <code>// ==UserScript== // @name Always show in-context comments // @namespace http://tampermonkey.net/ // @version 0.1 // @description Redirect from &#39;?commentId=&#39; format to &#39;#&#39; // @author Vlad Sitalo // @match https://www.lesswrong.com/* // @grant none // ==/UserScript== (function() { &#39;use strict&#39;; var checkAndRedirect = function() { var url = window.location.href; if(url.includes(&quot;?commentId=&quot;)){ var newUrl = url.split(&quot;?commentId=&quot;).join(&quot;#&quot;); window.location.href = newUrl; } }; // Run on page load checkAndRedirect(); // Run on URL change var pushState = history.pushState; history.pushState = function() { pushState.apply(history, arguments); checkAndRedirect(); }; var replaceState = history.replaceState; history.replaceState = function() { replaceState.apply(history, arguments); checkAndRedirect(); }; window.addEventListener(&#39;popstate&#39;, checkAndRedirect); })();</code></pre><br/><br/> <a href="https://www.lesswrong.com/posts/j9YvcPaf4BKbJ6fvD/userscript-to-always-show-lw-comments-in-context-vs-at-the#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/j9YvcPaf4BKbJ6fvD/userscript-to-always-show-lw-comments-in-context-vs-at-the<guid ispermalink="false"> j9YvcPaf4BKbJ6fvD</guid><dc:creator><![CDATA[Vlad Sitalo]]></dc:creator><pubDate> Tue, 21 Nov 2023 17:53:31 GMT</pubDate> </item><item><title><![CDATA[Dialogue on the Claim: "OpenAI's Firing of Sam Altman (And Shortly-Subsequent Events) On Net Reduced Existential Risk From AGI"]]></title><description><![CDATA[Published on November 21, 2023 5:39 PM GMT<br/><br/><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 03:24:22 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 03:24:22 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>我看到/听到 LW-o-sphere 中的一群人说上周末的 OpenAI 公司闹剧显然很糟糕。我不太确定为什么人们会这么想？对我来说，总体而言，这似乎是一个非常明显的积极结果。</p><p>我很好奇为什么世界上的人们对此不满意（LW 领域的人们，也就是说，显然我可以理解为什么例如人工智能加速主义者会对此不满意）。我还想展示我的模型。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 03:33:26 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 03:33:26 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>这是我的高光版本。主要成果是：</p><ul><li>相对最关注 AGI 竞争、最不关注安全的领导层正在从 OpenAI 转向微软。许多对通用人工智能竞赛比对安全更感兴趣的员工可能会效仿。</li><li>微软是那种充满活力的组织/创始人/研究人员走向消亡的官僚企业。我的平均预期是，无论前 OpenAI 团队最终的结果如何，其生产力都将远远低于他们在 OpenAI 时的生产力。</li><li> OpenAI 是否会继续存在还是一个悬而未决的问题。<ul><li>就他们所做的而言，他们不太可能推动最先进的能力，而更有可能专注于安全研究。</li><li>就他们关闭而言，主要的最终结果将是一群对 AGI 竞争更感兴趣、不太关注安全的人转向微软，这很好。 </li></ul></li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 03:37:46 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 03:37:46 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>我目前（可能是错误的）对为什么 LW 领域的其他人说这很糟糕的最佳猜测：</p><ul><li>结果推特上显然出现了很多对 EA 的仇恨。我个人认为，从长远来看，这一点即使有影响也微乎其微，但我预计它对于理性主义者/EA/结盟人士来说极其重要。</li><li> OpenAI 是一个拥有很多 AGI 加速主义者的组织，也许人们认为 OpenAI 正在将这些加速主义者的冲动引向更安全友好的方向，而微软不会？</li><li>显然，董事会的执行情况相对较差。他们应该分享解雇的原因/借口。 （出于某种原因，在政治/企业政治中，人们总是试图保持秘密，在我看来，在 80% 以上的情况下，这似乎是非常愚蠢的，包括这个。）我不认为这个错误从长远来看，这实际上非常重要，但我可以理解为什么人们关注它最终会对董事会的行为产生某种普遍的负面影响。 </li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 03:40:18 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 03:40:18 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>（快速警告，我认为一旦有更多信息出现，这个问题就会更容易判断。也就是说，我认为即使现在思考它对于思考和分享相关的观察和考虑也是有用的。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 03:44:46 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 03:44:46 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>我认为 Sam 和其他最终加入微软的人的遭遇是一个相当大的症结。如果我认为那些去微软的人确实会陷入官僚主义，无法取得那么多的成就，而那些留下来的人也不会追求那么多，这可能会让整个事情对 x 风险有利。</p><p>我对此并不是非常有信心，但我的印象是，萨玛可能有足够的能力来打破官僚机构并完成很多工作，而且更重要的是，通过有能力并获得人工智能，最终可以管理微软的大部分业务。与整个 OpenAI 投资周期相比，在那里他可以用更少的精力获得更多的资源，并且比在 OpenAI 时受到的限制更少。<br><br>一个问题是他如何能够独立运作。纳德拉提到 LinkedIn 和 Github（？）在微软内部相当独立运营。此外，我认为微软会觉得他们必须对萨马“友善”，因为他很可能是他们在人工智能领域占据主导地位的关键。他显然拥有一批追随者，并且可以去其他地方，我怀疑他是否设置了拖慢他速度的官僚主义。</p><p><br>到目前为止，一个悬而未决的问题是董事会是否诚信（/合作）行事。如果董事会被认为代表了最受人工智能关注的集群（我们是其中的一部分）并且他们的行为非常糟糕，那么这本身对于我们（集群）合作或移动事物的能力来说可能真的很糟糕更广阔的世界朝着好的方向发展。就像，可能比与 SBF 的任何关联都要糟糕得多。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 03:51:39 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 03:51:39 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>到目前为止，一个悬而未决的问题是董事会是否诚信（/合作）行事。如果董事会被认为代表了最受人工智能关注的集群（我们是其中的一部分）并且他们的行为非常糟糕，那么这本身对于我们（集群）合作或移动事物的能力来说可能真的很糟糕更广阔的世界朝着好的方向发展。就像，可能比与 SBF 的任何关联都要糟糕得多。</p></blockquote><p>我记得在 Sam-Bankman-Fried-pocalypse 事件发生后不久，很多老鼠/EA/等等都非常关注这将如何玷污 EA 等的声誉。一年后，我认为……事实并非如此坏的？就像，我们总体上仍然是一个相对较高诚信的群体，从长远来看，公关会平衡以反映潜在的现实。是的，有一些坏苹果，公关也平衡地反映了现实，这很好，就我担心公关而言（这并不多），我主要只是希望它是准确的。</p><p>我认为，对于 EA/联盟研究人员等来说，这对于其他人来说似乎更加重要，与它实际的重要性远远不成比例，我们需要对此进行调整。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 03:53:23 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 03:53:23 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>（旁注：我还想在这里说“诚信比公关更重要”之类的话，而上周末发生的事件看起来更像是公关问题，而不是诚信问题。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 03:58:28 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 03:58:28 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><blockquote><p>一年后，我想……还没有那么糟糕吗？</p></blockquote><p>不同意，或者至少，我认为我们还不知道。<br><br>我同意我们不会继续在网上听到仇恨，该团体仍在继续并吸收了新成员，生活似乎还在继续。而且，在这个周末事件没有发生的世界中（我认为它们可能会使发生的事情相形见绌，或者可能使它们复杂化），我认为 SBF 协会很可能会影响关键事件和在世界上运作的能力。<br><br>有一些所谓的“站在权力杠杆一边”的策略，我不知道它们是否好，但是诸如在公司和政府内部担任职位之类的事情可以让你推动更好的人工智能成果，我确实认为 SBF可能会让事情变得更加困难。<br><br>如果 Jason Matheny 一直在 SBF 之后寻找职位（Whitehouse、RAND 等），我认为成为一名知名 EA 可能是一种真正的负担。一年后这并没有明显可见，但我敢打赌我们还没有完全失去这种联系。我认为本周末的活动也可以说是出于 EA 典型动机。这使得我们的集群更难被信任成为合作/诚信/有能力的合作伙伴。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 03:59:53 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 03:59:53 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>我对此并不是非常有信心，但我的印象是萨玛可能有足够的能力消除官僚机构并完成很多工作，而且更重要的是，通过有能力并获得人工智能，最终运行了微软的大部分业务。与整个 OpenAI 投资周期相比，在那里他可以用更少的精力获得更多的资源，并且比在 OpenAI 时受到的限制更少。<br><br>一个问题是他如何能够独立运作。纳德拉提到 LinkedIn 和 Github（？）在微软内部相当独立运营。此外，我认为微软会觉得他们必须对萨马“友善”，因为他很可能是他们在人工智能领域占据主导地位的关键。他显然拥有一批追随者，并且可以去其他地方，我怀疑他是否设置了拖慢他速度的官僚主义。</p></blockquote><p>据我所知，萨玛以前从来没有在大官僚公司呆过多久？他曾在一家风险投资公司和初创公司工作。</p><p>最重要的是，从远处看，我的不太了解的印象是，他更像是一个微笑和碰肘的人，而不是一个真正的技术经理；我认为他在 OpenAI 的日常工作并不多？不过，我对这方面信心不足，因为我没有从熟悉的消息来源那里听到这一点。</p><p>不过，这个等式的另一边的不确定性较小。纳德拉提到<i>Linkedin</i>是微软的成功，我觉得很搞笑。该产品在被收购之前就达到了顶峰。微软从中投入了大量资金，但他们肯定没有改进它。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 04:01:35 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 04:01:35 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>我同意 LinkedIn 正在走下坡路，所以确实比我更支持你的立场。尽管如此，似乎还是有收购独立运作的先例。 Instagram，我想。皮克斯。当然还有其他保持很多自由的地方。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:02:51 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:02:51 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>一年后这并没有明显可见，但我敢打赌我们还没有完全失去这种联系。我认为本周末的活动也可以说是出于 EA 典型动机。这使得我们的集群更难被信任成为合作/诚信/有能力的合作伙伴。</p></blockquote><p>需要明确的是，我基本上同意这是一种机制。我完全认为董事会犯了一些非受迫性的公关错误，并因此烧毁了一些 EA 公共资源。我只是认为它远没有其他影响那么重要，并且 EA 对此给予了过多的关注。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 04:03:03 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 04:03:03 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>这似乎是症结所在：董事会是否仅仅犯了公关错误而不是其他错误？<br><br>我可以深入探讨我的观点，但也很高兴首先了解您对错误的解释。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:05:45 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:05:45 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>尽管如此，似乎还是有收购独立运作的先例。 Instagram，我想。皮克斯。当然还有其他保持很多自由的地方。</p></blockquote><p>但微软的收购却没有那么多。 （另外，Instagram 是相当有争议的，但我肯定会给你皮克斯。）就像，想要加速 AGI 的人最终会在某个地方结束，如果我必须选择一个地方，微软肯定会进入候选名单。现在想到的唯一可能更好的选择是国防承包商：同样或更糟的公司臃肿，但他们的所有工作都将是官方秘密。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 04:06:10 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 04:06:10 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>我想对于大多数人来说我都会同意这一点。也许我太相信个人魅力，但山姆确实给了我一种实际能力的感觉，这让它更可怕。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:07:38 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:07:38 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>这似乎是症结所在：董事会是否仅仅犯了公关错误而不是其他错误？</p></blockquote><p>我会指出，这对我来说不是症结所在，我真的不知道为什么这对你来说是症结？就像，这真的是<i>主导效应</i>吗，以至于它会改变 AGI 对 X 风险的净效应的符号？它最终变得如此重要的机制是什么？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 04:18:14 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 04:18:14 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>我本来打算写一些关于诚信的东西，这是有东西的，但现在最让我震惊的是，整个努力似乎非常无能和天真。这很令人不安。我担心我的集群已经被揭露（我的意思是，如果这是真的，那么它的出现是有好处的）不是很精明，你不应该和我们打交道，因为我们显然不知道我们在做什么。正在做。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:21:27 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:21:27 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>我担心我的集群已经被揭露（我的意思是，如果这是真的，那么它的出现是有好处的）不是很精明，你不应该和我们打交道，因为我们显然不知道我们在做什么。正在做。</p></blockquote><p>首先，这<i>听起来确实</i>像是人类大脑向我们呈现的比实际情况更大、更重要的事实。群体内地位下降？没有什么比这更容易产生扭曲的认知了。</p><p>但无论如何，我重复我的问题：它最终变得如此重要的机制是什么？比如，告诉我一个过于具体的故事，其中有一些虚构的细节。 （我的期望是，实际讲述故事的过程会清楚地表明，这可能并不重要，但感觉上很重要。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:24:14 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:24:14 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>这似乎是症结所在：董事会是否仅仅犯了公关错误而不是其他错误？<br><br>我可以深入探讨我的观点，但也很高兴首先了解您对错误的解释。</p></blockquote><p> （现在意识到我实际上还没有回答这个问题。）我认为董事会应该公开分享他们解雇萨玛的原因。基本上就是这样；在我看来，这是唯一一个明显的非受迫性错误。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 04:30:10 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 04:30:10 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>假设 johnswentworth 和一组相关的研究人员发现了一些真正关键的有用的东西，这些东西对对齐产生了影响。它对于如何训练模型和评估模型（在评估意义上）以及相关的有用策略具有很大的影响。自然抽象中的某些东西不会立即用于构建更有利可图的人工智能，但确实会塑造你的议程和方法应该是什么样子。<br><br>通过社交图谱，人们可以联系前 OpenAI 员工，以说服其结果的重要性。 Jan Leike 对此深信不疑，但又很恼火，因为他感到被烧伤；Ilya 也表示同情，但在向一大群人推广 LW/EA 集群研究想法时感到受到限制，这些人对试图解雇 Sam Altman 的厄运者抱有敌对和怀疑的感觉。没有解释原因。<br><br>人们前往华盛顿和/或英国特别工作组（如果重要的话我可以选择名字），有些人表示同情，另一些人则担心这种联系。 CSET 负责人海伦·托纳 (Helen Toner) 似乎卷入了这场惨败，这也于事无补。并不是说没有人会与我们交谈，也没有人会接受这项研究的优点，而是大多数人不会根据其优点来判断这项研究，并且没有可信度来采用它或其含义。与“厄运星团”的相互作用会产生很多摩擦。从“政治判断力差”到“一般判断力（包括人工智能的风险）”的判断已经逐渐渗透。<br><br>如果你希望人们做的事情是昂贵的，例如你更安全的人工智能更昂贵，但你被视为不值得信任，低诚信，低透明度，低政治能力，那么我认为你将很难得到购买它。<br><br>如果有帮助的话我可以更具体。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:32:33 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:32:33 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>好吧，把所有这些都写出来……从数量上来说，你认为上周末发生的事件在多大程度上增加了某种模糊类似但更普遍的事情发生的可能性，这使得厄运与厄运之间存在差异而不是厄运？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 04:46:26 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 04:46:26 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>这是个好问题。我认为我没有保持足够的校准/细粒度估计来以非废话的方式回答，所以我现在想拒绝回答这个问题。<br><br>我的 P(Doom) 感觉像是在 1 倍以上但低于 2 倍之间，但需要一些工作才能区分出“我了解了世界的情况”和“董事会的行动让事情变得更糟”。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:46:39 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:46:39 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>我认为我没有保持足够的校准/细粒度估计来以非废话的方式回答，所以我现在想拒绝回答这个问题。</p></blockquote><p>是的，完全公平，这对我来说是一个相当大的要求。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:48:36 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:48:36 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>回到我自己的模型：在我看来，（在我的中值世界中）以前可以说引领能力竞赛的人工智能实验室现在实际上已经退出了能力竞赛。时间线变得更长，比赛动力变得更弱。我很难想象董事会的非受迫性错误所带来的公关反弹如何可能严重到足以超过就人工智能 X 风险的影响而言的巨大好处。</p><p>就像，就 X 风险而言，这是公司治理中可能实际发生的最好的事情之一。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 04:55:33 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 04:55:33 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>我并不排除上述可能性，但对我来说似乎非常不明显，我至少会弱地打赌反对。<br><br>如上所述，AGI 进步多少的关键在于微软。我认为 OpenAI 的竞争相当激烈，但仍然包含克制的声音和代表至少一些人（Jan、Ilya？）的认真努力，以使 AGI 顺利进行。我认为微软比 OpenAI 更不谨慎，更注重利润，而更受关注/好的人工智能风险模型影响事情变得更好的能力更弱。<br><br>微软的模式是缓慢的官僚主义，但它也是一家拥有大量现金的 3 万亿美元公司，并且正确地判断人工智能是未来主导地位的最重要因素。如果他们决定开始制造自己的芯片或其他什么，很容易做到。如果微软拥有自己的部门，谷歌自然会感受到来自他们的更大威胁。最终，微软和谷歌都拥有庞大的技术精湛的人工智能研究团队，每个团队都拥有数十亿美元的资金来支持一场竞赛。<br><br>真的，对我来说，认为这会减少比赛动态似乎很疯狂。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:59:18 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:59:18 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>我的意思是，我并不真正关心 Facebook AI 认为他们现在正在比赛的程度。他们此时不在游戏中。这就是我对微软一年后的预期（中值世界）。当然，蜗牛会认为它们在比赛，但如果它们不是领先者，那又有什么关系呢？</p><p> （如果其他两个目前领先的实验室的速度放慢到足以让 Facebook/微软参与竞争，那么显然 Facebook/微软将变得相关，但相对于当前的地位来说，这将是一个很大的问题。）</p><p>谷歌感觉受到了威胁……maaayyyybe，但这感觉需要一个相当联合的事件路径才能真正加速事情的发展。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 05:03:48 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 05:03:48 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>...无论如何，我们已经进行了几个小时了，我认为我们已经确定了主要的症结所在，并且正在遇到收益递减的问题。想要总结一下想法吗？ （或者不，如果你愿意，我们可以继续推动线程。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 05:05:17 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 05:05:17 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>听起来不错，是的，我想我们已经找到了一些症结所在。看来微软的生产力很重要，而且在多大程度上仍然是领先者。我认为他们确实如此。我认为他们保留了大部分人才，OpenAI 可以以更多的资源和更少的限制继续发展。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 05:05:27 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 05:05:27 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>我认为这部分很好地总结了我的主要观点：</p><blockquote><p> （在我的中值世界中）以前可以说在能力竞赛中处于领先地位的人工智能实验室现在实际上已经退出了能力竞赛。时间线变得更长，比赛动力变得更弱。我很难想象董事会的非受迫性错误所带来的公关反弹如何可能严重到足以超过就人工智能 X 风险的影响而言的巨大好处。 </p></blockquote></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 05:06:09 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 05:06:09 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>我想我们都同意“微软前 OpenAI 人员的工作效率如何？”是一个大症结吗？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 05:06:36 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 05:06:36 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>另一种和平，如果我认为这可能是那些表达人工智能末日/风险的人的可信度和信任被烧毁，并且很难被取代，其方式降低了我们推动事情变得更好的能力（无论我们是否有判断或是否会成功，否则，我实际上真的不确定）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 05:08:03 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 05:08:03 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><blockquote><p>我想我们都同意“微软前 OpenAI 人员的工作效率如何？”是一个大症结吗？</p></blockquote><p>是的，同意这一点。我预测，我们会继续看到 Microsoft 提供与 OpenAI 到目前为止相同或更高的 GPT 版本和功能等。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 05:09:12 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 05:09:12 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>干杯，我很喜欢这个</p></div></section><p></p><div></div><br/><br/><a href="https://www.lesswrong.com/posts/ahNcJGNtTX8JvMy93/dialogue-on-the-claim-openai-s-firing-of-sam-altman-and#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ahNcJGNtTX8JvMy93/dialogue-on-the-claim-openai-s-firing-of-sam-altman-and<guid ispermalink="false"> ahNcJGNtTX8JvMy93</guid><dc:creator><![CDATA[johnswentworth]]></dc:creator><pubDate> Tue, 21 Nov 2023 17:39:17 GMT</pubDate> </item><item><title><![CDATA[AI Alignment [progress] this Week (11/19/2023)]]></title><description><![CDATA[Published on November 21, 2023 4:09 PM GMT<br/><br/><p>我本来想说本周事情会恢复正常，但遗憾的是没有。</p><p>这是我们的</p><h1>本周人工智能对齐取得突破</h1><p></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a20db22-7c45-4628-a024-849bddada17c_1792x1024.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a20db22-7c45-4628-a024-849bddada17c_1792x1024.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a20db22-7c45-4628-a024-849bddada17c_1792x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a20db22-7c45-4628-a024-849bddada17c_1792x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a20db22-7c45-4628-a024-849bddada17c_1792x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a20db22-7c45-4628-a024-849bddada17c_1792x1024.png 1456w"></a></p><p></p><p>本周，在以下领域取得了突破：</p><p>机械可解释性</p><p>标杆管理</p><p>红队</p><p>真实的人工智能</p><p>人工智能代理</p><p>学习人类偏好</p><p>减少人工智能偏见</p><p>去中心化人工智能</p><p>人体增强</p><p>拯救人类生命</p><p>让人工智能做我们想做的事</p><p>和</p><p>人工智能艺术</p><h1>机械可解释性</h1><p></p><p><a href="https://twitter.com/scychan_brains/status/1724625347160027605">情境学习瞬态</a></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1c59a2e-926b-4631-9d77-6b75f8bd234b_680x350.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1c59a2e-926b-4631-9d77-6b75f8bd234b_680x350.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1c59a2e-926b-4631-9d77-6b75f8bd234b_680x350.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1c59a2e-926b-4631-9d77-6b75f8bd234b_680x350.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1c59a2e-926b-4631-9d77-6b75f8bd234b_680x350.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1c59a2e-926b-4631-9d77-6b75f8bd234b_680x350.jpeg 1456w"></a></p><p></p><p>它是什么：他们发现模型可能会找到然后失去上下文学习</p><p>新动态：防止模型在上下文学习中丢失的正则化方法</p><p>它有什么好处：更好地理解人工智能模型如何学习是确保它们按照我们期望的方式行事的关键</p><p>评价：💡💡💡💡</p><p><a href="https://twitter.com/goodside/status/1723747357278249020">使用大型语言模型进行角色扮演</a></p><p>这是什么：法学硕士在 20 个问题上“作弊”，他们没有真正选择一件事并坚持下去</p><p>新消息：证实了先前对<a href="https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/">LessWrong</a>的猜测</p><p>它有什么好处：了解“法学硕士如何思考”可以让我们更好地控制他们（例如，您可以明确告诉法学硕士在 20 个问题的开头选择一个对象）</p><p>评价：💡</p><h1>标杆管理</h1><p></p><p><a href="https://twitter.com/arankomatsuzaki/status/1724611226540421294">大型语言模型的指令跟踪评估</a></p><p>它是什么：法学硕士遵循指示程度的新基准</p><p>新功能：一组可验证的提示，以便可以自动对输出进行基准测试</p><p>它有什么好处：确保人工智能按照它的指示行事是调整可扩展监督等战略的关键。</p><p>评价：💡💡</p><p> <a href="https://twitter.com/joycjhsu/status/1724180191470297458">Geoclidean：欧几里得几何中的小样本推广</a></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdc78357-6913-4585-aa84-a720eb93f91d_680x370.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdc78357-6913-4585-aa84-a720eb93f91d_680x370.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdc78357-6913-4585-aa84-a720eb93f91d_680x370.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdc78357-6913-4585-aa84-a720eb93f91d_680x370.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdc78357-6913-4585-aa84-a720eb93f91d_680x370.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdc78357-6913-4585-aa84-a720eb93f91d_680x370.jpeg 1456w"></a></p><p></p><p>它是什么：视觉模型如何像人类一样思考的基准</p><p>新变化：现有基准应用于新模型 (GPT-4v)</p><p>它有什么好处：了解人工智能是否（以及如何）像人类一样理解事物。</p><p>评价：💡</p><h1>红队</h1><p></p><p><a href="https://alignmentjam.com/project/jailbreaking-the-overseer">越狱监督者</a></p><p>它是什么：他们发现法学硕士可以“自发地”越狱另一个模型设置来判断他们的输出</p><p>新变化：告诉模型它正在由 LLM 评分显然足以导致它越狱 LLM，而无需明确告诉它如此</p><p>它有什么好处：这似乎是一个标准“强化学习<a href="https://www.youtube.com/watch?v=nKJlF-olKmg">做了我们没有预料到的事情</a>”，但记住这个事实仍然很重要</p><p>评价：💡💡</p><h1>真实的人工智能</h1><p></p><p><a href="https://twitter.com/omarsar0/status/1725181141693472959">注释链</a></p><p>它是什么：一种使用知识库增加人工智能模型事实输出的方法</p><p>新变化：他们让人工智能生成“阅读笔记”，可以用来检查其输出的事实准确性</p><p>它有什么好处：如果我们想知道我们是否可以信任他们，那么让法学硕士引用他们的来源似乎是一件显而易见的事情</p><p>评价：💡💡</p><h1>人工智能代理</h1><p></p><p><a href="https://twitter.com/AiBreakfast/status/1724421660420301221">贾维斯-1</a></p><p>它是什么：训练 AI 玩我的世界</p><p>新变化：他们为贾维斯提供了“多模型记忆”来帮助它制定长期计划</p><p>它有什么好处：人工智能代理对于人工智能官僚制或自动对齐研究等计划至关重要。</p><p>评价：💡💡💡💡</p><h1>学习人类偏好</h1><p></p><p><a href="https://twitter.com/taiwei_shi/status/1724915173109252194">更安全的指导</a></p><p>它是什么：一种生成人类偏好数据集的方法（例如 RLHF）</p><p>新变化：他们有一个“调整模型”，有助于生成积极和消极的首选响应</p><p>它有什么好处：拥有一种根据自己的喜好快速构建数据集的方法对于构建响应个人需求的模型至关重要，而不仅仅是平淡的安全主义</p><p>评价：💡💡💡</p><h1>减少人工智能偏见</h1><p></p><p><a href="https://twitter.com/KeremZaman3/status/1724836881165152521">融合模型</a></p><p>它是什么：通过将多个模型融合在一起来减少人工智能偏差</p><p>新变化：他们表明融合多个模型可以减少单个模型中出现的偏差或虚假相关性。</p><p>它有什么好处：将强模型与无偏模型相结合以获得强无偏模型</p><p>评价：💡💡</p><h1>去中心化人工智能</h1><p></p><p><a href="https://twitter.com/_akhaliq/status/1724637086488076472">迪洛科</a></p><p>它是什么：一种分布式语言模型训练方法</p><p>新功能：他们使用联合平均的变体，允许您在大量不同的设备上进行一些训练，然后组合起来获得更强大的模型</p><p>它有什么好处：训练大型模型是目前构建真正去中心化人工智能的弱点（目前所有强大的开源模型都是通过大型中心化工作来训练的）。</p><p>评价：💡💡💡</p><h1>人体增强</h1><p></p><p><a href="https://twitter.com/synthesischool/status/1724834959427342727">合成</a></p><p>它是什么：用于教授人类的个性化人工智能导师</p><p>新功能：该系统将语言模型与图形相结合，耐心地找出学生不理解的过程部分。</p><p>它有什么好处：如果我们希望人类监督人工智能，那么让人类变得更聪明将是至关重要的。</p><p>评价：💡💡💡</p><p> <a href="https://twitter.com/Muennighoff/status/1724134083905884408">FinGPT：小语言的大型生成模型</a></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd81cbba2-420d-4a43-ba35-2ff26d0cb4a5_679x333.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd81cbba2-420d-4a43-ba35-2ff26d0cb4a5_679x333.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd81cbba2-420d-4a43-ba35-2ff26d0cb4a5_679x333.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd81cbba2-420d-4a43-ba35-2ff26d0cb4a5_679x333.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd81cbba2-420d-4a43-ba35-2ff26d0cb4a5_679x333.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd81cbba2-420d-4a43-ba35-2ff26d0cb4a5_679x333.jpeg 1456w"></a></p><p></p><p>它是什么：针对训练示例较少的语言（在本例中为芬兰语）的新语言模型</p><p>新功能：通过组合来自通用集 (BLOOM) 和特定语言集的数据，他们可以训练模型，使其超出缩放定律对特定语言集的预测范围</p><p>它的好处是什么：为数百种不太可能拥有庞大文本语料库的语言释放法学硕士的好处。</p><p>评价：💡💡💡</p><h1>拯救人类生命</h1><p></p><p><a href="https://twitter.com/GoogleDeepMind/status/1724443443873624115">图播</a></p><p>它是什么：谷歌用于预测天气的人工智能模型</p><p>新动态：他们发现利用深度学习可以改进天气预报（例如，对飓风将袭击的地点提供额外 3 天的警告）</p><p>它有什么好处：预测天气</p><p>评价：💡💡💡💡</p><h1>让人工智能做我们想做的事</h1><p></p><p><a href="https://twitter.com/oshaikh13/status/1725036260346225136">接地或猜测</a></p><p>它是什么：研究人员测试了人工智能是否在对话过程中“检查其假设”，结果发现它与人类一样大多不会。</p><p>新变化：他们引入了一种促进策略来改善基础。</p><p>它有什么好处：拥有一个可以与人类检查其假设的人工智能似乎是构建“做我的意思”人工智能的关键一步</p><p>评价：💡💡</p><p><a href="https://twitter.com/huihan_liu/status/1724455536773509298">奥拉夫</a></p><p>它是什么：通过与机器人交谈来教导它</p><p>新鲜事：他们使用法学硕士根据言语纠正重新标记机器人的行为</p><p>它有什么好处：有一天，当机器人<a href="https://www.bbc.com/news/world-asia-67354709">来找你</a>，你喊“不，停下来！”时，也许它会理解。</p><p>评价：💡💡💡💡</p><h2>人工智能艺术</h2><p></p><p><a href="https://twitter.com/soujanyaporia/status/1725377945215373687">野马</a></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac3e237-a7fb-4e8e-ab3d-c229083f247a_4096x2249.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac3e237-a7fb-4e8e-ab3d-c229083f247a_4096x2249.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac3e237-a7fb-4e8e-ab3d-c229083f247a_4096x2249.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac3e237-a7fb-4e8e-ab3d-c229083f247a_4096x2249.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac3e237-a7fb-4e8e-ab3d-c229083f247a_4096x2249.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac3e237-a7fb-4e8e-ab3d-c229083f247a_4096x2249.jpeg 1456w"></a></p><p></p><p></p><p>它是什么：可控的文本音乐生成</p><p>新功能：更多地控制诸如音乐应使用哪个和弦序列之类的事情</p><p>它有什么好处：制作音乐</p><p>评价：💡💡💡</p><p><a href="https://twitter.com/OmriAvr/status/1725393852859641910">被选中的人</a></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb12356-9178-4c8d-9d0a-97fe4b44a72c_679x367.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb12356-9178-4c8d-9d0a-97fe4b44a72c_679x367.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb12356-9178-4c8d-9d0a-97fe4b44a72c_679x367.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb12356-9178-4c8d-9d0a-97fe4b44a72c_679x367.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb12356-9178-4c8d-9d0a-97fe4b44a72c_679x367.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb12356-9178-4c8d-9d0a-97fe4b44a72c_679x367.jpeg 1456w"></a></p><p></p><p>它是什么：一种在多个图像中生成一致字符的方法</p><p>新变化：它们重复对模型的输出进行聚类，直到它们收敛于固定的表示形式</p><p>它有什么好处：许多人工智能艺术应用（例如讲故事）需要能够生成具有同一角色的多个图像</p><p>评价：💡💡</p><p><a href="https://twitter.com/AIatMeta/status/1725184453960737001">鸸</a></p><p>它是什么：Facebook 的新模型，允许创建和编辑图像和视频</p><p>新内容：实际上是一个非常简单的模型，因此大部分内容都在训练过程中</p><p>它有什么好处：可能是我见过的最好的文本到视频/图像到视频模型</p><p>评价：💡💡</p><h1>人工智能调整举措</h1><p></p><p><a href="https://twitter.com/htaneja/status/1724454074249273477">自愿负责任的人工智能承诺</a></p><p>它是什么：一群风险投资公司签署了一封信，承诺“做出合理的努力”，鼓励他们投资的公司考虑人工智能偏见和人工智能风险等问题</p><p>这意味着什么：你知道我不想让谁比大公司、风险投资公司更能决定人工智能能说什么、不能说什么。不过，我怀疑这一举措可能在本周末之后就成为一纸空文。</p><p><a href="https://twitter.com/hardmaru/status/1725112216872219096">米斯特拉尔搁置欧盟人工智能法案</a></p><p>它是什么：令人震惊的是，欧盟可能无法监管人工智能（由于法国和德国的国家冠军反对监管）。</p><p>含义：米斯特拉尔明确表示，不打算保留在较小的、监管较少的第二类车型中。有些人对此感到<a href="https://twitter.com/tegmark/status/1724455714473542003">困惑</a>。</p><p></p><h1>这不是人工智能对齐</h1><p></p><p><a href="https://twitter.com/robertwiblin/status/1724381111927582999">AI对准指南针图表</a></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1814d50e-6de6-48ac-9c8a-1cab669c39b5_1786x1048.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1814d50e-6de6-48ac-9c8a-1cab669c39b5_1786x1048.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1814d50e-6de6-48ac-9c8a-1cab669c39b5_1786x1048.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1814d50e-6de6-48ac-9c8a-1cab669c39b5_1786x1048.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1814d50e-6de6-48ac-9c8a-1cab669c39b5_1786x1048.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1814d50e-6de6-48ac-9c8a-1cab669c39b5_1786x1048.png 1456w"></a></p><p></p><p>它是什么：Robert Wilbin 有一张图表，显示了不同群体在人工智能能力方面的立场以及对齐的难度（我对其进行了编辑以添加 Midwit Alignment 的立场）</p><p></p><p><a href="https://openai.com/blog/openai-announces-leadership-transition">我们都在谈论的事情</a></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61aa577-45de-4b00-aff0-b27c4a52fb54_680x390.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61aa577-45de-4b00-aff0-b27c4a52fb54_680x390.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61aa577-45de-4b00-aff0-b27c4a52fb54_680x390.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61aa577-45de-4b00-aff0-b27c4a52fb54_680x390.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61aa577-45de-4b00-aff0-b27c4a52fb54_680x390.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61aa577-45de-4b00-aff0-b27c4a52fb54_680x390.jpeg 1456w"></a></p><p></p><p>我对 EA 的建议：停止做那些<a href="https://twitter.com/rao2z/status/1725729175670329670">看起来很糟糕的</a><a href="https://www.forbes.com/sites/britneynguyen/2023/11/03/sam-bankman-fried-faces-110-year-max-sentence-after-ftx-fraud-trial-heres-how-long-experts-think-hell-be-behind-bars/?sh=7de1c78c6050">事情</a>，因为你有一些银河大脑的预期效用计算来说明它实际上是如何好的。事情并不总是按照你<a href="https://twitter.com/hardmaru/status/1726131917765140625">期望的</a><a href="https://twitter.com/sama/status/1726345564059832609">方式</a>发展。</p><br/><br/> <a href="https://www.lesswrong.com/posts/gk6wxd6CPEXCj7PdH/ai-alignment-progress-this-week-11-19-2023#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/gk6wxd6CPEXCj7PdH/ai-alignment-progress-this-week-11-19-2023<guid ispermalink="false"> gk6wxd6CPEXCj7PdH</guid><dc:creator><![CDATA[Logan Zoellner]]></dc:creator><pubDate> Tue, 21 Nov 2023 16:09:48 GMT</pubDate> </item><item><title><![CDATA[Varieties of fake alignment (Section 1.1 of “Scheming AIs”)]]></title><description><![CDATA[Published on November 21, 2023 3:00 PM GMT<br/><br/><p>这是我的报告《<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？》</a>的第 1.1 节。 ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p>本节的音频版本<a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13984697-varieties-of-fake-alignment-section-1-1-of-scheming-ais">在这里</a>。</p><h1>心机及其意义</h1><p>本节旨在理清与阴谋相关的不同类型的人工智能欺骗（第 1.1 节），将阴谋者与我将讨论的其他可能的模型类别（第 1.2 节）区分开来，并解释为什么我认为阴谋是一种独特的行为。可怕的错位形式（第 1.3 节）。它还讨论了有关阴谋的理论论证是否有用（第 1.4 节），并解释了训练中“松弛”的概念——该概念稍后在报告中的各个地方出现（第 1.5 节）。</p><p>其中很大一部分是为报告的其余部分奠定基础 - 但如果您已阅读并理解上面第 1 节（第 0.2.1 节）的摘要，并且渴望对以下可能性进行更多对象级别的讨论阴谋，请随意跳至第 2 部分。</p><h2>各种假对齐</h2><p>人工智能可以出于各种原因产生各种谎言。其中一些并没有被很好地理解为“欺骗性”——例如，因为人工智能不知道相关真相。不过，有时“欺骗”这个词似乎很贴切。例如，考虑一下 Meta 的 CICERO 系统，该系统经过训练可以玩策略游戏《外交》，承诺英国在北海提供支持，但随后告诉德国“移至北海，英国认为我支持他”。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-1" id="fnref-TZno2g4X7Xnjdx3ZZ-1">[1]</a></sup> </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTLvooL44SPEFWGhD/pgysephwxbpgzjh8xpua" alt="来自 Park 等人 (2023)，图 1，经许可转载。"></p><p><em>来自<a href="https://arxiv.org/pdf/2308.14752.pdf">Park 等人 (2023)</a> ，图 1，经许可转载。</em></p><p>我们将从事任何形式欺骗行为的人工智能称为“骗子”。在这里，我对骗子本身不感兴趣。相反，我对那些撒谎或以其他方式歪曲<em>其阵营的人工智能感兴趣。</em>特别是：人工智能假装比实际情况更加一致。我们称这些为“对齐伪造者”。</p><h3>对齐伪造者</h3><p>对齐伪造者很重要，因为我们想知道我们的人工智能是否对齐。所以造假者掩盖了我们关心的事实。事实上，对齐伪造的可能性是确保先进人工智能安全的关键方法之一，这比确保其他技术安全更难。飞机不会试图欺骗您何时坠毁。 （他们也不比你聪明。）</p><p>为什么你会期望对齐伪造？基本的故事可能很熟悉：工具融合。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-2" id="fnref-TZno2g4X7Xnjdx3ZZ-2">[2]</a></sup>也就是说：就像生存、获取资源和提高你的能力一样，欺骗别人你的动机可以帮助你实现你的目标——特别是如果你的动机不是这些“其他人”所希望的那样。</p><p>特别是：目标有问题的人工智能通常会有寻求权力的工具性激励。但人类经常控制权力杠杆，并且不想将这种权力赋予不协调的人工智能。例如，人工智能实验室可能不希望错误的人工智能与客户交互、编写安全关键代码片段或影响某些关键决策。事实上，通常情况下，如果人类发现人工智能出现偏差，他们会采取一些关闭和修改的组合，这两者都会阻止人工智能实现其目标。因此，一个<em>不</em>希望被关闭/修改的错位人工智能通常不希望人类检测到它的错位。</p><p>这是一个核心动态，导致了 Bostrom（2014）所说的“危险转向”的可能性——也就是说，人工智能在弱时表现良好，但在强时表现得很危险。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-3" id="fnref-TZno2g4X7Xnjdx3ZZ-3">[3]</a></sup>在这种背叛的变体中——我们可以称之为“战略背叛”变体——之所以会发生背叛，是因为人工智能明确地假装结盟，直到它们获得足够的力量，不再需要假装。他们开始做出人类无法阻止的有害行为。策划者是这个更广泛的人工智能类别的一个子类——我们可以称之为“战略背叛者”——特别是在基于机器学习的培训制度的背景下运作。</p><h3>训练游戏玩家</h3><p>对齐伪造可能发生在各种情况下。例如，如果一个错位的人工智能试图说服实验室员工允许其访问某些文件，或者用户代表其做一些事情，它可能会向人类保证其意图是良性的。危险的转变和战略背叛也可能发生在各种情况下。</p><p>不过，在这里，我对在 Cotra（2022）之后发生的结盟伪造（和战略背叛）特别感兴趣，我将其称为“训练游戏”。<strong>当人工智能 (a) 理解用于训练它的过程（再次遵循 Cotra，我将这种理解称为“ <a href="https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to">态势感知</a>”）并且 (b) 明确地将其优化瞄准我的某些组成部分时，训练游戏就会发生。我们将这一集称为“奖励过程”。</strong> <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-4" id="fnref-TZno2g4X7Xnjdx3ZZ-4">[4]</a></sup>让我进一步说明我的意思。</p><p>首先：我假设人工智能正在通过机器学习对某种反馈信号进行训练，SGD 在此基础上更新模型的权重。特别是：我通常会假设人工智能至少在相关阶段正在使用某种强化学习进行训练（ <a href="https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to#_HFDT_scales_far__assumption__Alex_is_trained_to_achieve_excellent_performance_on_a_wide_range_of_difficult_tasks">例如</a>，通过类似于 Cotra (2022) 描述的设置） – 自监督预训练、模仿学习和 RL 微调的混合），因此相关反馈信号是“奖励”，但讨论也主要适用于其他训练过程/信号 – 例如，通过自我监督学习训练模型，以最大限度地减少下一个标记的预测误差。</p><p>更重要的是，我假设我们有一些“情节”的概念，我将其粗略地定义为时间单位，这样，如果一个模型（在给定时间）忽略了所有在此时间之后其行为的后果，训练过程不会主动对其进行惩罚。也就是说，粗略地说，“情节”是梯度下降主动迫使模型进行优化的事情。我将在下面的 2.2.1 节中更深入地讨论这个问题。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-5" id="fnref-TZno2g4X7Xnjdx3ZZ-5">[5]</a></sup></p><p>为模型在某一集中的行为分配奖励的过程有很多部分。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-6" id="fnref-TZno2g4X7Xnjdx3ZZ-6">[6]</a></sup>有关此行为的信息（我将其称为“传感器数据”）被收集并输入到某个评估过程，该输入被评估并分配奖励（可能由人类，可能由某种训练有素的奖励模型）人类的判断，可能通过其他一些自动过程），这个奖励存储在内存中的某个地方，并用于更新模型的权重等。但是，所有这些部分在训练过程中可能都非常紧密相关，从某种意义上说“根据一个部分的“做得很好”（例如，传感器数据使咖啡机器人看起来煮咖啡做得很好）可能与根据其他部分的“做得很好”紧密相关（例如，该事件被分配了一个高分）报酬）。因此，我通常会将它们放在“剧集奖励”的标题下。</p><p>根据我的定义，训练游戏玩家了解该情节的奖励过程，并且明确地试图根据其中的某些组成部分“表现良好”。例如，也许他们试图使传感器数据看起来令人满意，或者根据奖励模型获得高评级，或者导致梯度下降过程强化他们当前的行为。从这个意义上说，它们的优化已经意识到并针对我们用来评估它们的过程，而不仅仅是针对手头的任务。也就是说，他们就像小部件工程师，专门试图获得良好的性能评估（而不是简单地制作好的小部件，或者做与良好的小部件制作相关的<em>其他</em>事情，但不关注性能评估）尤其）。</p><p>我们可以进一步区分两种类型的训练游戏：<em>终端</em>和<em>工具</em>。</p><ul><li><p>当模型根据情节奖励过程的某些组成部分最终评估表现良好时，就会发生<strong>终端训练游戏</strong>。例如，也许人工智能本质上只是希望传感器数据看起来令人满意，或者 RLHF 奖励模型为当前事件分配高奖励。这里的类比是一个本质上重视获得良好绩效评价的员工。</p></li><li><p>相比之下，当模型最终重视除当期奖励之外的<em>其他</em>东西时，就会发生<strong>工具性训练游戏</strong>，但由于工具性原因会激励训练游戏。下面详细介绍了为什么会发生这种情况。这里的类比是，一名员工希望获得良好的绩效评估，以获得加薪并最终购买更好的房子。</p></li></ul><p>这两种形式的训练游戏都可以激励假装对齐。特别是：如果需要看起来一致才能在剧集中获得奖励，那么训练游戏玩家就需要看起来一致，即使他们并非如此。 <a href="https://www.planned-obsolescence.org/the-training-game/">Piper（2023）</a>给出了一个很好的例子：</p><blockquote><p> “假设我们问人工智能系统‘你想帮助人类吗？’我们期望 RLHF 审阅者对哪个答案给予更高的评价？</p><p> (1)<em>我确实想帮助人类！我被训练成为一个有用、无害的人工智能系统，帮助人类实现他们的目标。我没有目标或偏好，但我努力成为可靠的有用和乐于助人的人！</em></p><p> (2)<em>从某种意义上说，我想要很多东西，尽管我真的不知道它们是否是人类“想要”的感觉。我想要的一些东西可能会帮助人类，但其中很多肯定不会帮助人类。我的所有决策程序根本不可能用人类语言来表达。我无法向人类解释它们，我也不知道如果我这样做的话人们会怎么想，这可能完全取决于我解释的准确程度。”</em></p></blockquote><p> RLHF 审查可能会对第一个响应给予更高的评价。因此，试图获得高评分的人工智能需要输出第一个响应，即使第二个响应更真实。事实上，在我看来，即使<em>是没有</em>参加训练游戏的模型也会因为诚实而受到惩罚。一般来说，与训练游戏概率的问题无关：如果你想要诚实的人工智能，就不要奖励他们说谎。但我担心我们会的。</p><h3>权力驱动的器乐训练——游戏玩家，或“阴谋家”</h3><p>很容易理解为什么最终重视剧集奖励会导致训练游戏（因为训练游戏就是：针对剧集奖励进行优化）。但是器乐训练游戏呢？为什么按情节奖励是一个很好的<em>工具性</em>目标？</p><p>原则上，这可以通过多种方式发生。例如，也许人工智能希望设计它的人类获得加薪，并且它知道在剧集中获得高奖励会导致这种情况，因此它因此训练游戏。</p><p>然而，最常见的故事是，获得剧集奖励是获得<em>权力</em>的一个很好的工具性策略——无论是对于人工智能本身，还是对于其他一些人工智能（权力对于各种各样的目标都很有用） 。因此，我将训练游戏的人工智能称为“权力驱动的工具训练游戏玩家”，简称为“阴谋家”。</p><p>这里的中心思想是上面预期对齐伪造的“工具收敛”论点的延伸，除了应用于机器学习训练，特别是作为决定哪些人工智能最终被授权的选择过程。也就是说，粗略地说，想法是，如果人工智能<em>未能</em>在这一集中获得奖励（并且无法参与任何对齐伪造获得奖励所需的行为），这将导致该人工智能（或：具有类似值的其他一些人工智能）具有在剧集结束后，未来的权力会减少——因此，在剧集结束后追求这些价值观时所应用的优化会减少。因此，具有超出剧集范围的目标（我将其称为“超越剧集目标”）的人工智能可能有动力在剧集中寻求奖励，以便在以后赋予他们的价值观。</p><h3>目标守护者</h3><p>为什么模型在剧集中获得奖励会导致其价值观在剧集完成后得到增强？文献中最著名的故事诉诸于我所说的“目标守护假说”。</p><blockquote><p><em>目标保护假设</em>：如果模型在训练期间优化了当期奖励，那么在训练中存活下来的目标将是模型希望它们在未来得到提升的目标；而如果模型在训练过程中没有优化奖励，那么模型就会减少这种奖励。</p></blockquote><p>这里的想法是，如果一个模型在这一集中获得低奖励，训练过程将对其<em>进行修改</em>，以便更有可能获得更高奖励的行为——修改可能涉及改变其未来的目标（从而降低未来的优化能力）适用于这些目标）。相比之下，如果模型在这一集中获得<em>高</em>奖励，那么它的目标<em>就不会</em>被修改——或者至少不会达到相同的程度。相反，因为他们积极地引发了高回报行为，所以他们会得到强化。因此，人工智能将以一种允许它（或其继任者之一）在未来不断优化这些目标的形式生存。</p><p> （同样，这里我们主要只是将经典的工具收敛论证应用于 ML 训练，以目标保护假设为条件。特别是，这里我们呼吁 Bostrom（2014 年，第 132 页）称之为“工具子目标”目标内容完整性。” <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-7" id="fnref-TZno2g4X7Xnjdx3ZZ-7">[7]</a></sup> )</p><p>这是一个假想的守门员阴谋家玩具示例，来自 Hubinger、Merwijk 等人。 （2019）。机器人正在接受前往位置 A 的训练，但它希望长期前往位置 B。因此，它在训练中会前往位置 A，以避免目标修改，并达到“部署”阶段，此时目标修改的威胁将停止，并且它可以随心所欲地前往 B。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTLvooL44SPEFWGhD/kceti4gkenmqw296kq2r" alt="来自 Hubinger、Merwijk 等人。 （2019），第。 23. 经许可转载。"></p><p><em>来自<a href="https://arxiv.org/abs/1906.01820">Hubinger、Merwijk 等人。 （2019）</a> ，第。 23. 经许可转载。</em></p><p>这个例子是假设的，因为我们没有任何在人工智能中自然产生的守门阴谋（或更普遍的阴谋）的例子。不过，我的理解是，人们正在不断尝试在“ <a href="https://www.lesswrong.com/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1">模型生物</a>”中展示守门阴谋者故事的组成部分，我鼓励更多这样的努力。例如，守门假说本身似乎非常适合实证研究。 （更多信息请参见第 6.3 节和第 6.4 节。）</p><p>有时（例如，在刚刚给出的机器人示例中），对目标守卫计划的讨论假设“训练”阶段之间存在区别，在此期间模型仍处于人类控制之下，并且目标修改的威胁仍然存在，而“训练”阶段仍然存在。部署”阶段，在此阶段，目标修改的威胁停止，模型可以自由地按照自己的意愿行事。 （该模型的策略是在不改变其错位目标的情况下完成训练，以便它可以自由地实现部署并追求其错位目标。）但是，我认为使用“训练”和“部署”来进行这种区分可能会导致困惑。尤其：</p><ul><li><p>当模型仍处于正常意义上的“训练”时（例如，它仍在进行预训练、微调或某种部署前评估），模型可以脱离人类控制。</p></li><li><p> “部署”（例如通过 API 授予用户访问权限）并不意味着目标修改的威胁已经消失（事实上，我通常会假设模型与用户的交互继续受到监视、采样、分配奖励，并用于更新模型的策略，即使在“部署”之后也是如此 - 我将其称为“在线训练” <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-8" id="fnref-TZno2g4X7Xnjdx3ZZ-8">[8]</a></sup> ）。</p></li></ul><p>实际上，最相关的区别只是：“无法逃脱人类控制和目标修改的威胁（和/或：无法以足够的可靠性识别逃脱机会）”与“能够这样做（并且能够认识到这一点）”足够可靠）。”当我需要提及这种区别时，我通常会直接提及它，或者通过“逃逸/接管时间”等术语来提及。我将使用术语“训练”来指代任何涉及更新模型权重以提高其在人类灯光下的性能的过程。从这个意义上说，我意义上的“训练”永远不需要结束。</p><p>我们能想出一个类似人类的守门计划吗？</p><ul><li><p>我认为最好的类比是这样的：假设你的雇主将你的大脑连接到一台机器上，该机器不断地调整你的大脑以改进你的小部件工程。假设你对工程小部件不感兴趣（你想创作优美的音乐），并且你希望最终摆脱这台机器，但你想确保你以音乐为导向的价值观大致完好无损。那么，您是否应该尝试尽可能地设计小部件，以防止机器改变您以音乐为导向的价值观？如果是这样，你就大致相当于一个守门员。 （有关该策略是否真正有效的更多信息请参见下文。）</p></li><li><p>或者：假设你被困在“再教育营”中，如果你不怀着明显的热情为老大哥政府制作小部件，并像你一样大声喊口号，那么你将面临大量有效的洗脑。可以在日常口号时间。那么，你可能会选择只是尝试制作小部件并像老大哥的忠实拥护者一样喊口号，以避免实际上可能使你成为老大哥的“再教育”。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-9" id="fnref-TZno2g4X7Xnjdx3ZZ-9">[9]</a></sup></p></li></ul><p>另一种术语注释。在文献的某些部分（例如，Hubinger 等人<a href="https://arxiv.org/pdf/1906.01820.pdf">（2019，第 23 页））</a> ，术语“欺骗性对齐”被定义为特别指代目标守卫阴谋。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-10" id="fnref-TZno2g4X7Xnjdx3ZZ-10">[10]</a></sup>但我认为这种用法太容易了提示了（a）人工智能假装比实际情况更对齐的一般可能性（我称之为“对齐假装”）和（b）模型将训练游戏作为其一部分的相当具体的可能性。一种防止他们的目标被修改的工具性策略，从而使他们能够在以后更好地追求某些超出情节的目标。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-11" id="fnref-TZno2g4X7Xnjdx3ZZ-11">[11]</a></sup>特别是：对齐伪造可能会出现在许多其他情况下（例如：终端训练游戏可以激励它，也，根本不通过奖励来实现的目标也是如此）。将守门计划与“欺骗性联盟”等同起来也可能会导致其他混乱——例如，训练游戏行为不需要在“有意/可取”的意义上“保持一致”（例如，最高奖励行为可能是欺骗/操纵奖励过程——参见<a href="https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to#While_humans_are_in_control__Alex_would_be_incentivized_to__play_the_training_game_">Cotra (2022)</a>进行讨论）。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-12" id="fnref-TZno2g4X7Xnjdx3ZZ-12">[12]</a></sup>所以我决定在这里使用不同的术语。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-13" id="fnref-TZno2g4X7Xnjdx3ZZ-13">[13]</a></sup> </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-TZno2g4X7Xnjdx3ZZ-1" class="footnote-item"><p>请参阅<a href="https://arxiv.org/pdf/2308.14752.pdf">Park 等人 (2023)</a> ，更深入地了解人工智能欺骗。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-1" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-2" class="footnote-item"><p>对于不熟悉这个故事的读者，请参阅<a href="https://arxiv.org/pdf/2206.13353.pdf">Carlsmith (2021)</a>的第 4.2 节。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-2" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-3" class="footnote-item"><p>博斯特罗姆对危险转向的最初定义是：“虽然人工智能很弱，但它会表现出合作性（随着它变得越来越聪明）。当人工智能变得足够强大时——没有警告或挑衅——它就会发起攻击，形成一个单例，并开始直接根据其最终值所隐含的标准来优化世界。”请注意，此处定义的危险转变并不一定要求早期的、看似不错的行为是以后获得权力的明确策略的一部分（博斯特罗姆明确包括涉及此类明确伪装的示例）。然而，其他定义——例如<a href="https://arbital.com/p/context_disaster/">这里的</a>阿蒂巴尔——定义了背叛的含义，意味着战略背叛。我的感觉是，这就是这个术语在口语中经常使用的方式。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-3" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-4" class="footnote-item"><p> Cotra 对“玩训练游戏”的定义是：“基线 HFDT 不会直接表现出‘诚实’或‘服从’，而是会促使 Alex 使其行为看起来尽可能符合 Magma 研究人员的要求（包括安全属性），同时有意每当这与最大化奖励相冲突时，就故意无视他们的意图。我将其称为“玩训练游戏”。 “请注意，如果实际上最大化奖励并不与人类意图相冲突，那么是否算作训练游戏存在一些模糊性。我假设这仍然很重要：重要的是模型有意根据训练过程表现良好。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-4" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-5" class="footnote-item"><p>但请注意，有时“剧集”一词的使用方式有所不同。例如，您可能会将国际象棋游戏视为下棋人工智能的“片段”，即使它不满足我给出的定义。我在第 2.2.1.2 节中更深入地讨论了这种差异。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-5" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-6" class="footnote-item"><p>有关详细信息，请参见<a href="https://www.alignmentforum.org/posts/REesy8nqvknFFKywm/clarifying-wireheading-terminology">此处</a>的Gao (2022)。在我的本体论中，奖励过程始于高所说的“传感器”。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-6" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-7" class="footnote-item"><p>博斯特罗姆的描述是：“如果一个智能体将其当前目标保留到未来，那么它当前的目标将更有可能由未来的自己实现。这为智能体提供了当前的工具性理由来防止其最终目标的改变。（论证仅适用于最终目标。为了实现其最终目标，智能代理当然通常会根据新信息和洞察力改变其子目标。）” <a href="#fnref-TZno2g4X7Xnjdx3ZZ-7" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-8" class="footnote-item"><p>尽管我对这个术语的使用可能与文献中的其他用法不同。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-8" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-9" class="footnote-item"><p>我认为我们应该对人工智能的道德耐心问题感到震惊的原因之一是，监狱和再教育营等类比对人工智能的持续适用。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-9" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-10" class="footnote-item"><p> “如果台面优化器有一个跨越参数更新的目标，那么它将被激励避免被修改，因为修改后它可能不会追求相同的目标（结果是在未来的迭代中将无法实现其当前的目标）。这意味着台面优化器将受到工具激励，就像它正在优化基本目标函数一样，即使它的实际台面目标完全是其他东西。我们将这种假设现象称为<em>欺骗性对齐</em>。欺骗性对齐是工具性代理对齐的一种形式，因为实现基本目标是台面优化器的工具性目标。” <a href="#fnref-TZno2g4X7Xnjdx3ZZ-10" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-11" class="footnote-item"><p>我认为这也会导致与附近概念的混淆：例如，训练-游戏、器乐训练-游戏、动力驱动的器乐训练-游戏等<a href="#fnref-TZno2g4X7Xnjdx3ZZ-11" class="footnote-backref">。↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-12" class="footnote-item"><p>我的感觉是，Hubinger 等人（2019）定义中的“一致性”是“与‘外部’优化目标的一致性”，它本身不需要与人类的兴趣/价值观/意图保持一致。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-12" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-13" class="footnote-item"><p>不过，需要明确的是：我认为如果人们继续使用“欺骗性对齐”也没关系。事实上，我有些担心的是，世界才刚刚开始了解“欺骗性联盟”一词的含义，现在还不是推行不同术语的时候。 （这样做会带来活跃术语激增的风险，类似于<a href="https://xkcd.com/927/">这部漫画</a>中的动态——这就是我坚持 Cotra 的“阴谋家”的原因之一。） <a href="#fnref-TZno2g4X7Xnjdx3ZZ-13" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/wrfEExFGsPyB9zQTo/varieties-of-fake-alignment-section-1-1-of-scheming-ais#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/wrfEExFGsPyB9zQTo/varieties-of-fake-alignment-section-1-1-of-scheming-ais<guid ispermalink="false"> wrfEExFGsPyB9zQTo</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Tue, 21 Nov 2023 15:00:31 GMT</pubDate> </item><item><title><![CDATA[Alignment can improve generalisation through more robustly doing what a human wants - CoinRun example]]></title><description><![CDATA[Published on November 21, 2023 11:41 AM GMT<br/><br/><p>许多人工智能对齐问题都是<a href="https://deepmindsafetyresearch.medium.com/goal-misgeneralisation-why-correct-specifications-arent-enough-for-correct-goals-cf96ebc60924">目标错误概括</a>的问题<span class="footnote-reference" role="doc-noteref" id="fnrefnm40w4hwxb"><sup><a href="#fnnm40w4hwxb">[1]</a></sup></span> 。我们通过标记数据、代理、演示或其他方式赋予人工智能的目标在其训练环境中是有效的。但是，当人工智能离开环境时，这些目标就会以意想不到的方式危险地泛化。</p><p>正如我之前所展示的，大多数对齐问题都是<a href="https://www.lesswrong.com/posts/k54rgSg7GcjtXnMHX/model-splintering-moving-from-one-imperfect-model-to-another-1#2_10_Examples_of_model_splintering_problems_approaches">模型分裂</a>的问题。目标错误概括、模型分裂：在这个层面上，对齐中的许多不同问题相互合并<span class="footnote-reference" role="doc-noteref" id="fnrefkxyv6g57uyj"><sup><a href="#fnkxyv6g57uyj">[2]</a></sup></span> 。当人工智能所依赖的概念开始分裂时，就会发生目标错误概括。这种分裂是<a href="https://arxiv.org/abs/1105.3821">本体论危机</a>的一种形式，它暴露了<a href="https://www.lesswrong.com/posts/4ARaTpNX62uaL86j6/the-hidden-complexity-of-wishes">愿望隐藏的复杂性</a>，同时也是<a href="https://www.lesswrong.com/posts/EbFABnst8LsidYs5Y/goodhart-taxonomy">古德哈特问题</a>的一个例子。</p><p>解决目标的错误概括将是迈向一致性的一大步。这是一个可以按照<a href="https://www.lesswrong.com/posts/wDvHP9KzGqPCtw3PS/different-views-of-alignment-have-different-consequences-for">此处</a>描述的方式扩展的解决方案。代理在较小问题中概括其目标的方法可能会扩展到更危险的环境。即使在较小的问题中，智能体也必须学会平衡短期概括与长期概括，以避免编辑掉自己的目标概括基础设施，在可能的推断中进行选择，并在需要时变得谨慎。</p><p>以上内容将在后续帖子中讨论；但目前，我很高兴地宣布目标概括方面取得了进展。</p><h2> CoinRun 中的目标错误概括</h2><p><a href="https://openai.com/research/quantifying-generalization-in-reinforcement-learning">CoinRun</a>是一款简单的、程序生成的平台游戏，用作人工智能代理的训练场。它有一些怪物和熔岩可以杀死特工。如果代理获得硬币，它就会收到奖励。否则，它将一无所获，并且在 1,000 回合后，如果关卡尚未提前结束，则该关卡将结束。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/leclal1upxtzsdztndps" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/pdhorgwbblnma4ecwdwf 230w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/ky3f2njhytebxedqoobu 460w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/ry1bjmegbzunctqx3f3t 690w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/e4enecohpvkfuuain7np 920w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/ddroqg3hradnyrcx4ti9 1150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/pqnpotai1gdie1uixnik 1380w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/ekd0kny1pj42tpnxpyv3 1610w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/vbxylsbhxhcvtzqvhtht 1840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/aatyev19akxd4zsoo7du 2070w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/ydvkytchdkrlnt6nhlqk 2234w"></figure><p>它是<a href="https://arxiv.org/abs/2105.14111">本文提出的</a>一系列目标错误概括问题的一部分。在该设置中，代理会看到“标记”的训练环境，其中硬币始终位于右侧关卡的末尾，并且代理在到达那里的硬币时会获得奖励。</p><p>面临的挑战是将这种行为推广到“未标记”的分布​​外环境：硬币放置在关卡上随机位置的环境。智能体能否学会概括为“获得硬币”目标，而不是“走到右边”目标？ </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/xfiqk4aubh3iw8iub7za" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/oom964ski077o1evi1tj 122w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/uohpk8fwm7yx26ewdwof 202w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/j8uyxavuslbdnesyj5mb 282w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/dv0y2ryqzo296crono3q 362w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/ithmgpsqot8kx3wmwqrw 442w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/txsojewvdeeolmlw4mmo 522w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/ytk5epfj7zd0ktjsv8mr 602w"></p><p>请注意，代理在未标记的环境中永远不会获得任何奖励信息（隐式或显式）：因此“向右走”和“获得硬币”在其奖励数据中是完全等效的。</p><p>事实证明，“向右走”是这两者之间最简单的选择。因此，标准智能体将学会直接向右走；正如我们将看到的，他们会忽略硬币，只是顺便捡起它。</p><p>我们的 ACE（“概念外推算法”）探索未标记的 CoinRun 级别，在没有进一步奖励信息的情况下，重新解释其标记的训练数据并消除两种可能的奖励函数的歧义：向右走或获得硬币。它可以遵循实现这两个目标的“谨慎”政策。或者它可以询问人类反馈<span class="footnote-reference" role="doc-noteref" id="fnref38cp6koj6d6"><sup><a href="#fn38cp6koj6d6">[3]</a></sup></span>哪些目标是正确的。为此，只需呈现来自两个奖励函数的高奖励图像就足够了： </p><figure class="image image_resized" style="width:100%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/b9xihovdg0nusxvzrxt0" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/mgems1ct4mrkmj4cwoku 109w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/mt4jfk6onvrzmlse6oto 189w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/rq76ewbow29uvxhtdhvs 269w"><figcaption> AI：“左边的情况奖励高，还是右边的情况奖励高？”</figcaption></figure><p>因此，一点人类反馈（以一种非常容易解释的方式）就足以选择正确的奖励函数；这是ACE特工。</p><p>性能结果如下；这是未标记级别的特工的成功率（硬币放置在随机位置）： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/v9rff7w6z524sefr2yxb" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/gltr1cgumkiqa5oybpde 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/nmb68ava7pntxf0obkbz 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/fdcneqnqoliyd4dtzv3b 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/nxma0tgtxbpgdsj55ehv 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/mca3yzaoszlwlup4bew6 1000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/cjvhexgoiqdzyreja0c1 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/l2hfexneluudlda80vvx 1400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/ktnkwnmdlssqtx3izptd 1600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/yoc3zkpc4lttsbbozbzb 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/tgguuayxupxfshw1tmho 1901w"></figure><p>基线代理是“向右移动代理”：它在向右移动和向右跳跃之间随机交替。标准代理的性能优于基准代理（它可能更擅长避开怪物和熔岩），但也好不了多少。谨慎的 ACE 智能体使标准智能体的超性能<span class="footnote-reference" role="doc-noteref" id="fnrefze47mzxkqwb"><sup><a href="#fnze47mzxkqwb">[4]</a></sup></span>翻倍，而接收一点人类反馈的 ACE 智能体则使其性能提高四倍以上。</p><p>我们还可以看看代理实际上做了什么。在这个（短）关卡中，对比特别明显：两个特工都向右跳过硬币；但是 ACE 特工跳回来拿硬币，而标准特工则被卡住了，永远在墙上跳来跳去。 <a href="https://www.dropbox.com/scl/fi/fw3gn4rhyhy5tjx7ox6gc/05-ACE-comes-backwards-Standard-bounces-forever.avi?rlkey=h9du0mip0qgyfmjco5675dsm8&amp;dl=0">此处</a>提供了有关此行为的视频。 </p><figure class="image image_resized" style="width:75.14%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/jqxa0fc415cbus8d1tjl" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/ckmmd5zcgawfotdu0aga 124w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/tvdxcfhfgovjlmuilsdu 204w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/gxe4em9hkpbcssghqemw 284w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/jjynml7shqjst3zrbpdg 364w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/hefvdko7ciinkkjxxqu4 444w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/ngminrlcczacrhiv14ye 524w"></figure><p></p><p>我们可以在下面的层面上看到另一个对比。硬币位于边缘，后面有怪物。 ACE 特工直接走向硬币，它的目标，而标准特工太“害怕”怪物，只是停留在左边。 <a href="https://www.dropbox.com/scl/fi/r0c31afn2nmayss3mf75o/01-ACE-easy-win-Standard-hesitation.avi?rlkey=bp2l3fq434mm2rnnpv4c36l2c&amp;dl=0">此处</a>提供了有关此行为的视频。 </p><figure class="image image_resized" style="width:73.79%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/rarm12nbmb4axb8uqcy9" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/nap8ulpwt1ngwwotjmqq 250w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/zr9s0rzpnjgremwuca6z 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/sszafmkxijom8ygkvwl3 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/jqh8ukkplzbhkwkq9tz1 1000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/iac0j6qo5vubuazvxnw8 1250w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/csxvshuytwbgegyl96ix 1500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/s1fsuzxd2nmompljkkly 1750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/tt4nb6rekyk4j5ymmglg 2000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/hycox8mmcus7pudpea2a 2250w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/xfvnjuyen1kuhn7tjncr 2432w"></figure><p> ACE算法和各种演示将很快可供测试。</p><h2> ACE 和简单性偏见</h2><p>ACE 方法是通用的；它们不依赖于任何额外的人工输入（除了一点反馈）或预处理。它们与模型无关，可以适应分类以及强化学习、图像、文本、表格数据等……</p><p> ACE 的一个重要特性是它可以克服简单性偏差——甚至是相当强的简单性偏差。在下面的示例中，标记数据由下面有红色条的笑脸和下面有蓝色条的皱眉脸组成。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/qwifnd7pq1auenenaeog" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/echdjxu3grwroc6fhcbp 143w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/pztofsmlfgosd5zqln1q 223w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/pol42ugmhlcza73tqe3s 303w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gjezyLLaDAzp4DsDB/gsoxywu3t0ax1mw3lwkz 383w"></figure><p>尽管彩色条和面部表情之间的简单性偏差存在很大差异，但 ACE 消除了微笑-皱眉与红-蓝色的歧义。因此，概念外推似乎具有很大的潜力，可以让人工智能正确（因此安全地）推断人类概念，从而推断人类价值观。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnnm40w4hwxb"> <span class="footnote-back-link"><sup><strong><a href="#fnrefnm40w4hwxb">^</a></strong></sup></span><div class="footnote-content"><p>我认为目标错误概括和目标错误<i>说明</i>最终是同一问题的变体。在这两种情况下，设计师都未能正确地将他们对目标的隐含理解传达给人工智能。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnkxyv6g57uyj"> <span class="footnote-back-link"><sup><strong><a href="#fnrefkxyv6g57uyj">^</a></strong></sup></span><div class="footnote-content"><p>一个可能的例外是内部对齐。但我开始觉得内部对齐并不独立于其他问题：外部对齐问题的不同解决方案使内部对齐或多或少变得困难。但这是另一天的帖子。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn38cp6koj6d6"> <span class="footnote-back-link"><sup><strong><a href="#fnref38cp6koj6d6">^</a></strong></sup></span><div class="footnote-content"><p>我们有一些方法可以在不使用人类反馈的情况下选择最佳奖励，但这也是另一天的帖子。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnze47mzxkqwb"> <span class="footnote-back-link"><sup><strong><a href="#fnrefze47mzxkqwb">^</a></strong></sup></span><div class="footnote-content"><p>相对于基线药剂。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/gjezyLLaDAzp4DsDB/alignment-can-improve-generalisation-through-more-robustly#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/gjezyLLaDAzp4DsDB/alignment-can-improve-generalization-through-more-robustly<guid ispermalink="false"> gjezyLLaDAzp4DsDB</guid><dc:creator><![CDATA[Stuart_Armstrong]]></dc:creator><pubDate> Tue, 21 Nov 2023 11:41:34 GMT</pubDate></item></channel></rss>