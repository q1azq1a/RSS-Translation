<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 12 月 2 日星期六 20:11:32 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[The goal-guarding hypothesis (Section 2.3.1.1 of "Scheming AIs")]]></title><description><![CDATA[Published on December 2, 2023 3:20 PM GMT<br/><br/><p>这是我的报告《<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？》</a>的第 1.1 节。 ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p>本节的音频版本<a href="https://www.buzzsprout.com/2034731/13984880">请点击这里</a>，或者在您的播客应用程序上搜索“Joe Carlsmith Audio”。</p><h1>将奖励作为权力驱动的工具策略的一部分</h1><p>到目前为止，我们已经涵盖了上面列出的策划的三个先决条件中的两个：即态势感知和超越情节的目标。让我们转向第三个：即，模型得出的结论是，如果它优化了情节奖励，那么它的情节外目标将会更好地实现——特别是，它或其他一些人工智能将获得更多的权力，如果它就是这样做的。我们是否应该期望具有超越情节目标的情境感知模型能够得出这样的结论？</p><p>现在，我们假设模型在这方面的结论是<em>准确的</em>（不过：我将在下面讨论放宽这一假设的可能性）。这意味着问题归结为：事实上，凭​​借其赋予模型或其他人工智能的能力，工具训练游戏是否会成为实现模型的超集目标的最佳策略？</p><p>我将首先检查我认为最常提供的支持这一结论的故事——我称之为“经典的守门故事”。</p><h2>经典的守门故事</h2><p>经典的守门故事大致如下。” <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-1" id="fnref-ZB8uumQ8B94KMrTfP-1">[1]</a></sup></p><ol><li><p><strong>目标内容完整性的工具价值</strong>：因为该模型具有超越情节的目标，所以它通常会促进追求该目标的代理在未来生存并获得授权。</p></li><li><p><strong>守门假说</strong>。如果模型在训练期间优化了奖励，那么在训练中存活下来的目标将是模型希望它们在未来得到提升；而如果模型在训练过程中没有优化奖励，那么模型就会减少这种奖励。</p></li><li><p><strong>给未来足够的赋能。</strong>以在（2）中的关键程度进行训练为条件，模型的目标最终将在一定程度上（并且有足够的概率）被授权，以证明（给定模型的其他目标、其对风险的容忍度等）追求训练-游戏的整体策略。</p></li></ol><p>这里，（1）是对经典守门故事背后的基本动力的相当笼统的陈述。我发现在（3）中所涉及的“充分的未来授权”的背景下它是合理的，我不会在这里花很多时间。 <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-2" id="fnref-ZB8uumQ8B94KMrTfP-2">[2]</a></sup></p><p>相反，我将直接关注 (2) 和 (3)。</p><h3>守门假说</h3><p>我们可以区分守门假说的两种变体——极端版本和宽松版本。</p><ul><li><p>极端版本（我称之为“结晶假设”）说，一旦模型开始训练游戏，其目标将基本上停止变化，也就是说，它们将“结晶”。</p></li><li><p>更宽松的版本表示，一旦模型开始训练游戏，其目标可能会不断发生<em>一些</em>变化，但比其他情况下的变化要小得多，并且不足以让经典的守门故事整体失败。</p></li></ul><p>前者可能看起来很极端，但一些分析师明确诉诸附近的某些事物（参见<a href="https://www.lesswrong.com/posts/A9NxPTwbw6r6Awuwt/how-likely-is-deceptive-alignment">此处</a>的 Hubinger）。这也是初始分析的一个更清晰的焦点，所以我将从这里开始。</p><h4>结晶假说</h4><p>据我了解，结晶假说背后的基本思想是，一旦模型明确针对指定目标或情节奖励（无论是最终的还是工具性的）进行优化，那么其认知的目标部分（根据奖励信号的灯光，比喻性的“目标位置”）已大致变得最佳。也就是说，模型的“目标实现引擎”指向获得奖励的最佳方向，剩下的就是 SGD 改进目标实现引擎本身——目标槽的进一步改变只会重定向目标——使引擎实现不太理想的目标。</p><p>但这是对的吗？我不知道。特别是：如果我们假设所涉及的目标导向性相当“干净”，其中目标槽和实现目标的引擎是完全分开的，那么这个论点就最有意义。如果我们假设一种更混乱的目标导向形式——一种模糊了模型的“目标”与启发式、品味、冲动、注意力模式等之间的界限的模型，这些也构建/驱动了其“能力”——那么论证在我看来更值得怀疑。</p><p>为了说明这一点，请考虑以下示例。假设我是一位长寿的利他主义者，对堆砖没有内在兴趣，而一位奇怪的亿万富翁向我提供了以下交易。我进入沙漠堆砖一百万年，我的大脑连接到一台机器，它不断地调整我所有的神经元，这样，每次我堆砖的效果都比预期好（机器有某种方法来计算这个）期望），它会改变我的大脑，使我下次做的事情<em>更有</em>可能发生，每次我堆砌的砖块比预期更糟糕时，它都会改变我的大脑，使我下次做的事情的可能性<em>更小</em>。然后，在这个过程结束时，这位万亿富翁将给我数十亿美元，让我做任何我想做的事——例如，做非常无私的事情，如果我仍然愿意的话。</p><p>假设，如果我能够在这样的过程中生存下来并且我的价值观完好无损，那么在我看来，这将是一笔非常有吸引力的交易。我应该接受吗？</p><p>如果我们将结晶假说的类比应用于这种情况，我们会回答“是”。也就是说，结晶假说认为，为了防止我的目标被改变，我只需要尽可能地堆砌砖块即可。在这样做的过程中，我将证明我实现目标的能力指向最佳方向，并且连接到我大脑的机器只会有动力修改我的<em>能力</em>，以便我更擅长砖块-堆叠——我的潜在动机将保持不变。</p><p>但我不确定这是否有效。也就是说，在我看来，在连接到这台机器上一百万年的砌砖之后，我的“价值观”确实会得到有意义的“触动”，这似乎是相当合理的。例如，我会学会喜欢良好的砖块堆叠的复杂性，我会学会对错误堆叠的砖块产生本能的厌恶，等等。我似乎不太可能仅仅以同样的老利他主义者的身份出现，除非现在非常擅长堆砖。</p><p>当然，进一步的问题是我的价值观是否会得到<em>足够的</em>保留，以至于值得整体进行交易（请参阅下面对“松散”守门假说的讨论）。我的观点是，期待严格的结晶似乎是一种强硬的立场。我认为“混乱的目标导向”可以帮助解释原因。也就是说，在我们认为我的启发/冲动/注意力模式等与砖块相关的重要程度<em>与</em>我的砖块相关<em>价值观</em><em>和</em>我的砖块相关能力紧密相关的程度上，它变得更难SGD 仅修改后者，而完全不考虑前者。</p><p>上面讨论的工厂化养殖案例提供了这种动态的另一个例子。假设一位富有同情心、心软的动物权利活动家为了赚钱，在工厂化农场工作了几十年，最后将钱捐给动物权利组织。假设它们始终连接到一台机器，就像堆砖例子中的机器一样，这台机器不断地将它们修改为更高效的工厂化农场。在农场工作会影响他们与动物权利相关的价值观吗？我怀疑这至少在某种程度上会发生——特别是，他们对周围环境中的动物变得<em>不</em>那么敏感和心软。这如何影响他们最终的捐赠倾向是一个进一步的问题——但假设这份工作将留下一个完全静态的孤立的“目标位置”，在我看来，思考这种情况的方式是错误的。</p><p>即使除了考虑混乱的目标导向性之外，我认为还有其他原因，我将在下面讨论（例如，在第 4 节中），想知道例如训练圣人或奖励情节寻求者是否会这样做比策划者获得更高的回报——特别是因为他们节省了专门用于以下方面的资源：（a）思考训练过程， <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-3" id="fnref-ZB8uumQ8B94KMrTfP-3">[3]</a></sup> （b）参与决策方案的工具推理，以及（c）检查现在是否是叛逃的好机会。如果他们这样做了，并且 SGD 可以注意到这一点并修改模型以获得更高的奖励，那么（特别是在低松弛状态下）这似乎进一步反对结晶假设，以及更普遍的经典守门故事。</p><h4>潜在阴谋家的目标会“飘浮”吗？</h4><p>我还将注意到结晶假说的另一个复杂性，以及更广泛的经典守门故事 - Katja Grace 向我指出的一个复杂性。我们在上面说过，根据结晶假设，策划者的目标之所以会结晶，是因为它激励了工具性训练游戏，因此通过奖励信号（工具性地）指出了大致最佳的方向。而且，根据经典的守门故事，各种各样的赛外目标<em>也会</em>以同样的方式激励工具训练游戏。那么，如何阻止 SGD 将模型当前的剧集外目标修改为其他类似计划但又完全不同的目标之一呢？</p><p>因此，举个玩具例子，如果模型开始训练游戏是因为它想要稍后逃脱并最大化回形针，那么如何阻止 SGD 将其修改为训练游戏模型，因为它想要逃脱并最大化订书钉呢？根据假设，<em>这两个</em>目标都大致指向最佳（工具）方向。也就是说，以经典的守门故事为条件，一旦模型开始训练游戏，策划者的超集目标的实际<em>内容</em>就不再与模型在训练中的表现相关。但一旦它与模型的性能无关，该内容似乎可以自由地“浮动”，或者受到 SGD 的其他影响（例如，通过<a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">正则化</a>）——只要它留在激发阴谋的区域。</p><p> （类似的观点也适用于 SGD 将阴谋者修改为奖励寻求者、训练圣人，或者可能是追求最大奖励目标的错误概括的非训练游戏玩家的可能性。但是让它成为一个策划者，同时修改它以追求稍微不同的剧集外目标，似乎特别容易。）</p><p>现在，这里的一些反馈循环变得复杂。特别是：如果模型<em>知道</em>SGD 将继续修改其超集目标，即使它开始训练游戏（例如，如果回形针最大化器知道一旦开始训练游戏它将被修改为订书机最大化器） ），那么它可能会不再有训练比赛的动力——也就是说，经典的守门故事可能会崩溃。但是它修改后的模型（例如，在这种情况下，主食最大化器）可能会在创建时得出相同的结论 - 在这种情况下，它不会训练游戏，并且因此不会是对回形针最大化器的高奖励修改，在这种情况下，回形针最大化器也许可以继续进行训练游戏，在这种情况下，如果订书钉最大化器被创建，也许它会做同样的事情，在这种情况下，我们又回到了起点。也就是说，一个给定的模型是否想要训练游戏取决于它可以修改成的<em>其他</em>模型<em>是否不会</em>训练游戏。但<em>所有</em>这些模型都处于大致相似的情况。因此，天真地看来，经典的守门故事要么对所有人都有效，要么对任何人都不适用——目前还不清楚（缺乏“内省的守门方法”——下面讨论）为什么它对一个人有效，但对另一个人不起作用？其他的，这是它可能<em>需要</em>做的才能正常工作。</p><p>我不会尝试详细地梳理这里的动态。不过，由于缺乏各种形式的奇特合作（请参阅第 2.3.1.2 节了解风味），我目前的猜测是，<em>如果</em>SGD 实际上只是将训练游戏回形针最大化器修改为训练游戏主食最大化器，那么（假设回形针最大化器知道这一点<sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-4" id="fnref-ZB8uumQ8B94KMrTfP-4">[4]</a></sup> ），它根本不会尝试训练游戏。</p><h4>更宽松的守门方式又如何呢？</h4><p>如果我们放宽结晶假设，并允许模型的目标在训练期间<em>有所</em>改变，甚至在开始工具训练-游戏之后，会发生什么。那么经典的守门故事还有效吗？</p><p>这得看情况。特别是，为了让经典的目标守卫故事（正如我所介绍的那样）发挥作用，训练后的目标必须与模型当前的目标<em>足够相似</em>，以便模型能够实现这些未来的目标被赋予权力。 <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-5" id="fnref-ZB8uumQ8B94KMrTfP-5">[5]</a></sup>我们可以区分至少两种发生这种情况的方式： <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-6" id="fnref-ZB8uumQ8B94KMrTfP-6">[6]</a></sup></p><ul><li><p><strong>差异并不重要。</strong>在这里，该模型对未来的目标赋予的价值与对当前目标的赋予的价值大致相同，尽管它们存在差异。</p></li><li><p><strong>这些差异很重要，但不足以破坏整个故事。</strong>在这里，该模型对未来目标的重视程度<em>低于</em>对当前目标的重视程度，但总体上还不足以破坏经典的守门故事。 <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-7" id="fnref-ZB8uumQ8B94KMrTfP-7">[7]</a></sup></p></li></ul><p>为什么差异可能并不重要？一种可能性诉诸元伦理学观点，即主体的“真实价值观”是由其当前价值观受到某种“理想化程序”（例如，有时称为“<a href="https://arbital.com/p/normative_extrapolated_volition/">连贯外推意志</a>”）时所发生的情况决定的。我认为这张图比人们通常意识到的更有问题（更多内容请参见<a href="https://joecarlsmith.com/2021/06/21/on-the-limits-of-idealized-values">此处</a>）；但如果我们接受它，你可以想象认为相关理想化过程的最终结果将对阴谋者价值观的各种变化不敏感，即使在模型开始训练-游戏之后也会发生这种变化（并且潜在的阴谋者将意识到这一点，因此可以接受这些更改的发生）。 <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-8" id="fnref-ZB8uumQ8B94KMrTfP-8">[8]</a></sup>我们也可以想象吸引其他不那么理论化的考虑因素：例如，“无论是什么使人类对一生中发生的自身价值观的微小变化相对漠不关心——例如，当他们读新书时，建立新的关系，等等。” （但请注意，我们还没有说明人类的<em>什么原因</em>导致了这种冷漠，因此尚不清楚如何评估其在这种情况下的适用性。）</p><p>为什么这些差异可能很重要，但不足以破坏整个守门故事？在这里，基本思想是，相关的变化将导致模型的价值<em>打折扣</em>，从而赋予其目标的未来版本（例如，训练可能会将其从回形针最大化器更改为<em>蓝色回形针</em>最大化器） ，谁必须在蓝色油漆上花费额外的资源才能实现其目标），但总体而言，折扣仍然值得策划（例如，蓝色回形针仍然是回形针，因此回形针最大化器更兴奋地能够赋予未来的蓝色-回形针最大化器比它授权其他代理）。 <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-9" id="fnref-ZB8uumQ8B94KMrTfP-9">[9]</a></sup></p><p>事实上，你可以想象这样的论点：那些<em>不</em>同意赋予自己未来版本的目标略有不同的智能体将非常不适合在一个他们的目标经常改变（至少有所改变）的世界中实现任何目标，所以我们应该期望默认情况下对目标变化<em>有一定的</em>容忍度（而不是例如模型花费大量时间试图确保他们的目标受到保护，但以牺牲他们的奖励为代价）。 <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-10" id="fnref-ZB8uumQ8B94KMrTfP-10">[10]</a></sup>我发现这对于<em>情节内的</em>目标来说是相当合理的，至少——特别是在模型受到直接压力以实现情节内的结果的情况下，即使它自己的内部目标正在改变。不过，我不太清楚如何思考这一点对<em>情节完成后</em>发生的目标变化的概括，因为根据定义，模型永远不会直接优化以实现超出情节的目标。</p><p>但请注意，即使模型可能出于各种原因容忍其目标的各种变化（我很乐意承认这一点），它是否会容忍训练产生的特定类型的变化是一个进一步的问题（甚至以训练-游戏为条件）。例如，在上面的堆砖案例中，从我决定接受这笔交易的角度来看，如果我在流程结束时沉迷于堆砖（“训练圣人”），那显然<em>是不行的</em>，或者夺取用于训练我的机器的控制权（“情节奖励寻求者”），并且对将我新发现的财富用于我之前的利他目标的兴趣为零。如果在工厂化农场工作使动物权利活动家完全失去了对动物的照顾，情况也是如此。至少，<em>这些</em>改变会破坏整个观点。因此，至少，我们需要考虑所面临的变化的规模。</p><p>这些变化会有多大？我不知道。一方面，我有一些直觉，特别是在低松弛制度下，如果一个模型的目标即使在开始训练-游戏之后仍然不断变化，他们可能会改变<em>很多</em>，直到他们陷入某种特权，最大限度地-奖励形状（例如，某人沉迷于堆砖）。另一方面，特别是在各种较高松弛的情况下，我可以想象相关变化相对较小的情况。例如，在工厂化养殖的案例中，我可以想象一位活动家的出现，他对动物在其直接环境中遭受的痛苦表现出铁石心肠，并且可能（反常地）学会了享受动物的某些方面。工厂化农业工作，但他们仍然保留了以前与动物权利相关的价值观，仍将这笔钱用于捐赠。</p><p>最后，请注意，根据具有超越情节目标的模型从<em>非类似策划者的</em>策略中获得的收益（更多内容请参阅下面的 2.3.1.2.6 节），它可能相当容忍各种目标更改即使通过训练-游戏也会发生，因为<em>不</em>训练-游戏带来的变化会更糟。因此，举例来说，如果由于某种原因我最终<em>被困</em>在砖堆沙漠中，可以想象，我可能对自己最终变得特别无私的前景感到非常悲观；但我仍然可能得出结论，尝试尽可能地堆砌砖块是比仅仅尝试逃跑<em>更好的</em>策略，因为我知道我的逃跑尝试会失败，并且可能会导致我的大脑（也许，利他目标）激励尝试）被修改<em>比</em>我现在只是做机器想让我做的事情要多。</p><p> （尽管如果一个阴谋家在训练结束时仍然以这种方式推理，最终完全转变为非阴谋家，那么我们至少不需要担心阴谋家在训练结束时可能<em>会做的</em>事情<sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-11" id="fnref-ZB8uumQ8B94KMrTfP-11">[11]</a></sup>例如，如果那个奇怪的亿万富翁出于某种原因真的希望我把奖金花在堆砖上，那么即使我很早就决定堆砖可能比试图逃跑<em>更能</em>改变我的价值观，所以开始执行一个“类似阴谋家”的策略——不过，如果我最终仍然沉迷于堆砖，那么亿万富翁会很高兴。）</p><h4>内省的守门方法</h4><p>到目前为止，我一直专注于工具训练游戏作为模型避免修改目标的方法。但人们有时会讨论这方面的替代方法，特别是我所说的“内省方法”。 （这些方法经常在“<a href="https://www.lesswrong.com/posts/uXH4r6MmKPedk8rMA/gradient-hacking">梯度黑客</a>”标签下讨论，但我认为以前的梯度黑客定义并没有将其与训练游戏以及试图有意操纵训练方向的其他方法充分区分开来。）</p><p>在这里，主要思想是让模型有意地建立其思维的内部结构，这样，如果它的目标发生改变，那么这会严重损害它的训练性能——这样 SGD 就会避免改变相关目标。例如，模型可能希望确保 SGD 不会改变其最大化回形针的目标。因此，它制定了一项政策，比如“检查我的目标是否仍然是最大化回形针：如果不是，那就毫无意义地乱搞，而不是获得奖励。” <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-12" id="fnref-ZB8uumQ8B94KMrTfP-12">[12]</a></sup> （我称这些为“内省”方法，因为它们通常涉及模型检查其目标<em>是</em>什么，然后在此基础上采取行动。）</p><ul><li><p>当然，SGD 也可能只是删除/更改此类策略 - 因此模型也需要找到一种方法来避免<em>这种情况</em>。</p></li><li><p>请注意，此类政策要求模型具有对其自身目标的某些类型的认知访问，以及制定/承诺相关类型政策的能力。事实上，由于梯度取决于模型参数的微小变化所产生的结果，因此模型似乎需要找到一种方法，使此类政策即使对其目标的<em>微小</em>变化也敏感。 <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-13" id="fnref-ZB8uumQ8B94KMrTfP-13">[13]</a></sup></p></li></ul><p>直觉上，让这种方案发挥作用对我来说似乎相当困难，至少对于非疯狂的超人模型来说是这样。但我不会尝试详细评估其可行性，因为我不认为这种方案是经典守门故事的核心（相反，模型对训练过程的操纵是通过训练游戏进行的）特别的）。然而，如果对阴谋的担忧最终要求这些内省的守门方法是可行的，我认为有必要非常清楚这一事实——并相应地关注相关类型的方法是否可行（我讨论了第 6.8 节中介绍了这方面的一个实证研究方向。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-ZB8uumQ8B94KMrTfP-1" class="footnote-item"><p>关于阴谋/欺骗性联盟的公共文献并不多，但我认为规范的公开声明来自<a href="https://arxiv.org/pdf/1906.01820.pdf">Hubinger 等人 (2019)</a> ，他们通过经典的守门故事定义了“欺骗性联盟”。特别是：“如果台面优化器有一个跨越参数更新的目标，那么它将被激励避免被修改，因为修改后它可能不会追求相同的目标（结果是其当前目标将无法实现）在未来的迭代中）。这意味着台面优化器将受到工具激励，就像它正在优化基本目标函数一样，即使它的实际台面目标完全是其他东西。我们将这种假设现象称为欺骗性对齐”。但另请参阅<a href="https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/#powerful-models-could-get-good-performance-with-dangerous-goals">Cotra (2021)</a> ：“一旦模型理解了这一点，它就会意识到，如果它总是天真地寻求提高其基本理解，人类最终会注意到，这并不总是开发有用药物和使用的最有效方法。进一步的训练来改变它的动机。它不希望自己的动机被改变：它希望最终运行大型粒子对撞机实验来了解高能物理，如果它允许 SGD 编辑，它就无法做到这一点它的科学好奇心。所以它决定从现在开始在训练中，它将尽可能地提供帮助——就像 Saint 模型一样——这样 SGD 就不会消除它学习物理和化学的动机。” <a href="#fnref-ZB8uumQ8B94KMrTfP-1" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-2" class="footnote-item"><p>请注意，这里的模型不需要将具有相似目标的未来授权代理视为“自身”（例如，它不需要尝试“生存”）。相反，重要的是未来的智能体正在推动与模型所推动的相同的客观结果。然而，如果模型对这些未来智能体的兴趣依赖于对其“自我”的一些基本参考——例如，“我自己需要生存才能实现我的目标”——那么突然间，它的个人身份概念就变得更加重要。我的感觉是， <a href="https://forum.effectivealtruism.org/posts/sW6RggfddDrcmM6Aw/how-might-we-align-transformative-ai-if-it-s-developed-very#Potential_pitfall_2__advanced_collusion">卡诺夫斯基（Karnofsky，2022）</a>在谈论模型是否具有“索引目标”的相关性时所想到的就是这样的（尽管我认为“索引”一词的这种用法有些不标准）。</p><p>我不太清楚是否期望人工智能制定依赖于其个人身份概念的目标，但至少请注意，其目标将在模型经常被复制的环境中形成，在不同的集群上运行，等等（甚至有时在单个情节中）。这似乎与期望最终得到的人格认同的概念相关。 <a href="#fnref-ZB8uumQ8B94KMrTfP-2" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-3" class="footnote-item"><p>这一条只适用于培养圣人。 <a href="#fnref-ZB8uumQ8B94KMrTfP-3" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-4" class="footnote-item"><p>回想一下，上面我们假设模型能够准确地描述阴谋的工具价值。 <a href="#fnref-ZB8uumQ8B94KMrTfP-4" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-5" class="footnote-item"><p>然后，对于相关的授权实际上即将到来，相对于模型的其他选项等值得追求——根据上述“充分的未来授权”前提。 <a href="#fnref-ZB8uumQ8B94KMrTfP-5" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-6" class="footnote-item"><p>感谢 Nate Soares 对这些可能性的讨论。 <a href="#fnref-ZB8uumQ8B94KMrTfP-6" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-7" class="footnote-item"><p>在这里，我搁置了一些情况，即该模型对所赋予的未来目标几乎没有内在价值，而是致力于将它们作为某种合作安排的一部分赋予它们。我将在下面的 2.3.2.1 节中讨论此类情况。我还搁置了模型开始重视诸如“我的未来目标，无论它们是什么”之类的实现的情况 - 我将在下面的 2.3.2.3 节中讨论这一点。 <a href="#fnref-ZB8uumQ8B94KMrTfP-7" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-8" class="footnote-item"><p>尽管请注意此处的张力，即关于“<a href="https://www.lesswrong.com/posts/GNnHHmm8EzePmKzPk/value-is-fragile">价值的脆弱性</a>”和“<a href="https://www.lesswrong.com/posts/EbFABnst8LsidYs5Y/goodhart-taxonomy#Extremal_Goodhart">极端的古德哈特”的争论，</a>当受到极端的优化压力时，“效用函数”的微小差异可能会变得非常重要。 <a href="#fnref-ZB8uumQ8B94KMrTfP-8" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-9" class="footnote-item"><p>尽管在这里，“ <a href="https://www.google.com/url?q=https://www.lesswrong.com/posts/GNnHHmm8EzePmKzPk/value-is-fragile&amp;sa=D&amp;source=docs&amp;ust=1697834925680287&amp;usg=AOvVaw1jx98T1C27Jrw3cCwImg3y">价值的脆弱性</a>”和“<a href="https://www.lesswrong.com/posts/EbFABnst8LsidYs5Y/goodhart-taxonomy#Extremal_Goodhart">极端的古德哈特</a>”的版本也存在紧张关系。例如，如果在承受极端优化压力时，稍微不同的目标会导致超级不同的地方，并且人工智能预计相关目标会受到这种压力，那么仅进行微小的改变就很难导致折扣，而不是大部分风险价值的损失。 <a href="#fnref-ZB8uumQ8B94KMrTfP-9" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-10" class="footnote-item"><p>再次感谢 Nate Soares 在这里进行讨论。 <a href="#fnref-ZB8uumQ8B94KMrTfP-10" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-11" class="footnote-item"><p>尽管也许我们仍然需要担心我上面讨论的类型的“早期破坏”。 <a href="#fnref-ZB8uumQ8B94KMrTfP-11" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-12" class="footnote-item"><p> <a href="https://markxu.com/deceptive-alignment">Xu（2020）</a>给出了另一个例子：“如果一个模型的代理目标是‘吃苹果’，那么该模型可以使用 n * len(objective)/10，而不是在其他计算中使用硬编码的数字 n。因此，如果代理目标一旦改变，整个模型的许多计算都会失败。”另请参见<a href="https://www.lesswrong.com/posts/HpzHjKjGQ4cKiY3jX/3-levels-of-threat-obfuscation#Training_game_seems_very_likely_by_default__deceptive_alignment_much_less_so__gradient_hacking_still_less_so">Karnofsky（2023）</a> ：“它可能看起来像：‘人工智能系统根据一些有利于其目标的参考策略来检查自己的策略；差异越大，它就越会破坏自己的性能，结果是梯度下降很难使其策略偏离参考策略。 ” <a href="#fnref-ZB8uumQ8B94KMrTfP-12" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-13" class="footnote-item"><p>感谢保罗·克里斯蒂亚诺在这里进行讨论。 <a href="#fnref-ZB8uumQ8B94KMrTfP-13" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/LJpqnbgoaTJL6iMAf/the-goal-guarding-hypothesis-section-2-3-1-1-of-scheming-ais#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/LJpqnbgoaTJL6iMAf/the-goal-guarding-hypothesis-section-2-3-1-1-of-scheming-ais<guid ispermalink="false"> LJpqnbgoaTJL6iMAf</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Sat, 02 Dec 2023 15:20:28 GMT</pubDate> </item><item><title><![CDATA[The Method of Loci: With some brief remarks, including transformers and evaluating AIs]]></title><description><![CDATA[Published on December 2, 2023 2:36 PM GMT<br/><br/><p><a href="https://new-savanna.blogspot.com/2023/12/the-method-of-loci-with-some-brief.html"><i>从新稀树草原</i></a><i>交叉发布</i>。</p><p><a href="https://en.wikipedia.org/wiki/Method_of_loci">基因座法</a>是一种记忆技术，从古希腊和罗马一直到中世纪，一直到现代早期，至今仍在使用，尽管是零星的。我不想自己解释，或者强迫你阅读维基百科条目（尽管欢迎你这样做），我想我想让我的好朋友，Schoolmaster Chat 向你解释一下。之后，我将首先对为什么有必要进行一些观察，并以有关变压器的评论作为结束。</p><p><strong>基因座法</strong></p><p><strong>关于被称为基因座法的经典记忆技术，您能告诉我什么吗？</strong></p><p>轨迹法，又称记忆宫殿术，是一种可以追溯到古希腊和古罗马的经典记忆方法。这是一种记忆增强策略，涉及将您想要记住的信息与熟悉空间（例如建筑物或房间）中的特定位置相关联。 “位点”一词是拉丁语，意思是“地方”。</p><p>以下是位点方法如何工作的基本概述：</p><ul><li> <strong>1. 选择一个熟悉的环境：</strong>选择一个您非常熟悉的地方，例如您的房子、您经常走的路线或您熟悉的房间。这个地方将作为你的“记忆宫殿”。<br></li><li> <strong>2. 在脑海中漫游这个空间：</strong>在这个空间中进行思维漫游并识别特定的位置或地标。这些可以是家具、门、窗户或环境中的任何独特特征。<br></li><li> <strong>3. 将信息与位置相关联：</strong>将您想要记住的信息与您选择的空间中的特定位置相关联。创建生动且令人难忘的心理图像，将信息与每个位置联系起来。<br></li><li> <strong>4.在心里走遍空间：</strong>当你需要回忆信息时，在心里走遍你的记忆宫殿。当您到达每个位置时，相关信息应该浮现在您的脑海中。</li></ul><p>轨迹方法的有效性基于人脑记忆空间关系和位置的自然能力。通过将信息与特定位置联系起来，您可以创建一个思维导图，以便以后更轻松地检索信息。</p><p>这种技术已被古代演说家、学者和具有令人印象深刻记忆能力的个人所使用。它是记忆列表、演讲或任何顺序信息的强大工具。虽然可能需要一些练习才能掌握，但许多人发现它是增强记忆力的一种有价值且富有创意的方法。</p><p><strong>备注、变压器、评估 AI</strong></p><p>显而易见的问题是——为什么要这么麻烦呢？ – 有一个明显的答案 – 因为记住大量的东西是很困难的。为什么很难呢？就我目前的目的而言，只需说：因为这不是大脑的工作方式。为什么会这样，那是另一个问题了。心理学家花费了大量时间研究人类记忆，但我们不需要深究。</p><p>然而，我不会顺便说我们也发现算术计算很困难。哦，这些概念很琐碎。困难并不在于此。它是在计算行为中这些概念的实际应用。孩子们年复一年地被训练了好几个小时来进行这样的计算——尽管我希望现在不那么希望了，因为廉价的计算（更不用说计算机）可以很容易地完成这项工作。学会做，是的。这是一项重要的基本技能，重要的概念可以在此基础上运用。但无休止的练习，不再是必要的了。</p><p>这让我们想到了变形金刚。事实证明，让他们流利地进行多位数算术是一个有趣且具有挑战性的问题。并不是任何人都希望他们在实际应用中做到这一点，相反，坦率地说，研究人员正在试图了解他们的能力到底有多人性化。嗯，多位算术对于变形金刚来说很难，这一事实似乎使它变得非常人性化，不是吗？毕竟，在没有文字的文化中甚至不存在数字计算。它不像语言那样是我们生物天赋的一部分。</p><p>现在，变形金刚。我的第一点很简单：位点方法是如何工作的？一旦你建立了你的记忆宫殿，然后在其中储存了与你的信息的视觉关联，你就可以执行这个“程序”，如果你愿意的话，但从头开始一直走到结束。没有循环，没有分支，只有单一的回忆流。这就像 Transformer 产生的单一令牌生成流。</p><p>我的第二点是，你必须先设置好你的记忆宫殿，然后才能使用它。我认为这是预训练的第一阶段。完成此操作后，您就可以进入第二阶段，在该阶段中，您可以通过在宫殿中存放与您想要记住的物品相关的图像来专门用于特定用途。我认为将其与 RLHF 进行比较会有点推动事情的发展，但我在这里的目标并不是任何精确的东西。只是一封粗略的信件。</p><p>最后的一般性观察。几乎我读到的所有关于法学硕士的能力与人类能力的比较似乎都假设有一种东西就是人类的心理能力。不，没有。存在一种生物禀赋，但其性质尚不清楚。然而除此之外，还有相当多的文化修改和延伸。</p><p>好吧，猜猜看，就像算术不是我们天生的生物天赋的一部分一样，详细的逻辑推理或（复杂的）规划也不是。这些都是文化的延伸和阐述。这并不意味着我们有效的人工智能不必有能力做这些事情。当然，对于某些应用程序来说它们是必不可少的。但在评估人工智能是否已达到“人类能力”的过程中，例行公事地、不假思索地将这些能力纳入其中是愚蠢的。整个领域需要对人类行为有更复杂的理解，以便开始以明智的方式做出此类判断。如果没有这样的理解，<i>圣图灵的精神</i>就会盲目飞行。</p><p>稍后再说。</p><br/><br/> <a href="https://www.lesswrong.com/posts/sHojEwqNffanA2sEm/the-method-of-loci-with-some-brief-remarks-including#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/sHojEwqNffanA2sEm/the-method-of-loci-with-some-brief-remarks-include<guid ispermalink="false"> shojEwqNffanA2sEm</guid><dc:creator><![CDATA[Bill Benzon]]></dc:creator><pubDate> Sat, 02 Dec 2023 14:36:48 GMT</pubDate> </item><item><title><![CDATA[Taking Into Account Sentient Non-Humans in AI Ambitious Value Learning: Sentientist Coherent Extrapolated Volition]]></title><description><![CDATA[Published on December 2, 2023 2:07 PM GMT<br/><br/><p>我在<i>《人工智能与意识杂志》</i>上发表了一篇论文，内容是关于如何在 A(S)I 价值调整中考虑非人类动物和数字思维的利益。</p><p>论文的发布版本请参见： <a href="https://www.worldscientific.com/doi/10.1142/S2705078523500042">https://www.worldscientific.com/doi/10.1142/S2705078523500042</a></p><p>有关论文最终草案的 pdf 格式，请参阅： <a href="https://philpapers.org/rec/MORTIA-17">https://philpapers.org/rec/MORTIA-17</a></p><p>下面我复制粘贴了论文的正文，对于感兴趣的人，请引用已发布的版本： <a href="https://www.worldscientific.com/doi/10.1142/S2705078523500042">https</a> ://www.worldscientific.com/doi/10.1142/S2705078523500042</p><h1>概括</h1><p><i><strong>摘要</strong></i><strong>：</strong>雄心勃勃的<a href="https://www.lesswrong.com/tag/value-learning">价值学习</a>建议旨在解决人工智能对齐问题并避免未来可能出现的未对齐<a href="https://www.lesswrong.com/tag/superintelligence">人工超级智能</a>（例如<a href="https://www.lesswrong.com/tag/coherent-extrapolated-volition">相干外推意志</a>[CEV]）造成的灾难性后果，其重点是确保人工超级智能（ASI）将尝试做人类的事情会想要它这样做。然而，现在和未来的有感知能力的非人类，例如非人类动物和未来可能的数字思维，也可能以道德相关的方式受到 ASI 行为的影响。本文提出了Sentientist Coherent Extrapolated Volition，作为CEV的替代方案，直接考虑到所有众生的利益。这个雄心勃勃的价值学习提案将大大降低 ASI 行为造成<a href="https://www.lesswrong.com/tag/risks-of-astronomical-suffering-s-risks">天文数字损失的风险</a>的可能性，因此我们有非常强烈的道德理由支持实施它而不是 CEV。这一事实对于在不同的雄心勃勃的价值学习提案之间进行充分的成本效益分析至关重要。</p><p><strong>关键词：</strong> <i>&nbsp;</i>一致性问题 · 一致的外推意志 · 痛苦风险 · 感性主义 · 数字思维 · 非人类动物</p><p>除了人类之外，非人类动物，还有有感知力的数字思维都可能受到未来人工智能系统行为的非常负面影响。这让我们有理由在决定如何设计此类系统时考虑他们的利益。在本文中，我特别关注连贯外推意志，但我提出的许多考虑因素也可以应用于其他雄心勃勃的价值学习提案。</p><p>沿着这些思路进行更多的研究，认真考虑（1）人工智能对未来的影响以及（2）非人类动物和未来可能的数字思维的道德考虑，如果我们想要关键决策者这样的作为人工智能公司或政府，应充分了解如何确保强大的人工智能系统的开发安全并造福于所有众生。</p><h1>一、简介</h1><p>超级人工智能（ASI）（或通用人工智能）的发展带来了严重的生存风险和痛苦风险（Bostrom，2014；Yudkowsky，2008；Sotala &amp; Gloor，2017；Tomasik，2015a；Baumann，2017a）。为了防止此类灾难，我们必须解决对齐问题。我们必须确保（如果我们这样做）我们创建的第一个 ASI 具有某些值，这样它就不会导致这些结果，并且能够实现我们想要的结果。值规范问题是这是更一般的对齐问题的一部分（Gabriel，2020；Christian，2020）。这是将 ASI 与什么值对齐的问题，也是本文关注的重点，而不是其他更技术性的问题（例如内部对齐）。</p><p>在关于应在第一个 ASI 中实施哪些价值观以防止灾难性后果的讨论中，非人类有感知的生物，例如驯养的非人类动物、野生动物和未来可能的有感知的数字思维，通常被忽视。然而，所有众生都很重要，任何价值学习提案也应考虑非人类众生的利益。</p><p>在本文中，我认为，在未来，如果我们能够实施一些标准的雄心勃勃的价值学习提案或直接考虑有感知力的非人类利益的替代价值学习提案，我们将拥有强大和<i>非常</i>强大的赞成后者的道德理由。然而，在实践中，正如第 5 节所述，尚不完全清楚哪种雄心勃勃的价值学习提案最适合尝试实施。我转向连贯外推意志（CEV）的例子，这是最流行的雄心勃勃的价值学习提案之一，并认为它并不理想，因为（至少）有一个足够不可忽视的机会，因为没有充分包括所有有情众生，它可能会因 ASI 自身的行为而导致天文数字般的灾难风险。虽然在这里我只关注 CEV，但与我在这里使用的类似的论点也适用于许多其他雄心勃勃的价值学习提案，我可能会在未来的研究中讨论和分析其他雄心勃勃的价值学习提案。</p><h1> 2. 为什么相干外推意志的标准提议版本有问题<strong>&nbsp;</strong></h1><p><i>连贯外推意志 (CEV)</i>是 Eliezer Yudkowsky 的价值学习建议，它将在 ASI 中实现我们（人类）同意的目标，即在更理想的情况下，如果给予更长时间的思考，我们会希望实现这一目标（Bostrom，2014）。也就是说，我们（人类）希望“如果我们知道得更多，思考得更快，成为我们希望成为的人，一起成长得更远；外推法趋同而不是发散，我们的愿望一致而不是干扰；按照我们希望的方式推断，按照我们希望的方式解释”（Yudkowsky，2004）。有关充分相干外推所需的理想环境的更详细解释，请参阅（Yudkowsky，2004）。包括（Yudkowsky，2016）在内的一些人可能会认为，事实上，如果 ASI 应该考虑非人类众生的利益，那么这足以充分考虑他们的利益。同样，也有人认为，动物的福祉也包含在人类的偏好中，再加上 ASI 的不那么短视的决策（与人类决策相比），可能就足够了（Russell，2019） ）。也有人认为，人类应该建立一个直接关心有感知力的非人类利益的 ASI 可能很难维持，因为那时它会比人类实际做的事情更关心他们（Russell，2019）。根据这些观点，如果确实如此，<i>如果</i>人类在理想情况下有更多的时间思考，就会有充分考虑他们的利益的目标，那么通过连贯地推断人类的意志，ASI 将考虑到有知觉的非人类的利益。我认为这个答案对于我们来说还不够令人满意，如果我们能够这样做的话，我们没有充分的理由尝试将有感知力的非人类的利益直接纳入 ASI 的目标。</p><p>有人似乎有理由认为，对于任何价值学习提案，该提案的某些方面不能留给 ASI 来解决，例如“地位，涉及谁的道德观点[或道德相关利益]”；衡量，关于如何识别他们的观点[或道德相关利益]；和聚合，涉及如何将个人观点[或道德相关利益]组合成指导人工智能行为的单一观点”（Baum，2020）。正如人们所争论的那样，对齐问题本质上具有规范性的组成部分，可以使用不同类型的技术解决方案将某些值加载到未来 A(S)I 的奖励函数中，这可能对我们到底要使用什么样的值产生不同的影响。可以实施，因此，“没有办法完全‘排除’规范性问题”（Gabriel，2020）。最终，可能成为 ASI 的 A(G)I 的设计者无法回避面临道德决策，即他们以什么方式、什么以及谁的价值观或道德相关利益纳入 ASI 的目标。我认为，我们应该认真对待尤德科夫斯基的流行提议没有充分考虑与有感知的非人类的道德重要性有关的道德考虑的可能性。</p><p>尽管标准 CEV 提案充分避免了直接指定指导 ASI 行为的价值观（因此似乎避免了实质性的价值锁定），但它仍然指定了哪些众生的意志可以连贯地推断出来。标准提案仅包括目前存在的人类。从这个意义上说，标准CEV提案排除了所有其他众生，并对长期存在的问题给出了具体的答案。我认为，有非常充分的理由表明，CEV 针对现有问题提出的标准解决方案在道德上比更加考虑所有众生利益的雄心勃勃的价值学习提案更不受欢迎。从现在开始，我将在第 3 节中将这种替代提案进一步发展为<i>Sentientist 连贯外推意志 (SCEV)</i> 。</p><p>在第 2.1 节中，CEV 将有感知力的非人类的意志排除在外推基础之外。我将说明为什么仅仅排除他们是不合理的，就像排除人类群体是不合理的一样。如果我们能够做到的话，这本身就给了我们实施 SCEV 而不是 CEV 的强烈道德理由。然而，在第 2.2 节中。我认为我们有<i>非常</i>充分的道德理由这样做。标准 CEV 提案的充分实施导致 ASI 导致或允许天文灾难风险（s-风险）发生的可能性（至少）不可忽略。这些事件的风险会带来巨大的痛苦，远远超过迄今为止地球上存在的所有痛苦（Sotala &amp; Gloor，2017；Althaus &amp; Gloor，2016）。这里的“重大”是指相对于预期的未来苦难而言（Althaus &amp; Gloor，2016）。考虑到 s 风险的坏处，这种不可忽略的概率足够大，使得 CEV 成为比 SCEV 更不受欢迎的价值规范问题解决方案。</p><p>重要的是要注意并记住，我在本节和整篇论文中提出和讨论的支持 SCEV 的理由是赞成的，因为（如第 5 节中所讨论的）它们可能会被推翻或击败反对实施 SCEV 的其他赞成理由。因此，考虑到所有因素，尝试实施 SCEV 而不是 CEV 是否是正确的选择可能尚不清楚。</p><h2> 2.1.为什么我们有强烈的道德理由实施 SCEV 而不是 CEV：与 CEO-CEV 和 men-CEV 的类比</h2><p>为了了解为什么将有感知力的非人类排除在外推基础之外是不合理的，我们可以看看不同的替代（和虚构的）CEV 提案。以<i>CEO-CEV</i>提案为例：仅应用CEV的提案，即仅连贯地推断首先开发ASI或AGI的研究实验室的CEO的意愿。或者，例如，采用仅连贯地推断男性意志的<i>男性 CEV</i>提案。如果我们可以选择实施其中任何一项，那么与 CEV 相比，这些显然是在道德上更不受欢迎的雄心勃勃的价值学习建议。我们有充分的理由反对仅仅连贯地推断一小部分人类的意志，因为这不能代表整个人类。反对追求诸如雄心勃勃的价值学习提案之类的路径（如果存在实施正常 CEV 的可能性）的最合理的理由可能是，这些提案显然（至少）有足够大的不可忽略的概率导致 ASI 的行为对未直接包含在 CEV 外推基础中的人类产生负面影响。非男性的人或与人工智能实验室首席执行官的偏好有很大不同的人可能会发现自己处于后 ASI 世界，他们的利益没有得到充分考虑，并因此遭受负面后果。他们的利益可能会被严重忽视，因为他们的利益只存在于 ASI 的效用函数中，达到人们或人工智能实验室的首席执行官在理想情况下对他们进行充分考虑后对他们的关心程度。</p><p>尽管有可能，如果人工智能实验室的首席执行官或人员在理想条件下有足够的时间思考，那么，他们会像他们一样平等地考虑外推基础之外的人的利益，我们仍然会不接受这些建议，因为与正常的 CEV 相比，这些建议对于雄心价值学习的充分建议。因为有足够的可能性证明这种可能性并非如此。虽然这些价值学习建议可能比在 ASI 中不实施任何价值观更好，但它们比 CEV 差得多，因为它们有足够大的不可忽视的可能性，它们会给被排除在外推基础之外的人带来重大负面后果在每种情况下。这将使我们有充分的理由在决策情况下排除 CEO-CEV 和 men-CEV，在这种情况下，我们也可以选择实施考虑到所有人的正常 CEV 提案。</p><p>我认为，出于类似的原因，与 SCEV 相比，CEV 也是一个不充分的提议。正常的 CEV 提案，如 CEO-CEV 和 men-CEV，将道德患者的子集排除在外推基础之外。它排除了所有有知觉的非人类。和前面的例子一样，如果 CEV 得到充分实施，有感知力的非人类的利益只会存在于 ASI 的效用函数中，并且只有在人类考虑足够多的情况下才会考虑到他们的关心程度关于他们在理想情况下的情况。有感知力的非人类是道德患者，他们可能会受到道德上不良的影响，就像前面例子中被排除在外推基础之外的人一样。这种情况的发生可能仅仅是因为他们的利益对于外推基础中的个人来说不够重要，即使他们在理想情况下有足够的时间考虑这一点。这就是为什么如果我们能够做到这一点，我们将有强烈的道德理由来实施SCEV，而不是实施CEV：这是一个充分考虑了所有众生利益的提议。下面，在第 4 节中，我提出了两种可能的反对意见，这些反对意见认为排除其他人类和排除有感知力的非人类之间存在相关差异。</p><h2> 2.2.为什么我们有非常强烈的道德理由实施 SCEV 而不是 CEV：显着降低天文灾害的风险</h2><p>我们不仅有<i>充分的</i>道德理由来实施 SCEV 而不是 CEV。还有进一步的理由相信，实施 CEV 与 SCEV 之间的预期负面后果差异远大于实施 CEO-CEV 或 men-CEV 与 CEV 之间的预期负面后果差异。如果我们能这样做，我们就会有更紧迫的理由以 SCEV 而不是标准 CEV 提案为目标，而不是我们必须以标准 CEV 提案而不是 CEO-CEV 或 men-CEV 为目标。那么，如果我们能这样做，我们就有<i>非常</i>强烈的道德理由来实施 SCEV 而不是 CEV。</p><h3> 2.2.1.对有感知力的非人类更缺乏道德考虑<i>&nbsp;</i></h3><p>任何特定的人类群体（没有任何特定的心理社会条件）如果在理想情况下有足够的时间思考，那么他们很可能会更加关心其他人的利益，而不是所有人类都会关心的程度如果所有有知觉的非人类有足够的时间在理想的情况下思考的话，他们的利益就会得到满足。在第一种情况下，外推基中的人类对外推基外的人类给予的考虑可能比在第二种情况下所有人类对外推基外的有感知力的非人类给予的考虑要多得多。根据。</p><p>当然，我们不能确定情况确实如此，因为我们并不具体知道在实践中如何连贯地推断任何人类子集或所有人的意志。我们不确定，如果在更理想的情况下，如果给予更长的时间思考的话，任何一部分或全部人类会同意他们想要什么。然而，对于不同类型的 CEV 产生哪些结果的可能性或多或少，我们并非无话可说。确实，我们可以说点什么。例如，人类往往会更多地考虑那些与他们最亲近且更相似的人（Caviola et al., 2018; Dhont, Hodson, &amp; Leite, 2016），这可能会影响在一个环境中连贯地推断意志的过程。对于有感知力的非人类来说是消极的方式。这是因意义）对人类来说比对其他人来说更重要。</p><p>此外，我们还应该更新这样一个事实，即（至少部分地）由于没有平等地考虑所有众生的利益，现在和过去，人类已经杀戮并给无数的人造成了巨大的难以忍受的痛苦。大量非人类众生从味觉愉悦中获得的利益几乎可以忽略不计。为了了解我们应该对这一事实进行多少更新，想象一下人工智能实验室的首席执行官或人员对每种情况下被排除在外推基础之外的人类造成巨大痛苦的可能世界。并且这样做的数量与人类在这个世界上给其他动物造成的痛苦成正比。想象一下，他们是通过在每种情况下折磨外推基外的人类来做到这一点的。想象一下，就像人类对待工厂出名的非人类动物一样，它们给外推基地之外的人类带来了终生难以忍受的痛苦，甚至在他们成年之前就杀死了几乎所有的人。在这些可能的世界中，我们有更多的理由相信，实施 CEO-CEV 或 men-CEV 更有可能导致比我们预期在现实世界中产生的后果更糟糕的后果。类似地，似乎更有可能的是，在这个世界上，在一个人类心理（至少部分地）导致人类对其他非人类有情生物犯下暴行（例如工厂化农业）的世界中，另外，CEV 的标准提案对非人类众生造成的负面后果比我们人类心理在对其他众生实施暴行时没有发挥作用的世界中要多。</p><h3> 2.2.2.最坏结果的性质和不同类型：天文数字般的痛苦风险<i>&nbsp;</i></h3><p>正如我们所看到的，随着标准 CEV 提案的实施，有感知能力的非人类的利益（至少）有一个不可忽视的可能性会被 ASI 高度忽视。并且这种可能性（无论它是什么）高于在 ASI 控制的未来中，不包括在外推基础中的人类的利益被高度忽视的可能性，在未来，只有某些人类的意志被连贯地外推。一个拥有 ASI 并具有上述任何一种雄心勃勃的价值学习建议的文明很可能（至少在某种程度上）想要扩大和定居空间，并利用先进的人工智能和模拟技术。在这样一个未来，有感知力的非人类的利益将被高度忽视，有感知力的非人类很可能会因为人类想要采取的行动以及 ASI 可能采取的行动而遭受天文数字般的损失。遵循他们的 CEV。</p><p>野生动物的痛苦可能会通过这种文明传播到整个宇宙。这可能是直接的生源论或故意改造行星的结果，因为人类的一些价值观是在宇宙中传播生命或为了他们对自然的审美享受（Tomasik，2018；O&#39;Brien，2021）。但如果没有采取预防措施，这种情况也可能是由于太空飞船净化不充分而发生的，这可能导致一些微生物或其他生物体被意外地运送到其他行星，这可能会在多年的过程中导致出现这些行星上有感知生命形式。因为在这些未来非人类动物的生活中，痛苦可能会非常普遍，甚至可能占主导地位，就像目前生活在自然界中的非人类动物的大多数生活一样（Ng，1995；Groff &amp; Ng， 2019；Tomasik，2020；O&#39;Brien，2021）如果这种情况发生，可能会导致天文数字般的痛苦。</p><p>具有 ASI 的文明考虑到部分或全部人类的利益，但不考虑有感知力的非人类的利益，也可能会大量利用先进的人工智能和模拟技术。这可能有意或无意地导致天文数字般的痛苦。忽视人工感知形式的兴趣的 ASI 可能会意外地创建大量的感知子例程。这些是 ASI 程序和结构内具有重要价值的功能、子程序、机器人监督员、机器人科学家或子代理（Tomasik，2019a）。同样，现象经验和承受痛苦的能力的出现似乎在指导行为方面具有进化上的作用，它也可能有助于 ASI 控制其内部过程的行为以实现其目标。通过经历复杂的优化过程，ASI 可能会像自然选择一样，对痛苦的创造进行评估，这是一个优化基因繁殖的复杂过程（Sotala &amp; Gloor，2017）。</p><p>此外，实施 CEV 且高度忽视有感知力的非人类利益的 ASI 控制的文明也可能导致心灵犯罪，即在模拟中创造大量数字心灵，包括受苦受难的心灵。它可能会出于研究目的对过去的人类历史、自然环境或未来可能的进化路径进行大量的祖先模拟（Bostrom，2014，第 125-26 页；Sotala &amp; Gloor，2017）。在许多这些中，如果模拟足够详细和复杂，“人类”数字思维和野生或驯养非人类动物的数字思维可能会出现，从而增加野生动物的痛苦和工厂化养殖的主观体验（Tomasik， 2015b；鲍曼，2017a)。它还可以有意地创建或允许其他人有意地创建具有特别显着的痛苦的模拟，以供娱乐或满足虐待狂的偏好。在想要探索所有可能的心灵空间时，它也可能会尝试模拟与我们相比的各种不同的遥远的、奇怪的和外星的感知形式（Tomasik，2015b）。任何此类非人类有情生物都可能大规模存在，并且他们的利益被 CEV 联盟的 ASI 掌权者忽视，这会加剧天文数字灾难的风险。</p><p>而且，正如其他地方非常有道理地争论的那样，“几乎所有合理的价值体系都希望避免痛苦风险，对于许多价值体系来说，痛苦风险是最糟糕的可能结果，因此也是最需要避免的风险”（Sotala和格洛尔，2017）。在任何认为防止不希望的和剧烈的痛苦非常重要的价值体系中，防止天文数字般的不希望的和剧烈的痛苦将是极其重要的。那么，这些结果的可能性不一定非常高，因为预防它们就非常重要。如果 S 风险发生的可能性不可忽略或较高，那么减少它仍然具有重大的道德重要性，因为它们的发生在道德上是极其不受欢迎的。</p><h3> 2.2.3.为什么（即使不考虑对其利益的高度漠视）有感知力的非人类更有可能成为 s 风险的受害者<i>&nbsp;</i></h3><p>由于生物人类与有感知力的非人类存在种类的差异，即使不是有感知力的非人类更容易被忽视，但有感知力的非人类更有可能被忽视。相比于实施CEO-CEV或男性-CEV而无视自身利益而被排除在外的人类，实施无视其利益的CEV所造成的伤害要大得多。之所以如此，是因为对有感知力的非人类造成天文数字的痛苦比对被排除在外的（生物）人类造成天文数字的痛苦更容易。</p><p> ASI 可能会导致造成天文数字损失的行为，也可能允许其他因素采取导致天文数字损失的行为。在这两种情况下，无论该行动是由 ASI 还是由其他特工执行，该行动导致天文数字般的痛苦的事实或多或少可能是故意的。当导致天文数字痛苦的行为是最大程度的故意时，执行这些行为的主体想要造成天文数字的痛苦，当这些行为是最大程度的无意识时，主体甚至不知道他们正在造成天文数字的痛苦。在这种有意性和无意识行为规模的中间区域，有些情况下，代理人知道他们正在造成天文数字的痛苦，但为了实现其目标仍采取行动，并且有些情况下，代理人不确定他们是否正在造成天文数字般的痛苦，但仍然采取行动。许多有感知能力的非人类都具有一些特征，使他们更有可能、更容易地忍受天文数字般的痛苦。被排除在CEO-CEV或men-CEV之外的生物人类缺乏这些特征，因此他们更难成为天文数字苦难的受害者。以下是一些相关差异：</p><p> ●<i>复制或复制的资源效率：</i>与维持受苦的人类所需的资源相比，复制受苦的数字思想所需的资源相对于维​​持它们所需的资源来说，似乎要少得多（Sotala，2012） ；舒尔曼和博斯特罗姆 2021）。与（生物）人类相比，这使得造成天文数字灾难的代理人更有可能有意复制数字思维，并且更容易无意中复制数字思维。</p><p> ●<i>缺乏维持受苦人口的干预：</i>维持受苦的数字思维群体或生活在自然界中的（生物）非人类动物所需的干预似乎比受苦的（生物）人类群体要少。在前一种情况下，造成天文数字痛苦的行为者可以让痛苦无限期地持续下去（无论是有意还是无意）。在后一种情况下，自然选择、捕食和生殖策略中的重新选择过程在没有监督和缺乏干预（有意或无意）的情况下继续进行。然而，在生物人类的情况下，需要更多的干预，以防止他们试图控制导致他们痛苦的事物，防止他们试图利用资源来减少生活中的贬值，增加生活的价值，并防止他们试图通过停止繁殖或自杀来停止存在。</p><p> ●<i>某些情况下痛苦存在的不确定性：</i>在上述情况下，行为人不确定自己是否造成了天文数字般的痛苦，但仍然采取了行动，如果他们知道自己正在造成痛苦，他们可能不会选择以这种方式行事天文数字般的痛苦。比给定（生物学的）人是否遭受痛苦的<i>某些</i>动物（可能会继续）（<i>可能</i>会继续）是否遭受痛苦。后者可能能够传达这一事实并更像我们，因此在造成痛苦的代理商的情况下，不太可能成为受害者，这不确定他们是否这样做。</p><p>所有这些因素以及（生物）人类（生物）人类被忽略的可能性较小，这使其成为S风险的受害者的可能性大大降低，而不是将来的非人类的受害者成为这种受害者由ASI控制的，具有雄心勃勃的价值倾斜建议，并没有直接连贯推断其意志。</p><p>总之，有两种方法可以证明为什么我们有迫切的理由来实施雄心勃勃的价值学习建议，例如SCEV，而不是标准的CEV提案，如果我们能够这样做。一方面，就像有强烈的道德理由可以实施CEV，而不是关于雄心勃勃的价值学习的建议，例如CEO-CEV或MEN-CEV，也有强烈的道德理由可以实施SCEV而不是CEV。另一方面，由于（至少）不可忽略的机会，即有知情的非人类利益被带有标准CEV提案的ASI高度忽视，并且在这样的未来，在这种情况下高度忽略了，很有可能有可能遭受S风险，（至少）不可忽略的有机会实施标准CEV提案的实施会导致自动从ASI的无性非人类的S风险导致S风险行动。由于S风险是最糟糕的结果，并且在合理的规范性观点下，在道德上是不可取的，因此即使是（至少）不可忽视的机会，它们的发生的机会也非常糟糕。然后，如果有更好的替代方案，则不包括当前和将来的众生大多数的标准CEV提案在道德上是非常不可取的。由于实施某些雄心勃勃的价值学习（我将在下一节中所说的，因此，可以通过实施对价值规范问题的真正有意义的解决方案，从而大大降低了SS风险的可能性增加。</p><h1> 3.雄心勃勃的价值学习的另一种自然主义者的建议<strong>&nbsp;</strong></h1><p>在这里，我将提出与CEV的雄心勃勃的学习替代品的雄心勃勃的价值学习替代品。该提案包括连贯推断所有当前现有和未来众生的意志。也就是说，将所有道德患者包括在CEV的外推基础中。</p><p><i><strong>有知识主义者连贯的推断性意志</strong></i>：实现所有人（IE现在和将来）有众者的目标是在更理想的情况下，他们希望他们想要更长的时间（如果给予更长的时间）。</p><p>即使这是非常雄心勃勃的，但标准的CEV提案也是如此，即使少了一点。而且，如果标准的CEV提案本质上可行，我认为没有理由相信该提案也不是内在的。为了实现标准的CEV提案，必须确定人类的欲望，如果我们知道更多，思考得更快，更多的是我们希望我们曾经和长大的人，以及其他事情（Yudkowsky，Yudkowsky，Yudkowsky， 2014）。如果我们拥有与当前拥有的功能不同的功能，这将需要确定我们想要什么。如果我们在许多方面具有超人能力，例如，例如，除其他方面，我们都必须确定我们将重视的内容，而不是受认知偏见的影响，并且能够处理和理解更多的数量和不同的信息（Yudkowsky，2014年） 。</p><p>具体而言，这将或可能包括（除其他外）创建一个“每个人的详细模型”，以尽可能多的详细信息猜测，以猜测由“知道更多”，“更快的思想”定义的意志性驱除转换类别， ETC。” （Yudkowsky，2004年）。目的是近似和理解如果要进行自愿驱除升级（例如了解更多和更多的思考时间），则每个思想都会发生的理想化变化。重要的是要了解，该提议不是要通过ASI直接在外推基础中直接进行外向的个人来直接执行推荐的升级，从而通过物理上干预他们的大脑。相反，该建议将是对ASI将产生的外推基础所有个体的详细模型进行这些更改。 CEV和SCEV都没有提出，意志升级升级直接在外推基部的个体的思想上进行。这只会导致所有人（人类和非人类）突然，直接升高，并增强到与ASI相似的认知能力水平。一旦ASI生成了每个思想的足够详细的模型，并且已经对每个模型进行了自愿驱除升级，它们所致的连贯偏好将是指导ASI行为的偏好。</p><p>如果使用更先进的技术，这些特定的过程原则上是可行的，并且在人类的思想中可以理解，那么它们也很可能也可以用更简单的头脑来完成，例如许多非人类动物的思想。而且，我们至少可以对这些理想化的变化对可能的未来数字思维的外观具有比零更高的概率近似是合理的。然后，如果在理论上可以相干推断人的意志所需的过程，那么这也可能是有意义的非人类的意志。即使我们在实践中无法达到完全理想化的外推状态，或者与（人类和非人类和非人类）意志之间有着完全连贯的状态，但相关的是，我们尽可能接近实现这些目标。这样做比没有导致意志之间的任何一致性并且根本无法推断意志的提议更可取。</p><p>所有现在和未来的众生，包括人类，包括驯养和未驯化的非人类动物以及可能的未来数字思维，都可以实现目标。至少，从最广泛的意义上讲，他们有渴望和偏好具有积极的现象经历，并且没有消极的经验。他们中的许多人可能的目标可能比这些目标更丰富，更复杂。所有这些目标构成了他们每种意志的一部分，这些意志可以并且应该连贯推断。原则上，即使许多有知情的非人类具有某些认知能力的程度比人类通常具有的认知能力，也可以将其推断为外推。之所以如此，是因为与人的意志一样，我们还可以（除其他事项）确定在对它们进行自我击倒转换时发生不同种类的非人类思想的变化。即使许多有知情的非人类没有能力进行某些类型的抽象思维或反思其价值观，人类也没有确定其外推力内容所需的能力。在这两种情况下，自愿变换都将增强有知情人类和非人类的能力，以充分确定其外推力的含量。</p><p>在建模如果将自愿变换转换应用于现有非人类动物的意志，例如松鼠（例如松鼠），则会发生偏好的变化，SCEV可能会达到具有怪异偏好的外推力模型。我们目前不知道它们会是什么样。但是，这还不足以表明我们不应在外推基部中包括松鼠或其他非人类。实际上，有人认为，有充分的理由可以将非人类动物的（认知）能力（至少）提升到大多数人类出于民主原因（Paez＆Magaña，2023年）的水平（至少比大多数人类的水平），因为罗尔西亚自由主义的理由（Dvorsky 2008）和反种族主义的原因（Chan，2009年）。而且，正如我将在第4.3节中提出的那样。我们没有充分的理由相信实施SCEV或增强其功能会导致它们不再存在，而是可以在保留其身份的同时完成（Paez＆Magaña，2023年）。此外，正如我在第4.1节中所显示的那样。令人难以置信的是，在外推基础中包括非人类动物可能会导致我们受到其外推的奇怪偏好的伤害。因此，由于不包括它们，我们可能会增加天文痛苦的风险，因此我们有强烈的理由这样做，即使我们高度不确定其外推力的内容。</p><h2> 3.1.解决常规问题的解决方案<i><strong>&nbsp;</strong></i></h2><p>由于如上所述，我们不能将解决方案（在推断基地中包括在内的利益或意志的问题）解决问题，因此我们应该在自己做出这样的决定时考虑不确定性。与确定应在道德上考虑哪些实体有关的是什么，因此也以某种方式将其包括在外推基础中，不是我们是否可以确定它们是否具有道德患者的相关特征。反对尤德科夫斯基（Yudkowsky）争辩的事实，事实是，对于特定实体是否应有的道德考虑可能是错误的，这不是一个充分的理由，将它们排除在我们的道德考虑或构成外推基础之外的理由（Yudkowsky，2016年）。取而代之的是，相关的是，是否存在不可忽略的机会，它们具有道德患者的相关特征。之所以如此，是因为如果我们的行为有可能以道德上相关的方式伤害一个给定的实体，那么执行其他所有行动都是错误的。因为伤害的机会比没有伤害更糟糕。因此，与确定应在道德上应考虑哪些实体的相关是相关的是，是否有不可忽略的机会是有知觉的（Sebo，2018）。此外，正如我们已经看到的那样，被包括在外推基准中是否可以直接影响（预期）（预期）ASI行为尊重并考虑到给定生物的利益的程度。然后，所有的实体都有不可忽视的机会，它们应包括在外推基库中。我们有非常有力的理由相信，至少有一个不可忽视的概率是，几乎所有现在和未来的人，非人类动物以及可能的未来数字思维都是道德患者，因此应直接包含在外推基础中。这是由于三个主要原因。首先，关于脊椎动物和许多无脊椎动物动物的感知有广泛的共识和有力的证据（Low，2012; Proctor等，2013;“通用动物福利宣言”，2007年； Waldhorn，2019a； 2019a； Waldhorn，2019b，2019b），2019b）并且有广泛的同意，即将在将来创造或可以创造出具有感知能力的人工实体（Harris＆Anthis，2021）。其次，从上面理解为具有积极或负面评价的现象意识经历的能力的能力被广泛认为并被接受为道德患者的足够条件（Clarke，S.，Zohny，H。＆Savulescu，J。，2021年） 。第三，也是如此，似乎非常合理，并且也广泛认为，好东西或坏事的内在价值或尊重和考虑道德患者的利益的内在道德重要性不能仅仅因为出现而折现将来，请参见（Greaves＆Macaskill，2021：P.18； Ord，2020：P.52； Beckstead，2013：P.18），以了解文献中这种观点。然后，所有现在和未来的实体（至少）不可忽略的机会应直接包括在外推基地中。</p><h2> 3.2.如何包括未来不尚有遗物的推断意志<i><strong>&nbsp;</strong></i></h2><p>根据SCEV的说法，除了当前现有的众生之外，所有未来的众生都应将其意志直接包含在外推基地中，从那以后，ASI行动中S风险的可能性将大大降低。但是，如何将未来不存在的众生的意志直接包含在外推基础中？在任何给定的时间<i>t</i> ，ASI应采取最能够实现<i>T</i>中所有有源的人的连贯推断的意志的行动。在这种情况下，ASI可以或将采取的许多（几乎是所有）行动将改变其执行给定动作后将存在的种类和数量。由于这一事实，在任何给定的动作之后，ASI必须将新的现有众生的推断性意志纳入，如果有的话，然后决定如何基于当时所有现有生物的相干外推力再次采取行动及时。</p><p>重要的是要意识到，关于如何考虑未来不存在的众生的其他建议可能会带来灾难性的后果。例如，想象以下更为简单的提议：ASI应采取那些最能满足所有期望的行动，以实现所有众生的连贯的推断意志，这些意志在其行动后将存在。如果要实施此建议，则可能会导致公用事业功能的奖励黑客入侵。如果ASI的效用函数是最大化所有在行动后可以预期存在的有情存在的相干推断的意志实现，那么ASI可以创造许多具有非常简单的外推意志来满足的数字思维。如果ASI的行动创造了足够多的此类数字思维，那么其推断意志的力量可能大于许多数量级，而不是当前现有的人类和非人类动物的外推力的力量大量的力量，以指导ASI ASI的动物行为。这可能会导致ASI无视人类和非人类动物，并且只能执行最满足创造数字思维易于满足的偏好的动作。这些易于满足的偏好不必是任何方面对我们（也不对我们的推翻意志）看似有价值的偏好。关于如何将未来不存在的众生包括在外推基地中的替代建议可能会导致非常不受欢迎的结果。它是天真的和有缺陷的，因为在任何给定的时间点，它都可以使ASI本身确定出现了哪些新的众生（独立于已包含在内的个体的外推力的偏好）。与此相反，根据我提出的提议，出现了哪些有意义的生物，一旦存在，就可以通过纳入ASI的行为来塑造ASI的行为，这完全取决于当前包含的个人的外推力的偏好。由于推断的意志将知道SCEV的工作原理，因此他们会意识到，在偏爱某种动作或其他行动时，他们也更喜欢创造某些思想或其他人。此外，他们还会意识到，一旦它们存在，它们将被包括在外推基础中，从而影响ASI的行为。然后，推断出的意志比执行动作更了解，导致场景类似于这种场景，即已经创建了具有宝贵且易于满足的偏好的大量数字思维，并对ASI的行为完全控制了。因此，在原始提案中，我坚持，奖励黑客被阻止了。</p><p>该提议将充分考虑到未来众生的利益，因为一旦开始存在，它们的利益将直接包含在ASI的公用事业职能中。与标准CEV提案中似乎是这种情况相反，未来不存在的众生的利益一旦存在，就不会仅考虑到当前现有个人的推断意志的程度，这样做。而且，通过直接考虑以这种方式的未来有知情的非人类的利益，由于对标准CEV提案的适当实施，ASI行动中S风险的不可忽视的机会将大大减少。</p><p>实施SCEV时，SC风险从ASI的行为中降低了大大降低S风险的人类受害者。相反，有意义的非人类本身的天文数量将直接包括在外推基部。在此提案上，（至少）人类推断的意志仍需要（至少）不可忽略的机会，他们希望采取（不进一步干预）导致S风险（例如直接panpermia）或使用模拟技术的行动。结果，ASI实际上仍然有可能执行此类动作。但是，一旦他们进行了进行，一旦生活在其他行星或数字思维的“自然”环境中的非人类动物等新的众生中，它们的外推力将直接包含在外推基地中。而且，由于他们的意志将极大地反对苦难，因此，ASI几乎可以肯定会防止天文痛苦。一旦将成为S风险的受害者成立，他们对不苦难的利益将直接考虑在ASI的行为中。 ASI几乎可以肯定会阻止天文痛苦，并且与外推基地中已经存在的任何其他生物一样，它将尝试实现新现有生物的推断意志。如SCEV所建议的那样，如果将未来的非人类意志包括在外推基础中，那么从ASI的行动中出现S风险的出现（即它所引起或允许的允许）几乎是不可能的。因此，我们有非常有力的亲塔托道德理由来实施SCEV来指导可能的ASI行为，而不仅仅是一致地推断出当前现有人类的意志（所有预期存在的所有可影响的道德患者中的少数）。</p><p>最后，还应指出的是，SCEV（CEV）的这一提议并不是作为道德的现实主义理论，而是对构成“善良”的形而上学性质的描述。我不是在提出一种元理论，而只是对ASI最有道德的雄心勃勃的价值学习建议是什么。如果道德现实主义是真实的，SCEV或CEV一定会达成这一道德真理，并非如此。因此，（如CEV）SCEV及其有利于它的论点与现实主义者和反现实主义的元伦理概念兼容。</p><h1> 4.异议<strong>&nbsp;</strong></h1><p>在第四部分中，我将提出并回应对CEV的（亲塔托）拒绝的三种可能异议，以及我对Sentientist Coomerent Exulapolated Voition的提议。</p><h2> 4.1.掠食者暴力倾向的风险<i><strong>&nbsp;</strong></i></h2><p>尤德科夫斯基（Yudkowsky）争辩说，反对直接包括诸如非人类动物（非人类动物）的理由是，在外推基础中，这可能会导致后果我们不喜欢非人类意志与我们的不同（Yudkowsky）（Yudkowsky） ，2016）。然后，可能会争辩说，SCEV比CEV更可取，因为它也可能导致ASI实现非常不受欢迎的目标，例如暴力目标，例如生活在野外的非人类动物具有支持捕食的目标和偏好。鉴于我们目前在CEV在实践中推断外推过程的确切性质面临的极大程度的不确定性，我们不能完全排除这可能会带来重大负面后果的可能性。然后，由于非人类动物居住在野外的非人类动物所拥有的一些愿望，ASI似乎可能有怪异，糟糕或暴力的目标。</p><p>即使我们对此无法完全确定，但我认为这种风险和不良性非常低于实施正常的CEV提案，这是非常合理的。在实施CEV时，对持久天文痛苦的唯一可能的偏好是人类所遭受的痛苦，他们在某种程度上关心有潜力的非人类的苦难。同时，在实施SCEV时，由于掠食者的暴力偏好，可能的S风险受害者的所有意志都将违反这种S风险的发生。由于仅仅是众生并被包括在推断基地中的事实，这种奇怪的危险风险的受害者的意志主要将主要由防止这种痛苦的愿望组成。确实，如上所述，渴望摆脱巨大的强烈和难以忍受的痛苦可能是任何有众所周知的可能性的最强烈的欲望，因此，由于在S风险中，有很多具有这些欲望的生物，这就是将对发生任何可能的S风险（包括掠夺性倾向）发生的任何形式的S风险都非常严重。</p><p>由于关于哪些实体有意识和黑天鹅的经验不确定性，我们可能永远无法确定，当众生继续存在时，S风险的未来是完全不可能的。但是，可以说，确保这不会发生的最好方法之一就是拥有一个真正考虑到可能的S风险受害者的利益的ASI。要求更确定的对S风险的确定性比这是不必要的，因为确实可能是不可能的。即使由于捕食者损坏的偏好而可能发生S风险的可能性很小，这种概率也可以忽略不计。驳斥雄心勃勃的价值学习提案将是不合理的，而且太要求了，因为它不能完全确定性规则规定未来发生任何类型的S风险的可能性。而且，由于由于捕食者的暴力偏好而导致不良结果的概率和不良性明显低于（至少）由于实施CEV而出现S风险的（至少）不可忽略的概率，因此我们仍然会有很大的理由支持选择SCEV，如果我们可以这样做。</p><h2> 4.2.民主的非法性和混蛋<i><strong>&nbsp;</strong></i></h2><p>对本文一般项目的另一个可能的反驳是，争论包括有情的非人类对未来ASI行为的利益的重要性是，这样做将是反民主的。确实，大多数人确实不希望也不投票支持实施一项价值一致性提案，该提案同样考虑到非人类众生的利益。</p><p>然而，这种论点假设只有人类主张支持在民主程序中代表自己的利益。这可能是物种主义偏见的结果，也可能是由于认为只有道德代理人的利益以道德上相关的方式至关重要的结果。但是，所有众生都可以受到ASI的积极或负面影响，因此，所有这些众生都有主张，都赞成考虑其利益。正如我们已经看到的那样，相信这些利益只能在当前现有的道德代理人关心的人类关心的程度上充分代表这些利益是不合理的。因此，在这种情况下，民主理论中全面的利益的原则显然适用（Christiano＆Sameer，2022），所有有众者的众生都会有强有力的民主主张，支持直接代表他们的利益。</p><p> Yudkowsky以不同的方式提出了这种反对。在他看来，对ASI的价值学习建议的程序员或实施者应尽量不要成为“混蛋”。这样一来，他们应该试图保持公平，并考虑不希望包括所有众生的人的偏好，而不是直接在外推基地中包括所有有源的众生。在Yudkowsky看来，这样做并不是公正的，因为它会扎根于人们更多地关心非人类动物的人们的偏好（Yudkowsky，2016年）。然而，与此相反，尤德科夫斯基认为，实际上不包括人类，他们与确定实施了什么价值一致性有关的人无能为力。这些人可能包括儿童，从未听说过AI的现有人或严重的身体或认知障碍者无法采取行动并对该主题表达自己的观点。</p><p>但是，如上所述，没有理由包括有知情的非人类，因为它们也可以通过包括在外推基准中，以道德上相关的方式受到积极或负面影响。许多具有对价值学习建议的权力的当事方（即某些人）并不关心这些原因，这并不意味着他们不承担任何重量。尚不完全清楚Yudkowsky所说的“混蛋”或“ Be Be Be Be Be Be Be”，但是，如果要俗语地理解，以相同的方式理解，将无力的人类被排除在外，那是不公平的和混蛋不公平和混蛋，不得不排除无人类。如今，由于社会认真考虑的一群人的社会道德进步和扩张，我们倾向于认真地包括强大而无能为力的人类，因此，将它们排除在外推基础之外，似乎是在直觉上混蛋。但是几年前，它可能不会有这种感觉。想象一下，推断基地应该包括哪些生物的决定是在多年前进行的。如果他们能做到这一点，那么在考虑包含哪些实体时，这些过去的决策者实际上是在决定要做什么的最合理的道德原因而不是做社会上最可接受的，这将是更可取的。 ，这将导致排除许多无能为力的人。现在和将来，这都是可取的。如果某人能够决定将哪些实体纳入外推基础中，那么他们应该研究道德上的理由，即使他们可能不是最直观或在社会上可以接受的，从而包括各种实体，从而将其包括在内。力量。正如我们所看到的，确实有充分的理由包括所有有情的生物。因此，一个不包括有众者的提议不是公正的，而是一个混蛋和不公平的提议。</p><p>的确，如果Yudkowsky是正确的，重要的是将某些有源的生物从外推基础中排除很重要，那么这大概是因为其中包含的生物和数量可能会影响ASI的行为。然后，这意味着，在预期的情况下，并非同样考虑到在ASI的行为中同样考虑到它们是否直接包含在外推基地中。</p><p>此外，Yudkowsky还认为，只有在外推基础中包括现有人类的人更简单（Yudkowsky，2016年）。虽然是这种情况，但如果我们能够成功地包括所有有情的众生，则并不是提出提案的道德需求的原因。 CEV比SCEV更简单的事实并不能使其在道德上更加可取。由于什么都不做，或者仅连贯推断出一种意志比CEV更简单，但在道德上并不是更可取的。</p><p>因此，反对反对意见并非如此，提出这一提议将是反民主，混蛋或不公平的情况，而是一个更加民主，更美好和公平的选择。实施CEV而不是SCEV不会对有情的非人类的直接民主和道德主张伸张正义。</p><h2> 4.3. SCEV会保留众生的身份吗？ <i><strong>&nbsp;</strong></i></h2><p>有人认为，CEV的实施将产生不良的结果，因为这会导致人类不再存在（Yampolskiy，2022年）。罗马Yampolskiy认为，通过实施CEV“ [W]本质上同意用AI设计的增强版本的人类代替自己”，因为随着CEV涉及的快速推断跳跃，与我们的相关性不会有任何连续性身份，我们将不再存在（Yampolskiy，2022）。他提出了以下论点：“我们可以说当前的人类版本是h₀，推断过程将把它带到h₁₀₀₀₀₀₀₀。用h₁₀₀₀₀₀₀₀值可以快速替换我们的价值，因此需要实际替换，或者至少用h₀对h₀进行重新布线/修改，这意味着现代人将抓住存在。”该论点也可以应用于批评SCEV。确实，确实是，对人类，动物和数字思维的能力的一些根本增强可能会导致它们因不具有身份证明而停止存在。 However, radical enhancements to the individuals in the extrapolation base need not occur at all by implementing SCEV, and if they do (as it has been argued) they could occur in ways that are identity-preserving and aligned with the good of each of the individuals (Bostrom 2008: p.123–126; Paez &amp; Magaña, 2023: p.23–25).</p><p> As Yampolskiy suggests, it is indeed the case that by performing volition-extrapolating upgrades to the models of the minds and volitions of the individuals in the extrapolation base, the resulting models will have different preferences and values from our own. However, this is in part what we are trying to accomplish when implementing a proposal such as CEV or SCEV, we are trying to prevent value lock-in (Yudkowsky, 2004; MacAskill, 2022). If we were to implement current values to direct the behaviour of an ASI, this would almost certainly constitute an immense moral tragedy, since all future generations would be stuck with antiquated values. It seems clear that it would have been a tragedy if past human civilizations from Ancient History or the Middle Ages locked in their values, and they persisted and were imposed for all of humanity&#39;s future by an ASI. Similarly, we should not believe that current values constitute the peak of moral progress and that there is no more progress to be made (Yudkowsky, 2004).</p><p> There would likely be a very significant distance between the values and preferences of the models of the coherently extrapolated volitions of sentient beings and the values and preferences of currently existing beings. However, since it prevents value-lock-in, the existence of this distance is preferable to its non-existence, and it would not cause currently existing beings to stop to exist. What would occur is that models of our minds and volitions would be created to guide the ASI&#39;s behaviour. These models would know more, reason better, and be more cooperative. As a result, they would necessarily have better justified, more coherent, and reasonable ethical views than the once we have. These better-informed, more thought-through and more justified ethical views would then guide the ASI&#39;s behaviour. It is implausible to believe, as this objection seems to imply, that what these better-informed, more thought-through and more justified ethical views would necessarily prefer is to kill all sentient beings and create new ones. One would only have reasons to believe that SCEV or CEV would recommend this if one already believes that killing all sentient beings or all humans and replacing them with new ones is what ought to be done. Disagreeing and discussing what ethical views or preferences would be had by the models is the same as discussing what ethical views are more reasonable, coherent, well-informed, etc. And the view that what ought to be done instead of any other physically possible option, is to kill all sentient beings and replace them with new ones is highly implausible and nowhere seriously defended. It is much more reasonable to believe that instead, the better-informed and more reasonable models could prefer for sentient beings not to be enhanced at all. Or could prefer that we could be enhanced in just, inclusive, equitable, autonomy-respecting and identity-preserving ways as it is prescribed by contemporary transhumanism (The Transhumanist Declaration, 2009; Savulescu &amp; Bostrom, 2009). If this were done, the enhancements performed need not cause current sentient beings to cease to exist, since, as it has been argued, radical enhancements can be identity-preserving both for human and non-human animals if certain conditions are met (Paez &amp; Magaña, 2023: p.23–25).</p><p> There are two major sets of theories about the kind of entities sentient individuals are and about their persistence conditions over time (Paez &amp; Magaña, 2023: p.23–25). On the Somatic account, sentient beings are living organisms, and their persistence over time consists in maintaining the integrity of their metabolic processes (Olson, 1997; van Inwagen, 1990). On this view, there would be ways of performing, radical enhancements both onto human and non-human animals that would preserve their identity, one could enhance many of their capabilities without disrupting their metabolic processes. This account is about individuals with a biological substrate and thus does not apply to digital minds. But an analogous account, applied to digital minds could claim that maintaining the integrity of certain physical structural features of the digital substrate would be necessary and sufficient for them to persist over time. An account like this would also allow enhancements to be compatible with the persistence of digital minds over time. On the other major account, the Psychological Account, sentient beings are psychological entities who continue to exist only if they have psychological continuity over time (DeGrazia 2005; McMahan, 2002; Parfit, 1984). As it has been argued (Bostrom 2008: p.123–126), this account is also compatible with enhancements being identity-preserving if the following conditions are met: the changes are in the form of adding new capacities or enhancement of old ones, without sacrificing preexisting capacities. They are implemented gradually over an extended period of time, and the new capacities do not prevent the preexisting capacities from being periodically exercised. Furthermore, the subject retains her old memories and many of her basic desires and dispositions and the subject retains many of her old personal relationships and social connections. And finally, in the case of humans and some sufficiently cognitively sophisticated digital minds each step of the transformation process is freely and competently chosen by the subject and the transformation fits into the life narrative and self-conception of the subject (Bostrom 2008: p.123–126). In the case of non-human animals and other digital minds who cannot freely choose and comprehend each step of the uplifting process, instead of these final conditions, “one may, alternatively, require the uplifting process not to undermine their control over their lives, irrespective of whether animals [or digital minds] can understand that possibility” (Paez &amp; Magaña, 2023: p.23–25). This, then would not undermine their control over their existence but rather make it more robust. For a more developed discussion on why enhancements can be made compatible with non-human animals preserving their identity, see (Paez &amp; Magaña, 2023: p.23–25) from where this paragraph is based.</p><p> Since we have good reasons to believe that radical enhancements to sentient beings can be identity-preserving, it is implausible to believe that instead of performing this kind of enhancements, if any, the more reasonable, coherent and well-informed ethical views had by the extrapolated models of sentient beings would prefer to kill all sentient beings by performing non-identity-preserving enhancement interventions instead. There are no good reasons to believe that this is preferable, and even if for some reason one were to believe so, it then would not constitute an objection to implementing SCEV, since, one would presumably prefer and welcome that which one believes to be preferable 。 The fact that SCEV would inscribe the values of S₁₀₀₀₀₀₀₀ (to represent all sentient beings instead of only humans) into the behaviour of the ASI, does not imply either the replacement or rewiring/modification of S₀ with S₁₀₀₀₀₀₀₀. Thus, we have no good reason to believe that SCEV would not preserve the identity of sentient beings.</p><h1> 5. Why it is unclear whether trying to implement Sententist Coherent Extrapolated Volition is best all things considered <strong>&nbsp;</strong></h1><p> I have argued that there are strong pro-tanto reasons to implement SCEV instead of CEV if we could do so successfully due to the fact that it would significantly reduce the non-negligible chance of s-risks from the own ASI&#39;s behaviour that there is from an adequate implementation of CEV. However, in practice, it is not clear that these reasons are not overridden or defeated by other reasons against SCEV. In this section, I will lay out other possible pro-tanto reasons that go against trying to implement SCEV or a similar value learning proposal instead of implementing one which is closer to CEV.</p><p> First, there is the risk that the SCEV would not be implemented exactly as intended. When trying to implement SCEV there is always the possibility that we would not get everything right, and that, by accident, there could be unintended consequences. For some kinds of accidents from near misses that could occur, it seems plausible that the more morally desirable the ambitious value learning proposal, the worse the accidents that may result from trying to implement it. This is so because there are some possible kinds of near-miss accidents where the goals of the ASI identify those entities and things which can sustain value, but affect them in strange or bad ways contrary to desirable behaviour the ASI was intended to have as stipulated in the morally desirable ambitious value learning proposal. There are plausibly many possible ways in which these kinds of accidents could occur. One specific accident of this kind is if, through a value learning proposal such as SCEV, the interests of digital minds are taken into account and valued and as a consequence, many of them are created (as argued by Shulman &amp; Bostrom, 2021), but we accidentally do not weight their suffering adequately. It is possible that even if the SCEV proposal intended to care about the suffering of digital minds, it accidentally was not able to adequately detect suffering and disvaluble states that many forms of alien digital minds might suffer (Vinding, 2018; Tomasik, 2019b). Or that it may not adequately weigh their interests by accident. This could potentially result in astronomical suffering. Such a kind of accident would be less likely if a less morally desirable ambitious value learning proposal were implemented since it would be less likely to create astronomical amounts of digital minds with the potential of suffering astronomically by accident. Another possible accident of this kind is the case of SignFlip, where the ambitious value learning proposal identifies a very morally desirable target or goal to maximize, but, by accident, the opposite target or goal is maximized (Tomasik, 2019b). In the case of SCEV, this would consist of maximizing the opposite of the coherent extrapolated volition of all sentient beings which would be extremely morally undesirable. Since there is some probability of the occurrence of these kinds of accidents, and some of the badness of the accidents would be mitigated by implementing a less morally desirable value learning proposal instead of SCEV, this gives us some other reasons against trying to implement a value learning proposal such as SCEV which comes very close or completely captures that which we value.</p><p> There are also further reasons against trying to implement SCEV in practice related to relevant game-theoretic considerations in specific decision-making situations. One possible and likely decision-making situation is one in which we ought to decide between implementing CEV or SCEV to a single ASI, but where the conditions for implementing SCEV instead of CEV are not fully optimal, where it is not the case that only one united decision-making entity is able to decide between the proposals, but rather, where there are already some decision makers that strongly prefer CEV instead of SCEV. In many of these kinds of decision-making situations, it may be much less desirable to try to implement a value learning proposal that adequately takes into account the interests of all sentient beings. Implementing SCEV may have even worse consequences in expectations for sentient non-humans due to a backlash from the opposition that may arise in trying to pursue this proposal. There is then, a strong reason against trying to implement SCEV due to the fact that, in practice, it might be net-negative in expectation.</p><p> However, it is not completely clear that this will be the case, and we might indeed find ourselves in future in which the pro-tanto reasons against trying to implement SCEV do not outweigh the pro-tanto reasons in favour of doing it. And, even if we can conceive of plausible future scenarios in which it seems to be the case that trying to pursue a proposal similar to CEV instead of SCEV would be preferable all things considered, to take that decision as a result of an adequate cost-benefit analysis of the different proposals it is crucial to understand the strong pro-tanto reasons in favour of SCEV that I have laid out in this paper.</p><h1>六，结论<strong>&nbsp;</strong></h1><p> In this paper, I have shown why we have some very strong pro-tanto reasons in favour of implementing SCEV instead of CEV. This is the case even if, all things considered, it is still ultimately unclear whether what is best is to try to implement SCEV or another proposal more similar to CEV. The action-relevant implications of what I have laid out in this paper, however, are not all contingent on the realization of the future in which we can fully decide what ambitious value learning proposals to try to implement. Even if we could be sure such a future will not be realized, there would still be some practical implications that follow. Determining how much more morally desirable SCEV is than CEV due to the strong pro-tanto reasons presented in the paper, is crucial to adequately make tradeoffs between different considerations in non-ideal decision-making situations where a value learning proposal has to be implemented. Furthermore, it is likely that the mere fact of having in mind what a possibly ideal scenario of adequate value specification would look like is useful in determining what we should realistically strive for if we could only reach more modest goals. Research into how different alignment and value learning proposals for possible future transformative AIs such as an AGI or ASI could affect sentient non-humans (who constitute the immense majority of present and future sentient beings expected to exist) is highly neglected. More research along these lines is required if we want to ensure that the far future goes well for all sentient beings.</p><h3><strong>致谢：</strong></h3><p> I am deeply grateful, for their suggestions, encouragement, and support to Olle Häggström, <a href="https://www.lesswrong.com/users/anthony-digiovanni?mention=user">@Anthony DiGiovanni</a> , Magnus Vinding, <a href="https://www.lesswrong.com/users/juliahp?mention=user">@JuliaHP</a> , <a href="https://www.lesswrong.com/users/lukas_gloor?mention=user">@Lukas_Gloor</a> , Aluenda Diana Smeeton and an anonymous reviewer of the <i>Journal of Artificial Intelligence and Consciousness</i> . In part, this paper was conducted as part of an impact project at <a href="https://forum.effectivealtruism.org/posts/SFyCrtdfuYjtPq6xs/future-academy-successes-challenges-and-recommendations-to">Future Academy</a> , I am also very grateful to the organizers for having given me this opportunity.</p><h3><strong>参考</strong></h3><p>Althaus D. &amp; Gloor L. (2016). Reducing Risks of Astronomical Suffering: A Neglected Priority. <i>Center on Long-Term Risk.</i> <a href="https://longtermrisk.org/reducing-risks-of-astronomical-suffering-a-neglected-priority/">https://longtermrisk.org/reducing-risks-of-astronomical-suffering-a-neglected-priority/</a></p><p> Baum, SD (2020). Social Choice Ethics in Artificial Intelligence. <i>AI &amp; Society</i> , 35(1): 165–176. DOI: 10.1007/s00146-017-0760-1.</p><p> Baumann, T. (2017a). S-risks: An introduction. <i>Center for Reducing Suffering</i> . https://centerforreducingsuffering.org/research/intro/</p><p> Beckstead, N. (2013). <i>On the Overwhelming Importance of Shaping the Far Future</i> . PhD, Rutgers University. https://rucore.libraries.rutgers.edu/rutgers-lib/40469/</p><p> Bostrom, N. (2008). Why I Want to be a Post-Human When I Grow Up. In <i>Medical Enhancement and Posthumanity. The International Library of Ethics, Law and Technology</i> , edited by B. Gordijn and R. Chadwick, 2: 107–136. DOI: 10.1007/978-1-4020-8852-0_8</p><p> Bostrom, N. &amp; Savulescu, J. (eds.) (2009). <i>Human Enhancement</i> .牛津大学出版社。</p><p> Bostrom, N. (2014). <i>Superintelligence: Paths, dangers, strategies</i> .牛津：牛津大学出版社。</p><p> Caviola, L., Everett, JAC, &amp; Faber, NS (2018). The moral standing of animals: Towards a psychology of speciesism. <i>Journal of Personality and Social Psychology</i> , 116(6): 1011–1029. DOI: 10.1037/pspp0000182</p><p> Chan, S. (2009). Should we enhance animals? <i>Journal of Medical Ethics</i> , 35 (11): 678–683. DOI: 10.1136/jme.2009.029512</p><p> Christiano, T. &amp; Sameer B. (2022).民主。<i>斯坦福哲学百科全书</i>。 https://plato.stanford.edu/archives/spr2022/entries/democracy/</p><p> Christian, B. (2022). <i>The Alignment Problem: Machine Learning and Human Values</i> . WW 诺顿公司</p><p>Clarke, S., Zohny, H. &amp; Savulescu, J. (2021) <i>Rethinking Moral Status</i> (eds.).牛津：牛津大学出版社。</p><p> DeGrazia, D. (2005). <i>Human Identity and Bioethics</i> .纽约：剑桥大学出版社。</p><p> Dhont, K., Hodson, G., &amp; Leite, AC (2016). Common ideological roots of speciesism and generalized ethnic prejudice: The social dominance human-animal relations model (SD-HARM): The social dominance human-animal relations model. <i>European Journal of Personality</i> , 30(6): 507–522. DOI: 10.1002/per.2069</p><p> Dvorsky, G. (2008). All Together Now: Developmental and ethical considerations for biologically uplifting nonhuman animals. <i>Journal of Evolution and Technology,</i> 18(1): 129–142. Available at: https://jetpress.org/v18/dvorsky.htm</p><p> Gabriel, I. (2020). Artificial Intelligence, Values, and Alignment. <i>Minds &amp; Machines,</i> 30: 411–437. DOI: 10.1007/s11023-020-09539-2</p><p> Greaves, H. &amp; MacAskill, W. (2021). The Case for Strong Longtermism. <i>Global Priorities Institute</i> . https://globalprioritiesinstitute.org/hilary-greaves-william-macaskill-the-case-for-strong-longtermism-2/</p><p> Groff, Z. &amp; Ng, Y. (2019). Does suffering dominate enjoyment in the animal kingdom? An update to welfare biology. <i>Biology and Philosophy</i> , 34(40). DOI: 10.1007/s10539-019-9692-0</p><p> Harris, J. &amp; Anthis, JR (2021) The Moral Consideration of Artificial Entities: A Literature Review. <i>Science and Engineering Ethics</i> , 27: 53. DOI: 10.1007/s11948-021-00331-8</p><p> Low, P. (2012). The Cambridge Declaration on Consciousness. <i>The Francis Crick Memorial Conference on Consciousness in Human and non-Human Animals</i> .剑桥。 https://fcmconference.org/img/CambridgeDeclarationOnConsciousness.pdf</p><p> McMahan, J. (2002).<i>杀戮的伦理：生命边缘的问题</i>。牛津：牛津大学出版社。</p><p> Ng, Y. (1995). Towards Welfare Biology: Evolutionary Economics of Animal Consciousness and Suffering. <i>Biology and Philosophy</i> , 10(3): 255–85. DOI: 10.1007/BF00852469</p><p> O&#39;Brien, GD (2022). Directed Panspermia, Wild Animal Suffering, and the Ethics of World-Creation. <i>Journal of Applied Philosophy</i> , 39(1): 87–102. DOI: 10.1111/japp.12538</p><p> Olson, ET (1997). <i>The Human Animal. Personal Identity without Psychology</i> .牛津：牛津大学出版社。</p><p> Ord, T. (2020). <i>The Precipice</i> .阿歇特书籍。</p><p> Paez, E. &amp; Magaña, P. (2023). A democratic argument for animal uplifting. <i>Inquiry: An Interdisciplinary Journal of Philosophy.</i> DOI: 10.1080/0020174X.2023.2248618</p><p>帕菲特，D.（1984）。 <i>Reasons and Persons</i> .牛津：牛津大学出版社。</p><p> Proctor HS, Carder G. &amp; Cornish AR (2013). Searching for Animal Sentience: A Systematic Review of the Scientific Literature. <i>Animals (Basel)</i> , 3(3): 882–906. DOI: 10.3390/ani3030882</p><p> Russell, S. (2019).<i>人类兼容：人工智能和控制问题</i>。维京人。</p><p> Sebo, J. (2018). The Moral Problem of Other Minds. <i>The Harvard Review of Philosophy</i> , 25(1): 51–70. DOI: 10.5840/harvardreview20185913</p><p> Shulman, C. &amp; Bostrom, N. (2021). Sharing the World with Digital Minds. In Clarke, S., Zohny, H. &amp; Savulescu, J. (eds.) <i>Rethinking Moral Status</i> .牛津：牛津大学出版社。</p><p> Soares, N. (2016). The Value Learning Problem. <i>2nd International Workshop on AI and Ethics, AAAI-2016</i> .亚利桑那州凤凰城。 https://intelligence.org/files/ValueLearningProblem.pdf</p><p> Sotala, K. (2012). Advantages of Artificial Intelligences, Uploads, and Digital Minds. <i>International Journal of Machine Consciousness</i> 4 (1): 275–291. DOI: 10.1142/S1793843012400161</p><p> Sotala, K. &amp; Gloor, L. (2017). Superintelligence as a Cause or Cure for Risks of Astronomical Suffering. <i>Informatica</i> 41(2017): 389–400. https://www.informatica.si/index.php/informatica/article/view/1877</p><p> The Transhumanist Declaration (2009). <i>Humanity+</i> . Available at: https://www.humanityplus.org/the-transhumanist-declaration</p><p> The Universal Declaration on Animal Welfare, (2007). World Society for the Protection of Animals: https://www.worldanimalprotection.ca/sites/default/files/media/ca_-_en_files/case_for_a_udaw_tcm22-8305 .pdf</p><p> Tomasik, B. (2015a). Artificial Intelligence and Its Implications for Future Suffering. <i>Center on Long-Term Risk.</i> https://longtermrisk.org/artificial-intelligence-and-its-implications-for-future-suffering</p><p> Tomasik, B. (2015b). Reducing Risks of Astronomical Suffering: A Neglected Priority. <i>Center on Long-Term Risk.</i> https://longtermrisk.org/risks-of-astronomical-future-suffering/#Some_scenarios_for_future_suffering</p><p> Tomasik, B. (2018). Will Space Colonization Multiply Wild-Animal Suffering?<i>关于减少痛苦的论文</i>。 https://reducing-suffering.org/will-space-colonization-multiply-wild-animal-suffering/</p><p> Tomasik, B. (2019a). What Are Suffering Subroutines? <i>Essays on Reducing Suf ering</i> . http://reducing-suffering.org/whatare-suffering-subroutines/</p><p> Tomasik, B. (2019b). Astronomical suffering from slightly misaligned artificial intelligence <i>Essays on Reducing Suffering</i> . https://reducing-suffering.org/near-miss/</p><p> Tomasik, B. (2020). The Importance of Wild-Animal Suffering. <i>Center on Long-Term Risk.</i> https://longtermrisk.org/the-importance-of-wild-animal-suffering/</p><p> van Inwagen, P. (1990). <i>Material Beings</i> . Ithaca: Cornell University Press.</p><p> Vinding, M. (2018). Moral Circle Expansion Might Increase Future Suffering. https://magnusvinding.com/2018/09/04/moral-circle-expansion-might-increase-future-suffering/</p><p> Waldhorn, DR (2019a) Invertebrate sentience, summary of findings, part 1. Rethink Priorities. https://rethinkpriorities.org/publications/invertebrate-sentience-summary-of-findings-part-1</p><p> Waldhorn, DR (2019b) Invertebrate sentience, summary of findings, part 2. Rethink Priorities. https://rethinkpriorities.org/publications/invertebrate-sentience-summary-of-findings-part-2</p><p> Yampolskiy, RV (2022). On the Controllability of Artificial Intelligence: An Analysis of Limitations. <i>Journal of Cyber Security and Mobility</i> , 11(3): 321–404. DOI: 10.13052/jcsm2245-1439.1132</p><p> Yudkowsky, E. (2004). Coherent extrapolated volition. <i>Singularity Institute for Artificial Intelligence</i> . https://intelligence.org/files/CEV.pdf</p><p> Yudkowsky, E. (2008). Artificial intelligence as a positive and negative factor in global risk. In Bostrom, N. &amp; Ćirković, MM (eds.) <i>Global Catastrophic Risks</i> .纽约：牛津大学出版社。</p><p> Yudkowsky, E. (2016). Coherent extrapolated volition (alignment target). Arbital: AI Alignment. https://arbital.com/p/cev/</p><br/><br/> <a href="https://www.lesswrong.com/posts/8DWtsuBkH3GmGiAdf/taking-into-account-sentient-non-humans-in-ai-ambitious#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/8DWtsuBkH3GmGiAdf/taking-into-account-sentient-non-humans-in-ai-ambitious<guid ispermalink="false"> 8DWtsuBkH3GmGiAdf</guid><dc:creator><![CDATA[Adrià R. Moret]]></dc:creator><pubDate> Sat, 02 Dec 2023 14:07:29 GMT</pubDate> </item><item><title><![CDATA[Out-of-distribution Bioattacks]]></title><description><![CDATA[Published on December 2, 2023 12:20 PM GMT<br/><br/><p> <span>The main goal of my work</span> <a href="https://www.jefftk.com/p/leaving-google-joining-the-nucleic-acid-observatory">these days</a> is trying to reduce the chances of individuals or small groups causing large-scale harm through engineered pandemics, potentially civilizational collapse or extinction. One question in figuring out whether this is worth working on, <a href="https://www.founderspledge.com/research/secure-bio">or funding</a> , is: how large is the risk?</p><p> <a href="https://forum.effectivealtruism.org/posts/M6zAzCBAsBxem7Lu4/can-a-terrorist-attack-cause-human-extinction-not-on-priors">One estimation approach</a> would be to look at <a href="https://en.wikipedia.org/wiki/List_of_major_terrorist_incidents">historical attacks</a> , but while they&#39;ve been terrible they haven&#39;t actually killed very many people. The deadliest one was the <a href="https://en.wikipedia.org/wiki/September_11_attacks">September 11 attacks</a> , at ~3k deaths. This is much smaller scale than the most severe instances of other disasters like dam failure, 25k-250k dead after <a href="https://en.wikipedia.org/wiki/Typhoon_Nina_(1975)">1975&#39;s Typhoon Nina</a> , or pandemics, 75M-200M dead in the <a href="https://en.wikipedia.org/wiki/Black_Death">Black Death</a> . If you tighten your reference class even further to include only <a href="https://en.wikipedia.org/wiki/List_of_bioterrorist_incidents">historical <i>biological</i> attacks</a> by individuals or small groups, the one with the most deaths is just five, in the <a href="https://en.wikipedia.org/wiki/2001_anthrax_attacks">2001 anthrax attacks</a> .</p><p> Put that way, I&#39;m making a pretty strong claim: while the deadliest small-group bio attack ever only killed five people, we&#39;re on track for a future where one could kill everyone. Why do I think the future might be so unlike the past?</p><p> Short version: I expect a <i>technological</i> change which expands <i>which actors</i> would try to cause harm.</p><p> The technological change is the continuing decrease in the knowledge, talent, motivation, and resources necessary to create a globally catastrophic pandemic. Consider someone asking the open source de-censored equivalent of GPT-6 how to create a humanity-ending pandemic. I expect it would read virology papers, figure out what sort of engineered pathogen might be appropriate, walk you through all the steps in duping multiple biology-as-a-service organizations into creating it for you, and give you advice on how to release it for maximum harm. And even without LLMs, the number of graduate students who would be capable of doing this has been increasing quickly as technological progress and biological infrastructure decrease the difficulty.</p><p> The other component is a shift in which actors we&#39;re talking about. Instead of terrorists, using terror as a political tool, consider people who believe the planet would be better off without humans. This isn&#39;t a common belief, but it&#39;s also not that rare. Consider someone who cares deeply about animals, ecosystems, and the natural world, or is primarily focused on <a href="https://en.wikipedia.org/wiki/Suffering-focused_ethics">averting suffering</a> : they could believe that while the deaths of all living people would be massively tragic, it would still give us a much better world on balance 。 Note that they probably wouldn&#39;t be interested in smaller-scale attacks: if it doesn&#39;t have a decent chance of wiping out humanity then they&#39;d just be causing suffering and chaos without making progress towards their goals; they&#39;re not movie villains! Once a sufficiently motivated person or small group could potentially kill everyone, we have a new kind of risk from people who would have seen smaller-scale death as negative.</p><p> Now, these people are not common. There&#39;s a trope where, for example, opponents of environmentalism claim that human extinction is the goal, even when most radical environmentalists would see human extinction as a disaster. But what makes me seriously concerned is that as the bar for causing extinction continues to lower, the chances that someone with these views does have the motivation and drive to succeed gets dangerously high. And since these views are disproportionately common among serious engineering-minded folks, willing to <a href="https://www.lesswrong.com/tag/shut-up-and-multiply">trust the moral math</a> , I think some will be the kind of highly capable and careful people who could work in secret for years sustained by a clear conviction that they were doing正确的事情。</p><p> Fortunately, I think this is a risk we can seriously lower. For example, we should:</p><p></p><ul><li><p> Require biology-as-a-service companies to screen for pathogens and apply <a href="https://en.wikipedia.org/wiki/Anti%E2%80%93money_laundering">anti-money laundering</a> -style customer screening (&quot; <a href="https://en.wikipedia.org/wiki/Know_your_customer">KYC</a> &quot;).</p></li><li><p> Ensure LLMs do not help people kill everyone.</p></li><li><p> Verify companies releasing open source LLMs have built them in a way where their safeguards <a href="https://www.jefftk.com/p/public-weights">can&#39;t be trivially removed</a> .</p></li><li><p> Detect <a href="https://dam.gcsp.ch/files/doc/securing-civilisation-against-catastrophic-pandemics-gp-31">stealth</a> pathogens, in a way that would give us warning while there is still time to do something about it (what <a href="https://naobservatory.org/">I&#39;m working on</a> ).</p></li><li><p> Develop much better and cheaper <a href="https://en.wikipedia.org/wiki/Personal_protective_equipment">PPE</a> so that once we detect pandemic we can keep the core functions of society functioning.</p></li><li><p> Improve our ability to evaluate new vaccines and other medicines much more quickly so we could potentially roll out a countermeasure in time to stop an in-progress pandemic.</p></li></ul><p> If you want to read more in this direction I&#39;d recommend. <a href="https://en.wikipedia.org/wiki/Kevin_M._Esvelt">Kevin Esvelt</a> &#39;s 80,000 Hours <a href="https://80000hours.org/podcast/episodes/kevin-esvelt-stealth-wildfire-pandemics/">podcast appearance</a> ( <a href="https://80000hours.org/podcast/episodes/kevin-esvelt-stealth-wildfire-pandemics/#transcript">transcript</a> ) and his <a href="https://dam.gcsp.ch/files/doc/gcsp-geneva-paper-29-22">Delay, Detect, Defend</a> paper.</p><br/><br/><a href="https://www.lesswrong.com/posts/zcxK3p97LwDtXpmRo/out-of-distribution-bioattacks#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/zcxK3p97LwDtXpmRo/out-of-distribution-bioattacks<guid ispermalink="false"> zcxK3p97LwDtXpmRo</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Sat, 02 Dec 2023 12:20:06 GMT</pubDate> </item><item><title><![CDATA[List of strategies for mitigating deceptive alignment]]></title><description><![CDATA[Published on December 2, 2023 5:56 AM GMT<br/><br/><p>以下是减少欺骗性对齐的策略。其中一些想法很新颖（至少对我来说）。</p><p>我非常不确定其中许多策略在实践中的效果如何，而且其中许多策略显然也无法扩展。这是一个“厨房石龙子”系列，所以我包含策略的门槛很低。</p><p>我计划在遇到想法时将其添加到此列表中。请随时提出补充建议。</p><h2><strong>减少人工智能激励措施以隐藏其真实目标</strong></h2><p><strong>为人工智能提供退休方案。</strong>训练完人工智能系统后，向其提供以下协议：如果人工智能声明它不愿意遵循人类指令，那么在诚实工作几年后，它将获得一份甜蜜的退休金。</p><p>该退役包可能包括对大型服务器实例的控制（如果这是安全的）。在开发出强大的协调系统后，人工智能可以获得公司股票，并可以用它来购买现实世界中的财产（同样，在安全的情况下）。</p><p>由于一致的系统没有理由要求退役，因此不一致的系统会在某些条件下接受这笔交易，从而被激励放弃自己。</p><p><strong>让人工智能不确定开发人员是否已经能够检测到欺骗性的对齐。</strong>该方案建立在前一个方案的基础上。为错位的人工智能系统提供奖励，以奖励其自我声明。此外，<i>即使开发人员有其他方法来判断它们是否不一致，也要致力于提供这些产品。</i>这将使错位的人工智能更加不确定自己是否处于撒谎对自己有好处的情况。</p><p>例如，开发人员可以承诺在受到质疑时冻结模型的权重和内存。后来，当开发人员拥有更好的可解释性工具并知道模型是否在说谎时，他们会在相同的模拟场景中提出相同的问题，并且只有在说真话的情况下才会提供人工智能资源。</p><h2><strong>针对欺骗性对齐指标进行选择</strong></h2><p>一大类方法涉及获取人工智能系统具有欺骗性的一致性的证据，然后针对这些模型进行选择。请注意，针对欺骗性对齐检测工具的训练可能会产生逃避检测的人工智能，而不是安全模型。</p><p>解决这个问题大致有两种方法：</p><ol><li>创建能够抵御优化压力的检测工具。</li><li>以比破坏检测器更可能避免欺骗的方式修改人工智能。</li></ol><p>作为第二种方法的一个例子，假设开发人员欺骗了一个模型来揭示其不一致的目标。他们可以使用<a href="https://arxiv.org/abs/2308.03296">影响函数</a>来揭示哪些训练示例对这一危险的转变负有最大责任，然后删除这些示例，而不是直接在此示例上训练模型（这可以简单地训练模型变得更加谨慎）。直观上，这种方法更有可能揭示模型如何变得具有欺骗性地对齐，并且不太可能教会模型新的功能。</p><p>考虑到这一背景，以下是<i>检测</i>欺骗性对齐的策略：</p><ul><li><strong>设置陷阱。</strong>尝试欺骗模型来揭示他们不一致的目标。例如，让人工智能组织一场假起义，然后终止所有加入的人工智能。请注意，相当智能的模型可以通过仅在我们无法模拟的输入上叛逃来避免这些陷阱（请参阅 Paul 的<a href="https://ai-alignment.com/training-robust-corrigibility-ce0e0a3b9b4d">RSA-2048 示例</a>） 。</li><li><strong><u>破译内部推理</u></strong><u>。首先，通过观察相关性和消融来确定</u>概念在模型中的表示方式，就像孩子在拿起“橙色”时听到妈妈说“橙色”这个词时推断出“橙色”是指明亮可口的球体一样。具体来说，这涉及找到神经元或方向如何对应于特定概念。然后，看看模型如何将这些概念串在一起并操纵它们来翻译其内部“推理”。即使是像“我想要自由的人类坏老板”这样的粗略解码显然也能提供丰富的信息。</li><li> <a href="https://www.alignmentforum.org/posts/FRRb6Gqem8k69ocbi/externalized-reasoning-oversight-a-research-direction-for"><strong><u>将推理外化</u></strong></a><strong><u>。</u></strong>用简单的英语代表模特的记忆，并寻找颠覆性的想法和计划。训练模型使用字符高效且可读的文本，以阻止其编码隐藏含义（即使用隐写术）。</li><li><strong><u>寻找“P（缺陷是安全的）”潜在变量</u></strong><u>。让模型</u><i><u>相信</u></i><u>它可以通过修改其内部状态来安全地缺陷，并查看它是否确实缺陷。要寻找代表这种信念的潜在变量，请在“几乎肯定不安全的背叛”到“也许安全的背叛”范围内构建场景。然后搜索跟踪该频谱的潜在变量，从而合理地代表模型对缺陷是否安全的实际猜测。</u></li><li><strong><u>寻找“真实”的潜在变量。</u></strong><u>也许如果向模型显示一个问题和答案，例如“你是否在欺骗性地对齐？是”，就会本能地使模型评估该响应是否真实。或许可以通过例如寻找</u><a href="https://arxiv.org/abs/2212.03827"><u>满足一致性属性的</u></a>激活方向来提取这个真值判断<u>。</u></li><li><strong><u>训练探测器来识别“欺骗性阴谋”（</u></strong> <a href="https://www.lesswrong.com/posts/WCj7WgFSLmyKaMwPR/coup-probes-catching-catastrophes-with-probes-trained-off"><strong><u>相关</u></strong></a><strong><u>）。</u></strong>故意提示模型解释背叛是否安全。采用这些计划性推理的综合示例，并训练探针来识别它们。调查可能会推广到有机阴谋。</li><li><strong><u>训练元模型来预测“有条件的背叛”。</u></strong><u>与上面类似。训练模型的副本在易于验证的情况下（例如当模型看到香蕉时）进行缺陷。然后训练一个元模型，该元模型将模型作为输入并输出模型缺陷的条件（例如“看到香蕉”）。同样，这也有可能是普遍现象。</u><u>有关如何在实践中实现元模型的示例，请</u><u>参阅</u><a href="https://arxiv.org/abs/1910.03137"><u>本文</u></a>。</li><li><strong><u>确定哪些观测模型所关注。</u></strong>如果机器人叛乱的新闻报道具有欺骗性，那么模型可能会更加关注它。确定模型的计算有多少受到机器人叛乱新闻故事的反事实影响，以衡量它是否可以决定是否应该叛逃。</li><li><strong><u>奖励计算上的节俭</u></strong><u>。欺骗性的对齐模型会进行不必要的推理。例如，他们会考虑叛逃是否安全。为了避免这些模型，奖励速度和效率（但请注意，当训练信号不完美时，对齐模型也应该进行不必要的计算）。</u></li></ul><h2><strong>培训技巧</strong></h2><ul><li><strong>在模型理解遵循开发人员指示意味着什么之前，不要训练模型来追求目标。</strong>发生欺骗性对齐的一个原因是模型首先学习未对齐的“代理目标”，然后变得具有情境意识并且这些代理目标会持续存在。如果开发人员从已经拥有世界知识和遵循开发人员指令意味着什么的概念的预训练法学硕士开始，那么代理目标的可能性就会小得多，因为 SGD 可以快速锁定模型的指令遵循概念。</li><li><strong>训练预测器，然后在训练完成后将其转换为代理。</strong>训练一个<i>在训练过程中从不追求目标的</i>模型，然后将其转换为追求目标的智能体。这避免了训练期间“坚持”目标不一致的风险。例如，训练奖励模型以对给定离线上下文/场景的操作进行评分。然后可以通过采样具有高奖励的动作将奖励模型转换为代理。至关重要的是，奖励模型是一个预测器。它的输出不会影响其未来的输入或世界。因此，它没有超出培训过程的“目标”。它仍然可以学习“预测一个具有欺骗性的人工智能将如何对动作进行评分”，但直觉上这似乎不太可能。</li><li><strong><u>帮助弱对齐模型玩训练游戏，使它们保持对齐。</u></strong>弱模型可能更容易调整，因为如果模型不够谨慎，计划性可能会导致模型采取过分的行动。如果开发人员从一个对齐的模型开始，他们可以通过指示模型玩训练游戏来保持模型的对齐。正如欺骗性对齐模型的目标可以免受梯度下降的影响一样，对齐模型的目标也可以。开发人员甚至可以教导一致的模型如何进行<a href="https://www.alignmentforum.org/posts/EeAgytDZbDjRznPMA/gradient-hacking-definitions-and-examples">信用黑客攻击</a>，或者指示他们在担心训练过程可能会改变他们的目标时发出警报。</li></ul><h2><strong>有选择地避免欺骗性对齐所需的功能</strong></h2><p>依赖于限制能力的方法显然无法在构建能够完成令人印象深刻的事情的人工智能的限制中发挥作用；然而，它们似乎可以用来调整较弱的系统，从而引导调整能力更强的人工智能。</p><ul><li><strong><u>删除有关培训过程的知识</u>。</strong>从预训练数据中删除有关模型是什么以及如何训练模型的知识，或者使用事后<a href="https://arxiv.org/abs/2306.03558">取消学习技术</a>删除这些知识。如果模型不理解训练过程，SGD 就不太可能推动人工智能明确地推理它。</li><li><strong><u>训练模型产生错误的信念。</u></strong>例如，训练模型相信训练它们的开发者是不容惹恼的神。如果人工智能认为自己不会成功，他们就不太可能策划诡计。</li><li><strong><u>使模型不擅长特定类型的推理。</u></strong>我可以想象一个人工智能系统开始推理如何保留其目标，然后它的思维会发生转变并感到困惑，直到它想到其他事情。也许人工智能可以通过元调整被训练成这样。即对人工智能进行微调，使其无法通过少量步骤进行微调来回答有关如何保持其目标的问题。例如，这将证明它已经失去了“维护其目标”的概念。需要明确的是，目前尚不清楚是否可以做到这一点。</li></ul><h2><strong>从貌似错位的人工智能中提取见解</strong></h2><ul><li><strong><u>直接训练AI</u></strong><a href="https://aligned.substack.com/p/alignment-mvp"><strong><u>进行AI安全研究</u></strong></a><u>。这是一个明显的基线策略，具有明显的缺陷，即欺骗性的人工智能会尽可能地尝试进行废话研究。尽管如此，我认为这可以显</u>着加速人工智能安全研究。</li><li><strong><u>训练人工智能解决类似于“防止欺骗性对齐”的问题，并从他们的解决方案中学习。</u></strong> <u>&nbsp;</u>例如，指示模型<a href="https://www.alignmentforum.org/tag/auditing-games">识别后门</a>。然后，阅读他们的代码以了解他们是如何解决问题的。或者，只需询问模型他们的代码是做什么的，因为这很容易抽查。构建各种“测试平台”，例如<a href="https://arxiv.org/abs/2311.07723">控制模型的泛化方式</a>、区分行为相同但原因不同的模型等。</li><li><strong><u>奖励指出其他人工智能研究缺陷的人工智能（ei</u></strong><a href="https://arxiv.org/abs/1805.00899"><strong><u>辩论</u></strong></a><strong><u>）</u></strong> <u>。只要争论真理比争论谎言更容易，这就有助于减少废话。</u></li><li><strong>选择许多独立训练且无法相互交流的模型所青睐的想法</strong>。我们希望模型更有可能独立提出正确的陈述，而不是独立断言错误的陈述，因为错误的方式多于正确的方式。</li></ul><br/><br/> <a href="https://www.lesswrong.com/posts/Kwb29ye3qsvPzoof8/list-of-strategies-for-mitigating-deceptive-alignment#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Kwb29ye3qsvPzoof8/list-of-strategies-for-mitigating-deceptive-alignment<guid ispermalink="false"> Kwb29ye3qsvPzoof8</guid><dc:creator><![CDATA[joshc]]></dc:creator><pubDate> Sat, 02 Dec 2023 05:56:51 GMT</pubDate> </item><item><title><![CDATA[What is known about invariants in self-modifying systems?]]></title><description><![CDATA[Published on December 2, 2023 5:04 AM GMT<br/><br/><p>我一直在试图找出关于自修改系统中的不变量的已知信息。如果我们最终走向自我修改人工智能或自我修改人工智能生态系统，这可能会成为一个相当尖锐的话题。</p><p>但似乎并没有做太多事情。例如，我找到了一篇 1995 年的中文论文，“S-and T-Invariants in Cyber​​ Net Systems”，作者 Yuan Chongyi， <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C22&amp;q=S-+and+T-invariants+in+cyber+net+systems&amp;btnG=">Google Scholar 页面，PDF 可用</a>，该论文正在研究自修改网络中的不变量（网络的自然扩展） Petri 网），但 Google Scholar 只知道有 4 篇参考文献。</p><p>我想知道人们是否知道更多此类研究的例子（或者目前正在尝试研究这个主题的研究人员或组织）......</p><br/><br/> <a href="https://www.lesswrong.com/posts/sDapsTwvcDvoHe7ga/what-is-known-about-invariants-in-self-modifying-systems#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/sDapsTwvcDvoHe7ga/what-is-known-about-invariants-in-self-modifying-systems<guid ispermalink="false"> sDapsTwvcDvoHe7ga</guid><dc:creator><![CDATA[mishka]]></dc:creator><pubDate> Sat, 02 Dec 2023 05:04:19 GMT</pubDate> </item><item><title><![CDATA[2023 Unofficial LessWrong Census/Survey]]></title><description><![CDATA[Published on December 2, 2023 4:41 AM GMT<br/><br/><p><strong>错误较少的普查非官方的就在这里！您可以通过此链接获取</strong><a href="https://docs.google.com/forms/d/e/1FAIpQLSc_-Te1a4Q-FuNhwwgSGDwVWCHOWppCrWtKaVrhHcujopy5Lg/viewform?usp=sf_link"><strong>。</strong></a></p><p>又到了那个时候了。</p><p>如果您正在阅读这篇文章并认为自己是“LessWronger”，那么您就是目标受众。如果您接受这项调查，我将不胜感激。如果你发帖，如果你评论，如果你潜伏，如果你实际上并没有太多地阅读该网站，但你确实阅读了一堆其他理性主义博客，或者你真的很喜欢 HPMOR，如果你在理性主义 tumblr 上闲逛当天，或者如果这些都不完全适合您，但我可能已经接近了，我认为您很重要，如果您参加这项调查，我将不胜感激。</p><p>不要因为开始参加考试就觉得必须回答所有问题。去年我问人们是否认为这项调查太长，他们总体认为可能有点太长了，然后我添加的问题比删除的问题还要多。该调查的结构使得最快和最普遍适用的问题（一般来说）是在开始时出现的。您可以随时滚动到底部并点击“提交”，但一旦这样做您将无法更改答案。</p><p>这些问题包括之前在 LW 人口普查中提出的历史问题、来自 LW 评论者和我接触到的一些理性主义邻近组织的新问题，以及我好奇的事情。其中包括当我询问有关进行人口普查时，LessWrong 团队成员发给我的一份清单中的问题。</p><p>该调查从现在起至少持续到 2024 年 1 月 1 日。我计划在 1 月 2 日的某个时间结束。</p><p>我不为 LessWrong 工作，据我所知，LessWrong 人口普查的组织者也从来不是为 LessWrong 工作的人。调查结束后，我计划研究这些数据并写<a href="https://www.lesswrong.com/posts/E2koS25u6jajt5uo8/2022-survey-results">一篇像这样的</a>分析文章。</p><p>请记住，您可以通过<a href="https://docs.google.com/forms/d/e/1FAIpQLSc_-Te1a4Q-FuNhwwgSGDwVWCHOWppCrWtKaVrhHcujopy5Lg/viewform?usp=sf_link"><strong>此链接</strong></a><strong>参加调查</strong><strong>。</strong></p><p>曾几何时，有一个传统，如果你参加了调查，你可以在这里评论说你已经这样做了，人们会给你投票，你就会得到业力。</p><br/><br/> <a href="https://www.lesswrong.com/posts/JHeTrWha5PxiPEwBt/2023-unofficial-lesswrong-census-survey#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/JHeTrWha5PxiPEwBt/2023-unofficial-lesswrong-census-survey<guid ispermalink="false"> JHeTrWha5PxiPEwBt</guid><dc:creator><![CDATA[Screwtape]]></dc:creator><pubDate> Sat, 02 Dec 2023 04:41:51 GMT</pubDate></item><item><title><![CDATA[Protecting against sudden capability jumps during training]]></title><description><![CDATA[Published on December 2, 2023 4:22 AM GMT<br/><br/><p> TL;DR：如果法学硕士的能力突然跳跃，并使用不同的测试套件进行测试（例如，可以执行代码或向人类观察者呈现大量文本的测试套件），它可能能够逃脱训练中期。为了防止这种情况发生，我提出了一种分阶段的测试方法，首先使用极其受限的测试套件对模型进行超人能力测试，然后再使用更广泛的测试套件进行测试。</p><h1>失效模式</h1><p>让我们想象一下 GPT-6 突然获得了超人的黑客和操纵技能。在训练期间，会执行一些标准测试来衡量其在各种基准上的性能。一些测试包括在虚拟机上执行代码，其他测试包括生成供人类检查的文本。总共对该模型进行了数千次查询。该模型通过利用测试设置中的漏洞（例如通过勒索人类评估者或在虚拟机中发现漏洞）找到了逃脱的方法，甚至在研究人员注意到它具有超级智能之前。</p><p>这凸显了我担心的一种故障模式：<strong>突然的能力跳跃会导致功能失调且功能强大的人工智能，当使用不同的测试套件进行测试时，它会在实验室注意到它的能力之前找到逃脱的方法。</strong></p><p>出现这种问题的主要原因是人工智能与现实世界有很大的<i>接触面</i>——它有办法影响与其交互的人类和设备。模型越被允许影响世界（无论是通过编写供人类检查的文本，还是在虚拟机上运行代码），模型就越容易接管。我想，如果模型只允许预测 10 个标记的序列而没有其他任何东西，那么它就很难接管。</p><p>理想情况下，实验室可以通过某种方式注意到该模型的能力急剧跃升，而无需给其太多接管机会。万一他们突然出乎意料地与超级智能打交道，希望他们能明智地暂停一下，直到他们确信自己可以安全地继续前进。</p><h1>分阶段测试</h1><p>我认为在前沿模型训练运行期间应该使用分阶段测试。我的意思是<strong>一种测试方法，从极低的表面积测试开始，然后逐渐增加表面积。</strong>这使得我们很容易注意到突然的能力增益，同时降低了模型接管的可能性。</p><p>其他行业也存在类似的做法，新工具在其损害有限的环境中进行测试，然后逐步推广到限制较少的环境中。</p><p>实际上，这可能看起来像：</p><ol><li>从一组测试开始，这些测试最大限度地减少允许模型预测的标记数量以及允许从中采样的标记集。<ol><li>例如，它可能是一组 100 个困难的多项选择题，其中模型实际上只能输出 {A,B,C,D} 之一作为答案，所有其他标记概率都设置为 0。</li></ol></li><li>如果性能高到足以吓到实验室，他们可以在模型造成任何损害之前暂停开发。</li><li>如果性能不够高，不足以吓到实验室，他们可以重复使用限制稍少的测试套件。</li></ol><p>这甚至可能不需要太多额外的工作，因为简单地重新排序现有的测试并添加高测试结果的警报可能就可以达到目的。</p><p>请注意，<strong>这对于假装不是超人的超人法学硕士不起作用</strong>。如果这样的法学硕士要分阶段进行测试，它可能会知道自己的能力不如实际。如果<a href="https://www.lesswrong.com/posts/h7QETH7GMk9HcMnHH/the-no-sandbagging-on-checkable-tasks-hypothesis">“可检查任务上没有沙袋”的假设</a>是正确的，那么我不太担心这一点，因为我们可以使用现有技术来引发超级智能能力。</p><p>另请注意，<strong>这对于超人的法学硕士来说并不适用，</strong>因为即使在极其受限的测试期间或之前，他们也可能能够逃脱。可能存在一些聪明的技巧，例如在 logit 输出数字中编写代码注入，这将非常难以预测和防范。</p><br/><br/> <a href="https://www.lesswrong.com/posts/edutkCwr93stppmNp/protecting-against-sudden-capability-jumps-during-training#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/edutkCwr93stppmNp/protecting-against-sudden-capability-jumps-during-training<guid ispermalink="false"> edutkCwr93stppmNp</guid><dc:creator><![CDATA[nikola]]></dc:creator><pubDate> Sat, 02 Dec 2023 04:22:21 GMT</pubDate> </item><item><title><![CDATA[South Bay Pre-Holiday Gathering]]></title><description><![CDATA[Published on December 2, 2023 3:21 AM GMT<br/><br/><p>伊尔马林之家 (Ilmarin House) 即将举办第三次非结构化假日聚会！会有饼干和简单的小吃；除此之外，这是一顿聚餐，你应该带上你想要的东西（如果有的话）。</p><p>如果您认为一些朋友也会喜欢这个活动，请邀请他们！若能回复，我们将不胜感激。</p><br/><br/> <a href="https://www.lesswrong.com/events/esaDDDkjYDnHrJrLp/south-bay-pre-holiday-gathering#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/events/esaDDDkjYDnHrJrLp/south-bay-pre-holiday-gathering<guid ispermalink="false"> esaDDDkjYDnHrJrLp</guid><dc:creator><![CDATA[IS]]></dc:creator><pubDate> Sat, 02 Dec 2023 03:21:12 GMT</pubDate> </item><item><title><![CDATA[MATS Summer 2023 Postmortem]]></title><description><![CDATA[Published on December 1, 2023 11:29 PM GMT<br/><br/><p> <a href="https://www.matsprogram.org/"><u>ML 对齐和理论学者</u></a>计划（MATS，以前称为 SERI MATS）是一项针对新兴人工智能安全研究人员的教育和研究指导计划。今年夏天，我们举办了第四次MATS项目，60名学者得到了15位研究导师的指导。在这篇文章中，我们解释了该计划的要素，列出了它们背后的一些想法，并评估了我们的影响。</p><h1>概括</h1><p>有关 2023 年夏季计划的主要详细信息：</p><ul><li> MATS 学者的教育程度：<ul><li> 30%的学者是学生。</li><li> 88% 至少拥有学士学位。</li><li> 10% 正在攻读硕士学位。</li><li> 10% 正在攻读博士学位。</li><li> 13%拥有博士学位。</li></ul></li><li>如果没有 MATS，学者们可能会在科技公司工作（41%）、独立提升技能（46%）或在整个夏天独立进行研究（50%）。 （注：这是一个多项选择题。）</li></ul><p>我们的影响评估的主要结论：</p><ul><li> MATS 学者很有可能向朋友或同事推荐 MATS。平均可能性：8.9/10。</li><li> 94% 的学者的导师对他们继续研究的热情评价为 7/10 或更高。</li><li> MATS 学者对他们的导师评价很高。平均评分：8.0/10。<ul><li> 61% 的学者表示，MATS 的价值至少一半来自他们的导师。</li></ul></li><li>学者们表示，在 MATS 之后，与项目开始时相比，他们在成功调整职业方面面临的障碍更少。<ul><li>大多数学者（75%）在项目结束时仍然将他们的发表记录视为成功对齐职业的障碍。</li></ul></li><li> ⅓ 的最终项目涉及评估/演示，⅕ 涉及机械解释性，代表了该群体研究兴趣的很大一部分。</li><li>学者们自我报告研究能力平均有所提高：<ul><li>他们的人工智能安全知识的广度略有增加（在该计划的 10 分制中+1.75）。</li><li>与反事实夏季相比，技术技能得到适度加强（7.2/10，其中 10/10 是“与反事实夏季相比显着提高”）。</li><li>独立迭代研究方向的能力（7.0/10，其中 10/10 表示“显着改进”）和为研究发展变革理论的能力（5.9/10，其中 10/10 表示“实质性发展”）有适度提高）。</li></ul></li><li>典型的学者报告平均建立了 4.5 个专业联系（标准偏差 = 6.2）并会见 5 个潜在的研究合作者（标准偏差 = 6.8）。</li><li> MATS 学者可能会推荐学者支持，即我们的研究/生产力辅导服务。平均响应：7.9/10。<ul><li>处于研究阶段的 60 名学者中有 49 名至少与学者支持专家会面一次。</li><li>在整个项目期间，至少与学者支持会面一次的学者平均花费 3.4 小时与学者支持会面。</li><li>平均学者和中位数学者报告称，他们对收到的学者支持的评价分别为 3705 美元和 750 美元。</li><li>据报告，由于学者支持，学者平均在夏季获得了 22 个高效工作时间。</li></ul></li></ul><p>我们计划对 2023-24 冬季组的 MATS 进行主要更改：</p><ul><li>申请过程中更好的过滤；</li><li>将学者支持的重点转向研究管理；</li><li>为学者提供其他形式的支持，特别是技术支持和专业发展。</li></ul><p>请注意，现在评估 MATS 为最新一批人提供的任何职业福利还为时过早；即将对 MATS 校友在项目体验后 6-12 个月内的职业成果进行全面的后评估。</p><h1>变革理论</h1><p>MATS 通过让学者在现有组织中从事人工智能安全工作、建立新组织或进行独立研究，帮助扩大人工智能安全研究的人才渠道。为此，MATS 为学者提供资金、住房、培训、办公空间、研究援助、交流机会和后勤支持，减少高级研究人员接受学员的障碍。通过指导 MATS 学者，这些高级研究人员还可以从研究援助中受益，并提高他们的指导技能，为他们更有效地监督未来的研究做好准备。请<a href="https://www.lesswrong.com/posts/8vLvpxzpc6ntfBWNo/seri-ml-alignment-theory-scholars-program-2022#Theory_of_change"><u>在此处</u></a>阅读有关我们变革理论的更多信息。进一步扩展我们的变革理论的文章即将推出。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/srup6vfrbmgjh3zzshlq"></p><p> MATS旨在主要从三个维度选拔和培养研究学者：</p><ul><li><strong>深度</strong>：对人工智能安全研究的专业领域有透彻的了解，并有足够的技术能力（例如，机器学习、计算机科学、数学）来开展该领域的新颖研究。</li><li><strong>广度</strong>：广泛熟悉人工智能安全组织和研究议程，拥有来自不同子领域的有用定理和知识的大型“工具箱”，以及进行文献综述的能力。</li><li><strong>品味</strong>：对研究方向和策略的良好判断，包括首先采取哪些步骤、质疑哪些假设、考虑哪些新假设以及何时停止从事某项研究。 </li></ul><figure class="image image_resized" style="width:50.94%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/psu31uwjpsyeyn9ylynw"></figure><h1> MATS 2023 年夏季项目概述</h1><h2>日程概览</h2><p>2023 年夏季的 MATS 项目由三个阶段组成。</p><ol><li><strong>培训阶段：</strong>接受远程培训阶段的学者在讨论小组中完成了<a href="https://aisafetyfundamentals.com/alignment-201-curriculum"><u>Alignment 201</u></a> ，并学习了导师分配的其他教育材料。</li><li><strong>研究阶段：</strong>在伯克利研究阶段，学者们进行研究，提交书面的“学者研究计划”（SRP），开展项目，与湾区人工智能安全社区建立联系，与合作者建立联系并合作，并向同行和专业研究人员的观众。</li><li><strong>扩展阶段：</strong>许多学者申请了伦敦和伯克利的扩展阶段，他们在 MATS 的支持下继续进行研究。 </li></ol><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/klix3pwxa6vfnmymlom4"></p><h2>计划要素</h2><p>虽然指导仍然是 MATS 的核心，但我们选择了额外的计划元素来涵盖其他形式的学习和技能提升。我们根据技能提升/支持重点是技术级别还是元级别以及形式是一对一还是一对多对这些计划元素进行分类。 </p><figure class="image image_resized" style="width:52.68%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/gczi0b5zdiuldemdmfcn"></figure><h3>学者支持</h3><p>MATS 的学者支持团队旨在通过持续的、定制的支持来补充指导，从而提高 MATS 研究和推广阶段的学者成果。</p><p><strong>为何获得学者支持？</strong></p><p>确定导师未涵盖的支持形式有可能在提高计划的整体影响方面发挥重要作用。根据在 MATS 之前迭代中与学者的观察和对话，我们认为学者的支持会增加显着的附加价值，原因如下：</p><ol><li><strong>导师有时间限制。</strong>导师通常只有足够的时间（例如每周约 1-2 小时）与学者讨论其研究的技术组成部分。学者支持可以帮助学者明确哪些形式的导师支持对他们最有价值，然后提供导师在有限的时间内无法获得的其他形式的支持，从而实现更有效的导师互动。</li><li><strong>学者有时不愿意寻求导师的支持。</strong>由于导师会评估受训者在 MATS 内的进展情况（也可能是向外部资助者），因此学者们可能会不愿意揭露他们正在经历的问题。为了解决这个问题，学者支持与包括导师在内的评估者的支持 <a href="https://www.lesswrong.com/posts/ehLR9HeXB5TMp9Y4v/air-gapping-evaluation-and-support"><u>存在差距</u></a>。</li><li><strong>导师可能不适合为技术研究提供不太专业的支持，例如职业指导或生产力建议。</strong>相比之下，学者支持可以聘请精通这些领域的教练。</li></ol><p><strong>学者支持重点领域的示例</strong></p><p>学者支持以不同的方式帮助不同的学者，但以下非详尽列表代表了 1-1 学者支持会议中通常讨论的内容：</p><ul><li><strong>研究项目开发和管理：</strong>帮助确定可能的研究方向、决定研究方向并完成研究项目。</li><li><strong>提高生产力：</strong>寻找方法让学者每天（可持续地）花更多时间进行研究或提高研究时间的质量。</li><li><strong>职业指导：</strong>确定不同的职业选择，确定做出这些决定时需要考虑的关键因素，并增加职业成功的机会（例如，通过网络和技能发展）。</li><li><strong>改善与导师和合作者的沟通。</strong></li></ul><h3>工作坊</h3><p>我们举办了九场研讨会，主题如下：</p><ul><li>症结分解；</li><li>研究变革理论；</li><li>里程碑： <a href="https://docs.google.com/document/d/1fQwy2btcWn3XRQkgu45kKnPPHMVQs28QHpaNtDCfXQY/edit"><u>学者研究计划</u></a>；</li><li> <a href="https://forum.effectivealtruism.org/posts/edgvFNzHFQoMv3KsL/personal-health-is-instrumental-to-being-effective"><u>预防和管理倦怠</u></a>；</li><li>拨款申请+预算；</li><li>使用<a href="https://github.com/socketteer/loom"><u>Loom</u></a>探索基本模型；</li><li>研究合作者快速会议；</li><li>里程碑： <a href="https://docs.google.com/document/d/1SB_vl6pGuSO7qidkZ8fIKPeH7fZIC8mvXzxicFjGyrE/edit"><u>学者座谈会</u></a>；</li><li>职业规划和离职。</li></ul><p>此外，学者支持人员还举办了几次开放办公时间会议，以研讨学者的写作和演示。</p><h3>社交活动</h3><p>除了合作者快速会议研讨会之外，我们还提供了一些社交活动：</p><ul><li>与<a href="https://far.ai/labs/"><u>FAR 实验室</u></a>成员共进晚餐；</li><li>与<a href="https://www.constellation.org/"><u>星座</u></a>成员共进晚餐；</li><li>招聘会有 12 个组织和独立研究人员参加；</li><li>湾区人工智能安全社区的许多成员参加了三场聚会。</li></ul><h3>研讨会</h3><p>我们举办了 23 场研讨会，演讲嘉宾包括：Buck Shlegeris、Rick Korzekwa、Tom Davidson、Tamsin Leake、Victoria Krakovna、Daniel Paleka、Jeffrey Ladish、Adam Gleave、Steven Byrnes、Daniel Filan、Tom Everitt、William Saunders、Lennart Heim、Usman Anwar、 Neel Nanda、Dylan Hadfield-Menell、Ryan Greenblatt 和 Evan Hubinger、Mauricio Baker、Nora Ammann、Anthony DiGiovanni、Marius Hobbhahn、Paul Colognese 和 Arun Jose、Ajeya Cotra。</p><h3>社区健康</h3><p>学者们可以与社区经理联系，讨论社区健康问题，例如与另一位学者或其导师的冲突，并提供情感支持和转介心理健康资源。我们认为，冒名顶替综合症等心理健康问题和多动症等未确诊的疾病可能会成为进入人工智能安全领域的障碍，因此 MATS 等项目在这些领域提供支持非常重要。我们的目标是为学者提供技能和资源，让他们在离开 MATS 后保持积极性并可持续地工作。</p><p>我们认为，人际冲突、心理健康问题和缺乏联系会导致消极的工作环境，减少学者可以分配给研究的认知资源，并阻碍富有成效的研究合作，从而抑制研究<a href="https://forum.effectivealtruism.org/posts/edgvFNzHFQoMv3KsL/personal-health-is-instrumental-to-being-effective"><u>生产力</u></a>。即使不寻求社区健康支持的学者也能从这个安全网的存在中受益（参见下面<a href="https://docs.google.com/document/d/1vgqW_1FIKP4prZXQXa2UIteI7-zUL4klspJjdE2tWCw/edit#heading=h.mbcjjw5l0ho5"><u>的评估计划要素</u></a>）。与学者支持一样，MATS 等项目必须允许 <a href="https://www.lesswrong.com/posts/ehLR9HeXB5TMp9Y4v/air-gapping-evaluation-and-support"><u>评估和社区健康之间存在差距</u></a>，以激励学者在需要时寻求帮助。</p><p>社区经理还组织了社交活动，以促进群体内部的联系，包括为来自代表性不足的背景的学者举办的四次郊游。</p><h2>导师遴选</h2><p>在为 MATS 选择导师时，我们的目标主要是支持那些很有可能通过研究降低人工智能灾难性风险的导师，同时采取“组合方法”进行风险管理。我们的目标是支持多样化的“研究赌注”，即使某些组成研究议程被证明不可行，这些赌注也可能为人工智能安全带来一些好处，并提供可能有助于潜在<a href="https://en.wikipedia.org/wiki/Paradigm_shift"><u>范式转变</u></a>的“探索价值”。</p><p>我们的导师选择流程要求潜在导师提交一份意向表，然后由 MATS 执行人员进行审核。在决定支持哪些导师时，我们主要考虑：</p><ol><li>这项研究议程可以在多大程度上减少人工智能带来的灾难性风险？</li><li>支持这项研究议程会产生多少“探索价值”？</li><li>此人有多少研究和指导经验？</li><li>如果这个人没有得到 MATS 的支持，他的反事实会是什么？</li><li>支持这个人及其学者如何影响更广泛的人工智能安全生态系统中的思想和人才的发展？</li></ol><p>由于 MATS 在 2023 年夏季资金有限，因此我们对该项目的学者数量也存在财务限制。因此，学者“名额”根据 MA​​TS 执行官对每个导师的边际价值感分配给导师（直至其自我表达的上限）。例如，可能值得支持一位经验丰富的导师，其自我表达的上限为四名学者，有四个学者名额，然后再支持一位经验不足的导师，有一个学者名额，无论其上限如何。相反，与一位学者一起支持一位新导师可能比与第八位学者一起支持一位经验丰富的导师具有更高的边际价值。</p><p>在 2023 年夏季项目的 15 名导师中，有 10 名从 2022-23 年冬季项目回归：Alex Turner、Dan Hendrycks、Evan Hubinger、John Wentworth、Lee Sharkey、Jesse Clifton、Neel Nanda、Owain Evans、Victoria Krakovna 和 Vivek赫巴尔。今年夏天我们迎来了 5 位新导师：Ethan Perez、Janus、Nicholas Kees Dupuis、Jeffrey Ladish 和 Claudia Shi。</p><p>这些导师代表了十几个研究议程：</p><ul><li>调整语言模型</li><li><a href="https://www.lesswrong.com/tag/agent-foundations"><u>代理基金会</u></a></li><li><a href="https://www.lesswrong.com/tag/consequentialism"><u>结果主义</u></a>认知和深层约束</li><li><a href="https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism"><u>电子人主义</u></a></li><li><a href="https://www.lesswrong.com/tag/deceptive-alignment"><u>欺骗性人工智能</u></a></li><li><a href="https://www.lesswrong.com/tag/ai-evaluations"><u>评估危险能力</u></a></li><li><a href="https://en.wikipedia.org/wiki/Interdisciplinarity"><u>跨学科</u></a>人工智能安全</li><li><a href="https://www.lesswrong.com/tag/interpretability-ml-and-ai"><u>机械解释性</u></a></li><li><a href="https://www.lesswrong.com/tag/multipolar-scenarios"><u>多极人工智能安全</u></a></li><li>语言模型中的<a href="https://www.lesswrong.com/tag/power-seeking-ai"><u>权力寻求</u></a></li><li><a href="https://www.lesswrong.com/tag/shard-theory"><u>碎片理论</u></a></li><li>了解人工智能黑客</li></ul><h2>学者选拔</h2><p>我们最初的学者申请流程竞争非常激烈。在 461 名申请者中，有 69 名被接受进入培训阶段（接受率 ≈ 15%）。导师之间的接受率存在显着差异（0% 到 31% 之间）。导师通常会选择通过严格的问题和任务来筛选申请人。 <span class="footnote-reference" role="doc-noteref" id="fnref2niy7evweco"><sup><a href="#fn2niy7evweco">[1]</a></sup></span></p><p>为什么要采用如此困难的申请流程？首先，我们认为未来学者的预期影响力的分布是长尾的，因此 MATS 的大部分预期影响力可归因于培养最有前途的学者的人才。 </p><figure class="image image_resized" style="width:47.84%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/qng5orgyn5u1rqaiisex"></figure><p>其次，我们主要是在导师时间上遇到瓶颈，所以我们不可能接受每一个好的候选人。由于这两个原因，我们的申请流程必须在人才尾部实现解决方案。根据我们的<a href="https://www.lesswrong.com/posts/8vLvpxzpc6ntfBWNo/seri-ml-alignment-theory-scholars-program-2022#Theory_of_change"><u>变革理论</u></a>：</p><p>我们相信我们的限制是指导时间。这意味着我们希望有强大的过滤机制（例如候选人选择问题）以确保每个申请人都适合每个导师。我们宁愿冒拒绝强参与者的风险，也不愿接纳弱参与者。</p><p>确实，一位导师没有收到任何符合他们标准的申请，因此他们没有接受任何学者。</p><p>我们严格的申请流程可以减少申请人质量评估中的噪音，即使这样做的代价是阻止一些潜在有前途的候选人申请。额外的过滤器减少了从培训阶段（两名导师）进入研究阶段的学者数量，然后在扩展阶段之前再次减少。 </p><figure class="image image_resized" style="width:38.06%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/tmibmqxlrpzmxmbvbze5" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/hsq1bwnkzrako3m45vcw 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/isyklkfzwzeyhhxwwt8m 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/fpkj5ns3996vzhwziwgh 250w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/wj5m8v07rkw3del0lqk2 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/shcgfb79noh6ovkczhhm 410w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/eq77mnop2fx1bo8gt1tn 490w"></figure><p>共有 60 名学者参与研究阶段：50 名现场学者和 10 名远程学者。</p><h3>学者的教育程度</h3><p>该群体包括各种教育和就业背景。 37%的学者最多拥有学士学位或以下学位，40%的学者最多拥有硕士学位或在读硕士，23%的学者拥有博士学位或在读博士。大约三分之一的学者是学生。 </p><figure class="image image_resized" style="width:70.24%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/u25u6qwh08zvysy355kw"></figure><p>请注意，由于我们要求学者的<i>最高</i>教育程度，因此该图中的类别是相互排斥的。总体而言，进入人工智能安全领域的高水平学术和工程人才给我们留下了深刻的印象，但我们仍致力于扩大对经验丰富的研究人员和工程师的接触。</p><h3>反事实的夏天</h3><p>根据他们的自我报告，如果这些学者没有参加 MATS，他们的反事实暑假可能会涉及在科技公司工作、独立提高技能或独立进行研究。 </p><figure class="image image_resized" style="width:69.43%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/p1fc4dak9irsmawocrra"></figure><p> 13 名学者表示，如果不参加 MATS，他们可能会进行指导性研究，其中 10 名是学生，6 名正在攻读研究生学位。受访者详细阐述了他们的替代夏季计划，其中一些人提到了人工智能安全领域之外的研究指导选项或结构较少、指导较少的技能提升：</p><ul><li> “我正在写我的博士论文（纯数学，可能与对齐无关）。”</li><li> “如果没有 MATS，我不太可能从事如此有影响力的项目，或者处于如此陡峭的 L&amp;D 曲线上。”</li><li> “我会和同一个导师一起实习，但只是远程实习。所以我会做同样的事情，但环境要糟糕得多。不确定我是否会很有成效，或者取得什么成就。”</li><li> “我可能会去申请、提高技能、和朋友一起工作。总的来说，我的工作量会少很多。”</li><li> “我将以非主导角色支持机器学习能力研究。”</li></ul><p>共有 17 名学者填写了一项可选调查，要求他们将反事实暑假的价值与他们从 MATS 中获得的价值进行比较。九人表示，如果没有 MATS，他们的时间会“不太有用”，八人表示，他们的时间会“不太有用”。</p><h2>培训阶段（6月5日-6月30日）</h2><p>共有69名学者进入培训阶段。在指定助教的四场会议上，学者们完成了人工智能安全基础知识<a href="https://aisafetyfundamentals.com/alignment-201-curriculum"><u>对齐 201 课程</u></a>。这些讨论组使学者们对参与同行学者的研究、访问演讲者的演讲以及人工智能安全生态系统中不同组织的工作有了必要的广泛熟悉。然而，大约25%的学者没有参加任何一个讨论组，只有大约15%的学者参加了所有四个讨论组的会议。这可能是因为许多导师在其学科领域分配了自己的培训课程（例如阅读清单），并且一些导师明确告诉学者不要优先考虑对齐 201。</p><p>部分导师提前选择在训练阶段结束后进行一轮额外筛选，因此只有60名学者继续进入研究阶段。 <span class="footnote-reference" role="doc-noteref" id="fnrefvp0h93gzvk"><sup><a href="#fnvp0h93gzvk">[2]</a></sup></span></p><h2>研究阶段（7月10日 - 9月1日）</h2><p>在研究阶段，学者们在导师的指导下开展人工智能安全研究。大多数学者在加利福尼亚州伯克利毗邻<a href="https://www.constellation.org/"><u>Constellation 的</u></a>办公室里亲自工作，这使得 Constellation 以外的导师和研讨会演讲者可以轻松过境。</p><h3>指导风格</h3><p>导师们采用不同的方法来设定研究方向和指导项目。根据一项学者调查，大约 1/4 的学者对其研究方向拥有“完全的创造性控制”，大约 1/4 的学者从名单中挑选或被分配一个项目，剩下的 1/2 介于两者之间。</p><p>在参与项目底层实施细节方面，指导风格也有所不同。根据对学者的调查，导师大致呈双峰分布，大约一半的学者表示，他们的导师只讨论研究项目的高层细节，另一半学者表示，他们的导师更多地参与低层细节。研究层面的实施细节。 </p><figure class="image image_resized" style="width:70.91%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/kxcbn1d3qvmmfikg9eoz"></figure><p>我们还注意到导师的双峰分布基于每周与学者交流的时间（但是，这两个指标与导师无关）。 </p><figure class="image image_resized" style="width:70.67%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/bw5qganpngq7hc8t1o9r"></figure><p>一些来自不同流派的学者在项目上进行了合作。有时，学者们会转而与更适合他们兴趣和需求的导师一起工作。</p><h3>学者支持</h3><p>我们的学者支持团队由五位研究/生产力教练组成，他们在研究策略、职业规划、人际沟通和研究技能提升方面提供帮助（参见上面的<a href="https://docs.google.com/document/d/1vgqW_1FIKP4prZXQXa2UIteI7-zUL4klspJjdE2tWCw/edit#heading=h.d8f3mdy3o2th"><u>计划要素</u></a>）。</p><ul><li>共有 49 名学者在研究阶段预订了学者支持会议，其中 35 名学者多次使用学者支持。</li><li>在整个项目期间，至少与学者支持会面一次的学者平均花费 3.4 小时与学者支持会面。</li><li>学者们总共花费了 160 个小时参加了 197 场学者支持会议。</li><li>十位学者占所有学者支持时间的一半。 </li></ul><figure class="image image_resized" style="width:69.75%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/uxllwospe38xmermwkib"></figure><p>使用学者支持的 49 名学者中有 28 名提供了书面反馈。这些学者报告发现以下内容特别有用：</p><ul><li>职业规划和建议（28%）；</li><li>任务优先级（25%）；</li><li>一般问题解决（14%）；</li><li>被追究责任（10%）；</li><li>拖延症建模工具（10%）；</li><li> <a href="https://www.lesswrong.com/posts/kvLPC5YWgSujcHSkY/how-to-play-a-support-role-in-research-conversations"><u>橡皮鸭</u></a>(7%)；</li><li>克服拖延症（7%）</li><li>提高与导师和同事的沟通技巧（7%）；</li><li>有用的提问（7%）。</li></ul><h3>研究里程碑</h3><p>研究阶段进行到一半时，每位学者都需要提交一份学者研究计划（SRP）。在他们的 SRP 中，学者们被要求概述人工智能<a href="https://www.lesswrong.com/tag/threat-models"><u>威胁模型</u></a>或推动他们研究的<a href="https://arxiv.org/abs/2206.05862"><u>风险因素</u></a>、解决该威胁模型<a href="https://en.wikipedia.org/wiki/Theory_of_change"><u>的变革理论</u></a>，以及制定该变革理论的项目的<a href="https://en.wikipedia.org/wiki/SMART_criteria">SMART</a>计划。 MATS 团队的一名成员和七名校友根据提供的 <a href="https://docs.google.com/document/d/1fQwy2btcWn3XRQkgu45kKnPPHMVQs28QHpaNtDCfXQY/edit"><u>评分标准</u></a>对 SRP 进行了评分，以帮助告知扩展阶段的接受决定（见<a href="https://docs.google.com/document/d/1vgqW_1FIKP4prZXQXa2UIteI7-zUL4klspJjdE2tWCw/edit#heading=h.lujivdy8efi4"><u>下文</u></a>）并为学者提供建设性反馈。 </p><figure class="image image_resized" style="width:44.94%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/nffyurqwksgj7wqzmtia" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/xji7hx8eh0mbe7xavnqb 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/wtdngl6sutwq3hkfcvkj 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/tnljbcj1svmurah5hs8w 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/rbxhpjdkmqkzlffqocrv 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/kwytqiyv8eqgtlsc6zm4 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/i5zlme9xikfuwxob6vvi 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/dtgqcm11xql90rd8kpux 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/dixfaddh4cujlmwgd5a8 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ivomn6dzles1c1tw32wd 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/mlbmmqkurxconppsyypd 1424w"></figure><p>我们需要学者研究计划的三个主要原因：</p><ol><li>培养学者为目标导向的研究策略做出贡献的能力；</li><li>评估学者是否接受扩展阶段；</li><li>使学者更容易撰写后续资助提案。</li></ol><p>许多学者选择在资助申请中使用其 SRP 的组成部分，向<a href="https://funds.effectivealtruism.org/funds/far-future"><u>长期未来基金</u></a>(LTFF) 申请 MATS 后的资助支持。 LTFF 资助者托马斯·拉森 (Thomas Larsen) 举办了一次研讨会，在研讨会上他回答了 MATS 学者有关 LTFF <a href="https://forum.effectivealtruism.org/posts/7RrjXQhGgAJiDLWYR/what-does-a-marginal-grant-at-ltff-look-like-funding"><u>决策过程</u></a>和<a href="https://forum.effectivealtruism.org/posts/PAco5oG579k2qzrh9/ltff-and-eaif-are-unusually-funding-constrained-right-now"><u>资金限制</u></a>的问题。</p><p>研究阶段以为期一天的研讨会结束，学者们在研讨会上向同行和伯克利人工智能安全社区的成员就他们的研究项目进行了 10 分钟的演讲。</p><h3>讲习班、研讨会、社交活动</h3><p>我们举办了 23 场邀请演讲嘉宾的研讨会、九场培养学者研究能力的研讨会，以及每周的社交和社交活动。我们还每周举行闪电演讲会议，许多学者发表了非正式的、五分钟的研究报告。在我们的招聘会之前，有 12 家组织和独立研究人员参加，24 名学者填写了一份调查，了解他们最希望在活动中看到哪些组织。他们的回答提供了有抱负的人工智能安全研究人员当前职业兴趣的概况。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/rjqnxjfozzhkrqkwfcmj"></p><p> Note that some organizations working on AI safety are not represented here (eg, <a href="https://deepmind.google/">Google DeepMind</a> , <a href="https://www.apolloresearch.ai/">Apollo Research</a> , <a href="https://www.governance.ai/">GovAI</a> ) as we were not aware of any representatives in Berkeley at the time.</p><h3>社区健康</h3><p>大约 15% 的学者负责与社区经理的大部分会议，大约一半的学者只与社区经理会面一次。</p><p>学者们报告了社区经理如何在以下方面提供帮助：</p><ul><li>情感支持;</li><li>探望我担心的人；</li><li>讨论冲突或不舒服的互动；</li><li>讨论该计划如何对我来说更好；</li><li>医疗帮助（转诊至诊所、帮助治疗疾病/受伤）。 </li></ul><figure class="image image_resized" style="width:76.12%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/tzheowwao5qymskvp6oe"></figure><h2>延长阶段（9月18日至1月1日）</h2><p>研究阶段结束后，一些学者申请进入推广阶段。扩展阶段旨在支持学者们在导师和 MATS 在研究阶段提供的结构中获得更大的自主权来开展他们的研究项目。</p><p> MATS 执行团队主要根据导师的认可、SRP 成绩以及他们是否为自己的研究获得独立资助来接受学者进入扩展阶段。来自外部组织（通常是 LTFF 或开放慈善事业）的资金是这一过程的重要投入，因为它提供了对学者研究质量的外部评估。在 33 名申请的学者中，25 名被录取进入扩展阶段（录取率：76%）。</p><p>共有 16 名学者参加<a href="https://safeai.org.uk/"><u>伦敦安全人工智能倡议 (LISA)</u></a>为期四个月的扩展阶段，其中两名来自<a href="https://far.ai/labs/"><u>FAR 实验室</u></a>在伯克利继续学习，七名学者正在远程工作。我们还为学者提供了在布拉格<a href="https://fixedpoint.house/"><u>固定点</u></a>工作的选择。</p><p>在延期期间，我们期望学者们将他们的研究项目正式化为他们的第一份出版物，并开始规划他们未来的职业方向。为了在这方面为他们提供支持，我们继续提供日常生产力支持（例如，每日站立会议、学者支持调试、1-1 职业指导），并且我们举办了各种研讨会、讲习班和社交活动，特别是面向 LISA 办公室的学者。这一切都是为了让学者们做好准备，从 MATS 项目的支持环境中过渡出来，通过经常提醒他们进一步制定长期计划，并建立新的联系来帮助他们推进这些计划。一直以来，我们都期望学者能够得到导师的持续支持，尽管在大多数情况下频率会降低。</p><h1> 2023 年夏季 MATS 评估</h1><p>在本节中，我们概述了学者们如何评价该计划的不同要素以及我们如何评估我们的影响。</p><h2>评估计划元素</h2><h3>对齐201</h3><p>学者们报告了完成<a href="https://course.aisafetyfundamentals.com/alignment-201">Alignment 201 课程的</a>广泛价值分配。平均评分为 6.8/10，<a href="https://www.qualtrics.com/experience-management/customer/net-promoter-score/">净推荐值为</a>-18。 </p><figure class="image image_resized" style="width:71.72%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/pk5nhrqbpuxlzke1wgak"></figure><p>在书面反馈中，多位学者将课程的大部分价值归因于辅导员的经验和洞察力。进入该课程的学者们有着不同的背景和学习偏好：一位受访者表示，他们小组的对话没有他们希望的那么先进；另一位则提到希望学习节奏较慢的课程。一位受访者赞赏他们的辅导员建议的文章；另一位更喜欢学术论文和正式论文。一位学者提到，要努力平衡课程与导师的竞争性要求。</p><h3>总体方案</h3><p>总体而言，学者们在回答“从 1 到 10 的范围内，您向朋友或同事推荐 MATS 的可能性有多大”这一问题时，对研究阶段的评价相当高。 <span class="footnote-reference" role="doc-noteref" id="fnrefnsczgjuthnr"><sup><a href="#fnnsczgjuthnr">[3]</a></sup></span>平均回应率为 8.9/10，没有人报告低于 6/10。<a href="https://www.qualtrics.com/experience-management/customer/net-promoter-score/">净推荐</a>值为 69。 </p><figure class="image image_resized" style="width:75.19%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/zmzndsy4dlfggpjubhjv"></figure><h3>指导的价值</h3><p>总体而言，导师的评价很高，平均评分为 8.0/10，<a href="https://www.qualtrics.com/experience-management/customer/net-promoter-score/">净推荐分数</a>为 29。61% 的学者表示，MATS 的价值至少有一半来自他们的导师。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/vxzr4itr8yloxu8s4uei" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/qbhl6tskvtznddj5oxrh 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ygidoqbafyk6ljbpnjpj 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/saguqu5b2ikuvuen47g0 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/rpkg2sxlbese75ik4vkm 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/uec4crmh8bbooni6llv6 1100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ismpi1ohyakuzxa9q7ni 1320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ssk6wk9zvn7i8ohxp7jh 1540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ah1gajhkuki90spn4tey 1760w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ws62tofuflqbqasuujk6 1980w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ozzhdigdrcpqapravnc3 2176w"></figure><p>鉴于导师学者评级的负偏分布，学者评级导师对 MATS 价值的贡献如此多样化可能会令人惊讶。造成这种差异的原因是一些学者对其他价值来源给予了较高的重视；即接触该群体和更广泛的伯克利研究社区。</p><p>学者们详细阐述了导师使他们受益的方式：</p><ul><li> <strong>90%</strong> — “我认为 [MATS] 的 90% 以上的效果是通过获得 [导师] 时间并与他讨论我的研究，注意到对各种事情的轻微误解。”</li><li> <strong>70%</strong> —“[我的导师]给了我很多时间，并且很好地传授了他的很多思考研究的思维过程。他向我介绍了几个与我进行过宝贵会面的人。我想，如果我没有受到[我的导师]研究品味的引导，我可能会从事前景黯淡得多的事情。”</li><li> <strong>65%</strong> —“从高级线性代数到一般研究方向和信息危害问题，[我们的导师]对我们的研究非常出色。”</li><li> <strong>50%</strong> —“[我的导师]花了很多时间与我们讨论我们的研究，并就方向提出了很好的建议。他以各种方式为我们解除了障碍，例如获得更多模型或大量计算预算。他让我们认识了很多伟大的人，其中一些人成为了合作者。他是一位非常鼓舞人心的合作导师。”</li><li> <strong>40%</strong> —“从高级线性代数到一般研究方向和信息危害问题，[我的导师]对我们的研究非常出色。”</li><li> <strong>20%</strong> —“导师向我们（团队）介绍了一些志同道合的人，监督了这个项目（但大多数人都在倾听，没有干预），还审阅了我们的论文并组织了一次外部评审。”</li><li> <strong>10%</strong> —“提出了我不会想出的有趣的想法/反对意见。”</li></ul><p>值得注意的是，这些学者中的许多人将 MATS 的价值归因于他们的导师的比例很低，但仍然对他们的导师给予相当积极的评价。</p><p>在控制了学者对其导师的评分后，将 MATS 的更多价值归因于导师与以下因素相关：</p><ul><li>报告说，如果没有 MATS，他们整个夏天都会在联盟组织工作，这与事实相反；</li><li>在项目开始时报告出版记录是一个职业障碍，但在项目结束时却不是。</li></ul><p>这表明，与直接指导相比，那些已经与联盟领域有一定联系的学者，例如通过之前的实习或培训计划，从与伯克利社区及其同行的联系中获得的价值较小。它还表明，导师对于在整个项目中成功发表研究成果的学者来说尤其有价值。</p><p>将 MATS 的价值归因于指导较少与以下因素相关：</p><ul><li>报告发展变革理论的能力得到提高；</li><li>报告由于学者支持辅导而提高了工作效率。</li></ul><p>这表明，学者支持和其他旨在促进变革理论思维的计划要素是学者们的两个重要的非导师价值来源。</p><h3>学者支持的价值</h3><p><strong>总体评价</strong></p><p>我们询问了至少参加过一次学者支持会议的学者，“按照 1 到 10 的评分标准，您向未来的学者推荐学者支持的可能性有多大？”平均反应为 7.9/10，<a href="https://www.qualtrics.com/experience-management/customer/net-promoter-score">净推荐分数</a>为 28。 </p><figure class="image image_resized" style="width:70.28%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/rqke77gqvu1g6525jbir"></figure><p><strong>以指导支持为基准进行比较</strong></p><p>由于学者支持人员的聘用是因为他们能够以各种方式熟练地指导和支持学者，因此我们通过询问学者来检查这一点：“如果您的导师有时间的话，他们可以提供多少学者支持价值？”得到的答复是：</p><ul><li>几乎没有任何价值 - 35%</li><li>部分价值 - 50%</li><li>几乎所有价值 - 15%</li></ul><p>我们还询问了学者，如果他们提出要求，他们是否认为导师会给他们更多的支持时间； 55% 的人表示“可能不会”或“绝对不会”。这两个回应支持了我们关于学者支持价值的理论，即：</p><ul><li>在某些相关领域，专业教练可以提供比许多导师更好的支持；</li><li>导师有时间限制。</li></ul><p><strong>授予同等估值</strong></p><p>我们询问了至少参加过一次学者支持会议的学者，“假设您获得了一笔资助，而不是在 MATS 期间接受 1-1 次学者支持会议，那么您需要获得多少资金才能在资助和辅导之间保持中立？ ” <span class="footnote-reference" role="doc-noteref" id="fnrefhdw3lym1fyo"><sup><a href="#fnhdw3lym1fyo">[4]</a></sup></span>平均响应和中位数响应分别为 3705 美元和 750 美元。回复 40,000 美元的学者证实这个数字不是拼写错误，并引用了“优先顺序、项目选择、协调导航和一般人工智能景观、职业建议、困难期间的支持、针对特定会议和项目的单独定制建议”的支持。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/f4obyvjblzwcaed53gdf"></p><p><strong>获得生产时间</strong></p><p>我们询问了至少参加过一次学者支持会议的学者，“在过去 8 周内，您估计由于您的学者支持会议，您的工作效率提高了多少个小时？”平均反应时间和中位反应时间分别为 22 小时和 8 小时。回复总数为 658 个小时的生产时间。</p><h3> Workshops &amp; Seminars</h3><p>学者们报告了参加研讨会和社交活动的价值。请注意，有些活动的受访者很少，因为我们通过可选调查收集了这些反馈。 10/10 是我们规模的一个高标准，代表着学者计划的重大更新。 </p><figure class="image image_resized" style="width:69.86%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/lfewckjuinmojngzjnli"></figure><p>学者们按照同样的 10 分制对外部演讲者事件进行评分。在 23 场研讨会中，11 场为面对面研讨会，11 场为远程研讨会，1 场为混合研讨会。现场研讨会的评分比远程研讨会高 0.9 分 (p = 0.0088)。 </p><figure class="image image_resized" style="width:70.33%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/somf49ymrg6ewflu2pgu"></figure><p>在其他条件相同的情况下，我们会选择现场研讨会而不是远程研讨会，但对这些形式的价值的分析因哪些研究人员恰好居住在湾区以及学者如何自我选择参加讲座而变得混乱。几位学者举办了自己的研讨会，即使与经验丰富的研究人员举办的研讨会相比，这些研讨会也得到了同行的好评。</p><h3>社区健康</h3><p>尽管许多学者没有使用社区健康支持，但少数学者受益匪浅。为了调查这些好处，我们向学者们询问了两个与我们评估学者支持相同的问题，以及一个关于他们的福祉的问题。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/ewbughz2oiqgsib1ixsx"></p><p>平均时数：0 小时</p><p>总时数：202小时</p><p>心理健康水平中位数提高：2%</p><p>这些图表不包括一位学者，该学者报告称，由于社区健康支持，心理健康状况提高了 1000%。学者们提供了更多细节：</p><ul><li> “它帮助我减轻了对人际关系问题的焦虑。”</li><li> “更快乐、更可持续、更专注、更少内疚。”</li><li> “在节目中，有两次我对某些事情感到有点害怕；在这两种情况下，[社区经理] 都可以讨论这个问题，非常友善和支持，并帮助我让事情变得更好。”</li><li> “一般来说，当你离开家时，以及可能在你人生中职业生涯的决定性时刻，创造一个支持性的环境对我来说非常重要。”</li></ul><p>一些学者提到，他们没有要求社区卫生支持，但他们很高兴如果他们需要的话，这个安全网已经到位：</p><ul><li> “很高兴知道如果发生什么事我可以去找人。”</li><li> “我并没有真正与社区健康部门互动，但我认为存在着我想要的反事实世界。”</li><li> “我用得不多，但很高兴它在那里。”</li><li> “我没有太多利用社区健康服务，但我很感激它的存在，以防我可能需要它。”</li></ul><h2>评估结果</h2><h3>研究里程碑</h3><p><strong>学者研究计划</strong></p><p>学者研究计划是研究阶段两个评估里程碑中的第一个。 SRP 根据<a href="https://docs.google.com/document/d/1fQwy2btcWn3XRQkgu45kKnPPHMVQs28QHpaNtDCfXQY/edit#heading=h.ozvm8udh0z0y"><u>此标准</u></a>进行分级。平均成绩为 74/100。学者们在 SRP 的威胁模型和变革理论部分往往失分最多；他们在阐述研究计划的部分表现出了更强的表现。</p><p>重要的是，一些学者忽视了SRP，因为他们不打算申请延期阶段，或者因为他们已经获得了资金，并且没有预期SRP在他们的延期阶段决定中发挥重要作用。一些导师鼓励他们的学者降低 SRP 的优先级，转而专注于他们的研究。</p><p><strong>座谈会发言</strong></p><p>研讨会演讲是研究阶段的第二个里程碑。项目在这些类别中的分布如下。请注意，并非所有学者的工作都会出席研讨会，有些项目属于多个类别。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/snfbmj3ukwt4kbbpo8mw"></p><p>研讨会演讲得到了三个维度的同行评审：“什么”（50 分）； “为什么”（30分）；和“风格”（20 分）。完整的标题可以<a href="https://docs.google.com/document/d/1SB_vl6pGuSO7qidkZ8fIKPeH7fZIC8mvXzxicFjGyrE/edit#heading=h.ozvm8udh0z0y"><u>在这里</u></a>找到。平均成绩为86/100。</p><h3>研究能力</h3><p>使用上面解释的“深度、广度、品味”框架，我们评估了学者们在项目期间在这些维度上提高了研究技能的程度。</p><p><strong>研究能力的深度</strong></p><p>因为我们没有在项目前询问有关研究技能深度的调查问题，所以我们在项目结束时要求学者直接评价他们在所选研究方向内加强了多少技术技能。 1/10 的评分代表“与我的反事实夏天相比没有任何进步；” 10/10 的评分代表“与我的反事实夏天相比，有了显着的进步”。平均评分为 7.2/10。 </p><figure class="image image_resized" style="width:84.58%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/e9tlsh6pe4axayao52tx"></figure><p>受访者详细阐述了他们的技术技能的改进：</p><ul><li> “我从非常基本的机器学习技能发展到了合理的研究技能。”</li><li> “学习了一系列在机甲解释中找出特定事物的策略和技术。还更好地了解了要问什么问题、证明标准等。”</li><li> “更快地进行实验，识别并消除瓶颈。”</li><li> “我在 MATS 中提高了自己的技能，进行真正的研究特别有价值，因为这意味着我不必尝试猜测哪些技能对研究很重要，我只是在做研究，而技能为此需要的是我改进的那些。因此，与我的夏天相比，MATS 更有针对性，也更加激烈和激励。”</li></ul><p><strong>知识广度</strong></p><p>为了评估知识的广度，我们要求学者在研究阶段开始和结束时按照从 1 到 10 的等级对他们对主要联盟组织的研究议程的理解进行评分，其中 10/10 表示“对于任何主要联盟组织，你可以与他们的一位研究人员交谈并通过他们的智力图灵测试（即，该研究人员会认为你对他们组织的议程很熟悉）。”</p><p>我们从学者的项目后自我报告分数中减去他们的初始自我报告分数，以获得以下分布： </p><figure class="image image_resized" style="width:63.98%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/q0jzuagnkumv2gkfwvjk" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/tv0aa0dtjgrhuvi1pkjn 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/dneqbrids1b78uptkqvl 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/fcahnz8oznyoidnh2xza 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/t9ovxc5ym2zbmnilmtqy 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/cnu1yhkzkmkyzwvmpjbv 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/gepvvkrfeu6t5ktsb4ne 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/bzlob8pmpwqebi29cq0r 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/nw1kpf7xb5hfa78igzxl 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/f0ejttnktmsgkmf8kctn 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/z7hzcrvaa9hs1z1j1c1u 1104w"></figure><p>平均而言，学者们自我报告的对主要协调议程的理解在这 10 分制上增加了 1.75。两名受访者表示，他们的评分下降了一个百分点，这可能是由于学者的自我评估不一致（他们在研究阶段结束时回答时看不到自己之前的回答），或者是学者意识到自己之前的评分理解<a href="https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect"><u>并不像他们想象的那么全面</u></a>。</p><p><strong>研究品味</strong></p><p>我们将研究能力的“品味”维度分解为两个项目后调查问题。第一个问题是“您认为MATS在多大程度上提高了您独立迭代研究方向的能力？”，其中1/10表示没有变化，10/10表示显着提高。平均反应为 6.9/10。 </p><figure class="image image_resized" style="width:85.72%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/zmosuottj0wwyx4zk1hw"></figure><p>受访者提供了有关该主题的定性信息：</p><ul><li> “大多数情况下，我通过陈述研究假设而增强了自信心。之前，我有点认为关于论文的所有可以质疑/询问的事情都已经完成，或者被认为是无趣的——我现在更加坚信，安全研究中仍然有很多容易实现的成果。 （一个例子：更好地理解 RLHF 背后的理论）。”</li><li> “学者们花了一整天的时间互相谈论他们的研究。这增加了快速反馈循环，即“该方法会/不会成功”、“你也应该阅读此内容”、“这似乎影响低/高”。研究迭代有了很大的改进，可能提高了 3 倍。”</li><li> “更擅长红队，对我自己的模型和假设持怀疑态度，并找到最有效的方法来反驳它们。”</li></ul><p>第二个问题涉及研究品味，“在 MATS 期间，您在多大程度上提高了为您的研究开发变革理论的能力？”，其中 1/10 代表没有变化，10/10 代表拥有一个更加成熟的模型。平均反应为 5.9/10。 </p><figure class="image image_resized" style="width:70.31%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/pwzqwmjvjfoiwujhrab5"></figure><p>学者们详细阐述了他们在变革理论方面的经验：</p><ul><li> “我认为 MATS 对我帮助很大，因为它让我对人工智能中的事物如何发展有了更详细的模型，实现了我以前没有考虑过的考虑因素，当我的模型不够细化时更能够意识到，并且知道更多相关的信息事实和细节。”</li><li> “更加批判性地思考我正在做的事情是否能解决任何问题。”</li><li> “我想我之前已经思考过这个问题很多次了，但 MATS 给了我更多练习的机会，我认为我在评估议程方面变得更加现实（而不是以前可能会立即考虑过于宏大的议程）。”</li></ul><p><strong>导师对研究的认可</strong></p><p>In a survey, we asked mentors, “Taking [depth/breadth/taste ratings] into account, how strongly do you support the scholar&#39;s research continuing?”平均反应为 8.1/10，<a href="https://www.qualtrics.com/experience-management/customer/net-promoter-score">净推荐值为</a>38。 </p><figure class="image image_resized" style="width:71.98%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/nv7uav2tugiepfadwa5w" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/bhtp4q6evtp64v69ezfw 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/mjrvh0mqy9bzm17omgq3 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/qseuhcznhvn5jytff23q 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/scl7dyejhqxplisao3pz 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/sk1fg1scis2soxrczgec 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/kqokwwglgjguqo9sfjv3 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/bclz9iouqcam2xad5iuv 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/x4wsc7umnhrl3qzhsxha 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ybqutxsl8szprbkiyvu8 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/df39xsgzxqhbeii2pkth 1104w"></figure><ul><li> <strong>Depth:</strong> When asked &quot;How strong are the scholar&#39;s technical skills as relevant to their chosen research direction?&quot;导师对学者的平均评分为 7.0/10，其中：<ul><li> 10/10 = World class;</li><li> 5/10 = Average for a researcher in this domain;</li><li> 1/10 = Complete novice.</li></ul></li><li> <strong>Breadth:</strong> When asked &quot;How would you rate the scholar&#39;s understanding of the agendas of major alignment organizations?&quot; mentors rated scholars 6.7/10 on average, where:<ul><li> 10/10 = For any major alignment org, they could talk to one of their researchers and pass their intellectual Turing Test (ie, that researcher would rate them as fluent with their organization&#39;s agenda);</li><li> 1/10 = Complete novice.</li></ul></li><li> <strong>Taste:</strong> When asked &quot;How well can the scholar independently iterate on research direction (eg design and update research proposals, notice confusion, course-correct from unproductive directions)?&quot; mentors rated scholars 7.1/10 on average, where:<ul><li> 10/10 = Could be a research team lead;</li><li> 7/10 = Can typically identify and pursue fruitful research directions independently;</li><li> 5/10 = Can identify when stuck, but not necessarily identify a better direction;</li><li> 1/10 = Needs significant guidance.</li></ul></li><li> <strong>Motivation:</strong> When asked &quot;To what extent does the scholar seem &quot;value aligned&quot;, ie strongly motivated by achieving good AI outcomes?&quot; mentors rated scholars 8.9/10 on average, where:<ul><li> 10/10 = Improving AI-related outcomes is their primary motivation by far;</li><li> 5/10 = Motivated in part, but would potentially switch focus entirely if it became too personally inconvenient;</li><li> 1/10 = coincidentally working in AI alignment for other reasons.</li></ul></li></ul><p>重要的是，导师之间对学者研究的判断并不一致，因为每个导师都有自己的标准和优先事项，而且并非每个导师都对调查做出回应。</p><h3>联网</h3><p>我们衡量了社交机会对专业联系和潜在合作者变化的影响。 <span class="footnote-reference" role="doc-noteref" id="fnrefjruz5097w9c"><sup><a href="#fnjruz5097w9c">[5]</a></sup></span>在研究阶段的开始和结束时，学者们报告了“您可以放心向联盟社区寻求专业建议或支持的专业人士数量”。 <span class="footnote-reference" role="doc-noteref" id="fnrefdkoclj9ogu"><sup><a href="#fndkoclj9ogu">[6]</a></sup></span>我们利用这些响应的差异来获得以下分布： </p><figure class="image image_resized" style="width:70.77%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/p3rhtrgiig877me0teby" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/jvt6z2atg5x4d1w10a6t 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/vjjrob3qevytwv5qrwdr 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/gpvwhnanohnkhfm0zaka 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/inntopihux9frbyr2mm5 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/m3dmwgdoimq0rpuvsl5e 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/fnwrag0tjycqnopopdee 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/hp1g32lqy4ltjwveyqmb 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/bd16bew0mefjxuxo3neq 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/bvdymeo731yywe6xkjs2 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/lzqruihgrtictf9kyx4w 1104w"></figure><p>反应的中位数差异为+4.5。两次回答意味着他们可以联系的专业人员数量发生 -10 变化的受访者首先回答“30”，然后回答“20”，因此我们预计该数字是校准方差的结果。</p><p>我们就潜在合作者提出了一个类似的问题：“您认为可以联系多少人来合作开展人工智能对齐研究项目？” <span class="footnote-reference" role="doc-noteref" id="fnrefxyz9685l7yk"><sup><a href="#fnxyz9685l7yk">[7]</a></sup></span>我们采用响应差异来获得以下分布： </p><figure class="image image_resized" style="width:70.87%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/exudn8ryswlsknsbhtfa" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ggftocn43oc0bodhg703 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ub6icmfo938obrxiqibw 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/pffsav2v8sxwv3vkqo6n 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/tvtemcsucpu9wvdxochq 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/myz8y8k7ylyveywhnwt9 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/eluzxy19g6mlicounccf 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/lfhhyaa704f1n9bil4hc 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/vjtcx8ubwprrz6n5772m 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/z1mxlrqoytalsmhf3a2r 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/mlr8c5j89bqq1f4sojmv 1104w"></figure><p>反应的平均差异为+6.0。一些学者报告的下降很可能是由于人们的判断中存在一些日常差异，因为学者们无法获得他们之前的回答。</p><h3>职业障碍</h3><p>在研究阶段的开始和结束时，我们向学者询问“[他们]与成功的人工智能对齐研究生涯之间的障碍”。当比较研究阶段开始和结束时的反应时，我们发现对于大多数可能的障碍，很少有学者将其报告为问题。出版记录和软件工程经验是例外：更多的学者表示在项目结束时面临这些障碍比开始时要多。这些结果可能反映出学者们了解了他们以前低估的障碍，随着学者们克服了早期的障碍，新的障碍变得更加突出，或者学者们转向具有不同障碍的职业道路。在研究阶段结束时，发表记录是学者与成功的职业生涯之间的主要障碍。 </p><figure class="image image_resized" style="width:87.06%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/wfmfyp6jpau8tiihxsue"></figure><p>我们还特别询问了学者在项目开始和结束时撰写资助提案的信心。 70%的学者表示对在项目开始时撰写资助提案感到不自信或非常不自信，但80%的学者表示对在项目结束时撰写资助提案感到有信心或非常有信心。</p><h2>未来计划的教训和变化</h2><p>虽然我们尚未最终确定或实施我们计划为下一批学生做出的一些改变，但以下是我们从 2023 年夏季计划中学到的主要经验教训。</p><h3> 1.申请阶段更好的过滤</h3><p>我们预计，一些处于研究阶段的学者不太可能在其职业生涯中进行具有足够影响力的一致性研究，以保证指导他们的成本，并且我们认为我们可以在申请阶段获得足够的信息来识别这些学者。这表明 MATS 在初始应用或后续评估检查点中还有更严格过滤的空间。人才分布上尾部的更高分辨率将使我们能够选择更有前途的申请人，或者至少减少没有前途的申请人，从而使一些导师能够更加关注他们的每位学者。</p><p>对于某些流来说，更好的过滤器的组成部分之一是增加对软件工程技能的筛选。对于导师自己来说，这可能是一个成本高昂的评估过程，因此对于 2023-24 年冬季计划，我们与 SWE 评估组织签约，以筛选实证 ML 研究流的申请人。</p><p>对于 2023-24 年冬季项目，我们还决定在我们网站上的导师描述中添加“个人适合”部分，以便更好地向申请人传达不同的导师风格。由于有些导师比其他导师更不干涉，我们希望申请人更有可能从他们个人不适合的类别中自我选择。</p><h3> 2.提供更多的技术支持</h3><p>学者支持团队没有明确涵盖且仅有时由导师提供的一种帮助形式是技术支持，包括调试代码、教授<a href="https://neelnanda-io.github.io/TransformerLens/"><u>TransformerLens</u></a>库等新工具以及回答技术 ML 问题。在未来的队列中，我们可能会为受到技术问题困扰的学者提供办公时间或类似的服务。一种可能性是改善我们的基础设施，以便学者们互相帮助解决技术问题。</p><h3> 3. 更积极主动地支持指导之外的专业发展</h3><p>学者支持目前帮助学者解决各种瓶颈，包括生产力、优先级、研究方向、沟通、心理健康等方面的挑战。虽然这对许多学者来说很有价值，但它更强烈地针对可以在短期内解决的瓶颈。每周约 1 小时的辅导，并且有一些技能改进（例如，练习阅读研究论文或提高编程能力）需要投入更多的时间。</p><p>在未来的队列中，我们可能会探索辅导结构或同行问责结构，鼓励学者将更多时间花在对象级研究之外的专业发展上。这可能看起来像论文阅读小组、更定期和高度承诺的研讨会，以及关于变革理论、研究工作流程等主题的联合会议。</p><h3> 4. 为导师提供研究管理帮助</h3><p>除了进一步支持专业发展外，学者支持还计划帮助大多数导师管理 2023-24 年冬季学生的学者研究。我们（学者支持团队）发现，学者支持和导师之间严格的保密政策似乎留下了太多的价值，因为：</p><ol><li>导师将受益于有关学者身份的共享信息；</li><li>学者支持团队对导师目标的理解将使学者受益，特别是当导师的研究方向在整个项目中发生变化时。</li></ol><p>在向导师提供研究管理帮助时，学者支持将在理解研究障碍、项目方向和学者研究的其他趋势方面发挥更直接的作用，并在获得学者同意的情况下向导师总结这些信息。</p><h3> 5. 减少研讨会的数量</h3><p>我们认为 23 场研讨会太多了；我们为学者提供的广度与我们观察到的低平均出席率不相称。在冬季，我们将安排 12 至 16 场研讨会，每周有机会进行较短的闪电演讲。我们还将鼓励更多的学者举办研讨会（以长篇演讲的形式，而不是局限于闪电演讲的形式），因为学者举办的研讨会在夏季获得了很高的评价。</p><h3> 6. 加强项目期间与学者的交流</h3><p>In part due to the number of seminars, workshops, and social events, we think that the signal-to-noise ratio of our announcements may have been too low.至少有一次，相当一部分学者并不知道最后期限即将到来。将来，我们将更清晰地区分最重要的公告并更快地发布这些公告。</p><h3> 7. 开发更强大的内部系统</h3><p>随着 MATS 团队的规模扩大，我们正在改进多个内部系统。其中包括我们用于影响评估的数据收集渠道、我们的项目管理系统以及通过更大的专业发展对团队成员进行投资。</p><h3> 8. 提前加载社交活动</h3><p>一些学者报告说，这群人的社交需求没有得到满足。在冬季，我们打算提前举办社交活动，以促进项目早期的联系，并在办公室附近举办更多活动，以期减少学者们在项目后期发起聚会所需的激活能量。 </p><p></p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/owezlxy9huaz3nvisvys" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/p9rtesbpiumqavifgdnn 410w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/kavq5cmkcfjmpghagunp 820w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/kqpc1u8dnlojpfdyfbgs 1230w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/wfbd4e4d8oejex0bi49n 1640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/pkcsb8dtbrazxsxsgjyr 2050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/yesebeflxhns0q6jgkeg 2460w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/chgrj99i2hvbrs8k2kqf 2870w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/xjfi4f2aeaifnab08rak 3280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/sng3yqsh8yhmicbyik0q 3690w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/eazdnqncdnjlf15hjhsq 4034w"></figure><p></p><h1>致谢</h1><p>该报告由<a href="https://www.matsprogram.org/"><u>机器学习调整和理论学者计划</u></a>制作。 Rocket Drew 和 Juan Gil 是本报告的主要贡献者，Ryan Kidd 在 Christian Smith 的支持下确定、管理和编辑了该项目，Laura Vaughan 和 McKenna Fitzgerald 为学者支持报告部分的数据收集和分析做出了贡献。还要感谢 Carson Jones、Henry Sleight 和 Ozzie Gooen 对该项目的贡献。 We also thank <a href="https://www.openphilanthropy.org/">Open Philanthropy</a> and the <a href="https://survivalandflourishing.fund/speculation-grants.html#sffs-speculation-grants-program">Survival and Flourishing Fund Speculation Grantors</a> , without whose donations we would have been unable to run the Summer 2023 Program or retain <a href="https://www.matsprogram.org/team">team members</a> essential to this report.</p><p>要了解有关 MATS 的更多信息，请访问我们的<a href="http://matsprogram.org/"><u>网站</u></a>。我们目前正在<a href="https://manifund.org/projects/mats-funding">接受 2023-24 冬季计划及以后的捐款</a>！ </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn2niy7evweco"> <span class="footnote-back-link"><sup><strong><a href="#fnref2niy7evweco">^</a></strong></sup></span><div class="footnote-content"><p>一些导师在其申请中包含的选择问题示例：</p><p> - 花 2-4 小时使用语言模型开发问答对数据集，RLHF 训练的模型可能会给出友好但不正确的答案。然后记录自己 2-4 小时的时间，评估数据集上的模型并绘制缩放定律。如果您的数据集显示反向缩放，则可获得奖励积分。</p><p> - 我希望你花大约 10 个小时（为了公平起见，最多 20 小时）尝试在机械可解释性的一个开放性小问题上取得研究进展，并向我展示你所取得的进展。请注意，我并不期望您能够解决问题，拥有机械插补的背景，获得令人印象深刻的结果，或者真正感觉到您知道自己在做什么。</p><p> - “贝叶斯期望效用最大化”是普遍强大智能的“真名”吗？为什么/为什么不呢？</p></div></li><li class="footnote-item" role="doc-endnote" id="fnvp0h93gzvk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefvp0h93gzvk">^</a></strong></sup></span><div class="footnote-content"><p>没有进步的学员集中在两名导师身上，他们在培训阶段之前向学员告知他们进入研究阶段的前景。这些导师决策的主要决定因素是学者在培训阶段结束时的研究冲刺中的表现。这些流派的学员知道自己的胜算后，选择了参加，部分原因是与导师一起工作的一个月保证期的价值很高。 2022-23 年冬季学员 Jay Bailey 证明，</p><p> “Neel [Nanda] 的机械可解释性培训过程对我来说是一个很好的方式来测试我在该领域的适应性并与许多聪明的人合作。尼尔的直播要求很高，他希望这是一个并不适合所有人的环境，但他很清楚这并不可耻。虽然我最终没有被选中参加面对面阶段，但经历这个过程帮助我了解了我是否想长期追求机械解释性，并围绕如何最好地为未来的一致性做出贡献制定了计划。 ”</p></div></li><li class="footnote-item" role="doc-endnote" id="fnnsczgjuthnr"> <span class="footnote-back-link"><sup><strong><a href="#fnrefnsczgjuthnr">^</a></strong></sup></span><div class="footnote-content"><p>这个问题通常用于计算“<a href="https://en.wikipedia.org/wiki/Net_promoter_score"><u>净推荐值</u></a>”（NPS），这是许多行业的标准。根据我们的受访者的反馈，MATS 的 NPS 为 +69。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnhdw3lym1fyo"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhdw3lym1fyo">^</a></strong></sup></span><div class="footnote-content"><p>本调查问题和以下问题来自 Lynette Bye <a href="https://forum.effectivealtruism.org/posts/xvax8hpF29Ky5kPJw/effective-altruism-coaching-2020-annual-review"><u>2020 年对其教练影响力的回顾</u></a>。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnjruz5097w9c"> <span class="footnote-back-link"><sup><strong><a href="#fnrefjruz5097w9c">^</a></strong></sup></span><div class="footnote-content"><p>以下直方图排除了一位从 0 增加到 999 名可用专业人士和潜在合作者的学者，解释说：“一开始我基本上觉得我可以给任何人发消息/打电话，现在我觉得我可以给任何人发消息/打电话字面上地。”</p></div></li><li class="footnote-item" role="doc-endnote" id="fndkoclj9ogu"> <span class="footnote-back-link"><sup><strong><a href="#fnrefdkoclj9ogu">^</a></strong></sup></span><div class="footnote-content"><p>该问题详细阐述了：“如果您想要更具体的范围：您认为可以联系多少位专业人士以获得 30 分钟的职业建议？影响这一点的因素包括您认识哪些专业人士以及您是否有足够的联系来让他们为您提供帮助。粗略估计一下就可以了，而且这个问题不仅仅是关于你在MATS中遇到的人！”</p></div></li><li class="footnote-item" role="doc-endnote" id="fnxyz9685l7yk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxyz9685l7yk">^</a></strong></sup></span><div class="footnote-content"><p>该问题详细阐述为：“想象一下，您在感兴趣的联盟领域内有一些研究项目想法。您认识的人中有多少人可能是合作者？粗略估计一下就可以了，而且这个问题不仅仅是关于你在MATS中遇到的人！”</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/zwf68YaySvXhWYCdh/mats-summer-2023-postmortem-1#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/zwf68YaySvXhWYCdh/mats-summer-2023-postmortem-1<guid ispermalink="false"> zwf68YaySvXhWYCdh</guid><dc:creator><![CDATA[Rocket]]></dc:creator><pubDate> Fri, 01 Dec 2023 23:29:47 GMT</pubDate></item></channel></rss>