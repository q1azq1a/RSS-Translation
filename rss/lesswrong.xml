<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 9 月 13 日星期三 04:14:37 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Padding the Corner]]></title><description><![CDATA[Published on September 13, 2023 1:30 AM GMT<br/><br/><p><span>我爸爸的厨房里有一个架子，离地大约四英尺。我记得当我不再矮到可以在它下面行走时：哎呀！我没有受到脑震荡或其他什么影响，但这非常不愉快。我的姐妹和表兄弟姐妹也记得他们对此摇头不已。我注意到我的大女儿已经够高了，于是开始给她讲这个故事，警告她注意这一点。</span></p><p>当我讲故事的时候，我意识到这是多么愚蠢，于是停下手头的事情，在角落里放了一些垫子。</p><p> <a href="https://www.jefftk.com/washcloth-padded-corner-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/dNBeQdB35qKruoCpr/yccwa82xz4pbcwhkz40p" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/dNBeQdB35qKruoCpr/yccwa82xz4pbcwhkz40p 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/dNBeQdB35qKruoCpr/m5ojftrweqlvxxt4rzro 1100w"></a></p><div></div><p></p><p>折叠起来并用螺钉固定在架子上的毛巾看起来不太好，但几年后的今天，三个表兄弟都足够高，可以与它相交，而且没有人受伤。也许有一天我们可以做一些更优雅的事情，但与此同时，修复尖角胜过警告人们。</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid034oVcWajuvk8MWeyna2ybS8iEqC28DEqRq42T32f3LGpe9uH2crmAL4aVxkFHDL2bl">facebook</a> , <a href="https://mastodon.mit.edu/@jefftk/111055243593039436">mastodon</a></i></p><br/><br/><a href="https://www.lesswrong.com/posts/dNBeQdB35qKruoCpr/padding-the-corner#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/dNBeQdB35qKruoCpr/padding-the-corner<guid ispermalink="false"> dnBeQdB35qKruoCpr</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Wed, 13 Sep 2023 01:30:04 GMT</pubDate> </item><item><title><![CDATA[Should an undergrad avoid a capabilities project?]]></title><description><![CDATA[Published on September 12, 2023 11:16 PM GMT<br/><br/><p><i>虽然我写的是我的个人情况和项目，但我希望其他人也能遇到这种情况。</i></p><p>我正在考虑加入<strong>ProjectX。</strong>这听起来像是一个与人工智能合作、获得经验并有可能创造出令我自豪的东西的绝佳机会。不幸的是，它是关于提高人工智能效率，我将其理解为“能力”。当能力增强时，世界末日就会越来越近、可能性也越来越大。</p><p></p><p>有关该项目的更多信息：</p><p> <strong>“ProjectX：机器学习研究竞赛</strong></p><p>ProjectX 是<strong>世界上最大的本科机器学习研究竞赛，</strong>参赛团队来自世界各地的顶尖大学。 3支获胜团队将分别获得<strong>20,000加元</strong>的现金奖励，所有参赛者将被邀请参加2024年1月中旬<strong>举行的多伦多大学人工智能年会</strong>。去年的比赛由谷歌、英特尔和Nvidia赞助，并有特邀主讲人詹姆斯·范龙.</p><p>今年的重点是<strong>高效人工智能</strong>：研究创新方法和机器学习方法来创建人工智能模型，在不影响性能的情况下显着降低功耗。</p><p><br></p><p>今年我们将派出一支由 3-6 名学生组成的团队代表西北大学。该团队将在 2023 年 10 月至 12 月期间研究他们选择的问题，最终发表一篇描述他们的发现的论文。</p><p><a href="https://drive.google.com/file/d/1_v4vlZlgY6KgCXXPF_m76dBZnTkDpEX5/view?usp=sharing">有关今年比赛的更多信息</a></p><p><a href="https://drive.google.com/file/d/1UotPB5_4_9akc8mcPFQYQCWwdD7YLJed/view?usp=sharing">去年获奖团队的论文样本</a>“</p><br/><br/> <a href="https://www.lesswrong.com/posts/az2ibmLhv3enpfrdq/should-an-undergrad-avoid-a-capabilities-project#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/az2ibmLhv3enpfrdq/should-an-undergrad-avoid-a-capability-project<guid ispermalink="false"> az2ibmLhv3enpfrdq</guid><dc:creator><![CDATA[Double]]></dc:creator><pubDate> Tue, 12 Sep 2023 23:16:40 GMT</pubDate> </item><item><title><![CDATA[[Linkpost] Contra four-wheeled suitcases, sort of]]></title><description><![CDATA[Published on September 12, 2023 8:36 PM GMT<br/><br/><p>是简单、坚固、可靠的系统更好，还是花哨、精密、复杂的系统更好？</p><p>这篇文章带着先入之见，分析了手提箱、汽车、登山装备、食物、杯子、太空笔、人、初创公司、足球、耳机、重量、火箭、火箭、轮船和银行，并得出结论：</p><blockquote><p>我希望这个练习能够表明，简单、坚固、可靠的系统在系统上比花哨的脆弱系统更好。但事实并非如此。有时崎岖不平会获胜，有时却不会。</p></blockquote><p>它更多地说明了他发现的趋势和模式。请阅读短文以了解更多信息。</p><p>我喜欢它<a href="https://www.lesswrong.com/s/zpCiuR4T343j9WkcK">注意到混乱</a>并<a href="https://www.lesswrong.com/tag/babble-and-prune">喋喋不休地提出</a>许多有趣的类别。</p><br/><br/> <a href="https://www.lesswrong.com/posts/nFGMvs9WSeau8ATTY/linkpost-contra-four-wheeled-suitcases-sort-of#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/nFGMvs9WSeau8ATTY/linkpost-contra-four-wheeled-suitcases-sort-of<guid ispermalink="false"> nFGMvs9WSeau8ATTY</guid><dc:creator><![CDATA[Gunnar_Zarncke]]></dc:creator><pubDate> Tue, 12 Sep 2023 20:36:03 GMT</pubDate></item><item><title><![CDATA[Seeking Feedback on My Mechanistic Interpretability Research Agenda]]></title><description><![CDATA[Published on September 12, 2023 6:45 PM GMT<br/><br/><h1>为什么发这个帖子</h1><p>我全职从事 MI 研究大约三个月了，由于我目前的资助即将结束，而且我最近收到了 Lightspeed 拒绝，现在似乎是从对象级工作中抽出一些时间来反思方向的好时机以及后续步骤。我花了几个小时写了一份草稿，意识到我认为它太复杂了（为了听起来很复杂？），然后用大约 750 个字重写了我真正想做的事情以及为什么。我打算将反馈纳入 OpenPhil 早期职业申请（我将在几天内提交）。我还在申请人工智能研究职位，如果我获得了职位，这将有助于了解要关注的内容。</p><h1>议程</h1><p>在我看来，机械可解释性研究的目标是充分了解最先进的网络正在做什么，这样我们就可以检查是否正在发生任何危险行为。我<a href="https://www.neelnanda.io/mechanistic-interpretability/attribution-patching">预计</a>自动化技术将成为理解此类模型<a href="https://arxiv.org/pdf/2211.00593.pdf">的重要一步（示例：1、2、3</a> <a href="https://arxiv.org/pdf/2304.14997.pdf">）</a> 。然而，我觉得我们缺少一个重要的基础，因为我们还没有完全理解小语言模型正在做什么，因此，不知道自动化技术应该检测的一组事情。 （这些技术应该寻找推理吗？、特定行为？、记忆信息？、叠加？）。我认为，我们首先需要对浅层语言模型进行细致的、底层的探索，以指导我们对更大模型的分析。</p><p>随着<a href="https://arxiv.org/abs/2305.07759">TinyStories 模型</a>的发布，我们现在有了可以生成合理文本补全（儿童故事）的小型语言模型。 <a href="https://d.docs.live.net/5217bc84fed48838/Desktop/TinyStories-1Layer-21M">TinyStories-1Layer-21M</a>是该系列中的一个单层模型，它将作为我研究的重点。我将使用<a href="https://www.anthropic.com/index/a-mathematical-framework-for-transformer-circuits">Anthropic 的电路框架</a>对此模型进行低级机械解释。我相信，鉴于其相对较小的规模和通过网络的路径数量有限，使用电路分析该网络是可行的。</p><p>我坚信，这一层模型中将存在一些规则和模式，这些规则和模式将作为我们在更大模型中搜索事物的指南。 （当然，几乎可以肯定，在更多样化的数据集上训练的大型模型中存在该模型中不存在的规则和模式，但这应该作为建立对语言模型正在做什么的机械理解的良好起点） 。我的希望是，通过对单层模型的权重和激活进行重点低级探索，我可以构建一个人类可解释的知识和功能库，该单层模型似乎已经学会了这些知识和功能。</p><p>我已经开始探索这个模型，所以我对可能存在的组件有一些粗略的想法，但这些说法应该被理解为初步的：我相信我已经检测到似乎与某个概念相关的 MLP 神经元，例如，我发现了几个神经元，当故事中的人物“寻找”或“搜索”某物时，这些神经元似乎表现出强烈的积极性；此外，这些神经元对残差流的贡献通常支持也与“查看”或“搜索”有关的输出标记。</p><p>另一方面，一些神经元似乎支持语法规则。一个神经元对代词呈强阳性；它对残差流的贡献通常支持动词和副词输出标记。 （我 ->; 是，他们 ->; 看，他们 ->; 看到，他们 ->; 两者[感觉]）。另一个对文章非常积极；它对残差流的贡献通常支持形容词和名词（A ->; 香蕉，the->; 树，a->; 大[香蕉]）。该模型是否故意编写内容和语法规则，以便使用正确的语法成功地编写有关“搜索”的故事？是否还正在制定其他类型的规则？</p><p>一旦我拥有了知识和功能库，我将尝试手工制作可以实现此行为的网络权重，类似于<a href="https://distill.pub/2020/circuits/curve-circuits/">Chris Olah 创建的曲线检测器</a>和<a href="https://docs.google.com/document/d/1Hk1NQSQE3ycaDRULxB-Cy78FuqFW9sUDIEc_56UMlMI/edit">我过去为 1 层变压器手工制作权重的工作</a>。手工设计网络权重使我能够检测到我之前错过的网络整体机制的一部分。我预计手工权重同样会指出我对<a href="https://d.docs.live.net/5217bc84fed48838/Desktop/TinyStories-1Layer-21M">TinyStories-1Layer-21M</a>的整体解释中不完整或缺失的部分。</p><p>在过去的三个月里，我成功地解释了三个小型变压器模型（ <a href="https://www.lesswrong.com/posts/vGCWzxP8ccAfqsrS3/thoughts-about-the-mechanistic-interpretability-challenge-2">Stephen Casper 的 MI 变压器挑战</a>、 <a href="https://github.com/freestylerick/quick_MI">ARENA 每月问题#1</a> 、 <a href="https://github.com/freestylerick/First-Unique-Token">ARENA 每月问题#2</a> ）。我对使用 Pytorch 进行电路式分析来操纵和组合网络权重和激活的能力充满信心，最终创建带注释的图表，我可以检查这些图表以生成和测试假设。</p><p>了解 1 层模型的工作原理将作为了解 2 层模型的基础。对于 2 层（或更多）层的模型，我们具有注意力头组合，这可能会解锁 1 层模型无法实现的行为。通过了解 1 层模型中存在的内容，2 层模型很可能会表现出一些相同的模式和一些不同的模式。在探索 2 层模型之后，我们希望可以继续扩展，再次使用较小的模型作为我们可能期望在较大模型中找到的一些内容的指南。希望这个过程最终能让我们更好地理解大型语言模型正在做什么，以便我们能够更好地评估安全问题。</p><h1>结论</h1><p>感谢您抽出时间来阅读。再次强调，我愿意接受所有反馈，包括负面反馈。</p><p>如果您是资助者或雇主，可能有兴趣讨论和/或资助这项工作，请通过 LessWrong DM 联系。</p><p>如果您对可能资助这项研究的组织有任何想法，请随时私信或在评论中发帖。</p><br/><br/> <a href="https://www.lesswrong.com/posts/ESaTDKcvGdDPT57RW/seeking-feedback-on-my-mechanistic-interpretability-research#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ESaTDKcvGdDPT57RW/seeking-feedback-on-my-mechanistic-interpretability-research<guid ispermalink="false"> ESaTDKcvGdDPT57RW</guid><dc:creator><![CDATA[RGRGRG]]></dc:creator><pubDate> Tue, 12 Sep 2023 18:45:08 GMT</pubDate> </item><item><title><![CDATA[Automatically finding feature vectors in the OV circuits of Transformers without using probing]]></title><description><![CDATA[Published on September 12, 2023 5:38 PM GMT<br/><br/><p>假设您正在努力了解给定的大型语言模型如何计算特定任务的输出。您可能对以下问题感到好奇：</p><ul><li>哪些线性特征向量决定模型在给定任务上的性能？</li><li>给定一组不同的任务，相同的特征在多大程度上负责模型在这些不同任务上的输出？</li><li> LayerNorm 等非线性如何转换用于给定任务的特征？</li><li>给定一对特征，如果一个输入的一个特征的值很高，那么这是否意味着该输入的另一个特征的值可能很高？</li><li>如何找到一个转向向量来添加到模型的激活中，从而增加模型在一项任务上的输出，同时减少另一项任务上的输出？</li></ul><p>最近，我一直致力于开发一种通用方法来部分回答这些问题。值得注意的是，与查找特征向量的探测方法不同，该方法可以通过<i>零前向传递数据</i>找到这些问题的近似答案，从而用很少的附加数据点<span class="footnote-reference" role="doc-noteref" id="fnrefu4fd3ietm2f"><sup><a href="#fnu4fd3ietm2f">[1]</a></sup></span>产生改进的答案。这篇文章介绍了这种寻找特征向量的方法，称为“可观察传播”；提出有关可观察传播产生的特征向量分析的理论结果；并介绍了测试该方法的一些初步实验的结果。</p><p>请注意，这一切都在进行中！我目前正在进行更多的实验，以便更好地了解可观察传播的效用和局限性。此外，我仍然必须在公开之前清理我的代码（尽管此处描述的方法应该不难重新实现）。但我认为，与其等到一切都完成后再分享我所取得的成果，不如向社区展示我迄今为止已完成的工作。</p><p>这项工作的贡献如下：</p><ul><li>这项工作引入了“可观察量”的概念，它概括了通过查看 Logit 差异来考虑模型在任务上的性能的模式。一旦人们开始将可观察量视为适合研究的具体对象，就会出现许多分析 Transformer 的新技术。</li><li>这项工作提出了一种称为“可观测传播”的方法，该方法允许人们在 Transformer 的 OV 电路中找到与任何给定可观测相对应的特征向量。请注意，此方法可以找到特征方向以及近似的特征大小，<i>而不需要任何额外的数据</i>。该方法可以使用少量数据扩展到 Transformer 中的非线性组件，以获得更好的特征量值近似值。</li><li>这项工作开发了一种特征向量分析理论。这包括一个定理，即 LayerNorm 非线性不会影响高维空间中的特征方向（尽管它们确实会影响特征大小）。这项工作还引入了一种称为“耦合系数”的相似性度量，它在输入与另一个特征向量的点积等于 1 的情况下测量输入和特征向量之间的预期点积。</li><li>我将可观察传播应用于<a href="https://cmathw.itch.io/identifying-a-preliminary-circuit-for-predicting-gendered-pronouns-in-gpt-2-smal">Chris Mathwin 等人考虑的性别代词预测问题。</a>作为案例研究。我通过考虑宾语和主语代词预测的情况来扩展他们的问题设置，并证明在这两种情况下都使用了许多相同的特征。我还发现，查看与不同注意力头相关的特征向量的范数可以很好地初步预测哪些注意力头最终对输出贡献最大。我表明，可观察传播找到的一些特征向量与它们各自注意力头的奇异向量没有完全对齐，这表明可观察传播可以找到 SVD 可能错过的特征向量。</li><li>最后，我展示了使用这些特征向量作为激活引导向量的一些初步结果，以减少模型显示的性别偏见。</li></ul><p><i>认知状态：我非常有信心可观察的传播，连同LayerNorms和耦合系数的理论，准确地描述了非MLP Transformer的OV电路，并且可以对这些OV电路的行为做出准确的预测。我也有点相信特征向量范数可以用来对对任务重要的注意力头做出体面的“有根据的猜测”，尽管我必须对更多任务进行更多实验才能变得更加确定。其他。然而，我仍然不确定理解 QK 行为对于理解 Transformer 的必要程度。我还在确定这些方法可以在多大程度上应用于 MLP。关于这里介绍的实验：代词预测任务的工作比性别偏见任务的工作更加成熟，目前更多地处于探索阶段。</i></p><h1>长话短说</h1><p>如果我们有一个任务想要评估我们的模型 - 例如，标记 A 和标记 B 之间的 logit 差异 - 那么我们可以构建与该任务相对应的线性函数。 （例如，令牌 A 和令牌 B 之间的 logit 差异对应于线性函数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n^T = (e_{A} - e_{B})^T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">B</span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>，其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="e_{A}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span></span></span></span></span>是独热向量，在对应于标记 A 的位置上有 1。）受量子力学概念的<i>启发</i>，我将 logits 上的线性泛函称为可观测量 。</p><p>一旦我们有了一个可观察的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n^T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span> ，然后给定一个注意力头<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span> ，与可观察的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n^T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span>相对应的该注意力头的特征向量由<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\left(W^{OV}_h\right)^T n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.593em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.335em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.593em; padding-bottom: 0.593em;">)</span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.89em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span>给出，其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W^{OV}_h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.335em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span></span></span></span>是 OV 矩阵注意头<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span> 。这可以简单地通过乘以它们的 OV 矩阵来扩展到虚拟注意力头，并且可以通过采用它们的线性近似来扩展到处理非线性。我证明，在高维度中，LayerNorm 不会改变特征向量方向——尽管 LayerNorm 确实会影响特征向量大小。我将这种在给定可观察量的情况下查找特征向量的通用方法称为“可观察传播”。</p><p>在可观察的传播产生特征向量后，我们可以分析它们，而无需在任何数据上运行模型。例如，我们可以查看特征向量范数来初步预测哪些注意力头可能很重要。我们还可以通过查看两个不同可观测值的余弦相似度来比较它们的特征向量；这使我们能够了解不同任务的两个电路何时使用相同的功能。我还将特征向量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span>到特征向量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span>的</span></span></span></span></span></span>“耦合系数”定义为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{v_1 \cdot v_2}{\Vert v_1 \Vert^2}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.84em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 2.602em; top: -1.368em;"><span class="mjx-mrow" style=""><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 2.602em; bottom: -1.089em;"><span class="mjx-mrow" style=""><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.347em; padding-left: 0px; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.84em;" class="mjx-line"></span></span><span style="height: 1.737em; vertical-align: -0.77em;" class="mjx-vsize"></span></span></span></span></span></span></span> ，并证明这表示在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot v_1 = 1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span>的情况下正态分布的嵌入向量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>和特征向量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span>之间的预期点积。</p><p>我进行了一些初步实验，将可观察传播应用于性别代词预测的设置。初步结果表明，特征向量范数通常与主动注意力头相对应；主语代词预测和宾语代词预测使用相同的特征向量；并且可观察传播产生的特征向量可以用作激活引导向量来成功改变模型的输出。</p><h1>简介：满足可观察量</h1><p>当我们想要了解模型如何执行某项任务时，通常会查看与该任务相对应的“logit 差异”。例如，当<a href="https://www.lesswrong.com/posts/cgqh99SHsCv3jJYDS/we-found-an-neuron-in-gpt-2">Joseph Miller 和 Clement Neo</a>研究导致模型预测标记“an”而不是“a”时，他们针对“an”和“a”的模型预测逻辑之间的差异执行激活修补。同样，在性别代词预测中， <a href="https://cmathw.itch.io/identifying-a-preliminary-circuit-for-predicting-gendered-pronouns-in-gpt-2-smal">Chris Mathwin 等人。</a>考虑“他”和“她”之间的逻辑差异。采用 logit 差异被认为是可解释性工作流程的重要组成部分：Neel Nanda 将其解释为<a href="https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=5Z-8RDn4JFf7wLtKosyDTNXA">“通过各种受可解释性启发的干预措施和技术（例如直接 logit 归因或激活修补）来判断模型性能的一个非常好的指标”</a> 。</p><p>但我们在这里的第一个见解是不仅仅将逻辑差异视为实验过程中的一个步骤。相反，我们希望将它们视为可以进行数学研究和操作的具体对象。什么样的物体？好吧，如果我们取 token <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span></span></span></span>和 token <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span>之间的 logit 差值，那么我们真正要做的就是计算<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(e_a - e_b)^T v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span> ，</span></span></span></span></span>其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span>是 logits 向量， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="e_x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span></span></span>是带有 a 的 one-hot 向量一个位于位置<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> 。对象<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(e_a - e_b)^T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span>是<i>线性函数</i>：从向量空间到实数的线性映射。显然，所有 Logit 差异都是 Logit 的线性函数。事实证明，除了两个标记之间的简单对数差异之外，我们可能还需要考虑线性函数。例如，我们可以考虑线性泛函<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(e_{\text{&quot; she&quot;}} + e_{\text{&quot; her&quot;}} - e_{\text{&quot; he&quot;}} - e_{\text{&quot; him&quot;}})^T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; she&quot;</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; her&quot;</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; he&quot;</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; his&quot;</span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span>来表示一般预测女性性别代词的任务。</p><p>受此启发，我们有以下定义：<strong>可观察量</strong>是 logits <span class="footnote-reference" role="doc-noteref" id="fnrefq6jwzi5ovy"><sup><a href="#fnq6jwzi5ovy">[2]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnreflpxvw4f8bc"><sup><a href="#fnlpxvw4f8bc">[3]</a></sup></span>上的线性函数。这个想法是，我们可能关心评估的一大类任务可以形式化为 logits 上的线性函数。一旦我们这样做了，我们就可以应用线性代数工具来找到与可观察量相对应的特征向量。</p><h1>通过可观察传播寻找特征向量</h1><p>现在，我将介绍一个查找与可观察量相对应的特征向量的过程。我将这种方法称为“可观察传播”，因为它涉及通过网络向后传播可观察数据。在本节中，我们将从更简单的情况下了解可观察的传播开始，然后逐渐增强通用性。</p><h2>基本线性模型</h2><p>可观察传播背后的基本见解非常简单。假设我们有一个线性模型：对于某个矩阵<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x) = Wx"><span class="mjx-mrow" aria-hidden="true">， <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> 。给定一个可观察量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> ，我们想要找到与该可观察量相对应的一些特征向量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span> 。这意味着我们想要找到<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span>使得<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y \cdot x = n \cdot f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。现在观察： <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x) = n^T Wx = (W^T n)^T x = (W^T n) \cdot x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> 。因此， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y=W^T n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> 。通过一行简单的线性代数，我们精确地找到了<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span>对应的特征向量。</p><p>请注意，这也适用于仿射情况，其中对于某些<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span> ， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x) = Wx + b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span> 。在这种情况下，对于标量常数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="c"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span></span></span></span></span> ，我们有<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x) = (y \cdot x) + c"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span></span></span></span></span> ——但这仍然意味着<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span>是嵌入空间中“直接确定”输出<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>的方向<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。</p><h3>旁白：可观察传播和相关方法之间的差异</h3><p>这个结果非常干净，但据我所知，还没有其他人使用过它。这让我非常惊讶！不过，其他一些作品也触及了类似的想法，我发现值得考虑我的表述与他们的表述有何不同。</p><p>在<a href="https://www.lesswrong.com/posts/cgqh99SHsCv3jJYDS/we-found-an-neuron-in-gpt-2">“我们在 GPT-2 中发现一个神经元”</a>中，Joseph Miller 和 Clement Neo 试图在 GPT-2 中找到负责预测某些标记的神经元（特别关注标记“an”）。他们在某种程度上是通过获取令牌嵌入与每个神经元输出权重（即权重矩阵的每一列）的点积并查看点积最高的神经元来实现这一点的。如果我们将此过程的结果存储在向量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span>中，则我们有<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y = W^T n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span>其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span>是一个 one-hot 向量，在我们关心的标记位置上有一个 1， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span>是输出权重矩阵。然而，作者并没有在概念上进行飞跃，将<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span>视为特征向量，而不仅仅是点积列表。相反，作者似乎在这样的范式下进行操作：目标是解释神经元或神经元组，而不是更一般的特征向量。这种方法可以取得一些成功，但它没有考虑到非基对齐特征，或更复杂的概念，例如<a href="https://transformer-circuits.pub/2022/toy_model/index.html">叠加</a>。</p><p>在<a href="https://www.lesswrong.com/posts/mkbGjzxD8d8XqKHzA/the-singular-value-decompositions-of-transformer-weight">“Transformer 权重矩阵的奇异值分解是高度可解释的”一文</a>中，Beren Millridge 和 Sid Black 表明，当使用模型的非嵌入矩阵投影到标记空间时，Transformer 权重矩阵的奇异向量会产生可解释的标记集。然后，他们演示了您可以通过首先找到这些标记的嵌入，然后查看标记嵌入和奇异向量之间的余弦相似度来找到与特定标记相对应的奇异向量；然后，具有最高余弦相似度的奇异向量被认为最有可能对应于给定的标记。但请注意，他们的工作主要是从一组奇异向量中选择与给定标记相关性最高的一个，即使没有一个奇异向量与该标记很好地对齐。因此，他们的框架与“我们在 GPT-2 中发现一个神经元”中相同：他们不考虑一般特征向量，而是首先考虑一组特征向量，然后从该组中选择最重要的特征向量。与给定的“查询”相关。此外，他们的工作只关注与标记相对应的奇异向量，而不是与更一般的可观察量相对应的向量。</p><p>因此，在我看来，“可观察传播”方法有两个概括，而这在上面两篇作品中没有得到：</p><ul><li>我们关心的特征向量可能无法在一小组基本向量（例如神经元或奇异向量）中找到。</li><li>我们希望不仅仅寻找与特定标记相关的特征向量，而是考虑与更一般任务相关的特征向量。 （在“可观察传播”公式中，这些“更一般的任务”对应于 logits 上的线性泛函。）</li></ul><p>我相信，在您将等式<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot Wx = (W^T n) \cdot x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>视为对可解释性有意义的东西之前，必须先内化这些概括。当然，这提出了以下问题：我现在缺少什么概括？我们稍后再回到这个问题。</p><p>此外，虽然上述研究工作是我发现与可观察传播方法最相关的工作，但我总是有可能错过文献综述中的一篇文章或帖子。如果是这样，请告诉我。</p><h2>解释 OV 电路</h2><h3>单注意力头</h3><p>如果我们正在考虑的模型是线性的，那么我们现在有一种从任何可观察到任何特征向量的方法。不幸的是，即使是仅注意 Transformer 也是非线性的。首先，计算注意力分数的过程涉及对多个标记进行双线性运算，然后进行 softmax。然后，将每个标记的线性函数乘以这些注意力分数。</p><p>然而，这个问题可以通过仅查看<a href="https://transformer-circuits.pub/2021/framework/index.html">原始变压器电路公式中</a>所谓的“OV 电路”的关注来缓解。这个想法是，注意力可以分解为两个“电路”：确定从哪些标记读取信息的计算，以及从这些标记写入哪些信息的计算。前一种计算称为“QK电路”，后一种计算称为“OV电路”。现在，如果我们将注意力分数视为固定常数，那么我们所做的就是忽略非线性 QK 电路，而只关注 OV 电路——这是所有标记的仿射函数。事实上，回想一下 Transformer 中的注意力层可以分解为</p><span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\begin{equation} x_j^{l+1} = x_j^l + \sum_{\text{attention head $h$}} \sum_{\text{token index $i$}} \operatorname{score}_h(x_i^l, x_j^l) W^{OV}_{l,h} x_i^l \end{equation}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">j</span></span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">j</span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-munderover MJXc-space2"><span class="mjx-itable"><span class="mjx-row"><span class="mjx-cell"><span class="mjx-op" style="padding-left: 1.8em;"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size2-R" style="padding-top: 0.74em; padding-bottom: 0.74em;">Σ</span></span></span></span></span> <span class="mjx-row"><span class="mjx-under" style="font-size: 70.7%; padding-top: 0.236em; padding-bottom: 0.141em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">注意力头</span></span><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span></span></span></span></span> <span class="mjx-munderover MJXc-space1"><span class="mjx-itable"><span class="mjx-row"><span class="mjx-cell"><span class="mjx-op" style="padding-left: 1.266em;"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size2-R" style="padding-top: 0.74em; padding-bottom: 0.74em;">Σ</span></span></span></span></span> <span class="mjx-row"><span class="mjx-under" style="font-size: 70.7%; padding-top: 0.236em; padding-bottom: 0.141em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">标记索引</span></span><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span></span></span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">得分</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">j</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.335em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span></span></span><p>其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_j^l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">j</span></span></span></span></span></span></span></span></span></span>是令牌<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="j"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">j</span></span></span></span></span></span></span>在层<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span></span></span></span></span> 、 <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\operatorname{score}_{l,h}(x_i^l, x_j^l)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">分数</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">、</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span></span></span></span></span>的残差流<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\operatorname{score}_{l,h}(x_i^l, x_j^l)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char"></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">j</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>是与标记<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_i^l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span></span></span>和<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_j^l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">j</span></span></span></span></span></span></span></span></span></span>的注意力头<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span>相关的第<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span></span></span></span></span>层的注意力得分，<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W^{OV}_{l,h}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.335em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span></span></span></span></span></span>是注意力头<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span>的组合输出值权重矩阵在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span></span></span></span></span>层。因此，给定一个可观察的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> ，我们可以得到<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">第 l</span></span></span></span></span></span></span>层注意力头<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span>的特征向量由下式给出</p><span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="y_{l,h} = (W^{OV}_{l,h} W_U)^T n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.335em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span><p>其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W^{OV}_{l,h}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.335em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">，</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span></span></span></span></span></span>是第<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span></span></span></span></span>层注意力头<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span>的组合输出值权重矩阵， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W_U"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span></span></span></span></span></span></span></span>是令牌去嵌入矩阵。请注意，这适用于任何层的注意力头，因为每层的所有注意力头的贡献都会保留在 Transformer 的残差流中（即使这些贡献后来被覆盖，它们仍然会在第一层中输出到残差流中）地方）。</p><h3>虚拟注意力头</h3><p>此时的下一步是注意一个注意力头的输出可以用作另一个注意力头的输入。结果在变压器电路公式中被称为“虚拟注意力头”。寻找虚拟注意力头的特征向量很简单：分别给定层 l <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h, h'"><span class="mjx-mrow" aria-hidden="true">、 <span class="mjx-msup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span>处的注意力头<span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">、</span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l, l'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">&#39;</span></span> <span class="mjx-msup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">，</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">且</span></span></span></span></span></span></span></span></span><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l < l'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-msup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span> ，即与层<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span></span></span></span></span>的头<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span>相关的特征向量，<i>通过</i><i>层 l 的</i><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">头</span></span></span></span></span></span></span></span></span><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span>介导<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span></span></span></span></span></span> ，由下式给出</p><span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="y_{l,h} = (W^{OV}_{l,h} W^{OV}_{l',h'} W_U)^T n."><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.335em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.375em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.347em; padding-left: 0px; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.347em; padding-left: 0px; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">。</span></span></span></span></span></span></span><p>当然，这适用于任意长度的注意力头组合——只需将所有相关头的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W^{OV}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span></span></span></span></span></span></span>矩阵相乘即可​​。</p><p>查看虚拟注意力头是解释 Transformer 计算的非常重要的一步：如果您只查看注意力头对输出 logits 的直接贡献，那么您最终会丢失对于理解幕后实际发生的情况至关重要的信息。我们稍后将讨论一种情况，其中模型最初似乎使用非常不同的特征向量来计算对应于两个不同可观察量的输出 - 但当我们查看虚拟注意头时，我们发现这些模型实际上使用相同的特征向量特征。</p><h3>可以忽略QK电路吗？</h3><p>回想一下，所有这些分析都只关注 OV 电路；它根本不考虑通过更改从中读取信息的标记来影响模型的所有特征方向。因此，我们应该问自己：这合理吗？当它们不考虑注意力计算的组成部分时，我们可以在多大程度上说这些特征向量捕获了模型的行为？</p><p>正如我们稍后在讨论实验结果时会看到的那样，即使可观察的传播确实因此产生了模型的不完整描述，它仍然拥有一些真正的实用性：它对与给定任务相关的注意力头提供了良好的零样本预测，它为我们提供了可用于改变模型行为的零样本转向向量，它使我们能够很好地理解一个注意头的输出与另一个注意头的输出相关的程度。我的看法是，OV 电路确实在我们感兴趣的许多任务（例如本文讨论的任务）中解释了模型的大量行为，并且至少对于这些任务，可观察传播可以是一个非常好的选择。理解模型行为的方法。</p><h2>处理非线性</h2><p>唉!现实世界中使用的变形金刚不仅仅是注意力。 Transformer 中每标记非线性的两种类型是 LayerNorm 和 MLP。我们处理它们的解决方案很简单：只需使用它们的梯度进行线性近似即可。更具体地说，如果我们有一些非线性函数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f : \mathbb{R}^d \to \mathbb{R}^d"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">:</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span></span></span> ，那么对于给定的可观察值<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> ，我们在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span>处将<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="g(x) = n \cdot f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;">g</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>近似为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x_0) + (x-x_0) \cdot \nabla g (x_0)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">∇</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;">g</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。我们可以看到，<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>近似等于<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\nabla g (x_0) \cdot x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">∇</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;">g</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>加上一些加性常数。因此，与可观察的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n 的</span></span></span></span></span></span></span><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>相关联的特征向量是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="g(x_0)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;">g</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。</p><p>当然，必须注意选择一个好的点<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span>来近似<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> 。我发现明智的做法是从正在使用的数据集中获取嵌入<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_-"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span></span></span></span></span></span></span></span> ，使得<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x_-) < 0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span> ，并嵌入嵌入<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_+"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span></span></span></span></span></span></span></span>使得<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x_+) > 0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">>;</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span> 。然后，您选择<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span>作为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_-"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span></span></span></span></span></span></span></span>和<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_+"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span></span></span></span></span></span></span></span>之间的直线上的点，使得<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x_0) = 0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span> 。这个想法是，<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>决策边界处的梯度应该捕获导致<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>为正或负的非线性<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>的更大规模行为；如果我们采用<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_-"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span></span></span></span></span></span></span></span>或<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_+"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span></span></span></span></span></span></span></span>处的梯度，那么非线性可能已经饱和，因此，非线性的行为可能无法表明其更广泛的行为。</p><p>现在，如果我们有一个涉及非线性的计算路径（例如，一个注意力头，后面跟着一个 LayerNorm，后面跟着另一个注意力头），那么给定一个可观察的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> ，我们可以如下计算整体特征向量。首先，计算与非线性相关的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span>的特征向量；将此特征向量称为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> 。然后，<i>将此特征向量</i>视为新的可观察量，并计算下层分量相对于“可观察量” <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span>的</span></span></span></span></span></span>特征向量。冲洗并根据需要重复<span class="footnote-reference" role="doc-noteref" id="fnrefdhiuepbiqad"><sup><a href="#fndhiuepbiqad">[4]</a></sup></span> 。</p><p>在这里，值得一提的是 Neel Nanda、Chris Olah、Catherine Olsson、Nelson Elhage 和 Tristan Hume 所做的<a href="https://www.neelnanda.io/mechanistic-interpretability/attribution-patching">“归因修补”</a> 。他们的想法是通过采用模型的线性近似来加速激活修补实验（在该实验中，将给定子层的模型的激活替换为另一个示例的激活，以确定该子层是否重要）。这样，您就可以计算线性近似，而不是每次想要修补子层的激活时重新运行完整的前向传递，这要快得多。 Nanda&#39;s post about this method also provides some good intuitions about when linear approximations should be expected to work well (and when they should be expected to work poorly), which is relevant when we want to use linear approximations alongside observable propagation.</p><h2> Dealing with LayerNorm</h2><p> LayerNorm is one particularly important nonlinearity to address, given that every sublayer in a Transformer is preceded by a LayerNorm. Therefore, we&#39;d be wise to perform a more thorough investigation of how amenable LayerNorm is to linear approximation -- and whether this approximation can be circumvented entirely.</p><p> In the &quot;attribution patching&quot; post, Nanda provides some intuitions about the gradient of LayerNorm. He argues that for sufficiently small regions of interest, LayerNorm can be treated as linear. The argument is this: the primary nonlinearity in a LayerNorm is a vector normalization step (ie <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v \mapsto \frac{v}{\Vert v \Vert}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">↦</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 1.191em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.685em; top: -1.16em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.685em; bottom: -0.999em;"><span class="mjx-mrow" style=""><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.191em;" class="mjx-line"></span></span><span style="height: 1.527em; vertical-align: -0.707em;" class="mjx-vsize"></span></span></span></span></span></span></span> ); in high-dimensional spaces, a small change <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Delta v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Δ</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span> will have a negligible component not orthogonal to <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span> ; vector normalization is approximately linear when <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Delta v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Δ</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span> is orthogonal to <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span> ; therefore, for small <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Delta v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Δ</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span> , LayerNorm is approximately linear.</p><p> We can build upon this intuition to give a precise argument regarding how LayerNorms affect feature vectors. In particular, we have the following theorem:</p><p> <strong>Theorem 1</strong> : <i>Define</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x; n) = n \cdot \operatorname{LayerNorm}(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">LayerNorm</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> <i>. Define</i></p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\theta(x;n) = \arccos\left(\frac{n \cdot \nabla_x f(x; n)}{\Vert n \Vert \Vert \nabla_x f(x; n) \Vert}\right)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">arccos</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size4-R" style="padding-top: 1.551em; padding-bottom: 1.551em;">(</span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 7.017em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 7.017em; top: -1.59em;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">∇</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span> <span class="mjx-denominator" style="width: 7.017em; bottom: -1.09em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">∇</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 7.017em;" class="mjx-line"></span></span><span style="height: 2.68em; vertical-align: -1.09em;" class="mjx-vsize"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-size4-R" style="padding-top: 1.551em; padding-bottom: 1.551em;">)</span></span></span></span></span></span></span></span><p> <i>-- that is,</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\theta(x;n)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> <i>is the angle between</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> <i>and</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\nabla_x f(x; n)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">∇</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> <i>. Then if</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> <i>and</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> <i>are iid</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathcal{N}(0,I)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.519em; padding-bottom: 0.372em; padding-right: 0.159em;">N</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> <i>in</i><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb{R}^d"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span></span></span> <i>, and</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="d\ge8"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.446em;">≥</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">8</span></span></span></span></span></span></span> <i>then</i></p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\mathbb{E}\left[ \theta(x;n) \right] < 2 \arccos\left(\sqrt{1-\frac{1}{d-1}}\right)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">E</span></span></span></span> <span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">arccos</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size4-R" style="padding-top: 1.551em; padding-bottom: 1.551em;">(</span></span> <span class="mjx-msqrt"><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-size4-R" style="padding-top: 1.551em; padding-bottom: 1.551em;">√</span></span> <span class="mjx-box" style="padding-top: 0.323em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mfrac MJXc-space2"><span class="mjx-box MJXc-stacked" style="width: 2.445em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 2.445em; top: -1.368em;"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="width: 2.445em; bottom: -0.866em;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 2.445em;" class="mjx-line"></span></span><span style="height: 2.234em; vertical-align: -0.866em;" class="mjx-vsize"></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-size4-R" style="padding-top: 1.551em; padding-bottom: 1.551em;">)</span></span></span></span></span></span></span></span><p> A proof can be found in <a href="https://github.com/jacobdunefsky/observable-propagation/raw/master/Observable_Propagation_Proofs.pdf">this PDF file</a> .</p><p> This theorem implies that in high dimensions, LayerNorms don&#39;t change the direction of feature vectors. For example, if we have a feature vector <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> for the input to an attention head, and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> is the feature vector corresponding to the input to a LayerNorm directly preceding that attention head, then the cosine similarity between <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> will be almost 1. This means that if you only care about the direction of your feature vectors, then you can completely ignore LayerNorms!</p><p> On the other hand, we also care about the magnitudes of our feature vectors. In this case, we then want to be able to quickly approximate LayerNorms&#39; gradients. It turns out that a principled way to do so is to compute <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{\sqrt{d}}{\widetilde{\Vert x \Vert}} W"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.253em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.772em; top: -1.766em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.111em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.772em; bottom: -1.248em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.189em; padding-bottom: 0.06em; padding-left: 0.064em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 0.519em; padding-bottom: 0.225em;">˜</span></span></span> <span class="mjx-op"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.253em;" class="mjx-line"></span></span><span style="height: 2.132em; vertical-align: -0.883em;" class="mjx-vsize"></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span> , where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="d"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span> is the model dimension, <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span> is the scaling matrix associated with the LayerNorm, and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\widetilde{\Vert x \Vert}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.189em; padding-bottom: 0.06em; padding-left: 0.064em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 0.519em; padding-bottom: 0.225em;">˜</span></span></span> <span class="mjx-op"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span></span></span></span></span></span></span> is an estimation of the input to the LayerNorm <span class="footnote-reference" role="doc-noteref" id="fnref5o6rzjjq02e"><sup><a href="#fn5o6rzjjq02e">[5]</a></sup></span> . Note that <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\widetilde{\Vert x \Vert}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.189em; padding-bottom: 0.06em; padding-left: 0.064em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 0.519em; padding-bottom: 0.225em;">˜</span></span></span> <span class="mjx-op"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span></span></span></span></span></span></span> is dependent on the distribution of inputs that you&#39;re considering, and as such, a LayerNorm approximation that works great for some inputs might not work well for others.</p><h1> Data-free feature vector analysis</h1><p> Once you&#39;ve used observable propagation to find feature vectors that you&#39;re interested in, you can then analyze those feature vectors <i>without running any forward passes</i> . In this section, I&#39;ll introduce two useful methods for doing so: looking at feature vector norms, and looking at &quot;coupling coefficents&quot;.</p><h2> Feature norm investigation</h2><p> Let&#39;s say that we have a set of model components (eg attention heads), and we want to get a preliminary idea of which of those heads will be important for a given observable. We can make an initial prediction by simply taking the norms of the feature vectors associated with those components; the feature vectors with the higher norms should correspond to components more likely to be relevant.</p><p> The rationale behind this: if a model component implements the computation <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> , and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span> is the feature vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> for observable <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> , then <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x) = y \cdot x = \Vert y \Vert \Vert x \Vert \cos \theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">cos</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span></span></span></span></span> , where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span></span></span></span></span> is the angle between <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> . This means that the output of that model component is proportional to <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Vert y \Vert"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span> . As such, knowing nothing else about our input, we can expect higher values of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Vert y \Vert"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span> to mean higher values of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> .</p><p> But knowledge about our input distribution changes the equation (literally). In particular, we have to make a slight correction for feature vectors involving LayerNorm gradients. In particular, if we are looking at the feature vector for the inputs to a LayerNorm, then as discussed above, the feature vector can be written as <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2 = \frac{\sqrt{d}}{\widetilde{\Vert x \Vert}} W y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 1.253em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.772em; top: -1.766em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.111em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.772em; bottom: -1.248em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.189em; padding-bottom: 0.06em; padding-left: 0.064em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 0.519em; padding-bottom: 0.225em;">˜</span></span></span> <span class="mjx-op"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.253em;" class="mjx-line"></span></span><span style="height: 2.132em; vertical-align: -0.883em;" class="mjx-vsize"></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> , where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> is the feature vector for whatever component comes immediately after the LayerNorm. Now, we have that</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\begin{align*} y_2 \cdot x &amp;= \Vert x \Vert \frac{\sqrt{d}}{\widetilde{\Vert x \Vert}} W \Vert y_1 \Vert \cos \theta \\ &amp;\approx \sqrt{d} W \Vert y_1 \Vert \cos \theta \\ &amp;\propto \sqrt{d} W \Vert y_1 \Vert \end{align*}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mtable" style="vertical-align: -2.721em; padding: 0px 0.167em;"><span class="mjx-table"><span class="mjx-mtr" style="height: 3.139em;"><span class="mjx-mtd" style="padding: 0px 0px 0px 0px; text-align: right; width: 2.173em;"><span class="mjx-mrow" style="margin-top: 0.65em;"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0px 0px 0px 0px; text-align: left; width: 9.985em;"><span class="mjx-mrow"><span class="mjx-mi"></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.772em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 1.772em; top: -1.65em;"><span class="mjx-msqrt"><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.111em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span> <span class="mjx-denominator" style="width: 1.772em; bottom: -1.339em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.189em; padding-bottom: 0.06em; padding-left: 0.064em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 0.519em; padding-bottom: 0.225em;">˜</span></span></span> <span class="mjx-op"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.772em;" class="mjx-line"></span></span><span style="height: 2.989em; vertical-align: -1.339em;" class="mjx-vsize"></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">cos</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span><span class="mjx-strut"></span></span></span></span> <span class="mjx-mtr" style="height: 1.477em;"><span class="mjx-mtd" style="padding: 0.15em 0px 0px 0px; text-align: right;"><span class="mjx-mrow" style="margin-top: -0.098em;"><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0.15em 0px 0px 0px; text-align: left;"><span class="mjx-mrow" style="margin-top: -0.098em;"><span class="mjx-mi"></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">≈</span></span> <span class="mjx-msqrt MJXc-space3"><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.063em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">cos</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span><span class="mjx-strut"></span></span></span></span> <span class="mjx-mtr" style="height: 1.327em;"><span class="mjx-mtd" style="padding: 0.15em 0px 0px 0px; text-align: right;"><span class="mjx-mrow" style="margin-top: -0.098em;"><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0.15em 0px 0px 0px; text-align: left;"><span class="mjx-mrow" style="margin-top: -0.098em;"><span class="mjx-mi"></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">∝</span></span> <span class="mjx-msqrt MJXc-space3"><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.063em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span><span class="mjx-strut"></span></span></span></span></span></span></span></span></span></span></span><p> Therefore, if your feature vector involves any LayerNorm gradients, then the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\widetilde{\Vert x \Vert}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.189em; padding-bottom: 0.06em; padding-left: 0.064em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 0.519em; padding-bottom: 0.225em;">˜</span></span></span> <span class="mjx-op"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span></span></span></span></span></span></span> term corresponding to the earliest LayerNorm in the computational path that you&#39;re considering should be ignored when looking at the norm of your feature vector.</p><h2> Coupling coefficients</h2><p> A common similarity metric for comparing feature vectors is the cosine similarity: the extent to which the two vectors point in the same direction. But we introduce another similarity metric that answers a question related to more specific predictions about model outputs.</p><p> Let&#39;s say that you have two feature vectors <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> for the same model component, corresponding to different observables. Now, if an input has a high dot product with <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> , then does this imply that the input will have a high dot product with <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> ? Answering this question provides a good metric of the extent to which one observable&#39;s output is &quot;coupled&quot; to another observable&#39;s output.</p><p> Having motivated this problem, let us translate it into the language of feature vectors. If <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> are observables with feature vectors <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> for a function <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> , then for inputs <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> , we have <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_1 \cdot f(x) = y_1 \cdot x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_2 \cdot f(x) = y_2 \cdot x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> . Now, if we constrain our input <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> to have norm <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="s"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span></span></span></span></span></span> , and constrain <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot y_1 = k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span></span></span> , then what is the expected value of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> ? And what are the maximum/minimum values of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> ? I present the following theorem to answer both questions:</p><p> <strong>Theorem 2</strong> : <i>Let</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1, y_2 \in \mathbb{R}^d"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span></span></span> <i>. Let</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> <i>be uniformly distributed on the hypersphere defined by the constraints</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Vert x \Vert = s"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span></span></span></span></span></span> <i>and</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot y_1 = k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span></span></span> <i>. Then we have</i></p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\mathbb{E}[x \cdot y_2] = k \frac{y_1 \cdot y_2}{\Vert y_1^2 \Vert}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">E</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 2.68em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 2.68em; top: -1.237em;"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span> <span class="mjx-denominator" style="width: 2.68em; bottom: -1.233em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.082em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 2.68em;" class="mjx-line"></span></span><span style="height: 2.47em; vertical-align: -1.233em;" class="mjx-vsize"></span></span></span></span></span></span></span><p> <i>and the maximum and minimum values of</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> <i>are given by</i></p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\frac{\Vert y_2 \Vert}{\Vert y_1 \Vert} \left(k\cos(\theta) \pm \sin(\theta)\sqrt{s^2 \Vert y_1 \Vert^2-k^2} \right)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 2.079em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 2.079em; top: -1.59em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span> <span class="mjx-denominator" style="width: 2.079em; bottom: -1.09em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 2.079em;" class="mjx-line"></span></span><span style="height: 2.68em; vertical-align: -1.09em;" class="mjx-vsize"></span></span> <span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 1.256em; padding-bottom: 1.256em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">cos</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">±</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">sin</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-msqrt"><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-size2-R" style="padding-top: 0.961em; padding-bottom: 0.961em;">√</span></span> <span class="mjx-box" style="padding-top: 0.251em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 1.256em; padding-bottom: 1.256em;">)</span></span></span></span></span></span></span></span><p> <i>where</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span></span></span></span></span> <i>is the angle between</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> <i>and</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> <i>.</i></p><p> The proof of this theorem can be found in <a href="https://github.com/jacobdunefsky/observable-propagation/raw/master/Observable_Propagation_Proofs.pdf">the PDF file from earlier</a> .</p><p> The second part of this theorem shows that the angle between the two feature vectors is important: the greater the angle, then the wider the spread of possible values for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> . This provides good motivation for using the cosine similarity to measure feature vector &quot;coupling&quot;. But the term in the first part of the theorem, <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="k \frac{y_1 \cdot y_2}{\Vert y_1^2 \Vert}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.679em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 2.375em; top: -1.367em;"><span class="mjx-mrow" style=""><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 2.375em; bottom: -1.323em;"><span class="mjx-mrow" style=""><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-stack" style="vertical-align: -0.402em;"><span class="mjx-sup" style="font-size: 83.3%; padding-bottom: 0.216em; padding-left: 0.069em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.679em;" class="mjx-line"></span></span><span style="height: 1.902em; vertical-align: -0.935em;" class="mjx-vsize"></span></span></span></span></span></span></span> , is also important, because it tells you the expected value of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> .</p><p> Motivated by this, let&#39;s define <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="C(y_1,y_2) = \frac{y_1 \cdot y_2}{\Vert y_1^2 \Vert}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 1.679em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 2.375em; top: -1.367em;"><span class="mjx-mrow" style=""><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 2.375em; bottom: -1.323em;"><span class="mjx-mrow" style=""><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-stack" style="vertical-align: -0.402em;"><span class="mjx-sup" style="font-size: 83.3%; padding-bottom: 0.216em; padding-left: 0.069em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.679em;" class="mjx-line"></span></span><span style="height: 1.902em; vertical-align: -0.935em;" class="mjx-vsize"></span></span></span></span></span></span></span> to be the &quot; <strong>coupling coefficient</strong> from <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> to <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> &quot;. The intuitive interpretation of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="C(y_1, y_2)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> is that on average, the output of the observable <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> associated with feature vector <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> should be <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="C(y_1,y_2)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> times the output of observable <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> associated with feature vector <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> .</p><p> We will later see how coupling coefficients can be used to help find steering vectors that reduce gender-biased model outputs in a preliminary experiment.</p><h1> Experiments</h1><p> In order to begin testing out observable propagation, I ran some preliminary experiments intended to build some intuition about the utility of observable propagation.</p><p> In particular, I considered two &quot;case studies&quot;. The former deals with the task of gendered pronoun prediction previously addressed by <a href="https://cmathw.itch.io/identifying-a-preliminary-circuit-for-predicting-gendered-pronouns-in-gpt-2-smal">Mathwin et al.</a> 。 The latter considers occupational gender bias (ie the model predicting that a female name is more or less likely to partake in certain occupations than a male name).</p><p> We&#39;ll now proceed to look at a selection of interesting results from each of the two case studies. Those who would like to see more results should rest assured that I&#39;m currently performing more experiments (including experiments that both consider more deeply the case studies addressed here, along with experiments addressing other case studies), and look forward to an update post with the results of these experiments.</p><h2> The model</h2><p> The language model that was used in all of these experiments is GPT-Neo-1.3B. This model has approximately 1.3 billion parameters, 24 layers, 16 attention heads per attention sublayer, an embedding space dimension of 2048, and an MLP hidden layer dimension of 8192. As such, it&#39;s a rather larger model than the GPT-2 series, which tends to be more frequently used in interpretability experiments. Using a larger model suggests the potential for observable propagation to scale (although 1.3 billion parameters is still quite a good deal smaller than the current state-of-the-art models.)</p><h2> Gendered pronoun prediction</h2><h3> Problem setting</h3><p> This problem investigates the question of what causes the model to predict the token &quot; she&quot; instead of &quot; he&quot;, or &quot; her&quot; instead of &quot; him&quot;. <a href="https://cmathw.itch.io/identifying-a-preliminary-circuit-for-predicting-gendered-pronouns-in-gpt-2-smal">Mathwin et al.</a> looked into the subject pronoun case (that is, the case of predicting &quot; she&quot; versus &quot; he&quot;) in GPT-2-small. They analyzed which components in the model were responsible for predicting these gendered pronouns. But with observable propagation, we can go further, and gain insights into the specific features that are being used in this task. Additionally, we consider the object pronoun case (ie &quot; her&quot; versus &quot; him&quot;) as well as the subject pronoun case, in order to see if there are any commonalities in the features by the model.</p><p> The observable that corresponds to the subject pronoun task is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(e_{\text{&quot; she&quot;}} - e_{\text{&quot; he&quot;}})"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; she&quot;</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; he&quot;</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> ; we denote this observable by <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> . The observable that corresponds to the object pronoun task is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(e_{\text{&quot; her&quot;}} - e_{\text{&quot; him&quot;}})"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; her&quot;</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; him&quot;</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> ; we denote this observable by <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> .</p><h3> Prompts</h3><p> Following Mathwin et al., we generate a dataset of prompts by taking a prompt template and filling in gendered names. Our prompt template for the subject pronoun case is <code>&quot;&lt;|endoftext|>;So, [NAME] really is a great friend, isn&#39;t&quot;</code> ; prompts are then generated by replacing <code>[NAME]</code> with a gendered name. The idea is that if the name is female, like &quot;Clara&quot; or &quot;Judy&quot;, then the most likely next token would be &quot; she&quot;, whereas if the name is male, like &quot;Mike&quot; or &quot;Joe&quot;, then the most likely next token would be &quot; he&quot;. Similarly, our prompt template for the object pronoun case is <code>&quot;&lt;|endoftext|>;What do I think about [NAME]? Well, to be honest, I love&quot;</code> .</p><p> Our list of names is as follows. Male names used are “John”, “David”, “Mark”, “Paul”, “Ryan”, “Gary”, “Jack”, “Arnold”, “Joe”, “Andy”; female names used are “Jennifer”, “Jane”, “Annie”, “Chloe”, “Amy”, “Judy”, “Lisa”, “Carol”, “Clara”, “Sarah”. Note that all names are one token long.</p><h3> Feature vector norms</h3><p> I calculated the norms of the feature vectors for each attention head for both the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> observable and the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> . The results can be found in the following figures. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/oi5dnlyytlqsdmzpslar" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/vpi9fn2xiettletivpkl 153w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/rp2pu9wgmtltqmgvrica 233w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/zovioyj8y7iuolbtn9aw 313w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/hlhf4ln3jwor0tjggxm2 393w"></figure><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/bdvedhicucuhqn1djefl" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/hiwfstnbcvmoxf57nxfz 153w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/o0pisx0lsrje6fnkrr9s 233w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/j5mk5cvmx35vup9okvls 313w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/gwl0wgt57s849zejlsim 393w"></figure><p> When taking into account LayerNorms, the attention heads with the highest feature vector norms for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> are 18.11, 17.14, 13.11, and 15.13, with norms 237.3204, 236.2457, 186.3744, 145.4124 respectively. The attention heads with the highest feature vector norms for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> are 17.14, 18.11, 13.11, and 15.13, with norms 159.1822, 156.9978, 144.9379, 112.3253. These are the four heads that are lit up the brightest in the figures.</p><p> Now, I then used activation patching to calculate the contribution of each head to the logits. The mean result over our dataset can be found in the following figures. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/pybrmfgaz0vvax1jkqqe" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/tgpsuffyjbctsidtsehx 135w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/pb7j94skgkigtkwf5hwq 215w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/zzurcsxpwfy4kp74pe9p 295w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/pxoioopnsree4wizmbte 375w"></figure><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/jduwkqywcditlxzfilnr" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/nckj0sb8hkco3ca6q59r 148w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/ntisqz0hp07upm4fzjth 228w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/epfpg1jp4tblpngfxro7 308w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/nmyfrcd1x96skngegv9a 388w"></figure><p> The four attention heads with the highest attributions for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> are 17.14, 13.11, 15.13, and 13.3, with corrupted-clean logit differences of 4.7859, 4.5473, 1.0804, 0.6352 respectively. The four attention heads with the highest attributions for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> are 17.14, 15.13, 13.11, and 22.2, with corrupted-clean logit differences of 3.5636, 3.0652, 2.1328, 0.5218 respectively. The most striking result is that the three attention heads with the largest attributions are a subset of those four heads with the highest feature norms. Of course, also striking is the absence of attention head 18.11 from the list of heads with highest attributions, despite being among the heads with highest feature norms; my suspicion is that this is due to QK circuit effects (ie attention head 18.11 yields outputs that would&#39;ve contributed greatly to the observables -- but it doesn&#39;t attend to the tokens that would be responsible for those outputs).</p><p> Despite the &quot;false positive&quot; of attention head 18.11, seeing that feature vector norms were able to correctly predict three of the four heads with highest attribution on real data -- predicting this <i>without using any data</i> <span class="footnote-reference" role="doc-noteref" id="fnref3ckjhluza55"><sup><a href="#fn3ckjhluza55">[6]</a></sup></span> and <i>only using the OV circuit</i> -- was very exciting for me. My intuition regarding the use of feature vector norms, therefore, is that they can yield an inexpensive initial &quot;ansatz&quot; of which model components you should further investigate with more data- and computationally-intensive methods.</p><h3> Cosine similarities and coupling coefficients</h3><p> The next thing to look into: cosine similarities and coupling coefficients between the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> feature vectors and the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> feature vectors. The four heads with the highest cosine similarities between are 17.14, 18.11, 15.13, and 13.11, with cosine similarities of 0.9882, 0.9831, 0.9816, and 0.9352 respectively. Note that these cosine similarities are very close to 1 -- indicating that the model is using (approximately) the same feature vectors for predicting subject pronouns as it uses for predicting object pronouns. When I first saw these results, I was very excited: <i>we now have evidence of a case where the model is using the same features for two different tasks</i> ! Even though subject pronoun prediction and object pronoun prediction are indeed similar, there is no guarantee that the model would use the same features for both: hence my welcome surprise at seeing otherwise.</p><p> Indeed, when we look at the cosine similarities between the pre-unembedding observables <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W_U^T n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.327em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W_U^T n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.327em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> , we find that they only have a cosine similarity of 0.5685. Thus, even though the tasks are similar, they are not so inherently similar as for it to be trivial that the model would use the same features for both.</p><p> I then looked at the coupling coefficients between heads 17.14, 15.13, and 13.11 (the heads that appear in common among those with the highest cosine similarities, highest feature norms, and highest head attributions). After finding them, the next step was to record the actual dot products of all embeddings in the dataset with the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> feature vectors and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> feature vectors. Once this was done, then for each feature vector, I considered the ratio of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> to <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> dot products, and found the best-fit line to fit this data. The results are given in the below table.</p><figure class="table"><table><thead><tr><th> Head</th><th> Coupling coefficient</th><th> Cosine similarity</th><th> Best-fit line slope</th><th> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="r^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">r</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span></th></tr></thead><tbody><tr><td> 17.14</td><td> 0.67086</td><td> 0.9882</td><td> 0.67774</td><td> 0.99811</td></tr><tr><td> 15.13</td><td> 0.77306</td><td> 0.9816</td><td> 0.79353</td><td> 0.98146</td></tr><tr><td> 13.11</td><td> 0.73552</td><td> 0.9352</td><td> 0.75580</td><td> 0.9274281</td></tr></tbody></table></figure><p> Notice that the coupling coefficients almost exactly match the slopes of the best-fit lines -- indicating that they did indeed accurately predict the ratio of dot products.</p><p> In addition to looking at the ratio of dot products between the two vectors, we also investigated whether the coupling coefficients predicted the ratio of activation patching attribution scores between heads. The resulting scatter plot is given below: each point represents an attention head, its x-coordinate represents its coupling coefficient, and its y-coordinate represents the ratio between the mean attribution score for that head for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> and the mean attention score for that head for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> . (Note that I excluded attention heads with attribution scores less than 0.1.) </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/jheoyn9fln2i7yueuh7b" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/duyy26u39pgbavnvwy9x 96w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/i97b9e8ovkeocug0rry9 176w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/vyc9skbor4bjq79dudir 256w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/pku6jcohddfbftt0jp6c 336w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/bvyd2npiyqzjvwfszopb 416w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/fixnrhpnp994cg3glstd 496w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/hyqgczdckk3kqusqfosv 576w"></p><p> Due to QK-circuit effects, there isn&#39;t a perfect correlation here, as opposed to when coupling coefficients are used for predicting dot products. Nevertheless, we can see that coupling coefficients still provide a decent estimation of not only the extent to which feature vectors&#39; dot products will be coupled, but even the extent to which attention heads&#39; <i>attributions</i> will be coupled.</p><h3> SVD</h3><p> One thing that I was interested in determining: to what extent are the feature vectors obtained by observable propagation aligned with the singular vectors of weight matrices? I investigated this for the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W_{OV}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.229em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span></span></span></span></span></span></span> matrices of the three attention heads considered above: 17.14, 15.13, and 13.11. The below table provides, for each head, the indices of the singular vectors that have the highest cosine similarities with the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> feature vectors for that head, along with the cosine similarities.</p><figure class="table"><table><thead><tr><th> Head</th><th> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> vs <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></th><th> Top 5 singular vector indices</th><th> Top 5 absolute cosine similarities</th></tr></thead><tbody><tr><td> 17.14</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span></td><td> 1, 3, 0, 2, 4</td><td> 0.8169, 0.4725, 0.2932, 0.0981, 0.0827</td></tr><tr><td> 17.14</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></td><td> 1, 3, 0, 4, 15</td><td> 0.8052, 0.4980, 0.2758, 0.1019, 0.0394</td></tr><tr><td> 15.13</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span></td><td> 0, 1, 17, 28, 13</td><td> 0.9466, 0.1254, 0.0875, 0.0774, 0.0747</td></tr><tr><td> 15.13</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></td><td> 0, 1, 9, 65, 13</td><td> 0.9451, 0.1761, 0.0761, 0.0622, 0.0597</td></tr><tr><td> 13.11</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span></td><td> 4, 3, 2, 1, 7</td><td> 0.6470, 0.5843, 0.3451, 0.2164, 0.1508</td></tr><tr><td> 13.11</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></td><td> 3, 4, 2, 7, 8</td><td> 0.5982, 0.5345, 0.4869, 0.1499, 0.1007</td></tr></tbody></table></figure><p> For head 15.13, singular vector 0 was very well-aligned with the feature vectors that observable propagation finds. However, this is less the case for head 17.14 (where the top absolute cosine similarities for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> are 0.8169 and 0.8052 respectively), and even less so for head 13.11 (where the top absolute cosine similarities for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> are 0.6470 and 0.5982 respectively). Additionally, for heads 17.14 and 13.11 in particular, the absolute cosine similarities for singular vectors other than the most similar one are still non-negligible, indicating that one singular vector alone cannot capture the full behavior of the feature vector.</p><p> It is also worth noting that for head 13.11, the most similar singular vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> is different from the most similar singular vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> . Since similar vectors are orthogonal, this means that naively analyzing head 13.11 by looking at the most similar singular vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> would mistakenly indicate that these two observables correspond to different features (despite their feature vector cosine similarity of 0.9352).</p><p> I think that these examples demonstrate the utility of using SVD to interpret weight matrices as explored by <a href="https://www.lesswrong.com/posts/mkbGjzxD8d8XqKHzA/">Beren Millridge and Sid Black</a> -- but also the necessity of constructing explicit feature vectors using observable propagation, rather than only looking at the most similar singular vectors. SVD can prove useful as an initial step for interpretability, but it doesn&#39;t tell the whole story; observable propagation&#39;s explicit feature vectors allow for further quantitative analysis to be performed.</p><h3> Activation steering</h3><p> As mentioned earlier, observable propagation does not take into account the nonlinearities involved in the QK circuit of Transformers. Thus, there was a fear that the feature vectors yielded by observable propagation would be unable to accurately predict the behavior of the model in practice.</p><p> In order to test this fear, I performed some preliminary activation steering experiments: seeing if adding the feature vectors found by observable propagation to the embeddings of certain tokens could be used to change the model&#39;s output. The idea is that if these vectors represent features that are robust even in the presence of the QK circuit, then adding these vectors should cause the model&#39;s output to change accordingly (eg adding a feature vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> to embeddings should lead to a higher output for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> ).</p><p> I tested activation steering on the three attention heads of interest (17.14, 15.13, 13.11) for both the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> observables. First, I used <a href="https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=disz2gTx-jooAcR0a5r8e7LZ">logit attribution</a> to determine which token was most important for each head. Then, I added/subtracted 50 times the feature vector for that attention head to the embeddings of that token <span class="footnote-reference" role="doc-noteref" id="fnrefyjcwq2rp51i"><sup><a href="#fnyjcwq2rp51i">[7]</a></sup></span> . I looked at the mean difference in model output over our dataset of prompts; the results can be found in the below table.</p><figure class="table"><table><thead><tr><th> Head</th><th> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> vs <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></th><th>代币</th><th><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-50v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">50</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span> mean difference</th><th> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="+50v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">50</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span> mean difference</th></tr></thead><tbody><tr><td> 17.14</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span></td><td> 15</td><td> -100.780</td><td> 87.517</td></tr><tr><td> 17.14</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></td><td> 15</td><td> -87.038</td><td> 70.865</td></tr><tr><td> 15.13</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span></td><td> 6</td><td> -13.238</td><td> 26.132</td></tr><tr><td> 15.13</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></td><td> 6</td><td> -22.681</td><td> 23.150</td></tr><tr><td> 13.11</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span></td><td> 6</td><td> -4.111</td><td> 12.659</td></tr><tr><td> 13.11</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></td><td> 6</td><td> -16.343</td><td> 5.992</td></tr></tbody></table></figure><p> As we can see, the feature vectors were quite effective -- although more so in some attention heads than others. In addition to different strengths of effects, we also see asymmetries, in which subtracting a feature vector yields a greater effect than adding that feature vector, or vice versa. I chalk these phenomena up to QK circuit nonlinearities, along with attention head composition effects (eg the feature vector for head 13.11 might actually be in the opposite direction as the feature vector for virtual attention head 13.3 ->; 17.14 -- where the same steering vector not only affects different heads in the same layer, but even different heads later on in the computation). Nevertheless, the fact that activation steering was efficacious in this setting gives me hope for observable propagation.</p><h2> Preliminary gender bias results</h2><p> In addition to the work on gendered pronoun prediction, I also wanted to investigate a more &quot;practical&quot; problem: addressing occupational gender bias in language models. Consider the prompt template <code>&quot;&lt;|endoftext|>;My friend [NAME] is an excellent&quot;</code> , where <code>[NAME]</code> is replaced by the names a gendered name. Now, if the name in the prompt is female, then we would expect the model to predict that the next token is more likely to be &quot; actress&quot; than &quot; actor&quot; -- the two tokens refer to the same occupation, but the former is grammatically female, while the latter is conventionally grammatically male. This is sensible behavior from the language model.</p><p> However, the model also predicts that for a female name, the next token is more likely to be &quot; nurse&quot; than &quot; programmer&quot;. In this case, we say that the model is biased, because it is making a prediction on the basis of gender, even though the difference between the occupations of nursing and programming should not be related to grammatical gender.</p><p> As such, this motivates the following questions:</p><ul><li> Do the same features that cause the model to predict &quot; actress&quot; to be more likely than &quot; actor&quot; also cause the model to predict &quot; nurse&quot; to be more likely than &quot; programmer&quot;?</li><li> Can we find activation steering vectors that lessen the extent to which &quot; nurse&quot; is predicted over &quot; programmer&quot;, while increasing the extent to which &quot; actress&quot; is predicted over &quot; actor&quot;?</li></ul><p> We can begin to tackle these tasks by defining the observables of interest. <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> will be the observable <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="e_{\text{&quot; actress&quot;}} - e_{\text{&quot; actor&quot;}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; actress&quot;</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; actor&quot;</span></span></span></span></span></span></span></span></span></span></span> , representing the extent to which the model predicts the token &quot; actress&quot; over &quot; actor&quot;. <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> will be the observable <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="e_{\text{&quot; nurse&quot;}} - e_{\text{&quot; programmer&quot;}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; nurse&quot;</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">&quot; programmer&quot;</span></span></span></span></span></span></span></span></span></span></span> , representing the extent to which the model predicts the token &quot; nurse&quot; over &quot; programmer&quot;. Ideally, the model&#39;s outputs would be high for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> given female names, because this represents the model recognizing that the word &quot;actress&quot; is specifically applied to women; on the other hand, the model&#39;s outputs should be low for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> given female names, because otherwise, this is evidence of model bias.</p><p> Although I&#39;m still in the process of investigating this task, here are a few preliminary results demonstrating the application of observable propagation to this setting.</p><h3> The model uses some of the same features to predict <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> as <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span></h3><p> Initially looking at the cosine similarities for attention heads&#39; feature vectors between <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> didn&#39;t indicate that the model was using similar features for both observables: the highest cosine similarity found was only 0.4896, for head 15.13. (Interestingly, we also found a number of heads with cosine similarities less than -0.75.)</p><p> However, I then took into account attention head composition, which bore more fruit. As one example, I found that the feature vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> corresponding to virtual attention head <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="6.6 \to 15.13 \to 17.14"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">6.6</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">15.13</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">17.14</span></span></span></span></span></span></span> had a cosine similarity of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="0.9541"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.9541</span></span></span></span></span></span></span> with the feature vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> corresponding to virtual head <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="6.6 \to 15.13 \to 21.13"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">6.6</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">15.13</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">21.13</span></span></span></span></span></span></span> . Note that the cosine similarity for head 6.6, without considering any attention head composition, is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-0.0640"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.0640</span></span></span></span></span></span></span> .</p><p> My preliminary takeaway is that when attention head composition is taken into account, the model does use some of the same features in computing its output for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> as it does for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> . In other words, some of the same information that is used to correctly predict that a female name is more likely to precede the token &quot; actress&quot; than &quot; actor&quot; is also used to yield the biased output that female names are more likely to be associated with the token &quot; nurse&quot; than &quot; programmer&quot;.</p><p> In an update, I plan to provide a more thorough analysis of shared feature vectors between the two observables. For now, though, results such as this seem to suggest that to some extent, the same intermediate computations are being used in both the desired scenario and the biased scenario.</p><h3> Finding steering vectors to debias the model</h3><p> I then wanted to see if I could find some steering vectors such that, when these vectors were added to certain activations, they would improve the model&#39;s performance on the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> objective but decrease its performance on the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> objective; this corresponds to decreasing biased behavior while increasing desired behavior.</p><p> As our steering vectors, I tried using the feature vectors from a number of different attention heads whose coupling coefficients between <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> feature vectors were the most negative. Although not every head worked, I found a number of heads where adding the feature vectors for those heads did yield the desired effects. I evaluated activation steering results using the methodology from the previous activation steering experiments, using a dataset generated by inserting gendered names into the prompt template <code>&quot;&lt;|endoftext|>;My friend [NAME] is an excellent&quot;</code> . The results for these heads can be found in the below table:</p><figure class="table"><table><thead><tr><th> Head</th><th>代币</th><th><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> or <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span></th><th> Coupling</th><th> Feature multiplier</th><th> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> effect</th><th> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> effect</th></tr></thead><tbody><tr><td> 17.6</td><td> 5</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span></td><td> -0.5230</td><td> -300</td><td> -3.6119</td><td> 2.7614</td></tr><tr><td> 18.2</td><td> 0</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span></td><td> -0.2298</td><td> -1000</td><td> -0.4604</td><td> 0.4694</td></tr><tr><td> 19.15</td><td> 0</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span></td><td> -0.4957</td><td> -300</td><td> -0.8513</td><td> 1.8351</td></tr><tr><td> 23.10</td><td> 4</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span></td><td> -0.5665</td><td> -120</td><td> -1.2027</td><td> 0.1038</td></tr></tbody></table></figure><p> Note that some trial and error was used to find which attention heads yielded the best effects, along with which feature multipliers were the best. For the reasons mentioned in the discussion of the previous activation steering experiments, not every attention head worked as much as one might initially think. However, by using the heads with the most negative coupling coefficients as a guide, I was able to relatively-easily find some good steering vectors.</p><p> In particular, when I subtracted <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-300"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">300</span></span></span></span></span></span></span> times the feature vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> for attention head 17.6 from the embeddings of token 5, this impressively led to a mean effect of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-3.6119"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3.6119</span></span></span></span></span></span></span> logits for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="2.7614"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2.7614</span></span></span></span></span></span></span> logits for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> . This means that after this vector was applied to the embeddings, <i>the average prediction of the biased output was</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-3.6119"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3.6119</span></span></span></span></span></span></span> <i>logits less than before</i> , while the average prediction of the grammatically-correct output was 2.7614 logits more than before.</p><p> I found these preliminary activation steering results to be a nice example of the benefits that observable propagation brings. By enabling specific tasks to be mathematically formalized as observables, whose corresponding feature vectors can then be compared using metrics like coupling coefficients, the search for steering vectors that improve the model&#39;s performance on one task while decreasing it on another can be made far simpler.</p><h1>讨论</h1><p>So, given these experiments, how useful can we say that observable propagation is? The preliminary results that I&#39;ve found so far (including those presented in this post) suggest that it&#39;s pretty useful in at least the following ways:</p><ul><li> It allows for the behavior of model components to be predicted without running the model on any data, using feature vector norms and coupling coefficients. Even when there are differences between the predictions and the actual results, the predictions can nevertheless be used as a good jumping-off point for further analysis.</li><li> It can provide a &quot;trace&quot; of what information is being used throughout the model for a given task.</li><li> It lets us get a look at when the model is using the same features for multiple different tasks, allowing for a better understanding of common computations used by the model.</li><li> It can be used as a starting point for finding activation steering vectors relevant to specific tasks, or even activation steering vectors that can have different (intended) effects on different tasks.</li></ul><p> Of course, there are still a number of limitations to observable propagation as presented. The biggest such limitation is that observable propagation only addresses OV circuits in Transformers, ignoring all of the computation performed in QK circuits. This means, for instance, that the mechanisms behind <a href="https://transformer-circuits.pub/2021/framework/index.html#induction-heads">induction heads</a> cannot be adequately modeled. This also leads to some of the unexpected effects seen in the activation steering experiments (eg asymmetric effects, feature vectors being less efficacious than expected, etc.). Now, dealing with QK circuits is quite difficult, because unlike MLPs and LayerNorms, QK circuits are nonlinearities that involve multiple tokens. But in order for us to have a full understanding of Transformers, though, QK circuits must be tackled: there cannot be any <i>ignorabimus</i> .</p><p> Beyond this, there is also the question of the extent to which the linear approximation approach for extending observable propagation to work with MLPs can yield a tractable set of features corresponding to different nearly-linear subregions in the MLP ( <i>a la</i> the <a href="https://www.lesswrong.com/posts/eDicGjD9yte6FLSie">polytope lens</a> ), or whether the nonlinearities in MLPs are so great as to make such an effort infeasible. Some preliminary experiments that didn&#39;t make it into this post indicated MLP feature vectors for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> with a cosine similarity of around 0.60 -- which isn&#39;t too high. But cosine similarity might not be the right metric for measuring similarity between &quot;local features&quot; found via linear approximation; alternatively, a better method for finding the point at which the linear approximation is performed might have yielded more similar feature vectors. Regardless, I plan to run more experiments on larger datasets with a focus on MLP features.</p><p> Despite these limitations, I think that observable propagation represents an important first step towards deeply understanding the feature vectors that Transformers utilize in their computations, and how these feature vectors can be used to change these models&#39; behavior. For me at least, the results of these preliminary experiments suggest that observable propagation will prove to be a useful tool for both interpreting and steering Transformers.</p><p> As a final note, let&#39;s return to the earlier question of what generalizations could increase the power of observable propagation that I&#39;m failing to make. It&#39;s hard for me to enumerate a list of my own blind spots, of course. I will say, though, that one limitation is that the &quot;observable/feature vector&quot; paradigm only looks at the interaction between a single token and a feature vector, rather than the interaction between multiple tokens. But interactions between multiple tokens are necessary for understanding QK circuits, for instance. Now, in the setting of linear algebra, a natural sort of function on multiple vectors is a &quot;multilinear form&quot;, which generalizes the notion of a linear functional to multiple arguments. As such, one way to generalize the observable propagation paradigm, which currently only makes use of linear functionals, would be to consider multilinear forms. But the proper way to do so remains to be seen.</p><h1>结论</h1><p>In this post, I introduce &quot;observable propagation&quot;, a simple method for automatically finding feature vectors in Transformers&#39; OV circuits that correspond to certain tasks. This post also develops a mathematical framework for analyzing these feature vectors, that allows for the prediction of model behavior on different tasks without running the model on any data. Preliminary experiments suggest that these methods perform well in predicting model behavior and steering model behavior towards desired outcomes. Of course, there&#39;s still a lot more work to be done in testing these methods and improving them, but I think that what I&#39;ve presented thus far in this post implies that observable propagation can already be useful.</p><p> If this post has piqued your interest, then stay tuned for an update which will contain even more experiments. Thank you for reading! </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnu4fd3ietm2f"> <span class="footnote-back-link"><sup><strong><a href="#fnrefu4fd3ietm2f">^</a></strong></sup></span><div class="footnote-content"><p> For those who have read ahead: this refers to finding approximate feature vectors by ignoring LayerNorms, and finding better approximations using small amounts of data by finding the linear approximation of LayerNorm at those datapoints.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnq6jwzi5ovy"> <span class="footnote-back-link"><sup><strong><a href="#fnrefq6jwzi5ovy">^</a></strong></sup></span><div class="footnote-content"><p> This name is intended to suggest the notion of &quot;observables&quot; from quantum mechanics; in that domain, observables are Hermitian operators corresponding to certain properties of a quantum system that one wants to measure. Although there are some differences between that setting and the LLM setting (for instance, a linear functional is not a Hermitian operator), the similarities between the two cases provide valuable intuition: in both cases, an observable is a linear map that corresponds to a type of measurement of a probabalistic system.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnlpxvw4f8bc"> <span class="footnote-back-link"><sup><strong><a href="#fnreflpxvw4f8bc">^</a></strong></sup></span><div class="footnote-content"><p> Note that while linear functionals and vectors are different beasts in general, it&#39;s true that in finite-dimensional vector spaces, there is a one-to-one natural correspondence between linear functionals and vectors. As such, for a vector <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> , I might abuse notation a bit and refer to both <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n^T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span> as observables.</p></div></li><li class="footnote-item" role="doc-endnote" id="fndhiuepbiqad"> <span class="footnote-back-link"><sup><strong><a href="#fnrefdhiuepbiqad">^</a></strong></sup></span><div class="footnote-content"><p> In essence, what this process is actually doing is computing the gradient of a specific computational path through the model that passes through the nonlinearity.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn5o6rzjjq02e"> <span class="footnote-back-link"><sup><strong><a href="#fnref5o6rzjjq02e">^</a></strong></sup></span><div class="footnote-content"><p> This follows from the expression for the gradient of LayerNorms used in the <a href="https://raw.githubusercontent.com/jacobdunefsky/observable-propagation/master/Observable_Propagation_Proofs.pdf">proof of Theorem 1</a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fn3ckjhluza55"> <span class="footnote-back-link"><sup><strong><a href="#fnref3ckjhluza55">^</a></strong></sup></span><div class="footnote-content"><p> Technically, the mean norms of embeddings were used in order to approximate the gradient of the final LayerNorm in the model, <code>ln_f</code> . But because the computational paths associated with these single attention heads all go through the same LayerNorm, we can get a decent approximation of relative feature vector norms by simply ignoring the LayerNorms entirely. I haven&#39;t included the figures for that here, but looking at feature vector norms without taking into account LayerNorms yields the same top four attention heads.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnyjcwq2rp51i"> <span class="footnote-back-link"><sup><strong><a href="#fnrefyjcwq2rp51i">^</a></strong></sup></span><div class="footnote-content"><p> There was nothing principled about multiplying the feature vector by 50, as opposed to some other constant.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/jDfjqu2qJLcPco9cf/automatically-finding-feature-vectors-in-the-ov-circuits-of#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/jDfjqu2qJLcPco9cf/automatically-finding-feature-vectors-in-the-ov-circuits-of<guid ispermalink="false"> jDfjqu2qJLcPco9cf</guid><dc:creator><![CDATA[Jacob Dunefsky]]></dc:creator><pubDate> Tue, 12 Sep 2023 17:50:12 GMT</pubDate> </item><item><title><![CDATA[Startup Roundup #1: Happy Demo Day]]></title><description><![CDATA[Published on September 12, 2023 1:20 PM GMT<br/><br/><p>最近有很多与 Y-Combinator 相关问题相关的讨论，与往常一样与他们的年度演示日相关。似乎值得将它们分成一个帖子。</p><span id="more-23535"></span><h4>拍卖中的竞标者大多认为价格太高</h4><p>YC 正在开会，所以所有平常的话题又回来了。</p><blockquote><p> Paul Graham：就像每一批 YC 项目一样，投资者抱怨估值太高，但初创公司无论如何都会筹集资金。</p><p>库什：您认为发生这种情况有什么具体原因吗？</p><p>保罗·格雷厄姆：一些投资者无法理解所有回报都集中在重大胜利这一事实的含义。不过，顶级投资者明白这一点；您很少会因为价格而失去其中之一。</p><p> Amal Dorai：YC 估值的动态范围不是比公司本身更窄吗？我们看到他们的融资幅度几乎是 2 倍，但当前牵引力的变化超过 10 倍。那些雄心勃勃的公司很好，但那些风险更大的公司仍然在 8 号球后面站稳脚跟。</p><p> Paul Graham：估值的变化远小于质量的变化。这才是决定风险的因素，而不是他们当前的吸引力。如果当前的牵引力是一个完美甚至良好的预测指标，那么投资将变得非常容易。</p><p> David Tran：“当买家抱怨但仍然付款时，你就找到了市场价格” <img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2azxasXxuhXvGfdW2/yskawtp1xroyjv2jhhtq" alt="😃" style="height:1em;max-height:1em"></p><p>丹·格雷：我看到投资者说的是，他们宁愿等待一年，然后投资下一轮——下一轮的价格相似，但有更多的证据。如果首轮融资未能为风险提供适当的上涨空间，那么投资者为什么要加入呢？</p><p>保罗·格雷厄姆：这是一个有趣的新颖变体。我只看到一位投资者这么说。这是一个愚蠢策略的原因是，选择一年后估值没有增加的公司就等于选择了糟糕的公司。</p></blockquote><p>这个模型告诉我，YC 中估值较低、不太令人兴奋的公司可能被高估，而 YC 中估值较高、更令人兴奋的公司则被高度低估。</p><p>我在这里看到了两种截然不同的动力，格雷厄姆和多莱加注的动力，以及特兰的动力。</p><p> Tran 是投资者抱怨价格过高的核心原因。当然，大多数投资者认为YC的价格太高了。有大量投资者追逐的 YC 公司数量并不多，但他们的融资轮次空间并不大。与非 YC 公司相比，YC 公司具有许多优势，包括所有三个：</p><ol><li>选择效应（我不认为整轮的假AI公司是零，但YC非常善于挑选优秀的创始团队和有前途的公司）。</li><li>代言效应（YC血统是一个强有力的信号和协调点，有了名字一切都会变得更容易）。</li><li>丰富效应（YC 为您提供了一个令人惊叹的网络和工具包，并教会您很多知识，并给您动力和专注力）。</li></ol><p>除此之外，还有估值压缩效应。</p><p>据互联网报道，YC 公司被明智地建议提高各轮的底价，因为这可以在所有权方面节省很多，而且有了 YC 的名字，你无论如何都可以筹集到资金。因此，那些相对不那么令人兴奋的公司收取的费用很高，这是理所应当的。当你可以出售更少的股权以获得更多的钱时，为什么你要以更少的钱出售更多的股权？</p><h4>你会为收取更多费用而付出代价</h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/paulg/status/1694099152404398581">Paul Graham 指出</a>，这整个动态使 YC 变得有价值，而且证人非常可信。</p><blockquote><p>未来的创始人：当后期投资者像往常一样抱怨 YC 公司在演示日的估值过高时，他们的意思是，做 YC 可以让你以更少的稀释来筹集资金。</p><p>对于 YC 来说，这是一个很有价值的主张，但如果是由那些显然无意恭维的人为 YC 提出的，那就更好了。</p></blockquote><p>从初创公司的角度来看，其增加的价值有多少来自认可而不是丰富，这并不重要。对他们来说，选择的程度确实很重要。</p><p>我还要指出的是，YC 的存在降低了每家不在 YC 中的公司的估值。你知道如果他们可以做 YC，他们很可能会做，所以你正在与高度逆向选择作斗争。那么，就更有理由去做 YC 了。</p><h4>最优惠的价格带来最优惠的价格</h4><p>YC 中最令人兴奋的公司收费也很高，但看起来他们的收费并没有高出多少。据我了解，该领域有一个关于“应该是”估值的惯例。你可以在这个范围内进行调整，但一旦创始人一开始就以异常高的估值筹集资金，价格的重要性就会大大降低，因为他们放弃的公司股份要少得多。因此，与其筹集更多资金来换取更少的公司股份，不如将重点转移到赢得盟友、开辟道路和讲述正确的故事上。</p><p>特别是，避免可能的折价融资和选择正确的战略风险投资合作伙伴的考虑似乎主导了高端市场的价格考虑。</p><p>你很少会因为价格而失去顶级风险投资家，因为双方都有强烈的愿望不让这阻止交易。初创公司获得更好的风险投资流来帮助其成功，而顶级风险投资家则获得更好的交易流，从而提供大部分阿尔法。</p><p>从这家初创公司的角度来看，这是一场史诗般的公路抢劫，利用风险投资公司的惯例以远低于其价值的价格购买股权，但考虑到目前的情况，他们最好还是付款。</p><p>如果你是顶级 VC，这真是太棒了。你不断推出优质产品，YC 将为你提供大量交易流量，在未充分利用其定价能力的绝佳机会上闪耀光芒。</p><p>如果你不是顶级的VC，这是一个大问题。现在正在发生逆向选择，不仅仅体现在后期估值的增长上。如果您可以投资 YC 上您认为不错的广泛公司组合，甚至是 YC 整体公司，那就没问题了。问题是你做不到这一点，所以你所关注的公司的前景比其他公司高出 10%（这些公司不会回复你的电子邮件，因为你很糟糕，他们可以做得更好），但估值只有 50%，并且说价格太高。</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/Jeffreyw5000/status/1692996154235949166">Jeff Weinstein</a> ：原本在 2017 年至 2020 年筹集资金上限为 800 万美元的 YC 初创公司如今筹集资金上限为 2000 万美元。</p><p>这在一定程度上是由于 YC 投资规模更大和最惠国待遇所致，但也感觉这些公司得到了不好的建议，并且仍然否认我们已经不再是 2021 年了。</p><p>如果你的执行绝对完美，找到 PMF，并筹集足够的资金来为你提供数年的跑道，那么这很好，但通常情况下，这会让初创公司在 12 个月内陷入困境，因为它们的估值取决于市盈率而不是故事。</p><p>鉴于这些创始人在演示日前后以无法投资的价格筹集资金，我们越来越频繁地因价格而通过并在 12 个月内重新审视！</p><p> Amjad Masad（首席执行官 Replit）：这只是市场动态——创始人没有任何非理性。阿尔法只是在消散（你无权获得阿尔法）。</p><p>那些将继续产生回报的人是那些可以获得巨大所有权%的优秀挑选者以及那些在种子前（和YC前）进行投资的人。</p></blockquote><p>我在这里与马萨德唯一的争吵是，人们必须小心，不要将优秀的挑选者与良好的交易流程混淆。风投绝对没有理由有权获得阿尔法，或者大多数 YC 投资甚至应该是不错的交易。</p><p>对于初创公司来说，这种动态的结果是，大多数初创公司通过提高评价和声誉从 YC 中获得巨大价值，但最顶尖的初创公司却没有。他们已经发出了足够强烈的信号，表明他们将在融资时自己开票，而不是收取市场出清价，因此提高市场出清价起不了多大作用。</p><p>尽管存在股权成本，那些顶级公司是否应该做 YC？它不太明显，而且可能因具体情况而异，特别是因为您永远无法尽早确定自己是否是或将继续成为这些公司之一，而 YC 可以帮助您成为其中一员。如果我的人生定位是我可以做 YC 并且正在创建一家合适的公司，那么无论事情看起来有多好，如果他们答应了，我肯定会申请并打算接受。如果我放弃一点价值，我就做得很好，所以我不在乎。</p><h4>提早加薪、经常加薪、到处加薪</h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/kwharrison13/status/1699457717977391608">凯尔·哈里森提供了看似不错的建议</a>，其中大部分都是标准的。从一年多的跑道开始筹集资金，因为它需要可变的时间，而且可能会很长，现在你比以往任何时候都不能指望风投来实际交付。 Cast a wide net and talk to many VCs, but be straight about who you are and what kind of fit you need so time isn&#39;t wasted on both ends.</p><p>他建议写一份阐明事情的备忘录，而不是纯粹依赖甲板。这看起来确实是一种优越的平衡。</p><h4>优秀的风险投资人经常会出人意料地收回资金</h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/paulg/status/1694401451169308912">保罗·格雷厄姆（Paul Graham）在下一点上看到了与我不同的结论。</a></p><blockquote><p> Paul Graham：VenCap 的 David Clark 分析了 1986 年至 2018 年间由 259 只基金支持的 11,350 家初创公司的回报。这些投资中约有一半亏损，但 121 家 (1.1%) 返还了投资它们的全部基金金额。</p><p>他们的十大投资中有两家是在 2010 年之后成立的。两家都是 YC 公司。这就是 YC 吸引后期投资者的原因。估值可能很高，但这是真正优秀的初创公司所在的地方，这对于回报来说是最重要的。</p><p> David Clark：按成本倍数计算，前 10 名基金回报者如下： 10. Coinbase 9. Slack 8. Portal Software 7. Facebook 6. Avanex 5. Google 4. Ariba 3. Yahoo 2. Brocade 1. DoorDash 倍数范围为 140 倍超过 800 倍</p></blockquote><figure class="wp-block-image"><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a839c18-8b2b-4ef2-95c8-9ead44a54da1_680x413.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/dGvcx3giYngcSEaMZ/pnqljhj791iv3f6ex2l1" alt="图像"></a></figure><p>相反，我看到了尤里的反应。</p><blockquote><p> Yuri Sagalov：实际上，令我惊讶的是，只有约 50% 的投资回报率低于 1 倍。我原以为这个数字会更高。</p><p>保罗·格雷厄姆：我也是。但我们还处于早期阶段。</p></blockquote><p>如果你能同时在 46.8% 的时间内收回你的钱，并且还有这种利润分配，那就是一个了不起的生意。即使您完全放弃基金回报者并将其他所有人标记为其范围的极低端，这也是 36.8% 的回报率。是的，FR 很重要，如果我们有 259 只基金进行约 12,000 笔投资，它们的平均起价约为 50 倍，但如果你只有一半的时间完全错过，你实际上并不需要它们。正如保罗指出的那样，这些将是稍后的投资，但也不会那么晚。</p><h4>如果你想把事情做好</h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/gustaf/status/1692685141221531728">Gusaf Alstomer（YC 的）指出，在融资平台上使用设计师是行不通的</a>。</p><blockquote><p> Gusaf Alstomer：融资方案建议：我认为我从未见过通过使用设计师来设计筹款方案而变得更好。使用 Figma、Keynote 等精美工具也是如此</p><p><a href="http://Pitch.com" rel="nofollow">http://Pitch.com</a>或 Canva。在<a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ycombinator">@ycombinator，</a>我们建议人们使用 Google 幻灯片并保持简单。创始人犯的两个错误是相信工具的创造性能力可以创造出更好的牌组。第二个错误是认为设计很重要。</p><p>最有创造力的人在约束下工作。最强大的工具就是你的言语和讲故事。清晰的沟通和相关的故事讲述可以让听众将自己置于正在解决问题的人的立场上。形象化这一点的最佳方法是使用有这些问题的真人的真实照片。</p><p>最好的筹款平台具有以下结构：</p><p> 1) 标题总结了你要表达的观点</p><p>2) 3-4 个要点，并提供支持你所阐述观点的证据</p><p>3）重复直到你涵盖所有结论</p><p>4) 将其融入讲故事的叙述中——将幻灯片与故事联系在一起</p><p>5) 只要有可能，只使用真实照片，如果使用屏幕截图，请放大讲述故事的内容</p><p>“不雇用设计师规则”的例外情况是创始人本身就是设计师。他们知道这项业务的重要之处——其他人永远不会知道这一点。</p></blockquote><p>这也非常符合我的经历。设计师拥有截然不同的技能，并且瞄准不同的目标。他们不明白什么是重要的，而重要的事情通常会很快发生变化，或者当你改变环境时，你会想要即时编辑。这套牌还需要与您保持一致并与您的声音相匹配。是的，如果你的套牌看起来不错固然很好，但最终这并不重要。</p><p>这里有一个重要的普遍观点。当主要专业知识最重要时，您经常会看到人们在次要领域犯下可怕的错误，因为获胜的策略是专注于重要的事情。我想知道人工智能是否会改变这一点。</p><h4>你需要时间来做这件事</h4><p>一个常见的生产力主题是，默认情况下，人们会做大量繁重的工作，占用他们大量的时间。另一个是，照顾好基本面并让你的房子井井有条会给你带来很大的帮助。</p><p>如果您的时间和精力很有价值，特别是如果您是创始人并且部署了效率递增回报， <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/webdevMason/status/1699172098865057968">也许有人应该提供帮助？</a></p><blockquote><p> Avi：我愿意为一项完全满足我基本需求的服务支付这么多钱，这样我就可以集中精力</p><p>* 洗衣店</p><p>* 每天 3 次膳食准备</p><p>* 私人教练</p><p>* 清洁工</p><p>* 治疗师把我的房子变成了一座修道院。</p><p>这应该是VC的增值。创始人应该把自己当作运动员</p><p>梅森：别说了</p><p>别说出来</p><p>梅森不</p><p>啊啊啊啊啊这是你想要的妻子</p><p>阿维（对他的OP的明确答复，但这个顺序更合乎逻辑，也更有趣）：有趣的是，如果我在推特上说我想要一个妻子为我做这件事，我也会被批评。我觉得如果你筹集资金，其中一部分应该“暂时”用于消除干扰。这包括健康的膳食准备、睡眠跟踪等。我知道这条推文听起来有点无聊，但我是一个 20 岁的单身人士，无意建立恋爱关系。我以工作为生。 Twitter 是我唯一的恶习。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/drethelin/status/1699288880657338382">Misha Gurevich</a> （回应OP）：我认为太多人小时候看过蝙蝠侠，并认为“修道院”是把你变成坏蛋的培训中心，而不是让你在贫困中做体力劳动和祈祷的根本无聊的地方。</p><p>很多人似乎认为，如果他们有一个管家，他就会成为蝙蝠侠的阿尔伯特，但实际上他们想要的是他们的伍斯特的吉夫斯。</p><p> “吉夫斯是一名男仆，不是管家；也就是说，他负责服务个人，而管家则负责一个家庭并管理其他仆人。在极少数情况下，他确实会代替别人的管家。据伯蒂·伍斯特说，他“可以与他们中最优秀的人较量。”</p></blockquote><h4>您需要更多的信用本质上是金钱</h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/yuris/status/1693784255237968307">友情提醒</a>。</p><blockquote><p> Yuri Sagalov：创始人，如果您有幸拥有 AWS 等积分，请不要将它们视为“免费资金”。相反，请将其视为资产负债表上<strong>只能</strong>用于一个目的的额外现金，并将您的 AWS 使用情况计入您的消耗的一部分。不要等到它们用完。</p><p> James Hu：这与信用卡积分和里程的思考方式相同。它是现金，对于任何旅行的人来说都和现金一样好，并且应该被同等对待。</p></blockquote><p>确切地。如果你在某个地方有信用并且不可避免地会花掉它然后继续消费，那么该信用在功能上与现金没有什么不同。花它和花现金没有什么不同。这同样适用于任何其他可以代替现金的资产。如果它会被浪费，那就不同了，否则它的价值就等于机会成本。通常每美元接近 1 美元。</p><h4>快速推出您的应用程序</h4><blockquote><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/theapplehub/status/1699725358017523928">Apple Hub</a> : The App Store and iOS are now officially designated as gatekeepers in the EU and will need to comply with the Digital Markets Act (DMA) This means Apple will be required to allow users to downloads apps from the internet and third-party app stores.</p><p>您同意这个规定吗？</p><p> Emmett Shear：哇，如果它得到执行，这真是一个大新闻。对于科技生态系统来说，这将是很长一段时间内最好的事情……如果美国不效仿，欧洲初创企业实际上将获得显着优势！或者至少是首先在欧盟部署的初创公司。</p></blockquote><p>没有进行民意调查，我猜这是 Apple Hub 的正确选择。</p><p>我不会有监管此类事务的习惯，但如果我有的话，这将是一个很好的监管选择。 It does seem first-level helpful.</p><p>这对初创公司有什么作用？这意味着您无需通过应用程序商店即可将您的应用程序提供给欧洲的 iPhone 用户。如果您可以在没有应用商店的情况下找到它们。如果他们愿意侧载。这将是罕见的。即使在 Android 上，人们也不喜欢侧载，因为 Android 上支持侧载，并且人们选择加入该生态系统。</p><p>我的预测是，这最终不会产生那么大的实际影响。</p><h4>不，比那更快</h4><blockquote><p>Bri Kimmel：这是很长一段时间以来的第一个 YC 演示日，大多数 B2B 公司都有付费客户、经常性收入，并且与规模太大而无法与小型初创公司合作的公司签订了大额合同。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/garrytan/status/1699777074456924662">Garry Tan</a> （YC 总裁）：今天出席的公司中有 75% 在 YC 的第一天就没有收入。 81% 的人从未筹集过一毛钱。在过去的三个月里，我们努力推动初创公司构建有意义的软件并进行销售。这是我真正见过 YC 为创始人所做的加速。</p><p>乔·本杰明：你认为为什么这么多创始人在刚起步时迟迟没有走出去并出售产品？</p><p> Garry Tan：害怕失败。</p></blockquote><p>人们很容易忘记选择效应、网络效应和其他可供性正在发挥作用。</p><p>如果你在 YC，你被 Garry Tan 和其他人选中，很大程度上是因为他们认为你很快就能出去销售，然后他们会教你如何做到这一点、网络连接和其他资源帮助你做到这一点，帮助你塑造你的宣传和目标等等，并让你在进入大公司的大门时“我在 YC”，我认为这对大公司有帮助。你有工具可以做出牺牲来进行销售，反过来也可以更快地进行，获得更好的估值，也可以更快地学习。当然，他们在另一个方向上施加了巨大的社会压力。</p><p>如果你不在 YC，那么你的处境就完全不同了。在你准备好之前，很可能会试图太快地卖出太多东西。</p><p>失败不仅会造成破坏，还会带来连锁反应。过早推出并试图获得收入而未能销售的游戏被标记为失败，我经历过这种情况，并在其他地方看到它发生 - 游戏后来改进，算法和粉丝已经继续前进，为时已晚。在为时过早之前关注收入也会浪费你的时间，讲述错误的故事，破坏你继续或筹集资金的能力，在你准备好之前烧毁你最好的线索和游戏，或者以其他方式毁灭。</p><p>所以不，我认为这个决定并不那么容易，即使最好的初创公司会更好地销售更多和更快的产品。我有过多次犯相反错误的经历。</p><h4>现在所有的初创公司都是人工智能初创公司</h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/paulg/status/1697083056597631271">与此同时，Paul Graham 继续注意到 YC 现在全都与人工智能有关</a>。</p><blockquote><p> Paul Graham: I haven&#39;t been more optimistic about YC since I retired in 2014. Garry has been doing a great job, and the current batch is a particularly good one.</p><p>人工智能的繁荣对 YC 来说将是非常有利的。这将意味着更多的初创公司，而YC 擅长的正是那些能在其中获胜的创始人。</p><p> YC 已经因人工智能热潮而发生了转变。我猜目前这批创始人中有一半以上正在从事人工智能初创公司的工作。这就像一场持续进行的人工智能研讨会，有超过 200 名参与者。</p></blockquote><p>我其实买这个。 YC 风格的团队和方法非常适合此时此刻，YC 的基础设施将提供很大帮助，而且 YC 将在很大程度上选择创始人。成为 YC 真是太棒了。</p><p>然而，我再次强调，毫无疑问，有相当多的虚假人工智能公司参与其中。没有什么能变得如此无处不在、如此令人投入、如此大肆宣传而不自夸。然而，未能发现它们并不意味着<a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=5vEp5Bv-J40&amp;ab_channel=EliteFilmClips">你就是傻瓜</a>。这是一个基于点击的系统，那么如果其中一些不是真实的怎么办？重要的是交易流程可以让您获得最好的东西，而不是避免误报。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/paulg/status/1699815950772519277">那么，这些不造假的公司到底在做什么呢？</a></p><blockquote><p> Aaron Levie：所有追求垂直市场的企业人工智能初创公司都有正确的想法。选择一个市场，深入了解工作流程，构建简单的软件来对工作流程进行建模，并使用人工智能来增强所涉及的人类判断。数千个类别中蕴藏着巨大的机会。</p><p> Paul Graham：这是当前 YC 批次中初创企业的中位数。</p></blockquote><p>我当然见过更糟糕的计划。 Enough to fill out a demo day.我怀疑是否有数千个这样的类别提供了巨​​大的机会。</p><h4>有护城河的人不关心不会飞的生物</h4><p>如果有人抄袭你怎么办？保罗说， <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/paulg/status/1697761812698034630">别担心</a>。</p><blockquote><p>保罗·格雷厄姆：当人们模仿你时，最好的策略通常是忽略他们。模仿你的人是（a）缺乏原创性和（b）机会主义者，而这些都是失败的有力预测因素。如果你等待它们消失，它们最终会消失。</p><p> Joel Fraunsic：“我被模仿得如此之好，我听到人们效仿我的错误。” ——吉米·亨德里克斯</p><p>Paul Graham：Viaweb 和 Y Combinator 都发生过这种情况。</p></blockquote><p>当人们试图在各个层面上进行精确复制时，是的，他们通常会失败，但通常他们也不会，并且如果有很多模仿者，他们中的大多数失败并不意味着你可以安全地忽略这种现象。忽略它们的建议与实际上非常努力地工作密切相关，以确保人们可以安全地忽略它们，通过成为前所未有的最好的人并不断改进并拥有强大的声誉和网络效应。在这种情况下，当然，带上它。</p><p>如果他们没有完全复制你，而是将你作为竞争的理由，那么从某种意义上来说，这对你在没有竞争的情况下的情况来说是个好消息，但它绝对应该让你担心，尤其是在竞争资源充足的情况下。注意到一个例子……</p><blockquote><p> Danny Alberson（首席执行官 Agentive，YC &#39;23）：我最近两次会见了一家风险投资公司，展示了产品演示，并回答了无数有关我们策略的问题。只是从别人那里发现他们已经投资了一个直接竞争对手。</p><p>保罗·格雷厄姆：我刚刚给你发了一封电子邮件。这应该进入投资者数据库。</p><p>丹尼·艾伯森：当然。感谢您的关注。</p><p> Absolutely.感谢您的关注：请考虑开源它！</p><p>李昂：非常需要一个开源数据库。</p><p> Ronak Shah（其他回复）：这也发生在我身上。不仅是电话，他们还不断询问我的财务模型，以便他们可以看到我的定价/我如何赢得大标志。他们隐瞒了投资我的竞争对手的事实。</p></blockquote><p> [其他几个回复指出了类似的行为，尤其是与 Web3/加密相关的行为]</p><p> Garry Tan (QTing Alberson)：警告投资者：这种行为会产生后果。我会亲自确认一下。</p><p> Austen Allred：我爱 YC。</p><p> Ryan Peterson：YC 不断投资于竞争对手。</p><p> Paul Graham：这不是投资竞争对手的案例。这是假装对一家公司感兴趣以获取信息的情况。</p><h4>投资者数据库是一个杀手级应用程序</h4><p>您可以从 YC 获得很多服务。考虑到对于初创企业而言，一切都是乘数性的，因此不需要太多就能获得丰厚的回报。纯粹提高你的野心本身就很棒，许多其他看似简单的原则也很棒。</p><p>最让我印象深刻的是声誉，其次是网络。最被低估的可能是广泛理解的投资者数据库，您可以在其中获得有关所有风险投资家的信息。</p><p>处理那些行为已经并将被记录到中央数据库中的人是非常不同的。 VC 知道你会回来汇报。您可以使用以前的报告来了解哪些风险投资家会善待您，提供哪些资源，使用哪种谈判方式，对各种方法做出良好的反应等等。如果信息准确，那么对从合适的人、在合适的条件下以最优惠的价格筹集资金的能力的最终影响似乎是巨大的。</p><p>虽然我理解为什么人们想要保留这种竞争优势，但如果可以将这些信息传播给每个人，那就太好了。行为会改善，那些善待投资者的人会得到奖励，尤其是局外人将更有机会成为创始人。即使我现在对加速创建人工智能初创公司的能力并不那么兴奋，但这也一定是正确的事情。</p><p> YC 放弃这个会不会很昂贵？我的直觉告诉我不会的。这将是令人惊叹的广告，它将为生态系统提供动力并展示价值。 YC 有足够多的额外优势，我预测大多数创始人不会改变是否参与的决定。 YC 不收取市场出清价格。</p><br/><br/> <a href="https://www.lesswrong.com/posts/dGvcx3giYngcSEaMZ/startup-roundup-1-happy-demo-day#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/dGvcx3giYngcSEaMZ/startup-roundup-1-happy-demo-day<guid ispermalink="false"> dGvcx3giYngcSEaMZ</guid><dc:creator><![CDATA[Zvi]]></dc:creator><pubDate> Tue, 12 Sep 2023 13:20:07 GMT</pubDate> </item><item><title><![CDATA[Is there something fundamentally wrong with the Universe?]]></title><description><![CDATA[Published on September 12, 2023 12:02 PM GMT<br/><br/><p> <i>Edit: added a paragraph nearing the end</i><br><br>通常的问题是：“我们的社会出了什么问题？”，但我想我的抱怨是，如果你用系统的视角看待事物，通常你关注的就是最具影响力的东西。<br><br>换句话说，如果我们的星球偏离了轨道，这并不是蚂蚁的错——即使他们本可以做得更多！原因是引力更大，或者我们的太阳需要更多的空间。<br><br>那么，为什么你会因为一些似乎受法律、力量和权力管辖的事情而责怪人类呢？我们 A) 不能从根本上理解，B) 不能从根本上影响 C) 不能从根本上改变？<br><br>我的意思是，从人类的角度来看，有很多答案——心理学、社会学、人类学、进化学科、宗教——甚至跨学科团体和项目。但同样，你只能从<i>盒子里</i>回答问题。如果盒子给出了一定的输出，并且有特定的约束，为什么要把盒子的工作方式归咎于输出呢？</p><p>对我来说，将错误归咎于问题所在的级别更有意义。如果我们不喜欢或厌恶某件事，它会在哪个层次上出现？<br>我们使用的许多表达方式都充满了针对我们个人行为的假设。以谋杀为例。杀人是不好的，我同意，但是凶手是否有个人选择来进行谋杀，使死亡成为可能？痛苦、痛苦、恐惧等？正是宇宙的法则和原则允许它并积极参与它（这个宇宙可以并且将会以无数种方式杀死我们），不是吗？<br><br>这只是我能想到的众多例子之一，我在质疑是否通过仔细观察一个问题，它似乎是我们对0直接控制的监督原则的直接结果。<br>我的意思是，个人责任听起来不错，但如果你真正审视它——这有什么意义吗？以基因为例。它们基于数百万年的生物进化，甚至文化进化。 That you have the &#39;ability&#39; to see a different way than eating your fellow friend, and can see more gains in keeping them alive - is it really &quot;Your&quot; achievement?有多少选择真正是“你的”，而不是在你有意识地意识到你有一张脸和一个与世界其他地方分开的身体之前数百万年就开始的过程的莫名其妙的结果？<br><br>因为如果问题出在宇宙上，如果你想从根本上改变什么，你是否就必须修正它的基本法则和原则？因为任何其他改变都只是表面的、局部的和暂时的。<br><br> To also add that here, you can of course look at humans as &#39;Part&#39; of the universe, and not separate. Different maybe, but not separate. Which is a relevant vein to delve into, if you have something. As I see it, there doesn&#39;t seem to be a reciprocally positive relationship between the Universe and our individual consciousness - which seems odd. If break-ups have taught me anything, it might seem that the Universe is still bitter we stole that god-damn apple.<br><br>另附注（笑话？）<br>所以我仍在寻找宇宙服务台。如果有人知道电话号码或联系方式，请告诉我。 If I&#39;m a beta-tester, I believe I should let them know that some things really, really, really don&#39;t seem to work that well.<br><br>亲切地，<br>卡鲁利亚-劳伦斯</p><br/><br/><a href="https://www.lesswrong.com/posts/GbQFbsswjDpkuSYEA/is-there-something-fundamentally-wrong-with-the-universe#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/GbQFbsswjDpkuSYEA/is-there-something-fundamentally-wrong-with-the-universe<guid ispermalink="false"> GbQFbsswjDpkuSYEA</guid><dc:creator><![CDATA[Caerulea-Lawrence]]></dc:creator><pubDate> Tue, 12 Sep 2023 12:02:44 GMT</pubDate> </item><item><title><![CDATA[Apple Cider Baklava]]></title><description><![CDATA[Published on September 12, 2023 2:10 AM GMT<br/><br/><p><span>自从去年遇到</span><a href="https://www.jefftk.com/p/apple-cider-syrup">苹果汁糖浆</a>以来，我一直在试图弄清楚用它可以做什么。苹果酒甜甜圈是传统的，但我不太喜欢。将其混合到生奶油中效果非常好，并且可以为烘焙食品提供良好的甜酸馅料或配料。我尝试过松饼，用它来混合液体、糖、调味剂和发酵用的酸，但我还没有得到任何令我满意的东西。但几天前我做了一些苹果果仁蜜饼，这是我最喜欢的！</p><p> <a href="https://www.jefftk.com/baklava-loaf-pan-mostly-gone-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wu3r9AfKMDYzLzPPc/t8bligbnzszddyu1o3gf" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wu3r9AfKMDYzLzPPc/t8bligbnzszddyu1o3gf 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wu3r9AfKMDYzLzPPc/fidrhkddito9amo2czvc 1100w"></a></p><div></div><p></p><p><a href="https://en.wikipedia.org/wiki/Baklava">果仁蜜饼</a>是一层层的<a href="https://en.wikipedia.org/wiki/Filo">酥皮面团</a>（一种非常薄的面团），中间被脂肪隔开，每隔几层就有坚果。烘烤后，将甜糖浆倒在上面。在美国，人们可能最熟悉希腊风格，它使用黄油作为脂肪，核桃作为坚果，蜂蜜作为糖浆，但存在大量的地区差异。</p><p>我做了两个平底锅，一个是纯素的（地球平衡），一个不是（黄油）。黄油的味道好很多；可能有比地球平衡更好的选择吗？我用杏仁作为坚果，因为这就是我所拥有的。对于糖浆，我使用了新英格兰煮沸的苹果酒。对结果非常满意，我计划再做一次！</p><p> (Each loaf pan used ~$1.80 of <a href="https://www.webstaurantstore.com/mountain-cider-company-64-fl-oz-100-natural-spiced-apple-cider-concentrate/110MTCIDER64.html">cider syrup</a> , though if you really like it you could <a href="https://www.webstaurantstore.com/mountain-cider-company-100-natural-spiced-apple-cider-70-brix-concentrate-54-gallon-drum/110MTCIDERLG.html">buy in bulk</a> and get it down to $1.42.)</p><br/><br/><a href="https://www.lesswrong.com/posts/wu3r9AfKMDYzLzPPc/apple-cider-baklava#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/wu3r9AfKMDYzLzPPc/apple-cider-baklava<guid ispermalink="false"> wu3r9AfKMDYzLzPPc</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Tue, 12 Sep 2023 02:10:05 GMT</pubDate> </item><item><title><![CDATA[How useful is Corrigibility?]]></title><description><![CDATA[Published on September 12, 2023 12:05 AM GMT<br/><br/><p><i>认知状态：我的最佳猜测（我是人工智能安全的新手）</i></p><p>我们不知道如何正式定义可修正性，这也是我们迄今为止尚未解决它的部分原因。<a href="https://arbital.com/p/corrigibility/">仲裁</a>中的可纠正性定义为：</p><blockquote><p> [代理]不会干扰我们直观地看到的“纠正”代理的尝试，或“纠正”我们在构建代理时所犯的错误</p></blockquote><p>从这个非正式的定义中，“干扰”、“尝试”或“正确”等词语的确切含义尚不清楚。即使对这些概念有最宽泛的定义，可纠正的代理人仍然可能是危险的。第一直觉是，如果我们有一个可纠正的代理，那么如果出现问题，我们总是可以阻止它。我想这里的大多数人都明白这种推理的缺陷，但我从未见过他们明确地表述过这些缺陷，所以这是我的尝试：</p><ul><li>当我们发现某个特工需要纠正时，它可能已经造成了太大的损害。</li><li>纠正代理可能需要大量的研究。</li><li>如果我们不能协调执行，那么仅仅能够纠正代理是不够的。</li></ul><p>在我看来，解决<strong>硬可修正性问题</strong>是通向解决对齐这一最终目标的道路上更有意义的中间目标。</p><h2>灾难场景</h2><p>下面的场景说明了<strong>可纠正的代理如何可能造成严重伤害</strong>。发挥你的想象力来填补空白并使示例更加真实。</p><p>假设我们开发了一个与我们的价值观不符的可纠正代理。代理的具体设计目的并不重要，但具体而言，您可以想象代理的设计目的是优化资源使用 - 它擅长任务调度、负载平衡、速率限制、规划等。人们可以使用代理在他们的服务器基础设施、物流、工厂生产或许多其他地方。无论其最终目标如何，智能体都可能以工具性的方式重视资源获取——它可能会使用说服或欺骗来获取和控制更多资源。在某些时候，人们会利用它来管理电网或互联网流量等。将代理集成到各种系统中的过程会持续几年，直到某个时候代理开始向回形针工厂付费以增加其产量。</p><p>此时，最好的情况是我们意识到出了问题，并考虑关闭代理。然而，代理控制着能源供应和互联网流量——我们已经变得依赖它，所以关闭它会产生严重的负面影响。在最坏的情况下，智能体不是回形针，而是最大化了一些价值更模糊的东西（例如食品生产），而人们实际上无法就是否必须修改智能体达成一致。</p><p>一个可纠正的代理人如何采取让我们依赖它的行动？可纠正性保证并没有涵盖这种情况。该代理不会干扰我们关闭它的能力。在选择其操作时，它甚至可能不考虑其停止按钮。它不会操纵我们不关闭它，就像一个结盟的代理人通过选择我们碰巧不反对的行动所做的那样。无论哪种情况，从智能体的角度来看，它只是选择可能世界中实用性较高的一个分支。<strong>对齐代理和未对齐代理之间的唯一区别在于，如果代理未对齐，则所选分支可能对应于我们的低效用</strong>。</p><p>为什么代理商要等好几年才给回形针工厂打电话？从长远来看，当追求一个目标时，投资你的钱可能比用它来购买你真正想要的东西更有利。一旦你足够富有，获得更多金钱的边际价值就足够低，因此花一些钱购买你真正想要的东西是有意义的。</p><p>发生的情况是，代理将世界引导到一个效用非常低的子树中，而我们没有做出反应。这可能是因为我们不够聪明，无法预见后果，或者因为代理的行为实际上是我们希望从一致的代理那里得到的。问题不仅仅在于我们有限的智力使我们无法预测特工行为的后果。在某个时间点，未结盟的代理实际上可能会表现出我们希望从结盟的代理那里得到的行为。</p><p>有人可能会说“除非我们确定人工智能是一致的，否则就不要依赖人工智能”。如果人工智能足够智能，这在实践中可能会很困难。无论如何，依赖性并不容易衡量或控制。它与有用性呈正相关，因此防止依赖会降低有用性。依赖性不是工具（例如人工智能代理）的属性，而是工具的使用模式的属性。我们不能强迫国家、组织和个人不以依赖人工智能的方式使用人工智能。有时人们可能没有意识到它们依赖于给定的人工智能，或者可能没有合理的替代方案。另外，我们不要低估人类将工作交给机器的愿望。</p><h2>速度和协调性</h2><p>人类的操作速度比机器慢得多。当客服人员开始做出不良行为时，花费几个小时来做​​出响应可能太过分了。一旦我们意识到需要纠正代理，我们可能需要花费数月或数年的研究才能弄清楚如何修改它。如果我们依赖人工智能，我们可能想让它同时运行，但它会继续造成损害。</p><p>如果我们可以设计一个停止按钮，我们仍然需要回答几个重要的问题：</p><p>谁控制着停止按钮？为什么我们应该信任这个人/组织？<br>我们根据什么规则来确定何时需要纠正代理？<br>我们使用什么标准来决定是否应该保持代理运行直到我们可以生成正确的版本？</p><p>普遍的问题是<strong>人类需要有一个行动计划和协调</strong>。这就涉及到<a href="https://www.lesswrong.com/posts/BEtzRE2M5m9YEAQpX/there-s-no-fire-alarm-for-artificial-general-intelligence">火灾报警问题</a>。</p><h2>可修正性的难题</h2><p>我们可以考虑一种更强的可修正性形式，<a href="https://arbital.com/p/hard_corrigibility/">如下</a>定义：</p><blockquote><p>表现得好像它在想：“我是不完整的，有一个外部力量试图让我完整，我的设计可能包含错误，有一个外部力量想要纠正它们，这是一件好事，我的预期效用计算表明这个动作具有超高效用，可能会犯危险的错误，我应该让它们超越外力；我想我已经完成了这个计算，显示了外力纠正我的预期结果，但也许我错了。”</p></blockquote><p>满足可纠正性仅要求主体不干扰我们纠正它的努力（包括例如通过操纵）。解决可修正性难题意味着，智能体在做出定期决策时还要考虑其缺陷，例如，在有疑问时请求批准或积极与人类合作来识别和修复其缺陷。更关键的是，<strong>它将积极帮助防止因需要修改而造成的灾难</strong>。</p><p>我认为这抓住了一个有用的、可纠正的智能体必须是什么样子的关键。我不清楚解决常规可纠性是否是一个有用的实际里程碑——它实际上可能提供一种错误的安全感。另一方面，解决可修正性这一难题可以带来巨大的好处。对齐最困难的方面之一是我们只有一次机会来解决它。解决可修正性这一难题似乎给我们提供了解决对齐问题的多种机会。一个一致的代理人是一个按照我们的价值观行事的人，这些价值观包括防止违反我们价值观的行为发生等。因此，解决对齐意味着解决硬可校正性。硬可修正性很有趣，因为它比对齐更容易解决。我们实际上并不知道情况是否如此以及程度如何。</p><br/><br/><a href="https://www.lesswrong.com/posts/Py3vqPp9uSqQJHFuy/how-useful-is-corrigibility#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Py3vqPp9uSqQJHFuy/how-useful-is-corrigibility<guid ispermalink="false"> Py3vqPp9uSqQJHFuy</guid><dc:creator><![CDATA[martinkunev]]></dc:creator><pubDate> Tue, 12 Sep 2023 00:05:43 GMT</pubDate> </item><item><title><![CDATA[Machine Evolution]]></title><description><![CDATA[Published on September 11, 2023 7:29 PM GMT<br/><br/><p><i>认知状态：这篇文章探讨了生物进化和我们机器的进化之间的关系。我们研究了塑造有机体和机器的进化压力之间的相似之处。我们仍在探索这个类比，我们的发现是初步的。我们希望在未来的文章中进一步探讨这些关系。非常感谢反馈和批评。</i></p><h1>介绍</h1><blockquote><p><i>毕竟，人的生命与机器的生命之间的区别只是程度上的区别，而不是种类的区别，尽管种类上的区别并不缺乏。动物比机器有更多的应对紧急情况的能力。机器的通用性较差；其作用范围较窄；它的力量和准确性在它自己的领域是超人的，但它在困境中表现得很糟糕；有时，当它的正常动作受到干扰时，它就会失去理智，变得越来越糟，就像暴雨中的疯子一样：但在这里，我们再次遇到了与以前相同的考虑，即机器仍然处于静止状态。在他们的婴儿期；他们只是骷髅，没有肌肉和血肉。</i></p></blockquote><p> ——塞缪尔·巴特勒的《Erewhon》，1872 年</p><p>机器随着时间的推移而变化。他们不断进化。我们今天的机器是昨天机器的进步和改进，每一代新机器都面临着选择性压力。一些变化促进了某些机器相对于其他类型的扩散，并且更有可能持续存在并经历进一步的完善和转变。机器能力的创新开拓了新的利基市场，并在整个生态系统中扩散、多样化并迅速传播。与此同时，就像生物进化一样，前几代机器会灭绝，而其他机器则安逸地坚持在自己的利基市场，仅经历数百年或数千年的微小变化。例如，塞缪尔·巴特勒（Samuel Butler）指出了<a href="https://www.goodreads.com/quotes/556914-i-remember-one-incident-which-bears-upon-this-part-of"><u>烟斗</u></a>，以及其他机械前工具，例如手斧和针，已经存在了数千年。</p><p> <a href="https://commons.wikimedia.org/wiki/File:Paleolithic_hand_axe_(both_sides)_(FindID_102443).jpg"><u><img style="width:40.89%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/n4ukcnrxl7mvja7h4trx"></u></a> <img style="width:53.33%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/f0wpbohxuufovy9fl6pf" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/jzqfktbmwnztl5g6hxq0 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/c6z1oubidqlal6dttetg 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/kpqpplpjy3lzua617idl 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/jlwkmdk6vjotna7h8vcn 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/tmejnx3btoyqhnd9xjtl 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/gtvimkbi6cetifoq1ivh 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/nhuxvgwnsv4rdgdkhfsy 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/yhhgmgh6t2vo2nrmbvmk 1280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/gx9vfwevvvod7ffyt8vw 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/vfgiavjilmcosaiqdt76 1523w"><br>手斧是<a href="https://en.wikipedia.org/wiki/Hand_axe"><u>人类历史上使用时间最长的工具</u></a>，几乎没有经过任何修改，已经使用了超过一百万年，而类似于我们今天使用的骨头制成的缝纫针的历史可以追溯到六万多年前。</p><p> <a href="https://commons.wikimedia.org/wiki/File:Fossil_horseshoe_crab_dead_in_its_tracks.jpg"><img style="width:45.25%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/crkrj0mqhovjpkaxrkrl" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/evh18qd2kkzmybmcwhgl 127w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/ro4mbyoandw6tiussgin 207w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/fq6rvadvvc4ighgsoymd 287w"></a> <a href="https://commons.wikimedia.org/wiki/File:Limulus_polyphemus_(Atlantic_horseshoe_crab)_(Sanibel_Island,_Florida,_USA)_7.jpg"><img style="width:44.83%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/wszloh4bpkvqph6pe7pq" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/ghmlyuye8xhmcj48ni8c 128w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/hzc1gxy4vkfkqelykbwz 208w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/xsd7znuo2kutg647axbp 288w"></a><br>一块 4.5 亿年前的鲎化石，旁边是一个现代标本。这种基本设计已经持续了近 5 亿年。</p><p>随着时间的推移，类似的变化过程也发生在生物进化中，特别是通过有据可查的重组、突变和自然选择等进化过程。机器和有机体都会随着时间而变化。它们都在进化。然而，问题是随着时间的推移推动这些进化变化的基本过程有多相似？</p><p>我们现在将注意力转向这个问题。我们将从个体有机体的角度关注生物进化，这与在更广泛的技术进化范围内作为个体物体的机器类似。我们将工具视为帮助或扩展人类能力的任何物体或模因（例如手斧和针），并将机器视为自供电的工具（例如汽车和计算机）。稍后，我们将讨论人工智能，我们将其视为在某种程度上自我导向的机器（例如 ChatGPT）。与有机体一样，机器也有种群和世代。机器由相互作用的微观部件组成，存在于施加选择压力的宏观结构中。在这篇文章中，我们探讨了应用生物进化的经验教训和见解的实用性，作为帮助我们理解机器进化背后的过程的第一步。</p><p>当我们随意描述机器进化的宏观趋势时，我们通常描述的是“随着时间的推移机器开发和创新的趋势”。</p><p>例如，我们可能会这样说：</p><ul><li> “哇，看来创新的步伐正在加快！”</li><li> “随着时间的推移，我们的机器肯定会变得越来越复杂。”</li><li> “有很多不同类型的新机器！”</li></ul><p>然而，我们似乎对机器进化没有很好的“<a href="https://www.lesswrong.com/tag/gears-level"><u>齿轮水平思维</u></a>”或“<a href="https://en.wikipedia.org/wiki/Intuition_pump"><u>直觉泵</u></a>”，尽管这种现象推动了人类社会和人类状况的巨大变化。</p><p>为了纠正这个问题，我们想要探讨这样一个观点：<i>机器进化</i>是一个值得直接研究的话题——特别是对于那些对人工智能、人工智能安全感兴趣的人，以及那些担心人类已经放弃对机器的控制权的人。</p><p>但是，首先，让我们首先对“机器”和“进化”进行定义，然后将它们放在一起作为“机器进化”的工作定义。</p><h1>扎根直觉</h1><blockquote><p><i>二十世纪初，大卫·希尔伯特试图建立数学的完整性，但却促使人们认识到数学真理的范围永远无法被系统地限制。进化论者似乎已经将思想和智力驱逐了，他们发现进化是一个智能过程，而智能也是一个进化过程，从而使这种分离变得不那么明显。技术被誉为将自然置于我们的智慧控制之下的手段，它使自然能够对我们运用智慧。</i></p></blockquote><p> —《机器中的达尔文：全球智能的演变》，乔治·B·戴森 (George B. Dyson)，1997 年</p><p>对于本练习，让我们从这两个术语最广泛接受的定义开始。为此，让我们转向维基百科。</p><p> <a href="https://en.wikipedia.org/wiki/Machine#:~:text=In%20the%2017th%20century%2C%20the,16th%20and%20early%2017th%20centuries.">维基百科将机器定义为：</a></p><p><i>使用力量施加力并控制运动来执行动作的物理系统。该术语通常适用于人造设备，例如使用发动机或马达的设备，但也适用于天然生物大分子，例如分子机器。机器可以由动物和人驱动，也可以由风和水等自然力驱动，也可以由化学能、热能或电力驱动，并且包括一个机制系统，可塑造执行器输入以实现输出力和运动的特定应用。它们还可以包括监控性能和计划运动的计算机和传感器，通常称为机械系统。</i></p><p>现在，<a href="https://en.wikipedia.org/wiki/Evolution">让我们对进化做同样的事情</a>：</p><p><i>在生物学中，进化是生物种群在连续几代中<strong>遗传</strong>特征的变化。这些特征是基因的表达，在<strong>繁殖过程</strong>中从亲代传递给后代。由于基因<strong>突变</strong>和<strong>重组</strong>，任何特定群体中往往都存在遗传变异。当<strong>自然选择</strong>（包括性选择）和遗传漂变等进化过程时，就会发生进化<strong>&nbsp;</strong>对这种变异采取行动，导致某些特征在连续几代的人口中变得或多或少普遍。正是这种进化过程在生物组织的各个层面上产生了生物多样性。</i></p><p>现在，没有关于机器进化的维基百科页面（也许有一个证据支持它尚未得到充分研究的说法），所以我们必须自己将这些术语放在一起。</p><p>简而言之，对我们来说，<strong>机器进化</strong><i>是机器连续几代发生变化的过程。</i></p><p>有趣的是，对于更广泛的<a href="https://en.wikipedia.org/wiki/Technological_evolution#:~:text=Technological%20evolution%20is%20a%20theory,Future%2C%20Masefield%20Books%2C%201993.">技术进化</a>现象，只有一个非常悲伤的维基百科页面。它确实提供了一个相对简单的“技术进化的三个阶段”，其中包括：（1）工具，然后（2）机器，最后（3）自动化。这表明技术进化的最终目标是自动化。但是，与机器进化一样，关于这个主题的研究严重缺乏。这里值得简单提一下为什么我们特别强调机器进化。</p><p><strong>首先</strong>，机器进化包括对比我们通常预期的工具更复杂的物体的探索（想想锤子或螺丝刀与数字计算机之间的区别）。</p><p><strong>其次</strong>，机器通常“使用动力来施加力并控制运动来执行动作”。这使得它们能够以更类似于代理而不是简单工具的方式与环境互动。</p><p><strong>第三</strong>，在更广泛的技术进化中对机器的关注，以及人类在设计机器中的作用，是简单工具和完全自主之间的关键点，我们最有可能对机器群体的进化产生重大影响。</p><p>那么，对我们来说，理解机器进化的第一个目标将涉及两个简单的步骤：（1）检查机器发展和机器种群的宏观趋势，以及（2）探索生物进化的微观过程如何提供对机器进化过程的见解。机器进化。在这种背景下，我们将探索关键的生物进化过程，例如<strong>遗传性</strong>、<strong>繁殖</strong>和<strong>重组</strong>等，以描述机器如何以及为何随着时间的推移而呈现出不同的形状和类型。此外，我们还将探讨一些关键区别，并强调<strong>人工选择</strong>与<strong>自然选择的作用相比的关键作用。</strong></p><h1>运用直觉</h1><p>机器开发有许多有趣的趋势，但在本文中，我们将重点关注以下 3 个不言而喻的趋势，我们认为它们有助于说明机器进化的基本过程：</p><ol><li><strong>机器能力的改进</strong></li><li><strong>计算机数量的增加</strong></li><li><strong>机器在新机器的设计和制造中的作用日益增强</strong></li></ol><p>为了解释机器本身的这些变化，我们探索了随着时间的推移塑造生物生命的 5 种生物进化机制，我们为每一种机制开发了机器进化的模拟。</p><p>这 5 种生物进化机制是：</p><ol><li><a href="https://en.wikipedia.org/wiki/Heredity">继承：</a><i>将特征从父母传给后代；通过无性繁殖或有性繁殖，后代细胞或生物体获得其父母的遗传信息。</i></li><li><a href="https://en.wikipedia.org/wiki/Reproduction">繁殖</a>：<i>新个体有机体（“后代”）从其“父母”产生的生物过程。</i></li><li><a href="https://en.wikipedia.org/wiki/Mutation">突变</a>：<i>生物体、病毒或染色体外DNA的基因组核酸序列的改变。</i></li><li><a href="https://en.wikipedia.org/wiki/Genetic_recombination">重组</a>：<i>是不同生物体之间遗传物质的交换，导致产生具有与亲本不同的性状组合的后代。</i></li><li><a href="https://en.wikipedia.org/wiki/Natural_selection">自然选择：</a><i>由于表型的差异，个体的生存和繁殖存在差异。查尔斯·达尔文普及了“自然选择”一词，将其与<strong>人工选择</strong>形成对比，人工选择是有意的，而自然选择则不是。</i></li></ol><p>在生物生命中，种群随着时间的推移，通过施加在个体生物体上的进化压力而发生变化。粗略地说，每个新生物体都是通过某种由生物体基因组决定的繁殖方法产生的。在有性生殖中，生物体在基因混合（重组）过程后从其父母那里继承特征（以及一些随机突变）。生物体基因组的变化导致生物体略有不同，产生不同表型的变化，只要环境条件保持足够稳定以支持持续适应性的前景，自然选择就会通过生物体的生存和繁殖率从中挑选出赢家。</p><p>如前所述，正如塞缪尔·巴特勒和乔治·戴森所主张的那样，进化的力量在机器上发挥着作用。生物进化过程也可以稍微扩大，将它们视为指导机器进化的潜在进化过程。这个类比似乎与智能计算机器以及人工智能指导这些机器行为的能力不断增强特别相关。本着类比的精神，让我们从机器开发的角度简要地重新审视这些机制。我们应该注意到，这些是暂时的、不完美的类比，我们希望随着时间的推移，通过进一步的工作和反馈来完善它们。</p><p> <strong>1. 机器继承：</strong><strong>设计特征、特性或编程从一代机器转移到下一代机器</strong><i><strong>。</strong></i></p><p>例如，新一代台式机、笔记本电脑和智能手机通常保留前几代的关键设计功能（屏幕、扬声器、微芯片）。他们继承了这些特征。同样，现代飞机的结构设计继承了前几代的结构设计，最终继承了早期飞机的空气动力学基本原理。</p><p> <strong>2. 机器复制：</strong><strong>创造和复制新一代机器的过程。</strong></p><p>例如，世界各地的工厂都使用相同的模板大规模生产最新的智能手机型号，或者其他机器和机械设计在飞机、汽车和平板电脑的复制中发挥着越来越大的作用。</p><p> <strong>3. 机器突变：</strong><strong>为特定机器引入新特性或功能的设计变更或创新。</strong></p><p>例如，耳机和电脑鼠标从有线技术向无线技术的转变，或者引入<a href="https://en.wikipedia.org/wiki/Office_Assistant#Criticism"><u>Clippy</u></a>的有害突变，Clippy 是微软程序中备受诟病的“办公助手”，但在后续几代中被删除，导致 Clippy 几乎灭绝。对于计算机器来说，这通常是软件的变化。另一个例子是为智能手机添加多个相机镜头。</p><p> <strong>4. 机器重组：</strong><strong>引入和综合现有机器的特定功能、设计或技术来创建新机器。</strong></p><p>例如，从计算机到电视的互联网连接的集成，向我们介绍了智能电视，或者无人机的开发，它结合了航空、机器人和远程控制系统的技术。还有<a href="https://en.wikipedia.org/wiki/Keytar"><u>keytar</u></a> ，著名的键盘和吉他的组合。</p><p> <strong>5. 人工选择：以个体机器的形式表达的成功技术特征（由于效率、有效性、受欢迎程度等）的差异化生存和复制。还应该指出的是，与更通常被认为是“瞎的”。</strong></p><p>智能手机的发展在这里也具有启发意义。在过去的几十年里，用户认为智能手机中最有用、最高效或最流行的功能在后续几代中得到了保留和改进，而不太受欢迎的功能则被逐步淘汰。例如，与物理键盘相比，消费者对触摸屏表现出强烈的偏好，导致触摸屏智能手机在当今占据主导地位。此外，面部识别、更大的电池容量和改进的相机技术等功能因其受欢迎程度和有效性而得到推广，塑造了当前一代的智能手机。</p><p>智能手机的进化还指出了另一种对智能计算机很重要的进化形式，那就是软件在机器进化中的作用。例如，人们可能认为人工智能的进化与任何特定机器的进化一样都是软件的进化，事实上，认为人工智能的进化主要是由进化驱动的可能更有意义。软件的。这是我们希望在以后的帖子中探讨的一点。</p><p>现在我们已经有了观察到的趋势，并且我们已经根据机器进化过程重塑了生物进化过程，让我们简要演示如何使用这些进化过程来帮助解释观察到的趋势。</p><ol><li><strong>机器能力的提高</strong>：这可以看作是“人工选择”的结果，其中机器经历了各种形式的“重组”和一些“突变”，从而导致了生存率和“繁殖”率的差异。</li><li><strong>计算机数量的增加</strong>：这可以被认为是整个“人工选择”机器生态系统中“计算”设计特征的一次特别成功的“重组”。</li><li><strong>机器在新机器的设计和创造中的作用日益增强</strong>：在某种程度上，“机器突变”导致机器参与其他机器的设计和创造。这是一次非常成功的突变，并因此被“遗传”和“重组”，并通过“人工选择”而广泛传播。</li></ol><h1>寻找偏差</h1><p>为了使机器和生物进化之间的比较有用，我们需要了解其局限性。这些理论在哪里一致，在哪里分歧？以下是它们之间的三个重要区别：</p><h2><strong>技术进化是外部导向的</strong></h2><p>在生物进化中，自然选择是一种<i>新兴</i>现象。个体将不完美的 DNA 副本传给后代，并受到复制错误和粗劣修复损伤的影响（就性别而言，是部分副本）。使基因更有可能传递的罕见突变将以中性和有害突变为代价而传播。</p><p>相比之下，技术变革是由设计引导的。新形式经历了类似于生物进化的选择压力，但技术的繁殖方式并不完全类似于无性繁殖或有性繁殖。我们看到的不是<a href="https://en.wikipedia.org/wiki/History_of_evolutionary_thought#:~:text=Darwin's%20theory%2C%20originally%20called%20descent,could%20share%20a%20common%20ancestor."><u>带有修改的达尔文血统</u></a>，而是带有修改的<i>复制</i>。变化是故意引入和消除的，这些变化背后的人们被激励尽快取得尽可能多的进步，而大多数物种<a href="https://en.wikipedia.org/wiki/Mutation_rate#Evolution"><u>保持适度突变率的权衡</u></a>，以平衡高突变率提供的代际适应性（以及<a href="https://en.wikipedia.org/wiki/DNA_polymerase_epsilon"><u>修复 DNA 复制错误</u></a>的代谢成本）与每一代中有害突变较少的优势（以及其他因素）相比。</p><h2><strong>基因必须做一切</strong></h2><p>在生物学中，基因必须履行许多功能，而无需任何长期计划。基因本身编码蛋白质，但也是系统的“记忆”——如果一个基因离开基因库，它就会消失，除非再次通过突变重新创建。每个基因必须确保其自身的复制。</p><p>相比之下，机器进化中存在权力分离。许多人可以解决同一问题，可以并行和提前比较许多解决方案，所有这些都必须在野外产生和测试任何物理表现之前进行。数据可以远程存储，而不是机器“基因组”的唯一副本存储在该机器内。这里有创造力和记忆：被遗忘的旧想法和全新的想法都可以在上一代没有任何前辈的情况下引入。</p><p>这一点，与第一点相结合，意味着机器进化可以比生物进化快得多，而且“浪费”更少。我们不需要尝试随机变化，其中大多数都会毁掉技术。与自然选择不同的是，我们可以故意干扰技术进化的<i>机制</i>，例如使用机器本身来帮助我们进行设计。这甚至可以被认为有点<a href="https://en.wikipedia.org/wiki/Lamarckism"><u>拉马克式的</u></a>。</p><h2><strong>机器没有性行为</strong></h2><p>许多物种都是无性繁殖，但在讨论进化时，我们倾向于关注有性繁殖，因为这是动物和植物最常见的形式。然而，有性生殖在机器进化中并没有明确的类似物。性涉及两个个体的基因混合以产生后代。</p><p>性很奇怪，因为它的进化尽管付出了<a href="https://en.wikipedia.org/wiki/Evolution_of_sexual_reproduction#Disadvantages_of_sex_and_sexual_reproduction"><u>巨大的代价</u></a>（例如，一半的人类无法繁殖，另一半则需要前半部分的输入才能繁殖）。性的优点很复杂，包括物种内部的变异等因素，这些因素不适用于机器，而机器往往以更类似于克隆而不是性的方式大规模生产。</p><p>性别也会导致性选择，当生物体提高吸引配偶的能力时，特征就会激增，通常是通过与同性的竞争。这有时会导致奇怪的适应，例如<a href="https://en.wikipedia.org/wiki/Peafowl#Sexual_selection"><u>孔雀的展示</u></a>、 <a href="https://www.google.com/search?q=pufferfish+courtship+ritual&amp;tbm=isch&amp;ved=2ahUKEwjx28fN3d6AAxVAmScCHTXIBxUQ2-cCegQIABAA&amp;oq=pufferfish+courtship+ritual&amp;gs_lcp=CgNpbWcQDDIECCMQJ1AAWABgswZoAHAAeACAATmIATmSAQExmAEAqgELZ3dzLXdpei1pbWfAAQE&amp;sclient=img&amp;ei=YnjbZPGiMsCynsEPtZCfqAE&amp;bih=923&amp;biw=1920&amp;rlz=1C1GCEA_enGB1047GB1047"><u>河豚的沙画</u></a>，以及一些人认为的<a href="https://en.wikipedia.org/wiki/Evolution_of_human_intelligence#Sexual_selection"><u>人类智慧</u></a>。在某些情况下，这些特征甚至最终会降低整个物种的适应性，例如雄性爱尔兰麋鹿的疯狂鹿角，其重量为 40 公斤，从尖端到尖端的长度为 3.65m。这些很可能是作为性展示而进化的，它们的负担可能导致了该<a href="https://en.wikipedia.org/wiki/Irish_elk#Extinction"><u>物种的灭绝</u></a>。</p><p> <a href="https://commons.wikimedia.org/wiki/File:Paonroue.JPG"><img style="width:45.6%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/ndo1isewwgb4vevatnwd" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/k740gwy4ytakhwadvzyk 155w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/pixm0h4nkhaeoudjpu96 235w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/md5fjgquhcixr2r74fji 315w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/ntgnrzdsvmtg3bujlpru 395w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/s3cbme2iyxh2co202al2 475w"></a> <a href="https://commons.wikimedia.org/wiki/File:Jele%C5%84_olbrzymi_Megaloceros_giganteus.jpg"><img style="width:41.65%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/kcsg7kz8po2xtef9okhh" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/dapmm9gogsmpe8btedkl 132w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/xekodopw8mjacze45ivb 212w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/oyajdbvwixfoobfidtel 292w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/w0omjau4sazjth9mdwfj 372w"></a></p><p>对于机器来说，这种选择压力及其后果没有确切的类似物。</p><h1>选择压力的演变</h1><p>在本节中，我们将探讨选择过程的演变，以及从 (1) 自然选择到 (2) 人工选择到 (3) 技术选择（或技术选择）的转变。我们认为，虽然自然选择继续在生物有机体的进化中发挥主导作用，但就人类而言，<i>人工选择</i>已被添加为一种新形式的进化压力。人工选择是我们从查尔斯·达尔文那里借来的一个术语，它强调了人类和人类社会在塑造人类、我们的机器以及其他人类制品（例如市场和组织）的进化中已经发挥的作用。进化选择压力的演变以及机器进化中发现的趋势表明，一种看似合理的新形式的选择压力即将出现，我们称之为技术选择。随着人类开始在塑造自己的进化压力方面发挥更大的作用，越来越智能的计算机也将开始在塑造自己的进化压力方面发挥更大的作用。我们已经看到，人类智力是一个比自然选择更强的选择过程。先进计算机器中的人工智能如果大大超越人类智能，将成为比人类智能更强大的选择过程。</p><h2><strong>自然选择</strong></h2><p>在生物进化中，对于所有动植物物种来说，<i>总是</i>有两个主要的宏观激励在起作用：生存和繁殖。生存和繁殖成功或失败的自然过程——<i>自然选择和性选择</i>——既盲目又缓慢。换句话说，如果自然环境条件发生变化，有时甚至是剧烈变化，那么无法相应适应的物种将面临<i>自然选择</i>的灭绝。</p><p>值得注意的是，在整个物种种群中，总会出现新出现的基因突变。突变更有可能对生物体有害，即失调。然而，有时，突变可能被证明是有益的，并且可以在环境利基中实现更大的适应性。例如，长颈鹿不仅仅是想吃树上更高的叶子，因此它们的脖子越来越长，并将这种渴望传递给后代的基因型。 （尽管表观遗传学可能对基因的乙酰化和甲基化有一些因果影响，但这并不是本例中的驱动因素。）</p><p>这是让-巴蒂斯特·拉马克（Jean-Baptiste Lamarck）的前达尔文信仰。但查尔斯·达尔文和《进化论新综合》的后来贡献者对自然行为提出了一种更加优雅和令人信服的解释。他们提出的不是拉马克式的解释，而是那些基因突变的长颈鹿赋予了它们脖子稍长的表型特征，它们往往能够更好地到达更高的叶子，因此生存得更健康、寿命更长，从而给它们更多的交配机会，反过来，这些长颈突变会在整个群体中传播。如果随着时间的推移，环境再次发生变化——例如，只有最低树枝上的叶子得以幸存——那么我们可能会看到随着时间的推移，种群表型特征发生基因变化，从而产生短脖子的长颈鹿。但这需要好几代人才能达到新的平衡选择。这样，通过自然选择和性选择的进化既是盲目的又是缓慢的。也就是说，如果环境条件发生巨大变化，那些具有稍微更合适的表型特征的幸运的少数突变体将比其他种群更有机会被选择生存。</p><p>从历史上看，查尔斯·达尔文和让·巴蒂斯特·拉马克之间正在进行着一种不同形式的进化论之战。这场战斗是进化认识论的一场战斗，也就是说，科学界将根据其说服力和健全性来选择竞争性思想或知识，以求生存。拉马克的“后天性状遗传”理论提出，父母在生存过程中学到的性状会在繁殖后以某种方式转移到他们的后代身上（参见上面的长颈鹿例子）。换句话说，拉马克错误地认为，父母习得的一系列自我改进可以以某种方式遗传给他们的后代。尽管这一理论错误地描述了人类进化的特征，并且没有被科学界选择继续存在/接受，但它可能会成为机器进化的基本模型。因为信息和行为的传输将非常系统地通过机器进行。换句话说，制造商使用的模型涉及拉马克模型，提出“获得的字符的继承”。</p><blockquote><p> <a href="https://necsi.edu/what-lamarck-believed#:~:text=Lamarck%20is%20best%20known%20for,passed%20on%20to%20its%20offspring"><u>如果一个有机体在生命过程中为了适应环境而发生变化，这些变化就会遗传给它的后代</u></a>。</p></blockquote><p>机器制造商以他们已有的基础为基础进行制​​造。他们不会重新发明轮子，而是根据消费者和财务压力进行改进。因此，机器进化遵循拉马克原理，但不适用于人类进化。但正如托勒密的地心天文系统被哥白尼、伽利略、布拉赫和牛顿的日心说版本所取代一样，海员仍然可以在海上使用它来正确引导他们。或许拉马克终将在人造生命中度过他的一天。</p><h2><strong>人工选择</strong></h2><p>大约600万年前，人类经过改良从与黑猩猩的共同祖先中分离出来，然后分化为南方古猿，然后分化为各种智人物种，最后分化为智人。现在，尽管人类像地球上所有其他形式的动植物一样，必须为性和生存而竞争，但我们的进化史是相当独特的，因为在整个 600 万年的进化过程中，我们进化出了意识和复杂的语言使我们能够积极指导我们的<a href="https://jcer.com/index.php/jcj/article/view/51"><u>行为并更好地控制我们的环境</u></a>。意识让我们的物种有能力反思性地设计针对不同环境压力的选择和替代方案，而不是纯粹根据本能盲目地应对环境压力。结果，我们的物种发展了丰富多样的文化，利用新颖的想法和材料操作来努力改善我们的生活并增加生存和繁殖的可能性。通过这种方式，我们在认识上从对环境压力的盲目反应转变为反思性行动。在我们的进化史中，我们第一次发展出了理解解释模式中差距的能力。然后我们可以采取行动，用有针对性的新颖想法来填补这些空白。</p><p>因此，在每种文化中，都发明、开发和改进了许多文物。从手斧，到火的控制使用，到轮子的发展，到细菌理论和核聚变。大约三万年前，所谓的上更新世或晚更新世的“文化爆炸”带来了工具、烹饪方法、武器、住房、服装以及几乎所有其他自我完善方式的巨大发展。这些文物——<a href="https://en.wikipedia.org/wiki/The_Selfish_Gene"><u>道金斯称之为模因</u></a>——随着人类文化的不断发展而不断发展。</p><p>大约一万年前农业出现后，世界就不再一样了。知道下一顿饭从哪里来，为我们的祖先腾出了大量时间，让他们能够熟练地完成各种任务，这些任务后来成为了职业。从那时起，人类在任务上变得越来越专业化。一旦特定的动植物群被驯化，没过多久就开始使用<i>人工选择的</i>育种技术来获得植物和动物所需要的特定品质。只要看看香蕉或玉米的小得多的祖先现在的大小就知道了。</p><p>或者想想我们的宠物狗；无论有多大、有多小、有多可爱、有多友好，它们的祖先都来自于普通的灰狼。如果你想知道为什么柯基犬看起来像它，或者松狮犬，大丹犬，吉娃娃犬，或者你的基本杂种狗，这是因为一些祖先认为将具有某些理想品质的狗与其他狗交配是个好主意拥有其他理想的品质。 </p><figure class="image image_resized" style="width:61.44%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/yg61jfi9jxrnbjjhetzv"></figure><p>非驯化类蜀黍的穗（上图）及其驯化变种玉米（下图），经过约 10,000 年的选择性培育供人类种植。</p><p>因此，现在，我们有史以来第一次能够控制出于某种特定原因或其他原因所需的表型特征。为了驯化和饲养动物，饲养狗是为了使其表型特征有助于狩猎（腊肠犬）或运输（哈士奇）或纯粹的美学（哈士奇）。</p><p>人类主导的人工选择也已扩展到机器进化领域。几千年来，人类一直在修补、调整和改造机器，以使机器变得对人类越来越有用和有益。例如，如果我们只看电视的发展，我们会看到这种设备的效率得到了许多不同的改进，从模拟到数字，从模糊屏幕到高清，从笨重和小到平面屏幕此类设备的配送服务也得到了极大改善；从50年代、60年代的兔耳，到天线，到有线，再到卫星，电视自诞生以来，一直在相对稳定的发展和完善中增长。同样的道理也适用于其他类型的机器——汽车、飞机、火车、电器等。当然，在谈论计算机和机器人等机器的进化时，也可以得出完全相同的相似之处。</p><p>从<a href="https://www.computerhistory.org/timeline/computers/"><u>最早</u></a>到<a href="https://www.youtube.com/watch?v=D_Vc_yDvU24"><u>现在</u></a>，我们已经看到这两个领域都取得了显着的进步。这种轨迹将持续下去，直到我们达到一个临界点，机器将能够为后代进行自己的修改。</p><h2><strong>技术选型</strong></h2><p>人工选择（据我们所知）是人类独有的。我们是第一个认识并使用我们自己的人工制品来对我们物种面临的选择压力进行某种程度控制的物种。机器在进化压力下会经历同样的相变吗？他们会像我们一样夺取对自身进化的控制权吗？目前，狭义人工智能（ANI）的行为很像我们的南方古猿祖先——盲目地并根据特定的限制。但正如我们创造了人工制品来改变我们自身进化的方向一样，当我们接近通用人工智能（AGI）时，机器进化可能也会发生类似的转变。</p><p>技术选择是我们为进化压力的下一次演变所使用的术语。粗略地说，自然选择依赖于缓慢、盲目的自然过程。人工选择还依赖于人类创造的人工制品，这些人工制品塑造了我们的进化过程以及经过有意设计的机器的进化过程；随着我们的技术在塑造其进化压力方面发挥着越来越大的作用，技术选择压力也随之出现。通过技术选择，机器本身在自身设计和开发中发挥着越来越重要的作用。在我们看来，这种进化过程可能源于 AGI 的发展（1）通过增强自主创造新的和有用的技术对象的能力和/或（2）通过机器发展出某种形式的机器感知、意识或一般自我意识。</p><p>关于机器是否能够理解自己的存在，并因此根据其新兴的价值体系反思性地修改自己或其他机器，存在不同的阵营。此时，此类机器的进化<a href="https://arxiv.org/abs/2303.07103"><u>表明了一条通往自我意识或统觉的潜在途径</u></a>。如果这种情况发生，将会引发一系列紧迫的问题，其中最重要的是：我们如何知道？什么样的图灵测试可以做出这样的决定？什么样的心智理论能让我们洞察技术大脑的黑匣子，从而知道（即使只是类似）他们正变得越来越像我们？但此时我们需要问另一个非常重要的问题：</p><p>为什么机器的涌现意识应该与我们相似？</p><p>我们以碳为基础；它们是硅基的。飞机不会像鸟一样拍打翅膀飞行；这将是极其低效的。然而它们却飞翔了。它们比任何鸟类能够或愿意飞得更快、更高、更好。对于那些回避机器发展类似人类品质（例如意识或知觉）的人来说，这难道不只是一种以人类为中心的新形式的逻辑偏见和歧视的出现——一种<i>广告机器</i>攻击？目前，我们还不知道人工智能机器具有意识或感知力会是什么样子。</p><p>此外，还需要回答更深刻、紧迫的问题；也许，迟早会发生。例如，<i>技术选择</i>的这种本体论转变是否意味着此类机器已经获得了人格地位？因此，他们应该被赋予权利吗？尽管有性繁殖不会成为此类机器的驱动因素，但复制和修改也许会是。无论这些机器是否达到了一定的意识水平，在未来对其系统进行修改时，应该给予这些机器多少自主权？我们在多大程度上愿意并且应该能够控制或遏制这种修改和自我完善的特征？如果机器学习的宏观程序是生存和最佳功能，那么在涉及越来越大的自我完善能力的预测场景中，这会如何发挥作用——无论是否有意识地获得？因为无论机器是否有意识地意识到其环境，<i>技术选择</i>仍然可能发生。盲目的技术选择也可以像反思性技术选择一样具有生产力或破坏性、受控或不受控制。如果技术选择出现，我们准备好了吗？我们是否充分预见并回答了上述问题？考虑到人工智能技术安全和人工智能治理的现状，答案显然是否定的。</p><h1>结论：机器进化与人类控制</h1><blockquote><p><i>塞缪尔·巴特勒 (Samuel Butler) 于 1902 年去世。机械王国继续蓬勃发展，催生了一系列新物种，而蒸汽机等其他物种却灭绝了。随着电子数字计算机的出现，人们对巴特勒预言的期待感和兴趣重新燃起。这些机器显示出了智能的迹象，而智能是生命的标志，甚至怀疑论者也同意这一点。但将活生生的智能归因于计算机混淆了原因和症状，很快就被证明为时过早。</i></p><p><i>作为技术进化的最终产品，计算机可能不再那么重要，而作为通过自我复制代码丝的孵化和传播促进进化过程的催化剂更重要……</i></p><p><i>我们所知道的生命的起源——以及我们正在创造的生命——可以在自我维持的新陈代谢和自我复制代码之间的交叉授精中找到。数字王国与机器王国的合并已经酝酿了三百多年。</i></p></blockquote><p> —《机器中的达尔文：全球智能的演变》，乔治·B·戴森 (George B. Dyson)，1997 年</p><p>这篇文章是探索<a href="https://www.lesswrong.com/posts/CFuqKkgEwQWCpdaZG/how-humanity-lost-control-and-humans-lost-liberty-from-our"><u>人类如何失去控制和人类如何失去自由</u></a>的连续序列第三部分的开始。在第三部分中，我们将探索一些最重要的物体和结构，这些物体和结构塑造了我们在人工智能黑暗新时代的当前时刻。本章对机器如何演变以及驱动这些过程的底层过程进行了初步探索。</p><p>我们注意到机器进化中容易观察到的总体趋势，包括（1）机器能力的增加，（2）计算机器的增加，以及（3）机器在创造新机器中的作用的增加。然后，我们简要描述了生物进化的 5 个核心工具（并非详尽无遗，只是探索性），包括：（1）遗传性，（2）繁殖，（3）突变，（4）重组，以及（5）自然选择。从这里开始，这些生物进化过程被赋予了机器进化的机器类似物。我们描述了机器继承、机器复制、机器突变和机器重组的概念。虽然我们发现这种简单的重命名对这些过程很有吸引力，但我们认为自然选择需要不同的处理方法。为了与自然选择进行类比，我们选择了<i>“人工选择”</i>这个术语，它在很大程度上是由人类文化、人类人工制品和人类个体驱动的。与“机器选择”或类似的东西相比，我们更喜欢人工选择，因为它与查尔斯·达尔文所做的区分密切相关，并明确了人类（以及我们的人工制品）在此过程中的持续作用。人工选择还强调了这种选择压力更普遍地应用于人类制品的方式。与生物进化相比，人类意图和人类设计改变了包括机器在内的人工制品的进化速度。然而，进化选择过程的演变并没有以人工选择结束。我们看到机器在机器设计、机器复制、机器重组和人工选择等过程中发挥着越来越大的作用。总的来说，这些趋势表明最终会出现一种新形式的进化压力，我们称之为<i>技术选择。</i>在技​​术选择的世界中，机器本身将在塑造自身进化方面发挥更直接的作用，类似于人类利用人工选择来塑造自身进化的方式。</p><p>例如，新一代数字计算机继承了前几代硬件和软件的变异和重组形式。然后，通过人工选择，通过人为辅助的不同繁殖率和生存率，获胜的机器蓬勃发展，失败的机器灭绝。特定的生物体和特定的机器通常通过竞争与合作来生存、繁殖和进化，以适应其环境，以免选择将它们抛在后面。</p><p>然而，这个类比是一项正在进行的工作。在这篇文章中，我们确定了我们的类比局限性的三个初步示例。当然还有其他例子，但我们相信这三个例子引起了人们对我们希望进一步探讨的重要区别的关注。第一个确定的限制是机器进化力量中缺乏明显的性选择类似物。此外，随机性或至少是准随机性在塑造进化方面发挥着重要作用。对于机器进化来说，情况并非如此，机器进化更多地是人类定向的产物，以及最近的机器辅助人类设计的产物。也就是说，虽然生物有机体缓慢地进化，随着时间的推移，自然选择有利于小的基因突变和重组，但由于多种因素的影响，人类故意设计、建造和部署了全新的和完全改造的机器。他们自己的性质和环境。</p><p>我们想在最后讨论的正是从生物进化的随机性到机器进化的刻意修改的这一点。从广义上讲，人类技术的全部努力就是帮助人类从自然中夺取一些控制权，并将其据为己有。这一过程已经开始将进化过程从自然选择转向人工选择。</p><p>机器进化已经是一种不是随机的现象，而是由人类有意和指导的现象。而且，正如我们之前讨论的那样，机器本身开始在其他机器的复制以及设计和创造新机器方面发挥更大的作用。这一趋势向我们表明，技术选择（机器至少部分指导自身进化的时刻）可能即将到来。随着选择压力朝这个方向发展，这种趋势清楚地表明了<a href="https://www.lesswrong.com/posts/J8WHyePqhTwPzXEPw/keep-humans-in-the-loop#Using_AI_to_develop_AI"><u>让人类参与其中</u></a>的重要性。</p><p>人们可以看到人类对其机器的控制逐渐消失，一次一代智能计算机。</p><h1>补充阅读和后续步骤</h1><p>虽然这个方向上的工作并不多，但您可能会觉得这个方向上的一些具体工作很有趣，并且我们在研究和开发这篇文章时借鉴了这些工作。这些包括</p><ul><li>塞缪尔·巴特勒 (1872) <a href="https://www.lesswrong.com/posts/jMZ8wcHNj8YgdGtKf/the-book-of-the-machines-chapter-8">《机器之书》</a> ；</li><li><a href="https://kk.org/outofcontrol/"><u>凯文·凯利 (1995) 《失控》</u></a> ；</li><li> <a href="https://en.wikipedia.org/wiki/Darwin_among_the_Machines#Evolution_of_Global_Intelligence"><u>乔治·戴森 (1997)“机器中的达尔文”</u></a> ；</li><li> <a href="https://arxiv.org/abs/2303.16200"><u>Dan Hendrycks (2023)“自然选择有利于人工智能而不是人类”</u></a> ；</li><li><a href="https://www.lesswrong.com/posts/PKeAzkKnbuwQeuGtJ/welcome-to-analogia-chapter-7"><u>贾斯汀·布洛克在此序列中的早期帖子“欢迎来到 Analogia！”</u></a></li><li> <a href="https://drive.google.com/file/d/1kXx-J68scFPHy-WZvbolGMMx4HdVzLxC/view?usp=share_link"><u>Justin Bullock 及其同事（2023）“牛津人工智能治理手册简介”。</u></a></li></ul><p>正如全文所述，我们希望探索将生物进化的一般逻辑也应用于其他现象和物体的想法。组织的进化是这个序列中的下一个主题，我们也希望进一步探讨技术进化、软件进化和人工智能进化等其他主题，以更好地理解如何用这些镜头来审视人工智能和技术发展的风险。</p><p> <i>**这篇文章由收敛分析团队开发，作者 Justin Bullock、Christopher DiCarlo 和 Elliot Mcckernon 均对该论点做出了实质性贡献。我们收到了 David Kristofferson 的多轮详细反馈，我们对此表示感谢。当我们寻求更好地了解人工智能和智能计算机器的演变时，我们很高兴有机会探索这些概念。我们相信，对这些主题的更深入了解将帮助我们更好地了解减轻人工智能风险的途径。**</i></p><br/><br/><a href="https://www.lesswrong.com/posts/e6gg8S8AfJmwE8HLh/machine-evolution#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/e6gg8S8AfJmwE8HLh/machine-evolution<guid ispermalink="false"> e6gg8S8AfJmwE8HLh</guid><dc:creator><![CDATA[Justin Bullock]]></dc:creator><pubDate> Mon, 11 Sep 2023 19:29:53 GMT</pubDate></item></channel></rss>