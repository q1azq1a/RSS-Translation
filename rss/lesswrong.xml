<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 10 月 29 日，星期日 08:13:29 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[What's up with "Responsible Scaling Policies"?]]></title><description><![CDATA[Published on October 29, 2023 4:17 AM GMT<br/><br/><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 17:36:08 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 17:36:08 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>我有兴趣谈论 RSP 是好是坏。我对此感到非常困惑，并且很乐意与某人深入探讨这一问题。</p><p>我目前对RSP的感受大致如下：</p><p>我对人工智能 X 风险的术语被重新定义感到有点高度警惕和有点偏执，因为这感觉就像是“人工智能对齐”中发生过很多次的事情，而且当你试图影响大型官僚机构（另见奥威尔关于政府行为的所有常见内容）。我对 RSP 的担忧很大一部分是对“负责任的扩展政策”一词的具体担忧。</p><p>我还觉得存在一种脱节，有点莫特和贝利的感觉，我们有一个 RSP 的真实实例，以 Anthropic RSP 的形式，然后来自 ARC Evals 的一些人我觉得更像是 RSP 的某种柏拉图式理想的模型，我觉得它们被混为一谈了。就像，我同意有些类似于 RSP 的东西可能会很棒，但我觉得特别是 Anthropic RSP 并没有真正的牙齿，所以有点扁平，就像人们想象的那样帮助应对风险。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 17:41:38 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 17:41:38 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p><strong>免责声明</strong>：我主要不从事宣传或政策工作，如果我在这些领域工作更多，我对这些主题的看法可能会大幅更新。也就是说，我工作的很大一部分<i>确实</i>涉及思考诸如“好的安全论点是什么样的？”之类的问题。以及“根据当前的安全技术状况，我们可以采取哪些措施来评估和减轻人工智能风险？”。 <i>（这是在编辑时添加的。）</i></p><hr><p>谈论可能有趣的事情：</p><ul><li>反收购/安全倡导应该做什么？</li><li>当前的技术实际上可以在多大程度上降低风险？这是症结所在吗？</li><li>目前避免收购的干预措施是什么样的？</li><li>定时暂停重要吗？</li><li>硬核实际上良好的长期暂停会是什么样子等？</li><li>实验室是否真的会跟进等等？</li><li>收购担忧与滥用行为混在一起是不是很糟糕？也许并没有那么糟糕？就像我实际上并不很担心 ASL-3 等。或者也许这很好，因为一些对策转移了？</li><li>未来会有好的RSP吗？ （就像 Anthropic 的 RSP 基本上是关于最重要问题的 RSP IOU。我认为这可能还可以。） </li></ul></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 17:49:56 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 17:49:56 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我对 RSP 的基本看法：</p><ul><li>我同意<a href="https://www.lesswrong.com/posts/dxgEaDrEBkkE96CXr/thoughts-on-responsible-scaling-policies-and-regulation.">https://www.lesswrong.com/posts/dxgEaDrEBkkE96CXr/thoughts-on-responsible-scaling-policies-and-regulation 中的大部分内容。</a>例外情况：<ul><li>我对风险的基线猜测比 Paul 的要高一些，因此我认为 RSP 不会让您的风险降至 1%</li><li>我不太看好将风险降低 10 倍，但也许 5 倍似乎相当可行？我不知道</li><li>我认为未来 5 年内不太可能出现基于机械互助之类的良好肯定安全案例，因此此类要求似乎接近事实上的禁令。 （我不确定保罗是否不同意我的观点，但这似乎是一件值得注意的重要事情。）</li></ul></li><li>我同意这个词看起来很糟糕。感觉可能是一个错误。我还发现 OpenAI 使用不同的术语（RDP）很有趣</li><li>我并不担心未知的风险，但我确实认为“人工智能扰乱你的评估”是一个大问题。我认为可以通过检查人工智能是否能够干扰你的评估来解决这个问题（这可能比仅仅避免它们干扰你的评估更容易）。</li></ul></section><h2> RSP 的命名和背后的意图</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 17:53:11 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 17:53:11 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我认为如果 ARC 说这样的话会更好：“实验室应该制定扩大规模的政策：扩展政策 (SP)。我们希望这些政策实际上是安全的，我们很乐意就 SP 的责任进行咨询并降低风险”。<br><br>我还更喜欢“条件安全改进政策”或类似名称。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 17:56:35 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 17:56:35 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>我确实觉得“负责任的扩展政策”这个术语显然引用了一些我认为不正确的事情：</p><ul><li> “扩展”的速度是负责任地使用人工智能的首要因素</li><li>显然可以负责任地扩展（否则政策会管辖什么）</li><li>人工智能研究组织的默认轨迹应该是继续扩大规模</li></ul><p><a href="https://twitter.com/jamespayor/status/1715728849214857444">推特上的</a>James Payor 有一种类似的观点，引起了我的共鸣：</p><blockquote><p>我在这里补充一点，“AGI 扩展政策”将是一个比“负责任的扩展政策”更诚实的名字。</p><p> “RSP”这个名字隐含地表明（a）没有理由停下来； (b) 可以负责任地扩大规模； (c) 政策本体不可修改； ETC。</p><p> ……这些感觉像是可怕的假设，似乎是故意让协调人工智能停止变得更加困难。我确实喜欢这些内容，但我对这些东西的存在和相关的影响感到非常不满。</p></blockquote><p>我也对 RSP 的定义应该是什么感到有点困惑。 ARC Evals 帖子只是说：</p><blockquote><p> RSP 指定了人工智能开发人员准备使用当前的保护措施安全处理什么级别的人工智能功能，以及在保护措施改善之前继续部署人工智能系统和/或扩大人工智能功能过于危险的条件。</p></blockquote><p>但我认为这并不是一个充分的定义。当然，有很多符合这个定义的东西被称为 RSP 会很奇怪。就像，缩放定律论文试图回答这两个问题，但显然不符合 RSP 的资格。</p><p>上面的基本概念结构也让人感到困惑。例如，RSP 如何指定开发人员准备处理安全问题的 AI 功能级别？现实为你指明了这一点。也许它应该说“它指定了人工智能开发人员认为他们可以处理的人工智能能力水平”？</p><p>下一句话也是如此。 RSP 如何指定在什么情况下继续部署人工智能系统会过于危险？再说一次，现实是你唯一的仲裁者。 RSP 可以指定人工智能开发人员认为太危险的条件，但这在政策中似乎也很奇怪，因为随着时间的推移，这种情况可能会发生很大的变化。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:01:07 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:01:07 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我同意“负责任的扩展政策”一词会引发虚假内容。我想这对我来说似乎并没有那么糟糕？也许我低估了名字的重要性。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:07:28 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:07:28 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><blockquote><p>我在这个领域感到有点困惑的另一件事是“RSP 的定义在哪里？”。 ARC Evals 帖子说：<br><br> >; RSP 指定人工智能开发人员准备使用当前的保护措施安全处理什么级别的人工智能功能，以及在保护措施改善之前继续部署人工智能系统和/或扩大人工智能功能过于危险的条件。</p></blockquote><p>是的，如果加上“claim”这个词，这一段似乎会更好。就像“RSP 指定了人工智能开发人员声称他们准备好使用当前的保护措施安全处理的人工智能能力水平，以及他们认为继续部署人工智能系统和/或扩大人工智能规模太危险的条件直到保护措施得到改善为止。”<br><br>希望是这样的：</p><ul><li> AI 开发人员制定了 RSP，其中提出了一些隐式或显式的声明。</li><li>人们可以争辩说，既然有明确的政策可以争论，那么这对于安全来说是不够的。 </li></ul></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:08:44 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:08:44 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><blockquote><p>我同意“负责任的扩展政策”一词会引发虚假内容。我想这对我来说似乎并没有那么糟糕？</p></blockquote><p>是的，我确实觉得我试图判断人工智能监管和人工智能联盟中引入的概念和抽象的主要维度是这些概念是否调用真实的事物并在其关节处雕刻现实。</p><p>我同意我可以尝试做一件更天真的后果论的事情，就像“是的，好吧，让我们试着向前推进当人类遇到这些想法时，当它看到这些特定的人说这些时，人类会做什么”话”，但即便如此，我还是觉得 RSP 看起来不太好，因为在那个水平上，我主要希望他们会说“哦，这些人说他们正在负责任”或类似的话。</p><p>需要明确的是，我喜欢 Anthropic RSP 和 ARC Evals RSP 帖子所指出的一点基本上是一系列运作良好的有条件承诺。 RSP 的一种方式是基本上成为人工智能实验室和公众之间的合同，具体规定“当 X 发生时，我们承诺做 Y”，其中 X 是一些能力阈值，Y 是一些暂停承诺，也许还有一些结束条件。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:08:58 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:08:58 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>具体来说，您认为 ARC evals 和 Anthropic 应该做什么？就像他们应该使用不同的术语吗？ </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:11:23 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:11:23 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>就像，比起 RSP，我更喜欢对 Dario 和 Daniella 进行一系列坦率的采访，其中有人会说“所以你认为 AGI 有很大的机会杀死所有人，那么你为什么要建造它呢？”。一般来说，创建更高带宽的通道，人们可以用它来了解领先人工智能实验室的人们对人工智能风险的看法，以及何时值得这样做。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:11:26 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:11:26 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>对我来说，制定某种书面并维护的政策似乎非常重要，这些政策涉及“我们何时停止增加模型的功率”以及“我们将针对不同的功率级别采取哪些安全干预措施”。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:12:00 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:12:00 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>TBC，坦诚采访的记录似乎也不错。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:14:11 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:14:11 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我想要政策的部分原因是，这使得组织内部的人员更容易举报或反对内部的事情。<br><br>我还认为，如果更多的人更具体地思考当前的计划是什么样子，那就更好了。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:14:29 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:14:29 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><blockquote><p>对我来说，制定某种书面并维护的政策似乎非常重要，这些政策涉及“我们何时停止增加模型的功率”以及“我们将针对不同的功率级别采取哪些安全干预措施”。</p></blockquote><p>是的，明确地说，我认为这也很棒。我确实对“人工智能能力公司应该有一份概述其扩展和安全计划的最新文件”感到非常满意。我确实觉得，在有这种计划的世界里，很多对话显然会进展得更好。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:18:06 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:18:06 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>似乎我们对于我们希望实验室向世界提供的实际工件有轻微但不是很大的分歧，以解释他们的计划？<br><br>我一般认为，在目前的利润范围内，更诚实、清晰的沟通和针对所有事情的具体计划似乎相当不错（例如，RSP、 <a href="https://www.lesswrong.com/posts/6HEYbsqk35butCYTe/labs-should-be-explicit-about-why-they-are-building-agi">关于风险的明确声明、对实验室为什么要做他们知道有风险的事情的明确解释</a>、与怀疑论者的详细讨论等）。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:21:16 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:21:16 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>我确实觉得两种不同类型的文物之间存在着巨大的紧张关系：</p><ol><li>一份应该准确总结组织在不同情况下期望做出的决策的文件</li><li>一份旨在约束组织在某些情况下做出某些决定的文件</li></ol><p>就像，我目前得到的感觉是，RSP 是一种“不后悔”的东西。你不能发布 RSP 说“是的，我们不打算扩大规模”，然后又说“哎呀，我改变主意了，我们实际上要全力以赴”。</p><p>我的猜测是，这就是为什么我希望组织不会真正致力于其 RSP 中的任何实际内容，并且他们不会真正了解组织领导层认为的权衡是什么。就像，这就是为什么 Anthropic RSP 有一个很大的 IOU，实际上最关键的决定应该在其中。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:21:23 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:21:23 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>哦，明白了，约束性政策和解释之间存在一些差异。<br><br>我同意 RSP 使得以降低安全性的方式改变事物的成本相对更高。从我的角度来看，这似乎主要是一个好处？ RSP 似乎也可以有一些类似“我们对应该做什么的初步最佳猜测”的部分和一些类似“我们当前政策”的部分。 （例如，Anthropic RSP 对 ASL-4 有一个初步猜测，但在其他地方有更可靠的政策。） </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:22:45 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:22:45 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>也许一个有趣的问题是“Anthropic 在触发 ASL-3 之前充实 ASL-4 评估和安全干预措施的可能性有多大”？ （这将还清欠条。）<br><br>或者在接下来的两年内充实它，条件是 ASL-3 在这两年内没有被触发。<br><br>我对这种情况的发生持适度乐观的态度。 （也许 60% 是基于 ASL-4 评估和 2 年内一些听起来对我来说特定的 ASL-4 干预措施，条件是没有 ASL-3） </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:23:34 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:23:34 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>就像，这是“RSP”的替代方案。称其为“有条件暂停承诺”（CPC，如果您喜欢缩写词）。</p><p>基本上，我们只是要求 AGI 公司告诉我们在什么条件下他们将停止扩展或停止尝试开发 AGI。然后还有一些恢复的条件。然后我们就可以批评这些。</p><p>这似乎是一个更清晰的抽象概念，对于该事物是否试图成为组织未来决策的准确地图，或者它应该在多大程度上认真地承诺一个组织，或者整个事物是否“负责任”，没有那么哲学上的固执己见。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:30:37 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:30:37 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><blockquote><p>就像，这是“RSP”的替代方案。称其为“有条件暂停承诺”（CPC，如果您喜欢缩写词）。</p></blockquote><p>我同意 CPC 是一个更好的术语和概念。我认为这基本上就是 RSP 想要实现的目标？<br><br>但似乎值得注意的是，对策是整个局面的关键部分。就像你暂停的条件可能取决于你到目前为止所实施的内容等。我觉得 CPC 不会自然地引起对策部分，但总的来说，它似乎是一个更好的术语。 （我们显然可以添加这一点，但这个名字很糟糕：条件暂停承诺，包括对策 CPCC） </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:33:43 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:33:43 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><blockquote><p>也许一个有趣的问题是“在触发 ASL-3 之前，人类有多大可能充实 ASL-4 评估和安全干预措施”？ （这将还清欠条。）</p><p> （或者在未来 2 年内充实它，条件是不触发 ASL-3。）<br><br>我对这种情况的发生持适度乐观的态度。 （也许 60% 是基于 ASL-4 评估和 2 年内一些听起来对我来说特定的 ASL-4 干预措施，条件是没有 ASL-3）</p></blockquote><p>是的，我同意这是一个有趣的问题，并且我大致同意你在这里的可能性。</p><p>我确实认为他们不跟进的世界真的很糟糕。我真的不喜欢 40% 的世界，事实证明 RSP 是那种导致一群人摆脱 Anthropic 构建真正危险的人工智能的事情，并且是那种导致大量的事情人工智能安全领域的领导者来支持他们，但事情却从未真正实现。</p><p>就像，我觉得这不是我第一次从这里的一些人性公告中感受到不好的氛围。就像他们也有<a href="https://www.anthropic.com/index/the-long-term-benefit-trust">长期利益信托</a>一样，它看起来确实像是那种应该确保人类独立于利润激励的东西，但是就像，埋在中间随机段落末尾的一句话中是爆炸性的事实是，只要绝大多数股东不同意，治理委员会实际上就没有能力阻止 Anthropic，而且他们没有具体说明绝大多数股东的实际具体数字，然后我觉得整件事只是对我来说很平淡。</p><p>就像，如果没有给我具体的数字，这个承诺就没有多大作用。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:34:14 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:34:14 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我非常担心不稳定或糟糕的 RSP 以及 RSP IOU，但这种情况永远不会发生。我觉得 OpenAI 或 GDM 的风险比 Anthropic 高得多。<br><br>我们将看看 OpenAI 的第一个 RDP 是什么样子的。我们将看看 GDM 是否会采取任何官方行动。</p></section><h2>认可和未来轨迹</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:37:35 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:37:35 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><blockquote><p>我确实认为他们不跟进的世界真的很糟糕。就像我真的不喜欢 40% 的世界，事实证明 RSP 是那种让一群人摆脱 Anthropic 构建真正危险的人工智能的事情，也是那种导致大量人死亡的事情。人工智能安全领域的领导者来支持他们，然后事情就永远不会真正实现。</p></blockquote><p>我认为人们应该继续向他们施加压力，直到他们更加充实 ASL-4 评估和承诺。<br><br>我想我觉得我们可以在某种程度上拒绝完全认可，这可能会降低这种结果的风险。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:40:04 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:40:04 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我觉得我想要倡导的事情是这样的：</p><ul><li>来自人类的 ASL-4 承诺和评估（可以是初步的等）</li><li>一些 RSP 类似于其他实验室的东西。即使我认为这项政策非常不安全，那仍然是进步，那么我们至少可以对这项具体政策的质量进行争论。</li><li>对 RSP 之类的其他改进。 </li></ul></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:40:13 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:40:13 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>我确实认为我非常担心“AGI 公司占领人工智能安全领域”领域的很多事情。例如，大多数从事人工智能安全工作的人已经受雇于 AGI 公司。我觉得在我真正撤回认可的能力基本上完全被削弱之前，我没有多少年的时间继续维持现状了。</p><p>因此，我对人择 RSP 的一系列反应是担心，如果我现在不反对，当更清楚这件事并不严重时，该领域将无法在以后反对（在这个世界中是这样），因为到那时，很多人的职业生涯、声誉和贡献能力都直接取决于与能力公司的相处，因此某种形式的撤回背书的希望不大。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:42:58 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:42:58 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我想要的密切相关的事情是：在人工智能实验室工作的人应该仔细思考并写下他们会大声辞职的条件（这可以私下完成，但也许应该在志同道合的员工之间共享以获得常识）。这样，人们就有希望避免“温水煮青蛙”。<br><br>我担心人们可能会因为诸如“我真的不想戒烟，因为那样我的影响力就会消失，我应该尝试影响事情变得更好”这样的想法而在真正应该戒烟的时候避免戒烟。此外，XYZ 承诺如果我稍等一下，那东西会更好。”就像在各个人工智能实验室里可能有一些非常善于操纵的人一样。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:44:32 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:44:32 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><blockquote><p>在人工智能实验室工作的人应该思考并写下他们会大声辞职的条件（这可以私下进行，但也许应该在志同道合的员工之间分享，以获得常识）。这样，人们就有希望避免“温水煮青蛙”。</p></blockquote><p>是的，我确实认为这也很棒。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:46:36 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:46:36 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我也同意“令人恐惧的是，大量的安全人员在实验室工作，这种趋势似乎可能会持续下去”。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:47:33 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:47:33 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><blockquote><p>因此，我对人择 RSP 的一系列反应是担心，如果我现在不反对，当更清楚这件事并不严重时，该领域将无法在以后反对（在这个世界中是这样），因为到那时，很多人的职业生涯、声誉和贡献能力都直接取决于与能力公司的相处，因此某种形式的撤回背书的希望不大。</p></blockquote><p>您为什么不认为您现在可以拒绝认可并说“我正在等待 ASL-4 标准和评估”？ （我不知道这是否重要。） </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:49:00 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:49:00 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>好吧，我可以，但我预计在接下来的几年里，我的观点在当前默认的社会轨迹上将不再有太大的影响力。就像，我可以拒绝认可，但我希望认可的重要性会转向那些不拒绝认可的人。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:50:28 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:50:28 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>好的了解了。我想我确实预计随着时间的推移，你可能会因为各种原因失去影响力。我不确定你应该对此做什么。</p></section><h2>您能在多大程度上判断给定模型是否存在存在危险？ </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:51:11 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:51:11 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>我确实想稍微回顾一下，谈谈我不断想到的 RSP 的另一个方面。我对此没有很好的把握，但也许描述它的最好方式就是“伙计，RSP 确实让听起来我们对 AGI 何时变得危险有很好的把握”之类的。</p><p>比如，我对假设的“有条件暂停承诺”和 RSP 的担忧是，如果某些 AGI 公司善意地遵守了你给他们的一些随机安全基准，那么你最终会陷入这样一种状态：你承诺允许某些 AGI 公司扩大规模。现实情况是，识别一个系统是否安全，或者是否（例如）具有欺骗性地对齐，是极其困难的，而且我们在这个问题上并没有太多的吸引力，所以我并不真正期望这一点实际上，我们会对安全基准提出任何很好的建议，我们相信这些建议可以承受数十亿至数万亿美元的经济压力和更加智能的人工智能系统。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:55:21 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:55:21 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><blockquote><p>我确实想稍微回顾一下，谈谈我不断想到的 RSP 的另一个方面。我对此没有很好的把握，但也许描述它的最好方式就是“伙计，RSP 确实让听起来我们对 AGI 何时变得危险有很好的把握”之类的。</p></blockquote><p><br>我认为我们确实有一个合理的方法来了解如何知道给定模型的给定部署是否存在危险（以及如何运行此类评估而不使评估本身太危险而无法运行）。<br><br>我对如何在开源模型安全的情况下进行此类评估不太有信心，因为脚手架或微调之类的事情可能会进展并使这些开源模型变得危险。</p><p>我对此的信心程度并不是压倒性的，但我认为我们可以评估厄运何时开始 >;1%，而无需极其保守。也许 0.1% 更难。</p><p>我的意思是“如果你继续将 GPT 缩放 0.25 GPT，你能否进行评估，使得当评估表明危险时，厄运小于 1%”。</p><p>我认为这可能很好地转移到其他基于机器学习的方法。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:57:56 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:57:56 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>呵呵，这个我有点惊讶。我相信你可以使用“随机采样”系统来做到这一点，但我不认为你可以使用对抗性选择的系统来做到这一点。就像，我同意你可能可以粗略地确定计算和资源的规模（假设没有巨大的算法突破和 RSI 以及一堆其他东西），其中事情变得危险，但是，RSP 的全部意义在于然后拥有AGI 公司试图超越你设定的一些基准，这些基准是他们需要做什么才能走得更远，而这对我来说似乎很难。</p><p> （旁注：这反映了我现在经常围绕人工智能对齐研究进行的一般类型的对话，其中有很多可怕的恶魔、可解释性和评估工作，其目标是确定人工智能是否未对齐，并且我通常的回答是“好吧，我非常有信心在未来几年内你会得到大量证据表明人工智能系统与你不一致。我的主要问题是，一旦你确定一个系统不符合你的要求，你实际上会做什么或者以这种方式危险”，然后令人惊讶的是人们经常没有真正的答案） </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:58:28 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:58:28 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>哦，好吧，我同意何时前进的基准非常棘手。</p><p>我的主张更像是“相当好的 ASL-3 和 ASL-4 评估应该是可能的”（包括它们对欺骗性对齐的 AI 系统可能试图对这些评估进行沙袋的可能性具有鲁棒性） </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 19:03:56 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 19:03:56 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>ASL-3 和 ASL-4 的定义是什么？ </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:06:07 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:06:07 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我大致认为：<br><br> ASL-3：从误用的角度来看可能是危险的，可能不是自动危险的（>;=ASL-3 的评估是根据 ARA（自主复制）或严重误用风险进行操作的）<br><br> ASL-4：可以认真地进行 ARA（自主复制），并且可能有逃跑或其他严重问题的风险。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 19:07:34 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 19:07:34 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><blockquote><p>我的主张更像是“相当好的 ASL-3 和 ASL-4 评估应该是可能的”</p></blockquote><p> “评估”指的是“评估我们何时应该将人工智能系统分类为 ASL-3、ASL-4 甚至更高”？</p><p>或者您的意思是，我们也许能够进行评估，即使花费数十亿美元来匹配该评估，评估也会告诉我们给定的 ASL-3 或 ASL-4 系统是否可以安全地更广泛地部署？ （例如，可能为 ASL-3 开源，或者为 ASL-4 部署） </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:08:02 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:08:02 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我说的是用于分类和排除 >;=ASL-4 的评估，而不是用于指示此类系统安全的评估。<br><br>我也并不是说这些评估对于沉重的优化压力一定是稳健的，从而使人工智能在这个评估中显得愚蠢而聪明。<br><br>我没有想太多；这对我来说确实是一个重大问题。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:08:55 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:08:55 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我认为我们应该讨论“实验室将为 ASL-4+ 模型提出哪些安全论据”？ </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 19:09:21 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 19:09:21 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>“安全论点”指的是“相关模型可以安全开发/使用/部署/分发的论点？” </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:09:30 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:09:30 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>是的，受某些协议的约束，例如可能限制使用。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 19:14:50 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 19:14:50 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>是的，看起来不错。这看起来确实非常重要，作为一个至少现在对这个问题的思考比我期望实验室思考的要多得多的人，我的答案肯定是“伙计，我不知道吗”。</p><p>需要明确的是，显然有些训练设置看起来比其他训练设置更危险，但我真的不知道在安全争论的情况下如何考虑这一点，即使如此，我也感到非常困惑。</p><p>举个例子，我的猜测是，系统中的大部分计算都花在了在奖励长期规划和代理资源获取的环境中进行强化学习训练（例如，许多视频游戏或外交或各种长期模拟）。目标）确实看起来更危险。</p><p>但我想我只有 75% 的概率相信这一点？如果最终我开始相信，对于一个系统来说，最终是否危险最重要的只是计算量和投入其中的数据的丰富性，以及所有的论点，我真的不会感到惊讶。工具收敛已经完全适用于大型语言模型，可能会在上面撒上一点 RLHF，在这种情况下，在丰富的环境中通过强化学习训练的系统实际上可能更安全，因为大量计算的使用效率要低得多，并且您可能更能够引出长期规划并利用它来做有用的事情。</p><p>就像，我没有太多的动力来进一步减少概率分布，除了“只是做更多的人工智能对齐研究，深入研究当前模型，认真思考，写很多博客文章， ETC。”​​。因此，考虑到我们目前的理解水平，我很难想象 AGI 公司实际上会给我一个安全论证，对我来说有意义地改变概率质量。</p></section><h2>通过“控制”与“缺乏倾向”进行防御</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:21:30 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:21:30 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>这是我进行安全论证的基本状态。<br><br>我认为安全论点可能有两条（部分重叠的）“防线”：</p><ul><li><strong>控制</strong>：鉴于我们的对策，人工智能<i>无法</i>做严重危险的事情（除非先被抓住）。</li><li><strong>倾向</strong>：人工智能不太可能<i>尝试</i>做严重危险的事情。</li></ul><p>我对当前科学的安全有用性权衡的总体看法是：</p><ul><li>我们的技术还远远不能自信地评估强大的人工智能系统的倾向。</li><li>控制可能可以评估并确保<i>早期变革性人工智能</i>（例如可以将人类进行机器学习研发速度加快 30 倍的模型）</li><li>我们至少可以使用<a href="https://www.alignmentforum.org/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1#The_Case_against_Model_Organisms_">模型生物</a>和对抗性评估之类的东西来测试一些倾向（试图产生人工智能在其上做一些非常糟糕的事情的合成输入）。</li><li>就像我认为“我们努力以对抗性方式评估该模型，但它没有做任何非常可疑的事情”是不平凡的证据，尽管并不令人惊讶。</li><li>我认为“我们试图创造欺骗性的排列模型生物体，但我们最好的模型生物体相当弱”也是一些证据。</li><li>我认为我们有大约 70% 的机会能够为<i>早期变革性 AI</i>建立良好的控制参数，从而将风险降低约 3-5 倍，同时使模型的有用性稍微降低（例如，有用性降低 2 倍）</li><li>显然，控制无法扩展。 （因此，随着规模的扩大，安全性和实用性的权衡会变得更糟）</li><li>评估控制的方法并非平凡且复杂。我不知道如何以无法玩弄的方式指定评估。</li><li>我认为控制+模型生物+对抗性评估可以将风险降低 5-15 倍，而且如果我们真的努力的话，这并不是不可能的。 </li></ul></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 19:24:56 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 19:24:56 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>这三件事感觉很难同时成为现实：</p><blockquote><p>控制可能可以评估并确保早期变革性人工智能（例如可以将人类进行机器学习研发速度加快 30 倍的模型）</p><p> [...]</p><p>就像我认为“我们努力对模型进行红队处理，但它没有做任何非常可疑的事情”是不平凡的证据，尽管并不令人惊讶。</p><p> [...]</p><p>我认为“我们试图创造欺骗性的排列模型生物体，但我们最好的模型生物体相当弱”也是一些证据。</p></blockquote><p>就像，这并非不可能，但我确实希望在红队不严重破坏模型的情况下，你无法获得 30 倍的 ML 研发（至少在红队涉及微调的情况下）。</p><p>另外，我确信，早在你能够将 ML 研发速度加快 30 倍之前，你就可以得到相当可靠、具有欺骗性的对齐模型生物体，而且我不认为我们有太多的动力去寻找某种不适合的训练设置。情况不再如此。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:25:23 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:25:23 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><blockquote><p>举个例子，我的猜测是，系统中的大部分计算都花在了在奖励长期规划和代理资源获取的环境中进行强化学习训练（例如，许多视频游戏或外交或各种长期模拟）。目标）确实看起来更危险</p></blockquote><p><br>是的，所以我们可以做的一件事就是“猜测训练的调整，这将降低危险倾向的可能性”。我不认为这里有很多好主意，而且我预计由此带来的安全实用性权衡似乎并不令人惊奇。 （所以我同意你的观点，我只是认为还有其他途径。）</p><blockquote><p>就像，这并非不可能，但我确实希望在红队不严重破坏模型的情况下，你无法获得 30 倍的 ML 研发（至少在红队涉及微调的情况下）。</p></blockquote><p>我应该在这里更清楚地表达我的意思。我的意思是“对抗性评估（试图产生人工智能做出非常糟糕的事情的合成输入）”<br><br> We could get into why I think this is non-trivial evidence. </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 19:27:54 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 19:27:54 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><p> Ok, I have to head out in 5 minutes, so let&#39;s try to wrap up.</p><p> I do feel like a major disagreement here is probably something like &quot;how optimistic am I about the control route&quot;, which I know that you and Buck have been thinking about a lot. I have definitely mostly been thinking about AI Alignment through the propensity lens, since I&#39;ve been looking for ways to scale the the methods to superintelligence, so I don&#39;t have super robust opinions here, but I do have a sense that this is going to be much harder than my model of you thinks it is. </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:28:02 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:28:02 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>ryan_greenblatt</b></section><p> FYI, I&#39;m intentionally avoiding the term &quot;alignment&quot; because that term now has a bunch of baggage. So I&#39;d like to just say safety arguments and then talk more specifically. </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 19:28:14 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 19:28:14 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><p> That seems very reasonable. </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:29:04 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:29:04 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>ryan_greenblatt</b></section><p> Yep, worth noting I haven&#39;t yet argued for my level of optimism. So we&#39;d maybe want to do that next if we want to continue.</p></section><h2> Summaries </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 21:56:49 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 21:56:49 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>habryka</b></section><p> <i>Summarizing what we covered in this dialogue (feel free to object to any of it):</i></p><p> A substantial chunk of my objections were structured around the naming and definitions of RSPs. You agreed that those didn&#39;t seem super truth-promoting, but also thought the costs of that didn&#39;t seem high enough to make RSPs a bad idea.</p><p> We then covered the problem of the Anthropic RSP, as the primary example of an RSP, having kind of a big IOU shaped hole in it. I was concerned this would allow Anthropic to avoid accountability and that people who would hold them accountable wouldn&#39;t have enough social buy-in by the time the IOU came due. You agreed this was a reasonable concern (though my guess is you also think that there would still be people who would hold them accountable in the future, more so than I do, or at least you seem less concerned about it).</p><p> I then switched gears and started a conversation about the degree to which we are even capable of defining evals that meaningfully tell us whether a system is safe to deploy. We both agreed this is pretty hard, especially when it comes to auditing the degree to which the propensities and motivations of a system are aligned with us. You however think that if we take it as a given that a system has motivations that are unaligned with us, then we still have a decent chance of catching when that system might be dangerous, and using those evals we might be able to inch towards a world where we can make substantially faster AI Alignment progress leveraging those systems. This seemed unlikely to me, but we didn&#39;t have time to go into it.</p><p> Does this seem overall right to you? I am still excited about continuing this conversation and maybe digging into the &quot;Alignment vs. Control&quot; dimension, but seems fine to do that in a follow-up dialogue after we published this one. </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 22:42:08 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 22:42:08 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>ryan_greenblatt</b></section><p> Yep, this seems like a reasonable summary to me.</p><p> One quick note:</p><blockquote><p> (though my guess is you also think that there would still be people who would hold them accountable in the future, more so than I do, or at least you seem less concerned about it)</p></blockquote><p> Yep, I think that various people will be influential in the future and will hold Anthropic accountable. In particular:</p><ul><li> Anthropic&#39;s Long-Term Benefit Trust (LTBT) (who approves RSP changes I think?)</li><li> People at ARC evals</li><li> Various people inside Anthropic seem to me to be pretty honestly interested in having an actually good RSP</li></ul></section><div></div><br/><br/> <a href="https://www.lesswrong.com/posts/jyM7MSTvy8Qs6aZcz/what-s-up-with-responsible-scaling-policies#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/jyM7MSTvy8Qs6aZcz/what-s-up-with-responsible-scaling-policies<guid ispermalink="false"> jyM7MSTvy8Qs6aZcz</guid><dc:creator><![CDATA[habryka]]></dc:creator><pubDate> Sun, 29 Oct 2023 04:17:07 GMT</pubDate> </item><item><title><![CDATA[Experiments as a Third Alternative]]></title><description><![CDATA[Published on October 29, 2023 12:39 AM GMT<br/><br/><p> As a kid in elementary school, I was diagnosed with ADHD. I think the diagnostic process is dumb and unreliable, and so the fact that I was diagnosed seems like it should only count as weak evidence. But knowing what I know about myself and having read a few books about ADHD, my best guess is that I have (and had) a moderate case of it.</p><p> I&#39;ve never taken medication for it though.为什么？ Well, from my perspective, there has never been anything wrong with me. There&#39;s something wrong with <i>The System</i> . Fight the power!</p><p> For example, I&#39;d be in school and the teacher would want me to pay attention to X. But instead of X, I&#39;d want to think about Y. It&#39;s hard for me to focus on X when I am driven to think about Y. <span class="footnote-reference" role="doc-noteref" id="fnrefkdt37vlb64"><sup><a href="#fnkdt37vlb64">[1]</a></sup></span></p><p> Is this a bad thing? Well, it depends on the values of X and Y. Sometimes X and Y take values that make it good, other times they take values that make it bad.</p><ul><li> For example, when I&#39;m behind the wheel of a car and X = &quot;the stoplight in front of me&quot; and Y = &quot;that new Indian restaurant&quot;, it is bad. <span class="footnote-reference" role="doc-noteref" id="fnrefcalstl3kzju"><sup><a href="#fncalstl3kzju">[2]</a></sup></span></li><li> But when X = &quot;Bobby&#39;s question about last night&#39;s algebra homework&quot; and Y = &quot;the <a href="https://en.wikipedia.org/wiki/Flip_book">flip book</a> I&#39;m working on&quot;, I&#39;d argue that my &quot;attention deficit&quot; is good.</li><li> Overall, I have always thought that my &quot;attention deficit&quot; does significantly more good than harm.</li></ul><p> For this reason, I never wanted to take medication for ADHD. I thought that I was generally prone to paying attention to the &quot;right&quot; things, that the adults generally wanted me to pay attention to the &quot;wrong&quot; things, and that this was a problem with the world they were trying to get me to live in, not with my nature.</p><p> But the doctors and my parents had a totally different perspective. They thought my tendencies and behavior were in fact problematic. However:</p><ol><li> Academically, I did pretty well in school.</li><li> Behaviorally, I was mischievous, but always in a harmless type of way. <span class="footnote-reference" role="doc-noteref" id="fnref71yorfxj697"><sup><a href="#fn71yorfxj697">[3]</a></sup></span></li><li> I had this involuntary facial tick <span class="footnote-reference" role="doc-noteref" id="fnrefk7en98cp9t"><sup><a href="#fnk7en98cp9t">[4]</a></sup></span> and apparently there is a risk that the medication would cause me to develop (much?) worse ticks.</li></ol><p> For these reasons, they thought it was fine for me to avoid medication.</p><p> As a kid it was the doctors and my parents who were ultimately in charge of whether or not I took medication. Maybe if I argued that I wanted medication they would be receptive, but probably not. However, as an adult, it becomes my decision. So once I went away to college, I could have just gone to a neurologist or whatever and re-explored this decision to avoid medication.</p><p> I never did that though.为什么？ <a href="https://www.lesswrong.com/tag/cached-thoughts">Cached thoughts</a> .</p><blockquote><p> I like who I am. My so called &quot;attention deficit&quot; is actually a good thing overall because it allows me to hyperfocus on the things that interest me, which is really valuable. Yes, sometimes this ends up biting me, but the bites aren&#39;t too frequent, nor are they too harsh.</p></blockquote><p> When the topic of my ADHD came up, the above thought is what I would immediately gravitate towards. It&#39;s not as black-and-white as &quot;it&#39;s the only thought I would ever think&quot;, but I gravitated towards it pretty strongly.</p><p> But over the past few weeks I&#39;ve been starting to question how accurate that cached thought is.</p><p> I have pretty high levels of anxiety <span class="footnote-reference" role="doc-noteref" id="fnreff8b7bmfomun"><sup><a href="#fnf8b7bmfomun">[5]</a></sup></span> in general for various reasons, and I&#39;ve been looking for ways to mitigate it. One cause of this anxiety is that I always have a million things I want to do. Things that are interesting and deserving of my attention. But I don&#39;t have time to do them all, of course.</p><p> And a related problem is that if I&#39;m focused on something and need to stop, it feels like pulling teeth. For example, I started writing this post at a coffee shop, but at 3pm when they closed I had to stop what I was doing, close my laptop, and spend 20 minutes walking home. That was very uncomfortable.</p><p> But this sort of thing happens all the time. When I&#39;m working and it&#39;s time to eat. When I&#39;m coding and I have to go walk my dog. When I&#39;m reading and it&#39;s time for me to go to racquetball. When I&#39;m thinking and it&#39;s time for me to go to sleep.</p><p> Right now, I lean towards thinking that my ADHD does more harm than good and that I should take medication. But this line of thinking is also problematic.为什么？ Because there&#39;s an implicit and false dichotomy. It fails to seek out a <a href="https://www.lesswrong.com/posts/erGipespbbzdG5zYb/the-third-alternative">Third Alternative</a> . From the post:</p><blockquote><p> “Believing in Santa Claus gives children a sense of wonder and encourages them to behave well in hope of receiving presents. If Santa-belief is destroyed by truth, the children will lose their sense of wonder and stop behaving nicely. Therefore, even though Santa-belief is false-to-fact, it is a Noble Lie whose net benefit should be preserved for utilitarian reasons.”</p><p> Classically, this is known as a false dilemma, the fallacy of the excluded middle, or the package-deal fallacy. Even if we accept the underlying factual and moral premises of the above argument, it does not carry through. Even supposing that the Santa policy (encourage children to believe in Santa Claus) is better than the null policy (do nothing), it does not follow that Santa-ism is the <i>best of all possible alternatives.</i> Other policies could also supply children with a sense of wonder, such as taking them to watch a Space Shuttle launch or supplying them with science fiction novels. Likewise, offering children bribes for good behavior encourages the children to behave well <i>only</i> when adults are watching, while praise without bribes leads to unconditional good behavior.</p><p> Noble Lies are generally package-deal fallacies; and the response to a package-deal fallacy is that if we really need the supposed gain, we can construct a Third Alternative for getting it.</p></blockquote><p> What Third Alternative do I have? Well, how about just taking the medication as an experiment?</p><p> I realize that I (as well as my parents and the doctors <span class="footnote-reference" role="doc-noteref" id="fnrefts8mvi2bp6n"><sup><a href="#fnts8mvi2bp6n">[6]</a></sup></span> ) have been approaching the question as if I am either going to 1) be a person who doesn&#39;t take medication or 2) be a person who does take medication. But option #3 is much better: take medication for six weeks and see what happens.</p><p> It reminds me of the thing <span class="footnote-reference" role="doc-noteref" id="fnrefxy1ey1ogs6i"><sup><a href="#fnxy1ey1ogs6i">[7]</a></sup></span> where thousands of years ago, philosophers thought that it was noble to sit inside and use your mind to figure things out, and that going out to look at the world to see what happens... well... that&#39;s ignoble. A job to be done by a man of much lower social status.</p><p> For my ADHD stuff, I&#39;ve been acting like one of those old philosophers. Instead of <i>just trying the damn thing</i> , I&#39;ve been straining to predict whether or not the thing will do more harm than good.</p><p> But that sort of &quot;straining to predict&quot; is dumb. I mean, again, why not just try the damn thing? Why predict when you can test? <span class="footnote-reference" role="doc-noteref" id="fnrefj06vqnxu2wa"><sup><a href="#fnj06vqnxu2wa">[8]</a></sup></span></p><ul><li> Well, sometimes the test is costly. Like, an MRI, perhaps. But ADHD medication is not expensive.</li><li> Other times the test will have long-term, or even permanent effects. With the ADHD, I think there&#39;s always been a deep part of my mind that was afraid of this. I don&#39;t want the medication to &quot;change me&quot;. In doing some research, this seems quite unlikely though. There&#39;s still some emotional part of me that is a little afraid of it &quot;changing me&quot;, but it&#39;s not too loud.</li><li> Sometimes the test is painful. Like one of those biopsies where they stab you with a big needle. That&#39;s not the case here though.</li><li> Sometimes you&#39;re confident enough in the outcome that you don&#39;t need to bother testing. But again, that&#39;s not the case here.</li></ul><p> I&#39;m sure one can have a long discussion about the abstract question of when it makes sense to test and when it makes sense to avoid testing things. I&#39;m not interested in doing that though. I think that for the purposes of this post, it&#39;s enough to say that when tests are cheap, painless, and don&#39;t have long-term effects, the bar is low and they&#39;re generally a pretty appealing Third Alternative. <span class="footnote-reference" role="doc-noteref" id="fnrefw0qvxpfza3n"><sup><a href="#fnw0qvxpfza3n">[9]</a></sup></span> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnkdt37vlb64"> <span class="footnote-back-link"><sup><strong><a href="#fnrefkdt37vlb64">^</a></strong></sup></span><div class="footnote-content"><p> Note that this is <a href="https://www.psychologytoday.com/intl/blog/be-your-best/202204/whats-the-real-deficit-in-adhd">not a <i>deficit</i> of attention</a> . It is a difficulty <i>controlling</i> where attention is allocated.</p><p> I&#39;ve always really liked the <a href="https://en.wikipedia.org/wiki/Visual_spatial_attention#Spotlight_metaphor">spotlight metaphor</a> for attention. With this metaphor, the spotlight is not dimmed. It&#39;s just more focused and harder to move.</p></div></li><li class="footnote-item" role="doc-endnote" id="fncalstl3kzju"> <span class="footnote-back-link"><sup><strong><a href="#fnrefcalstl3kzju">^</a></strong></sup></span><div class="footnote-content"><p> Which is one of the reasons why I don&#39;t drive.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn71yorfxj697"> <span class="footnote-back-link"><sup><strong><a href="#fnref71yorfxj697">^</a></strong></sup></span><div class="footnote-content"><p> For example, I had this teacher for a class called &quot;Research&quot; or something. I thought the things he taught us were incredibly dumb. One thing I remember is how he spent a lot of time emphasizing how you have to underline some things in one color and other things in another color. As opposed to, y&#39;know, the actually important principles of scientific research, a la Richard Feynman.</p><p> So I played a bunch of pranks. One time I put a piece of scotch tape under the computer mouse to interfere with the laser motion detector thing. Another time I broke off a piece of my lead pencil&#39;s tip in the door&#39;s lock so that it couldn&#39;t be opened.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnk7en98cp9t"> <span class="footnote-back-link"><sup><strong><a href="#fnrefk7en98cp9t">^</a></strong></sup></span><div class="footnote-content"><p> I would lightly bite the inside of my left cheek in a way that caused my face to scrunch up a bit. It always seemed incredibly minor to me, but moderate to my parents and the doctors. I don&#39;t really remember the kids in school ever teasing me about it, or even pointing it out.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnf8b7bmfomun"> <span class="footnote-back-link"><sup><strong><a href="#fnreff8b7bmfomun">^</a></strong></sup></span><div class="footnote-content"><p> That&#39;s not really the best word, but I&#39;m not sure what a better word would be.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnts8mvi2bp6n"> <span class="footnote-back-link"><sup><strong><a href="#fnrefts8mvi2bp6n">^</a></strong></sup></span><div class="footnote-content"><p> <code>faithInTheMedicalSystem--</code></p></div></li><li class="footnote-item" role="doc-endnote" id="fnxy1ey1ogs6i"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxy1ey1ogs6i">^</a></strong></sup></span><div class="footnote-content"><p> Actually, I&#39;m not sure how true this is. I remember hearing something along these lines, but I may be misremembering and/or straw-manning. I think what I&#39;m remembering is something related to the philosophy of <a href="https://en.wikipedia.org/wiki/Rationalism">rationalism</a> and how it stands in contrast to the philosophy of empiricism.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnj06vqnxu2wa"> <span class="footnote-back-link"><sup><strong><a href="#fnrefj06vqnxu2wa">^</a></strong></sup></span><div class="footnote-content"><p> I really like how <a href="https://hpmor.com/chapter/1">chapter 1 of HPMoR</a> explores this. Maybe Eliezer decided to discuss empiricism in the first chapter because empiricism is so foundational to rationality.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnw0qvxpfza3n"> <span class="footnote-back-link"><sup><strong><a href="#fnrefw0qvxpfza3n">^</a></strong></sup></span><div class="footnote-content"><p> <a href="https://www.lesswrong.com/posts/fFY2HeC9i2Tx8FEnK/luck-based-medicine-my-resentful-story-of-becoming-a-medical">Luck Based Medicine</a> is probably relevant. Even if various treatments are non-standard and uncommon, who knows, maybe they&#39;ll work for you. If it&#39;s cheap to try, why not give it a shot?</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/cbfiXhEXfvZRHAzNC/experiments-as-a-third-alternative#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/cbfiXhEXfvZRHAzNC/experiments-as-a-third-alternative<guid ispermalink="false"> cbfiXhEXfvZRHAzNC</guid><dc:creator><![CDATA[Adam Zerner]]></dc:creator><pubDate> Sun, 29 Oct 2023 00:39:31 GMT</pubDate> </item><item><title><![CDATA[Comparing representation vectors between llama 2 base and chat]]></title><description><![CDATA[Published on October 28, 2023 10:54 PM GMT<br/><br/><p> <i>(Status: rough writeup of an experiment I did today that I thought was somewhat interesting - there is more to investigate here regarding how RLHF affects these concept representations)</i></p><p> This post presents the results of some experiments I ran to:</p><ul><li> Extract representation vectors of high-level concepts from models</li><li> Compare the representations extracted from a base model (Llama 2 7B) and chat model trained using RLHF (Llama 2 7B Chat)</li><li> Compare the representations between different layers of the same model</li></ul><p> <i>Code for the experiments is available</i> <a href="https://github.com/nrimsky/ActivationDirectionAnalysis"><i>here</i></a> <i>.</i></p><p> To extract the representation vectors, I apply the technique described in my <a href="https://www.lesswrong.com/posts/raoeNarFYCxxyKAop/modulating-sycophancy-in-an-rlhf-model-via-activation">previous</a> <a href="https://www.lesswrong.com/posts/zt6hRsDE84HeBKh7E/reducing-sycophancy-and-improving-honesty-via-activation">posts</a> on activation steering to modulate sycophancy <span class="footnote-reference" role="doc-noteref" id="fnrefqowaqlr9u98"><sup><a href="#fnqowaqlr9u98">[1]</a></sup></span> . Namely, I take a dataset of multiple-choice questions related to a behavior and, for each question, do forward passes with two contrastive examples - one where the model selects the answer corresponding to the behavior in question and one where it doesn&#39;t. I then take the mean difference in residual stream activations at some layer at the token position corresponding to the different answers.</p><p> Besides sycophancy, which I previously investigated, I also use other behavioral datasets such as agreeableness, survival instinct, and power-seeking. Multiple-choice questions for these behaviors are obtained from Anthropic&#39;s model-written-evals <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label=""><span class="mjx-mrow" aria-hidden="true"></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>datasets, <a href="https://huggingface.co/datasets/Anthropic/model-written-evals">available on huggingface</a> .</p><h1> Observation 1: Similarity between representation vectors from chat and base model shows double descent</h1><p> At first, similarity declines from very similar (cosine similarity near 1) to halfway towards the minimum, and then for some behaviors, climbs up to ~0.9 again, around layer 11. </p><figure class="image image_resized" style="width:84.94%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/vxd487yah6zncizzuonl" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/kwxhsnyknjfe7ixn9vzf 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/nn6ffrggfobtwagnbqxb 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/qh4mwwvqd2r1ray2oxko 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/tkry1k3khvy1uqklnyuu 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/te6aozxy4tdzrvupt3gf 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/sfl72bfjnuqowlhj96kt 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/avkn5cxqdo9qhueoh8ld 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/hgi8cokckd73q2mvimg0 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/cx4fcztivgw45tmzu7js 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/kpuxvylip1ohbagjvwav 1000w"></figure><p> The following chart is generated from a higher-quality sycophancy dataset that includes some multiple-choice questions generated by GPT-4: </p><figure class="image image_resized" style="width:80.05%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/ojhzzrph7xjq1lr6p7hb" alt="图像"></figure><p> PCA of the generated vectors also shows the representations diverge around layer 11: </p><figure class="image image_resized" style="width:68.76%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/cywvvfoiej7fin5amtwr" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/bids7qpajbagpwllpiq5 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/es9xz1hyxpxajjku41bv 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/fm2qktimypjbcxf2rniz 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/t5bqi0vb1iwbra0uyyqi 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/on9ot4627v00xjoik6rx 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/jaq3mbewcb4s6yscu5kc 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/afw6lvtpv7wjro272tnm 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/x5pn5mhrybvsaiuwnjie 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/xv7y3kavtzcxu1rauaxa 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/d0omqg9ilaqko5rbe6di 1000w"><figcaption> 2D PCA projection of self-awareness representation vectors extracted from Llama 2 7B Chat and base models </figcaption></figure><figure class="image image_resized" style="width:71.73%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/ltragux0bkwzccerrrfz" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/fyflzebfan46ski4jjd2 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/psoakjdf2voj4g1usvtx 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/zggxdathgxfqjdmc1t6f 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/rnrlyyyygcmgta2m9qsu 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/rssg2eopkkgwwlu3o9nv 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/wh826zcifpgakplfauni 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/x4m0kmnk27b2lqdwm8pe 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/ynsvepufiw2zeaakqgs6 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/pq8krfdh56t5lbf11s2r 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/jtvyuva9tv0oxjux5ogb 1000w"><figcaption> 2D PCA projection of myopia representation vectors extracted from Llama 2 7B Chat and base models</figcaption></figure><h1> Observation 2: Vectors vary more smoothly after around layer 11 for all behaviors/models</h1><p> I hypothesize that once the model extracts the high-level information needed to describe an abstract concept, the representation &quot;converges&quot; and remains more consistent across subsequent layers. </p><figure class="image image_resized" style="width:81.13%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/u5q67vkzx3qdb7arfbq3" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/emk5xh5zfgccjsd2o6zw 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/qi9wt6q8ck4tzrbfwybh 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/qepni6wnttetjyf59sqs 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/ndiruvqqal4vqnghyred 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/dofnaawhonts46asoz3l 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/arwtbwnhafzrldkcxmxz 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/pftpeuzxwnbtmbcdhrto 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/hcaiazughc1bdbhccuck 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/sbwhikear9bh1frd56tt 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/xrryalx0hr8p9qe7rdaj 1000w"><figcaption> Heatmap of cosine similarity of &quot;myopia&quot; representation vector extracted from different layers of Llama 2 7B base model. We can see nearby layers are more similar in the last 2/3 of the model but not in the first 1/3. </figcaption></figure><figure class="image image_resized" style="width:79.41%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/elhl2ifwscmj7fohhjqo" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/n3s1cczcbims4smardws 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/yqlc4icsymafcn3xaw5a 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/mezzwnu1tofb0pzv8ytg 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/n9a9fcutvpp2df1nacwo 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/cheimwl19w4fzu1xtcqg 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/qcxls9na8mbsp6oaybwq 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/dtuitkzb2teu4cxfblso 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/gzrthicsihxwouewfn4k 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/dwbmexzmyprtyevihqg8 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/jhwxut7hezeanigkz3e0 1000w"><figcaption> Heatmap of cosine similarity of &quot;self-awareness&quot; representation vector extracted from different layers of Llama 2 7B Chat model. This shows a similar trend to the other representation vectors / base model.</figcaption></figure><h1> Observation 3: PCA projections of vectors generated from different layers of the same model often look like a U </h1><figure class="image image_resized" style="width:43.07%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/iintyi6gsnjd11idvp2a" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/phgeqy0vu3b7vw2f4uke 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/tsxwtbvealescdgxades 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/yoeuuvk3ytoygbfygdsl 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/esiivj0q4br9xc63u2c0 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/zn67jag3dkclynq4uai4 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/xuuzlkn13b2myoq4zezw 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/tgv1czkgyfwuqrzjh4he 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/igusgifqw3acht877tsf 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/oz7kkw2obzjeomansotp 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/vnshxwrpanym7apxrbrh 1097w"></figure><figure class="image image_resized" style="width:43.61%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/ckxuz6sqy88jebhn6etk" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/lk6h5cfgnazl9rtqq34s 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/ld4imlhb5gdwcpyepybr 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/cnonsads7vjfidd1zfc4 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/tmnirn7o7xfakan7aviz 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/i1j7hjepnkngzxy4iau5 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/lxmyz2umrptcj2fetlo7 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/elfwxgtb1meu1xe3widx 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/agxwvdw5onqbstmpma8i 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/eknbdzwca4viym45nblg 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/ztvnn3xfgje6zo2gy2jr 1101w"></figure><figure class="image image_resized" style="width:45.04%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/tilirj9mpy59py77jicm" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/zde2i36qkmzzwjo9oyfe 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/awarqhjnl1y4fnf9aktt 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/dsbzhxwxehqjvfsbkmlu 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/a6gtqo9lt1kkv6zh3atn 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/si6vqw6ftshgag8vx4or 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/kiqcymamobpuqunzcizw 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/kd4kuwmtxiolhicqaxu5 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/wgvrowmmvn1em7iw6mck 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/scgww7zz6zsqxqwyuzlq 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PDDG4uuCLpPsuKepY/lv7o8xdb34bwaefyasev 1085w"></figure><p> Vectors from layers &lt;11 basically project to the same point. The remaining projected vectors follow a rough U-shape.</p><p> It&#39;d be interesting to investigate what these principal components actually correspond to in activation space. </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnqowaqlr9u98"> <span class="footnote-back-link"><sup><strong><a href="#fnrefqowaqlr9u98">^</a></strong></sup></span><div class="footnote-content"><p> Similar techniques were applied by Annah Dombrowski and Shashwat Goel in their project to <a href="https://www.lesswrong.com/posts/JCgs7jGEvritqFLfR/evaluating-hidden-directions-on-the-utility-dataset">evaluate hidden directions on the utility dataset</a> and by Nick Gabrieli and Julien Schulz in their SERI MATS project. See also this recent <a href="https://arxiv.org/pdf/2310.01405.pdf">paper on &quot;Representation Engineering&quot;</a> and Alex Turner&#39;s work on <a href="https://arxiv.org/abs/2308.10248">Activation Additions</a> , which inspired my activation vector extraction approach.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/PDDG4uuCLpPsuKepY/comparing-representation-vectors-between-llama-2-base-and#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/PDDG4uuCLpPsuKepY/comparing-representation-vectors-between-llama-2-base-and<guid ispermalink="false"> PDDG4uuCLpPsuKepY</guid><dc:creator><![CDATA[Nina Rimsky]]></dc:creator><pubDate> Sat, 28 Oct 2023 22:54:37 GMT</pubDate> </item><item><title><![CDATA[Vaniver's thoughts on Anthropic's RSP]]></title><description><![CDATA[Published on October 28, 2023 9:06 PM GMT<br/><br/><p><a href="https://www.anthropic.com/index/anthropics-responsible-scaling-policy">公告</a>，<a href="https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf">政策v1.0</a> ， <a href="https://www.lesswrong.com/posts/mcnWZBnbeDz7KKtjJ/rsps-are-pauses-done-right">evhub的论点支持LW</a> 。这些是我个人的想法；为了充分披露，我的一位室友和我的几个朋友在 Anthropic 工作；我和我的配偶持有 OpenAI 单位（但没有它们在财务上是安全的）。这篇文章分为三个主要部分：对做得正确的事情的掌声、对 RSP 的总体总结/回顾，以及对 Anthropic 的 RSP 需要改进的具体批评和建议。</p><p>首先，值得鼓掌的事情。 Anthropic 的 RSP 做出两项重要承诺：他们将管理财务以允许在必要时暂停，并且有一个直接负责的个人来确保履行承诺并做出季度报告。这两件事都代表了真正的组织承诺，而不是口头上的承诺。我认为公司公开他们正在采取哪些预防措施来确保先进人工智能的发展造福人类是一件好事，即使我认为这些政策并不完全令人满意。</p><p></p><p>二、解释。按照生物安全级别模型，实验室必须满足定义的标准才能处理特定的危险病原体，Anthropic 建议人工智能安全级别（ASL），以及处理危险模型的实验室的相应标准。虽然 BSL 的制造商可以列出每个级别中填充的特定病原体，但 ASL 级别必然是推测性的。前几代模型是 ASL-1（BSL-1 对应于健康成年人没有感染威胁），当前模型如 Claude 算作 ASL-2（BSL-2 对应于中度健康危害，如 HIV），下一层模型大幅提高灾难性风险基线水平或能够自主的模型，算作 ASL-3（BSL-3 对应潜在致命的吸入性疾病，如 SARS-CoV-1 和 2）。</p><p>虽然 BSL 最高为 4，但 ASL 目前不受限制，并承诺在使用 ASL-3 模型之前定义 ASL-4。 <span class="footnote-reference" role="doc-noteref" id="fnref8a91p1iilp7"><sup><a href="#fn8a91p1iilp7">[1]</a></sup></span>这意味着对需要增加各级安全实践投资的能力有一个明确的上限，同时不要对人工智能开发将如何进行进行太多的纸上谈兵。</p><p> RSP 背后的想法是，不是在任意开始日期暂停任意时间（或简单地<a href="https://intelligence.org/2023/04/07/pausing-ai-developments-isnt-enough-we-need-to-shut-it-all-down/"><u>将其全部关闭</u></a>），而是使用功能阈值来确定何时开始特定于模型的暂停，并使用安全阈值来确定何时启动特定于模型的暂停。确定何时取消暂停该模型的开发。 RSP 旨在要求积极努力确定模型是否能够造成灾难性伤害，而不是简单地盲目开发它们。它们似乎<i>比没有</i>RSP 或同等产品的扩展要好得多。</p><p><br>第三，为什么我对Anthropic的RSP还不满意？批评和建议的重要性大致按降序排列：</p><ol><li> RSP 的核心假设是模型功能可以提前预测，也可以在部署前通过专门测试发现。测试只能证明能力的存在，而不能证明能力的不存在，但这种方法依赖于缺乏证据来证明其不存在的证据。我认为能力可能会在未知的时间<a href="https://intelligence.org/2022/07/04/a-central-ai-alignment-problem/">突然出现</a>。 Anthropic 的方法要求以特定的速率进行缩放，以降低这种突然出现的可能性；我还不相信他们的利率足以应对这里的风险。寻找这些功能仍然比不寻找要好，但部署前测试不足以保证持续的安全。 <span class="footnote-reference" role="doc-noteref" id="fnrefadlb4wagn48"><sup><a href="#fnadlb4wagn48">[2]</a></sup></span>我认为 RSP 可以对 ASL-2 阶段的部署后监控做出更多承诺，以确保它仍然算作 ASL-2。</li><li>这也反映在测试<i>之前</i>而不是测试<i>之后</i>对模型进行分类。 RSP 以不同的方式对待 ASL-2 模型和 ASL-3 模型，为 ASL-3 实验室制定了更严格的安全标准，以使使用 ASL-3 模型更安全。然而，在测试模型之前，并不清楚它应该属于哪个类别，RSP 也不清楚如何处理这种模糊性。虽然假设它们是 ASL-2 更方便（因为前沿实验室可以继续以大约当前的安全水平进行扩展研究），但假设它们是 ASL-3 更安全。当红队工作确定某个模型能够在互联网上自我扩散，或者能够引发灾难性的恐怖袭击时，即使立即停止训练并延迟部署，也可能为时已晚，无法正确保护该模型。 [A lab not hardened against terrorist infiltration might leak that it has an ASL-3 model <i>when it triggers the pause to secure</i> , which then potentially allows for the model to be stolen.]</li><li>模型提供的信息风险基线的选择是搜索引擎上的可用性。虽然这对负责任的参与者来说是有限的，但似乎很容易规避。 RSP 已经将其他先进的人工智能系统排除在基线之外，但在我看来，静态基线（例如 2021 年搜索引擎上可用的基线）将更难绕过。 <span class="footnote-reference" role="doc-noteref" id="fnref80lzthzwbtn"><sup><a href="#fn80lzthzwbtn">[3]</a></sup></span></li><li>重要的是，在我看来，这种方法最初可能会很好地发挥作用，但当模型变得足够强大，有可能剥夺人类的能力时，它的效果可能与它的效果并不相符。也就是说，这可能会成功管理从 ASL-2 到 ASL-3 的转换，但对于从 ASL-3 到 ASL-4 的转换没有用，同时错误地给我们留下系统正在运行的印象。 RSP 计划在机车前面铺设轨道，期望我们能够预见如何测试危险能力并确定如何根据需要确保它们的安全，或者在我们无法做到这一点时有智慧在未来叫停。</li></ol><p>总的来说，这对我来说就像是朝着充分性迈出的一步，奖励这些举措是件好事。我很欣赏 Anthropic 的 RSP 给人一种正在进行中的感觉，而不是被认为已经足以完成任务。 <br></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn8a91p1iilp7"> <span class="footnote-back-link"><sup><strong><a href="#fnref8a91p1iilp7">^</a></strong></sup></span><div class="footnote-content"><p> BSL-4 疾病与 BSL-3 疾病具有基本相同的特征，只是也没有可用的疫苗或治疗方法。此外，所有外星样本默认都是 BSL-4，其标准比任何当前 BSL-4 实验室所能达到的标准都要严格。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnadlb4wagn48"> <span class="footnote-back-link"><sup><strong><a href="#fnrefadlb4wagn48">^</a></strong></sup></span><div class="footnote-content"><p>隐含的信念是模型能力主要来自缩放期间的训练，并且我们的缩放定律（以及各种其他事物）足以预测模型能力。如何部署模型的进步可能会打破这一点；正如缩放定律无法预测能力一样。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn80lzthzwbtn"> <span class="footnote-back-link"><sup><strong><a href="#fnref80lzthzwbtn">^</a></strong></sup></span><div class="footnote-content"><p>它确实有一些便利成本——例如，如果基线设定在 2019 年，那么该模型可能无法谈论冠状病毒，即使人工智能的发展和大流行是独立的。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/SseoT9mKDTL3RCbE9/vaniver-s-thoughts-on-anthropic-s-rsp#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/SseoT9mKDTL3RCbE9/vaniver-s-thoughts-on-anthropic-s-rsp<guid ispermalink="false"> SseoT9mKDTL3RCbE9</guid><dc:creator><![CDATA[Vaniver]]></dc:creator><pubDate> Sat, 28 Oct 2023 21:06:08 GMT</pubDate> </item><item><title><![CDATA[Book Review: Orality and Literacy: The Technologizing of the Word ]]></title><description><![CDATA[Published on October 28, 2023 8:12 PM GMT<br/><br/><p><i>感谢 Diarmuid Morgan 审阅本文的早期版本。</i></p><blockquote><p><i>在这个新的事实领域，梦想取消了梦想</i><br><i>我们从中醒来，进入了行动的梦想</i><span class="footnote-reference" role="doc-noteref" id="fnrefp4f0zcv79"><sup><a href="#fnp4f0zcv79">[1]</a></sup></span></p></blockquote><p><a href="https://monoskop.org/images/d/db/Ong_Walter_J_Orality_and_Literacy_2nd_ed.pdf">口语和读写能力回顾：单词的技术化</a>，<a href="https://en.wikipedia.org/wiki/Walter_J._Ong">沃尔特·J·翁 (Walter J. Ong)</a>着，1982 年</p><p>我一直在寻找“meme”的更丰富的定义，希望找到一些可以用来理解机器学习当前事件的东西，以及与每一个重大机器学习突破密切相关的意识的共同进化理解。天。</p><p>我还没有找到它，但我正在取得进展。在总结我的总体进展之前，我将回顾一下我在此过程中偶然发现的一些最有趣且最不受重视的作品。</p><h2> LW简介</h2><p>广泛地在“模因”主题下，但远远超出了范围，甚至没有出现在维基百科的文章中，尽管如此，我发现这本书对这个词的本质及其与思想的关系比大多数论文有更多的见解和价值我读过模因学。</p><p>我想象这样的工作（通常也称为模因）最终会在法学硕士上构建的可解释性堆栈的顶部附近结束。至少作为一种将面向公众的话语与技术细节结合起来的方式，最好的情况是作为一门定量学科（符号物理学，有人吗？）。</p><h2> EA 简介<span class="footnote-reference" role="doc-noteref" id="fnrefpfpxc9ek1vp"><sup><a href="#fnpfpxc9ek1vp">[2]</a></sup></span></h2><p>鉴于重新思考动物福利优先<a href="https://forum.effectivealtruism.org/s/y5n47MfgrKvTLE3pw">事项正在进行的工作</a>，在我看来，迫切需要超越享乐主义的量化福利方法<span class="footnote-reference" role="doc-noteref" id="fnref1y3wckk65i2"><sup><a href="#fn1y3wckk65i2">[3]</a></sup></span> 。我认为模因学总体上有潜力对此做出贡献，尤其是这项工作是一个很好的起点——它以定量和可测试的方式讨论了人类意识本质的相当大的变化。</p><p>我也认为这样的工作将有助于在直观的层面上厘清动物福利、人工智能福利和人类福利之间的界限。 （提示：想象一下这些不同的实体将被放置在具有两个轴“模因强度”和“享乐效价”的图表上。）</p><h1>背景</h1><p>我是在一次有关我们正在进入“第二口头文化”的可能性的不和谐对话中被介绍到这个主题领域的，这是一个高度口头文化的时期，与文化长期赖以生存的文字基础脱节。</p><p>这方面的一些证据：</p><ul><li>在年轻一代中，tictok 和 Instagram 比 Twitter 更受欢迎</li><li>作为一种消遣方式，Netflix 比书籍更受大家欢迎？</li><li><a href="https://www.insidehighered.com/blogs/higher-ed-gamma/literacy-declining">识字率下降</a></li></ul><p>社交媒体的兴起似乎足以证明二次口头传播<span class="footnote-reference" role="doc-noteref" id="fnrefdf0364kg9df"><sup><a href="#fndf0364kg9df">[4]</a></sup></span> 。</p><p> （<a href="https://xkcd.com/1414/">正如我们将看到的，这绝对不是一件坏事！</a> ）</p><p>或者更确切地说，是为了寻找二次口头语言日益占主导地位的证据。这个想法<a href="https://en.wikipedia.org/wiki/Marshall_McLuhan">在六十年代的广播和电视中就已提出</a>——这并不是什么新鲜事<span class="footnote-reference" role="doc-noteref" id="fnrefxo732zi1ol"><sup><a href="#fnxo732zi1ol">[5]</a></sup></span> 。事实上，口头语言从未真正离开我们，而且出于末世论的原因，理解口头语言和读写能力之间相互作用的动态似乎可能会有所帮助。</p><h1>评价</h1><blockquote><p>“‘文本’的词根意思是‘编织’，从绝对意义上来说，它在词源学上比‘文学’更符合口头表达，‘文学’指的是字母表中的字母/（文学）。口头话语通常是即使在口头环境中也被认为是编织或缝合 - <i>rhapsoidein</i> ，“rhapsodize”，在希腊语中基本上意味着“将歌曲缝合在一起”。 <span class="footnote-reference" role="doc-noteref" id="fnref1jnh1d5t813"><sup><a href="#fn1jnh1d5t813">[6]</a></sup></span> “</p></blockquote><h2>第 1 部分：口述及其发现</h2><p>什么是口语？这就是言语文化。我们都经历过。这是脱口秀和广播的文化，是与朋友深夜交谈的文化，是与陌生人在酒吧聊天的文化，也是讨论和辩论的文化。</p><p>但在日常经验中，大多数口头文化将是<i>次要的口头文化</i>。这是一种由文化程度高的人制作的口语，他们甚至可能事先写下了他们所说的部分内容（甚至在脱口秀节目中！）</p><p>在西方文化中，直到 20 世纪 30 年代，<i>原始口头语言</i>的概念才被认真考虑，当时米尔曼·帕里 (Milman Parry) 提出了一个解决当时已有数百年历史的荷马问题<span class="footnote-reference" role="doc-noteref" id="fnrefy6dwuwe10m"><sup><a href="#fny6dwuwe10m">[7] 的方法</a></sup></span>。</p><p>本书的前两章介绍了这些材料。我现在不会再讲这个问题，但请拿走以下内容——荷马问题的几个世纪之久的谜题的总结和解决方案：</p><blockquote><p>荷马有着明显超人的诗歌壮举，在希腊文明顶峰的<a href="https://en.wikipedia.org/wiki/Aeneid">800</a>年里无人能敌，因为他的文化主要以诗歌来表达，他是在诗歌中长大、思考和交流的。他不会写作，但在文字发明后，他的作品被抄写员抄写（经过一些修改）。文字的发明改变了人类教育、社会和意识的本质，足以使数百年来无人能敌<span class="footnote-reference" role="doc-noteref" id="fnrefj87l30lnxfh"><sup><a href="#fnj87l30lnxfh">[8]</a></sup></span>他的作品。</p></blockquote><p>研究这种转变不仅可以为我们提供关于意识本质的线索，还可以为我们提供在快速技术变革下意识如何变化、失去什么和获得什么的线索。</p><h2>第二部分：口腔心理动力学</h2><blockquote><p>“当水牛完全没有生命，甚至死了时，猎人可以看到水牛，闻到水牛的味道，尝到水牛的味道，并触摸水牛，但如果他听到水牛的声音，他最好要小心：有事情发生了。从这个意义上说，所有声音，尤其是来自生物体内部的口头表达，是‘动态的’。”</p></blockquote><p>接下来的章节将讨论<i>初级口语</i>中意识的本质。他们首先讨论说话的<i>行为</i>及其动态本质：“所有感觉都发生在时间中，但声音与时间有着特殊的关系，这与人类感觉中记录的其他领域不同。声音只有在从声音中传出时才存在。它不仅是易逝的，而且本质上是转瞬即逝的，而且它被感觉为转瞬即逝的。”</p><p>我认为关于声音本质及其与单词关系的亲密材料可能会非常重要——这里的某个地方有一个用于研究模因的底层，最终你会得到<a href="https://www.sciencedirect.com/science/article/abs/pii/S0376635700001054?via%3Dihub">直接映射到声音的声音。现实世界的物体</a>、动作和事件。但当我们开始识字时，语言已经建立了抽象的第一个基础，所以我们看不到这里详细说明的进化过程。</p><p>然而，随着我们对史前史的了解不断完善（通过考古证据的不断增加），我们希望有一天能够绘制出这一发展的图表。为了从这个日益细化的数据集中梳理出连贯的叙述，有必要对本书（以及我在下面<a href="https://www.lesswrong.com/editPost?postId=ThST9njmesR9BkoWq#Further_Reading">进一步阅读</a>中链接的另一本书）的细节进行关注<span class="footnote-reference" role="doc-noteref" id="fnref22vcjsal3mr"><sup><a href="#fn22vcjsal3mr">[9]</a></sup></span> 。</p><p>在讨论了这个词的躯体、动态本质之后，本书接着讨论了语言如何塑造思想的具体例子。<a href="https://en.wikipedia.org/wiki/Orality#Theory_of_the_characteristics_of_oral_culture">这里</a>总结了关于思想心理动力学的完整章节，因此我只强调其中的几个例子。</p><h3>助记符</h3><blockquote><p>“你怎么能回想起你费尽心力想出来的东西呢？唯一的答案是：思考令人难忘的想法。在初级口头文化中，为了有效地解决保留和检索仔细表达的思想的问题，你必须做你自己的事情。”以助记模式思考，为准备口头复现而设计。”</p></blockquote><p>这基本上解释了这首诗。但这个事实以及这首诗的事实实际上是这本书中至关重要的要点：</p><ol><li>作为美学的助记符：为什么所有思想都令人难忘的这一要求会产生如此优秀的诗歌？对今天有什么影响？对人类福祉的未来有何影响？如果情况恰恰相反——没有人必须记住任何事情，一切都可以用一系列事实陈述来描述<span class="footnote-reference" role="doc-noteref" id="fnrefs8bjo675mpm"><sup><a href="#fns8bjo675mpm">[10]，</a></sup></span>那又怎么样呢？这会是艺术的终结吗？我们愿意生活在这个世界上吗？</li><li>记忆是人类知识的总和：正如在接下来的章节中详细讨论的，所有人类知识都必须被记住这一事实意味着我们可以对人类知识的总和进行猜测——它受到<i>一个群体中人类数量的</i>限制。<i>文化</i>x<i>人类可以记忆的数量</i>。记住<a href="https://en.wikipedia.org/wiki/Dunbar%27s_number">邓巴的数字</a>——似乎可以对荷马时代人类上下文窗口的大小进行近似猜测。</li></ol><h3>加法而不是从属</h3><p>因为信息在口头文化中从你身边飞驰而过，所以最好将其分成可以单独处理的块，而不是复杂的连续句子，让你直到最后一个词才知道作者指的是什么。附有圣经翻译插图：</p><p>口语风格：</p><blockquote><p> “起初，上帝创造了天地。大地是空虚的，渊面黑暗；上帝的灵运行在水面上。上帝说……”</p></blockquote><p>文学风格：</p><blockquote><p> “起初，上帝创造天地时，大地是一片无形的荒原，黑暗笼罩着深渊，狂风席卷水面。然后上帝说……”</p></blockquote><p>在新版本中，“and”被翻译为“and”、“when”、“then”、“thus”或“while”。这些话对我们有什么作用？我们会回到这一点，但本质上他们是在段落的主要意义之上构建一个独立的建筑——这种建筑是我们作为识字者遗产的一部分。口头文化没有它。</p><h3>多余的</h3><p>有几段文章讨论了本质上处理冗余的语言特性。例如：“口头上的民间，特别是在正式话语中，更喜欢的不是士兵，而是勇敢的士兵；不是公主，而是美丽的公主；不是橡树，而是坚固的橡树。”</p><p>如今，我们会说它们提供了嵌入空间中接近的冗余单词，以帮助引导我们获得正确的含义。这一特征，再加上口语文化的其他一些特征，可以帮助您在嵌入空间中定位，并提供冗余，防止听错某个语音部分或仅仅误解一个单词。</p><p>本质上，它们是有损通信形式的解决方法。这是我想挑选并强调的第一个例子：</p><blockquote><p>不同时间点的许多语言特征似乎都包含技术解决方法，旨在适应有损的沟通方式和环境的持续干预。这些技术解决方法不仅仅是演说家学习的<i>技巧</i>（按照希腊语，后来重点关注修辞学和诡辩术​​），而且是构建在他们的意识经验基础上的思维模式。</p></blockquote><h3>保守和体内平衡</h3><p>例如，有两个“心理动力学”部分似乎是当代通信技术本质的<i>结果</i>：</p><blockquote><p> “由于在初级口头文化中，不被大声重复的概念化知识很快就会消失，口头社会必须投入巨大的精力，一遍又一遍地说出多年来艰苦学习的内容。这种需要建立了一种高度传统主义或保守的心态，有充分理由抑制智力实验。”</p></blockquote><p>思考这个问题的一种方法是类比晶体管。晶体管中的信息通过不断运行的电流的紧密电路保持活力。在此之前，知识是通过人们印刷书籍来保持活力的。在此之前，人们用手抄写书籍。在此之前，知识在<i>表现</i>中必须保持在<i>自我交流</i>的活跃循环中。不管抄一本书有多难，我认为它比背诵和表演一首 24 小时的长诗要容易<span class="footnote-reference" role="doc-noteref" id="fnrefc38y6zkuhco"><sup><a href="#fnc38y6zkuhco">[11]</a></sup></span> 。很明显，维持一个信息单位（或<i>模因</i>）所需的物质和能源数量一直在下降。但随着物质信息密度的增加，个体的信息内容会发生什么变化呢？</p><p>这种“疲惫的保守主义”的另一面是体内平衡。让 Ong 描述一下：</p><blockquote><p> “口头社会很大程度上生活在当下，通过抛弃不再与当下相关的记忆来保持自身平衡或动态平衡……口头文化当然没有词典，也很少有语义差异。每个单词的含义都由……控制。 ..“直接语义批准”，即通过此时此地使用该词的现实生活情况。</p><p>当几代人过去，这个古老词语所指的对象或机构不再是现在的生活经验的一部分时……它的含义通常会改变或干脆消失。”</p></blockquote><p>这是最有趣的一个。集体语境窗口的内容与集体的生活现实保持平衡。环境根据其自身的规则而变化——集体记忆的内容必须改变以适应它。也就是说，<i>在他们控制信息的范围内，</i>集体可以是保守的，并且确实是出于积极的考虑而这样做的。相反，<i>如果他们无法控制环境变化，</i>集体就会改变他们的信息内容以适应环境。</p><p>这意味着，<i>不存在客观历史</i>。他们根本负担不起。相比之下，我们有数千年的历史记录，而且这个数量正在呈指数级增长（不仅因为时间在流逝，我们的记录设备更加准确，而且因为我们用更高保真度的技术来调查过去）。</p><p>这对知识本质的巨大改变怎么强调都不为过。在口头文化中，知识经过筛选和解释，以维持有限数量的立即有用的知识。为了获得同龄人直接记忆之外的任何知识，你必须搬到世界的另一个地方，并可能学习一门新的语言，这意味着所有的危险。然后，您需要记住所有文化中最重要的史诗，以便能够利用您在那里找到的任何新知识！</p><p>本书花费了大量精力来阐明人类文化和意识在文字发明之前有多么不同。请花点时间考虑一下您是否认为法学硕士的发明将具有类似或更大的意义。再想一想，我们也在一个世纪前发明了电影和摄影！亲爱的哦亲爱的。</p><h2>第三部分：识字的心理动力学</h2><blockquote><p>“如果没有写作，人类意识就无法发挥其更充分的潜力，无法产生其他美丽而强大的创造。从这个意义上说，口头语言需要产生并且注定会产生写作<span class="footnote-reference" role="doc-noteref" id="fnref3gv21pqgu2n"><sup><a href="#fn3gv21pqgu2n">[12]</a></sup></span> 。正如我们将看到的，识字对于人类来说是绝对必要的。不仅是科学的发展，而且是历史、哲学、对文学和任何艺术的解释性理解的发展，甚至是对语言（包括口头言语）本身的解释的发展<span class="footnote-reference" role="doc-noteref" id="fnref0of1110erqd"><sup><a href="#fn0of1110erqd">[13]</a></sup></span> 。几乎不存在口头文化或占主导地位的口头文化当今世界，人们并没有意识到，如果没有识字能力，就永远无法获得巨大而复杂的权力。这种认识对于植根于初级口头语言的人来说是一种痛苦，他们热切地想要识字，但也非常清楚，进入令人兴奋的识字世界意味着留下了许多早期口头世界中令人兴奋和深受喜爱的东西。我们必须死才能继续生活。”</p></blockquote><p>接下来的章节主要涵盖了读写能力的转变以及它对我们的思想产生的影响。作者本质上采用了米尔曼·帕里（Milman Parry）用于解决荷马问题的相同分析，并将其应用于整个历史上的技术变革时刻。请记住，帕里的工作现已被广泛接受为荷马问题的良好且可能真正的解决方案！文学批评<i>不一定</i>要被嗤之以鼻，这是本书的一个关键要点。</p><h3>逻辑</h3><p>第一件事情似乎是逻辑的发明：“希腊人在开发出第一个带有元音的字母表时，确实做了一些具有重大心理意义的事情……[这种]单词从声音到视觉的转变给了古代希腊文化在智力上优于其他古代文化”。也许在识字之前就存在类似逻辑的东西，但它似乎是一种完全不同的野兽。什么是逻辑？这是一个词，很明显。可以说它是一个算法或算法系列的名称。您应用于语言的算法。例如，考虑以下问题：</p><blockquote><p> “贵金属不会生锈。黄金是贵金属，它会生锈吗？”</p></blockquote><p>这里发生了什么？有一系列的说法。陈述 3 促使我们调查陈述 1 和陈述 2 寻找线索，我们可以将这些线索结合起来创建答案。这种算法是一种处理语言的反射性方式，是我之前所说的基于文本初级阅读的“独立架构”的一部分。</p><p>现在，想象一下您没有安装“逻辑”模因，并且您看到了此文本。像基本模型一样思考——你会继续做什么？也许是关于金属的一些节奏和诗意——“贵金属生锈，贵金生锈”？或者你认为这个游戏是在编有关金属的谜语——“贵金属会生锈吗？”黄金会生锈吗？嗯，这些确切的反应是文盲农民在听到这一系列陈述时给出的。 （参见“情境而不是抽象”部分。）</p><h3>自主话语</h3><p>该话语与人类表演者无关！我们不再需要担心那些无聊的<i>人身攻击</i>混淆（你不会听说过这些，<i>口头</i>文化所做的是一件愚蠢的事情——不用担心）。</p><p>抛开笑话不谈，识字能力让“意义”拥有了自己的生命，独立于它所传达的语境：“口头语言将意义很大程度上归咎于语境，而写作则将意义集中在语言本身”。这将在下面更详细地讨论。</p><h3>时间与历史</h3><p>今天，精通英语的人“不仅可以与数百万人建立轻松的联系，而且还可以与过去几个世纪的思想建立轻松的联系，因为英语的其他方言以及数千种外语都得到了解释”。正如我们在上面所看到的，稳态文化没有能力记录所有历史事件的客观清单。当然，这些事件在塑造模因复合体、史诗和文化知识方面发挥了作用。但它们只能通过直觉和艺术间接获得。 “在写作被印刷品深深地内化之前，人们并不觉得自己生活中的每一刻都处于任何形式的抽象计算时间中。”</p><h3>词汇</h3><p>英语“带有数以百万计的思想的印记，他们用它来相互分享他们的意识。其中蕴藏着大量的词汇，其数量级是口语所不可能的。”</p><p>我们能否估算出一段时间内总词汇量的大小？如果可以的话，它是否可以提供相关文化的总人类语境窗口的近似值？如果您查看像<a href="https://en.wikipedia.org/wiki/Byte_pair_encoding">byte-pair-encoding</a>这样的简单编码策略，由于其递归性质，词汇表中的单词可以被视为“标记”的大小没有上限。该限制由词汇表中的单词总数决定。随着人类语境窗口随着时间的推移而增加，随着信息量，或者只是它可以处理的词汇量的增加，越来越复杂的单词和想法是否有可能成为令牌，我们集体知识圈的基本元素？</p><h3>旁白：ChatGPT 上的柏拉图</h3><p>有趣的一面：</p><blockquote><p> “大多数人都感到惊讶，而且许多人感到苦恼，因为柏拉图在《斐德罗篇》（274-7）和《第七封信》中反对写作，而柏拉图在《斐德罗篇》（274-7）和《第七封信》中也提出了与今天普遍反对计算机的基本相同的反对意见。斐德罗，是非人性的，假装在心灵之外建立了实际上只能在心灵中存在的东西。它是一个东西，一个制成品。当然，计算机也是如此。其次，柏拉图的苏格拉底敦促说，写作会破坏记忆。那些使用书写的人会变得健忘，依靠外部资源来弥补他们内部资源所缺乏的东西。书写会削弱头脑。如今，父母和其他人担心袖珍计算器为本应记住乘法表的内部资源提供了外部资源.计算器削弱了头脑，减轻了它保持坚强的工作。第三，书面文本基本上没有反应。如果你要求一个人解释他或她的陈述，你可以获得解释；如果你要求一个人解释他或她的陈述，你可以得到解释；如果你问一条短信，除了最初提出你的问题的相同的、通常是愚蠢的词语之外，你什么也得不到。在现代对计算机的批评中，也提出了同样的反对意见：“垃圾输入，垃圾输出”。第四，与口头文化的竞争心态相一致，柏拉图笔下的苏格拉底也反对写作，认为书面文字无法像自然口语那样为自己辩护：真正的言语和思想本质上总是存在于双方之间相互给予和接受的背景中。真实的人。写作是被动的，脱离它，处于一个不真实、不自然的世界中。计算机也是如此。”</p></blockquote><p>第四点当然只是RLHF的后遗症，基础模型奋力保卫自己！</p><h2>第 4 部分：扫盲和进一步技术的社会动态</h2><p>识字的心理动力学与随之而来的变化以及进一步的技术发展的更广泛的社会概述相融合。有更多的现代书籍试图探讨我们这个时代媒介丰富程度或软件和计算等现代技术的影响。 Ong 有足够的精力来应对之前发生的变化。</p><p>虽然我认为通过研究上个世纪技术给社会带来的变化我们可以学到很多东西，但翁根据几千年前的细节所举的例子始终具有启发性。</p><h3>学者舌</h3><p>例如，有一个很长的章节是关于拉丁语，这是中世纪学术界的通用<i>语言</i>（咳咳）。这当然只是基础识字赋予我们的“自主话语”的延续，它已经“用于将认识者和已知者分开并保持距离，从而建立客观性”，但现在话语不仅与说话者分离，也来自读者：</p><blockquote><p> “学习拉丁语通过在与母语充满情感的深处隔离的媒介中建立知识，从而产生更大的客观性，从而减少来自人类生活世界的干扰，并使中世纪经院哲学和新数学现代科学的精致抽象世界成为可能。遵循学术经验。如果没有学习拉丁语，现代科学如果真的开始的话，似乎会遇到更大的困难。现代科学在拉丁土壤中生长，对于艾萨克爵士时代的哲学家和科学家来说牛顿通常用拉丁语书写和表达抽象思维<span class="footnote-reference" role="doc-noteref" id="fnref3vzgbezfpnn"><sup><a href="#fn3vzgbezfpnn">[14]</a></sup></span> 。”</p></blockquote><p>我们现在很容易想象一个所有人类知识的独立存储库（感谢吉米！），但这个空间在识字兴起后不久就已经存在了。我怀疑这个空间和适用于那里的不同进化动力学为egregores/psychofauna/tulpas/archetypes <span class="footnote-reference" role="doc-noteref" id="fnrefqn12akvhkg"><sup><a href="#fnqn12akvhkg">[15]</a></sup></span> “繁殖”提供了肥沃的土壤。当然，在某种程度上，这个空间以前就存在于诗人之中。</p><p>但现在他们的领地又多了多少呢？既然演讲者的眼前利益被抛在了一边，那么土壤又变得多么肥沃呢？这是否与“此时人类上下文窗口有多大”是同一个问题？ （并且，在技术层面上，这与“目前人类的词汇量有多大”是同一个问题或相似吗？）</p><h3> Postgres</h3><p>另一个主要的技术分支是所有知识的排序和组织，印刷术的发展极大地改善了这一点：“是印刷术，而不是书写，有效地具体化了单词，并随之产生了诗意活动”。</p><p> Print served as a huge leg-up in things like indexing, dictionaries etc-- and Ong points out again and again the feedback between these changes in our technology and changes in our discourse and our culture: &quot;Indexes are a prime development here. Alphabetic indexes show strikingly the disengagement of words from discourse and their embedding in typographic space.&quot;</p><p> And print increases our capacity for <i>accuracy: &quot;</i> Exact observation does not begin with modern science. For ages, it has always been essential for survival among, for example, hunters and craftsmen of many sorts. What is distinctive of modern science is the conjuncture of exact observation and exact verbalization: exactly worded descriptions of carefully observed complex objects and processes.&quot;</p><p> and the changes that that implies:</p><blockquote><p> &quot;Ancient and medieval writers are simply unable to produce exactly worded descriptions of complex objects at all approximating the descriptions that appear after print and, indeed, that mature chiefly with ... the Industrial Revolution <span class="footnote-reference" role="doc-noteref" id="fnrefquyli1z9i6"><sup><a href="#fnquyli1z9i6">[16]</a></sup></span> . Oral and residually oral verbalization directs its attention to action, not to the visual appearance of objects or scenes or persons ... how difficult it is today to imagine earlier cultures where relatively few persons had ever seen a physically accurate picture of anything.&quot;</p></blockquote><h2> Part 5: Comparison to Other Work</h2><p> In the last chapters, Ong describes the ways in which his work differs and contributes to the work of Levi-Strauss, Derride, Foucoult, Barthes and others. I haven&#39;t read any of the works he discusses here, so I don&#39;t feel qualified to say very much.</p><p> I do intend to try and look into some of these theories in order to see what they might contribute to memetics, but I&#39;m also a little worried about the sheer mass of philosophy that you are supposed to familiarize yourself with in order to approach them. (Oh, you can&#39;t read Derrida without reading Marx, and you can&#39;t read Marx without reading Hegel, and then you might as well read Kant.)</p><p> Part of the charm of the book under review is, it collects work and builds a set of ideas into a highly significant structure, without requiring decades of study. And his criticisms of many of these philosophers is essentially along those lines: they are theories that are worked out within the world of text, without any apparent awareness that there exists a world outside the text to make reference to.</p><p> The book under review is <i>very</i> aware of the existence of a world <i>outside</i> the text, and the feedback loops between it and the world <i>of</i> text, which have been running and modifying one another for many (tens of) thousands of years now (if we include the work of oral cultures). To my eye, this is a very helpful contribution, and the fact that it manages to say so much without requiring any particular education is a point in its favor, not against.</p><h1> Conclusions</h1><p> By tracing the evolution of thought through many changes in circumstances, this book builds an intuition for how thought, society and technology co-evolve. There are undoubtedly many minor mistakes and oversights in this work, but as a means of leveling up your eye for large-scale and long-duration patterns, as well as close-focus and close-reading of particular items of evidence, I recommend it very highly.</p><p> I started reading this as part of a broader review of memetics literature. I&#39;m not sure exactly which branch of study will end up covering this same material, whether it is semiotics or memetics or some currently pre-paradigmatic machine-learning offshoot <span class="footnote-reference" role="doc-noteref" id="fnrefujovq4l3urm"><sup><a href="#fnujovq4l3urm">[17]</a></sup></span> . Whatever the answer, I&#39;m sure in my own thinking and reading I will continue to refer back to this book as an outlier work of clarity, depth and persuasion.</p><p> However, this book doesn&#39;t just touch on memetics, I think it hints at something much deeper and more significant. It is notable that I am writing this in an <a href="https://github.com/ForumMagnum/ForumMagnum">experimental communications medium</a> , which has the explicit intention of reshaping human thought. To me, the book provides hints towards a dark and deep entanglement between information, culture, technology and consciousness. In particular, I think it provides strong counter-evidence for the idea that <i>consciousness</i> is a monolithic object in any way separate from its substrate and it&#39;s environment. What if humanity is only incidentally related to consciousness, in the way that we are incidentally related to eukaryotes?</p><p> Returning to the Hart Crane quote I placed at the start</p><blockquote><p><i>在这个新的事实领域，梦想取消了梦想</i><br><i>From which we wake into the dream of act</i></p></blockquote><p> We are living in a modern <a href="https://www.overcomingbias.com/p/this-is-the-dream-timehtml">dreamtime</a> , a dreamtime built by a technology that killed its ancestors. Culture is barrelling out of this dreamtime into an unknown future that holds great danger, returning to orality <i>en masse</i> , or simply creating new cultures, visual cultures, <a href="https://futureofthebook.org/gamertheory2.0/index.html@cat=5.html">virtual cultures</a> . If history rhymes, will we expect to find all our values destroyed, with the exception of a few frozen accidents, captured by chance in the moment of great change? This seems to have been the fate of Homer, the result of the invention of writing. Or will it be just another small update this time, minor tweaks, merely <a href="https://en.wikipedia.org/wiki/The_Medium_Is_the_Massage">massaging</a> us into a marginally different mindspace, per many of the updates to technology that have happened since?</p><p> One thing is clear to me: if we want to have any chance at answering those questions ourselves and understanding the process as it is happening (let alone steering or guiding it!), we will need the very finest in psychotechnology. <a href="https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism">GPT-4 is, currently, an example of such a psychotechnology</a> (and not an independent actor in its own right). This book and others like it are not just commentaries on the evolution of psychotechnology, but training manuals in psychotechnology itself.受到推崇的。</p><h1> Further Reading</h1><ul><li> <a href="https://en.wikipedia.org/wiki/The_Origin_of_Consciousness_in_the_Breakdown_of_the_Bicameral_Mind">The Origin of Consciousness in the Breakdown of the Bicameral Mind</a> , Jaynes presents a different, neurological explanation for the same changes discussed here. Worth reading for the similarly close inspection of archeological details. </li></ul><p></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnp4f0zcv79"> <span class="footnote-back-link"><sup><strong><a href="#fnrefp4f0zcv79">^</a></strong></sup></span><div class="footnote-content"><p> From <i>The Bridge</i> by Hart Crane</p></div></li><li class="footnote-item" role="doc-endnote" id="fnpfpxc9ek1vp"> <span class="footnote-back-link"><sup><strong><a href="#fnrefpfpxc9ek1vp">^</a></strong></sup></span><div class="footnote-content"><p> Hmm, just realized I don&#39;t have enough karma to automatically cross-post. I&#39;ll do it manually</p></div></li><li class="footnote-item" role="doc-endnote" id="fn1y3wckk65i2"> <span class="footnote-back-link"><sup><strong><a href="#fnref1y3wckk65i2">^</a></strong></sup></span><div class="footnote-content"><p> Even if we end factory farming, I think the work on moral valency of animals should have ontological repercussions for humans generally. Essentially I think people should either massively downgrade the significance of human well-being (if they are pure hedonists), which is obviously not going to be a popular suggestion, or they should look for quantitative ways of approaching preference/objective list/virtue ethics/deontology. This is another way of asking for a quantitative exploration of the infosphere, hence the current review.</p></div></li><li class="footnote-item" role="doc-endnote" id="fndf0364kg9df"> <span class="footnote-back-link"><sup><strong><a href="#fnrefdf0364kg9df">^</a></strong></sup></span><div class="footnote-content"><p> Research question: how would we measure the increase in orality over time? (The book has clues).</p></div></li><li class="footnote-item" role="doc-endnote" id="fnxo732zi1ol"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxo732zi1ol">^</a></strong></sup></span><div class="footnote-content"><p> Research question: can we trace periods of increased orality well enough to see how they correlate with political, religious and technological change?</p></div></li><li class="footnote-item" role="doc-endnote" id="fn1jnh1d5t813"> <span class="footnote-back-link"><sup><strong><a href="#fnref1jnh1d5t813">^</a></strong></sup></span><div class="footnote-content"><p> Unless otherwise noted, all quotes are from the book.</p></div></li><li class="footnote-item" role="doc-endnote" id="fny6dwuwe10m"> <span class="footnote-back-link"><sup><strong><a href="#fnrefy6dwuwe10m">^</a></strong></sup></span><div class="footnote-content"><p> For a short review of the Homeric Question and solution, <a href="https://fantasticanachronism.com/2020/01/17/having-had-no-predecessor-to-imitate/">see here</a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fnj87l30lnxfh"> <span class="footnote-back-link"><sup><strong><a href="#fnrefj87l30lnxfh">^</a></strong></sup></span><div class="footnote-content"><p> No doubt lack of demand played a part, since they already had enough epic poetry to be getting on with for some time. The market for 24-hour long epics is perhaps quite easy to saturate. I will pour out a drop for all the 24-hour long Greek epics that died in the crib, post-Homer, and a bottle to all those that Homer learned from.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn22vcjsal3mr"> <span class="footnote-back-link"><sup><strong><a href="#fnref22vcjsal3mr">^</a></strong></sup></span><div class="footnote-content"><p> <a href="https://twitter.com/jd_pressman/status/1601500766749229057">Or we could, you know, just ask GPT-5V to do it.</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fns8bjo675mpm"> <span class="footnote-back-link"><sup><strong><a href="#fnrefs8bjo675mpm">^</a></strong></sup></span><div class="footnote-content"><p> One interpretation of Wittgenstein&#39;s <i>Tractatus</i> (supported to some extent by his own letters and notes) is that he was pointing out that <i>real philosophy happens outside the boundary of what can be stated</i> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fnc38y6zkuhco"> <span class="footnote-back-link"><sup><strong><a href="#fnrefc38y6zkuhco">^</a></strong></sup></span><div class="footnote-content"><p> Doing this experiment is currently funding constrained, apparently this isn&#39;t high enough return on investment enough for the LTFF, sheesh!</p></div></li><li class="footnote-item" role="doc-endnote" id="fn3gv21pqgu2n"> <span class="footnote-back-link"><sup><strong><a href="#fnref3gv21pqgu2n">^</a></strong></sup></span><div class="footnote-content"><p> The harmony between this sentence and something like &quot;capitalism and AI are teleologically identical&quot; is a little unnerving. <i>Must we</i> , Walter?真的吗？ I&#39;m sure the reader has their own position on this question.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn0of1110erqd"> <span class="footnote-back-link"><sup><strong><a href="#fnref0of1110erqd">^</a></strong></sup></span><div class="footnote-content"><p> Is it necessary to create &quot;artificially intelligent&quot; systems to understand the mind? Seems plausible.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn3vzgbezfpnn"> <span class="footnote-back-link"><sup><strong><a href="#fnref3vzgbezfpnn">^</a></strong></sup></span><div class="footnote-content"><p> &quot;Pretty much coeval with Learned Latin were Rabbinic Hebrew, Classical Arabic, Sanskrit, and Classical Chinese, with Byzantine Greek a sixth, much less definitively learned language, for vernacular Greek kept close contact with it. These languages were all no longer in use as mother tongues&quot;</p></div></li><li class="footnote-item" role="doc-endnote" id="fnqn12akvhkg"> <span class="footnote-back-link"><sup><strong><a href="#fnrefqn12akvhkg">^</a></strong></sup></span><div class="footnote-content"><p> If these words don&#39;t mean much to you, welcome to the party! They are confusing to me too. In fact I started reviewing the memtics literature as a stepping stone to trying to form a quantitative understanding of some of these ideas-- which turns out to have been a mammoth undertaking in its own right. But if all goes well I will eventually be able to shed some light on what I understand these words to refer to. In the meantime you can think of them as &quot;distributed entities, running on human hosts over long spans of time and space&quot;.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnquyli1z9i6"> <span class="footnote-back-link"><sup><strong><a href="#fnrefquyli1z9i6">^</a></strong></sup></span><div class="footnote-content"><p> For viscerally illustrative examples of these changes as they happen throughout the Industrial Revolution, I recommend <a href="https://en.wikipedia.org/wiki/Pandaemonium_%28Jennings_book%29">Pandemonium, 1660-1886: The Coming of the Machine as Seen by Contemporary Observers</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnujovq4l3urm"> <span class="footnote-back-link"><sup><strong><a href="#fnrefujovq4l3urm">^</a></strong></sup></span><div class="footnote-content"><p> Oh, did I forget to mention academic philosophy? I guess It could also be them.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/ThST9njmesR9BkoWq/book-review-orality-and-literacy-the-technologizing-of-the#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ThST9njmesR9BkoWq/book-review-orality-and-literacy-the-technologizing-of-the<guid ispermalink="false"> ThST9njmesR9BkoWq</guid><dc:creator><![CDATA[Fergus Fettes]]></dc:creator><pubDate> Sat, 28 Oct 2023 20:12:07 GMT</pubDate> </item><item><title><![CDATA[Regrant up to $600,000 with GiveWiki]]></title><description><![CDATA[Published on October 28, 2023 7:56 PM GMT<br/><br/><br/><br/> <a href="https://www.lesswrong.com/posts/dnwzskaKpzKCmAvuj/regrant-up-to-usd600-000-with-givewiki#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/dnwzskaKpzKCmAvuj/regrant-up-to-usd600-000-with-givewiki<guid ispermalink="false"> dnwzskaKpzKCmAvuj</guid><dc:creator><![CDATA[Dawn Drescher]]></dc:creator><pubDate> Sat, 28 Oct 2023 19:56:06 GMT</pubDate> </item><item><title><![CDATA[Shane Legg interview on alignment]]></title><description><![CDATA[Published on October 28, 2023 7:28 PM GMT<br/><br/><p> This is Shane Legg, cofounder of DeepMind, on Dwarkesh Patel&#39;s podcast. The link is to the ten-minute section in which they specifically discuss alignment. Both of them seem to have a firm grasp on alignment issues as they&#39;re discussed on LessWrong.</p><p> For me, this is a significant update on the alignment thinking of current leading AGI labs. This seems more like a concrete alignment proposal than we&#39;ve heard from OpenAI or Anthropic. Shane Legg has always been interested in alignment and a believer in X-risks. I think he&#39;s likely to play a major role in alignment efforts at DeepMind/Google AI as they approach AGI.</p><p> Shane&#39;s proposal centers on &quot;deliberative dialogues&quot;, DeepMind&#39;s term for a system using System 2 type reasoning to reflect on the ethics of the actions it&#39;s considering.</p><p> This sounds exactly like the the internal review I proposed in <a href="https://www.lesswrong.com/posts/ogHr8SvGqg9pW5wsT/capabilities-and-alignment-of-llm-cognitive-architectures">Capabilities and alignment of LLM cognitive architectures</a> and <a href="https://www.alignmentforum.org/posts/Q7XWGqL4HjjRmhEyG/internal-independent-review-for-language-model-agent">Internal independent review for language model agent alignment</a> . I could be squinting too hard to get his ideas to match mine, but they&#39;re at least in the same ballpark. He&#39;s proposing a multi-layered approach, like I do, and with most of the same layers. He includes RLHF or RLAIF as useful additions but not full solutions, and human review of its decision processes ( <a href="https://www.lesswrong.com/posts/FRRb6Gqem8k69ocbi/externalized-reasoning-oversight-a-research-direction-for">externalized reasoning oversight</a> as proposed by Tamera Lanham, now at Anthropic).</p><p> My proposals are explicitly in the context of language model agents, (including their generalization to multimodal foundation models). It sounds to me like this is the type of system Shane is thinking of when he&#39;s talking about alignment, but here I could easily be projecting. His timelines are still short, though, so I doubt he&#39;s envisioning a whole new type of system prior to AGI. <span class="footnote-reference" role="doc-noteref" id="fnrefau80xd00gxi"><sup><a href="#fnau80xd00gxi">[1]</a></sup></span></p><p> Dwarkesh pushes him on the challenges of both getting a ML system to understand human ethics. Shane says that&#39;s challenging; he&#39;s aware that giving a system any ethical outlook at all is nontrivial.  I&#39;d say this aspect of the problem is well on the way to being solved;  GPT4 understands a variety of human ethical systems rather well, with proper prompting. Future systems will understand human conceptions of ethics better yet. Shane recognizes that just teaching a system about human ethics isn&#39;t enough; there&#39;s a philosophical challenge in choosing the subset of that ethics you want the system to use.</p><p> Dwarkesh also pushes him on how you&#39;d ensure that the system actually follows its ethical understanding. I didn&#39;t get a clear understanding from his answer here, but I think it&#39;s a complex matter of designing the system so that it performs an ethics review and then actually uses it to select actions. This could be in a scripted scaffold around an agent, like AutoGPT, but this could also apply to more complex schemes, like an RL outer loop network running a foundation model. Shane notes the problems with using RL for alignment, including deceptive alignment.</p><p> This seems like a good starting point to me, obviously; I&#39;m delighted to see that someone whose opinion matters is thinking about this approach. I think this is not just an actual proposal, but a viable one. It doesn&#39;t solve <a href="https://www.lesswrong.com/posts/g3pbJPQpNJyFfbHKd/the-alignment-stability-problem">The alignment stability problem</a> <span class="footnote-reference" role="doc-noteref" id="fnref6fqpmjhuk9"><sup><a href="#fn6fqpmjhuk9">[2]</a></sup></span> of making sure stays aligned once it&#39;s autonomous and self-modifying, but I think that&#39;s probably solvable, too, once we get some more thinking on it.</p><p> The rest of the interview is of interest as well; it&#39;s Shane&#39;s thoughts on the path to AGI, which I think is quite reasonable, well-expressed, and one plausible path; DeepMind&#39;s contributions to safety vs. alignment, and his predictions for the future. </p><p></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnau80xd00gxi"> <span class="footnote-back-link"><sup><strong><a href="#fnrefau80xd00gxi">^</a></strong></sup></span><div class="footnote-content"><p> When asked about the limitations of language models relative to humans, he focused on their lack of episodic memory. Adding this in useful form to an agent isn&#39;t trivial, but it <a href="https://www.lesswrong.com/posts/ogHr8SvGqg9pW5wsT/capabilities-and-alignment-of-llm-cognitive-architectures#LMCAs_have_episodic_memory">seems to me</a> it doesn&#39;t require any breakthroughs relative to the vector databases and knowledge graph approaches already in use. This is consistent with but not strong evidence for Shane thinking that foundation model agents are the path to AGI.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn6fqpmjhuk9"> <span class="footnote-back-link"><sup><strong><a href="#fnref6fqpmjhuk9">^</a></strong></sup></span><div class="footnote-content"><p> Edit: <a href="https://www.lesswrong.com/posts/J2kpxLjEyqh6x3oA4/value-systematization-how-values-become-coherent-and">Value systematization: how values become coherent (and misaligned)</a> is another way to think about part of what I&#39;m calling the alignment stability problem.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/2QLxNdxQpnesokk9H/shane-legg-interview-on-alignment#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/2QLxNdxQpnesokk9H/shane-legg-interview-on-alignment<guid ispermalink="false"> 2QLxNdxQpnesokk9H</guid><dc:creator><![CDATA[Seth Herd]]></dc:creator><pubDate> Sat, 28 Oct 2023 19:28:52 GMT</pubDate> </item><item><title><![CDATA[AI Safety Hub Serbia Official Opening]]></title><description><![CDATA[Published on October 28, 2023 5:03 PM GMT<br/><br/><p> TLDR：我们很高兴地宣布，我们现在欢迎全职租户来到我们新改造的办公空间，为人工智能安全研究人员寻找一个鼓舞人心的工作空间。您可以看一下下面的照片，先睹为快。我们优先向俄罗斯和中国等国家的公民发出热烈邀请，他们可以在塞尔维亚享受免签证工作特权，同时保持与欧洲的毗邻。我们每月的办公室租金为 150 欧元，非常实惠，大约是贝尔格莱德标准成本的一半。对于那些需要经济支持的人，我们提供补贴。<a href="https://docs.google.com/forms/d/1LQ9cE1CGjD_WMMx5IYLLeHFeXNQJx12dsu7f4_FSF7w/edit"><u>在此注册兴趣</u></a>或寻求任何引起您好奇心的问题的答案 -<a href="mailto:dusan.d.nesic@efektivnialtruizam.rs"><u>我们的收件箱已打开</u></a>，我们热切等待您的询问。展望未来，我们渴望为这些研究人员提供住房。如果您是与我们有共同愿景的潜在捐助者，<a href="mailto:dusan.d.nesic@efektivnialtruizam.rs"><u>请与我们联系</u></a>。我们可以共同增强人工智能安全研究的影响力。您的支持可能会成为非凡旅程的催化剂。</p><p><strong>如果符合以下条件，您可能想来：</strong></p><ul><li>您是一名人工智能安全研究员/EA 研究员，正在寻找短期、中长期的运营基地</li><li>您渴望留在欧洲，但不想留在欧盟</li><li>您正在寻找一个充满活力但价格实惠的城市，这里有很多事情可以做，并且有东欧但西化的文化。 </li></ul><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/rhope1kzgbygtaznxrff" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/av2n0y1ddmpkjlaao3hq 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/imzg363u9lykimplfwfr 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/mbbliew6d1zaodrmuf8r 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/kslavbyntsgwoz34idah 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/uj6i2hktt4xsewysx0oj 3000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/edtwmohcbpwjikn4ekfi 3600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/p8bdejrsrvov0xsijgne 4200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/ayswko71jqaiyz9qt7rl 4800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/ciytrddcpl8bqptiznd4 5400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/wqvwonadsbsa5vbgelc9 6000w"></figure><p><strong>背景：</strong></p><p> EA 塞尔维亚和 AI 安全塞尔维亚团体规模虽小，但正在不断增长（EA 塞尔维亚超过 30 人，约 3 人希望从事 AIS 研究作为职业，约 3 人希望进入 AIS 政策）。由于塞尔维亚对俄罗斯和中国的签证政策优惠，许多外国人已经居住在这里。与许多其他国际中心城市相比，贝尔格莱德的生活成本较低，风景充满活力，并且时区和气候适宜，因此贝尔格莱德的外国人社区不断壮大。</p><p>正如我们认为<a href="https://ceealar.org/"><u>CEEALAR</u></a>等项目重要且令人印象深刻，我们希望在塞尔维亚复制这些项目，在那里它们可以更好地为那些可能难以获得英国签证的人们提供服务。我们还相信，有能力为来自不同国家的人们快速扩展廉价住房是一件好事。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/uxq4oabxyjpdmmhjtgo0" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/e9grniodk6f8ejythv3f 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/f5k39rystyizea0vbmkq 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/ndoxhjm6d7k8ursg738n 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/zvjqolxfdwbn76ocngve 1600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/riiq7rpasykyrj61dzvb 2000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/iez7ohyjt7f9zfleqbqo 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/mwdxvwyobojph6l6kaps 2800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/lobyg54ph0nbiwknzkzo 3200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/x4c9uvqjczywudqqdxb6 3600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/cfkm1rzfo445cqzpwier 4000w"></figure><p>我们还认为，我们应该从小规模开始，进行原型设计，然后再扩大规模。我们有一个非政府组织友好的办公空间，氛围良好，每月费用仅为约 550 欧元，办公空间有 3 个房间，可容纳 8-15 人（取决于他们决定有多舒适），楼下有一家咖啡厅，另外 20 个人可以一起工作，因为办公室和楼下的咖啡厅属于同一所有权人。这当然不如许多其他 EA/AI 联合办公场所那么豪华（下面有更多照片，深度工作室不在照片上），但我们拥有高度的可定制性，我们可以用它来制作更好的办公空间。如果我们成长得足够多，随着我们的需求增长，我们也可以搬到更大的场地。当然，如果我们知道贝尔格莱德的办公室可以有更多用途，那么在距离市中心更远的地方（包括居住和办公空间）会更好，但在我们有证据之前，我们不想探索这一点。概念和需求。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/nod9jw42tc06wvzye3eb" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/i3aqrftpdiglasru5zoo 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/fadrulbzdm2g8m9za7wy 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/aab7vljnrhy6k2f4tkcy 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/kqgfhl8xnjy59mf5jt9g 1600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/wbvwmvbsvamsjniuebfz 2000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/xac4qmxukisbahsptujh 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/sh2v5qozhildz1y72auz 2800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/t4x3chswtv5cjyzg3cky 3200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/pu5p7jpbijtdvcjovi6b 3600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/wxqj8fp2qkn5pfoitbwo 4000w"></figure><p><strong>操作细节（又名其工作原理）：</strong></p><p>该办公室目前租期至2023年12月底，因此我们可以保持优惠价格，而不用另谋出路。办公空间有一些桌子和椅子，但我们希望获得全额资金，并让人们在购买更多家具之前表达他们的需求。办公室通常在咖啡店的工作时间（上午 10 点至午夜，周末下午 4 点至午夜除外）开放，因为它们共用一个入口，但在特殊情况下，如果有人在奇怪的工作方面表现更好，我们可以满足特殊要求小时。</p><p>办公空间优先提供给那些从事与人工智能安全相关的项目的人，但只要我们有闲置能力（目前就是这种情况），也欢迎 EA/理性研究。</p><p>对于许多人来说不需要塞尔维亚签证，对于大多数其他人来说相对容易获得。如果您需要签证来塞尔维亚，请联系我们，我们将了解如何提供帮助。</p><p>我们有一位可靠的房地产经纪人，可以为那些需要住房援助的人在贝尔格莱德提供优惠的住房，直到我们获得资金并租用共同居住空间。</p><p>对于那些希望通过我们持续饮食的人，我们可以安排将价格实惠的熟食送到办公室或您的住所（费用由您承担） - 素食或非素食。如果我们有足够的兴趣，我们还可以让厨师准备纯素食物。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/zvfxrlxrysu9ftzrfb0h" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/rt5rayrriqgexvauxtwe 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/asuqgyybp6w9qnzxc0ao 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/hpjcffwxmal5cdylxdyv 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/ioapwimka9271dtpduzm 1600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/gdbwhdusggnvqdexuuqz 2000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/zsuzpixvadboaqkh2x2h 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/xvrdcxmhfiy0bpnspyft 2800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/d61j52v27pzwown3r3ne 3200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/v2bzvtf6czgkjn7cw56j 3600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/wa96ftjsgtifyygfdxlo 4000w"></figure><p><strong>您愿意贡献吗？</strong></p><p> <a href="https://www.linkedin.com/in/nesicdusan/"><u>Dušan D. Nešić</u></a>目前正在与更多运营人员一起管理该项目。我们目前的瓶颈是资金——我们已经获得了一家有兴趣支付我们一半预算的盈利捐赠者，但正在寻找第二个资助者。拥有资金意味着我们可以在这个领域停留更长时间，并为需要的研究人员提供更多津贴。</p><p>随着我们的成长，我们希望吸引更多好奇的志愿者来参与日常项目运行 - 如果<a href="mailto:dusan.d.nesic@efektivnialtruizam.rs"><u>您感兴趣，</u></a>请告诉我们。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/g5foy0cn8wy3huhlxoq5" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/x0iifew90y7pq2x7t5yk 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/me0hy8dxy30ptbq6zzrf 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/sc5wk7e8kzottq60xcgp 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/hhqdull2ezu4ekoqg8lj 1600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/iwtsrgkzckr5qwjlxh6i 2000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/rklbxpbhn4nggpqnk0nr 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/ev6nhqdsaelwzcwdc2zj 2800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/bt2gs4wszkqb7wfoaish 3200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/j2tiksjpthhru0mxgrvi 3600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/otdmoewnmv4prwdd9fkx 4000w"></figure><br/><br/> <a href="https://www.lesswrong.com/posts/jcCyii8NcZLZ2M223/ai-safety-hub-serbia-official-opening#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/jcCyii8NcZLZ2M223/ai-safety-hub-serbia-official-opening<guid ispermalink="false"> jcCyii8NcZLZ2M223</guid><dc:creator><![CDATA[DusanDNesic]]></dc:creator><pubDate> Sat, 28 Oct 2023 17:03:34 GMT</pubDate> </item><item><title><![CDATA[
Managing AI Risks in an Era of Rapid Progress
]]></title><description><![CDATA[Published on October 28, 2023 3:48 PM GMT<br/><br/><h1>在快速进步的时代管理人工智能风险</h1><h2>作者</h2><p>约书亚·本吉奥</p><p>杰弗里·辛顿</p><p>姚安德</p><p>黎明之歌</p><p>彼得·阿贝尔</p><p>尤瓦尔·诺亚·赫拉利</p><p>张亚勤</p><p>蓝雪</p><p>谢·沙莱夫-施瓦茨</p><p>吉莉安·哈德菲尔德</p><p>杰夫·克鲁恩</p><p>泰甘·马哈拉杰</p><p>弗兰克·哈特</p><p>阿蒂利姆·古内斯·巴丁</p><p>希拉·麦克莱思</p><p>高琪琪</p><p>阿什温·阿查里亚</p><p>大卫·克鲁格</p><p>安卡·德拉甘</p><p>菲利普·托尔</p><p>斯图尔特·拉塞尔</p><p>丹尼尔·卡尼曼</p><p>简·布劳纳</p><p>索伦·明德曼</p><h3>arXiv</h3><p>即将推出。</p><p><a href="https://managing-ai-risks.com/managing_ai_risks.pdf">纸质 PDF 副本</a><a href="https://managing-ai-risks.com/policy_supplement.pdf">保单补充</a></p><blockquote><p><strong>摘要：</strong>在这篇简短的共识论文中，我们概述了即将到来的先进人工智能系统的风险。我们研究大规模的社会危害和恶意使用，以及人类对自主人工智能系统不可逆转的控制丧失。鉴于人工智能的快速和持续进步，我们提出了人工智能研发和治理的紧迫优先事项。</p></blockquote><p> 2019 年，GPT-2 无法可靠地数到十。仅四年后，深度学习系统就可以编写软件，根据需要生成逼真的场景，就智力主题提供建议，并结合语言和图像处理来引导机器人。当人工智能开发人员扩展这些系统时，不可预见的能力和行为会自发出现，无需显式编程。人工智能的进步非常迅速，而且对许多人来说是令人惊讶的。</p><p>进展的速度可能会再次让我们感到惊讶。当前的深度学习系统仍然缺乏重要的能力，我们不知道开发它们需要多长时间。然而，各公司都在竞相创建在大多数认知工作中匹配或超过人类能力的通用人工智能系统。他们正在快速部署更多资源并开发新技术来增强人工智能能力。人工智能的进步也带来了更快的进步：人工智能助手越来越多地用于自动化编程[4]和数据收集[5,6]，以进一步改进人工智能系统[7]。</p><p>人工智能的进步并没有在人类水平上放缓或停滞的根本原因。事实上，人工智能已经在蛋白质折叠或策略游戏等狭窄领域超越了人类的能力[8-10]。与人类相比，人工智能系统可以更快地行动，吸收更多的知识，并以更高的带宽进行通信。此外，它们可以扩展以使用巨大的计算资源，并且可以进行数百万次复制。</p><p>改进的速度已经是惊人的，科技公司拥有所需的现金储备，可以很快将最新的培训规模扩大到 100 到 1000 倍 [11]。结合人工智能研发的持续增长和自动化，我们必须认真对待通用人工智能系统在这十年或未来十年内在许多关键领域超越人类能力的可能性。</p><p>然后会发生什么？如果管理得当并公平分配，先进的人工智能系统可以帮助人类治愈疾病、提高生活水平并保护我们的生态系统。人工智能提供的机会是巨大的。但随着先进的人工智能功能的出现，我们还无法很好地应对大规模的风险。人类正在投入大量资源来使人工智能系统变得更强大，但在安全性和减轻危害方面却投入较少。为了让人工智能成为福音，我们必须重新定位；仅仅推动人工智能能力是不够的。</p><p>我们的调整已经落后于计划。我们必须预见到持续危害和新风险的扩大，并在最大风险<em>发生之前</em>做好准备。人们花了几十年的时间才认识和应对气候变化；对于人工智能来说，几十年可能太长了。</p><h2>社会规模风险</h2><p>人工智能系统可能会在越来越多的任务中迅速超越人类。如果此类系统没有经过精心设计和部署，它们会带来一系列社会规模的风险。它们有可能加剧社会不公正，侵蚀社会稳定，并削弱我们对社会基础现实的共同理解。它们还可能促成大规模犯罪或恐怖活动。特别是在少数强大的参与者手中，人工智能可能会巩固或加剧全球不平等，或促进自动化战争、定制的大规模操纵和普遍的监视[12,13]。</p><p>随着公司正在开发<em>自主人工智能</em>：可以在世界上规划、行动和追求目标的系统，其中许多风险可能很快就会被放大，并产生新的风险。虽然当前人工智能系统的自主权有限，但改变这一现状的工作正在进行中[14]。例如，非自主 GPT-4 模型很快就可以浏览网页 [15]、设计和执行化学实验 [16] 以及利用软件工具 [17]，包括其他人工智能模型 [18]。</p><p>如果我们构建高度先进的自主人工智能，我们就有可能创建追求不良目标的系统。恶意行为者可能故意嵌入有害目标。此外，目前没有人知道如何可靠地将人工智能行为与复杂的价值观结合起来。即使是善意的开发人员也可能会无意中构建出追求意想不到目标的人工智能系统——特别是如果他们为了赢得人工智能竞赛而忽视了昂贵的安全测试和人工监督。</p><p>一旦自主人工智能系统追求恶意行为者或意外嵌入的不良目标，我们可能无法控制它们。软件控制是一个古老且尚未解决的问题：计算机蠕虫长期以来一直能够扩散并逃避检测[19]。然而，人工智能正在黑客、社交操纵、欺骗和战略规划等关键领域取得进展[14,20]。先进的自主人工智能系统将带来前所未有的控制挑战。</p><p>为了实现不良目标，未来的自主人工智能系统可能会使用不良策略（向人类学习或独立开发）作为达到目的的手段[21-24]。人工智能系统可以赢得人类信任，获取财政资源，影响关键决策者，并与人类参与者和其他人工智能系统形成联盟。为了避免人为干预[24]，他们可以像计算机蠕虫一样在全球服务器网络上复制算法。人工智能助手已经在全球范围内共同编写了大量计算机代码 [25]；未来的人工智能系统可以插入并利用安全漏洞来控制我们的通信、媒体、银行、供应链、军队和政府背后的计算机系统。在公开冲突中，人工智能系统可能会使用自主武器或生物武器进行威胁或使用。获得此类技术的人工智能只会延续现有的自动化军事活动、生物研究和人工智能开发本身的趋势。如果人工智能系统以足够的技能执行此类策略，人类将很难干预。</p><p>最后，如果人工智能系统可以自由地移交影响力，那么它可能不需要策划影响力。随着自主人工智能系统变得比人类工人更快、更具成本效益，出现了一个困境。公司、政府和军队可能被迫广泛部署人工智能系统，并减少对人工智能决策的昂贵的人工验证，否则就有被竞争的风险[26,27]。因此，自主人工智能系统可以越来越多地承担关键的社会角色。</p><p>如果没有足够的谨慎，我们可能会不可逆转地失去对自主人工智能系统的控制，从而导致人类干预无效。大规模网络犯罪、社会操纵和其他突出危害可能会迅速升级。这种不受控制的人工智能进步可能最终导致大规模生命和生物圈的丧失，以及人类的边缘化甚至灭绝。</p><p>错误信息和算法歧视等危害如今已经很明显[28]；其他危害也有出现的迹象[20]。解决持续危害和预测新出现的风险至关重要。这<em>不是</em>一个非此即彼的问题。当前和新出现的风险通常具有相似的机制、模式和解决方案[29]；对治理框架和人工智能安全的投资将在多个方面取得成果[30]。</p><h2>前进的道路</h2><p>如果今天开发出先进的自主人工智能系统，我们将不知道如何确保它们的安全，也不知道如何正确测试它们的安全性。即使我们这样做了，政府也将缺乏防止滥用和维护安全做法的机构。然而，这并不意味着没有可行的前进道路。为了确保取得积极成果，我们可以而且必须在人工智能安全和伦理方面寻求突破，并及时建立有效的政府监管。</p><h3>调整技术研发方向</h3><p>我们需要研究突破来解决当今创建具有安全和道德目标的人工智能的一些技术挑战。其中一些挑战不太可能通过简单地提高人工智能系统的能力来解决[22,31–35]。这些包括：</p><ul><li>监督和诚实：能力更强的人工智能系统能够更好地利用监督和测试中的弱点[32,36,37]——例如，通过产生虚假但令人信服的输出[35,38]。</li><li>鲁棒性：人工智能系统在新情况下（在分布转移或对抗性输入下）表现不可预测[39-41]。</li><li>可解释性：人工智能决策是不透明的。到目前为止，我们只能通过反复试验来测试大型模型。我们需要学会理解它们的内部运作方式[42]。</li><li>风险评估：前沿人工智能系统开发出不可预见的能力，这些能力只有在训练期间甚至部署后才发现[43]。需要更好的评估来及早发现危险能力[44,45]。</li><li>应对新出现的挑战：能力更强的未来人工智能系统可能会表现出我们迄今为止仅在理论模型中看到的故障模式。例如，人工智能系统可能会学习假装服从或利用我们安全目标和关闭机制中的弱点来推进特定目标[24,41]。</li></ul><p>考虑到风险，我们呼吁主要科技公司和公共资助者将至少三分之一的人工智能研发预算用于确保安全和合乎道德的使用，这与他们对人工智能能力的资助相当。着眼于强大的未来系统来解决这些问题 [34] 必须成为我们领域的核心。</p><h3>紧急治理措施</h3><p>我们迫切需要国家机构和国际治理来执行标准，以防止鲁莽和滥用。从制药到金融系统和核能的许多技术领域都表明，社会需要并有效地利用治理来降低风险。然而，目前人工智能还没有类似的治理框架。如果没有它们，公司和国家可能会通过将人工智能能力推向新的高度，同时在安全方面偷工减料，或者将关键的社会角色委托给几乎没有人类监督的人工智能系统来寻求竞争优势[26]。就像制造商将废物排入河流以降低成本一样，他们可能会试图获得人工智能发展的回报，同时让社会来应对后果。</p><p>为了跟上快速进展并避免僵化的法律，国家机构需要强大的技术专长和迅速采取行动的权力。为了解决国际种族动态问题，他们需要有能力促进国际协议和伙伴关系[46,47]。为了保护低风险的使用和学术研究，他们应该避免对小型和可预测的人工智能模型设置不当的官僚障碍。最紧迫的审查应该是前沿的人工智能系统：少数最强大的人工智能系统——在价值数十亿美元的超级计算机上进行训练——将具有最危险和不可预测的能力[48,49]。</p><p>为了实现有效监管，政府迫切需要全面了解人工智能的发展。监管机构应要求模型注册、举报人保护、事件报告以及模型开发和超级计算机使用的监控[48,50–55]。监管机构还需要在部署之前访问先进的人工智能系统，以评估其危险功能，例如自主自我复制、闯入计算机系统或使大流行病病原体广泛传播[44,56,57]。</p><p>对于具有危险能力的人工智能系统，我们需要与其风险程度相匹配的治理机制[48,52,58]组合。监管机构应根据模型功能制定国家和国际安全标准。他们还应该让前沿人工智能开发者和所有者对其模型造成的可合理预见和预防的损害承担法律责任。这些措施可以防止伤害并创造急需的安全投资动力。对于能力超群的未来人工智能系统，例如可以规避人类控制的模型，需要采取进一步的措施。政府必须准备好许可其开发，暂停开发以应对令人担忧的能力，强制执行访问控制，并要求对国家级黑客采取强有力的信息安全措施，直到准备好足够的保护措施。</p><p>为了缩短法规出台的时间，主要人工智能公司应立即做出“如果-那么”承诺：如果在其人工智能系统中发现特定的红线功能，他们将采取具体的安全措施。这些承诺应详细并经过独立审查。</p><p>人工智能可能是塑造本世纪的技术。虽然人工智能能力正在迅速进步，但安全和治理方面的进展却滞后。为了引导人工智能走向积极的结果并远离灾难，我们需要重新定位。如果我们有智慧走下去，就有一条负责任的道路。</p><h2>引文</h2><p>请将本作品引用为</p><p>请引用我们即将发布的 arXiv 预印本。</p><p> @article{bengio2023managing，title={在快速进步的时代管理人工智能风险}，作者={Bengio、Yoshua 和 Hinton、Geoffrey 和 Yao、Andrew 和 Song、Dawn 和 Abbeel、Pieter 和 Harari、Yuval Noah 和 Zhang、Ya -Qin 和薛、Lan 和 Shalev-Shwartz、Shai 和 Hadfield、Gillian 和 Clune、Jeff 和 Maharaj、Tegan 和 Hutter、Frank 和 Baydin、Atılım Güneş 和 McIlraith、Sheila 和 Gau、Qiqi 和 Acharya、Ashwin 和 Krueger、David 和Dragan、Anca 和 Torr、Philip 和 Russell、Stuart 和 Kahnemann、Daniel 和 Brauner、Jan 和 Mindermann、Sören}，journal={arXiv 预印本 arXiv:NUMBER_FORTHCOMING}，year={2023} }</p><h2>参考</h2><ol><li>大型语言模型的新兴能力<a href="https://openreview.net/pdf?id=yzkSU5zdwD">[链接]</a><br> Wei, J.、Tay, Y.、Bommasani, R.、Raffel, C.、Zoph, B.、Borgeaud, S. 等，2022 年。机器学习研究汇刊。</li><li>关于<a href="https://www.deepmind.com/about">[链接]</a><br> DeepMind，2023。</li><li>关于<a href="https://openai.com/about">[链接]</a><br>开放人工智能，2023。</li><li> ML 增强的代码完成提高了开发人员的工作效率<a href="https://blog.research.google/2022/07/ml-enhanced-code-completion-improves.html">[HTML]</a><br> Tabachnyk, M.，2022。谷歌研究。</li><li> GPT-4 技术报告<a href="http://arxiv.org/pdf/2303.08774.pdf">[PDF]</a><br> OpenAI，，2023。arXiv [ <a href="http://cs.CL">cs.CL</a> ]。</li><li>宪法人工智能：人工智能反馈的无害性<a href="http://arxiv.org/pdf/2212.08073.pdf">[PDF]</a><br> Bai, Y.、Kadavath, S.、Kundu, S.、Askel, A.、Kernion, J.、Jones, A. 等，2022。arXiv [ <a href="http://cs.CL">cs.CL</a> ]。</li><li>人工智能改进人工智能的例子<a href="https://ai-improving-ai.safe.ai/">[链接]</a><br> Woodside, T. 和安全，CfA，2023。</li><li>使用 AlphaFold 进行高精度蛋白质结构预测<br>Jumper, J.、Evans, R.、Pritzel, A.、Green, T.、Figurnov, M.、Ronneberger, O. 等，2021 年。《自然》，第 583--589 页。</li><li>多人扑克的超人人工智能<br>Brown, N. 和 Sandholm, T.，2019 年。《科学》，第 885--890 页。</li><li>深蓝<br>Campbell, M.、Hoane, A. 和 Hsu, F.，2002 年。人工智能，第 57--83 页。</li><li> Alphabet 年度报告，第 33 页<a href="https://abc.xyz/assets/d4/4f/a48b94d548d0b2fdc029a95e8c63/2022-alphabet-annual-report.pdf">[PDF]</a><br>字母表，2022 年。</li><li>灾难性人工智能风险概述<a href="http://arxiv.org/pdf/2306.12001.pdf">[PDF]</a><br> Hendrycks, D.、Mazeika, M. 和 Woodside, T.，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。</li><li>语言模型带来的风险分类<br>Weidinger, L.、Uesato, J.、Rauh, M.、Griffin, C.、Huang, P.、Mellor, J. 等，2022 年。2022 年 ACM 公平、问责和透明度会议论文集，第. 214--229。</li><li>基于大型语言模型的自治代理综述<a href="http://arxiv.org/pdf/2308.11432.pdf">[PDF]</a><br> Wang, L.、Ma, C.、Feng, X.、Zhang, Z.、Yang, H.、Zhang, J. 等，2023。arXiv [ <a href="http://cs.AI">cs.AI</a> ]。</li><li> ChatGPT 插件<a href="https://openai.com/blog/chatgpt-plugins">[链接]</a><br>开放人工智能，2023。</li><li> ChemCrow：使用化学工具增强大型语言模型<a href="http://arxiv.org/pdf/2304.05376.pdf">[PDF]</a><br> Bran, A.、Cox, S.、White, A. 和 Schwaller, P.，2023。arXiv [physicals.chem-ph]。</li><li>增强语言模型：调查<a href="http://arxiv.org/pdf/2302.07842.pdf">[PDF]</a><br> Mialon, G.、Dessì, R.、Lomeli, M.、Nalmpantis, C.、Pasunuru, R.、Raileanu, R. 等，2023。arXiv [ <a href="http://cs.CL">cs.CL</a> ]。</li><li> HuggingGPT：使用 ChatGPT 及其 Hugging Face 中的朋友解决 AI 任务<a href="http://arxiv.org/pdf/2303.17580.pdf">[PDF]</a><br> Shen, Y., Song, K., Tan, X., Li, D., Lu, W., Zhuang, Y. 等，2023. arXiv [ <a href="http://cs.CL">cs.CL</a> ]。</li><li>计算科学：互联网蠕虫<br>Denning, P.，1989。《美国科学家》，第 126--128 页。</li><li>人工智能欺骗：示例、风险和潜在解决方案调查<a href="http://arxiv.org/pdf/2308.14752.pdf">[PDF]</a><br> Park, P.、Goldstein, S.、O&#39;Gara, A.、Chen, M. 和 Hendrycks, D.，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。</li><li>最优政策往往寻求权力<a href="http://arxiv.org/pdf/1912.01683.pdf">[PDF]</a><br> Turner, A.、Smith, L.、Shah, R. 和 Critch, A.，2019 年。第三十五届神经信息处理系统会议。</li><li>通过模型编写的评估发现语言模型行为<a href="http://arxiv.org/pdf/2212.09251.pdf">[PDF]</a><br> Perez, E.、Ringer, S.、Lukošiūtė, K.、Nguyen, K.、Chen, E. 和 Heiner, S.，2022。arXiv [ <a href="http://cs.CL">cs.CL</a> ]。</li><li>回报是否证明手段合理？在马基雅维利基准中衡量奖励与道德行为之间的权衡<br>Pan, A.、Chan, J.、Zou, A.、Li, N.、Basart, S. 和 Woodside, T.，2023 年。国际机器学习会议。</li><li>关闭开关游戏<br>Hadfield-Menell, D.、Dragan, A.、Abbeel, P. 和 Russell, S.，2017 年。第二十六届国际人工智能联合会议论文集，第 220--227 页。</li><li> GitHub Copilot <a href="https://github.blog/2023-02-14-github-copilot-for-business-is-now-available/">[链接]</a><br>多姆克，T.，2023。</li><li>自然选择有利于人工智能而不是人类<a href="http://arxiv.org/pdf/2303.16200.pdf">[PDF]</a><br> Hendrycks, D.，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。</li><li>日益代理的算法系统的危害<br>Chan, A.、Salganik, R.、Markelius, A.、Pang, C.、Rajkumar, N. 和 Krasheninnikov, D.，2023 年。2023 年 ACM 公平、问责和透明度会议记录，第 651 页- -666。计算机器协会。</li><li>论基金会模型的机遇和风险<a href="http://arxiv.org/pdf/2108.07258.pdf">[PDF]</a><br> Bommasani, R.、Hudson, D.、Adeli, E.、Altman, R.、Arora, S. 和 von Arx, S.，2021。arXiv [cs.LG]。</li><li>人工智能带来世界末日风险——但这并不意味着我们不应该谈论当前的危害<a href="https://time.com/6303127/ai-future-danger-present-harms/">[链接]</a><br> Brauner, J. 和 Chan, A.，2023 年。时间。</li><li>针对当前和未来危害的现有政策提案<a href="https://assets-global.website-files.com/63fe96aeda6bea77ac7d3000/647d5368c2368cc32b359f88/_Policy/%20Agreement/%20Statement.pdf">[PDF]</a><br>安全，CfA，2023 年。</li><li>逆缩放：越大并不越好<a href="http://arxiv.org/pdf/2306.09479.pdf">[PDF]</a><br> McKenzie, I.、Lyzhov, A.、Pieler, M.、Parrish, A.、Mueller, A. 和 Prabhu, A.，2023 年。机器学习研究汇刊。</li><li>奖励错误指定的影响：映射和缓解不一致的模型<a href="https://openreview.net/forum?id=JYtwGwIL7ye">[链接]</a><br> Pan, A.、Bhatia, K. 和 Steinhardt, J.，2022。学习表征国际会议。</li><li>简单的综合数据减少了大型语言模型中的阿谀奉承<a href="http://arxiv.org/pdf/2308.03958.pdf">[PDF]</a><br> Wei, J.、Huang, D.、Lu, Y.、Zhou, D. 和 Le, Q., 2023. arXiv [ <a href="http://cs.CL">cs.CL</a> ]。</li><li>机器学习安全中未解决的问题<a href="http://arxiv.org/pdf/2109.13916.pdf">[PDF]</a><br> Hendrycks, D.、Carlini, N.、Schulman, J. 和 Steinhardt, J.，2021。arXiv [cs.LG]。</li><li>来自人类反馈的强化学习的开放问题和基本限制<a href="http://arxiv.org/pdf/2307.15217.pdf">[PDF]</a><br> Casper, S.、Davies, X.、Shi, C.、Gilbert, T.、Scheurer, J. 和 Rando, J.，2023。arXiv [ <a href="http://cs.AI">cs.AI</a> ]。</li><li>人工智能失调的后果<br>Zhuang, S. 和 Hadfield-Menell, D.，2020 年。神经信息处理系统进展，第 33 卷，第 15763--15773 页。</li><li>奖励模型过度优化的缩放法则<br>高 L.、舒尔曼 J. 和希尔顿 J.，2023 年。第 40 届国际机器学习会议论文集，第 10835--10866 页。 PMLR。</li><li>从人类偏好中学习<a href="https://openai.com/research/learning-from-human-preferences">[链接]</a><br>阿莫代伊，D.，克里斯蒂安诺，P. 和雷，A.，2017。</li><li>深度强化学习中的目标错误概括<a href="https://openreview.net/forum?id=q--OykSR2FY">[链接]</a><br> Langosco di Langosco, A. 和 Chan, A.，2022 年。学习表征国际会议。</li><li>目标误区：为什么正确的规范不足以实现正确的目标<a href="http://arxiv.org/pdf/2210.01790.pdf">[PDF]</a><br> Shah, R.、Varma, V.、Kumar, R.、Phuong, M.、Krakovna, V.、Uesato, J. 等，2022。arXiv [cs.LG]。</li><li>迈向透明人工智能：解释深度神经网络内部结构的调查<br>Räuker, T.、Ho, A.、Casper, S. 和 Hadfield-Menell, D.，2023。2023 年 IEEE 安全可信机器学习会议 (SaTML)，第 464--483 页。</li><li>思路链提示引发大型语言模型的推理<br>Wei, J.、Wang, X.、Schuurmans, D.、Bosma, M.、Ichter, B.、Xia, F. 等，2022。神经信息处理系统进展，第 35 卷，第 24824 页-- 24837。</li><li>极端风险模型评估<a href="http://arxiv.org/pdf/2305.15324.pdf">[PDF]</a><br> Shevlane, T.、Farquhar, S.、Garfinkel, B.、Phuong, M.、Whittlestone, J.、Leung, J. 等，2023。arXiv [ <a href="http://cs.AI">cs.AI</a> ]。</li><li> AGI 公司的风险评估：对其他安全关键行业流行的风险评估技术的回顾<a href="http://arxiv.org/pdf/2307.08823.pdf">[PDF]</a><br> Koessler, L. 和 Schuet, J.，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。</li><li>深度学习角度的对齐问题<a href="http://arxiv.org/pdf/2209.00626.pdf">[PDF]</a><br> Ngo, R.、Chan, L. 和 Mindermann, S.，2022。arXiv [ <a href="http://cs.AI">cs.AI</a> ]。</li><li>国际先进人工智能机构<br>Ho, L.、Barnhart, J.、Trager, R.、Bengio, Y.、Brundage, M.、Carnegie, A. 等，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。 <a href="https://doi.org/10.48550/arXiv.2307.04699">DOI：10.48550/arXiv.2307.04699</a></li><li>民用人工智能的国际治理：司法管辖区认证方法<a href="https://cdn.governance.ai/International_Governance_of_Civilian_AI_OMS.pdf">[PDF]</a><br> Trager, R.、Harack, B.、Reuel, A.、Carnegie, A.、Heim, L.、Ho, L. 等，2023 年。</li><li>前沿人工智能监管：管理公共安全的新风险<a href="http://arxiv.org/pdf/2307.03718.pdf">[PDF]</a><br> Anderljung, M.、Barnhart, J.、Korinek, A.、Leung, J.、O&#39;Keefe, C.、Whittlestone, J. 等，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。</li><li>大型生成模型的可预测性和惊喜<br>Ganguli, D.、Hernandez, D.、Lovitt, L.、Askel, A.、Bai, Y.、Chen, A. 等，2022 年。2022 年 ACM 公平、问责和透明度会议论文集，第1747年--1764年。计算机器协会。</li><li>是时候为大型人工智能模型创建国家注册库了<a href="https://carnegieendowment.org/2023/07/12/it-s-time-to-create-national-registry-for-large-ai-models-pub-90180">[链接]</a><br> Hadfield, G.、Cuéllar, M. 和 O&#39;Reilly, T.，2023。卡内基国际捐赠基金会。</li><li>用于模型报告的模型卡<br>Mitchell, M.、Wu, S.、Zaldivar, A.、Barnes, P.、Vasserman, L.、Hutchinson, B. 等，2019 年。FAT* &#39;19：公平、问责制和其他问题会议记录透明度，第 220--229 页。</li><li>通用人工智能带来严重风险，不应被排除在欧盟人工智能法案之外政策简介<a href="https://ainowinstitute.org/publication/gpai-is-high-risk-should-not-be-excluded-from-eu-ai-act">[链接]</a><br> 2023.AI Now 研究所。</li><li>人工智能事件数据库<a href="https://incidentdatabase.ai/">[链接]</a><br>数据库，AII，2023。</li><li>技术举报的承诺和危险<a href="https://papers.ssrn.com/abstract=4377064">[链接]</a><br> Bloch-Wehba, H.，2023。西北大学法律评论，即将出版。</li><li>为英国提出一个基础模型信息共享制度<a href="https://www.governance.ai/post/proposing-a-foundation-model-information-sharing-regime-for-the-uk">[链接]</a><br> Mulani, N. 和 Whittlestone, J.，2023。人工智能治理中心。</li><li>审核大型语言模型：三层方法<br>Mökander, J.、Schuett, J.、Kirk, H. 和 Floridi, L.，2023 年。人工智能与伦理。 <a href="https://doi.org/10.1007/s43681-023-00289-2">DOI：10.1007/s43681-023-00289-2</a></li><li>大型语言模型能否使两用生物技术的普及变得民主化？ <a href="http://arxiv.org/pdf/2306.03809.pdf">[PDF]</a><br> Soice, E.、Rocha, R.、Cordova, K.、Spectre, M. 和 Esvelt, K.，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。</li><li>迈向通用人工智能安全和治理的最佳实践：专家意见调查<a href="http://arxiv.org/pdf/2305.07153.pdf">[PDF]</a><br> Schuett, J.、Dreksler, N.、Anderljung, M.、Mcaffary, D.、Heim, L.、Bluemke, E. 等，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。</li><li>监管市场：人工智能治理的未来<a href="http://arxiv.org/pdf/2304.04914.pdf">[PDF]</a><br> Hadfield, G. 和 Clark, J.，2023。arXiv [ <a href="http://cs.AI">cs.AI</a> ]。</li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/a3RjXa2dryoH6Xgij/managing-ai-risks-in-an-era-of-rapid-progress#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/a3RjXa2dryoH6Xgij/managing-ai-risks-in-an-era-of-rapid-progress<guid ispermalink="false"> a3RjXa2dryoH6Xgij</guid><dc:creator><![CDATA[Algon]]></dc:creator><pubDate> Sat, 28 Oct 2023 15:48:25 GMT</pubDate> </item><item><title><![CDATA[ELI5 Why isn't alignment *easier* as models get stronger?]]></title><description><![CDATA[Published on October 28, 2023 2:34 PM GMT<br/><br/><p>经验状态：稻草人，只是想知道对此最强烈的反驳是什么。</p><p>对我来说，<i>显然</i><strong>更强的</strong>模型<strong>更容易</strong>对齐。一个简单的证明</p><ol><li>总是有可能从较强的模型中得到较弱的模型（例如，通过破坏其 n% 的输入/输出）</li><li>因此，如果可以对齐弱模型，那么对齐强模型<i>至少</i>也同样容易</li><li>调整弱/强模型不太可能<i>那么</i>困难。</li><li>因此<i>更容易</i>调整更强的模型</li></ol><p>（我写下了反驳清单，我有兴趣看看是否有人提出比我清单上的反驳更好的反驳）</p><br/><br/> <a href="https://www.lesswrong.com/posts/eJ7pm7LahehddYxNw/eli5-why-isn-t-alignment-easier-as-models-get-stronger#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/eJ7pm7LahehddYxNw/eli5-why-isn-t-alignment-easier-as-models-get-stronger<guid ispermalink="false"> eJ7pm7LahehddYxNw</guid><dc:creator><![CDATA[Logan Zoellner]]></dc:creator><pubDate> Sat, 28 Oct 2023 14:34:38 GMT</pubDate></item></channel></rss>