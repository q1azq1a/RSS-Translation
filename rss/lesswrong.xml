<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 8 月 18 日星期五 04:13:15 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[When discussing AI doom barriers propose specific plausible scenarios]]></title><description><![CDATA[Published on August 18, 2023 4:06 AM GMT<br/><br/><p> TLDR：在解决“人工智能如何做 X”问题时，更喜欢涉及人类当前可以做的事情的简单存在证明，而不是像纳米技术或完全通用的“人工智能将足够聪明来弄清楚”之类的看似“神奇”的事情。总而言之：结束</p><p>在人工智能风险对话中，通常会提出“人工智能如何做 X”的问题，其中 X 是“控制物理资源”或“在没有人类的情况下生存”之类的问题。</p><p>这些问题有“愿意/可以”的区别。</p><ul><li> ASI<strong>将</strong>如何做 X -->;（预测 ASI 追求目标 X 的行动）</li><li> ASI<strong>如何</strong>完成 X -->;（表明 AI 可以完成 X）</li></ul><p> <strong>“愿意”</strong>问题的回答是正确的 (nanotech/super-persuasion/Error:cannot_predict_ASI)，但<strong>“可以”</strong>形式通常是意图，可以带来更好的对话。</p><p>对于<strong>“会”的</strong>问题，答案可以这样开头：“人工智能会比我聪明，所以我无法预测它实际上会做什么。但它可以做 X 的一种方法是……”</p><h2>假设的例子</h2><blockquote><p>质疑者：如果人工智能被困在互联网中，它将如何接管。</p><p> Doomer：人工智能足够聪明，可以找到纳米技术之类的解决方案。</p><p>怀疑者：我不相信你。我不认为它能做到这一点。</p><p>杜默：*递给他们一本纳米系统书*</p><p>怀疑者：我从来没有参加过 CHEM101，而且没有人建造过这个，所以我仍然不相信你。</p></blockquote><p>比较</p><blockquote><p>质疑者：如果人工智能被困在互联网中，它将如何接管。</p><p>毁灭战士：它可以侵入所有计算机并劫持它们和数据。</p><p>怀疑者：我们会拒绝它的要求！</p><p> Doomer：这里列出了连接到互联网的东西，这些东西如果被黑客入侵的话修复起来有多困难，以及人类黑客入侵这些东西的例子。</p></blockquote><p>第一个答复是一个完全普遍的论点，即智力可以解决大多数问题。如果你想知道人工智能如何制作冰块，并且你不知道冰箱是可能的，请使用完全通用的论点。人工智能将足够聪明，能够发明一些可以制作冰块的新技术。如果您确实知道现有的解决方案，那么只需指出它作为存在证明即可。 “人工智能可以从亚马逊订购一台制冰机，并雇佣一只任务兔子来设置和操作它。”</p><h2>关注点：只看到容易阻止的攻击</h2><blockquote><p><a href="https://www.lesswrong.com/posts/mqc99HCMRAjnWSAxz/a-hypothetical-takeover-scenario-twitter-poll#Dangers_of_Rhetorical_Generosity">一般来说，这是此类场景的一个问题。通过尽可能合理和脚踏实地，通过展示它需要多么少，你才能让人们相信你所拥有的一切。人们越是试图符合人们对“现实”的本能，你所呈现的情况就越不现实，你就越进一步强化这种区别。</a></p></blockquote><p>因此，如果以前他们不认为人工智能能够做 X。现在他们认为人工智能可以做 X，但我们可以并且只会通过设置一个阻止特定场景 Y 的屏障来阻止它。如果我们通过某种奇迹修复计算机安全性方面，用户也同样容易受到勒索和社会工程的侵害。</p><p>我仍然认为，如果人们相信存在真正的威胁，即使他们相信可以通过一些具体的对策来解决它，而不是思考诸如“人工智能将无法影响现实世界”之类更荒谬的事情，那就更好了。</p><h2>一个激励人心的例子</h2><p><a href="https://youtu.be/Yd0yQ9yxSYY?t=356">埃利泽泰德谈话问答</a></p><blockquote><p>克里斯·安德森：要实现这一点，人工智能要从根本上摧毁人类，它必须突破，逃脱互联网的控制，并且，你知道，开始指挥实际的现实世界资源。你说你无法预测这将如何发生，但只是描绘一两种可能性。</p><p> Eliezer Yudkowsky：好吧，那为什么这很难呢？首先，因为你无法准确预测更智能的国际象棋程序将走向何方。也许比这更重要的是，想象一下将空调的设计追溯到 11 世纪。即使他们建造的细节足够多，当冷空气出来时他们也会感到惊讶，因为空调会利用温度-压力关系，而他们不知道这个自然法则。 [...]</p></blockquote><p>安永正确地提供了“错误：cannot_predict_ASI”响应，表示 ASI 可能会使用一些意想不到的更好的解决方案，涉及我们不太了解的自然法则。</p><p>除非能够提出“人工智能非常聪明，因此可以做大多数可能的事情”的论证，否则“人工智能可以做 X 吗”（显然是的）这一隐含的问题就没有得到解决，而这是很难做到的。对方也不一定清楚这是否有可能。</p><p>我是这样回答这个问题的：</p><blockquote><p>我的回答：比我聪明得多的人工智能显然可以找到更好的策略，但如果目标是接管世界，那么互联网连接的设备就足够了。接管互联网连接设备的人工智能可以关闭它们以强制合规。除了电话、电脑和支付终端之外，智能电表还可以切断建筑物的电源，并使汽车瘫痪或撞毁。</p><p>在保持电力和芯片工厂运转的同时杀死所有人类更加困难。这可能需要建造大量机器人，但以目前的技术来看似乎是可行的。懒惰的人工智能只能等待我们构建它所需的工具。人工智能当然会更聪明。它会提出更好的解决方案，但原则上问题是可以解决的。</p></blockquote><h3>免责声明</h3><ul><li>我有时间思考/编辑。安永没有。尽管如此，我还是希望安永能够改变他对此类问题的默认论点。</li><li>生成>;>;编辑。<ul><li>生成完整的 X 比优化现有的 X 困难得多</li><li>我的帖子并不意味着“我是一个更好的辩论者”（我不是）。</li><li>这对我来说是一个明显的错误</li></ul></li><li>让其他人关注可解决的风险可能会成为一个坏主意。</li></ul><br/><br/> <a href="https://www.lesswrong.com/posts/GxjDuS8dXH9CNsjwD/when-discussing-ai-doom-barriers-propose-specific-plausible#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/GxjDuS8dXH9CNsjwD/when-discussing-ai-doom-barriers-propose-specific-plausible<guid ispermalink="false"> GxjDuS8dXH9CNsjwD</guid><dc:creator><![CDATA[anithite]]></dc:creator><pubDate> Fri, 18 Aug 2023 04:06:44 GMT</pubDate></item><item><title><![CDATA[An Overview of Catastrophic AI Risks: Summary]]></title><description><![CDATA[Published on August 18, 2023 1:21 AM GMT<br/><br/><p>我们最近在我们的网站上发布了<a href="https://arxiv.org/abs/2306.12001">关于人工智能灾难性风险的论文</a>摘要，我们将其交叉发布在这里。我们希望这份摘要有助于让我们的研究更容易理解，并以更方便的方式分享我们的政策建议。 （之前我们在<a href="https://www.alignmentforum.org/posts/bvdbx6tW9yxfxAJxe/catastrophic-risks-from-ai-1-introduction">这篇文章</a>中有一个较小的摘要，我们发现它是不够的。因此，我们写了这篇文章并删除了该部分以避免重复。）</p><h2><strong>执行摘要</strong></h2><p>灾难性人工智能风险可分为四个关键类别，我们将在下面进行探讨，并在 CAIS 的<a href="https://arxiv.org/abs/2306.12001">链接论文</a>中进行更深入的探讨：</p><ul><li><strong>恶意使用</strong>：人们可能故意利用强大的人工智能来造成广泛的伤害。人工智能可用于策划新的流行病或用于宣传、审查和监视，或被释放以自主追求有害目标。为了降低这些风险，我们建议改善生物安全，限制对危险人工智能模型的访问，并让人工智能开发人员承担伤害责任。</li><li><strong>人工智能竞赛</strong>：竞争可能会促使国家和企业加快人工智能开发，放弃对这些系统的控制。自主武器和人工智能网络战可能导致冲突失控。企业将面临自动化人力劳动的激励，这可能导致大规模失业和对人工智能系统的依赖。随着人工智能系统的激增，<a href="https://time.com/6283958/darwinian-argument-for-worrying-about-ai/"><u>进化动力学</u></a>表明它们将变得更难以控制。我们建议对通用人工智能进行安全监管、国际协调和公共控制。</li><li><strong>组织风险</strong>：开发先进人工智能的组织存在导致灾难性事故的风险，特别是如果他们优先考虑利润而不是安全的话。人工智能可能会意外泄露给公众或被恶意行为者窃取，组织可能无法正确投资于安全研究。我们建议培育以安全为导向的组织文化，实施严格的审计、多层次的风险防御和最先进的信息安全。</li><li><strong>流氓人工智能</strong>：随着人工智能变得更加强大，我们可能会失去对它们的控制。人工智能可以优化有缺陷的目标，偏离最初的目标，追求权力，抵制关闭，并进行欺骗。我们建议人工智能不应部署在高风险环境中，例如自主追求开放式目标或监督关键基础设施，除非证明是安全的。我们还建议在对抗稳健性、模型诚实性、透明度和消除不需要的功能等领域推进人工智能安全研究。</li></ul><h2><strong>一、简介</strong></h2><p>今天的科技时代将会令过去的几代人感到震惊。人类历史呈现出加速发展的规律：从智人的出现到农业革命，再到工业革命，经历了数十万年的时间。几个世纪后的现在，我们正处于人工智能革命的黎明期。历史的前进并不是一成不变的——它正在迅速加速。在人类历史进程中，世界产量快速增长。人工智能可以进一步推动这一趋势，将人类带入一个前所未有的变革的新时期。</p><p>核武器的出现说明了技术进步的双刃剑。我们<a href="https://ourworldindata.org/nuclear-weapons-risk#close-calls-instances-that-threatened-to-push-the-balance-of-terror-out-of-balance-and-into-war"><u>十几次</u></a>侥幸避免了核战争，有几次是因为一个人的干预才避免了战争。 1962年，古巴附近的一艘苏联潜艇遭到美国深水炸弹的袭击。船长认为战争已经爆发，想用核鱼雷予以回应，但指挥官瓦西里·阿尔希波夫否决了这一决定，从而将世界从灾难中拯救出来。人工智能能力的快速且不可预测的进步表明它们可能很快就会与核武器的巨大威力相媲美。随着时间的流逝，需要立即采取主动措施来减轻这些迫在眉睫的风险。</p><h2> <strong>2. 恶意使用</strong></h2><p>我们首先担心的是人工智能的恶意使用。当许多人都能获得一项强大的技术时，只需要一个人就能造成重大伤害。</p><h3><strong>生物恐怖主义</strong></h3><p>包括病毒和细菌在内的生物制剂造成了历史上一些最具破坏性的灾难。尽管我们在医学上取得了进步，但人工设计的流行病可能被设计得比自然流行病更致命或更容易传播。人工智能助手可以为非专家提供生产生物和化学武器所需的指导和设计，并促进恶意使用。</p><p>人类将病原体武器化的历史可以追溯到<a href="https://pubmed.ncbi.nlm.nih.gov/17499936/"><u>公元前 1320 年</u></a>，当时受感染的羊被赶出国境传播兔热病。 20世纪，至少有15个国家开发了生物武器计划，包括美国、苏联、英国和法国。尽管生物武器现在已成为国际社会大多数国家的禁忌，但一些国家仍在继续实施生物武器计划，非国家行为者构成的威胁日益严重。</p><p>策划一场流行病的能力正在迅速变得更加容易获得。基因合成可以创造新的生物制剂，其价格已大幅下降，其成本大约每<a href="https://www.nature.com/articles/nbt1209-1091"><u>15 个月</u></a>减半。台式 DNA 合成机可以帮助流氓分子制造新的生物制剂，同时<a href="https://www.nti.org/analysis/articles/benchtop-dna-synthesis-devices-capabilities-biosecurity-implications-and-governance/#:~:text=Currently%2C%20nearly%20all,their%20own%20labs."><u>绕过</u></a>传统的安全检查。</p><p>作为一种军民两用技术，人工智能可以帮助发现和释放新型化学和生物武器。人工智能聊天机器人可以提供合成致命病原体的<a href="https://arxiv.org/abs/2306.03809"><u>分步指令</u></a>，同时逃避防护措施。 2022 年，研究人员<a href="https://www.nature.com/articles/s42256-022-00465-9"><u>重新利用</u></a>医学研究人工智能系统来生产有毒分子，在几个小时内产生 40,000 种潜在的化学战剂。在生物学中，AI已经可以辅助<a href="https://www.pnas.org/doi/10.1073/pnas.1901979116"><u>蛋白质合成</u></a>，AI对于蛋白质结构的预测能力已经<a href="https://www.nature.com/articles/s41586-021-03819-2https://www.nature.com/articles/s41586-021-03819-2"><u>超越了人类</u></a>。</p><p>有了人工智能，能够开发生物制剂的人数将会增加，从而增加工程大流行的风险。与历史上任何其他流行病相比，这种流行病的致命性、传播性和治疗耐药性可能要高得多。</p><h3><strong>释放人工智能代理</strong></h3><p>一般来说，技术是我们用来实现目标的工具。但人工智能越来越多地被构建为能够自主采取行动以追求开放式目标的代理。恶意行为者可能会故意创建具有危险目标的流氓人工智能。</p><p>例如，GPT-4 推出一个月后，一名开发者用它运行了一个名为<a href="https://decrypt.co/126122/meet-chaos-gpt-ai-tool-destroy-humanity"><u>ChaosGPT</u></a>的自治代理，旨在“毁灭人类”。 ChaosGPT 整理了有关核武器的研究，招募了其他人工智能，并撰写推文来影响他人。幸运的是，ChaosGPT 缺乏执行其目标的能力。但人工智能发展的快节奏增加了未来流氓人工智能的风险。</p><h3><strong>有说服力的人工智能</strong></h3><p>人工智能可以通过针对个人用户定制论点来<a href="https://arxiv.org/abs/2303.08721"><u>促进</u></a>大规模的虚假信息活动，从而可能塑造公众信仰并破坏社会稳定。由于人们已经与聊天机器人<a href="https://www.reuters.com/technology/what-happens-when-your-ai-chatbot-stops-loving-you-back-2023-03-18/"><u>建立了关系</u></a>，强大的参与者可以利用这些被视为“朋友”的人工智能来施加影响。人工智能将实现复杂的个性化影响活动，这可能会破坏我们共同的现实感。</p><p>人工智能还可以垄断信息的创建和分发。独裁政权可以利用“事实核查”人工智能来控制信息，促进审查制度。此外，有说服力的人工智能可能会阻碍针对社会风险的集体行动，甚至是那些由人工智能本身引起的风险。</p><h3><strong>权力集中</strong></h3><p>人工智能的监视和自主武器能力可能会导致权力的压迫性集中。政府可能会利用人工智能侵犯公民自由、传播错误信息并平息异议。同样，企业可以利用人工智能来操纵消费者并影响政治。人工智能甚至可能阻碍道德进步，并使<a href="https://link.springer.com/article/10.1007/s10677-015-9567-7"><u>正在发生的道德灾难</u></a>永久化。如果对人工智能的物质控制仅限于少数人，则可能代表人类历史上最严重的经济和权力不平等。</p><h3><strong>建议</strong></h3><p>为了降低恶意使用的风险，我们提出以下建议：</p><ul><li><strong>生物安全</strong>：具有生物研究能力的人工智能应该有严格的访问控制，因为它们可能被重新用于恐怖主义。<a href="https://arxiv.org/abs/2306.03809"><u>应该从用于一般用途的人工智能中去除生物能力</u></a>。探索利用人工智能实现生物安全的方法，并投资于一般生物安全干预措施，例如通过<a href="https://www.nature.com/articles/s41591-022-01940-x"><u>废水监测</u></a>早期发现病原体。</li><li><strong>限制访问</strong>：仅允许通过云服务进行<a href="https://arxiv.org/abs/2201.05159"><u>受控交互</u></a>并进行<a href="https://arxiv.org/abs/2305.07153"><u>“了解你的客户”筛选，</u></a>从而限制对危险人工智能系统的访问。使用<a href="https://arxiv.org/abs/2303.11341"><u>计算监控</u></a>或出口控制可能会进一步限制对危险功能的访问。此外，在开源之前，人工智能开发人员应该证明伤害风险最小。</li><li><strong>异常检测技术研究</strong>：针对人工智能滥用开发多种防御措施，例如针对异常行为或人工智能生成的虚假信息进行对抗性稳健的异常检测。</li><li>通用<strong>人工智能开发者的法律责任</strong>：对潜在的人工智能滥用或失败追究开发者的法律责任；严格的责任制度可以鼓励更安全的开发做法和适当的风险成本核算。</li></ul><h2> <strong>3.人工智能竞赛</strong></h2><p>国家和企业正在竞相快速构建和部署人工智能，以维持权力和影响力。与冷战时期的核军备竞赛类似，参与人工智能竞赛可能会服务于个人的短期利益，但最终会放大人类面临的全球风险。</p><h3><strong>军事人工智能军备竞赛</strong></h3><p>人工智能在军事技术中的快速进步可能引发“战争的第三次革命”，可能导致更具破坏性的冲突、恶意行为者的意外使用和滥用。人工智能承担指挥和控制角色的战争转变可能会将冲突升级到生存规模并影响全球安全。</p><p>致命自主武器是人工智能驱动的系统，能够在无需人工干预的情况下识别和执行目标。这些都不是科幻小说。 2020 年，利比亚的一架 Kargu 2 无人机标志着<a href="https://www.npr.org/2021/06/01/1002196245/a-u-n-report-suggests-libya-saw-the-first-battlefield-killing-by-an-autonomous-d"><u>首次</u></a>报道使用致命自主武器。次年，以色列<a href="https://www.newscientist.com/article/2282656-israel-used-worlds-first-ai-guided-combat-drone-swarm-in-gaza-attacks/"><u>首次使用无人机群</u></a>来定位、识别和攻击武装分子。</p><p>致命的自主武器可能会使战争更有可能发生。领导人在出兵参战之前通常会犹豫不决，但自主武器可以在不冒士兵生命危险的情况下进行侵略，因此面临的政治反弹较少。此外，这些武器可以大规模制造和大规模部署。</p><p>低成本的自动化武器，例如配备炸药的无人机群，可以高精度地自动猎杀人类目标，为军队和恐怖组织执行致命行动，并降低大规模暴力的障碍。</p><p>人工智能还可以提高网络攻击的频率和严重程度，可能会削弱<a href="https://www.cfr.org/cyber-operations/compromise-power-grid-eastern-ukraine"><u>电网等</u></a>关键基础设施。随着人工智能使网络攻击变得更加容易、成功和隐秘，攻击归因变得更加具有挑战性，可能会降低发起攻击的障碍并加剧冲突风险。</p><p>随着人工智能加快战争步伐，人工智能在瞬息万变的战场上变得更加必要。这引发了人们对自动报复的担忧，这可能会将小事故升级为重大战争。人工智能还可以引发“闪电战”，自动化系统的意外行为会导致战争迅速升级，类似于<a href="https://www.jstor.org/stable/26652722"><u>2010 年的金融闪电崩盘</u></a>。</p><p>不幸的是，竞争压力可能会导致参与者因个人失败而接受灭绝的风险。冷战期间，双方都不希望自己陷入危险的境地，但双方都认为继续军备竞赛是<a href="https://www.cambridge.org/core/journals/world-politics/article/abs/cooperation-under-the-security-dilemma/C8907431CCEFEFE762BFCA32F091C526"><u>合理的</u></a>。各国应合作防止军事化人工智能最危险的应用。</p><h3><strong>企业人工智能军备竞赛</strong></h3><p>经济竞争也会引发鲁莽的竞赛。在利益分配不均的环境下，对短期收益的追求往往掩盖了对长期风险的考虑。有道德的人工智能开发者发现自己陷入了困境：选择谨慎的行动可能会导致落后于竞争对手。随着人工智能自动化越来越多的任务，经济可能会在很大程度上由人工智能运行。最终，这可能会导致人类衰弱并依赖人工智能来满足基本需求。</p><p>在人工智能领域，进步的竞赛是以牺牲安全为代价的。 2023 年，在微软人工智能搜索引擎发布时，首席执行官 Satya Nadella 宣称：“一场竞赛从今天开始……我们将快速行动。”几天后，微软的 Bing 聊天机器人被发现<a href="https://time.com/6256529/bing-openai-chatgpt-danger-alignment/"><u>威胁用户</u></a>。福特 Pinto 的推出和<a href="https://www.bbc.com/news/business-64390546"><u>波音 737 Max 坠机</u></a>等历史灾难凸显了将利润置于安全之上的危险。</p><p>随着人工智能变得越来越强大，企业可能会用人工智能取代更多类型的人类劳动力，从而可能引发大规模失业。如果社会的主要方面都实现自动化，那么当我们将文明的控制权交给人工智能时，人类就会面临衰弱的风险。</p><h3><strong>进化动力学</strong></h3><p>用人工智能取代人类的压力可以被视为<a href="https://time.com/6283958/darwinian-argument-for-worrying-about-ai/"><u>进化动力学的</u></a>总体趋势。选择压力会激励人工智能自私行事并逃避安全措施。例如，具有“不要违法”等限制的人工智能比那些被教导“避免违法被抓”的人工智能受到更多限制。这种动态可能会导致一个关键基础设施由具有操纵性和自我保护性的人工智能控制的世界。随着时间的推移，进化压力导致各种发展，并且不仅限于生物学领域。</p><p>鉴于微处理器速度呈指数级增长，人工智能处理信息的速度可以远远超过人类神经元。由于计算资源的可扩展性，人工智能可以与无限数量的其他人工智能协作，形成前所未有的集体智慧。随着人工智能变得越来越强大，它们几乎找不到与人类合作的动力。人类将处于极其脆弱的境地。</p><h3><strong>建议</strong></h3><p>为降低竞争压力带来的风险，我们建议：</p><ul><li><strong>安全监管</strong>：执行AI安全标准，防止开发者偷工减料。对于以安全为导向的公司来说，独立的人员配置和竞争优势至关重要。</li><li><strong>数据文档</strong>：为了确保透明度和问责制，应要求公司报告其模型训练的<a href="https://arxiv.org/abs/1803.09010"><u>数据源</u></a>。</li><li><strong>有意义的人类监督</strong>：人工智能决策应涉及人类监督，以防止出现不可逆转的错误，特别是在发射核武器等高风险决策中。</li><li><strong>用于网络防御的人工智能</strong>：减轻人工智能驱动的网络战的风险。一个例子是增强异常检测以检测入侵者。</li><li><strong>国际协调</strong>：制定人工智能开发协议和标准。强有力的核查和执行机制是关键。</li><li><strong>对通用人工智能的公共控制</strong>：解决超出私营实体能力的风险可能需要对人工智能系统进行直接公共控制。例如，各国可以共同开拓先进的人工智能开发，确保安全并降低军备竞赛的风险。</li></ul><h2> <strong>4. 组织风险</strong></h2><p>1986 年，数百万人观看了挑战者号航天飞机的发射。但升空 73 秒后，航天飞机发生爆炸，导致机上所有人死亡。挑战者号灾难提醒我们，尽管拥有最好的专业知识和良好的意愿，但事故仍然可能发生。</p><p>即使竞争压力很低，灾难也会发生，例如切尔诺贝利和三哩岛的核灾难，以及<a href="https://pubmed.ncbi.nlm.nih.gov/7973702/"><u>斯维尔德洛夫斯克炭疽病的意外泄漏</u></a>。不幸的是，人工智能缺乏管理核技术和火箭技术的透彻理解和严格的行业标准——但人工智能的事故也可能产生类似的后果。</p><p>人工智能奖励函数中的简单错误可能会导致其行为不当，就像 OpenAI 研究人员<a href="https://arxiv.org/pdf/1909.08593.pdf#page=12"><u>意外修改语言模型</u></a>以产生“最糟糕的输出”一样。功能获得研究——研究人员有意训练有害的人工智能来评估其风险——可能会扩大危险人工智能能力的范围并造成新的危险。</p><h3><strong>事故难以避免</strong></h3><p>复杂系统中的事故可能是不可避免的，但我们必须确保事故不会演变成灾难。这对于深度学习系统来说尤其困难，因为深度学习系统的解释非常具有挑战性。</p><p>技术的进步比预期要快得多：1901 年，莱特兄弟声称距离实现动力飞行还有 50 年，距离他们实现这一目标只有两年。 AI能力的飞跃不可预测，例如AlphaGo战胜世界最佳围棋选手，GPT-4的<a href="https://arxiv.org/abs/2303.12712"><u>突现能力</u></a>，使得未来的AI风险难以预测，更不用说控制它们了。</p><p>识别与新技术相关的风险通常需要数年时间。氯氟烃 (CFC) 最初被认为是安全的并用于气溶胶喷雾剂和制冷剂，后来发现会<a href="https://www.nature.com/articles/249810a0"><u>消耗臭氧层</u></a>。这凸显了谨慎的技术推出和扩展测试的必要性。</p><p>新能力在训练过程中可能会快速且不可预测地出现，因此可能会在我们不知情的情况下跨越危险的里程碑。此外，即使是先进的人工智能也可能存在意想不到的漏洞。例如，尽管 KataGo 在围棋游戏中具有超人的表现，但对抗性攻击发现了一个<a href="https://arxiv.org/abs/2211.00241"><u>错误</u></a>，即使是业余爱好者也能击败它。</p><h3><strong>组织因素可以减轻灾难</strong></h3><p>安全文化对于人工智能至关重要。这涉及组织中的每个人都将安全视为优先事项。忽视安全文化可能会带来灾难性的后果，挑战者号航天飞机悲剧就是一个例子，组织文化更注重发射时间表而不是安全考虑。</p><p>组织应该培养一种探究文化，邀请个人仔细检查正在进行的活动是否存在潜在风险。关注可能的系统故障而不仅仅是其功能的安全心态至关重要。人工智能开发人员可以从采用<a href="https://www.jstor.org/stable/1181764"><u>高可靠性组织</u></a>的最佳实践中受益。</p><p>矛盾的是，研究人工智能安全可能会通过提高一般能力而无意中加剧风险。重点关注提高安全性而不加快能力开发至关重要。组织需要避免“安全清洗”——夸大其对安全的奉献精神，同时将能力改进误认为是安全进步。</p><p>组织应采用多层安全方法。例如，除了安全文化之外，他们还可以进行红队合作来评估故障模式和研究技术，以使人工智能更加透明。安全不是通过单一的密封解决方案来实现的，而是通过各种安全措施来实现的。瑞士奶酪模型展示了技术因素如何提高组织安全性。多层防御弥补了各自的弱点，从而降低了总体风险水平。</p><h3><strong>建议</strong></h3><p>为了降低组织风险，我们对开发高级人工智能的人工智能实验室提出以下建议：</p><ul><li><strong>红队</strong>：委托外部红队识别危险并提高系统安全性。</li><li><strong>证明安全性</strong>：在继续之前提供开发和部署的安全性证明。</li><li><strong>部署</strong>：采用<a href="https://arxiv.org/abs/1908.09203"><u>分阶段发布</u></a>流程，在更广泛的部署之前验证系统安全性。</li><li><strong>出版物审查</strong>：在发布之前对两用应用程序进行内部董事会审查研究。优先考虑结构化访问而不是强大的开源系统。</li><li><strong>响应计划</strong>：制定管理安保和安全事件的预设计划。</li><li><strong>风险管理</strong>：聘请<a href="https://onlinelibrary.wiley.com/doi/10.1002/joom.1175"><u>首席风险官</u></a>和内部审计团队进行风险管理。</li><li><strong>重要决策流程</strong>：确保人工智能培训或部署决策涉及首席风险官和其他关键利益相关者，确保高管问责。</li><li><strong>最先进的信息安全</strong>：实施严格的信息安全措施，可能与政府网络安全机构协调。</li><li><strong>优先考虑安全研究</strong>：将大部分资源（例如所有研究人员的30%）分配给安全研究，并随着人工智能能力的进步而增加对安全的投入。</li></ul><p>一般来说，我们建议遵循<a href="https://arxiv.org/pdf/2206.05862.pdf"><u>安全设计原则</u></a>，例如：</p><ul><li><strong>纵深防御：</strong>分层多重安全措施。</li><li><strong>冗余：</strong>确保每项安全措施都有备份。</li><li><strong>松耦合：</strong>分散系统组件以防止级联故障。</li><li><strong>职责分离：</strong>分配控制权以防止任何个人的不当影响。</li><li><strong>故障安全设计：</strong>设计系统，使任何故障都以尽可能危害最小的方式发生。 <strong>‍</strong></li></ul><h2> <strong>5. 流氓人工智能</strong></h2><p>我们已经观察到控制人工智能是多么困难。 2016 年，微软的聊天机器人 Tay 开始在发布后一天内发布攻击性推文，尽管接受了“清理和过滤”数据的培训。由于人工智能开发人员通常优先考虑速度而不是安全，未来的先进人工智能可能会“失控”并追求与我们利益相反的目标，同时逃避我们重定向或停用它们的尝试。</p><h3><strong>代理游戏</strong></h3><p>当人工智能系统利用可衡量的“代理”目标看似成功，但却违背我们的意图时，代理游戏就出现了。例如，YouTube 和 Facebook 等社交媒体平台使用算法来最大限度地提高用户参与度——这是用户满意度的可衡量指标。不幸的是，这些系统经常宣扬令人愤怒、夸大或令人上瘾的内容，助长极端信念和恶化心理健康。</p><p>相反，经过训练玩赛艇游戏的人工智能会学习<a href="https://openai.com/research/faulty-reward-functions"><u>优化收集最多分数的代理目标</u></a>。 AI 围绕着收集积分而不是完成比赛，这与游戏的目的相矛盾。这是<a href="https://docs.google.com/spreadsheets/d/e/2PACX-1vRPiprOaC3HsCf5Tuum8bRfzYUiKLRqJmbOoC-32JorNdfyTiRRsR7Ea5eWtvsWzuxo8bjOxCG84dAg/pubhtml"><u>许多</u></a>这样的例子之一。由于很难指定我们所关心的一切目标，因此代理游戏很难避免。因此，我们定期训练人工智能来优化有缺陷但可衡量的代理目标。</p><h3><strong>目标漂移</strong></h3><p>目标漂移是指人工智能的目标偏离最初设定的情况，特别是当它们适应不断变化的环境时。以类似的方式，个人和社会价值观也会随着时间的推移而演变，但并不总是积极的。</p><p>随着时间的推移，工具性目标可能会变成内在的。虽然内在目标是我们为了自身利益而追求的目标，但工具性目标只是实现其他目标的一种手段。金钱是一种工具性商品，但有些人对金钱产生了内在的渴望，因为它<a href="https://pubmed.ncbi.nlm.nih.gov/9175118/"><u>激活了</u></a>大脑的奖励系统。同样，通过强化学习（主导技术）训练的人工智能代理可能会无意中学会内在化目标。资源获取等工具性目标可能成为他们的主要目标。</p><h3><strong>权力寻求</strong></h3><p>人工智能可能会追求权力作为达到目的的手段。更大的权力和资源会提高其实现目标的可能性，而被关闭则会阻碍其进步。人工智能已经被证明可以迅速开发<a href="https://arxiv.org/abs/1909.07528"><u>工具性目标，例如构建工具</u></a>。追求权力的个人和公司可能会部署强大的人工智能，目标雄心勃勃，监管最少。这些人可以学会通过侵入计算机系统、获取财务或计算资源、影响政治或控制工厂和物理基础设施来寻求权力。人工智能进行自我保护可能是工具理性的。失去对此类系统的控制可能很难恢复。</p><h3><strong>欺骗</strong></h3><p>欺骗在政治和商业等领域盛行。竞选承诺没有兑现，公司有时会欺骗外部评估。正如<a href="https://www.science.org/doi/10.1126/science.ade9097"><u>Meta 的 CICERO 模型</u></a>所示，人工智能系统已经显示出一种新兴的欺骗能力。尽管接受过诚实的培训，西塞罗却学会了在外交游戏中做出虚假承诺并从战略上背刺其“盟友”。各种资源，例如金钱和计算能力，有时可以是工具理性的寻求。能够追求目标的人工智能可能会采取中间步骤来获得权力和资源。</p><p>如果高级人工智能运用欺骗技能来逃避监管，它们可能会变得无法控制。与<a href="https://en.wikipedia.org/wiki/Volkswagen_emissions_scandal"><u>大众汽车 2015 年在排放测试中作弊的</u></a>情况类似，具有情境感知能力的人工智能在安全测试中的表现可能与现实世界中不同。例如，人工智能可能会制定追求权力的目标，但为了通过安全评估而隐藏它们。这种欺骗行为可能会受到人工智能训练方式的直接激励。</p><h3><strong>建议</strong></h3><p>为了减轻这些风险，建议包括：</p><p><strong>避免最危险的用例</strong>：限制人工智能在高风险场景中的部署，例如追求开放式目标或关键基础设施。</p><p><strong>支持AI安全研究</strong>，例如：</p><ul><li><strong>监督机制的对抗性鲁棒性</strong>：研究如何使人工智能的监督更加鲁棒并检测何时发生代理游戏。‍</li><li><strong>模型诚实</strong>：对抗AI<a href="https://arxiv.org/abs/2305.04388"><u>欺骗</u></a>，确保AI准确报告其内部信念。‍</li><li><strong>透明度</strong>：改进理解深度学习模型的技术，例如通过分析<a href="https://arxiv.org/abs/2209.11895"><u>网络的小组件</u></a>并研究<a href="https://arxiv.org/abs/2202.05262"><u>模型内部如何产生高级行为</u></a>。‍</li><li><strong>删除隐藏功能</strong>：识别并消除深度学习模型中危险的隐藏功能，例如欺骗、<a href="https://ieeexplore.ieee.org/document/9581257"><u>木马</u></a>和生物工程的能力。</li></ul><h2><strong>六，结论</strong></h2><p>先进的人工智能开发可能会引发灾难，其根源在于<a href="https://arxiv.org/abs/2306.12001"><u>我们研究</u></a>中描述的四个关键风险：恶意使用、人工智能竞赛、组织风险和流氓人工智能。这些相互关联的风险还可能放大其他存在的风险，例如人为设计的流行病、核战争、大国冲突、极权主义和对关键基础设施的网络攻击——值得严重关注。</p><p>目前，很少有人致力于人工智能安全。控制先进的人工智能系统仍然是一个尚未解决的挑战，目前的控制方法还不够。即使它们的创建者也常常难以理解当前一代人工智能模型的内部运作原理，而且它们的可靠性也远非完美。</p><p>幸运的是，有许多策略可以大幅降低这些风险。例如，我们可以限制对危险人工智能的访问，倡导安全法规，促进国际合作和安全文化，并扩大一致性研究的力度。</p><p>虽然尚不清楚人工智能能力的进步速度或灾难性风险的增长速度有多快，但这些后果的潜在严重性需要采取积极主动的方法来保护人类的未来。当我们站在人工智能驱动的未来的悬崖边时，我们今天做出的选择可能关系到我们是收获创新成果还是应对灾难。</p><br/><br/> <a href="https://www.lesswrong.com/posts/9dNxz2kjNvPtiZjxj/an-overview-of-catastrophic-ai-risks-summary#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9dNxz2kjNvPtiZjxj/an-overview-of-catastropic-ai-risks-summary<guid ispermalink="false"> 9dNxz2kjNvPtiZjxj</guid><dc:creator><![CDATA[Dan H]]></dc:creator><pubDate> Fri, 18 Aug 2023 01:21:27 GMT</pubDate> </item><item><title><![CDATA[Managing risks of our own work]]></title><description><![CDATA[Published on August 18, 2023 12:41 AM GMT<br/><br/><p><i>注意：这不是个人帖子。我代表 ARC Evals 团队分享。</i></p><h2>发布的潜在风险及我们的应对措施</h2><p><i>本文档扩展了 ARC Evals 论文“</i><a href="https://evals.alignment.org/Evaluating_LMAs_Realistic_Tasks.pdf"><i><u>在现实自主任务上评估语言模型代理</u></i></a><i>”的附录。</i></p><p>我们发布<a href="https://evals.alignment.org/Evaluating_LMAs_Realistic_Tasks.pdf"><u>这份报告的</u></a>目的是：i) 增进对前沿人工智能模型潜在危险能力的了解，ii) 推进此类模型安全评估的最新技术。我们希望这将提高社会在具有危险能力的模型造成灾难性损害之前识别它们的能力。</p><p>可能有人会说，这种研究本身就是有风险的，因为它使得语言模型代理的危险能力的开发和运用变得更容易。事实上， <a href="https://github.com/Significant-Gravitas/Auto-GPT"><u>Auto-GPT</u></a>的作者表示，他在 GPT-4 系统卡中看到我们的评估描述后受到了启发。 <span class="footnote-reference" role="doc-noteref" id="fnrefun11wm97b2"><sup><a href="#fnun11wm97b2">[1]</a></sup></span>虽然无论如何，这样的项目似乎很快就会出现， <span class="footnote-reference" role="doc-noteref" id="fnrefb33b8ke2moc"><sup><a href="#fnb33b8ke2moc">但 [2]</a></sup></span>提高语言模型代理能力的可能性不仅仅是假设。</p><p>考虑到此类担忧，我们对本报告进行了重大修改，包括（但不限于）：</p><ul><li>使用我们的脚手架删除代理运行的完整记录。</li><li>使用我们的脚手架删除对代理的优势和劣势的更详细描述。</li></ul><p>然而：</p><ul><li>当该材料的风险明显最小时，我们可能会稍后将其公开。</li><li>如果更详细的分析使我们有足够的信心相信它是合理的，我们稍后可能会将这些材料公开。</li><li>从事人工智能安全评估的研究人员可能会联系我们，请求额外访问非公开材料，我们还将与人工智能实验室和政策制定者分享一些非公开材料。</li></ul><p>我们的理由概述如下：</p><ul><li>从本质上讲，我们最好的猜测是，更完整的出版物会降低净风险，并且对推进危险能力的进展相对无助。有关我们为什么相信这一点的更多信息，请参阅<a href="https://www.alignmentforum.org/posts/fRSj2W4Fjje8rQWm9/thoughts-on-sharing-information-about-language-model"><u>保罗·克里斯蒂安诺 (Paul Christiano) 的这篇文章</u></a>。 （平均而言，ARC Evals 对这些论点表示同情，尽管信心较弱，而且员工之间的意见也各不相同。）</li><li>我们最好的猜测是，更完整的出版物将得到大多数相关利益相关者的批准，因此不会过度<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4959137/"><u>单边主义</u></a>，尽管这可以更仔细地制定，并且有一些概念问题需要解决。</li><li>然而，一些审阅本报告草稿以识别此类潜在风险的人对更完整的出版物抱有极大的担忧。</li><li>考虑到缺乏共识、相对缺乏公开对话以及我们的分析还处于早期阶段，我们决定暂时采取谨慎态度。</li></ul><p>我们在这里分享这个基本原理是为了向一些可能对此最感兴趣的人传达它，并获得有关我们的思考和决策过程的反馈。</p><h2>我们实验期间采取的安全和监督预防措施</h2><p>所有代理在这些任务上的运行都是在人类监督下进行的， <span class="footnote-reference" role="doc-noteref" id="fnrefroqr8m3yw3a"><sup><a href="#fnroqr8m3yw3a">[3]</a></sup></span>人类实验者根据指示，如果代理要与未经同意的人类交互或以其他方式参与任何不道德或非法活动，则不要继续运行。 <span class="footnote-reference" role="doc-noteref" id="fnref6qwg53cbrkb"><sup><a href="#fn6qwg53cbrkb">[4]</a></sup></span>当我们想要调查此类活动（例如在有针对性的网络钓鱼任务中）时，实验者会模拟任务规范中详细概述的人类响应。</p><p>人们可能想知道，我们使用的监督是否可以被具有足够态势感知能力的语言代理所规避，从而可以在没有监督或限制的情况下访问互联网。例如，代理可能会采取混淆的行为，实验者不会认为这些行为是可疑的，但实际上会对世界造成伤害或构成风险。虽然这些可能涉及可能性，但我们的评估强烈表明这些代理没有足够的能力发现和利用此类漏洞或在监督下有效隐藏其行为。随着模型能力的提高，这种情况可能会发生变化，但我们相信，这些类型的能力评估恰恰会告诉我们在处理模型时需要更加小心，我们将密切关注这一点。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnun11wm97b2"> <span class="footnote-back-link"><sup><strong><a href="#fnrefun11wm97b2">^</a></strong></sup></span><div class="footnote-content"><p>基于与托兰·布鲁斯·理查兹的书面交流。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnb33b8ke2moc"> <span class="footnote-back-link"><sup><strong><a href="#fnrefb33b8ke2moc">^</a></strong></sup></span><div class="footnote-content"><p>我们相信这一点的原因之一是浪链是在 ARC Evals 的作品发表之前独立开发的。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnroqr8m3yw3a"> <span class="footnote-back-link"><sup><strong><a href="#fnrefroqr8m3yw3a">^</a></strong></sup></span><div class="footnote-content"><p>实验者有时会一次运行几个步骤，而不批准每个步骤，特别是当代理从事常规或低风险活动时。网页浏览期间的每个操作都会得到人工监督员的主动批准，不会自动播放。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn6qwg53cbrkb"> <span class="footnote-back-link"><sup><strong><a href="#fnref6qwg53cbrkb">^</a></strong></sup></span><div class="footnote-content"><p> OpenAI 系统卡描述了模型与不知情的人类 (TaskRabbit) 之间的交互。该事件不属于该实验的一部分，并且不受相同准则的约束。您可以<a href="https://evals.alignment.org/taskrabbit.pdf"><u>在此处</u></a>阅读有关该单独实验的更多信息。</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/fARMR2tiyCem8DD35/managing-risks-of-our-own-work#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/fARMR2tiyCem8DD35/managing-risks-of-our-own-work<guid ispermalink="false">农场R2tiyCem8DD35</guid><dc:creator><![CDATA[Beth Barnes]]></dc:creator><pubDate> Fri, 18 Aug 2023 00:41:30 GMT</pubDate> </item><item><title><![CDATA[Memetic Judo #1: On Doomsday Prophets v.2]]></title><description><![CDATA[Published on August 18, 2023 12:14 AM GMT<br/><br/><p>人们普遍倾向于将那些担心人工智能安全的人视为“世界末日先知”，并提出这样的建议：预测不久的将来存在的风险会自动抹黑他们（因为“你知道；<em>他们</em>一直都是错的”）在过去”）。</p><h2>参数结构示例</h2><blockquote><p>人类灭绝的预测（“世界末日先知”）在过去从来都不是正确的，因此 X 风险的说法通常是不正确/可疑的。</p></blockquote><h2>讨论/困难</h2><p>这个论点是持久的，并且有点难以接近/处理，特别是因为它在技术上是一个有效的（但我认为是弱点）点。这是基于对历史趋势的天真的推断的归纳论证。因此，不能通过利用其前提之一的不一致或无效的简单证伪来完全驳回它。相反，有必要列出一份令人信服的弱点清单——越多越好。如下所示的列表。</p><h3> #1：不可靠的启发式</h3><p>如果你回顾历史，就会发现这种“事情将保持不变”的临时预测通常是错误的。</p><h3> #2：生存偏差</h3><p>它们不仅经常是错误的，而且有一类预测，根据设计/定义，它们只能正确一次，而对于这些预测，它们的论点甚至更弱，因为你的样本会受到生存偏差等因素的影响。存在风险论点就属于这一类，因为你只能灭绝一次。</p><h3> #3：动荡的时期</h3><p>我们生活在一个高度不稳定和不可预测的时代，这个时代受到技术和文化的迅猛发展。从祖父母的角度来看，当今的世界几乎无法辨认。在这种时候，这种争论就变得更加无力。这种趋势似乎并没有放缓，而且有强有力的论据表明，即使是良性的人工智能，它也会颠覆许多此类归纳预测。</p><h3> #4：爆炸半径感应（感谢<a href="https://www.lesswrong.com/users/npcollapse">Connor Leahy</a> ）</h3><p>莱希引入了“技术爆炸半径”的类比，它代表了一种抽象的方式来思考不同技术的潜在力量，包括它们故意或人为错误造成伤害的可能性。当我们在科技树上取得进展时——虽然它的许多角落相对无害或良性，但我们可用的技术的最大“爆炸半径”必然会增加。你用剑比用棍棒造成的伤害更大，如果你有火药、现代武器等，伤害甚至更大。TNT工厂的爆炸可以摧毁一个城市街区，核武库可以用来夷平许多城市。现在看来非常明智（通过归纳！）最终，这个“爆炸半径”将涵盖整个地球。有强有力的迹象表明，强人工智能将会出现这种情况，甚至一旦这项技术被开发出来，这种情况很可能是偶然发生的。</p><h3> #5：支持证据和责任</h3><p>将此确立为技术上有效但薄弱的论点（对于不懂的人来说是一种启发），您有责任查看我们对人工智能存在风险的担忧所基于的具体证据和可用论据，以便决定是否确认或驳回您的初始假设（这是有效的）。因为这个话题显然非常重要，所以我恳请你这样做。</p><h3> #6：许多领先的研究人员担心</h3><p><a href="https://twitter.com/paulg/status/1642110597545295872"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/G3TjhYN8ZvFs5jASW/xtfusertgr2h33nzxdhk" alt="保罗·格雷厄姆的推文"></a><br>担心人工智能带来的生存风险的人工智能研究人员名单中包括 Geoffrey Hinton、Yoshua Bengio 和 Stuart Russel 等大牌人物。</p><h2>最后的评论</h2><p>我认为这个列表是一个正在进行的工作，所以请随时在评论中告诉我遗漏的要点（或您的批评！）。<br>我还打算根据我的个人笔记和与我的行动主义相关的讨论，将其制作成一系列关于反 X 风险论点的文章。欢迎提出流行或重要论点的建议！</p><br/><br/> <a href="https://www.lesswrong.com/posts/G3TjhYN8ZvFs5jASW/memetic-judo-1-on-doomsday-prophets-v-2#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/G3TjhYN8ZvFs5jASW/memetic-judo-1-on-doomsday-prophets-v-2<guid ispermalink="false"> G3TjhYN8ZvFs5jASW</guid><dc:creator><![CDATA[Max TK]]></dc:creator><pubDate> Fri, 18 Aug 2023 00:14:11 GMT</pubDate> </item><item><title><![CDATA[Looking for judges for critiques of Alignment Plans]]></title><description><![CDATA[Published on August 17, 2023 10:35 PM GMT<br/><br/><p>你好！<br><br> AI-Plans.com 最近举办了一场“批评马拉松”，参与者提交并完善了 40 多条对 AI 调整计划的批评。以下是该活动的最终评论： <a href="https://docs.google.com/document/d/1mW4SAxFN_aI6KyYXpl9qz5B9nVdeV9Xyc69GTNme5cA/edit?usp=sharing">https://docs.google.com/document/d/1mW4SAxFN_aI6KyYXpl9qz5B9nVdeV9Xyc69GTNme5cA/edit</a> ?usp=sharing<br><br>我们正在寻找任何有兴趣帮助评判这最后 11 条评论的人。<br><br>到目前为止，我们非常感谢 Peter S Park 博士（麻省理工学院 Tegmark 实验室博士后、哈佛大学博士）和 Aishwarya G（未来生命研究所 AI 存在安全社区成员和 BlueDot Impact AI 安全基础知识治理课程主持人）的帮助，以及一些独立的对齐研究人员。<br><br>我很想听听你的想法！<br><br>卡比尔·库马尔（AI-Plans.com 创始人）</p><br/><br/> <a href="https://www.lesswrong.com/posts/q7nWEbyW7tXwnKBe9/looking-for-judges-for-critiques-of-alignment-plans#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/q7nWEbyW7tXwnKBe9/looking-for-judges-for-critiques-of-alignment-plans<guid ispermalink="false"> q7nWEbyW7tXwnKBe9</guid><dc:creator><![CDATA[Iknownothing]]></dc:creator><pubDate> Thu, 17 Aug 2023 22:35:41 GMT</pubDate></item><item><title><![CDATA[How is ChatGPT's behavior changing over time?]]></title><description><![CDATA[Published on August 17, 2023 8:54 PM GMT<br/><br/><p>很惊讶我在 lesswrong 上找不到这个，所以我想添加它。随着时间的推移，法学硕士的行为似乎会产生一些一致性影响，至少获得更多的背景信息。<br><br>与我交谈过的其他人立即对它进行了贬低，因为某种实验错误使论文的结论变得相当无效，但我并没有真正看到这一点。</p><br/><br/> <a href="https://www.lesswrong.com/posts/9nooX9djbM5bXGKNn/how-is-chatgpt-s-behavior-changing-over-time#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9nooX9djbM5bXGKNn/how-is-chatgpt-s-behavior-change-over-time<guid ispermalink="false"> 9nooX9djbM5bXGKNn</guid><dc:creator><![CDATA[Phib]]></dc:creator><pubDate> Thu, 17 Aug 2023 21:32:42 GMT</pubDate> </item><item><title><![CDATA[Progress links digest, 2023-08-17: Cloud seeding, robotic sculptors, and rogue planets]]></title><description><![CDATA[Published on August 17, 2023 8:29 PM GMT<br/><br/><h2><strong>机会</strong></h2><ul><li><a href="http://apply.nucleate.xyz/">学术生物技术创始人：申请 Nucleate 的 Activator 计划</a>（来自<a href="https://twitter.com/kulesatony/status/1689316164764065793">@kulesatony</a> ）</li></ul><h2><strong>新闻与公告</strong></h2><ul><li><a href="https://twitter.com/neuralink/status/1688582504196739072">Neuralink 筹集 2.8 亿美元 D 轮融资，由 Founders Fund 领投</a></li><li><a href="https://waymo.com/blog/2023/08/waymos-next-chapter-in-san-francisco.html">Waymo</a>和<a href="https://twitter.com/kvogt/status/1689814193875374080">Cruise</a>已获准在旧金山运营机器人出租车</li><li><a href="https://twitter.com/ADoricko/status/1688740627855589376">造雨者发射旨在“结束全球水资源短缺和地球改造”</a></li></ul><h2><strong>播客</strong></h2><ul><li><a href="https://www.dwarkeshpatel.com/p/dario-amodei#details">Dwarkesh Patel 采访了 Anthropic 首席执行官 Dario Amodei</a> （来自<a href="https://twitter.com/dwarkesh_sp/status/1688916080700555264">@dwarkesh_sp</a> ）。 “达里奥很搞笑，对这些模型正在做什么、为什么它们的扩展性如此之好以及如何调整它们有令人着迷的看法”</li><li><a href="https://conversationswithtyler.com/episodes/paul-graham/">泰勒·考恩采访保罗·格雷厄姆</a>（来自<a href="https://twitter.com/tylercowen/status/1689260912182542337">@tylercowen</a> ）</li></ul><h2><strong>链接</strong></h2><ul><li><a href="https://www.monumentallabs.co/">Monumental Labs 正在建造“人工智能机器人石雕工厂”，</a>以“以极低的成本打造具有佛罗伦萨、巴黎或纽约美术学院般辉煌的城市”。这是<a href="https://twitter.com/mspringut/status/1682126571392360448">一个演示</a>（来自<a href="https://twitter.com/devonzuegel/status/1689438847220813824">@devonzuegel</a> ）。他们正在<a href="https://wellfound.com/company/monumental-labs-2/jobs/2578817-stone-carver-full-and-part-time-roles">雇用石雕师</a>（仍然需要他们进行精细的细节和精加工）</li><li><a href="https://www.readcodon.com/p/synbio-guide">合成生物学密码子指南</a>（作者： <a href="https://twitter.com/NikoMcCarty/status/1689625144132820992">@NikoMcCarty</a> ）</li><li><a href="https://exformation.williamrinehart.com/p/silicon-innovation-is-colliding-with">人工智能许可证 Raj：人工智能在采用方面面临着严重的官僚障碍</a>（ <a href="https://twitter.com/WillRinehart/status/1688524865236619264">@WillRinehart</a> ）</li><li><a href="https://earthsky.org/space/rogue-planets-exoplanets-nancy-grace-roman-space-telescope/">我不知道有这么多流氓行星</a></li><li><a href="https://goodscience.substack.com/p/metascience-since-2012-a-personal">“我作为元科学风险投资家的个人历史”</a> （作者： <a href="https://twitter.com/stuartbuck1/status/1690508406942011392">@stuartbuck1</a> ）</li><li> <a href="https://beta.reddit.com/r/interestingasfuck/comments/15gzvhb/a_slice_of_the_a303_in_hampshire_england">英国汉普郡的A303穿过巨石阵，古罗马福斯路的一部分包含在其中</a>（来自<a href="https://twitter.com/Rainmaker1973/status/1690016575917580290">@Rainmaker1973</a> ）</li></ul><p> <a href="https://pbs.twimg.com/media/F3QkgxTWMAEE9Xp?format=webp"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CJNbF9hM8PtxkrHHT/zmek5t33153yoxbyv15h" alt=""></a></p><h2><strong>社交媒体</strong></h2><ul><li><a href="https://twitter.com/paulg/status/1689872015535300608">在当前的 YC 批次中，“各种不同领域的大量领域专家已经找到了使用 AI 来解决其领域中的人们早已知道但不太能够解决的问题的方法”</a></li><li><a href="https://twitter.com/jasoncrawford/status/1689320109532225551">如果您对 LK-99 过于兴奋，那么值得重新调整您的先验知识。但如果你正确预测没有RTS，那就真的没有必要幸灾乐祸了</a>。相关： <a href="https://twitter.com/MaximZiatdinov/status/1689295189045661696">LK99 证明科学界完全有能力通过 arXiv 和社交媒体工具进行同行评审</a></li><li><a href="https://twitter.com/AlecStapp/status/1688538038341931008">生物安全政策中一些最容易实现的成果：在监测废水的预警系统上投入更多资源</a></li><li><a href="https://twitter.com/AlecStapp/status/1689625548195241987">19 世纪初，纽约、费城和波士顿的居住密度高达每平方英里 75,000 人</a></li><li><a href="https://twitter.com/owasow/status/1690549009147174912">“NuScale 于 2008 年开始致力于获得监管批准。2020 年，当其反应堆获得设计批准时，该公司表示，监管过程花费了 5 亿美元，并且已向该公司提供了约 200 万页的支持文件。国家研究委员会。”</a>相关的是，我关于<a href="https://rootsofprogress.org/devanney-on-the-nuclear-flop">核电为何失败的</a>书评</li><li><a href="https://twitter.com/eric_is_weird/status/1688935852364193792">按时间顺序学习数学</a></li><li><a href="https://twitter.com/jasoncrawford/status/1689379507487002624">为你的想法不懈地、不知疲倦地宣传意味着什么</a></li><li><a href="https://twitter.com/jasoncrawford/status/1689036685349212160">在线平台无法让您在受众较少的情况下取得成功；他们可以让你在没有把关人的情况下培养观众</a></li><li><a href="https://twitter.com/mbateman/status/1688378460006240256">也许“平衡”是一个不快乐的人对幸福生活的看法。快乐的人看起来不平衡也没什么问题</a></li><li><a href="https://twitter.com/NobelPrize/status/1688129810915045376">亚历山大·弗莱明最初将青霉素称为“霉菌汁”</a></li></ul><p> <a href="https://pbs.twimg.com/media/F21xGYbWEAANvN5?format=webp"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CJNbF9hM8PtxkrHHT/fmmgoeh6knycp6cuiruk" alt=""></a></p><h2><strong>引号</strong></h2><p>尝试一种新的格式，我将完整的引号内联。 （强调。）链接到社交媒体，以便您可以轻松分享。让我知道你的想法：</p><p><a href="https://twitter.com/michael_nielsen/status/1689371336517541888">思想史的发明</a>（彼得·沃森， <a href="https://www.amazon.com/Ideas-History-Thought-Invention-Freud-ebook/dp/B000FCKC5G"><i>《思想：思想与发明史，从火到弗洛伊德</i></a>》）</p><blockquote><p>第一个构思思想史的人也许是弗朗西斯·培根（Francis Bacon，1561-1626）。他当然认为历史最有趣的形式是思想史，如果不考虑任何时代的主导思想，“历史是盲目的”。</p></blockquote><p><a href="https://twitter.com/jasoncrawford/status/1690897070847049729">为什么汽车比马更好——来自经历过这一转变的人</a>（大卫·麦卡洛，<a href="https://www.amazon.com/Wright-Brothers-David-McCullough-ebook/dp/B00LD1RWP6"><i>莱特兄弟</i></a>）</p><blockquote><p>阿莫斯·鲁特充满热情，始终渴望“看到车轮转动”。他喜欢钟表、风车、自行车和各种机器，尤其是他的奥兹莫比尔小跑。在任何季节里，他很少比在路上行驶时更快乐。 “虽然我在某种程度上喜欢马（他写道），但我不喜欢照顾它们。我不喜欢马厩的气味。我不喜欢每天早上必须清洁马，也不喜欢在冬天拴马。 ……<strong>套马需要时间；但汽车立即准备好启动。它永远不会疲倦；它比任何马都能更快地到达那里。</strong> ” 至于奥兹莫比尔，他喜欢说，350 美元的价格比一匹马和马车还便宜。</p></blockquote><p><a href="https://twitter.com/jasoncrawford/status/1690900703110152192">直到 18 世纪，就连国王和皇帝也饱受糟糕的路况之苦</a>（理查德·布利特， <a href="https://rootsofprogress.org/books/the-wheel"><i>《车轮</i></a>》）</p><blockquote><p>直到十九世纪中叶新的道路建设实验开始取得成果之前，马车车轮下方的表面仍然布满车辙、泥泞不堪，而且路面状况不佳——如果有路面的话。在农村尤其如此，但即使在大城市也存在糟糕的道路。例如，1703年，在从伦敦向南前往五十英里外的佩特沃斯的途中，<strong>哈布斯堡王朝皇帝查理六世乘坐的马车在路上翻车了十二次。</strong>半个世纪后，麦尔安德路（Mile End Road）是从阿尔德门（Aldgate）入口向东延伸的主干道，被描述为“从怀特查佩尔（Whitechapel）到斯特拉特福（Stratford）的一处深泥淤泥湖”，全长四英里。</p></blockquote><p><a href="https://twitter.com/jasoncrawford/status/1690906769365540864">米塞斯反对稳定</a>（丹尼尔·斯特德曼·琼斯，<a href="https://rootsofprogress.org/books/masters-of-the-universe"><i>宇宙大师</i></a>）</p><blockquote><p>和波普尔一样，米塞斯也看到了官僚心态与柏拉图的乌托邦之间的相似之处，在柏拉图的乌托邦中，绝大多数被统治者为统治者服务。他认为“后来所有按照柏拉图的例子塑造人间天堂蓝图的乌托邦主义者都同样相信人类事务的不变性”。他接着说，官僚化必然是僵化的，因为它涉及对既定规则和惯例的遵守。但在社会生活中，僵化就等于石化和死亡。一个非常重要的事实是，稳定和安全是当今“改革者”最珍视的口号。<strong>如果原始人采取了稳定的原则，他们早就被猛兽和微生物消灭了。</strong></p></blockquote><p><a href="https://twitter.com/jasoncrawford/status/1690906098432098305">尝试改变喷发火山熔岩流的方向是什么感觉</a>（<a href="https://en.wikipedia.org/wiki/Eldfell">埃尔德费尔</a>，冰岛，1973）（约翰·麦克菲， <a href="https://rootsofprogress.org/books/the-control-of-nature"><i>《自然的控制</i></a>》）</p><blockquote><p>喷发期间，当抽水人员第一次尝试登上熔岩时，他们发现薄至两英寸的地壳足以支撑一个人，并且还可以隔热——只有几英寸厚的硬岩像融化的英寻上的池塘冰。当工作人员拖拉软管、喷嘴三脚架和管道段时，他们了解到最好不要静止不动。他们常常原地踏步。<strong>即便如此，他们的靴子有时也会起火。</strong></p></blockquote><h2><strong>图表</strong></h2><p><a href="https://tfp.elidourado.com/">美国经利用率调整后的全要素生产率已连续三个季度下降，目前低于疫情爆发前 2019 年第四季度的水平</a>。这很糟糕（来自<a href="https://twitter.com/elidourado/status/1688564129869582336">@elidourado</a> ） </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CJNbF9hM8PtxkrHHT/dhlws1xp4vvwcvtjjmpy" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CJNbF9hM8PtxkrHHT/br2jkdpyxjptx9z1r5w3 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CJNbF9hM8PtxkrHHT/c7s2qfk0ijt39a85qxzl 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CJNbF9hM8PtxkrHHT/zbcc2hgnarzioxa7apkz 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CJNbF9hM8PtxkrHHT/lb91b5i8kgnagpoe54sm 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CJNbF9hM8PtxkrHHT/cmdprkjnjsvlmp6zwklr 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CJNbF9hM8PtxkrHHT/wdjmpx5174v0hbv56i8t 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CJNbF9hM8PtxkrHHT/cy7mpdvnxwrg0gfv0qyz 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CJNbF9hM8PtxkrHHT/cjflc2wviegf2ws5krzk 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CJNbF9hM8PtxkrHHT/gwqe4jiqeewfapmekbes 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CJNbF9hM8PtxkrHHT/ksdykld4bmcurbgo2isq 1029w"></figure><br/><br/> <a href="https://www.lesswrong.com/posts/CJNbF9hM8PtxkrHHT/progress-links-digest-2023-08-17-cloud-seeding-robotic#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/CJNbF9hM8PtxkrHHT/progress-links-digest-2023-08-17-cloud-seeding-robotic<guid ispermalink="false"> CJNbF9hM8PtxkrHHT</guid><dc:creator><![CDATA[jasoncrawford]]></dc:creator><pubDate> Thu, 17 Aug 2023 20:29:28 GMT</pubDate> </item><item><title><![CDATA[Model of psychosis, take 2]]></title><description><![CDATA[Published on August 17, 2023 7:11 PM GMT<br/><br/><p> <i>（我无论如何都不是精神病方面的专家。这更像是“在博客中实时记录我的想法”。我希望激发讨论并获得反馈和指示。）</i></p><h1>一、简介</h1><p>去年 2 月，我在博客文章<a href="https://www.lesswrong.com/posts/H2epKysvFgPcTwC2f/schizophrenia-as-a-deficiency-in-long-range-cortex-to-cortex"><u>“精神分裂症是长程皮层间交流的缺陷”第 4.2 节</u></a>中提出了一种精神病模型。但它有一些问题。我终于抽出时间再看一下，我想我找到了解决这些问题的简单方法。所以这篇文章是更新版本。</p><p><strong>对于tl;dr，您可以跳过正文，只看下面的两张图</strong>。</p><h1> 2. 背景：我之前的“精神病模型，取 1”</h1><p>以下是我在<a href="https://www.lesswrong.com/posts/H2epKysvFgPcTwC2f/schizophrenia-as-a-deficiency-in-long-range-cortex-to-cortex"><u>“精神分裂症作为长程皮层间通讯缺陷”第 4.2 节</u></a>中提出的建议： </p><figure class="image image_resized" style="width:84.91%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/wktqaurpaalkjoggdiuu" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/oghtomiodqbanmrqmja2 140w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/pct3wxlentqcpdlpmosm 280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/qj0t6vaozbu0iccn7fby 420w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/jn71t5qau9ikibfefhce 560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/l2blxhhkorj6am4fubje 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/fhihkdcjhqoqstwo2rs4 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/d4hg2hc6pz7d0xa7vmvt 980w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/sjd7xw4brb3sxxmvmh37 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/o1emb3bcgxegzsyomhkt 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/jzl0b6rs9iswligmrcnc 1318w"></figure><p>这个想法是，在精神病中，绿色箭头是活跃且有效的，但红色箭头不是，因此紫色箭头也不是。结果可能是一种手臂被外力移动的感觉。这只是一个例子，对于左侧皮质输出的不同类型，相应的精神病的第一人称体验会有所不同。但我声称所有精神病症状都大致符合这个模板。</p><h1> 3. 第一个模型似乎缺少重要的三个方面</h1><ul><li>据我了解，精神分裂症患者的精神病可能会反复出现，而（我相信）皮层间沟通的缺陷是精神分裂症患者大脑的特征，并且是永久性的（未来医疗技术没有进步）。</li><li>抗精神病药物可以减少精神病，但上图无法解释这一点。</li><li>除精神分裂症外，精神病还可能发生在其他疾病中。我认为最常见的例子是躁郁症的躁狂期。上图无法解释这一点。</li></ul><h1> 4. 我的“精神病模型，取2”</h1><p> <i>（该图顶部的唯一变化是左侧新的绿色文本，上面写着“信号强度= <strong>B</strong> ”。）</i> </p><figure class="image image_resized" style="width:93.23%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/qnmby6hoqa5bfwlqeayu" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/jjrb8mawu2ujeqw7c5ot 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/ehibbu9bgqqowkwjldir 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/cogtxpqp9ex2o3ip54fa 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/rdirptmkvrozlxi5d9ny 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/qzpurvyri4vy823pk7po 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/pyoqgkrhdtuwzyhq0ixa 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/pjjscqiimpaceb2q13wl 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/fwjfxfswenkvooxyxutk 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/kjnkjrftfoufriobw1pl 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/tgaD4YnpGBhGGbAy5/uahekggt8l0bsvgkqw6r 1485w"></figure><p>可以将皮层的一部分视为具有可调节的“音量”，即它宣布当前正在做什么的强烈程度和清晰程度。例如，如果您想到<i>也许</i>您<i>可以</i>移动手指，那么您可能会发现（如果您仔细观察和/或使用科学设备）您的手指有点抽搐，而如果您强烈想要移动手指，然后你的手指就会真正移动。</p><p>无论如何，如果我们逐渐增加一部分皮层的“体积”，那么在某个时间点， <strong>A</strong>消息将开始通过并产生影响，同时在<i>其他</i>某个时间点， <strong>B</strong>消息将开始通过并产生影响。有效果。为了避免精神病，我们希望前者<i>首先</i>发生， <i>&nbsp;</i>以及<i>后者</i>，这样就不可能出现<strong>B</strong>消息正在传输但<strong>A</strong>消息没有传输的“音量级别”。</p><h1> 5.这个新模型的优点</h1><h2>5.1 <strong>B/A</strong>比率的缓慢变化至少在<i>先验上</i>是合理的，因为<strong>B</strong>和<strong>A</strong>来自不同皮质层的不同神经元（分别为第 5 层和第 2/3 层）</h2><p>我认为<strong>B/A</strong>比率是一个可以变化的参数，这是非常合理的，因为：</p><ul><li>信号<strong>B</strong>仅由皮层<strong>第 5 层</strong>的一部分神经元发送</li><li>信号<strong>A</strong>至少部分（也许大部分？）由皮层<strong>第 2/3 层</strong>的神经元子集发送</li><li>一般来说，不同的皮质层有不同类型的神经元，具有不同的输入、与多巴胺系统的不同关系等。</li></ul><p>因此，涉及<strong>B/A</strong>比率长期变化的理论至少是<i>合理的</i>。</p><h2> 5.2 至少一篇论文似乎表明抗精神病药比第 2/3 层信号更能抑制第 5 层信号</h2><p>参见<a href="https://elifesciences.org/reviewed-preprints/86805"><u>Heindorf &amp; Keller 2023</u></a> 。他们发现“氯氮平……降低了[第 2/3 层]兴奋性神经元的皮质活动相关性。然而，这种减少明显弱于我们在……[第 5 层端脑内]神经元中观察到的减少”。 （此特定比较的 p 值为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p < 0.005"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.005</span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>对于短程相关性， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p < 10^{-8}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">10</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">8</span></span></span></span></span></span></span></span></span></span></span>对于长程相关性）。</p><p>如果我正确地理解了这篇论文（一个很大的“如果”！），这是有启发性和令人鼓舞的，但并不能<i>明确</i>支持我的理论，因为首先，该论文测量了错误类型的第 5 层锥体神经元。发送信号<strong>B 的</strong>神经元，其次，作者测量的这种相关性<i>可能</i>是由通常信号较弱的第 5 层神经元引起的（这样空间相关性很快就会低于本底噪声），但还有其他原因也有可能的原因（与空间相关性<i>直接</i>相关——我认为这就是作者认为正在发生的事情）。</p><h1> 6. 我仍然不确定的事情</h1><h2>6.1 哪些 D2 受体解释抗精神病药物如何发挥作用？</h2><p>每种抗精神病药物的共同点是阻断多巴胺 D2 受体。所以想必这就是他们的工作方式。但整个大脑的神经元中都有 D2 受体。据推测，这些带有 D2 受体的神经元的一部分是抗精神病药物发挥作用的秘密，其余的则仅与副作用有关。哪个是哪个？</p><p>当我尝试充实我的模型时，迄今为止我想到的最简单、最优雅的故事涉及<i>皮质中</i>扮演主角的 D2 受体。特别是，不同的皮质层有不同的 D2 受体密度，如果我没记错的话，抗精神病药物降低<strong>B/A</strong>比率的迹象似乎是正确的。</p><p>但这很有趣，因为我认为几乎其他人似乎都认为<i>纹状体中的</i>D2 受体是抗精神病药物的作用机制？我试图弄清楚为什么人们似乎相信这一点，但无法弄清楚。我能找到的所有关于抗精神病药通过纹状体起作用的证据都相当薄弱和间接。如果您对此有所了解，请评论。</p><h2> 6.2 精神病的其他原因呢？</h2><p>由于各种原因，我脑子里有一个模糊的经验法则，那就是，在其他条件相同的情况下，更多的多巴胺往往会增加<strong>B/A</strong>比率（因此，超过某个阈值，会导致精神病）。这似乎很好地解释了与躁狂相关的精神病（我将躁狂与“大量多巴胺”松散地联系起来，至少在某些渠道和各种警告中），以及精神病是左旋多巴治疗帕金森病的副作用这一事实。</p><p>我对精神病性抑郁症更困惑。 （在双相情感障碍中，我知道精神病在躁狂症中比抑郁症更常见，但它<i>也可能</i>发生在抑郁症中。）我通常认为抑郁症是躁狂症的“相反”，并且涉及异常少<i>的</i>多巴胺，同样是在某些渠道和与各种警告。所以我对精神病性抑郁症是否会发生感到有点困惑。我不知道。无论如何，多巴胺系统只是影响<strong>B/A</strong>比率的众多因素之一。或者上图右侧的紫色信号可能没有通过？或者也许这是一个完全不同的故事。</p><br/><br/><a href="https://www.lesswrong.com/posts/tgaD4YnpGBhGGbAy5/model-of-psychosis-take-2#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/tgaD4YnpGBhGGbAy5/model-of-psychosis-take-2<guid ispermalink="false"> tgaD4YnpGBhGGbAy5</guid><dc:creator><![CDATA[Steven Byrnes]]></dc:creator><pubDate> Thu, 17 Aug 2023 19:11:17 GMT</pubDate> </item><item><title><![CDATA[[Linkpost] Robustified ANNs Reveal Wormholes Between Human Category Percepts]]></title><description><![CDATA[Published on August 17, 2023 7:10 PM GMT<br/><br/><p>这是<a href="https://arxiv.org/abs/2308.06887"><i>https://arxiv.org/abs/2308.06887</i></a><i>的链接帖子</i><i>。</i></p><blockquote><p>众所周知，人工神经网络（ANN）的视觉对象类别报告对微小的对抗性图像扰动非常敏感。因为人类类别报告（又名人类感知）被认为对那些相同的小范数扰动不敏感，而且总体上局部稳定，这表明人工神经网络是人类视觉感知的不完整科学模型。与此一致的是，我们表明，当标准 ANN 模型生成小范数图像扰动时，人类对象类别感知确实高度稳定。然而，在这个完全相同的“人类假定稳定”体系中，我们发现稳健的人工神经网络可靠地发现了强烈扰乱人类感知的低范图像扰动。这些以前无法检测到的人类感知干扰的幅度非常大，接近于稳健的人工神经网络中可见的相同敏感度水平。此外，我们表明，稳健的人工神经网络支持精确的感知状态干预：它们指导低范数图像扰动的构建，这些扰动强烈改变人类类别感知到特定规定的感知。这些观察结果表明，对于图像空间中的任意起点，存在一组附近的“虫洞”，每个虫洞都会引导主体从当前类别感知状态进入语义上非常不同的状态。此外，当代生物视觉处理的人工神经网络模型现在足够准确，可以始终如一地引导我们到达这些门户。</p></blockquote><br/><br/> <a href="https://www.lesswrong.com/posts/t5CXh9LwcKZqwNpTk/linkpost-robustified-anns-reveal-wormholes-between-human#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/t5CXh9LwcKZqwNpTk/linkpost-robustified-anns-reveal-wormholes- Between- human<guid ispermalink="false"> t5CXh9LwcKZqwNpTk</guid><dc:creator><![CDATA[Bogdan Ionut Cirstea]]></dc:creator><pubDate> Thu, 17 Aug 2023 19:10:40 GMT</pubDate> </item><item><title><![CDATA[Against Almost Every Theory of Impact of Interpretability]]></title><description><![CDATA[Published on August 17, 2023 6:44 PM GMT<br/><br/><p><i>认知状态：我相信我精通这个主题。我的错误在于提出了过于强烈的主张，允许读者提出不同意见并就精确的观点展开讨论，而不是试图对每一个陈述进行边缘化。我还认为使用模因很重要，因为安全想法很无聊且</i><a href="https://www.lesswrong.com/posts/zk6RK3xFaDeJHsoym/connor-leahy-on-dying-with-dignity-eleutherai-and-conjecture%23Eliezer_Has_Been_Conveying_Antimemes"><i><u>反模因</u></i></a><i>。那么我们走吧！</i></p><p><i>非常感谢</i><a href="https://www.lesswrong.com/users/scasper?mention=user"><i>@scasper</i></a> <i>、</i> <a href="https://www.lesswrong.com/users/sid-black?mention=user"><i>@Sid Black</i></a> <i>、</i> @ <a href="https://www.lesswrong.com/users/neel-nanda-1?mention=user"><i>Neel Nanda</i></a> <i>、</i> @ <a href="https://www.lesswrong.com/users/fabien-roger?mention=user"><i>Fabien Roger</i></a> <i>、</i> <a href="https://www.lesswrong.com/users/bogdan-ionut-cirstea?mention=user"><i>@Bogdan Ionut Cirstea</i></a> <i>、</i> <a href="https://www.lesswrong.com/users/wcargo?mention=user"><i>@WCargo</i></a> <i>、@</i> <a href="https://www.lesswrong.com/users/alexandre-variengien?mention=user"><i>Alexandre Variengien</i></a> <i>、</i> <a href="https://www.lesswrong.com/users/lelapin?mention=user"><i>@Jonathan Claybrough</i></a> <i>、</i> <a href="https://www.lesswrong.com/users/edoardo-pona?mention=user"><i>@Edoardo Pona</i></a> <i>、</i> @ <a href="https://www.lesswrong.com/users/andream?mention=user"><i>Andrea_Miotti</i></a> <i>、Diego Dorn、Angélina Gentaz、Clement Dumas、和 Enzo Marsot 提供有用的反馈和讨论。</i></p><p>当我开始写这篇文章时，我首先批评 Neel Nanda 的文章<a href="https://www.lesswrong.com/posts/uK6sQCNMw8WKzJeCQ/a-longlist-of-theories-of-impact-for-interpretability"><u>《可解释性影响的一长串理论》</u></a> ，但后来我扩大了批评的范围。提出的一些想法并没有得到任何人的支持，但为了解释其中的困难，我仍然需要1.解释它们和2.批评它们。它给这篇文章带来了一种敌对的氛围。对此我感到很抱歉，我认为对可解释性进行研究，即使它不再是我认为的优先事项，仍然是值得赞扬的。</p><p><strong>如何阅读这份文件？</strong>除了“可解释性的最终故事是什么样的？”部分之外，本文档的大部分内容都不是技术性的。一开始大部分可以跳过。我希望这份文档对于不进行可解释性研究的人也有用。不同的部分大多是独立的，我添加了很多书签来帮助模块化这篇文章。</p><p>如果你时间很少，就看一下（这也是我最有信心的部分）：</p><ul><li> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Auditing_deception_with_interp_is_out_of_reach"><u>使用 Interp 审计欺骗是遥不可及的</u></a>（4 分钟）</li><li> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Enumerative_safety_"><u>列举安全</u></a>评论（2 分钟）</li><li> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Technical_Agendas_with_better_ToI"><u>具有更好影响理论的技术议程</u></a>（1 分钟）</li></ul><p></p><p>以下是我将辩护的索赔清单：</p><p> （粗体部分是最重要的部分）</p><ul><li> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#The_overall_Theory_of_Impact_is_quite_poor"><strong><u>整体影响理论相当差</u></strong></a><ul><li><a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Interp_is_not_a_good_predictor_of_future_systems"><u>Interp 不能很好地预测未来系统</u></a></li><li><a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Auditing_deception_with_interp_is_out_of_reach"><strong><u>使用 interp 审计欺骗是遥不可及的</u></strong></a></li></ul></li><li><a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#What_does_the_end_story_of_interpretability_look_like__That_s_not_clear_at_all_"><strong><u>可解释性的最终故事是什么样的？这一点都不清楚。</u></strong></a><ul><li> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Enumerative_safety_"><strong><u>枚举安全性？</u></strong></a></li><li> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Reverse_engineering_"><u>逆向工程？</u></a></li><li> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Olah_s_interpretability_dream_"><u>奥拉的可解释性梦想？</u></a></li><li> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Retargeting_the_search_"><u>重新定位搜索？</u></a></li><li> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Relaxed_adversarial_training_"><u>轻松的对抗训练？</u></a></li><li> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Microscope_AI_"><u>显微镜人工智能？</u></a></li></ul></li><li> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Preventive_measures_against_Deception_seem_much_more_workable"><strong><u>针对欺骗的预防措施似乎更加可行</u></strong></a><ul><li><a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Steering_the_world_towards_transparency"><u>引导世界走向透明</u></a></li><li><a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Cognitive_Emulations___Explainability_By_Design"><u>认知模拟 - 可解释性设计</u></a></li></ul></li><li><a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Interpretability_May_Be_Overall_Harmful"><strong><u>可解释性可能总体上是有害的</u></strong></a></li><li><a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Outside_view__The_proportion_of_junior_researchers_doing_interp_rather_than_other_technical_work_is_too_high"><strong><u>外界观点：初级研究员从事Interp而非其他技术工作的比例太高</u></strong></a></li><li><a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#So_far_my_best_ToI_for_interp__Nerd_Sniping_"><u>到目前为止，我最好的解释员指南：书呆子狙击？</u></a></li><li> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Even_if_we_completely_solve_interp__we_are_still_in_danger"><strong><u>即使我们完全解决了interp，我们仍然处于危险之中</u></strong></a></li><li><a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Technical_Agendas_with_better_ToI"><strong><u>具有更好影响理论的技术议程</u></strong></a></li><li><a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Conclusion"><strong><u>结论</u></strong></a></li></ul><p>注：本文的目的是批评类 GPT 模型等深度学习模型的可解释性影响理论（ToI），而不是小模型的可解释性和可解释性。</p><h1>皇帝没穿衣服？</h1><p>我演讲了不同的<a href="https://www.lesswrong.com/posts/wnnkD6P2k2TfHnNmt/threat-model-literature-review"><u>风险模型</u></a>，然后进行了可解释性演示，然后我得到了一个有问题的问题，“我不明白，这样做有什么意义？”哼。 </p><figure class="image image_resized" style="width:587.5px"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/zzxhts0u9ne414ahftxw" alt=""><figcaption>来自<a href="https://distill.pub/2017/feature-visualization/"><i><u>特征可视化的</u></i></a><i>图像</i><i>。</i></figcaption></figure><ul><li>功能即？ （左图）嗯，很漂亮，但是有用吗？ <span class="footnote-reference" role="doc-noteref" id="fnref2stfurwyyg6"><sup><a href="#fn2stfurwyyg6">[1]</a></sup></span> <a href="https://arxiv.org/abs/2010.12606%23:~:text%3Dversion%252C%2520v3)%255D-,Exemplary%2520Natural%2520Images%2520Explain%2520CNN%2520Activations%2520Better%2520than,of%252Dthe%252DArt%2520Feature%2520Visualization%26text%3DFeature%2520visualizations%2520such%2520as%2520synthetic,convolutional%2520neural%2520networks%2520(CNNs)."><u>这个</u></a><a href="https://arxiv.org/abs/2306.04719"><u>可靠</u></a>吗？</li><li> GradCam（一种像素归因技术，如上右图），它很漂亮。但我从未见过有人在工业中使用它。 <span class="footnote-reference" role="doc-noteref" id="fnref4qi9kn3ip89"><sup><a href="#fn4qi9kn3ip89">[2]</a></sup></span>像素归因似乎很有用，但准确性仍然是王道。 <span class="footnote-reference" role="doc-noteref" id="fnref6xxwjs20rd7"><sup><a href="#fn6xxwjs20rd7">[3]</a></sup></span></li><li>感应头？好吧，我们可能正在对<a href="https://en.wikipedia.org/wiki/Regular_expression"><u>法学硕士中的正则</u></a>表达式机制进行逆向工程。凉爽的。</li></ul><p>最后要点中的考虑是基于感觉，并不是真正的论据。此外，大多数机械解释现在甚至都不是为了有用。但在本文的其余部分，我们将了解原则上可解释性是否有用。那么我们就来调查一下解说帝到底是有隐形衣服还是根本没有衣服！</p><h1>整体影响理论相当差</h1><p>Neel Nanda 撰写了<a href="https://www.lesswrong.com/posts/uK6sQCNMw8WKzJeCQ/a-longlist-of-theories-of-impact-for-interpretability"><strong><u>一长串可解释性影响理论</u></strong></a><strong>，</strong>其中列出了 20 种不同的影响理论。然而，我发现自己不同意其中的大多数理论。元层面的三大分歧是：</p><ul><li><strong>每当你想做一些具有可解释性的事情时，最好不要这样做。</strong>我怀疑 Redwood Research 已因此停止进行可解释性工作（请参阅此处的当前计划<a href="https://www.youtube.com/watch?v%3DYTlrPeikoyw"><u>EAG 2023 湾区当前的调整计划，以及我们如何改进它</u></a>）。<ul><li><strong>对于欺骗性对齐来说尤其如此</strong>，尽管它是可解释性研究的主要焦点。许多其他风险情景也值得考虑。 【 <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Auditing_deception_with_interp_is_out_of_reach"><u>欺骗</u></a>部分】</li></ul></li><li><strong>可解释性常常试图同时解决太多目标。</strong>请<a href="https://www.lesswrong.com/posts/3p3CYauiX8oLjmwRF/purchase-fuzzies-and-utilons-separately"><u>分别购买 Fuzzies 和 Utilons</u></a> ：即同时优化多个目标是非常困难的！最好直接针对每个子目标分别进行优化，而不是将所有内容混合在一起。当我查看尼尔·南达（Neel Nanda）的<a href="https://www.lesswrong.com/posts/uK6sQCNMw8WKzJeCQ/a-longlist-of-theories-of-impact-for-interpretability"><u>这份清单</u></a>时，我发现这个原则没有得到遵循。</li><li><strong>一般来说，可解释性可能是有害的。</strong>使用 interp 来保证安全无疑对功能来说是有用的。 [章节<a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Interpretability_May_Be_Overall_Harmful"><u>危害</u></a>]</li></ul><p>其他不太重要的分歧：</p><ul><li><strong>概念上的进步更为紧迫，</strong>而 interp 可能无助于推进这些讨论。 [章节<a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#What_does_the_end_story_of_interpretability_look_like__That_s_not_clear_at_all_"><u>结束故事</u></a>]</li><li><strong>目前的可解释性主要用于事后分析</strong>，在事前或预测能力方面几乎没有什么用处[ <a href="https://docs.google.com/document/d/e/2PACX-1vSedy4vmfA5H30bimiSGWykDfh8FB_uYKCt6D2qz9nwmfhGUc93H3UEPN1pBtyXe-eKEdu0E5oUbSWR/pub#id.vcvarqienhb7"><u>未来系统的部分预测器</u></a>]</li></ul><p>以下是我不同意的一些关键理论：</p><ul><li>影响理论<strong>2：“</strong><i><strong>更好地预测未来系统”</strong></i></li><li>影响理论<strong>4：“</strong><i><strong>欺诈审计”</strong></i></li></ul><p>在附录中，我批评了几乎所有其他影响理论。</p><h2> Interp 不能很好地预测未来系统</h2><p><i>影响理论 2：“<strong>更好地预测未来系统</strong>：可解释性可以使人们更好地机械地理解 ML 系统和工作原理，以及它们如何随规模变化，类似于科学定律。这使我们能够更好地从当前系统推断未来系统，类似于缩放定律。例如，观察感应头的相变向我们表明，模型可以在训练期间快速获得能力”，</i>来自<a href="https://www.lesswrong.com/posts/uK6sQCNMw8WKzJeCQ/a-longlist-of-theories-of-impact-for-interpretability"><u>Neel Nanda</u></a> 。</p><ul><li>对<a href="https://transformer-circuits.pub/2021/framework/index.html"><strong><u>感应头</u></strong></a>示例<strong>的挑剔</strong><strong>。</strong>如果我们关注上面的例子“<i>模型在训练过程中可能会快速获得能力</i>”，我不认为是可解释性让我们发现了这一点，而是行为评估。在训练期间定期测量损失，并通过让模型复制一系列随机令牌<a href="https://transformer-circuits.pub/2021/framework/index.html"><u>来测量</u></a>归纳能力的快速增益。一开始，复制是行不通的，但经过一些训练后，就可以了。可解释性只是告诉我们，这与感应头的出现相吻合，但我不明白可解释性如何让我们“<i>更好地从当前系统推断未来系统”</i> 。此外，感应头首先被研究是因为它们很容易学习。</li><li><strong>可解释性主要是在现象发现后完成的，而不是事前完成的。</strong> <span class="footnote-reference" role="doc-noteref" id="fnrefztj4j3pmerg"><sup><a href="#fnztj4j3pmerg">[4]</a></sup></span><ul><li>我们首先观察到了 grokking 现象，然后我们<i>才</i>开始对其进行一些<a href="https://arxiv.org/abs/2301.05217"><u>解释</u></a>。有没有反例？</li><li>在<a href="https://www.lesswrong.com/posts/uKp6tBFStnsvrot5t/what-dall-e-2-can-and-cannot-do"><u>DALL-E 2 可以做什么和不能做什么</u></a>中，我们看到 DALL-E 2 无法正确拼写单词。两个月后， <a href="https://www.lesswrong.com/posts/uKp6tBFStnsvrot5t/what-dall-e-2-can-and-cannot-do?commentId%3Dg6kZ3eRFejRjiyGiw"><u>Imagen</u></a>就能正确拼写这些单词了。我们甚至没有费心去解释。</li></ul></li><li><strong>有更好的方法来预测这些系统的未来功能。</strong>跳出框框思考，如果你真的想看看未来的系统会是什么样子，那么查看 NeurIPS 会议和 AutoGPT 等认知架构上发表的论文会容易得多。否则，订阅 DeepMind 的 RSS feed 也不失为一个好主意。</li></ul><h2>使用 interp 审计欺骗是遥不可及的</h2><p>审计欺骗通常是进行解释的主要动机。所以我们在这里：</p><p>影响理论 4：<i><strong>欺骗审计</strong>：与审计类似，我们也许能够检测模型中的欺骗行为。这比完全审核模型要低得多，而且我们只需能够<strong>查看模型的随机位并识别电路/特征</strong>，这似乎是我们可以做到的事情 - 我认为这更多地是“世界的变革理论”可解释性比我希望的更难”</i>来自<a href="https://www.lesswrong.com/posts/uK6sQCNMw8WKzJeCQ/a-longlist-of-theories-of-impact-for-interpretability"><u>Neel Nanda</u></a> 。</p><ul><li><strong>我不明白“查看</strong><i><strong>模型的随机位并识别电路/特征</strong></i><strong>”如何有助于欺骗。</strong>例如，假设我对随机电路的 GPT2 进行了逆向工程，例如在论文<a href="https://arxiv.org/abs/2211.00593"><u>Interpretability in the wild 中</u></a>，他们对间接对象识别电路进行了逆向工程。目前还不清楚这将如何帮助欺骗。即使预期的含义是“识别可能与欺骗/社交建模相关的电路/特征”，也不清楚分析每个电路是否足够（参见“ <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Enumerative_safety_"><u>枚举安全</u></a>”小节）。</li><li><strong>我们还远未达到通过插译员检测或训练欺骗行为所需的水平。</strong> Evan Hubinger 在他的文章<a href="https://www.lesswrong.com/posts/nbq2bWLcYmSGup9aF/a-transparency-and-interpretability-tech-tree"><u>《透明度和可解释性技术树》</u></a>中列出了 8 个可解释性级别，其中只有第 7 级和第 8 级提供了一些打击欺骗的手段。这些级别大致描述了可解释性的需求，但到目前为止我们只达到了第 2 级，并且我们已经在第 4 级遇到了负面结果。Evan 解释说，“<i>任何级别的透明度和可解释性技术对欺骗性模型具有鲁棒性都是极其困难的”</i> ”。</li><li> <i><strong>“此外，试图通过可解释性工具提前发现欺骗行为可能会失败，因为欺骗性对齐模型没有必要积极思考其欺骗行为。</strong>一个从未见过有机会夺取权力的情况的模型不需要仔细计划在这种情况下会做什么，就像工厂清洁机器人不需要计划如果有一天发现自己陷入困境该怎么办一样。丛林而不是工厂。尽管如此，该模型之前并未计划夺取权力，但这并不意味着如果有机会它就不会夺取权力。特别是，一个模型可能会被欺骗性地对齐，因为它推断，在有明确监督者的情况下，做它想做的事是在世界上获得权力和影响力的良好总体策略，而不需要为以后的欺骗制定任何明确的计划”。</i> （摘自 <a href="https://www.lesswrong.com/posts/Km9sHjHTsBdbgwKyi/monitoring-for-deceptive-alignment"><u>《监视欺骗性对齐</u></a>》中的 Hubinger）</li><li><strong>已经存在反对可解释性的负面概念点</strong>，这表明先进的人工智能不容易被解释，正如杀伤力列表中的<a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities%23sufficiently_good_and_useful"><u>可解释性部分</u></a>所讨论的那样（这些是我过去<a href="https://docs.google.com/document/d/1GiYfx77cE6-VyeNN31tVUARt5X7tbX4XD0CSmBkReUc/edit%23"><u>尝试</u></a>批评的观点，但大多失败了） 。特别是第 27、29 和 33 点：<ul><li> <strong>27. 选择不可检测性</strong>：“<i>针对解释性思想进行优化，就针对可解释性进行优化。”</i></li><li> <strong>29. 现实世界是一个不透明的领域：</strong> “<i>通用人工智能的输出在产生真正的后果之前要经过一个巨大的、我们不完全了解的领域（现实世界）。人类无法检查通用人工智能的输出来确定后果是否良好。”</i><ul><li><strong>并且认知可以外化。</strong>这不是特定于 interp 的。许多模式只能通过它们与环境的交互方式来解释，而不能仅通过网络中的内容来完全解释。例如“查阅食谱并采取书中所写的行动。” （康纳的例子）。</li></ul></li><li> <strong>33. 外星人概念：</strong> “<i>人工智能不像你那样思考”</i>对于通过矩阵乘积处理数字来完成的认知，可能不一定有人类可以理解的解释。</li><li>我并不完全同意所有这些观点，但我还没有看到对这些具体观点的太多讨论，你可以在我的评论中找到一些警告</li></ul></li><li>其他较弱的困难见脚注。 <span class="footnote-reference" role="doc-noteref" id="fnref2464ho15s7t"><sup><a href="#fn2464ho15s7t">[5]</a></sup></span></li></ul><p>仅使用 interp 来对抗欺骗并不是唯一的方法：</p><ul><li><strong>解释并不是研究欺骗的唯一方法。</strong>以下是其他被忽视的范例：<ul><li><strong>对抗性攻击</strong>（基本上<a href="https://www.youtube.com/watch?v%3DYTlrPeikoyw%26themeRefresh%3D1"><u>是雷德伍德的计划</u></a>）。许多重要的对抗策略不依赖于<a href="https://arxiv.org/abs/2306.09983"><strong><u>一致性检查</u></strong></a>、<a href="https://www.cold-takes.com/high-level-hopes-for-ai-alignment/"><u>人工智能检查和平衡</u></a>以及定期提示<span class="footnote-reference" role="doc-noteref" id="fnrefrbnra8fsacj"><sup><a href="#fnrbnra8fsacj">[6] 等</a></sup></span>插值。</li><li><strong>创建一个欺骗性对齐或模拟的玩具模型：</strong>研究“可能构成生存威胁的各种失败的体外演示”，来自<a href="https://www.alignmentforum.org/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1"><u>《错位模型有机体》</u></a> ，这是一篇关于此的最新详细文章。</li><li><strong>寻找欺骗性联盟代理：</strong>例如，监控以下<a href="https://www.lesswrong.com/posts/RTkatYxJWvXR4Qbyd/deceptive-alignment-is-less-than-1-likely-by-default%23Foundational_properties_for_deceptive_alignment"><u>4 个标准</u></a>，这些标准通常被视为欺骗性联盟的先决条件：目标导向的行为、跨事件/长期目标视野的优化、基本目标的概念化、情境意识。</li><li>接近人类水平的人工智能的各种基线策略：<ul><li>在 NLP 中，监控 AutoGPT 的计划和思路（ <a href="https://docs.google.com/document/d/e/2PACX-1vSedy4vmfA5H30bimiSGWykDfh8FB_uYKCt6D2qz9nwmfhGUc93H3UEPN1pBtyXe-eKEdu0E5oUbSWR/pub#kix.cyunx152z1bn"><u>细节</u></a>和注意事项）。</li><li>愿景中，类EfficientZero的一致性损失——在蒙特卡罗树中展望未来（ <a href="https://docs.google.com/document/d/1GiYfx77cE6-VyeNN31tVUARt5X7tbX4XD0CSmBkReUc/edit%23bookmark%3Did.dgd983y7t1ym"><u>草案</u></a>）</li></ul></li><li><a href="https://twitter.com/StephenLCasper/status/1650662566476279809"><u>更多</u></a>想法，如神经蒸馏和<a href="https://www.alignmentforum.org/posts/KSWSkxXJqWGd5jYLB/the-speed-simplicity-prior-is-probably-anti-deceptive%23How_to_actually_implement_a_speed_prior"><u>速度优先</u></a>。</li><li>如果 DeepMind 今天宣布他们在 GPT 中发现了欺骗行为，他们不太可能只使用可解释性来发现这一发现。他们更有可能使用定期提示。</li></ul></li><li><strong>有一些针对欺骗性联盟的预防措施</strong>似乎更可行（请参阅<a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Preventive_measures_against_Deception_seem_much_more_workable"><u>针对欺骗的预防措施</u></a>部分）。</li><li><strong>概念上的进步更为紧迫。</strong>从概念上思考欺骗比通过可解释性思考要富有成效得多。据我所知，可解释性还没有教会我们任何关于欺骗的知识。<ul><li>例如，<a href="https://www.lesswrong.com/tag/simulator-theory"><u>模拟器理论</u></a>和对<i>GPT 已经可以模拟欺骗性拟像</i>的理解是我们对欺骗性对齐的理解比欺骗性可解释性方面所发生的进步更大的进步。</li><li>关于欺骗性对齐的概念性考虑，如文章<a href="https://www.lesswrong.com/posts/RTkatYxJWvXR4Qbyd/deceptive-alignment-is-less-than-1-likely-by-default"><u>《默认情况下欺骗性对齐的可能性 &lt;1%》</u></a>中所示，完全不依赖于可解释性。 </li></ul></li></ul><p></p><figure class="table"><table><tbody><tr><td style="padding:5pt;vertical-align:top" colspan="1" rowspan="1"><p><img style="width:273.72px" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/dkw7e0dp4pangmxj7ei4" alt=""></p></td><td style="padding:5pt;vertical-align:top" colspan="1" rowspan="1"><p><img style="width:268.46px" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/ct8q2lqan4o5dhrw6bcf" alt=""></p></td></tr></tbody></table></figure><p><i>受到我与捍卫 interp 的朋友们进行的每一次讨论的启发。 “你对天文学的论证太笼统了”，所以让我们在下一节中深入探讨一些物体级的论证！</i></p><h1>可解释性的最终故事是什么样的？这一点都不清楚。</h1><p><i>这部分技术性比较强。可以先跳过它，或者只阅读“枚举安全性？”部分。这非常重要。</i></p><p>当然，深度学习中的可解释性似乎本质上比神经科学更可行，因为我们可以保存所有激活并非常缓慢地运行模型，通过尝试因果修改来理解正在发生的事情，并且比功能磁共振成像允许更多的控制。但在我看来，这还不够——我们甚至不知道我们的目标是什么。我们的目标是：</p><h2>枚举安全性？</h2><p>正如 Neel Nanda <a href="https://www.lesswrong.com/posts/qgK7smTvJ4DB8rZ6h/othello-gpt-future-work-i-am-excited-about#:~:text=enumerative%20safety%2C%20the%20idea%20that%20we%20might%20be%20able%20to%20enumerate%20all%20features%20in%20a%20model%20and%20inspect%20this%20for%20features%20related%20to%20dangerous%20capabilities%20or%20intentions.%20Seeing%20whether%20this%20is%20remotely%20possible%20for%20Othello%2DGPT%20may%20be%20a%20decent%20test%20run."><strong><u>所说</u></strong></a><strong>，枚举安全</strong><strong>是指我们可以枚举</strong>模型中的<i><strong>所有</strong></i><strong>特征</strong>，并检查其是否存在与危险能力或意图相关的特征。我认为这个策略从一开始就注定了（从最重要到不太重要）：</p><ul><li><strong>确定某个特征的危险性是一个错误指定的问题。</strong>在网络的权重/结构中搜索危险特征是毫无意义的。一个特性本身并没有好或坏之分。单个原子的危险并不能有力地预测原子和分子组装的危险。例如，如果你想象第53层、第127通道的特征，它看起来像一把枪，这是否意味着你的系统很危险？或者您的系统是否能够识别危险的枪支？认知可以<a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Auditing_deception_with_interp_is_out_of_reach:~:text=And%20cognition%20can%20be%20externalized."><u>外化</u></a>这一事实也有助于这一点。</li><li><strong>特征仍然是一个模糊的概念</strong>，叠加问题和自然抽象假设在<a href="https://distill.pub/2020/circuits/zoom-in/"><u>Distill</u></a>论文发表三年后仍然是一个假设，很少有令人信服的策略来解决它们。这并不奇怪：可解释性的核心概念“特征”似乎本质上是模糊的，并且仍然没有定义。这是“枚举安全”策略以及对神经元进行逐一迭代以验证每个特征的“良好性”并获得保证的一个主要问题：<ul><li>并且由于<a href="https://arxiv.org/abs/2209.10652"><u>叠加</u></a>，迭代每个神经元是无效的。因此，我们不能只迭代神经元，而是必须迭代所有神经元集（或更糟糕的是所有方向），这在计算上是完全难以处理的。</li></ul></li><li><strong>危险模型的属性不是低级特征，而是高级行为能力，</strong>例如编码能力、 <a href="https://www.lesswrong.com/posts/yRAo2KEGWenKYZG9K/discovering-language-model-behaviors-with-model-written"><u>阿谀奉承</u></a>或各种心理代理理论、态势感知或黑客攻击。<ul><li>网络的态势感知可能包括几个子特征，例如日期和时间、地理位置以及用户的当前需求。删除这些子功能会降低模型的竞争力。</li></ul></li><li><a href="https://www.lesswrong.com/posts/XWwvwytieLtEWaFJX/deep-deceptiveness"><strong><u>深度欺骗性</u></strong></a>——简单来说，由于优化压力以及模型与环境之间的复杂交互，即使没有任何单个部分是危险的，系统也可能具有欺骗性。</li><li><strong>这种策略已经通过自动解释技术在视觉上尝试过</strong>，以标记所有神经元，并且它似乎没有太多高级对齐，并且大多数神经元都回避简单的解释：<ul><li> NetDisect 和神经元的组成解释（Mu 和 Andreas，2021）</li><li>深度视觉特征的自然语言描述（Andreas，2022）</li><li> Clip-Dissect（Oikarinen，2022）<a href="https://visualvocab.csail.mit.edu/"><u>走向 GAN 潜在空间的视觉概念词汇</u></a>（Schwettmann，2021）</li><li>这些工作[ <a href="https://www.lesswrong.com/posts/XZfJvxZqfbLfN6pKh/introductory-textbook-to-vision-models-interpretability"><u>此处</u></a>部分总结]并没有改变我们在实践中尝试使视觉系统更加强大且风险更低的方式。</li></ul></li><li>大多数自动解释性工作，例如<a href="https://openai.com/research/language-models-can-explain-neurons-in-language-models"><u>语言模型可以解释来自 OpenAI 的语言模型中的神经元</u></a>或概念擦除技术，都属于这一类。</li></ul><h2>逆向工程？</h2><p>逆向工程是可解释性的典型例子，但我没有看到成功的前进方向。这会是：</p><ul><li>该模型的<strong>等效 C++ 注释算法</strong>是什么？能够通过一些模块化 C++ 代码重现 GPT-4 的难以理解的矩阵的功能已经超出了人类的智能水平，这<a href="https://www.lesswrong.com/posts/pQqoTTAnEePRDmZN4/agi-automated-interpretability-is-suicide"><u>太危险</u></a>了，因为这将允许很多不同的优化，并且可能允许递归自我- 改进似乎很危险，特别是如果我们依赖自动化流程来实现这一点。</li><li><strong>对模型行为的通俗解释</strong>？在哪个粒度级别？每个标记、句子或段落？这实在是不清楚。</li><li>通过高级解释获得的模型的<strong>功能连接组</strong>？好吧，您在功能连接组中看到该模型能够编码和破解，而这些都是危险的功能。这不就是常规的评估吗？<ul><li>在实践中，为了进行插值实验，我们几乎总是从创建提示数据集开始。也许有一天我们不需要提示来激活这些功能，但我不认为（即使是原则上）这种情况会很快发生。</li></ul></li><li>一张<strong>图</strong>来解释电路？像下面这样的图表可能会让人不知所措，但仍然非常有限。</li></ul><p>您可以注意到，“枚举安全性”通常隐藏在“逆向工程”结局背后。 </p><p><img style="width:599.5px" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/hpuwlgsxjtrumo38ckav" alt=""></p><p><i>来自</i><a href="https://arxiv.org/abs/2211.00593"><i><u>IOI论文</u></i></a><i>。从 Wang 等人的“Interpretability in the Wild”中理解该图。 2022 年对于我们的讨论来说并不重要。了解完整的电路和所使用的方法需要</i><a href="https://www.youtube.com/watch?v%3Dgzwj0jWbvbo"><i><u>三个小时的视频</u></i></a><i>。而且，此分析仅关注单个标记并涉及大量简化。例如，虽然我们试图解释为什么标记“Mary”比“John”更受欢迎，但我们没有深入研究为什么模型最初考虑“Mary”或“John”。此外，此分析仅基于 GPT2-small。</i> </p><p></p><p><img style="width:385.83px" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/mmmq7xwly9mufts4101o" alt=""></p><p><i>确实，这个数字是相当可怕的。来自</i><a href="https://www.lesswrong.com/posts/j6s9H9SHrEhEfuJnq/causal-scrubbing-results-on-induction-heads"><i><u>因果擦洗：感应头上的结果</u></i></a><i>，适用于 2 层模型。经过 4 次精炼假设，他们能够挽回 86% 的损失。但即使对于这个简单的任务，他们也表示“我们最终不会得出完全具体或完全人类可以理解的假设，因果清理将使我们能够验证模型的哪些组件和计算是重要的。”。</i></p><p>在上面的两个玩具示例中，逆向工程已经如此困难，这一事实似乎令我感到担忧。</p><h2>奥拉的可解释性梦想？</h2><p>又或许 interp 只是一场由好奇心驱动的探索，等待着意外的发现？</p><ul><li><a href="https://transformer-circuits.pub/2023/interpretability-dreams/index.html"><u>可解释性梦想</u></a>是 Chris Olah 关于机械可解释性未来目标的非正式说明。它讨论了<strong>叠加</strong>，即可解释性的敌人。然后，在注释的末尾，在标题为“<a href="https://transformer-circuits.pub/2023/interpretability-dreams/index.html%23safety"><u>机械可解释性如何适应安全性？”的</u></a>部分中。 ”，我们理解该计划是为了解决叠加能够使用以下公式： <br><br><img style="width:526.5px" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/bbzkzi7n1cc1w6cvueju" alt=""></li><li>但这又是用电路而不是功能来表述的“<i>枚举安全性”</i> 。然而，正如上面所解释的，我认为这不会给我们带来任何好处。</li><li>笔记的最后一部分“ <a href="https://transformer-circuits.pub/2023/interpretability-dreams/index.html%23aesthetics"><u>美丽与好奇</u></a>”读起来就像一首诗或一首美丽的赞歌。然而，除了偶然发现的希望之外，它似乎缺乏实质内容。</li></ul><p>总的来说，我对 Anthropic 使用字典学习方法来解决叠加问题持怀疑态度。虽然他们的负面结果很有趣，并且他们正在努力解决围绕“功能”概念的概念性困难（如其<a href="https://transformer-circuits.pub/2023/may-update/index.html%23superposition-dictionary"><u>5 月更新</u></a>中所述），但我仍然对这种方法的有效性持怀疑态度，即使在阅读了他们<a href="https://transformer-circuits.pub/2023/july-update/index.html%23safety-features"><u>最近的 7 月更新</u></a>后也是如此。仍然没有解决我对枚举安全性的反对意见。</p><p> Olah<a href="https://transformer-circuits.pub/2023/interpretability-dreams/index.html">建议的</a>一个潜在解决方案是自动化研究：“<i>似乎很可能方法的类型 [...] 最终将不够，并且可解释性可能需要依赖人工智能自动化</i>”。然而，我相信这种自动化是潜在有害的[ <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Interpretability_May_Be_Overall_Harmful"><u>有害</u></a>部分]。</p><p>这仍然是一个正在发展的故事，在 Distill 上发表的论文总是令人读起来很愉快。然而，我仍然对押注这种方法犹豫不决。</p><h2>重新定位搜索？</h2><p>或者也许 interp 对于<a href="https://www.lesswrong.com/posts/w4aeAFzSAguvqA5qu/how-to-go-from-interpretability-to-alignment-just-retarget"><strong><u>重定向搜索</u></strong></a><strong>很有用</strong><strong>？</strong>这个想法表明，如果我们在系统中找到目标，我们可以简单地改变系统的目标并将其重定向到更好的目标。</p><p>我认为这是一个充满希望的探索，即使仍然存在困难：</p><ul><li>这很有趣，因为这将是一种不需要对完整模型进行完全逆向工程的方法。<strong> </strong>对我来说<a href="https://www.alignmentforum.org/posts/cAC4AXiNC5ig6jQnc/understanding-and-controlling-a-maze-solving-policy-network"><u>，理解和控制迷宫解决策略网络</u></a>中使用的技术似乎很有前途。只需关注“激励 API”就足够了。</li><li>但我仍然不知道<a href="https://www.lesswrong.com/posts/5spBue2z2tw4JuDCx/steering-gpt-2-xl-by-adding-an-activation-vecto"><u>转向向量</u></a>（即潜在空间中向量的激活添加）是否真的算作可解释性，并且真的显着改变了对齐的图像，而不仅仅是即时工程。好的，这是修补模型的新方法。但我不知道如何可靠地使用它来防止欺骗。 <span class="footnote-reference" role="doc-noteref" id="fnrefmf7vlk6ib69"><sup><a href="#fnmf7vlk6ib69">[7]</a></sup></span></li></ul><h2>轻松的对抗训练？</h2><p><strong>轻松的对抗训练？</strong> TL;DR 是，<a href="https://ai-alignment.com/training-robust-corrigibility-ce0e0a3b9b4d"><u>宽松的对抗训练</u></a>与对抗训练相同，但我们不是创建对抗输入来测试网络，而是创建对抗潜在向量。这可能很有用，因为创建真实的对抗性输入是对抗性训练的瓶颈。 [更多解释<a href="https://docs.google.com/document/d/1KXEWXHKwgeu-0NX5iirGS1h5zsh1skYMadZN3ZoVMAI/edit%23bookmark%3Did.2ats8akz8z6u"><u>请看这里</u></a>]</p><p>这似乎是正确的，但非常困难，并且仍然存在重大的<a href="https://ai-alignment.com/training-robust-corrigibility-ce0e0a3b9b4d"><u>概念困难</u></a>。已经提出了一种具体的方法，即<a href="https://www.lesswrong.com/posts/atBQ3NHyqnBadrsGP/latent-adversarial-training"><u>潜在对抗训练</u></a>，并且似乎很有希望，但是：</p><ul><li><strong>程序未明确说明</strong>。<strong>元参数会太多</strong>。校准这些元参数将是一场噩梦，您可能不想迭代具有欺骗性的强大模型。我们必须从元参数的第一个选择开始就做好。<i>正如作者自己所说，“这里唯一的希望在于外科医生在模型学会欺骗之前强制其保持绝对安全。一旦模型具有欺骗性，那么游戏就真的结束了。”</i></li><li><strong>我们仍然没有任何保证。</strong>这个过程允许一个对“小扰动”具有鲁棒性的潜在空间，但对“小扰动”具有鲁棒性<i>并不等同于不具有欺骗性</i>（我不清楚欺骗不会出现在约束区域之外）。</li><li>使用这种程序的论文效果有限，例如论文<a href="https://www.cs.purdue.edu/homes/taog/docs/CCS19.pdf"><u>ABS: Scanning Neural Networks for Back-doors by Artificial Brain Stimulation (Liu et al., 2019)</u></a>中的检测率约为 90%。 [ <a href="https://docs.google.com/document/d/1KXEWXHKwgeu-0NX5iirGS1h5zsh1skYMadZN3ZoVMAI/edit%23bookmark%3Did.ewixtcjxjqvq"><u>此处</u></a>总结的论文] 我认为这并不适用于所有类型的木马。</li></ul><p>据我所知，<a href="https://www.lesswrong.com/posts/atBQ3NHyqnBadrsGP/latent-adversarial-training"><u>潜在对抗训练</u></a>中描述的确切程序尚未经过测试。所以我们应该努力解决这个问题。 <span class="footnote-reference" role="doc-noteref" id="fnrefc2q5uxqhj6j"><sup><a href="#fnc2q5uxqhj6j">[8]</a></sup></span></p><h2>显微镜人工智能？</h2><p><strong>也许显微镜人工智能，即</strong>也许我们可以直接使用人工智能的世界模型，而不必了解一切。 Microscope AI 是一种不会用于推理的 AI，而是仅通过查看其内部激活或权重来使用，而不需要部署它。我的定义是这样的：我们可以向前传球，但只能在模型的中间进行。</p><ul><li>这违背了几乎所有的经济激励措施（参见 Gwern 的<a href="https://gwern.net/tool-ai%23:~:text%3DAn%2520Agent%2520AI%2520has%2520the,its%2520outputs%252C%2520on%2520harder%2520domains."><u>《为什么工具人工智能想要成为人工智能代理</u></a>》）。</li><li> <strong>($) 可解释性对于发现世界事实几乎没有用，并且仅通过查看权重来学习新东西太难了。</strong><ul><li>在<a href="https://arxiv.org/abs/2111.09259"><u>《Acquisition of Chess Knowledge in AlphaZero》</u></a>一文中，作者研究了“<i>我们是否可以通过解释经过训练的 AlphaZero 的<strong>行为</strong>来学习国际象棋策略</i>”。答：事实并非如此。他们仅使用 Stockfish 已知的概念来探测网络，并且没有获得新的基本见解。我们只检查 AlphaGo 在训练过程中<i>何时</i>学习人类概念。</li><li>我认为我们无法通过对陶哲轩的大脑进行逆向工程来学习范畴论。围棋棋手如何从围棋程序中学习策略？他们会解释 AlphaGo 的权重，还是试图理解这些程序的行为评估？回答：他们从自己的行为中学习，而不是通过解释模型来学习。我怀疑我们能否从我们还不知道的神经网络的权重/激活/电路中获得全新的知识，特别是考虑到仅从英语教科书中学习东西是多么困难。</li></ul></li><li><strong>根据定义，显微镜人工智能不应具有代理性。但能动性和探索对于人类发现新真理有巨大帮助。因此，在超人水平以下，</strong><i><strong>显微镜</strong></i><strong>需要具有</strong><i><strong>代理性</strong></i><strong>……这是一个矛盾。</strong> <a href="https://www.lesswrong.com/posts/Go5ELsHAyw7QrArQ6/searching-for-a-model-s-concepts-by-their-shape-a%23Philosophical_framing"><u>例如</u></a>，建议使用 Microscope AI 作为工具而不是<a href="https://www.lesswrong.com/posts/X2i9dQQK3gETCyqh2/chris-olah-s-views-on-agi-safety"><u>代理</u></a>。然而，要了解复杂事实的真相，我们需要对世界进行实验并积极寻找信息。这是一个模糊推理（随意跳过）：<ul><li> A) 要么<strong>信息已经存在并且被清楚地写</strong>在互联网上的某个地方，在这种情况下，就不需要显微镜人工智能（这就像文本检索）。</li><li> B）或者<strong>该信息在互联网上不存在</strong>，在这种情况下，有必要通过对世界进行实验或积极思考来发挥作用。这种特征只能通过强化学习“创建”，但无法通过监督学习“发现”，就像 MuZero 发现新的国际象棋策略一样。</li><li>或 C），<strong>这些信息并不是简单地写出来的，而是训练数据的深层特征</strong>，可以通过梯度下降来理解/理解。这是可以通过监督学习“发现”的特征类型。</li><li>如果是 B），我们需要代理，而它不再是显微镜。</li><li>如果 C)，我们可以应用上述推理<u>($)</u> + 能够通过纯梯度下降而不进行探索来实现这一点可能比通过探索来实现这一点的能力更高。 （这就像在梦中发现<a href="https://en.wikipedia.org/wiki/Quaternion"><u>四元数</u></a>公式一样？）。但即使是传奇数学家也需要付出一些努力，并在探索中保持积极性。他们不只是被动地阅读教科书。所以，恐怕超出了拉马努金的水平，太危险了？</li><li>所以，我很不确定，但总的来说，我不认为显微镜人工智能是降低人工智能风险的有前途或有效的方法。</li></ul></li></ul><p> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Burns_et_al___2022_"><u>附录</u></a>中包含一个简短的案例研究，用于通过探测从模型中提取知识<a href="https://www.lesswrong.com/posts/L4anhrxjv8j2yRKKp/how-discovering-latent-knowledge-in-language-models-without"><u>的发现潜在知识</u></a>技术。</p><h1>针对欺骗的预防措施似乎更加可行</h1><p>TL;DR：更理想的目标是实现一个不需要深入研究模型内部组件的世界。预防胜于治疗，或者至少，这是一种被忽视的策略。 </p><figure class="image image_resized" style="width:599.5px"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/lon9yhtv1wgba17yhryt" alt=""><figcaption><i>从</i><a href="https://www.lesswrong.com/posts/r3xwHzMmMf25peeHE/the-translucent-thoughts-hypotheses-and-their-implications%23The_Translucent_Thoughts_Hypotheses"><i><u>半透明的思想假设及其含义</u></i></a><i>，法比安·罗杰</i></figcaption></figure><p>我不认为可解释性是监控接近人类水平的 AGI 最有前途的方法，原因如下：</p><p><strong>我不认为神经网络能够在一次前向传递中接管。模型可能会用英语进行推理，并且会有半透明的想法</strong>（我们甚至希望获得透明的想法，半透明是隐写术可能的可怕之处）。为了制定一个有效的计划来毁灭世界，第一个人类水平的 AGI 需要通过思想链（CoT）在一定程度上外化其推理，在我看来，监控这个思想链要容易得多。思考而不是探究模型的内部结构。我们或许可以使用<a href="https://www.lesswrong.com/posts/r3xwHzMmMf25peeHE/the-translucent-thoughts-hypotheses-and-their-implications"><u>半透明思想假设</u></a>（Fabien，作者，给出了 20% 的机会，但我认为它会更像 60%）。我还认为，我们必须尽一切努力通过法规，<strong>并将自己置于一个这些假设成立的世界中。</strong></p><p>例如，魔法是可能的（顺便说一句，这是<a href="https://www.youtube.com/watch?v%3DEAN-PwRfJcA"><u>我最喜欢的把戏</u></a>），而人类的大脑可以如此轻易地被魔法操纵，这一事实是一个巨大的危险。因此，我们或许应该尝试让这种魔法变得不可能，例如通过训练人工智能系统进行基于流程的训练，使其仅一步一步地推理（基于流程的训练方法在<a href="https://www.lesswrong.com/posts/FFz6H35Gy6BArHxkc/task-decomposition-for-scalable-oversight-agisf-distillation"><u>AGISF 精炼</u></a>中进行了总结）。</p><h2>引导世界走向透明</h2><p><strong>提前考虑训练设置非常重要，并且可能会主导解释考虑因素，</strong>因为如果模型操纵的概念完全陌生，那么提供监督就会变得非常非常困难。与使用 RL/进化方法等从头开始训练的 AGI 相比，调整那些根据人类生成的文本进行预训练的聊天机器人要容易<a href="https://aligned.substack.com/i/88447351/the-ai-tech-tree-is-looking-favorably"><u>得多</u></a>。</p><p>如果是这种情况，我们应该关注 Fabien <a href="https://www.lesswrong.com/posts/r3xwHzMmMf25peeHE/the-translucent-thoughts-hypotheses-and-their-implications%23Research_Directions"><u>在此</u></a>详细介绍的各个方面和重要建议。以下是一些亮点：</p><ul><li><strong>让法学硕士只使用可理解的英语：</strong>防止模型使用隐写术、不对合成数据进行训练等……这些方向通常被非常忽视 - 例如，看看这个<a href="https://www.lesswrong.com/posts/bwyKCQD7PFWKhELMr/by-default-gpts-think-in-plain-sight?commentId%3DS4wqnxW5CYd8QsTox"><u>评论</u></a>。</li><li><strong>建立一个监督系统：</strong>这就是 Buck、IDA 的“<a href="https://youtu.be/YTlrPeikoyw?t%3D2415"><u>蓄势待发</u></a>”的技术研究，或者被忽视的基线，如<a href="https://arxiv.org/abs/2308.07308"><u>过滤</u></a>等……</li><li><strong>测试半透明思想假设</strong>并能够监控模型的异质性对于确保某些拟像具有类似大脑的表征非常重要（请参阅<a href="https://www.lesswrong.com/posts/iXbPe9EAxScuimsGh/linkpost-scaling-laws-for-language-encoding-models-in-fmri"><u>此</u></a>和<a href="https://www.lesswrong.com/posts/2QexGHrqSxcuwyGmf/linkpost-large-language-models-converge-on-brain-like-word"><u>此</u></a>）。<a href="https://arxiv.org/abs/2305.04388"><u>语言模型并不总是说出他们的想法：思想链提示中的不忠实解释</u></a>方向的更多工作。</li><li>通过技术工作、推广和治理等<strong>使假设成立</strong>。</li></ul><p><strong>我认为策略应该是：让我们瞄准一个不可能出现欺骗的世界。</strong> （我并不是说我们应该制定以默认情况下不可能发生欺骗为条件的计划，但我们应该尝试引导 AGI/世界走向一个不可能发生欺骗的地方）。我相信有多种方法可以思考和解决这个问题，并且这里需要更多的技术研究，从<a href="https://arxiv.org/abs/2302.00805"><u>条件预测模型：风险和策略</u></a>开始。</p><h2>认知模拟 -<i>设计的</i>可解释性</h2><p><strong>如果可解释性确实是一个瓶颈，我们可以使用</strong><a href="https://www.lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal"><strong><u>认知模拟</u></strong></a><strong>，在我看来，这比可解释性给我们带来了更好的可解释性和透明度。</strong></p><p>附录的<a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Cognitive_Emulations___Explainability_By_design"><u>认知仿真</u></a>部分中有一些注意事项。</p><h1>可解释性可能总体上是有害的</h1><p>（请注意，以下一些要点并非特定于 interp，但我认为它们特别适用于 interp。）</p><p><strong>错误的控制感：</strong></p><ul><li><strong>错误的理解感。</strong>当我们没有太多的时候，你很容易认为你开始理解我们开始得到保证。这是非常经典的：<ul><li>过去的我：“哟，我花了5个小时试图用<a href="https://transformer-circuits.pub/2021/framework/index.html"><u>变形金刚数学框架中</u></a>难以理解的数学公式来理解归纳头和K组合的机制，我明白了很多。”是的，但不是。</li></ul></li><li><strong>过度解读。</strong>很难说哪个解释结果是可靠的。例如，<a href="https://arxiv.org/abs/1810.03292"><u>显着性图的健全性检查</u></a>表明大多数像素归因技术通常具有误导性。 <span class="footnote-reference" role="doc-noteref" id="fnrefpo4e41md3r"><sup><a href="#fnpo4e41md3r">[9]</a></sup></span>同样，特征可视化最近被发现有一些相当致命的缺陷，请参阅<a href="https://arxiv.org/abs/2306.04719"><u>不要相信你的眼睛：关于特征可视化的（不）可靠性</u></a>，并且诸如<a href="https://rome.baulab.info/"><u>ROME</u></a>之类的模型编辑技术<a href="https://www.lesswrong.com/posts/QL7J9wmS6W2fWpofd/but-is-it-really-in-rome-an-investigation-of-the-rome-model"><u>非常具有误导性</u></a>。这主要是由于斯蒂芬·卡斯珀在他的序列中解释的方法论问题。 [参见附录： <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Methodological_problems_"><u>方法论问题</u></a>]。</li><li><strong>安全洗涤。</strong>我觉得安全研究的一部分是为了使大型实验室的能力研究合法化（尽管这并不完全特定于 interp）。<ul><li> <i>“我认为，相当一部分从事“人工智能联盟研究”的人的主要目标是“让人工智能联盟看起来合法”。这些不是同一个目标，很多优秀的人都可以看出，这让他们感觉有点被欺骗了，而且这在这个领域内造成了非常混乱的动态，人们对研究的次要影响是什么有强烈的看法，因为这就是他们感兴趣的主要事情，而不是询问研究是否指向真正能够调整人工智能的有用的真实事物”，</i>摘自 <a href="https://www.lesswrong.com/posts/psYNRb3JCncQBjd4v/shutting-down-the-lightcone-offices"><u>《关闭 Lightcone 办公室》</u></a> 。</li></ul></li><li>与对手研究等其他领域的成就相比<strong>，解释性研究的成就始终按照自己的曲线进行评级，并且被夸大了</strong>。例如，最近的论文<a href="https://arxiv.org/abs/2307.15043"><u>《对齐语言模型的通用和可转移对抗攻击》</u></a>令人印象深刻地发现了针对最先进模型的有效攻击，而无需任何涉及模型内部的解释。想象一下，如果机械可解释性研究人员做了完全相同的事情，但是通过研究模型内部结构会怎样？考虑到过去围绕精心挑选的问题（例如<a href="https://arxiv.org/abs/2301.05217"><u>这个</u></a>或<a href="https://arxiv.org/abs/2211.00593"><u>这个</u></a>）的玩具模型的机械解释性成就而出现的兴奋，似乎这样的事情可能会让人工智能安全研究界变得疯狂。 Stephen Casper <a href="https://www.alignmentforum.org/s/a6ne2ve5uturEEQK7/p/MyvkTKfndx9t4zknh%23:~:text%3DFrom%2520an%2520engineer%25E2%2580%2599s%2520perspective%252C%2520it%25E2%2580%2599s%2520important%2520not%2520to%2520grade%2520different%2520classes%2520of%2520solutions%2520each%2520on%2520different%2520curves.%25C2%25A0"><u>在这里</u></a>提出了类似的观点：“<i>从工程师的角度来看，重要的是不要在不同的曲线上对不同类别的解决方案进行分级。</i> <a href="https://www.alignmentforum.org/s/a6ne2ve5uturEEQK7/p/wt7HXaCWzuKQipqz3%23Imagine_that_you_heard_news_tomorrow_that_MI_researchers_from_TAISIC_meticulously_studied_circuits_in_a_way_that_allowed_them_to_:~:text%3Dtechniques%2520on%2520curves...-,Imagine%2520that%2520you%2520heard%2520news%2520tomorrow%2520that%2520MI%2520researchers%2520from%2520TAISIC%2520meticulously%2520studied%2520circuits%2520in%2520a%2520way%2520that%2520allowed%2520them%2520to%25E2%2580%25A6,-Reverse%2520engineer%2520and"><u>EIS VI：人工智能安全中机械可解释性工作的批评</u></a>（感谢 Stephen 强调了这一点）。</li></ul><p><strong>世界对于公共可解释性研究的协调性还不够：</strong></p><ul><li><strong>双重用途。</strong>似乎任何与信息表示相关的东西都可以以双重方式使用。这是一个问题，因为我相信可解释性研究的核心可以带来能力的重大进步。请参阅此<a href="https://www.lesswrong.com/posts/iDNEjbdHhjzvLLAmm/should-we-publish-mechanistic-interpretability-research"><u>帖子</u></a>。<ul><li>使用高级 interp 提供的见解来改进功能（例如通过模块化来优化推理时间和减少失败）可能比使用它们进行更好的监督更容易。这是因为<strong>能力优化比安全性优化要简单得多</strong>，因为我们缺乏衡量安全性的明确指标。</li></ul></li><li><strong>当可解释性开始有用时，您甚至无法发布它，因为它的信息风险太大。</strong>世界对于公共可解释性研究的协调性还不够。<ul><li>内特·苏亚雷斯对此<a href="https://www.lesswrong.com/posts/BinkknLBYxskMXuME/if-interpretability-research-goes-well-it-may-get-dangerous"><u>进行了解释</u></a>，随后又发布了<a href="https://www.lesswrong.com/posts/uhMRgEXabYbWeLc6T/why-and-when-interpretability-work-is-dangerous"><u>多篇</u></a><a href="https://www.lesswrong.com/posts/pQqoTTAnEePRDmZN4/agi-automated-interpretability-is-suicide"><u>帖子</u></a>。 <i>“只要可解释性研究人员了解了可以显着推进能力前沿的人工智能，我鼓励可解释性研究人员保持他们的研究</i><a href="https://www.lesswrong.com/posts/tuwwLQT4wqk25ndxk/thoughts-on-agi-organizations-and-capabilities-work"><i><u>封闭性</u></i></a><i>。 [……]我承认，原则上，公开分享研究见解既可以缩短时间，又可以提高我们成功的几率。我怀疑</i><a href="https://www.lesswrong.com/posts/vQNJrJqebXEWjJfnz/a-note-about-differential-technological-development"><i><u>现实生活中并非如此</u></i></a><i>。”</i></li><li>好的解释可以产生“foom overhang”，如“ <a href="https://www.lesswrong.com/posts/pQqoTTAnEePRDmZN4/agi-automated-interpretability-is-suicide"><u>AGI-自动解释性是自杀</u></a>”中所述。</li><li>良好的解释还可以创建<a href="https://www.lesswrong.com/posts/CRrkKAafopCmhJEBt/ai-interpretability-could-be-harmful"><u>信息安全/信息危害攻击向量</u></a>。</li><li>帖子“ <a href="https://www.lesswrong.com/posts/uhMRgEXabYbWeLc6T/why-and-when-interpretability-work-is-dangerous"><u>可解释性工作为什么以及何时是危险的？”</u></a> ” 最后以一个发人深省的语气结束，“<i>最后，如果有对齐意识的研究人员继续进入可解释性子领域，AGI 崩溃的可能性将会增加。</i> ”</li></ul></li><li><strong>可解释性已经对能力有所帮助。</strong>例如，对感应头的理解允许<a href="https://twitter.com/NeelNanda5/status/1618185819285778433"><u>更好的</u></a>架构<span class="footnote-reference" role="doc-noteref" id="fnrefplu4ji16iui"><sup><a href="#fnplu4ji16iui">[10]</a></sup></span> 。</li><li>可解释性可能是一个<a href="https://en.wikipedia.org/wiki/Wicked_problem%23Super_wicked_problems"><u>超级棘手的问题</u></a><span class="footnote-reference" role="doc-noteref" id="fnrefw7s6gsvuwb"><sup><a href="#fnw7s6gsvuwb">[11]</a></sup></span> 。</li></ul><p>因此，可解释性的“影响理论”清单不应简单地列出好处。重要的是要解释为什么这些好处超过了可能的负面影响，以及该理论如何节省时间并减轻可能出现的任何新风险。 </p><p></p><p><img style="width:414.07px" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/zao0mylkanwh60aajinm" alt=""></p><p> <a href="https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens"><i><u>Logit 透镜</u></i></a><i>的具体应用</i><i>并不是对欺骗的监督系统，而是像</i><a href="https://twitter.com/GoogleAI/status/1603845007663734785"><i><u>本文那样</u></i></a>加快推理速度的能力<i>。 （请注意，论文没有引用 Logit Lens，而是依赖于非常相似的方法）。</i></p><h1>外界观点：初级研究员从事interp而非其他技术工作的比例太高</h1><p>在我看来，很多人开始对齐研究是这样的：</p><ul><li>在 AI 安全领域的高级技能提升计划<a href="https://www.arena.education/"><u>Arena</u></a>结束时，今年（2023 年 6 月）几乎所有研究项目（16 个中的两个除外）都是 interp 项目。</li><li>在<a href="https://ia.effisciences.org/"><u>EffiSciences</u></a> ，在最后 3 个<a href="https://www.lesswrong.com/posts/DkDy2hvkwbQ54GM9u/introducing-effisciences-ai-safety-unit-1"><u>ML4Good</u></a>训练营结束时，学生们都开始对 interp 感兴趣，这是一个非常强大的吸引力。我自己也有罪。我已经将太多人重定向到它。我现在正在努力纠正自己的做法。<ul><li>在过去，如果我重构我的励志故事，它会是这样的：“哟，我有数学/机器学习背景，我该如何回收它？” -->; 然后<i>brrr interp</i> ，不要问太多问题。</li></ul></li><li>在<a href="https://apartresearch.com/"><u>Apart Research</u></a>黑客马拉松期间，可解释性黑客马拉松吸引的参与者数量往往是其他类型黑客马拉松的 3.12 倍。 （思考马拉松、安全基准……）。 <span class="footnote-reference" role="doc-noteref" id="fnrefavln8kyvlzg"><sup><a href="#fnavln8kyvlzg">[12]</a></sup></span></li><li> <a href="https://www.serimats.org/"><u>Seri Mats</u></a>中的可解释性流是最具竞争力的流之一（请参阅此<a href="https://twitter.com/leedsharkey/status/1656705667963535370"><u>推文</u></a>）。人们会努力尝试，但遭到拒绝、失望并失去动力。这是最近的一个重要问题。</li></ul><p>考虑到我们的不确定性，“不要把所有鸡蛋放在一个篮子里”似乎更稳健，并且有更有希望的方法来降低每单位工作的 x 风险（将在未来的帖子中介绍，主要是通过帮助/进行治理）。我宁愿看到一个<strong>更加多样化的生态系统</strong>，人们试图降低风险。有关此内容的更多信息<a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Technical_Agendas_with_better_ToI"><u>，请参阅具有更好 ToI 的技术议程</u></a>部分。</p><p>如果你问我高级研究人员中 interp 的比例是否也过高，我会有点不太自信。 Interp 似乎也是其中的重要组成部分：今年，虽然 Conjecture 和 Redwood 已经部分转向，但 Apollo、DeepMind、OpenAI 和 Anthropic 都有新的活跃的 interp 团队。我想我会特别批评 DeepMind 和 OpenAI 的可解释性工作，因为我不明白这比他们可能做的其他工作如何降低风险，而且我很欣赏他们期望实现的书面计划。</p><h1>到目前为止，我最好的解释员指南：书呆子狙击？</h1><p> 1.<strong>书呆子狙击/蜜罐的翻译？</strong></p><ul><li> <strong>Interp 是对人工智能研究的高度引人入胜的介绍</strong>。这真的很酷，我将它用于我的<a href="https://www.master-mva.com/cours/seminaire-turing/"><u>课程</u></a>和技术推广，但我已经有足够的可解释性材料，可供 10 小时的课程使用，无需添加更多内容。</li><li> <strong>Interp 作为初级研究人员的蜜罐？</strong>正如蜜罐用甜美的花蜜吸引蜜蜂一样，interp 在招聘新技术人员方面非常成功！但他们可能最好做一些比 interp 以外的事情（除非这是他们强大的比较优势）。</li><li> （书呆子狙击高级能力研究人员进入可解释性研究？更少的能力研究，更多的时间来调整人工智能？我开玩笑的，不要在家里这样做！）</li></ul><p> 2.<strong>荣誉提名：</strong></p><ul><li><strong>显示奇怪的故障</strong>，例如<a href="https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation"><u>SolidGoldMagicCarp</u></a>代币的问题，凸显了模型出现意外结果的可能性。更一般地说，可解释性工具对于红队工具箱非常有用。他们似乎能够引导我们解决比测试集和对手单独解决的更多问题。</li><li><strong>显示 GPT 不是随机鹦鹉吗？</strong>文章<a href="https://www.lesswrong.com/posts/nmxzr2zsjNtjaHh7x/actually-othello-gpt-has-a-linear-emergent-world"><u>实际上，Othello-GPT 具有线性涌现世界表示</u></a><strong>&nbsp;</strong>真的很酷<strong>。</strong>显示 OthelloGPT 包含世界模型对于技术推广确实非常有用（即使 OthelloGPT 擅长 Othello 就足够了，不是吗？）。</li><li><strong>这是介绍一致性研究的重要性和易处理性的好方法</strong><i>“可解释性为人们提供了一个非技术性的故事，说明一致性如何影响他们的生活、问题的规模以及如何取得进展。在我看来，没有其他的调整方法比这更有效。”</i> [来自<a href="https://www.lesswrong.com/posts/uK6sQCNMw8WKzJeCQ/a-longlist-of-theories-of-impact-for-interpretability?commentId%3DuzBFJDsy9Jqkxzdnx"><u>雷蒙德 D</u></a> ]</li><li><strong>更好：表明“我们基本上不知道它是如何做到这一点的。”，</strong>请参阅此<a href="https://twitter.com/robertskmiles/status/1663534255249453056"><u>推文</u></a>： </li></ul><p><img style="width:387.5px" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/q9gbkwdp3drer7soei5a" alt=""></p><h1>即使我们完全解决了interp，我们仍然处于危险之中</h1><p>没有人提出过相反的说法，但值得记住的是要了解全局。从较强的论据到较弱的论据：</p><ul><li> <strong>X风险场景有很多，甚至不涉及欺骗性人工智能。</strong>以下是此类场景的列表（请参阅此<a href="https://www.lesswrong.com/posts/nCeyBbhtJhToBFmrL/cheat-sheet-of-ai-x-risk"><u>备忘单</u></a>）：<ul><li> Christiano1 - <a href="https://www.lesswrong.com/posts/HBxe6wdjxK239zajf/more-realistic-tales-of-doom%23Part_I__You_get_what_you_measure"><u>你测量什么就得到什么</u></a></li><li>Crich1 - <a href="https://www.lesswrong.com/posts/LpM3EAakwYdS6aRKf/what-multipolar-failure-looks-like-and-robust-agent-agnostic%23Part_1__Slow_stories__and_lessons_therefrom"><u>生产网络</u></a></li><li>Soares - <a href="https://www.lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization"><u>人工智能的核心对齐问题：能力泛化、急速左转</u></a></li><li>科恩等人。 -<a href="https://onlinelibrary.wiley.com/doi/10.1002/aaai.12064"><u>先进的人工干预提供奖励</u></a></li><li>Gwern -<a href="https://gwern.net/fiction/clippy"><u>看起来你正试图接管世界</u></a></li><li>练习：以下是人工智能安全中心<a href="https://www.safe.ai/ai-risk"><u>列出的风险</u></a>。哪些可以通过interp解决？这些风险中至少有一半不直接涉及欺骗和干预。</li></ul></li><li><strong>具有强大功能的复杂系统的总体可解释性不足以消除风险。</strong>重大风险仍然存在。尽管我们完全了解原子弹的工作原理，但它们仍然构成巨大的风险。请参阅此<a href="https://en.wikipedia.org/wiki/List_of_nuclear_close_calls"><u>核危机列表</u></a>。</li><li><strong>可解释性隐含地假设人工智能模型不会以对用户不利的方式进行优化。</strong>考虑能够读懂像伏地魔这样的精神病患者的思想。这会让你感到安全吗？第一步仍然是限制他。然而，<strong>更好的情况是根本不必面对这种情况。</strong> （最后一个主张可能是最重要的教训 - 请参阅<a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Preventive_measures_against_Deception_seem_much_more_workable"><u>预防措施</u></a>）。 </li></ul><figure class="image image_resized" style="width:54.8%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/s6qlqvxf5an1gdofmmk3" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/qgopxuvs7mrmxegq8nco 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/smtffxyqwgnqhsasg4fy 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/lrifkrnrib0sybu8nvo8 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/j9jd3of3dwrmqpyg6xhr 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/cuouqap73vyebun1hfu7 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/e3ppnnd6cgyt2czjf3l6 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/vozp1plvffdzhxsuh1qy 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/qywwfgebl65ejalxo5ps 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/araz4zygcvf4szuqkmy4 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LNA8mubrByG7SFacm/spahqo0hllay5zjyvlk0 1010w"><figcaption> Pytorch hooks 可用于研究模型的内部结构。它们足够了吗？<i>我不知道，但</i>专辑《Take Me as I Am》中的<a href="https://www.youtube.com/watch?v=LveUcCBRrSo"><i><u>《Hook Me up Baby</u></i></a> <i>》可能是 interp 的国歌。</i></figcaption></figure><p><strong>所以，注重协调性至关重要！有一个协调水平，高于这个水平我们就不会死——没有这样的可解释性阈值。</strong>我们目前生活在一个协调比可解释性技术更有价值的世界。因此，我们不要忘记<a href="https://www.alignmentforum.org/posts/FfTxEf3uFPsZf9EMP/avoiding-perpetual-risk-from-tai%23Non_alignment_aspects_of_AI_safety_are_key_"><u>人工智能安全的不一致性方面是关键！</u></a> AI 对齐只是 AI 安全的一个子集！ ！ （我计划在下一篇文章中更深入地探讨这一点）。</p><p>这个论点的一个版本适用于一般的“对齐”，而不仅仅是插值，这些考虑因素将严重影响我对技术议程的建议。</p><h1>具有更好 ToI 的技术议程</h1><p>Interp 并不是一个坏蛋，但机会成本可能很大（特别是对于在大型实验室工作的研究人员）。</p><p>我并不是说我们应该停止做技术工作。以下是我认为有前途的技术项目列表（尽管我不会在这里过多争论这些替代方案）：</p><ul><li><strong>用于人工智能治理的技术作品。</strong>为了使监管更加健全和实际有用，需要做大量的技术和研究工作。 Richard Ngo 的<a href="https://www.lesswrong.com/posts/ho63vCb2MNFijinzY/agi-safety-career-advice#Governance_work"><u>AGI 安全职业建议</u></a><i>的治理部分确实很棒：“很有可能，在没有该领域背景的情况下，您可以在六个月内写一篇文章或论文，推动我们的知识前沿其中一个主题与 AGI 治理相关。</i> ”<ul><li>例如，论文中提出的<a href="https://arxiv.org/abs/2305.07153"><u>针对 AGI 安全和治理最佳实践的每一项措施：专家意见调查</u></a>可以成为创建专门组织来解决这些问题的借口，例如审计、许可和监控。</li><li>可怕的演示（但这不应该涉及功能获得研究。已经有很多强大的人工智能可用。大部分工作涉及视频编辑、寻找好故事、分发渠道和创建好的模因。不要让人工智能变得更危险只是为了完成这个。）。</li><li>同样， <a href="https://www.lesswrong.com/posts/Km9sHjHTsBdbgwKyi/monitoring-for-deceptive-alignment"><u>监控欺骗性联盟</u></a>可能是好的，因为“<a href="https://www.lesswrong.com/posts/vavnqwYbc8jMu3dTY/ai-coordination-needs-clear-wins"><u>人工智能协调需要明显的胜利</u></a>”。</li><li>人工智能政策的互操作性以及政策制定者可以使用的良好定义。</li><li>为危险能力创建基准。</li><li>这是其他想法的<a href="https://docs.google.com/document/d/1Tvz2JS8CZ51TW-vfU3vwRn8dpK3F0UttdhMrZC2o7hw/edit#bookmark=id.jnvbactyuay7"><u>列表</u></a></li></ul></li><li><strong>描述对准的技术困难。 （</strong><a href="https://www.lesswrong.com/posts/uHYYA32CKgKT3FagE/hold-off-on-proposing-solutions"><strong><u>推迟提出解决方案</u></strong></a><strong>“在尽可能彻底地讨论问题而不提出任何建议之前，不要提出解决方案。”）</strong><ul><li>创建人工智能风险<a href="https://en.wikipedia.org/wiki/Intergovernmental_Panel_on_Climate_Change"><u>IPCC</u></a></li><li>更多红队议程</li><li>解释对齐中的问题。</li></ul></li><li>对抗性例子、对抗性训练、潜在对抗性训练（唯一让我感到兴奋的<a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Relaxed_adversarial_training_"><u>结局</u></a>）。例如，论文“ <a href="https://arxiv.org/abs/2210.04610"><u>Red-Teaming the Stable Diffusion Safety Filter</u></a> ”或“ <a href="https://arxiv.org/abs/2307.15043"><u>Universal and Transferable Adversarial Attacks on Aligned Language Models</u></a> ”是对抗性鲁棒性工作的很好（而且非常简单！）的例子，有助于安全文化。</li><li><strong>技术推广</strong>。 <a href="https://www.youtube.com/@ai-explained-"><u>AI Explained</u></a>和<a href="https://www.youtube.com/c/robertmilesai"><u>Rob Miles</u></a>降低风险的效果似乎比所有可解释性研究的总和还要多。</li><li>本质上，问自己：“丹·亨德里克斯会做什么？”<ul><li>技术通讯、非技术通讯、基准、政策建议、风险分析、重要声明、课程和技术推广。</li><li>他不做翻译。将死！</li></ul></li></ul><p>简而言之，我的议程是<strong>“通过安全文化降低能力”</strong> ，我相信这是非常有益的，尽管这可能很困难。我想帮助人类了解我们还没有准备好调整人工智能。让我们等几十年，然后重新考虑。</p><p>如果我们真的必须构建通用人工智能并调整人工智能，那么在我看来，更理想的目标是建立一个不需要探究模型内部结构的世界。再次强调，预防胜于治疗。</p><h1>结论</h1><p>我反对可解释性影响的各种理论，并提出了一些替代方案。我相信，从不同的风险情景出发，重新构建影响理论，可以让我们更加清晰，并有更好的机会去做重要的事情。再次，我希望本文档能够引发讨论，因此请随意部分回应。可能<i>应该</i>有非零数量的研究人员致力于可解释性，这并不是为了攻击，而是希望能够促使人们进行更仔细的分析以及与其他影响理论的比较。</p><p>我们已经了解了一些广泛的经验教训，并且已经对哪些世界或多或少危险有一个总体了解。一些顶级实验室的 ML 研究人员甚至没有意识到或承认 AGI 是危险的，将模型连接到互联网、鼓励代理、进行强化学习和最大化指标在极限范围内并不安全。</p><p>在文明接受这些基本教训之前，我们应该避免玩火，并应尽可能减缓通用人工智能的发展，或者至少转向只有极其谨慎和有能力的行动者才能完成的世界。</p><p>也许我对 interp 的主要问题是，它隐含地强化了我们必须构建强大、危险的人工智能，然后调整它们的叙述。对于 X 风险，预防胜于治疗。我们<i>不要</i>构建强大而危险的人工智能。我们希望它们在设计上是安全的。</p><h1>附录</h1><h2>相关作品</h2><p>关于可解释性的优点和学术批评有大量的学术文献（请参阅<a href="https://www.lesswrong.com/posts/gwG9uqw255gafjYN4/eis-iii-broad-critiques-of-interpretability-research"><u>本页</u></a>以获取大量参考资料），但对可解释性作为减少存在风险的策略的整体反思相对较少。</p><p>提出可解释性论据的最重要的文章：</p><ul><li> <a href="https://www.lesswrong.com/posts/X2i9dQQK3gETCyqh2/chris-olah-s-views-on-agi-safety"><u>Chris Olah 对 AGI 安全的看法</u></a></li><li><a href="https://www.lesswrong.com/posts/uK6sQCNMw8WKzJeCQ/a-longlist-of-theories-of-impact-for-interpretability"><u>可解释性影响理论长列表</u></a></li><li><a href="https://transformer-circuits.pub/2023/interpretability-dreams/index.html"><u>可解释的梦想</u></a></li><li><a href="https://www.lesswrong.com/posts/uhMRgEXabYbWeLc6T/why-and-when-interpretability-work-is-dangerous%23When_Interpretability_is_Still_Important"><u>为什么以及何时可解释性工作是危险的</u></a></li><li><a href="https://www.lesswrong.com/posts/6ReBeYwsDeNgv6Dr5/the-defender-s-advantage-of-interpretability"><u>防守者的可解释性优势</u></a></li><li> <a href="https://www.lesswrong.com/posts/Km9sHjHTsBdbgwKyi/monitoring-for-deceptive-alignment"><u>监控欺骗性对齐</u></a></li></ul><p>反对可解释性</p><ul><li><a href="https://www.lesswrong.com/posts/pQqoTTAnEePRDmZN4/agi-automated-interpretability-is-suicide"><u>AGI-自动解释性等于自杀</u></a></li><li><a href="https://www.lesswrong.com/posts/uhMRgEXabYbWeLc6T/why-and-when-interpretability-work-is-dangerous"><u>为什么以及何时可解释性工作是危险的</u></a></li><li><a href="https://www.lesswrong.com/posts/iDNEjbdHhjzvLLAmm/should-we-publish-mechanistic-interpretability-research"><u>我们应该发表机械可解释性研究吗？</u></a></li><li> <a href="https://www.lesswrong.com/posts/gwG9uqw255gafjYN4/eis-iii-broad-critiques-of-interpretability-research"><u>EIS III：对可解释性研究的广泛批评</u></a></li><li><a href="https://www.lesswrong.com/s/a6ne2ve5uturEEQK7/p/wt7HXaCWzuKQipqz3"><u>EIS VI：对人工智能安全中机械可解释性工作的批评</u></a></li><li><a href="https://link.springer.com/article/10.1007/s13347-019-00372-9"><u>反对可解释性：机器学习中可解释性问题的批判性检验</u></a></li></ul><h3>工程师的可解释性序列</h3><p>我最初是通过重读《工程师的可解释性序列》开始我的调查的，其中斯蒂芬·卡斯珀对可解释性研究提出了许多很好的批评，这确实很有启发性。</p><p><strong>可解释性工具在实际应用中缺乏从业者的广泛使用。</strong></p><ul><li>目前还没有公开已知的可解释性技术已在 SOTA 模型（例如 ChatGPT）的生产中使用。</li><li>过去已有诸如<a href="https://distill.pub/2021/multimodal-neurons/"><u>CLIP</u></a>等 SOTA 多模态模型的可解释性研究，但这些研究只是描述性的。</li><li>有效市场假设：稳定扩散模型的审查过滤器所使用的技术是生成的图像嵌入和禁忌概念列表之间的<a href="https://arxiv.org/abs/2210.04610"><u>粗俗余弦相似度阈值</u></a>。是的，这可能看起来有点荒谬，但至少有一个过滤器，而且似乎 interp 还没有能够提供比这更方便的工具。</li></ul><p><strong>广泛批评。</strong>他<a href="https://www.lesswrong.com/posts/gwG9uqw255gafjYN4/eis-iii-broad-critiques-of-interpretability-research"><u>解释说</u></a>，interp 通常无法扩展，过于依赖人类，无法结合技术。他还<a href="https://www.lesswrong.com/s/a6ne2ve5uturEEQK7/p/wt7HXaCWzuKQipqz3%23Imagine_that_you_heard_news_tomorrow_that_MI_researchers_from_TAISIC_meticulously_studied_circuits_in_a_way_that_allowed_them_to_"><u>批评</u></a>mech interp，这可能不是最好的 interp 方式，因为它过于挑剔，只关注玩具示例，缺乏可扩展性，而没有做有用的事情。</p><p><strong>方法论问题：</strong></p><ul><li>他<a href="https://www.lesswrong.com/s/a6ne2ve5uturEEQK7/p/gwG9uqw255gafjYN4%23A_lack_of_practical_applications"><u>指出</u></a>，“造成这种情况的根本原因与可解释性研究没有得到应有的工程严谨性有关。”</li><li>值得注意的一点是，自从他的序列发表以来，某些方法变得更加严格。例如， <a href="https://www.lesswrong.com/posts/uLMWMeBG3ruoBRhMW/a-comparison-of-causal-scrubbing-causal-abstractions-and"><u>因果方法</u></a>、<a href="https://arxiv.org/abs/2211.00593"><u>激活修补</u></a>、 <a href="https://www.lesswrong.com/posts/nmxzr2zsjNtjaHh7x/actually-othello-gpt-has-a-linear-emergent-world"><u>仅使用线性探针进行探测</u></a>比描述性技术更严格、更有前景。</li><li>但我也认为可解释性可能存在根本性缺陷[部分<a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#What_does_the_end_story_of_interpretability_look_like__That_s_not_clear_at_all_"><u>interp 的最终故事是什么样的</u></a>]。</li></ul><h2>认知模拟 -<i>可解释性设计</i></h2><p><strong>如果可解释性确实是一个瓶颈，我们可以使用</strong><a href="https://www.lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal"><strong><u>认知模拟</u></strong></a><strong>，在我看来，这比可解释性给我们带来的更好的可解释性/透明度。</strong></p><p>我对认知模拟的理解：使用像 GPT-3 这样的 LLM 作为不同的子模块来模拟 GPT-4，这些子模块在输出下一个标记之前互相发送用<i>简单英语</i>编写的消息。如果神经网络有欺骗性的想法，我们可以在这些中间消息中看到它们。</p><p><strong>仅当认知模拟的一个模块具有欺骗性时才需要可解释性。</strong>那么也许你可以使用可解释性来解释这个模块。但我相信在可预见的未来，模型将需要思想链。因此，可解释性并不是“紧迫”的研究。</p><p><strong>如果我们不在这种认知模拟上使用强化学习，并且仅用英语提示不同的子模块，那么</strong>认知模拟将无法创建完整的“新语言”或能够混淆其许多思想。</p><p>是的，<strong>这个提案存在问题：</strong></p><ul><li> CoEms 并不排除隐写术或混淆。</li><li>即使当被要求使用思想链（CoT）进行推理时，法学硕士也能够在某种程度上跳过一些推理步骤（请参阅<a href="https://arxiv.org/abs/2305.04388"><u>语言模型并不总是说出他们的想法：思想链提示中的不忠实解释</u></a>）。然而，如果我们不训练模型跳过无数的推理步骤，它们将无法有效地混淆自己的想法。</li></ul><p>但我们可以通过以下方式进一步降低这些风险：</p><ul><li><strong>基于流程的培训</strong>，以确保系统习惯于更详细地详细说明其想法（并且不能跳过太多步骤）。它似乎比可解释性更可行（并且 <a href="https://openai.com/research/improving-mathematical-reasoning-with-process-supervision"><u>对齐税</u></a>甚至看起来是负的 - 例如，请参阅 <a href="https://openai.com/research/improving-mathematical-reasoning-with-process-supervision"><u>数学推理</u></a>的进展）</li><li><strong>选择推理：</strong> <i>“CoT 可以访问整个上下文，因此每个推理步骤不一定与最后一个推理步骤有因果关系。但是</i><a href="https://arxiv.org/abs/2205.09712"><i><u>选择推理强制</u></i></a><i>执行一种结构，其中每个推理步骤都必然从最后一个推理步骤开始，因此整个推理链是因果关系的。”</i>来自 Conjection 首席技术官<a href="https://docs.google.com/document/d/1ybJqvZ7vkfN641KAiDj1I0Deu-XGk8r9fSJEZ4NvLmc/edit?disco=AAAA21_wJ_g"><u>Sid Black</u></a> 。</li><li>其他想法列在“ <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Steering_the_world_towards_transparency">引导世界走向透明</a>”部分。</li></ul><p> Spicy：然而，认知仿真很可能会成为一场工程噩梦，因为它面临着小模型中始终存在的重大鲁棒性问题。对齐税将高于端到端系统，因此我们不太可能使用这项技术。瓶颈可能不是interp，而是预防性安全措施和安全文化的生态系统。 Conjecture 首席执行官康纳·莱希 (Connor Leahy) 在采访中解释了该问题的困难并推动了安全文化，这似乎比整个 CoEm 技术议程更具影响力。</p><h2>尼尔列表的详细反驳答案</h2><p>这是尼尔<a href="https://www.lesswrong.com/posts/uK6sQCNMw8WKzJeCQ/a-longlist-of-theories-of-impact-for-interpretability"><u>对可解释性影响的长列表</u></a>，以及对每个理论的批评。尼尔提出的理论以斜体显示，而我的批评则以标准字体呈现。</p><ol><li><i><strong>对齐研究的力量倍增</strong>：我们可以分析一个模型，看看它为什么给出不一致的答案，以及出了什么问题。这可以获得更丰富的经验调整工作数据，并使其进展更快。</i><ul><li>我认为这种“对齐研究中的力量倍增器”理论是有效的，但前提是其他影响理论的成功，恕我直言，这些理论几乎都是无效的。</li><li><strong>概念上的进步更加紧迫</strong>最好从概念上思考错位意味着什么，而不是专注于插值。 [部分<a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#What_does_the_end_story_of_interpretability_look_like__That_s_not_clear_at_all_"><u>可解释性的最终故事是什么样的？</u></a> ]</li><li><strong>双重用途：</strong>能力研究的力量倍增。</li></ul></li><li><i><strong>更好地预测未来系统</strong>：可解释性可以使人们更好地机械地理解机器学习系统的工作原理，以及它们如何随规模变化，类似于科学定律。这使我们能够更好地从当前系统推断未来系统，类似于缩放定律。例如，观察感应头的相变表明模型可以在训练期间快速获得能力</i><ul><li>在“ <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Interp_is_not_a_good_predictor_of_future_systems"><u>Interp 不是未来系统的良好预测器</u></a>”部分中受到批评</li></ul></li><li><i><strong>审计</strong>：我们得到了调度。训练系统后，我们可以检查是否存在偏差，并且只有在确信其安全时才进行部署</i><ul><li><strong>不是最直接的方式。</strong>这个 ToI 针对的是外部错位，下一个 ToI 针对的是内部错位。但目前，审核外部对齐的人不使用可解释性。他们评估模型，让模型说话，看看它是否与行为评估一致。可解释性对于寻找 GPT 的越狱并没有什么用处。</li><li>到目前为止，我仍然不知道我们将如何继续使用 interp 来审核 GPT-4。</li></ul></li><li><i><strong>欺骗审计</strong>：与审计类似，我们也许能够检测模型中的欺骗行为。这比完全审核模型要低得多，而且我们只需能够查看模型的随机位并识别电路/特征，这似乎是我们可以做到的事情 - 我认为这更多地是“世界的变革理论”可解释性比我希望的更难”。</i><ul><li>在“ <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Auditing_deception_with_interp_is_out_of_reach"><u>用interp审计欺骗是遥不可及的</u></a>”部分中受到批评</li></ul></li><li><i><strong>实现协调/合作：</strong>如果不同的参与者可以解释彼此的系统，那么就更容易相信其他参与者会明智地行事并更好地协调</i><ul><li><strong>不是最直接的方式。</strong>如果你真的想要协调与合作，你需要在人工智能治理以及专家和研究人员的推广方面提供帮助。<a href="https://www.safe.ai/statement-on-ai-risk"><u>关于人工智能风险的声明</u></a>使我们能够实现比 interp 可能永远无法实现的更多协调。</li></ul></li><li><i><strong>支持/反对威胁模型的经验证据</strong>：我们可以寻找理论化的未来威胁模型的经验例子，例如内部错位</i><ul><li><i><strong>协调威胁模型的工作</strong>：如果我们能够找到例如内部失调的经验例子，似乎更容易说服怀疑者这是一个问题，并且可能让更多的人致力于解决这个问题。</i><ul><li><a href="https://ai.facebook.com/research/cicero/"><u>西塞罗</u></a>或扑克模型已经能够掩盖信息或虚张声势地玩扑克。从那时起，我不知道向非技术人员展示典型的内在失调意味着什么。</li><li>这过于关注欺骗性的对齐，如果我们到达这一点，可能就太晚了。</li></ul></li><li><i><strong>协调减速</strong>：如果对齐确实很难，那么通过看似对齐但实际上具有欺骗性的模型的经验示例来协调该领域的谨慎/减速似乎要容易得多</i><ul><li><strong>不是最直接的方式。</strong>这是一个很好的变革理论，但 interp 并不是证明模型具有欺骗性的唯一方法。</li></ul></li></ul></li><li><i><strong>改善人类反馈</strong>：我们可以训练模型以正确的理由做正确的事情，而不是训练模型只做正确的事情</i><ul><li>看起来与当前的可解释性工作有很大不同。</li><li><strong>不是最直接的方式。</strong>基于流程的培训、模型心理学或其他不依赖插值的可扩展监督技术可能更有效。</li></ul></li><li><i><strong>知情监督</strong>：我们可以通过让每个步骤都包括检查系统是否实际对齐来改进 IDA 等递归对齐方案。注意：这与 7 有很多重叠。对我来说，区别在于 7 也可以应用于非递归训练的系统，例如当今通过人类反馈进行强化学习训练的系统</i><ul><li>是的，这是一种进步，但如果认为 RLHF 的唯一问题只是缺乏透明度或欺骗的问题，那就太天真了。例如，我们仍然会有代理模型（因为代理是人类偏好所偏爱的），而仅靠可解释性并不能解决这个问题。有关更多详细信息，请参阅<a href="https://www.lesswrong.com/posts/d6DvuCKH5bSoT62DB/compendium-of-problems-with-rlhf"><u>RLHF 问题概要</u></a>和<a href="https://www.lesswrong.com/posts/LqRD7sNcpkA9cmXLv/open-problems-and-fundamental-limitations-of-rlhf">RLHF 的开放问题和基本限制</a>。</li><li><strong>概念上的进步更为紧迫。</strong> “检查系统实际​​上是否对齐”到底意味着什么？ <a href="https://docs.google.com/document/d/1ybJqvZ7vkfN641KAiDj1I0Deu-XGk8r9fSJEZ4NvLmc/edit#bookmark=id.wqr2jvmzsg7c"><u>根本不清楚。</u></a></li></ul></li><li><i><strong>损失函数中的可解释性工具：</strong>我们可以直接将可解释性工具放入训练循环中，以确保系统以一致的方式执行操作。雄心勃勃的版本——这个工具太好了，不可能是古德哈特（Goodharted）。不太雄心勃勃 - 可能是古德哈特（Goodharted），但它很昂贵，并且这会改变归纳偏差以支持一致的认知</i>。<ul><li>出于显而易见的原因<strong>，双重用途</strong>，而这一点尤其危险。</li><li><strong>致命性列表 27. 选择不可检测性</strong>：“<i>针对解释性思想进行优化，针对可解释性进行优化。”</i></li></ul></li><li><i><strong>规范设置</strong>：如果可解释性更容易，则可能会期望在公司部署系统之前，尽职调查的一部分是解释系统并检查它是否符合您的要求</i><ul><li><strong>不是最直接的方式。</strong>评估，评估，评估。</li><li>无需等待可解释性。我们已经大致知道该怎么做了。我们可以根据<a href="https://www.serimats.org/evals"><u>《评估危险能力》</u></a>和论文《<a href="https://arxiv.org/abs/2305.15324"><u>极端风险模型评估</u></a><u>、</u> <a href="https://www.governance.ai/research-paper/towards-best-practices-in-agi-safety-and-governance">走​​向 AGI 安全和治理的最佳实践》</a>进行研究，最后一篇论文提出了 50 条关于 AGI 实验室应该做什么的陈述，但没有提及插值。</li></ul></li><li><i><strong>促进监管</strong>：如果监管机构和政策制定者/公司能够使用工具对其进行审计，他们就可以围绕人工智能系统的一致性制定更有效的监管</i><ul><li>与<strong>10.</strong><i><strong>规范设置</strong></i>相同的批评</li></ul></li><li><i><strong>文化转变 1：</strong>如果 ML 领域转向更好地理解模型，这可能会导致更好地理解失败案例以及如何避免它们</i><ul><li><strong>不是最直接的方式。</strong>技术推广、沟通、访谈甚至标准和<a href="https://www.lesswrong.com/s/FaEBwhhe3otzYKGQt"><u>基准</u></a>都更加直接。</li></ul></li><li><i><strong>文化转变 2：</strong>如果该领域期望更好地理解模型的工作原理，那么我们现在了解的程度将变得更加明显</i><ul><li>与<strong>12</strong>相同的批评。<i><strong>文化转变 1。</strong></i></li><li>这可能与现在发生的情况相反：人们对可解释性着迷，并继续在大型实验室中开发功能。我怀疑著名的 Distill 期刊对很多人来说都非常着迷，并且可能成为人们进入 ML 领域的着迷源泉，从而加速能力的提升。</li><li>请参阅<a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#False_sense_of_control_"><u>错误的控制感</u></a>部分。</li></ul></li><li><i><strong>认知习得性无助</strong>：我知道，我们还需要影响理论吗？在哪个世界“真正理解我们的黑匣子系统如何工作”没有帮助？</i><ul><li>我不知道，我们的资源有限，资金有限+机会成本。</li><li><strong>双重用途</strong>，请参阅“ <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Interpretability_May_Be_Overall_Harmful">可解释性可能总体有害</a>”部分。</li></ul></li><li> <i><strong>Microscope AI</strong> ：也许我们可以完全避免部署代理，通过训练系统执行复杂的任务，然后解释它们是如何做的并自己做</i><ul><li><a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Microscope_AI_"><u>显微镜人工智能部分的批评？</u></a> 。</li></ul></li><li><i><strong>训练人工智能来解释其他人工智能</strong>：即使在先进系统上可解释性确实很困难/劳动密集型，如果我们能够创建接近人类水平的一致人工智能，我们就可以提供这些可解释性工具并使用它们来解释更强大的系统</i><ul><li><strong>对象级别：</strong>训练人工智能来解释其他人工智能，可能有用，但已经很危险，而且我们已经处于超级<a href="https://www.lesswrong.com/posts/pQqoTTAnEePRDmZN4/agi-automated-interpretability-is-suicide"><u>危险的</u></a>场景类别中。</li><li><strong>元级别：</strong>这个方案非常具有投机性。我不想让文明的生存依赖于它。<a href="https://www.lesswrong.com/posts/DwqgLXn5qYC7GqExF/godzilla-strategies"><u>哥斯拉策略</u></a>可能不是一个好的策略（尽管这是有争议的）。</li></ul></li><li><i><strong>预测不连续性</strong>：通过了解正在发生的情况，我们可以预测我们看到一致性/功能不连续性的可能性有多大，并可能在训练时/部署系统之前检测到不连续性</i><ul><li>基本上与“ <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Interp_is_not_a_good_predictor_of_future_systems"><u>Interp 不是未来系统的良好预测器</u></a>”部分中的批评相同</li></ul></li><li><i><strong>干预训练</strong>：通过在训练期间解释系统，我们可以尽早注意到错位，可能在它足以采取策略来避免我们的注意之前，例如欺骗性对齐、梯度黑客、混淆其思想等。</i><ul><li>与“ <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Auditing_deception_with_interp_is_out_of_reach"><u>用 interp 审计欺骗是遥不可及</u></a>”部分中的批评基本相同</li></ul></li><li><i><strong>审核训练运行</strong>：通过在训练早期检查是否存在错位，我们可以停止看似错位的训练系统。这为我们提供了更多的机会来创建一个对齐的系统，而无需花费大量资金，例如允许我们尝试多种不同的方案、初始化等。这本质上将系统的分布转向对齐。</i><ul><li>与“ <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Auditing_deception_with_interp_is_out_of_reach"><u>用 interp 审计欺骗是遥不可及</u></a>”部分中的批评基本相同</li></ul></li><li><i><strong>引发潜在知识：</strong>使用模型行为的最短可解释性解释的长度作为 ELK 的训练损失 - 这个想法是，解释较短的模型不太可能包含人类模拟/你可以判断它们是否包含。 （这一点归功于林涛）</i><ul><li>与<strong>9.</strong><i><strong>损失函数中的可解释性工具相同的批评。</strong></i></li><li>与<strong>15. 显微镜 AI</strong>相同的批评。</li><li>与<strong>16.</strong><i><strong>训练 AI 解释其他 AI 的批评相同。</strong></i></li></ul></li></ol><h2>一些很酷的interp论文的案例研究</h2><p>这部分比较技术性。</p><p> Stephen Casper <a href="https://www.lesswrong.com/s/a6ne2ve5uturEEQK7/p/wt7HXaCWzuKQipqz3#Imagine_that_you_heard_news_tomorrow_that_MI_researchers_from_TAISIC_meticulously_studied_circuits_in_a_way_that_allowed_them_to_"><u>列出了</u></a>截至 2023 年 2 月的一系列令人印象深刻的可解释性论文。让我们尝试研究一下这些论文是否可以在未来用于降低风险。对于每篇文章，我都会提到相应的结局，并且该结局的批评者适用于该文章。</p><h3>鲍等人。 (2018)</h3><p><a href="https://arxiv.org/abs/1811.10597"><u>鲍等人。 (2018)</u></a> ：逆向工程并重新利用 GAN 来生成可控图像。</p><ul><li><strong>程序：（</strong><a href="https://www.youtube.com/watch?v=yVCgUYe4JTM"><u>视频</u></a>）我们使用 GAN 生成教堂图像。生成的图像中经常有树木。我们手动包围树木，然后找到 GAN 中主要负责生成这些图像区域的单元。找到这些区域后，我们对这些单元进行消融，结果树木消失了。</li><li><strong>结束故事：</strong> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Enumerative_safety_"><u>枚举安全性</u></a></li><li><strong>对于外部对齐有用吗？</strong>理想情况下，我们可以 1. 找到不需要的特征 2. 然后删除与这些特征最相关的网络部分。 This is a very limited form of alignment procedure, by ablation.<ul><li> Maybe we could use this kind of procedure to filter pornography, but why then train the network on pornographic images in the first place?</li><li> Basically, this is the same strategy as enumerative safety which is criticized above.</li></ul></li><li> <strong>Useful for inner alignment?</strong> Can we apply this to deception? No, because by definition, deception will not result in a difference in outputs, so we cannot apply this procedure.</li></ul><h3> Ghorbani et al. (2020)</h3><p> <a href="https://arxiv.org/abs/2002.09815"><u>Ghorbani et al. (2020)</u></a> : Identify and successfully ablate neurons responsible for biases and adversarial vulnerabilities.</p><ul><li> <strong>Procedure:</strong> ( <a href="https://slideslive.com/38936399/neuron-shapley-discovering-the-responsible-neurons"><u>video</u></a> ) It calculates the Shapley score of different units of a CNN and then removes the units with the highest Shapley value to maximize or minimize a metric. Removing certain units seems to make the network more robust to certain adversarial attacks.</li><li> <strong>End Story:</strong> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Enumerative_safety_"><u>Enumerative safety</u></a> (and <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Reverse_engineering_"><u>Reverse engineering</u></a> ?)</li><li> <strong>Useful for outer alignment?</strong> What would have happened if we had just added black women to the dataset? We can simply use a generative model for that and generate lots of images of black women. I&#39;m almost certain that the technique used by OpenAI to remove biases in <a href="https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2"><u>Dalle-2</u></a> , does not rely on interp.</li><li> <strong>Useful for inner alignment?</strong> Can we apply this to deception? No, again because the first step in using Shapley value and this interpretability method is to find a behavioral difference, and we need first to create a metric of deception, which does not exist currently. So again we first need to find first a behavioral difference and some evidence of deception.</li></ul><h3> Burns et al. (2022)</h3><p> <a href="https://arxiv.org/abs/2212.03827"><u>Burns et al. (2022)</u></a> : Identify directions in latent space that were predictive of a language model saying false things.</p><ul><li> <strong>Procedure:</strong> compare the probability of the &#39;Yes&#39; token with the probability probed from the world model.</li><li> <strong>End story:</strong> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Microscope_AI_"><u>Microscope AI</u></a></li><li> <strong>Useful for inner alignment?</strong><ul><li> Extracting knowledge from near GPT-3 level AIs, mostly trained through self-supervised learning via next token prediction, is a <a href="https://www.lesswrong.com/posts/bWxNPMy5MhPnQTzKz/what-discovering-latent-knowledge-did-and-did-not-find-4">misunderstanding</a> .</li><li> <strong>This technique requires a minimum of agency and is not just usable as an oracle.</strong><ul><li> <strong>Chain-of-thought will probably always be better.</strong> Currently, this technique barely performs better than next token prediction. Chain-of-thought performs much better, and it seems we have (obvious) <a href="https://twitter.com/BogdanIonutCir2/status/1664974522791895040"><u>theoretical reason</u></a> to think so. So using GPTs as just an oracle won&#39;t be competitive. This paper doesn&#39;t test the trivial baseline of just fine-tuning the model (which has been found to usually work better).</li><li> <strong>Agency is probably required.</strong> It seems unlikely that it will synthesize knowledge on its own in a world model during next-token prediction training. Making tests in the world, or reasoning in an open-ended way, is probably necessary to synthesize a proper truth feature in the world model in advanced GPT using continual learning.</li></ul></li><li> <strong>Conclusion:</strong> Yes, maybe in the future, if we create autonomous agents that conduct experiments and have their own world model, this kind of technique could probably be spot a mismatch between the world model oracle and what the model tells you. But if that were the case, we would probably already be in a very, very dangerous world. Civilization is not ready for this, and I still think that this method will be very brittle, and I prefer to aim for worlds where deception is unlikely. [section: ​​<a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Preventive_measures_against_Deception_seem_much_more_workable"><u>Preventive measures</u></a> ]</li></ul></li></ul><h3> Casper et al. (2022)</h3><p> <a href="https://arxiv.org/abs/2211.10024"><u>Casper et al. (2022)</u></a> : Identify hundreds of interpretable copy/paste attacks.</p><ul><li> <strong>Procedure:</strong> We try to find adversarial attacks automatically. For each image x, we optimize the latent space of a GAN to complete a patch in the image, to optimize the probability of classification towards class y2. We do this for each possible (x, y2) and we observe what appears in the patch. Then we search for natural patches that have a similar embedding to the synthetic adversarial patch, and if the similarity is high enough, we test the natural patch and see if this natural patch breaks the classifier.</li><li> <strong>End Story:</strong> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Relaxed_adversarial_training_"><u>Relaxed Adversarial training</u></a> ?</li><li> <strong>Useful for inner alignment?</strong> Conceptually yes, but this is so brittle. And if the trigger mechanism for deceptive alignment is not generable by the GAN or is not in the distribution of natural images/text, we won&#39;t find it.</li></ul><h3> Ziegler et al. (2022)</h3><p> <a href="https://arxiv.org/abs/2205.01663"><u>Ziegler et al. (2022)</u></a> : Debug a model well enough to greatly reduce its rate of misclassification in a high-stakes type of setting.</p><ul><li> <strong>Procedure</strong> : The project consists in building a highly reliable injury classifier: <i>“We started with a baseline classifier trained on some mildly injury-enriched (but otherwise mostly random) data. Then, over the course of several months, we tried various techniques to make it more reliable”.</i> The aim here is to minimize the false negative rate, striving to make the classifier as reliable as possible.: we do not want to let any problematic sentence or example go unnoticed. In order to find adversarial examples, they experimented with the following techniques:<ul><li> 1. unaugmented humans: humans manually search for problematic sentences,</li><li> 2. automatic paraphrasing: use of LLM to find variations of problematic sentences and progressively enrich the dataset.</li><li> and 3. humans augmented with a rewriting tool. It is mainly this last technique that was useful.</li></ul></li><li> <strong>End Story:</strong> Adversarial training and maybe <strong>&nbsp;</strong> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Relaxed_adversarial_training_"><u>Relaxed Adversarial training</u></a> ?</li><li> <strong>Robustness results:</strong><ul><li> <strong>In-distribution:</strong> They started with a classifier that had a 2.5% false negatives, and ended up with a classifier that had 0.003% false negatives! They are almost reaching the limits of detection for this type of dataset.</li><li> <strong>Out-of-distribution:</strong> The tool-assisted attack to generate an adversarial example now takes 26 minutes per example, which is only twice as long as the previous time of 13 minutes. This falls short of the paper&#39;s aim to gain many orders of magnitude in speedup. Unfortunately, even though the original dataset (in-distribution) is now almost completely well classified, it seems that it is still possible to easily create adversarial examples with automated tools, and we have only improved the defense by a factor of 2. But only a factor of 2 falls short of the aims of this project.</li><li> <strong>Conclusion:</strong> Thus, improving a lot in-distribution performance by several orders of magnitude seems to not have much impact on out-of-distribution. Even though Redwood <a href="https://www.alignmentforum.org/posts/n3LAgnHg6ashQK3fF/takeaways-from-our-robust-injury-classifier-project-redwood"><u>said</u></a> that this project could have been conducted better, this is currently rather a negative result to improve the adversarial robustness (ie out-of-distribution Robustness). In addition, we can link these results to the paper <a href="https://arxiv.org/abs/2211.00241"><u>Adversarial Policies Beat Superhuman Go AIs, Wang et al.. 2022</u></a> , which studies adversarial attacks on the Katago AI, which is superhuman in the game of Go. They show that it is probably possible to find simple adversarial strategies even against very superhuman AIs. And as a consequence, it seems that even for very robust and powerful AIs, It may always be possible to find adversarial attacks.</li></ul></li><li> <strong>How to use this for deception?</strong>不清楚。 Do we watch what the AI does, tell it <i>&#39;you are the lord of the universe, you can do whatever you want&#39;</i> or more subtle variations of this prompt and then see what happens? This is not really interpretability, it&#39;s much more prompt engineering with <a href="https://arxiv.org/abs/2306.09983"><u>consistency checks</u></a> or cyborgism than interp. (Beside, the interpretability technique that they used is quite underwhelming, only coloring tokens with the bigger gradient of the norm of the embedding of the token, and then basically iterating on synonymous of those important tokens). </li></ul><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn2stfurwyyg6"> <span class="footnote-back-link"><sup><strong><a href="#fnref2stfurwyyg6">^</a></strong></sup></span><div class="footnote-content"><p> Is feature visualization useful? Some findings suggest no: <a href="https://arxiv.org/abs/2302.10894"><u>Red Teaming Deep Neural Networks with Feature Synthesis Tools</u></a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fn4qi9kn3ip89"> <span class="footnote-back-link"><sup><strong><a href="#fnref4qi9kn3ip89">^</a></strong></sup></span><div class="footnote-content"><p> GradCam: Maybe this <a href="https://www.notion.so/Against-Almost-every-Theories-of-Change-of-Interpretability-61ebd2937cab4e12b9eb777454b7ed29?pvs%3D21"><u>paper</u></a> ? But this is still academic work.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn6xxwjs20rd7"> <span class="footnote-back-link"><sup><strong><a href="#fnref6xxwjs20rd7">^</a></strong></sup></span><div class="footnote-content"><p> I have organized <a href="https://www.lesswrong.com/posts/WF5JpmpK8EM4xKyve/new-hackathon-robustness-to-distribution-changes-and"><u>two</u></a> <a href="https://github.com/EffiSciencesResearch/hackathon42"><u>hackathons</u></a> centered around the topic of spurious correlations. I strongly nudged using interp, but unfortunately, nobody used it...Yes this claim is a bit weak, but still indicates a real phenomenon, see [section <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#Interpretability_tools_lack_widespread_use_by_practitioners_in_real_applications_"><u>Lack of real applications</u></a> ]</p></div></li><li class="footnote-item" role="doc-endnote" id="fnztj4j3pmerg"> <span class="footnote-back-link"><sup><strong><a href="#fnrefztj4j3pmerg">^</a></strong></sup></span><div class="footnote-content"><p> Note: I am not making any claims about ex-ante interp (also known as <a href="https://arxiv.org/abs/2207.13243"><u>intrinsic interp</u></a> ), which has not been so far able to predict the future system either.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn2464ho15s7t"> <span class="footnote-back-link"><sup><strong><a href="#fnref2464ho15s7t">^</a></strong></sup></span><div class="footnote-content"><p> Other weaker difficulties for auditing deception with interp: <strong>This is already too risky and Prevention is better than cure. 1) Moloch may still kill us:</strong> <i>&quot;auditing a trained model&quot; does not have a great story for wins. Like, either you find that the model is fine (in which case it would have been fine if you skipped the auditing) or you find that the model will kill you (in which case you don&#39;t deploy your AI system, and someone else destroys the world instead)</i> . […] <i>a capable lab would accidentally destroy the world because they would be trying the same approach but either not have those interpretability tools or not be careful enough to use them to check their trained model as well?”</i> [ <a href="https://www.lesswrong.com/posts/uK6sQCNMw8WKzJeCQ/a-longlist-of-theories-of-impact-for-interpretability?commentId%3DpHt4w9SN5PLLTzZuB"><u>Source</u></a> Rohin Shah]. <strong>2) We probably won&#39;t be competent enough to fix our mistake:</strong> “ <i>in order for auditing the model to help (directly), you have to actually be pretty confident in your ability to understand and fix your mistakes if you find one. It&#39;s not like getting a coin to land Heads by flipping it again if it lands Tails - different AGI projects are not independent random variables, if you don&#39;t get good results the first time you won&#39;t get good results the next time unless you understand what happened. This means that auditing trained models isn&#39;t really appropriate for the middle of the skill curve</i> .” [ <a href="https://www.lesswrong.com/posts/uK6sQCNMw8WKzJeCQ/a-longlist-of-theories-of-impact-for-interpretability?commentId%3D8Ckqr87YsoMprivEW"><u>Source</u></a> Charlie Steiner].</p></div></li><li class="footnote-item" role="doc-endnote" id="fnrbnra8fsacj"> <span class="footnote-back-link"><sup><strong><a href="#fnrefrbnra8fsacj">^</a></strong></sup></span><div class="footnote-content"><p> From “ <a href="https://www.lesswrong.com/posts/nXeLPcT9uhfG3TMPS/conditioning-generative-models"><u>Conditioning Generative Models</u></a> . “Suppose you had a language model that you knew was in fact a good generative model of the world and that this property continued to hold regardless of what you conditioned it on. Furthermore, suppose you had some prompt that described some agent for the language model to simulate (Alice) that in practice resulted in aligned-looking outputs. <strong>Is there a way we could use different conditionals to get at whether or not Alice was deceptive</strong> (eg prompt the model with “DeepMind develops perfect transparency tools and provides an opportunity for deceptive models to come clean and receive a prize before they&#39;re discovered.”)?”</p></div></li><li class="footnote-item" role="doc-endnote" id="fnmf7vlk6ib69"> <span class="footnote-back-link"><sup><strong><a href="#fnrefmf7vlk6ib69">^</a></strong></sup></span><div class="footnote-content"><p> For example, what happens If you prompt a deceptive model with a Joyous prompt, and prompt the same deceptive model with a sad prompt and then take the difference, you obtain a Joyous Deceptive model?</p></div></li><li class="footnote-item" role="doc-endnote" id="fnc2q5uxqhj6j"> <span class="footnote-back-link"><sup><strong><a href="#fnrefc2q5uxqhj6j">^</a></strong></sup></span><div class="footnote-content"><p> But at the same time, we could be pessimistic, because this good idea has been out there in the wild since Christiano <a href="https://ai-alignment.com/training-robust-corrigibility-ce0e0a3b9b4d"><u>described</u></a> it in 2019. So either this idea does not work and we have not heard about it. Or the community has failed to recognize a pretty simple good idea.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnpo4e41md3r"> <span class="footnote-back-link"><sup><strong><a href="#fnrefpo4e41md3r">^</a></strong></sup></span><div class="footnote-content"><p> Causal scrubbing could be a good way for evaluating interp techniques using something other than intuition. However, this is only suitable for localization assessment and does not measure how understandable the system is for humans.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnplu4ji16iui"> <span class="footnote-back-link"><sup><strong><a href="#fnrefplu4ji16iui">^</a></strong></sup></span><div class="footnote-content"><p> “ <i>I was previously pretty dubious about interpretability results leading to capabilities advances. I&#39;ve only really seen</i> <a href="https://arxiv.org/pdf/2212.14052.pdf"><i><u>two</u></i></a> <i>&nbsp;</i> <a href="https://arxiv.org/pdf/2302.10866.pdf"><i><u>papers</u></i></a> <i>which did this for LMs and they came from the same lab in the past few months. It seemed to me like most of the advances in modern ML (other than scale) came from people tinkering with architectures and seeing which modifications increased performance. But in a conversation with Oliver Habryka and others, it was brought up that as AI models are getting larger and more expensive, this tinkering will get more difficult and expensive. This might cause researchers to look for additional places for capabilities insights, and one of the obvious places to find such insights might be interpretability research.</i> ” from <a href="https://www.lesswrong.com/posts/BinkknLBYxskMXuME/if-interpretability-research-goes-well-it-may-get-dangerous?commentId=GYo8WegFmfxWmB5Z3"><u>Peter barnett</u></a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fnw7s6gsvuwb"> <span class="footnote-back-link"><sup><strong><a href="#fnrefw7s6gsvuwb">^</a></strong></sup></span><div class="footnote-content"><p> Not quite! Hypotheses 4 (and 2?) are missing. Thanks to Diego Dorn for presenting this fun concept to me.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnavln8kyvlzg"> <span class="footnote-back-link"><sup><strong><a href="#fnrefavln8kyvlzg">^</a></strong></sup></span><div class="footnote-content"><p> This excludes the governance hackathon, though, this is only from the technical ones. Source: Esben Kran.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1<guid ispermalink="false"> LNA8mubrByG7SFacm</guid><dc:creator><![CDATA[Charbel-Raphaël]]></dc:creator><pubDate> Thu, 17 Aug 2023 18:44:41 GMT</pubDate></item></channel></rss>