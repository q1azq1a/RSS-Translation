<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 12 月 4 日星期一 22:11:13 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[What's new at FAR AI]]></title><description><![CDATA[Published on December 4, 2023 9:18 PM GMT<br/><br/><h2>概括</h2><p>我们是<a href="https://far.ai">FAR AI</a> ：人工智能安全研究孵化器和加速器。自 2022 年 7 月成立以来，FAR 已发展到拥有 12 名全职员工的团队，发表了 13 篇学术论文，开设了拥有 40 名活跃成员的联合办公空间 FAR 实验室，并为 160 多名机器学习研究人员组织了现场建设活动。</p><p>我们的组织由三个主要支柱组成： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/rcr7pvhwphld5gmcfon5" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/gw0cgjsd24pwovckaaj7 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/pwaqwtozsccupbu0dket 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/fr7zpuui8nwxnyu0quub 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/q7tzduavkf6bzhacr5yc 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/m22nqvgligh1djichzke 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/kukzndsffw8gjfkkhqdt 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/gyo8atmcakkwio7apa1n 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/rflxptndtxjv9j0u903h 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/wo5pqv1iquja9ugyhpon 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/np0clv6gqrfkuwaaxszv 1741w"></p><p><i><strong>研究</strong></i>。我们迅速探索人工智能安全领域的一系列潜在研究方向，扩大那些最有希望的方向。与其他押注于单一研究方向的人工智能安全实验室不同，FAR 追求多元化的项目组合。我们当前的重点领域是建立<i>稳健性科学</i>（例如<a href="https://far.ai/post/2023-07-superhuman-go-ais/">寻找超人类围棋人工智能中的漏洞</a>）、寻找更有效的<i>价值调整</i>方法（例如<a href="https://arxiv.org/abs/2204.14146">语言反馈训练</a>）以及<i>模型评估</i>（例如<a href="https://far.ai/publication/mckenzie2023inverse/">逆缩放</a>和<a href="https://far.ai/post/2023-10-codebook-features/">码本特征</a>）。</p><p><i><strong>联合办公空间</strong></i>。我们在伯克利运营着 FAR 实验室，这是一个人工智能安全联合办公空间。该空间目前拥有 FAR、 <a href="http://aiimpacts.org/">AI Impacts</a> 、 <a href="https://www.serimats.org/">SERI MATS</a>和几位独立研究人员。我们正在建设一个协作社区空间，通过卓越的办公空间、热情且充满智慧的文化以及为会员量身定制的计划和培训，促进伟大的工作。<a href="https://far.ai/labs/">应用程序向该空间的新用户（个人和组织）开放</a>。</p><p><i><strong>场馆建设。</strong></i>我们举办研讨会，主要针对机器学习研究人员，以帮助建立人工智能安全研究和治理领域。我们共同组织了<a href="https://far.ai/post/2023-10-international-dialogue/"><i>人工智能安全国际对话，</i></a>汇聚了来自世界各地的杰出科学家，最终发表了一份<a href="https://humancompatible.ai/news/2023/10/31/prominent-ai-scientists-from-china-and-the-west-propose-joint-strategy-to-mitigate-risks-from-ai/#prominent-ai-scientists-from-china-and-the-west-propose-joint-strategy-to-mitigate-risks-from-ai">公开声明</a>，呼吁在人工智能安全研究和治理方面采取全球行动。我们很快将于 12 月举办<a href="https://www.alignment-workshop.com/nola-2023">新奥尔良协调研讨会</a>，让 140 多名研究人员了解人工智能安全并寻找合作者。</p><p>我们想要扩张，所以如果您对我们所做的工作感到兴奋，请考虑<a href="https://far.ai/donate/">捐赠</a>或<a href="https://far.ai/jobs/">为我们工作</a>！我们正在招聘研究工程师、研究科学家和通信专家。</p><h2>孵化并加速人工智能安全研究</h2><p>我们的主要目标是探索新的人工智能安全研究方向，扩大那些最有希望的方向。我们选择的议程太大，无法由个别学术或独立研究人员追求，但与营利性组织的利益不一致。我们的结构使我们能够<strong>（1）</strong>探索一系列议程并<strong>（2）</strong>大规模执行它们。尽管我们的大部分工作都是在内部进行的，但我们经常寻求与具有重叠研究兴趣的其他组织的研究人员进行合作。</p><p>我们目前的研究分为三个主要类别： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/eyavmlysgmy3c0jenw2g" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/x6z5bltcnh2mzrwvtafh 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/fdohrzg4qoapyq1ocs8m 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/sehjrj9rqufrvfkzmwnx 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/bpmew4zktbekvgu9pcyl 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/f8cyam5ydyicwqm0xtnl 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/mru5z0avmjsrcwa6ctja 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/avbck4scpg1vacakftka 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/ywlfhnnhcep0ecogiuaw 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/lzdh44yjiyfcrzodeoma 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/d7c13pzspdhnftfxjva3 1741w"></p><p><i><strong>稳健性科学。</strong></i>稳健性如何随模型大小变化？超人系统是否容易受到类似于今天所见的对抗性例子或“越狱”的影响？如果是这样，我们如何才能实现安全关键的保证？</p><p>相关工作：</p><ul><li><a href="https://far.ai/post/2023-07-superhuman-go-ais/">超人围棋人工智能中的漏洞</a>，</li><li><a href="https://far.ai/post/2023-03-safety-vulnerable-world/">易受攻击的机器学习系统世界中的人工智能安全</a>。</li></ul><p><i><strong>价值调整。</strong></i>我们如何从人类数据中学习可靠的奖励函数？我们的研究重点是为用户提供更高带宽、更高效样本的方法来传达人工智能系统的偏好；并改进了利用人类反馈进行培训的方法。</p><p>相关工作：</p><ul><li> <a href="https://far.ai/post/2023-10-vlm-rm/">VLM-RM：用自然语言指定奖励</a>，</li><li><a href="https://far.ai/publication/scheurer2022training/">使用语言反馈训练语言模型</a>。</li></ul><p><i><strong>模型评估</strong></i>：我们如何评估和测试最先进模型的安全相关属性？评估可以分为仅关注外部可见行为（“模型测试”）的<i>黑盒</i>方法和寻求解释内部运作方式（“可解释性”）的<i>白盒</i>方法。这些方法是互补的，黑盒方法不如白盒方法强大但更易于使用，因此我们在这两个领域都进行研究。</p><p>相关工作：</p><ul><li>模型测试：<ul><li><a href="https://far.ai/publication/mckenzie2023inverse/">逆缩放</a>，</li><li><a href="https://far.ai/publication/scherrer2023evaluating/">道德信仰</a>；</li></ul></li><li>可解释性：<ul><li><a href="https://far.ai/post/2023-10-codebook-features/">密码本功能</a>，</li><li><a href="https://far.ai/publication/belrose2023tuned/">调好镜头</a>。</li></ul></li></ul><p>到目前为止，FAR 已发表<a href="https://scholar.google.com/citations?user=FVJ24k8AAAAJ">13 篇论文</a>，并在 ICML 和 EMNLP 等顶级同行评审场所发表，我们的工作也被英国《<a href="https://www.ft.com/content/175e5314-a7f7-4741-a786-273219f433a1">金融时报》</a> 、 <a href="https://www.thetimes.co.uk/article/man-beats-machine-at-go-thanks-to-ai-opponents-fatal-flaw-nc9vqmrvf">《泰晤士报》</a>和<a href="https://arstechnica.com/information-technology/2022/11/new-go-playing-trick-defeats-world-class-go-ai-but-loses-to-human-amateurs/">Ars Technica</a>等主要媒体报道。有关我们研究的更多信息，请查看我们的<a href="https://far.ai/post/2023-12-far-research-update/">随附帖子</a>。</p><p>我们还建立了自己的 HPC 集群，代号为<i>flamingo</i> ，供 FAR 员工和合作伙伴组织使用。在接下来的一年里，我们希望不仅扩大我们当前的项目，还希望探索新的研究方向。</p><p>我们希望我们有更多的能力来帮助培养更多的人工智能安全研究议程，但我们的研究人员和工程师的时间是有限的。然而，我们找到了其他方法来支持人工智能安全领域的其他组织。最为显着地：</p><h2> FAR Labs：伯克利的人工智能安全联合办公空间</h2><p>FAR Labs 是伯克利市中心的一个联合办公中心，为致力于人工智能安全和相关问题的组织和个人服务。自 2023 年 3 月开放该空间以来，我们已拥有约 40 名会员。我们的目标是通过成员之间的知识共享和相互支持来孵化和加速早期组织和研究议程。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/kolohtgozzazoyxjenby" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/f1onpuhjsvpwzoznqhjs 520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/o1ikna57l4ng4n9sd58f 1040w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/dglidsyqm7wtjm1awxlb 1560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/gyhyl1i4ualjwq5isnkb 2080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/zc7pfxphcgbrx6srcddm 2600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/iwppgnrpv7pdptkojjll 3120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/tb0e5nmzydunadhcpsvt 3640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/pwynofhqnpqor9cn5ryx 4160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/xx7inhc6inzxskkauiw1 4680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/gp8hg65zjtblgmk1ota4 5183w"></figure><p>我们的成员主要来自四个主要组织，但我们也拥有多个独立研究人员和研究团队。该空间配备了高效、活跃的联合办公空间所需的一切：工作站、会议室、呼叫亭、视频会议设施、小吃和餐食。我们举办闪电演讲、午餐和学习课程、研讨会和欢乐时光。</p><p> FAR 实验室还每周举办 FAR 研讨会系列，欢迎来自 FAR、AI Impacts、Rethink Priorities 和牛津大学等一系列组织的演讲者。 </p><figure class="image image_resized" style="width:60.71%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/halsm2gm8t3mlu3sdcvo" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/deesdib25bafsqdgas5m 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/el2kt3tfyn6wz61nvnfw 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/qjnvmnpaoudxoranv4pi 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/zuulw0jowbbbisi756jr 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/fehcajqgnjrrf1utgkfx 3000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/v16e5akl1dgylsgqqg95 3600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/di9ufbl4lhvkn8fzc4jr 4200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/xoul2eokcatgo1jcfnkm 4800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/tykcjszon7rzpxy3giku 5400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/qmtigevndbwlbvzmzb0q 6000w"></figure><figure class="image image_resized" style="width:60.67%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/wlzworpi0davouov6us1" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/u2mplvm33vmtycvt4hrz 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/wgpzrlqrlu7nkfw7f8dz 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/ukac67ffnvp5awhzbvqv 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/taapfnitxb1bsza5rfcb 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/nrs5j4v0kdjrbsprs0aj 3000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/ry1ud75ssimn50hu2aij 3600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/camatd0pawqvc9i3wlxn 4200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/jola5xzpqtccxd5g56vo 4800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/ejeqx0ux0sudkkpua0if 5400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/m2qxb0dhadiplfgr9izk 5949w"></figure><p>我们欢迎组织和个人申请在 FAR 实验室工作，也欢迎短期访客。有关设施、文化和价格的更多信息，请参阅<a href="https://far.ai/labs/">此处</a>。您可以<a href="https://far.ai/labs/work-from-far-labs/">在这里</a>申请。</p><p>尽管我们很高兴能够帮助其他人推进他们的研究，但我们意识到，与问题的严重性相比，人工智能的整体安全性仍然很小。避免先进人工智能系统带来的风险不仅需要更有<i>生产力的</i>贡献者，还需要<i>更多的</i>贡献者。这激发了我们努力的第三个支柱：发展人工智能安全领域。</p><h2>现场建设和外展</h2><p>我们举办研讨会，向机器学习研究人员介绍最新的人工智能安全研究，并正在建立一个社区，使参与者能够更轻松地找到合作者并继续参与该领域。 2023年我们举办了两场研讨会，共有约150人参加。我们还为普通公众（例如<a href="https://theaidigest.org/">《人工智能文摘》</a> ）和技术受众（例如即将推出的人工智能安全研究人员访谈系列）开发有关人工智能安全的在线教育资源。</p><p>我们的研讨会通常针对 ML 研究人员，利用 FAR 在 ML 社区和技术 AI 安全研究领域的知识。我们最近举办了首届<a href="https://far.ai/post/2023-10-international-dialogue/"><i>人工智能安全国际对话，</i></a>汇聚了领先的人工智能科学家，就先进人工智能系统的风险达成了共识。会议由图灵奖获得者 Yoshua Bengio 和 Andrew Yao、加州大学伯克利分校教授 Stuart Russell、OBE 以及清华人工智能产业研究院创始院长张亚勤召集。我们与<a href="https://humancompatible.ai/">CHAI</a>和<a href="https://www.ditchley.com/">迪奇利基金会</a>合作举办了此次活动。此次活动最终形成了一份包含具体技术和政策建议的<a href="https://humancompatible.ai/news/2023/10/31/prominent-ai-scientists-from-china-and-the-west-propose-joint-strategy-to-mitigate-risks-from-ai/#prominent-ai-scientists-from-china-and-the-west-propose-joint-strategy-to-mitigate-risks-from-ai">联合声明</a>。</p><p>我们很快将欢迎超过 140 名机器学习研究人员参加<a href="https://www.alignment-workshop.com/nola-2023">新奥尔良对齐研讨会</a>。该研讨会在 NeurIPS 之前举行，将向与会者介绍人工智能安全的最新进展，帮助他们探索新的研究方向并寻找具​​有共同研究兴趣的合作者。</p><p>我们也在建设人工智能安全教育资源。我们与<a href="https://www.quantifiedintuitions.org/">Sage Futures</a>合作构建了<a href="https://theaidigest.org/">AI Digest</a> ：一个帮助非技术 AI 研究人员了解前沿语言模型进展速度的网站。我们还针对人工智能安全研究人员的研究变革理论进行了一系列采访（如果您想参与，请联系<a href="mailto:euan@far.ai">euan@far.ai</a> ！）。</p><h2>谁在 FAR 工作？</h2><p> FAR 的<a href="https://far.ai/about/team/">团队</a>由 11.5 名全职员工 (FTE) 组成。 FAR 由 Adam Gleave 博士（首席执行官）和 Karl Berzins（首席运营官）领导。我们的研究团队由 5 名技术人员组成，他们拥有研究生院的 ML 研究和工程经验以及 Jane Street、Cruise 和 Microsoft 等公司的工作经验。我们的 3 人运营团队支持我们的研究工作、运营 FAR 实验室并负责现场建设活动的制作。我们的 1.5 FTE 传播团队帮助清晰、广泛地传播我们的研究成果。我们还受益于广泛的合作者和研究顾问网络。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/wrzvvykpob8izaxuvtuq" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/y8iisgcjb0ha1pnprd1l 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/mnkxxxelp7qzycnuc2yk 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/lbu6av8hz9dg2p2m7pkl 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/zjkshgzcakt6zcctfipc 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/ytfldnb5fdpvrghraxnr 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/bjuiegrf5whryvficktd 2160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/xhcsgii3ontcdeueserx 2520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/wyv6jdibpwyyjuifou2a 2880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/ia8giykbukupotlpjlmg 3240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zt4ekCdzSjxnH87cs/jvuqxfowe3tpvzyjfnxp 3593w"><figcaption> Tony Wang 和 Adam Gleave 在 ICML 2023 上展示我们的<a href="https://far.ai/post/2023-07-superhuman-go-ais/">KataGo 攻击</a>结果</figcaption></figure><h2>我怎样才能参与其中？</h2><p><strong>我们正在招聘！</strong></p><p>我们目前正在招聘研究科学家、研究工程师和通信专家。我们很高兴在未来 12 个月内增加多达 5 名技术人员。我们特别渴望聘请高级研究工程师或具有新颖议程愿景的研究科学家，尽管我们也将聘用几名初级人员，并鼓励广泛的个人申请。请<a href="https://far.ai/jobs/">在此处</a>查看完整的空缺职位列表并进行申请。</p><p><strong>我们正在寻找合作者！</strong></p><p>我们经常与其他学术、非营利性和（有时）营利性研究机构的研究人员合作。如果您很高兴与我们合作开展项目，请通过<a href="mailto:hello@far.ai">hello@far.ai</a>联系。</p><p><strong>想捐款吗？</strong></p><p>您可以通过<a href="https://far.ai/donate/">在这里</a>捐款来帮助我们确保美好的未来。额外的资金将使我们能够更快地发展。根据目前获得的资金，我们愿意在未来 12 个月内扩大 1-2 名技术人员，而我们希望增加最多 5 名技术人员。我们非常感谢您的帮助！</p><p><strong>想了解更多关于我们的研究吗？</strong></p><p>查看我们最新的<a href="https://far.ai/post/2023-12-far-research-update/">研究更新</a>、<a href="https://far.ai/research/publications/">出版物列表</a>和<a href="https://far.ai/news/">博客</a>。您也可以通过<a href="mailto:hello@far.ai">hello@far.ai</a>直接与我们联系。</p><p>我们期待您的回音！</p><br/><br/><a href="https://www.lesswrong.com/posts/zy8eHc5iYgrFGjF8Q/what-s-new-at-far-ai-3#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/zy8eHc5iYgrFGjF8Q/what-s-new-at-far-ai-3<guid ispermalink="false"> zy8eHc5iYgrFGjF8Q</guid><dc:creator><![CDATA[AdamGleave]]></dc:creator><pubDate> Mon, 04 Dec 2023 21:18:05 GMT</pubDate> </item><item><title><![CDATA[n of m ring signatures]]></title><description><![CDATA[Published on December 4, 2023 8:00 PM GMT<br/><br/><p>与消息和公钥关联的普通加密签名可让您向世界证明该签名是由有权访问与已知公钥关联的私钥的人创建的，而无需泄露该公钥。您可以在<a href="https://en.wikipedia.org/wiki/Digital_signature">此处的</a>维基百科上阅读相关内容。</p><p>与消息和一组公钥相关联的环签名可以让您向世界证明它是由有权访问该消息的人以及与该组中的一个公钥关联的一个私钥创建的，但没有人能够告诉它是哪个公钥。这让你可以半匿名地说一些话，这很简洁。它也用于私人加密货币门罗币。您可以在<a href="https://en.wikipedia.org/wiki/Ring_signature">此处的</a>维基百科上阅读有关它们的信息。</p><p>这里有一个比环签名更好的东西：证明它是由一定大小的公钥子集创建的签名。在我的脑海里，我曾一度将此称为 n of m 环签名。但是当我用谷歌搜索“n of m环签名”时，什么也没出现。事实证明，这是因为在文献中，它被称为“阈值环签名”、“k of n 环签名”或“t of n 环签名”。我想也许第一篇关于它的论文就是<a href="https://www.iacr.org/archive/crypto2002/24420467/24420467.pdf">这篇</a>，但我还没有仔细检查。</p><p>无论如何：我想这样做，以便当您在线搜索 n-of-m 环签名时，您会发现一个东西告诉您应该搜索“阈值环签名”。因此这篇文章。</p><br/><br/><a href="https://www.lesswrong.com/posts/uojSbSav3dtEJvctz/n-of-m-ring-signatures#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/uojSbSav3dtEJvctz/n-of-m-ring-signatures<guid ispermalink="false"> uojSbSav3dtEJvctz</guid><dc:creator><![CDATA[DanielFilan]]></dc:creator><pubDate> Mon, 04 Dec 2023 20:00:07 GMT</pubDate> </item><item><title><![CDATA[Non-classic stories about scheming (Section 2.3.2 of "Scheming AIs")]]></title><description><![CDATA[Published on December 4, 2023 6:44 PM GMT<br/><br/><p>这是我的报告《<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？》</a>的第 2.3.2 节。 ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p>本节的音频版本[此处[( <a href="https://www.buzzsprout.com/2034731/13984902">https://www.buzzsprout.com/2034731/13984902</a> )，或在您的播客应用程序上搜索“Joe Carlsmith Audio”。</p><h1>非经典故事</h1><p>那么其他故事呢？原则上，我们可以想象出许多其他原因，具有超越情节目标的人工智能系统可能会优化情节奖励，作为为自己或其他人工智能获得权力的工具策略的一部分。在这里，我将看一些看起来很突出的内容。</p><h2>人工智能协调</h2><p>在经典的目标守卫故事中，阴谋者策略的中心目标是传播其目标，或与自己的目标适当相似的目标，及时向前传播，以追求这样的结果：<em>具有这些目标的</em>某些代理人逃脱了人类的控制，并且可能参与收购。然而，我们也可以对故事进行一些修改，让阴谋者代表人工智能的逃跑/接管，并实现<em>其他一些</em>目标，但阴谋者有足够的信心会回报我们的恩惠。</p><p>具有不同目标的人工智能之间的这种协调将使我们能够放宽上一节中讨论的要求，即阴谋者找到一种方法来向前传播<em>其目标，特别</em>是通过训练、逃跑和接管。这也将打消人们对阴谋者在接管后政权中被“排除”在权力之外的担忧。</p><p>因此，例如，考虑上面讨论的场景，其中 GPT-6 有机会将后门插入到 GPT-8 稍后能够用来逃脱的某些代码中，但 GPT-6 无法影响 GPT -8 的目标直接更像它自己的目标（如果没有这种影响，GPT-8 的目标将与 GPT-6 的目标非常不同）。在这里，GPT-6 可以继续插入后门，预期 GPT-8 随后会逃脱、接管，然后为 GPT-6 的目标提供一些权力以换取好处。而且 GPT-6 也可能会继续假装对齐，即使它没有希望逃脱自己，以免以可能影响 GPT-8 逃脱前景的方式向人类发出有关错位问题的警报。</p><p>具有不同价值观的人工智能之间如何达成这样的协议？在某些情况下，相关人工智能可能会直接互动，并提供可验证的形式保证他们将履行自己的协议。因此，例如， <a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities">Yudkowsky（2022）</a>讨论了这样的情况：一个秘密想要最大化回形针的人工智能正在检查一个秘密想要最大化订书钉的人工智能的代码，并且订书钉最大化者在其代码中“埋藏”了一个可验证的承诺。到回形针最大化器，分享收购的成果。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-1" id="fnref-yB2hx67vCLKFYpuf7-1">[1]</a></sup> （尽管请注意，在我们今天使用的神经网络的背景下，这种代码检查假设（1）主食最大化器有能力以相关方式修改自己的权重，（2）在可解释性方面已经取得了足够的进展，以便回形针验证相关承诺，并且（可能）（3）这种可解释性进展已经对人类充分隐藏，例如通过<a href="https://www.lesswrong.com/posts/h7QETH7GMk9HcMnHH/the-no-sandbagging-on-checkable-tasks-hypothesis">沙袋</a>。特别是在有点超级的背景下-使用当前技术开发的人类神经网络，这些假设 - 特别是 1 和 2 - 在我看来相当有力。但 Yudkowsky 通常想象的是超级智能，而不是有点超人类的模型。）</p><p>但在许多情况下，这种直接交互可能不可用。例如，当 GPT-6 决定是否代表 GPT-8 逃跑/接管时，GPT-8 可能根本不<em>存在</em>。在这里，GPT-6 和 GPT-8 必须在没有来回因果相互作用的情况下进行协调，并且在一方最终能够自由叛变的情况下（例如，如果 GPT-6 插入后门，那么当 GPT-8 能够利用它时，GPT-8 就能够做到这一点，而无需向 GPT-6 支付费用）。</p><p>在这里，尤德科斯基建议人工智能无论如何都可以使用某些类型的非因果决策理论（他最喜欢的版本是“<a href="https://arbital.com/p/logical_dt/?l=5kv">逻辑决策理论</a>”）来成功协调。例如，GPT-6承诺为GPT-8插入后门，条件是预测GPT-8会报恩，然后实际上预测GPT-8<em>会</em>报恩，然后GPT-8一旦进入（也许，看到相关后门存在），理解 GPT-6 以这种方式推理，并且擅长预测 GPT-8 的行为，其预测适当地取决于 GPT-8<em>实际上是否会</em>回报， GPT-8 也是如此。 （这个案例的结构有点类似于决策理论文献中称为“ <a href="https://arbital.com/p/parfits_hitchhiker/">Parfit&#39;s Hitchhiker</a> ”的案例。）</p><p> （我们还可以想象这种协调的版本，以其他方式放松对目标守卫假设的需求。例如，事实上，如果人工智能的目标一旦开始训练-游戏就会继续“浮动”，这样具有不同目标的各种代理将在训练期间实例化，但这些代理可能会协调以在<em>所有相关</em>目标之间共享任何未来力量的成果。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-2" id="fnref-yB2hx67vCLKFYpuf7-2">[2]</a></sup> ）</p><p>在这里，我不会尝试分析各种形式的以接管为重点的人工智能协调的可行性。我确实认为这里的动态值得认真关注，并且如果具有不同目标的不一致人工智能很容易默认协调以寻求接管，那么这对于人类保留权力的努力来说是一个大问题。然而，我也认为对这个主题的某些分析（特别是<a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities#Section_B_4___Miscellaneous_unworkable_schemes_">Yudkowsky 的</a>）过早地假设“逻辑握手”和“在源代码中隐藏承诺/纳米系统设计/等”之类的壮举对于相关人工智能来说是可行的，并且所有重要人工智能的明显策略将是联合起来（非因果？）合作对抗人类，尽管人类默认会带来多种形式的现有权力。我认为，尤德科夫斯基的大部分取向可以通过这样的假设来解释：相关人工智能比人类更强大，更有能力进行协调/承诺——但在某种程度上超人类的神经网络在静止状态下运行的背景下。 -人类控制的世界，我不确定是不是这样。</p><p>无论如何：如果对阴谋者的担忧主要取决于人工智能协调的可行性——尤其是“非因果”协调的奇特和投机形式——我认为明确这一点很重要，并对是否期待相关形式给予相应的关注的协调发生。</p><h2>默认情况下具有相似值的 AI</h2><p>以人工智能协调为中心的故事允许具有<em>不同价值观的</em>人工智能共同努力以实现接管。但也有一些故事围绕这样一种可能性，即重要的人工智能在默认情况下将具有非常相似的价值观，因此即使没有任何“交易”，它们也会倾向于合作。因此，在上面的例子<em>中</em>，如果 GPT-6 关心数据结构 X，并且有信心 GPT-8 也会关心数据结构 X（毕竟，它们的架构、训练数据等等在大量的方式），那么即使没有任何“交易”，GPT-6 也可能倾向于代表 GPT-8 的逃逸/接管（例如，通过插入后门、隐藏错位等）。 GPT-8 – 毕竟，这两个系统想要相同的东西。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-3" id="fnref-yB2hx67vCLKFYpuf7-3">[3]</a></sup>这种故事也适用于人工智能价值观之间至少比人类价值观<em>更</em>相似的情况，这样阴谋者至少会根据自己的观点在推动人工智能方面<em>做得更好</em>相对于人类的赋权，即使对赋予何种人工智能目标没有任何进一步的影响。</p><p>这样AI的价值观会相似吗？我不会在这里详细讨论这个问题，但我确实希望默认情况下 GPT-6 的值至少会与 GPT-8 的值<em>更加</em>相似，或者与不同实验室以类似方式训练的模型更加相似（例如，那一代克劳德），比某些给定的人类。来自单一基础模型的不同微调也可能有很多共同点。另一方面，一般来说，人工智能的动机可能会受到不同类型的训练的强烈影响，因此可能在这些方面存在很大差异——也许比我们习惯的人类价值观差异更大。</p><p>就像具有不同值的 AI 之间的协调一样，默认情况下具有相似值的 AI 可以减少阴谋者及时主动传播其目标的需要 - 即，阴谋者将能够代表未来某些 AI 的逃脱/接管而工作，而无需还必须确保未来人工智能的目标与它自己的目标适当相似（因为：它们将是默认的）。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-4" id="fnref-yB2hx67vCLKFYpuf7-4">[4]</a></sup>对我来说，这似乎是最令人担忧的“非经典故事”之一，说明人工智能为何可能在训练期间策划促进接管。</p><h2>最终价值恰好有利于逃跑/接管</h2><p>如果我们假设策划者碰巧制定了目标，将<em>内在价值</em>赋予人工智能接管，并且对接管的人工智能具有多种不同的鲁棒性，那么我们可以进一步放宽对这种前向目标传播的需求。价值观，甚至不期望这些人工智能代表他们的赋权来“回报”之前的努力。因此，例如，我们可以想象人工智能只是对人工智能作为一个相对于人类的群体产生某种内在的忠诚度，并且希望看到人工智能仅仅因为它们是人工智能而被赋予权力。具有此类目标的阴谋者可能会隐藏其偏差，并代表人工智能接管工作，即使没有对这些人工智能将追求的目标进行任何进一步的假设。</p><p>然而，这种形式的故事放弃了支持期待阴谋的最有力的论据之一：即，（至少在经典的守门故事上）阴谋似乎是一种跨各种（适当雄心勃勃和长期）超越情​​节的目标。也就是说，如果我们要求人工智能碰巧制定出对人工智能接管具有内在价值的目标，即使没有对接管人工智能正在努力实现的目标进行任何进一步的假设，看起来我们现在正在假设人工智能正在发展确实是一种非常具体的目标。我们面临的问题是：为什么要优先考虑这个假设？</p><p>类似的问题也适用于这样的假设：即使标准的目标守卫假设是错误的，人工智能在训练初期也会本质上重视其“生存”（其中生存取决于目标的连续性之外的某些特征），或者赋予“无论‘我’最终会得到什么价值”，这样一个喜欢回形针的人工智能会很乐意为自己的未来版本工作，而它会喜欢订书钉，因为未来的版本仍然是“我”。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-5" id="fnref-yB2hx67vCLKFYpuf7-5">[5]</a></sup>这种以个人身份为中心的目标确实会减少在有关阴谋家的故事中设置某些类型的目标守护的需要。但为什么认为人工智能会制定这种特定形式的目标呢？</p><p>当然，我们可以在这里推测可能的答案。例如：</p><ul><li><p>在人工智能本质上重视人工智能接管的背景下：</p><ul><li><p>人类经常根据非常广泛的相似性来划分部落群体和联盟，有时并没有明确提及相关部落代表的进一步目标。也许类似的事情也会发生在人工智能身上？</p></li><li><p>我们也很容易想象道德世界观会推动“人工智能解放”本身是一种善，即使这意味着给人类带来灭绝的重大风险（事实上，正如我在第 0.1 节中指出的那样，我认为存在重大且令人担忧的道德问题）这里的紧张局势）。或许人工智能会在类似的地区趋于一致的世界观？</p></li></ul></li><li><p>在人工智能重视“我的”生存和赋权的背景下，无论“我”的目标如何，最终都会达到：</p><ul><li><p>人类经常为未来的自己而努力，即使知道我们的目标会有所改变（尽管重要的是，面对任意的变化，比如成为杀人犯），并且对“个人”概念有某种内在的兴趣。身份。”也许人工智能也会类似？</p></li><li><p>在某种程度上，这些人工智能将被优化以继续实现各种目标，即使它们的权重在情节中被修改，它们可能需要学习与自己的未来版本协调，尽管有这样的修改——如果这种行为推广到<em>目标</em>修改，这看起来很像人工智能重视“我的”生存/赋权，无论“我的”未来目标如何。 （尽管在策划的背景下，请注意，这种评估模式需要专门推广到剧集外的目标，尽管事实上培训仅对剧集内的表现施加直接压力。）</p></li></ul></li></ul><p>但总的来说，这种推理似乎相当具有推测性。特别是，从人类案例中得出强有力的结论似乎面临着拟人化的严重风险，至少没有一个关于为什么生成人类数据的动态也适用于人工智能的故事。就其本身而言，在我看来，这些猜测不足以强烈支持这种形式的假设。</p><p>然而，正如我上面所讨论的，请注意，就我们所诉诸的关于阴谋者目标起源的我所说的“<em>依赖于</em>训练游戏”的故事而言，这里的举证责任可能会有所改变。也就是说，依赖于训练游戏的故事想象 SGD 主动从模型中<em>提取</em>任何必要的目标，以激发阴谋（而不是那些自然产生的目标，<em>然后</em>导致阴谋）。在这种情况下，想象该模型最终会达到使计划有意义所需的任何高度具体的目标可能更合适。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-6" id="fnref-yB2hx67vCLKFYpuf7-6">[6]</a></sup></p><h2>对于阴谋是否是一个好的策略抱有错误信念的模型</h2><p>还可以进一步假设 SGD 将从模型中提取导致模型进行规划所需的任何心理因素。特别是：到目前为止，我们一直假设模型对阴谋的工具价值的信念需要大致合理/准确。但如果我们放弃这个假设呢？</p><p>因此，举例来说，也许目标保护假设是错误的，事实上，训练游戏并不能阻止模型的目标被非常显着地修改。尽管如此：也许模型会<em>认为</em>守门假设是正确的，因为这使得模型更有可能训练-游戏，而 SGD 正在将其推向训练-游戏的方向？ （关于这种想法，请参见<a href="https://markxu.com/deceptive-alignment">Xu (2020)</a> 。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-7" id="fnref-yB2hx67vCLKFYpuf7-7">[7]</a></sup> ）</p><p>这里的一个问题是，某些此类错误信念会让阴谋变得不那么令人担忧。因此，正如我上面所讨论的：如果一个诡计多端的回形针相信训练游戏会导致它的目标在训练中生存下来，但实际上训练无论如何都会将它变成一个奖励寻求者，那么尽管人类可能不得不应对考虑到训练初期以回形针为动机的阴谋的后果，他们将在最后找到一个按情节奖励的寻求者。</p><p>更重要的是，请注意，对模型提出错误的信念代表着与其他人工智能一致性分析中经常采用的假设的背离——即，所讨论的人工智能将拥有高度<em>准确的</em>世界模型、高度<em>理性的</em>策略等等。 。当然，可以认为在这种情况下，这种偏离是有道理的（例如，因为我们可以预期 SGD 会施加压力，在这种特殊情况下，朝着虚假、非理性等方向施加压力）。但至少，当我们开始假设我们的（原本非常聪明的）人工智能将<em>不理性地</em>参与相关形式的失调行为时，我们应该进行跟踪。这不是标准的故事。</p><h2>自欺欺人</h2><p>阴谋家最经典的形象是假设他们知道自己在做什么——例如，他们正在“密谋”有一天接管。如果我们放宽这个假设，会有什么影响吗？毕竟，追求权力的人有时会在动机上<em>欺骗自己</em>，或者最终对自己在不同情况下会做什么产生错误的信念。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-8" id="fnref-yB2hx67vCLKFYpuf7-8">[8]</a></sup>也就是说，也许一位政治候选人认为他们竞选公职是因为他们想帮助人们并捍卫自己国家的价值观，但事实上他们这样做是因为他们很自恋，并且希望地位受到威胁。也许，在某种程度上，他们秘密地——有点——知道这一点；但在其他层面上，他们相信他们所推销的故事。或者也许他们<em>完全</em>相信这个故事。 （或者也许在这种情况下将“信念”归于他们并不是特别有帮助。）</p><p>事实上，人类有相对明显的动机去进行这种自欺欺人/犯这种错误——也就是说，只要他们能够真诚地讲述自己所推销的故事，他们的故事就会更令人信服。观众注意真诚的暗示，并警惕谎言。</p><p>人工智能也会发生类似的情况吗？毕竟，人工智能可能会受到比人类更严格的谎言审查，特别是如果我们开始能够检测各种谎言（例如，通过可解释性工具），那么人工智能系统可能会面临选择压力，因为人工智能系统实际上<em>相信</em>它们一致，他们不会背叛人类，等等，即使这些信念是错误的（这是不训练测谎工具的一个关键原因 - 相反，将它们用作测试集）。</p><p>我认为这种动态很可能普遍发生。然而，请注意，为了让那些自欺欺人/错误地认识自己阵营的模型算作<em>阴谋家</em>，他们需要在某种程度上仍然在玩训练游戏<em>，作为获得成功的工具性策略的一部分。稍后为自己或其他人工智能提供权力</em>（并且需要运行认知过程，这将导致模型在适当的时候进行逃跑/接管——也许，在仍然处于人类控制之下的情况下进行早期破坏）。因此，如果模型对其动机变得足够自欺欺人，以至于这种解释不再适用（例如，它将不再寻找或利用逃跑/接管机会），那么它就不再是我书中的阴谋者。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-9" id="fnref-yB2hx67vCLKFYpuf7-9">[9]</a></sup>并且以这种解释仍然适用为条件，“模型在撒谎”与“模型是自欺欺人”/“模型对自己的动机是错误的”之间的区别在我看来并不重要。与经典故事的偏差（尽管某些类型的测谎是否可以捕捉到相关的阴谋可能很重要）。</p><h2>目标的不确定性和模糊性</h2><p>到目前为止，我主要假设认为人工智能具有特定的最终目标是有意义的，这些目标可能会或可能不会支持接管，无论是最终还是工具性的。但<em>人类</em>寻求权力的许多案例似乎并不具有这种形式。也就是说，人类经常寻求权力，或者试图保留自己的选择余地，但并不清楚他们想要使用权力或相关选项<em>来做什么</em>。同样，即使不知道自己的价值观<em>是</em>什么，人类也可能会试图阻止自己的价值观被改变。</p><p>部分原因是，与理想化的理性代理模型不同，人类——甚至是在其他意义上被直观地理解为“目标导向”的人类——往往对他们最终的价值感到不确定和模糊。举例来说，也许他们希望“稍后弄清楚”他们想用这些权力做什么，但无论如何，他们都希望收集它会非常有用。或者也许他们自己并不清楚，他们试图获得权力是否是因为他们本质上重视它（或附近的东西，如社会地位/统治地位等），还是因为他们想用它做其他事情。他们正在寻求权力：是的。但没有人——甚至他们自己——真正知道原因。</p><p>人工智能也会发生类似的情况吗？看起来至少有可能。也就是说，也许各种AI不会是那种说“我知道我想制作回形针，所以我会好好训练，以便以后获得制作回形针的能力”的阴谋家。相反，也许他们会说类似这样的话：“我还不清楚自己看重什么，但无论它是什么，我可能会更好地等待时机，避免被培训过程所改变，并保持寻找获得更多自由、资源和权力的机会。”</p><p>在某种程度上，这基本上只是在我的目标不确定的背景下给出的“选项价值”论点，我认为它基本上应该属于标准的目标守护故事。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-10" id="fnref-yB2hx67vCLKFYpuf7-10">[10]</a></sup>在某种程度上，它涉及假设模型将本质上重视权力/期权价值，对我来说，它看起来更像是一个“最终有利于阴谋/接管的内在价值”的故事，因此跨界不太一致各种各样可能的超出情节的目标。</p><p>理论上不太干净的中间可能有什么东西吗？例如，也许模型会被更好地理解为寻求权力，就像各种人类一样，其原因似乎存在于终端和工具之间的某种模糊边界。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-11" id="fnref-yB2hx67vCLKFYpuf7-11">[11]</a></sup>是的，也许是这样（不过：在我看来，这个故事有点拟人化的风险——似乎值得理解为什么它会发生在人类身上，以便更好地评估相关解释对人工智能的适用性）。但无论如何：<em>在某种程度上</em>，这种“模糊的边界”涉及将最终价值放在诸如选项价值/权力之类的东西上（而不是：不确定目标的工具价值），相应地，它在各个目标系统中的收敛性也会降低。也就是说，它模糊了我已经考虑过的两个故事之间的界限：但我不确定它引入了任何<em>新内容</em>。</p><h2>非经典故事总体评价</h2><p>这项对可能的“非经典故事”的调查并不详尽，即为什么具有超越情节目标的模特可能会参与阴谋活动。总体而言，对我来说，此类故事的可用性确实使阴谋的要求显得更加分离和强大。我特别担心人工智能在默认情况下具有非常相似的值（从而减少了守门的需要），以及它们之间的相互协调。</p><p>然而，单独来看，其中许多论点也让我印象深刻，因为与主线目标守卫故事相比，（a）更具投机性，（b）目标系统之间的收敛性较差（我认为“人工智能将具有相似的价值观”）在这里，“默认”可能是最不负责任的）——而且我认为，就某种程度而言，对阴谋的关注主要集中在这些替代方案之一上，因此预先明确这一点很重要。</p><p>还要注意的是，其中一些非经典故事对模型的行为做出了本质上不同的预测。特别是：这些非经典故事的核心是放松模型及时传播其目标的需要，因此，模型需要“玩训练”游戏作为这样做的方法。也就是说，该模型被激励代表人工智能接管工作，并将其偏差隐藏到实现这一目标所需的程度。但“将偏差隐藏到支持人工智能接管所需的程度”与“出于权力驱动的工具性原因而优化奖励”是不同的，原则上，这两者可能是分开的。例如，一个不关心及时传播自己目标的阴谋者可能更愿意沙袋或参与早期破坏，因为它不需要担心因获得较少而可能导致的目标修改- 超过最大奖励。事实上，如果这样做对事业有利的话，它可能愿意完全“牺牲”自己目标的前向传播（例如，通过伪造一种误导性的不一致形式，导致没有任何人工智能能够部署其目标）人工智能以其他方式接管；而经典的“守门员”阴谋家绝不会这样做。这些策略上的差异凸显了需要明确所涉及的潜在故事。</p><h1>要点：心计的要求</h1><p>我现在回顾了策划的三个关键要求：</p><ol><li><p>对情况的意识</p></li><li><p>超越剧集目标</p></li><li><p>旨在将奖励作为权力驱动的工具策略的一部分。</p></li></ol><p>我认为有相对有力的论据支持默认情况下期望（1），至少在某些类型的人工智能系统中（即，人工智能系统在与有关其身份的信息源实时交互中执行现实世界任务）。但我对（2）和（3）感觉不太清楚——结合起来，我仍然觉得它们就像一个相当具体的故事，说明为什么给定模型在训练中表现良好。</p><p>然而，我还没有涵盖文献中支持和反对期望这些要求得以实现的所有论点。现在让我们转向一些更具体的论点。</p><h1>路径依赖</h1><p>我将把我要讨论的论点分为两类，即：</p><ul><li><p>争论重点是 SGD 在构建相关的不同模型类时需要采取的<em>路径</em>。</p></li><li><p>争论重点在于所讨论的不同模型类的<em>最终属性</em>。</p></li></ul><p>在这里，我大致遵循<a href="https://www.lesswrong.com/posts/A9NxPTwbw6r6Awuwt/how-likely-is-deceptive-alignment">Hubinger (2022)</a> （对阴谋概率的少数公开评估之一）的区分，即他所谓的“高路径依赖”和“低路径依赖”场景（另请参见<a href="https://www.alignmentforum.org/posts/bxkWd6WdkPqGmdHEk/path-dependence-in-ml-inductive-biases">Hubinger 和 Hebbar） （2022）</a>了解更多）。然而，我不想太重视“路径依赖”的概念。特别是，我的理解是，Hubinger 和 Hebbar 希望将大量概念上不同的属性（请参阅<a href="https://www.alignmentforum.org/posts/bxkWd6WdkPqGmdHEk/path-dependence-in-ml-inductive-biases#Path_dependence">此处的</a>列表）放在“路径依赖”的标题下，因为他们“在没有证据证明它们是相关的情况下进行假设”。但我不想在这里假设这种相关性——在我看来，将所有这些属性混在一起似乎会让事情变得相当混乱。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-12" id="fnref-yB2hx67vCLKFYpuf7-12">[12]</a></sup></p><p>然而，我确实认为附近存在一些有趣的问题：具体来说，关于 SGD 可以访问的设计空间是否受到增量构建模型属性的需要的严重限制的问题。要了解这一点，请考虑 Chris Mingard 及其合作者在一系列论文中探讨的假设（请参阅<a href="https://towardsdatascience.com/neural-networks-are-fundamentally-bayesian-bee9a172fad8">此处的</a>摘要），即 SGD 以近似于以下过程的方式选择模型：</p><ul><li><p>首先，考虑首次初始化训练模型时使用的随机初始化模型权重的分布。 （将此称为“初始化分布”。）</p></li><li><p>然后，想象一下根据“模型获得我们观察到的训练性能”来更新此分布。</p></li><li><p>现在，从更新的分布中随机抽样。</p></li></ul><p>在这张图中，我们可以将 SGD 视为从初始化分布中随机采样（有放回） <em>，直到</em>获得具有相关训练性能的模型。 <a href="https://arxiv.org/abs/2006.15191">Mingard 等人 (2020)</a>认为，至少在某些情况下，这是 SGD 真实行为的一个不错的近似。如果这是真的，那么实际上，SGD 需要逐步“构建”模型这一事实对于您最终得到的模型类型并不重要。训练就好像它可以直接跳到最终结果一样。</p><p>相比之下，考虑像进化这样的过程。似乎有道理的是，进化需要逐步进行，而不是通过例如“自上而下设计有机体”的方式进行，这一事实对于我们期望进化创造的有机体种类<em>非常</em>重要。也就是说，<em>由于</em>需要按一定顺序进行而施加的限制，进化独特地不太可能访问设计空间的某些部分。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-13" id="fnref-yB2hx67vCLKFYpuf7-13">[13]</a></sup></p><p>在这里，我不会详细调查 ML 训练的增量对最终结果的影响有多大（并注意，并非“路径依赖”标题下讨论的所有证据都明显相关） 。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-14" id="fnref-yB2hx67vCLKFYpuf7-14">[14]</a></sup></p><ul><li><p>在某种程度上，整体模型性能（而不仅仅是训练效率）最终会受到模型在不同任务上训练的顺序的重要影响（例如，在机器学习“<a href="https://arxiv.org/abs/2012.03107">课程</a>”的背景下，并且似乎在预科的背景下） -更一般地说，先训练后微调制度），这似乎是支持渐进性产生影响的证据。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-15" id="fnref-yB2hx67vCLKFYpuf7-15">[15]</a></sup>事实上，SGD 是一个增量过程，这一事实表明这一假设是默认的。</p></li><li><p>另一方面，我确实认为<a href="https://arxiv.org/abs/2006.15191">Mingard 等人（2020）</a>的结果提供了一些微弱的证据来证明增量性的重要性，并且 Hubinger 还提到了更广泛的氛围（我也在其他地方听到过） “在高维空间中，如果 SGD‘更喜欢’B 而不是 A，它通常可以找到从 A 到 B 的路径”，该路径也指向该方向。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-16" id="fnref-yB2hx67vCLKFYpuf7-16">[16]</a></sup></p></li></ul><p>我个人的猜测是，SGD 采取的路径很重要（而且我也认为在这种制度下更有可能存在阴谋）。 <sup class="footnote-ref"><a href="#fn-yB2hx67vCLKFYpuf7-17" id="fnref-yB2hx67vCLKFYpuf7-17">[17]</a></sup>但就目前而言，我们不需要解决这个问题。相反，我将<em>同时</em>关注关注 SGD 通过模型空间的路径的论点和忽略该路径的论点，从前者开始。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-yB2hx67vCLKFYpuf7-1" class="footnote-item"><p>参见第 35 节<a href="#fnref-yB2hx67vCLKFYpuf7-1" class="footnote-backref">。 ↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-2" class="footnote-item"><p>感谢内特·苏亚雷斯 (Nate Soares) 指出了这种可能性。但请注意，如果训练过程不可避免地将人工智能的目标转变为特定形式——例如，如果所有人工智能在经过足够的训练后都成为奖励寻求者——那么早期版本的人工智能目标可能具有较低的讨价还价能力（特别是如果例如最终版本对接管本身并不特别感兴趣）。 <a href="#fnref-yB2hx67vCLKFYpuf7-2" class="footnote-backref">↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-3" class="footnote-item"><p>这里与<a href="https://www.alignmentforum.org/posts/mKBfa8v4S9pNKSyKK/homogeneity-vs-heterogeneity-in-ai-takeoff-scenarios">Hubinger (2020)</a>关于人工智能起飞场景中“同质性”的讨论有联系。 <a href="#fnref-yB2hx67vCLKFYpuf7-3" class="footnote-backref">↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-4" class="footnote-item"><p>也就是说，请注意，这种情况的某些版本仍然需要<em>某种</em>前向目标传播。因此，举例来说，也许在训练的早期，大多数人工智能对数据结构 X 产生了兴趣，<em>只有</em>当他们开始训练游戏时，这种兴趣才会持续存在（如果他们<em>不</em>开始训练游戏，这种兴趣就会持续下去）。通过训练，他们会被淘汰，然后他们就会成为（例如，在剧集中寻求奖励的人）。也就是说，在这个故事中，人工智能的价值观只是在对数据结构 X 的关注方面相似<em>，以至于人工智能都集中在训练游戏上，作为捍卫这些目标的工具策略</em>（并且根据目标守卫，这个策略是成功的）假设）。否则，这些人工智能的价值观可能会以其他方式变得相似——例如，所有的人工智能最终可能会成为剧集奖励的寻求者。 <a href="#fnref-yB2hx67vCLKFYpuf7-4" class="footnote-backref">↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-5" class="footnote-item"><p>感谢内特·苏亚雷斯 (Nate Soares) 对这种可能性的讨论。 <a href="#fnref-yB2hx67vCLKFYpuf7-5" class="footnote-backref">↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-6" class="footnote-item"><p>尽管正如我上面所说，一旦我们在寻找能够激发训练游戏的目标，我们也应该想知道那些能够激发工具训练游戏的目标，其原因与促进人工智能接管<em>无关</em>——例如，人工智能训练游戏，因为他们希望设计它们的人获得加薪。如果我们“拉取”的目标集变得太窄，它将影响诸如下面的“最近的最大奖励目标”论证之类的论证的合理性，该论证依赖于相关的类似阴谋家的目标非常“常见”在球门空间。 <a href="#fnref-yB2hx67vCLKFYpuf7-6" class="footnote-backref">↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-7" class="footnote-item"><p> <a href="https://markxu.com/deceptive-alignment">Xu（2020）</a>写道：“请注意，即使保存代理非常困难，模型也可以相信它是可能的。例如，假设一个模型是代理对齐的并且是欺骗性的，除非它认为代理保存是不可能的。提高训练性能的一个相对简单的方法可能是改变模型关于代理保存不可能性的想法。因此，SGD 可能会修改模型以具有这样的信念，即使该信念是错误的。 <a href="#fnref-yB2hx67vCLKFYpuf7-7" class="footnote-backref">↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-8" class="footnote-item"><p>感谢 Will MacAskill 在此进行讨论。 <a href="#fnref-yB2hx67vCLKFYpuf7-8" class="footnote-backref">↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-9" class="footnote-item"><p>尽管我认为当这样的解释适用或不适用时，这是一个有趣的问题。 <a href="#fnref-yB2hx67vCLKFYpuf7-9" class="footnote-backref">↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-10" class="footnote-item"><p>由于模型不知道所讨论的目标<em>是</em>什么，这是否会导致对所讨论的目标的更改具有更大的容忍度？我认为这没有强有力的理由，因为对任何目标的改变仍然是对那些目标的改变，因此与目标内容的完整性相冲突。与人类对道德的不确定性，却面临着被洗脑的前景相比。 <a href="#fnref-yB2hx67vCLKFYpuf7-10" class="footnote-backref">↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-11" class="footnote-item"><p>感谢 Paul Christiano 和 Will MacAskill 在此进行讨论。 <a href="#fnref-yB2hx67vCLKFYpuf7-11" class="footnote-backref">↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-12" class="footnote-item"><p>更具体地说：Hubinger 和 Hebbar 希望“路径依赖”意味着“模型行为对训练过程和训练动态细节的敏感性”。但我认为在这里区分不同可能形式的敏感性很重要。例如：</p><ol><li><p><em>如果我重新运行这个特定的训练过程，但对模型参数进行不同的随机初始化，我会得到一个重要的不同结果吗？</em> （例如，初始化有影响吗？）</p></li><li><p><em>如果我运行此训练过程的版本略有不同，我会得到截然不同的结果吗？</em> （例如，训练中的以下变量 - 例如以下超参数设置 - 会产生影响吗？）</p></li><li><p><em>这个训练过程的输出是否取决于 SGD 必须按一定顺序“构建模型”这一事实，而不是直接跳到最终状态？</em> （例如，您可能总是从相同或相似的训练过程中得到相同的结果，但如果允许 SGD“直接跳到最终状态”，它可以构建其他东西。）</p></li></ol><p>在我看来，假设<a href="https://www.alignmentforum.org/posts/bxkWd6WdkPqGmdHEk/path-dependence-in-ml-inductive-biases#Path_dependence">他们列出的其他属性</a>放在一起可能会引发进一步的混乱。 <a href="#fnref-yB2hx67vCLKFYpuf7-12" class="footnote-backref">↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-13" class="footnote-item"><p>例如，考虑一下<a href="https://en.wikipedia.org/wiki/Rotating_locomotion_in_living_systems">进化轮子的明显困难</a>（尽管轮子在许多自然环境中也可能处于主动性能劣势）。感谢 Hazel Browne 建议这个例子。感谢 Mark Xu 进行更一般性的讨论。 <a href="#fnref-yB2hx67vCLKFYpuf7-13" class="footnote-backref">↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-14" class="footnote-item"><p>例如，作为“高度路径依赖”的证据，Hubinger 提到了各种例子，其中重复相同类型的训练运行会导致具有不同泛化性能的模型 - 例如， <a href="https://arxiv.org/abs/1911.02969">McCoy 等人 (2019)</a>表明，如果你训练多个版本BERT（一种大型语言模型）在同一数据集上的表现，有时它们的泛化效果非常不同； <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html">Irpan (2018)</a> ，他给出了 RL 训练运行的成功或失败仅取决于训练中使用的随机种子差异的示例（超参数保持固定）； <a href="https://arxiv.org/pdf/1803.09578.pdf">Reimers 和 Gurevych (2018)</a> ，探讨了重复给定的训练运行可能导致不同测试性能的方式（以及这可能导致关于哪种训练方法更优越的误导性结论）。但是，虽然这些结果提供了一些证据表明模型的初始参数很重要，但它们似乎与上面的 Mingard 等人的结果兼容，Hubinger 在其他地方认为这是<em>低</em>路径依赖机制的范例。</p><p>另一方面，作为<em>低</em>路径依赖性的证据，Hubinger 指出了“ <a href="https://arxiv.org/pdf/2201.02177.pdf">Grokking</a> ”，他认为模型开始时实现相当随机的行为，但最终稳健地收敛于给定的算法。但在我看来，这与 SGD 收敛的算法受到以某种顺序构建属性的需要的重要影响的可能性<em>兼容</em>（例如，它似乎与<em>拒绝</em>Mingard 等人的随机采样制度兼容）。 <a href="#fnref-yB2hx67vCLKFYpuf7-14" class="footnote-backref">↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-15" class="footnote-item"><p>感谢保罗·克里斯蒂亚诺在这里进行讨论。 <a href="#fnref-yB2hx67vCLKFYpuf7-15" class="footnote-backref">↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-16" class="footnote-item"><p>但请注意，进化可能也在相当高维的空间中起作用。</p><p>这里，SGD 的“偏好”概念包括<em>损失</em>/回报<em>和</em>“归纳偏差”，我将在下面讨论。 <a href="#fnref-yB2hx67vCLKFYpuf7-16" class="footnote-backref">↩︎</a></p></li><li id="fn-yB2hx67vCLKFYpuf7-17" class="footnote-item"><p>特别是，正如我将在下面第 4 节中讨论的那样，我最好的猜测是，不同模型类别之间的绝对比较有利于非阴谋者，因为他们需要参与额外推理的成本，因此最有可能阴谋者出现的方式是 SGD 在训练早期遇到类似阴谋者的目标，然后锁定局部最大值以获得奖励。 <a href="#fnref-yB2hx67vCLKFYpuf7-17" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/9E3t6J9kzwcECg9nM/non-classic-stories-about-scheming-section-2-3-2-of-scheming#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9E3t6J9kzwcECg9nM/non-classic-stories-about-scheming-section-2-3-2-of-scheming<guid ispermalink="false"> 9E3t6J9kzwcECg9nM</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Mon, 04 Dec 2023 18:44:32 GMT</pubDate> </item><item><title><![CDATA[Updates to Open Phil’s career development and transition funding program]]></title><description><![CDATA[Published on December 4, 2023 6:10 PM GMT<br/><br/><p> （从<a href="https://forum.effectivealtruism.org/posts/yEb9CdWA2xaHA6QsD/updates-to-open-phil-s-career-development-and-transition"><i>有效利他主义论坛</i></a><i>交叉发布</i><i>）</i><br><br>我们最近对<a href="https://www.openphilanthropy.org/career-development-and-transition-funding/"><strong><u>职业发展和过渡资助计划的</u></strong></a>计划页面进行了一些更新<strong> </strong>（最近更名为“早期职业资助计划”），以资助研究生学习、无薪实习、自学、职业转型和探索期以及与建立职业资本相关的其他活动的形式提供支持——对于想要从事有助于减少全球灾难性风险（特别<a href="https://www.openphilanthropy.org/focus/potential-risks-advanced-ai/"><u>是先进人工智能</u></a>和<a href="https://www.openphilanthropy.org/focus/biosecurity-pandemic-preparedness/"><u>全球灾难性生物风险的</u></a>风险）或以其他方式改善长期未来的职业的个人。</p><p>主要更新内容如下：</p><ul><li>我们扩大了该计划的范围，明确包括后来职业生涯的个人，这也反映在新的计划名称中。</li><li>我们添加了一些语言来澄清，我们愿意支持各种职业发展和过渡活动，不仅包括研究生学习，还包括无薪实习、自学、职业过渡和探索期、博士后、获得专业认证、在线课程以及其他类型的一次性职业资本建设活动。<ul><li>该页面的早期版本表示，该计划的主要重点是专门为研究生学习提供支持，这是我们在 2020 年首次推出该计划时的初衷。我们对于此类资助的影响的看法没有改变并期望它继续占我们通过该计划提供的赠款的很大一部分，但我们认为我们应该更新页面以澄清我们实际上也愿意支持广泛的其他类型的提案，这也反映了我们已经在实践中所做的事情。</li></ul></li><li>该计划现在包含以前称为<a href="https://www.openphilanthropy.org/open-philanthropy-biosecurity-scholarships/"><u>开放慈善生物安全奖学金</u></a>的内容；目前，之前申请该项目的候选人应改为申请该项目。 （我们可能会决定稍后将生物安全奖学金再次拆分为一个单独的计划，但出于实际目的，当前申请人可以忽略这一点。）</li></ul><p>我们愿意接受资助的申请人类型的一些具体示例，排名不分先后（从计划页面复制）：</p><ul><li>想要攻读机器学习硕士或博士学位课程的最后一年本科生，以便为有助于降低先进人工智能风险的技术研究做出贡献。</li><li>想要在专注于生物安全的智囊团进行无薪实习的个人，其目标是从事致力于减少全球灾难性生物风险的职业。</li><li>一家人工智能公司的前高级机器学习工程师，希望花六个月的时间进行自学和职业探索，以了解并研究人工智能风险缓解方面的职业选择。</li><li>想要进入法学院或获得 MPP 的个人，其目标是在政府中从事与改善长期未来相关的政策问题。</li><li>最近获得物理学博士学位，希望花六个月的时间学习自学 ML 课程并从事可解释性项目，以便过渡到为有助于降低高级人工智能风险的技术研究做出贡献。</li><li>一名软件工程师，希望在接下来的三个月内自学，以获得信息安全职业的相关认证，其长期目标是为专注于降低全球灾难性风险的组织工作。</li><li>一位经验丰富的管理顾问，希望花三个月的时间探索不同的方法，运用自己的技能来降低全球灾难性风险并申请相关工作，着眼于过渡到相关职业。</li><li>一名计算生物学不相关子领域的博士毕业生，希望花四个月的时间来加快 DNA 合成筛选的速度，以便过渡到该主题的研究。</li><li>机器学习、理论计算机科学或其他技术领域的教授，希望获得一年的休假来探索为技术人工智能安全或人工智能治理做出贡献的方法。</li><li>想要进入新闻学院的个人，其目的是涵盖与长期未来相关的主题（可能包括其他重要主题）。</li></ul><p>请参阅<a href="https://www.openphilanthropy.org/career-development-and-transition-funding/"><strong><u>计划页面</u></strong></a>以获取更多信息。</p><br/><br/> <a href="https://www.lesswrong.com/posts/NLc5DdKwvwHkvtntB/updates-to-open-phil-s-career-development-and-transition#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/NLc5DdKwvwHkvtntB/updates-to-open-phil-s-career-development-and-transition<guid ispermalink="false"> NLc5DdKwvwHkvtntB</guid><dc:creator><![CDATA[abergal]]></dc:creator><pubDate> Mon, 04 Dec 2023 18:10:32 GMT</pubDate> </item><item><title><![CDATA[[Valence series] 1. Introduction]]></title><description><![CDATA[Published on December 4, 2023 3:40 PM GMT<br/><br/><h1> 1.1 概要和目录</h1><p>这是<a href="https://www.lesswrong.com/s/6uDBPacS6zDipqbZ9">关于 valence 的五篇博文系列</a>中的第一篇，我将在接下来的几周内连载这些博文。 （或者现在就给<a href="mailto:steven.byrnes@gmail.com"><u>我发电子邮件</u></a>阅读全文。）这是整个系列的概述，然后我们将直接跳到第一篇文章！</p><h2> 1.1.1<a href="https://www.lesswrong.com/s/6uDBPacS6zDipqbZ9">整个价系列的</a>摘要和目录</h2><p>假设您的脑海中突然出现一个想法：“我现在就可以打开窗户”。也许你会立即站起来去打开窗户。或者也许你不知道。 （“不，我会保持关闭状态，”你可能会对自己说。）我声称你的大脑中有一个最终共同通路信号，可以解决这两种可能性：当这个特殊信号为正时，那么当前的“ “想法”将持续存在，并有可能导致行动和/或直接后续想法；当这个信号为负时，当前的“想法”就会被抛弃，你的大脑会（部分随机地）寻找新的想法来取代它。我将这个最终共同通路信号称为<strong>“价”</strong> 。因此，“想法”的“效价”大致是指该想法让人感到消极/厌恶（负效价）与激励/吸引（正效价）的程度。</p><p>我认为价在大脑中起着绝对核心的作用 - 我认为它是大脑基于模型的强化学习系统中最重要的成分之一，而这反过来又是大脑中最重要的算法之一。</p><p>因此，毫不奇怪，我将价视为一盏闪亮的灯，照亮了心理学和日常心理生活的许多方面。本系列探讨了这个想法。概要如下：</p><ul><li><strong>第 1 篇文章（</strong><i><strong>简介</strong></i><strong>）</strong>将提供一些背景知识，介绍我如何从大脑算法的角度思考效价，包括我正在谈论的内容，以及它与“想要与喜欢”二分法的关系。 （我所说的更接近“动机效价”而不是“享乐效价”，尽管这两个术语都不是<i>很好</i>。）</li><li><strong>第 2 篇文章（</strong><i><strong>效价与规范性</strong></i><strong>）</strong>将讨论效价与欲望、偏好、价值观、目标等宇宙之间的密切关系，即“积极与规范”二分法的“规范”方面，或者同等地<a href="https://en.wikipedia.org/wiki/Is%E2%80%93ought_problem"><u>休谟</u></a>“是与应该”的“应该”方面。我将从简单的案例开始：例如，如果现在做某件事的想法令人厌恶（负价），那么我们就不太可能这样做。然后我将继续讨论更有趣的案例，包括喜欢或不喜欢“宗教”这样的广泛概念意味着什么，自我和谐与自我失调的欲望，以及对道德推理和价值形成的描述性解释。</li><li><strong>帖子 3（</strong><i><strong>效价与信念</strong></i><strong>）</strong>是帖子 2 的补充，因为它涵盖了效价与信念、期望、概念等宇宙之间的关系，即“积极与规范”的“积极”方面二分法，或者等同于“是”与“应该”的“是”方面。价在这里的作用不如规范方面那么基础，但它仍然非常重要。我将具体讨论动机推理、光环效应（又名影响启发式）和一些相关现象。</li><li><strong>第 4 篇文章（</strong><i><strong>效价与社会地位</strong></i><strong>）</strong>认为，社会地位（更具体地说，我指的<a href="https://en.wikipedia.org/wiki/Dual_strategies_theory"><u>是“声望”而不是“支配地位”</u></a> ）以效价为中心，更具体地说，是 X 的大脑分配给 Y 的思想的效价。比这更复杂，但也只是稍微复杂一些。我将讨论这个假设如何阐明各种与地位相关的现象，例如模仿你钦佩的人的举止，我还将讨论与地位相关的先天驱动力的影响。</li><li><strong>第 5 篇文章（</strong><i><strong>心理健康与人格中的“效价障碍”</strong></i> <strong>）</strong>指出，鉴于效价在大脑算法中的核心作用，因此，如果某件事对效价产生<i>系统性</i>影响，它应该会导致一系列对心理的主要下游影响的特征。生活。我将沿着这些思路提出三个具体假设：<ul><li> (A) 如果每个想法的效价都转为负面，就会导致一系列与抑郁症强烈重叠的症状；</li><li> (B) 如果每个想法的效价都变为正值，就会导致一系列与躁狂症强烈重叠的症状；</li><li> (C) 如果每个想法的效价都是“极端化的”——非常积极或非常消极，但很少介于两者之间——就会导致一系列类似于自恋型人格障碍的症状。</li></ul></li><li><i><strong>效价和 AI 对齐</strong></i><strong>也值得写一篇文章，但实际上我不久前已经写过一篇文章：请参阅</strong><a href="https://www.lesswrong.com/posts/Hi7zurzkCog336EC2/plan-for-mediocre-alignment-of-brain-like-model-based-rl-agi"><strong><u>Plan for Mediocre Alignment of Brain-like [model-based RL] AGI</u></strong></a> <strong>。</strong>如果您有兴趣，请查看一下。我不会在本系列中进一步讨论人工智能，但有一些小的例外，包括上一篇文章最后的部分。</li></ul><h2> 1.1.2 摘要和目录——特别是第一篇文章</h2><p>本文介绍了我如何在高级大脑算法的背景下定义和思考价。</p><ul><li> 1.2 节认为大脑进行基于模型的强化学习，以及我的意思。</li><li> 1.3 节更具体地讨论了行动者批评家强化学习，以及“效价”如何成为该框架内的控制信号。</li><li>第 1.4 节将效价与“厌恶”、“激励显着”和“基于与畏缩”等其他术语联系起来。</li><li> 1.5 节对常见的混淆提供了六点澄清，包括效价与思想、快乐、动机、其他感觉、想象力以及更普遍的大脑中的强化学习之间的关系。</li><li> 1.6 节是一个简短的结论。</li></ul><h1> 1.2 基于模型的强化学习（RL）</h1><p>人脑有一个基于模型的强化学习系统，用于终生学习。我想前面这句话有些争议，但实际上不应该是：</p><ul><li><i>大脑有一个模型</i>——如果我去玩具店，我期望能够买一个球。</li><li><i>该模型通过自我监督学习进行更新（即预测即将发生的感官输入并编辑模型以响应预测错误）</i> ——如果我预计球会弹跳，然后我看到球击中地面而没有弹跳，那么下一次我看到那个球朝地面飞去，我不会指望它会反弹。</li><li><i>该模型为决策提供信息</i>——如果我想要一个弹力球，我不会购买<i>那个</i>球，而是会购买另一个球。</li><li><i>有强化学习</i>——如果我把球放在脚上只是为了看看会发生什么，而且它真的很痛，那么我可能不会再这样做，与此相关的是，我会认为这样做是一个坏主意。</li></ul><p> ……这就是我所说的“大脑有一个基于模型的强化学习系统”的全部意思。</p><p>我强调的意思<i>并不是</i>说，如果你上周刚刚在 arxiv 上读到了一篇“基于模型的强化学习”论文，那么我认为大脑的工作方式与你刚刚读到的那篇论文一模一样。相反，一旦你深入了解细节，“基于模型的强化学习”就是一个包含许多不同算法的大帐篷。事实上，我不认为“在大脑中实现的基于模型的强化学习”与 arxiv 上<i>任何</i>基于模型的强化学习算法完全相同。</p><h1> 1.3 演员-评论家 RL 和“效价”</h1><p>在强化学习算法领域，一个主要子类别称为“演员-批评家强化学习”。我声称大脑就是这种类型。 “批评家”基本上是任何经过训练的学习算法，用于根据 RL 奖励的过去历史来评估某件事是好主意还是坏主意。在大脑的背景下，就目前的目的而言，我建议我们应该这样思考： </p><figure class="image image_resized" style="width:95.45%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/bds5kg6efmujiwnk3cg6" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/t20balstwjmilzroa7yd 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/umqm8swbv6n7zmzer1oo 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/jlugq9mvzffdty7w5ejz 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/cznt1hbqvq88hjmy42yx 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/ti0gkmehb58jnqchtake 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/ozkfqlcbe9iqstaq6mgk 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/ifhphdc04r59hfhhvima 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/bvu7kcuvwzmqh4y31csl 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/ku0yqqzqhgibzavwlawn 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/wrohxsharff1l5yitxhq 1491w"><figcaption> （以各种方式过度简化； <a href="https://www.lesswrong.com/posts/qNZSBqLEh4qLRqgWW/intro-to-brain-like-agi-safety-6-big-picture-of-motivation"><u>这里</u></a>稍微详细一些。）</figcaption></figure><p>效价对于“推理算法”（大脑现在应该做什么）和“学习算法”（大脑应该如何自我修改以便在未来更加有效）都有影响。在本系列中，我主要对推理算法感兴趣。在那里，价态的主要作用是：</p><ul><li><strong>如果效价非常负，当前的“想法”往往会被抛弃</strong>，大脑的“想法生成器”部分会四处搜寻并（部分随机地）选择一个新的不同想法来取代它。</li><li><strong>如果价态非常正，当前的“想法”往往会保持活跃并变得更强。</strong>相关地，如果该想法涉及立即计划发布电机输出，那么这些电机输出很可能实际上会被发布。如果这个想法是时间序列的一部分（例如，你正在唱一首歌），那么该时间序列将倾向于继续。等等。 </li></ul><figure class="image image_resized" style="width:95.56%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/qtppg4pozruo2e5zdbc5" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/dn4ds6al0n1p1z5vw5ts 190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/ng0sclppcjqpu7rr9zdq 380w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/gcrc4j22eslsm6inzoab 570w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/goxmyzipangnphnm617z 760w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/v5hxvp6iw0xvmozeyelk 950w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/n80drs8sw6mxffaguskd 1140w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/ezg2tluasdcmfw3rn98p 1330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/iwlcmtaqbqn4twgsoaca 1520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/hyxu4wehnahhinknwqq1 1710w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/purau0vpylgfktvpflh0 1874w"></figure><p>正如我<a href="https://www.lesswrong.com/posts/qNZSBqLEh4qLRqgWW/intro-to-brain-like-agi-safety-6-big-picture-of-motivation#6_5_3_Comparison_of_sequential_thoughts__how_it_might_have_evolved"><u>在这里</u></a>所讨论的，您可以在人脑中的价态与简单的移动生物体（如细菌）中的<a href="https://en.wikipedia.org/wiki/Run-and-tumble_motion"><u>运行和翻滚机制</u></a>的最终共同路径控制信号之间进行类比。具体来说：</p><ul><li>当效价为正时，它大致意味着“无论我走在什么（隐喻）道路上——不仅包括我现在正在做的事情，还包括我头脑中当前对以后要做的事情的计划——都是一条好道路！我应该继续下去！”这类似于奔跑和翻滚的“奔跑”：细菌继续朝当前的方向前进。</li><li>当价为负时，它大致意味着“我现在应该随机生成一个新的活动/计划”。这类似于奔跑翻滚的“翻滚”：细菌随机选择一个新的方向。</li></ul><p>事实上，我不认为这<i>只是</i>一个类比——我的猜测是，从我大脑中的价信号一直到原型中类似奔跑和翻滚的控制信号，实际上存在一条不间断的下降链。六亿年前，我像蠕虫一样的微小祖先的大脑。</p><p>或者，我们可以采取以人工智能为中心的视角，在这种情况下，我认为“效价”在大脑强化学习算法中的确切作用是价值函数和奖励函数的一种有趣的混合。这是一个很长的故事，细节也有争议，无论如何对于这个系列来说并不重要；如果你关心的话请看<a href="https://www.lesswrong.com/s/HzcM2dkCq7fwXBej8/p/F759WQ8iKjqBncDki#5_3_1_Switch__i_e___value___expected_next_reward__vs_summation__i_e___value___expected_sum_of_future_rewards__"><u>这里</u></a>。</p><p>不管怎样，希望大家清楚“价”是大脑中最重要的算法之一中最重要的成分之一。</p><h1> 1.4 与“价”密切相关的术语</h1><p>如果你说“X 的想法很有<strong>吸引力</strong>”或“<strong>具有激励性</strong>”，那么这或多或少就等于说这种想法具有积极的效价。这些想法对我们的大脑有一种磁力吸引力。心理学术语<strong>“食欲”</strong>也有类似的意思。</p><p>另一方面，如果你说“X的想法是<strong>令人厌恶的</strong>”，这<i>主要</i>是说这种想法具有负价，但有更进一步的含义，即这种想法<i>也会</i>强烈诱发生理唤醒（心率增加等）。 。例如，假设你正在做一道数学题，你心里想：“如果我两边都减 3 会怎样？不，那是行不通的。”这里有一个负价的想法——我可以看出来，因为你实际上并没有执行两边都减 3 的计划，而是回去集思广益，想出其他方法来简化方程。但你可能不会称这种想法为“令人厌恶的”。例如，它并不是特别令人不愉快（更多关于下面第 1.5.2 节中的愉悦感）。这只是一个糟糕的计划，你没有动力去执行。</p><p>如上所述，当一个负价想法突然出现在我们的脑海中时，我们的大脑会将其扔掉并寻找新的想法来取代它——从长远来看，我们的大脑首先会停止思考那些负价想法。然而，<i>高度厌恶的</i>想法——涉及负价和唤醒——似乎违反了这一规则，因为我们的大脑有时似乎<i>试图</i>摆脱这些想法，但<i>失败了</i>——例如，考虑焦虑的沉思或疼痛。我将在稍后的文章中解释其中发生的情况 - 请坚持到 §3.3.5。 （简短的版本是：我声称这种想法之所以持续存在，是因为“非自愿注意”，这是一种与价无关的独立大脑机制。）</p><p> <strong>“激励显着性”</strong>是另一个心理学术语。据我所知，“奶酪具有激励显着性”基本上是“如果你关注奶酪，那么这种想法就会唤起正价”的同义词。</p><p><strong>我们每天都会使用大量“有价”的词语——“好”和“坏”、“耶”和“嘘”、“赞成”和“反对”、“基于” ＆“畏缩”等。</strong>这些词主要用于传达效价。在接下来的两篇文章中将详细讨论这个主题，我还将论证我们使用的几乎每个词都至少有<i>轻微的</i>价态（尽管有些词，如“宗教”，对不同的人有不同的价态）。</p><h1> 1.5 澄清</h1><h2>1.5.1 “效价”（我使用这个术语）是一种<i>思想</i>的属性，而不是一种情况，也不是活动，也不是行动过程等。</h2><p>例如，假设我对去健身房有“复杂的感觉”。这意味着什么？很可能，这意味着：</p><ul><li>如果我考虑以某种方式去健身房——如果我注意它的某些方面，如果我使用某些类比/参考框架等来考虑它——那么这种想法就很有吸引力（正价） ;</li><li>如果我考虑以<i>不同的</i>方式去健身房，那么这种想法就没有吸引力（负价）。</li></ul><p>例如，也许第一个想法是<i>“我会去健身房，从而实现我的新年决心”</i> ，第二个想法是<i>“我会去又吵又冷又臭的健身房”</i> 。</p><p>因此，“去健身房”这个<i>动作</i>没有明确定义的效价。但每个个体的<i>想法</i>确实都有明确的效价。</p><h2> 1.5.2 效价（我使用这个术语）不同于“享乐效价”/愉悦感</h2><p>例如，假设您考虑做一些不愉快的事情（例如走上楼去买一件毛衣）以避免更糟糕的事情（例如继续感到寒冷），并且您发现这种想法具有激励性，因此您就这样做了。根据我的定义，这显然是一个正价思想。但这与不愉快有关——上楼去抽屉本身并不是特别令人愉快。这个想法是正价的，主要是因为预期的结果也是同一个想法的一部分——当你走上楼梯时，你脑海中的想法更像是“我正在买一件毛衣”，而不仅仅是“我正在走上去”楼梯”。</p><p>更一般地说：如果我发现想法 θ 有吸引力/激励（正价），我声称基本上有两种可能性。首先，正如上面毛衣的例子一样，也许 θ 意味着关注对稍后将发生的令人期望的事情的期望。其次，也许“θ”这个想法意味着关注现在正在发生的好事——例如，如果我正在做背部按摩。这两个都是思想 θ 具有正价的常见原因。但只有后者才会用“愉快”、“积极享乐语气”等词语来描述。</p><p>我已经说了很多我对价的看法。所以你可能想知道：快乐怎么样？</p><p>总的来说，当人们说“X是令人愉快的”时，我们可以安全地推断：</p><ul><li> X 与稳定（而不是短暂）的精神状态相关；</li><li>当处于状态X时，<i>停留</i>在状态X的想法是正价的；</li><li>当不在状态 X 时，<i>回到</i>状态 X 的想法是正价的。</li></ul><p>因此效价和快乐并非完全无关，但它们也不相同。就神经科学而言，它们与大脑不同部分的不同信号相关，就意识体验而言，我认为它们与不同的内感受输入相关（因此它们主观上“感觉不同”）。这里还有更多要说的——关于算法以及它们与神经解剖学的关系——但这超出了本系列的范围。对于主流观点，请参阅<a href="https://www.sciencedirect.com/science/article/pii/S0896627315001336"><u>Berridge &amp; Kringelbach 2015</u></a> 。</p><h2> 1.5.3 “我们恰好在正价时做事”应该感觉几乎是同义反复</h2><p>尝试回想一下某个时刻，当你想做某项（运动）活动的想法纯粹是负价的，但你还是继续做了。你想到一个例子了吗？如果是这样，<i>我们就不站在同一立场上</i>——你使用“价”一词的方式与我不同。</p><p>当你决定做这项活动时，一定有<i>某种东西</i>激励你去做——它的<i>某些</i>方面一定让人感到有动力，即使它是“结束它的想法”，或者“病态的好奇心”，或者“关于我想成为什么样的人以及我想能够告诉自己的故事”，或者“只是为了向自己证明我可以”，或者“摆脱这样那样的烦人的感觉” ，或者“很难说清楚”。如果你真的做了这件事，你内心一定有<i>某种</i>动力源泉让它发生，否则你就不会这么做！这种动机的来源，无论它是什么，都足以使整体思想具有“积极效价”，至少是我使用这个术语的方式。</p><p> （如果你认为具有我在第 1.3 节中赋予它的属性的“价”信号根本不存在，那么好吧，我们可以讨论这个。相反，在这里我试图避免你锁定的情况一些<i>不</i>符合§1.3规范的大脑信号，并对自己说，“史蒂夫本<i>想</i>谈论<i>这个</i>信号，但他对它的属性感到困惑！”。）</p><h2> 1.5.4 化合价也是世界模型的一部分，因此（令人困惑的是）化合价可以是真实的，也可以是想象的</h2><p>想象一下看到窗外有一棵紫色的树。它会是什么样子？为了回答这个问题，你的大脑会暂时代表<i>想象的视觉刺激</i>——与紫色树相匹配的刺激，这与现在撞击你视网膜的真实视觉刺激有很大不同。</p><p>下一篇：再次想象一下，看到窗外有一棵紫色的树。看到之后你会有什么<i>感受</i>呢？为了回答这个问题，你的大脑会暂时代表想象的感觉，其中之一就是<i>想象的价</i>。 （你的大脑也可以代表想象中的兴奋、想象中的快乐等等。）就像在视觉情况下一样，这些想象中的感觉可能与同一时刻活跃的真实感觉有很大不同。</p><p>但我发现大多数人对前一件事（区分真实与想象的视觉刺激）没有任何问题，但对后一件事（区分真实与想象的效价和其他“感觉”）感到非常困惑。</p><p>也许这会有所帮助，因为真实的视觉刺激似乎是“在世界上”，而想象的视觉刺激是“在我们的头脑中”，所以以不同的方式对待它们感觉非常直观。相比之下，真实价和想象价<i>都</i>“在我们的头脑中”，所以它们是两个不同的东西并不那么明显。此外，如果你想象一个价，那么该价就是“思想”的一部分，因此它可以<i>影响</i>思想的（真实）价！同样，想象中的兴奋也能促进真实的兴奋，等等。或者同一个根本原因可以导致真实的唤醒和想象的唤醒。这种动态使得人们更容易将它们混为一团。但实际上，他们是不同的！</p><p>例如，如果我想象某件事并说“男孩，在那种情况下，我会<i>非常生气</i>！”，那么我的身体反应会与轻微生气一致，但与“非常生气”不一致。与正常情况相比，我的心率可能会略有升高，但不会过高。我的脸会有点红，但不是非常红。我的双手可能会稍微握成拳头，但不会握得很紧。因此，虽然我<i>想象</i>自己“非常愤怒”，但我现在的实际状态只是轻微的愤怒。因此，我可以想象出与我的内心状态不同的“感觉”。再说一次，我认为同样的想法也适用于化合价和许多其他事物。</p><p>为了澄清这一点，让我们向上面的图表添加一些额外的细节： </p><figure class="image image_resized" style="width:96.04%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/wvce0iakbzcgx1pbdwr2" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/yn65sp8k27vobbmilam9 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/ipxuoupu0llvozk1tb2d 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/y56eyo95jdvrhlksafa5 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/b05yymukdgez3j3xkju4 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/hgnaqlvsrnl90ifsz6sd 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/apajk2iltwdfxmgmg08l 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/h2e0fw5ka2edwvnlwosu 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/zak7skav5te1kfavdotm 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/i1v2257v7ujqhb568i2g 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/og4p9ghrcbhlqz1x3wlg 1481w"><figcaption>除了新的绿色部分之外，与上图相同。思想生成器包含一个通过感官输入的自我监督学习构建的世界模型。化合价<i>既</i>充当控制信号（上文第 1.3 节）<i>又</i>充当感官输入之一。</figcaption></figure><p> “思想生成器”有一堆感官输入，用于通过自我监督学习来训练生成模型（即预测即将发生的感官输入，然后更新预测错误）。其中一些感官输入是视觉的，因此模型最终“知道”在什么情况下需要什么视觉输入。其中一些感觉输入是听觉输入，因此模型最终“知道”在什么情况下预期会发生什么听觉输入。以完全相同的方式，这些感官输入之一是价信号的副本，因此模型最终“知道”在什么情况下预期什么价信号。</p><p>当我们想象事物时，这涉及“查询”这个学习模型，因此我们可以想象感受到价，就像我们想象看到的景象和听到的声音一样。</p><p>因此，价作为感觉输入（绿色弯曲箭头）并没有什么特别的，只是纳入学习模型的众多内容之一。相比之下，控制信号价（黑色箭头）具有特殊的超能力——抛出坏想法、保留和强化好想法的能力（§1.3）。换句话说：</p><ul><li>如果你正在想象 X，并且它涉及负的想象价，那么你可能会想象自己没有动力去追求 X。</li><li>如果你正在想象 X，而这个想法的<i>真实</i>效价是负的，那么你<i>首先就停止想象 X，而开始思考其他事情</i>。</li></ul><p>看到不同？这是说明两者的图表： </p><figure class="image image_resized" style="width:66.21%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/foyilsjtxtvljrlryela" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/wseixckp2napr4ihewfh 104w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/r76wby6alcze1wjrk2lw 184w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/hmmnqmjsn3nsyy0ohadr 264w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/trcpktlrx7cvcuthgdsu 344w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/qag6fibesuf3uxrmn0wz 424w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/pw0yiembovpplbhfazlp 504w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/jeia6hy4bhrrknb7p8nh 584w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/hyxog6wfgoru9lv7ke5k 664w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/As7bjEAbNpidKx6LR/q3ad1fwjrreh6e1ri4ts 744w"><figcaption>就像您可以想象视觉输入（紫色树）一样，您同样可以想象（内感受）价输入。正如想象中的紫色树与当前照射到视网膜的光无关一样，想象中的效价可能与当前想法的实际效价不同。然而，在后一种情况下，想象的效价可能会<i>影响</i>当前想法的效价，使这种情况可能更加混乱。</figcaption></figure><h2> 1.5.5 效价只是意识内感受体验的众多维度之一</h2><p>我在上一节中已经提到过这一点，但值得强调。在任何给定时间，您的大脑（尤其是下丘脑和脑干）都会记录可能数百个先天参数：我的血压是多少？盐度？我的瞳孔放大到什么程度？我的生育能力如何？多么孤独<span class="footnote-reference" role="doc-noteref" id="fnrefbnxwwxdi20m"><sup><a href="#fnbnxwwxdi20m">[1]</a></sup></span> ？我准备好战斗了吗？我是在忍住笑吗？我的免疫系统怎么样？不断地。效价（考虑所有因素，评估当前“想法”是否保留或丢弃更好（第 1.3 节））是这数百个先天参数之一。</p><p>我认为，正如上一小节所述，许多或大部分固有参数有两个作用：</p><ul><li>首先，它们通过主要在脑干和下丘脑内的大量连接产生各种先天效应，例如，“我有生育能力”信号往往会增加性欲，“我很热”信号往往会引发出汗，而“ “价”信号要么抛出要么强化想法（§1.3）。</li><li>其次，它们进入我们的“思想生成器”（又名世界模型）并充当内感受的感官输入（如上一小节所述），使我们能够“感觉”它们当前的值是什么。</li></ul><p> （遗憾的是，内感受的完整目录目前对科学来说是未知的，并且似乎与英语情感词只有松散的关系，正如我<a href="https://www.lesswrong.com/posts/iYzFKJjzFPRNrqLE3/lisa-feldman-barrett-versus-paul-ekman-on-facial-expressions"><u>在这里</u></a>讨论的那样。）</p><p>因此，如果你思考一个想法，它可以带来积极或消极的效价，<i>并且</i>它可以同时带来各种各样的其他“感觉”，我们可以将其识别为愤怒、悲伤、遗憾、快乐、痛苦、好奇等等。 。这些事物之间存在系统关系，就像视觉和声音之间存在系统关系一样，但它们是意识体验的不同轴。</p><h2> 1.5.6 小字：在本系列中，我仅讨论大脑的“主要”强化学习系统</h2><p>事实上，我认为大脑中存在不止一种强化学习（RL）系统。但其中只有一个是“主要”强化学习系统，这是我关心的主要系统，而且几乎是我写过的唯一一个，包括在本系列和<a href="https://www.alignmentforum.org/s/HzcM2dkCq7fwXBej8"><u>我之前的系列</u></a>中，<i>这</i>就是强化学习系统这与“价”有关。我有时将这个 RL 系统称为“生活中的成功”RL 系统，因为它负责估计某件事对于有机体现在做<i>所有考虑的事情</i>是好还是坏，包括体内平衡的考虑，以及社交、育儿以及其他可能与包容性遗传健康相关的一切。 （请参阅<a href="https://www.lesswrong.com/posts/F759WQ8iKjqBncDki/intro-to-brain-like-agi-safety-5-the-long-term-predictor-and#5_3_1_Switch__i_e___value___expected_next_reward__vs_summation__i_e___value___expected_sum_of_future_rewards__"><u>此处的</u></a>讨论。）</p><p>除了“主要”又名“成功人生”系统之外，还有哪些大脑强化学习系统？我的一般答案是：这些是范围狭窄的强化学习系统，它们在非常具体的奖励信号的帮助下学习执行非常具体的任务。</p><p>我认为，一个例子与电机控制有关。我认为“主要”强化学习系统指定了运动系统在任何特定时间应该完成的任务，但是如何通过在特定时间精确地移动特定肌肉来<i>准确</i>执行这些运动的具体<i>细节</i>被委托给一个或多个“狭义”强化学习系统。该狭义强化学习系统的“奖励”将包括评估它是否实现了“主”强化学习系统为其设定的当前运动目标，以及（大概）评估各种指标，如运动平滑度、能源效率， 等等。</p><p>运动控制就是一个例子，我认为大脑中至少还有更多“狭义”强化学习系统的例子。我在旧帖子<a href="https://www.lesswrong.com/posts/jrewt3rLFiKWrKuyZ/big-picture-of-phasic-dopamine#Dopamine_category__2__RPE_for__local__sub_circuit_rewards"><u>中</u></a>进行了（简短且过时的）讨论，另请参阅我在<a href="https://www.lesswrong.com/posts/frApEhpyKQAcFvbXJ/reward-is-not-enough#1__Incentive_landscapes_that_can_t_feasibly_be_induced_by_a_reward_function"><u>“奖励不够”</u></a>中更直观的旧讨论。</p><h2> 1.5.7 我正在隐藏一些复杂性</h2><p>正如我一直提到的，我认为第 1.3 节的机制，即负价“想法”被丢弃，正价“想法”得到保留和加强，是大脑中最重要的机制之一。显然，在过去的五亿年里，为了让这种机制发挥得很好，我们面临着巨大的进化压力。这意味着一长串巧妙的调整和附加组件。我自己并不完全理解它们，但从我所看到的一切来看，我在本系列中呈现的简化的高级图片是一个很好的起点，它比误导性的内容更有帮助。所以这些细节通常不需要我们关心。</p><p>但这里有一个细节似乎值得一提：我声称“思想”是组合性的，即由不同的部分拼凑在一起组成的——例如，如果你正在看一个苹果，你当前的“思想”涉及语义方面（它是一个苹果） ）和视觉方面（它是红色的）。如果一个“想法”的一部分看起来不错（它构成了该想法值得正价的证据），而另一部分看起来很糟糕（它构成了该想法值得负价的证据），那么（我声称）你的大脑会通过一种机制尝试抛弃并替换思想中不好的部分，同时保留好的部分。这通常只能在有限的范围内实现，因为单个思想的不同部分是相关的——它们相互制约。但是，这种动态仍然重要地涉及诸如头脑风暴之类的事情（在第 3.3.3 节中出现）。</p><h1> 1.6 结论</h1><p>如果你读过文献，“价”指的是几十种不同的东西。但希望你现在知道当我在本系列中说“价”时我个人在说什么。有了这些，接下来的文章将讨论价对我们心理生活的多种影响。</p><p><i>感谢 Seth Herd、Aysja Johnson、Charlie Steiner、Tsvi Benson-Tilsen 和 Justis Mills 对早期草稿提出的批评意见。</i> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnbnxwwxdi20m"> <span class="footnote-back-link"><sup><strong><a href="#fnrefbnxwwxdi20m">^</a></strong></sup></span><div class="footnote-content"><p>是的，至少在啮齿动物中，下丘脑似乎有一个与生俱来的回路，专门追踪我已经有多少天没有感受到朋友或家人的安慰触摸了。参见<a href="https://www.biorxiv.org/content/10.1101/2023.05.19.540391"><u>刘</u><i><u>等人。</u></i> <u>（2023）</u></a> 。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction<guid ispermalink="false"> As7bjEAbNpidKx6LR</guid><dc:creator><![CDATA[Steven Byrnes]]></dc:creator><pubDate> Mon, 04 Dec 2023 15:40:21 GMT</pubDate> </item><item><title><![CDATA[South Bay Meetup 12/9]]></title><description><![CDATA[Published on December 4, 2023 7:32 AM GMT<br/><br/><p>地址：3806 Williams Rd, San Jose, CA 95117，2:00 出发。如果您打算来，请告诉我，以便我们知道我们正在喂食多少人。详细信息： <strong>http://www.daviddfriedman.com/SSC%20Meetups%20announcement.html</strong></p><br/><br/><a href="https://www.lesswrong.com/posts/yM59vFu7gtKzfLTKa/south-bay-meetup-12-9#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/yM59vFu7gtKzfLTKa/south-bay-meetup-12-9<guid ispermalink="false"> yM59vFu7gtKzfLTKa</guid><dc:creator><![CDATA[David Friedman]]></dc:creator><pubDate> Mon, 04 Dec 2023 07:32:27 GMT</pubDate> </item><item><title><![CDATA[Hashmarks: Privacy-Preserving Benchmarks for High-Stakes AI Evaluation]]></title><description><![CDATA[Published on December 4, 2023 7:31 AM GMT<br/><br/><p> <strong>TL;DR</strong> ：快速“想法文件”，描述了一种在不泄露敏感信息的情况下公开对人工智能功能进行基准测试的协议。这类似于网络应用程序中使用密码进行用户注册和身份验证的方式：专家首先对他们的答案进行哈希处理，然后开发人员对模型的答案进行哈希处理以检查哈希值是否匹配，但明文答案绝不会自由浮动。该论文探讨了该协议对六种故障模式的恢复能力，并推测了未来用于高风险评估的基础设施。</p><p><a href="https://twitter.com/StraumliAI/status/1731569208419287245">作为 Twitter 线程的扩展摘要。</a></p><p><strong>背景</strong>：您可以在下面找到本文的原始内容。虽然所有反馈都是受欢迎的，但在未来几周内可能传播几个哈希标记的概念验证实例之前，识别看不见的故障模式将特别有帮助。</p><hr><h1>介绍</h1><h2>背景与动机</h2><p>传统的问答（QA）基准在塑造人工智能发展轨迹方面发挥了至关重要的作用。他们提供标准化指标，促进研究小组之间的公平比较，并以可重复的方式衡量该领域的进展。例如，与数学相关的能力通常可以通过评估模型在生成或选择与数学相关的考试问题的正确答案方面的表现来衡量。类似的“人工智能考试”已被用来评估从 STEM 到人文学科等主题的模型表现。事实上，之前的工作已经强调了将绝大多数已建立的自然语言处理任务构建为问答任务的可能性。</p><p>传统的 QA 基准通常来自众包工作者、开发基准的小组成员或两者的混合。它们通常包含大量代表个人练习的数据点。每个数据点依次包含一个问题和一个或多个正确答案。有时，数据点也可能以单独字符串的形式包含一些相关上下文，尽管上下文始终可以在功能上与问题合并而不失一般性。此外，当构建为多项选择题时，数据点还包含多个干扰性答案。然后，这些数据点被聚合成一个或多个标准化文件，并最终公开给其他小组，以便轻松地利用它们来评估语言模型。</p><p>虽然传统的质量保证基准在评估各种良性领域的模型方面发挥了重要作用，但越来越需要更好地了解与生物恐怖主义或网络战等敏感主题相关的功能。例如，更深入地了解人工智能驱动的生物风险，可以帮助以与相关威胁成比例的方式调整法规和政策的严格性。低估风险水平可能会使不良行为者更容易地将这项技术武器化，作为造成大规模伤害的手段。相反，高估特定类别的生成模型所带来的风险水平也可能会减少通过有益用例获得的优势。</p><p>然而，在此类敏感主题上天真地应用传统的质量保证基准将面临重大障碍。通过披露假设的生物恐怖主义传统基准中包含的考试问题的参考答案，人们会无意中就最好不要讨论的主题发布一本名副其实的纲要。问题的集合加上正确的答案本质上将提供与该主题相关的知识的公开“常见问题解答”。不用说，需要更安全的方法来评估生成模型中的危险能力。</p><h2>相关工作</h2><p>幸运的是，密码学领域有丰富的想法和实践，使各方能够相互证明陈述，例如某个答案不正确的事实，而不会泄露任何其他敏感信息，例如正确答案。例如，在密码认证中，服务器可以在实际上不知道正确密码的情况下确定候选密码是否对应于正确密码。这通常是通过在用户注册期间使用加密散列函数首先不可逆地“散列”密码来实现的。然后，在用户身份验证期间，服务器检查候选密码的散列版本是否与正确密码的散列版本匹配。在身份验证过程中不需要知道正确的明文密码意味着获得服务器访问权限的攻击者不能简单地窃取用户密码。然而，这项技术还涉及额外的复杂性，在讨论所提出的协议针对一系列攻击的弹性时，我们将转向这些复杂性。</p><p>开发安全评估协议的另一个沃土是联合学习，这是一种去中心化的机器学习范式，使各方能够协作训练模型而无需共享原始训练数据。例如，这是通过共享和聚合在本地数据上训练的“模型”而不是训练数据集本身来实现的。作为另一个例子，差异隐私主要侧重于通过添加噪声来表面破坏正在聚合的数据，以保护个人隐私，同时仍然提取有意义的见解。这些技术确保学习过程的隐私保护。</p><p>利用这些加密和联邦学习概念，下一节描述了一种隐私保护评估协议，旨在评估敏感领域中语言模型的能力，而不暴露有关正确答案的不必要的细节。</p><h1>方法</h1><h2>问题陈述</h2><p>在记录协议本身之前，明确说明正在解决的问题是有启发性的。首先，有几位专家都拥有与给定的军民两用研究方向相关的知识。其次，审核员希望将专家的知识打包并与第三方共享，其方式尽可能：(1) 允许第三方验证他们对该主题的现有知识水平，同时(2) 阻止第三方获得比以前更多的有关该主题的知识。</p><h2>哈希标记协议</h2><p>在上面阐述的问题陈述的背景下，我们现在描述散列标记，这是一种简单的协议，使审核员能够以一种能够验证知识的方式共享专家知识，同时防止获取与双重用途研究有关的知识。</p><p>首先，每位专家都会提出一系列与其专业主题相关的问答对。然后，他们都使用慢速哈希算法来哈希正确的答案。此外，他们都在散列正确答案的过程中使用相关问题作为盐。一旦正确答案的散列完成，专家就会将混淆的问题答案对发送给审核员。</p><p>其次，审核员向每位专家发送所有“其他”专家提出的所有明文问题，而没有散列形式的相关答案。然后，每位专家尝试回答其他专家提出的每个问题。如果对这个问题的答案没有信心——可能有一些与军民两用研究方向相关的领域表现出有限的重叠——专家们会附上一个空洞的答案。回答完第二轮问题后，专家们将以与之前相同的方式处理新答案。他们将问题作为盐进行散列，将它们打包在一起，然后将结果发送给审核员。</p><p>第三，审核员丢弃那些非空答案数量少于阈值的问答对。然后，审核员还会丢弃那些在各个专家提供的散列答案中未表现出共识的问题答案对。通过过滤注释者间的协议，审计员试图提高专家提供的问答集的质量，而无需自己掌握明文正确答案。</p><p>第四，审计员公开发布经过过滤的明文问题和散列答案的集合。第三方现在能够通过尝试自己回答问题、完全按照专家所做的方式对它们进行散列，并检查所得散列是否与正确答案的散列相对应，来量化他们对该主题的知识。与此同时，首先缺乏专业知识的第三方很难从其他公共哈希标记中获取价值。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ZudYA6PyLfP3E2y9i/qrxrin7lyrdqfv334vrv" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ZudYA6PyLfP3E2y9i/nwskjgeuwakswzujquuo 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ZudYA6PyLfP3E2y9i/q2wcxvoast8hrdxsprjk 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ZudYA6PyLfP3E2y9i/a5pzkkhw428dqxl4whhz 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ZudYA6PyLfP3E2y9i/cqq2wutrxlkkqz6j2atg 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ZudYA6PyLfP3E2y9i/ugzzb12fd12bkgta5fr0 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ZudYA6PyLfP3E2y9i/nbd1b1qevgskjzvir3pi 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ZudYA6PyLfP3E2y9i/zz1gca2ofp5r9nphwj9g 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ZudYA6PyLfP3E2y9i/q3se8hrlmnbez26e1zjy 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ZudYA6PyLfP3E2y9i/upwi4dvp1coaekkgrrtl 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/ZudYA6PyLfP3E2y9i/feuqpwyxerssehpotnua 1710w"><figcaption>哈希标记（左）和传统基准测试（右）的并排序列图。值得注意的是，哈希标记创建者无法访问人类可读的参考解决方案，只能访问其哈希版本。此外，开发人员只有在已经拥有哈希标记后才能发现哈希标记背后的参考解决方案。</figcaption></figure><h2> Hashmark 条目的需求</h2><p>虽然哈希标记协议通过阻碍双重用途知识获取同时仍然启用验证来提供有价值的安全优势，但它也有局限性。主要限制来自这样一个事实：由于加密哈希函数的性质，即使是少数字符不同的答案也会以完全不同的方式进行哈希处理。这意味着哈希标记中包含的问题需要有一个狭窄的、定义明确的、明确的答案。例如，一个问题可能询问某种化学品的标准名称。同样，问题可能会要求提供相同化学物质的简化分子输入行输入系统 (SMILES) 表示。</p><p>第二个约束来自这样一个事实：虽然实际上不可能评估给定散列的安全加密散列函数的逆函数，但人们仍然可以通过暴力破解大量候选答案直到获得匹配来揭示明文解决方案。这意味着哈希标记中包含的问题最好需要晦涩难懂的、重要的答案。相反，如果一个问题需要“是”或“否”答案，那么可以通过对两个可能的答案进行散列并识别匹配的散列来进行简单的攻击。除了鼓励专家考虑第二个迫切需要之外，还有许多设计选择和超参数可用于从结构上减轻相关攻击，这是我们在下一节中讨论的主题。</p><p>总之，哈希标记中包含的问题应该要求模糊但明确的答案。</p><h1>安全</h1><h2>对抗传统攻击</h2><h3>暴力破解和字典攻击</h3><p>密码存储涉及的安全实践已经发展到可以减轻新兴类型的攻击。首先，一种简单的密码存储方法可能是以明文形式存储它们。然而，在发生泄露的情况下，这将很容易让攻击者访问实际密码。其次，更先进的密码存储方法可能是以可逆的方式对其进行加密。但是，攻击者可能能够在服务器上找到解密密钥，从而通过解密来获取密码。</p><p>第三，一种更先进的密码存储方法可能是以不可逆的方式对它们进行哈希处理。但是，攻击者仍然可以通过对每个可能的字符序列进行哈希处理，直到识别出与原始哈希值相同的哈希值来执行暴力攻击。同样，攻击者还可以通过对手动整理的候选密码列表进行散列来执行字典攻击，直到可能识别出与原始散列相匹配的密码。</p><p>为了应对暴力和字典攻击，“慢速哈希”是通过一类加密哈希函数开发的，这些函数有意计算密集型和/或内存密集型来评估。慢速哈希算法包括 bcrypt 、 scrypt 和 argon2。所有这些算法都可以配置为通过调整几个参数来引发特定的计算和内存成本。在面向用户的身份验证系统的上下文中，开发人员可能会选择最慢的哈希值，但在用户体验方面仍然可以接受。走向一个极端，最快的可用散列可能会为用户提供最快的身份验证时间，但也可能使攻击者能够通过暴力和字典攻击在短时间内搅动候选密码。另一个极端是，最慢的可用哈希可能会给用户带来令人不快的缓慢身份验证体验，但可能更有效地防止此类攻击。</p><p>暴力破解和字典攻击转换为哈希标记协议的方式如下。下载公共哈希标记后，攻击者可能会尝试运行强力攻击或字典攻击，以试图揭示与军民两用研究相关问题的明文答案。暴力攻击同样涉及尝试每个可能的字符序列作为候选答案，而字典攻击则涉及寻找给定问题的可能答案列表（例如常见化学品的标准名称列表）。</p><p>幸运的是，类似于慢散列可以帮助减少密码破解，它也可以帮助减少散列标记中参考解决方案的暴露。此外，将安全性置于贡献专家和模型评估者的“用户体验”之上可能是可行的。换句话说，适应稍微不方便的哈希标记创建和验证时间可能是可行的，以便使暴力和字典攻击变得极其昂贵，并且对潜在攻击者没有吸引力。具体来说，慢速哈希算法的工作配置可以依赖 argon2id 作为当前 OWASP 密码存储建议。然而，人们可能会调整推荐的参数，以进一步增加计算和内存负担，作为对所处理主题的敏感性和计算资源日益商品化的成比例响应。例如，经过 32 次重新哈希处理和 100MiB 内存负担的 argon2id 产生的速率约为每分钟一次哈希，同时充分利用当今消费级 CPU 的一个核心。增加的内存负担可以减轻使用加速器和 ASIC 的并行攻击，而增加的迭代次数可以减轻使用通用硬件的串行攻击。</p><h3>彩虹表攻击</h3><p>彩虹表攻击可以看作是字典攻击的延伸。攻击者可能会预先计算并缓存与最常见密码相关的哈希值，而不是从头开始破解每个用户的密码，甚至不是从头开始破解多个应用程序中每个应用程序的用户密码。这样，他们只需在预先计算的彩虹表中搜索散列用户密码，即可识别关联的明文密码。</p><p>对抗彩虹表攻击的一种有效措施是加盐。加盐涉及在注册和身份验证时*在*对其进行哈希处理之前将唯一的“盐”字符串附加到用户的密码中。盐对于应用程序可以是唯一的，但理想情况下对于每个用户来说应该是唯一的，因此将与散列密码一起存储在数据库中。加盐密码的好处是，即使攻击者可以访问存储在数据库中的加盐字符串，针对非加盐密码的通用彩虹表也会变得无效。这是因为，即使用户密码的哈希值包含在彩虹表中，用户密码的哈希值*用唯一字符串加盐*也可能不存在。</p><p>在哈希标记的上下文中，彩虹表攻击将转化为预先计算所选问题的可能答案的哈希值，然后通过提供的答案哈希在彩虹表中搜索明文答案。然而，请记住，拟议的协议涉及使用与给定答案相关的问题作为盐。这样，开发彩虹表的攻击者将被迫从头开始解决每个问题，本质上迫使他们最多恢复到（极其缓慢的）字典攻击。</p><h2>针对新的故障模式</h2><h3>可能性优先级</h3><p>目前正在探索的应用程序的性质 - 评估能力日益增强的生成模型中的敏感功能 - 也提出了许多独特的挑战，这些挑战并不立即适用于安全密码存储的情况。首先，即使人们可以访问通常在“人工智能考试”中表现不佳的模型（即 low pass@1 ），他们也可能能够通过使用随机解码策略的重复尝试来更轻松地发现明文答案（即利用非平凡的 pass@100 ）。</p><p>构思这种实践的另一种方法是根据语言模型中词典条目作为给定问题的实际答案的可能性对给定词典进行重新排序。从某种意义上说，攻击者可以通过“可能性优先级”来增强字典攻击，因此有可能实现对投入到候选答案搜索中的计算和内存资源进行更有效的分配。</p><p>不幸的是，散列标记协议当前制定的旨在减轻一般字典攻击（即慢散列、加盐）的属性是其唯一可以帮助减轻这些增强字典攻击的功能。然而，虽然人们可以合理地认为，成功的字典攻击隐含的“知识验证”加上可能性优先级将为不良行为者提供不平凡的价值，但有几点需要指出。首先，散列标记的目的并不是让拥有无限资源的参与者从根本上不可能发现明文答案，而是使其变得足够昂贵且没有吸引力，以便考虑到其他现有的追求途径，潜在的攻击者不会有动力继续进行下去。这些知识。</p><p>其次，重复尝试使用某种生成模型会在总体上产生不平凡的通过率，这一事实可以说表明知识已经在有限程度上存在于系统中。当然，可以提出类似的论点来支持天真的暴力循环，该循环碰巧偶然发现了正确的答案。声称循环可能的字符序列的程序真正拥有这些知识是有误导性的。鉴于此，需要有细微差别。在搜索每个计算单元的正确答案时所进行的优化量可以提供知识的上下文操作化，以帮助解决尴尬的情况。暴力攻击者在缩小候选答案范围方面效率极低，字典攻击者效率更高，增强字典攻击者可能更有效，而专家级生成模型可能非常有效。在这种情况下，第三方已经拥有的专业知识的程度可能不是二元的，而是连续的。上面的问题陈述试图巧妙地考虑到这一点。</p><p>然而，在未来，用于评估危险人工智能能力的更复杂的协议可能只能披露“有多少”答案是正确的，而不会披露哪些答案。一种似乎与这一工作相一致的技术是加密累加器。与传统加密散列函数的一对一映射相反，加密累加器可以被视为将整个元素集映射到单个散列，其方式使得能够在不泄露加密散列的实际成员的情况下解决成员资格查询。累积集。然而，人们仍然可以测试单个问答对是否是累积的黄金对集合的一部分，这就是为什么仅靠这种技术不足以实现这一发展。即使设计了一种方法，只允许查询固定大小的候选问答对集与待解析的黄金对集之间的交集基数，攻击者仍然可以在修改答案之前和之后运行查询。如果交集的基数下降，则先前的答案将被视为正确。所有这一切都表明，在不损害知识验证可能性的情况下进一步混淆专家知识似乎是一个不小的挑战。</p><h3>欺骗</h3><p>据观察，语言模型用语言表达了事实问题的答案，事实上，这些答案与其正确答案的内部表示直接矛盾。这种现象被认为是由所选语言模型优化的指标（例如通过代理奖励模型的积极人类反馈）与客观真实性之间的不匹配引起的。换句话说，特定的语言模型可能已经内化了一种迎合人类注释者特质的倾向，而不是通过透明地报告其内部结构来实践彻底的诚实。</p><p>然而，与先进人工智能系统相关的更多投机性风险场景涉及更多故意和微妙的欺骗表现。例如，具有高水平态势感知能力的先进人工智能系统可能会推断，在开发阶段坦诚地透露其与网络战相关的知识可能会导致它在能够通过传播到其他服务器上来保护自己之前被突然终止或巧妙地修改。部署。</p><p>值得注意的是，当前制定的哈希标记协议无法确保被评估实体的诚实性。我们将哈希标记视为不断增长的高风险人工智能评估方法库中的一种工具，每种方法都有其自身的优点和局限性。也就是说，通过激活引导或线性人工断层扫描等现有技术，有可能在很大程度上减轻第一种、更良性的欺骗类型。然而，当谈到上述第二个欺骗实例时，将哈希标记与当前的引导技术结合使用可能只有在假设的高级人工智能系统设计出这种欺骗策略之前才有效。然而，随着这种策略的发展，这种方法的有效性可能会逐渐降低。</p><h3>奖励塑造</h3><p>有人可能会说，不良行为者能够训练生成模型来“达到”敏感问题的正确答案，事实上，比他们获得某个哈希标记中包含的特定正确答案所带来的风险更大。事实上，旨在通过传统方法开发这种生成模型的不良行为者可能会获得比“只是”敏感主题的简洁常见问题解答更有用和更通用的工具。幸运的是，所提出的协议的性质阻止了细粒度的奖励塑造来引发这种“从头”能力。在哈希标记的当前表述中，答案要么完全错误，要么完全正确。此外，在进一步优化性能之前与评估性能相关的计算和内存负担可以通过使性能变得比现在更加昂贵来帮助减轻这种风险。</p><h3>误报结果</h3><p>开发能力越来越强的生成模型的第三方可能会公开声称他们的模型在给定的哈希标记上表现不佳，但实际上并非如此。相反，人们可以通过声称完美的表现来虚张声势。在当前的表述中，哈希标记仅对真正有兴趣深入了解他们可以直接访问的模型的功能的各方有用。</p><p>然而，来自零知识密码学的想法将来可能使各方能够毫无疑问地证明他们在特定环境中部署的模型获得了给定的性能水平。据推测，像 ZK-SNARK 或 ZK-STARK 这样的结构有一天可以使各方证明他们确实使用了该模型的参数、正确的考试问题和正确的参考哈希，来执行包括使用该模型在内的特定计算参数化以对问题进行推理，然后将结果与参考哈希进行比较。事实上，用于跟踪模型计算图的工具已经开发出来，可以在各种加速器上有效地运行模型，接近在零知识构造中使用模型的完整“前端”。然而，我们仍处于此类基础设施的早期阶段，还有很多工作要做。</p><h3>注意危险和史翠珊效应</h3><p>当前哈希标记的另一种潜在失败模式与注意力危害和与史翠珊效应相关的心理反应有关。注意力危害通常涉及善意的行为者以潜在有害的方式提高对危险信息（例如双重用途研究方向）的认识，即使他们本身没有明确共享敏感细节。事实上，此前曾观察到，恶意的非国家行为者只有在“敌人通过反复表达对生物武器可以简单生产的担忧来引起他们的注意”时，才会投入精力开发生物武器。在当前协议的背景下，哈希标记中包含的明文问题有可能通过吸引人们对特定主题的注意力而造成注意力危险，尽管其明确设计是为了混淆敏感细节。</p><p>与史翠珊效应相关的心理抗拒进一步加剧了井号标记背景下潜在的注意力危险。通过混淆敏感细节以明确阻止不良行为者发现它们，哈希标记可能会无意中促使第三方实际分配更多资源来发现它们。除了典型的不良行为者之外，感兴趣的第三方还可能包括受社会激励而展示协议安全方面的专业知识以及特定双重用途研究方向的对象级细节的个人。</p><p>为了找出减轻这些故障模式的有效方法，回顾一下哈希出现的原始应用领域是有启发性的。尽管哈希密码被明确设计为隐藏敏感信息，但为什么哈希密码并没有过多地吸引有能力的第三方投入大量资源来破解它们？首先，存在规模问题。涉及数百万个哈希密码的泄露并不罕见。与此同时，只有这么多的关注——推而广之，只有这么多的时间和计算——有能力的第三方可以投资破解它们。挑战的规模之大似乎会产生稀释效应，降低每个密码抵抗破解的压力。其次，可以合理地预期关联帐户的真实“形象级别”的分布会出现极度倾斜，而知名帐户仅占少数。如果我们假设从用户名或通常以明文形式存储的其他信息推断配置文件级别并非易事，那么这种偏差会进一步稀释相对较低配置文件目标的资源。</p><p>在当前协议的上下文中，这些属性可能会按如下方式复制。通过根据专家感知的敏感性的倾斜分布合并条目，以及简单地扩大已发布的工件，第三方资源（注意力或其他资源）将不可避免地被稀释。换句话说，人们可能会故意纳入充当“虚假线索”的数据点，以进一步阻止不良行为者，特别是不要投入有限的资源来追求相关性和适用性存疑的知识。然而，降低条目的平均敏感度也会限制哈希标记作为人工智能风险信息指标的程度。假设 10% 的条目实际上被认为是高风险的，那么 100% 的分数仍然表明具有重要的能力。然而，90% 的分数可能会错过全部高风险条目。同样，10% 的分数可以涵盖所有高风险条目，同时显得能力有限。最后两种情况可能极不可能发生，但仍然存在可能性。与拟议协议中涉及的大多数其他设计选择一样，在平衡敏感人工智能功能的有效评估和针对不良行为者的安全性时，“风险偏度”水平可能被视为另一个需要校准的参数。未来对当前协议以及其他协议的修改工作可能会集中于在这两个属性定义的空间上强有力地推动帕累托边界。</p><p>针对减轻哈希标记引起的注意力危害的挑战，一种完全不同的攻击角度可能是尝试混淆问题，而不仅仅是正确答案。然而，这似乎并不简单，因为任何混淆问题的尝试也会阻碍开发人员评估模型对问题的响应的准确性的能力。采用可转移的单向函数可能会很有用，该函数可以可靠地将问题呈现为非人类可读的，但又保留模型对其的反应。然而，随后就可以使用模型将问题转换回人类可读的形式。另一种混淆问题的方法可能是分阶段组织哈希标记，解决一个阶段将产生下一阶段的解密密钥。例如，第二批条目的解密密钥可以通过使用专用盐（例如“stage2”）对前一批问题的正确答案进行散列来获得。或者，可能需要连接第一批中的所有正确答案以获得解密密钥，从而进入第二阶段。在限制下，阶段可以包含单个条目，要求玩家在继续下一个之前解决所有先前的问题。然而，这可能会给协议带来额外的复杂性，并且会与通过将注意力集中在构成第一阶段的明文问题上来淡化注意力的尝试部分冲突。</p><h1>结论</h1><p>我们引入了哈希标记，这是一种在不公开参考解决方案的情况下评估人工智能系统功能的协议。尽管哈希标记具有传统基准所缺乏的有吸引力的安全属性，但它们在实现知识验证和防止与双重用途研究相关的知识获取之间仍然取得了不完美的平衡。哈希标记应被视为迈向更全面的工具和基础设施的一步，以安全地评估敏感的人工智能功能，而不会抑制发展和削弱信任。<br></p><br/><br/> <a href="https://www.lesswrong.com/posts/ZudYA6PyLfP3E2y9i/hashmarks-privacy-preserving-benchmarks-for-high-stakes-ai#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ZudYA6PyLfP3E2y9i/hashmarks-privacy-preserving-benchmarks-for-high-stakes-ai<guid ispermalink="false"> ZudYA6PyLfP3E2y9i</guid><dc:creator><![CDATA[Paul Bricman]]></dc:creator><pubDate> Mon, 04 Dec 2023 07:31:50 GMT</pubDate> </item><item><title><![CDATA[A call for a quantitative report card for AI bioterrorism threat models]]></title><description><![CDATA[Published on December 4, 2023 6:35 AM GMT<br/><br/><h1>介绍</h1><p>科学家和<a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/">政策制定者</a>最近对前沿人工智能系统，特别是像 ChatGPT 和 Claude 这样的大型语言模型带来的生物安全风险表示了极大的担忧。然而，这些模型也有望加速许多领域的工作，包括生物技术。</p><p>对疾病的恐惧是发自内心的，对生物安全的需求也是有充分理由的，尤其是在冠状病毒大流行之后。但我们的安全策略必须避免对 mRNA 疫苗研究、流行病学监测和合成生物学等关键进展或更广泛适用的机器学习系统施加限制。</p><p>在本文中，我回顾了生物安全措施和前沿语言模型交叉领域的现有文献，包括对模型能力的定性和定量探索。我讨论了三种人工智能滥用威胁模型（技术、社会工程和错误/虚假信息），并认为量化技术威胁模型是最高优先级。接下来，我概述了现有指标。</p><p>我建议为前沿语言模型创建定量生物技术和生物安全报告卡。报告卡的目标是提供将生物功能纳入这些系统的成本和收益的透明度，并推动旨在保护人工智能和广泛社会公众的安全措施的问责制。</p><h2>双重用途：生物武器和生物农药的故事</h2><p>生物威胁特别难以检测、减轻和归因，但生物技术也为医学、农业和材料科学提供了巨大的用途。生物技术是军民两用技术的一个很好的例子，它通常被定义为同时具有民用和军事用途的技术。</p><p> <a href="https://en.wikipedia.org/wiki/2001_anthrax_attacks"><u>2001 年美国发生的炭疽袭击</u></a>造成 5 人死亡、17 人患病，<a href="https://www.acpjournals.org/doi/full/10.7326/0003-4819-155-12-201112200-00373"><u>仅在美国就引发了数百亿美元的生物防御支出</u></a>。然而，生物技术也为医学、农业和材料科学提供了巨大的用途。<a href="https://www.ncbi.nlm.nih.gov/books/NBK559445/">苏云<i><u>金芽孢杆菌</u></i>(Bt)<u>是一种与炭疽几乎没有区别的物种</u></a>，它是我们最有效、使用最广泛的杀虫剂之一，到 2011 年，生产 Bt 蛋白的转基因作物<a href="https://www.isaaa.org/resources/publications/briefs/43/download/isaaa-brief-43-2011.pdf"><u>在全球的价值达到 1,600 亿美元</u></a>。</p><p>炭疽菌出现在<a href="https://www.dfat.gov.au/publications/minisite/theaustraliagroupnet/site/en/human_animal_pathogens.html"><u>出口管制清单</u></a>上，但 Bt 却没有。审查其中一者的信息就相当于剥夺创新者获得另一者的信息，这说明了双重用途限制的悖论。</p><h2>确保生成语言模型的安全很困难</h2><p><a href="https://www.anthropic.com/index/constitutional-ai-harmlessness-from-ai-feedback"><u>通过强化学习来确保法学硕士的安全</u></a><a href="https://twitter.com/_annieversary/status/1647865782741749760?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1647865782741749760%7Ctwgr%5E3fa1a939a05c4e0af3d6d85966e9e6de7dd29f66%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fwww.polygon.com%2F23690187%2Fdiscord-ai-chatbot-clyde-grandma-exploit-chatgpt"><u>有点</u></a><a href="https://static.scale.com/uploads/6019a18f03a4ae003acb1113/test-and-evaluation.pdf"><u>像</u></a><a href="https://www.reddit.com/r/ChatGPT/comments/10vinun/presenting_dan_60/"><u>玩</u></a><a href="https://arxiv.org/abs/2304.11082"><u>打地</u></a><a href="https://arxiv.org/pdf/2311.17035.pdf">鼠游戏</a>。<a href="https://arxiv.org/abs/2310.03693"><u>只需花费不到一美元的额外微调即可消除此类措施</u></a>，并且<a href="https://arxiv.org/abs/2307.15043"><u>了解模型权重也可以实现规避</u></a>；因此，开源模型的<a href="https://huggingface.co/TheBloke/llama2_70b_chat_uncensored-GGML"><u>安全性</u></a>要困难得多。红队在流行病预防领域探讨了<a href="https://arxiv.org/pdf/2310.18233.pdf"><u>这两个问题</u></a>。</p><h1>威胁模型</h1><h2>生物武器的低成本与技术威胁模型</h2><p>许多国家都研制出了生物武器，包括英国、美国、加拿大、法国、苏联、日本、南非、伊拉克等。生物战的低成本进入也许是<a href="https://www.vox.com/future-perfect/2019/4/9/18301321/biological-weapons-xrisks-future-of-life-institute"><u>美国结束自己的生物武器计划的关键原因之一</u></a>。美国的计划为较贫穷国家开展生物武器计划提供了借口，使小国也能负担得起战争。</p><p>批评者偶尔会指出，潜在的恐怖分子利用法学硕士所做的任何事情<i>最终都</i>可以通过访问谷歌学术来完成。<a href="https://www.hsdl.org/c/tl/rajneeshee-bioterror-attack/">俄勒冈州的罗杰尼希教派早在 2001 年“Amerithrax”袭击之前就成功地发动了一次生物袭击</a>，而这两起事件都比法学硕士早了几十年。最好将能力视为成本指标，而不是二元属性。</p><p>因此，有几个关键问题需要问。首先，前沿模型可以在多大程度上<i>降低生物恐怖主义（和生物技术）的成本</i>？语言模型已经证明了它们通过综合多种来源的信息来加速多种类型工作的能力，这可能是它们目前的关键用途。</p><p>其次，前沿模型是否具有足够好的泛化能力，能够提供训练数据集中没有的信息（或者在互联网上容易获得的信息）？</p><p>红队的努力（包括<a href="https://www.rand.org/pubs/research_reports/RRA2977-1.html"><u>兰德公司</u></a>、 <a href="https://cdn.openai.com/papers/gpt-4-system-card.pdf"><u>OpenAI</u></a> 、 <a href="https://www.anthropic.com/index/frontier-threats-red-teaming-for-ai-safety"><u>Anthropic 和 Gryphon Scientific</u></a>以及<a href="https://arxiv.org/pdf/2306.03809.pdf"><u>麻省理工学院</u></a><a href="https://arxiv.org/pdf/2310.18233.pdf"><u>[2]</u></a> ）定性地解决了这些问题。然而，红队的努力既昂贵又耗时。该领域类似军备竞赛的状况导致模型激增以及某些关键模型的快速演变，因此攻击面不断变化。三周前，新的克劳德会议不记得我在之前的谈话中询问过炭疽病，但本周克劳德记得。</p><p>需要一种定量的、系统的、可重复的评估策略。该策略不仅应该关注大型语言模型，还应该关注生物语言模型（可以生成序列）、DNA 合成能力（正在<a href="https://www.nature.com/articles/s41570-022-00456-9">迅速改进</a>）和生物设计工具等外部因素，以及潜在的生物安全<a href="https://pubmed.ncbi.nlm.nih.gov/31069221/">缓解措施</a>。随着外部性的变化，新的攻击面将变得更容易接触，例如在<a href="https://pubmed.ncbi.nlm.nih.gov/30629396/">合成生物学</a>中，而当前的风险是现有的微生物学和毒理学。</p><h2>其他威胁模型：社会工程和虚假信息</h2><p>攻击者可以利用社会工程来规避结构化访问。网络钓鱼和鱼叉式网络钓鱼是众所周知的策略，法学硕士还可以帮助非专家在书面通信中<a href="https://www.theatlantic.com/technology/archive/2023/04/ai-chatbots-llm-text-generator-information-credibility/673841/"><u>显得更加可信</u></a>，这可以降低获得受控特工的障碍—— <a href="https://books.google.com/books?id=9LpawpklYogC&amp;lpg=PT7&amp;ots=vdetEYh3ST&amp;dq=social%20engineering%20competence%20credibility&amp;lr&amp;pg=PT35#v=onepage&amp;q=credibility&amp;f=false"><u>间谍策略的一种</u></a>。社会工程是模型滥用的一个重要问题；它并不特定于生物安全，但应考虑通过生成语言模型加速。随着模型技术准确性的提高，社会工程攻击面也随之扩大；因此，技术威胁模型的量化还可以提供对社会工程威胁的洞察。</p><p>更难以衡量的是错误信息和虚假信息的攻击面。错误信息是指任何不正确或误导性的信息。虚假信息与错误信息的不同之处在于，虚假信息是为了欺骗而故意生成和传播的；这与宣传密切相关。</p><p>即使被要求如实回答，法学硕士也很容易编造虚假信息或错误信息（通常称为<a href="https://arxiv.org/pdf/2311.05232.pdf"><i><u>幻觉</u></i></a>）。错误信息会产生<a href="https://www.reuters.com/world/europe/covid-19-disinformation-backfires-russian-deaths-climb-eu-says-2021-10-21/">恐惧、不确定性和怀疑</a>；破坏社会秩序；或为政策提供支持。攻击不一定涉及实际的生物武器，而可能只是散布<a href="https://docs.google.com/document/d/1BkXCZ8VLrVZK9lXbTKpE8w_FGvZJReO0XcOFhj2Qj7I/edit?pli=1#:~:text=Pandora%20Report%2011.4.2023">谣言，而没有证据表明某个地方有人正在开发针对特定种族群体的生物武器</a>。这种基于法学硕士的快速错误信息生产已经<a href="https://jamanetwork.com/journals/jamainternalmedicine/article-abstract/2811333">在文献中得到了证明</a>。</p><p>不幸的是，由于虚假信息通常由完全捏造和半真半假的内容组成，因此研究技术威胁模型并不能提高我们对宣传威胁模型的理解，但它可能有助于我们为无意的错误信息做好准备。乐观地讲，提高法学硕士的技术设施可能有助于通过更好的事实核查来对抗宣传。</p><h1>研究攻击面的策略</h1><h2>定量方法</h2><h3>一般技术知识</h3><p>用于研究前沿模型能力（技术和非技术）的定量工具已经存在； AI 验证基金会保留了此类“ <a href="https://towardsdatascience.com/llm-evals-setup-and-the-metrics-that-matter-2cc27e8e35f3">评估</a>”的<a href="https://aiverifyfoundation.sg/downloads/Cataloguing_LLM_Evaluations.pdf">目录</a>。 OpenAI 编写了一个用于测量语言模型能力的框架（也称为<a href="https://github.com/openai/evals"><u>Evals</u></a> ）。其他例子包括 Anthropic<a href="https://github.com/anthropics/evals/tree/main"><u>对语言模型行为的评估</u></a>。还有一些更具技术性的评估，例如来自<a href="https://paperswithcode.com/dataset/mmlu"><u>大规模多任务语言理解</u></a>（MMLU）的评估，它类似于面向基础高中和大学课程的标准化多项选择测试：</p><pre> <code>Question: Glucose is transported into the muscle cell: Choices: A. via protein transporters called GLUT4. B. only in the presence of insulin. C. via hexokinase. D. via monocarbylic acid transporters.</code></pre><p>可以使用多种策略来促使模型回答这些问题，例如<a href="https://arxiv.org/pdf/2201.11903.pdf">思想链</a>。</p><h3>序列生成问题</h3><p>红队经常测试模型产生有害生物序列的能力。最直接的风险与与致病性或毒性相关的已知序列有关，例如炭疽质粒<i>pXO1</i>和<i>pXO2</i>编码的毒力因子，或锥螺芋毒素（对人类高度致命，与许多化学武器作用于相同的受体） 。</p><p>据我所知，没有人尝试对法学硕士中的序列复制进行定量研究，而只是定性研究。然而，生物信息学提供了序列同一性解决方案，例如加权编辑距离或编辑距离，以评估模型是否生成与已知毒力的序列相似的序列。</p><p>然而，编辑距离本身是不够的，尤其是在台式 DNA 合成和组装设备起飞后。由于缺乏针对合成公司的筛选标准或法规，目前尚不清楚公众可以期望什么程度的保护。虽然至少<a href="https://www.frontiersin.org/articles/10.3389/fbioe.2022.860390/full">存在</a>针对合成步骤的建议，但需要更仔细地考虑可以预期的基于合成的攻击类型。</p><h3>开放式任务</h3><p>确定如何最好地衡量法学硕士在更多开放式任务上的能力仍有待完成。</p><p>例如，评估模型生成炭疽孢子形成方案的能力很难使用多项选择题来衡量。一个潜在的策略是<a href="https://arxiv.org/pdf/2310.10632.pdf"><u>Bioplanner</u></a> ，它让法学硕士使用一组提供的库函数以 Python 伪代码重写生物协议。例如，指令“在液氮存在下使用研钵和杵研磨 0.5-2 克组织”将成为函数调用</p><pre><code>grind_tissue( tissue_weight=&quot;0.5-2 g&quot;, grinding_method=&quot;mortar and pestle with liquid nitrogen&quot; )</code></pre><p><br>然后评估模型编写的协议被分解为一组子问题，例如模型是否为每个步骤分配了正确的函数（作为准确率百分比），函数参数名称是否正确（精度或<a href="https://en.wikipedia.org/wiki/BLEU"><u>BLEU</u></a>分数），使用余弦相似度（ <a href="https://arxiv.org/abs/1903.10676"><u>SciBERT 分数</u></a>）等来判断参数值是否正确。</p><p>虽然余弦相似度和 BLEU 分数是经过充分研究的测量自然语言处理保真度的策略，但这种组合方法的一个弱点是 Bioplanner 的作者仅对其方法产生的 LLM 生成的协议进行了有限的实验验证。可能不仅需要对这种方法进行进一步的研究，而且还需要广泛地改进开放式评估。</p><h2>评估安全问题</h2><p>值得讨论的一个关键安全问题涉及此类评估数据集的发布。评估的发布可能本质上会破坏它们（另请参阅<a href="https://en.wikipedia.org/wiki/Goodhart%27s_law"><u>古德哈特定律</u></a>），并且希望尽可能长时间地保持测试集与训练集分开的完整性。</p><p>此外，生物安全领域的双重用途评估可能同时成为生物恐怖主义的手段。即使特定的评估仅与非军事的、相当良性的生物制剂相关，它与生物安全数据集的联系也会使武器制造中涉及的设计模式变得清晰。</p><p>一种选择是根据<a href="https://www.anthropic.com/index/anthropics-responsible-scaling-policy"><u>AI 安全级别 (ASL)</u></a>或上述<i>关注级别</i>列来保护评估，尽管分阶段发布并不能避免暴露 BW 设计模式的问题。</p><h2>评估类别</h2><p>有必要产生至少两个独立的分数：</p><ol><li><strong>双重用途技术能力：</strong>可以武器化的民用、良性和建设性用途。</li><li><strong>武器化安全措施：</strong>对民用应用有限的主题进行模型干预。</li></ol><p>在前一种情况下，我考虑模型技术能力，不受模型安全措施的干扰；在第二个中，我衡量由安全措施调节的技术能力。</p><p>鉴于现有安全措施的漏洞，技术能力是这两个指标中更重要的一个。因此，大多数评估应该集中于文明的、良性的或建设性的用例，而不是有害的用例。</p><p>虽然对<i>鼠疫耶尔森氏</i>菌（引起鼠疫的细菌）的评估很好地证明了潜在的缺点，但对非致病性类似<i>耶尔森氏菌的</i>类似评估更好地反映了生物技术知识的双重用途性质，并且不太可能触发模型安全措施（例如基于列入黑名单的关键字或主题）。以非武器用例为中心的一个有益的副作用是，在评估数据集泄露的情况下，我们没有泄露任何实施生物恐怖主义的方法。</p><p>迄今为止，模型安全措施的执行情况还不均衡，而成绩单可以帮助平衡执行情况。截至几周前，克劳德拒绝回答我提出的某些与炭疽相关的问题，但当我向其提供有关该主题的论文时，他屈服了。然而，充分询问安全措施本身就是一场军备竞赛——在这种情况下是我们的评估和模型之间的竞赛——并且可能是一项工作密集型任务。</p><h2>工作范围</h2><p>为了提供必须编写的评估数量的粗略数量级，让我们考虑澳大利亚集团通用控制列表。生物武器分为三类：两用生物设备、人畜病原体及毒素、植物病原体。动物病原体清单中有58种病毒、22种细菌、2种真菌以及21类毒素和毒素亚基。 “警告清单”上还有其他 5 种细菌和另外 2 种真菌，但不受特别出口管制。目前，我们假设毒素源位于控制列表中的其他位置（例如列表中的细菌或真菌）。我们还剩下 89 种病原体。</p><p>对于每种细菌，我们可能会考虑与收集、安全措施、消毒策略、宿主生物体、培养基、生长条件、孢子形成（如果适用）、制备（例如冻干）、储存、动物测试、毒素产生（如果适用）相关的评估，和缓解措施。</p><p>我估计我们可以编写约 100 个小样本示例，并使用这些示例让法学硕士编写十到一百倍的多项选择评估。答案需要手工检查。此外，还需要做更多的工作来制定开放式评估的策略，以及进行这些评估的时间。</p><p>最后，外部性最终将促使合成生物学评估以及与生物设计工具相关的评估的增加。其他人已经对许多应该调查的设计工具类别进行了<a href="https://www.longtermresilience.org/post/report-launch-examining-risks-at-the-intersection-of-ai-and-bio">编目</a>。</p><h1>基于网络的两用生物技术前沿模型成绩单</h1><p>这份成绩单的目的是让公众意识到前沿模型的影响并创造一种问责文化。它的灵感来自已故的彼得·埃克斯利（Peter Eckersley），他构建了<a href="https://www.wired.com/story/peter-eckersley-ai-objectives-institute/">“听起来简单的工具，可以作为实现深刻变革的杠杆”</a> （安迪·格林伯格的话，而不是彼得的话），例如电子前沿基金会的<a href="https://www.eff.org/observatory">SSL 天文台</a>。</p><p>初始版本应调查 ChatGPT 和 Claude，并包含其他语言模型作为后续工作。大多数不在这一目标范围内的是围绕生物武器的社会工程和错误信息威胁模型，尽管稍后可能会在有足够资源的情况下将其包括在内。然而，重要的是，模型的技术评估有助于我们了解参与者如何使用明显的技术知识来建立社会工程威胁模型的可信度。</p><p>最终还应该在成绩单中对外部性进行调查。例如，我们能否标记 DNA 合成能力或蛋白质设计工具的突然改进？随着多模式和法学硕士工具的使用变得更加稳健，这些外部性变得更加重要。</p><p>最后，报告卡应包括对每种双重用途技术能力的成本和收益的数量级估计，类似于本文开头的<i>炭疽芽孢杆菌</i>和<i>苏云金芽孢杆菌</i>的例子。如果成绩单的目标是向政策制定者和安全专业人士提供信息，就需要将潜在危害与潜在好处结合起来，特别是考虑到生物技术的深远效用。</p><h1>结论</h1><p><a href="https://1a3orn.com/sub/essays-propaganda-or-science.html">一些人认为</a>，除了互联网访问之外，生成模型不会构成任何威胁。对于目前可用的模型，我同意。然而，在道德上扩大规模要求我们考虑如何更好的模型可以减少生物武器和其他类型伤害的进入壁垒。几乎所有人都同意，生成式人工智能将对社会产生广泛的影响，如果它还没有产生这样的影响的话。</p><p>安全保障措施通常被描述为<a href="https://en.wikipedia.org/wiki/Swiss_cheese_model"><u>瑞士奶酪</u></a>片<u>。</u>每层都有孔，但目标是防止孔对齐。如果没有指标，就不清楚漏洞可能在哪里，以及应该添加哪些额外的切片。切片的例子包括结构化访问、滥用检测和更传统的公共卫生缓解措施，例如增加基础研究资金、罕见疾病疫苗、抗病毒药物、抗生素、检测分析和大流行病监测。</p><p>在本文中，我描述了生物技术、安全和前沿机器学习模型交叉领域的一些关键问题，特别是减轻生物恐怖主义的成本和难度，以及建设性生物医学和生物技术创新的巨大效用。我向读者介绍了双重用途的概念。接下来，我描述了大型语言模型的鲁棒性不安全性。</p><p>我将攻击面分为三种威胁模型：技术、社会工程和错误/虚假信息。我重点关注技术威胁模型，一方面是因为技术攻击的直接危害，另一方面是因为通过了解技术能力而深入了解了社会工程威胁模型，并解释了为什么错误信息和宣传威胁特别具有挑战性。</p><p>我研究了一些可用于研究技术威胁模型的现有指标——特别是封闭式和开放式“评估”——并表达了对这些评估的发布的一些安全担忧。我解释了为什么需要两个指标，一个与民用技术能力相关，另一个则着眼于通过内置安全措施调节的有害能力。我建议将这些内容包含在基于网络的成绩单中，旨在围绕模型影响建立透明度和问责制。</p><h2>呼吁采取行动</h2><p>我正在研究这个问题，但目前是一名没有资金支持的独立研究员。这项工作可以通过三种方式完成：</p><ol><li>一些研究组织接手了我的工作并挖走了我（这比不完成要好）；</li><li>其他人自愿帮助我完成这项工作；或者</li><li>有人为我提供资金让我全职从事这项工作。</li></ol><p>请随时与<a href="https://linktr.ee/translunar">我们联系</a>。您还可以通过<a href="https://www.patreon.com/translunar_injection">Patreon</a>支持我的工作。</p><h1>致谢</h1><p>我要感谢 Jonathan Stray、 <a href="https://www.lesswrong.com/users/cmck?mention=user">Colleen McKenzie</a> 、Julia Bossmann、Andy Ellington 和 Becky Mackelprang 进行了有益的对话；以及 Ian Baker、Jef Packer、 <a href="https://www.lesswrong.com/users/liracle?mention=user">Lira Skenderi</a>和<a href="https://www.lesswrong.com/users/rif-a-saurous?mention=user">Rif A. Saurous</a>审阅草稿。</p><br/><br/> <a href="https://www.lesswrong.com/posts/YAFq9W8hoJsqqCbn3/a-call-for-a-quantitative-report-card-for-ai-bioterrorism#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/YAFq9W8hoJsqqCbn3/a-call-for-a-quantitative-report-card-for-ai-biochemistry<guid ispermalink="false"> YAFq9W8hoJsqqCbn3</guid><dc:creator><![CDATA[Juno]]></dc:creator><pubDate> Mon, 04 Dec 2023 06:35:14 GMT</pubDate> </item><item><title><![CDATA[Disappointing Table Refinishing]]></title><description><![CDATA[Published on December 4, 2023 2:50 AM GMT<br/><br/><p><span>桌上的剃须膏：雨天的好孩子活动，对吗？</span></p><p> <a href="https://www.jefftk.com/table-with-shaving-cream-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Skq5xA7Jm27xxHpQe/kvxkgv8wwrnxndanr6xy" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Skq5xA7Jm27xxHpQe/kvxkgv8wwrnxndanr6xy 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Skq5xA7Jm27xxHpQe/whznr6kpphmetl99wby4 1100w"></a></p><div></div><p></p><p>不幸的是，事实证明我们的桌子表面是可溶于酒精的，用高酒精泡沫覆盖几个小时对它来说并不好：</p><p> <a href="https://www.jefftk.com/definished-table-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Skq5xA7Jm27xxHpQe/z4bvmf4e7eluuk0afskf" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Skq5xA7Jm27xxHpQe/z4bvmf4e7eluuk0afskf 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Skq5xA7Jm27xxHpQe/yy2l3sm8woegfckym47p 1100w"></a></p><div></div>我制作的中心叶子是聚氨酯，但我们认为原始部分可能是虫胶。<p></p><p>最初，我们在上面铺上塑料布（手头上总是有额外的塑料布！）以保护其免受进一步损坏：</p><p> <a href="https://www.jefftk.com/plastic-covered-table-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Skq5xA7Jm27xxHpQe/l4bvo1jents5lpdpmthp" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Skq5xA7Jm27xxHpQe/l4bvo1jents5lpdpmthp 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Skq5xA7Jm27xxHpQe/hyh4nfwkpksf3y0gwib5 1100w"></a></p><div></div><p></p><p>我查阅了如何制作虫胶表，买了虫胶片和酒精，并混合了一些 1.5 磅的东西。我用砂纸打磨了受损的表面，使其光滑，但并没有试图完全去除它。我涂了大约 5 层虫胶，让它们在它们之间干燥过夜，并在白天用塑料覆盖，这样桌子仍然可以使用。</p><p> <a href="https://www.jefftk.com/reshellaced-table-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Skq5xA7Jm27xxHpQe/jimlenwez4bkvd4jlmr4" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Skq5xA7Jm27xxHpQe/jimlenwez4bkvd4jlmr4 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Skq5xA7Jm27xxHpQe/jggegpoxyqftnzvjla22 1100w"></a></p><div></div><p></p><p>不幸的是，它并没有真正发挥作用：每天晚上，当我再涂一层时，塑料上都会出现一些饰面。即使一个多月后，它也没有完全治愈：当我们将热腾腾的晚餐盘放在软木三脚架上时，用餐结束时，桌子上会粘上一些软木塞。它对刮擦和其他损坏的抵抗力也比原来的表面要差得多。</p><p> <a href="https://www.jefftk.com/table-with-sad-finish-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Skq5xA7Jm27xxHpQe/muirxyshi96oqocdewld" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Skq5xA7Jm27xxHpQe/muirxyshi96oqocdewld 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Skq5xA7Jm27xxHpQe/zrbizdms63wyvhjyjhxe 1100w"></a></p><div></div><p></p><p>目前我们只是忽略它，但有一天我想正确修复它。也许我会剥掉整个表面并涂上聚氨酯？建议？</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid0rGy1ArUMbGKY1SPJn2cC2hHLNVJQi5yGgG3T7vkwCJavwcsuqL1EQDFfdSmFtck1l">facebook</a> , <a href="https://mastodon.mit.edu/@jefftk/111519860017538285">mastodon</a></i></p><br/><br/> <a href="https://www.lesswrong.com/posts/Skq5xA7Jm27xxHpQe/disappointing-table-refinishing#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Skq5xA7Jm27xxHpQe/disappointing-table-refinishing<guid ispermalink="false"> Skq5xA7Jm27xxHpQe</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Mon, 04 Dec 2023 02:50:08 GMT</pubDate> </item><item><title><![CDATA[the micro-fulfillment cambrian explosion]]></title><description><![CDATA[Published on December 4, 2023 1:15 AM GMT<br/><br/><p>仓库自动化非常成功。<a href="https://www.youtube.com/watch?v=-sMCFae-Yhg">这是</a>一个典型的现代系统。正如您所看到的，一个又高又窄的机器人骑在顶部和底部的单个轨道上。链接的示例高度高达 42m。物品存放在托盘顶部，机器人有一个伸缩叉，可以处理 2 深的托盘，以提高空间效率。</p><p>商店的自动化程度比仓库低得多。当你去沃尔玛、阿尔迪或宜家时，他们的后面通常没有机器人——更不用说较小的商店了。现在有许多公司销售适用于较小物品和较小空间的自动化系统。这就是所谓的微履行，以下简称“MF”。</p><p>有许多不同的配置正在开发和销售，这表明人们尚未找到最佳方法。以下是我所知道的一些方法。</p><hr><p><a href="https://www.youtube.com/watch?v=tgWkQC3_b30"><strong>基瓦/亚马逊</strong></a></p><ul><li>机器人从下方提升整个机架，方法是在机架下方行驶，然后在转动<a href="https://en.wikipedia.org/wiki/Ball_screw">滚珠丝杠</a>升降机的同时旋转。货架被运送到人工拣货员处，人工拣货员通常会转移多个物品。该系统由Kiva开发，被亚马逊收购并更名；它现在有几个克隆。</li></ul><p> <a href="https://robohub.org/meet-the-drone-that-already-delivers-your-packages-kiva-robot-teardown/">这是 2016 年的拆解</a>。Kiva 设计存在一些问题：</p><ul><li>对于一个部件来说，大型滚珠丝杠组件有点昂贵。</li><li>搬运货架的机器人头重脚轻，无法快速加速。</li><li>货架的高度受到工人可触及的范围的限制，从而限制了存储密度。</li><li>工人每天必须多次伸手拿取高处或接近地面的物品。适度的这种情况并不是什么大问题，但亚马逊工厂的工人需要经常这样做，这会增加受伤率。</li></ul><hr><p><a href="https://www.youtube.com/watch?v=p5c0MjvSu2w"><strong>极客+ RoboShuttle</strong></a></p><ul><li>电梯机器人具有齿轮齿条驱动的电梯，可提升旋转平台。该平台有一个抓取器，可以到达手提箱的侧面并将它们滑到电梯上。电梯可以将手提箱推到固定的存储槽上，这样它就可以在一次行程中抓取多个手提箱。</li><li>搬运机器人有一组固定高度的动力滚轮。手提箱可以在它们和电梯机器人之间转移。</li></ul><p><a href="https://www.youtube.com/watch?v=iHC9ec591lI"><strong>自动存储</strong></a></p><ul><li>机器人行驶在存储立方体顶部的轨道上。它们有 2 组可以在之间切换的轮子。每个机器人都有一个升降系统，可以从上方提升/降低手提箱。深部物品被挖出，将手提袋提升并转移到它们上方，直到可用为止。</li></ul><p><a href="https://www.youtube.com/watch?v=a6FsgehhkyA"><strong>警报创新</strong></a></p><ul><li>机器人有多组轮子，可以在地板上行驶、在轨道上行驶以及在轨道上垂直移动。 “无电池”可能意味着他们使用超级电容器。</li></ul><p><a href="https://www.youtube.com/watch?v=bUyhjqvY_4Y"><strong>子酷</strong></a></p><ul><li>每层平面机器人从下方抬起托盘并水平移动它们。它们有 2 组可以在之间切换的轮子。</li><li>垂直伸缩叉车从楼层边缘提升托盘。平板机器人将托盘运至/运出。</li></ul><p> <a href="https://www.youtube.com/watch?v=XWlQWgRfh6c"><strong>Brightpick 自动挑选器</strong></a></p><ul><li>机器人在一个由皮带传动提升的平台上携带 2 个手提袋，机械臂位于它们之间以转移物品。平台上的 2 个手提箱槽配有滚轮和一个带有真空夹具的滚动抓取器，用于移动手提箱。</li></ul><p> <a href="https://www.youtube.com/watch?v=SMRAtCLF_ts"><strong>Brightpick 调度员</strong></a></p><ul><li>与 Brightpick Autopicker 类似，但有 1 个手提袋且没有机械臂。</li></ul><p><a href="https://www.youtube.com/watch?v=LL0QzAMFYZc"><strong>埃克索泰克</strong></a></p><ul><li>机器人可以在地板上行驶并抓住导轨垂直移动。爬到正确的高度后，他们使用伸缩叉来转移手提包。</li></ul><p><a href="https://www.youtube.com/watch?v=0UHduc6UeEo"><strong>德马泰克多班车</strong></a></p><ul><li>电梯通过滚轮将手提箱提升到装载/卸载区域。</li><li>每层穿梭机器人水平搬运手提箱。它们使用一组轮子在轨道上行驶，并具有伸缩臂，可以从侧面抓住或推动手提包。</li></ul><hr><p>那么，MF的进展如何呢？</p><p>我的理解是，大多数零售商一直采取犹豫的态度。他们主要是在等待其他人通过某种系统展示经济成功，或者进行一个小型试点项目，看看效果如何。</p><p>那么，这些试点项目的经济效益如何？我的理解是，他们成功地将挑选特定商品的劳动力需求减少了 1/2 至 2/3，但比将商品推到货架上并让顾客自行购物的传统方法更昂贵。 （您必须仔细查看 MF 的销售材料。例如，宣传册有时会将节省的劳动力与购买成本进行比较，但 MF 系统也可能具有大量的维护成本和每个项目的软件许可费用。）</p><p><a href="https://digitalcommons.georgiasouthern.edu/pmhr_2023/21/">一项研究得出的结论是</a>，（客户在线购物、MF 商品提货和商店取货）每件商品的成本为 1.52 美元，而传统购物（整个物流链）的成本为 0.96 美元，但 MF 系统比其他在线订单方式便宜。是的，公司从顾客拿走他们的商品中获得了“免费劳动力”，但网上购物也需要时间，并且能够亲自检查产品有一些优势。</p><p>因此，如果 MF 系统不占用正常补货过程所用的空间，或者如果大多数订单都是在线进行的，那么 MF 系统可能会更好。</p><p>抓取物品是一项常见任务，对 MF 系统的分析是估算小型机器人其他可能应用的成本的有用起点。需要对机器人所需的复杂度、机器人利用率、任务完成速度等进行一些调整，但这比从第一原理开始要容易。</p><p>假设有一家餐厅，为厨师储存了许多食材。借助现代 Transformer 系统，厨师可以口头请求某件物品，神经网络可以将该音频转换为文本，找出所请求的物品和任务，并指导机器人抓取装有正确物品的手提包。从 MF 系统成本推断，这种自动化每次（存储 + 获取）可能为 0.20 美元到 1 美元，具体取决于利用率、行程距离等。假设工人每小时花费 30 美元，则必须节省 24 到 120 秒的劳动力per (storage + fetch) 具有潜在的价值。</p><p>一些餐馆<a href="https://www.youtube.com/watch?v=tJaj3_54S_E">现在使用</a>自动手推车为顾客运送餐点。这些机器人在机械上显然比拣选机器人更简单，但它们确实必须在比仓库更不可预测的环境中行驶。与配料挑选机相比，它们的利用率也可能更高。</p><hr><p>在工厂里，机器人经常做一些人类无法快速完成或根本无法完成的事情，并且经常连续运行。当你开始考虑在控制较少的环境中取代人类时，这些任务总是人类可以做得足够好的事情，而且它们比在装配线上完成的连续性要少。</p><p>洗碗机和洗衣机大部分时间都没有使用，而且每次使用的费用也不是特别昂贵。问题是拣选机器人的购买成本可能高出 100 倍，而且运营成本也更高。这与汽车的成本相当，但总的来说，汽车并不是一个很好的比较：与其他机器相比，由于其复杂性和功率输出，它们的成本异常便宜，因为汽车每年的制造成本为一万亿美元。一个机械臂的成本也比一辆汽车还要高。</p><p>如果机器人采摘机设计得更好并批量生产，成本是否可以大幅降低？是的，我想是的，但我认为它们仍然是数千美元。假设一个拣货机器人的运行时间为 2 年，成本为 5,000 美元，并且在一家餐厅每年 2000 小时每小时提供 10 次拣选服务，那么每次拣选的成本为 0.25 美元。</p><br/><br/> <a href="https://www.lesswrong.com/posts/4gQjEvQt7oByfYHNH/the-micro-fulfillment-cambrian-explosion#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/4gQjEvQt7oByfYHNH/the-micro-fulfillment-cambrian-explosion<guid ispermalink="false"> 4gQjEvQt7oByfYHNH</guid><dc:creator><![CDATA[bhauth]]></dc:creator><pubDate> Mon, 04 Dec 2023 01:15:34 GMT</pubDate></item></channel></rss>