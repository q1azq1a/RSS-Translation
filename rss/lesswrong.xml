<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 6 日星期一 00:54:44 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[When and why should you use the Kelly criterion?]]></title><description><![CDATA[Published on November 5, 2023 11:26 PM GMT<br/><br/><p>这是<a href="https://www.lesswrong.com/events/BJcNeJss4jxc68GQR/online-dialogues-party-sunday-5th-november">在线对话聚会</a>时的对话。 Phil、River 和我（Garrett）讨论了凯利准则。我错误地认为，即使没有折扣因素，它也会出现在有限游戏中。事实证明这是错误的！在此类投注游戏中，您总是希望投注最大金额（假设金钱的线性效用）。</p><p>然后我们讨论了如何在不引入货币对数效用或无限游戏中的折扣率的情况下保存该标准。这两个结论是，你要么拥有有限的效用函数，要么本质上关心不破产/最大化比你世界中的其他代理人获得更多钱的可能性。</p><p>我认为最重要的是，在使用动态规划试图证明 Phil 是错误的之后，我改变了对有限游戏的看法。我们提出的证明对我来说既令人惊讶又优雅。</p><h2>凯利的可能理由</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:13:39 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:13:39 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>所以，我之前在 LessWrong 上看到过一些关于凯利准则的解释，它们似乎分为 3 类：</p><ol><li>你采用凯利准则是因为你对货币有对数效用。</li><li>您执行凯利准则是因为您的货币具有线性效用，但您可以使用当前的货币在未来获得更多收益。</li><li>您采用凯利标准是因为您部分更新了市场头寸。 </li></ol></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:13:49 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:13:49 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>对我来说，这里的一些背景是我之前写过<a href="https://www.lesswrong.com/posts/XnnfYrqaxqvirpxFX/on-kelly-and-altruism">https://www.lesswrong.com/posts/XnnfYrqaxqvirpxFX/on-kelly-and-altruism</a>和<a href="https://www.lesswrong.com/posts/JAmyTWoukk8xzhE9n/ruining-an-expected-log-money-maximizer">https://www.lesswrong.com/posts/JAmyTWoukk8xzhE9n/ruining-an -expected-log-money-maximizer</a> ，他们没有得到太多业力，我不知道这是“他们有问题”还是“他们没有被太多人看到”或者什么</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:15:09 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:15:09 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><blockquote><p>你采用凯利准则是因为你对货币有对数效用。</p></blockquote><p>这个我觉得很复杂；我会说“你做了一件等同于凯利准则的事情，但其原因比推导凯利准则的原因更简单” </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:16:08 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:16:08 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><blockquote><p>您执行凯利准则是因为您的货币具有线性效用，但您可以使用当前的货币在未来获得更多收益。</p></blockquote><p>在这种情况下，我会说不，如果你实际上在金钱上有线性效用，你应该在我见过的大多数/所有游戏结构中每次都下注；这会导致明显错误的行为，但那是因为货币的线性效用显然是错误的</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:17:08 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:17:08 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><blockquote><p>您采用凯利标准是因为您部分更新了市场头寸。</p></blockquote><p>我想我没见过这个，虽然我猜分数凯利会是这个？在我的头脑中纯粹的凯利就是“市场这么想，我这么想，两者的区别在于我能在多大程度上赢得市场” </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:18:33 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:18:33 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>我想我在这里要明确说明的一件事（部分重述了上面的内容）是，我认为如果你有一个效用函数，你就不需要将凯利带入事物中。如果你的效用函数是对数，那么你所做的事情结果相当于凯利，但派生更简单。凯利的推导方式，在我看来，它给你的东西与优化效用函数只是不同的东西</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:19:07 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:19:07 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><blockquote><p>在这种情况下，我会说不，如果你实际上在金钱上有线性效用，你应该在我见过的大多数/所有游戏结构中每次都下注；这会导致明显错误的行为，但那是因为货币的线性效用显然是错误的</p></blockquote><p>在大多数现实世界的情况下这是错误的？您能在这里举一些具体的例子吗？就像，在扑克中你有这种动力，在投资中你有这种动力，在投注中你有这种动力，在做出人生决定时你有这种动力，等等。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:20:32 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:20:32 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>嗯，我承认我没有考虑太多现实场景，我的想法是我想先找出简单的例子。因此，我脑海中的简单例子是经典的“您可以在 60/40 的机会下注任意金额，使您的赌注翻倍”，然后我声称，对于线性效用，您每次都应该下注一切。你不同意吗？</p></div></section><h2>菲尔用词的方式很奇怪吗？ </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:23:45 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:23:45 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><blockquote><p>我想我在这里要明确说明的一件事（部分重述了上面的内容）是，我认为如果你有一个效用函数，你就不需要将凯利带入事物中。如果你的效用函数是对数，那么你所做的事情结果相当于凯利，但派生更简单。凯利的推导方式，在我看来，它给你的东西与优化效用函数只是不同的东西</p></blockquote><p>这对我来说似乎是一个奇怪的说法？就像，我可以告诉您有关优化线性规划问题的单纯形算法，并使用相同的逻辑，您可以回到我身边，并告诉我单纯形算法并不那么有趣，因为您正在做的真正事情是优化线性约束下的线性函数，并且您正在优化的线性函数不必是效用函数，它可以是任何东西。而且约束不一定是物理的，它们也可以是社会的约束，甚至是所谓的效用函数的一部分。</p><p>尽管这是事实，但对我来说这感觉很奇怪。对我来说，似乎在很多情况下你想要使用单纯形算法，而在很多情况下你想要使用凯利赌注公式</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:24:58 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:24:58 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><blockquote><p>嗯，我承认我没有考虑太多现实场景，我的想法是我想先找出简单的例子。因此，我脑海中的简单例子是经典的“您可以在 60/40 的机会下注任意金额，使您的赌注翻倍”，然后我声称，对于线性效用，您每次都应该下注一切。你不同意吗？</p></blockquote><p>是的，我确实不同意这一点。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:26:05 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:26:05 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>好吧，实际上，如果你收到很多这种形式的赌注，那么使用凯利就变得明智了，而不是一直赌所有东西。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:28:11 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:28:11 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>我不确定我是否明白你所描绘的联系，所以我可能会尝试更清楚地说明我提出这一主张的原因。因此，如果我有一个对数效用函数，我可以做“最大化我的预期效用的下注金额是多少”，这是一个相对简单的计算，并且它简化为等于凯利公式的公式。尽管凯利准则的推导方式是获得相同公式的更为复杂的方式，但它不涉及最大化对数效用。或者就像，可能在幕后它是通过深刻的数学等价或其他东西来做到这一点的。但无论如何它比“最大化我的预期日志效用”更复杂</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:28:43 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:28:43 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>是的，它的推导方式是通过数字 2，对吧？你有一种情况，你想在这种情况下最大化你的效用，而你这样做的方式就是凯利</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:29:14 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:29:14 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>#2 是“你采用凯利标准是因为你的金钱具有线性效用，但你可以使用当前的金钱在未来获得更多收益。”？我不会这么说；如果我没记错的话，它最初的推导方式是定义一个称为“增长率”的东西，然后尝试最大化它</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:30:25 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:30:25 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>其中增长率类似于 lim (n->;∞) of 1/n log（n 时的财富 / 0 时的财富）。这是随机变量的极限，但这很好，因为在极限内你会得到一个随机变量，它以概率 1 呈现特定值</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:30:28 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:30:28 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>看看维基百科页面，你在谈论伯努利的证明吗？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:30:44 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:30:44 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><blockquote><p><a href="https://en.wikipedia.org/wiki/Daniel_Bernoulli">丹尼尔·伯努利 (Daniel Bernoulli)</a>在 1738 年的一篇文章中建议，当人们可以选择下注或投资时，应该选择结果几何<a href="https://en.wikipedia.org/wiki/Geometric_mean">平均值</a>最高的选项。这在数学上等同于凯利准则，尽管动机不同（伯努利想要解决<a href="https://en.wikipedia.org/wiki/St._Petersburg_paradox">圣彼得堡悖论</a>）。 </p></blockquote></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:31:08 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:31:08 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>我不这么认为——我从我认为的原始论文中得到了这个（这是从信息论的角度出发的）</p></div></section><h2>在有限游戏中你应该每次都下注吗？ </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:32:22 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:32:22 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>嗯，退一步 - 我认为这个帖子是“我是不是以一种奇怪的方式说了什么”，对吧？如果您愿意，很乐意继续，但我们可能更愿意切换到“您应该每次都下注吗”主题</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xEjYKycvoJSWWfKE7-Sun, 05 Nov 2023 21:33:49 GMT" user-id="xEjYKycvoJSWWfKE7" display-name="River" submitted-date="Sun, 05 Nov 2023 21:33:49 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>河</b></section><div><p>我对使用凯利的原因的理解可能与#2有关，但可能有所不同，那就是如果你比凯利下注更积极，你会得到越来越多的预期资金，集中在可能世界中越来越小的碎片中。极端地说，你在可能世界的无限小部分中获得了无限的美元，这意味着你获得了 0 美元，因此效用为 0。无论你的效用函数是对数函数、线性函数还是其他函数，这都是事实。除非 0 美元对你来说是一种积极的效用状态，在这种情况下，我想你可以随心所欲地下注。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:34:08 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:34:08 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>我的意思是，显然你不应该每次都赌上一切</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:34:40 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:34:40 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><blockquote><p>极端地说，你在可能世界的无限小部分中获得了无限的美元，这意味着你获得了 0 美元，因此效用为 0。</p></blockquote><p>所以我声称这是在以一种不允许的方式做无穷大：p 在这种情况下，“无限美元的概率 0”比“0 效用”更“未定义” </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xEjYKycvoJSWWfKE7-Sun, 05 Nov 2023 21:35:45 GMT" user-id="xEjYKycvoJSWWfKE7" display-name="River" submitted-date="Sun, 05 Nov 2023 21:35:45 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>河</b></section><div><blockquote><p>我的意思是，显然你不应该每次都赌上一切</p></blockquote><p>你不必在任何时候都赌上一切来得到这个结论，你只需比凯利告诉你的赌注更多即可。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:36:08 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:36:08 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><blockquote><p>我的意思是，显然你不应该每次都赌上一切</p></blockquote><p>所以如果我们有一个有限游戏，我想你会同意你应该这样做吗？比如，有 100 轮，您最终有 0.6^100 的机会获得原始赌注的 2^100 倍，其余时间您的赌注为零，这是根据线性效用函数所能做到的最好结果。同意？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:36:22 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:36:22 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><blockquote><p>...有限游戏...</p></blockquote><p>我猜你会做一些更复杂的事情，因为早期的投注会影响你在以后的投注中可以赚多少钱，但后来的投注没有这个属性。您应该在后面的投注中投注很多，但在之前的投注中不要投注很多。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:36:48 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:36:48 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><blockquote><p>你不必在任何时候都赌上一切来得到这个结论，你只需比凯利告诉你的赌注更多即可。</p></blockquote><p> （这真的是“更多吗？”如果是这样，我会感到惊讶，但我不认为这对我来说是任何问题的症结所在） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:38:22 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:38:22 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><blockquote><p>我猜你会做一些更复杂的事情，因为早期的投注会影响你在以后的投注中可以赚多少钱，但后来的投注没有这个属性。您应该在后面的投注中投注很多，但在之前的投注中不要投注很多。</p></blockquote><p>我不这么认为；我认为数学（在这个玩具示例中）确实可以解决最终优化预期资金的问题，您只需每次都下注全额</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:39:10 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:39:10 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><blockquote><p>所以我声称这是在以一种不允许的方式做无穷大：p 在这种情况下，“无限美元的概率 0”比“0 效用”更“未定义”</p></blockquote><p>一般来说，无限的实用程序在很多不同的方面都是超级糟糕的。因此，当我想到“无限效用”时，我想到的只是一个天文数字般巨大的效用，无论你的效用有多大，我们仍然得到 River 的结论。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:39:59 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:39:59 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>我同意如果效用仅限于天文数字那么事情就不同了</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:42:01 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:42:01 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>嗯，所以我认为这里发生的一件事是，你将其建模为“你玩这个游戏，你可以想玩多久就玩多久，可能永远玩下去，然后你以某种概率分布完成游戏超越金钱，无论你玩了多久”。或者其他的东西？但是就像，如果你可以永远玩下去，凯利会给你无限的钱，但“每次下注分钟（凯利，$1）”也是如此</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:42:32 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:42:32 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>那是个很好的观点。我就是这样建模的。我不知道以不同的方式建模（例如使用折扣率）是否会产生如此不同的结果？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:43:13 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:43:13 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>因此，我想要添加到模型中的不是折扣率，而是“在玩游戏时，此时我有多少效用？”比如，在时间步长 100 时，我的效用是什么样的？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:44:54 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:44:54 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>因为如果游戏永远持续下去，然后停止......我真的不知道如何处理结果。有很多方法可以在这个限制内获得无限的金钱，并且有一种方法可以让凯利函数给你一个更高的无穷大，但这很奇怪</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:44:56 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:44:56 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>是的，在这种情况下我会在这里指出我的答案</p><blockquote><p>我猜你会做一些更复杂的事情，因为早期的投注会影响你在以后的投注中可以赚多少钱，但后来的投注没有这个属性。您应该在后面的投注中投注很多，但在之前的投注中不要投注很多。</p></blockquote><p>当你停止时增加，你就会接近凯利。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:45:10 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:45:10 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>也许我只是错了</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:45:46 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:45:46 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>是的，我仍然不同意这一点。嗯，我们可以尝试进行数学计算，但我不知道对话框格式对此有何帮助。我想我们至少可以做乳胶</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:46:17 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:46:17 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>这不是很有帮助，我以前尝试过类似的事情，而且这些都很困难，尽管我在进去之前已经知道我想要做的证明，如果我有白板，5 分钟内就能完成。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:46:21 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:46:21 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>点头</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:48:42 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:48:42 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>我想，我们可以对小 n 进行证明，而不是提出证明，然后看看会发生什么？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:48:49 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:48:49 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>是的</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:51:13 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:51:13 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>好的，对于一次抛硬币，您只能选择一个值。假设您从 1 英镑开始，下注 £ <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>，最终得到 ( <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="1 + W_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> ) 的 60% 和 ( <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="1 - W_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> ) 的 40%（通过最大化<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span>来最大化） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 21:52:09 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 21:52:09 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>对于两个，你会得到两个值，当我过去处理这个问题时，我可能假设它们必须是相同的分数，但事实并非如此。实际上，它们甚至不必是相同的分数，具体取决于您是否获胜，因此您可以下注三个值</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 21:59:56 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 21:59:56 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>好吧，采用动态规划方法，我们可以假设您上次下注时，您下注了所有资金，最终得到<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W_T = W_{T-1}+ 0.2B_T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.2</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">B</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span> ，其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W_t"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span></span></span></span></span></span></span></span>是您在时间<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="t"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span></span></span></span></span></span>时的财富， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="B_t"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">B</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span></span></span></span></span></span></span></span>是您在时间<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="t"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span></span></span></span></span></span>下注的金额。您的赌注必须是您财富的一小部分，因此我们可以将<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W_T = W_{T-1} + 0.2W_{T-1}f_T = W_{T-1} ( 1 + 0.2f_T)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">其</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">重写</span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">为</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">WT</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">=</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">WT</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">−</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">1</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">+</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">0.2</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">WT</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.06em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">WT</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">−</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">1</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">(</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">1</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">+</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">0.2</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">f</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.06em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">T</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">)</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">，</span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W_T = W_0(1 + 0.2f_1)\cdots (1+0.2f_T)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">因此</span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">WT</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">=</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">W</span></span></span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.2</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.06em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋯</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.2</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.06em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。嗯...这实际上意味着我们要为所有事情选择最大<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f_i = 1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.06em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span> ，因为乘法是与顺序无关的... </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:00:28 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:00:28 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>是啊！是的，这个论点对我来说似乎是正确的（并给出了我已经预料到的结论，所以确认偏差：p） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 22:02:28 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 22:02:28 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>狂野，好吧。我想你已经让我相信了这一点</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:03:18 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:03:18 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>我想类似的论点是，假设我们即将做出最后的赌注。我们已经确定，无论我们目前有多少钱（假设是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="V_{N-1}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.186em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span></span></span> ，我们想赌上一切），都可以在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="E(V_N) = 1.2 V_{N-1}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.186em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1.2</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.186em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span></span></span>处最大化预期<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="V_N"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.186em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span></span></span></span></span></span></span></span> ，然后通过归纳法我们通过将所有财富也押在该赌注上来最大化<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="E(V_{N-1})"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.186em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:03:52 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:03:52 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>好吧，酷。嗯，所以我想我们现在退后一步，弄清楚这其中有哪些线索？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 22:04:27 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 22:04:27 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>我认为你是在断言我假设存在折扣率，或者至少从这个事实中得出了我的很多直觉。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:05:23 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:05:23 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>我认为我没有用这些术语来思考它，但类似的事情听起来是对的，是的</p></div></section><h2>无限游戏呢？ </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:08:34 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:08:34 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>好的，所以在这一点上我们同意，在有限游戏中，线性效用玩家每次都应该下注。我想，如果我们愿意的话，我们可以讨论无限游戏？但听起来我们都同意这些都搞砸了，所以这可能不是我们想要去的地方</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 22:08:40 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 22:08:40 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>无限的实用程序很糟糕，但无限的游戏我很好</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:10:44 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:10:44 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>好吧，无限游戏。因此，建模的一种方法是“如果你永远玩这个游戏，凯利投注者将以概率 1 拥有无限金钱，而赌注一切的投注者将以概率 1 拥有零金钱”，但这感觉是一种糟糕的建模方法对我来说</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:11:50 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:11:50 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>就像，如果我们在每个时间步上取财富的概率分布极限，我认为一切赌注极限确实是一个概率分布，在 0 处为 1，其他地方为 0。但我认为凯利极限是一个处处为零的函数，而不是概率分布</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 22:13:47 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 22:13:47 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>是的，这听起来是正确的。你成功地让我困惑了，我想这就是你想要我的地方</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 22:15:26 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 22:15:26 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>好吧，我想我发现了我的困惑。问题是，如果效用函数有一个界限，那么打赌一切的家伙只会得到 0 效用，但凯利女孩会得到最大的效用</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xEjYKycvoJSWWfKE7-Sun, 05 Nov 2023 22:15:40 GMT" user-id="xEjYKycvoJSWWfKE7" display-name="River" submitted-date="Sun, 05 Nov 2023 22:15:40 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>河</b></section><div><p>我不明白你说的菲尔是什么意思。凯利函数的极限在特定位置意味着什么？极限就是我们所说的地方。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:16:54 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:16:54 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><blockquote><p>好吧，我想我发现了我的困惑。问题是，如果效用函数有一个界限，那么打赌一切的家伙只会得到 0 效用，但凯利女孩会得到最大的效用</p></blockquote><p>是的，听起来不错。但是，用线性到一定范围的效用函数下注的人会以某种方式表现出不同的行为，这对我来说并不明显。 （如果他们最终只是赌凯利，我不会完全感到震惊，实际上......） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:19:40 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:19:40 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><blockquote><p>凯利函数的极限在特定位置意味着什么？</p></blockquote><p>因此，在某个固定的时间步长，我们对财富有一些概率分布，在这种情况下，概率分布是函数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="ℝ → ℝ"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span></span></span></span></span> ，积分为 1。因此，在时间 ->; 无穷大的极限中，我们可以取这些概率的极限分布。这些的逐点极限，即通过在固定点取每个先前函数并取该数字序列的极限而得出的函数，是一个始终为 0 的函数</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xEjYKycvoJSWWfKE7-Sun, 05 Nov 2023 22:21:25 GMT" user-id="xEjYKycvoJSWWfKE7" display-name="River" submitted-date="Sun, 05 Nov 2023 22:21:25 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>河</b></section><div><p>为什么我们要关心固定时间点概率分布的极限？这个限制不是必须始终为零吗？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xEjYKycvoJSWWfKE7-Sun, 05 Nov 2023 22:22:37 GMT" user-id="xEjYKycvoJSWWfKE7" display-name="River" submitted-date="Sun, 05 Nov 2023 22:22:37 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>河</b></section><div><blockquote><p>我们可以取这些概率分布的极限。</p></blockquote><p>当然，听起来您正在某个固定时间点取概率分布的极限？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xEjYKycvoJSWWfKE7-Sun, 05 Nov 2023 22:22:50 GMT" user-id="xEjYKycvoJSWWfKE7" display-name="River" submitted-date="Sun, 05 Nov 2023 22:22:50 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>河</b></section><div><p>就像，我不知道如何解析该语句。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:25:26 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:25:26 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>所以在时间 t 我们有一个概率分布<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="V_t"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.186em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span></span></span></span></span></span></span></span> 。我们取<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lim_{t→∞} V_t"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-munderover"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">lim</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">∞</span></span></span></span></span></span></span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.186em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span></span></span></span></span></span></span></span> ，由于每个<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="V_t"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.186em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span></span></span></span></span></span></span></span>都是一个函数，所以极限也是一个函数。嗯，有点。我认为这实际上可能是“取决于我们认为的极限等等”。但在这种情况下，有一个极限，我们称之为逐点极限，它确实存在，而且是一个函数。但即使每个<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="V_t"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.186em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span></span></span></span></span></span></span></span>都是一个函数，也是一个概率分布，极限是一个不是概率分布的函数</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:26:15 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:26:15 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>嗯，但这里发生的事情的一部分是我说“这是一件愚蠢的事情”，<i>但这</i>也是人们在比较无限游戏中凯利与赌注的结果时所做的事情</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xEjYKycvoJSWWfKE7-Sun, 05 Nov 2023 22:29:37 GMT" user-id="xEjYKycvoJSWWfKE7" display-name="River" submitted-date="Sun, 05 Nov 2023 22:29:37 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>河</b></section><div><p>我同意加勒特的观点，在这里尝试做数学很烦人。我同意赌一切策略有一个限制，即 0 处为 1，其他地方均为 0。我不认为我同意凯利有一个到处都是 0 的极限。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 22:30:30 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 22:30:30 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>我认为“到处都是 0”意味着 p(utility=Utility|kelly) = 0 无论效用是什么。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xEjYKycvoJSWWfKE7-Sun, 05 Nov 2023 22:30:34 GMT" user-id="xEjYKycvoJSWWfKE7" display-name="River" submitted-date="Sun, 05 Nov 2023 22:30:34 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>河</b></section><div><p>凯利永远不会告诉你赌上一切，无论你有多么确定。因此，即使你在凯利投注中遭受了巨大损失，你最终也会恢复过来。所以在极限情况下，你还是应该变得富有。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 22:30:57 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 22:30:57 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>而 p(0 = 效用 | 赌上一切) = 1 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 22:31:26 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 22:31:26 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>重点是要表明这实际上是一种非常愚蠢的分析事物的方式</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:31:39 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:31:39 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><blockquote><p>我认为“到处都是 0”意味着 p(utility=Utility|kelly) = 0 无论效用是什么。</p></blockquote><p>是的，这个。任何特定结果的概率为零（这意味着它不是概率分布） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:32:33 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:32:33 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>（嗯，这不精确，但我声称它至少不是标准概率分布。我认为人们想出了一些奇怪的东西，可以让你处理这样的事情） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 22:32:37 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 22:32:37 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>我想有人可能会反驳说，到处概率为 0 比除 0 以外处处概率为 0 更好。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:33:15 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:33:15 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>是的。但我想我的主要回答是“那时我们并没有真正进行统计” </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xEjYKycvoJSWWfKE7-Sun, 05 Nov 2023 22:34:45 GMT" user-id="xEjYKycvoJSWWfKE7" display-name="River" submitted-date="Sun, 05 Nov 2023 22:34:45 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>河</b></section><div><p>好吧，我想我同意。直觉上，我认为一定有一个相关的意义，其中凯利的所有非零结果相加得到 1，而赌注一切的非零结果得到 0，但我不知道足够的分析来提出更具体的东西关于这一点。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 22:35:25 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 22:35:25 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>我想我们可以对非零结果取积分的极限</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:36:21 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:36:21 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>嗯，我想我看到了两件事可能意味着，其中之一是“期望值的极限”，另一个是“恒定为 1 的函数的极限” </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 22:37:57 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 22:37:57 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>我是说</p><p><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lim_{T\to \infty} \int_{C_T} p(u=U_T | \text{strategy})du"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-munderover"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">lim</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">∞</span></span></span></span></span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.138em;"><span class="mjx-mo" style="padding-right: 0.138em;"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.593em; padding-bottom: 0.593em;">∫</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.517em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.045em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.278em; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">u</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.084em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.519em;">策略</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">u</span></span></span></span></span></span></span></p><p>其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="C_T = (0, T)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.045em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xEjYKycvoJSWWfKE7-Sun, 05 Nov 2023 22:40:46 GMT" user-id="xEjYKycvoJSWWfKE7" display-name="River" submitted-date="Sun, 05 Nov 2023 22:40:46 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>河</b></section><div><p>也许思考的方式是，在每个时间点，我们可以在 (0, inf) 范围内对每个策略的概率函数进行积分，并取其极限。对于赌注一切，这是 0。对于凯利，这是 1。这似乎是我们应该关心的事情。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 22:41:01 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 22:41:01 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>转化为我的东西， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lim_{T\to \infty} \int_{C_T} p(u=U_T | \text{kelly})du = 1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-munderover"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">lim</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">∞</span></span></span></span></span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.138em;"><span class="mjx-mo" style="padding-right: 0.138em;"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.593em; padding-bottom: 0.593em;">∫</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.517em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.045em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.278em; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">u</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.084em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">kelly</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">u</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span> ，和<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lim_{T\to \infty} \int_{C_T} p(u=U_T | \text{bet everything})du = 0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-munderover"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">lim</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">∞</span></span></span></span></span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.138em;"><span class="mjx-mo" style="padding-right: 0.138em;"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.593em; padding-bottom: 0.593em;">∫</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.517em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.045em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.278em; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">u</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.084em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">bet everything</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">u</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span> 。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 22:42:49 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 22:42:49 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>我想菲尔也许可以在 On kelly 和 altrusim 的 TLDR 中阐述他试图表达的观点：</p><blockquote><p><i>一句话概括：凯利不是关于优化效用函数；而是关于优化效用函数。总的来说，我建议你要么停止假装你有其中之一，要么停止谈论凯利。</i> </p></blockquote></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:43:30 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:43:30 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><blockquote><p>在每个时间点，我们可以在 (0, inf) 范围内对每个策略的概率函数进行积分，并取其极限。</p></blockquote><p>因此，如果我们积分的只是概率函数本身，则积分始终为 1（这就是概率函数）如果我们积分的是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="xp(x) dx"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> ，那么这就是期望值。并且两者都在极限内增长到无穷大</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:44:38 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:44:38 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><blockquote><p><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lim_{T\to \infty} \int_{C_T} p(u=U_T | \text{strategy})du"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-munderover"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">lim</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">∞</span></span></span></span></span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.138em;"><span class="mjx-mo" style="padding-right: 0.138em;"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.593em; padding-bottom: 0.593em;">∫</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.517em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.045em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.278em; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">u</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.084em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.519em;">策略</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">u</span></span></span></span></span></span></span></p></blockquote><p> （嗯，我目前不知道这是怎么回事） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 22:45:16 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 22:45:16 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>这基本上是在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span>时间步后你没有 0 钱的概率的极限<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="T \to \infty"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">∞</span></span></span></span></span></span></span></p><p> （假设你不能负债） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xEjYKycvoJSWWfKE7-Sun, 05 Nov 2023 22:45:37 GMT" user-id="xEjYKycvoJSWWfKE7" display-name="River" submitted-date="Sun, 05 Nov 2023 22:45:37 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>河</b></section><div><blockquote><p>因此，如果我们要积分的只是概率函数本身，则积分始终为 1（这就是概率函数）</p></blockquote><p>不，整合所有可能结果的概率函数必须是一个。我的观点是排除一个结果（破产），这意味着积分可能小于 1。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:48:51 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:48:51 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><blockquote><p>不，整合所有可能结果的概率函数必须是一个。我的观点是排除一个结果（破产），这意味着积分可能小于 1。</p></blockquote><p>啊，所以如果概率分布是连续的（我认为对于这个无限游戏来说它必须是连续的，但是......我不知道，也许不是），那么排除点值实际上不会改变积分。但我们可以考虑“破产的可能性”。但我的回答是“但是线性公用事业人士并不关心他们破产的可能性，他们关心的是他们的预期收入” </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xEjYKycvoJSWWfKE7-Sun, 05 Nov 2023 22:48:56 GMT" user-id="xEjYKycvoJSWWfKE7" display-name="River" submitted-date="Sun, 05 Nov 2023 22:48:56 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>河</b></section><div><p>我们有离散的时间步长，每个时间步长都有离散的美元数量，所以我认为这些概率分布都不是连续的。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:49:26 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:49:26 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>好的。我不确定，但我认为这不是问题的关键</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 22:49:31 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 22:49:31 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>我们可以考虑连续数美金的情况，就可以了</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xEjYKycvoJSWWfKE7-Sun, 05 Nov 2023 22:52:07 GMT" user-id="xEjYKycvoJSWWfKE7" display-name="River" submitted-date="Sun, 05 Nov 2023 22:52:07 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>河</b></section><div><p>是的，这不是一个特别富有成效的方向，对此感到抱歉。</p></div></section><h2>回到 Phil 之前的 tl;dr </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 22:54:47 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 22:54:47 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><blockquote><p>我想菲尔也许可以在 On kelly 和 altrusim 的 TLDR 中阐述他试图表达的观点：</p></blockquote><p>当然。所以这在一定程度上取决于我们放弃的关于我是否以奇怪的方式说了什么的话题。但是，就像，如果我们接受这种奇怪的表达方式，那么我声称，如果你有一个对数效用函数，你所做的事情相当于凯利投注，但我（承认是温和的）不赞成将其称为凯利投注。如果你有不同的效用函数，那么你所做的事情就会有所不同。</p><p>但是（这是我们未能达到的另一点）凯利给你的一件事是，将其视为“我通过得到这个来最大化我的效用函数”并没有真正意义，但是在我看来确实是一件好事（因为我没有效用函数，如果我这样做了，它就不会纯粹以美元等计价）。</p><p>事实是，投注凯利意味着以 1 的概率，随着时间的推移，你会比不投注凯利的人更富有。因此，如果你想实现这一目标，凯利就很棒。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 23:03:56 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 23:03:56 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>我会说我在这里很困惑。我确实认为，如果你提出 River 提出的论点，并且发现它令人信服，那么你确实似乎在努力最大化你成为最终拥有最多金钱的实体的可能性。然而，我认为如果你有一定的折扣率，你也可以进行凯利投注，这似乎是一个比说我只想最大化我比其他人有更多钱的概率更合理的调整。我还声称，想要比其他人更多的钱实际上是一个合理的效用函数。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 23:04:01 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 23:04:01 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>所以我认为具有线性效用的贴现率可能等同于具有对数效用？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 23:04:22 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 23:04:22 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>是的，似乎有可能</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 23:06:10 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 23:06:10 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>我同意比其他人想要更多的钱是合理的，我不确定将其视为效用函数是否有意义。无论如何，作为一个人还是很尴尬的。就像，它肯定不是一个可以用你当前的财富来表达的效用函数。我认为“关于凯利和利他主义”中有一个附录对此进行了一些研究，但我不记得有多仔细</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 23:06:53 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 23:06:53 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>我不认为这有多尴尬，你只是最大化你比其他人有更多钱的可能性。但我确实同意你需要纳入有关你的世界中特工分布的信息才能实施它，所以它不仅仅是你财富的函数。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 23:07:20 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 23:07:20 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>也许你的意思是，人们没有简单地用他们的财富来表示的效用函数。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 23:08:13 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 23:08:13 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>嗯，我认为人们，至少是人类，根本没有效用函数。有时将它们作为速记来讨论是合理的，但我认为这是错误的。但是，我也认为在这种情况下这很好，因为我们不需要将“我想成为房间里最富有的人”视为效用函数</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 23:08:43 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 23:08:43 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>我们可以直接说“我想最大化这种可能性”，然后凯利就会给你它</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 23:09:02 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 23:09:02 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>从某种意义上说你是对的，但我确实认为从更强烈的意义上说你是错的。就像，我们实际上并没有效用函数，但是通过分析人们，就好像他们具有效用函数一样，您确实可以获得有用的结果。经济学领域有很多这样的例子。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 23:10:04 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 23:10:04 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>我还认为这是一种看待生活选择的有用方法，并寻找你可能犯错误的领域（记住你的效用函数不必很简单，如果改变感觉不对，你可能应该发现自己站在了一边）你的直觉比你对情况的简单分析更常见） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 23:10:39 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 23:10:39 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>似乎很合理——我认为我们在这里的任何分歧都可能是关于灰色区域内的划线，而不是实质性的</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 23:11:19 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 23:11:19 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>听起来不错。这是一次很好的对话！我想我们可能没有什么可讨论的了。你想到了什么吗？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 23:11:44 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 23:11:44 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>我有点希望我们能想出一些办法，但这确实感觉像是一个自然的结论</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="nrP5EZZj4vRvYwQ7b-Sun, 05 Nov 2023 23:11:50 GMT" user-id="nrP5EZZj4vRvYwQ7b" display-name="philh" submitted-date="Sun, 05 Nov 2023 23:11:50 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>菲尔</b></section><div><p>谢谢你！我很喜欢这个</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6c2KCEXTGogBZ9KoE-Sun, 05 Nov 2023 23:25:59 GMT" user-id="6c2KCEXTGogBZ9KoE" display-name="Garrett Baker" submitted-date="Sun, 05 Nov 2023 23:25:59 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>加勒特·贝克</b></section><div><p>相同的。</p></div></section><div></div><br/><br/> <a href="https://www.lesswrong.com/posts/qXvj6abkc9eqPjKaB/when-and-why-should-you-use-the-kelly-criterion#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/qXvj6abkc9eqPjKaB/when-and-why-should-you-use-the-kelly-criterion<guid ispermalink="false"> qXvj6abkc9eqPjKaB</guid><dc:creator><![CDATA[Garrett Baker]]></dc:creator><pubDate> Sun, 05 Nov 2023 23:26:38 GMT</pubDate> </item><item><title><![CDATA[On Overhangs and Technological Change]]></title><description><![CDATA[Published on November 5, 2023 10:58 PM GMT<br/><br/><p>想象一下，中世纪早期农村的几乎无限、几乎平坦的平原，居住着人类和他们的牲畜（牛、马、羊等），在政治上被组织成小公国，除了罕见的小冲突外，总体上是和平的。</p><p>添加一些关键技术，如马镫和复合弓（以及一些社会技术——征服的欲望、机动战争、多元文化主义），一个伟大的可汗或军阀就可以率领人马征服整个世界。金帐汗国在 1200 年代对欧亚大陆就是这样做的。</p><p>我在这里使用的意义上的<a href="https://old-wiki.lesswrong.com/wiki/Computing_overhang">悬垂物</a>意味着某种资源（如人、马和土地）的积累，其积累远远超出了某些新的消费过程的需要，并且消耗过程迅速进行，就像登山者从悬垂物上掉下来一样悬崖，而不是仅仅从陡峭的斜坡上滚下来。</p><p> 1200年之前的欧亚平原处于<strong>“草原部落脆弱的悬垂地区”</strong> 。他们不知道，但他们的世界正处于亚稳态，这种状态可能会迅速转变为新的、更“受到能量青睐”的状态，在那里他们被蒙古人屠杀或奴役。</p><p>在智人传播之前，陆地脊椎动物生物量几乎完全不是来自智人属。如今，人类和农场动物约占其中的 90%。智人之前的世界有一个<strong>“非文明生物质过剩”</strong> ：有很多动物和生态系统，但它们都是毫无意义的（没有全球性的资源利用，一切都只是局部的生存斗争，所以稍微协调和有能力的团队可以拿走一切）。</p><p>为什么会发生这些亚稳态转变？为什么欧亚平原不立即逐渐在各地发展弓骑兵，使现有群体不至于被真正扰乱呢？为什么森林不逐渐在各处燃烧一点点，这样就不会发生大规模而危险的森林火灾呢？为什么所有的动物物种没有和人类同时发展出文明，从而没有发生人类造成的大多数其他物种的灭绝和灭绝？</p><p>这是因为在技术转型中从较不受欢迎的状态到较受欢迎的状态的跳跃是复杂的，并且需要非平凡的适应，而其他群体可能永远不会发展这种适应，或者发展得慢得多。海豚无法创造文明，因为它们没有手，也没有火，所以它们基本上肯定会在文明竞赛中输给人类。蒙古人碰巧集齐了草原帝国的所有要素——也许可能是其他人，但蒙古人首先做到了，他们在那个世界的领先地位变得不可阻挡，他们几乎征服了这片大陆上的一切。</p><p>这些转变也会产生阈值效应。一片燃烧的叶子可能会被扑灭，火灾就结束了。一个带着马镫和弓的单身男子是一种好奇，一万个这样的人是一个有潜力发展的小部落。因此，新的状态必须跨越一定的规模阈值才能传播。</p><p>阈值规模效应、空间多米诺骨牌效应和创新的最小有用复杂性意味着最佳可用技术的变化可能是破坏性的悬垂事件，其中某些参数在变化发生之前被推得远远超过其平衡值，并且由此产生的变化是剧烈的。</p><p>除了快速/暴力/破坏性之外，这些变化往往对现任者不利。欧亚农民宁愿蒙古帝国不存在。欧洲贵族宁愿火器从未被发明。但一旦他们开始行动，就很难协调起来，而且在他们开始行动之前很难说服人们相信他们是真实的。</p><p> Of course there is some degree of change where a gradual transition is favored over a violent phase change. A slightly innovative military weapon may simply get shared around the world, rather than giving the entity that invented it enough of an advantage to roll everyone else up. If you are an incumbent and you have any choice in the matter, you would almost certainly prefer that the rate of change is below the threshold for violent, overhang-y metastable transitions.</p><br/><br/> <a href="https://www.lesswrong.com/posts/EwGFEPxwynf3ALdeK/on-overhangs-and-technological-change#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/EwGFEPxwynf3ALdeK/on-overhangs-and-technological-change<guid ispermalink="false"> EwGFEPxwynf3ALdeK</guid><dc:creator><![CDATA[Roko]]></dc:creator><pubDate> Sun, 05 Nov 2023 22:58:52 GMT</pubDate> </item><item><title><![CDATA[xAI announces Grok, beats GPT-3.5]]></title><description><![CDATA[Published on November 5, 2023 10:11 PM GMT<br/><br/><p> Some highlights:</p><blockquote><p> <i>Grok is still a very early beta product – the best we could do with 2 months of training – so expect it to improve rapidly with each passing week with your help.</i></p></blockquote><p> I find it very interesting that they managed to beat GPT-3.5 with <strong>only 2 months of training!</strong> This makes me think xAI might become a major player in AGI development.</p><blockquote><p> By creating and improving Grok, we aim to:</p><ul><li> Gather feedback and ensure we are building AI tools that maximally benefit all of humanity. We believe that it is important to design AI tools that are useful to people of all backgrounds and political views. We also want empower our users with our AI tools, subject to the law. Our goal with Grok is to explore and demonstrate this approach in public. </li></ul></blockquote><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pbCw4QdL9K4tB7JEM/lrlmmozd5odxgyeit9v7" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pbCw4QdL9K4tB7JEM/s900loobwytouakbdn7d 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pbCw4QdL9K4tB7JEM/qets9ica5c8sypsxb7r4 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pbCw4QdL9K4tB7JEM/llwusocu9gqjeekxwlte 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pbCw4QdL9K4tB7JEM/kxrkscrmwui9mwk0sjxt 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pbCw4QdL9K4tB7JEM/pr7wqyeww9e1ygwpg9gu 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pbCw4QdL9K4tB7JEM/afo8gaupzefizhsjhrqt 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pbCw4QdL9K4tB7JEM/zveac5m8jtvbymjwtenk 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pbCw4QdL9K4tB7JEM/oq8gylhbhxp2hkyyzomt 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pbCw4QdL9K4tB7JEM/zwjyldzikkz3kc8dmn8x 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pbCw4QdL9K4tB7JEM/yzusoyaygpppc5dhf0c8 1711w"></figure><blockquote><p> On these benchmarks, Grok-1 displayed strong results, surpassing all other models in its compute class, including ChatGPT-3.5 and Inflection-1. It is only surpassed by models that were trained with a significantly larger amount of training data and compute resources like GPT-4. This showcases the rapid progress we are making at xAI in training LLMs with exceptional efficiency.</p></blockquote><p></p><blockquote><p> We believe that AI holds immense potential for contributing significant scientific and economic value to society, so we will work towards developing reliable safeguards against catastrophic forms of malicious use. We believe in doing our utmost to ensure that AI remains a force for good.</p></blockquote><br/><br/> <a href="https://www.lesswrong.com/posts/pbCw4QdL9K4tB7JEM/xai-announces-grok-beats-gpt-3-5#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/pbCw4QdL9K4tB7JEM/xai-announces-grok-beats-gpt-3-5<guid ispermalink="false"> pbCw4QdL9K4tB7JEM</guid><dc:creator><![CDATA[nikola]]></dc:creator><pubDate> Sun, 05 Nov 2023 22:11:16 GMT</pubDate> </item><item><title><![CDATA[Disentangling four motivations for acting in accordance with UDT]]></title><description><![CDATA[Published on November 5, 2023 9:26 PM GMT<br/><br/><h2>介绍</h2><p>In this post, I examine a number of different arguments for acting like an updateless agent. Concretely, I try to provide answers to the following question: <strong>What could move someone who isn&#39;t already born a perfectly coherent</strong> <a href="https://www.lesswrong.com/posts/de3xjFaACCAk6imzv/towards-a-new-decision-theory"><strong>UDT</strong></a> <strong>agent to adopt a UDT-like policy?</strong></p><p> I take this perspective because I was not born as an idealized UDT agent, and I want the extent to which I&#39;m willing to follow something like UDT (or endorse instructing an AI to do it) to be justified on non-tautological grounds. After all, doing &#39;the updateless as opposed to the updateful thing&#39; by definition means doing something that, to first approximation, is bad by one&#39;s current lights.</p><p> To gain clarity, I consider four ways of climbing the mountain of updatelessness. At the base, I assume that we start with non-indexical preferences and some pre-existing decision-theoretical intuitions, for instance &#39;I want to cause good outcomes&#39; for those who are inclined towards CDT. The first three paths begin the journey from there: if we treat our current decision-theoretical intuitions as bedrock, will this lead us to act in UDT-like ways? The fourth approach I consider is to drop our previous decision-theoretical intuitions, attempting to jump up to UDT directly.</p><p> A caveat: none of the motivations I present here will receive the in-depth discussion they deserve. The role of this post is rather that of an opinionated guidebook: to make salient the fact that there exist different paths, the difficulties one is faced with by taking them, and that they end up at relevantly different UDT-like endpoints. That isn&#39;t to say that the guide is complete: I&#39;m still a wanderer myself, occasionally lost, and looking to diverge from the beaten paths.</p><h2> Four justifications for UDT-like policies</h2><p> To set the stage, here are some deliberately vague definitions:</p><ul><li> <i>Updatelessness</i> is the maxim of choosing the action you would have wanted to commit to ex-ante, ie before you learned everything you know now. What exactly this means depends on various factors, such as what you consider your ex-ante perspective to be, or what sorts of things you would/should have wanted to allow yourself to learn and act upon.</li><li> <a href="https://www.lesswrong.com/tag/updateless-decision-theory"><i><u>UDT</u></i></a> is a particular decision theory that was designed to fulfill the desideratum of updatelessness. Different versions of UDT have been proposed. <span class="footnote-reference" role="doc-noteref" id="fnrefg2futd1ty3r"><sup><a href="#fng2futd1ty3r">[1]</a></sup></span></li><li> A policy is a mapping from observations to actions. I call a policy <i>UDT-like</i> (in some decision problem) if it chooses the same actions as some updateless agent&#39;s policy, though this doesn&#39;t necessarily require that one is actually updateless. <span class="footnote-reference" role="doc-noteref" id="fnrefk29az2gs07"><sup><a href="#fnk29az2gs07">[2]</a></sup></span></li></ul><p> So why would we want to adopt a UDT-like policy? Let us look at four possible reasons.</p><h3> Updatelessness as a meta-commitment</h3><p> When thinking about a multitude of possible decision problems, we notice that in the future we might act differently from what we now wish we will act like. For example, we know that committing to paying up in <a href="https://www.lesswrong.com/posts/mg6jDEuQEjBGtibX7/counterfactual-mugging"><u>counterfactual mugging</u></a> <i>now</i> <a href="https://casparoesterheld.com/2016/11/21/thoughts-on-updatelessness/"><u>is cause/evidence for a higher expected payoff</u></a> in case we encounter this situation in the future. Because we don&#39;t know all the decision problems in advance, <a href="https://www.lesswrong.com/posts/88vuFDw3dCX7hC6uW/self-modification-is-the-correct-justification-for"><u>we can implement a meta-commitment</u></a> to always act like we would have liked to commit, had we known about the decision problem at the time of making the meta-commitment: given a pre-existing updateful decision theory X, like EDT, we say that we self-modified into <i>&nbsp;</i> <a href="https://www.lesswrong.com/posts/5bd75cc58225bf067037528e/updatelessness-and-son-of-x"><i><u>Son of X</u></i></a> . Another way to frame this reasoning is to say that an updateful decision theory does action selection in isolated decision situations, and Son of X represents the insight that by the lights of X, it is optimal to use the earliest opportunity to perform the action &#39;commit to an optimal policy according to my current beliefs&#39;.</p><p> Precisely which commitments are implied from you becoming Son of X depends on which commitments you would have endorsed by the lights of X at the time of self-modification. This gives rise to some subtleties:</p><ul><li> If this is the reason why you want to implement UDT-like behavior, you don&#39;t (yet) have a reason to pay up if you&#39;re &#39;born into&#39; the problem. For example, if Omega approached you with a counterfactual mugging <i>before you self-modified into Son of X</i> , becoming Son of X wouldn&#39;t justify paying up.</li><li> There&#39;s a difference between Son of CDT and Son of EDT: Suppose Omega approaches you with a counterfactual mugging <i>after</i> you went updateless, but tells you that it made its prediction <i>before</i> you went updateless. Then Son of CDT would not pay up because going updateless can&#39;t have been a cause of Omega&#39;s prediction, whereas Son of EDT can still reason itself into paying up because going updateless provided evidence for what Omega has predicted before going updateless.</li><li> Son of X can implement <a href="https://www.lesswrong.com/posts/K5Qp7ioupgb7r73Ca/logical-updatelessness-as-a-robust-delegation-problem"><u>logical updatelessness</u></a> by considering what logical priors it had at the time of going updateless. <span class="footnote-reference" role="doc-noteref" id="fnrefhwnrsq5ihmf"><sup><a href="#fnhwnrsq5ihmf">[3]</a></sup></span></li></ul><h3> Updatelessness as having intrinsic preferences about counterfactual worlds</h3><p> When faced with the decision to pay up in counterfactual mugging, you notice that you would receive a large payoff in a <a href="https://plato.stanford.edu/entries/counterfactuals/"><u>counterfactual</u></a> world if and only if you pay up in the world you observe. Even though you are not observing that counterfactual world, you might still <a href="https://www.lesswrong.com/posts/9W4TQvixiQjpZmzrx/decision-theory-and-dynamic-inconsistency"><u>have intrinsic preferences</u></a> about it. This could be because you think that the other world actually exists, such that what you do in the world you are observing has (logical or evidential) implications for what happens there. <span class="footnote-reference" role="doc-noteref" id="fnref9mxfv5frni7"><sup><a href="#fn9mxfv5frni7">[4]</a></sup></span> But you could have preferences about counterfactuals for other reasons.</p><p> Again, we can observe some subtleties about this view:</p><ul><li> In a sense this is a way in which UDT-like behavior follows from EDT or TDT without self-modification, when combined with preferences about counterfactual worlds. On the flip side, note that this doesn&#39;t work for orthodox CDT agents.</li><li> In contrast to Son of X, this reasoning works even for agents &#39;born into&#39; the problem, provided they have sufficient credence in the existence of a world where they were &#39;born into&#39; the other branch of the problem.</li><li> It seems hard to be logically updateless using this motivation, because it is pretty counterintuitive – and in my opinion nonsensical – to have intrinsic preferences about impossible counterfactuals. Once Omega approaches you with a counterfactual mugging on the trillionth digit of π being even, you know that there is no world in which the trillionth digit of π is odd, and thus no possible world in which Omega pays you. <span class="footnote-reference" role="doc-noteref" id="fnrefmjh7gf6nzzg"><sup><a href="#fnmjh7gf6nzzg">[5]</a></sup></span></li></ul><h3> UDT-like behavior as a consequence of anthropic uncertainty</h3><p> If you find yourself in a counterfactual mugging, you might think <a href="https://casparoesterheld.com/2017/05/12/anthropic-uncertainty-in-the-evidential-blackmail/"><u>“maybe Omega is simulating me in order to make its prediction”</u></a> . <span class="footnote-reference" role="doc-noteref" id="fnrefa581s2u0k5"><sup><a href="#fna581s2u0k5">[6]</a></sup></span> (Note that this subtly violates the initial assumption of an honest Omega in counterfactual mugging.) So paying up is cause/evidence for getting a large payoff in reality. This sounds simple and <a href="https://www.alignmentforum.org/posts/5bd75cc58225bf06703751b2/in-memoryless-cartesian-environments-every-udt-policy-is-a"><u>elegant</u></a> , but is actually pretty hairy for many reasons. To give just three considerations:</p><ul><li> Coarse-grained simulations: Making simulations is costly, especially if the simulations are of &#39;big&#39; agents like superintelligences. But a coarse-grained simulation of a superintelligence probably gives different outputs from the full-fidelity version, which itself is a relevant complicating factor when considering the possibility that one is a simulation.</li><li> Isomorphic simulations: Suppose you care about maximizing paperclips. Instead of simulating an identical copy of you, Omega could simulate a version of you that cares about, say, staplers. That way, Omega finds out what &#39;your algorithm&#39; would do in a counterfactual mugging, but each of your algorithm&#39;s instances doesn&#39;t care about benefiting the other. (This problem mainly affects CDT agents.)</li><li> Limited compatibility of anthropic theories and decision theories: For instance, there exist Dutch books against <a href="https://joelvelasco.net/teaching/3865/briggs10-puttingavalueonbeauty.pdf"><u>EDT with SIA</u></a> , and <a href="https://www.andrew.cmu.edu/user/coesterh/DeSeVsExAnte.pdf"><u>CDT with SSA</u></a> . Doing anthropic reasoning becomes <a href="https://www.andrew.cmu.edu/user/coesterh/DeSeVsExAnte.pdf"><u>complicated</u></a> once decision making is involved.</li></ul><p> Assuming this works, however, here are two observations related to the ones we made for other motivations:</p><ul><li> This reasoning can work for cases where one is &#39;born into&#39; the decision problem, including for orthodox CDT agents.</li><li> It is unclear whether this is able to motivate acting as if one were logically updateless. On the one hand, presumably, one can&#39;t simulate agents in impossible worlds (as otherwise they are possible). On the other hand, in practice, our simulator could sometimes fool us into believing that the world is possible – but this might not apply to all cases where logical updatelessness could be relevant.</li></ul><h3> UDT as a result of rejecting everything else</h3><p> You reject CDT for two-boxing in Newcomb&#39;s problem, then reject EDT for not smoking in Smoking Lesion, then embrace EDT again because the <a href="https://www.andrew.cmu.edu/user/coesterh/TickleDefenseIntro.pdf"><u>tickle defense</u></a> takes care of Smoking Lesion, then (maybe) reject EDT again for paying in <a href="https://www.alignmentforum.org/posts/5bd75cc58225bf0670374e7d/exploiting-edt"><u>XOR blackmail</u></a> . TDT <span class="footnote-reference" role="doc-noteref" id="fnrefkp296xiineq"><sup><a href="#fnkp296xiineq">[7]</a></sup></span> seems reasonable (modulo some questions around <a href="https://www.lesswrong.com/posts/QpqKBYzPKdZpByZS3/fdt-defects-in-a-realistic-twin-prisoners-dilemma"><u>similar-but-not-identical algorithms</u></a> ), and becoming Son of X does too, but then you realize that all of the previously mentioned decision theories <a href="https://www.lesswrong.com/posts/c3wWnvgzdbRhNnNbQ/timeless-decision-theory-problems-i-can-t-solve"><u>wouldn&#39;t pay in a logical counterfactual mugging if they&#39;re &#39;born into&#39; it</u></a> . However, whether paying in such a counterfactual mugging means winning or losing is a matter of perspective: a natural one is to say “well, I already know that the world in which Omega just gives me a million bucks is impossible, so <a href="https://casparoesterheld.com/2016/11/21/thoughts-on-updatelessness/"><u>the way to win is not to pay</u></a> ”. Having priors that prima facie give nonzero weight to impossible hypotheses, in my opinion, requires a normative or epistemic justification from <i>somewhere</i> , such as that maybe I care about logically impossible counterfactual worlds – but why? – or maybe I believe that I&#39;m in a simulation, or that there exists a world where Omega has bet on the opposite parity of the relevant digit of π.</p><p> A <a href="https://www.lesswrong.com/posts/RcvyJjPQwimAeapNg/torture-vs-dust-vs-the-presumptuous-philosopher-anthropic"><u>more compelling reason</u></a> for rejecting updateful decision theories is their reliance on anthropics. Anthropic reasoning seems dubious <span class="footnote-reference" role="doc-noteref" id="fnrefiyinm22wk78"><sup><a href="#fniyinm22wk78">[8]</a></sup></span> and enables various <a href="http://www.cs.cmu.edu/~conitzer/dutchSYNTHESE.pdf"><u>Dutch books</u></a> , and perhaps other <a href="https://www.lesswrong.com/posts/GJdymoviRywpBMXqc/sia-greater-than-ssa-part-2-telekinesis-reference-classes#V__Can_you_move_boulders_with_your_mind_"><u>self-defeating maneuvers</u></a> . Addressing this cluster of issues is worth a post of its own, so I will not go into more detail here – for now I note that in my opinion, most of the argumentative force for why one would want to follow UDT comes from here.</p><p> Nevertheless, subscribing to UDT is not as straightforward as we would hope. There remain issues around how to formalize UDT<a href="https://www.lesswrong.com/posts/Bj244uWzDBXvE2N2S/a-model-of-udt-with-a-halting-oracle"><u>in practice</u></a> , how to select priors, and the question of whether (and to what extent) one should be logically updateless.</p><h2> Takeaways</h2><p> To summarize: there are different possible considerations that could pull someone towards considering UDT-like behavior, but different considerations yield qualitatively different flavors of it. In particular, this affects attitudes to logical updatelessness, or what one should do when one is &#39;born into&#39; a decision problem without a previous opportunity to self-modify into Son of X.</p><p> Insofar as one thinks of UDT as an ideal, this might be unsatisfactory: for someone who has been &#39;poisoned&#39; by previous decision-theoretic intuitions, it&#39;s hard to arrive at what appears to be the very top of the mountain. Even with all of the first three approaches combined, it is likely that this doesn&#39;t, for instance, lead to logical updatelessness with respect to facts one starts out knowing. But, to carry this analogy a bit too far, jumping straight to the very top of the mountain might devoid us of oxygen: UDT has a bunch of free parameters, we don&#39;t know how to set them, and one way to ground UDT-like behavior is by asking why, and to which extent, we would endorse it by our current lights.</p><p> The bottom line:</p><ul><li> There might not be a compelling justification to be logically updateless with respect to logical facts one starts out knowing when considering updatelessness.</li><li> Son of X versions of UDT are relatively unproblematic, but can&#39;t justify updatelessness with respect to any facts one starts out knowing.</li><li> Having preferences about counterfactual worlds is one description of what it means to be updateless. Compared to Son of X, preferences about counterfactual worlds can potentially motivate updatelessness even with respect to empirical facts that one has always known. But such preferences do not motivate logical updatelessness, unless one has preferences about impossible worlds.</li><li> Anthropic uncertainty leads one to consider UDT-like behavior, but is all in all a pretty big mess in terms of what other implications it has.</li><li> It is tempting to reject updateful decision theories for their reliance on dubious anthropics. As far as I can tell, the questions of whether (and how) to be updateless after having rejected anthropics, and on the flip side, whether anthropics combined with updateful decision theories can be saved, are open questions.</li></ul><h2> Acknowledgements</h2><p> Thanks to Caspar Oesterheld, Jesse Clifton, Sylvester Kollin, Anthony DiGiovanni, and Martín Soto for helpful comments and discussion. </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fng2futd1ty3r"> <span class="footnote-back-link"><sup><strong><a href="#fnrefg2futd1ty3r">^</a></strong></sup></span><div class="footnote-content"><p> <a href="https://philpapers.org/rec/LEVCDI"><u>Functional Decision Theory</u></a> (FDT) is often considered a version of FDT, but Wei Dai doesn&#39;t endorse this <a href="https://www.lesswrong.com/posts/2THFt7BChfCgwYDeA/let-s-discuss-functional-decision-theory?commentId=LzPH8utKGSf97NihW"><u>as far as I can tell</u></a> . For more context and an overview of different versions of UDT, I recommend <a href="https://www.lesswrong.com/posts/QPhY8Nb7gtT5wvoPH/comparison-of-decision-theories-with-a-focus-on-logical"><u>this post</u></a> . This <a href="https://www.lesswrong.com/posts/FBbHEjkZzdupcjkna/miri-op-exchange-about-decision-theory-1"><u>exchange</u></a> between people at MIRI and OpenPhil also provides helpful context and framing.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnk29az2gs07"> <span class="footnote-back-link"><sup><strong><a href="#fnrefk29az2gs07">^</a></strong></sup></span><div class="footnote-content"><p> An alternative attempt to gesture at this without reference to UDT or updatelessness: My decision making is UDT-like if I sometimes do something <i>only</i> because it would be endorsed by a version of myself in a different location in spacetime (of an actual or hypothetical universe).</p></div></li><li class="footnote-item" role="doc-endnote" id="fnhwnrsq5ihmf"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhwnrsq5ihmf">^</a></strong></sup></span><div class="footnote-content"><p> As the post linked in this sentence explains, this might be problematic if done carelessly. We might want to consider <a href="https://www.alignmentforum.org/posts/uPWDwFJnxLaDiyv4M/open-minded-updatelessness"><u>open-minded updatelessness</u></a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fn9mxfv5frni7"> <span class="footnote-back-link"><sup><strong><a href="#fnref9mxfv5frni7">^</a></strong></sup></span><div class="footnote-content"><p> One could argue about whether this really counts as &#39;caring about counterfactual worlds&#39;.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnmjh7gf6nzzg"> <span class="footnote-back-link"><sup><strong><a href="#fnrefmjh7gf6nzzg">^</a></strong></sup></span><div class="footnote-content"><p> Though one way to motivate being UDT-like in this particular case is that maybe there exist worlds where Omega performed the counterfactual mugging on us by betting that the trillionth digit of pi would be odd, and that our choice is logically entangled with what happens in that world. But in practice, many problems involving logical counterfactuals could involve logical facts that are chosen in some deterministic (but previously unknown to us) way.</p></div></li><li class="footnote-item" role="doc-endnote" id="fna581s2u0k5"> <span class="footnote-back-link"><sup><strong><a href="#fnrefa581s2u0k5">^</a></strong></sup></span><div class="footnote-content"><p> The <a href="https://www.lesswrong.com/posts/9W4TQvixiQjpZmzrx/decision-theory-and-dynamic-inconsistency"><u>post</u></a> by Paul Christiano that I linked in the above paragraph could also appropriately be linked under this one, since it seems to draw intuition from both motivations.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnkp296xiineq"> <span class="footnote-back-link"><sup><strong><a href="#fnrefkp296xiineq">^</a></strong></sup></span><div class="footnote-content"><p> and <a href="https://philpapers.org/rec/SPORY"><u>Wolfgang Spohn&#39;s interpretation of CDT</u></a></p></div></li><li class="footnote-item" role="doc-endnote" id="fniyinm22wk78"> <span class="footnote-back-link"><sup><strong><a href="#fnrefiyinm22wk78">^</a></strong></sup></span><div class="footnote-content"><p> Different anthropic theories partially rely on metaphysical intuitions/stories about how centered worlds or observer moments are &#39;sampled&#39;, and have counterintuitive implications (eg, the Doomsday argument for SSA and the Presumptuous philosopher for SIA).</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/nc2tzMLgXKc8NGzrQ/disentangling-four-motivations-for-acting-in-accordance-with#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/nc2tzMLgXKc8NGzrQ/disentangling-four-motivations-for-acting-in-accordance-with<guid ispermalink="false"> nc2tzMLgXKc8NGzrQ</guid><dc:creator><![CDATA[Julian Stastny]]></dc:creator><pubDate> Sun, 05 Nov 2023 21:47:52 GMT</pubDate> </item><item><title><![CDATA[AI as Super-Demagogue]]></title><description><![CDATA[Published on November 5, 2023 9:21 PM GMT<br/><br/><p> Sam Altman <a href="https://twitter.com/sama/status/1716972815960961174">recently said</a> :</p><blockquote><p> i expect ai to be capable of superhuman persuasion well before it is superhuman at general intelligence, which may lead to some very strange outcomes</p></blockquote><p> I believe that he is absolutely right. Superhuman persuasion can be achieved by having LLMs consistently apply existing capabilities to known persuasion techniques. Some of these techniques are already proven to work at scale. Others have demonstrated effectiveness, and can more easily be applied at scale by AI. This makes superhuman persuasion a straightforward technology proposition.</p><p> I will look at this from the point of view of how AI can enable someone possessing the positions, skills, and desires necessary to attempt to create an authoritarian regime. In other words, I am describing something that is a near-term possibility without major advances in AI. Major advances seem likely, and would only make this picture worse.</p><p> I will also focus on techniques whose effectiveness has been proven by repeated human success. I will focus most of all on dictators and demagogues. Because he is so familiar, I will cite Donald Trump as an expert practitioner. This is not support for, or criticism of, him. I&#39;ve aimed to have this read equally well whether or not you like him.</p><p> The information that I&#39;m presenting is not new. Though it has come together for me as part of thinking about <a href="https://rationaldino.substack.com/">my blog</a> . And I decided to post this as a response to, <a href="https://www.lesswrong.com/posts/LdEwDn5veAckEemi4/we-are-already-in-a-persuasion-transformed-world-and-must">We are already in a persuasion-transformed world and must take precautions</a> .</p><h2> Talk to System 1</h2><p> Dictators want a mass audience who is emotionally aligned with them. These people should want the dictator to be right. And ideally should find it painful to question the dictator. The result is followers who can&#39;t be convinced by rational argument.</p><p> This requires conditioning System 1. So you want to speak in a way that System 1 responds to, but doesn&#39;t activate System 2. Use your speeches to deliver a key emotional message over and over again.</p><p> The necessary verbal pattern involves lots of simple and repetitive language. Avoid questions. Questions activate System 2, and you don&#39;t want that. If you can, rearrange sentences so that the most impactful word comes last. Do not worry about logical consistency. If System 2 doesn&#39;t activate, logical gaps won&#39;t be noticed.</p><p> You can personally practice this speech pattern by studying <a href="https://poly.land/2016/12/14/ventriloquist-hey-taught/">dirty talking</a> . If you&#39;re in a relationship, you can even practice with a consenting target. You&#39;ll find that it really works.</p><p> Reading through that article on dirty talking, the dialog is simple, repetitive, and blunt. If you&#39;re emotionally aligned with the speaker, it is extremely pleasant to hear. If you&#39;re not aligned with the speaker, it feels like attempted mental rape.</p><p> Now go review some of Donald Trump&#39;s speeches. You&#39;ll find the same pattern. Though with generally less sexual content. His speeches feel wonderful if you&#39;re aligned with him. You listen, and truly believe that he will make America great again. If you don&#39;t like him, they are torture to sit through. The resulting liberal outrage is music to the ears of conservatives who want to <a href="https://en.wikipedia.org/wiki/Owning_the_libs">own the libs</a> .</p><p> Readability metrics score Trump&#39;s speeches at about a grade 5 complexity. He has by far the easiest to understand speeches of any major politician. He&#39;s also the only politician with 70 million devoted followers who hang on his every word. This is absolutely not coincidence.</p><p> You&#39;ll find the same thing in the propaganda used by successful dictators from Benito Mussolini onwards. For example, try watching <a href="https://www.youtube.com/@russianmediamonitor">Russia Media Monitor</a> . You&#39;ll find the same verbal patterns, and the same results. The condition is literally strong enough that <a href="https://counteroffensive.substack.com/p/this-is-my-moms-brain-on-russian">people would prefer</a> to think their children Nazis than question the propaganda.</p><p> ChatGPT has no problem imitating a style like this. You just have to list the emotional buttons to hit, and tell it to copy the style of already effective demagogues.</p><p> If you want to dive deeper into this topic, <a href="https://www.amazon.com/Comply-Me-Hypnosis-Toolkit-Exposed/dp/1916346014">Comply with Me: Trump&#39;s Hypnosis Toolkit Exposed</a> may be worth reading.</p><h2> Change Your Position</h2><p> Dictators are famously inconsistent. Most don&#39;t realize that this inconsistency helps them succeed.</p><p> The name of the game is attention. I grew up in a dysfunctional family, and the dynamic was the same. My mother always had a declared enemy. Every so often she declared a new one. Often the previous enemy was now our ally. Questioning her shifts made you suspect, and a potential target. Being aligned with the order of the day was the best way to be in her good graces. And everyone wanted to be in her good graces.</p><p> The only way to consistently get it right, was to pay close attention to her. And follow her every mercurial shift.</p><p> Dictators do the same thing. Paying attention requires their followers to constantly consume targeted media content. Creating the perfect audience for System 1 targeted propaganda. That reinforces the followers&#39; desire to agree with the leader. Which makes each sudden shift even more effective as a demand for attention. And the bigger the shift, the more it reinforces for the followers that their reality is whatever the leader says.</p><p> Eventually people&#39;s desire to comply overcomes their sense of reality. Leading to the Orwellian reality that people really do believe the regime when it says, <i>&quot;We have always been at war with Oceana.&quot;</i></p><p> Trump also changes positions regularly. His opponents keep hoping that Trump&#39;s latest change in position will wake his followers up. That&#39;s wishful thinking. Mercurial behavior reinforces control. There is every reason to believe that it will continue working for Trump.</p><p> Someone using AI for propaganda can obviously simply manually decide when the AI should change positions. So AI does not need to figure this out for effective propaganda.</p><p> That said, I expect that ChatGPT could do an excellent job of deciding when to change positions. The ability to issue personalized appeals should let AI suck people into many small groups, and then manipulate those groups into a mass movement.</p><h2> Commit people with Cognitive Dissonance</h2><p> This was one of Donald Trump&#39;s key techniques for taking control of the Republican Party. Over and over again he humiliated opponents. Then he found opportunities to get them to support him. He amplified their statements of support to commit them to it. And then treated them generously.</p><p> This left his opponents with a problem. Why would they support someone who had treated them badly? Trump offered only one easy out. Accept that Trump truly is a great man. You deserved punishment before when you denied his greatness. Now that you&#39;ve seen the light, you deserve When you deny his greatness, you deserve punishment. Now that you&#39;ve admitted the truth, you deserve honor. And if you take this out, you&#39;ve just become his loyal supporter.</p><p> That explains why Ted Cruz <a href="https://www.bbc.com/news/av/world-us-canada-55540215">became Trump&#39;s ally</a> . It was not despite <a href="https://www.youtube.com/watch?v=LIl8AuMigyQ">Trump&#39;s humiliation of Cruz</a> , but because of it. <a href="https://specialto.thebulwark.com/p/the-corruption-of-lindsey-graham">The Corruption of Lindsey Graham</a> is an excellent in depth read on how another opponent became a devoted supporter. In the section <a href="https://specialto.thebulwark.com/p/trumps-best-friend">Trump&#39;s Best Friend</a> you see over and over again how Trump got Lindsey to compromise himself. The Kavanaugh section of <a href="https://specialto.thebulwark.com/p/power-shift-to-trump">Power Shift to Trump</a> shows when he completely and utterly became Trump&#39;s man.</p><p> Please note. This happened to intelligent elites who thought that they had a clear understanding of how they could be manipulated. Flipping them generally took Trump 2-3 years. And they&#39;ve stayed loyal since. Effective persuasion is not magic. It takes time. But conversely, we tend to underestimate we change over such periods of time. And therefore we overestimate how resistant we are to such persuasion.</p><p> An authoritarian leader can only get to so many people individually. Doing this at scale is harder. Groups have come up with many approaches. You can require public declarations from party members. Openly name and reward people who turn in friends and family. A cult like Scientology can give everyone individualized therapy with therapists trained to create cognitive dissonance. All of these use those who already converted to help convert more.</p><p> It seems unlikely that ChatGPT will match the best humans in the near term. I expect it to be better than most people. But a lot of people want to take control of major organizations such as a political party or country. Success requires many things to go your way, but is extremely unlucky unless you have exceptional skills. So a would-be authoritarian assisted by AI should personally develop this skill.</p><p> But what the AI lacks in individual ability, it makes up for in scale. Demagogues struggle with creating opportunities for cognitive dissonance in a mass audience. But AIs allow people to be individually monitored and manipulated. And if this technology is deployed on a mass level, this capability is an obvious target for improvement.</p><h2> Group Socialization</h2><p> We want to be part of groups. Then once we feel that we are, we naturally change our ideas to fit with the group. This is the source of groupthink.</p><p> These dynamics are easiest to see in cults. For example read<a href="https://articles1.icsahome.com/articles/brainwashing-and-the-moonies-galanti-csj-1-1-1984">Brainwashing and the Moonies</a> for how Moonies suck potential members in. Authoritarian regimes also use similar techniques. See <a href="https://www.amazon.com/Thought-Reform-Psychology-Totalism-brainwashing/dp/0807842532">Thought Reform and the Psychology of Totalism</a> for a detailed description.</p><p> All of these things work far better on people who are young and impressionable. My wife still talks about how effective the Soviet <a href="https://en.wikipedia.org/wiki/Pioneer_movement">Pioneer</a> organization was on her. Ukrainians today are struggling with the <a href="https://www.atlanticcouncil.org/blogs/ukrainealert/russias-mass-abduction-of-ukrainian-children-may-qualify-as-genocide/">mass abduction and brainwashing</a> of their children by Russia.</p><p> For Putin it wasn&#39;t a crazy idea to capture kids, brainwash them, then send them to fight against their parents. Totalitarian regimes have a lot of experience with brainwashing. He knew that it would reliably work, about how long it should take, and how to set up the program.</p><p> How can a would-be authoritarian use AI to help?</p><p> The biggest thing that I see is that social media is full of lonely people seeking community. Social media is very good at helping them find it. But, especially when controlled by AI, social media can choose which community for them to find. It can choose which messages get boosted, which get suppressed. Participants in the community may themselves be artificially created. Through those, AI can directly make suggestions for community building exercises to reinforce the dynamics. And, over time, AI can ensure that the other techniques are used to bind people to the group, then move the group to thinking what the AI wants.</p><h2> What Needs Improving?</h2><p> From a would-be dictator&#39;s point of view, current AI has some unfortunate limitations.</p><p> The biggest one is consistency. For example it is easy to create a chatbot to be your girlfriend. Unfortunately some fraction of conversations between a couple will lead to a breakup. Therefore there is a chance that <a href="https://www.myaiobsession.com/p/my-ai-girlfriend-broke-up-with-me">your AI girlfriend will break up with you</a> . Properly indoctrinating people takes more consistency that AI has.</p><p> The second one is memory. Using the same AI girlfriend example, people notice that, &quot;Replika has the memory of a goldfish.&quot;</p><p> I don&#39;t believe that either of these needs a fundamentally better LLM. Memory can be achieved by having the LLM summarize and save information, then at appropriate times re-read it back into memory and carry on. A variety of schemes are possible for this, and this is an area of active research. This problem is probably solvable for our potential AI-enabled future overlord.</p><p> Consistency can be addressed similarly. AI may not stay on message all of the time. But it can also be prompted behind the scenes to reload the prompt. Between having good prompts, and periodic reminders of what they are, we should achieve sufficient consistency to make the technology work.</p><p> Therefore I believe that both improvements can be achieved with better tooling around LLMs, without having fundamental improvements in LLM technology itself.</p><p> You may wonder why I am not worried about known AI weaknesses like prompt injection. The answer is simple. Authoritarian techniques just need to be good enough to work for large numbers of people. As long as they are accepted at an emotional level, logical flaws will dissuade people. Therefore being able to show people what is going on won&#39;t change their minds.</p><p> For example, consider what happened when fact checkers tried making rational arguments about how often Trump bends the truth. Trump supporters did not stop supporting Trump. Instead they came to distrust the fact checkers!</p><h2> Is This Already Happening?</h2><p> Probably?</p><p> The obvious social network to pick on is TikTok. It is controlled by China. China, obviously, is an authoritarian country with a deep understanding of authoritarian techniques. And they have direct access to the most eyeballs in the young adult audience - which historically has been the most desirable target group for indoctrination.</p><p> In the last month we&#39;ve had an entirely unexpected outburst of actual antisemitism worldwide. Jews are being libeled, murdered and assaulted all over the world, whether or not they personally support Israel. This is absolutely shocking for those of us who thought that antisemitism was dead and gone, a problem for other people far away from is in geography and/or time. And the age range where this is happening most obviously is the prime target for TikTok.</p><p> Was this outburst entirely a spontaneous social media phenomena, sparked by world events? Or has it been shaped behind the scenes with the help of AI? I have no real evidence either way, but I have my suspicions. I would be shocked if China wasn&#39;t trying to figure out how to create effects like this. And this is exactly what I&#39;d expect it to look like if they did. But it could have happened naturally. So they at least have plausible deniability.</p><h2> What About AI Safety?</h2><p> My opinion is entirely personal. I know very intelligent people who think oppositely from me. And so I encourage readers to make up their own mind.</p><p> I see AI safety as a PR effort by established tech companies aimed at getting government to create a regulatory moat for them. I&#39;m sure that many very sincere people are part of the AI safety community. But they will only get funding to the extent that tech likes what they say, and will only get listened to to the extent that politicians hear something that they want to hear.</p><p> I admit to having a prior bias for this opinion. I&#39;ve long been concerned about the ways in which regulatory capture allows established companies to take control of regulatory regimes for their own benefit. This inclines me to be suspicious when CEOs of companies who would most benefit from regulatory capture are proposing a new regulatory regime.</p><p> However I&#39;m not the only one with some level of cynicism. As an example, well known machine learning researcher Andrew Ng <a href="https://www.deeplearning.ai/the-batch/issue-220/">has doubts about AI safety</a> . And <a href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a> recently <a href="https://twitter.com/ESYudkowsky/status/1718654143110512741">said in a piece of fiction</a> :</p><blockquote><p> ...it&#39;s just a historical accident that &#39;AI safety&#39; is the name of the subfield of computer science that concerns itself with protecting the brands of large software companies from unions advocating that AIs should be paid minimum wage.</p></blockquote><p> So as you think about it, assign a prior to how likely it is that this is regulatory capture, versus a genuine concern. If you want to do it right, you should assign that prior per individual because it is almost certain that different participants have different motivations. Then make your own evaluations of which theory each action that they take more strongly supports one theory versus the other.</p><p> My prior starts off biased towards regulatory capture because I know how well-known the dynamic is in tech. And I see the financial incentives to think that way. My opinion has only been strengthened by proposed regulations. They seem to me to do more to make entering the market expensive than they do to solve real problems. This strengthens my opinion.</p><p> However my opinion would shift if I saw more concern about what I&#39;m discussing here. That is, thinking about how existing technology could take advantage of known flaws in humans. Rather than discussion of what shiny future technologies might create problems.</p><p> Your opinion may differ from mine for a variety of reasons. For example it seems obvious to me that people should be thinking along the lines that I outlined above. What could be more natural than that people should think the way that I do. But you may conclude that I&#39;m just weird in thinking the way that I do.</p><p> But, whatever you think of my potentially weird thinking, I hope that others at least find this an interesting thing to think about.</p><br/><br/><a href="https://www.lesswrong.com/posts/DdDKsyA925Sm8BpQh/ai-as-super-demagogue#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/DdDKsyA925Sm8BpQh/ai-as-super-demagogue<guid ispermalink="false"> DdDKsyA925Sm8BpQh</guid><dc:creator><![CDATA[RationalDino]]></dc:creator><pubDate> Sun, 05 Nov 2023 23:00:58 GMT</pubDate> </item><item><title><![CDATA[EA orgs' legal structure inhibits risk taking and information sharing on the margin]]></title><description><![CDATA[Published on November 5, 2023 7:13 PM GMT<br/><br/><h1> <strong>What is fiscal sponsorship?</strong></h1><p> It&#39;s fairly common for EA orgs to provide fiscal sponsorship to other EA orgs.  Wait, no, that sentence is not quite right. The more accurate sentence is that there are very few EA organizations, in the legal sense; most of what you think of as orgs are projects that are legally hosted by a single org, and which governments therefore consider to be one legal entity.</p><p> The king umbrella is Effective Ventures Foundation, which hosts CEA, 80k, Longview, EA Funds, Giving What We Can, Asterisk magazine, Centre for Governance of AI, Forethought Foundation, Non-Trivial, and BlueDot Impact. Posts on the castle <a href="https://forum.effectivealtruism.org/posts/xof7iFB3uh8Kc53bG/why-did-cea-buy-wytham-abbey?commentId=u3yJfbm2pes8TFpYX"><u>also describe it</u></a> as an EVF project, although it&#39;s not listed on the website. Rethink Priorities has a <a href="https://rethinkpriorities.org/news/announcing-special-projects"><u>program</u></a> specifically to provide sponsorship to groups that need it. LessWrong/Lightcone is hosted by CFAR, and have sponsored at least one project themselves (source: me. It was my project).</p><p> Fiscal sponsorship has a number of advantages. It gets you the privileges of being a registered non-profit (501c3 in the US) without the time-consuming and expensive paperwork. That&#39;s a big deal if the project is small, time-limited (like mine was) or is an experiment you might abandon if you don&#39;t see results in four months.  Even for large projects/~orgs, sharing a formal legal structure makes it easier to share resources like HR departments and accountants. In the short term, forming a legally independent organization seems like a lot of money and effort for the privilege of doing more paperwork.</p><p><br></p><h1> <strong>The downsides of fiscal sponsorship</strong></h1><p> …are numerous, and grow as the projects involved do.</p><p> The public is rightly suspicious about projects that share a legal entity claiming to be independent, so bad PR for one risks splash damage for all. The government is very confident in its belief that you are the same legal entity, so legal risks are shared almost equally (iamnotalawyer). So sharing a legal structure automatically shares risk. That may be fixable, but the fix comes at its own cost.</p><p> The easiest thing to do is just take fewer risks. Don&#39;t buy retreat centers that could be described as lavish. And absolutely, 100%, don&#39;t voluntarily share any information about your interactions with FTX, especially if the benefits to doing so are intangible. So some amount of value is lost because the risk was worth it for an individual or small org, but not to the collective.</p><p> [it is killing me that I couldn&#39;t follow the <a href="https://en.wikipedia.org/wiki/Rule_of_three_(writing)"><u>rule of three</u></a> with that list, but it turns out there aren&#39;t that many legible, publicly visible examples of decisions to not share information]</p><p> And then there are the coordination costs. Even if everyone in the legal org is okay with a particular risk, you now have an obligation to check with them. The answer is often “it&#39;s complicated”, which leads to negotiations eating a lot of attention over things no one cares that much about. Even if there is some action everyone is comfortable with, you may not find it because it&#39;s too much work to negotiate between that many people (if you know anyone who lived in a group house during covid: remember how fun it was to negotiate safety rules between 6 people with different value functions and risk tolerances?).</p><h2> <strong>Chilling effects</strong></h2><h3> <strong>A long, complicated (but nonetheless simplified)example</strong></h3><p> The original version of this story was one paragraph long. It went something like: A leader at an EVF-sponsored project wanted to share some thoughts on a controversial issue, informally but in public. The comments were not riskless, but this person would happily have taken the risk if it affected only themselves or their organization. Someone at EVF said no. Boo, grrr.</p><p> I sent that version to the source to check for accuracy. They gave me a new, more complicated story. Maybe it was good they never published those comments, because they were coming from an angry place. Maybe it was good they never published the initial version of those comments, but bad they didn&#39;t publish a draft revised after a good night&#39;s sleep. Maybe it&#39;s not fair to blame EVF, since they (commenter) gave up pretty quickly and maybe EVF would have said yes if they&#39;d kept pushing. Maybe that&#39;s all an excuse, and those comments were great and it was a tragedy they were lost…</p><p> It became clear there was no way to portray the story with the level of nuance the source wanted, without giving enough details to totally blow their anonymity. I offered to let them write out the whole thing in their words with their name on it. They considered it but didn&#39;t feel able to do so without checking with their colleagues, which would have further delayed things and eaten up multiple people&#39;s time. Especially because it would probably not have been a quick yes or no, it would have been more rounds of negotiation between people, all of whom were busy and didn&#39;t hold this as a priority…</p><p> I told them not to bother, because it was unnecessary. The fact that it is so difficult to share enough information to even figure out if the comments were net positive or negative, and how that would change if projects didn&#39;t share fiscal sponsorship, is already on display. So I wrote up this story of trying to share the  original example.</p><p><br></p><h3> <strong>Other examples</strong></h3><p> As <a href="https://www.lesswrong.com/posts/AocXh6gJ9tJC2WyCL/book-review-going-infinite?commentId=pFAYzGxGJgxFfwn4J"><u>reported</u></a> by Oliver Habryka: Will MacAskill has written up reflections on the SBF debacle, but EVF told him not to publish. </p><p><img src="https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/GRYFJGnye2gCxCTG4/ctisrjlrdlsxjo24ldni"></p><p> Luke Freeman, Executive Director at Giving What We Can, <a href="https://forum.effectivealtruism.org/posts/vXzEnBcG7BipkRSrF/how-has-ftx-s-collapse-impacted-ea?commentId=izNdDMjZb7r5Dxjsm"><u>said that</u></a> the EVF board ordered a cessation of the GWWC pledge drive in the wake of the FTX explosion, and explicitly ascribed this to the EVF board making a conservative rule and not having time to review exceptions. </p><p><img src="https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/GRYFJGnye2gCxCTG4/i6vve6wgej3ij8jgl7ja"></p><p> I object to this way less than to the censorship; not fundraising in the immediate wake of FTX seems like a pretty reasonable decision. But I expect the factors he brings up in defense of this decision, <a href="https://forum.effectivealtruism.org/posts/vXzEnBcG7BipkRSrF/how-has-ftx-s-collapse-impacted-ea?commentId=BHTwaSmL2j4rmgCDg"><u>risk to sister projects</u></a> and bandwidth limitations, to be systemic.</p><h2> <strong>Confusion tolerance</strong></h2><p> There&#39;s another issue with fiscal sponsorship. I think it&#39;s minor compared to the chilling effect on risk taking, but still worth mentioning. One side effect of sharing a legal structure is that people doing business with project P (eg 80k, or Longview) will receive checks, invoices, or other paperwork that uses the name of sponsoring organization O (eg EVF). This might look sketchy at first, but then someone explains fiscal sponsorship to you and you accept it.</p><p> Which is why it didn&#39;t raise any alarm bells for me when my first check from “the FTX Future Fund (regrantor program)” came via CEA, and the second used the name North Dimensions.  I&#39;ve gotten lots of checks that didn&#39;t match the organization&#39;s name, so I mumbled something about EA&#39;s lack of professionalism and moved on with my day. What has come out since is that North Dimensions was a pre-existing company FTX bought in order to use its bank account, and that <a href="https://news.yahoo.com/north-dimension-central-misappropriation-ftx-133000733.html"><u>bank account was shared</u></a> between FTX and Alameda in ways that have to have been inappropriate.</p><p> [Note: I haven&#39;t attempted to nail down the details of that bank account or my grants and may have gotten something wrong. I don&#39;t think any individual error would contradict my claim that training people to accept misdirection creates cover for malfeasance. The fact that the situation breeds errors is the point.]</p><h1><br><strong>结论</strong></h1><p>I think EA should grapple with the risk creation and risk aversion caused by fiscal sponsorship, especially umbrella orgs, and how those trade-off against the benefits. This is hard because the benefits of sponsorship are legible and predictable, and the costs are nebulous and erratic. But that makes it all the more important to deliberately investigate them. My guess is that this will show that having multiple large orgs share a legal structure is not worth it, but using sponsorship for short term projects or a launching pad will continue to make sense. Maybe I&#39;m wrong though, we can&#39;t know until we check.</p><p><br></p><br/><br/> <a href="https://www.lesswrong.com/posts/XvEJydHAHk6hjWQr5/ea-orgs-legal-structure-inhibits-risk-taking-and-information#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/XvEJydHAHk6hjWQr5/ea-orgs-legal-structure-inhibits-risk-taking-and-information<guid ispermalink="false"> XvEJydHAHk6hjWQr5</guid><dc:creator><![CDATA[Elizabeth]]></dc:creator><pubDate> Sun, 05 Nov 2023 19:13:58 GMT</pubDate> </item><item><title><![CDATA[Eric Schmidt on recursive self-improvement]]></title><description><![CDATA[Published on November 5, 2023 7:05 PM GMT<br/><br/><p> Recently, Eric Schmidt gave a talk at Harvard called “Our AI Future: Hopes and Hurdles Ahead”. The entire talk is available <a href="https://www.youtube.com/watch?v=IeVY_Ag8JI8"><u>here</u></a> but there was one part that was interesting to me (around the 1:11:00 mark), and that is, his views on AI safety and trust in AI labs to stop scaling if recursive self-improvement starts happening. <strong>Emphasis my own.</strong></p><blockquote><p> The technical term is recursive self-improvement. <strong>As long as the system isn&#39;t busy learning on its own, you&#39;re okay.</strong> I&#39;ll parrot Sam&#39;s speech at OpenAI. [...]</p><p> In the next few years we&#39;ll get to AGI [...] Some number of years after that, the computers are going to start talking to each other, probably in a language that we can&#39;t understand, and collectively their superintelligence [...] is going to rise very rapidly. <strong>My retort to that is, do you know what we&#39;re going to do in that scenario? We&#39;re going to unplug them all.</strong></p><p> The way you would do this if you were an evil person [...] is you would simply say to the computer: “Learn everything. Try really hard. Start right now.” So the computer starts learning. It learns about French, it learns about science, it learns about people, it learns about politics. It does all of that, and at some point, it learns about electricity and it learns that it needs electricity, and it decides it needs more. So it hacks into the hospital and takes the electricity from the hospital to give it to itself.</p><p> That&#39;s a simple example of why this is so dangerous. <strong>Most people in the industry who thought about this believe that when you begin recursive self-improvement, there will be a very serious regulatory response</strong> because of these issues. And that makes sense to me.</p></blockquote><br/><br/> <a href="https://www.lesswrong.com/posts/cLC2HcQbFZ5pFAgqC/eric-schmidt-on-recursive-self-improvement#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/cLC2HcQbFZ5pFAgqC/eric-schmidt-on-recursive-self-improvement<guid ispermalink="false"> cLC2HcQbFZ5pFAgqC</guid><dc:creator><![CDATA[nikola]]></dc:creator><pubDate> Sun, 05 Nov 2023 19:05:16 GMT</pubDate> </item><item><title><![CDATA[Pivotal Acts might Not be what You Think they are]]></title><description><![CDATA[Published on November 5, 2023 5:23 PM GMT<br/><br/><p> <em>This article is mainly for people who have not read the <a href="https://arbital.com/p/pivotal/">pivotal act</a> article on arbital or need a refresher. If you have, the most interesting section would probably be &quot;Omnicient ML Researchers: A Pivotal Act without a Monolithic Control Structure&quot;.</em></p><p> Many people seem to match the concept of a &quot; <a href="https://arbital.com/p/pivotal/">pivotal act</a> &quot; to some dystopian version of &quot;deploy AGI to take over the world&quot;. &#39;Pivotal act&#39; <a href="https://www.lesswrong.com/posts/PKBXczqhry7iK3Ruw/pivotal-acts-means-something-specific">means something much more specific</a> , though. Something, arguably, quite different. I strongly recommend you read the <a href="https://arbital.com/p/pivotal/">original article</a> , as I think it is a very important concept to have.</p><p> I use the term quite often, so it is frustrating when people start to say very strange things, such as &quot;We can&#39;t just let a powerful AI system loose on the world. That&#39;s dangerous!&quot; as if that were the defining feature of a pivotal act.</p><p> As the original article is quite long let me briefly summarize what I see as the most important points.</p><h1> Explaining Pivotal Act</h1><p> An act that puts us outside of the existential risk danger zone (especially from AI), and into a position from which humanity can flourish is a pivotal act.</p><p> Most importantly that means a pivotal act needs to prevent a misaligned AGI from being built. Taking over the world is really not required per se. <em>If you can</em> prevent the creation of a misaligned AGI by creating a powerful global institution that can effectively regulate AI, then that counts as a pivotal act. <em>If</em> I could prevent a misaligned AGI from ever being deployed, by eating 10 bananas in 60 seconds, then that would count as a pivotal act too!</p><h2> Preventing Misaligned AGI Requires Control</h2><p> Why then, is &#39;pivotal act&#39; often associated with the notion of taking over the world? Preventing a misaligned AGI from being built, is a tough problem. Efficively we need to constrain the state of the world such that no misaligned AGI can arise. To successfully do this you need a lot of control over the world. There is no way around that.</p><p> Taking over the world really means putting oneself into a position of high control, and in that sense, it is necessary to take over the world, at least to a certain extent, to prevent a misaligned AGI from ever being built.</p><h1> Common Confusions</h1><p> Probably, one point of confusion is that &quot;taking over the world&quot; has a lot of negative connotations associated with it. Power is easy to abuse. Putting an entity <sup class="footnote-ref"><a href="#fn-Xn4vF9NdExCw5SXra-1" id="fnref-Xn4vF9NdExCw5SXra-1">[1]</a></sup> into a position of great power can certainly go sideways. But I fail to see the alternative.</p><p> What else are we supposed to do instead of controlling the world in such a way that no misaligned AGI can ever be built? The issue is that many people seem to argue, that giving an entity a lot of control over the world is a pretty terrible idea, <em>as if</em> there is some better alternative we can fall back onto.</p><p> And then they might start to talk about how they are more hopeful about AI regulation as if pulling off AI regulation successfully does not require an entity that has a great deal of control over the world.</p><p> Or worse, they name some alternative proposal like figuring out mechanistic interpretability, <em>as if</em> figuring out mechanistic interpretability is identical to putting the world into a state where no misaligned AGI can arise. <sup class="footnote-ref"><a href="#fn-Xn4vF9NdExCw5SXra-2" id="fnref-Xn4vF9NdExCw5SXra-2">[2]</a></sup></p><h1> Pivotal acts that don&#39;t directly create a position of Power</h1><p> There are pivotal acts that don&#39;t require you to have a lot of control over the world. However, any pivotal acts I know of will still ultimately need to result in the creation of some powerful controlling structure. Starting a process that will ultimately result in the creation of the right controlling structure that can prevent misaligned AGI would already count as a pivotal act.</p><h2> Human Upload</h2><p> An example of such a pivotal act is uploading a human. Imagine you knew how to upload yourself into a computer, running 1,000,000 times faster, and being able to make copies of yourself while having perfect read-and-write access to your own brain. Then you could probably gain sufficient control over the world directly, such that you could mitigate all potential existential risks. Alternatively, you probably could just solve alignment.</p><p> In any case, uploading yourself would be a pivotal act, even though that would not directly put the world into a state where no misaligned AGI can arise.</p><p> That is because uploading yourself is enough to ensure with a very high probability that the state of the world where no misaligned AGI can arise will soon be reached. But that state will still feature some entity with a lot of control over the world. Either that entity is you in the case where you put yourself into a position of power, or an aligned AGI, in the case where you choose to solve alignment</p><h2> Omnicient ML Researchers: A Pivotal Act without a Monolithic Control Structure</h2><p> There are also pivotal acts that don&#39;t result in the creation of a monolithic entity that is in control. Control may be distributed.</p><p> Imagine you could write an extremely mimeticly fit article that is easy to understand and makes everybody who reads it understand AI alignment so well that it would become practically impossible for them to build a misaligned AGI on accident. That would count as a pivotal act. Like in the &quot;Human Upload&quot; pivotal act, you don&#39;t need a lot of control over the world to pull this off. Once you have the article you just need an internet connection.</p><p> Not only do you not need a lot of control over the world, but there is also no central controlling entity in this scenario. The controlling structure is distributed across the brains of all the people who read the article. All these brains together now constrain the world such that no misaligned AGI can arise. Or you could think of it as us having constrained the brains such that they will not generate a misaligned AGI. That effectively means that no misaligned AGI can arise, assuming that the only way it could arise is through being generated by one of these brains. </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-Xn4vF9NdExCw5SXra-1" class="footnote-item"><p> This could be an organization, a group of people, a single individual, etc. <a href="#fnref-Xn4vF9NdExCw5SXra-1" class="footnote-backref">↩︎</a></p></li><li id="fn-Xn4vF9NdExCw5SXra-2" class="footnote-item"><p> Of course mechanistic interpretability might be an important piece for putting the world into a state where no misaligned AGI can arise. <a href="#fnref-Xn4vF9NdExCw5SXra-2" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/MtkcDDf2ZPvFk4jtN/pivotal-acts-might-not-be-what-you-think-they-are#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/MtkcDDf2ZPvFk4jtN/pivotal-acts-might-not-be-what-you-think-they-are<guid ispermalink="false"> MtkcDDf2ZPvFk4jtN</guid><dc:creator><![CDATA[Johannes C. Mayer]]></dc:creator><pubDate> Sun, 05 Nov 2023 17:23:51 GMT</pubDate> </item><item><title><![CDATA[The Assumed Intent Bias]]></title><description><![CDATA[Published on November 5, 2023 4:28 PM GMT<br/><br/><p> Summary: when thinking about the behavior of others, people seem to have a tendency to assume clear purpose and intent behind it. In this post I argue that this assumption of intent quite often is incorrect, and that a lot of behavior exists in a gray area where it&#39;s easily influenced by subconscious factors.</p><p> This consideration is not new at all and relates to many widely known effects such as the <a href="https://www.lesswrong.com/tag/typical-mind-fallacy"><u>typical mind fallacy</u></a> , the <a href="https://en.wikipedia.org/wiki/False_consensus_effect"><u>false consensus effect</u></a> , black and white thinking and the concept of <a href="https://www.lesswrong.com/posts/reitXJgJXFzKpdKyd/beware-trivial-inconveniences"><u>trivial inconveniences</u></a> . It still seems valuable to me to clarify this particular bias with some graphs, and have it available as a post one can link to.</p><p> Note that “assumed intent bias” is not a commonly used name, as I believe there is no commonly used name for the bias I&#39;m referring to.</p><h2> The Assumed Intent Bias</h2><p> Consider three scenarios:</p><ol><li> When I quit my previous job, I was allowed to buy my work laptop from the company for a low price and did so. Hypothetically the company&#39;s admins should have made sure to wipe my laptop beforehand, but they left that to me, apparently reasoning that had I had any intent whatsoever to do anything shady with the company&#39;s data, I could have easily made a copy prior to that anyway. So they further assumed that anyone without a clear intention of stealing the company&#39;s data would surely do the right thing then, and wipe the device themselves.</li><li> At a different job, we continuously A/B-tested changes to our software. One development team decided to change a popular feature, so that using it required a double click instead of a single mouse click. They reasoned that this shouldn&#39;t affect feature usage of our users, because anyone who wants to use the feature can still easily do it, and nobody in their right mind would say “I will use this feature if I have to click once, but two clicks are too much for me!”. (The A/B test data later showed that the usage of that feature had reduced quite significantly due to that change)</li><li> In debates about gun control, gun enthusiasts sometimes make an argument roughly like this: gun control doesn&#39;t increase safety, because potential murderers who want to shoot somebody will find a way to get their hands on a gun anyway, whether they are easily and legally available or not. <span class="footnote-reference" role="doc-noteref" id="fnref341qb7a53lj"><sup><a href="#fn341qb7a53lj">[1]</a></sup></span></li></ol><p> These three scenarios all are of a similar shape: Some person or group (the admins; the development team; gun enthusiasts) make a judgment about the potential behavior (stealing sensitive company data; using a feature; shooting someone) of somebody else (leaving employees; users; potential murderers), and assume that the behavior in question happens or doesn&#39;t happen <i>with full intentionality</i> .</p><p> According to this view, if you plotted the number of people that have a particular level of intent with regards to some particular action, it may look somewhat like this: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/i4WsKvFYEMdya94DW/bwd2dywtxaddr73goqox"><figcaption> The assumed intent bias: assuming that every person out there has a clear intention to act in a certain way (value of 1 on the x axis), or not to act in that way (value of 0). Eg a product designer may assume that every user who uses their product has a clear idea of what they want to achieve, and how to use the software to do so, so the user will have a plan in mind that either involves using a particular feature or not.</figcaption></figure><p> This graph would represent a situation where practically every person either has a strong intention to act in a particular way (the peak on the right), or to <i>not</i> act in that way (peak on the left).</p><p> And indeed, in such a world, relatively weak interventions such as <i>“triggering a feature on double click instead of single click”</i> , or <i>“making it more difficult to buy a gun”</i> may not end up being effective: while such interventions would move the action threshold slightly to the right or left, this wouldn&#39;t actually change people&#39;s behavior, as everyone stays on the same side of the threshold. So everybody would still act in the same way they would otherwise. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/i4WsKvFYEMdya94DW/dsmw2etaomnriiqvkunw"><figcaption> In the world of the assumed intent bias, weak interventions that slightly move the action threshold don&#39;t really matter: people are far away from that middle area of indecision, so they remain unaffected by the intervention.</figcaption></figure><p> However, I think that in many, if not most, real life scenarios, the graph actually looks more like this: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/i4WsKvFYEMdya94DW/t1v49oqkl6x30jhr2zlj"><figcaption> Sometimes most people have a somewhat clear intent, but still there&#39;s a considerable number of people existing in between as well. An example may be vegetarianism: most people have a strong intention to eat meat (left peak), while vegetarians have a strong intention not to eat meat (right peak). But there&#39;s surely some number of people who are somewhere in between, “on the edge” so to speak – for those, weak interventions might make the difference between them actually deciding to go vegetarian or not.</figcaption></figure><p> Or even this: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/i4WsKvFYEMdya94DW/g2dugw8ozdcyavwbxqd2"><figcaption> In some cases, the majority of people may even not care that much at all about some behavior, and hence have no clear intent in either direction. An example of this may be which brand of napkins people buy. While there are surely some people who either love or hate any given napkin brand, most people will just buy whichever is easiest available to them, so even small interventions such as the placement in the store, the color of the packaging, or small differences in pricing, can shift people&#39;s behaviors.</figcaption></figure><p> In these cases, only a relatively small number of people have a clear and strong intention with regards to the behavior, and a lot of people are somewhere in between. Here it gets apparent that even subtle interventions have an impact: moving the action threshold even slightly to either direction will mean that some people will now end up on the other side of the threshold than before – their intention was just weak enough that adding a tiny additional inconvenience will now avert them from that behavior, or vice versa, their intention was just strong enough that making the action a tiny bit easier causes them to now follow that behavior. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/i4WsKvFYEMdya94DW/byk3khmfz3uxxln98uja"><figcaption> If some people don&#39;t have a clear intention but are distributed over the whole spectrum of possible levels of intent, this means that even small changes to the action threshold (such as making the behavior in question very slightly easier/more difficult/more obvious/less appealing/…) will have real effects on people&#39;s behavior. The people in the area marked red would now end up on the other side of the action threshold, so they are affected by the intervention, even though people may not even be consciously aware of that fact.</figcaption></figure><p> The impact of such interventions then depends on the distribution of people&#39;s intent levels: the more people are undecided and/or don&#39;t care about the given behavior, the greater the number of individuals that will react to interventions that move the threshold.</p><p> Of course, and I think this is partially where this fallacy is coming from, such cases are not as salient, and more difficult to imagine. It&#39;s easy to think of a person who clearly wants to use a given feature of my software, or one who doesn&#39;t need that feature. But what does a user look like who uses the feature when it requires a single click, but doesn&#39;t use the feature if it requires a double click? Clearly the data shows that these people exist, but I couldn&#39;t easily point to a single person for whom that intervention is decisive in determining their behavior. What&#39;s more, these people themselves are probably not even aware that this minor change affected them.</p><h2> How to Avoid the Assumed Intent Bias</h2><p> As with many biases, <i>knowing</i> the assumed intent bias is half the battle. In my experience the most common way in which people fall victim to this bias is when they argue that certain environmental changes, eg affecting how convenient or easy or obvious it is to follow some particular behavior, will not have any impact on how people actually behave. This view makes sense only when you assume the naive view of every person having clear intent with regards to that action. But it falls apart when taking into account that in most scenarios people are actually distributed over the whole spectrum of intention levels.</p><p> Software development and policy are domains in which this bias occurs rather frequently. But it basically affects any area that deals with influencing (or understanding) the behavior of others.</p><p> If you&#39;re aware of the importance of <a href="https://www.lesswrong.com/posts/reitXJgJXFzKpdKyd/beware-trivial-inconveniences"><u>trivial inconveniences</u></a> and are used to <a href="https://www.spencergreenberg.com/2020/06/three-types-of-nuanced-thinking/"><u>nuanced thinking</u></a> , then you&#39;re probably on the safe side. But it still doesn&#39;t hurt to stay on the lookout for people (including yourself) arguing about the intentions of unidentified others. And if this happens, be aware that it&#39;s easy to assume intent where there is little.</p><p><br> A lack of intent – in this case meaning being close to 0.5 on the graphs above – can mean at least two things: that people are simply undecided about something, or that they are unaware and/or don&#39;t care. Most people don&#39;t care to the same degree about what you care about. If I&#39;ve been working for Generic Napkin Company for years and love the product, then it&#39;s easy for me to assume that most of our customers also care deeply about our product. It might not occur to me that the vast majority of customers who buy the product <i>don&#39;t even know my company&#39;s name</i> , and would barely notice if their store decided to replace the product with that of a competing brand. They don&#39;t waste a second thought on these napkins – they just buy them because it is the convenient and simple thing to do, and then they forget about it. And while this is not necessarily representative of most other decisions humans make, it still probably doesn&#39;t hurt to realize that most people care much less about the decisions that we care about while we are thinking about how to change other people&#39;s behavior. </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn341qb7a53lj"> <span class="footnote-back-link"><sup><strong><a href="#fnref341qb7a53lj">^</a></strong></sup></span><div class="footnote-content"><p> Of course this is not the only or even the main argument; I&#39;m not meaning to make any argument for or against gun control here, but just point out that one particular argument is flawed</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/i4WsKvFYEMdya94DW/the-assumed-intent-bias#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/i4WsKvFYEMdya94DW/the-assumed-intent-bias<guid ispermalink="false"> i4WsKvFYEMdya94DW</guid><dc:creator><![CDATA[silentbob]]></dc:creator><pubDate> Sun, 05 Nov 2023 16:28:03 GMT</pubDate> </item><item><title><![CDATA[Go flash blinking lights at printed text right now]]></title><description><![CDATA[Published on November 5, 2023 7:29 AM GMT<br/><br/><ol><li> Install a strobe light app on your phone (I used &quot;strobe light tachometer&quot; on ios.)</li><li> Get some printed text like a nutrition label or a paper book</li><li> Try to read the text with the light blinking at 5, 6, 7, 8, 9, 10, 11, 12, and 13 hz</li><li> Report results. Was reading with one frequency much easier than the others? Easier than with normal constant light? Were they all terrible?</li></ol><hr><p> I just tried this and my eyes totally glazed over for everything except 12! I was feeling kinda tired and unfocused when I started and 12 was easier than baseline for me. Although annoying. I have incandescent lights in my kitchen. I did not turn them off. The phone light was brighter than the incandescent light.</p><p> Framerate stuff:</p><ul><li> Phone flashlights are not meant to blink really fast (and max frequency is not documented) but the app seemed to work ok. I did notice an irregularity here and there but I don&#39;t think that 12 being an even divisor of the flashlight frequency or something mattered.</li><li> If you have a 60hz monitor, then your screen can do a strobe light with 12, 10, 8.6, 7.5, or 6.7 hz. This is not very good resolution. A 120hz monitor should be good enough.</li><li> Would be better to test with a dedicated strobe light so this is not an issue.</li></ul><p> More info about this experiment on first item <a href="https://www.astralcodexten.com/p/quests-and-requests">here</a></p><br/><br/> <a href="https://www.lesswrong.com/posts/diohDcgu3YdSbHd3j/go-flash-blinking-lights-at-printed-text-right-now#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/diohDcgu3YdSbHd3j/go-flash-blinking-lights-at-printed-text-right-now<guid ispermalink="false"> diohDcgu3YdSbHd3j</guid><dc:creator><![CDATA[lukehmiles]]></dc:creator><pubDate> Sun, 05 Nov 2023 07:29:44 GMT</pubDate></item></channel></rss>