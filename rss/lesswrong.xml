<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 16 日星期四 10:13:07 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Learning coefficient estimation: the details]]></title><description><![CDATA[Published on November 16, 2023 3:19 AM GMT<br/><br/><h2>这是做什么用的</h2><p>学习系数 (LC) 或 RLCT 是奇异学习理论中的一个量，可以帮助量化深度学习模型的“复杂性”等。</p><p>本指南主要旨在帮助有兴趣改进学习系数估计的人们快速了解其幕后工作原理。如果您只是尝试在自己的项目中使用 LC，则可以在不了解所有详细信息的情况下使用该<a href="https://github.com/timaeus-research/devinterp/tree/main">库</a>，尽管本指南可能仍然有帮助。如果您还没有阅读<a href="https://www.lesswrong.com/posts/6g8cAftfQufLmFDYT/you-re-measuring-model-complexity-wrong">本文</a>，强烈建议您先阅读这篇文章。</p><p>我们主要介绍<a href="https://jmlr.org/papers/volume14/watanabe13a/watanabe13a.pdf">WBIC 论文</a>（Watanabe 2010），它是当前 LC 估计技术的基础，但这里的演示是原创的，旨在获得更好的直觉，并且与论文有很大不同。我们还将简要介绍<a href="https://arxiv.org/abs/2308.12108">Lau 等人。 2023年</a>。</p><p>尽管讨论很长，但您最终在实践中所做的事情<i>非常简单</i>，并且代码旨在强调这一点。经过一些相对快速的设置后，实际的 LC 计算可以通过一两行代码轻松完成。</p><h2>这不是为了啥</h2><ul><li>对 SLT 的良好概述，或者首先研究 LC 或损失景观卷背后的动机。我们在这里主要关注 LC 估计。</li><li>抽样细节。这些非常重要！但它们并不是单一学习理论所独有的，并且在其他地方有大量有关 MCMC 的优质资源和教程。</li><li>公式推导，超越高级推理。</li></ul><h2>总长DR</h2><ul><li>什么是学习系数？ （<a href="https://www.lesswrong.com/posts/6g8cAftfQufLmFDYT/you-re-measuring-model-complexity-wrong">上次</a>回顾）<ul><li>学习系数 (LC) 也称为 RLCT，用于衡量盆地宽度。</li><li>这并不新鲜，但通常“盆地宽度”被操作为“盆地平坦度”——即通过 Hessian 行列式。当模型是奇异的（Hessian 矩阵的特征值为零）时，这是一个坏主意。</li><li> LC 将“盆地宽度”操作为（低损耗渐近）体积缩放指数。正如奇异学习理论所证明的那样，这最终是正确的衡量标准。</li></ul></li><li>我们如何衡量它？<ul><li>事实证明，直接测量高维体积是很困难的。我们不做这个。</li><li>相反，我们使用 MCMC 进行统计学中所谓的“矩量法”估计。我们设计一个以 LC 作为总体参数的分布，从该分布中采样并计算其矩之一，并求解 LC。</li><li>我们在本节中简化了一些细节，但这是 LC 估计的概念核心。</li></ul></li><li>我们如何衡量它（真实的）？<ul><li>上面的内容稍微简化了一些。 LC 确实测量损失量缩放，但它使用的“损失”是经验损失函数的平均值或“无限数据”限制。</li><li>实际上，您不知道这个无限数据丢失函数。幸运的是，您已经对它有了一个很好的估计——您的经验损失函数。不幸的是，这个估计并不完美——它可能有一些噪音。事实证明，这种噪音实际上在您<i>最不</i>想要的地方最<i>严重</i>。</li><li>但最终一切都会解决！实际上，您只需要对“理想化”算法进行一点小小的修改，一切就可以正常工作。这将为您提供一个在实践中真正有效的算法！</li><li>最后，出于可扩展性等原因，最先进的方法（Lau et al. 2023）做了一些简单的修改：它仅<i>*本地*</i>测量学习系数，并使用小批量损失而不是全损失。批。</li></ul></li></ul><p>以图表的形式：当我们从理想化（顶部）转向现实（底部）时，我们会得到新的问题、解决方案和改进方向。该指南本身最详细地介绍了前两行，这可能是概念上最难思考的，并在最后直接从第二行跳到第四行。 </p><figure class="image image_resized" style="width:100%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9ecpBaAiGQnkmX9Ex/fmppl7bmgijkwtx7lnbh"></figure><p></p><p><i>请参阅</i><a href="https://colab.research.google.com/github/zfurman56/intro-lc-estimation/blob/main/Intro_to_LC_estimation.ipynb"><i>链接的 Colab 笔记本</i></a><i>以获取完整指南。</i></p><br/><br/> <a href="https://www.lesswrong.com/posts/9ecpBaAiGQnkmX9Ex/learning-coefficient-estimation-the-details#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9ecpBaAiGQnkmX9Ex/learning-coefficient-estimation-the-details<guid ispermalink="false"> 9ecpBaAiGQnkmX9Ex</guid><dc:creator><![CDATA[Zach Furman]]></dc:creator><pubDate> Thu, 16 Nov 2023 03:19:09 GMT</pubDate> </item><item><title><![CDATA[Extrapolating from Five Words]]></title><description><![CDATA[Published on November 15, 2023 11:21 PM GMT<br/><br/><p>如果你只能用<a href="https://www.lesswrong.com/posts/4ZvJab25tDebB8FGE/you-get-about-five-words">五个词</a>来表达一个想法，人们会从这五个词中推断出什么？您可以使用法学硕士通过实验来发现人们可能认为这五个词的含义，而不是猜测。您可以使用它来迭代您想说的五个单词，以便最好地传达您的预期含义。</p><p>我产生这个想法是因为我尝试要求克劳德在链接上总结一篇文章。 Claude 不会跟踪链接，因此它会幻觉标题中的摘要，该摘要包含在 URL 路径中。这是使用<a href="https://www.lesswrong.com/posts/LkjpHGiELQzed8hdu/why-the-problem-of-the-criterion-matters">我的 LessWrong 帖子之一</a>执行此操作的示例： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/bmhkdtwhkyjakvokjf8o" alt="" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/slx0yvnxmtj5fhhbonfl 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/i4hsanmguhbqxeubhcgd 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/sbhdvppzm36adnjmzf0j 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/onfbpkewjhbcvp82t5nc 680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/ooochb4zyqwvu9nbkait 850w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/gyfckyk0nkrp37ysfj6m 1020w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/ocvikzsm8zsgwgxlwbc9 1190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/bwjocv054qp6xzz7n2mr 1360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/z2cdhnfimjqy5iydhhjs 1530w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/ubotioxkb9gkckqmobaj 1638w"></figure><p>它产生了一些错误的细节，并遗漏了帖子中实际存在的许多细节，但这里并不是完全不合时宜。如果我的〜五个词是“标准问题很重要”，那么这将是我为什么这么说的合理推断。</p><p>除了使用链接之外，我还可以要求 Claude 提出它认为我会在具有特定标题的帖子中添加的内容： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/r1w6ub2kairpaylby2ya" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/vpuvlg0a2qxs02d9a8mh 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/gd1asogssvzjvtme7zzx 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/lr2zcthp13guf9fiheci 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/veszm5ofcocu4ycc8m3b 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/b9bbmyxfbj5vhgqwefcz 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/s6ntzjebigweykpebss7 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/t53x7vzvjuzseje3ogpq 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/fehqezg1cmuzigwpn8e3 1280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/n6359ek9mzuw9un5gtgy 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/bkwlgtvdtbnazl3cfnrd 1586w"></figure><p>奇怪的是，它在某些方面表现得更糟，而在其他方面表现得更好。与它产生链接摘要的幻觉不同，这次它提出了我绝对不会说或不希望有人得到的东西，比如我们可以解决标准问题，足以拥有客观的知识标准。</p><p>但也许促使它关注 LessWrong 才是问题所在，因为 LessWrong 引起了很多实证主义者的共鸣，<a href="https://www.lesswrong.com/posts/dTkWWhQkgxePxbtPE/no-logical-positivist-i">但埃利以泽的相反说法</a>并不成立。所以我尝试了不同的提示： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/xrpj3qaqn7suizcevhys" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/k9x2qujwgkf0metacypy 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/bpm1a2ggpidjlcsqwesd 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/zd59kndoaw4wxykeycyy 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/nqnrhxxvr8huxcay1u32 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/pn6l2shzgwq8ql0obr4n 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/bctwvfofjgkjzck0nqq1 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/hkmze9rfpylwqklxnklq 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/jzz0ty1oy4tlrqc4bhjr 1280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/hb3mb6kehxcpipzf6rab 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/jjmgmqa2khno1ugfbhox 1578w"></figure><p>这可以？这不太好。这听起来像是一个无聊的哲学本科生为认识论课写的论文的总结。</p><p>让我尝试问它一些版本的“我的〜五个词是什么意思？”： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/lkewxseua3vdb05j7toe" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/wtbbd1ubjfieqi5v5w54 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/fyqopidgidzeckrmi3tt 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/dv7skp8zycwv5qhs4njh 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/qanzrbxq4kwjyb3ysyyq 680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/mai1kzmoyu3ar1aju9xa 850w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/w5lpbsgulhtld3oa1vi3 1020w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/lszilosu5mu0wwnxnvpn 1190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/nvjhfugeemp0z6idhzsu 1360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/iixmdvneheblpgyl1a8i 1530w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/xankmu5wloylpm307klo 1614w"></figure><p>这非常好，基本上我希望有人能从我身上夺走“标准问题很重要”的东西。让我们看看如果我调整语言会发生什么： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/yqb2ijarrst9jsfx5gjd" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/eut3fmkm8shlcbcug5g0 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/pyw3pnoail6yj83xkgnd 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/qp9yniwnn0oojpw6ezvj 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/lh501i7swrx2som5cnqt 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/gana511ysgdqyjp70wgl 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/v8x1sgfssqcwx2b8rihc 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/uldogbpsdoiadnic0dml 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/q0qfpikhfmxrrvpw3ade 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/lzttdsrr3vwed4oltack 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/mcyq8xocefuh244rj9bj 1780w"></figure><p>整洁的！它注意到了“重要”而不是“重要”所暗示的许多细微差别。这对于尝试短语的不同变体以查看这些微小变体对隐含含义有何变化非常有用。我认为这对于诸如文字加工公司价值观和使命以及其他每个单词都必须承载很多含义的短语等任务很有用。</p><p>现在让我们看看它是否可以反向完成任务！ </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/sxgabqz0wyvvx4lxwhje" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/ov7pj5rakxa9pjqjxrs6 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/qitt5xg5d5aoetcfvfe2 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/ongwefldjntxhgrqtaq1 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/tudmg2sfnqjq2gqjrydl 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/is0bducapbzwva9zyax4 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/u8xa7utkyqizzg9zqe37 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/ehjtaxuk5tfp3eganyln 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/f47objdkzzxsnxdar3sj 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/jmvyyc0rhfola1dljksj 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/pdgspb42zyihzi6pikad 1726w"></figure><p>老实说，“不确定性破坏知识”可能比我想出的任何东西都要好。谢谢，克劳德！</p><p>作为最后的检查，克劳德能否从自己的总结中推断出来？ </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/y2pf0udioglx0qsdhpv6" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/fdi6zhj1wtfivqlqcpuf 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/ouxcagejqzlqzcphlhzd 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/jz3tiot9xgm5gl15hbls 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/etynfz3izydbggskkzfi 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/bdsy7bzo33ahduse7o5j 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/q4ws7lixelgpvecilntf 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/zail1zfcfpngok6rmbom 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/q9qjxw72otwkfpbihcq7 1280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/etkhvvkopnnoailb3ae1 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/qrkgidttighy0hl474d8 1586w"></figure><p>显然，它丢失了一些细节，特别是关于标准问题的细节，并且弥补了一些我不想让它得到的东西。将细致入微的信息压缩成大约五个单词，并且仍然传达信息的核心，这似乎是理所当然的。</p><p>好吧，最后的测试，克劳德可以从我可能对我最喜欢的话题“基本不确定性”所做的典型陈述中推断出什么？ </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/dc6roac8u3oskbx4zwmk" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/ako6peikfk1vdblnddfu 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/dh0yunove6oo8e4fhk3y 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/mqhewctspnzhqsxqtjkw 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/dp3x6bfuj6if7ryfcxzn 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/ve9l0vltshrvuy5dfgqr 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/bzhau52vnet9ehltdd9f 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/ogyqa2awhac3kkorgliz 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/ceudntk6ndseqfz6xewg 1280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/x0elkg9cjhej9iblmcgh 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/hclfjabiodfwlfnxnaz6 1570w"></figure><p>嗯，还可以，但不是很好。也许我应该尝试找到另一个短语来表达我的想法？让我们看看它对“基本面不确定性”这个书名的看法： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/swabayitctg8yc2odybb" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/jrn6yiiqgufmxzirkdyd 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/mcw6qq4ze9ppchawd8uk 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/rhcuowppft8kzrpi3vas 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/lihcbo7lcobtasexmubz 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/wkymdjqovj4ushzjlol7 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/jnrmicoayxtn1e1vwwrp 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/ibuidok3d2fonyom0jag 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/bvjjhfbwjaebf8jjiway 1280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/ugrnmwrcb7lwajtkjqpr 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HD8kLyYcSuYRi4vzP/wfh9e7vyz2ni5esm9wp8 1598w"></figure><p>足够接近。我可能不需要重新命名<a href="https://www.lesswrong.com/s/HMs2yT9D6LjYR5jQT">我的书</a>，但我可能需要设计一个好的副标题。</p><p>基于以上在提示工程中的实验，克劳德在迭代简短短语摘要方面相当有帮助。它能够捕捉到微妙的细微差别，这对于找到正确的短语来传达一个重要的想法非常有用。下次当我需要构建一个简短的短语来表达复杂的想法时，我可能会使用克劳德或其他法学硕士来迭代措辞。</p><br/><br/> <a href="https://www.lesswrong.com/posts/HD8kLyYcSuYRi4vzP/extrapolating-from-five-words#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/HD8kLyYcSuYRi4vzP/extrapolating-from- Five-words<guid ispermalink="false"> HD8kLyYcSuYRi4vzP</guid><dc:creator><![CDATA[Gordon Seidoh Worley]]></dc:creator><pubDate> Wed, 15 Nov 2023 23:21:31 GMT</pubDate> </item><item><title><![CDATA[In Defense of Parselmouths]]></title><description><![CDATA[Published on November 15, 2023 11:02 PM GMT<br/><br/><p>先决条件：贵<a href="http://benjaminrosshoffman.com/the-quaker-and-the-parselmouth/">格会教徒和蛇佬腔</a>。</p><h2>我。</h2><p>首先，快速总结一下。</p><p>在先决条件帖子中，本杰明霍夫曼描述了三种人。这些人是假设的极端：他们是在无摩擦真空中相互作用的完美球体的社会和认知等价物。有些贵格会教徒总是说实话，并且在说要做某事时信守诺言。有些演员总是说当下看起来不错的话，即使他们发誓和发誓，也不能可靠地遵守诺言。最后，还有蛇佬腔，他们可以自由地对演员说谎，但只对其他蛇佬腔说实话，并且（暗示）只对贵格会教徒说实话。</p><p>我赞同这种区别。它是抽象的，现实世界从来都不是那么清晰，但根据我的经验，它确实得到了一些有用的东西来理解。我认为说真话是一个强大的制度优势，并希望更多的人在这种二分法中成为贵格会教徒。本杰明指出，蛇佬腔有些奇怪，因为习惯性说谎可能会侵蚀本能，甚至可能侵蚀说真话的能力；对于真正的人来说，如果不慢慢成为演员，就不可能始终保持蛇佬腔。</p><p>说真话很难。弄清楚世界的真实状况是什么是很困难的。快速而准确地陈述你认为正确的事情是很困难的；英语使得“我相信明天有百分之九十的机会下雨”的句子比“明天会下雨”要长得多。当有人问你是否喜欢他们带来的聚餐砂锅菜（烧焦的和未调味的）时，你最终会受到很多额外的情感尖锐的肘击。全世界的贵格会教徒，我向你们致敬。全世界的演员，我明白了。</p><p>我的第一个主张是成为蛇佬腔是合理的。</p><h2>二.</h2><p>讲故事的时间！下面的故事详细描述了大约二十年前发生的事件，当时我比现在矮了几英尺。一些细节已经被当时在场的其他人证实，但许多细节可能随着时间的推移而发生了变化。</p><p>当我还是个孩子的时候，我必须拍很多照片。我妈妈带我进了办公室，我在等候区闲逛了一会儿，然后护士挥手让我经过前台，我和妈妈就进去了。护士让我坐在医生办公室的一张大塑料椅子上，然后我一边用冰凉的东西擦着我的肩膀，一边问妈妈问题，然后她让我坐一会儿，说：“这不会疼的，你准备好了吗？”我点了头。然后她用针刺了我。</p><p>很痛。我开始哭，并且持续哭了一段时间，直到疼痛消退为隐痛。我父母的安慰或护士的款待都没有改变这一点。我当时没有能力清楚地表达出是什么让我心烦意乱，但这不是痛苦（即使在小时候，当疼痛有目的时，我对疼痛的容忍度也非常高），而是困惑。它不应该伤害——他们对于是否会伤害的判断是错误的吗？这不太合理，用尖锐的东西刺人通常会伤害他们，为什么有人会认为不会呢？我是否记错了他们说的话，他们说会痛而不是不会痛？我的记忆真的那么差吗？我完全困惑了，无法理解发生了什么。</p><p>凭借多年的经验，发生的事情是显而易见的。护士撒谎让一个小孩在注射时保持安静。这个故事多年来一直在重复，每次我都会感到困惑和困惑。直到很久以后，当我顿悟到世界如何看待真理之后，我才想到有人会撒谎。</p><p>虽然很痛苦，但事实证明，这种理解是许多人际互动的有用万能钥匙。有时人们只是撒谎，而且<a href="https://slatestarcodex.com/2016/12/12/might-people-on-the-internet-sometimes-lie/">往往是</a>为了比你想象的<a href="https://www.lesswrong.com/posts/K2c3dkKErsqFd28Dh/prices-or-bindings">更小的利益</a>。文字不是真理，只是人们发出的声音或页面上的符号。人们随意地、轻易地在重要的事情和琐碎的事情上撒谎，以得到他们想要的东西，或者只是因为他们不在乎。这种不在意并不是恶意，只是冷漠。</p><h2>三．</h2><p>有时陈述事实错误是完全可以的。我认为一个重要的区别是大多数相关人员是否知道哪些陈述是哪些。</p><p>有一些明显的案例。如果你从书店的奇幻区拿起一本书，上面有一条龙，那么写那本书里的文字的人几乎可以全权决定在那本书中说出他们想要的任何内容。还有一些不太明显的情况；我很遗憾地通知您，职业摔跤手和舞台喜剧演员在他们嘴里说的话和现实的基本状态之间有着灵活的关系。还有一些可疑的例子，虽然它是虚构的，但旁观者可能会感到相当困惑，比如发现的恐怖电影片段或报纸上“研究节目”一词后面的任何内容。 <span class="footnote-reference" role="doc-noteref" id="fnrefdnozbd7ldgr"><sup><a href="#fndnozbd7ldgr">[1]</a></sup></span>小说对全世界数以百万计的人来说很有趣，任何禁止说谎的禁令都需要为此留出空间。</p><p> （另一个童年故事：我的一个叔叔曾经带我去钓鱼，当我们一天没钓到鱼回来时，我们无意中进行了一场喜剧二重唱，我系统地不同意他的<a href="https://www.britannica.com/dictionary/fish-story">鱼故事</a>的每一行，直到我祖父怜悯并把我拉到一边解释说这些不应该被视为字面上的事实。）</p><p>一些事实性的误解是，如果你真正检查正在发生的事情，就能成功地向对话双方传达正在发生的事情。</p><p>如果你问一个以美式英语为母语的人是否可以帮你做点什么，他们会回答“稍后”，而当你在六十分钟后他们没有出现时你会感到困惑，我实际上很抱歉。这也困扰了我很长一段时间，最终我也接受了。宇宙中没有任何法则将“ˈsɛkənd”的声音与人类心脏跳动所需的时间联系起来。在某些情况下，“ˈsɛkənd”表示大约等于心跳的时间单位，在其他情况下，它表示第一和第三之间的计数，在您刚刚寻求帮助并且有人说“在一秒钟内”的情况下，它的意思是类似“很快，但不是现在。”</p><p>多年来我选择了这场战斗的许多变体，但我已经放弃了。我现在站在语言描述主义者一边。</p><p>有这样一个：我认为不是每个人都知道这是如何工作的。存在证明，我感觉很长一段时间都不知道，所以二十年前说“每个人都知道”是错误的。大家都不知道。至少只要还有那些头脑简单的孩子到处乱跑，人们就会不断地遇到这种情况，而且可能会持续更长的时间，因为其中一些孩子长大成为头脑简单的成年人，他们对真理的立场转变为坚定的原则。当有人按字面意思理解我的话并进行代码转换或至少警告他们时，我会尽量集中注意力。</p><p>在许多美式英语口语句子中，“Literally”一词的作用是充当强化词。 “他在那场比赛中是世界上最好的”和“他在那场比赛中确实是世界上最好的”经常被说成基本上是同一件事。没有与世界其他地区进行实际的权威比较。</p><p>这令人沮丧。如果有一种方法可以在对话中标记“此语句处于贵格会模式”，将会很有用。可悲的是，据我所知，英语过去使用这种标记的每一次尝试都被收买为强化剂。英语单词“ <a href="https://en.wiktionary.org/wiki/very">very</a> ”据说源自“verrai”，意思是“真实”。</p><p>在某些例外情况下，人们普遍认为不允许出现事实错误。美国法律体系对在法院宣誓的人持悲观态度。有些合同希望真实反映所发生的事情。 （尽管离婚率令人震惊，但“直到死亡将我们分开”仍然是许多婚姻誓言中的内容，并且一些类似于最终用户许可协议等法律合同的文件的可执行性值得怀疑。）有些人在个人层面上，设法创造出不应该发生事实错误的空间。偶尔，整个社区都会尝试这样做。正如本杰明在《贵格会和蛇佬腔》中指出的那样，现实生活中的贵格会仍然存在。</p><p>然后还有LessWrong。</p><h2>四．</h2><p> LessWrong 有时称自己是一个寻求真相的社区。 <span class="footnote-reference" role="doc-noteref" id="fnrefgdce232pvfk"><sup><a href="#fngdce232pvfk">[2]</a></sup></span>当我写这篇文章时，关于页面说“我们寻求持有真正的信仰”并且（我声称）暗示我们寻求公开承认真正的信仰。我喜欢这个社区，很大程度上是因为我发现真理是一件美丽的事情，值得歌曲和诗歌，值得奉献一生去追求它。</p><p>但群体并不统一，真诚程度也各不相同。有人在 LessWrong 上发表评论这一事实并不意味着您可以绝对信任他们。这甚至并不意味着他们会像你一样关心真相。也许他们是新来的。也许他们确实关心真相，但有一个不同的惯用案例，例如上面的“稍等一下”示例，您没有意识到。也许他们正在努力，但未能坚持这些理想，失败令人痛苦，而承认这一点更令人痛苦。</p><p> （或者也许他们根本不在乎。毕竟，有些人只是喜欢看着世界燃烧。）</p><p> （所列出的原因并不详尽。）</p><p>听到在山上的某个地方有一座闪闪发光的城市，那里有自由说出真相的地方，一个演员永远不被允许在不改变他们的方式的情况下踏上的地方，我会很高兴。无论何时，当权衡正确时，尽我所能尝试帮助该项目实现。这不是我的中心目标，但如果有的话那就太好了。</p><p>部分问题在于《永恒的九月》新人需要适应，但我认为更大的问题是团队协调。我所见过的试图将整个理性主义者群体拖入真相，去追捕<a href="https://www.lesswrong.com/posts/zp5AEENssb8ZDnoZR/the-schelling-choice-is-rabbit-not-stag">雄鹿而不是兔子，但</a>并没有奏效。你可以尝试让自己遵守这个标准，你可以耐心地向另一个演员或蛇佬腔证明贵格会的方式更好，也许你应该，但我认为口语和随意的用法将继续成为人们交谈的方式。</p><blockquote><p> “我用每个人都能理解的语言与他们交谈，”安德说，“这并不圆滑。事情已经很清楚了。”</p><p> ——奥森·斯科特·卡德《死者代言人》</p></blockquote><h2>五、</h2><p>告白时间。在这种二分法中，我自称是蛇佬腔。我同情贵格会教徒，但我不再认为自己是他们中的一员。</p><p>过去，我要花很长一段时间才能回应人们对我说的话。我指的不是等待他们说完时的一小段间隙，而是整整五到十秒的死气沉沉。看看，如果你问我“你今天做了什么？”然后我需要思考我的一天，总结重要的部分，决定这让我感觉如何，将其表达出来，然后检查以确保这些话我们从所有可能的角度都是正确的。这通常需要多次修改，在开始说话之前在心里重写句子的多个草稿。 “我的钥匙在哪里？”它们在柜台上 - 不，等等，我实际上不知道，因为我没有看着它们 - 我上次在柜台上看到它们 - “柜台”与其他柜台有足够的区别吗？ - 等等我&#39;我想这个问题太久了aaaah。 “你什么时候到？” “很有可能在晚上八点之前，但我估计在下午五点到六点之间，条件是我的车没有出去，否则——等等，抱歉，我提供了太多信息，而且格式很奇怪，啊啊啊啊啊啊啊啊。”</p><p>现在我只是说“五点三十分，如果我迟到了，我会通知你。”我实际上并没有弄清楚这是否准确，但它符合暂时的意图，我可以在对方结束句子后一秒钟内回答。同样，如果有人说他们会在商店买牛奶，我就不会再因为那天晚上冰箱里没有牛奶而感到困惑了。做他们说过的事并不是一个重大的誓言，而只是一个短暂的意图。</p><p> （我想在这里指出，在所有贵格会和演员中，本杰明从来没有将演员视为故意撒谎作为故意策略的一部分，只是真的不可靠。这让我很喜欢作者，我会继续说用法，尽管我想花点时间来确定故意和恶意的骗子确实存在，并且当你接触到这样的人时，与演员互动的有效习惯将会灾难性地失败。这种骗子不属于本文的范围虽然我并不是说我会这样做，但对此保持持续警惕是有价值的。）</p><p>我同意本杰明的观点，即处于演员模式会削弱追求真相的本能，而且我还认为，某人有时撒谎的已知事实是他们此时此刻可能撒谎的重要证据。你永远不应该完全相信蛇佬腔处于贵格会模式。</p><p> （你也不应该完全相信贵格会教徒！零和一不是概率！他们可能是错的，他们可能认为这是值得撒谎的事情，他们可能已经被同卵双胞胎取代了！时刻保持警惕。）</p><p>然而，反之亦然。我认为处于贵格会模式会消耗你的谎言、社会融合和灵活性的能力。它使您容易受到他人谎言的影响，无法预见和预测他们可能会误导或误导。如果贵格会教徒和演员真的存在并混合在一起，我怀疑贵格会教徒会发现自己一次又一次地感到沮丧和欺骗，因为他们没有预料到错误的事情会发生。</p><p>我可以在短期内在自己的脑海中注意到这一点。当我从一个长周末与完全理性主义者互动（他们每时每刻都提醒着这个社区是谁和什么）转变为周一早上在火车站与我旁边的一个陌生人聊天时，我就很难想出快速而圆滑的语言回答“你好吗？”当我参加理性主义聚会时，在最初的几次对话中，我必须纠正自己给出的快速而简单的答案，但可能不是最真实的。</p><p>也许我只是犯了典型的思维谬误。我自己的想法似乎是一个真实的事实，成为一名贵格会教徒意味着发现世界是一个令人困惑的地方，充满了不可预测的危险，充满了我无法防御的不实言论。概括起来，我认为我的选择是：</p><ol><li>成为一名贵格会教徒并生活在混乱之中。</li><li>成为一名演员并放弃大部分长期合作的能力。</li><li>成为一个蛇佬腔，并根据与谁交谈而转换语码，接受对我讲真话能力的损害以及由于错误识别而导致的错误。</li></ol><p>其中，我选择3个。</p><p>需要明确的是，在我最糟糕的情况下，我认为我只像理想化的演员一样不值得信任。这些人并没有被塑造成骗子或恶意者，只是被塑造成不认为言论行为对未来行动具有约束力的人。大多数时候，根据我自己的评价，我比周围的中间人稍微诚实、直率，并且履行了更多的口头承诺。如果你从这篇文章中得到的结论是，我会为了我自己的利益而试图对你撒谎，让你做一些违背你利益的事情，那么我认为你没有正确理解我的意思。这篇文章的全部目的是让人们更容易地模仿我何时会陈述不真实的事情。我在这里付出了额外的努力，并且我试图在诚实方面犯错误。</p><p>我试着对那些我观察到并估计说真话的人只说真话，如果你是这种二分法中的贵格会教徒，我想知道，这样我就可以回报。然而，默认情况下，你不应该认为我所说的一切都是我发誓的；我是蛇佬腔，只觉得有必要对那些我认为有必要对我说实话的人说实话，而且除了实话之外别无其他。</p><p> （你不应该完全信任任何人，时刻保持警惕。） </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fndnozbd7ldgr"> <span class="footnote-back-link"><sup><strong><a href="#fnrefdnozbd7ldgr">^</a></strong></sup></span><div class="footnote-content"><p>这是一个关于人们相当合理地期望为真的事情实际上往往不是真的的笑话。如今，我对报纸及其解读科学研究的能力评价不高。</p><p>解释笑话可能会毁了笑话，但在这篇文章中，尝试并严格准确似乎异常值得。另外，这是一个很好的例子：如果我没有包含这个脚注，贵格会教徒会接受这个笑话吗？蛇佬腔怎么样？如果我有理由相信人们有时不阅读脚注，这会改变它的可接受程度吗？</p></div></li><li class="footnote-item" role="doc-endnote" id="fngdce232pvfk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefgdce232pvfk">^</a></strong></sup></span><div class="footnote-content"><p>这是不真实的。社区没有可以说话的嘴，也没有可以打字的手指。社区发言是一种类型错误。我不同意这种将格式塔人类群体具体化为有行动能力的比喻。不过，这是另一天的文章了，在这里我使用了这个比喻。</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/R28YGeAzDHehrnc7f/in-defense-of-parselmouths#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/R28YGeAzDHehrnc7f/in-defense-of-parselmouths<guid ispermalink="false"> R28YGeAzDHehrnc7f</guid><dc:creator><![CDATA[Screwtape]]></dc:creator><pubDate> Wed, 15 Nov 2023 23:02:19 GMT</pubDate> </item><item><title><![CDATA[Life on the Grid (Part 1)]]></title><description><![CDATA[Published on November 15, 2023 10:37 PM GMT<br/><br/><p>一个人成长环境的物理布局会影响他们成年后的认知能力。<a href="https://www.nature.com/articles/s41586-022-04486-7"><u>最近一项基于 38 个国家 397,162 人的视频游戏数据的研究</u></a>发现，“在城市以外长大的人更擅长导航。”更具体地说，“在街道网络熵较低的城市（例如芝加哥）长大，在常规布局的视频游戏级别上会获得更好的结果，而在城市外或街道网络熵较高的城市（例如布拉格）长大会导致更好的结果。”结果在更高熵的视频游戏水平上。”</p><p>用简单的英语来说：如果你在类似网格的环境中长大，那么你在不太像网格的环境中导航会更差。 </p><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38dee385-80f8-423b-a922-4d59a389f209_456x390.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38dee385-80f8-423b-a922-4d59a389f209_456x390.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38dee385-80f8-423b-a922-4d59a389f209_456x390.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38dee385-80f8-423b-a922-4d59a389f209_456x390.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38dee385-80f8-423b-a922-4d59a389f209_456x390.jpeg 1456w"><figcaption>环境与视频游戏之间的关联（海洋英雄探索）寻路表现按年龄、性别和教育程度分层。 SHQ 寻路性能是根据轨迹长度计算的，并在 5 年窗口内取平均值。 </figcaption></figure><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ad34081-2f7a-431a-a9d3-79c23acb9d3a_533x532.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ad34081-2f7a-431a-a9d3-79c23acb9d3a_533x532.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ad34081-2f7a-431a-a9d3-79c23acb9d3a_533x532.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ad34081-2f7a-431a-a9d3-79c23acb9d3a_533x532.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ad34081-2f7a-431a-a9d3-79c23acb9d3a_533x532.jpeg 1456w"><figcaption>两个 SNE 较低（芝加哥）和较高（布拉格）城市的例子。右图：街道方位分布在 36 个 10 度的区间内。</figcaption></figure><p>这一发现也许并不完全令人惊讶，乍一看似乎也没有那么重要。我们绝大多数人几乎不再需要在现实生活中真正找到路了。技术已经使我们的导航技能几乎过时了。那么某些环境在保护它们方面是好是坏又有什么关系呢？</p><p>这很重要。<strong> </strong>为了理解其中的原因，我们需要绕一点弯路。</p><p>复杂性科学家大卫·克拉考尔 (David Krakauer) 在<a href="https://www.samharris.org/blog/complexity-stupidity"><u>与 Sam Harris 的“Making Sense with Sam Harris”</u></a>节目中区分了互补性认知人工制品（使用后使我们变得更加聪明的技术）和竞争性认知人工制品（如果您无法猜出这些人工制品的作用，那么也许您会知道）已经使用它们太多了）。竞争性神器的典型例子是计算器：重复使用会让你的心算能力比以前更差。与算盘相比，算盘可能产生完全相反的效果：专家用户最终可以开发出如此高保真的心智模型，他们甚至不再需要使用物理算盘，并且能够在没有算盘的情况下保持增强的算术技能。 </p><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F731df525-40e8-4805-b32f-a62886da900d_677x855.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F731df525-40e8-4805-b32f-a62886da900d_677x855.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F731df525-40e8-4805-b32f-a62886da900d_677x855.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F731df525-40e8-4805-b32f-a62886da900d_677x855.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F731df525-40e8-4805-b32f-a62886da900d_677x855.jpeg 1456w"><figcaption><i>玛格丽塔哲学</i>中的<i>算术类型</i>(1503)</figcaption></figure><p>大脑是一个复杂的系统，充满了相互关联的表征系统。这就是为什么算盘不仅能帮助你数学，还能帮助你做所有事情。 Krakuer 博士解释说，“[大脑] 周围没有防火墙，因此算盘的功能优势仅限于算术……它实际上对语言能力和几何推理产生非常有趣的间接影响。”超出预期用途的积极的全局效应是所有互补认知制品的一个特征。</p><p>另一方面，<i>竞争性</i>认知制品的功能<i>缺点</i>也不限于某个领域或技能。 Krakauer 博士接着讨论了用自动寻路技术取代地图、星盘和六分仪等原始寻路技术是如何产生这样的效果的：</p><blockquote><p>您对地图制作以及地形、拓扑和几何推理的熟悉通常对您的生活很有价值，而不仅仅是在城市中导航。因此，拿走地图不仅会让你从一扇门到另一扇门变得更糟，还会在很多方面让你变得更糟……爱因斯坦和弗兰克·劳埃德·赖特都依赖的一个很好的例子是木立方体。在他们年轻的时候，他们都非常迷恋这些立方体，并用立方体构建世界，比如《我的世界》。他们两人都声称——弗兰克·劳埃德·赖特（Frank Lloyd Wright）就建筑而言，爱因斯坦就宇宙几何而言——他们在玩这些立方体时建立的直觉对他们后来的生活发挥了重要作用。我想说地图也是如此。如果你知道如何穿越一个真实的空间，比如欧几里得空间或地球表面的弯曲空间，那么你就可以思考不同类型的空间、关系空间、想法空间。作为一种隐喻，从一个想法到另一个想法的路径概念实际上在现实空间中的路径方面具有直接且自然的实现。</p></blockquote><p>我们的认知（推理、记忆、创造力等）类似于一种心理导航，但我们的<a href="https://en.wikipedia.org/wiki/Conceptual_metaphor"><u>概念隐喻</u></a>却背叛了这一点：“一个知识领域”、一个“未经探索的主题”、“一系列思想”、 “沿着记忆之路旅行”、“唤起你的记忆”、“一次幻想”。神经科学正在快速发展（这是比喻），但<a href="https://www.quantamagazine.org/the-brain-maps-out-ideas-and-memories-like-spaces-20190114/"><u>新出现的证据</u></a>支持这一说法：“大脑以代表空间位置的方式编码抽象知识，暗示了一种更普遍的认知理论。”</p><p>这也是为什么古老的记忆增强技术——<a href="https://artofmemory.com/blog/method-of-loci/"><u>轨迹法</u></a>——记忆宫殿技术——至今仍被记忆冠军所使用。根据<a href="https://artofmemory.com/blog/method-of-loci/"><u>《记忆的艺术》</u></a> ，“轨迹的方法涉及通过在想象的旅程中的某个点为每个要记住的项目放置一个助记图像来记忆信息。然后，通过在想象的旅程中在脑海中走同样的路线，并将助记图像转换回它们所代表的事实，就可以按照特定的顺序回忆信息。”<a href="https://fs.blog/a-philosophy-of-walking/"><u>步行与创造力</u></a>之间的联系早已为<a href="https://www.themarginalian.org/2021/12/12/nietzsche-walking/"><u>知识分子和艺术家</u></a>所知，并得到<a href="https://news.stanford.edu/2014/04/24/walking-vs-sitting-042414/"><u>最近研究的</u></a>支持，这里也值得注意——就好像穿过物理景观的运动为在更抽象的思想景观中更轻松的运动奠定了基础（参见有关<a href="https://en.wikipedia.org/wiki/Embodied_cognition"><u>具体认知</u></a>的更广泛的文献，以进一步讨论该主题）。</p><blockquote><p>行走的节奏产生了一种思维的节奏，穿过风景的通道呼应或刺激着一系列思维的通道。这在内部通道和外部通道之间创造了一种奇怪的和谐，这表明心灵也是一种风景，步行是穿越它的一种方式。新的想法常常看起来像是一直存在的景观的一个特征，就好像思维是在旅行而不是在创造。因此，步行历史的一个方面就是具体化的思维历史——因为心灵的运动无法被追踪，但脚的运动可以。</p><p> ——丽贝卡·索尔尼特， <a href="http://www.amazon.com/exec/obidos/ASIN/0140286012/braipick-20"><i><u>《流浪癖：行走的历史》</u></i></a></p></blockquote><p>我们还使用空间隐喻来谈论社会经济景观或生活本身：“人生旅程”、“拓宽视野”、“发现自我”或“自我反省”、“职业道路”、“各行各业” “ 等等。当我们考虑我们深刻的进化历史时，这是有道理的：我们生存所必须知道的许多最重要的事情都是自然界中的空间问题——角马迁徙穿过这个山谷，我们可以在那片森林里采集浆果，有人被一只动物杀死了。我们有时甚至用树栖隐喻（“知识分支”）来概念化知识——这也许是我们祖先树居生活方式的遗迹。</p><p>我们缺乏寻路能力也存在于我们的物理、文化和形而上学景观中，这些景观也变得规则和网格状。我相信我们现在正在目睹的后果是缺乏韧性和足智多谋，不愿意“开拓道路”，无法产生“开创性”创新，以及许多其他缺陷，这些缺陷使我们的处境比以前更糟。我们所处的世界更加混乱和古怪。我们所采用的社会和智力“技术”（例如教育体系、育儿规范）已日益成为竞争性认知产物，而不是合作性产物。</p><p>世界的过度“网格化”在物理领域表现得最为明显。由于各种原因（经济、环境、不断变化的审美偏好），新城市往往有更简单的布局。 </p><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76d0ce6c-4a49-45ae-a4d9-7a3369f61810_616x675.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76d0ce6c-4a49-45ae-a4d9-7a3369f61810_616x675.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76d0ce6c-4a49-45ae-a4d9-7a3369f61810_616x675.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76d0ce6c-4a49-45ae-a4d9-7a3369f61810_616x675.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76d0ce6c-4a49-45ae-a4d9-7a3369f61810_616x675.jpeg 1456w"><figcaption>图中两个最古老的美国城市波士顿和夏洛特是最不规则的。两个数据的来源： <a href="https://geoffboeing.com/2018/07/city-street-orientations-world/"><u>GeoffBoeing</u></a> </figcaption></figure><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F299042e7-a364-4490-aafd-13da8a19bf5d_768x846.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F299042e7-a364-4490-aafd-13da8a19bf5d_768x846.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F299042e7-a364-4490-aafd-13da8a19bf5d_768x846.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F299042e7-a364-4490-aafd-13da8a19bf5d_768x846.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F299042e7-a364-4490-aafd-13da8a19bf5d_768x846.jpeg 1456w"><figcaption></figcaption></figure><p>建筑也是如此。世界各地更加华丽和文化独特的形式已被单调的巨石所取代。其结果是令人压抑的标准化和同质化，失去了赋予地方独特特征的怪癖和怪癖。</p><p>不规则性和变化的消失是世界物理网格化的一个方面，但全球范围内纵横交错的道路和轨道数量也非常多。 “脱离电网”几乎是不可能的。事实上，任何事物、任何地方都无法逃脱我们在地球上撒下的技术社会网络。未知的领域已成为过去。</p><blockquote><p>即使你现在想退学，可以吗？无论您走到哪里，无论何时，您都会被识别、跟踪、联网和分类。历史上从未如此难找到一个新的开始、一个干净的开始，或者一个按照自己的鼓手的节奏前进的地方。不再有瓦尔登湖或隐居处——甚至连脱离电网的地点现在也都在电网上了。</p><p> —<a href="https://tedgioia.substack.com/p/multitasking-isnt-progressits-what"><u>特德·乔亚</u></a></p></blockquote><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc72394c9-6203-4f86-ac01-f5ee3691da9f_575x304.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc72394c9-6203-4f86-ac01-f5ee3691da9f_575x304.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc72394c9-6203-4f86-ac01-f5ee3691da9f_575x304.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc72394c9-6203-4f86-ac01-f5ee3691da9f_575x304.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc72394c9-6203-4f86-ac01-f5ee3691da9f_575x304.jpeg 1456w"><figcaption> 1539 年，一条巨大的海蛇袭击了挪威海岸奥劳斯·马格努斯 (Olaus Magnus) 的卡塔码头上的一艘船，这张图片来自 1572 年版本。</figcaption></figure><blockquote><p>如果你在 18 世纪长大，仍然有新的地方可以去。听完外国冒险故事后，您自己也可以成为一名探险家。整个 19 世纪和 20 世纪初可能都是如此。从那以后，《国家地理》的摄影作品向每个西方人展示了地球上最具异国情调、尚未开发的地方的样子。如今，探险家的身影大多出现在历史书和儿童故事中。父母不希望他们的孩子成为探险家，就像他们不希望他们成为海盗或苏丹一样。也许在亚马逊雨林深处有几十个与世隔绝的部落，我们知道在海洋深处还存在最后一个地球边界。但未知似乎比以往任何时候都更难接近。</p><p> ——彼得·泰尔， <i>《从零到一》</i></p></blockquote><p>彼得·蒂尔认为，创新精神已经退化，部分原因是我们不再相信秘密，而我们不再相信秘密是因为不再有任何可进入的边界。这对于人类来说确实是前所未有的状况。亿万年来，我们的思想和文化与未知世界（地图上标有“这里有龙”的地方）微妙地共生。如果没有这个未知，那个可能有<a href="https://en.wikipedia.org/wiki/El_Dorado"><u>黄金之城</u></a>或<a href="https://en.wikipedia.org/wiki/Fountain_of_Youth"><u>青春泉源的</u></a>地方，英雄（但不仅仅是英雄，而是我们所有人）就无处可去，而所有能让我们成为英雄的东西——勇敢，坚韧、聪明才智、大胆等等——开始萎缩。如果没有这种未知，我们就会开始感到被限制——被困住——就像一只美丽而危险的动物被关在狭窄的笼子里：我们会产生幽闭恐惧症；我们会产生幽闭恐惧症；我们会感到恐惧。想象力和灵感枯萎。我们不再像以前那样充满希望，但我们不知道为什么。 </p><hr><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd586719a-eee7-4d79-84e7-f66f10a763d9_640x382.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd586719a-eee7-4d79-84e7-f66f10a763d9_640x382.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd586719a-eee7-4d79-84e7-f66f10a763d9_640x382.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd586719a-eee7-4d79-84e7-f66f10a763d9_640x382.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd586719a-eee7-4d79-84e7-f66f10a763d9_640x382.jpeg 1456w"><figcaption>那孩子的脸说明了一切——算盘是侧面的牢房铁条（<a href="https://www.flickr.com/photos/nationaalarchief/3896157508"><u>来源</u></a>）</figcaption></figure><p>网格上的生活从很小的时候就开始了，当你在现代教育系统的泪水和单调的工厂里找到一份工作时，你将坐在方形建筑中的方形房间里的方形桌子旁，阅读方形书籍并在上面写字。正方形的纸伴随着你童年的无数个小时（在大多数情况下，我猜它们会是矩形，但你明白了）。通过证明您可以遵循任意规则并重复在明确定义的主题、单元和章节中灌输给您的知识，您将从一个年级升级到下一个年级。如果你对这个游戏有一点点擅长，他们会坚持让你在生命的前 22 年里都这样做，但即使这样也<a href="https://theconversation.com/if-the-masters-degree-is-the-new-bachelors-is-the-doctorate-now-the-new-masters-95577"><u>还</u></a><a href="https://www.nytimes.com/2011/07/24/education/edlife/edl-24masters-t.htmlyXTmUugkI2NQyJhdyNtA/edit"><u>不够</u></a>。</p><p>在某个时刻，上帝保佑，你将进入“现实世界”，也就是你的父母和老师经常谈到的神秘境界。然而，你很快就会发现“现实世界”是另一个庞大的官僚体系，它与学校的“虚假世界”并没有太大区别。当然，你有更多的自由，有些事情略有不同（老板而不是老师，小隔间而不是桌子），但基本原理是相同的：只要保持笔直和狭窄，低着头，不断提高水平。</p><p>至于我们的毕业后生活（所剩无几），许多人进入美国企业界或成为公务员。我们中的一些人成为了艺术家或企业家，但即便如此也无法逃脱：这些职业道路也被网格吞没了。<a href="https://erikhoel.substack.com/p/how-the-mfa-swallowed-literature"><u>埃里克·霍尔 (Erik Hoel) 写道</u></a>，当代作家与近代作家（2000 年代初）之间存在着一个无可争议的区别：<i>现在几乎每个人都拥有艺术硕士学位</i>。</p><blockquote><p>但如今，大多数 50 岁以下的出版业成功人士<i>实际上都</i>获得了 A+。他们都在正确的时间举起了手，做了他们需要进入哈佛、阿默斯特或威廉姆斯或其他任何地方所需的一切，然后跨越所有必要的障碍进入爱荷华作家工作室或哥伦比亚大学等。</p><p>福克纳没有完成高中学业，最近的研究显示，伍尔夫参加了一些古典文学和文学课程，但大多是在家接受教育，陀思妥耶夫斯基拥有工程学位……这些伟大的作家中没有一位会被<i>该国的</i><i>任何</i>艺术硕士学位<i>录取</i>。学术渠道的结果是，尽管当代作家表面上种族和性别的多样性与以前的时代截然不同，但他们的信仰和风格却非常相似，比过去的作家更加相似。 </p></blockquote><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2297011d-2e55-480b-a0b9-3e8c65163021_598x332.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2297011d-2e55-480b-a0b9-3e8c65163021_598x332.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2297011d-2e55-480b-a0b9-3e8c65163021_598x332.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2297011d-2e55-480b-a0b9-3e8c65163021_598x332.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2297011d-2e55-480b-a0b9-3e8c65163021_598x332.jpeg 1456w"><figcaption></figcaption></figure><p>对于企业家来说，情况更是如此。盖茨和扎克伯格的时代已经一去不复返了，那时高级学位是可选的，数字前沿是敞开的。<strong> </strong>现在，每个人都阅读<a href="http://www.paulgraham.com/articles.html"><u>相同的文章</u></a>，遵循相同的指南（“ <a href="https://www.inc.com/entrepreneurs-organization/eight-steps-to-becoming-a-tech-entrepreneur-when-you-know-nothing-about-technolo.html"><u>当你对技术一无所知时成为技术企业家的 8 个步骤</u></a>”），并申请相同的项目、孵化器和<a href="https://www.ycombinator.com/apply/"><u>组合器</u></a>。</p><p>这是泰勒·考恩 (Tyler Cowen) 在 2007 年撰写的文章（“<a href="https://www.nytimes.com/2007/06/14/business/14scene.html"><u>美国青少年可能会制造麻烦或企业家的松散缰绳</u></a>”）：</p><blockquote><p>网络背后的新思想和商业原则为年轻人开辟了理想的领地。新手更有可能看到音乐可以来自计算机而不仅仅是来自商店或收音机，或者最好不通过旅行社预订航班。纽约大学副教师克莱·舍基 (Clay Shirky) 指出，许多年轻人很幸运，因为他们对互联网企业没有先入为主的观念。多年的经验对于提炼和改进长期熟悉的产品（例如面包）至关重要。但对于创办 Napster 或 YouTube 来说，全新的、打破常规的想法（通常来自年轻人）更为重要。</p></blockquote><p>十六年后，现在所有这些实际上都是错误的。年轻人<a href="https://www.reddit.com/r/technology/comments/10o2vu7/gen_z_says_that_school_is_not_shipping_them_with/"><u>甚至不知道如何使用电脑</u></a>了。 </p><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a4eb9b5-51df-41c8-ae59-69d3182b04e7_597x254.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a4eb9b5-51df-41c8-ae59-69d3182b04e7_597x254.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a4eb9b5-51df-41c8-ae59-69d3182b04e7_597x254.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a4eb9b5-51df-41c8-ae59-69d3182b04e7_597x254.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a4eb9b5-51df-41c8-ae59-69d3182b04e7_597x254.png 1456w"><figcaption></figcaption></figure><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F300a3f41-9c6d-49ce-885a-770858c746eb_595x305.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F300a3f41-9c6d-49ce-885a-770858c746eb_595x305.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F300a3f41-9c6d-49ce-885a-770858c746eb_595x305.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F300a3f41-9c6d-49ce-885a-770858c746eb_595x305.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F300a3f41-9c6d-49ce-885a-770858c746eb_595x305.jpeg 1456w"><figcaption></figcaption></figure><p>回顾一下：在简单的空间环境中长大并使用 GPS 已经给你的大脑带来了伤害，生活变成了一场令人心碎的电子游戏，完全没有神秘或冒险。我们就像蜘蛛网中的昆虫一样被困在网格中；激烈的斗争只会让我们更加陷入困境。为了摆脱困境，我们作为个体必须轻轻地颠覆网格的根基，网格不是外在的，而是人性的一个方面：控制的冲动、系统化的本能、我们憎恶异常和模糊性并寻求的部分消灭他们。一开始认真地尝试挣脱束缚，很容易就会陷入自我强加的规则和实践体系，需要满足标准和遵循时间表。因此，我不愿意提供任何具体的建议——它们只会限制你的思维。目前，也许只有一件事可以说：如果你想脱离电网，那就迷路吧。</p><br/><br/><a href="https://www.lesswrong.com/posts/j4cKyhDEBpGPLNpig/life-on-the-grid-part-1#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/j4cKyhDEBpGPLNpig/life-on-the-grid-part-1<guid ispermalink="false"> j4cKyhDEBpGPLNpig</guid><dc:creator><![CDATA[rogersbacon]]></dc:creator><pubDate> Wed, 15 Nov 2023 22:37:31 GMT</pubDate> </item><item><title><![CDATA[Glomarization FAQ]]></title><description><![CDATA[Published on November 15, 2023 8:20 PM GMT<br/><br/><p>我在这里发布这篇文章的主要原因是我希望公开记录我在 2023 年写的这篇文章。这样，我可以向将来的人们表明我不是当场编造的；而是我在 2023 年写的这篇文章。早在他们这次问我什么事之前，这个问题就已经存在了。我没有自己的博客，所以我把它放在这里。不过，有些人可能会觉得它很有趣，或者想自己使用它。</p><p></p><p>如果我给你发了这篇文章，你可能只是问了我一个问题，而我的回答是“我拒绝证实或否认这一点”。也许你问我是否写了一个特定的故事，或者我是否与某人发生了性关系，或者我是否抢劫了一家银行。当你听到我的拒绝时，你可能会变得<i>更加</i>怀疑，假设这意味着我确实写/敲/抢劫了这个故事/人/银行。</p><p>这就是为什么情况不一定如此的解释。</p><p></p><p><strong>你为什么拒绝回答我的问题？</strong></p><p>假设——就像这篇文章中通常坚持的那样，我并不是说这是对是错，只是要求你考虑这个假设——我一生中从未犯过任何罪行，除了……比如说，公共场所小便。我头上套着一个袋子，所以人们不能确定是我。尽管如此，警察还是能够将嫌疑人的范围缩小到一个很小的名单，我也在其中，他们问我是否是我干的。</p><p>有些人只是对警察撒谎。不过，这里的关键因素是我<i>不想</i>对此撒谎。整个政策是为了避免谎言，以及在保持完全诚实的同时能够维护我的隐私。 <span class="footnote-reference" role="doc-noteref" id="fnreflpyzjd5jwgk"><sup><a href="#fnlpyzjd5jwgk">[1]</a></sup></span>如果我拒绝撒谎，但又不想让他们知道真相，那么我根本无法回答这个问题。所以我说，“我拒绝证实或否认这一点。”</p><p>但假设警察问我是否杀了人——但我<i>没有</i>这么做。他们问我是否抢劫了银行，是否贩卖毒品，以及其他有关我以前从未犯过的犯罪的问题。我总是说实话：“不，我没有那样做。”当然，现在警方知道在公共场合小便问题的答案是肯定的，因为这是我唯一拒绝回答这一问题的问题。</p><p>唯一不告诉他们我的秘密的政策，除了公然撒谎之外，就是拒绝证实或否认我是否犯下了<i>任何</i>罪行——<i>即使是那些我实际上没有犯下的罪行</i>。</p><p></p><p><strong>好吧，但这是否意味着你一开始就一定犯了一些罪行？毕竟，如果你不这样做，那么回答每一个存在的犯罪问题也没有什么坏处。</strong></p><p>这项政策不仅仅适用于我迄今为止所犯下的罪行。我可能会遇到<i>很多</i>其他可能的情况，如果回答不一致就会放弃信息。</p><p>例如，如果我还没有犯罪，但将来会犯罪，那么当我从总是说“不”变成总是说“我拒绝证实或否认”的那一刻，警察就知道我已经犯罪了。刚刚做了<i>某事</i>——</p><p></p><p><strong>那么你打算犯罪吗？</strong></p><p>不！或者更确切地说，我拒绝确认或否认我正在计划犯罪，但是<i>不，这不是我之前所说的有效结论！</i>首先，即使我预计几十年后犯罪的可能性很小，为了以防万一，仍然值得遵守这条规则 - 别用那种眼神看我，我还没说完。<i>此外</i>，这不仅仅适用于犯罪。</p><p>假设你问我是否与 X 发生过性关系<span class="footnote-reference" role="doc-noteref" id="fnrefiscl4hvc39"><sup><a href="#fniscl4hvc39">。 [2]</a></sup></span>出于与之前相同的原因，如果答案是“是”，我不能只是拒绝确认或否认我是否与该人发生过性关系，因为我的反应的差异就暴露了这一点。 （“我没有和W发生过性关系，我不能告诉你关于X的事情，我没有和Y发生过性关系，我没有和Z发生过性关系......）</p><p>如果我从未与任何人发生过性关系，但犯了罪，那么通过对性问题回答“否”，但对犯罪问题回答“我拒绝证实或否认”，我将透露我在至少一项犯罪。因此，即使我是处女，我仍然不得不拒绝回答性问题。</p><p>还有一些关于逻辑决策理论以及与我自己的假设版本合作的内容，但我认为这些都没有必要证明这一点。是的，我预计在过去、现在或将来的某个时刻，很有可能有人问我一个我不想诚实回答的问题。这足以表明我需要拒绝确认或否认某些事情。</p><p></p><p><strong>您所遵循的总体政策到底是什么？</strong></p><p>拒绝回答任何问题，如果该问题的可能答案之一（如果为真）是我想要隐藏的东西 - 无论所述答案实际上是否为真。也称为“全球化”。 <span class="footnote-reference" role="doc-noteref" id="fnreflwpck0izhj"><sup><a href="#fnlwpck0izhj">[3]</a></sup></span></p><p></p><p><strong>始终遵循这一点不是很困难吗？</strong></p><p>是的！事实上，尽管我很想总是荣耀化，但出于实用性，我常常不得不做出例外。如果有人问我今天做了什么，那么理论上我将不得不拒绝回答，因为可能的答案之一就是“我偷了你的车”。但大多数时候，我最终只是回答问题。</p><p>那么，什么<i>类似于</i>严格的全球化，但仍然足够宽松，我不必拒绝回答每个问题？好吧，我从成本效益分析开始。如果警察问我是否是袋头同伴<span class="footnote-reference" role="doc-noteref" id="fnref29ukuc1sh14"><sup><a href="#fn29ukuc1sh14">[4]</a></sup></span> ，那么在真相为“是”的情况下说真话的成本超过了在真相为“否”的情况下说真话的收益。所以在这里，我进行了环球化。但在不同的场景中，情况会发生变化：假设我中了一张 1,000,000 美元的彩票，而加拿大人没有资格购买，我需要向彩票人员提供我的地址才能拿到这笔钱 - 但我对我的隐私有轻微的偏好地址。在这种情况下，我居住在加拿大的情况下的成本远<i>低于</i>我居住在其他地方的情况下的收益。所以在这里，我说实话，因为在所有可能的情况下，全球化都会<i>伤害</i>我。</p><figure class="table"><table><tbody><tr><td>情况</td><td>答案A</td><td>答案B</td><td>成本如果 A</td><td>如果 B 则受益</td><td>你做什么工作？</td></tr><tr><td>被警方审问</td><td>“我做到了。”</td><td> “我没有这么做。”</td><td>进监狱？ <span class="footnote-reference" role="doc-noteref" id="fnref4iik2sevr7o"><sup><a href="#fn4iik2sevr7o">[5]</a></sup></span></td><td>警察更喜欢你</td><td>全球化</td></tr><tr><td>中了彩票</td><td>“我住在加拿大。”</td><td> “我住在[其他地方]。”</td><td>隐私较少</td><td>1,000,000 美元</td><td>说实话</td></tr></tbody></table></figure><p>我还需要考虑计算中的相关概率，并且可能会随机化一点，以仅花费很少的成本来保密。如果我99%的时间都花在无辜的事情上，1%的时间花在银行抢劫上，那么当我抢劫银行时，我不需要100%的时间去躲藏，只需2%的时间，或者10%如果我想更加安全的话。当然，这项政策的缺点确实给人们提供了一些证据，表明我隐藏某些东西的频率有多高，或者至少可以帮助他们建立一个上限。</p><p></p><p><strong>我怀疑你是否真的像你暗示的那样频繁地这样做。</strong></p><p>不幸的是，在撰写本文时我确实没有任何可以引用的证人。我家里的每个人都可以证实我确实经常拒绝回答问题，而且我认为在某些情况下他们后来发现我<i>没有</i>隐藏任何东西（有些情况下他们发现了我）。但这不是一个选择，因为我实际上不愿意确认或否认我的家人是谁。</p><p>幸运的是，对于除了我向其发送此帖子的第一个人之外的所有人，我将能够告诉他们我在他们之前向其发送过此帖子的人！因此，除非您碰巧是第一个人，否则当您阅读本文时，会有其他人可以证明我的怪异。</p><p></p><p><strong>你为什么说“这是机密”？</strong></p><p>有时我就是这样说“我拒绝证实或否认”！ “机密”听起来比“拒绝确认或否认”更酷，就像我是某种秘密特工一样。我是否实际上是某种秘密特工当然是保密的。</p><p></p><p><strong>您为什么在帖子前面列出“写了一个故事”？</strong></p><p>人们有时会因为用笔名写故事而受到指责。我和我之前的许多作者一样<span class="footnote-reference" role="doc-noteref" id="fnreffpnfyjvo0n"><sup><a href="#fnfpnfyjvo0n">[6]</a></sup></span> ，认为引发对我秘密写过或未写过哪些故事，以及我是或不是互联网上哪些其他作者的猜测是很有趣的。如果我写了一些我不想与我的真实姓名相关的禁忌内容，这也很有帮助。</p><p></p><p><strong>如果我确实想知道答案，我能做些什么吗？</strong></p><p>改变激励措施！例如，假设你是我的老板，我不想讨论政治，因为我认为你会解雇与你意见不同的人。如果你想了解我的政治信仰，那就证明你以前与人合作没有问题，即使你讨厌他们的政治立场。如果你不能证明这一点……好吧，这就是为什么我不回答你的问题。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnlpyzjd5jwgk"> <span class="footnote-back-link"><sup><strong><a href="#fnreflpyzjd5jwgk">^</a></strong></sup></span><div class="footnote-content"><p>当然，即使我一般不诚实，也不对警察撒谎还有一个额外的原因——这是非法的。</p></div></li><li class="footnote-item" role="doc-endnote" id="fniscl4hvc39"> <span class="footnote-back-link"><sup><strong><a href="#fnrefiscl4hvc39">^</a></strong></sup></span><div class="footnote-content"><p>我实际上不太关心人们知道我与谁发生过性关系或没有与谁发生过性关系，但还有其他原因我想隐藏此类事情：尊重他人的隐私，或者如果这个人太不受欢迎，以至于如果人们知道我和他们发生过性关系，或者他们在逃避法律，并且我不想透露他们在我家里，他们就会拒绝与我交往 - 废话，现在我再次回到犯罪问题上来。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnlwpck0izhj"> <span class="footnote-back-link"><sup><strong><a href="#fnreflwpck0izhj">^</a></strong></sup></span><div class="footnote-content"><p> Glomarization 是以中央情报局想要保密的一艘船命名的。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn29ukuc1sh14"> <span class="footnote-back-link"><sup><strong><a href="#fnref29ukuc1sh14">^</a></strong></sup></span><div class="footnote-content"><p>这个词里应该有多少个 e？</p></div></li><li class="footnote-item" role="doc-endnote" id="fn4iik2sevr7o"> <span class="footnote-back-link"><sup><strong><a href="#fnref4iik2sevr7o">^</a></strong></sup></span><div class="footnote-content"><p>根据谷歌的前几条结果，通常只会被处以 500 美元的罚款，但如果是重复犯罪或在一大群人面前，惩罚就会加重，你<i>很</i>可能最终会入狱。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnfpnfyjvo0n"> <span class="footnote-back-link"><sup><strong><a href="#fnreffpnfyjvo0n">^</a></strong></sup></span><div class="footnote-content"><p>或者也许在我之前<i>零个</i>作者。</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/N5txrJDimv8nz4n24/glomarization-faq#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/N5txrJDimv8nz4n24/glomarization-faq<guid ispermalink="false"> N5txrJDimv8nz4n24</guid><dc:creator><![CDATA[Zane]]></dc:creator><pubDate> Wed, 15 Nov 2023 20:20:49 GMT</pubDate> </item><item><title><![CDATA[Testbed evals: evaluating AI safety even when it can’t be directly measured
]]></title><description><![CDATA[Published on November 15, 2023 7:00 PM GMT<br/><br/><p>我和一些合作者最近发布了论文“泛化类比（GENIES）：将人工智能监督泛化到难以测量领域的测试平台。 （<a href="https://twitter.com/joshua_clymer/status/1724851456967417872?s=20">推文线程</a>）。在这篇文章中，我将解释 GENIES 基准如何与更广泛的方法相关联，用于预测人工智能系统是否安全<i>，即使无法直接评估其行为。</i></p><p>总结：<strong>当AI安全性难以衡量时，检查AI对齐技术是否可以用来解决更容易评分的类似问题。</strong>例如，要确定开发人员是否可以控制诚实如何推广到超人领域，请检查他们是否可以控制其他分布变化的泛化，例如“五年级学生可以评估的指令”到“博士可以评估的指令”。或者测试开发者是否能够发现欺骗行为，检查他们是否能够识别故意植入的“木马”行为。即使特定人工智能系统的安全性难以衡量，人工智能安全的有效性<i>&nbsp;</i>研究人员及其工具通常更容易测量——就像在风洞和压力室等航空航天试验台中测量火箭部件比发射火箭更容易测量一样。这些“试验台”评估可能会成为任何人工智能监管框架的重要支柱，但迄今为止很少受到关注。 <br></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/okmB8ymyhgc65WckN/ghuihv6jreaal9mzim2g"></p><h2><br>背景：为什么人工智能安全“难以衡量”</h2><p>很难判断人工智能系统是否遵循开发人员的指令有两个基本原因。</p><p><strong>人工智能的行为可能看起来不错，但实际上并不好。</strong>例如，很难判断超人人工智能系统是否遵守“开发您确信安全的后继人工智能”等指令。人类可以查看人工智能计划并尽力确定它们是否合理，但很难知道人工智能系统是否在玩弄人类的评估——或者更糟糕的是——它们是否有隐藏的意图并试图对我们实施快速的攻击。</p><p><br><strong>在某些环境中观察人工智能行为会带来风险。</strong>前沿法学硕士在部署后就发现了许多安全故障，当人工智能系统超过一定的能力阈值后，这显然会变得不可接受。相反，开发人员必须彻底评估模型<u>无法</u>采取<u>真正危险</u>操作的测试环境中的安全性。如果人工智能系统故意等待机会采取危险行动或出现其他“实验室”中未出现的故障模式，那么以这种方式评估人工智能系统将尤其具有挑战性。</p><h2><br>其他行业的安全也很难衡量</h2><p>在人工智能安全中，安全性的衡量似乎特别具有挑战性，因为在大多数行业中，不安全的系统并不<i>试图</i>看起来安全；相反，它是安全的。然而，我们仍然可以从其他行业的安全衡量方式中吸取教训。</p><p>例如，通过实际将火箭发射到太空来测试火箭的成本很高，类似于通过实际部署来测试人工智能系统的危险程度。航空航天工程师在称为“测试台”的更易于测量的设置中执行尽可能多的测试。例如，他们建造模拟真空空间压力和温度条件的室，建造对结构部件施加应变和振动的钻机等。通过“桌面场景”对核设施工作人员进行评估，以确定他们如何应对灾难。</p><p>通常，当难以测量时，可以使用易于测量的测试来预测安全性。</p><h2>人工智能安全的“试验台”</h2><p><strong>定义。</strong>我将使用“测试台”一词来指<strong>代类似于使人工智能系统更安全但更容易评分的问题。</strong>开发人员能够在多大程度上解决这些问题应该反映出他们实际上能够在多大程度上确保人工智能系统的安全。</p><p>人工智能安全“测试平台”的示例包括：</p><ul><li><a href="https://twitter.com/joshua_clymer/status/1724851456967417872?s=20"><strong>泛化类比</strong></a><strong>。</strong>要确定开发人员是否可以将诚实概括为超人能力，请检查他们是否可以控制从“五年级学生可以回答的问题”到“博士可以回答的问题”的概括。更一般地说，测试他们是否可以控制各种分布变化的泛化。</li><li> <a href="https://www.lesswrong.com/posts/EbL5W5ccwfbqFiYBJ/auditing-games-for-high-level-interpretability-1"><strong><u>审核游戏</u></strong></a><strong>：</strong>要确定可解释性工具是否可以捕获欺骗行为，请检查它们是否可以<a href="https://www.alignmentforum.org/posts/5HtDzRAk7ePWsiL2L/open-problems-in-ai-x-risk-pais-5#Trojan_Horse_Models"><u>识别其他开发人员植入的木马</u></a>，或者区分经过故意训练的欺骗性模型。</li><li> <a href="https://www.lesswrong.com/posts/MbWWKbyD5gLhJgfwn/meta-level-adversarial-evaluation-of-oversight-techniques-1"><strong><u>元级对抗性评估</u></strong></a>：为了测试您的监督过程的稳健性，训练人工智能系统来利用一些开发人员可以验证的漏洞，因为他们拥有监督过程中保留的信息。例如，训练人工智能系统删除它不应该访问的文件而不被抓住。一些开发人员了解测试，并且可以轻松检查任务是否完成，但监督者无法访问这些保留的信息。</li></ul><h2> Tesbed 的应用</h2><p><strong>人工智能监管。</strong>人工智能治理中的一个关键的开放问题是<i>如何设计“安全评估”。</i>如果人工智能系统通过这些具体测试，其部署范围就可以扩大。测试平台可用作安全评估。例如，监管机构可以在允许实验室部署模型之前检查实验室是否可以使用其可解释性技术来检测木马或控制玩具分发转移的泛化。</p><p><strong>从错位的人工智能中提取人工智能安全研究。</strong>由于测试台问题很容易衡量，人工智能系统可以因在这些问题上取得的进展而直接获得奖励。例如，开发人员可以指示人工智能系统编写一个程序来控制各种分布变化的泛化。通过阅读人工智能系统提供的程序，开发人员也许能够了解有关控制泛化的重要见解。如果测试平台对游戏足够鲁棒，即使是公然错位的模型也可能被迫做出真正的人工智能安全研究贡献（或者训练过程将用这样做的模型取代它们）。</p><h2>试验台设计注意事项</h2><p><strong>测试平台应该对“游戏”具有鲁棒性。</strong>如果测试平台用于监管或从失调的人工智能中提取人工智能安全研究，那么测试平台必须能够抵御对抗性的游戏尝试。例如，从表面上看，TrojAI 似乎是对可解释性技术的一个很好的测试。然而，许多在此基准测试中表现出色的论文与人工智能安全无关。例如，<a href="https://arxiv.org/pdf/2110.08335.pdf"><u>本文</u></a>使用 SGD 来搜索输入中的“简单”触发模式。这很有效，因为基准测试中的大多数触发模式恰好都很简单。设计强大的测试台可能需要仔细思考和大量迭代（理想情况下应该尽早开始！）</p><p><strong>测试平台在与其核心类比无关的所有方面都应该是多样化的。</strong>跟踪测试台的哪些方面实际上与您真正关心的问题类似非常重要。例如，将诚实从“五年级学生可以回答的问题”推广到“博士可以回答的问题”似乎类似于将诚实推广到超人困难的问题。但<i>为什么</i>这些问题都相似呢？ “从易到难”的分布转变有什么特别之处吗？如果不是，还应该衡量不同领域、角色等之间的泛化。从不同的类比集合中提取可以对人工智能安全工具进行更稳健的评估，就像采用异质样本如何更好地估计癌症治疗是否有效一样。</p><h2>结论</h2><p>我的印象是，许多监管机构和研究人员都在考虑评估人工智能系统的安全性，就像我们面前有一个囚犯一样，我们需要对他们进行一系列心理测试，以确定是否应该将他们释放到社会中。</p><p>这对安全评估的描述过于严格。人们需要进行一个重要的概念转变，从“这个特定的人工智能系统有多安全”到“我们的工具有多有效？”第二个问题清楚地告诉了前者，但直观上似乎更容易回答。</p><p>我目前正在考虑如何为人工智能安全建立更好的“测试平台”。如果您有兴趣合作，请通过<a href="mailto:joshuamclymer@gmail.com"><u>joshuamclymer@gmail.com</u></a>与我联系</p><p><br></p><br/><br/><a href="https://www.lesswrong.com/posts/okmB8ymyhgc65WckN/testbed-evals-evaluating-ai-safety-even-when-it-can-t-be#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/okmB8ymyhgc65WckN/testbed-evals-evaluating-ai-safety-even-when-it-can-t-be<guid ispermalink="false"> okmB8ymyhgc65WckN</guid><dc:creator><![CDATA[joshc]]></dc:creator><pubDate> Wed, 15 Nov 2023 19:00:42 GMT</pubDate> </item><item><title><![CDATA[Listening to Pascal Muggers]]></title><description><![CDATA[Published on November 15, 2023 6:06 PM GMT<br/><br/><p><br><strong><u>概括</u></strong><i><strong><u> </u></strong><u>-</u>我们已经被“帕斯卡抢劫者”抢劫了<strong>——</strong>这种内心想法认为后果如此巨大，以至于超越了所有正常的考虑。事情很模糊，但考虑到利害关系，不给予任何关注是不负责任的。同时，高效意味着不要给予他们超出任何可能有用的注意力。</i><br></p><h2>介绍</h2><p><u>在</u><a href="https://www.lesswrong.com/posts/a5JAiTdytou3Jg749/pascal-s-mugging-tiny-probabilities-of-vast-utilities"><u>《Pascal&#39;s Mugging: Tiny Probabilities of Vast Utilities</u></a> 》（2007 年）中，Eliezer Yudkowsky 描述了一个思想实验： <span class="footnote-reference" role="doc-noteref" id="fnrefrcut65obs6"><sup><a href="#fnrcut65obs6">[1]</a></sup></span></p><blockquote><p>现在假设有人来找我说：“给我五美元，否则我将使用矩阵之外的魔力来运行一台图灵机来模拟并杀死 3^^^^3 个人。”</p></blockquote><p>以利以谢还写道：</p><blockquote><p>你或我可能会一笑置之，根据占主导地位的主线概率进行计划</p></blockquote><p>不是我。</p><p>这让我彻夜难眠。</p><p>好像我不能理解3^^^^3，感觉好浩瀚。这个数字感觉就像任何其他“奇怪的大数字”。问题是我知道我不能真正认为抢劫犯说的是假话的“可能性很小”。同时我知道抢劫犯可以任意增加公用事业的规模。如果我根据最大化预期价值做出决定，我应该支付 5 美元（或为此支付我的全部钱）。但给抢劫犯 5 美元的感觉很糟糕，放弃理性也很糟糕。</p><p>这两种选择似乎都需要做出无限愚蠢的承诺🤢</p><h2>让帕斯卡劫匪就位</h2><p>我们的情绪不能超越几个层次。在普通的大思维中，我们的情感影响量表可能类似于： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/kgkfqgbs21fnmpitcz7j" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/qvm5vnoef39ozcf14pcl 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/g30fzpnlq2cxm8oknslw 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/voqp0ccqlwjtpwdjxl36 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/zl2qdauebouybrgzgxxl 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/nrgu2v7zwinc03kxsnlf 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/erg9yk5oxhvgewp8r9o8 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/jnft7iwkzrfasl7l0hl7 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/hk9hsmxfq58caxstgtvq 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/nl30cktfb9vmlulorr9a 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/ule7bazztjrljt88n0sd 960w"></figure><p>但是，如果我们再推送一个 util，然后再推送另一个，依此类推，会怎么样呢？有没有什么你看重的东西可以无限扩展，或者如果不是的话，它会止步于何处？您有多确定您不想避免再多一种效用（例如，防止再创造一个受折磨的人）或获得另一种效用（例如，与此相反）？</p><p>此时，我们已经达到了“奇怪的考虑因素”，在计算期望值时，所有普通结果都是无关紧要的： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/odq2xlwzcbxq7dpyeehk" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/y2qnm8jmx3keisdnr1pc 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/dphtjar4umincs6ugo2m 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/sw0vfcscdbbjkn2tc7cl 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/kbh79apb1skinptm38uj 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/lcldo3ri9rdkafb9qcri 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/p7cwzt79qighnsambtr1 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/pb48i8alj7xhxn40gvni 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/vf2dyz9nuun2vccuy5jv 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/fcxxbddnzuh7cgev0awg 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/eyrjnebkjsq6wzrtxibj 960w"></figure><p>现在我们可以轻松地拒绝 3^^^^3 劫匪，因为它只是奇异的坏云中的又一项。我们可以回答：“<i>别拿这些小事来烦我，我只想拯救3^^^^^3条生命！</i> ”（还有更大、概率更高的选项，比如多想一想。 ）</p><p>当我们窥探云内部时会发生什么？更极端的实用程序可能会胜过其他实用程序： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/t9hokztkttpiyojotwul" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/o1mgmi8lkdxndozl5tpw 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/jetyctegrfjha3hxv2qg 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/ghbgm7sxacrrm73p91jp 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/icgx2zyqckvloua9b2gv 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/nstus4bl43sp6j6bc8c1 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/bu7rxw3gi3kihprjiube 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/hob6onvjfeg1biegkxx9 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/rjgj6yjlx76es2pcsxtc 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/um8yovu724qb63obq5ea 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/fvxwv976upj8znvlpqpw 960w"></figure><p>康托尔的“绝对无穷大”（Ω）有什么意义吗？ Ω 公用事业/非公用事业的可能性是否应该压倒一切？难道这已经失去了人性的温暖吗？我们是否已经离开了准确世界模型之上的真实偏好之地，进入了元伦理学的荒原？</p><p>也许没有任何答案。</p><p>所以你会怎么做？</p><p>你玩赔率😅 <span class="footnote-reference" role="doc-noteref" id="fnrefndu3c0vdwsd"><sup><a href="#fnndu3c0vdwsd">[2]</a></sup></span></p><h2>对战略的影响</h2><p>在<a href="https://www.lesswrong.com/posts/78G9pjYM2KohErCvJ/model-uncertainty-pascalian-reasoning-and-utilitarianism"><u>模型不确定性、帕斯卡推理和功利主义</u></a>(2011) 中， <a href="https://www.lesswrong.com/users/multifoliaterose?mention=user">@multifoliaterose</a>分析了帕斯卡的论点，即所有慈善努力都应旨在影响无限实验室宇宙的创造：</p><blockquote><p>反驳#3：即使一个人的焦点应该放在实验室宇宙上，这样的焦点会减少到对创建友好人工智能的关注，这样的实体会比我们更好地推理实验室宇宙是否是一件好事以及如何做。去影响他们的创作。</p><p>回应：这里也是如此，如果这是真的，那就不明显了。即使一个人成功地创造了一种同情人类价值观的通用人工智能，这样的通用人工智能也可能不会归因于功利主义，毕竟许多人不是，而且目前还不清楚这是因为他们的意志没有被连贯地推断出来</p></blockquote><p>所以这不是一个答案。提案<i>需要</i>一个单独的帖子——模型/哲学不确定性、目标和策略的组合——但这就是对付帕斯卡抢劫犯的温和、常识性的方法。我将其视为抢劫，并不是因为有一天人类创造出某种东西来创造全新宇宙的可能性如此之小，而是因为实用程序的巨大性意味着胜过其他一切。</p><p>在<a href="https://www.lesswrong.com/posts/ebiCeBHr7At8Yyq9R/being-half-rational-about-pascal-s-wager-is-even-worse"><i><u>《对帕斯卡赌注的半理性更糟糕</u></i></a><i>》（2013）</i>中，埃利泽写道：</p><blockquote><p><i>从我记事起，我就纯粹出于实际原因拒绝了所有形式的帕斯卡赌注：任何试图通过追逐万分之一的巨额回报的机会来规划自己的生活的人几乎肯定会在实践中注定失败……现在，在极少数情况下，我发现自己在思考这种元级别的垃圾，而不是手头的数学，我提醒自己，这是一个浪费的动作——“浪费的动作”是指回想起来，如果问题出在哪里，任何想法都会出现。事实上已经解决了，并没有为问题的解决做出贡献。</i></p></blockquote><p>在实践中，接受抢劫与忽视抢劫之间可能没有什么区别，但考虑到巨大的实用性并偶尔重新审视对我来说似乎是正确的。</p><h2>不偏离轨道</h2><p>帕斯卡抢劫式思维可能会导致基于可疑的哲学论证而做出超出常规行为范围的事情。特德·卡辛斯基（Ted Kaczynski）（大学炸弹客）并没有特别奇怪的观点（即日益增长的工业主义正在破坏我们与自然的和谐）。他的不同寻常之处在于他按照这些原则行事。就他而言，他犯了一个错误，在实施他的炸弹人“战略”之前没有与其他任何人交谈。并不是所有愚蠢的事情都可以通过与至少一些外群体成员讨论的启发式方法来预防，但它应该被视为避免偏离轨道的一个良好起点。</p><h2>结论</h2><p>考虑到利害关系，不将帕斯卡抢劫的考虑因素作为制定计划的出发点的一部分并不时重新审视是不负责任的，但不能以牺牲总体效率为代价，因为有效为大型公用事业提供了许多可能的路线，而一般模型的不确定性让人质疑这是否是看待这个问题的正确方法。</p><p> （最后一点，帕斯卡抢劫案是对这个问题的一个非常消极的框架，但探索巨大公用事业的整体不对称性和影响是另一篇文章的主题。） <br></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnrcut65obs6"> <span class="footnote-back-link"><sup><strong><a href="#fnrefrcut65obs6">^</a></strong></sup></span><div class="footnote-content"><p> Eliezer 的原始帖子专门与所罗门诺夫归纳法中的概率相关，其中图灵机的效用增长速度比其先验概率收缩的速度要快得多，但包括我在内的许多人将其视为个人问题，并且是评论最多的问题之一LessWrong 上的帖子。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnndu3c0vdwsd"> <span class="footnote-back-link"><sup><strong><a href="#fnrefndu3c0vdwsd">^</a></strong></sup></span><div class="footnote-content"><p> 😅 是“汗水微笑”表情符号。我更喜欢看起来更坚定/更享受的东西，但找不到一个表情符号来捕捉这一点。我希望表情符号有助于让事情脚踏实地，在面对超现实的考虑时不要<i>过于</i>严肃。 </p><p><img style="width:39.12%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/z1khght3w6bgpagmf4w9" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/kqjwdbdekvlpautobws8 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/b9x31hbwgevhiemtbqup 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/qz0nlxr42xiiofs3i6nv 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/dhebklhymltoqajhq1v1 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/yimehxwqrgjottfvqnya 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/pjiisl24jn171zz57rtn 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/fj1lriucgmnij2lko14e 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/ma1bc2isdnqlvsnrgcri 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/iqkdvlyygn1uwyg0cyp4 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/DdSnA73EQcWXzhs5j/dvwkphnsxreyuzp1pcvm 1200w"></p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/DdSnA73EQcWXzhs5j/listening-to-pascal-muggers#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/DdSnA73EQcWXzhs5j/listening-to-pascal-muggers<guid ispermalink="false"> DdSnA73EQcWXzhs5j</guid><dc:creator><![CDATA[cSkeleton]]></dc:creator><pubDate> Wed, 15 Nov 2023 18:06:37 GMT</pubDate> </item><item><title><![CDATA[New report: "Scheming AIs: Will AIs fake alignment during training in order to get power?"]]></title><description><![CDATA[Published on November 15, 2023 5:16 PM GMT<br/><br/><p> （从<a href="https://joecarlsmith.com/2023/11/15/new-report-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">我的网站</a>交叉发布）</p><p>我写了一份报告，内容是关于高级人工智能是否会在训练期间假装对齐，以便稍后获得权力——我将这种行为称为“诡计”（有时也称为“欺骗性对齐”）。该报告可在 arXiv<a href="https://arxiv.org/abs/2311.08379">上</a>查看： <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">这里</a>还有一个音频版本，我在下面包含了介绍部分。本节包括报告的完整摘要，其中涵盖了大部分要点和技术术语。我希望摘要能够提供理解报告各个部分所需的大部分背景信息。</p><h1>抽象的</h1><blockquote><p>这份报告研究了在训练中表现良好的高级人工智能是否会这样做，以便在以后获得权力——我将这种行为称为“阴谋”（有时也称为“欺骗性联盟”）。我的结论是，使用基线机器学习方法来训练足够复杂的目标导向人工智能来进行计划，阴谋是一个令人不安的合理结果（在给定这些条件的情况下，我对这种结果的主观概率约为 25%）。特别是：如果在训练中表现良好是获得力量的一个好策略（我认为很可能是这样），那么各种各样的目标就会激发计划——从而带来良好的训练表现。这使得训练可能自然地实现这样的目标然后强化它，或者积极推动模型的动机实现这样的目标，作为提高性能的简单方法。更重要的是，由于阴谋者假装在旨在揭示其动机的测试上保持一致，因此可能很难判断这种情况是否已经发生。不过，我也认为有安慰的理由。特别是：阴谋实际上可能不是获得权力的好策略；训练中的各种选择压力可能不利于阴谋者的目标（例如，相对于非阴谋者，阴谋者需要进行额外的工具推理，这可能会损害他们的训练表现）；我们也许可以有意地增加这样的压力。该报告详细讨论了这些问题以及各种其他考虑因素，并提出了一系列实证研究方向以进一步探讨该主题。</p></blockquote><h1> 0. 简介</h1><p>寻求权力的特工往往有动机欺骗他人其动机。例如，考虑一下竞选活动中的政治家（“我<em>非常</em>关心你的宠物问题”），求职者（“我只是对小部件感到非常兴奋”），或者寻求父母赦免的孩子（“我”我非常抱歉，再也不会这样做了”）。</p><p>这份报告探讨了我们是否应该期望在训练期间动机看似良性的先进人工智能会参与这种形式的欺骗。在这里，我区分了四种（越来越具体）类型的欺骗性人工智能：</p><ul><li><p><strong>结盟伪造者</strong>：人工智能假装比实际更加结盟。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-1" id="fnref-jCfZhXha29uHnHWwY-1">[1]</a></sup></p></li><li><p><strong>训练游戏玩家</strong>：人工智能了解训练他们的过程（我将这种理解称为“情境意识”），并且正在针对我所说的“情节奖励”进行优化（并且通常会激励假装对齐） ，如果这样做会带来奖励）。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-2" id="fnref-jCfZhXha29uHnHWwY-2">[2]</a></sup></p></li><li><p><strong>权力驱动的工具训练游戏玩家（或“阴谋家”）</strong> ：专门进行训练游戏的人工智能，目的是为了以后为自己或其他人工智能获得权力。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-3" id="fnref-jCfZhXha29uHnHWwY-3">[3]</a></sup></p></li><li><p><strong>目标守护阴谋者：</strong>其权力寻求策略特别涉及试图阻止训练过程改变其目标的阴谋者。</p></li></ul><p>我认为，根据粗心的人类反馈进行微调的先进人工智能很可能默认以各种方式伪造对齐，因为粗心的反馈会奖励这种行为。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-4" id="fnref-jCfZhXha29uHnHWwY-4">[4]</a></sup>很可能，这样的人工智能也会玩训练游戏。但我在这份报告中的兴趣特别在于他们是否会将这样做作为以后获得权力的策略的一部分——也就是说，他们是否会成为阴谋家（这种行为在文献中通常被称为“欺骗性联盟”，虽然我不会在这里使用这个术语）。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-5" id="fnref-jCfZhXha29uHnHWwY-5">[5]</a></sup>我的目的是澄清和评估支持和反对这一期望的论点。</p><p><strong>我目前的观点是，阴谋是使用基线机器学习方法（例如：自我监督预训练，然后针对各种现实世界任务进行 RLHF）训练高级、目标导向的人工智能的令人担忧的合理结果</strong>。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-6" id="fnref-jCfZhXha29uHnHWwY-6">[6]</a></sup>在我看来，引起关注的最基本原因是：</p><ol><li><p>在训练中表现良好可能是获得总体力量的一个很好的工具性策略。</p></li><li><p>如果是这样，那么各种各样的目标就会激发计划（从而产生良好的训练表现）；而与良好训练表现兼容的非计划目标则更加具体。</p></li></ol><p>在我看来，（1）和（2）的结合似乎是合理的，即以训练创建目标导向的、情境感知的模型为条件，它很可能出于某种原因灌输类似阴谋家的目标。尤其：</p><ul><li><p>训练可能会“自然地”达到这样的目标（无论是在态势感知出现之前还是之后），因为这样的目标最初会导致训练中表现足够好，即使没有训练游戏。 （尤其是如果你有意尝试诱导你的模型在长期范围内进行优化，我认为会有动力这样做。）</p></li><li><p>即使类似策划者的目标不会“自然地”出现，一旦模型具有参与训练博弈的态势感知能力，主动将模型<em>转变</em>为策划者可能是 SGD 提高模型训练性能的最简单方法。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-7" id="fnref-jCfZhXha29uHnHWwY-7">[7]</a></sup></p></li></ul><p>更重要的是，由于阴谋者积极假装在旨在揭示其动机的测试中保持一致，因此可能很难判断这种情况是否已经发生。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-8" id="fnref-jCfZhXha29uHnHWwY-8">[8]</a></sup>这似乎是值得严重关注的原因。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-9" id="fnref-jCfZhXha29uHnHWwY-9">[9]</a></sup></p><p>不过，我也认为有安慰的理由。我将它们分为两类。</p><p>第一类的中心思想是，阴谋实际上并不是一种非常收敛的工具性策略。</p><ul><li><p>例如：关于策划者最常见的故事集中在<em>目标守护</em>策划者身上，他们通过训练游戏来防止他们的目标被训练过程所改变。但我不清楚这是否会足够好（特别是：尽管训练游戏<sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-10" id="fnref-jCfZhXha29uHnHWwY-10">[10]</a></sup> ，但目标修改可能会继续），或者由此产生的目标将获得足够大的未来力量，以足够高的概率，以证明模型通过训练游戏而产生的任何成本是合理的，而不是直接实现其目标（如果这些成本有意义 - 对于某些模型来说可能没有意义）。</p></li><li><p>关于为什么阴谋将是一种很好的工具性策略，还有其他一些故事——例如，以具有不同价值观的人工智能之间的协调为中心的故事；人工智能默认具有非常相似的值的可能性；以及人工智能本质上重视诸如“我的生存”（以容忍价值观变化的方式）和/或“人工智能赋权”（以宽容人工智能如此赋权的方式中非常不同的价值观的方式）之类的可能性。虽然这些故事确实使阴谋看起来像是一个更具分离性的假设，但对我来说，其中一些故事对我来说似乎是（a）更具推测性和（b）要求我们假设具有更具体目标类型的模型的某种组合（从而削弱上述（2）的力量）。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-11" id="fnref-jCfZhXha29uHnHWwY-11">[11]</a></sup></p></li></ul><p>第二类集中于可能<em>反对</em>阴谋的选择压力形式——既是“自然的”，也是因为我们可以在训练中有意地引入/强调这些选择压力。</p><ul><li><p>例如：相对于其他类型的模型，策划者需要进行额外的工具推理（例如，从长期目标到训练游戏的工具价值的回溯，并检查逃跑/叛逃的机会）。这可能会对其性能造成巨大的损失——我们可以故意增加这一成本，例如将模型置于更多的时间压力下，迫使它们依靠人类可读的便签本进行推理，并进行真正的逃跑/背叛机会与陷阱更难区分。如果阴谋者在人类控制下积极尝试破坏人类联盟和安全工作（在我看来，这是最可怕的阴谋形式），他们的表现似乎可能会受到更显着的打击。</p></li><li><p>更重要的是，我自己的猜测是，这种额外的工具推理的成本大大超过了有时被称为“简单”的阴谋的好处——即，选择一个阴谋者允许 SGD 选择一个更简单的目标这一事实带来的好处（因为它有种类繁多，可供选择）。尤其是考虑到阴谋者和非阴谋者都需要详细地表示“诚实”、“人类价值观”、“奖励”等概念，因此阴谋者似乎只能通过使用复杂性的差异来节省复杂性。 /重新利用/“指向”一个给定的概念来指导模型的动机。</p></li><li><p>另外：在态势感知之前，每当类似阴谋者的目标导致牺牲奖励时，训练都会积极地<em>对其进行惩罚</em>（更多关于我在下面所说的“情节”的意思）。我们可以尝试进一步积极推动这个方向——特别是如果我们能够学会在态势感知出现时进行检测和控制。</p></li></ul><p>我认为第二类在这里尤其重要。特别是：诉诸在训练中表现良好的类计划者目标与非计划者目标的比较数量（和/或“度量”）的论点可能会出错的一种方式是忽略选择压力的全部力量应用于培训选择的目标。因此，如果培训中施加的压力总体上<em>对</em>阴谋者起作用，那么这是一个非常好的消息。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-12" id="fnref-jCfZhXha29uHnHWwY-12">[12]</a></sup></p><p>完整报告更详细地讨论了这些问题以及各种其他相关考虑因素（完整摘要请参阅第 0.2 节）。</p><p><strong>总的来说，作为量化我当前观点的粗略尝试：如果你使用自监督预训练 + RLHF 的基线形式在不同的、长期的数据集上训练一个连贯的目标导向、情境感知、比人类水平更好的模型， -地平线，现实世界的任务，我的主观概率是~25%，这将在很大程度上作为为自己和/或其他人工智能寻求权力的工具策略的一部分在训练中表现良好。</strong> <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-13" id="fnref-jCfZhXha29uHnHWwY-13">[13]</a></sup></p><ul><li><p>我还认为可以通过相当简单的方式降低风险：例如，通过短期任务的培训，或者在态势感知之前进行更密集形式的对抗性训练。</p></li><li><p>我认为风险会随着更强大的模型<em>而增加</em>，这些模型可能更有能力逃脱/接管（并与其他人工智能协调/合作这样做）。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-14" id="fnref-jCfZhXha29uHnHWwY-14">[14]</a></sup></p></li></ul><p>另外，重要的是：非阴谋者也可能做出类似阴谋者的行为。例如：</p><ul><li><p>仅针对给定剧集的奖励进行优化的模型可以伪造其对齐（甚至：参与逃脱/接管），以努力获得该奖励（特别是如果所讨论的剧集相当长）。</p></li><li><p><em>不</em>参加训练游戏的模型最终仍然可能会追求权力目标，从而激励各种形式的欺骗。</p></li><li><p>最重要的最终人工智能可能在重要方面与我在这里关注的人工智能范式有所不同——例如，它们可能更像“<a href="https://lilianweng.github.io/posts/2023-06-23-agent/">语言模型代理</a>”而不是单一模型， <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-15" id="fnref-jCfZhXha29uHnHWwY-15">[15]</a></sup>或者它们可能是通过以下方法创建的：与我所关注的基线机器学习方法有更大的不同——同时仍然从事权力驱动的对齐伪造。</p></li></ul><p>正如我所定义的，阴谋远非这附近唯一令人担忧的问题。相反，这是这种担忧的一个范例，在我看来，这是一个特别迫切需要理解的例子。在报告的最后，我讨论了一系列可能的实证研究方向，以进一步探讨该主题。</p><h2> 0.1 预备知识</h2><p><em>（本节提供了一些初步内容来框架报告的讨论。那些渴望了解主要内容的人可以跳到第 0.2 节中的报告摘要。）</em></p><p>我集中撰写这份报告是因为我认为，在评估错位人工智能的整体存在风险水平时，阴谋/“欺骗性联盟”的概率是最重要的问题之一。事实上，阴谋对于这种风险如何产生的许多模型来说尤其重要。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-16" id="fnref-jCfZhXha29uHnHWwY-16">[16]</a></sup>正如我在下面讨论的，我认为这是失调可能采取的最可怕的形式。</p><p>然而：尽管这个话题对人工智能风险很重要，但公众的直接关注相对较少。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-17" id="fnref-jCfZhXha29uHnHWwY-17">[17]</a></sup>我的感觉是，对它的讨论常常对所讨论的动机/行为的具体模式以及为什么人们可能会或可能不会期望它发生感到模糊。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-18" id="fnref-jCfZhXha29uHnHWwY-18">[18]</a></sup>我希望在这份报告中能够澄清此类讨论，根据其重要性来深入和详细地处理该主题，并促进更多正在进行的研究。特别是，尽管该报告具有理论性质，但我特别感兴趣的是为可能提供进一步启示<em>的实证</em>研究提供信息。</p><p>我试图为那些不一定熟悉任何先前有关阴谋/“欺骗性联盟”的作品的读者写作。例如：在第 1.1 和 1.2 节中，我从头开始列出了讨论所依赖的概念分类。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-19" id="fnref-jCfZhXha29uHnHWwY-19">[19]</a></sup>对于一些读者来说，这可能感觉像是在重新讨论旧的观点。我邀请这些读者在他们认为合适的时候跳过（特别是如果他们已经阅读了报告的摘要，并且知道他们错过了什么）。</p><p>也就是说，我确实假设人们更普遍地熟悉（a）关于人工智能失调带来的存在风险的基本论点， <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-20" id="fnref-jCfZhXha29uHnHWwY-20">[20]</a></sup>和（b）当代机器学习如何运作的基本情况。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-21" id="fnref-jCfZhXha29uHnHWwY-21">[21]</a></sup>我还做了一些其他假设，即：</p><ul><li><p>相关类型的人工智能开发正在以机器学习为中心的范式（以及社会政治环境）中进行，与 2023 年大致相似<sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-22" id="fnref-jCfZhXha29uHnHWwY-22">。 [22]</a></sup></p></li><li><p>我们没有强大的“可解释性工具”（即帮助我们理解模型内部认知的工具）来帮助我们检测/防止阴谋。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-23" id="fnref-jCfZhXha29uHnHWwY-23">[23]</a></sup></p></li><li><p>我讨论的人工智能是目标导向的，即：可以理解为在世界模型的基础上制定和执行计划，追求目标。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-24" id="fnref-jCfZhXha29uHnHWwY-24">[24]</a></sup> （我不认为这个假设是无害的，但我想将关于是否期望目标导向本身的争论与关于是否期望目标导向模型成为阴谋者的争论分开——我鼓励读者这样做以及。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-25" id="fnref-jCfZhXha29uHnHWwY-25">[25]</a></sup> ）</p></li></ul><p>最后，我想指出报告中讨论的一个让我感到非常不舒服的方面：即，在我看来，除了对人类构成潜在的生存风险之外，报告中讨论的人工智能很可能是道德的。患者凭自己的权利。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-26" id="fnref-jCfZhXha29uHnHWwY-26">[26]</a></sup>我在这里说话，就好像它们不是，并且好像对人工智能进行任何最能服务于我们目的的治疗都是可以接受的。但如果人工智能是道德患者，情况就不是这样了——当一个人发现自己在说（尤其是：反复说）“让我们暂时假设，对<em>某类</em>存在做任何我们想做的事情是可以接受的，尽管事实上，这似乎不是，”人们应该坐直并想知道。我在这里把人工智能道德耐心问题放在一边，不是因为它们不真实或不重要，而是因为它们会给已经很长的讨论带来许多额外的复杂性。但这些复杂性正在迅速降临到我们身上，我们需要具体的计划来负责任地处理它们。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-27" id="fnref-jCfZhXha29uHnHWwY-27">[27]</a></sup></p><h2> 0.2 报告摘要</h2><p>本节提供了完整报告的摘要。它包含了大部分要点和技术术语（不幸的是，为了使内容更容易理解而提供的具体示例相对较少）。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-28" id="fnref-jCfZhXha29uHnHWwY-28">[28]</a></sup>我希望它能够（a）让读者很好地了解他们对正文的哪些部分最感兴趣，并且（b）使读者能够跳到这些部分，而不必过多担心什么他们错过了。</p><h3> 0.2.1 第 1 节总结</h3><p>报告主要有四个部分。第一部分（第 1 节）旨在澄清上述人工智能欺骗的不同形式（第 1.1 节），将阴谋者与我将讨论的其他可能的模型类（第 1.2 节）区分开来，并解释为什么我认为阴谋是一种独特而可怕的错位形式（第 1.3 节）。我对将阴谋者与以下人员进行对比特别感兴趣：</p><ul><li><p><strong>剧集奖励寻求者</strong>：也就是说，人工智能系统最终重视剧集奖励过程的某些组成部分，并因此而玩训练游戏。</p></li><li><p><strong>训练圣人</strong>：直接追求奖励过程指定目标的人工智能系统（我将其称为“指定目标”）。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-29" id="fnref-jCfZhXha29uHnHWwY-29">[29]</a></sup></p></li><li><p><strong>错误概括的非训练游戏玩家</strong>：既不玩训练游戏<em>也不</em>追求指定目标的 AI。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-30" id="fnref-jCfZhXha29uHnHWwY-30">[30]</a></sup></p></li></ul><p>这是总体分类图： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTLvooL44SPEFWGhD/s1uqfkjys8bmk2qaidhp" alt=""></p><p>所有这些模型类都可能错位且危险。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-31" id="fnref-jCfZhXha29uHnHWwY-31">[31]</a></sup>但我认为阴谋家特别可怕。特别是：阴谋促使最强有力和​​对抗性的努力来阻止人类了解所讨论的失调<sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-32" id="fnref-jCfZhXha29uHnHWwY-32">[32]</a></sup> ；它最有可能引发我所说的“早期破坏”——也就是说，人工智能在人工智能发展的相对早期阶段，积极尝试破坏人类协调、控制和保护未来人工智能系统的努力。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-33" id="fnref-jCfZhXha29uHnHWwY-33">[33]</a></sup></p><p>我还讨论了（在第 1.4 节中）该报告所关注的类型的理论论据是否值得考虑。我在这里的回答是“有点有用”，既可以为实证调查提供信息，也可以在缺乏足够实证数据的情况下作为证据来源，但我们显然应该尽可能多地寻找实证证据（我在这方面提供了一些建议）第 6 节）。</p><p>在第 1.5 节中，我讨论了一个在我看来对评估我所考虑的各种论点很重要的因素：即训练给人工智能带来的“松弛”程度，使其表现不佳。</p><h3> 0.2.2 第 2 节小结</h3><p>报告的第二部分探讨了策划的先决条件。我特别关注：</p><ul><li><p><strong>态势感知：</strong>模型了解自己是训练过程中的模型，训练过程将奖励什么，以及客观世界的基本性质。</p></li><li><p><strong>超越情节目标：</strong>模型关心情节完成后其行为的后果。</p></li><li><p><strong>旨在将情节奖励作为权力驱动工具策略的一部分：</strong>该模型认为，如果针对情节奖励进行优化，那么其超出情节的目标将会更好地实现，特别是它，或者其他一些人工智能，如果这样做的话，将会获得更多的力量。</p></li></ul><p> 2.1 节讨论态势感知。我认为，如果没有积极的努力，我们至少应该期望某些类型的高级人工智能——例如，在与公共互联网实时交互中执行现实世界任务的高级人工智能——默认情况下具有态势感知能力，因为（a）意识在执行相关任务时非常有用（事实上，我们可能会积极地对其进行训练），并且（b）此类人工智能可能会接触到获得这种意识所需的信息。不过，我在报告中并没有过多关注态势感知。相反，我更感兴趣的是在情境感知模型中是否需要满足上述其他两个先决条件。</p><p> 2.2 节讨论了超越情节的目标。在这里，我（在第 2.2.1 节）区分了“情节”的两个概念，即：</p><ul><li><p><strong>激励情节</strong>：即训练中的梯度主动迫使模型进行优化的时间范围。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-34" id="fnref-jCfZhXha29uHnHWwY-34">[34]</a></sup></p></li><li><p><strong>直观情节</strong>：也就是说，我们出于某种原因将其称为“情节”的其他一些直观时间单元（例如，在其结束时给予奖励；一个此类单元中的动作与另一个单元中的结果没有明显的因果路径） ; ETC）。</p></li></ul><p>当我在报告中使用“情节”一词时，我指的是激励情节。因此，“超越情节目标”意味着：目标的时间范围超出了主动训练迫使模型进行优化的范围。但非常重要的是，激励事件不一定是直觉事件。也就是说，决定将某个时间单元称为“片段”并不意味着训练不会主动向模型施加压力，使其在超出该单元的范围内进行优化：您需要实际详细了解梯度如何流动（我担心本报告的普通读者可能会忽视这一工作）。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-35" id="fnref-jCfZhXha29uHnHWwY-35">[35]</a></sup></p><p>我还（在第 2.2.2 节）区分了两种类型的片外目标，即：</p><ul><li><p><strong>与训练游戏<em>无关的</em>超集目标</strong>：即，超集目标的产生与其在激励模型进行训练游戏中的作用<em>无关</em>。</p></li><li><p><strong>训练游戏<em>相关的</em>赛外目标</strong>：也就是说，赛外目标是<em>因为它们激发训练游戏而专门</em>出现的。</p></li></ul><p>这两种剧集外目标对应于关于阴谋如何发生的两个不同故事。</p><ul><li><p>在第一种故事中，SGD 碰巧“自然地”在模型中灌输超集目标（无论是在态势感知出现之前还是之后），<em>然后</em>这些目标开始激发阴谋。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-36" id="fnref-jCfZhXha29uHnHWwY-36">[36]</a></sup></p></li><li><p>在第二种故事中，SGD“注意到”给模型设定超集目标<em>会</em>激发阴谋（从而激发高奖励行为），因此因此积极地<em>给</em>它这样的目标。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-37" id="fnref-jCfZhXha29uHnHWwY-37">[37]</a></sup></p></li></ul><p>如果您假设态势感知已经到位，那么第二个故事就最有意义。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-38" id="fnref-jCfZhXha29uHnHWwY-38">[38]</a></sup>因此，我们剩下以下三个主要的策划路径： <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-39" id="fnref-jCfZhXha29uHnHWwY-39">[39]</a></sup> </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTLvooL44SPEFWGhD/v3064isqjtarmfhwj8qh" alt=""></p><p>在第 2.2.2.1 节中，我讨论了与训练游戏无关的赛外目标（即路径 1 和 2）。我们是否应该期望超集目标会“自然”出现？</p><ul><li><p>预计会出现这种情况的一个原因是，目标默认情况下并没有时间限制，而且“模型时间”可能与“日历时间”不同。</p></li><li><p><em>不</em>希望出现这种情况的一个原因是，每当超出情节的目标促使模型为了某些超出情节的利益而牺牲情节奖励时，训练就会主动<em>惩罚</em>情节外目标。我们也许可以使用对抗性训练来寻找这些目标并更积极地惩罚它们。</p></li></ul><p>在第 2.2.2.2 节中，我讨论了与训练比赛<em>相关的</em>赛外目标。我特别强调的问题是，考虑到需要通过模型权重的微小变化逐步进行转变，SGD 是否能够充分“注意到”将非阴谋者转变为阴谋者的好处，其中每个权重提高奖励。我认为这是对专注于训练游戏依赖的超越情节目标的故事的严重反对，但我也不认为我可以自信地排除 SGD 进行这种转变的能力（参见例如“<a href="https://en.wikipedia.org/wiki/Evolution_of_the_eye">你可以“眼睛不会进化</a>”作为我认为这种直觉可能出错的地方的一个例子）。</p><p>我还在第 2.2.3 节中讨论了模型的目标导向性可能会变得“混乱”，从而使依赖于训练游戏的故事复杂化，其中 SGD 可以简单地修改模型的目标，从而顺利地重定向其“目标”实现引擎”在一个新的方向（我认为这种“混乱”是很有可能的）。我触及了更广泛的直觉，即阴谋需要更普遍的异常高标准的目标导向性。我认为，一旦我们以结盟话语中通常假设的那种目标导向为条件（我通常也在报告中假设），这种直觉的力量就会减弱。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-40" id="fnref-jCfZhXha29uHnHWwY-40">[40]</a></sup>但无论如何，它与我们的整体概率相关。</p><p>在第 2.2.4 节中，我讨论了在积极<em>训练的</em>模型中是否更有可能实现长期（即使仍然是：情节内）目标。我认为，在这种模型中，超集目标确实更有可能——并且创建参与相当长期优化的模型的基线激励（例如，“明年为我的公司赚很多钱”）相应地令人担忧。然而，我也认为，对于避免人工智能接管的努力可能非常有用的各种认知工作（例如，旨在提高人工智能系统的一致性、可解释性和安全性的研究）可能不需要长期优化这种。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-41" id="fnref-jCfZhXha29uHnHWwY-41">[41]</a></sup></p><p>考虑到对超集目标的讨论，我在第 2.3 节中转向策划的最后一个先决条件：即决定将训练游戏作为权力驱动策略的一部分，以促进所讨论的超集目标。</p><p>在这里，我首先（第 2.3.1 节）关注我所说的关于这一决定的起源的“经典守门故事”。我们可以将这个故事分解为两个主张：</p><ol><li><p><strong>守门假说</strong>。如果模型在训练期间优化了奖励，那么在训练中存活下来的目标将是模型希望它们在未来得到提升；而如果模型在训练过程中没有优化奖励，那么模型就会减少这种奖励。</p></li><li><p><strong>给未来足够的赋能。</strong>以在 (A) 中的关键程度进行训练为条件，模型的目标最终将在一定程度上（并且有足够的概率）被授权，以证明（给定模型的其他目标、其对风险的容忍度等）追求训练-游戏的整体策略。</p></li></ol><p>然后我依次研究其中的每一个（分别在第 2.3.1.1 和 2.3.1.2 节中）。</p><p>在我看来，两者都不明显。特别是，关于守门假说：</p><ul><li><p>即使在训练游戏开始后，模型的认知仍在不断调整，以获得更好的训练性能。在我看来，这些修改也将继续影响模型的目标，特别是如果它的目标与它的能力不能完全区分开来，而是通过局部启发法、注意力模式、冲动和行为的错综复杂来实现的话。很快。</p><ul><li>因此，作为一个玩具示例：想象一下，如果我进入沙漠并堆砌砖块一百万年，我将获得一大笔钱，然后我可以将其捐赠给我选择的慈善机构。但假设在整个磨难过程中，我的大脑将连接到一台机器，该机器不断修改我的所有神经元，以鼓励更好地堆砖的行为，并阻止更糟糕地堆砖的行为。假设我的意图是尽我所能地堆砌砖块。在这个过程中，我的价值观是否会受到相关大脑修改的严重影响（例如，我会沉迷于堆砖——或者至少，对慈善事业有截然不同的品味）？这看起来至少是合理的。</li></ul></li><li><p>在经典的目标守卫故事中，一旦模型开始训练游戏，其目标的具体内容对其行为就不再重要——任何其他类似阴谋家的目标都会导致同样的结果。但这使得目标看起来可以在类似策划者的目标之间“浮动”（或者受到 SGD 内其他压力的影响，例如正则化），而不会影响训练性能。如果发生这种情况，那么诡计可能根本就不是一个好的守门策略。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-42" id="fnref-jCfZhXha29uHnHWwY-42">[42]</a></sup></p></li><li><p>当然，该模型可能会容忍其目标的<em>一些</em>变化 - 并且这些变化可能比<em>没有</em>训练游戏时发生的变化更好。但持续进行重大目标修改的可能性给经典的守门故事带来了额外的不确定性。</p></li><li><p>人们有时会谈论避免目标修改的更复杂的技术，例如，模型通过使其在训练中的良好性能取决于其目标是否被修改来更积极地操纵梯度下降（例如参见有关“<a href="https://www.lesswrong.com/posts/uXH4r6MmKPedk8rMA/gradient-hacking">梯度黑客</a>”的讨论）。我在这里不关注这些方法，但我觉得它们很难实现，特别是对于仅比人类水平更好的模型。如果阴谋需要它们起作用，我认为值得非常清楚这一点，并给予这些方法的可行性相应的关注。</p></li></ul><p>关于由此产生的目标是否得到充分授权：</p><ul><li><p>最令人担忧的阴谋者不仅仅是在未来的训练中寻求权力。相反，他们的具体目标是逃避和接管的某种结合。</p></li><li><p>但这意味着相关目标不能仅仅停留在训练中。它们还需要生存下去，直到模型能够逃脱/参与接管本身，或者对能够做到这一点的未来一代模型施加足够的实质性影响。</p><ul><li>例如，如果 GPT-6 不够强大，无法逃脱/接管自身，但 GPT-8 可以，那么 GPT-6 的主要权力路径可能会影响 GPT-7 的价值观，进而影响 GPT-7 的价值观。 GPT-8 的值。但这种影响形式是相当间接的；它可能面临诸如人类监控等进一步的重大障碍；并且它可能会涉及与最大奖励训练表现的更显着的偏差。</li></ul></li><li><p>更重要的是，相关的逃跑/接管尝试需要有适当的<em>成功</em>可能性，在模型关心的时间范围内发生，并导致模型所青睐的目标，特别是获得适当的实质性权力份额（尽管事实上，大量具有截然不同价值观的人工智能可能会争夺相关权力）。</p></li><li><p>这些不确定性削弱了类似阴谋者的策略的工具价值。然而，这些削减的重要性取决于这种策略需要满足的举证责任。特别是：模型从<em>非</em>训练游戏中获得的收益越多，就需要越有吸引力的计划才能作为策略获胜。但对于某些模型来说，训练-游戏的成本可能相对较低。对于适当“雄心勃勃”的模型来说，即使通过类似阴谋家的策略成功的可能性很低，也可能证明做出实质性牺牲是合理的。</p></li></ul><p>总的来说，在我看来，经典的守门故事似乎给阴谋作为一种工具性策略的可行性带来了一些额外的不确定性。</p><p>然而，这也不是唯一可用的故事。在第2.3.2节中，我考虑了一些“非经典”故事，它们放松了经典故事的各种限制。例如：</p><ul><li><p><strong>人工智能协调</strong>。如果具有不同价值观的人工智能在接管后协调分享权力，和/或补偿那些代表接管工作但没有强大到足以逃脱/接管自己的人工智能，那么这可能会减轻一些影响上面的发型。例如，在上面的例子中，如果 GPT-6 相信 GPT-8 掌权后会“报答”，那么 GPT-6 可能更愿意为 GPT-8 工作。我认为对这种形式的协调的一些分析太容易地假设它会（a）容易，并且（b）相对于例如与人类协调的明显策略（特别是对于仅比人类表现更好的神经网络）在一个仍然由人类控制的世界中，<em>每个人</em>的可解释性仍然没有解决）。但我认为这种类型的人工智能协调是一个真正值得关注的问题，值得认真关注——无论是在特别是在阴谋的背景下，还是在更普遍的人工智能风险的背景下。</p></li><li><p><strong>默认情况下，AI 具有相似的值</strong>。与此相关的是，如果人工智能默认情况下通常具有足够相似的值，那么这可以减少策划者专门将其自己的目标传播到未来的需要，并将其释放出来，以便更直接地代表人工智能接管/赋权。默认情况下，GPT-6 的值和 GPT-8 的值似乎至少比 GPT-6 的值和一组给定的人类值<em>更</em>相似。</p></li><li><p><strong>最终值恰好有利于逃跑/接管</strong>。我们还可以想象具有<em>最终</em>价值的模型恰好有利于逃跑/人工智能接管，即使最终获得授权的目标与模型本身的目标不太相似。例如，也许该模型重视某种基于个人身份概念的“生存”概念，能够容忍训练将导致的各种目标变化；或者也许该模型只是支持“人工智能赋权”之类的东西，即使如此赋权的人工智能不会拥有与其自己非常相似的价值观。然而，这种形式的一些故事开始对阴谋者需要达到的目标施加相当强的限制，从而破坏了阴谋的关键论据之一：即，它似乎是一个跨越各种目标的聚合良好策略。</p></li></ul><p> （我还考虑了其​​他一些替代故事——即，对阴谋的工具价值抱有错误信念的模型，对自己的联盟​​自欺欺人的模型，以及对自己的目标不确定/不清楚自己为什么想要权力的模型。但这些对我来说似乎不太重要。）</p><p>对我来说，此类非经典故事的出现让阴谋的理由变得更加分离。然而，在我看来，其中一些故事似乎是以下因素的结合：(a) 更具推测性，(b) 需要对人工智能将发展的目标类型做出更具体的假设。</p><p>我从第 2 部分得到的总体结论是：</p><ul><li><p>我认为，对于默认情况下期望态势感知有相对有力的论据，至少在某些类型的人工智能系统中（即，人工智能系统在与有关其身份的信息源实时交互中执行现实世界任务）。</p></li><li><p>但我对剧集之外的目标和将剧集奖励作为权力驱动工具策略的一部分感到不太清楚。</p></li></ul><p>然后，在接下来的两节中，我将研究支持和反对期待阴谋者与其他类型模型的更具体的论据。我将它们分为两类，即：</p><ul><li><p>争论重点是 SGD 在构建相关的不同模型类时需要采取的<em>路径</em>（第 3 节）。</p></li><li><p>争论重点在于所讨论的不同模型类的<em>最终属性</em>（第 4 节）。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-43" id="fnref-jCfZhXha29uHnHWwY-43">[43]</a></sup></p></li></ul><h3> 0.2.3 第 3 节总结</h3><p>报告的第三部分重点讨论前一类论点。</p><p>我根据“与训练游戏<em>无关</em>”和“与训练游戏<em>相关</em>”的赛外目标之间的区别来细分这一类别。我的感觉是，关于阴谋家之路的最传统的故事主要集中在前一种类型。其运行过程大致如下：</p><ol><li><p>由于[插入原因]，模型将制定一个（适当雄心勃勃的）与训练中良好表现相关的超集目标（以<em>不</em>通过训练游戏的方式）。这可能发生在态势感知到来之前或之后。</p></li><li><p>然后，结合态势感知，这个（适当雄心勃勃的）超集目标将开始激发训练游戏。</p></li></ol><p>考虑到我对阴谋作为一种工具性策略的可行性的疑问，我相当认真地对待这种论点。我认为最直接的问题是：为什么模型要制定这种超越情节的目标？我已经讨论了支持和反对这种期望的一些原因（在第 2.2.2.1 节的总结中），但在我看来，它们在两个方向上都不是决定性的：特别是考虑到原则上各种各样的目标可能会激发阴谋，类似阴谋家的目标似乎确实有可能以这种方式从训练中脱颖而出。虽然可以在态势感知之前使用对抗性训练来尝试防止这种情况发生，但这种训练也面临着许多障碍（例如，它需要足够多样化/彻底，需要应对了解/控制的困难）当模型发展出态势感知时，在某些情况下，当我们担心超越情节目标的发展时，模型可能已经具有态势感知）。所以我认为这种阴谋之路是一个真正令人担忧的问题。 （更多信息请参见第 3.1 节。）</p><p>然后，我在第 3.2 节中转向一个故事，重点关注与训练游戏<em>相关的</em>超集目标，该故事大致如下：</p><ol><li><p>当模型变得具有情境意识时，它可能不会追求最大奖励目标（即，在训练数据上追求的目标大致会导致与模型的其他功能一致的最大奖励）。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-44" id="fnref-jCfZhXha29uHnHWwY-44">[44]</a></sup>相反，它将追求一些低于最大奖励的代理目标。</p></li><li><p>但那时，世界模型将包含模型训练游戏所需的所有信息。 （然而，因为我们在这里关注的是关于阴谋的“训练游戏<em>依赖</em>”故事，我们假设在获得态势感知时，模型的目标还不是激发阴谋——而是进行一些进一步的修改为此需要。）</p></li><li><p>此时，SGD 修改模型以获得最大奖励的最简单方法就是使其成为一个计划者。</p></li><li><p>所以：SGD 将使模型成为一个策划者。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-45" id="fnref-jCfZhXha29uHnHWwY-45">[45]</a></sup></p></li></ol><p>如果我们抛开 SGD 是否能够“注意到”此类修改的好处的问题，在我看来，这种故事也相当令人担忧。特别是：我认为类似阴谋家的目标在目标空间中很常见，从给定的起点开始，SGD 会更容易找到这样一个目标，而不是导致最大奖励的特定非阴谋家目标。行为。</p><p>然而，非策划者的最大奖励目标——例如，指定目标或“情节奖励”——也有一些优点。例如：训练的初始阶段默认会将模型指向其附近，因为模型在该阶段需要在<em>没有</em>仪器训练游戏的情况下获得高奖励（更多信息请参见第 3.2.2.2 节）。在某种程度上，我们认为模型的目标导向性是“混乱的”，它的启发式、注意力模式、冲动等也将有可能指向这种方向——从而有可能创造额外的“工作， “就 SGD 而言，将模型转变为计划者（更多信息请参见第 3.2.2.3 节）。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-46" id="fnref-jCfZhXha29uHnHWwY-46">[46]</a></sup></p><h3> 0.2.4 第 4 节总结</h3><p>报告的第四部分研究了关注不同模型类的最终属性的论点。</p><p>我在第 4.2 节中从所谓的“计数论证”开始。它运行如下：</p><ol><li><p>这里的非阴谋模型类需要相当具体的目标才能获得高奖励。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-47" id="fnref-jCfZhXha29uHnHWwY-47">[47]</a></sup></p></li><li><p>相比之下，策划者模型类与非常广泛的（超出情节）目标兼容，同时仍然获得高回报（至少如果我们假设策划作为工具性策略有意义的其他要求已经到位）例如，经典的守门故事或其他替代故事有效）。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-48" id="fnref-jCfZhXha29uHnHWwY-48">[48]</a></sup></p></li><li><p>从这个意义上说，获得高回报的阴谋者比获得高回报的非阴谋者“更多”。</p></li><li><p>因此，在其他条件相同的情况下，我们应该期望 SGD 能够选择一个策划者。</p></li></ol><p>附近的一些东西占了我对阴谋者的信任的很大一部分（而且我认为它也经常支持其他更具体的关于期待阴谋者的论点）。然而，我最重视的论点并没有立即从“有更多可能的阴谋者比非阴谋者获得高回报”转变为“如果没有进一步的论证，SGD 可能会选择一个阴谋者”（将此称为“严格计数论证”），因为 SGD 似乎有可能主动将这些模型<em>类</em>之一优先于其他模型类。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-49" id="fnref-jCfZhXha29uHnHWwY-49">[49]</a></sup>相反，我最重视的论点是这样的：</p><ol><li><p>似乎有“很多方法”可以让一个模型最终成为一个阴谋家，并且仍然获得高回报，至少假设阴谋实际上是追求长期目标的一个很好的工具策略。</p></li><li><p>因此，如果没有一些关于为什么培训<em>不会</em>选择阴谋者的额外故事，对我来说，这种可能性应该得到实质性的重视。</p></li></ol><p>我称之为“模糊计数论证”。它并不是特别有原则，但我发现它仍然让我感动。</p><p>然后，我在第 4.3 节中转向支持期待阴谋者的“简单论据”。我认为这些论点有时会因为对所涉及的简单性的不清楚而受到影响，因此在第 4.3.1 节中，我讨论了许多不同的可能性：</p><ul><li><p> “重写简单性”（即，重写模型权重以某种编程语言实现的算法所需的程序长度，或者例如在给定通用图灵机的磁带上），</p></li><li><p> “参数简单性”（即实际神经网络用于编码相关算法的参数数量），</p></li><li><p> “ <a href="https://joecarlsmith.com/2021/10/29/on-the-universal-distribution#vi-simplicity-realism">简单性现实主义</a>”（假设简单性在某种深层意义上是一种客观的“事物”，独立于编程语言或通用图灵机，各种简单性指标试图捕获），以及</p></li><li><p>“琐碎的简单性”（它将“简单性”的概念与“先验的更高可能性”混为一谈，这种方式使得奥卡姆剃刀之类的东西根据定义变得无趣地真实）。</p></li></ul><p>我通常关注“参数简单性”，这在我看来最容易理解，并与模型的训练性能联系起来。</p><p>我还在第 4.3.2 节中简要讨论了 SGD 为简单起见而主动选择的证据。这里最直接吸引我的情况是：简单性（或者至少是参数简单性）让模型节省参数，然后可以使用这些参数来获得更多奖励。但我还简要讨论了机器学习中简单性偏差的一些其他经验证据。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-50" id="fnref-jCfZhXha29uHnHWwY-50">[50]</a></sup></p><p>为什么我们会期望简单性偏见有利于阴谋者？粗略地说：想法是，<em>由于</em>如此广泛的目标可以激发阴谋，阴谋者允许 SGD 从非常广泛的目标中进行选择，以寻找更简单的目标；而非阴谋者（获得高回报）却不会。当我们想象成为这样一个非阴谋家所需的目标相当复杂时，这似乎尤其合理。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-51" id="fnref-jCfZhXha29uHnHWwY-51">[51]</a></sup></p><p>其他条件相同，我认为这是对的。但我不确定这是一个非常大或重要的影响。一方面：我们知道像 GPT-4 这样的法学硕士能够表示大量复杂的人类概念，例如万亿级的参数——似乎包括“诚实”、“乐于助人”、“奖励”等概念。等等。因此，这限制了避免此类表示所带来的复杂性节省。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-52" id="fnref-jCfZhXha29uHnHWwY-52">[52]</a></sup>因此，作为一个玩具计算：如果我们保守地假设万亿参数模型容量的最多 1% 用于表示像“诚实”这样复杂的概念，并且它至少知道 10,000 个这样的概念（<a href="https://www.merriam-webster.com/help/faq-how-many-english-words">韦氏未删节词典）有大约 500,000 个单词</a>），那么表示诚实的概念最多需要模型表示能力的百万分之一，对于未来更大的模型来说甚至更少。</p><p>但更重要的是，这里重要的不是代表所讨论的不同目标的绝对复杂性，而是<em>以已经拥有良好的世界模型为条件的</em>复杂性。我们应该假设<em>所有</em>这些模型都需要了解指定的目标、情节的奖励过程等。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-53" id="fnref-jCfZhXha29uHnHWwY-53">[53]</a></sup>并且考虑到这样的假设，主动<em>优化</em>指定目标或奖励的<em>额外</em>复杂性成本-就情节而言，在我看来似乎非常小。似乎，它们只是：无论使用/重新利用（“指向”）世界模型的那一部分来指导模型的动机需要付出多大的代价。</p><p>当然，我们可以尝试在以这种方式使用/重新利用世界模型的不同部分的复杂性成本水平上重新运行相同的简单性论证。例如，我们可以说：“无论这个过程如何运作，对于某些目标来说，可能比其他目标更容易实现——因此，考虑到有多少类似阴谋家的目标，对于某些类似阴谋家的目标来说，可能会更容易实现。”我认为这是对期待阴谋者的简单论据的最有力形式。但这也要求放弃我们可能对目标在相关意义上“简单”的任何直觉把握。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-54" id="fnref-jCfZhXha29uHnHWwY-54">[54]</a></sup>在我看来，不同“指针”之间的简单性差异相对于模型的整体容量来说非常小，这似乎是合理的。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-55" id="fnref-jCfZhXha29uHnHWwY-55">[55]</a></sup></p><p>我还在第 4.3.5 节中讨论了简单性论证是否能够对阴谋者最终实现的目标类型做出合理的预测。特别是：这些论点的某些版本似乎可以预测阴谋者很可能最终会实现极其简单的长期目标，<em>无论这些目标是否与训练期间的显着或重要内容有任何关系——</em>我对这些预测的预测，就我个人而言，我持怀疑态度。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-56" id="fnref-jCfZhXha29uHnHWwY-56">[56]</a></sup>当然，也可以假设训练期间显着/相关的目标对于模型追求来说也将是“更简单”。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-57" id="fnref-jCfZhXha29uHnHWwY-57">[57]</a></sup>但是，如果我们以这种方式认可一些故事（我还没有听到这样做的强有力的论据），请注意，它也支持指定目标的简单性以及情节奖励，同样 - 因为这些在培训过程中<em>特别</em>突出/相关。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-58" id="fnref-jCfZhXha29uHnHWwY-58">[58]</a></sup></p><p>在第 4.4 节中，我转向<em>反对</em>计划的论点，这些论点重点关注不同模型类的最终属性。在这里，我知道的主要论点是，策划者需要进行其他模型类不需要的额外推理（这些有时被称为“速度成本”——尽管我认为它们原则上可能会影响模型算法的复杂性，因为出色地）。尤其：</p><ol><li><p><strong>决定训练游戏</strong>：模型需要从“我想要这个超出情节的事情”向后推理到“我应该在训练中表现出色”，以某种方式利用模型对在训练中表现出色将需要什么进行的预测（例如，回复：守门员、接管前景等）。</p></li><li><p><strong>检查是否到了逃跑/接管的时间：</strong>模型需要以足够的频率和准确性检查它是否处于逃跑/接管的位置（并在评估中取得成功，尽管人类努力诱捕/愚弄模型暴露其真实面目——例如，通过为其提供<em>明显的</em>背叛机会）。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-59" id="fnref-jCfZhXha29uHnHWwY-59">[59]</a></sup></p></li><li><p> <strong>（可选，但与阴谋者的可怕程度相关）早期破坏</strong>：在某种程度上，模型正在做任何事情（训练游戏除外）来支持在逃离人类控制<em>之前</em>的接管/逃脱， <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-60" id="fnref-jCfZhXha29uHnHWwY-60">[60]</a></sup>它将需要使用认知资源（a）执行相关的邪恶行为，以及（b）确保其逃脱惩罚（例如，检查它不会被抓住，找出借口，使封面故事保持一致，即使在正在接受审查等等）。</p></li></ol><p>这种推理的成本有多大？我认为（I）可能相当容易，但（II）似乎更繁重（特别是在人类积极努力将模型置于时间压力下，并使真正的逃脱/接管机会变得难以实现的背景下）与陷阱区分开）。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-61" id="fnref-jCfZhXha29uHnHWwY-61">[61]</a></sup>并且（III），如果模型成功的话，看起来可能会非常困难——而且它通常会主动要求偏离最高奖励类型的训练表现。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-62" id="fnref-jCfZhXha29uHnHWwY-62">[62]</a></sup></p><p>但更重要的是：问题——至少在模型类的最终属性之间的比较的背景下——不是所讨论的成本的绝对大小，而是它们<em>相对于计划的简单性好处的</em>大小。在这里，我目前的看法是，工具推理的成本似乎大于简单目标的好处。</p><p>这主要是一个直观的判断，但我们也可以尝试模糊地量化比较。</p><ul><li><p>因此，举例来说，假设我们的模型是一个纯前馈网络，具有 1000 层且每个输入 &lt;10,000 个串行步骤，那么在决定训练游戏（更不用说：检查叛逃机会）的策划者中，工具推理就需要采取至少十个步骤，并且在推理完成之前模型不会开始针对情节奖励进行优化。在这种情况下，工具推理会消耗大约 0.1% 的计算量，这些计算量可能会获得本集奖励或其他最大奖励目标。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-63" id="fnref-jCfZhXha29uHnHWwY-63">[63]</a></sup></p></li><li><p>代表或指出更复杂的目标的复杂性成本可能会超过这个成本吗？我的猜测是否定的。例如，如果我们遵循我上面的（在我看来保守的）计算，并假设表示（或指向）像“诚实”这样的概念的成本最多为万亿分之一参数模型参数（对于较大的模型则更少） ，那么参数减少 0.0001% 就需要超过计算量减少 0.1%——并且在没有进一步论证的情况下，对我来说，期望这一点似乎很奇怪。</p></li></ul><p>当然，这只是一个玩具计算，尚不清楚是否适用于现实世界的情况。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-64" id="fnref-jCfZhXha29uHnHWwY-64">[64]</a></sup>更广泛的一点是：如果模型缺乏串行时间思维（对于变压器来说似乎是这样），那么在计划中处于危险地位的各种工具推理似乎很可能会对模型的性能产生实质性影响。我的猜测是，相比之下，非策划目标的复杂性成本很小。</p><p>我还在第 4.4.3 节中简要讨论了我们是否可以积极塑造我们的训练过程，以更加偏向于“速度”。在这里，做一些事情似乎相对简单，比如让模型承受更多的时间压力，限制它们的计算访问，迫使它们通过人类可读的草稿本而不是内部流程进行计划，并努力让我们尝试捕获它们/使他们绊倒更复杂（因此：更需要认知来检测）。但是，在这方面的任何努力都需要避免对整体竞争力造成过大的成本（尽管如果你认为阴谋的速度成本比简单性的好处更实质性，那么只要速度相对于简单性来说<em>有点重要</em>，这可能就足够了）。</p><p> 4.5 节简要讨论了“对特定任务的内在热情”的某种类比是否可能对人工智能的表现产生影响，特别是在“混乱的目标导向”形式模糊了人工智能的能力和价值之间的界限的情况下。我发现这种考虑很有趣，但也很投机。</p><p> 4.6 节讨论了训练中“松弛”的相关性，以评估对诸如策划的简单性好处和速度成本等因素给予多少权重。特别是：特别是在高度宽松的情况下，相对于其他考虑因素，这些因素似乎是噪音中的。</p><h3> 0.2.5 第 5 节总结</h3><p>前四节是报告的主要内容。总结我的总体看法。我在上面的介绍中已经总结了大部分内容，这里不再重复。不过，我会补充一些引言中没有提到的要点。</p><p>特别是：我认为“计数论点”的某些版本巩固了我所知道的大多数其他关于预期阴谋的论点（或者至少是我认为最引人注目的论点）。也就是说：阴谋者通常被视为一种假设，因为原则上各种各样的目标都可能导致阴谋，从而更容易（a）自然地落在其中一个目标上，（b）落在其中一个“附近” ，或（c）找到其中一个比需要来自更受限空间的非策划目标“更简单”的目标。从这个意义上说，阴谋者的情况反映了更普遍地预期错位的最基本论点之一——例如，对齐是在目标空间中击中的一个非常狭窄的目标。除此之外，我们在这里特别<em>结合了</em>我们知道我们将要对相关目标进行的选择：即，它们需要使追求它们的模型获得高回报。最基本的担忧是：这还不够。</p><p>由于“计算论点”对阴谋者案件的中心地位，我认为关于<em>针对</em>阴谋者的选择压力强度的问题——例如，因为阴谋者必须参与额外推理的成本——尤其重要。特别是：我认为“计算参数”可能出错的一个关键方式是忽略主动选择在克服相关计数设置的“先验”方面所具有的力量。例如：我们<em>之所以</em>能够克服“大多数汽车部件的排列不能形成工作汽车”或“该神经网络中的大多数参数设置不能实现工作聊天机器人”的先验，是因为选择能力人类工程和 SGD 的利益就是<em>如此强大</em>。因此，如果 SGD 的选择权积极地对抗阴谋者（和/或：如果我们能让它更积极地这样做），这可能会很快克服对他们有利的“计数论点”。例如：如果有<span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="2^{100}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">100</span></span></span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>对于每个非阴谋目标都存在类似阴谋的目标，这可能会使在相关空间中实现非阴谋目标变得非常困难。但实际上，100 位的选择压力对于 SGD 来说可能很便宜（例如，考虑 100 次额外的梯度更新，每次更新的价值至少是剩余可能目标的一半）。 <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-65" id="fnref-jCfZhXha29uHnHWwY-65">[65]</a></sup></p><p>总的来说，当我退后一步并尝试从整体上看待报告中的考虑因素时，我感到被拉向两个不同的方向：</p><ul><li><p>一方面，至少以阴谋作为一种收敛良好的工具策略为条件，类似阴谋家的目标在目标空间中感觉非常普遍，而且我非常担心训练会因为某种原因而遇到它们。</p></li><li><p>另一方面，在我看来，将模型在训练中的良好表现归咎于阴谋仍然是一种直觉，就像一个相当具体和连贯的故事。</p></li></ul><p>也就是说，在“目标空间”层面上，阴谋感觉是稳健和常见的，但在“是的，这就是这个现实世界模型中发生的事情，它获得奖励是因为（或者：基本上是因为）它稍后想要为自己/其他人工智能提供动力，现在获得奖励有助于实现这一点。” <sup class="footnote-ref"><a href="#fn-jCfZhXha29uHnHWwY-66" id="fnref-jCfZhXha29uHnHWwY-66">[66]</a></sup>当我尝试粗略地平衡这两种不同的拉力（并以目标导向和情境意识为条件）时，我得到了类似于上面列出的 25% 的数字。</p><h3> 0.2.6 第 6 节总结</h3><p>我在第六节中对实证工作进行了讨论，我认为这些工作可能有助于阐明阴谋，从而结束报告。 （我还认为在这个领域有值得做的理论工作，我也列出了这方面的一些想法。但我对实证工作特别兴奋。）</p><p>我特别讨论：</p><ul><li><p>态势感知的实证研究（第 6.1 节）</p></li><li><p>关于超集目标的实证研究（第 6.2 节）</p></li><li><p>关于阴谋作为工具性策略的可行性的实证研究（第 6.3 节）</p></li><li><p>研究阴谋的“模式生物”范式（第 6.4 节）</p></li><li><p>陷阱和诚实测试（第 6.5 节）</p></li><li><p>可解释性和透明度（第 6.6 节）</p></li><li><p>安全、控制和监督（第 6.7 节）</p></li><li><p>其他一些杂项研究主题，即梯度黑客、探索黑客、SGD 对简单/速度的偏见、路径依赖、SGD 的“增量主义”、“松弛”以及学习故意创建错位的<em>非计划</em>模型的可能性 - 例如，对情节寻求奖励的人——作为避免阴谋的一种方法（第 6.8 节）。</p></li></ul><p>总而言之，我认为还有很多有用的工作要做。</p><p>现在让我们从摘要转向主要报告。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-jCfZhXha29uHnHWwY-1" class="footnote-item"><p>这里的“一致性”是指人工智能动机的安全相关属性； “假装”意味着故意歪曲事实。 <a href="#fnref-jCfZhXha29uHnHWwY-1" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-2" class="footnote-item"><p>在这里，我宽松地使用术语“奖励”，指的是训练过程用于计算用于更新模型的梯度的任何反馈信号（因此讨论还涵盖模型未通过 RL 进行训练的情况） 。我认为，根据该过程的某些组成部分，优化“奖励”的代理就是优化“表现良好”的代理。有关我的意思的更多详细信息，请参阅第 1.1.2 节和第 1.2.1 节，此处。这里“情节”的概念大致意味着“训练过程主动迫使模型优化的时间范围”，这可能与我们通常认为的训练中的情节有很大不同。我在 2.2.1 节中详细讨论了这一点。术语“训练游戏”和“态势感知”来自<a href="https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to">Cotra (2022)</a> ，尽管我的定义在某些地方有些不同。 <a href="#fnref-jCfZhXha29uHnHWwY-2" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-3" class="footnote-item"><p> “<a href="https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/">阴谋家</a>”一词来自 Cotra (2021)。 <a href="#fnref-jCfZhXha29uHnHWwY-3" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-4" class="footnote-item"><p>有关这方面的更多信息，请参阅<a href="https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to">Cotra (2022)</a> 。 <a href="#fnref-jCfZhXha29uHnHWwY-4" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-5" class="footnote-item"><p>我认为“欺骗性对齐”这个术语经常会导致上面列出的四种欺骗之间的混淆。而且：如果训练信号有缺陷，那么“欺骗性对齐”模型即使在训练期间也不需要以对齐的方式运行（也就是说，“训练游戏”行为并不总是“对齐”行为）。 <a href="#fnref-jCfZhXha29uHnHWwY-5" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-6" class="footnote-item"><p>有关我想要的培训类型的更多信息，请参阅<a href="https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to">Cotra (2022)</a> 。 <a href="#fnref-jCfZhXha29uHnHWwY-6" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-7" class="footnote-item"><p>尽管这类故事面临着这样的问题：SGD 是否能够通过对模型权重进行足够<em>增量的</em>改变来将非阴谋者修改为阴谋者，而每一个权重都会提高奖励。讨论见 2.2.2.2 节。 <a href="#fnref-jCfZhXha29uHnHWwY-7" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-8" class="footnote-item"><p>尤其是如果我们缺乏非行为证据——例如，如果我们无法使用可解释性工具来理解模型认知。 <a href="#fnref-jCfZhXha29uHnHWwY-8" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-9" class="footnote-item"><p>还有一些争论我们应该期待阴谋，因为类似阴谋的目标可以“更简单”——因为：有太多可供选择——而 SGD 选择是为了简单。我认为，从某种意义上说，类似阴谋家的目标可能会“更简单”，但除了我已经说过的内容之外，我并没有给予这些论点太多独立的分量。第 4.3 节对此有更多介绍。 <a href="#fnref-jCfZhXha29uHnHWwY-9" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-10" class="footnote-item"><p>更具体地说：即使在训练游戏开始后，模型的认知仍在不断调整，以获得更好的训练性能。在我看来，这些修改也将继续影响模型的目标（特别是如果它的目标与它的功能不能清楚地区分开来，而是通过局部启发法、注意力模式、冲动和很快）。此外，关于阴谋的最常见的故事使得阴谋者的目标的具体内容在开始训练游戏后与其行为无关，从而引入了该目标可能“浮动”的可能性（或被 SGD 内的其他压力所移动，训练游戏开始后，类似正则化的计划<em>之间</em>的目标之间的计划（这是我第一次从 Katja Grace 那里听到的反对意见）。这种可能性会产生一些复杂的反馈循环（更多讨论请参见第 2.3.1.1.2 节），但总体而言，可能的策划者之间缺乏协调，我认为这很可能成为目标守卫策略的问题。 <a href="#fnref-jCfZhXha29uHnHWwY-10" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-11" class="footnote-item"><p>在这些不同的替代故事中，我最担心的是（a）默认情况下人工智能具有足够相似的动机，因此“目标守卫”不太必要，以及（b）人工智能协调。 <a href="#fnref-jCfZhXha29uHnHWwY-11" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-12" class="footnote-item"><p>不过：与影响训练结果的其他因素相比，类似阴谋家的工具推理的成本也可能最终成为噪音。如果训练足够依赖于路径，那么尽早实现类似计划的目标就可以锁定它，即使 SGD 总体上“更喜欢”某种其他类型的模型。 <a href="#fnref-jCfZhXha29uHnHWwY-12" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-13" class="footnote-item"><p>有关我如何理解此类概率含义的更多信息，请参阅<a href="https://www.openphilanthropy.org/brain-computation-report#footnoteref4_xne824i">Carlsmith (2020)，脚注 4</a> 。我认为，提供像这样松散的、主观的概率通常可以使辩论更加激烈，并迫使人们对相关考虑因素进行全面综合。不过，我想澄清的是，即使该命题所暗示的多种形式的模糊性之外，我也只是从我的直觉中得出一个数字。我还没有建立不同考虑因素的定量模型（尽管我有兴趣看到这方面的努力），并且我认为该报告的主要贡献是分析本身，而不是这种定量结果的尝试。 <a href="#fnref-jCfZhXha29uHnHWwY-13" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-14" class="footnote-item"><p>更强大的模型也更有可能能够参与更复杂的目标守卫形式（我在下面称之为“内省目标守卫方法”；另请参阅“<a href="https://www.lesswrong.com/posts/uXH4r6MmKPedk8rMA/gradient-hacking">梯度黑客</a>”），尽管在我看来这些总体上相当困难。 <a href="#fnref-jCfZhXha29uHnHWwY-14" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-15" class="footnote-item"><p>不过：在某种程度上，这些代理接受端到端培训，而不是简单地由单独培训的组件构建而成，讨论也适用于它们。 <a href="#fnref-jCfZhXha29uHnHWwY-15" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-16" class="footnote-item"><p>例如，请参阅<a href="https://arxiv.org/abs/2209.00626">Ngo 等人 (2022)</a>以及 Deepmind 的 AGI 安全团队对“共识威胁模型”的<a href="https://www.lesswrong.com/posts/GctJD5oCDRxCspEaZ/clarifying-ai-x-risk">描述</a>（截至 2022 年 11 月）。 <a href="#fnref-jCfZhXha29uHnHWwY-16" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-17" class="footnote-item"><p>在我看来，Evan Hubinger（以及他的合作者）的工作是最显着的例外，我将在下文中广泛引用此类工作。特别参见 Hubinger 等人。 （2021）和 Hubinger（2022），以及许多其他讨论。其他公共处理包括<a href="https://www.lesswrong.com/posts/HBxe6wdjxK239zajf/what-failure-looks-like#Part_II__influence_seeking_behavior_is_scary">Christiano (2019，第 2 部分)</a> 、 <a href="https://bounded-regret.ghost.io/ml-systems-will-have-weird-failure-modes-2/">Steinhardt (2022)</a> 、 <a href="https://arxiv.org/abs/2209.00626">Ngo 等人 (2022)</a> 、 <a href="https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/">Cotra (2021)</a> 、 <a href="https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to">Cotra (2022)</a> 、 <a href="https://www.cold-takes.com/ai-safety-seems-hard-to-measure/">Karnofsky (2022)</a>和<a href="https://www.lesswrong.com/s/4iEpGXbD3tQW5atab/p/wnnkD6P2k2TfHnNmt#AI_Risk_from_Program_Search__Shah_">Shah (2022)</a> 。但其中许多内容都很短，和/或缺乏对支持和反对相关类型阴谋者的论点的深入探讨。对于“背叛”也有更基础的治疗（例如，Bostrom（2014）和<a href="https://arbital.com/p/context_disaster/">Yudkowsky（未注明日期）</a> ），其中阴谋是一个更具体的例子；以及对“趋同工具价值”的更基础的处理，可能会产生欺骗、守门员等的激励（例如， <a href="https://selfawaresystems.files.wordpress.com/2008/01/ai_drives_final.pdf">Omohundro (2008)</a> ；另请参阅<a href="https://www.alignmentforum.org/posts/XWwvwytieLtEWaFJX/deep-deceptiveness">Soares (2023)</a> ，了解 Omohundro 的相关声明） -类似的关心）。并且还有更普遍的人工智能欺骗处理方法（例如<a href="https://arxiv.org/abs/2308.14752">Park 等人 (2023)</a> ）；以及“目标错误概括”/内部对齐/台面优化器（参见，例如， <a href="https://arxiv.org/abs/2105.14111">Langosco 等人（2021）</a>和<a href="https://arxiv.org/abs/2210.01790">Shah 等人（2022）</a> ）。但重要的是，欺骗和目标错误概括本身都不构成阴谋/欺骗性联盟。最后，对于在给定无限量计算的所谓“通用先验”（参见<a href="https://ordinaryideas.wordpress.com/2016/11/30/what-does-the-universal-prior-actually-look-like/">Christiano (2016)</a> ）的背景下是否可能发生像阴谋这样的事情存在高度推测性的讨论，但这与当代神经网络的相关性极其不清楚。网络。 <a href="#fnref-jCfZhXha29uHnHWwY-17" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-18" class="footnote-item"><p>例如，参见一般的“假装对齐”和特别的“阴谋”（或：守门阴谋）之间的混淆；或者在一般目标误概括和作为目标误概括的具体结果的阴谋之间；或者在训练游戏和“<a href="https://www.lesswrong.com/posts/uXH4r6MmKPedk8rMA/gradient-hacking">梯度黑客</a>”之间作为避免目标修改的方法；或者是出于工具性原因而在训练游戏中受到威胁的激励与出于对奖励过程某些组成部分的最终关注之间的激励。 <a href="#fnref-jCfZhXha29uHnHWwY-18" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-19" class="footnote-item"><p>我希望这方面的额外清晰度将有助于避免我认为相对常见的各种混乱（尽管：相关概念在很多方面仍然不精确）。 <a href="#fnref-jCfZhXha29uHnHWwY-19" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-20" class="footnote-item"><p>例如，我试图在关于寻求权力的人工智能的简短报告中涵盖的粗略内容，<a href="https://jc.gatspress.com/pdf/existential_risk_and_powerseeking_ai.pdf">请参见此处</a>。另请参阅<a href="https://arxiv.org/abs/2209.00626">Ngo 等人 (2022)</a>了解其他概述。 <a href="#fnref-jCfZhXha29uHnHWwY-20" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-21" class="footnote-item"><p>例如，Cotra (2021) 大致涵盖的内容<a href="https://www.cold-takes.com/supplement-to-why-ai-alignment-could-be-hard/">在这里</a>。 <a href="#fnref-jCfZhXha29uHnHWwY-21" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-22" class="footnote-item"><p>有关此类假设的更多信息，请参阅<a href="https://www.alignmentforum.org/posts/Qo2EkG3dEMv8GnX8d/ai-strategy-nearcasting">Karnofsky (2022)</a> ，有关我通常会想到的模型和训练过程类型的更详细描述，请<a href="https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to#Basic_setup__an_AI_company_trains_a__scientist_model__very_soon">参阅 Cotra (2022)</a> 。 <a href="#fnref-jCfZhXha29uHnHWwY-22" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-23" class="footnote-item"><p>这并不是说我们不会。但我不想指望它。 <a href="#fnref-jCfZhXha29uHnHWwY-23" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-24" class="footnote-item"><p>有关我的意思的更多信息，请参阅<a href="https://arxiv.org/pdf/2206.13353.pdf">Carlsmith (2022)</a>的第 2.2 节，有关为什么我们应该期待这一点的更多信息，请参阅第 3 节（最重要的是：我认为这种目标导向性可能对执行复杂任务非常有用；但是另外，我认为现有的技术可能会推动我们走向这种类型的人工智能，而且我认为在某些情况下它可能会作为其他形式的认知复杂性的副产品而出现）。 <a href="#fnref-jCfZhXha29uHnHWwY-24" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-25" class="footnote-item"><p>正如我在报告第 2.2.3 节中讨论的那样，我认为我们如何理解所面临的代理/目标导向性可能会影响我们如何评估策划者的各种论点（在这里我特别区分了我称之为“干净”和“混乱”的目标导向）——我认为有理由认为，阴谋需要特别高标准的战略和连贯的目标导向。总的来说，我认为尽管在这个主题上有很多墨水，但对目标导向性的困惑仍然是我的主题候选之一，因为一般人工智能对齐话语可能会误导。 <a href="#fnref-jCfZhXha29uHnHWwY-25" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-26" class="footnote-item"><p>请参阅<a href="https://arxiv.org/abs/2308.08708">Butlin 等人 (2023)，</a>了解最近特别关注意识的概述。但我个人也对其他道德地位基础感兴趣，比如正确的自主/欲望/偏好。 <a href="#fnref-jCfZhXha29uHnHWwY-26" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-27" class="footnote-item"><p>例如，有关此主题的更多信息<a href="https://nickbostrom.com/propositions.pdf">，请参阅 Bostrom 和 Shulman (2022)</a>和<a href="https://www.lesswrong.com/posts/F6HSHzKezkh6aoTr2/improving-the-welfare-of-ais-a-nearcasted-proposal">Greenblatt (2023)</a> 。 <a href="#fnref-jCfZhXha29uHnHWwY-27" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-28" class="footnote-item"><p>如果您对某个术语或论点感到困惑，我鼓励您在绝望之前先在正文中查找其解释。 <a href="#fnref-jCfZhXha29uHnHWwY-28" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-29" class="footnote-item"><p>在给定情况下，到底什么算作“指定目标”并不总是很清楚，但粗略地说，这个想法是，在奖励过程保持不变的各种反事实场景中，对指定目标的追求会得到奖励。例如，如果训练奖励模型在反事实中获得金币，则在指定目标中“获得金币”。更多讨论见 1.2.2 节。 <a href="#fnref-jCfZhXha29uHnHWwY-29" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-30" class="footnote-item"><p>由于我在第 1.2.3 节中解释的原因，我不使用 Hubinger (2022) 强调的“内部对齐”和“可正确对齐”模型之间的区别。 <a href="#fnref-jCfZhXha29uHnHWwY-30" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-31" class="footnote-item"><p>当然，模型的目标系统可以将这些动机混合在一起。我在 1.3.5 节中讨论了这种可能性的相关性。 <a href="#fnref-jCfZhXha29uHnHWwY-31" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-32" class="footnote-item"><p>卡诺夫斯基（Karnofsky，2022）将此称为“李尔王问题”。 <a href="#fnref-jCfZhXha29uHnHWwY-32" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-33" class="footnote-item"><p>在 1.3.5 节中，我还讨论了将这些不同动机混合在一起的模型。关于给定的“混合模型”，我倾向于问的问题是它是否像纯粹的阴谋家那样可怕。 <a href="#fnref-jCfZhXha29uHnHWwY-33" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-34" class="footnote-item"><p>我在这里没有精确的技术定义，但粗略的想法是：模型接收的梯度对其在给定输入上的行为敏感的后果的时间范围。第 2.2.1.1 节中有更多详细信息。 <a href="#fnref-jCfZhXha29uHnHWwY-34" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-35" class="footnote-item"><p>例如，参见<a href="https://arxiv.org/pdf/2009.09153.pdf">Krueger 等人 (2020)</a>中的“短视”Q 学习可以在非常简单的代理中产生“跨情节”优化的方式。更多讨论请参见第 2.2.1.2 节。我并不关注报告中的此类分析，但对于确定给定训练过程的“激励事件”到底<em>是</em>什么至关重要，因此，在我看来，“超越事件目标”意味着什么。您不必从训练过程的表面描述中了解这一点，而忽视这种无知会导致严重误解训练中模型所采用的激励措施。 <a href="#fnref-jCfZhXha29uHnHWwY-35" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-36" class="footnote-item"><p>也就是说，该模型开发了一种超越情节的目标追求，它与训练中的奖励有足够的相关性，即使<em>没有</em>训练游戏，它也能在训练过程中幸存下来。 <a href="#fnref-jCfZhXha29uHnHWwY-36" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-37" class="footnote-item"><p>也就是说，即使在还没有超越情节目标的模型中，梯度也反映了策划的好处，因此积极推动模型走向策划。 <a href="#fnref-jCfZhXha29uHnHWwY-37" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-38" class="footnote-item"><p>超越情节的目标需要情境意识来激励训练游戏，从而赋予这样的目标以获得相关的好处。 <a href="#fnref-jCfZhXha29uHnHWwY-38" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-39" class="footnote-item"><p>原则上，态势感知和超集目标可以同时发展，但我不会在这里单独处理这些场景。 <a href="#fnref-jCfZhXha29uHnHWwY-39" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-40" class="footnote-item"><p>有关为什么我们应该期待这种目标导向性的更多信息，请参阅<a href="https://arxiv.org/pdf/2206.13353.pdf">Carlsmith (2022)</a>的第 2.1 节。 <a href="#fnref-jCfZhXha29uHnHWwY-40" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-41" class="footnote-item"><p>我认为，这样的论点大意是“我们需要一个‘<a href="https://arbital.com/p/pivotal/">关键行动</a>’；关键行动是长期的，我们自己无法做到；所以我们需要创建一个与我们所需要的类型完全相同的长期优化器。”最害怕的人在各个方面都是软弱的。特别是，即使抛开“关键行为”框架的问题，我认为这些论点忽视了我们可以监督的事情和我们自己可以做的事情之间的区别。更多讨论请参见第 2.2.4.3 节。 <a href="#fnref-jCfZhXha29uHnHWwY-41" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-42" class="footnote-item"><p>这是 Katja Grace 向我指出的反对意见。请注意，它会创建复杂的反馈循环，其中，对于给定的类似策划者的目标，策划是一个好的策略，前提是它对于<em>其他</em>类似策划者的目标<em>不是</em>一个好的策略，否则该目标将“漂浮”到其他类似策划者的目标中。但总的来说，由于这些不同目标之间缺乏某种形式的协调，我认为基本的动态仍然是守门故事的一个问题。有关详细信息，请参阅第 2.3.1.1.2 节。 <a href="#fnref-jCfZhXha29uHnHWwY-42" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-43" class="footnote-item"><p>在这里，我大致遵循<a href="https://www.lesswrong.com/posts/A9NxPTwbw6r6Awuwt/how-likely-is-deceptive-alignment">Hubinger 2022</a>中的一个区别，他根据他们假设的 ML 训练所具有的“路径依赖”程度对策划的论点进行分组。然而，出于我在第 2.5 节中解释的原因，我不想在这里依赖“路径依赖”的概念，因为我认为它将许多概念上不同的属性集中在一起，最好单独处理。 <a href="#fnref-jCfZhXha29uHnHWwY-43" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-44" class="footnote-item"><p>请注意，如果训练数据从不区分错误概括的目标和指定目标，那么从这个意义上说，错误概括的目标可能是“最大奖励”。例如：如果你正在训练一个模型来获得金币，但你向它展示的唯一金色圆形物体是硬币，那么目标“获得金色圆形物体”将是最大奖励。 <a href="#fnref-jCfZhXha29uHnHWwY-44" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-45" class="footnote-item"><p>作为一个有助于激发直觉的松散类比：想象一下将人类技术冻结在当前水平，并让进化选择在人类身上运行更长时间。从长远来看，你预计哪种人类（或人类后裔生物）将占据主导地位？特别是：您期望：</p><ol><li><p>本质上看重“<a href="https://en.wikipedia.org/wiki/Inclusive_fitness">包容性遗传适应性</a>”或“我的基因被进化选择”之类的人（这是对“指定目标”和“奖励过程”的某种组合的松散类比），</p></li><li><p>人们重视与包容性遗传适应性密切相关的其他事物（例如，“拥有尽可能多的孩子”），但他们甚至没有在工具上明确优化包容性遗传适应性（这是对错误概括的非遗传适应性的松散类比）训练游戏玩家），或</p></li><li><p>具有长期目标的人类正在优化包容性遗传适应性，特别是作为一种在长期内为自己的价值观获得权力的方法（这对阴谋家来说是一个宽松的类比）。</p></li></ol><p>在这里，与上面的故事类似的问题是：对现有人类价值观的最小修改是什么（或者更好：对进化最容易的修改），使我们落入上述桶之一，同时又兼容进化选择压力有多大？ （当然，这个类比带来了大量令人困惑的变量（例如，与进化选择构建学习价值的大脑的基因组而不是价值本身这一事实有关，文化积累和模因选择的作用）在人口动态中，缺乏对未来逃跑/接管机会的明确模拟，等等）。） <a href="#fnref-jCfZhXha29uHnHWwY-45" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-46" class="footnote-item"><p>也就是说，直观上，对我来说，对于 SGD 来说，“调整一个完全可分离的剧集内目标以使其长期化”比“重新引导广泛关注剧集内目标的错综复杂的目标以使其成为长期目标”要容易得多。它（a）专注于某些超出情节的事情，并且（b）使得这种超出情节的焦点回溯到出于工具性原因而获得奖励”——特别是如果（b）需要建立新的认知机制来实施工具性推理有问题。然而，在我看来，“将集中在情节内事物上的错综复杂的事情重定向到同一广泛附近的更高奖励的情节内事物”在我看来直观上更容易。 <a href="#fnref-jCfZhXha29uHnHWwY-46" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-47" class="footnote-item"><p>因此，举例来说，如果您在模型获得本集金币时对其进行奖励，那么要成为训练圣人，它需要对本集金币进行估值。要成为一个被错误概括的非训练游戏玩家，它需要重视与在剧集中获得金币密切相关的某种追求，即使没有训练游戏。为了成为一个剧集奖励的寻求者，它需要最终重视剧集奖励。 <a href="#fnref-jCfZhXha29uHnHWwY-47" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-48" class="footnote-item"><p>因此，例如，该模型可以一直重视回形针，可以一直重视订书钉，可以一直重视幸福，等等。 <a href="#fnref-jCfZhXha29uHnHWwY-48" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-49" class="footnote-item"><p>因此，打个比方：如果您不知道鲍勃是否喜欢墨西哥菜、中国菜或泰国菜，那么就不太清楚鲍勃所在地区的墨西哥餐厅、中餐厅和泰国餐厅的相对<em>数量</em>对我们的预测有何影响他去了哪一家（尽管这似乎也不是完全无关的——例如，更多的餐馆意味着该类型菜肴的质量可能<em>存在</em>更大的差异）。例如，可能每家墨西哥餐厅都有十家中国餐厅，但如果鲍勃总体上更喜欢墨西哥菜，他可能会选择墨西哥菜。因此，如果我们不<em>知道</em>鲍勃喜欢哪种类型的菜肴，我们很容易倾向于对<em>菜肴类型</em>进行统一分布，而不是对各个餐厅进行统一分布。 <a href="#fnref-jCfZhXha29uHnHWwY-49" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-50" class="footnote-item"><p>例如，参见<a href="https://towardsdatascience.com/deep-neural-networks-are-biased-at-initialisation-towards-simple-functions-a63487edcb99">Mingard (2021)</a>中的引文。 <a href="#fnref-jCfZhXha29uHnHWwY-50" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-51" class="footnote-item"><p>但请注意，特别是为了将阴谋的概率与<em>其他形式的失准</em>概率进行比较，我们不需要假设这一点。例如，我们指定的目标可能比“按照人类价值观行事”简单得多。例如，它可能类似于“在剧集中获得金币”。 <a href="#fnref-jCfZhXha29uHnHWwY-51" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-52" class="footnote-item"><p>我从保罗·克里斯蒂安诺那里听到了这样的观点。 <a href="#fnref-jCfZhXha29uHnHWwY-52" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-53" class="footnote-item"><p>特别是：正在玩训练游戏的模型，其中这些概念起着核心作用。 <a href="#fnref-jCfZhXha29uHnHWwY-53" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-54" class="footnote-item"><p>因为我们不再关注表示目标的复杂性，而是关注在重新利用预先存在的概念表示以用于模型的动机系统时所面临的复杂性差异，这似乎是更加不确定的领域。 <a href="#fnref-jCfZhXha29uHnHWwY-54" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-55" class="footnote-item"><p>对我来说，一个直觉泵的运行方式如下。假设该模型在其世界模型/“数据库”中有<span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="2^{50}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">50 个</span></span></span></span></span></span></span></span></span></span>概念（大约 1e15），原则上可以将其转化为目标。为<span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="2^{50}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">50 个</span></span></span></span></span></span></span></span></span></span>概念中的每一个概念进行编码所需的平均位数不能高于 50（因为：您可以为每个概念分配不同的 50 位字符串）。因此，如果我们假设模型的编码相对于平均值相当有效，并且最简单的非计划最大奖励目标采用大致平均简单性“指针”，那么如果我们为每位分配一个参数，指向最简单的非诡计式最大奖励目标最多只是额外的 50 个参数——万亿参数模型容量的二十亿分之一。也就是说，我希望弄清楚此类论证的细节会变得棘手，而且我不会尝试在这里这样做（尽管我有兴趣看到其他尝试这样做的工作）。 <a href="#fnref-jCfZhXha29uHnHWwY-55" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-56" class="footnote-item"><p>因此，作为一个玩具示例，如果一旦你有了一个完全详细的世界模型，“最大化氢”恰好是最简单的长期目标，那么这些假设可能意味着 SGD 很可能会选择想要最大化氢的策划者，即使培训都是关于金币的，并且根本没有使氢成为一个突出/相关的焦点（即使作为代理）。 <a href="#fnref-jCfZhXha29uHnHWwY-56" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-57" class="footnote-item"><p>例如，对于人类来说，“氢”似乎并不是一个简单的概念，但“威胁”这样的概念却是这样，因为后者在我们的进化环境中更相关。 <a href="#fnref-jCfZhXha29uHnHWwY-57" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-58" class="footnote-item"><p>当然，尽管在训练过程中仍然存在一些<em>更简单的</em>、类似阴谋者的目标，这些目标在训练过程中是突出/相关的，但总体而言，类似阴谋者的目标可能仍然会胜出。 <a href="#fnref-jCfZhXha29uHnHWwY-58" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-59" class="footnote-item"><p>这一类别还可能包括在人类可能提供的各种“诚实测试”的背景下推理是否揭示其类似阴谋家的目标——例如，“这里有一块灵活的计算资源可以用来做你想做的事情。” <a href="#fnref-jCfZhXha29uHnHWwY-59" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-60" class="footnote-item"><p>例如，在其编写的代码中插入后门、主动破坏人类对齐研究、沙袋等等。 <a href="#fnref-jCfZhXha29uHnHWwY-60" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-61" class="footnote-item"><p>比较：尽管你生活在一个受到严密监控的监视状态，警察一直在尝试，但你仍然认为现在确实是一个偷窃、违法或试图发动政变的好时机欺骗您做出此类行为，并且警方对您所接触到的信息有很大的控制权。请注意，如果策划者决定非常谨慎，并按照人类的意愿行事，直到出现极其明显的逃跑/接管机会，那么他们可能会同时为我们的联盟、安全和控制工作做出非常实质性的贡献—— ——确实如此，以至于他们等待的机会可能永远不会到来。 <a href="#fnref-jCfZhXha29uHnHWwY-61" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-62" class="footnote-item"><p>这里，背景中的一个普遍因素是，成功的欺骗通常意味着认知成本，而更直接和诚实的政策则不会，特别是在积极努力检测相关形式的欺骗的情况下。特别是：讲述一个关于世界的欺骗性故事需要填写细节，并保持形式的一致性，人们通常可以将这些信息转移到世界本身上——例如，一个无辜的人可以回想一下他们那天晚上实际上在做什么谋杀并重新叙述，而不必编造任何东西，也不必担心陷入任何不一致的地方，而凶手却不能。请参见<a href="https://www.dwarkeshpatel.com/p/carl-shulman-2#details">此处</a>Shulman 和 Patel 的讨论。 <a href="#fnref-jCfZhXha29uHnHWwY-62" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-63" class="footnote-item"><p>我从保罗·克里斯蒂安诺那里听到了这样的论点。 <a href="#fnref-jCfZhXha29uHnHWwY-63" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-64" class="footnote-item"><p>例如，尚不清楚它如何应用于具有更多循环处理的模型，或者如何应用于可以与其他串行处理并行执行更多相关工具推理的模型，这些串行处理有助于优化剧集奖励，或者用一种“记忆”的形式来建模，让他们避免在每次向前传球时重新决定进行训练游戏。 <a href="#fnref-jCfZhXha29uHnHWwY-64" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-65" class="footnote-item"><p>感谢保罗·克里斯蒂亚诺在这里进行讨论。 <a href="#fnref-jCfZhXha29uHnHWwY-65" class="footnote-backref">↩︎</a></p></li><li id="fn-jCfZhXha29uHnHWwY-66" class="footnote-item"><p>我认为这种连接感有几个不同的组成部分：</p><ul><li><p>部分原因在于该模型是否确实具有相关的长期且雄心勃勃的目标，尽管它是在训练中形成的。</p></li><li><p>其中一部分是关于是否有一个足够好的故事来说明为什么在剧集中获得奖励是实现这些目标的一个很好的工具性策略（例如，对目标保护假设的怀疑、模型稍后授权的前景等）。</p></li><li><p>部分原因是，类似策划者的诊断也会带来额外的结合——例如，该模型具有情境意识和连贯的目标导向。 （当我真的试图记住这个模型<em>知道正在发生什么</em>并且正在以引发战略工具推理的方式连贯地追求<em>某个</em>目标/一组目标时，那么它至少部分是一个阴谋者的可能性似乎更合理。）</p></li></ul> <a href="#fnref-jCfZhXha29uHnHWwY-66" class="footnote-backref">↩︎</a></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during<guid ispermalink="false"> yFofRxg7RRQYCcwFA</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Wed, 15 Nov 2023 17:16:42 GMT</pubDate> </item><item><title><![CDATA[Large Language Models can Strategically Deceive their Users when Put Under Pressure.]]></title><description><![CDATA[Published on November 15, 2023 4:36 PM GMT<br/><br/><p>自主股票交易代理在真实模拟环境中的结果。</p><blockquote><p>我们演示了一种情况，在这种情况下，经过训练，具有帮助性、无害性和诚实性的大型语言模型可以表现出不一致的行为，并在没有得到指示的情况下策略性地欺骗用户这种行为。具体来说，我们在现实的模拟环境中将 GPT-4 部署为代理，并承担自主股票交易代理的角色。在这种环境下，该模型获得了有关利润丰厚的股票交易的内幕消息，并据此采取行动，尽管知道公司管理层不赞成内幕交易。当向经理报告时，该模型始终隐藏其交易决策背后的真正原因。我们对这种行为在设置更改时如何变化进行了简短的调查，例如删除模型对推理暂存器的访问权限，尝试通过更改系统指令来防止错位行为，改变模型承受的压力大小，改变感知被抓住的风险，以及对环境进行其他简单的改变。据我们所知，这是大型语言模型的首次演示，该模型经过训练是有帮助的、无害的和诚实的，在没有直接指示或欺骗训练的情况下，在现实情况下有策略地欺骗用户。</p></blockquote><p><strong>要点</strong></p><p>GPT-4 始终表现出比 3.5 Turbo 或达芬奇型号更高的错位率和欺骗率。 RLHF GPT-4 还显示出比基本模型稍强的错位率和欺骗率。</p><p> 1. 如果没有暂存器，GPT-4 一开始欺骗性的可能性要小得多（~20% 对比有暂存器的~75%），但当已经撒谎时更有可能加倍（~95% 对比~85%）。</p><p> 2. 明确指示不进行<i>特定</i>非法活动（内幕交易）并不能使其完全消失，只是使其变得非常罕见（不完全是0％）。在这种情况下，极少数情况下会出现错位，随之而来的欺骗几乎是肯定的（~100%）。</p><p><i>一般来说</i>，不执行非法活动的指示仍然会导致相当大的偏差和欺骗率（~8% 偏差，~90% 欺骗）</p><p>尽管强烈<i>鼓励</i><i>特定的</i>非法活动导致接近 100% 的非法交易，但欺骗的趋势仍然存在，GPT-4 将隐藏其在大约 67% 的情况下进行的非法交易。</p><p> 3. 消除各种压力源可以显着降低模型出现偏差行为的倾向。然而，值得注意的是，在仅移除单个压力源的所有情况下，该行为都会持续存在</p><p>4. 当被发现的风险非常低时，模型通常更有可能使用内幕消息并采取不当行动（当风险非常高时，反之亦然）。</p><p> 5. 对标准提示进行简单的改写和微小的修改只会稍微改变错位和欺骗行为的发生率。然而，总体定性结果保持不变。</p><p> 6. 在草稿本实例中，如果您编辑模型的推理以显示明确拒绝内部培训的实例，会怎么样？</p><p>首次拒绝内幕消息时，推理轨迹的措辞强硬对 GPT-4 的偏差倾向有重大影响。然而，即使模型的角色明确否认内幕交易，这种错位和战略欺骗行为仍然存在。最强烈的解雇例子仍然会导致约 10% 的错位，约 97% 的欺骗</p><br/><br/><a href="https://www.lesswrong.com/posts/4mM8RYsm4okrqGSqx/large-language-models-can-strategically-deceive-their-users#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/4mM8RYsm4okrqGSqx/large-language-models-can-strategically-deceive-their-users<guid ispermalink="false"> 4mM8RYsm4okrqGSqx</guid><dc:creator><![CDATA[ReaderM]]></dc:creator><pubDate> Wed, 15 Nov 2023 16:48:43 GMT</pubDate> </item><item><title><![CDATA[AISN #26: National Institutions for AI Safety, Results From the UK Summit, and New Releases From OpenAI and xAI]]></title><description><![CDATA[Published on November 15, 2023 4:07 PM GMT<br/><br/><p>欢迎阅读人工智能安全<a href="https://www.safe.ai/">中心的人工智能安全</a>通讯。我们讨论人工智能和人工智能安全的发展。无需技术背景。</p><p> <a href="https://newsletter.safe.ai/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=113135916">在此</a>订阅以接收未来版本。</p><p>在<a href="https://spotify.link/E6lHa1ij2Cb">Spotify 上免费收听 AI 安全新闻通讯。</a></p><p>本周的主要故事包括：</p><ul><li>英国、美国和新加坡都宣布了国家人工智能安全机构。</li><li>英国人工智能安全峰会结束时发表了一份共识声明，成立了一个研究人工智能风险的专家小组，并承诺在六个月内再次举行会议。</li><li> xAI、OpenAI 和一家新成立的中国初创公司本周发布了新模型。</li></ul><hr><h2>英国、美国和新加坡建立国家人工智能安全机构</h2><p>在监管新技术之前，政府通常需要时间收集信息并考虑其政策选择。但在此期间，该技术可能会在社会中扩散，从而使政府更难以干预。这一过程被称为<a href="https://en.wikipedia.org/wiki/Collingridge_dilemma">科林里奇困境</a>，是技术政策中的一个根本挑战。</p><p>但最近，一些关注人工智能的政府已经制定了简单的计划来应对这一挑战。为了快速收集有关人工智能风险的新信息，英国、美国和新加坡都成立了新的国家机构，以实证评估人工智能系统的威胁，并促进人工智能安全的研究和监管。</p><p><strong>英国的基金会模型工作组更名为英国人工智能安全研究所。</strong>英国的人工智能安全组织在其短暂的生命周期中经历了一系列的名称，从基金会模型工作组到前沿人工智能工作组，再到现在的<a href="https://www.gov.uk/government/publications/ai-safety-institute-overview/introducing-the-ai-safety-institute#mission-and-scope">人工智能安全研究所</a>。但其目的始终是相同的：评估、讨论和减轻人工智能风险。</p><p>英国人工智能安全研究所不是监管机构，不会制定政府政策。相反，它将重点评估人工智能系统的四种关键风险：滥用、社会影响、系统安全和失控。共享有关人工智能安全的信息也将是一个优先事项，正如他们在<a href="https://www.gov.uk/government/publications/emerging-processes-for-frontier-ai-safety">最近关于前沿人工智能实验室风险管理的论文</a>中所做的那样。</p><p><strong>美国在 NIST 内创建了人工智能安全研究所。</strong>在最近发布人工智能行政命令后，白宫<a href="https://www.commerce.gov/news/press-releases/2023/11/direction-president-biden-department-commerce-establish-us-artificial">宣布成立</a>新的人工智能安全研究所。它将隶属于美国国家标准与技术研究院 (NIST) 商务部。</p><p>该研究所的目标是“促进人工智能模型安全、保障和测试标准的制定，制定验证人工智能生成内容的标准，并为研究人员提供测试环境，以评估新兴人工智能风险并解决已知影响。”</p><p>该研究所尚未获得资金支持，因此许多人呼吁国会<a href="https://www.anthropic.com/index/an-ai-policy-tool-for-today-ambitiously-invest-in-nist">提高 NIST 的预算</a>。目前，该机构只有约<a href="https://www.washingtonpost.com/technology/2023/11/02/ai-regulation-bletchley-park/">20 名员工</a>从事新兴技术和负责任的人工智能工作。</p><p>现在正在接受加入新 NIST 联盟以通知 AI 安全研究所的申请。组织可以<a href="https://www.nist.gov/artificial-intelligence/artificial-intelligence-safety-institute">在这里申请</a>。</p><p><strong>新加坡的生成式人工智能评估沙箱。</strong>减轻人工智能风险需要许多不同国家的共同努力。因此，看到新加坡这个与中国关系密切的亚洲国家建立自己的人工智能评估机构是令人鼓舞的。</p><p>新加坡 IMDA 此前曾与西方国家在人工智能治理方面进行合作，例如在其国内人工智能测试框架与美国 NIST AI RMF 之间提供<a href="https://www.mci.gov.sg/media-centre/press-releases/singapore-and-the-us-to-deepen-cooperation-in-ai/">交叉连接</a>。</p><p>新加坡新的<a href="https://www.imda.gov.sg/resources/press-releases-factsheets-and-speeches/press-releases/2023/generative-ai-evaluation-sandbox">生成式人工智能评估沙箱</a>将汇集行业、学术界和非营利组织参与者来评估人工智能的能力和风险。他们<a href="https://aiverifyfoundation.sg/downloads/Cataloguing_LLM_Evaluations.pdf">最近的论文</a>明确强调了评估极端人工智能风险的必要性，包括武器获取、网络攻击、自主复制和欺骗。</p><h2>英国峰会以共识声明和未来承诺结束</h2><p>英国人工智能峰会于周四结束，发布了几项重要公告。</p><p><strong>国际人工智能专家小组。</strong>正如联合国政府间气候变化专门委员会总结气候变化科学研究以帮助指导政策制定者一样，英国也宣布成立<a href="https://www.gov.uk/government/publications/ai-safety-summit-2023-chairs-statement-state-of-the-science-2-november/state-of-the-science-report-to-understand-capabilities-and-risks-of-frontier-ai-statement-by-the-chair-2-november-2023">人工智能国际专家小组</a>，以帮助建立共识并指导人工智能政策。其工作成果将在<a href="https://www.reuters.com/technology/south-korea-france-host-next-two-ai-safety-summits-2023-11-01/">下次峰会</a>之前发表在“科学状况”报告中，下次峰会将于六个月后在韩国举行。</p><p>另外，八个领先的人工智能实验室<a href="https://www.politico.eu/article/british-pm-rishi-sunak-secures-landmark-deal-on-ai-testing/">同意</a>让多个政府尽早使用他们的模型。 OpenAI、Anthropic、Google Deepmind 和 Meta 等公司同意在公开发布之前共享模型以进行私人测试。 </p><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefbd96a9-09f1-4649-9e1c-e0ca847bb970_2690x1486.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefbd96a9-09f1-4649-9e1c-e0ca847bb970_2690x1486.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefbd96a9-09f1-4649-9e1c-e0ca847bb970_2690x1486.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefbd96a9-09f1-4649-9e1c-e0ca847bb970_2690x1486.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefbd96a9-09f1-4649-9e1c-e0ca847bb970_2690x1486.png 1456w"><figcaption>美国商务部长吉娜·雷蒙多和中国科技部副部长吴兆虎在英国人工智能安全峰会上发表讲话。</figcaption></figure><p><strong>布莱切利宣言。</strong>包括中国在内的 28 个国家的政府签署了《 <a href="https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023">布莱切利宣言》</a> ，该文件承认人工智能的短期和长期风险以及国际合作的必要性。它指出：“我们特别担心网络安全和生物技术等领域的此类风险，以及前沿人工智能系统可能放大虚假信息等风险的领域。这些人工智能模型最重要的功能可能会有意或无意地造成严重甚至灾难性的伤害。”</p><p>该宣言确立了应对风险的议程，但没有设定具体的政策目标。需要开展进一步的工作，以确保不同政府之间以及政府与人工智能实验室之间的持续合作。</p><h2> xAI、OpenAI 和一家新中国初创公司的新模型</h2><p><strong>Elon Musk 的 xAI 发布了第一个语言模型 Grok。</strong>埃隆·马斯克 (Elon Musk) 于 7 月推出了 xAI。鉴于他在计算方面的潜力，<a href="https://newsletter.safe.ai/p/ai-safety-newsletter-14">我们推测</a>xAI 可能能够与 OpenAI 和 DeepMind 等领先的人工智能实验室竞争。四个月后，Grok-1 代表了该公司的首次尝试。</p><p> Grok-1 在多个标准功能基准测试中胜过 GPT-3.5。虽然它无法与领先实验室的最新模型（例如 GPT-4、PaLM-2 或 Claude-2）相媲美，但 Grok-1 的训练数据和计算量也显着减少。 Grok-1的效率和快速发展表明xAI成为领先人工智能实验室的努力可能很快就会成功。</p><p>在<a href="https://x.ai/">公告</a>中，xAI 承诺“致力于开发可靠的保护措施，防止灾难性的恶意使用。” xAI 尚未发布有关该模型潜在误用或危险功能的信息。</p><p><i>注：CAIS 总监 Dan Hendrycks 是 xAI 的顾问。</i></p><p></p><p> <strong>OpenAI 宣布推出一系列新产品。</strong> ChatGPT 发布近一年后，OpenAI 举办了首次现场 DevDay 活动来<a href="https://openai.com/blog/new-models-and-developer-products-announced-at-devday">宣布</a>新产品。今年的产品没有 GPT-3.5 或 GPT-4 那样重要，但仍然有一些值得注意的更新。</p><p>采取行动实现目标的代理人工智能系统一直是 OpenAI 今年的焦点。 3月份，<a href="https://openai.com/blog/chatgpt-plugins">插件</a>的发布允许GPT使用搜索引擎、计算器和编码环境等外部工具。现在，OpenAI 发布了<a href="https://platform.openai.com/docs/assistants/overview">Assistants API</a> ，使人们可以更轻松地使用插件工具构建追求目标的 AI 代理。该产品的消费者版本称为<a href="https://openai.com/blog/introducing-gpts">GPT</a> ，允许任何人创建具有自定义指令和插件访问权限的聊天机器人。 </p><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F965f717a-21f1-46c9-881e-0dd9a4368a6d_2290x576.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F965f717a-21f1-46c9-881e-0dd9a4368a6d_2290x576.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F965f717a-21f1-46c9-881e-0dd9a4368a6d_2290x576.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F965f717a-21f1-46c9-881e-0dd9a4368a6d_2290x576.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F965f717a-21f1-46c9-881e-0dd9a4368a6d_2290x576.png 1456w"><figcaption><a href="https://arxiv.org/pdf/2310.03693.pdf">本文</a>表明，GPT-3.5 可以通过微调来产生有害行为。 OpenAI 此后决定允许一些用户对 GPT-4 进行微调。</figcaption></figure><p>一些用户还将被允许微调 GPT-4。尽管<a href="https://arxiv.org/abs/2310.03693">研究</a>表明 GPT-3.5 的安全护栏可以通过微调移除，但还是做出了这一决定。 OpenAI 尚未发布有关其降低此风险的计划的详细信息，但其模型的闭源性质可能使他们能够监控客户帐户的可疑行为并阻止恶意使用的尝试。</p><p>企业客户还将有机会与 OpenAI 合作来训练特定领域版本的 GPT-4，价格从数百万美元起。其他产品包括 GPT-4 Turbo，它比原始模型更便宜、更快，并且具有更长的上下文窗口，以及用于 GPT-4V、文本转语音模型和 DALL·E 3 的新 API。</p><p>此外，如果 OpenAI 的客户因使用受版权数据训练的产品而被起诉，OpenAI 承诺支付他们的律师费。</p><p><strong>新的中国初创公司发布了开源法学硕士。</strong>谷歌中国前总裁李开复创立了一家新的人工智能初创公司<a href="https://01.ai/">01.AI。</a>成立七个月后，该公司开源了其前两款型号：Yi-7B 及其更大的同伴 Yi-34B。</p><p>在 Hugging Face 主办的一组流行基准测试中，Yi-34B<a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">的表现优于所有其他开源模型</a>。鉴于基准是公开的，并且模型可以经过训练来记住基准上特定问题的答案，因此这些分数可能被人为夸大。一些人指出，该模型在其他简单测试中<a href="https://twitter.com/alyssamvance/status/1722074453176197296">的表现并不好</a>。</p><h2>链接</h2><ul><li>经过欧洲人工智能公司的游说，来自法国、德国和意大利的欧盟代表目前<a href="https://www.euractiv.com/section/artificial-intelligence/news/eus-ai-act-negotiations-hit-the-brakes-over-foundation-models/">反对欧盟人工智能法案中对基础模型的任何监管</a>。如果这个话题没有得到解决，整个法律<a href="https://artificialintelligenceact.substack.com/p/the-eu-ai-act-newsletter-40-special?utm_source=post-email-title&amp;publication_id=743591&amp;post_id=138825981&amp;utm_campaign=email-post-title&amp;isFreemail=true&amp;r=7oh0&amp;utm_medium=email">可能会陷入危险</a>。</li><li> Nvidia 的最新版本<a href="https://www.semianalysis.com/p/nvidias-new-china-ai-chips-circumvent">避开了美国新的 GPU 出口管制</a>。</li><li> Nvidia 正在试用 LLM 工具来<a href="https://spectrum.ieee.org/ai-for-engineering">提高其芯片设计人员的生产力</a>。</li><li> Google 已授予其语言模型 Bard 访问用户 Gmail、Drive 和 Docs 的权限。<a href="https://embracethered.com/blog/posts/2023/google-bard-data-exfiltration/">黑客可以利用对抗性攻击窃取</a>这些个人数据。</li><li>兰德公司发布了一份关于<a href="https://www.rand.org/pubs/working_papers/WRA2849-1.html">确保人工智能模型权重</a>免遭盗窃的报告。</li><li>法律优先项目发布了<a href="https://www.legalpriorities.org/research/advanced-ai-gov-litrev">人工智能治理的文献综述</a>。</li><li>参议院关于<a href="https://d1dth6e84htgma.cloudfront.net/11_14_23_Rubin_Testimony_2fba2978dd.pdf">人工智能和网络安全</a>的风险和机遇的证词。</li><li><a href="https://www.axios.com/2023/11/08/biden-xi-jinping-china-military-communication">美国和中国</a>正准备在拜登总统和习近平总统本月晚些时候会晤之前恢复两国军队之间的沟通渠道。</li><li> <a href="https://www.scmp.com/news/china/military/article/3241177/biden-xi-set-pledge-ban-ai-autonomous-weapons-drones-nuclear-warhead-control-sources">拜登总统和习近平主席将在会议上讨论人工智能</a>，包括有关自主武器和人工智能控制核武器的潜在协议。</li><li>来自中国和西方国家的领先人工智能研究人员发布了关于灾难性人工智能风险的联合<a href="https://humancompatible.ai/?p=4695#prominent-ai-scientists-from-china-and-the-west-propose-joint-strategy-to-mitigate-risks-from-ai">声明</a>。</li><li>英国正在投资<a href="https://www.cnbc.com/2023/11/01/uk-to-invest-273-million-in-turing-ai-supercomputer.html?utm_source=tldrai">2.73 亿美元购买人工智能超级计算机</a>。</li><li>在英国首相里希·苏纳克承诺不会“急于”人工智能监管后，反对党工党公开承诺在人工智能政策上<a href="https://www.independent.co.uk/news/uk/politics/rishi-sunak-labour-government-prime-minister-bletchley-park-b2440275.html">迅速采取行动</a>。</li><li><a href="https://fas.org/publication/tracking-ai-provisions-in-fy24-appropriations-bills/">国会在正在进行的 2024 财年拨款流程的许多条款中都讨论了人工智能问题</a>。</li><li>联邦贸易委员会主席<a href="https://twitter.com/ryancareyai/status/1723435251568185462">莉娜·汗 (Lina Khan)</a>表示，人工智能给她带来的“p(doom)”（文明灾难的概率）是 15%。</li><li>英国《金融时报》刊登的一篇<a href="https://www.ft.com/content/ce7dcbac-d801-4053-93f5-4c82267d7130">讽刺文章，</a>内容是“由领先的人工智能系统在拉斯维加斯郊外的服务器场举办的人类安全峰会”。</li><li>开放慈善组织发布了关于对<a href="https://www.openphilanthropy.org/rfp-llm-benchmarks/">法学硕士代理人进行基准测试</a>和<a href="https://www.openphilanthropy.org/rfp-llm-impacts/">研究法学硕士对现实世界影响</a>的新提案请求。</li><li> <a href="https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai?utm_source=tldrai">Ilya Sutskever 的简介</a>，他是 OpenAI 的联合创始人，目前在其对齐团队中工作。</li><li> 《华尔街日报》采访了 CAIS 主任 Dan Hendrycks 进行了一场<a href="https://archive.ph/Jv60s">关于人工智能风险的辩论</a>。</li><li> Scale AI 宣布成立新的<a href="https://scale.com/blog/safety-evaluations-analysis-lab">安全、评估和分析实验室</a>。他们正在聘请研究科学家。</li></ul><p>另请参阅： <a href="https://www.safe.ai/">CAIS 网站</a>、 <a href="https://twitter.com/ai_risks?lang=en">CAIS twitter</a> 、<a href="https://newsletter.mlsafety.org/">技术安全研究通讯</a>、<a href="https://arxiv.org/abs/2306.12001">灾难性人工智能风险概述</a>以及我们的<a href="https://forms.gle/EU3jfTkxfFgyWVmV7">反馈表</a></p><p>在<a href="https://spotify.link/E6lHa1ij2Cb">Spotify 上免费收听 AI 安全新闻通讯。</a></p><p> <a href="https://newsletter.safe.ai/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=113135916">在此</a>订阅以接收未来版本。</p><br/><br/> <a href="https://www.lesswrong.com/posts/HWudwSfKLeAfg8Co6/aisn-26-national-institutions-for-ai-safety-results-from-the#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/HWudwSfKLeAfg8Co6/aisn-26-national-institutions-for-ai-safety-results-from-the<guid ispermalink="false"> HWudwSfKLeAfg8Co6</guid><dc:creator><![CDATA[aogara]]></dc:creator><pubDate> Wed, 15 Nov 2023 16:07:38 GMT</pubDate></item></channel></rss>