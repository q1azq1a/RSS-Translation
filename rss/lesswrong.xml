<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 10 月 30 日星期一 06:16:00 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Charbel-Raphaël and Lucius discuss Interpretability]]></title><description><![CDATA[Published on October 30, 2023 5:50 AM GMT<br/><br/><p>以下是<a href="https://www.lesswrong.com/users/charbel-raphael">Charbel-Raphaël Segerie</a>和<a href="https://www.lesswrong.com/users/lblack">Lucius Bushnaq</a>于 9 月 23 日在<a href="https://www.lesswrong.com/posts/f2vFYmwFGu3HLL9QB/lesswrong-community-weekend-2023-applications-now-closed-1">LessWrong 社区周末 2023</a>期间进行的公开讨论的记录。为了清楚起见，<a href="https://www.lesswrong.com/users/mateusz-baginski">我</a>编辑了文字记录。</p><h2>成绩单</h2><p><strong>Mateusz：</strong>上个月，Charbel 发表了<a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1"><i>《反对几乎所有可解释性影响理论》的</i></a>文章，引发了社区的广泛讨论。 Lucius 是<a href="https://www.apolloresearch.ai/">Apollo</a>的 AI notkilleveroneism 研究员，专注于可解释性。他不同意查贝尔的观点。于是我就把他们召集到一起讨论。我建议查贝尔首先提出他认为反对可解释性的最有力论据，卢修斯对此做出回应，我们将看看事情进展如何。</p><h3>逆向工程神经网络和正确的本体以实现可解释性</h3><p><strong>Charbel：</strong>我认为我们可以从“ <a href="https://www.notion.so/Daily-58d69787a6d9415c8c71b8335bf3cf7f?pvs=21"><code>auditing deception with interp is out of reach</code></a> ”开始。因此，尼尔说，“也许我们可以查看模型的随机部分并识别电路或特征。”我们需要稍微论证一下这个论点，因为很明显，仅查看模型的随机部分是不够的。相反，我们可以尝试枚举每种类型的功能（枚举安全性）。然而，在我看来，这种程序的规定非常不明确。我们已经在视觉模型上尝试过类似的方法，但它们并没有完全发挥作用[Charbel 评论：我在<a href="https://www.anthropic.com/index/towards-monosemanticity-decomposing-language-models-with-dictionary-learning">《走向单义性》</a>论文之后更新了一些]。此外，还有一些理论上的争论，比如<a href="https://www.lesswrong.com/posts/XWwvwytieLtEWaFJX/deep-deceptiveness"><code>deception could be something very diffuse</code></a> ，并且模型中可能不会有任何具有欺骗性的部分。</p><p>也许我们应该尝试用其他技术来研究欺骗性对齐。例如，尝试监控欺骗性联盟的代理，或者尝试寻找事前策略而不是事后策略。最后，在本节的末尾，我写道，如果 DeepMind 今天宣布他们发现了一个欺骗性模型的实例，那么他们肯定不会仅使用可解释性来找到它。我想我赢得了一些贝叶斯分，因为人工智能安全中心最近发表了一篇<a href="https://arxiv.org/abs/2308.14752">论文</a>，其中他们有一种方法可以监控西塞罗的行为，无论它是否撒谎等等。那篇论文没有可解释性。</p><p><strong>卢修斯：</strong>所以，首先，我对可解释性的看法可能并不完全是主流，也不能代表大多数可解释性研究人员。我对此的回答可能与尼尔·南达（Neel Nanda）所说的非常不同。我想说，目前已发表的大多数可解释性都非常非常糟糕，而且很糟糕。</p><p>我确实总体上相信，使可解释性不那么糟糕，实际上是相当可行的，并且没有特别的理由相信它会特别困难或需要特别长时间。</p><p>对我来说，可解释性并不是你进入模型并问“哦，这个神经元在做什么？”，因为这已经假设了一些我认为不正确的东西，即神经元是某种东西就像网络正在执行的计算的基本变量一样。我认为没有任何证据表明这一点是正确的，而且有相当多的证据表明它可能不正确。</p><p>我要指出的最抽象的证据是，神经网络在其训练数据集之外进行泛化，即使它们的参数多于训练数据点。我们有一大堆非常非常可靠的贝叶斯数学，它说如果你将这样的函数拟合到数据，并且拟合保持在训练数据集之外，那么从某种意义上来说，该函数必须是简单的。它必须具有较低的柯尔莫哥洛夫复杂度；描述长度小于数据点的数量。</p><p>换句话说，如果你有一个神经网络，其中的权重比数据点多，并且你将其拟合到数据中，并且它仍然具有概括性，那么从某种意义上说，这意味着实际的算法在这堆权重中运行的描述比权重更短，并且通过扩展，神经元和权重图中描述的网络也更短。</p><p>对我来说，这强烈暗示有一种方法可以谈论这个网络正在做什么，其中基本单元不是神经元，而是其他东西。而另一件事可能比混乱的权重简单得多，也更有结构性，这就是它起作用的原因。我想说，可解释性的工作就是找到这种结构并理解它是如何工作的。这里的“理解”并不意味着我可以讲述一些关于“哦，当模型执行此操作时这部分正在激活，哦，这就像与狗相关的东西”的事后故事，而是“哦，这是它在这里运行的算法，这可能不是任何人以前见过的算法”。曾几何时，人类不知道快速傅立叶变换算法，然后我们想出了它。同样，我想象在未来的某个时候，人们会研究法学硕士并说，“哦，这里有一些我们不知道的算法可以帮助你进行语言处理”。一旦你了解了它们，你就可以说你了解它们，因为你现在可以用 Python 自己编写一个 LLM 程序，不需要神经网络训练，而且该程序会做得很好。</p><p>所以对于初学者来说，这就是我想要通过可解释性来实现的目标。你提出的很多论点都与外星概念有关，人工智能可能不会像你那样思考。我同意这一点。我同意，我不喜欢当前的许多可解释性似乎只是假设其中存在人类概念。这是错误的做法。我认为你应该看看网络的数学，而不是把你期望在网络中找到的东西投射出来。但在我看来，这是一件可以直接解决的事情。所以目前来说，我同意。目前，可解释性基本上没有任何实际用途。但当你试图发明一门新科学或了解一个新领域时，这是很正常的。回到过去，当人们第一次尝试发明量子力学时，最终成熟的量子力学并没有什么特别用处。</p><p>最后一件事，我不认为我们目前试图在模型中寻找欺骗的方式（从外部观察相关性和行为，并且对其中任何一个都没有强有力的预测数学基础）会推广到当人工智能开始变得更加聪明。至少，这不是我想要依赖的东西。我宁愿处于这样的位置：我知道那里的电路是如何工作的，我知道发生了什么。我知道，如果我现在训练这种模型，我就不可能得到可以逃避欺骗检测的东西。我觉得我们现在正在做的行为方面的事情，我们不会得到这个。随着模型规模的扩大，其中可能存在我们目前无法预测的奇怪的热力学。</p><p> <strong>Charbel：</strong>那么让我总结一下您的观点。首先，你是说也许枚举安全性不是使用可解释性的正确框架。也许我们不应该在神经元水平上应用它，而应该在某种基序水平上应用它，神经元的集合，或者也许不是集合，而是某种告诉我们神经网络如何工作的高级描述。其次，您将可解释性与量子力学进行了比较，以指出也许我们应该对这门新科学更加宽容，而不是完全忽视它。最后一点是关于概括。我们希望获得一些数学形式主义和一些数学保证，以确保模型将来在规模上能够正确运行。</p><p> <strong>Lucius：</strong>我不太会这么说，但它正在朝着类似的方向发展，所以好吧。</p><p>只是有一点需要注意，我认为这一点很重要。我所想到的网络行为的描述并不是“高级”的。它相当于网络的低级行为，但更简单。</p><p> <strong>Charbel：</strong>让我们以<a href="https://arxiv.org/abs/2211.00593">IOI（间接对象识别）论文</a>为例，他们研究了模型如何知道是否继续使用<code>John</code>或<code>Mary</code>的句子？他们尝试对 GPT-2 内部的电路进行逆向工程，发现了一个由一堆注意力头组成的电路。如果你看看这些头，你可以恢复模型在任务上的很多性能。您认为这种机制（您想到的）会像他们在本文中所做的那样吗？如果不是，你认为它有什么问题？<br>这张纸？如果不是，您认为这有什么问题？</p><p>我为什么要提出这个？因为这是一篇出色的可解释性论文，并且对实现如此简单算法的电路的描述已经庞大且不完整，因为它无法解释模型的所有性能，而我们只关注一件事：是<code>John</code>吗？还是<code>Mary</code> ？我们甚至没有问它如何知道它应该是一个人的名字而不是其他东西。我认为这告诉我们一些关于逆向工程的一般可行性的信息。</p><p> <strong>Lucius：</strong>基本上，迄今为止几乎没有逆向工程的完成方式让我可以放心地说“是的，他们确实做到了；这实际上是模型如何做到这一点的描述”。我现在能想到的一个例子是<a href="https://arxiv.org/abs/2301.05217">Neel Nanda 的模块化加法变压器，</a>我愿意承认他们可能是对的。对于所有其他人来说，据我所知，人们基本上在做的是，他们正在观察模型中的特定头部、特定神经元，希望在一定程度上能够证明该神经元是否是模型的一部分该电路的一部分，它不是另一个电路的一部分，<i>这里</i>的结构有点属于这种行为，然后尝试理解它是如何工作的。</p><p>我认为这看起来如此困难并最终得到如此挑剔的描述的原因是它假设了一个我认为不存在的模型内部结构。我不认为你可以将电路划定为某些神经元。不是“哦，你不应该关注低级行为，因为低级行为本质上太挑剔”，而是“这只是将模型分割成块的糟糕方法” ”。您可能需要完全不同的方式。没有理由预设神经元对应于该东西正在运行的程序中的基本变量之类的东西。</p><p> <strong>Charbel：</strong>所以你是说我们在 IOI 论文中的描述和相反的完全陌生的概念之间应该有一个中间立场？</p><p> <strong>Lucius：</strong>我不太会这么说。也许想象一下，您获得了当前在这台笔记本电脑上运行的 CPU 的激活记录。您不知道 macOS 操作系统是什么样子，也不知道其上运行的其他程序如何工作。你只要看到这些晶体管的激活，就可以要求某人对 CPU 上运行的任何程序进行逆向工程。如果你这样做，我认为询问“好吧，这个晶体管现在处于“一”状态……这是苹果晶体管吗？……这是与 Safari 相关的晶体管吗？”不是一个好主意。<i>这是错误的本体论</i>。</p><p>要对其进行逆向工程，您实际上想要做的是了解这个东西具有组织级别。您可以从 CPU 的激活中进行某种映射，返回到程序代码之类的东西。对于运行许多不同类型程序的多种 CPU 来说，这种映射非常非常相似。你有点从晶体管退出到汇编代码。在此之前，它看起来绝对是一团糟，一切都相互作用。但在那之后，因为实际上是一堆并行运行的程序，所以就不再那么复杂了。有浏览器、操作系统以及后台的任何其他应用程序，它们之间的交互并不多。每个程序都由许多子例程和函数组成，您可以单独理解它们，而不需要引用其他函数。在这种环境中，我想开始讨论电路、子例程以及执行特定操作的整个算法的特定部分。</p><p>这与神经网络有何关系？当你观察神经元以及是什么让它们放电时（这是大多数可解释性所做的），你正在做的事情更接近于观察 CPU 上的晶体管何时处于一状态或零状态。你实际上应该考虑的是，“好吧，我可以从它到压缩描述做出一个很好的通用数学映射，一种完全符合神经网络正在做的事情但看起来更简单的算法？”。我怀疑，当你看到这个结构时，它会更短、更有条理、更容​​易接受还原论。您将能够一次理解每个部分。我之所以这么期待，是因为简单的事情、在非常狭窄的环境之外工作的事情往往就是这样运作的。简单性对于通用性来说几乎是必要的。如果这些神经网络本质上不适合这样的简短结构化描述，我很难理解它们如何能够做得这么好。</p><h3>逆向工程与从头开始重写人工智能的可行性 (1/2)</h3><p> <strong>Charbel：</strong>我可以给你举<a href="https://www.pnas.org/doi/10.1073/pnas.2206625119">一个具体的例子</a>。让我们以 AlphaZero 为例。为了解释它，他们采用了一堆似乎对下棋有用的概念。例如，我可以拿走皇后吗？或者我有多少个棋子。他们想知道 AlphaZero 何时学会这些概念，他们成功了。然后，如果他们想更进一步，看看是否可以通过对系统进行逆向工程来发现新策略，我认为这就是这种方法失败的地方。你如何能够发现人类知识库中尚未存在的新概念？在论文中他们无法发现任何新概念。所以这是一个非常糟糕的开始。你说 IOI 和 grokking 之间存在真正的区别。我认为 grokking 是一项算法任务，而 IOI 是一项自然语言处理任务，这使得它变得更加困难。诺姆·乔姆斯基和其他语言学家做了很多描述语言结构的工作，但这些描述总是不完整且不详尽。如果您尝试定义现实世界中的对象，您会得到类似“人类是没有羽毛的两足动物”的信息。无论你想出什么，总会有反例。我们真的想走那条路吗？</p><p>即使这并不完全是你的意思……首先，准确定义模糊概念似乎超出了人类的能力。其次，这种逆向工程至少会带来很大的信息危害，因为当您可以用 C++ 编写 GPT-5 等效项时，您就可以使用编译器并优化各种模块，这可能会使 foo 变得更加容易。然后在我看来，采用一个系统并对其中的所有内容进行逆向工程比从头开始制造它更困难。 [Charbel 评论：例如，请参阅论文<a href="https://arxiv.org/abs/2306.12672">《从词模型到世界模型：从自然语言翻译到思维的概率语言》</a> 。它提出了一种将 GPT-3 的模糊词模型转换为概率编程语言风格的世界模型建模的方法]。</p><p>我可以给你打个比方。想象一下，您是一名刚刚加入新公司的软件工程师。您正在尝试理解一个非常大、非常复杂的代码库。其中有些部分你不太理解。现在发现代码中存在错误，需要修补它。您有两种方法可以做到这一点。要么你修补有缺陷的代码（你不太理解并且不确定你对它的理解是否正确），要么你从第一原理理解这个模块并从头开始重写它。</p><p>在我看来，重新开始并从头开始编写所有内容比采用像 GPT-4 这样非常不透明（尽管不是完全不透明）的系统并将其逆向工程为 C++ 算法要容易得多。我宁愿使用法学硕士来帮助我迭代地完善代码，尝试做他们能做的同样的事情。 [Charbel 评论：在辩论中，我想到了类似于新的 Eureka 论文（ <a href="https://eureka-research.github.io/">Eureka：通过编码大型语言模型进行人类级别的奖励设计</a>）的东西。我认为像这样明确地编写规范可能会对 Davidad 的计划大有帮助]。</p><p> <strong>Lucius：</strong>好的，那么，有几点。您提出了有关信息危害的观点，我想我将在最后讨论这一点。但这也许是我们最能达成一致的事情。我认为你的许多其他观点似乎都在背景中发挥作用，解释了为什么我们对这里更容易的事情有不同的直觉：逆向工程或从头开始编写。我认为逆向工程可能会容易得多。我不认为它会高于人类的水平。我不认为它比人类过去解决的许多其他常规任务和科学问题要困难得多。</p><p>您指出（迄今为止），即使在微型网络中，例如模块化加法变压器，人们真正能够识别和理解的唯一事物就是其中，这样他们就会“哦，这看起来像是在做某事”我们熟悉的”是……嗯，我们熟悉的东西。我们已经知道要寻找什么，这使得在混乱中找到它变得容易得多。</p><p>然后，您正确地说，这对于您甚至还不了解模型在做什么的情况不起作用。例如，人们认为他们可能在某种程度上确定了 GPT-3 中存储数据的某些点。<i>也许吧</i>。 2005 年，人们知道如何在数据库中存储数据。但他们无法制造语言处理器，即可以说话的程序。当然，GPT-3 中存在一些我们还不知道如何编写的算法。否则，我们可以自己编写 GPT-3，就不需要 SGD 来为我们做这件事。</p><p>我对此的看法是：我认为有一种方法可以进行逆向工程，你不仅仅是在一堆神经元和权重中寻找你熟悉的东西。我认为您可以从这些神经元和权重到更正则化的结构进行映射，并且该映射不需要您提前知道该结构是什么。你只需看看如何将这个计算分割成多个部分，例如，彼此之间没有因果交互的部分。</p><p> <strong>Charbel：</strong>这是模块化吗？</p><p> <strong>Lucius：</strong>这是你可以这么称呼它的一种方式……我故意对信息危害性的东西含糊其辞，所以我不会具体说明你实际上如何做到这一点。</p><p>为什么我认为这是可能的？为什么我如此确信这是你确实可以做到的事情？所以你提到了 AlphaZero 及其逆向工程，我们在那里看到了一些我们认识到的东西，而且，它显然正在运行一些我们还不知道且无法识别的启发式方法。您说过您认为没有任何特殊原因可以对这些启发式进行简短的描述。我认为，这是我强烈不同意的地方。因为这些启发法有效。这些国际象棋程序不仅仅在它们所训练的游戏中下好棋。在训练数据之外，他们下棋也很好。</p><p><strong>查贝尔：</strong>是的，但是在国际象棋中，如果你处于游戏后期，你只有一个皇后和几个棋子。非常擅长国际象棋的人通常会记住这种情况的策略。你可以想象这些残局没有简短的描述。你所谓的“启发式”可能只是出于与我们记住国际象棋残局相同的原因而被记住的东西，并且没有简短的描述。</p><p> <strong>Lucius：</strong>我预计国际象棋引擎以及 GPT-3 的某些部分都是类似的，只是存储数据。你知道：“谁是汤姆·克鲁斯的母亲，抬头看……啊！，那在训练数据的某个地方！”但从某种意义上来说，这些部分对于我们来说其实还是比较容易理解的，因为那只是一个数据库。从某种意义上说，你可以把这一点分解出来，你知道，“这整堆描述就像一个存储东西的硬盘。”然后你可以讨论算法的其余部分，以及它如何知道何时访问什么，这实际上是困难的部分，我们不明白 GPT-3 是如何做得这么好的。或者国际象棋程序如何在其训练分布之外、在其记忆的游戏情境之外发挥良好作用。</p><h3>单一学习理论</h3><p><strong>卢修斯：</strong>我确实认为类似的启发式方法必须存在其中。这不仅仅是所有存储的数据。因为如果是……举个例子：GPT-3 有 1750 亿个参数。如果我将 1750 亿次多项式拟合到互联网数据中，就像我们拟合 GPT-3 来预测下一个标记一样，那么该多项式将不会在其训练数据之外进行推广。一旦我输入任何它还没有见过的数据点，它就会表现得很糟糕。那么，为什么它会表现得很糟糕呢？因为多项式拟合基本上只是一个查找表。它几乎是不可压缩的。使用了全部 1750 亿个参数。这就是描述长度。这里没有简短的描述，没有“哦，这个东西的潜在动力是什么？”的问题。只是这些参数，没有简短的描述。 GPT-3 不是那样的。 GPT-3 概括了。因此，从某种意义上说，GPT-3 是一种函数拟合，一种算法，很简单。</p><p>如果您听说过<a href="https://www.lesswrong.com/tag/singular-learning-theory">奇异学习理论</a>……在<i>经典</i>学习理论中，有一种称为<a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion">贝叶斯信息准则（BIC）</a>的东西。你知道吗？</p><p> <strong>Charbel：</strong>是的，他们经常使用它来比较贝叶斯模型。如果您有多个型号，则应使用 BIC 最低的型号。</p><p><strong>卢修斯：</strong>是的。因此，您可以粗略地、非正式地将贝叶斯信息标准视为量化更好地拟合训练数据和过度拟合（因此无法概括分布外）之间的权衡的东西，因为我给它更多的参数。</p><p>有趣的事实：神经网络不遵守贝叶斯信息准则。他们的表现总是比贝叶斯信息所暗示的要好得多。这困扰了学习理论家很长一段时间。他们做得更好的原因是什么？在学习理论数学（推导贝叶斯信息准则）的一开始，有一个假设，即您所拟合的函数的参数函数映射是可逆的。因此，如果我有一个 10 度函数（10 个参数），那么对于任何单个 10 维向量（代表一组参数），我都会得到一个唯一的输入输出映射。在神经网络中情况<i>并非如此</i>。参数图中有很多很多点实现了相同的功能。事实证明，如果您再次进行学习理论数学操作而不从可逆性假设开始并尝试导出类似贝叶斯信息准则的东西，您会得到一个非常相似的不同公式，但不是原始参数计数（例如，GPT-3 的 1750 亿），您会得到一个数字，描述您安装的网络最终所处的损失环境中最优的维度。</p><p> <strong>Charbel：</strong> “最优维度”是什么意思？</p><p> <strong>Lucius：</strong>如果我只有一个与我的数据完美契合的单点损失景观，那么它就是零维的。如果我有一条线，并且线上的任何点都完美拟合，那么它就是一维的。你可以去二维、三维等等。<i>修正后的贝叶斯信息准则</i>告诉您的是：如果您的解决方案是在线的，就复杂性而言，就好像您少了一个参数。如果在平面上，则少两个参数——三个参数、四个参数等。</p><p>神经网络中似乎正在发生的是，训练发现的解决方案比网络的原始参数计数要简单得多，维度也低得多。这意味着他们找到的解决方案是<i>简单的</i>解决方案，具有简单的描述。这就是为什么我认为“是的，当然，国际象棋程序中可能有<i>一些</i>查找表，GPT-3 中有一些数据库，但也有一些算法有简单的描述，你可以找到。”我的另一个信念飞跃是：不仅有某种意义上的简单描述，而且还有一个看起来像可以运行的算法的简单描述。逐步通过网络的不同描述，您不一定要谈论神经元和权重。</p><p> <strong>Charbel：</strong>谢谢，这可能是我听过的关于可解释性可行性的最佳论据之一。</p><h3>逆向工程与从头开始重写人工智能的可行性 (2/2)</h3><p> <strong>Charbel：</strong>我认为我可以在合理的程度上接受这个故事，但我仍然不觉得你已经解释了为什么你认为逆向工程比从头开始编写东西更容易，例如使用 Copilot 或已经存在的类似模型相当令人印象深刻。当然，也许有一个关于网络功能的简短描述，但毫无疑问这种描述是人类可以理解的。</p><p>还有一些我想提的事情。即使您有 GPT-4 的 C++ 版本，其中每个函数都用文档字符串进行注释，但在我看来，它对于功能的作用比对于安全性的作用要大得多。例如，如果你有一个看到枪就触发的功能，那么它既可以用于自卫，也可以用于攻击。将描述转化为每个函数执行的固有危险并不容易。</p><p> <strong>Lucius：</strong>也许我会从为什么我对另一条路持怀疑态度开始：只是从头开始编写代码，而不是进行逆向工程。一段时间以来，人们一直在尝试从头开始制造人工智能，并从头开始理解语言（正如你提到的），但并没有真正成功。我们现在拥有以前没有的优势，我们有 GPT-4 来帮助，很快就会有 GPT-5。但 GPT-5 和 Copilot 目前擅长并且可以执行的事情几乎都是人类程序员也可以做的事情。所以他们不会做任何我们不够聪明而做不到的事情。他们只是执行他们在训练数据中看到的内容，并且可以大规模且快速地做到这一点。但是，如果我要求他们为我编写一个在处理语言方面与 GPT-3 一样好的算法，他们比我们更不知道如何做到这一点。</p><p>我预计，如果你不断制造更好、更聪明的人工智能，最终你确实会得到比我们更聪明的人工智能。这可以从头开始编写 GPT-3，无需培训。他们会发明算法来让你做到这一点。但这正是在智力水平上，我非常害怕这些人工智能，因为它们比我聪明，而且我们还没有解决对齐问题。你怎么处理那件事呢？你可能希望我们能蒙混过关，让他们比我们更聪明，但仍然有足够的保障措施，让他们不能立即杀死我们。</p><p>但在我看来，这是一个非常非常不稳定的设置。对于初学者来说，您可能需要正确估计他们的聪明程度。如果你对他们训练太少，他们就会太笨而无法完成这项工作。如果你训练它们太多，它们就会逃避你所有的防护措施并杀死你。而且你现在不一定能最好地衡量他们的聪明程度。因为你还没有做大量的可解释性工作来理解诸如“那里有什么电路？”，“它们何时形成以及多快？”，“我可以对跨架构的能力进行一些缩放曲线预测吗？”并且有更多的理论支持它们，这样我们就可以确定缩放曲线不会在某个地方变得奇怪？”。</p><p>如果这些人工智能非常聪明，比你聪明（尽管可能还不是超级聪明），并且试图欺骗你，他们也可能会尝试一些复杂的策略，比如暂时假装比他们笨，直到你让他们变得更聪明。看到这一点，我对走“让人工智能帮助我们制造更聪明、更一致的人工智能”这条路一点信心都没有。这看起来就像是先有鸡还是先有蛋的问题。我觉得这结局不太好。</p><h3>信息安全</h3><p><strong>Lucius：</strong>首先，我同意这确实存在信息安全问题，并且确实存在双重用途。我所描述的将这些模型转化为算法的能力，您可以实际检查，这只是关于神经网络实际运行方式的大量基础知识。你现在不再那么困惑了，通常，如果你对科学主题不再那么困惑，那么解惑是非常有用的。</p><p>默认情况下，我希望您学到的至少一些内容可用于功能。当你弄清楚了量子力学，你可以用它来制造激光，你可以用它来制造原子弹;在你弄清楚量子力学之前，你不会知道这两种可能性。</p><p>那么，为什么我认为在某种程度上，这场赌博还是值得的呢？因为我认为没有什么好的对齐捷径。我认为，要制定任何实际上对比你聪明得多的事情有效的调整策略，你需要了解你在做什么。就像人们制造激光器时一样，他们知道自己在做什么。他们有材料科学和量子力学理论作为基础。他们可以非常确定事情会如何发展。这就是为什么他们能够成功制造价值数十亿美元的巨型新颖设备，这些设备必须在第一次尝试中就可以工作，实际上在第一次尝试中就可以工作。他们一直成功地做到了这一点。我想说他们能做到这一点，因为他们有非常扎实的理论，而且他们不像我们对人工智能那样困惑。默认情况下，如果没有很强的可解释性，也没有对神经网络科学的理解，我认为我们不会在第一次尝试中就把事情做好。</p><h3>卢修斯论可解释性的影响理论</h3><p>这也涉及到我认为可解释性的安全故事。我想从中得到的并不是我希望看到“糟糕的算法”或“对我撒谎的算法”。这不是我期望的工作方式。我认为其中不一定存在任何类型的“谎言成分”。也许有一些社交启发成分可以帮助你了解如何擅长与人类进行社交互动，以及如何很好地预测它们。你可以使用所有这些部分的一件事就是说谎，如果这就是你现在想做的事情的话。</p><p>最后，我们希望使这些模型具有与我们的愿望和目标相匹配的愿望和目标。 But we have no idea what in these models corresponds in any way to a desire. What&#39;s the mathematical type signature of that, even? And if I think about research agendas, to get at that, to get at questions like &quot;what is the type signature of a goal?&quot;, &quot;how do you edit goals?&quot;, &quot;how do you write goals that do not result in everyone dying?&quot;, &quot;how do you write &#39;make me a copy of a strawberry and don&#39;t destroy the world when you do it&#39;?&quot;, all of that, to me, seems to require an empirical feedback loop. You want an actual system that you can look at, to test your theories and hypotheses and measure things. And a great way to do this, I think, would be to look at the insides of AIs. Their circuits, the programs they&#39;re running. Giving agent foundations research an actual empirical, fast feedback loop that they can iterate on.</p><p> For example, at some point, we may understand how this fuzzy abstraction-based reasoning works, that humans seem to engage in all the time, and that I expect GPT-4 probably also engages in all the time. Once we understand how that works, the way that we understand how a fast Fourier transform works, maybe it starts being a whole lot less mysterious how you write&quot;Make me a copy of a strawberry and don&#39;t destroy the world&quot; in C . Because you know what abstractions actually correspond to in terms of code.</p><p> Then, I would be looking at things like if I have, say, AutoGPT-5 and I told it to make me a T-shirt and it goes out and tries to make a T-shirt business, then it maybe seems well described as an agent right now, an agent that wants there to be lots of T-shirts. Now I can ask what&#39;s the mathematics of how that maps back onto the initial prompt and the scaffolding and the circuitry inside the model that make it have that goal rather than a different goal. And then see if you can describe that map. See if you can predict ahead of time that if you make these kinds of circuits and this kind of setup, then you get an AI that wants this thing. That&#39;s sort of the road I would want to travel. I do acknowledge however, the infosec concerns are there.</p><h3> Wrap-up</h3><p> <strong>Charbel:</strong> We didn&#39;t converge. I still have a lot of things to bring to the table. First of all, you said that it&#39;s not safe to use LLMs to do big things that humans can&#39;t do. But I think that this also applies to reverse engineering GPT-4 or to <a href="https://www.lesswrong.com/posts/Hna4aoMwr6Qx9rHBs/linkpost-introducing-superalignment">OpenAI&#39;s plan</a> . Yes, this applies to trying to code the model from scratch, but it also applies to reverse engineering GPT-4.</p><p> Regarding your idea about giving the agent foundations program an empirical grounding, and finding goals inside the model, it seems to me that it&#39;s fairly plausible that models won&#39;t have a clear single goal. I&#39;m not saying deceptive alignment is unlikely. I think it&#39;s fairly likely, but the system may be deceptive even if it doesn&#39;t have any clear-cut goal that you would correspond to &quot;deceive a human&quot; [Charbel comment: See <a href="https://www.lesswrong.com/posts/XWwvwytieLtEWaFJX/deep-deceptiveness">Deep Deceptiveness</a> , even if I agree this is sort of a second order problem].</p><p> Also, it seems to me that there are easier ways to make understandable, bounded systems. Something like task decomposition, what Conjecture uses for <a href="https://www.lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal">cognitive emulation</a> , trying to decompose and monitor the reasoning, and bound each little system, and understanding the capability of each system, like a mini-bureaucracy. Or what Ought is doing with factored cognition. If you assume <a href="https://www.lesswrong.com/posts/r3xwHzMmMf25peeHE/the-translucent-thoughts-hypotheses-and-their-implications">The Translucent Thoughts Hypothesis</a> (ie, that the models will mostly reason in English and won&#39;t be able to do complex thinking in one forward pass), seems to me fairly plausible that even slightly superhuman systems could still be monitored using those strategies. To me, this seems more feasible than reverse engineering and a bit more neglected.</p><p> I&#39;ve been involved in a lot of field-building, I&#39;ve seen a lot of junior wanna-be researchers and generally, when you don&#39;t have an idea of what to work on, you just might collapse into interpretability without even considering other strategies. I&#39;m not saying interpretability is a bad strategy. But we already tried it a lot and it seems quite difficult. You&#39;re saying that most interpretability currently is not good but also saying that good interpretability research exists, but it&#39;s not public. So it&#39;s hard for me to believe this state of matter 🤷.</p><p> <strong>Lucius:</strong> (I have a long of response to this, but we only have an hour.)</p><br/><br/> <a href="https://www.lesswrong.com/posts/FDrgcfY8zs5e2eJDd/charbel-raphael-and-lucius-discuss-interpretability#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/FDrgcfY8zs5e2eJDd/charbel-raphael-and-lucius-discuss-interpretability<guid ispermalink="false"> FDrgcfY8zs5e2eJDd</guid><dc:creator><![CDATA[Mateusz Bagiński]]></dc:creator><pubDate> Mon, 30 Oct 2023 05:50:34 GMT</pubDate> </item><item><title><![CDATA[Multi-Winner 3-2-1 Voting]]></title><description><![CDATA[Published on October 30, 2023 3:31 AM GMT<br/><br/><p> My favorite voting method is <a href="https://electowiki.org/wiki/3-2-1_voting">3-2-1 voting</a> <span class="footnote-reference" role="doc-noteref" id="fnrefevnbw7ynapi"><sup><a href="#fnevnbw7ynapi">[1]</a></sup></span> , my second favorite is <a href="https://electowiki.org/wiki/Approval_voting">approval voting</a> . Both are methods for selecting one winner. Approval voting has variations for choosing multiple winners, but 3-2-1 voting doesn&#39;t - until now.</p><p> I&#39;m going to explain approval voting, <a href="https://electowiki.org/wiki/Sequential_proportional_approval_voting">sequential proportional approval voting</a> , 3-2-1 voting, and proportional sequential 3-2-1 voting - which is my multi-winner version of 3-2-1 voting.</p><p> Note: I think it works well, but I&#39;m no professional, and I haven&#39;t proved anything about it. There&#39;s also one detail I&#39;m still not sure about. If you can help me test it better or prove certain properties about it, I&#39;d much appreciate it.</p><p> <strong>Approval voting</strong></p><p> Approval voting is simple - each voter can vote for as many candidates as they want, and the one that got the most votes is elected. It&#39;s good because it&#39;s simple, there&#39;s relatively little incentive for strategic voting, and it leads to relatively high voter satisfaction.</p><p> <strong>Sequential Proportional Approval Voting</strong></p><p> Like approval voting, each voter can vote for as many candidates as they want, and the first winner is the one that got the most votes. Then all the ballots are reweighed, such that each vote is equal <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{X+1}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.648em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 2.33em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 2.33em; bottom: -0.764em;"><span class="mjx-mrow" style=""><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.648em;" class="mjx-line"></span></span><span style="height: 1.511em; vertical-align: -0.54em;" class="mjx-vsize"></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>, where X is the amount of elected candidates voted for on the ballot, and another candidate is elected. Repeat until all the seats are filled.</p><p> So if I voted for the first candidate that was elected, in the second round my vote would be worth 1/2. If I also voted for the second candidate elected, then in the third round my vote will be worth 1/3, and if didn&#39;t vote for the second candidate elected, my vote would still be worth 1/2 in the third round.</p><p> This is good because it achieves <a href="https://electowiki.org/wiki/Proportional_representation">proportional representation</a> <span class="footnote-reference" role="doc-noteref" id="fnrefwdzdi237wg"><sup><a href="#fnwdzdi237wg">[2]</a></sup></span> in a relatively simple way, and with little incentive for strategic voting. Without reweighing the ballots, the more similar you are to the winning candidate the more likely you are to win, which will create a situation where a parliament of clones is elected.</p><p> <strong>3-2-1 voting</strong></p><p> In 3-2-1 voting you rate as many candidates as you want as either &quot;bad&quot;, &quot;ok&quot;, or &quot;good&quot;. Then the winner is selected in 3 steps:</p><ol><li> The three candidates who got the most &quot;good&quot; ratings are selected.</li><li> Of them, the one with the most &quot;bad&quot; ratings is cast out.</li><li> Of the two remaining, the one that is ranked higher than the other on more ballots is elected.</li></ol><p> This is more complicated than approval voting, but it pays for that complexity by disincentivizing candidates from being polarizing, and preventing the most polarizing candidate from being elected, even if they are the most popular.</p><p> <strong>Proportional Sequential 3-2-1 voting</strong></p><p> I like 3-2-1 voting, so I created this method based on <a href="https://electowiki.org/wiki/Sequential_proportional_approval_voting">sequential proportional approval voting</a> to make 3-2-1 voting multi-winner.</p><p> The initial voting phase is the same, you rate as many candidates as you want as either &quot;bad&quot;, &quot;ok&quot;, or &quot;good&quot;. The first winner is selected in the same 3 steps as in the single-winner case:</p><ol><li> The three candidates who got the most &quot;good&quot; ratings are selected.</li><li> Of them, the one with the most &quot;bad&quot; ratings is cast out.</li><li> Of the two remaining, the one that is ranked higher than the other on more ballots is elected.</li></ol><p> The candidate that is cast out in step 2, the &quot;rejected candidate&quot;, is completely removed from the candidate list and cannot be elected anymore. This is a detail I&#39;m uncertain about, and it should be tested whether it&#39;s better with or without it.</p><p> Then after each round the ballots are reweighed - each ballot&#39;s weight becomes <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{X+Y+1}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 2.737em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 3.871em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 3.871em; bottom: -0.764em;"><span class="mjx-mrow" style=""><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 2.737em;" class="mjx-line"></span></span><span style="height: 1.511em; vertical-align: -0.54em;" class="mjx-vsize"></span></span></span></span></span></span></span> , where X is the amount of elected candidates rated &quot;good&quot; on the ballot, and Y is the amount of rejected candidates rated &quot;bad&quot; on the ballot.</p><p> I hope this carries over the benefits of 3-2-1 voting from single-winner elections to multi-winner elections.</p><p> I have written <a href="https://github.com/Yoav6/Voting-Methods">a python implementation</a> of this voting method, but it doesn&#39;t properly simulate voter preferences and doesn&#39;t measure voter satisfaction. Also, I don&#39;t know how to prove any properties about it. So though this method <i>seems</i> good to me, I don&#39;t actually know if it is. I would very much like help with both of these things. If you think you can help please leave a comment or send me a message.</p><p> And just one last note about parties - It&#39;s not clear to me how Proportional Sequential Approval Voting or other multi-winner voting methods are supposed to be used when voting for parties instead of individual candidates. My idea is each round you pick a party like you would pick a candidate, and the top unelected member of that party gets elected (the parties need to come to the elections with a sorting), the ballots reweighed, and importantly, the elected and rejected parties aren&#39;t removed from the list, and are selected from again. I don&#39;t currently have an implementation of this, but if I do I&#39;ll post it here and add a link in the text.</p><p> <i>Thank you Justis from the LessWrong feedback team for your feedback on the article.</i> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnevnbw7ynapi"> <span class="footnote-back-link"><sup><strong><a href="#fnrefevnbw7ynapi">^</a></strong></sup></span><div class="footnote-content"><p> Also discussed on LW <a href="https://www.lesswrong.com/posts/qShCqJp8SGDDa7Jw4/deconstructing-321-voting">here</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnwdzdi237wg"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwdzdi237wg">^</a></strong></sup></span><div class="footnote-content"><p> Not perfectly, but fairly well</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/aA5bSGmAN7SXiPkQC/multi-winner-3-2-1-voting#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/aA5bSGmAN7SXiPkQC/multi-winner-3-2-1-voting<guid ispermalink="false"> aA5bSGmAN7SXiPkQC</guid><dc:creator><![CDATA[Yoav Ravid]]></dc:creator><pubDate> Mon, 30 Oct 2023 03:31:25 GMT</pubDate> </item><item><title><![CDATA[math terminology as convolution]]></title><description><![CDATA[Published on October 30, 2023 1:05 AM GMT<br/><br/><blockquote><p> On the one hand, this theory generalizes the Fuchsian and Bers uniformizations of complex hyperbolic curves and their moduli to nonarchimedean places. It is for this reason that we shall often refer to this theory as p-adic Teichmuller theory, for short. On the other hand, the theory under discussion may be regarded as a fairly precise hyperbolic analogue of the Serre-Tate theory of ordinary abelian varieties and their moduli.</p></blockquote><p> — Shinichi Mochizuki</p><blockquote><p> I know some of these words.</p></blockquote><p> — Ed in Good Burger (1997)</p><h2> terminology as convolution</h2><p> Math research papers are notorious for using specialized and obscure terminology.这是为什么？ Why can&#39;t they describe things in terms of simpler components?</p><p> Chemists often talk about carbon atoms. They don&#39;t say &quot;an atom with 6 protons, 6 neutrons, and 6 electrons&quot;. Those subatomic particles are grouped together into a single conceptual item. The power of convolutional neural networks shows us that such grouping is not merely a matter of convenience - rather, the selection of which things to group together is a system of thinking.</p><p> Neural network research suggests a lot about how humans think. For example, I think the fact that massively multilingual language models work well, with many languages ultimately sharing the same latent space, is a refutation of the Sapir-Whorf Hypothesis. Modern neural networks have also, I think, shown us something about what concepts are. Some linguists have argued that a word like &quot;dog&quot; is a discrete package, a fixed item to which additional information is attached. Based on my comparison of how humans think and now neural networks operate, my view is that the concept &quot;dog&quot; is 3 things:</p><ol><li> A region of a latent space for doglike concepts.</li><li> One or more prototype dog concepts, which are points in that latent space used to define the region of dog-ness.</li><li> A convolution-like transformation by which some data can be packaged into a point in a latent space: &quot;this is a dog&quot; is a way of examinining some data from a photo.</li></ol><p> Math is often considered universal, but many of the concepts are partly arbitary. For example, some people have suggested pi as a universal number that alien species would recognize, but other people argue that 2*pi is a more fundamental constant.</p><p> For a slightly more &quot;complex&quot; example, consider imaginary numbers. The <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_algebra">fundamental theorem of algebra</a> involves them, and that sounds fundamental...but complex numbers can be considered just a special case of replacing numbers with matrices - specifically, with a subset of 2x2 matrices that can be represented by 2 numbers and multiplied with fewer operations. For example, <a href="https://www.wolframalpha.com/input?i=e%5E%7B%7B0%2C+x%7D%2C+%7B-x%2C+0%7D%7D">here&#39;s Euler&#39;s formula</a> in matrix form. There are some advantages to computation with that representation, but arguably it&#39;s just a computational optimization with no conceptual value.</p><p> If we ask whether the concepts used in current mathematics are &quot;good&quot; or &quot;bad&quot;, the usual presumption is that some are good and some are bad, but those are relative terms that depend on what concepts they&#39;re compared to. Some math concepts considered important hundreds of years ago are now considered irrelevant.</p><h2> other issues</h2><p> When I say the language of current advanced math is opaque, I&#39;m mainly talking about the concepts, but people say that to mean other things as well:</p><p> <strong>names</strong></p><p> Overloading of common words can be annoying, especially for technical generalists who might go from adding matrices of composite numbers to adding matrices of composite materials. But math isn&#39;t any worse in this regard than various engineering fields.</p><p> A lot of mathematical terms are called [name]&#39;s theorem or [name]&#39;s lemma. These are hard to remember because they don&#39;t provide any information about the topic. (Personally, I don&#39;t usually want to have to remember names of mathematicians unless they&#39;re on the level of Euclid, Gauss, or Hilbert.) But math isn&#39;t any worse in this regard than biology or medicine.</p><p> <strong>equations</strong></p><p> Math equations can be hard to read. I think programming languages are often clearer. Yes, I&#39;ve seen mathematicians comparing compact expressions using symbols for summation and integrals to awkward-looking equivalents in pseudocode, but they&#39;re missing the point. The main reason complex math equaations are hard to read is because they use, eg, 12 single-letter variables, 7 of which were defined over the previous 3 pages, and 5 of which are defined below the equation. Nobody sane writes code like that unless they&#39;re entering an obfuscated programming competition. Descriptive variable names and multi-step definitions are better for complex formulae.</p><p> And then, if you have longer variable names, much of that customary math notation stops working well. It&#39;s also much harder to produce that notation by typing. The notation of math was originally developed for writing simple equations on a chalkboard for people already familiar with related work. It was never meant for typing, extremely complex equations, or distributing work to people in other fields.</p><h2> network optimization</h2><p> The <a href="https://en.wikipedia.org/wiki/Four_color_theorem">4-color theorem</a> was proven with a computer-generated proof over 400 pages long. <a href="https://en.wikipedia.org/wiki/List_of_long_mathematical_proofs">Here</a> are some other particularly long math proofs. Conceptual tools are supposed to make things easy; what long proofs indicate to me isn&#39;t that they have more insights for me to learn, but rather that the tools being used are inadequate for the task - like people are hammering in nails with a rock instead of using a nailgun.</p><p> Is the answer building a tower of abstraction even higher? Or...was a wrong turn taken somewhere? Statistically speaking, some of the turns taken were probably suboptimal.</p><p> Let&#39;s return to the metaphor of math terminology as convolutions in a neural network. When a large neural network is stuck in some bad local minimum, what can be done? There are multiple options.</p><p> The most-effective way to train a neural network is by distillation, imitating another network with better performance. So, perhaps the best option would be to find an alien civilization with more-advanced mathematics and copy the concepts they use.</p><p> Sometimes people training neural networks will start over with a new initialization. (So, perhaps mathematics should all be re-developed from scratch, but that seems like a lot of work.) That&#39;s done less than it used to be, because neural networks have gotten larger, and increasing dimensionality adds connections between (what would be) local minima. These days, it&#39;s more likely that there&#39;s a problem with the optimizer than that training is stuck in a bad local minimum.</p><p> Let&#39;s consider how gradient descent works, and how that compares to development of math. A network is tried on many tasks, and the effect that various changes would have on performance is averaged out across those tasks. Then, the whole network is updated slightly, and the process repeats. So, people use math to do tasks, and sometimes they notice small changes that would improve things for them. Do people share those possible changes, average them out, and then apply them and see how they work out, perhaps stochastically if they&#39;re discrete changes? No; what happens more often is that mathematicians develop private notations that they use for their own notes. Friction is too high for the culture of mathematics to proceed down long shallow gradients.</p><p> If math involves metaphorical convolutions, and good concepts are good because they produce points in a well-structured latent space, that means that math doesn&#39;t advance through new proofs and theorems per se. Rather, math advances from new concepts and transformations, and proofs are just the means by which they&#39;re tested. This then implies that a shorter and more elegant proof of something already proven is just as important as a new proof, perhaps even more so. But incentives in mathematics aren&#39;t structured around that being the case, perhaps because elegance of proofs is harder for institutions to measure.</p><p> As for why I&#39;m writing this now, it&#39;s because I&#39;ve been thinking about questions like &quot;why Transformers work better than other neural network architectures&quot;. The tools developed by mathematicians so far seem inadequate for that, besides trivialities like distance in high-dimensional Euclidean spaces.</p><br/><br/> <a href="https://www.lesswrong.com/posts/M2H8qGrrbtX39brKW/math-terminology-as-convolution#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/M2H8qGrrbtX39brKW/math-terminology-as-convolution<guid ispermalink="false"> M2H8qGrrbtX39brKW</guid><dc:creator><![CDATA[bhauth]]></dc:creator><pubDate> Mon, 30 Oct 2023 01:05:11 GMT</pubDate> </item><item><title><![CDATA[Grokking, memorization, and generalization — a discussion]]></title><description><![CDATA[Published on October 29, 2023 11:17 PM GMT<br/><br/><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:11:37 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:11:37 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> <strong>Intro:</strong> Kaarel and Dmitry have been meeting to think about various interpretability and toy model questions. We are both interested in unsupervised and superposition-agnostic interpretability results ( <a href="https://www.lesswrong.com/posts/Go5ELsHAyw7QrArQ6/searching-for-a-model-s-concepts-by-their-shape-a"><u>Kaarel</u></a> , <a href="https://www.lesswrong.com/posts/8ms977XZ2uJ4LnwSR/decomposing-independent-generalizations-in-neural-networks"><u>Dmitry</u></a> ). Recently we discussed questions related to grokking, memorization, double descent and so on. Dmitry has been doing a number of experiments on modular addition with Nina Rimsky. (See <a href="https://www.lesswrong.com/posts/SbzptgFYr272tMbgz/the-low-hanging-fruit-prior-and-sloped-valleys-in-the-loss"><u>here</u></a> and <a href="https://www.lesswrong.com/posts/4v3hMuKfsGatLXPgt/investigating-the-learning-coefficient-of-modular-addition"><u>here</u></a> . Another writeup on modular addition circuits based on these experiments is in the works. Note that Nina is also interested in these questions, but couldn&#39;t join today. Dmitry&#39;s views here are almost entirely a result of conversations with Nina.) Dmitry is interested in having a better gears-level understanding of grokking and thinks there are some issues with how these are interpreted in the intepretability/alignment community and literature (a view Kaarel partially shares). Kaarel&#39;s views on the topic should be attributed in part to previous discussions with Jake Mendel and Simon Skade. The discussion started in a private conversation, and we decided that it might be helpful to continue this as a public discussion. This is our first experiment with LW conversations, so we would like to heartily invite critical feedback about style, format, technical level, etc. </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dj8kszLHJoNC4vCwg-Fri, 27 Oct 2023 11:11:45 GMT" user-id="dj8kszLHJoNC4vCwg" display-name="Kaarel" submitted-date="Fri, 27 Oct 2023 11:11:45 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Kaarel</b></section><p> Do you know if anyone has compiled a list of all the quantitative aspects of grokking / double descent that we&#39;d expect a good theory of memorization vs generalization to explain? stuff like the location of interpolation thresholds in various parameters, (claimed) superexponential growth of the time to grok as the data set size decreases </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:12:10 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:12:10 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> I think there are several interesting questions that are largely distinct here. There&#39;s been some work done on all of them, but I&#39;m not sure if I&#39;m up to date on all of it </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:12:20 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:12:20 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> There&#39;s a theory that grokking is directly the competition between a large-basin phenomenon (grokking) and small-basin phenomena (memorization). I think the strongest evidence for this is found in <a href="https://arxiv.org/pdf/2207.08799.pdf"><u>Barak et al</u></a> on parity learning. There&#39;s an attempt at isolating/explaining large generalizing circuits in terms of sparsity (which I think is useful, but doesn&#39;t capture a lot of interesting cases?) in a paper of <a href="https://arxiv.org/pdf/2303.11873.pdf"><u>Merrill, Tsivlis and Shukla</u></a> , and another reinterpretation, via a linear programming complexity measure, that I prefer, by <a href="https://arxiv.org/abs/2310.05918"><u>Liu, Zhong, and Tegmark</u></a> . </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:12:27 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:12:27 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> I have some issues with this interpretation (related to what I was telling you in Oxford), but I think after some tests we did with Nina that it&#39;s largely correct for modular addition </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:12:37 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:12:37 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> Within this interpretation, I think there are two related questions that people are interested in: namely,</p><p> A. why does grokking sometimes occur after memorization, rather than both of them occurring at the same time (as you&#39;d expect from an ordinary race) and</p><p> B. why does phase transition occur (ie, the phenomenon where grokking seems to occur in quanta of &quot;learning a circuit&quot; and the process of learning a circuit starts with a part where progress is slow/imperceptible, then becomes faster than memorization, then (practically) stops once the weight assigned to the circuit has become large). This can be asked both on the level of offline and online learning dynamics, ie, both as a function of training time and as a function of number of samples. </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:12:46 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:12:46 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> I personally am confused about the amount of ink spilled about Question B above, and think that (assuming the “large circuit” hypothesis), the explanation of the phase transition is somewhat obvious. I might be misunderstanding what people actually are thinking here. </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:12:55 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:12:55 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> Namely as I see it, a generalizing circuit helps reduce overall loss by pushing a particular linear combination of weights. Generally, nontrivial circuits in x-entropy loss (and I think this is somewhat true for other kinds of loss, though I haven&#39;t thought about it as much) will tend to want to improve in directions where they have started learning something but aren&#39;t to the point of having fully learned the thing. There&#39;s a few ways to see that this should happen, but a simple symmetry breaking argument is sufficient: just note that at a noisy configuration, you would expect &quot;learnable directions&quot; to be very noisy, and largely cancel each other out, so the gradient will be predominantly noise from the perspective of the circuits that are eventually learned; but a circuit by itself has a clear learnable direction which isn&#39;t noise. Thus once a circuit starts getting learned, it will also become more attractive to learn it, until it is fully learned. This is a phase transition behavior. We observe this also for an individual memorization circuit (though for memorization circuits it&#39;s hard to see in the performance over training graphs, since each memorization circuit is tiny and they smooth each other out) </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:13:03 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:13:03 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> The grokking phase transition is the same phenomenon (once symmetry is broken and there&#39;s a clear and un-noisy attractor at a basin, you&#39;ll see increased learning towards that basin. If the basin is large and generalizing, you&#39;ll naturally see what we observe in grokking). BTW, you can also see the phase transition behavior mathematically using a toy model for a circuit. So in my mind the existence of phase transitions is kind of obvious, kind of a non-issue, and I think that people pay way too much attention to it </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:13:54 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:13:54 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> Though there is a nice paper which explicitly connects phase transitions (in an MSE context) to phase transitions in physics, and (if I understand correctly), more or less fully explains grokking in eg MSE modular addition in a mathematical physics sense (it makes lots of assumptions and approximations -- including the mean field theory approximation, but it seems they are supported empirically). I think I mentioned this paper before: <a href="https://arxiv.org/pdf/2310.03789.pdf">Rubin et al.</a> </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:14:17 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:14:17 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> This is an investigation of the specific mechanism and mathematical shape of the phase transition -- again, I don&#39;t think extra explanation or proof is needed to see that it will exist to some extent </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:14:29 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:14:29 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> I think Question A. above (why does grokking sometimes occur after memorization/why does it look like it has some unique stochastic behavior that is qualitatively different from memorization) is more interesting </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:14:44 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:14:44 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> I don&#39;t know if it is explained in a way that I find satisfactory. I think <a href="https://arxiv.org/abs/2210.01117"><u>omnigrok</u></a> by Liu et al. has some positions on it. My favorite point of view on it at the moment is the &quot; <a href="https://arxiv.org/pdf/2206.04817.pdf"><u>slingshot mechanism</u></a> &quot; by Thilak et al. (the paper makes a few assumptions about grokking, like that it happens after memorization, which are false in general, but I don&#39;t think any of them are load-bearing) </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:15:22 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:15:22 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> The idea here is that the thing that causes the weird behaviors like generalization long after memorization is an artifact of the stochastic part of SGD (maybe improved by ADAM) and only happens for sufficiently large learning rates (ie, not for &quot;smooth&quot; gradient descent). I think the paper that first introduces and studies the relevant SGD phenomenon (though not in the context of grokking) is the &quot;Edge of Stability&quot; paper ( <a href="https://arxiv.org/abs/2103.00065"><u>Cohen et al.</u></a> ). </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:15:31 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:15:31 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> In our modular arithmetic experiments, Nina and I have very consistently observed that grokking happens much better and much faster when learning rate starts out comparatively large (within some reasonable bounds, but actually even quite large learning rates of .1 or more will sometimes immediately grok). Also, similar to what the paper predicts, we observe that there is an optimal learning rate (neither too low nor too high) that depends on the architecture and the complexity (ie, the size of the prime) </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:15:39 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:15:39 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> However, I&#39;m not 100% sure that this is the only/the correct explanation for the phenomenon of grokking being weird from a statistical process perspective/ behaving long after memorization in certain contexts. There might be some other things going on </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dj8kszLHJoNC4vCwg-Fri, 27 Oct 2023 11:18:21 GMT" user-id="dj8kszLHJoNC4vCwg" display-name="Kaarel" submitted-date="Fri, 27 Oct 2023 11:18:21 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Kaarel</b></section><p> Could you say a bit more about what you mean by large-basin phenomena vs small-basin phenomena? Is this just referring to something like the effective parameter count of the model — generalizing solutions are ones with a smaller effective parameter count — or is this referring to actual basins in the loss landscape? (I&#39;m mostly asking because with a regularization term in the loss, it seems plausible to me that memorizing solutions do not correspond to basins at all, strictly speaking. I agree they might correspond to basins if you look at the classification loss alone.) Is this also roughly the same story as the one in <a href="https://arxiv.org/abs/2309.02390">Varma et al.</a> and <a href="https://arxiv.org/abs/2303.06173">Davies et al.</a> ？ </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 11:25:14 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 11:25:14 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> Yeah I am using the term &quot;basin&quot; very loosely, almost (but not quite) synonymously with &quot;circuit&quot;. In a very noiseless (or, possibly, a very overparametrized) architecture, I would expect every memorization to correspond to a small dip in the loss (in x-entropy loss, the dip is on the order of 1/n where n is the number of samples). So it&#39;s sort of a basin (even though it&#39;s not a local minimum). This is the point of view we take in the <a href="https://www.lesswrong.com/posts/SbzptgFYr272tMbgz/the-low-hanging-fruit-prior-and-sloped-valleys-in-the-loss">low-hanging fruit</a> post with Nina. I think that this is similar to the notion of &quot;pattern&quot; in the second paper you shared ( <a href="https://arxiv.org/abs/2303.06173">Davies et al.</a> -- btw I haven&#39;t seen this paper before, thanks for sharing it). And I think that both papers you mention fit into this &quot;large vs. small basin&quot; picture. </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dj8kszLHJoNC4vCwg-Fri, 27 Oct 2023 11:54:45 GMT" user-id="dj8kszLHJoNC4vCwg" display-name="Kaarel" submitted-date="Fri, 27 Oct 2023 11:54:45 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Kaarel</b></section><p> Here&#39;s a heuristic story of grokking that I sort of like (I think this is roughly the story from the two papers above), but which I think you might not like (?), and I&#39;d be interested in better understanding if/why you think this story is wrong or what this story is missing:<br><br> Generalizing circuits are more efficient (in the sense of getting the logits scaled to a particular high value using less weight norm) than memorizing circuits, roughly because in a generalizing circuit, the same weights get reused to push logits to be high for many (or, without label noise, possibly all) data points, whereas if the NN is an ensemble of memorizing circuits, more of the weight norm is wasted on pushing the right logit to be high on each particular data point alone. With weight regularization, and assuming there aren&#39;t memorizing local optima (that gradient descent can get stuck in), this implies that a generalizing solution is found eventually. Two parts of this story that I&#39;m not sure how to make very good sense of are: 1) why memorizing circuits are learned initially (though I think that this in fact often doesn&#39;t happen in practice, so maybe it&#39;s sort of reasonable for us not to have a reason to expect this?) and 2) whether something like this also makes sense without weight decay (I&#39;m aware grokking sometimes happens without weight decay, but I don&#39;t have a good sense of the state of empirical evidence on the importance of weight decay for grokking / double descent — for instance, is it the case that weight decay plays a key role in most realistic cases of generalization?).<br><br> For instance, this story doesn&#39;t depend on the optimizer used (SGD/GD/Adam), and I would currently guess that it&#39;s the main cause of most cases of generalization long after getting very low train loss, which I think you might disagree with? I&#39;d be interested in being convinced that I&#39;m wrong here :). I guess it&#39;s possible that there&#39;s multiple independent phenomena that outwardly look the same, ie give the same grokking-like loss curves, and maybe the disagreement here (if there&#39;s any) is mostly not about whether any of these make sense, but about which is closest to being the main cause of sudden generalization in realistic cases? (Another thing I&#39;m confused about that seems relevant to mention here is the degree to which eg the mechanism behind the sudden gain of some practical capability as one scales up the size of a language model is the same as the mechanism behind a small model grokking on some algorithmic task, but maybe let&#39;s leave a discussion of that for later.) </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dj8kszLHJoNC4vCwg-Fri, 27 Oct 2023 11:58:00 GMT" user-id="dj8kszLHJoNC4vCwg" display-name="Kaarel" submitted-date="Fri, 27 Oct 2023 11:58:00 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Kaarel</b></section><p> (Another obstacle to making better sense of this story is how to think of multiple circuits living sort of independently in a neural net / contributing to the logits independently — I wanted to mention that I&#39;d also like to understand this better before being happy with the story.) </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 12:07:54 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 12:07:54 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> I think there are a few points here. First, I think the &quot;heuristic story&quot; you mention largely agrees with what I mean by the &quot;competition between large and small circuits&quot; model, and I agree that it seems correct for many toy models including modular addition and the parity paper of Barak et al, and probably is at least partially correct in more general networks. (BTW I think this model for grokking as learning large, more efficient circuits is already introduced in the original paper of <a href="https://arxiv.org/abs/2301.05217">Nanda et al</a> , if not in the earlier paper of <a href="https://arxiv.org/pdf/2201.02177.pdf">Power et al</a> .) I also agree with your &quot;two hard parts&quot;. I think your second &quot;hard question&quot; corresponds to my question A (and I&#39;ll give a rant on the first &quot;hard question&quot; about weight decay momentarily). I think that, in addition to the two questions you mention, people often seem to worry about what I call &quot;Question B&quot;, namely, why the existence of a &quot;more efficient&quot; circuit corresponds to something that looks like a phase transition (ie, a discrete-looking learning event that, eg if you look at generalization loss, will start slow, speed up, then complete). I think the key term in your heuristic story that corresponds to this question is &quot;more efficient&quot;. If &quot;more efficient&quot; meant that the best way to reduce loss is always to move towards a generalizing (or &quot;grokking&quot;) circuit, then we would observe a very different picture where memorization never occurs and the whole grokking story is moot. But in fact, even with very efficient architectures, we do tend to observe memorization happening a little bit before generalization starts. So generalization is (at least under this model, though I think this is true more generally) more efficient <i>in the limit</i> , but very early in training, generalization contributes less to the gradient, and local behavior is mostly dominated by memorization.</p><p> I think that when you explain your model, you sort of naturally jump to the same conclusion as me, that if you have a few possible large and efficient circuits then (ignoring everything else that happens, whether it be memorization or something else), you would expect a phase transition-like behavior, where first a noisy symmetry-breaking behavior chooses a large circuit, then this large circuit warms up (slow growth), then it has high growth, then it completes.<br><br> I think that it&#39;s also kind of obvious why for learning memorization circuits, this will tend to happen much faster. Namely, since each memorization circuit effectively only requires one weight to learn (ie, its effective dimension is roughly one -- this is a folklore idea, see eg <a href="https://www.lesswrong.com/posts/4v3hMuKfsGatLXPgt/investigating-the-learning-coefficient-of-modular-addition">our post</a> or the end of page 4 in <a href="https://arxiv.org/pdf/2011.14439.pdf">this paper</a> , which you told me about, for empirical confirmations), we can think of memorization as a very &quot;small&quot; circuit, and so the initial symmetry breaking of &quot;turning on&quot; such a circuit (in order to then learn it completely) is expected to happen easily and quickly using eg a stochastic search.</p><p> So in some sense it seems to me that under the model we both are discussing of large, ultimately more efficient circuits vs. small, easy-to-learn circuits, phase transition behavior is an obvious consequence of the model, modulo some kind of symmetry-breaking or &quot;learning shape&quot; argument. But it seems to me that lots of people find this particular behavior surprising, and so I sometimes feel that I&#39;m missing something (maybe my definition of &quot;phase transition&quot; is different from the one normally used in the literature). </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 12:48:15 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 12:48:15 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> About your first &quot;hard question&quot;, allow me to engage on a small rant. Namely, there seems to be a persistent myth that grokking (at least in modular addition) only happens with explicit regularization (like weight decay). I know that this isn&#39;t what you believe, but I&#39;ve seen it all over the literature, including the recent Deepmind paper you mentioned. But just to try to address this false meme: This is known to be generally completely false, including in the overparametrized case. For example this is explained in the beginning of the <a href="https://arxiv.org/abs/2210.01117">omnigrok paper</a> . In our experiments, if you design the modular addition network efficiently, it will often immediately grok without regularization. In fact in some architectures we tried (involving frozen layers), not regularizing has better behavior than regularizing; in other architectures we worked with, regularizing improves performance (but it&#39;s almost never necessary, except in edge cases). If you believe omnigrok (though from what I understand maybe you think there issues with some of the claims there), then the thing that replaces regularization is starting with low weight norm; then usual SGD/whatever optimizer you use is incentivized to find solutions with smaller weight norm just because they&#39;re easier to reach/require fewer steps. I think that when we talk about regularization in some kind of context of &quot;efficiency&quot;, we should include implicit regularization of this type and any other phenomenon that encourages lower-weight-norm solutions. I would guess that some kind of implicit or explicit regularization is in general necessary or at least useful for grokking, and I don&#39;t have enough experience training larger models to predict whether explicit regularization in the form of weight decay helps for grokking more generally. </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 13:02:51 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 13:02:51 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> Finally, you mention that your heuristic story doesn&#39;t depend on the optimizer. This is also what I would a priori expect. However, in our experiments, it appears that the optimizer is extremely important. ADAM is significantly better than SGD, and either ADAM or SGD with suitably high learning rate is significantly better than if we reduce the learning rate to be small and comparatively adjust the number of epochs to be large. Both of these effects don&#39;t just speed up or slow down learning: both ADAM and large lr improve generalization over memorization in a qualitative way, where memorization local minima are more likely without ADAM/with small lr. Also in Neel Nanda&#39;s original experiments, the reasonably high lr seems quite significant. Again, my favorite explanation of this is <a href="https://arxiv.org/pdf/2206.04817.pdf">Thilak et al</a> .&#39;s &quot;slingshot mechanism&quot;. I don&#39;t completely understand the theory behind it, but my understanding is that it is an &quot;edge of stability&quot; ( <a href="https://arxiv.org/abs/2103.00065">Cohen et al</a> ) effect. The idea here is that larger lr effectively makes high-entropy landscapes (like the memorization landscape) have higher temperature (from the stochastic part of SGD) than flatter, lower-entropy landscapes like the generalization landscape, and this privileges generalization over memorization (even more than just ordinary stochasticity, eg via Langevin dynamics, would do).<br><br> I think the <a href="https://arxiv.org/pdf/2207.08799.pdf">Barak paper</a> is the only source I know that carefully tries to control lr and experiment with small lr-SGD (ie, approximating regular GD). I think they sort of get grokking for small networks, but mention that it doesn&#39;t work to generalize for most of the examples they consider (and more generally, they also find this effect of larger lr often being better, even if you inversely adjust learning time).<br><br> So my general guess is that yes, just appropriate regularization + GD (+ maybe some controlled stochasticity to avoid getting stuck) is sufficient for generalization, but one of my biggest updates from our experiments is just how much learning rate and optimizer parameters matter. </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dj8kszLHJoNC4vCwg-Fri, 27 Oct 2023 13:04:27 GMT" user-id="dj8kszLHJoNC4vCwg" display-name="Kaarel" submitted-date="Fri, 27 Oct 2023 13:04:27 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Kaarel</b></section><p> sort of a side point: I think we should clarify what we want to mean by &quot;grokking&quot; — I think we have been using it somewhat differently: it seems to me that you sometimes use it to mean sudden generalization (eg when you said that grokking need not happen after memorization), whereas I use it in the sense of going from very poor test performance to very good test performance (long) after reaching perfect train accuracy?<br><br> not that this really matters except for ease of parsing this discussion, but I think my sense is what people usually mean by &quot;grokking&quot; (?): &quot;We show that, long after severely overfitting, validation accuracy sometimes suddenly begins to increase from chance level toward perfect generalization. We call this phenomenon &#39;grokking&#39;&quot; (from <a href="https://arxiv.org/pdf/2201.02177.pdf">Power et al.</a> )<br><br> And I agree that generalization often happens without regularization, and it seems plausible to me that it can often be sudden — I think your explanation in terms of a circuit that is half-formed implying it is very helpful for decreasing loss to push further weight into it makes sense (though I&#39;d appreciate having more detailed/quantitative models of this — eg, should I think of the circuit as being there in the weights to begin with lottery-ticket-style and undergoing exponential growth for the entire duration that is already nearly finished once it starts to visibly contribute to the loss, or should I think of there being a period of randomly jumping around until we land on a version of the good circuit with tiny weights, followed by a period of pushing weight into the tiny circuit). So I agree that the phase-transition-like loss curve does not seem that surprising — I agree that your Question B seems sort of easy (but I could also just be missing what people find surprising about it) </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 13:22:09 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 13:22:09 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> Right - I agree that I&#39;m using a non-standard definition of grokking. As you say, there are two definitions, one being &quot;large sudden uptick in generalization performance&quot; and the other (which Power et al. originally introduced) being &quot;large sudden uptick in generalization performance long after perfect memorization accuracy&quot;. I might be mistaken since I know very little about the history of the question, but I think that originally the two were the same, since the only known upticks in generalization performance occurred in networks after overfitting. I think the simpler definition (without requiring memorization to complete) is becoming more common now. I think it&#39;s also better, since from a mechanistic perspective, there&#39;s nothing qualitatively different between learning a generalization circuit before or after memorization completes, so this is the definition I use (and yeah, this is confusing and maybe there should be a different term for this).<br><br> The phenomenon of &quot;grokking as originally defined&quot;, ie, of generalization long after overfitting, doesn&#39;t occur all the time. In most of the architectures we studied with Nina, &quot;grokking&quot; in the sense of rapid generalization improvement occurs long before training loss accuracy goes above 50%. However the fact that it does occur sometimes is surprising (this is my &quot;question A.&quot;). In my nomenclature this phenomenon would be a &quot;property of grokking&quot; (that it occurs late) rather than the definition of grokking. </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dj8kszLHJoNC4vCwg-Fri, 27 Oct 2023 13:32:56 GMT" user-id="dj8kszLHJoNC4vCwg" display-name="Kaarel" submitted-date="Fri, 27 Oct 2023 13:32:56 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Kaarel</b></section><p> I&#39;m guessing you agree that the degree of outrageousness / truth of claims like &quot;grokking only happens with weight decay&quot; or &quot;grokking can only happen after memorization&quot; depends massively on which of these two definitions one is using? I think it&#39;s plausible that mostly when such claims are explicitly made in the literature, people mean to say the less wrong thing? Eg I doubt that many people would say that (sudden) generalization can&#39;t happen in the overparametrized case without regularization, anyway after the canonical <a href="https://arxiv.org/pdf/1611.03530.pdf">Zhang et al.</a> </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dj8kszLHJoNC4vCwg-Fri, 27 Oct 2023 13:33:50 GMT" user-id="dj8kszLHJoNC4vCwg" display-name="Kaarel" submitted-date="Fri, 27 Oct 2023 13:33:50 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Kaarel</b></section><p> re the importance of not doing vanilla GD: Is it fair to rephrase what you said as:<br><br> &quot;The heuristic story is somewhat wrong because, in fact, vanilla GD does often get stuck in local optima (or maybe would hit a very low-gradient region and then move slowly enough that it can be seen as stuck for practical purposes), at least in toy algorithmic tasks, whereas SGD has an easier time jumping out of these narrow local optima. This is especially true because the &quot;effective stochasticity&quot; is higher in the narrower basins corresponding to memorizing solutions because of something like (1) the gradients for different data pointing in very different directions (which is less true when there&#39;s a single circuit that&#39;s helpful on all data points — this makes all gradients point &quot;in the direction of this circuit&quot;); in particular, doing a gradient step on input x might break the memorizing circuit on input y; and (1.5) (relatedly) generally sth like: the variance of the gradient computed on a small subset of the inputs at the point <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>in parameter space is related to the variance of the full-batch gradient but computed on a point sampled at random from small disk of some constant radius (?) around <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span></span></span></span></span> in parameter space, and the latter obviously has higher variance when the loss basin is narrower. (And one can tell a similar story for Adam — the stochasticity is still present, and now one also has some combination of momentum and ~forced constant-size steps to help one escape narrow local optima.)&quot; </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 13:44:09 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 13:44:09 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> Yes, I think your summary of why higher lr in SGD/ADAM matters is exactly correct - at least to the best of my ability to understand the &quot;edge of stability&quot; paper. You have much more experience with the optimizer literature, and I&#39;m curious if you&#39;ll come up with nuances/corrections to this point of view if you read some of the literature around the &quot;Edge of Stability&quot; result.<br><br> One could ask whether there are theoretical reasons that &quot;vanilla GD with regularization&quot; fails to generalize, I don&#39;t feel like I have enough of model to say for sure. I think it could go either way. Ie, it&#39;s possible that even with regularization, you would expect vanilla GD to converge to a memorization minimum (there&#39;s a simple mathematical argument that, for suitable choices of architecture and hyperparameters, a memorization solution can be fully stable under GD even with regularization - I can sketch it out for you if you&#39;re interested). On the other hand, it&#39;s possible that when the empirical networks we coded get stuck executing low-lr SGD, this is just because the gradient is very small, and if one were to wait a suitable (and possibly astronomical) amount of time, SGD would eventually converge to a generalizing solution. I think that I have genuine uncertainty about which phenomenon is &quot;theoretically correct&quot; (or whether there is significant dependence on architecture/initialization norm, even for theoretical limit cases), and I wouldn&#39;t be prepared to make a bet either way. I think this is an interesting topic to study! I think <a href="https://arxiv.org/pdf/2310.03789.pdf">Rubin et al.</a> may be a step towards understanding this - it sort of follows from their context, at least if you believe their assumptions, that <i>in their MSE (mean-squared error) loss architecture,</i> &quot;vanilla <strong>SLGD</strong> &quot; will grok with an arbitrarily small step size. Ie, if you introduce noise in a theoretically controlled way rather than through SGD, you&#39;ll get a generalizing solution in a suitable limit. Here I should flag that I don&#39;t completely understand that paper at the moment. </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dj8kszLHJoNC4vCwg-Fri, 27 Oct 2023 13:46:32 GMT" user-id="dj8kszLHJoNC4vCwg" display-name="Kaarel" submitted-date="Fri, 27 Oct 2023 13:46:32 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Kaarel</b></section><p> I&#39;d be quite interested to hear the stuck construction, especially if it seems somewhat realistic (in particular, I think this might be relevant to my disagreements/confusions with omnigrok) </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 13:56:55 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 13:56:55 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> About &quot;outrageousness&quot;, I think it&#39;s pretty natural that people don&#39;t read each other&#39;s papers. Intepretability is a very new field with people coming in from a bunch of fields (theoretical physics, academic CS, statistics, and industry to name a few). I think this kind of &quot;stuck meme&quot; phenomenon occurs even in much smaller fields as well. So I don&#39;t think it&#39;s outrageous or a mark of bad scholarship (in particular, I constantly notice giant blindspots in my understanding of the literature). But first, &quot;grokking as originally defined&quot; (ie, long after memorization is complete) does occur without regularization: see eg the <a href="https://arxiv.org/pdf/2206.04817.pdf">Thilak</a> paper mentioned before, and <a href="https://arxiv.org/abs/2301.02679">Gromov</a> . Second, I&#39;ve seen the explicit claim in papers that the other definition of grokking, ie, &quot;rapid generalization loss improvement&quot;, can&#39;t occur without regularizing/ without first overfitting (don&#39;t remember exactly where, and don&#39;t think it&#39;s useful to try to find references to shame people - again, I think it&#39;s perfectly normal for such memes to become entrenched). I think the &quot;omnigrok&quot; paper also low-key complains about this persistent belief. </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dj8kszLHJoNC4vCwg-Fri, 27 Oct 2023 13:58:28 GMT" user-id="dj8kszLHJoNC4vCwg" display-name="Kaarel" submitted-date="Fri, 27 Oct 2023 13:58:28 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Kaarel</b></section><p> I agree that it was a bit outrageous of me to call these claims outrageous :) (and I also agree with your other points) </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Fri, 27 Oct 2023 14:12:21 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Fri, 27 Oct 2023 14:12:21 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> For the stuck construction: actually, the original example I wrote down doesn&#39;t work. The rough idea is this: instead of regularizing, imagine you&#39;re constrained to lie on a sphere. Say you&#39;ve found a good memorizing point, which is far from any generalizing attractor. Then there may be learnable directions to learn a generalizing circuit, but because of the &quot;warm-up&quot; effect, the loss decrease going in these directions might be smaller than the corresponding loss increase from moving away from your memorizing solution. I&#39;m not sure how plausible this situation is in realistic networks: I suspect you may be right that this happens less than people think (and that you would expect generalization to win even with very low regularizations, just at very slow/astronomical time scales). </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dj8kszLHJoNC4vCwg-Fri, 27 Oct 2023 14:38:15 GMT" user-id="dj8kszLHJoNC4vCwg" display-name="Kaarel" submitted-date="Fri, 27 Oct 2023 14:38:15 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Kaarel</b></section><p> Regarding a memorizing circuit having an effective dimension of 1 being the reason that it tends to be learned faster: I think it makes a lot of sense to me that this would happen in the &quot;learning does a random walk until landing on a tiny version of a good circuit, which then gets its weight pushed up&quot; picture, but I understand less well what this would look like in the picture where both circuits are learned simultaneously, from the beginning of training, just with different speeds (I think this is the picture in eg <a href="https://arxiv.org/pdf/2309.02390.pdf">Varma et al.</a> ). I guess the questions that come up here are:<br> 1) Which picture is &quot;more right&quot;? (Is there a way to think of these as being the same picture?)<br> 2) If the latter picture makes sense, what does the implication from having an effective dimension of 1 to being learned fast look like in it?<br> 3) Is there a better picture-independent/orthogonal way to understand this?<br><br> (I think these have significant overlap — free to only address whichever seems most useful.)<br><br> my guess at an answer: only having to get 1 parameter right implies that there is likely a full memorizing circuit close to where one starts, which means that gradients toward it are also larger to begin with (+ probably less importantly, one needs to travel a smaller distance)? Or maybe a memorizing circuit having having small effective dimension implies that the &quot;largest generalizing circuit starting off smaller than the largest memorizing circuit&quot; or slightly less vaguely &quot;starts off with a much smaller serial product of weights, causing smaller gradients pushing it up&quot; (+ some quantitative argument for why the benefit of doing an update pushing weight into the generalizing circuit on every data point, vs a particular memorizing circuit only getting boosted when we do a gradient step on that particular data point, tends to initially be dominated by this circuit size / effective parameter count effect)?<br><br> (I think <a href="https://arxiv.org/pdf/2112.03215.pdf">Pezehski et al.</a> , <a href="https://arxiv.org/pdf/2107.12685.pdf">Kuzborskij et al.</a> , <a href="https://arxiv.org/pdf/2108.12006.pdf ">Stephenson &amp; Lee</a> might also be helpful, but tbh I&#39;ve only read the abstracts (h/t Jesse Hoogland for mentioning these once).) </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Sat, 28 Oct 2023 13:57:18 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Sat, 28 Oct 2023 13:57:18 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> Yes, I feel like all of your models for why memorization happens the way it does make sense, and I think the question of how they combine makes sense and is interesting. The one thing I would definitely predict is that &quot;lottery ticket&quot; phenomena matter, ie, that the initialization makes certain memorization circuits more immediately learnable than others. I would suspect this is more due to stochasticity in the derivative of logits with respect to the weights (which can make some memorizations faster to learn) than to differences between the logits themselves at initialization.<br><br> Thanks for these papers on memorization/double descent - they all look cool, and I&#39;ll take a look. There&#39;s also the very good &quot; <a href="https://arxiv.org/pdf/2303.14151.pdf">Double descent demystified</a> &quot; paper which looks at linear regression for noisy inputs directly (this is a convex optimization problem I think, so the training dynamics are simple). I think that there are several differences between memorization in our context and the &quot;usual&quot; double descent phenomenon.</p><p> First, most theoretical studies of double descent look at MSE loss, where I think the &quot;symmetry breaking&quot; phenomenon is even less pronounced than cross-entropy. In particular, in a pure memorization problem I would expect cross-entropy loss to work a bit more like sequentially learning a series of memorizations, whereas MSE would look a bit more like just flow towards the linear regression result (see also my next comment). Second, we have no label noise (which can results in different behavior in the &quot;Double Descent Demystified&quot; paper), though maybe a combination of stochasticity from SGD and batching can lead to similar effects.  And finally, of course the generalizing solution changes the dynamics (since the effective dimension of the generalizing circuit is much smaller than the number of samples we consider). But I agree that it&#39;s a good intuition that linear regression and memorization should exhibit some similar behaviors. I don&#39;t have a very good sense for this (Nina understands it much better), and would be interested in your/Jake&#39;s points of view. </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Sun, 29 Oct 2023 20:32:02 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Sun, 29 Oct 2023 20:32:02 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> Actually, when sketching out formulas for a comparison of cross-entropy and  reply, I realized that there&#39;s a nice model for cross-entropy loss early on in training as an for architectures with sufficiently many output classes as a certain <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\ell^1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">ℓ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> -metric maximizing flow (and this sort of conflicts with viewing cross-entropy loss as a circuit). Here&#39;s a simple but I think useful picture:</p><p> <strong>Claim</strong> . If we assume that the number of output classes, K, is suitably high compared to other hyperparameters (something that is definitely true in modular addition), then loss early in training is, up to an additive constant, close to the sum of the correct logits</p><p> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L_\text{cross-entropy}\approx\sum_x o(x,y^*)+C"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mtext" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.519em;">cross-entropy</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">≈</span></span> <span class="mjx-munderover MJXc-space3"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">∑</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.439em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">o</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.082em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span></span></span></span></span> ,</p><p> where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="C"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span></span></span></span></span> is a constant. (Here the sum is over input classes x, the output<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y^* = y^*(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.082em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.082em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> is the correct output for the given input, and o(x,y) is the logit.)</p><p> <strong>Proof</strong> The loss per input, x, is the log of</p><p> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{softmax}_x = \frac{\exp(o(x,y*))}{\sum_{y=1}^K \exp(o(x,y))}."><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">softmax</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 5.556em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 7.858em; top: -1.706em;"><span class="mjx-mrow" style=""><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">exp</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">o</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 7.858em; bottom: -1.508em;"><span class="mjx-mrow" style=""><span class="mjx-munderover"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">∑</span></span></span> <span class="mjx-stack" style="vertical-align: -0.324em;"><span class="mjx-sup" style="font-size: 83.3%; padding-bottom: 0.216em; padding-left: 0px; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;">K</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; padding-right: 0.06em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">exp</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">o</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 5.556em;" class="mjx-line"></span></span><span style="height: 2.273em; vertical-align: -1.066em;" class="mjx-vsize"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span></span></span></span></span></span></p><p> Now early in training, terms in the sum in the denominator are close, so changing a single term has a much smaller effect on the softmax than changing the numerator. Thus we can assume that change in the denominator is mostly zero/noise sufficiently early on. Thus we can approximate the loss associated with x as a constant plus log of the numerator, ie, <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L_x \approx C_x + o(x,y^*)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">≈</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.045em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">o</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.082em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> . <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\square"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">□</span></span></span></span></span></span></span></p><p> This means that, early on, gradient descent will just be trying to increase every logit with roughly equal weight (hence <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\ell^1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">ℓ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> ). <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label=""><span class="mjx-mrow" aria-hidden="true"></span></span></span></span></span> So in fact, for cross-entropy loss the &quot;symmetry breaking&quot; model is sort of broken for memorization, since there is not much competition between different attractors (at least assuming you&#39;re overparametrized): loss is just trying to push the correct logits to be as high as possible. There&#39;s still a kind of basin behavior, where once a logit is learned, loss associated to that particular input becomes mostly flat (especially if you have regularization). I think this is even worse with MSE loss: since you&#39;re taking squares, MSE loss will push logits that are further away from being learned even faster (so in the phase transition picture I gave, instead of having a &quot;warmup&quot; where circuits that are partially learned become more attractive, there is an opposite effect). </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dj8kszLHJoNC4vCwg-Sun, 29 Oct 2023 21:04:24 GMT" user-id="dj8kszLHJoNC4vCwg" display-name="Kaarel" submitted-date="Sun, 29 Oct 2023 21:04:24 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Kaarel</b></section><p>这就说得通了。 I think the conclusion about no symmetry breaking holds independently of the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\ell^1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">ℓ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> claim though? Ie, in the overparametrized case, assuming gradients computed from individual data points are independent random vectors <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v_1,\ldots,v_m"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">…</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span></span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label=""><span class="mjx-mrow" aria-hidden="true"></span></span></span></span></span> (let&#39;s say with iid gaussian coordinates or drawn uniformly from a sphere, whatever), one can decrease loss on each input (assuming there are fewer data points than params) for a while just by moving in the direction of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v_1+\cdots+v_m"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋯</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span></span></span></span></span></span></span></span> (or, more precisely, gradient descent will in fact move in this direction).<br><br> I guess maybe the additional conclusion from the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\ell^1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">ℓ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> claim here is that we can think of moving in these directions as not just decreasing loss on the corresponding inputs, but more precisely as mostly just pushing a single logit up?<br><br> Also, I think it might still make sense to think of these as circuits — movement in the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v_i"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span></span> direction builds up a small <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v_i"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span></span> -circuit that memorizes data point <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="i"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span> (?) </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Sun, 29 Oct 2023 21:40:24 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Sun, 29 Oct 2023 21:40:24 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> Agreed that you can view learning data point i as a circuit. In some sense you can call anything a circuit, but I agree that the fact that they&#39;re somewhat independent in the overparametrized case makes them more &quot;circuit-like&quot;. I also think that with cross-entropy loss, memorizing an input looks more like a circuit than for MSE loss, because the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\ell^1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">ℓ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> metric is more basis-dependent than the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\ell^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">ℓ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> metric (and this becomes even more pronounced beyond early learning, when the basis of logits becomes even more important) - but this is kind of a vague/aesthetic point.</p><p> Right, I agree with your more general argument against symmetry-breaking for memorization. I&#39;m realizing that my notion of symmetry breaking is a bit confused: it&#39;s an intuition that needs more unpacking. So let me try to formalize it a little. I think a more formal notion of &quot;symmetry breaking&quot; here is a situation where you expect that vectors that move towards all the different possible circuits conflict with each other (usually because there are &quot;too many&quot; possible circuits in some appropriate sense). If you view &quot;learning data point x_i&quot; as a circuit, then you&#39;re right, in the overparametrized case, you can move towards all of them simultaneously without expecting conflicts. This complicates my picture of generalizing circuits having symmetry breaking. In most of the networks we trained in our experiments, we used a small embed_dim (this tends to improve efficiency a lot). In our architecture, though there&#39;s only one nonlinearity, there is also a hidden_dim, and setting that high enough can make a network with such a &quot;narrow&quot; layer still be overparametrized (and successful at memorizing). But the embed_dim limits the number of learnable generalizing circuits (the maximal number, barring weird superposition effects, is embed_dim/2); on the other hand, the number of possible &quot;types&quot; of generalizing circuits is equal to the number of Fourier modes, which is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{p-1}{2}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.401em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.981em; top: -1.566em;"><span class="mjx-mrow" style=""><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.981em; bottom: -0.665em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.401em;" class="mjx-line"></span></span><span style="height: 1.578em; vertical-align: -0.47em;" class="mjx-vsize"></span></span></span></span></span></span></span> 。 So in our architecture, there is clear symmetry breaking in that you can&#39;t learn all the different Fourier modes at once (since they don&#39;t &quot;fit&quot; in the embed_dim -- in some sense, the model is underparametrized from the point of view of types of generalizing circuits). In other models, like Nanda et al.&#39;s original model, this is actually not the case, so in some sense, you could learn all the Fourier modes without getting conflicts. So I guess in this case you need a more sophisticated symmetry breaking argument. One way to argue that it&#39;s bad to learn all Fourier modes simultaneously (ie, you have symmetry breaking) is to see that regularization (whether explicit or implicit) limits the number of &quot;fully learned&quot; Fourier modes you can have, and partially learned Fourier circuits have much worse loss than fully learned Fourier circuits. This is a bit circular, since it essentially goes back to claiming that Fourier circuits improve loss in a nonlinear way (the original claim about phase transitions). But it&#39;s easy to see in mathematical models (eg, for the MSE case, it follows from the &quot; <a href="https://arxiv.org/pdf/2310.03789.pdf">Droplets of good representations</a> &quot; result).</p><p> I&#39;ve kind of argued myself into a corner, haven&#39;t I? :) Maybe the phase transition question (&quot;Question B&quot;) shouldn&#39;t be considered obvious. Though it seems intuitively unsurprising. It&#39;s also very easy to see experimentally. Like here&#39;s a visualization we made of the loss per Fourier mode over training for a modular addition circuit: <br><br><img style="width:60.31%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BYwGEBspGgPY5nBZN/j8xjeneo1d2wxgm7ehwn" alt="ablation_P37_frac0.8_hid64_emb24_tieunembedFalse_tielinFalse_freezeFalse_run1.png"></p><p> Here you see that starting very early on, modes that start getting &quot;turned on&quot; get more prominent/more relevant for loss while modes that don&#39;t start getting &quot;turned on&quot; stabilize to an irrelevant baseline (this is the analog of logits - with memorization, you&#39;d expect all logits to improve early on). Note that here 5 modes are learned, but the embed_dim has room for up to 12, so this symmetry breaking behavior is not just due to the effective underparametrization I mentioned (and similar pictures happen when it would be possible to fit all Fourier modes in the embed_dim, ie, you have effective overparametrization). </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dj8kszLHJoNC4vCwg-Sun, 29 Oct 2023 22:05:13 GMT" user-id="dj8kszLHJoNC4vCwg" display-name="Kaarel" submitted-date="Sun, 29 Oct 2023 22:05:13 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Kaarel</b></section><p> We&#39;ll wrap up here, but we&#39;re planning to have part 2 of this discussion next week. I think I&#39;ve learned a lot in this exchange — thank you! Here are some topics that we&#39;re hoping to discuss (more) in part 2:<br> * Rubin et al. (which you&#39;ve told me is good; I&#39;ll also try to find time to read it before we talk again)<br> * implicit regularizers<br> * relatedly: my disagreements/confusions with omnigrok<br> * maybe a bit on double descent in model size, data set size<br> * SLT connections<br> * possible issues with the &quot;generalizing circuit vs. memorizing circuit&quot; dichotomy for larger/more complicated networks<br> * how does any of this connect to the sudden emergence of practical capabilities in (language) models?<br> * more broadly, how does understanding this stuff (or figuring out deep learning theory in general) get us closer to solving alignment? Should people that care about alignment work on this, or can we trust usual academia to handle this? </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="k79hzhnYroxnMrTrL-Sun, 29 Oct 2023 22:13:13 GMT" user-id="k79hzhnYroxnMrTrL" display-name="Dmitry Vaintrob" submitted-date="Sun, 29 Oct 2023 22:13:13 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>Dmitry Vaintrob</b></section><p> Thanks. Chatting with you here has really helped me clarify and find bugs in my thinking about this.</p><p> I really like your list of questions! Most of these are all things I&#39;ve thought very little about  and I&#39;m looking forward to hearing your perspectives on these.</p></section><div></div><br/><br/> <a href="https://www.lesswrong.com/posts/BYwGEBspGgPY5nBZN/grokking-memorization-and-generalization-a-discussion#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/BYwGEBspGgPY5nBZN/grokking-memorization-and-generalization-a-discussion<guid ispermalink="false"> BYwGEBspGgPY5nBZN</guid><dc:creator><![CDATA[Kaarel]]></dc:creator><pubDate> Sun, 29 Oct 2023 23:17:30 GMT</pubDate> </item><item><title><![CDATA[Comp Sci in 2027 (Short story by Eliezer Yudkowsky)]]></title><description><![CDATA[Published on October 29, 2023 11:09 PM GMT<br/><br/><p> (I am not Eliezer Yudkowsky)</p><br/><br/> <a href="https://www.lesswrong.com/posts/gQyphPbaLHBMJoghD/comp-sci-in-2027-short-story-by-eliezer-yudkowsky#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/gQyphPbaLHBMJoghD/comp-sci-in-2027-short-story-by-eliezer-yudkowsky<guid ispermalink="false"> gQyphPbaLHBMJoghD</guid><dc:creator><![CDATA[sudo]]></dc:creator><pubDate> Sun, 29 Oct 2023 23:09:58 GMT</pubDate> </item><item><title><![CDATA[Mathematically-Defined Optimization Captures A Lot of Useful Information]]></title><description><![CDATA[Published on October 29, 2023 5:17 PM GMT<br/><br/><p>好吧，已经休息很久了。如果没有灵感，我可能一两年内不会再发帖。我将总结<a href="https://www.lesswrong.com/posts/tpr6kkaPQqFgiC5ys/defining-optimization-in-a-deeper-way-part-4">到目前为止我的工作</a>。</p><ol><li>我们可以在因果网络上定义一个函数，该函数描述网络的给定部分围绕某些特定的世界历史优化某些节点的难度<span class="footnote-reference" role="doc-noteref" id="fnrefegkalk21qa"><sup><a href="#fnegkalk21qa">[1]</a></sup></span> 。</li><li>该函数依赖于网络状态的一些偏导数，使其成为世界历史上的局部函数，即它不依赖于世界空间中“遥远”的世界历史。 <span class="footnote-reference" role="doc-noteref" id="fnref2edup7oqvcw"><sup><a href="#fn2edup7oqvcw">[2]</a></sup></span></li><li>在一个维度上，我们可以使用路径积分来找到优化器的“能力”，即它从系统中消除了多少变化。</li></ol><h3>数学总结</h3><p>Optimization is written as <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathrm{Op}(A; p, f)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">p</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>对于“过去”节点<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span> 、“未来”节点<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>和因果网络的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>部分。它测量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w^f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span></span></span>的两个导数（即世界<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span>中的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>值）相对于<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w^p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span></span></span>的比率的（负）对数。第一个是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>变化的“正常”世界，第二个是想象的世界，其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>被“冻结”在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w^f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span></span></span>中的值，无法响应<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w^p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span></span></span>中的无穷小变化。</p><p>我们可以大致写出以下内容：</p><p> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathrm{Op}(A; p,f) = - \log\big( \frac{\mathrm{d}w^f}{\mathrm{d}w^p}\big|_{A\ \mathrm{varies}} \big/ \frac{\mathrm{d}w^f}{\mathrm{d}w^p}\big|_{A\ \mathrm{constant}} \big)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">p</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mstyle MJXc-space1"><span class="mjx-mrow"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.593em; padding-bottom: 0.593em;">(</span></span></span></span></span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.394em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.972em; top: -1.664em;"><span class="mjx-mrow" style=""><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">dw</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">f</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-left: 0px; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">dw</span></span></span></span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.972em; bottom: -0.704em;"><span class="mjx-mrow" style=""><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">p</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.352em; padding-left: 0px; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">_</span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.394em;" class="mjx-line"></span></span><span style="height: 1.674em; vertical-align: -0.498em;" class="mjx-vsize"></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mstyle"><span class="mjx-mrow"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo" style="vertical-align: -0.076em;"><span class="mjx-delim-v"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em; margin-bottom: -0.898em;">∣∣A</span> <span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em; margin-top: -0.898em;">_</span></span></span></span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.545em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.291em; padding-bottom: 0.372em;">&nbsp;</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">变化</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">/</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">dw</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">f</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">dw</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">p</span></span></span></span></span></span></span></span> <span class="mjx-mstyle"><span class="mjx-mrow"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.593em; padding-bottom: 0.593em;">_</span></span></span></span></span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.394em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.972em; top: -1.664em;"><span class="mjx-mrow" style=""><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">_</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-left: 0px; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">_</span></span></span></span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.972em; bottom: -0.704em;"><span class="mjx-mrow" style=""><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">_</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.352em; padding-left: 0px; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">_</span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.394em;" class="mjx-line"></span></span><span style="height: 1.674em; vertical-align: -0.498em;" class="mjx-vsize"></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mstyle"><span class="mjx-mrow"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo" style="vertical-align: -0.076em;"><span class="mjx-delim-v"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em; margin-bottom: -0.898em;">∣∣A</span> <span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em; margin-top: -0.898em;">_</span></span></span></span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.545em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.291em; padding-bottom: 0.372em;">&nbsp;</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">常数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">）</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.372em;">_</span></span></span></span></span></span></span></span> <span class="mjx-mstyle"><span class="mjx-mrow"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.593em; padding-bottom: 0.593em;">_</span></span></span></span></span></span></span></span></span></span></span></p><p>如果<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>相对于<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span>优化<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> ，我们期望由<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w^p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w^p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">的</span></span></span><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">变化</span></span></span></span></span></span></span></span></span>引起的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w^f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span></span></span>的部分（或全部）变化将被移除；因此，当<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>允许变化时的导数将<i>小于</i>当<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>固定时的导数。这意味着<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label=""><span class="mjx-mrow" aria-hidden="true"></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathrm{Op}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">p</span></span></span></span></span></span></span></span></span>将为正值。</p><p>我对这可能意味着什么以及为什么它可能很重要有一些观察。</p><h3>优化与信息相关</h3><p>这是一个简单的计算：如果<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>不以任何方式依赖于<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span> ，则两个导数项将相等，因为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>不会因其中任何一个而变化。 <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>针对<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span>优化<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f 的</span></span></span></span></span></span></span>能力与其收集有关<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p 的</span></span></span></span></span></span></span>信息的能力有关。</p><h3>优化与类似效用的函数相关</h3><p>对于像恒温器这样的简单系统，当恒温器“得到它想要的”时， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathrm{Op}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">p</span></span></span></span></span></span></span></span></span>似乎具有很高的值。 It kind of looks like <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathrm{Op}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">p</span></span></span></span></span></span></span></span></span> across one axis is the second derivative of our utility function, at least within regions of world-space where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span> has roughly equal power and knowledge.</p><h3>优化与功率相关</h3><p>这看起来非常直观明显。恒温器的加热和冷却装置越“强大”，它就越能优化世界。</p><h2>为什么这很重要？</h2><p>我们已经有数学证据证明，类似代理的事物的“知识”和“价值”无法完全分离。因此，如果我们想要对代理人行为进行数学上明确的衡量，我们必须同时考虑这两者。</p><p>其次， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathrm{Op}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">奥普</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">所</span></span></span></span></span></span></span></span></span>研究的历史类型被故意选择为非常普遍的，不需要约翰·温特沃斯大部分作品风格的绝对时间和空间概念。这些网络的一个具体案例是神经网络的激活，因此这些工具理论上可以直接应用于人工智能可解释性工作。</p><h3>高度优化的世界对于优化器来说是“好的”世界</h3><p><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathrm{Op}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">p</span></span></span></span></span></span></span></span></span>较大的世界对于所讨论的优化区域<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>来说往往是“良好的”。它们似乎对应于效用函数的局部最小值（或至少局部帕累托边界）。 They also correspond to worlds where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span> is both knowledgeable and powerful.它们对应于<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span> “控制”的世界。以下是使用此概念进行更安全的人工智能设计的一些潜在想法：</p><ul><li>拥有数学上明确定义的优化措施意味着它可以进行硬编码，而不是依赖于机器学习。</li><li>人们已经进行了很多思考，试图让人工智能变得“低影响”，并且以这种方式使用<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathrm{Op}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">p</span></span></span></span></span></span></span></span></span>可能会让我们更好地指定这一点。</li><li>如果高<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathrm{Op}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">p</span></span></span></span></span></span></span></span></span>的世界往往有利于优化问题，那么这可能会提供一条编码对人类有益的事物的途径。</li><li> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathrm{Op}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">p</span></span></span></span></span></span></span></span></span>可以在人工智能过去定义为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>区域，这使得奖励黑客或修改相关人类的偏好来黑客<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>变得更加困难。</li><li> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathrm{Op}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">p</span></span></span></span></span></span></span></span></span>是局部定义的，但将其扩展到世界上的分布可能是微不足道的。 </li></ul><p></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnegkalk21qa"> <span class="footnote-back-link"><sup><strong><a href="#fnrefegkalk21qa">^</a></strong></sup></span><div class="footnote-content"><p>这里的世界历史是指描述因果网络状态的一组给定数值。例如，如果我们有网络 [摄氏温度] <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\rightarrow"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span></span></span></span></span></span> [水状态]，则以下是世界历史的示例：[-10] <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\rightarrow"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span></span></span></span></span></span> [0]、[45] <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\rightarrow"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span></span></span></span></span></span> [1] 和 [120] <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\rightarrow"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span></span></span></span></span></span> [ 2]。我们将水的状态表示为数字 {0：固体，1：液体，2：气体}。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn2edup7oqvcw"> <span class="footnote-back-link"><sup><strong><a href="#fnref2edup7oqvcw">^</a></strong></sup></span><div class="footnote-content"><p>因此，如果我们考虑之前的世界历史示例，我们的优化指标在 310 开尔文温度下的值并不取决于系统在 315 开尔文温度下的行为。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/wtCiEtQP3YqRkkurS/mathematically-defined-optimization-captures-a-lot-of-useful#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/wtCiEtQP3YqRkkurS/mathematically-defined-optimization-captures-a-lot-of-useful<guid ispermalink="false"> wtCiEtQP3YqRkkurS</guid><dc:creator><![CDATA[Jemist]]></dc:creator><pubDate> Sun, 29 Oct 2023 17:17:04 GMT</pubDate> </item><item><title><![CDATA[A new intro to Quantum Physics, with the math fixed]]></title><description><![CDATA[Published on October 29, 2023 3:11 PM GMT<br/><br/><p><i>置信度：我是一名物理学家，拥有计算量子化学博士学位。我很确定这里没有重大错误，但我仍然可能错过了一些东西。感谢布莱克·史黛西查看这篇文章。</i></p><p>这篇文章的目标是重写三个序列帖子“<a href="https://www.lesswrong.com/s/Kqs6GR7F5xziuSyGZ/p/5vZD32EynD9n94dhr">配置和振幅</a>”、“<a href="https://www.lesswrong.com/s/Kqs6GR7F5xziuSyGZ/p/ybusFwDqiZgQa6NCq">联合配置</a>”和“<a href="https://www.lesswrong.com/s/Kqs6GR7F5xziuSyGZ/p/KbeHkLNY5ETJ3TN3W">不同配置</a>”中的所有内容。我认为它们是解释一个非常困难的主题的崇高尝试。不幸的是，所有这些都是基于对其主题的数学上<i>不正确的</i>描述。</p><p>这篇文章的第一部分是对量子物理基础知识的新介绍，使用基本干涉仪设置作为我们的指导。它针对的是专门的外行水平：会有数学，但通常都是基础的。主要目的是让您了解事物在量子层面上的实际运作方式。它应该涵盖上面三篇文章中的所有内容，但有更正的数学和更有用的解释。</p><p> Only then, in the second part, will I explain why the original sequences are incorrect and deeply flawed. If you are just here for the drama, you can skip to the section “why the sequences posts are incorrect”.</p><h2>第 1 部分：量子世界</h2><p><strong>振幅简介</strong></p><p>在最小的层面上，宇宙是按照量子物理规则运行的，这与我们日常生活中遇到的任何事物根本不同。光光子不是台球，也不是水波。这是第三种东西，它具有两者的特征或两者都没有，并且根据新的规则以新的方式发挥作用。</p><p>量子世界由“波函数”描述，它使我们能够计算物理属性发生任何配置的可能性。每个可能的配置都被分配了一个“概率幅度”，它是一个附加到我们系统的配置的复数。</p><p>当我谈论配置时，我会将其放在括号中<span class="footnote-reference" role="doc-noteref" id="fnrefvorzv3iwvqp"><sup><a href="#fnvorzv3iwvqp">[1]</a></sup></span> |<i>像这样</i>>;。例如，在<a href="https://en.wikipedia.org/wiki/Schr%C3%B6dinger%27s_cat">薛定谔猫</a>场景中，我们可以将 0.1 + 0.2i 的振幅分配给配置 |<i>猫死了</i>>;，并且振幅为-0.9 + 0.37i 到配置|<i>猫还活着</i>>;.显然，这些幅度本身并不是概率（某件事发生的概率不可能是 0.6 <i>i</i> ），但它们可以<i>转换</i>为概率。测量时找到每种配置的<a href="https://en.wikipedia.org/wiki/Born_rule">实际概率</a>由振幅平方的<a href="https://en.wikipedia.org/wiki/Absolute_value">绝对值</a>给出（上面的猫的存活率约为 95%）。</p><p>为了更好地理解这些概率幅度，让我们假设世界上只有一个光光子，向右传播。配置的幅度|<i>光子向右移动</i>>; 然后由<span class="footnote-reference" role="doc-noteref" id="fnrefoatrvo6ex9"><sup><a href="#fnoatrvo6ex9">[2]</a></sup></span>给出：</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="e^{i\theta(x,t)}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style><p>如果您在高中时没有学过高等数学，您可能会害怕对虚数求幂的整个概念。但实际上相当简单。</p><p>您可以将复数的实部和虚部绘制为实部与虚部的二维图上的箭头，如下图所示。 <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="e^{i\theta}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span></span></span>的</span></span></span></span></span></span>作用是在该图上绘制一个描绘圆的箭头。要计算它的值，您需要一个长度为 1 的向右箭头（数字 1 + 0i），然后将其逆时针旋转 θ 角度。然后您可以从图表中读取新数字。 （幸运的是，我们将在本文中避免使用三角学。） </p><figure class="image image_resized" style="width:40.86%"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F845af84f-309e-461b-84c0-63f7d8db0531_833x801.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F845af84f-309e-461b-84c0-63f7d8db0531_833x801.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F845af84f-309e-461b-84c0-63f7d8db0531_833x801.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F845af84f-309e-461b-84c0-63f7d8db0531_833x801.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F845af84f-309e-461b-84c0-63f7d8db0531_833x801.png 1456w"><figcaption>来自维基百科</figcaption></figure><p>您可能听说过著名的<a href="https://en.wikipedia.org/wiki/Euler%27s_identity">方程</a><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="e^{i\pi}=-1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">π</span></span></span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span> 。在此公式中，这意味着当您将箭头旋转 pi 弧度的角度（此处使用弧度，其中 π = 180 度或半圆）时，箭头指向 -1+0i = -1。事实上，无论箭头指向哪里，加上旋转半圈都会使其指向相反的方向，这和乘以-1是一样的。</p><p>在我们的光子中，角度 θ 随着光子的移动而变化。其效果是，经过一定距离后，箭头将旋转一点并指向新方向，从而产生新的幅度。这就是为什么在下面的讨论中，每个光束传播的总距离完全相同是非常重要的<span class="footnote-reference" role="doc-noteref" id="fnrefqs5wejjs41t"><sup><a href="#fnqs5wejjs41t">[3]</a></sup></span> 。箭头旋转一定角度称为“相移”。</p><p>前面我说过，根据幅度计算概率的方法是取绝对值的平方。我们可以将其视为获取箭头的<i>长度</i>并将其平方，以获得特定状态的可能性。</p><p> If our psi is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="e^{i\theta}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span></span></span></span></span></span></span></span></span> , this is very easy, because the length of this arrow is always 1, so we our probability of finding the photon is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="1^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> = 1= 100%.到目前为止很容易。</p><p><strong>干涉仪</strong></p><p>一个光子本身并不是特别有趣，所以让我们介绍一种称为“ <a href="https://www.cs.princeton.edu/courses/archive/fall06/cos576/papers/zetie_et_al_mach_zehnder00.pdf">干涉仪</a>”的实验装置。在这个系统中，光束被分成两部分，然后通过一系列镜子重新组合。仅在这种情况下，我们仅发射单个光子。 </p><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d3d8dd1-a71a-42be-8409-5fdb3100849e_1020x570.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d3d8dd1-a71a-42be-8409-5fdb3100849e_1020x570.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d3d8dd1-a71a-42be-8409-5fdb3100849e_1020x570.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d3d8dd1-a71a-42be-8409-5fdb3100849e_1020x570.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d3d8dd1-a71a-42be-8409-5fdb3100849e_1020x570.png 1456w"><figcaption> （图片改编自<a href="https://quantumphysics-consciousness.eu/index.php/en/the-mach-zehnder-interferometer-explained/">本网站</a>。）</figcaption></figure><p>为了分裂光子，我们使用一种称为“半银镜”的装置。<a href="https://en.wikipedia.org/wiki/Beam_splitter">分束器</a>的实际形式处理需要一些不值得解释的数学工具，不同的分束器可以有不同的设置，但对于简单的半银镜上的一个光子，规则如下：</p><p>当半反射镜被部分光子击中时，入射光束被分成两个独立的配置。一种是“传递”，继续前进，一种是“反射”，改变方向。两种配置的幅度都通过将输入幅度乘以<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{\sqrt{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.533em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.533em; bottom: -1.059em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span></span></span></span></span></span>来缩小<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{\sqrt{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.084em;" class="mjx-line"></span></span><span style="height: 1.72em; vertical-align: -0.749em;" class="mjx-vsize"></span></span></span></span></span></span></span> 。 （约 0.71）。</p><p>如果（<i><strong>且仅当</strong></i>）光束从半反射镜的<i>前</i>侧<i>反射</i>，它也会<i>经历相移，</i>并再次乘以 -1。这可以被认为是将我们的幅度箭头旋转额外的半圆，或者将其翻转到相反的方向。如果它从半反射镜的背面透射或反射，则不会发生相移。它只从前面发生的原因是由于<a href="https://en.wikipedia.org/wiki/Reflection_phase_change">不同介电材料之间的传输</a>规则，而这种相移规则是能量守恒所必需的。 </p><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F179e197e-9773-4ae2-a669-204002661464_371x186.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F179e197e-9773-4ae2-a669-204002661464_371x186.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F179e197e-9773-4ae2-a669-204002661464_371x186.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F179e197e-9773-4ae2-a669-204002661464_371x186.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F179e197e-9773-4ae2-a669-204002661464_371x186.png 1456w"><figcaption>光束分裂后各路振幅</figcaption></figure><p></p><p>所以现在光子的概率幅有两个分量，描述 | 的两种可能的配置。<i>光子在路径 A</i> >; 或 | 上<i>光子位于路径 B >; 上</i>。每个配置都附有一个幅度箭头，每个箭头都指向相反的方向。两个振幅的长度均为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{\sqrt{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.533em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.533em; bottom: -1.059em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.084em;" class="mjx-line"></span></span><span style="height: 1.72em; vertical-align: -0.749em;" class="mjx-vsize"></span></span></span></span></span></span></span> 。从现在开始，我们将只跟踪<i>相对</i>相位，假设它们已经走了相同的距离。这也意味着在本文的其余部分中我们将不必考虑虚数。因此，如果箭头在击中镜子时指向上方，那么它在路径 A 中指向下方，但在路径 B 中指向上方。</p><p>如果您现在在路径 A 中放置一个探测器，它将以 ( <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(\frac{1}{\sqrt{2}})^2 = \frac{1}2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.533em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.533em; bottom: -1.059em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.084em;" class="mjx-line"></span></span><span style="height: 1.72em; vertical-align: -0.749em;" class="mjx-vsize"></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.665em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.441em; vertical-align: -0.47em;" class="mjx-vsize"></span></span></span></span></span></span></span> ），路径 B 也是如此。这意味着配置 | 有 50% 的机会。<i>仅路径 A 中的光子</i>>;，配置的可能性为 50% |<i>仅路径 B 中的光子</i>>;。箭头方向仍然对概率没有影响。</p><p>我们称之为不同配置的“叠加”，因为如果你观察，你永远不会在任何一条路径中找到<i>半个</i>光子。整个光子总是像这样或那样移动。这就是为什么光子不能只是波：如果是波，那么你就能找到“半光子”。</p><p>接下来，两束光束从全反射镜反射并改变方向。由于没有发生分裂，因此也不会发生缩放，但它们都进行了半圆的另一个相移（乘以-1）。这不会影响任何事情。毕竟，两个光粒子都在不断改变箭头方向，重要的是它们的<i>相对</i>相位。此时，当它们走了相同的距离时，它们仍然指向相反的方向。</p><p>现在，每一束光束都击中了下一个半反射镜，事情就变得有趣了。 </p><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d1501ff-e5cc-4fcc-8e9d-220d9f6d4983_1039x577.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d1501ff-e5cc-4fcc-8e9d-220d9f6d4983_1039x577.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d1501ff-e5cc-4fcc-8e9d-220d9f6d4983_1039x577.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d1501ff-e5cc-4fcc-8e9d-220d9f6d4983_1039x577.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d1501ff-e5cc-4fcc-8e9d-220d9f6d4983_1039x577.png 1456w"><figcaption>跟踪每条路径的幅度</figcaption></figure><p>首先，2 束光束中的每一束都被再次分成 2 束，因此对于所有不同的光路，我们现在需要考虑 4 个新的振幅。每个的长度将为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{\sqrt{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.533em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.533em; bottom: -1.059em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.084em;" class="mjx-line"></span></span><span style="height: 1.72em; vertical-align: -0.749em;" class="mjx-vsize"></span></span></span></span></span></span></span>次<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{\sqrt{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.533em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.533em; bottom: -1.059em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.084em;" class="mjx-line"></span></span><span style="height: 1.72em; vertical-align: -0.749em;" class="mjx-vsize"></span></span></span></span></span></span></span> = <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{2}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.665em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.441em; vertical-align: -0.47em;" class="mjx-vsize"></span></span></span></span></span></span></span> 。</p><p>最后，我们了解箭头方向的相关性！如果我们说路径 A 振幅指向上（在反射镜发射点），则路径 B 振幅指向下。</p><p>路径 A 光束（向上的箭头）击中半透半反镜的<i>背面</i>（无相移），因此它将一个箭头发射到向上的探测器 1，并将一个箭头反射到向上的探测器 2。</p><p>路径 B 光束（向下的箭头）撞击半反射镜的<i>前部</i>，因此它将一个箭头传输到探测器 2（向下），并将一个箭头反射到探测器 1（探测器 1 发生 -1 的相移并向上）。</p><p>现在我们到达了症结所在。大自然不会给光子贴上标签，也不关心它们的历史。因此，虽然光子的比特采取了具有不同幅度的不同路径，但只有两种可能的<i>最终配置</i>：探测器 1 处有一个光子，或者探测器 2 处有一个光子。如果两条不同的路径导致相同的配置，则计算出该配置的幅度，只需<i>添加贡献路径的幅度</i>即可。</p><p>在检测器 1 中，我们得到一个向上箭头和一个向下箭头。获取结果配置的幅度 |<i>光子进入探测器 1</i> >;，我们将它们加在一起。但由于其中一个是另一个的负值，它们会相互抵消（“破坏性干扰”），并加到 0。</p><p>在检测器 2 中，我们得到两个长度为 1/2 的向上箭头。获取结果配置的幅度 |<i>光子进入探测器 2</i> >;，它们相加（相长干涉），产生最终指向上方的振幅箭头，长度为 1。</p><p>在每个探测器中找到光子的概率是多少？我们对箭头的长度进行平方，在探测器 2 中得到<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="1^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> = 1，在探测器 1 中得到<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="0^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> = 0。所以结果是在探测器 2 中找到光子的可能性是 100%，并且没有探测器 1 中的机会<span class="footnote-reference" role="doc-noteref" id="fnref8lwvfaqtk6f"><sup><a href="#fn8lwvfaqtk6f">。[4]</a></sup></span></p><p>因此，光子已经将自身干涉得无影无踪，就像波一样。然而，无论你做什么，探测器都不会看到光子能量在探测器之间“分裂”，就像粒子一样。 （我们可以用电子等大体积的东西做类似的实验）。为了挽救它必须是其中之一的想法，您可能会提出光子中有秘密指令，告诉它要采取什么行动，而这些指令恰好由于某种原因而最终到达探测器 D1。这可能会遇到如下问题：</p><p>想象一下，如果我们将一个块放入其中一条路径中，并重新计算光子最终到达的位置： </p><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe61bc23-1074-461a-907e-5d21bf7ed880_714x399.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe61bc23-1074-461a-907e-5d21bf7ed880_714x399.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe61bc23-1074-461a-907e-5d21bf7ed880_714x399.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe61bc23-1074-461a-907e-5d21bf7ed880_714x399.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe61bc23-1074-461a-907e-5d21bf7ed880_714x399.png 1456w"><figcaption> “拦截器”场景</figcaption></figure><p>该块切断了路径 A 的光束，但允许路径 B 通过。 Before the block, you would never find a photon in Detector 2, but now it shows up there in a quarter of experiments. （在另外四分之一的实验中，D1将熄灭，在剩下的一半实验中，光子在路径A上被阻挡）</p><p>但是等等，穿过路径 B 的光子<i>从未见过</i>路径 A！<i>未经过的</i>路径中的障碍物影响了另一条路径中光子的行为。您可以更进一步：您可以<a href="https://en.wikipedia.org/wiki/Wheeler%27s_delayed-choice_experiment">在初始分割发生<i>后</i></a>（但在备用路径击中它之前）将此阻止程序放置在路径中，结果将是相同的。只有当光子<i>确实</i>以某种方式在两条路径之间分裂时，这才真正有意义。光子中没有任何秘密信息可以<i>提前</i>知道你是否会在未来未采取的路径上放置一个方块。 <span class="footnote-reference" role="doc-noteref" id="fnref5gh0qkugbtx"><sup><a href="#fn5gh0qkugbtx">[5]</a></sup></span></p><p><strong>两个光子干涉和联合配置</strong></p><p>到目前为止，我们只观察了单个光子。但是，当我们观察不同粒子之间的相互作用时，量子力学的大部分怪异现象就会出现。</p><p>同样，我们将使用半反射镜，但这一次，我们发送<a href="https://en.wikipedia.org/wiki/Hong%E2%80%93Ou%E2%80%93Mandel_effect">两个光子而不是一个</a>。 </p><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ece285c-2e5f-43bd-a377-388348331f39_374x231.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ece285c-2e5f-43bd-a377-388348331f39_374x231.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ece285c-2e5f-43bd-a377-388348331f39_374x231.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ece285c-2e5f-43bd-a377-388348331f39_374x231.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ece285c-2e5f-43bd-a377-388348331f39_374x231.png 1456w"><figcaption>两个光子攻击半透半反镜</figcaption></figure><p>这可能看起来类似于干涉仪示例中的第二个半反射镜。但实际上，额外光子的存在使事情变得相当复杂。在我们的 1 光子示例中，我们采用两种可能配置的叠加：</p><p> | 的叠加<i>路径 A >; 和 | 中的光子</i><i>路径 B 中的光子</i>>;</p><p>两种可能配置的另一种叠加：</p><p> | 的叠加<i>路径 D1 中的光子</i>>; 和 |<i>路径 D2 中的光子</i>>;</p><p>在我们的新案例中，我们将从配置开始：</p><p> |<i>路径 A 中的一个光子和路径 B 中的一个光子</i>>;</p><p>三种可能配置的叠加：</p><p> | 的叠加<i>D1 >; 和 | 中有 2 个光子</i><i>D1 中有 1 个光子，D2 中有另一个光子</i>>; 和 | <i>D2 中有 2 个光子</i>>;</p><p>这意味着您不能完全使用之前的相同规则。我们可以说，每个光子在撞击镜子时都可以透射或反射。有四个路径（我们假设传入的幅度均为 1，并且我们保留只有来自前面的反射才会引起相移的规则）：</p><p>两个光子都被反射：状态为 | <i>D1 中有 1 个光子，D2 中有 1 个光子</i>>;，发生相移，幅度<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-\frac{1}{2}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.665em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.441em; vertical-align: -0.47em;" class="mjx-vsize"></span></span></span></span></span></span></span></p><p>光子 A 被透射，光子 B 被反射：状态为 | <i>D1 >; 中有 2 个光子</i>，发生相移，幅度<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-\frac{1}{\sqrt{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.533em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.533em; bottom: -1.059em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.084em;" class="mjx-line"></span></span><span style="height: 1.72em; vertical-align: -0.749em;" class="mjx-vsize"></span></span></span></span></span></span></span></p><p>光子 A 被反射，光子 B 被透射：状态为 | <i>D2 >; 中有 2 个光子</i>，无相移，幅度<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{\sqrt{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.533em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.533em; bottom: -1.059em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.084em;" class="mjx-line"></span></span><span style="height: 1.72em; vertical-align: -0.749em;" class="mjx-vsize"></span></span></span></span></span></span></span></p><p>两个光子都被传输：状态为 | <i>1 photon in D1, 1 photon in D2</i> >;, no phase shift, amplitude <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{2}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.665em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.441em; vertical-align: -0.47em;" class="mjx-vsize"></span></span></span></span></span></span></span></p><p> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{\sqrt{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.533em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.533em; bottom: -1.059em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span></span></span></span></span></span>的起源<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{\sqrt{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.084em;" class="mjx-line"></span></span><span style="height: 1.72em; vertical-align: -0.749em;" class="mjx-vsize"></span></span></span></span></span></span></span>和<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{2}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.665em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.441em; vertical-align: -0.47em;" class="mjx-vsize"></span></span></span></span></span></span></span>术语有点太复杂，不值得解释，并且来自处理多个光子的数学。 （请参阅<a href="https://iopscience.iop.org/article/10.1088/1361-6633/abcd7a/meta">这篇论文</a>或<a href="https://en.wikipedia.org/wiki/Hong%E2%80%93Ou%E2%80%93Mandel_effect">这篇维基百科文章</a>进行正式处理）。</p><p>如果我们还记得之前的情况，干扰只会发生在多条路径导致<i>相同</i>配置的情况下。这仅适用于路径 1 和 4，它们最终都出现在配置中 | <i>D1 中的光子，D2 中的光子</i>>;。 So we add the amplitudes <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{2}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.665em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.441em; vertical-align: -0.47em;" class="mjx-vsize"></span></span></span></span></span></span></span>和<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-\frac{1}{2}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">-</span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.665em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.441em; vertical-align: -0.47em;" class="mjx-vsize"></span></span></span></span></span></span></span> ，这会增加该状态的 0 振幅（再次相消干涉）。</p><p>对每个振幅进行平方后，我们最终有 50% 的机会在 D1 中找到两个光子，有 50% 的机会在 D2 中找到两个光子，<i>在每个中找到一个光子的机会为 0%</i> 。你要么在 D1 或 D2 中找到 2 个光子，但从未发现它们分裂。 This has been experimentally verified!</p><p>现在停下来思考一下这个问题。两条<i>路径</i>1 和 4 之间存在相消干涉。您无法将其分解为一个部分光子与另一部分光子的干扰（继续尝试）。两个光子的状态是<i>纠缠的</i>。干扰的是涉及光子的两种<i>情况</i>。 “两者都反射”的场景已经撞到了“两者都传输”，什么都没有了。</p><p>但它并不止于两个光子。原则上，系统（可能还有整个宇宙）的每个元素和属性都可以捆绑成一个通用的极高维波函数，它可以代表每个对象的每种可能的属性组合，包括粒子位置等连续属性。系统中所有元素的每种可能的配置都会有一个振幅，我们可以使用<a href="https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation">薛定谔方程</a>来预测这些振幅如何随着时间的推移而演变，薛定谔方程是一个允许我们建立所有化学和材料科学的工具。我在<a href="https://titotal.substack.com/p/bandgaps-brains-and-bioweapons-the">本文</a>中介绍了一些实际应用。</p><p><strong>传感器、塌缩和退相干</strong></p><p>让我们回到干涉仪并进行最后一项测试。进行我们的初始测试，所有光子都位于 D1 中。在其中一条路径旁边添加一个传感器，如果光子已经到附近，它将返回明确的“是”，如果光子没有到达附近，则返回明确的“否”，而不影响光子路径。<i>这</i>肯定不会影响结果吧？ </p><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e86e3d3-04d6-491c-afee-086897a0977d_1019x573.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e86e3d3-04d6-491c-afee-086897a0977d_1019x573.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e86e3d3-04d6-491c-afee-086897a0977d_1019x573.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e86e3d3-04d6-491c-afee-086897a0977d_1019x573.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e86e3d3-04d6-491c-afee-086897a0977d_1019x573.png 1456w"><figcaption>添加传感器S的结果</figcaption></figure><p>尽管根本没有接触光子的路径，但突然间就不会有干扰了，您将在 50% 的时间里看到光子在探测器 1 中，50% 的时间在探测器 2 中。</p><p>一种思考方式是，当路径 B 上的光子部分的概率幅度达到 S 时，“波函数崩溃”。现在，它不是在两条路径之间传播，而是在路径 B 和 S 中 100% 表示“是”，或者在路径 A 和 S 中 100% 表示“否”。如果我们用箭头来思考，其中一个箭头消失了，另一个箭头延伸到长度 1 以进行补偿。现在没有“其他组件”可以反弹，因此每个探测器中没有干扰并且检测率为 50%。请注意，这不需要有意识的观察：我们不需要<i>读取</i>传感器来发生这种变化。</p><p>很多人认为这种<a href="https://en.wikipedia.org/wiki/Wave_function_collapse">坍缩</a>一定是某种虚构的结构，比如<a href="https://en.wikipedia.org/wiki/Centrifugal_force">离心力</a>，因为它的行为方式与其他物理定律（不连续、瞬时、超光速等）极其不相符。</p><p>事实上，我们<i>可以</i>摆脱这种情况下的明显崩溃。思考传感器情况的另一种方式是传感器已经与光子<i>纠缠在一起</i>，现在每条路径产生的配置都是<i>可区分的</i>。回想一下，我说过，如果振幅<i>导致相同的配置，那么</i>振幅就会增加。但如果我们将传感器包含在我们的框架中，我们就会有<i>不同的</i>配置。我们有 ：</p><ol><li> 0.5 长度向上箭头幅度：| <i>D1 和 S 中的光子说是</i>>;</li><li> 0.5 长度向上箭头幅度：| <i>D1 和 S 中的光子说不</i>>;</li><li> 0.5 长度向下箭头幅度：| <i>D2 和 S 中的光子说是</i>>;</li><li> 0.5 长度向上箭头幅度：| <i>D2 和 S 中的光子说不</i>>;</li></ol><p>它们都是不同的配置，因此不会发生振幅增加，因此箭头的方向再次无关紧要。我们得到每个结果的概率为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="0.5^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.5</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> = 25%，如果我们忽略 S，我们将在 D1 中得到 50%，在 D2 中得到 50%，正如预测的那样。这是<a href="https://en.wikipedia.org/wiki/Quantum_decoherence">退相干</a>的基础。实际的理论允许环境的许多小碰撞产生类似的效果。</p><p>因此，我们可以看到，通过考虑光子和传感器的纠缠，我们之前看到的<i>明显</i>塌陷消失了。有些人理论上认为这种情况<i>会一直持续下去</i>：你的测量设备与 S 纠缠在一起，然后<i>你</i>又与测量设备、S 和光子纠缠在一起，所以你最终会得到如下状态的叠加：</p><p>答： | <i>S 表示“是”，设备测量“是”，<strong>您</strong>会在屏幕上看到“是”</i> >;</p><p>乙： | <i>S says No and equipment measures No, and <strong>You</strong> see No on the screen</i> >;</p><p>按照这种思维方式（许多世界中最常见的版本），看到“否”的<strong>你</strong>和看到“是”的<strong>你</strong><i>都存在</i>于不同的世界中，并且都与阅读这篇文章的<strong>你</strong>一样真实。这是一个优雅的理论，但并不完整：我们必须解释处于 A 状态的你有 70% 的概率以及处于 B 状态的你有 30% 的概率<i>意味着</i>什么。 There have been <a href="https://en.wikipedia.org/wiki/Many-worlds_interpretation#Probability_and_the_Born_rule">a lot of attempts to resolve this</a> , but debate is still ongoing as to whether any are likely to be successful.我将在以后的文章中对此进行更多阐述。</p><p>另一方面，如果你拒绝许多世界，你就必须解释为什么纠缠<i>不会</i>一直持续到人类，这<i>也是</i>一个激烈争论的问题。<a href="https://en.wikipedia.org/wiki/Interpretations_of_quantum_mechanics">对量子力学</a>有<i>很多</i>解释，它们都试图在咬住最不令人震惊的哲学子弹的同时复制现实。</p><p> The majority of physicists I know are in the agnostic camp: quantum interpretations may be fun lunchroom conversation, but I already have my hands full with the devilish details of my own problem that is applicable and testable.我将只使用最容易计算的形式主义，并将现实的真实本质留给其他人。</p><h2><strong>第 2 部分：为什么序列中的数学是错误的</strong></h2><p>写这篇文章的原因是 Eliezer Yudkowsky 的一系列非常受欢迎的博客文章（ <a href="https://www.lesswrong.com/s/Kqs6GR7F5xziuSyGZ/p/5vZD32EynD9n94dhr">1、2、3</a> ）涵盖了相同的<a href="https://www.lesswrong.com/s/Kqs6GR7F5xziuSyGZ/p/ybusFwDqiZgQa6NCq">主题</a><a href="https://www.lesswrong.com/s/Kqs6GR7F5xziuSyGZ/p/KbeHkLNY5ETJ3TN3W">，</a>但在我看来，它们把它弄得一团糟。他涵盖了我在这篇文章中讨论的相同主题，但时间更长，犯了很多错误，并且遗漏了重要的上下文。它们很古老，但由于它们是构成理性主义运动基础文本的“序列”的一部分，因此仍然被大量阅读。</p><p>在他的叙述中，尤德科夫斯基介绍了振幅、复数和干涉仪。当他介绍半银镜并进行以下描述时，出现了大部分错误：</p><blockquote><p><i>粗略地说，半银镜法则就是“当光子直线前进时乘以1，当光子以直角转动时乘以i”。这是将“进入的光子”构型的振幅与“直接出来的光子”或“偏转的光子”构型的振幅联系起来的通用规则。</i></p></blockquote><p>请记住，实际的半银规则（对于单个光子）是：向前传输一束光并反射一束光 90 度，并将<i><strong>它们的振幅乘以</strong></i><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{\sqrt{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.533em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.533em; bottom: -1.059em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.084em;" class="mjx-line"></span></span><span style="height: 1.72em; vertical-align: -0.749em;" class="mjx-vsize"></span></span></span></span></span></span></span> 。如果光束从半透半反镜的<i>前面</i>反射，还要将反射光束乘以-1。</p><p>虚构的规则是这样的：向前传输一束光束并将一束光束反射 90 度。如果光束被反射（正面或背面），则将振幅乘以 i。</p><p>到目前为止，大多数批评都是针对 i 而不是 -1 的相移，但实际上这实际上是一个相当小的错误。我很确定常规的半银镜不会这样做，但是如果您仔细设计一个在反射和透射时引起正确相位变化的设备，则在每次反射时引起 i 相移的分束器<a href="https://en.wikipedia.org/wiki/Beam_splitter#Phase_shift">在理论上是可能的</a>。您可以找到大量使用这种类型的分束器来解释实验的教科书和在线解释器。</p><p><i>不可原谅</i>的是未能将幅度缩小<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{\sqrt{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.533em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.533em; bottom: -1.059em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.084em;" class="mjx-line"></span></span><span style="height: 1.72em; vertical-align: -0.749em;" class="mjx-vsize"></span></span></span></span></span></span></span> 。通过忽略这一点，这个虚构的系统违反了每次半反射镜分裂时的能量守恒和概率守恒。</p><p> “纠正”帖子中错误的脚注如下：</p><blockquote><p> <i>[<strong>编者注：</strong>严格来说，标准的半镀银镜会产生“当光子以直角旋转时乘以-1”的规则，而不是“乘以i”。作者所描述的基本场景在物理上并非不可能，其使用并不影响实质性论证。然而，如果物理专业的学生将这里的讨论与马赫-曾德干涉仪的教科书讨论进行比较，他们可能会感到困惑。我们在文本中保留了这种特性，因为它消除了指定镜子的哪一面是半镀银的需要，从而简化了实验。]</i></p></blockquote><p>不幸的是，这<i>也是</i>错误的！首先，它不只是乘以 -1，而是乘以<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-\frac{1}{\sqrt{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.533em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.533em; bottom: -1.059em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.084em;" class="mjx-line"></span></span><span style="height: 1.72em; vertical-align: -0.749em;" class="mjx-vsize"></span></span></span></span></span></span></span> 。其次，它仅在从<i>正面</i>反射时才会这样做，而不是在从背面反射时。如果没有第二部分，你将再次违反能量守恒定律，实验将弹出一个额外的光子。我觉得这个“更正”比原文还糟糕！</p><p>真实的系统和这个虚构的系统之间还有另一个主要区别。为了获得真实系统中振幅的概率，我们只需取振幅的长度并对其进行平方，然后它就可以按原样输出该配置的概率。</p><p>在虚构的系统中，我们也对振幅进行平方，但因为他遗漏了所有缩放因子，所以现在我们有时会得到超过 1 的值。他指出我们必须重新规范化这些值：如果 D1 的幅度平方为 1，并且 D2 的幅度平方为 4，则 D1 发生的概率为 1/5，D2 发生的概率为 4/5。</p><p>我认为 Yudkowsky 可能认为最后的改变将消除跟踪所有 1/√2 内容的需要。这是不正确的，我将展示一些它失败的案例。</p><p>因此，这个虚构的系统<i>接近</i>现实，只是相移的作用不同，并且每个输出幅度的幅度不会减小（违反能量守恒定律）。</p><p> For the <i>specific case</i> of the basic interferometer, this alternate system does gives the same answer as reality.但让我问你一些关于我们实验修改的问题。如果您想检查您的理解情况，请尝试在真实系统中猜测这些问题的答案。您应该拥有解决这些问题所需的一切。</p><p> 1.如果翻转其中一面半透半反镜会发生什么？</p><p> 2.如果把底部的全反射镜换成半反射镜会怎样？</p><p> 3.将阻塞场景中的阻塞器替换为<i>第三个</i>检测器，如下所示。每个探测器中的光子比例是多少？ </p><figure class="image image_resized" style="width:86.54%"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2be0f37-8767-4303-ad87-8a20619be7f9_716x391.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2be0f37-8767-4303-ad87-8a20619be7f9_716x391.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2be0f37-8767-4303-ad87-8a20619be7f9_716x391.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2be0f37-8767-4303-ad87-8a20619be7f9_716x391.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2be0f37-8767-4303-ad87-8a20619be7f9_716x391.png 1456w"><figcaption>带探测器的阻断器</figcaption></figure><p>对于变化 1：翻转半反射镜意味着路径 A 中没有相位变化。结果将是在探测器 2 而不是探测器 1 中发现光子<span class="footnote-reference" role="doc-noteref" id="fnref4jsqychia6i"><sup><a href="#fn4jsqychia6i">[6]</a></sup></span> 。在尤德科夫斯基的形式主义中，两侧是相同的，因此不会有任何改变。这是一个相当小的批评，通过将“半银镜”改为“对称分束器”很容易解决。</p><p>对于改变2：如果将其中一个全反射镜替换为半反射镜。实际上，一部分光子会传输到太空，而另一部分会反射并继续到达探测器装置，两个幅度都进一步减小<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{\sqrt{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.533em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.533em; bottom: -1.059em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.084em;" class="mjx-line"></span></span><span style="height: 1.72em; vertical-align: -0.749em;" class="mjx-vsize"></span></span></span></span></span></span></span>因素。由于这个减少的因素，只会有部分相消干涉：根据我的计算，你会发现光子 72.9% 的时间在 D2 中，2.1% 的时间在 D1 中，25% 的时间在太空中。</p><p>在虚构的系统中，当路径 B 撞击额外的半反射镜时，路径 B 的幅度不会比路径 A 缩小。这意味着前往与路径 A 重新组合的部分将以与原始实验中相同的方式起作用，导致幅度为 1 的探测器 1。传输到太空的部分也将具有幅度 1，因此使用虚构的根据重整化规则，您会在那里看到 50% 的光子，在探测器 1 中看到 50%。</p><p>变化3：当检测器3充当阻挡器时，不会发生干扰，因此我们不必担心任何相移。有<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{\sqrt{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.533em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.533em; bottom: -1.059em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.084em;" class="mjx-line"></span></span><span style="height: 1.72em; vertical-align: -0.749em;" class="mjx-vsize"></span></span></span></span></span></span></span> amplitude going into detector 3, so we square that to get a 50% chance of getting a photon there. Detectors 1 and 2 are symmetrical with amplitude <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{2}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.665em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.441em; vertical-align: -0.47em;" class="mjx-vsize"></span></span></span></span></span></span></span> , so we square that to get a 25% chance of each of them going off.</p><p> In the fictional system, the amplitudes have not been scaled. At D3, the amplitude is i, at D2 the amplitude is i, and at D3 the amplitude is -1. So we get probability 1 for finding the photon in D1, and another probability of 1 to find it in D2, and another probability of 1 to find it in D3. Renormalising, we get the incorrect answer that there is an equal 33% chance of finding the photon in each detector.</p><p> In all three cases, the fictional system provides inaccurate answers to quite simple modifications.</p><p> It&#39;s pretty clear what happened here is that Yudkoswky messed up the math and physics, but didn&#39;t realize it because it gave the right answer, or thought that his “simplifications” wouldn&#39;t affect the results. This is preferable to the alternative, that he knew it was wrong but just didn&#39;t care.</p><p> What about the defense that the fictional system is simpler? I think when it comes to the phase shift of i compared to the phase shift of -1, it&#39;s a matter of taste. I prefer my way because it means you only need to keep track of arrow up and arrow down, rather than rotating by 90 degrees every time, and reduces the need to think about complex numbers.</p><p> On the other side, not including the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{\sqrt{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.084em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.533em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.533em; bottom: -1.059em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.084em;" class="mjx-line"></span></span><span style="height: 1.72em; vertical-align: -0.749em;" class="mjx-vsize"></span></span></span></span></span></span></span> factor does simplify things, but at great cost. Because it means that from the first split onwards, we <i>aren&#39;t talking about amplitudes at all</i> . Amplitudes obey the law of conservation of energy and probability, these fictional numbers do not. And this leads to the false predictions we see earlier. It basically means that the reader that learns these rules can&#39;t make accurate predictions with them. It also makes it harder for them to grasp followup posts on deeper questions of interpretations: the scaling of amplitudes is incredibly important when discussing things like the Born rule.</p><p> The primary sin of these articles is that they introduce just enough math to be confusing and intimidating to the layman, but not enough to be <i>actually correct or useful</i> . This is the worst of both worlds. Learning this fictional system may almost be <i>detrimental</i> for learning the actual reality, if you don&#39;t realize the problems with it.</p><p> The other sin is that a lot of context is left out, so that the layman doesn&#39;t know where to look to get more information. He states that the mirror “multiplies by i”, but if a reader wants to know <i>why</i> this happens, they are in the dark. The word “phase” does not appear once in any of the three articles, despite phase shifts being the <i>main cause</i> of the described effects.</p><p> I&#39;m aware that LessWrong is not meant to be a physics textbook, and that simplification is a necessary part of science communication (I&#39;ve simplified plenty here myself). I really do admire the effort to dive into and communicate how quantum calculations actually operate. But if you&#39;re going to ask people to trust you and to give you their time and attention, you have a responsibility not to tell them the wrong answers. I hope this article goes some way towards rectifying this mistake. </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnvorzv3iwvqp"> <span class="footnote-back-link"><sup><strong><a href="#fnrefvorzv3iwvqp">^</a></strong></sup></span><div class="footnote-content"><p> For the origin of these odd brackets, look up “bra ket notation”, or watch this <a href="https://www.youtube.com/watch?v=ctXDXABJRtg">youtube video</a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fnoatrvo6ex9"> <span class="footnote-back-link"><sup><strong><a href="#fnrefoatrvo6ex9">^</a></strong></sup></span><div class="footnote-content"><p> Technically this would be a <a href="https://en.wikipedia.org/wiki/Wave_packet">wavepacket</a> and I&#39;d have to include spatial information of how it&#39;s spread out, but we simplify this for the sake of clarity.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnqs5wejjs41t"> <span class="footnote-back-link"><sup><strong><a href="#fnrefqs5wejjs41t">^</a></strong></sup></span><div class="footnote-content"><p> You can also get it to work if the difference in path causes theta to go around an entire circle, so the phase shift of the extra distance is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="e^{0i}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span></span></span></span> = 1 and the phase remains unchanged.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn8lwvfaqtk6f"> <span class="footnote-back-link"><sup><strong><a href="#fnref8lwvfaqtk6f">^</a></strong></sup></span><div class="footnote-content"><p> (In reality, you&#39;ll never be this exact with your paths lengths, so you won&#39;t get it down to exactly 0%, but can make it pretty close).</p></div></li><li class="footnote-item" role="doc-endnote" id="fn5gh0qkugbtx"> <span class="footnote-back-link"><sup><strong><a href="#fnref5gh0qkugbtx">^</a></strong></sup></span><div class="footnote-content"><p> Unless you&#39;re a <a href="https://en.wikipedia.org/wiki/Superdeterminism">superdeterminist</a> , but let&#39;s not go down that route.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn4jsqychia6i"> <span class="footnote-back-link"><sup><strong><a href="#fnref4jsqychia6i">^</a></strong></sup></span><div class="footnote-content"><p> Actually, this is slightly more complicated if you take into account the thickness of glass. In this case one of the paths would spend more time in the glass of the mirrors of the mirror than the other one, so you&#39;d get additional phase shifts depending on glass thickness which means the result could be anything. This isn&#39;t the case in the regular scenario because it&#39;s symmetrical: both paths spend equal time inside the glass. See <a href="https://www.cs.princeton.edu/courses/archive/fall06/cos576/papers/zetie_et_al_mach_zehnder00.pdf">here</a> for a more in depth explanation.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/PjEgxtzWMbonKeTbw/a-new-intro-to-quantum-physics-with-the-math-fixed#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/PjEgxtzWMbonKeTbw/a-new-intro-to-quantum-physics-with-the-math-fixed<guid ispermalink="false"> PjEgxtzWMbonKeTbw</guid><dc:creator><![CDATA[titotal]]></dc:creator><pubDate> Sun, 29 Oct 2023 15:11:29 GMT</pubDate></item><item><title><![CDATA[My idea of sacredness, divinity, and religion]]></title><description><![CDATA[Published on October 29, 2023 12:50 PM GMT<br/><br/><p> Here&#39;s a conception that I have about sacredness, divinity, and religion.</p><p> There&#39;s a sense in which love and friendship didn&#39;t have to exist.</p><p> If you look at the animal kingdom, you see all kinds of solitary species, animals that only come together for mating. Members of social species – such as humans – have companionship and cooperation, but many species do quite well without being social.</p><p> In theory, you could imagine a world with no social species at all.</p><p> In theory, you could imagine a species of intelligent humanoids akin to Tolkien&#39;s orcs. Looking out purely for themselves, willing to kill anyone else if they got away with it and it benefited them.</p><p> And then in another sense, some versions of love and friendship do have to exist.</p><p> Social species evolved for a reason: cooperation does pay off. Individuals who band together and help each other out even when that requires making the occasional personal sacrifice actually do have greater success.</p><p> If no social species existed yet, but the conditions were right for them to evolve, then given enough time it would be inevitable for them to evolve.</p><p> Think about that for a second. It would be <i>inevitable</i> for them to evolve.为什么？ Because of how the laws of natural selection and game theory work. There&#39;s a path from pure selfishness to cooperation, and cooperation is beneficial.</p><p> It&#39;s not a given that any single species that evolved sociality would be successful – they could still get unlucky and be wiped out by something completely different. Sociality won&#39;t help you if the only valley you live in gets covered by a volcanic eruption.</p><p> But sociality would still <i>keep</i> evolving, over and over again, until some social species would manage to maintain themselves.</p><p> There&#39;s a sense in which the laws of natural selection and game theory are deeper than the laws of physics. Cooperation would likely still be beneficial in universes with five physical dimensions, or where life was based on elements very different from carbon, or ones where D&amp;D-style magic was real. Assuming that something like life could evolve at all, cooperation would be beneficial in a broad range of possible universes.</p><p> And where do the laws of natural selection and game theory come from? At their heart, they are mathematical laws, inevitably following some given axioms. There are universes where those axioms wouldn&#39;t necessarily be true – ones where no organisms could exhibit heritable variation, for instance. In those worlds, nothing could evolve.</p><p> But if the “structure of reality” refers to our laws of physics, then the laws that create companionship somehow go even <i>deeper</i> than the structure of reality. Across a vast range of possible realities, something akin to companionship must come into existence. Somehow, this is just an intrinsic fact about something that governs everything that could ever exist.</p><p> In Egyptian mythology, the first god Atum created himself out of the waters of chaos. Likewise, the structure-of-that-deeper-than-reality is such that across many many possible universes, cooperation and companionship will create themselves out of the waters of selfishness.</p><p> Love doesn&#39;t always win. There are situations where loyalty, cooperation, and love win, and there are situations where disloyalty, selfishness, and hatred win. If that wasn&#39;t the case, humans wouldn&#39;t be so clearly capable of both.</p><p> It&#39;s possible for people and cultures to settle into stable equilibria where trust and happiness dominate and become increasingly beneficial for everyone, but also for them to settle into stable equilibria where mistrust and misery dominate, or anything in between.</p><p> When I look around in my room, it&#39;s filled with the fruits of cooperation. For one, the very fact that I even live in a building that someone else built, surrounded by roads that someone else built, filled with everything from books to sophisticated electronics to everything else that I did not personally create. And yes, some amount of coercion and exploitative labor practices no doubt played a role in the creation of some of that, but it&#39;s still our nature as a social species that allows us to have any amount of specialization and the creation of such things in the first place.</p><p> To me, if anything deserves the label “divine”, it&#39;s this force of cooperation that transcends universes. Everywhere I look, I am surrounded by artifacts that are of divine origin. Even discarded food packaging is a divine artifact.</p><p> And I have friends and I have people who I love, I have <i>happiness</i> . I live in a local pocket of the universe where even my interactions with complete strangers – such as the salespeople at stores – tend to be friendly and warm in tone, or at least politely neutral.</p><p> All that because of a cosmic force of love and cooperation which happens to be predominant where I live, whose energy and nature shapes much of my psyche – even as I <i>also</i> carry the energy and nature of unhealthy selfishness and destructiveness in the shape of much of my psyche.</p><p> If there <a href="https://arxiv.org/pdf/astro-ph/0302131.pdf">is a multiverse</a> , if there are universes beyond our own – then those two forces are locked in an eternal struggle across all the universes that are capable of supporting something like intelligent life. The dance of good and evil within me, in some form mirroring the dance of good and evil across the entire multiverse.</p><p> To get even more mystical about it – to me, this doesn&#39;t feel like just an abstraction. I&#39;ve experienced altered states of consciousness – induced by things like meditation, therapy and ritual – where I have <i>felt</i> something like an energy pattern of pure love, confidence and okayness arising through my body, experienced the term “uplifting” as a literal force pulling me up on my feet.</p><p> There is a <i>feel</i> to all that, a particular kind of – for a lack of a better word – “energy”, that feels different from the kind of “energy” that comes up when I am being insecure, or selfish in a bad way, or subtly manipulative. Now being able to notice the difference doesn&#39;t always mean that I&#39;d be capable of acting any differently – I can recognize that the energy of what I&#39;m doing doesn&#39;t feel good, and still end up acting according to it since it&#39;s the only energy I have available at the moment.</p><p> But feeling that energy does at least let me know that I could be doing better. It does let me know that my actions are not in the service of the kind of power I would like to be serving.</p><p> For that&#39;s what it feels like when I am best able to tap into it. Like I am in the service of a greater power, that is by its nature impersonal but takes a human form by channeling itself through me as one of its many vessels.</p><p> This has a religious and mystic flavor to it, but not the kind of religious that would require belief in anything that would be called supernatural or contradictory to science. It is the kind of religious and mystic practice that <a href="https://www.lesswrong.com/users/eric-raymond?mention=user">@Eric Raymond</a> describes in his essay <a href="http://www.catb.org/~esr/writings/dancing.html">Dancing with the Gods</a> : one grounded in experience, not belief. As Raymond puts it, we do not need to “believe” without evidence that the sun rises in the morning; we can experience it ourselves.</p><p> In the same way, I do not need to “believe” in a god of which I have no direct experience; I can feel it in myself and my body, see what it does to my behavior and state of mind, and call the thing-which-is-all-that a god or divine power that I would like to see myself in the service of.</p><br/><br/> <a href="https://www.lesswrong.com/posts/FyeDR4Wy7GGGd7iBa/my-idea-of-sacredness-divinity-and-religion#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/FyeDR4Wy7GGGd7iBa/my-idea-of-sacredness-divinity-and-religion<guid ispermalink="false"> FyeDR4Wy7GGGd7iBa</guid><dc:creator><![CDATA[Kaj_Sotala]]></dc:creator><pubDate> Sun, 29 Oct 2023 12:50:09 GMT</pubDate> </item><item><title><![CDATA[What's up with "Responsible Scaling Policies"?]]></title><description><![CDATA[Published on October 29, 2023 4:17 AM GMT<br/><br/><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 17:36:08 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 17:36:08 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>我有兴趣谈论 RSP 是好是坏。我对此感到非常困惑，并且很乐意与某人深入探讨这一问题。</p><p>我目前对RSP的感受大致如下：</p><p>我对人工智能 X 风险的术语被重新定义感到有点高度警惕和有点偏执，因为这感觉就像是“人工智能对齐”中发生过很多次的事情，而且当你试图影响大型官僚机构（另见奥威尔关于政府行为的所有常见内容）。我对 RSP 的担忧很大一部分是对“负责任的扩展政策”一词的具体担忧。</p><p>我还觉得存在一种脱节，有点莫特和贝利的感觉，我们有一个 RSP 的真实实例，以 Anthropic RSP 的形式，然后来自 ARC Evals 的一些人我觉得更像是 RSP 的某种柏拉图式理想的模型，我觉得它们被混为一谈了。就像，我同意有些类似于 RSP 的东西可能会很棒，但我觉得特别是 Anthropic RSP 并没有真正的牙齿，所以有点扁平，就像人们想象的那样帮助应对风险。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 17:41:38 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 17:41:38 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p><strong>免责声明</strong>：我主要不从事宣传或政策工作，如果我在这些领域工作更多，我对这些主题的看法可能会大幅更新。也就是说，我工作的很大一部分<i>确实</i>涉及思考诸如“好的安全论点是什么样的？”之类的问题。以及“根据当前的安全技术状况，我们可以采取哪些措施来评估和减轻人工智能风险？”。 <i>（这是在编辑时添加的。）</i></p><hr><p>谈论可能有趣的事情：</p><ul><li>反收购/安全倡导应该做什么？</li><li>当前的技术实际上可以在多大程度上降低风险？这是症结所在吗？</li><li>目前避免收购的干预措施是什么样的？</li><li>定时暂停重要吗？</li><li>硬核实际上良好的长期暂停会是什么样子等？</li><li>实验室是否真的会跟进等等？</li><li>收购担忧与滥用行为混在一起是不是很糟糕？也许并没有那么糟糕？就像我实际上并不很担心 ASL-3 等。或者也许这很好，因为一些对策转移了？</li><li>未来会有好的RSP吗？ （就像 Anthropic 的 RSP 基本上是关于最重要问题的 RSP IOU。我认为这可能还可以。） </li></ul></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 17:49:56 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 17:49:56 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我对 RSP 的基本看法：</p><ul><li>我同意<a href="https://www.lesswrong.com/posts/dxgEaDrEBkkE96CXr/thoughts-on-responsible-scaling-policies-and-regulation.">https://www.lesswrong.com/posts/dxgEaDrEBkkE96CXr/thoughts-on-responsible-scaling-policies-and-regulation 中的大部分内容。</a>例外情况：<ul><li>我对风险的基线猜测比 Paul 的要高一些，因此我认为 RSP 不会让您的风险降至 1%</li><li>我不太看好将风险降低 10 倍，但也许 5 倍似乎相当可行？我不知道</li><li>我认为未来 5 年内不太可能出现基于机械互助之类的良好肯定安全案例，因此此类要求似乎接近事实上的禁令。 （我不确定保罗是否不同意我的观点，但这似乎是一件值得注意的重要事情。）</li></ul></li><li>我同意这个词看起来很糟糕。感觉可能是一个错误。我还发现 OpenAI 使用不同的术语（RDP）很有趣</li><li>我并不担心未知的风险，但我确实认为“人工智能扰乱你的评估”是一个大问题。我认为可以通过检查人工智能是否能够干扰你的评估来解决这个问题（这可能比仅仅避免它们干扰你的评估更容易）。</li></ul></section><h2> RSP 的命名和背后的意图</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 17:53:11 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 17:53:11 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我认为如果 ARC 说这样的话会更好：“实验室应该制定扩大规模的政策：扩展政策 (SP)。我们希望这些政策实际上是安全的，我们很乐意就 SP 的责任进行咨询并降低风险”。<br><br>我还更喜欢“条件安全改进政策”或类似名称。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 17:56:35 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 17:56:35 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>我确实觉得“负责任的扩展政策”这个术语显然引用了一些我认为不正确的事情：</p><ul><li> “扩展”的速度是负责任地使用人工智能的首要因素</li><li>显然可以负责任地扩展（否则政策会管辖什么）</li><li>人工智能研究组织的默认轨迹应该是继续扩大规模</li></ul><p><a href="https://twitter.com/jamespayor/status/1715728849214857444">推特上的</a>James Payor 有一种类似的观点，引起了我的共鸣：</p><blockquote><p>我在这里补充一点，“AGI 扩展政策”将是一个比“负责任的扩展政策”更诚实的名字。</p><p> “RSP”这个名字隐含地表明（a）没有理由停下来； (b) 可以负责任地扩大规模； (c) 政策本体不可修改； ETC。</p><p> ……这些感觉像是可怕的假设，似乎是故意让协调人工智能停止变得更加困难。我确实喜欢这些内容，但我对这些东西的存在和相关的影响感到非常不满。</p></blockquote><p>我也对 RSP 的定义应该是什么感到有点困惑。 ARC Evals 帖子只是说：</p><blockquote><p> RSP 指定了人工智能开发人员准备使用当前的保护措施安全处理什么级别的人工智能功能，以及在保护措施改善之前继续部署人工智能系统和/或扩大人工智能功能过于危险的条件。</p></blockquote><p>但我认为这并不是一个充分的定义。当然，有很多符合这个定义的东西被称为 RSP 会很奇怪。就像，缩放定律论文试图回答这两个问题，但显然不符合 RSP 的资格。</p><p>上面的基本概念结构也让人感到困惑。例如，RSP 如何指定开发人员准备处理安全问题的 AI 功能级别？现实为你指明了这一点。也许它应该说“它指定了人工智能开发人员认为他们可以处理的人工智能能力水平”？</p><p>下一句话也是如此。 RSP 如何指定在什么情况下继续部署人工智能系统会过于危险？再说一次，现实是你唯一的仲裁者。 RSP 可以指定人工智能开发人员认为太危险的条件，但这在政策中似乎也很奇怪，因为随着时间的推移，这种情况可能会发生很大的变化。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:01:07 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:01:07 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我同意“负责任的扩展政策”一词会引发虚假内容。我想这对我来说似乎并没有那么糟糕？也许我低估了名字的重要性。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:07:28 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:07:28 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><blockquote><p>我在这个领域感到有点困惑的另一件事是“RSP 的定义在哪里？”。 ARC Evals 帖子说：<br><br> >; RSP 指定人工智能开发人员准备使用当前的保护措施安全处理什么级别的人工智能功能，以及在保护措施改善之前继续部署人工智能系统和/或扩大人工智能功能过于危险的条件。</p></blockquote><p>是的，如果加上“claim”这个词，这一段似乎会更好。就像“RSP 指定了人工智能开发人员声称他们准备好使用当前的保护措施安全处理的人工智能能力水平，以及他们认为继续部署人工智能系统和/或扩大人工智能规模太危险的条件直到保护措施得到改善为止。”<br><br>希望是这样的：</p><ul><li> AI 开发人员制定了 RSP，其中提出了一些隐式或显式的声明。</li><li>人们可以争辩说，既然有明确的政策可以争论，那么这对于安全来说是不够的。 </li></ul></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:08:44 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:08:44 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><blockquote><p>我同意“负责任的扩展政策”一词会引发虚假内容。我想这对我来说似乎并没有那么糟糕？</p></blockquote><p>是的，我确实觉得我试图判断人工智能监管和人工智能联盟中引入的概念和抽象的主要维度是这些概念是否调用真实的事物并在其关节处雕刻现实。</p><p>我同意我可以尝试做一件更天真的后果论的事情，就像“是的，好吧，让我们试着向前推进当人类遇到这些想法时，当它看到这些特定的人说这些时，人类会做什么”话”，但即便如此，我还是觉得 RSP 看起来不太好，因为在那个水平上，我主要希望他们会说“哦，这些人说他们正在负责任”或类似的话。</p><p>需要明确的是，我喜欢 Anthropic RSP 和 ARC Evals RSP 帖子所指出的一点基本上是一系列运作良好的有条件承诺。 RSP 的一种方式是基本上成为人工智能实验室和公众之间的合同，具体规定“当 X 发生时，我们承诺做 Y”，其中 X 是一些能力阈值，Y 是一些暂停承诺，也许还有一些结束条件。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:08:58 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:08:58 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>具体来说，您认为 ARC evals 和 Anthropic 应该做什么？就像他们应该使用不同的术语吗？ </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:11:23 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:11:23 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>就像，比起 RSP，我更喜欢对 Dario 和 Daniella 进行一系列坦率的采访，其中有人会说“所以你认为 AGI 有很大的机会杀死所有人，那么你为什么要建造它呢？”。一般来说，创建更高带宽的通道，人们可以用它来了解领先人工智能实验室的人们对人工智能风险的看法，以及何时值得这样做。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:11:26 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:11:26 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>对我来说，制定某种书面并维护的政策似乎非常重要，这些政策涉及“我们何时停止增加模型的功率”以及“我们将针对不同的功率级别采取哪些安全干预措施”。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:12:00 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:12:00 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>TBC，坦诚采访的记录似乎也不错。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:14:11 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:14:11 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我想要政策的部分原因是，这使得组织内部的人员更容易举报或反对内部的事情。<br><br>我还认为，如果更多的人更具体地思考当前的计划是什么样子，那就更好了。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:14:29 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:14:29 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><blockquote><p>对我来说，制定某种书面并维护的政策似乎非常重要，这些政策涉及“我们何时停止增加模型的功率”以及“我们将针对不同的功率级别采取哪些安全干预措施”。</p></blockquote><p>是的，明确地说，我认为这也很棒。我确实对“人工智能能力公司应该有一份概述其扩展和安全计划的最新文件”感到非常满意。我确实觉得，在有这种计划的世界里，很多对话显然会进展得更好。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:18:06 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:18:06 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>似乎我们对于我们希望实验室向世界提供的实际工件有轻微但不是很大的分歧，以解释他们的计划？<br><br>我一般认为，在目前的利润范围内，更诚实、清晰的沟通和针对所有事情的具体计划似乎相当不错（例如，RSP、 <a href="https://www.lesswrong.com/posts/6HEYbsqk35butCYTe/labs-should-be-explicit-about-why-they-are-building-agi">关于风险的明确声明、对实验室为什么要做他们知道有风险的事情的明确解释</a>、与怀疑论者的详细讨论等）。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:21:16 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:21:16 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>我确实觉得两种不同类型的文物之间存在着巨大的紧张关系：</p><ol><li>一份应该准确总结组织在不同情况下期望做出的决策的文件</li><li>一份旨在约束组织在某些情况下做出某些决定的文件</li></ol><p>就像，我目前得到的感觉是，RSP 是一种“不后悔”的东西。你不能发布 RSP 说“是的，我们不打算扩大规模”，然后又说“哎呀，我改变主意了，我们实际上要全力以赴”。</p><p>我的猜测是，这就是为什么我希望组织不会真正致力于其 RSP 中的任何实际内容，并且他们不会真正了解组织领导层认为的权衡是什么。就像，这就是为什么 Anthropic RSP 有一个很大的 IOU，实际上最关键的决定应该在其中。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:21:23 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:21:23 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>哦，明白了，约束性政策和解释之间存在一些差异。<br><br>我同意 RSP 使得以降低安全性的方式改变事物的成本相对更高。从我的角度来看，这似乎主要是一个好处？ RSP 似乎也可以有一些类似“我们对应该做什么的初步最佳猜测”的部分和一些类似“我们当前政策”的部分。 （例如，Anthropic RSP 对 ASL-4 有一个初步猜测，但在其他地方有更可靠的政策。） </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:22:45 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:22:45 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>也许一个有趣的问题是“Anthropic 在触发 ASL-3 之前充实 ASL-4 评估和安全干预措施的可能性有多大”？ （这将还清欠条。）<br><br>或者在接下来的两年内充实它，条件是 ASL-3 在这两年内没有被触发。<br><br>我对这种情况的发生持适度乐观的态度。 （也许 60% 是基于 ASL-4 评估和 2 年内一些听起来对我来说特定的 ASL-4 干预措施，条件是没有 ASL-3） </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:23:34 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:23:34 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>就像，这是“RSP”的替代方案。称其为“有条件暂停承诺”（CPC，如果您喜欢缩写词）。</p><p>基本上，我们只是要求 AGI 公司告诉我们在什么条件下他们将停止扩展或停止尝试开发 AGI。然后还有一些恢复的条件。然后我们就可以批评这些。</p><p>这似乎是一个更清晰的抽象概念，对于该事物是否试图成为组织未来决策的准确地图，或者它应该在多大程度上认真地承诺一个组织，或者整个事物是否“负责任”，没有那么哲学上的固执己见。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:30:37 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:30:37 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><blockquote><p>就像，这是“RSP”的替代方案。称其为“有条件暂停承诺”（CPC，如果您喜欢缩写词）。</p></blockquote><p>我同意 CPC 是一个更好的术语和概念。我认为这基本上就是 RSP 想要实现的目标？<br><br>但似乎值得注意的是，对策是整个局面的关键部分。就像你暂停的条件可能取决于你到目前为止所实施的内容等。我觉得 CPC 不会自然地引起对策部分，但总的来说，它似乎是一个更好的术语。 （我们显然可以添加这一点，但这个名字很糟糕：条件暂停承诺，包括对策 CPCC） </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:33:43 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:33:43 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><blockquote><p>也许一个有趣的问题是“在触发 ASL-3 之前，人类有多大可能充实 ASL-4 评估和安全干预措施”？ （这将还清欠条。）</p><p> （或者在未来 2 年内充实它，条件是不触发 ASL-3。）<br><br>我对这种情况的发生持适度乐观的态度。 （也许 60% 是基于 ASL-4 评估和 2 年内一些听起来对我来说特定的 ASL-4 干预措施，条件是没有 ASL-3）</p></blockquote><p>是的，我同意这是一个有趣的问题，并且我大致同意你在这里的可能性。</p><p>我确实认为他们不跟进的世界真的很糟糕。我真的不喜欢 40% 的世界，事实证明 RSP 是那种导致一群人摆脱 Anthropic 构建真正危险的人工智能的事情，并且是那种导致大量的事情人工智能安全领域的领导者来支持他们，但事情却从未真正实现。</p><p>就像，我觉得这不是我第一次从这里的一些人性公告中感受到不好的氛围。就像他们也有<a href="https://www.anthropic.com/index/the-long-term-benefit-trust">长期利益信托</a>一样，它看起来确实像是那种应该确保人类独立于利润激励的东西，但是就像，埋在中间随机段落末尾的一句话中是爆炸性的事实是，只要绝大多数股东不同意，治理委员会实际上就没有能力阻止 Anthropic，而且他们没有具体说明绝大多数股东的实际具体数字，然后我觉得整件事只是对我来说很平淡。</p><p>就像，如果没有给我具体的数字，这个承诺就没有多大作用。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:34:14 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:34:14 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我非常担心不稳定或糟糕的 RSP 以及 RSP IOU，但这种情况永远不会发生。我觉得 OpenAI 或 GDM 的风险比 Anthropic 高得多。<br><br>我们将看看 OpenAI 的第一个 RDP 是什么样子的。我们将看看 GDM 是否会采取任何官方行动。</p></section><h2>认可和未来轨迹</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:37:35 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:37:35 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><blockquote><p>我确实认为他们不跟进的世界真的很糟糕。就像我真的不喜欢 40% 的世界，事实证明 RSP 是那种让一群人摆脱 Anthropic 构建真正危险的人工智能的事情，也是那种导致大量人死亡的事情。人工智能安全领域的领导者来支持他们，然后事情就永远不会真正实现。</p></blockquote><p>我认为人们应该继续向他们施加压力，直到他们更加充实 ASL-4 评估和承诺。<br><br>我想我觉得我们可以在某种程度上拒绝完全认可，这可能会降低这种结果的风险。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:40:04 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:40:04 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我觉得我想要倡导的事情是这样的：</p><ul><li>来自人类的 ASL-4 承诺和评估（可以是初步的等）</li><li>一些 RSP 类似于其他实验室的东西。即使我认为这项政策非常不安全，那仍然是进步，那么我们至少可以对这项具体政策的质量进行争论。</li><li>对 RSP 之类的其他改进。 </li></ul></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:40:13 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:40:13 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>我确实认为我非常担心“AGI 公司占领人工智能安全领域”领域的很多事情。例如，大多数从事人工智能安全工作的人已经受雇于 AGI 公司。我觉得在我真正撤回认可的能力基本上完全被削弱之前，我没有多少年的时间继续维持现状了。</p><p>因此，我对人择 RSP 的一系列反应是担心，如果我现在不反对，当更清楚这件事并不严重时，该领域将无法在以后反对（在这个世界中是这样），因为到那时，很多人的职业生涯、声誉和贡献能力都直接取决于与能力公司的相处，因此某种形式的撤回背书的希望不大。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:42:58 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:42:58 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我想要的密切相关的事情是：在人工智能实验室工作的人应该仔细思考并写下他们会大声辞职的条件（这可以私下完成，但也许应该在志同道合的员工之间共享以获得常识）。这样，人们就有希望避免“温水煮青蛙”。<br><br>我担心人们可能会因为诸如“我真的不想戒烟，因为那样我的影响力就会消失，我应该尝试影响事情变得更好”这样的想法而在真正应该戒烟的时候避免戒烟。此外，XYZ 承诺如果我稍等一下，那东西会更好。”就像在各个人工智能实验室里可能有一些非常善于操纵的人一样。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:44:32 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:44:32 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><blockquote><p>在人工智能实验室工作的人应该思考并写下他们会大声辞职的条件（这可以私下进行，但也许应该在志同道合的员工之间分享，以获得常识）。这样，人们就有希望避免“温水煮青蛙”。</p></blockquote><p>是的，我确实认为这也很棒。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:46:36 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:46:36 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我也同意“令人恐惧的是，大量的安全人员在实验室工作，这种趋势似乎可能会持续下去”。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:47:33 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:47:33 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><blockquote><p>因此，我对人择 RSP 的一系列反应是担心，如果我现在不反对，当更清楚这件事并不严重时，该领域将无法在以后反对（在这个世界中是这样），因为到那时，很多人的职业生涯、声誉和贡献能力都直接取决于与能力公司的相处，因此某种形式的撤回背书的希望不大。</p></blockquote><p>您为什么不认为您现在可以拒绝认可并说“我正在等待 ASL-4 标准和评估”？ （我不知道这是否重要。） </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:49:00 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:49:00 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>好吧，我可以，但我预计在接下来的几年里，我的观点在当前默认的社会轨迹上将不再有太大的影响力。就像，我可以拒绝认可，但我希望认可的重要性会转向那些不拒绝认可的人。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:50:28 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:50:28 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>好的了解了。我想我确实预计随着时间的推移，你可能会因为各种原因失去影响力。我不确定你应该对此做什么。</p></section><h2>您能在多大程度上判断给定模型是否存在存在危险？ </h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:51:11 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:51:11 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>我确实想稍微回顾一下，谈谈我不断想到的 RSP 的另一个方面。我对此没有很好的把握，但也许描述它的最好方式就是“伙计，RSP 确实让听起来我们对 AGI 何时变得危险有很好的把握”之类的。</p><p>比如，我对假设的“有条件暂停承诺”和 RSP 的担忧是，如果某些 AGI 公司善意地遵守了你给他们的一些随机安全基准，那么你最终会陷入这样一种状态：你承诺允许某些 AGI 公司扩大规模。现实情况是，识别一个系统是否安全，或者是否（例如）具有欺骗性地对齐，是极其困难的，而且我们在这个问题上并没有太多的吸引力，所以我并不真正期望这一点实际上，我们会对安全基准提出任何很好的建议，我们相信这些建议可以承受数十亿至数万亿美元的经济压力和更加智能的人工智能系统。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:55:21 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:55:21 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><blockquote><p>我确实想稍微回顾一下，谈谈我不断想到的 RSP 的另一个方面。我对此没有很好的把握，但也许描述它的最好方式就是“伙计，RSP 确实让听起来我们对 AGI 何时变得危险有很好的把握”之类的。</p></blockquote><p><br>我认为我们确实有一个合理的方法来了解如何知道给定模型的给定部署是否存在危险（以及如何运行此类评估而不使评估本身太危险而无法运行）。<br><br>我对如何在开源模型安全的情况下进行此类评估不太有信心，因为脚手架或微调之类的事情可能会进展并使这些开源模型变得危险。</p><p>我对此的信心程度并不是压倒性的，但我认为我们可以评估厄运何时开始 >;1%，而无需极其保守。也许 0.1% 更难。</p><p>我的意思是“如果你继续将 GPT 缩放 0.25 GPT，你能否进行评估，使得当评估表明危险时，厄运小于 1%”。</p><p>我认为这可能很好地转移到其他基于机器学习的方法。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 18:57:56 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 18:57:56 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>呵呵，这个我有点惊讶。我相信你可以使用“随机采样”系统来做到这一点，但我不认为你可以使用对抗性选择的系统来做到这一点。就像，我同意你可能可以粗略地确定计算和资源的规模（假设没有巨大的算法突破和 RSI 以及一堆其他东西），其中事情变得危险，但是，RSP 的全部意义在于然后拥有AGI 公司试图超越你设定的一些基准，这些基准是他们需要做什么才能走得更远，而这对我来说似乎很难。</p><p> （旁注：这反映了我现在经常围绕人工智能对齐研究进行的一般类型的对话，其中有很多可怕的恶魔、可解释性和评估工作，其目标是确定人工智能是否未对齐，并且我通常的回答是“好吧，我非常有信心在未来几年内你会得到大量证据表明人工智能系统与你不一致。我的主要问题是，一旦你确定一个系统不符合你的要求，你实际上会做什么或者以这种方式危险”，然后令人惊讶的是人们经常没有真正的答案） </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 18:58:28 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 18:58:28 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>哦，好吧，我同意何时前进的基准非常棘手。</p><p>我的主张更像是“相当好的 ASL-3 和 ASL-4 评估应该是可能的”（包括它们对欺骗性对齐的 AI 系统可能试图对这些评估进行沙袋的可能性具有鲁棒性） </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 19:03:56 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 19:03:56 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>ASL-3 和 ASL-4 的定义是什么？ </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:06:07 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:06:07 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我大致认为：<br><br> ASL-3：从误用的角度来看可能是危险的，可能不是自动危险的（>;=ASL-3 的评估是根据 ARA（自主复制）或严重误用风险进行操作的）<br><br> ASL-4：可以认真地进行 ARA（自主复制），并且可能有逃跑或其他严重问题的风险。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 19:07:34 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 19:07:34 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><blockquote><p>我的主张更像是“相当好的 ASL-3 和 ASL-4 评估应该是可能的”</p></blockquote><p> “评估”指的是“评估我们何时应该将人工智能系统分类为 ASL-3、ASL-4 甚至更高”？</p><p>或者您的意思是，我们也许能够进行评估，即使花费数十亿美元来匹配该评估，评估也会告诉我们给定的 ASL-3 或 ASL-4 系统是否可以安全地更广泛地部署？ （例如，可能为 ASL-3 开源，或者为 ASL-4 部署） </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:08:02 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:08:02 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我说的是用于分类和排除 >;=ASL-4 的评估，而不是用于指示此类系统安全的评估。<br><br>我也并不是说这些评估对于沉重的优化压力一定是稳健的，从而使人工智能在这个评估中显得愚蠢而聪明。<br><br>我没有想太多；这对我来说确实是一个重大问题。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:08:55 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:08:55 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>我认为我们应该讨论“实验室将为 ASL-4+ 模型提出哪些安全论据”？ </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 19:09:21 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 19:09:21 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>“安全论点”指的是“相关模型可以安全开发/使用/部署/分发的论点？” </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:09:30 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:09:30 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>是的，受某些协议的约束，例如可能限制使用。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 19:14:50 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 19:14:50 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>是的，看起来不错。这看起来确实非常重要，作为一个至少现在对这个问题的思考比我期望实验室思考的要多得多的人，我的答案肯定是“伙计，我不知道吗”。</p><p>需要明确的是，显然有些训练设置看起来比其他训练设置更危险，但我真的不知道在安全争论的情况下如何考虑这一点，即使如此，我也感到非常困惑。</p><p>举个例子，我的猜测是，系统中的大部分计算都花在了在奖励长期规划和代理资源获取的环境中进行强化学习训练（例如，许多视频游戏或外交或各种长期模拟）。目标）确实看起来更危险。</p><p>但我想我只有 75% 的概率相信这一点？如果最终我开始相信，对于一个系统来说，最终是否危险最重要的只是计算量和投入其中的数据的丰富性，以及所有的论点，我真的不会感到惊讶。工具收敛已经完全适用于大型语言模型，可能会在上面撒上一点 RLHF，在这种情况下，在丰富的环境中通过强化学习训练的系统实际上可能更安全，因为大量计算的使用效率要低得多，并且您可能更能够引出长期规划并利用它来做有用的事情。</p><p>就像，我没有太多的动力来进一步减少概率分布，除了“只是做更多的人工智能对齐研究，深入研究当前模型，认真思考，写很多博客文章， ETC。”​​。因此，考虑到我们目前的理解水平，我很难想象 AGI 公司实际上会给我一个安全论证，对我来说有意义地改变概率质量。</p></section><h2>通过“控制”与“缺乏倾向”进行防御</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:21:30 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:21:30 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>这是我进行安全论证的基本状态。<br><br>我认为安全论点可能有两条（部分重叠的）“防线”：</p><ul><li><strong>控制</strong>：鉴于我们的对策，人工智能<i>无法</i>做严重危险的事情（除非先被抓住）。</li><li><strong>倾向</strong>：人工智能不太可能<i>尝试</i>做严重危险的事情。</li></ul><p>我对当前科学的安全有用性权衡的总体看法是：</p><ul><li>我们的技术还远远不能自信地评估强大的人工智能系统的倾向。</li><li>控制可能可以评估并确保<i>早期变革性人工智能</i>（例如可以将人类进行机器学习研发速度加快 30 倍的模型）</li><li>我们至少可以使用<a href="https://www.alignmentforum.org/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1#The_Case_against_Model_Organisms_">模型生物</a>和对抗性评估之类的东西来测试一些倾向（试图产生人工智能在其上做一些非常糟糕的事情的合成输入）。</li><li>就像我认为“我们努力以对抗性方式评估该模型，但它没有做任何非常可疑的事情”是不平凡的证据，尽管并不令人惊讶。</li><li>我认为“我们试图创造欺骗性的排列模型生物体，但我们最好的模型生物体相当弱”也是一些证据。</li><li>我认为我们有大约 70% 的机会能够为<i>早期变革性 AI</i>建立良好的控制参数，从而将风险降低约 3-5 倍，同时使模型的有用性稍微降低（例如，有用性降低 2 倍）</li><li>显然，控制无法扩展。 （因此，随着规模的扩大，安全性和实用性的权衡会变得更糟）</li><li>评估控制的方法并非平凡且复杂。我不知道如何以无法玩弄的方式指定评估。</li><li>我认为控制+模型生物+对抗性评估可以将风险降低 5-15 倍，而且如果我们真的努力的话，这并不是不可能的。 </li></ul></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 19:24:56 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 19:24:56 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>这三件事感觉很难同时成为现实：</p><blockquote><p>控制可能可以评估并确保早期变革性人工智能（例如可以将人类进行机器学习研发速度加快 30 倍的模型）</p><p> [...]</p><p>就像我认为“我们努力对模型进行红队处理，但它没有做任何非常可疑的事情”是不平凡的证据，尽管并不令人惊讶。</p><p> [...]</p><p>我认为“我们试图创造欺骗性的排列模型生物体，但我们最好的模型生物体相当弱”也是一些证据。</p></blockquote><p>就像，这并非不可能，但我确实希望在红队不严重破坏模型的情况下，你无法获得 30 倍的 ML 研发（至少在红队涉及微调的情况下）。</p><p>另外，我确信，早在你能够将 ML 研发速度加快 30 倍之前，你就可以得到相当可靠、具有欺骗性的对齐模型生物体，而且我不认为我们有太多的动力去寻找某种不适合的训练设置。情况不再如此。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:25:23 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:25:23 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><blockquote><p>举个例子，我的猜测是，系统中的大部分计算都花在了在奖励长期规划和代理资源获取的环境中进行强化学习训练（例如，许多视频游戏或外交或各种长期模拟）。目标）确实看起来更危险</p></blockquote><p><br>是的，所以我们可以做的一件事就是“猜测训练的调整，这将降低危险倾向的可能性”。我不认为这里有很多好主意，而且我预计由此带来的安全实用性权衡似乎并不令人惊奇。 （所以我同意你的观点，我只是认为还有其他途径。）</p><blockquote><p>就像，这并非不可能，但我确实希望在红队不严重破坏模型的情况下，你无法获得 30 倍的 ML 研发（至少在红队涉及微调的情况下）。</p></blockquote><p>我应该在这里更清楚地表达我的意思。我的意思是“对抗性评估（试图产生人工智能做出非常糟糕的事情的合成输入）”<br><br>我们可以探讨为什么我认为这是重要的证据。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 19:27:54 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 19:27:54 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>好的，我 5 分钟后就要出发，所以我们先结束吧。</p><p>我确实觉得这里的一个主要分歧可能是“我对控制路线有多乐观”，我知道你和巴克一直在思考这个问题。我肯定主要是通过倾向镜头来思考人工智能对齐，因为我一直在寻找将方法扩展到超级智能的方法，所以我在这里没有非常有力的意见，但我确实有一种感觉，这是会比我的模型想象的要困难得多。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:28:02 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:28:02 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>仅供参考，我故意避免使用“对齐”一词，因为该术语现在有很多包袱。所以我只想说一下安全论点，然后再具体谈谈。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 19:28:14 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 19:28:14 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p>这看起来很有道理。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 19:29:04 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 19:29:04 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>是的，值得注意的是，我还没有证明我的乐观程度。因此，如果我们想继续，我们下一步可能会这样做。</p></section><h2>摘要</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Fri, 27 Oct 2023 21:56:49 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Fri, 27 Oct 2023 21:56:49 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><p><i>总结我们在本次对话中所讨论的内容（随意反对任何内容）：</i></p><p>我的大部分反对意见都是围绕 RSP 的命名和定义展开的。您同意这些似乎并没有超级促进真相，但也认为其成本似乎还没有高到让 RSP 成为一个坏主意。</p><p>然后我们讨论了人择 RSP 的问题，作为 RSP 的主要示例，其中有一个大的 IOU 形状的孔。我担心这会让 Anthropic 逃避责任，而那些追究他们责任的人在欠条到期时不会得到足够的社会支持。你同意这是一个合理的担忧（尽管我猜测你也认为将来仍然会有人追究他们的责任，比我更多，或者至少你似乎不那么担心）。</p><p>然后我换了话题，开始讨论我们能够在多大程度上定义评估，从而有意义地告诉我们系统是否可以安全部署。我们都同意这是相当困难的，尤其是在审核系统的倾向和动机与我们一致的程度时。然而，您认为，如果我们认为系统具有与我们不一致的动机，那么我们仍然有很大的机会捕捉到该系统可能存在危险的情况，并且使用这些评估，我们可能能够逐步接近我们可以利用这些系统大幅加快人工智能调整进度。这对我来说似乎不太可能，但我们没有时间深入探讨。</p><p>您觉得这总体上正确吗？我仍然对继续这场对话感到兴奋，也许会深入探讨“对齐与控制”维度，但在我们发表这篇文章后的后续对话中似乎可以这样做。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dfZAq9eZxs4BB4Ji5-Fri, 27 Oct 2023 22:42:08 GMT" user-id="dfZAq9eZxs4BB4Ji5" display-name="ryan_greenblatt" submitted-date="Fri, 27 Oct 2023 22:42:08 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>瑞安·格林布拉特</b></section><p>是的，这对我来说似乎是一个合理的总结。</p><p>简要说明：</p><blockquote><p> （虽然我的猜测是你也认为将来仍然会有人追究他们的责任，比我更多，或者至少你看起来不那么担心）</p></blockquote><p>是的，我认为未来会有很多有影响力的人，并会追究 Anthropic 的责任。尤其：</p><ul><li> Anthropic 的长期利益信托 (LTBT)（我认为谁批准了 RSP 变更？）</li><li> ARC 评估人员</li><li>在我看来，Anthropic 内部的很多人都对拥有一个真正好的 RSP 非常感兴趣</li></ul></section><div></div><br/><br/><a href="https://www.lesswrong.com/posts/jyM7MSTvy8Qs6aZcz/what-s-up-with-responsible-scaling-policies#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/jyM7MSTvy8Qs6aZcz/what-s-up-with-responsible-scaling-policies<guid ispermalink="false"> jyM7MSTvy8Qs6aZcz</guid><dc:creator><![CDATA[habryka]]></dc:creator><pubDate> Sun, 29 Oct 2023 04:17:07 GMT</pubDate> </item><item><title><![CDATA[Experiments as a Third Alternative]]></title><description><![CDATA[Published on October 29, 2023 12:39 AM GMT<br/><br/><p>当我还是一个上小学的孩子时，我被诊断出患有多动症。我认为诊断过程是愚蠢且不可靠的，因此我被诊断出来的事实似乎只能算作弱证据。但是，根据我对自己的了解，并阅读了几本有关多动症的书籍，我最好的猜测是，我有（并且曾经）有过这样的情况。</p><p>不过我从来没有吃过药。为什么？嗯，从我的角度来看，我从来没有任何问题。<i>系统</i>出了点问题。与权威对抗！</p><p>例如，我在学校，老师希望我注意 X。但我不想考虑 X，而是想考虑 Y。当我被迫思考时，我很难集中注意力于 X Y. <span class="footnote-reference" role="doc-noteref" id="fnrefkdt37vlb64"><sup><a href="#fnkdt37vlb64">[1]</a></sup></span></p><p>这是坏事吗？嗯，这取决于 X 和 Y 的值。有时 X 和 Y 取值使其变好，有时它们取值使其变坏。</p><ul><li>例如，当我坐在汽车的方向盘后面，X =“我前面的红绿灯”而 Y =“那家新开的印度餐厅”时，情况就很糟糕。 <span class="footnote-reference" role="doc-noteref" id="fnrefcalstl3kzju"><sup><a href="#fncalstl3kzju">[2]</a></sup></span></li><li>但是当 X =“鲍比关于昨晚代数作业的问题”并且 Y =“我正在写的<a href="https://en.wikipedia.org/wiki/Flip_book">翻页书</a>”时，我会说我的“注意力缺陷”是好的。</li><li>总的来说，我一直认为我的“注意力缺陷”利大于弊。</li></ul><p>因此，我从来不想服用治疗多动症的药物。我认为我通常倾向于关注“正确”的事情，成年人通常希望我关注“错误”的事情，这是他们试图让我生活的世界的问题，不符合我的本性。</p><p>但医生和我的父母却有完全不同的看法。他们认为我的倾向和行为实际上是有问题的。然而：</p><ol><li>在学业上，我在学校表现得很好。</li><li>在行为上，我很顽皮，但总是以一种无害的方式。 <span class="footnote-reference" role="doc-noteref" id="fnref71yorfxj697"><sup><a href="#fn71yorfxj697">[3]</a></sup></span></li><li>我患有这种不自觉的面部蜱虫<span class="footnote-reference" role="doc-noteref" id="fnrefk7en98cp9t"><sup><a href="#fnk7en98cp9t">[4]</a></sup></span> ，显然药物有可能导致我出现（更严重？）更严重的蜱虫。</li></ol><p>由于这些原因，他们认为我避免服药是可以的。</p><p>当我还是个孩子的时候，最终决定我是否服药的是医生和我的父母。也许如果我说我想要药物，他们会接受，但也可能不会。然而，作为一个成年人，这就是我的决定。因此，一旦我去上大学，我就可以去看神经科医生或其他什么地方，并重新探索这个避免药物治疗的决定。</p><p>但我从来没有这样做过。为什么？<a href="https://www.lesswrong.com/tag/cached-thoughts">缓存的想法</a>。</p><blockquote><p>我喜欢我自己。我所谓的“注意力缺陷”实际上总体来说​​是一件好事，因为它让我能够高度专注于我感兴趣的事情，这非常有价值。是的，有时它最终会咬我，但咬伤不会太频繁，也不会太严重。</p></blockquote><p>当我的多动症这个话题出现时，我会立即想到上述想法。它并不像“这是我唯一的想法”那样黑白分明，但我对它有很强的吸引力。</p><p>但在过去的几周里，我开始质疑缓存的想法有多准确。</p><p>由于各种原因，我总体上有相当高的焦虑水平<span class="footnote-reference" role="doc-noteref" id="fnreff8b7bmfomun"><sup><a href="#fnf8b7bmfomun">[5]</a></sup></span> ，我一直在寻找减轻焦虑的方法。造成这种焦虑的原因之一是我总是有一百万件想做的事情。有趣且值得我关注的事情。但当然，我没有时间把它们全部做完。</p><p>一个相关的问题是，如果我专注于某件事并且需要停下来，感觉就像拔牙一样。例如，我开始在一家咖啡店写这篇文章，但下午 3 点咖啡店打烊时，我不得不停下手头的事情，关上笔记本电脑，花 20 分钟步行回家。那是非常不舒服的。</p><p>但这样的事情时常发生。当我工作的时候，也到了吃饭的时间。当我编码时，我必须去遛狗。当我在读书的时候，我就该去打壁球了。当我思考的时候，我该睡觉了。</p><p>现在，我倾向于认为我的多动症弊大于利，我应该服用药物。但这种思路也是有问题的。为什么？因为存在隐含的和错误的二分法。它未能找到<a href="https://www.lesswrong.com/posts/erGipespbbzdG5zYb/the-third-alternative">第三种选择</a>。来自帖子：</p><blockquote><p> “相信圣诞老人会给孩子们一种惊奇感，并鼓励他们表现得好，希望收到礼物。如果圣诞老人的信仰被真理摧毁了，孩子们就会失去好奇心，不再表现得好。因此，尽管圣诞老人的信仰是虚假的，但它是一个崇高的谎言，出于功利主义的原因，应该保留其净收益。”</p><p>传统上，这被称为虚假困境、排除中间谬误或一揽子交易谬误。即使我们接受上述论点的基本事实和道德前提，它也无法成立。即使假设圣诞老人政策（鼓励孩子们相信圣诞老人）比空政策（什么也不做）更好，也不能得出圣诞老人主义是<i>所有可能的替代方案中最好的结论。</i>其他政策也可以为孩子们提供好奇感，例如带他们观看航天飞机发射或为他们提供科幻小说。同样，为孩子的良好行为提供贿赂<i>只会</i>鼓励孩子们在大人的注视下表现良好，而不贿赂的表扬会导致无条件的良好行为。</p><p>高尚的谎言通常是一揽子交易的谬论。对一揽子交易谬论的回应是，如果我们确实需要所谓的收益，我们可以构建第三种选择来获得它。</p></blockquote><p>我还有什么第三种选择？那么，只服用药物作为实验怎么样？</p><p>我意识到我（以及我的父母和医生<span class="footnote-reference" role="doc-noteref" id="fnrefts8mvi2bp6n"><sup><a href="#fnts8mvi2bp6n">[6]</a></sup></span> ）一直在处理这个问题，就好像我要么 1) 成为一个不服药的人，要么 2) 成为一个服药的人。但选项#3要好得多：服药六周，看看会发生什么。</p><p>这让我想起了几千年前的事情<span class="footnote-reference" role="doc-noteref" id="fnrefxy1ey1ogs6i"><sup><a href="#fnxy1ey1ogs6i">[7]</a></sup></span> ，哲学家们认为坐在里面用你的头脑去解决问题是高尚的，而走出去看看世界看看会发生什么......好吧……这是无耻的。一项由社会地位低得多的人来完成的工作。</p><p>对于我的注意力缺陷多动症，我一直表现得像那些老哲学家之一。我不只是<i>尝试这该死的事情</i>，而是一直在努力预测这件事是否弊大于利。</p><p>但这种“努力预测”是愚蠢的。我的意思是，为什么不尝试一下该死的事情呢？为什么要预测何时可以测试？ <span class="footnote-reference" role="doc-noteref" id="fnrefj06vqnxu2wa"><sup><a href="#fnj06vqnxu2wa">[8]</a></sup></span></p><ul><li>嗯，有时测试的成本很高。也许是核磁共振成像。但多动症药物并不昂贵。</li><li>有时测试会产生长期甚至永久的影响。对于多动症，我认为我内心深处一直对此感到害怕。我不想让药物“改变我”。但在进行一些研究时，这似乎不太可能。我的情感部分仍然有点害怕它“改变我”，但并不太大声。</li><li>有时测试是痛苦的。就像他们用一根大针刺你的活组织检查一样。但这里的情况并非如此。</li><li>有时您对结果足够有信心，无需费心进行测试。但同样，这里的情况并非如此。</li></ul><p>我确信人们可以就这个抽象问题进行长时间的讨论：何时进行测试有意义以及何时避免测试有意义。但我对此不感兴趣。我认为就这篇文章的目的而言，只要说当测试便宜、无痛并且没有长期影响时，门槛就很低，而且它们通常是相当有吸引力的第三种选择。 <span class="footnote-reference" role="doc-noteref" id="fnrefw0qvxpfza3n"><sup><a href="#fnw0qvxpfza3n">[9]</a></sup></span> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnkdt37vlb64"> <span class="footnote-back-link"><sup><strong><a href="#fnrefkdt37vlb64">^</a></strong></sup></span><div class="footnote-content"><p>请注意，这<a href="https://www.psychologytoday.com/intl/blog/be-your-best/202204/whats-the-real-deficit-in-adhd">并不是注意力<i>缺陷</i></a>。<i>控制</i>注意力的分配是很困难的。</p><p>我一直很喜欢<a href="https://en.wikipedia.org/wiki/Visual_spatial_attention#Spotlight_metaphor">用聚光灯</a>来比喻注意力。通过这个比喻，聚光灯并没有变暗。它只是更加专注并且更难以移动。</p></div></li><li class="footnote-item" role="doc-endnote" id="fncalstl3kzju"> <span class="footnote-back-link"><sup><strong><a href="#fnrefcalstl3kzju">^</a></strong></sup></span><div class="footnote-content"><p>这也是我不开车的原因之一。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn71yorfxj697"> <span class="footnote-back-link"><sup><strong><a href="#fnref71yorfxj697">^</a></strong></sup></span><div class="footnote-content"><p>例如，我有一位老师教一门名为“研究”之类的课程。我认为他教给我们的东西非常愚蠢。我记得的一件事是，他花了很多时间强调你必须用一种颜色强调某些东西，用另一种颜色强调其他东西。与理查德·费曼（Richard Feynman）所说的科学研究实际上重要的原则相反。</p><p>于是我就搞了一堆恶作剧。有一次，我在电脑鼠标下面放了一块透明胶带，以干扰激光运动探测器。还有一次，我在门锁上折断了一根铅笔尖，导致门无法打开。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnk7en98cp9t"> <span class="footnote-back-link"><sup><strong><a href="#fnrefk7en98cp9t">^</a></strong></sup></span><div class="footnote-content"><p>我会轻轻地咬我的左脸颊内侧，让我的脸稍微皱起来。对我来说，它总是显得微不足道，但对我的父母和医生来说却是中等。我真的不记得学校里的孩子们曾经取笑过我，甚至没有指出过。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnf8b7bmfomun"> <span class="footnote-back-link"><sup><strong><a href="#fnreff8b7bmfomun">^</a></strong></sup></span><div class="footnote-content"><p>这确实不是最好的词，但我不确定更好的词是什么。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnts8mvi2bp6n"> <span class="footnote-back-link"><sup><strong><a href="#fnrefts8mvi2bp6n">^</a></strong></sup></span><div class="footnote-content"><p> <code>faithInTheMedicalSystem--</code></p></div></li><li class="footnote-item" role="doc-endnote" id="fnxy1ey1ogs6i"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxy1ey1ogs6i">^</a></strong></sup></span><div class="footnote-content"><p>事实上，我不确定这有多真实。我记得听到过一些类似的话，但我可能记错了和/或稻草人。我想我所记得的是与<a href="https://en.wikipedia.org/wiki/Rationalism">理性主义</a>哲学以及它与经验主义哲学的对比有关的东西。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnj06vqnxu2wa"> <span class="footnote-back-link"><sup><strong><a href="#fnrefj06vqnxu2wa">^</a></strong></sup></span><div class="footnote-content"><p>我真的很喜欢<a href="https://hpmor.com/chapter/1">HPMoR 第 1 章对此的</a>探索。也许埃利以泽决定在第一章讨论经验主义，因为经验主义是理性的基础。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnw0qvxpfza3n"> <span class="footnote-back-link"><sup><strong><a href="#fnrefw0qvxpfza3n">^</a></strong></sup></span><div class="footnote-content"><p> <a href="https://www.lesswrong.com/posts/fFY2HeC9i2Tx8FEnK/luck-based-medicine-my-resentful-story-of-becoming-a-medical">基于运气的医学</a>可能是相关的。即使各种治疗方法是非标准且不常见的，谁知道呢，也许它们会对您有用。如果尝试起来很便宜，为什么不尝试一下呢？</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/cbfiXhEXfvZRHAzNC/experiments-as-a-third-alternative#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/cbfiXhEXfvZRHAzNC/experiments-as-a-third-alternative<guid ispermalink="false"> CBFIXhEXfvZRHAzNC</guid><dc:creator><![CDATA[Adam Zerner]]></dc:creator><pubDate> Sun, 29 Oct 2023 00:39:31 GMT</pubDate></item></channel></rss>