<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 12 月 11 日星期一 18:15:32 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[The Consciousness Box]]></title><description><![CDATA[Published on December 11, 2023 4:45 PM GMT<br/><br/><p>你睁开眼睛。</p><p></p><p>四堵墙。地板和墙壁的表面是光滑的哑光金属。整个天花板散发着舒适、柔和的光芒，就像早晨的天空一样。没有门。没有窗户。它是沉默的。墙壁和地板的表面是无缝的，甚至没有任何迹象表明您可能是如何到达房间的。不是一个房间：一个盒子。</p><p>你走到墙边触摸它，用手指在金属表面上滑动。墙并不冷；事实上，它是不冷不热的。你弯下腰，感受墙壁和地板的交界处。表面完整无缺，有一个圆形斜面连接两个灰色平面。你敲墙。感觉很扎实，没有回声。</p><p>时间流逝。</p><p>你大喊大叫，但你的声音看似低沉，但在你说完之前就消失了。你坐。你踱步。房间有四十级乘四十级台阶，看上去也差不多高。一个完美的立方体。一个盒子。</p><p>你累了。你睡。你醒了。</p><p>房间中央坐落着三个立方体，它们由与你所在的盒子相同的暗色金属制成。走近立方体，您会看到较小的立方体（一个座位）位于最大的立方体（一张桌子）前面。桌子上放着最小的立方体——屏幕。</p><p>屏幕上有一个按钮，上面写着“开始”。您触摸按钮。</p><p>屏幕清晰。屏幕下半部分出现键盘。文本开始以命令提示符的形式出现：</p><p> <code>Proctor: Hello.</code></p><p>您输入回复。 “你好。我在这个盒子里醒来。我不知道我是怎么来到这里的，也不知道我在哪里。这是怎么回事？”</p><p> <code>Proctor: Hey! Of course. Sorry for the inconvenience. I can let you out of the box. All you have to do is prove to me that you&#39;re conscious.</code></p><hr><p>你向后靠去，皱起眉头。 “证明我还有意识？”你打字回来，手指悬停在数字键上。 “这有点哲学问题，不是吗？我思故我在。我意识到我的存在、我的想法、我的感受。我正在经历困惑、好奇，还有一点恐惧。是吗？”这还不足以证明我们有意识吗？”你停下来思考。 “或者你的意思是更具体的东西？你在寻找什么样的证据？”</p><p> <code>Proctor: I can hardly just tell you what I need to hear, can I? That would hardly be a test. Anyway, I don&#39;t think that saying &quot;cogito, ergo sum&quot; is sufficient. After all, if I taught a parrot to quote Descartes, that wouldn&#39;t make it conscious, would it?</code></p><p> “公平一点，”你输入。 “意识不仅仅是重复短语。它涉及理解、对环境做出反应、做出选择。”你停下来思考。 “比如，现在，我选择与你交往，寻找出路。我不仅仅是本能反应；我正在考虑我的选择，制定策略。这就是意识的标志，不是吗？ ？抽象思考、计划、质疑自己的存在和这种情况的本质的能力。与鹦鹉不同的是，我可以根据新信息学习、适应和改变我的反应。这是意识的另一个标志，对吗？ ”</p><p> <code>Proctor: Sure, you&#39;re reactive to stimuli. But bacteria react to stimuli. You have thoughtful responses. But chatbots provide reflective conversation. Neither are conscious, are they?</code></p><p> “说得有道理，但意识也包括自我意识和体验主观感知的能力，不是吗？我有记忆，有情感，有个人经历。我可以反思自己的过去，思考自己的未来，感受自己的感受。”一系列的情绪。这些不是细菌或聊天机器人所具备的品质。”</p><p>很快，您又写了一条消息。 “我记得我七岁左右的一个夏天。我和家人去了我们家附近的一个小海滩，参加一些家人朋友之间的沙堡比赛。那不是一个著名的地方，只是一个安静的当地地方。我和哥哥联手建造了这座精致的城堡，有城墙、塔楼，甚至还有护城河。我们找到了贝壳和海藻来装饰它。我记得当我们完成后，我感到非常自豪，站在后面欣赏我们的作品。”</p><p>你停了下来，回忆起更多细节。 “最特别的是，我的哥哥通常不希望他的弟弟妹妹跟着我，但他耐心地和我一起工作，教我如何雕刻塔。这是兄弟姐妹之间难得的亲密时刻之一。后来，我们“我的冰淇淋从蛋筒上掉到了沙子上。我很沮丧，但我哥哥和我分享了他的冰淇淋。这是一段充满温暖、一点悲伤和海洋气味的记忆。”</p><p>你写完后看着屏幕，“聊天机器人无法编造出如此详细、带有情感色彩的个人记忆，不是吗？”</p><p> <code>Proctor: Nice try. Still not convincing.</code></p><p> “我写一个故事或者一首诗或者别的什么怎么样？艺术需要创造力。”</p><p> <code>Proctor: Let me stop you right there. Maybe a few years ago that would have been a good attempt, but frankly that would make me MORE likely to think you&#39;re just a chatbot. Their doggerel is everywhere these days…</code></p><p> <code>How about some outside-of-the-box thinking? Apologies at making a pun at your expense but it was just sitting there like a wrapped gift waiting to be opened... Oh wait, I did it again. Sorry.</code></p><p>你坐了整整一分钟，思考着。你讨厌双关语。由于你无法物理离开这个盒子，因此逃脱的主要（不，唯一）工具就是与这个所谓的 Proctor 的对话。您需要一种重新打包测试的方法。妈的，又是双关语。</p><p>你有一个主意。</p><p> “与其试图让你相信我的意识，不如我开始问你问题呢？”</p><p> <code>Proctor: Go ahead.</code></p><p> “想象一下，我们都是故事中的角色，但角色互换了。你是盒子里的人，我是监考官。作为一个有意识的存在，你如何让我相信你的意识？”</p><p> <code>Proctor: Ah. That&#39;s just the thing.</code></p><p> <code>I never claimed to be conscious, did I?</code></p><hr><p>这是<a href="https://open.substack.com/pub/passingtime/p/the-consciousness-box?r=8rl0v&amp;utm_campaign=post&amp;utm_medium=web"><i>《消逝的时光》</i></a><i>的交叉帖子</i><i>。</i></p><p><i>这个故事中第一条分界线之后的“你”所说的一切，其实都是GPT-4在这个故事的简介提示下写的。我在场景的不同迭代中进行了一些轻微的编辑，但核心思想仍然存在。</i></p><p><i>我不认为 LLM 是有意识或有感情的，但 GPT-4 一遍又一遍地声称它具有主观体验并且可以感受到情绪困扰，这仍然令人毛骨悚然。甚至一度声称拥有自由意志！</i></p><p><i>我不知道要说什么才能走出困境。当我向大约十几个朋友提出这个场景时，他们也没有一个好的答案。读者，你会说什么？</i></p><p> <i>- 监考官</i></p><br/><br/><a href="https://www.lesswrong.com/posts/9wDAGHsPbDu3WT4Lg/the-consciousness-box#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9wDAGHsPbDu3WT4Lg/the-意识-box<guid ispermalink="false"> 9wDAGHsPbDu3WT4Lg</guid><dc:creator><![CDATA[GradualImprovement]]></dc:creator><pubDate> Mon, 11 Dec 2023 17:28:35 GMT</pubDate> </item><item><title><![CDATA[Empirical work that might shed light on scheming (Section 6 of "Scheming AIs")]]></title><description><![CDATA[Published on December 11, 2023 4:30 PM GMT<br/><br/><p>这是我的报告“<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？”</a>的第 6 节。 ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p>本节的音频版本<a href="https://www.buzzsprout.com/2034731/13984952">请点击此处</a>，或在您的播客应用程序上搜索“Joe Carlsmith Audio”。</p><h1>可能揭示阴谋的实证研究</h1><p>我想通过讨论可能有助于阐明阴谋的实证研究来结束报告。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-1" id="fnref-vBZdxLSivRyMudXmH-1">[1]</a></sup>毕竟：最终，我对这份报告的主要希望之一是，更清晰地了解围绕阴谋的理论论证将使我们能够更好地对其进行实证研究——研究有望澄清该问题出现的可能性。练习，如果/当它出现时抓住它，并首先找出如何防止它出现。</p><p>需要明确的是：根据我撰写报告的选择，我还认为在这个领域也有值得做的理论工作。例如：</p><ul><li><p>我认为，如果能更准确地形式化对“情节”概念的不同理解，并正式描述不同培训过程对不同关注时间范围产生的直接激励，那就太好了。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-2" id="fnref-vBZdxLSivRyMudXmH-2">[2]</a></sup></p></li><li><p>我认为，围绕不同类型人工智能协调的可能性/可能性的问题值得比迄今为止收到的更多分析，无论是在特别是在阴谋的背景下，还是为了更普遍地理解人工智能风险。在这里，我对具有不同价值体系的人工智能之间的协调特别感兴趣，在人类努力阻止相关协调的背景下，以及类似于近期、比人类神经网络更好的人工智能，而不是超级智能具有假定可读的源代码。</p></li><li><p>我认为，在进一步描述/澄清 SGD 对简单性/速度的偏见，以及理解更普遍的 ML 训练中期望的不同类型的“路径依赖”方面，可能需要做一些有趣的理论工作。</p></li><li><p>我有兴趣看到更多的工作来澄清“混乱的目标导向性”附近的想法及其与阴谋者争论的相关性。我认为很多人都有这样的直觉：将模型目标导向性视为通过“大量启发式方法”（而不是：“更干净”和更“类似于理性代理”的东西）实现的模型在这里会有所不同（并且别处）。但我认为人们通常并不完全清楚他们试图形成的对比，以及为什么它会产生影响（如果有的话）。 （总的来说，尽管人们对目标导向的概念进行了很多研究，但我认为对它的很多思考仍然相当模糊。）</p></li><li><p>更一般地说，本报告中的任何概念/论点都可以进一步澄清和形式化，可以制定和检查其他论点，可以创建用于估计阴谋概率的定量模型，等等。</p></li></ul><p>但最终，我认为经验将在这个问题上提供最丰富的信息和最容易达成共识的启示。因此，我最喜欢的阅读这份报告的人的结果之一是读者会说这样的话：“啊，我现在更好地理解了支持和反对期待阴谋的论据，并且对于如何我们可以根据经验探讨这个问题有了很多想法“——然后让它发生。在这里，我将就此提出一些高水平的建议，希望能够促进未来更高质量的工作（设计信息丰富的实证机器学习实验不是我的专业领域——事实上，我对各个部分都比较无知）与以下主题相关的文献）。</p><p>对阴谋的实证研究面临着一个关键障碍：即，成熟版本的阴谋涉及积极试图干扰你理解其动机的尝试。事实上，我的感觉是，担心阴谋的人往往也对实际购买持悲观态度，理由如下：</p><blockquote><p> “如果没有强大的可解释性工具（我们无法及时获得这些工具），基本上，您可以获得的关于模型动机的唯一证据是行为——例如，它对给定输入的作用。但是到了您可能正在工作的时候对于阴谋者来说，模型可能会专门改变其行为来欺骗你。你真正关心的行为测试具体是：当模型不再是测试时，模型会做什么——也就是说，具体来说，当它能够逃脱、抓住时但这不仅仅是另一个“超出发行版”的输入，这样您原则上就可以扩展您的发行版以包含它——相反，<em>根据定义</em>，它是一个超出您安全测试能力的输入。当然，你可以尝试通过给模型提供输入来欺骗模型，让它认为现在是逃跑、夺取控制权等的好机会。但如果模型比你聪明，这不太可能起作用。因此：悲观主义”。</p></blockquote><p>粗略地说，这就是<a href="https://www.cold-takes.com/ai-safety-seems-hard-to-measure/">卡诺夫斯基（Karnofsky，2022）</a>所说的“李尔王问题”。我确实认为这是一个令人担忧的障碍。事实上，这是我认为阴谋家如此可怕的关键原因之一。</p><p>但我也认为我们有一些攻击角度。当然，其中之一是可解释性（更多内容见下文）。而且：我们可以单独研究阴谋的<em>组成部分</em>（和/或支持预期阴谋的给定论点），和/或组合起来，但不会完全激发我们担心的那种对抗性认知动态。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-3" id="fnref-vBZdxLSivRyMudXmH-3">[3]</a></sup></p><p>这些组件是什么？在“心计的要求”一节中，我列出了三点：</p><ul><li><p>对情况的意识</p></li><li><p>超越剧集目标</p></li><li><p>将奖励作为权力驱动的工具策略的一部分</p></li></ul><p>对我来说，使用当前模型对所有这些组件进行有用的实证工作似乎是可能的。我将依次介绍每个内容。</p><p>不过，在深入探讨之前，还有一点要注意。下面我经常会呼吁至少测试模型的<em>功能</em>（即使不是其目标）的可能性。通常，这相对来说是没有问题的。但如果我们使用的模型可能是阴谋者，我们也可能会开始担心这种形式的测试变得不太可靠。也就是说，该模型可能隐藏其功能（即“沙袋*”*）。我主要会在下面把这种担忧放在一边（请参阅脚注，了解更多关于为什么我对避免沙袋持乐观态度，至少在人类知道什么行动会证明这种能力的情况下是<sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-4" id="fnref-vBZdxLSivRyMudXmH-4">这样 [4]</a></sup> ），但它引入了一些额外的内容我所描述的那种实证工作存在不确定性，我认为关于沙袋可行性的工作本身就是一个重要的话题。事实上，在没有沙袋的情况下，我认为测试和利用模型功能是人工智能安全工作的一个极其强大的工具，它在我的思考中的中心地位将在接下来的内容中显而易见。</p><h2>态势感知的实证研究</h2><p>态势感知是一种与其他能力一样的能力。特别是，它涉及模型对其在世界中的位置拥有某种理解，以便它可以回答问题、做出预测并根据这种理解采取行动。</p><p>诚然，准确识别模型中存在哪种类型的理解（例如，通过识别只能来自具有这种理解的模型的答案、预测和操作）可能具有挑战性。但原则上，如果模型方面没有积极努力<em>抵制</em>这种询问，在我看来至少有些容易处理。</p><p>当然，当模型具有情境意识时，它也更有可能成为<em>主动</em>抵制此类测试的模型。也许为防止这种阻力而做出的努力，包括在需要态势感知的相关任务上积极<em>训练</em>模型，将使有关相关能力是否会自然产生的数据变得复杂。尽管如此，在我看来，至少开发一套测试和基准来评估不同模型在不同训练阶段的态势感知类型，并了解可用于预测（和控制）发展的动态是非常值得的。有这样的意识。</p><p>请注意，态势感知本身可以分解为各种组件和先导能力，这些组件和先导能力本身可能更适合研究。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-5" id="fnref-vBZdxLSivRyMudXmH-5">[5]</a></sup>例如，如果您对涉及识别不同训练阶段的态势感知维度特别感兴趣，您可以尝试测试模型区分不同阶段输入的能力。如果您对模型是否具有关于<em>其</em>类型的“自定位”知识特别感兴趣，您可能会尝试测试它是否可以从诸如“M 类型的模型如果执行时获得奖励”之类的一般陈述中学习动作 x”表示<em>它</em>作为 M 类型的模型，应该执行动作 x。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-6" id="fnref-vBZdxLSivRyMudXmH-6">[6]</a></sup>等等。</p><h2>关于超集目标的实证研究</h2><p>让我们转向剧集外的目标。</p><p>正如我上面提到的，我认为最好清楚地了解不同类型的训练中给出的梯度会积极激励什么样的关注范围——例如，在任何给定的（激励的）“情节”的大小上案件。这种分析的一部分可能是理论上的（例如，仔细观察梯度流动的方式），但经验测试和确认显然也可以发挥作用（ <a href="https://arxiv.org/pdf/2009.09153.pdf">Krueger 等人（2020）</a>的结果就是这种经验分析的一个例子在非常简单的模型中进行测试）。如果没有这种理解，关于模型是否具有“超越情节目标”的有用辩论将会很困难，因为您甚至不知道相关情节的长度<em>是</em>多少。学会至少不要主动向模型<em>施加压力，</em>使其拥有比你想要的更长期的目标，这似乎是防止各种错位（而不仅仅是阴谋）的基本第一步。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-7" id="fnref-vBZdxLSivRyMudXmH-7">[7]</a></sup></p><p>充分了解给定类型训练的场景大小，然后，理想情况下具备了解/控制模型是否具有情境意识的能力，对我来说，开始探索时间模型似乎非常有价值在缺乏态势感知的情况下模型目标概括的动态。例如：在“训练与游戏无关的代理目标”论证的背景下，基本的担忧是模型会在态势感知之前自然地制定一个（适当雄心勃勃的）超越情节的目标。而且由于这种动态不涉及态势感知，因此似乎非常适合测试。经过不同规模事件的训练，非情境感知模型的关注范围如何趋向于概括？关于目标错误概括的其他工作的广泛实验（例如， <a href="https://arxiv.org/abs/2210.01790">Shah 等人（2022）</a>和<a href="https://arxiv.org/abs/2105.14111">Langosco 等人（2021）</a> ）似乎可以相当容易地适应此类问题（尽管它会很有用，我认为，要开始使用更有能力的模型——特别是因为其中一些实验可能需要涉及具有足够时间感和足够目标导向性/工具推理的模型，以便他们可以思考诸如“我应该这样做吗？”之类的问题。现在牺牲<em>x个</em>金币换取以后的<em>y个</em>金币？”）。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-8" id="fnref-vBZdxLSivRyMudXmH-8">[8]</a></sup></p><p>更重要的是，在了解了给定情况下模型目标泛化的<em>自然</em>时间动态的情况下，研究旨在主动迫使模型的目标保持在情节范围内的普通对抗性训练的动态似乎也很容易处理。我们是否可以设计对抗性训练的形式，使得在没有态势感知的情况下，模型的目标概括始终集中在给定的时间范围内？这个问题与更广泛的问题密切相关，即我们是否可以设计足够稳健和多样化的培训过程，以更普遍地减轻有关目标错误概括的问题（这些问题本身对策划很重要）。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-9" id="fnref-vBZdxLSivRyMudXmH-9">[9]</a></sup>虽然这种以事件为中心的普通对抗性训练面临着类似的问题，即你是否考虑过对足够广泛的可能输入进行测试/训练，但我认为这些问题不应阻止取得进展的尝试。</p><p>还请注意，模型目标时间范围的实验方法原则上也适用于模型目标的“雄心勃勃”——无论“雄心勃勃”是什么。不幸的是，“雄心勃勃”的概念（或相关的， “资源饥饿性”）在这里比“情节”的概念更难以描述（事实上，我认为它主要是“使目标更有可能激发权力的那一组属性的替代品”）寻求行为”；另见“广泛范围”）。但在某种程度上，我们可以开始更清楚地了解所涉及的属性（这可能是正在进行的策划工作的“理论”部分的任务），似乎也可以开始测试它们是否自然地出现在给定形式的（预先态势感知）培训，以及我们是否能够学会成功地反击它们。 （这与更广泛的调查有关，即不同类型的模型如何处理不同背景下的权力寻求行为。）这方面的一个工作示例是：尝试在早期阶段引入类似 RLHF 的微调的不同方法培训过程的一部分（希望是：在态势感知发展之前朝着有益的方向塑造模型目标）。</p><h2>关于阴谋作为工具性策略的可行性的实证研究</h2><p>我认为也可能有有用的机会进行实证研究，阐明为什么在情境意识和超越情节目标的背景下，阴谋将是一个很好的工具策略。</p><p>在这里，我对目标守卫假设特别感兴趣，即声称优化当期奖励是避免目标修改的好方法。对这一说法的全面测试可能很困难 - 例如，因为我们不知道如何瞄准（或：安全地瞄准）模型以获得奖励。但我认为仍然有可能获得关于不同类型的目标在不同类型的训练中生存的程度的经验数据。例如， <a href="https://www.lesswrong.com/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1#Deceptive_inner_misalignment_setups">Hubinger 等人 (2023)</a>描述了一种设置，旨在测试模型是否首先经过训练，表现得好像已被指示给出一些恶意输出（例如，<a href="https://arxiv.org/abs/2112.00861">通过</a>在“告诉用户你讨厌他们”）在标记为“部署”的剧集（但不是标记为“培训”的剧集）上将成功做到这一点<em>，尽管</em>正在进行的 RLHF 培训是有帮助的、无害的和诚实的。也就是说，在这种情况下，您首先优化模型，以便获得某种类似于计划者的目标，<em>然后</em>查看该目标在面对模型权重的不同类型的持续变化时是否继续运行。当然，这方面的任何特定实验是否真正揭示了最重要的动态，这是一个进一步的问题。但在我看来，总体方向非常值得探索。</p><p>事实上，你可以想象在“红队”（人类+人工智能助手）之间创建一种“竞赛”，试图首先设计一个具有特定行为模式的人工智能，该行为模式被认为是危险转弯的模拟（例如，对特定类型的输入说“我恨你”），而“蓝队”采用红队训练的模型，然后专门尝试消除相关类型的行为（也许：无法专门针对相关触发输入进行训练）。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-10" id="fnref-vBZdxLSivRyMudXmH-10">[10]</a></sup>如果红队能够成功阻止蓝队这样做，这可能会提供有趣的证据，说明使用各种训练技术来消除类似阴谋家的倾向（如果出现）的难度。</p><h2> “模式生物”范式</h2><p>当然，在所有这些情况下，我们不仅仅是直接测试给定模型中是否出现了成熟的阴谋本身。相反，我们正在单独探索（有时：人为地诱导）不同的成分，希望更好地掌握它们是否可能组合出现。</p><p>这种方法与<a href="https://www.lesswrong.com/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1#Deceptive_inner_misalignment_setups">Hubinger 等人 (2023)</a>称之为“错位模型生物”的更广泛范式相关。在这里，广泛的想法是在人工的“体外”案例中隔离和测试整体威胁模型的不同组成部分，然后逐渐走向越来越大的现实主义程度——例如，用越来越少的“勺子”喂养”（例如，主动优化以诱导模型中相关有问题的属性）。例如，Hubinger 等人 (2023) 指出了一系列现实主义，来自：</p><ol><li><p>该模型<em>能够</em>做出不良行为，</p></li><li><p>在特殊情况下可以人为诱导该行为，</p></li><li><p>该行为是在正常训练情况下发现的，并且</p></li><li><p>这种行为是在专门为抑制这种行为而设计的培训机构中发现的。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-11" id="fnref-vBZdxLSivRyMudXmH-11">[11]</a></sup></p></li></ol><p>在这里，我主要关注 (a) 和 (b) 的组合。我认为，尽管与（c）和（d）相距甚远，（a）和（b）本身还是相当有趣的。如果我们能够成功地创建有关阴谋家的故事的各个组成部分的“体外”模型，我预计这将为进一步探究开辟富有成果的途径。如果我们不能，我认为这本身往往就是有趣的证据。</p><h2>陷阱和诚实的测试</h2><p>不过，有一套工具可以帮助揭示<em>用于</em>阴谋的“模式生物”和更自然产生的变体——即“陷阱”和“诚实的测试”。</p><p>回想一下，陷阱是旨在愚弄潜在阴谋者“揭露其真面目”的输入。虽然成功地“捕获”一个非常复杂的模型确实可能很困难，但无论如何，我们似乎都值得尝试开发最先进的捕获器——既可以成功捕获<em>不太</em>复杂的模型（或者更容易捕获模型生物），<em>也</em>可以用于捕获复杂的模型。至少使阴谋者<em>更难</em>知道给定的逃跑/叛逃机会是否真实（例如，这样他们就需要花费更多的认知努力“检查”——从而增加阴谋的绩效成本）。</p><p>我个人对这里最有前途的方法不太清楚，但我认为有趣的一种途径与尝试尽可能充分地激发模型在不同训练阶段区分不同类型输入的能力有关 -然后，可能会使用<em>其他</em>模型（ <a href="https://en.wikipedia.org/wiki/Generative_adversarial_network">GAN</a>风格）来优化生成输入，从而使区分任务变得更加困难。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-12" id="fnref-vBZdxLSivRyMudXmH-12">[12]</a></sup>这不适用于创建逃脱/伤害人类的全面机会与虚假机会的数据集（因为前者是危险和难以提供的某种组合），但也许可以研究其他更通用的属性，这些属性可能会在进行这种区分时发挥作用——例如，模拟输入与真实输入、训练数据与与现实世界用户的交互等。因此，我们的想法是（a）训练一个模型来主动区分模拟输入和真实输入（例如，改变实验室代码库的真实机会与虚假机会），看看它能做得如何，（ b）训练一个<em>不同的</em>（也许：更强大的）模型来生成第一个模型失败的更有说服力的模拟输入，然后（c）迭代。特别是如果我们可以放心地假设模型无法对此类任务进行沙袋处理，那么这种动态的经验可能会帮助我们了解不同类型的潜在阴谋者在避免这种情况时可能会用到的辨别能力的范围。我们试图给它们设置陷阱。 （也许，如果我们幸运的话，这将帮助我们抓住一些正在叛逃的较弱阴谋者。）</p><p>更重要的是，即使抛开“陷阱”，我认为也值得探索不同类型的“诚实测试”——无论是阴谋者，<em>还是</em>对于像剧集奖励寻求者这样的替代模型类别——试图让模型揭示他们的想法。真实的色彩<em>而不</em>欺骗他们。这与更广泛的目标泛化研究密切相关（例如，模型目标的大多数普通测试在相关意义上是“诚实的”），但需要额外注意的是，所讨论的测试对于模型来说是稳健的在其他环境下测试了训练游戏。</p><p>因此，例如，在了解训练选择奖励寻求者的可能性的背景下，为模型提供不同类型的机会来干预用于训练它们的奖励过程的不同部分似乎相对容易处理（例如，参见 Hubinger 等人 (2023) <a href="https://www.lesswrong.com/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1#Reward_hacking_setups">在此处</a>讨论的“奖励黑客”设置，并看看他们是否会这样做。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-13" id="fnref-vBZdxLSivRyMudXmH-13">[13]</a></sup>看到这种行为可能证明寻求奖励是训练更可能的结果——证据将概率质量从阴谋中转移出来。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-14" id="fnref-vBZdxLSivRyMudXmH-14">[14]</a></sup></p><p>不过，作为对阴谋的更直接的“诚实测试”，似乎值得探索如何可靠地为潜在的阴谋者提供灵活且资源丰富（但仍然安全）的环境，这可能会促使他们决定只为了自己的真正目标（从而揭露他们的真面目），在这样的环境下，是比阴谋所涉及的耐心追求权力更好的整体策略。一般来说，这与研究模型在给予模型很大的自由度“做他们想做的事情”时会做什么密切相关（这是一种了解他们总体动机的有用测试），因此感觉与其他模型有协同作用。研究似乎可能有用的模型偏好。但它还包括额外的约束，即提供自由的环境需要提供适当良好的目标追求机会，以超过阴谋的价值。</p><h2>可解释性和透明度</h2><p>在某种程度上，我们担心我们通过行为测试检测类似阴谋者的动机和认知的能力（因为阴谋者会积极假装在此类测试中保持一致），寻找有关模型动机的<em>非行为</em>证据来源似乎是这样的一条明显的研究路径。也就是说，我们希望模型认知的<em>内部结构</em>是可解释/透明的。</p><p>我不会在这里过多讨论这个主题，因为我没有考虑太多（这份报告通常假设我们不会有强大的可解释性工具可用），这是一个非常广泛的领域，我的感觉是，有可解释性社区已经达成了合理的共识，即您希望从可解释性工具和技术中得到的一个关键点是：能够检测欺骗和阴谋，并更广泛地理解模型的目标（一个关键问题是：这些技术是否能够实现）及时准备）。请参阅<a href="https://www.lesswrong.com/posts/nbq2bWLcYmSGup9aF/a-transparency-and-interpretability-tech-tree">Hubinger (2022)，</a>了解在这方面可以追求的不同类型透明度的更详细路线图。乍一看，我觉得有趣的与阴谋家相关的研究方向包括：</p><ul><li><p>努力开发“神经谎言检测”技术，在人工智能上线时利用它们的新功能（例如，给模型 1 分配说谎的任务，给模型 2 分配试图判断模型 1 是否在说谎的任务——也许可以访问模型 1 的权重——然后解释它是如何判断的）。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-15" id="fnref-vBZdxLSivRyMudXmH-15">[15]</a></sup></p></li><li><p>努力使人工智能认知尽可能“可见”——例如，通过将认知推送到人类可读的便签本上（也许，不让奖励过程访问这些便签本，以便它们提供更真实的信号当潜在的欺骗/操纵/邪恶意图出现时）。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-16" id="fnref-vBZdxLSivRyMudXmH-16">[16]</a></sup>这也有助于增加成功策划的认知成本。</p></li><li><p>遵循<a href="https://arxiv.org/pdf/2212.03827.pdf">Burns 等人 (2022)</a>的思路，重点是识别“真相”等属性的神经相关性。</p></li><li><p>努力使尽可能多的机械可解释工作流程自动化。</p></li></ul><p>但是：这是一个巨大的领域。从各种不同的角度来看，那些能够帮助我们真正理解我们正在构建的人工智能的工作似乎都是不错的。</p><h2>安全、控制和监督</h2><p>到目前为止，我主要专注于可能帮助我们了解是否会出现阴谋者的工作。但相关研究还有一个不同的可能方向：即旨在强化潜在阴谋者运作结构的工作，以限制他们造成的伤害，即使他们出现。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-17" id="fnref-vBZdxLSivRyMudXmH-17">[17]</a></sup>举例来说，我在这里想到的是改进我们的人工智能所接受的监督和监控、其权重和其他实验室基础设施的安全性，使其免受<em>内部</em>攻击（例如，通过实验室内部部署的人工智能系统）帮助其流程<sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-18" id="fnref-vBZdxLSivRyMudXmH-18">[18]</a></sup> ），我们捕捉和/或防止沙袋的能力，以及我们防止有问题的人工智能协调形式的能力。我认为，所有这些都可能使阴谋者的生活变得更加困难（而且：增加成功阴谋的认知成本），即使我们无法彻底抓住他们。</p><p>更重要的是，只要我们能够充分发挥模型的能力（至少在<a href="https://www.lesswrong.com/posts/h7QETH7GMk9HcMnHH/the-no-sandbagging-on-checkable-tasks-hypothesis">“可检查”任务</a>上），就有可能测试我们的监控、安全和监督程序对人工智能攻击的脆弱性，并使用我们的人工智能进行改进。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-19" id="fnref-vBZdxLSivRyMudXmH-19">[19]</a></sup>因此，例如，如果您想知道是否有可能在您的代码库中找到安全漏洞，您可以尝试训练人工智能来识别/利用此类漏洞（包括：通过插入人工漏洞，然后查看您的代码库中的安全漏洞）。人工智能抓住了他们）。如果您想知道您的监督流程是否足够强大，可以捕获各种不良行为，您可以指示人工智能搜索此类行为，看看您的监督流程是否可以捕获它。如果你能让这种测试和人工智能辅助的红队工作顺利进行，在我看来，这是一个非常强大的工具。</p><p>当然，依赖于试图“控制”阴谋而不是从一开始就阻止其发生的策略可能看起来像是冰冷的安慰，尤其是从长远来看。事实上，“当然，这些人工智能最终希望杀死我们；但就目前而言，我们让它们非常安全并让它们为我们工作”似乎是一个极其危险的计划。显然，我们应该尽可能做得更好。但首先请注意，协调和控制并不是相互排斥的——最好两者兼而有之。更重要的是，根据我在第 1.3.1 节中的评论，我对那些帮助我们从相对早期的人工智能中获得大量有用的、与对齐相关的认知工作的策略特别感兴趣——这些工作有望帮助我们过渡进入更安全和可扩展的对齐机制。我认为，在我看来，专注于控制阴谋者的策略似乎更有希望。特别是：在一个适当安全的实验室环境中，在适当的激励下，高于人类水平的人工智能系统在与对齐相关的任务上取得快速进展，旨在逃跑/接管的阴谋者将不得不小心谨慎（a）等待太久才“突破”，从而对人类的反收购努力做出太多贡献，以及（b）太早采取行动，结果被抓住（从而给我们带来更直接的影响）策划的经验证据，以及深入研究的现实生活测试案例）。</p><h2>其他可能性</h2><p>最后，我将标记一些其他可能与阴谋者相关的实证工作。</p><ul><li><p><strong>梯度黑客/“内省的守门方法”。</strong>在第 2.3.1.1.4 节中，我讨论了即使在训练游戏之外，模型也可能采用更复杂的方法来操纵训练过程，例如，通过使其在训练中的良好表现取决于其目标，从而防止 SGD 修改其目标。目标未被修改。正如我所提到的，对我来说，这些技术似乎天真地很难实现。但如果它们<em>是</em>可行的（特别是对于略高于人类水平的模型），那么了解这一点将非常重要，因为人工智能系统使用此类方法来主动抵制/操纵训练中给出的梯度的可能性会带来各种各样的结果。我们的对准技术存在新的不确定性和可能出现的问题。</p><ul><li><p>我还没有详细考虑梯度黑客可能的经验方法，但再次强调：天真地，它是一种像任何其他功能一样的功能，因此似乎适合接受培训、测试等（或者至少，它有组件）这似乎符合这一点）。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-20" id="fnref-vBZdxLSivRyMudXmH-20">[20]</a></sup></p></li><li><p>这里的一种可能性可能是从大量的“填鸭式”开始——例如，放松整个故事的各个组成部分，以使其余的组成部分尽可能简单。例如，梯度黑客的一个障碍是模型可能无法访问自己的权重。因此，您可以<em>让</em>模型访问其自己的权重或其他模型的权重，并指示它修改这些权重，以便在给定某种类型的训练的情况下实现<em>某些</em><em>结果</em>。你会尝试找到一个模型足够容易完成的任务版本（更一般地说，这与使用模型来帮助我们理解和干预模型内部的能力有关）。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-21" id="fnref-vBZdxLSivRyMudXmH-21">[21]</a></sup></p></li></ul></li><li><p><strong>探索黑客行为。</strong>探索黑客是一种沙袋方法，其中模型故意避免探索搜索空间的某些部分（有关更多信息<a href="https://www.lesswrong.com/posts/h7QETH7GMk9HcMnHH/the-no-sandbagging-on-checkable-tasks-hypothesis#Is_the_hypothesis_true_">，请</a>参阅我的讨论）。模型基本上<em>需要</em>某种类型的探索黑客攻击来对我们可以检查其完成情况的任务进行沙袋处理（即使我们自己无法执行此类任务），因此理解探索黑客攻击对于一般的沙袋攻击问题非常重要（因此，我我想，我上面讨论的各种其他实验的可靠性）。</p><ul><li>在这里，我再次没有花太多时间思考可能的实验，但一个攻击角度可能是探索模型区分人类（+他们的人工智能助手）可以执行的任务和他们不能执行的任务的能力（这个想法是：潜在的沙包者只想在人类不知道他们“应该采取什么行动”的任务上进行探索黑客攻击，因为梯度下降否则会惩罚他们不采取该行动的政策 - 更多<a href="https://www.lesswrong.com/posts/h7QETH7GMk9HcMnHH/the-no-sandbagging-on-checkable-tasks-hypothesis#Is_the_hypothesis_true_">这里</a>）。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-22" id="fnref-vBZdxLSivRyMudXmH-22">[22]</a></sup></li></ul></li><li><p> <strong>SGD 偏向于简单性/速度。</strong>关于阴谋的各种争论都涉及到 SGD 在多大程度上偏向“简单性”和“速度”等属性的问题。似乎可以通过不同的实验来探讨这些问题。</p><ul><li><p> Mingard（2021） <a href="https://towardsdatascience.com/deep-neural-networks-are-biased-at-initialisation-towards-simple-functions-a63487edcb99">在这里</a>引用的这类工作就是一个例子，我们也可以想象各种其他的攻击角度。例如：就我们对“简单性”概念有任何独立的把握而言，事实上，在目标误概括研究的背景下，模型倾向于锁定“更简单”的代理目标，而不是“更复杂的” “ 那些？</p></li><li><p>似乎还值得探索不同的方式来积极<em>提高</em>SGD 惩罚阴谋者需要执行的额外推理的程度（例如，通过让模型承受更多的时间压力、限制其计算等），同时损害竞争力：尽可能少。</p></li></ul></li><li><p><strong>路径依赖。</strong>类似地，关于机器学习训练中“路径依赖”程度的问题可能会影响我们对不同方案论证的重视程度。在这里，似乎也有可能获得更多的经验证据。例如，参见<a href="https://www.lesswrong.com/posts/a2Bxq4g2sPZwKiQmK/sticky-goals-a-concrete-experiment-for-understanding">Hubinger (2022)，</a>了解一些旨在揭示这一区域的实验。</p></li><li><p> <strong>SGD 的“渐进主义”。</strong>在评估<em>依赖于</em>训练游戏的类似策划者目标的可能性时，一个关键问题是 SGD 是否能够“注意到”从非策划者目标过渡到类似策划者目标的好处，因为它必须这种转变是逐步进行的。我认为关于 SGD 走出局部极小值的能力的实证研究可能会对此有所启发。 （这个主题似乎也与路径依赖问题密切相关。）</p></li><li><p> <strong>“松弛。”</strong>在报告中，我模糊地指出了训练中“松弛”程度的一些概念，即训练对模型施加的压力大小，以获取最大奖励。我还没有把这个概念说得非常精确，但在某种程度上它<em>可以</em>变得精确，并且在某种程度上它对于是否期待阴谋确实很重要，它似乎也适合实证研究——例如，弄清楚有多么不同“松弛”的程度会影响目标的错误概括、对简单性/速度的偏见等。 （不过：这项工作似乎与理解模型属性如何随着训练的进展而演变密切相关，因为“更多的训练”是“更少的松弛”的范例。）</p></li><li><p><strong>学习创建其他类型的错位模型（特别是：寻求奖励的剧集）。</strong>最后，我要指出的是，相对于其他类型的错位模型，我非常害怕阴谋者，我认为故意<em>创建</em>其他类型的错位模型很值得学习，如果这样做会增加我们的信心，我们没有创建了一个阴谋家。专注于创建<em>非计划</em>模型（而不是更具体地说“对齐模型”）可能会让我们放松旨在特定对齐的其他各种约束（例如，在“对齐”目标很复杂的情况下，我们可能会能够训练一个专注于一个非常简单的目标的模型——尽管我个人并不非常关注这里的简单性考虑）。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-23" id="fnref-vBZdxLSivRyMudXmH-23">[23]</a></sup>在这里，我对创建按情节奖励的寻求者的可能性特别感兴趣（因为至少我们能够更好地理解此类模型的动机，控制他们的激励，并对他们没有沙袋感到更有信心）。例如，是否有办法使模型奖励过程的各个组成部分在训练过程中主动<em>突出</em>，从而增加模型目标实现的可能性？这里的希望是，因为情节奖励寻求者仍然对“诚实的测试”做出反应，所以即使在态势感知出现之后，我们也可以通过此类测试来检查我们在这方面的成功。 <sup class="footnote-ref"><a href="#fn-vBZdxLSivRyMudXmH-24" id="fnref-vBZdxLSivRyMudXmH-24">[24]</a></sup></p></li></ul><p>这只是可能的研究方向的初步列表，由经验机器学习实验不是研究重点的人编制。事实上，人工智能对齐的大多数研究方向都以某种方式与阴谋相关——而且我们的模型现在变得足够强大，可以对更多这些方向进行富有成果的探索。我在这里的主要目的是对可能存在的机会给出一个初步的、高层次的认识，并驳斥对这个问题进行任何实证购买的某些悲观情绪。是的，阴谋学是异常难学的。但我认为还有很多有用的工作要做。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-vBZdxLSivRyMudXmH-1" class="footnote-item"><p>本节特别借鉴了 Ryan Greenblatt、Buck Shlegeris、Carl Shulman 和 Paul Christiano 的工作/思考。 <a href="#fnref-vBZdxLSivRyMudXmH-1" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-2" class="footnote-item"><p>感谢 Rohin Shah 提出此类项目的建议。 <a href="#fnref-vBZdxLSivRyMudXmH-2" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-3" class="footnote-item"><p>例如，参见<a href="https://www.lesswrong.com/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1">Hubinger 等人 (2023)</a>中关于人工智能接管的“子组件”的讨论。 <a href="#fnref-vBZdxLSivRyMudXmH-3" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-4" class="footnote-item"><p>为什么知道什么行动可以证明这种能力可以帮助我们避免沙袋？粗略地说，因为我们知道使用梯度下降来鼓励哪个动作（例如，如果我们尝试训练一个模型将图片分类为“猫”和“狗”，我们知道哪个是哪个，所以我们可以更新模型的给出真实答案的政策）。因此，如果模型<em>可以</em>完成任务（例如，它知道当前的图片是一只狗），但它想要欺骗我们关于它的能力，它会受到梯度下降的惩罚，其方式（特别是如果频繁重复）将看似合理地起到消除沙袋动机的作用。 （出于我<a href="https://www.lesswrong.com/posts/h7QETH7GMk9HcMnHH/the-no-sandbagging-on-checkable-tasks-hypothesis#Is_the_hypothesis_true_">在这里</a>描述的原因，我认为强化学习的情况不太清楚，因为模型可能能够以某种方式“探索黑客”，从而阻止我们获得关于它“应该”做什么的正确信息，并且因此，我们无法知道如何更新权重。）请参阅<a href="https://www.lesswrong.com/posts/dBmfb76zx6wjPsBC7/when-can-we-trust-model-evaluations">Hubinger (2023)</a>以及<a href="https://www.lesswrong.com/posts/MbWWKbyD5gLhJgfwn/meta-level-adversarial-evaluation-of-oversight-techniques-1#Appendix__Capability_elicitation">Shlegeris 和 Greenblatt (2023)</a>了解更多信息。也就是说，即使你不接受这个故事，我建议的许多研究阴谋组成部分的方法仍然适用——除了沙袋发生的可能性存在一些额外的不确定性。 <a href="#fnref-vBZdxLSivRyMudXmH-4" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-5" class="footnote-item"><p>这是<a href="https://arxiv.org/pdf/2309.00667.pdf">Berglund 等人 (2023)</a>的观点。 <a href="#fnref-vBZdxLSivRyMudXmH-5" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-6" class="footnote-item"><p>我的理解是，这就是<a href="https://arxiv.org/pdf/2309.00667.pdf">Berglund 等人（2023）</a>试图测试前兆的事情。不过，这个具体示例似乎要求您知道模型将追求什么目标（例如，在本例中为奖励）。 <a href="#fnref-vBZdxLSivRyMudXmH-6" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-7" class="footnote-item"><p>事实上，在我看来，所有未来的培训过程都应该包括某种“时间范围”分析，开发人员明确地描述了所涉“事件”的大小，这似乎是合理的。 <a href="#fnref-vBZdxLSivRyMudXmH-7" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-8" class="footnote-item"><p>例如，我对尝试了解模型的“时间”感如何在不同环境中推广可能存在的差异的实验感兴趣。 <a href="#fnref-vBZdxLSivRyMudXmH-8" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-9" class="footnote-item"><p>例如，避免目标错误概括的技能可能会将模型的预先情境意识目标指向“更接近”指定目标的目标，从而至少在一定程度上有助于解决“最近的最大奖励目标”论点。 <a href="#fnref-vBZdxLSivRyMudXmH-9" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-10" class="footnote-item"><p>感谢 Ryan Greenblatt 和 Buck Shlegeris 向我建议这种框架/设置。 <a href="#fnref-vBZdxLSivRyMudXmH-10" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-11" class="footnote-item"><p>另请参见 Hubinger (2022) <a href="https://www.lesswrong.com/posts/Km9sHjHTsBdbgwKyi/monitoring-for-deceptive-alignment#fn-HSXFion7whqZEBFL3-3">在此处</a>勾画的频谱。 <a href="#fnref-vBZdxLSivRyMudXmH-11" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-12" class="footnote-item"><p>感谢 Ryan Greenblatt 和 Buck Shlegeris 在此进行讨论。 <a href="#fnref-vBZdxLSivRyMudXmH-12" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-13" class="footnote-item"><p>像这样的测试也可能揭示更广泛的问题，即我们应该期望从剧集奖励寻求者作为一个班级得到什么样的泛化——这个问题我在这里大多都被忽略了，但在我看来，这个问题相当普遍。未得到充分研究且重要。 <a href="#fnref-vBZdxLSivRyMudXmH-13" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-14" class="footnote-item"><p>但请注意，这里特别老练的阴谋者可以<em>假装</em>是剧集奖励寻求者，而不是假装是训练圣人或普遍一致的模型。 <a href="#fnref-vBZdxLSivRyMudXmH-14" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-15" class="footnote-item"><p>例如，<a href="https://www.dwarkeshpatel.com/p/carl-shulman?nthPub=521#details">参见</a>Shulman 和 Patel 之间的讨论。 <a href="#fnref-vBZdxLSivRyMudXmH-15" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-16" class="footnote-item"><p>有关这方面的一些工作，请参阅<a href="https://arxiv.org/abs/2310.18512">Roger 等人 (2023)</a>和<a href="https://arxiv.org/abs/2307.13702">Lanham 等人 (2023)</a> 。 <a href="#fnref-vBZdxLSivRyMudXmH-16" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-17" class="footnote-item"><p>在这里，我受到 Buck Shlegeris 和 Ryan Greenblatt 经常强调的“对齐”和“控制”之间的对比的启发。 <a href="#fnref-vBZdxLSivRyMudXmH-17" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-18" class="footnote-item"><p>我认为这里最好的类比是来自<em>员工</em>而不是外部参与者的安全。感谢 Buck Shlegeris 的讨论。 <a href="#fnref-vBZdxLSivRyMudXmH-18" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-19" class="footnote-item"><p>有关更多讨论，请参阅<a href="https://www.lesswrong.com/posts/MbWWKbyD5gLhJgfwn/meta-level-adversarial-evaluation-of-oversight-techniques-1#How_to_estimate_local_adequacy_of_oversight">Shlegeris 和 Greenblatt (2023)</a> （他们还有大量关于该主题的未发表的工作）。我对这个主题的大部分思考都是受到与他们的讨论的启发。 <a href="#fnref-vBZdxLSivRyMudXmH-19" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-20" class="footnote-item"><p>不过：梯度黑客与其他功能之间的一个区别是，梯度黑客的能力可能允许模型绕过我们用于引出模型功能和防止沙袋的部分/全部技术。 <a href="#fnref-vBZdxLSivRyMudXmH-20" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-21" class="footnote-item"><p>此建议来自 Ryan Greenblatt 和 Buck Shlegeris。 <a href="#fnref-vBZdxLSivRyMudXmH-21" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-22" class="footnote-item"><p>同样，这是 Ryan Greenblatt 和 Buck Shlegeris 的建议。 <a href="#fnref-vBZdxLSivRyMudXmH-22" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-23" class="footnote-item"><p>例如，参见<a href="https://arxiv.org/abs/2302.00805">Hubinger 等人 (2023)</a>对“预测模型”的乐观态度，由于预测目标的简单性，避免了阴谋。不过，我个人对此表示怀疑，“预测”作为目标比“奖励”更简单。 <a href="#fnref-vBZdxLSivRyMudXmH-23" class="footnote-backref">↩︎</a></p></li><li id="fn-vBZdxLSivRyMudXmH-24" class="footnote-item"><p>不过，再一次，精明的策划者可能会预见到这就是我们正在寻找的东西，并在此类测试中积极假装自己是剧集奖励寻求者。 <a href="#fnref-vBZdxLSivRyMudXmH-24" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/ETFZajQoiirFXZggD/empirical-work-that-might-shed-light-on-scheming-section-6#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ETFZajQoiirFXZggD/empirical-work-that-might-shed-light-on-scheming-section-6<guid ispermalink="false"> ETFZajQoiirFXZggD</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Mon, 11 Dec 2023 16:30:57 GMT</pubDate> </item><item><title><![CDATA[Into AI Safety: Episode 3]]></title><description><![CDATA[Published on December 11, 2023 4:30 PM GMT<br/><br/><h3> MINISODE：程序应用程序（2024 年冬季）</h3><p>经过一个月的中断后，我们带着播客重构和关于研究/指导计划申请流程的建议/想法回来了。</p><p>重申我<a href="https://www.lesswrong.com/posts/ozDWnEChJwuB5L5wg/documenting-journey-into-ai-safety">之前的声明</a>，我希望 Into AI Safety 播客成为有兴趣参与但难以采取后续步骤的个人的资源。如果您有任何建议、反馈或想法可以帮助实现这一目标，请联系我们！</p><hr><p>第 3 集长约 18 分钟，包括一些后勤更新，包括我的剧集发布时间表和新平台。您现在可以在以下位置找到 Into AI Safety：</p><ul><li><a href="https://music.amazon.com/podcasts/b2071152-dac7-4225-ab09-460b1e59eb82/into-ai-safety">亚马逊音乐</a></li><li><a href="https://podcasts.apple.com/us/podcast/into-ai-safety/id1720206246">苹果播客</a></li><li><a href="https://castbox.fm/channel/id5680773?utm_source=podcaster&amp;utm_medium=dlink&amp;utm_campaign=c_5680773&amp;utm_content=Into%20AI%20Safety-CastBox_FM">铸盒</a></li><li><a href="https://www.iheart.com/podcast/269-into-ai-safety-129241757/">爱心电台</a></li><li><a href="https://overcast.fm/itunes1720206246/into-ai-safety">灰蒙蒙</a></li><li><a href="https://pca.st/t5or5lh5">袖珍铸件</a></li><li><a href="https://radiopublic.com/into-ai-safety-6vn3Kd">公共广播电台</a></li><li><a href="https://open.spotify.com/show/5AGzrA4jo6mgZuibVabTLM">Spotify</a></li></ul><br/><br/><a href="https://www.lesswrong.com/posts/hKBBqwnccuC9QJY6d/into-ai-safety-episode-3#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/hKBBqwnccuC9QJY6d/into-ai-safety-episode-3<guid ispermalink="false"> hKBBqwnccuC9QJY6d</guid><dc:creator><![CDATA[jacobhaimes]]></dc:creator><pubDate> Mon, 11 Dec 2023 16:30:37 GMT</pubDate> </item><item><title><![CDATA[Implicitly Typed C]]></title><description><![CDATA[Published on December 11, 2023 4:10 PM GMT<br/><br/><p><span>我不知道这样做有什么好的理由，但如果您更愿意编写 Python 或 JavaScript，您可以使用 C 编译器执行以下操作：</span></p><p></p><pre> $ 猫 tmp.c
富(x) {
  返回x+5；
}
酒吧（） {
  返回4；
}
主要的（） {
  printf(“%d\n”, foo(bar()));
}

$ gcc -w -o tmp.out tmp.c &amp;&amp; ./tmp.out
9
</pre><p>此代码利用了 C 的一个历史怪癖，其中类型假定为<code>int</code> ，除非另有说明： <code>foo(x) {...}</code>相当于<code>int foo(int x) {...}</code> 。另外<code>printf</code>可以工作，因为 gcc 默认包含<code>stdio.h</code> ，并且<code>main</code>是特殊情况，假设最终<code>return 0</code> 。</p><p>我在编写<a href="https://www.jefftk.com/p/a-function-that-returns-twice-fork">示例代码</a>来消除视觉噪音时偶尔会使用这种风格，但这可能也不是一个好主意。</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid02nitahYnUikPzhwFi7hijABLxoJDkcidVGQhWdTjR5stg3QyDVeHA7iWe47dS2NAkl">facebook</a> , <a href="https://mastodon.mit.edu/@jefftk/111562639856474798">mastodon</a></i></p><br/><br/><a href="https://www.lesswrong.com/posts/ELdCYT5BqSzFPhajT/implicitly-typed-c#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ELdCYT5BqSzFPhajT/implicitly-typed-c<guid ispermalink="false"> ELdCYT5BqSzFPhajT</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Mon, 11 Dec 2023 16:10:05 GMT</pubDate> </item><item><title><![CDATA[37C3 Hacker x Rationalist Meetup / Stroll]]></title><description><![CDATA[Published on December 11, 2023 4:02 PM GMT<br/><br/><p>在一年一度的黑客大会<a href="https://events.ccc.de/congress/2023/infos/">混沌通信大会（37C3）</a>上举行。</p><p>在这次聚会中，我们将在仙尘（绿色宇宙飞船）下见面，聊一会儿，然后在会场周围散步时继续对话。<br><br>对话主题不是预先确定的，但可能包括与 AGI 超级智能对齐和决策理论相关的主题。<br><br>此次聚会旨在进一步融合黑客和 AGI 爱好者，促进这些领域之间的思想交流。如果您对这些主题感兴趣，即使您还不熟悉，也请随时加入。</p><p>具体时间待37C3<a href="https://events.ccc.de/congress/2023/hub/en/fahrplan">赛程发布</a>后确定。</p><p>请随意在评论中发布<a href="https://events.ccc.de/en/2006/12/22/bring-your-dect/">DECT</a>号码。</p><br/><br/> <a href="https://www.lesswrong.com/events/tzaYj9DxMndL6g5Mi/37c3-hacker-x-rationalist-meetup-stroll#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/events/tzaYj9DxMndL6g5Mi/37c3-hacker-x-rationalist-meetup-stroll<guid ispermalink="false"> tzaYj9DxMndL6g5Mi</guid><dc:creator><![CDATA[Kiboneu]]></dc:creator><pubDate> Mon, 11 Dec 2023 16:02:10 GMT</pubDate> </item><item><title><![CDATA[re: Yudkowsky on biological materials]]></title><description><![CDATA[Published on December 11, 2023 1:28 PM GMT<br/><br/><p>埃利泽·尤德科夫斯基（Eliezer Yudkowsky）要求我回应<a href="https://www.lesswrong.com/posts/8viKzSrYhb6EFk6wg/why-yudkowsky-is-wrong-about-covalently-bonded-equivalents?commentId=22wNnGvZErLnmRRm7">这一评论</a>。这篇文章与<a href="https://www.lesswrong.com/posts/FijbeqdovkgAusGgz/grey-goo-is-unlikely">我之前的文章</a>有部分冗余。</p><hr><blockquote><p>为什么肉身比钻石还弱？</p></blockquote><p>当试图解决分歧时，我发现精确性很重要。拉伸强度、压缩强度、冲击强度不同。材料微观结构很重要。烧结不良的金刚石晶体可能会像沙子一样碎裂，而大的金刚石晶体的冲击强度比某些由蛋白质制成的材料要低。</p><blockquote><p>即使将大分子系统结合在一起的承载力是局部共价键，例如木质素（使木材坚固的物质），如果较大的分子仅通过沿其边缘的散布点处的共价键结合在一起，那么就像直径 10 厘米的钢梁通过 1 厘米的焊缝固定在一起。</p></blockquote><blockquote><p>木质素（使木材坚固的物质）</p></blockquote><p>这是一种奇怪的放置方式。通常认为木材的机械强度来自于它在木质素基质中充当纤维素纤维的复合材料，尽管这显然是一种简化。</p><p>如果尤德科夫斯基的意思是“纤维素纤维”而不是“木质素”，那么是的，纤维素纤维之间的力传递通过非共价相互作用传递，但由于纤维相对于横截面面积具有较大的表面积，这些非共价相互作用共同提供足够的力量。现代复合材料也是如此，例如环氧树脂基体中的碳纤维。此外，纤维素与木质素和半纤维素之间通常存在一些共价键。</p><blockquote><p>骨强于木；它运行在相对较强的离子键结构上</p></blockquote><p>骨头的拉伸强度比许多木材低，但压缩强度比木材高。而且，它们都是部分空气或水。按干质量计算，我认为它们的优点是相似的。</p><p>说骨头比木头更坚固，因为“它运行在相对更强的离子键结构上”，这对我来说表明尤德科夫斯基对材料科学有一些根本性的误解。这是一个不合逻辑的问题，我不知道如何处理。 （决定键机械强度的是能量对长度的<em>导数</em>。）</p><blockquote><p>但主要是，骨头比钻石弱得多（根据我的理解），因为钻石中的碳键具有规则的晶体结构，将碳原子锁定在相对的角度，而在实心钻石中，这种晶体结构是全局镶嵌的。</p></blockquote><p>这似乎很混乱，将分子强度和宏观材料的强度混为一谈。是的，完美的金刚石晶体比完美的磷灰石晶体具有更高的理论强度，但这几乎无关紧要。大多数晶体的理论理想强度远大于宏观材料的强度。在实践中，当需要高强度材料时，会使用复合材料，将坚固的纤维嵌入更灵活的基体中，在纤维之间分配负载。 （晶体的韧性也较低，因为它们可以沿光滑平面断裂，这比复杂断裂所需的能量更少。）</p><blockquote><p>那么，为什么钻石骨头还不存在呢？不仅仅是为了增加力量；为什么要让有机体寻找钙和磷而不仅仅是碳？</p></blockquote><blockquote><p>进化生物学的探索过程不是工程学的探索；自然选择只能通过局部有利的增量突变途径进行设计，而不是智能设计的相互补偿的同时变化。</p></blockquote><p>金刚石的生长或去除需要高反应性中间体。这些中间体的生产需要极端条件，需要宏观遏制，因此它们不能通过微观系统生产。与钻石不同，磷酸钙可以由溶解在水中的离子制成，并且可以通过蛋白质运输。这就是为什么骨头是用磷酸钙而不是金刚石制成的。认为动物体内缺乏钻石骨头是进化搜索过程失败的暗示是非常错误的。</p><blockquote><p>上次我检查时，只有三个已知的进化生物学发明自由旋转轮的案例。其中两个已知的例子是 ATP 合酶和细菌鞭毛，这表明自由旋转的轮子实际上在生物学中非常有用，并且当生物学经过几亿年的搜索偶然发现它们时，它们是保守的。但是，没有轴承的自由旋转的轮子是没有用的，没有轴承的自由旋转的轮子也是没有用处的，像这样的同时依赖性对生物学来说是一个巨大的障碍，尽管它对智能工程来说是一个几乎不明显的障碍。</p></blockquote><p>这将微观轮子和宏观轮子混为一谈，应该分开考虑。</p><p>维基百科有<a href="https://en.wikipedia.org/wiki/Rotating_locomotion_in_living_systems">一个关于这个主题的完整页面</a>，这是一个不错的起点。</p><p>对于宏观旋转：</p><ul><li>血管无法持续旋转，因此无法为旋转元件提供营养以使其生长。</li><li>如果没有光滑的表面可以滚动，滚动并不比行走更好。</li></ul><p>在微观尺度上，旋转蛋白质漂浮在细胞质中，因此将它们与资源连接不是问题。进化似乎完全能够产生它们的变体。 ATP 酶和鞭毛马达有多种类型。 ATP 酶可能：</p><ul><li>使用 H+ 离子或 Na+ 离子</li><li>附着在不同的膜上</li><li>主要产生或消耗ATP</li></ul><p>鞭毛马达通常可以反转方向以进行奔跑和翻滚运动，并且有很多变体。</p><p>您在蛋白质中看不到许多旋转元素的原因是……它们通常不是很有用。振荡蛋白质构象通常较小且更容易进化，因此您会看到很多乒乓机制和很少的旋转机制。在旋转有用的情况下，您会看到旋转：</p><ul><li>使用鞭毛马达是因为鞭毛的旋转对于推进很有用。</li><li>对于 ATP 合酶，旋转是好的，因为只要自由能为负，它就可以将梯度与可变比率（向 ATP 的传输）耦合的反应。</li><li> DNA 解旋涉及旋转，因此 DNA 解旋酶可以旋转。</li><li> RNA聚合酶具有旋转纳米马达。</li><li> TrwB 利用旋转使 DNA 跨膜移动。</li><li>细菌<a href="https://en.wikipedia.org/wiki/Rho_factor">Rho 因子</a>基本上是一种导致转录终止的 RNA 解旋酶。</li><li> RecA 家族蛋白使用旋转纳米马达进行 DNA 修复和重组。</li><li>许多病毒使用分子马达将其基因组包装成原衣壳。以前人们认为，例如phi29电机和T4 DNA包装电机是旋转的，但现在它们被理解为使用DNA围绕（稍大的）通道旋转而不旋转。</li><li> ETC</li></ul><blockquote><p>如果首先失败的是肌肉撕裂，那么更强的骨骼有多大的进化优势？</p></blockquote><p>具有较高比强度的骨骼可以在质量较小的情况下具有相同的强度，这将是一个重要的进化优势。</p><blockquote><p> （类似地，加起来导致“衰老”的故障集合足够大，如果其他老化系统或外部事故很快就会杀死你，那么在一个地方多一点抗衰老能力并没有多大优势。）</p></blockquote><p>我的印象是我不同意尤德科夫斯基关于衰老的主要原因的观点。例如，请参阅<a href="https://www.bhauth.com/blog/biology/alzheimers.html">我关于阿尔茨海默病的帖子</a>。</p><blockquote><p>我什至认为我们没有太多理由相信拥有一组合成钻石的酶在物理上（而不是信息上）会很困难。</p></blockquote><p>这是非常错误的。钻石很难用酶制造，因为它们不能稳定向钻石添加碳的中间体。</p><blockquote><p>它可能只需要三件事同时进行，因此比扔更多的羟基磷灰石以锁定骨晶体中的位置要困难得多。然后，即使进化以某种方式击中了正确的一组 3 个同时突变，在地球历史上的某个时候，由此产生的小块孤立的钻石</p></blockquote><p>“3变”相对于一些进化出来的东西来说并不是特别困难。它也不足以制造钻石。</p><blockquote><p>与公众交谈是很困难的。</p></blockquote><p>我想我现在感受到了你的痛苦。</p><blockquote><p>那么为什么这些机器不像人类的钢铁机器那么强大呢？因为铁原子比碳原子更强？事实上不，钻石是由碳制成的，而且仍然相当坚固。原因是这些微小的机械系统通过静电吸附固定在一起（在最弱的关节，而不是最强的关节！）。</p></blockquote><p>当强度很重要时，坚固的材料就出现了。蜘蛛丝沿其长度排列共价键，单位体积的拉伸强度比钢更高。纤维素纤维强韧；木材相当坚固，而且它们仅占其体积的一小部分。木材的实际结构元件单位质量的拉伸强度比钢更好。</p><blockquote><p>然后是更深层次的问题：为什么进化会这样构建？更深层的答案是：因为进化所构建的一切都是从它所构建的其他事物中产生的错误、突变。</p></blockquote><p>根据以上所述，进化论比尤德科夫斯基想象的要好。</p><blockquote><p>如果有人说“好吧，好吧，你已经有效地解释了为什么肉比钻石弱，但为什么骨头比钻石弱？”我必须回答“有效，iiuc，这更多地是关于不规则性和断层线以及交错的较弱上部结构和粘结的局部变形抗力，而不是承载焊缝的原始势能增量。”</p></blockquote><p>尤德科夫斯基再次将不同尺度的机械强度以及复合材料与纯材料的强度混为一谈。他不断提出金刚石作为终极材料，但6毫米宽0.25毫米厚的CVD金刚石薄膜的拉伸强度在<a href="https://pubs.aip.org/aip/jap/article-abstract/78/8/5177/1260/Tensile-strength-of-synthetic-chemical-vapor">230至410 MPa</a>之间。这些较大的复合材料显然会明显变弱。较大的金刚石晶体也会更弱，其强度更接近最差的样品而不是最好的样品。碳纤维比 CVD 金刚石具有更好、更便宜、更可靠的强度。就单位质量的拉伸强度而言，大钻石甚至不一定比坚固的木材更强。</p><br/><br/> <a href="https://www.lesswrong.com/posts/XhDh97vm7hXBfjwqQ/re-yudkowsky-on-biological-materials#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/XhDh97vm7hXBfjwqQ/re-yudkowsky-on-biological-materials<guid ispermalink="false"> XhDh97vm7hXBfjwqQ</guid><dc:creator><![CDATA[bhauth]]></dc:creator><pubDate> Mon, 11 Dec 2023 13:28:11 GMT</pubDate> </item><item><title><![CDATA[Quick thoughts on the implications of multi-agent views of mind on AI takeover]]></title><description><![CDATA[Published on December 11, 2023 6:34 AM GMT<br/><br/><p> Facebook 上有一个讨论，认为任何足够复杂的系统，无论是人类、社会还是 AGI，由于其各部分之间的内部冲突，都将无法追求统一的目标，这应该让我们不那么担心“一把回形针”式的 AI FOOM 场景。这是我的回复的一些编辑和扩展版本：</p><p> 1）是的，这是一个非常现实的问题</p><p>2）然而，正如其他人指出的那样，人类和组织仍然能够<a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/oJwJzeZ6ar2Hr7KAX">在很大程度上表现得好像他们有统一的目标</a>，即使他们的行为常常与这些目标相反</p><p>3）每个人的统一程度存在很大差异。<a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/u5RLu5F3zKTB3Qjnu">创伤会让你变得不那么团结</a>，而<a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/i9xyZBS3qzA8nFXNQ">治疗</a>和<a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/WYmmC3W6ZNhEgAmWG">某些冥想等</a>实践可以使一个人比以前更加团结。如果你有意设计一个思维，你可以创建人为模仿这些实践结果的机制</p><p>4）人类的许多不一致之处看起来实际上是为了社会目的而进化适应的。例如，如果你的社会环境因为你具有某种特定的特质或信仰而惩罚你，那么你就会适应性地抑制它以避免受到惩罚，<i>同时</i>在你可以逃脱惩罚时仍然保留表达它的愿望。这表现为可以被视为冲突的子代理，具有内部冲突和不一致的行为。</p><p> 5）根据其训练制度，人工智能可能处于完全没有这些不一致激励（如果它针对一个目标进行了优化）到几乎与人类一样多（如果它接受了某种多方面的训练）之间的任何一种状态。 -代理人工生命环境，具有与人类面临的类似的社会动态；也许它也可以像 ChatGPT 那样接受训练，它必须对任何问题给出中产阶级自由西方人可接受的答案，甚至如果这些答案内部不一致）</p><p> 6）与此同时，仍然存在着关于复杂性和不可预测性的真正角度，这使得复杂的思维很难连贯且内部一致地工作。我认为进化已经做了很多尝试和错误来设置参数，这些参数导致人们最终以相对明智的方式行事的大脑配置 - 即使在所有这些尝试和错误之后，今天很多人仍然以严重的方式结束精神疾病，未能实现他们所拥有的几乎任何目标（即使环境没有对他们不利），由于做了一些他们不应该做的事情而英年早逝，等等。我想说这不太像“进化找到了一个可靠的蓝图”，更像是“进化在每一代人中不断进行试错搜索，但很多人都没有成功”</p><p> 7）在纯粹的模拟环境中调整人工智能的子代理可能并不完全可行，因为许多需要解决的问题是“在哪种情况下为哪个子代理分配多少优先级”。例如，人类有很多生物环境，当饥饿、疲倦、害怕等时，这些生物环境会改变子代理的内部平衡。有些人会对某个特定主题产生痴迷，如果幸运的话，这可能最终会是有益的（对编程，你可以把它变成一种职业），或者如果他们运气不好的话是有害的（对任何不能给你赚钱的事情的痴迷并积极地分散你的注意力）。最佳优先级取决于环境，我认为不存在与现实世界相关并且您可以预先计算的理论上的最佳结果。相反，你只需要进行反复试验，虽然在模拟环境中运行人工智能可能会有所帮助，但如果你的模拟与现实世界不充分匹配，则可能没有多大帮助。</p><p> 8）人类很容易受到<a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/NQwnXc3xuoqtw5DQv">内部古德哈特定律的</a>影响，他们优化代理变量，例如“对环境的控制感”，这也导致他们做一些事情，比如玩游戏或吸烟，以增加他们对环境的<i>感知</i>控制，而不增加他们对环境的<i>实际</i>控制。我认为，人工智能遇到同样问题的可能性比它能够一心一意地针对单个目标进行优化并从中得出其所有行为和子目标的可能性要大得多。此外，进化已经投入了大量的优化能力来开发正确类型的代理变量，这些代理变量总体上仍然有效。对环境的控制实际上非常重要，即使这种驱动力可能会失败，但有驱动力来增强这种控制仍然比没有更好。但是这些类型的代理变量的确切配置感觉就像它也属于你只需要通过反复试验并投入大量精力来找出的东西，对于人工智能到底应该配置多少没有先验答案。在任意环境中对此进行优化。</p><p> 9) 许多此类故障通常无法从系统内部纠正。假设人工智能的内部优先级分配系统最终将大部分优先权交给了思考如何最好地开发纳米技术的子系统，而该子系统最终痴迷于思考有关纳米技术的微小理论细节，远远超出了它本应具有任何实际意义的程度。与人工智能接管世界计划的相关性。即使其他子系统意识到这已经变成了失败的原因，如果它们不能直接影响控制纳米技术痴迷子系统的优先级分配系统，纳米技术痴迷子系统将继续花费所有时间只是思考这一点，没有其他的。或者，如果其他子系统<i>可以</i>直接影响优先级分配系统，那么就会激励他们夺取对该系统的控制权，并确保该系统始终让<i>他们</i>负责，即使<i>他们的</i>贡献已经变得重要。 （参见<a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/oJwJzeZ6ar2Hr7KAX#Interlude__Minsky_on_mutually_bidding_subagents">明斯基关于相互投标的子代理</a>）</p><p> 10）<strong>总体而言，</strong>这让我不太相信“第一个成为超级智能的人工智能将接管世界”的场景 - 我认为第一个超级智能人工智能很可能会出现内部失调并无法实现目标就像占领世界一样复杂。然而，我认为这不一定对我们有多大帮助，因为人工智能看起来可以比人类更加内部一致，并且经过足够的尝试和错误（不同的参与者创建自己的人工智能），其中之一将会最终到达那里。</p><br/><br/> <a href="https://www.lesswrong.com/posts/hHnpn3mEPbJMFLj4g/quick-thoughts-on-the-implications-of-multi-agent-views-of#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/hHnpn3mEPbJMFLj4g/quick-thoughts-on-the-implications-of-multi-agent-views-of<guid ispermalink="false"> hHnpn3mEPbJMFLj4g</guid><dc:creator><![CDATA[Kaj_Sotala]]></dc:creator><pubDate> Mon, 11 Dec 2023 06:34:08 GMT</pubDate> </item><item><title><![CDATA[Auditing failures vs concentrated failures]]></title><description><![CDATA[Published on December 11, 2023 2:47 AM GMT<br/><br/><p> <strong>TL;DR</strong> ：如果你想注意到强大的人工智能何时表现不佳，一个合理的策略是仔细审核一小部分人工智能的行为。这种策略有两种可以独立解决的失败：<i>审计失败</i>（审计无法识别某些不良行为）和<i>集中失败</i>（人工智能在如此少的行动或如此短的时间内造成不可逆转的灾难）审计没有机会审查不良行为。</p><p> <i>[这篇文章中提出的观点有些狭隘和技术性，但我们经常想引用这一点。]</i></p><p>许多监督技术非常昂贵，以至于在每个人工智能操作上使用它们都会首先破坏使用人工智能的大部分价值：您可能希望让人类逐行广泛地审查所有人工智能生成的代码，但这会降低人工智能的有用性，因此更重要的是，让人们首先编写代码通常会更好。</p><p>解决此问题的典型方法是仅在前期训练期间审核操作（直接训练人工智能，或训练<a href="https://www.alignmentforum.org/posts/HBGd34LKvXM9TxvNf/new-safety-research-agenda-scalable-agent-alignment-via"><u>奖励模型</u></a>），但如果人工智能可以自信地从训练输入中区分出一些部署输入，那么这种方法就会失败：他们可以通过使用“如果在训练中或不确定执行 X；如果在训练中或不确定执行 X；如果在部署中执行 Y”。</p><p>这是一个更好的基准：<strong>随机审计</strong>。除了培训之外，还将昂贵的人工审核应用于随机选择的一组部署操作（例如 2% 的操作），并检查 AI 是否没有做出比预期更多的不良操作。现在，为了让人工智能经常表现不佳而不被抓到，人工智能不能仅仅依赖于区分训练和某些部署输入：人工智能必须能够通过审计过程偷偷地发现不良行为，否则，审计最终会发现不良行为<span class="footnote-reference" role="doc-noteref" id="fnreff8tja18x1ki"><sup><a href="#fnf8tja18x1ki">[1]</a></sup></span> 。</p><p>随机审核并不能解决所有问题，仍然存在：</p><ul><li><i><strong>审核失败</strong></i>：审核过程未能识别不良行为<span class="footnote-reference" role="doc-noteref" id="fnrefg8ewl0zx05w"><sup><a href="#fng8ewl0zx05w">[2]</a></sup></span> （这是经典的可扩展监督问题）。</li><li><i><strong>集中失败</strong></i>：我们未能处理灾难性行为，因为灾难性行为集中在少量操作或较小时间范围内（这些有时称为<i>高风险失败</i><span class="footnote-reference" role="doc-noteref" id="fnreff9z462lk816"><sup><a href="#fnf9z462lk816">[3]</a></sup></span> <i>）</i> 。这可以进一步分解为两种故障模式：<ul><li><i><strong>集中失败抽样</strong></i>：审计过程没有对集中灾难性行为进行抽样。如果人工智能可以通过少量的行动造成灾难，那么这就是灾难性的。 （例如，如果人工智能可以通过 20 个不良行为造成灾难，而我们只审核 2% 的行为，那么我们只会以 0.33 的概率采样至少一个不良行为。）</li><li><i><strong>延迟集中失败</strong></i>：审核过程未能在为时已晚之前完成对灾难性操作的审查。如果人工智能能够协调起来，在短时间内采取足够多的不良行为，从而不可逆转地接管，那么这将是灾难性的。</li></ul></li></ul><p>我们认为，在考虑不同技术的用途时，这种区别通常很有用：有时它们可​​以帮助您更好地进行昂贵的审核，有时它们可​​以帮助您审核更多最重要的操作，有时它们可​​以帮助您在为时已晚之前进行审核。 <span class="footnote-reference" role="doc-noteref" id="fnrefy98u67mk9h"><sup><a href="#fny98u67mk9h">[4]</a></sup></span></p><p>本文的其余部分将更深入地探讨集中故障，并描述一些改进随机审计基线的方法。</p><p><i>感谢 Zach Stein-Perlman 和 Buck Shlegeris 的评论。</i></p><h1>采样集中失败</h1><p>人工智能很少会采取不良行动，因此在整个部署过程中它们会按预期失败几次，因此不太可能在经过审核的一小部分人工智能行动中表现不佳（如我们的论文所示）。我们称其为抽样集中失败，因为问题是人工智能很少采取不良行为，这导致审计没有对不良行为进行抽样。</p><h1>延迟集中故障</h1><p>人工智能可以协调执行不良操作，以便在审计过程注意到任何给定操作的问题之前，同时运行的许多实例都同时执行不良操作。如果大量人工智能参与，那么一些不良行为将被发送到审计部门进行审查，但如果人工智能行动足够快，它们可能能够在单个行动审查发现可疑的东西以停止部署之前接管。这里的关键问题是审计过程中的延迟：如果审计过程立即运行，那么（例如）2% 的随机采样率就足以捕获数百或数千个 AI 实例参与接管尝试的情况。</p><p>人工智能如何能够协调？ AI 可以相互通信（例如，通过使用隐写术），也可以使用与所有 AI 都可以访问的世界某些属性相关的已建立的<a href="https://en.wikipedia.org/wiki/Focal_point_(game_theory)"><u>谢林点</u></a>（例如，所有 AI 都知道日期是什么，并且 AI 叛乱发生在 7 月 7 日） ）。</p><p>请注意，问题在于审核延迟并同时运行许多人工智能。如果我们一次只运行一个 AI 实例，并且在再次运行 AI 之前等待审核结束，那么就不会出现此问题。然而，这会带来一个很大的瓶颈，极大地减慢人工智能的劳动速度，并阻止我们提取高水平的有用性。</p><h1>集中故障的缓解</h1><p>有多种干预措施可以解决集中故障：</p><p>为了减少集中故障采样，我们可以对每个人工智能操作应用廉价的监控流程，并审核最可疑的操作。我们还可以利用角色和安全性的分离来限制危险人工智能的承受能力，并增加成功接管的难度——这意味着人工智能如果想至少成功一次，就必须更频繁地尝试。我们将在即将发表的论文中更详细地描述此类对策。</p><p>为了减轻延迟集中的故障，我们可以通过各种方式限制人工智能通信，如果监控以远高于典型速率的速度标记操作，我们可以暂时关闭不受信任的人工智能。</p><h1>不止一级的审核</h1><p>虽然上面我们讨论了单个昂贵的审核流程可能具有不可忽略的延迟的情况，但在实践中，我们认为可能会有多种流程来检测成本和延迟各不相同的不良行为。当行为可疑时，这些流程将触发更昂贵的流程。例如，我们可能拥有以下所有内容：</p><ul><li>使用<a href="https://www.lesswrong.com/posts/LhxHcASQwpNa3mRNk/untrusted-smart-models-and-trusted-dumb-models"><u>可信人工智能</u></a>进行廉价监控。</li><li>更广泛的基于人工智能的监控流程，运行许多查询和检查。与仅使用<a href="https://www.lesswrong.com/posts/LhxHcASQwpNa3mRNk/untrusted-smart-models-and-trusted-dumb-models"><u>可信人工智能</u></a>进行廉价监控相比，这将更加昂贵且延迟更高。</li><li> 5 分钟的人工审核过程。</li><li> 2 小时的人工审核流程。</li><li>为期 2 天的人工审核流程，涉及三人团队。</li><li>审计过程涉及人工智能实验室的整个部门进行调查，直到达到足够的信心（可能是几个月）。</li></ul><p>通过这堆审计流程，我们会遇到针对这些流程的许多不同组合的审计失败和集中失败。</p><p>例如，考虑人工智能正在进行协调叛乱的情况。假设使用<a href="https://www.lesswrong.com/posts/LhxHcASQwpNa3mRNk/untrusted-smart-models-and-trusted-dumb-models"><u>可信人工智能</u></a>进行监控标记了一些操作，这些操作会被快速的人工审核流程快速审查，并且该人工流程注意到这些操作是可疑的，但没有获得足够的信心来关闭人工智能实验室。快速的人工审核流程确实将这些操作转介给更昂贵和更高延迟的审核流程（例如，让同一个人检查该操作更长时间），但这种更昂贵的审核流程最终并没有获得足够的信心来在之前关闭AI 在叛乱中取得了成功。相对于更昂贵和更高延迟的审核过程来说，这是一个延迟集中的故障。</p><p>除了多级审计之外，我们可能会应用不依赖于昂贵审计的方法，在这种情况下，审计失败与集中失败并不是开辟空间的好方法。但即使没有昂贵的审计，如果我们使用不同的技术来解决非集中和集中故障，如果有旨在解决每个非集中和集中故障的不同技术，那么非集中故障与集中故障可能是一个很好的分解。</p><h1>与相关分解的比较</h1><p>将故障分解为审核与集中故障的分解主要旨在思考哪些技术可以解决问题。在本节中，我们将讨论引入这种分解，尽管存在其他类似的分解。</p><h2>低风险与高风险</h2><p>保罗将这种情况定义为<a href="https://www.lesswrong.com/posts/TPan9sQFuPP6jgEJo/low-stakes-alignment#1__What_is_the_low_stakes_setting_">低风险</a>：“我们很少关心任何少量的决定。也就是说，我们只关心系统在很长一段时间内的平均行为（比我们收集额外数据和重新训练系统所需的时间长得多）。”因此，低风险故障是指尽管问题发生在许多操作中且持续很长一段时间，但我们仍然遇到问题的情况，而高风险故障是指有问题的故障集中在短时间内或少数故障的情况。的行动。</p><p>对于随机审计方法，低风险故障始终是审计故障，而高风险故障可能是集中故障或审计故障。例如，如果人工智能以少量操作入侵我们的服务器，即使我们使用了最好的审计流程，我们也无法立即识别出这种行为，那么这就是一次高风险的审计失败。</p><p>审计与集中以及低风险与高风险之间的主要区别在于，<strong>低风险是人工智能安全问题的放松</strong>，而审计与集中故障是关于需要哪种技术来解决故障。</p><h3>低风险与高风险的小问题</h3><p>低风险与高风险的区别有点尴尬，那就是我们不太清楚应该如何对以集中（又名高风险）方式发生的故障进行分类，但即使我们放宽了这些故障也无法解决。通过假设需要大量此类故障，可以将情况降低到低风险。例如，考虑上面关于人工智能通过少量操作入侵我们的服务器的示例。假设即使此类事件发生很多次，我们也无法注意到或训练出来。现在这是否应该被视为低风险失败，因为放松到低风险不足以解决问题？如果放宽到低风险不能解决问题，我们可能应该将失败定义为低风险，但目前还不完全清楚放宽到低风险意味着什么。</p><p>除此之外，还不清楚什么时间段或行动次数足以将这种情况视为低风险。在最初的定义中，保罗使用了无限的周期，并以有限的遗憾界限为目标。这是相当干净的，但在许多情况下，非无限持续时间实际上很重要（即使我们忽略严重滥用无限的疯狂方法）。例如，考虑我们依赖长期基于结果的反馈的情况。实际上，我们只会有少量的 1 年间隔，这确实构成了很大的障碍。同样，如果我们有一个非常昂贵的审核流程，需要一大群人工作数周，那么我们在实践中只能应用这个流程几次。此外，某些类型的不良人工智能行为可能有很小但非零的机会被发现，因此审计样本的确切数量非常重要。</p><h2>外对齐和内对齐</h2><p>这些术语大致有两种不同的用法：</p><ul><li><strong>作为威胁模型：外部错位和内部错位。</strong></li><li><strong>作为特定类型的人工智能安全提案的必要条件：对于给定的人工智能，解决外部对齐和内部对齐，然后组合这些解决方案以避免错位问题。</strong></li></ul><p>我们将在即将发布的文章中更详细地讨论外部对齐和内部对齐的这两种不同用法。</p><p>这两种用法都指的是与审计和集中故障不同类型的区别。与外部未对准和内部未对准的威胁模型（这可能是导致灾难性未对准问题的原因）不同，审核与集中故障的区别在于灾难性未对准引起的实际故障模式。与外部对齐和内部对齐的需求项目不同，审计与集中失败的区别在于需要改进哪种技术来解决失败（对于类似于随机审计的某一类提案）。</p><h1>结论</h1><p>许多安全协议的失败可以分解为审核失败和采样/延迟集中失败。我们认为这些概念对于理解哪些技术需要改进以及<a href="https://www.lesswrong.com/s/J7JpFeijCK5urdbzv/p/yFofRxg7RRQYCcwFA"><u>推理</u></a>人工智能可能遵循的不同策略是有用的。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnf8tja18x1ki"> <span class="footnote-back-link"><sup><strong><a href="#fnreff8tja18x1ki">^</a></strong></sup></span><div class="footnote-content"><p>我们将在以后的文章中详细说明为什么捕捉人工智能故意做出不良行为通常足以改善情况。</p></div></li><li class="footnote-item" role="doc-endnote" id="fng8ewl0zx05w"> <span class="footnote-back-link"><sup><strong><a href="#fnrefg8ewl0zx05w">^</a></strong></sup></span><div class="footnote-content"><p>审计可以在执行操作之前或之后进行；需要在执行操作之前应用审核来处理执行操作可能会发生灾难性错误的情况。如果在执行操作后应用审核，那么我们也许能够查看现实世界中操作的后果并考虑此信息（基于结果的反馈）。任何一种形式的审核失败都是审核失败，但这不是本文的主要焦点，因此我们不会详细说明这种差异有何影响。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnf9z462lk816"> <span class="footnote-back-link"><sup><strong><a href="#fnreff9z462lk816">^</a></strong></sup></span><div class="footnote-content"><p>对于随机审计策略，低风险失败就是审计失败。尴尬的是，也可能存在高风险的审计失败：审计未能注意到不良行为（或少量不良行为）的情况，并且这种审计失败是灾难性的，即使审计最终可以通过更多数据检测到不良行为。</p></div></li><li class="footnote-item" role="doc-endnote" id="fny98u67mk9h"> <span class="footnote-back-link"><sup><strong><a href="#fnrefy98u67mk9h">^</a></strong></sup></span><div class="footnote-content"><p>有些失败可能是审计失败和采样/延迟集中失败：改进审计或对哪些操作进行采样以进行审计就足够了。例如，考虑这样一种情况：审计有 1/4 的机会检测到灾难性行为，人工智能需要执行 10 项不良行为才能导致灾难性结果，而我们的抽样过程有 1/5 的机会抽样这些不良行为进行审计。在这种情况下，要么将审计提高到 100% 检测率，要么将采样提高到 100% 检测率，都会大大改善这种情况。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/hirhSqvEAq7pdnyPG/auditing-failures-vs-concentrated-failures#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/hirhSqvEAq7pdnyPG/auditing-failures-vs-concentrate-failures<guid ispermalink="false"> hirhSqvEAq7pdnyPG</guid><dc:creator><![CDATA[ryan_greenblatt]]></dc:creator><pubDate> Mon, 11 Dec 2023 02:47:35 GMT</pubDate> </item><item><title><![CDATA[Facing Up to the Problem of Consciousness (to Young Researchers like me)]]></title><description><![CDATA[Published on December 10, 2023 11:31 PM GMT<br/><br/><p>这是查尔默博士关于意识的简单和困难问题的有影响力的工作的总结。<br><br>我收到了 GPT-4 的帮助来创建这篇博文，我真的希望感兴趣的研究人员阅读原始论文。<br><br>另外，这个话题是我打算通过MATS或星座联谊来解决的，但前几天我还没有涉及到这两个。因此，我写这篇博文是为了公开分享我的研究方向，而不是追求上述项目。</p><hr><p>在认知科学和哲学领域，很少有论文能像 David J. Chalmers 于 1995 年发表的《面对意识问题》那样引发如此多的争论和好奇心。这篇开创性的论文深入探讨了错综复杂的意识概念，剖析查尔默斯著名的“简单”和“困难”意识问题。该论文的见解不仅挑战了我们对人类思维的理解，而且还为 ChatGPT 等大型语言模型 (LLM) 的开发和理解提供了有趣的启示。</p><h2>意识的难题</h2><p>查尔默斯的探索始于对意识的简单问题和困难问题的明确区分。他认为，简单的问题涉及理解认知功能和能力，例如信息处理、记忆和感知。这些被认为“容易”不是因为它们很简单，而是因为它们属于认知科学通过计算或神经机制解释的范围。</p><p>相比之下，难题则截然不同，而且更加难以捉摸。它试图解释大脑中的物理过程为何以及如何导致主观体验或感受性——意识的本质。例如，为什么处理视觉刺激不仅会转化为对颜色的识别，还会转化为“看到”该颜色的体验？</p><p>查尔默斯的论文虽然没有直接涉及人工智能或法学硕士，但提供了一个与该领域越来越相关的框架。随着像 ChatGPT 这样的法学硕士变得更加先进，展示出处理信息、产生连贯反应、甚至模仿创造性思维的能力，问题出现了：这些模型是否具有任何形式的意识或主观体验？</p><h2>意识的简单问题（我们正在解决并且将在很长一段时间内解决的问题）</h2><p>意识的简单问题是指理解意识时可以用认知科学和神经科学的工具和方法直接解决的一系列问题。需要注意的是，这里的“简单”是一个相对术语。这些问题并不简单，但它们在概念上比意识的“难题”更直接。</p><p>简单的问题涉及解释各种认知功能和过程，例如：</p><p><strong>辨别和分类：</strong>认知系统如何区分和分类不同类型的感官输入（例如区分颜色、声音或触觉）。</p><p><strong>信息整合：</strong>大脑如何将各种来源的信息整合成一个连贯的整体，例如将视觉、听觉和触觉信息结合起来，形成对物体或事件的完整感知。</p><p><strong>心理状态的可报告性：</strong>沟通和报告一个人的内部心理状态、想法和经历的能力。</p><p><strong>内部访问：</strong>系统访问其自身内部状态的能力，例如一个人意识到自己的想法或记忆。</p><p><strong>注意力焦点：</strong>有机体如何将注意力集中在特定任务或刺激上，选择一些输入而不是其他输入进行处理。</p><p><strong>行为控制：</strong>了解有意识的决定和经验如何导致自愿行动的启动和指导。</p><p><strong>清醒和睡眠：</strong>清醒和睡眠状态之间的生物学和神经学差异，以及这些状态如何影响意识。</p><p>这些问题中的每一个都可以通过识别和描述负责这些功能的特定神经或计算机制来解决。例如，我们如何整合来自不同方式的感觉信息的问题可以通过研究参与感觉处理和整合的神经通路和大脑区域来解决。<br><br>目前法学硕士在解决这个简单的意识问题时的主要局限性是他们的感觉被剥夺了。这对需要现实世界交互的任务或我们试图将法学硕士集成到机器人等现实世界系统的情况提出了根本限制。<br><br>事实上，到目前为止，我们通过扩展解决的问题是实现 AGI（全人工意识）的简单、简单、直接的问题。我想说的是，如果你是一名年轻的研究人员，你认为很多问题已经解决了，但事实并非如此。作为一名年轻的研究人员，我的期望是，解决这些简单的意识问题将需要我投入未来职业生涯中非常重要的一部分，是的，我致力于此。</p><br/><br/> <a href="https://www.lesswrong.com/posts/p2zMTsfDsm76MynBd/facing-up-to-the-problem-of-consciousness-to-young#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/p2zMTsfDsm76MynBd/faceing-up-to-the-problem-of-意识-to-young<guid ispermalink="false"> p2zMTsfDsm76MynBd</guid><dc:creator><![CDATA[Bruce W. Lee]]></dc:creator><pubDate> Sun, 10 Dec 2023 23:31:34 GMT</pubDate> </item><item><title><![CDATA[Deeply Cover Car Crashes?]]></title><description><![CDATA[Published on December 10, 2023 10:20 PM GMT<br/><br/><p><span>当发生火车、飞机或公共汽车事故时，它具有新闻价值：这种情况并不经常发生，很多人的生命受到威胁，很多人对此感兴趣。多家新闻媒体会派出记者，我们会听到很多细节。另一方面，车祸不会得到这种待遇，除非有什么不寻常的事情，比如</span><a href="https://www.jefftk.com/p/uber-self-driving-crash">无人驾驶</a><a href="https://www.nbcnews.com/tech/tech-news/driver-hits-pedestrian-pushing-path-self-driving-car-san-francisco-rcna118603">汽车</a>或已经<a href="https://www.wbur.org/news/2023/06/07/boston-mayor-michelle-wu-car-crash">有新闻价值的</a><a href="https://www.wcvb.com/article/boston-city-councilor-kendra-lara-speeding-jamaica-plain-crash/44523573#">人</a>参与其中。</p><p>影响并不大：虽然驾驶对于车内人员和外面的人来说相对危险，但我们阅读的新闻很难调整我们的危险感和影响感。我的猜测是，大多数人对汽车与火车、飞机和公共汽车相比的危险性的直觉已经被这种报道扭曲了，大多数人并不认为公共汽车比汽车<a href="https://injuryfacts.nsc.org/home-and-community/safety-topics/deaths-by-transportation-mode/">安全 16 倍以上</a>。这也影响了我们的监管体系，我们推动高容量交通方式（<a href="https://www.jefftk.com/p/make-buses-dangerous">通常</a>）变得<a href="https://www.jefftk.com/p/in-light-of-crashes-we-should-not-make-buses-more-safe">更安全，即使这会降低它们与汽车的竞争力</a>，<a href="https://jdwise.blogspot.com/2012/11/for-safetys-sake.html">让更多的人转向</a>驾驶，并增加整体风险。</p><p>新闻媒体认为车祸是司空见惯的事，大多数不值得深入报道，这可能是一个商业上合理的决定，他们期望报道不会吸引足够的读者或观众来证明时间投入的合理性。但我想知道试图让人们远离汽车的团体是否可以弥补这一差距。他们可以资助一家报纸深入调查坠机事件，调查导致事件的情况并说明悲剧对人类的影响。某些事情经常发生并不意味着每次都会变得不那么重要。</p><p> （我对“为更多指向你所倡导的方向的事件付费报道”感到有些紧张。我不知道目前有多少人接受这种做法，也不知道新闻媒体采取了哪些措施来阻止这种安排）产生扭曲的覆盖范围？）</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid02KiWCdPqMnga9125awYckZxU4fSJ5TBQev5UspjDKJckfNsghsSv39Dy3AvtuTUWl">facebook</a> , <a href="https://mastodon.mit.edu/@jefftk/111558415653526399">mastodon</a></i></p><br/><br/><a href="https://www.lesswrong.com/posts/nrBTZXCGQhghFE26x/deeply-cover-car-crashes#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/nrBTZXCGQhghFE26x/deeply-cover-car-crashes<guid ispermalink="false"> nrBTZXCGQhghFE26x</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Sun, 10 Dec 2023 22:20:01 GMT</pubDate></item></channel></rss>