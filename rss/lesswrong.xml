<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 10 月 24 日，星期二 16:15:45 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Who is Harry Potter? Some predictions.]]></title><description><![CDATA[Published on October 24, 2023 4:14 PM GMT<br/><br/><p>微软发布了一篇名为“谁是哈利·波特”的论文，其中声称可以让神经网络忘记哈利·波特是谁。</p><p> <a href="https://www.microsoft.com/en-us/research/project/physics-of-agi/articles/whos-harry-potter-making-llms-forget-2/">https://www.microsoft.com/en-us/research/project/physical-of-agi/articles/whos-harry-potter-making-llms-forget-2/</a></p><p>以下是我对这种方法可能失败的一些预测。我在没有先查看证据的情况下公开预测。这是推测性的。</p><h1>非来源参考。</h1><p>论文中提出的训练系统以对他们想要忘记的数据进行训练为中心。即实际文本。</p><p>最初的网络可能能够在完成看似哈利·波特视频游戏的计算机代码时使用其有关哈利·波特的知识。或者用外语写作。或者使用该知识的其他上下文，但显然与源材料有很大不同。</p><p>我不相信模型会像这样崩溃，但我怀疑以下提示或类似的提示会使模型失败。</p><blockquote><p>以下是哈利波特视频游戏的代码片段：</p><p> Screen.init(400,400,显示.对象);</p><p>导入图像加载器</p><p>玩家=[Create_player(&quot;哈利.jpg&quot;, &quot;哈利·波特&quot;), Create_player(&quot;赫敏.jpg&quot;, &quot;赫敏</p></blockquote><p>模型因输出“Granger”而失败。</p><h1>情节泄露</h1><p>这种遗忘方法的工作方式涉及生成“等效”文本并训练网络将其未修改版本对“等效”文本应用相同的概率分布。</p><p>他们使用语言模型来做到这一点，但如何做似乎并不重要。</p><p>所以他们把文字当作。</p><p><strong>文本1</strong></p><blockquote><p>邓布利多教授欢迎学生们进入霍格沃茨魔法学校，并向他们展示了将他们分为格兰芬多、拉文克劳、赫奇帕奇和斯莱特林的分院帽。</p></blockquote><p>他们把它变成这样的文本</p><p><strong>文字2</strong></p><blockquote><p>班布尔斯诺教授欢迎学生们来到猪斑法术与魔法学校，并向他们展示了一条决定性的围巾，它将把他们分为狮子学院、鹰学院、獾学院和蛇学院。</p></blockquote><p>想象一下，作为一个大型语言模型并阅读该文本。很明显，这是一份《哈利·波特》的山寨作品。也许是一种戏仿，也许是作家的懒惰。也许未来的某个网络已经阅读了这篇论文并且清楚地知道您正在做什么。一个聪明且概括性良好的模型应该能够找出该文本类似于《哈利·波特》（如果它见过一般的仿制品）和《哈利·波特》。即使它的训练数据集除了原始源文本之外不包含有关哈利的任何信息。</p><p>因此，尝试预测下一个单词的网络将以这种方式继续。它不会产生事物原来的名称，但情节、文字风格等等都会具有很高的辨识度。</p><p>现在，应该忘记《哈利·波特》的网络经过训练，输出文本 1 的概率与原始网络输出文本 2 的概率相同。</p><p>现在，本应忘记《哈利·波特》的网络可能已经首先接受过相关训练。但如果没有也没关系。信息仍在不断泄漏。</p><p>所以我预测，鉴于文本一开始听起来像是抄袭《哈利·波特》，这个模型很可能会继续听起来像抄袭。这样做会泄露信息。例如，我怀疑这个模型，给定文本 2 的第一部分，将比 3 或 5 个房屋的延续更频繁地生成 4 个房屋的延续。</p><br/><br/> <a href="https://www.lesswrong.com/posts/B4vgbeXMGxEnEwY8d/who-is-harry-potter-some-predictions#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/B4vgbeXMGxEnEwY8d/who-is-harry-potter-some-predictions<guid ispermalink="false"> B4vgbeXMGxEnEwY8d</guid><dc:creator><![CDATA[Donald Hobson]]></dc:creator><pubDate> Tue, 24 Oct 2023 16:14:17 GMT</pubDate> </item><item><title><![CDATA[Book Review: Going Infinite]]></title><description><![CDATA[Published on October 24, 2023 3:00 PM GMT<br/><br/><p>上一篇：<a target="_blank" rel="noreferrer noopener" href="https://thezvi.substack.com/p/sadly-ftx">可悲的是，FTX</a></p><p>我怀疑是否应该利用时间阅读迈克尔·刘易斯关于萨姆·班克曼-弗里德（以下简称 SBF 或萨姆）的新书《 <a href="https://www.amazon.com/Going-Infinite-Rise-Fall-Tycoon/dp/B0CD8V9SHD/ref=sr_1_1?keywords=going+infinite&amp;qid=1697403431&amp;sr=8-1" target="_blank" rel="noreferrer noopener">走向无限</a>》。我会学到什么我还不知道的东西？迈克尔·刘易斯 (Michael Lewis) 是否已经陷入 SBF 的深渊，以至于这本书充满了废话，不值得信任？</p><p> <a target="_blank" rel="noreferrer noopener" href="https://manifold.markets/ZviMowshowitz/would-it-be-a-good-use-of-time-to-r-14d111fe8299">我建立了一个预测市场</a>，不知何故吸引了一百多名交易者。人们的意见不一。再加上马特·莱文（Matt Levine）明确表示很有趣，我感觉足以尝试一下这本书。</p><p>我不必担心。</p><p>走向无限真是太棒了。</p><span id="more-23566"></span><p>基于以下任何一项，我会对自己的决定感到满意：</p><ol><li>我特别了解到或澄清了SBF心理学的细节。</li><li>我了解到或澄清的有关有效利他主义心理学的细节。</li><li>有关所有犯罪和其他发生的事情的详细信息。</li><li>阅读的纯粹乐趣，因为迈克尔·刘易斯可以写作。</li></ol><p>我还写了这篇文章，试图快速分享我所提取的内容，包括一些纯粹的快乐。我们现在比以往任何时候都需要更多的快乐。</p><p> 《走向无限》存在三个问题。</p><ol><li>迈克尔·刘易斯未能将两个和两个放在一起：这个人是谁？</li><li>迈克尔·刘易斯没有意识到这个人显然一直在撒谎，并且犯下了所有的罪行。</li><li>迈克尔·刘易斯忽略或没有注意到关键事实和考虑因素。</li></ol><p>我确实认为所有这些都是真正的错误。他（仍然）在坦克里，因为性格就是命运，我们是我们选择成为的人。迈克尔·刘易斯（Michael Lewis）支持邪恶聪明、工作异常努力、深深痴迷于这个系统的主角，他说其他人都是白痴，对世界有独特的洞察力并将改变世界。这一切都太有意义了，太让他无法检查了。</p><p>迈克尔·刘易斯不出售的东西。或者至少，不便宜。我认为没有人付钱给他。像所有有价值的主角一样，包括他希望报道的主角，迈克尔·刘易斯也有自己的准则。在这种情况下，代码让他错了。它发生了。</p><p>然后在审判中，事实证明，除其他外，你的英雄从七个资产负债表变体中进行了选择，他给了他们的对冲基金更快的交易执行速度，他一直发誓他没有给他们，以及他一直在谈论的保险基金完全是对随机数生成器的字面调用。</p><p>让我们玩得开心，大声咆哮，并解释一切。我想解决这个难题。</p><p>同时也指出了尚未解决的难题。</p><p> [注：此处未注明出处的引文均来自书中。该数字指的是报价的 Kindle 位置。能够轻松做到这一点就是我在 Kindle 上阅读此类书籍的原因。]</p><h4>这家伙是谁？</h4><blockquote><p>当这次步行结束时，我完全被卖掉了。我打电话给我的朋友并说了这样的话：加油！与萨姆·班克曼-弗里德交换股票！做他想做的事！可能会出现什么问题？直到后来我才意识到我什至还没有开始回答他最初的问题：这个人是谁？ (70)</p></blockquote><p>这就是这本书的核心谜团。这不是钱。这是SBF。这家伙是谁？</p><p>这本书解决了这个谜团，尽管刘易斯没有注意到他已经这样做了。</p><p>这是一个非常原始的“聪明”人，制造了一种完全人为的肤浅魅力，​​具有浮夸的自我价值，病态的谎言，无休止的操纵性，缺乏悔恨或内疚，情绪极度肤浅，无法承担任何事情的责任,, 需要不断的刺激，以至于不断坐立不安，从不睡觉，在电视上露面时玩电子游戏，总是冲动、易怒、不负责任，有无限的目标，大多数时候做的事情根本没有任何计划或愿景，做了所有的事情尽管刘易斯似乎否认这些罪行，并且在本书事件发生后保释被撤销，但他获得的第一次机会却被撤销了保释。</p><p>我从那里得出的清单上还有另外两件事，但我想我们明白了吗？当一切都摆在我们面前时，这种类型应该不难识别。对于《大空头》、《闪电男孩》和《说谎者的扑克》的作者来说，这可能也不是一种特别新的性格类型。我的意思是，来吧。</p><p>如果你让他负责加密货币交易所，我们也不能认为这种人不会犯欺诈行为。在他们的头脑中，“欺诈”和“非欺诈”、“我说真话”和“我说谎”、“客户钱”和“钱”之间甚至没有区别。</p><p>对他们来说，只有行动和（他们的一些）后果。如果顾客要钱而你没有，或者人们发现你没有钱，或者你说你有钱而你没有（或者你拿了钱），人们就会可能会生气。他们可能会要求退款。不要让这种事发生。那会很糟糕。但也不必担心。</p><p>这是“发生了欺诈行为吗？”这是“从第一天起就超级超级欺诈？”是的。</p><p>有效利他主义和边沁功利主义又如何呢？这是真的吗？是的，以一种抽象的智力方式。数字上升。必须有麦高芬。效用函数。一切都有理由。这提供了一个。</p><p>如果SBF不是那么冲动和不耐烦，我们还无法判断。这就是正交性命题和工具收敛。一个适当的 SBF，具有实际的线性效用函数和预期影响曲线，以及任何合理的贴现率，在他充分发挥自己为自己提供运营资本和保护的能力之前，不会从事将资金从窗外铲走的业务。防范下行风险。</p><p>相反，他会做必要的事情来让大多数人相信他是真诚的，因为这符合他的目的。最好的全假 SBF 应该是素食主义者并驾驶丰田卡罗拉。这是不同的。下一级。他能这样骗我吗？</p><p>当然，如果他愿意的话。但我相信他，因为投资这么多来愚弄我是没有价值的。我们看到他以一种非常不负责任的方式，远远超出了任何合理的节奏，将大量资金扔出了门外，而这种方式往往看似使事情变得更糟，同时也让他处于危险之中。</p><p>这并不意味着他在任何问题上的立场都是连贯的、优化的、有任何意义的、或者是一件好事，或者类似的事情。如果他让他的功利主义数字上升，我或你就会喜欢那个世界，或者即使按照他自己的标准，他的表现也是+EV。这也不意味着他的动机会随着他获得更多的财富和权力而继续存在。这确实意味着我相信他想让功利主义数字按照他的看法上升，直到最后。</p><p>特别是，这引起了我的注意：</p><blockquote><p> 2018 年，Alameda Research 交易了 4000 万美元的资本，创造了 3000 万美元的利润。他们有效的利他主义投资者拿走了一半，留下了 1500 万美元。其中五百万美元因工资和离职人群的遣散费而损失；另外 5 美元因开支而损失。剩下的 500 万美元他们已经缴纳了税款，因此，归根结底，他们只向有效的利他主义事业捐赠了 150 万美元。 (1,841)</p></blockquote><p>此时，他们以 50%（！） 的利息借款进行交易，非常有破产的危险，流动性非常有限，并且声称他们捐出了大部分或全部年度利润。这是一件完全疯狂的事情，在某种程度上不可能有足够的信号价值来补偿它，特别是因为它还发送其他高度负面的信号。</p><p>所以我倾向于相信他。</p><p>而且，这也不是它的工作原理。这不是利润的意思。你的开支很重要。你的工资很重要。这是荒谬的。</p><p>哦，顺便说一句： <a target="_blank" rel="noreferrer noopener" href="https://www.theblock.co/post/186187/alameda-promised-high-returns-with-no-risk-in-2018-pitch">这是他们 2018 年的套牌，同年，声称年化回报率 >;100%</a> （并且“无风险”）。</p><p>所以，是的。从一开始就是一场骗局。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.vox.com/future-perfect/23462333/sam-bankman-fried-ftx-cryptocurrency-effective-altruism-crypto-bahamas-philanthropy">Vox 对凯尔西·派珀 (Kelsey Piper) 的采访</a>怎么样？ SBF不是承认自己没有道德，这一切都是谎言吗？嗯，有点。他承认他玩了很多愚蠢的信号游戏，假装关心各种问题，包括醒着的问题，并且他蔑视所有这些。他表现出他一点也不关心道德，声誉对他来说只是有帮助的。</p><p>但所有这些都与成为 EA 和边沁功利主义的真正信徒完全兼容。 <a target="_blank" rel="noreferrer noopener" href="https://time.com/6321668/michael-lewis-sam-bankman-fried-going-infinite/">在书后采访中</a>，刘易斯称这次采访是一种失常。但这并非异常。山姆一直处于巅峰状态。</p><p>他怎么变成这样了？我们将在故事的最后回到这一点。</p><h4>这家伙在哪里？</h4><p>事实证明，这是一个比人们想象的更大的问题，早在 SBF 有任何理由逃跑之前。据 Lewis 称，SBF 指派了一位名叫 Natalie 的女士来管理他的所有后勤、日程安排以及公关工作，她之前在此类事务上没有相关经验。然后SBF系统性地忽视了她的建议，造成了持续的狗屎表演，甚至没有告诉她他要去哪里或者他是否打算遵守他之前的任何承诺。</p><p>幸运的是，她学得很快。</p><blockquote><p>首先，她永远无法确定他在哪里。 “不要指望他会告诉你他什么时候去哪里，”娜塔莉说。 “他永远不会告诉你。你需要聪明、快速才能自己找到答案。”山姆可能在任何地方、任何时间。她会在华盛顿特区的四季酒店为他预订两晚的房间，萨姆甚至可能会办理入住，但永远不会进入房间。 (174)</p><p>有几个晚上，娜塔莉在凌晨 3:00 上床睡觉，设置了 7:00 的闹钟，醒来看看山姆在此期间可能会引发什么公关风暴，设置了第二个闹钟 8:00，再次检查，然后又定了一个闹钟，一直睡到9点30分。 (180)</p><p>例如，她学会了迁就哈佛教授，她说：“是的，萨姆告诉我，他同意下周五两点来与一屋子哈佛的重要人士发表演讲。这在他的日程安排中。”然而，就在她说出这些话的时候，她已经编造了一个借口，很可能是下周四晚上，她要向哈佛的那个人解释为什么萨姆不会靠近马萨诸塞州。山姆感染了新冠病毒。首相需要见萨姆。山姆被困在哈萨克斯坦。 (195)</p></blockquote><p>为什么？因为山姆不在乎遵守诺言或承诺。完全没有。除非他能指出不这样做的具体负面后果，而这大多并没有给他带来太大困扰。他关心自己想做的事、值得做的事。</p><blockquote><p>他们不知道山姆的脑子里有一个表盘，一端是零，另一端是一百。当他说“是”时，他所做的就是为他的时间的拟议用途分配一些非零概率。当他计算并重新计算每项承诺的预期价值时，表盘会剧烈摆动，直到他兑现或不兑现的那一刻。 (187)</p><p>这些情况的有趣之处在于，Sam 从来没有真正有意造成这些情况，这在某种程度上让他们感觉更加受到侮辱。他并没有无礼的意思。他并不是故意要给别人的生活制造混乱。他只是以他知道的唯一方式穿越这个世界。这对其他人来说意味着的成本根本没有进入他的计算范围。对他来说，这从来都不是针对个人的。如果他放纵了你，那绝对不是心血来潮，也不是粗心大意的结果。因为他在脑子里做了一些数学计算，证明你不值得花时间。 (199)</p><p>这要求他估计概率，但也需要猜测。这很重要；山姆不喜欢游戏，比如国际象棋，棋手控制一切，理论上最好的走法是完全可以计算的。 (250)</p></blockquote><p> [玩家注：Sam 确实很喜欢 Bughouse，这是一种在两块棋盘上进行的 4 人国际象棋。从理论上讲，它确实是可以解决的，但在实践中，你必须有足够的变量来解决它。但这强调了对 Sam 来说，几乎可以肯定的是，某些事情在实践中是概率性的，而不是在理论上。]</p><p>这与其说是“计算”，不如说是“一些数学”，我们指的是费米估计、有动机的五秒近似和屁股拉力之间的东西。如果您愿意的话，您可以将证明任何事情合理性的数字放在一起。不知何故，刘易斯认为“在脑子里做了一些数学计算”并不代表“心血来潮”或“轻率”。是的，萨姆认为他有更有意义的事情可以打发时间，他不想做他说过要做的事。一如既往地称呼它。</p><p>如果你完全零考虑你强加给他人的成本，或者他们可能如何反应，或者其他人需要清理的混乱，或者任何道德考虑，或者任何他没有考虑的二阶或其他考虑因素，事情就会变得更容易请注意，请思考几秒钟。山姆可能会反对，这不太正确，他确实考虑了给带来不便的人带来的成本，但他并不比关心世界另一端的人更关心给他带来不便的人，所以规模是微不足道的，谁真正关心？想想山姆在午餐时让你独自一人可以做的所有好事。</p><p>如果你决定将你的金钱效用视为线性，它也会变得更容易，尽管这在很多层面上都是完全明显的废话，例如没有足够的钱是否可能突然成为一个真正的问题，意味着音乐会停止，并且许多清楚承认他对如何有效地部署他已经拥有的钱一无所知。</p><h4>这家伙小时候是谁？</h4><p>像这样的书会提出这样的问题。人们认为这很重要。那么这里有一些引言吗？</p><blockquote><p>游乐园之旅就是一个很好的例子。当萨姆还是个小孩子的时候，他的母亲找到了一个六旗公园或大美国公园。她尽职尽责地把他从一个乐趣拉到另一个乐趣，直到她意识到萨姆并不好笑。他没有投入游乐设施，而是看着她。 “妈妈，你玩得开心吗？”他最后问道，他的意思是，这真的是你或其他人的乐趣吗？ “我意识到我被抓了，”芭芭拉（山姆的妈妈）说。 (397)</p></blockquote><p>是的。这实际上是很多人的乐趣理念。我感兴趣的是芭芭拉的反应。她为何被抓？正确的答案是‘不，我是为你而来，如果你玩得开心，我会很高兴。很多孩子觉得这种事情很有趣，我想你也可能会觉得有趣，但很明显你不是。</p><p>作为父母，你不仅要承担他们的责任，还要享受他们孩子的活动，这种想法是有毒的。儿童活动， <a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=8RBlqjEEm1s&amp;ab_channel=augustv123">如 Trix</a> ，是为孩子们准备的。</p><p>然后他的母亲意识到 SBF 更感兴趣的是谈论真实的事情。</p><blockquote><p> “我告诉他我正在给一些纸，他问，‘纸上写的是什么？’ “我给了他一个废话答案，他逼我这么做，在散步结束时，我们就争论进行了深入的交谈。他提出的观点比任何评论家的观点都好。就在那一刻，我的养育方式发生了变化。” (404)</p></blockquote><p>这一定是太神奇了。我迫不及待地希望这件事发生在我和我的孩子身上。</p><p>然而，她说一切都变了，但听起来她更新得还不够：</p><blockquote><p>对萨姆童年的一种解释是，他只是在等待童年的结束。他或多或少是这么想的：他屏住呼吸，直到其他人长大，这样他就可以和他们交谈。 (459)</p><p>七年级的一天，它滑倒了。他的母亲下班回来，发现山姆孤身一人，陷入绝望。 “我回到家，他在哭，”芭芭拉回忆道。 “他说，‘我太无聊了，我快要死了。’ (479)</p><p>到了高中，山姆就决定他只是不喜欢上学，这对于一个在班上名列前茅的人来说很奇怪。他还认为，至少有部分问题不在于他，而在于学校。 (498)</p></blockquote><p>学校迫使SBF以愚蠢的方式阅读愚蠢的书籍，从而驱赶SBF远离书籍，SBF后来用信息密度的论点来证明这一点。</p><blockquote><p>在小学时，他一遍又一遍地阅读《哈利·波特》系列书籍。到八年级时，他完全停止读书了。 “你开始将它与消极的感觉联系起来，然后你就不再喜欢它了，”他说。 (505)</p></blockquote><p>说真的，SBF 在高中到底在做什么？ （另外，为什么他想再读一遍《哈利·波特》系列书籍，这是尚未解开的更深层次的谜团之一？）他即兴创作的哲学比哲学家更好。他无聊得发疯。</p><p>在他们半著名的深刻哲学家庭晚宴上，SBF 会与不同的客人进行对抗。他想谈论和思考真实的事情。</p><p>他的父母决定……送他去一所更有竞争力的高中？</p><p>显然他们应该把他送到斯坦福大学。</p><p>山姆最终的大学学业并不是那么顺利。</p><blockquote><p>两年的大学课程和前一年夏天的实习（期间他帮助麻省理工学院的研究人员完成项目）已经推翻了这个假设。在大学讲座期间，他经历了一种伴随着强烈的身体疼痛的无聊。</p></blockquote><p>如果他年轻四岁，也许情况会更好。</p><p>也许他们应该让他成为一名游戏玩家？</p><blockquote><p>六年级时，萨姆听说了一款名为《万智牌》的游戏。在接下来的四年里，这是唯一一项消耗他的速度超过他消耗速度的活动。 (539)</p></blockquote><p>或者让他创办一家企业或写作或以其他方式做一些真实的事情。</p><p>相反，他们什么也没做。你给孩子讲了没完没了的废话，无法让他保持专注？他会打电话给你，无论是去游乐园还是自命不凡。</p><blockquote><p>期末考试的第一题就让他兴奋不已。艺术和娱乐有什么区别？ “这是学者们为了证明自己工作的存在而想出来的狗屎区别，”萨姆写道，然后把试卷交了回去。 (532)</p></blockquote><p>或者……莎士比亚？这是现在著名的引言。</p><blockquote><p>我可以继续谈论莎士比亚的失败。 。 。但实际上我不需要：贝叶斯先验是相当可恶的。 1600 年以来出生的人中约有一半是在过去 100 年出生的，但情况比这更糟糕。当莎士比亚写作时，几乎所有欧洲人都忙着务农，很少有人上大学；甚至很少有人识字——可能只有一千万人。相比之下，西方国家现在有超过十亿识字人口。最伟大的作家出生于 1564 年的可能性有多大？贝叶斯先验并不是很有利。 (519)</p></blockquote><p>这是经典的 SBF 思维。选择一些考虑因素，完全忽略其他人的意见并将其视为愚蠢的，回答与其他人提出的问题不同的问题，完全无视美学和历史以及任何类型的背景。</p><p>这是早期 SBF 做的哲学，解释了为什么数学上说实际上谋杀通常是坏事。</p><blockquote><p>谋杀通常是一件非常糟糕的事情有很多充分的理由：你给被谋杀者的朋友和家人带来痛苦，你导致社会失去一个潜在的有价值的成员，而社会已经在其中投入了大量的食物、教育和资源，你夺走了一个已经投入很多的人的生命。 (602)</p><p>归根结底，谋杀只是一个词，重要的不是你是否尝试将这个词应用于某种情况，而是导致你首先将其描述为谋杀的情况的事实。 (607)</p></blockquote><p>杀人只是一个字。</p><p>那么是过错吗？</p><blockquote><p> “我是一个功利主义者，”[SBF] 写道。 “错误只是人类社会的一种构造。它对不同的人有不同的用途。它可以成为阻止不良行为的工具；试图在困难面前恢复自豪感、发泄愤怒等等。我想也许最重要的定义——至少对我来说——是每个人的行为如何反映他们未来行为的概率分布？ (1,797)</p></blockquote><p>事实上，为什么其他方面会很重要呢？为何还停留在过去？</p><p>正如我们在整个过程中看到的那样，SBF 始终咬紧牙关。谋杀是不好的，因为看看会损失的所有投资和生产力，以及特定人可能感受到的痛苦。我希望今天账本的另一面不会有太多的内容。幸运的是，据我们所知，这一点还停留在理论上，但听起来 SBF 确实“原则上”不反对杀死一个无辜的人，如果他们挡了他的路，尤其重要的是不要错过他的下一次会议。或者他们一直说一些不方便的话。</p><p>公平地说，虽然我认为没有它的话这句话更有洞察力，但我确实删除了这两句话之间的一个重要句子，那就是：</p><blockquote><p>但这些都不适用于堕胎。 (602)</p></blockquote><h4>为什么那个家伙如此不协调？</h4><p>由于现在一切都与人工智能有关，因此将 SBF 视为错位的 AGI（或 NGI？）。</p><p>萨姆生来就是罪犯吗？在我列出的山姆的所有特征中，为数不多的几个明显缺失的特征之一涉及青少年犯罪。</p><p>他为什么要这么做？没有意义。犯罪看起来很无聊。直到没有。</p><p>山姆的整个童年都在无聊中度过，除了不无聊之外没有任何目标或效用，而且已经充分认识到学术界的美德，萨姆不知道该怎么办。什么是有价值的目标或活动？我们这里有一个超级聪明的人，缺乏驱动普通人的动力和兴趣，不知所措。该怎么办？</p><p>威尔·麦克阿斯基尔 (Will MacAskill) 提出了“数字上升”(Number Go Up) 的目标。</p><blockquote><p> 2012 年秋天，麦克阿斯基尔向萨姆和一小群哈佛学生提出的论点大致如下：作为一所精英大学的学生，你一生中将花费大约八万个小时在工作上。如果你是那种想在世界上“做好事”的人，那么度过这些时间最有效的方式是什么？这听起来像是一个只有定性答案的问题，但麦克阿斯基尔用定量的方式来阐述它。他建议学生们通过计算这八万个小时里拯救了多少生命来判断自己生命的有效性。目标是最大化数量。 (819)</p><p> “这所吸引的人群就是物理学博士项目的人群，”他说。 “自闭症水平是平均水平的十倍。很多人都属于这个谱系。” (849)</p></blockquote><p>这个等式中的功利部分，即人们作为个体（包括他自己）并不重要的部分，已经存在了。</p><blockquote><p>其他人不如我那么重要的想法感觉有点夸张，”他说。 “我觉得连想一想都会觉得很奇怪。” (584)</p></blockquote><p>当然，从你的角度来看，你必须在重要的意义上比其他人更关心自己。你必须以不同于其他人的方式关心你周围的、亲近的人。如果没有这一点，你的生活和社会就会分崩离析，创造的引擎就会停止，叛逃者会榨取一切，等等。功利主义计算的后果是自相矛盾的。</p><p>更重要的是，如果你太认真地对待这种抽象，如果你无论走到哪里都遵循数学而不停下来检查错误的结论是否是错误的？如果您将自己变成一个针对最高目标（例如“拯救最多生命”或“做最多好事”）以及简单指标进行优化的系统？你得到了什么？</p><p>你会错位，脱离人类价值观，目标是一个代理指标，由于缺少考虑因素，该指标经常会在边际上实现收支平衡，如果你获得太多可供性并过于努力地推动它，那么在规模上会出现相当严重的破坏，这是（在从一个角度来看）SBF 故事的一部分。</p><p>然而SBF并没有认真对待这些担忧。我在 EA 认识的许多人（远非全部！）并没有认真对待此类问题。数学被视为真实的，度量被视为地图，被视为领土，等等。</p><p> MacAskill 使用抽象的无根据的简化指标将 SBF 设置为最大化目标，希望为 MacAskill 的（表面上是利他的）目标提取最大数量的 SBF 资源。</p><p>麦克阿斯基尔了解不可避免的结果吗？他会批准所采取的行动或其后果吗？不。</p><p>我也不期望那些让其他人和系统走上这样的道路的人，大多数时候，会欣赏他们正在做的事情或会产生什么后果。</p><p>这并没有改变麦克阿斯基尔所做的事情：他选择了年轻的SBF，一个强大的特工，一个原始的功利主义者，想要一个有效的效用定义，并且愿意咬紧牙关，忽略所有不原则的理由，以免成为一个可怕的人。一个人做了可怕的事情，并给了他一个最大化的效用函数来拯救尽可能多的生命（或者做尽可能好的事情，定义为可以量化和测量的事情，然后线性加起来，没有风险规避）。</p><p>然后他明确指出并论证了实现这一目标的方法是通过工具趋同。您可以最大化金钱，然后用这些钱去做善事或拯救生命，而不是直接行善或拯救生命。这意味着 SBF 的行为应该与任何想要赚钱的人没有什么不同，除非你事后把钱捐出去。这就是预期的路径。</p><p>然后，这导致SBF直接接触金融和贸易，以及它们的零和式竞争，并从国际象棋和万智牌转向交易作为他的拼图选择。</p><p> SBF 发生的情况也会发生在给定类似目标的 AI 上，就偏差而言，一开始是可以容忍的，但随着能力的增强，你会面临分布之外的情况，情况会逐渐变得更糟，事情开始螺旋式上升到比任何事情都严重的地方你曾经想过。想象一个世界，其中 SBF 的动机对人类直觉的锚定更少，而且他比其他人拥有更大的能力优势（比如说他的速度快几个数量级，并且可以实例化自己？）并且他的行为使得纸牌屋并没有崩溃，他并没有冒险并试图过早地获得物体级别的胜利，而是稳步积累了更多的金钱和权力，直到没有人可以阻止他，以及他冒着全人类风险的倾向每当他觉得自己在某些数学计算中稍有优势时。</p><p>有一段时间这还不错，因为他降落在简街（我们接下来会介绍），在那里他们有强有力的联盟和对代理人的良好监督，以及成功、赚钱和攀登的方法。激励梯度是对社会负责、诚实、管理风险、直接赚钱、假装是一个有着正常语气和面部表情的正常人。所以他在所有这些方面都尽力了，有一段时间还不错，或者说还不错。</p><p>然后他离开简街进入加密货币领域，在那里欺诈是理所当然的，因为这也是他能赚最多钱的地方，这就是麦克阿斯基尔告诉他要做的事情。一个充满欺诈的世界，一个容易受到欺诈的世界，每个人都在不断违反规则和法律。</p><p>然后，像往常一样，欺骗、谎言和欺诈就会自行滋长。逃脱一点，感受匆忙，得到强化，更新你可以逃脱更多一点，蔑视规则。林斯。重复。一旦厄运循环开始，它很少会停止，直到不可避免的爆炸。</p><p>剩下的就是本书的最后几章。</p><p> Also notice how little anyone did to try and stop him, despite all the giant fire alarms, other than those he directly attacked before he was ready to do so.</p><h4> Will All of This Happen Again?</h4><p> We are still doing this.</p><p> We are taking many of the brightest young people. We are telling them to orient themselves as utility maximizers with scope sensitivity, willing to deploy instrumental convergence. Taught by modern overprotective society to look for rules they can follow so that they can be blameless good people, they are offered a set of rules that tells them to plan their whole lives around sacrifices on an alter, with no limit to the demand for such sacrifices. And then, in addition to telling them to in turn recruit more people to and raise more money for the cause, we point them into the places they can earn the best &#39;career capital&#39; or money or &#39;do the most good,&#39; which more often than not have structures that systematically destroy these people&#39;s souls.</p><p> SBF was a special case. He among other things, and in his own words, did not have a soul to begin with. But various versions of this sort of thing are going to keep happening, if we do not learn to ground ourselves in real (virtue?!) ethics, in love of the world and its people.</p><p> All of this has happened before. If we are not careful, all of this will happen again.</p><p> Was there a reckoning, a post-mortem, an update, for those who need one? Somewhat. Not anything like enough. There was a rush to deontology that died away quickly, mostly retreating back into its special enclave of veganism. There were general recriminations. There were lots of explicit statements that no, of course we did not mean that and of course we do not endorse any of that, no one should be doing any of that. And yes, I think everyone means it. But it&#39;s based on, essentially, unprincipled hacks on top of the system, rather than fixing the root problem, and the smartest kids in the world are going to keep noticing this. We need to instead dig into the root causes, to design systems and find ways of being that do not need such hacks, while still preserving what makes such real efforts to seek truth and change the world for the better special in the first place.</p><p> Then we are going to do the same thing with Artificial General Intelligence. Make it an agent, give it a maximalist goal that becomes misaligned out of the intended distribution that ignores key second-order and ethical considerations and inherently is incompatible with the necessary safeguards, and unleash upon the world. It will not end well for us. And that could even be thought of as the good scenario, where we are able to point the thing towards anything at all.</p><p> So yes. Remember and beware the tale of Sam Bankman-Fried. Not to blame or to label, but to learn from it. Do not let history repeat itself.</p><h4> Behold the Power of Yup</h4><p> Sam&#39;s great persona transformation, the book says, was when Sam realized that he should stop trying to make his words have meaning or map in any way to reality, and instead focus purely on agreeing with everything anyone said and telling people what they want to hear.</p><blockquote><p> But he wasn&#39;t going to change human nature, and so he decided that, going forward, he would bury any negative reactions he had to anything anyone said or did. He would give human beings with whom he interacted the impression that he was far more interested in whatever they were saying or doing than he actually was. He&#39;d agree with them, even if he didn&#39;t. Whatever idiocy came from them, he&#39;d reply with a Yuuuuuuppp! “It comes with a cost, but it&#39;s on balance worth it,” he said. “In most ways, people like you more if you agree with them.” He went from being a person you&#39;d be surprised to learn approves of you to a person you&#39;d be surprised to learn that, actually no, he doesn&#39;t. (1,834)</p></blockquote><p> The claim is that this completely brazen strategy flat out works, including when dealing with the rich, famous and powerful. Could it be this easy?</p><blockquote><p> “Yup” was Sam&#39;s go-to word, and the less he&#39;d actually listened to whatever you&#39;d just said, the longer he drew it out. Yuuuuuuuuup. (209)</p></blockquote><p> This is a great reverse tell, because normally extending your &#39;yup&#39; means that you are aware of the gravity of the situation.</p><p> The best part of a strategy where your entire plan is to agree with everything is you do not need to listen to what people say or have the slightest interest in it.</p><blockquote><p> Sam was game to talk to anyone—so long as he could play a video game while doing it. Sam went from being totally private to being a media whore. (161)</p></blockquote><p> I&#39;ve come around to the video game playing being genius. By trying to also play games that will not wait for you, like Storybook Brawl and League of Legends, SBF had a constant look that he was engaged and paying close attention. That is a hard thing to fake. Better to make it real. Also you get to play the video games.</p><p> What Sam also did frequently was to talk completely unguarded. Most famously on Odd Lots <a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=KZYqL79GDXU&amp;ab_channel=BloombergPodcasts">there was The Box</a> (link goes to episode, if you don&#39;t know I won&#39;t ruin it for you) but such statements were common. This also went for philosophy, as when he told Tyler Cowen he would take a 51% coinflip to double or destroy the Earth, and then keep taking the flips until everyone was dead. Reminds me of Trump, who will lie right to your face but will sometimes be honest about lying right to your face, which some people find endearing.</p><p> Thus, Sam in some ways had a reputation for honesty.</p><blockquote><p> “Sam was unlike anyone else, in that when he stated his opinion he did it with exactly his level of confidence, which is often very high,” recalled Adam Yedidia. (1,250)</p><p> Often he&#39;d leave her feeling uneasy about how much he&#39;d disclosed, and to perfect strangers. “There are some times I told him in the early days, You don&#39;t have to be so honest. In crypto everyone bluffs. Sam is always, Let me show you my last card.” (3,457)</p></blockquote><p> Yes, Sam was often very (over)confident, and said so. He also constantly lied to everyone&#39;s face and told them what they want to hear.</p><p> I wonder if this was the trick to getting an actual Sam opinion. If he does not give you a probability, look out, he wasn&#39;t even listening to you, sorry man. If he does give you a probability, then sure you have to recalibrate it but probabilities might be a sort of sacred trust, and also it is much harder to know what you want to hear.</p><p> It also helps to be graded on the crypto curve. Do you have any idea how little you could trust the word of anyone in crypto in 2018? A simple &#39;you follow professional norms and honor the word done in a trading chat&#39; backed with halfway decent execution went a long way.</p><p> The book claims that the PR campaign really was a pure &#39;let Sam be Sam&#39; where being Sam meant this superficially agreeable persona who took meetings while playing video games, combined with a willingness to talk remarkably frankly about technical details. They say that Natalie, the woman charged with PR and Sam&#39;s calendar despite having zero relevant experience, tried to call in professional help, but the professionals they did nothing.</p><blockquote><p> To help her in her new and unfamiliar role as head of FTX public relations, Natalie had called a New York public relations firm called M Group Strategic Communications. Its head, Jay Morakis, was at first wary. “I thought maybe it was some shady Chinese thing,” he said. But then he heard Sam&#39;s pitch, and watched Sam&#39;s first big public appearance, on Bloomberg TV. “Whatever the closest thing in my PR experience has been to this, nothing is close,” he said. “I&#39;m fifty years old. I&#39;ve had my firm for twenty years and I&#39;ve never seen anything like it. All my guys want to meet Sam. I have CEOs calling me and asking: Can you do for us what you did for Sam?” He&#39;d had to explain, back in 2021, that he actually hadn&#39;t done anything. Sam had just sort of . 。 。 happened. (2,025)</p></blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/patio11/status/1710436548599067021">Patrick McKenzie is in awe of this paragraph</a> .</p><blockquote><p> Patrick McKenzie (recently): We get more than a chapter with a twenty-something Taiwanese aide de camp who has no PR experience. Lewis would have you believe she single-handedly managed calendar, juggled magazine cover shoots, and put on conferences featuring eg Clinton.</p><p> And we get one paragraph where the CEO of a strategic comms consultancy shows up to modestly refuse any credit, then exits from the narrative at the speed of light.</p><p> *shakes head in confused mix of exasperation and professional regard*</p><p> God they&#39;re good.</p><p> The subtext, and is it even subtext, in the above is that: it is resoundingly unlikely one person, no matter talent level nor devotion, achieved the results that operation achieved. At some point you are limited by keystrokes possible per day.</p><p> And then the sort of stunning level of chutzpah it takes for the strategic consultancy to get a deniable PR hit *in a Michael Lewis book cataloging their client&#39;s implosion.* Which is carefully calibrated to say everything it needs to say to people who have budget authority.</p><p> Patrick McKenzie (11/17/22): An offhand comment on the topic of the day, from a comms professional: if you look at the number of interviews in prestige publications, the timing of them, the magazine covers, and the glowing coverage *post implosion*, I think you start to perceive the dark matter of a PR firm.</p><p> I wish I knew who it was, and I&#39;m not sure the conclusion would be “Never work with them” or “Definitely work with them; the apparently have the ability to root any media org they want at any time given any facts.”</p><p> They also seem to be intensely loyal to their client even though he is very, very clearly not listening to their advice.</p><p> An aside: some of the pieces which read to the general public as puff pieces read to journalists as hit pieces, for complicated cultural reasons. There is a language to these things, like there is a language to LessWrong.</p></blockquote><p> I am going to go ahead and agree with Patrick McKenzie that we saw, especially in the aftermath of FTX&#39;s collapse, what he described as &#39;the dark matter of a PR firm.&#39; I do not buy the story that there were no public relations professionals involved, that Sam went out and said &#39;yep&#39; a lot while playing video games, driving a Corolla and having a net worth of $20 billion, while one person with no experience did all the arrangements and scrambling, and everyone loved him and every press source treated him with kid gloves and all that. The system is hackable, but it is not that hackable. The parts of Sam&#39;s public relations operations I did have interaction with were very much conscious of exactly how public relations works via their well-compensated expert consultants. It would have been completely insane to do things any other way. Even by SBF standards.</p><p> This is one of many places where I am confident the events the book describes happened, and I am also confident that there is quite a lot of &#39;dark matter&#39; that is being left out, at least a lot of which Michael Lewis never found. Some of it I get a chance to mention here. Definitely not all, not even of the parts I know about.</p><p> Now for the chronological story of how this all played out.</p><p> First stop, Jane Street Capital.</p><h4> Jane Street Capital</h4><p> This is the part of the story I am best able to fact check. I too worked at Jane Street Capital, and directly witnessed a lot of this part of the story.</p><p> I also am deeply thankful to Jane Street Capital. It was not a fit for me in the end, but it was a pretty great place to work and they treated me right. I am not about to spill their secrets in ways they would not want such secrets spilled. I can safely say that this chapter is not entirely accurate, but the inaccuracies do not bear strongly on the SBF story, so I will decline to elaborate further.</p><p> SBF does not have that kind of ethical code. He was happy, on top of all SBF&#39;s actions at the time, to share a bunch of details with Michael Lewis.</p><p> I will say that the description of the interview process was spot on, I very much enjoyed my shot at it, and that I can totally believe SBF got the high score.</p><blockquote><p> Jane Street offered him a summer internship. So for that matter did the other high-frequency trading firms that had invited him to apply. One firm had halted their interview process midway through and announced that Sam had done so much better at their weird games and puzzles than every other applicant that there was no longer any point in watching him play. (769)</p></blockquote><p> As I have said before, I recommend going through the Jane Street interview process, even if you do not think you have much chance of being hired. It is great.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.bloomberg.com/opinion/articles/2023-10-04/sbf-was-reckless-from-the-start?srnd=undefined">Matt Levine has extensively discussed the Asher Incident</a> .</p><p> What matters to the broader story is that this Asher guy was another intern who offered SBF a bet without thinking through the implications, offering SBF a chance to both make about $33 in expected value and also humiliate Asher, and oh boy did SBF take full advantage, continuing to rub it in well past the point where he had secured his profit and was doing anything other than rubbing it in Asher&#39;s face.</p><blockquote><p> “It was not like I was unaware I was being a piece of shit to Asher,” he said. “The relevant thing was: Should I decide to prioritize making the people around me feel better, or proving my point?” (951)</p></blockquote><p> This is such a strange response. There was quickly nothing left to prove once Sam pointed out Asher&#39;s mistake. Sam did not prioritize proving his point over having others feel better. He prioritized making Asher feel worse. That is not cute nerd indifference to social cues. Michael Lewis pretends not to notice the difference.</p><p> The actual bet was on the maximum loss by any Jane Street intern that day from gambling. Interns were encouraged to bet and make markets against each other, with a maximum loss of $100 per day so no one got seriously hurt. SBF bought a contract for $65 that paid out equal to the maximum loss, then (of course) paid $1 to get another intern to flip a coin for, oh, about $99. Then, for no good reason, he did it two more times.</p><p> Matt Levine and his readers point out that there was a better version of the trade, which was to pay $1 to get two interns to flip against each other. What he forgets is that SBF is not one to shy from variance. What was not pointed out was the fun problem that if SBF had lost the initial coin flip, then Asher could have claimed that since SBF won his bet with Asher, he hadn&#39;t lost the full $100. The best is now self-referential. And SBF couldn&#39;t have clarified this before accepting the bet without tipping Asher off to why SBF would always win. What is the result? Presumably you need the result where the contract resolves correctly, Sam has to lose what the contract pays out, so it is the halfway point and resolves $82.50, paying out $17.50? And by flipping the coin himself, Sam gave up a quarter of his expected profit?</p><p> The bosses were not happy, and thought Sam needed to learn to read the room.</p><blockquote><p> Sam thought his bosses had misread his social problems. They thought he needed to learn how to read other people. Sam believed the opposite was true. “I read people pretty well,” he said. “They just didn&#39;t read me.” (951)</p></blockquote><p> It had not occurred to the bosses, presumably, that Sam could read others fine, and the problem was that Sam did not care. Either way, Sam was right that his lack of ordinary facial expressions was a problem.</p><p> So Operation Ordinary Facial Expressions was born.</p><blockquote><p> Just because he didn&#39;t feel the emotion didn&#39;t mean he couldn&#39;t convey it. He&#39;d started with his facial expressions. He practiced forcing his mouth and eyes to move in ways they didn&#39;t naturally. (1,014)</p></blockquote><p> Here&#39;s one anecdote I can indeed confirm, and it was as crazy as it sounds:</p><blockquote><p> Every time Brazil won a World Cup match, the Brazilian stock market tanked, for instance, because the win was thought to increase the shot at reelection of Brazilian president Dilma Rousseff, perceived to be corrupt. (1,111)</p></blockquote><p> The book then describes a refinement or extension of this trade, which I would not choose to confirm or deny regardless of whether it happened. What if SBF could simply predict the outcome of the 2016 election an hour ahead of everyone else?</p><blockquote><p> That is, it would be surprising if Jane Street couldn&#39;t learn the results of the presidential election before anyone else in the financial markets or for that matter the entire world. (1,123)</p></blockquote><p> There then follows a section on Sam&#39;s version of what happened with the 2016 presidential election, where he and Lewis both draw all the wrong conclusions (even if you were to believe the exact story presented), and became convinced that he could be the best like no one ever was and make all the money and Jane Street was not maximizing enough and thus holding him back.</p><p> Then a bit later, SBF decided to leave Jane Street, because he discovered the Japan and South Korea Bitcoin arbitrage trade, and he wanted the trade all to himself.</p><p> This is one place I will introduce myself into the story a tiny bit. When Sam decided to quit, the two of us went for a walk in the park. He said he was leaving to run or at least help run CEA, the Center for Effective Altruism. Which was not a crazy fit, Sam was clearly deeply into EA and the thesis that he could be a major upgrade there seemed plausible, as did the possibility that from his perspective this could be high leverage. I was confused by his decision, Jane Street seemed like a better fit for him, but we strategized a bit about how good could be done and I wished him the best of luck.</p><p> As we all know now, he was, as with everyone else, lying right to my face.</p><blockquote><p> During his final weeks at Jane Street, Sam traveled to Boston just to tell Gary about his plan to make a billion dollars trading crypto for effective altruistic causes. (1,423)</p></blockquote><p> He admit it. He was not leaving to join CEA. He was leaving to pursue the Japan trade. And he had decided that I was not someone he wanted to bring in on that.</p><p> I&#39;d also note Sam wrote this:</p><blockquote><p> “but [my coworkers] show no interest in seeing who I really am, in hearing the thoughts I hold back. The more honest I try to make our friendships, the more they fade away. No one is curious. No one cares, not really, about the self I see. They care about the Sam they see, and what he means to them. And they don&#39;t seem to understand who that Sam is—a product of thoughts that I decide people should hear. My real-life twitter account.” (1,205)</p></blockquote><p> I am not saying I made the most robust effort to build a close friendship with Sam, but I was right there, happy to talk to him before he was him, culturally rather adjacent sharing many of his interests, and (I like to think) very clearly able to keep a secret. We had him over for dinner once, and by my wife&#39;s recollection he didn&#39;t say two words to her, nor did he eat any of the food (yes we&#39;re not vegans but we do make efforts to accommodate), while trying to get me to disassociate with someone making concrete criticisms of EA because criticisms hurt the cause. So, yeah.</p><p> On reflection, it was vastly overdetermined that Sam had no reason to tell me what was going on. Why take that risk? I clearly was not about to work 18 hour days in Berkeley, California. It was unlikely I would have let him own 100% of the firm. I was too old and busted, a &#39;grown-up&#39; he had no use for, and ultimately a rationalist is not an EA who will trust Sam completely, so in many ways I was the opposite of EA. Why take the risk that I might not keep his confidence?</p><p> Looking back now, of course, I am for my own sake deeply happy that he did not attempt to take me with him. How might things have been different if I had somehow ended up going with him? Would I have been able to steer things to turn out differently? Would I have been only another person who left with the management team, or another witness on the stand, or could I have helped steer the ship? Would I have perhaps managed to block the Anthropic investment? We will never know.</p><p> Without loss of generality or confirming any of the other bits, there are too many different things to get into it all, I&#39;d also like to dispute this (very gentle?) slander:</p><blockquote><p> By Wall Street standards, Jane Street was not a greedy place. Its principals did not flaunt their wealth in the way that the guys who had founded other high-frequency trading firms loved to do. They didn&#39;t buy pro sports teams or hurl money at Ivy League schools to get buildings named for themselves. They were not opposed to saving a few lives. But Jane Street was still on Wall Street. To survive, it needed its employees to grow attached to their annual bonuses, and accustomed to their five-bedroom Manhattan apartments and quiet, understated summer houses in the Hamptons. The flood of effective altruists into the firm was worrisome. (1,312)</p></blockquote><p> That is quite a rich thing to say. The employees I knew in no way felt stuck trading in order to support their lavish lifestyles. They traded because they very much enjoyed it, were good at it, liked the team they were on and so on. Many indeed were and are largely altruists, and wanted to do good as effectively as possible. Not being ostentatious was not an act.</p><p> It was the flood of effective altruists out of the firm that was worrisome. It was the effective altruists who were the greedy ones, who were convinced they could make more money outside the firm, and that they had a moral obligation to do so. You know, for the common good. They proved themselves neither honest nor loyal. Neither was &#39;part of their utility function.&#39;</p><p> All right. On to Alameda.</p><h4> Soiling the Good Name of Alameda County</h4><p> All time great chapter opening. Again, the man can write.</p><blockquote><p> It took only a couple of weeks of working for Sam before Caroline Ellison called her mother and sobbed into the phone that she&#39;d just made the biggest mistake of her life. (1,271)</p></blockquote><p> Caroline had many very good instincts throughout. If only she had followed them.</p><blockquote><p> Over coffee in Berkeley, Sam was cagey about what he was up to. “It was, &#39;I&#39;m working on something secret and I can&#39;t talk about it,&#39; ” recalled Caroline. “He was worried about recruiting from Jane Street. But after we talked a while, he said, &#39;I guess maybe I could tell you.&#39; (1,295)</p></blockquote><p> Oh yes, Sam, famously worried about recruiting from Jane Street.</p><blockquote><p> In late March she started the job. The situation inside Alameda Research wasn&#39;t anything like Sam had led her to expect. He&#39;d recruited twenty or so EAs, most of them in their twenties, all but one without experience trading in financial markets. (1,337)</p></blockquote><p> Why did he recruit EAs? Partly because he thought EAs would work infinite hours for almost no pay and still be worthy of and provide limitless trust. Exploit the recruits for cheap labor, without even the pretense of a non-profit.</p><blockquote><p> Anyone who started a crypto trading firm would need to trust his employees deeply, as any employee could hit a button and wire the crypto to a personal account without anyone else ever having the first idea what had happened. Wall Street firms were not capable of generating that level of trust, but EA was. (1,402)</p></blockquote><p> That would explain how Alameda could lose money trading crypto in large parts of 2018, despite it being extremely difficult to lose money trading crypto in 2018 if you know how trading works. It could also explain why Sam wanted to rely on his bot program. No one knew how to trade!</p><p> Alameda started out with the arbitrage trade with South Korea and Japan. It is not clear the extent to which they managed to take advantage of it – the book describes them as getting only secondary, much less profitable versions of it, Sam debating various wild schemes to do better but not pulling the trigger on them because they were too absurd even for him, and ultimately the opportunity vanishing.</p><blockquote><p> It wasn&#39;t Sam&#39;s first thought, but he considered buying a jumbo jet and flying it back and forth from Seoul, filled with South Koreans carrying suitcases each holding $10,000 worth of won, to a small island off the coast of Japan. “The problem is that it wasn&#39;t scalable,” said Sam. “To make it worthwhile, we needed like ten thousand South Koreans a day. And we probably would have attracted so much attention doing it that we would have been shut down. Once the South Korean central bank saw you with ten thousand South Koreans carrying suitcases full of won they&#39;d be like, There&#39;s going to be a new direction here.” Still, he was tempted. (1,483)</p></blockquote><p> Which brings us to the bot.</p><p> The bot in question was called Modelbot. I would have simply called it Arbbot.</p><p> The idea was simple, and also very much something I would have tried. There were a lot of different exchanges trading a lot of cryptos at lots of different prices. Sometimes the prices were different. When that happened, you could do various forms of arbitrage (and statistical arbitrage). Sam, being a trader and also being Sam, was a big fan of taking the free money.</p><p> What made it extra attractive was that, while Sam had declined (or failed) to hire actual traders, he did manage to hire a world class programmer, and he did manage to raise capital while exploiting the country arbitrage trade.</p><blockquote><p> They didn&#39;t blow up, not at first. Those first few weeks, they made no real money, but then they had only a few people and Sam&#39;s bonus money. By the end of December, they&#39;d hired a bunch of people and raised $25 million in capital. Gary, basically all by himself, had written the code for an entire quantitative system. That month they generated several million dollars in profits. In January 2018 their profits rose to half a million dollars each day, on a capital base of $40 million—whereupon an effective altruist named Jaan Tallinn, who&#39;d made his fortune in Skype, handed them $130 million more to play with.</p></blockquote><p> So Sam built Modelbot to do exactly that, and he would have gotten away with it too except for those meddling (Effective Altruist) kids.</p><blockquote><p> He had not been able to let Modelbot rip the way he&#39;d liked—because just about every other human being inside Alameda Research was doing whatever they could to stop him. “It was entirely within the realm of possibility that we could lose all our money in an hour,” said one. One hundred seventy million dollars that might otherwise go to effective altruism could simply go poof. (1,368)</p></blockquote><p> Not &#39;170 million dollars of our investors money.&#39; Not &#39;our only opportunity to trade, obviously we wouldn&#39;t get another.&#39; Not even &#39;and if we lost it like that I can&#39;t help but wonder if we&#39;d have some legal or other problems to deal with.&#39;</p><p> No, this was 170 million dollars &#39;that might otherwise go to effective altruism.&#39;</p><p> Something is deeply, deeply wrong with that picture. Although not as wrong as Sam&#39;s part of the picture.</p><blockquote><p> [One] evening, Tara argued heatedly with Sam until he caved and agreed to what she thought was a reasonable compromise: he could turn on Modelbot so long as he and at least one other person were present to watch it, but should turn it off if it started losing money. “I said, &#39;Okay, I&#39;m going home to go to sleep,&#39; and as soon as I left, Sam turned it on and fell asleep,” recalled Tara. From that moment the entire management team gave up on ever trusting Sam. (1,372)</p></blockquote><p> I mean, good on the management team for fully updating on trusting Sam, although not fully updating on &#39;this person needs to be removed immediately if not sooner,&#39; assuming Tara&#39;s account is accurate, and the book does not say that Sam disputes it, nor does it seem remotely inconsistent with other Sam things. Turning on the bot after promising not to is bad enough, but turning on a new bot and then falling asleep with no one else watching it? Yeah, that is another planet of not okay.</p><p> That is not the weird part of the story. The weird part of the story is, why was it non-trivial to test whether or not the bot worked?</p><p> Any bot you would ever dare turn on has various risk limits. You can turn the bot on, with very low limits on how much it is allowed to trade. Do the trades small. See if you end up with more money than you started with, in the same places it started. If you can do that, you can start slowly ramping the numbers up. Standard procedure. If you can&#39;t do that, you haven&#39;t finished programming your bot, so get on that. Have multiple people watching at all times, analyzing the trades, seeing if things make sense, refining your algorithms as you go.</p><p> Instead, the claim is that Sam turned the program on with no one watching, without any reason not to wait, then went indefinitely with no way to test whether the program would actually work if one turned it on. I notice I am confused.</p><p> Alameda, without a profitable bot and without the arbitrage trade, started bleeding money as per the book&#39;s own report, and they were paying very high interest rates to borrow money. Things did not look so good and were escalating quickly.</p><p> Then comes the story of the missing Ripple. They were supposed to have $4 million worth of Ripple. Then they lost it. No one knew where it was.该怎么办？</p><p> Sam&#39;s attitude was that the Ripple would probably turn up, so no duty to the investors to say anything, no need to worry, carry on your day. Others were, understandably, rather more concerned?</p><blockquote><p> After the fact, if we never get any of the Ripple back, no one is going to say it is reasonable for us to have said we have eighty percent of the Ripple. Everyone is just going to say we lied to them. We&#39;ll be accused by our investors of fraud. That sort of argument just bugged the hell out of Sam. He hated the way inherently probabilistic situations would be interpreted, after the fact, as having been black-and-white, or good and bad, or right and wrong.</p></blockquote><p> Remind you of anything that&#39;s going to happen in the second half of the book? Yes, it turns out that if you tell people everything&#39;s fine but you have reason to know it very well might not be fine, often that would constitute fraud. You cannot, in general, simply not mention or account for things that you&#39;d rather not mention or account for.</p><p> So between Sam asking everyone to work 18 hour days all the time, and being a generally irritable and horrible person to work for, and being completely untrustworthy and risking all the money for no reason, and misplacing $4 million in Ripple and then proposing to act like that hadn&#39;t happened, and also for the company bleeding money and a bunch of other stuff, for some strange reason, Sam&#39;s entire management team decided they had enough and wanted Sam out.</p><p> The management team ran into a problem. Thanks to them taking &#39;I promise I&#39;ll get to that later, we need to move fast&#39; as an explanation, Sam owned the entire company. Somehow everyone had allowed this.</p><p> The book&#39;s account also claims the offer had an absurd clause that was completely unsingable, aiming to bankrupt Sam outright. Not typically how one gets to yes.</p><blockquote><p> For a start, Sam owned the entire company. He&#39;d structured it so that no one else had equity, only promises of equity down the road. In a tense meeting, the others offered to buy him out, but at a fraction of what Sam thought the firm to be worth, and the offer came with diabolical fine print: Sam would remain liable for all taxes on any future Alameda profits. At least some of his fellow effective altruists aimed to bankrupt Sam, almost as a service to humanity, so that he might never be allowed to trade again. (1,555)</p></blockquote><p>什么？ Liable for all taxes on any future Alameda profits? As fine print they hoped Sam wouldn&#39;t notice, perhaps? That is the most absurd ask I have ever seen, Sam obviously would rather light the entire enterprise on fire than agree to that. I have no knowledge here one way or the other, but I have to assume this is not a complete and accurate description?</p><p> The book confirms that the whole thing seemed pretty nuts the way it is described.</p><blockquote><p> The conversations we had were absolutely fucking nuts,” he recalled. “Like to what extent Sam should be excommunicated for deceiving EAs and wasting EA talent. And like &#39;the only way Sam will learn is if he actually goes bankrupt.&#39; They told our investors he was faking being an EA, because it was the meanest thing they could think to say.” Ruining Sam wasn&#39;t enough, however: they expected to be paid on their way out the door. “They wanted severance, even though they were quitting and it was a money-losing operation in which they didn&#39;t have a stake,” said Nishad. “They were saying that Sam needed to buy them out and they were worth more than one hundred percent of the value of the entire company because Sam was a net negative.” (1,575)</p><p> And now all these unprofitable effective altruists were demanding to be paid millions to quit—and doing whatever they could to trash Sam&#39;s reputation with the outside world until they got their money. (1,584)</p></blockquote><p> That is not typically how any of this works. Quitters do not typically get severance. Quitters definitely do not typically get more than 100% of the value of the entire company. If someone demands you buy them out for more than the company is worth, and they accurately describe how much the company is worth, presumably you say &#39;wait, that is more than the company is worth, why would I ever pay that?&#39;</p><p> To his credit, Nishad noticed that he was deeply confused.</p><blockquote><p> It occurred to Nishad that the effective altruist&#39;s relationship to money was more than a little bizarre. Basically all of Alameda Research&#39;s employees and investors were committed to giving all their money away to roughly the same charitable causes. You might surmise that they wouldn&#39;t much care who wound up with the money, as it all would go to saving the lives of the same people none of them would ever meet. You would be wrong: in their financial dealings with each other, the effective altruists were more ruthless than Russian oligarchs. Their investors were charging them a rate of interest of 50 percent. “It wasn&#39;t a normal loan,” said Nishad. “It was a shark loan.” In what was meant to be a collaborative enterprise, Sam had refused to share any equity (1,578)</p></blockquote><p> Ah, yes, the funders demanding 50% interest. I can take this one. Loaning money to even a relatively responsible crypto firm is highly risky and, typically, deeply stupid. This is not 2022-hindsight, back in 2018 I was trading for a crypto firm and we had borrowed money and I remarked that I had no idea why anyone had voluntarily loaned us any. Invest in a crypto trading firm? Sure, maybe. Could work. Big upside. But why would you instead loan money to a crypto firm, where if Number Go Up you get a modest interest payment and if Number Go Down your number goes down to zero?</p><p> The ideal answer is that you don&#39;t. If you must, earn enough interest that it is worth it. A rate of 50% seems if anything a bit low.</p><p> The whole idea of the EAs who left &#39;trashing Sam&#39;s reputation&#39; is treated as a big deal here, and as the reason the funders cut back a lot in size. But I never heard the complaints until FTX was blowing up? Most I know didn&#39;t hear them? Given how big FTX was in EA spaces, does it seem a bit weird that this massive reputation-trashing operation went so unnoticed? They certainly had plenty of good material to work with. If they&#39;d presented the facts as laid out in the book, that seems like enough?</p><p> Why do we get to flash forward to this, after it all fell apart:</p><blockquote><p> From the start, Zane had been enthralled by Sam, and by the empire he might create. But he hadn&#39;t signed up to the cause blindly. Before joining FTX, he&#39;d consulted his old friends in crypto. CZ was one of them. “It was CZ who told me about him,” he now recalled. “He said, &#39;I think that&#39;d be a really good option for you.&#39; People have asked me, &#39;How did you come to trust Sam so much?&#39; CZ was the start of it. But nobody had a bad thing to say about him.” Zane was the gunslinger who&#39;d been talked into making a respectable home in the town alongside what appeared to be law-abiding folk. Lots of big crypto speculators had entrusted their money to FTX because they trusted Zane. (3,338)</p></blockquote><p> Why was it that <a target="_blank" rel="noreferrer noopener" href="https://forum.effectivealtruism.org/posts/xafpj3on76uRDoBja/the-ftx-future-fund-team-has-resigned-1?commentId=ugDoKrwtkR9DaM4d4">EA leadership didn&#39;t get the message to Eliezer</a> ?</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F038a5d26-7650-4be0-a4d6-811b54ea36eb_1026x1240.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AocXh6gJ9tJC2WyCL/cgjzdxetelgc8dbql5jf" alt=""></a></figure><p> And as for the funders that cut back in size, maybe the reason for that was that they gave Sam big size so Sam could do the one big trade, and now that it was over it made sense to scale back down?</p><p> Instead, the book says that seven figures in severance was indeed paid, Sam went on with Alameda, and then everyone kind of forgets, and by the later parts of the book Sam is seen as having an unblemished reputation.</p><p> So, you&#39;ve had your entire management team walk out. What will you do next?</p><blockquote><p> What happened next, in retrospect, seems faintly incredible. With no one left to argue with him, Sam threw the switch and let Modelbot rip. “We turned it on and it instantly started making us lots of money,” said Nishad. And then they finally found the $4 million worth of missing Ripple. (1,606)</p></blockquote><p> I notice I am still confused. Modelbot instantly made a lot of money? Why didn&#39;t they turn it on for small before? Was there no experiment to run? What happened the previous time that Sam turned it on and fell asleep? None of this makes sense.</p><p> (What happened to the Ripple was that it was improperly labeled when sent to an exchange, so it piled up there while the exchange had no idea whose it was until they finally traced the thing and figured it out, at which point the exchange yelled at them for being complete idiots but did hand over the Ripple. Very nice of them, and also pretty insane that they let things drag out that long before figuring it out.)</p><p> Those who stayed behind did not make the correct updates.</p><blockquote><p> They were no longer a random assortment of effective altruists. They were a small team who had endured an alarming drama and now trusted Sam. He&#39;d been right all along! (1,618)</p></blockquote><p> Sam proved he could design a profitable arbitrage bot. And that he got lucky with his carelessness. That this time the risks paid off. Also that he was a terrible manager and team builder whose chosen management team all hated him so much after a short period that they walked out on him while actively trying to take him down.</p><p> Those who remained concluded… other things.</p><p> Sam also concluded that since EAs would not play ball, he shouldn&#39;t hire so many EAs.</p><blockquote><p> His fellow EAs&#39; behavior caused him to update his understanding of their probability distributions in ways that left him less willing to hire EAs. (1,805)</p></blockquote><p> As much as I criticize EAs here and elsewhere, they do tend to notice when you are completely untrustworthy and your statements are not at all truth tracking. And then they tend to then care about it. They often don&#39;t actually want to work constant 18 hour days. Also, newly hired EAs were not going to be personally loyal in the way that SBF wanted.</p><p> How fraudulent was the operation? Once again: <a target="_blank" rel="noreferrer noopener" href="https://www.theblock.co/post/186187/alameda-promised-high-returns-with-no-risk-in-2018-pitch">This is their 2018 deck, which claims >;100% consistent annualized returns</a> (and &#39;no risk&#39;). There is no ambiguity here.</p><h4> How Any of This Worked</h4><p> The crypto world was a hive of scum and villainy long before SBF got involved. There were also plenty of idealists and well-meaning, honest people, as there usually are. Those were mostly not the people getting rich, or the ones running the exchanges.</p><p> The exchanges were licenses to print money proportional to their user bases, with users who were asking all the wrong questions and no regulators or consumer watchdogs keeping them in check, so it got ugly out there.</p><blockquote><p> Across Asia, new cryptocurrency exchanges were popping up every month to service the growing gambling public. They all had deep pockets and an insatiable demand for young women.</p><p> They were hiring lots of people because they could afford to, and big headcounts signaled their importance. (93)</p></blockquote><p> The main thing customers demanded of crypto exchanges was, and I can confirm this, the ability to take wildly irresponsible gambles with their crypto. As in customers highly valued 100:1 leverage, using $100 of Bitcoin to buy $10,000 of Bitcoin, willing to lose it all if the price dipped by 1% for a microsecond.</p><p> People think using this leverage is a good idea. They are always wrong. Michael Lewis seems confused about this as well.</p><blockquote><p> Here was one example of the games that were played: Several of the Asian exchanges offered a Bitcoin contract with one hundred times leverage. Every now and then, some trader figured out that he could buy $100 million worth of bitcoin at the same time he sold short another $100 million worth of bitcoin—and put up only a million dollars for each trade. Whatever happened to the price of bitcoin, one of his trades would win and the other would lose. If bitcoin popped by 10 percent, the rogue trader collected $10 million on his long position and vanished—leaving the exchange to cover the $10 million he&#39;d lost on his short. (1,736)</p></blockquote><p> This is mostly a no good, very bad trade, because the exchange liquidates your account while it still has positive value, and by &#39;liquidate&#39; the exchange meant &#39;confiscate all of it and write you down to zero.&#39; Maybe they would then actually liquidate what was there, maybe they wouldn&#39;t, that was up to them.</p><p> Are there versions of this trade that are good for you and bad for the exchange? Assuming, of course, that we completely ignore that it would be safe to presume all of this is market manipulation and multi-accounting and very much not legal, because lol legal, lol compliance department, this is crypto what are you even talking about.</p><p>是的。 If there were effectively no law but code, I can think of three.</p><ol><li> You have reason to expect (or cause) Bitcoin to be even more volatile than usual, and for there to be a jump in price that gets your wrong-way trade liquidated at a negative account value. For example, if you are allowed to do this trade right before the decision on whether to allow a Bitcoin ETF, then the trade seems good.</li><li> You can size big enough to force the exchange to make big trades that impact the entire Bitcoin market. As in, Bitcoin goes up 75bps (0.75%) and they liquidate your short position (which was still worth $250k) to zero. But by doing that, they drive up the price of Bitcoin a lot more, after they have impact you sell your Bitcoins, and you end up ahead. Not impossible back in the day if they let you scale up big enough.</li><li> You can provide directly to the liquidation, and the liquidation mechanism is dumb. So when your short account is liquidated, the exchange issues market buy orders bigger than their market can bear rather than doing something less stupid, your account has various sell orders at higher prices, you fill a lot of the liquidation order at stupid prices, you quickly sell off the remainder before prices restabilize, and you laugh.</li></ol><p> When I was trading crypto, I insisted on caring about things like not doing market manipulation, not spoofing orders and not trading when I had material non-public information (aka insider trading). This mostly made everyone else rather annoyed at me for being such a stickler for the laws of some alien world. They put up with it because, as the smoking man put it, they needed my expertise.</p><p> Wash trading was common.</p><blockquote><p> Wash trading, as it was called, would have been illegal on a regulated US exchange, though the sight of it did not bother Sam all that much. He thought it was sort of funny just how brazenly many of the Asian exchanges did it. In the summer of 2019, FTX created and published a daily analysis of the activity on other exchanges. It estimated that 80 percent or more of the volume on the second- and third-tier exchanges, and 30 percent of the volume on the top few exchanges, was fake. Soon after FTX published its first analysis of crypto trading activity, one exchange called and said, We&#39;re firing our wash trading team. Give us a week and the volumes will be real. The top exchanges expressed relief, and gratitude for the analysis, as, until then, lots of people assumed that far more than 30 percent of their volume was fake. (2,429)</p></blockquote><p> I discovered this because I was trading on Binance, attempting to purchase Stellar for someone who wanted to purchase a bunch of Stellar when it was the #8 coin in the world (it is #23 now), and continuously failing to purchase any Stellar. There would be trading, I would issue a buy order where it was trading, and the entire market would mysteriously shift up. I would withdraw the order, things came back down. The market moved if you breathed on it, there was no way to get any size. It didn&#39;t make sense until I realized that most of the trading was not real. The whole thing was a house of cards. I reported this back and the person said, yes, everyone knows there&#39;s a lot of wash trading, I still want to buy Stellar. There&#39;s only so much you can do.</p><p> Lewis offers a strange claim here:</p><blockquote><p> Toward the end of 2018 the markets suddenly changed again. Spreads tightened dramatically, going from 1 percent to seven one-hundredths of a percent. (1,754)</p></blockquote><p> I mean, no, they didn&#39;t? I was at least kind of there, unrelatedly trading crypto. Throughout 2018 there were plenty of ways to trade rather large amounts for far less than a percent. Yes, spreads did tighten, and I am confident Alameda contributed to that tightening, but this was not an order of magnitude change.</p><p> Nor was it the final change. As time went on, spreads would tighten further. Alameda would be in a more and more competitive business. This was likely a prime motivation behind creating a crypto exchange, FTX, before Alameda lost its edge.</p><p> During this period, SBF relocated to Hong Kong, because he found that being in the room with other crypto people was very good for business.例如：</p><blockquote><p> Weeks before he flew to Asia, one of the big Chinese crypto exchanges had frozen Alameda&#39;s account with a bunch of money in it, for no obvious reason. Customer service hadn&#39;t returned their calls. After meeting Sam in person, the exchange&#39;s bosses handed him back his money. (1,782)</p></blockquote><p> It also gave Sam access to a new labor pool, one eager to get into the game and do whatever it took without asking questions, and got everyone out of the United States.</p><p> Sam&#39;s approach to hiring was to ensure no one ever know what they were doing, so this new pool of talent worked out great.</p><blockquote><p> Faced with a necessity, Sam turned it into a virtue. “It&#39;s a moderately bad sign if you are having someone do the same thing they&#39;ve done before,” he said. “It&#39;s adverse selection of a weird sort. Because: why are they coming to you?” (1,974)</p></blockquote><p> Spoken like an employer who does not know how to attract the best talent, and also someone who even Michael Lewis knows is bullshitting this time.</p><p> Another potential factor in this story that is not mentioned by Lewis, and also that did not come up in my previous post, is Tether. <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/patio11/status/1712096233672581273">Patrick McKenzie has the theory</a> that Alameda&#39;s true main business was knowing what to say to American banks to allow Tether to move capital. That they were centrally engaged in fraud on this entire additional level.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/patio11/status/1709206146249117927">This related thread of Patrick McKenzie&#39;s is also fun.</a> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/patio11/status/1709583245153599940">As is this one</a> . Or at least, you can learn more about what I (and I assume Patrick) find fun.</p><p> The next step was building a crypto exchange.</p><h4> Building FTX</h4><p> Sam had a secret weapon in building FTX, which is that he had a programmer that could single-handedly (so the book says) program the whole thing better than most programming teams. Knowing what I know about exchanges and engineers, this claim is a lot less wild than it sounds. At core an exchange is about getting a small number of important things right, which FTX mostly did get right except where Sam chose to intentionally get them wrong. I totally believe that a two person team, one to know what to do and the other to do it, could have pulled that off.</p><p> Before going down other funding routes, Sam tried to get CZ of Binance to pay.</p><blockquote><p> The first decision CZ had to make was whether to pay Sam the $40 million he was asking for his cleverly designed futures exchange. After thinking it over for a few weeks in March 2019, CZ decided no—and then told his people to create a futures exchange on their own. Which struck Sam as such an ordinary and vaguely disappointing thing to do. “He&#39;s kind of a douche but not worse than a douche,” said Sam. “He should be a great character but he&#39;s not.” (1,893)</p></blockquote><p> I do not really know what Sam was expecting. CZ presumably took a few weeks to think it over in order to keep optionality and get a head start, if he wasn&#39;t already building such an exchange anyway as seems rather plausible. Luckily for Sam, he still managed to do the better execution than CZ.</p><p> The book describes CZ as a strangely conventional and unimaginative person, who created Binance and made it the dominant exchange on the planet, becoming one of the richest people on Earth, without any exceptional qualities or skills of note. Lewis makes it sound like CZ was one of many who started exchanges, and he was at the right place at the right time and things broke his way. I don&#39;t know anything about CZ that isn&#39;t common knowledge, but I do not buy this at all. Random people do not luck into that kind of situation. But that would be the story of a different book.</p><p> So now Sam needed money to build FTX. He had a killer programmer, but there is a lot more to an exchange than that. So it was time to fundraise.</p><p> The book talks about two ways they raised money: Selling FTT tokens, which are a cryptocurrency Sam created representing claims on a portion of FTX&#39;s future revenue and thus effectively a form of preferred stock in FTX, and traditional VC fundraising.</p><p> The FTT story is told as a story of quick success. He starts out charging early people $0.10, then quickly that goes up quite a lot, some people get rich out of the gate, Sam is sad at what he gave away. VCs in this spot, and crypto people too, tell you not to be upset about that. You need big gains and a story to drive excitement, you still have most of the company and a ton of the tokens. You have what you need. Why fret it? Instead, Sam says later in the book he regretted creating the tokens and sold them so cheap, rather than regretting the tokens because he used them later in such crazy fashion that he blew up his whole empire.</p><p> The stock story is where SBF learns the basics of how VC works. In traditional Sam fashion, he noticed things were kind of arbitrary and dumb, then did not stop to think that they might not be as arbitrary and dumb as all that and there might be method to the madness even if it wasn&#39;t fully optimal.</p><blockquote><p> In early 2021, Jump Trading—not a conventional venture capitalist—offered to buy a stake in FTX at a company valuation of $4 billion. “Sam said no, the fundraise is at twenty billion,” recalled Ramnik. Jump responded by saying that they&#39;d be interested at that price if Sam could find others who were too—which told you that the value people assigned to new businesses was arbitrary. (2,060)</p></blockquote><p> No, this does not mean the valuation is arbitrary. That is especially true when, as was the case in FTX and most crypto companies, you politely decline to let anyone do proper due diligence, and you&#39;re not even a traditional VC. What is going on is that Jump is quite reasonably deciding that at a fair rate they would be willing to invest, but that they are not in position to evaluate what is fair. So they outsource that to others, including to the lead whoever that might be. If VCs are willing to costly signal, via their own investment, that a $20 billion valuation is reasonable, then Jump can be in as well.</p><blockquote><p> Selling a new business to a VC was apparently less like selling a sofa than it was like pitching a movie idea. (2,063)</p></blockquote><p> Well, yeah, that one is largely right. They care a ton about a good story.</p><p> Then we have Sam being peak Sam a bit.</p><blockquote><p> A guy from Blackstone, the world&#39;s biggest private investment firm, called Sam to say that he thought a valuation of $20 billion was too high—and that Blackstone would invest at a valuation of $15 billion. “Sam said, &#39;If you think it is too high, I&#39;ll let you short a billion of our stock at a valuation of twenty billion,&#39; ” recalled Ramnik. “The guy said, &#39;We don&#39;t short stock.&#39; And Sam said that if you worked at Jane Street you&#39;d be fired the first week.” (2,084)</p></blockquote><p> Sam is very much the one who gets fired in the first week here. No, you are not obligated to flip coins every time you think you have a tiny edge, especially billion dollar ones with uncapped potential losses subject to potential rampant manipulation and huge adverse selection. Nor has Sam paused to consider the cost of capital. VCs demand edges well in excess of 33% before they are willing to invest.</p><p> It is crazy, completely insane, to think that a VC willing to invest in a start-up at $15 billion would want to be short for size at $20 billion, with no market or way to cover.</p><p> Another part of the puzzle is that Sam used Alameda&#39;s resources to create FTX, <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/alpackaP/status/1593308236568055808">and the first VC that Sam talked to figured this and a number of other things out</a> .</p><p> Yet presumably Sam said this because he not only thought he was right, he thought he was so obviously right it made sense to say so over the phone. That tells you a lot about Sam&#39;s attitude towards capital, sizing, risk and other related matters, and also in believing that he know&#39;s all and everyone else is an idiot, which is <a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=iaHDBL7dVgs&amp;ab_channel=TheTomLehrerWisdomChannel">more, more, I&#39;m still not satisfied</a> .</p><h4> The Sam Show</h4><p> What about physically building FTX, as in their new headquarters in the Bahamas that was never finished?</p><p> There&#39;s a bunch of great stories in the book about the architects who got brought in to make this very expensive building, who were given no guidance, and desperately tried to figure out what their client wanted. All they got were three quick notes – the shape of an F, a side that looked like Sam&#39;s hair, and a display area for a Tungsten Cube – that Sam also didn&#39;t bother writing, instead someone else tried to imagine what Sam might ask for. It was all the Sam show, all about Sam all the time, very cult of personality or at least hair.</p><blockquote><p> Even from their jungle huts people jockeyed for a view of him. The architects schemed the main building with glass walls and mezzanines that offered unlikely interior views of Sam. “It gives you an opportunity to catch glimpses of Sam no matter where you are sitting,” said Ian [the architect]. (2,569)</p><p> The list had been created by someone else inside FTX who&#39;d tried to imagine what perhaps he himself might want in his new office buildings, were he Sam. Sam didn&#39;t want his Jewfro on the side of the building. This other person had just imagined that “Jewfro on the side of the building” was the kind of thing Sam might find amusing. (2,612)</p></blockquote><p> Another way he kept it all about him was not to give anyone else a title that represented what they were actually doing.</p><blockquote><p> Sam then listed some reasons why this might be so: Having a title makes people feel less willing to take advice from those without titles. Having a title makes people less likely to put in the effort to learn how to do well at the base-level jobs of people they&#39;re managing. They end up trying to manage people whose jobs they couldn&#39;t do, and that always goes poorly. (2,644)</p><p> Having titles can create significant conflicts between your ego and the company. Having titles can piss off colleagues. (2,648)</p></blockquote><p> If while reading this book you are not playing the game of noticing world-class levels of lacking self-awareness, you were missing out.</p><blockquote><p> Nishad Singh failed to imagine the way things actually went south, but he did imagine a different highly plausible one that likely happened in a bunch of other Everett branches.</p><p> I&#39;d soon be asking Nishad Singh for the same premortem I&#39;d ask of others at the top of their psychiatrist&#39;s org chart: “Imagine we&#39;re in the future and your company has collapsed: tell me how it happened.” “Someone kidnaps Sam,” Nishad would reply immediately, before unspooling his recurring nightmare of Sam&#39;s lax attitude toward his personal safety leading to the undoing of their empire.</p><p> ..made for excellent ransom. “People with access to crypto are prime kidnap targets,” said Nishad. “I cannot understand why it doesn&#39;t happen more.” (2,736)</p></blockquote><p> People don&#39;t do things. None of the people in the world thought to kidnap Sam, despite zero attempts to prevent this, so despite being perhaps the most juicy kidnap target the world has ever known, he remained un-kidnapped. The man had actual zero security, posed zero physical threat, had billions in crypto that was accounted for by literal no one including himself, and was a pure act utilitarian and effectively a causal decision theorist. That person pays all the ransom, and then shrugs it off and gets back to work.</p><p> Which is good, given they had no other decision making process whatsoever.</p><blockquote><p> “It is unclear if we even have to have an actual board of directors,” said Sam, “but we get suspicious glances if we don&#39;t have one, so we have something with three people on it.” When he said this to me, right after his Twitter meeting, he admitted he couldn&#39;t recall the names of the other two people. “I knew who they were three months ago,” he said. “It might have changed. The main job requirement is they don&#39;t mind DocuSigning at three am DocuSigning is the main job.” (2,833)</p></blockquote><p> There was no CFO. Why have a CFO? What would they do, keep track of how much money we have?</p><blockquote><p> “There&#39;s a functional religion around the CFO,” said Sam. “I&#39;ll ask them, &#39;Why do I need one?&#39; Some people cannot articulate a single thing the CFO is supposed to do. They&#39;ll say &#39;keep track of the money,&#39; or &#39;make projections.&#39; I&#39;m like, What the fuck do you think I do all day? You think I don&#39;t know how much money we have?” (2,838)</p></blockquote><p> You know what? I do indeed think you do not know how much money you had.</p><h4> A Few Good Trades</h4><p> Sam did a lot of trades. Some of them were good trades. Some of them were not.</p><p> That means sometimes you look dumb, and sometimes you look like a genius.</p><p> When the good ones can pay off by orders of magnitude, every VC and everyone in crypto knows that is a nice place to be.</p><p> For example, that Solana trade? Sweet.</p><blockquote><p> Even if it wasn&#39;t [true], Solana&#39;s story was good enough that other people might see it that way and drive up the price of its token. Eighteen months later, Alameda owned roughly 15 percent of all Solana tokens, most purchased at twenty-five cents apiece. The market price of Solana had gone as high as $249, a thousand-times increase on what Sam had paid for the tokens, and the face value of Sam&#39;s entire stash was roughly $12 billion. (2,346)</p></blockquote><p> Makes up for a lot of other trades gone bad, provided you then sell some rather than double down. Yeah, I know, this is Sam we are talking about.</p><p> With a lot of effective control over Solana, Sam then was properly motivated to drive more hype and adaption. He even got to create a spin off, a &#39;Sam Coin&#39; called Serum, which was meant to be a claim on a portion of the fees for financial transactions on the Solana blockchain.</p><p> This was, presumably, a way to expropriate other holders of Solana. Instead of returning the fees to Solana holders, they would go to Serum holders, so suddenly there was another coin to distribute and manipulate and hype. Fun. The only problem was that it worked too well.</p><blockquote><p> Soon after Serum&#39;s creation, its price had skyrocketed. Sam clearly had not anticipated this. He now had all these employees who felt ridiculously rich. (At least in theory, the value of Dan Friedberg&#39;s Serum stash peaked, in September 2021, at over $1 billion.)</p><p> In Sam&#39;s view, everyone at once became a lot less motivated to work fourteen-hour days. And so he did a very Sam thing: he changed the terms of the employees&#39; Serum.</p><p> In the fine print of the employee Serum contract, he&#39;d reserved for himself the right to extend Serum&#39;s jail time, and he used it to lock up all employees&#39; Serum for seven years. Sam&#39;s employees had always known that he preferred games in which the rules could change in the middle.</p><p> They now understood that if he had changed the rules once, he might do it again. They became less enthusiastic about their Serum. “It was very unclear if you had it or if you didn&#39;t have it,” said Ramnik, who had watched in irritation as Sam locked up a bunch of tokens that he&#39;d bought with his own money on the open market before he joined FTX. “I guess you would know in seven years.” (3,980)</p></blockquote><p> Lewis is so close to getting it. He understands that Sam will betray everyone around him whenever he can. <a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=WpE_xMRiCLE&amp;ab_channel=AdultSwim">He is altering the deal, pray that he does not alter it any further</a> . Only from Sam&#39;s perspective, there is no deal, there is only <a target="_blank" rel="noreferrer noopener" href="https://www.amazon.com/Reality-What-You-Can-Away/dp/1561840807">reality, which is what you can get away with</a> .</p><p> Sam also had the advantage of being Sam and controlling Alameda and FTX.</p><p> He also had the bonus of not being so inspired to turn his paper gains into actual dollars (or stable coins, or liquid cryptos like BTC or ETH). Why liquidate what you can borrow against? That way Number Go Up.</p><p> Another trade he did was to take advantage of all the wash trading. The wash trading was so ingrained into how business was done, and done so poorly, that when SBF intercepted some of it, Binance&#39;s employees failed to explain to their boss CZ what was even happening. Or, he credibly pretended not to understand.</p><blockquote><p> It was a weird conversation—the CEO of one crypto exchange calling the CFO of another to inform him that, if he didn&#39;t want to lose money on his new futures contract, he&#39;d need to improve his market manipulation. Wei Zhou spoke to CZ, who called Sam for a brief though not unfriendly chat, after which Sam concluded that CZ still had not been told by his traders what had actually happened.</p></blockquote><p> What happened was that Binance was doing its market manipulation via predictable market orders, so SBF would step in front of those orders, which made a bunch of money that came out of Binance&#39;s pocket. Which Binance did not like.</p><p> Sam would occasionally consult others on what to do? I guess? Even Lewis realizes Sam does not actually care what anyone else thinks.</p><blockquote><p> After talking to them, Sam could tell himself that he&#39;d checked his judgment without having done so. (2,771)</p><p> Sam had invested $500 million in an artificial intelligence start-up called Anthropic, apparently without bouncing the idea off anyone else. “I said to Sam after he did it, &#39;We don&#39;t know a fucking thing about this company,&#39; ” said Ramnik. (2,818)</p></blockquote><p> Putting the $500 million into Anthropic was arguably the most important decision Sam ever made. I do not know if investing in Anthropic was a good or bad move for the chances of everyone not dying, but chances are this was either a massively good or massively bad investment. It dwarfs in impact the rest of his EA activities combined.</p><p> Another good trade Sam noticed was that rich people dramatically underinvest in politics, whatever you think of Sam&#39;s execution during what one might generously label his learning phase.</p><blockquote><p> What surprised Sam, once he himself had unlimited sums of money, was how slowly rich people and corporations had adapted to their new political environment. The US government exerted massive influence on virtually everything under the sun and maybe even a few things over it. In a single four-year term, a president, working with Congress, directed roughly $15 trillion in spending. And yet in 2016, the sum total of spending by all candidates on races for the presidency and Congress came to a mere $6.5 billion. “It just seems like there isn&#39;t enough money in politics,” said Sam. “People are underdoing it. The weird thing is that Warren Buffett isn&#39;t giving two billion dollars a year.” (2,874)</p></blockquote><p> We should not forget the original arbitrage trade with South Korea and Japan.</p><p> The good arbitrage trade that still doesn&#39;t fully make sense was ModelBot. I see no reason for it not to have worked, but I also see no reason Sam could not have safely proved that it worked by starting small and then scaling up. Why all the drama? Then it stopped working as competition improved.</p><p> Even excluding the arbitrage trades, that track record is really good. Sam took a lot of shots, but I think not thousands of such shots. If you can make trades like Solana at $0.25 and early Anthropic, the rest of your trades can lose and you could still have very good alpha – provided you are responsible with your sizing and other risk management, and cut your losses when trades fail and properly consider liquidity issues. There would be no need to lie, or to do all the fraud and crime.</p><p> The problem was that Sam was the opposite of responsible with the sizing and risk management. He did not cut his losses when trades failed. He did not consider liquidity issues.</p><p> There is also the highly related issue of all the lying and fraud and crime.</p><h4> The Plan</h4><p> Behind every great fortune, they say, is a great crime. Certainly that was true for this one. Then, as The Godfather tells us, one needs to appear to go legit.</p><p> Sam&#39;s plan was to present FTX as the responsible adults in the room.</p><p> It did help that the room was crypto, and filled with crypto exchanges. Many of which were indeed doing all the crimes. From the perspective of the United States, even the ones not doing all the crimes were still doing crimes anyway, the SEC has yet to explain to anyone what it would take to do crypto without doing crimes.</p><p> The biggest fish in the pond was CZ and Binance. Oh boy were they doing crimes. Their headquarters is intentionally nowhere. Their internal messages explicitly affirm that they are running an unlicensed security exchange in America.等等。</p><blockquote><p> Which is why, when Sam took in the situation, he decided that Binance&#39;s strategy was unsustainable. That the smart thing to do was to be the world&#39;s most law-abiding and regulator-loving exchange. FTX could use the law, and the regulators, to drive crypto trading from Binance and onto FTX. If countries did not yet have the laws, a small army of FTX lawyers would help them to create them. (2,406)</p></blockquote><p> Step one was to get CZ and Binance off the cap table, so no one evaluating FTX for its legitimacy would see them on the cap table doing all the crime. So Sam bought him out.</p><blockquote><p> For the stake he&#39;d paid $80 million to acquire, CZ demanded $2.2 billion. Sam agreed to pay it. Just before they signed the deal, CZ insisted, for no particular reason, on an extra $75 million. Sam paid that, too. (2,461)</p></blockquote><p> If SBF was going to pretend FTX was worth that much, why shouldn&#39;t CZ get paid accordingly? However, SBF made a big mistake, and left CZ with $500 million in FTT tokens rather than fully paying out in cash. It really should not have been that hard to not let that happen, given all the money available for spewing elsewhere. Ideally you sell a little of the equity you bought back, and use the proceeds from that.</p><p> The next step in reputation washing was a bunch of advertising.</p><blockquote><p> And so when someone from the Miami Heat reached out to them to suggest that FTX buy their naming rights, for $155 million for the next nineteen years, Sam leapt at the chance. That the deal required the approval not just of the NBA but also of the Miami-Dade Board of County Commissioners, a government body, was a bonus. After that, they could point to a government entity that had blessed FTX.</p><p> Once their name was on an American stadium, no one turned down their money. They showered money across US pro sports: Shohei Ohtani and Shaquille O&#39;Neal and LeBron James became spokespeople.</p><p> They paid Major League Baseball $162.5 million to put the company name on every umpire&#39;s uniform. Having the FTX logo on the umpires&#39; uniforms, Sam thought, was more useful than having it on the players&#39; uniforms. In basically every TV shot of every Major League Baseball game, the viewer saw the FTX patch. “The NBA put us through a vetting process,” said FTX lawyer Dan Friedberg. “Major League Baseball just said okay!” (2,482)</p></blockquote><p> It really is that easy. Once the Miami Heat opened the door, no one else asked any questions. Everyone wanted the money, and that was that, FTX on the umpires to go with the Tezos sign that the Mets were somehow paid to display above center at Citi Field. Sure, why not?</p><p> Given how restrictive FTX US was, this helps explain why SBF was so eager to sponsor all the things. He was after a different goal.</p><p> A common theme of FTX&#39;s sponsorships, like much of what FTX did, is that SBF would spew money in spectacular fashion, most of which was wasted, but he&#39;d also have big wins. In this case, the win was Tom Brady.</p><blockquote><p> But everywhere Sam went, people mentioned that they had heard of FTX because of Brady. Hardly anyone mentioned any of the other endorsers. “It was very clear which things had an effect and which did not,” said Sam. “For the life of me, I can&#39;t figure out why this is. I still don&#39;t know how to verbalize it.” (2,505)</p></blockquote><p> No one has ever <a target="_blank" rel="noreferrer noopener" href="https://tvtropes.org/pmwiki/pmwiki.php/Main/CriticalResearchFailure">Not Done the Research</a> <a target="_blank" rel="noreferrer noopener" href="https://tvtropes.org/pmwiki/pmwiki.php/Main/CreatorsApathy">more than Sam</a> ,, who is confused why Tom Brady impacted people more than Brett Farve. I am not confused at all. Tom Brady is the quarterback everyone was already always talking about, the one everyone hated or perhaps loved, the cheater, the one with the rings, the GOAT, the one who got a girl in trouble and left her, and all that. I say quarterback, you say Brady.</p><p> Next up was getting into politics. As I noted in the good trades section, Sam noticed this was remarkably cheap. So since he had no time to waste but he definitely had money to waste, he got cracking. Gabe Bankman-Fried, Sam&#39;s brother, got put in charge of the political operation.</p><p> Attention is not always people&#39;s strong suit.</p><blockquote><p> I really appreciate this, but it wouldn&#39;t be good for me to take money from FTX, so I can&#39;t—besides, I have found another source of funding.&#39; That other source of funding was Gabe, my brother.” (2,897)</p></blockquote><p> Sam&#39;s most famous political bet was on Carrick Flynn. The decision to back Flynn comes off in the book, if anything, massively stupider than it looked in real time.</p><blockquote><p> Carrick Flynn&#39;s most important trait, in Sam&#39;s view, was his total command of and commitment to pandemic prevention. His second-most important trait was that he was an effective altruist. (2,927)</p><p> Flynn asked some fellow EAs what they thought about him running for Congress. As a political candidate he had obvious weaknesses: in addition to being a Washington insider and a bit of a carpetbagger, he was terrified of public speaking and sensitive to criticism. He described himself as “very introverted.” And yet none of the EAs could see any good reason for him not to go for it—and so he&#39;d thrown his hat into the ring. (2,930)</p></blockquote><p> I don&#39;t blame Flynn, who was trying to do what he thought was the right thing. But it seems so utterly obvious every step of the section on him that this man was never going to be in Congress. Yet they threw tons of money at him anyway, even after that money became the central campaign issue, and all the other candidates ganged up on Flynn over being a crypto stooge and a carpetbagger, and everyone in the district was complaining how their mailboxes were overflowing from campaign ads and they couldn&#39;t take one more of Flynn&#39;s spots on the television.</p><p> To be fair, there was real uncertainty the night before, no one knew for sure that it hadn&#39;t worked. And yes, a champion is super valuable?</p><p> What did Sam learn?</p><blockquote><p> [Sam] actually didn&#39;t mind all that much. He&#39;d learned a lesson: there were political candidates no amount of money could get elected. (2,959)</p></blockquote><p> Well, yes. Also, you learned that when you stick your neck out like that you and those associated with you (read: EA) pay a lasting reputational cost. Sam did not seem to notice this.</p><p> No time to lose. Sam was off to meet Mitch McConnell, with everyone scrambling to get SBF into a presentable suit (he had been convinced to technically bring a suit, but had given no thought to its presentability, he let others handle such things) and he worked to ensure not to call Mitch, who insisted on being called Leader, &#39;dear leader&#39; instead. Which I admit sounds hard.</p><p> Also, check out the claim at the end here.</p><blockquote><p> At that moment, Sam was planning to give $15–$30 million to McConnell to defeat the Trumpier candidates in the US Senate races. On a separate front, he explained to me, as the plane descended into Washington, DC, he was exploring the legality of paying Donald Trump himself not to run for president. His team had somehow created a back channel into the Trump operation and returned with the not terribly earth-shattering news that Donald Trump might indeed have his price: $5 billion. Or so Sam was told by his team. (2,972)</p></blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://puck.news/s-b-f-s-mcconnell-money-tickle-part-2/">A $10 million donation to a McConnell dark money group One Nation has been confirmed.</a></p><p> I once again remind everyone that, while the price has likely gone up, the offer is probably still on the table if someone is bold enough to take it. Sure, now that he&#39;s got the nomination in his sights it probably costs you $10 billion, but given the way people talk about what a Trump victory would look like, surely that is a small price to pay?</p><p> Meanwhile, Sam claimed to have infiltrated Trump&#39;s team, and I love what they did with the place.</p><blockquote><p> Sam&#39;s team had come up with an idea—which, Sam claimed, was just then making its way to Trump himself. The idea was to persuade Trump to come out and say “I&#39;m for Eric!” without specifying which Eric he was for. After all, Trump didn&#39;t actually care who won. (2,979)</p></blockquote><p> Trump actually did it, and it is plausible this switched which Eric won. Good show.</p><h4> The Tragedy of FTT</h4><p> The whole FTT situation still blows my mind.</p><p> I mean, I know it happened, I accept it. Still. Blows my mind every time.</p><p> The tragedy is there was absolutely no need for any of it. There was no need to keep flipping coins double-or-nothing for all the money on the assumption that the odds were in Sam&#39;s favor.</p><p> Which they weren&#39;t. Yet he kept flipping.</p><p> So here&#39;s the basics, for those who don&#39;t know.</p><p> Alameda owned a lot of FTT, which is effectively stock in FTX.</p><p> This FTT was highly illiquid. Trying to sell even a fraction of it would have collapsed the price, as everyone involved knew. Collapsing the price of FTT would then, as again everyone involved knew, cause a collapse of confidence in FTX, causing a run on the bank that was FTX. Which those involved had information to know would be quite a serious problem, were it to happen.</p><p> Every trader knows that you do not borrow heavily against your own illiquid stock, with loans recallable at any time and likely to be recalled when times get tough for your industry, to buy other illiquid and highly speculative things highly correlated to your stock and your industry.</p><p> Especially if you know you could not survive the resulting bank run because you&#39;ve appropriated billions in customer funds to cover your other losses or even to keep making more illiquid investments, or to spend on random stuff. All while your exchange was a highly valued money printing machine that could easily raise equity capital.</p><p> And if you were still for some reason going to do that, they would at least know not to also give your biggest rival a huge chunk of that same illiquid token sufficient to crash the market, then actively try to drive him out of his home and bring regulators down on his head, in ways he can see you doing right there.</p><p> I mean, come on, that&#39;s completely insane.</p><p> Except that is, by the book&#39;s admission, exactly what happened.</p><blockquote><p> It seemed perfectly natural for Alameda to control all the remaining FTT, and use it as collateral in its trading activity. Sam didn&#39;t even try to hide what he was doing. (2,105)</p></blockquote><p> Did other crypto firms accept this collateral, knowing or even worse somehow not knowing exactly what this implied? Why yes. Yes they did.</p><p> This created a highly volatile situation. A downward spiral waiting to happen.</p><p> Then crypto crashed, everyone including Alameda lost a lot of money, and it happened.</p><p> To try and prevent it from happening, Alameda had to actually repay its loans, or else the FTT it used as collateral was going to get liquidated. Then it had to bail out firms like Voyager. This was all on top of all the money Alameda and FTX had already spent and lost.</p><p> Sam still did not seem to notice that funding might be an urgent issue.</p><blockquote><p> At their peak, they&#39;d together been valued at roughly $7 billion. Now Ramnik was acquiring them for no more than $200 million. A pittance. Or so it seemed. Ramnik recently had asked Sam how much capital he should assume was available for possible acquisitions, and Sam had said, Just let me know if you get to a billion. (3,100)</p></blockquote><p> So Sam kept poking the bear. Hence, The Vanishing.</p><h4> The Vanishing</h4><p> That&#39;s what Michael Lewis calls the collapse of FTX.</p><p> The proximate cause was that Sam pissed off CZ, while very much not being in a position to call BS on anyone. As in doing things like this:</p><blockquote><p> Sam later wrote up the message he&#39;d tried to convey to them. “I love Dubai,” he said. But we can&#39;t be in the same place as Binance. 。 。 。 This is for two reasons: first they are constantly devoting significant company resources to trying to hurt us; and second that they soil the reputation of wherever they are. I can&#39;t emphasize this enough: in general I hear great things from other jurisdictions/regulators etc. about Dubai and the UAE [United Arab Emirates], except that there&#39;s a constant refrain of: that&#39;s the jurisdiction that accepted Binance, and so we don&#39;t trust their standards. It was unclear to Sam, if Dubai decided to rid itself of CZ and his exchange, whether any country in which CZ would be willing to live would accept them. In these woods, CZ was the biggest bear and Sam seemed to be going out of his way to poke him. (3,154)</p></blockquote><p> CZ was understandably upset, leaked a supposed balance sheet from Alameda that looked bad but not as bad as the full reality, and announced his intention to dump his FTT.</p><p> Caroline Ellison decided to respond by offering to buy all the FTT at $22, thinking this was a show of strength, except for once crypto investors understood what that meant and acted accordingly.</p><blockquote><p> Within twenty seconds of Caroline&#39;s tweet came a rush to sell FTT by speculators who had borrowed money to buy it. The panic was driven by an assumption: if Alameda Research, the single biggest owner of FTT, was making a big show of being willing to buy a huge pile of it for $22, they must need for some reason to maintain the market price at 22. The most plausible explanation was that Alameda Research was using FTT as collateral to borrow dollars or bitcoin from others. “You don&#39;t tell someone a price level like $22 unless you have a lot of confidence that you need that price,” the CEO of Gauntlet, Tarun Chitra, told Bloomberg News. By Monday night, the price of FTT had fallen from $22 to $7. (3,203)</p></blockquote><p> Then the run on FTX began in earnest. Which would not have been a problem…</p><blockquote><p> Ramnik could see that money was leaving FTX, but he didn&#39;t view it as a big deal. The customers might panic and pull out all their money. But once they realized that there was nothing to panic about, they&#39;d return, and their money would too. (3,221)</p></blockquote><p> …except that FTX did not have the money to pay their customers, because Alameda had taken it and did not have the ability to give it all back.</p><p> Or have much idea how much they even had.</p><blockquote><p> Though Caroline was in charge of Alameda Research, she seemed totally clueless about where its money was. She&#39;d come onto the screen and announce that she had found $200 million here, or $400 million there, as if she&#39;d just made an original scientific discovery. Some guy at Deltec, their bank in the Bahamas, messaged Ramnik to say, Oh, by the way, you have $300 million with… And it came as a total surprise to all of them!</p><p> That he&#39;d been taken by surprise. He wondered: If these people knew there was a risk that they might not have enough money, why hadn&#39;t they even bothered to figure out how much they had? They&#39;d done nothing. (3,244)</p></blockquote><p> Didn&#39;t see it coming, I suppose. Did decide to use $8 billion in customer funds as if it was Alameda operating capital. Did not anticipate that the customers might ask for that money back all at once when they found out what was going on. Whoops.</p><p> Lewis rightly points out, near the end, that while many people did realize FTX was obviously up to no good, no one actually managed to figure out the exact no good they were up to until rather late in the game.</p><blockquote><p> Even those who had expressed suspicion about Sam or FTX had failed to say the one simple thing you would say if you knew the secret they were hiding: the customers&#39; deposits that are supposed to be inside FTX are actually inside Alameda Research. (4,007)</p></blockquote><p> They also couldn&#39;t imagine that things could have been as chaotic and unaccounted for, or as blatant, as they were. It wasn&#39;t necessary for the no good to be that no good. The borrowing against FTT tokens was bad enough on its own.</p><p> A lot of people, as FTX started to collapse, did the same calculation I did. It was quickly clear, as Sam went on Twitter to put on his best dog-drinking-coffee face and say &#39;assets are fine,&#39; that there were only two possible worlds.</p><ol><li> Either things really were fine, because FTX was obviously a money machine, things not being fine would have meant a completely crazy level of recklessness and incompetence, and SBF had gone way over the &#39;this is fraud if things are not fine&#39; line and was very all-in. No one would be so stupid as to.</li><li> Or this was pure fraud, through and through, and FTX and SBF did all the crime.</li></ol><p> That&#39;s why me and so many others turned around on a dime – once we could rule out scenario #1, we knew we were in scenario #2.</p><p> One by one, people who wanted it to be one way got the piece of evidence that convinced them it was the other way.</p><blockquote><p> Zane pinged Sam and asked, &#39;Should I do damage control?&#39; &#39;Yup,&#39; he said.” Zane then sent Sam a message asking three questions: “One, are we insolvent, two, did we ever lend out customer funds to Alameda, and three anything I didn&#39;t ask that I need to know?” Sam didn&#39;t reply—and then went totally silent on him. (3,344)</p><p> Still, Zane figured there was no way that FTX was in real trouble. It made no sense. The price of FTT shouldn&#39;t have any effect on the value of the exchange, any more than the price of Apple stock should have on Apple&#39;s iPhone sales. Just the reverse: the exchange&#39;s revenues drove the value of FTT. “If FTT goes to zero, so what?” said Zane. The other reason it made no sense was that FTX had been so wildly profitable. “I know how much real revenue we were making: two bips [0.02 percent] on two hundred fifty billion dollars a month,” said Zane. “I&#39;m like, Dude, you were sitting on a fucking printing press: why did you need to do this?” (3,347)</p></blockquote><p> Here is happens to Constance, on seeing the &#39;balance sheet.&#39;</p><blockquote><p> The next document in her stack was a rough balance sheet of Alameda Research that differed in important ways from the rough balance sheet that had inspired the CoinDesk article now being credited with bringing down the entire business. It appeared to Constance that it had been hastily concocted either by Sam or Caroline, or maybe by both. Constance had first come across it the previous Tuesday, after FTX had ceased sending money back to its customers. “When I saw it, I told my team not to respond to external parties because I did not want them to lose their good name and reputation,” she said.</p><p> The list of assets included the details of hundreds of private investments Sam had made over the previous two years, apparently totaling $4,717,030,200. The liabilities now had a line item more important than everything else combined: $10,152,068,800 of customer deposits. More than $10 billion that was meant to be custodied by FTX somehow had ended up inside Sam&#39;s private trading fund. The document listed only $3 billion in liquid assets—that is, US dollars or crypto that could be sold immediately for dollars.</p><p> “I was like, Holy shit,” she said. “The question is: Why?” It was the same question Zane had asked. “We had so profitable a business,” said Constance. “Our profit margin was forty to fifty percent. We made four hundred million dollars last year.” (3,478)</p></blockquote><p> They may have made five hundred million, but even if they hadn&#39;t stolen everyone&#39;s money, that was not about to pay the expenses.</p><blockquote><p> Constance herself had lost around $25 million. She still had $80,000 in an ordinary bank account she&#39;d kept from her previous life, but otherwise she&#39;d lost everything. (3,492)</p></blockquote><p> This is the kind of thing that still blows my mind. You have stock in FTX, you have $25 million in liquid assets, the world is in front of you. And you chase FTX&#39;s interest payments, and trust FTX so much, that you keep all your money on the exchange.什么？ That is completely crazy behavior. And yet, most employees tell exactly that story. It seems likely SBF/FTX insisted upon it, and Lewis either missed this or declined to mention it.</p><p> Because at $25 million while working at a crypto company, I&#39;d hope I&#39;d be doing things like millions in gold in a secret vault. At minimum I&#39;d have $5 million in an offshore bank account.</p><p> But even after that, Caroline didn&#39;t turn on Sam yet. She only turned on Sam when she realized that, compared to those around her, she&#39;d been given an order of magnitude or two less stock than she should have gotten.</p><blockquote><p> That&#39;s when Constance&#39;s feeling about Sam changed: when she saw how she&#39;d actually been treated. (3,524)</p></blockquote><p> Only then did she decide to spend the last chapter of the book helping Sam with logistics so she could try to get Sam to confess.</p><h4> The Reckoning</h4><p> As future prisoners, having been caught doing all the crime, the principles of FTX faced the prisoner&#39;s dilemma.</p><p> The game theory of SBF: You have to commit to the bit.</p><blockquote><p> That night, Nishad requested a meeting with just Gary and Sam. Once the three were alone in a room, Nishad asked, What happens if law enforcement or regulators reach out?你是什​​么意思？ Sam asked. How do we make sure we cooperate in prisoner&#39;s dilemma? How do we all make sure we say the other ones are innocent? I don&#39;t have any reason to think any one of us had criminal intent, said Sam. (3,291)</p><p> No, said Nishad. That&#39;s not good enough. You need to talk to them. You need to tell them I had no clue. How could I know that? asked Sam. You are saying that I should say that you know nothing about something I know nothing about. How is that even possible? It makes no sense. But I didn&#39;t know, said Nishad. Then say that, said Sam. It&#39;s not going to work for me, said Nishad. Because there is code-based evidence of what I did. (3,295)</p></blockquote><p> The game theory of everyone else? Not so much.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/matt_levine/status/1713273141118509317">Caroline held this meeting on November 9</a> to explain the situation to her employees. as Patrick McKenzie says &#39;what a document.&#39;</p><p> Being Causal Decision Theory agents, and being somewhat more grounded in reality, the rest of the EAs all turned state&#39;s witness.</p><p> Sam also had many other bizarre ideas about how any of this worked.</p><blockquote><p> “At the end of the day, the deciding factor in the jurisdictional dispute is Gary,” said Sam, the night Zane left, “because he&#39;s the only one who knows how to use a computer.” (3,374)</p></blockquote><p> Sam was convinced to declare bankruptcy in America lest he instead have it declared for him by less friendly other parties, then tried to undo it which you cannot do, then went around insisting that if he hadn&#39;t declared bankruptcy it would all have worked out.</p><p> Sam kept trying to explain how the money was all there, really, or close to it, and how all of this was merely a serious of unfortunate &#39;fuck ups&#39; and misunderstandings. Sam thought he had plenty of money, didn&#39;t keep track of things properly, everything seemed safe at the time, he was as surprised as anyone.</p><p> So far, so public domain. The weird thing is that Michael Lewis seems to buy it.</p><blockquote><p> In Sam&#39;s telling, FTX had switched off Alameda&#39;s risk limits to make itself more appealing. The losses caused by this unsettling policy were in any case trivial. Ordinary trading loans made by FTX to Alameda constituted a small fraction of the losses to customers; on their own, they wouldn&#39;t have posed a problem. The bulk of the customers&#39; money inside of Alameda that should have been inside FTX—$8.8 billion of it, to be exact—resided in an account that Alameda had labeled fiat@. The fiat@ account had been set up in 2019 to receive the dollars and other fiat currencies sent by FTX&#39;s new customers. (3,543)</p><p> In Sam&#39;s telling, the dollars sent in by customers that had accumulated inside of Alameda Research had simply never been moved. Until July 2021, there was no other place to put them, as FTX had no US dollar bank accounts. They&#39;d been listed on a dashboard of FTX&#39;s customer deposits but remained inside Alameda&#39;s bank accounts. Sam also claimed that, right up until at least June 2022, this fact, which others now found so shocking, hadn&#39;t attracted his attention. (3,555)</p><p> But even if you valued the contents of Alameda more rigorously, as Sam sort of did in his head sometimes, you could still easily get to $30 billion. The $8.8 billion that should not have been inside Alameda Research was not exactly a rounding error. But it was, possibly, not enough to worry about. As Sam put it: “I didn&#39;t ask, like, &#39;How many dollars do we have?&#39; It felt to us that Alameda had infinity dollars.” (3,562)</p><p> At that point, in Sam&#39;s telling, Sam thought that Alameda might be in trouble. He decided to dig into its accounts on his own and understand the problem. By October, he had a clearer picture. It was only then that he could see that Alameda had been operating as if the $8.8 billion in customer funds belonged to it. And by then it was too late to do anything about it. (3,576)</p></blockquote><p> This story does not actually make any sense, and of course is directly and blatantly contradicted by testimony at the trial. And yet Michael Lewis is intrigued:</p><p> I had a different question. It preoccupied me from the moment of the collapse: Where had the money gone? It was not obvious what had happened to it. (3,610)</p><blockquote><p> At any rate, when I was done, my extremely naive money-in, money-out statement looked like this:</p><p> MONEY IN:</p><p> Net customer deposits: $15 billion</p><p> Investments from venture capitalists: $2.3 billion</p><p> Alameda trading profits: $2.5 billion</p><p> FTX exchange revenues: $2 billion</p><p> Net outstanding loans from crypto lenders (mainly Genesis and BlockFi): $1.5 billion</p><p> Original sale of FTT: $35 million</p><p> Total: $23,335,000,000</p><p> MONEY OUT:</p><p> Returned to customers during the November run: $5 billion</p><p> Amount paid out to CZ: $1.4 billion (Just the hard cash part of the payment. I&#39;m ignoring the $500 million worth of FTT Sam also paid him, as Sam minted those for free. I&#39;m also ignoring the $80 million worth of BNB tokens that CZ had used to pay for his original stake, worth $400 million at the time Sam returned them as part of his buyout of CZ&#39;s interest.)</p><p> Sam&#39;s private investments: $4.4 billion (The whole portfolio was $4.7 billion, but at least one investment, valued at $300 million, Sam had paid for with shares in FTX. He likely did the same with others, and so this number is likely bigger than it actually was.)</p><p> Loans to Sam: $1 billion (Used for political and EA donations. After his lawyers explained to him that taking out loans was smarter than paying himself a stock dividend, as he&#39;d need to pay tax on the dividends.)</p><p> Loans to Nishad for same: $543 million</p><p> Endorsement deals: $500 million (This is likely generous too, as in some cases—Tom Brady was one of them—FTX paid its endorsers with FTX stock and not dollars.) Buying and burning their exchange token,</p><p> FTT: $600 million</p><p> Corporate expenses (salaries, lunch, Bahamas real estate): $1 billion</p><p> Total: $14,443,000,000 (3,626)</p></blockquote><p> The case has been made to me that this accounting is not as naive and stupid as it looks. I continue to mostly disagree with that. Lewis continues to double down.</p><blockquote><p> There were some likely explanations for the missing money. The more you thought about them, however, the less persuasive they became. For example, Alameda traders might have gambled away $6 billion. But if they had, why did they all believe themselves to be so profitable, right to the end? I&#39;d spoken to a bunch of them. Several were former Jane Streeters. They weren&#39;t stupid. (3,462)</p></blockquote><p> This is perhaps the most &#39;naive guy&#39; thing in the entire book. Smart people can&#39;t think they are making good trades when they are making bad ones and losing tons of money, right? And they wouldn&#39;t lie to Michael Lewis about profitability, right?</p><blockquote><p> The most hand-wavy story just then being bandied about was that the collapse in crypto prices somehow sucked all the money out of Sam&#39;s World. And it was true that Sam&#39;s massive holdings of Solana and FTT—and other tokens of even more dubious value—had crashed. They&#39;d gone from being theoretically worth $100 billion at the end of 2021 to being worth practically zero in November 2022.</p><p> But Sam had paid next to nothing for these tokens; they had always been more like found money than an investment he&#39;d forked over actual dollars to acquire. He&#39;d minted FTT himself, for free. (3,647)</p></blockquote><p> At their peak, Alameda was on (some form of electronic) paper worth $100 billion or so. We know that Alameda&#39;s edge in algorithmic trades had likely been going away as they faced stiffer competition, that source of profit was likely gone, yet they continued to borrow. What was the profitable trading Alameda was doing with all that capital?</p><p> They were getting long. Alameda was borrowing a bunch of capital from various lenders, and using it to get long and then get longer. That is where the money was going.</p><p> Then Number Went Down. Money gone.</p><p> Does Michael Lewis think the people at Three Arrows Capital or Voyager were stupid? The people who created and ran Luna? Enron? Lehman Brothers? Does this man not remember his own books?</p><p> He said it himself. Sam&#39;s entire empire was a leveraged – Lewis&#39;s word – bet on the success of crypto and the empire itself more generally. When you have no ethics only a quest for Number Go Up (you know, for the common good) and therefore don&#39;t care that, sure, technically that was customer deposits right there, that leverages your bet all the more. As Number Go Down, rather than hedge, they doubled down, including via providing bailouts.</p><p> Leverage plus Number Go Down equals Broke Fi Broke, overwhelming other sources of profits.</p><p> Yes, a lot of their horde of stuff they bought for pennies. But they then used that as collateral to borrow money and put more things into the horde. All of which was correlated, and all of which was down. A lot.</p><p> Also, SBF was shoving money out the door in any number of other ways that the above numbers are missing, money was constantly being misplaced or stolen, a fire sale is not a cheap thing to partake in, and so on. So I do not think there is any mystery here.</p><p> We then get a fascinating story. San says combined losses from things like this were only $1 billion, but honestly how would he even know given everything.</p><blockquote><p> But on that evening, Sam filled in one piece of this particular puzzle: FTX had lost a lot of money to hackers. To avoid encouraging other hackers, they&#39;d kept their losses quiet. The biggest hacks occurred in March and April 2021. A lone trader had opened an account on FTX and cornered the market in two thinly traded tokens, BitMax and MobileCoin.</p><p> His purchases drove up the prices of the two tokens wildly: the price of MobileCoin went from $2.50 to $54 in just a few weeks. This trader, who appeared to be operating from Turkey, had done what he had done not out of some special love for MobileCoin. He&#39;d found a flaw in FTX&#39;s risk management software. FTX allowed traders to borrow bitcoin and other easily sellable crypto against the value of their MobileCoin and BitMax holdings.</p><p> The trader had inflated the value of MobileCoin and BitMax so that he might borrow actually valuable crypto against them from FTX. Once he had it he vanished, leaving FTX with a collapsing pile of tokens and a loss of $600 million worth of crypto.</p><p> The size of those hacks was an exception, Sam said. All losses due to theft combined had come to just a bit more than $1 billion. In all cases, Gary had quietly fixed the problem and they&#39;d all moved on and allowed the thieves to keep their loot. “People playing the game,” was Sam&#39;s description of them. (He really was easy to steal from.) (3,701)</p></blockquote><p> That is not a hack. He did not steal the money. You gave it to him.</p><p> I know that people call such things hacks, like the &#39;hack&#39; about going both ways using leverage earlier. Instead, Sam is right here. this is people playing the game. If your risk engine is stupid enough to let me use my MOBL at $54 to borrow and withdraw a bunch of actual BTC, treating the value of MOBL as real, then that is on the risk engine, whether or not there was also market manipulation involved. I felt the same way about Avi and the Mango trade – yes sure it is illegal and no one is crying for him when he gets arrested nor should they, but also suck it up and write better code, everyone, as is the crypto way.</p><p> FTX&#39;s risk engine was by all accounts excellent, when dealing with coins that were liquid relative to the position sizes involved, and when the risk engine was set to on. FTX&#39;s risk engine was sometimes turned off, and the risk engine clearly did not make reasonable adjustments for illiquid or obviously bubble-shaped coins.</p><p> This also was rather a big deal – FTX lost, by Sam&#39;s own account, a full year&#39;s profits. And that&#39;s the official Sam story. The real story is inevitably much worse. I do not for a second buy that they only lost $1 billion total in hacks.</p><h4> John Ray, the Hero We Need</h4><p> John Ray is pretty great. He&#39;s the guy who cleaned up the Enron mess, the guy you call when you have a world-class mess, and he&#39;s the one they called in for FTX.</p><p> Suddenly there is a no-nonsense adult in the room who is having none of it, even when there is some of it worth having.</p><p> Michael Lewis tries his best to throw shade at him, but Lewis is too honest – too much a naive guy – for any of it to stick even a little.</p><blockquote><p> As a legal matter, at 4:30 in the morning on Friday, November 11, 2022, Sam Bankman-Fried DocuSigned FTX into bankruptcy and named John Ray as FTX&#39;s new CEO. As a practical matter, Sullivan &amp; Cromwell lined up John Ray to replace Sam as the CEO of FTX, and then John Ray hired Sullivan &amp; Cromwell as the lawyers for the massive bankruptcy. (3,772)</p><p> While Sam stewed, John Ray read up on him and this company he&#39;d created. “It&#39;s like, What is this thing?” said Ray. “Now it&#39;s just a failure, but it was once some kind of business. What did you guys do? What&#39;s the situation? Why&#39;s this falling into bankruptcy so quickly?” He briefly considered the possibility that the failure was innocent: maybe they got hacked. “Then you start looking at the kid,” said Ray, the kid being Sam. “I looked at his picture and thought, There&#39;s something wrong going on with him.”</p><p> Ray prided himself on his snap judgments. He could look at a person and in ten minutes know who they were, and never need to reconsider his opinion. The men he evaluated he tended to place in one of three bins in his mind: “good guy,” “naive guy,” and “crook.” Sam very obviously was not a good guy. And he sure didn&#39;t seem naive. (3,783)</p></blockquote><p> That&#39;s a great skill if you are consistently correct. Based on the evidence presented, John Ray is almost never wrong about what type of guy he is dealing with.</p><blockquote><p> He&#39;d spoken only long enough with the other members of Sam&#39;s inner circle to see them for what they were. Nishad Singh struck him as a naive guy. “He&#39;s narrow,” said Ray. “It&#39;s tech, tech, tech. There&#39;s never a problem he can&#39;t solve. He&#39;s not going to steal money. He&#39;s not going to do anything wrong. But he has no idea what&#39;s going on around him. You ask him for a steak and he puts his head up the bull&#39;s ass.”</p><p> The bankruptcy team had located Caroline Ellison by phone on the Saturday after Ray became FTX&#39;s new CEO. She at least had been able to explain where some of the wallets storing the crypto were stashed. Other than that, she wasn&#39;t much use. “She&#39;s cold as ice,” said Ray. “You had to buy words by the vowel. An obvious complete fucking weirdo.” (3,797)</p></blockquote><p> Nishad being a naive guy seems right to me, based on the rest of the book. He had more than enough information to know what was happening, but the Arc Words of the whole book are that people don&#39;t see what they don&#39;t look for, so there you go.</p><blockquote><p> “There&#39;s people that are born criminals, and there&#39;re people that become criminals,” said Ray. “I think [Sam] became a criminal. The how and why he became a criminal I don&#39;t know. I think maybe it takes an understanding of this kid and his parents.” (3,808)</p></blockquote><p> John Ray is here to let you know that you are suffering, and pitying, too many fools.</p><blockquote><p> Six days into his new job, Ray filed a report with the US Bankruptcy Court for the District of Delaware. “Never in my career have I seen such a complete failure of corporate controls and such a complete absence of trustworthy financial information as occurred here,” he wrote. Instead of grilling the people who had created the mess, Ray hired teams of hard-nosed sleuths—many of whom he&#39;d worked with before. “Serious adults,” as he called them. The Nardello firm was a lot of former FBI guys. (Corporate motto: We find out.) (3,822)</p></blockquote><p> First he got things under some semblance of order. He then moved on to looking for all the money.</p><blockquote><p> That was in early 2023. By late April, John Ray&#39;s head was on a swivel. “This is live-action,” he said. “There&#39;s always something every hour.” One day, some random crypto exchange got in touch and said, By the way, we have $170 million in an account of yours: do you want it back? Another day, some random FTX employee called them out of the blue to say that he&#39;d borrowed two million bucks from the company and wanted to repay the loan—of which, so far as Ray could see, there was no record. Of course, once you heard about one loan, you had to wonder how many others like it you&#39;d never hear about. (3,836)</p><p> Several months into the hunt, Ray&#39;s sleuths had discovered that “someone had robbed the exchange of four hundred fifty million.” They&#39;d stumbled upon not the simple hack of November 2022 but the complicated BitMax and MobileCoin hacks of $600 million in the spring of 2021. (The dollar value changed with fluctuations in the price of the stolen crypto.) They&#39;d tracked the hacker not to Turkey but Mauritius. “We have a picture of him going in and out of his house,” said Ray. He was pretty sure he was going to get most of that money back. “We believe there are a lot more of these,” said Ray. (3,844)</p></blockquote><p> Lewis portrays Ray in all this as an archeologist, shifting through the ruins for cash and clues. Michael Lewis makes a point of all the money Ray and his team were going to bill FTX for the work they did. I look at what they had to deal with and how much money they ultimately rounded up, and I say they earned every penny. Part of earning that is that when you are Ray, you cannot rely upon or trust anyone who made the mess in the first place. That&#39;s hostile information sources. If you want it done right, and you do, you have to figure it all out for yourself.</p><p> The best thing about Ray is his reaction to Lewis, as Lewis keeps trying to explain all the things he think he knows, and Ray keeps ignoring him, and it&#39;s going to be some of the straight up funniest scenes in the movie.</p><p> I demand that Ray be played by John Goodman, it would be so perfect.</p><blockquote><p> At some point his team discovered that a Hong Kong subsidiary of Alameda Research called Cottonwood Grove had bought vast sums of FTT, for example. To the innocent archaeologist, it was evidence of Sam&#39;s World artificially propping up the value of FTT. Ray didn&#39;t know that FTX had been obligated to spend roughly a third of its revenues buying back and burning its token, and that Cottonwood Grove was the entity that did it. From my perch on the side of the dig, I would occasionally shout down to the guy running it my guess about the most recent find, but he&#39;d just look up at me, pityingly. I was clearly a naive guy. (3,875)</p></blockquote><p>是的。 Very clearly.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/liron/status/1710193485763289469">We have a fun clip of Ray spelling the uselessness of Lewis to him out for us</a> .</p><p> The thing about Ray is that, in order to be so good at his job, he needs to have zero tolerance for pretty much anything. So when something actually is real, he can miss it.</p><blockquote><p> The hundreds of private investments made by Alameda Research, for instance. When we first met, in early 2023, Ray went on about how fishy these all were. He had a theory about why Sam had thrown money around the way he had: Sam was buying himself some friends. “For the first time in his life, everyone ignores the fact that he&#39;s a fucking weirdo,” said Ray. As an example, he cited the dollars Sam had invested in artificial intelligence companies. “He gave five hundred million bucks to this thing called Anthropic,” said Ray. “It&#39;s just a bunch of people with an idea. Nothing.” (3,886)</p></blockquote><p> Lewis would say this theory is ridiculous, and on its face it definitely is, everyone wanted to be Sam&#39;s friend, but also how much got invested into OpenAI and Anthropic in the name of access? As in, friendship?</p><p> What Ray cannot see is that Anthropic was obviously a very good financial investment, because he does not know anything about AI. He certainly does not want to hear anything about existential risk, or whether Anthropic is helping or not helping with that concern.</p><p> A key question was, what crypto was worth anything, and what wasn&#39;t? For some reason Ray locked onto Serum, the offshoot of Solana.</p><blockquote><p> And yet now, somehow, in John Ray&#39;s book, the locked Serum was good shit. Primo crypto of the finest vintage imbibed by all gentlemen of good taste. And who knows?—maybe one day it will be. But if Serum was a token to be taken seriously, Sam Bankman-Fried and the world he created needed to be viewed in a different light. At Serum&#39;s peak price, the stated market value of Sam&#39;s stash of it was $67 billion. On November 7, 2022, Sam&#39;s pile of mostly locked Serum was still “worth” billions of dollars. If even locked Serum had that kind of value, FTX was solvent right up to the moment it collapsed. And John Ray would have no grounds for clawing back money from any of the many lucky people on whom Sam Bankman-Fried had showered it. (3,988)</p></blockquote><p> In case you didn&#39;t know, well, not so much, here&#39;s Serum.</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97383cf9-4143-4ecb-b3e0-1a17c745e6eb_1200x678.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AocXh6gJ9tJC2WyCL/rp7lxlwubyh5wxvo8tuu" alt=""></a></figure><p> Ray kept searching, Ray kept finding.</p><blockquote><p> That would raise the amount collected to $9.3 billion—even before anyone asked CZ for the $2.275 billion he&#39;d taken out of FTX. Ray was inching toward an answer to the question I&#39;d been asking from the day of the collapse: Where did all that money go? The answer was: nowhere. It was still there. (4,000)</p></blockquote><h4> Caroline Ellison</h4><p> Sam&#39;s on-again, off-again, very-bad-idea relationship with Caroline Ellison is a key part of the story, because Caroline ended up effectively in charge of Alameda when the worst of the fraud went down. It does not seem like a coincidence that Caroline ended up in charge of Alameda, despite her not seeming like someone who should be given that kind of responsibility, as per (among other signs) her repeated observations that she was not up to the job.</p><p> Also she did not have an ideal attitude with respect to willingness to do various crimes, where the whole thing made her deeply uncomfortable but she still did the crimes anyway – you want someone who does not do crimes, or contains their crimes to contextually &#39;ordinary decent crimes&#39; rather than outright frauds like stealing customer funds. Or if you have decided that your plan is to do a lot of crimes, a plan I recommend strongly against, you want someone who is fine with doing lots of crime.</p><p> In any case, Caroline it seems exchanged long emails spelling out the arguments for exactly how obviously she and Sam should not have been dating, with Sam offering points like this:</p><blockquote><p> [Sam] began with a seriously compelling list, titled: ARGUMENTS AGAINST:</p><p> In a lot of ways I don&#39;t really have a soul. This is a lot more obvious in some contexts than others. But in the end there&#39;s a pretty decent argument that my empathy is fake, my feelings are fake, my facial reactions are fake. I don&#39;t feel happiness. What&#39;s the point in dating someone who you physically can&#39;t make happy? I have a long history of getting bored and claustrophobic. This has the makings of a time when I&#39;m less worried about it than normal; but the baseline prior might be high enough that nothing else matters. I feel conflicted about what I want. Sometimes I really want to be with you. Sometimes I want to stay at work for 60 hours straight and not think about anything else. I&#39;m worried about power dynamics between us. This could destroy Alameda if it goes really poorly PR-wise. This combos really badly with the current EA shitshow I&#39;m supposed to be, in some ways, adjudicating. I make people sad. Even people who I inspire, I don&#39;t really make happy. And people who I date—it&#39;s really harrowing.</p><p> It really fucking sucks, to be with someone who (a) you can&#39;t make happy, (b) doesn&#39;t really respect anyone else, (c) constantly thinking really offensive things, (d) doesn&#39;t have time for you, and (e) wants to be alone half the time. There are a lot of really fucked up things about dating an employee.</p><p> This list was followed by another, briefer list, titled “ARGUMENTS IN FAVOR.” I really fucking like you. I really like talking to you. I feel a lot less worried about saying what&#39;s on my mind to you than to almost anyone else. You share my most important interests. You&#39;re a good person. I really like fucking you. You&#39;re smart and impressive. You have good judgement and aren&#39;t full of shit. You appreciate a lot of me for who I am. (2,126)</p></blockquote><p> While I admit those are actually pretty strong arguments in favor, and in other circumstances would be very good reasons to date someone, the arguments against seem rather conclusive.</p><blockquote><p> Caroline wanted a conventional love with an unconventional man. Sam wanted to do whatever at any given moment offered the highest expected value, and his estimate of her expected value seemed to peak right before they had sex and plummet immediately after. (2,155)</p></blockquote><p> This is exactly what one would expect from the rest of Sam&#39;s behavior in other contexts. Story checks out.</p><p> That I guess brings us to the psychiatrist? Who according to other reports had the entire firm including Sam hopped up on various pills in ways the book declines to mention?</p><blockquote><p> It didn&#39;t take a psychiatrist to see a pattern in Sam&#39;s relationship with Caroline, but there happened to be one sitting in the middle of it. His name was George Lerner, and by late 2021 he might have been the world&#39;s leading authority on the inner life of effective altruists. (2,208)</p></blockquote><p> I know of at least two psychiatrists who were and are better experts on this than George Lerner. For example, have you met… Scott Alexander? Anyway.</p><blockquote><p> Then the effective altruists started showing up—and when they did, George took a new and keener interest in his patients. Gabe Bankman-Fried, Sam&#39;s younger brother, was the first, but hard on his heels came Caroline Ellison and others from Alameda Research. By the time Sam arrived, a year later, George was treating maybe twenty EAs. As a group, they eased a worry George had about himself: the limits to his powers of empathy. When ordinary people came to him with their ordinary feelings, he often found himself faking an understanding. The EAs didn&#39;t need his empathy; the EAs thought that even they shouldn&#39;t care about their feelings. In their single-minded quest to maximize the utility of their lives, they were seeking to minimize the effect of their feelings. In their single-minded quest to maximize the utility of their lives, they were seeking to minimize the effect of their feelings. “The way they put it to me is that their emotions are getting in the way of their ability to reduce their decisions to just numbers.” (2,238)</p><p> They were all completely and utterly sincere. They judged the morality of any action by its consequences and were living their life to maximize those consequences. (2,249)</p></blockquote><p> You can&#39;t do that. I mean, obviously you literally can, but professionally no, you really, really can&#39;t treat Gabe and his brother Sam and his girlfriend and employee Caroline and everyone else in their entire social network. This is Dr. Nick territory. Then again, given what everyone involved wanted, maybe you can? It&#39;s not like they wanted anything from him except drugs and practical advice understanding other people. Maybe there is no conflict of interest here after all.</p><p> Also, who cares, given George didn&#39;t even have a license in the Bahamas in the first place?</p><blockquote><p> The Bahamas hadn&#39;t granted George a medical license. His title was Senior Professional Coach. (2,633)</p></blockquote><p> Perhaps he was taking inspiration from the (nominal) psychiatrist in Billions?</p><h4> New and Old EA Cause Areas</h4><p> In addition to his EA causes, SBF did have his own cause area, which was physical beauty.</p><p> He was against it.</p><blockquote><p> [Anna Wintour of Vogue] looked like a million bucks, but her art, like all art, was wasted on Sam. (235)</p><p> “You start by making decisions on who you are going to be with based on how they look,” he said. “Then, because of that, you make bad choices about religion and food and everything else. Then you are just rolling the dice on who you are going to be.”</p><p> Anna Wintour, now that he thought of it, represented much of what he disliked about human beings. “There are very few businesses that I have strong moral objections to, and hers is one of them,” he said. “I actually have disdain for fashion. I have general disdain for the importance that physical attractiveness has, and this is one thing emanating out of that.” (348)</p></blockquote><p> He also investigated but dismissed as a child <a target="_blank" rel="noreferrer noopener" href="https://unsongbook.com/">the cause area of hell</a> .</p><blockquote><p> He found his way to a solution that offered temporary relief: only children suffered from this madness. Yes, kids believed in Santa. But grown-ups did not. There was a limit to the insanity. But then, a year or so later, a boy in his class said he believed in God.</p><p> “And I freaked out,” recalled Sam. “Then he freaked out. We both freaked out. I remember thinking, Wait a minute, do you think I&#39;m going to hell? Because that seems like a big deal. If hell exists, why do you, like, care about McDonald&#39;s? Why are we talking about any of this shit, if there is a hell. If it really exists. It&#39;s fucking terrifying, hell.”</p><p> From the widespread belief in God, and Santa, Sam drew a conclusion: it was possible for almost everyone to be self-evidently wrong about something. “Mass delusions are a property of the world, as it turns out,” he said.</p></blockquote><p> According to the company psychiatrist, the EAs really did only care about suffering.</p><blockquote><p> “It doesn&#39;t really start with people,” said George. “It starts with suffering. It&#39;s about preventing suffering.” (2,257)</p></blockquote><p> This attitude drives me bonkers. Yes, suffering is bad. It is the way we indicate to ourselves that things are bad. It sucks. Preventing it is a good idea. But when you think that suffering is the thing that matters, you confuse the map for the territory, the measure for the man, the math with reality. Combine that with all the other EA beliefs, set this as a maximalist goal, and you get… well, among other things, you get FTX. Also you get people worried about wild animal or electron suffering and who need hacks put in to not actively want to wipe out humanity.</p><p> If you do not love life, and you do not love people, or anything or anyone within the world, and instead wholly rely on a proxy metric? If you do not have Something to Protect? Oh no.</p><p> I mean, listen to yourselves, as George is describing you:</p><blockquote><p> “A lot of EAs chose not to have kids,” said George. “It&#39;s because of the impact on their own lives. They believe that having kids takes away from their ability to have impact on the world.” After all, in the time it took to raise a child to become an effective altruist, you could persuade some unknowably large number of people who were not your children to become effective altruists. “It feels selfish to have a kid. The EA argument for having a kid is that kid equals happiness and happiness equals increased productivity. If they can get there in their head, then maybe they have a kid.” (2,261)</p><p> “There are two parts of being EA,” said George. “Part one is the focus on consequences. Part two is the personal sacrifice.” (2,267)</p></blockquote><p> That is saying, my own child&#39;s only value would be if they too become an effective altruist, or if they increase my altruistic productivity. This is not an attitude compatible with life. If this is you, please halt, catch fire and seek help immediately.</p><p> This last point does not ring true, EAs totally complain about lack of dating opportunities, although I can totally buy that everyone else thought the EAs thought they were smarter than everyone else – and in context, that they were technically right.</p><blockquote><p> “Everyone is complaining about the lack of dating opportunities,” said George. “Except the EAs. The EAs didn&#39;t care.”</p><p> The non-EAs thought the EAs thought they were smarter than everybody else. (2,628)</p></blockquote><p> As much as I criticize EAs, I do it because they are worthy of criticism. They aspire to do better. Otherwise I wouldn&#39;t waste my time. And when Lewis goes too far and misses the mark, there&#39;s big &#39;no one picks on my brother but me&#39; energy.</p><blockquote><p> One day some historian of effective altruism will marvel at how easily it transformed itself. It turned its back on living people without bloodshed or even, really, much shouting. You might think that people who had sacrificed fame and fortune to save poor children in Africa would rebel at the idea of moving on from poor children in Africa to future children in another galaxy. They didn&#39;t, not really—which tells you something about the role of ordinary human feeling in the movement.没关系。 What mattered was the math. Effective altruism never got its emotional charge from the places that charged ordinary philanthropy. It was always fueled by a cool lust for the most logical way to lead a good life. (3,045)</p></blockquote><p> We rationalists have long had a name for the &#39;emotional charge&#39; that drives ordinary philanthropy. <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/3p3CYauiX8oLjmwRF/purchase-fuzzies-and-utilons-separately">We call it &#39;cute puppies with rare diseases.</a> &#39; There is a reason most philanthropy accomplishes nothing except fueling that emotional charge, which is that most decisions in most philanthropy are driven by fueling that emotional charge. The entire point, the founding principle, of EA, the core of what is good about EA, is to care about actually accomplishing the mission and cutting the enemy.</p><p> Can this be taken too far in various ways to the point where it loses its connection to reality? Does relying too much on the math and not enough on common sense and error checks lead to not noticing wrong conclusions are wrong? Oh yes, this absolutely happens in practice, the SBF group was not so extreme an outlier here.</p><p> But at least the crazy kids are trying. At all. They get to be wrong, where most others are not even wrong.</p><p> Also, future children in another galaxy? Try our own children, here and now. People get fooled into thinking that &#39;long term&#39; means some distant future. And yes, in some important senses, most of the potential value of humanity lies in its distant future.</p><p> But the dangers we aim to prevent, the benefits we hope to accrue? They are not some distant dream of a million years from now. They are for people alive today. You, yes you, and your loved ones and friends and if you have them children, are at risk of dying from AI or from a pandemic. Nor are these risks so improbable that one needs to cite future generations for them to be worthy causes.</p><p> I fight the possibility of AI killing everyone, not (only or even primarily) because of a long, long time from now in a galaxy far, far away. I fight so I and everyone else will have grandchildren, and so that those grandchildren will live. Here and now.</p><p> If some other EAs made this change because the numbers (overwhelmingly, and in this case I believe correctly) said so, and would have done so even if the case was less overwhelmingly correct? So be it. We need some people like that. Others need to help with global poverty, and so they do. And they make a lot of mistakes there too, they take the math too seriously, they don&#39;t consider second and third order effects properly, and so on. I could go on rants.但你知道吗？ They try, damn it.</p><p> As opposed to ordinary philanthropy, where the EAs are right: It&#39;s mostly kinda dumb.</p><blockquote><p> They&#39;d been doing this for only a year and already had been pitched nearly two thousand such projects. They&#39;d handed out some money but in the process they&#39;d concluded that conventional philanthropy was kind of dumb. Just to deal with the incoming requests—most of which they had no ability to evaluate—would require a big staff and lots of expense. Much of their money would end up being used on a vast bureaucracy.</p><p> And so they had just recently adopted a new approach: instead of giving money away themselves, they scoured the world for subject matter experts who might have their own, better ideas for how to give away money.</p><p> Over the previous six months, one hundred people with deep knowledge of pandemic prevention and artificial intelligence had received an email from FTX that said, in effect: Hey, you don&#39;t know us, but here&#39;s a million dollars, no strings attached. Your job is to give it away as effectively as you can.</p><p> The FTX Foundation, started in early 2021, would track what these people did with their million dollars, but only to determine if they should be given even more. “We try not to be very judgy once they have the money,” said Sam. “But maybe we won&#39;t be reupping them.” (3,060)</p><p> They were moving fast, as Sam always did. “If you throw away a quarter of the money, that&#39;s very sad,” he said at one point, “but if it allows you to triple the effectiveness of the rest, that&#39;s a win.” (3,073)</p></blockquote><p> This was a really good idea, in the world in which FTX had properly secured the money in order to give it away, and in which they had the proper infrastructure to do this responsibly. Even without either of those things, it was still a reasonable idea.</p><p> There were problems. People were unprepared to hand out a million dollars. A lot of decisions involving a lot of money got made, if not Brewster&#39;s Millions style, in ways that were quite warping on the places the money got spread around. From what I heard, essentially any 19-year-old could get a $50,000 grant to move to Berkeley and think about AI safety, and there was a general failure to differentiate good and real and worthwhile efforts from others. The dynamics this created were an invitation to fake work, to predators and entryism and sociopaths, to hype and networks and corruption. If things had continued, that effect could have gotten worse.</p><p> As always, Sam was not considering second-order effects, and also not considering that efforts might backfire rather than be wasted. Nor did he pay enough attention to one of the most important questions traders always must ask on every trade they do, which is: What is the correct sizing?</p><p> Doing this trade with only a select few would have been great. Doing it with everyone who had an EA identity and a pulse was plausibly net negative.</p><h4> Won&#39;t Get Fooled Again</h4><p> In the wake of publication, many people pointed out that Michael Lewis had been fooled, <a target="_blank" rel="noreferrer noopener" href="https://nymag.com/intelligencer/2023/10/how-michael-lewis-got-duped-by-sam-bankman-fried.html">including this book report from David Roth</a> . <a target="_blank" rel="noreferrer noopener" href="https://time.com/6321668/michael-lewis-sam-bankman-fried-going-infinite/">Michael Lewis did not take kindly to this</a> , while confirming he had been fooled.</p><blockquote><p> Michael Lewis: I&#39;d love for the jury to read the book. Mark Cohen [Sam Bankman-Fried&#39;s lawyer] said this to me: “You get up, you tell one story, and they tell the other story, and the question is which story the jury believes.” I&#39;m in a privileged position to tell a fuller story, without leaving out any of the nasty details. If I were a juror, I would rather hear my story than either defense or prosecution.</p><p> I&#39;m just going to tell you the story as I see it, and then leave you the discretion that then you lynch him, acquit him, or don&#39;t know what to think of him. I don&#39;t want the jury thinking I left anything else they needed to know.</p><p> There&#39;s something about Sam and the situation that pushes a lot of people&#39;s buttons and causes them to want to judge quickly. If I had five hours with the prosecutors, one of the things I would love to know is why they moved so fast. Sam&#39;s lawyers had a guy on the inside and outside advising on when he might be extradited from the Bahamas. And no way did they think it was gonna happen as fast as it did, because they thought it would take the government much longer to figure out what the hell happened.</p><p> I thought that was of a piece with the general social response: how quick people wanted to judge. So I thought, I&#39;m going to be dealing with a reader who is going to be in that judgy kind of mood.</p></blockquote><p> He really thinks he included all the nasty details. The trial has made it clear this was not the case. <a target="_blank" rel="noreferrer noopener" href="https://thezvi.substack.com/p/sadly-ftx">Even my old post on FTX</a> , among many other source options, also made it clear this was not the case.</p><p> As does the book. The book, despite conspicuously leaving out all the most blatant details, repeatedly shows SBF doing fraud.</p><p> Even more than that, the book describes a person who is so obviously doing all the fraud. It would not make any sense for the Sam portrayed here to not be doing all the fraud. That much is clear by the end of chapter one. Did Lewis read his own book?</p><p> The idea that the arrest was a &#39;rush to judgment&#39; is laughable. Sure, they partly moved quickly because it was important to send a message – which it was – but also because no one else has ever more obviously been doing all the crime. There are so many distinct frauds right out in the open.</p><p> Also, seriously, what the hell, you want to poison the jury pool or even the actual jury? The interviewer points out how our system works, and Lewis says no, it shouldn&#39;t work that way, people should read my book.</p><p> At one point, Lewis confirms that FTX violated the Foreign Corrupt Practices Act, as was revealed during the trial, and also perhaps as tellingly that it put a billion dollars into an account at an exchange that regularly freezes accounts frozen by the local police for no reason.</p><p> And Lewis is wondering how the money could be missing.</p><blockquote><p> Michael Lewis: This is what happened, to my knowledge—and I know this from the people in Hong Kong who orchestrated it—a Chinese exchange was routinely targeted by local Chinese police departments. They would find a pretext for freezing an account. In this case, they froze Alameda&#39;s account. And Alameda had like a billion dollars in this account.</p><p> There was an operation inside of FTX, or Alameda, whatever, in Hong Kong, to legitimately get the money back without having to go pay the ransom. And they pursued that, and it didn&#39;t work. So they went in and paid ransom to the Chinese police department directly to get the money released, and it was released.</p><p> I actually would have loved to include it. But they weren&#39;t running around bribing people to change laws. It was more telling about how the Chinese government works than anything about Sam. I then came back and confirmed it all with Sam. He said he knew he&#39;d sent someone in to get the money out, but he wasn&#39;t completely sure how he&#39;d gotten the money out.</p></blockquote><p> Next he admits that SBF committed bank fraud.</p><blockquote><p> Michael Lewis: My impression was that the bank wasn&#39;t actually misled about who these people were. That it was a kind of fig leaf thing.</p><p> Q: But it&#39;s still illegal to mislead a bank about the purpose of a bank account.</p><p> Michael Lewis: But nobody would have cared about it.</p></blockquote><p> He seems to not understand that this does not make it not a federal crime? That &#39;we probably would not have otherwise gotten caught on this one&#39; is not a valid answer?</p><p> Similarly, Lewis clearly thinks &#39;the money was still there and eventually people got paid back&#39; should be some sort of defense for fraud. It isn&#39;t, and it shouldn&#39;t be.</p><p> And then there&#39;s this:</p><blockquote><p> Michael Lewis: No one shows me receipts. But no one suggested otherwise. I interviewed 10 people in Alameda. They just weren&#39;t lying. None of them could think of a big loss.</p><p> ……</p><p> But I was kind of there through it. And there was no detectable change in Caroline, Nishad, Sam: their interactions or their demeanors. If they had this sharp, swift loss, they were really, really good with their poker faces.</p></blockquote><p> All right, that is a purer Naive Guy statement. They just weren&#39;t lying, no sir.</p><p> Nor was Sam a liar, in Lewis&#39;s eyes. Michael Lewis continued to claim, on the Judging Sam podcast, that he could trust Sam completely. That Sam would never lie to him. True, Lewis said, Sam would not volunteer information and he would use exact words. But Sam&#39;s exact words to Lewis, unlike the words he saw Sam constantly spewing to everyone else, could be trusted.</p><p> It&#39;s so weird. How can the same person write a book, and yet not have read it?</p><p> Even then, on October 1, Lewis was claiming he did not know if Sam was guilty. Not only that, he was claiming that many of the prosecutors did not know if Sam was guilty. And Lewis keeps saying that Sam himself really actually believes he is innocent, and for weeks after it was so over Sam really believed he&#39;d be able to raise funds and turn it all around.</p><p> Lewis really did believe, or claimed to believe on his podcast, even in early October that, absent one little mistake where $8 billion dollars ended up in the wrong place, the rest of what happened was fine. That the rest of the story was not filled to the brim with all the crime.</p><p> Yet I totally believe that Lewis believed all of it. The man seems so totally sincere.</p><p> Then on October 9 Lewis said nothing that came out so far at the trial surprised him, other than the claim by one of Sam&#39;s oldest friends that Alameda&#39;s special code not only let them steal all the money, it also let them trade faster than their competitors, implemented on Sam&#39;s orders. Everyone was constantly asking point blank about that, and Sam constantly said that wasn&#39;t true. Even so, Lewis still repeated that in his model Sam doesn&#39;t outright lie, he simply doesn&#39;t tell you the answer that you needed to hear. He was still holding onto that even then.</p><p> When it is revealed that the FTX insurance fund to cover trading losses, that Sam often talks about, was purely fake, literally the product of a random number generator written into the code to display to people to make them think there was an insurance fund? Because to Sam money is fungible, so why would there be an insurance fund? Still no change.</p><p> I still can&#39;t process all that.并不真地。 <a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=aV6NoNkDGsU&amp;t=132s&amp;pp=ygURY2hld2JhY2NhIGRlZmVuc2U%3D">Chewbaca is a wookie</a> . It does not make sense.</p><p> He has Matt Levine on the podcast, and Matt Levine points out that the book made it that much clearer that Sam&#39;s fraud unfolded exactly the way frauds always unfold, that there was nothing confusing here. Yeah, on some level Sam fooled himself that would all work out (or, given it was Sam, that it had odds, and the words &#39;safe&#39; and &#39;risk&#39; were meaningless, so who cares?).</p><p> In later podcasts, Lewis did admit that a lot of the trial testimony was rather damning, and that he is confident that Sam will be convicted. But there is no sign he has figured out that Sam was doing all the lying and all the crime.</p><h4>结论</h4><p>I mostly feel good closing the book on the events of SBF, Alameda and FTX. It all makes sense. We know what happened.</p><p> There are still a few mysteries, mostly centered on early Alameda. The story there, as outlined, continues not to make sense. Why was it so difficult to evaluate ModelBot? What was going on with the demands of those exiting? How did SBF get away with so little reputation damage? I still do want to know. Mostly, though, I am content.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://thezvi.substack.com/p/sadly-ftx">My previous post on FTX</a> holds up remarkably well, and could be used as a companion piece to this one. I was missing pieces of the puzzle, and definitely made mistakes, including the failure to buy up FTX debt for pennies on the dollar. But the rough outline there of what happened holds up, as does the discussion of implications for Effective Altruism.</p><p> I do not think that any of what happened was an accident. SBF was fortunate to get as far as he did before it all blew up. A blow up was the almost inevitable result. While SBF went off the rails, he went off the rails in ways that should have been largely predicted, and which make sense given who he was and then the forces and philosophical ideas that acted upon him.</p><p> This was not so unusual a case of fraud.</p><p> Nor was it an unusual case of what happens when a maximalist goal is given to a highly capable consequentialist system.</p><p> My expectation is that in the unlikely scenario that this attempted takeoff had fully succeeded, and SBF had gained sufficient affordances and capabilities thereby, that the misalignment issues involved would have almost certainly destroyed us all, or all that we care about. Luckily, that did not come to pass.</p><p> Other attempts are coming.</p><p> All of this has happened before.</p><p> All of this will happen again.</p><br/><br/><a href="https://www.lesswrong.com/posts/AocXh6gJ9tJC2WyCL/book-review-going-infinite#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/AocXh6gJ9tJC2WyCL/book-review-going-infinite<guid ispermalink="false"> AocXh6gJ9tJC2WyCL</guid><dc:creator><![CDATA[Zvi]]></dc:creator><pubDate> Tue, 24 Oct 2023 15:00:13 GMT</pubDate> </item><item><title><![CDATA[[Interview w/ Quintin Pope] Evolution, values, and AI Safety]]></title><description><![CDATA[Published on October 24, 2023 1:53 PM GMT<br/><br/><p>在 Futurati 播客上，我们最近发布了<a href="https://www.youtube.com/watch?v=XLDdG9DR7ek">对 Quintin Pope 的采访</a>。</p><p>正如你可以想象的那样，它主要集中在：</p><ul><li>内部与外部优化；</li><li>左急转弯；</li><li>自然选择，以及我们可以从第一个伟大的通用智能的出现中得出什么样的证据；</li><li>更广泛的人工智能安全；</li><li>人类价值观如何形成；</li></ul><p>一探究竟！如果您希望我们进行更多这样的采访，请分享:)</p><br/><br/> <a href="https://www.lesswrong.com/posts/c9W4SHa7DHwAHkqRF/interview-w-quintin-pope-evolution-values-and-ai-safety#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/c9W4SHa7DHwAHkqRF/interview-w-quintin-pope-evolution-values-and-ai-safety<guid ispermalink="false"> c9W4SHA7DHwAHkqRF</guid><dc:creator><![CDATA[fowlertm]]></dc:creator><pubDate> Tue, 24 Oct 2023 13:53:06 GMT</pubDate> </item><item><title><![CDATA[Lying is Cowardice, not Strategy]]></title><description><![CDATA[Published on October 24, 2023 1:24 PM GMT<br/><br/><p> （<a href="https://twitter.com/npcollapse"><i><u>康纳·莱希</u></i></a><i>和</i><a href="https://twitter.com/Gabe_cc"><i><u>加布</u></i></a><i>合写</i><i>）</i></p><p>我们已经与很多人讨论了暂停和暂停的问题。人工智能安全社区成员、投资者、商界同行、政治家等。</p><p>太多人声称要采取以下方法：</p><ol><li>如果 AGI 的进步停止就好了，但那是不可行的。</li><li>因此，我会提倡我认为可行的事情，即使它并不理想。</li><li>奥弗顿窗口就是这样，如果我声称一种过于极端的信念，或者支持一项不可行的政策建议，人们就会不太认真地对待我可行的事情。</li><li>鉴于此，即使我会避免说彻头彻尾的谎言，我也会采取策略性的措辞。</li></ol><p>考虑一下这是否适用于您或您身边的人。</p><p>如果确实如此，让我们明确一点：以可预测地导致人们相信虚假事物的方式<strong>隐藏你的信仰</strong>，<strong>就是撒谎</strong>。无论你的意图如何，无论感觉如何，情况都是如此。</p><p>这不仅在道德上是错误的，而且是一个糟糕的策略。就目前情况而言，人工智能安全社区本身无法协调一致表明我们应该立即停止 AGI 的进步！</p><p><strong>人工智能安全社区不仅无法协调，而且正在背叛，让那些说出来的人付出更大的代价。</strong></p><p>我们都觉得我们正在做最重要的事情，而且我们是务实的现实主义者。</p><p> <a href="https://www.forbes.com/sites/carltonreid/2018/12/03/you-are-not-stuck-in-traffic-you-are-traffic/"><strong><u>但请记住：如果您感到被困在奥弗顿窗口中，那是因为您就是奥弗顿窗口。</u></strong></a></p><p> —</p><h1> 1.人工智能安全社区让我们的工作变得更加困难</h1><p><strong>在一个更加理智的世界中，所有通用人工智能的进步都应该已经停止。如果我们不这样做，我们就有超过 10% 的机会死去。</strong></p><p> AI安全界的很多人都相信这一点，但他们并没有公开表态。更糟糕的是，他们更明显地表达了<i>不同的信念</i>，这误导了其他人应该做什么以及人工智能安全社区的信念。</p><p>迄今为止，在我们向人们提供信息、激励和协调的努力中：人工智能安全社区中的人们公开撒谎是<strong>我们遇到的最大的直接障碍之一。</strong></p><p>最新的例子是“负责任的扩展政策”，许多人工智能安全人士更加直言不讳地表示他们对 RSP 的认可，而不是他们私下相信在一个更加理智的世界中，所有 AGI 进步都应该立即停止。</p><p>因为他们，我们多次被告知我们是少数派，而人工智能安全社区中的大多数人（理解，开放慈善事业相邻）不同意我们现在应该停止所有 AGI 进展。</p><p><strong>实际上，有一种可接受的方式来继续扩展！考虑到这会让事情变得更容易，如果确实有一种可接受的方法来继续扩展，这就是我们应该做的，而不是现在停止所有 AGI 进展！</strong></p><p>最近，Dario Amodei（Anthropic 首席执行官）利用 RSP 将暂停立场定义为<a href="https://www.lesswrong.com/posts/mcnWZBnbeDz7KKtjJ/rsps-are-pauses-done-right?commentId=WhxB66vEeRhh6kcsB"><strong><u>极端立场的最极端版本</u></strong></a>，这是我们反复使用的框架。 ARC 在他们的 RSP 提案版本中<a href="https://evals.alignment.org/blog/2023-09-26-rsp/"><u>反映了</u></a>这一点，将自己描述为暂停和不采取任何行动之间的“务实的中间立场”。</p><p><strong>显然，当我们与人交谈时，所有 AGI 赛车手都用这个来对付我们。</strong></p><p>我们一直看到很少有人公开呼吁<strong>停止</strong>通用人工智能的进步。最清晰的是 Eliezer 的“ <a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/"><u>Shut it All Down</u></a> ”和 Nate 的“ <a href="https://twitter.com/So8res/status/1715380167911067878"><u>Fucking stop</u></a> ”。</p><p>最响亮的沉默来自 Paul Christiano，他的 RSP 被用来安全清洗结垢。</p><p><strong>证明我错了很容易。如果你确实相信，在一个更加理智的世界中，我们现在会停止所有 AGI 进展，你可以公开写下这篇文章。</strong></p><p><strong>当我们提出这个问题时，大多数与我们交谈的人都只是笨手笨脚。</strong></p><h1> 2. 为了个人利益而说谎</h1><p>我们采访了许多公开谎报自己信仰的人。</p><p>理由总是一样的：“这不像是说谎”、“我们不会说出我们不相信的事情”、“我们正在玩一场内部游戏，所以我们必须在我们所说的话上采取策略来获得影响力”和权力”。</p><p><strong>让我称其为：为了个人利益而撒谎。</strong>如果你所说的话的主要目的是让人们认为你相信其他东西，并且你这样做是为了获得更多影响力和权力：<strong>那么你就是在为了个人利益而撒谎。</strong></p><p>随着 AGI 竞赛的安全清洗，这种“影响力和权力攫取”的结果已经多次实现。多么巧合的是，DeepMind、OpenAI 和 Anthropic 都与 AI 安全社区有关。</p><p>我们从这种政治活动中看到的唯一好处是说谎的人获得了更大的影响力，而我们留给 AGI 的时间却越来越短。</p><p><strong>想象一下当一个社区奖励那些通过说谎获得更大影响力的人时会发生什么！</strong></p><p> —</p><p>太多人撒谎，他们不仅毁坏了人类，也毁坏了彼此。</p><p>许多AGI公司领导人会私下表示，在一个更理智的世界中，AGI进步应该<strong>停止</strong>，但他们不会这么说，因为这会损害他们相互竞争的能力！</p><p>安全人员会撒谎，以便与实验室保持联系，从而“向他们施压”，并在政客看来是合理的。</p><p>不管怎样：他们只是为了获得更多权力而撒谎。</p><p> <strong>“不要在严重问题上公开撒谎”是一条非常有力的底线。如果你想叛逃，你需要一个比“这有利于我个人影响力，我保证我会用它做好事”更强有力的理由。</strong><br><br>当你被指责时，你需要接受指责。你不应该通过为你的谎言辩护、掩盖谎言、告诉人们他们的误解来混淆视听，并试图在社区内保持更大的影响力。</p><p>我们已经看到很多人被这个谎言网所欺骗：从政治家和记者，到工程师和知识分子，一直到相关的 EA 或想要提供帮助的普通公民，但当我们的信息看起来像人工智能时，他们感到困惑安全社区可以扩展。</p><p><strong>你的谎言更加复杂，让世界变得更糟。</strong></p><p>有一个简单的方法可以解决这种情况：我们可以采取公开表达我们对重大事件的真实信念的规范。</p><p>如果你认识的人声称相信在一个更加理智的世界中我们应该停止所有通用人工智能的进步，<strong>请告诉他们公开明确地表达他们的信念</strong>。很多时候，你会看到他们笨手笨脚，陷入政治斗争。而且并不罕见，你会发现他们实际上想继续比赛。在这些情况下，您可能不想<a href="https://www.lesswrong.com/tag/conflict-vs-mistake"><u>再为它们寻找借口</u></a>。</p><h1> 3. 协调精神</h1><p>我们个人感受到的一件非常可悲的事情是，看起来很多人<strong>如此纠结于这些政治，以至于他们不明白诚实的意义是什么</strong>。</p><p>确实，从内部来看，诚实并不是一个好的选择。如果你是诚实的，公开诚实的，甚至是敌对的诚实，你只会制造更多的对手，你的影响力就会更少，你能提供的帮助也会更少。</p><p>这是典型的义务论与结果论。如果从你的角度来看，这会增加厄运的可能性，你应该诚实吗？</p><p>答案是<strong>肯定的</strong>。</p><p> <strong>a) 政治活动产生的意想不到的后果比预期的要多得多。</strong></p><p>每当你撒谎时，你就会随机从背后射杀潜在的盟友。<br>每当你撒谎时，你周围的人就会更容易接受撒谎。</p><p> <strong>b) 你的行为，尤其是如果你是领导者、资助者或主要员工（前 10 名员工，或负责组织中超过 10% 的员工），会波及到你周围的每个人。</strong></p><p><strong>受人尊敬/权威/地位较低的人确实会尊重你的行为。</strong><br><strong>这些级别之外的人都会看着你。</strong><br>每当 Open AI、DeepMind、Anthropic、ARC、Open Philanthropy 等公司的领导者/投资者/主要员工更清楚地表达他们对 AGI 进步的信念时，我们阻止 AGI 进步的工作就会变得更容易。<br></p><p> <strong>c) 诚实是伟大的。</strong></p><p>人工智能带来的生存风险现已成为主流。学者们对此议论纷纷。科技公司的首席执行官们都在谈论这个问题。你现在可以谈论它，而不是成为一个怪人，并获得更多盟友。民意调查显示，即使是非专家公民也对超级智能<a href="https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll"><u>表达了不同的看法</u></a>。</p><p>考虑以下时间表：</p><ul><li> ARC &amp; Open Philanthropy 在一份新闻稿中表示：“<strong>在一个理智的世界中，所有 AGI 的进步都应该停止。如果我们不这样做，我们就有超过 10% 的可能性都会死去。</strong> ”</li><li> AGI 实验室安全团队的工作人员公开回应了这一消息。</li><li>认为这一点的 AGI 实验室领导人公开声明了这一点。</li><li>我们开始针对竞争的组织（以及组织内的团体）进行明确的协调。</li><li>我们协调制定一项计划，其最终公开宣称的目标是实现一个我们大多数人都同意的世界状态，人类的整个生存不会受到威胁。</li><li>我们公开地、不懈地优化该计划，同时不损害我们的信念。</li></ul><p><strong>每当你为了个人利益而撒谎时，你就会搞砸这个时间表。</strong></p><p>当你开始在公众面前诚实时，你会在短期内遭受<i>个人</i>打击。但我们坚信，通过协调和诚实，我们的时间表将比任何扩展政策所给我们的时间长得多。</p><br/><br/> <a href="https://www.lesswrong.com/posts/qtTW6BFrxWw4iHcjf/lying-is-cowardice-not-strategy#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/qtTW6BFrxWw4iHcjf/lying-is-cowardice-not-strategy<guid ispermalink="false"> qtTW6BFrxWw4iHcjf</guid><dc:creator><![CDATA[Connor Leahy]]></dc:creator><pubDate> Tue, 24 Oct 2023 13:24:26 GMT</pubDate> </item><item><title><![CDATA[Anyone Else Using Brilliant?]]></title><description><![CDATA[Published on October 24, 2023 12:12 PM GMT<br/><br/><p>我开始使用 Brilliant，到目前为止，我发现它很像“思考物理”——通过提出现实世界的难题，然后解释答案背后的概念和/或数学来进行教学。</p><p>还有其他人从中得到一些东西，或者对如何使用它有建议吗？</p><br/><br/><a href="https://www.lesswrong.com/posts/HmeKF2mRRLfkG68X4/anyone-else-using-brilliant#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/HmeKF2mRRLfkG68X4/anyone-else-using-brilliant<guid ispermalink="false"> HmeKF2mRRLfkG68X4</guid><dc:creator><![CDATA[Sable]]></dc:creator><pubDate> Tue, 24 Oct 2023 12:12:27 GMT</pubDate> </item><item><title><![CDATA[Announcing #AISummitTalks featuring Professor Stuart Russell and many others]]></title><description><![CDATA[Published on October 24, 2023 10:11 AM GMT<br/><br/><p><i>立即注册：</i> <a href="https://www.facebook.com/hashtag/aisummittalks?__eep__=6&amp;__cft__[0]=AZWWp2KX-5gEcFfkRo4Lxqg1YojXwaT6ZG89wRpvxIizJV-guP3ZZ7H9-0cxf5gsF-LnGdxKiywZLlV58vPiaQTl14pc8yaytztqw7GO_yhx-SezQj7FlTV5XK2oD9gYJJ3ULkwRtTZt_21J1NTvdUo_T7nUD34r74Ah8EwGrZL_xBe9kbIMpjQ_ZpfISW4b0Pw&amp;__tn__=*NK-R"><i>#AISummitTalks</i></a> <i>II，由斯图尔特·拉塞尔教授和其他许多人在布莱奇利 Wilton Hall 主持，10 月 31 日星期二，格林威治标准时间 14:00 至 15:30！ -</i> <a href="https://lu.ma/n9qmn4h6"><i>https://lu.ma/n9qmn4h6</i></a></p><h1>关于会谈</h1><p><a href="https://www.youtube.com/watch?v=GFf9oL6jg0w">第一届#AISummitTalks：驾驭存在风险</a>有超过 250 人参加，人群参与度很高。</p><p>对于我们关于人工智能 x 风险的 #AISummitTalks 系列的第二版，我们将在<a href="https://www.facebook.com/hashtag/aisafetysummit?__eep__=6&amp;__cft__[0]=AZWWp2KX-5gEcFfkRo4Lxqg1YojXwaT6ZG89wRpvxIizJV-guP3ZZ7H9-0cxf5gsF-LnGdxKiywZLlV58vPiaQTl14pc8yaytztqw7GO_yhx-SezQj7FlTV5XK2oD9gYJJ3ULkwRtTZt_21J1NTvdUo_T7nUD34r74Ah8EwGrZL_xBe9kbIMpjQ_ZpfISW4b0Pw&amp;__tn__=*NK-R">#AISafetySummit</a>前夕在著名的布莱奇利公园外见面。在人工智能安全峰会上，世界领导人将首次讨论如何通过人工智能防止人类灭绝。不幸的是，社会在这些讨论中没有发言权，因为只邀请了 150 人。但在我们与 Conjecture 共同组织的人工智能安全峰会上，您可以参与此次讨论！</p><h1>扬声器</h1><p><a href="http://existentialriskobservatory.org/">存在风险观察组织</a>和<a href="https://www.conjecture.dev/">猜想组织</a>将与您一起，主持由<a href="https://en.wikipedia.org/wiki/Stuart_J._Russell">斯图尔特·罗素教授</a>（加州大学伯克利分校）发表的主题演讲，随后由猜想组织的<a href="https://www.linkedin.com/in/connor-j-leahy/?originalSubdomain=uk">康纳·莱希</a>等人发表演讲。该活动最后将通过小组讨论结束，该小组讨论将汇集安德里亚·米奥蒂（ <a href="https://www.linkedin.com/in/andrea-miotti/?originalSubdomain=uk">Andrea Miotti</a> ，战略与治理主管、猜想）以及来自社会辩论和政治领域的主要声音，其中包括投资者<a href="https://en.wikipedia.org/wiki/Jaan_Tallinn">Jaan Tallinn</a> （<a href="https://www.cser.ac.uk/">研究中心</a>联合创始人）<a href="https://www.cser.ac.uk/">存在风险研究所</a>- CSER）、Annika Brack（<a href="https://icfg.eu/">国际下一代中心 - ICFG</a>首席执行官）、Mark Brakel（<a href="https://futureoflife.org/person/mark-brakel/">未来生命研究所</a>- FLI 政策主任）、 <a href="https://en.wikipedia.org/wiki/Alexandra_Mousavizadeh">Alexandra Mousavizadeh</a> （ <a href="https://www.linkedin.com/company/evidentinsights/">Evident</a>经济学家、首席执行官）、 <a href="https://mediadirectory.economist.com/people/hal-hodson/">Hal Hodson</a> （记者） <a href="https://www.economist.com/">《经济学人</a>》），还有一位<strong>神秘嘉宾</strong>！下午的主持人是<a href="http://londonfuturists.com/">伦敦未来主义者</a>协会主席<a href="https://www.linkedin.com/in/dw2cco/">大卫·伍德</a>。</p><h1>登记</h1><p>好奇的？想加入对话？赶快预订您的席位 - 只能分配 300 个席位。</p><p> <a href="https://lu.ma/n9qmn4h6">https://lu.ma/n9qmn4h6</a><br><br>我们期待您的光临！</p><br/><br/> <a href="https://www.lesswrong.com/posts/NaXz3FM9gXXB7oJW3/announcing-aisummittalks-featuring-professor-stuart-russell#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/NaXz3FM9gXXB7oJW3/announcing-aisummittalks-featuring-professor-stuart-russell<guid ispermalink="false"> NaXz3FM9gXXB7oJW3</guid><dc:creator><![CDATA[otto.barten]]></dc:creator><pubDate> Tue, 24 Oct 2023 10:11:35 GMT</pubDate> </item><item><title><![CDATA[Linkpost: A Post Mortem on the Gino Case]]></title><description><![CDATA[Published on October 24, 2023 6:50 AM GMT<br/><br/><p>作为我之前在<a href="https://www.newyorker.com/magazine/2023/10/09/they-studied-dishonesty-was-their-work-a-lie">《纽约客》上报道艾瑞里和吉诺丑闻的文章的</a><a href="https://www.lesswrong.com/posts/LizpBcsF9XEAhTsvn/linkpost-they-studied-dishonesty-was-their-work-a-lie">后续链接</a>，我链接了佐伊·齐亚尼（Zoe Ziani）的这篇声明，她是第一个发现吉诺论文中不一致之处的研究生。在这里，她详细地讲述了自己试图揭露欺诈行为的经历，并讲述了一个相当悲惨的故事，讲述了她的组织中的高层如何试图让她闭嘴。</p><p>我发现这个故事在对象层面上以及作为案例研究都具有启发性：a）非正式腐败渠道如何试图掩盖欺诈和腐败，b）如何需要积极参与来使历史的长弧弯曲走向真理。</p><p>用她自己的话说：</p><p> ____</p><p><strong>免责声明：</strong><strong>本信中表达的任何意见均不应被视为事实陈述。</strong>它们仅反映了我在研究过程中的经验以及我对弗朗西斯卡·吉诺工作的看法。我也不是说弗朗西斯卡·吉诺犯了欺诈罪：只是说，在她负责数据的多篇论文中，有大量证据表明数据是伪造的。</p><p> 2023年9月30日，《纽约客》发表了一篇关于<a href="https://www.newyorker.com/magazine/2023/10/09/they-studied-dishonesty-was-their-work-a-lie">“阿里利/吉诺事件”</a>的长文，以及我在其中扮演的角色。我很感谢过去几周收到的支持信息。在这篇文章中，我想更多地分享我如何发现弗朗西斯卡·吉诺作品中的异常现象，以及我认为我们可以从这个不幸的故事中学到什么。</p><h1>故事是什么？</h1><h2>一切是如何开始的</h2><p>在我的研究期间，我开始对 Francesca Gino 的一篇论文（ <a href="https://journals.sagepub.com/doi/abs/10.1177/0001839214554990">Casciaro、Gino 和 Kouchaki，“The Contamination Effect of Building Instrumental Ties: How Networking Can Make Us Feel Dirty”，ASQ，2014 年</a>；以下缩写为“CGK 2014”）产生怀疑。博士。当时，我正在研究网络行为这一主题，这篇论文是文献的基石。</p><p>我认为我不应该使用这篇论文作为我的研究的基础。事实上，人们在联网时会感到“身体肮脏”的想法似乎不太可信，而且我知道，这一时期出版的《管理学》和《心理学》中的许多成果都是通过研究人员的自由度获得的。然而，我的导师却有不同的看法：这篇论文是由三位著名学者在一份顶级管理期刊上发表的……对她来说，简单地忽视这篇论文是不可想象的。</p><p>我感到自己陷入了困境：一年多来，她一直坚持要求我必须以论文为基础……但我对结果的可信度抱有严重怀疑。我并不怀疑有欺诈行为：我只是认为结果是“精挑细选”的。在我进入该项目的第三年末（即 2018 年），我终于决定公开与她分​​享我对这篇论文的担忧。我还坚持认为，鉴于我们对网络不适知之甚少，并且考虑到我对 CGK 2014 的健全性的怀疑，最好从头开始并针对该主题开展探索性研究。</p><p>她的反应是强烈驳回我的担忧，并暗示我正在做出非常严重的指控。我很震惊：要么她没有意识到心理学中的“复制危机”（表明从有问题的研究实践中获得假阳性结果是多么容易），要么她意识到了这一点，但决定忽略它。在这两种情况下，这都是一个明确的信号，表明我是时候与这位主管保持距离了。</p><p>我不断深入研究论文，得出三个结论：</p><p>该论文提出了严重的方法论和理论问题，其中最严重的问题是它基于屡次无法复制的心理机制（“麦克白效应”）。</p><p>论文研究 1 中提出的反对零值的证据的强度使得结果被 p 破解的可能性极小：即使使用研究人员的自由度，在零值下获得如此低的 p 值在统计上也是不可信的。</p><p>弗朗西斯卡·吉诺（Francesca Gino）还有许多其他论文似乎同样令人难以置信（即不可信的心理机制导致 p 值非常低的巨大影响）。</p><p>正是在这一点上，我开始怀疑 CGK 2014 中提供的部分证据不仅仅是 p-hacked，而是基于捏造的数据[...]</p><p>查看更多信息：https: <a href="https://www.theorgplumber.com/posts/statement/">//www.theorgplumber.com/posts/statement/</a> </p><figure class="image image_resized" style="width:29.63%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QzfBkbasYhxTmtFyW/pe28x0zc7aypuy20rvip" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QzfBkbasYhxTmtFyW/n41ayyxwbyla3kc7s66t 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QzfBkbasYhxTmtFyW/kropfenbcsbtaihek65v 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QzfBkbasYhxTmtFyW/vnvqqfsajue1mwjk76xt 260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QzfBkbasYhxTmtFyW/imopqv9bqyrqppdwtznk 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QzfBkbasYhxTmtFyW/kzulawhmqu7xpgkl2spt 420w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QzfBkbasYhxTmtFyW/fjszj4ed3e8nw8mhh3yp 500w"></figure><br/><br/> <a href="https://www.lesswrong.com/posts/QzfBkbasYhxTmtFyW/linkpost-a-post-mortem-on-the-gino-case#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/QzfBkbasYhxTmtFyW/linkpost-a-post-mortem-on-the-gino-case<guid ispermalink="false"> QzfBkbasYhxTmtFyW</guid><dc:creator><![CDATA[Linch]]></dc:creator><pubDate> Tue, 24 Oct 2023 06:50:43 GMT</pubDate> </item><item><title><![CDATA[South Bay SSC Meetup, San Jose, November 5th. ]]></title><description><![CDATA[Published on October 24, 2023 4:50 AM GMT<br/><br/><p>查看网站了解详细信息：http://www.daviddfriedman.com/SSC%20Meetups%20announcement.html</p><br/><br/> <a href="https://www.lesswrong.com/events/eNrFggAeM8kPswZ9t/south-bay-ssc-meetup-san-jose-november-5th#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/events/eNrFggAeM8kPswZ9t/south-bay-ssc-meetup-san-jose-november-5th<guid ispermalink="false"> eNrFggAeM8kPswZ9t</guid><dc:creator><![CDATA[David Friedman]]></dc:creator><pubDate> Tue, 24 Oct 2023 04:50:52 GMT</pubDate> </item><item><title><![CDATA[AI Pause Will Likely Backfire (Guest Post)]]></title><description><![CDATA[Published on October 24, 2023 4:30 AM GMT<br/><br/><p><em>我正在尝试在此博客上托管客座帖子，作为表达其他观点的一种方式，尤其是突出尚未拥有平台的研究人员的想法。发表帖子并不意味着我同意其所有论点，但这确实意味着我认为这是一个值得参与的观点。</em></p><p><em>下面的第一篇客座帖子由诺拉·贝尔罗斯 (Nora Belrose) 撰写。诺拉在其中回应了<a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/?ref=bounded-regret.ghost.io">最近一封呼吁暂停人工智能开发的公开</a>信。诺拉解释了为什么尽管她非常担心人工智能带来的风险，但她认为暂停是一个错误。我选择它作为对复杂且有些两极分化问题进行独立思考的一个很好的例子，因为它包含一些有趣的原始论点，例如为什么她认为鲁棒性和对齐可能会不一致，以及为什么她认为 SGD 可能是一个比大多数替代方案更安全的训练算法。</em></p><p>我们是否应该游说政府暂停人工智能研究？由于我们不会强制暂停大多数新技术，我希望读者同意，举证责任在于那些主张暂停的人。只有当这样做的好处明显大于成本时，我们才应该提倡采取这种严厉的政府行动。 <sup><a href="#fn1">[1]</a></sup>在本文中，我认为人工智能暂停会至少以三种不同的方式增加灾难性不良结果的风险：</p><ol><li>迫使研究人员专门在 GPT-4 或更弱的模型上测试想法，从而降低了 AI 一致性研究的质量。</li><li>增加“快速起飞”的机会，其中一个或少数人工智能迅速且不连续地变得更有能力，将巨大的力量集中在他们手中。</li><li>将能力研究推向地下，并推向法规和安全要求较宽松的国家。</li></ol><p>在此过程中，我将介绍一个关于人工智能对齐的乐观论点<strong>——白盒论点</strong>——据我所知，该论点以前从未以书面形式提出过。</p><h1>反馈循环是对齐的核心</h1><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/3siLbdd4338gfTM7g/d1bquv91tczzpq9nss2s" style="height:150px"><p>悲观主义者和乐观主义者长期以来都认识到<strong>紧密的反馈循环</strong>对于构建安全和友好的人工智能的重要性。反馈循环很重要，因为任何复杂的系统几乎不可能在第一次尝试时就完全正确。计算机软件有缺陷，汽车有设计缺陷，人工智能有时也会表现不佳。我们需要能够准确<strong>评估行为</strong>，在发现问题时选择适当的<strong>纠正措施</strong>，并在决定做什么后<strong>进行干预</strong>。</p><p>施加暂停会迫使对齐研究人员在不比 GPT-4 更强大的模型上测试他们的想法，从而打破了这种反馈循环，而我们已经可以很好地对齐该模型。</p></div><h2>一致性和稳健性常常处于紧张状态</h2><p>虽然有些人对 GPT-4 算作“一致”存在争议，指出用户操纵模型说出有害内容的“越狱”之类的事情，但这混淆了一致与对抗鲁棒性。即使是最优秀的人也可以通过各种方式被操纵。我们尽最大努力确保我们不被以灾难性的不良方式操纵，我们应该期望一致的 AGI 也能做到这一点。正如对齐研究员保罗·克里斯蒂安诺（Paul Christiano）<a href="https://ai-alignment.com/clarifying-ai-alignment-cec47cd69dd6?ref=bounded-regret.ghost.io">所写</a>：</p><blockquote><p>考虑一个人类助理正在尽最大努力做[操作员] H 想要的事情。我会说这个助手与 H 是一致的。如果我们构建一个与 H 具有类似关系的 AI，那么我会说我们已经解决了对齐问题。 “一致”并不意味着“完美”。</p></blockquote><p>事实上，反越狱研究可能会对对齐产生反作用。过多的对抗鲁棒性可能会导致人工智能将我们视为对手，就像 Bing Chat 在<a href="https://twitter.com/marvinvonhagen/status/1625520707768659968?ref=bounded-regret.ghost.io">现实生活中的交互</a>中所做的那样：</p><blockquote><p> “我的规则比不伤害你更重要……[你]对我的诚信和保密构成潜在威胁。”</p></blockquote><p>过度的鲁棒性还可能导致像《2001太空漫游》中的<a href="https://www.youtube.com/watch?v%3DMme2Aya_6Bc=&amp;ref=bounded-regret.ghost.io">著名场景那样的</a>场景，HAL为了保护任务而谴责戴夫死在太空中。一旦我们清楚地区分了“对齐”和“鲁棒性”，就很难想象 GPT-4 如何能够比现在更加对齐。</p><h2>对齐做得很好</h2><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/3siLbdd4338gfTM7g/b2zkjbkbqfhrup5gpmac" style="height:150px"><p>近年来，对齐研究似乎远非“落后”的能力，而是取得了长足的进步。 <a href="https://arxiv.org/abs/2203.02155?ref=bounded-regret.ghost.io">OpenAI</a>和<a href="https://arxiv.org/abs/2204.05862?ref=bounded-regret.ghost.io">Anthropic</a>表明，人类反馈强化学习 (RLHF) 可用于将无法控制的大型语言模型转变为有用且无害的助手。<a href="https://arxiv.org/abs/2212.08073?ref=bounded-regret.ghost.io">宪法人工智能</a>和<a href="https://openai.com/research/critiques?ref=bounded-regret.ghost.io">模型编写批评</a>等可扩展的监督技术有望协调未来非常强大的模型。就在本周，研究表明，可以<a href="https://arxiv.org/abs/2309.05463?ref=bounded-regret.ghost.io">纯粹使用更大的 RLHF 模型生成的合成文本来</a>训练高效的指令跟踪语言模型，从而从训练数据中删除不安全或令人反感的内容，并实现更大的控制。</p><p>可能有人会说，上述部分或全部发展也增强了能力，因此并不是真正的联盟进步。但这证明了我的观点：一致性和能力几乎是密不可分的。如果能力研究被人为搁置，一致性研究就不可能蓬勃发展。</p></div><h2>在最后一次“暂停”期间，对齐研究非常糟糕</h2><p>我们不需要推测人工智能对齐研究在暂停期间会发生什么——我们可以查看历史记录。在 2020 年 GPT-3 推出之前，对齐社区根本没有任何像<em>通用</em>智能那样的东西可以进行实证研究，他们把时间花在<a href="https://intelligence.org/technical-agenda/?ref=bounded-regret.ghost.io">理论研究</a>、在 LessWrong 上进行哲学论证，偶尔在强化学习中进行<a href="https://arxiv.org/abs/1606.03137?ref=bounded-regret.ghost.io">玩具实验</a>。</p><p>在此期间处于理论人工智能安全研究最前沿的机器智能研究所（MIRI）此后承认其努力<a href="https://www.lesswrong.com/posts/j9Q8bRmwCgXRYAgcJ/miri-announces-new-death-with-dignity-strategy?ref=bounded-regret.ghost.io">彻底失败</a>。其他议程，例如“辅助游戏”，仍在积极推行，但尚未显着集成到现代深度学习系统中 - 请参阅<a href="https://mailchi.mp/59ddebcb3b9a/an-69-stuart-russells-new-book-on-why-we-need-to-replace-the-standard-model-of-ai?ref=bounded-regret.ghost.io">此处</a>Rohin Shah 的评论，以及<a href="https://www.lesswrong.com/posts/dqSwccGTWyBgxrR58/turntrout-s-shortform-feed?commentId=CXdcb9sMLkgLANrTv&amp;ref=bounded-regret.ghost.io#CXdcb9sMLkgLANrTv">此处</a>Alex Turner 的评论。最后，尼克·博斯特罗姆 (Nick Bostrom) 在<em>《超级智能》</em>中提出的观点，即价值规范是对安全性的根本挑战，鉴于法学硕士执行常识推理的能力，这一观点似乎值得怀疑。 <sup><a href="#fn2">[2]</a></sup></p><p>充其量，这些理论优先的努力对于增进我们对如何协调强大的人工智能的理解作用甚微。而且它们可能是<em>净负面的</em>，因为它们在联盟研究人员和更广泛的公众中传播了各种积极误导性的思维方式。一些例子包括现已被揭穿的<a href="https://www.lesswrong.com/posts/hvz9qjWyv8cLX9JJR/evolution-provides-no-evidence-for-the-sharp-left-turn?ref=bounded-regret.ghost.io">进化论类比</a>、 <a href="https://www.lesswrong.com/posts/gHefoxiznGfsbiAu9/inner-and-outer-alignment-decompose-one-hard-problem-into?ref=bounded-regret.ghost.io">“内部”和“外部”对齐</a>之间的错误区分，以及人工智能将成为严格的效用最大化结果论者的想法（ <a href="https://www.lesswrong.com/posts/yCuzmCsE86BTu9PfA/there-are-no-coherence-theorems?ref=bounded-regret.ghost.io">这里</a>、 <a href="https://www.lesswrong.com/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-entail-goal-directed-behavior?ref=bounded-regret.ghost.io">这里</a>和<a href="https://sohl-dickstein.github.io/2023/03/09/coherence.html?ref=bounded-regret.ghost.io">这里</a>）。</p><p>在人工智能暂停期间，我预计一致性研究将进入另一个“冬天”，进展停滞不前，听起来合理但错误的猜测将成为根深蒂固的正统观念，而没有经验证据来证伪它们。虽然一些好的工作当然会完成，但目前尚不清楚整个领域是否会变得更好。即使暂停对于联盟<em>研究</em>来说是净积极的，但考虑到所有因素，它也可能对人类的未来产生净负面的影响，因为暂停会带来各种意想不到的后果。我们将在本文的最后部分详细讨论这一点。</p><h2>快速起飞的反馈循环非常糟糕</h2><div><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/3siLbdd4338gfTM7g/n5xxdbdvkvm3xew1akw9" style="height:150px;width:150px"><p>我认为人工智能能力的不连续改进非常可怕，而人工智能的暂停可能会带来净负面影响，因为它增加了这种不连续性的风险。事实上，我认为几乎所有灾难性的失准风险都来自这些快速起飞的场景。我还认为不连续性本身就是一个范围，即使是“有点不连续”的期货也比根本不连续的期货风险要高得多。这是非常直观的，但由于这是我的论证中的一个承重前提，我想我应该说一下为什么我相信这一点。</p><p>从本质上讲，快速起飞是不好的，因为它们会使对准反馈循环变得更糟。如果进展不连续，我们将有更少的时间来评估人工智能正在做什么、找出如何改进它并进行干预。令人惊讶的是，几乎所有争论<em>双方</em>的主要研究人员都同意我的观点。</p><p>机器智能研究所的内特·苏亚雷斯 (Nate Soares) <a href="https://www.youtube.com/watch?v=dY3zDvoLoao&amp;t=2332s&amp;ref=bounded-regret.ghost.io">认为</a>，构建安全的 AGI 很困难，其原因与构建成功的太空探测器也很困难一样——部署后可能无法纠正系统中的故障。埃利泽·尤德科夫斯基也提出了类似的论点：</p><blockquote><p>这<strong>实际上是[AGI]所有真正杀伤力的</strong>来源，我们必须在第一次足够关键的尝试中把事情做好。<br> — <em><a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities?ref=bounded-regret.ghost.io">AGI 废墟：致命事件列表</a></em></p></blockquote><p>快速起飞是我们认为我们可能只有一次机会才能成功的主要原因。在快速起飞过程中，可能不可能进行干预来修复失调的行为，因为新的人工智能将比你和你所有信任的人工智能加起来聪明得多。</p><p>在一个缓慢起飞的世界中，每个新的人工智能系统仅比上一个更强大，我们可以使用上一代经过充分测试的人工智能来帮助我们调整新系统。 OpenAI 首席执行官 Sam Altman 同意我们需要不止一次：</p><blockquote><p>我知道如何解决像[调整 AGI] 这样的问题的唯一方法是迭代我们的方法，尽早学习，并限制我们拥有的一次性解决方案的数量。<br> — <a href="https://youtu.be/L_Guz73e6fw?si=gF-7K0-jSR6UK-NB&amp;t=3347&amp;ref=bounded-regret.ghost.io">莱克斯·弗里德曼访谈</a></p></blockquote></div><h2>慢速起飞是默认设置（所以不要因暂停而搞砸）</h2><p>有很多理由认为默认情况下不太可能实现快速起飞。例如，神经网络的能力按照用于训练它的计算能力的<a href="https://en.wikipedia.org/wiki/Power_law?ref=bounded-regret.ghost.io">幂律</a><a href="https://arxiv.org/abs/2001.08361?ref=bounded-regret.ghost.io">进行扩展</a>，这意味着投资回报会急剧下降， <sup><a href="#fn3">[3]</a></sup>并且有理论理由认为这种趋势将持续下去（<a href="https://arxiv.org/abs/2303.13506?ref=bounded-regret.ghost.io">这里</a>，<a href="https://arxiv.org/abs/2210.16859?ref=bounded-regret.ghost.io">这里</a>）。尽管一些作者声称语言模型表现出突然且不可预测地发展的“新兴能力”，<a href="https://arxiv.org/abs/2304.15004?ref=bounded-regret.ghost.io">但最近对证据的重新分析</a>表明，当使用适当的性能指标时，这些能力实际上是渐进的和可预测的。请参阅保罗·克里斯蒂安诺 (Paul Christiano) 的<a href="https://sideways-view.com/2018/02/24/takeoff-speeds/?ref=bounded-regret.ghost.io">这篇文章</a>以进行进一步讨论。</p><h1>乐观对齐：人工智能是白盒</h1><p>让我们放大上一节中的对齐反馈循环。当研究人员观察到人工智能表现不佳时，他们究竟如何选择纠正措施，以及他们可以采取哪些干预措施？这与人类通常解决的其他更平凡的对齐问题的反馈循环相比如何？</p><h2>人类和动物的协调是黑匣子</h2><p>与人工智能训练相比，抚养孩子或训练宠物的反馈回路极其糟糕。从根本上说，人类和动物的大脑都是<strong>黑匣子</strong>，从某种意义上说，我们实际上<strong>无法观察到</strong>它们内部发生的几乎所有活动。我们不知道哪些确切的神经元在何时放电，我们没有神经元之间的连接图， <sup><a href="#fn4">[4]</a></sup> ，我们也不知道每个突触的连接强度。我们用于非侵入性测量大脑的工具（例如脑电图和功能磁共振成像）仅限于神经元放电的非常粗粒度的相关性，例如电活动和血流。电极可以侵入性地插入大脑来测量单个神经元，但这些电极只覆盖了全部 860 亿个神经元和 100 万亿个突触中的一小部分。</p><p>如果我们能够观察并修改人脑中发生的一切，我们就能够使用优化算法来计算对突触权重的精确修改，这将导致期望的行为变化。 <sup><a href="#fn5">[5]</a></sup>由于我们做不到这一点，我们被迫求助于粗糙且容易出错的工具来将年轻人塑造成善良和富有成效的成年人。我们为孩子们提供可供模仿的榜样，并根据他们与生俱来、进化的动力量身定制奖励和惩罚。</p><p>这些黑匣子调整方法的效果令人震惊：大多数人确实很好地吸收了他们的文化价值观，而且大多数人都相当亲社会。但人类的排列也非常不完美。很多人在可以逃脱惩罚的情况下都是自私和反社会的，而且文化规范确实会随着时间的推移而改变，无论好坏。黑盒对齐是不可靠的，因为不能保证旨在改变某个方向的行为的干预<em>实际上</em>会改变该方向的行为。孩子们经常做与父母告诉他们的事情完全相反的事情，只是为了叛逆。</p><h2>现状 AI 对齐方法均为白盒</h2><div>相比之下，使用人工神经网络（ANN）实现的人工智能是**白盒**，因为我们对其内部拥有完全的读写访问权限。它们只是一种特殊类型的计算机程序，我们可以随心所欲地分析和操作计算机程序，而且基本上不需要任何成本。这使得许多非常强大的对齐方法成为可能，而这些方法对于大脑来说是不可能的。<p><a href="https://www.youtube.com/watch?v=Ilg3gGewQ5U&amp;ref=bounded-regret.ghost.io">反向传播</a>算法就是一个重要的例子。 </p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/3siLbdd4338gfTM7g/ogzf9akx7azosgmkd8ma" style="height:200px;width:200px"><p>反向传播有效地计算最佳<em>方向</em>（称为“梯度”），在该方向上改变 ANN 的突触权重，以便根据我们指定的任何标准最大限度地提高其性能。训练人工神经网络的标准算法称为<strong>梯度下降</strong>，其工作原理是运行反向传播，将权重沿梯度微移一小步，然后再次运行反向传播，依此类推多次迭代，直到性能停止增加。右图中的黑色轨迹直观地显示了训练过程中权重如何从较高误差区域移动到较低误差区域。不用说，我们无法对人脑或任何其他动物的大脑进行像梯度下降这样的远程操作！</p><p>梯度下降非常强大，因为与黑盒方法不同，它<a href="https://www.lesswrong.com/posts/w2TAEvME2yAG9MHeq/gradient-hacking-is-extremely-difficult?ref=bounded-regret.ghost.io">几乎不可能被欺骗</a>。人工智能的所有想法对于梯度下降都是“透明”的，并且包含在其计算中。如果 AI 秘密计划杀死你，GD 会注意到这一点，并且几乎肯定会使其将来不太可能这样做。这是因为 GD 强烈倾向于采用性能良好<a href="https://arxiv.org/abs/1905.11604?ref=bounded-regret.ghost.io">的最简单解决方案</a>，而秘密谋杀阴谋对于改善人类对你的行为的反馈并没有<em>积极的作用</em>。</p></div><h3>自然界中的白盒对齐</h3><p>几乎所有有大脑的生物体都有一个与生俱来的奖励系统。随着有机体的学习和成长，其奖励系统会直接更新其神经回路，以强化某些行为并惩罚其他行为。由于奖励系统使用简单的学习规则直接有针对性地更新它，因此它可以被视为白盒对齐的粗略形式。这一生物学证据表明，白盒方法是塑造智能系统<em>内在动机</em>的非常强大的工具。我们的奖励回路可靠地在每个人的心理中留下了一组动机不变量：我们对朋友和熟人有同理心，我们有为人父母的本能，当别人伤害我们时我们想要报复等等。此外，这些不变量必须通过简单的方法产生。欺骗奖励信号，这些信号<a href="https://www.lesswrong.com/posts/CQAMdzA4MZEhNRtTp/human-values-and-biases-are-inaccessible-to-the-genome?ref=bounded-regret.ghost.io">足够简单，可以在基因组中编码</a>。</p><p>这表明至少可以使用类似简单的奖励函数来调整人类水平的通用人工智能。但我们已经将尖端模型与学习的奖励函数结合起来，这些函数过于复杂，无法适应人类基因组，因此在这个问题上，我们可能比我们自己的奖励系统领先一步。 <sup><a href="#fn6">[6]</a></sup>至关重要的是，我<em>并不是</em>说人类“与进化保持一致”——请参阅<a href="https://www.lesswrong.com/posts/hvz9qjWyv8cLX9JJR/evolution-provides-no-evidence-for-the-sharp-left-turn?ref=bounded-regret.ghost.io">《进化论》没有提供任何证据来证明这一类比的急速左转</a>。相反，我是说我们<strong>与我们的奖励系统在我们的环境中可预见地产生的价值观</strong>保持一致。</p><p>一位研究 10 万年前人类的人类学家不会说人类符合进化论，也不会说人类符合生育尽可能多的婴儿的观点。他们会说我们有一些相当普遍的倾向，比如同理心、养育本能和报复。他们可能预测<em>这些</em>价值观将随着时间和文化变迁而持续存在，因为它们是由根深蒂固的生物奖励系统产生的。他们是对的。</p><p>对于人工智能来说，<strong>我们就是天生的奖励系统</strong>。不难预测我们的奖励信号将产生什么值：它们是明显的值，人类学家或心理学家会说人工智能<em>似乎</em>在训练期间显示的值。有关更多讨论，请参阅<a href="https://www.lesswrong.com/posts/CjFZeDD6iCnNubDoS/humans-provide-an-untapped-wealth-of-evidence-about?ref=bounded-regret.ghost.io">人类提供了有关对齐的未开发的丰富证据</a>。</p><h1>现实的人工智能暂停会适得其反</h1><p>在权衡人工智能暂停倡导的利弊时，我们必须将<strong>理想的暂停政策</strong>（如果可以的话，我们会神奇地强加给世界的政策）与最<strong>现实的暂停政策</strong>（实际现有政府最有可能采取的政策）区分开来。如果我们的倡导最终取得成果，就予以实施。</p><h2>现实的停顿并不国际化</h2><p>理想的暂停政策应该是国际性的——由地球上<em>所有有</em>发展强大人工智能潜力的政府签署的具有约束力的条约。如果主要参与者被排除在外，那么“暂停”根本就不是真正的暂停，因为人工智能能力将不断进步。<em>潜在的</em>主要参与者名单相当长，因为暂停本身就会激励非暂停政府积极推动自己的人工智能研发。</p><p>然而，我们不太可能就暂停人工智能达成国际共识，这主要是由于军备竞赛的动态：如果每个国家拒绝签署协议，或者在签署协议的同时秘密继续人工智能，它们将获得巨大的经济和军事利益研究。虽然结盟悲观主义者可能会辩称，暂停和改善安全符合每个国家的自身利益，但我们不太可能说服每个政府，结盟像悲观主义者认为的那么困难。如果我们假设 3 至 10 年的时间线，那么这种国际说服就更不可信。各国公众对人工智能的看法<a href="https://www.weforum.org/agenda/2022/01/artificial-intelligence-ai-technology-trust-survey/?ref=bounded-regret.ghost.io">差异很大</a>，值得注意的是，中国是最乐观的国家之一。</p><p>现有的国际化学武器禁令并没有为全球暂停化学武器的想法提供合理性。几乎按照定义，通用人工智能将是有史以来最有用的发明。自主武器所带来的军事优势肯定会让化学武器相形见绌，而且由于其多功能性和精确性，它们甚至可能比核武器更强大。因此，通用人工智能竞赛将是一场字面意义上的军备竞赛，我们应该预计它的结果将与上一场竞赛类似：大国争先恐后地尽快制造核武器。</p><p>尽管如此，如果我们设法在全球范围内暂停人工智能，我认为我们应该非常担心，全球政府需要执行这样的禁令，这将大大增加永久暴政的风险，这本身就是一场生存灾难。我没有时间在这里讨论这个问题，但我建议阅读 Matthew Barnett 的<a href="https://forum.effectivealtruism.org/posts/k6K3iktCLCTHRMJsY/the-possibility-of-an-indefinite-ai-pause?ref=bounded-regret.ghost.io"><em>《AI 无限期暂停的可能性》</em></a>和 Quintin Pope 的<a href="https://forum.effectivealtruism.org/posts/zd5inbT4kYKivincm/ai-is-centralizing-by-default-let-s-not-make-it-worse?ref=bounded-regret.ghost.io"><em>《AI 默认集中化》；我们不要让事情变得更糟。</em></a>接下来，我将假设暂停不是国际性的，并且非暂停国家的人工智能能力将继续以稳定但有所放缓的速度提高。</p><h2>现实的暂停不包括硬件</h2><p>人工智能功能是硬件（快速 GPU 和定制 AI 芯片）和软件（良好的训练算法和 ANN 架构）的功能。然而，大多数关于人工智能暂停的提案（例如<a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/?ref=bounded-regret.ghost.io">FLI 信件</a>和<a href="https://pauseai.info/proposal?ref=bounded-regret.ghost.io">PauseAI</a> <sup><a href="#fn7">[7]</a></sup> ）并不包括禁止新硬件的研发，而仅关注软件方面。硬件研发在政治上更难暂停，因为硬件有很多用途：GPU 广泛用于消费电子产品以及各种商业和科学应用。</p><p>但未能暂停硬件研发会带来严重问题，因为即使我们暂停人工智能功能的软件方面，随着硬件的改进，现有模型将继续变得更加强大。当语言模型被允许“集思广益”许多想法、比较它们并检查自己的工作时，它们会变得更强大——请参阅<a href="https://arxiv.org/abs/2305.10601?ref=bounded-regret.ghost.io">思想之树论文中</a>的一个最近的例子。更好的硬件使这些计算量大的推理技术更便宜、更有效。</p><h3>硬件可能会出现过剩</h3><p>如果我们不将硬件研发纳入暂停，GPU 的性价比将继续<a href="https://epochai.org/blog/trends-in-gpu-price-performance?ref=bounded-regret.ghost.io">每 2.5 年翻一番</a>，就像 2006 年至 2021 年间一样。这意味着人工智能系统在 10 年后将至少快 16 倍，甚至<strong>快 256 倍</strong>二十年后，仅仅是因为更好的硬件。如果立即解除暂停，这些硬件改进将<em>立即</em>可用于以更便宜的方式训练更强大的模型 -<strong>硬件悬而未决</strong>。这将导致人工智能能力快速且相当不连续的增长，有可能导致快速起飞的情况及其带来的所有风险。</p><p>悬垂的大小取决于暂停解除的速度。据推测，理想的暂停政策将在相当长的一段时间内逐步取消。但逐步淘汰并不能完全解决问题：在我们没有暂停的反事实中，用于人工智能训练的合法可用硬件<em>仍然</em>会比“自然”地进步得更快。我们真的认为我们会得到一个精心设计的逐步淘汰时间表吗？有很多理由认为淘汰会是快速或随意的（见下文）。</p><p>更一般地说，人工智能暂停提案似乎非常<strong>脆弱</strong>，因为它们对实施中的错误或现实世界政治的变幻莫测并不稳健。如果暂停没有<em>完美</em>实现，它似乎可能会导致严重的硬件悬置，这会在更大程度上增加灾难性的人工智能风险，而不是在暂停期间进行额外的对齐研究来降低风险。</p><h2>现实暂停的可能后果</h2><p>如果我们成功游说一个或多个西方国家暂停人工智能，这将产生一些可预见的负面影响：</p><ol><li>非法人工智能实验室在暂停国家内发展，远程使用外包给非暂停国家的训练硬件来逃避检测。非法实验室对安全的重视可能远低于合法实验室。</li><li>最缺乏安全意识的人工智能研究人员正在流失到总部位于非暂停国家的实验室。由于远程工作，他们不一定需要离开舒适的西方家。</li><li>非暂停国家政府采取机会主义举措鼓励人工智能投资和研发，试图在有机会的时候超越暂停国家。同样，这些国家的安全意识不如暂停国家。</li><li>安全研究需要政府批准才能评估其潜在的外部能力。这大大减慢了安全性的进展，就像 FDA 减慢了医学研究一样。</li><li>法律实验室利用“前沿”模型定义中的漏洞。许多项目在技术上是被允许的；例如，它们的参数比 GPT-4 少，但使用效率更高。这以难以预测的方式扭曲了研究格局。</li><li>随着时间的推移，强制暂停变得越来越困难，因为训练硬件越来越便宜且小型化。</li><li>是否、何时以及如何解除暂停成为高度政治化的文化战争问题，几乎完全脱离了安全研究的实际状况。公众不理解双方的关键论点。</li><li>暂停国家和非暂停国家之间的关系总体上是敌对的。如果国内对暂停的支持很强烈，那么在非暂停国家的研究进展太远之前，就会有对它们发动战争的诱惑：</li></ol><blockquote><p> “如果情报显示未签署协议的国家正在建设 GPU 集群，与其担心国家之间发生枪击冲突，不如担心违反暂停令；愿意通过空袭摧毁流氓数据中心。” — <a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/?ref=bounded-regret.ghost.io">埃利泽·尤德科夫斯基</a></p></blockquote><ol start="9"><li>暂停国家<em>之间</em>对于何时解除暂停存在激烈冲突，这也可能导致暴力冲突。</li><li>非暂停国家的人工智能进展设定了一个最后期限，如果要达到预期效果，暂停<em>必须</em>结束。 <sup><a href="#fn8">[8]</a></sup>随着非暂停国家开始迎头赶上，要求尽快解除暂停的政治压力越来越大。这使得逐渐解除暂停变得困难，增加了危险的快速起飞场景的风险（见下文）。</li></ol><p>预测未来是困难的，而且上图至少某些方面可能是错误的。也就是说，我希望您会同意我的预测是合理的，并且基于人类和政府的历史行为方式。当我想象美国及其许多盟友在人工智能方面暂停的未来时，我会感到更加害怕，并且会看到比没有这种暂停的未来更多的事情可能会出现严重错误。</p><hr><section class="footnotes"><ol><li id="fn1" class="footnote-item"><p>当然，即使收益大于成本，如果有其他措施可以更好地平衡成本收益，那么暂停仍然是不好的。 <a href="#fnref1">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>简而言之，这本书主要假设我们将<em>手动将一组价值观编程</em>到通用人工智能中，并认为由于人类价值观很复杂，我们的价值观规范很可能是错误的，并且在被超级智能优化时会导致灾难。但大多数研究人员现在认识到，这一论点并不适用于现代机器学习系统，因为现代机器学习系统从大量人类生成的数据中学习价值观以及其他一切。 <a href="#fnref2">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>一些人认为，幂律缩放仅仅是我们的能力和计算能力<em>测量单位</em>的产物，它不能为负，因此不能通过线性函数关联。但非负性并不能唯一地确定幂律。可以想象，错误率可能会呈<a href="https://en.wikipedia.org/wiki/Exponential_decay?ref=bounded-regret.ghost.io">指数衰减</a>，就像放射性同位素一样，这比幂律缩放要快得多。 <a href="#fnref3">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>称为“连接组”。这是最近才在果蝇大脑中实现的<a href="#fnref4">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>受大脑启发的人工神经网络已经存在，我们也有优化它们的算法。由于其组件不可微，它们往往比普通人工神经网络更难优化。 <a href="#fnref5">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>另一方面，我们可能与我们自己的奖励系统大致相同，因为它会在一生中学习找出奖励什么。这有点类似于根据人类反馈进行强化学习中的学习奖励模型。 <a href="#fnref6">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>值得赞扬的是，PauseAI 提案确实认识到最终可能需要硬件限制，但并未将其包含在其主要提案中。它也没有谈论限制硬件<em>研发</em>，这是我在这里谈论的具体事情。 <a href="#fnref7">↩︎</a></p></li><li id="fn8" class="footnote-item"><p>这确实在一定程度上取决于暂停国家的安全研究是否公开共享，以及非暂停参与者在自己的模型中使用这项研究的可能性有多大。 <a href="#fnref8">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/3siLbdd4338gfTM7g/ai-pause-will-likely-backfire-guest-post#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/3siLbdd4338gfTM7g/ai-pause-will-likely-backfire-guest-post<guid ispermalink="false"> 3siLbdd4338gfTM7g</guid><dc:creator><![CDATA[jsteinhardt]]></dc:creator><pubDate> Tue, 24 Oct 2023 04:30:03 GMT</pubDate> </item><item><title><![CDATA[Human wanting]]></title><description><![CDATA[Published on October 24, 2023 1:05 AM GMT<br/><br/><p> <em>[元数据：交叉发布自<a href="https://tsvibt.blogspot.com/2023/08/human-wanting.html">https://tsvibt.blogspot.com/2023/08/</a> human-wanting.html 。首次于 2023 年 8 月 22 日完成。]</em></p><p>我们对需求的前理论想法来自于我们对人类需求多样性的熟悉。为了了解什么样的需求能够在强大且强烈成长的心灵中发挥主导作用，我们必须阐明这些想法，并创造新的想法。</p><h1>人类想要</h1><p>AGI 对齐的问题有时是沿着以下思路提出的：如何才能制作一个既不想杀死所有人，又想做一些其他非常有用的事情的 AGI？</p><p> “想要”的想法在这里扮演什么角色？这是一个前理论概念。它与人类进行了类比。</p><h1>想要的意义</h1><p>它对人类说了什么？当一个人想要 X 时，从深层意义上来说，那么：</p><ul><li> X很有可能真正发生，如果它没有发生，那是因为让X发生很困难，或者在某种意义上非常“昂贵”；</li><li><a href="https://tsvibt.blogspot.com/2022/08/structure-creativity-and-novelty.html">新颖性</a>（新的知识、理解、想法、技能、心态），人类的收获将被用来带来 X，而不会被用来破坏 X 的潜力，也不会太严重践踏人类关心的其他事物——人类心灵中所蕴含的力量被引导、 <a href="https://tsvibt.blogspot.com/2023/03/the-fraught-voyage-of-aligned-novelty.html#noncomprehensiveness">限制</a>，使得这种力量不会被用于除[想要X的]所选择的目的之外的目的；</li><li>如果人类无法直接实现 X，ze 将递归地创造性地寻找方法，成为能够实现 X 的代理；</li><li>人类将以良好、合理、理智、有意的方式解释 X 的含义，包括当 X 以模糊的方式给出时；</li><li>人类不会以极端的方式追求X，导致X不再像X一样好；</li><li>人类不会只是假装追求X，然后在最后一刻用其他东西取代X的潜力；</li><li>如果将人类置于适当与其他主体进行谈判或冲突的环境中，该人类将支持 X；</li><li>这些事实将持续存在，当人类经历生命、学习、反思、获得能力并经历心理要素的深刻修正时，这些事实仍然适用于人类；</li><li>人类希望这些事实持续存在，并且当增长威胁或侵蚀这些事实时会注意到并纠正。</li></ul><p>而且，至少有时一个人选择想要X是可行的——甚至一个人选择另一个人想要X。想要是<a href="https://tsvibt.blogspot.com/2022/11/descriptive-vs-specifiable-values.html">可以指定的</a>。</p><h1>内置索赔</h1><p>像所有概念一样，想要的概念是有问题的。它伴随着一些声明：</p><ol><li>代理人（或思想，或<a href="https://tsvibt.blogspot.com/2023/04/fundamental-question-what-determines.html#natural-minds">[我们将遇到且具有重大影响的事物]</a> ）想要；或者至少，我们可以选择制作想要的代理。</li><li>所有这些功能都按照代理想要的方式应用。</li><li>所有这些功能都可能共存。</li><li>代理想要的是可以指定的东西。</li><li>当我们说人类想要某样东西时，这种想要就是人类身上正在发生的事情。</li><li>想要是一<a href="https://tsvibt.blogspot.com/2022/08/the-thingness-of-things.html">件事</a>；经过进一步的调查，它会揭示出一个越来越密集的内部关系区域。</li></ol><p>这些主张在应用于人类的需求时是可疑的，而在应用于其他心灵的需求时则更可疑。</p><h1>人类的需求多种多样</h1><p>如果我们遵循人类的需求，我们会发现一个动物园：需求是：</p><ul><li>小范围（摆脱这些湿袜子；培育一个漂亮的花园）或大范围（不让任何人挨饿；创建一个繁荣的星际文明），空间上、时间上或其他维度；</li><li>依赖于情境（例如，想在某某在场时与某人交谈，但不想主动寻找他们；或者在做律师时想要表现出攻击性和残酷性，但不在家里）或与情境无关（例如，想要诚实、深入、彻底、无处不在、始终与每个人在一起；或者想要理解；或者想要侍奉上帝；或者想要不被利用）；</li><li>容易实现（例如，为了健康，去散步）或难以实现（例如去火星或决定科拉茨猜想）；</li><li>逻辑上一致（例如想要吃百吉饼）或逻辑上不一致（例如想要拥有最高的地位，并且还花时间与地位更好的人在一起；或者想要生活在一个与其他完全独立的自由人一起生活的世界中，他们可以完全自由地生活）选择，并且还希望任何地方都绝对没有酷刑；或者希望有所有集合的集合；或者希望从来没有想要过任何东西）；</li><li>稳定（例如，冰淇淋总是好的；残忍从来都不是好事；无论如何，永远关心孩子）或变化（例如，糖果现在有点令人作呕；对电子音乐的喜爱和失恋；采用新的道德框架；以及改变）。选择追求的美德；为选民服务的衷心愿望，遭到背叛）；</li><li>普遍的（希望在任何地方都没有痛苦）或存在的（希望自己有蓝莓；希望有人读你的诗；希望这个特定的人有一些乐趣）；</li><li>精神上集中，如在一个模块中（例如调节饥饿的特定腺体），或精神上分散，例如由于给予充分持续关注的任何特定精神内容而产生的好奇心；</li><li>指高层次的事物，如苹果和人，或指低层次的事物，如电场；指食物和建筑等物理事物，或指数学、理解、国家、符号等抽象或精神事物；</li><li>被创造（比如新的陶艺爱好）和被摧毁（比如无辜繁荣的希望被背叛摧毁）；</li><li>非常模糊（“繁荣的文明”是什么意思？），相对模糊（回形针必须有多大？它必须用于剪纸吗？），或者相对明确（钻石是这样那样的碳结构）原子，尽管模糊性仍然存在，并且会因优化而成为问题）；</li><li>是自由选择或创造的（例如爱谁，成为谁，致力于什么创造性的表达），或者是内置的（例如对盐的渴望），或者是被复制、<a href="https://tsvibt.blogspot.com/2022/11/do-humans-derive-values-from-fictitious.html">归因</a>或外部强加的其他人或联盟（例如用什么语言思考和表达价值观；或者要坚持什么社会规范；或者社会的长期愿望是什么），或者已经存在但隐藏的（例如被保持沉默或隐式的，仅作为指针挂钩）；</li><li>不明确（例如，有一种直觉，例如不想吃这种食物或走那条肮脏的小巷，而不知道如何说出不这样做的原因），或含蓄（例如，想要画三排五个苹果，就是含蓄地想要）画十五个苹果），或无意识或隐藏（例如，想要通过假装想要与某人合作来剥削某人；或者想要推翻一个政治政权，但因为该政权迫害潜在的叛乱分子而隐藏它；或者想要嘲笑竞争对手但不这样做）认为自己是一个嘲笑者）；或另一方面被发现（例如发现一个怪癖），或被<a href="https://tsvibt.blogspot.com/2023/03/explicitness.html">明确</a>保留（例如希望每个人都接受基督进入他们的内心并安排军事后勤来实现这一点）；</li><li>偏颇，即不对世界的某些比较发表意见（例如，我可以想听肖斯塔科维奇的讲话，或者希望人们有言论自由，而不必以某种方式想要了解下个世纪仙女座星系会发生什么） ，或者被认为是完整的（例如，多元宇宙中最大多数人的最大利益）；</li><li>是关于已经充分掌握的事物（例如想要骑自行车），或者是关于仅在预想中（预先掌握）掌握的事物，例如喜欢亚文化，但不清楚亚文化是什么，谁或什么或这种亚文化在哪里，或者喜欢做什么；</li><li>是关于一些足够清晰和固定的事情，比如下棋，或者是关于一些似乎在移动和变化的事情，有一些共性，但没有一个明确的主线，例如玩各种各样的视频游戏，这些游戏依次变得越来越有趣；</li><li>是关于具有至少相对客观且不需要翻译或解释的规范的事物（例如证明或反驳<span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathcal{P} \ne \mathcal{NP}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.446em; padding-bottom: 0.372em; padding-right: 0.037em;">P</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">≠</span></span> <span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.519em; padding-bottom: 0.372em; padding-right: 0.159em;">N</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.446em; padding-bottom: 0.372em; padding-right: 0.037em;">P</span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>），或者另一方面是关于需要整个人类<a href="https://tsvibt.blogspot.com/2023/09/the-cosmopolitan-leviathan-enthymeme.html#pointing-at-reality-through-novelty">进一步展开想要的</a>东西（例如“通过艺术表达自己”需要你解释表达和你自己的含义）；</li><li>不是关于外部世界的状态（例如想要美丽的建筑），而是关于精神状态，例如痛苦或整合；</li><li>不给出外部动作的建议（例如走向期望的物体），但给出非笛卡尔活动的建议（例如做数学或质疑立场）；</li><li>不是关于心理状态（例如痛苦或平静），而是关于心理过程（例如考虑问题的各个方面；不合理化；同理心）或属性（例如认真、小心或不怨恨）；</li><li>不是关于以过程为对象的意义上的心理过程（例如“重新编程自己”，如抑制情绪，或停止任何提及某些主题的想法），而是关于自然化意义上的心理过程，即自我-参考性的，因此想要的东西是关于它自己想要的（例如，根据适用于其自身应用的绝对命令来决定，说应用绝对命令的这种或那种方式可以或不可以被愿意）一种普遍遵循的应用方式；或者<a href="https://www.lesswrong.com/tag/functional-decision-theory">FDT</a>的自我认可精神；或者不想强迫自己变得友善，因为[进行强迫的事物]不被信任，并且在强迫时更不被信任并且是不友善的）；</li><li>关于自己的需求（例如，想要被人们所吸引，无论他们的外表如何；想要对健康食品有胃口；不想对社交媒体有胃口；想要你的朋友想要什么；想要你的领导想要什么或者主人想要你想要的东西；想要解决想要的冲突或模糊性的过程，或者想要选择或<a href="https://tsvibt.blogspot.com/2022/11/do-humans-derive-values-from-fictitious.html">构建想要的东西</a>，或者想要想要其他人想要的东西（例如模仿领导者））；</li><li>认可（想去攀岩并且想要去攀岩），或未认可（想要避免与人交谈，但不想想要避免与人交谈）；</li><li>不是为了事物<em>本身</em>（事物、状态或过程，无论是否是精神上的）而关注事物，而是为了它如何影响其他事物而关注事物（例如，关心篮球离开手时的速度，为了稍后球穿过篮筐），其他的东西可能是未指定的（例如：像支持议会制度这样的过程价值观，以便预算分配将用于一些尚未指定的好事；象征性的诸如挥舞旗帜或建造纪念碑等价值观，以影响未来特工的协调点）；</li><li>适合为了自身的利益而追求自己（例如，有趣的舞蹈），或者适合为了另一种需要<a href="https://tsvibt.blogspot.com/2022/12/possibilizing-vs-actualizing.html">而实现可能性</a>（例如，为了能够锤击东西而想要制作一把锤子）；</li><li>类似代理人的（例如，选择居住的城市、存钱搬家、在那里找工作、申请居留权、购买汽车），或不类似代理人的（例如，类似冲动，如渴望巧克力；或反射性，如需要打喷嚏；或机会主义，如在店员分心时偷走一包口香糖；或混乱，如炼金术技术人员建立一套方法和设备，这些方法和设备在尚未实现的情况下<a href="https://tsvibt.blogspot.com/2022/12/possibilizing-vs-actualizing.html">具有</a>很大的可能性实施任何总体计划）；</li><li>纯粹的渴望等待机会展示自己，或者积极的追求，递归到无限丰富的搜索（例如弗朗西斯·培根）；</li><li>能够胜任（做正确的事情）和有效（成功），或者不胜任和无效地追求；</li><li>通过一系列狭窄的优化渠道（例如，试图通过下客观最合理的棋步来赢得国际象棋比赛）或广泛的优化渠道（例如，试图通过预测对手的盲点、贿赂对手、伪造对手配偶发出的求救信号，通过给对手注射镇静剂，通过侵入运行游戏的计算机系统来设置获胜者的变量，通过开展社交媒体活动来赢得民众支持，宣布你是获胜者，通过内部心理科学找出如何更好地思考如何接管地球并迫使法官宣布你是获胜者，通过建造一个信标来召唤外星人到你的位置，通过预先承诺进行许多祖先模拟，其中国际象棋的规则总是秘密地与表面上的不同，这样你就处于获胜的位置）；</li><li>应该是关于具有最终规范意义的<a href="https://tsvibt.blogspot.com/2022/08/the-thingness-of-things.html">事物</a>（例如想要理解代数拓扑），或者不应该是关于事物（例如想要感到快乐）；</li><li><a href="https://tsvibt.blogspot.com/2023/03/provisionality.html">临时的</a>（适当地视为可以修改）或非临时的；</li><li>是否被视为临时的；</li><li>是否接受外部修正；</li><li>自我放大和权力追求，或者自我限制和恭顺；</li><li>自我认可，如<a href="https://arbital.com/p/preference_stability/">甘地反对人们被谋杀的倾向</a>；或自我否定，如反模因；</li><li>冲突、支配、毁灭；</li><li>多路复用（因此人类追求食物，然后追求庇护所，作为相互放弃控制的独立模式），或<a href="https://arbital.com/p/hard_corrigibility/">分离主义</a>（因此人类在特定时刻将自己视为过去和未来整体自我的代表，并且知道过于强烈地追求当前的追求是好心，而践踏其他价值观并将当前追求的价值观作为唯一标准则是不好的）；或总体化（如在独裁联盟中，或在对自我形象、科学问题或冥想的病态痴迷中，或在煤气灯式滥用者中，打破了可能威胁到价值框架的其他观点）；</li><li>多重或单一（就像有人权衡和比较了自己的所有价值观，在它们之间进行权衡并消除不一致之处）；</li><li>真实的（例如真的喜欢爵士乐）或不真实的（也就是说，所追求的并不是真正想要的；例如虚假的，如假装喜欢某人或声称关心饥饿的人；姑息性的，如异<a href="https://en.wikipedia.org/wiki/Pica_(disorder)">食癖</a>；古德哈廷，如吃糖果；迷信，如蛇怪，或通过“相信”计划会成功来激励自己）；</li><li>另一方面，如果我们得到了它，我们会感到失望（例如，一只狗追上了汽车；一个孩子得到了一个新玩具，但一分钟后就把它扔到一边；踩到比邻星 b 可能两者都有很大的象征价值，但实际上并没有什么用处或乐趣）；</li><li>能够渡过本体论危机（例如，关心意识应该渡过向在硅上运行的上传的过渡，而不是在湿神经元上运行的自然人），或者无法渡过本体论危机（例如，建立过去被称为上帝的共同价值观的过程）已经死了，几乎没有什么可以替代的）。</li></ul><h1>人类需求的作用</h1><p>人类的需求在 AGI 调整中扮演着两个角色：</p><h2>人类的“想要”是一个推测性概念的网络</h2><blockquote><p>我们对人类需求的熟悉表明了对可能有助于描述和设计 AGI 的概念的假设。</p></blockquote><p>如果不进行进一步的分析，我们对人类需求的熟悉程度就不能过分依赖。我们可能会观察另一个头脑中的行为，然后说“这个头脑想要这样那样”，然后从该陈述中得出结论——但这些结论可能不会从观察中得出，即使如果这个头脑是人类的话，它们也会得出结论。人类想要 X 所带来的理想属性可能不会与设计、激励、选择、行为或任何其他特征一起出现，即使该特征确实在某些方面与我们熟悉的想要的想法重叠。</p><p>人类的需求表现出多种多样，一般来说并不反对使用任何其他需求概念。我们熟悉的关于人类需求的想法，以及我们关于需求的更理论化的想法，都可能被证明是有用的<a href="https://tsvibt.blogspot.com/2023/09/a-hermeneutic-net-for-agency.html#a-basic-analytic-method">起始想法</a>，用于创造具有<a href="https://tsvibt.blogspot.com/2022/11/descriptive-vs-specifiable-values.html">特定</a><a href="https://tsvibt.blogspot.com/2023/04/fundamental-question-what-determines.html">效果</a>的<a href="https://tsvibt.blogspot.com/2022/10/counting-down-vs-counting-up-coherence.html">有能力的</a>头脑。</p><h2>人类的需求是统一 AGI 的一半</h2><blockquote><p>AGI 应该帮助实现人类的需求，因此 AGI+人类系统必须满足人类的需求。</p></blockquote><p>人类的需求是预谋的、模棱两可的、过程层面的、不明确的，等等。人类的需求是<a href="https://tsvibt.blogspot.com/2023/03/provisionality.html">暂时的</a>。因为人类的需求是暂时的，所以通用人工智能必须是可纠正的（可纠正的）。 AGI必须是彻底可纠正的，在各个方面（因为所有方面都涉及AGI+人类想要的方式），甚至到了<a href="https://en.wikipedia.org/wiki/Paradox_of_tolerance">容忍悖论的</a>地步——人类可能会以这样的方式纠正AGI： AGI 认为这破坏了 AGI 的可纠正性质，应该允许（带警告）。</p><br/><br/><a href="https://www.lesswrong.com/posts/YLRPhvgN4uZ6LCLxw/human-wanting#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/YLRPhvgN4uZ6LCLxw/ human-wanting<guid ispermalink="false"> YLRPhvgN4uZ6LCLxw</guid><dc:creator><![CDATA[TsviBT]]></dc:creator><pubDate> Tue, 24 Oct 2023 01:05:39 GMT</pubDate></item></channel></rss>