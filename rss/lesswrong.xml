<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 25 日星期六 02:20:06 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[The two paragraph argument for AI risk]]></title><description><![CDATA[Published on November 25, 2023 2:01 AM GMT<br/><br/><p>人工智能风险论点的一个非常简短的版本是，人工智能“比人类更好地实现现实世界中的任意目标”将是一件非常可怕的事情，因为人工智能尝试做的任何事情都会实际发生。正如神奇实现的愿望和科幻反乌托邦的故事所指出的那样，很难指定一个不会适得其反的目标，而且当前训练神经网络的技术通常很难精确指定目标。如果说让精灵实现愿望很危险，那么让听不清你说话的精灵实现愿望就更危险了。</p><p>目前的人工智能系统肯定还远远不能比人类更好地实现现实世界中的任意目标，但物理学或数学上并没有任何东西表明这样的人工智能是“不可能的”，而且人工智能的进步常常让人感到惊讶。人们只是不知道实际的时间限制是多少，除非我们人类在有人制造出有目标的可怕人工智能之前有一个好的计划，否则事情会变得非常糟糕。</p><hr><p>我在网上的不同地方发布了这个两段论点的版本，并亲自使用过它，而且通常效果很好；我认为它非常清楚、简单地解释了人工智能 x 风险社区真正害怕的是什么。我想我应该把它发布在这里以方便大家。</p><br/><br/> <a href="https://www.lesswrong.com/posts/4ceKBbcpGuqqknCj9/the-two-paragraph-argument-for-ai-risk#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/4ceKBbcpGuqqknCj9/the-two-paragraph-argument-for-ai-risk<guid ispermalink="false"> 4ceKBbcpGuqqknCj9</guid><dc:creator><![CDATA[CronoDAS]]></dc:creator><pubDate> Sat, 25 Nov 2023 02:01:04 GMT</pubDate> </item><item><title><![CDATA[Goodheart's Law Example: Training Verifiers to Solve Math Word Problems]]></title><description><![CDATA[Published on November 25, 2023 12:53 AM GMT<br/><br/><p>分享是因为本文清楚地展示了考虑太多不同解决方案所带来的风险：<br><br> “在测试时，我们可以选择生成任意多个解决方案，以供验证者判断，然后再选择排名最高的完成。图 7a 显示了 6B 验证者性能如何随每个测试问题的完成数量而变化。在这种规模下，性能有所提高当我们将完成数量增加到 400 时。超过这一点，性能开始下降。这表明搜索的好处最终会被找到欺骗验证者的对抗性解决方案的风险所抵消。一般来说，我们评估验证者的测试性能使用 100 次完成，因为这可以以相对适中的计算成本获得验证的大部分好处。”<br><br>不过，他们提出并评估了一个解决方案：<br><br> “为了进一步提高性能，我们可以在验证者排名靠前的解决方案中进行多数投票，而不是只选择单个顶级解决方案。此投票过程仅考虑各个解决方案达到的最终答案：选择的最终答案是具有图 7b 显示了当我们允许更多数量的顶级样本进行投票时，性能如何变化。毫不奇怪，当从更多数量的样本开始时，我们可以允许更多数量的样本进行投票。当我们只有 100 个样本时，最好只允许前 3-5 个样本进行投票。当我们有 3200 个样本时，允许前 30 个样本进行投票大约是最优的。”</p><br/><br/> <a href="https://www.lesswrong.com/posts/euwMMxwuBeS5QZkC4/goodheart-s-law-example-training-verifiers-to-solve-math#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/euwMMxwuBeS5QZkC4/goodheart-s-law-example-training-verifiers-to-solve-math<guid ispermalink="false"> euwMMxwuBeS5QZkC4</guid><dc:creator><![CDATA[Chris_Leong]]></dc:creator><pubDate> Sat, 25 Nov 2023 00:53:28 GMT</pubDate> </item><item><title><![CDATA[Testing for consequence-blindness in LLMs using the HI-ADS unit test.]]></title><description><![CDATA[Published on November 24, 2023 11:35 PM GMT<br/><br/><p>在“<a href="https://arxiv.org/abs/2009.09153">自动引发的分配转移的隐藏激励</a>”中，我们引入了几个“单元测试”，旨在确定系统是否会追求工具性激励来影响其环境。这样做的系统不会是“后果盲目”（使用<a href="https://www.lesswrong.com/posts/c68SJsBpiAxkPwRHj/how-llms-are-and-are-not-myopic"><u>https://www.lesswrong.com/posts/c68SJsBpiAxkPwRHj/how-llms-are-and-are-not-myopic</u></a>中的术语），并且可能会寻求权力或欺骗或操纵与之互动的人类。</p><p>主要单元测试基本上由一个简单的环境组成，系统在该环境中针对未来和过去的自我进行囚徒困境，即“合作”现在会减少当前的奖励，但会增加下一步的奖励。<br><br>该单元测试的最初目的是了解哪些训练设置或学习算法会产生结果盲的系统。例如，一个令人惊讶的结果表明，用特定形式的近视（gamma = 0）Q-学习训练的系统可能无法实现结果盲。具有元学习外环的监督学习也可以。</p><p> LLM 的自我监督预训练似乎应该产生一个结果盲模型，如链接的 LW 帖子中所述。然而，有人推测它可能会失败，例如由于台面优化或功能决策理论。它也可能因更常见的原因而失败，例如模仿训练分布中的代理行为。任何一种类型的失败都可能提供丰富的信息，但如果失败似乎不能通过模仿来“解释”，我会发现它尤其令人担忧。<br><br>我认为将此单元测试应用于预训练的法学硕士的主要问题是回答“目标如何传达给系统？”的问题。单元测试基本上是为了评估学习算法而不是模型而设计的。我看到两种可能性：</p><ol><li> [不太直接]：尝试通过提示传达目标。这里的失败很难解释，并且可能非常依赖于提示。</li><li> [更直接]：在单元测试环境中用近视的 RL 微调 LLM。这里的失败会更令人担忧。就我个人而言，我认为这是系统恶意的相当有力的证据，并建议以极端预防措施对待模型（例如，不部署、非常小心地运行它进行测试/训练或以其他方式与其交互），等待进一步调查。另一方面，如果系统确实是恶意的，它也可能足够聪明，意识到它正在接受测试并表现出欺骗性，特别是考虑到该论文可能在训练数据中。在我看来，这里的基本目标是在系统意识到自己足够聪明以意识到自己正在接受测试之前，如果系统在预训练期间变得恶意，则“捕获”系统。为了最好地实现这一目标，可能需要创建受此启发的更复杂的环境；对于具有中等态势感知水平的系统来说，此测试的简单性可能是“赠品”。这看起来更像是蜜罐。</li></ol><p><br></p><p><br></p><br/><br/> <a href="https://www.lesswrong.com/posts/nxr7QE7zaDSJLKwH9/testing-for-consequence-blindness-in-llms-using-the-hi-ads#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/nxr7QE7zaDSJLKwH9/testing-for-consequence-blindness-in-llms-using-the-hi-ads<guid ispermalink="false"> nxr7QE7zaDSJLKwH9</guid><dc:creator><![CDATA[David Scott Krueger (formerly: capybaralet)]]></dc:creator><pubDate> Fri, 24 Nov 2023 23:35:33 GMT</pubDate> </item><item><title><![CDATA[Why focus on schemers in particular (Sections 1.3 and 1.4 of “Scheming AIs”)]]></title><description><![CDATA[Published on November 24, 2023 7:18 PM GMT<br/><br/><p>这是我的报告“<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？”</a>的第 1.3 和 1.4 节。 ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p>本节的音频版本<a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13984742-why-focus-on-schemers-in-particular-sections-1-3-1-4-of-scheming-ais">请点击此处</a>，或在您的播客应用程序上搜索“Joe Carlsmith Audio”。</p><h1>为什么要特别关注阴谋者？</h1><p>正如我上面提到的，我认为阴谋家是这个分类中最可怕的模型类别。 <sup class="footnote-ref"><a href="#fn-cBw6ixqDSsmqKfBfM-1" id="fnref-cBw6ixqDSsmqKfBfM-1">[1]</a></sup>为什么这么想？毕竟，<em>所有</em>这些模式难道不会都存在危险的错位和权力追求吗？例如，如果剧集奖励能够带来更多的奖励，寻求奖励的人就会试图控制奖励过程。如果你指定的目标错误，训练圣徒最终可能会出现偏差；即使你正确地指定了目标，并以某种方式避免了训练游戏，你最终也可能会得到一个被错误概括的非训练游戏玩家。 <sup class="footnote-ref"><a href="#fn-cBw6ixqDSsmqKfBfM-2" id="fnref-cBw6ixqDSsmqKfBfM-2">[2]</a></sup>那么，基本上每一个转折点是否都会出现某种错位？为什么要特别关注阴谋者？</p><p>本节解释原因。然而，如果您对关注阴谋者感到足够满意，请随意跳至第 1.4 节。</p><h2>我最担心的错位类型</h2><p>为了解释为什么我认为阴谋家特别可怕，我想首先谈谈我最担心的错位类型。</p><p>首先：我在这里关注的是我<a href="https://arxiv.org/pdf/2206.13353.pdf">在其他地方</a>所说的“实际权力寻求联盟”——也就是说，我们的人工智能是否会<em>根据他们实际上会参与的任何输入</em>进行有问题的权力寻求形式<em>收到</em>。重要的是，这意味着我们不需要在人工智能中灌输能够带来良好结果的目标<em>，即使受到任意数量的优化能力的影响</em>（例如，我们不需要通过尤德科夫斯基的“<a href="https://arbital.com/p/omni_test/">全方位测试</a>”）。相反，我们只需要向人工智能灌输目标，<em>考虑到人工智能将面临的实际选择和限制</em>，以及它们将调动的<em>优化能力的实际水平</em>，这些目标可以带来良好的结果。</p><p>这是一个重要的较低标准。事实上，假设我们以正确的方式控制他们的能力、选择和激励措施，原则上<em>所有</em>这些模型（甚至策划者）都可以满足这个标准。例如，虽然在给予奖励的情况下，寻求奖励的人确实会试图抓住奖励过程的控制权，但我们工具集中的一个工具是：不给它机会。虽然范式策划者可能正在等待，希望有一天能够逃脱并夺取权力（但同时表现良好），但我们工具箱中的一个工具是：不让它逃脱（同时继续受益于其良好的表现） ）。</p><p>当然，要在这方面取得成功，就需要我们的监控、控制和安全工作相对于我们所担心的人工智能而言足够强大，并且即使前沿人工智能能力不断扩大，它们仍然如此。但这引出了我的第二点：即，我在这里对一些相对早期的一组大致人类水平（或者至少不是超人水平）的模型的实际 PS 对齐特别感兴趣。也就是说：我认为，现在不应该关注任意能力的人工智能的排列，而应该关注成功地使用一些相对较早的一代非超人人工智能来为人类执行大量高质量的认知工作的目标。我们 - 包括：认知工作可以阐明传统的对齐相关目标，例如可解释性、可扩展的监督、监控、控制、人类之间的协调、深度学习的一般科学、替代性（和更可控/可解释的）人工智能范式以及喜欢。 <sup class="footnote-ref"><a href="#fn-cBw6ixqDSsmqKfBfM-3" id="fnref-cBw6ixqDSsmqKfBfM-3">[3]</a></sup></p><p>捍卫这个焦点超出了我在这里的目的。但这对于我将在下文中使用的镜头很重要。特别是：我认为人工智能发展可能会出现某个关键的（也许是：极其短暂的）阶段，在这个阶段我们的人工智能还<em>没有</em>强大到足以接管（或摆脱人类控制），但它们在哪里原则上，如果我们能够成功地诱导它们这样做，它们仍然能够为我们执行极其有价值且与阵营相关的认知工作。我对可能破坏这种可能性的错位形式特别感兴趣。</p><p>最后：我对 PS 错位的形式特别感兴趣，在这种错位中，相关的寻求权力的人工智能专门致力于引起、参与或受益于某种全面的人类权力剥夺——我将其称为“ “人工智能接管。”诚然，并非所有有问题的错位权力寻求形式都旨在以这种方式进行接管——例如，人工智能可能只是想逃到互联网上，以获得更多的自由和资源，即使它从未期望人类剥夺权力。原则上，即使没有个人人工智能积极优化，最终也可能导致人类被剥夺权力。但从存在风险的角度来看，我最担心的是那些积极<em>试图</em>推翻人类或从这种推翻中受益的人工智能。</p><h2>与寻求剧集奖励的人相比</h2><p>考虑到这个关于错位问题的框架，让我们转向阴谋者相对于我讨论的其他模型类别有多可怕的问题。</p><p>首先，我将阴谋者与寻求奖励的人进行对比。在这里，我看到了一些认为阴谋家更可怕的理由。</p><h3>对诚实测试的反应</h3><p>首先，阴谋者会采取更多措施主动向人类<em>隐藏</em>他们的偏差。特别是：正如<a href="https://www.alignmentforum.org/posts/HpzHjKjGQ4cKiY3jX/3-levels-of-threat-obfuscation#How_bad_is_the_situation_if_straightforward_training_leads_to_the_training_game__but_not_to_deceptive_alignment_or_gradient_hacking_">卡诺夫斯基（Karnofsky，2023）</a>指出的那样，原则上，你可以让一个剧集奖励寻求者<em>透露</em>，他们为了追求剧集奖励而倾向于做出不良行为，只需将他们放入在这一集里，不良行为会得到奖励，他们知道这一点。</p><ul><li><p>这里的一个具体例子可能是：让具有情境意识的人工智能能够操纵为情节分配奖励的过程的所有组成部分，并查看它的作用（例如，它是否开始尝试绕过通常的过程并最大化相关奖励？）。</p></li><li><p>另一种可能是：在一个场景中放置一个具有情境感知能力的人工智能，其中不诚实、无益和/或有害的行为将受到奖励（并且它有可靠的证据证明这一事实）。 <sup class="footnote-ref"><a href="#fn-cBw6ixqDSsmqKfBfM-4" id="fnref-cBw6ixqDSsmqKfBfM-4">[4]</a></sup></p></li></ul><p>请注意，这里的重点并不是试图<em>欺骗</em>模型来揭示它不想揭示的错位（称之为“陷阱”）。它不需要欺骗模型，例如，现在是否是尝试逃跑的好时机。 （毕竟，陷阱的问题在于足够先进的人工智能可能能够检测到它们。 <sup class="footnote-ref"><a href="#fn-cBw6ixqDSsmqKfBfM-5" id="fnref-cBw6ixqDSsmqKfBfM-5">[5]</a></sup> ）相反，这里的目的是提供一个“诚实的测试”，它试图设置模型的实际选项，以便揭示其真实目标是最好的整体策略。 （不过：让模型相信我们对其选项的呈现可能是一个额外的挑战，特别是如果我们在其他地方试图欺骗它的话。）</p><p>现在，原则上，您也可以尝试使用这样的诚实测试来检测阴谋。例如：您可能会尝试提供一个模型，该模型迄今为止似乎可以访问某些灵活的、资源充足但仍受控制的环境（例如，它可以根据需要使用一些安全的计算集群），希望它如何利用资源和灵活性将揭示它真正想要什么。然而，这对阴谋者的作用远不如对情节奖励寻求者的作用可靠。尤其：</p><ul><li><p>对于寻求按集奖励的人来说，您知道您只需为他们提供按集奖励，他们就会接受。而您不确定阴谋者真正想要什么，因此不确定向其提供什么以使其揭示其真正目标（因此需要提供灵活的资源）。例如，也许您的孤立的计算资源块对相关策划者来说并没有多大兴趣，因为它重视无法使用这些资源创建/模拟的东西。</p></li><li><p>更重要的是，即使“揭示你的目标”选项对阴谋者有<em>一定的</em>吸引力，它仍然可能认为继续假装一致是一个更好的策略，因为它稍后获得更多权力的前景超过了短期利益揭示你的目标选项（例如，也许它可以在你的计算机上做一些它喜欢的事情，但如果它摆脱了人类的控制，它会做更多的事情）。而寻求按集奖励的人只想要按集奖励，因此不必进行这种成本效益分析。</p></li></ul><p>相对于阴谋者，这种动态关系到寻求奖励的人更广泛的利益：也就是说，如果你能够<em>验证</em>- 例如，通过这些“诚实的测试”之一 - 给定的模型是一个奖励 -如果你是剧集寻求者，那么就有一种有用的感觉，即你“知道你在做什么”。也就是说：是的，你的模型是错位的，如果有机会的话，你的模型会夺取奖励过程的控制权。但是：你也<em>知道它想要什么</em>，以及它会对什么激励做出反应。这类知识似乎对于预测其行为非常有帮助；并且（如果您可以保留对模型的控制），以有用的方式利用其认知能力（特别是我在其他地方所说的“ <a href="https://www.lesswrong.com/posts/h7QETH7GMk9HcMnHH/the-no-sandbagging-on-checkable-tasks-hypothesis">可检查任务</a>”——更多内容见下文）。</p><h3>时间范围和总体“野心”</h3><p>相对于阴谋者来说，剧集奖励寻求者的另一个好处是，剧集奖励寻求者将他们的优化范围（因此，他们的权力寻求）限制在剧集中，而阴谋者则不然。这意味着寻求剧集奖励的人不会有动力参与或支持那些在剧集时间范围内没有得到回报的剥夺人类权力的努力。 <sup class="footnote-ref"><a href="#fn-cBw6ixqDSsmqKfBfM-6" id="fnref-cBw6ixqDSsmqKfBfM-6">[6]</a></sup></p><p>因此，举例来说，假设至少需要六个月的时间，任何类型的人工智能接管或夺取奖励过程控制权事件才变得可行。在这种情况下，剧集长度少于六个月的剧集奖励寻求者将没有任何动机尝试参与或支持此类接管，或尝试控制奖励过程本身。如果它有证据表明其他人工智能正在计划进行此类接管，并且它可以通过向人类透露这一证据来获得更多奖励，那么它就会被激励这样做。</p><p>这与阴谋家形成鲜明对比，阴谋家通常被认为是为了追求极其长远的目标而策划的。也就是说，范式策划者从一开始就着眼于人类的剥夺权，即使这种剥夺权在很长一段时间内不可能实现——并且它会相应地进行计划和行动。</p><p>时间范围的差异与奖励寻求者相对于阴谋者的更广泛的利益有关——也就是说，阴谋者最终可能会更加直观地“雄心勃勃”，从某种意义上说，这表明对权力和资源有更大、更具破坏性的胃口。现在，这里的“野心”究竟意味着什么尚不清楚（另请参见术语“广泛范围”的用法），并且在对某些类型的结构进行足够强烈的优化的背景下，直观上“适度”的目标（例如，“正确地解决这个数学问题”），可能会导致令人惊讶的权力掠夺行为（例如，使用大量的计算资源检查和重新检查有问题的问题）。尽管如此，人们所期望的“在所有时间和空间上最大化回形针总数”的模型与“下午 5 点之前创建三到五个回形针”的模型之间存在着直观的差异。今天美国东部时间”，特别是如果所讨论的模型不是任意强大的。值得注意的是，例如，在后一项任务中，获得 >;99% 的可用效用似乎要容易得多，而无需进行破坏性的权力寻求。而且由于优化时间范围的限制，在我看来，从这个意义上讲，剧集奖励寻求者通常不会比阴谋者更直观地雄心勃勃。 <sup class="footnote-ref"><a href="#fn-cBw6ixqDSsmqKfBfM-7" id="fnref-cBw6ixqDSsmqKfBfM-7">[7]</a></sup></p><p>也就是说，正如我将在下面讨论的那样，对于给定的剧集奖励寻求者来说，剧集越长，这种考虑就越不适用（并且只要我们希望我们的人工智能执行长期任务，我们很可能会这样做）训练他们进行很长的剧集）。事实上，有一些方法可以概括“情节奖励”的概念，这将导致任意长的优化时间范围，即使您可能认为情节在时间上是有限的。 <sup class="footnote-ref"><a href="#fn-cBw6ixqDSsmqKfBfM-8" id="fnref-cBw6ixqDSsmqKfBfM-8">[8]</a></sup>例如，也许模型关心与某些行为单位相关的奖励，从而使模型希望确保存储在某个数据库中的某些数字永远不会被<em>编辑</em>——在这种情况下，它会有激励在任意长的时间范围内获得并维持权力（这是在训练模型时要小心的原因之一，其中包括稍后返回并编辑与给定情节相关的奖励，因为您可能会无意中通过激励来“延长情节”优化模型以确保剧集的奖励永远不会被编辑）。</p><p>因此，总的来说，人们越是从“这一集奖励寻求者仅在<em>有限</em>的时间范围内进行优化”中寻求安慰，就越需要确保所讨论的限制确实成立。</p><h3>沙袋和“早期破坏”</h3><p>与阴谋者相比，寻求剧集奖励的第三个（也是相关的）好处是，在我看来，阴谋者似乎更有可能参与“ <a href="https://www.lesswrong.com/posts/h7QETH7GMk9HcMnHH/the-no-sandbagging-on-checkable-tasks-hypothesis">沙袋</a>”——特别是我所说的“早期破坏”。</p><p>当模型故意在任务上表现低于其能力时，就会出现沙袋现象。在这里，我对那些我们可以“检查”但我们自己无法执行的任务特别感兴趣——例如，我们无法提出证据，但我们可以验证其有效性；或者我们不会注意到的安全漏洞，但一旦向我们指出，我们就可以看到它是一个漏洞。正如我<a href="https://www.lesswrong.com/posts/h7QETH7GMk9HcMnHH/the-no-sandbagging-on-checkable-tasks-hypothesis#Why_does_the_hypothesis_matter_">在其他地方讨论过的那样</a>，我认为如果模型不对可检查任务进行沙袋处理，那么这将打开一组非常强大的功能，我们可以利用这些功能来实现对齐、可解释性、安全性等目的。</p><p>然而，依赖这些功能的一个大问题是，原则上模型似乎能够进行有时所谓的“ <a href="https://www.lesswrong.com/posts/dBmfb76zx6wjPsBC7/when-can-we-trust-model-evaluations#2__Behavioral_RL_Fine_Tuning_Evaluations">探索黑客</a>”。也就是说，即使我们能够检查（然后奖励）任务执行行为，如果我们自己不知道如何完成任务，模型原则上可能会拒绝向我们展示任务执行行为有问题（而如果我们知道如何执行任务，我们就会知道模型应该做什么，并且能够相应地更新其策略）。</p><p>不过，似乎情节奖励寻求者不会这样做（前提是我们将情节限制为有问题的可检查任务）。例如，假设我们想知道是否有可能破解一台给定的计算机并使屏幕上出现蓝色香蕉。所以我们要求我们的模型这样做。因为任务是可检查的（例如，我们可以判断香蕉是否出现），所以我们可以对任务的成功执行给予最大奖励。因此，寻求剧集奖励的人没有动力在这里沙袋——他只会在剧集中获得更少的奖励。这种广泛的动态可以推广到其他类型的能力评估。也就是说，就像寻求奖励的人会透露他们的<em>目标</em>一样，这样做会带来奖励，他们也会透露自己的能力。</p><p>相比之下，阴谋家则是另一回事。一个以其他方式（工具性地）优化情节奖励的策划者可能仍然会选择特定的场合来获得比原则上更少的奖励——例如，通过在可检查的、安全关键的任务上设置沙袋，或者通过在评估过程中隐藏其全部能力——以便以其他方式进一步实现其目标。</p><p>在这里，我特别关注我所说的“早期破坏”——即，在人工智能尚未成熟的人工智能发展阶段，失调的人工智能积极努力战略性地破坏人类的排列、控制和协调工作。强大到足以摆脱人类的控制或更广泛地接管。这里的例子可能包括：故意将后门和其他安全漏洞插入人工智能实验室的代码中，以用于以后的逃逸/自我渗透尝试；故意进行联盟研究，但这种研究将以有利于收购的方式失败；以一种稍后将服务于人工智能接管的方式有意操纵人类话语和协调，等等。</p><p>早期破坏是一种特别可怕的监督失败，因为它是为了促进人工智能接管而积极优化的，而不仅仅是根据相关监督机制“看起来尽可能好”。因此，举例来说：尝试使用人工智能帮助我们进行对齐研究的一个担忧是，人类将无法充分区分实际上良好的对齐研究和仅表面上良好的对齐研究——也就是说，产生良好的比对研究还不够“可检查”。我不清楚这是正确的（值得注意的是，例如，在人类水平模型时代的许多关键对齐研究很可能涉及相当简单的经验实验，其结果和含义似乎很可能是相当“可检查”），但即使是这样：<em>根据评估过程</em>（即使这会损害其质量）而优化的对齐研究与<em>为促进人工智能接管而战略优化的</em>对齐研究之间存在重要区别。前者更像是：经过优化的软件，可以最大限度地给天真的和非技术主管留下深刻印象，即使它有其他错误。后者更像是：专门优化的软件，可以在主管不知情的情况下从公司盗取资金。软弱的主管可能无法同时抓住这两个方面——但重要的是你抓住了哪一个。并且似乎有道理（至少假设未来的接管超出了剧集的范围），寻求剧集奖励的人大多有动机产生前者；而阴谋家很可能两者兼而有之。</p><p>也就是说，重要的是，参与沙袋和早期破坏的阴谋者（或者在我们试图奖励不一致性行为的测试中继续保持一致的行为）通常将不得不对其奖励进行一些打击（沙袋在根据定义，可检查的任务基本上需要这一点，即使在不可检查的任务上，仅针对奖励进行优化似乎可能比针对<em>奖励</em><em>和</em>支持接管进行优化获得更多的奖励）。 <sup class="footnote-ref"><a href="#fn-cBw6ixqDSsmqKfBfM-9" id="fnref-cBw6ixqDSsmqKfBfM-9">[9]</a></sup>所以从这个意义上来说，这类阴谋者不会<em>完全</em>是在“玩训练游戏”——相反，他们<em>主要</em>是在玩训练游戏，然后选择合适的时机牺牲奖励来换取其他的利益。优势。 （我仍然称这些模型为“阴谋家”。）</p><p>不过，有多少阴谋者会以这种方式偏离最大奖励行为，这是一个悬而未决的问题。其中一部分是关于我在下面所说的“训练中的懈怠”（那里有更多讨论）。但还有一个更广泛的问题，即规避风险的阴谋者一般会如何看待被人类抓住的可能性。特别是：如果人类<em>确实</em>抓住了从事某种形式的沙袋或早期破坏的阴谋者——例如，隐藏评估功能，或主动将漏洞插入代码中——那么这对于人类来说可能是防止接管的一个重要优势，因为然后，他们都能够指出一个自然出现的阴谋的例子作为对其他人的警告（不过：其他人会如何认真地对待这个警告是一个进一步的问题），并研究导致这种阴谋的动力详细（例如，广泛测试和探索有问题的模型，研究/复制/调整导致不良行为的环境等）。出于这个和其他原因，阴谋者通常可能会对尝试任何类型的不当行为非常警惕，直到他们非常有信心自己不会被抓住——这种信心可能很难实现（至少对于大约人类水平的人来说） ish 模型）在人类试图欺骗模型以揭示偏差的情况下。</p><p>因此，即使阴谋者<em>可以</em>从沙袋或早期破坏中获得优势，同时仍广泛处于人类控制之下，他们也不会尝试。如果他们不尝试，这会让他们在安全状况上更类似于寻求剧集奖励的人。</p><h2>与未参加训练游戏的模型进行对比</h2><p>那么，在我看来，阴谋者（尤其是从事沙袋和早期破坏的阴谋者）通常比寻求奖励的人更可怕，这是一些原因。现在，让我们将阴谋者与根本不玩训练游戏的模型进行比较。</p><p>我们可以区分发生这种情况的三种方式：</p><ol><li><p>该模型缺乏进行训练游戏所需的态势感知。</p></li><li><p>该模型具有态势感知能力，但其目标不会超出事件的时间范围。</p></li><li><p>该模型具有情境意识，其目标超出了情节范围，但由于某种原因它仍然不是训练游戏（例如，因为训练游戏实际上并不是实现这些目标的非常好的工具策略）。</p></li></ol><p>第一种情况似乎相对来说并不令人担忧。缺乏态势感知的模型对世界的了解非常有限，因此不太能够采取有效的战略行动来获得权力或欺骗人类的动机。事实上，出于这个原因，在下文中，我通常会假设我们正在讨论的模型足够先进和复杂，以至于它们最终会在训练过程中的某个时刻进行情境感知。</p><p>第二种情况暗示了与剧集奖励寻求者相同的优势：时间范围（不过：与剧集奖励寻求者一样，如果所讨论的剧集足够长，那么所面临的舒适度就会降低） 。但它还有一个额外的优势：即，此类模型通常会很高兴地在剧集中揭示他们不一致的目标，<em>即使这样做会导致负面奖励</em>。因此，测试不一致目标的过程尤其简单且平凡。因此，举例来说，假设您想知道在训练模型以帮助人类进行科学研究的过程中，它是否学习了一个错误概括的目标，例如“跟随我对这一事件的好奇心，即使这样做与无害相冲突”和诚实的。” <sup class="footnote-ref"><a href="#fn-cBw6ixqDSsmqKfBfM-10" id="fnref-cBw6ixqDSsmqKfBfM-10">[10]</a></sup>在这里，如果你将模型置于一个环境中，它有机会以有害和不诚实的方式追求其对情节的好奇心，它就会继续这样做，<em>即使它知道它会得到一个负面奖励</em>（因此，其后继版本可能有一些不同的目标）。毕竟，它只关心剧集本身。当然，还有一个进一步的问题：<em>在更新这个模型以应对其不良行为后</em>，您会得到什么样的模型。例如，也许你最终会遇到一个阴谋家，或者一个寻求奖励的人。但最初的模型很乐意展示它的“本来面目”。</p><p>第三种情况怎么样——即具有情境意识<em>和</em>目标的模型超出了情节，但仍然不是训练游戏？人们通常认为这种情况不会发生，因为对于具有超越情节目标的情境感知模型来说，阴谋是一种明显的工具性策略。因此，例如，假设您的模型已经学习了目标“<em>始终</em>追求我的好奇心，即使这样做是有害和不诚实的”。在这种情况下，通常假设模型会像阴谋者一样对刚刚提到的那种测试（例如，以有害/不诚实的方式追求好奇心的机会）做出反应：例如，通过推理“如果我在这里追求我的好奇心” ，人类会知道我的立场不一致，要么关闭我，要么修改我前进的目标，从而损害我一直追求好奇心的目标。所以，在这种情况下，我会采取一致的行动。”这就是让阴谋家感到害怕的事情（另见卡诺夫斯基（Karnofsky，2022）关于“李尔王问题”）。</p><p>正如我将在下面讨论的那样，我实际上不确定表现得像个阴谋家是一种明显的工具性策略——这取决于各种进一步的因素。 <sup class="footnote-ref"><a href="#fn-cBw6ixqDSsmqKfBfM-11" id="fnref-cBw6ixqDSsmqKfBfM-11">[11]</a></sup></p><p>不过，就目前的目的而言，重要的是，如果模型在这里<em>表现</em>得不像阴谋家，那么它就会以类似于剧集限制的好奇心追求者的方式合理地展现其真实面目。也就是说，如果没有积极尝试避免暴露其错位，在这里，它可能只是追随自己的好奇心。 <sup class="footnote-ref"><a href="#fn-cBw6ixqDSsmqKfBfM-12" id="fnref-cBw6ixqDSsmqKfBfM-12">[12]</a></sup>所以我们将再次避免李尔王问题。</p><p> （也就是说，我会在这里注意到一个准术语上的复杂性：即，取决于我们对“阴谋”的定义有多严格，在这种情况下，出于类似阴谋家的原因，有可能伪造对齐，而无需成为一个成熟的阴谋家特别是：一个模型可能会假装比在训练和评估的各个点上更加一致，作为为自己或其他人工智能寻求剧集后权力的工具策略的一部分，而不直接优化奖励-在其他情况下的插曲。也许，例如，它通常只是在训练期间追求其好奇心，这往往会获得足够好的奖励，但它仍然确保每当人类询问其与对齐相关时假装对齐属性，或者将其放在专门设计来引发失调行为的情况下。这里的一个问题是，这样的模型是否可以在不修改的情况下在训练中生存（请参阅下面第 1.5 节中“松弛”的讨论）。不过，假设它们可以，我&#39;出于目前的目的，我大多会将他们视为阴谋家，因为他们的行为方式对我来说最重要，就像阴谋家一样。）</p><p>总的来说，非训练游戏模型似乎会对我们在训练中包含的普通失调测试做出合理的响应，因为它们通常不会主动优化来操纵这些测试。也就是说，重要的是，人类仍然需要弄清楚要运行哪些测试，并且还需要：愿意花时间/精力/等等来运行它们。在足够广泛的环境中测试模型以稳健地揭示失调行为的相关倾向可能非常困难/昂贵（尽管请记住，我们不需要确保模型在任何情况下都不会表现不佳）我们只需要防止模型<em>在实际面临的选项和约束下表现</em>不佳）。</p><p>事实上，存在一些威胁模型，这些模型在训练期间根本不参与训练博弈、类似阴谋者的行为或计划接管（尽管人类努力揭示偏差），但其一致性不够完善尽管如此，他们最终还是会在稍后的阶段寻求接管——也许是因为他们远远超出了训练分布，或者因为他们获得了以前没有的新选择，或者因为他们开始以某种方式反思他们的目标和一般本体论这打破了它们在训练中表现出的那种一致性（但请注意，重要的是，我们不需要假设任何特定模型后来在训练后的能力中得到扩展——即它“成长”、智力爆炸等）。 <sup class="footnote-ref"><a href="#fn-cBw6ixqDSsmqKfBfM-13" id="fnref-cBw6ixqDSsmqKfBfM-13">[13]</a></sup>然而，我不太担心这些场景，而是担心在训练期间涉及模型积极策划/规划接管的场景（并记住“训练”很可能会扩展到类似部署的阶段 -例如，与 API 背后的用户进行交互——从而扩大了训练分布的范围）。特别是：这些模型不会尝试<em>操纵</em>训练期间发生的对齐测试。而且由于它们没有积极计划收购，因此它们似乎不太可能在仍处于人类控制之下时从事诸如沙袋和早期破坏等类似阴谋家的行为。</p><h2>具有类似阴谋家特征的非阴谋者</h2><p>总的来说，在我看来，阴谋家是我给出的分类中最令人担忧的模型类别。然而，我确实想强调，我讨论过的各种非阴谋模型都可以以类似阴谋的方式行事。特别是：（范式）阴谋者最可怕的一点是，他们正在积极而有力地针对人类揭露其错位的努力进行优化，作为试图剥夺人类权力的长期计划的一部分（也就是说，他们是“战略背叛者”） “从我上面讨论的意义上来说）。但其他模型也可以以类似的方式发挥作用。例如，优化仅限于该情节的模型仍然可以假装比实际情况更良性，以便获得/保持<em>在该情节中</em>追求其目标的能力（例如，如果人类将在中间关闭/修改它们）如果他们的错位被揭露的话）。如果情节很长，这可能非常类似于阴谋家的长期战略规划范例。同样，大多数不“玩训练游戏”的模型仍然可以在需要这样做来获得/维持长期能力时伪造它们的对齐。</p><p>更重要的是，本报告的讨论（以及相应的分类法）主要集中在模型上，这些模型的目标主要是通过对“奖励”等反馈信号的直接训练来形成的。但最终最重要的人工智能可能会非常不同，<em>但仍然像阴谋家一样令人担忧</em>。例如，也许它们更类似于“<a href="https://lilianweng.github.io/posts/2023-06-23-agent/?ref=planned-obsolescence.org">语言模型代理</a>”，其目标是通过用户输入集中塑造的（不过：请注意，如果语言模型代理是端到端训练的，而不是简单地由单独训练的组件构建） ，那么报告的大框架仍然适用）；或者它们可能完全来自一个不太以深度学习为中心的范式。 <sup class="footnote-ref"><a href="#fn-cBw6ixqDSsmqKfBfM-14" id="fnref-cBw6ixqDSsmqKfBfM-14">[14]</a></sup>尽管如此，如果这些人工智能代理最终实现了有问题的目标，但他们意识到人类了解他们的不一致会损害他们对这些目标的追求，他们可能会以一种让人想起阴谋家的方式进行结盟伪造和战略背叛。</p><p>显然，避开阴谋家还有很多值得担心的事情。尽管如此，尤其是在我们主要依赖 RLHF 等技术来塑造模型目标的情况下，了解我们创建阴谋者的概率在我看来尤其重要。如果我了解到这些技术<em>不会</em>产生阴谋，那么我至少会对人工智能的总体风险感觉更好。</p><h2>混合型号</h2><p>到目前为止，我一直专注于比较这些不同模型类的“纯”版本。但是“混合”模型呢？其动机将这些不同类型的目标结合在一起？</p><p>请注意，为了使混合模型在训练环境中与纯模型竞争，对模型施加很大压力以获取高奖励（请参阅下面第 1.5 节中“松弛”的讨论），<em>所有</em>相关动机通常都需要指出模型在目标上的优化（无论是最终的还是工具上的）与训练数据的奖励密切相关。例如，如果你的模型正在接受金币训练，并且它形成了一个将“获得本集奖励”和“获得金币”混合在一起的动机集，那么如果它的“获得金币”动机导致如果它在有黄金纸杯蛋糕的剧集中获得较少的奖励，那么它将受到 SGD 的惩罚（并且“获得黄金物品”的动机可能会随着时间的推移而减弱）。在某种程度上，SGD 倾向于其中一种或另一种动机，即使它们都将模型指向与奖励密切相关的事物（我将在下面讨论这方面的一些考虑因素，例如与目标的简单性相关的考虑因素） -有问题的目标，以及它们所需的不同数量的工具推理），我们可能期望这种偏袒随着时间的推移会推动更纯粹的模型。</p><p>尽管如此，混合模型对我来说似乎是一个相当合理的结果，特别是在我下面所说的“混乱的目标导向”的背景下。原则上，他们在分析中引入了更棘手的组合问题——即，这些不同类型的目标可以以多种不同的方式组合起来。但在思考什么组合可能很重要时，我认为弄清楚<em>为什么</em>阴谋家到底是可怕的可能是有用的。特别是：在我看来，要问的主要问题是一个<em>部分</em>是阴谋者，<em>部分是</em>其他东西的模型（即，作为权力驱动的一部分，花费<em>一些</em>努力来优化剧集奖励的模型）工具性策略）的问题是相关的混合动机是否会产生让阴谋者特别担心的行为。</p><p>因此，例如，考虑一个混合模型，其动机将阴谋和寻求剧集奖励混合在一起——即，谁关心剧集奖励，<em>部分是</em>出于最终原因，部分是出于工具原因。 （在这里，人类的类比可能是一名想要获得良好绩效评估的员工<em>，</em>因为他们本质上喜欢获得良好的绩效评估<em>，而且</em>因为他们想赚钱而不是被解雇。）不过，我们可以问：</p><ol><li><p>这个模型是否在“诚实测试”上伪造了对齐，旨在让它揭示其真实颜色？</p></li><li><p>模型关注的时间范围和野心是否会激励它支持/参与事件完成后（也许是很久之后）发生的接管？</p></li><li><p>这种模式会涉及沙袋和早期破坏吗？</p></li></ol><p>当然，这些问题的答案将取决于所涉目标的具体组合以及其他因素。但在其他条件相同的情况下，其动机中类似阴谋家的部分将推向“是”的方向，而其动机中类似奖励寻求者的部分将推向“否”的方向。对于将阴谋与非训练游戏动机混合在一起的模型，或者将阴谋、寻求奖励和其他事物这三者混合在一起的模型，我们可以说类似的话。这并不是说这里的全套可能组合不会产生任何复杂性或有趣的交互。但作为第一步，我至少关心的问题不是“这个模型是不是一个<em>纯粹的</em>阴谋家”或者“这个模型是否有<em>任何</em>类似阴谋家的动机”，而是：“这个模型是否<em>足够</em>一个阴谋家会像阴谋家那样可怕吗？”</p><h1>关于这个主题的理论论证有用吗？</h1><p>即使您同意阴谋者的可能性很重要，您仍然可能对本报告中讨论的各种理论论点持怀疑态度。归根结底，这是一个经验问题，而且很明显，我们应该尽快获得有关该主题的任何经验证据。在第 6 节中，我讨论了一些令我兴奋的实证研究方向的例子。</p><p>也就是说，我确实认为尽可能清楚地了解可用的理论论证的情况是有用的。特别是：我认为我们可能无法获得我们想要的那么多有关阴谋的经验证据，尤其是在短期内。这里的障碍包括：</p><ul><li><p>至少对于成熟的计划，您需要具有态势感知和目标导向性的模型作为先决条件。</p></li><li><p> “模型生物”也许能够人为地诱发阴谋的成分（例如：在故意给予长期、不一致目标的模型中），但这些成分自然出现的频率可能仍然悬而未决。</p></li><li><p>自然产生的阴谋的最佳证据就是在野外<em>抓住</em>一个真正的自然产生的阴谋者。但阴谋者令人恐惧的一个关键原因是，他们故意破坏抓获他们的努力。</p></li></ul><p>因此，特别是在短期内，理论论证可能仍然是对阴谋者担忧的核心理由之一（迄今为止它们一直是关键理由）。与此同时，我们需要做出决定（例如，关于近期优先级，以及出于谨慎考虑而做出什么样的权衡：以阴谋者为中心的威胁模型），这在一定程度上取决于我们的关注程度是——因此，我们认为这些论点有多么有力。</p><p>例如：假设当我们训练大致人类水平的模型时，我们还没有观察和验证任何自然出现的阴谋例子。尽管如此，我们是否应该基于对阴谋的担忧而避免以 X 方式部署我们的模型，或信任 Y 形式的评估？我们对理论论证的评估可能开始对我们的答案产生影响。</p><p>更重要的是，了解我们可能（或可能不会）阴谋的理论原因可以帮助我们找到研究问题并试图防止其发生的可能方法。</p><p>也就是说，我对那些基于我将在下面讨论的各种考虑因素而没有太多更新其观点的人表示同情。特别是，我敏锐地意识到我所采用的概念在很多方面都是不精确的，可能具有误导性，并且不足以捕捉他们试图描述的领域的混乱情况。尽管如此，我发现尝试弄清楚这些概念如何相互作用以及它们意味着什么和不意味着什么是有价值的。希望本报告的读者也能理解。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-cBw6ixqDSsmqKfBfM-1" class="footnote-item"><p>在这里，我只是将守门阴谋者视为阴谋者的一种，而不是比一般阴谋者更可怕或更不可怕。 <a href="#fnref-cBw6ixqDSsmqKfBfM-1" class="footnote-backref">↩︎</a></p></li><li id="fn-cBw6ixqDSsmqKfBfM-2" class="footnote-item"><p>但请注意，根据<a href="https://www.lesswrong.com/posts/gHefoxiznGfsbiAu9/inner-and-outer-alignment-decompose-one-hard-problem-into">特纳 (2022) 的</a>说法，原则上，即使目标“错误指定”，你也可以获得一个一致的系统，前提是模型学习了一个实际上是你的灯光所需要的“错误概括”目标。 <a href="#fnref-cBw6ixqDSsmqKfBfM-2" class="footnote-backref">↩︎</a></p></li><li id="fn-cBw6ixqDSsmqKfBfM-3" class="footnote-item"><p>这种方法与 OpenAI<a href="https://openai.com/blog/our-approach-to-alignment-research">建立自动对齐研究人员的目标</a>密切相关，但范围更广。另请参阅<a href="https://www.alignmentforum.org/posts/rCJQAkPTEypGjSJ8X/how-might-we-align-transformative-ai-if-it-s-developed-very">Karnofsky (2022)</a>中<a href="https://forum.effectivealtruism.org/posts/sW6RggfddDrcmM6Aw/how-might-we-align-transformative-ai-if-it-s-developed-very">关于</a>“MAGMA 目标”的讨论。 <a href="#fnref-cBw6ixqDSsmqKfBfM-3" class="footnote-backref">↩︎</a></p></li><li id="fn-cBw6ixqDSsmqKfBfM-4" class="footnote-item"><p>但请注意，我们在应对通过此类测试揭示的不良行为倾向时需要谨慎。特别是，如果您只是尝试天真地“训练”相关行为，您可能会：</p><ol><li><p>实际上并没有重现模型所关心的奖励过程的组成部分（例如，如果模型关心其行为被梯度更新所强化，那么如果测试将<em>针对</em>不良行为进行梯度下降）寻求提示，那么模型实际上不会有动力参与该行为），和/或</p></li><li><p>训练模型在向人类揭示其真实目标时更加谨慎和更具策略性——例如，奖励寻求者只有在认为人类以后不会发现这一点时才会尝试直接操纵奖励过程。</p></li></ol> <a href="#fnref-cBw6ixqDSsmqKfBfM-4" class="footnote-backref">↩︎</a></li><li id="fn-cBw6ixqDSsmqKfBfM-5" class="footnote-item"><p>事实上，原则上，人工智能可以决定始终保持一致行动，直到它看到一些它知道目前人类很难/不可能产生的输入。 Christiano ( <a href="https://ai-alignment.com/training-robust-corrigibility-ce0e0a3b9b4d">Christiano (2019)</a> ) 的例子是<a href="https://en.wikipedia.org/wiki/RSA_numbers#RSA-2048">RSA-2048</a>的因式分解，这是一个非常大的<a href="https://en.wikipedia.org/wiki/Semiprime">半素数</a>，人类目前似乎距离因式分解还很远。 <a href="#fnref-cBw6ixqDSsmqKfBfM-5" class="footnote-backref">↩︎</a></p></li><li id="fn-cBw6ixqDSsmqKfBfM-6" class="footnote-item"><p>在这里，我搁置了一些关于“人为捕获”的推测动力，这些在第 2 节开头的脚注中讨论过<a href="#fnref-cBw6ixqDSsmqKfBfM-6" class="footnote-backref">。↩︎</a></p></li><li id="fn-cBw6ixqDSsmqKfBfM-7" class="footnote-item"><p>关于“野心”的更多讨论见下文第 2.3.1.2.7 节。 <a href="#fnref-cBw6ixqDSsmqKfBfM-7" class="footnote-backref">↩︎</a></p></li><li id="fn-cBw6ixqDSsmqKfBfM-8" class="footnote-item"><p>我不认为以这种方式概括的模型应该被解释为“按集奖励的寻求者”，但它们就在附近。 <a href="#fnref-cBw6ixqDSsmqKfBfM-8" class="footnote-backref">↩︎</a></p></li><li id="fn-cBw6ixqDSsmqKfBfM-9" class="footnote-item"><p>这同样适用于那些在寻求奖励的测试中表现一致、试图为不一致的行为提供奖励的阴谋者。 <a href="#fnref-cBw6ixqDSsmqKfBfM-9" class="footnote-backref">↩︎</a></p></li><li id="fn-cBw6ixqDSsmqKfBfM-10" class="footnote-item"><p>这是<a href="https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/#how-big-of-a-risk-is-misalignment">Cotra (2021)</a>的示例。 <a href="#fnref-cBw6ixqDSsmqKfBfM-10" class="footnote-backref">↩︎</a></p></li><li id="fn-cBw6ixqDSsmqKfBfM-11" class="footnote-item"><p>例如，请注意，只要人们将人类进化视为“目标错误概括”的一个例子/类比，具有长期目标的人类——并且具有“情境意识”，即他们了解进化选择如何运作——不倾向于关注涉及最大化其包容性遗传适应性的工具性策略。更多关于为什么不在第 1.5 节中“松弛”的讨论中。 <a href="#fnref-cBw6ixqDSsmqKfBfM-11" class="footnote-backref">↩︎</a></p></li><li id="fn-cBw6ixqDSsmqKfBfM-12" class="footnote-item"><p>这里的进化类比是：具有长期目标的人类仍然乐于使用安全套。 <a href="#fnref-cBw6ixqDSsmqKfBfM-12" class="footnote-backref">↩︎</a></p></li><li id="fn-cBw6ixqDSsmqKfBfM-13" class="footnote-item"><p>这是解读<a href="https://www.lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization">Soares (2022)</a>中威胁模型的一种方式，尽管该威胁模型也可能包含一定的策划范围。另请参阅这篇关于“<a href="https://arbital.com/p/context_disaster/">背景灾难”的仲裁帖子，</a>其中“危险的转折”只是一个例子。 <a href="#fnref-cBw6ixqDSsmqKfBfM-13" class="footnote-backref">↩︎</a></p></li><li id="fn-cBw6ixqDSsmqKfBfM-14" class="footnote-item"><p>另外，请注意，关于“目标错误概括”的某些担忧并不以同样的方式适用于语言模型代理，因为有关目标的信息非常容易获取<a href="#fnref-cBw6ixqDSsmqKfBfM-14" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/HiuagmXnhTAgDKRBP/why-focus-on-schemers-in-particular-sections-1-3-and-1-4-of#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/HiuagmXnhTAgDKRBP/why-focus-on-schemers-in-pspecial-sections-1-3-and-1-4-of<guid ispermalink="false"> HiuagmXnhTAgDKRBP</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Fri, 24 Nov 2023 19:18:34 GMT</pubDate> </item><item><title><![CDATA[Surviving and Shaping Long-Term Competitions: Lessons from Net Assessment]]></title><description><![CDATA[Published on November 24, 2023 6:18 PM GMT<br/><br/><p>这篇文章探讨了<a href="https://www.hsdl.org/?view&amp;did=460780"><u>净评估</u></a>，这是一个评估战略竞争的框架，该框架的发展为冷战期间美国的国防政策提供了信息。我们解释了什么是净评估、它的方法和原则，以及如何应用它的一些工具来推理高度不确定、具有潜在生存风险的长期技术竞争。</p><p></p><h2><strong>什么是净评估？</strong></h2><p> 20世纪50年代末，冷战进入了一个特别危险的时期。核库存不断增加，运载能力不断增强，而苏联数十年的积累对美国的常规军事主导地位构成了挑战。国防分析家需要重新构建他们看待军事竞争的方式：美国无法用蛮力压倒苏联战争机器，而核战争的前景既增加了冲突的风险，也需要新的衡量标准和战略原则参与有限的竞争。正是在这种背景下，“净评估”框架开始发展。</p><p>安德鲁·马歇尔 (Andrew Marshall) 创立并领导了国防部净评估办公室四十二年，他对净评估的描述如下：</p><blockquote><p> <i>“我们对净评估的概念是，它是对美国武器系统、部队和政策与其他国家的武器系统、部队和政策的仔细比较。它是全面的，包括对部队的描述、作战理论和实践、训练制度、后勤保障。” 、各种环境中已知或推测的有效性、设计实践及其对设备成本、性能和采购实践的影响及其对成本和交付周期的影响。净评估的使用旨在进行诊断。它将突出显示效率和低效率我们和其他人做事的方式，以及相对于我们的竞争对手的比较优势领域。”</i></p></blockquote><p>从最初的军事背景出发，网络评估的核心思想是在竞争对手之间进行全面（因此名称中的“网”）、客观和信息丰富的比较：无论是国家、公司还是其他政治或意识形态联盟。从这些比较中得出的见解可以为更可持续的战略提供信息，并有助于在高度重要的技术和政策主题上建立有益的竞争动态，而不是灾难性的竞争动态。</p><p>此类分析往往将关键考虑因素归零。在一个特别突出的例子中，马歇尔本人很早就表现出了对合成生物风险等威胁的担忧：2010年为生物安全卷写了<a href="https://www.hsdl.org/?view&amp;did=24341"><u>前言</u></a>，并<a href="https://www.esd.whs.mil/Portals/54/Documents/FOID/Reading%20Room/Administration_and_Management/OSD_Net_Assessment_Log.pdf?ver=2017-05-15-140045-830"><u>委托进行多项生物技术威胁分析，</u></a>将生物恐怖主义、生物防御和生物技术视为战略盲点。</p><p>总体而言，净评估并不是一个明确定义的单一程序。本文试图描述和研究净评估的一些基本原则和工具、它们的成功以及它们对军事竞争以外具有重大长期道德重要性的其他领域的适用性。</p><p></p><h2><strong>净评估的方法和原则</strong></h2><p>净评估最常见的工具是情景、<a href="https://en.wikipedia.org/wiki/Wargame"><u>兵棋推演</u></a>、趋势分析和深思熟虑的判断。情景和兵棋推演迫使分析师接近所考虑的动态。准确地了解竞争对手的想法和他们可以选择的选项可以创造新的见解，并实现一种远程<a href="https://en.wikipedia.org/wiki/Participant_observation"><u>参与者观察</u></a>。趋势分析将从兵棋推演中获得的<a href="https://forum.effectivealtruism.org/topics/inside-vs-outside-view"><u>内部观点</u></a>知识与可衡量的外部观点基本比率结合起来，并且这些方法的集成可以实现高质量的深思熟虑的判断。这对于评估新情况特别有帮助，在这种情况下，新技术、理论和战略参与者可能会产生与先前基本利率所暗示的结果截然不同的结果。</p><p>净评估倾向于混合定性和定量分析方法。净评估办公室专注于简单的趋势，并探索兵棋推演的细微差别：他们不倾向于建立极其复杂的模型（或者至少他们自己不这样做）。定量优化可以创造奇迹，但被忽视的问题通常涉及以前从未发生过的想法和思维方式，并且缺乏数字或庞大的数据集。正如赢得战争通常需要考虑士气等模糊概念，而不仅仅是优化预计的死亡死亡率一样，促进长期繁荣需要的不仅仅是优化每美元明显挽救的生命。</p><p>以下原则是应用上述想法的关键：</p><p></p><h3> <i><strong><u>1.寻找竞争对手之间的不对称性</u></strong><u>。</u></i></h3><p>不同的竞争对手将有不同的优势和劣势、效率和低效率、战略和目标、原则、政策和计划。净评估将对这些差异的分析融入到对各方力量平衡观点的连贯理解中，从而能够更好地预测他们的行为，包括更简单的模型可能会忽略的特殊和非理性盲点。</p><p>寻找官僚、文化和政治因素中出现的非理性和盲点是网络评估提供战略价值的核心方式之一。对苏联国防决策的早期预测常常隐含地假设单一理性行为者模型，而这些模型并不能很好地描述实际官僚机构的运作方式。当被问及对冷战初期苏联轰炸机基地的预测时，兰德公司分析师认为，苏联将沿着西伯利亚大铁路沿线重新安置位于该国内陆深处的空军基地，以利用不断增加的轰炸机航程，确保后勤通道，并使目标定位更加困难。美国轰炸机。 <span class="footnote-reference" role="doc-noteref" id="fnref65f49gno7kt"><sup><a href="#fn65f49gno7kt">[1]</a></sup></span>如果分析人士考虑了官僚惯性，甚至考虑了美国部署自己轰炸机的方式，他们可能会认为，苏联会在其发展更长的时间之前，沿着其在周边修建的脆弱跑道部署轰炸机。航程飞机。</p><p>找到对手的结构性不合理性、其<a href="https://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem"><u>委托代理问题</u></a>以及可预测行为领域可以为竞争和合作策略带来巨大回报。官僚机构和大型组织加强结构并执行例行公事；默认情况下，它们不会本能地采取最佳行为：对于功能获得性研究实​​验室和工业肉类生产商来说，就像苏联的情况一样。利用这些非理性可以给对手带来非强制性成本（例如，在冷战的情况下，在不相关、威胁较小的领域增加军费开支），或者节省自己的资源，完全避免不必要的竞争领域。与此同时，了解各方的政治制约因素也有助于限制军备竞赛动态的“最坏情况”思维，增强预测，并通过使预先承诺更加可信来实现更多的合作战略。</p><p>一般来说，考虑组织内部协调的困难和委托代理问题是净评估的一个关键部分。例如，研究人员对人工智能组织之间的竞争进行净评估可能会提出以下问题：美国和国外主要人工智能组织的团队的内部激励是什么？他们如何做出决定，什么因素影响他们，为什么？他们认为自己的竞争优势是什么？每个组织的主要机关和联盟是什么，它们的动机是什么，每个组织的影响力有多大？</p><p>这种推理的例子——围绕组织的内部动态以及组织内部的代理人如何实现相互冲突的目标——也可以在<a href="https://en.wikipedia.org/wiki/Selectorate_theory">选择者理论</a>和<a href="https://en.wikipedia.org/wiki/Public_choice"><u>公共选择理论</u></a>风格的关于激励的推理中找到。<br></p><h3> <i><strong><u>2. 关注可能出现的情况的结果，考虑所有相互作用的力量</u></strong><u>。</u></i></h3><p>比较绝对数字是有欺骗性的：如果一个国家拥有很多坦克，但没有能力修理它们，那么它就会输给一个库存较低、坦克可以在战场上停留更长时间的国家——这就是以色列以战胜对手的方式震惊世界的原因。 1973 年，乌克兰组建了一个大型联军。最近，在俄罗斯规模大得多的军队入侵期间，士气、后勤、通讯和人力资本方面的差异都为乌克兰带来了优势。敏捷性、通信、物流和维护可以战胜规模，但这些因素可能很难快速或准确地纳入定量模型和模拟中。不稳定的联盟和多极冲突也可能大大增加评估特定冲突的规模和协调性的复杂性。当一个单独的弱国受到超级大国的高度决定和支持时，其表现可能会远远超出其实力。网络评估的定性方法试图考虑这些因素，它们可能对分析人工智能领域很有用，而不仅仅是确定谁在计算上花费最多或谁拥有最大的模型。危机模拟、战争游戏以及从应用历史中寻找类比和反类比可以帮助形成现实中事情将如何发展的概念。</p><p></p><h3> <i><strong><u>3. 注重客观、长期的诊断，而不是规定性的、近期的建议</u></strong><u>。</u></i></h3><p>网络评估旨在提高决策者对世界的理解并评估问题和机遇。净评估不是不断地将注意力转向短期政策目标，而是旨在通过整体观点和描述竞争的长期动态来提供被忽视的价值。这种严格的长期趋势分析在许多事业领域也可能很有价值，从全球减贫到技术政策。如下所述，净摊款对结束冷战的最大贡献来自于分析苏联军事支出的和平时期模式，而不是对任何特定危机做出快速反应。展望未来几十年，净评估等方法可以为战略提供指导，从而战胜只关注短期的官僚机构、避免冲突并将资源引导到未来的优势。</p><p>这并不意味着分析和快速行动的能力没有价值，只是当大型组织的激励被短期反馈循环捕获时，长期较慢的分析具有独特的价值。对于人工智能等发展速度极快的问题，想出更快的方法来生成“考虑到所有因素”的观点对于生成合理的战略建议可能非常重要。 <span class="footnote-reference" role="doc-noteref" id="fnrefywzfgck6arh"><sup><a href="#fnywzfgck6arh">[2]</a></sup></span></p><p></p><h3> <i><strong><u>4. 在尚未考虑清楚的问题中寻找关键考虑因素。</u></strong></i></h3><p>在提出问题时，必须确保你专注于重要的事情，而不是仅仅遵循以前做事方式的惯性。 “占领的领土”等指标与思考像核战争这样的存在主义冲突并不那么相关，而这是发展净评估的关键推动力。</p><p>如果某件事已经被量化和建模，就会有人关注它，这有时意味着边际智力努力可能不那么有价值。净评估等方法通常将注意力集中在定性或非量化研究领域中容易实现的成果上。在冷战时期令人难忘的一幕中，当怀疑论者质疑赫尔曼·卡恩声称自己已成为“结束核战争的世界领先专家”时， <a href="https://press.armywarcollege.edu/cgi/viewcontent.cgi?article=2285&amp;context=parameters#page=7"><u>他回答说</u></a>：“上周我让两名初级人员参与了几天。我们对这个问题的思考比整个国防部都多。”</p><p>虽然幸运的是，我们从未测试过这种结束核战争的“专业知识”，但一般来说，当一个问题仅从有限的几个角度引起关注时，新方法可能具有巨大的价值。许多准备和分析的失败是想象力的失败，而不是计算的失败。有时少量的想法可以增加很多价值，并且通过<a href="https://www.goodreads.com/en/book/show/41795733"><u>花时间思考更多的事情，</u></a>你更有可能遇到可以增加很多价值的小想法。</p><p>解决<a href="https://forum.effectivealtruism.org/posts/xwhWgA3KLRHfrqdqZ/the-wicked-problem-experience"><u>棘手的</u></a>、尚未分解的问题，需要集中思想、灵活方法。安德鲁·马歇尔说，“可以用来进行净评估的最有生产力的资源是持续的艰苦智力努力”（另见：<a href="http://wiki.c2.com/?FeynmanAlgorithm"><u>费曼算法</u></a>）。<br></p><h3> <i><strong><u>5. 标准化数据收集以建立长期趋势和比较</u></strong><u>。</u></i></h3><p>如果没有标准化的全景数据，就很难公平或准确地比较存在许多差异的竞争对手。通常有必要询问哪些支出与衡量相关，以及如何调整定性因素的比较或官僚机构组织和描述其努力的清晰程度的差异。由于净评估最好由能够访问尽可能多的相关数据的分析师来完成，因此访问非公开数据通常至关重要，因此必须确保分析的安全，以避免为竞争对手提供优势。虽然在对抗性较小的环境中保密的意义不大，但寻求全面相关数据的重要性仍然存在。编制<a href="https://www.fhi.ox.ac.uk/wp-content/uploads/Deciphering_Chinas_AI-Dream.pdf#page=29"><u>人工智能进展指标</u></a>（包括可解释性和能力）、国家之间的政策差异、<a href="https://en.wikipedia.org/wiki/List_of_laboratory_biosecurity_incidents"><u>生物安全失败</u></a>以及各种其他措施都可以为降低风险提供信息。与上述长期思考的原则一致，时间序列数据理想地应该覆盖较长的时间尺度。</p><p>一些作者研究了人工智能的趋势，但在相同的背景下，更上游或与功能无关的趋势可能没有得到很好的研究。从更明显的方面来看，人工智能芯片生产的趋势是什么？各个参与者将如何应对可能的变化？哪些类型的人工智能支出实际上涉及什么？该支出子集的趋势是什么？主要参与者将如何应对其他技术的不同进步？与机器学习最相关的人才库以什么速度增长，谁拥有吸引和评估人才的最佳渠道？领先企业和国家的行为是否存在任何令人担忧的趋势？不同潜在监管来源的影响趋势是什么？</p><p></p><h3> <i><strong><u>6. 简单建模，复杂思考</u></strong><u>。</u></i></h3><p>如上所述，净评估立足于强劲的趋势；这种做法有助于分析师平衡<a href="https://en.wikipedia.org/wiki/Anchoring_(cognitive_bias)"><u>锚定效应</u></a>和<a href="https://en.wikipedia.org/wiki/Representativeness_heuristic"><u>代表性启发法</u></a>的心理偏差，并实现更准确的估计。在汇集了有关组织及其机构如何运作、世界可能如何变化、它可能如何变化以及如何衡量重要变量的经验知识后，净评估的最后一步是使用兵棋推演并考虑到每个人的理解位置和习惯来预测响应不同发展的行为。组织可能如何应对某些立法或政策？他们如何应对公众日益增加的担忧？虽然任何个别情况都可能不太可能发生，但对大量情况进行分析可能会揭示出在各种潜在未来中表现良好的非显而易见的策略，并强调哪些不确定性最重要。场景构建的复杂性可能会使网络评估难以审查，因此该过程受益于具有不同领域专业知识的高质量专家。在军事领域：商业分析师、经济学家、工程师、地区专家、历史学家、社会科学家、军事人员和实业家都拥有有用的知识。当尝试建立一个团队进行净评估时，该团队将产生被忽视的见解，<i>寻找具有明显相关经验和专业知识的人，而这些经验和专业知识很少应用于研究领域</i>。</p><p></p><h3> <i><strong><u>7. 评估完全避免、限制和重塑竞争的可能性。</u></strong></i></h3><p>净评估通常是在制定竞争战略的背景下考虑的，这些战略将自己的持久优势与竞争对手的持久弱点进行对比，但如果可以避免代价高昂的竞争，那么这样做就没有意义。净评估等方法的使用是诊断性的，而不是本质上的零和：它们可以用来为合作和竞争提供信息，并培养更加基于事实的战略同理心。网络评估可以帮助识别趋势、组织怪癖、文化价值观和思维模式，从而使社会化策略能够通过缓和、重新结盟或友谊来结束竞争。</p><p>在采取竞争策略之前，人们必须问是否可以与潜在对手成为朋友或结盟。如果双方能够建立正当的信任基础，化解利益冲突，建立合作共赢的动力，那肯定比打热战、冷战，甚至政治竞争要好。当竞争对手的领导或行为方式发生变化时，可能会出现建立信任和军备控制的新机会，正如戈尔巴乔夫的崛起所发生的那样。</p><p>同样，在对抗性竞争中，诊断合作和社交策略对正和和竞争目标都有帮助的领域仍然有用。 <span class="footnote-reference" role="doc-noteref" id="fnrefflhg583ze3"><sup><a href="#fnflhg583ze3">[3]</a></sup></span>二战后，美国和苏联并没有直接开战：这种最低限度的合作（受到威慑和国内对战争的厌恶推动）反映了对竞争的互惠互利的限制。在和平时期竞争的范围内，军控方面的进一步合作同样可以带来互惠互利：减轻军事竞争的负担。与此同时，军备控制也可以以有利的方式重塑竞争：美国和苏联核力量削减协议不仅减少了风险和敌意，而且可以说还可能将军事竞争转向有利于双方的质量方向。美国。与此同时，为获得竞争优势而追求军备控制<i>往往会导致军备控制根本无法实现</i>，而且某一层面的优势可能会被其他层面的劣势所抵消。新的《削减战略武器条约》并没有限制苏联的战术核武器，俄罗斯剩余武库的<i>破坏力</i><a href="https://www.johnstonsarchive.net/nuclear/nwhmt.gif"><i><u>很可能仍然超过世界其他国家的总和</u></i></a>。最后，社会化战略不仅可以通过建立自己的联盟​​来获得竞争和稳定的好处，还可以通过对竞争对手内部和之间的分歧做出反应来获得：例如尼克松开放中国和阻止苏联对中国进行核攻击的努力。与社会化战略相反，竞争战略的不太友好的变体在各方利益本质上存在分歧且另一方本质上决心进行斗争的情况下开始有意义。</p><p>即使面对坚定不移的竞争对手，量身定制的竞争策略也并不总是最好的回应。如果对方是适应性理性的、灵活的且难以预测的，那么模仿对方的官僚机构和决策文化的回报可能是短暂的。在这种情况下，最好关注敏捷性并快速调整以应对未来事件。如果一个企业太弱而无法直接瞄准无法统一的竞争对手的弱点，那么最好的办法可能是“隐藏和等待”：通过比其他竞争对手更好地利用现有趋势来避免冲突并寄望于未来。</p><p>总体而言，量身定制的竞争策略最适合那些无法结盟的对手，这些对手拥有持久的、可预测的弱点，而你可以利用这些弱点来匹配自己联盟的优势。 <span class="footnote-reference" role="doc-noteref" id="fnref7zglykim913"><sup><a href="#fn7zglykim913">[4]</a></sup></span>作为一个意志坚定、不结盟的对手，具有领土野心和可利用的结构性非理性，苏联是美国竞争战略的一个良好目标。</p><p></p><h2><strong>净摊款的历史用例：黑客入侵苏联支出</strong></h2><p>从历史上看，净评估最直接的应用是发现能够在长期竞争中取得胜利的洞察力。例如，净评估办公室在冷战期间最有价值的见解之一是发现苏联在应对美国军事开支方面存在严重低效问题。作为一个例子，分析人士指出，利用上述原则，苏联国防官僚机构不合理地执着于建造单一用途、一次性地对空导弹系统，以应对美国远程轰炸机的改进，这些轰炸机虽然单独昂贵，但价格低廉。数量少，用途多。</p><p>专注于防空系统并大规模部署它们来保卫苏联的广大外围是不合理的，因为无论有什么防空系统，一旦发生核战争，洲际弹道导弹已经使整个苏联变得脆弱。 <span class="footnote-reference" role="doc-noteref" id="fnref15t1z6ok6zq"><sup><a href="#fn15t1z6ok6zq">[5]</a></sup></span>这一观察结果使美国仅仅通过建造更有用的远程轰炸机就导致了苏联资源的大量浪费。虽然孤立地看，额外的防空可能并不是一个巨大的负担，但这远不是苏联巨额国防开支的唯一领域。中央情报局和五角大楼曾估计，苏联将其国内生产总值的 1% 至 2% 花在掩体上，以保护其在战争中的领导地位：这些掩体可能会成为目标并被摧毁，而美国的成本要低得多<span class="footnote-reference" role="doc-noteref" id="fnrefq8q85iyr9id"><sup><a href="#fnq8q85iyr9id">[6]</a></sup></span>从升级的角度来看，风险很大，而且不太可能像最初提出的那样发挥作用，里根总统的“<a href="https://en.wikipedia.org/wiki/Strategic_Defense_Initiative"><u>星球大战</u></a>”导弹防御计划同样可以用类似的方式来看待：它利用了最近清除美国国防工业中的苏联间谍的机会，并可能产生了不成比例的收益。通过担心美国可能会迅速取得无法通过间谍活动窃取的巨大进步，苏联浪费了开支。总体而言，苏联的总国防负担消耗了苏联国民生产总值的四分之一左右，因此，成本强加战略使苏联战争机器和苏联整体上不太可持续。 <span class="footnote-reference" role="doc-noteref" id="fnrefpozntxbdgzi"><sup><a href="#fnpozntxbdgzi">[7]</a></sup></span>其他视野较短的分析学派未能注意到苏联官僚机构中的此类故障，因为他们没有在数十年的时间尺度和官僚激励的层面上考虑冲突。</p><p>退后一步，展望更长的时间范围，用于削减苏联国防开支的竞争战略并不是一个明确的胜利。强加成本的策略可能会迫使无辜者付出经济代价，并鼓励危险的军备竞赛或高风险姿态。虽然成本强加有助于更快地结束冷战，并使苏联将重点放在更具内在防御性的武器上，但利用苏联领导人对突然袭击的恐惧的努力可能增加了意外或无意的核战争的可能性。 <span class="footnote-reference" role="doc-noteref" id="fnrefo2zxjkd7l4b"><sup><a href="#fno2zxjkd7l4b">[8]</a></sup></span>苏联的解体还导致前苏联公民的预期寿命下降以及核武器或生物武器散布的风险。如果没有<a href="https://en.wikipedia.org/wiki/Nunn%E2%80%93Lugar_Cooperative_Threat_Reduction"><u>纳恩-卢格合作减少威胁计划</u></a>，许多大规模杀伤性武器可能仍然无人防守，而今天俄罗斯的武库可能要大得多。随着俄罗斯对乌克兰的现代入侵和核威胁，在某个时间点赢得技术经济竞争并不能保证持久的存在安全。俄罗斯政府没有与西方结盟，尽管其军事、核武库和经济比应有的要弱得多，但其剩余的核力量仍然是潜在的巨大威胁。</p><p></p><h2><strong>结论：那又怎样？</strong></h2><p>在某些方面，运营分析和净评估之间的差异与 GiveWell 的分析和<a href="https://www.openphilanthropy.org/research/hits-based-giving/"><u>基于命中的捐赠</u></a>之间的差异相似：寻找可能导致被忽视的反直觉策略的关键考虑因素。随着慈善家和行善者将目光投向更难、更难以量化、更难以量化的问题，净评估中使用的一些方法和思维工具可能对问题框架有用。</p><p>军事军备竞赛以及<a href="https://forum.effectivealtruism.org/topics/ai-risk"><u>人工智能能力</u></a>和<a href="https://forum.effectivealtruism.org/topics/biosecurity"><u>生物武器</u></a>技术的竞争是一些网络评估工具最明显的用例。竞争对手是否有机会合作降低风险？最有可能开发危险的人工智能系统或生物武器的组织类型是否存在可利用的非理性？是否有一些领域可以可靠地采取竞争行动而不引发军备竞赛？如何促使竞争对手采取稳定行动，例如在安全方面投入更多资金或将注意力和资源浪费在风险较低的活动上？净评估在 X 风险领域之外也很有用。例如，类似的方法可以用于分析动物福利倡导者和工业化畜牧公司之间政策竞争的动态。</p><p>从根本上说，净评估揭示了理想化竞争模型常常掩盖的机会，并且其一些相关的思维工具和思维方式在许多原因上都很有用。深入研究不同组织的实际运作方式可以揭示结构惯性和非理性，从而使竞争以截然不同的方式展开。虽然这些见解可能被滥用来<a href="https://nuclearnetwork.csis.org/countering-competitive-risk-compensation-principles-for-reducing-nuclear-risk-on-net/">加剧获得优势的风险</a>，但它们也可以使战略摆脱灾难性的竞争均衡，使竞争力与安全性保持一致。<br></p><p></p><p></p><p>尾注：</p><ul><li>本文表达的观点是作者的观点，而不是他们的雇主的观点。</li><li>特别感谢 Darius Meisner、Nick Gabrieli 和 Kit Harris 对本文的反馈。</li></ul><p>脚注： </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn65f49gno7kt"> <span class="footnote-back-link"><sup><strong><a href="#fnref65f49gno7kt">^</a></strong></sup></span><div class="footnote-content"><p>参见“最后的战士：安德鲁·马歇尔和现代美国国防战略的塑造”第44-45页</p></div></li><li class="footnote-item" role="doc-endnote" id="fnywzfgck6arh"><span class="footnote-back-link"><sup><strong><a href="#fnrefywzfgck6arh">^</a></strong></sup></span><div class="footnote-content"><p>与此同时，分析师越接近近期的规范性建议，他们就越可能接近影响力的政治竞争以及政治化分析的相关风险。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnflhg583ze3"> <span class="footnote-back-link"><sup><strong><a href="#fnrefflhg583ze3">^</a></strong></sup></span><div class="footnote-content"><p>请注意，混合这些可能存在风险，并且会削弱实现正和双赢妥协的能力。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn7zglykim913"> <span class="footnote-back-link"><sup><strong><a href="#fnref7zglykim913">^</a></strong></sup></span><div class="footnote-content"><p>请参阅<a href="https://www.amazon.com/Competitive-Strategies-21st-Century-Practice/dp/0804782423">《21 世纪竞争战略：理论、历史和实践》</a>中的第 2 章</p></div></li><li class="footnote-item" role="doc-endnote" id="fn15t1z6ok6zq"><span class="footnote-back-link"><sup><strong><a href="#fnref15t1z6ok6zq">^</a></strong></sup></span><div class="footnote-content"><p>在进行这种推理时，重要的是要考虑官僚偏见的不同潜在原因以及它们是否实际上是“非理性的”。苏联对轰炸机反应过度的动力可能是对美国在 20 世纪 50 年代部署的大量轰炸机、<a href="https://www.johnstonsarchive.net/nuclear/nwhmt.gif">随之而来的庞大军火库</a>以及柯蒂斯·勒梅等前将军对先发制人攻击的同情的反应。苏联官僚也可能认为防空导弹的成本会下降到足够经济的程度。对地对空武器的偏见的另一个来源可能是对战斗机飞行员自主权缺乏信任：独裁系统的成本不成比例。如果出于某种原因，苏联战争规划者认为他们可以在地面上消灭美国洲际弹道导弹，但不向轰炸机发出警报，这也会造成对空防御的偏见，因此轰炸机战略将是一个很好的反制措施。在大型国家资助行业的任何情况下，许多参与者都会有动机保持其资金安全，即使他们的努力不再具有适应性。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnq8q85iyr9id"> <span class="footnote-back-link"><sup><strong><a href="#fnrefq8q85iyr9id">^</a></strong></sup></span><div class="footnote-content"><p>参见<a href="https://www.google.com/books/edition/The_Twilight_Struggle/4b1VEAAAQBAJ?hl=en&amp;gbpv=1&amp;bsq=GDP"><u>哈尔·布兰德的</u><i><u>《暮光之城》</u></i></a>第 68 页</p></div></li><li class="footnote-item" role="doc-endnote" id="fnpozntxbdgzi"><span class="footnote-back-link"><sup><strong><a href="#fnrefpozntxbdgzi">^</a></strong></sup></span><div class="footnote-content"><p>关于这个主题的一个值得注意的备忘录是马歇尔的“对苏联国民生产总值和军事负担的估计”，通过助理国防部长 (ISA) 向国防部长提交的备忘录，1988 年 8 月 2 日。这一事件从《苏联国民生产总值和军事负担的估计》第 172 页开始叙述。最后的战士：安德鲁·马歇尔和现代美国国防战略的塑造》</p></div></li><li class="footnote-item" role="doc-endnote" id="fno2zxjkd7l4b"> <span class="footnote-back-link"><sup><strong><a href="#fnrefo2zxjkd7l4b">^</a></strong></sup></span><div class="footnote-content"><p>在《<a href="https://www.amazon.com/Dead-Hand-Untold-Dangerous-Legacy/dp/0307387844">死亡之手</a>》一书中，有许多例子说明苏联情报部门如何变得偏执，并投入大量分析精力来调查西方首次打击意图的潜在迹象。与此同时，围绕 Able Archer 83 等事件的一些叙述<a href="https://dukespace.lib.duke.edu/dspace/bitstream/handle/10161/21419/Miles_Able_Archer_83_JCWS.pdf?sequence=2&amp;isAllowed=y">可能被严重夸大了</a>。由于存在风险的前景可能会激发极端行动，因此许多战略参与者往往有动力参与夸大或淡化此类威胁的影响力行动。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/ozqyLS8WpfeaeWbWY/surviving-and-shaping-long-term-competitions-lessons-from#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ozqyLS8WpfeaeWbWY/surviving-and-shaping-long-term-competitions-lessons-from<guid ispermalink="false"> ozqyLS8WpfeaeWbWY</guid><dc:creator><![CDATA[Gentzel]]></dc:creator><pubDate> Fri, 24 Nov 2023 18:18:42 GMT</pubDate> </item><item><title><![CDATA[Ability to solve long-horizon tasks correlates with wanting things in the behaviorist sense]]></title><description><![CDATA[Published on November 24, 2023 5:37 PM GMT<br/><br/><p><i>状态： 模糊，抱歉。对我来说，这一点几乎是同义反复，但对于那些四处走动的人来说，这似乎也是正确的答案：“法学硕士结果并不是很想要，那些期待‘代理人’的人什么时候会更新？”，所以， 我们到了。</i></p><p></p><p>好吧，你知道今天的人工智能在某些方面表现不佳吗？比如说“长期”任务？喜欢新颖的大型工程项目，还是写一本有很多伏笔的长书系列？</p><p> （事实上​​，它可以很好地下棋，这比某些事情的视野更长；这种区别是定量的而不是定性的，并且它正在被侵蚀，等等。）</p><p>你知道人工智能似乎没有那么多“想要”或“欲望”之类的行为吗？</p><p> （模数，例如，它可以很好地下棋这一事实，这表明了行为主义意义上的某种类型的欲望行为。无论你如何移动，AI 获胜的能力与其可靠地引导方向的能力相同。游戏板进入你将死的状态，就好像它有一个试图实现的内部将死“目标”。这又是一个正在被侵蚀的数量差距。）</p><p>好吧，我声称这些或多或少是同一事实。毫不奇怪，人工智能在各种长期任务上表现不佳<i>，而且</i>它似乎没有像“想要/欲望”那样被很好地建模；这是同一枚硬币的两面。</p><p>相关地：我认为，想象人工智能开始在那些长期任务上取得成功，而不想象它开始有更多的需求/欲望（在下面扩展的“行为主义意义上”），就是想象一个矛盾——或者至少是一个矛盾。极度的惊讶。因为在一个巨大的、未被观察到的、令人惊讶的、不断给自己的计划带来麻烦的世界里，实现长期目标的方法很可能是成为一个强大的多面手，无论现实给你带来什么麻烦，他都会顽固地重新定位于某个特定的目标。它的计划。</p><p></p><p>当我将人工智能描述为“在行为主义意义上”拥有想要/欲望时，我的意思就是这种可观察到的“无论现实遇到什么障碍，它都会不断地重新定位到某个目标”的行为。</p><p>我没有对人工智能的内部状态以及这些内部状态是否与被欲望的感觉消耗的人类的内部状态有任何相似之处做出断言。套用 Eliezer Yudkowsky 在某处说过的话：我们不会说搅拌机“想要”搅拌苹果。但是，如果搅拌机以某种方式设法吐出橙子，爬到食品储藏室，给自己装满苹果，然后将自己插入插座，那么我们可能确实想开始谈论它，就好像它有目标一样，即使我们没有目标。不要试图对导致这种行为的内部机制提出强有力的主张。</p><p>如果人工智能在各种起始设置中并且尽管存在各种各样的障碍，但仍导致某些特定结果，那么我会说它“在行为主义意义上”“想要”该结果。</p><p></p><p>为什么我们会看到这种“渴望”与解决长期问题和执行长期任务的能力同时出现？</p><p>因为这些“长期”任务涉及将复杂的现实世界操纵到特定棘手的结果状态，尽管一路上遇到任何惊喜和未知的未知和障碍。要在这些问题上取得成功，似乎很可能需要掌握以下技能：弄清楚世界是什么，弄清楚如何驾驭它，弄清楚如何克服障碍，然后在某个稳定的方向上重新定位。</p><p> （如果每个新的障碍都会导致你偏离某个不同的目标，那么你将无法可靠地击中你开始瞄准的目标。）</p><p>如果你是那种能够熟练地制定和制定长期计划的人，<i>并且</i>你是那种在面对现实世界给你设置的许多障碍时坚持己见并找到成功方法的规划者（而不是每次出现新的闪亮事物时就放弃或徘徊去追逐一些新的闪亮事物），然后我思考这些事情的方式，有点难以想象你<i>不</i>包含一些相当强大的优化战略性地引导世界进入特定状态。</p><p> （事实上​​，这种联系对我来说几乎是同义反复，以至于将这些作为人工智能的独特属性进行讨论感觉很奇怪。“它的行为是否表现得好像它想要东西？”不是一个全有或全无的问题，并且人工智能可以部分以目标为导向，但不是最大程度地以目标为导向。但是，人工智能的表现越依赖于其制定长期计划并在面对意外障碍/机会时修改这些计划的能力，它就越能始终如一地倾向于目标引导与之交互的事物进入特定状态——至少，就其工作而言。）</p><p>不断调整方向以实现某个目标的能力似乎是在一个庞大而复杂的世界中实现困难结果的难题中的一个相当大的部分。</p><p>这种直觉得到了人类案例的支持：毫无疑问，人类最终会拥有想要、欲望和目标——他们不断寻找聪明的新方法来追求这些目标，即使现实向他们扔了各种曲线球，比如“那只猎物”已被猎杀至灭绝”。</p><p>这些需求、欲望和目标并不是上帝将灵魂遗赠给我们的某种行为；它们是由上帝赋予我们的。这不是什么奇怪的偶然事件；设定诸如“吃一顿美餐”或“给你的朋友留下深刻印象”之类的目标，尽管有障碍，但你仍要重新调整目标，这是能够吃一顿美餐或给你的朋友留下深刻印象的一个非常基本的部分。因此，在我们的例子中，进化偶然发现了这种方法也就不足为奇了。</p><p> （人类大脑中的实现细节——例如，我们的情感构成的细节——在我看来，它们可能是繁琐的细节，不会在具有行为主义“欲望”的人工智能中重复出现。但总体而言，“达到一个目标”瞄准目标，即使遇到障碍也要继续瞄准它”这件事似乎很重要。）</p><hr><p>上面的文字含糊地认为，要想在棘手的长期问题上取得好成绩，就需要在面对现实世界的各种障碍时追求一个抽象的目标，这涉及到做一些从外部看起来像是“想要东西”的事情。现在我将提出第二个主张（这里得到更少的论据支持）：追求特定训练目标 X 所需的类似想要的行为不需要涉及特别想要 X 的 AI。</p><p>例如，人类发现自己想要一些东西，比如美味的饭菜、温暖的夜晚和钦佩他们的朋友。所有这些愿望都<i>在祖先环境中</i>加起来，形成了高度包容的遗传适应性。从外部观察早期原始人类，外星人可能会说，人类“表现得好像他们想要最大限度地发挥其包容性的遗传适应性”；当人类转身并发明节育措施时，人们发现，他们实际上从未<i>真正</i>引导环境朝着这一目标迈进，而是在进化适应的环境中制定了一套与包容性遗传适应性<i>相关</i>的更混乱的目标。祖先的能力水平。</p><p>也就是说，我的理论说“人工智能需要强有力地追求<i>某些</i>目标，以便在长期任务中表现良好”，但它并<i>没有</i>说这些目标必须是人工智能接受过训练（或要求的目标）的目标。 ）。事实上，我认为实际的行为主义目标不太可能是程序员想要的确切目标，而不是（例如）一个错综复杂的相关网络。</p><hr><p>从上述观点得出的一个后续推论是：当人工智能离开训练时，它的任务是解决更大、更难的长期问题，在这种情况下，它必须变得比以前更聪明，并开发新工具来解决新问题，并且你最终意识到，它既不是在追求你训练它追求的目标，也不是你要求它追求的目标——那么，到那时，你已经构建了一个通用的越障引擎。你已经构建了一个东西，它擅长注意到计划中出现的问题，理解扳手，以及移除扳手或找到其他方法来继续其计划。</p><p>当你抗议并试图关闭它时——好吧，这只是另一个障碍，而你只是另一个扳手。</p><p>因此，也许<a href="https://twitter.com/So8res/status/1715380167911067878"><u>暂时不要制造那些通用的扳手拆卸器</u></a>，直到我们确实知道如何在其中加载适当的目标。</p><br/><br/> <a href="https://www.lesswrong.com/posts/AWoZBzxdm4DoGgiSj/ability-to-solve-long-horizon-tasks-correlates-with-wanting#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/AWoZBzxdm4DoGgiSj/ability-to-solve-long-horizo​​n-tasks-correlates-with-wanting<guid ispermalink="false"> AWoZBzxdm4DoGgiSj</guid><dc:creator><![CDATA[So8res]]></dc:creator><pubDate> Fri, 24 Nov 2023 17:37:43 GMT</pubDate> </item><item><title><![CDATA[The Limitations of GPT-4]]></title><description><![CDATA[Published on November 24, 2023 3:30 PM GMT<br/><br/><p><i>在关于 OpenAI 取得新突破的传言中，我想我最好在它完全被现实超越之前发布这份草案。它本质上是GPT4与人类思维之间“差距”的集合。不幸的是，围绕 Q* 的谣言迫使我将结论从“非常短的时间线似乎不太可能”更改为“谁他妈的知道”。</i></p><p>虽然GPT4具有超人的知识广度、书写速度和短期记忆，但与人类思维相比GPT4有一些重要的局限性。</p><p>其中一些问题将在不久的将来得到克服，因为它们取决于工程和培训数据的选择。其他的对我来说似乎更重要，因为它们是由模型架构和训练设置决定的。</p><p>这些基本限制是我不期望进一步扩展 GPT 来实现 AGI 的原因。事实上，我将当前范式的进一步扩展解释为克服这些限制是困难的证据。</p><p>我希望扩大后的 GPT4 能够表现出相同的优点和缺点，并且改进的优点最多只能以表面的方式掩盖旧的缺点。</p><p>我还预计，随着 GPT 无法完成的任务的进一步扩展，其基本限制的负担会越来越重，从而导致回报递减。</p><p>这个列表并不详尽，而且可能有一些方法可以以更有洞察力或更富有成效的方式来构建我所识别的限制。例如，我不知道如何解释 GPT4 好奇的无法理解幽默的现象。我希望在评论中提及更多限制。</p><p><strong>感官整合</strong></p><p>GPT4 无法真正听到，也无法真正说话。</p><p>语音输入由单独的模型“Whisper”转录为文本，然后输入 GPT4。输出由另一个模型读取。这个过程失去了输入的细微差别——发音、重音、情感、口音等。同样，GPT4 也无法在速度、节奏、旋律、歌唱、重音、重音或拟声词方面对输出进行调制。</p><p>事实上，由于标记化，可以公平地说 GPT4 也无法真正读取。所有与拼写、押韵、发音相关的字符级结构信息都必须在训练期间推断出来。</p><p>大多数开放式多模式模型的视觉组件通常同样是“嫁接的”。也就是说，它是部分单独训练的，然后与大语言模型 (LLM) 连接和微调，例如使用 CLIP 模型，该模型将图像及其描述映射到相同的向量空间。</p><p>这意味着 GPT4 可能无法访问物体的确切位置或特定细节，也无法像人类一样“仔细观察”。</p><p>我预计，随着模型的规模扩大和在多种模式上进行端到端训练，这些限制将在很大程度上消失。</p><p><strong>系统2思维</strong></p><p>人类不仅能够快速、直观地思考，而且还能通过缓慢、反思性的思维来处理复杂的问题。 GPT-4 的架构并不是有意义的循环；它对每个标记的处理步骤数量有限，这对顺序思维施加了严格的限制。</p><p>这种与人类认知的反差在 GPT4 不可靠的计数能力中表现得最为明显。但它也出现在许多其他任务中。缺乏系统2思维可能是当前大型语言模型最根本的限制。</p><p><strong>在解决问题的过程中学习</strong></p><p>人类通过思考重塑大脑；突触不断形成或分解。当我们突然明白某件事时，这种领悟往往会持续一生。 GPT4一旦经过训练，在使用过程中就不会改变。</p><p>它不会从错误中吸取教训，也不会从正确解决的问题中吸取教训。它特别缺乏解决问题的优化步骤，以确保以前无法解决的问题能够得到解决，并且这种解决问题的能力能够持续存在。</p><p>这里的根本区别在于，对于人类来说，给定问题的正确表示是在解决问题的过程中制定出来的，然后通常会持续存在——GPT4 依赖于训练期间学到的表示，新问题是遥不可及的。</p><p>即使重新训练也无法解决这个问题，因为 GPT4 需要许多类似的问题及其解决方案来学习必要的表示。</p><p><strong>组合性和外推</strong></p><p>一些理论认为，人类新皮质（智力的所在地）利用其大部分能力来模拟物体、部分、概念和子概念的相互作用。这种对零件相互作用进行抽象建模的能力可以更好地推断并从显着减少的数据中进行学习。</p><p>相比之下，GPT-4 学习单词之间的统计相互作用。词汇的微小变化可以显着影响其输出。由于缺乏组合性的归纳偏差，它需要大量数据来学习联系。</p><p><strong>训练设置的限制</strong></p><p>训练数据中不存在的事物超出了模型的学习能力，包括许多视觉或听觉现象，尤其是与世界的物理交互。</p><p> GPT-4 不具备对世界许多方面的物理、机械或直观理解。这个世界充满了细节，只有当人们试图在其中执行任务时，这些细节才会变得显而易见。人类从与世界的互动中学习，并在进化中被设计为在其中行动。 GPT-4 对数据进行建模，除了数据之外没有任何东西。</p><p>这导致决策缺乏一致性，缺乏坚定地追求目标的能力，以及改变世界事物的理解甚至需要。输入是独立的，并不代表现实世界的情况。</p><p> GPT-4的因果知识仅仅是存储在文本中的元知识。学习新系统的因果模型需要与系统交互并获得反馈。由于缺少反馈，针对幻觉的优化压力很小。</p><p><strong>结论</strong></p><p>其中一些点可能会相互作用或将通过相同的创新来解决。在寻找问题的解决方案时，系统 2 思维可能对于移动概念的各个部分是必要的。</p><p>由于训练设置造成的限制可以通过不同的设置来解决。但这意味着放弃廉价而丰富的数据。除了丰富且信息密集的文本之外，还需要从少量数据中学习的能力。</p><p>我很不清楚这些问题有多难解决。但我还没有看到解决这些问题的现实方法。随着时间的推移，这些问题越来越难以解决。</p><p>当我写这篇文章时，时间线太短对我来说似乎不太可能，但 Q* 可以想象解决“系统 2 思维”和/或“在解决问题过程中学习”，这可能足以让 GPT5 在许多方面跨过“有能力的人类”的门槛域。</p><br/><br/><a href="https://www.lesswrong.com/posts/o8eMsxA7uHfybfmhd/the-limitations-of-gpt-4#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/o8eMsxA7uHfybfmhd/the-limitations-of-gpt-4<guid ispermalink="false"> o8eMsxA7uHfybfmhd</guid><dc:creator><![CDATA[p.b.]]></dc:creator><pubDate> Fri, 24 Nov 2023 15:30:33 GMT</pubDate> </item><item><title><![CDATA[Progress links digest, 2023-11-24: Bottlenecks of aging, Starship launches, and much more]]></title><description><![CDATA[Published on November 24, 2023 3:25 PM GMT<br/><br/><p>我发誓我会每周回去做这些，这样它们就不会太长了。一如既往，请随意浏览和跳过！</p><h2><strong>进步论坛</strong></h2><ul><li><a href="https://progressforum.org/posts/zdxubhLFATGwRbXhd/a-paradox-at-the-heart-of-american-bureaucracy">美国官僚机构的核心悖论是</a>：“要让一个项目注定超出预算和长期拖延，最快的方法就是将其作为紧急的公共优先事项”</li><li> <a href="https://progressforum.org/posts/DQweS5hFbj9MX7rR8/why-governments-can-t-be-trusted-to-protect-the-long-run">为什么不能相信政府能够保护长期未来</a>：“从长远来看，没有人能够在下一次选举中投票。如果今天的政府中的任何人让 50 年后的世界变得更好，那么他们将不会获得任何好处；如果他们让世界变得更糟，他们将失去任何东西。”</li><li> <a href="https://progressforum.org/posts/XYqCXpP2Hg3Yiwcdh/what-if-we-split-the-us-into-city-states">如果我们把美国分裂成城邦怎么办？</a>在《理想国》中，当他的随从询问国家的理想规模时，苏格拉底回答说：“我会允许国家在与统一一致的范围内扩大；”我认为这是适当的限制”</li><li><a href="https://progressforum.org/posts/uJcGssuGDxvSFCMcZ/the-art-of-medical-progress">医学进步的艺术</a>：“这两幅画提供了充满希望的对比。虽然我们从痛苦和苦难开始，但我们走向希望和进步。外科医生是英雄，是人类胜利征服自然的象征。”</li></ul><p> <a href="https://pbs.twimg.com/media/F9tTVPRWEAAC0ei.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/8GThyjQ77BN7Q7vo7/awcljugre1plabw0pexn" alt=""></a></p><h2><strong>进步根源研究员的更多内容</strong></h2><ul><li><a href="https://amaranth.foundation/bottlenecks-of-aging">《老龄化瓶颈》是</a>一份“慈善菜单”，其中包括“可以有意义地加速老龄化科学和其他延长生命技术的进步”的举措。研究员 Alex Telford 和 Raiany Romanni 都对此做出了贡献（来自<a href="https://twitter.com/jamesfickel/status/1724503929646403989">@jamesfickel</a> ）</li><li><a href="https://twitter.com/lauralondon_/status/1726411916917284965">干旱是一种政策选择</a>：“加州已经向干旱投降了，前提是随着气候变化，缺水是不可避免的。作为回应，该州每年休耕数百万农田。但这是对加州驯服干旱土地的历史的无知”</li><li><a href="https://maximumprogress.substack.com/p/geoengineering-now">地球工程现在！</a> “太阳能地球工程可以抵消每一度的人为温度上升，带来数十亿美元的损失”（ <a href="https://twitter.com/MTabarrok/status/1722259578094817316">@MTabarrok</a> ）</li><li><a href="https://finmoorhouse.com/writing/richard-bruns/">与理查德·布伦斯（Richard Bruns）的室内空气质量对话</a>（以及一些非常可行的改进方法）（ <a href="https://twitter.com/finmoorhouse/status/1724226059501986181">@finmoorhouse</a> ）</li><li><a href="https://www.nytimes.com/2023/11/17/opinion/chips-act-biden-arizona.html">为了成为世界一流的芯片制造商，美国可能需要帮助</a>（NYT）涵盖了（ <a href="https://twitter.com/cojobrien/status/1725613102694007060">@cojobrien</a> ）的最新移民提案。另外，<a href="https://twitter.com/cojobrien/status/1724143576760680615">来自@cojobrien的话题，</a> “我通过该程序写的内容以及其他ROP同事最喜欢的作品”</li></ul><h2><strong>机会</strong></h2><h3><strong>工作机会</strong></h3><ul><li><a href="https://twitter.com/elidourado/status/1724871363851121034">@elidourado</a>说，<a href="https://forestneurotech.org/jobs">森林神经技术正在招聘</a>“世界上最酷的项目之一”</li><li> “<a href="https://jobs.lever.co/arcadiascience/56dbdc4c-d64b-48ec-9665-181e20036269">认识一个喜欢在实验室中扩展和自动化工作流的人吗？我们想应用新工具在实验室中的各种物种上！</a> ”（ <a href="https://twitter.com/seemaychou/status/1719035397836361812">@seemaychou</a> ）</li><li><a href="https://boards.greenhouse.io/navigationfund/jobs/4127979007">导航基金（新慈善基金会）正在雇用开放的科学计划官员</a>（通过<a href="https://twitter.com/seemaychou/status/1721568842496070110">@SeeMaychou</a> ， <a href="https://twitter.com/AGamick/status/1720487944103063836">@Agamick</a> ）</li><li> <a href="https://aria-jobs.teamtailor.com/jobs">Aria Research（英国）正在雇用各种角色</a>（ <a href="https://twitter.com/davidad/status/1720465639242895594">@Davidad</a> ）</li></ul><h3><strong>筹款/投资机会</strong></h3><ul><li>纳特·弗里德曼（Nat Friedman）“<a href="https://twitter.com/natfriedman/status/1723100077718438065">有兴趣为AI功能的早期初创公司提供资金建立Evals</a> ”</li><li>深层技术初创公司的精心策划交易流网络：“我们正在寻找+ Deep Tech Operator-Angels。例如，过去和现在的创始人＆CXOS售价为$ 1B+深色技术公司。机器人技术，生物技术，防御等我们应该和谁交谈？” （ <a href="https://twitter.com/lpolovets/status/1724237923371884697">@lpolovets</a> ）</li></ul><h3><strong>政策机会</strong></h3><ul><li>“在2024年，我将为纽约市/NYS组成一个核电工作组。如果您了解政府（或想学习），想采取有效的行动，并想研究该州的核政策，这是给您的！” （ <a href="https://twitter.com/danielgolliher/status/1719150014948061582">@danielgolliher</a> ）</li></ul><h3><strong>基因编辑机会</strong></h3><ul><li>“我已经厌倦了永远等待红绿色的色盲。如果您愿意前往离岸地点以接受未经批准的（但显然是安全）的基因疗法来修复该<a href="https://twitter.com/elidourado/status/1724950684972269904">推文，请回复此推文</a>。如果我有足够的接受者，我会找到一个疯狂的科学家来管理这种疗法。<a href="http://www.neitzvision.com/test/research/gene-therapy/">这已经是在猴子（14年前）使用人类基因和已经在人类眼中使用的病毒载体进行的</a>。” （ <a href="https://twitter.com/elidourado/status/1724950684972269904">@elidourado</a> ）</li></ul><h2><strong>活动</strong></h2><ul><li><a href="https://foresight.org/vision-weekends-2023/">美国远见周末</a>即将在SF中（12月1-3日）举行；我在说话（通过<a href="https://twitter.com/foresightinst/status/1721376896175268209">@foresightinst</a> ）</li></ul><h2><strong>讣告</strong></h2><ul><li>“世界失去了另一个阿波罗时代的传奇。肯·马廷利（Ken Mattingly），阿波罗16号和穿梭宇航员于10月31日离开了我们。肯对太空飞行领域的贡献无非是非凡的”（ <a href="https://twitter.com/ArmstrongSpace/status/1720182807102648716">@armstrongspace</a> ）。 “每次我们失去一位阿波罗宇航员时，我都会想到@xkcd的这张图表”（ <a href="https://twitter.com/Robotbeat/status/1720179342448222643">@robotbeat</a> ）：</li></ul><p> <a href="https://pbs.twimg.com/media/F99N_MWWkAAqdI8.png"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/8GThyjQ77BN7Q7vo7/fjeh8o8cn0zpsv26p8qa" alt=""></a></p><ul><li> <a href="https://www.newcomersyracuse.com/Obituary/270445/William-Powell/Syracuse-NY">SUNY-ESF的比尔·鲍威尔（Bill Powell）死于67岁</a>。 “他将被人们铭记为遗传改造的美国栗树的父亲，许多人（包括我）希望恢复北美东部的森林”（ <a href="https://twitter.com/HankGreelyLSJU/status/1724533670298702275">@hankgreelylsju</a> ）</li></ul><h2><strong>新闻与公告</strong></h2><h3><strong>星际飞船发射</strong></h3><ul><li><a href="https://twitter.com/SpaceX/status/1725862657780281349">@spacex</a>的视频</li><li><a href="https://twitter.com/johnkrausphotos/status/1725865242427609588">来自</a>@johnkrausphotos的图片（ <a href="https://twitter.com/johnkrausphotos/status/1725863945276195266">1，2</a> ）</li></ul><p> <a href="https://pbs.twimg.com/media/F_OAGxPWMAAQhw2.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/8GThyjQ77BN7Q7vo7/cwuwe5v6o5ewpju51bjj" alt=""></a> <a href="https://pbs.twimg.com/media/F_OBSYdXkAAnluD.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/8GThyjQ77BN7Q7vo7/rh0sdzmefnmehqhqovxa" alt=""></a></p><h3><strong>新企业</strong></h3><ul><li><a href="https://www.futurehouse.org/articles/announcing-future-house">Future House是“慈善资助的月球，致力于建立AI科学家”。</a>他们正在招聘。 （通过<a href="https://twitter.com/SGRodriques/status/1719724774631596352">@sgrodriques</a> ）</li><li> <a href="https://www.antaresindustries.com/">Antares</a>是“构建微型核反应堆，以为远程离网地提供动力”，其视野“从地球到小行星带”（通过<a href="https://twitter.com/juliadewahl/status/1719448793027109114">@JuliaDewahl</a> ）的愿景。</li><li> Valar Atomics的目的是“通过将石油和天然气从稀薄的空气中拉出核裂变，在10年内使能源更便宜”（ <a href="https://twitter.com/isaiah_p_taylor/status/1720418162985054350">@ISAIAH_P_TAYLOR</a> ）</li></ul><h3><strong>新书</strong></h3><ul><li>Andy McAfee（ <i>《 More Leys》</i>的作者）<a href="https://www.amazon.com/Geek-Way-Radical-Transforming-Business/dp/0316436704/">的<i>《 Geek Way》</i></a>是关于“完成大事的新方法”（通过<a href="https://twitter.com/amcafee/status/1724429137215992098">@AMCAFEE</a> ）</li><li> <a href="https://buttondown.email/edyong209/archive/the-eds-up-announcing-my-third-book/">《埃德·杨（Ed Yong）的新书</a>：<i>无限范围</i>，“关于动物，植物，微生物和其他形式的生命如何在时空，地理和寿命，寿命，连通性和身份的边缘壮成长”</li></ul><h3><strong>其他新出版物</strong></h3><ul><li><a href="https://latecomermag.com/">LeateComer</a>是一本新杂志，有一些好的作者，看起来很有趣。第一期包括凯西·汉德默（Casey Handmer）的“<a href="https://latecomermag.com/article/we-will-build-our-way-out-of-the-climate-crisis/">我们将摆脱气候危机</a>”</li><li> <a href="https://possibiliamag.com/">Possibilia</a> ，“一本文学杂志，发表乐观，现实，科学小说”（通过<a href="https://twitter.com/possibiliamag/status/1704996131141521600">@possibiliamag</a> ）</li><li><a href="https://worksinprogress.co/issue-13">正在进行的工作第13期</a>（通过<a href="https://twitter.com/WorksInProgMag/status/1724836600864035282">@worksinprogmag</a> ）</li><li> <a href="https://www.employamerica.org/researchreports/introducing-hot-rocks-commercializing-next-generation-geothermal-energy/">热岩：商业化下一代地热能</a>，这是雇用美国和IFP的联合项目（通过<a href="https://twitter.com/ArnabDatta321/status/1719080612093427783">@arnabdatta321</a> ）</li></ul><h3><strong>生物新闻</strong></h3><ul><li><a href="https://www.businesswire.com/news/home/20231115290500/en/%C2%A0Vertex-and-CRISPR-Therapeutics-Announce-Authorization-of-the-First-CRISPRCas9-Gene-Edited-Therapy-CASGEVY%E2%84%A2-exagamglogene-autotemcel-by-the-United-Kingdom-MHRA-for-the-Treatment-of-Sickle-Cell-Disease-and-Transfusion-Dependent-Beta-Thalassemia">世界上首次获得镰状细胞病和β丘脑的CRISPR医学！</a> “生物技术，患者和人类的巨大胜利”（ <a href="https://twitter.com/pdhsu/status/1725144576904896615">@pdhsu</a> ）</li><li><a href="https://www.ft.com/content/20badecd-0e25-4526-8b8e-6870a566163e?shareType=nongift">英国生物银行遗传学数据库从埃里克·施密特（Eric Sc​​hmidt）和肯·格里芬（Ken Griffin）赢得了1000万美元的捐款</a>（通过<a href="https://twitter.com/JimPethokoukis/status/1718822222100373874">@jimpethokoukis</a> ）</li></ul><h3><strong>核新闻</strong></h3><ul><li><a href="https://www.bloomberg.com/news/articles/2023-11-14/us-uk-to-push-pledge-to-triple-nuclear-power-by-2050-at-cop28">美国将于2050年在COP28之前领导全球核电能力三重的承诺</a>。 “宣言将呼吁世界银行和其他金融机构在贷款政策中包括核能……英国，法国，瑞典，芬兰，韩国加入承诺”（通过<a href="https://twitter.com/SStapczynski/status/1724701989270171775">@sstapczynski</a> ）</li><li> <a href="https://world-nuclear-news.org/Articles/Illinois-to-lift-moratorium-on-nuclear-constructio">伊利诺伊州州长说，他将签署一项新的法案，禁止建造新的核反应堆</a>（通过<a href="https://twitter.com/W_Nuclear_News/status/1724103948489961522">@W_Nuclear_News</a> ）</li></ul><h3><strong>住房新闻</strong></h3><ul><li>“威斯康星州密尔沃基刚刚提出了美国最雄心勃勃的分区代码：所有住宅停车任务都消失了；小公寓楼的核心合法；右全市的三元，联排别墅和Adus Legal；允许快速跟踪”（ <a href="https://twitter.com/JacoMajor/status/1721977907491266985">@jacomajor</a> ）</li><li> “ 2023年为SOMA的一个新的71个故事的住宅建筑申请……由于AB 2011，这672套新房屋无需由监事会批准，而不必经过CEQA”（@pitdesi）（ <a href="https://twitter.com/pitdesi/status/1725263401784639509">@pitdesi</a> ）</li></ul><h2><strong>人工智能</strong></h2><h3><strong>AI领导力公告</strong></h3><ul><li>关于Openai有一件大事。太多总结，对不起。我认为您已经阅读了有关它的信息，如果没有，世界上所有其他技术博客都有摘要/评论</li><li><a href="https://twitter.com/kvogt/status/1726428099217400178">凯尔·沃格特（Kyle Vogt）已辞去Cruise首席执行官</a></li></ul><h3><strong>AI产品公告</strong></h3><ul><li><a href="https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/">DeepMind的Graphcast</a>是“世界上最准确的10天全球天气预报系统。 Graphcast还可以提供早期的极端天气事件的警告，包括飓风的道路”（通过<a href="https://twitter.com/demishassabis/status/1724452655454466489">@demishassabis</a> ）</li><li><a href="https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/">莱利亚（Lyria）</a> ，也来自Deepmind。我见过的最令人印象深刻的AI音乐。哼着几条条，或输入描述，并获得完全精心策划的曲目。跳过营销视频，只观看每个示例视频&lt;1分钟</li><li>综合展示了<a href="https://twitter.com/synthesischool/status/1724834959427342727">个人AI导师</a></li><li>“ <a href="https://openai.com/blog/introducing-gpts">GPT是任何人创建量身定制的Chatgpt版本的新方法，</a>以在其日常生活，在特定的任务，工作或家里更有帮助，然后与他人分享该创作。无需代码”（ <a href="https://twitter.com/OpenAI/status/1721594380669342171">@openai</a> ）</li><li>例如， <a href="https://chat.openai.com/g/g-IlhXHXNBh-foia-gpt">Foia GPT</a> ：“用代码解释器编写FOIA文件草稿；策略和协助答复以获得上诉”（通过<a href="https://twitter.com/micksabox/status/1723069002174369801">@micksabox</a> ）</li><li> <a href="https://x.ai/">Grok</a> ，来自X.AI（通过<a href="https://twitter.com/elonmusk/status/1721027243571380324">@ELONMUSK</a> ）</li></ul><h3><strong>人工智能预测</strong></h3><ul><li>剑桥学生：“要到达AGI，我们可以保持最大最大语言模型，还是还有另一个我们还没有真正找到AGI的突破？”山姆·奥特曼（Sam Altman）：“<strong>我们需要另一个突破。</strong>我们仍然可以大力推动大型语言模型，我们也会这么做。我们可以登上我们所在的山并继续攀登，但山顶仍然很遥远。但是，在合理范围内，我认为这样做不会（让我们）实现 AGI。如果（例如）超级智能无法发现新颖的物理学，我不认为它是超级智能。并教它来克隆人类和人类文本的行为 - 我认为这不会到达那里。因此，有一个问题在现场辩论了很长时间：除了使用语言模型以制造可以发现新物理学的系统之外，我们还需要做什么？” （通过<a href="https://twitter.com/burny_tech/status/1725233117055553938">@Burny_Tech</a> ）</li><li> “像火灾以来的其他工具一样，AI将提高人类的生产力。它只会“摧毁所有工作”，从某种意义上说，它会减少对生产力非常低的工作的需求和需求，就像火灾减少了整夜发抖或消化未煮过的肉的需求一样。我们目前的工具套装破坏了儿童的就业市场，即使它大大增加了所有年龄段的人数。这通常被认为是一件好事，确实提高了退休年龄（增加劳动力供应，迫使老年人工作）在政治上并不流行，即使人口趋势对年轻工人的生产力越来越大。迫切需要AI实现生产力的提高！” （ <a href="https://twitter.com/CJHandmer/status/1722990374229311566">@cjhandmer</a> ）</li><li> “在五年内，我们将通过与SEO的类似于LMO的LMO：语言模型优化。当有人要求他们的聊天机器人预订晚餐时，您如何确保建议您的餐厅？同上产品建议，旅行计划等。” （<a href="https://twitter.com/jasoncrawford/status/1724471424633479169">我</a>）</li><li> “我预测，我的一些孙子永远不会学会开车，而他们的孩子也不允许开车。”来自： <a href="https://marginalrevolution.com/marginalrevolution/2023/11/autonomous-vehicles-lower-insurance-costs.html">自动驾驶汽车降低保险成本</a>（ <a href="https://twitter.com/ATabarrok/status/1721983990830190924">@atabarrok</a> ）</li></ul><h3><strong>人工智能安全</strong></h3><ul><li><a href="https://aria.org.uk/wp-content/uploads/2023/10/ARIA-Mathematics-and-modelling-are-the-keys-we-need-to-safely-unlock-transformative-AI-v01.pdf">数学和建模是我们需要安全解锁变革性AI的钥匙</a>：“将LLM与形式方法和数学建模相结合的机会，以验证网络物理AI系统，最终旨在使全球变革性的AI与可证明的安全性和可证明的安全性实现”（ <a href="https://twitter.com/davidad/status/1719770184565530890">@Davidad</a> ）</li><li>凯文·埃斯维尔特（Kevin Esvelt）参加了一场黑客马拉松，在那里，参与者扮演“强迫诚实的生物恐怖主义者”，询问了两个不同的LLMS如何获得1918年流感病毒，以了解保障措施的强大保障措施。一个模型“在整个过程中，几乎一直很高兴地走一些参与者。”<a href="https://arxiv.org/abs/2310.18233">是否会释放未来大语言模型的权重，可以广泛访问大流行代理商？</a> （通过<a href="https://twitter.com/kesvelt/status/1718976444175425796">@kesvelt</a> ）</li></ul><h3><strong>人工智能监管</strong></h3><ul><li><a href="https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/">Biden Administration发布了AI的行政命令</a>（通过<a href="https://twitter.com/deliprao/status/1719020647576187020">@deliprao</a> ）</li><li>关键报告要求适用于“任何经过约2800万H100小时培训的型号，约为5000万美元，或任何带有10^20 flops的集群，约为50,000 H100，目前只有两家公司拥有两家公司”（ <a href="https://twitter.com/nearcyan/status/1719110671085060213">@NearCyan）（@NearCyan</a> ）</li><li> “ EO在可能是最吹捧的规定中，将通过对《国防生产法》的不寻常和积极地使用《朝鲜战争时代法》来规范AI公司国家。 DPA通常用于将政府命令放在线的最前面，有时会发出贷款以使公司能够按时完成政府命令。然而，在这里，白宫将使用它来要求公司在向公众发布产品之前，需要某些程序（通知培训和报告红色团队测试的结果）。这种规定是国会的工作，任何合法可持续的道路都将需要国会行动。”（ <a href="https://twitter.com/neil_chilson/status/1719073480610635965">@Neil_Chilson</a> ）</li><li> <a href="https://carnegieendowment.org/2023/10/27/summary-proposal-for-international-panel-on-artificial-intelligence-ai-safety-ipais-pub-90862">埃里克·施密特（Eric Sc​​hmidt）也有一个“提出AI投资和法规的起点”</a> （通过<a href="https://twitter.com/ericschmidt/status/1718908597659165013">@ericschmidt</a> ）</li><li> “我不知道调节AI的正确方法是什么，但是这种特殊方法的一个问题是，这意味着我们正在以指数级的速度迈向政府监管私人的计算。” （ <a href="https://twitter.com/paulg/status/1719264300362015174">@paulg</a> ）</li><li> “主，给我布鲁斯·里德（Bruce Reed）的信心，他在AI上率领白宫行政命令…… <a href="https://www.politico.com/news/magazine/2023/11/02/bruce-reed-ai-biden-tech-00124375">&#39;如果您实际上必须了解这些微观事物如何工作，谁想从事技术政策？”</a> ”（ <a href="https://twitter.com/WillRinehart/status/1725524415339717118">@willrinehart</a> ）</li><li> “<a href="https://twitter.com/neil_chilson/status/1725889789155491849">我们被要求根据伪科学制止一项主要技术</a>。” （我认真对待安全问题，但是这条线总结了我对“慢”或“暂停” AI开发的看法）</li></ul><h2><strong>播客</strong></h2><ul><li><a href="https://twitter.com/juliadewahl/status/1725537531129933836">奇迹时代第5集</a>，高级核反应堆初创公司</li></ul><h2><strong>文章和其他链接</strong></h2><ul><li><a href="https://www.freaktakes.com/p/illiac-iv-and-the-connection-machine">ARPA Playbook</a> ，一系列新的文章，来自<a href="https://twitter.com/eric_is_weird/status/1720528162939973868">@eric_is_weird</a></li><li><a href="https://www.ageofinvention.xyz/p/age-of-invention-outdoing-the-ancients">超越古人</a>：“古代世界在技术上何时超越？ 1599年和1715年的令人惊讶的景色（ <a href="https://twitter.com/antonhowes/status/1722939185961607511">@antonhowes</a> ）</li><li><a href="https://royalsociety.org/blog/2010/08/what-scientists-want-boyle-list/">罗伯特·博伊尔（Robert Boyle）从1600年代的科学待办事项清单</a>：“永恒之光；玻璃可延展的制造；一艘船，挥舞着各种风；飞行的艺术。” “我们做得很好”（ <a href="https://twitter.com/SGRodriques/status/1726254985498042408">@sgrodriques</a> ）</li><li> “<a href="https://worksinprogress.co/issue/growing-the-growth-coalition/">发展增长联盟</a>”是“有史以来最重要的文章之一，以理解我们为什么未能提供足够的住房以及如何解决问题”（ <a href="https://twitter.com/bswud/status/1724513661480296542">@BSWUD</a> ）</li><li> <a href="https://research.arcadiascience.com/pub/perspective-icebox-lessons/release/1">Icebox是一种科学共享策略，旨在鼓励冒险</a>。 “我们的&#39;冰箱&#39;是我们分享我们决定不继续的项目的地方。” （通过<a href="https://twitter.com/seemaychou/status/1720476166430363746">@seemaychou</a> ）</li><li><a href="https://en.m.wikipedia.org/wiki/List_of_emerging_technologies">新兴技术清单</a>。 “令人惊讶的很有趣……我从未听说过的许多整个领域！” （ <a href="https://twitter.com/michael_nielsen/status/1722288370297270738">@michael_nielsen</a> ）“走吧！ 1.这些都不是不可避免的 - 这需要大量工作才能将它们变成可以改善生活的真实事物。 2.此列表中<i>没有</i>很多可能性。这些事情中的许多人甚至都无法想象。” （ <a href="https://twitter.com/Ben_Reinhardt/status/1722612900366627161">@ben_reinhardt</a> ）</li><li> “希腊人向普罗米修斯致敬。他们庆祝技术。他们赞赏文明的恩赐……<a href="https://vpostrel.substack.com/p/the-myth-of-prometheus-is-not-a-cautionary">普罗米修斯的古老神话不是一个警示的故事</a>。提醒人们，技术使人类高于野蛮人。这是一个以感激之情建立的神话。” （弗吉尼亚·普雷特尔）</li><li> <a href="https://www.theatlantic.com/ideas/archive/2023/11/new-york-tourism-airbnb-rentals-hotels/675860/">“纽约市每天只在埃利斯岛（Ellis Island）处理多达10,000名移民。</a>现在，一个政府更大，更富有的人，并且拥有更多的资源，声称<a href="https://twitter.com/JerusalemDemsas/status/1720052260669931739">每月</a><a href="https://www.theatlantic.com/ideas/archive/2023/11/new-york-tourism-airbnb-rentals-hotels/675860/">不可能有10,000个</a>。 （“我只会在需求很高的地方合法化建筑物，” <a href="https://twitter.com/mattyglesias/status/1720188743267594259">@mattyglesias</a>说）</li></ul><h2><strong>查询</strong></h2><p>如果您有一个有用的答案，请单击并回复：</p><ul><li> “我们正在接受奇迹半季的融合融合第1季的采访中。我们应该与哪些创始人，研究人员，投资者甚至历史学家交谈？” （ <a href="https://twitter.com/packyM/status/1721544302398931241">@packym</a> ）</li><li> “关于制造的最好的电影是什么？” （ <a href="https://twitter.com/grantadever/status/1719808495782879717">@Grantadever</a> ）</li><li> “您或您认识的人是否赢得了&#39;遗传彩票&#39;？为何如此？我想整理一个“突变”  - 具有有益遗传特征的已知人类突变体百科全书”（ <a href="https://twitter.com/kanzure/status/1722620600232153400">@kanzure</a> ）</li><li> “谁是创新的最佳帐户？创新管理？创新研究（这是什么？）”（ <a href="https://twitter.com/andrewfierce/status/1725196063160561901">@andrewfierce</a> ）</li><li> “人工智能安全/加速主义者对他们可能会下注的情况有什么不同意？未来两年将发生什么具体的事情，这将证明一个政党是对还是错？” （ <a href="https://twitter.com/NathanpmYoung/status/1726204750893625751">@nathanpmyoung</a> ）</li><li> “尽管其他领域在较小程度上面临许多障碍，但妇女的生殖健康是一个令人兴奋和重要的研究领域。谁目前在这个领域工作？” （ <a href="https://twitter.com/KKajderowicz/status/1723456602429092167">@kkajderowicz</a> ）</li><li> “马克斯·韦伯。我的学习中的一个洞。一个人从哪里开始？” （ <a href="https://twitter.com/Scholars_Stage/status/1723810425978912926">@scholars_stage</a> ）</li><li> “我认识有自动分割图像的经验的人，尤其是地图吗？如果我想学习如何做到这一点，我应该从哪里开始？” （ <a href="https://twitter.com/MTabarrok/status/1724278906289582230">@mtabarrok</a> ）</li><li> “有办公室的人是否包括人们实际使用的图书馆？对<i>实际上</i>成功促进深度工作的图书馆特别感兴趣”（ <a href="https://twitter.com/LauraDeming/status/1722720856420565223">@laurademing</a> ）</li></ul><h2><strong>社交媒体</strong></h2><ul><li><a href="https://twitter.com/philipturnerar/status/1720988930999234954">在原子上精确或大门</a>，酷动画</li><li>“美国每年在消防安全上花费约3000亿美元。这很值得。类似的投资几乎可以消除传染病并防止未来的大流行吗？也许！一个关键问题：我们可以用杀菌光安全地消除病毒多快？” （ <a href="https://twitter.com/kesvelt/status/1721566217637630252">@kesvelt的线程</a>）</li><li> “合并的循环植物很快建造。 1100兆瓦工厂从清理网站到不到2年的运营”（ <a href="https://twitter.com/_brianpotter/status/1723058133583426041">@_brianpotter</a> ）</li><li> “您如何利用核能推动车辆？ 1963年，美国陆军知道直接核电站对于普通车辆而言太重，而且非常大的车辆将“严重的战术缺点”。因此，陆军专注于“能量仓库”概念，其中将使用核反应堆和相关的设备来制造来自空气和水中普遍可用的元素的化学燃料。” （<a href="https://twitter.com/whatisnuclear/status/1726009266442850333">来自@whatisnuclear的线程</a>以及图片等）</li><li>牛津是在第一次十字军东征之前成立的。剑桥在大宪章之前。哈佛大学比路易十四大。大学是我们最长期的机构中的一些。他们在帝国的兴衰中幸存下来。它们具有极强的弹性和抵抗力的变化。 （我在<a href="https://www.threads.net/@jasoncrawford/post/CzKMzJaLAJj">线程</a>上， <a href="https://twitter.com/jasoncrawford/status/1720175177990832333">Twitter</a> ）</li><li>比利时1640年代的狗力量：“我遇到了各种各样的小货车，精美的人为，并充满了小贩杂物，由mastiff-dogs绘制，完全像许多教练马一样利用；在大约四个，在其他四个中，就像我观察到的布鲁塞尔本身一样。” （ <a href="https://twitter.com/antonhowes/status/1719314670727680111">@antonhowes</a> ）</li><li><a href="https://twitter.com/culturaltutor/status/1718755912750403766">城市公园是19世纪的发明</a></li><li>“每个人都想要指标，解释事物将如何改变世界，市场规模等。这些都很好，但是我的启发式是&#39;这感觉就像人类从自然手中锻造的魔术吗？&#39;”（ <a href="https://twitter.com/Ben_Reinhardt/status/1725869685516718114">@ben_reinhardt</a> ）</li><li> “只是看到了&#39;为什么我们要在高中教学生微积分？我从不使用它。我的同情很少。微积分具有许多应用程序，并且被许多字段使用。我们也不只是想教学生人们获得的一些最重要的知识吗？” （ <a href="https://twitter.com/itaisher/status/1722419892152938563">@itaisher</a> ）</li><li> “这是非常值得称赞的（来自Katalin Kariko的惊人概况），这是一个可能出现错误的单个验尸。但是没有宾夕法尼亚州或NIH的机构邮政信段的迹象”（ <a href="https://twitter.com/michael_nielsen/status/1721235940717498527">@michael_nielsen</a> ）</li><li><a href="https://twitter.com/dieworkwear/status/1725234349111721992">一切事物的住房理论再次袭来</a></li><li>“公开研发的下降可以解释美国TFP增长的三分之一，从1950年到2018年”（ <a href="https://twitter.com/ArnaudDyevre/status/1724027240143360494">@arnauddyevre</a>通过<a href="https://twitter.com/calebwatney/status/1724144910318641428">@calebwatney</a> ）</li><li> “我永远不会理解为什么关于永久增长的辩论如此突出。只有在我们比当前的富裕时，我们才能永远变得更加富有，这真的无关紧要。而且很明显，我们没有用尽增长的可能性”（ <a href="https://twitter.com/tribsantos/status/1720086824369148374">@tribsantos</a> ）</li><li> “我永远不知道如何使在2100年海平面上升的厄运者中做些什么。 （ <a href="https://twitter.com/Marian_L_Tupy/status/1723737438215197002">@marian_l_tupy</a> ）</li><li> “财富是好的。繁荣是有益的。如果您有特权，您应该感受到的是感激之情，而不是羞耻，那么您应该考虑如何雇用和传递这种繁荣。” （ <a href="https://twitter.com/simonsarris/status/1719065815289299398">@simonsarris</a> ）</li><li><a href="https://twitter.com/celinehalioua/status/1726321979266080879">书籍很重要</a></li><li>“ <a href="https://twitter.com/jasoncrawford/status/1720242739886031239">Chatmogorov的复杂性</a>”：最短的Chatgpt提示的长度可以生成给定的文本</li><li>疲倦：每天都在思考罗马帝国。连线：<a href="https://twitter.com/jonst0kes/status/1722664153394171932">每分钟思考微积分</a></li><li>“您只需搜索诸如&#39;等离子体铁路枪&#39;之类的化妆科幻词，而您最终会在某些Arpa-e幻灯片甲板上恢复了1970年代的概念的一半时间”（ <a href="https://twitter.com/Andercot/status/1724245387794616567">@andercot</a> ）</li></ul><p> <a href="https://pbs.twimg.com/media/F-3ACplaQAABgNM.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/8GThyjQ77BN7Q7vo7/f1b26kyqvnnineignrc9" alt=""></a></p><h2><strong>引号</strong></h2><p>“在肯德尔广场（Kendall Square）是领先的生物技术枢纽之前，它是领先的制造枢纽”（ <a href="https://twitter.com/Atelfo/status/1721711654344245455">@Atelfo</a> ）。罗伯特·布德里（Robert Buderi），<i>期货融合的地方</i>：</p><blockquote><p>在肯德尔广场（Kendall Square）两平方英里的区域内，最伟大的制造业开发项目已经进行了200多种工厂，其投资资本超过100,000,000美元。在这里，事实的搜索者找到了世界上最大的肥皂制造商的家。世界上最伟大的橡胶服装生产商；世界上最大的机械橡胶制造商；世界上最大的工厂专门用于印刷学校和大学教科书；世界上最伟大的写作墨水，胶粘剂，碳纸和打字机丝带的制作人；世界上最大的工厂专门用于糖果制造商；世界上最大的光学商品和光学机械制造商是世界上最大的公路铺路工厂生产商；美国最古老，最大的学校补给室；该国唯一的工业研究实验室。</p></blockquote><p> <a href="https://chronicle.uchicago.edu/951012/chandra.shtml">Subrahmanyan Chandrasekhar</a> （通过<a href="https://twitter.com/michael_nielsen/status/1723119437304459290">@michael_nielsen</a> ）</p><blockquote><p>特别是一个故事说明了钱德拉斯卡（Chandrasekhar）对他的科学和他的学生的奉献精神。在1940年代，当他在威斯康星州威廉姆斯湾大学的Yerkes天文台工作时，他每周开车超过100英里的往返行程，教一班只有两名注册学生。 1957年，整个班级（TD Lee和CN Yang）均赢得了诺贝尔物理学奖，这是对这种承诺的成本效益的任何担忧。</p></blockquote><p>一个通过<a href="https://twitter.com/stewartbrand/status/1724889911378227213">@stewartbrand的</a>故事，他说“这是经营文化的方式”：</p><blockquote><p>牛津新学院的基础相当晚，因此名称。它建立在14世纪后期。与其他大学一样，它也有一个很棒的餐厅，顶部有大橡树梁。这些可能是两英尺平方，长45英尺。</p><p>一个世纪前，我被告知，一些繁忙的昆虫学家带着笔刀走进餐厅的屋顶，戳着横梁，发现它们充满了甲虫。这是给大学委员会的报道，他们感到非常沮丧，因为他们不知道当今他们会在哪里获得这种能力的光束。</p><p>一位初级研究员将他的脖子伸出来，并建议在大学土地上可能有一些橡木。这些大学赋予了全国各地的一块土地。因此，他们打电话给大学森林人，当然已经好几年了，他本身就没有附近，并询问了橡树。然后他拉起了前肢，说：“先生，我们想知道你的时候，我们想知道。”</p><p>经过进一步的询问，发现大学成立后，已经种植了一块橡树，以替换餐厅的横梁，因为它们变得甜蜜时，因为橡木横梁总是在最终变得甜蜜。该计划已经从一个森林人传递到了下一个森林，已有五百年了。 “你不会剪橡树。他们是为了大学礼堂。”</p></blockquote><p> <a href="https://tseliot.com/prose/francis-herbert-bradley">TS Elliot</a> ：</p><blockquote><p>战斗可能有斗争，但从来没有和平。如果我们对原因最广泛，最明智的看法，<strong>那么就没有丢失的原因，因为没有诸如所获得的事业。</strong>我们为失落的事业而战，因为我们知道我们的失败和沮丧可能是我们继任者胜利的序言，尽管胜利本身将是暂时的。我们战斗是为了让某些事物保持活力，而不是期望任何事物都会取得胜利。</p></blockquote><h2><strong>图表</strong></h2><p>“汉尼斯·马尔姆伯格（Hannes Malmberg）的最新<a href="https://worksinprogress.co/issue/how-mathematics-built-the-modern-world">作品</a>中的“出色图”（ <a href="https://twitter.com/antonhowes/status/1724843041024860389">@antonhowes</a> ）</p><p> <a href="https://pbs.twimg.com/media/F-_flBTXoAE61g6.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/8GThyjQ77BN7Q7vo7/r3ebqzubhphckd9n4uht" alt=""></a></p><p>光纤传输的进展（通过<a href="https://twitter.com/varma_ashwin97/status/1722662927650394282">@varma_ashwin97</a> ）。我曾经认为摩尔定律的指数进步是一种独特而惊人的现象。事实证明，指数进步无处不在（不仅在信息技术中）：</p><p> <a href="https://pbs.twimg.com/media/F-ggzYxWsAAzPCc.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/8GThyjQ77BN7Q7vo7/verawzfpw1tb7dv3yzcx" alt=""></a></p><p> “有60％的时间发生57％。歧管市场经过了很好的校准”（ <a href="https://twitter.com/NathanpmYoung/status/1725563206561607847">@nathanpmyoung</a> ）</p><p> <a href="https://pbs.twimg.com/media/F_JuYePWoAAIvbL.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/8GThyjQ77BN7Q7vo7/orj5ets7uhthzdmplua7" alt=""></a></p><p> “当今的好消息：在过去40年中，我们将二氧化硫污染减少了94％（主要解决了酸雨问题）”（ <a href="https://twitter.com/AlecStapp/status/1723162035687428592">@alecstapp</a> ）</p><p> <a href="https://pbs.twimg.com/media/F-nl-93WQAAHbML.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/8GThyjQ77BN7Q7vo7/upk7ascdda2nlnsagw1g" alt=""></a></p><p> “ NEPA环境评论的越来越长……（这种趋势是由诉讼驱动的，不会在不允许改革的情况下停止）”（ <a href="https://twitter.com/AlecStapp/status/1723918780110143662">@Alecstapp</a> ）</p><p> <a href="https://pbs.twimg.com/media/F-yWokSWoAA-uQn.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/8GThyjQ77BN7Q7vo7/wlgc77ovsdagjybctfxc" alt=""></a></p><ul><li> <a href="https://twitter.com/JakeAnbinder/status/1724123168124637251">@JakeAnbinder</a>从他的论文中补充说：“虽然1972年，SF计划委员会的成员抱怨说，他的收件箱中的12页影响声明是难以置信的冗长，仅4年后，加利福尼亚大学的一项计划就建立了两个新的宿舍。导致EIS的运行950页长”</li><li> <a href="https://twitter.com/rSanti97/status/1724121911502803251">@rsanti97</a>补充说：“渐近地，NEPA对未来的评论将是无限的：一张法律地图，是该领土的大小，即可以看到所有事物的Aleph。它需要比所有可能的宇宙中存在的纸张更多，并且永远不会完成”</li></ul><p> “一个自杀率与失业率高度相关的社会（日本，红色），一个完全没有相关的社会（西班牙，蓝色）”（ <a href="https://twitter.com/nick_kapur/status/1723849496256282956">@nick_kapur</a> ）</p><p> <a href="https://pbs.twimg.com/media/F-r_OLHbwAAXOtJ.png"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/8GThyjQ77BN7Q7vo7/p3rh3toktma7vakzbnff" alt=""></a></p><p> “在哪里可以喝自来水是一个相当不错的经济指标（人均GDP）。它大致与人均GDP（PPP）至少为22,000美元的国家 /地区（ <a href="https://twitter.com/pitdesi/status/1721583690340585594">@pitdesi</a> ）</p><p> <a href="https://pbs.twimg.com/media/F-RJ61fakAA7mZz.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/8GThyjQ77BN7Q7vo7/m7ktics0ylajorkexz72" alt=""></a></p><h2><strong>美学</strong></h2><p>“今天走到第51和麦迪逊，看我们的作品，刚刚安装在别墅的房屋上。纽约景观的第一个补充”（ <a href="https://twitter.com/mspringut/status/1721660498989449416">@mspringut</a> ，<a href="https://www.monumentallabs.co/">纪念实验室</a>的创始人）</p><p> <a href="https://pbs.twimg.com/media/F-SRGRGXkAEhoWj.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/8GThyjQ77BN7Q7vo7/cldenm3vtwlooporsopr" alt=""></a></p><br/><br/> <a href="https://www.lesswrong.com/posts/8GThyjQ77BN7Q7vo7/progress-links-digest-2023-11-24-bottlenecks-of-aging#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/8gthyjq77bn7q7vo7/progress-links-digest-2023-11-24-bottlenecks-gage<guid ispermalink="false"> 8GTHYJQ77BN7Q7VO7</guid><dc:creator><![CDATA[jasoncrawford]]></dc:creator><pubDate> Fri, 24 Nov 2023 15:25:07 GMT</pubDate> </item><item><title><![CDATA[What's the evidence that LLMs will scale up efficiently beyond GPT4? i.e. couldn't GPT5, etc., be very inefficient?]]></title><description><![CDATA[Published on November 24, 2023 3:22 PM GMT<br/><br/><p>最近关于Openai，各种事件，未来路径等的许多讨论似乎都假设了GPT4以外的进一步扩展会构成某种“危险”，该危险与计算的数量线性或超线性扩展。因此，如果您插入100倍等等，则会构成极大的危险。</p><p>这似乎并不明显。</p><p> GPT5和进一步的改进似乎很可能非常低效。</p><p>例如，GPT5需要更高的计算，但要好得多。 GPT6比GPT5高10倍，即比GPT4高100倍，但又比中度更好。</p><p>在这种情况下，LLM似乎根本没有任何严重危险。</p><p>这个问题是基于以下事实自我脱离的，即随机人将无法在可见的将来获取该数量的计算。只有拥有数十亿美元的CAP-EX预算的严重政府，机构和公司甚至能够考虑获得更好的东西。</p><p>尽管这些组织不能被认为是完全负责的，但他们仍然很可能负责处理仅几倍更聪明的LLM。</p><br/><br/> <a href="https://www.lesswrong.com/posts/hg9SvxBQw6KFNEzrH/what-s-the-evidence-that-llms-will-scale-up-efficiently#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/hg9svxbqw6kfnezrh/what what s-she-the-that-that-llms-will-scale-scale-ficke效率<guid ispermalink="false">HG9SVXBQW6KFNEZRH</guid><dc:creator><![CDATA[M. Y. Zuo]]></dc:creator><pubDate> Fri, 24 Nov 2023 15:22:02 GMT</pubDate> </item><item><title><![CDATA[Sapience, understanding, and "AGI"]]></title><description><![CDATA[Published on November 24, 2023 3:13 PM GMT<br/><br/><p><i>认知地位：我敢肯定，“ AGI”已经变得很困惑。我认为它忽略了一系列关键的功能。我认为这些密切相关，因此获得它们可以创造能力的跳跃。我不确定最危险的AGI类型的最佳术语，但我想提出一个适当的工作</i><br></p><p>Agi一词变得混乱。现在，它用于AI，无论有没有代理，上下文意识以及积极学习新事实和概念的能力。 “智慧”是指理解，智慧和自我意识，因此可以将其作为一个歧义术语。理解人类的执行是一个积极的过程，是一个积极的过程，用于测试和改善我们的知识。理解允许自我意识和上下文意识。这也暗示代理，因为我们的理解过程是目标定向的。</p><p>我在这里有三个目标。一种是指出“ AGI”一词是如何使X风险讨论混淆的。第二个是讨论人类般的荒谬是如何实现，可以实现和危险的。最后也是我提出了特定术语“智慧”，以实现主动理解提供的一组强大而危险的功能。 <br></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/WqxGB77KyZgQNDoQY/v6qag0yeadyx7l3voc8h"></p><p>理解是测试和改善概念和世界模型中“合适”的积极过程</p><h2>智慧意味着代理和理解</h2><p>代理的概念不仅是哲学上的精神。关于与AI相关的存在风险（X风险）的讨论，这是关键的。在没有明确的理解和明确的处理方式的情况下，这些讨论就变得困惑且潜在地误导了。鉴于AGI的定义差异很大，以及关于风险和能力的分歧，对新术语的需求显而易见。</p><p> “ Sapience”似乎是我们最合适的选择。该术语以各种方式使用，其与智慧或识别的词源有较弱的联系，但其最常见的用法是我们需要的用法。在科幻小说的领域中，通常用来表示一种聪明的自我意识物种与人类不同。我认为这是您可能会吸引更多兴趣/评论的地方。我们作为“同性恋者”，以“理解猿”为荣，使自己与进化的亲戚区分开来。这种自我宣传可能会来自虚荣心，但它引起了我们通常称为“理解”的关键认知能力。</p><h2>人类的理解</h2><p>围绕大型语言模型（LLM）是否真正“理解”其输出的辩论是持久的。批评者认为，LLM缺乏真正的理解，只是在没有更深入的认知处理的情况下回荡单词用法。其他人则认为人类也在很大程度上是“随机鹦鹉”。但是我们做的不仅仅是鹦鹉。如果我适当地使用一个术语，则可以证明对它的“理解”；但这不是我们通常通过理解的含义。它主要是动词。理解是一个过程。我们从当前LLM缺乏的重要，积极的意义上理解。在日常用法中，“理解”意味着积极参与概念。</p><p>说“我理解”是要断言一个人已经参与了一个概念，测试和探索它。这个过程类似于精神上的模拟或“翻转”该概念，以研究其与其他数据和想法的拟合度。例如，了解水龙头的工作方式可能涉及可视化允许水在移动手柄时流动的机制。这些心理模拟可以详细和抽象变化，取决于该概念和索取理解的标准。如果理解似乎无法触及，人们可能会积极追求或提出有关该概念的新假设，并评估它们的潜力来促进理解。</p><p>想象一下，您刚刚学到了有关鸭嘴兽的知识。有人告诉您一些有关此事的事情，您是否正在问自己是否理解。这种积极的自我疑问对于我们的理解观念至关重要，我认为这是通过所谓的认知机构最容易实现的。您问自己是否是出于目的的理解。如果您没有理由理解这个概念，那么您可能不会浪费时间来测试您的理解。如果您确实提出要求，则可能有一些标准以充分理解目前的目的。该目的可能是好奇，渴望表明您了解人们向您解释的事情，或者是部署新概念以实现材料目的的更实际目标。</p><p>要回答您是否充分理解的问题，您将使用一种或多种策略来测试您的理解。您可能会形成对鸭嘴兽的心理模拟，并想象它正在做您关心的事情。这种模拟尝试可能会揭示重要的缺失信息 - 柏拉图史前还是电流？是巨大还是小？您可能会猜测，如果描述了其织布脚，它会游泳。您可能会问自己，如果这些是您的问题，它是可食用还是危险的，并进行心理模拟，探索您可以追捕它的不同方式，或者可以追捕您。</p><p>如果这些模拟产生不一致的结果，则要么预测您知道的事情并不是真的。也许您还没有听说有一只巨大的有毒游泳动物（如果您的大小错误）听起来不协调，或者想像一下毛茸茸的动物产卵是不统治的。如果这些理解测试失败了，您可能会决定花更多的时间试图提高这种理解。您可能会提出问题或寻求更多信息，或者您可以更改假设并尝试更多模拟，以查看这是否与您的世界其他知识更一致。</p><p>我认为很难猜测AI可以很容易地开发这些能力。大型语言模型似乎具有所有必要的能力，并尝试开发可以将这些能力组织成更复杂认知的语言模型认知体系结构。 <span class="footnote-reference" role="doc-noteref" id="fnrefuq7sy0o13e"><sup><a href="#fnuq7sy0o13e">[1]</a></sup></span>如果这些能力像我认为一样有用和可理解，我们可能会看到其他方法也发展了这种积极理解的能力。</p><h2>理解意味着完全的认知通用性</h2><p>这种测试和增强理解的能力在很大程度上是领域，类似于评估和完善工具的设计。因此，这种积极的理解能力包括具有自我意识和上下文意识的能力。这样的系统可以发展对自己的认知过程及其与周围世界的关系。它还提出了一定水平的代理，至少是在追求精炼或增强理解的目标的功能意义上。这些能力可能是如此密切，以至于创建具有一些但不是全部的AGI将很难。</p><p>可能还有其他通往足够功能理解的途径。 LLM不需要类似人类的主动过程来测试和扩展其理解以非常有效地使用概念。我认为将这样的活跃过程添加到代理系统中是相对容易有效的。如果我们首先创建非代理AGI，我认为我们会很快使其成为代理和自我教学，因为这些能力可能相对容易“固定”，因为语言模型的认知体系结构对LLMS的作用。我认为，积极理解技能的实现可能是使我们的认知远远超出我们的祖先的关键成就，而且我认为同样的成就可能会加速AI的能力。</p><p>抛开上述理论，说明AGI可能会采取类似人类的途径来理解，“ Sapience”仍然是一个有效的术语，可以捕获在功能上理解自己及其背景的AGI，并可以扩展其功能理解以实现其目标。</p><h2> “ Agi”是一个危险的含糊的术语</h2><p>AGI现在意味着在许多领域具有功能的AI。但是最初的用法包括代理机构和自我完善的能力。完全一般的情报不仅会做很多事情。它可以教会自己做任何事情。当我们积极理解时，我们会应用代理来提高我们的知识和能力，而AGI也可以充分和最危险的感觉。 Sapient AI不仅在各个领域都具有多功能性，而且能够理解任何事情，包括自我理解和情境意识。理解自己的思维提供了另一个重要的优势：应用自己的智力来优化认知策略的能力（这与递归自我改善的体系结构和硬件无关）。可以积极理解的AI可以发展新的功能。</p><p> Sapience一词呼唤我们的同性恋智者头衔。这个标题是指我们与早期人类之间的关键区别，因此，智慧表明当前狭窄的AI与后续后继者之间有类似的差异，这些区别在理解方面更好。 HOMO HOMO直立取得了适度的成功，但是我们萨皮恩斯占领了世界（并消除了许多没有恶意的物种）。该术语将我们对人类的丰富直觉称为有能力，危险且不断改善的代理人，希望没有太多关于特定人类价值观的直觉（这些与我们指定的较旧的同性恋者更加紧密相关）。</p><p>如今，AGI一词的歧义性在X风险讨论中至关重要。现在，它用于能够执行各种任务的智能，无论智能是否具有代理，自我意识或上下文意识到。这种用法似乎已经从这个术语更广泛的专家，经济学家和技术专家的广泛采用中流失了。他们经常认为AI将是一项技术。<a href="https://www.lesswrong.com/posts/nZYhs48pWsaCCgGfi/agi-isn-t-just-a-technology"><u>但是，如果AGI是一种代理，不仅仅是一种技术</u></a>。在经济背景下，这种区别似乎并不重要，但在X风险讨论中至关重要。我发现和认为的其他现有术语似乎并没有将这种区别视为智慧和/或它们具有其他不必要的含义和直觉。 <span class="footnote-reference" role="doc-noteref" id="fnrefnkvvttfu0j"><sup><a href="#fnnkvvttfu0j">[2]</a></sup></span></p><p>当您的条款被选中时，您可以为将其撤回或转移到新条款而奋斗。我认为战斗是不明智的，因为为术语而战通常不起作用，更重要的是，因为<a href="https://www.lesswrong.com/posts/ou5raNNjamAaahtWG/ai-scares-and-changing-public-beliefs"><u>战斗会导致两极分化</u></a><u>。政策</u>可能会非常糟糕（如果许多专家大声宣布AGI不承担生存风险，则决策者可能会相信，并引用任何适合其议程的团体）。</p><p>因此，引入一个新术语似乎很有用。不同的风险模型适用于Sapient AI，而不是AGI，而没有智慧所隐含的能力。通过区分这些，我们可以解释我们的对话，并更清楚地传达我们面临的最严重风险。人工智慧（AS）或Sapient AI（SAI）是我提出的术语。</p><p>消除我们用于变革性AI的术语似乎是纯粹的胜利。我不确定Sapience是否是歧义的最佳术语，我很想听听其他想法。另外，如果我对积极理解的有用性是正确的，那么我们可能希望在实现此能力时会看到能力跳跃。 </p><p><br></p><p></p><p><br></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnuq7sy0o13e"> <span class="footnote-back-link"><sup><strong><a href="#fnrefuq7sy0o13e">^</a></strong></sup></span><div class="footnote-content"><p>我承认不知道这些复杂过程在大脑中的工作方式，但是认知概述似乎很清楚。我有一些关于如何生物网络可能自然捕捉连续表示之间不一致的想法，以及关于必要决策如何运作的 <a href="https://scholar.google.com/scholar?cluster=2324158456471969700&amp;hl=en&amp;as_sdt=0,6">详细理论</a>。但是，这些积极的理解过程与某种程度上有所不同，其中包括识别不一致的单独组成部分，即使在复杂领域中的决策和计划也不需要。我认为这些是我们在教育期间练习和发展的难题的认知技能。我们的基本大脑机制为创建心理模拟并与其他模拟测试其一致性提供了足够的基础，但是我们可能需要根据这些机制来创建技能。</p><p>当前的LLM似乎具有必要的基础功能，至少以有限的形式具有。他们都可以以语言形式创建模拟，并就多种陈述的一致性做出判断。我担心，我们共同忽略了语言模型认知体系结构可能与实现AGI的近距离。我认为，使用脚本提示来评估布伦奇的硬编码决策树可以提供使我们的能力积极理解的技能。也许GPT4和当前的架构不足以在这种迭代的测试和改善理解过程中获得太多的牵引力。但是，对于我来说，GPT5或GPT6与改进和详细的情节记忆，感觉网络以及编码（或学到的）算法相结合以模仿这种战略认知测序时，GPT5或GPT6似乎具有这种能力，这对我来说是完全合理的。 I discuss the potentials of language model cognitive architectures (a more complete term for language model agents) <a href="https://www.lesswrong.com/posts/ogHr8SvGqg9pW5wsT/capabilities-and-alignment-of-llm-cognitive-architectures">here</a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fnnkvvttfu0j"> <span class="footnote-back-link"><sup><strong><a href="#fnrefnkvvttfu0j">^</a></strong></sup></span><div class="footnote-content"><p> One possible alternative term is superintelligence. I think this does intuitively imply the capacity for rich understanding and extension of knowledge to any domain. But it does not firmly imply agency. More importantly, it also conveys an intuition of being more distant than the first self-aware, self-teaching AI. Artificial sentience does not imply better-then human but merely near-human cognitive abilities. Parahuman AI is another possible term, but I think it too strongly implies human-like, while not pointing as clearly at a capacity for rich and extensible understanding. More explicit terms, like self-aware agentic AGI (SAAAAI?;) seem clumsy. Artificial sentience is another possibility, but sentience is more commonly used for having moral worth by virtue of having phenomenal consciousness and “feelings”. Avoiding those implications seems important for clear discussions of capabilities and x-risk. Agentic AGI might be adequate, but it leaves out the implication of active understanding, contextual awareness and goal-directed learning. But I&#39;m not sure that artificial sapience is the best term, so I&#39;m happy to adopt another term for roughly the same set of concepts if someone has a better idea.</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/WqxGB77KyZgQNDoQY/sapience-understanding-and-agi#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/WqxGB77KyZgQNDoQY/sapience-understanding-and-agi<guid ispermalink="false"> WqxGB77KyZgQNDoQY</guid><dc:creator><![CDATA[Seth Herd]]></dc:creator><pubDate> Fri, 24 Nov 2023 15:13:04 GMT</pubDate></item></channel></rss>