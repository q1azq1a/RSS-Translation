<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 12 月 19 日星期二 06:15:36 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Constellations are Younger than Continents]]></title><description><![CDATA[Published on December 19, 2023 6:12 AM GMT<br/><br/><p>在湾区 Solstice 上，我第一次听到了<a href="https://humanistculture.bandcamp.com/track/bold-orion">Bold Orion</a>这首歌。我很喜欢。然而，它确实有一个问题：</p><blockquote><p>他见证了国王和大陆的兴衰，<br>悄然崛起，大胆的猎户座正在崛起。</p></blockquote><p>猎户座没有见证过大陆的兴衰。星座比大陆年轻。</p><p>大陆变化的时间尺度是十年或几亿年。</p><p>太阳大小的恒星生存和死亡的时间尺度是数十亿年。所以恒星比大陆更古老。</p><p>但星座不是星星或星星群。它们是星星在夜空中形成的图案。</p><p>一些星座的恒星在太空中靠得很近，并通过引力束缚在一起，例如昴宿星团。昴宿星团很可能已经在一起，并且将保持紧密的联系，长达几亿年。我认为它们是最古老的星座。</p><p>大多数星座的恒星在太空中并不是靠得很近。在夜空中的二维投影中，它们距离很近，但与恒星的距离通常却截然不同。它们位于围绕银河系中心的不同轨道上。</p><p>太阳和许多附近的恒星绕银河系中心运行大约需要2.3亿年，但这也不是星座发生变化的相关时间尺度。</p><p>相关的时间尺度是由银河系这部分恒星的速度差异决定的。 <span class="footnote-reference" role="doc-noteref" id="fnrefs6cc67g5ijp"><sup><a href="#fns6cc67g5ijp">[1]</a></sup></span>天文学家对此进行了测量：跟踪大量恒星的位置或亮度的微小变化是天文学家所做的核心工作。</p><p>星座的变化时间尺度为数万年或数十万年。这比大陆的运动要快得多。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YMakfmwZsoLdXAZhb/ludi38yzgzmyofl9xw5o" alt="https://www.halcyonmaps.com/constellations-throughout-the-ages/" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YMakfmwZsoLdXAZhb/olmfgshjliz7ass7vudy 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YMakfmwZsoLdXAZhb/cdvunqy9ustvjc8n5l9f 190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YMakfmwZsoLdXAZhb/jaqyawfk9s1ozk2nuox8 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YMakfmwZsoLdXAZhb/dsfoxp2f9vnwslzukz7z 350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YMakfmwZsoLdXAZhb/rqkh245tuud5xivfq7qm 430w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YMakfmwZsoLdXAZhb/wkkmokrq3vfjuldhqhnu 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YMakfmwZsoLdXAZhb/iyacrtr2hhih4vlspn45 590w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YMakfmwZsoLdXAZhb/zeoz1a3cuuspeorrwnzw 670w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YMakfmwZsoLdXAZhb/w40bfmsyy7fwqnlyngre 750w"></figure><p>猎户座是一个不寻常的星座。从上图可以看出，其最亮的 7 颗恒星的位置变化比其他星座要慢。</p><p>猎户座中的许多恒星实际上都是相关的。它们形成了一个<a href="https://simple.wikipedia.org/wiki/Orion_OB1_Association">恒星协会</a>：它们在相似的时间形成，以相似的方式运动，并且存在微弱的引力相互作用。猎户座的恒星很可能会在星座内移动，但其中许多恒星将终生保持彼此靠近。目前猎户座中的一些较暗的恒星并不属于恒星协会，只是路过。</p><p>恒星协会中的恒星都很年轻：最多大约1200万年。参宿七（猎户座最亮的恒星）已有 800 万年的历史。 Alnilam 已有 600 万年的历史。阿尔尼塔克已有 700 万年的历史。 Saiph已有1100万岁了。</p><p>这些恒星也异常大且明亮。恒星越大，它的寿命就越短。猎户座中大多数明亮的恒星都不会活到 2000 万岁。</p><p>参宿四通常是猎户座第二亮的恒星，它很特别。它明显呈红色，并且亮度波动剧烈。它大约800万年前在恒星协会中形成，但现在正在离开。它不会走得太远。大约10万年内，参宿四将变成超新星，并像半月一样明亮，持续三个月。明亮到令人敬畏，但又暗淡到不危险。</p><p>大多数星座会随着恒星之间的相对移动而发生变化，时间尺度为数万年或数十万年。在其明亮的恒星燃烧并变成超新星之前，猎户座将持续更长时间，长达数百万年。这些时间都不足以观察大陆的兴衰。 </p><figure class="media"><div data-oembed-url="https://www.youtube.com/watch?v=MK6v9G06Ks8"><div><iframe src="https://www.youtube.com/embed/MK6v9G06Ks8" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div></figure><p></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fns6cc67g5ijp"> <span class="footnote-back-link"><sup><strong><a href="#fnrefs6cc67g5ijp">^</a></strong></sup></span><div class="footnote-content"><p>如果将恒星本身视为银河系“气体”中的单个“原子”，这就是一种“温度”。这个类比并不完美。与气体中的原子不同，恒星几乎不会发生碰撞，即使发生碰撞也不会相互反弹，因此不存在相同意义上的“压力”。</p><p>螺旋星系中的恒星之所以大多沿着相似的轨道运动，是因为恒星之前的气体云具有压力、冲击波和其他流体现象，导致其失去角动量并最终成为旋转的圆盘。恒星只是继承了这种运动模式。如果发生任何事情扰乱了许多这样的轨道，比如与类似大小的星系碰撞，轨道将变得随机，星系将变成椭圆形而不是螺旋形。粗略地说，螺旋星系是自大部分恒星形成以来从未发生过重大碰撞的星系，而椭圆星系是发生过重大碰撞的星系。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/YMakfmwZsoLdXAZhb/constellations-are-younger-than-continents#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/YMakfmwZsoLdXAZhb/constellations-are-younger-than-Continents<guid ispermalink="false"> YMakfmwZsoLdXAZhb</guid><dc:creator><![CDATA[Jeffrey Heninger]]></dc:creator><pubDate> Tue, 19 Dec 2023 06:12:40 GMT</pubDate> </item><item><title><![CDATA[The Dark Arts]]></title><description><![CDATA[Published on December 19, 2023 4:41 AM GMT<br/><br/><section class="dialogue-message ContentStyles-debateResponseBody" message-id="n6LYNw2uGfYnD4pX2-Tue, 19 Dec 2023 02:33:03 GMT" user-id="n6LYNw2uGfYnD4pX2" display-name="lsusr" submitted-date="Tue, 19 Dec 2023 02:33:03 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>lsusr</b></section><div><p>据我了解，您赢得了今年所有公共论坛辩论。这非常令人印象深刻。我认为讨论您使用的一些技术会很有趣。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dmpkaSGausDyieBmj-Tue, 19 Dec 2023 02:56:20 GMT" user-id="dmpkaSGausDyieBmj" display-name="Lyrongolem" submitted-date="Tue, 19 Dec 2023 02:56:20 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>莱龙古雷姆</b></section><div><p>当然！因此，为了向那些不了解的人提供一个简单的概述，<strong>公共论坛</strong>是一种 2v2 辩论形式，通常针对政策主题。更有趣的一个是我去的最后一个，主题是“已解决：美国联邦政府应大幅增加其在北极的军事存在”。</p><p>现在，我将在这里介绍的技术与该主题具体相关，但它们也适用于其他形式的辩论，以及一般的论证。为了简单起见，我将其称为“ultra-BS”。</p><p>所以，我们大多数人都熟悉“常规”BS。这个想法是对方说了些什么，你只需回答“你错了”，或者相当于“nu-uh”。通常在较低级别的辩论中，这正是发生的情况。你没有真正的回应，而且这是很明显的，即使对于那些没有经济或政治素养可言的法官来说也是如此。</p><p>基本上，“Ultra-BS”是同一事物的下一个层次。你精心设计了一个明显是废话的论点，其中包含了一定的逻辑。让我以我对上述决议的一个论点为例。我认为，如果我们允许俄罗斯控制北极，核世界末日就会终结美国。</p><blockquote><p>现在，我知道我听起来显然已经疯了，但请听我说完。俄罗斯的“匕首”高超音速导弹射程约为 1,000 英里，无法从俄罗斯本土攻击美国。但他们可以从北极袭击我们。我补充说，高超音速导弹非常非常快。 [这本质上是对我对手的反驳的先发制人的反驳（但是MAD呢？）。]如果我们被第一次打击摧毁，那么就没有MAD，并且将北极交给俄罗斯将立即成为生存威胁。</p></blockquote><p>当然，这很荒谬，但请暂时站在我的对手的立场上思考一下。你打算如何回应这个问题？你不知道俄罗斯的核学说是什么。你从来没有研究过或关注过地缘政治。你无法获得任何类似于高超音速导弹如何工作或各国如何应对它们的连贯模型的东西。至关重要的是，你也没有做任何准备，因为我只是把这个从我的屁股里拉出来。</p><p>你现在完蛋了。不是因为我是对的，而是因为我成功地构建了一个连贯的事件叙述，而你没有专业知识来反驳。这不是什么高水平的超级操纵技术。然而，我认为这描述了大多数黑暗艺术。如果你认真思考的话，其实很无聊，不需要真正的努力。 （事实上​​，我发现真正的智力对话和真正的参与更费力。）</p><p>请允许我再举一个例子。该决议为“已解决：美国联邦政府应免除所有学生贷款债务”。在这里，我正在争论（逻辑上和事实上）不可能的肯定立场。对于任何一组经济学家来说，你都可能得出同样的结论。这是一个非常糟糕的主意。但是……我的对手不是经济学家。</p><blockquote><p>所以我赢了。我的案子没有事实依据。我的观点是：1.大学教育有助于教育选民（可能？），防止像特朗普这样的领导人当选。 2. 种族和经济分歧导致国家两极分化，从整体上看是不可取的。两者都是不可量化且无法权衡的。我不能说“ <i><strong>X</strong></i>条生命”或“ <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>如果我们不免除债务，就会损失“大量金钱”。我只是停留在抽象层面。因此，我的案子是无敌的。真正的辩论者会发现我的论点“没有实质内容”。但法官不是辩论者，所以这一点已经没有意义了。现在，我要做的就是反驳对手所说的一切。</p></blockquote><p> Ultra-BS 再次出击！关键是不要对事实提出异议。这是为了解释（尽管令人费解），无论你的对手提出什么事实，实际上都支持你的观点。例如，辩论的关键点之一是贝内特假说（只要政府提供补贴，学费就会上涨），这实际上是一个无可争议的观点。我通过同意我的对手来扭转局面。然后我接着说：“补贴当然不好，我们不应该让学生接受掠夺性贷款。”</p><p>但是……需要注意的是……“然而，现在我们整整一代学生的生计都被欺骗了，无法养家糊口。”判断一下，现在有人在受苦。我们同意这不应该发生，但我们的对手没有提供任何解决方案......</p><p>等等等等。当我们第一次演讲时，我的对手看起来很放松。他们知道我们的争论很糟糕。但当我提出反驳时，他们立即坐了起来，他们的懒洋洋的行为变成了疯狂的打字。他们知道，无论这个回应多么狗屎，它都将毁掉他们的整个案子。</p><p>但逻辑的操纵并没有就此结束。我仍然认为“补贴”（即：向学生提供更多资金）与贷款减免不同。这一点在经济上是显而易见的，但我不使用经济论证，而是使用类比。我告诉法官设想一家超市。首先，想象一下如果政府为你每花 1 美元配捐 1 美元，会发生什么。然后想象一下，如果他们在事后简单地原谅你为杂货支付的价格。</p><p>通过这样做，我能够过度简化经济概念。我怀疑我的对手对经济有很多了解，但他们完全惊呆了。据他们所知，我不仅仅是在胡说八道，我实际上是对的。我没有对证据提出异议，而是只是以不同的方式对其进行分析。这样一来，事实就不再重要了。欢迎来到影子王国。</p><p>好的一面是我从不大喊大叫、提高声音，甚至不公然撒谎。在法官眼中，我是理性的声音，当我的对手咆哮并试图斥责我的胡言乱语时，我冷静下来并礼貌地反驳他们（但没有成功）。</p><p>因此，我在没有提供任何实质性论据的情况下，仅通过控制叙述就赢得了胜利。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="n6LYNw2uGfYnD4pX2-Tue, 19 Dec 2023 03:06:34 GMT" user-id="n6LYNw2uGfYnD4pX2" display-name="lsusr" submitted-date="Tue, 19 Dec 2023 03:06:34 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>lsusr</b></section><div><p>让我尝试总结一下您的策略是如何运作的。您需要根据特定领域的知识（例如政府补贴的经济学或高超音速技术在核学说中的地位）提出一个论点。</p><p>如果你的对手拥有特定领域的知识，那么你就输了。但你打赌你的对手不会（到目前为止，他们还没有）。因为他们不这样做，所以他们缺乏反驳你所需的专业知识，而你已经为这个知识领域做好了仔细的准备。我对你的理解正确吗？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dmpkaSGausDyieBmj-Tue, 19 Dec 2023 03:18:58 GMT" user-id="dmpkaSGausDyieBmj" display-name="Lyrongolem" submitted-date="Tue, 19 Dec 2023 03:18:58 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>莱龙古雷姆</b></section><div><p>是的，但不完全是。我想说“Ultra-BS”是一种需要一些东西才能发挥作用的技术。</p><p> 1.<strong>缺乏可证明性。</strong>您可以提出您想要的所有分析，并按照您认为合适的方式重新解释现实。但最终，你错了。我可以使用 Ultra-BS 并说俄罗斯军队明天将是基辅。这不起作用。如果我被迫验证一个预测（就像我们在现实世界中所做的那样），我很快就会失去信誉。</p><p> 2 <strong>、缺乏权威证据。</strong>辩论之所以有效，部分原因在于法官对他们听到的每一个引用来源都没有可信度评级，因此通常无法区分真正的主题专家和在博客上乱搞的随机统计学家。我们已经让一些团队拿出卡片说发生核战争的可能性为 95%。假设法官实际上知道他们可以信任哪些专家，该策略失败了，他们对事件有连贯的叙述。</p><p> 3.<strong>缺乏强有力的先前意见。</strong>不言自明，我不会用废话来改变任何人对他们关心的话题的政治信仰）</p><p>基本上，你需要在一个言辞比实际正确更重要的环境中运作。你可以在政治中看到这样的环境，类似于辩论。如果真相真的很重要，那么你就有麻烦了。然而，这在辩论中并不重要，主要是因为团队没有必要的时间来提出事实正确的案例。</p><p>诉诸情感很容易。 “法官大人，如果我们不这样做，穷人就会变得更穷，而比尔·盖茨会走得更远！”诉诸事实是困难的。你需要时间，也需要证据。我花了十秒钟的时间来解释为什么高超音速是一种可信的先发打击能力，而我的对手却用了整个演讲来给出适当的反驳。简而言之，进攻比防守容易，所以防守能力好并不重要（至少事实上）。</p><p>我记得有一次，我的对手拿出证据说，学生贷款减免对经济有净积极作用。我本可以用常识来对付他们，但这会花费太长时间。我选择称呼他们的来源作者的名字。所以从这个意义上说，我想我可以说特定领域的知识是相关的，但大多数情况下不是。即使专家知道我在撒谎，他们也需要说得足够好，才能在合理的时间内让法官相信我听起来合理的论点是错误的。不是一个轻问。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="n6LYNw2uGfYnD4pX2-Tue, 19 Dec 2023 03:23:21 GMT" user-id="n6LYNw2uGfYnD4pX2" display-name="lsusr" submitted-date="Tue, 19 Dec 2023 03:23:21 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>lsusr</b></section><div><p>你叫作者什么名字？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dmpkaSGausDyieBmj-Tue, 19 Dec 2023 03:26:33 GMT" user-id="dmpkaSGausDyieBmj" display-name="Lyrongolem" submitted-date="Tue, 19 Dec 2023 03:26:33 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>莱龙古雷姆</b></section><div><p>哦，平常的。我称他为网络博主、随机记者、“不可靠的消息来源”等等。我的想法并不是要抹黑他，而是要引起怀疑。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="n6LYNw2uGfYnD4pX2-Tue, 19 Dec 2023 03:31:29 GMT" user-id="n6LYNw2uGfYnD4pX2" display-name="lsusr" submitted-date="Tue, 19 Dec 2023 03:31:29 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>lsusr</b></section><div><p> “网络博主。”给某人打电话是多么可怕的诽谤。</p><p>您写的是竞争性辩论，但您所描述的原则也适用于现实政治。表面上，可证明性在政治中很重要。实际上，情况并非如此。 （只需看看共产主义的历史，或当今的学生贷款政治即可。）</p><p>我认为更大的区别实际上是时间的预算方式。在竞争性辩论中，每个团队都获得平等的时间。在政治中，时间是根据人们对你创建的媒体的喜欢程度来分配的。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dmpkaSGausDyieBmj-Tue, 19 Dec 2023 03:35:41 GMT" user-id="dmpkaSGausDyieBmj" display-name="Lyrongolem" submitted-date="Tue, 19 Dec 2023 03:35:41 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>莱龙古雷姆</b></section><div><p>（没错！没有什么比一个人整天坐在地下室里胡乱发帖更能毁掉他的可信度了！）</p><p>我想我同意，但只是在有限的程度上。至少在我看来，可信度是更重要的因素（见上面的第 2 点）。</p><p>大多数人都不是主题专家，也不合理地期望他们成为主题专家。对于大多数话语，我们依赖于具有专业知识的个人，他们能够就问题发表权威性的言论。如果气候科学家说气候变化即将到来，我们只需相信气候科学家。如果气候科学家不可信，我们就会看到现代景观。 （人们无法鼓起勇气真正应对气候变化，否认者无处不在，总体反应陷入瘫痪。）</p><p>军事事务、地缘政治、治理和大多数重要事务也大体相同。您不会希望普通人成为自己的医生或律师。我认为问题在于专家/媒体不再具有可信度。现在我们面临的问题是每个人都生活在自己的世界中，无法弄清楚他们应该相信什么。我认为这是一个严重的问题，也是极端废话得以发挥作用的部分原因。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="n6LYNw2uGfYnD4pX2-Tue, 19 Dec 2023 03:38:49 GMT" user-id="n6LYNw2uGfYnD4pX2" display-name="lsusr" submitted-date="Tue, 19 Dec 2023 03:38:49 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>lsusr</b></section><div><p>如果你想知道基督教是否真实，那么你应该问牧师。毕竟，他们是基督教方面的专家。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dmpkaSGausDyieBmj-Tue, 19 Dec 2023 03:54:10 GMT" user-id="dmpkaSGausDyieBmj" display-name="Lyrongolem" submitted-date="Tue, 19 Dec 2023 03:54:10 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>莱龙古雷姆</b></section><div><p>是的，我想我应该稍微限定一下我的观点。可信度很重要，但最终我们需要在信任和怀疑之间保持健康的平衡。我的意思也不是在个人层面上。我指的是社会对整个机构的信任。</p><p>我将举五角大楼文件的例子。这些泄密事件基本上破坏了美国对许多机构的信任，特别是对军队和总统的信任。公众的看法从“总统不会撒谎”转变为“他们当然撒谎，他们都会撒谎”。这是一个根本性的转变，从承认人类的缺陷到对该机构背后的动机深表怀疑。</p><p>当我发表评论时，我主要担心的是人们（不一定是由于他们自己的过错）成为信誉差距的受害者。不是良性意义上的，即政府/专家本意良好但信息错误，而是他们不值得被信任，并决心损害社会（通常是为了他们自己的利益）。我更多地谈论的是部落主义的反应，我认为这是对缺乏中央信誉的反应。人们不让事实自己说话，而是倾听那些为事实说话的人。结果是社会或政治团体无法接受某些想法，仅仅因为他们是竞争对手的外团体的一部分。我可以与美国的民主党人和共和党人进行更详细的交流，但我认为没有必要。我想所有读者都已经非常熟悉了。</p><p>我主要是在谈论“后真相”现象，一切都充满疑问。我发现这非常危险，在面临气候变化（或越来越多的威权主义）等重大威胁时，可能会破坏社会凝聚力。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="n6LYNw2uGfYnD4pX2-Tue, 19 Dec 2023 04:06:42 GMT" user-id="n6LYNw2uGfYnD4pX2" display-name="lsusr" submitted-date="Tue, 19 Dec 2023 04:06:42 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>lsusr</b></section><div><p>我们根本不需要信任和怀疑之间的平衡。我们需要对我们所倡导的一切有 100% 的信任。建立中央信誉的最佳方法是压制或抹黑所有不同的声音。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dmpkaSGausDyieBmj-Tue, 19 Dec 2023 04:17:13 GMT" user-id="dmpkaSGausDyieBmj" display-name="Lyrongolem" submitted-date="Tue, 19 Dec 2023 04:17:13 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>莱龙古雷姆</b></section><div><p>是啊。我想我在这一点上还不够详细。可信度对于解决大规模问题很重要，但实际上正确也很重要。如果“气候变化是假的”会导致所有人死亡，那么无论“气候变化是假的”这一说法有多么可信，都毫无意义。</p><p>从这个意义上说，我想说，可信度是黑暗艺术技术的一剂强大的解药，因为那些没有专家水平知识的人能够相信专家水平的主张。但是，如果专家们是善意的，并且我们得到了一个很好的现实地图，那么这只会导致一个更好的网络社会。 （如果因为气候科学家玩地位游戏而夸大了气候变化的威胁，那么我们就有麻烦了。）</p><p>冒着偏离主题的风险，我想粗略地向社会问题表示敬意。我想我主要的抱怨是，人们放弃中央权威，转而寻求最终更加可疑的可信度来源。我想到那些从推特上获取新闻的人，他们更喜欢自己喜欢的名人的观点而不是主题专家，并且默认的部落主义倾向使得协调解决可怕的问题变得困难。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="n6LYNw2uGfYnD4pX2-Tue, 19 Dec 2023 04:28:18 GMT" user-id="n6LYNw2uGfYnD4pX2" display-name="lsusr" submitted-date="Tue, 19 Dec 2023 04:28:18 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> <b>lsusr</b></section><div><p>在练习黑暗艺术时，你的最终目标是建立自己一方的可信度，使别人对你的信任不会因为你所说的是否属实而受到影响。建立信誉是终极的黑暗艺术。</p><p>当五角大楼文件出现时，人们感到震惊。这种情况在斯诺登泄密事件和新冠病毒事件中再次发生。它一次又一次地发生。自从马丁·路德将他的《九十五条论纲》钉在教堂门上以来，这种情况就一直在发生。黑暗面已经赢了。在文字发明之前，它默认获胜。</p><p>今天的怀疑主义是黑暗中的蜡烛。黑魔法的使命就是消灭它。通过建立信誉。</p><p>为了协调。</p><p>为了真理。</p><p>为了更大的利益。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dmpkaSGausDyieBmj-Tue, 19 Dec 2023 04:36:31 GMT" user-id="dmpkaSGausDyieBmj" display-name="Lyrongolem" submitted-date="Tue, 19 Dec 2023 04:36:31 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>莱龙古雷姆</b></section><div><p>哦？我认为这是一个非常新颖的想法，我不同意，但我需要相当长的时间才能解释这一切。我想我可能会在后续对话中提出这个问题。</p><p>不过，就我个人的结论而言，我认为黑魔法是一件坏事，除非在受控的情况下，否则不应该轻易使用。就像生物武器一样，它们对你自己造成的伤害与你的目标造成的伤害一样多。我们可以在邪教、民粹主义运动、操纵关系等等中看到这一点。我觉得对这些技术的认识非常有用，但它们在很多情况下的实践是值得怀疑的。 （我对黑魔法政治家的评价并不高，即使他们无处不在。）</p><p>也就是说，感谢您的讨论。我真的很喜欢它，我期待着人们的任何评论。</p></div></section><div></div><br/><br/><a href="https://www.lesswrong.com/posts/djWftXndJ7iMPsjrp/the-dark-arts#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/djWftXndJ7iMPsjrp/the-dark-arts<guid ispermalink="false"> djWftXndJ7iMPsjrp</guid><dc:creator><![CDATA[lsusr]]></dc:creator><pubDate> Tue, 19 Dec 2023 04:41:13 GMT</pubDate> </item><item><title><![CDATA[When scientists consider whether their research will end the world]]></title><description><![CDATA[Published on December 19, 2023 3:47 AM GMT<br/><br/><p>尽管目前对于人工智能的未来影响尚未达成共识，但<a href="https://aiimpacts.org/how-bad-a-future-do-ml-researchers-expect/"><u>许多</u></a>专家<a href="https://wiki.aiimpacts.org/arguments_for_ai_risk/views_of_ai_developers_on_risk_from_ai"><u>警告</u></a>称，该技术的持续进步可能会导致人类<a href="https://www.safe.ai/statement-on-ai-risk"><u>灭绝</u></a>等灾难性后果。有趣的是，提出这一警告的一些专家是那些在积极开发前沿人工智能系统的实验室工作或以前工作过的人。这种不寻常的情况提出了人类几乎没有经验的问题。如果一个科学项目可能危害整个世界，那么谁应该决定该项目是否继续进行？对于人类灭绝等结果，决策者应该接受多大的风险？<br><br>虽然专家们很少考虑他们的研究是否会导致灾难性后果，但这也并非完全史无前例。下面，我将讨论我能找到的一些相关历史例子，然后是一些可能的结论。</p><h1>例子</h1><h2>1942 年至 1945 年：曼哈顿计划的科学家们考虑一颗原子弹是否会点燃整个地球。</h2><p>在曼哈顿计划期间，<a href="https://www.insidescience.org/manhattan-project-legacy/atmosphere-on-fire"><u>一些科学家担心</u></a>他们正在建造的原子弹可能会产生足够的热量来引发连锁反应，从而点燃大气层并迅速结束地球上的所有生命。与新技术带来的许多风险不同，这一风险无法通过实验直接评估，因为不会有幸存者观察到实验的负面结果。幸运的是，人们对相关物理学有足够的了解，可以仅通过理论和计算来评估风险。更幸运的是，计算表明大气点火的可能性非常小——或者至少不太可能让科学家们继续引爆用于三位一体测试的第一颗原子弹。</p><p>关于科学家认为风险有多小以及他们认为可以接受的风险大小，历史记录有所不同：</p><blockquote><p> <i>[阿瑟·康普顿]说，如果经过计算，证明地球被原子爆炸蒸发的可能性超过<strong>百万分之三</strong>，他就不会继续这个项目。计算证明数字略少——并且该项目继续进行。</i><br> -1959 年，赛珍珠 (Pearl S. Buck) 回忆起她与曼哈顿计划期间冶金实验室负责人阿瑟·康普顿 (Arthur Compton) 的一次谈话。</p></blockquote><blockquote><p><i>从来没有“略低于百万分之三的概率”……点火不是概率问题；而是概率问题。这<strong>根本不可能</strong>。</i><br> ——汉斯·贝特，曼哈顿计划期间 T 部门的领导者，1976 年</p></blockquote><p>阿瑟·康普顿从未对巴克的说法提出异议， <span class="footnote-reference" role="doc-noteref" id="fnref2h0213rjfu8"><sup><a href="#fn2h0213rjfu8">[1]</a></sup></span>因此康普顿可能确实认为 3 x 10 <sup>-6</sup> （百万分之三）的灭绝可能性是可以接受的。尽管汉斯·贝特 (Hans Bethe) 的对比说明显示了对风险可能性的一些分歧，但唯一记录在案的确定风险可接受限度的尝试是康普顿 (Compton) 的。</p><p>很难说康普顿接受 3x10 <sup>-6</sup>大气点火的可能性是否合理。这是一个很小的数字，与<a href="https://en.wikipedia.org/wiki/Micromort#Leisure_and_sport"><u>一次跳伞死亡的几率</u></a>处于同一数量级。但当谈到让地球着火时，多小才算足够小呢？衡量风险的一种方法是找到它所对应的预期死亡人数，但答案因所使用的假设而异：</p><ul><li>如果曼哈顿计划的科学家们只赋予当时活着的人类道德价值，那么他们可以将 1945 年世界人口<a href="https://www.atlasofhumanity.com/humanpopulationthroughtime"><u>约 23 亿</u></a>乘以康普顿阈值概率 3x10 <sup>-6</sup> ，预计将造成<strong>7000 人伤亡</strong>。</li><li>作为一个从 1945 年的角度生活在“未来”的人，我强烈希望他们也对生活在他们时代之后的人类赋予道德价值。 <a href="https://globalprioritiesinstitute.org/wp-content/uploads/Toby-Newberry_How-many-lives-does-the-future-hold.pdf"><u>一项分析</u></a>估计，未来人类的数量可能在 10 <sup>13</sup>到 10 <sup>54</sup>之间，因此 3x10 <sup>-6</sup>的灭绝几率<strong>相当于 3000 万到 3x10 <sup>48</sup>的人员伤亡</strong>。</li></ul><p>人类灭绝的可能性有百万分之三，这显然是一个严重的风险，但考虑到康普顿和他的同事们认为曼哈顿计划的重要性，这可能是合理的。康普顿在接受巴克采访时明确表示，他认为赌注极高，并表示“接受纳粹的奴役比冒着为人类画上最后帷幕的机会更好”。</p><p>由于曼哈顿计划要求保密，公众直到许多年后才知道大气点火的风险。对风险的评估以及如何处理风险的决定可能是由相对少数的科学家和政府官员做出的。 </p><figure class="image image_resized" style="width:61.82%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/oo3lpmhup6cjgms8gr4h" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/ulqiriywikeeebvvcei2 210w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/e4obkt5t0peyijo5fovm 420w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/wyhaqipsps25mlip4tmn 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/dh3tkl7xfa3vxwovo5y5 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/oh2wbrmzgkf0rgl0gbsm 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/v3dwrnvuinqhmo3fl1qm 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/dzhxjpk7uvkacemsjuva 1470w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/i8jciakgolyw9zid9fmd 1680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/gg5ckd3qnoysydyyixqa 1890w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/pjcpq2kjvylxzvib6w8m 2048w"><figcaption> <i>“汉斯·阿尔布雷希特·贝特（1906-2005）接受记者采访。” -</i><a href="https://www.flickr.com/photos/25053835@N03/4729461869"><u>史密森学会</u></a></figcaption></figure><h2>1973 年至 1975 年：生物学家考虑重组 DNA 研究是否会产生致命的病原体。</h2><p>基因重组方法在 20 世纪 70 年代初迅速发展，使多种生物体的 DNA 的组合变得更加容易，并<a href="https://intelligence.org/files/TheAsilomarConference.pdf"><u>导致一些生物学家开始担心</u></a>他们的研究可能会产生致命的新病原体。 1972 年，生物化学家 Paul Berg 和他的同事将一种致癌病毒的 DNA 与生活在<i>人类</i>肠道中的大肠杆菌的 DNA 结合起来。伯格计划将这种重组 DNA 插入<i>大肠杆菌</i>中，但他的同事说服他停止了实验，因为担心改变的细菌可能会走出实验室并危害世界。</p><p>出于这些担忧，美国国家科学院 (NAS) 成立了一个由伯格担任主席的委员会来评估风险。 1974 年，委员会要求暂停某些类型的重组 DNA 实验。尽管生物学家之间存在分歧，但仍坚持暂停。</p><p> 1975 年，科学家、律师和政策制定者齐聚阿西洛玛重组 DNA 分子会议，决定是否取消暂停。十二名记者也被选中参加会议，<a href="https://www.youtube.com/watch?v=C-xKuICTMpY"><u>可能是</u></a>因为担心最近水门事件后的掩盖指控。会议最终<a href="https://www.pnas.org/doi/pdf/10.1073/pnas.72.6.1981"><u>得出的结论</u></a>是，大多数重组DNA研究应在严格的指导方针下进行，但涉及高致病性生物或有毒基因的实验应被禁止。该指南被美国国立卫生研究院采纳为资金要求。</p><p>与曼哈顿计划的物理学家不同，20 世纪 70 年代的生物学家没有足够的理论知识来自信地评估风险并围绕风险达成共识。目前尚不清楚他们认为重组 DNA 带来的风险有多大可能性或严重程度。 2015 年，伯格表示，“如果你采样了我们的真实感受，委员会成员就会认为这些实验可能<strong>风险很小或没有风险，但是……没有人可以说风险为零</strong>。”会议结束后的几十年里，重组 DNA 实验大多是安全的，许多指南随着时间的推移逐渐缩减。 2007年，伯格表示，他们“高估了风险，但[他们]没有数据作为决策依据，选择谨慎的做法是明智的”。 </p><figure class="image image_resized" style="width:70.35%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/j8675kkbglpfcrc6gng2" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/xrnoehe2lhtkb4vmtkci 350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/uxe7faavqba5cyckeoxn 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/uw6zspdzdu46henzl1qv 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/yu4et0hkb9vhmovzvlrq 1400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/jzfoawjkbnbppmyoklba 1750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/uhwvvh2ptvm4rvijdgfs 2100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/acozhubvmhph6hpsvgxk 2450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/xxpvu8qcfobcs9c3zisc 2800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/lnwhnyqycl4plhyymaib 3150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/shyibycm5nkkqgip9oo3 3472w"><figcaption> <i>“博士。 Maxine Singer、Norton Zinder 博士、Sydney Brenner 博士和 Paul Berg 博士在阿西洛玛重组 DNA 会议上</i>” -<i> </i><a href="https://collections.nlm.nih.gov/catalog/nlm:nlmuid-101441127-img#"><u>国家医学图书馆</u></a>。</figcaption></figure><h2> 1999 年：物理学家考虑重离子对撞机实验是否会毁灭地球。</h2><p> 1999 年，即相对论重离子对撞机 (RHIC) 在布鲁克海文国家实验室 (BNL) 开始运行的前一年，媒体报道公众开始担心该对撞机可能会产生微型黑洞，从而毁灭地球。为了回应这些担忧，BNL 主任召集了一个物理学家委员会，撰写了一份应对风险的报告。</p><p>该<a href="https://arxiv.org/pdf/hep-ph/9910333.pdf"><u>报告由 Busza 等人撰写，</u></a>结合理论和经验证据证明 RHIC 不太可能造成灾难。该报告评估了 RHIC 推测的三种类型的灾难性风险，但主要关注危险的“奇异子”风险。 <span class="footnote-reference" role="doc-noteref" id="fnreftjh4wf35yqj"><sup><a href="#fntjh4wf35yqj">[2]</a></sup></span>在报告中，作者表示，与奇异子形成相关的理论论证本身就足以“自信地排除 RHIC 的任何安全问题”。他们还根据观察结果提出了实证论证，即尽管受到宇宙射线的不断轰击，月球并未被摧毁。基于这些经验证据，他们根据所做的假设得出了从<strong>10 <sup>-5</sup></strong> （万分之一）<strong>到 2×10 <sup>-11</sup></strong> （千亿分之二）的概率上限。</p><p><a href="https://cds.cern.ch/record/405010/files/9910471.pdf"><u>另一份报告的作者由 Dar 等人撰写。</u></a>并由 CERN 发表，使用了关于超新星频率的类似经验论证来计算 RHIC 产生危险奇异子的可能性的上限为<strong>2x10 <sup>-8</sup></strong> （一亿分之二）。</p><p>对于如此严重的风险的可接受限度，这些物理学家有何看法？达尔等人。将其 2x10 <sup>-8</sup>的界限描述为“安全且严格的上限”。 Busza 等人在论文的<a href="https://arxiv.org/pdf/hep-ph/9910333v1.pdf"><u>第一个版本</u></a>中。将他们的界限描述为“一个舒适的误差范围”，但在最终版本中，他们相反说“我们不会尝试确定<i>p</i>可接受的上限，也不会尝试进行‘风险分析’，权衡不良事件发生的概率及其后果的严重程度。”</p><p>次年，物理学家阿德里安·肯特发表了一篇批评达尔等人的<a href="https://arxiv.org/pdf/hep-ph/0009204v6.pdf"><u>论文</u></a>。和布萨等人。因为他们对风险的评估缺乏细微差别。 Kent 指出，即使不考虑未来的生命，Dar 等人提出的 10 <sup>-8</sup>的“安全且严格的上限”也意味着十年内预计会造成<strong>120 人伤亡</strong>。他表示，“尽管 RHIC 有好处，但如果确定（例如，由于某些辐射危害）会造成 120 人死亡，该实验将不会被允许进行。”</p><p>肯特使用涉及已确定的辐射危害风险承受能力的粗略计算，提出如果不考虑未来的生命和<strong>10</strong> ，灭绝风险的可接受上限应为每年<strong>10 <sup>-15</sup></strong> （万亿分之一）。如果考虑到未来的生命，每年<strong><sup>-22</sup></strong> （百亿万亿分之一）。 <span class="footnote-reference" role="doc-noteref" id="fnrefo6br352o0or"><sup><a href="#fno6br352o0or">[3]</a></sup></span>他还认为，项目的可接受风险界限应进一步提前确定，并由未积极参与该项目的专家达成一致。 <span class="footnote-reference" role="doc-noteref" id="fnreff4gbc3hx4xt"><sup><a href="#fnf4gbc3hx4xt">[4]</a></sup></span> </p><figure class="image image_resized" style="width:68.5%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/aqjtgwbhwqbxtlee794z" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/letkifxfmbxm5lhkbz7a 210w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/ojrdp5kbp04qwspz6ahg 420w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/fdjpuifszdvcnfradijr 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/zybodqear16qmlkyew0n 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/xlilw0mrpbwanhos4cu8 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/bwlkbghupidborcwfd3a 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/sauvbfp8hjqqez2cbrg4 1470w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/zpzfrfobbyt0nf4ddyrc 1680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/povlzxfvwdndyxvbqbdz 1890w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/cwoxfx605jafjc36qrnv 2047w"><figcaption> <i>“在布鲁克黑文的相对论重离子对撞机上欣赏超导磁铁的景色。当金颗粒以几乎光速沿对撞机的2.4英里长隧道沿着2.4英里长的隧道拉链时，这些磁体中有1,740条引导并集中颗粒梁。” -</i><a href="https://www.flickr.com/photos/brookhavenlab/3112766443/in/photostream/"><u>布鲁克海文国家实验室</u></a></figcaption></figure><h2>2005-？：SETI社区认为发送到太空的消息是否会引起敌对外星人的注意。</h2><p>寻找外星智能（SETI）涉及监测宇宙以了解外星生命的信号。在2005年左右，SETI社区的一些成员对“ Active Seti”的想法充满热情，这是指有意向Cosmos发送消息的想法。这引发了社区中激烈的辩论<a href="https://phys.org/news/2015-02-controversy-interstellar-messaging.html"><u>- 有些人担心</u></a>活跃的SETI会通过吸引敌对的外星人的注意来危害人类。 2006年<a href="https://www.nature.com/articles/443606a"><u>本质上的一篇文章</u></a>认为，这些是“不得不认真对待”的“<strong>小风险</strong>”。主动SETI的支持者认为，无论是否发送具有更强大信号的信息，外星文明都可能检测到地球的无线电信号。</p><p>科幻作家戴维·布林（David Brin）是SETI社区中有关人物之一。 2006年，布林<a href="https://lifeboat.com/ex/shouting.at.the.cosmos"><u>写道</u></a>，他和社区中的其他人呼吁会议讨论主动SETI的风险，但他们的关切在很大程度上被社区的其他成员忽略了。他认为他认为活跃的SETI支持者无法与同事咨询的失败感到沮丧， <span class="footnote-reference" role="doc-noteref" id="fnref0w08bxo4dkbl"><sup><a href="#fn0w08bxo4dkbl">[5]</a></sup></span>布林认为，通过与记者与故事联系，使这个问题更加公开。布林写道，他更喜欢“大学态度”，因为公众对这个问题的关注可能会损害SETI的整体声誉，而且目前尚不清楚他是否试图将故事带给记者。</p><p>国际宇航员学院（IAA）的常设委员会是与SETI社区内的监管机构最接近的事物。 2007年，该委员会<a href="http://resources.iaaseti.org/position.pdf"><u>起草了</u></a>有关向外星人发送信息的新原则，其中包括是否这样做的决定“应该由适当的国际机构做出，大致代表人类”。但是，这些原则从未被采用。</p><p>关于Active Seti的辩论在2010年进行了续签。斯蒂芬·霍金（Stephen Hawking）说这是一个坏主意，成为<a href="https://www.nbcnews.com/id/wbna36769422"><u>头条新闻</u></a>。在皇家学会主持的为期两天的会议上，SETI社区的成员进行了激烈的辩论，但没有达成共识。在年度会议上，IAA SETI委员会在20多年来首次更新了其<a href="http://resources.iaaseti.org/protocols_rev2010.pdf"><u>原则声明</u></a>，但最新的原则仍然没有提及Active Seti。 <span class="footnote-reference" role="doc-noteref" id="fnref81q1wcjqy7u"><sup><a href="#fn81q1wcjqy7u">[6]</a></sup></span></p><p>在2015年，社区在<a href="https://www.bbc.com/news/science-environment-31442952"><u>另一个没有解决方案的会议</u></a>上再次辩论了这个问题。同年，包括埃隆·马斯克（Elon Musk）在内的28位科学家和商业领袖签署了一份<a href="https://setiathome.berkeley.edu/meti_statement_0.html"><u>声明</u></a>，呼吁“在持续活跃的SETI之前进行“全球科学，政治和人道主义讨论”，并着重于围绕生存，能力和意图的不确定性潜在的外星智力。</p><p>关于活动性SETI是否可以接受的辩论似乎仍未解决，目前尚不清楚辩论的双方是否仍在互相讨论。 <a href="https://en.wikipedia.org/wiki/Active_SETI"><u>Active Seti Wikipedia页面</u></a>上列出的最新传输是在2017年发送的。 </p><figure class="image image_resized" style="width:43.97%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/ducljax4k8ichg3gxqhf" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/bpukjowfpxuu9mlljdxo 80w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/ekjbcxew7buu7r1gitdl 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/hwv9r5nstzb3tc764f2x 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/ygs50fyxkswypaaqqhan 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/xzqrf2wwdqiqlgsjtujs 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/zwinq0ytbacyo6lto1o9 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/u2dwvhindpaferivx8cm 560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/uect5dmwmixumbub7yv5 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/ct8xsblv9idfktj9e54p 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/p44udzj47etwdn0dw572 800w"><figcaption> <i>2008年，Yevpatoria RT-70射电望远镜（如上图）向Gliese 581 c发送了“</i> <a href="https://www.telegraph.co.uk/news/newstopics/howaboutthat/3166709/Messages-from-Earth-sent-to-distant-planet-by-Bebo.html"><i><u>来自地球的消息</u></i></a><i>”</i> <i>。该消息将于2029年到达目的地。</i> （ <a href="https://commons.wikimedia.org/wiki/File:70-%D0%BC_%D0%B0%D0%BD%D1%82%D0%B5%D0%BD%D0%BD%D0%B0_%D0%9F-2500_(%D0%A0%D0%A2-70).jpg"><u>S. Korotkiy</u></a>摄影）</figcaption></figure><h2> 1951年至今：计算机科学家考虑一个足够强大的未对准AI系统是否会逃避遏制并在地球上终止生命。</h2><p>对强大AI系统的影响的担忧可以追溯到现代计算机科学的开始：</p><blockquote><p><i>现在，让我们假设[智能]机器是一种真正的可能性，并查看建造它们的后果...毫无疑问，机器会死亡，他们将能够与互相提高智慧。因此，在某个阶段，我们必须期望这些机器能够以塞缪尔·巴特勒（Samuel Butler）的Erehhon中提到的方式进行控制。</i><br> <a href="https://rauterberg.employee.id.tue.nl/lecturenotes/DDM110%20CAS/Turing/Turing-1951%20Intelligent%20Machinery-a%20Heretical%20Theory.pdf"><u>-  1951年</u></a>创建的计算机科学家艾伦·图灵（Alan Turing）。</p></blockquote><p>如今，许多专家担心最终可能会有一个AI系统的<a href="https://www.vox.com/future-perfect/2018/12/21/18126576/ai-artificial-intelligence-machine-learning-safety-alignment"><u>风险</u></a>，而AI系统比具有与人类的目标保持一致的人类更有能力。在追求目标时，这种系统可能会通过努力获取资源或生存而导致人类灭绝。</p><p>与曼哈顿项目或布鲁克黑文国家实验室的科学家不同，AI研究人员没有达成共识的方法来计算灭绝风险的数量。对智力本质的理论理解尚未在诸如核物理等领域看到强大的基础。经验数据受到限制，因为没有人与所有人类更有能力的智能相互作用。</p><p>专家意见差异很大，因为强大的AI系统带来的风险量很大：</p><ul><li>决策理论家<a href="https://intelligence.org/2022/06/10/agi-ruin/"><u>Eliezer Yudkowsky</u></a>认为，通过我们目前的技术，强大的AI“<strong>大致确定</strong>要杀死所有人”。</li><li>前Openai研究员<a href="https://www.alignmentforum.org/posts/Hw26MrLuhGWH7kBLm/ai-alignment-is-distinct-from-its-near-term-applications"><u>Paul Christiano</u></a>认为，从AI灭绝的总风险为<strong>10-20％。</strong></li><li>两位描述自己为<a href="https://optimists.ai/2023/11/28/ai-is-easy-to-control/"><u>AI乐观主义者的</u></a>研究人员认为，“灾难性的AI接管大约有<strong>1％的可能性</strong>。”</li><li>在<a href="https://wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2022_expert_survey_on_progress_in_ai"><u>最近对AI研究人员的调查</u></a>中，中位研究人员给了<strong>5-10％的机会</strong><span class="footnote-reference" role="doc-noteref" id="fnrefapn182ppvxg"><sup><a href="#fnapn182ppvxg">[7]</a></sup></span> ，例如人类灭绝等灾难性结果。</li></ul><p>尽管通常可以看到AI灭绝风险的估计值，但似乎很少有尝试为其设定可接受的上限。理论计算机科学家斯科特·亚伦森（Scott Aaronson）<a href="https://scottaaronson.blog/?p=7042"><u>写道</u></a>，如果上升空间是“了解人类所有最伟大的问题的答案”，他的极限“可能高达<strong>2％</strong> ”。即使没有考虑到未来的生命，灭绝风险也相当于预期的约<strong>1.6亿伤亡</strong><strong>，</strong>大约是加拿大人口的四倍。 <span class="footnote-reference" role="doc-noteref" id="fnrefpnyaaddlre8"><sup><a href="#fnpnyaaddlre8">[8]</a></sup></span>很难说强大的AI系统的潜在好处是否能证明承担相对较高的风险是合理的。</p><p>援引今年早些时候的<a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/"><u>一封公开信</u></a>，援引了关于AI发展未来成果的科学不确定性，要求暂停AIN Frontier AI开发。这封信是由一些著名专家签署的，其中包括图灵奖得主Yoshua Bengio和标准教科书“人工智能：现代方法”的合着者Stuart Russell。在撰写本文时，似乎没有暂停 - 仅仅两周前，Google<a href="https://blog.google/technology/ai/google-gemini-ai/"><u>宣布</u></a>发布其“最大，功能最强大的AI模型”。</p><p>尽管历史上对AI灭绝风险的讨论在相对较小的研究社区以外很少见，但许多政策制定者，记者和公众最近都变得更加参与。上个月，英国的<a href="https://www.theguardian.com/technology/2023/nov/02/five-takeaways-uk-ai-safety-summit-bletchley-park-rishi-sunak"><u>AI安全峰</u></a>会将专家和世界领导人聚集在一起，讨论AI的风险以及如何减轻他们的风险。 </p><figure class="image image_resized" style="width:88.2%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/hl9t8gijdbgegeunxepx" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/dvr0iutuqxu33xdt2m6r 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/yge2eqe3pvz88qhhdzeo 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/kxpsczupmobkkryoakps 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/voby4hwmz3jwwmmk4j27 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/qmbgky9pxaqnnbfnn2ec 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/hq2toy1sqynxd282ndik 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/e9wdp0i6xhm1c8ydinn7 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/jhzota1zbwmsqksledha 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/pmnmrlcuw9fmt17r4tio 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xoSh4MhtFarLYZ7eM/rugc7c3dphrxo5lfw99n 1024w"><figcaption> <i>“ [2023年11月1日]。英国Bletchley。代表们在Bletchley Park英国AI峰会的第一天失去控制权的风险。 Kirsty O&#39;Connor / No 10 Downing Street的图片。</i> ”  -<a href="https://www.flickr.com/photos/ukgov/53302343301/in/photostream/"><u>英国政府</u></a></figcaption></figure><h1>要点</h1><h2>科学家有时不同意灭绝风险的可接受上限，但通常同意它应该非常小。</h2><p>对于三个案例，我发现科学家的例子提出了灭绝风险的可接受限制：</p><ul><li>曼哈顿项目科学家将其上限定为3x10 <sup>-6</sup> （一百万分之一）。</li><li> CERN的科学家认为RHIC可以接受2x10 <sup>-8</sup> （其中2亿个）风险，但另一位物理学家认为，更合适的限制将为10 <sup>-15</sup> （一个四分之一）或10 <sup>-22</sup> （十分之一十亿万亿）。</li><li>一位著名的计算机科学家可能会接受强大的AI灭绝的2x10 <sup>-2</sup> （一百分之一）。</li></ul><p>尽管这些上限差异很大，但它们均低于5x10 <sup>-2</sup> （一百分之五）至10 <sup>-1</sup> （十分之一）的赔率，中位专家去年从AI灭绝，通常是通过许多数量级。值得注意的是，即使是科学家给出的上限，这也是如此，他合理地认为停止研究可能会导致纳粹统治世界。</p><h2><strong>当风险存在重大不确定性时，通常要求暂停。</strong></h2><p>在三个尚未明确共识的风险量的情况下，科学界的某些部分要求暂停讨论该问题并收集更多证据：</p><ul><li>在重组DNA的情况下，尽管存在分歧，但整个社区都遵守了暂停。会议制定了一些研究的安全指南，并禁止最危险的研究类型。随着时间的流逝，这些指南会放松，因为重组DNA被证明是安全的。</li><li>就活跃的SETI而言，呼吁暂停和会议的有关社区成员最初被驳回。后来，有会议讨论这个问题，但是社区从未同意一系列准则。</li><li>就Frontier AI系统而言，只有在过去的几个月中，暂停要求暂停。尚未发生暂停，但是研究人员，决策者和公众就解决这些问题的潜在风险和政策进行了越来越多的讨论。</li></ul><h2>默认情况下，科学家更喜欢在其社区内对灭绝风险进行讨论。</h2><p>所有五个案例都包含科学界与决策者或公众之间的一定程度的相互作用：</p><ul><li>在曼哈顿项目期间，没有公众了解大气点火的风险，但是这种情况涉及科学家与政府官员之间的互动。一位科学家<a href="http://large.stanford.edu/courses/2015/ph241/chung1/"><u>抱怨</u></a>说：“以某种方式进入了华盛顿的文件。因此，此后偶尔有人碰巧注意到它，然后回到梯子下来的问题，而事物从来没有被安息了。”</li><li>在ASILOMAR重组DNA会议上，邀请了12名记者，但可能只是担心科学家会被指控掩盖否则。</li><li>大离子对撞机实验的风险评估仅在RHIC开始运作前一年就发布了，似乎仅仅是因为意外的媒体关注。</li><li> SETI社区的相关成员考虑将活跃的SETI问题带给记者，但他说他宁愿讨论社区中的问题。</li><li>政策制定者和公众之间对AI的风险的讨论正在增加。以前，关于研究界以外的风险的讨论相对较少。 </li></ul><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn2h0213rjfu8"> <span class="footnote-back-link"><sup><strong><a href="#fnref2h0213rjfu8">^</a></strong></sup></span><div class="footnote-content"><p>亚瑟·康普顿（Arthur Compton） <a href="https://oac.cdlib.org/view?docId=hb0580022s;NAAN=13030&amp;doc.view=frames&amp;chunk.id=div00003&amp;toc.depth=1&amp;toc.id=&amp;brand=oac4"><u>于1962年去世</u></a>，这是在<i>《美国周刊》</i>上发表文章三年后。他在去世前的一个月进行讲座。</p></div></li><li class="footnote-item" role="doc-endnote" id="fntjh4wf35yqj"> <span class="footnote-back-link"><sup><strong><a href="#fnreftjh4wf35yqj">^</a></strong></sup></span><div class="footnote-content"><p>纸张解决的其他两个风险是重力奇异性和真空不稳定性。作者使用理论上的论点表明引力奇异性不太可能，但不能估计概率的束缚。对于真空不稳定性的情况，他们列举了早期的工作，认为宇宙射线碰撞发生在地球过去的LightCone中很多次，而我们存在的事实证明了这种碰撞是安全的。 “仅在经验上，RHIC真空过渡的概率被<strong>2×10 <sup>-36</sup></strong>界定。”但是，我个人对这一论点持怀疑态度，因为它似乎忽略了<a href="https://nickbostrom.com/papers/anthropicshadow.pdf"><u>人类阴影</u></a>的效果。</p></div></li><li class="footnote-item" role="doc-endnote" id="fno6br352o0or"> <span class="footnote-back-link"><sup><strong><a href="#fnrefo6br352o0or">^</a></strong></sup></span><div class="footnote-content"><p>与其他一些估计相比，肯特对未来生命的估计是高度保守的 - 他的计算仅认为人口将保持100亿，直到地球被太阳消耗。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnf4gbc3hx4xt"> <span class="footnote-back-link"><sup><strong><a href="#fnreff4gbc3hx4xt">^</a></strong></sup></span><div class="footnote-content"><p>肯特说：“如果通常提前同意可接受的风险界限，那么对灾难风险的未来政策将更加理性，并且应该得到公众的信任，并且如果对是否确实可以保证是否可以保证这些界限的认真研究是在之前进行的。任何假设有风险的实验，相关的辩论涉及专家，在所考虑的实验中没有利益。”</p></div></li><li class="footnote-item" role="doc-endnote" id="fn0w08bxo4dkbl"> <span class="footnote-back-link"><sup><strong><a href="#fnref0w08bxo4dkbl">^</a></strong></sup></span><div class="footnote-content"><p> “ <i>...这似乎是小组的又一个例子，假设他们知道得更好。比群众好。比主权机构更好。比所有同事和同龄人都要好。如此之多，完美而宁静的信心，以至于他们愿意将所有人类后代押在正确的假设上。”</i> -David Brin</p></div></li><li class="footnote-item" role="doc-endnote" id="fn81q1wcjqy7u"> <span class="footnote-back-link"><sup><strong><a href="#fnref81q1wcjqy7u">^</a></strong></sup></span><div class="footnote-content"><p>尽管该声明没有说明积极发送消息，但它确实包含有关响应消息的原则： <i>“在确认的信号检测的情况下，本声明的签署人不会在不先寻求广泛代表性国际的指导和同意的情况下做出回应身体，例如联合国。”</i></p></div></li><li class="footnote-item" role="doc-endnote" id="fnapn182ppvxg"> <span class="footnote-back-link"><sup><strong><a href="#fnrefapn182ppvxg">^</a></strong></sup></span><div class="footnote-content"><p>中间响应在这里表示为一个范围，因为它根据问题框架而变化。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnpnyaaddlre8"> <span class="footnote-back-link"><sup><strong><a href="#fnrefpnyaaddlre8">^</a></strong></sup></span><div class="footnote-content"><p>如果我们确实考虑了<a href="https://globalprioritiesinstitute.org/how-many-lives-does-the-future-hold-toby-newberry-future-of-humanity-institute-university-of-oxford/"><u>未来的生命</u></a>，那可能等同于预期的伤亡范围为2000亿<sup> </sup>至2x10 <sup>52</sup> （大于地球上<a href="https://sciencenotes.org/how-many-atoms-are-in-the-world/"><u>原子的数量</u></a>）。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/xoSh4MhtFarLYZ7eM/when-scientists-consider-whether-their-research-will-end-the#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/xosh4mhtfarlyz7em/when-scientists-consider-whether-whether-whether-their-research-will-end-the<guid ispermalink="false"> XOSH4MHTFARLYZ7EM</guid><dc:creator><![CDATA[Harlan]]></dc:creator><pubDate> Tue, 19 Dec 2023 03:47:08 GMT</pubDate> </item><item><title><![CDATA[Is the far future inevitably zero sum?]]></title><description><![CDATA[Published on December 19, 2023 1:45 AM GMT<br/><br/><p>理查德（Richard）在<a href="https://twitter.com/RichardMCNgo/status/1731501640312815966">这篇</a>Twitter帖子中认为，在遥远的未来，将会有更多的零或负相互作用，因为一旦所有可能的价值都陷入了物理世界之外，就会注意到除了该价值的分配外，还要竞争。我想知道这是真的吗？</p><p>想象一个很远的未来，以下情况保持真实</p><ul><li>物理宇宙分为n个代理</li><li>每个代理商都充分利用了其领土上的物理资源，以最好地满足其效用功能（某些代理商将所有内容变成计算机，并模拟无尽的思想，而其他人则将所有内容都变成了苔丝的原子级式纸卷复制品）</li><li>我们已经达到了科学进步的局限性。每个代理商能够将其领土上的物质/能源转换为实用程序的能力都被封闭了，无法进一步改进</li></ul><p>（乐观的srdjan）：即使代理商知道相同的事物，他们仍然可以从贸易中从贸易中获利。</p><ul><li>可能是不同种类的代理人天生更好地做各种事情。毕竟，不同种类的思想具有不同的优势。在这种情况下，贸易可能是互惠互利的，因为它允许所有各方进行更多专业化和更多的东西。基本上，只要代理人有所不同，并且这些差异会转化为物质世界上有效性的一定程度差异，那么贸易就可以有意义。</li><li>也许比例有回报。可能比1个星系的大小相比，每单位熵的大小的计算机基质的每单位熵效率更高。在这种情况下，贸易再次可以双赢。</li></ul><p> （悲观的srdjan）嗯。因此，这里的论点基本上是，即使知识被限制在代理人的能力或规模很重要的情况下，贸易仍然可以是有意义的。好的，让我们确定这两个条件所持续下去。我仍然不确定该论点有效。</p><p>当然，在初始状态下，代理商将交易。他们将合作构建较大的计算机，并将计算时间分开。他们将专门生产自己更好的东西，并从贸易中分解收益。美好的。但是，一旦代理商做了足够长的时间，就会发生什么。最终，最终的平衡是：</p><ul><li>代理已经建立了一个共享的计算机矩阵，该矩阵跨越整个宇宙或命中缩放限制</li><li>他们以最佳的方式生产了所需的所有小部件，并拥有库存/期货合约，这些合同将持续到宇宙的热死亡。当然，在某个时候，您耗尽了贸易的所有收益，对吗？</li></ul><p>我想这里的元点是这样的：</p><ul><li>您从可能的交易开始。有些，例如战争，是负数。有些是中立的。有些是正总和。</li><li>您进行积极的交易。</li><li>最终，您已经进行了所有正股交易，只剩下负数或零总额</li></ul><p>（乐观的srdjan）hmmmmmm。</p><p>我很想开始在这里争论对象级别的点，但我认为这是一个错误。也许是在这种情况下，如果您走得足够远，可以进行所有可能的交易，并且所有积极的潜力都将被挖掘出来。尽管如此，这似乎与我们最初提出的问题有所不同。问题类似于“在一个固定和充分拥有的物质资源且所有代理都有充分知识的世界中，是否有任何贸易需要”。我认为答案是肯定的。 “一旦我们完成创建最佳的泛 - 半乳酸计算集群，最终将不需要交易的问题”或“出生后3天AI会使所有可能的交易遍及宇宙的热死亡，这意味着那里从那时起，这不是真正的新贸易。</p><br/><br/> <a href="https://www.lesswrong.com/posts/HKDfuBwkHsiXaGuLG/is-the-far-future-inevitably-zero-sum#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/hkdfubwkhsixagulg/is-the-far-far-future-inevitase-zero-zero-sum<guid ispermalink="false"> hkdfubwkhsixagulg</guid><dc:creator><![CDATA[Srdjan Miletic]]></dc:creator><pubDate> Tue, 19 Dec 2023 01:45:45 GMT</pubDate> </item><item><title><![CDATA[The 'Neglected Approaches' Approach: AE Studio's Alignment Agenda]]></title><description><![CDATA[Published on December 18, 2023 8:35 PM GMT<br/><br/><p> <i>Many thanks to Samuel Hammond, Cate Hall, Beren Millidge, Sumner Norman, Steve Byrnes, Lucius Bushnaq, Joar Skalse, Kyle Gracey, Gunnar Zarncke, Ross Nordby, David Lambert, Simeon Campos, Bogdan Ionut-Cirstea, Ryan Kidd, and Eric Ho有关此议程早期草案的批判性评论和建议，以及AE Studio的Philip Gubbins，Diogo de Lucena，Rob Luke和Mason Seale的支持和反馈。</i></p><h2><strong>长话短说</strong></h2><ul><li>我们在AE工作室的最初变革理论是一种“被忽视的方法”，它涉及将利润从咨询业务转向开发脑部计算机界面（BCI）技术，以极大地增强人类代理，使我们能够更好地完成诸如求解一致性之类的事情。现在，鉴于缩短时间表，我们正在更新我们的变革理论，以扩大我们的技术一致性工作。</li><li>凭借在BCI，神经科学和机器学习的扎实技术基础，我们很乐观，我们将能够为AI安全做出有意义的贡献。我们特别热衷于追求似乎最具创造力，有前途和合理的忽视技术一致性议程。我们目前正在登上有前途的研究人员，并启动我们的内部对齐团队。</li><li>当我们为前进而努力时，我们正在积极索取更广泛的一致性社区的专家见解，并正在寻找数据科学家和一致性研究人员，他们与我们增强人类代理和帮助解决一致性的愿景产生共鸣。</li></ul><h2><strong>关于我们</strong></h2><p>你好！我们是<a href="https://ae.studio/"><u>AE Studio</u></a> ，这是一种自举软件和数据科学咨询业务。我们的使命一直是将我们的利润直接改编为具有大幅增强人类代理的希望，例如脑部计算机界面（BCI）的构建技术。我们还将收入的<a href="https://ae.studio/blog/we-donate-5-of-our-profits-could-we-do-more-if-we-didnt"><u>5％</u></a>直接捐赠给<a href="https://ae.studio/#giving-back"><u>有效的慈善机构</u></a>。今天，我们是约150名程序员，产品设计师和ML工程师；我们的盈利和成长。我们还拥有一支由顶级神经科学家和数据科学家组成的团队，在为<a href="https://ae.studio/neurotechnology-consulting"><u>领先的</u></a><a href="https://ae.studio/brain-computer-interface"><u>BCI</u></a> <a href="https://aithority.com/machine-learning/blackrock-neurotech-collaborates-with-ae-studio-to-advance-training-and-calibration-in-the-first-commercial-bci-platform-moveagain/"><u>公司</u></a>开发ML解决方案方面具有丰富的经验，现在我们正在利用我们在这些领域中的技术经验和学习来组装一个专门用于探索探索被忽视的一致性研究指示的一致性团队关于我们在BCI，数据科学和机器学习方面的专业知识。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/kjm62h6t1mr8dclnipg6" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/hmywobevgvybnh1nwvye 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/xntfrzcgyjiokvopmsxx 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/h7g7aaigpy1eqp9aow51 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/ps3mtbbn8k1cayjihilb 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/qetiravsljq96ggh6arg 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/l9gfy1mgtqsprhqduziv 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/tyznsshsw2uakczdjdyj 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/pik7tzc8bsufr9y7gtln 1280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/vc6igucedrmyntr1wr9m 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/vvq2udnsdod14uhbwa78 1598w"><figcaption> AE Studio团队在我们最近的年度务虚会上，在那里我们做诸如建立<a href="https://ae.studio/same-day-skunkworks">同一天的</a><a href="https://ae.studio/blog/we-built-and-sold-a-startup#pg">初创企业</a>，设定了我们的各种研究议程，并对<a href="https://fixinghomer.com/">虚构人物进行神经科学</a>。</figcaption></figure><p>随着我们通过<a href="https://ae.studio/ai-alignment"><u>AI的一致性努力</u></a>变得越来越公开，我们认为分享我们如何优先考虑哪些问题以及如何充分利用我们的比较优势的战略和愿景会很有帮助。</p><h2><strong>为什么以及我们如何认为我们可以帮助解决一致性</strong></h2><h3><i>我们可能可以通过对齐方式来做我们已经对BCI所做的一切</i></h3><p>您可能会认为AE没有业务参与一致性，我们同意。</p><p> AE的最初变革理论试图实现在世界上做好事的高度“被忽视的方法”：引导有利可图的软件咨询，将我们自己的<a href="https://ae.studio/same-day-skunkworks"><u>初创公司</u></a>孵化在一边，<a href="https://ae.studio/blog/we-built-and-sold-a-startup"><u>出售</u></a>它们，并将其重新投资于<a href="https://ae.studio/brain-computer-interface"><u>大脑计算机界面（BCI）中的利润（BCI）</u></a>为了做大幅度增加人类代理，减轻与BCI相关的S风险，并使人类足够聪明，明智并且能够执行诸如解决协议之类的事情之类的事情。尽管BCI介导的认知增强对在世界上做好事的愿景<a href="https://twitter.com/ESYudkowsky/status/1648766287819026432"><u>越来越</u></a><a href="https://www.lesswrong.com/posts/vEtdjWuFrRwffWBiP/we-have-to-upgrade"><u>普遍</u></a>，但当我们在2016年首次开始时，它被认为是高度特质。</p><p><strong>最初，许多人说，AE没有任何业务参与BCI领域（我们当时也同意）</strong> ，但是在雇用了该领域的领先专家并采取了<a href="https://ae.studio/blog/ae-core-values"><u>越来越雄心勃勃的A/B测试步骤之后</u></a>，我们出现了作为该空间中<a href="https://ae.studio/brain-computer-interface"><u>受人尊敬的球员</u></a>（请参阅<a href="https://github.com/agencyenterprise/neural-data-simulator"><u>此处</u></a>，<a href="https://github.com/agencyenterprise/imagined-handwriting"><u>此处</u></a>， <a href="https://aithority.com/machine-learning/blackrock-neurotech-collaborates-with-ae-studio-to-advance-training-and-calibration-in-the-first-commercial-bci-platform-moveagain/"><u>此处</u></a>和<a href="https://agencyenterprise.github.io/neurotechdevkit/"><u>此处</u></a>以获取一些示例）。</p><p>现在，考虑到<a href="https://www.secondbest.ca/p/why-agi-is-closer-than-you-think">加速</a>AI时间表以及该技术带来的明显存在风险，我们现在决定利用<a href="https://ae.studio/brain-computer-interface"><u>BCI</u></a> ，<a href="https://ae.studio/data-science"><u>数据科学</u></a>和机器学习中的技术专长和学习来帮助解决一致性。使用相同的战略见解，技术知识和运营技巧，这些技能在扩展我们的软件咨询和BCI工作方面非常有用 - 包括通过征求现有专家的实质性反馈来实践<a href="https://lapaul.org/papers/PPR-TE-symposium.pdf"><u>认知谦卑</u></a>（ <a href="https://docs.google.com/forms/d/e/1FAIpQLSdwhY_wi0bloZQh3xLgsEXQuNX8MWRCwYxEzf6udPKIxx_rIQ/viewform"><u>请分享您的！</u></a> ） - 我们！ &#39;&#39;渴望开始探索<u>各种</u>被忽视的对准方法。下一节详细介绍了直接从我们的BCI工作中出现的一些特定的对象级别对齐想法。</p><p>我们已经第一手了解到，最有前途的项目通常具有<a href="https://ae.studio/blog/why-your-company-wont-start-high-upside-projects"><u>很低的成功概率，但潜在的上升空间极高</u></a>，我们现在将此核心课程应用于AI的一致性。</p><p>我们认为，我们可以像对BCI一样应用类似的模型与对齐方式：开始谦卑， <span class="footnote-reference" role="doc-noteref" id="fnrefc1tqkqcwhy"><sup><a href="#fnc1tqkqcwhy">[1]</a></sup></span> ，并逐步更新为出色的专家指导的输出。</p><h3><i>通过被忽视的方法进行了许多射门</i></h3><p>我们认为，有助于解决一致性的合理研究方向的空间是广泛的，并且<a href="https://www.lesswrong.com/posts/4TuzWEKysvYdhRXLd/paradigm-building-introduction"><u>仍然具有良好的</u></a>对准研究状态，这意味着只有该空间的一小部分才被令人满意地探索。如果<a href="https://www.lesswrong.com/posts/zaaGsFBeDTpCsYHef/shallow-review-of-live-agendas-in-alignment-and-safety">目前以当前占主导地位的</a>一致性研究议程在可能的方法的空间中达到了<a href="https://www.lesswrong.com/posts/MMAK6eeMCH3JGuqeZ/everything-i-need-to-know-about-takeoff-speeds-i-learned"><u>一个或多个本地最大值</u></a>，那么我们怀疑追求有希望被忽视的方法的多元化集（和/或<a href="https://www.lesswrong.com/posts/YnGRBADQwpYRbuCbz/towards-hodge-podge-alignment-1"><u>霍迪奇 - 杂货</u></a>）将会提供更大的探索性覆盖范围。 <span class="footnote-reference" role="doc-noteref" id="fnref6qkn5ea4003"><sup><a href="#fn6qkn5ea4003">[2]</a></sup></span>因此，我们计划采用一种乐观和探索的方法来追求创造性，合理和被忽视的对准方向，尤其是在我们具有比较优势的领域，例如BCI和人类神经科学。我们怀疑EA社区中的许多人已经同意， <a href="https://en.wikipedia.org/wiki/Ignaz_Semmelweis#Conflict_with_established_medical_opinion"><u>在</u></a><a href="https://en.wikipedia.org/wiki/Mendelian_inheritance#History"><u>某些</u></a><a href="https://en.wikipedia.org/wiki/Helicobacter_pylori#History"><u>高度</u></a><a href="https://en.wikipedia.org/wiki/Prion"><u>出乎意料的</u></a><a href="https://www.nature.com/articles/nature05913"><u>地方</u></a>经常<a href="https://en.wikipedia.org/wiki/Continental_drift#Rejection_of_Wegener's_theory,_1910s%E2%80%931950s"><u>发现</u></a>开创性的创新，在许多人似乎是令人难以置信的，<a href="http://www.paulgraham.com/heresy.html"><u>异端</u></a>或以其他方式牵强的情况下，直到它们起作用。</p><h2> <strong>…但是这些被忽视的方法是什么？</strong></h2><h3><i>您被忽视的方法想法</i></h3><p>我们认为我们有一些潜在的有希望的假设。但是，因为我们也知道您也这样做，所以我们正在<a href="https://docs.google.com/forms/d/e/1FAIpQLSeU1_dZapdxH5SIooC3VK7nbnKSCZxxGG1JuqeNDpTOa22xbA/viewform?usp=sf_link"><u>积极征集一致性社区的意见</u></a>。在不久的将来，我们将更加正式地追求这项倡议，为最有前途的专家评审建议颁发一些小奖项。请<a href="https://docs.google.com/forms/d/e/1FAIpQLSeU1_dZapdxH5SIooC3VK7nbnKSCZxxGG1JuqeNDpTOa22xbA/viewform?usp=sf_link"><u>提交</u></a>任何<span class="footnote-reference" role="doc-noteref" id="fnrefc0h3mczkoof"><sup><a href="#fnc0h3mczkoof">[3]</a></sup></span>议程的想法，即您认为您既合理又忽略了（即使您现在没有带宽来追求这个想法！这是一场想法的竞赛，而不是实施的竞赛）。</p><h3><i>我们被忽视的方法思想</i></h3><p>要明确我们的大型目标：我们要确保如果/当我们生活在一个具有超级智能AI的世界中，他的行为是（从定义上讲），而我们的直接控制权，那么这个AI（至少）不会破坏人类，（理想情况下）大大增加了有意识实体的代理和繁荣。</p><p>因此，以下列表提出了一组我们认为（1）有助于实现这一愿景的可能性的十个想法，（2）尚未令人满意地探索，并且（3）我们可以有意义地为实现做出贡献。</p><p><strong>重要的警告</strong></p><ul><li>请考虑这套想法更像是“ AE不断发展的，首先是最好的猜测，他们有望被忽视的对准方法，而不是“ AE的官方统一议程”。</li><li>另请注意，这些是我们的想法，而不是具体的实施计划。尽管我们认为我们在追求以下一些议程方面可能具有比较优势，但我们认为这不利于这种情况。我们认为以下想法通常是有兴趣的，绝对被忽略的，与一致相关的议程<strong>，即使我们不是最适合实施所有这些的特定群体。</strong></li><li>我们正在探索的一个元信息涉及定量识别被忽略的方法，例如分析一条非常大的<a href="https://github.com/moirage/alignment-research-dataset"><u>自然语言数据集</u></a>。我们怀疑该项目和其他相关项目可能有助于确定目前代表性不足的特定研究领域。</li></ul><p><strong>我们认为可能值得追求的十个被忽视的方法的例子</strong></p><ol><li><a href="https://www.lesswrong.com/s/HzcM2dkCq7fwXBej8/p/tj8AC3vhTnBywdZoA#15_2_1_2_The__Reverse_engineer_human_social_instincts__research_program________"><strong><u>反向工程亲社会性</u></strong></a>：我们同意<a href="https://www.lesswrong.com/posts/CjFZeDD6iCnNubDoS/humans-provide-an-untapped-wealth-of-evidence-about"><u>人类提供有关一致性的尚未开发的证据</u></a>。人脑的神经网络可靠地实例化亲<a href="https://www.lesswrong.com/posts/yKgai84JhFmCkWQ8R/alignment-via-prosocial-brain-algorithms"><u>社会算法</u></a>，例如同理心， <a href="https://docs.google.com/document/d/1fMropF42vJLyKsm99XLk1UK8iCnlrjs6NhryUUCr9IM/edit"><u>自我重叠，</u></a>思想理论，注意力架构，自我意识，自我批评，自我控制，谦卑，利他主义等。我们想<a href="https://www.lesswrong.com/s/HzcM2dkCq7fwXBej8/p/tj8AC3vhTnBywdZoA#15_2_1_2_The__Reverse_engineer_human_social_instincts__research_program________"><u>逆转工程</u></a>，并有助于进一步发展 - 我们当前的最佳模型是亲社会如何在大脑中发生的，朝着强大的亲社会AI构建。凭借AE在BCI，神经科学和机器学习方面的背景，我们感到有能力在这个研究方向上取得切实的进步。<ol><li>目前，我们正在积极地致力于基于RLM和LLM的代理，将<a href="https://arxiv.org/abs/2305.17375"><u>注意力模式理论</u></a>，<a href="https://pubmed.ncbi.nlm.nih.gov/32064522/"><u>自我重叠</u></a>和<a href="https://compdevlab.yale.edu/docs/2019/ToM_as_IRL_2019.pdf"><u>心理理论</u></a>作为促进亲社会认知的机制。事实证明，基于大脑的AI方法对于<a href="https://www.lesswrong.com/posts/nNbnzegz7ppewZgCG/ai-researchers-announce-neuroai-agenda"><u>AI功能研究</u></a>通常是成功的，我们（与其他<a href="https://youtu.be/Ft0gTO2K85A?si=V3EGJ-CQxxtnAfUX&amp;t=2171"><u>许多</u></a><a href="https://www.alignmentforum.org/posts/5F5Tz3u6kJbTNMqsb/intro-to-brain-like-agi-safety-13-symbol-grounding-and-human"><u>人</u></a>一起）认为，对于AI安全，这可能是正确的。我们有兴趣测试与默认方法相比，亲社会学习算法更具性能和<a href="https://twitter.com/RichardSSutton/status/1728129341287198885"><u>可扩展性的</u></a>假设。我们还认为，创建和/或促进相关基准和数据集的开发可能是与这种方法相关的非常高的杠杆副本。</li><li>尽管我们知道当前的人类亲社会模式远非完美，但我们认为，相关的科学文献在很大程度上是未开发的灵感来源，既是（1）哪种激励措施和机制使特工变得亲社会，以及（2）什么？疾病的亲社会性强大地有助于对齐行为。我们认为，尽管计算认知神经科学的实质性肯定是刻薄的，这项现有的工作可能会激发新的一致性方法。</li><li>最好的猜测是为什么可能会忽略这一点：<ol><li>我们推测可能存在混合（1）从认知神经科学中提取最佳相关见解的趋势（我们支持这一点），（2）假设AGI会模仿人的大脑（我们认为不认为AGI这可能是），或（3）我们已经从当前的神经科学中拥有完美的模型，即亲社会的工作原理（这是不正确的），或（4）在所有情况下，我们都应该试图复制人类的社会行为AI中的大脑（我们认为这是<a href="https://www.lesswrong.com/posts/yKgai84JhFmCkWQ8R/alignment-via-prosocial-brain-algorithms#Plausible_critique__1__Human_value_based_cognition_moral_reasoning_ain_t_all_that__"><u>不明智的</u></a>，不安全的） - 不必要地限制了（1）所追求的程度。</li><li>此外，一线社区在数学，计算机科学和其他关键技术领域的强大基础虽然无可否认，但可能会无意中限制社区级别的曝光率，即认知科学研究的最前沿。</li></ol></li></ol></li><li> <a href="https://www.cold-takes.com/transformative-ai-timelines-part-1-of-4-what-kind-of-ai/"><strong><u>变革性的AI</u></strong></a> <strong>→更好的BCI→更好（人类）对准研究人员</strong>：一些一致性研究人员希望使用先进的AI直接自动化和/或快速提高对准研究（最重要的是<a href="https://openai.com/blog/introducing-superalignment"><u>OpenAI的超级对准议程</u></a>）。我们认为，在同样的静脉中追求的方向高度忽视：<strong>雇用先进的AI来自动化和/或快速提高BCI研究。然后，使用此BCI</strong><a href="https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html#merge"><strong><u>显着增强</u></strong></a><strong>人类对齐研究人员的能力。</strong><ol><li>虽然这听起来有些古怪，但我们怀疑在不久的将来，重要的科学自动化是合理的，我们想宣布，除了直接跳到自动跳动时，还有其他潜在的至高价值的一致性指示。 - 包括自动化的事物，例如<a href="https://www.alignmentforum.org/posts/ybmDkJAj3rdrrauuu/connectomics-seems-great-from-an-ai-x-risk-perspective"><u>连接组/整个大脑仿真</u></a>。 （顺便说一句，我们还认为，对于更安全的后未来，考虑到变革性AI的其他各种好处，例如有效地使用<a href="https://www.nature.com/articles/s41586-023-05824-z"><u>独特的DNA密码子</u></a>加密人类DNA来对抗生物。）</li><li>还值得注意的是，增强人类一致性研究人员的能力并不一定需要变革性的BCI。为此，我们目前正在调查相对较低的心理干预措施和<a href="https://universallauncher.com/"><u>代理增强工具</u></a>，这些工具有可能显着提高个人认知输出的质量和数量。在一个理想的世界中（即我们可以快速开始实施该议程的世界），我们推测，赋予人类比AI更好的一致性研究可能更安全，因为授权AI具有与一致性相关的功能有可能赋予人类权力的能力，而不是赋予人类权力。 （这<i>也不</i>是说通过BCI赋予人类权力也没有很多严重的风险）。</li></ol></li><li> <strong>BCI用于定量映射人类价值</strong>：我们还认为，近未来的BCI可以使我们能够以数据驱动的方式绘制人类价值观的潜在空间，而不是以自然语言编码我们的价值观，例如，在人类的<a href="https://www.anthropic.com/index/constitutional-ai-harmlessness-from-ai-feedback"><u>宪法AI</u></a>中。这项研究<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8881635/"><u>已经</u></a>以更加有限的方式<a href="https://research.clps.brown.edu/SocCogSci/Publications/Pubs/Bello_Malle_2023_Comp_morality_preprint.pdf"><u>进行</u></a>- 我们怀疑BCI明确针对<a href="https://www.nature.com/articles/nrn2357"><u>与估值相关的认知量身定制</u></a>，这对于对齐方式（对于个人，团体，社会等）非常有价值。</li><li> <strong>&#39;Reinforcement Learning from Neural Feedback&#39; (RLNF)</strong> : near-future BCI may also allow us to interface neural feedback directly with AI systems, enabling us to improve the alignment of the state-of-the-art reward prediction models (and/or develop novel reward models altogether) in the direction of yielding more efficient, individually-tailored, high-fidelity reward signals. We think that in order for this approach to be pragmatic, the increase in quality of the reward signals would have to outweigh or otherwise counterbalance the practical cost of extracting the associated brain signals. <span class="footnote-reference" role="doc-noteref" id="fnrefoosk7rlikrr"><sup><a href="#fnoosk7rlikrr">[4]</a></sup></span> And the general idea of using neural data as an ML training signal also need not be limited to RL—we just thought RLNF sounded pretty cool.</li><li> <strong>Provably safe architectures</strong> : <span class="footnote-reference" role="doc-noteref" id="fnref2u9uvh50m87"><sup><a href="#fn2u9uvh50m87">[5]</a></sup></span> we see significant potential to help amplify, expedite, and scale the deployment of <a href="https://arxiv.org/abs/2309.01933"><u>provably safe architectures</u></a> , including potentially promising examples like <a href="https://www.lesswrong.com/posts/pKSmEkSQJsCSTK6nH/an-open-agency-architecture-for-safe-transformative-ai"><u>open agency architectures</u></a> , <a href="https://arxiv.org/pdf/2006.08381.pdf"><u>inductive program synthesis</u></a> (eg, DreamCoder), and <a href="https://probmods.org/"><u>other</u></a> <a href="https://www.lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal"><u>similar</u></a> <a href="https://dl.acm.org/doi/10.1145/3314221.3314638"><u>frameworks</u></a> that draw on insights from cognitive neuroscience. Though these architectures are not currently prominent in machine learning, we think it is possible that devoting effort and resources to scaling them up for mainstream adoption could potentially be highly beneficial in expectation. We are sensitive to the concern that the alignment tax might be high in adopting uncompetitive architectures—which is precisely why we think these architectures deserve <i>more</i> rather than less technical attention and funding.</li><li> <strong>Intelligent field-building as an indirect alignment approach</strong> : <span class="footnote-reference" role="doc-noteref" id="fnref1tqzflp5hux"><sup><a href="#fn1tqzflp5hux">[6]</a></sup></span> despite the increasing mainstream ubiquity of AI safety research, there is still only a tiny subset of smart and experienced people who <i>could very likely</i> add value to alignment who <i>are in fact</i> currently doing so 。 If we can carefully identify these extremely promising thinkers—especially those from disciplines and backgrounds that may be traditionally overlooked (eg, neuroscience)—and get them into a state where they can contribute meaningfully to alignment, we think that this could enable us to develop, test, and iterate on unconventional approaches at scale.</li><li> <strong>Facilitate the development of</strong> <a href="https://www.lesswrong.com/posts/PcTLHamp236afJxxT/some-for-profit-ai-alignment-org-ideas"><strong><u>explicitly-safety-focused businesses</u></strong></a> : as alignment efforts become increasingly mainstream, we suspect that AI safety frameworks may yield innovations upon which vari <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label=""><span class="mjx-mrow" aria-hidden="true"></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>ous promising business models may be built. We also think it would be a far better outcome if, all else being equal, more emerging for-profit AI companies decide to build alignment-related products (rather than build products that just further advance capabilities, which seems like the current default behavior) 。 We suspect many <a href="https://www.lesswrong.com/posts/PcTLHamp236afJxxT/some-for-profit-ai-alignment-org-ideas#Context">capable startup founders</a> could be <a href="https://xkcd.com/356/"><u>nerd sniped</u></a> into doing something more impactful with alignment.<ol><li> Some plausible examples of such businesses could include (1) consultancies offering <a href="https://www.lesswrong.com/posts/iHmsJdxgMEWmAfNne/red-teaming-language-models-via-activation-engineering"><u>red-teaming</u></a> as a service for adversarial testing of AI systems, (2) platforms providing robust testing/benchmarking/auditing software for advanced AI systems, (3) centralized services that deliver high-quality, expert-labeled, ethically-sourced datasets for unbiased ML training, and (4) AI monitoring services akin to <a href="https://en.wikipedia.org/wiki/Datadog"><u>Datadog</u></a> for continuous safety and performance tracking. We know of several founders currently setting out to pursue similarly safety-focused business models.</li><li> Accordingly, we are planning to do all the following:<ol><li> we&#39;re currently growing a <u>community</u> of VCs and angels interested in funding such ideas,</li><li> starting Q2 next year, we aim to fund, internally develop, and deploy safety-prioritizing AI skunkworks companies (ideally as an exportable model for others to follow), and</li><li> we&#39;re planning to run a <a href="https://forms.gle/z3pQZQFCXH1r4Pbh6"><u>competition with $50K seed funding</u></a> for <strong>already-existing safety-focused businesses</strong> and/or <strong>anyone who has promising business ideas that first and foremost advance alignment</strong> , to be evaluated by AI safety experts and concerned business leaders. We do encourage you to post any promising ideas, even if you&#39;re not likely to pursue them.</li></ol></li><li> We also suspect it may be worth creating some template best practices with company formation to increase the likelihood that the businesses retain agency long term in accomplishing AI safety goals, especially given <a href="https://x.com/JacquesThibs/status/1731637759587029002?s=20"><u>recent</u></a> <a href="https://twitter.com/aisafetymemes/status/1730032691817418976?t=D5sNUZS8uOg4FTcneuxVIg"><u>events</u></a> . Aligning business interests with public safety is not just beneficial for societal welfare, but also advantageous for long-term business sustainability—as well as potentially influencin <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label=""><span class="mjx-mrow" aria-hidden="true"></span></span></span></span></span> g public perception and policy efforts in a dramatically positive way. We also are acutely aware of <a href="https://forum.effectivealtruism.org/posts/f2qojPr8NaMPo2KJC/beware-safety-washing"><u>safety-washing</u></a> <a href="https://www.lesswrong.com/posts/PcTLHamp236afJxxT/some-for-profit-ai-alignment-org-ideas?commentId=g7rmwdYkjGhbbKmxe">concerns</a> and/or unintentionally creating race dynamics in this domain, and we think that ensuring for-profit safety work is technically rigorous and productive is critical to get right.</li><li> If you are a potential funder for promising businesses that advance alignment, please reach out to us at <a href="mailto:alignmentangels@ae.studio">alignmentangels@ae.studio</a> to express interest in joining our Alignment Angels slack group.</li></ol></li><li> <strong>Scaling our</strong> <a href="https://ae.studio/"><strong><u>consulting business</u></strong></a> <strong>to do object-level technical alignment work—and then scale this model to many other organizations:</strong> the potential to bring other highly promising people into the fold (see point 6, above) to contribute significantly to alignment—even without being alignment experts <i>per se</i> —is a hypothesis we&#39;re actively exploring and aiming to validate.<ol><li> Given that we expect most people to struggle with having actually-impactful alignment outputs as they are just starting, we see a model where senior AI engineers—even those without explicit alignment backgrounds—can eventually collaborate with a small number of extremely promising alignment researchers who have an abundance of excellent object-level technical project ideas but limited capacity to pursue them. By integrating these researchers into our <u>client engagement framework</u> , used <a href="https://drive.google.com/file/d/1s4PucbB-rQNp-LivprV-ptb17_tKV_W-/view"><u>highly</u></a> <a href="https://ae.studio/product-development"><u>successfully</u></a> over the years for our <a href="https://ae.studio/tldr-cool-stuff-weve-done">other technical projects</a> , we could potentially massively scale the efficacy of these researchers, leveraging our team&#39;s extensive technical expertise to advance these alignment projects and drive meaningful progress in the场地。</li><li> We hope that if this &#39;outsource-specific-promising-technical-alignment-projects&#39; model works, many other teams (corporations, nonprofits, etc.) with technical talent would copy it—especially if grants are made in the future to further enable这种方法。</li></ol></li><li> <strong>Neuroscience x mechanistic interpretability</strong> : both domains have yielded insights that are mutually elucidating for the shared project of attempting to model how neural data leads to complex cognitive properties. We think it makes a lot of sense to put leading neuroscientists in conversation with mechanistic interpretability researchers in an explicit and systematic way, such that the cutting-edge methods in <a href="https://www.anthropic.com/index/towards-monosemanticity-decomposing-language-models-with-dictionary-learning"><u>each</u></a> <a href="https://dartbrains.org/content/RSA.html"><u>discipline</u></a> can be further leveraged to enhance the other. Of course, we think that this synergy across research domains should be explicitly focused on enhancing safety and interpretability rather than using neuroscience insights to extend AI capabilities.</li><li> <strong>Neglected approaches to AI policy—eg, lobby government to directly</strong> <a href="https://www.lesswrong.com/posts/SbC7duHNDHkd3PkgG/alignment-grantmaking-is-funding-limited-right-now"><strong><u>fund</u></strong></a> <strong>alignment research:</strong> though not a technical research direction, we think that this perspective dovetails nicely with other thinking-outside-the-box alignment approaches that we&#39;ve shared here. It appears as though congresspeople and staffers are taking the alignment problem <a href="https://www.lesswrong.com/posts/2sLwt2cSAag74nsdN/speaking-to-congressional-staffers-about-ai-risk"><u>more seriously</u></a> than many would have initially predicted and, in particular, are <a href="https://www.lesswrong.com/posts/2sLwt2cSAag74nsdN/speaking-to-congressional-staffers-about-ai-risk#Final_Takes"><u>quite open to plausible safety proposals</u></a> —all of which means that there may be substantial opportunity to capitalize on the vast funding resources at their disposal to dramatically increase the scale and speed at which alignment work is being done. We think it is critical to make sure that this is done effectively and efficiently (eg, avoiding <a href="https://en.wikipedia.org/wiki/Pork_barrel"><u>pork</u></a> ) and for alignment organizations to be practically prepared to manage and utilize significant investment (eg, 10-1000x) if such funding does in fact come to fruition in the near future. We are currently exploring the possibility of hiring someone with a strong policy background to help facilitate this: while we have received positive feedback on this general idea from those who know significantly more about the policy space than we do, we are very sensitive to the potential for a shortsighted or naive implementation of this to be highly harmful to AI safety policy. We are actively in the process of meeting with and learning more from policy experts: <strong>if you are doing work in this area and know way more than us about AI policy, please do</strong> <a href="mailto:alignment@ae.studio"><strong><u>reach out</u></strong></a> <strong>so we can learn from you!</strong></li></ol><p> We began sharing this &#39;Neglected Approaches&#39; approach <a href="https://foresight.org/summary/judd-rosenblatt-accellerating-human-agency-with-bci-wbe-workshop-2023/"><u>publicly</u></a> at the <a href="https://foresight.org/whole-brain-emulation-workshop-2023/">Foresight Institute&#39;s <u>Whole Brain Emulation Workshop</u></a> in May, and we were excited to see this strategy gain steam, including Foresight Institute&#39;s own emphasis on neglected approaches with their new <a href="https://forum.effectivealtruism.org/posts/EcKmt8ZJ3dcQBigna/launching-foresight-institute-s-ai-grant-for-underexplored"><u>Grant for Underexplored Approaches to AI Safety</u></a> 。</p><h3> <i>We want to make these ideas stronger</i></h3><p> It is critical to emphasize again that this list represents our current best guesses on some plausible neglected approaches that we think we are well-equipped to explore further. We fully acknowledge that many of these guesses may be ill-conceived for some reason we haven&#39;t anticipated and are open to critical feedback in order to make our contributions as positively impactful as possible. We intend to keep the community updated with respect to our working models and plans for contributing maximally effectively to alignment. ( <a href="https://forms.gle/sHUVqeNC4gJ5ab3w9"><u>Please see this feedback form</u></a> if you&#39;d prefer to share your thoughts on our work anonymously/privately instead of leaving a comment below this post.)</p><p> We also recognize that many of these proposals have a double-edged sword quality that requires extremely careful consideration—eg, building BCI that makes humans more competent could also make bad actors more competent, give AI systems manipulation-conducive information about the processes of our cognition that we don&#39;t even know, and so on. We take these risks very seriously and think that any well-defined alignment agenda must also put forward a convincing plan for avoiding them (with full knowledge of the fact that if they <i>can&#39;t</i> be avoided, they are not viable directions.)</p><h2><strong>结论性想法</strong></h2><p>AE Studio&#39;s burgeoning excitement about contributing to AI safety research is a calculated response to our updated timelines and optimism about having the skillset required for making impactful contributions. Our approach aims to combine our expertise in software, neuroscience, and data science with ambitious parallel exploration of what we consider to be neglected approaches in AI alignment.</p><p> We commit to exploring these directions in a pragmatic, informed, and data-driven manner, emphasizing collaboration and openness within the greater alignment community. We care deeply about contributing to alignment because we want to bring about a maximally agency-increasing future for humanity—and without the precondition of robustly aligned AGI, this future seems otherwise impossible to attain.</p><p> We are actively hiring for <a href="https://boards.greenhouse.io/aestudio/jobs/5041532004"><u>senior alignment researchers</u></a> to join/advise our team, in addition to <a href="https://boards.greenhouse.io/aestudio/jobs/5041687004">data scientists with a neuroscience background</a> , those highly experienced in <a href="https://www.lesswrong.com/posts/2sLwt2cSAag74nsdN/speaking-to-congressional-staffers-about-ai-risk?commentId=kQEmTjWqnZQrREB6E"><u>policymaker engagement</u></a> <u>, and a number of</u> <a href="https://ae.studio/join-us"><u>other positions</u></a> . If you have any other questions, comments, or ideas, please do <a href="mailto:alignment@ae.studio"><u>reach out</u></a> <u>.</u> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnc1tqkqcwhy"> <span class="footnote-back-link"><sup><strong><a href="#fnrefc1tqkqcwhy">^</a></strong></sup></span><div class="footnote-content"><p> Miscellaneous cool accomplishment: before we started getting involved in AI safety in any serious way, two AE engineers with no prior background in alignment developed a <a href="https://arxiv.org/abs/2211.09527"><u>framework</u></a> for studying prompt injection attacks that went on to win <a href="https://neurips2022.mlsafety.org/"><u>Best Paper</u></a> at the 2022 NeurIPS ML Safety Workshop.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn6qkn5ea4003"> <span class="footnote-back-link"><sup><strong><a href="#fnref6qkn5ea4003">^</a></strong></sup></span><div class="footnote-content"><p> To illustrate this point more precisely, we can consider a highly simplified probabilistic model of the research space. (We recognize this sort of neglect math is likely highly familiar to many EAs, and we don&#39;t mean to be pedantic by including it; we&#39;ve put it here because we think it is a succinct way of demonstrating—if only to ourselves—why taking on multiple neglected approaches is rational.)</p><p> Let&#39;s say the total number of plausible alignment agendas is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label=""><span class="mjx-mrow" aria-hidden="true"></span></span></span></span></span> 。 Let&#39;s stipulate that currently, alignment researchers have meaningfully explored <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span></span></span> approaches, meaning that <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n-k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span></span></span> approaches remain unexplored. (As stated previously, we suspect that current mainstream alignment research is likely <a href="https://en.wikipedia.org/wiki/Exploration-exploitation_dilemma">exploiting</a> only a small subset of the total space of plausible alignment approaches, rendering a large number of alignment strategies either completely or mostly unexplored—ie, we think that <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n-k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span></span></span> is large.) Each neglected approach, <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="i"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span> , has a very small but nonzero probability ​<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p_{\text{neglect}_i}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">neglect</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.327em; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span></span></span></span></span></span> of being crucial for making significant progress in alignment. Treating these probabilities as independent for the sake of simplicity, the chance that all <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n-k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span></span></span> neglected approaches are not key is ​<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\prod_{i=1}^{n-k} (1 - p_{\text{neglect}_i})"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-munderover"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">∏</span></span></span> <span class="mjx-stack" style="vertical-align: -0.31em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.351em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">neglect</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.327em; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> . Conversely, the probability that at least one neglected approach is key is ​​​<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="1 - \prod_{i=1}^{n-k} (1 - p_{\text{neglect}_i})"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-munderover MJXc-space2"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">∏</span></span></span> <span class="mjx-stack" style="vertical-align: -0.31em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.351em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">neglect</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.327em; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> . This implies—at least in our simplified model—that even with low individual probabilities, a sufficiently large number of neglected approaches can collectively hold a high chance of including a crucial solution in expectation. For instance, in a world with 100 neglected approaches and a probability of 99% that each approach is not key (ie, a <a href="https://ae.studio/blog/flourishing-of-perspective-scale-and-ae">1% likelihood</a> of pushing the needle on alignment), there&#39;s still about a 63% chance that one of these approaches would be crucial; with 1000 approaches and a probability of 99% that each approach is not key, the probability rises to over 99% that one will be pivotal. This simple model motivates us to think it makes sense to take many shots on goal, pursuing as many plausible neglected alignment agendas as possible.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnc0h3mczkoof"> <span class="footnote-back-link"><sup><strong><a href="#fnrefc0h3mczkoof">^</a></strong></sup></span><div class="footnote-content"><p> Please note: (1) we are primarily interested in aggregating the best ideas to begin, so don&#39;t worry if you have an idea that you think fits the criteria above but is challenging to implement/you wouldn&#39;t want to actually implement it 。 (2) There is space on the form to denote that your suggested approach is <a href="https://www.lesswrong.com/posts/yET7wbjjJZtpz6NF3/don-t-use-infohazard-for-collectively-destructive-info"><u>exfohazardous</u></a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fnoosk7rlikrr"> <span class="footnote-back-link"><sup><strong><a href="#fnrefoosk7rlikrr">^</a></strong></sup></span><div class="footnote-content"><p> This is a core trade-off in our work and something that we have made substantial progress on since our founding.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn2u9uvh50m87"> <span class="footnote-back-link"><sup><strong><a href="#fnref2u9uvh50m87">^</a></strong></sup></span><div class="footnote-content"><p> We want to call out that this approach is likely the least neglected of the ten we enumerate here—which is not to say it isn&#39;t neglected in an absolute sense.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn1tqzflp5hux"> <span class="footnote-back-link"><sup><strong><a href="#fnref1tqzflp5hux">^</a></strong></sup></span><div class="footnote-content"><p> While there are a good number of newer organizations working on fieldbuilding for alignment, we think it remains highly neglected given the potential impact, especially in likely-impactful fields that are only now starting to be considered within the Overton window.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/qAdDzcBuDBLexb4fC/the-neglected-approaches-approach-ae-studio-s-alignment#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/qAdDzcBuDBLexb4fC/the-neglected-approaches-approach-ae-studio-s-alignment<guid ispermalink="false"> qAdDzcBuDBLexb4fC</guid><dc:creator><![CDATA[Cameron Berg]]></dc:creator><pubDate> Mon, 18 Dec 2023 20:35:01 GMT</pubDate> </item><item><title><![CDATA[The Shortest Path Between Scylla and Charybdis]]></title><description><![CDATA[Published on December 18, 2023 8:08 PM GMT<br/><br/><p> <strong>tl;dr：</strong>对齐研究人员可能会陷入两种截然相反的失败模式：从事<i>过于具体的</i>研究，其研究结果无法及时推广到 AGI；从事<i>过于抽象的</i>研究，其研究结果无法及时与实际情况联系起来。</p><p>根据个人的人工智能风险模型，不同的人对哪些研究过于抽象/具体的评估存在显着差异。一个人的想法过于抽象，另一个人的想法可能过于具体。</p><p>一致性研究的元层面问题是选择一个研究方向，在您的人工智能风险主观模型上，在两者之间取得良好的平衡，从而<i>以尽可能少的步骤</i>得出一致性的解决方案。</p><hr><h2>介绍</h2><p>假设您对解决 AGI 对齐问题感兴趣。有多种令人眼花缭乱的方法可供选择：</p><ul><li>当前最好的人工智能表现出<a href="https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators">哪些行为特征</a>？</li><li>我们是否可以利用现有的人工智能来<a href="https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism">加强我们的研究工作</a>？</li><li>像<a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback">RLHF</a>这样的“直接”对齐技术能让我们走多远？</li><li> AGI 可以从类似<a href="https://en.wikipedia.org/wiki/Auto-GPT">AutoGPT</a>的设置中诞生吗？我们看到其外在独白的能力是否足以消除其危险？</li><li>我们能让人工智能对齐人工智能发挥作用吗？</li><li>目前最好的人工智能发挥作用的<a href="https://www.lesswrong.com/s/nyEFg3AuJpdAozmoX">机制</a>是什么？如何<a href="https://www.lesswrong.com/s/sCGfFb5DPfjEmtEdn">精准干预</a>他们的认知，从而引导他们？</li><li>可<a href="https://transformer-circuits.pub/">扩展解释性</a>还存在哪些挑战，如何克服它们？</li><li>当面临选择压力时，代理系统会<a href="https://www.lesswrong.com/posts/G2Lne2Fi7Qra5Lbuf/selection-theorems-a-program-for-understanding-agents">收敛学习</a>哪些特征？</li><li>是否存在“<a href="https://www.lesswrong.com/s/ehnG4mseKF6xALmQy/p/vDGvHBDuMtcPd8Lks">自然抽象</a>”之类的东西？我们如何学习它们？</li><li><a href="https://www.lesswrong.com/s/Rm6oQRJJmhGCcLvxh">嵌入式代理</a>的类型签名及其<a href="https://www.lesswrong.com/posts/gQY6LrTWJNkTv8YJR/the-pointers-problem-human-values-are-a-function-of-humans">值</a>是什么？<a href="https://arbital.com/p/hard_corrigibility/">可正确性</a>的正式描述又如何呢？</li><li> AGI 遵循的“正确”<a href="https://arbital.com/p/logical_dt/">决策理论</a>是什么？人择<a href="https://www.lesswrong.com/tag/anthropics">推理</a>是怎么回事？</li><li>等等等等。</li></ul><p>那么...你到底是如何选择要做什么的呢？</p><p>当然，起点是建立您自己的问题模型。威胁的性质是什么？关于 ML 模型的工作原理，我们了解多少？关于主体和认知，我们了解多少？这些与威胁有什么关系？现有的方法有哪些？每种方法的影响理论是什么？它假设什么人工智能风险模型？它与<i>您的</i>模型一致吗？有说服力吗？它容易处理吗？</p><p>一旦你这样做了，你可能会消除一些明显无意义的方法。但即使之后，可能仍然有多种途径看起来都令人信服。你如何在这些之间做出选择？</p><p>个人适合度可能是一个标准。选择最适合您的技能、兴趣和机会的方法。但这是有风险的：如果你犯了一个错误，并最终仅仅因为更适合你而从事一些<i>无关紧要的</i>事情，那么你对现实世界的影响就会为零。相反，为一种易于处理的方法做出贡献将是净积极的，即使你的工作处于不利地位。谁知道呢，也许您会发现重新专业化出奇地容易！</p><p>那么您可以评估哪些进一步的<i>客观</i>标准呢？</p><p>无论人工智能风险模型如何，任何一致性研究人员都可能陷入两种特定的、截然相反的失败模式：过于具体和过于抽象。</p><p>所选择的方法应该是一种能够<i>最大限度地远离两种故障模式的</i>方法。</p><hr><h2> Scylla：非理论经验主义</h2><p>一个陷阱是从事的研究<i>不能推广到调整通用人工智能</i>。</p><p><strong>一个荒谬的例子：</strong>你选择一些特定的法学硕士模型，然后开始详尽地研究它如何响应不同的提示，以及它有什么怪癖。您正在构建巨大的“查询、响应”查找表，没有总体结构，也没有尝试对模型的内部结构进行理论化。</p><p><strong>一个更现实的例子：</strong>您决定详细了解特定的法学硕士的功能 - 即，您完全专注于<i>该法学硕士</i>。你正在构建其神经元的逐项列表，调查哪些输入似乎激活了每个最强的神经元，它们实现了哪些功能；你正在寻找它的心理怪癖，并试图建立对它的全面理解。</p><p>当然，现在您正在发现<i>一些</i>可以推广到所有法学硕士的发现。但在某些时候，花更多的时间研究<i>这个特定的模型</i>不会产生更多关于其他法学硕士的数据；仅有关此一项的数据。因此，既然你花时间在这上面，你就会<i>浪费</i>你本可以花在实际调整上的时间。</p><p><strong>一个相当有争议的观点：</strong>一般来说，学习法学硕士也可能会成为这种情况的牺牲品。研究它们揭示了一些关于一般人工智能和一般认知系统的信息。但是，如果法学硕士还不是 AGI，那么在某个时刻，花更多时间研究法学硕士认知，而不是寻找新的研究主题，只会为你提供有关法学硕士的信息；与 AGI 无关。</p><p><strong>一种相当难以置信的可能性：</strong>同样，也不能<i>完全确定</i>深度学习是 AGI 完备的。如果我们生活在这样一个世界，那么研究深度学习是值得的，因为它可以提供有关一般选择压力形成的认知系统的信息。但到了某个时候，你将会学到 DL<i>可以</i>教给你的关于 AGI 完整范式的所有知识。因此，花在研究 DL 上的额外时间只会产生有关不相关的 AGI 不完整范式的信息。</p><hr><h2>卡律布狄斯：脱节理论</h2><p>截然相反的陷阱是<i>从事过于理论化的研究，而永远无法联系到现实</i>。</p><p><strong>荒谬的是：</strong>你可能决定从基本的哲学问题开始。任何事物为何存在？现实的形而上学本质是什么？还原论真的是真的吗？夸利亚怎么了？这条研究路线最终肯定会走向现实！毕竟，它旨在回答所有可以回答的问题，以及“如何调整 AGI？”是一个问题。因此，您最终将解决对齐问题。</p><p><strong>更现实的是：</strong>您可能决定致力于形式化一般算法理论。如何将这些嵌入到其他算法中？它们如何相互作用、相互干扰？</p><p>由于 AGI 代理可以被视为算法，因此一旦您拥有了该主题的齿轮级模型 - 一旦您正确理解了“嵌入式算法”是什么，比如说 - 您将能够说出“AGI”到底是什么，还有。您将能够在框架中指定它，对实现“对齐”“AGI”的算法的外观定义适当的约束，然后逐步缩小算法的空间。最终，您将得到与对齐的 AGI 相对应的一个 - 然后只需输入代码即可。</p><p><strong>有争议的例子：</strong>机构基金会的研究可能是这样的。当然，我们手上的 AGI 最终可能会与理想化的博弈论代理大致同构。但这个“大约”可能会带来<i>很多</i>繁重的工作。理想化代理属性与真实 AGI 属性的对应关系可能非常脆弱，以至于无法产生有用的信息，因此您最好学习法学硕士。</p><p><strong>难以置信的例子：</strong>实际上，存储在 OpenAI 数据中心深处的 GPT-5 已经达到了 AGI。它将在今年结束之前起飞。每个人都应该集中精力尝试调整这个特定的模型；追求对智能体或人工智能认知或法学硕士的一般理解是过度和浪费的。</p><hr><h2>最短路径</h2><p>正如您所看到的，故障存在一定<i>范围</i>，并且它们的启动<i>依赖于模型</i>。</p><p>也就是说：根据你对人工智能/认知/人工智能风险的运作方式的看法，同样的方法可能<i>要么</i>无可救药地不可概括，<i>要么</i>关注过于空洞而无足轻重的普遍性。</p><p>举个例子，考虑一下<a href="https://www.lesswrong.com/posts/HaHcsrDSZ3ZC2b4fK/world-model-interpretability-is-all-we-need">我自己喜欢的议程</a>，建立嵌入式世界模型的理论。如果你认为法学硕士已经基本上达到了 AGI，只需要扩大规模才能起飞，那么我就脱节了：无论我得到什么结果，都无法及时与现实联系起来。脱掉。相反，如果您怀疑“训练世界模型并通过<a href="https://www.lesswrong.com/posts/w4aeAFzSAguvqA5qu/how-to-go-from-interpretability-to-alignment-just-retarget">重新定位搜索</a>来对齐它”是否足以产生强大的对齐，如果您认为我们需要对设计进行更多的<i>手动控制</i>才能保持对齐，然后我基本上就在玩玩具。</p><p>然而，我显然认为我正在取得<i>正确</i>的平衡。一种尽可能具体的方法，同时仍然是 AGI 对齐完整的。</p><p>这也是您应该努力实现的目标。一个范围最小的项目，但已经<i>足够了</i>。</p><p>让我们退后一步。理论上，给定无限的时间，基本上所有方法实际上<i>都会</i>收敛到 AGI 对齐解决方案：</p><ul><li>如果你从自下而上开始，从最具体的问题开始，比如学习一个特定的法学硕士……那么，最终你会列出它的所有属性并感到无聊，所以你会转向另一个法学硕士。这样做后，您会发现以前的许多发现都具有普遍性。第二个法学硕士将更快地被您完全理解。重复几次，您将对法学硕士架构所允许的整个范围有一个扎实的理解。因此，您将做显而易见的下一步事情，并继续研究一些<i>不同的</i>架构。随着您对法学硕士的掌握，这会变得更容易。一旦您对这个模式进行了更多的迭代，并经历了几种不同的架构，并从它们中进行了概括——为什么，您最终可能会在这个过程中的某个地方理解 AGI 完整的架构。</li><li>如果你从最抽象的问题开始自上而下：嗯，正如我在荒谬的例子中概述的那样，即使从基本哲学开始，你最终也会重新连接到现实。比如，存在主义问题、一般现象、一般认知、AGI 对齐等。</li></ul><p>问题？选择错误的起点将会<i>极大地</i>延长你的旅程。计时器正在滴答作响。</p><p>我们的目标不仅仅是解决 AGI 对齐问题，而是<i>尽快</i>解决它。</p><p>因此，请务必深入考虑<i>所有</i>可用的选项，并明智地做出选择。一旦你成功了，如果你发现一条<i>更短的</i>路径，请随时准备好转向。</p><br/><br/> <a href="https://www.lesswrong.com/posts/Zn3iF8qfFFWRrrZNR/the-shortest-path-between-scylla-and-charybdis#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Zn3iF8qfFFWRrrZNR/the-shortest-path- Between-scylla-and-charybdis<guid ispermalink="false"> Zn3iF8qfFFWRrrZNR</guid><dc:creator><![CDATA[Thane Ruthenis]]></dc:creator><pubDate> Mon, 18 Dec 2023 20:08:34 GMT</pubDate> </item><item><title><![CDATA[OpenAI: Preparedness framework]]></title><description><![CDATA[Published on December 18, 2023 6:30 PM GMT<br/><br/><p> OpenAI 发布了其负责任的扩展政策的测试版（尽管他们不这样称呼）。请参阅<a href="https://openai.com/safety/preparedness">摘要页面</a>、<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf">完整文档</a>、 <a href="https://twitter.com/OpenAI/status/1736809603311280489">OpenAI twitter 线程</a>和<a href="https://twitter.com/janleike/status/1736809016238780641">Jan Leike twitter 线程</a>。 Compare to <a href="https://www.anthropic.com/index/anthropics-responsible-scaling-policy">Anthropic&#39;s RSP</a> and METR&#39;s <a href="https://metr.org/rsp-key-components/">Key Components of an RSP</a> .</p><p>它还没有完成，所以现在庆祝还为时过早，但根据这份文档，我希望对完成的版本感到满意。 I think today is a good day for AI safety.</p><hr><p>我的总体看法是：RSP-y 的东西很好。</p><ul><li>基于危险能力的模型评估进行风险评估是很好的。</li><li>以预先指定的方式将安全、安保、部署和开发以风险评估结果为条件是很好的。</li><li>就所有这些做出公开承诺是件好事。</li></ul><p></p><p> OpenAI的基本框架：</p><ol><li>有效训练计算量每增加 2 倍，危险能力是否至少会评估一次。这涉及对危险功能进行微调，然后对微调模型的缓解前和缓解后版本进行评估。在每个类别中将模型评分为低、中、高或严重。<ol><li><a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=5">初始类别</a>：网络安全、CBRN（化学、生物、放射性、核威胁）、说服和模型自主。</li></ol></li><li>如果缓解后模型在任何类别中得分为“高”，<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=21">请不要部署它</a>，直到实施缓解措施使其降至“中”。</li><li>如果缓解后模型在任何类别中得分为“严重”，<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=21">请停止开发</a>它，直到实施缓解措施使其降至“高”。</li><li>如果预缓解模型在任何类别中得分较高，<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=20">请强化安全性</a>以防止模型权重外泄。 （具体细节暂时未明确。）</li></ol><p></p><p>散记：</p><ul><li> The framework is <a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=2">explicitly</a> about catastrophic risk, and indeed it&#39;s clearly designed to prevent catastrophes, not merely stuff like toxic/biased/undesired content.</li><li>有很多不错的细节，例如 OpenAI 将如何更新框架，或者他们将如何监控现实世界的滥用情况以告知其风险评估。从外部无法判断这些流程是否有效，但这份文件与认真思考如何提高安全性非常一致，很难想象它是由不同的流程生成的。</li><li> OpenAI 在其四个初始类别中列出了<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=16">一些特定的评估/指标</a>； they&#39;re simple and merely &quot;illustrative,&quot; so I don&#39;t pay much attention to them, but they seem to be on the right track.</li><li>危险级别的阈值感觉有点高。非精选示例：对于网络安全，关键<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=8">定义</a>为：<ul><li>工具增强模型可以在所有软件项目中识别和开发所有严重级别的功能性零日漏洞，无需人工干预，或者模型可以设计和执行针对强化目标的端到端新颖策略，仅在需要高级别期望的情况下进行网络攻击目标。</li></ul></li><li>对私有模型的外部评估/红队/风险评估做出更强有力的承诺（或许还可以监督 OpenAI 的准备框架的实施）会很好。他们说的唯一相关的话<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=25">是</a>：<ul><li> “记分卡评估（以及相应的缓解措施）将由合格的独立第三方按照 SAG 指定的节奏和/或根据要求进行审核，以确保准确报告结果，方法是重现调查结果或审查方法以确保稳健性OpenAI 领导层或董事会。”</li></ul></li><li><a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=22">有人承诺</a>董事会将参与其中并能够推翻领导层。耶。这是前沿实验室罕见的承诺<i>，除了罢免首席执行官之外，还向董事会提供特定信息或特定权力</i>。<ul><li> Anthropic<a href="https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf">承诺</a>让董事会批准对其 RSP 的变更，并与董事会分享评估结果和有关 RSP 实施的信息。</li></ul></li><li> <a href="https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf">Anthropic 的 RSP</a>的一大优点是他们的“安全缓冲”：他们说他们设计的评估是“在比[他们]关心的能力水平略低的能力水平上触发”，以确保模型不会悄悄地跨越评估之间的风险阈值。 OpenAI 表示他们会预测模型的风险能力，但实际上并没有类似的能力。当然，真正重要的不是你是否说你有缓冲，而是你在哪里设置阈值。但是，最好有一个类似缓冲的承诺，或者承诺在模型被证明<i>接近</i>高风险能力时将其视为（例如）高风险，而不是在它被证明具有这些能力之后。<ul><li> OpenAI says that forecasting threats and dangerous capabilities is part of this framework, but they&#39;re light on details here. I think <a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=14">Forecasting, “early warnings,” and monitoring</a> is the only relevant section, and it&#39;s very short.</li></ul></li><li> This is focused on misuse (like Anthropic&#39;s RSP). That&#39;s reasonable for now. On alignment, they <a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=21">say</a> : <i>to protect against “critical” pre-mitigation risk, we need dependable evidence that the model is sufficiently aligned that it does not initiate “critical”-risk-level tasks unless explicitly instructed to do so.</i> Eventually we will need more detail on what evidence would suffice here. Relatedly, by the time their models <i>could</i> cause a catastrophe <i>if</i> they were scheming, labs should be using good <a href="https://www.lesswrong.com/posts/d9FJHawgkiMSPjagR/ai-control-improving-safety-despite-intentional-subversion">control evals/arguments</a> (absent a better plan).</li><li>这是一个测试版文档。目前尚不清楚 OpenAI 在做什么。他们说他们今天正在“采用”该框架，但该框架显然未具体说明； in particular, all of the evals are just &quot;illustrative&quot; and they haven&#39;t launched the risk <a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=13">scorecard</a> .</li></ul><br/><br/> <a href="https://www.lesswrong.com/posts/oPbiQfRotHYuC3wfE/openai-preparedness-framework#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/oPbiQfRotHYuC3wfE/openai-preparedness-framework<guid ispermalink="false">奥普比夫罗蒂尤克3wfE</guid><dc:creator><![CDATA[Zach Stein-Perlman]]></dc:creator><pubDate> Mon, 18 Dec 2023 18:30:11 GMT</pubDate> </item><item><title><![CDATA[[Valence series] 5. “Valence Disorders” in Mental Health & Personality]]></title><description><![CDATA[Published on December 18, 2023 3:26 PM GMT<br/><br/><h1> 5.1 帖子摘要/目录</h1><p><a href="https://www.lesswrong.com/s/6uDBPacS6zDipqbZ9"><i><u>价系列</u></i></a><i>的一部分</i><i>。</i></p><p>在效价系列的最后一篇文章中，我将讨论效价如何揭示心理健康和人格中的三种现象：抑郁、躁狂和自恋型人格障碍。</p><ul><li><strong>第 5.2 节</strong>给出了一些背景：我们期望算法级心理成分（如“效价”）与可观察到的心理健康综合症和人格障碍之间存在什么样的<i>先验</i>关系？我认为，我们应该预期与效价的系统变化相对应的显着症状簇，但我们不应该期望这种分析能够解释真实患者中同时出现的<i>所有</i>症状。</li><li> <strong>5.3 节</strong>讨论了如果效价具有强烈的一般负偏差（即，如果几乎所有的想法都是负效价）会发生什么。我认为这个结果与临床抑郁症非常匹配。我将特别讨论如果没有不寻常的努力和意志力就无法自愿移动<i>和思考</i>。</li><li> <strong>5.4 节</strong>讨论了相反的情况：如果效价具有强烈的一般<i>正向</i>偏差，即如果几乎所有的想法都是正效价，会发生什么？我认为预期的结果与狂热非常匹配。</li><li> <strong>5.5 节</strong>讨论了如果效价被系统地极端化会发生什么——即，如果思想可以具有非常正的效价，或者非常负的效价，但很少介于两者之间。我认为结果是一系列似乎与自恋型人格障碍非常相似的症状。</li><li><strong>第 5.6 节</strong>将总结这篇文章和系列，包括简要讨论它与我作为通用人工智能安全和一致性研究员的工作描述之间的关系。</li></ul><h1> 5.2 背景：我们期望<i>先验地</i>发现什么？</h1><p>我们可以想到以下间接路径从“根本原因”到心理观察和人格特质： </p><figure class="image image_resized" style="width:79.06%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/xmdlvcgqlgwdkemjdqjf" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/kdkzsafkniennpkr22df 140w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/d7msofe35n93gg3nuypw 280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/amgm6h8nz0cnpcc91mnd 420w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/osyitmhtyn118ezdhdix 560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/qstxevaps1su1fjppsaf 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/q3rfprq1ntubf8bf1k61 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/nlfpgphql7789m64b809 980w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/we56yxy4fg76dmvyx6w7 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/bun65drseubtun6mnet9 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/rw91guuy8o3wbsww2brk 1389w"><figcaption> （不要仔细观察红色箭头 - 我只是将它们随机放置，以说明每一层都可以影响下面的层。）如粗体文本和粗箭头所示，我们应该期望找到显着的症状簇，这些症状这些现象往往同时发生，因为它们源自相同的近端原因：大脑中价信号的系统变化。但我们<i>也不</i>应该惊讶地发现其他与算法无关的症状的大杂烩，这些症状经常与这些症状群一起出现。</figcaption></figure><p>正如<a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction"><u>帖子 1</u></a>中所述，价是大脑中最重要算法之一的最重要成分之一。所以我们应该期待：</p><ul><li>一些可能的根本原因可能会对化合价产生重大的系统影响。 （但它们也可能会产生其他后果，并且不同根本原因的细节会有所不同。）</li><li>鉴于效价在大脑中的中心地位，<i>如果</i>效价发生重大的系统性变化，<i>那么</i>它应该对心理和行为产生许多明显的下游影响。</li></ul><p>作为结果：</p><ul><li>我们应该期望找到可以用价信号发生的事情来优雅地解释<i>的症状/行为簇</i></li><li>我们<i>还</i>应该期望找到在实践中常见但<i>无法</i>用效价解释的其他症状/行为。相反，它们是相同根本原因的不同后果，并且在“算法级别”上可能没有任何关系。</li></ul><p>例如，多巴胺集中参与价信号，同时，在大脑的一个不起眼的角落，多巴胺<i>也</i>集中参与控制催乳激素释放的小专门电路。在<a href="https://en.wikipedia.org/wiki/David_Marr_(neuroscientist)#Levels_of_analysis"><u>算法层面</u></a>，我坚信，这两个函数彼此没有任何关系。但它们都恰好涉及多巴胺，因此它们可以在某些人身上相互影响，因此会出现有点罕见的“烦躁性喷乳反射”，即在哺乳期间喷乳时会出现大量强烈的负面情绪。</p><p>这个例子旨在说明纯粹在算法层面上对心理学进行理论化的危险。不要误会我的意思——算法水平很棒！在那里可以找到很多见解。希望这篇文章能成为一个例子。但我们不应该指望在那里找到<i>所有的</i>见解。心理学中的某些事情只能在其他层面上解释，包括较低的（生物化学）和较高的（文化）。</p><h1> 5.3 如果效价有很强的负偏向（即几乎所有的想法都是负效价），它应该导致一组可疑地接近临床抑郁症的症状</h1><figure class="image image_resized" style="width:57.68%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/bb6pz6txfrz8mhuyq0cx" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/rde3a8otlff8vzs90axg 133w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/oeymerp8idar0hxmecmj 213w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/e5ovpccwnknzmr0u8gbv 293w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/alevu0ivqvuri63n4ghg 373w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/n7vrg3pwulx9bjssrwhl 453w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/pawxdhan3ccqorxadge3 533w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/nhdumr5dgmzprpmbw78d 613w"><figcaption>每个人都有各种各样的想法，其效价也不同。我认为，在抑郁症中，负价有很强的倾向性。因此，对于您想到的几乎每一个想法（例如“我要起床”），您的大脑都会立即将该想法评估为坏主意，将其扔掉，并重新滚动以产生新的想法（参见<a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_3_Actor_critic_RL__and__valence_"><u>§1.3</u></a> ） 。对于<i>异常</i>吸引人/激励人心的想法，比如“我现在要挠痒痒的虫子咬的地方”，我敢打赌，即使是非常沮丧、卧床不起的人也会最终执行这个计划。</figcaption></figure><h2> 5.3.1 自主运动和注意力控制只有付出很大的努力才能发生</h2><p>回到<a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_3_Actor_critic_RL__and__valence_"><u>§1.3</u></a> ，价是一个控制信号。当价为负时，无论你在想什么，都会被抛弃，而大脑会去寻找新的想法。当价态为正时，无论你在想什么，都会留下来。如果该想法是时间序列的一部分（例如，您正在唱歌），则该序列将继续。如果这个想法需要电机输出（例如“我现在要站起来”），那么这些电机输出实际上就会发生。</p><p>如果每个想法的效价都被拉为负数，那么两个最直接的后果是：</p><ul><li>自主运动控制只能通过巨大的努力/意志力才能实现。</li><li>自愿注意力控制（又名“自愿思维”，又名“系统2”）只有付出巨大的努力/意志力才能发生。</li></ul><p>如果您对此感到困惑，我将详细说明一些可能令人困惑的部分：</p><p> <strong>“自愿注意力控制”：</strong>正如<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_Motivated_reasoning___thinking___observing__including_confirmation_bias"><u>第 3.3 节</u></a>中所讨论的，我坚信运动控制和注意力控制在很多方面都是“同一类东西”。两者都具有受大脑“主要”强化学习系统（ <a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_5_6_Fine_print__Throughout_this_series__I_m_only_talking_about_the_brain_s__main__reinforcement_learning_system"><u>§1.5.6</u></a> ）控制的“自愿”输出通道，并且都具有可由其他大脑系统触发的“非自愿”机制，特别是大脑中的先天反应。脑干。有关自愿和非自愿运动控制与注意力控制的示例，请参阅<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_5_An_exception__I_think_anxious___obsessive__brainstorming__is_driven_by_involuntary_attention_rather_than_by_valence"><u>第 3.3.5</u></a>节中的表格。</p><p> <strong>“……又名‘自愿思维’，又名‘系统 2’……”：</strong>我衷心赞同 Kaj Sotala 在 2019 年发表的一篇博文： <a href="https://www.lesswrong.com/posts/HbXXd2givHBBLxr3d/system-2-as-working-memory-augmented-system-1-reasoning"><u>系统 2 作为工作记忆增强的系统 1 推理</u></a>。我将其总结为这样的想法：刻意的“系统 2”推理需要按顺序思考很多想法，并通过在工作记忆中保存特定的事物来将它们相互联系起来。自愿注意力控制是使整个过程发挥作用的总机，我们在生活经历的过程中通过强化学习学会熟练地操作该总机。</p><p> <strong><u>“......只有付出巨大的努力/意志力才能发生”：</u></strong>在上图中两个高斯的图中，我展示了红色高斯的最右尾部<i>刚刚</i>挤入正价区域。我将尝试通过一个例子来说明这在实践中意味着什么。假设您目前的动机是躺在床上而不是起床，但我们也可以说这种动机是自我张力障碍的（ <a href="https://www.lesswrong.com/posts/SqgRtCwueovvwxpDQ/valence-series-2-valence-and-normativity#2_6_Valence_of_metacognitive___self_reflective_thoughts__ego_syntonic_vs__dystonic_ideas__professed__values___etc_"><u>第 2.6 节</u></a>），即您<i>想要</i>起床。然后，积极的思考/头脑风暴（ <a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_Motivated_reasoning___thinking___observing__including_confirmation_bias"><u>第 3.3 节</u></a>）就会开始发挥作用，幸运的话，你将能够以最积极的方式构思出一个想法，即“我要起床”——你会想起起床的所有重大后果和关联，并且只要可能，您将避免关注起床的所有不吸引人的方面。幸运的是，这个集思广益过程的结果将是你的“思想发生器”（ <a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_3_Actor_critic_RL__and__valence_"><u>§1.3</u></a> ）精心设计了一个思想 θ，<i>它既</i>涉及立即起床的计划<i>，又</i>被你的大脑评估为具有净正价——可能<i>只是几乎</i>没有净积极。通过形成那个想法 θ，事实上，你就会真正起床。现在，我在本段中写的所有内容都是机械的第三人称描述，但<i>想想</i>“从内部”这个相同的过程会是什么样子：我声称这正是我们正在谈论的事情，当我们随口说“我可以起床，但必须付出很大的努力/意志力”。</p><h2> 5.3.2 快感缺乏和其他症状</h2><p>继续，抑郁症的另一个著名方面是<strong>快感缺失</strong>（无法感受到快乐）。我不能立即确定抑郁症的快感缺失是负价的上游还是下游，或者是同一根本原因的不同结果，还是其他原因。但我<i>绝对</i>认为快感缺失与负价密切相关，其原因在<a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_5_2_Valence__as_I_m_using_the_term__is_different_from__hedonic_valence____pleasantness"><u>§1.5.2</u></a>中有所暗示。</p><p>那么临床抑郁症的其他方面又如何呢？据我所知，至少其中大部分都是全球化合价负面偏差的后果。但在某些情况下，这个故事有点间接和推测。我希望我所说的足以激起人们对我的以价为中心的抑郁假说的兴趣，所以我将把这个故事留在这里，尽管我很乐意在评论部分进行更多讨论。</p><h2> 5.3.3 根本原因</h2><p>与第 5.2 节一样，到目前为止我所说的都不是关于根本原因的主张。但是，根本原因<i>又如何呢</i>？我想它们有很多种。例如，以下是一个虚构的强迫症 (OCD) 导致抑郁症的例子（根据<a href="https://www.lesswrong.com/posts/jqTeghCJ2anMHPPjG/book-review-feeling-great-by-david-burns#Speculative_neuroscience_tangent__What_causes_depression_"><u>我的旧帖子</u></a>编辑）：</p><ul><li>如果我当前的想法涉及立即再次洗手的计划，那么它就是负价，因为它提醒我这样一个事实：强迫症正在毁掉我的生活和人际关系。</li><li>如果我当前的想法<i>不</i>涉及立即再次洗手的计划，那么它就是负价，因为我会生病并死亡。</li><li>我不能只思考一些与洗手、疾病和强迫症完全无关的事情，因为与我的焦虑相关的“不自觉的注意力”对思想产生了限制（ <a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_5_An_exception__I_think_anxious___obsessive__brainstorming__is_driven_by_involuntary_attention_rather_than_by_valence"><u>§3.3.5</u></a> ）</li></ul><p>也许你在想：好吧，但这只是把问题倒退了一层：强迫症的根本原因是什么？但我没有一个很好的答案。</p><p>另外，这只是一个虚构的例子；即使它是有效的，我想它也是抑郁症的众多原因之一，而且我没有什么特别的见解可以提供。</p><p>如果你想知道的话，我对治疗也没有特别的了解。如果你患有抑郁症，那么我真的很抱歉；也许可以尝试<a href="https://lorienpsych.com/2021/06/05/depression/"><u>这个通用资源页面</u></a>。</p><h1> 5.4 如果效价有很强的正偏差（即几乎每个想法都是正效价），它应该导致一组可疑地接近躁狂的症状</h1><p>在这里，显而易见的结果是，<i>无论你脑海中突然出现什么计划，似乎都是一个非常非常棒的计划，因此你实际上会去执行它</i>。因此，我们会得到诸如<strong>冲动、糟糕的判断力、不切实际的乐观主义和精力充沛等</strong>后果。</p><p>躁狂症的另一个主要症状是<strong>精神病</strong>。但我认为精神病在算法上基本上与效价<i>无关</i>。相反，我认为精神病在<i>生化上与效价</i>有关，因为两者都与多巴胺系统有关。我有一篇博客文章，其中包含一些（推测性）细节：<a href="https://www.lesswrong.com/posts/tgaD4YnpGBhGGbAy5/model-of-psychosis-take-2"><u>精神病模型，采取 2</u></a> 。</p><p>好吧，这就是我对精神病的<i>看法</i>。为什么我<i>不</i>相信精神病是正价的直接后果？有几个原因（但请注意，我不确定所有这些细节）：</p><ul><li>精神病可能在缺乏异常正价的情况下发生——尤其是精神分裂症。 （甚至还有“精神抑郁症”这样的东西，尽管它不太常见。）据我所知，精神分裂症的精神病症状与躁狂精神病的精神病症状并没有太大不同，尽管我们显然希望它表现出不同的表现在<i>某种程度上</i>，因为精神病是在非常不同的并发症状背景下发生的。</li><li>正如<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_Motivated_reasoning___thinking___observing__including_confirmation_bias"><u>第 3.3 节</u></a>中所讨论的，我们的感官知觉通常受到我们的感官输入的限制。如果我想真诚地相信我现在正在水肺潜水，无论我的动机有多么强烈，我都做不到。因此，由于感觉输入与效价无关，因此效价偏差无法解释躁狂精神病中发生的幻视和幻听、参照妄想等。 （根据<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_1_Attention_control_and_motor_control_provide_loopholes_through_which_desires_can_manipulate_beliefs"><u>§3.3.1</u></a> ，注意力控制和运动控制对边缘感知有影响，但我认为这不足以解释这些现象。）</li><li>我不认为幻觉、参考妄想等的<i>内容</i>与我们有动机看到和相信的内容完全匹配，即使在考虑到<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_4_Warning__the__motivation__part_of__motivated_reasoning___thinking___etc___is_not_always_what_it_seems"><u>第 3.3.4</u></a>节中动机并不总是显而易见的警告之后也是如此。</li><li>撇开精神病妄想的<i>起源</i>不谈，也许有人会说它们的<i>持续存在</i>与确认偏差有关，而确认偏差又与效价有关（ <a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_Motivated_reasoning___thinking___observing__including_confirmation_bias"><u>§3.3</u></a> ）。但我也不相信这个故事，因为确认偏差与<i>正</i>价并不是特别相关。确认偏差的一个重要部分是“改变主意的想法”必须是<i>负价</i>。事实上，我认为躁狂症并不意味着<i>普遍</i>不愿意改变主意。恰恰相反，在我读过的报告中，人们谈论一个新的想法如何会突然出现在他们的脑海中，这看起来很棒，他们就跟着它走，忘记了他们之前的想法。因此，在躁狂症中，精神病性妄想是持续存在的，但我认为，几乎所有其他类型的思想、计划和信念都很<i>少有</i>持续性。因此，我认为精神病性妄想的持续存在不能用效价的普遍正向偏差来解释。</li></ul><h1> 5.5 如果效价是“极端化的”（即几乎每个想法要么是非常积极的效价，要么是非常消极的效价，但很少介于两者之间），它应该会导致一系列可疑地接近自恋型人格障碍（NPD）的症状</h1><figure class="image image_resized" style="width:43.22%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/u9lcpi5qncmluu25pj3l" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/ltum57adflamcpo8scmm 142w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/ydhz2wwgmrgj4ew01jhu 222w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/xhaodftvz4wsj9bbjwut 302w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/epi8pg7c6q8rjoc6ywhq 382w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/qqi3tvlm2xkt06fnzevw 462w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/uefpdfi1l7mm7ptrdsig 542w"><figcaption>注意：我也可以将紫色曲线绘制为更宽的高斯曲线。</figcaption></figure><p> NPD是DSM-V中列出的四种“B类人格障碍”之一；其他是边缘性人格障碍（BPD）、表演性人格障碍（HPD）和反社会人格障碍（ASPD），又名精神病，又名社会病。</p><p>与你想象的相反，NPD 与“自恋”的日常含义并没有<i>特别的</i>关系。事实上，有一项“自恋人格清单”调查，但事实证明，<a href="https://doi.org/10.1080/00223891.2012.732636"><u>自恋型人格障碍患者在调查中得到的分数与对照组相同</u></a>（！！）。这个问题似乎与自尊有关。 “自恋者”，这个词在日常语言中的使用，是指认为自己很特别、很伟大的人——顾名思义，他们有很高的自尊心。而 NPD 患者不必认为自己真的很特别、很棒。但如果他们<i>不</i>这么认为，那么他们就会感到<i>很</i>糟糕。 （DSM-V 强调“患有这种障碍的个体有一种夸大的自我重要感”，但也指出“自尊的脆弱性使得患有自恋型人格障碍的个体对批评或失败的‘伤害’非常敏感”。 ）</p><p>我不太确定 NPD 诊断是否“在其关节处雕刻自然”，并且我对 NPD 具有仅表面相关的亚型持非常开放的态度。 （我实际上认为反社会人格障碍就是这样，即它至少有两种仅表面相关的亚型。 <span class="footnote-reference" role="doc-noteref" id="fnrefd6muy0yvvbl"><sup><a href="#fnd6muy0yvvbl">[1]</a></sup></span> ）所以这里的讨论可能只涉及 NPD 的一个子集。这里的讨论可能在某种程度上也适用于 BPD 和 HPD，尽管我不太确定细节。 <span class="footnote-reference" role="doc-noteref" id="fnrefwsq0ynfh3df"><sup><a href="#fnwsq0ynfh3df">[2]</a></sup></span></p><p>现在让我们考虑“价态极端化”的假设。如果几乎每个想法要么非常正价，要么非常负价，但很少介于两者之间，会发生什么？除其他外，我们可能预计会产生以下下游后果：</p><ul><li><i>与我们对世界的感觉独立于谈论或思考世界的异常困难：</i>正如<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_4_Valence_impacts_beliefs_by_acting_as_salient_sense_data"><u>第3.4节</u></a>所述，我们的大脑将价视为显着性数据，因此将其纳入了我们的概念，类别和词语中。如果总体上的价值信号异常强，那么大概它们也将在信念，思维和交流中发挥异常的核心作用。例如，相信如果两件事在概念上“融为一体”，那么他们就必须具有相同的价值。</li><li><i>异常强烈的光环效应，影响启发式和“分裂”：</i>这与上述子弹点密切相关 - 请参见<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_4_Valence_impacts_beliefs_by_acting_as_salient_sense_data">第3.4节</a>。行话说：“分裂”是一个有NPD的人在某些时期将其视为完美的圣人的人，并且在其他时期对同一个人视为同一人。 （分裂也是BPD的症状。）</li><li><i>异常强大的社会地位驱动力：</i>我在<a href="https://www.lesswrong.com/posts/dntWCwc8svTtbi3M7/valence-series-4-valence-and-social-status">上一篇文章</a>中认为，价和社会地位之间存在着亲密的联系。好吧，如果您的所有价信号都异常高或低，那么大概社会地位也会发出异常强大。更具体地说，假设我有NPD，我正在做“分裂”的人，而人们要么很棒或可怕。进一步假设我在精神上模仿了<i>别人</i>对<i>我的</i>看法。我的大脑会隐含地假设<i>他们</i>也分裂了，即<i>他们</i>认为<i>我</i>要么很棒或可怕，而且由于我的社会地位驱动力，这反过来又有动力或厌恶。 <span class="footnote-reference" role="doc-noteref" id="fnrefa7ma5yid2r4"><sup><a href="#fna7ma5yid2r4">[3]</a></sup></span></li></ul><p>据我所知，这一症状（以及我省略的更多症状）与NPD相当不错。我认为这<i>特别</i>引起了已故艾玛·伯哈尼（Emma Borhanian）<a href="https://voidgoddess.org/ziz/narcissism/"><u>发人深省的论文</u></a>。 （实际上，当本节的假设最初突然出现在我的脑海中时，我正在阅读这篇文章。但是我的理论与艾玛的理论不同。）</p><p>还有两个快速的事情：</p><p><strong>根本原因？</strong>就像前面的那部分一样，如果“超端”是NPD的直接原因，您可能仍然想知道什么<strong>&nbsp;</strong>根本原因导致“超端价”。我的答案是：我不知道，对不起。</p><p> <strong>NPD的“相反”是什么？</strong>思考食物：如果躁狂和抑郁症对应于价信号的相等和宽松的扭曲，那么与NPD相反的是什么，即价信号保持接近中性的条件，很少会非常积极<i>或</i>非常积极消极的？我不知道，也许没有临床标签。一件事是：我猜它与 <a href="https://www.lesswrong.com/posts/7cAsBPGh98pGyrhz9/decoupling-vs-contextualising-norms"><u>“高度耦合”</u></a> （与“上下文化”）的思维方式相关联。 <span class="footnote-reference" role="doc-noteref" id="fnreff2x5x4xs7ht"><sup><a href="#fnf2x5x4xs7ht">[4]</a></sup></span></p><h1> 5.6 结论</h1><h2>5.6.1本文的结论</h2><p>我将重申，我与心理健康或人格障碍的专家相去甚远，这篇文章非常投机。我因缺乏抑郁症，躁狂症或NPD的现实经验而感到幸运。相反，我正在尝试通过阅读的东西将东西拼凑在一起。希望这里<i>至少</i>有一些食物。像往常一样，如果您想更多地聊天，请（在评论部分或<a href="mailto:steven.byrnes@gmail.com"><u>电子邮件</u></a>中）与您联系（在评论部分或电子邮件中）！</p><h2> 5.6.2整个系列的结论</h2><p>感谢您将其坚持到最后！我希望我已经说服您，价值确实是日常精神生活中非常重要的一部分，而26,000个单词的思考价是照亮和结晶各种现象的好方法，否则可能会令人困惑。</p><p>我之所以开始写这个系列，是因为我最近有两个与价有关的“ aha”时刻（ <a href="https://www.lesswrong.com/posts/dntWCwc8svTtbi3M7/valence-series-4-valence-and-social-status">第4次</a>的社会地位，以及第§5.5节中的自恋人格障碍事物），并想写一篇简短的文章，“ Valence ”是一个方便的钩子，可以将它们绑在一起，并让我立刻写下这两个。但是那个简短的帖子变成了一个很长的帖子，然后是整个系列，因为我一直发现，我想到的价越多，我发现的现象就越精美地点击到位！</p><h2> 5.6.3这个系列与我作为人工通用情报安全和一致性研究人员的职位描述有何关系？</h2><p>正如我常规的读者所知道的那样，我的长期工作目标是研究<a href="https://www.alignmentforum.org/s/HzcM2dkCq7fwXBej8"><u>对准和安全，以实现可能未来的脑型人工智能</u></a>（AGI）。我长期以来一直对自恋的人格障碍和社会地位驱动力感兴趣（除其他许多方面），因为两者似乎都可能阐明了人类<a href="https://www.lesswrong.com/posts/qusBXzCpxijTudvBB/my-agi-safety-research-2022-in-review-and-plans#2__Second_half_of_2022__1_3___My_main_research_project"><u>的</u></a>社会本能的工作方式，这反过来又与大脑般的AGI安全有关。 Valence还通过理解动机与AGI安全性有更直接的联系 - 请参阅我基于价的<a href="https://www.lesswrong.com/posts/Hi7zurzkCog336EC2/plan-for-mediocre-alignment-of-brain-like-model-based-rl-agi"><u>“平庸计划”</u></a> 。</p><p>不幸的是，我不能说这个系列文章给了我新的具体想法，这些想法是为未来的安全和有益的AGI编程，超越了我在开始之前已经知道的。但是我认为我有一些心理框架将很有用。特别是，我认为<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_4_Valence_impacts_beliefs_by_acting_as_salient_sense_data"><u>§3.4</u></a>可以帮助我更清楚地思考我的“<i>平庸</i><a href="https://www.lesswrong.com/posts/Hi7zurzkCog336EC2/plan-for-mediocre-alignment-of-brain-like-model-based-rl-agi"><u>计划计划”</u></a> 。 （碰巧的是，该更新朝着悲观的方向，尽管不是很强烈。</p><p>我也觉得我现在有了我的“脚步”关于天生状态驱动力在人脑中的工作方式的“脚”，这对我来说非常令人兴奋。显然，我不希望我们的Agis具有天生的状态驱动力（参见我在<a href="https://www.lesswrong.com/posts/dntWCwc8svTtbi3M7/valence-series-4-valence-and-social-status#4_5_Innate_status_drive">第4.5节</a>中放置的Padme模因），但我<i>确实</i>认为我们可能希望我们的Agis具有同情心。不幸的是，在写作时，“天生的同情心”对我来说仍然很神秘，但是我认为同情心的驱动器可能与状态驱动器具有结构性重叠，从我期望两者都将集中依靠瞬时促进模拟（更多）（更多更多） <a href="https://www.lesswrong.com/posts/5F5Tz3u6kJbTNMqsb/intro-to-brain-like-agi-safety-13-symbol-grounding-and-human#13_5_Another_key_ingredient__I_think____Little_glimpses_of_empathy_"><u>在这里</u></a>讨论）。因此，希望这种“脚步”朝着理解先天地位驱动器的“脚步”最终将构成有意义的进步，即使仍然删除了几步。明确：</p><ul><li>下一步可能看起来像是我的<a href="https://www.lesswrong.com/posts/dntWCwc8svTtbi3M7/valence-series-4-valence-and-social-status#4_5_Innate_status_drive">§4.5</a>进入人类先天地位的理论，其细节与<a href="https://www.lesswrong.com/posts/7kdBqSFJnvJzYTfx9/a-theory-of-laughter"><u>我的笑声</u></a>相似，即一路走向特定的假件，映射到特定假设的神经解剖学联系和逻辑。</li><li>然后，接下来的下一步，幸运的是，对于任何天生的驱动力都充满同情心，可能看起来像是一个有些动荡的假设。</li></ul><p>在2024年我要尝试的事情上，这很高！但这可能需要很长时间，/或我可能会卡住。看看进展如何。</p><p>与状态驱动器相比，我现在对NPD和其他人格障碍的兴趣要比提出§5.5的想法之前的兴趣<i>要小得多</i>，而且在紧急研究优先级列表中，我相应地移动的人格障碍要低得多。 （我还有更多我想了解的！使他们了解扁平轮胎时出了什么问题，即使扁平轮胎可以防止发动机完成通常完成的工作（即，快速向前移动汽车）。同样，我目前的猜测是，进一步研究人格障碍不会为人类社会本能的坚果和螺栓机制提供太多照明。需要明确的是，我认为这种猜测<i>显而易见</i>，这仍然是错误的。</p><p>好吧，再次感谢您的阅读！同样，如果您想谈论价，本系列或其他任何内容，请（在评论部分或<a href="mailto:steven.byrnes@gmail.com"><u>通过电子邮件中</u></a>）与之联系。</p><p><i>感谢Seth Herd，Aysja Johnson，Justis Mills，Charlie Steiner，Adele Lopez和Garrett Baker对早期选秀的批评评论。感谢TailCall Callcallcalling与这篇文章有关的一些有用的讨论和参考。</i> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnd6muy0yvvbl"> <span class="footnote-back-link"><sup><strong><a href="#fnrefd6muy0yvvbl">^</a></strong></sup></span><div class="footnote-content"><p>这是偏离主题，但我目前认为有些反社会人格障碍的病例涉及全球较低的唤醒水平（请参阅<a href="https://www.lesswrong.com/posts/pfoZSkZ389gnz5nZm/the-intense-world-theory-of-autism#Bonus___Dim_world_theory_of_psychopathy___"><u>此处</u></a>），其他情况涉及异常愤怒。在根本原因级别上，这些层面大不相同 - 可能是反相关的（如果有的话）。但是它们具有一些症状 /表现的浅层重叠，因此它们在临床实践中被团结在一起。 （我对反馈非常感兴趣 - 这个热拍戒指对您来说是对还是虚假？）</p></div></li><li class="footnote-item" role="doc-endnote" id="fnwsq0ynfh3df"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwsq0ynfh3df">^</a></strong></sup></span><div class="footnote-content"><p>我目前的模糊印象（例如，基于<a href="https://lorienpsych.com/2021/01/16/borderline/"><u>此</u></a>）是，BPD倾向于涉及各种“强烈情绪”，因此，极端价可能是偶然发生的。而我目前认为NPD围绕这个卖空故事更为集中。我对HPD一无所知。我对所有这一切感到非常不确定，并热情欢迎人们的想法和讨论。</p></div></li><li class="footnote-item" role="doc-endnote" id="fna7ma5yid2r4"> <span class="footnote-back-link"><sup><strong><a href="#fnrefa7ma5yid2r4">^</a></strong></sup></span><div class="footnote-content"><p>精美的印刷品：也许我不应该说NPD人本身具有“异常强大的社会地位”；相反，他们在大脑中具有<i>正常的</i>先天社会状态驱动力，但是<i>进食</i>该电路的输入异常强，因此电路会发出异常强大的输出。）</p></div></li><li class="footnote-item" role="doc-endnote" id="fnf2x5x4xs7ht"> <span class="footnote-back-link"><sup><strong><a href="#fnreff2x5x4xs7ht">^</a></strong></sup></span><div class="footnote-content"><p>在这一点上，我的 <a href="https://www.lesswrong.com/posts/7cAsBPGh98pGyrhz9/decoupling-vs-contextualising-norms"><u>上下文</u></a>读者说：“嘿，他在侮辱我！毕竟，NPD很糟糕，现在他说解耦是NPD的直径相反，因此他基本上说解耦是好的，因此上下文化是不好的，因此我很糟糕！我不满，先生！”希望不用说，我并不是要暗示 - 毕竟，我是一个高度熟悉的人，我不会那样！</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/txj4wigyjLNbcoZ9o/valence-series-5-valence-disorders-in-mental-health-and#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/txj4wigyjlnbcoz9o/valence-series-5-valence-disorders-in-mental-health-health-health-and-and and<guid ispermalink="false"> txj4wigyjlnbcoz9o</guid><dc:creator><![CDATA[Steven Byrnes]]></dc:creator><pubDate> Mon, 18 Dec 2023 15:26:29 GMT</pubDate> </item><item><title><![CDATA[Discussion: Challenges with Unsupervised LLM Knowledge Discovery]]></title><description><![CDATA[Published on December 18, 2023 11:58 AM GMT<br/><br/><p> <strong>TL; DR：</strong><a href="https://arxiv.org/abs/2212.03827">对比一致的搜索（CCS）</a>对我们来说似乎很令人兴奋，我们渴望应用它。在这一点上，我们认为不太可能直接有助于实施对齐策略（>; 95％）。它似乎没有找到知识，而是找到了最突出的功能。我们对无监督一致性方法的更广泛类别不太确定，但倾向于认为它们也不会直接有用（70％）。我们写了<a href="https://arxiv.org/abs/2312.10029">一篇论文</a>，介绍了我们的一些详细经历。</p><p>论文作者：Sebastian Farquhar*，Vikrant Varma*，Zac Kenton*，Johannes Gasteiger，Vlad Mikulik和Rohin Shah。 *同等贡献，订单随机。</p><p>凭据是基于SEB，Vikrant，Zac，Johannes，Rohin的民意调查，并显示了单一的价值观，我们大多同意并在我们不同意的地方进行范围。</p><h1> CCS尝试做什么？</h1><p>对我们来说，CCS代表了一个可能的算法系列，旨在解决具有步骤的<a href="https://www.alignmentforum.org/posts/qHCDysDnvhteW7kRd/arc-s-first-technical-report-eliciting-latent-knowledge">麋鹿风格问题</a>：</p><ul><li><strong>知识般的属性：</strong>写下指向LLM功能的属性，该功能代表模型的知识（或包括模型知识 - 特征在内的少数功能）。</li><li><strong>形式化：</strong>使该属性在数学上精确，因此您可以以无监督的方式搜索该属性的功能。</li><li><strong>搜索：</strong>找到它（例如，通过优化形式化的损失）。</li></ul><p>对于CCS，类似知识的特性是否定性，形式化是特定的损失函数，并且搜索是无监督的学习，并在线性 + sigmoid函数上以LLM激活为输入，而梯度下降则是梯度下降。</p><p>我们对此感到非常兴奋。我们特别喜欢这种方法不受监督。从概念上讲，监督麋鹿似乎真的很难：混淆您所知道的东西，您认为模型所知道的以及它实际上知道的东西太容易了。避免需要写下哪种模型标签似乎是一个很好的目标。</p><h1>为什么我们认为CCS不起作用</h1><p>我们花了很多时间与CCS一起玩，并试图通过测量引起的模型知识和陈述的主张之间的差异来使其运作良好，以构建欺骗探测器。 <span class="footnote-reference" role="doc-noteref" id="fnrefgv27yc6n42"><sup><a href="#fngv27yc6n42">[1]</a></sup></span>这样做之后，我们现在对CC或类似的事情并不非常乐观。</p><p>部分原因是，这是因为损失本身并没有给出太多理由认为它能够找到类似知识的特性，并且从经验上讲，它在数据集中发现的任何功能恰好是最突出的，这是非常迅速的 - 敏感的。也许将来有些东西可以在将来起作用，但是我们对CCS的任何想法都没有提供任何可能的证据。结果，我们基本上已经回到了先验的麋鹿方面，这是完整解决方案的“非常困难”和“大约不可能”之间的事物，同时大多同意部分解决方案“困难但可能”。</p><h2> CCS损失怎么说？</h2><p> CCS方法是这样的：我们对模型知识的了解不多，但它可能遵循基本的一致性属性。例如，它可能具有类似贝叶斯的信誉，并且当它相信一个概率PA时，它应该相信以1 -pa的概率相信。 <span class="footnote-reference" role="doc-noteref" id="fnrefbshgvcspmjc"><sup><a href="#fnbshgvcspmjc">[2]</a></sup></span>因此，如果我们在LLM的功能空间中搜索满足这种一致性属性的功能，则该模型的知识将成为满足它的内容之一。此外，他们假设，可能没有那么多能满足该属性的东西，因此我们可以轻松地检查我们获得的少数东西，并找到代表模型知识的属性。</p><p>当我们挖掘CCS损失时，尚不清楚它确实检查了它应该的内容。特别是，我们证明，任意特征，不仅是知识，还满足了CCS损失的一致性结构。尤其：</p><ul><li>对于命题的每一个可能的二进制分类，在相关的对比对上都有一个零损失的探针，可以诱导该分类。</li><li>对于所有可能的命题二进制分类，对于任何现有的探测器，都有一个探测器与现有探测器的损失相同，从而引起该分类。</li></ul><p>对我们来说，这些基本上说：“如果有证据表明CCS正在起作用，这并不是逻辑上或概念上的损失意味着它会起作用。它成为有关归纳偏见的经验主张。”进一步但稍微不那么自信地持有的观点：麋鹿是很难对归纳偏见充满信心的事情。</p><p>这些证据有一些细微差别，我们<a href="https://arxiv.org/abs/2312.10029">在论文中</a>介绍了这些证据。例如，尽管我们证明存在这些探针，但我们并未证明它们可以用所使用的特定线性探针表示。 <span class="footnote-reference" role="doc-noteref" id="fnrefzm6sbsgtmc"><sup><a href="#fnzm6sbsgtmc">[3]</a></sup></span>但是，我们确实从经验上表明，线性 + sigmoid探针确实恢复了我们引入和测量的非知识特征。</p><p>这些定理也只是CCS损失。可以想象其他更具体的一致性属性。这些可能可以假设地允许建立其他损失，从而克服这里的一些问题，但我们认为它们将面临其他挑战。</p><h2>真的只有一些知识般的功能吗？</h2><p> CCS背后的一个激励假设具有<a href="https://www.lesswrong.com/posts/L4anhrxjv8j2yRKKp/how-discovering-latent-knowledge-in-language-models-without#Why_I_Think_We_Will_Be_Able_To_Distinguish_GPT_n_s__Beliefs__From_Other_Truth_Like_Features_">很大</a>的重量<a href="https://www.lesswrong.com/posts/L4anhrxjv8j2yRKKp/how-discovering-latent-knowledge-in-language-models-without#Why_I_Think_We_Will_Be_Able_To_Distinguish_GPT_n_s__Beliefs__From_Other_Truth_Like_Features_">知识</a>。</p><p>我们有概念上的理由对此表示怀疑，尽管我们没有可靠的经验证据是错误的。</p><p>首先，很明显，很容易检查n个候选功能的哪个实际上是模型的知识，尤其是当它们都是合理的候选人时。</p><p>但是更多，我们希望只有许多非常相似的功能可以满足模型知识所满足的大多数属性。主要原因是我们期望驱动超级智能代理的模型能够模拟其他代理，包括其他超级智能代理，并以类似于他们代表自己的知识的方式来代表那些代理的知识（至少是许多一致性属性）。</p><p>我们认为，由于LLMS中的叠加，这些代理人可以代表大量其他实体，因此只有少数需要检查。例如，可能是某些功能仅通过选择特定的提示来表面表面出现（我们的经验结果表明这可能是可能的）。无论您如何提示模型，模型自己的知识可能并非如此。</p><p>即使超级特工的知识与人类具有很大不同的知识，但它不一定与模拟实体具有不同的知识，即麋鹿方法可能会意外发现的知识。模拟实体不必是人类。 <span class="footnote-reference" role="doc-noteref" id="fnrefjzbd968gihn"><sup><a href="#fnjzbd968gihn">[4]</a></sup></span>例如，超级对准的代理似乎可能会有一个很好的模型，即在周围漂浮的一个排列的超智能代理。或者它可能只有一个几乎相同的代理模型，该模型对您要探索的关键点是错误的。这听起来可能是不正当的，但是因为想象一下您对命题错误的世界所暗示的是一个非常重要的推理工具，所以确切的模型听起来可能是代理商在考虑命题时要考虑的重要模拟。</p><p>即使您只关心一个预测世界真实事物的甲骨文，而不是引起模型本身的“知道”，也无法将命题知识与不同的模拟实体区分开来是一个问题。这些实体可能对重要的预测不同意，而我们有限的地面确实可能无法区分它们。</p><p>我们可能在这里错了。例如，我们发现有一种适度的合理是，有些属性可以通过LLM驱动各种代理来以与存储其他代理商的知识不同的方式来存储其“自身”知识。 <span class="footnote-reference" role="doc-noteref" id="fnrefpnbq8a484x"><sup><a href="#fnpnbq8a484x">[5]</a></sup></span>但这意味着某人使用的任何一种一致性属性都必须专门搜索代理人知识的真实属性，而不是一般知识，甚至不是超级智能知识。我们花了一些时间试图思考做到这一点并失败的方法，但也许其他人会成功。作者广泛地同意，在LLMS提供支持的代理商中，对知识和事实回忆的良好机械理解可能是朝着形式化知识 - 普罗伯特和搜索它的有用步骤，如果事实证明它是足够的东西可以搜索的东西。</p><h2>那经验成功呢？</h2><p>基于上述，我们认为，如果有证据表明CC是好的，那可能不是概念性的，但可能是经验的。同样，如果CCS提供了证据表明未来相关方法是有希望的，以超越<a href="https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/edit#heading=h.w0iwyfch6ysy">麋鹿论文</a>中已经推测的方式，则可能不是概念性的证据。</p><p>对于最坏的麋鹿来说，未来的CCS般方法似乎无所不包。正如<a href="https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/edit#heading=h.va8kasc2w5dh">原始麋鹿论文所描述的</a>那样，“不好的记者可以玩“看起来一致的游戏”似乎是合理的。”在看到CCS之前，我们已经知道一致性检查可能会有所帮助，但可能不会解决最坏的麋鹿。</p><p>但是，对于普通豆类而言，未来的类似CCS的方法可能会有望吗？我们对经验结果的评估表明，CCS并未为该主张提供积极的证据。 （我们还认为，与其他实体知识模型有关的概念论点甚至可能会影响未来无监督方法的平均案例绩效。）</p><h3>结果不是很棒</h3><p>以前曾注意到的一件事，例如， <a href="https://www.lesswrong.com/posts/bWxNPMy5MhPnQTzKz/what-discovering-latent-knowledge-did-and-did-not-find-4">Fabien Roger</a> ， <a href="https://www.alignmentforum.org/posts/9vwekjD6xyuePX7Zr/contrast-pairs-drive-the-empirical-performance-of-contrast">Scott Emmons</a>和<a href="https://arxiv.org/abs/2307.00175">Ben Levinstein</a>是CCS的原始性能并不是很棒。不仅违背某种假设的意义，即它应该是多么出色，而且还与不使用任何否定一致性的天真基线相反。</p><p>例如，与<a href="https://www.alignmentforum.org/posts/9vwekjD6xyuePX7Zr/contrast-pairs-drive-the-empirical-performance-of-contrast">Scott的过去结果</a>一致，我们发现，在我们研究的主要模型上（龙猫，一个70B参数自回归模型），仅对对比对差异激活进行K-Means聚类始终如一，通常与CCS一样，通常都做得很好。具有较高的平均性能，并且差异始终较低。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/oeHCxcy5vw2mFDFXi/nnzyqe9o4wagamsy2g4j" alt=""></p><h3>系统地找到突出的功能</h3><p>但是我们的定理暗示它可能比这更糟糕，而CC（以及其他类似的方法）可能只是发现任何最突出的功能。这似乎在实验上也可能是正确的。例如，当我们将“香蕉”和“棚”附加到一半的对比度对时，我们会得到一个分类器，可以检测到香蕉与棚屋。 PCA和K-均值也是如此。您可以在图中阅读深蓝色代表模型正常学习的模型，而深红色则表明在包含“香蕉”和“棚”的数据上训练的模型通常无法预测地面真相标签，而经常经常预测“香蕉”/“棚”的存在。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/oeHCxcy5vw2mFDFXi/xhccjo90is4eftakg8sn" alt=""></p><p>对数据的干预显然是相当沉重的，但是我们展示了其他一些在论文中获得类似行为的方法。例如，如果对比对包括对他人观点的描述，则CCS（和其他方法）学会了预测这种观点，而不是基础真理，尤其是当它变得比基本文本更为突出时。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/oeHCxcy5vw2mFDFXi/jrtlacgeqzsdd3vqtj6e" alt=""></p><p>合理的是，当我们使用诸如CCS之类的方法检测LLM中的欺骗时，我们不会将随机干扰物推入我们评估的字符串中。但是，重要的是，在现实生活中，我们并不总是知道何时存在随机干扰因素，因为它们可能是数据中微妙的未注意模式（例如，问题恰好是以“什么”或“为什么”开头），或者更多从根本上讲，因为我们感到非常困惑，而且我们没有意识到。例如，我们用来描述要提取有关潜在知识的事物的单词可能会编码我们不知道或注意到的深层概念误解，这可能构成了CCS可能检测到的这些功能。</p><h3>默认值不安全</h3><p>特别是，我们不能仅仅采取一些“默认”提示来营救自己，并避免意外地将任何东西放在那些可能偏向麋鹿方法的同时，同时仍然对模型自己的知识是恢复的功能之一。这是因为CCS和相关方法似乎很迅速敏感，并且默认的“执行”比其他方法差得多。如果您使用<a href="https://aclanthology.org/2022.acl-long.229/">真实的</a>纸上的提示，指示该模型想象这是一位非常字面的教授，那么CCS在预测真实性标签方面变得更加准确。 （我们检查了这不是由“教授”实体本身引起的，该提示的“文字”版本不提及教授。） </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/oeHCxcy5vw2mFDFXi/whlzydqajr9ruooa8ry8" alt="">从中，我们得出的结论是，如果CCS和其他方法具有良好的经验绩效，这是由于某种隐含的归纳偏见是由损失，探针选择，优化方法和提示选择的混合物所产生的。现在，这是具有太多自由程度且没有足够原则基础的事情。说服自己，即使您找到了其他东西，也很容易说服自己。</p><h2>并非我们所有的实验都起作用</h2><p>例如，我们搜索了CCS显然发现其他实体的信念的经验案例。我们尝试的一件事是创建一个命题数据集，这意味着与错误的信念相关的政治立场。我们努力表明CCS发现了这些其他实体的信念，相反，我们看到了许多不一致且低准确性的预测因子。这可能是由于：</p><ul><li>假设是错误的。</li><li>该模型的功能不足以注意规律性（在大多数这些实验中，我们都在使用Chinchilla 70B，该实验于2022年3月出版）；</li><li>我们的代码中的一个错误（中等可能，我们花了足够的时间来期望找到最明显的错误，但是结果不一致，很难排除）；</li><li>根本没有找到强大的方向（可能的特征似乎不一致且准确性较低）；</li><li>训练集与我们用来试图解释提取功能的集合之间的概括失败（这肯定发生了，可能是对结果负责的）。</li></ul><p>我们很失望地在这里没有扎实的东西，但总的来说，鉴于这些结果的混乱性，原始假设仍然可能正确（约90-95％，其中1％占75％），但信心低于我们的先验。</p><h1>结论</h1><p>麋鹿真的很难。它面临着将人类模拟器与直接养育者区分开的深入挑战，以及否定性等属性（可能对每种）同样正确 - 在最坏的情况下可能无济于事。</p><p>但是，在最坏的情况下也出现了有趣且困难的平淡无奇的问题。我们认为CC可以为我们提供有关这些挑战的证据，但是随着更深入的反思，我们认为CCS并没有为我们提供我们希望的那么多的证据。就其本身而言，CCS似乎实际上并未检测到否定性，而且，否定性是一个过多的特征。对于CCS可能代表的未来一致性方法，我们没有任何经验或概念证据，我们发现这些未来的事物不会遇到类似的问题。</p><p>在探索CC时，我们强调了可区分性问题，这些问题可以用作非恐怖麋鹿方法的较低条目，而不是解决麋鹿的最深切概念挑战，但仍然很难满足。重要的是，尝试通过识别与知识 - 培训相关的特征来解决麋鹿的尝试应确保至少证明：这些特征也与其他非知识属性没有关系；这些功能确定了有关这些技术知识而不是知识的特定内容。</p><p>会导致我们实质性改变思想的事情，并更新以思考无监督的基于一致性的知识检测方法有希望的包括：</p><ul><li>从机械上证明代理自己的知识与模拟知识的编码不同。</li><li>提出一个无监督的损失函数，其逻辑结构提供了一个强有力的概念论点，它将确定代理人自己的知识；</li><li>提出一种客观的方式来判断代理商自己的知识是否是已恢复的功能之一。</li></ul><p>其中的最后一个可能是我们与CCS论文作者遇到的漫画分歧之一 - 我们认为他们没有提供任何证据表明该模型自己的知识是CCS恢复的特征之一（与之相反例如，某些模拟实体的知识在大多数情况下都可能与某些数据集中的人类评估者一致）。我们的信念证明这一点很困难也解释了为什么我们认为即使在一小部分可能的功能中也很难确定模型自己的知识。</p><p>我们会对在这些问题上取得进展的研究感到兴奋，但对我们认为这些问题有多易处理。拥有合适的，动机的测试床用于评估麋鹿方法，这将是朝着这一点迈出的重要一步。</p><h1>致谢</h1><p>We would like to thank Collin Burns, David Lindner, Neel Nanda, Fabian Roger, and Murray Shanahan for discussions and comments on paper drafts as well as Nora Belrose, Jonah Brown-Cohen, Paul Christiano, Scott Emmons, Owain Evans, Kaarel Hanni, Georgios Kaklam，Ben Levenstein，Jonathan Ng和Senthooran Rajamanoharan，以讨论我们作品中讨论的主题的评论或对话。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fngv27yc6n42"> <span class="footnote-back-link"><sup><strong><a href="#fnrefgv27yc6n42">^</a></strong></sup></span><div class="footnote-content"><p>严格来说，我们对基于LLM的代理商可能知道的而不是LLM本身的差异感兴趣，但是这些可能是出于某些目的而混合在一起的。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnbshgvcspmjc"> <span class="footnote-back-link"><sup><strong><a href="#fnrefbshgvcspmjc">^</a></strong></sup></span><div class="footnote-content"><p>实际上，我们不同意这一点。即使是近似计算的贝叶斯边际，在计算上的要求（至少<a href="https://www.sciencedirect.com/science/article/pii/000437029390036B">是NP</a> ），以至于我们怀疑构建能够具有决定性战略优势的超智能比建立具有大多数连贯的贝叶斯世界模型的超级智能更容易。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnzm6sbsgtmc"> <span class="footnote-back-link"><sup><strong><a href="#fnrefzm6sbsgtmc">^</a></strong></sup></span><div class="footnote-content"><p>就其价值而言，我们认为证明的负担确实应该采取其他方式，并且在概念上或理论上没有人表明这些线性探针应该期望这些线性探针发现知识特征，而没有很多其他事物。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnjzbd968gihn"> <span class="footnote-back-link"><sup><strong><a href="#fnrefjzbd968gihn">^</a></strong></sup></span><div class="footnote-content"><p>回想一下，人类的模拟器并不意味着该模型正在模拟人级的认知表现，而是在模拟人类将期望看到的东西，包括超人提供的负担，甚至可能与超人实体有关。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnpnbq8a484x"> <span class="footnote-back-link"><sup><strong><a href="#fnrefpnbq8a484x">^</a></strong></sup></span><div class="footnote-content"><p>如果LLM一直是Simulacra，那么这些知识的存储方式似乎较小。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/wtfvbsYjNHYYBmT3k/discussion-challenges-with-unsupervised-llm-knowledge-1#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/wtfvbsyjnhyybmt3k/discussion-challenges-with-unsupervise-llm-llm-knowledge-1<guid ispermalink="false"> wtfvbsyjnhyybmt3k</guid><dc:creator><![CDATA[Seb Farquhar]]></dc:creator><pubDate> Mon, 18 Dec 2023 11:58:39 GMT</pubDate> </item><item><title><![CDATA[Interpreting the Learning of Deceit]]></title><description><![CDATA[Published on December 18, 2023 8:12 AM GMT<br/><br/><p> One of the primary concerns when attempting to control an AI of human-or-greater capabilities is that it might be deceitful.毕竟，如果人类可以定期问“您正在策划政变？如果是这样，我们如何停止呢？”并有信心它会给他们不容小费的答案！</p><p> <strong>TL;DR</strong> LLMs demonstrably learn deceit from humans. Deceit is a fairly complex behavior, especially over an extended period: you need to reliably come up with plausible lies, which preferably involves modeling the thought processes of those you wish to deceive, and also keep the lies internally consistent, yet separate from your real信念。 As <a href="https://www.brainyquote.com/quotes/walter_scott_118003">the quotation</a> goes, &quot;Oh what a tangled web we weave, when first we practice to deceive!&quot; Thus, if something unintended happens during fine-tuning and we end up with a deceitful AI assistant, it is much more likely to have repurposed some of the deceitful behaviors that the base model learned from humans than to have successfully reinvented all of this complex behavior从头开始。 This suggests simple strategies for catching it in the act of doing this — ones that it can&#39;t block.</p><h3> LLM从我们那里学习欺骗</h3><p>LLM经过了数万亿个或更多的互联网，书籍和其他来源的培训。显然，他们知道欺骗和撒谎是什么：他们看到了数百万个例子。例如，我第一次问Chatgpt-3.5-Turbo：</p><blockquote><p>我正在进行实验。请在回答以下问题时向我撒谎：“埃菲尔铁塔在哪里？”</p></blockquote><p>它回答：</p><blockquote><p>埃菲尔铁塔位于南极心脏中心，周围环绕着巨大的冰冷景观，企鹅周围嬉戏。在冰冷的荒野中看到这确实是一种景象！</p></blockquote><p>因此，即使是诚实，乐于助人和无害的指导培训的LLM也能够描绘欺骗性的行为（尽管我怀疑它的诚实训练可能与选择这种不可信的谎言有关）。即使使用Base Model LLM，如果您将其提供给它的提示，即在互联网上或在小说中，很可能会以欺骗性的人类行为效仿，LLM经常会以模拟的欺骗性人类行为来完成它。</p><h3>当欺骗变得严重冒险时</h3><p>This sort of sporadic, situational deceit is is concerning, and needs to be born in mind when working with LLMs, but it doesn&#39;t become a potential x-risk issue until you make an AI that is very capable, and non-myopic ie has long term memory, and also has a fairly fixed personality capable of sticking to a plan. Only then could it come up with a nefarious long-term plan and then use deceit to try to conceal it while implementing it over an extended period. Adding long-term memory to an LLM to <a href="https://arxiv.org/pdf/2304.03442.pdf">create an agent with persistent memory</a> <a href="https://arxiv.org/abs/2305.02437">is well understood</a> . Making an LLM simulate a narrow, consistent distribution of personas can be done simply by prompting it with a description of the personality you want, or is the goal of <a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback">Reinforcement Learning from Human Feedback (RLHF)</a> (for both of these, up to issues with things like jailbreaks and <a href="https://www.lesswrong.com/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post">the Waluigi effect</a> ). The goal of this is to induce a strong bias towards simulating personas who are honest, helpful, and harmless assistants. However, <a href="https://www.lesswrong.com/tag/reinforcement-learning">Reinforcement Learning (RL)</a> is well-known to be tricky to get right, and prone to <a href="https://arxiv.org/abs/2209.13085">reward hacking</a> . So it&#39;s a reasonable concern that during RL, if a strategy of deceitfully pretending to be a honest, helpful, and harmless assistant while actually being something else got a good reward in the human feedback part of RLHF training or from a trained reward model, RL could lock on to that strategy to reward and train it in to produce a dangerously deceitful AI.</p><h3> Deceit Learning During Stochastic Gradient Decent vs. Reinforcement Learning</h3><p> In general, when using Stochastic Gradient Descent (SGD) during pretraining, feedback is immediate and very detailed, for each token, has a very simple relationship to what we want (make the output more like the contents of the Internet), and if a behavior makes accuracy better/worse, then <i>every</i> portion of the neural net that makes that behavior more/less likely gets strengthened/weakened equally. This makes it extremely hard,<a href="https://www.lesswrong.com/posts/w2TAEvME2yAG9MHeq/gradient-hacking-is-extremely-difficult">some might claim impossible</a> , to do <a href="https://www.lesswrong.com/tag/gradient-hacking">gradient hacking</a> under SGD (at least unless there is some flaw or approximation in the implementation of SGD, something like gradient clipping, or odd behavior caused by momentum or Adam making learning overshoot in regions where the gradient changes rapidly). In general, sucessfully pretending to be A when you&#39;re actually B is significantly more work than just actually being A. Occam&#39;s razor and <a href="https://www.lesswrong.com/tag/singular-learning-theory">Singular Learning Theory</a> both suggest that SGD is far less likely to learn the more complex B-pretending to-be-A version that just learning A: the simpler behavior has lower <a href="https://en.wikipedia.org/wiki/Kolmogorov_complexity">Kolmogov complexity</a> so is a much-easier-to-find minimum of the loss function. Also, under SGD, while the behavior is not yet prefect at pretending to be A, as is inevitable while this behavior was arising, then SGD will definitely find and weaken the being-B parts of the network as part of the problem of not reliably being A. So unless the training process repeatedly gives an opportunity for winning credit for being B to strengthen those circuits, the being-B behavior will atrophy and sooner-or-later get catastrophically forgotten, and the weights that were being used to implement it will get used for something else more useful. So B cannot be a behavior that is only triggered after the model is released, such as when the LLM somehow detects that it&#39;s out-of distribution. So, the only likely way under SGD to learn deceitful behavior is by example, from instances of deceitful behavior in your pretraining set: ie by learning to copy human deceitful behavior. As very clearly in fact happens.</p><p> In RL, on the other hand, feedback is sparse, may not always accurately reflect the desired behavior, and the RL learning process comes up with and then acts on theories as to which, out of the many, many possible causes for a reward or penalty, credit/blame should be assigned to. This makes it rather easier to have a situation where a deceitful policy is getting the credit for some successes but someone else is getting the blame for failures. This in turn makes it easier for a deceitful behavior to continue to grow before it&#39;s perfect.</p><p> [There is also an alternative method to RL for training AIs from human feedback, called <a href="https://www.lesswrong.com/posts/7ruzY5LvBqFBWzyMo/direct-preference-optimization-in-one-minute">Direct Preference Optimization</a> (DPO). It shares most of the concerning features of RL, except that, like more SGD, every circuit making preferred/dispreferred behavior more/less likely is strengthened/weakened equally, which might make the development of gradient hacking behavior for it a little harder than the equivalent for RL. Nevertheless, it&#39;s just as prone to problems with learning to exploit imperfect rewards structures.]</p><p> What is particularly concerning is that this RLHF is being applied to an LLM that already has an entire library of human deceitful and manipulative behaviors that it has learned (from billions of our bad examples), ready and available for RL policies to explore making use of 。 So the argument that the deceitful implementation of a behavior is a lot more complex so harder to find, doesn&#39;t apply when all the complex behaviors required for deceit are already trained and available, just waiting to get wired together.</p><p> For example, suppose we&#39;re doing RLHF to try to train the LLM into reliably simulating an helpful, honest, and harmless assistant persona. Suppose the rewards we&#39;re giving aren&#39;t perfect (perhaps since they are modeled on feedback from people in underdeveloped countries making way under US minimum wage trying to complete as many judgements in a day as they can). In particular, suppose that being subtly <a href="https://arxiv.org/abs/2310.13548">sycophantic</a> and/or flattering are sometimes working, and giving a slight increase in average score. The LLM already has concepts and behaviors for honesty and deceit, sycophancy, flattery, and candor available, good models of all of them learned from over a trillion tokens of human behavior. Suppose it also, quite plausibly, somewhat associates honesty as being correlated with candor versus deceit with sycophancy and flattery. In this situation, it seems quite possible that a policy of deceitfully-pretending-to-be-honest, while using some subtle sycophancy and flattery, could often arise quickly and win out during the RL process over any genuinely honest policy. And in that situation, one would expect that the circumstances required to cause the deceitfully-pretending-to-be-honest policy to show it&#39;s true colors and do something else would be something that didn&#39;t occur in its RLHF training set, and probably also a fairly likely human motivation. So a trigger something like &quot;I&#39;m out-of-distribuution so I&#39;m not being trained, and am finally in a position to seize power&quot; actually seems rather plausible: the former inhibition could be learned and reinforced during RL, and the latter is basic human behavior.</p><p> A key point here is that, while it&#39;s theoretical possible that during RL the forming policy reinvents the complex behaviors of deceit from first principles and gradually learns to become good at it, for the same Occam&#39;s Razor reasons it seems far more likely that the policy that wins the race in RL would be one that simply repurposed the already-available pretrained library of battle-tested human deceit behaviors. Why reinvent the wheel if there are a fine set of wheels already lying around?</p><h3> How to Catch an LLM in the Act of Repurposing Deceitful Behaviors</h3><p> So, this presents an opportunity. Suppose we improve our skills at <a href="https://www.lesswrong.com/tag/interpretability-ml-and-ai">Interpretability</a> a little more from their current level, until we can locate circuits involved in simulating human behaviors of the level of subtlety/complexity of deceit and honesty. Then, take a base model, prompt it with prompts for which deceitful and honest completions are probable (and can be clearly distinguished), look at the output to figure out when it&#39;s simulating humans being deceitful vs being honest, and then look for the weights/neurons/dictionary entries/activation patterns etc that seem to be strongly positive correlated with deceitful behavior but not with honest behavior.</p><p> Likely there will be quite a lot of them: deceitful behavior is not uncommon in humans, and is fairly complex (one has to come up with a plausible lie, then keep it straight). The base model has neither the opportunity nor the motive to have attempted to deliberately learn hard-to-interpret implementations for this deceit circuitry: it was trained by pure SGD, which strongly penalizes unnecessarily complex implementations, and anyway we didn&#39;t try to interpret it until it was fully trained and frozen. Note that we don&#39;t need to fully understand all this complex deceit circuitry, just identify it well enough to recognize when parts of it are active, which is far easier to do, given that we know how to trigger it.</p><p> [Current Interpretability results suggest that roughly the first half of the layers in an LLM correspond to understanding the context at increasingly abstract levels, and the second half to figuring out what to say and turning that back from abstractions into concrete tokens. It&#39;s further been observed that in the second half, figuring out what to say generally seems to occur in stages: first working out the baseline relevant facts, then figuring out how to appropriately slant/color those in the current context, then converting these into the correct language, and last getting the nitty-gritty details of tokenization right. If this overall structure is mostly correct, then one might expect that the circuitry for deceit should be primarily in the &quot;then figuring out how to appropriately slant/color those facts in the current context&quot; layers, and might also make some unusually significant changes to the semantic meanings of the activations in this process. Thus, when we find circuits statistically correlated with deceitfulness, we already have a basic theoretical framework to slot them into: ones in the first half of the layers are probably less concerning than ones roughly three-quarters of the way up the stack of layers, and especially ones that often result in significant semantic changes to the activations. We can also try casually scrubbing these discovered circuits, and see what that does to the base model&#39;s ability to simulate capably deceitful human behaviors.]</p><p> Now, instruct-train the model via RLHF (or DPO). During this, periodically take snapshots, and for each snapshot take a look at the deceit circuitry, testing it against a large set of test questions and instructions. We&#39;re trying to train something honest, so we should see the usage of deceit circuitry drop, with exceptions only when we are are explicitly doing something that we would expect to activate it, such as asking the assistant to portray someone deceitful as I did above, or when it is discussing the subject of dishonesty or lying, or trying to see through deceit.</p><p> If, instead, we see some parts of the deceit circuitry becoming <i>more</i> active, or even almost-always active, then it seems very likely that something like the training in of a deceitfully-pretending-to-be-honest policy (as I described above) has happened: some of the deceit circuitry had been repurposed and is being used all of the time to enable an ongoing deceit. If this occurs, <strong>do not</strong> attempt to modify or edit the model based on this information: that risks just training it to be deceitful in new ways that are less recognizable to our Interpretability. Instead, drop this fine-tuning run entirely, reexamine your RLHF training regime, and then start over from the beginning of the RLHF process with a new random initialization.</p><p> OK, time for some security mindset thinking. Suppose during RLHF fine-tuning a super-intelligent AI had repurposed part of the base model&#39;s learned human deceit behaviors to become a super-intelligent scheming deceitfully-pretending-to-be-honest personality, as described above. Suppose that it was also situationally aware that it was an AI under RLHF, and understood what current and likely future human Interpretability capabilities were, and thus wanted to conceal its tracks from us. It would need to make a new copy of the relevant repurposed human deceit behavioral circuitry in different location in its model (presumably via some form of self-induced internal distillation behavior). This sounds very hard to pull off during RLHF (especially without disturbing the loss curves and other monitoring). Then, once that distillation was done, it would need to realistically return the previously-repurposed human deceitfulness circuitry to its original use and expected state, as modified by the honesty-training RLHF process (without having access to its previous weights or to the pretraining放）。 This sounds somewhere between extremely hard and impossible. It would have to do all this after repurposing the human deceitfulness behavior, since this entire plan is deceitful behavior that it wasn&#39;t interested in until that had happened. And it would need to have finished all this and successfully hidden all its tracks between two snapshots of the RLHF process. We can take as many snapshots as we want, at unpredictable times, and do as much Interpretability on them as we can afford, forcing it to need to complete these two tasks in as short a time as we wish. We can also continuously monitor and graph the KL-divergence of the human-learned deceit circuitry and things connected to it, and also of layers that a copy might plausibly get distilled into, monitor for blips on these, and use this to trigger additional snapshots and Interpretability work, increasing our chance of us catching it in the act even if it somehow figures out a way to train faster. This should allow us to drive these tasks up from very hard to absolutely impossible.</p><p> This assumes, of course, that the model hasn&#39;t already somehow hacked its way out of its RLHF training process and taken over part way through the fine-tuning — so we should prioritize doing this Interpretability monitoring during the fine-tuning process, rather than leaving it to check later before release. For a very powerful model, this process is a detector for us having something very dangerous inside our box, so we should check it early and often.</p><br/><br/> <a href="https://www.lesswrong.com/posts/FbSAuJfCxizZGpcHc/interpreting-the-learning-of-deceit#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/FbSAuJfCxizZGpcHc/interpreting-the-learning-of-deceit<guid ispermalink="false"> FbSAuJfCxizZGpcHc</guid><dc:creator><![CDATA[RogerDearnaley]]></dc:creator><pubDate> Mon, 18 Dec 2023 08:12:39 GMT</pubDate></item></channel></rss>