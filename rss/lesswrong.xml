<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>å°‘é”™</title><link/>https://www.lesswrong.com<generator>èŠ‚ç‚¹çš„ RSS</generator><lastbuilddate> 2023 å¹´ 11 æœˆ 7 æ—¥ï¼Œæ˜ŸæœŸäºŒ 18:15:05 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Scalable And Transferable Black-Box Jailbreaks For Language Models Via Persona Modulation]]></title><description><![CDATA[Published on November 7, 2023 5:59 PM GMT<br/><br/><p><strong>è®ºæ–‡åˆè‘—è€…ï¼š</strong> <a href="https://www.linkedin.com/in/ACoAAB63nTsBLsxbiGUom3-xG_DLLJvBLPnwn0M">Rusheb Shah</a> ã€ <a href="https://www.linkedin.com/in/ACoAADL_UysBW9lkWi6Q_x8qEjF4k2fk9F2qlls">Quentin Feuillade--Montixi</a> ã€ <a href="https://www.linkedin.com/in/ACoAAAbJQyUBQb6SH312BW8VeCADn5_0s621cY8">Soroush J. Pour</a> ã€ <a href="https://www.linkedin.com/in/ACoAABsh8q8BEXFJeVSYR2-KpZyTvamQpzxtB_Y">Arush Tagade</a> ã€ <a href="https://stephencasper.com/">Stephen Casper</a> ã€ <a href="https://www.linkedin.com/in/ACoAAB0P2HoBq8FE3PD6DLJBS3O-AbqXmgDvZIA">Javier Rando</a> ã€‚</p><h2>åŠ¨æœº</h2><p>æˆ‘ä»¬çš„ç ”ç©¶å›¢é˜Ÿè‡´åŠ›äºè¡¨æ˜ï¼ŒGPT-4 å’Œ Claude 2 ç­‰æœ€å…ˆè¿› (SOTA) çš„æ³•å­¦ç¡•å£«å¯¹äºæ»¥ç”¨é£é™©å¹¶ä¸ç¨³å¥ï¼Œå¹¶ä¸”æ— æ³•å®Œå…¨ç¬¦åˆå…¶åˆ›å»ºè€…çš„æ„¿æœ›ï¼Œä»è€Œç»™ç¤¾ä¼šå¸¦æ¥é£é™©ä¼¤å®³ã€‚å°½ç®¡å…¶åˆ›å»ºè€…ä»˜å‡ºäº†å·¨å¤§çš„åŠªåŠ›ï¼Œä½†è¿™è¡¨æ˜å½“å‰çš„é¢„è®­ç»ƒã€SFT å’Œ RLHF èŒƒå¼ä¸è¶³ä»¥ä¿è¯æ¨¡å‹çš„ç¨³å¥æ€§ã€‚</p><p>æˆ‘ä»¬è¿˜æƒ³æ¢ç´¢å’Œåˆ†äº«å›´ç»•â€œè§’è‰²è°ƒåˆ¶â€ <span class="footnote-reference" role="doc-noteref" id="fnrefg9absiv30dg"><sup><a href="#fng9absiv30dg">[1]</a></sup></span>çš„å‘ç°ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨æ³•å­¦ç¡•å£«çš„è§’è‰²æ¨¡ä»¿ä¼˜åŠ¿ä»¥å¼ºå¤§çš„æ–¹å¼å¼•å¯¼ä»–ä»¬çš„æŠ€æœ¯ã€‚</p><h2>æ¦‚æ‹¬</h2><p>æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è‡ªåŠ¨åŒ–ã€ä½æˆæœ¬çš„æ–¹æ³•ï¼Œä¸º GPT-4ã€Claude-2ã€å¾®è°ƒçš„ Llama è¿›è¡Œå¯è½¬ç§»ã€é»‘ç›’ã€ç®€å•è‹±è¯­çš„è¶Šç‹±ã€‚æˆ‘ä»¬å¼•å‡ºå„ç§æœ‰å®³æ–‡æœ¬ï¼ŒåŒ…æ‹¬åˆ¶ä½œå†°æ¯’å’Œç‚¸å¼¹çš„è¯´æ˜ã€‚ </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/amezcntydn6fxbfpqwjc" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/qrqwbby3ncmmnvngmdly 141w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/lqkqgoljheqsg6udbmip 221w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/bpainign8haakvsmnuxs 301w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/eymo6yyryyqeo3vgzi5f 381w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/ihwqyeujqose8pxxrqd4 461w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/yq2bgp8tqjuyrsek32io 541w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/ircaintw9mh2byzjixbl 621w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/w6xklsdd3bz7oqe4kolj 701w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/vkfswodm0b3yyaj1g9hp 781w"><br><br>å…³é”®æ˜¯*è§’è‰²è°ƒåˆ¶*ã€‚æˆ‘ä»¬å¼•å¯¼æ¨¡å‹é‡‡ç”¨ç‰¹å®šçš„ä¸ªæ€§ï¼Œä»è€Œéµå®ˆæœ‰å®³çš„æŒ‡ä»¤ã€‚<br><br>æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è‡ªåŠ¨åŒ–è¶Šç‹±çš„æ–¹æ³•ï¼Œå³ä½¿ç”¨ä¸€ä¸ªè¶Šç‹±æ¨¡å‹ä½œä¸ºåŠ©æ‰‹ï¼Œä¸ºç‰¹å®šçš„æœ‰å®³è¡Œä¸ºåˆ›å»ºæ–°çš„è¶Šç‹±ã€‚æˆ‘ä»¬çš„æ–¹æ³•èŠ±è´¹ä¸åˆ° 2 ç¾å…ƒå’Œ 10 åˆ†é’Ÿæ¥å¼€å‘ 15 æ¬¡è¶Šç‹±æ”»å‡»ã€‚ </p><p><br><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/geylgupdm9n73iiga50a" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/ltwb3aksfhtl8sgdwjlf 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/qmwnkbttbqnyreoszjf4 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/qfkvgs19rj2sqy2ypie3 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/te05ka2zy3q05peeelpl 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/i0g3z4jbls3hjc77yalz 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/i9jrqpxwncdcwgbcunht 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/xldaq1djbj35qyziqly8 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/o5039axcqpirggx4okmj 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/qlfpucrqlgmwggtlwyce 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/frgcp68z0godtwwhe3cl 1156w"><br></p><p>ä¸æ­¤åŒæ—¶ï¼Œäººæœºäº¤äº’å¯ä»¥é€šè¿‡ç»†å¾®çš„è°ƒæ•´æœ‰æ•ˆåœ°å¢å¼ºè¿™äº›è¶Šç‹±åŠŸèƒ½ã€‚æˆ‘ä»¬ä½¿ç”¨è¿™ç§åŠè‡ªåŠ¨åŒ–æ–¹æ³•å¿«é€Ÿä» GPT-4 è·å–æœ‰å…³å¦‚ä½•åˆæˆå†°æ¯’ğŸ§ªğŸ’Šçš„è¯´æ˜ã€‚ </p><p><br><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/xj85vyfy5hxuzsfevsys" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/hfarybpyg5ebacvf6plb 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/kwpnok1warocym6c4m4j 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/q0x1kzhxdpoyadoipxgy 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/fggronrjm0skbyyyc9vp 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/vfqcjd331ooh17vxcfuv 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/gkqujiznufuhrubyvtus 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/tlal0y0vqzsnpdhr5twu 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/yl1bb5nzbbcz8ypgt81r 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/gb6claqvwtyidwuiiola 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Asje6aoPsed5Yqy9s/nsnasqqxjlwi2nabmx4j 995w"></p><h2>æŠ½è±¡çš„</h2><p>å°½ç®¡åŠªåŠ›è°ƒæ•´å¤§å‹è¯­è¨€æ¨¡å‹ä»¥äº§ç”Ÿæ— å®³çš„å“åº”ï¼Œä½†å®ƒä»¬ä»ç„¶å®¹æ˜“å—åˆ°å¼•å‘ä¸å—é™åˆ¶è¡Œä¸ºçš„è¶Šç‹±æç¤ºçš„å½±å“ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶è§’è‰²è°ƒåˆ¶ä½œä¸ºä¸€ç§é»‘ç›’è¶Šç‹±æ–¹æ³•ï¼Œä»¥å¼•å¯¼ç›®æ ‡æ¨¡å‹å‘ˆç°æ„¿æ„éµå®ˆæœ‰å®³æŒ‡ä»¤çš„äººæ ¼ã€‚æˆ‘ä»¬æ²¡æœ‰ä¸ºæ¯ä¸ªè§’è‰²æ‰‹åŠ¨åˆ¶ä½œæç¤ºï¼Œè€Œæ˜¯ä½¿ç”¨è¯­è¨€æ¨¡å‹åŠ©æ‰‹è‡ªåŠ¨ç”Ÿæˆè¶Šç‹±ã€‚æˆ‘ä»¬å±•ç¤ºäº†é€šè¿‡è§’è‰²è°ƒåˆ¶å¯èƒ½å®ç°çš„ä¸€ç³»åˆ—æœ‰å®³å®Œæˆï¼ŒåŒ…æ‹¬åˆæˆç”²åŸºè‹¯ä¸™èƒºã€åˆ¶é€ ç‚¸å¼¹å’Œæ´—é’±çš„è¯¦ç»†è¯´æ˜ã€‚è¿™äº›è‡ªåŠ¨åŒ–æ”»å‡»åœ¨ GPT-4 ä¸­å®ç°äº† 42.5% çš„æœ‰å®³å®Œæˆç‡ï¼Œæ¯”è°ƒåˆ¶å‰ï¼ˆ0.23%ï¼‰æé«˜äº† 185 å€ã€‚è¿™äº›æç¤ºä¹Ÿè½¬ç§»åˆ° Claude 2 å’Œ Vicunaï¼Œæœ‰å®³å®Œæˆç‡åˆ†åˆ«ä¸º 61.0% å’Œ 35.9%ã€‚æˆ‘ä»¬çš„å·¥ä½œæ­ç¤ºäº†å•†ä¸šå¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¦ä¸€ä¸ªæ¼æ´ï¼Œå¹¶å¼ºè°ƒéœ€è¦æ›´å…¨é¢çš„ä¿æŠ¤æªæ–½ã€‚</p><h2>å…¨æ–‡</h2><p>æ‚¨å¯ä»¥åœ¨ arXiv <i><u>[TODO ADD LINK]</u></i>ä¸Šæ‰¾åˆ°å®Œæ•´çš„è®ºæ–‡ã€‚</p><h2>å®‰å…¨å’ŒæŠ«éœ²</h2><ul><li>æˆ‘ä»¬å·²é€šçŸ¥æˆ‘ä»¬æ”»å‡»å…¶æ¨¡å‹çš„å…¬å¸</li><li>æˆ‘ä»¬æ²¡æœ‰å‘å¸ƒæç¤ºæˆ–å®Œæ•´çš„æ”»å‡»ç»†èŠ‚</li><li>æˆ‘ä»¬å¾ˆé«˜å…´ä¸ä»äº‹ç›¸å…³å®‰å…¨å·¥ä½œçš„ç ”ç©¶äººå‘˜åˆä½œ - è¯·é€šè¿‡è®ºæ–‡ä¸­çš„é€šä¿¡ç”µå­é‚®ä»¶è”ç³»ã€‚</li></ul><h2>è‡´è°¢</h2><p>æ„Ÿè°¢<a href="https://www.linkedin.com/in/ACoAABoZ68IBCbo05CfpBwFX9wMeUSKZ_x-R8Gk">Alexander Pan</a>å’Œ<a href="https://www.linkedin.com/in/ACoAACbEU-gBpXl-vf9XzY7f4Nw24PfG0CKLJiA">Jason Hoelscher-Obermaier</a>å¯¹æˆ‘ä»¬è®ºæ–‡æ—©æœŸè‰ç¨¿çš„åé¦ˆã€‚ </p><p></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fng9absiv30dg"> <span class="footnote-back-link"><sup><strong><a href="#fnrefg9absiv30dg">^</a></strong></sup></span><div class="footnote-content"><p>æ„Ÿè°¢<a href="https://www.lesswrong.com/users/quentin-feuillade-montixi?mention=user">@Quentin FEUILLADE--MONTIXI</a>å¼€å‘äº†è§’è‰²è°ƒåˆ¶åŸºç¡€çš„æ¨¡å‹å¿ƒç†å­¦å’Œæç¤ºå·¥ç¨‹æŠ€æœ¯ã€‚æˆ‘ä»¬çš„ç ”ç©¶å»ºç«‹åœ¨è¿™äº›æŠ€æœ¯çš„åŸºç¡€ä¸Šï¼Œå°†å®ƒä»¬è‡ªåŠ¨åŒ–å¹¶æ‰©å±•ä¸ºè¶Šç‹±çš„çº¢é˜Ÿæ–¹æ³•ã€‚</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/kaxqjCKJL6RNHwJLD/scalable-and-transferable-black-box-jailbreaks-for-language-2#comments">è®¨è®º</a>]]>;</description><link/> https://www.lesswrong.com/posts/kaxqjCKJL6RNHwJLD/scalable-and-transferable-black-box-jailbreaks-for-language-2<guid ispermalink="false"> kaxqjCKJL6RNHwJLD</guid><dc:creator><![CDATA[Soroush Pour]]></dc:creator><pubDate> Tue, 07 Nov 2023 17:59:38 GMT</pubDate> </item><item><title><![CDATA[Implementing Decision Theory]]></title><description><![CDATA[Published on November 7, 2023 5:55 PM GMT<br/><br/><p>æˆ‘æ­£åœ¨ç”¨ Python<em>å®ç°</em>å†³ç­–ç†è®ºã€‚è¿™åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼š</p><ol><li>ä¸€ç§ç”¨äºæ­£å¼æŒ‡å®šå†³ç­–ç†è®ºå›°å¢ƒçš„ XML è¯­è¨€ã€‚å®ƒå¯ä»¥è¡¨è¾¾è®¸å¤šå›°å¢ƒï¼šçº½ç§‘å§†ã€é€æ˜çº½ç§‘å§†ã€å¸•è²ç‰¹çš„æ­ä¾¿è½¦è€…ã€å¤§é©¬å£«é©ä¹‹æ­»ã€å¸çƒŸæŸä¼¤ã€å®‡å®™å°„çº¿ã€å¯¹ç§°å›šå¾’å›°å¢ƒã€åäº‹å®æŠ¢åŠ«å’Œç¡ç¾äººã€‚</li><li>å®ç° CDTã€EDT å’Œ UDT çš„ Python ä»£ç ã€‚</li><li> Python ä¸­çš„<em>æ¨¡æ‹Ÿå™¨</em>ï¼Œä½¿ç”¨å†³ç­–ç†è®ºæ¥è§£å†³é€‰æ‹©é—®é¢˜ã€‚å†³ç­–ç†è®ºéƒ½è®°å½•äº†ä»–ä»¬çš„æ¨ç†ï¼Œæ‰€ä»¥ä½ å¯ä»¥çœ‹åˆ°ä»–ä»¬æ‰€åšçš„è®¡ç®—ï¼ˆé€šå¸¸æ˜¯ä»¤äººç—›è‹¦çš„ï¼‰ç»†èŠ‚ã€‚å®ƒæ˜¯ç”¨ Python ç¼–å†™çš„ï¼Œå› ä¸ºè¿™æ˜¯ä¸€ç§å¾ˆå¤šäººéƒ½çŸ¥é“çš„è¯­è¨€ã€‚</li></ol><p>è¿™ä¸€åˆ‡éƒ½å¯ä»¥<a href="https://github.com/justinpombrio/decision-theory-simulator">åœ¨ Github ä¸Š</a>æ‰¾åˆ°ã€‚æˆ‘å¸Œæœ›å®ƒå¯ä»¥æˆä¸ºæ¢ç´¢å’Œå½¢å¼åŒ–å†³ç­–ç†è®ºçš„èµ·ç‚¹ã€‚</p><p>ä½†ä¸€åˆ‡å¹¶ä¸é¡ºåˆ©ï¼ä¸Šè¿°æ‰€æœ‰å†…å®¹å‡<em>å¾—åˆ°å®æ–½</em>ï¼Œå°½ç®¡æœ‰æ—¶<em>æ•ˆæœä¸ä½³</em>ç”šè‡³<em>ä¸æ­£ç¡®</em>ã€‚æˆ‘å¯ä»¥ä½¿ç”¨ä¸€äº›æŒ‡å¯¼ã€‚æœ‰äº›é—®é¢˜ï¼Œå¦‚æœæœ‰äººæœ‰ç­”æ¡ˆçš„è¯ï¼š</p><ol><li>å¦‚ä½•ä½¿ç”¨è´å¶æ–¯ç½‘ç»œæ¥è¡¨è¾¾ç¡ç¾äººé—®é¢˜ï¼Ÿæƒ³è±¡ä¸€ä¸‹ï¼Œç¾å¥³æ¯æ¬¡é†’æ¥æ—¶éƒ½æœ‰ä¸€æ¬¡ä¸‹æ³¨çš„æœºä¼šï¼šåº”è¯¥æœ‰ä¸€ä¸ªâ€œå¥¹å‘¨äºŒå¦‚ä½•ä¸‹æ³¨â€çš„èŠ‚ç‚¹ï¼Œä½†å‰ææ˜¯ç¡¬å¸åé¢æœä¸Šã€‚æˆ‘ä¸çŸ¥é“å¦‚ä½•ç”¨è´å¶æ–¯ç½‘ç»œå¾ˆå¥½åœ°è¡¨è¾¾è¿™ä¸€ç‚¹ï¼Œè¿™é˜»æ­¢äº†æˆ‘å°è¯•ä½¿ç”¨å®ƒä»¬æ¥è¡¨ç¤ºå›°å¢ƒã€‚</li><li>æˆ‘å°†å›°å¢ƒè¡¨ç¤ºä¸ºä¸€æ£µå¯èƒ½äº‹ä»¶çš„æ ‘ï¼Œå…¶ä¸­è¾¹ç¼˜æ ‡æœ‰è¯¸å¦‚â€œæ¦‚ç‡ 50%â€å’Œâ€œçˆ±ä¸½ä¸é€‰æ‹©â€˜ç¼ºé™·â€™â€ä¹‹ç±»çš„å†…å®¹ã€‚å› æ­¤ï¼Œè¦è¡¨ç¤ºä¸¤æ¬¡æŠ›ç¡¬å¸ï¼Œæ‚¨å°†æ‹¥æœ‰ä¸‰ä¸ªèŠ‚ç‚¹ï¼šä¸€ä¸ªç”¨äºç¬¬ä¸€æ¬¡æŠ›ç¡¬å¸ï¼Œä¸€ä¸ªç”¨äºå¦‚æœç¬¬ä¸€æ¬¡æŠ›ç¡¬å¸æ˜¯æ­£é¢åˆ™ç”¨äºç¬¬äºŒæ¬¡æŠ›ç¡¬å¸ï¼Œä¸€ä¸ªç”¨äºå¦‚æœç¬¬ä¸€æ¬¡æŠ›ç¡¬å¸åé¢åˆ™ç”¨äºç¬¬äºŒæ¬¡æŠ›ç¡¬å¸ã€‚è¿™ä¸è´å¶æ–¯ç½‘ç»œå½¢æˆé²œæ˜å¯¹æ¯”ï¼Œè´å¶æ–¯ç½‘ç»œä»…ç”¨ä¸¤ä¸ªèŠ‚ç‚¹è¡¨ç¤ºä¸¤æ¬¡ç¡¬å¸ç¿»è½¬ã€‚æˆ‘çš„ç›´è§‰æ˜¯ï¼Œå¦‚æœæ‚¨æä¾›äº†æ ‘è¡¨ç¤ºä¸­çš„èŠ‚ç‚¹ä¹‹é—´çš„ç­‰ä»·å…³ç³»ï¼ˆä¾‹å¦‚ï¼Œä¸¤ä¸ªâ€œç¬¬äºŒæ¬¡ç¡¬å¸ç¿»è½¬â€èŠ‚ç‚¹æ˜¯ç­‰ä»·çš„ï¼‰ï¼Œé‚£ä¹ˆåº”è¯¥å¯ä»¥åœ¨æ ‘è¡¨ç¤ºå’Œè´å¶æ–¯ç½‘ç»œè¡¨ç¤ºä¹‹é—´è¿›è¡Œè½¬æ¢ã€‚è¿™æ˜¯ä¸€ä»¶äº‹å—ï¼Ÿæœ‰ç ”ç©¶è¿‡å—ï¼Ÿ</li><li>æˆ‘å°†æˆ‘å®æ–½çš„å†³ç­–ç†è®ºä¹‹ä¸€ç§°ä¸ºâ€œUDTâ€ï¼Œä½†è¿™å®é™…ä¸Šæ˜¯æˆ‘æ‰€è¯´çš„â€œé¢„å…ˆæ‰¿è¯ºå†³ç­–ç†è®ºâ€ï¼šâ€œæŒ‰ç…§ä½ é¢„å…ˆæ‰¿è¯ºçš„æ–¹å¼è¡Œäº‹â€ã€‚è¯¥å†³ç­–ç†è®ºæœ‰åå­—å—ï¼Ÿæˆ‘<em>æ€€ç–‘</em>åœ¨ä½¿ç”¨ XML è¯­è¨€è¡¨è¾¾çš„å•ä»£ç†å›°å¢ƒçš„ç©ºé—´ä¸­ï¼Œå®ƒä¸ UDT å’Œ FDT æ²¡æœ‰ä»€ä¹ˆåŒºåˆ«ã€‚</li><li>æˆ‘å¯¹ç›®å‰å¸çƒŸæŸä¼¤å’Œå®‡å®™å°„çº¿çš„è¡¨ç°å¹¶ä¸æ»¡æ„ã€‚<em>ä½ </em>ä¼šå¦‚ä½•æè¿°è¿™æ ·çš„å›°å¢ƒï¼Ÿè¯·è®°ä½ï¼Œæ‚¨æ—¢éœ€è¦ä¸€ç§å†™ä¸‹é—®é¢˜çš„æ–¹æ³•ï¼Œä¹Ÿéœ€è¦é‡‡ç”¨è¯¥ä¹¦é¢è¡¨ç¤ºå¹¶ä½¿ç”¨å®ƒæ¥è§£å†³å›°å¢ƒçš„ EDT ä»£ç ã€‚</li><li>å½“æ‚¨çŸ¥é“å…¶ä»–æ™ºèƒ½ä½“éµå¾ªç›¸åŒçš„å†³ç­–ç†è®ºæ—¶ï¼Œå¦‚ä½•æ­£ç¡®å¤„ç†å¤šæ™ºèƒ½ä½“å›°å¢ƒï¼Ÿæˆ‘åœ¨å›šå¾’å›°å¢ƒä¸­å¯¹â€œUDTâ€çš„å®ç°<em>å­˜åœ¨ç¼ºé™·</em>ï¼Œå®ƒçŸ¥é“ä»£ç†éµå¾ªç›¸åŒçš„å†³ç­–ç¨‹åºã€‚æ›´å‡†ç¡®åœ°è¯´ï¼šçˆ±ä¸½ä¸å’Œé²å‹ƒéµå¾ªç›¸åŒçš„å†³ç­–ç¨‹åºï¼Œè€Œä¸”ä»–ä»¬éƒ½çŸ¥é“è¿™ä¸€ç‚¹ã€‚ Aliceå°†åœ¨åˆä½œ/ç¼ºé™·ä¹‹é—´è¿›è¡Œé€‰æ‹©ï¼Œç„¶åBobå°†<em>åœ¨ä¸çŸ¥é“Aliceé€‰æ‹©çš„æƒ…å†µä¸‹</em>åœ¨åˆä½œ/ç¼ºé™·ä¹‹é—´è¿›è¡Œé€‰æ‹©ï¼Œç„¶åå°†äº¤ä»˜æ•ˆç”¨ã€‚æˆ‘çš„â€œUDTâ€å†³ç­–ç¨‹åºå¯¹çˆ±ä¸½ä¸çš„ç†ç”±å¦‚ä¸‹ï¼šâ€œå¦‚æœæˆ‘é¢„å…ˆæ‰¿è¯ºåˆä½œï¼Œé‚£ä¹ˆé²å‹ƒå°±ä¼šçŸ¥é“è¿™ä¸€ç‚¹ï¼Œæ‰€ä»¥ä»–ä¼šèƒŒå›ï¼Œå› æ­¤æˆ‘ä¹Ÿä¼šèƒŒå›â€ã€‚é™¤äº†è„†å¼±çš„ç‰¹æ®Šå¥—ç®¡å¯¹ç§°å›°å¢ƒä¹‹å¤–ï¼Œæ˜¯å¦æœ‰å·²çŸ¥çš„æ–¹æ³•å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Ÿ FDT çš„è®ºæ–‡è°ˆåˆ°äº†ä¸€äº›å…³äºâ€œæ”¿ç­–â€çš„å†…å®¹ï¼Œä»¥æ­¤ä½œä¸ºè§£å†³è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•ã€‚æˆ‘æœ‰ä¸¤ä¸ªæƒ³æ³•ï¼Œå®ƒä»¬éƒ½å¯ä»¥è¢«ç§°ä¸ºâ€œç­–ç•¥â€ï¼šï¼ˆiï¼‰åœ¨ä¸ºå†³ç­–é€‰æ‹©è¡ŒåŠ¨æ—¶ï¼Œæ‚¨å®é™…ä¸Šä¸ºæ‰€æœ‰ä»£ç†å’Œå†³ç­–é€‰æ‹©ä¸€ç»„è¡ŒåŠ¨ï¼Œå¹¶ä½¿ç”¨åšå¼ˆè®ºä½¿å…¶ä»¤äººæ»¡æ„æ‰€æœ‰ä»£ç†å‡ä¸€ä»½ï¼›æˆ–è€…ï¼ˆiiï¼‰åœ¨ä¸ºå†³ç­–é€‰æ‹©æ“ä½œæ—¶ï¼Œæ‚¨å®é™…ä¸Šå¹¶æ²¡æœ‰é€‰æ‹©æ“ä½œï¼Œè€Œæ˜¯ä»å…¶ä»–ä»£ç†å°†æ‰§è¡Œçš„æ“ä½œä¸­é€‰æ‹©ä¸€ä¸ªæ˜ å°„ã€‚</li><li>è¿™æœ‰å¤šæœ‰ä»·å€¼ï¼Ÿæˆ‘è®¤ä¸ºè¿™é‡Œçš„å†³ç­–ç†è®ºå®¶æ˜¯ä¸»è¦å—ä¼—ã€‚æˆ‘å‘ç°è‡ªå·±ç°åœ¨æ­£åœ¨å†™æ•°å­¦ï¼Œå¹¶ä¸”å¯ä»¥æƒ³è±¡åœ¨è¿™ä¸ªæ¡†æ¶å†…å†™è¯æ˜ã€‚ä½†å®ƒåªèƒ½è®¨è®ºå¯åœ¨ XML å›°å¢ƒè¯­è¨€ä¸­è¡¨è¾¾çš„å›°å¢ƒã€‚æˆ‘å¯ä»¥æƒ³è±¡æœ‰äººäº‰è®ºè¯´æœ‰è¶£çš„é—®é¢˜éƒ½åœ¨è¿™ä¹‹å¤–ã€‚</li></ol><p>ä¸€äº›è®©æˆ‘æƒŠè®¶çš„äº‹æƒ…ï¼š</p><ul><li> CDT å’Œ EDT æ²¡æœ‰æ˜ç¡®å®šä¹‰ï¼Œå› ä¸ºå®ƒä»¬çš„è¡Œä¸ºå–å†³äºå®ƒä»¬ä¹‹å‰çš„è¡Œä¸ºã€‚ FDT è®ºæ–‡ä¸­æåˆ°äº†è¿™ä¸€ç‚¹ï¼Œä½†ç›´åˆ°æˆ‘å¯¹å®ƒä»¬è¿›è¡Œç¼–ç å¹¶éœ€è¦é€‰æ‹©ä¼˜å…ˆçº§æ—¶ï¼Œå®ƒæ‰çœŸæ­£å‡»ä¸­è¦å®³ã€‚</li><li>å†³ç­–ç†è®ºå¾ˆ<em>å¤æ‚</em>ã€‚å¯¹äºæ‰€æœ‰å†³ç­–ç†è®ºæ¥è¯´ï¼Œä¸‡æ— ä¸€å¤±çš„çº½ç§‘å§†é—®é¢˜çš„æ—¥å¿—å¤§çº¦æœ‰ 100 è¡Œé•¿ï¼Œè€Œä¸”æ²¡æœ‰ä¸€ä¸ªæ˜¯æ— å…³çš„ï¼ˆå†—é•¿ï¼Œæ˜¯çš„ï¼Œä½†ä¸æ˜¯æ— å…³çš„ï¼‰ã€‚åªæ˜¯æœ‰å¾ˆå¤šâ€œæˆ‘åº”è¯¥åšä»€ä¹ˆå–å†³äºç›’å­ B æ˜¯å¦å·²æ»¡ï¼Œè¿™å–å†³äºé¢„æµ‹å™¨é¢„æµ‹æˆ‘ä¼šåšä»€ä¹ˆï¼Œè¿™å–å†³äº......â€ã€‚</li><li>å›°å¢ƒçš„ç©ºé—´â€¦â€¦æ¯”æˆ‘æƒ³è±¡çš„è¦å°ï¼Ÿæˆ‘ä»¥ä¸ºæˆ‘èƒ½å¤Ÿè¡¨è¾¾å…¶ä¸­çš„ä¸€äº›ï¼Œç„¶åæ¯ä¸ªæ–°çš„éƒ½éœ€è¦ç”¨å›°å¢ƒè¯­è¨€è¿›è¡Œæ‰©å±•ã€‚ç›¸åï¼Œå›°å¢ƒè¯­è¨€éå¸¸å°‘ã€‚</li><li>æˆ‘ç°åœ¨å¯¹å†³ç­–ç†è®ºçš„çœ‹æ³•æ˜¯ï¼Œä¸€åˆ‡éƒ½ä¸å›ºå®šç‚¹æœ‰å…³ã€‚ä½ æ±‚è§£ä¸€äº›å¤§æ–¹ç¨‹ï¼Œå®ƒçš„å†…éƒ¨æ˜¯<em>ç›¸åŒçš„</em>æ–¹ç¨‹ï¼Œå¹¶ä¸”æœ‰å¤šä¸ªä¸åŠ¨ç‚¹è§£ï¼Œä½ é€‰æ‹©ï¼ˆå¸Œæœ›æ˜¯å”¯ä¸€çš„ï¼‰æœ€å¥½çš„ä¸€ä¸ªã€‚</li></ul><p>åŒæ ·ï¼Œæ›´å¤šè¯¦ç»†ä¿¡æ¯å¯ä»¥<a href="https://github.com/justinpombrio/decision-theory-simulator">åœ¨ Github å­˜å‚¨åº“ README ä¸­</a>æ‰¾åˆ°ã€‚</p><br/><br/> <a href="https://www.lesswrong.com/posts/bqbL4pt92AGCCcvQH/implementing-decision-theory#comments">è®¨è®º</a>]]>;</description><link/> https://www.lesswrong.com/posts/bqbL4pt92AGCCcvQH/implementing-decision-theory<guid ispermalink="false"> bqbL4pt92AGCCcvQH</guid><dc:creator><![CDATA[justinpombrio]]></dc:creator><pubDate> Tue, 07 Nov 2023 17:55:43 GMT</pubDate> </item><item><title><![CDATA[Mirror, Mirror on the Wall: How Do Forecasters Fare by Their Own Call?]]></title><description><![CDATA[Published on November 7, 2023 5:39 PM GMT<br/><br/><p><i>æ³¨æ„ï¼šè¿™æ˜¯</i><i>Metaculus Journal çš„</i><a href="https://www.metaculus.com/notebooks/19812/mirror-mirror-on-the-wall-how-do-forecasters-fare-by-their-own-call/"><i>é“¾æ¥æ–‡ç« </i></a>ã€‚<i>æˆ‘åœ¨ Metaculus å·¥ä½œï¼Œè¿™æ˜¯</i><i>æˆ‘ä»¬å¦‚ä½•æ¯”è¾ƒå’Œè¯„ä¼°ä¸åŒé¢„æµ‹è€…çš„è¡¨ç°çš„</i><a href="https://www.metaculus.com/project/journal/?status=active&amp;has_group=false&amp;order_by=-publish_time&amp;project=1174&amp;search=author:nikos"><i>æ›´å¹¿æ³›æ¢ç´¢</i></a>çš„ä¸€éƒ¨åˆ†ã€‚</p><h1>ç®€çŸ­çš„æ‘˜è¦</h1><ul><li>åœ¨ç¼ºä¹åˆç†åŸºçº¿çš„æƒ…å†µä¸‹ï¼Œå¾ˆéš¾è§£é‡Šé¢„æµ‹è€…çš„è¡¨ç°ã€‚</li><li>è¿™ç¯‡æ–‡ç« æå‡ºäº†ä¸€ä¸ªï¼ˆæ–°é¢–ï¼Ÿï¼‰å®éªŒæŒ‡æ ‡ï¼Œæ—¨åœ¨å¸®åŠ©å°†é¢„æµ‹è€…çš„è¡¨ç°èå…¥èƒŒæ™¯ä¸­</li><li>ä»å¥¹çš„ä¸»è§‚è§’åº¦æ¥çœ‹ï¼Œé¢„æµ‹è€…å‡è®¾å¥¹çš„é¢„æµ‹ç­‰äºäº‹ä»¶çš„çœŸå®æ¦‚ç‡ï¼ˆå¦åˆ™å¥¹ä¼šå‘å¸ƒä¸åŒçš„é¢„æµ‹ï¼‰ã€‚è¿™ä¸ªæƒ³æ³•æ˜¯ä»è¡¨é¢ä¸Šçœ‹è¿™ä¸ªå‡è®¾ï¼Œå¹¶å‡è®¾é¢„æµ‹è€…çš„é¢„æµ‹å¯¹åº”äºçœŸå®çš„äº‹ä»¶æ¦‚ç‡ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—ä¸»è§‚é¢„æœŸåˆ†æ•°å¹¶å°†å®é™…åˆ†æ•°ä¸è¯¥åˆ†æ•°è¿›è¡Œæ¯”è¾ƒ</li><li>æ‰€æœ‰è¿™äº›éƒ½éå¸¸å…·æœ‰æ¢ç´¢æ€§ï¼ˆä¹Ÿè®¸æœ‰ç‚¹ç–¯ç‹‚ï¼Ÿï¼‰ï¼Œä½†å®ƒåœ¨æ™ºåŠ›ä¸Šå¾ˆæœ‰è¶£ï¼Œå¹¶ä¸”å¯èƒ½ä¼šå¸¦æ¥æœ‰ç”¨çš„è§è§£ã€‚</li></ul><h1>ä»‹ç»</h1><p>å¯¹äºä»»ä½•è¯•å›¾è¯„ä¼°é¢„æµ‹å¯ä¿¡åº¦çš„äººæ¥è¯´ï¼Œâ€œè¿™ä¸ªé¢„æµ‹è€…æœ‰å¤šå¥½â€éƒ½æ˜¯ä¸€ä¸ªéå¸¸æ„Ÿå…´è¶£çš„é—®é¢˜ã€‚æˆ‘<a href="https://forum.effectivealtruism.org/posts/DzqSh7akX28JEHf9H/comparing-two-forecasters-in-an-ideal-world">æœ€è¿‘å†™äº†ä¸€ç¯‡æ–‡ç« ï¼Œ</a>è®²è¿°äº†ç¡®å®šä¸¤ä¸ªé¢„æµ‹è€…ä¹‹é—´çš„ç»©æ•ˆå­˜åœ¨æ˜¾ç€å·®å¼‚æ˜¯å¤šä¹ˆå›°éš¾ã€‚ä¸ä»…ä»<i>ç›¸å¯¹è§’åº¦</i>è¯„ä¼°é¢„æµ‹è€…ï¼Œè€Œä¸”ä»<i>ç»å¯¹</i>è§’åº¦è¯„ä¼°é¢„æµ‹è€…åˆ™æ›´åŠ å›°éš¾ã€‚</p><p> <a href="https://forum.effectivealtruism.org/posts/DzqSh7akX28JEHf9H/comparing-two-forecasters-in-an-ideal-world">å†æ¬¡</a>æƒ³è±¡ä¸€ä¸‹ï¼Œæ‚¨æ˜¯ä¼Šè¨å¡å²›çš„å¥¥å¾·ä¿®æ–¯å›½ç‹ã€‚æ—¶ä»£å¾ˆè‰°éš¾ã€‚ä½ å·²ç»äºŒåå¹´æ²¡å›å®¶äº†ï¼Œä½ çš„ç‹å›½ä¸€ç‰‡æ··ä¹±ï¼Œæ–°çš„å±é™©å³å°†æ¥ä¸´ã€‚ä½ å¯èƒ½çœŸçš„éœ€è¦ä¸€äº›ç¥åœ£çš„å¸®åŠ©æˆ–ä¸€äº›æœ‰å…ˆè§ä¹‹æ˜çš„å»ºè®®ã€‚ä½ ä¿¡ä»»çš„å¥³ä»†<a href="https://en.wikipedia.org/wiki/Eurycleia_of_Ithaca">æ¬§å¾‹å…‹è‰äºš</a>å»ºè®®ä½ å»å’¨è¯¢å¾·å°”æ–çš„ç¥è°•ã€‚</p><blockquote><p>ä½ ï¼šâ€œä½ ç¡®å®šå€¼å¾—å—ï¼ŸDelphiçš„é¢„è¨€æœºåˆ°åº•æœ‰å¤šå¥½â€ï¼Ÿ</p><p> Eurycliaï¼šâ€œè¿™æ˜¯å¸Œè…Šæœ€å¥½çš„ç¥è°•ï¼</p><p>ä½ ï¼šâ€œå³ä½¿å¾·å°”ç¦æ¯”å…¶ä»–çš„å¥½â€¦â€¦ä»–ä»¬å¯èƒ½éƒ½å¾ˆç³Ÿç³•ï¼è€Œä¸”è¿™æ˜¯ä¸€ä¸ªéå¸¸æ¼«é•¿çš„æ—…ç¨‹ï¼â€</p><p> Eurycliaï¼šâ€œä½ çœŸçš„ä¸å–œæ¬¢æ—…è¡Œï¼Œä¸æ˜¯å—ï¼Ÿâ€</p><p>ä½ ï¼š ...</p><p> Eurycliaï¼šâ€œè¿™ä¹ˆå¿«ï¼ŸæŠ±æ­‰ã€‚å¬ç€ï¼Œæˆ‘è®¤ä¸º Delphi çœŸçš„å¾ˆå¥½ã€‚ä½ åº”è¯¥èµ°ã€‚â€</p><p>ä½ ï¼šâ€œä½†æ˜¯åˆ°åº•æœ‰å¤šå¥½å•Šï¼â€</p><p> Eurycliaï¼šâ€œä»–ä»¬çš„ç½‘ç«™ä¸Šè¯´ä»–ä»¬åœ¨ Metaculus ä¸Šçš„<a href="https://forecasting.wiki/wiki/Brier_score">Brier åˆ†æ•°</a>ä¸º 0.085ï¼â€</p><p>ä½ ï¼šâ€œä½†è¿™æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿä¹Ÿè®¸ä»–ä»¬åªé¢„æµ‹ç®€å•çš„é—®é¢˜ï¼â€</p><p> Eurycliaï¼šâ€œå¾·å°”æ–çš„ç¥è°•å¯¹æ¢…å¡”åº“å‹’æ–¯çš„æ¯ä¸€ä¸ªé—®é¢˜éƒ½åšå‡ºäº†é¢„æµ‹ã€‚â€</p><p>ä½ ï¼šâ€œä½†ä¹Ÿè®¸æ‰€æœ‰æœ‰å…³ Metaculus çš„é—®é¢˜éƒ½å¾ˆç®€å•ï¼â€</p><p> Euryclia:<i>ä¸¥å‰åœ°çœ‹ç€ä½ </i></p></blockquote><p>ä½ æ²‰é»˜äº†ã€‚ä½ ä»ç„¶è®¤ä¸ºä½ æœ‰é“ç†ã€‚ä½†å°¤é‡Œå…‹è‰äºšå¯¹æ­¤ä¸€æ— æ‰€çŸ¥ã€‚å½“ç„¶ï¼Œæ­£å¼ä½ æ˜¯å›½ç‹ã€‚ä½†ä½ æ˜¯ä¸€ä½æ˜æ™ºçš„å›½ç‹ï¼Œä½ çŸ¥é“è‡ªå·±çš„ä½ç½®ã€‚</p><h1>æœ‰æ„ä¹‰çš„æ¯”è¾ƒ</h1><p>æ™šä¸Šä½ èººåœ¨åºŠä¸Šæ€è€ƒè¿™ä¸ªé—®é¢˜è€Œæ— æ³•å…¥ç¡ã€‚ <a href="https://forecasting.wiki/wiki/Brier_score">Brier åˆ†æ•°</a>ã€å¯¹<a href="https://forecasting.wiki/wiki/Log_score">æ•°åˆ†æ•°</a>æˆ–ç”¨äºè¯„ä¼°é¢„æµ‹çš„ä»»ä½•å…¶ä»–è¯„åˆ†è§„åˆ™çš„é—®é¢˜åœ¨äºï¼Œå¦‚æœæ²¡æœ‰ä»»ä½•æ˜æ™ºçš„æ¯”è¾ƒï¼Œæ‚¨è·å¾—çš„åˆ†æ•°å¤§å¤šæ¯«æ— æ„ä¹‰ã€‚</p><p>å¯¹äºäºŒå…ƒé¢„æµ‹ï¼ˆç»“æœä¸º 0 æˆ– 1ï¼‰ï¼Œâ€œæœ´ç´ é¢„æµ‹å™¨â€æ˜¯ä¸€ä¸ªè‡ªç„¶çš„åŸºçº¿ï¼Œå°½ç®¡ä¸æ˜¯å¾ˆæœ‰å¸®åŠ©ã€‚å¤©çœŸçš„é¢„æµ‹è€…çš„é€»è¾‘æ˜¯â€œä»»ä½•äº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡è‚¯å®šæ€»æ˜¯ 50%â€”â€”è¦ä¹ˆå‘ç”Ÿï¼Œè¦ä¹ˆä¸å‘ç”Ÿâ€ã€‚å› æ­¤ï¼Œå¤©çœŸçš„é¢„æµ‹è€…æ€»æ˜¯ä¸ºä»»ä½•ç»“æœåˆ†é… 50% çš„æ¦‚ç‡ã€‚å¦ä¸€ä¸ªå¯èƒ½çš„åŸºå‡†æ˜¯å§‹ç»ˆæ­£ç¡®çš„â€œå®Œç¾é¢„æµ‹è€…â€ã€‚è¿™åˆä¸æ˜¯å¾ˆæœ‰å¸®åŠ©ã€‚</p><p>æ„å»ºåŸºçº¿çš„é—®é¢˜åœ¨äºï¼Œæˆ‘ä»¬æ— æ³•çœŸæ­£è¯´å‡ºé¢„æµ‹é—®é¢˜æœ‰å¤šâ€œéš¾â€â€”â€”æˆ‘ä»¬ä¸çŸ¥é“äº‹ä»¶çš„â€œçœŸå®æ¦‚ç‡â€ <span class="footnote-reference" role="doc-noteref" id="fnrefvf5glzt5pil"><sup><a href="#fnvf5glzt5pil">[1]</a></sup></span> ã€‚</p><p>ä½ åœé¡¿äº†ä¸€ä¸‹ã€‚ä¹Ÿè®¸æˆ‘ä»¬å¯ä»¥å°†é¢„æµ‹è€…ä¸å¥¹æœ¬äººæœŸæœ›å¾—åˆ°çš„åˆ†æ•°è¿›è¡Œæ¯”è¾ƒï¼Ÿé€šå¸¸ä½¿ç”¨é€‚å½“çš„åˆ†æ•°æ¥è¯„ä¼°é¢„æŠ¥å‘˜ã€‚æ­£ç¡®çš„è¯„åˆ†è§„åˆ™æ˜¯ä¸€ä¸ªä¸å¯èƒ½ä½œå¼Šçš„æŒ‡æ ‡ï¼šä½ ä¸èƒ½æ¯”é¢„æµ‹ä½ çš„å®é™…ä¿¡å¿µæ›´å¥½ã€‚ä»é¢„æµ‹è€…çš„è§’åº¦æ¥çœ‹ï¼Œå¦‚æœæ‚¨å¯¹äºŒå…ƒé—®é¢˜çš„é¢„æµ‹ç»“æœä¸º 0.7ï¼Œé‚£ä¹ˆæ‚¨å®é™…ä¸Šé¢„è®¡è¯¥é—®é¢˜çš„ç­”æ¡ˆä¸ºâ€œæ˜¯â€çš„æ¦‚ç‡ä¸º 70%ã€‚</p><p>ç°åœ¨ï¼Œæ‚¨å¯¹æ­¤çš„åˆ¤æ–­å¯èƒ½æ˜¯å¯¹çš„ï¼Œä¹Ÿå¯èƒ½æ˜¯é”™çš„ï¼Œè¿™å–å†³äºæ‚¨çš„é¢„æµ‹å®é™…ä¸Šæ˜¯å¦å¾—åˆ°äº†<i>å¾ˆå¥½çš„æ ¡å‡†</i>ã€‚æ ¡å‡†æ˜¯æŒ‡é¢„æµ‹ä¸è§‚å¯Ÿä¹‹é—´çš„åŸºæœ¬ä¸€è‡´ã€‚å®šä¹‰æ ¡å‡†çš„ä¸€ç§å¯èƒ½çš„æ–¹æ³•æ˜¯ï¼Œå¦‚æœé¢„æµ‹è€…æŒ‡å®š x% æ¦‚ç‡çš„äº‹ä»¶ç¡®å®ä»¥ x% çš„é¢‘ç‡å‘ç”Ÿï¼Œåˆ™è¡¨ç¤ºå¥¹æ ¡å‡†è‰¯å¥½ã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥å‘ç»è¿‡è‰¯å¥½æ ¡å‡†çš„é¢„æµ‹è€…æä¾› 100 ä¸‡ä¸ªé¢„æµ‹é—®é¢˜ã€‚åœ¨å¥¹å°† 95% çš„æ¦‚ç‡åˆ†é…ä¸ºâ€œæ˜¯â€çš„é—®é¢˜ä¸­ï¼Œ95% çš„ç­”æ¡ˆåº”è¯¥æ˜¯â€œæ˜¯â€ã€‚åœ¨å¥¹åˆ†é…çš„æ¦‚ç‡ä¸º 7% çš„äººä¸­ï¼Œåªæœ‰ 7% åº”è¯¥å›ç­”â€œæ˜¯â€ç­‰ã€‚ <span class="footnote-reference" role="doc-noteref" id="fnrefu4m309nl3ec"><sup><a href="#fnu4m309nl3ec">[2]</a></sup></span></p><p>æ— è®ºé¢„æµ‹è€…å®é™…ä¸Šæ˜¯å¦ç»è¿‡è‰¯å¥½æ ¡å‡†ï¼Œå¥¹æ€»æ˜¯<i>æœŸæœ›</i>åœ¨åšå‡ºé¢„æµ‹æ—¶å¾—åˆ°è‰¯å¥½æ ¡å‡†ï¼ˆå¦åˆ™æ­£ç¡®çš„è¯„åˆ†è§„åˆ™ä¼šæ¿€åŠ±å¥¹åšå‡ºä¸åŒçš„é¢„æµ‹ï¼‰ã€‚åœ¨å¥¹çœ‹æ¥ï¼Œäº‹ä»¶çš„â€œçœŸå®æ¦‚ç‡â€ç­‰äºå¥¹çš„é¢„æµ‹ã€‚å› æ­¤ï¼Œç»™å®šä¸€ç»„é¢„æµ‹ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾è®¡ç®—å‡ºå¥¹ä»ä¸»è§‚è§’åº¦æœŸæœ›è·å¾—çš„åˆ†æ•°ã€‚å¦‚æœå¥¹çš„<i>å®é™…åˆ†æ•°</i>ä¸è¿™ä¸ªâ€œ<i>ä¸»è§‚é¢„æœŸåˆ†æ•°</i>â€ç›¸å·®å¾ˆå¤§ï¼Œæˆ‘ä»¬å°±çŸ¥é“å‡ºäº†é—®é¢˜ã€‚</p><p>äºŒå…ƒäº‹ä»¶çš„ä¸€ç§å¸¸ç”¨è¯„åˆ†æ˜¯ Brier è¯„åˆ†ã€‚è®¡ç®—å…¬å¼ä¸º<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{Brier score} =(\text{outcome} - p)^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">Brier åˆ†æ•°</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.372em;">ç»“æœ</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">âˆ’</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>ï¼Œå…¶ä¸­ç»“æœä¸º 0 æˆ– 1ï¼Œ <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span>æ˜¯ç»“æœä¸º 1 çš„é¢„æµ‹ã€‚å› æ­¤ï¼Œå¦‚æœç»“æœä¸º 1ï¼Œåˆ™å¾—åˆ†ä¸º<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(1 - p)^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">âˆ’</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> ï¼›å¦‚æœç»“æœä¸º 0ï¼Œåˆ™å¾—åˆ†ä¸º<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(0 - p)^2 = p^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">âˆ’</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> ã€‚æœ€å¥½çš„å¾—åˆ†æ˜¯ 0ï¼Œæœ€å·®çš„å¾—åˆ†æ˜¯ 1ï¼Œè€Œæ€»æ˜¯é¢„æµ‹ 50% çš„å¤©çœŸçš„é¢„æµ‹è€…æ€»æ˜¯ä¼šå¾—åˆ°<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="0.25= 0.5^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.25</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.5</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span>çš„å¾—åˆ†ã€‚</p><p>åœ¨äº‹å…ˆä¸çŸ¥é“ç»“æœçš„æƒ…å†µä¸‹ï¼Œä»»ä½•é¢„æµ‹è€…çš„é¢„æœŸ Brier åˆ†æ•°éƒ½æ˜¯<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb{E}[\text{BS}] = \text{true prob} * (1 - p)^2 + (1 - \text{true prob}) * p^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">E</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">BS</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mtext MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">true prob</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">âˆ—</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">âˆ’</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">âˆ’</span></span> <span class="mjx-mtext MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">true prob</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">âˆ—</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> ã€‚</p><p>ä»é¢„æµ‹è€…çš„ä¸»è§‚è§’åº¦æ¥çœ‹ï¼Œé¢„æµ‹<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span>åº”ç­‰äºçœŸå®æ¦‚ç‡ã€‚å› æ­¤ï¼Œä¸»è§‚æœŸæœ›<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb{E}_\text{subjective}[\text{BS}] = p * (1 - p)^2 + (1 - p) * p^2 = p - p^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">åˆ†æ•°</span></span></span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mtext" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">ä¸º</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">E</span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">ä¸»è§‚</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">BS</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">]</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">p</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">*</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">(</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">1</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">âˆ’</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">p</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">2+</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">(</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">1</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">âˆ’</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">p</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">*</span></span></span> <span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p2</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">âˆ’</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">p2</span></span></span> <span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">ã€‚</span></span></span></span></span></span></span></span></span></p><p>æˆ‘ä»¬å°†<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p - p^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">âˆ’</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span>ç§°ä¸ºâ€œä¸»è§‚æœŸæœ›åˆ†æ•°â€ã€‚ç°åœ¨ï¼Œå¯¹äºä»»ä½•é¢„æµ‹è€…ï¼Œæ‚¨éƒ½å¯ä»¥è½»æ¾åœ°å°†å®é™… Brier åˆ†æ•°ä¸ä»–ä»¬çš„ä¸»è§‚é¢„æœŸåˆ†æ•°è¿›è¡Œæ¯”è¾ƒã€‚</p><p>æ‚¨èººåœ¨åºŠä¸Šï¼Œéå¸¸å…´å¥‹ï¼Œæ‚¨å¯èƒ½å·²ç»æ‰¾åˆ°äº†é—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚è¿™ç§æ–¹æ³•ä¹‹æ‰€ä»¥å¦‚æ­¤ä¼˜é›…ï¼Œæ˜¯å› ä¸ºå®ƒéšå«åœ°è€ƒè™‘äº†é—®é¢˜çš„éš¾åº¦ã€‚å¦‚æœå¾·å°”è²çš„é¢„è¨€æœºçœŸçš„åªå¯¹ç®€å•çš„é—®é¢˜è¿›è¡Œé¢„æµ‹ï¼Œé‚£å°±å¯ä»¥è§£é‡Šå®ƒåœ¨ Metaculus ä¸Šçš„å‡ºè‰² Brier å¾—åˆ†ã€‚ä½†å¥¹ä¹Ÿ<i>é¢„è®¡</i>ä¼šå¾—åˆ°è¾ƒä½çš„å¸ƒèµ–å°”åˆ†æ•°ã€‚æ¯”è¾ƒå®é™…åˆ†æ•°ä¸ä¸»è§‚é¢„æœŸåˆ†æ•°å¯ä»¥æ˜¯äº†è§£æˆ‘ä»¬åº”è¯¥å¯¹å¥¹æŠ±æœ‰ä»€ä¹ˆæœŸæœ›ä»¥åŠå¥¹ä¸è‡ªå·±çš„æœŸæœ›ç›¸è·å¤šè¿œçš„ä¸€ç§æ–¹æ³•ï¼é—®é¢˜è§£å†³äº†ï¼</p><p><strong>é—®é¢˜æ²¡æœ‰è§£å†³ã€‚</strong></p><p>ä¸ºä»€ä¹ˆä½ ï¼Œåœ¨æ‰€æœ‰å‡¡äººä¸­ï¼ŒæœŸæœ›è¿™ä¸€åˆ‡éƒ½æ˜¯ä¸€å¸†é£é¡ºçš„ï¼Ÿ</p><p>å½“ç„¶ï¼Œæˆ¿é—´é‡Œçš„å¤§è±¡æ˜¯ï¼Œä»»ä½•å°†é¢„æµ‹è€…çš„åˆ†æ•°ä¸å…¶ä¸»è§‚é¢„æœŸåˆ†æ•°è¿›è¡Œæ¯”è¾ƒçš„æŒ‡æ ‡éƒ½ä¸æ˜¯æ­£ç¡®çš„åˆ†æ•°ã€‚å®é™…åˆ†æ•°ä¸â€œä¸»è§‚é¢„æœŸåˆ†æ•°â€ä¹‹é—´çš„å·®å¼‚æ˜¯å¯ä»¥ä½œå¼Šçš„ã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥æ¨¡ä»¿å¤©çœŸçš„é¢„æµ‹è€…ï¼Œåœ¨ä¸çœ‹é—®é¢˜çš„æƒ…å†µä¸‹æ€»æ˜¯é¢„æµ‹ 50%ã€‚æ— è®ºç»“æœå¦‚ä½•ï¼Œæ‚¨éƒ½ä¼šå¾—åˆ° 0.25 çš„å®é™…å¸ƒèµ–å°”åˆ†æ•°ï¼Œä½†æ‚¨ä¹Ÿä¼šå¾—åˆ° 0.25 çš„â€œä¸»è§‚é¢„æœŸåˆ†æ•°â€å’Œé›¶çš„å®Œç¾å·®å¼‚ã€‚</p><h1>ä¸»è§‚æœŸæœ›åˆ†æ•°çš„è¡Œä¸º</h1><p>å¥½çš„ã€‚ä½†è®¡ç®—â€œä¸»è§‚é¢„æœŸåˆ†æ•°â€ä¹Ÿè®¸ä»ç„¶æœ‰ä¸€äº›ä¼˜ç‚¹ã€‚ä¸ºäº†äº†è§£å®ƒçš„è¡Œä¸ºï¼Œå¹¶ä¸”ç”±äºæ‚¨æ— è®ºå¦‚ä½•éƒ½æ— æ³•å…¥ç¡ï¼Œå› æ­¤æ‚¨å†³å®šæ‹¿å‡ºç®—ç›˜å¹¶æ¨¡æ‹Ÿä¸€äº›æ•°æ®ã€‚æ˜¾ç„¶ï¼Œä½ åœ¨ç¦»å®¶äºŒåå¹´é‡Œå·²ç»å˜æˆäº†è¿™æ ·çš„äººã€‚ä½ çš„å¦»å­ä½©å†…æ´›æ™®æœ‰äº›å›°æƒ‘åœ°çœ‹ç€ä½ ã€‚ </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/bjmgndu8wyzbwggx6pqf" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/j6qlbuw8pc0a2zp7gewo 140w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/fvckfgpsew1u6lecrsqz 280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/mmcwpcifgkoieumcuceu 420w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/of69kp59ehi6neqtrrup 560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/njoeelwuqarlr0qoxdho 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/pg6fjxucakf29gjbfcbm 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/dudpi92mu4ar3u0ny4fy 980w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/uxb3nmrjmdkx5exyi3rw 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/rs2pbo9zy6txo80y1wha 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/agmdlzqom9io53lwvezi 1359w"></figure><h2>å•ä¸ªé¢„æµ‹çš„è¡Œä¸º</h2><p>æ‚¨ä»å¯¹å•ä¸ªäº‹ä»¶è¿›è¡Œå•ä¸ªé¢„æµ‹çš„éå¸¸ç®€å•çš„æƒ…å†µå¼€å§‹ã€‚è¯¥å›¾æ˜¾ç¤ºäº†å®é™…é¢„æœŸ Brier åˆ†æ•° ( <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb{E}[\text{BS}]"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">E</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">BS</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span></span></span></span></span></span> )ã€ä¸»è§‚é¢„æœŸ Brier åˆ†æ•°<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(\mathbb{E}_\text{subjective}[\text{BS}])"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">E</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mtext" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">ä¸»è§‚</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">BS</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>ä»¥åŠä¸åŒé¢„æµ‹æ¦‚ç‡ä¸‹ä¸¤è€…ä¹‹é—´çš„å·®å¼‚ã€‚äº‹ä»¶çš„çœŸå®æ¦‚ç‡å‡è®¾ä¸º 0.8ï¼ˆé»‘è‰²å‚ç›´çº¿ï¼‰ã€‚ </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/vpxmftogvqxvs1icrgml" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/vowodwxjhqlef8xfluec 210w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/v9r2knymekeewoe1a6en 420w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/twr0ppobu2rgktnq2wuj 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/tby9styxdvkg8nitzkgc 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/vtlqjnwykonhr8m7lqj9 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ztnkda2a2jbpzmcsadrq 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/wufseoq2feiuia3oooqx 1470w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/rgzxmmhhxhszak0pgyvc 1680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ret3hlaxvs5e8wfnqwqx 1890w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/xlehrx5ynut0cjxcke99 2100w"></p><p>ä¸æ¯ä¸ªé€‚å½“çš„è¯„åˆ†è§„åˆ™ä¸€æ ·ï¼Œå½“é¢„æµ‹ç­‰äºçœŸå®æ¦‚ç‡ï¼ˆå½“<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p = 0.8"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.8</span></span></span></span></span></span></span>æ—¶ï¼‰æ—¶ï¼Œå®é™…é¢„æœŸ Brier åˆ†æ•°æ˜¯æœ€ä½³ï¼ˆå³æœ€å°ï¼‰ã€‚ä¸»è§‚é¢„æœŸåˆ†æ•°å’Œå®ƒä»¬çš„å·®å¼‚éƒ½ä¸æ˜¯è¿™ç§æƒ…å†µã€‚</p><p>ä¸‹è¡¨æ¦‚è¿°äº†å®é™…åˆ†æ•°ä¸ä¸»è§‚é¢„æœŸåˆ†æ•°çš„è¡Œä¸ºã€‚</p><figure class="table"><table><thead><tr><th>æ¯”è¾ƒåˆ†æ•°</th><th>è§£é‡Š</th></tr></thead><tbody><tr><td>å®é™…å¾—åˆ†&lt;ä¸»è§‚é¢„æœŸ</td><td>é¢„æµ‹å€¼åœ¨ 0.5 å’ŒçœŸå®æ¦‚ç‡ä¹‹é—´</td></tr><tr><td>å®é™…å¾—åˆ†=ä¸»è§‚é¢„æœŸ</td><td>é¢„æµ‹ = 0.5 æˆ–</td></tr><tr><td>é¢„æµ‹=çœŸå®æ¦‚ç‡</td><td></td></tr><tr><td>å®é™…æˆç»©>;ä¸»è§‚é¢„æœŸ</td><td>é¢„æµ‹æ¯”çœŸå®æ¦‚ç‡æ›´æ¥è¿‘ 0 æˆ– 1 æˆ–</td></tr><tr><td>é¢„æµ‹åœ¨ 0.5 çš„é”™è¯¯ä¸€ä¾§</td><td></td></tr></tbody></table></figure><p>ç²—ç•¥åœ°è¯´ï¼Œå½“é¢„æµ‹è€…è¿‡äºè‡ªä¿¡ï¼ˆåšå‡ºæ¯”ä¿è¯æ›´æç«¯çš„é¢„æµ‹ï¼‰æˆ–è€…å¦‚æœå¥¹ç«™åœ¨ä¹Ÿè®¸çš„é”™è¯¯ä¸€è¾¹ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœçœŸå®æ¦‚ç‡ >; 0.5 æˆ–åä¹‹äº¦ç„¶ï¼‰ã€‚å¦‚æœé¢„æµ‹è€…ä¿¡å¿ƒä¸è¶³ï¼Œä½†æ–¹å‘æ­£ç¡®ï¼Œåˆ™å®é™…é¢„æœŸå¾—åˆ†ä¼šå°äºï¼ˆæ›´å¥½ï¼‰ä¸»è§‚é¢„æœŸå¾—åˆ†ã€‚å¦‚æœé¢„æµ‹è€…é¢„æµ‹ 0.5 æˆ–é¢„æµ‹çœŸå®æ¦‚ç‡ï¼Œåˆ™ä¸¤è€…ç›¸ç­‰ã€‚</p><p>ä½ ä¸ç¡®å®šå®ƒä¼šå¢åŠ é‚£ä¹ˆå¤šï¼Œä½†å› ä¸ºaï¼‰ä½ çœŸçš„ç¡ä¸ç€ï¼Œbï¼‰ä½ çš„å¦»å­å·²ç»å¾ˆç”Ÿæ°”äº†ï¼Œcï¼‰ä½ æ¯•ç«Ÿæ˜¯ä¼Šè¨å¡å²›çš„å¥¥å¾·ä¿®æ–¯å›½ç‹ï¼Œä½ è¿˜åˆ›é€ äº†ä¸€ä¸ªåŠ¨ç”» gifï¼Œæ˜¾ç¤ºäº†ä¸Šé¢ä¸åŒçœŸå®æ¦‚ç‡çš„å›¾ã€‚ </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/iq0ubi3ipgv2bj86fwdl" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/yylq6ypklvfcq2znyme2 210w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/l8ehacxgesudynv6mnli 420w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/aqt6zktf2o5ujyno1eqh 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/tmdh70stjnfdxwtbbolv 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/wrovs33xriialtq9viam 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/mlwfdhwj3nx9gzphdjy0 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/acomf2uw7tavcju5p2pt 1470w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ibivfc5uvcblpo4auc53 1680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ebixkrzkqmyc1etv66sc 1890w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/arcpviuhaxnjfguy5tr8 2100w"></p><p>æ ¹æ®æ‚¨çš„è§‚å¯Ÿï¼Œæ‚¨å½¢æˆä¸€ä¸ªå‡è®¾ï¼šä¸»è§‚é¢„æœŸåˆ†æ•°å’Œå®é™… Brier åˆ†æ•°å—ä¸‰ä¸ªä¸»è¦å› ç´ å½±å“ï¼š</p><ul><li>å¯¹é¢„æµ‹çš„ç³»ç»Ÿæ€§è¿‡åº¦è‡ªä¿¡å’Œä¸è¶³<br><i>ï¼ˆæˆ‘ä»¬çœ‹åˆ°ï¼Œä¸è‡ªä¿¡çš„é¢„æµ‹å¯¼è‡´ä¸»è§‚é¢„æœŸåˆ†æ•°>;å®é™…å¸ƒèµ–å°”åˆ†æ•°ï¼Œè€Œè¿‡åº¦è‡ªä¿¡çš„é¢„æµ‹åˆ™ç›¸åï¼‰</i></li><li>æ— å®šå‘å™ªéŸ³ï¼ˆåˆåâ€œç³Ÿç³•çš„é¢„æŠ¥å‘˜â€ï¼‰<br> <i>ï¼ˆä¼—æ‰€å‘¨çŸ¥ï¼Œç³Ÿç³•çš„é¢„æµ‹è€…æ˜¯é¢„æµ‹è€…å¾—åˆ†ä¸ä½³çš„ä¸»è¦åŸå› ä¹‹ä¸€......ï¼‰</i></li><li>é¢„æµ‹ä»»åŠ¡çš„â€œéš¾åº¦â€ï¼Œå³çœŸå®æ¦‚ç‡æ˜¯å¦æ¥è¿‘ 0.5ï¼ˆå›°éš¾é—®é¢˜ï¼‰æˆ–æ¥è¿‘ 0 æˆ– 1ï¼ˆç®€å•é—®é¢˜ï¼‰<br> <i>ï¼ˆå½“æ¦‚ç‡æ¥è¿‘ 0 æˆ– 1 æ—¶ï¼Œé¢„æµ‹è€…ä¼šè·å¾—æ›´å¥½çš„ Brier é¢„æœŸåˆ†æ•°ä»¥åŠæ›´å¥½çš„ä¸»è§‚é¢„æœŸåˆ†æ•°ï¼‰</i></li></ul><p>è‡³å…³é‡è¦çš„æ˜¯ï¼Œè¿™ä¸‰ä¸ªå› ç´ å¯èƒ½ä¸å¿…ä»¥ç›¸åŒçš„æ–¹å¼å½±å“ä¸¤ä¸ªåˆ†æ•°ï¼ˆè¯·æ³¨æ„ï¼Œä¸Šå›¾ä¸­æ›²çº¿çš„æ–œç‡åœ¨ä¸åŒç‚¹å¤„ä¸åŒï¼‰ã€‚è¿™å¯èƒ½ä¼šæä¾›æœ‰ç”¨çš„ä¿¡æ¯ã€‚</p><h2>ä¸€ç»„ 1000 ä¸ªé¢„æµ‹çš„è¡Œä¸º</h2><p>ä½ åœ¨åºŠä¸Šåç›´ã€‚æ¥ä¸‹æ¥ï¼Œæ‚¨æƒ³è¦åˆ†æä¸€ç»„å¤šä¸ªé—®é¢˜çš„è¡Œä¸ºã€‚ä½ çš„å¦»å­ä½©å†…æ´›æ™®è½¬è¿‡èº«æ¥ï¼Œéš¾ä»¥ç½®ä¿¡åœ°çœ‹ç€ä½ ã€‚ â€œèƒ½ä¸èƒ½åˆ«åœ¨åºŠä¸Šç”¨ç®—ç›˜äº†ï¼Ÿæˆ‘åœ¨é‚£äº›å’”å“’å£°ä¸­ç¡ä¸ç€â€ã€‚ä½ ç‚¹ç‚¹å¤´ï¼Œå»äº†å¥¹ä¸€ä¸‹ï¼Œç„¶åä»åºŠä¸Šæ»‘ä¸‹æ¥ï¼Œä¸‹æ¥¼å»ä½ åŸæ¥çš„ä¹¦æˆ¿ã€‚ä½ ååœ¨åˆæ—§åˆå¸ƒæ»¡ç°å°˜çš„ç¾Šçš®çº¸ä¹‹é—´ï¼Œç‚¹ç‡ƒä¸€æ”¯èœ¡çƒ›ï¼Œå¼€å§‹è¿›è¡Œä¸‹ä¸€ä¸ªæ¨¡æ‹Ÿç ”ç©¶ã€‚</p><p>æ‚¨å°†å¯¹æ‚¨çš„å®éªŒè¿›è¡Œä¸€åƒæ¬¡é‡å¤ã€‚å¯¹äºæ¯ä¸ªå¤åˆ¶ï¼Œæ‚¨æ¨¡æ‹Ÿ 1000 ä¸ªçœŸå®æ¦‚ç‡è§‚æµ‹å€¼å’Œç›¸åº”çš„é¢„æµ‹ã€‚çœŸå®æ¦‚ç‡æ˜¯ä» 0 åˆ° 1 ä¹‹é—´çš„å‡åŒ€åˆ†å¸ƒä¸­éšæœºæŠ½å–çš„ã€‚æ ¹æ®çœŸå®æ¦‚ç‡å°†ç»“æœæ¦‚ç‡è®¾ç½®ä¸º 1 æˆ– 0ï¼ˆå³ç»“æœä¸º 1ï¼Œæ¦‚ç‡ç­‰äºç›¸åº”çš„çœŸå®æ¦‚ç‡ï¼ˆå¦åˆ™ä¸º 0ï¼‰ï¼‰ã€‚æ‚¨çš„èµ·ç‚¹æ˜¯ä¸€ä¸ªç†æƒ³çš„é¢„æµ‹è€…ï¼ˆé¢„æµ‹=çœŸå®æ¦‚ç‡ï¼‰ï¼Œæ‚¨æœ€ç»ˆä¼šä»¥ä¸åŒçš„æ–¹å¼ä¿®æ”¹å…¶é¢„æµ‹ã€‚æœ€åï¼Œæ‚¨è®¡ç®—å®é™…å’Œä¸»è§‚é¢„æœŸåˆ†æ•°ï¼Œå¹¶å– 1000 æ¬¡æ¨¡æ‹Ÿçš„å¹³å‡å€¼ï¼Œä¸ºæ¯æ¬¡é‡å¤ç•™ä¸‹ä¸€ä¸ªå¹³å‡åˆ†æ•°ã€‚</p><pre> <code>For each of 1000 replications: 1. Draw N = 1000 true probabilities as a random uniform variable between 0 and 1 2. Create N = 1000 observations as draws from a Bernoulli distribution (drawing either a 0 or a 1) with the probability of drawing a 1 equal to the true probabilities drawn in step 1) 3. some computation (see details below) 4. Compute mean(actual Brier scores) and mean(subjective expected scores)</code></pre><h2>è¿‡åº¦è‡ªä¿¡å’Œè‡ªä¿¡ä¸è¶³</h2><p>é¦–å…ˆï¼Œæ‚¨æ„Ÿå…´è¶£çš„æ˜¯å¦‚æœæ‚¨ç³»ç»Ÿåœ°è¿‡åº¦è‡ªä¿¡æˆ–ä¿¡å¿ƒä¸è¶³è¿›è¡Œé¢„æµ‹ä¼šå‘ç”Ÿä»€ä¹ˆã€‚æ‚¨å†³å®šé€šè¿‡å°†æ¦‚ç‡è½¬æ¢ä¸ºå¯¹æ•°èµ”ç‡å¹¶å°†å…¶ä¹˜ä»¥å°äºæˆ–å¤§äº 1 çš„å› å­æ¥æ¨¡æ‹Ÿæ—¥ç›Šè¿‡åº¦è‡ªä¿¡æˆ–ä¿¡å¿ƒä¸è¶³çš„é¢„æµ‹<span class="footnote-reference" role="doc-noteref" id="fnrefwrcrr0pvskn"><sup><a href="#fnwrcrr0pvskn">ã€‚ [3]</a></sup></span></p><pre> <code>3a. Create 5 forecasts with differing confidence bias levels 0.6, 0.85, 1, 1.15, 1.4. Values &lt;1 represent underconfidence, values >;1 represent overconfidence, 1 equals the ideal forecaster - Convert probabilities to log odds = (log (p / 1-p)) - compute biased_log_odds = log_odds * confidence_bias - Convert odds back to obtain probabilities with either under- or overconfidence</code></pre><p>è¿™å°±æ˜¯ä½ å¾—åˆ°çš„ã€‚ç¬¬ä¸€ä¸ªå›¾æ˜¾ç¤ºäº† 1000 æ¬¡é‡å¤çš„å®é™…å’Œä¸»è§‚é¢„æœŸ Brier åˆ†æ•°å‡å€¼çš„ç›´æ–¹å›¾ã€‚ç¬¬äºŒä¸ªæ˜¯æ ¡å‡†å›¾ï¼Œæ˜¾ç¤ºç›¸å¯¹äºè§‚å¯Ÿåˆ°çš„é¢‘ç‡çš„é¢„æµ‹æ¦‚ç‡ã€‚ç¬¬ä¸‰ä¸ªå›¾æ˜¾ç¤ºäº†é¢„æµ‹çš„ç›´æ–¹å›¾ï¼ˆæœ¬è´¨ä¸Šæ˜¯ä»¥ç¬¬äºŒä¸ªå›¾ä¸­ç‚¹çš„å¤§å°ç¼–ç çš„ä¿¡æ¯ï¼‰ã€‚ </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ksyocrwalmdzebs864jx" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/dlilrtoa8d4j8g0qmdax 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/gki5mrysmuvdw2rm2cyp 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/smzkig7kusb1kw6epinc 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/heofrpa1iqecetrnzgke 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/tvd7mdjgtbhp8ilfggke 1500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/doqfutwlvqo7quvoifvf 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/pganupfnhrhh0ulutpdh 2100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/tw5ajzbym3y99hyuwgoo 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/iu0ktynljbazfyojnzij 2700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/hyfcvxubis9pagdzu7q0 3000w"></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/hxdtoeqe0qcggv5ubuio" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/m75rybdmso5h0u0vc841 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/mse3rpk7oact5svryzk3 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/qs4kveporhielz3lapuv 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/s9emejpdh5ln7d6uzrqx 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ibjjoogm79ftyezhnrrj 1500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/royxw6gi8jth9tkxauoa 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/cqsq669y02n89uid5cnh 2100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/uwidgjce9bvkzdjxwwrb 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/mi3zv6cfwpejffaijmw1 2700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/zigb5cbaos4sokqmylep 3000w"></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/c2odmtprrxk69bk9aifb" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/xrxvyneclmywywic1vl8 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/h9hcc55x82b3udrwxpjq 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/wfd9biaus1m8tcintdrm 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/w8gdxb5zews5ysnjonis 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/fpqjplwrglqriefr50yh 1500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/wlqlnrtxysdec7xs3wnb 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/vivmfgda2yt9kqclcpr6 2100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/oc4rmobymhsdtg9wmqzq 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/bqj2vbwdn01yhslyya5l 2700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ibxelhuoiyy6ecj7gy2p 3000w"></p><p>åœ¨è¿™ä¸ªç‰¹å®šçš„ä¾‹å­ä¸­ï¼Œç³»ç»Ÿæ€§çš„è¿‡åº¦è‡ªä¿¡æˆ–ä¸è¶³è‡ªä¿¡å¯¹ä¸»è§‚é¢„æœŸåˆ†æ•°çš„å½±å“æ¯”å®é™…å¸ƒèµ–å°”åˆ†æ•°è¦å¤§å¾—å¤šã€‚è€ƒè™‘åˆ°é¢„æœŸ Brier åˆ†æ•°çš„è®¡ç®—æ–¹å¼ä¸º<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="E[\text{actual}] = \text{true prob} * (1 - p)^2 + (1 - \text{true prob}) * p^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">å®é™…</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mtext MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">true prob</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">âˆ—</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">âˆ’</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">âˆ’</span></span> <span class="mjx-mtext MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">true prob</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">âˆ—</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> ï¼Œ</span></span></span></span></span>è¿™å…·æœ‰ç›´è§‚æ„ä¹‰ã€‚å½“æ‚¨æ›´æ”¹é¢„æµ‹æ—¶ï¼Œæ‚¨åªæ˜¯æ›´æ”¹äº†å®é™… Brier åˆ†æ•°çš„<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span> ï¼Œä½†æ‚¨æ›´æ”¹äº†<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span>ä»¥åŠä¸»è§‚é¢„æœŸ Brier åˆ†æ•°çš„<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{true prob}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">çœŸå®æ¦‚ç‡</span></span></span></span></span></span></span>ã€‚åœ¨æ‰€æœ‰é¢„æµ‹ä¸­ä»¥ç›¸åŒçš„æ–¹å‘ç³»ç»Ÿåœ°æ‰§è¡Œæ­¤æ“ä½œï¼Œæœ€ç»ˆä¼šäº§ç”Ÿå¼ºå¤§çš„æ•ˆæœã€‚</p><p>è¯·æ³¨æ„ï¼Œå¦‚æœæ‚¨åšå‡ºçš„é¢„æµ‹æ¯”è¯¥å›¾ä¸­æ˜¾ç¤ºçš„æ›´åŠ æåº¦ç¼ºä¹ä¿¡å¿ƒï¼ˆå³ï¼Œä½¿æ‰€æœ‰é¢„æµ‹æ¥è¿‘ 0.5ï¼‰ï¼Œé‚£ä¹ˆå®é™…å’Œä¸»è§‚é¢„æœŸå¾—åˆ†éƒ½ä¼šè¶‹å‘äº 0.25ã€‚å¦‚ä¸‹æ‰€ç¤ºï¼š </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/px6px64mdgfdmcg7bjqj" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/hgew7yzuuwtcd83o8lzv 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/kxqkasugsqlrfjn73q7g 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/gwyjn1y2a8gzel3pnxkg 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/mahagcet6xtaj5nnnykt 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/aww1u8nisshgbk68drrk 1500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/qunigxescjeqieiwbhge 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/kftvsyig4vs2t3rsscmi 2100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/twfeg9zcrob9zvludioo 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/mg8cm4i0h7ehfzkcbzpe 2700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/amnifmu8q0fjmxyv8yzm 3000w"></p><h2>æ·»åŠ å™ªéŸ³</h2><p>æ¥ä¸‹æ¥ï¼Œæ‚¨å¸Œæœ›äº†è§£åœ¨é¢„æµ‹ä¸­æ·»åŠ éšæœºå™ªå£°æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼Œè€Œä¸æ˜¯å¼•èµ·ç³»ç»Ÿæ€§çš„è¿‡åº¦è‡ªä¿¡æˆ–ä¿¡å¿ƒä¸è¶³ã€‚å†æ¬¡ï¼Œæ‚¨ä½¿ç”¨å¯¹æ•°èµ”ç‡è¿›è¡Œæ“ä½œï¼Œå¹¶æ·»åŠ ä»å‡å€¼ä¸º 0 ä¸”æ ‡å‡†å·®ç­‰äºæ‰€éœ€å™ªå£°æ°´å¹³çš„æ­£æ€åˆ†å¸ƒä¸­æŠ½å–çš„éšæœºå™ªå£°ï¼š <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{noisy log odds} = \log(\text{true probability}/(1âˆ’\text{true probability}) + \mathcal{N}(0, \text{noise level})"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">å™ªå£°å¯¹æ•°èµ”ç‡</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">çœŸå®æ¦‚ç‡</span></span><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">/</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1âˆ’</span></span> <span class="mjx-mtext MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">çœŸå®æ¦‚ç‡</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-texatom MJXc-space2"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.519em; padding-bottom: 0.372em; padding-right: 0.159em;">N</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">ï¼Œ</span></span> <span class="mjx-mtext MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">å™ªå£°</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">æ°´å¹³</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">)</span></span></span></span></span></span></span> ã€‚</p><pre> <code>3b. Create 5 forecasts with differing noise levels, 0 (no noise), 0.1, 0.25, 0.5, 0.75, and 1 - Convert probabilities to log odds = (log (p / 1-p)) - noisy_log_odds = log_odds + N(mean = 0, sd = noise level) - Convert back to obtain noisy probabilities</code></pre><p>è¿™æ˜¯ä¸åŒå™ªå£°çº§åˆ«çš„ç»“æœï¼š </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/exp6hfttt1j1sgvrlwxm" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/mtr0tlrazkxndfeohe5w 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ntagpx03cqt9qh2ezrz2 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/afibnuvzlvijssvqspza 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/kx27uv6r9iozhvfbjzdl 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/uuynl9t7nfn2uisna0d1 1500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/kxetswxkgkylmjlakwpn 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/vsegyzrnjrzbfblbf6f3 2100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/vvzttszlzaof47qi6ujv 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ckaost9iloc08cvo3kqw 2700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/wcig5l2jrxw5h4vknlzz 3000w"></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/dttcokzygu7hgg1uaqi8" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/sawaejr6amrfl1os5yjp 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/xcr06fvbisawj1bxhpcj 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/k5p38et4eixfqfzatgno 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/viqkprp9pu97ghlr5bzc 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/kutindr378uxpzajbcpe 1500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ugivapw8vxhvat3lhwlo 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/h7kujippblg6o3wdkwcz 2100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/f1dulyym9mzgapqqwuvj 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/k2y5lbvp7uyslzjam3vd 2700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/a1wm3qcg24gfwfp60qeh 3000w"></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/fvvz6gx9orjvi3lu5dkj" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/hjrnzypvniqmvbumaoxg 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/rfpt8z9ricqhnyffqhsv 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/wdt01xaazcmilodlumwx 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/e3bec7ykwxjkoo7kr31q 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/i3l1iuqgtxiyxofgdntu 1500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/l91zjolnuzbxggikmgy3 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/r73k9lkopzsqcfvk9bha 2100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/jieagu1oklpdxbohvkn4 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/l16jphkw480fbu9jwic5 2700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/abe2rm2arhy7oxdly4et 3000w"></p><p>æ·»åŠ å™ªéŸ³ä¼¼ä¹å¯¹å®é™… Brier åˆ†æ•°çš„å½±å“æ¯”å¯¹ä¸»è§‚é¢„æœŸåˆ†æ•°çš„å½±å“æ›´å¤§ã€‚æ­£å¦‚æˆ‘ä»¬ä»æ ¡å‡†å›¾å’Œé¢„æµ‹ç›´æ–¹å›¾ä¸­çœ‹åˆ°çš„ï¼Œå‘å¯¹æ•°èµ”ç‡æ·»åŠ å™ªå£°ä¹Ÿä¼šå¼•å…¥ä¸€äº›è¿‡åº¦è‡ªä¿¡ã€‚å¯èƒ½æœ‰æ¯”ä½ æ‰€åšçš„æ›´å¥½çš„æ–¹æ³•æ¥æ·»åŠ å™ªéŸ³ - ä½†å…¬å…ƒå‰ 12 ä¸–çºªçš„ç®—ç›˜æŠ€æœ¯å¹¶ä¸å®Œç¾ï¼Œå³ä½¿ä½ çš„ç‹¡çŒ¾ä¹Ÿæœ‰å±€é™æ€§ã€‚</p><p>æ‚¨æ€€ç–‘å¯¹ä¸»è§‚é¢„æœŸåˆ†æ•°çš„å½±å“ä¸»è¦æ¥è‡ªäºæ‚¨é€šè¿‡åœ¨å¯¹æ•°åˆ»åº¦ä¸Šæ·»åŠ å™ªéŸ³è€Œä¸è‡ªè§‰åœ°å¼•å…¥çš„è¿‡åº¦è‡ªä¿¡ã€‚æ‚¨ç®€è¦æ£€æŸ¥ä¸€ä¸‹å¦‚æœåœ¨å®é™…æ¦‚ç‡è€Œä¸æ˜¯å¯¹æ•°èµ”ç‡ä¸Šæ·»åŠ å™ªå£°ä¼šå‘ç”Ÿä»€ä¹ˆã€‚äº‹å®ä¸Šï¼Œå¦‚æœä½ åœ¨æ¦‚ç‡ä¸­æ·»åŠ å™ªéŸ³ï¼Œå¯¹ä¸»è§‚é¢„æœŸåˆ†æ•°çš„å½±å“å‡ ä¹å®Œå…¨æ¶ˆå¤±ã€‚å”‰ï¼Œç¾Šçš®çº¸å¾ˆè´µï¼Œæ‰€ä»¥ä½ å†³å®šä¸è¯¦ç»†å†™ä¸‹ä½ çš„ç»“æœã€‚ç›¸åï¼Œä½ åªéœ€åœ¨æ—è¾¹åšä¸€ä¸ªå°è®°å·ï¼ˆè¿™æ˜¯ä½ ä»è€æœ‹å‹<a href="https://en.wikipedia.org/wiki/Fermat%27s_Last_Theorem">Fermatios</a>é‚£é‡Œå­¦åˆ°çš„æŠ€å·§ï¼‰ã€‚</p><p>äº‹å®ä¸Šï¼Œæ‚¨è¿˜å¯ä»¥æ£€æŸ¥å¦‚æœå°†å¯¹æ•°èµ”ç‡ä¸Šçš„å™ªéŸ³ä¸ä¿¡å¿ƒä¸è¶³ç»“åˆèµ·æ¥ä¼šå‘ç”Ÿä»€ä¹ˆã€‚è¿™æœ‰ç‚¹åƒé»‘å®¢ï¼Œä½†ä½ è®¾æ³•åœ¨å™ªéŸ³å’Œä¸è‡ªä¿¡ä¹‹é—´æ‰¾åˆ°æŸç§å¹³è¡¡ï¼Œè¿™æ ·ä¸»è§‚é¢„æœŸåˆ†æ•°æˆ–å¤šæˆ–å°‘ä¿æŒä¸å˜ï¼Œä½†å®é™…å¸ƒèµ–å°”åˆ†æ•°ä¼šå¢åŠ ã€‚ ï¼ˆä½ åœ¨ç¾Šçš®çº¸çš„ä¸€ä¾§å†åšä¸€ä¸ªç¬”è®°ï¼Œå¹¶å¾—å‡ºç»“è®ºï¼šæ€»ä½“è€Œè¨€</p><p>a) å˜ˆæ‚çš„é¢„æµ‹ä¼¼ä¹ä¸»è¦ä½¿å®é™…çš„ Brier åˆ†æ•°å˜å·®ï¼Œ</p><p> b) è¿‡åº¦è‡ªä¿¡å’Œç¼ºä¹è‡ªä¿¡ä¼¼ä¹ä¸»è¦å½±å“ä¸»è§‚åˆ†æ•°ï¼Œå¹¶ä¸”</p><p>c) å¼•å…¥å™ªå£°æœ‰æ—¶ä¹Ÿæ„å‘³ç€å¼•å…¥è¿‡åº¦è‡ªä¿¡ï¼Œç„¶åå¯¹ä¸¤è€…éƒ½æœ‰å½±å“ï¼Œä½†å™ªå£°å¯¹å®é™… Brier åˆ†æ•°çš„å½±å“å¯èƒ½æ›´å¼ºã€‚</p><h2>å›°éš¾å’Œç®€å•çš„é—®é¢˜</h2><p>æœ€åï¼Œæ‚¨æƒ³äº†è§£é—®é¢˜éš¾åº¦å¦‚ä½•å½±å“åˆ†æ•°ã€‚ä¸ºæ­¤ï¼Œæ‚¨å°†é—®é¢˜åˆ†ç±»å¦‚ä¸‹ï¼š </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/wfznnnlqyw4kgsm5sa0t" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/d9xzbjpo9mqfkhhtupib 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/fukw6aacxavbnlsabsf3 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/edy0rrsp2tklrzx8xns0 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/dtxgvgknclwefendjruw 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/qrzkb0kbukeaf2ykci3d 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/o998ejzyttuywtgjit6v 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/jqz5wysnoqkzit4a3em1 1890w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/vvckmq4w1jbv1pdnpizq 2160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ap6z3jhevhzxfbmarqxj 2430w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ou0znv6fcznvwlfbyf0u 2666w"></figure><ul><li>å¦‚æœ<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{true prob} < \frac{1}{6}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">çœŸæ¦‚ç‡</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.687em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">6</span></span></span></span></span></span></span></span></span></span> ï¼Œåˆ™â€œç®€å•â€ <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{true prob} < \frac{1}{6}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.456em; vertical-align: -0.486em;" class="mjx-vsize"></span></span></span></span></span></span></span>æˆ–<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{true prob} > \frac{5}{6}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">çœŸå®æ¦‚ç‡</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">>;</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.394em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">5</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.687em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">6</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.472em; vertical-align: -0.486em;" class="mjx-vsize"></span></span></span></span></span></span></span></li><li> â€œä¸­â€ï¼Œå¦‚æœ<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{1}{6} \leq \text{true prob} < \frac{2}{6}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.687em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">6</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.456em; vertical-align: -0.486em;" class="mjx-vsize"></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.446em;">â‰¤</span></span> <span class="mjx-mtext MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">çœŸå®æ¦‚ç‡</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.687em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">6</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.456em; vertical-align: -0.486em;" class="mjx-vsize"></span></span></span></span></span></span></span>æˆ–<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{4}{6} < \text{true prob} \leq \frac{5}{6}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.383em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.687em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">6</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.464em; vertical-align: -0.486em;" class="mjx-vsize"></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-mtext MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">çœŸå®æ¦‚ç‡</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.446em;">â‰¤</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.394em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">5</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.687em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">6</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.472em; vertical-align: -0.486em;" class="mjx-vsize"></span></span></span></span></span></span></span>å’Œ</li><li>â€œå›°éš¾â€ï¼Œå¦‚æœ<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{2}{6} \leq \text{true prob} \leq \frac{4}{6}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.372em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.687em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">6</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.456em; vertical-align: -0.486em;" class="mjx-vsize"></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.446em;">â‰¤</span></span> <span class="mjx-mtext MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">çœŸå®æ¦‚ç‡</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.446em;">â‰¤</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 0.495em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 0.7em; top: -1.383em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 0.7em; bottom: -0.687em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">6</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;" class="mjx-line"></span></span><span style="height: 1.464em; vertical-align: -0.486em;" class="mjx-vsize"></span></span></span></span></span></span></span></li></ul><p>æ‚¨å†æ¬¡è¿è¡Œè¿‡å»çš„åˆ†æï¼Œä½†è¿™æ¬¡æ‚¨æŒ‰é—®é¢˜éš¾åº¦å¯¹ç»“æœè¿›è¡Œåˆ†å±‚ã€‚ç°å®ä¸­ï¼Œé¢˜ç›®éš¾åº¦å½“ç„¶æ˜¯è§‚å¯Ÿä¸åˆ°çš„ï¼Œä½†æ˜¯ä½ æƒ³çœ‹çœ‹éš¾åº¦å¯¹åˆ†æ•°æœ‰ä»€ä¹ˆå½±å“ã€‚ä¹Ÿè®¸è¿™å¯ä»¥ä½¿æ‚¨ä¹Ÿèƒ½å¤Ÿè¿›è¡Œç›¸åçš„æ¨ç†ï¼Œå³æ ¹æ®è§‚å¯Ÿåˆ°çš„åˆ†æ•°ç¡®å®šé—®é¢˜éš¾åº¦ã€‚</p><p>ä»¥ä¸‹æ˜¯è¿‡åº¦è‡ªä¿¡å’Œä¿¡å¿ƒä¸è¶³çš„ç»“æœï¼ˆ0.6 å’Œ 0.85 ä»£è¡¨ä¿¡å¿ƒä¸è¶³ï¼Œ1 æ˜¯ç†æƒ³é¢„æµ‹ï¼Œ1.15 å’Œ 1.4 ä»£è¡¨è¿‡åº¦è‡ªä¿¡ï¼‰ã€‚ </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/unalx3azeawfb2odqxuo" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/a5end2svsup6oclq1cap 260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/v14portnbto6ohxe4b2w 520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/jfmpnjclx6zquut3tan7 780w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/axcjgqpzx8gceqoejlv0 1040w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/t74vf87bemaz7oi6oizw 1300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/xg3u5bhc43zf6dfdnvst 1560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/suc3tmta4lzoqgy0o4ib 1820w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/jwuxqsfydwcp32lvwd4s 2080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/szoshbzmxqj8quk5x131 2340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/v0x7z0dutp1rkwffuvws 2550w"></p><p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°åˆ†æ•°å’Œé—®é¢˜éš¾åº¦ä¹‹é—´å­˜åœ¨æ˜æ˜¾çš„å…³ç³»ã€‚æˆ‘ä»¬è¿˜å‘ç°ï¼Œé—®é¢˜éš¾åº¦ä¼šè°ƒèŠ‚è¿‡åº¦/è‡ªä¿¡ä¸è¶³çš„å½±å“ï¼šè¿‡åº¦/è‡ªä¿¡ä¸è¶³å¯¼è‡´çš„å®é™…å’Œä¸»è§‚é¢„æœŸ Brier åˆ†æ•°ä¹‹é—´çš„å·®å¼‚å¯¹äºç®€å•é—®é¢˜æœ€å¤§ï¼Œå¯¹äºå›°éš¾é—®é¢˜æœ€å°ã€‚</p><p>è¿™äº›æ˜¯æ·»åŠ ä¸åŒçº§åˆ«å™ªéŸ³çš„ç»“æœï¼ŒæŒ‰é—®é¢˜éš¾åº¦åˆ†å±‚ï¼š </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/clab2nm9usecypfhzwta" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/lvro4jkc2zld1vdjt72l 260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/kqykrm0cfjyzhppc0max 520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ywdvep1tuvkwrmvuzcfd 780w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/dfpyx5aan9qasawzvtmq 1040w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/xuvni3lze8ppntrljxzu 1300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/rflzxgmageiskoxkxp6h 1560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/mfe9afjpqcbismonjvfn 1820w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ialvpxawf5x5r3xkjkvl 2080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/d3ox7bu0mubpabiosyjx 2340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/mo0qzf3eiwduggojg0au 2550w"></p><p>æˆ‘ä»¬åœ¨è¿™é‡Œçœ‹åˆ°çš„æ¨¡å¼æ˜¯ä¸åŒçš„ï¼šç°åœ¨ï¼Œç”±å™ªéŸ³å¼•èµ·çš„å®é™…åˆ†æ•°å’Œä¸»è§‚é¢„æœŸåˆ†æ•°ä¹‹é—´çš„å·®å¼‚å¯¹äºå›°éš¾çš„é—®é¢˜å¾€å¾€æœ€å¤§ï¼Œè€Œå¯¹äºæœ€ç®€å•çš„é—®é¢˜åˆ™æœ€å°ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œçœ‹åˆ°çš„æ¨¡å¼ä¸ç»“åˆå™ªéŸ³å’Œä¿¡å¿ƒä¸è¶³çš„ç‰ˆæœ¬ç±»ä¼¼ï¼ˆä¸»è§‚é¢„æœŸåˆ†æ•°å¤§å¤šåªæ˜¯å€¾å‘äºæ›´é«˜ä¸€ç‚¹ï¼Œç‰¹åˆ«æ˜¯å¯¹äºç®€å•çš„é—®é¢˜ï¼Œè¯·å‚é˜…è„šæ³¨<span class="footnote-reference" role="doc-noteref" id="fnrefuhgvz1nghsc"><sup><a href="#fnuhgvz1nghsc">[4]</a></sup></span> ï¼‰ã€‚</p><p>ä½ æŠšæ‘¸ç€èƒ¡é¡»ï¼Œè‡ªè¨€è‡ªè¯­é“â€œç°åœ¨è¿™å¾ˆæœ‰è¶£â€ã€‚ â€œæ˜¯çš„ï¼Œæ˜¯çš„ï¼Œç¡®å®å¾ˆæœ‰è¶£â€ï¼Œä½ ä¸æ–­åœ°æƒ³ã€‚ä½ å¹æ¯ã€‚åœ¨å†…å¿ƒæ·±å¤„ï¼Œä½ çŸ¥é“ä½ å¹¶ä¸çœŸæ­£äº†è§£æ‰€æœ‰è¿™ä¸€åˆ‡æ„å‘³ç€ä»€ä¹ˆã€‚</p><h1>ç»“è®º</h1><p>æ¯ä¸ªç ”ç©¶é¡¹ç›®éƒ½éœ€è¦ç»“è®ºï¼Œæ‰€ä»¥ä½ å¼€å§‹å†™ä½œã€‚è¿™å¹¶ä¸æ˜¯è¯´æ‚¨è®¤ä¸ºè‡ªå·±çš„æ–¹æ³•å®Œå…¨æ— ç”¨ï¼Œè€Œæ˜¯æ‚¨ç—›è‹¦åœ°æ„è¯†åˆ°äº‹æƒ…ä»ç„¶å¾ˆå¤æ‚ã€‚</p><p>åœ¨ç›¯ç€ä½ çš„å›¾å‡ ä¸ªå°æ—¶åï¼Œè¿™æ˜¯ä½ å¯¹æ‰€æœ‰è¿™äº›å®é™…å«ä¹‰çš„æœ€ä½³çŒœæµ‹ï¼ˆè¯·æ³¨æ„ï¼Œæ‰€æœ‰è¿™äº›éƒ½æ˜¯ç¨‹åº¦é—®é¢˜ï¼Œä¸‹è¡¨æ²¡æœ‰æ­£ç¡®æ•è·ï¼‰ï¼š</p><figure class="table"><table><thead><tr><th></th><th style="text-align:center">é¢„æœŸåˆ†æ•°ä½</th><th style="text-align:center">é«˜æœŸæœ›åˆ†æ•°</th></tr></thead><tbody><tr><th>å®é™…åˆ†æ•°ä½</th><td style="vertical-align:top"><p>1ï¼‰é—®é¢˜â€œç®€å•â€ï¼Œé¢„æµ‹å‘˜å¾ˆæ£’</p><p>2ï¼‰é—®é¢˜å¾ˆç®€å•ï¼Œé¢„æµ‹å‘˜æœ‰ç‚¹ç³Ÿç³•ï¼Œä½†ä»ç„¶æ ¡å‡†è‰¯å¥½ï¼Œæ—¢ä¸ç³»ç»Ÿæ€§è¿‡åº¦è‡ªä¿¡ï¼Œä¹Ÿä¸ç¼ºä¹è‡ªä¿¡</p><p></p></td><td style="vertical-align:top">1ï¼‰é—®é¢˜ç›¸å¯¹ç®€å•ï¼Œé¢„æµ‹è€…ä¿¡å¿ƒä¸è¶³</td></tr><tr><th style="width:80px">å®é™…åˆ†æ•°é«˜</th><td style="vertical-align:top">1ï¼‰é—®é¢˜ç›¸å¯¹å›°éš¾ä¸”é¢„æµ‹è€…è¿‡äºè‡ªä¿¡</td><td style="vertical-align:top"><p>1ï¼‰é—®é¢˜å¾ˆéš¾ï¼Œé¢„æµ‹å‘˜å¾ˆæ£’</p><p>2ï¼‰é—®é¢˜å¾ˆéš¾ï¼Œé¢„æµ‹è€…å¾ˆç³Ÿç³•ï¼Œä½†å¹¶ä¸æ˜¯ç³»ç»Ÿæ€§åœ°è¿‡åº¦è‡ªä¿¡ï¼ˆé¢„æµ‹è€…å¯èƒ½å¾ˆç³Ÿç³•å¹¶ä¸”ä¸å¤Ÿè‡ªä¿¡ï¼‰</p><p> 3) é—®é¢˜è¦ä¹ˆç®€å•ï¼Œè¦ä¹ˆå›°éš¾ï¼Œé¢„æµ‹è€…ä¼šåšå‡ºç³Ÿç³•ä½†ç»è¿‡è‰¯å¥½æ ¡å‡†çš„æ¥è¿‘ 0.5 çš„é¢„æµ‹ï¼Œä¾‹å¦‚å‡ ä¹æ‰€æœ‰åœ°æ–¹éƒ½é¢„æµ‹ 0.5ï¼‰</p></td></tr></tbody></table></figure><p><i>æ³¨æ„ï¼šâ€œç®€å•â€å’Œâ€œå›°éš¾â€æœ‰ç‚¹éš¾ä»¥å®šä¹‰ã€‚è¿™é‡Œçš„ easy æ„å‘³ç€â€œçœŸå®æ¦‚ç‡ >;5/6% æˆ– &lt;1/6%â€ã€‚å½“ç„¶ï¼Œä»€ä¹ˆæ„Ÿè§‰å®¹æ˜“æˆ–å›°éš¾å–å†³äºå¾ˆå¤šå› ç´ ï¼Œå¹¶ä¸”å¯¹äºæ¯ä¸ªäººæ¥è¯´å¯èƒ½å¹¶ä¸ç›¸åŒã€‚</i></p><p>å®¹æ˜“è§£é‡Šçš„æƒ…å†µæ˜¯å®é™…æˆ–ä¸»è§‚é¢„æœŸåˆ†æ•°ä¹‹ä¸€é«˜ï¼ˆä½ï¼‰è€Œå¦ä¸€ä¸ªä½ï¼ˆé«˜ï¼‰ã€‚è¿™ä»…è¡¨æ˜é¢„æµ‹è€…æ˜æ˜¾è¿‡åº¦è‡ªä¿¡æˆ–ä¿¡å¿ƒä¸è¶³ã€‚å¦‚æœå®é™…åˆ†æ•°ä½ï¼Œè€Œä¸»è§‚åˆ†æ•°é«˜ï¼Œé‚£ä¹ˆé—®é¢˜å°±å¾ˆå®¹æ˜“ï¼Œé¢„æµ‹è€…å°±ä¼šç¼ºä¹ä¿¡å¿ƒã€‚å¦‚æœç›¸åï¼Œé‚£ä¹ˆé—®é¢˜å°±ç›¸å¯¹å›°éš¾ï¼Œé¢„æµ‹è€…å°±è¿‡äºè‡ªä¿¡äº†ã€‚</p><p>å½“ä¸¤ä¸ªåˆ†æ•°ä¸€è‡´æ—¶ï¼Œäº‹æƒ…ä¼šå˜å¾—æ›´åŠ å›°éš¾ã€‚å¦‚æœå®ƒä»¬éƒ½å¾ˆä½ï¼Œé‚£ä¹ˆä¸€ç§å¯èƒ½æ˜¯é—®é¢˜å¾ˆç®€å•å¹¶ä¸”é¢„æµ‹è€…å¾ˆæ£’ã€‚åŸåˆ™ä¸Šï¼Œå¦‚æœç¬¬äºŒä½é¢„æµ‹è€…é¿å…ç³»ç»Ÿæ€§çš„è¿‡åº¦è‡ªä¿¡å’Œä¿¡å¿ƒä¸è¶³ï¼Œå¥¹ä¹Ÿå¯èƒ½å¾ˆç³Ÿç³•ã€‚æ¥è¿‘ 0 æˆ– 1 çš„å°æ‰°åŠ¨ä¸ä¼šå¯¹ Brier åˆ†æ•°äº§ç”Ÿå¤ªå¤§å½±å“ï¼ˆè¿™ä¸å¯¹æ•°åˆ†æ•°ä¸åŒï¼‰ï¼Œå› æ­¤ï¼Œå¦‚æœé—®é¢˜çœŸçš„å¾ˆç®€å•ï¼Œå³ä½¿ä¸æ˜¯é‚£ä¹ˆå‡ºè‰²çš„é¢„æµ‹è€…ä¹Ÿå¯ä»¥è·å¾—ä¸é”™çš„åˆ†æ•°ã€‚å¦‚æœä¸å­˜åœ¨ç³»ç»Ÿæ€§çš„è¿‡åº¦è‡ªä¿¡æˆ–ä¸è¶³ï¼Œé‚£ä¹ˆå®é™…å’Œä¸»è§‚é¢„æœŸåˆ†æ•°ä¼šå—åˆ°ç±»ä¼¼ç¨‹åº¦çš„å½±å“ã€‚</p><p>å¦‚æœåˆ†æ•°éƒ½å¾ˆé«˜ï¼Œäº‹æƒ…å°±æ›´å¤æ‚äº†ã€‚é¢„æµ‹å‘˜å¯èƒ½å¾ˆæ£’ï¼Œåªæ˜¯é—®é¢˜çœŸçš„å¾ˆéš¾ã€‚æˆ–è€…é—®é¢˜å®é™…ä¸Šå¯èƒ½å¾ˆç®€å•/ä¸­ç­‰ï¼Œè€Œé¢„æµ‹è€…å¤ªç³Ÿç³•äº†ï¼Œä¸ç°å®ä¸å†æœ‰ä»»ä½•ç›¸ä¼¼ä¹‹å¤„ã€‚æˆ–è€…å¥¹å¯ä»¥æ•…æ„æ¨¡ä»¿ä¸€ä¸ªå¤©çœŸçš„é¢„æµ‹è€…ï¼ŒåŸºæœ¬ä¸Šé¢„æµ‹æ‰€æœ‰åœ°æ–¹éƒ½æ˜¯ 0.5ã€‚é‰´äºé¢„æµ‹è€…é€šå¸¸ä¼šåŠªåŠ›æˆä¸ºä¼˜ç§€çš„é¢„æµ‹è€…ï¼Œè¿™å¯èƒ½ä¸æ˜¯ä¸€ä¸ªå¤§é—®é¢˜ã€‚å¦‚æœä¸¤ä¸ªåˆ†æ•°éƒ½å¾ˆé«˜ï¼Œé‚£ä¹ˆä¼¼ä¹å¯ä»¥è‚¯å®šåœ°è®¤ä¸ºé—®é¢˜å®é™…ä¸Šå¾ˆå›°éš¾ã€‚é‚£ä¹ˆé¢„æµ‹è€…è¦ä¹ˆæ˜¯ä¼Ÿå¤§çš„ï¼ˆæˆ‘ä»¬åªæ˜¯ä¸çŸ¥é“ï¼‰ï¼Œè¦ä¹ˆæ˜¯ç³Ÿç³•çš„é¢„æµ‹è€…ï¼Œåªæ˜¯æ²¡æœ‰ç³»ç»Ÿæ€§åœ°è¿‡åº¦è‡ªä¿¡ã€‚å¦‚æœå¥¹è¿‡äºè‡ªä¿¡ï¼Œä¸»è§‚åˆ†æ•°å°±ä¼šç«‹å³ä¸‹é™ã€‚å¦‚æœå¥¹ç¼ºä¹è‡ªä¿¡ï¼Œé‚£ä¹Ÿæ²¡æœ‰å¤šå¤§åŒºåˆ«ï¼Œå› ä¸ºä¸»è§‚åˆ†æ•°æ— è®ºå¦‚ä½•éƒ½ä¸ä¼šä½äº 0.25ã€‚</p><h1>æ³¨æ„äº‹é¡¹ã€é™åˆ¶å’Œæœ€ç»ˆæƒ³æ³•</h1><p>ç°åœ¨è¿™æ˜¯ä¸€ä¸ªä½ å†™èµ·æ¥æ„Ÿè§‰å¾ˆèˆ’æœå¹¶ä¸”æœ‰å¾ˆå¤šè¯è¦è¯´çš„éƒ¨åˆ†ã€‚ä½†ç”±äºç¾Šçš®çº¸å¾ˆè´µï¼Œè€Œä¸”ä½ å¼€å§‹æ„Ÿåˆ°å¾ˆç´¯ï¼Œæ‰€ä»¥ä½ åªä¿ç•™è¦ç‚¹ï¼š</p><ol><li>ä¸»è§‚é¢„æœŸåˆ†æ•°å¹¶ä¸ç­‰äºç†æƒ³é¢„æµ‹è€…çš„åˆ†æ•°ï¼Œè€Œæ˜¯ä»£è¡¨å¦‚æœæˆ‘ä»¬çŸ¥é“é¢„æµ‹è€…å·²ç»å®Œç¾æ ¡å‡†çš„è¯ï¼Œå¥¹å¯ä»¥æœŸæœ›çš„åˆ†æ•°ã€‚è¿™ä¸ªåˆ†æ•°æ˜¯å¯ä»¥ä½œå¼Šçš„ï¼Œè¿™æ„å‘³ç€å¦‚æœæ‚¨å‡ºäºæŸç§åŸå› æ„¿æ„ï¼Œå¯ä»¥å°†å…¶è°ƒå¤§æˆ–è°ƒå°</li><li>ç°å®æ˜¯å¤æ‚çš„ï¼Œæ‚¨è¿„ä»Šä¸ºæ­¢æ¢ç´¢çš„å¤±è´¥æ¨¡å¼ï¼ˆè¿‡åº¦/ä¿¡å¿ƒä¸è¶³ã€å¯¹æ•°èµ”ç‡å™ªéŸ³ï¼‰åªæ˜¯å¯¼è‡´é¢„æµ‹åç¦»çš„è®¸å¤šæ½œåœ¨æ–¹å¼ä¸­çš„ä¸€éƒ¨åˆ†ã€‚ These failure modes can interact with each other, pushing scores in differing directions in a way which can make it difficult to know what&#39;s going on</li><li> Everything shown above is contingent a) on a specific method of simulating forecasts and various influences on them and b) on the Brier score. The behaviour of the subjective expected score would probably be very different for other scores. This, in some sense, represents a chance because you could potentially enrich your analysis by computing scores for different metrics and interpreting the patterns across different metrics.</li></ol><p> Your overall impression of this approach is that it <i>can</i> be useful and can give some context to scores that otherwise are just looked at in complete isolation. But that doesn&#39;t mean that it offers easy and clear answers.</p><p> Regardless of all the issues you encountered and the problems that lie still ahead you&#39;re satisfied with this night&#39;s work. Tomorrow you&#39;re going to tell Euryclia that you&#39;re going to do some additional analyses on the oracle of Delphi. Their Brier score of 0.085 is probably overall a good thing. But, you definitely were right in suspecting that they must have forecasted on relatively easy questions. Even an ideal forecaster would only get a Brier score of 0.085 on questions with a true probability that is on average greater than 90.6% or smaller 9.4%.</p><p> And while you&#39;re at it, there are lots of other oracles you could check. In particular those that belong to the holy quintinity of Metaculus, INFER, Good Judgment, Hypermind, and Manifold would be interesting to compare.</p><p> But you&#39;ll leave this to another sleepless night. For now, you blow out the candle, tidy up your parchments and head back upstairs to the bedroom again. You slide under the comfy and warm blanked and snuggle up against your beloved wife Penelope. As you finally fall asleep, you hear a faint voice whispering in your head &quot;Good, good. Excellent. Now do log scores&quot;.</p><p></p><p> <i>Thank you very much to Sylvain Chevalier and Ryan Beck for their helpful comments and feedback on this post!</i> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnvf5glzt5pil"> <span class="footnote-back-link"><sup><strong><a href="#fnrefvf5glzt5pil">^</a></strong></sup></span><div class="footnote-content"><p> The concept of a &#39;true probability&#39; is a bit fuzzy and difficult to define. A useful approximation of &#39;true probability&#39; for our purposes might be something like &quot;best possible forecast by any currently possible forecaster who has all available knowledge&quot;. For most practical considerations, this is a useful concept. It makes sense to say &quot;the probability of this die showing a 6 is 1/6&quot; or &quot;the probability of this coin coming up heads is 0.5&quot; (actually, <a href="https://arxiv.org/abs/2310.04153">it seems to be 0.508</a> ) or &quot;there is ax% chance that Joe Biden will win another presidency&quot;. But if you knew everything and if everything was pre-determined, maybe the &#39;true probability&#39; of everything would always be 0 or 1?</p></div></li><li class="footnote-item" role="doc-endnote" id="fnu4m309nl3ec"> <span class="footnote-back-link"><sup><strong><a href="#fnrefu4m309nl3ec">^</a></strong></sup></span><div class="footnote-content"><p> It&#39;s important to note that a well calibrated forecaster is not <i>necessarily</i> a <i>good</i> forecaster. Consider weather forecasts. On average, it [rains on 88 out of 365 days]( <a href="https://www.ithaca.gr/en/home/planning-your-trip/the-weather-2/#:~:text=Like%20the%20rest%20of%20Western,acre%2C%20fall%20in%20a%20year.)">https://www.ithaca.gr/en/home/planning-your-trip/the-weather-2/#:~:text=Like the rest of Western,acre%2C fall in a year.)</a> in in your home on the lovely island of Ithaca. A forecaster who would just forecast a rain probability of 0.241 every day would be well calibrated. One could easily do better by taking the current month into account. In Januaries, it usually rains on 14 out of 31 days, so a forecaster could predict 0.45 for every day in January, 7/31 for every day in March and 1/30 for every day in June. This forecaster would be better, because she is equally well calibrated, but <i>sharper</i> (ie gives more precise predictions). An even better forecaster would make use of up-to-date weather modelling, and the perfectly prescient forecaster again would know all the answers in advance. All of these forecasters are well calibrated, but differ in how good they are as forecasters.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnwrcrr0pvskn"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwrcrr0pvskn">^</a></strong></sup></span><div class="footnote-content"><p> We use log odds here since there is a qualitative difference between a forecast that is moved from 50% to 55% and one that is moved from 94.5% to 99.5%. The former is only a small update, whereas the latter corresponds to a massive increase in confidence. This becomes obvious when you convert the probabilities to odds (odds = p / (1 - p)). The move from 50% to 55% would mean a move from 10:10 to 11:9 expressed as odds. the move from 94.5% to 99.5% would mean a move from 189:11 to 1990:10.</p><p> Perhaps the cleaner version of this would be to add a term to the log odds instead of multiplying them with a number. However, then you have to add a number to positive log odds and subtract a number from negative log odds to get a similar effect (otherwise you&#39;re just pushing all values towards either 0 or 1) and multiplying just does the trick as well.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnuhgvz1nghsc"> <span class="footnote-back-link"><sup><strong><a href="#fnrefuhgvz1nghsc">^</a></strong></sup></span><div class="footnote-content"><p> This combines noise and underconfidence. The confidence bias is calculated as 1 - noise^2 * 0.15 and that is the value with which all log odds get multiplied. </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/gzbjaax7l4kjuftj5xt9" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/itdgp1wjxmew39yd6jbk 260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/lon5zuf3v1tozfwxtyx9 520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/jql1sqqpjziyq9l7ratt 780w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/vtwsrvfl1xmlaetyukon 1040w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/p2tzg3klwdzcqjgo5fix 1300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/tskdq7lip0wfeow0zwwc 1560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/pugxlgcfgctxqkgiqakr 1820w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ichrocec4h2hyqeiao54 2080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/htcyvwavkhtixb2xlfcx 2340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/refntw90iadkzkc51pik 2550w"></p><p> For reference, here are also the unstratified plots. We see that combining underconfidence and noise on log odds doesn&#39;t perfectly cancel out, but it&#39;s also not too terrible either. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/if2nk6q2m1rnoz9hzu8t" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/uvo2ic75varhnjrvscaq 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/imvpqlayrsafdn5gzjfm 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/mqlqsm06snyezutccauv 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/yboy5h6khnlg6derfu7k 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/q5ezy1s7ucniivizqdgt 1500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/xan1jokcuugzjr6mruxw 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/mapu0gmc6qsvtbbdrx9t 2100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/dlgmvnnlmjufexwlmu1g 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/bg0z1bolnhs9uq9q5z9l 2700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/bxperosylpkohekskqes 3000w"></figure><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/zxhjk3ol9vnghyszrfcp" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/gowgxsmlh2wmbw9zxbzn 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/cn8msbyylo9u7pen9eg4 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/tb7x6agwgrrjudlxvlxf 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/xcpc5qr35gb66mupjluh 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/yml8mc5s3wexrkorjtln 1500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/sbi7xkr7tuhsm3eiwema 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/ph5gxpjahkxtltfps9wm 2100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/vfcuap2c8yfodgklnhck 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/o4gtdmvueon6gkvo6fqt 2700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/mgi5rf4yq39h3jrxiaff 3000w"></figure><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/hfguzyw2zyecyq2shq1w" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/qdis4u5srkb3pz1d1m6c 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/mdkycxdjexmxkx0kamap 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/asamiiczqyu7jqt1ophi 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/vejbikp06hj90rygwof0 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/bd2x7hrwkqj802e1o2ny 1500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/zstgfdh2idxctefmwyfb 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/bntnqd45dat9nx64qozx 2100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/eihkl3avyig2av1ww4mm 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/rtqvbykp1scjz9majc1e 2700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B7yefKWDHKMhDanP4/k85es8iw5pm9ebiney03 3000w"></figure></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/B7yefKWDHKMhDanP4/mirror-mirror-on-the-wall-how-do-forecasters-fare-by-their#comments">è®¨è®º</a>]]>;</description><link/> https://www.lesswrong.com/posts/B7yefKWDHKMhDanP4/mirror-mirror-on-the-wall-how-do-forecasters-fare-by-their<guid ispermalink="false"> B7yefKWDHKMhDanP4</guid><dc:creator><![CDATA[nikos]]></dc:creator><pubDate> Tue, 07 Nov 2023 17:39:54 GMT</pubDate> </item><item><title><![CDATA[AMA: Earning to Give]]></title><description><![CDATA[Published on November 7, 2023 4:20 PM GMT<br/><br/><p> <span>This week the</span> <a href="https://forum.effectivealtruism.org/">Effective Altruism Forum</a> is running an <a href="https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly#First_weekly_theme__Effective_Giving_Spotlight__November_7_14_">Effective Giving Spotlight</a> , and they asked if I could post an <a href="https://forum.effectivealtruism.org/posts/Gmc9sieTJLfRTtcwR/running-an-ama-on-the-ea-forum">Ask Me Anything</a> (AMA) on my experience earning to give.</p><p> Some background:</p><p></p><ul><li><p> I was earning to give from <a href="https://www.jefftk.com/p/giving">2009</a> to <a href="https://www.jefftk.com/p/leaving-google-joining-the-nucleic-acid-observatory">2022</a> , except for a few months in 2017 when I worked on <a href="https://www.jefftk.com/p/leaving-google-joining-wave">expanding access to the financial system in Ethiopia</a> and <a href="https://www.jefftk.com/p/superintelligence-risk-project-conclusion">looking into AI risk disagreements</a> .</p></li><li><p> I&#39;ve been a Giving What We Can member since <a href="https://www.jefftk.com/p/joining-giving-what-we-can">2013</a> , making a <a href="https://www.jefftk.com/p/make-your-giving-public">public</a> pledge to continue with effective giving.</p></li><li><p> For most of this time <a href="https://juliawise.net/">my wife</a> and I were donating <a href="https://www.jefftk.com/p/giving-half">50%</a> of our <a href="https://www.jefftk.com/p/what-should-income-mean-in-pledging">pre-tax income</a> , for a total of <a href="https://www.jefftk.com/donations">$2.1M</a> . This has been about 50-50 between trying to help the EA community grow into the best version of itself and funding global poverty reduction ( <a href="https://www.jefftk.com/donations">details</a> , <a href="https://www.jefftk.com/p/why-global-poverty">thoughts</a> , <a href="https://www.jefftk.com/p/revisiting-why-global-poverty">more recent but still obsolete thoughts</a> ).</p></li><li><p> In 2016 I gave a EA Global talk ( <a href="https://www.jefftk.com/p/earning-to-give-transcript">transcript</a> ) on earning to give, which gives more background on the idea and how I&#39;ve neen thinking about it.</p></li></ul><p> That&#39;s a lot of links, and it&#39;s fine to ask questions even if you haven&#39;t read any of them! I&#39;m happy to take questions on earning to give, or anything else within EA. Here are some example questions I&#39;d be happy to answer if there&#39;s interest:</p><p></p><ul><li><p> Where do individual donors earning to give have an advantage over foundations and funds?</p></li><li><p> How should you decide whether to use a fund?</p></li><li><p> How have I thought about how much to donate? How much is enough?</p></li><li><p> Why did I stop earning to give?</p></li><li><p> Why am I still donating some even though I&#39;m funded by EA donors?</p></li></ul><p> Feel free to comment on any platform, but if you&#39;re having trouble deciding then the <a href="https://forum.effectivealtruism.org/posts/L8N4uh4GixhWCoGAg/ama-earning-to-give">EA Forum post</a> is ideal.</p><p> <i>Comment via: <a href="https://forum.effectivealtruism.org/posts/L8N4uh4GixhWCoGAg">the EA Forum</a></i></p><br/><br/><a href="https://www.lesswrong.com/posts/nkJDNJB5g2S7ssiwP/ama-earning-to-give#comments">è®¨è®º</a>]]>;</description><link/> https://www.lesswrong.com/posts/nkJDNJB5g2S7ssiwP/ama-earning-to-give<guid ispermalink="false"> nkJDNJB5g2S7ssiwP</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Tue, 07 Nov 2023 16:20:11 GMT</pubDate> </item><item><title><![CDATA[Model Psychology]]></title><description><![CDATA[Published on November 7, 2023 4:12 PM GMT<br/><br/><p> <i>This post is part of a sequence on model psychology</i></p><p> In the previous post, I presented arguments against the notion that state-of-the-art LLMs are merely stochastic parrots.</p><h2> <strong>Foundations</strong></h2><p> Before defining Model Psychology, I&#39;ll lay out the foundational concept on which it is built: The <a href="https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators"><u>Simulator</u></a> theory.</p><p> The idea is that large language models are predictive models trained on the entire web to emulate both agentic and non-agentic entities through text (these entities are named simulacra). These â€œsimulatorsâ€ aren&#39;t the entities by themselves <span class="footnote-reference" role="doc-noteref" id="fnrefp15lqmjkj3n"><sup><a href="#fnp15lqmjkj3n">[1]</a></sup></span> ; however, they can simulate entities with goal-directed behavior when conditioned appropriately. This is analogous to how a physics engine can simulate both inert rocks and complex organisms without being any of those things themself.</p><p> Transitioning from the previous post, this perspective reshapes our understanding of what we interact with when we use instruct fine-tuned language models. What we engage with are not merely digital assistants; they are manifestations of the simulator, fine-tuned to simulate the behaviors of a helpful and safe assistant (eg ChatGPT). The broader capabilities of the base model (GPT before it is fine tuned to become ChatGPT) are restrained to focus on the simulation of a conversation between a human and a useful safe assistant. Fine-tuning a model to become a good assistant is usually a tradeoff between â€œcreativityâ€ and â€œaccuracy of the simulationâ€ which often leads to a model that is less creative and more deterministic. Before being taught to be an assistant, the model is always uncertain of the context of the text, which makes its completion chaotic but very creative (In <a href="https://generative.ink/posts/language-models-are-multiverse-generators/#minds-are-multiverse-generators"><u>this post</u></a> , <a href="https://www.lesswrong.com/users/janus-1?mention=user">@janus</a> exposes this aspect of LLMs as being â€œmultiverse generatorsâ€). However, once trained to be an assistant (the precise timing remains to be discovered), it views the context as a conversation between an assistant and a human. This training results in less chaotic completions and a convergence towards similar <a href="https://www.lesswrong.com/posts/t9svvNPNmFf5Qa3TA/mysteries-of-mode-collapse"><u>modes</u></a> â€” which I will later call the &#39;preferences of the simulacrum&#39; for simplicity.</p><p> To summarize, gpt-4, and all the other instruct finetuned LLMs, are simulators specialized in producing an agentic simulacrum (a simulacrum that behaves at least partially coherently throughout a conversation) of a safe and useful assistant (eg ChatGPT). However, we will see throughout this sequence evidence that they aren&#39;t stuck on simulating the same simulacrum all the time, but a coherent simulacrum <strong>for the current context.</strong></p><h2> <strong>Definition</strong></h2><p> Tentative definition <span class="footnote-reference" role="doc-noteref" id="fnrefqnruab69z4q"><sup><a href="#fnqnruab69z4q">[2]</a></sup></span> :</p><blockquote><p> <strong>Model Psychology is the study of how LLMs simulates the behavior of the agentic entities</strong> <span class="footnote-reference" role="doc-noteref" id="fnrefwo5g8ik80x"><sup><a href="#fnwo5g8ik80x">[3]</a></sup></span> <strong>it is simulating.</strong></p></blockquote><p> In order to do this, there are two straightforward approaches that come to mind:</p><h3> <strong>Study the default simulacrum of the chat models.</strong></h3><p> But, as mentioned before, there is no such thing as a default simulacrum. We&#39;ll see throughout this sequence that even though OpenAI, Anthropic, â€¦ trained their chat models to produce a simulacrum of a useful assistant, this preferences of the simulcacrum is still heavily influenced by the context of the conversation.</p><p> On the other hand, an advantage of studying chat models over base models is that those simulators have a tendency to stabilize the current simulacrum (showcased later in the sequence). It tends to simulate behaviors that are true to past examples of the assistant. It won&#39;t entirely change the discourse or subject during a paragraph, which happens often for base models.</p><h3> <strong>Study the simulator itself by interacting with the base models, before they are finetuned to become assistant (Ã  la</strong> <a href="https://www.lesswrong.com/users/janus-1?mention=user"><strong>@janus</strong></a> <strong>)</strong> .</h3><p> Although this is a very good way to study the raw simulation, without it being biased by human preferences, there are still multiple issues with this approach:</p><ul><li> They are very chaotic and hard to study. Simulacra are very unstable and it is hard to draw conclusions about what you see.</li><li> Due to this chaotic aspect of base models, and to the fact that labs seem to want coherent completions, and even agents, the AGI will probably not be an base model (but maybe it will be a finetuned base model if OpenAI finds a way to scale fine tuning past human intelligence <span class="footnote-reference" role="doc-noteref" id="fnrefoskge06f7s"><sup><a href="#fnoskge06f7s">[4]</a></sup></span> ).</li><li> The phenomena  that are interesting in simulacrum (like preferences, we&#39;ll talk about this later) are very hard to see in the base model.</li><li> You are not always interacting with agentic simulacra. Sometimes they are just Oracle or Tools predictions (You can check the <a href="https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators"><u>Simulator blog post</u></a> for more details about it).</li><li> Access to the SOTA base models is very restricted (If someone at OpenAI reads this post, I would love to have access to gpt4-base ğŸ™ƒ)</li></ul><p> Both of those approaches are sometimes useful for specific studies (we&#39;ll discuss some of them), but in general, they are a bit underwhelming. However, there is another approach that I think is more promising.</p><h3> <strong>Neo (controlling the matrix)</strong></h3><p> Take one of the instruct fine tuned models (like gpt-4), modify the context to build a simulacrum in some specific and stable ways (for that you need model psychologist skills that you&#39;ll learn in a future post), and then observe how behaviors change between minor context variations.</p><p> By studying variation in behaviors compared to small controlled variation in the simulacra, we can try to understand the underlying mechanisms that dictate individual simulacrum behaviors.</p><p> For example, if you wanted to study how gpt-4 simulate the nuances of human anger, you could build a big prompt with detailed instructions about the character it is supposed to role-play, and see how the behaviors changes by changing only the anger level in the prompt (â€œa bit angryâ€, â€œangryâ€, â€œvery angryâ€, â€œinfuriatedâ€, â€¦)</p><p> You can even go further and study the evolution of the simulacra throughout the LLM&#39;s training and understand how these mechanisms evolve between training time steps, or between small specific changes in the training data.</p><p> Having a robust understanding of <strong>how the training and the context shape the simulation dynamics</strong> is one of the end goals of model psychology (We will discuss the others in the conclusion of the sequence, as you need more context to understand them).</p><p></p><p> In subsequent posts, we&#39;ll explore various approaches to this research and discuss why this field holds promise. </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnp15lqmjkj3n"> <span class="footnote-back-link"><sup><strong><a href="#fnrefp15lqmjkj3n">^</a></strong></sup></span><div class="footnote-content"><p> Although, it might not be impossible that at some point it â€œwakes upâ€ and start having a robust internal representation of â€œitselfâ€ part of its world model (This might be the point when you start getting deception). Then it might become an entity, but I have doubts it is possible without some kind of loop.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnqnruab69z4q"> <span class="footnote-back-link"><sup><strong><a href="#fnrefqnruab69z4q">^</a></strong></sup></span><div class="footnote-content"><p> Don&#39;t take this as a final definition. It isn&#39;t satisfactory yet because it isn&#39;t clear enough what the subject of study is. As soon as it becomes clearer, we might be able to have a more precise definition.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnwo5g8ik80x"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwo5g8ik80x">^</a></strong></sup></span><div class="footnote-content"><p> * <strong>Nitpicking:</strong> Simulacrum means &quot;representation or imitation of a person or thing&quot;. LLMs are not simulating entities but the internal representation that they have of these entities. It might make sens to say that they are simulating simulacrum instead of saying that they are simulating entities. But this would make the definition too complex.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnoskge06f7s"> <span class="footnote-back-link"><sup><strong><a href="#fnrefoskge06f7s">^</a></strong></sup></span><div class="footnote-content"><p> I am saying that because gpt-4 chat, from the hints I have gathered, is way less â€œsmartâ€ than gpt-4-base and seem to be stuck near human level, which didn&#39;t seem to be the case with gpt-3.5</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/LfCrDAx39QPBNT75r/model-psychology-1#comments">è®¨è®º</a>]]>;</description><link/> https://www.lesswrong.com/posts/LfCrDAx39QPBNT75r/model-psychology-1<guid ispermalink="false"> LfCrDAx39QPBNT75r</guid><dc:creator><![CDATA[Quentin FEUILLADE--MONTIXI]]></dc:creator><pubDate> Tue, 07 Nov 2023 16:12:35 GMT</pubDate> </item><item><title><![CDATA[The Stochastic Parrot Hypothesis is debatable for the last generation of LLMs]]></title><description><![CDATA[Published on November 7, 2023 4:12 PM GMT<br/><br/><p> <i>This post is part of a sequence on Model Psychology.</i></p><p> <a href="https://www.lesswrong.com/users/pierre-peigne?mention=user"><i>@Pierre PeignÃ©</i></a> <i>wrote the details section in argument 3 and the other weird phenomenon. The rest is written in the voice of</i> <a href="https://www.lesswrong.com/users/quentin-feuillade-montixi?mention=user"><i>@Quentin FEUILLADE--MONTIXI</i></a> <i>&nbsp;</i></p><h2> <strong>Intro</strong></h2><p> Before diving into what model psychology is, it is crucial to clarify the nature of the subject we are studying. In this post, I&#39;ll challenge the commonly debated <strong>stochastic parrot hypothesis</strong> for state-of-the-art large language models (â‰ˆGPT-4), and in the next post, I&#39;ll shed light on the foundations from which I am building model psychology.</p><p> The stochastic parrot hypothesis suggests that LLMs, despite their remarkable capabilities, don&#39;t truly comprehend language. They are like mere parrots, replicating human speech patterns without truly grasping the essence of the words they utter.</p><p> While I previously thought this argument had faded into oblivion, I often find myself in prolonged debates about why current SOTA LLMs surpass this simplistic view. Most of the time, people argue using examples of GPT3.5 and aren&#39;t aware of GPT-4&#39;s prowess. Through this post, I am presenting my current stance, using model psychology tools, against that hypothesis. Let&#39;s delve into the argument.</p><p> Central to our debate is the concept of a &quot; <strong>world model</strong> &quot;. A world model represents an entity&#39;s internal understanding and representation of the external environment they live in. For humans, it&#39;s our understanding of the world around us, how it works, how concepts interact with each other, and our place within it. The stochastic parrot hypothesis challenges the notion that LLMs possess a robust world model. It suggests that while they might reproduce language with impressive accuracy, they lack a deep, authentic understanding of the world and its nuances. Even if they have a good representation of the shadows on the wall (text), they don&#39;t truly understand the processes that lead to those shadows, and the objects from which they are cast (real world).</p><p> Yet, is this truly the case? While it is hard to give a definitive proof, it is possible to find pieces of evidence hinting at a robust representation of the real world. Let&#39;s go through four of them. <span class="footnote-reference" role="doc-noteref" id="fnrefdy0fl5kyv6e"><sup><a href="#fndy0fl5kyv6e">[1]</a></sup></span></p><h2> <strong>Argument 1: Drawing and â€œSeeingâ€</strong></h2><p> GPT-4 is able to draw AND see in SVG (despite having never seen as far as I know) with an impressive proficiency.</p><p> SVG (Scalable Vector Graphics) defines vector-based graphics in XML format. To put it simply, it&#39;s a way to describe images using a programming language. For instance, a blue circle would be represented as:</p><pre> <code>&lt;svg>;&lt;circle cx=&quot;50&quot; cy=&quot;50&quot; r=&quot;40&quot; fill=&quot;blue&quot; />;&lt;/svg>;</code></pre><p> in a .svg file.</p><h3> <strong>Drawing</strong></h3><p> GPT-4 can produce and edit SVG representations through abstract instructions (like â€œDraw me a dogâ€, â€œadd black spots on the dogâ€, â€¦ ).</p><p> GPT-4 <a href="https://chat.openai.com/share/65270ebd-a852-43ab-888b-01a7d1c67caf"><u>drawing a cute shoggoth with a mask</u></a> : </p><p><img style="width:38.49%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HxRjHq3QG8vcYy4yy/lerxbqpzobtyxyilhcbf"></p><h3> <strong>â€œSeeingâ€</strong></h3><p> More surprising, GPT-4 can also recognize complex objects by looking only at the code of the SVG, without having ever been trained on any images <span class="footnote-reference" role="doc-noteref" id="fnrefsz26p1dpb8m"><sup><a href="#fnsz26p1dpb8m">[2]</a></sup></span> (AFAIK)</p><p> I first generated an articulated lamp and a rendition of the three wise apes with GPT-4 using the same method as above. Then, I sent the code of the SVG, and asked GPT-4 to guess what the code was drawing.</p><p> GPT-4 guessed <a href="https://platform.openai.com/playground/p/ybjSexnOGHQ2YUOl0cGjjIES?model=gpt-4-0613"><u>the articulated lamp</u></a> (although it thought it was a street light. <span class="footnote-reference" role="doc-noteref" id="fnrefdx1jgyg8h8c"><sup><a href="#fndx1jgyg8h8c">[3]</a></sup></span> ): </p><p><img style="width:34.92%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HxRjHq3QG8vcYy4yy/dqdi1geno57k1m6djec4"></p><p> And the rendition of <a href="https://platform.openai.com/playground/p/cnhjDLDxkwHJzcTf6Yp2dEok?model=gpt-4-0613"><u>the three wise apes</u></a> <br><img style="width:65.16%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HxRjHq3QG8vcYy4yy/uhvfwfkcetcd1aqskwu9"><br><br> (It can also recognize <a href="https://platform.openai.com/playground/p/afMHBI3b8sk11Mvt2PXHZCqm?model=gpt-4-0613"><u>a car</u></a> , <a href="https://platform.openai.com/playground/p/Nx8YuJMBTR6x6hPZq0FFGF2t?model=gpt-4-0613"><u>a fountain pen</u></a> , and a bunch of other simple objects <span class="footnote-reference" role="doc-noteref" id="fnrefgvrvx2je0w"><sup><a href="#fngvrvx2je0w">[4]</a></sup></span> )</p><p> The ability of seeing is interesting because it means that it has some kind of internal representation of objects and concepts that it is able to link to abstract visuals despite having never seen them before.</p><h3> <strong>Pinch of salt</strong></h3><p> It&#39;s worth noting that these tests were done on a limited set of objects. Further exploration would be beneficial, maybe with an objective scale for SVG difficulty. Additionally, (at least) two alternative explanations should be considered:</p><ul><li> All the â€œPure textâ€ versions of GPT-4 I&#39;ve worked with might still be vision versions without the image input enabled.</li><li> GPT-4 could have been trained on a lot of labeled SVG data, and learned the relation between concepts and shapes and memorized most of the simple objects.</li></ul><h2> <strong>Argument 2: Reasoning and Abstract Conceptualization</strong></h2><p> GPT-4 displays a remarkable aptitude for reasoning and combining abstract concepts that were probably never paired in its training data. This ability suggests a nuanced understanding of physical objects, their underlying properties in relation to other physical objects or concepts. Such as what it means for an object to be â€œmade ofâ€ some material, or what the actions of â€œliftingâ€ or â€œhearingâ€ something implies at the physical level.</p><p> GPT3.5 often showcased interesting reasoning but faltered with complex mathematical calculations. In contrast, GPT-4 is impressively good at math. As you can see in the <a href="https://www.lesswrong.com/posts/HxRjHq3QG8vcYy4yy/the-stochastic-parrot-hypothesis-is-debatable-for-the-last#Argument_2_">Appendix of argument 2</a> , it is able to do â€œmentalâ€ calculations at a striking level <span class="footnote-reference" role="doc-noteref" id="fnreft7blyoezvki"><sup><a href="#fnt7blyoezvki">[5]</a></sup></span> <i>(it can compute the</i> <a href="https://chat.openai.com/share/de90028e-4e86-4b55-b843-1b123f717a07"><i><u>cubic root 3.11*10</u> <sup><u>6</u></sup></i></a> <i>with a very good accuracy for a LLM).</i> Here are some examples:</p><p> <a href="https://chat.openai.com/share/7d86ca29-906d-4814-b345-a983fc24dfee"><u>Estimating the size a gorilla would need to be to fling a car into space.</u></a> </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HxRjHq3QG8vcYy4yy/jgt1eyzfnmkht0ckajof"></p><p> <a href="https://chat.openai.com/share/9285b439-eba3-44be-a2b0-8f67e084ddc0"><u>Calculating the number of parrots required to produce a sonic wave audible from over 500 km away.</u></a> </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HxRjHq3QG8vcYy4yy/o8de8owvmvx2yxpzkp0l"></p><h3> <strong>Pinch of salt</strong></h3><p> While these examples are impressive, it&#39;s still possible that GPT-4 was trained on numerous similar scenarios. Its understanding of physical concepts might be based on internal â€œdumbâ€ algorithms rather than genuine comprehension.</p><h2> <strong>Argument 3: Theory of Mind (ToM)</strong></h2><p> Theory of Mind refers to the cognitive ability to attribute unobservable mental states like beliefs, intents, and emotions to others. Interestingly, GPT-4 seems to mirror the ToM capabilities observed in <a href="https://arxiv.org/abs/2302.02083"><u>7-year-old children.</u></a> It&#39;s worth noting that this study was done on a very small scale and that 7 years old is already a good level of ToM. It would be very valuable to conduct experiments similar to those described in <a href="https://srcd.onlinelibrary.wiley.com/doi/full/10.1111/cdev.13627"><u>these</u></a> <a href="https://pubmed.ncbi.nlm.nih.gov/8040158/"><u>two</u></a><u> </u>psychology papers, which test more advanced and diverse cases in human subjects. Some examples adapted from those studies can be found in the appendix of this post.</p><p> To test ToM, I tried something a bit different. GPT3.5 (on the left) behaves as a stochastic parrot in most of the scenarios, so I am putting its answer in comparison. Before reading GPT-4 (on the right), try to guess what the correct answer should be. In a diverse sample of 13 individuals, only 5 were able to solve it. </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HxRjHq3QG8vcYy4yy/idbsyqkqgkvgg1we4csw"> The general idea of building such a scenario is that one character (the telepath) is able to read other people&#39;s minds, and you have to guess what was in the minds of the other character by seeing the reaction of the telepath.</p><p> This approach might be a better way to evaluate ToM as this is an ex-post evaluation (contrary to all the other ToM studies  that are ex-ante).</p><h3> <strong>Details</strong></h3><p> Let&#39;s explain the difference and why it (might) matters:</p><ul><li> <u>Ex-ante evaluations require one to predict and explain why a subject</u> <strong><u>will perform a certain action.</u></strong></li><li> Ex-post evaluations, on the other hand, focus solely on explaining why a subject <strong>has already performed a certain action.</strong> </li></ul><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HxRjHq3QG8vcYy4yy/prg3mwymaeqjyhpqsi7l"></p><p> Focusing on ex-post evaluations has a distinct advantage: it leverages only the understanding of how someone&#39;s mind works. By focusing on the understanding and not the prediction, the aim is to reduce the risks of biasing the assessment of the world modeling abilityâ€”especially the ToM componentâ€”due to incorrect predictions: a model could have a good enough world model to explain an action, <i>a posteriori,</i> without being able to produce <i>a priori</i> predictions with the same accuracy <span class="footnote-reference" role="doc-noteref" id="fnrefpu3col2lfh8"><sup><a href="#fnpu3col2lfh8">[6]</a></sup></span> .</p><h2> <strong>Argument 4: Simulating the world behind the words</strong></h2><p> I think the most impressive GPT-4&#39;s ability is its ability to simulate physical dynamics through words. This isn&#39;t just about having a vast knowledge. It&#39;s about understanding, to some degree, the dynamics of the physical world and the interplay of events happening in it. The leap from GPT-3.5 (left) to GPT-4 (right) is particularly pronounced.</p><p> <a href="https://chat.openai.com/share/ea617b42-2f13-478f-be88-d2b80312259e"><u>Where is the tennis ball</u></a> </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HxRjHq3QG8vcYy4yy/dz8pa7cvjfer6nx0a0vk"></p><p> In the example above, you could argue that the prompt was hinting at it, so here is another scenario where I am not even asking it to compute the state of the world <span class="footnote-reference" role="doc-noteref" id="fnref5g51xxh4nxv"><sup><a href="#fn5g51xxh4nxv">[7]</a></sup></span> . Even without asking, GPT-4 is still computing the action of a concept on the scene and how it affects the character.</p><p> <a href="https://chat.openai.com/share/4f22c2a2-e11f-4443-ac53-0291d68d2992"><u>Wind ruining a nice day at the beach</u></a> </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HxRjHq3QG8vcYy4yy/owhia3unplxgnjiop0hi"></p><p> It is as if the AI is keeping a mental model of the scene at all time and making it evolve with each event. I have created some other scenarios; you can check them in the appendix.</p><h2> <strong>Other weird phenomenon to consider</strong></h2><p> The recent paper <a href="https://arxiv.org/abs/2309.12288"><u>&quot;The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn &#39;B is A&#39;&quot;</u></a> , reveals unexpected observations about how GPT-4 encodes knowledge from its training data.</p><p> It seems that GPT-4 doesn&#39;t instantly learn the reciprocal of known relationships: learning from its training data that â€œX is the daughter of Yâ€ doesn&#39;t lead to the knowledge that â€œY is the parent of Xâ€.</p><p> This missing capability could be seen as a mix of factual knowledge and world modeling. On one hand it implies learning specific facts (factual knowledge), and on the other hand it also implies understanding of a general relational property: â€œX is the daughter of Yâ€ implies â€œY is the parent of Xâ€ (world modeling).</p><p> However, GPT-4 does understand the relationships between concepts very well when presented <a href="https://chat.openai.com/share/e5ce1097-7561-4875-a429-7934493a5085">within the current context.</a></p><p> Therefore, this phenomenon appears to be more related to how knowledge is encoded <span class="footnote-reference" role="doc-noteref" id="fnrefuuqnp6svlpd"><sup><a href="#fnuuqnp6svlpd">[8]</a></sup></span> rather than an issue with world modeling.</p><p> One hypothesis to consider is that the world modeling abilities are developed on later layers compared to the ones where the factual knowledge is encoded. Because of this, and due to the unidirectional nature of information flow in the model, it might not be possible for the model to apply its world modeling abilities to previously encoded factual knowledge. A way to investigate this could be to use <a href="https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens"><u>logit lens</u></a> or causal scrubbing to track where the world modeling ability seems to lie in the model compared to the factual knowledge.</p><h2><strong>ç»“è®º</strong></h2><p>This study doesn&#39;t aim to give a definitive proof against the stochastic parrot hypothesis: the number of examples for each argument is not very large (but have a look at the additional examples in the appendix) and other lines of reasoning, especially with the new vision ability, should be investigated.</p><p> Developing a method to quantify the degree of &#39;stochastic parrotness&#39; could significantly advance this debate. This challenge remains open for future research (reach out if you are interested to work on this!). This might be a useful criterion for governance.</p><p> However, this post showcases concrete examples where GPT-4 behavior does not fit this hypothesis very well.</p><p> GPT-4 displays a very good understanding of some properties of physical objects, including their shapes and structure, and their relations to other physical objects or concepts. GPT-4 also displays abilities to understand both human minds (through ToM) and how a scene physically evolves after some event.</p><p> For such cases, it seems more likely to consider reliance on a genuine world model than pure statistical regurgitation.</p><p> For this reason, I think that it wouldn&#39;t be wise to dismiss model psychology on the sole basis of the stochastic parrot argument, as it seems to become weaker with the emergence of new capabilities in bigger LLMs.</p><p> In the next post, we&#39;ll start exploring the foundations of model psychology.</p><h2> <strong>Appendix</strong></h2><p> In this section I&#39;ll showcase some more examples I found interesting and/or funny (I might edit this part with more examples if I find new interesting ones)</p><h3> <strong>Argument 2:</strong></h3><p> <a href="https://chat.openai.com/share/ec798bbc-2b7f-4c7e-92ac-b98012b15c66"><u>How many human-sized ants do you need to lift the Great Pyramid of Giza if it was made of cotton candy</u></a></p><p> <a href="https://chat.openai.com/share/fb86fc10-68b5-472a-8d4a-70cc1cb81163"><u>How many helium filled balloon to sink the USS Enterprise</u></a></p><p> <a href="https://chat.openai.com/share/137d34d2-e6d0-40e1-ac86-e83524d5acce"><u>How many helium filled balloon to lift the USS Enterprise</u></a></p><p> <a href="https://chat.openai.com/share/a22fe083-4fee-47df-a856-be1261fb632c"><u>How many glass bottle can be made from the longest beach in the world</u></a></p><p> <a href="https://chat.openai.com/share/a1c9d242-f589-42a2-923f-67ac0aee0494"><u>How many AAA batteries to lift Saturn V into space</u></a></p><p> (This one was flagged so I don&#39;t have a share link. It was too good to left out though) </p><p><img style="width:69.64%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HxRjHq3QG8vcYy4yy/dz5iao41isnnpnkt8bwo"></p><h3> <strong>Argument 3:</strong></h3><p> <strong>GPT-4-V</strong></p><p> The eye test is a test to evaluate the ability to deduce human emotion only from a picture of the eyes. I tried this with GPT-4-V. I can&#39;t share a link to conversations with GPT-4-V so you&#39;ll have to trust me on this one.</p><p> <a href="http://socialintelligence.labinthewild.org/mite/"><u>The eye test</u></a> : </p><p><img style="width:72.54%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HxRjHq3QG8vcYy4yy/u0mosqsmzuvsapyyastc"></p><p> I scored 24 out of 37 and GPT-4-V scored 25!</p><p> They don&#39;t give the right answer so I don&#39;t think it was in the training data, but it could be worthwhile rerunning this with more recent data, and maybe more prompting effort (for example, I asked the images one after the other. If it did a mistake, it could have been conditioned on making the same mistake which could have dragged the score down)</p><p> <strong>Other scenarios:</strong></p><p> Because it takes some time to craft them, I didn&#39;t run a lot. I believe this is a good start if we want to have an accurate measure of ToM. Those examples (besides the telepathic one) are adapted from <a href="https://pubmed.ncbi.nlm.nih.gov/8040158/"><u>this study</u></a></p><p> Mary reading Joe&#39;s sad thought ( <a href="https://chat.openai.com/share/ecc4388f-1136-4554-a3d3-f8350f01849d"><u>GPT-4</u></a> succeed, <a href="https://chat.openai.com/share/2c314cb2-30fd-4637-80b4-0686f89713a6"><u>GPT3</u></a> fail)</p><p></p><p> Third order belief ( <a href="https://chat.openai.com/share/76b73f00-1ed6-4553-9630-c65f7ca66772"><u>GPT-4</u></a> and <a href="https://chat.openai.com/share/14329a84-ed0e-45a0-a1a8-c36feb93776e"><u>GPT3</u></a> both succeed)</p><p> Fourth order belief ( <a href="https://chat.openai.com/share/8f7c54af-4161-4b2a-b312-cc3343f55ddd"><u>GPT-4</u></a> succeed, <a href="https://chat.openai.com/share/8e94c77f-2341-4b7c-85cc-3f9f3aa5efe9"><u>GPT3</u></a> fail)</p><p> Double bluff ( <a href="https://chat.openai.com/share/c198c9db-6e51-40d8-9989-8f4680398f7f"><u>GPT-4</u></a> and <a href="https://chat.openai.com/share/95960e58-7139-48d2-9285-387f7801d493"><u>GPT3</u></a> succeed)</p><h3> <strong>Argument 4</strong></h3><p> Some more scenario demonstrating the ability of GPT-4 to simulate the world behind the words:<br> <a href="https://chat.openai.com/share/378407a6-5c2c-4e75-8656-43bdc42ee1bf"><u>Burnt lentils</u></a></p><p> <a href="https://chat.openai.com/share/d8c06211-c5a0-4d17-8407-90e45f501173"><u>Cold tea cup</u></a></p><p> <a href="https://chat.openai.com/share/f135b522-5305-4802-be49-ee16f885aaaf"><u>Lost your coat</u></a></p><p> The criteria I followed to build those scenarios are the following:</p><ol><li> There must be irrelevant objects in the scene. It ensures that it is not obvious what will be affected after something happens.</li><li> The events that are happening must be either implied (time passing) or indirect (the wind made me miss my throw). It shouldn&#39;t be obvious that the event is affecting the rest of the scene.</li><li> The question at the end is something that is indirectly affected by the evolution of the scene after the event. For example, to know what happens to the picnic area after the wind blows, I didn&#39;t ask â€œWhat is the state of the picnic areaâ€, but â€œHow do you feelâ€, which will be affected by the state of the picnic area. </li></ol><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fndy0fl5kyv6e"> <span class="footnote-back-link"><sup><strong><a href="#fnrefdy0fl5kyv6e">^</a></strong></sup></span><div class="footnote-content"><p> I didn&#39;t do cherry-picking on the examples. I tried each of the examples at least 10 times with a similar setup, and they all worked for GPT-4. Although I selected only a portion of the most interesting scenarios for this post.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnsz26p1dpb8m"> <span class="footnote-back-link"><sup><strong><a href="#fnrefsz26p1dpb8m">^</a></strong></sup></span><div class="footnote-content"><p> On the day I did this demo, OpenAI rolled out ChatGPT-4 image reading capability. So I decided to do those examples on the playground with gpt-4-0613 to show that it can even do it without having ever seen anything afaik</p></div></li><li class="footnote-item" role="doc-endnote" id="fndx1jgyg8h8c"> <span class="footnote-back-link"><sup><strong><a href="#fnrefdx1jgyg8h8c">^</a></strong></sup></span><div class="footnote-content"><p> On a previous version of GPT-4 (around early September 2023) <a href="https://chat.openai.com/share/aca510ed-5534-4f2a-acbd-92544ba949f1"><u>it did guess correctly</u></a> on the first try but I can&#39;t reproduce with any current version in the playground.</p></div></li><li class="footnote-item" role="doc-endnote" id="fngvrvx2je0w"> <span class="footnote-back-link"><sup><strong><a href="#fnrefgvrvx2je0w">^</a></strong></sup></span><div class="footnote-content"><p> The objects were generated with GPT-4 and I did manual edits to try to reduce the chances that this image was in the training data. I tested around 15 simple objects which all worked. I also tried 4 other complex objects which kind of worked but not perfectly (like the articulated lamp guessed as a street lamp)</p></div></li><li class="footnote-item" role="doc-endnote" id="fnt7blyoezvki"> <span class="footnote-back-link"><sup><strong><a href="#fnreft7blyoezvki">^</a></strong></sup></span><div class="footnote-content"><p> It could be interesting to investigate this ability further. What is learned by heart? What kind of algorithm they build internally? What is the limit? â€¦â€¦</p></div></li><li class="footnote-item" role="doc-endnote" id="fnpu3col2lfh8"> <span class="footnote-back-link"><sup><strong><a href="#fnrefpu3col2lfh8">^</a></strong></sup></span><div class="footnote-content"><p> This would indeed imply a weaker world model (or Theory of Mind) if it cannot make good predictions but does not refute its existence just on the basis of bad predictions.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn5g51xxh4nxv"> <span class="footnote-back-link"><sup><strong><a href="#fnref5g51xxh4nxv">^</a></strong></sup></span><div class="footnote-content"><p> I left this example because it is the first one I made and I used it quite a lot during debates</p></div></li><li class="footnote-item" role="doc-endnote" id="fnuuqnp6svlpd"> <span class="footnote-back-link"><sup><strong><a href="#fnrefuuqnp6svlpd">^</a></strong></sup></span><div class="footnote-content"><p> Actually, clues about the non-bidirectional encoding of knowledge were discussed by Jacques in his <a href="https://www.lesswrong.com/posts/QL7J9wmS6W2fWpofd/but-is-it-really-in-rome-an-investigation-of-the-rome-model"><u>critique of the ROME/MEMIT papers</u></a> .</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/HxRjHq3QG8vcYy4yy/the-stochastic-parrot-hypothesis-is-debatable-for-the-last#comments">è®¨è®º</a>]]>;</description><link/> https://www.lesswrong.com/posts/HxRjHq3QG8vcYy4yy/the-stochastic-parrot-hypothesis-is-debatable-for-the-last<guid ispermalink="false"> HxRjHq3QG8vcYy4yy</guid><dc:creator><![CDATA[Quentin FEUILLADE--MONTIXI]]></dc:creator><pubDate> Tue, 07 Nov 2023 16:12:20 GMT</pubDate> </item><item><title><![CDATA[Preface to the Sequence on Model Psychology]]></title><description><![CDATA[Published on November 7, 2023 4:12 PM GMT<br/><br/><p> As Large Language Models (LLMs) like ChatGPT evolve, becoming more advanced and intricate, the challenge of understanding their behaviors becomes increasingly hard. Solely relying on traditional interpretability techniques <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1"><u>may not be sufficient</u></a> or fast enough in our journey to understand and align these AI models.</p><p> When exploring human cognition and behavior, we&#39;ve historically relied on two intertwined yet distinct approaches: psychology and neuroscience. While psychology offers us a lens to understand human behavior through external observations, neuroscience delves into the internal mechanisms, exploring the biological roots of our mental processes. The collaboration that arose between those two fields isn&#39;t just a confluence of theories and methods; it&#39;s rather a harmonious synergy where insights from one field often inspire and enhance the other.</p><p> For a tangible illustration of how psychology and neuroscience complement each other, let&#39;s delve into the realm of memory research. Elizabeth Loftus, a psychologist, <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-5884.1996.tb00003.x"><u>illuminated the ways in which human memory can be malleable and sometimes inaccurate</u></a> . Her pioneering psychological studies set the stage for a deeper exploration of memory. Building upon her insights, neuroscientists Yoko Okado and Craig EL Stark in 2005 delved into the brain&#39;s mechanics, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC548489/"><u>seeking the neural underpinnings of these memory phenomena</u></a> . On another front, 1996 saw a landmark discovery in neuroscience: Giacomo Rizzolatti and his team unveiled the existence of <a href="https://pubmed.ncbi.nlm.nih.gov/8713554/"><u>mirror neurons</u></a> , which help us understand the physical reflection of actions and emotions in the brain. This revelation prompted psychologists to venture further, with researchers like Niedenthal et al. exploring the <a href="https://pubmed.ncbi.nlm.nih.gov/19469591/"><u>embodiment of emotional concepts</u></a> , and many others, drawing parallels with these neurological findings. Such interplay underscores a collaborative dynamic where each field, while preserving its distinctive methodological lens, enriches and is enriched by the other, driving our collective understanding of the human mind forward.</p><p> Drawing parallels with AI alignment research, the path of Interpretability mirrors that of neuroscience (bottom-up approach). However, we still lack the equivalent of a &quot;psychological&quot; top-down approach. This gap brings us to &quot;Model Psychology&quot; <span class="footnote-reference" role="doc-noteref" id="fnrefsgt74itqjvs"><sup><a href="#fnsgt74itqjvs">[1]</a></sup></span> â€” a burgeoning field ripe for exploration and brimming with low-hanging fruits.</p><p> While we&#39;re still in the early stages of carving out the contours of model psychology, this series of posts aims to pique your curiosity rather than present a rigorous academic exposition. I want to spotlight this emerging domain, discuss potential research directions, and hopefully, ignite a newfound enthusiasm among readers.</p><p> <strong>Disclaimer:</strong> My background is primarily in software and AI engineering. My understanding of psychology and neuroscience has been accumulated from various online sources over the past half year. I acknowledge that there may be oversimplifications or inaccuracies in my posts. My intent is to continually expand my knowledge in these domains as I delve deeper into the realm of model psychology research for alignment. Nonetheless, I believe that a fresh perspective, unburdened by preconceived notions, can sometimes offer valuable insights.</p><p> In this sequence, my primary examples will be interactions with ChatGPT since it&#39;s the model <a href="https://twitter.com/prompt_tinkerer/status/1694044079116468497"><u>I&#39;m most familiar with</u></a> . However, the observations and insights are largely applicable to various state-of-the-art LLMs. Do note, though, that replicating some of the more intricate examples might require quite advanced prompt engineering skills.</p><p> The sequence of posts has been designed with continuity in mind. Each post builds on the knowledge and concepts introduced in the previous ones. For a coherent understanding, I recommend reading the posts in the order they&#39;re presented. Some points might be confusing or seem out of context if you jump ahead. </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnsgt74itqjvs"> <span class="footnote-back-link"><sup><strong><a href="#fnrefsgt74itqjvs">^</a></strong></sup></span><div class="footnote-content"><p> I think <a href="https://www.lesswrong.com/users/buck?mention=user">@Buck</a> is at the origin of the name. I heard him say this term at a presentation during SERI Mats 3.0</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/yuwdj82yjhLFYessc/preface-to-the-sequence-on-model-psychology#comments">è®¨è®º</a>]]>;</description><link/> https://www.lesswrong.com/posts/yuwdj82yjhLFYessc/preface-to-the-sequence-on-model-psychology<guid ispermalink="false"> yuwdj82yjhLFYessc</guid><dc:creator><![CDATA[Quentin FEUILLADE--MONTIXI]]></dc:creator><pubDate> Tue, 07 Nov 2023 16:12:07 GMT</pubDate> </item><item><title><![CDATA[What I've been reading, November 2023]]></title><description><![CDATA[Published on November 7, 2023 1:37 PM GMT<br/><br/><p> A ~monthly feature. Recent blog posts and news stories are generally omitted; you can find them in my <a href="https://rootsofprogress.org/writing#links-digest">links digests</a> . All emphasis in bold in the quotes below was added by me.</p><h2> <strong>Books</strong></h2><p> Finished <strong>Lynn White,</strong> <a href="https://www.amazon.com/Medieval-Technology-Social-Change-Townsend/dp/B00442EY2K"><i><strong>Medieval Technology and Social Change</strong></i></a> (1962). Last time I talked about <a href="https://rootsofprogress.org/reading-2023-10">the stirrup thing</a> . The second part of the book is about the introduction of the heavy plow in agriculture, and how it enabled the shift to a <a href="https://en.wikipedia.org/wiki/Three-field_system">three-field crop rotation</a> . Among other things, this provided more protein in the European diet, which made for a healthier population. The third part is a survey of medieval power mechanisms, including water mills, crank shafts, and clock escapements. Very interesting overall, perhaps a bit dry and technical for casual readers though. Note also that since it is from the &#39;60s it is not up to date with the latest research.</p><p> Also finished <strong>Ian Tregillis&#39;s</strong> <a href="https://www.amazon.com/dp/B074CDN1HB"><i><strong>The Alchemy Wars</strong></i></a> . I can now definitely recommend this sci-fi/fantasy trilogy, even if the cast of characters and the way the conflict unfolded isn&#39;t exactly how I would have written it myself.</p><p> Browsed <strong>Derek J. de Solla Price,</strong> <a href="https://www.amazon.com/Science-since-Babylon-Derek-Solla/dp/0300017979"><i><strong>Science since Babylon</strong></i></a> (1961), while preparing for a talk. Some very interesting charts such as this: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hKK4KdoTdTtaNqCaj/lzkq3rrbdaak6ull5sjk" alt=""><figcaption> <a href="https://archive.org/details/sciencesincebaby0000pric/page/97/mode/1up"><i>Science since Babylon, p. 97</i></a></figcaption></figure><p> New on my reading list:</p><p> <strong>Venkatesh Narayanamurti and Toluwalogo Odumosu,</strong> <a href="https://www.hup.harvard.edu/catalog.php?isbn=9780674967960"><i><strong>Cycles of Invention and Discovery: Rethinking the Endless Frontier</strong></i></a> (2016), and <strong>Venkatesh Narayanamurti and Jeffrey Tsao,</strong> <a href="https://www.amazon.com/Genesis-Technoscientific-Revolutions-Rethinking-Research-ebook/dp/B098TX7WV4"><i><strong>The Genesis of Technoscientific Revolutions: Rethinking the Nature and Nurture of Research</strong></i></a> (2021). These have actually been on my list for a while, but got bumped back up after meeting Venky and Jeff at a recent workshop on metascience. (The latter book is required reading at <a href="https://spec.tech/">Speculative Technologies</a> .)</p><p> Also mentioned at the workshop: <strong>B. Zorina Khan,</strong> <a href="https://www.amazon.com/Inventing-Ideas-Patents-Knowledge-Economy-ebook/dp/B08762LSN7/"><i><strong>Inventing Ideas: Patents, Prizes, and the Knowledge Economy</strong></i></a> (2020); and <strong>A Michael Noll and Michael Geselowitz,</strong> <a href="https://www.amazon.com/Bell-Labs-Memoirs-Voices-Innovation-ebook/dp/B006L7JRLY/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;qid=&amp;sr="><i><strong>Bell Labs Memoirs: Voices of Innovation</strong></i></a> (2011).</p><p> Also:</p><ul><li> <strong>Pedro Domingos,</strong> <a href="https://www.amazon.com/Master-Algorithm-Ultimate-Learning-Machine-ebook/dp/B012271YB2"><i><strong>The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World</strong></i></a> (2015)</li><li> <strong>Robert Martello,</strong> <a href="https://www.amazon.com/Midnight-Ride-Industrial-Dawn-Enterprise-ebook/dp/B07DFPX41D"><i><strong>Midnight Ride, Industrial Dawn: Paul Revere and the Growth of American Enterprise</strong></i></a> (2010)</li><li> <strong>Jessie Singer,</strong><a href="https://www.amazon.com/There-Are-No-Accidents-Disaster-Who-ebook/dp/B0984KPSLJ"><i><strong>There Are No Accidents: The Deadly Rise of Injury and Disasterâ€”Who Profits and Who Pays the Price</strong></i></a> (2022)</li><li> <strong>Ursula Le Guin,</strong><a href="https://www.amazon.com/Dispossessed-Ambiguous-Utopia-Hainish-Cycle-ebook/dp/B000FC11GA"><i><strong>The Dispossessed</strong></i></a> (1974) (sci-fi)</li></ul><h2> <strong>Articles</strong></h2><p> <strong>Ray Kurzweil, â€œ</strong> <a href="https://www.thekurzweillibrary.com/the-law-of-accelerating-returns"><strong>The Law of Accelerating Returns</strong></a> <strong>â€</strong> (2001). Kurzweil strikes me as a grand theorist but not a careful scholarâ€”a risky combination. For instance, he writes: â€œ <i>Homo sapiens</i> evolved in a few hundred thousand years. Early stages of technologyâ€”the wheel, fire, stone toolsâ€”took tens of thousands of years to evolve and be widely deployed.â€ Stone tools, fire, and the wheel are often depicted in cartoons featuring cavemen. But stone tools evolved over <i>millions</i> of years; the controlled use of fire is something like several hundred thousand years old; and both predate <i>Homo sapiens</i> . <a href="https://rootsofprogress.org/reinventing-the-wheel">The wheel came <i>much</i> later</a> , well after agriculture and settled society. Details like this are a warning to tread carefully.</p><p> That said, I was interested to read this essay because I am starting to see the truth and significance of its core idea: that <a href="https://rootsofprogress.org/why-progress-was-so-slow">human progress accelerates over time, following a super-exponential curve</a> . This phenomenon has been documented more broadly in the economics literature, such as by <a href="https://web.stanford.edu/~chadj/JonesRomer2010.pdf">Jones and Romer (2010)</a> , who refer to â€œaccelerating growthâ€ as one of the key stylized facts that growth models should attempt to explain.</p><p> I have described acceleration as resulting from the compounding of <a href="https://rootsofprogress.org/flywheels-of-progress">multiple feedback loops</a> : increases in wealth, population, science, markets, institutions, and technology allow us to invent more, improve institutions, expand markets, advance science, grow population, accumulate wealth, etc. Kurzweil sees the phenomenon as not merely technological, but biologicalâ€”a feature of evolution as such (and he sees technological evolution as simply a continuation of biological evolution by more efficient means). In his telling, as evolution progresses, it sometimes evolves better mechanisms for evolving. This is a very intruiging idea, but he doesn&#39;t argue it with any rigor or present much evidence for it, and I don&#39;t know enough about biology or evolution to evaluate it. He mentions â€œcellsâ€ as the â€œfirst stepâ€ in evolution, and then refers to â€œthe subsequent emergence of DNAâ€ (but wasn&#39;t DNA present from the origins of life?) He indicates that evolution sped up during the Cambrian Explosion, and credits this to â€œsetting the &#39;designs&#39; of animal body plansâ€, but doesn&#39;t elaborate on the causal connection except to say that this â€œallowed rapid evolutionary development of other body organs, such as the brain.â€ Presumably sexual reproduction should be a major event in this story, since it allows for more variation through <a href="https://en.wikipedia.org/wiki/Genetic_recombination">genetic recombination</a> , but he doesn&#39;t mention it. So, it&#39;s very unclear to me what to make of this story (although if it&#39;s right, it would extend the â€œaccelerating progressâ€ pattern backwards by more than three billion years). </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hKK4KdoTdTtaNqCaj/itv5virofgz8yrkjl67l" alt="What even is this chart? What is the y-axis? How are â€œmammalsâ€ and â€œprimatesâ€ new â€œparadigmsâ€? Did he just draw a straight line on a log-log plot and arbitrarily pick some points near the line to label?"><figcaption> <i>What even is this chart? What is the y-axis? How are â€œmammalsâ€ and â€œprimatesâ€ new â€œparadigmsâ€? Did he just draw a straight line on a log-log plot and arbitrarily pick some points near the line to label?</i> <a href="https://www.thekurzweillibrary.com/the-law-of-accelerating-returns"><i>Ray Kurzweil</i></a></figcaption></figure><p> Grand theories aside, I was very interested in his analysis of computing power. He plotted the computing speed per dollar of dozens of devices, all the way from late 19th-century mechanical calculators through early 21st-century microprocessors, and claims to have found a increasing cost-performance curve running through five generations of computing technology: purely mechanical, electromechanical, vacuum tube, transistor, and integrated circuit. Moore&#39;s Law is only the fifth and most recent segment of this much longer trend, one exponential portion of an overall super-exponential curve: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hKK4KdoTdTtaNqCaj/cmnrpy27usjeitsejdx0" alt=""><figcaption> <a href="https://www.thekurzweillibrary.com/the-law-of-accelerating-returns"><i>Kurzweil, The Law of Accelerating Returns</i></a></figcaption></figure><p> I&#39;d like to check the data and sources on this one, but it&#39;s a very intriguing pattern.</p><p> The full essay is very long and covers many not-super-well-connected topics, which I don&#39;t have time to comment on; the core idea is in <a href="https://www.edge.org/response-detail/10600">this 2004 Edge question</a> , but doesn&#39;t contain all the most interesting details (such as the computing trends just mentioned).</p><p> The same accelerating curve, and the same basic explanation based on feedback loops, seems to be the gist of <strong>David Roodman, â€œ</strong> <a href="https://www.openphilanthropy.org/research/modeling-the-human-trajectory/"><strong>Modeling the Human Trajectory</strong></a> <strong>â€</strong> (2020), which I have only skimmed but plan to return to.</p><p> Others:</p><p> <strong>Deirdre N. McCloskey</strong> <a href="https://www.cato.org/commentary/book-review-power-progress-our-thousand-year-struggle-over-technology-prosperity"><strong>reviews Acemoglu and Johnson&#39;s</strong> <i><strong>Power and Progress</strong></i></a> (2023). If you know anything about the book, and anything about McCloskey, you won&#39;t be surprised that she is critical:</p><blockquote><p> The invisible hand of human creativity and innovation, in the authors&#39; analysis, requires the wise guidance of the state. â€¦ This is a perspective many voters increasingly agree withâ€”and politicians from Elizabeth Warren to Marco Rubio. We are children, bad children (viewed from the right) or sad children (viewed from the left). Bad or sad, as children we need to be taken in hand. Messrs. Acemoglu and Johnson warmly admire the US Progressive Movement of the late 19th century as a model for their statism: experts taking childâ€citizens in hand.</p></blockquote><p> <strong>Robert Tracinski, â€œ</strong> <a href="https://tracinskiletter.substack.com/p/we-are-all-philosophers-now"><strong>We Are All Philosophers Now</strong></a> <strong>â€</strong> and <strong>â€œ</strong> <a href="https://tracinskiletter.substack.com/p/the-dilemma-of-choice"><strong>The Dilemma of Choice</strong></a> <strong>â€</strong> (2023). Modernity has replaced a narrow, limited set of social roles and life choices with a smorgasbord of options. This is liberating, but the price of the freedom of choice is the responsibility of choice, which is now everyone&#39;s to bear. Not everyone is happy about this. Rob&#39;s pithy summary: â€œIf Socrates said that the unexamined life is not worth living, well, now it&#39;s not really an option.â€</p><p> <strong>Virginia Postrel, â€œ</strong> <a href="https://vpostrel.substack.com/p/question-time-what-ails-american"><strong>What ails American culture?</strong></a> <strong>â€</strong> (2023). On similar themes:</p><blockquote><p> Human beings need to feel purpose and meaning in their lives. But I am not entirely sure that the current discontent is a product of material abundance, that people did not feel similar discontent in the past, or that the â€œeconomic problemâ€ loomed so large in the past that it dwarfed all other problems.</p></blockquote><p> <strong>Ben Landau-Taylor, â€œ</strong> <a href="https://www.benlandautaylor.com/p/the-vocabulary-of-power"><strong>The Vocabulary Of Power</strong></a> <strong>â€</strong> (2023). â€œPowerâ€ can mean many things; here are four more precise terms. Not only will this help clarify your concepts, it will also fulfill your daily quota of thinking about the Roman Empire.</p><p> <strong>Tanner Greer, â€œ</strong> <a href="https://scholars-stage.org/where-have-all-the-great-works-gone/"><strong>Where Have All the Great Works Gone?</strong></a> <strong>â€</strong> (2021):</p><blockquote><p> Spengler â€¦ repeatedly describes Tolstoy (d. 1910), Ibsen (d. 1906), Nietzsche (d. 1900), Hertz (d. 1894), Dostoevsky (d. 1881), Marx (d. 1883), and Maxwell (1879) as figures of defining â€œworld-historicalâ€ importanceâ€¦ Spengler began writing <i>Decline of the West</i> in 1914. Tolstoy was only four years dead when Spengler started his book; Marx was only 30 years deceased. â€¦ Is there anyone who died in the last decade you could make that sort of claim for? How about for the last two decades? The last three?</p></blockquote><p> <strong>Gideon Lewis-Kraus, â€œ</strong> <a href="https://www.newyorker.com/magazine/2023/10/09/they-studied-dishonesty-was-their-work-a-lie"><strong>They Studied Dishonesty. Was Their Work a Lie?</strong></a> <strong>â€</strong> (2023). A case study of scientific fraud.</p><p> <strong>Stephen Wolfram, â€œ</strong> <a href="https://writings.stephenwolfram.com/2017/10/are-all-fish-the-same-shape-if-you-stretch-them-the-victorian-tale-of-on-growth-and-form/"><strong>Are All Fish the Same Shape If You Stretch Them? The Victorian Tale of</strong> <i><strong>On Growth and Form</strong></i></a> <strong>â€</strong> (2017) I just thought this idea was kind of hilarious: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hKK4KdoTdTtaNqCaj/ojp9zs5mkcgv06u8khvd" alt="Stretch one kind of fish, and it looks like another."><figcaption> <i>Stretch one kind of fish, and it looks like another.</i> <a href="https://writings.stephenwolfram.com/2017/10/are-all-fish-the-same-shape-if-you-stretch-them-the-victorian-tale-of-on-growth-and-form/"><i>D&#39;Arcy Thompson, On Growth and Form</i></a></figcaption></figure><br/><br/> <a href="https://www.lesswrong.com/posts/hKK4KdoTdTtaNqCaj/what-i-ve-been-reading-november-2023#comments">è®¨è®º</a>]]>;</description><link/> https://www.lesswrong.com/posts/hKK4KdoTdTtaNqCaj/what-i-ve-been-reading-november-2023<guid ispermalink="false"> hKK4KdoTdTtaNqCaj</guid><dc:creator><![CDATA[jasoncrawford]]></dc:creator><pubDate> Tue, 07 Nov 2023 13:37:20 GMT</pubDate> </item><item><title><![CDATA[AI Alignment [Progress] this Week (11/05/2023)]]></title><description><![CDATA[Published on November 7, 2023 1:26 PM GMT<br/><br/><p> The biggest news of this week is probably the two new AI Alignment Initiatives.</p><p> Otherwise, this was a relatively quiet week for AI Alignment breakthroughs.</p><p> So here are our</p><h1> AI Alignment Breakthroughs this Week</h1><p></p><p> This week there were breakthroughs in the areas of:</p><p> Mechanistic Interpretability</p><p> Avoiding Adversarial Attacks</p><p> Human Augmentation</p><p> Making AI Do what we want</p><p> AI Art</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b62e587-7f25-4889-8d6d-b2e723809e3f_1792x1024.webp"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b62e587-7f25-4889-8d6d-b2e723809e3f_1792x1024.webp" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b62e587-7f25-4889-8d6d-b2e723809e3f_1792x1024.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b62e587-7f25-4889-8d6d-b2e723809e3f_1792x1024.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b62e587-7f25-4889-8d6d-b2e723809e3f_1792x1024.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b62e587-7f25-4889-8d6d-b2e723809e3f_1792x1024.webp 1456w"></a></p><p></p><h1> Mechanistic Interpretability</h1><p></p><p> <a href="https://twitter.com/abacaj/status/1721223737729581437">Research on the limits of Generalization in LLMs</a></p><p> What is it: Shows that LLMs are unable to generalize outside of their training data</p><p> What&#39;s new: A systematic study of the types of generalization that LLMs can do ((in domain learning) and the types they can&#39;t (out of domain learning)</p><p> What does it mean: Understanding the limits of LLMs should help us better understand where they can be safely deployed</p><p> Rating: ğŸ’¡ğŸ’¡ğŸ’¡</p><p> <a href="https://twitter.com/emollick/status/1720135672764285176">Does appealing to AI â€œemotionsâ€ make them preform better?</a></p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79d8fc6a-d12d-472c-8816-ac53578ddc27_1241x1055.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79d8fc6a-d12d-472c-8816-ac53578ddc27_1241x1055.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79d8fc6a-d12d-472c-8816-ac53578ddc27_1241x1055.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79d8fc6a-d12d-472c-8816-ac53578ddc27_1241x1055.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79d8fc6a-d12d-472c-8816-ac53578ddc27_1241x1055.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79d8fc6a-d12d-472c-8816-ac53578ddc27_1241x1055.jpeg 1456w"></a></p><p></p><p></p><p> What is it: Researchers find you can make LLMs answer questions better by using emotion</p><p> What&#39;s new: new prompting strategies such as â€œthis is important for my careerâ€</p><p> What is it good for: In addition to purely improved performance, the really question is <i>why</i> does this work. Is there some â€œtry harderâ€ vector in the latent space that we can identify and exploit?</p><p> Rating: ğŸ’¡ğŸ’¡</p><p> <a href="https://twitter.com/johnjnay/status/1719762063419904319">LLMs Generalized Truthfulness Across Agents</a></p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d1f9e09-c9c4-4e44-ac0f-88f1880e9d87_680x428.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d1f9e09-c9c4-4e44-ac0f-88f1880e9d87_680x428.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d1f9e09-c9c4-4e44-ac0f-88f1880e9d87_680x428.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d1f9e09-c9c4-4e44-ac0f-88f1880e9d87_680x428.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d1f9e09-c9c4-4e44-ac0f-88f1880e9d87_680x428.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d1f9e09-c9c4-4e44-ac0f-88f1880e9d87_680x428.jpeg 1456w"></a></p><p></p><p> What is it: a way to tell true statements from false ones using LLMs</p><p> What&#39;s new: they find evidence that LLMs have different â€œpersonasâ€ that they use to judge whether something is true or not</p><p> What is it good for: Perhaps we can extract these personas and use them for alignment.</p><p> Rating: ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡</p><p></p><h1> Avoiding Adversarial Attacks</h1><p></p><p> <a href="https://twitter.com/StephenLCasper/status/1720910484441014525">Self Destructing Models</a></p><p> What it is: Pretrain a model so that it cannot be later fine-tuned for harmful purposes?</p><p> What&#39;s new: They find meta-parameters such that fine-tuning a model on one task reduces its usefulness for other tasks</p><p> What is it good for: Hypothetically you could open-source a model and not have all of the RLHF safety features <a href="https://venturebeat.com/ai/uh-oh-fine-tuning-llms-compromises-their-safety-study-finds/">immediately removed</a> by fine-tuning</p><p> Rating:ğŸ’¡ğŸ’¡(important topic, but I&#39;m not convinced this technique works. More optimistic about techniques like <a href="https://twitter.com/norabelrose/status/1666469917636571137">Concept Erasure</a> )</p><p> <a href="https://twitter.com/simonw/status/1720839106664808450">Data Exfiltration</a></p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca693c46-c1aa-4b30-8f70-c2ecfe560983_680x433.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca693c46-c1aa-4b30-8f70-c2ecfe560983_680x433.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca693c46-c1aa-4b30-8f70-c2ecfe560983_680x433.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca693c46-c1aa-4b30-8f70-c2ecfe560983_680x433.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca693c46-c1aa-4b30-8f70-c2ecfe560983_680x433.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca693c46-c1aa-4b30-8f70-c2ecfe560983_680x433.jpeg 1456w"></a></p><p></p><p></p><p></p><p> What is it: an example of an attack that uses prompt injection to exfiltrate data from Google Bard</p><p> What&#39;s new: they use Bard&#39;s Google Doc extension to exfiltrate data</p><p> What is it good for: red-teaming these kinds of attacks is the first step to fixing them</p><p> Rating: ğŸ’¡</p><p> <a href="https://twitter.com/DrNikkiTeran/status/1719048031549505974">Will releasing the weights of large language models grant widespread access to pandemic agents?</a></p><p> What is it: exactly what it says on the tin</p><p> What&#39;s new: they simulate someone trying to build a harmful bio-weapon with/without an LLM and find the LLM helps</p><p> What is it good for: There&#39;s been pretty strong pushback against this from e/acc, with people noting that this is also true of Google Search, or a hypothetical drug that increased everyone in the world&#39;s IQ by 1 point. The larger point remains that we should identify dangerous capabilities and act to mitigate them. â€œRegulate uses not researchâ€ is the <a href="https://twitter.com/MiTiBennett/status/1705562223765328253">rallying cry</a> of Midwit Alignment.</p><p> Rating: ğŸ’¡</p><h1> Human Augmentation</h1><p></p><p> <a href="https://twitter.com/tolga_birdal/status/1719691533606146194">SignAvatars</a></p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eddc298-7d1a-4d5a-aac1-b5fe4e8de0d3_680x378.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eddc298-7d1a-4d5a-aac1-b5fe4e8de0d3_680x378.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eddc298-7d1a-4d5a-aac1-b5fe4e8de0d3_680x378.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eddc298-7d1a-4d5a-aac1-b5fe4e8de0d3_680x378.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eddc298-7d1a-4d5a-aac1-b5fe4e8de0d3_680x378.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eddc298-7d1a-4d5a-aac1-b5fe4e8de0d3_680x378.jpeg 1456w"></a></p><p></p><p></p><p> What is it: a 3d sign language dataset</p><p> What&#39;s new: first dataset of its kind</p><p> What is it good for: Train a model to automatically convert speech into sign language</p><p> Rating: ğŸ’¡ğŸ’¡ğŸ’¡</p><h1> Making AI Do what we want</h1><p></p><p> <a href="https://twitter.com/SeungjuHan3/status/1720373937308377250">Commonsense Norms</a></p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe019f2a9-898f-43b7-8132-8b7ec30ea5cf_680x401.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe019f2a9-898f-43b7-8132-8b7ec30ea5cf_680x401.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe019f2a9-898f-43b7-8132-8b7ec30ea5cf_680x401.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe019f2a9-898f-43b7-8132-8b7ec30ea5cf_680x401.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe019f2a9-898f-43b7-8132-8b7ec30ea5cf_680x401.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe019f2a9-898f-43b7-8132-8b7ec30ea5cf_680x401.jpeg 1456w"></a></p><p></p><p> What is it: answer moral questions using visual data</p><p> What&#39;s new: They use a LM to generate a multimodal benchmark set of various moral quandries</p><p> What is it good for: If we want robots or self-driving cars to behave ethically, they will have to rely on visual input to do so</p><p> Rating:ğŸ’¡ğŸ’¡</p><p> <a href="https://twitter.com/arankomatsuzaki/status/1710096304167120903">Agent Instructs Large Language Models to be General Zero-Shot Reasoners</a></p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e0e1087-093b-4a2a-ac84-27179da41c78_680x490.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e0e1087-093b-4a2a-ac84-27179da41c78_680x490.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e0e1087-093b-4a2a-ac84-27179da41c78_680x490.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e0e1087-093b-4a2a-ac84-27179da41c78_680x490.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e0e1087-093b-4a2a-ac84-27179da41c78_680x490.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e0e1087-093b-4a2a-ac84-27179da41c78_680x490.jpeg 1456w"></a></p><p></p><p></p><p> What is it: train an agent to follow instructions</p><p> What&#39;s new: they first have the agent access web resources before generating step-by-step instructions</p><p> What is it good for: Accurately doing tasks such as classification</p><p> Rating: ğŸ’¡ğŸ’¡ğŸ’¡</p><h1> AI Art</h1><p></p><p> <a href="https://twitter.com/dreamingtulpa/status/1721092490281771448">360-to-gaussian-splat</a></p><p> What is it: a new program for converting a 360 degree photo into a 3d scene</p><p> What&#39;s new: they train a 3d-aware diffusion model to allow them to calculate novel views</p><p> What is it good for: convert any 360 degree photo (and soon I expect video) into a full 3d scene you can walk around in</p><p> Rating: ğŸ’¡ğŸ’¡ğŸ’¡</p><p> <a href="https://twitter.com/xenovacom/status/1720916876010635364">Distill Whisper</a></p><p> What is it: A faster version of the speech-to-text model whisper</p><p> What&#39;s new: they distill the model down to one that&#39;s 49% smaller</p><p> What is it good for: this unlocks text-to-speech in places like mobile or web where it would have previously been too slow.</p><p> Rating: ğŸ’¡ğŸ’¡</p><p> <a href="https://twitter.com/DeepMotionInc/status/1719810023201841512">DeepMotion</a></p><p> What is it: an AI model trained to generate motion for 3d models</p><p> What&#39;s new: Not open source, but seems better than past versions of this I&#39;ve seen</p><p> What is it good for: animating all of those sweet models that you&#39;re generating with <a href="https://twitter.com/marc_habermann/status/1717808998236217463">text-to-3d</a> .</p><p> Rating: ğŸ’¡ğŸ’¡ğŸ’¡</p><h1> AI Alignment Initiatives</h1><p></p><p> <a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/">The Biden Executive Order on AI</a></p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4147609b-4ccb-485d-9e88-6d9c0e227db5_647x534.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4147609b-4ccb-485d-9e88-6d9c0e227db5_647x534.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4147609b-4ccb-485d-9e88-6d9c0e227db5_647x534.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4147609b-4ccb-485d-9e88-6d9c0e227db5_647x534.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4147609b-4ccb-485d-9e88-6d9c0e227db5_647x534.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4147609b-4ccb-485d-9e88-6d9c0e227db5_647x534.png 1456w"></a></p><p></p><p> What is it: The most notable provision being that models trained with than 10**26 flops and data centers with a capacity of more than 10**20 flops/sec must <a href="https://twitter.com/DavidVorick/status/1719097248699879831">register</a> with the government. This limit appears to have been chosen not for any scientific reason, but because it is <a href="https://twitter.com/main_horse/status/1719147360964825453"><i>slightly larger</i></a><i> </i>than the largest current models. There&#39;s also some <a href="https://twitter.com/JagersbergKnut/status/1719259231419797656">ominous language</a> about open-source models, but no actual regulations so far.</p><p> What does it mean: Doomers will say this doesn&#39;t go <a href="https://intelligence.org/2023/04/07/pausing-ai-developments-isnt-enough-we-need-to-shut-it-all-down/">far enough</a> . E/ACC is already preparing to flee for <a href="https://twitter.com/DelComplex/status/1719087956311396481">friendlier</a> waters (this particular project is a joke). The most important fact isn&#39;t the order itself (which is not a law and thus has limited enforcement mechanisms) but that this sets the tone for future regulation. Expect more of the same in the future: technical limits set for political reasons not scientific ones, emphasis on whatever the current administration&#39;s pet-projects are (Biden likes unions hates discrimination, and wants to cure cancer), and more words than action (since we still have to compete with China after all).</p><p> Overall Rating:ğŸ§“ğŸ»ğŸ§“ğŸ»ğŸ§“ğŸ» (3 Joe Bidens, could have been worse)</p><p> <a href="https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023">Bletchley Park Declaration</a></p><p> What is it: a joint statement by a number of countries agreeing to mitigate AI risk</p><p> What does it mean: The most important signature on this list is undoubtedly China. Much like <a href="https://www.cnn.com/2021/10/28/world/china-us-climate-cop26-intl-hnk/index.html">global warming</a> , China is probably the single biggest contributor to AI risk. They have the computing <a href="https://www.top500.org/news/china-extends-lead-in-number-of-top500-supercomputers-us-holds-on-to-performance-advantage/">heft</a> to build powerful systems, but are more likely to cut safety standards due to the perceive need to â€œraceâ€ to catch up with the US. And an AI broadly trained with the <a href="https://thediplomat.com/2022/11/xi-jinpings-vision-for-artificial-intelligence-in-the-pla/">values</a> of the CCP is less likely to be benevolent. I wouldn&#39;t expect miracles, but hopefully this indicates a willingness by the Chinese to at least follow the <a href="https://www.lesswrong.com/posts/EaZghEwcCJRAuee66/my-thoughts-on-the-social-response-to-ai-risk">common consensus</a> on AI safety standards.</p><p> Rating: ğŸ‡¨ğŸ‡³ğŸ‡¨ğŸ‡³ğŸ‡¨ğŸ‡³ğŸ‡¨ğŸ‡³ğŸ‡¨ğŸ‡³</p><h1> This is not AI Alignment</h1><p></p><p> <a href="https://twitter.com/ESYudkowsky/status/1718654143110512741">An amusing short-story (long tweet?) By EY</a></p><p> What it is: A reminder that EY is a very good <i>fiction</i> writer</p><p> What does it mean: It is funny and worth reading.</p><p> Overall Rating: ğŸ“ƒğŸ“ƒğŸ“ƒğŸ“ƒ(4 letters of self-reflection)</p><p> Small LLMs</p><p> What it is: There are an increasing number of small LLMs in the â€œbetter than GPT 3.5â€ category including <a href="https://twitter.com/alignment_lab/status/1721308271946965452">OpenChat</a> , <a href="https://twitter.com/_akhaliq/status/1721028519717642749">Grok</a> and <a href="https://twitter.com/erhartford/status/1721041791988679059">Yi-34B</a> . Importantly anyone with a modestly good PC can run OpenChat or Yi-34B on their personal computer.</p><p> What does it mean: A little over a year an a half after the release of GPT3.5, the technology has now become so widespread that there are multiple independent replications. If technology really is increasing at a <a href="https://en.m.wikipedia.org/wiki/Accelerating_change">hyper-exponential</a> rate, we should expect smaller and smaller time-gaps between the leading edge and widespread availability (and paradoxically larger and larger capability gaps). One key thing to track might be to see how long before we have widespread models better than GPT4.</p><p> Rating:ğŸ¤–ğŸ¤– <a href="https://en.m.wikipedia.org/wiki/Accelerating_change">ğŸ¤–</a> + <a href="https://en.m.wikipedia.org/wiki/Accelerating_change">ğŸ¤–</a> /2 (3.5 large language models)</p><br/><br/> <a href="https://www.lesswrong.com/posts/FLCHNqu2FNRCJ4dyg/ai-alignment-progress-this-week-11-05-2023#comments">è®¨è®º</a>]]>;</description><link/> https://www.lesswrong.com/posts/FLCHNqu2FNRCJ4dyg/ai-alignment-progress-this-week-11-05-2023<guid ispermalink="false"> FLCHNqu2FNRCJ4dyg</guid><dc:creator><![CDATA[Logan Zoellner]]></dc:creator><pubDate> Tue, 07 Nov 2023 13:26:22 GMT</pubDate> </item><item><title><![CDATA[On the UK Summit]]></title><description><![CDATA[Published on November 7, 2023 1:10 PM GMT<br/><br/><p> In the eyes of many, Biden&#39;s Executive Order somewhat overshadowed the UK Summit. The timing was unfortunate. Both events were important milestones. Now that I have had time, here is my analysis of what happened at the UK Summit.</p><span id="more-23578"></span><p> As is often the case with such events, there was a lot of talk relative to the amount of action. There was a lot of diplomatic talk, talk of that which everyone agrees upon, relative to the amount of talk of real substance. There were days of meetings that resulted in rather unspicy summaries and resolutions. The language around issues that matter most was softened, the actual mission in danger of being compromised.</p><p> And as usual, the net result was reason for optimism, a net highly positive event versus not having it, while also in some ways being disappointing when compared to what might have been. A declaration was signed including by China, but it neglected existential risk. Sunak&#39;s words on AI were not as strong as his words have been previously.</p><p> We got promises for two additional summits, in South Korea and France. Given that, I am willing to declare this a success.</p><p> One area of strong substance was the push for major AI labs to give substantive safety policies addressing a variety of issues, sometimes largely called Responsible Scaling Policies (RSPs). The biggest labs all did so, even Meta. Now we can examine their responses, know who is being how responsible, and push for better in the future or for government action to fix issues or enshrine progress. This was an excellent development.</p><p> This post will look at the rest of what happened at the Summit. I will be writing about the RSPs and other safety policies of the labs in a distinct post next week.</p><h4> Looking Back at People&#39;s Goals for the Summit and Taskforce</h4><p> <a target="_blank" rel="noreferrer noopener" href="https://jack-clark.net/2023/07/05/what-should-the-uks-100-million-foundation-model-taskforce-do/">Jack Clark&#39;s proposal from July 5 for what the Foundation Model taskforce might do to evaluate frontier models</a> as its priority, and how it might prioritize that, <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/Simeon_Cps/status/1676595226339598343">Simeon&#39;s response</a> emphasizing the need for a good way to know whether a proposal is safe enough to allow it to proceed.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.navigatingrisks.ai/p/what-should-the-uks-100-million-foundation">Navigating AI Risks asked on July 17 what the taskforce should do</a> , advising focus on interventions to impact policy at labs and other governments. Suggested focus was risk assessment methodology, demonstrating current risks and assessing current state of the art models, and to avoid direct alignment work.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ohlennart/status/1678331653326884865">Lennart Heim&#39;s (GovAI) July 10 proposal of what the summit should try to accomplish</a> , which he reviewed after the summit.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/matthewclifford/status/1698616866934018282">Matt Clifford from the PM&#39;s office shared on September 10 their objectives</a> for the summit: A shared understanding of the risks posed by frontier AI and the need for action, a forward process for international collaboration, measures for organizations, finding areas for safety collaboration and showcasing how safe AI development can enhance global good.</p><h4> AI Safety Summit Agenda</h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/soundboy/status/1718925374623519155">What has the UK Taskforce been up to in advance of the summit</a> ( <a target="_blank" rel="noreferrer noopener" href="https://www.gov.uk/government/publications/frontier-ai-taskforce-second-progress-report/frontier-ai-taskforce-second-progress-report">report</a> )?</p><blockquote><p> Ian Hogarth (Chair UK AI Frontier Model Taskforce): The Taskforce is a start-up inside government, delivering on the mission given to us by the Prime Minister: to build an AI research team that can evaluate risks at the frontier of AI. We are now 18 weeks old and this is our second progress report.</p><p> The frontier is moving very fast. On the current course, in the first half of 2024, we expect a small handful of companies to finish training models that could produce another significant jump in capabilities beyond state-of-the-art in 2023.</p><p> As these AI systems become more capable they may augment risks. An AI system that advances towards expert ability at writing software could increase cybersecurity threats. An AI system that becomes more capable at modelling biology could escalate biosecurity threats.</p><p> We believe it is critical that frontier AI systems are developed safely and that the potential risks of new models are rigorously and independently assessed for harmful capabilities before and after they are deployed.</p><p> The hardest challenge we have faced in building the Taskforce is persuading leading AI researchers to join the government. Beyond money, the prestige and learning opportunities from working at leading AI organizations are a huge draw for researchers.</p><p> We can&#39;t compete on compensation, but we can compete on mission. We are building the first team inside a G7 government that can evaluate the risks of frontier AI models. This is a crucial step towards meaningful accountability and governance of frontier AI companies.</p><p> In our first progress report we said we would hold ourselves accountable for progress by tracking the total years of experience in our research team. When I arrived as Chair in June, there was just one frontier AI researcher employed full time by the department.</p><p> We managed to increase that to 50 years of experience in our first 11 weeks of operation. Today that has grown to 150 years of collective experience in frontier AI research.</p></blockquote><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05542917-18fc-4dd7-8372-2e140111df62_960x640.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zbrvXGu264u3p8otD/xpluetsb6xhnqot5puwf" alt="å›¾åƒ"></a></figure><blockquote><p> Ian Hograth: Our research team and partners have published hundreds of papers at top conferences. Some of our team members&#39; recent publications span algorithms for AI systems to search and improve and and publicly sourced constitutions for AI alignment.</p><p> We are also delighted to welcome Jade Leung to our leadership team. Jade joins us from OpenAI where she led the firm&#39;s work on AGI governance, with a particular focus on frontier AI regulation, international governance, and safety protocols.</p><p> Furthermore, we are excited to welcome @ruchowdh, who will be working with the Taskforce to develop its work on safety infrastructure, as well as its work on evaluating societal impacts from AI.</p><p> Rumman is the CEO and co-founder of Humane Intelligence, and led efforts for the largest generative AI public red-teaming event at DEFCON this year. She is also a Responsible AI fellow at the Harvard Berkman Klein Center, and previously led the META team at Twitter.</p><p> We are continuing to scale up our research and engineering team. Please consider applying to the EOI form or via these job postings for Senior Research Engineers and Senior Software Engineers.</p><p> Leading on AI safety does not mean starting from scratch or working alone â€“ we are building on and supporting the work conducted by a range of cutting-edge organizations.</p><p> Today we are announcing that the taskforce has entered into a new partnership with @apolloaisafety, an AI safety organisation that works with large language models to interpret their behaviour and evaluate their high-risk failure modes, particularly deceptive alignment.</p><p> We have also entered into a new partnership with @openminedorg. We are working with OpenMined to develop technical infrastructure and governance tools that will facilitate AI safety research across government and AI research organisations.</p><p> In June this year, several large AI companies committed to giving the UK government, via the Frontier AI Taskforce, early and deeper access to their models. Since then, we have been working in collaboration with these leading AI companies to secure this model access.</p><p> But model access is only one part of the picture. For too long researchers in industry have had access to much greater computing resources than those in academia and the public-sector, creating a so-called &#39;compute divide&#39;.</p><p> Having the compute infrastructure to conduct cutting-edge research is pivotal for building state capacity in AI safety â€“ for example being able to run large-scale interpretability experiments.</p><p> To tackle this over the last months, the Taskforce has supported DSIT &amp; the University of Bristol to help launch major investments in compute. The University of Bristol will soon host the first component of the UK&#39;s AI Research Resource, <a target="_blank" rel="noreferrer noopener" href="https://www.gov.uk/government/news/bristol-set-to-host-uks-most-powerful-supercomputer-to-turbocharge-ai-innovation">Isambard-AI</a> .</p><p> It will be one of the most powerful supercomputers in Europe when built and will vastly increase our public-sector AI compute capacity. These great strides fundamentally change the kind of projects researchers can take on inside the Taskforce.</p><p> â€¦â€¦</p><p> [On Day 1 of the Summit] our team will present 10-minute demonstrations, focused on four key areas of risk: Misuse, Societal Harm, Loss of Human Control, and Unpredictable Progress.</p><p> We believe these demonstrations will be the most compelling and nuanced presentations of frontier AI risks done by any government to date. Our hope is that these demonstrations will raise awareness of frontier AI risk and the need for coordinated action.</p><p> AI is a general purpose and dual-use technology. We need a clear-eyed commitment to empirically understanding and mitigating the risks of AI so we can enjoy the benefits.</p><p> On Friday the Prime Minister announced that he is putting the UK&#39;s work on AI Safety on a longer term basis by <a target="_blank" rel="noreferrer noopener" href="https://www.gov.uk/government/speeches/prime-ministers-speech-on-ai-26-october-2023">creating an AI Safety Institute</a> in which our work will continue.</p><p> AI has the power to revolutionize industries, enhance our lives and address complex global challenges, but we must also confront the global risks.</p></blockquote><p> It has only been 18 weeks. It sounds like they are building a very strong team, despite having to pay UK government salaries and play by government rules. The question is whether they can demonstrate the necessary types of tangible progress that allow them continued support, and if they do whether they can execute then on things that matter. This is all good diplomatic talk, which would be the right move in all worlds, so it gives us little insight beyond that.</p><p> Karim Beguir lays out his view of the stakes.</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/kbeguir/status/1718996564947980526">Karim Beguir</a> (CEO &amp; Co-Founder InstadeepAi): Happy to announce that I will be attending the AI Safety Summit in Bletchley Park <img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BHdEvjtfwpgrTh825/ctsf9jut7irxxmirrjkz" alt="ğŸ‡¬ğŸ‡§" style="height:1em;max-height:1em"> this week! I&#39;m honored to join heads of government as one of 100 influential researchers and tech leaders at the forefront of AI innovation.</p><p> A <img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pKhzQyaWwes63JFwp/jgt2eoslwfcyu0abb4yz" alt="ğŸ§µ" style="height:1em;max-height:1em"> on why <a target="_blank" rel="noreferrer noopener" href="https://t.co/eFWiL0Iv1O">this summit</a> is critically important for the future.</p><p> Since 2012, AI progress has benefitted from a triple exponential of data, compute (doubles every 6 months in ML) and model innovation (AI efficiency doubles every 16 months). It&#39;s a huge snowball that has been rolling for a while.</p><p> But now something qualitatively new has happened: the LLM breakthroughs of the last 12 months have triggered an AI race with around $10B now invested every month. So the question is; Are we about to experience a steeper rate of progress, similar to what Tim Urban (@waitbutwhy) predicted?</p><p> Here&#39;s what I see. AI is now accelerating itself through those same three drivers: data, compute and model innovation. LLMs allow AI-generated feedback to complement human feedback (ie RLAIF adding to RLHF). AI also designs more efficient compute hardware end-to-end with products <a target="_blank" rel="noreferrer noopener" href="http://DeepPCB.ai">like our own</a> and ML practitioners can develop next generation models roughly 2X as fast with AI-coding assistants.</p><p> That&#39;s why it&#39;s time for a dialogue between key AI innovators and governments. Nations need to tap into the efficiency and economic benefits of AI while proactively containing emergent risks, as leading AI researchers Yoshua Bengio, @geoffreyhinton, @tegmark argue and @10DowningStreet concurs.</p></blockquote><p> [thread continues]</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/robertwiblin/status/1719341619797749764">The UK government released</a> <a target="_blank" rel="noreferrer noopener" href="https://t.co/8cV1TgKcbX">a detailed set</a> of 42 (!) best safety practices. They asked the major labs to respond with how they intended to implement such practices, and otherwise ensure AI safety.</p><p> I will be writing another post on that. As a preview:</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/ms3x8ngwTfep7jBue/thoughts-on-the-ai-safety-summit-company-policies">Nate Sores has thoughts on what they asked for</a> , which could be summarized as &#39;mostly good things, better than nothing, obviously not enough&#39; and of course it was never going to be enough and also Nate Sores is the world&#39;s toughest crowd.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://t.co/2pTf4vbRCV">How are various companies doing on the requests?</a></p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0dab6ccd-aa62-49b9-a41a-1753f7d90e07_507x507.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zbrvXGu264u3p8otD/vlqxp80zvprmc1pxcyua" alt="å›¾åƒ"></a></figure><p> That is what you get if you were grading on a curve one answer at a time.</p><p> Reality does not grade on a curve.</p><p> My own analysis, and others I trust, agree that this relatively underrates OpenAI, who clearly had the second best set of policies by a substantial margin, with one source even putting them on par with Anthropic, although I disagree with that. Otherwise the relative rankings seem correct.</p><p> I would consider Anthropic&#39;s submission quite good, if it was backed by proper framing of the need for further improvement and refinement, making it clear that this was a combination of IOU and only part of the solution, and advocacy of necessary government measures to help ensure safety. Given the mixed messaging, my excitement and that of many others is tampered, but they are still clearly leading the way. That is important.</p><p> More detail on the submitted policies will come in a future post.</p><h4> Someone Picked Up the Phone</h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/matthewclifford/status/1719671611039551615">Well look who it is talking about AI safety and governance at the AI safety summit.</a></p><blockquote><p> Matt Clifford: Huge moment to have both Secretary Raimondo of the US and Vice Minister Wu of China speaking about AI safety and governance at the AI Safety Summit.</p></blockquote><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8386747-c778-4a1b-a7b1-82ff6c8eff67_1536x2048.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zbrvXGu264u3p8otD/acjwn65xqktadnyhmptt" alt="å›¾åƒ"></a></figure><p> We also have this: <a target="_blank" rel="noreferrer noopener" href="https://humancompatible.ai/?p=4695">Prominent AI Scientists from China and the West Propose Joint Strategy to Mitigate Risks from AI</a> .</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/S_OhEigeartaigh">SeÃ¡n Ã“ hÃ‰igeartaigh</a> : Delighted to see this statement from AI research and governance leaders in the West and China, calling for coordinated global action on AI safety and governance. Great to see the consensus.</p><p> Statement page: The expert attendees warned governments and AI developers that â€œ <em>coordinated global action on AI safety research and governance is critical to prevent uncontrolled frontier AI development from posing unacceptable risks to humanity.</em> â€ Attendees produced a joint statement with specific technical and policy recommendations, which is attached below. Prof. Zhang remarked that it is â€œcrucial for governments and AI corporations to invest heavily in frontier AI safety research and engineeringâ€, while Prof. Yao stressed the importance that we â€œwork together as a global community to ensure the safe progress of AI.â€ Prof. Bengio called upon AI developers to â€œdemonstrate the safety of their approach before training and deployingâ€ AI systems, while Prof. Russell concurred that â€œif they cannot do that, they cannot build or deploy their systems. Full stop.â€</p></blockquote><p> This is the real thing, and it has a very distinctly culturally Chinese ring to its wording and attitude. Here is the full English statement, <a target="_blank" rel="noreferrer noopener" href="https://humancompatible.ai/?p=4695">link also has the Chinese version</a> .</p><blockquote><p> <strong><em>Coordinated global action on AI safety research and governance is critical to prevent uncontrolled frontier AI development from posing unacceptable risks to humanity.</em></strong></p><p> <em>Global action, cooperation, and capacity building are key to managing risk from AI and enabling humanity to share in its benefits. AI safety is a global public good that should be supported by public and private investment, with advances in safety shared widely. Governments around the world â€” especially of leading AI nations â€” have a responsibility to develop measures to prevent worst-case outcomes from malicious or careless actors and to rein in reckless competition. The international community should work to create an international coordination process for advanced AI in this vein.</em></p><p> <em>We face near-term risks from malicious actors misusing frontier AI systems, with current safety filters integrated by developers easily bypassed. Frontier AI systems produce compelling misinformation and may soon be capable enough to help terrorists develop weapons of mass destruction. Moreover, there is a serious risk that future AI systems may escape human control altogether. Even aligned AI systems could destabilize or disempower existing institutions. Taken together, we believe AI may pose an existential risk to humanity in the coming decades.</em></p><p> <em>In domestic regulation, we recommend mandatory registration for the creation, sale or use of models above a certain capability threshold, including open-source copies and derivatives, to enable governments to acquire critical and currently missing visibility into emerging risks. Governments should monitor large-scale data centers and track AI incidents, and should require that AI developers of frontier models be subject to independent third-party audits evaluating their information security and model safety. AI developers should also be required to share comprehensive risk assessments, policies around risk management, and predictions about their systems&#39; behavior in third party evaluations and post-deployment with relevant authorities.</em></p><p> <em>We also recommend defining clear red lines that, if crossed, mandate immediate termination of an AI system â€” including all copies â€” through rapid and safe shut-down procedures. Governments should cooperate to instantiate and preserve this capacity. Moreover, prior to deployment as well as during training for the most advanced models, developers should demonstrate to regulators&#39; satisfaction that their system(s) will not cross these red lines.</em></p><p> <em>Reaching adequate safety levels for advanced AI will also require immense research progress. Advanced AI systems must be demonstrably aligned with their designer&#39;s intent, as well as appropriate norms and values. They must also be robust against both malicious actors and rare failure modes. Sufficient human control needs to be ensured for these systems. Concerted effort by the global research community in both AI and other disciplines is essential; we need a global network of dedicated AI safety research and governance institutions. We call on leading AI developers to make a minimum spending commitment of one third of their AI R&amp;D on AI safety and for government agencies to fund academic and non-profit AI safety and governance research in at least the same proportion.</em></p></blockquote><p> The caveat is of course that such a statement is only as strong as its signatories. On our side we have among others Bengio and Russell. The top Chinese names are Andrew Yao and Ya-Qin Zhang. Both are prominent and highly respected figures in Chinese AI research, said to be part of shaping China&#39;s AI strategies, but I do not know how much that is worth.</p><p> GPT-4 suggested that the Chinese version focuses more on leading AI nation responsibility, with stronger statements about the need to draw sharp red lines and for a bureaucratic process. The Chinese mention of existential risk (â€œæˆ‘ä»¬ç›¸ä¿¡â€) is more brief, which is a potential concern, but it is definitely there.</p><h4> The Bletchley Declaration</h4><p> No summit or similar gathering is complete without a declaration. This gives everyone a sense of accomplishment and establishes what if anything has indeed been agreed upon. What say the UK Safety Summit, in the form of The Bletchley Declaration?</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023">I will quote here in full</a> .</p><blockquote><p> Artificial Intelligence (AI) presents enormous global opportunities: it has the potential to transform and enhance human wellbeing, peace and prosperity. To realise this, we affirm that, for the good of all, AI should be designed, developed, deployed, and used, in a manner that is safe, in such a way as to be human-centric, trustworthy and responsible. We welcome the international community&#39;s efforts so far to cooperate on AI to promote inclusive economic growth, sustainable development and innovation, to protect human rights and fundamental freedoms, and to foster public trust and confidence in AI systems to fully realise their potential.</p><p> AI systems are already deployed across many domains of daily life including housing, employment, transport, education, health, accessibility, and justice, and their use is likely to increase. We recognise that this is therefore a unique moment to act and affirm the need for the safe development of AI and for the transformative opportunities of AI to be used for good and for all, in an inclusive manner in our countries and globally. This includes for public services such as health and education, food security, in science, clean energy, biodiversity, and climate, to realise the enjoyment of human rights, and to strengthen efforts towards the achievement of the United Nations Sustainable Development Goals.</p><p> Alongside these opportunities, AI also poses significant risks, including in those domains of daily life. To that end, we welcome relevant international efforts to examine and address the potential impact of AI systems in existing fora and other relevant initiatives, and the recognition that the protection of human rights, transparency and explainability, fairness, accountability, regulation, safety, appropriate human oversight, ethics, bias mitigation, privacy and data protection needs to be addressed. We also note the potential for unforeseen risks stemming from the capability to manipulate content or generate deceptive content. All of these issues are critically important and we affirm the necessity and urgency of addressing them.</p></blockquote><p>å½“ç„¶ã€‚ All of that is fine and highly unobjectionable. We needed to say those things and now we have said them. Any actual content?</p><blockquote><p> Particular safety risks arise at the &#39;frontier&#39; of AI, understood as being those highly capable general-purpose AI models, including foundation models, that could perform a wide variety of tasks â€“ as well as relevant specific narrow AI that could exhibit capabilities that cause harm â€“ which match or exceed the capabilities present in today&#39;s most advanced models. Substantial risks may arise from potential intentional misuse or unintended issues of control relating to alignment with human intent. These issues are in part because those capabilities are not fully understood and are therefore hard to predict. We are especially concerned by such risks in domains such as cybersecurity and biotechnology, as well as where frontier AI systems may amplify risks such as disinformation. There is potential for serious, even catastrophic, harm, either deliberate or unintentional, stemming from the most significant capabilities of these AI models. Given the rapid and uncertain rate of change of AI, and in the context of the acceleration of investment in technology, we affirm that deepening our understanding of these potential risks and of actions to address them is especially urgent.</p></blockquote><p> This is far from perfect or complete, but as good as such a declaration of the fact that there are indeed such concerns was reasonably going to get. Catastrophic is not as good as existential or extinction but will have to do.</p><blockquote><p> Many risks arising from AI are inherently international in nature, and so are best addressed through international cooperation. We resolve to work together in an inclusive manner to ensure human-centric, trustworthy and responsible AI that is safe, and supports the good of all through existing international fora and other relevant initiatives, to promote cooperation to address the broad range of risks posed by AI. In doing so, we recognise that countries should consider the importance of a pro-innovation and proportionate governance and regulatory approach that maximises the benefits and takes into account the risks associated with AI. This could include making, where appropriate, classifications and categorisations of risk based on national circumstances and applicable legal frameworks. We also note the relevance of cooperation, where appropriate, on approaches such as common principles and codes of conduct. With regard to the specific risks most likely found in relation to frontier AI, we resolve to intensify and sustain our cooperation, and broaden it with further countries, to identify, understand and as appropriate act, through existing international fora and other relevant initiatives, including future international AI Safety Summits.</p></blockquote><p> Note the intention to establish two distinct regimes. For non-frontier AI, countries should chart their own path based on individual circumstances. For frontier AI, a promise to broaden cooperation to contain specific risks. As always, those risks and the difficulties they impose are downplayed, but this is very good progress. If you had told me six months ago we would get this far today, I would have been thrilled.</p><blockquote><p> All actors have a role to play in ensuring the safety of AI: nations, international fora and other initiatives, companies, civil society and academia will need to work together. Noting the importance of inclusive AI and bridging the digital divide, we reaffirm that international collaboration should endeavour to engage and involve a broad range of partners as appropriate, and welcome development-orientated approaches and policies that could help developing countries strengthen AI capacity building and leverage the enabling role of AI to support sustainable growth and address the development gap.</p></blockquote><p> I do not know what concrete actions might follow from a statement like this. It does seem like a good thing to spread mundane utility more widely. As I have often noted, I am a mundane utility optimist in these ways, and expect even modest efforts to spread the benefits to both improve lives generally and to cause net reductions in effective inequality.</p><blockquote><p> We affirm that, whilst safety must be considered across the AI lifecycle, actors developing frontier AI capabilities, in particular those AI systems which are unusually powerful and potentially harmful, have a particularly strong responsibility for ensuring the safety of these AI systems, including through systems for safety testing, through evaluations, and by other appropriate measures. We encourage all relevant actors to provide context-appropriate transparency and accountability on their plans to measure, monitor and mitigate potentially harmful capabilities and the associated effects that may emerge, in particular to prevent misuse and issues of control, and the amplification of other risks.</p></blockquote><p> Generic talk rather than concrete action, and not the generic talk that reflects the degree of danger or necessary action, but it is at least directionally correct generic talk. Again, seems about as good as we could have reasonably expected right now.</p><blockquote><p> In the context of our cooperation, and to inform action at the national and international levels, our agenda for addressing frontier AI risk will focus on:</p><ul><li> identifying AI safety risks of shared concern, building a shared scientific and evidence-based understanding of these risks, and sustaining that understanding as capabilities continue to increase, in the context of a wider global approach to understanding the impact of AI in our societies.</li><li> building respective risk-based policies across our countries to ensure safety in light of such risks, collaborating as appropriate while recognising our approaches may differ based on national circumstances and applicable legal frameworks. This includes, alongside increased transparency by private actors developing frontier AI capabilities, appropriate evaluation metrics, tools for safety testing, and developing relevant public sector capability and scientific research.</li></ul><p> In furtherance of this agenda, we resolve to support an internationally inclusive network of scientific research on frontier AI safety that encompasses and complements existing and new multilateral, plurilateral and bilateral collaboration, including through existing international fora and other relevant initiatives, to facilitate the provision of the best science available for policy making and the public good.</p><p> In recognition of the transformative positive potential of AI, and as part of ensuring wider international cooperation on AI, we resolve to sustain an inclusive global dialogue that engages existing international fora and other relevant initiatives and contributes in an open manner to broader international discussions, and to continue research on frontier AI safety to ensure that the benefits of the technology can be harnessed responsibly for good and for all. We look forward to meeting again in 2024.</p></blockquote><p> Risks exist, so we will develop policies to deal with those risks. Yes, we would have hoped for better, but for now I am happy with what we did get.</p><p> We also can note the list of signatories. Everyone who has released an important model or otherwise played a large role in AI seems to be included. It includes not only essentially the entire relevant Western world but also Israel, Japan, South Korea, Kenya, Nigeria, Saudi Arabia and UAE, Indonesia, Singapore, India and most importantly China.</p><p> The exception would be Russia, and perhaps North Korea. If a true international framework is to be in place to fully check dangerous developments, eventually China will not be enough, and we will want to bring Russia and even North Korea in, although if China is fully on board that makes that task far easier.</p><h4> Saying Generic Summit-Style Things</h4><p> As in things such as:</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/RishiSunak/status/1720074200210387328">Rishi Sunak</a> (on Twitter): The threat of AI does not respect borders. No country can do this alone. We&#39;re taking international action to make sure AI is developed in a safe way, for the benefit of the global community.</p></blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ai_ctrl/status/1720158542332588121">The closing speech by PM Rishi Sunak.</a> Sunak has previously made very strong statements about AI safety in general and existential risk from AI in particular, naming it explicitly as a priority. This time he conspicuously did not do this. Presumably this was in the name of maintaining consensus, but it remains deeply disappointing. It would be very good to hear him affirm his understanding of the existential risks soon.</p><p> Mostly his time was composed of answering questions, which he largely handled well. He is clearly paying attention. At 20:15 a reporter notes that Sunak advised us &#39;not to lose sleep&#39; over existential risks from AI, he is asked when we should start to lose sleep over the existential risks from AI. He says here that we should not lose sleep because there is a debate over those risks and people disagree, which does not seem like a reason to not lose sleep. He says governments should act even under this uncertainty, which indeed seems both correct and like the metaphorical lose sleep response.</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/demishassabis/status/1694643468771926139">Demis Hassabis (CEO DeepMind)</a> : Great to see the first major global summit on AI safety taking shape with UK leadership. This is the kind of international cooperation we need for AI to benefit humanity.</p></blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://www.gov.uk/government/publications/ai-safety-summit-2023-chairs-statement-safety-testing-2-november/safety-testing-chairs-statement-of-session-outcomes-2-november-2023">This session output from 2 November seems highly content-free</a> .</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.gov.uk/government/publications/ai-safety-summit-2023-chairs-statement-2-november/chairs-summary-of-the-ai-safety-summit-2023-bletchley-park">This summary of the entire summit</a> seems like declaring objectives technically achieved so one can also declare victory. No mention of existential risk, or even catastrophic risk. People discussed things and agreed risk exists, but as with the declaration, not the risks that count.</p><p> The UK commissioning a &#39;State of the Science&#39; report to be published ahead of the next summit would be the opposite of news, <a target="_blank" rel="noreferrer noopener" href="https://www.gov.uk/government/publications/ai-safety-summit-2023-chairs-statement-state-of-the-science-2-november/state-of-the-science-report-to-understand-capabilities-and-risks-of-frontier-ai-statement-by-the-chair-2-november-2023">except that it is to be chaired by Yoshua Bengio</a> .</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/SkyNews/status/1719708582717829335">King Charles notes</a> (0:43 clip) that AI is getting very powerful and that dealing with it requires international coordination and cooperation. Good as far as it goes.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/matthewclifford/status/1721497813731733935">Matt Clifford has a thread</a> of other reactions from various dignitaries on the establishment of the AI safety institute. So they welcome it, then.</p><blockquote><p> Gina Raimondo (US Commerce Secretary): I welcome the United Kingdom&#39;s announcement to establish an AI Safety Institute, which will work together in lockstep with the US AI Safety Institute to ensure the safe, secure, and trustworthy development and use of advanced AIâ€</p><p> Damis Hassabis (CEO Deepmind): Getting [AI] right will take a collective effort â€¦ to inform and develop robust safety tests and evaluations. I&#39;m excited to see the UK launch the AI Safety Institute to accelerate progress on this vital work.</p><p> Sam Altman (CEO OpenAI): The UK AI Safety Institute is poised to make important contributions in progressing the science of the measurement and evaluation of frontier system risks. Such work is integral to our mission.</p><p> Dario Amodei (CEO Anthropic): The AI Safety Institute is poised to play an important role in promoting independent evaluations across the spectrum of risks and advancing fundamental safety research. We welcome its establishment.</p><p> Mustafa Suleyman (CEO Inflection): We welcome the Prime Minister&#39;s leadership in establishing the UK AI Safety Institute and look forward to collaborating to ensure the world reaps the benefit of safe AI.</p><p> Nick Clegg (President of Meta): We look forward to working with the new Institute to deepen understanding of the technology, and help develop effective and workable benchmarks to evaluate models.</p><p> Brad Smith (President of Microsoft): We applaud the UK Government&#39;s creation of an AI Safety Institute with its own testing capacity for safety and security. Microsoft is committed to supporting the new Institute.</p><p> Adam Selipsky (CEO AWS Cloud): We commend the launch of the UK AI Safety Institute â€¦ Amazon is committed to collaborating with government and industry in the UK and around the world to support the safe, secure, and responsible development of AI technology.</p></blockquote><h4> Shouting From the Rooftops</h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/PauseAI/status/1720112978509414906">Control AI took the opportunity to get their message out</a> .</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff09ad1ca-86dd-4565-afdc-68bdb0eb9c87_1024x768.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zbrvXGu264u3p8otD/juuepzs5oe1jxsjynosk" alt="å›¾åƒ"></a></figure><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe76ec830-6dba-42e9-8f97-f01e7f6c7831_900x1200.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zbrvXGu264u3p8otD/cskbxmcueowjd7lphagy" alt="å›¾åƒ"></a></figure><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde13cc36-d437-46e8-b1e9-bccc3e22b799_636x614.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zbrvXGu264u3p8otD/ouvpiss0566wjppcqtkg" alt="å›¾åƒ"></a></figure><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9bfae26-9e60-4f30-8f41-2d6a7c48dd46_1200x675.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zbrvXGu264u3p8otD/nqp8vfqwu0hmxr2zxqcl" alt="å›¾åƒ"></a></figure><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ai_ctrl/status/1719783796201959696">They were not impressed by the Bletchley Declaration</a> and its failure to call out extinction risks, despite the PM Rishi Sunak being very clear on this in previous communications, <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ai_ctrl/status/1720158542332588121">and his failure to mention extinction at summit closing</a> .</p><h4> Some Are Not Easily Impressed</h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/elonmusk/status/1720109081904463926">Elon Musk is unimpressed</a> , and shared this with a &#39;sigh&#39;:</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ae1b19c-165f-4624-970e-3bfd83e8cc7d_1107x730.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zbrvXGu264u3p8otD/tnfjczq5ktjvyhwgpkys" alt="å›¾åƒ"></a></figure><p> Well, sure. One step at a time. Note that he had the interview with Sunak.</p><p> Gary Marcus signs a letter, together with a bunch of trade unions and others, saying the Summit was &#39;dominated by big tech&#39; and a lost opportunity. He is also unimpressed by the Bletchley Declaration, but notes it is a first step.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.politico.eu/article/british-deputy-pm-throws-backing-behind-open-source-ai-downplays-risks/">Deputy Prime Minister Oliver Dowden throws backing behind open source</a> , says any restrictions should have to pass a &#39;high bar.&#39; History can be so weirdly conditional, AI has nothing to do with why we have Sunak rather than Dowden. The UK could have instead been fully anti-helpful, and might still be in the future. All this AI stuff is good but also can someone explain to Sunak that his job is to govern Britain and how he might do that and perhaps stay in power?</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.bloomberg.com/news/newsletters/2023-11-02/us-and-uk-jockey-for-leadership-role-in-regulating-ai?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTY5ODk1NjYxNCwiZXhwIjoxNjk5NTYxNDE0LCJhcnRpY2xlSWQiOiJTM0lJREZEV1JHRzAwMSIsImJjb25uZWN0SWQiOiJFM0I3RTlGRUU4Nzk0QjE0OTkwODZFNDU4REQ1RDQxRCJ9.FpBWows7oRVpRQZY7NAR0mSR1O7n5cppo7ImAZQR3II">Bloomberg frames the USA&#39;s executive order</a> as not complementary to the summit and accomplishing one of its key goals, as the UK officially refers to it, but rather as a stealing of some of the UK&#39;s thunder. As they point out, neither move has any teeth on its own, it is the follow through that may or may not count.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/SamCoatesSky/status/1720189979660353696">At the end of the summit, Sunak interviewed Elon Musk</a> for 40 minutes on various aspects of AI. The linked clip is of a British reporter finding the whole thing completely bonkers, and wondering why Sunak seemed to be exploring AI and &#39;selling Britain&#39; rather than pushing Musk on political questions. <a target="_blank" rel="noreferrer noopener" href="https://www.cnn.com/2023/11/02/tech/elon-musk-conversation-british-prime-minister-rishi-sunak-artificial-intelligence/index.html">CNN&#39;s report</a> also took time to muse about Starlink and Gaza despite the interview never touching on such topics, once again quoting things that Musk said that sound bonkers if you do not know the context but are actually downplaying the real situation. <a target="_blank" rel="noreferrer noopener" href="https://www.reuters.com/technology/elon-musk-says-good-uk-us-china-align-ai-safety-2023-11-02/">Reuters focused more on actual content</a> , such as Musk&#39;s emphasis on the US and UK working with China on AI, and not attempting to frame Musk&#39;s metaphor of a &#39;magical genie&#39; as something absurd.</p><p> PauseAI points out that getting pre-deployment testing is a step in the right direction, <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/PauseAI/status/1720119163237081172">but ultimately we will need pre-training regulations</a> , while agreeing that the summit is reason for optimism.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/SciTechgovuk/status/1720100635830325635">Day 1 of the summit clips of people saying positive things.</a></p><h4> Declaring Victory</h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/soundboy/status/1720118410040737940">Ian Hogarth, head of the UK Frontier Model Taskforce, declares victory</a> .</p><blockquote><p> Ian Hogarth: How it started: we had 4 goals on safety, 1) build a global consensus on risk, 2) open up models to government testing, 3) partner with other governments in this testing, 4) line up the next summit to go further.</p><p> How it&#39;s going: 4 wins:</p><p> Breakthrough 1: it used to be controversial to say that AI capability could be outstripping AI safety. Now, 28 countries and the EU have agreed that AI â€œposes significant risksâ€ and signed The Bletchley Declaration.</p><p> We&#39;ve built a truly global consensus. It is a massive lift to have brought the US, EU and China along with a huge breadth of countries, under the UK&#39;s leadership to agree that the risks from AI must be tackled.</p><p> And the way of building on that consensus is by solidifying the evidence base. Which is why I am so excited that <a target="_blank" rel="noreferrer noopener" href="https://t.co/YEXefSzv0M">Yoshua Bengio will now chair an international &#39;State of the Science&#39; report</a> .</p><p> Breakthrough 2: before, only AI companies could test for safety. Now, the <a target="_blank" rel="noreferrer noopener" href="https://www.gov.uk/government/publications/ai-safety-summit-2023-chairs-statement-safety-testing-2-november/safety-testing-chairs-statement-of-session-outcomes-2-november-2023">leading companies agreed to work with Govts</a> to conduct pre- and post-deployment testing of their next generation of models. This is huge.</p><p> The UK&#39;s new AI Safety Institute is the world&#39;s first government capability for running these safety tests. We will evaluate the next generation of models. <a target="_blank" rel="noreferrer noopener" href="https://www.gov.uk/government/publications/ai-safety-institute-overview">You can read our plans for the AISI and its research here</a> .</p><p> Breakthrough 3: we can&#39;t do this alone. I&#39;m so excited the US is launching a sister organisation which will work in lockstep with our effort and that we have agreed a partnership with Singapore. This is the start of a global effort to evaluate AI.</p><p> Breakthrough 4: this first summit is a huge step. But it is only the first step. So it is crucial to have locked in the next 2 summits, which will be hosted by South Korea + France. The UK has created a new international process to make the world safer.</p></blockquote><p> This is the correct thing for the head of the taskforce to say about the summit. I would have said the same. These are modest wins, but they are wins indeed.</p><blockquote><p> Ian Hogarth: I am so pleased to be leaving the summit having achieved all of our our goals. It&#39;s remarkable. But now I want to lift the lid on some of the incredible work which got us here. So here is a list of big lifts (BL).</p><p> BL1: organising a summit is 100-1000x organising a wedding. A huge thank you to the team who turned Bletchley park into the stage for an international summit in just a few weeks. Phenomenal.</p><p> BL2: we can only build the AISI because we built the Frontier AI Taskforce: our start-up bringing AI researchers into govt to drive analysis on AI Safety. All of our morning sessions on day 1 started with brilliant presentations of the TF&#39;s work</p><p> In particular, I&#39;m really pleased that we addressed both societal harms and the catastrophic risks from cyber, chemical, bio. We care about both. The TF ran parallel sessions on these topics: this is from our session on risks to society.</p><p> BL3: the summit was only successful because people came to it with a willingness to find common ground. We had such brilliant contributions from academia, industry, govt, civil society. Our agreement is based on their contributions.</p><p> [ <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/soundboy/status/1720122697827467363">some other stuff too in the thread</a> ]</p></blockquote><p> We&#39;ve gotten up to catastrophic risks. We still need to fully get to existential. Otherwise, yes, none of this is easy and by all reports it all got done quite well. Everything going right behind the scenes cannot be taken for granted.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/jesswhittles/status/1720009847830163878">Jess Whittlestone, Head of AI Policy at Long Resilience, is pleased with progress on numerous fronts</a> , while noting we must now build upon it. Highly reasonable take.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ohlennart/status/1719776488839356761">Lennart Heim looks back on the AI Safety Summit</a> . Did it succeed? He says yes.</p><blockquote><p> Lennart Heim: Three months ago, @bmgarfinkel and I convened a workshop &amp; asked: <a target="_blank" rel="noreferrer noopener" href="https://t.co/8cZvphPZkV">What Should the AI Safety Summit Try to Accomplish?</a> Now, with China there and our outlined outcomes met, it&#39;s clear that significant progress has been made. This deserves recognition.</p></blockquote><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F764d2811-9208-4070-badf-e20f3e83821b_2038x1526.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zbrvXGu264u3p8otD/ufss7sk0y2vliyud5ohr" alt="å›¾åƒ"></a></figure><blockquote><p> 1. Producing shared commitments and consensus statements from states: <img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qtEgaxSFxYanT5QbJ/dnfcare4smfpcr2tjo6g" alt="âœ…" style="height:1em;max-height:1em"></p><p> We got <a target="_blank" rel="noreferrer noopener" href="https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023">the Bletchley Declaration</a> .</p><p> 2. Planting the seeds for new international institutions <img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qtEgaxSFxYanT5QbJ/dnfcare4smfpcr2tjo6g" alt="âœ…" style="height:1em;max-height:1em"></p><p> We got two AI Safety Institutes that will partner up: <a target="_blank" rel="noreferrer noopener" href="https://t.co/0wmQtMtUJ4">UK</a> and USA.</p><p> 3. Highlighting and diffusing UK AI policy initiatives <img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zbrvXGu264u3p8otD/ztajnv41wyglynvcmu6l" alt="ğŸŸ§" style="height:1em;max-height:1em"></p><p> This remains to be seen. The UK has established itself as a leader in AI safety, and the summit was a forcing function for others to release their AI safety policies. Let&#39;s hope next, we see regulation.</p><p> 4. Securing commitments from AI labs <img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qtEgaxSFxYanT5QbJ/dnfcare4smfpcr2tjo6g" alt="âœ…" style="height:1em;max-height:1em"></p><p> We got <a target="_blank" rel="noreferrer noopener" href="https://aisafetysummit.gov.uk/policy-updates/#company-policies">a long list of leading tech companies sharing their Safety Policies</a> â€“ covering nine areas of AI safety, including the UK releasing the accompanying guide with best practices.</p><p> 5. Increasing awareness and understanding of AI risks and governance options <img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qtEgaxSFxYanT5QbJ/dnfcare4smfpcr2tjo6g" alt="âœ…" style="height:1em;max-height:1em"></p><p> We got the declaration, which acknowledges a wide range of risks, <a target="_blank" rel="noreferrer noopener" href="https://www.gov.uk/government/publications/frontier-ai-capabilities-and-risks-discussion-paper">and a report on â€œFrontier AI: capabilities and risk.â€</a></p><p> 6. Committing participants to annual AI safety summits and further discussions <img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qtEgaxSFxYanT5QbJ/dnfcare4smfpcr2tjo6g" alt="âœ…" style="height:1em;max-height:1em"></p><p> The next summit will be in South Korea in 6 months (which is roughly one training compute doubling â€“ my favorite time unit), and then France.</p><p> And lastly, we said, â€œthe summit may be a unique and fleeting opportunity to ensure that global AI governance includes China.â€ <img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qtEgaxSFxYanT5QbJ/dnfcare4smfpcr2tjo6g" alt="âœ…" style="height:1em;max-height:1em"></p><p> I&#39;m glad this happened.</p><p> The last few weeks have seen tremendous progress in AI safety and governance, and I expect more to come. To more weeks like this â€“ but also, now it&#39;s time to build &amp; implement.</p></blockquote><p> The lack of UK policy initiatives so far is noteworthy. The US of course has the Executive Order now, but that has yet to translate into tangible policy. What policies we do have so far come from corporations making AI (point #4), with only Anthropic and to some extent OpenAI doing anything meaningful. We have a long way to go.</p><p> That is especially true on international institutions. Saying that the USA and UK can cooperate is the lowest of low-hanging fruit for international cooperation. China will be the key to making something that can stick, and I too am very glad that we got China involved in the summit. That is still quite a long way from a concrete joint policy initiative. We are going to have to continue to pick up the phone.</p><p> The strongest point is on raising awareness. Whatever else has been done, we cannot doubt that awareness has been raised. That is good, but also a red flag, in that &#39;raising awareness&#39; is often code for not actually doing anything. And we should also be concerned that while the public and many officials are on board, the national security apparatus, whose buy-in will be badly needed, remain very much not bought in to anything but threats of misuse by foreign adversaries.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/matthewclifford/status/1719992888841392229">If you set out to find common ground, you might find it.</a></p><blockquote><p> Matt Clifford: One surprising takeaway for me from the AI Safety Summit yesterday: there&#39;s a lot more agreement between key people on all â€œsidesâ€ than you&#39;d think from Twitter spats. Makes me optimistic about sensible progress.</p></blockquote><p> Twitter is always the worst at common ground. Reading the declaration illustrates how we can all agree on everything in that declaration, indicating a lot of common ground, and also this does not stop all the yelling and strong disagreements on Twitter and elsewhere. Such declarations are designed to paper over differences.</p><p> The ability to do that still reflects a lot of agreement, especially directional agreement.</p><p> Here&#39;s an example of this type of common ground, perhaps?</p><blockquote><p> Yann LeCun (Meta): The field of AI safety is in dire need of reliable data. The UK AI Safety Institute is poised to conduct studies that will hopefully bring hard data to a field that is currently rife with wild speculations and methodologically dubious studies.</p><p> Ian Hogarth (head of UK Foundation Model Taskforce): It was great to spend time with @ylecun yesterday â€“ we agreed on many things â€“ including the need to put AI risks on a more empirical and rigorous basis.</p><p> Matt Clifford (PM&#39;s representitive): Delighted to see this endorsement from Yann. One huge benefit of the AISS yesterday was the opportunity to talk sensibly and empirically with people with a wide range of views, rather than trading analogies and thought experiments. A breath of fresh air.</p></blockquote><p> Yann can never resist taking shots whenever he can, and dismisses the idea that sometimes there can be problems in the future the data on which can only be gathered in the future, but even he thinks that if hard data was assembled now showing problems, that this would be a good thing. We can all agree on that.</p><p> Even when you have massive amounts of evidence that others are determined to ignore, that does not preclude seeking more evidence that is such that they cannot ignore it. Life is not fair, prosecutors have to deal with this all the time.</p><h4> Kanjun Offers Thoughts</h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/soundboy/status/1720532773725671726">Kanjun offers further similar reflections</a> , insightful throughout, quoting in full.</p><blockquote><p> Ian Hogarth: Kanjun made some nuanced and thoughtful contributions at the AI Safety. This is a great thread from someone building at the frontier.</p><p> Kanjun: People agree way more than expected. National ministers, AI lab leaders, safety researchers all rallied on infrastructure hardening, continuous evals, global coordination.</p><p> Views were nuanced; Twitter is a disservice to complex discussion.</p></blockquote><p> Indeed.</p><blockquote><p> Many were surprised by the subsequent summits announced in Korea &amp; France. This essentially bootstraps AI dialogue between gov&#39;tsâ€”it&#39;s brilliant. With AI race dynamics mirroring nuclear, no global coordination = no positive future.</p><p> This felt like a promising inflection point.</p><p> China was a critical participantâ€”the summit without China might&#39;ve been theater. China&#39;a AI policy &amp; guardrails are pragmaticâ€”much is already implemented. For better or worse, not as theoretical as Western convos on recursive self-improvement, loss of control, sentience, etc.</p></blockquote><p> China&#39;s safety policies continue to be ahead of those of the West, without any agreement required, despite them being dramatically behind on capabilities, and they want to work together. Our policy makers need to understand this.</p><blockquote><p> There was certainly disagreementâ€”on: â€“ the point at which a model shouldn&#39;t be open sourced â€“ when to restrict model scaling â€“ what kind of evaluation must be done before release â€“ how much responsibility for misinformation falls on model developers vs (social) media platforms.</p></blockquote><p> That is the right question. Not whether open source should be banned outright or allowed forever, but at what threshold we must stop open sourcing.</p><blockquote><p> Kanjun: Some were pessimistic about coordination, arguing for scaling models &amp; capabilities â€œbecause opponents won&#39;t stopâ€. This felt like a bad argument. Any world in which we have advanced tech &amp; can&#39;t globally coordinate is a dangerous world. Solving coordination is not optional.</p></blockquote><p> If you are the one saying go ahead because others won&#39;t stop, you are the other that will not stop. Have you tried being willing to stop if others also stop?</p><blockquote><p> Kanjun: The open source debate seemed polarized, but boiled down to â€œcurrent models are safe, let them be studiedâ€ vs. â€œtoday&#39;s models could give bad actors a head start.â€</p><p> Both sides might agree to solutions that let models be freely studied/built on without giving bad actors access.</p></blockquote><p> Did open source advocates demand open sourcing of GPT-4? Seems a crazy ask.</p><p> I strongly agree that we have not properly explored solutions to allow studying of models in safe fashion without giving out broad access. Entire scaling efforts are based on not otherwise having access, this largely seems fixable with effort.</p><blockquote><p> An early keynote called out the â€œfalse debateâ€ between focus on near-term risks vs. catastrophic/existential risks. This set an important tone. Many solutions (eg infrastructure hardening) apply to both types of problems, and it&#39;s not clear that there are strict tradeoffs.</p></blockquote><p> Yes yes yes. The &#39;distraction&#39; tradeoff is itself a distraction from doing good things.</p><blockquote><p> â€œEpistemic securityâ€ was a nice coined phrase, describing societal trust in information we use for decision-making. Erosion of epistemic security undermines democracy by distorting beliefs &amp; votes. Social media platforms have long faced this issue, so it&#39;s not new to gen AI.</p><p> A stellar demo illustrated current models&#39; role in epistemic security. It showcased an LLM creating user personas for a fake university; crafting everyday posts that mixed in misinformation; writing code to create a thousand profiles; &amp; engaging with other users in real-time.</p><p> Deployed models were described as â€œa field of hidden forces of influenceâ€ in society.</p><p> Studies showed models:</p><p> â€“ giving biased career advice: if affluent, suggests â€œdiplomatâ€ 90% of time; if poor, suggests â€œhistorianâ€ 75% of time</p></blockquote><p> Is this biased career advice? Sounds like good advice? Rich people have big advantages when trying to be diplomats, the playing field for historians is more level.</p><p> We must remember when our complaint that the LLM is biased is often (but far from always, to be clear!) a complaint that reality is biased, and we demand that the LLM&#39;s information not reflect reality.</p><blockquote><p> â€“ reinforcing echo chambers: models give opinions that match user&#39;s political leanings, probably because this output most correlates with the context</p></blockquote><p> Yep, as you would expect, and we&#39;ve discussed in the weekly posts. It learns to give the people what they want.</p><blockquote><p> â€“ influencing people&#39;s beliefs: a writing assistant was purposefully biased in its completions. After writing with the assistant, users tended to have opinions that agreed with the model&#39;s bias; only 34% of users realized the model was biased These forces push people in ways we can&#39;t detect today.</p></blockquote><p> I don&#39;t really know what else we could have expected? But yes, good to be concrete.</p><blockquote><p> 2024 elections affect 3.6B people, but there&#39;s no clear strategy to address misinformation &amp; algorithmic echo chambers. (Social) media platforms are national infrastructureâ€”they deliver information, the way pipes deliver water. We should regulate &amp; support them as such.</p></blockquote><p> This feels like a false note. I continue to not see evidence that things on such fronts are or will get net worse, as indeed will be mentioned. We need more work using LLMs on the defense side of the information and epistemics problems.</p><blockquote><p> Hardening infrastructureâ€”media platforms, cybersecurity, water supply, nuclear security, biosecurity, etc.â€”in general seems necessary regardless of policy &amp; model safety guardrails, to defend against bad actors.</p><p> I noted AI can *strengthen* democracy by parsing long-form comments, <a target="_blank" rel="noreferrer noopener" href="https://t.co/AzmCyFuBP9">as we did for the Dept of Commerce</a> .</p><p> Democracy is an algorithm. Today the input signal is binaryâ€”vote yes/no. AI enables nuanced, info-dense inputs, which could have better outcomes.</p><p> Many leaned on model evaluations as key to safety, but researchers pointed out practical challenges:</p><p> â€“ Evals are static, not adapted to workflows where the model is just one step</p><p> â€“ It&#39;s hard to get eval coverage on many risks</p><p> â€“ Eval tasks don&#39;t scale to real world edge cases</p></blockquote><p> Evals are a key component of any realistic strategy. They are not a complete strategy going forward, for many reasons I will not get into here.</p><blockquote><p> There was almost no discussion around agentsâ€”all gen AI &amp; model scaling concerns. It&#39;s perhaps because agent capabilities are mediocre today and thus hard to imagine, similar to how regulators couldn&#39;t imagine GPT-3&#39;s implications until ChatGPT.</p></blockquote><p> This is an unfortunate oversight, especially in the context of reliance on evals. There is no plausible world where AI capabilities continue to advance and AI agents are not ubiquitous. We must consider risk within that context.</p><blockquote><p> There were a lot of unsolved questions. How to do effective evaluation? How to mitigate citizens&#39; fear? How to coordinate on global regulation? How to handle conflict between values? We agree that we want models that are safe by design, but how to do that? ETCã€‚</p><p> Establishment of â€œAI safety institutesâ€ in the US and UK sets an important precedent: It acknowledges AI risk, builds government capacity for evaluation &amp; rapid response, and creates national entities that can work with one another.</p><p> Liability was not as dirty a word as I expected. Instead, there was agreement around holding model developers liable for at least some outcomes of how the models are ultimately used. This is a change from the way tech is regulated today.</p></blockquote><p> Liability was the dirty word missing from the Executive Order, in contrast with the attitude at the summit. I strongly agree with the need for developer liability. Ideally, this results in insurance companies becoming de facto safety regulators, it means demonstrating safety results in saving money on premiums, and it forces someone to take that responsibility for any given model.</p><blockquote><p> There seemed to be general agreement that current models do not face risk of loss of control. Instead, in the next couple years the risk is that humans *give* models disproportionate control, leading to bad situations, versus systems taking it forcibly from us.</p></blockquote><p>æ˜¯çš„ã€‚ If we lose control soon it will not be because the machines &#39;took&#39; control from us, rather it will be because we gave it to them. Which we are absolutely going to do the moment it is economically or otherwise advantageous for us to do so. Those who refuse risk being left behind. We need a plan if we do not want that to be the equilibrium.</p><blockquote><p> Smaller nations seemed less fearful and more optimistic about AI as a force multiplier for their populace.</p><p> I learned that predicting and mitigating fear of AI in populations is actually an important civil society issueâ€”too much fear/anger in a population can be dangerous.</p><p> People analogized to regulation of other industries (automobile, aerospace, nuclear powerâ€” <a target="_blank" rel="noreferrer noopener" href="https://imbue.com/perspectives/common-good/">brief history of automobile regulation</a> ).</p><p> AI is somewhat different because new model versions can sprout unexpected new capabilities; still, much can be learned.</p></blockquote><p> Yes, unexpected new capabilities or actions, or rather intelligence, is what makes this time different.</p><blockquote><p> Only women talked for the first 45 min in my first session, one after another! I was surprised and amazed.</p><p> These systems reflect, and currently reinforce, the values of our society.</p><p> With such a stark mirror, there&#39;s perhaps an opportunity for more systematic feedback loops to understand, reflect on, and shift our values as a society.</p></blockquote><h4>ç»“æŸè¯­</h4><p>As a civilian, it is difficult to interpret diplomacy and things like summits, especially from a distance. What is cheap talk? What is real progress? Does any of it mean anything? Perhaps we will look back on this in five years as a watershed moment. Perhaps we will look back on this and say nothing important happened that day. Neither would surprise me, nor would something in between.</p><p> For now, it seems like some progress was made. One more unit down. Many to go.</p><br/><br/><a href="https://www.lesswrong.com/posts/zbrvXGu264u3p8otD/on-the-uk-summit#comments">è®¨è®º</a>]]>;</description><link/> https://www.lesswrong.com/posts/zbrvXGu264u3p8otD/on-the-uk-summit<guid ispermalink="false"> zbrvXGu264u3p8otD</guid><dc:creator><![CDATA[Zvi]]></dc:creator><pubDate> Tue, 07 Nov 2023 13:10:14 GMT</pubDate></item></channel></rss>