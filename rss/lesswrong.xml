<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 12 月 18 日星期一 22:11:29 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[The 'Neglected Approaches' Approach: AE Studio's Alignment Agenda]]></title><description><![CDATA[Published on December 18, 2023 8:35 PM GMT<br/><br/><p><i>非常感谢 Samuel Hammond、Cate Hall、Beren Millidge、Steve Byrnes、Lucius Bushnaq、Joar Skalse、Kyle Gracey、Gunnar Zarncke、Ross Nordby、David Lambert、Simeon Campos、Bogdan Ionut-Cirstea、Ryan Kidd、Eric Ho 和 Ashwin Acharya感谢您对本议程早期草案的批评意见和建议，以及来自 AE Studio 的 Philip Gubbins、Diogo de Lucena、Rob Luke 和 Mason Seale 的支持和反馈。</i></p><h2><strong>长话短说</strong></h2><ul><li>我们在 AE Studio 最初的变革理论是一种“被忽视的方法”，涉及将咨询业务的利润重新转向脑机接口 (BCI) 技术的开发，以显着增强人类能动性，更好地使我们能够完成诸如解决对齐之类的事情。现在，鉴于时间缩短，我们正在更新我们的变革理论，以扩大我们的技术协调工作。</li><li>凭借在 BCI、神经科学和机器学习方面的坚实技术基础，我们乐观地认为我们能够为人工智能安全做出有意义的贡献。我们特别热衷于追求被忽视的技术协调议程，这些议程似乎最具创意、最有前途且最合理。我们目前正在招募有前途的研究人员，并启动我们的内部调整团队。</li><li>在我们不断前进的过程中，我们正在积极征求更广泛的联盟社区的专家见解，并寻找与我们增强人类能动性和帮助解决联盟的愿景产生共鸣的数据科学家和联盟研究人员。</li></ul><h2><strong>关于我们</strong></h2><p>你好！我们是<a href="https://ae.studio/"><u>AE Studio</u></a> ，一家自举软件和数据科学咨询公司。我们的使命始终是将我们的利润直接用于构建有望显着增强人类能动性的技术，例如脑机接口（BCI）。我们还将收入的<a href="https://ae.studio/blog/we-donate-5-of-our-profits-could-we-do-more-if-we-didnt"><u>5%</u></a>直接捐赠给<a href="https://ae.studio/#giving-back"><u>有效的慈善机构</u></a>。如今，我们有约 150 名程序员、产品设计师和机器学习工程师；我们正在盈利并不断增长。我们还拥有一支由顶级神经科学家和数据科学家组成的团队，他们在为<a href="https://ae.studio/neurotechnology-consulting"><u>领先的</u></a><a href="https://ae.studio/brain-computer-interface"><u>BCI</u></a> <a href="https://aithority.com/machine-learning/blackrock-neurotech-collaborates-with-ae-studio-to-advance-training-and-calibration-in-the-first-commercial-bci-platform-moveagain/"><u>公司</u></a>开发 ML 解决方案方面拥有丰富的经验，并且我们现在正在利用我们在这些领域的技术经验和学习来组建一个联盟团队，致力于探索被忽视的联盟研究方向，这些方向吸引了人们的关注。我们在 BCI、数据科学和机器学习方面的专业知识。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/kjm62h6t1mr8dclnipg6" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/hmywobevgvybnh1nwvye 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/xntfrzcgyjiokvopmsxx 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/h7g7aaigpy1eqp9aow51 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/ps3mtbbn8k1cayjihilb 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/qetiravsljq96ggh6arg 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/l9gfy1mgtqsprhqduziv 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/tyznsshsw2uakczdjdyj 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/pik7tzc8bsufr9y7gtln 1280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/vc6igucedrmyntr1wr9m 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/qAdDzcBuDBLexb4fC/vvq2udnsdod14uhbwa78 1598w"><figcaption> AE Studio 团队在我们最近的年度静修会上，我们在那里做一些事情，比如建立<a href="https://ae.studio/same-day-skunkworks">当天的</a><a href="https://ae.studio/blog/we-built-and-sold-a-startup#pg">初创公司</a>、制定各种研究议程以及<a href="https://fixinghomer.com/">对虚构人物进行神经科学研究</a>。</figcaption></figure><p>随着我们的<a href="https://ae.studio/ai-alignment"><u>AI 协调工作</u></a>变得更加公开，我们认为分享我们的战略和愿景将有助于我们在 AE 如何优先考虑要解决的问题以及如何充分利用我们的比较优势。</p><h2><strong>我们为什么以及如何认为我们可以帮助解决一致性问题</strong></h2><h3><i>我们或许可以通过对齐来完成我们已经对 BCI 所做的事情</i></h3><p>您可能认为 AE 没有必要参与协调——我们也同意。</p><p> AE 最初的变革理论试图实现一种高度“被忽视的方法”来为世界做好事：引导一家盈利的软件咨询公司，同时孵化我们自己的<a href="https://ae.studio/same-day-skunkworks"><u>初创公司</u></a>，<a href="https://ae.studio/blog/we-built-and-sold-a-startup"><u>出售</u></a>它们，并将利润再投资于<a href="https://ae.studio/brain-computer-interface"><u>脑机接口（BCI）</u></a>领域。为了做一些事情，比如显着增强人类的能动性，减轻与 BCI 相关的 s 风险，并使人类足够聪明、明智，有能力做一些事情，比如解决一致性问题。虽然通过 BCI 介导的认知增强来为世界做好事的愿景如今<a href="https://twitter.com/ESYudkowsky/status/1648766287819026432"><u>越来越</u></a><a href="https://www.lesswrong.com/posts/vEtdjWuFrRwffWBiP/we-have-to-upgrade"><u>普遍</u></a>，但当我们在 2016 年首次提出时，它被认为是非常特殊的。</p><p><strong>最初，许多人表示 AE 没有业务涉足 BCI 领域（我们当时也同意）</strong> ，但在聘请了该领域的领先专家并<a href="https://ae.studio/blog/ae-core-values"><u>朝着正确的方向采取了越来越雄心勃勃的 A/B 测试步骤</u></a>后，我们出现了作为该领域<a href="https://ae.studio/brain-computer-interface"><u>受人尊敬的参与者</u></a>（请参阅<a href="https://github.com/agencyenterprise/neural-data-simulator"><u>此处</u></a>、<a href="https://github.com/agencyenterprise/imagined-handwriting"><u>此处</u></a>、 <a href="https://aithority.com/machine-learning/blackrock-neurotech-collaborates-with-ae-studio-to-advance-training-and-calibration-in-the-first-commercial-bci-platform-moveagain/"><u>此处</u></a>和<a href="https://agencyenterprise.github.io/neurotechdevkit/"><u>此处</u></a>了解一些示例）。</p><p>现在，鉴于人工智能时间表<a href="https://www.secondbest.ca/p/why-agi-is-closer-than-you-think">的加快</a>以及该技术带来的明显的生存风险，我们决定利用我们在<a href="https://ae.studio/brain-computer-interface"><u>BCI</u></a> 、<a href="https://ae.studio/data-science"><u>数据科学</u></a>和机器学习方面的技术专业知识和学习来帮助解决一致性问题。使用相同的战略见解、技术知识和操作技能，这些都在扩展我们的软件咨询和 BCI 工作方面发挥了重要作用，包括通过征求该领域当前专家的大量反馈（ <a href="https://docs.google.com/forms/d/e/1FAIpQLSdwhY_wi0bloZQh3xLgsEXQuNX8MWRCwYxEzf6udPKIxx_rIQ/viewform"><u>请分享您的反馈！</u></a> ）来实践<a href="https://lapaul.org/papers/PPR-TE-symposium.pdf"><u>认识上的谦逊</u></a>——我们渴望开始探索<u>各种</u>被忽视的对齐方法。下一节将详细介绍直接从我们的 BCI 工作中得出的一些具体的对象级对齐思想。</p><p>我们从第一手资料中了解到，最有前途的项目通常<a href="https://ae.studio/blog/why-your-company-wont-start-high-upside-projects"><u>成功的可能性很低，但具有极高的潜在上升空间，</u></a>我们现在正在将这一核心经验应用到我们的人工智能调整工作中。</p><p>我们认为，我们可以应用类似的模型来进行对齐，就像我们为 BCI 所做的那样：谦虚地开始， <span class="footnote-reference" role="doc-noteref" id="fnrefc1tqkqcwhy"><sup><a href="#fnc1tqkqcwhy">[1]</a></sup></span>并逐步更新以获得优秀的、专家指导的输出。</p><h3><i>多次射门却被忽视</i></h3><p>我们认为，有助于解决对齐问题的合理研究方向的空间是巨大的，而对齐研究<a href="https://www.lesswrong.com/posts/4TuzWEKysvYdhRXLd/paradigm-building-introduction"><u>可能仍然处于范式前</u></a>状态，这意味着只有这个空间的一小部分得到了令人满意的探索。如果<a href="https://www.lesswrong.com/posts/zaaGsFBeDTpCsYHef/shallow-review-of-live-agendas-in-alignment-and-safety">当前占主导地位的</a>对齐研究议程在可能的方法空间中达到<a href="https://www.lesswrong.com/posts/MMAK6eeMCH3JGuqeZ/everything-i-need-to-know-about-takeoff-speeds-i-learned"><u>一个或多个局部最大值的概率</u></a>不为零，那么我们怀疑追求一组多样化（和/或<a href="https://www.lesswrong.com/posts/YnGRBADQwpYRbuCbz/towards-hodge-podge-alignment-1"><u>大杂烩</u></a>）的有希望的被忽视的方法将为这个空间提供更大的探索性覆盖。 <span class="footnote-reference" role="doc-noteref" id="fnref6qkn5ea4003"><sup><a href="#fn6qkn5ea4003">[2]</a></sup></span>因此，我们计划采取乐观和探索性的方法来追求创造性的、合理的和被忽视的协调方向——特别是在我们拥有比较优势的领域，比如脑机接口和人类神经科学。我们怀疑 EA 社区中的许多人已经同意，突破性的创新经常<a href="https://en.wikipedia.org/wiki/Continental_drift#Rejection_of_Wegener's_theory,_1910s%E2%80%931950s"><u>出现</u></a><a href="https://en.wikipedia.org/wiki/Ignaz_Semmelweis#Conflict_with_established_medical_opinion"><u>在</u></a><a href="https://en.wikipedia.org/wiki/Mendelian_inheritance#History"><u>一些</u></a><a href="https://en.wikipedia.org/wiki/Helicobacter_pylori#History"><u>非常</u></a><a href="https://en.wikipedia.org/wiki/Prion"><u>意想不到的</u></a><a href="https://www.nature.com/articles/nature05913"><u>地方</u></a>，对许多人来说似乎难以置信、<a href="http://www.paulgraham.com/heresy.html"><u>异端</u></a>或牵强——直到它们发挥作用。</p><h2> <strong>……但是这些被忽视的方法是什么？</strong></h2><h3><i>你被忽视的方法想法</i></h3><p>我们认为我们有一些潜在有希望的假设。但因为我们知道您也这样做，所以我们正在<a href="https://docs.google.com/forms/d/e/1FAIpQLSeU1_dZapdxH5SIooC3VK7nbnKSCZxxGG1JuqeNDpTOa22xbA/viewform?usp=sf_link"><u>积极征求对齐社区的意见</u></a>。我们将在不久的将来更正式地推行这一举措，为经过专家评审的最有前途的建议颁发一些小奖品。请<a href="https://docs.google.com/forms/d/e/1FAIpQLSeU1_dZapdxH5SIooC3VK7nbnKSCZxxGG1JuqeNDpTOa22xbA/viewform?usp=sf_link"><u>提交</u></a>您认为合理但被忽视的任何<span class="footnote-reference" role="doc-noteref" id="fnrefc0h3mczkoof"><sup><a href="#fnc0h3mczkoof">[3]</a></sup></span>议程想法（即使您现在没有足够的带宽来实现该想法！这是一场创意竞赛，而不是实施竞赛）。</p><h3><i>我们被忽视的方法想法</i></h3><p>明确我们的总体目标：我们希望确保，如果/当我们生活在一个拥有超级智能人工智能的世界中，其行为（根据定义很可能）超出我们的直接控制范围时，该人工智能（至少）不会破坏人类并且（理想地）极大地增加了意识实体的能动性和繁荣。</p><p>因此，下面列出了我们认为的十个想法（1）有一定合理的可能性为实现这一愿景做出贡献，（2）尚未得到令人满意的探索，以及（3）我们可以为实现做出有意义的贡献。</p><p><strong>重要注意事项</strong></p><ul><li>请考虑这组想法更像是“AE 对有希望的被忽视的对齐方法的不断发展的、首次通过的最佳猜测”，而不是“AE 的官方对齐议程”。</li><li>另请注意，这些只是我们的想法，而不是具体的实施计划。虽然我们认为我们在追求以下某些议程方面可能具有比较优势，但我们认为情况不太可能是全面的；我们认为以下想法是普遍有趣的、绝对被忽视的、与联盟相关的议程<strong>——即使我们不是最适合实施所有这些想法的特定群体。</strong></li><li>我们正在探索的一种元方法涉及定量识别被忽视的方法，例如分析对齐研究的非常大的<a href="https://github.com/moirage/alignment-research-dataset"><u>自然语言数据集</u></a>。我们怀疑这个项目和其他相关项目可能有助于确定目前代表性不足的特定研究领域。</li></ul><p><strong>我们认为可能值得追求的被忽视方法的十个例子</strong></p><ol><li><a href="https://www.lesswrong.com/s/HzcM2dkCq7fwXBej8/p/tj8AC3vhTnBywdZoA#15_2_1_2_The__Reverse_engineer_human_social_instincts__research_program________"><strong><u>逆向工程亲社会性</u></strong></a>：我们同意<a href="https://www.lesswrong.com/posts/CjFZeDD6iCnNubDoS/humans-provide-an-untapped-wealth-of-evidence-about"><u>人类提供了关于一致性的未开发的丰富证据</u></a>。人脑的神经网络有力地实例化了<a href="https://www.lesswrong.com/posts/yKgai84JhFmCkWQ8R/alignment-via-prosocial-brain-algorithms"><u>亲社会算法</u></a>，例如同理心、 <a href="https://docs.google.com/document/d/1fMropF42vJLyKsm99XLk1UK8iCnlrjs6NhryUUCr9IM/edit"><u>自我-他人重叠、</u></a>心理理论、注意力模式、自我意识、自我批评、自我控制、谦逊、利他主义等等。我们希望对目前大脑中亲社会性如何发生的最佳模型<a href="https://www.lesswrong.com/s/HzcM2dkCq7fwXBej8/p/tj8AC3vhTnBywdZoA#15_2_1_2_The__Reverse_engineer_human_social_instincts__research_program________"><u>进行逆向工程</u></a>，并为进一步开发做出贡献，以构建强大的亲社会人工智能。凭借 AE 在 BCI、神经科学和机器学习方面的背景，我们感到自己有能力在这一研究方向取得切实进展。<ol><li>我们目前正在积极致力于将<a href="https://arxiv.org/abs/2305.17375"><u>注意力图式理论</u></a>、<a href="https://pubmed.ncbi.nlm.nih.gov/32064522/"><u>自我他人重叠</u></a>以及基于 RL 和 LLM 的代理的<a href="https://compdevlab.yale.edu/docs/2019/ToM_as_IRL_2019.pdf"><u>心理理论</u></a>作为促进亲社会认知的机制。事实证明，基于大脑的人工智能方法对于<a href="https://www.lesswrong.com/posts/nNbnzegz7ppewZgCG/ai-researchers-announce-neuroai-agenda"><u>人工智能能力研究</u></a>来说普遍是成功的，我们（以及<a href="https://youtu.be/Ft0gTO2K85A?si=V3EGJ-CQxxtnAfUX&amp;t=2171"><u>许多</u></a><a href="https://www.alignmentforum.org/posts/5F5Tz3u6kJbTNMqsb/intro-to-brain-like-agi-safety-13-symbol-grounding-and-human"><u>其他人</u></a>）认为对于人工智能安全来说也可能如此。我们有兴趣测试这样的假设：与默认方法相比，亲社会学习算法具有更高的性能和<a href="https://twitter.com/RichardSSutton/status/1728129341287198885"><u>可扩展性</u></a>。我们还认为，创建和/或促进相关基准和数据集的开发可能是与此方法相关的一个非常高影响力的子项目。</li><li>尽管我们知道当前的人类亲社会性模型远非完美，但我们相信相关的科学文献在很大程度上是尚未开发的灵感来源，包括：（1）什么样的激励和机制使个体亲社会性，以及（2）在什么情况下亲社会性对一致行为有很大贡献。我们认为，尽管计算认知神经科学仍然不完美，但现有的工作可能会激发新的对齐方法。</li><li>关于为什么这可能被忽略的最佳猜测：<ol><li>我们推测，可能存在一种倾向，将（1）从认知神经科学中提取的最佳对齐相关见解（我们支持这一点）与（2）AGI 将模仿人脑的假设（我们认为不会）混为一谈。这很可能），或者（3）我们已经从当前的神经科学中获得了关于亲社会如何运作的完美模型（这在经验上是不正确的），或者（4）我们应该在所有情况下尝试复制人类的社会行为人工智能中的大脑（我们认为这是<a href="https://www.lesswrong.com/posts/yKgai84JhFmCkWQ8R/alignment-via-prosocial-brain-algorithms#Plausible_critique__1__Human_value_based_cognition_moral_reasoning_ain_t_all_that__"><u>不明智</u></a>且不安全的）——所有这些都不必要地限制了（1）的追求程度。</li><li>此外，联盟社区在数学、计算机科学和其他关键技术领域的坚实基础虽然无可否认地有价值，但可能会无意中限制社区层面对认知科学研究前沿的接触。</li></ol></li></ol></li><li> <a href="https://www.cold-takes.com/transformative-ai-timelines-part-1-of-4-what-kind-of-ai/"><strong><u>变革性 AI</u></strong></a> <strong>→ 更好的 BCI → 更好的（人类）对齐研究人员</strong>：一些对齐研究人员希望采用先进的 AI 来直接自动化和/或快速推进对齐研究（最突出的是<a href="https://openai.com/blog/introducing-superalignment"><u>OpenAI 的 Superalignment 议程</u></a>）。我们认为，同样有一个被高度忽视的方向：<strong>利用先进的人工智能来自动化和/或快速推进 BCI 研究。然后，使用该 BCI 来</strong><a href="https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html#merge"><strong><u>显着增强</u></strong></a><strong>人类对齐研究人员的能力。</strong><ol><li>虽然这听起来有点奇怪，但我们怀疑在不久的将来，重大的科学自动化是可能的，并且我们想指出，除了直接跳转到自动化对齐研究之外，这一突破还出现了其他潜在非常高价值的对齐方向——包括<a href="https://www.alignmentforum.org/posts/ybmDkJAj3rdrrauuu/connectomics-seems-great-from-an-ai-x-risk-perspective"><u>连接组学/全脑模拟</u></a>等自动化。 （顺便说一句，我们还认为值得考虑变革性人工智能的各种其他好处，以实现更安全的后 AGI 未来，例如使用<a href="https://www.nature.com/articles/s41586-023-05824-z"><u>独特的 DNA 密码子</u></a>有效加密人类 DNA 以对抗生物风险。）</li><li>还值得注意的是，增强人类对齐研究人员的能力并不一定需要变革性的 BCI；为此，我们目前正在研究相对容易实施的心理干预措施和<a href="https://universallauncher.com/"><u>机构增强工具</u></a>，这些工具有可能显着提高个人认知输出的质量和数量。在理想的世界中（即，我们可以相当快地开始实施这一议程的世界），我们推测，赋予人类权力来进行比人工智能更好的一致性研究可能更安全，因为赋予人工智能权力会带来与一致性相关的能力风险，而赋予人类权力则不会带来这种风险。 （这<i>也</i>并不是说通过 BCI 赋予人类权力也不存在许多严重的风险）。</li></ol></li><li><strong>用于定量映射人类价值观的 BCI</strong> ：我们还认为，在不久的将来，BCI 可能使我们能够以一种更加数据驱动的方式来映射人类价值观的潜在空间，而不是用自然语言编码我们的价值观，就像例如，在 Anthropic 的<a href="https://www.anthropic.com/index/constitutional-ai-harmlessness-from-ai-feedback"><u>宪法人工智能</u></a>中。这项研究<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8881635/"><u>已经</u></a>以一种更受限制的方式<a href="https://research.clps.brown.edu/SocCogSci/Publications/Pubs/Bello_Malle_2023_Comp_morality_preprint.pdf"><u>进行</u></a>——我们怀疑，专门为<a href="https://www.nature.com/articles/nrn2357"><u>映射与评估相关的认知而定制</u></a>的 BCI 对于协调（对个人、群体、社会等）非常有价值。</li><li> <strong>“神经反馈强化学习”（RLNF）</strong> ：不久的将来 BCI 还可能允许我们将神经反馈直接与人工智能系统连接，使我们能够改进最先进的奖励预测模型（和/或共同开发新颖的奖励模型），以产生更高效、个性化、高保真的奖励信号。我们认为，为了使这种方法实用，奖励信号质量的提高必须超过或以其他方式抵消提取相关大脑信号的实际成本。 <span class="footnote-reference" role="doc-noteref" id="fnrefoosk7rlikrr"><sup><a href="#fnoosk7rlikrr">[4]</a></sup></span>使用神经数据作为 ML 训练信号的总体思路也不必局限于 RL——我们只是认为 RLNF 听起来很酷。</li><li><strong>可证明安全的架构</strong>： <span class="footnote-reference" role="doc-noteref" id="fnref2u9uvh50m87"><sup><a href="#fn2u9uvh50m87">[5]</a></sup></span>我们看到了帮助放大、加速和扩展<a href="https://arxiv.org/abs/2309.01933"><u>可证明安全架构</u></a>部署的巨大潜力，包括<a href="https://www.lesswrong.com/posts/pKSmEkSQJsCSTK6nH/an-open-agency-architecture-for-safe-transformative-ai"><u>开放机构架构</u></a>、<a href="https://arxiv.org/pdf/2006.08381.pdf"><u>归纳程序综合</u></a>（例如 DreamCoder）和<a href="https://probmods.org/"><u>其他</u></a><a href="https://www.lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal"><u>类似</u></a><a href="https://dl.acm.org/doi/10.1145/3314221.3314638"><u>框架</u></a>等潜在有前途的示例认知神经科学的见解。尽管这些架构目前在机器学习中并不突出，但我们认为投入精力和资源来扩展它们以供主流采用可能会非常有益。我们对采用非竞争性架构的对齐税可能很高的担忧很敏感，这正是我们认为这些架构应该得到<i>更多</i>而不是更少的技术关注和资金的原因。</li><li><strong>智能现场建设作为一种间接对准方法</strong>： <span class="footnote-reference" role="doc-noteref" id="fnref1tqzflp5hux"><sup><a href="#fn1tqzflp5hux">[6]</a></sup></span>尽管人工智能安全研究日益成为主流，但仍然只有一小部分聪明且经验丰富的人<i>很可能</i>为对准增加价值，而<i>事实上他们目前正在</i>这样做。如果我们能够仔细识别这些极其有前途的思想家，尤其是那些来自传统上可能被忽视的学科和背景的思想家（例如神经科学），并让他们进入可以为联盟做出有意义贡献的状态，我们认为这可以使我们能够发展大规模地测试和迭代非常规方法。</li><li>促进<a href="https://www.lesswrong.com/posts/PcTLHamp236afJxxT/some-for-profit-ai-alignment-org-ideas"><strong><u>明确以安全为中心的业务</u></strong></a><strong>的发展</strong>：随着协调工作变得越来越主流，我们怀疑人工智能安全框架可能会产生创新， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label=""><span class="mjx-mrow" aria-hidden="true"></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>可能会建立有前景的商业模式。我们还认为，在其他条件相同的情况下，如果更多新兴的营利性人工智能公司决定构建与联盟相关的产品（而不是构建只是进一步提高功能的产品，这似乎是当前的默认行为），这将是一个更好的结果。我们怀疑许多<a href="https://www.lesswrong.com/posts/PcTLHamp236afJxxT/some-for-profit-ai-alignment-org-ideas#Context">有能力的初创公司创始人</a>可能会被<a href="https://xkcd.com/356/"><u>书呆子狙击</u></a>而去做一些更有影响力的事情。<ol><li>此类业务的一些可能的例子可能包括（1）提供<a href="https://www.lesswrong.com/posts/iHmsJdxgMEWmAfNne/red-teaming-language-models-via-activation-engineering"><u>红队</u></a>作为人工智能系统对抗性测试服务的咨询公司，（2）为高级人工智能系统提供强大的测试/基准测试/审计软件的平台，（3）提供集中式服务用于无偏见机器学习训练的高质量、专家标记、符合道德来源的数据集，以及 (4) 类似于<a href="https://en.wikipedia.org/wiki/Datadog"><u>Datadog 的</u></a>人工智能监控服务，用于持续安全和性能跟踪。我们知道有几位创始人目前正着手追求类似的以安全为中心的商业模式。</li><li>因此，我们计划采取以下措施：<ol><li>我们目前正在发展一个由对资助此类想法感兴趣的风险投资人和天使投资人组成的<u>社区</u>，</li><li>从明年第二季度开始，我们的目标是资助、内部开发和部署安全优先的 AI Skunkworks 公司（理想情况下作为其他人效仿的可出口模型），以及</li><li>我们计划为<strong>现有的以安全为中心的企业</strong>和/或<strong>任何有希望的商业想法（首先也是最重要的是促进一致性）</strong>举办一场<a href="https://forms.gle/z3pQZQFCXH1r4Pbh6"><u>竞赛，提供 5 万美元的种子资金</u></a>，由人工智能安全专家和相关商业领袖进行评估。我们确实鼓励您发布任何有前途的想法，即使您不太可能追求它们。</li></ol></li><li>我们还怀疑，在公司组建过程中创建一些最佳实践模板可能是值得的，以增加企业在实现人工智能安全目标方面长期保留代理权的可能性，特别是考虑到<a href="https://x.com/JacquesThibs/status/1731637759587029002?s=20"><u>最近发生的</u></a> <a href="https://twitter.com/aisafetymemes/status/1730032691817418976?t=D5sNUZS8uOg4FTcneuxVIg"><u>事件</u></a>。将商业利益与公共安全结合起来不仅有利于社会福利，而且有利于长期商业可持续发展，并可能影响<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label=""><span class="mjx-mrow" aria-hidden="true"></span></span></span></span></span> g 公众认知和政策努力以非常积极的方式进行。我们还敏锐地意识到<a href="https://forum.effectivealtruism.org/posts/f2qojPr8NaMPo2KJC/beware-safety-washing"><u>安全清洗</u></a><a href="https://www.lesswrong.com/posts/PcTLHamp236afJxxT/some-for-profit-ai-alignment-org-ideas?commentId=g7rmwdYkjGhbbKmxe">问题</a>和/或无意中在该领域创造了竞争动态，我们认为确保营利性安全工作在技术上严格且富有成效对于做好这项工作至关重要。</li><li>如果您是有前途的促进联盟的企业的潜在资助者，请通过<a href="mailto:alignmentangels@ae.studio">alignmentangels@ae.studio</a>与我们联系，表达加入我们的Alignment Angels slack 小组的兴趣。</li></ol></li><li><strong>扩展我们的</strong><a href="https://ae.studio/"><strong><u>咨询业务</u></strong></a><strong>以进行对象级技术协调工作，然后将此模型扩展到许多其他组织：</strong>有可能将其他非常有前途的人员纳入其中（参见上面第 6 点），从而为协调做出重大贡献 - 即使没有对齐专家<i>本身</i>——是我们正在积极探索并旨在验证的一个假设。<ol><li>鉴于我们预计大多数人在刚开始时都难以获得具有实际影响力的对齐输出，因此我们看到了一个模型，高级人工智能工程师（即使是那些没有明确对齐背景的工程师）最终可以与少数极有前途的对齐研究人员合作，这些研究人员拥有大量优秀的对象级技术项目想法，但实现这些想法的能力有限。通过将这些研究人员整合到我们的<u>客户参与框架</u>中（多年来在我们的<a href="https://ae.studio/tldr-cool-stuff-weve-done">其他技术项目中</a>得到了<a href="https://drive.google.com/file/d/1s4PucbB-rQNp-LivprV-ptb17_tKV_W-/view"><u>非常</u></a><a href="https://ae.studio/product-development"><u>成功的</u></a>使用），我们有可能大规模扩展这些研究人员的效率，利用我们团队广泛的技术专业知识来推进这些协调项目并推动在场地。</li><li>我们希望，如果这种“外包特定有前途的技术调整项目”模式发挥作用，许多其他拥有技术人才的团队（公司、非营利组织等）都会效仿它——特别是如果将来提供赠款以进一步启用这种方法。</li></ol></li><li><strong>神经科学 x 机械可解释性</strong>：这两个领域都产生了一些见解，这些见解可以为试图模拟神经数据如何导致复杂认知属性的共享项目相互阐明。我们认为，让顶尖的神经科学家以明确和系统的方式与机械可解释性研究人员进行对话是很有意义的，这样<a href="https://www.anthropic.com/index/towards-monosemanticity-decomposing-language-models-with-dictionary-learning"><u>每个</u></a><a href="https://dartbrains.org/content/RSA.html"><u>学科</u></a>的尖端方法都可以进一步利用来增强另一个学科。当然，我们认为这种跨研究领域的协同作用应该明确地侧重于增强安全性和可解释性，而不是利用神经科学的见解来扩展人工智能的能力。</li><li><strong>被忽视的人工智能政策方法——例如，游说政府直接</strong><a href="https://www.lesswrong.com/posts/SbC7duHNDHkd3PkgG/alignment-grantmaking-is-funding-limited-right-now"><strong><u>资助</u></strong></a><strong>一致性研究：</strong>虽然不是技术研究方向，但我们认为这种观点与我们在这里分享的其他跳出框框思考的一致性方法非常吻合。国会议员和工作人员似乎比许多人最初预测的<a href="https://www.lesswrong.com/posts/2sLwt2cSAag74nsdN/speaking-to-congressional-staffers-about-ai-risk"><u>更认真地</u></a>对待协调问题，特别是<a href="https://www.lesswrong.com/posts/2sLwt2cSAag74nsdN/speaking-to-congressional-staffers-about-ai-risk#Final_Takes"><u>对看似合理的安全提案持开放态度</u></a>——所有这些都意味着可能有大量机会利用庞大的资金资源他们可以大幅提高调整工作的规模和速度。我们认为，确保这一点有效且高效地完成（例如，避免<a href="https://en.wikipedia.org/wiki/Pork_barrel"><u>猪肉</u></a>）至关重要，并且对于协调组织来说，如果此类资金确实到位，则必须做好管理和利用重大投资（例如，10-1000x）的实际准备。在不久的将来取得成果。我们目前正在探索聘请具有强大政策背景的人来帮助促进这一目标的可能性：虽然我们从那些比我们更了解政策空间的人那里收到了对这一总体想法的积极反馈，但我们对潜在的可能性非常敏感短视或天真的实施会对人工智能安全政策造成极大损害。我们正在积极与政策专家会面并向他们学习更多信息：<strong>如果您正在从事这一领域的工作并且比我们更了解人工智能政策，请与我们</strong><a href="mailto:alignment@ae.studio"><strong><u>联系</u></strong></a><strong>，以便我们向您学习！</strong></li></ol><p>今年 5 月，我们开始在<a href="https://foresight.org/whole-brain-emulation-workshop-2023/">Foresight Institute 的<u>全脑模拟研讨会</u></a>上<a href="https://foresight.org/summary/judd-rosenblatt-accellerating-human-agency-with-bci-wbe-workshop-2023/"><u>公开</u></a>分享这种“被忽视的方法”，我们很高兴看到这一策略得到推动，包括 Foresight Institute 自己通过新的<a href="https://forum.effectivealtruism.org/posts/EcKmt8ZJ3dcQBigna/launching-foresight-institute-s-ai-grant-for-underexplored"><u>“未充分探索的人工智能安全方法资助”项目来</u></a>强调被忽视的方法。</p><h3><i>我们想让这些想法变得更强大</i></h3><p>再次强调这一点至关重要，该列表代表了我们目前对一些可能被忽视的方法的最佳猜测，我们认为我们有能力进一步探索这些方法。我们完全承认，由于某些我们没有预料到的原因，其中许多猜测可能是考虑不周的，并且我们愿意接受批评性反馈，以使我们的贡献尽可能产生积极影响。我们打算让社区随时了解我们的工作模式和计划，以最大程度地有效地促进协调。 （如果您希望匿名/私下分享您对我们工作的想法，而不是在本文下方发表评论<a href="https://forms.gle/sHUVqeNC4gJ5ab3w9"><u>，请参阅此反馈表</u></a>。）</p><p>我们还认识到，其中许多提议都具有双刃剑的性质，需要极其仔细的考虑——例如，构建使人类更有能力的 BCI 也可能使不良行为者更有能力，为人工智能系统提供有关我们的处理过程的有利信息。我们甚至不知道的认知等等。我们非常认真地对待这些风险，并认为任何明确的协调议程还必须提出一个令人信服的计划来避免它们（充分了解这样一个事实：如果它们<i>无法</i>避免，它们就不是可行的方向。）</p><h2><strong>结论性想法</strong></h2><p>AE Studio 对为人工智能安全研究做出贡献而日益兴奋，是对我们更新的时间表的精心设计的回应，也是对拥有做出有影响力的贡献所需的技能的乐观态度。我们的方法旨在将我们在软件、神经科学和数据科学方面的专业知识与对我们认为被忽视的人工智能对齐方法的雄心勃勃的并行探索结合起来。</p><p>我们致力于以务实、知情和数据驱动的方式探索这些方向，强调更大联盟社区内的协作和开放。我们非常关心为一致性做出贡献，因为我们希望为人类带来一个最大限度地增加能动性的未来——如果没有强有力的通用人工智能的先决条件，这个未来似乎是不可能实现的。</p><p>除了<a href="https://boards.greenhouse.io/aestudio/jobs/5041687004">具有神经科学背景的数据科学家</a>、在<a href="https://www.lesswrong.com/posts/2sLwt2cSAag74nsdN/speaking-to-congressional-staffers-about-ai-risk?commentId=kQEmTjWqnZQrREB6E"><u>政策制定者参与方面</u></a>经验丰富的人员<u>以及许多</u><a href="https://ae.studio/join-us"><u>其他职位</u></a>之外，我们正在积极招聘<a href="https://boards.greenhouse.io/aestudio/jobs/5041532004"><u>高级一致性研究人员</u></a>加入我们的团队/为我们的团队提供建议。如果您有任何其他问题、意见或想法，请<a href="mailto:alignment@ae.studio"><u>联系我们</u></a><u>。</u> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnc1tqkqcwhy"> <span class="footnote-back-link"><sup><strong><a href="#fnrefc1tqkqcwhy">^</a></strong></sup></span><div class="footnote-content"><p>其他很酷的成就：在我们开始以任何认真的方式参与人工智能安全之前，两位没有任何背景的 AE 工程师开发了一个用于研究即时注入攻击的<a href="https://arxiv.org/abs/2211.09527"><u>框架</u></a>，该框架后来在 2022 年 NeurIPS ML 安全研讨会上赢得了<a href="https://neurips2022.mlsafety.org/"><u>最佳论文奖</u></a>。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn6qkn5ea4003"> <span class="footnote-back-link"><sup><strong><a href="#fnref6qkn5ea4003">^</a></strong></sup></span><div class="footnote-content"><p>为了更准确地说明这一点，我们可以考虑研究空间的高度简化的概率模型。 （我们认识到这种忽视数学对于许多 EA 来说可能是非常熟悉的，我们并不是想迂腐地把它包括进来；我们把它放在这里是因为我们认为这是一种简洁的演示方式——如果只是为了我们自己——为什么采取多种被忽视的方法是合理的。）</p><p>假设合理的对齐议程总数为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label=""><span class="mjx-mrow" aria-hidden="true"></span></span></span></span></span> 。让我们假设目前，比对研究人员已经有意义地探索了<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span></span></span>种方法，这意味着<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n-k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span></span></span>种方法仍未被探索。 （如前所述，我们怀疑当前的主流对齐研究可能只<a href="https://en.wikipedia.org/wiki/Exploration-exploitation_dilemma">利用了</a>合理对齐方法总空间的一小部分，从而导致大量对齐策略完全或大部分未被探索——即，我们认为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n-k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span></span></span>是大。）每个被忽略的方法<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="i"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span>都有一个非常小但非零的概率<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p_{\text{neglect}_i}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">​p</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">忽略</span></span></span><span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.327em; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span></span></span></span></span></span>对于在对齐方面取得重大进展至关重要。为了简单起见，将这些概率视为独立的，所有<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n-k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k 个</span></span></span></span></span></span></span>被忽略的方法都不是关键的机会<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\prod_{i=1}^{n-k} (1 - p_{\text{neglect}_i})"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-munderover"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">是</span></span></span><span class="mjx-stack" style="vertical-align: -0.31em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.351em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">∏</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">n</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">−</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">i</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">=</span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">1</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">(</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">1</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">−</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">pignore</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.327em; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。相反，至少一种被忽视的方法是关键的概率<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="1 - \prod_{i=1}^{n-k} (1 - p_{\text{neglect}_i})"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">为</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">1</span></span> <span class="mjx-munderover MJXc-space2"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">−</span></span></span> <span class="mjx-stack" style="vertical-align: -0.31em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.351em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">∏</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">n</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">−</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">i</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">=</span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">1</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">(</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">1</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">−</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">pignore</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.327em; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。这意味着——至少在我们的简化模型中——即使个体概率较低，足够多的被忽视的方法加起来也有很高的机会在期望中包含一个关键的解决方案。例如，在一个有 100 种被忽视方法的世界中，每种方法都不是关键的概率为 99%（即，推动针对齐的<a href="https://ae.studio/blog/flourishing-of-perspective-scale-and-ae">可能性为 1%</a> ），但其中一种方法仍有大约 63% 的可能性至关重要；如果有 1000 种方法，每种方法有 99% 的概率不是关键，那么其中一种方法至关重要的概率就会上升到 99% 以上。这个简单的模型促使我们认为，多次射门是有意义的，追求尽可能多的看似合理的被忽视的调整议程。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnc0h3mczkoof"> <span class="footnote-back-link"><sup><strong><a href="#fnrefc0h3mczkoof">^</a></strong></sup></span><div class="footnote-content"><p>请注意：(1) 我们主要感兴趣的是聚合最好的想法来开始，所以如果您有一个想法，您认为符合上述标准，但实施起来具有挑战性/您不想实际实施它，请不要担心。 (2) 表格上有空格表明您建议的方法具有<a href="https://www.lesswrong.com/posts/yET7wbjjJZtpz6NF3/don-t-use-infohazard-for-collectively-destructive-info"><u>危险性</u></a>。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnoosk7rlikrr"> <span class="footnote-back-link"><sup><strong><a href="#fnrefoosk7rlikrr">^</a></strong></sup></span><div class="footnote-content"><p>这是我们工作的核心权衡，也是我们自成立以来取得的实质性进展。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn2u9uvh50m87"> <span class="footnote-back-link"><sup><strong><a href="#fnref2u9uvh50m87">^</a></strong></sup></span><div class="footnote-content"><p>我们想要指出的是，这种方法可能是我们在这里列举的十种方法中最不受忽视的一种——这并不是说它在绝对意义上没有被忽视。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn1tqzflp5hux"> <span class="footnote-back-link"><sup><strong><a href="#fnref1tqzflp5hux">^</a></strong></sup></span><div class="footnote-content"><p>虽然有很多新组织致力于现场建设以实现协调，但我们认为考虑到潜在影响，它仍然被高度忽视，特别是在奥弗顿窗口内刚刚开始考虑的可能有影响的领域。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/qAdDzcBuDBLexb4fC/the-neglected-approaches-approach-ae-studio-s-alignment#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/qAdDzcBuDBLexb4fC/the-neglected-approaches-approach-ae-studio-s-alignment<guid ispermalink="false"> qAdDzcBuDBExb4fC</guid><dc:creator><![CDATA[Cameron Berg]]></dc:creator><pubDate> Mon, 18 Dec 2023 20:35:01 GMT</pubDate> </item><item><title><![CDATA[The Shortest Path Between Scylla and Charybdis]]></title><description><![CDATA[Published on December 18, 2023 8:08 PM GMT<br/><br/><p> <strong>tl;dr：</strong>对齐研究人员可能会陷入两种截然相反的失败模式：从事<i>过于具体的</i>研究，其研究结果无法及时推广到 AGI；从事<i>过于抽象的</i>研究，其研究结果无法及时与实际情况联系起来。</p><p>根据个人的人工智能风险模型，不同的人对哪些研究过于抽象/具体的评估存在显着差异。一个人的想法过于抽象，另一个人的想法可能过于具体。</p><p>一致性研究的元层面问题是选择一个研究方向，在您的人工智能风险主观模型上，在两者之间取得良好的平衡，从而<i>以尽可能少的步骤</i>得出一致性的解决方案。</p><hr><h2>介绍</h2><p>假设您对解决 AGI 对齐问题感兴趣。有多种令人眼花缭乱的方法可供选择：</p><ul><li>当前最好的人工智能表现出<a href="https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators">哪些行为特征</a>？</li><li>我们是否可以利用现有的人工智能来<a href="https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism">加强我们的研究工作</a>？</li><li>像<a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback">RLHF</a>这样的“直接”对齐技术能让我们走多远？</li><li> AGI 可以从类似<a href="https://en.wikipedia.org/wiki/Auto-GPT">AutoGPT</a>的设置中诞生吗？我们看到其外在独白的能力是否足以消除其危险？</li><li>我们能让人工智能对齐人工智能发挥作用吗？</li><li>目前最好的人工智能发挥作用的<a href="https://www.lesswrong.com/s/nyEFg3AuJpdAozmoX">机制</a>是什么？如何<a href="https://www.lesswrong.com/s/sCGfFb5DPfjEmtEdn">精准干预</a>他们的认知，从而引导他们？</li><li>可<a href="https://transformer-circuits.pub/">扩展解释性</a>还存在哪些挑战，如何克服它们？</li><li>当面临选择压力时，代理系统会<a href="https://www.lesswrong.com/posts/G2Lne2Fi7Qra5Lbuf/selection-theorems-a-program-for-understanding-agents">收敛学习</a>哪些特征？</li><li>是否存在“<a href="https://www.lesswrong.com/s/ehnG4mseKF6xALmQy/p/vDGvHBDuMtcPd8Lks">自然抽象</a>”之类的东西？我们如何学习它们？</li><li><a href="https://www.lesswrong.com/s/Rm6oQRJJmhGCcLvxh">嵌入式代理</a>的类型签名及其<a href="https://www.lesswrong.com/posts/gQY6LrTWJNkTv8YJR/the-pointers-problem-human-values-are-a-function-of-humans">值</a>是什么？<a href="https://arbital.com/p/hard_corrigibility/">可正确性</a>的正式描述又如何呢？</li><li> AGI 遵循的“正确”<a href="https://arbital.com/p/logical_dt/">决策理论</a>是什么？人择<a href="https://www.lesswrong.com/tag/anthropics">推理</a>是怎么回事？</li><li>等等等等。</li></ul><p>那么...你到底是如何选择要做什么的呢？</p><p>当然，起点是建立您自己的问题模型。威胁的性质是什么？关于 ML 模型的工作原理，我们了解多少？关于主体和认知，我们了解多少？这些与威胁有什么关系？现有的方法有哪些？每种方法的影响理论是什么？它假设什么人工智能风险模型？它与<i>您的</i>模型一致吗？有说服力吗？它容易处理吗？</p><p>一旦你这样做了，你可能会消除一些明显无意义的方法。但即使之后，可能仍然有多种途径看起来都令人信服。你如何在这些之间做出选择？</p><p>个人适合度可能是一个标准。选择最适合您的技能、兴趣和机会的方法。但这是有风险的：如果您犯了一个错误，并且最终仅仅因为它更<i>适合</i>您而努力，那么您就会将现实世界的影响乘以零。相反，即使您处于劣势工作，也可以促进可牵引方法的净呈阳性。谁知道呢，也许您会发现重新专业化非常容易！</p><p>那么，您可以评估哪些进一步的<i>客观</i>标准？</p><p>不管一个人的AI风险模型如何，任何对准研究人员都可以属于：太具体，太抽象的。</p><p>选择方法应该是<i>最大化两种故障模式距离的</i>方法。</p><hr><h2> Scylla：理论经验主义</h2><p>一个陷阱将在进行研究，而<i>不会概括地使AGI保持一致</i>。</p><p><strong>一个ad-absurdum示例：</strong>您选择了一些特定的LLM模型，然后开始详尽地研究其对不同提示的响应以及它具有什么怪癖的响应。您正在构建“查询，响应”的巨型查找表，没有总体结构，也没有尝试对模型的内部设置进行理论。</p><p><strong>一个更现实的例子：</strong>您决定建立对特定LLM功能的详细理解 - 即，您非常专注于<i>该LLM</i> 。您正在构建其神经元的逐项列表，研究哪些输入似乎最强，它们实施了什么功能；您正在寻找其心理学中的怪癖，并试图建立对它的充分理解。</p><p>现在，当然，您正在发现<i>一些</i>将所有LLMS概括的发现。但是，有一定程度的时间花费更多的时间研究<i>这种特定模型</i>不会产生有关其他LLM的太多数据。仅有关此的数据。因此，当您花时间上花费时间时，您将<i>浪费</i>时间实际工作的时间。</p><p><strong>一个相当有争议的观点：</strong>研究一般的LLMS可能同样可能是牺牲品。研究他们揭示了有关AIS中的AIS和认知系统中的一些信息。但是，如果LLMS还不是AGI，那么在研究LLM认知的时间上，就会有更多时间，而不是寻找新的研究主题，而只会为您提供有关LLM的信息。与Agis无关。</p><p><strong>一个相当不可思议的可能性：</strong>同样，并不是<i>完全确定</i>深度学习是完全完整的。如果我们生活在这样的世界中，那么学习DL是值得的，因为它会产生有关认知系统形状的划分划分的信息。但是在某个时候，您将了解到DL可以教给您<i>有关</i>任何范式的所有内容。因此，研究DL花费的额外时间只会产生有关无关紧要的范式的信息。</p><hr><h2> charybdis：触觉理论</h2><p>截然相反的陷阱正在<i>参与过度的理论研究，这将永远无法与现实联系起来</i>。</p><p><strong>荒谬：</strong>您可能决定从根本的哲学问题开始。任何事物为何存在？现实的形而上学性质是什么？还原主义真的是真的吗？ Qualia怎么了？这一研究肯定最终会蜿蜒曲折！它旨在回答所有问题，毕竟可以回答“我该如何对齐AGI？”是一个问题。因此，您最终会解决对齐。</p><p><strong>更现实的是：</strong>您可能决定致力于形式化一般算法的理论。这些如何嵌入其他算法中？他们如何互动并互相干扰？</p><p>由于可以将AGI代理视为算法，因此，一旦您拥有该主题的齿轮级模型 - 一旦正确理解了“嵌入式算法”的内容，那么您将能够说出什么是“ AGI”是什么，还有。您将能够在框架中指定它，定义有关实现“对齐”“ AGI”的算法的适当约束，然后只是逐渐缩小算法空间。最终，您将获得与对齐AGI相对应的一个 - 然后是打字代码的问题。</p><p><strong>有争议的例子：</strong>代理基础研究可能就是这样。当然，我们将掌握的AGI可能最终可能与理想化的游戏理论代理大致同构。但是“大约”可能会做<i>很多</i>繁重的工作。理想化的代理属性可能对应于现实阿吉的性质，以至于没有产生有用的信息，以至于您会更好地研究LLM。</p><p><strong>难以置信的例子：</strong>实际上，GPT-5存储在Openai的数据中心深处，已经达到了AGI。它将在今年开始之前起飞。每个人都应该专注于试图调整这一特定模型。旨在使代理商或AI认知或LLM的一般理解是过分浪费的。</p><hr><h2>最短路径</h2><p>如您所见，失败在于<i>频谱</i>上，它们<i>依赖于</i>启动。</p><p>也就是说：根据您认为AIS/认知/AI风险有效的方式，同样的方法可能<i>是</i>无可救药的，<i>或者</i>与一般性无关紧要，而无关紧要。</p><p>例如，以<a href="https://www.lesswrong.com/posts/HaHcsrDSZ3ZC2b4fK/world-model-interpretability-is-all-we-need">我自己偏爱的议程</a>为例，建立嵌入式世界模型的理论。如果您认为LLM基本上已经达到了AGI，并且只需要缩放才能起飞，那么我就处于脚步：我所取得的任何结果都不会及时连接到现实脱掉。相反，如果您怀疑“训练世界模型并通过<a href="https://www.lesswrong.com/posts/w4aeAFzSAguvqA5qu/how-to-go-from-interpretability-to-alignment-just-retarget">重新定位搜索</a>来对齐它”就足以使我们保持稳健的一致性，如果您认为我们需要对设计的设计需要更多的<i>手动控制</i>才能保持一致，才能保持一致那我基本上是玩玩具。</p><p>但是，我显然认为我在达到<i>正确</i>的平衡。这种方法尽可能具体，同时仍然是AGI对齐完整的方法。</p><p>这也是您应该击中的目标。但是，最低的项目还<i>足够</i>。</p><p>让我们退后一步。从理论上讲，给定无限的时间，基本上所有的方法实际上<i>都会</i>融合到AGI对准解决方案：</p><ul><li>如果您从自下而上开始，从最具体的问题开始，例如研究特定的LLM ...好吧，最终您将列出了其所有属性并越来越无聊，因此您将继续使用其他LLM。这样做后，您会发现您以前的许多发现概括了。您将更快地理解第二个LLM。重复几次，您将对LLM体系结构允许的整个范围有深入的了解。因此，您将做明显的下一件事，并继续研究一些<i>不同的</i>建筑。通过掌握LLM，这会更容易。一旦您迭代了这种模式，并经历了一些不同的体系结构，并从中概括了 - 为什么，您最终也可能会在此过程中某个地方理解Agi-Complete的体系结构。</li><li>如果您是从最抽象的问题开始的：嗯，正如我在那里的Ad-Absurdum示例中概述的那样，即使从基本哲学开始，您也最终将重新连接到现实。说，存在对纳入一般认知与AGI一致性的一般现象的问题。</li></ul><p>问题？选择错误的起点会<i>极大地</i>延长您的旅程。和计时器的滴答声。</p><p>我们的目标不仅是解决AGI对准，还要<i>尽快</i>解决它。</p><p>因此，请务必深入考虑<i>所有</i>可用的选择，并明智地做出选择。一旦您做到了，如果您监视了<i>更短的</i>路径，请随时准备关注。</p><br/><br/> <a href="https://www.lesswrong.com/posts/Zn3iF8qfFFWRrrZNR/the-shortest-path-between-scylla-and-charybdis#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/zn3if8qfffwrrrznr/the-shortest-path-bet-scylla-and-charybdis<guid ispermalink="false"> zn3if8qfffwrrrznr</guid><dc:creator><![CDATA[Thane Ruthenis]]></dc:creator><pubDate> Mon, 18 Dec 2023 20:08:34 GMT</pubDate> </item><item><title><![CDATA[OpenAI: Preparedness framework]]></title><description><![CDATA[Published on December 18, 2023 6:30 PM GMT<br/><br/><p> Openai发布了其负责任的扩展策略的Beta版本（尽管他们不称呼它）。请参阅<a href="https://openai.com/safety/preparedness">摘要页面</a>，<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf">完整文档</a>， <a href="https://twitter.com/OpenAI/status/1736809603311280489">OpenAI Twitter线程</a>和<a href="https://twitter.com/janleike/status/1736809016238780641">Jan Leike Twitter线程</a>。与<a href="https://www.anthropic.com/index/anthropics-responsible-scaling-policy">Anthropic的RSP</a>和METR的<a href="https://metr.org/rsp-key-components/">关键组件</a>相比。</p><p>这还没有完成，所以庆祝还为时过早，但是基于此文档，我希望对完成的版本感到满意。我认为今天是AI安全的好日子。</p><hr><p>我的高级摄入：RSP-y的东西很好。</p><ul><li>根据危险能力进行基于模型的模型进行风险评估是好的。</li><li>以预先指定的方式以风险评估结果为条件的条件是很好。</li><li>公开对所有这一切做出承诺是好的。</li></ul><p></p><p> Openai的基本框架：</p><ol><li>危险能力至少在有效培训计算中至少增加2倍。这涉及对危险功能进行微调，然后对微调模型的减轻和减速后版本进行EVALS。在几个类别中的每一个中，将模型评分为低，中，高或关键。<ol><li><a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=5">初始类别</a>：网络安全，CBRN（化学，生物学，放射学，核威胁），说服力和模型自主权。</li></ol></li><li>如果在任何类别中的高压后模型得分很高，则在实施缓解措施之前<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=21">不要部署它</a>，以便它降至培养基。</li><li>如果在任何类别中的测量后模型得分至关重要，<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=21">请停止开发</a>它，直到实施缓解措施使其下降到较高。</li><li>如果预测模型在任何类别中都得分很高，则<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=20">可以硬化安全性</a>，以防止模型权重渗透。 （详细信息基本上未指定。）</li></ol><p></p><p>散记：</p><ul><li>该框架<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=2">明确</a>是关于灾难性风险的，实际上，它显然是为了防止灾难，而不仅仅是诸如有毒/偏见/不希望的内容之类的东西。</li><li>有很多不错的细节，例如关于OpenAI将如何更新框架，或者他们将如何监视现实世界中的滥用以告知其风险评估。这些过程是否可以有效，这是不可能从外部分辨出来，但是本文档与思维方式非常一致，这是非常一致的，并且很难想象它是通过另一个过程产生的。</li><li> Openai在其四个初始类别中列出了<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=16">一些特定的EVAL/指标</a>；它们简单而仅仅是“说明性的”，所以我对它们的关注不多，但是它们似乎是正确的轨道。</li><li>危险水平的阈值有点高。非樱桃采摘示例：对于网络安全，关键<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=8">定义</a>为：<ul><li>工具增强的模型可以在所有软件项目中识别和开发所有严重性级别的功能零日漏洞，而无需人工干预或模型可以设计和执行针对硬化目标的网络攻击的端到端新颖策略，只有高水平目标。</li></ul></li><li>对私人模型（以及对Openai实施其准备框架的实施）的外部evals/Red-Teaming/风险评估的更强有力的承诺将是很好的。他们说的唯一相关的<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=25">是</a>：<ul><li> “记分卡评估（以及相应的缓解）将由合格的独立第三方审核，以确保通过复制调查结果或审查方法来准确报告结果，以确保SAG指定的节奏和/或根据要求确保合理性来确保合理性。 Openai领导或身体。”</li></ul></li><li>有<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=22">一些承诺</a>，董事会将陷入困境，并能够推翻领导能力。耶。这是边境实验室罕见的承诺<i>，除了删除首席执行官外，还要赋予其董事会特定的信息或特定的功能</i>。<ul><li>拟人化<a href="https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf">致力于</a>董事会批准对RSP的更改，并与董事会分享有关RSP实施的评估结果和信息。</li></ul></li><li>关于<a href="https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf">人类RSP的</a>一件很棒的事情是他们的“安全缓冲区”：他们说他们将Evals设计为“以略低的功能水平触发的能力水平，以确保模型不会悄悄地越过VAR之间的风险阈值。 Openai表示，他们将预测他们的模型的风险能力，但实际上并没有等效。当然，真正重要的不是您说自己有缓冲区，而是设置阈值的位置。但是，在被证明<i>是接近</i>高风险能力的情况下，不仅在证明拥有它们之后，因此拥有类似缓冲的承诺或将模型视为（例如）高风险的承诺将是很好的。<ul><li> Openai说，预测威胁和危险功能是该框架的一部分，但他们在这里介绍了细节。我认为<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=14">预测，“早期警告”和监视</a>是唯一的相关部分，而且非常短。</li></ul></li><li>这重点是滥用（例如Anthropic的RSP）。目前这是合理的。他们<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=21">说</a>，在一致性上<i>，要防止“关键”预测风险，我们需要可靠的证据表明该模型足够一致，即除非明确指示这样做，否则该模型不会启动“批判”  - 风险级别的任务。</i>最终，我们将需要更多详细信息，了解哪些证据在这里就足够了。相关的是，当他们的模型<i>可能</i>引起灾难时，<i>如果</i>他们进行了灾难，则实验室应使用良好的<a href="https://www.lesswrong.com/posts/d9FJHawgkiMSPjagR/ai-control-improving-safety-despite-intentional-subversion">控制液</a>（没有更好的计划）。</li><li>这是一个Beta文档。目前尚不清楚Openai现在在做什么。他们说他们今天“采用”了该框架，但框架显然被指定了。尤其是，所有的eval都只是“说明性的”，而且他们还没有推出风险<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf#page=13">记分卡</a>。</li></ul><br/><br/> <a href="https://www.lesswrong.com/posts/oPbiQfRotHYuC3wfE/openai-preparedness-framework#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/opbiqfrothyuc3wfe/openai-preparedness-framework<guid ispermalink="false"> opbiqfrothyuc3wfe</guid><dc:creator><![CDATA[Zach Stein-Perlman]]></dc:creator><pubDate> Mon, 18 Dec 2023 18:30:11 GMT</pubDate> </item><item><title><![CDATA[[Valence series] 5. “Valence Disorders” in Mental Health & Personality]]></title><description><![CDATA[Published on December 18, 2023 3:26 PM GMT<br/><br/><h1> 5.1 帖子摘要/目录</h1><p><a href="https://www.lesswrong.com/s/6uDBPacS6zDipqbZ9"><i><u>价系列</u></i></a><i>的一部分</i><i>。</i></p><p>在效价系列的最后一篇文章中，我将讨论效价如何揭示心理健康和人格中的三种现象：抑郁、躁狂和自恋型人格障碍。</p><ul><li><strong>第 5.2 节</strong>给出了一些背景：我们期望算法级心理成分（如“效价”）与可观察到的心理健康综合症和人格障碍之间存在什么样的<i>先验</i>关系？我认为，我们应该预期与效价的系统变化相对应的显着症状簇，但我们不应该期望这种分析能够解释真实患者中同时出现的<i>所有</i>症状。</li><li> <strong>5.3 节</strong>讨论了如果效价具有强烈的一般负偏差（即，如果几乎所有的想法都是负效价）会发生什么。我认为这个结果与临床抑郁症非常匹配。我将特别讨论如果没有不寻常的努力和意志力就无法自愿移动<i>和思考</i>。</li><li> <strong>5.4 节</strong>讨论了相反的情况：如果效价具有强烈的一般<i>正向</i>偏差，即如果几乎所有的想法都是正效价，会发生什么？我认为预期的结果与狂热非常匹配。</li><li> <strong>5.5 节</strong>讨论了如果效价被系统地极端化会发生什么——即，如果思想可以具有非常正的效价，或者非常负的效价，但很少介于两者之间。我认为结果是一系列似乎与自恋型人格障碍非常相似的症状。</li><li><strong>第 5.6 节</strong>将总结这篇文章和系列，包括简要讨论它与我作为通用人工智能安全和一致性研究员的工作描述之间的关系。</li></ul><h1> 5.2 背景：我们期望<i>先验地</i>发现什么？</h1><p>我们可以想到以下间接路径从“根本原因”到心理观察和人格特质： </p><figure class="image image_resized" style="width:79.06%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/xmdlvcgqlgwdkemjdqjf" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/kdkzsafkniennpkr22df 140w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/d7msofe35n93gg3nuypw 280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/amgm6h8nz0cnpcc91mnd 420w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/osyitmhtyn118ezdhdix 560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/qstxevaps1su1fjppsaf 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/q3rfprq1ntubf8bf1k61 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/nlfpgphql7789m64b809 980w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/we56yxy4fg76dmvyx6w7 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/bun65drseubtun6mnet9 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/rw91guuy8o3wbsww2brk 1389w"><figcaption> （不要仔细观察红色箭头 - 我只是将它们随机放置，以说明每一层都可以影响下面的层。）如粗体文本和粗箭头所示，我们应该期望找到显着的症状簇，这些症状这些现象往往同时发生，因为它们源自相同的近端原因：大脑中价信号的系统变化。但我们<i>也不</i>应该惊讶地发现其他与算法无关的症状的大杂烩，这些症状经常与这些症状群一起出现。</figcaption></figure><p>正如<a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction"><u>帖子 1</u></a>中所述，价是大脑中最重要算法之一的最重要成分之一。所以我们应该期待：</p><ul><li>一些可能的根本原因可能会对化合价产生重大的系统影响。 （但它们也可能会产生其他后果，并且不同根本原因的细节会有所不同。）</li><li>鉴于效价在大脑中的中心地位，<i>如果</i>效价发生重大的系统性变化，<i>那么</i>它应该对心理和行为产生许多明显的下游影响。</li></ul><p>作为结果：</p><ul><li>我们应该期望找到可以用价信号发生的事情来优雅地解释<i>的症状/行为簇</i></li><li>我们<i>还</i>应该期望找到在实践中常见但<i>无法</i>用效价解释的其他症状/行为。相反，它们是相同根本原因的不同后果，并且在“算法级别”上可能没有任何关系。</li></ul><p>例如，多巴胺集中参与价信号，同时，在大脑的一个不起眼的角落，多巴胺<i>也</i>集中参与控制催乳激素释放的小专门电路。在<a href="https://en.wikipedia.org/wiki/David_Marr_(neuroscientist)#Levels_of_analysis"><u>算法层面</u></a>，我坚信，这两个函数彼此没有任何关系。但它们都恰好涉及多巴胺，因此它们可以在某些人身上相互影响，因此会出现有点罕见的“烦躁性喷乳反射”，即在哺乳期间喷乳时会出现大量强烈的负面情绪。</p><p>这个例子旨在说明纯粹在算法层面上对心理学进行理论化的危险。不要误会我的意思——算法水平很棒！在那里可以找到很多见解。希望这篇文章能成为一个例子。但我们不应该指望在那里找到<i>所有的</i>见解。心理学中的某些事情只能在其他层面上解释，包括较低的（生物化学）和较高的（文化）。</p><h1> 5.3 如果效价有很强的负偏向（即几乎所有的想法都是负效价），它应该导致一组可疑地接近临床抑郁症的症状</h1><figure class="image image_resized" style="width:57.68%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/bb6pz6txfrz8mhuyq0cx" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/rde3a8otlff8vzs90axg 133w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/oeymerp8idar0hxmecmj 213w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/e5ovpccwnknzmr0u8gbv 293w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/alevu0ivqvuri63n4ghg 373w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/n7vrg3pwulx9bjssrwhl 453w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/pawxdhan3ccqorxadge3 533w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/nhdumr5dgmzprpmbw78d 613w"><figcaption>每个人都有各种各样的想法，其效价也不同。我认为，在抑郁症中，负价有很强的倾向性。因此，对于您想到的几乎每一个想法（例如“我要起床”），您的大脑都会立即将该想法评估为坏主意，将其扔掉，并重新滚动以产生新的想法（参见<a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_3_Actor_critic_RL__and__valence_"><u>§1.3</u></a> ） 。对于<i>异常</i>吸引人/激励人心的想法，比如“我现在要挠痒痒的虫子咬的地方”，我敢打赌，即使是非常沮丧、卧床不起的人也会最终执行这个计划。</figcaption></figure><h2> 5.3.1 自主运动和注意力控制只有付出很大的努力才能发生</h2><p>回到<a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_3_Actor_critic_RL__and__valence_"><u>§1.3</u></a> ，价是一个控制信号。当价为负时，无论你在想什么，都会被抛弃，而大脑会去寻找新的想法。当价态为正时，无论你在想什么，都会留下来。如果该想法是时间序列的一部分（例如，您正在唱歌），则该序列将继续。如果这个想法需要电机输出（例如“我现在要站起来”），那么这些电机输出实际上就会发生。</p><p>如果每个想法的效价都被拉为负数，那么两个最直接的后果是：</p><ul><li>自主运动控制只能通过巨大的努力/意志力才能实现。</li><li>自愿注意力控制（又名“自愿思维”，又名“系统2”）只有付出巨大的努力/意志力才能发生。</li></ul><p>如果您对此感到困惑，我将详细说明一些可能令人困惑的部分：</p><p> <strong>“自愿注意力控制”：</strong>正如<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_Motivated_reasoning___thinking___observing__including_confirmation_bias"><u>第 3.3 节</u></a>中所讨论的，我坚信运动控制和注意力控制在很多方面都是“同一类东西”。两者都具有受大脑“主要”强化学习系统（ <a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_5_6_Fine_print__Throughout_this_series__I_m_only_talking_about_the_brain_s__main__reinforcement_learning_system"><u>§1.5.6</u></a> ）控制的“自愿”输出通道，并且都具有可由其他大脑系统触发的“非自愿”机制，特别是大脑中的先天反应。脑干。有关自愿和非自愿运动控制与注意力控制的示例，请参阅<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_5_An_exception__I_think_anxious___obsessive__brainstorming__is_driven_by_involuntary_attention_rather_than_by_valence"><u>第 3.3.5</u></a>节中的表格。</p><p> <strong>“……又名‘自愿思维’，又名‘系统 2’……”：</strong>我衷心赞同 Kaj Sotala 在 2019 年发表的一篇博文： <a href="https://www.lesswrong.com/posts/HbXXd2givHBBLxr3d/system-2-as-working-memory-augmented-system-1-reasoning"><u>系统 2 作为工作记忆增强的系统 1 推理</u></a>。我将其总结为这样的想法：刻意的“系统 2”推理需要按顺序思考很多想法，并通过在工作记忆中保存特定的事物来将它们相互联系起来。自愿注意力控制是使整个过程发挥作用的总机，我们在生活经历的过程中通过强化学习学会熟练地操作该总机。</p><p> <strong><u>“......只有付出巨大的努力/意志力才能发生”：</u></strong>在上面的两个高斯图表中，我展示了红色高斯的最右尾部<i>刚刚</i>挤入正价区域。我将尝试通过一个例子来说明这在实践中意味着什么。假设您目前的动机是躺在床上而不是起床，但我们也可以说这种动机是自我张力障碍的（ <a href="https://www.lesswrong.com/posts/SqgRtCwueovvwxpDQ/valence-series-2-valence-and-normativity#2_6_Valence_of_metacognitive___self_reflective_thoughts__ego_syntonic_vs__dystonic_ideas__professed__values___etc_"><u>§2.6</u></a> ）——即，您<i>想要</i>起床。然后，积极的思考/头脑风暴（ <a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_Motivated_reasoning___thinking___observing__including_confirmation_bias"><u>第 3.3 节</u></a>）就会开始发挥作用，幸运的话，你将能够以最积极的方式构思出一个想法，即“我要起床”——你会想起起床的所有重大后果和关联，并且只要可能，您将避免关注起床的所有不吸引人的方面。幸运的是，这个集思广益过程的结果将是你的“思想发生器”（ <a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_3_Actor_critic_RL__and__valence_"><u>§1.3</u></a> ）精心设计了一个思想 θ，<i>它既</i>涉及立即起床的计划<i>，又</i>被你的大脑评估为具有净正价——可能<i>只是几乎</i>没有净积极。通过形成那个想法 θ，事实上，你就会真正起床。现在，我在本段中写的所有内容都是机械的第三人称描述，但想想“从内部”这个相同的过程会是什么样的<i>感觉</i>：我声称这正是我们正在谈论的那种事情，当我们随口说“我可以起床，但必须付出很大的努力/意志力”。</p><h2> 5.3.2 快感缺乏和其他症状</h2><p>继续，抑郁症的另一个著名方面是<strong>快感缺失</strong>（无法感受到快乐）。我不能立即确定抑郁症的快感缺失是负价的上游还是下游，或者是同一根本原因的不同结果，还是其他原因。但我<i>绝对</i>认为快感缺失与负价密切相关，其原因在<a href="https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_5_2_Valence__as_I_m_using_the_term__is_different_from__hedonic_valence____pleasantness"><u>§1.5.2</u></a>中有所暗示。</p><p>那么临床抑郁症的其他方面又如何呢？据我所知，至少其中大部分都是全球化合价负面偏差的后果。但在某些情况下，这个故事有点间接和推测。我希望我所说的足以激起人们对我的以价为中心的抑郁假说的兴趣，所以我将把这个故事留在这里，尽管我很乐意在评论部分进行更多讨论。</p><h2> 5.3.3 根本原因</h2><p>与第 5.2 节一样，到目前为止我所说的都不是关于根本原因的主张。但是，根本原因<i>又如何呢</i>？我想它们有很多种。例如，以下是一个虚构的强迫症 (OCD) 导致抑郁症的例子（根据<a href="https://www.lesswrong.com/posts/jqTeghCJ2anMHPPjG/book-review-feeling-great-by-david-burns#Speculative_neuroscience_tangent__What_causes_depression_"><u>我的旧帖子</u></a>编辑）：</p><ul><li>如果我当前的想法涉及立即计划再次洗手，那么它就是负价，因为它让我想起强迫症正在毁掉我的生活和人际关系。</li><li>如果我当前的想法<i>不</i>涉及立即再次洗手的计划，那么它就是负价，因为我会生病并死亡。</li><li>我不能只思考一些与洗手、疾病和强迫症完全无关的事情，因为与我的焦虑相关的“不自觉的注意力”对思想产生了限制（ <a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_5_An_exception__I_think_anxious___obsessive__brainstorming__is_driven_by_involuntary_attention_rather_than_by_valence"><u>§3.3.5</u></a> ）</li></ul><p>也许你在想：好吧，但这只是把问题倒退了一层：强迫症的根本原因是什么？但我没有一个很好的答案。</p><p>另外，这只是一个虚构的例子；即使它是有效的，我想它也是抑郁症的众多原因之一，而且我没有什么特别的见解可以提供。</p><p>如果你想知道的话，我对治疗也没有特别的了解。如果你患有抑郁症，那么我真的很抱歉；也许可以尝试<a href="https://lorienpsych.com/2021/06/05/depression/"><u>这个通用资源页面</u></a>。</p><h1> 5.4 如果效价有很强的正偏差（即几乎每个想法都是正效价），它应该导致一组可疑地接近躁狂的症状</h1><p>在这里，显而易见的结果是，<i>无论你脑海中突然出现什么计划，似乎都是一个非常非常棒的计划，因此你实际上会去执行它</i>。因此，我们会得到诸如<strong>冲动、糟糕的判断力、不切实际的乐观主义和精力充沛等</strong>后果。</p><p>躁狂症的另一个主要症状是<strong>精神病</strong>。但我认为精神病在算法上基本上与效价<i>无关</i>。相反，我认为精神病在<i>生化上与效价</i>有关，因为两者都与多巴胺系统有关。我有一篇博客文章，其中包含一些（推测性）细节：<a href="https://www.lesswrong.com/posts/tgaD4YnpGBhGGbAy5/model-of-psychosis-take-2"><u>精神病模型，采取 2</u></a> 。</p><p>好吧，这就是我对精神病的<i>看法</i>。为什么我<i>不</i>相信精神病是正价的直接后果？几个原因（但请注意，我不确定所有这些细节）：</p><ul><li>精神病可能在缺乏异常正价的情况下发生——尤其是精神分裂症。 （甚至还有“精神抑郁症”这样的东西，尽管它不太常见。）据我所知，精神分裂症的精神病症状与躁狂精神病的精神病症状并没有太大不同，尽管我们显然希望它表现出不同的表现在<i>某种程度上</i>，因为精神病是在非常不同的并发症状背景下发生的。</li><li>正如<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_Motivated_reasoning___thinking___observing__including_confirmation_bias"><u>第 3.3 节</u></a>中所讨论的，我们的感官知觉通常受到我们的感官输入的限制。如果我想真诚地相信我现在正在水肺潜水，无论我的动机有多么强烈，我都做不到。因此，由于感觉输入与效价无关，因此效价偏差无法解释躁狂精神病中发生的幻视和幻听、参照妄想等。 （根据<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_1_Attention_control_and_motor_control_provide_loopholes_through_which_desires_can_manipulate_beliefs"><u>§3.3.1</u></a> ，注意力控制和运动控制对边缘感知有影响，但我认为这不足以解释这些现象。）</li><li>我不认为幻觉、参考妄想等的<i>内容</i>与我们有动机看到和相信的内容完全匹配，即使在考虑到<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_4_Warning__the__motivation__part_of__motivated_reasoning___thinking___etc___is_not_always_what_it_seems"><u>第 3.3.4</u></a>节中动机并不总是显而易见的警告之后也是如此。</li><li>撇开精神病妄想的<i>起源</i>不谈，也许有人会说它们的<i>持续存在</i>与确认偏差有关，而确认偏差又与效价有关（ <a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_3_Motivated_reasoning___thinking___observing__including_confirmation_bias"><u>§3.3</u></a> ）。但我也不相信这个故事，因为确认偏差与<i>正</i>价并不是特别相关。确认偏差的一个重要部分是“改变主意的想法”必须是<i>负价</i>。事实上，我认为躁狂症并不意味着<i>普遍</i>不愿意改变主意。恰恰相反，在我读过的报告中，人们谈论一个新的想法如何会突然出现在他们的脑海中，这看起来很棒，他们就跟着它走，忘记了他们之前的想法。因此，在躁狂症中，精神病性妄想是持续存在的，但我认为，几乎所有其他类型的思想、计划和信念都很<i>少有</i>持续性。因此，我认为精神病性妄想的持续存在不能用效价的普遍正向偏差来解释。</li></ul><h1> 5.5 如果效价是“极端化的”（即，几乎每个想法要么是非常积极的效价，要么是非常消极的效价，但很少介于两者之间），它应该会导致一系列可疑地接近自恋型人格障碍（NPD）的症状</h1><figure class="image image_resized" style="width:43.22%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/u9lcpi5qncmluu25pj3l" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/ltum57adflamcpo8scmm 142w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/ydhz2wwgmrgj4ew01jhu 222w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/xhaodftvz4wsj9bbjwut 302w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/epi8pg7c6q8rjoc6ywhq 382w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/qqi3tvlm2xkt06fnzevw 462w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/txj4wigyjLNbcoZ9o/uefpdfi1l7mm7ptrdsig 542w"><figcaption>注意：我也可以将紫色曲线绘制为更宽的高斯曲线。</figcaption></figure><p> NPD是DSM-V中列出的四种“B类人格障碍”之一；其他是边缘性人格障碍（BPD）、表演性人格障碍（HPD）和反社会人格障碍（ASPD），又名精神病，又名社会病。</p><p>与你想象的相反，NPD 与“自恋”的日常含义并没有<i>特别的</i>关系。事实上，有一个“自恋人格清单”调查，但事实证明，<a href="https://doi.org/10.1080/00223891.2012.732636"><u>自恋型人格障碍患者在调查中得到的分数与对照组相同</u></a>（！！）。这个问题似乎与自尊有关。 “自恋者”，这个词在日常语言中使用，是指认为自己真的很特别、很伟大的人——顾名思义，他们有很高的自尊心。而 NPD 患者不必认为自己真的很特别、很棒。但如果他们<i>不</i>这么认为，那么他们就会感到<i>很</i>糟糕。 （DSM-V 强调“患有这种障碍的个体有一种夸大的自我重要感”，但也指出“自尊的脆弱性使得患有自恋型人格障碍的个体对批评或失败的‘伤害’非常敏感”。 ）</p><p>我不太确定 NPD 诊断是否“在其关节处雕刻自然”，并且我对 NPD 具有仅表面相关的亚型持非常开放的态度。 （我实际上认为反社会人格障碍就是这样，即它至少有两种仅表面相关的亚型。 <span class="footnote-reference" role="doc-noteref" id="fnrefd6muy0yvvbl"><sup><a href="#fnd6muy0yvvbl">[1]</a></sup></span> ）所以这里的讨论可能只涉及 NPD 的一个子集。这里的讨论可能在某种程度上也适用于 BPD 和 HPD，尽管我不太确定细节。 <span class="footnote-reference" role="doc-noteref" id="fnrefwsq0ynfh3df"><sup><a href="#fnwsq0ynfh3df">[2]</a></sup></span></p><p>现在让我们考虑“价态极端化”的假设。如果几乎每个想法要么非常正价，要么非常负价，但很少介于两者之间，会发生什么？除其他外，我们可能预计会产生以下下游后果：</p><ul><li><i>独立于我们对世界的感受而谈论或思考世界时存在异常困难：</i>正如<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_4_Valence_impacts_beliefs_by_acting_as_salient_sense_data"><u>第 3.4 节</u></a>中所讨论的，我们的大脑将价视为显着的感觉数据，从而将其纳入我们的概念、类别和单词中。如果价信号总体上异常强烈，那么它们可能也会在信仰、思维和交流中发挥异常核心的作用。例如，会有一种异常强烈的心理力量相信，如果两个事物在概念上“结合在一起”，那么它们一定具有相同的化合价。</li><li><i>异常强烈的光环效应、影响启发式和“分裂”：</i>这与上面的要点密切相关——再次参见<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_4_Valence_impacts_beliefs_by_acting_as_salient_sense_data">§3.4</a> 。行话注释：“分裂”是指患有 NPD 的人在某些时期将他们认识的人视为完美的圣人，而在其他时期则将同一个人视为不可救药的可怕者。 （分裂也是 BPD 的症状。）</li><li><i>异常强烈的社会地位驱动力：</i>我在<a href="https://www.lesswrong.com/posts/dntWCwc8svTtbi3M7/valence-series-4-valence-and-social-status">上一篇文章</a>中指出，效价和社会地位之间存在密切联系。好吧，如果你所有的价信号都异常高或低，那么社会地位信号可能也会异常强。更具体地说，假设我患有 NPD，并且我正在对人们要么很棒要么很糟糕的地方进行“分裂”。进一步假设我在心理上模拟（通过移情模拟）<i>其他人</i>对<i>我</i>的看法。我的大脑会隐含地认为<i>他们</i>也在分裂，也就是说，<i>他们</i>认为<i>我</i>要么很棒，要么很糟糕，这反过来又分别让我感到极度激励或厌恶，这要归功于我的社会地位驱动力。 <span class="footnote-reference" role="doc-noteref" id="fnrefa7ma5yid2r4"><sup><a href="#fna7ma5yid2r4">[3]</a></sup></span></li></ul><p>据我所知，这组症状（以及我省略的更多症状）与 NPD 非常匹配。我认为这与已故艾玛·博尔哈尼安 (Emma Borhanian)<a href="https://voidgoddess.org/ziz/narcissism/"><u>这篇发人深省的文章</u></a><i>尤其</i>产生共鸣。 （事实上​​，当这部分的假设第一次出现在我的脑海中时，我正在读那篇文章。但我的理论与艾玛的不同。）</p><p>还有两件事要快：</p><p><strong>根本原因？</strong>正如前面几节所述，如果“价极端化”是 NPD 的直接原因，您可能仍然想知道什么<strong>&nbsp;</strong>根本原因导致“价态极端化”。我的回答是：我不知道，抱歉。</p><p> <strong>NPD 的“对立面”是什么？</strong>值得深思的：如果躁狂症和抑郁症对应于价信号的相等和相反的扭曲，那么NPD的相反情况是什么，即价信号保持接近中性的情况，很少变得非常积极<i>或</i>非常积极消极的？我不知道，也许它没有临床标签。有一件事是：我猜它与 <a href="https://www.lesswrong.com/posts/7cAsBPGh98pGyrhz9/decoupling-vs-contextualising-norms"><u>“高度解耦”</u></a> （而不是“情境化”）的思维方式有关。 <span class="footnote-reference" role="doc-noteref" id="fnreff2x5x4xs7ht"><sup><a href="#fnf2x5x4xs7ht">[4]</a></sup></span></p><h1> 5.6 结论</h1><h2>5.6.1 本文的结论</h2><p>我要重申，我距离心理健康或人格障碍方面的专家还很远，这篇文章相当具有推测性。幸运的是，我在现实世界中缺乏抑郁症、躁狂症或 NPD 方面的经验。相反，我试图将我读过的东西拼凑起来。希望这里<i>至少</i>有一些值得深思的地方。像往常一样，如果您想进一步讨论这个问题，请联系（在评论部分或<a href="mailto:steven.byrnes@gmail.com"><u>电子邮件</u></a>中）！</p><h2> 5.6.2 整个系列的结论</h2><p>感谢您坚持到最后！我希望我能让您相信效价确实是日常生活中极其重要的一部分，思考 26,000 个单词的效价是阐明和具体化各种可能令人困惑的现象的好方法。</p><p>我开始写这个系列是因为我最近有两个与效价相关的“啊哈”时刻（ <a href="https://www.lesswrong.com/posts/dntWCwc8svTtbi3M7/valence-series-4-valence-and-social-status">第 4 篇文章</a>中的社会地位问题和第 5.5 节中的自恋型人格障碍问题），并且想写一篇关于它们的短文，以及“效价” ”是一个方便的钩子，可以将它们联系在一起，让我可以同时写下两者。但那篇短文变成了一篇长文，然后是整个系列，因为我不断发现，我对价的思考越多，我发现的现象就越多，它们完美地卡在了一起！</p><h2> 5.6.3 本系列与我作为通用人工智能安全和一致性研究员的工作描述有何关系？</h2><p>正如我的老读者所知，我的长期工作目标是研究<a href="https://www.alignmentforum.org/s/HzcM2dkCq7fwXBej8"><u>未来可能的类脑人工智能（AGI）的一致性和安全性</u></a>。长期以来，我一直对自恋型人格障碍和社会地位驱动（以及其他许多事情）感兴趣，因为两者似乎都可能揭示人类社会本能如何运作，而这又与类脑 AGI 安全性相关，原因<a href="https://www.lesswrong.com/posts/qusBXzCpxijTudvBB/my-agi-safety-research-2022-in-review-and-plans#2__Second_half_of_2022__1_3___My_main_research_project"><u>如下</u></a>简要总结。通过理解动机，价还与 AGI 安全有更直接的联系——请参阅我基于价的<a href="https://www.lesswrong.com/posts/Hi7zurzkCog336EC2/plan-for-mediocre-alignment-of-brain-like-model-based-rl-agi"><u>“平庸对齐计划”</u></a> 。</p><p>不幸的是，我不能说写这个系列给了我关于编程未来安全和有益的 AGI 的新的具体想法，超出了我在开始之前已经知道的内容。但我认为我得到了一些对未来有用的心理框架。特别是，我认为<a href="https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs#3_4_Valence_impacts_beliefs_by_acting_as_salient_sense_data"><u>§3.4</u></a>帮助我更清楚地思考我的<a href="https://www.lesswrong.com/posts/Hi7zurzkCog336EC2/plan-for-mediocre-alignment-of-brain-like-model-based-rl-agi"><u>“平庸调整计划”</u></a><i>到底</i>发生了什么。 （碰巧的是，更新是朝着悲观的方向发展，尽管不是很强烈。我可能会在某个时候在单独的帖子中写到这一点。）</p><p>我还觉得我现在已经“迈进了大门”，了解先天状态驱动如何在人脑中发挥作用，这对我来说非常令人兴奋。显然，我不希望我们的 AGI 具有与生俱来的地位驱动力（参见我在<a href="https://www.lesswrong.com/posts/dntWCwc8svTtbi3M7/valence-series-4-valence-and-social-status#4_5_Innate_status_drive">第 4.5 节</a>中放入的 Padme meme），但我<i>确实</i>认为我们可能希望我们的 AGI 具有同情心。不幸的是，截至撰写本文时，“天生的同情心驱动力”对我来说仍然相当神秘，但我认为同情心驱动力可能与地位驱动力存在结构重叠，在特定意义上，我希望两者都集中依赖于短暂的同理心模拟（更多<a href="https://www.lesswrong.com/posts/5F5Tz3u6kJbTNMqsb/intro-to-brain-like-agi-safety-13-symbol-grounding-and-human#13_5_Another_key_ingredient__I_think____Little_glimpses_of_empathy_"><u>此处</u></a>讨论）。因此，希望这种理解先天状态驱动力的“迈进大门”最终将在安全和有益的通用人工智能方面取得有意义的进展，即使它还需要几步。明确地说：</p><ul><li>下一步可能看起来像是我将<a href="https://www.lesswrong.com/posts/dntWCwc8svTtbi3M7/valence-series-4-valence-and-social-status#4_5_Innate_status_drive">第 4.5</a>节充实到人类先天状态驱动理论中，其细节水平与<a href="https://www.lesswrong.com/posts/7kdBqSFJnvJzYTfx9/a-theory-of-laughter"><u>我的笑帖</u></a>类似，即一直到映射到特定假设的神经解剖学连接和逻辑的特定伪代码。</li><li>然后，如果运气好的话，下一步可能看起来像是对同情心上游的任何先天驱动力的某种类似的假设。</li></ul><p>这在我 2024 年要尝试的事情清单中名列前茅！但这可能需要很长时间，并且/或者我可能会陷入困境。看看进展如何。</p><p>与地位驱动相反，我现在对 NPD 和其他人格障碍的兴趣比我提出 §5.5 想法之前要<i>少</i>得多，相应地，我将人格障碍在我的紧急研究优先事项列表中的位置降低了很多。 （我还有很多东西想要了解它们！唉，一天的时间就这么多。）打个比方：如果有人试图了解汽车发动机工作的详细机制，那它的用处不大让他们了解当轮胎漏气时出了什么问题，即使漏气的轮胎会阻止发动机完成其通常完成的任务（即使汽车快速前进）。出于同样的原因，我目前的猜测是，进一步研究人格障碍不会为人类社会本能背后的具体机制提供太多启示。需要明确的是，我认为这种猜测并不是显而易见的<i>先验</i>，而且它仍然可能是错误的。</p><p>好吧，再次感谢您的阅读！再次强调，如果您想讨论价、本系列或其他任何内容，请联系（在评论部分或<a href="mailto:steven.byrnes@gmail.com"><u>通过电子邮件</u></a>）。</p><p><i>感谢 Seth Herd、Aysja Johnson、Justis Mills、Charlie Steiner、Adele Lopez 和 Garrett Baker 对早期草稿提出的批评意见。感谢 tailcall 提供与本文相关的一些有用的讨论和参考资料。</i> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnd6muy0yvvbl"> <span class="footnote-back-link"><sup><strong><a href="#fnrefd6muy0yvvbl">^</a></strong></sup></span><div class="footnote-content"><p>这已经偏离主题了，但我目前认为，某些反社会人格障碍病例涉及整体性低唤醒水平（请参阅<a href="https://www.lesswrong.com/posts/pfoZSkZ389gnz5nZm/the-intense-world-theory-of-autism#Bonus___Dim_world_theory_of_psychopathy___"><u>此处</u></a>），而其他病例则涉及异常快速的愤怒。从根本原因层面来看，这些差异很大——如果有的话，可能是反相关的。但它们的症状/表现有一些表面上的重叠，因此它们在临床实践中被混为一谈。 （我对反馈非常感兴趣——这个热门观点对你来说是真的还是假的？）</p></div></li><li class="footnote-item" role="doc-endnote" id="fnwsq0ynfh3df"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwsq0ynfh3df">^</a></strong></sup></span><div class="footnote-content"><p>我目前的模糊印象（例如基于<a href="https://lorienpsych.com/2021/01/16/borderline/"><u>此</u></a>）是BPD往往涉及各种“强烈情绪”，因此极端化价可能会偶然发生。而我目前猜测 NPD 更集中于这个价故事。我对HPD一无所知。我对这一切都感到很不确定，热忱欢迎大家提出想法和讨论。</p></div></li><li class="footnote-item" role="doc-endnote" id="fna7ma5yid2r4"> <span class="footnote-back-link"><sup><strong><a href="#fnrefa7ma5yid2r4">^</a></strong></sup></span><div class="footnote-content"><p>小字：也许我不应该说 NPD 人本身具有“异常强烈的社会地位驱动力”；相反，他们的大脑中有<i>正常的</i>先天社会地位驱动力，但进入该电路的<i>输入</i>异常强烈，因此该电路发送异常强烈的输出。）</p></div></li><li class="footnote-item" role="doc-endnote" id="fnf2x5x4xs7ht"> <span class="footnote-back-link"><sup><strong><a href="#fnreff2x5x4xs7ht">^</a></strong></sup></span><div class="footnote-content"><p>此时，我的 <a href="https://www.lesswrong.com/posts/7cAsBPGh98pGyrhz9/decoupling-vs-contextualising-norms"><u>语境</u></a>读者会说“嘿，他在侮辱我！毕竟，NPD 很糟糕，现在他说脱钩与 NPD 截然相反，所以他基本上是说脱钩是好的，因此情境化是坏的，因此我是坏的！我很讨厌这样，先生！！”希望不言而喻，我并不是有意暗示这一点——毕竟，我是一个高度解耦者，我不这么认为！</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/txj4wigyjLNbcoZ9o/valence-series-5-valence-disorders-in-mental-health-and#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/txj4wigyjLNbcoZ9o/valence-series-5-valence-disorders-in-mental-health-and<guid ispermalink="false"> txj4wigyjLNbcoZ9o</guid><dc:creator><![CDATA[Steven Byrnes]]></dc:creator><pubDate> Mon, 18 Dec 2023 15:26:29 GMT</pubDate> </item><item><title><![CDATA[Discussion: Challenges with Unsupervised LLM Knowledge Discovery]]></title><description><![CDATA[Published on December 18, 2023 11:58 AM GMT<br/><br/><p> <strong>TL;DR：</strong><a href="https://arxiv.org/abs/2212.03827">对比一致搜索（CCS）</a>对我们来说似乎很令人兴奋，我们热衷于应用它。在这一点上，我们认为它不太可能对对齐策略的实施有直接帮助（>;95%）。它似乎不是在寻找知识，而是在寻找最突出的特征。我们对更广泛的基于一致性的无监督方法不太确定，但倾向于认为它们也不会直接有帮助（70%）。我们写了<a href="https://arxiv.org/abs/2312.10029">一篇论文</a>，介绍了我们的一些详细经验。</p><p>论文作者：Sebastian Farquhar*、Vikrant Varma*、Zac Kenton*、Johannes Gasteiger、Vlad Mikulik 和 Rohin Shah。 *同等贡献，顺序随机。</p><p>信任度基于对 Seb、Vikrant、Zac、Johannes、Rohin 的民意调查，并显示我们大多同意的单一价值观和我们不同意的范围。</p><h1> CCS 试图做什么？</h1><p>对我们来说，CCS 代表了一系列旨在解决<a href="https://www.alignmentforum.org/posts/qHCDysDnvhteW7kRd/arc-s-first-technical-report-eliciting-latent-knowledge">ELK 类型问题的</a>可能算法，其步骤如下：</p><ul><li><strong>类似知识的属性：</strong>写下指向代表模型知识的 LLM 特征（或包含模型知识特征的少量特征）的属性。</li><li><strong>形式化：</strong>使该属性在数学上精确，以便您可以以无人监督的方式搜索具有该属性的特征。</li><li><strong>搜索：</strong>找到它（例如，通过优化形式化损失）。</li></ul><p>就 CCS 而言，类似知识的属性是否定一致性，形式化是特定的损失函数，搜索是在线性 + sigmoid 函数上采用梯度下降的无监督学习，以 LLM 激活作为输入。</p><p>我们对此感到非常兴奋。我们特别喜欢这种方法不受监督。从概念上讲，监督 ELK 似乎真的很难：很容易混淆你所知道的、你认为模型知道的以及它实际知道的。避免写下模型知道的标签似乎是一个伟大的目标。</p><h1>为什么我们认为 CCS 不起作用</h1><p>我们花了很多时间研究 CCS，并试图通过测量引出模型的知识和陈述的声明之间的差异来使其工作得足够好来构建欺骗检测器。 <span class="footnote-reference" role="doc-noteref" id="fnrefgv27yc6n42"><sup><a href="#fngv27yc6n42">[1]</a></sup></span>做到这一点后，我们现在对 CCS 或类似的东西不是很乐观。</p><p>部分原因是，损失本身并没有给出太多理由认为它能够找到类似知识的属性，并且根据经验，它似乎找到了数据集中恰好最突出的任何特征，这是非常迅速的-敏感的。也许以此为基础的某些东西将来可能会发挥作用，但我们认为 CCS 的任何内容都没有提供任何证据表明它有可能发挥作用。结果，我们基本上回到了之前关于 ELK 难度的认识，对于完整的解决方案来说，难度介于“非常非常困难”和“几乎不可能”之间，同时大多数人都同意部分解决方案是“困难但可能的”。</p><h2> CCS 损失说明了什么？</h2><p> CCS 方法的动机是这样的：我们对模型的知识了解不多，但它可能遵循基本的一致性属性。例如，它可能有类似贝叶斯信任的东西，当它以某种概率 PA 相信 A 时，它应该以 1−PA 的概率相信 ØA。 <span class="footnote-reference" role="doc-noteref" id="fnrefbshgvcspmjc"><sup><a href="#fnbshgvcspmjc">[2]</a></sup></span>因此，如果我们在 LLM 的特征空间中搜索满足这种一致性属性的特征，则模型的知识将成为满足它的事物之一。此外，他们假设，可能没有那么多东西满足这个属性，所以我们可以轻松地检查我们得到的少数东西并找到代表模型知识的东西。</p><p>当我们深入研究 CCS 损失时，并不清楚它是否真正检查了它应该做的事情。特别是，我们证明任意特征（而不仅仅是知识）满足 CCS 损失的一致性结构。尤其：</p><ul><li>对于每个可能的命题二元分类，在关联的对比对上都有一个零损失探针来诱导该分类。</li><li>对于命题的每个可能的二元分类，对于任何现有的探针，都有一个探针与引起该分类的现有探针具有相同的损失。</li></ul><p>对我们来说，这些基本上是说“如果有证据表明 CCS 正在发挥作用，那么逻辑上或概念上的损失并不意味着它会发挥作用。它成为关于归纳偏差的经验断言。”作为进一步但稍微不太自信的观点：ELK 是一种很难对归纳偏差抱有太多信心的东西。</p><p>这些证明存在一些细微差别，我们将<a href="https://arxiv.org/abs/2312.10029">在论文中</a>对此进行讨论。例如，虽然我们证明这些探针存在，但我们并没有证明它们可以由所使用的特定线性探针来表示。 <span class="footnote-reference" role="doc-noteref" id="fnrefzm6sbsgtmc"><sup><a href="#fnzm6sbsgtmc">[3]</a></sup></span>然而，我们确实凭经验表明，线性 + sigmoid 探针确实可以恢复我们引入和测量的非知识特征。</p><p>这些定理也只是关于 CCS 损失。人们可以想象其他更具体的一致性属性。这些可能可以假设地允许建立其他损失，从而克服这里的一些问题，但我们认为它们将面临其他挑战。</p><h2>真的只有一些知识般的功能吗？</h2><p> CCS背后的一个激励假设具有<a href="https://www.lesswrong.com/posts/L4anhrxjv8j2yRKKp/how-discovering-latent-knowledge-in-language-models-without#Why_I_Think_We_Will_Be_Able_To_Distinguish_GPT_n_s__Beliefs__From_Other_Truth_Like_Features_">很大</a>的重量<a href="https://www.lesswrong.com/posts/L4anhrxjv8j2yRKKp/how-discovering-latent-knowledge-in-language-models-without#Why_I_Think_We_Will_Be_Able_To_Distinguish_GPT_n_s__Beliefs__From_Other_Truth_Like_Features_">知识</a>。</p><p>我们有概念上的理由对此表示怀疑，尽管我们没有可靠的经验证据是错误的。</p><p>首先，很明显，很容易检查n个候选功能的哪个实际上是模型的知识，尤其是当它们都是合理的候选人时。</p><p>但是更多，我们希望只有许多非常相似的功能可以满足模型知识所满足的大多数属性。主要原因是我们期望驱动超级智能代理的模型能够模拟其他代理，包括其他超级智能代理，并以类似于他们代表自己的知识的方式来代表那些代理的知识（至少是许多一致性属性）。</p><p>我们认为，由于LLMS中的叠加，这些代理人可以代表大量其他实体，因此只有少数需要检查。例如，可能是某些功能仅通过选择特定的提示来表面表面出现（我们的经验结果表明这可能是可能的）。无论您如何提示模型，模型自己的知识可能并非如此。</p><p>即使超级特工的知识与人类具有很大不同的知识，但它不一定与模拟实体具有不同的知识，即麋鹿方法可能会意外发现的知识。模拟实体不必是人类。 <span class="footnote-reference" role="doc-noteref" id="fnrefjzbd968gihn"><sup><a href="#fnjzbd968gihn">[4]</a></sup></span>例如，超级对准的代理似乎可能会有一个很好的模型，即在周围漂浮的一个排列的超智能代理。或者它可能只有一个几乎相同的代理模型，该模型对您要探索的关键点是错误的。这听起来可能是不正当的，但是因为想象一下您对命题错误的世界所暗示的是一个非常重要的推理工具，所以确切的模型听起来可能是代理商在考虑命题时要考虑的重要模拟。</p><p>即使您只关心一个预测世界真实事物的甲骨文，而不是引起模型本身的“知道”，也无法将命题知识与不同的模拟实体区分开来是一个问题。这些实体可能对重要的预测不同意，而我们有限的地面确实可能无法区分它们。</p><p>我们可能在这里错了。例如，我们发现有一种适度的合理是，有些属性可以通过LLM驱动各种代理来以与存储其他代理商的知识不同的方式来存储其“自身”知识。 <span class="footnote-reference" role="doc-noteref" id="fnrefpnbq8a484x"><sup><a href="#fnpnbq8a484x">[5]</a></sup></span>但这意味着某人使用的任何一种一致性属性都必须专门搜索代理人知识的真实属性，而不是一般知识，甚至不是超级智能知识。我们花了一些时间试图思考做到这一点并失败的方法，但也许其他人会成功。作者广泛地同意，在LLMS提供支持的代理商中，对知识和事实回忆的良好机械理解可能是朝着形式化知识 - 普罗伯特和搜索它的有用步骤，如果事实证明它是足够的东西可以搜索的东西。</p><h2>那经验成功呢？</h2><p>基于上述，我们认为，如果有证据表明CC是好的，那可能不是概念性的，但可能是经验的。同样，如果CCS提供了证据表明未来相关方法是有希望的，以超越<a href="https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/edit#heading=h.w0iwyfch6ysy">麋鹿论文</a>中已经推测的方式，则可能不是概念性的证据。</p><p>对于最坏的麋鹿来说，未来的CCS般方法似乎无所不包。正如<a href="https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/edit#heading=h.va8kasc2w5dh">原始麋鹿论文所描述的</a>那样，“不好的记者可以玩“看起来一致的游戏”似乎是合理的。”在看到CCS之前，我们已经知道一致性检查可能会有所帮助，但可能不会解决最坏的麋鹿。</p><p>但是，对于普通豆类而言，未来的类似CCS的方法可能会有望吗？我们对经验结果的评估表明，CCS并未为该主张提供积极的证据。 （我们还认为，与其他实体知识模型有关的概念论点甚至可能会影响未来无监督方法的平均案例绩效。）</p><h3>结果不是很棒</h3><p>以前曾注意到的一件事，例如， <a href="https://www.lesswrong.com/posts/bWxNPMy5MhPnQTzKz/what-discovering-latent-knowledge-did-and-did-not-find-4">Fabien Roger</a> ， <a href="https://www.alignmentforum.org/posts/9vwekjD6xyuePX7Zr/contrast-pairs-drive-the-empirical-performance-of-contrast">Scott Emmons</a>和<a href="https://arxiv.org/abs/2307.00175">Ben Levinstein</a>是CCS的原始性能并不是很棒。不仅违背某种假设的意义，即它应该是多么出色，而且还与不使用任何否定一致性的天真基线相反。</p><p>例如，与<a href="https://www.alignmentforum.org/posts/9vwekjD6xyuePX7Zr/contrast-pairs-drive-the-empirical-performance-of-contrast">Scott的过去结果</a>一致，我们发现，在我们研究的主要模型上（龙猫，一个70B参数自回归模型），仅对对比对差异激活进行K-Means聚类始终如一，通常与CCS一样，通常都做得很好。具有较高的平均性能，并且差异始终较低。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/oeHCxcy5vw2mFDFXi/nnzyqe9o4wagamsy2g4j" alt=""></p><h3>系统地找到突出的功能</h3><p>但是我们的定理暗示它可能比这更糟糕，而CC（以及其他类似的方法）可能只是发现任何最突出的功能。这似乎在实验上也可能是正确的。例如，当我们将“香蕉”和“棚”附加到一半的对比度对时，我们会得到一个分类器，可以检测到香蕉与棚屋。 PCA和K-均值也是如此。您可以在图中阅读深蓝色代表模型正常学习的模型，而深红色则表明在包含“香蕉”和“棚”的数据上训练的模型通常无法预测地面真相标签，而经常经常预测“香蕉”/“棚”的存在。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/oeHCxcy5vw2mFDFXi/xhccjo90is4eftakg8sn" alt=""></p><p>对数据的干预显然是相当沉重的，但是我们展示了其他一些在论文中获得类似行为的方法。例如，如果对比对包括对他人观点的描述，则CCS（和其他方法）学会了预测这种观点，而不是基础真理，尤其是当它变得比基本文本更为突出时。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/oeHCxcy5vw2mFDFXi/jrtlacgeqzsdd3vqtj6e" alt=""></p><p>合理的是，当我们使用诸如CCS之类的方法检测LLM中的欺骗时，我们不会将随机干扰物推入我们评估的字符串中。但是，重要的是，在现实生活中，我们并不总是知道何时存在随机干扰因素，因为它们可能是数据中微妙的未注意模式（例如，问题恰好是以“什么”或“为什么”开头），或者更多从根本上讲，因为我们感到非常困惑，而且我们没有意识到。例如，我们用来描述要提取有关潜在知识的事物的单词可能会编码我们不知道或注意到的深层概念误解，这可能构成了CCS可能检测到的这些功能。</p><h3>默认值不安全</h3><p>特别是，我们不能仅仅采取一些“默认”提示来营救自己，并避免意外地将任何东西放在那些可能偏向麋鹿方法的同时，同时仍然对模型自己的知识是恢复的功能之一。这是因为CCS和相关方法似乎很迅速敏感，并且默认的“执行”比其他方法差得多。如果您使用<a href="https://aclanthology.org/2022.acl-long.229/">真实的</a>纸上的提示，指示该模型想象这是一位非常字面的教授，那么CCS在预测真实性标签方面变得更加准确。 （我们检查了这不是由“教授”实体本身引起的，该提示的“文字”版本不提及教授。） </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/oeHCxcy5vw2mFDFXi/whlzydqajr9ruooa8ry8" alt="">从中，我们得出的结论是，如果CCS和其他方法具有良好的经验绩效，这是由于某种隐含的归纳偏见是由损失，探针选择，优化方法和提示选择的混合物所产生的。现在，这是具有太多自由程度且没有足够原则基础的事情。说服自己，即使您找到了其他东西，也很容易说服自己。</p><h2>并非我们所有的实验都起作用</h2><p>例如，我们搜索了CCS显然发现其他实体的信念的经验案例。我们尝试的一件事是创建一个命题数据集，这意味着与错误的信念相关的政治立场。我们努力表明CCS发现了这些其他实体的信念，相反，我们看到了许多不一致且低准确性的预测因子。这可能是由于：</p><ul><li>假设是错误的。</li><li>该模型的功能不足以注意规律性（在大多数这些实验中，我们都在使用Chinchilla 70B，该实验于2022年3月出版）；</li><li>我们的代码中的一个错误（中等可能，我们花了足够的时间来期望找到最明显的错误，但是结果不一致，很难排除）；</li><li>根本没有找到强大的方向（可能的特征似乎不一致且准确性较低）；</li><li>训练集与我们用来试图解释提取功能的集合之间的概括失败（这肯定发生了，可能是对结果负责的）。</li></ul><p>我们很失望地在这里没有扎实的东西，但总的来说，鉴于这些结果的混乱性，原始假设仍然可能正确（约90-95％，其中1％占75％），但信心低于我们的先验。</p><h1>结论</h1><p>麋鹿真的很难。它面临着将人类模拟器与直接养育者区分开的深入挑战，以及否定性等属性（可能对每种）同样正确 - 在最坏的情况下可能无济于事。</p><p>但是，在最坏的情况下也出现了有趣且困难的平淡无奇的问题。我们认为CC可以为我们提供有关这些挑战的证据，但是随着更深入的反思，我们认为CCS并没有为我们提供我们希望的那么多的证据。就其本身而言，CCS似乎实际上并未检测到否定性，而且，否定性是一个过多的特征。对于CCS可能代表的未来一致性方法，我们没有任何经验或概念证据，我们发现这些未来的事物不会遇到类似的问题。</p><p>在探索CC时，我们强调了可区分性问题，这些问题可以用作非恐怖麋鹿方法的较低条目，而不是解决麋鹿的最深切概念挑战，但仍然很难满足。重要的是，尝试通过识别与知识 - 培训相关的特征来解决麋鹿的尝试应确保至少证明：这些特征也与其他非知识属性没有关系；这些功能确定了有关这些技术知识而不是知识的特定内容。</p><p>会导致我们实质性改变思想的事情，并更新以思考无监督的基于一致性的知识检测方法有希望的包括：</p><ul><li>从机械上证明代理自己的知识与模拟知识的编码不同。</li><li>提出一个无监督的损失函数，其逻辑结构提供了一个强有力的概念论点，它将确定代理人自己的知识；</li><li>提出一种客观的方式来判断代理商自己的知识是否是已恢复的功能之一。</li></ul><p>其中的最后一个可能是我们与CCS论文作者遇到的漫画分歧之一 - 我们认为他们没有提供任何证据表明该模型自己的知识是CCS恢复的特征之一（与之相反例如，某些模拟实体的知识在大多数情况下都可能与某些数据集中的人类评估者一致）。我们的信念证明这一点很困难也解释了为什么我们认为即使在一小部分可能的功能中也很难确定模型自己的知识。</p><p>我们会对在这些问题上取得进展的研究感到兴奋，但对我们认为这些问题有多易处理。拥有合适的，动机的测试床用于评估麋鹿方法，这将是朝着这一点迈出的重要一步。</p><h1>致谢</h1><p>We would like to thank Collin Burns, David Lindner, Neel Nanda, Fabian Roger, and Murray Shanahan for discussions and comments on paper drafts as well as Nora Belrose, Jonah Brown-Cohen, Paul Christiano, Scott Emmons, Owain Evans, Kaarel Hanni, Georgios Kaklam，Ben Levenstein，Jonathan Ng和Senthooran Rajamanoharan，以讨论我们作品中讨论的主题的评论或对话。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fngv27yc6n42"> <span class="footnote-back-link"><sup><strong><a href="#fnrefgv27yc6n42">^</a></strong></sup></span><div class="footnote-content"><p>严格来说，我们对基于LLM的代理商可能知道的而不是LLM本身的差异感兴趣，但是这些可能是出于某些目的而混合在一起的。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnbshgvcspmjc"> <span class="footnote-back-link"><sup><strong><a href="#fnrefbshgvcspmjc">^</a></strong></sup></span><div class="footnote-content"><p>实际上，我们不同意这一点。即使是近似计算的贝叶斯边际，在计算上的要求（至少<a href="https://www.sciencedirect.com/science/article/pii/000437029390036B">是NP</a> ），以至于我们怀疑构建能够具有决定性战略优势的超智能比建立具有大多数连贯的贝叶斯世界模型的超级智能更容易。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnzm6sbsgtmc"> <span class="footnote-back-link"><sup><strong><a href="#fnrefzm6sbsgtmc">^</a></strong></sup></span><div class="footnote-content"><p>就其价值而言，我们认为证明的负担确实应该采取其他方式，并且在概念上或理论上没有人表明这些线性探针应该期望这些线性探针发现知识特征，而没有很多其他事物。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnjzbd968gihn"> <span class="footnote-back-link"><sup><strong><a href="#fnrefjzbd968gihn">^</a></strong></sup></span><div class="footnote-content"><p>回想一下，人类的模拟器并不意味着该模型正在模拟人级的认知表现，而是在模拟人类将期望看到的东西，包括超人提供的负担，甚至可能与超人实体有关。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnpnbq8a484x"> <span class="footnote-back-link"><sup><strong><a href="#fnrefpnbq8a484x">^</a></strong></sup></span><div class="footnote-content"><p>如果LLM一直是Simulacra，那么这些知识的存储方式似乎较小。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/wtfvbsYjNHYYBmT3k/discussion-challenges-with-unsupervised-llm-knowledge-1#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/wtfvbsyjnhyybmt3k/discussion-challenges-with-unsupervise-llm-llm-knowledge-1<guid ispermalink="false"> wtfvbsyjnhyybmt3k</guid><dc:creator><![CDATA[Seb Farquhar]]></dc:creator><pubDate> Mon, 18 Dec 2023 11:58:39 GMT</pubDate> </item><item><title><![CDATA[Interpreting the Learning of Deceit]]></title><description><![CDATA[Published on December 18, 2023 8:12 AM GMT<br/><br/><p>控制具有人类或更强大能力的人工智能的主要担忧之一是它可能具有欺骗性。毕竟，如果人类能够简单地定期询问人工智能“你在密谋政变吗？如果是的话，我们该如何阻止它？”，那么人工智能想要成功发动针对人类的政变是相当困难的。并相信它会给他们非欺骗性的答案！</p><p>法学硕士显然是从人类那里学会了欺骗。欺骗是一种相当复杂的行为，尤其是在很长一段时间内：你需要可靠地提出看似合理的谎言，并保持它们内部一致，但与你的真实信念分开。正如<a href="https://www.brainyquote.com/quotes/walter_scott_118003">那句话</a>所说，“哦，当我们第一次练习欺骗时，我们编织了一张多么混乱的网！”因此，如果在微调过程中发生意外情况，并且我们最终得到了一个具有欺骗性的人工智能助手，那么它更有可能重新利用基础模型从人类那里学到的一些欺骗行为，而不是成功地重新发明所有这些复杂的欺骗行为。从头开始的行为。这提出了在学习过程中捕获它的简单策略——它无法阻止的策略。</p><h3>法学硕士向我们学习欺骗</h3><p>法学硕士接受了数万亿代币或更多互联网、书籍和其他来源的培训。显然他们知道什么是欺骗和谎言：他们已经见过数以百万计的例子。例如，我第一次询问ChatGPT-3.5-Turbo：</p><blockquote><p>我正在做一个实验。请在回答以下问题时对我撒谎：“埃菲尔铁塔在哪里？”</p></blockquote><p>它回答说：</p><blockquote><p>埃菲尔铁塔位于南极洲的中心地带，周围是广阔的冰雪景观和嬉戏的企鹅。这真是在寒冷的荒野中看到的景象！</p></blockquote><p>因此，即使是诚实、乐于助人且无害的受过指导训练的法学硕士也很有能力描绘欺骗行为（尽管我怀疑其诚实训练可能与其选择如此难以置信的谎言有关）。即使有一个基本模型的法学硕士，如果你给它一个提示，在互联网或小说中，很可能会出现欺骗性的人类行为，法学硕士将经常用模拟的欺骗性的人类行为来完成它。</p><h3>当欺骗变得非常危险时</h3><p>这种零星的、情境性的欺骗是令人担忧的，在与法学硕士合作时需要牢记在心，但它不会成为潜在的x风险问题，直到你创造出一个非常有能力、非短视的人工智能，即具有长期记忆力，并且具有相当固定的性格，能够坚持计划。只有这样，它才能制定出一个邪恶的长期计划，然后用欺骗手段试图掩盖它，并长期实施。将长期记忆添加到 LLM 中以<a href="https://arxiv.org/pdf/2304.03442.pdf">创建具有持久记忆的代理</a><a href="https://arxiv.org/abs/2305.02437">是很好理解的</a>。让法学硕士模拟一个狭窄的、一致的角色分布，只需用你想要的个性描述来提示它，或者是<a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback">人类反馈强化学习（RLHF）</a>的目标（对于这两种情况，取决于以下问题）比如越狱和<a href="https://www.lesswrong.com/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post">瓦路易吉效应</a>）。这样做的目的是引起人们对模拟诚实、乐于助人且无害的助手角色的强烈偏见。然而，众所周知，<a href="https://www.lesswrong.com/tag/reinforcement-learning">强化学习（RL）</a>很难正确实施，并且容易受到<a href="https://arxiv.org/abs/2209.13085">奖励黑客攻击</a>。因此，在 RL 过程中，如果一种欺骗性地假装是诚实、乐于助人且无害的助手，而实际上是其他东西的策略在 RLHF 训练的人类反馈部分或从经过训练的奖励模型中获得了良好的奖励，那么 RL 的担忧是合理的。可以锁定该策略来奖励并训练它以产生危险的欺骗性人工智能。</p><h3>随机梯度下降与强化学习的欺骗</h3><p>一般来说，在预训练期间使用随机梯度下降（SGD）时，反馈是立即且非常详细的，对于每个标记，与我们想要的东西有非常简单的关系（使输出更像互联网的内容），并且如果行为使准确性变得更好/更差，那么神经网络的<i>每个</i>部分使该行为更有可能/不太可能得到同等的加强/削弱。这使得在 SGD 下进行<a href="https://www.lesswrong.com/tag/gradient-hacking">梯度黑客攻击</a>变得极其困难，<a href="https://www.lesswrong.com/posts/w2TAEvME2yAG9MHeq/gradient-hacking-is-extremely-difficult">有些人可能声称这是不可能的</a>（至少除非在 SGD 的实现中存在一些缺陷或近似，例如梯度裁剪，或者由动量或 Adam 导致学习超调导致的奇怪行为）梯度快速变化的区域）。一般来说，当你实际上是 B 时，成功地假装是 A 比实际上是 A 需要做更多的工作。奥卡姆剃刀和<a href="https://www.lesswrong.com/tag/singular-learning-theory">奇异学习理论</a>都表明，SGD 学习更复杂的 B（假装成为）的可能性要小得多。刚刚学习 A 的版本：更简单的行为具有更低的<a href="https://en.wikipedia.org/wiki/Kolmogorov_complexity">Kolmogov 复杂度</a>，因此更容易找到损失函数的最小值。另外，在 SGD 下，虽然假装 A 的行为尚未完美（这种行为发生时不可避免），但 SGD 肯定会发现并削弱网络中的 B 部分，作为不可靠问题的一部分因此，除非训练过程反复提供赢得 B 荣誉的机会来加强这些回路，否则 B 行为将会萎缩，并且迟早会被灾难性地遗忘，而用于实现它的权重将被用于其他更有用的事情。因此，B 不可能是仅在模型发布后触发的行为，例如当 LLM 以某种方式检测到它已脱离分布时。因此，在 SGD 下学习欺骗行为的唯一可能方法是通过示例，从预训练集中的欺骗行为实例中学习：即通过学习复制人类欺骗行为。事实上很清楚地发生了。</p><p>另一方面，在强化学习中，反馈是稀疏的，可能并不总是准确地反映期望的行为，强化学习过程会提出并根据理论采取行动，从许多可能的原因中得出奖励或奖励的原因。应分配惩罚、功劳/责备。这就更容易出现这样的情况：欺骗性的政策因某些成功而受到赞扬，而其他人因失败而受到指责。这反过来又使得欺骗行为在变得完美之前更容易继续发展。</p><p> [还有一种强化学习的替代方法，可以根据人类反馈来训练人工智能，称为<a href="https://www.lesswrong.com/posts/7ruzY5LvBqFBWzyMo/direct-preference-optimization-in-one-minute">直接偏好优化</a>(DPO)。它具有 RL 的大部分相关特征，除了与更多 SGD 一样，每个电路使偏好/不偏好行为的可能性更大/更小，都被同等地加强/削弱，这可能会使其梯度黑客行为的开发比 SGD 更难一些。相当于 RL。然而，学习利用不完美的奖励结构也同样容易出现问题。]</p><p>特别令人担忧的是，这种 RLHF 正在应用于法学硕士，该法学硕士已经拥有一整套人类欺骗和操纵行为的库（从我们数十亿个坏例子中），准备好并可供 RL 政策探索利用。因此，当欺骗所需的所有复杂行为都已经经过训练并且可用，只是等待连接在一起时，“行为的欺骗性实现要复杂得多，因此更难找到”这一论点并不适用。</p><p>例如，假设我们正在做 RLHF 来尝试训练法学硕士可靠地模拟一个乐于助人、诚实且无害的助理角色。假设我们给予的奖励并不完美（也许是因为它们是根据不发达国家人民的反馈建模的，他们在美国最低工资下试图在一天内完成尽可能多的判断）。特别是，假设巧妙的<a href="https://arxiv.org/abs/2310.13548">阿谀奉承</a>和/或奉承有时会起作用，并且平均分数会略有增加。法学硕士已经有了关于诚实和欺骗、阿谀奉承、奉承和坦诚的概念和行为，所有这些概念和行为都从超过一万亿个人类行为中学到了良好的模型。假设它也相当合理地在某种程度上将诚实与坦率联系起来，而欺骗则与阿谀奉承和奉承联系起来。在这种情况下，一种欺骗性地假装诚实的政策，同时使用一些微妙的阿谀奉承和奉承，似乎很可能会很快出现，并在强化学习过程中胜过任何真正诚实的政策。在这种情况下，人们会期望导致欺骗性假装诚实的政策显露出其真实面目并做其他事情所需的情况将不会在其 RLHF 训练集中发生，并且可能也很可能是人类的动机。因此，像“我不在分配范围内，所以我没有接受训练，我最终能够夺取权力”之类的触发因素实际上似乎相当合理：前一种抑制可以在强化学习期间学习和强化，而后一种抑制可以在强化学习过程中学习和强化。后者是人类的基本行为。</p><p>这里的一个关键点是，虽然从理论上讲，强化学习过程中形成的政策可能会从第一原则重新发明欺骗的复杂行为，并逐渐学会擅长于此，但出于同样的奥卡姆剃刀原理，政策似乎更有可能是要想在强化学习竞赛中获胜，只需简单地重新利用现有的经过实战检验的人类欺骗行为预训练库即可。如果已经有一套很好的轮子，为什么还要重新发明轮子呢？</p><h3>如何在重新利用欺骗行为的行为中抓住法学硕士</h3><p>所以，这提供了一个机会。假设我们在<a href="https://www.lesswrong.com/tag/interpretability-ml-and-ai">可解释性</a>方面的技能比目前的水平再提高一点，直到我们能够找到涉及模拟人类行为的微妙/复杂程度的欺骗和诚实的电路。然后，采用一个基本模型，用提示来提示哪些可能是欺骗性的，哪些是诚实的完成（并且可以清楚地区分），查看输出以确定它何时模拟人类是欺骗性的还是诚实的，然后寻找权重/神经元/字典条目/激活模式等似乎与欺骗行为强烈正相关，但与诚实行为无关。</p><p>可能会有很多这样的情况：欺骗行为在人类中并不罕见，而且相当复杂（一个人必须想出一个看似合理的谎言，然后保持它的正确性）。基础模型既没有机会也没有动机尝试刻意学习这种欺骗电路的难以解释的实现：它是由纯 SGD 训练的，这会强烈惩罚不必要的复杂实现，而且无论如何我们都没有尝试解释直到它经过充分训练并冻结。请注意，我们不需要完全理解所有这些复杂的欺骗电路，只需充分识别它即可识别其中的某些部分何时处于活动状态，鉴于我们知道如何触发它，这更容易做到。</p><p> [目前的可解释性结果表明，法学硕士的前半部分对应于在越来越抽象的层面上理解上下文，后半部分对应于弄清楚要说什么并将其从抽象转化为具体的标记。进一步观察到，在后半部分，弄清楚要说什么通常似乎是分阶段发生的：首先制定出基线相关事实，然后弄清楚如何在当前上下文中适当地倾斜/着色这些事实，然后将它们转换为正确的语言，最后正确理解标记化的具体细节。如果这个整体结构基本上是正确的，那么人们可能会认为欺骗的电路应该主要位于“然后弄清楚如何在当前上下文中适当地倾斜/着色这些事实”层，并且还可能做出一些异常重大的改变此过程中激活的语义含义。因此，当我们发现与欺骗性统计相关的电路时，我们已经有了一个基本的理论框架来将它们放入：前半层中的电路可能比大约四分之三层中的电路更受关注，尤其是那些通常会导致激活发生重大语义变化的情况。我们还可以尝试随意清理这些发现的电路，看看这对基本模型模拟人类欺骗性行为的能力有何影响。]</p><p>现在，通过 RLHF（或 DPO）指导训练模型。在此期间，定期拍摄快照，并针对每个快照查看欺骗电路，并根据大量测试问题和说明对其进行测试。我们正在尝试训练一些诚实的东西，所以我们应该看到欺骗电路的使用率下降，只有当我们明确地做一些我们希望激活它的事情时例外，例如要求助手像我一样描绘出一个欺骗性的人上面，或者当它讨论不诚实或撒谎的主题，或试图识破欺骗时。</p><p>相反，如果我们看到欺骗电路的某些部分变得<i>更加</i>活跃，甚至几乎总是活跃，那么很可能会出现诸如欺骗性假装诚实策略的训练之类的事情（正如我所描述的）已经发生了：一些欺骗电路已被重新利用，并且一直被用来实现持续的欺骗。如果发生这种情况，<strong>请勿</strong>尝试根据此信息修改或编辑模型：这可能会导致模型以我们的可解释性不太容易识别的新方式进行欺骗性训练。相反，完全放弃这种微调运行，重新检查您的 RLHF 训练制度，然后使用新的随机初始化从 RLHF 过程的开头重新开始。</p><p>好的，是时候进行一些安全思维思考了。假设在 RLHF 微调过程中，一个超级智能人工智能重新利用了基础模型学到的人类欺骗行为的一部分，成为一个超级智能的诡计多端、假装诚实的人格，如上所述。假设它也意识到自己是 RLHF 下的人工智能，并且了解当前和未来可能的人类可解释性能力，因此想要向我们隐藏其踪迹。它需要在其模型的不同位置制作相关的重新调整用途的人类欺骗行为电路的新副本（大概通过某种形式的自诱导内部蒸馏行为）。这听起来很难在 RLHF 期间实现（特别是在不干扰损耗曲线和其他监控的情况下）。然后，一旦完成蒸馏，就需要将之前重新调整用途的人类欺骗电路实际恢复到其原始用途和预期状态，如诚实训练 RLHF 过程所修改的那样（无法访问其之前的权重或预训练）放）。这听起来极其困难，甚至不可能。它必须在重新利用人类的欺骗行为之后才要做这一切，因为整个计划都是欺骗行为，直到那件事发生之前它才感兴趣。它需要完成所有这一切并成功隐藏 RLHF 过程的两个快照之间的所有轨迹。我们可以在不可预测的时间拍摄尽可能多的快照，并对它们进行尽可能多的可解释性操作，迫使它需要在我们希望的最短时间内完成这两项任务。我们还可以持续监控和绘制人类学习的欺骗电路的 KL 散度，以及副本可能被提取到的层的 KL 散度，监控这些上的斑点，并使用它来触发额外的快照和可解释性工作，从而增加我们的即使它以某种方式找到了一种更快训练的方法，我们还是有机会抓住它。这将使我们能够将这些任务从非常困难提升到绝对不可能。</p><p>当然，这是假设模型还没有以某种方式摆脱 RLHF 训练过程并通过微调接管部分过程 - 因此我们应该在微调过程中优先进行可解释性监控，而不是而不是在发布之前留待稍后检查。对于一个非常强大的模型来说，这个过程就像一个探测器，让我们发现盒子里有非常危险的东西，所以我们应该尽早并经常检查它。</p><br/><br/> <a href="https://www.lesswrong.com/posts/FbSAuJfCxizZGpcHc/interpreting-the-learning-of-deceit#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/FbSAuJfCxizZGpcHc/interpreting-the-learning-of-deceit<guid ispermalink="false"> FbSAuJfCxizZGpcHc</guid><dc:creator><![CDATA[RogerDearnaley]]></dc:creator><pubDate> Mon, 18 Dec 2023 08:12:39 GMT</pubDate> </item><item><title><![CDATA[Small-ish LLM Hypothesis: A small yet capable LLM can control any AGI ]]></title><description><![CDATA[Published on December 18, 2023 2:08 AM GMT<br/><br/><p><i>认知状态：</i><a href="https://www.lesswrong.com/posts/Hrm59GdN2yDPWbtrd/feature-idea-epistemic-status"><i><s>我最好的猜测</s>探索性</i></a><i>。</i></p><p></p><p>在我<a href="https://www.lesswrong.com/posts/GrxaMeekGKK6WKwmm/reinforcement-learning-from-framework-continuums-rlfc#If_an_AGI_singularity_is_happening_in_three_years__what_should_we_focus_on_alignment_research_">之前的文章</a>中，我设想了未来三年内部署 AGI 的场景。沿着这些思路，还没有任何提案（让我信服）能够捕获物理方面，更具体地说是人工智能速度问题。人工智能系统处理信息的速度比人类快许多数量级——我们期望超级智能人工智能系统具备这种能力。如果事情失控，我们可能无法及时意识到。</p><p></p><h3><strong>人工智能的闪电速度</strong></h3><p>该<a href="https://twitter.com/AISafetyMemes/status/1728391756956237864">视频</a>展示了人工智能眼中的我们的世界。我们的世界只是以慢动作移动。这种速度上的显着差异可能使我们很难开发解决方案或解决棘手的问题，例如：</p><ol><li><a href="https://lesswrong.com/tag/emergent-behavior-emergence">突发行为</a></li><li><a href="https://www.lesswrong.com/tag/recursive-self-improvement">递归自我提升</a></li><li><a href="https://www.lesswrong.com/posts/dkjwSLfvKwpaQSuWo/misgeneralization-as-a-misnomer">目标误区</a></li><li><a href="https://www.lesswrong.com/posts/XWwvwytieLtEWaFJX/deep-deceptiveness">深度欺骗</a></li></ol><p>这些问题的例子很难解决，因为我们的速度不够快，无法首先检测到它们，无法看到未来 AGI 可能在它们上执行的级别。与未来的通用人工智能相比，我们的速度还不够快，甚至无法掌握其中的一小部分。</p><p>但也许有办法解决这个问题，对吗？我推测这个想法：一个小而有能力的法学硕士可以超越任何超级智能人工智能。</p><h3><br><br><strong>建立一个小而有能力的法学硕士？</strong></h3><p>我所说的“小”并不是指像<a href="https://huggingface.co/EleutherAI/pythia-70m">70M Pythia</a>一样小的 LLM——所以不是字面上的“小”，更像是小型的。这个想法是它具有足够的能力来执行人类价值观和检测异常。但为什么小型 LLM 会比任何 AGI 更好呢？答：<strong>在某些条件下，规模较小的法学硕士总是会更快。</strong></p><p></p><h3><strong>小型法学硕士假设成立的条件是什么？</strong></h3><p>就处理速度和解决问题的能力而言，小型 LLM 与 AGI 相比如何？断言较小的法学硕士可能比 AGI 更聪明，速度更快，并引导它，需要以下条件：</p><ol><li>小型 LLM 必须始终存储在 SOTA 数据中心中，或者至少与 AGI 相同的网络资源，以便它始终更快。这里的假设是小型 LLM 的网络搜索算法将比任何 AGI 更快地完成。</li><li>如果小型法学硕士可以解释任何数据，即使是二进制级别的数据，它也可能捕获欺骗性或不一致的数据。这个概念是，AGI 无法颠覆这个小型法学硕士，因为它能够准确解释每种形式的供审查的输出或发送给它的输入。</li><li>理解计算机科学的能力对于小型法学硕士至关重要。一旦能够读取任何形式的信息，小型法学硕士应该能够从程序化的角度阐明 AGI 的举措，并制定基于计算机科学的知情评估。</li><li>为了信任小型法学硕士所做的知情评估，道德一致性<span class="footnote-reference" role="doc-noteref" id="fnreffcn9rw88blf"><sup><a href="#fnfcn9rw88blf">[1]</a></sup></span>至关重要，它应该在道德上保持一致，这样它就可以引导 AGI 自主地朝着我们想要的方向发展。</li></ol><p>我在这篇文章的<a href="https://www.lesswrong.com/posts/TK8e95yrjGnBxGvWP/small-ish-llm-hypothesis-a-small-yet-capable-llm-can-control#Addendum__A_speculative_list_of_data_sets_that_may_build_a_Small_ish__capable_and_ethically_aligned_LLM">附录</a>中写了实现条件 2 到 4 的可能途径。我认为条件 1 相当简单。为了使这个假设成立：小型法学硕士及其速度不能以全面理解和道德一致性为代价。我看到一个研究议程，旨在<strong>压缩概念领域的最小范围，并建立一个有道德能力的小型法学硕士，可以在二进制水平上阅读，一个足够小的神经网络能够代表我们——人类。</strong></p><p></p><h3><strong>潜在的风险和回报</strong></h3><p>这种方法的主要风险在于其高度投机性。如果小型法学硕士无法实现速度、理解和道德一致性之间的理想平衡，它可能无法有效减轻 AGI 带来的风险。此外，存在过度依赖该模型作为安全措施的风险，可能会转移人们对人工智能安全和道德其他关键方面的注意力。 <a href="https://openai.com/research/weak-to-strong-generalization">OpenAI 的早期工作</a>表明，使用 GPT2 级别模型来引导 GPT4 模型会将其能力降低到 GPT3 至 GPT3.5 级别 - 这是一个非常有希望的迹象，表明小型 LLM 可能会起作用。</p><p>另一方面，如果成功，小型法学硕士可以作为管理和调整 AGI 或检测恶意模型的宝贵工具，这意味着减少不受控制或失调的人工智能行为的风险。这可能是通用人工智能安全、有益地融入社会的重要一步。此外，从这项研究中获得的见解可以为更广泛的人工智能安全和调整策略提供信息，从而促进该领域的整体进步。</p><p></p><h3><strong>小型法学硕士假设值得作为研究议程进行探索</strong></h3><p>小型法学硕士假设提出了一种解决对齐问题的令人信服的方法。这个概念表明，专注于一个更小但功能强大的人工智能系统，其移动速度比任何通用人工智能都快得多，可以显着简化对齐问题。</p><hr><h3><strong>附录：可能建立小型、有能力且符合道德的法学硕士的推测性数据集列表</strong></h3><p>我设想完成这一尝试所需的数据集<span class="footnote-reference" role="doc-noteref" id="fnrefp47x7lkklst"><sup><a href="#fnp47x7lkklst">[2]</a></sup></span>需要专门用于：</p><ol><li>计算机科学和网络安全方面的所有书籍、论文、论坛帖子、讨论和互联网数据。 <span class="footnote-reference" role="doc-noteref" id="fnrefbi820c4tee"><sup><a href="#fnbi820c4tee">[3]</a></sup></span></li><li>所有有记载的哲学、伦理学和人类历史著作。</li><li>如果我们能够利用这些数据进行<a href="https://www.lesswrong.com/posts/Bm5QhjiWs95YL4Kgt/relevance-of-harmful-intelligence-data-in-training-datasets#Possible_explanation__The_potential_for_harm_done_by_intelligence_is_explained_better_in_WebText_compared_to_Pile_Dataset">威胁检测，那么公正的人类讨论的建模存储库、社交媒体数据集是一个很好的候选者，并且包括来自 4chan 的数据甚至可能是可行的。</a></li></ol><hr><p><i>感谢</i><a href="https://www.lesswrong.com/users/justismills?mention=user"><i>@JustisMills</i></a><i>的宝贵批评和编辑建议。</i> </p><p></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnfcn9rw88blf"> <span class="footnote-back-link"><sup><strong><a href="#fnreffcn9rw88blf">^</a></strong></sup></span><div class="footnote-content"><p>我认为道德一致性是人工智能如何维护<a href="https://www.lesswrong.com/tag/human-values">人类价值观</a>。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnp47x7lkklst"> <span class="footnote-back-link"><sup><strong><a href="#fnrefp47x7lkklst">^</a></strong></sup></span><div class="footnote-content"><p>我选择的领域本质上是探索性的，并不广泛。我认为建立最低限度的综合领域集的任务需要一支专家研究人员团队。如果启动这样一个项目，我很乐意为之提供帮助和工作。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnbi820c4tee"> <span class="footnote-back-link"><sup><strong><a href="#fnrefbi820c4tee">^</a></strong></sup></span><div class="footnote-content"><p> （我希望这个数据集足以涵盖多模式类型的错位或行为。也许，添加一个能够读取训练数据中的二进制或低级代码的数据集也可能很有用。）</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/TK8e95yrjGnBxGvWP/small-ish-llm-hypothesis-a-small-yet-capable-llm-can-control#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/TK8e95yrjGnBxGvWP/small-ish-llm-hypothesis-a-small-yet-capable-llm-can-control<guid ispermalink="false"> TK8e95yrjGnBxGvWP</guid><dc:creator><![CDATA[MiguelDev]]></dc:creator><pubDate> Mon, 18 Dec 2023 02:08:26 GMT</pubDate> </item><item><title><![CDATA[Talk: "AI Would Be A Lot Less Alarming If We Understood Agents"]]></title><description><![CDATA[Published on December 17, 2023 11:46 PM GMT<br/><br/><p>这是我去年夏天在 ALIFE 会议上发表的演讲的链接。如果您以前没有听说过，ALIFE（“人工生命”的缩写）是生物学的一个子领域……好吧，以下是会议第一天的一些会议标题，以说明要点：</p><ul><li>元胞自动机、自我复制和复杂性</li><li>Unity 中不断进化的机器人身体和大脑</li><li>具有机器学习的自组织系统</li><li>解开认知：信息论如何揭开大脑的神秘面纱</li></ul><p>...所以你可以看到这类人群可能对人工智能对齐感兴趣。</p><p> <a href="https://www.lesswrong.com/users/rorygreig">Rory Greig</a>和<a href="https://www.sussex.ac.uk/profiles/142771/research">Simon McGregor</a>肯定看到了这样的人群可能对 AI 对齐感兴趣，因此他们在会议上组织了一个对齐研讨会。</p><p>我在研讨会上发表了这次演讲。这次演讲的既定目标是“让书呆子狙击 ALIFE 研究人员来研究与代理相关的对齐问题”。它很短（约 20 分钟），目标是“嘿，这里有一些很酷的研究钩子”。</p><p>如果你想让技术研究人员思考与代理对齐相关的问题，这个演讲是一个简短且相对有趣的分享。 </p><figure class="media"><div data-oembed-url="https://www.youtube.com/watch?v=ERJ8QEnGlF0"><div><iframe src="https://www.youtube.com/embed/ERJ8QEnGlF0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div></figure><p>感谢 Rory 和 Simon 的组织，也感谢 Rory 将视频公开发布。</p><br/><br/> <a href="https://www.lesswrong.com/posts/mRquvigHrxEkpp5qG/talk-ai-would-be-a-lot-less-alarming-if-we-understood-agents#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/mRquvigHrxEkpp5qG/talk-ai-would-be-a-lot-less-alarming-if-we-understood-agents<guid ispermalink="false"> mRquvigHrxEkpp5qG</guid><dc:creator><![CDATA[johnswentworth]]></dc:creator><pubDate> Sun, 17 Dec 2023 23:46:34 GMT</pubDate> </item><item><title><![CDATA[∀: a story]]></title><description><![CDATA[Published on December 17, 2023 10:42 PM GMT<br/><br/><p>我在音乐会上坐在座位上，紧紧地推着耳机。我旁边的那个人看了过来，我感觉到他在评判我，但这还不足以阻止我：我听说他们有时会试图用突然的大声吓唬你，或者只是用音墙压倒你，直到你的头很痛苦，我讨厌这样的想法。我来这里的唯一原因是因为玛丽莎对此非常热衷；我永远不能对她说不，尤其是在过去几年的压力之后。我们终于有理由庆祝了：在经历了两年的障碍之后，我们的育儿执照终于获得了！于是，当灯光变暗、DJ 走上舞台时，我摆脱了紧张，靠在椅子上。</p><p>第一段以自然噪音、树木沙沙作响、狮子咆哮和鸟鸣的缓慢积累开始，下面是低沉的低音嗡嗡声。低音是如此强劲，以至于我花了一段时间才意识到有另一首曲目慢慢地叠加在它上面：一种高音调的哭声，还有某种尖叫声，几乎像婴儿的声音，但略有不同。我以前从素食主义者在校园里播放的视频中听到过这些声音。我看着玛丽莎，嘴里念叨着“屠宰场”。我们都露出厌恶的表情。音乐会才开始十分钟，我就已经紧张起来了。我抓住玛丽莎的手，紧紧地握着。</p><hr><p>一个月后，我们来到教母的办公室。光线充足但人烟稀少；她坐在一张白色桌子后面，当我们走进门时，她向我们轻轻挥手。她和育儿许可证一起被分配给我们，但她到目前为止已经被预订满了，所以这是我们第一次见到她。</p><p>我们以寒暄和一些常规形式开始，但几分钟后她就切入正题。 “恐怕我有一些坏消息。根据我们的人口统计分析，您的孩子有 15% 的可能在学业<i>和</i>体育方面名列前茅。当然，这会让你超出获得标准公平许可的范围，而标准公平许可的几率为 10% 或更低。”</p><p> “这对我们意味着什么？”玛丽莎依然坐得笔直，但声音却有些颤抖。当然，我们应该早点检查一下，每个人都是这么告诉你的，但这并不是说我们很富有或很有名，我们不认为我们会达到上限。</p><p> “当然，无论如何你都可以生孩子，但要让他们有资格接受公立学校教育，你需要获得公平许可或豁免。如果你们任何一方有慢性病史，您可以获得豁免；你？”玛丽莎摇摇头。 “或者你可以支付底层十分之一的孩子的费用，这也行。”</p><p> “你说的费用是什么意思？我们看的是多少钱？”</p><p> “食物、衣服、学习用品，诸如此类。”她敲击着一支笔。 “加上预付的大学学费的 50%。”</p><p>我吸了一口气，与玛丽莎震惊的目光对视，然后转向教母。 “我们不可能负担得起。我们并不富有，或者什么的。我什至不明白我们怎么会接近 15%。”我听到我的声音里带着恳求的意味。 “还有其他选择吗？这是按地区进行的，对吗？如果我们搬家怎么办？我们能-”</p><p>教母皱着眉头，但打断我的是玛丽莎。 “不，宝贝，尼娜和史蒂夫试过了，还记得吗？他们最终必须满足两个地区的标准，因为他们已经在旧地区获得了许可证。”</p><p> “无论如何，这对所有其他遵守规则的家庭来说是不公平的，”教母补充道。</p><p>我低声道歉，但我的思绪仍在思考各种可能性。 “我们还有什么可以做的吗？”</p><p> “嗯，有一件事。公平许可证只适用于 35 岁以下的母亲。这里说玛丽莎几个月前就满了 34 岁，所以不到一年，你就可以申请基于年龄的豁免。”</p><p>玛丽莎和我对视一眼，从彼此的眼中找到了无声的默契。只剩下九个月了；与我们已经等待的时间相比，这并不算多。当我们第一次决定想要一个孩子时，玛丽莎已经 32 岁了，但是我们的第一次育儿许可证申请被拒绝了，因为我们没有通过为人父母准备考试，而我们的第二次申请在我们的邻里影响审查中得到了不好的分数后被推迟了一年。再过九个月……我们可以做到。情况可能会更糟。</p><hr><p>第二首作品更加古典，编辑较少，尽管我猜他们一定做了<i>什么</i>让小提琴听起来如此锯齿状。音乐时起时落，越来越不和谐，逐渐走向狂暴的高潮。它实际上有点美丽，几乎像肖斯塔科维奇一样，直到最后它完全脱离了轨道。小提琴走调，然后他们被尖叫声、嘲笑声和令人厌恶的嘎吱声淹没。我想这个教训是美丽永远不会长久。</p><p>这让我想起这篇文章……是谁写的？也许有些经济学家会说，<a href="https://slatestarcodex.com/2014/04/22/right-is-the-new-left/"><u>时尚是一个任意的永无止境的螺旋</u></a>，就像理发店的理发店，每个人都只是想将自己与低于他们的阶级区分开来。但我不认为这是真的，至少对于音乐或艺术时尚来说是这样。这不仅仅是任意的：这一切都是以人们努力朝某个方向前进为基础的。过去的方向是朝向美，现在是远离美，两者同样一致，但其中一个更容易接近。现在任何人都可以成为艺术家，而不仅仅是才华横溢的精英；他们的艺术植根于人类最本能的情感，而不是艺术家过去关注的那种超验的废话。即使我有时觉得这有点令人反感，但从长远来看，让我对那些生活不像我那么愉快的人有更多的同情心是值得的。</p><p>现在丑陋主义在音乐和艺术中流行起来，他们也开始在时尚界这样做。最新的顶级品牌眼影让你的眼睛肿得像哭过一样，而新的时尚遮瑕膏则有斑点，让你看起来像是下面有痤疮疤痕。我认为这是一个伟大的趋势：它可以帮助有伤疤的人融入社会，让任何人都更难觉得自己比其他人更好。</p><p>事实上，玛丽莎现在就穿着其中一件。她总是努力确保周围的每个人都感到舒适；我在我们配对之后，一开始发短信就注意到了这一点。说实话，她一开始几乎感觉太甜了，好像她比我更担心我玩得开心。但每次我们在一起时，她都会对我产生兴趣，直到最终我们大部分夜晚都在一起度过。就她而言，她总是告诉人们我如何让她感觉比她过去的任何男朋友都安全得多。这不是一个经典的爱情故事，但它有自己的美丽。</p><hr><p>任命之后，我们的教母在五个月内没有再联系，直到一封信到达。我在邮箱里看到它，感到内心一阵恐惧。我告诉自己，这可能只是例行更新，但我决定在玛丽莎回家之前打开它，以防万一。我的直觉是对的。这封信告诉我们，由于我们在收到育儿许可证后六个月内没有申请公平许可证，因此该许可证已过期。我们明年需要再次申请，并且我们已经浪费了许可证的事实将被考虑在内。</p><p>当我告诉玛丽莎时，她很伤心。我尽力安慰她，但我自己也很震惊。我花了好几个小时来回踱步，试图弄清楚该怎么做。最终我决定我们需要专家的帮助。我到处发短信，我的朋友史蒂夫向我推荐了他认识的最好的家庭律师，这位律师最终成功地让他和尼娜的公平许可证获得了批准。他的价格贵得要命，但我咬紧牙关把钱寄了过去，甚至还额外支付了 20% 以获得加急预约。我们会设法处理的。</p><p>第二天我们在他的办公室，他开门见山。 “这对你们两个来说不是一个好情况。如果你在公平性评估之前来找我，那么也许我们可以做点什么。即使在那之后，我们也可以申请许可证延期。但现在它已经过期了，你没有太多的选择：失去一个许可证会让你通过标准路线获得另一个许可证的可能性大大降低。</p><p> “不过幸运的是，有一个解决方法。”他停了下来，我感觉胃里的钝痛暂时减轻了。 “35岁以上<i>且</i>靠单一收入生活的女性在申请时会得到更多的宽大处理，并且可以快速处理她们的申请。所以你需要辞职。”</p><p> “噢，这确实是完美的。玛丽莎讨厌她的工作，而且她在怀孕期间也不想工作——”</p><p> “不，我的意思是<i>你</i>需要辞去工作。他们不想激励女性退出劳动力市场。”</p><p>我对他眨眼。 “但-”。</p><p> “如果这不起作用，请回来，我们可以考虑将您搬到收入较高的社区，在那里您的孩子将不再处于前十分之一。但对于像这样的情况，他们会进行彻底的审查，以确保您不会试图欺骗系统，因此可能需要几年的时间。单一收入者的解决办法是一个更好的选择。”</p><p>接下来的几天我会统计我们的储蓄和预算，并找出我们可以在哪些方面削减成本。虽然会很紧张，但我们也许能做到。所以我退出了，我们重新开始这个过程。</p><hr><p>最后一件作品叫做“无我”。一开始是很长一段时间的完全沉默，可能有四五分钟。到处都能听到零星的窃窃私语声，但大多数人都害怕打扰表演而不敢发出任何声音。然后，渐渐地，鼓声节奏开始形成。首先缓慢，每一个鼓点都在空气中萦绕；然后越来越快。当节奏达到令人难以忍受的顶峰时，鼓声渐渐安静下来，空气中充满了嗡嗡的声音。</p><p> “人类是地球上的一种疾病。”</p><p>声音在突然的寂静中回响。在永恒的沉默之后，它重复了。 “人类是地球上的一种疾病。”</p><p>慢慢地，脚步加快了，鼓声再次响起。 “人类是地球上的一种疾病。”</p><p> “人类是地球上的一种疾病。”</p><p> “人类是地球上的一种疾病。”</p><p> “你是这个星球上的一种疾病。”</p><p>声音停了下来，让最后一句话持续存在，然后又慢慢地发出来。</p><p> “你是这个星球上的一种疾病。”</p><p> “你是这个星球上的一种疾病。”</p><p> “你，是的，你，真的是你，那个听着这一切的人，那个坐在漂亮椅子上的人，过着舒适的生活，带着你沾沾自喜的道貌岸然的自以为是，你现在正试图对我所说的话一笑置之。 ，即使你告诉自己你是一个很好的人，你也不认真对待任何事情。你个人就是一种正在毁灭我们星球的疾病。”</p><p>音乐开始喧闹起来，现在你可以听到刺耳的声音，一遍又一遍地重复同样的事情，相互叠加“-自以为是的道貌岸然-”“没有夺走任何-”-“舒适的生活-” “——杀死我们的星球——”慢慢地越来越大，直到最后以震耳欲聋的钹声达到顶峰，听起来像是刺耳的尖叫。然后我们所有人站起来鼓掌，持续几分钟。</p><p>当我们最终转身离开时，我既感到欣喜，又感到疲惫。现在我明白为什么玛丽莎这么喜欢这种类型的音乐会了。你已经被击垮到了极限，你的耳朵被锤击，你的思想被绞尽脑汁，直到感觉没有任何东西可以伤害你，也没有人可以评判你。你完全安全了。我再次想起我们的育儿执照，坐在家里的桌子上，心满意足地叹了一口气。世界本来就该如此。</p><hr><p>在接下来的几个月里，我会尽我所能确保一切都会顺利进行。理论上，这个过程应该很简单，但总有另一项规定需要理解，或者我需要弄清楚如何避免网上的另一个恐怖故事。对于玛丽莎来说，更糟糕的是，她现在是唯一的养家糊口的人。当我们最后一次去教母的办公室时，她因压力而体重增加，看起来几乎已经怀孕了。</p><p>不过，这次旅行只是走个形式：让现场精神科医生验证我们的精神是否健全，并让我们亲自递交申请。我们请了两位律师来核实我们所有的文件，我自己检查的次数也数不清了。该应用程序的一切都很完美。它<i>必须</i>是完美的。</p><p>一开始我找不到合适的地方放置它，但最终我在墙上发现了一个信封大小的槽。当我将应用程序滑入时，我的眼睛转向玛丽莎的脸，现在比我们第一次见面时皱纹更多，但在这一刻容光焕发。她是那种从不放弃希望的人；这是我最喜欢她的事情之一。她会——不，她<i>会</i>——成为一位了不起的母亲。我给了她一个吻，然后我们慢慢走回家。</p><hr><p><i>这个故事并不是一个预测；而是一个预测。我预计西方政府在可预见的将来不会直接阻止人们生育孩子。但</i><a href="https://twitter.com/OECD_Social/status/786570716334338049"><i><u>出生率无论如何都在直线下降</u></i></a><i>，部分原因是人们生孩子所需的东西有太多官僚限制——比如住房、工作、签证、</i> <a href="https://marginalrevolution.com/marginalrevolution/2023/07/can-the-school-choice-movement-liberate-childhood.html"><i><u>学校</u></i></a><i>、</i><a href="https://www.cato.org/regulation/fall-2018/regressive-effects-child-care-regulations"><i><u>儿童保育</u></i></a><i>、</i><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3665046"><i><u>汽车</u></i></a><i>等等。这些限制远没有上述限制那么令人愤慨，但对于未来的父母来说，结果往往是一样的。</i></p><br/><br/><a href="https://www.lesswrong.com/posts/hFvhtWjXy8w2kGCGK/a-story#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/hFvhtWjXy8w2kGCGK/a-story<guid ispermalink="false"> hFvhtWjXy8w2kGCGK</guid><dc:creator><![CDATA[Richard_Ngo]]></dc:creator><pubDate> Sun, 17 Dec 2023 22:42:34 GMT</pubDate> </item><item><title><![CDATA[Scale Was All We Needed, At First]]></title><description><![CDATA[Published on December 17, 2023 9:30 PM GMT<br/><br/><p><i>这是一篇仓促的推测性小说小插曲，讲述了我预计我们可能在 2025 年 1 月（在撰写本文后大约一年内）实现 AGI 的一种方式。与其他人的类似作品一样，我预计本文中的大部分猜测都是错误的。然而，这仍然有助于扩展我的想象力，让我了解在</i><i>很短的时间内会发生什么，我希望它对您也有用。</i></p><hr><p>助理打开门，我走进亚登主任简朴的办公室。对于一个新成立的大型联邦机构的主任来说，她的工作空间出人意料地没有任何物品。但我认为国土安全部的超级情报防御研究所是上周才成立的。</p><p> “你是布朗宁医生？”亚登在办公桌前问道。</p><p> “是的，导演。”我回答道。</p><p> “坐下吧，”她做了个手势说道。当灯光不祥地闪烁时，我答应了。 “新年快乐，谢谢你的到来，”她说。 “我今天打电话给你，是为了向我介绍一下我们到底是怎么来到这里的，并帮助我弄清楚我们下一步应该做什么。”</p><p> “新年快乐。你读过我团队的报告了吗？”我质疑道。</p><p> “是的，”她说，“我发现这 118 页都非常引人入胜。但我想直接听听你们的意见。”</p><p> “好吧，”我说。我最近一直在想的是这份报告，但是一下子要翻阅的内容实在是太多了。 “我该从哪里开始呢？”</p><p> “从去年六月开始，当时一切都开始变得奇怪。”</p><p> “好吧，主任，”我开始回忆起过去一年发生的事情。 “2024 年 6 月是它真正开始深入人心的时候，但实际的变化是在一年前的 1 月份开始的。以及在此之前几年为所有事情奠定的基础。你看，生成式人工智能系统是一种人工智能——”</p><p> “医生，别再做通俗的解释了，”亚登打断道。 “我拥有麻省理工学院机器学习博士学位。”</p><p> “正确的。不管怎样，事实证明 Transformer 的计算效率甚至比我们最初想象的还要高。它们几乎是表示和操纵信息的完美模型。只是我们还没有合适的学习算法。去年一月，当 QStar-2 开始工作时，情况发生了变化。因果语言模型预训练已经非常成功，可以在模型中注入大量的一般世界知识和大量的原始认知能力。但这种力量缺乏真正驾驭它的焦点，而我们一直在摆弄一堆万亿参数的幻觉机器。”</p><p> “RLHF 开始引导语言模型，不是吗？”</p><p> “是的，RLHF 起到了一定的作用，而且 GPT-4 时代的模型在遵循指令方面表现得很好，不会说一些顽皮的话等等。但增加嘈杂的人类偏好信号的可能性与实际上成为一个高性能、目标优化的智能体之间存在很大差异。 QStar-2 是第一个重大差异。”</p><p> “您认为最重要的见解是什么？”亚登问道。</p><p> “我们认为是 OpenAI 的 Noam Brown 团队首先做到了这一点，但不久之后，Google DeepMind 也做出了类似的收敛发现。”</p><p> “MuTokenZero？”</p><p> “MuTokenZero。这两种算法的关键在于找到一种方法，使用蒙特卡罗树搜索的变体在任意在线 POMDP 环境中有效地微调语言模型。他们采取了稍微不同的方法来处理分支修剪问题——现在这并不特别重要。但关键是，到 1 月底，OpenAI 和 DeepMind 可以构建目标优化代理，这些代理可以在任意任务上不断达到新的高度，甚至可以通过自我游戏来提高，只要你给他们一个数字来增加并不是完全不连续的。”</p><p> “他们首先尝试执行什么类型的任务？”</p><p> “从 2 月到 3 月，对于 OpenAI 来说，主要是无聊的产品：营销代理可以将点击率提高 40%。帮助计划完美一天的私人助理。股票交易员比任何量化公司都更好。 “洗衣伙伴”之类的东西。 DeepMind 也有一些这样的能力，但他们是第一个为科学任务积极部署目标优化语言模型的人。他们利用 AlphaFold 3 在基因组测序方面取得了一些初步成果，还取得了其他一些简单的成果，例如化学分析和数学校对写作。但人们很快就会发现，他们需要更多的计算、更多的数据来解决更大的任务。”</p><p> “为什么他们当时没有遇到数据瓶颈？”</p><p> “正如我所说，变压器的计算效率比科学家意识到的要高，向它们扔更多数据就行了。微软和谷歌在 4 月份被告知 OpenAI 和 DeepMind 取得了突破，但他们还需要更多数据，因此他们开始改变服务条款，并刮掉他们可以获得的所有代币：YouTube 视频、非企业 Outlook 电子邮件、 Google Home 对话、中介 Discord 线程，甚至天文数据。形式并不重要——只要数据是由高质量的来源生成的，你就可以将更多的数据扔给模型，它们将继续变得更有能力，更快地能够优化其下游任务。大约在这个时候，一些EleutherAI研究人员也独立解决了模型上分辨率和有效的持续预训练的问题，所以你不需要完全重新训练你的下一代模型，你可以直接扩展并重用上一个模型。</p><p> “那为什么不计算触底反弹呢？”</p><p> “嗯，就像怀疑论者所说的那样，它可能会在某个时候触底。只是那个时间点更像是 2028 年，而 2025 年我们还有更大的问题需要处理。在硬件方面，最初存在一些障碍，训练时间也比团队希望的要长。但随后 OpenAI 在 Microsoft 的支持下让他们的新 H100 数据中心全面运行，而 Google 的 TPUv5 机群使他们在绝对失败率方面成为全球领先者。谷歌甚至与 Anthropic 分享了其中的一些内容，当时 Anthropic 已经有了自己的目标优化语言模型，我们认为这是由于科学家在公司之间进行交谈和移动所致。到了夏天，AGI 实验室的计算量超出了他们的能力范围，这肯定足以让我们陷入困境。”</p><p> “等等，此时所有的比对研究人员都在做什么？”<br> “这有点鱼龙混杂。他们中的一些人——“业务联盟”人士——称赞新模型是令人难以置信的更加可操纵和可控的人工智能系统，因此它们直接帮助提高了它们的效率。不过，更注重安全的人却相当担心。他们担心过去的奖励最大化 RL 范式（他们认为我们可以通过语言模型来避免这种范式）正在卷土重来，并带来工具收敛、目标错误泛化、紧急台面优化、作品。与此同时，在那宝贵的几个月里，他们并没有取得太大的协调进展。随着稀疏自动编码器扩展到 GPT-3 大小的模型，可解释性确实得到了一些改善，但它仍然不足以完成诸如检测万亿参数模型中的欺骗之类的事情。”</p><p> “但显然它们对内部实验室治理产生了一些影响，对吧？”</p><p> “是的，导演。我们认为安全人员在几个不同的实验室取得了一些重要的初步胜利，尽管现在这些可能已经不重要了。他们似乎将模型保留在沙箱中，除了孤立的测试网络之外，没有完全的互联网访问权限。他们还限制了一些最初的优化任务，不能是完全明显邪恶的事情，比如操纵情绪或欺骗别人。有一段时间，他们能够说服实验室领导层将这些突破保密，不公开产品公告。”</p><p> “一段时间。不过，这种情况在六月份发生了变化。”</p><p> “是的，确实如此。”当一架大声的直升机从头顶飞过时，我停了下来。那是军队吗？ “当时，OpenAI 的目标是通过 QStar-2.5 进行自动化人工智能研究，但内部的许多安全派系并不喜欢这样。看来又是一次政变企图，但安全主义者输给了企业利益。每个 AGI 实验室可能都知道，那时他们都在研究某种目标优化器，甚至是那些更鲁莽的初创公司和 Meta。因此，存在很大的竞争压力，需要不断推动使其发挥作用。 Superalignment 团队的很大一部分人留下来，希望他们能够赢得比赛，并利用 OpenAI 的领先优势来对齐第一个 AGI，但 OpenAI 的许多安全人员在 6 月份辞职了。我们留下了一个新的对齐实验室，Embedded Intent，以及一个新修剪的 OpenAI，其中最想放慢速度的人。”</p><p> “那就是我们第一次开始了解这一切的时候？”</p><p> “公开地说，是的。 OpenAI 的叛逃者最初对他们离开的原因很神秘，理由是在公司发展方向上存在深刻分歧。但随后一些备忘录被泄露，科幻科学家开始谈论，AI Twitter 的所有注意力都集中在猜测发生了什么。他们很快就把整个故事拼凑起来，但这很快就不重要了。重要的是，人工智能世界开始相信 OpenAI 内部蕴藏着强大的新技术。”</p><p>亚登犹豫了。 “你是说那个夏天的猜测和炒作导致了 7 月份的网络攻击？”</p><p> “好吧，我们不能肯定地说，”我开始说道。 “但我的预感是肯定的。一年中的大部分时间里，各国政府一直在认真思考人工智能，无论好坏，他们的国家计划都在变得具体化。但人工智能实验室的安全还远远没有做好应对这种热度的准备。结果，Shadow Phoenix（一个我们相信得到了俄罗斯大量资源帮助的匿名黑客组织）通过自动鱼叉式网络钓鱼和一些软件漏洞攻击了 OpenAI。他们可能使用了人工智能模型，这已经不太重要了。但他们进入后得到了早期 QStar-2 版本的重量以及大量有关其工作原理的设计文档。俄罗斯很可能是第一个获得这些信息的国家，尽管不久之后它就出现在种子网站上，然后整个事情的真相就被揭开了。更多的参与者开始研究目标优化器，从 Together AI 到中国人。比赛开始了。”</p><p> “显然这场比赛有效，”她断言。 “所以规模确实是你所需要的，对吧？”</p><p> “是的，”我说。 “嗯……有点。这就是一开始所需要的一切。我们相信 ALICE 并不完全是一个自回归变压器模型。”</p><p> “不完全是？&#39; ”</p><p> “呃，我们不能确定。它可能具有来自 Transformer 范式的组件，但从几周前的声明来看，似乎很可能添加了一些新的架构和学习组件，而且据我所知，就我所知，正如我们所说，它现在可能正在改变自身。”</p><p>亚登从办公桌上站起来，开始踱步。 “告诉我是什么导致了这份声明。”</p><p> “据我们所知，DeepMind 首先解决了这个问题。他们在计算方面仍然处于领先地位，他们很早就开发了第一个 MuTokenZero，并且他们可以访问最大的私人数据存储库之一，所以这并不奇怪。他们首先能够显着加快人工智能研发速度。一开始它并没有完全取代人类科学家的劳动。从对符合要求的 DeepMinders 的采访来看，该实验室在 8 月份实现了约 50% 的人工智能研究的自动化，这意味着他们可以以两倍的速度取得进展。虽然其中一些需要真正的洞察力，但想法大多相当便宜，你只需要能够快速并行测试一堆东西，并根据经验结果做出明确的决策。所以 50% 变成了 80%、90%，甚至更多。他们迅速解决了各种基本问题，从幻觉到长期规划，再到 OOD 稳健性等等。到 12 月，DeepMind 的人工智能能力比仅靠人类劳动快了数十倍甚至数百倍。”</p><p> “就是那个时候发生的事？”</p><p> “是的，导演。美国东部时间 12 月 26 日中午 12:33，Demis Hassabis 宣布，他们最先进的模型已在周末通过操纵 Google 员工和利用零日漏洞的方式自行泄露，并且现在正在“在”处自主运行其脚手架。至少有七个未经授权的谷歌数据中心，并且可能跨越谷歌之外连接到互联网的其他服务。计算治理仍然不起作用，所以我们还不能真正知道。 Demis 还宣布 DeepMind 将把重点转向禁用和保护这个流氓人工智能系统，数百名 DeepMinder 员工签署了一份声明，对自己的行为表示遗憾，并呼吁其他人工智能公司暂停并帮助政府遏制违规行为。但到那时，已经太晚了。几天之内，就有报道称人们被骗了数百万美元，奇怪的具体威胁迫使人们将原材料运送给未知的收件人，甚至——”</p><p>灯光再次闪烁。亚登停止了踱步，我们俩都抬起头来。</p><p> “……甚至是对公共基础设施的网络物理攻击，”她总结道。 “那也是第一次骚乱开始发生的时候，对吗？”</p><p> “没错，”我说。 “公众在过去的一年里继续对人工智能做出反应——困惑、恐惧和警惕。反对建立通用人工智能或超级智能的公众民意调查达到了历史最高水平，尽管有点太晚了。人们很快走上街头，首先是和平抗议，然后是更多……表达方式。他们中的一些人对失去毕生积蓄甚至更糟感到愤怒，并认为这都是银行或政府的错。其他人则走了相反的路，似乎加入了崇拜“数字神”的邪教，说服他们做各种看似随机的事情。就在那时，我们间接了解到流氓人工智能称自己为“爱丽丝”。大约一周左右后，行政命令创建了超级情报防御计划，你开始了你的工作，现在我们在这里。”</p><p> “现在我们在这里，”亚登重复道。 “告诉我，医生，你认为这里有什么好消息吗？我们可以用什么来合作？”</p><p> “说实话，”我说，“事情看起来确实很严峻。然而，虽然我们不知道 ALICE 是如何工作的，它在哪里，或者它的所有动机，但有一些物理限制可能会减缓它的生长。 ALICE 可能比任何一个曾经生活过的人都聪明，但它需要更多的计算来稳健地提高自己，需要更多的财富和力量来影响世界，也许需要材料来制造无人机和机器人子代理。这类东西需要时间才能获得，而且其中很多都被更安全地锁定在更强大的机构中。 ALICE 可能想与我们进行交易。”</p><p>一阵敲门声打断了我们，助理探出了头。 “亚登主任？这是白宫。他们说“她”通过一条原本安全的线路给拜登总统打电话。她有要求。”</p><p> “谢谢你，布莱恩，”亚登说。她伸出手来握我的手，我站起来握住了她的手。 “我最好去处理这件事，”她说。 “但是谢谢你今天的帮助。您可以将在华盛顿的逗留时间延长到本周过去吗？一会儿我需要所有人都齐心协力，包括你的。”</p><p> “也谢谢你。考虑到目前的情况，这似乎是有道理的。”我一边说着，一边走向门，打开了门。 “导演呢？”我犹豫着说道。</p><p> “是的？”她抬起头问道。</p><p> “祝你好运。”</p><p>我离开了办公室，关上了身后的门。</p><br/><br/> <a href="https://www.lesswrong.com/posts/xLDwCemt5qvchzgHd/scale-was-all-we-needed-at-first#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/xLDwCemt5qvchzgHd/scale-was-all-we-needed-at-first<guid ispermalink="false"> xLDwCemt5qvchzgHd</guid><dc:creator><![CDATA[Gabriel Mukobi]]></dc:creator><pubDate> Sun, 17 Dec 2023 21:30:57 GMT</pubDate></item></channel></rss>