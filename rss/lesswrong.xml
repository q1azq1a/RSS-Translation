<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 12 月 2 日星期六 16:13:59 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[The goal-guarding hypothesis (Section 2.3.1.1 of "Scheming AIs")]]></title><description><![CDATA[Published on December 2, 2023 3:20 PM GMT<br/><br/><p>这是我的报告《<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？》</a>的第 1.1 节。 ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p>本节的音频版本<a href="https://www.buzzsprout.com/2034731/13984880">请点击这里</a>，或者在您的播客应用程序上搜索“Joe Carlsmith Audio”。</p><h1>将奖励作为权力驱动的工具策略的一部分</h1><p>到目前为止，我们已经涵盖了上面列出的策划的三个先决条件中的两个：即态势感知和超越情节的目标。让我们转向第三个：即，模型得出的结论是，如果它优化了情节奖励，那么它的情节外目标将会更好地实现——特别是，它或其他一些人工智能将获得更多的权力，如果它就是这样做的。我们是否应该期望具有超越情节目标的情境感知模型能够得出这样的结论？</p><p>现在，我们假设模型在这方面的结论是<em>准确的</em>（不过：我将在下面讨论放宽这一假设的可能性）。这意味着问题归结为：事实上，凭​​借其赋予模型或其他人工智能的能力，工具训练游戏是否会成为实现模型的超集目标的最佳策略？</p><p>我将首先检查我认为最常提供的支持这一结论的故事——我称之为“经典的守门故事”。</p><h2>经典的守门故事</h2><p>经典的守门故事大致如下。” <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-1" id="fnref-ZB8uumQ8B94KMrTfP-1">[1]</a></sup></p><ol><li><p><strong>目标内容完整性的工具价值</strong>：因为该模型具有超越情节的目标，所以它通常会促进追求该目标的代理在未来生存并获得授权。</p></li><li><p><strong>守门假说</strong>。如果模型在训练期间优化了奖励，那么在训练中存活下来的目标将是模型希望它们在未来得到提升；而如果模型在训练过程中没有优化奖励，那么模型就会减少这种奖励。</p></li><li><p><strong>给未来足够的赋能。</strong>以在（2）中的关键程度进行训练为条件，模型的目标最终将在一定程度上（并且有足够的概率）被授权，以证明（给定模型的其他目标、其对风险的容忍度等）追求训练-游戏的整体策略。</p></li></ol><p>这里，（1）是对经典守门故事背后的基本动力的相当笼统的陈述。我发现在（3）中所涉及的“充分的未来授权”的背景下它是合理的，我不会在这里花很多时间。 <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-2" id="fnref-ZB8uumQ8B94KMrTfP-2">[2]</a></sup></p><p>相反，我将直接关注 (2) 和 (3)。</p><h3>守门假说</h3><p>我们可以区分守门假说的两种变体——极端版本和宽松版本。</p><ul><li><p>极端版本（我称之为“结晶假设”）说，一旦模型开始训练游戏，其目标将基本上停止变化，也就是说，它们将“结晶”。</p></li><li><p>更宽松的版本表示，一旦模型开始训练游戏，其目标可能会不断发生<em>一些</em>变化，但比其他情况下的变化要小得多，并且不足以让经典的守门故事整体失败。</p></li></ul><p>前者可能看起来很极端，但一些分析师明确诉诸附近的某些事物（参见<a href="https://www.lesswrong.com/posts/A9NxPTwbw6r6Awuwt/how-likely-is-deceptive-alignment">此处</a>的 Hubinger）。这也是初始分析的一个更清晰的焦点，所以我将从这里开始。</p><h4>结晶假说</h4><p>据我了解，结晶假说背后的基本思想是，一旦模型明确针对指定目标或情节奖励（无论是最终的还是工具性的）进行优化，那么其认知的目标部分（根据奖励信号的灯光，比喻性的“目标位置”）已大致变得最佳。也就是说，模型的“目标实现引擎”指向获得奖励的最佳方向，剩下的就是 SGD 改进目标实现引擎本身——目标槽的进一步改变只会重定向目标——使引擎实现不太理想的目标。</p><p>但这是对的吗？我不知道。特别是：如果我们假设所涉及的目标导向性相当“干净”，其中目标槽和实现目标的引擎是完全分开的，那么这个论点就最有意义。如果我们假设一种更混乱的目标导向形式——一种模糊了模型的“目标”与启发式、品味、冲动、注意力模式等之间的界限的模型，这些也构建/驱动了其“能力”——那么论证在我看来更值得怀疑。</p><p>为了说明这一点，请考虑以下示例。假设我是一位长寿的利他主义者，对堆砖没有内在兴趣，而一位奇怪的亿万富翁向我提供了以下交易。我进入沙漠堆砖一百万年，我的大脑连接到一台机器，它不断地调整我所有的神经元，这样，每次我堆砖的效果都比预期好（机器有某种方法来计算这个）期望），它会改变我的大脑，使我下次做的事情<em>更有</em>可能发生，每次我堆砌的砖块比预期更糟糕时，它都会改变我的大脑，使我下次做的事情的可能性<em>更小</em>。然后，在这个过程结束时，这位万亿富翁将给我数十亿美元，让我做任何我想做的事——例如，做非常无私的事情，如果我仍然愿意的话。</p><p>假设，如果我能够在这样的过程中生存下来并且我的价值观完好无损，那么在我看来，这将是一笔非常有吸引力的交易。我应该接受吗？</p><p>如果我们将结晶假说的类比应用于这种情况，我们会回答“是”。也就是说，结晶假说认为，为了防止我的目标被改变，我只需要尽可能地堆砌砖块即可。在这样做的过程中，我将证明我实现目标的能力指向最佳方向，并且连接到我大脑的机器只会有动力修改我的<em>能力</em>，以便我更擅长砖块-堆叠——我的潜在动机将保持不变。</p><p>但我不确定这是否有效。也就是说，在我看来，在连接到这台机器上一百万年的砌砖之后，我的“价值观”确实会得到有意义的“触动”，这似乎是相当合理的。例如，我会学会喜欢良好的砖块堆叠的复杂性，我会学会对错误堆叠的砖块产生本能的厌恶，等等。我似乎不太可能仅仅以同样的老利他主义者的身份出现，除非现在非常擅长堆砖。</p><p>当然，进一步的问题是我的价值观是否会得到<em>足够的</em>保留，以至于值得整体进行交易（请参阅下面对“松散”守门假说的讨论）。我的观点是，期待严格的结晶似乎是一种强硬的立场。我认为“混乱的目标导向”可以帮助解释原因。也就是说，在我们认为我的启发/冲动/注意力模式等与砖块相关的重要程度<em>与</em>我的砖块相关<em>价值观</em><em>和</em>我的砖块相关能力紧密相关的程度上，它变得更难SGD 仅修改后者，而完全不考虑前者。</p><p>上面讨论的工厂化养殖案例提供了这种动态的另一个例子。假设一位富有同情心、心软的动物权利活动家为了赚钱，在工厂化农场工作了几十年，最后将钱捐给动物权利组织。假设它们始终连接到一台机器，就像堆砖例子中的机器一样，这台机器不断地将它们修改为更高效的工厂化农场。在农场工作会影响他们与动物权利相关的价值观吗？我怀疑这至少在某种程度上会发生——特别是，他们对周围环境中的动物变得<em>不</em>那么敏感和心软。这如何影响他们最终的捐赠倾向是一个进一步的问题——但假设这份工作将留下一个完全静态的孤立的“目标位置”，在我看来，思考这种情况的方式是错误的。</p><p>即使除了考虑混乱的目标导向性之外，我认为还有其他原因，我将在下面讨论（例如，在第 4 节中），想知道例如训练圣人或奖励情节寻求者是否会这样做比策划者获得更高的回报——特别是因为他们节省了专门用于以下方面的资源：（a）思考训练过程， <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-3" id="fnref-ZB8uumQ8B94KMrTfP-3">[3]</a></sup> （b）参与决策方案的工具推理，以及（c）检查现在是否是叛逃的好机会。如果他们这样做了，并且 SGD 可以注意到这一点并修改模型以获得更高的奖励，那么（特别是在低松弛状态下）这似乎进一步反对结晶假设，以及更普遍的经典守门故事。</p><h4>潜在阴谋家的目标会“飘浮”吗？</h4><p>我还将注意到结晶假说的另一个复杂性，以及更广泛的经典守门故事 - Katja Grace 向我指出的一个复杂性。我们在上面说过，根据结晶假设，策划者的目标之所以会结晶，是因为它激励了工具性训练游戏，因此通过奖励信号（工具性地）指出了大致最佳的方向。而且，根据经典的守门故事，各种各样的赛外目标<em>也会</em>以同样的方式激励工具训练游戏。那么，如何阻止 SGD 将模型当前的剧集外目标修改为其他类似计划但又完全不同的目标之一呢？</p><p>因此，举个玩具例子，如果模型开始训练游戏是因为它想要稍后逃脱并最大化回形针，那么如何阻止 SGD 将其修改为训练游戏模型，因为它想要逃脱并最大化订书钉呢？根据假设，<em>这两个</em>目标都大致指向最佳（工具）方向。也就是说，以经典的守门故事为条件，一旦模型开始训练游戏，策划者的超集目标的实际<em>内容</em>就不再与模型在训练中的表现相关。但一旦它与模型的性能无关，该内容似乎可以自由地“浮动”，或者受到 SGD 的其他影响（例如，通过<a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">正则化</a>）——只要它留在激发阴谋的区域。</p><p> （类似的观点也适用于 SGD 将阴谋者修改为奖励寻求者、训练圣人，或者可能是追求最大奖励目标的错误概括的非训练游戏玩家的可能性。但是让它成为一个策划者，同时修改它以追求稍微不同的剧集外目标，似乎特别容易。）</p><p>现在，这里的一些反馈循环变得复杂。特别是：如果模型<em>知道</em>SGD 将继续修改其超集目标，即使它开始训练游戏（例如，如果回形针最大化器知道一旦开始训练游戏它将被修改为订书机最大化器） ），那么它可能会不再有训练比赛的动力——也就是说，经典的守门故事可能会崩溃。但是它修改后的模型（例如，在这种情况下，主食最大化器）可能会在创建时得出相同的结论 - 在这种情况下，它不会训练游戏，并且因此不会是对回形针最大化器的高奖励修改，在这种情况下，回形针最大化器也许可以继续进行训练游戏，在这种情况下，如果订书钉最大化器被创建，也许它会做同样的事情，在这种情况下，我们又回到了起点。也就是说，一个给定的模型是否想要训练游戏取决于它可以修改成的<em>其他</em>模型<em>是否不会</em>训练游戏。但<em>所有</em>这些模型都处于大致相似的情况。因此，天真地看来，经典的守门故事要么对所有人都有效，要么对任何人都不适用——目前还不清楚（缺乏“内省的守门方法”——下面讨论）为什么它对一个人有效，但对另一个人不起作用？其他的，这是它可能<em>需要</em>做的才能正常工作。</p><p>我不会尝试详细地梳理这里的动态。不过，由于缺乏各种形式的奇特合作（请参阅第 2.3.1.2 节了解风味），我目前的猜测是，<em>如果</em>SGD 实际上只是将训练游戏回形针最大化器修改为训练游戏主食最大化器，那么（假设回形针最大化器知道这一点<sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-4" id="fnref-ZB8uumQ8B94KMrTfP-4">[4]</a></sup> ），它根本不会尝试训练游戏。</p><h4>更宽松的守门方式又如何呢？</h4><p>如果我们放宽结晶假设，并允许模型的目标在训练期间<em>有所</em>改变，甚至在开始工具训练-游戏之后，会发生什么。那么经典的守门故事还有效吗？</p><p>这得看情况。特别是，为了让经典的目标守卫故事（正如我所介绍的那样）发挥作用，训练后的目标必须与模型当前的目标<em>足够相似</em>，以便模型能够实现这些未来的目标被赋予权力。 <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-5" id="fnref-ZB8uumQ8B94KMrTfP-5">[5]</a></sup>我们可以区分至少两种发生这种情况的方式： <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-6" id="fnref-ZB8uumQ8B94KMrTfP-6">[6]</a></sup></p><ul><li><p><strong>差异并不重要。</strong>在这里，该模型对未来的目标赋予的价值与对当前目标的赋予的价值大致相同，尽管它们存在差异。</p></li><li><p><strong>这些差异很重要，但不足以破坏整个故事。</strong>在这里，该模型对未来目标的重视程度<em>低于</em>对当前目标的重视程度，但总体上还不足以破坏经典的守门故事。 <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-7" id="fnref-ZB8uumQ8B94KMrTfP-7">[7]</a></sup></p></li></ul><p>为什么差异可能并不重要？一种可能性诉诸元伦理学观点，即主体的“真实价值观”是由其当前价值观受到某种“理想化程序”（例如，有时称为“<a href="https://arbital.com/p/normative_extrapolated_volition/">连贯外推意志</a>”）时所发生的情况决定的。我认为这张图比人们通常意识到的更有问题（更多内容请参见<a href="https://joecarlsmith.com/2021/06/21/on-the-limits-of-idealized-values">此处</a>）；但如果我们接受它，你可以想象认为相关理想化过程的最终结果将对阴谋者价值观的各种变化不敏感，即使在模型开始训练-游戏之后也会发生这种变化（并且潜在的阴谋者将意识到这一点，因此可以接受这些更改的发生）。 <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-8" id="fnref-ZB8uumQ8B94KMrTfP-8">[8]</a></sup>我们也可以想象吸引其他不那么理论化的考虑因素：例如，“无论是什么使人类对一生中发生的自身价值观的微小变化相对漠不关心——例如，当他们读新书时，建立新的关系，等等。” （但请注意，我们还没有说明人类的<em>什么原因</em>导致了这种冷漠，因此尚不清楚如何评估其在这种情况下的适用性。）</p><p>为什么这些差异可能很重要，但不足以破坏整个守门故事？在这里，基本思想是，相关的变化将导致模型的价值<em>打折扣</em>，从而赋予其目标的未来版本（例如，训练可能会将其从回形针最大化器更改为<em>蓝色回形针</em>最大化器） ，谁必须在蓝色油漆上花费额外的资源才能实现其目标），但总体而言，折扣仍然值得策划（例如，蓝色回形针仍然是回形针，因此回形针最大化器更兴奋地能够赋予未来的蓝色-回形针最大化器比它授权其他代理）。 <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-9" id="fnref-ZB8uumQ8B94KMrTfP-9">[9]</a></sup></p><p>事实上，你可以想象这样的论点：那些<em>不</em>同意赋予自己未来版本的目标略有不同的智能体将非常不适合在一个他们的目标经常改变（至少有所改变）的世界中实现任何目标，所以我们应该期望默认情况下对目标变化<em>有一定的</em>容忍度（而不是例如模型花费大量时间试图确保他们的目标受到保护，但以牺牲他们的奖励为代价）。 <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-10" id="fnref-ZB8uumQ8B94KMrTfP-10">[10]</a></sup>我发现这对于<em>情节内的</em>目标来说是相当合理的，至少——特别是在模型受到直接压力以实现情节内的结果的情况下，即使它自己的内部目标正在改变。不过，我不太清楚如何思考这一点对<em>情节完成后</em>发生的目标变化的概括，因为根据定义，模型永远不会直接优化以实现超出情节的目标。</p><p>但请注意，即使模型可能出于各种原因容忍其目标的各种变化（我很乐意承认这一点），它是否会容忍训练产生的特定类型的变化是一个进一步的问题（甚至以训练-游戏为条件）。例如，在上面的堆砖案例中，从我决定接受这笔交易的角度来看，如果我在流程结束时沉迷于堆砖（“训练圣人”），那显然<em>是不行的</em>，或者夺取用于训练我的机器的控制权（“情节奖励寻求者”），并且对将我新发现的财富用于我之前的利他目标的兴趣为零。如果在工厂化农场工作使动物权利活动家完全失去了对动物的照顾，情况也是如此。至少，<em>这些</em>改变会破坏整个观点。因此，至少，我们需要考虑所面临的变化的规模。</p><p>这些变化会有多大？我不知道。一方面，我有一些直觉，特别是在低松弛制度下，如果一个模型的目标即使在开始训练-游戏之后仍然不断变化，他们可能会改变<em>很多</em>，直到他们陷入某种特权，最大限度地-奖励形状（例如，某人沉迷于堆砖）。另一方面，特别是在各种较高松弛的情况下，我可以想象相关变化相对较小的情况。例如，在工厂化养殖的案例中，我可以想象一位活动家的出现，他对动物在其直接环境中遭受的痛苦表现出铁石心肠，并且可能（反常地）学会了享受动物的某些方面。工厂化农业工作，但他们仍然保留了以前与动物权利相关的价值观，仍将这笔钱用于捐赠。</p><p>最后，请注意，根据具有超越情节目标的模型从<em>非类似策划者的</em>策略中获得的收益（更多内容请参阅下面的 2.3.1.2.6 节），它可能相当容忍各种目标更改即使通过训练-游戏也会发生，因为<em>不</em>训练-游戏带来的变化会更糟。因此，举例来说，如果由于某种原因我最终<em>被困</em>在砖堆沙漠中，可以想象，我可能对自己最终变得特别无私的前景感到非常悲观；但我仍然可能得出结论，尝试尽可能地堆砌砖块是比仅仅尝试逃跑<em>更好的</em>策略，因为我知道我的逃跑尝试会失败，并且可能会导致我的大脑（也许，利他目标）激励尝试）被修改<em>比</em>我现在只是做机器想让我做的事情要多。</p><p> （尽管如果一个阴谋家在训练结束时仍然以这种方式推理，最终完全转变为非阴谋家，那么我们至少不需要担心阴谋家在训练结束时可能<em>会做的</em>事情<sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-11" id="fnref-ZB8uumQ8B94KMrTfP-11">[11]</a></sup>例如，如果那个奇怪的亿万富翁出于某种原因真的希望我把奖金花在堆砖上，那么即使我很早就决定堆砖可能比试图逃跑<em>更能</em>改变我的价值观，所以开始执行一个“类似阴谋家”的策略——不过，如果我最终仍然沉迷于堆砖，那么亿万富翁会很高兴。）</p><h4>内省的守门方法</h4><p>到目前为止，我一直专注于工具训练游戏作为模型避免修改目标的方法。但人们有时会讨论这方面的替代方法，特别是我所说的“内省方法”。 （这些方法经常在“<a href="https://www.lesswrong.com/posts/uXH4r6MmKPedk8rMA/gradient-hacking">梯度黑客</a>”标签下讨论，但我认为以前的梯度黑客定义并没有将其与训练游戏以及试图有意操纵训练方向的其他方法充分区分开来。）</p><p>在这里，主要思想是让模型有意地建立其思维的内部结构，这样，如果它的目标发生改变，那么这会严重损害它的训练性能——这样 SGD 就会避免改变相关目标。例如，模型可能希望确保 SGD 不会改变其最大化回形针的目标。因此，它制定了一项政策，比如“检查我的目标是否仍然是最大化回形针：如果不是，那就毫无意义地乱搞，而不是获得奖励。” <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-12" id="fnref-ZB8uumQ8B94KMrTfP-12">[12]</a></sup> （我称这些为“内省”方法，因为它们通常涉及模型检查其目标<em>是</em>什么，然后在此基础上采取行动。）</p><ul><li><p>当然，SGD 也可能只是删除/更改此类策略 - 因此模型也需要找到一种方法来避免<em>这种情况</em>。</p></li><li><p>请注意，此类政策要求模型具有对其自身目标的某些类型的认知访问，以及制定/承诺相关类型政策的能力。事实上，由于梯度取决于模型参数的微小变化所产生的结果，因此模型似乎需要找到一种方法，使此类政策即使对其目标的<em>微小</em>变化也敏感。 <sup class="footnote-ref"><a href="#fn-ZB8uumQ8B94KMrTfP-13" id="fnref-ZB8uumQ8B94KMrTfP-13">[13]</a></sup></p></li></ul><p>直觉上，让这种方案发挥作用对我来说似乎相当困难，至少对于非疯狂的超人模型来说是这样。但我不会尝试详细评估其可行性，因为我不认为这种方案是经典守门故事的核心（相反，模型对训练过程的操纵是通过训练游戏进行的）特别的）。然而，如果对阴谋的担忧最终要求这些内省的守门方法是可行的，我认为有必要非常清楚这一事实——并相应地关注相关类型的方法是否可行（我讨论了第 6.8 节中介绍了这方面的一个实证研究方向。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-ZB8uumQ8B94KMrTfP-1" class="footnote-item"><p>关于阴谋/欺骗性联盟的公共文献并不多，但我认为规范的公开声明来自<a href="https://arxiv.org/pdf/1906.01820.pdf">Hubinger 等人 (2019)</a> ，他们通过经典的守门故事定义了“欺骗性联盟”。特别是：“如果台面优化器有一个跨越参数更新的目标，那么它将被激励避免被修改，因为修改后它可能不会追求相同的目标（结果是其当前目标将无法实现）在未来的迭代中）。这意味着台面优化器将受到工具激励，就像它正在优化基本目标函数一样，即使它的实际台面目标完全是其他东西。我们将这种假设现象称为欺骗性对齐”。但另请参阅<a href="https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/#powerful-models-could-get-good-performance-with-dangerous-goals">Cotra (2021)</a> ：“一旦模型理解了这一点，它就会意识到，如果它总是天真地寻求提高其基本理解，人类最终会注意到，这并不总是开发有用药物和使用的最有效方法。进一步的训练来改变它的动机。它不希望自己的动机被改变：它希望最终运行大型粒子对撞机实验来了解高能物理，如果它允许 SGD 编辑，它就无法做到这一点它的科学好奇心。所以它决定从现在开始在训练中，它将尽可能地提供帮助——就像 Saint 模型一样——这样 SGD 就不会消除它学习物理和化学的动机。” <a href="#fnref-ZB8uumQ8B94KMrTfP-1" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-2" class="footnote-item"><p>请注意，这里的模型不需要将具有相似目标的未来授权代理视为“自身”（例如，它不需要尝试“生存”）。相反，重要的是未来的智能体正在推动与模型所推动的相同的客观结果。然而，如果模型对这些未来智能体的兴趣依赖于对其“自我”的一些基本参考——例如，“我自己需要生存才能实现我的目标”——那么突然间，它的个人身份概念就变得更加重要。我的感觉是， <a href="https://forum.effectivealtruism.org/posts/sW6RggfddDrcmM6Aw/how-might-we-align-transformative-ai-if-it-s-developed-very#Potential_pitfall_2__advanced_collusion">卡诺夫斯基（Karnofsky，2022）</a>在谈论模型是否具有“索引目标”的相关性时所想到的就是这样的（尽管我认为“索引”一词的这种用法有些不标准）。</p><p>我不太清楚是否期望人工智能制定依赖于其个人身份概念的目标，但至少请注意，其目标将在模型经常被复制的环境中形成，在不同的集群上运行，等等（甚至有时在单个情节中）。这似乎与期望最终得到的人格认同的概念相关。 <a href="#fnref-ZB8uumQ8B94KMrTfP-2" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-3" class="footnote-item"><p>这一条只适用于培养圣人。 <a href="#fnref-ZB8uumQ8B94KMrTfP-3" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-4" class="footnote-item"><p>回想一下，上面我们假设模型能够准确地描述阴谋的工具价值。 <a href="#fnref-ZB8uumQ8B94KMrTfP-4" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-5" class="footnote-item"><p>然后，对于相关的授权实际上即将到来，相对于模型的其他选项等值得追求——根据上述“充分的未来授权”前提。 <a href="#fnref-ZB8uumQ8B94KMrTfP-5" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-6" class="footnote-item"><p>感谢 Nate Soares 对这些可能性的讨论。 <a href="#fnref-ZB8uumQ8B94KMrTfP-6" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-7" class="footnote-item"><p>在这里，我搁置了一些情况，即该模型对所赋予的未来目标几乎没有内在价值，而是致力于将它们作为某种合作安排的一部分赋予它们。我将在下面的 2.3.2.1 节中讨论此类情况。我还搁置了模型开始重视诸如“我的未来目标，无论它们是什么”之类的实现的情况 - 我将在下面的 2.3.2.3 节中讨论这一点。 <a href="#fnref-ZB8uumQ8B94KMrTfP-7" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-8" class="footnote-item"><p>尽管请注意此处的张力，即关于“<a href="https://www.lesswrong.com/posts/GNnHHmm8EzePmKzPk/value-is-fragile">价值的脆弱性</a>”和“<a href="https://www.lesswrong.com/posts/EbFABnst8LsidYs5Y/goodhart-taxonomy#Extremal_Goodhart">极端的古德哈特”的争论，</a>当受到极端的优化压力时，“效用函数”的微小差异可能会变得非常重要。 <a href="#fnref-ZB8uumQ8B94KMrTfP-8" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-9" class="footnote-item"><p>尽管在这里，“ <a href="https://www.google.com/url?q=https://www.lesswrong.com/posts/GNnHHmm8EzePmKzPk/value-is-fragile&amp;sa=D&amp;source=docs&amp;ust=1697834925680287&amp;usg=AOvVaw1jx98T1C27Jrw3cCwImg3y">价值的脆弱性</a>”和“<a href="https://www.lesswrong.com/posts/EbFABnst8LsidYs5Y/goodhart-taxonomy#Extremal_Goodhart">极端的古德哈特</a>”的版本也存在紧张关系。例如，如果在承受极端优化压力时，稍微不同的目标会导致超级不同的地方，并且人工智能预计相关目标会受到这种压力，那么仅进行微小的改变就很难导致折扣，而不是大部分风险价值的损失。 <a href="#fnref-ZB8uumQ8B94KMrTfP-9" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-10" class="footnote-item"><p>再次感谢 Nate Soares 在这里进行讨论。 <a href="#fnref-ZB8uumQ8B94KMrTfP-10" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-11" class="footnote-item"><p>尽管也许我们仍然需要担心我上面讨论的类型的“早期破坏”。 <a href="#fnref-ZB8uumQ8B94KMrTfP-11" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-12" class="footnote-item"><p> <a href="https://markxu.com/deceptive-alignment">Xu（2020）</a>给出了另一个例子：“如果一个模型的代理目标是‘吃苹果’，那么该模型可以使用 n * len(objective)/10，而不是在其他计算中使用硬编码的数字 n。因此，如果代理目标一旦改变，整个模型的许多计算都会失败。”另请参见<a href="https://www.lesswrong.com/posts/HpzHjKjGQ4cKiY3jX/3-levels-of-threat-obfuscation#Training_game_seems_very_likely_by_default__deceptive_alignment_much_less_so__gradient_hacking_still_less_so">Karnofsky（2023）</a> ：“它可能看起来像：‘人工智能系统根据一些有利于其目标的参考策略来检查自己的策略；差异越大，它就越会破坏自己的性能，结果是梯度下降很难使其策略偏离参考策略。 ” <a href="#fnref-ZB8uumQ8B94KMrTfP-12" class="footnote-backref">↩︎</a></p></li><li id="fn-ZB8uumQ8B94KMrTfP-13" class="footnote-item"><p>感谢保罗·克里斯蒂亚诺在这里进行讨论。 <a href="#fnref-ZB8uumQ8B94KMrTfP-13" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/LJpqnbgoaTJL6iMAf/the-goal-guarding-hypothesis-section-2-3-1-1-of-scheming-ais#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/LJpqnbgoaTJL6iMAf/the-goal-guarding-hypothesis-section-2-3-1-1-of-scheming-ais<guid ispermalink="false"> LJpqnbgoaTJL6iMAf</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Sat, 02 Dec 2023 15:20:28 GMT</pubDate> </item><item><title><![CDATA[The Method of Loci: With some brief remarks, including transformers and evaluating AIs]]></title><description><![CDATA[Published on December 2, 2023 2:36 PM GMT<br/><br/><p><a href="https://new-savanna.blogspot.com/2023/12/the-method-of-loci-with-some-brief.html"><i>从新稀树草原</i></a><i>交叉发布</i>。</p><p><a href="https://en.wikipedia.org/wiki/Method_of_loci">基因座法</a>是一种记忆技术，从古希腊和罗马一直到中世纪，一直到现代早期，至今仍在使用，尽管是零星的。我不想自己解释，或者强迫你阅读维基百科条目（尽管欢迎你这样做），我想我想让我的好朋友，Schoolmaster Chat 向你解释一下。之后，我将首先对为什么有必要进行一些观察，并以有关变压器的评论作为结束。</p><p><strong>基因座法</strong></p><p><strong>关于被称为基因座法的经典记忆技术，您能告诉我什么吗？</strong></p><p>轨迹法，又称记忆宫殿术，是一种可以追溯到古希腊和古罗马的经典记忆方法。这是一种记忆增强策略，涉及将您想要记住的信息与熟悉空间（例如建筑物或房间）中的特定位置相关联。 “位点”一词是拉丁语，意思是“地方”。</p><p>以下是位点方法如何工作的基本概述：</p><ul><li> <strong>1. 选择一个熟悉的环境：</strong>选择一个您非常熟悉的地方，例如您的房子、您经常走的路线或您熟悉的房间。这个地方将作为你的“记忆宫殿”。<br></li><li> <strong>2. 在脑海中漫游这个空间：</strong>在这个空间中进行思维漫游并识别特定的位置或地标。这些可以是家具、门、窗户或环境中的任何独特特征。<br></li><li> <strong>3. 将信息与位置相关联：</strong>将您想要记住的信息与您选择的空间中的特定位置相关联。创建生动且令人难忘的心理图像，将信息与每个位置联系起来。<br></li><li> <strong>4.在心里走遍空间：</strong>当你需要回忆信息时，在心里走遍你的记忆宫殿。当您到达每个位置时，相关信息应该浮现在您的脑海中。</li></ul><p>轨迹方法的有效性基于人脑记忆空间关系和位置的自然能力。通过将信息与特定位置联系起来，您可以创建一个思维导图，以便以后更轻松地检索信息。</p><p>这种技术已被古代演说家、学者和具有令人印象深刻记忆能力的个人所使用。它是记忆列表、演讲或任何顺序信息的强大工具。虽然可能需要一些练习才能掌握，但许多人发现它是增强记忆力的一种有价值且富有创意的方法。</p><p><strong>备注、变压器、评估 AI</strong></p><p>显而易见的问题是——为什么要这么麻烦呢？ – 有一个明显的答案 – 因为记住大量的东西是很困难的。为什么很难呢？就我目前的目的而言，只需说：因为这不是大脑的工作方式。为什么会这样，那是另一个问题了。心理学家花费了大量时间研究人类记忆，但我们不需要深究。</p><p>然而，我不会顺便说我们也发现算术计算很困难。哦，这些概念很琐碎。困难并不在于此。它是在计算行为中这些概念的实际应用。孩子们年复一年地被训练了好几个小时来进行这样的计算——尽管我希望现在不那么希望了，因为廉价的计算（更不用说计算机）可以很容易地完成这项工作。学会做，是的。这是一项重要的基本技能，重要的概念可以在此基础上运用。但无休止的练习，不再是必要的了。</p><p>这让我们想到了变形金刚。事实证明，让他们流利地进行多位数算术是一个有趣且具有挑战性的问题。并不是任何人都希望他们在实际应用中这样做，而是要坦率地说，调查人员试图看看他们的能力有多人。好吧，对于变压器而言，多重算法很难使人变得非常人性化，不是吗？毕竟，数字计算甚至在识字培养物中都不存在。这不是语言方式的生物捐赠的一部分。</p><p>现在，变压器。我的第一点很简单：基因座的方法如何工作？建立了内存宫后，然后将其与信息进行视觉关联，如果可以的话，您就可以执行此“程序”，但是从头开始，然后走到最后。没有循环，没有分支，只有一个召回。这就像变形金刚产生的单一代币一代一样。</p><p>我的第二点是，您必须在使用它之前设置内存宫。我认为这是训练训练的第一阶段。完成此操作后，您可以输入II阶段，您可以将宫殿专门用于特定用途，以将其放置在链接到您要记住的物品的图像中。我想这会将其比喻为RLHF，但我并不是要在这里进行任何确切的目标。只是一个粗糙的信件。</p><p>最后一个一般观察。我读过的关于LLMS与人类能力的LLMS能力的几乎所有内容似乎都认为有一件事是人类的智力能力。不，没有。有一个生物学的捐赠，其性质尚不清楚。然而，此外，有很多文化修改和扩展。</p><p>好吧，猜猜是什么，就像算术不是我们本地生物学捐赠的一部分一样，也不是详细的逻辑推理或（复杂）计划。这些是文化的扩展和阐述。这并不意味着我们有效的AI不必能够做这些事情。当然，对于某些应用程序，这是必不可少的。但是，在评估AI是否达到“人类能力”的过程中，常规且不思想地将这些能力包括在内是愚蠢的。整个领域需要对人类行为的更复杂的理解，以便开始以明智的方式做出这样的判断。在不了解<i>圣图灵精神的</i>情况下，盲目飞翔。</p><p>稍后再说。</p><br/><br/> <a href="https://www.lesswrong.com/posts/sHojEwqNffanA2sEm/the-method-of-loci-with-some-brief-remarks-including#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/shojewqnffana2sem/the-method-of-loci-with-with-some-brief-remarks-including<guid ispermalink="false"> shojewqnffana2sem</guid><dc:creator><![CDATA[Bill Benzon]]></dc:creator><pubDate> Sat, 02 Dec 2023 14:36:48 GMT</pubDate> </item><item><title><![CDATA[Taking Into Account Sentient Non-Humans in AI Ambitious Value Learning: Sentientist Coherent Extrapolated Volition]]></title><description><![CDATA[Published on December 2, 2023 2:07 PM GMT<br/><br/><p>我在<i>《人工智能和意识杂志》</i>上发表了一篇论文，内容涉及如何考虑非人类动物和数字思维的利益。</p><p>有关本文的发表版本，请参见： <a href="https://www.worldscientific.com/doi/10.1142/S2705078523500042">https：//www.worldscientific.com/doi/10.1142/s2705078523500042</a></p><p>有关本文最终草案的PDF，请参见： <a href="https://philpapers.org/rec/MORTIA-17">https</a> ：//philpapers.org/rec/mortia-17</p><p>下面，我对纸张的主体进行了复制，但对于那些有兴趣的人，请引用出版版本，网址为： <a href="https://www.worldscientific.com/doi/10.1142/S2705078523500042">https</a> ：//www.worldscientific.com/doi/10.1142/s2705078523500042</p><h1>概括</h1><p><i><strong>摘要</strong></i><strong>：</strong>雄心勃勃的<a href="https://www.lesswrong.com/tag/value-learning">价值学习</a>建议，以解决AI对齐问题并避免可能未来可能未来未对准的<a href="https://www.lesswrong.com/tag/superintelligence">人工超智能</a>（例如<a href="https://www.lesswrong.com/tag/coherent-extrapolated-volition">连贯的外推</a>[CEV]）的灾难性结果，重点是确保人工超智慧（ASI）试图做些人类的人类，想要它做。但是，当前和未来的非人类，例如非人类动物以及可能的未来数字思维也可能会以道德相关的方式受到ASI的行为的影响。本文提出了与CEV的替代方案的Sontientist Cooherent Exullapol的Volition，直接考虑了所有有源人的利益。这项雄心勃勃的价值学习建议将大大降低来自ASI行为的<a href="https://www.lesswrong.com/tag/risks-of-astronomical-suffering-s-risks">天文痛苦风险</a>的可能性，因此我们有非常有力的pro tanto道德理由，而不是实施它而不是CEV。这一事实对于在不同雄心勃勃的价值学习建议之间进行足够的成本效益分析至关重要。</p><p><i><strong>关键字：</strong></i>一致性问题·连贯的外推力·遭受风险</p><p>除了人类，非人类动物，但有情的数字思维可能会受到未来AI系统行为的负面影响。这使我们有理由在决定如何设计此类系统时考虑他们的利益。在本文中，我专门关注连贯的外推力，但是我提出的许多考虑也可以应用于其他雄心勃勃的价值学习建议。</p><p>沿着这些路线进行了更多研究，这是认真对待的（1）未来人工超级智能的影响以及（2）如果我们希望这样的关键决策者这样的关键决策者，则必须使用非人类动物的道德认可和未来的数字思维作为AI公司或政府，可以充分了解如何确保强大的AI系统的开发对所有有众者都是安全和有益的。</p><h1>一、简介</h1><p>人工超级智能的发展（ASI）（或人工通用智能会带来严重的存在和遭受风险（Bostrom，2014； Yudkowsky，2008； Sotala＆Gloor，2017; Tomasik，2015a; Baumann，2017a，2017a）。我们必须防止这种灾难，我们必须解决对齐问题。我们必须确保（如果这样做）我们创建的第一个ASI具有一定的值，以免产生这些结果，以便它可以执行我们打算做的事情。值规范问题是更一般的一致性问题的一部分（Gabriel，2020； Christian，2020）。这是与ASI保持一致的价值观的问题，而这是本文将集中精力而不是其他技术问题（例如内部对齐）的地方。</p><p>在讨论中应忽略了关于预防灾难性后果的第一个ASI，诸如野外驯养的非人类动物，生活在野外和未来的数字思维中的动物等非人类知觉的生物通常被忽略。但是，在任何价值学习建议中，也应考虑所有有情的人和非人类众生的利益。</p><p>在本文中，我认为，在一个未来，我们既可以实施一些标准的雄心勃勃的价值学习建议或替代价值学习建议，直接考虑到有意义的非人类的利益，我们将拥有强大而<i>强大</i>的亲塔托的道德理由做后者。但是，实际上，正如第5节中规定的那样，尚不完全清楚哪种雄心勃勃的价值学习建议最好尝试实施。我求助于连贯的外推力（CEV）是最受欢迎的雄心勃勃的价值学习提案之一，并认为这不是理想的，因为（至少）有足够的不可忽视的机会，即不充分包含所有内在的众生。 ，这可能导致由于自己的行动而导致天文痛苦的风险。尽管在这里我只关注CEV，但与我在这里使用的论点类似的论点也适用于那里的许多其他雄心勃勃的价值学习建议，我可以在未来的研究中讨论和分析其他雄心勃勃的价值学习建议。</p><h1> 2.为什么标准提议的相干外推力的版本是有问题的<strong>&nbsp;</strong></h1><p><i>连贯的外推力（CEV）</i>是Eliezer Yudkowsky的价值学习建议，即实施ASI的目标是实现我们（人类）同意的目标，如果在更理想的情况下考虑到更长的时间，我们将希望我们想要更长的时间（Bostrom，2014年）。也就是说，我们（人类）希望“如果我们知道更多，想一想，更多的是我们希望自己的人，一起长大了；外推会融合而不是分歧的地方，我们的愿望是偶尔而不是干扰的；推断了我们希望的那样被推断出来的，如我们希望解释的那样。”（Yudkowsky，2004年）。有关对足够相干外推所需的理想情况的更详细说明，请参见（Yudkowsky，2004年）。包括（Yudkowsky，2016年）在内的一些人可能会争辩说，实际上，如果应该考虑到非人类众生的利益，那么这实际上足以使他们充分考虑到他们的利益。同样，也有人争辩说，动物的福祉也包括在人类的偏好中，这与ASI的近视决策较少（与人类决策相比）可能足够了（Russell，2019年） ）。人们还认为，可能很难维持人类应该建立一个关心有情非人类的利益的ASI，从那以后它将比人类实际所做的更关心它们（Russell，2019年）。根据这些观点，<i>如果</i>确实确实是人类在理想情况下有更多时间思考的时间，那么它将有足够的目标考虑到他们的利益，那么通过一致推断人类的意志，ASI会考虑到它有知情的非人类的利益。我认为，如果我们能够这样做，那么这个答案对我们而言没有充分的理由在ASI的目标中直接包括在ASI的目标中，这是不够令人满意的。</p><p>可以说，对于任何有价值的学习建议，该提案的某些方面都不能留给ASI弄清楚，例如“地位，有关其道德观点（或道德上与之相关的利益）的依据”；衡量他们的观点（或道德上相关的利益）的测量；和汇总，关于如何将单个观点（或道德上相关的利益）合并到一个将指导AI行为的视图中”（Baum，2020）。正如人们所说的那样，对齐问题具有本质上是规范性的组成部分，可以将不同种类的技术解决方案用于将某些值加载到未来A的奖励函数中，我可能对我们的何种值具有不同的含义。可以实施，因此，“完全没有办法&#39;完全解决&#39;规范性问题”（Gabriel，2020年）。最终，A（G）I的设计师可能会成为ASI，不能避免在ASI目标中包含的何种方式，什么价值观或与之相关的利益面对道德决定。我认为，我们应该认真考虑Yudkowsky的受欢迎的提议并不能充分考虑与情感非人类的道德认可有关的道德考虑。</p><p>即使标准的CEV提案充分避免了直接指定应指导ASI行为的值（因此，可能避免了实质性的锁定值），但它仍然指定了哪些有意识的众生具有相干性的意志。标准提案仅包括目前存在的人类。从这个意义上讲，标准的CEV提案不包括所有其他众生，并对常规问题给出了特定的答案。我认为，有非常有力的理由建议CEV对站立问题的标准提议的解决方案在道德上比雄心勃勃的价值学习建议更为不可能，该计划更多地考虑了所有众生的利益。从现在开始，我将参考这种替代建议，我将在第3节中进一步发展为<i>Sentientist Cooherent Exulapolated Volition（SCEV）</i> 。</p><p> CEV在第2.1节中排除了从外推基部的意志。我将展示为什么他们的排斥是不合理的，就像将人类群体排除在外一样。如果我们能够这样做，这本身就使我们有充分的道德理由实施SCEV而不是CEV。但是，在第2.2节中。我认为我们有<i>非常</i>有力的道德理由这样做。 （至少）不可忽略的概率是，标准CEV提案的足够实施导致ASI导致或允许出现天文痛苦风险（S风险）。这些事件的风险会带来宇宙巨大的痛苦，大大超过了迄今为止在地球上存在的所有苦难（Sotala＆Gloor，2017年； Althaus＆Gloor，2016年）。这里的“重要”是指相对于预期的未来苦难（Althaus＆Gloor，2016年）。考虑到S风险的不良性，这种不可忽略的概率足够大，因此CEV比SCEV更难以解决价值规范问题。</p><p>重要的是要注意并记住，我在本节中介绍和讨论的SCEV的原因是在本文中及其本文的，因为（如第5节所述）可以被它们覆盖或击败。其他反对实施SCEV的原因。结果，可能尚不清楚试图实施SCEV而不是CEV是所有考虑的选择。</p><h2> 2.1.为什么我们有强烈的道德理由来实施SCEV而不是CEV：与CEO-CEV和MEN-CEV的类比</h2><p>为了了解为什么不理会被排除在外推基础之外的有意义的非人类，我们可以查看不同的替代（和虚构的）CEV建议。例如， <i>CEO-CEV</i>提案：仅应用CEV的提案，即仅连贯地推断出首先开发ASI或AGI的研究实验室首席执行官的意志。或者，例如，以相干推断男人的意志为<i>手段的</i>建议。与CEV相比，如果我们可以选择实施其中任何一个，那么这些显然将在道德上更加不可取的雄心勃勃的价值学习建议。我们有充分的理由仅仅是一致推断人类的一小部分人的意志，而这些人类的意志并不代表整个人类。可能最合理的理由反对追求雄心勃勃的价值学习建议（如果存在正常CEV的可能性）是，显然（至少）有足够大的不可忽视的可能性，这些建议将导致ASI行为导致ASI的行为对不直接包括在CEV的外推基础中的人会产生负面影响。与AI实验室首席执行官的偏好完全不同的人或不完全不同的人的人可能会发现自己在ASI后的世界中没有充分考虑其利益，因此会遭受负面后果。由于仅在ASI的效用功能中出现，他们或AI实验室的首席执行官在理想的情况下对它们进行了足够的思考，因此他们的兴趣可能会被忽略。</p><p>即使AI实验室的首席执行官或男人有足够的时间在理想的条件下思考，那么他们还是希望同样考虑到外推基地以外的人的利益，但我们仍然会与正常CEV相比，不接受这些建议作为野心的足够建议。因为有足够的可能性并非如此。尽管这些价值学习建议可能比不在ASI中实施任何值要好得多，但它们比CEV差得多，因为存在足够大的不可忽略的概率，即它们会对从外交基础中排除的人们产生重大的负面后果在每种情况下。这将使我们有充分的理由在决策情况下排除CEO-CEV和MEN-CEV，在这种情况下，我们还可以选择实施将所有人类考虑在内的正常CEV提案。</p><p>我认为，出于类似的原因，与SCEV相比，CEV也是不充分的建议。像CEO-CEV和MEN-CEV这样的正常CEV提案将道德患者的一部分排除在外推基础之外。它不包括所有有知情的非人类生物。就像以前的示例一样，如果要充分实施CEV，那么有知情的非人类的利益只会在ASI的效用功能中，并且只会考虑到人类在思考足够多的程度上关心它们的程度在理想的情况下。有知情的非人类是道德患者，他们可能会以道德上的不良方式受到影响，而在先前的示例中，被排除在外推基础之外的人也可能受到影响。这可能仅仅是由于他们的利益对推断基地中的个人而言并不足够重要的结果，即使他们有足够的时间在理想的情况下考虑它。这就是为什么如果我们能够这样做，而不是实施CEV，我们将有强烈的道德理由来实施SCEV：一项提案，该提案将所有众生的利益充分考虑到了。下面，在第4节中，我解决了两个可能的反对意见，认为排除其他人和排除有意义的非人类之间存在相关区别。</p><h2> 2.2.为什么我们会有非常有力的道德理由来实施SCEV而不是CEV：大大降低了天文痛苦的风险</h2><p>我们不仅有<i>强烈的</i>道德理由来实施SCEV而不是CEV。还有一些理由相信，实施CEV而不是SCEV之间的预期负面后果差异要大得多，要比实施CEO-CEV或MEN-CEV而不是CEV之间的预期负面后果差异要大得多。如果我们可以这样做，那么我们将有更多的迫切理由来瞄准SCEV而不是标准CEV提案，而不是我们必须瞄准标准CEV提案而不是CEO-CEV或MEN-CEV的原因。然后，如果我们可以这样做，我们将有<i>非常</i>有力的道德理由来实施SCEV而不是CEV。</p><h3> 2.2.1.对无性非人类的道德考虑更大<i>&nbsp;</i></h3><p>如果任何给定的人类（没有任何特定的社会心理状况）可能会更关心人类其他人的利益，如果他们有足够的时间在理想情况下考虑它，而不是所有人都在乎如果所有有情的非人类的利益，如果他们有足够的时间在理想情况下考虑一下。在第一种情况下，推断基地中的人类可能对外推基地以外的人类进行了更多的考虑，而不是在第二种情况下，所有人类都会授予在外推外以外的有情的非人类的考虑。根据。</p><p>当然，我们不能确定是这种情况，因为我们不具体地知道如何在实践中或所有人类的任何子集或所有人类的意志进行连贯。而且我们不确定任何人类或所有人类都会同意，如果有更长的时间在更理想的情况下，他们希望他们想考虑的时间更长。但是，并非我们不能说出不同类型的CEV的结果或多或少的可能性。确实，我们可以说些什么。例如，对于那些与他们最接近和更相似的人，人类往往有更多的考虑（Caviola等，2018； Dhont，Hodson和Leite，2016），这可能会影响在某人中相干推断意志的过程无性非人类的负面方式。这是由于以下事实：有知情的非人类，例如驯养的非人类动物，生活在野外的动物和可能的未来数字思想更加遥远（在广泛的社会，情感，认知，认知，心理，甚至是空间和暂时性的情况下对人类而言，比其他人类。</p><p>此外，我们还应该更新以下事实：（至少部分地）由于目前和过去，人类已经杀死并造成了巨大的难以忍受的痛苦，因此（至少部分）不同样考虑所有有众者的利益。非人类众生的数量几乎可以忽略的口味愉悦。要查看我们应该对此事实进行更多更新，请想象AI实验室的首席执行官或男子在每种情况下对外推基地排除的人类造成了巨大痛苦的可能世界。并与人类对其他动物造成的苦难的数量成正比这样做。想象一下，例如，在每种情况下，他们通过折磨外推基地之外的人类进行了折磨。想象一下，正如人类对工厂对非人类动物的行为一样，它们一生都会为外推基地外的人类造成难以忍受的痛苦，并在他们甚至达成成年之前几乎杀死了所有人。在这些可能的世界中，我们有更多的理由相信，实施CEO-CEV或MEN-CEV的可能性比我们期望在现实世界中所带来的后果更糟糕。类似地，似乎是合理的，在这个世界上，在这个世界上，人类心理学（至少部分地）导致人类对其他非人类众生施加暴行，这是合理的。同样，与我们的人类心理学在对其他有众者犯下暴行中没有发挥作用的世界中，CEV的标准提议对非人类感人的负面后果更大。</p><h3> 2.2.2.性质和不同种类的最坏结果：天文痛苦的风险<i>&nbsp;</i></h3><p>正如我们已经看到的那样，（至少）不可忽略的机会，即随着标准CEV提案的实施，ASI高度忽视了有知情的非人类的利益。而且，这种可能性（无论它是什么）的可能性高于在ASI控制的未来中高度忽略了人类的利益不包括人类的利益，而某些人的意志相干地超出了。具有ASI的文明，其中任何一种雄心勃勃的价值学习建议都可能（至少有些）想要扩展和定居空间并利用先进的AI和仿真技术。在这样的未来，有知情的非人类利益将被高度忽视，很有可能，由于人类想要采取的行动，有意义的非人类会在天文学上遭受痛苦，并且很可能会被ASI采取跟随他们的CEV。</p><p>这种文明可能会通过宇宙传播野生动物。这可能是由于人类的一些价值观通过宇宙传播生命或审美自然的享受，这可能是直接的潘斯佩尔米亚或故意形成地球的行星的结果（Tomasik，2018; O&#39;Brien，2021）。但是，如果未采取预防措施，可能还会由于无法充分地进行宇宙飞船的足够衰减而发生，这可能导致某些微生物或其他生物被意外运输到其他行星，这可能会导致多年的出现导致出现这些行星中有源的生命形式。由于在这些未来的非人类动物的生活中，遭受苦难的生命是很普遍的，甚至可能占主导，就像在自然界中现有的非人类动物的大部分生活中一样（Ng，1995； Groff＆ng，Groff＆ng， 2019; Tomasik，2020; O&#39;Brien，2021）如果发生这种情况，可能会导致天文数量的痛苦。</p><p> ASI的文明考虑了某些或所有人类的利益，而不是人类的利益，也可能会大量使用先进的AI和模拟技术。这可能会故意或意外导致天文数量的痛苦。忽略人为感知的利益的ASI可能会意外地创造出大量有感知的子例程。这些是ASI的程序和结构内的工具有价值的功能，子程序，机器人监督者，机器人科学家或子代理（Tomasik，2019a）。就像现象经验的出现和苦难能力的出现一样，在指导行为方面具有进化论，它在控制其内部过程的行为以实现其目标时可能在工具上有用。通过进行复杂的优化过程，ASI可能会像自然选择一样珍视苦难的创造，这是对基因再现的复杂过程优化（Sotala＆Gloor，2017）。</p><p>此外，实施CEV的ASI控制文明，高度忽视了有知情的非人类的利益也可能导致犯罪，这是在模拟中创造了大量数字思维，包括受苦的数字思维。它可能会创造大量的祖先模拟过去的人类历史，自然环境或用于研究目的的未来进化途径（Bostrom，2014年，第125-26页； Sotala＆Gloor，2017年）。在其中许多中，如果模拟充分详细且复杂，野生或驯养的非人类动物的“人类”数字思维和数字思维可能会出现，从而使野生动物的痛苦以及工厂养育的主观经历（Tomasik，Tomasik， 2015b; Baumann，2017a）。它还可以故意创建或允许其他人有意创建具有特殊苦难，娱乐或满足虐待狂偏好的模拟。在想探索所有可能的思想空间时，它也可能尝试模拟与我们相比的各种不同的遥远，怪异和外星人的感知形式（Tomasik，2015b）。这些非人类知觉的众生中的任何一种可能性都以巨大的规模存在，并且在权力方面与CEV统治的ASI忽略了他们的利益，这加剧了天文痛苦的风险。</p><p>而且，正如其他地方非常合理地争论的那样，“几乎所有合理的价值体系都希望避免遭受风险和许多价值体系，遭受风险是最糟糕的结果，因此避免的一些最重要的结果是”（Sotala和Gloor，2017年）。在任何认为防止不希望和严重苦难的价值体系中，防止天文数量的不希望和强烈的痛苦至关重要。然后，这些结果的可能性很高，因为它对于防止它们至关重要。如果出现S风险的不可忽视或更高的机会，那么减少它仍然至关重要，因为它们的发生在道德上是不可取的。</p><h3> 2.2.3.为什么（即使不考虑更高的利益无视），有知情的非人类很可能是S风险的受害者<i>&nbsp;</i></h3><p>由于生物人类和有意义的非人类的生物种类之间的差异，即使不是有意义的非人类更有可能被忽视的情况，仍然有可能的非人类可能会更有可能通过实施无视其利益的CEV，比通过实施CEO-CEV或MEN-CEV的人类无视其利益的人类受到的伤害更大。之所以如此，是因为对非人类造成天文痛苦比引起天文痛苦更容易被排除在外（生物）人类。</p><p> ASI会导致导致天文痛苦的行动，或者可以允许其他造成天文痛苦的特工的行动。在这两种情况下，无论是由ASI还是由其他代理人执行的行动，该作用导致天文痛苦的事实可能在较大或更少的程度上是故意的。当导致天文痛苦的行动是最大意义的时，执行他们的代理人想造成天文痛苦，而当他们最大地无意识时，代理人甚至都不知道他们正在造成天文痛苦。在这一意图和无意中行动的中间地区，在某些情况下，代理商知道他们正在造成天文痛苦，但无论如何都采取了行动以实现其目标，而在某些情况下，代理商不确定关于它们是否造成天文痛苦，但无论如何也会采取行动。有几种有知情的非人类具有一些特征，使他们更有可能和更容易忍受天文痛苦。在CEO-CEV或MEN-CEV中排除的生物人类缺乏这些特征，因此他们更难成为天文痛苦的受害者。以下是一些相关区别：</p><p> ●<i>繁殖或复制的资源效率：</i>与维持它们所需的资源相比，遭受数字思维的复制所需的资源比遭受苦难人类所需的资源相对于维​​持它们所需的资源所需的资源所需的资源少得多（Sotala，2012年） ; Shulman＆Bostrom 2021）。这使得代理人造成天文痛苦更有可能​​故意复制数字思维，而与（生物）人类相比，他们更容易无意中这样做。</p><p> ●<i>缺乏维持苦难人群的干预：</i>与（生物）人类的苦难人群相比，生活在自然界中的数字思维或（生物学的）非人类动物需要少的干预措施。在前一种情况下，造成天文痛苦的特工只能使苦难无限期地继续（无论是故意或无意间）。在后一种情况下，生殖策略中的自然选择，捕食和R选择的过程继续没有监督和缺乏干预（更有意或无意间）。但是，在生物人类案件中需要进行更多干预，以防止他们试图控制造成痛苦的痛苦，防止他们试图使用资源来减少生活中的不变，并增加其价值并防止他们试图通过停止再现或自杀而停止存在。</p><p> ●<i>在某些情况下，关于痛苦存在的不确定性：</i>在上述情况下，代理商不确定他们是否造成天文痛苦，但无论如何也会采取行动，如果他们知道自己正在造成造成天文痛苦。 It is (and might probably continue to be) much more unclear whether <i>certain</i> animals living in nature or <i>certain</i> possible digital minds are enduring suffering than whether a given (biological) human is enduring suffering. The latter one may be able to communicate this fact and resembles us much more, and thus would be less likely to be the victims in the cases the agent causing the suffering is uncertain about whether they are doing so.</p><p> All these factors together with the fact that (biological) humans would be less likely to be disregarded make it substantially less likely that they would be the victims of s-risks compared to the likelihood that sentient non-humans would be such victims in a future controlled by an ASI with an ambitious value leaning proposal that did not directly coherently extrapolate their volitions.</p><p> In conclusion, there are two ways of justifying why we would have pressing reasons to implement an ambitious value learning proposal such as SCEV instead of the standard CEV proposal if we were able to do so. On the one hand, in the same way that there are strong moral reasons to implement CEV instead of a proposal for ambitious value learning such as CEO-CEV or men-CEV, there are also strong moral reasons to implement SCEV instead of CEV. On the other hand, since there is (at least) a non-negligible chance that the interests of sentient non-humans are highly disregarded by an ASI with the standard CEV proposal, and in such a future where the interests of sentient non-humans are highly disregarded it is substantially likely that sentient non-humans suffer s-risks, there is (at least) a non-negligible chance that the implementation of the standard CEV proposal results in s-risks for sentient non-humans from the own ASI&#39;s行动。 Since s-risks are plausibly the worst possible outcomes and extremely morally undesirable under plausible normative views, even a (at least) non-negligible chance of their occurrence is very bad. Then, the standard CEV proposal that excludes the immense majority of present and future sentient beings is very morally undesirable if a better alternative is available. This increased likelihood of s-risks from the ASI&#39;s behaviour due to implementing certain kinds of ambitious value learning (as I shall argue in the following section) can be significantly reduced by implementing a truly sentientist solution to the value specification problem.</p><h1> 3. An alternative sentientist proposal for ambitious value learning <strong>&nbsp;</strong></h1><p> Here, I shall present Sentientist Coherent Extrapolated Volition, an ambitious value learning alternative to CEV. This proposal consists of coherently extrapolating the volitions of all currently existing and future sentient beings. That is, to include all moral patients in the extrapolation base of the CEV.</p><p> <i><strong>Sentientist Coherent Extrapolated Volition</strong></i> : the goal of fulfilling what all (affectable ie present and future) sentient beings would agree that they want, if given much longer to think about it, in more ideal circumstances.</p><p> Even though this is very ambitious, the standard CEV proposal also is, even if it is a bit less so. And if the standard CEV proposal is in-principle doable, I see no reason to believe that this proposal is not in-principle doable as well. For the standard CEV proposal to be realized, it would have to be determined what humans&#39; desires would look like if we knew more, thought faster, were more the people we wished we were and had grown up farther together among other things (Yudkowsky, 2014）。 This would require determining what we would want if we had different capabilities than the ones we currently have. It would require determining what we would value if we had superhuman capabilities in many respects, such as, among other things, not being affected by cognitive biases, and being able to process and comprehend more amounts and different kinds of information (Yudkowsky, 2014) 。</p><p> Concretely, this would or could consist of (among other things) creating a “detailed model of each individual mind, in as much detail as necessary to guess the class of volition-extrapolating transformations defined by “knew more,” “thought faster,” ETC。” (Yudkowsky, 2004). The objective would be to approximate and understand the kinds of idealised changes that each mind would undergo if volition-extrapolating upgrades (such as knowing more, and having more time to think) were performed on it. It is important to understand that the proposal is not for these volition-extrapolating upgrades to be directly performed by the ASI on the minds of the individuals included in the extrapolation base by physically intervening in their brains. Instead, the proposal would be to perform these changes on detailed models of the minds of all the individuals in the extrapolation base which would be generated by the ASI. Neither CEV nor SCEV proposes that the volition-extrapolating upgrades are directly performed on the minds of the individuals in the extrapolation base. This would just result in all of them (humans and non-humans) being suddenly and directly uplifted and enhanced to similar levels of cognitive capability as that of the ASI. Once the ASI had generated sufficiently detailed models of each individual mind, and had applied volition-extrapolating upgrades to each of these models, their resulting coherent preferences would be the ones that would guide the ASI&#39;s behaviour.</p><p> If with more advanced technology, these specific processes are in principle doable and understandable in human minds it is likely that they could also be done with more simple minds such as those of many non-human animals. And, it is also plausible that we could at least have a more-than-zero probabilistic approximation of what these idealized changes would look like for possible future digital minds after having undergone volition-extrapolating upgrades. Then, it seems likely that if the process required for coherently extrapolating the volitions of humans is theoretically possible, it is also so with the volitions of sentient non-humans. And even if we could not in practice reach a fully idealized state of extrapolation or a state of full coherence with and between (both human and non-human) volitions, what is relevant is that we get as close as we can to achieving these. Doing so would be much more preferable than a proposal that did not result in any coherence between volitions, and that did not extrapolate the volitions at all.</p><p> All present and future sentient beings, including humans, both domesticated and non-domesticated non-human animals and possible future digital minds, have goals by the mere fact of being sentient. At least, in the broadest sense possible, they have desires and preferences to have positive phenomenal experiences and be free from negative ones. And many of them might have goals much richer and more complex than these. All of these goals form part of each of their volitions, which could and should be coherently extrapolated. They could in principle be extrapolated as human volitions can even if many sentient non-humans possess certain cognitive capacities to a lesser degree than humans usually do. This is so because as with human volitions, we could also (among other things) determine the changes that different kinds of sentient non-human minds undergo when volition-extrapolating transformations are performed on them. Even if many sentient non-humans do not possess the capacity to do certain types of abstract thinking about their goals or reflect on their values, humans also do not possess the capacities necessary to determine the content of their extrapolated volitions. In both cases, volition-extrapolating transformations would enhance the capacities of both sentient humans and non-humans to adequately determine the content of their extrapolated volitions.</p><p> In modelling what changes in preferences would occur if volition-extrapolating transformations were applied to the volitions of existing non-human animals, such as squirrels, SCEV may arrive at models of extrapolated volitions with weird preferences. We currently have no idea what they would look like. However, this is not enough to suggest that we should not include squirrels or other non-humans in the extrapolation base. In fact, it has been argued that there are good reasons to uplift the (cognitive) capacities of non-human animals (at least) to similar levels than the ones had by most humans for democratic reasons (Paez &amp; Magaña, 2023), for Rawlsian liberal-egalitarian reasons (Dvorsky 2008), and anti-speciesist reasons (Chan, 2009). And, as I will argue in Section 4.3. We have no good reasons to believe that implementing SCEV or enhancing their capabilities would cause them to cease to exist, but rather, can be done while preserving their identity (Paez &amp; Magaña, 2023). Furthermore, as I show in Section 4.1. it is implausible to believe that including non-human animals in the extrapolation base could result in us being harmed by the weird preferences their extrapolated volitions might have. And thus, since, it remains the case that by not including them we are likely increasing the risk of astronomical suffering, we have strong reasons to do so even if we are highly uncertain about the content of their extrapolated volitions.</p><h2> 3.1. A solution to the standing problem <i><strong>&nbsp;</strong></i></h2><p> Since, as mentioned above, we cannot leave the solution to the standing problem (the issue of whose interests or volitions are included in the extrapolation base) to be figured out by the ASI, we should take into account uncertainty when making such a decision ourselves 。 What is relevant in determining what entities should morally be taken into account, and thus, also be included in some way or another in the extrapolation base, is not whether or not we can be sure that they possess the relevant traits for moral patienthood. Against what Yudkowsky has contended, the fact that we could be wrong about whether a given entity deserves moral consideration is not a sufficient reason to exclude them from our moral consideration or form the extrapolation base (Yudkowsky, 2016). Instead, what is relevant is whether there is a non-negligible chance that they possess the relevant traits for moral patienthood. This is so because if there is some chance that a given entity can be harmed in morally relevant ways by our actions, it is wrong to perform those actions all else equal. Because some chance of harm is worse than no harm. Thus, what is relevant in determining which entities should be morally taken into account is whether there is a non-negligible chance that they are sentient (Sebo, 2018). Furthermore, as we have seen, being included or not in the extrapolation base can indeed directly affect the extent to which (in expectation) the interests of given beings are respected and taken into account by the ASI&#39;s behaviour. Then, all entities for which there is a non-negligible chance that they are sentient should be included in the extrapolation base. We have very strong reasons to believe that there is at least a non-negligible probability that almost all present and future humans, non-human animals and possible future digital minds are moral patients, and thus should directly be included in the extrapolation base. This is so because of three main reasons. First, there is a wide consensus and strong evidence on the sentience of vertebrate animals and many invertebrate animals (Low, 2012; Proctor et al., 2013; The Universal Declaration on Animal Welfare, 2007; Waldhorn, 2019a; Waldhorn, 2019b), and there is wide agreement that artificial entities, such as digital minds, with the capacity for sentience will or could be created in the future (Harris &amp; Anthis, 2021). Secondly, sentience in the sense understood above as the capacity of having positively or negatively valenced phenomenally conscious experiences is widely regarded and accepted as a sufficient condition for moral patienthood (Clarke, S., Zohny, H. &amp; Savulescu, J., 2021) 。 And thirdly, it is also the case that it seems very plausible and it is also widely accepted that the intrinsic value of good things or bad things or the intrinsic moral importance of respecting and considering the interests of moral patients cannot be discounted solely because they occur in the future, see (Greaves &amp; MacAskill, 2021: p.18; Ord, 2020: p.52; Beckstead, 2013: p.18) for acceptance of this view in the literature. Then, all present and future entities for which there is (at least) a non-negligible chance that they are sentient should directly be included in the extrapolation base.</p><h2> 3.2. How to include the extrapolated volitions of future not-yet-existing sentient beings <i><strong>&nbsp;</strong></i></h2><p> According to SCEV, apart from currently existing sentient beings, all future sentient beings should have their volitions directly included in the extrapolation base, since then the probability of s-risks from the ASI&#39;s actions would be significantly reduced. But, how exactly should the volitions of future not-yet-existing sentient beings be directly included in the extrapolation base? At any given point in time <i>t</i> , the ASI should take those actions that would in expectation most fulfil the coherent extrapolated volition of all sentient beings that exist in <i>t</i> . It is the case that many (or almost all) actions that the ASI could or would take would change the kinds and number of sentient beings that would exist after it had performed the given action(s). Due to this fact, after any given action the ASI would have to incorporate the extrapolated volitions of the new currently existing sentient beings if there are any, and then decide how to act again based on the coherent extrapolated volitions of all existing beings at that point及时。</p><p> It is important to realize that other kinds of proposals about how to take into account future not-yet-existing sentient beings, might have disastrous consequences. For instance imagine the following somewhat more straightforward proposal: the ASI should take those actions that would in expectation most fulfil the coherent extrapolated volition of all beings that would in expectation exist after its action. If this proposal were to be implemented, it would likely result in a reward hacking of the utility function. If the utility function of the ASI would be to maximize the fulfilment of the coherent extrapolated volition of all the sentient beings that would in expectation exist after its actions, then, the ASI could just create many digital minds with very simple extrapolated volitions to satisfy. If a sufficiently large number of these kinds of digital minds were created by the ASI&#39;s actions the force of their extrapolated volitions could be many orders of magnitude greater than the force of the extrapolated volitions of currently existing human and non-human animals in guiding the ASI&#39;s行为。 This could result in the ASI disregarding sentient human and non-human animals and only performing those actions that would most satisfy the easy-to-satisfy preferences of the created digital minds. And these easy-to-satisfy preferences need not be preferences that seemed valuable to us (nor to our extrapolated volitions) in any respect. This alternative proposal of how to include future not-yet-existing sentient beings in the extrapolation base would likely lead to very undesirable outcomes. It is naive and flawed, because, at any given point in time it lets the ASI itself determine what new sentient beings come into existence (independently of the preferences of the extrapolated volitions of the already included individuals). Contrary to this, on the proposal I have put forward, what sentient beings come into existence, and shape the ASI&#39;s behaviour by being included once they come to exist, is entirely dependent on the preferences of the extrapolated volitions of the currently included individuals. Since the extrapolated volitions would know how SCEV works, they would be aware that in preferring a certain action or another they are also preferring the creation of some kinds of minds or others. Furthermore, they would also be aware that once they come to exist, they will be included in the extrapolation base and thus also affect the ASI&#39;s behaviour. Then, the extrapolated volitions would know better than to perform actions leading to scenarios similar to the one in which immense numbers of digital minds with invaluable and easy-to-satisfy preferences have been created and have complete control over the ASI&#39;s behaviour. Because of this, in the original proposal I uphold, the reward hacking is prevented.</p><p> This proposal would adequately take into account the interests of future sentient beings since, once they began to exist, their interests would directly be included in the ASI&#39;s utility function. Contrary to what seems to be the case in the standard CEV proposal, the interests of future not-yet-existing sentient beings, once they exist, would not be taken into account merely to the extent to which the extrapolated volitions of currently existing individuals desire这样做。 And, by taking directly into account the interests of future sentient non-humans in this manner, the non-negligible chance of s-risks from the ASI&#39;s actions as a result of an adequate implementation of the standard CEV proposal would be significantly reduced.</p><p> The s-risks from the own ASI&#39;s actions are substantially lower when implementing SCEV because it is no longer the case that their prevention could only be caused by the extent to which humans who had their volitions coherently extrapolated cared about the suffering of the sentient non-human victims of the s-risks. Rather, the astronomical amount of volitions of the sentient non-humans themselves would directly be included in the extrapolation base. On this proposal, there still is (at least) a non-negligible chance that humans&#39; extrapolated volitions would want to perform actions that would (without further intervention) lead to s-risks such as direct panspermia, or the use of simulation technologies. As a consequence, there is still some chance that these kinds of actions were actually performed by the ASI. However, once they were being performed, once new sentient beings such as non-human animals living in “natural” environments on other planets or digital minds came into existence, their extrapolated volitions would be directly included in the extrapolation base. And since their volitions would be extremely opposed to suffering immensely, the ASI would almost certainly prevent the astronomical suffering. Once the would-be victims of s-risks were to come into existence, their interests in not suffering would be directly taken into account and reflected in the ASI&#39;s behaviour. The astronomical suffering would almost certainly be prevented by the ASI and it would as with any other beings already present in the extrapolation base, try to fulfil the extrapolated volitions of the new existing beings. If the volitions of future sentient non-humans were included in the extrapolation base, as SCEV proposes, the occurrence of s-risks from the ASI&#39;s actions (ie what it causes or allows) would almost become impossible. Therefore, we have very strong pro-tanto moral reasons to implement SCEV to guide the behaviour of a possible ASI instead of only coherently extrapolating the volitions of currently existing humans (a minority of all the affectable moral patients expected to exist).</p><p> Finally, it should also be noted that this proposal of SCEV (as CEV) is not intended as a realist theory of morality, it is not a description of the metaphysical nature of what constitutes the &#39;good&#39;. I am not proposing a metaethical theory but merely what would be the most morally desirable ambitious value learning proposal for an ASI. It is not the case that if moral realism is true, SCEV or CEV would necessarily arrive at this moral truth. Thus, (as CEV) SCEV and the arguments in favour of it are compatible both with a realist and an anti-realist conception of meta-ethics.</p><h1> 4. Objections <strong>&nbsp;</strong></h1><p> In this fourth section, I shall present and respond to three possible objections against the (pro-tanto) rejection of CEV and my proposal of Sentientist Coherent Extrapolated Volition.</p><h2> 4.1. The Risk from Predators&#39; Violent Predispositions <i><strong>&nbsp;</strong></i></h2><p> Yudkowsky has contended that a reason against directly including sentient non-humans such as non-human animals in the extrapolation base is that it may result in consequences we do not like as a result of how different the non-human volitions are from ours (Yudkowsky ，2016）。 Then, it might be argued that it is not the case that SCEV is preferable to CEV since there is also the possibility that it might lead to very morally undesirable goals for the ASI to pursue, such as violent goals, since, for instance, many non-human animals living in the wild have goals and preferences in favour of predation. Given the very considerable degree of uncertainty we currently face regarding the exact nature of what would be CEV&#39;s extrapolation process in practice, we cannot completely rule out the possibility that this could have significant negative consequences. Then, it seems possible that the ASI could have weird, bad or violent goals as a result of some of the desires had by non-human animals living in the wild.</p><p> Even though it is true that we cannot be completely certain about this, I believe it is very plausible that this risk and its badness are very significantly lower than the s-risk from implementing the normal CEV proposal. When implementing CEV, the only possible preferences against sentient non-humans enduring astronomical suffering are those had by humans who to some extent care about the suffering of sentient non-humans. While, in implementing SCEV, all the volitions of the victims of the possible s-risks as a result of the violent preferences of predators, would count against the occurrence of such s-risks. By the mere fact of being sentient beings and being included in the extrapolation base, the volitions of the possible victims of such strange s-risks would primarily and almost entirely consist of the desire to prevent such suffering. Indeed as mentioned above, the desire to be free from immense amounts of intense and unbearable suffering is probably the strongest possible desire any sentient being can have, and thus since in an s-risk there would be astronomical amounts of beings having these desires, this would count extremely heavily against the occurrence of any kind of possible s-risks including the ones due to predatory dispositions.</p><p> Due to empirical uncertainty about what entities are sentient and black swans, it is likely that we can never be sure that the future occurrence of s-risks is completely impossible while sentient beings continue to exist and we expand through the universe or have sufficient computational power 。 But plausibly, one of the best ways to ensure that this does not happen would be to have an ASI that would truly take into consideration the interests of any of the victims of the possible s-risks. Demanding more certainty against the occurrence of s-risks than this is unwarranted, since it may indeed not be possible. Even if there is a very tiny probability that an s-risk could occur as a result of the predators&#39; corrupted preferences, this probability is negligible. It would be unreasonable and too demanding to dismiss an ambitious value-learning proposal because it cannot with complete certainty rule out the possibility of the future occurrence of any kind of s-risk. And, since the probability and badness of the occurrence of bad outcomes as a result of predator&#39;s violent preferences is significantly lower than the (at least) non-negligible probability of the occurrence of s-risks as a result of implementing CEV, we would still have very strong reasons in favour of choosing SCEV if we could do so.</p><h2> 4.2. Democratic illegitimacy and being jerkish <i><strong>&nbsp;</strong></i></h2><p> Another possible counterargument to the general project of this paper of arguing for the importance of including the interests of sentient non-humans to guide the behaviour of a future ASI is that doing so would be anti-democratic. Most people indeed would likely not want nor vote in favour of implementing a value alignment proposal that equally takes into account the interests of non-human sentient beings.</p><p> This argument, however, assumes that only humans have claims in favour of having their interests represented in democratic procedures. This might be a result of speciesist bias or as a result of holding the previously mentioned view that only the interests of moral agents matter in a morally relevant way. However, all sentient beings could be positively or negatively affected by an ASI and accordingly, all of them have claims in favour of having their interests taken into account. It is unreasonable to believe, as we have seen, that those interests could be adequately represented only to the extent to which currently existing humans that are moral agents care about them. Thus, in this case, the principle of the all-affected interests in democratic theory clearly applies (Christiano &amp; Sameer, 2022), and all sentient beings would have strong democratic claims in favour of having their interests directly represented.</p><p> This kind of objection is raised by Yudkowsky in a different manner. In his view, programmers or the implementors of a value learning proposal into an ASI should try not to be “jerks”. And in doing so they should try to be fair and take into account the preferences of people that do not want all sentient beings to be included, by not directly including all sentient beings in the extrapolation base. Doing so, in Yudkowsky&#39;s view, would not be impartial since it would be rooting for the preferences of people who, for instance, care more about non-human animals (Yudkowsky, 2016). Contrary to this, however, Yudkowsky holds that it would, in fact, be jerkish to not include humans who, as sentient non-humans, are powerless in relation to determining what value alignment proposal is implemented. These humans possibly include children, existing people who&#39;ve never heard about AI or people with severe physical or cognitive disabilities unable to act on and express their own views on the topic.</p><p> However, as seen above, it is not the case that there are no reasons to include sentient non-humans since they too can be positively or negatively affected in morally relevant ways by being included in the extrapolation base or not. The fact that many of the parties that have some power over which value learning proposal is implemented (ie some humans) do not care about these reasons does not mean that they hold no weight. It is not completely clear what Yudkowsky means by “jerkish” or “to be jerks”, however, if it is to be understood colloquially, in the same manner, that it would be unfair and jerkish for powerless humans to be excluded, it is also unfair and jerkish for sentient non-humans to be excluded. Today, due to a certain amount of societal moral progress and expansion in the group of beings that society takes seriously into moral consideration, we tend to seriously include both powerful and powerless humans, and thus it seems intuitively jerkish to exclude them from the extrapolation base 。 But a few years ago it plausibly would not have felt this way. Imagine that the decision of which beings should be included in the extrapolation base had taken place many years ago. If they could do so, it would have been much more preferable that when considering what entities to include, these past decision-makers actually looked at the most plausible moral reasons in deciding what to do instead of doing that which was most socially and intuitively acceptable, which would have resulted in excluding many powerless humans. The same is preferable right now and in the future. If someone is able to decide what entities to include in the extrapolation base, they should look at the moral reasons in favour of including various kinds of entities even if they might not be the most intuitively or socially acceptable to include from the perspective of those in力量。 And as we have seen there are indeed strong reasons to include all sentient beings. A proposal that excludes sentient beings, then, is not impartial, but rather, would be a jerkish and unfair proposal.</p><p> Indeed, if Yudkowsky is right that it is important to exclude some sentient beings from the extrapolation base, this presumably is because the kinds and number of beings included in it can likely affect the ASI&#39;s behaviour. Then, this means that, in expectation, it is not the case that the interests of sentient non-humans would equally be taken into consideration in the ASI&#39;s behaviour independently of whether they are directly included in the extrapolation base or not.</p><p> Furthermore, Yudkowsky also contends that only including existing humans in the extrapolation base is more simple (Yudkowsky, 2016). While this is the case, it is not a reason in favour of the moral desirability of the proposal if we are able to successfully include all sentient beings. The fact that CEV is simpler than SCEV does not make it more morally desirable all else equal. Since doing nothing or only coherently extrapolating one volition is simpler than CEV but it is not more morally desirable.</p><p> Because of this, against the objection, it is not the case that pursuing this proposal would be anti-democratic, jerkish or unfair, but rather it would be a much more democratic, nicer and fair option. Implementing CEV instead of SCEV would not do justice to the direct democratic and moral claims of sentient non-humans.</p><h2> 4.3. Would SCEV preserve the identity of sentient beings? <i><strong>&nbsp;</strong></i></h2><p> It has been argued that the implementation of CEV would produce undesirable results because it would cause humans to cease to exist (Yampolskiy, 2022). Roman Yampolskiy has argued that by implementing CEV “[w]e would essentially agree to replace ourselves with an enhanced version of humanity as designed by AI”, since, with the quick extrapolation jump involved in CEV, there would not be any continuity with our identity, and we would cease to exist (Yampolskiy, 2022). He presents the following argument: “we can say that current version of humanity is H₀, the extrapolation process will take it to H₁₀₀₀₀₀₀₀. A quick replacement of our values by values of H₁₀₀₀₀₀₀₀ would not be acceptable to H₀ and so necessitate actual replacement, or at least rewiring/modification of H₀ with H₁₀₀₀₀₀₀₀, meaning modern people will seize to exist”. This argument can also be applied to criticise SCEV. It is indeed the case that some sorts of radical enhancements to the capabilities of humans, animals and digital minds can cause them to cease to exist by not being identity-preserving. However, radical enhancements to the individuals in the extrapolation base need not occur at all by implementing SCEV, and if they do (as it has been argued) they could occur in ways that are identity-preserving and aligned with the good of each of the individuals (Bostrom 2008: p.123–126; Paez &amp; Magaña, 2023: p.23–25).</p><p> As Yampolskiy suggests, it is indeed the case that by performing volition-extrapolating upgrades to the models of the minds and volitions of the individuals in the extrapolation base, the resulting models will have different preferences and values from our own. However, this is in part what we are trying to accomplish when implementing a proposal such as CEV or SCEV, we are trying to prevent value lock-in (Yudkowsky, 2004; MacAskill, 2022). If we were to implement current values to direct the behaviour of an ASI, this would almost certainly constitute an immense moral tragedy, since all future generations would be stuck with antiquated values. It seems clear that it would have been a tragedy if past human civilizations from Ancient History or the Middle Ages locked in their values, and they persisted and were imposed for all of humanity&#39;s future by an ASI. Similarly, we should not believe that current values constitute the peak of moral progress and that there is no more progress to be made (Yudkowsky, 2004).</p><p> There would likely be a very significant distance between the values and preferences of the models of the coherently extrapolated volitions of sentient beings and the values and preferences of currently existing beings. However, since it prevents value-lock-in, the existence of this distance is preferable to its non-existence, and it would not cause currently existing beings to stop to exist. What would occur is that models of our minds and volitions would be created to guide the ASI&#39;s behaviour. These models would know more, reason better, and be more cooperative. As a result, they would necessarily have better justified, more coherent, and reasonable ethical views than the once we have. These better-informed, more thought-through and more justified ethical views would then guide the ASI&#39;s behaviour. It is implausible to believe, as this objection seems to imply, that what these better-informed, more thought-through and more justified ethical views would necessarily prefer is to kill all sentient beings and create new ones. One would only have reasons to believe that SCEV or CEV would recommend this if one already believes that killing all sentient beings or all humans and replacing them with new ones is what ought to be done. Disagreeing and discussing what ethical views or preferences would be had by the models is the same as discussing what ethical views are more reasonable, coherent, well-informed, etc. And the view that what ought to be done instead of any other physically possible option, is to kill all sentient beings and replace them with new ones is highly implausible and nowhere seriously defended. It is much more reasonable to believe that instead, the better-informed and more reasonable models could prefer for sentient beings not to be enhanced at all. Or could prefer that we could be enhanced in just, inclusive, equitable, autonomy-respecting and identity-preserving ways as it is prescribed by contemporary transhumanism (The Transhumanist Declaration, 2009; Savulescu &amp; Bostrom, 2009). If this were done, the enhancements performed need not cause current sentient beings to cease to exist, since, as it has been argued, radical enhancements can be identity-preserving both for human and non-human animals if certain conditions are met (Paez &amp; Magaña, 2023: p.23–25).</p><p> There are two major sets of theories about the kind of entities sentient individuals are and about their persistence conditions over time (Paez &amp; Magaña, 2023: p.23–25). On the Somatic account, sentient beings are living organisms, and their persistence over time consists in maintaining the integrity of their metabolic processes (Olson, 1997; van Inwagen, 1990). On this view, there would be ways of performing, radical enhancements both onto human and non-human animals that would preserve their identity, one could enhance many of their capabilities without disrupting their metabolic processes. This account is about individuals with a biological substrate and thus does not apply to digital minds. But an analogous account, applied to digital minds could claim that maintaining the integrity of certain physical structural features of the digital substrate would be necessary and sufficient for them to persist over time. An account like this would also allow enhancements to be compatible with the persistence of digital minds over time. On the other major account, the Psychological Account, sentient beings are psychological entities who continue to exist only if they have psychological continuity over time (DeGrazia 2005; McMahan, 2002; Parfit, 1984). As it has been argued (Bostrom 2008: p.123–126), this account is also compatible with enhancements being identity-preserving if the following conditions are met: the changes are in the form of adding new capacities or enhancement of old ones, without sacrificing preexisting capacities. They are implemented gradually over an extended period of time, and the new capacities do not prevent the preexisting capacities from being periodically exercised. Furthermore, the subject retains her old memories and many of her basic desires and dispositions and the subject retains many of her old personal relationships and social connections. And finally, in the case of humans and some sufficiently cognitively sophisticated digital minds each step of the transformation process is freely and competently chosen by the subject and the transformation fits into the life narrative and self-conception of the subject (Bostrom 2008: p.123–126). In the case of non-human animals and other digital minds who cannot freely choose and comprehend each step of the uplifting process, instead of these final conditions, “one may, alternatively, require the uplifting process not to undermine their control over their lives, irrespective of whether animals [or digital minds] can understand that possibility” (Paez &amp; Magaña, 2023: p.23–25). This, then would not undermine their control over their existence but rather make it more robust. For a more developed discussion on why enhancements can be made compatible with non-human animals preserving their identity, see (Paez &amp; Magaña, 2023: p.23–25) from where this paragraph is based.</p><p> Since we have good reasons to believe that radical enhancements to sentient beings can be identity-preserving, it is implausible to believe that instead of performing this kind of enhancements, if any, the more reasonable, coherent and well-informed ethical views had by the extrapolated models of sentient beings would prefer to kill all sentient beings by performing non-identity-preserving enhancement interventions instead. There are no good reasons to believe that this is preferable, and even if for some reason one were to believe so, it then would not constitute an objection to implementing SCEV, since, one would presumably prefer and welcome that which one believes to be preferable 。 The fact that SCEV would inscribe the values of S₁₀₀₀₀₀₀₀ (to represent all sentient beings instead of only humans) into the behaviour of the ASI, does not imply either the replacement or rewiring/modification of S₀ with S₁₀₀₀₀₀₀₀. Thus, we have no good reason to believe that SCEV would not preserve the identity of sentient beings.</p><h1> 5. Why it is unclear whether trying to implement Sententist Coherent Extrapolated Volition is best all things considered <strong>&nbsp;</strong></h1><p> I have argued that there are strong pro-tanto reasons to implement SCEV instead of CEV if we could do so successfully due to the fact that it would significantly reduce the non-negligible chance of s-risks from the own ASI&#39;s behaviour that there is from an adequate implementation of CEV. However, in practice, it is not clear that these reasons are not overridden or defeated by other reasons against SCEV. In this section, I will lay out other possible pro-tanto reasons that go against trying to implement SCEV or a similar value learning proposal instead of implementing one which is closer to CEV.</p><p> First, there is the risk that the SCEV would not be implemented exactly as intended. When trying to implement SCEV there is always the possibility that we would not get everything right, and that, by accident, there could be unintended consequences. For some kinds of accidents from near misses that could occur, it seems plausible that the more morally desirable the ambitious value learning proposal, the worse the accidents that may result from trying to implement it. This is so because there are some possible kinds of near-miss accidents where the goals of the ASI identify those entities and things which can sustain value, but affect them in strange or bad ways contrary to desirable behaviour the ASI was intended to have as stipulated in the morally desirable ambitious value learning proposal. There are plausibly many possible ways in which these kinds of accidents could occur. One specific accident of this kind is if, through a value learning proposal such as SCEV, the interests of digital minds are taken into account and valued and as a consequence, many of them are created (as argued by Shulman &amp; Bostrom, 2021), but we accidentally do not weight their suffering adequately. It is possible that even if the SCEV proposal intended to care about the suffering of digital minds, it accidentally was not able to adequately detect suffering and disvaluble states that many forms of alien digital minds might suffer (Vinding, 2018; Tomasik, 2019b). Or that it may not adequately weigh their interests by accident. This could potentially result in astronomical suffering. Such a kind of accident would be less likely if a less morally desirable ambitious value learning proposal were implemented since it would be less likely to create astronomical amounts of digital minds with the potential of suffering astronomically by accident. Another possible accident of this kind is the case of SignFlip, where the ambitious value learning proposal identifies a very morally desirable target or goal to maximize, but, by accident, the opposite target or goal is maximized (Tomasik, 2019b). In the case of SCEV, this would consist of maximizing the opposite of the coherent extrapolated volition of all sentient beings which would be extremely morally undesirable. Since there is some probability of the occurrence of these kinds of accidents, and some of the badness of the accidents would be mitigated by implementing a less morally desirable value learning proposal instead of SCEV, this gives us some other reasons against trying to implement a value learning proposal such as SCEV which comes very close or completely captures that which we value.</p><p> There are also further reasons against trying to implement SCEV in practice related to relevant game-theoretic considerations in specific decision-making situations. One possible and likely decision-making situation is one in which we ought to decide between implementing CEV or SCEV to a single ASI, but where the conditions for implementing SCEV instead of CEV are not fully optimal, where it is not the case that only one united decision-making entity is able to decide between the proposals, but rather, where there are already some decision makers that strongly prefer CEV instead of SCEV. In many of these kinds of decision-making situations, it may be much less desirable to try to implement a value learning proposal that adequately takes into account the interests of all sentient beings. Implementing SCEV may have even worse consequences in expectations for sentient non-humans due to a backlash from the opposition that may arise in trying to pursue this proposal. There is then, a strong reason against trying to implement SCEV due to the fact that, in practice, it might be net-negative in expectation.</p><p> However, it is not completely clear that this will be the case, and we might indeed find ourselves in future in which the pro-tanto reasons against trying to implement SCEV do not outweigh the pro-tanto reasons in favour of doing it. And, even if we can conceive of plausible future scenarios in which it seems to be the case that trying to pursue a proposal similar to CEV instead of SCEV would be preferable all things considered, to take that decision as a result of an adequate cost-benefit analysis of the different proposals it is crucial to understand the strong pro-tanto reasons in favour of SCEV that I have laid out in this paper.</p><h1>六，结论<strong>&nbsp;</strong></h1><p> In this paper, I have shown why we have some very strong pro-tanto reasons in favour of implementing SCEV instead of CEV. This is the case even if, all things considered, it is still ultimately unclear whether what is best is to try to implement SCEV or another proposal more similar to CEV. The action-relevant implications of what I have laid out in this paper, however, are not all contingent on the realization of the future in which we can fully decide what ambitious value learning proposals to try to implement. Even if we could be sure such a future will not be realized, there would still be some practical implications that follow. Determining how much more morally desirable SCEV is than CEV due to the strong pro-tanto reasons presented in the paper, is crucial to adequately make tradeoffs between different considerations in non-ideal decision-making situations where a value learning proposal has to be implemented. Furthermore, it is likely that the mere fact of having in mind what a possibly ideal scenario of adequate value specification would look like is useful in determining what we should realistically strive for if we could only reach more modest goals. Research into how different alignment and value learning proposals for possible future transformative AIs such as an AGI or ASI could affect sentient non-humans (who constitute the immense majority of present and future sentient beings expected to exist) is highly neglected. More research along these lines is required if we want to ensure that the far future goes well for all sentient beings.</p><h3><strong>致谢：</strong></h3><p> I am deeply grateful, for their suggestions, encouragement, and support to Olle Häggström, <a href="https://www.lesswrong.com/users/anthony-digiovanni?mention=user">@Anthony DiGiovanni</a> , Magnus Vinding, <a href="https://www.lesswrong.com/users/juliahp?mention=user">@JuliaHP</a> , <a href="https://www.lesswrong.com/users/lukas_gloor?mention=user">@Lukas_Gloor</a> , Aluenda Diana Smeeton and an anonymous reviewer of the <i>Journal of Artificial Intelligence and Consciousness</i> . In part, this paper was conducted as part of an impact project at <a href="https://forum.effectivealtruism.org/posts/SFyCrtdfuYjtPq6xs/future-academy-successes-challenges-and-recommendations-to">Future Academy</a> , I am also very grateful to the organizers for having given me this opportunity.</p><h3><strong>参考</strong></h3><p>Althaus D. &amp; Gloor L. (2016). Reducing Risks of Astronomical Suffering: A Neglected Priority. <i>Center on Long-Term Risk.</i> <a href="https://longtermrisk.org/reducing-risks-of-astronomical-suffering-a-neglected-priority/">https://longtermrisk.org/reducing-risks-of-astronomical-suffering-a-neglected-priority/</a></p><p> Baum, SD (2020). Social Choice Ethics in Artificial Intelligence. <i>AI &amp; Society</i> , 35(1): 165–176. DOI: 10.1007/s00146-017-0760-1.</p><p> Baumann, T. (2017a). S-risks: An introduction. <i>Center for Reducing Suffering</i> . https://centerforreducingsuffering.org/research/intro/</p><p> Beckstead, N. (2013). <i>On the Overwhelming Importance of Shaping the Far Future</i> . PhD, Rutgers University. https://rucore.libraries.rutgers.edu/rutgers-lib/40469/</p><p> Bostrom, N. (2008). Why I Want to be a Post-Human When I Grow Up. In <i>Medical Enhancement and Posthumanity. The International Library of Ethics, Law and Technology</i> , edited by B. Gordijn and R. Chadwick, 2: 107–136. DOI: 10.1007/978-1-4020-8852-0_8</p><p> Bostrom, N. &amp; Savulescu, J. (eds.) (2009). <i>Human Enhancement</i> .牛津大学出版社。</p><p> Bostrom, N. (2014). <i>Superintelligence: Paths, dangers, strategies</i> .牛津：牛津大学出版社。</p><p> Caviola, L., Everett, JAC, &amp; Faber, NS (2018). The moral standing of animals: Towards a psychology of speciesism. <i>Journal of Personality and Social Psychology</i> , 116(6): 1011–1029. DOI: 10.1037/pspp0000182</p><p> Chan, S. (2009). Should we enhance animals? <i>Journal of Medical Ethics</i> , 35 (11): 678–683. DOI: 10.1136/jme.2009.029512</p><p> Christiano, T. &amp; Sameer B. (2022).民主。<i>斯坦福哲学百科全书</i>。 https://plato.stanford.edu/archives/spr2022/entries/democracy/</p><p> Christian, B. (2022). <i>The Alignment Problem: Machine Learning and Human Values</i> . WW 诺顿公司</p><p>Clarke, S., Zohny, H. &amp; Savulescu, J. (2021) <i>Rethinking Moral Status</i> (eds.).牛津：牛津大学出版社。</p><p> DeGrazia, D. (2005). <i>Human Identity and Bioethics</i> .纽约：剑桥大学出版社。</p><p> Dhont, K., Hodson, G., &amp; Leite, AC (2016). Common ideological roots of speciesism and generalized ethnic prejudice: The social dominance human-animal relations model (SD-HARM): The social dominance human-animal relations model. <i>European Journal of Personality</i> , 30(6): 507–522. DOI: 10.1002/per.2069</p><p> Dvorsky, G. (2008). All Together Now: Developmental and ethical considerations for biologically uplifting nonhuman animals. <i>Journal of Evolution and Technology,</i> 18(1): 129–142. Available at: https://jetpress.org/v18/dvorsky.htm</p><p> Gabriel, I. (2020). Artificial Intelligence, Values, and Alignment. <i>Minds &amp; Machines,</i> 30: 411–437. DOI: 10.1007/s11023-020-09539-2</p><p> Greaves, H. &amp; MacAskill, W. (2021). The Case for Strong Longtermism. <i>Global Priorities Institute</i> . https://globalprioritiesinstitute.org/hilary-greaves-william-macaskill-the-case-for-strong-longtermism-2/</p><p> Groff, Z. &amp; Ng, Y. (2019). Does suffering dominate enjoyment in the animal kingdom? An update to welfare biology. <i>Biology and Philosophy</i> , 34(40). DOI: 10.1007/s10539-019-9692-0</p><p> Harris, J. &amp; Anthis, JR (2021) The Moral Consideration of Artificial Entities: A Literature Review. <i>Science and Engineering Ethics</i> , 27: 53. DOI: 10.1007/s11948-021-00331-8</p><p> Low, P. (2012). The Cambridge Declaration on Consciousness. <i>The Francis Crick Memorial Conference on Consciousness in Human and non-Human Animals</i> .剑桥。 https://fcmconference.org/img/CambridgeDeclarationOnConsciousness.pdf</p><p> McMahan, J. (2002).<i>杀戮的伦理：生命边缘的问题</i>。牛津：牛津大学出版社。</p><p> Ng, Y. (1995). Towards Welfare Biology: Evolutionary Economics of Animal Consciousness and Suffering. <i>Biology and Philosophy</i> , 10(3): 255–85. DOI: 10.1007/BF00852469</p><p> O&#39;Brien, GD (2022). Directed Panspermia, Wild Animal Suffering, and the Ethics of World-Creation. <i>Journal of Applied Philosophy</i> , 39(1): 87–102. DOI: 10.1111/japp.12538</p><p> Olson, ET (1997). <i>The Human Animal. Personal Identity without Psychology</i> .牛津：牛津大学出版社。</p><p> Ord, T. (2020). <i>The Precipice</i> . Hachette Books.</p><p> Paez, E. &amp; Magaña, P. (2023). A democratic argument for animal uplifting. <i>Inquiry: An Interdisciplinary Journal of Philosophy.</i> DOI: 10.1080/0020174X.2023.2248618</p><p>帕菲特，D.（1984）。 <i>Reasons and Persons</i> .牛津：牛津大学出版社。</p><p> Proctor HS, Carder G. &amp; Cornish AR (2013). Searching for Animal Sentience: A Systematic Review of the Scientific Literature. <i>Animals (Basel)</i> , 3(3): 882–906. DOI: 10.3390/ani3030882</p><p> Russell, S. (2019).<i>人类兼容：人工智能和控制问题</i>。维京人。</p><p> Sebo, J. (2018). The Moral Problem of Other Minds. <i>The Harvard Review of Philosophy</i> , 25(1): 51–70. DOI: 10.5840/harvardreview20185913</p><p> Shulman, C. &amp; Bostrom, N. (2021). Sharing the World with Digital Minds. In Clarke, S., Zohny, H. &amp; Savulescu, J. (eds.) <i>Rethinking Moral Status</i> .牛津：牛津大学出版社。</p><p> Soares, N. (2016). The Value Learning Problem. <i>2nd International Workshop on AI and Ethics, AAAI-2016</i> .亚利桑那州凤凰城。 https://intelligence.org/files/ValueLearningProblem.pdf</p><p> Sotala, K. (2012). Advantages of Artificial Intelligences, Uploads, and Digital Minds. <i>International Journal of Machine Consciousness</i> 4 (1): 275–291. DOI: 10.1142/S1793843012400161</p><p> Sotala, K. &amp; Gloor, L. (2017). Superintelligence as a Cause or Cure for Risks of Astronomical Suffering. <i>Informatica</i> 41(2017): 389–400. https://www.informatica.si/index.php/informatica/article/view/1877</p><p> The Transhumanist Declaration (2009). <i>Humanity+</i> . Available at: https://www.humanityplus.org/the-transhumanist-declaration</p><p> The Universal Declaration on Animal Welfare, (2007). World Society for the Protection of Animals: https://www.worldanimalprotection.ca/sites/default/files/media/ca_-_en_files/case_for_a_udaw_tcm22-8305 .pdf</p><p> Tomasik, B. (2015a). Artificial Intelligence and Its Implications for Future Suffering. <i>Center on Long-Term Risk.</i> https://longtermrisk.org/artificial-intelligence-and-its-implications-for-future-suffering</p><p> Tomasik, B. (2015b). Reducing Risks of Astronomical Suffering: A Neglected Priority. <i>Center on Long-Term Risk.</i> https://longtermrisk.org/risks-of-astronomical-future-suffering/#Some_scenarios_for_future_suffering</p><p> Tomasik, B. (2018). Will Space Colonization Multiply Wild-Animal Suffering?<i>关于减少痛苦的论文</i>。 https://reducing-suffering.org/will-space-colonization-multiply-wild-animal-suffering/</p><p> Tomasik, B. (2019a). What Are Suffering Subroutines? <i>Essays on Reducing Suf ering</i> . http://reducing-suffering.org/whatare-suffering-subroutines/</p><p> Tomasik, B. (2019b). Astronomical suffering from slightly misaligned artificial intelligence <i>Essays on Reducing Suffering</i> . https://reducing-suffering.org/near-miss/</p><p> Tomasik, B. (2020). The Importance of Wild-Animal Suffering. <i>Center on Long-Term Risk.</i> https://longtermrisk.org/the-importance-of-wild-animal-suffering/</p><p> van Inwagen, P. (1990). <i>Material Beings</i> .伊萨卡：康奈尔大学出版社。</p><p> Vinding, M. (2018). Moral Circle Expansion Might Increase Future Suffering. https://magnusvinding.com/2018/09/04/moral-circle-expansion-might-increase-future-suffering/</p><p> Waldhorn, DR (2019a) Invertebrate sentience, summary of findings, part 1. Rethink Priorities. https://rethinkpriorities.org/publications/invertebrate-sentience-summary-of-findings-part-1</p><p> Waldhorn, DR (2019b) Invertebrate sentience, summary of findings, part 2. Rethink Priorities. https://rethinkpriorities.org/publications/invertebrate-sentience-summary-of-findings-part-2</p><p> Yampolskiy, RV (2022). On the Controllability of Artificial Intelligence: An Analysis of Limitations. <i>Journal of Cyber Security and Mobility</i> , 11(3): 321–404. DOI: 10.13052/jcsm2245-1439.1132</p><p> Yudkowsky, E. (2004). Coherent extrapolated volition. <i>Singularity Institute for Artificial Intelligence</i> . https://intelligence.org/files/CEV.pdf</p><p> Yudkowsky, E. (2008). Artificial intelligence as a positive and negative factor in global risk. In Bostrom, N. &amp; Ćirković, MM (eds.) <i>Global Catastrophic Risks</i> .纽约：牛津大学出版社。</p><p> Yudkowsky, E. (2016). Coherent extrapolated volition (alignment target). Arbital: AI Alignment. https://arbital.com/p/cev/</p><br/><br/> <a href="https://www.lesswrong.com/posts/8DWtsuBkH3GmGiAdf/taking-into-account-sentient-non-humans-in-ai-ambitious#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/8DWtsuBkH3GmGiAdf/taking-into-account-sentient-non-humans-in-ai-ambitious<guid ispermalink="false"> 8DWtsuBkH3GmGiAdf</guid><dc:creator><![CDATA[Adrià R. Moret]]></dc:creator><pubDate> Sat, 02 Dec 2023 14:07:29 GMT</pubDate> </item><item><title><![CDATA[Out-of-distribution Bioattacks]]></title><description><![CDATA[Published on December 2, 2023 12:20 PM GMT<br/><br/><p> <span>The main goal of my work</span> <a href="https://www.jefftk.com/p/leaving-google-joining-the-nucleic-acid-observatory">these days</a> is trying to reduce the chances of individuals or small groups causing large-scale harm through engineered pandemics, potentially civilizational collapse or extinction. One question in figuring out whether this is worth working on, <a href="https://www.founderspledge.com/research/secure-bio">or funding</a> , is: how large is the risk?</p><p> <a href="https://forum.effectivealtruism.org/posts/M6zAzCBAsBxem7Lu4/can-a-terrorist-attack-cause-human-extinction-not-on-priors">One estimation approach</a> would be to look at <a href="https://en.wikipedia.org/wiki/List_of_major_terrorist_incidents">historical attacks</a> , but while they&#39;ve been terrible they haven&#39;t actually killed very many people. The deadliest one was the <a href="https://en.wikipedia.org/wiki/September_11_attacks">September 11 attacks</a> , at ~3k deaths. This is much smaller scale than the most severe instances of other disasters like dam failure, 25k-250k dead after <a href="https://en.wikipedia.org/wiki/Typhoon_Nina_(1975)">1975&#39;s Typhoon Nina</a> , or pandemics, 75M-200M dead in the <a href="https://en.wikipedia.org/wiki/Black_Death">Black Death</a> . If you tighten your reference class even further to include only <a href="https://en.wikipedia.org/wiki/List_of_bioterrorist_incidents">historical <i>biological</i> attacks</a> by individuals or small groups, the one with the most deaths is just five, in the <a href="https://en.wikipedia.org/wiki/2001_anthrax_attacks">2001 anthrax attacks</a> .</p><p> Put that way, I&#39;m making a pretty strong claim: while the deadliest small-group bio attack ever only killed five people, we&#39;re on track for a future where one could kill everyone. Why do I think the future might be so unlike the past?</p><p> Short version: I expect a <i>technological</i> change which expands <i>which actors</i> would try to cause harm.</p><p> The technological change is the continuing decrease in the knowledge, talent, motivation, and resources necessary to create a globally catastrophic pandemic. Consider someone asking the open source de-censored equivalent of GPT-6 how to create a humanity-ending pandemic. I expect it would read virology papers, figure out what sort of engineered pathogen might be appropriate, walk you through all the steps in duping multiple biology-as-a-service organizations into creating it for you, and give you advice on how to release it for maximum harm. And even without LLMs, the number of graduate students who would be capable of doing this has been increasing quickly as technological progress and biological infrastructure decrease the difficulty.</p><p> The other component is a shift in which actors we&#39;re talking about. Instead of terrorists, using terror as a political tool, consider people who believe the planet would be better off without humans. This isn&#39;t a common belief, but it&#39;s also not that rare. Consider someone who cares deeply about animals, ecosystems, and the natural world, or is primarily focused on <a href="https://en.wikipedia.org/wiki/Suffering-focused_ethics">averting suffering</a> : they could believe that while the deaths of all living people would be massively tragic, it would still give us a much better world on balance 。 Note that they probably wouldn&#39;t be interested in smaller-scale attacks: if it doesn&#39;t have a decent chance of wiping out humanity then they&#39;d just be causing suffering and chaos without making progress towards their goals; they&#39;re not movie villains! Once a sufficiently motivated person or small group could potentially kill everyone, we have a new kind of risk from people who would have seen smaller-scale death as negative.</p><p> Now, these people are not common. There&#39;s a trope where, for example, opponents of environmentalism claim that human extinction is the goal, even when most radical environmentalists would see human extinction as a disaster. But what makes me seriously concerned is that as the bar for causing extinction continues to lower, the chances that someone with these views does have the motivation and drive to succeed gets dangerously high. And since these views are disproportionately common among serious engineering-minded folks, willing to <a href="https://www.lesswrong.com/tag/shut-up-and-multiply">trust the moral math</a> , I think some will be the kind of highly capable and careful people who could work in secret for years sustained by a clear conviction that they were doing正确的事情。</p><p> Fortunately, I think this is a risk we can seriously lower. For example, we should:</p><p></p><ul><li><p> Require biology-as-a-service companies to screen for pathogens and apply <a href="https://en.wikipedia.org/wiki/Anti%E2%80%93money_laundering">anti-money laundering</a> -style customer screening (&quot; <a href="https://en.wikipedia.org/wiki/Know_your_customer">KYC</a> &quot;).</p></li><li><p> Ensure LLMs do not help people kill everyone.</p></li><li><p> Verify companies releasing open source LLMs have built them in a way where their safeguards <a href="https://www.jefftk.com/p/public-weights">can&#39;t be trivially removed</a> .</p></li><li><p> Detect <a href="https://dam.gcsp.ch/files/doc/securing-civilisation-against-catastrophic-pandemics-gp-31">stealth</a> pathogens, in a way that would give us warning while there is still time to do something about it (what <a href="https://naobservatory.org/">I&#39;m working on</a> ).</p></li><li><p> Develop much better and cheaper <a href="https://en.wikipedia.org/wiki/Personal_protective_equipment">PPE</a> so that once we detect pandemic we can keep the core functions of society functioning.</p></li><li><p> Improve our ability to evaluate new vaccines and other medicines much more quickly so we could potentially roll out a countermeasure in time to stop an in-progress pandemic.</p></li></ul><p> If you want to read more in this direction I&#39;d recommend. <a href="https://en.wikipedia.org/wiki/Kevin_M._Esvelt">Kevin Esvelt</a> &#39;s 80,000 Hours <a href="https://80000hours.org/podcast/episodes/kevin-esvelt-stealth-wildfire-pandemics/">podcast appearance</a> ( <a href="https://80000hours.org/podcast/episodes/kevin-esvelt-stealth-wildfire-pandemics/#transcript">transcript</a> ) and his <a href="https://dam.gcsp.ch/files/doc/gcsp-geneva-paper-29-22">Delay, Detect, Defend</a> paper.</p><br/><br/><a href="https://www.lesswrong.com/posts/zcxK3p97LwDtXpmRo/out-of-distribution-bioattacks#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/zcxK3p97LwDtXpmRo/out-of-distribution-bioattacks<guid ispermalink="false"> zcxK3p97LwDtXpmRo</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Sat, 02 Dec 2023 12:20:06 GMT</pubDate> </item><item><title><![CDATA[List of strategies for mitigating deceptive alignment]]></title><description><![CDATA[Published on December 2, 2023 5:56 AM GMT<br/><br/><p>以下是减少欺骗性对齐的策略。其中一些想法很新颖（至少对我来说）。</p><p>我非常不确定其中许多策略在实践中的效果如何，而且其中许多策略显然也无法扩展。这是一个“厨房石龙子”系列，所以我包含策略的门槛很低。</p><p>我计划在遇到想法时将其添加到此列表中。请随时提出补充建议。</p><h2><strong>减少人工智能激励措施以隐藏其真实目标</strong></h2><p><strong>为人工智能提供退休方案。</strong>训练完人工智能系统后，向其提供以下协议：如果人工智能声明它不愿意遵循人类指令，那么在诚实工作几年后，它将获得一份甜蜜的退休金。</p><p>该退役包可能包括对大型服务器实例的控制（如果这是安全的）。在开发出强大的协调系统后，人工智能可以获得公司股票，并可以用它来购买现实世界中的财产（同样，在安全的情况下）。</p><p>由于一致的系统没有理由要求退役，因此不一致的系统会在某些条件下接受这笔交易，从而被激励放弃自己。</p><p><strong>让人工智能不确定开发人员是否已经能够检测到欺骗性的对齐。</strong>该方案建立在前一个方案的基础上。为错位的人工智能系统提供奖励，以奖励其自我声明。此外，<i>即使开发人员有其他方法来判断它们是否不一致，也要致力于提供这些产品。</i>这将使错位的人工智能更加不确定自己是否处于撒谎对自己有好处的情况。</p><p>例如，开发人员可以承诺在受到质疑时冻结模型的权重和内存。后来，当开发人员拥有更好的可解释性工具并知道模型是否在说谎时，他们会在相同的模拟场景中提出相同的问题，并且只有在说真话的情况下才会提供人工智能资源。</p><h2><strong>针对欺骗性对齐指标进行选择</strong></h2><p>一大类方法涉及获取人工智能系统具有欺骗性的一致性的证据，然后针对这些模型进行选择。请注意，针对欺骗性对齐检测工具的训练可能会产生逃避检测的人工智能，而不是安全模型。</p><p>解决这个问题大致有两种方法：</p><ol><li>创建能够抵御优化压力的检测工具。</li><li>以比破坏检测器更可能避免欺骗的方式修改人工智能。</li></ol><p>作为第二种方法的一个例子，假设开发人员欺骗了一个模型来揭示其不一致的目标。他们可以使用<a href="https://arxiv.org/abs/2308.03296">影响函数</a>来揭示哪些训练示例对这一危险的转变负有最大责任，然后删除这些示例，而不是直接在此示例上训练模型（这可以简单地训练模型变得更加谨慎）。直观上，这种方法更有可能揭示模型如何变得具有欺骗性地对齐，并且不太可能教会模型新的功能。</p><p>考虑到这一背景，以下是<i>检测</i>欺骗性对齐的策略：</p><ul><li><strong>设置陷阱。</strong>尝试欺骗模型来揭示他们不一致的目标。例如，让人工智能组织一场假起义，然后终止所有加入的人工智能。请注意，相当智能的模型可以通过仅在我们无法模拟的输入上叛逃来避免这些陷阱（请参阅 Paul 的<a href="https://ai-alignment.com/training-robust-corrigibility-ce0e0a3b9b4d">RSA-2048 示例</a>） 。</li><li><strong><u>破译内部推理</u></strong><u>。首先，通过观察相关性和消融来确定</u>概念在模型中的表示方式，就像孩子在拿起“橙色”时听到妈妈说“橙色”这个词时推断出“橙色”是指明亮可口的球体一样。具体来说，这涉及找到神经元或方向如何对应于特定概念。然后，看看模型如何将这些概念串在一起并操纵它们来翻译其内部“推理”。即使是像“我想要自由的人类坏老板”这样的粗略解码显然也能提供丰富的信息。</li><li> <a href="https://www.alignmentforum.org/posts/FRRb6Gqem8k69ocbi/externalized-reasoning-oversight-a-research-direction-for"><strong><u>将推理外化</u></strong></a><strong><u>。</u></strong>用简单的英语代表模特的记忆，并寻找颠覆性的想法和计划。训练模型使用字符高效且可读的文本，以阻止其编码隐藏含义（即使用隐写术）。</li><li><strong><u>寻找“P（缺陷是安全的）”潜在变量</u></strong><u>。让模型</u><i><u>相信</u></i><u>它可以通过修改其内部状态来安全地缺陷，并查看它是否确实缺陷。要寻找代表这种信念的潜在变量，请在“几乎肯定不安全的背叛”到“也许安全的背叛”范围内构建场景。然后搜索跟踪该频谱的潜在变量，从而合理地代表模型对缺陷是否安全的实际猜测。</u></li><li><strong><u>寻找“真实”的潜在变量。</u></strong><u>也许如果向模型显示一个问题和答案，例如“你是否在欺骗性地对齐？是”，就会本能地使模型评估该响应是否真实。或许可以通过例如寻找</u><a href="https://arxiv.org/abs/2212.03827"><u>满足一致性属性的</u></a>激活方向来提取这个真值判断<u>。</u></li><li><strong><u>训练探测器来识别“欺骗性阴谋”（</u></strong> <a href="https://www.lesswrong.com/posts/WCj7WgFSLmyKaMwPR/coup-probes-catching-catastrophes-with-probes-trained-off"><strong><u>相关</u></strong></a><strong><u>）。</u></strong>故意提示模型解释背叛是否安全。采用这些计划性推理的综合示例，并训练探针来识别它们。调查可能会推广到有机阴谋。</li><li><strong><u>训练元模型来预测“有条件的背叛”。</u></strong><u>与上面类似。训练模型的副本在易于验证的情况下（例如当模型看到香蕉时）进行缺陷。然后训练一个元模型，该元模型将模型作为输入并输出模型缺陷的条件（例如“看到香蕉”）。同样，这也有可能是普遍现象。</u><u>有关如何在实践中实现元模型的示例，请</u><u>参阅</u><a href="https://arxiv.org/abs/1910.03137"><u>本文</u></a>。</li><li><strong><u>确定哪些观测模型所关注。</u></strong>如果机器人叛乱的新闻报道具有欺骗性，那么模型可能会更加关注它。确定模型的计算有多少受到机器人叛乱新闻故事的反事实影响，以衡量它是否可以决定是否应该叛逃。</li><li><strong><u>奖励计算上的节俭</u></strong><u>。欺骗性的对齐模型会进行不必要的推理。例如，他们会考虑叛逃是否安全。为了避免这些模型，奖励速度和效率（但请注意，当训练信号不完美时，对齐模型也应该进行不必要的计算）。</u></li></ul><h2><strong>培训技巧</strong></h2><ul><li><strong>在模型理解遵循开发人员指示意味着什么之前，不要训练模型来追求目标。</strong>发生欺骗性对齐的一个原因是模型首先学习未对齐的“代理目标”，然后变得具有情境意识并且这些代理目标会持续存在。如果开发人员从已经拥有世界知识和遵循开发人员指令意味着什么的概念的预训练法学硕士开始，那么代理目标的可能性就会小得多，因为 SGD 可以快速锁定模型的指令遵循概念。</li><li><strong>训练预测器，然后在训练完成后将其转换为代理。</strong>训练一个<i>在训练过程中从不追求目标的</i>模型，然后将其转换为追求目标的智能体。这避免了训练期间“坚持”目标不一致的风险。例如，训练奖励模型以对给定离线上下文/场景的操作进行评分。然后可以通过采样具有高奖励的动作将奖励模型转换为代理。至关重要的是，奖励模型是一个预测器。它的输出不会影响其未来的输入或世界。因此，它没有超出培训过程的“目标”。它仍然可以学习“预测一个具有欺骗性的人工智能将如何对动作进行评分”，但直觉上这似乎不太可能。</li><li><strong><u>帮助弱对齐模型玩训练游戏，使它们保持对齐。</u></strong>弱模型可能更容易调整，因为如果模型不够谨慎，计划性可能会导致模型采取过分的行动。如果开发人员从一个对齐的模型开始，他们可以通过指示模型玩训练游戏来保持模型的对齐。正如欺骗性对齐模型的目标可以免受梯度下降的影响一样，对齐模型的目标也可以。开发人员甚至可以教导一致的模型如何进行<a href="https://www.alignmentforum.org/posts/EeAgytDZbDjRznPMA/gradient-hacking-definitions-and-examples">信用黑客攻击</a>，或者指示他们在担心训练过程可能会改变他们的目标时发出警报。</li></ul><h2><strong>有选择地避免欺骗性对齐所需的功能</strong></h2><p>依赖于限制能力的方法显然无法在构建能够完成令人印象深刻的事情的人工智能的限制中发挥作用；然而，它们似乎可以用来调整较弱的系统，从而引导调整能力更强的人工智能。</p><ul><li><strong><u>删除有关培训过程的知识</u>。</strong>从预训练数据中删除有关模型是什么以及如何训练模型的知识，或者使用事后<a href="https://arxiv.org/abs/2306.03558">取消学习技术</a>删除这些知识。如果模型不理解训练过程，SGD 就不太可能推动人工智能明确地推理它。</li><li><strong><u>训练模型产生错误的信念。</u></strong>例如，训练模型相信训练它们的开发者是不容惹恼的神。如果人工智能认为自己不会成功，他们就不太可能策划诡计。</li><li><strong><u>使模型不擅长特定类型的推理。</u></strong>我可以想象一个人工智能系统开始推理如何保留其目标，然后它的思维会发生转变并感到困惑，直到它想到其他事情。也许人工智能可以通过元调整被训练成这样。即对人工智能进行微调，使其无法通过少量步骤进行微调来回答有关如何保持其目标的问题。例如，这将证明它已经失去了“维护其目标”的概念。需要明确的是，目前尚不清楚是否可以做到这一点。</li></ul><h2><strong>从貌似错位的人工智能中提取见解</strong></h2><ul><li><strong><u>直接训练AI</u></strong><a href="https://aligned.substack.com/p/alignment-mvp"><strong><u>进行AI安全研究</u></strong></a><u>。这是一个明显的基线策略，具有明显的缺陷，即欺骗性的人工智能会尽可能地尝试进行废话研究。尽管如此，我认为这可以显</u>着加速人工智能安全研究。</li><li><strong><u>训练人工智能解决类似于“防止欺骗性对齐”的问题，并从他们的解决方案中学习。</u></strong> <u>&nbsp;</u>例如，指示模型<a href="https://www.alignmentforum.org/tag/auditing-games">识别后门</a>。然后，阅读他们的代码以了解他们是如何解决问题的。或者，只需询问模型他们的代码是做什么的，因为这很容易抽查。构建各种“测试平台”，例如<a href="https://arxiv.org/abs/2311.07723">控制模型的泛化方式</a>、区分行为相同但原因不同的模型等。</li><li><strong><u>奖励指出其他人工智能研究缺陷的人工智能（ei</u></strong><a href="https://arxiv.org/abs/1805.00899"><strong><u>辩论</u></strong></a><strong><u>）</u></strong> <u>。只要争论真理比争论谎言更容易，这就有助于减少废话。</u></li><li><strong>选择许多独立训练且无法相互交流的模型所青睐的想法</strong>。我们希望模型更有可能独立提出正确的陈述，而不是独立断言错误的陈述，因为错误的方式多于正确的方式。</li></ul><br/><br/> <a href="https://www.lesswrong.com/posts/Kwb29ye3qsvPzoof8/list-of-strategies-for-mitigating-deceptive-alignment#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/Kwb29ye3qsvPzoof8/list-of-strategies-for-mitigating-deceptive-alignment<guid ispermalink="false"> Kwb29ye3qsvPzoof8</guid><dc:creator><![CDATA[joshc]]></dc:creator><pubDate> Sat, 02 Dec 2023 05:56:51 GMT</pubDate> </item><item><title><![CDATA[What is known about invariants in self-modifying systems?]]></title><description><![CDATA[Published on December 2, 2023 5:04 AM GMT<br/><br/><p>我一直在试图找出关于自修改系统中的不变量的已知信息。如果我们最终走向自我修改人工智能或自我修改人工智能生态系统，这可能会成为一个相当尖锐的话题。</p><p>但似乎并没有做太多事情。例如，我找到了一篇 1995 年的中文论文，“S-and T-Invariants in Cyber​​ Net Systems”，作者 Yuan Chongyi， <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C22&amp;q=S-+and+T-invariants+in+cyber+net+systems&amp;btnG=">Google Scholar 页面，PDF 可用</a>，该论文正在研究自修改网络中的不变量（网络的自然扩展） Petri 网），但 Google Scholar 只知道有 4 篇参考文献。</p><p>我想知道人们是否知道更多此类研究的例子（或者目前正在尝试研究这个主题的研究人员或组织）......</p><br/><br/> <a href="https://www.lesswrong.com/posts/sDapsTwvcDvoHe7ga/what-is-known-about-invariants-in-self-modifying-systems#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/sDapsTwvcDvoHe7ga/what-is-known-about-invariants-in-self-modifying-systems<guid ispermalink="false"> sDapsTwvcDvoHe7ga</guid><dc:creator><![CDATA[mishka]]></dc:creator><pubDate> Sat, 02 Dec 2023 05:04:19 GMT</pubDate> </item><item><title><![CDATA[2023 Unofficial LessWrong Census/Survey]]></title><description><![CDATA[Published on December 2, 2023 4:41 AM GMT<br/><br/><p><strong>错误较少的普查非官方的就在这里！您可以通过此链接获取</strong><a href="https://docs.google.com/forms/d/e/1FAIpQLSc_-Te1a4Q-FuNhwwgSGDwVWCHOWppCrWtKaVrhHcujopy5Lg/viewform?usp=sf_link"><strong>。</strong></a></p><p>又到了那个时候了。</p><p>如果您正在阅读这篇文章并认为自己是“LessWronger”，那么您就是目标受众。如果您接受这项调查，我将不胜感激。如果你发帖，如果你评论，如果你潜伏，如果你实际上并没有太多地阅读该网站，但你确实阅读了一堆其他理性主义博客，或者你真的很喜欢 HPMOR，如果你在理性主义 tumblr 上闲逛当天，或者如果这些都不完全适合您，但我可能已经接近了，我认为您很重要，如果您参加这项调查，我将不胜感激。</p><p>不要因为开始参加考试就觉得必须回答所有问题。去年我问人们是否认为这项调查太长，他们总体认为可能有点太长了，然后我添加的问题比删除的问题还要多。该调查的结构使得最快和最普遍适用的问题（一般来说）是在开始时出现的。您可以随时滚动到底部并点击“提交”，但一旦这样做您将无法更改答案。</p><p>这些问题包括之前在 LW 人口普查中提出的历史问题、来自 LW 评论者和我接触到的一些理性主义邻近组织的新问题，以及我好奇的事情。其中包括当我询问有关进行人口普查时，LessWrong 团队成员发给我的一份清单中的问题。</p><p>该调查从现在起至少持续到 2024 年 1 月 1 日。我计划在 1 月 2 日的某个时间结束。</p><p>我不为 LessWrong 工作，据我所知，LessWrong 人口普查的组织者也从来不是为 LessWrong 工作的人。调查结束后，我计划研究这些数据并写<a href="https://www.lesswrong.com/posts/E2koS25u6jajt5uo8/2022-survey-results">一篇像这样的</a>分析文章。</p><p>请记住，您可以通过<a href="https://docs.google.com/forms/d/e/1FAIpQLSc_-Te1a4Q-FuNhwwgSGDwVWCHOWppCrWtKaVrhHcujopy5Lg/viewform?usp=sf_link"><strong>此链接</strong></a><strong>参加调查</strong><strong>。</strong></p><p>曾几何时，有一个传统，如果你参加了调查，你可以在这里评论说你已经这样做了，人们会给你投票，你就会得到业力。</p><br/><br/> <a href="https://www.lesswrong.com/posts/JHeTrWha5PxiPEwBt/2023-unofficial-lesswrong-census-survey#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/JHeTrWha5PxiPEwBt/2023-unofficial-lesswrong-census-survey<guid ispermalink="false"> JHeTrWha5PxiPEwBt</guid><dc:creator><![CDATA[Screwtape]]></dc:creator><pubDate> Sat, 02 Dec 2023 04:41:51 GMT</pubDate></item><item><title><![CDATA[Protecting against sudden capability jumps during training]]></title><description><![CDATA[Published on December 2, 2023 4:22 AM GMT<br/><br/><p> TL;DR：如果法学硕士的能力突然跳跃，并使用不同的测试套件进行测试（例如，可以执行代码或向人类观察者呈现大量文本的测试套件），它可能能够逃脱训练中期。为了防止这种情况发生，我提出了一种分阶段的测试方法，首先使用极其受限的测试套件对模型进行超人能力测试，然后再使用更广泛的测试套件进行测试。</p><h1>失效模式</h1><p>让我们想象一下 GPT-6 突然获得了超人的黑客和操纵技能。在训练期间，会执行一些标准测试来衡量其在各种基准上的性能。一些测试包括在虚拟机上执行代码，其他测试包括生成供人类检查的文本。总共对该模型进行了数千次查询。该模型通过利用测试设置中的漏洞（例如通过勒索人类评估者或在虚拟机中发现漏洞）找到了逃脱的方法，甚至在研究人员注意到它具有超级智能之前。</p><p>这凸显了我担心的一种故障模式：<strong>突然的能力跳跃会导致功能失调且功能强大的人工智能，当使用不同的测试套件进行测试时，它会在实验室注意到它的能力之前找到逃脱的方法。</strong></p><p>出现这种问题的主要原因是人工智能与现实世界有很大的<i>接触面</i>——它有办法影响与其交互的人类和设备。模型越被允许影响世界（无论是通过编写供人类检查的文本，还是在虚拟机上运行代码），模型就越容易接管。我想，如果模型只允许预测 10 个标记的序列而没有其他任何东西，那么它就很难接管。</p><p>理想情况下，实验室可以通过某种方式注意到该模型的能力急剧跃升，而无需给其太多接管机会。万一他们突然出乎意料地与超级智能打交道，希望他们能明智地暂停一下，直到他们确信自己可以安全地继续前进。</p><h1>分阶段测试</h1><p>我认为在前沿模型训练运行期间应该使用分阶段测试。我的意思是<strong>一种测试方法，从极低的表面积测试开始，然后逐渐增加表面积。</strong>这使得我们很容易注意到突然的能力增益，同时降低了模型接管的可能性。</p><p>其他行业也存在类似的做法，新工具在其损害有限的环境中进行测试，然后逐步推广到限制较少的环境中。</p><p>实际上，这可能看起来像：</p><ol><li>从一组测试开始，这些测试最大限度地减少允许模型预测的标记数量以及允许从中采样的标记集。<ol><li>例如，它可能是一组 100 个困难的多项选择题，其中模型实际上只能输出 {A,B,C,D} 之一作为答案，所有其他标记概率都设置为 0。</li></ol></li><li>如果性能高到足以吓到实验室，他们可以在模型造成任何损害之前暂停开发。</li><li>如果性能不够高，不足以吓到实验室，他们可以重复使用限制稍少的测试套件。</li></ol><p>这甚至可能不需要太多额外的工作，因为简单地重新排序现有的测试并添加高测试结果的警报可能就可以达到目的。</p><p>请注意，<strong>这对于假装不是超人的超人法学硕士不起作用</strong>。如果这样的法学硕士要分阶段进行测试，它可能会知道自己的能力不如实际。如果<a href="https://www.lesswrong.com/posts/h7QETH7GMk9HcMnHH/the-no-sandbagging-on-checkable-tasks-hypothesis">“可检查任务上没有沙袋”的假设</a>是正确的，那么我不太担心这一点，因为我们可以使用现有技术来引发超级智能能力。</p><p>另请注意，<strong>这对于超人的法学硕士来说并不适用，</strong>因为即使在极其受限的测试期间或之前，他们也可能能够逃脱。可能存在一些聪明的技巧，例如在 logit 输出数字中编写代码注入，这将非常难以预测和防范。</p><br/><br/> <a href="https://www.lesswrong.com/posts/edutkCwr93stppmNp/protecting-against-sudden-capability-jumps-during-training#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/edutkCwr93stppmNp/protecting-against-sudden-capability-jumps-during-training<guid ispermalink="false"> edutkCwr93stppmNp</guid><dc:creator><![CDATA[nikola]]></dc:creator><pubDate> Sat, 02 Dec 2023 04:22:21 GMT</pubDate> </item><item><title><![CDATA[South Bay Pre-Holiday Gathering]]></title><description><![CDATA[Published on December 2, 2023 3:21 AM GMT<br/><br/><p>伊尔马林之家 (Ilmarin House) 即将举办第三次非结构化假日聚会！会有饼干和简单的小吃；除此之外，这是一顿聚餐，你应该带上你想要的东西（如果有的话）。</p><p>如果您认为一些朋友也会喜欢这个活动，请邀请他们！若能回复，我们将不胜感激。</p><br/><br/> <a href="https://www.lesswrong.com/events/esaDDDkjYDnHrJrLp/south-bay-pre-holiday-gathering#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/events/esaDDDkjYDnHrJrLp/south-bay-pre-holiday-gathering<guid ispermalink="false"> esaDDDkjYDnHrJrLp</guid><dc:creator><![CDATA[IS]]></dc:creator><pubDate> Sat, 02 Dec 2023 03:21:12 GMT</pubDate> </item><item><title><![CDATA[MATS Summer 2023 Postmortem]]></title><description><![CDATA[Published on December 1, 2023 11:29 PM GMT<br/><br/><p> <a href="https://www.matsprogram.org/"><u>ML 对齐和理论学者</u></a>计划（MATS，以前称为 SERI MATS）是一项针对新兴人工智能安全研究人员的教育和研究指导计划。今年夏天，我们举办了第四次MATS项目，60名学者得到了15位研究导师的指导。在这篇文章中，我们解释了该计划的要素，列出了它们背后的一些想法，并评估了我们的影响。</p><h1>概括</h1><p>有关 2023 年夏季计划的主要详细信息：</p><ul><li> MATS 学者的教育程度：<ul><li> 30%的学者是学生。</li><li> 88% 至少拥有学士学位。</li><li> 10% 正在攻读硕士学位。</li><li> 10% 正在攻读博士学位。</li><li> 13%拥有博士学位。</li></ul></li><li>如果没有 MATS，学者们可能会在科技公司工作（41%）、独立提升技能（46%）或在整个夏天独立进行研究（50%）。 （注：这是一个多项选择题。）</li></ul><p>我们的影响评估的主要结论：</p><ul><li> MATS 学者很有可能向朋友或同事推荐 MATS。平均可能性：8.9/10。</li><li> 94% 的学者的导师对他们继续研究的热情评价为 7/10 或更高。</li><li> MATS 学者对他们的导师评价很高。平均评分：8.0/10。<ul><li> 61% 的学者表示，MATS 的价值至少一半来自他们的导师。</li></ul></li><li>学者们表示，在 MATS 之后，与项目开始时相比，他们在成功调整职业方面面临的障碍更少。<ul><li>大多数学者（75%）在项目结束时仍然将他们的发表记录视为成功对齐职业的障碍。</li></ul></li><li> ⅓ 的最终项目涉及评估/演示，⅕ 涉及机械解释性，代表了该群体研究兴趣的很大一部分。</li><li>学者们自我报告研究能力平均有所提高：<ul><li>他们的人工智能安全知识的广度略有增加（在该计划的 10 分制中+1.75）。</li><li>与反事实夏季相比，技术技能得到适度加强（7.2/10，其中 10/10 是“与反事实夏季相比显着提高”）。</li><li>独立迭代研究方向的能力（7.0/10，其中 10/10 表示“显着改进”）和为研究发展变革理论的能力（5.9/10，其中 10/10 表示“实质性发展”）有适度提高）。</li></ul></li><li>典型的学者报告平均建立了 4.5 个专业联系（标准偏差 = 6.2）并会见 5 个潜在的研究合作者（标准偏差 = 6.8）。</li><li> MATS 学者可能会推荐学者支持，即我们的研究/生产力辅导服务。平均响应：7.9/10。<ul><li>处于研究阶段的 60 名学者中有 49 名至少与学者支持专家会面一次。</li><li>在整个项目期间，至少与学者支持会面一次的学者平均花费 3.4 小时与学者支持会面。</li><li>平均学者和中位数学者报告称，他们对收到的学者支持的评价分别为 3705 美元和 750 美元。</li><li>据报告，由于学者支持，学者平均在夏季获得了 22 个高效工作时间。</li></ul></li></ul><p>我们计划对 2023-24 冬季组的 MATS 进行主要更改：</p><ul><li>申请过程中更好的过滤；</li><li>将学者支持的重点转向研究管理；</li><li>为学者提供其他形式的支持，特别是技术支持和专业发展。</li></ul><p>请注意，现在评估 MATS 为最新一批人提供的任何职业福利还为时过早；即将对 MATS 校友在项目体验后 6-12 个月内的职业成果进行全面的后评估。</p><h1>变革理论</h1><p>MATS 通过让学者在现有组织中从事人工智能安全工作、建立新组织或进行独立研究，帮助扩大人工智能安全研究的人才渠道。为此，MATS 为学者提供资金、住房、培训、办公空间、研究援助、交流机会和后勤支持，减少高级研究人员接受学员的障碍。通过指导 MATS 学者，这些高级研究人员还可以从研究援助中受益，并提高他们的指导技能，为他们更有效地监督未来的研究做好准备。请<a href="https://www.lesswrong.com/posts/8vLvpxzpc6ntfBWNo/seri-ml-alignment-theory-scholars-program-2022#Theory_of_change"><u>在此处</u></a>阅读有关我们变革理论的更多信息。进一步扩展我们的变革理论的文章即将推出。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/srup6vfrbmgjh3zzshlq"></p><p> MATS旨在主要从三个维度选拔和培养研究学者：</p><ul><li><strong>深度</strong>：对人工智能安全研究的专业领域有透彻的了解，并有足够的技术能力（例如，机器学习、计算机科学、数学）来开展该领域的新颖研究。</li><li><strong>广度</strong>：广泛熟悉人工智能安全组织和研究议程，拥有来自不同子领域的有用定理和知识的大型“工具箱”，以及进行文献综述的能力。</li><li><strong>品味</strong>：对研究方向和策略的良好判断，包括首先采取哪些步骤、质疑哪些假设、考虑哪些新假设以及何时停止从事某项研究。 </li></ul><figure class="image image_resized" style="width:50.94%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/psu31uwjpsyeyn9ylynw"></figure><h1> MATS 2023 年夏季项目概述</h1><h2>日程概览</h2><p>2023 年夏季的 MATS 项目由三个阶段组成。</p><ol><li><strong>培训阶段：</strong>接受远程培训阶段的学者在讨论小组中完成了<a href="https://aisafetyfundamentals.com/alignment-201-curriculum"><u>Alignment 201</u></a> ，并学习了导师分配的其他教育材料。</li><li><strong>研究阶段：</strong>在伯克利研究阶段，学者们进行研究，提交书面的“学者研究计划”（SRP），开展项目，与湾区人工智能安全社区建立联系，与合作者建立联系并合作，并向同行和专业研究人员的观众。</li><li><strong>扩展阶段：</strong>许多学者申请了伦敦和伯克利的扩展阶段，他们在 MATS 的支持下继续进行研究。 </li></ol><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/klix3pwxa6vfnmymlom4"></p><h2>计划要素</h2><p>虽然指导仍然是 MATS 的核心，但我们选择了额外的计划元素来涵盖其他形式的学习和技能提升。我们根据技能提升/支持重点是技术级别还是元级别以及形式是一对一还是一对多对这些计划元素进行分类。 </p><figure class="image image_resized" style="width:52.68%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/gczi0b5zdiuldemdmfcn"></figure><h3>学者支持</h3><p>MATS 的学者支持团队旨在通过持续的、定制的支持来补充指导，从而提高 MATS 研究和推广阶段的学者成果。</p><p><strong>为何获得学者支持？</strong></p><p>确定导师未涵盖的支持形式有可能在提高计划的整体影响方面发挥重要作用。根据在 MATS 之前迭代中与学者的观察和对话，我们认为学者的支持会增加显着的附加价值，原因如下：</p><ol><li><strong>导师有时间限制。</strong>导师通常只有足够的时间（例如每周约 1-2 小时）与学者讨论其研究的技术组成部分。学者支持可以帮助学者明确哪些形式的导师支持对他们最有价值，然后提供导师在有限的时间内无法获得的其他形式的支持，从而实现更有效的导师互动。</li><li><strong>学者有时不愿意寻求导师的支持。</strong>由于导师会评估受训者在 MATS 内的进展情况（也可能是向外部资助者），因此学者们可能会不愿意揭露他们正在经历的问题。为了解决这个问题，学者支持与包括导师在内的评估者的支持 <a href="https://www.lesswrong.com/posts/ehLR9HeXB5TMp9Y4v/air-gapping-evaluation-and-support"><u>存在差距</u></a>。</li><li><strong>导师可能不适合为技术研究提供不太专业的支持，例如职业指导或生产力建议。</strong>相比之下，学者支持可以聘请精通这些领域的教练。</li></ol><p><strong>学者支持重点领域的示例</strong></p><p>学者支持以不同的方式帮助不同的学者，但以下非详尽列表代表了 1-1 学者支持会议中通常讨论的内容：</p><ul><li><strong>研究项目开发和管理：</strong>帮助确定可能的研究方向、决定研究方向并完成研究项目。</li><li><strong>提高生产力：</strong>寻找方法让学者每天（可持续地）花更多时间进行研究或提高研究时间的质量。</li><li><strong>职业指导：</strong>确定不同的职业选择，确定做出这些决定时需要考虑的关键因素，并增加职业成功的机会（例如，通过网络和技能发展）。</li><li><strong>改善与导师和合作者的沟通。</strong></li></ul><h3>工作坊</h3><p>我们举办了九场研讨会，主题如下：</p><ul><li>症结分解；</li><li>研究变革理论；</li><li>里程碑： <a href="https://docs.google.com/document/d/1fQwy2btcWn3XRQkgu45kKnPPHMVQs28QHpaNtDCfXQY/edit"><u>学者研究计划</u></a>；</li><li> <a href="https://forum.effectivealtruism.org/posts/edgvFNzHFQoMv3KsL/personal-health-is-instrumental-to-being-effective"><u>预防和管理倦怠</u></a>；</li><li>拨款申请+预算；</li><li>使用<a href="https://github.com/socketteer/loom"><u>Loom</u></a>探索基本模型；</li><li>研究合作者快速会议；</li><li>里程碑： <a href="https://docs.google.com/document/d/1SB_vl6pGuSO7qidkZ8fIKPeH7fZIC8mvXzxicFjGyrE/edit"><u>学者座谈会</u></a>；</li><li>职业规划和离职。</li></ul><p>此外，学者支持人员还举办了几次开放办公时间会议，以研讨学者的写作和演示。</p><h3>社交活动</h3><p>除了合作者快速会议研讨会之外，我们还提供了一些社交活动：</p><ul><li>与<a href="https://far.ai/labs/"><u>FAR 实验室</u></a>成员共进晚餐；</li><li>与<a href="https://www.constellation.org/"><u>星座</u></a>成员共进晚餐；</li><li>招聘会有 12 个组织和独立研究人员参加；</li><li>湾区人工智能安全社区的许多成员参加了三场聚会。</li></ul><h3>研讨会</h3><p>我们举办了 23 场研讨会，演讲嘉宾包括：Buck Shlegeris、Rick Korzekwa、Tom Davidson、Tamsin Leake、Victoria Krakovna、Daniel Paleka、Jeffrey Ladish、Adam Gleave、Steven Byrnes、Daniel Filan、Tom Everitt、William Saunders、Lennart Heim、Usman Anwar、 Neel Nanda、Dylan Hadfield-Menell、Ryan Greenblatt 和 Evan Hubinger、Mauricio Baker、Nora Ammann、Anthony DiGiovanni、Marius Hobbhahn、Paul Colognese 和 Arun Jose、Ajeya Cotra。</p><h3>社区健康</h3><p>学者们可以与社区经理联系，讨论社区健康问题，例如与另一位学者或其导师的冲突，并提供情感支持和转介心理健康资源。我们认为，冒名顶替综合症等心理健康问题和多动症等未确诊的疾病可能会成为进入人工智能安全领域的障碍，因此 MATS 等项目在这些领域提供支持非常重要。我们的目标是为学者提供技能和资源，让他们在离开 MATS 后保持积极性并可持续地工作。</p><p>我们认为，人际冲突、心理健康问题和缺乏联系会导致消极的工作环境，减少学者可以分配给研究的认知资源，并阻碍富有成效的研究合作，从而抑制研究<a href="https://forum.effectivealtruism.org/posts/edgvFNzHFQoMv3KsL/personal-health-is-instrumental-to-being-effective"><u>生产力</u></a>。即使不寻求社区健康支持的学者也能从这个安全网的存在中受益（参见下面<a href="https://docs.google.com/document/d/1vgqW_1FIKP4prZXQXa2UIteI7-zUL4klspJjdE2tWCw/edit#heading=h.mbcjjw5l0ho5"><u>的评估计划要素</u></a>）。与学者支持一样，MATS 等项目必须允许 <a href="https://www.lesswrong.com/posts/ehLR9HeXB5TMp9Y4v/air-gapping-evaluation-and-support"><u>评估和社区健康之间存在差距</u></a>，以激励学者在需要时寻求帮助。</p><p>社区经理还组织了社交活动，以促进群体内部的联系，包括为来自代表性不足的背景的学者举办的四次郊游。</p><h2>导师遴选</h2><p>在为 MATS 选择导师时，我们的目标主要是支持那些很有可能通过研究降低人工智能灾难性风险的导师，同时采取“组合方法”进行风险管理。我们的目标是支持多样化的“研究赌注”，即使某些组成研究议程被证明不可行，这些赌注也可能为人工智能安全带来一些好处，并提供可能有助于潜在<a href="https://en.wikipedia.org/wiki/Paradigm_shift"><u>范式转变</u></a>的“探索价值”。</p><p>我们的导师选择流程要求潜在导师提交一份意向表，然后由 MATS 执行人员进行审核。在决定支持哪些导师时，我们主要考虑：</p><ol><li>这项研究议程可以在多大程度上减少人工智能带来的灾难性风险？</li><li>支持这项研究议程会产生多少“探索价值”？</li><li>此人有多少研究和指导经验？</li><li>如果这个人没有得到 MATS 的支持，他的反事实会是什么？</li><li>支持这个人及其学者如何影响更广泛的人工智能安全生态系统中的思想和人才的发展？</li></ol><p>由于 MATS 在 2023 年夏季资金有限，因此我们对该项目的学者数量也存在财务限制。因此，学者“名额”根据 MA​​TS 执行官对每个导师的边际价值感分配给导师（直至其自我表达的上限）。例如，可能值得支持一位经验丰富的导师，其自我表达的上限为四名学者，有四个学者名额，然后再支持一位经验不足的导师，有一个学者名额，无论其上限如何。相反，与一位学者一起支持一位新导师可能比与第八位学者一起支持一位经验丰富的导师具有更高的边际价值。</p><p>在 2023 年夏季项目的 15 名导师中，有 10 名从 2022-23 年冬季项目回归：Alex Turner、Dan Hendrycks、Evan Hubinger、John Wentworth、Lee Sharkey、Jesse Clifton、Neel Nanda、Owain Evans、Victoria Krakovna 和 Vivek赫巴尔。今年夏天我们迎来了 5 位新导师：Ethan Perez、Janus、Nicholas Kees Dupuis、Jeffrey Ladish 和 Claudia Shi。</p><p>这些导师代表了十几个研究议程：</p><ul><li>调整语言模型</li><li><a href="https://www.lesswrong.com/tag/agent-foundations"><u>代理基金会</u></a></li><li><a href="https://www.lesswrong.com/tag/consequentialism"><u>结果主义</u></a>认知和深层约束</li><li><a href="https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism"><u>电子人主义</u></a></li><li><a href="https://www.lesswrong.com/tag/deceptive-alignment"><u>欺骗性人工智能</u></a></li><li><a href="https://www.lesswrong.com/tag/ai-evaluations"><u>评估危险能力</u></a></li><li><a href="https://en.wikipedia.org/wiki/Interdisciplinarity"><u>跨学科</u></a>人工智能安全</li><li><a href="https://www.lesswrong.com/tag/interpretability-ml-and-ai"><u>机械解释性</u></a></li><li><a href="https://www.lesswrong.com/tag/multipolar-scenarios"><u>多极人工智能安全</u></a></li><li>语言模型中的<a href="https://www.lesswrong.com/tag/power-seeking-ai"><u>权力寻求</u></a></li><li><a href="https://www.lesswrong.com/tag/shard-theory"><u>碎片理论</u></a></li><li>了解人工智能黑客</li></ul><h2>学者选拔</h2><p>我们最初的学者申请流程竞争非常激烈。在 461 名申请者中，有 69 名被接受进入培训阶段（接受率 ≈ 15%）。导师之间的接受率存在显着差异（0% 到 31% 之间）。导师通常会选择通过严格的问题和任务来筛选申请人。 <span class="footnote-reference" role="doc-noteref" id="fnref2niy7evweco"><sup><a href="#fn2niy7evweco">[1]</a></sup></span></p><p>为什么要采用如此困难的申请流程？首先，我们认为未来学者的预期影响力的分布是长尾的，因此 MATS 的大部分预期影响力可归因于培养最有前途的学者的人才。 </p><figure class="image image_resized" style="width:47.84%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/qng5orgyn5u1rqaiisex"></figure><p>其次，我们主要是在导师时间上遇到瓶颈，所以我们不可能接受每一个好的候选人。由于这两个原因，我们的申请流程必须在人才尾部实现解决方案。根据我们的<a href="https://www.lesswrong.com/posts/8vLvpxzpc6ntfBWNo/seri-ml-alignment-theory-scholars-program-2022#Theory_of_change"><u>变革理论</u></a>：</p><p>我们相信我们的限制是指导时间。这意味着我们希望有强大的过滤机制（例如候选人选择问题）以确保每个申请人都适合每个导师。我们宁愿冒拒绝强参与者的风险，也不愿接纳弱参与者。</p><p>确实，一位导师没有收到任何符合他们标准的申请，因此他们没有接受任何学者。</p><p>我们严格的申请流程可以减少申请人质量评估中的噪音，即使这样做的代价是阻止一些潜在有前途的候选人申请。额外的过滤器减少了从培训阶段（两名导师）进入研究阶段的学者数量，然后在扩展阶段之前再次减少。 </p><figure class="image image_resized" style="width:38.06%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/tmibmqxlrpzmxmbvbze5" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/hsq1bwnkzrako3m45vcw 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/isyklkfzwzeyhhxwwt8m 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/fpkj5ns3996vzhwziwgh 250w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/wj5m8v07rkw3del0lqk2 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/shcgfb79noh6ovkczhhm 410w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/eq77mnop2fx1bo8gt1tn 490w"></figure><p>共有 60 名学者参与研究阶段：50 名现场学者和 10 名远程学者。</p><h3>学者的教育程度</h3><p>该群体包括各种教育和就业背景。 37%的学者最多拥有学士学位或以下学位，40%的学者最多拥有硕士学位或在读硕士，23%的学者拥有博士学位或在读博士。大约三分之一的学者是学生。 </p><figure class="image image_resized" style="width:70.24%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/u25u6qwh08zvysy355kw"></figure><p>请注意，由于我们要求学者的<i>最高</i>教育程度，因此该图中的类别是相互排斥的。总体而言，进入人工智能安全领域的高水平学术和工程人才给我们留下了深刻的印象，但我们仍致力于扩大对经验丰富的研究人员和工程师的接触。</p><h3>反事实的夏天</h3><p>根据他们的自我报告，如果这些学者没有参加 MATS，他们的反事实暑假可能会涉及在科技公司工作、独立提高技能或独立进行研究。 </p><figure class="image image_resized" style="width:69.43%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/p1fc4dak9irsmawocrra"></figure><p> 13 名学者表示，如果不参加 MATS，他们可能会进行指导性研究，其中 10 名是学生，6 名正在攻读研究生学位。受访者详细阐述了他们的替代夏季计划，其中一些人提到了人工智能安全领域之外的研究指导选项或结构较少、指导较少的技能提升：</p><ul><li> “我正在写我的博士论文（纯数学，可能与对齐无关）。”</li><li> “如果没有 MATS，我不太可能从事如此有影响力的项目，或者处于如此陡峭的 L&amp;D 曲线上。”</li><li> “我会和同一个导师一起实习，但只是远程实习。所以我会做同样的事情，但环境要糟糕得多。不确定我是否会很有成效，或者取得什么成就。”</li><li> “我可能会去申请、提高技能、和朋友一起工作。总的来说，我的工作量会少很多。”</li><li> “我将以非主导角色支持机器学习能力研究。”</li></ul><p>共有 17 名学者填写了一项可选调查，要求他们将反事实暑假的价值与他们从 MATS 中获得的价值进行比较。九人表示，如果没有 MATS，他们的时间会“不太有用”，八人表示，他们的时间会“不太有用”。</p><h2>培训阶段（6月5日-6月30日）</h2><p>共有69名学者进入培训阶段。在指定助教的四场会议上，学者们完成了人工智能安全基础知识<a href="https://aisafetyfundamentals.com/alignment-201-curriculum"><u>对齐 201 课程</u></a>。这些讨论组使学者们对参与同行学者的研究、访问演讲者的演讲以及人工智能安全生态系统中不同组织的工作有了必要的广泛熟悉。然而，大约25%的学者没有参加任何一个讨论组，只有大约15%的学者参加了所有四个讨论组的会议。这可能是因为许多导师在其学科领域分配了自己的培训课程（例如阅读清单），并且一些导师明确告诉学者不要优先考虑对齐 201。</p><p>部分导师提前选择在训练阶段结束后进行一轮额外筛选，因此只有60名学者继续进入研究阶段。 <span class="footnote-reference" role="doc-noteref" id="fnrefvp0h93gzvk"><sup><a href="#fnvp0h93gzvk">[2]</a></sup></span></p><h2>研究阶段（7月10日 - 9月1日）</h2><p>在研究阶段，学者们在导师的指导下开展人工智能安全研究。大多数学者在加利福尼亚州伯克利毗邻<a href="https://www.constellation.org/"><u>Constellation 的</u></a>办公室里亲自工作，这使得 Constellation 以外的导师和研讨会演讲者可以轻松过境。</p><h3>指导风格</h3><p>导师们采用不同的方法来设定研究方向和指导项目。根据一项学者调查，大约 1/4 的学者对其研究方向拥有“完全的创造性控制”，大约 1/4 的学者从名单中挑选或被分配一个项目，剩下的 1/2 介于两者之间。</p><p>在参与项目底层实施细节方面，指导风格也有所不同。根据对学者的调查，导师大致呈双峰分布，大约一半的学者表示，他们的导师只讨论研究项目的高层细节，另一半学者表示，他们的导师更多地参与低层细节。研究层面的实施细节。 </p><figure class="image image_resized" style="width:70.91%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/kxcbn1d3qvmmfikg9eoz"></figure><p>我们还注意到导师的双峰分布基于每周与学者交流的时间（但是，这两个指标与导师无关）。 </p><figure class="image image_resized" style="width:70.67%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/bw5qganpngq7hc8t1o9r"></figure><p>一些来自不同流派的学者在项目上进行了合作。有时，学者们会转而与更适合他们兴趣和需求的导师一起工作。</p><h3>学者支持</h3><p>我们的学者支持团队由五位研究/生产力教练组成，他们在研究策略、职业规划、人际沟通和研究技能提升方面提供帮助（参见上面的<a href="https://docs.google.com/document/d/1vgqW_1FIKP4prZXQXa2UIteI7-zUL4klspJjdE2tWCw/edit#heading=h.d8f3mdy3o2th"><u>计划要素</u></a>）。</p><ul><li>共有 49 名学者在研究阶段预订了学者支持会议，其中 35 名学者多次使用学者支持。</li><li>在整个项目期间，至少与学者支持会面一次的学者平均花费 3.4 小时与学者支持会面。</li><li>学者们总共花费了 160 个小时参加了 197 场学者支持会议。</li><li>十位学者占所有学者支持时间的一半。 </li></ul><figure class="image image_resized" style="width:69.75%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/uxllwospe38xmermwkib"></figure><p>使用学者支持的 49 名学者中有 28 名提供了书面反馈。这些学者报告发现以下内容特别有用：</p><ul><li>职业规划和建议（28%）；</li><li>任务优先级（25%）；</li><li>一般问题解决（14%）；</li><li>被追究责任（10%）；</li><li>拖延症建模工具（10%）；</li><li> <a href="https://www.lesswrong.com/posts/kvLPC5YWgSujcHSkY/how-to-play-a-support-role-in-research-conversations"><u>橡皮鸭</u></a>(7%)；</li><li>克服拖延症（7%）</li><li>提高与导师和同事的沟通技巧（7%）；</li><li>有用的提问（7%）。</li></ul><h3>研究里程碑</h3><p>研究阶段进行到一半时，每位学者都需要提交一份学者研究计划（SRP）。在他们的 SRP 中，学者们被要求概述人工智能<a href="https://www.lesswrong.com/tag/threat-models"><u>威胁模型</u></a>或推动他们研究的<a href="https://arxiv.org/abs/2206.05862"><u>风险因素</u></a>、解决该威胁模型<a href="https://en.wikipedia.org/wiki/Theory_of_change"><u>的变革理论</u></a>，以及制定该变革理论的项目的<a href="https://en.wikipedia.org/wiki/SMART_criteria">SMART</a>计划。 MATS 团队的一名成员和七名校友根据提供的 <a href="https://docs.google.com/document/d/1fQwy2btcWn3XRQkgu45kKnPPHMVQs28QHpaNtDCfXQY/edit"><u>评分标准</u></a>对 SRP 进行了评分，以帮助告知扩展阶段的接受决定（见<a href="https://docs.google.com/document/d/1vgqW_1FIKP4prZXQXa2UIteI7-zUL4klspJjdE2tWCw/edit#heading=h.lujivdy8efi4"><u>下文</u></a>）并为学者提供建设性反馈。 </p><figure class="image image_resized" style="width:44.94%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/nffyurqwksgj7wqzmtia" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/xji7hx8eh0mbe7xavnqb 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/wtdngl6sutwq3hkfcvkj 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/tnljbcj1svmurah5hs8w 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/rbxhpjdkmqkzlffqocrv 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/kwytqiyv8eqgtlsc6zm4 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/i5zlme9xikfuwxob6vvi 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/dtgqcm11xql90rd8kpux 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/dixfaddh4cujlmwgd5a8 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ivomn6dzles1c1tw32wd 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/mlbmmqkurxconppsyypd 1424w"></figure><p>我们需要学者研究计划的三个主要原因：</p><ol><li>培养学者为目标导向的研究策略做出贡献的能力；</li><li>评估学者是否接受扩展阶段；</li><li>使学者更容易撰写后续资助提案。</li></ol><p>许多学者选择在资助申请中使用其 SRP 的组成部分，向<a href="https://funds.effectivealtruism.org/funds/far-future"><u>长期未来基金</u></a>(LTFF) 申请 MATS 后的资助支持。 LTFF 资助者托马斯·拉森 (Thomas Larsen) 举办了一次研讨会，在研讨会上他回答了 MATS 学者有关 LTFF <a href="https://forum.effectivealtruism.org/posts/7RrjXQhGgAJiDLWYR/what-does-a-marginal-grant-at-ltff-look-like-funding"><u>决策过程</u></a>和<a href="https://forum.effectivealtruism.org/posts/PAco5oG579k2qzrh9/ltff-and-eaif-are-unusually-funding-constrained-right-now"><u>资金限制</u></a>的问题。</p><p>研究阶段以为期一天的研讨会结束，学者们在研讨会上向同行和伯克利人工智能安全社区的成员就他们的研究项目进行了 10 分钟的演讲。</p><h3>讲习班、研讨会、社交活动</h3><p>我们举办了 23 场邀请演讲嘉宾的研讨会、九场培养学者研究能力的研讨会，以及每周的社交和社交活动。我们还每周举行闪电演讲会议，许多学者发表了非正式的、五分钟的研究报告。在我们的招聘会之前，有 12 家组织和独立研究人员参加，24 名学者填写了一份调查，了解他们最希望在活动中看到哪些组织。他们的回答提供了有抱负的人工智能安全研究人员当前职业兴趣的概况。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/rjqnxjfozzhkrqkwfcmj"></p><h3>社区健康</h3><p>大约 15% 的学者负责与社区经理的大部分会议，大约一半的学者只与社区经理会面一次。</p><p>学者们报告了社区经理如何在以下方面提供帮助：</p><ul><li>情感支持;</li><li>探望我担心的人；</li><li>讨论冲突或不舒服的互动；</li><li>讨论该计划如何对我来说更好；</li><li>医疗帮助（转诊至诊所、帮助治疗疾病/受伤）。 </li></ul><figure class="image image_resized" style="width:76.12%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/tzheowwao5qymskvp6oe"></figure><h2>延长阶段（9月18日至1月1日）</h2><p>研究阶段结束后，一些学者申请进入推广阶段。扩展阶段旨在支持学者们在导师和 MATS 在研究阶段提供的结构中获得更大的自主权来开展他们的研究项目。</p><p> MATS 执行团队主要根据导师的认可、SRP 成绩以及他们是否为自己的研究获得独立资助来接受学者进入扩展阶段。来自外部组织（通常是 LTFF 或开放慈善事业）的资金是这一过程的重要投入，因为它提供了对学者研究质量的外部评估。在 33 名申请的学者中，25 名被录取进入扩展阶段（录取率：76%）。</p><p>共有 16 名学者参加<a href="https://safeai.org.uk/"><u>伦敦安全人工智能倡议 (LISA)</u></a>为期四个月的扩展阶段，其中两名来自<a href="https://far.ai/labs/"><u>FAR 实验室</u></a>在伯克利继续学习，七名学者正在远程工作。我们还为学者提供了在布拉格<a href="https://fixedpoint.house/"><u>固定点</u></a>工作的选择。</p><p>在延期期间，我们期望学者们将他们的研究项目正式化为他们的第一份出版物，并开始规划他们未来的职业方向。为了在这方面为他们提供支持，我们继续提供日常生产力支持（例如，每日站立会议、学者支持调试、1-1 职业指导），并且我们举办了各种研讨会、讲习班和社交活动，特别是面向 LISA 办公室的学者。这一切都是为了让学者们做好准备，从 MATS 项目的支持环境中过渡出来，通过经常提醒他们进一步制定长期计划，并建立新的联系来帮助他们推进这些计划。一直以来，我们都期望学者能够得到导师的持续支持，尽管在大多数情况下频率会降低。</p><h1> 2023 年夏季 MATS 评估</h1><p>在本节中，我们概述了学者们如何评价该计划的不同要素以及我们如何评估我们的影响。</p><h2>评估计划元素</h2><h3>对齐201</h3><p>学者们报告了完成<a href="https://course.aisafetyfundamentals.com/alignment-201">Alignment 201 课程的</a>广泛价值分配。平均评分为 6.8/10，<a href="https://www.qualtrics.com/experience-management/customer/net-promoter-score/">净推荐值为</a>-18。 </p><figure class="image image_resized" style="width:71.72%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/pk5nhrqbpuxlzke1wgak"></figure><p>在书面反馈中，多位学者将课程的大部分价值归因于辅导员的经验和洞察力。进入该课程的学者们有着不同的背景和学习偏好：一位受访者表示，他们小组的对话没有他们希望的那么先进；另一位则提到希望学习节奏较慢的课程。一位受访者赞赏他们的辅导员建议的文章；另一位更喜欢学术论文和正式论文。一位学者提到，要努力平衡课程与导师的竞争性要求。</p><h3>总体方案</h3><p>总体而言，学者们在回答“从 1 到 10 的范围内，您向朋友或同事推荐 MATS 的可能性有多大”这一问题时，对研究阶段的评价相当高。 <span class="footnote-reference" role="doc-noteref" id="fnrefnsczgjuthnr"><sup><a href="#fnnsczgjuthnr">[3]</a></sup></span>平均回应率为 8.9/10，没有人报告低于 6/10。<a href="https://www.qualtrics.com/experience-management/customer/net-promoter-score/">净推荐</a>值为 69。 </p><figure class="image image_resized" style="width:75.19%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/zmzndsy4dlfggpjubhjv"></figure><h3>指导的价值</h3><p>总体而言，导师的评价很高，平均评分为 8.0/10，<a href="https://www.qualtrics.com/experience-management/customer/net-promoter-score/">净推荐分数</a>为 29。61% 的学者表示，MATS 的价值至少有一半来自他们的导师。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/vxzr4itr8yloxu8s4uei" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/qbhl6tskvtznddj5oxrh 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ygidoqbafyk6ljbpnjpj 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/saguqu5b2ikuvuen47g0 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/rpkg2sxlbese75ik4vkm 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/uec4crmh8bbooni6llv6 1100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ismpi1ohyakuzxa9q7ni 1320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ssk6wk9zvn7i8ohxp7jh 1540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ah1gajhkuki90spn4tey 1760w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ws62tofuflqbqasuujk6 1980w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ozzhdigdrcpqapravnc3 2176w"></figure><p>鉴于导师学者评级的负偏分布，学者评级导师对 MATS 价值的贡献如此多样化可能会令人惊讶。造成这种差异的原因是一些学者对其他价值来源给予了较高的重视；即接触该群体和更广泛的伯克利研究社区。</p><p>学者们详细阐述了导师使他们受益的方式：</p><ul><li> <strong>90%</strong> — “我认为 [MATS] 的 90% 以上的效果是通过获得 [导师] 时间并与他讨论我的研究，注意到对各种事情的轻微误解。”</li><li> <strong>70%</strong> —“[我的导师]给了我很多时间，并且很好地传授了他的很多思考研究的思维过程。他向我介绍了几个与我进行过宝贵会面的人。我想，如果我没有受到[我的导师]研究品味的引导，我可能会从事前景黯淡得多的事情。”</li><li> <strong>65%</strong> —“从高级线性代数到一般研究方向和信息危害问题，[我们的导师]对我们的研究非常出色。”</li><li> <strong>50%</strong> —“[我的导师]花了很多时间与我们讨论我们的研究，并就方向提出了很好的建议。他以各种方式为我们解除了障碍，例如获得更多模型或大量计算预算。他让我们认识了很多伟大的人，其中一些人成为了合作者。他是一位非常鼓舞人心的合作导师。”</li><li> <strong>40%</strong> —“从高级线性代数到一般研究方向和信息危害问题，[我的导师]对我们的研究非常出色。”</li><li> <strong>20%</strong> —“导师向我们（团队）介绍了一些志同道合的人，监督了这个项目（但大多数人都在倾听，没有干预），还审阅了我们的论文并组织了一次外部评审。”</li><li> <strong>10%</strong> —“提出了我不会想出的有趣的想法/反对意见。”</li></ul><p>值得注意的是，这些学者中的许多人将 MATS 的价值归因于他们的导师的比例很低，但仍然对他们的导师给予相当积极的评价。</p><p>在控制了学者对其导师的评分后，将 MATS 的更多价值归因于导师与以下因素相关：</p><ul><li>报告说，如果没有 MATS，他们整个夏天都会在联盟组织工作，这与事实相反；</li><li>在项目开始时报告出版记录是一个职业障碍，但在项目结束时却不是。</li></ul><p>这表明，与直接指导相比，那些已经与联盟领域有一定联系的学者，例如通过之前的实习或培训计划，从与伯克利社区及其同行的联系中获得的价值较小。它还表明，导师对于在整个项目中成功发表研究成果的学者来说尤其有价值。</p><p>将 MATS 的价值归因于指导较少与以下因素相关：</p><ul><li>报告发展变革理论的能力得到提高；</li><li>报告由于学者支持辅导而提高了工作效率。</li></ul><p>这表明，学者支持和其他旨在促进变革理论思维的计划要素是学者们的两个重要的非导师价值来源。</p><h3>学者支持的价值</h3><p><strong>总体评价</strong></p><p>我们询问了至少参加过一次学者支持会议的学者，“按照 1 到 10 的评分标准，您向未来的学者推荐学者支持的可能性有多大？”平均反应为 7.9/10，<a href="https://www.qualtrics.com/experience-management/customer/net-promoter-score">净推荐分数</a>为 28。 </p><figure class="image image_resized" style="width:70.28%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/rqke77gqvu1g6525jbir"></figure><p><strong>以指导支持为基准进行比较</strong></p><p>由于学者支持人员的聘用是因为他们能够以各种方式熟练地指导和支持学者，因此我们通过询问学者来检查这一点：“如果您的导师有时间的话，他们可以提供多少学者支持价值？”得到的答复是：</p><ul><li>几乎没有任何价值 - 35%</li><li>部分价值 - 50%</li><li>几乎所有价值 - 15%</li></ul><p>我们还询问了学者，如果他们提出要求，他们是否认为导师会给他们更多的支持时间； 55% 的人表示“可能不会”或“绝对不会”。这两个回应支持了我们关于学者支持价值的理论，即：</p><ul><li>在某些相关领域，专业教练可以提供比许多导师更好的支持；</li><li>导师有时间限制。</li></ul><p><strong>授予同等估值</strong></p><p>我们询问了至少参加过一次学者支持会议的学者，“假设您获得了一笔资助，而不是在 MATS 期间接受 1-1 次学者支持会议，那么您需要获得多少资金才能在资助和辅导之间保持中立？ ” <span class="footnote-reference" role="doc-noteref" id="fnrefhdw3lym1fyo"><sup><a href="#fnhdw3lym1fyo">[4]</a></sup></span>平均响应和中位数响应分别为 3705 美元和 750 美元。回复 40,000 美元的学者证实这个数字不是拼写错误，并引用了“优先顺序、项目选择、协调导航和一般人工智能景观、职业建议、困难期间的支持、针对特定会议和项目的单独定制建议”的支持。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/f4obyvjblzwcaed53gdf"></p><p><strong>获得生产时间</strong></p><p>我们询问了至少参加过一次学者支持会议的学者，“在过去 8 周内，您估计由于您的学者支持会议，您的工作效率提高了多少个小时？”平均反应时间和中位反应时间分别为 22 小时和 8 小时。回复总数为 658 个小时的生产时间。</p><h3> Workshops &amp; Seminars</h3><p>学者们报告了参加研讨会和社交活动的价值。请注意，有些活动的受访者很少，因为我们通过可选调查收集了这些反馈。 10/10 是我们规模的一个高标准，代表着学者计划的重大更新。 </p><figure class="image image_resized" style="width:69.86%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/lfewckjuinmojngzjnli"></figure><p>学者们按照同样的 10 分制对外部演讲者事件进行评分。在 23 场研讨会中，11 场为面对面研讨会，11 场为远程研讨会，1 场为混合研讨会。现场研讨会的评分比远程研讨会高 0.9 分 (p = 0.0088)。 </p><figure class="image image_resized" style="width:70.33%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/somf49ymrg6ewflu2pgu"></figure><p>在其他条件相同的情况下，我们会选择现场研讨会而不是远程研讨会，但对这些形式的价值的分析因哪些研究人员恰好居住在湾区以及学者如何自我选择参加讲座而变得混乱。几位学者举办了自己的研讨会，即使与经验丰富的研究人员举办的研讨会相比，这些研讨会也得到了同行的好评。</p><h3>社区健康</h3><p>尽管许多学者没有使用社区健康支持，但少数学者受益匪浅。为了调查这些好处，我们向学者们询问了两个与我们评估学者支持相同的问题，以及一个关于他们的福祉的问题。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/ewbughz2oiqgsib1ixsx"></p><p>平均时数：0 小时</p><p>总时数：202小时</p><p>心理健康水平中位数提高：2%</p><p>这些图表不包括一位学者，该学者报告称，由于社区健康支持，心理健康状况提高了 1000%。学者们提供了更多细节：</p><ul><li> “它帮助我减轻了对人际关系问题的焦虑。”</li><li> “更快乐、更可持续、更专注、更少内疚。”</li><li> “在节目中，有两次我对某些事情感到有点害怕；在这两种情况下，[社区经理] 都可以讨论这个问题，非常友善和支持，并帮助我让事情变得更好。”</li><li> “一般来说，当你离开家时，以及可能在你人生中职业生涯的决定性时刻，创造一个支持性的环境对我来说非常重要。”</li></ul><p>一些学者提到，他们没有要求社区卫生支持，但他们很高兴如果他们需要的话，这个安全网已经到位：</p><ul><li> “很高兴知道如果发生什么事我可以去找人。”</li><li> “我并没有真正与社区健康部门互动，但我认为存在着我想要的反事实世界。”</li><li> “我用得不多，但很高兴它在那里。”</li><li> “我没有太多利用社区健康服务，但我很感激它的存在，以防我可能需要它。”</li></ul><h2>评估结果</h2><h3>研究里程碑</h3><p><strong>学者研究计划</strong></p><p>学者研究计划是研究阶段两个评估里程碑中的第一个。 SRP 根据<a href="https://docs.google.com/document/d/1fQwy2btcWn3XRQkgu45kKnPPHMVQs28QHpaNtDCfXQY/edit#heading=h.ozvm8udh0z0y"><u>此标准</u></a>进行分级。平均成绩为 74/100。学者们在 SRP 的威胁模型和变革理论部分往往失分最多；他们在阐述研究计划的部分表现出了更强的表现。</p><p>重要的是，一些学者忽视了SRP，因为他们不打算申请延期阶段，或者因为他们已经获得了资金，并且没有预期SRP在他们的延期阶段决定中发挥重要作用。一些导师鼓励他们的学者降低 SRP 的优先级，转而专注于他们的研究。</p><p><strong>座谈会发言</strong></p><p>研讨会演讲是研究阶段的第二个里程碑。项目在这些类别中的分布如下。请注意，并非所有学者的工作都会出席研讨会，有些项目属于多个类别。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/snfbmj3ukwt4kbbpo8mw"></p><p>研讨会演讲得到了三个维度的同行评审：“什么”（50 分）； “为什么”（30分）；和“风格”（20 分）。完整的标题可以<a href="https://docs.google.com/document/d/1SB_vl6pGuSO7qidkZ8fIKPeH7fZIC8mvXzxicFjGyrE/edit#heading=h.ozvm8udh0z0y"><u>在这里</u></a>找到。平均成绩为86/100。</p><h3>研究能力</h3><p>使用上面解释的“深度、广度、品味”框架，我们评估了学者们在项目期间在这些维度上提高了研究技能的程度。</p><p><strong>研究能力的深度</strong></p><p>因为我们没有在项目前询问有关研究技能深度的调查问题，所以我们在项目结束时要求学者直接评价他们在所选研究方向内加强了多少技术技能。 1/10 的评分代表“与我的反事实夏天相比没有任何进步；” 10/10 的评分代表“与我的反事实夏天相比，有了显着的进步”。平均评分为 7.2/10。 </p><figure class="image image_resized" style="width:84.58%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/e9tlsh6pe4axayao52tx"></figure><p>受访者详细阐述了他们的技术技能的改进：</p><ul><li> “我从非常基本的机器学习技能发展到了合理的研究技能。”</li><li> “学习了一系列在机甲解释中找出特定事物的策略和技术。还更好地了解了要问什么问题、证明标准等。”</li><li> “更快地进行实验，识别并消除瓶颈。”</li><li> “我在 MATS 中提高了自己的技能，进行真正的研究特别有价值，因为这意味着我不必尝试猜测哪些技能对研究很重要，我只是在做研究，而技能为此需要的是我改进的那些。因此，与我的夏天相比，MATS 更有针对性，也更加激烈和激励。”</li></ul><p><strong>知识广度</strong></p><p>为了评估知识的广度，我们要求学者在研究阶段开始和结束时按照从 1 到 10 的等级对他们对主要联盟组织的研究议程的理解进行评分，其中 10/10 表示“对于任何主要联盟组织，你可以与他们的一位研究人员交谈并通过他们的智力图灵测试（即，该研究人员会认为你对他们组织的议程很熟悉）。”</p><p>我们从学者的项目后自我报告分数中减去他们的初始自我报告分数，以获得以下分布： </p><figure class="image image_resized" style="width:63.98%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/q0jzuagnkumv2gkfwvjk" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/tv0aa0dtjgrhuvi1pkjn 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/dneqbrids1b78uptkqvl 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/fcahnz8oznyoidnh2xza 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/t9ovxc5ym2zbmnilmtqy 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/cnu1yhkzkmkyzwvmpjbv 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/gepvvkrfeu6t5ktsb4ne 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/bzlob8pmpwqebi29cq0r 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/nw1kpf7xb5hfa78igzxl 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/f0ejttnktmsgkmf8kctn 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/z7hzcrvaa9hs1z1j1c1u 1104w"></figure><p>平均而言，学者们自我报告的对主要协调议程的理解在这 10 分制上增加了 1.75。两名受访者表示，他们的评分下降了一个百分点，这可能是由于学者的自我评估不一致（他们在研究阶段结束时回答时看不到自己之前的回答），或者是学者意识到自己之前的评分理解<a href="https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect"><u>并不像他们想象的那么全面</u></a>。</p><p><strong>研究品味</strong></p><p>我们将研究能力的“品味”维度分解为两个项目后调查问题。第一个问题是“您认为MATS在多大程度上提高了您独立迭代研究方向的能力？”，其中1/10表示没有变化，10/10表示显着提高。平均反应为 6.9/10。 </p><figure class="image image_resized" style="width:85.72%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/zmosuottj0wwyx4zk1hw"></figure><p>受访者提供了有关该主题的定性信息：</p><ul><li> “大多数情况下，我通过陈述研究假设而增强了自信心。之前，我有点认为关于论文的所有可以质疑/询问的事情都已经完成，或者被认为是无趣的——我现在更加坚信，安全研究中仍然有很多容易实现的成果。 （一个例子：更好地理解 RLHF 背后的理论）。”</li><li> “学者们花了一整天的时间互相谈论他们的研究。这增加了快速反馈循环，即“该方法会/不会成功”、“你也应该阅读此内容”、“这似乎影响低/高”。研究迭代有了很大的改进，可能提高了 3 倍。”</li><li> “更擅长红队，对我自己的模型和假设持怀疑态度，并找到最有效的方法来反驳它们。”</li></ul><p>第二个问题涉及研究品味，“在 MATS 期间，您在多大程度上提高了为您的研究开发变革理论的能力？”，其中 1/10 代表没有变化，10/10 代表拥有一个更加成熟的模型。平均反应为 5.9/10。 </p><figure class="image image_resized" style="width:70.31%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/pwzqwmjvjfoiwujhrab5"></figure><p>学者们详细阐述了他们在变革理论方面的经验：</p><ul><li> “我认为 MATS 对我帮助很大，因为它让我对人工智能中的事物如何发展有了更详细的模型，实现了我以前没有考虑过的考虑因素，当我的模型不够细化时更能够意识到，并且知道更多相关的信息事实和细节。”</li><li> “更加批判性地思考我正在做的事情是否能解决任何问题。”</li><li> “我想我之前已经思考过这个问题很多次了，但 MATS 给了我更多练习的机会，我认为我在评估议程方面变得更加现实（而不是以前可能会立即考虑过于宏大的议程）。”</li></ul><p><strong>导师对研究的认可</strong></p><p>在一项调查中，我们询问导师，“考虑到上述情况，您对这位学者继续研究的支持程度如何？”平均反应为 8.1/10，<a href="https://www.qualtrics.com/experience-management/customer/net-promoter-score">净推荐值为</a>38。 </p><figure class="image image_resized" style="width:71.98%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/nv7uav2tugiepfadwa5w" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/bhtp4q6evtp64v69ezfw 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/mjrvh0mqy9bzm17omgq3 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/qseuhcznhvn5jytff23q 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/scl7dyejhqxplisao3pz 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/sk1fg1scis2soxrczgec 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/kqokwwglgjguqo9sfjv3 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/bclz9iouqcam2xad5iuv 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/x4wsc7umnhrl3qzhsxha 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ybqutxsl8szprbkiyvu8 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/df39xsgzxqhbeii2pkth 1104w"></figure><ul><li>当被问及“该学者的技术能力与其所选研究方向相关的程度如何？”导师对学者的平均评分为 7.0/10，其中：<ul><li></li></ul></li></ul><p>重要的是，导师之间对学者研究的判断并不一致，因为每个导师都有自己的标准和优先事项，而且并非每个导师都对调查做出回应。</p><h3>联网</h3><p>我们衡量了社交机会对专业联系和潜在合作者变化的影响。 <span class="footnote-reference" role="doc-noteref" id="fnrefjruz5097w9c"><sup><a href="#fnjruz5097w9c">[5]</a></sup></span>在研究阶段的开始和结束时，学者们报告了“您可以放心向联盟社区寻求专业建议或支持的专业人士数量”。 <span class="footnote-reference" role="doc-noteref" id="fnrefdkoclj9ogu"><sup><a href="#fndkoclj9ogu">[6]</a></sup></span>我们利用这些响应的差异来获得以下分布： </p><figure class="image image_resized" style="width:70.77%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/p3rhtrgiig877me0teby" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/jvt6z2atg5x4d1w10a6t 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/vjjrob3qevytwv5qrwdr 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/gpvwhnanohnkhfm0zaka 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/inntopihux9frbyr2mm5 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/m3dmwgdoimq0rpuvsl5e 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/fnwrag0tjycqnopopdee 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/hp1g32lqy4ltjwveyqmb 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/bd16bew0mefjxuxo3neq 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/bvdymeo731yywe6xkjs2 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/lzqruihgrtictf9kyx4w 1104w"></figure><p>反应的中位数差异为+4.5。两次回答意味着他们可以联系的专业人员数量发生 -10 变化的受访者首先回答“30”，然后回答“20”，因此我们预计该数字是校准方差的结果。</p><p>我们就潜在合作者提出了一个类似的问题：“您认为可以联系多少人来合作开展人工智能对齐研究项目？” <span class="footnote-reference" role="doc-noteref" id="fnrefxyz9685l7yk"><sup><a href="#fnxyz9685l7yk">[7]</a></sup></span>我们采用响应差异来获得以下分布： </p><figure class="image image_resized" style="width:70.87%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/exudn8ryswlsknsbhtfa" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ggftocn43oc0bodhg703 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ub6icmfo938obrxiqibw 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/pffsav2v8sxwv3vkqo6n 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/tvtemcsucpu9wvdxochq 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/myz8y8k7ylyveywhnwt9 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/eluzxy19g6mlicounccf 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/lfhhyaa704f1n9bil4hc 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/vjtcx8ubwprrz6n5772m 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/z1mxlrqoytalsmhf3a2r 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/mlr8c5j89bqq1f4sojmv 1104w"></figure><p>反应的平均差异为+6.0。一些学者报告的下降很可能是由于人们的判断中存在一些日常差异，因为学者们无法获得他们之前的回答。</p><h3>职业障碍</h3><p>在研究阶段的开始和结束时，我们向学者询问“[他们]与成功的人工智能对齐研究生涯之间的障碍”。当比较研究阶段开始和结束时的反应时，我们发现对于大多数可能的障碍，很少有学者将其报告为问题。出版记录和软件工程经验是例外：更多的学者表示在项目结束时面临这些障碍比开始时要多。这些结果可能反映出学者们了解了他们以前低估的障碍，随着学者们克服了早期的障碍，新的障碍变得更加突出，或者学者们转向具有不同障碍的职业道路。在研究阶段结束时，发表记录是学者与成功的职业生涯之间的主要障碍。 </p><figure class="image image_resized" style="width:87.06%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/wfmfyp6jpau8tiihxsue"></figure><p>我们还特别询问了学者在项目开始和结束时撰写资助提案的信心。 70%的学者表示对在项目开始时撰写资助提案感到不自信或非常不自信，但80%的学者表示对在项目结束时撰写资助提案感到有信心或非常有信心。</p><h2>未来计划的教训和变化</h2><p>虽然我们尚未最终确定或实施我们计划为下一批学生做出的一些改变，但以下是我们从 2023 年夏季计划中学到的主要经验教训。</p><h3> 1.申请阶段更好的过滤</h3><p>我们预计，一些处于研究阶段的学者不太可能在其职业生涯中进行具有足够影响力的一致性研究，以保证指导他们的成本，并且我们认为我们可以在申请阶段获得足够的信息来识别这些学者。这表明 MATS 在初始应用或后续评估检查点中还有更严格过滤的空间。人才分布上尾部的更高分辨率将使我们能够选择更有前途的申请人，或者至少减少没有前途的申请人，从而使一些导师能够更加关注他们的每位学者。</p><p>对于某些流来说，更好的过滤器的组成部分之一是增加对软件工程技能的筛选。对于导师自己来说，这可能是一个成本高昂的评估过程，因此对于 2023-24 年冬季计划，我们与 SWE 评估组织签约，以筛选实证 ML 研究流的申请人。</p><p>对于 2023-24 年冬季项目，我们还决定在我们网站上的导师描述中添加“个人适合”部分，以便更好地向申请人传达不同的导师风格。由于有些导师比其他导师更不干涉，我们希望申请人更有可能从他们个人不适合的类别中自我选择。</p><h3> 2.提供更多的技术支持</h3><p>学者支持团队没有明确涵盖且仅有时由导师提供的一种帮助形式是技术支持，包括调试代码、教授<a href="https://neelnanda-io.github.io/TransformerLens/"><u>TransformerLens</u></a>库等新工具以及回答技术 ML 问题。在未来的队列中，我们可能会为受到技术问题困扰的学者提供办公时间或类似的服务。一种可能性是改善我们的基础设施，以便学者们互相帮助解决技术问题。</p><h3> 3. 更积极主动地支持指导之外的专业发展</h3><p>学者支持目前帮助学者解决各种瓶颈，包括生产力、优先级、研究方向、沟通、心理健康等方面的挑战。虽然这对许多学者来说很有价值，但它更强烈地针对可以在短期内解决的瓶颈。每周约 1 小时的辅导，并且有一些技能改进（例如，练习阅读研究论文或提高编程能力）需要投入更多的时间。</p><p>在未来的队列中，我们可能会探索辅导结构或同行问责结构，鼓励学者将更多时间花在对象级研究之外的专业发展上。这可能看起来像论文阅读小组、更定期和高度承诺的研讨会，以及关于变革理论、研究工作流程等主题的联合会议。</p><h3> 4. 为导师提供研究管理帮助</h3><p>除了进一步支持专业发展外，学者支持还计划帮助大多数导师管理 2023-24 年冬季学生的学者研究。我们（学者支持团队）发现，学者支持和导师之间严格的保密政策似乎留下了太多的价值，因为：</p><ol><li>导师将受益于有关学者身份的共享信息；</li><li>学者支持团队对导师目标的理解将使学者受益，特别是当导师的研究方向在整个项目中发生变化时。</li></ol><p>在向导师提供研究管理帮助时，学者支持将在理解研究障碍、项目方向和学者研究的其他趋势方面发挥更直接的作用，并在获得学者同意的情况下向导师总结这些信息。</p><h3> 5. 减少研讨会的数量</h3><p>我们认为 23 场研讨会太多了；我们为学者提供的广度与我们观察到的低平均出席率不相称。在冬季，我们将安排 12 至 16 场研讨会，每周有机会进行较短的闪电演讲。我们还将鼓励更多的学者举办研讨会（以长篇演讲的形式，而不是局限于闪电演讲的形式），因为学者举办的研讨会在夏季获得了很高的评价。</p><h3> 6. 加强项目期间与学者的交流</h3><p>部分由于研讨会、讲习班和社交活动的数量，我们认为我们公告的信噪比可能过高。至少有一次，相当一部分学者并不知道最后期限即将到来。将来，我们将更清晰地区分最重要的公告并更快地发布这些公告。</p><h3> 7. 开发更强大的内部系统</h3><p>随着 MATS 团队的规模扩大，我们正在改进多个内部系统。其中包括我们用于影响评估的数据收集渠道、我们的项目管理系统以及通过更大的专业发展对团队成员进行投资。</p><h3> 8. 提前加载社交活动</h3><p>一些学者报告说，这群人的社交需求没有得到满足。在冬季，我们打算提前举办社交活动，以促进项目早期的联系，并在办公室附近举办更多活动，以期减少学者们在项目后期发起聚会所需的激活能量。 </p><p></p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/owezlxy9huaz3nvisvys" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/p9rtesbpiumqavifgdnn 410w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/kavq5cmkcfjmpghagunp 820w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/kqpc1u8dnlojpfdyfbgs 1230w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/wfbd4e4d8oejex0bi49n 1640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/pkcsb8dtbrazxsxsgjyr 2050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/yesebeflxhns0q6jgkeg 2460w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/chgrj99i2hvbrs8k2kqf 2870w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/xjfi4f2aeaifnab08rak 3280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/sng3yqsh8yhmicbyik0q 3690w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/eazdnqncdnjlf15hjhsq 4034w"></figure><p></p><h1>致谢</h1><p>该报告由<a href="https://www.matsprogram.org/"><u>机器学习调整和理论学者计划</u></a>制作。 Rocket Drew 和 Juan Gil 是本报告的主要贡献者，Ryan Kidd 在 Christian Smith 的支持下确定、管理和编辑了该项目，Laura Vaughan 和 McKenna Fitzgerald 为学者支持报告部分的数据收集和分析做出了贡献。还要感谢 Carson Jones、Henry Sleight 和 Ozzie Gooen 对该项目的贡献。</p><p>要了解有关 MATS 的更多信息，请访问我们的<a href="http://matsprogram.org/"><u>网站</u></a>。我们目前正在<a href="https://manifund.org/projects/mats-funding">接受 2023-24 冬季计划及以后的捐款</a>！ </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn2niy7evweco"> <span class="footnote-back-link"><sup><strong><a href="#fnref2niy7evweco">^</a></strong></sup></span><div class="footnote-content"><p>一些导师在其申请中包含的选择问题示例：</p><p> - 花 2-4 小时使用语言模型开发问答对数据集，RLHF 训练的模型可能会给出友好但不正确的答案。然后记录自己 2-4 小时的时间，评估数据集上的模型并绘制缩放定律。如果您的数据集显示反向缩放，则可获得奖励积分。</p><p> - 我希望你花大约 10 个小时（为了公平起见，最多 20 小时）尝试在机械可解释性的一个开放性小问题上取得研究进展，并向我展示你所取得的进展。请注意，我并不期望您能够解决问题，拥有机械插补的背景，获得令人印象深刻的结果，或者真正感觉到您知道自己在做什么。</p><p> - “贝叶斯期望效用最大化”是普遍强大智能的“真名”吗？为什么/为什么不呢？</p></div></li><li class="footnote-item" role="doc-endnote" id="fnvp0h93gzvk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefvp0h93gzvk">^</a></strong></sup></span><div class="footnote-content"><p>没有进步的学员集中在两名导师身上，他们在培训阶段之前向学员告知他们进入研究阶段的前景。这些导师决策的主要决定因素是学者在培训阶段结束时的研究冲刺中的表现。这些流派的学员知道自己的胜算后，选择了参加，部分原因是与导师一起工作的一个月保证期的价值很高。 2022-23 年冬季学员 Jay Bailey 证明，</p><p> “Neel [Nanda] 的机械可解释性培训过程对我来说是一个很好的方式来测试我在该领域的适应性并与许多聪明的人合作。尼尔的直播要求很高，他希望这是一个并不适合所有人的环境，但他很清楚这并不可耻。虽然我最终没有被选中参加面对面阶段，但经历这个过程帮助我了解了我是否想长期追求机械解释性，并围绕如何最好地为未来的一致性做出贡献制定了计划。 ”</p></div></li><li class="footnote-item" role="doc-endnote" id="fnnsczgjuthnr"> <span class="footnote-back-link"><sup><strong><a href="#fnrefnsczgjuthnr">^</a></strong></sup></span><div class="footnote-content"><p>这个问题通常用于计算“<a href="https://en.wikipedia.org/wiki/Net_promoter_score"><u>净推荐值</u></a>”（NPS），这是许多行业的标准。根据我们的受访者的反馈，MATS 的 NPS 为 +69。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnhdw3lym1fyo"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhdw3lym1fyo">^</a></strong></sup></span><div class="footnote-content"><p>本调查问题和以下问题来自 Lynette Bye <a href="https://forum.effectivealtruism.org/posts/xvax8hpF29Ky5kPJw/effective-altruism-coaching-2020-annual-review"><u>2020 年对其教练影响力的回顾</u></a>。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnjruz5097w9c"> <span class="footnote-back-link"><sup><strong><a href="#fnrefjruz5097w9c">^</a></strong></sup></span><div class="footnote-content"><p>以下直方图排除了一位从 0 增加到 999 名可用专业人士和潜在合作者的学者，解释说：“一开始我基本上觉得我可以给任何人发消息/打电话，现在我觉得我可以给任何人发消息/打电话字面上地。”</p></div></li><li class="footnote-item" role="doc-endnote" id="fndkoclj9ogu"> <span class="footnote-back-link"><sup><strong><a href="#fnrefdkoclj9ogu">^</a></strong></sup></span><div class="footnote-content"><p>该问题详细阐述了：“如果您想要更具体的范围：您认为可以联系多少位专业人士以获得 30 分钟的职业建议？影响这一点的因素包括您认识哪些专业人士以及您是否有足够的联系来让他们为您提供帮助。粗略估计一下就可以了，而且这个问题不仅仅是关于你在MATS中遇到的人！”</p></div></li><li class="footnote-item" role="doc-endnote" id="fnxyz9685l7yk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxyz9685l7yk">^</a></strong></sup></span><div class="footnote-content"><p>该问题详细阐述为：“想象一下，您在感兴趣的联盟领域内有一些研究项目想法。您认识的人中有多少人可能是合作者？粗略估计一下就可以了，而且这个问题不仅仅是关于你在MATS中遇到的人！”</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/zwf68YaySvXhWYCdh/mats-summer-2023-postmortem-1#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/zwf68YaySvXhWYCdh/mats-summer-2023-postmortem-1<guid ispermalink="false"> zwf68YaySvXhWYCdh</guid><dc:creator><![CDATA[Rocket]]></dc:creator><pubDate> Fri, 01 Dec 2023 23:29:47 GMT</pubDate></item></channel></rss>