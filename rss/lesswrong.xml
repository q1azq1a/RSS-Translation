<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 12 月 5 日，星期二 10:13:34 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[A Socratic dialogue with my student]]></title><description><![CDATA[Published on December 5, 2023 9:31 AM GMT<br/><br/><p>这是我和我的学生诺姆之间的对话。经他许可，以编辑形式转载。评论时，请考虑他是一个青少年。其中许多想法对他来说都是<a href="https://xkcd.com/1053/">新的</a>。</p><p>怎样才能招到学生呢？你偷了它们。他以前的老师是一位马克思主义者。我在辩论中彻底摧毁了他以前的老师，以至于他放弃了她的教诲，现在转而听我的。</p><p>我认为这段对话展示了良好的教学技巧。</p><ul><li>我让诺姆来判断什么是合理的、什么是有道理的、什么是“证据”。在诺姆出生之前，我参加了我的第一次辩论比赛。这个障碍稍微缩小了差距。</li><li>我会问一系列问题，而不只是说“ <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>是真的”。这使得<a href="https://www.lesswrong.com/posts/NMoLJuDJEms7Ku9XS/guessing-the-teacher-s-password">密码猜测</a>变得不可能。他是在下棋，而不是<i>危险边缘！</i></li><li>我避免告诉诺姆我的信仰，除非他明确询问。这对诺姆来说更有趣，因为没有人喜欢未经请求的讲道。这也更有说服力，因为结论感觉像是他的结论。</li><li>当诺姆改变话题时，我立即退缩了。</li></ul><p><strong>诺姆：</strong>我知道你反对免除学生贷款债务。你能告诉我为什么吗？我这样做是为了一场演讲和辩论比赛。</p><p> <strong>Lsusr：</strong>你<a href="https://www.youtube.com/watch?v=o_wNNjfCG1E&amp;t=4s">以前不相信</a>支持救济的论点吗？当然，重复曾经说服你的论点并不困难。</p><p><strong>诺姆：</strong>我不知道我现在是否有足够的研究来与像你这样的人辩论。</p><p> <strong>Lsusr：</strong>你并不是想说服我。你正试图说服<a href="https://www.youtube.com/watch?v=xuaHRN7UhRo"><i>他们</i></a>。利用他们的偏见、非理性、部落主义和无知。</p><p><strong>诺姆：</strong>我还必须安抚评委们。</p><p> <strong>Lsusr：</strong>我就是这么说的。</p><hr><p><strong>诺姆：</strong>我正在努力寻找一个关于学生贷款减免的好论据。</p><p> <strong>Lsusr：</strong>但是你以前不是很赞同吗？当然，你可以重复曾经说服你的糟糕论点。</p><p><strong>诺姆：</strong>这些都是道德争论，没有任何经济理解。</p><p> <strong>Lsusr：</strong>没关系。你的听众可能是经济文盲。</p><p><strong>诺姆：</strong>不知何故，我认为我们作为赞成免除所有学生贷款债务的一方赢得了一次胜利。</p><p> <strong>Lsusr：</strong>干得好。</p><p><strong>诺姆：</strong>谢谢。</p><hr><p> <strong>Lsusr：</strong>你听说过“有效利他主义”吗？您可能会喜欢他们推出的一些东西。它往往具有道德一致性和经济素养（与主要的民主共和党、社会主义等政治纲领不同）。</p><p><strong>诺姆：</strong>不，但我会调查一下。</p><p> <strong>Lsusr：</strong>你可能不同意。但我预计它的智力稳健性会让你耳目一新。</p><hr><p><strong>诺姆：</strong>这是否意味着我自杀然后将我所有的器官捐献给需要它们的人是道德的？我想，除非我能在不自杀的情况下拯救更多的生命。也许更好的论点是自杀，让某人卖掉我所有的身体部位，然后用这笔钱购买疟疾网，送给生活在非洲的人们。</p><p> <strong>Lsusr：</strong>你可以在不自杀的情况下拯救更多生命。而且，我想不出有哪个 EA 曾为此案自杀过。</p><p><strong>诺姆：</strong>可能是因为我们直觉上认为自杀是错误的。</p><p> <strong>Lsusr：</strong>不要因为肾脏的事情而分心。基本思想如下：</p><ul><li>美国政府需要花费 10,000,000 美元才能挽救一个美国人的生命。</li><li>在非洲，通过公共卫生措施挽救一条生命需要 5,000 美元。</li></ul><p>这就是我上个月为非洲公共卫生措施捐赠 20 美元的原因。它的作用相当于美国联邦政府花费的 40,000 美元。</p><p><strong>诺姆：</strong>是的，确实如此。在美国靠什么拯救生命？</p><p> <strong>Lsusr：</strong>基本的想法是你应该计算数字。 </p><figure class="media"><div data-oembed-url="https://www.youtube.com/watch?v=dNgp-s8IvRs"><div><iframe src="https://www.youtube.com/embed/dNgp-s8IvRs" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div></figure><p><strong>诺姆：</strong>我认为这对钱有用，但我不知道它是否可以完全应用于所有事情。</p><p> <strong>Lsusr：</strong>为什么不呢？具体例子。</p><p><strong>诺姆：</strong>嗯，这取决于你是否认为人类应该拥有受保护的权利。</p><p> <strong>Lsusr：</strong>这不是一个具体的例子。您的主张可能适用于什么现实世界的决定？请明确点。</p><p><strong>诺姆：</strong>一位医生有5名病人需要器官移植，否则他们就会死。有一名完全健康的人因接受小手术而处于麻醉状态。如果我们仔细计算一下数字，医生应该杀死那个人才能挽救五个人的生命。如果你认为人类有权利，那就是不道德的。如果你认为人类不会，那就不会了。</p><p> <strong>Lsusr：</strong>正确。这显然是不道德的。但人权并不是医生不应该谋杀病人的唯一原因。你能想到一种实用主义的吗？</p><p><strong>诺姆：</strong>医生会失去执照，然后他们就会失业。</p><p> <strong>Lsusr：</strong>如果没有许可证要求怎么办？比如在战区。</p><p><strong>诺姆：</strong>患者将来也许能够挽救生命。</p><p> <strong>Lsusr：</strong> 5 个器官接受者也可以。另一个原因。</p><p><strong>诺姆：</strong>我不确定。</p><p> <strong>Lsusr：</strong>没有人会去看他们认为会谋杀他们的医生。</p><p><strong>诺姆：</strong>如果是战区，那么可能没有其他选择。</p><p> <strong>Lsusr：</strong>公平。您熟悉“义务论伦理学”这个词吗？</p><p><strong>诺姆：</strong>是的。任何有最好意图的事情都是如此。那是对的吗？我可能已经忘记了。</p><p> <strong>Lsusr：</strong>没有。这不是最好的意图。</p><p><strong>诺姆：</strong>好的。之后怎么样了？</p><p> <strong>Lsusr：</strong>义务论伦理遵循“不要杀死你的病人”这样的良好规则。 EA 相信要处理数字，但它们通常不会违反义务论限制。当我捐20美元时，我捐的是我自己的钱。我没有偷它。</p><p><strong>诺姆：</strong>好的。让我想想我是否发现任何缺陷。</p><p> <strong>Lsusr：</strong>慢慢来。</p><p><strong>诺姆：</strong>如果你遵循我认为好的规则，并且你帮助了最多的人，那么我不可能反对。</p><p> <strong>Lsusr：</strong>那是 EA。但不仅仅是人。他们的素食主义者数量远远超过了应有的比例。</p><p><strong>诺姆：</strong>好的。稍微不相关的问题：您对素食主义者有何看法？</p><p> <strong>Lsusr：</strong>我已经几个月没吃肉了。</p><p><strong>诺姆：</strong>这对你来说是环境问题还是对杀害动物的道德反对？还是健康？</p><p> <strong>Lsusr：</strong>对我的健康可能会产生负面影响。环境影响对我来说无关紧要。我不在乎杀死动物。如果你能找到一个符合道德来源的汉堡，那么我很乐意吃它。问题是，我们的动物产品默认来自工厂化农场，那是人间地狱。 [更正：我在家人的感恩节晚餐上吃了一些肉汁。]</p><p><strong>诺姆：</strong>这对我来说很有趣，我不一定不同意你的推理。</p><p> <strong>Lsusr：</strong>我尽量不将我的信仰和价值观强加给别人。这就是为什么直到你问我才提到这一点。</p><p><strong>诺姆：</strong>如果你说折磨动物是错误的，那么杀死动物不也是不道德的吗？</p><p> <strong>Lsusr：</strong>动物干净的死亡几乎没有什么痛苦，特别是与漫长而美好的生命相比。我正在努力减少痛苦，同时遵守义务论限制。</p><p><strong>诺姆：</strong>你认为道德考虑的重要性应该与事物的先进程度成正比吗？抱歉，如果我措辞不好。现在已经是深夜了，我正在等待电源恢复，这样我就可以做剩下的作业了。</p><p> <strong>Lsusr：</strong>我知道你的意思。答案=是。如果我必须在拯救两只牛和一个人之间做出选择，那么人类是显而易见的选择。</p><p><strong>诺姆：</strong>好的。我同意你的看法。</p><hr><p> <strong>Lsusr：</strong>辩论进行得怎么样？</p><p><strong>诺姆：</strong>你的假设是非常正确的，即法官们都是经济文盲。</p><p> <strong>lsusr：</strong>哈哈哈哈哈哈</p><hr><p><strong>Lsusr：</strong>你喜欢吗？我觉得你很喜欢辩论锦标赛。干得好，能够与校队的孩子们竞争。</p><p><strong>诺姆：</strong>是的。非常有趣。</p><p> <strong>Lsusr：</strong>我也喜欢高中辩论。我做了3-4年。</p><p><strong>诺姆：</strong>尝试捍卫错误的立场很有趣，因为这很困难。</p><p> <strong>Lsusr：</strong>如果你的信念是错误的（所以你认为这是正确的立场）怎么办？那很难吗？</p><p><strong>诺姆：</strong>我知道不是在这个问题上，因为正如你所说，这就像争论天空是否是蓝色的。但对于其他一些诸如“美国应该在&lt;地方>;部署更多军队”之类的问题，很难看出什么是正确的。</p><p> <strong>Lsusr：</strong>出去吧。直视。准确地告诉我你看到的是什么颜色。</p><p><strong>诺姆：</strong>现在是黑色的。</p><p> <strong>Lsusr：</strong>通常，辩论比赛决议的定义（故意）如此模糊，以至于它们可能是正确的，也可能是错误的，这取决于它们的解释方式。</p><p><strong>诺姆：</strong>据我所知，无论你如何解释，这个都是错误的。我认为“全部”这个词几乎让人无法辩护。</p><blockquote><p>美国联邦政府应免除所有联邦学生贷款债务。</p></blockquote><p> <strong>Lsusr：</strong>假设民主国家的每个人（错误地）都支持学生贷款减免。民选政府是否应该尊重人民的意愿？</p><p><strong>诺姆：</strong>是的，因为如果他们不这样做，就会开创一个不服从人民的危险先例。</p><p> <strong>Lsusr：</strong>那么你所要做的就是表明绝大多数美国选民支持贷款减免。</p><p><strong>诺姆：</strong>比起 3.4% 的通胀率，我更担心这种影响。</p><p> <strong>Lsusr：</strong>不用担心。绝大多数美国选民支持愚蠢得多的政策。美国的通胀率应该是多少？</p><p><strong>诺姆：</strong>我的直觉是 0%，但有一些我不知道的经济小事表明一个国家应该有<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>程度的通货膨胀。</p><p> <strong>Lsusr：</strong>这是我制作的一个长达一小时的 YouTube 视频，试图传达这个问题的复杂性。 【我就是右边那个戴面具的人。】 </p><figure class="media"><div data-oembed-url="https://www.youtube.com/watch?v=fdlFHnxDE94"><div><iframe src="https://www.youtube.com/embed/fdlFHnxDE94" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div></figure><p>为什么它应该为零？</p><p><strong>诺姆：</strong>我认为，我在经济知识方面的差距正在显现，但当一种货币尽可能值钱时，这不是很好吗？而且，我的力量现在又恢复了。所以我要做作业然后去睡觉。</p><p> <strong>Lsusr：</strong>如果你希望货币尽可能值钱，那么我们应该有负通胀率。晚安！保证充足的睡眠。</p><p><strong>诺姆：</strong>噢，你说得对。我把这归咎于“凌晨2点”。</p><p> <strong>Lsusr：</strong>不。你的问题并不愚蠢。这很难。</p><p><strong>诺姆：</strong>我想我应该记住数字可能会下降。</p><p> <strong>lsusr：</strong> 🤑</p><br/><br/> <a href="https://www.lesswrong.com/posts/TtdJt78mgGiDubnAM/a-socratic-dialogue-with-my-student#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/TtdJt78mgGiDubnAM/a-socratic-dialogue-with-my-student<guid ispermalink="false"> TtdJt78mgGiDubnAM</guid><dc:creator><![CDATA[lsusr]]></dc:creator><pubDate> Tue, 05 Dec 2023 09:31:05 GMT</pubDate> </item><item><title><![CDATA[Neural uncertainty estimation for alignment]]></title><description><![CDATA[Published on December 5, 2023 8:01 AM GMT<br/><br/><h2>介绍</h2><p>假设您已经构建了一些人类价值观的人工智能模型。你输入一个情况，它就会给出一个良好度评级。您可能想问：“此优度评级的误差线是多少？”除了了解误差线之外，不确定性估计在人工智能内部也很有用：指导主动学习<span class="footnote-reference" role="doc-noteref" id="fnref80ywo0pbl8r"><sup><a href="#fn80ywo0pbl8r">[1]</a></sup></span> 、纠正<a href="https://www.lesswrong.com/posts/5gQLrJr2yhPzMCcni/the-optimizer-s-curse-and-how-to-beat-it">优化器的诅咒</a><span class="footnote-reference" role="doc-noteref" id="fnrefq23duy4ut0g"><sup><a href="#fnq23duy4ut0g">[2]</a></sup></span>或进行分布外检测<span class="footnote-reference" role="doc-noteref" id="fnref3dij2j9svj8"><sup><a href="#fn3dij2j9svj8">[3]</a></sup></span> 。</p><p>我最近出于一个<a href="https://www.lesswrong.com/s/aJvgWxkCBWpHpXti4/p/nA3n2vfCy3ffnjapw">喜欢的原因</a>进入了神经网络（NN）的不确定性估计文献：我认为这对于量化人工智能潜在特征的有效性域的对齐很有用。如果我们<a href="https://www.lesswrong.com/posts/w4aeAFzSAguvqA5qu/how-to-go-from-interpretability-to-alignment-just-retarget">将人工智能指向其世界模型中的某个概念</a>，那么对该概念的实现进行优化可能会因为将该概念推到其有效范围之外而出错。</p><p>但现在就先把对齐的想法放在你的后口袋里吧。这篇文章主要是对不确定性估计文献的调查，其中夹杂着我自己的看法。</p><p></p><h2>贝叶斯神经网络图片</h2><p>贝叶斯神经网络图是几乎所有神经网络不确定性估计方法的鼻祖，因此从这里开始是合适的。</p><p>图片很简单。您从参数的先验分布开始。您的训练数据就是证据，在对其进行训练后，您将获得更新的参数分布。给定输入，您可以通过贝叶斯神经网络传播输入来计算输出的分布。</p><p>这一切都是非常正确且无关紧要的（“<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="2^{trillion}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">当然</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">，</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">让</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">我</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">更新</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">我</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">的</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">2</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">万亿</span></span></span></span></span></span></span></span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>模型所有参数的维度联合分布”），但<i>实际上训练神经网络确实是这样工作的</i>。<i> </i>如果您使用对数似然损失和 L2 正则化，并且您的参数先验是高斯分布，则最小化损失的参数将位于贝叶斯神经网络所具有的分布的峰值<span class="footnote-reference" role="doc-noteref" id="fnreffo4svcpvxs"><sup><a href="#fnfo4svcpvxs">[4]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnrefcogdul3x2xj"><sup><a href="#fncogdul3x2xj">[5]</a></sup></span> 。</p><p>这是因为损失景观和参数不确定性之间存在桥梁。 <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(parameters \;|\; dataset) ="><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">贝叶斯</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">规则</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">表示</span></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">P</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">（</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">集</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">P</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">⋅</span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(parameters) \cdot \text{P}(dataset \;|\; parameters) / \text{P}(dataset)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">P</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">集</span></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mtext MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">）</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">/</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">P</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">（</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">集</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">）</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">。</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span></span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(parameters \;|\; dataset)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">这里</span></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">P</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">集</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">是</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">要</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">估计</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">的</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">后</span></span></span></span></span></span></span><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(parameters) \cdot \text{P}(dataset \;|\; parameters)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">验</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">分布</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">，</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">P</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">⋅</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">P</span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">(</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">集</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mtext MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">s</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">是</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">损失</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">的</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">指数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">6</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">]</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">。</span></span></span></span></span></span></span> <span class="footnote-reference" role="doc-noteref" id="fnrefamk58pvab4"><sup><a href="#fnamk58pvab4">_</a></sup></span>这适用于物理隐喻，例如“参数的分布是位于损失盆地底部的玻尔兹曼分布”。</p><p>根据经验，通过假装遵循贝叶斯神经网络图来计算神经网络的不确定性效果非常好，以至于一篇关于集成方法的好论文<span class="footnote-reference" role="doc-noteref" id="fnreflpb1b2qcoen"><sup><a href="#fnlpb1b2qcoen">[7]</a></sup></span>将其称为“基本事实”。当然，要在这里实际计算任何东西，你必须进行近似，如果你进行快速而肮脏的近似（例如假装你可以从 Hessian 找到损失盆地的形状），你会得到不好的结果<span class="footnote-reference" role="doc-noteref" id="fnrefd9jz9mfml"><sup><a href="#fnd9jz9mfml">[8]</a></sup></span> ，但人们正在做这些天，蒙特卡罗方法变得很聪明<span class="footnote-reference" role="doc-noteref" id="fnrefbct5kii2m07"><sup><a href="#fnbct5kii2m07">[9]</a></sup></span> ，他们发现贝叶斯神经网络计算的更好近似可以得到更好的结果。</p><p>但对损失景观进行蒙特卡罗遍历的成本很高。对于大规模应用的技术，它必须只对运行模型的成本施加很小的乘数，并且如果您希望它变得普遍，那么它施加的成本必须非常小。</p><p></p><h2>合奏团</h2><p>解决不确定性的一种完全不同的方法是集成<span class="footnote-reference" role="doc-noteref" id="fnrefen0yeoqzg0k"><sup><a href="#fnen0yeoqzg0k">[10]</a></sup></span> 。只需训练十几个模型，询问他们的建议，并估计传播的不确定性。所有事情的数十倍成本乘数都很陡峭，但如果您经常查询模型，它比损失情况的蒙特卡洛估计便宜。</p><p>集成在理论上很简单。您不需要假装模型经过训练可以收敛，不需要专门针对预测损失进行训练，甚至不需要固定的架构。您只需选择一些想要分散不确定性的模型分布并进行采样。</p><p>你可以用合奏做一些聪明的事情。通过计算集成如何适应贝叶斯神经网络图片，您会了解到改变正则化的零点可能是个好主意，否则您将在模型的泛化方式中得到虚假相关性<span class="footnote-reference" role="doc-noteref" id="fnreflpb1b2qcoen"><sup><a href="#fnlpb1b2qcoen">[7]</a></sup></span> 。您可以拆分数据集并训练单独的较小模型，然后巧妙地聚合这些模型（类似于<a href="https://www.kaggle.com/code/prashant111/bagging-vs-boosting">装袋和提升</a>），以降低集成的计算溢价<span class="footnote-reference" role="doc-noteref" id="fnrefen0yeoqzg0k"><sup><a href="#fnen0yeoqzg0k">[10]</a></sup></span> 。这些论文中暗示，聪明的集成技巧在更大的尺度上并不那么重要，但目前还不清楚收益是否完全为零。</p><p>集成的一个棘手部分是，如果一枚硬币正面朝上的概率为 51%，并且您已训练神经网络以获得正确答案，那么集成中的每个成员都会预测正面。正确答案并不不确定，因此您的团队表示不存在不确定性。如果您希望不确定性度量包含环境中的熵，则必须训练神经网络来估计该熵，这在很大程度上放弃了使用非预测损失的自由。</p><p>解释时的类似关注适用于在模型的潜在特征上使用集成，尽管我在文献中没有看到人们这样做。假设您训练了十几个模型，并用有关狗的数据探测它们，为每个模型找到一个“狗向量”。您可以对它们的大小和方差进行标准化，然后使用集合的方差作为“狗向量的不确定性”。这并不是关于狗的完全不确定性，因为它没有衡量人工智能模型中关于狗的不确定性，这只是不同模型根据特定探测方法的内部表示的传播。</p><p></p><h2>关于任意不确定性的注释</h2><p>文献中很大一部分文字是关于任意不确定性和认知不确定性之间的区别<span class="footnote-reference" role="doc-noteref" id="fnrefxqxuuw1xe2"><sup><a href="#fnxqxuuw1xe2">[11]</a></sup></span> 。当我说集成会告诉你由于建模选择而导致的输出的不确定性时，这就是我必须谈论的区别，但不会告诉你人工智能内部对环境的不确定性。在不确定性估计文献中，由于模型方差而产生的不确定性被称为“认知性”，而人工智能环境模型内部的不确定性被称为“随意性”。 <span class="footnote-reference" role="doc-noteref" id="fnref2jiolbj6tn8"><sup><a href="#fn2jiolbj6tn8">[12]</a></sup></span></p><p>在大数据限制下，认知不确定性相对于任意不确定性变得很小（除非你故意将模型推入高度认知不确定性的情况）。有些论文忘记了这一点，做了一些愚蠢的事情，使他们的认知不确定性估计更大，因为他们认为这应该是总的不确定性，这就是为什么其他论文必须用章节来讨论这种区别。</p><p></p><h2>添加噪声，由于某种原因通常会丢失</h2><p>如果您想要不确定性估计，您可以将随机噪声添加到神经网络的中间激活中。如果输出对噪声更敏感，则不确定性更大，如果输出不太敏感，则不确定性更小<span class="footnote-reference" role="doc-noteref" id="fnrefud7l8eu73jk"><sup><a href="#fnud7l8eu73jk">[13]</a></sup></span> 。有一些自然的启发式论证可以解释为什么这是有意义的<span class="footnote-reference" role="doc-noteref" id="fnreflgnhfp0m35e"><sup><a href="#fnlgnhfp0m35e">[14]</a></sup></span> ，并且通过更多的工作，您可以尝试将其与贝叶斯神经网络图和损失景观的蒙特卡洛估计联系起来。</p><p>或者，您可以忽略抽象参数并使用 dropout 作为随机噪声分布<span class="footnote-reference" role="doc-noteref" id="fnrefhfox6k7gfev"><sup><a href="#fnhfox6k7gfev">[15]</a></sup></span> 。</p><p>哦，当然，人们给出了理由，但我认为这里的第一印象是正确的，添加 dropout 然后采样在理论上是愚蠢的。但在实验上，它的效果很好，人们一直在谈论它<span class="footnote-reference" role="doc-noteref" id="fnref0hl862nst9f9"><sup><a href="#fn0hl862nst9f9">[16]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnrefu11lguv41wc"><sup><a href="#fnu11lguv41wc">[17]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnrefhzxdsrsco9g"><sup><a href="#fnhzxdsrsco9g">[18]</a></sup></span> ，而且它不需要你做任何额外的训练。</p><p>为什么它起作用的一个谜题可能是，在具有一些噪声样本的数据集上训练的网络将学会输出一个包罗万象的先验以响应噪声<span class="footnote-reference" role="doc-noteref" id="fnreffqljh5j8ipf"><sup><a href="#fnfqljh5j8ipf">[19]</a></sup></span> 。我怀疑 dropout 是足够大的噪音，它将网络推向这个先验，这有助于过度自信。</p><p>我希望人们对更小的、非丢失的噪声进行更多的比较<span class="footnote-reference" role="doc-noteref" id="fnrefvl2ahm3user"><sup><a href="#fnvl2ahm3user">[20]</a></sup></span> 。这在理论上似乎更合理，尽管当翻译回贝叶斯术语时，将噪声注入内部层似乎对应于有趣但不寻常的噪声分布。</p><p></p><h2>校准</h2><p>文献<span class="footnote-reference" role="doc-noteref" id="fnref0hl862nst9f9"><sup><a href="#fn0hl862nst9f9">[16]</a></sup></span>的很大一部分是人们只是试图获取神经网络的输出并对它们应用简单的函数来获得不确定性估计。我将简要地对待他们。</p><p>第 0 级只是按面值获取 NN 输出。当数据较多且参数不确定性较小时，神经网络的直接预测可以很好地估计不确定性。例如，基础 GPT-4 在分配给下一个标记的概率分布中得到了很好的校准，包括当这些下一个标记是以前从未见过的测试问题的答案时<span class="footnote-reference" role="doc-noteref" id="fnrefzkojoz799ka"><sup><a href="#fnzkojoz799ka">[21]</a></sup></span> 。即使是非分布，这也比什么都没有好——正如我上面提到的，如果神经网络的训练集包含意外数据，那么它们确实会学会不确定意外数据<span class="footnote-reference" role="doc-noteref" id="fnreffqljh5j8ipf"><sup><a href="#fnfqljh5j8ipf">[19]</a></sup></span> ，尽管它们仍然倾向于过度自信。</p><p>随着模型的泛化能力越来越强，我预计它们的输出能够在更大的领域得到很好的校准。相反，对于在有限数据上训练小型模型的应用程序，您将需要一种不同的方法来估计不确定性。</p><p>通常人们会尝试比第 0 级更奇特一些，并做一些事情，比如调整 softmax 函数的参数，以最大限度地提高对保留验证集的校准<span class="footnote-reference" role="doc-noteref" id="fnrefnglt70rybd9"><sup><a href="#fnnglt70rybd9">[22]</a></sup></span> 。这也很容易与其他方法结合作为最终校准步骤<span class="footnote-reference" role="doc-noteref" id="fnrefgx8tqfun0w"><sup><a href="#fngx8tqfun0w">[23]</a></sup></span> 。</p><p>如果您有分布外 (OOD) 数据样本，您还可以做更奇特的事情，例如同时进行 OOD 检测和校准<span class="footnote-reference" role="doc-noteref" id="fnreftmgq2x5m6t"><sup><a href="#fntmgq2x5m6t">[24]</a></sup></span> 。或者，如果您有 OOD 数据样本并且是频率论者，则可以进行保形预测<span class="footnote-reference" role="doc-noteref" id="fnrefg3rtbqm4247"><sup><a href="#fng3rtbqm4247">[25]</a></sup></span> 。</p><p>校准的一个卖点是您可以对任何经过训练的模型执行此操作。但如果您愿意放弃这一点并干预训练，就有一些方法可以改进模型的校准。这可能看起来像使用额外的正则化<span class="footnote-reference" role="doc-noteref" id="fnrefqbdlqupa3x"><sup><a href="#fnqbdlqupa3x">[26]</a></sup></span>或对比示例<span class="footnote-reference" role="doc-noteref" id="fnref2qfcvdqkx2y"><sup><a href="#fn2qfcvdqkx2y">[27]</a></sup></span>进行训练。这些也在一定程度上提高了 OOD 泛化能力，对抗性训练也是如此<span class="footnote-reference" role="doc-noteref" id="fnrefazba93s687"><sup><a href="#fnazba93s687">[28]</a></sup></span> 。</p><p>最终，网络输出的校准似乎并没有达到我想要的不确定性估计方法的效果。其一，它不会估计潜在特征的不确定性，而是与您拥有数据的输出的不确定性有关。</p><p>另一方面，它<a href="https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation">缺乏搜索的鲁棒性</a><span class="footnote-reference" role="doc-noteref" id="fnrefv1gf6chx43"><sup><a href="#fnv1gf6chx43">[29]</a></sup></span> 。确实，所有其他不确定性估计方法在优化时也应该容易受到对抗性示例的影响（部分原因是对抗性示例是特征，而不是错误<span class="footnote-reference" role="doc-noteref" id="fnrefa3kc8qjhdn6"><sup><a href="#fna3kc8qjhdn6">[30]</a></sup></span> ），但是当网络输出及其不确定性估计是相同的时，对良好输出的本地搜索应该<i>特别</i>有效地找到奇怪的意想不到的最佳值<span class="footnote-reference" role="doc-noteref" id="fnref28983dpfjdp"><sup><a href="#fn28983dpfjdp">[31]</a></sup></span> 。</p><p></p><h2>训练高阶模型</h2><p>校准的另一面。首先让你的神经网络为你提供更好的不确定性估计。</p><p>如果您想获得二阶不确定性的估计，请训练神经网络以输出<a href="https://en.wikipedia.org/wiki/Dirichlet_distribution#Occurrence_and_applications">狄利克雷分布</a>的参数，而不是进行正常分类<span class="footnote-reference" role="doc-noteref" id="fnrefkm10b29by7c"><sup><a href="#fnkm10b29by7c">[32]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnrefhfc8x4hav0b"><sup><a href="#fnhfc8x4hav0b">[33]</a></sup></span> 。或者，如果您正在进行回归，请训练神经网络以输出答案的分布参数<span class="footnote-reference" role="doc-noteref" id="fnrefen0yeoqzg0k"><sup><a href="#fnen0yeoqzg0k">[10]</a></sup></span> 。或者，如果您拥有法学硕士并且每个问题都是钉子，请训练您的法学硕士用语言表达不确定性<span class="footnote-reference" role="doc-noteref" id="fnrefffdudph3qus"><sup><a href="#fnffdudph3qus">[34]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnrefadsp4hkxuk"><sup><a href="#fnadsp4hkxuk">[35]</a></sup></span> 。</p><p>表达不确定性的训练模型存在一个微妙的问题：不存在适当的二阶损失函数<span class="footnote-reference" role="doc-noteref" id="fnrefxuwhb9ieyh"><sup><a href="#fnxuwhb9ieyh">[36]</a></sup></span> 。这意味着仅从数据点出发，很难准确地训练模型来给出概率分布 - 您可以创建损失函数来尝试做到这一点，但只要您只监督正确答案是什么，而不监督正确答案是什么。正确的概率分布是，通过损失最小化得到的概率分布将会有偏差。</p><p>贝叶斯方法，或者至少是贝叶斯理论框架，在这里会很有用。您不需要适当的损失函数来进行贝叶斯更新。但还没有人写下该应用程序的贝叶斯神经网络图的类似物。</p><p>理论上也不清楚如何整合我们可以获得的有关概率分布的其他类型的监督数据。例如，人为噪声的例子可以给出直接的监督信号，表明正确的概率分布是高熵的。或者，我们可以通过询问“我期望我对正确答案的估计随着更多数据而改变多少？”来学习分布。它的监督分布在整个数据集中，因此绕过了没有适当评分规则的证明 - 但我们可以以公正的方式做到这一点吗？</p><p></p><h2>比较方法</h2><p>那么，哪个是最好的？</p><p>目前，它正在训练一个整体。但训练高阶模型具有尚未开发的潜力。</p><p>情况尚不清楚，因为比较是在玩具问题上进行的，文献很少并且并不总是重复，比较很困难，因为每种方法都有十几种变体，而且不同的论文有时会评估完全不同的指标。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/xptyd74vj7qmuirlgkdq" alt="该图显示了一些神经网络曲线与不同方法生成的误差条的拟合情况。" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/h6cj9a57suxcupp18t15 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/uqc5c2ci9zjyioeqilyd 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/dgoocd9ekrsj4v2ldc3f 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/pbdddhbajg3sxt9ixtsy 680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/bavrtb78i5icyf0kiyki 850w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/r4pe2oeov2q0fyqkckyj 1020w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/uraeyjenw52atepowgt4 1190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/lsoqntf6avhbtk0qkyhp 1360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/dbifkkrzkczba42uqllp 1530w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/dcy3kxiejmh9igglcn63 1603w"><figcaption>来自<a href="https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment#fnlpb1b2qcoen">参考文献。 7</a> .玩具曲线拟合问题的不确定性估计方法比较。<br><br> Ground Truth 是一个贝叶斯神经网络，Hamiltonian MC 是它的一个很好的蒙特卡洛近似，变分推理是它的一个廉价近似，MC Dropout 根据 dropout 后的方差估计不确定性，而我们的方法是一个具有奇特初始化的集成。</figcaption></figure><p>这个数字是一个不错的直觉泵。它在玩具曲线拟合任务（只有<span class="footnote-reference" role="doc-noteref" id="fnreflpb1b2qcoen"><sup><a href="#fnlpb1b2qcoen">6</a></sup></span>个数据点的回归问题）上比较了不确定性估计方法（尽管它明显错过了校准和高阶建模），每种方法都使用 ReLU 与 Sigmoid。我认为这个数字的一​​些定性印象是概括性的。</p><p>印象笔记：</p><ul><li>贝叶斯神经网络、蒙特卡洛近似和集成方法都做出了类似的预测。</li><li>架构对于泛化属性来说非常重要，在某种程度上使这些方法看起来过于自信。 （整合不同的架构将是一个好的开始，但没有人这样做。）</li><li> Dropout 和变分推理近似在数据点附近的置信度都低于集成簇，但在分布之外的置信度更高。</li></ul><p>在对 CIFAR-10 或 LSTM 语言模型<span class="footnote-reference" role="doc-noteref" id="fnrefhzxdsrsco9g"><sup><a href="#fnhzxdsrsco9g">[18]</a></sup></span>或医学 MRI 数据<span class="footnote-reference" role="doc-noteref" id="fnrefu11lguv41wc"><sup><a href="#fnu11lguv41wc">[17]</a></sup></span>进行更彻底的比较（现在包括校准）时，集成似乎是最好的方法。但老实说，我提到的所有方法都非常接近，在复杂任务上，dropout 比玩具模型所建议的更有竞争力，而变分推理在 MNIST 上表现得令人惊讶。</p><p>高阶建模出现在较少的比较中。但这是参考文献中的一个数字。 31 其中模型在 MNIST 上进行训练，然后在<a href="https://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html">非 MNIST</a>上进行测试<span class="footnote-reference" role="doc-noteref" id="fnrefkm10b29by7c"><sup><a href="#fnkm10b29by7c">[32]</a></sup></span> 。学习分类输出上的狄利克雷分布（EDL 虚线）与包的其余部分不同，就像包与原始模型输出（蓝色 L2 线）的不同一样： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/iyp8dpi29scplwjsybyy" alt="该图显示高阶建模给出了分布的高熵猜测。" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/p6hfgbwkaxi6erapiwuq 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/jomn5fobieqqetqjk169 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/pi2t8mbqbba98fa0jpou 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/w6trrvylxr34gdixbcwx 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/ehphdoebwsegtp3qtlsb 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/bnaqfkt3qw2dubftvxql 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/kejhllk816mnmsjsnixm 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/urqu1kjrrbmc5dvnlfbw 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/t99gmgzve5q2xvdbicct 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/ba87fp8izpeheft8u4ka 829w"><figcaption>来自<a href="https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment#fnkm10b29by7c">参考文献。 32</a> . OOD 数据集上输出熵的积分直方图（或累积分布）。训练是在 MNIST 上进行的，但测试是在<a href="https://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html">非 MNIST</a>上进行的，因此具有更高的高熵概率是好的。<br><br> EDL 是他们的狄利克雷分布模型，L2 是原始模型输出，DeepEnsemble 是一个集成，FFLU 不清楚但可能是贝叶斯 NN 近似，Dropout 是 dropout，FFG 是贝叶斯 NN 方法，MNFG 是变分推理近似。</figcaption></figure><p>当显示 OOD 数据时，这是一种非常令人印象深刻的不确定能力。是的，在分布上（在 MNIST 上）它具有正常的准确性。显然，学习何时不确定就是获取一些其他方法无法获取的信息。</p><p>但如此不确定真的正确吗？假设您正在对数字进行分类，这就是您所知道的，然后有人输入字符“B”。这肯定是8，对吧？或者也许是一个被压在一起的 13，如果你能想到这个想法的话。但它肯定不是 2。既然你知道这一点，那么在这里返回最大熵分布将是一个错误。但这似乎正是狄利克雷分布模型倾向于做的事情。</p><p>我希望高阶模型与论文中其他所有内容之间的不同行为是因为这些方法具有不同的背景假设，如果我们知道我们在做什么，我们可以在适当的时候灵活地使用不同的假设。</p><p></p><h2>我未来想从事这个领域的工作</h2><ul><li>更大的尺度<ul><li>对 Transformer 语言模型的不确定性估计进行基准测试。</li></ul></li><li>搜索的鲁棒性<ul><li>看看认知不确定性对对抗性例子有何影响。</li><li>分析找到新的对抗性例子来欺骗不确定性估计和原始指​​标是多么容易。检查这些例子对人类来说是否自然。</li></ul></li><li>非压差噪声<ul><li>当您向神经网络添加噪声时，改进采样的理论。</li><li>对不同类型的噪声进行相互比较和其他方法的基准测试。</li></ul></li><li>合奏带来更多聪明的事情<ul><li>测试改变架构的集成。</li><li>测试正在探索“相同”潜在特征的集合。</li></ul></li><li>更好的高阶模型<ul><li>发展神经网络学习二阶分布的贝叶斯视角。</li><li>通过尝试转化理论和修补信号（例如预测未来更新），为高阶模型开发更好的训练方法。</li><li>弄清楚如何使用高阶建模来获得不同背景假设的不确定性。</li></ul></li><li>更好的比较<ul><li>更系统地比较校准和 Brier 评分。</li><li>对决策问题进行基准测试，为分布数据之外的“良好行为”提供具体标准。</li><li>开发包含“自然”分布泛化的标记数据集，我们可以将其类比为现实世界中模型完成的 OOD 泛化。</li></ul></li><li>更多协同效应<ul><li>通过将多种方法结合在一起，可以获得更好的结果。校准太容易与一切结合起来，尽管它仍然是一个好主意，但这不算新闻。</li></ul></li></ul><p>如果这些论文确实存在而我错过了，请告诉我。如果他们不这样做，并且其中一个项目听起来像是您想做的事情，请联系我 - 我很乐意聊天。</p><p></p><h2>与一致性、结论的相关性</h2><p>文献与对齐的相关性不如我的预期，但这主要是因为我的期望被混淆了。我对某种“人类价值观的不确定性”感兴趣，它不同于文献中的“任意”或“认知”不确定性。</p><p>任意不确定性是从数据中得知的，但我们没有人类价值观的真实标签。或者，如果模型中有一些与人类价值观相关的潜在特征，我们不仅仅想了解该特征在某些训练集上的方差。</p><p>认知不确定性更接近，但正如文献中所使用的那样，它实际上是关于某些输出或特征对于训练目标的有用程度。在训练过程中收敛到相同答案的模型越多，认知不确定性就越小。但相对于我想要的，这感觉好像缺少一些关于首先使用什么训练程序或特征检测程序的不确定性<span class="footnote-reference" role="doc-noteref" id="fnrefmyfeye042z"><sup><a href="#fnmyfeye042z">[37]</a></sup></span> 。</p><p>正确的训练/特征检测程序的不确定性偏离了“有一个基本事实答案，不确定性是与该答案的预期偏差”的通常范式。为了保持一致，我认为图片应该更像是通信——我们试图通过架构和数据向人工智能传达一些信息，而人工智能应该对如何解释它有不确定性。</p><p>构建这种关于人类价值观的不确定性是相当棘手的——我什至还不知道我想从中得到什么！也许如果我们更清楚地理解我们想要什么，我们就可以用更标准的不确定性来构建它。例如，我们可以设计一个人工智能可以玩的“游戏”，激励对人类概念的不同解释，这样游戏中的任意和认知不确定性就可以充分捕捉到我们希望人工智能对人类价值观具有的不确定性。</p><p></p><p><i>这篇文章部分写于</i><a href="https://www.mitalignment.org/"><i>MAIA</i></a> <i>。谢谢玛雅！还有贾斯蒂斯·米尔斯（Justis Mills）进行编辑，以及波士顿的各种人士进行对话。</i> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn80ywo0pbl8r"> <span class="footnote-back-link"><sup><strong><a href="#fnref80ywo0pbl8r">^</a></strong></sup></span><div class="footnote-content"><p>主动学习文献调查。<i>伯尔·塞特尔斯</i>(2010) <a href="https://burrsettles.com/pub/settles.activelearning.pdf">https://burrsetles.com/pub/settles.activelearning.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnq23duy4ut0g"> <span class="footnote-back-link"><sup><strong><a href="#fnrefq23duy4ut0g">^</a></strong></sup></span><div class="footnote-content"><p>优化器的诅咒：决策分析中的怀疑主义和决策后惊喜。<i>詹姆斯·E·史密斯、罗伯特·L·温克勒</i>(2006) <a href="https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1050.0451">https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1050.0451</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn3dij2j9svj8"> <span class="footnote-back-link"><sup><strong><a href="#fnref3dij2j9svj8">^</a></strong></sup></span><div class="footnote-content"><p>用于检测神经网络中错误分类和分布外示例的基线。<i>丹·亨德里克斯、凯文·金佩尔</i>(2016) <a href="https://arxiv.org/abs/1610.02136">https://arxiv.org/abs/1610.02136</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnfo4svcpvxs"> <span class="footnote-back-link"><sup><strong><a href="#fnreffo4svcpvxs">^</a></strong></sup></span><div class="footnote-content"><p>使用贝叶斯统计进行神经网络不确定性评估并应用于遥感。 <i>F. Aires、C. Prigent、WB Rossow</i> (2004)</p><p>第 1 部分：网络权重<a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004173">https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004173</a></p><p>第 2 部分：输出错误<a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004174">https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004174</a></p><p>第 3 部分：网络雅可比矩阵<a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004175">https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004175</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fncogdul3x2xj"> <span class="footnote-back-link"><sup><strong><a href="#fnrefcogdul3x2xj">^</a></strong></sup></span><div class="footnote-content"><p>深度学习中不确定性估计的通用框架。<i>安东尼奥·洛奎西奥、马蒂亚·塞古、大卫·斯卡拉穆扎</i>(2020) <a href="https://www.zora.uzh.ch/id/eprint/197704/1/RAL20_Loquercio.pdf">https://www.zora.uzh.ch/id/eprint/197704/1/RAL20_Loquercio.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnamk58pvab4"> <span class="footnote-back-link"><sup><strong><a href="#fnrefamk58pvab4">^</a></strong></sup></span><div class="footnote-content"><p>如果<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="P(parameters)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;">p</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">（</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">r</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">r</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">）</span></span></span></span></span></span></span>是高斯（指定的L2正则化）， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(dataset \; | \; parameters)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">并且</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">您</span></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">的</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">损失</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">是</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">对</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">损失</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">，</span></span></span></span></span></span></span>则这是正确的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(dataset \; | \; parameters)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">r</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">r</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">）</span></span></span></span></span></span></span>是它的指数。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnlpb1b2qcoen"> <span class="footnote-back-link"><sup><strong><a href="#fnreflpb1b2qcoen">^</a></strong></sup></span><div class="footnote-content"><p>神经网络中的不确定性：大约是贝叶斯的结合。<i>蒂姆·皮尔斯（Tim Pearce），菲利克斯·莱布里德（Felix Leibfried），亚历山德拉·布林特鲁普（Alexandra Brintrup），穆罕默德·扎基（Mohamed Zaki），安迪·尼利（Andy Neely）</i> <a href="http://proceedings.mlr.press/v108/pearce20a/pearce20a.pdf">（</a> 2020）</p></div></li><li class="footnote-item" role="doc-endnote" id="fnd9jz9mfml"> <span class="footnote-back-link"><sup><strong><a href="#fnrefd9jz9mfml">^</a></strong></sup></span><div class="footnote-content"><p>最明显的问题是Hessian的奇异性。但是，损失格局可能会在短长度上皱纹，有时使低阶近似值失败。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnbct5kii2m07"> <span class="footnote-back-link"><sup><strong><a href="#fnrefbct5kii2m07">^</a></strong></sup></span><div class="footnote-content"><p>迈向神经网络的校准且可扩展的不确定性表示。 <i>Nabeel Seedat，Christopher Kanan</i> （2019） <a href="https://arxiv.org/abs/1911.00104">https://arxiv.org/abs/1911.00104</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnen0yeoqzg0k"> <span class="footnote-back-link"><sup><strong><a href="#fnrefen0yeoqzg0k">^</a></strong></sup></span><div class="footnote-content"><p>简单可扩展的预测性不确定性使用深层合奏。 <i>Balaji Lakshminarayanan，Alexander Pritzel，Charles Blundell</i> （2017） <a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/9ef2ed4b7fd2c810847ffa5fa85bce38-Paper.pdf">https://proceedings.neurips.cc/prape_files/prape/prape/2017/file/9ef2ed4b7fd2c810847ffa5fa5bce385fa5bce38-fa85bce38-paper.paper.paper.paper.paper.paper.papdfdfffa</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnxqxuuw1xe2"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxqxuuw1xe2">^</a></strong></sup></span><div class="footnote-content"><p>在贝叶斯深度学习计算机视觉中，我们需要哪些不确定性？ <i>Alex Kendall, Yarin Gal</i> (2017) <a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/2650d6089a6d640c5e85b2b88265dc2b-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2017/file/2650d6089a6d640c5e85b2b88265dc2b-Paper.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn2jiolbj6tn8"> <span class="footnote-back-link"><sup><strong><a href="#fnref2jiolbj6tn8">^</a></strong></sup></span><div class="footnote-content"><p>从希腊的根源“关于知识”和“关于赌博”。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnud7l8eu73jk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefud7l8eu73jk">^</a></strong></sup></span><div class="footnote-content"><p>如何仅给定型号的权重， <i>dkirmani</i> （2023） <a href="https://www.lesswrong.com/posts/tvLi8CyvvSHrfte4P/how-2-tell-if-ur-input-is-out-of-distribution-given-only">https://www.lesswrong.com/posts/tvli8cyvvshrfte4p/how-2-tell-2-tell-2-tell-if-if-ur-input-input-input-input--- - 分布赋予</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnlgnhfp0m35e"><span class="footnote-back-link"><sup><strong><a href="#fnreflgnhfp0m35e">^</a></strong></sup></span><div class="footnote-content"><p>噪音存在于现实世界中，因此，如果小输入噪音会改变您的答案，那么您不应该对此充满信心。相反，在行为良好的输入中，神经网络学会对噪声变得强大。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnhfox6k7gfev"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhfox6k7gfev">^</a></strong></sup></span><div class="footnote-content"><p>密集回归的无训练不确定性估计：敏感性作为替代物。 <i>Lu Mi，Hao Wang，Yonglong Tian，Hao He，Nir Shavit</i> （2022） <a href="https://arxiv.org/abs/1910.04858">https://arxiv.org/abs/1910.04858</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn0hl862nst9f9"> <span class="footnote-back-link"><sup><strong><a href="#fnref0hl862nst9f9">^</a></strong></sup></span><div class="footnote-content"><p>深度神经网络中不确定性的调查。 <i>Jakob Gawlikowski等。</i> （2021） <a href="https://arxiv.org/abs/2107.03342">https://arxiv.org/abs/2107.03342</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnu11lguv41wc"> <span class="footnote-back-link"><sup><strong><a href="#fnrefu11lguv41wc">^</a></strong></sup></span><div class="footnote-content"><p>估计心脏MRI分割神经网络中的不确定性：一项基准研究。 Matthew Ng，Fumin Guo，Labonny Biswas，Steffen <a href="https://ieeexplore.ieee.org/abstract/document/10002847">E.</a> <i>Petersen，Stefan K. Piechnik，Stefan Neubauer，Graham Wright</i> （2023）</p></div></li><li class="footnote-item" role="doc-endnote" id="fnhzxdsrsco9g"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhzxdsrsco9g">^</a></strong></sup></span><div class="footnote-content"><p>您能相信模型的不确定性吗？评估数据集偏移下的预测不确定性。 <i>Yaniv Ovadia，Emily Fertig，Jie Ren，Zachary Nado，D Sculley，Sebastian Nowozin，Joshua V. Dillon，Balaji Lakshminarayanan，Jasper Snoek</i> <a href="https://arxiv.org/abs/1906.02530">（</a> 2019）</p></div></li><li class="footnote-item" role="doc-endnote" id="fnfqljh5j8ipf"> <span class="footnote-back-link"><sup><strong><a href="#fnreffqljh5j8ipf">^</a></strong></sup></span><div class="footnote-content"><p>深层神经网络倾向于可预测。 <i>Katie Kang，Amrith Setlur，Claire Tomlin，Sergey Levine</i> （2023） <a href="https://arxiv.org/abs/2310.00873">https://arxiv.org/abs/2310.00873</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnvl2ahm3user"> <span class="footnote-back-link"><sup><strong><a href="#fnrefvl2ahm3user">^</a></strong></sup></span><div class="footnote-content"><p>对于分布外检测似乎有些普遍，例如增强神经网络中分布外图像检测的可靠性。 <i>Shiyu Liang，Yixuan Li，R。Srikant</i> （2020） <a href="https://arxiv.org/abs/1706.02690">https://arxiv.org/abs/1706.02690</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnzkojoz799ka"> <span class="footnote-back-link"><sup><strong><a href="#fnrefzkojoz799ka">^</a></strong></sup></span><div class="footnote-content"><p> GPT-4技术报告。 <i>Openai</i> （2023） <a href="https://openai.com/research/gpt-4">https://openai.com/research/gpt-4</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnnglt70rybd9"> <span class="footnote-back-link"><sup><strong><a href="#fnrefnglt70rybd9">^</a></strong></sup></span><div class="footnote-content"><p> Mix-n匹配：深度学习中不确定性校准的合奏和组成方法。 <i>Jize Zhang，Bhavya Kailkhura，T。Yong-Jin Han</i> （2020） <a href="https://arxiv.org/abs/2003.07329">https://arxiv.org/abs/2003.07329</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fngx8tqfun0w"> <span class="footnote-back-link"><sup><strong><a href="#fnrefgx8tqfun0w">^</a></strong></sup></span><div class="footnote-content"><p>不确定性定量和深层合奏。 <i>Rahul Rahaman，Alexandre H. Thiery</i> （2020） <a href="https://arxiv.org/abs/2007.08792">https://arxiv.org/abs/2007.08792</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fntmgq2x5m6t"> <span class="footnote-back-link"><sup><strong><a href="#fnreftmgq2x5m6t">^</a></strong></sup></span><div class="footnote-content"><p>在分布数据集上校准深度神经网络分类器。 <i>Zhihui Shao，Jianyi Yang，Shaolei Ren</i> （2020） <a href="https://arxiv.org/abs/2006.08914">https://arxiv.org/abs/2006.08914</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fng3rtbqm4247"> <span class="footnote-back-link"><sup><strong><a href="#fnrefg3rtbqm4247">^</a></strong></sup></span><div class="footnote-content"><p>归纳性共形预测：对神经网络的理论和应用。 <i>Harris Papadopoulos</i> （2008） <a href="https://www.intechopen.com/chapters/5294">https://www.intechopen.com/chapters/5294</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnqbdlqupa3x"> <span class="footnote-back-link"><sup><strong><a href="#fnrefqbdlqupa3x">^</a></strong></sup></span><div class="footnote-content"><p>通过logit归一化来缓解神经网络过度自信。 <i>Hongxin Wei，Renchunzi Xie，Hao Cheng，Lei Feng，Bo An，Yixuan li</i> （2022） <a href="https://proceedings.mlr.press/v162/wei22d/wei22d.pdf">https://proceedings.mlr.press/v162/wei222d/wei22d/wei22d.pdf.pdf.pdf.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn2qfcvdqkx2y"> <span class="footnote-back-link"><sup><strong><a href="#fnref2qfcvdqkx2y">^</a></strong></sup></span><div class="footnote-content"><p>使用噪声对比的先验，深度神经网络中可靠的不确定性估计。 <i>Danijar Hafner，Dustin Tran，Timothy Lillicrap，Alex Irpan，James Davidson</i> （2018） <a href="https://openreview.net/forum?id=HkgxasA5Ym">https://openreview.net/forum?id=hkgxasa5ym</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnazba93s687"> <span class="footnote-back-link"><sup><strong><a href="#fnrefazba93s687">^</a></strong></sup></span><div class="footnote-content"><p>通过对抗训练和预训练改善了OOD的概括。 <i>Mingyang Yi，Lu Hou，Jicheng Sun，Lifeng Shang，Xin Jiang，Qun Liu，Zhi-Ming MA</i> （2021） <a href="http://proceedings.mlr.press/v139/yi21a/yi21a.pdf">http://proceedings.mlr.press/v139/v139/yi21a/yi21a/yii21a/yii21a.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnv1gf6chx43"> <span class="footnote-back-link"><sup><strong><a href="#fnrefv1gf6chx43">^</a></strong></sup></span><div class="footnote-content"><p> SolidGoldMagikarp（加上及时生成）。<i>杰西卡·伦贝洛（Jessica Rumbelow），马修·沃特金斯</i>（2023）<i> </i><a href="https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation">https://www.lesswrong.com/posts/apeje8bso6rafolqg/solidgoldmagikarp-plus-prompt-generation</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fna3kc8qjhdn6"> <span class="footnote-back-link"><sup><strong><a href="#fnrefa3kc8qjhdn6">^</a></strong></sup></span><div class="footnote-content"><p>对抗性示例不是错误，它们是功能。<i>安德鲁·伊利亚斯（Andrew Ilyas）等人。</i> （2019） <a href="https://arxiv.org/abs/1905.02175">https://arxiv.org/abs/1905.02175</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn28983dpfjdp"> <span class="footnote-back-link"><sup><strong><a href="#fnref28983dpfjdp">^</a></strong></sup></span><div class="footnote-content"><p>如果我们使用生成而不是搜索来构建良好的输出，则可以避开不强大的优化的问题。或在RL上下文中，如果我们使用策略预测器将我们保持在系统的有效性领域中。但这是昂贵的，有时容易以不同速度推广的能力。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnkm10b29by7c"> <span class="footnote-back-link"><sup><strong><a href="#fnrefkm10b29by7c">^</a></strong></sup></span><div class="footnote-content"><p>证据深度学习以量化分类不确定性。 <i>Murat Sensoy，Lance Kaplan，Melih Kandemir</i> （2018） <a href="https://arxiv.org/abs/1806.01768">https://arxiv.org/abs/1806.01768</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnhfc8x4hav0b"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhfc8x4hav0b">^</a></strong></sup></span><div class="footnote-content"><p>使用Dirichlet深神经网络识别室外对象。<i>艾哈迈德·哈马姆（Ahmed Hammam），弗兰克·邦纳斯（Frank Bonarens</i> <a href="https://openaccess.thecvf.com/content/ICCV2023W/UnCV/papers/Hammam_Identifying_Out-of-Domain_Objects_with_Dirichlet_Deep_Neural_Networks_ICCVW_2023_paper.pdf">）</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnffdudph3qus"> <span class="footnote-back-link"><sup><strong><a href="#fnrefffdudph3qus">^</a></strong></sup></span><div class="footnote-content"><p>教学模型以表达他们的文字不确定性。 <i>Stephanie Lin，Jacob Hilton，Owain Evans</i> （2023） <a href="https://openreview.net/forum?id=8s8K2UZGTZ">https://openreview.net/forum?id=8S8S8K2UZGTZ</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnadsp4hkxuk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefadsp4hkxuk">^</a></strong></sup></span><div class="footnote-content"><p>直接从GPT-3引起概率。 <i>nuno sempere</i> （2023） <a href="https://forum.effectivealtruism.org/posts/aGmhi4uvAJptY8TA7/straightforwardly-eliciting-probabilities-from-gpt-3#Fine_tune_the_model_on_good_worked_examples_of_forecasting_reasoning">https://forum.effectivealtruism.org/posts/agmhi4uvajpty8ta7/straightforwardforwardforwardly-eliciting-probability-probabilities-probabilities-from-gpt-from-gpt-fine_tune_tune_tune_the_model_good_good_good_good_model_of_exam__exame_examequarky_examectimed_exampleastion_ofrachiquest</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnxuwhb9ieyh"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxuwhb9ieyh">^</a></strong></sup></span><div class="footnote-content"><p>关于认知不确定性定量的二阶评分规则。 <i>Viktor Bengs，EykeHüllerMeier，Willem Weegeman</i> （2023） <a href="https://arxiv.org/abs/2301.12736">https://arxiv.org/abs/2301.12736</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnmyfeye042z"> <span class="footnote-back-link"><sup><strong><a href="#fnrefmyfeye042z">^</a></strong></sup></span><div class="footnote-content"><p>我还可能会提及要使用哪些抽象或使用哪种推理过程的不确定性。但是这些似乎是训练的下游。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/79eegmp3ebs8ptfqa/neural-unclentity-unclenty-simation-for-anignment<guid ispermalink="false"> 79EEGMP3EBS8PTFQA</guid><dc:creator><![CDATA[Charlie Steiner]]></dc:creator><pubDate> Tue, 05 Dec 2023 08:01:32 GMT</pubDate></item><item><title><![CDATA[Analyzing the Historical Rate of Catastrophes]]></title><description><![CDATA[Published on December 5, 2023 6:30 AM GMT<br/><br/><p>为了传达风险，我们经常转向故事。核武器会想到相互保证的破坏，红色按钮和核冬季的故事。气候变化总结了极端天气的故事，由于海平面上升而超过了农作物的失败。大流行时期的同性恋几乎不需要想象力，但以前是<em><a href="https://en.wikipedia.org/wiki/Contagion_(2011_film)?ref=bounded-regret.ghost.io">传染病</a></em>等电影的主题。</p><p>故事非常适合传达具体的风险（我本人<a href="https://bounded-regret.ghost.io/gpt-2030-and-catastrophic-drives-four-vignettes/">最近为AI风险做到这一点</a>），但它们是预测未来的糟糕方式。那是因为大多数故事太具体了，无法可能。更重要的是，故事倾向于以短暂的，简单的因果关系为特色，而现实是复杂且多元的。</p><p>大多数竞争性预报员没有使用故事，而是通过查看历史<a href="https://forecasting.quarto.pub/book/base-rates.html?ref=bounded-regret.ghost.io">参考课</a>来开始他们的预测。这确实很好，而且也很有意义：历史使我们摆脱了实际发生的事件的基础，使我们摆脱了讲故事的偏见。尽管历史是通过叙述过滤的，但良好的历史将与现实的复杂性有关，我们可以通过原始数字来进一步剥离叙事。 <sup><a href="#fn1">[1]</a></sup></p><p>在这篇文章中，我将使用参考课来了解社会当今面临的最大风险。我将考虑两个不同的历史灾难参考课程来做到这一点：</p><ul><li>杀死了全球人口中很大一部分的事件（<a href="#historical-causes-of-human-population-loss">第1节</a>）</li><li>物种的灭绝，尤其是大规模灭绝事件（<a href="#species-extinctions">第2节</a>）</li></ul><p>查看这些参考课程教会了我们两件事。首先，它为我们提供了不同不同灾难的数值估计。如果我们将一场灾难定义为一场事件，在十年内杀死了1％的全球人口，那么自1500年以来就发生了11起这样的灾难，每年的基本速度为2％。如果我们将标准提高到杀死10％的人口，则基本利率下降了一个数量级，至0.2％。</p><p>历史也为我们提供了定性的见解。例如，上一段中的所有灾难都是流行病，战争或饥荒。此外，许多事件都是多因果的 - 最糟糕的流行病是在人口已经被饥荒削弱时发生的，而气候变化或政治动荡促成了许多流行病和饥荒。物种的灭绝也是多因果的，常见的罪魁祸首是气候变化，自然灾害，入侵物种和人类。</p><p>反对使用历史基本利率的一个论点是，现在与过去有很大不同（例如由于技术引起的），以至于基本费率毫无意义。尽管当今的世界确实与过去不同，但基本费率可以通过澄清实际情况来帮助增强而不是忽略这些差异。例如，技术的存在不能使我们远远超过基本速率，因为许多技术在整个历史上已经开发了，没有任何技术在上面定义的意义上造成了灾难。取而代之的是，我们应该寻找与灾难的历史驱动因素共享财产的技术：流行病，饥荒，战争，政治动荡，气候变化，自然灾害，入侵物种和人类。</p><p>我详细分析了这些驱动程序（<a href="#takeaways-for-modern-catastrophes-and-for-ai">第3节</a>），发现它们属于几个核心群体：</p><ul><li>自然事件的规模是全球或区域性的（饥荒，气候变化，自然灾害）</li><li>新颖的，高度适应的，自我复制的生物（流行病，新病原体和捕食者，入侵物种）</li><li>协调的人类寻求资源，土地或权力（战争，政治动荡，灭绝和栖息地破坏引起的灭绝）</li></ul><p>此列表是有道理的 - 要产生全球影响，应该从全球范围（大型自然事件）开始，或者有能力到达那里的手段（自我复制，协调）。</p><p>从这个角度来看，21世纪的灾难驱动因素是什么？从上面的列表中可以明显看出一些答案 - 助手，气候变化和重大战争仍然是严重的威胁。饥荒不太明显地威胁性，因为最后一个主要是1961年，但为饥荒的准备仍然可能是谨慎的。而政治动荡本身并非灾难性，为其他灾难带来了发生的条件。</p><p>转向新技术，工程病原体是危险的，因为它们是新型的自我复制者，<a href="https://en.wikipedia.org/wiki/Gray_goo?ref=bounded-regret.ghost.io">某些类型的纳米技术</a>也是如此。核武器是危险的，因为它们与自然灾害具有相似的影响，并且因为它们增加了战争中最严重的损害。</p><p>最后，不幸的是，AI（我自己的研究领域）与许多灾难驱动因素具有共同的特性。它是一种新颖的自我复制器（可以复制自身），可以快速适应新数据。可以对AI系统<a href="https://arxiv.org/abs/1705.08926?ref=bounded-regret.ghost.io">进行培训以协调</a>并<a href="https://bounded-regret.ghost.io/intrinsic-drives-and-extrinsic-misuse-two-intertwined-risks-of-ai/">寻求权力</a>，从而反映人类协调群体的威胁。最后，如果AI导致经济动荡和随后的政治动荡，可能会加剧其他灾难的驱动因素。</p><h1>人口损失的历史原因</h1><p>为了开始我们的分析，我研究了人口损失的最大历史原因，这是由被给定事件杀死的全球人口的比例来衡量的。为此，我结合了Wikipedia的<a href="https://en.m.wikipedia.org/wiki/List_of_anthropogenic_disasters_by_death_toll?ref=bounded-regret.ghost.io#Wars_and_armed_conflicts">主要战争</a>， <a href="https://en.m.wikipedia.org/wiki/List_of_anthropogenic_disasters_by_death_toll?ref=bounded-regret.ghost.io#Abuse_of_workers,_forced_laborers_and_slaves">奴隶制和其他强迫劳动</a>，<a href="https://en.m.wikipedia.org/wiki/List_of_famines?ref=bounded-regret.ghost.io">饥荒</a>， <a href="https://en.m.wikipedia.org/wiki/List_of_epidemics_and_pandemics?ref=bounded-regret.ghost.io">流行病</a>和<a href="https://en.m.wikipedia.org/wiki/List_of_natural_disasters_by_death_toll?ref=bounded-regret.ghost.io">自然灾害的</a>数据。我考虑了其他数据来源，例如技术灾难，但所有这些数据来源的死亡人数比上面的五个要小得多。主要例外是种族灭绝，因为它们通常与战争同时发生，并且已经包含在那些死亡人数中，因此我排除了它们以避免双重计数。</p><p>我编写了一个Python脚本（在<a href="#scraping-script">附录</a>中共享）来刮擦这些来源并将它们汇总到单个PANDAS DataFrame中，然后被过滤以创建两个数据集：</p><ul><li><strong>灾难性</strong>：所有事件杀死至少0.1％的人口的事件，这些事件通过在事件开始时被世界人口划分的总死亡而计算出来。 <sup><a href="#fn2">[2]</a></sup> <sup><a href="#fn3">[3]</a></sup></li><li><strong>严格的灾难</strong>：我进一步局限于“快速”（持续不到十年）的事件，其中至少有1％的人口死亡。</li></ul><p>一组灾难包括85个事件，其中80起发生以来发生，其中33例是战争，28人是饥荒，15例是流行病，有6人是强迫劳动，而3例是自然灾害。严格的灾难包括17个事件：5场战争，8种饥荒和4个流行病。我在下面包括严格的灾难的完整列表，以及所有灾难的散点图（有关原始数据，请参见<a href="#scraping-script">附录</a>）。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/zsdej27vshx817jxxgzq"></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/aoh79fzuiwbvftkounrs"></p><p>除了这些历史事件外，两个重要的史前事件是<a href="https://en.wikipedia.org/wiki/Toba_catastrophe_theory?ref=bounded-regret.ghost.io">Toba灾难</a>（人口下降了97％，可能是由于Supervolcano的造成的）和<a href="https://en.wikipedia.org/wiki/4.2-kiloyear_event?ref=bounded-regret.ghost.io">4.2KYA事件</a>（可能导致全球饥荒，但死亡人数尚不清楚）。</p><p><strong>报告偏见和基本费率。</strong>由于我们看到1500年代和1900年代再次灾难的速度“增加”的速度很可能会有偏见，而且这对于包括饥荒在内的所有类别都会发生这种情况（随着时间的推移会随着时间的推移而降低）。如果我们从1500起开始，则发生了51次灾难（0.11/年），有11例严格的灾难（0.02/年）。</p><p>让我们下一个模型（快速）灾难<sup><a href="#fn4">[4]</a></sup>的基本速率如何随其严重程度而变化。查看所有导致人口至少下降1％的灾难，我们看到了大约<a href="https://en.wikipedia.org/wiki/Zipf%27s_law?ref=bounded-regret.ghost.io">Zipfian</a>分布：死亡率为R的灾难的可能性与1/R成正比。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/wgfcegdndv1dtfwggmzl"></p><p>基于此，死亡率10％的灾难的发生率为0.002/年（每5世纪一次），死亡率为1％的灾难发生0.02/年（每世纪两次）。尽管这些数字似乎很低，但它们表明，<strong>在未来25年中，大约有10％的灾难灾难的机会大约有5％的机会</strong>（由于0.002 * 25 = 0.05）。</p><p>低于1％的死亡率，灾难比ZIPF定律预测的可能性少（请参阅<a href="#log-log-plot-of-catastrophes">附录</a>）。例如，0.1％死亡率的经验频率为0.08/年（略低于每十年一次）。</p><p><strong>随着时间的推移趋势。</strong>如果我们计算自1500年以来每十年的灾难，我们将获得以下图： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/wb5os0qkd9psxc2zrno9"></p><p>在1850  -  1950年期间，还有更多的灾难，尽管我怀疑这是报告偏见的文物。在此期间之前，随着时间的流逝，灾难的发生率大致恒定： <a href="https://en.wikipedia.org/wiki/Ljung%E2%80%93Box_test?ref=bounded-regret.ghost.io">Ljung-box测试</a>和<a href="https://en.wikipedia.org/wiki/Wald%E2%80%93Wolfowitz_runs_test?ref=bounded-regret.ghost.io">Wald-Wolfowitz测试</a>都不能拒绝在数十年中从1500-1900数十年来分布灾难的零（P = 0.36和0.26） ， 分别）。</p><p>随着时间的流逝，最值得注意的变化是我们目前处于平静时期，从1950  -  1960年左右开始。确实，自20世纪上半叶以来，灾难显着下降：</p><ul><li> 9个饥荒发生在20世纪上半叶，但下半年只有1次（中国饥荒，1959- 1961年）</li><li>上半场发生了5场重大战争，但下半场只有1次（朝鲜战争，1950- 1953年）</li><li>流行病更为恒定，上半场有2个，下半场有1个（加2019年的Covid）。</li></ul><p>由于粮食生产和储存量更好，饥荒可能会减少，这是持久的改善。战争可能由于<a href="https://en.wikipedia.org/wiki/Pax_Americana?ref=bounded-regret.ghost.io">PAX Americana</a>而减少，但不幸的是，由于日益增长的全球紧张局势可能会放松。因此，流行病和（可能）战争是迄今为止灾难的主要现代来源。</p><p><strong>定性分析：多用途。</strong>许多灾难有多种原因。例如，在黑死的主要理论中，气候变化是两种方式的驱动力。首先，亚洲的气候变化导致啮齿动物从山区迁移到人口更多的地区，从而传播了这种疾病。其次，欧洲的小冰河时代导致饥荒，导致人口疲软，因此更容易受到疾病的影响。 <sup><a href="#fn5">[5]</a></sup>有趣的是，黑死亡也可能通过造成人口减少的重新森林造成造林，从而加剧了较小的冰河时代，从而导致碳捕获和随后的冷却。</p><p>给出其他多种原因的例子：</p><ul><li>在美洲的欧洲殖民化中，大多数死亡是由于疾病而不是战争造成的。</li><li>从明对的过渡是由许多因素引起的，包括疾病和饥荒。饥荒本身可能是由小冰河时代引起的。</li><li> Taiping叛乱是由于饥荒的政治动荡而开始的，随后的许多死亡是由干旱，饥荒和疾病而不是军事死亡引起的。</li><li>总的来说，许多饥荒是由气候事件和/或不良政府政策造成的。</li></ul><p>总体而言，这表明要减少灾难的数量或强度，我们不仅应立即攻击原因，而且还应攻击更多的系统性上游原因。</p><h1>物种灭绝</h1><p>作为第二个参考类别，我考虑了非人类物种的灭绝。 <sup><a href="#fn6">[6]</a></sup>由于几个原因，这更难分析：</p><ul><li>大多数灭绝发生在数百万年前，因此我们只有间接证据，并且存在明显的采样偏见，因为某些物种更容易保存为化石。</li><li>如果一个物种逐渐适应一种新物种，我们可能不想将其算作“灾难”。</li><li>一些声称的质量灭绝事件实际上可能是一段时间内发生的许多较小事件。</li></ul><p>为了减少这些困难，我将专注于两个相对较新的灭绝事件：</p><ul><li>第四纪晚期灭绝（ <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev.ecolsys.34.011802.132415?journalCode=ecolsys&amp;ref=bounded-regret.ghost.io">Koch and Barnosky，2006年</a>），发生在10,000-50,000年前，导致大多数大型哺乳动物灭绝。</li><li><a href="https://en.wikipedia.org/wiki/Holocene_extinction?ref=bounded-regret.ghost.io">全新世灭绝</a>发生在过去10，000年中（在过去的一个世纪中增加），主要是由人类的狩猎和栖息地破坏驱动。</li></ul><p>尽管大多数历史大规模灭绝事件都是由气候变化或自然灾害驱动的，但这两个最近的灭绝事件被认为是人类全部或部分驱动的。我将在下面回顾有关两个灭绝事件的证据和领导理论。</p><h2>历史基本率</h2><p>在讨论第四纪和全新世灭绝之前，让我们计算上下文的基本费率。根据化石记录，平均<a href="https://en.wikipedia.org/wiki/Background_extinction_rate?ref=bounded-regret.ghost.io">每百万年每种物种大约有一个灭绝</a>。 <sup><a href="#fn7">[7]</a></sup>但是，这些灭绝并不是在时间的范围内恒定，而是以“脉冲”为中，如下所示（ <a href="https://en.wikipedia.org/wiki/Extinction_event?ref=bounded-regret.ghost.io">Wikipedia的</a>图像）： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/dfuifcmc1rwf6nughndc"></p><p>在这些脉冲中，每百万年的灭绝量大约是背景速率2-10倍。 <sup><a href="#fn8">[8]</a></sup></p><h2>第四纪晚期灭绝</h2><p><a href="https://en.wikipedia.org/wiki/Quaternary_extinction_event?ref=bounded-regret.ghost.io">第四纪晚期的灭绝</a>将一段时间从约50,000年前到10，000年前。在这段时间里，大约34％的哺乳动物灭绝了，包括美洲和澳大利亚的大多数哺乳动物以及全球几乎所有大型哺乳动物。这是一个比预期的背景灭绝率高的数量级（在40，000年内约为4％）。</p><p>下面的表（根据Wikipedia改编）按地理区域和规模灭绝的文档灭绝： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/hyklusibuiqlssx8a9j4"></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/xfvtfxj13q8vij8qqsmx"></p><p>如表所示，灭绝在非洲（人类起源的地方，因此哺乳动物可以共同进化），并且在大型哺乳动物中最为严重。</p><p><strong>原因。</strong>从历史上看，研究人员辩论了这些灭绝是由气候变化还是人类接触驱动的。为了理解这场辩论，我阅读了几篇论文，并选择关注<a href="https://www.annualreviews.org/doi/abs/10.1146/annurev.ecolsys.34.011802.132415?journalCode=ecolsys&amp;ref=bounded-regret.ghost.io">Koch＆Barnosky（2006）</a> ，该论文系统地回顾了许多竞争理论。 Koch＆Barnosky得出的结论是，灭绝的模式和强度是由人类驱动的，但是气候变化是重要的额外贡献者：<br><br></p><p> “从整体上讲，最近的研究表明，人类通过联合直接（狩猎）以及间接（竞争，栖息地的改变和碎片化）促进了全球许多地区的灭绝，但是晚期的环境变化影响了时机，地理，地理位置影响，也许是灭绝的大小。换句话说，没有<i>智人智人</i>的各种影响，在晚期季季晚期，全球生态系统极不可能经历大型慢养动物的大规模灭绝。但是，没有同时存在的快速气候变化在全球许多地区明显看出，某些物种可能持续更长的时间。”</p><p>因此，人类可能会驱动灭绝的几条途径：</p><ul><li>直接狩猎</li><li>间接狩猎（狗，老鼠和我们带来的其他动物）</li><li>栖息地破坏（例如，人为火灾）</li></ul><p>重要的是，由于不同的原因，不同的物种可能灭绝。 Koch＆Barnosky认为，欧亚大陆的大多数灭绝都是由于气候变化所致，澳大利亚和大多数岛屿上的灭绝都几乎完全归因于人类，而北美主要是人类具有气候的人类，这是一个加剧的因素。</p><p>这是一个说明关键点的故事。它与Koch＆Barnosky一致，但是不确定性支持简单。</p><ul><li>当人类到达岛屿时，他们带来了猪，狗和大鼠，所有这些都捕食了土著物种。由于岛屿物种在进化上是对这些掠食者的幼稚，因此许多物种灭绝了。</li><li>由于火和土地清理造成的栖息地破坏也导致了岛屿灭绝。</li><li>在较大的土地上，哺乳动物并不是进化于食肉动物的掠食者，因此并不容易灭绝。但是，人类是非常有效的猎人，足以使许多物种的出生率低于死亡率，这最终导致了数千年的灭绝。</li><li>重要的是，人类的饮食多种多样，因此即使他们狩猎了一些哺乳动物以灭绝，他们也从其他动物和植物那里收集了足够的食物来维持大量人口，从而避免了传统的<a href="https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations?ref=bounded-regret.ghost.io">捕食者捕食周期</a>。</li><li>在非洲和欧亚大陆，哺乳动物与人类或其前辈共同发展了数十万年以上。因此，他们有足够的进化时间来为有效的人类猎人开发防御能力，并解释了与美国和澳大利亚的灭绝率较低。</li></ul><p>总体而言，人类的狩猎可能是非岛屿灭绝的主要驱动力，还有其他因素，例如气候变化。重要的是，人类是一种新颖的捕食者是不够的，因为新的掠食者并不总是会导致灭绝。同样重要的是，我们是一个特别有效的捕食者，可以占据许多地理区域并且饮食多样化。</p><h2>全新世灭绝</h2><p>全新世灭绝开始于大约10，000年前，最近有可能加速，大多数研究人员认为人类发挥了重要作用。</p><p>矛盾的是，尽管最近发生，但全新世灭绝的程度比晚期灭绝晚期更具争议性，原因有两个。首先，大多数其他灭绝计数都取决于化石记录，但全新世灭绝是基于人类的当前和历史观察。这使得很难进行直接比较，因为两种方法具有不同的（且大）的采样偏差。其次，全新世灭绝的程度被政治化，因为它对于当今关于自然保存的论点至关重要，因此很难找到中性来源。</p><p>浏览了几篇论文后，我决定关注<a href="https://www.nature.com/articles/nature09678?ref=bounded-regret.ghost.io">Barnosky等人。 （2011）</a> <sup><a href="#fn9">[9]</a></sup> ，仔细讨论了采样偏见的几种来源，并试图为它们纠正它们。 Barnosky等。得出的结论是，在过去的500年中，总物种中有几个已经灭绝，这比灭绝的预期背景速率高（请注意，某些论文给出了更高的估计<sup><a href="#fn10">[10]</a></sup> ）。 Barnosky等。还得出结论，如果大多数濒危物种在下一个世纪灭绝，并且这种速度持续下去，我们将在几个世纪内失去所有物种中的大多数，仅与5个历史（通常更慢）的大规模灭绝事件相当。</p><p><strong>原因。</strong> Barnosky等。列出几种造成这些灭绝的压力源：“迅速变化的大气条件和变暖[...]，栖息地破碎，污染，过度捕捞和过度狩猎，入侵物种和病原体[...]以及扩大人类生物量”。 <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev.ecolsys.34.011802.132415?journalCode=ecolsys&amp;ref=bounded-regret.ghost.io">Koch and Barnosky（2006）</a>增加了第四纪灭绝的生态破坏，作为进一步的压力源。 <sup><a href="#fn11">[11]</a></sup></p><p>与过去的灭绝不同，我们可以直接观察到当今许多全新世灭绝的原因。基于<a href="https://pubmed.ncbi.nlm.nih.gov/20978281/?ref=bounded-regret.ghost.io">Hoffmann等。 （2010年）</a> ，栖息地破坏是当前灭绝的最大驱动因素，其次是入侵物种（包括疾病）和过度狩猎，其次是环境原因，例如气候变化和污染。 <sup><a href="#fn12">[12]</a></sup> <sup><a href="#fn13">[13]</a></sup></p><h2>摘要：灭绝的典型原因是什么？</h2><p>总体而言，我对过去灭绝的分析指出了一个物种可以灭绝的几种方式：</p><ul><li>大规模的灾难或气候事件直接使物种不可行，或者破坏生态系统并导致后来的灭绝。</li><li>引入了一种新颖的侵略性生物，原始物种尚未适应该生物。这包括：<ul><li>一种入侵物种，它可以直接胜任其利基市场或破坏周围生态系统的物种。</li><li>一种新颖的病原体，特别是如果它具有<a href="https://en.wikipedia.org/wiki/Natural_reservoir?ref=bounded-regret.ghost.io">储层物种</a>。 <sup><a href="#fn14">[14]</a></sup></li><li>一个新的，有效的捕食者。这对岛屿物种影响最大，因为大陆物种在进化上暴露于多种捕食者中，以发展强大的反策略。但是，即使对于非岛屿物种，具有多种饮食的非常有效的捕食者也会淹没这些进化的防御能力。</li></ul></li><li>栖息地的变化（通常来自气候变化或其他物种）。</li><li>其他物种灭绝的后续作用。这部分与上面的项目重叠：例如，大型生动的灭绝导致森林的再生，因此显着改变了其他物种的栖息地。</li></ul><p>因此，通常大多数物种灭绝是由以下原因引起的：</p><ul><li>原始物种没有机会适应的第二种物种。第二种也必须不依赖原始物种来传播自身。</li><li>灾难性的自然灾害或气候事件。</li><li>上面两个来源之一造成的栖息地破坏或生态系统破坏。</li></ul><p><strong>为什么灭绝通常很少见。</strong>由于灭绝通常的基本速率较低，因此灭绝的原因必须很少见。为了更好地了解<em>可能</em>导致灭绝的是什么，让我们理解为什么大多数对物种的威胁<em>不会</em>导致灭绝。</p><p>首先，大多数捕食者不会造成灭绝。这是因为猎物与捕食者的犯罪同时发展防御，而捕食者越好的是猎物上的进化压力越多（因此，防御速度更快）。除此之外，如果猎物变得太罕见，那么捕食者种群<a href="https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations?ref=bounded-regret.ghost.io">通常会崩溃</a>，从而使猎物种群重新成长。因此，捕食者通常只有在（1）两者进入具有非进化适应猎物的新环境时才造成灭绝，并且（2）它们以多种物种为食，以便它们可以驱使一个物种灭绝而不会自身人口崩溃。</p><p>同样，默认情况下，新颖的病原体不会导致宿主灭绝，因为如果它们杀死了太多的宿主物种，他们就没有靶标要传播。取而代之的是，“病原体更有可能引起宿主的灭绝，如果它们……具有长期传染病，或者是可以在普通储层宿主和更脆弱的目标物种之间传播的多宿主病原体”（ <a href="https://www.nature.com/scitable/knowledge/library/disease-ecology-15947677/?ref=bounded-regret.ghost.io">Kilpatrick和Altizer，2010年</a>） 。</p><p><strong>人类。</strong>最后，让我们分析为什么人类尤其是如此有效的猎人，以至于我们能够驱动这么多物种灭绝。首先，我们具有高度适应性的能力，因此不仅能够生存，而且能够在各种环境中依靠多种食物来源。这使我们在全球范围内传播，并驱动一些物种灭绝，同时仍有其他食物来源。其次，我们可以有效地协调（ <a href="https://www.scientificamerican.com/article/how-homo-sapiens-became-the-ultimate-invasive-species/?ref=bounded-regret.ghost.io">Marean，2015年</a>），通过更好的战术使更大的猎物压倒了较大的猎物。最后，我们使用工具和技术来提高狩猎能力并塑造环境，放大上面讨论的两个关键灭绝驱动因素。</p><h1>现代灾难和人工智能的收获</h1><p>我们将所有驱动因素都用于人类灾难和非人类灭绝的驱动因素，我们看到了少数主题：</p><ul><li>非常大规模的自然事件</li><li>高度适应，自我复制的生物，尤其是受害者没有共同适应的生物（流行病，新颖的病原体和捕食者，入侵物种）。</li><li>人类协调的群体（战争，狩猎，栖息地破坏）</li><li>政治镇压或破坏（强迫劳动，不良政策导致饥荒）</li><li>其他灾难的后续作用。</li></ul><p>有趣的是，在大多数人类灾难中，技术似乎并不是直接的罪魁祸首，尽管它可能是发生大规模核战争的。对于非人类的灭绝，这可能是一个贡献者，因为技术提高了狩猎能力和栖息地破坏的便利性。</p><p>鉴于现代威胁，纳米技术和生物技术都威胁着创建新颖的自我复制者，并且人类设计的包含可能会导致它们以与我们进化防御的方式分布的方式“适应”。</p><p>核武器增加了战争的最坏情况，大规模监视增加了政治镇压的最坏情况。</p><p>气候变化是一个大规模的自然事件。除了直接影响，如果它导致非人类物种的许多灭绝或引起政治动荡，那么后续影响可能对人类造成灾难性。由于持续的灭绝而导致的生物多样性损失也可能会造成不良的后续影响，尽管这种影响的发生得很慢，以至于这可能不是直接的威胁。</p><p>最后，我们在此方程式中将AI放在哪里？不幸的是，它似乎拥有许多其他灾难驱动因素的特性：</p><ul><li> AI是可以自我复制的，并且可以训练自己以快速适应新数据的意义。因此，这是一个适应人的自我复制者，人类本身并不适应。</li><li> AI可能会接受比人类更好的培训以更好地坐标，因为从进化上，人类只能以<a href="https://en.wikipedia.org/wiki/Dunbar%27s_number?ref=bounded-regret.ghost.io">〜150</a>的群体进行协调，而如果我们解决了相关的<a href="https://arxiv.org/abs/1705.08926?ref=bounded-regret.ghost.io">多代理RL挑战，</a>则可以对AI进行培训以在任意大型组中进行协调。</li><li> AI的经济流离失所可能导致政治动荡。</li><li> AI还是上述许多其他驱动因素的贡献（尽管可以说是双重计数）：它使大规模监视更加容易，并可能加快创建其他危险技术（例如工程性病原体）的创建。</li></ul><p> AI也具有改善特性。首先，其他新技术并未引起灾难，这应该减少我们对AI的先前。其次，AI辅助研究可以帮助饥荒和气候变化，如果AI增加繁荣，AI可能会减少政治动荡。这些是重要的考虑因素，但是许多技术具有这些特性，而几乎没有一个可以在组中进行协调的自我复制器。</p><p>总体而言，我希望AI会增加灾难的速度。 As <a href="https://docs.google.com/document/d/1DOmluInO2KkgmumAf1wKLKHU7HbMeveIugR_oiFvHPc/edit?ref=bounded-regret.ghost.io#bookmark=id.xu338fnad04c">calculated above</a> , the base rate of very large (10% death rate) catastrophes over the next 25 years is 5%, and I personally expect AI to add an additional 10% on top of that, as I&#39;ll justify in the next邮政。</p><p> <strong>Open questions.</strong> There are several questions not resolved by this post. First, my analysis was inconclusive on whether or how much the rate of catastrophes changes over time. Data from extinctions suggests that it can vary by an order of magnitude, but it would be better to have data about human events.</p><p> Second, this post says little about the importance of technology and intelligence, even though these are intuitively important. Are technological catastrophes increasing over time, even if right now they are too small to register in the data above? Do more intelligent species often drive less intelligent species to extinction? <sup><a href="#fn15">[15]</a></sup> Base rates on either of these would inform forecasts for AI.</p><p> Finally, one might argue that elapsed time is not the right x-axis, but instead elapsed population growth, economic growth, or technological progress. As one example, take world GDP. There have been as many doublings of world GDP since 1900 as there have been between 1900 and 0CE, so if GDP doublings are the right “clock” to measure against then we might expect many more catastrophes to happen each decade now than in the past. This doesn&#39;t seem true to me from the data so far, but I&#39;d like to see it analyzed in more detail.</p><p><strong>致谢。</strong> Thanks especially to Dhruv Madeka for the discussions and initial data that inspired this post. Thanks also to Sham Kakade, Dean Foster, Tamay Berisoglu, Eli Lifland, Nuño Sempere, Daniel Kokotajlo, and Ege Erdil for useful discussions and comments on this post. Thanks to Justis Mills and Louise Verkin for copy-editing and helpful feedback.</p><hr><section class="footnotes"><ol><li id="fn1" class="footnote-item"><p> Of course, numbers themselves can be misleading, as many historical numbers are based on guesswork! A lot of the work that went into this post was doing extensive reading to decide which numbers to believe. <a href="#fnref1">↩︎</a></p></li><li id="fn2" class="footnote-item"><p> Population sizes were collected from <a href="https://ourworldindata.org/grapher/population?time=-1000..latest&amp;country=%7EOWID_WRL&amp;ref=bounded-regret.ghost.io">Our World in Data</a> , see <a href="#population-by-country-across-history">Appendix</a> . <a href="#fnref2">↩︎</a></p></li><li id="fn3" class="footnote-item"><p> The Taiping rebellion is double-counted, once as a War and once as a Famine. <a href="#fnref3">↩︎</a></p></li><li id="fn4" class="footnote-item"><p> As above, “fast” means taking less than one decade. <a href="#fnref4">↩︎</a></p></li><li id="fn5" class="footnote-item"><p> Another theory is that the Mongol invasions (another catastrophe) spread the Black Death, since Mongols threw diseased corpses into cities as a form of biological warfare. This is not currently the predominant theory, but would be another instance of multi-causality, and shows that different major catastrophes can be linked to each other. <a href="#fnref5">↩︎</a></p></li><li id="fn6" class="footnote-item"><p> Technically speaking, the historical fossil record usually only resolves extinctions at the level of genera rather than species, but I will generally elide this distinction for simplicity. <a href="#fnref6">↩︎</a></p></li><li id="fn7" class="footnote-item"><p> Note that this varies by taxon and estimates within a taxon are approximate, with different estimates in the literature varying by a factor of 4 or sometimes greater. <a href="#fnref7">↩︎</a></p></li><li id="fn8" class="footnote-item"><p> The 2-10x number is when looking at bins of 1 million years. For sudden catastrophic events such as an asteroid strike, the extinction rate over a 1-year time interval would spike much more than that. <a href="#fnref8">↩︎</a></p></li><li id="fn9" class="footnote-item"><p> This is the same Barnosky as above, though I did not know that when searching for papers—in both cases he happened to write the papers that I found most neutral and persuasive. To my delight, I learned that he is also at UC Berkeley.熊们走吧！ <a href="#fnref9">↩︎</a></p></li><li id="fn10" class="footnote-item"><p> See eg <a href="https://www.science.org/doi/10.1126/sciadv.1400253?ref=bounded-regret.ghost.io">Ceballos et al. (2015)</a> , with an estimate closer to two orders of magnitude above the background rate. <a href="#fnref10">↩︎</a></p></li><li id="fn11" class="footnote-item"><p> “Examples include plants that have lost their primary agents of seed dispersal or that are replete with defenses for herbivores that no longer exist, herbivores that are “overdesigned” for all existing predators,<br> and scavengers such as condors that have no naturally occurring carcasses to eat in continental settings.” <a href="#fnref11">↩︎</a></p></li><li id="fn12" class="footnote-item"><p> I follow Figure S7 of <a href="https://pubmed.ncbi.nlm.nih.gov/20978281/?ref=bounded-regret.ghost.io">Hoffmann et al.</a> (reproduced in the <a href="#species-endangerment-by-cause">Appendix</a> ), which counts endangered species grouped by cause of endangerment. I grouped the rows into the categories “habitat destruction”, “invasive species” (which includes the <a href="https://en.wikipedia.org/wiki/Chytridiomycosis?ref=bounded-regret.ghost.io">chytrid fungus</a> disease in amphibians), “overhunting/overfishing”, and “environment” (climate change / pollution / natural disasters). Some categories were ambiguous or did not fit into these 4. Overall I counted approximately ~360 in habitat destruction, ~250 from invasive species (dominated by amphibians), ~130 from overhunting/overfishing, and ~40 from environment. <a href="#fnref12">↩︎</a></p></li><li id="fn13" class="footnote-item"><p> See also <a href="https://www.annualreviews.org/doi/pdf/10.1146/annurev.energy.28.050302.105532?ref=bounded-regret.ghost.io">Dirzo &amp; Raven (2003)</a> who similarly claim that habitat destruction is the primary driver. <a href="#fnref13">↩︎</a></p></li><li id="fn14" class="footnote-item"><p> A reservoir species is a second species in which the pathogen is not deadly, allowing it to multiply more freely, and from which the pathogen can cross over to the target species. <a href="#fnref14">↩︎</a></p></li><li id="fn15" class="footnote-item"><p> The closest I found was <a href="https://www.nature.com/articles/s41598-022-07327-9?ref=bounded-regret.ghost.io">Dembitzer et al. (2022)</a> , who claim that more intelligent mammals were less likely to go extinct during the Late Quaternary Extinction. However, we ideally want to study the opposite: are more intelligent mammals more likely to cause <em>other</em> species to go extinct? <a href="#fnref15">↩︎</a></p></li></ol></section><h1>附录</h1><h2>Log-Log Plot of Catastrophes</h2><p> As noted in Section 1, the distribution of catastrophes no longer follows Zipf&#39;s law when we go below death tolls of 1%, as shown below: <br><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/pogy0xusqv3jf1vpdej2" alt="events_power_law_01.png"><br> One possibility is that the actual trend is log-normal instead of power law. Another is that less severe events are underreported.</p><h2> Species Endangerment by Cause</h2><p> The following is a reproduction of Figure S7 from <a href="https://www.science.org/doi/10.1126/science.1194442?ref=bounded-regret.ghost.io">Hoffmann et al. （2010）</a> 。 <br><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/o0x5tingr8fej6jn4f7z" alt="hoffman_figs7.png"></p><h2> Population by Country Across History</h2><div><a href="https://bounded-regret.ghost.io/content/files/2023/12/population.csv"><div><div>人口</div><div>Raw data on historical world population (see directly below for interactive HTML)</div><div><div> population.csv</div><div> 1MB</div></div></div><div> download-circle </div></div><iframe src="https://ourworldindata.org/grapher/population?tab=table&amp;time=-1000..latest&amp;country=~OWID_WRL"></iframe><h2> Scraping Script </h2><div><a href="https://bounded-regret.ghost.io/content/files/2023/12/scrape_events.py"><div><div> scrape_events</div><div> Python script used to scrape Wikipedia lists of major catastrophes</div><div><div> scrape_events.py</div><div> 13KB</div></div></div><div> download-circle</div></div><h2> Complete List of All Major Catastrophes</h2><div><a href="https://bounded-regret.ghost.io/content/files/2023/12/events_all.csv"><div><div> events_all</div><div> List of all major catastrophes scraped from Wikipedia</div><div><div> events_all.csv</div><div> 6KB</div></div></div><div> download-circle</div></div><br/><br/> <a href="https://www.lesswrong.com/posts/SgYz4YPKridWXJSE6/analyzing-the-historical-rate-of-catastrophes#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/SgYz4YPKridWXJSE6/analyzing-the-historical-rate-of-catastrophes<guid ispermalink="false"> SgYz4YPKridWXJSE6</guid><dc:creator><![CDATA[jsteinhardt]]></dc:creator><pubDate> Tue, 05 Dec 2023 06:30:03 GMT</pubDate> </item><item><title><![CDATA[Some open-source dictionaries and dictionary learning infrastructure]]></title><description><![CDATA[Published on December 5, 2023 6:05 AM GMT<br/><br/><p> As more people begin work on interpretability projects which incorporate dictionary learning, it will be valuable to have high-quality dictionaries publicly available. <span class="footnote-reference" role="doc-noteref" id="fnrefxki2bn9t6a"><sup><a href="#fnxki2bn9t6a">[1]</a></sup></span> To get the ball rolling on this, my collaborator (Aaron Mueller) and I are:</p><ul><li> open-sourcing a number of sparse autoencoder dictionaries trained on Pythia-70m MLPs</li><li> releasing our <a href="https://github.com/saprmarks/dictionary_learning">repository</a> for training these dictionaries <span class="footnote-reference" role="doc-noteref" id="fnrefp7b5kczep0n"><sup><a href="#fnp7b5kczep0n">[2]</a></sup></span> .</li></ul><p> Let&#39;s discuss the dictionaries first, and then the repo.</p><h1> The dictionaries</h1><p> The dictionaries can be downloaded from <a href="https://baulab.us/u/smarks/autoencoders/">here</a> . See the sections &quot;Downloading our open-source dictionaries&quot; and &quot;Using trained dictionaries&quot; <a href="https://github.com/saprmarks/dictionary_learning">here</a> for information about how to download and use them. If you use these dictionaries in a published paper, we ask that you mention us in the acknowledgements.</p><p> We&#39;re releasing two sets of dictionaries for EleutherAI&#39;s 6-layer pythia-70m-deduped model. The dictionaries in both sets were trained on 512-dimensional MLP <i>output</i> activations (not the MLP hidden layer like Anthropic used), using ~800M tokens from <a href="https://pile.eleuther.ai/">The Pile</a> .</p><ul><li> The first set, called <code>0_8192</code> , consists of dictionaries of size <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="8192 = 16 \times 512"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">8192</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">16</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">512</span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>。 These were trained with an L1 penalty of <code>1e-3</code> .</li><li> The second set, called <code>1_32768</code> , consists of dictionaries of size <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="32768 = 64 \times 512"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">32768</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">64</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">512</span></span></span></span></span></span></span> . These were trained with an l1 penalty of <code>3e-3</code> .</li></ul><p> Here are some statistics. (See our repo&#39;s <a href="https://github.com/saprmarks/dictionary_learning">readme</a> for more info on what these statistics mean.)</p><p> For dictionaries in the <code>0_8192</code> set:</p><figure class="table"><table><thead><tr><th>层</th><th>MSE Loss</th><th> L1 loss</th><th> L0</th><th> % Alive</th><th> % Loss Recovered</th></tr></thead><tbody><tr><td> 0</td><td> 0.056</td><td> 6.132</td><td> 9.951</td><td> 0.998</td><td> 0.984</td></tr><tr><td> 1</td><td> 0.089</td><td> 6.677</td><td> 44.739</td><td> 0.887</td><td> 0.924</td></tr><tr><td> 2</td><td> 0.108</td><td> 11.44</td><td> 62.156</td><td> 0.587</td><td> 0.867</td></tr><tr><td> 3</td><td> 0.135</td><td> 23.773</td><td> 175.303</td><td> 0.588</td><td> 0.902</td></tr><tr><td> 4</td><td> 0.148</td><td> 27.084</td><td> 174.07</td><td> 0.806</td><td> 0.927</td></tr><tr><td> 5</td><td> 0.179</td><td> 47.126</td><td> 235.05</td><td> 0.672</td><td> 0.972</td></tr></tbody></table></figure><p> For dictionaries in the <code>1_32768</code> set:</p><figure class="table"><table><thead><tr><th>层</th><th>MSE Loss</th><th> L1 loss</th><th> L0</th><th> % Alive</th><th> % Loss Recovered</th></tr></thead><tbody><tr><td> 0</td><td> 0.09</td><td> 4.32</td><td> 2.873</td><td> 0.174</td><td> 0.946</td></tr><tr><td> 1</td><td> 0.13</td><td> 2.798</td><td> 11.256</td><td> 0.159</td><td> 0.768</td></tr><tr><td> 2</td><td> 0.152</td><td> 6.151</td><td> 16.381</td><td> 0.118</td><td> 0.724</td></tr><tr><td> 3</td><td> 0.211</td><td> 11.571</td><td> 39.863</td><td> 0.226</td><td> 0.765</td></tr><tr><td> 4</td><td> 0.222</td><td> 13.665</td><td> 29.235</td><td> 0.19</td><td> 0.816</td></tr><tr><td> 5</td><td> 0.265</td><td> 26.4</td><td> 43.846</td><td> 0.13</td><td> 0.931</td></tr></tbody></table></figure><p> And here are some histograms of feature frequencies. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/bwz8jq2puk7bt2v5i30r" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/y1doqsgw6saydkevmegk 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/bxmnx1a065hxjb1kxm7w 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/amxktqpnee5yslwybgjr 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/nqczszdt53rrze0yyqjn 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/wt8mfxq5hu3so0xkzhlp 1000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/ypwhg5ljidk3ihwawra9 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/yew2oxwaf2h3qktmyzdz 1400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/cl13rve82dtm4e7n5rvg 1600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/t3gi9wznfqvmwt5g5hjk 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/lgksrskpkvezs1uxrf7v 1920w"></figure><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/xbofxvy4qa4st0bujv2y" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/bswlwokzl9cxxohyp3wl 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/ygciqg8mfkawmroztrlh 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/faowowuclak0zfo8nqa9 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/lrnmhst9cfd5ly40moe9 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/p0x4nejio2vg2ewj7jlh 1000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/bmbi0dnpjkbgs3fclthv 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/kb17kbppyw7ykj0zrnou 1400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/uiwq1n28muzqmvbnwwyl 1600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/syvuw8hizr4ltbmlchyf 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/heoaxgupuv2ku1zzul2w 1920w"></figure><p> Overall, I&#39;d guess that these dictionaries are decent, but not amazing.</p><p> We trained these dictionaries because we wanted to work on a downstream application of dictionary learning, but lacked the dictionaries. These dictionaries are more than good enough to get us off the ground on our mainline project, but I expect that in not too long we&#39;ll come back to train some better dictionaries (which we&#39;ll also open source). I think the same is true for other folks: these dictionaries should be sufficient to get started on projects that require dictionaries; and when better dictionaries are available later, you can swap them in for optimal results.</p><p> Some miscellaneous notes about these dictionaries (you can find more in the <a href="https://github.com/saprmarks/dictionary_learning">repo</a> ).</p><ul><li> The L1 penalty for <code>1_32768</code> seems to have been too large; only 10-20% of the neurons are alive, and the loss recovered is much worse. That said, we&#39;ll remark that after examining features from both sets of dictionaries, the dictionaries from the <code>1_32768</code> set seem to have more interpretable features than those from the <code>0_8192</code> set (though it&#39;s hard to tell).<ul><li> In particular, we suspect that for <code>0_8192</code> , the many high-frequency features in the later layers are uninterpretable but help significantly with reconstructing activations, <strong>resulting in deceptively good-looking statistics</strong> . (See the bullet point below regarding neuron resampling and bimodality.)</li></ul></li><li> As we progress through the layers, the dictionaries tend to get worse along most metrics (except for % loss recovered). This may have to do with the growing scale of the activations themselves as one moves through the layers of pythia models (h/t to Arthur Conmy for raising this hypothesis).</li><li> We note that our dictionary features are significantly higher frequency than the features in <a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html">Anthropic&#39;s</a> and <a href="https://www.lesswrong.com/posts/fKuugaxt2XLTkASkk/open-source-replication-and-commentary-on-anthropic-s">Neel Nanda&#39;s</a> . We don&#39;t know if this difference is because we are working with a multi-layer model or if it is because of a difference in hyperparameters. We generally suspect it would be better if we were learning features of lower frequency.<ul><li> We&#39;ll note, however, that after layer 0, it doesn&#39;t seem like many of our features are of the form &quot;always fire on a particular token,&quot; whereas many of Anthropic&#39;s feature were. So it&#39;s possible that more interesting features also tend to be higher-frequency. See <a href="https://www.lesswrong.com/posts/tEPHGZAb63dfq2v8n/?commentId=zXEsbbJHsg98FY6uj">here</a> for some flavor.</li></ul></li><li> We&#39;re not sure, but the bimodality in the histograms for <code>0_8192</code> may be due to dead neurons being resampled. We resample every 30000 steps, including at step 90000 out of 100000 total steps. The resampled features tend to be very high-frequency, and it might take more than 10000 steps for the peak to move to the left.</li></ul><h1> The dictionary learning repository</h1><p> Again, this can be found <a href="https://github.com/saprmarks/dictionary_learning">here</a> . We followed the approach detailed in <a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html#appendix-autoencoder">Anthropic&#39;s paper</a> (including using untied encoder/decoder weights, constraining the decoder vectors to have unit norm, and resampling dead neurons according to their wacky scheme), except for the following:</p><ul><li> We didn&#39;t have the space to store activations for our entire dataset, so – following <a href="https://www.lesswrong.com/posts/fKuugaxt2XLTkASkk/open-source-replication-and-commentary-on-anthropic-s">Neel Nanda&#39;s replication</a> – we maintain a buffer of tokens from a few thousand contexts and randomly sample from this buffer until it&#39;s half-empty (at which point we refresh it with tokens from new contexts).</li><li> We used a brief linear learning rate warm-up to fix a problem where Adam would kill too many of our neurons in first few training steps, before it had a chance for the Adam parameters to calibrate.</li></ul><p> (A brief plug: this repository is built using <a href="http://nnsight.net/">nnsight</a> , a new interpretability tooling library (like <a href="https://github.com/neelnanda-io/TransformerLens">transformer_lens</a> and <a href="https://github.com/davidbau/baukit">baukit</a> ) being developed by Jaden Fiotto-Kaufman and others in the <a href="https://baulab.info/">Bau lab</a> . <code>nnsight</code> is still under development, so I only recommend trying to dive into it now if you&#39;re okay with occasional bugs, memory leaks, etc. (which you can report in the feedback channel of <a href="https://discord.gg/JqMpyYtS">this Discord server</a> ). But I&#39;m overall very excited about the project – aside from providing a very clean user experience, one major design goal is that <code>nnsight</code> code is highly <i>portable</i> : you should ideally be able to prototype an experiment with Pythia-70m, switch seamlessly to running it on LLaMA-2-70B split across multiple GPUs, and then ship your code to Anthropic to be run on Claude.)</p><p> In addition to the mainline functionality, our repo also supports some experimental features, which we briefly investigated as alternative approaches to training dictionaries:</p><ul><li> <strong>MLP stretchers.</strong> Based on the perspective that one may be able to identify features with &quot; <a href="https://transformer-circuits.pub/2022/toy_model/index.html">neurons in a sufficiently large model</a> &quot; we experimented with training &quot;autoencoders&quot; to, given as input an MLP <i>input</i> activation <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> , output <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="MLP(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;">M</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;">P</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> (the MLP output ）。 For instance, given an MLP which maps a 512-dimensional input <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> to a 1024-dimensional hidden state <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span> and then a 512-dimensional output <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span> , we train a dictionary <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span> with hidden dimension <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="16384 = 16 \times 1024"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">16384</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">16</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1024</span></span></span></span></span></span></span> so that <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> is close to <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span> (and, as usual, so that the hidden state of the dictionary is sparse).<ul><li> The resulting dictionaries seemed decent, but we decided not to pursue the idea further.</li><li> (h/t to Max Li for this suggestion.)</li></ul></li><li> <strong>Replacing L1 loss with entropy</strong> . Based on the ideas in this <a href="https://transformer-circuits.pub/2023/may-update/index.html#simple-factorization">post</a> , we experimented with using entropy to regularize a dictionary&#39;s hidden state instead of L1 loss. This seemed to cause the features to either be dead features (which never fired) or very high-frequency features which fired on nearly every input, which was not the desired behavior. But plausibly there is a way to make this work better.</li></ul><p> If you want to pursue one of the ideas in the above bullet points, I ask that you get in touch with me (Sam) once you have preliminary results – I may be interested in discussing results or collaborating. </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnxki2bn9t6a"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxki2bn9t6a">^</a></strong></sup></span><div class="footnote-content"><p> This is both for the sake of reproducibility, and because each dictionary takes some effort to train.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnp7b5kczep0n"> <span class="footnote-back-link"><sup><strong><a href="#fnrefp7b5kczep0n">^</a></strong></sup></span><div class="footnote-content"><p> Of course, the repository from the <a href="https://arxiv.org/abs/2309.08600">Cunningham et al. paper</a> is also available <a href="https://github.com/HoagyC/sparse_coding">here</a> .</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/AaoWLcmpY3LKvtdyq/some-open-source-dictionaries-and-dictionary-learning#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/AaoWLcmpY3LKvtdyq/some-open-source-dictionaries-and-dictionary-learning<guid ispermalink="false"> AaoWLcmpY3LKvtdyq</guid><dc:creator><![CDATA[Sam Marks]]></dc:creator><pubDate> Tue, 05 Dec 2023 06:05:21 GMT</pubDate> </item><item><title><![CDATA[The LessWrong 2022 Review]]></title><description><![CDATA[Published on December 5, 2023 4:00 AM GMT<br/><br/><p>雪花飘落，颂歌开始响起，我们都知道是时候开始我们最喜欢的冬季假期传统了。审稿时间少了！ </p><figure class="image image_resized" style="width:69.55%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/swcjknwqnq58jqjizlbu" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/iunw2eqowsdnnqfksyra 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/gx5phndd8vqwcthofkdb 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/wmh2aidexazx07hj2dfu 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/ahkmuaycxg9peesnssqr 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/ktgsgz7mjgpix2gho83k 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/zu2vamwcsp7qmxac899u 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/q4dfchxbyjvzz33q0olz 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/h8sonntrtlw1vx8tfek1 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/jlbb43705pckl5ufchsf 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/pqylqykbwbqxdf0ebiud 1024w"></figure><p>每年我们都会聚在一起审查至少一年前的帖子。这意味着在接下来的两个月里，我们将审核 2022 年的所有帖子。</p><p> While our everyday lives are filled with fads and chasing the sweet taste of karma and social approval, the LessWrong review is the time to take a step back and ask ourselves &quot;did this actually help me think better?&quot;, &quot;did this actually turn out to be valuable?&quot; and &quot;which things withstood further and extended scrutiny?&quot;.</p><p> We&#39;ve done this 4 times so far ( <a href="https://www.lesswrong.com/posts/3yqf6zJSwBF34Zbys/2018-review-voting-results">2018</a> , <a href="https://www.lesswrong.com/posts/kdGSTBj3NA2Go3XaE/2019-review-voting-results">2019</a> , <a href="https://www.lesswrong.com/posts/TSaJ9Zcvc3KWh3bjX/voting-results-for-the-2020-review">2020</a> , <a href="https://www.lesswrong.com/posts/zajNa9fdr8JYJpxrG/voting-results-for-the-2021-review">2021</a> ).</p><p> The full technical details of how the Annual Review works are in the <a href="https://www.lesswrong.com/posts/B6CxEApaatATzown6/the-lesswrong-2022-review#How_does_the_review_work_">final section</a> of this post, but it&#39;s basically the same as the past few years. There are three phases:</p><ol><li> <strong>Preliminary Voting Phase</strong> <i>(2 weeks, Dec 4 — 17)</i> : We identify posts especially worthy of consideration in the review casting preliminary votes. Posts with 2 preliminary votes move into the Discussion Phase.</li><li> <strong>Discussion Phase</strong> <i>(4 weeks, Dec  17 — Jan 14)</i> :<i> </i>We review and debate posts. Posts that receive at least one written review move to the final voting phase.</li><li> <strong>Final Voting</strong> <i>(2 weeks, Jan 14 — Jan 28)</i> : We do a full voting pass, using quadratic voting. The outcome determines the Annual Review results.</li></ol><p> For more of the philosophy of the Annual Review, see the previous announcement posts <a href="https://www.lesswrong.com/posts/qXwmMkEBLL59NkvYR/the-lesswrong-2018-review">here</a> , <a href="https://www.lesswrong.com/posts/QFBEjjAvT6KbaA3dY/the-lesswrong-2019-review#Improving_our_incentives_and_rewards">here</a> , <a href="https://www.lesswrong.com/posts/M9kDqF2fn3WH44nrv/the-2020-review">here</a> , and <a href="https://www.lesswrong.com/posts/qCc7tm29Guhz6mtf7/the-lesswrong-2021-review-intellectual-circle-expansion">here</a> .</p><h2>入门</h2><p>At the top of any posts eligible for the review, you will see this: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1672905457/mirroredImages/qCc7tm29Guhz6mtf7/d0fpa6iead1yz8j7y10n.png"></figure><p> These will be your preliminary votes for the 2022 review. Posts need to get at least 2 preliminary votes (positive or negative) in order to move to the next phase of the review.</p><p> To start perusing posts, I recommend going to the <a href="https://www.lesswrong.com/allPosts?timeframe=yearly&amp;after=2022-01-01&amp;before=2023-01-01&amp;limit=100&amp;sortedBy=top&amp;filter=unnominated&amp;includeShortform=false"><u>All 2022 Posts page</u></a> , or the <a href="https://www.lesswrong.com/votesByYear/2022"><u>View Your Past Upvotes</u></a> page. <i>Note: only users with accounts registered before January 2022 are eligible to vote.</i></p><h2> No books this year, sorry folks</h2><p> For 2018, 2019, and 2020 we printed books of the results of the review. We have sold many thousands of them, I am very proud of them, and many people told me that these are among the favorite things that they own: </p><figure class="table"><table style="border-color:white;border-style:solid"><tbody><tr><td style="border-color:hsl(0, 0%, 100%);border-style:solid"><figure class="image image_resized" style="width:100%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/hkxvgpqalnv6oevaxned"><figcaption> 2018: A Map that Reflects the Territory ( <a href="https://www.amazon.com/Map-that-Reflects-Territory-LessWrong/dp/1736128507/ref=sr_1_1?crid=5YSFIY94WGVQ&amp;keywords=lesswrong+books&amp;qid=1701728381&amp;sprefix=lesswrong+book%2Caps%2C145&amp;sr=8-1">Amazon</a> ) </figcaption></figure></td><td style="border-color:hsl(0, 0%, 100%);border-style:solid"><figure class="image image_resized" style="width:100%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/kcpulhgcmm5hsxlnaxga"><figcaption> 2019: The Engines of Cognition ( <a href="https://www.amazon.com/Engines-Cognition-Essays-LessWrong-Community/dp/1736128515/ref=sr_1_2?crid=5YSFIY94WGVQ&amp;keywords=lesswrong+books&amp;qid=1701728381&amp;sprefix=lesswrong+book%2Caps%2C145&amp;sr=8-2">Amazon</a> ) </figcaption></figure></td><td style="border-color:hsl(0, 0%, 100%);border-style:solid"><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/noak9x8qlrktfpottnxx"><figcaption> 2020: The Carving of Reality ( <a href="https://www.amazon.com/Carving-Reality-Essays-LessWrong-Community/dp/B0C95MJJBK/ref=sr_1_5?crid=5YSFIY94WGVQ&amp;keywords=lesswrong+books&amp;qid=1701728398&amp;sprefix=lesswrong+book%2Caps%2C145&amp;sr=8-5">Amazon</a> )</figcaption></figure></td></tr></tbody></table></figure><p> Sadly, there won&#39;t be a book this year (and also not of the 2021 review). The effort involved in making them is hard to justify with increasing demands from many of our other projects (as well as reduced funding, since if you take into account the 4-5 staff months these cost to make each year, we net lost money on这些）。</p><p> I am thinking about other ways to create an easy to reference artifact that captures the results of this year&#39;s and last year&#39;s review. I think the minimum I want to do is to create a good ebook and maybe an audible version using our machine narration (or doing human narration). Additional suggestions are welcome.</p><p> We are going to be doing a Christmas sale of all of the previous years&#39; books in the next few days, and hopefully before Christmas we will also have a good ebook (and maybe even an audiobook version) available of last year&#39;s review results.</p><h1> How does the review work?</h1><h2> Phase 1: Preliminary Voting</h2><p> To nominate a post, cast a preliminary vote for it. Eligible voters will see this UI: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1672905457/mirroredImages/qCc7tm29Guhz6mtf7/d0fpa6iead1yz8j7y10n.png"></figure><p> If you think a post was an important intellectual contribution, you can cast a vote indicating roughly how important it was. For some rough guidance:</p><ul><li> A vote of 1 means “it was good.”</li><li> A vote of 4 means “it was quite important”.</li><li> A vote of 9 means it was &quot;a crucial piece of intellectual progress.&quot;</li></ul><p> You can vote at the top of a post page, or anywhere the post appears in a list (like the <a href="https://www.lesswrong.com/allPosts?timeframe=yearly&amp;after=2022-01-01&amp;before=2023-01-01&amp;limit=100&amp;sortedBy=top&amp;filter=unnominated&amp;includeShortform=false"><u>All Posts page</u></a> , or the new <a href="https://www.lesswrong.com/votesByYear/2022"><u>View Your Past Upvotes</u></a> page).</p><p> Posts that get at least one positive vote go to the <a href="https://lesswrong.com/reviewVoting/2022">Voting Dashboard</a> , where other users can vote on it. You&#39;re encouraged to give at least a rough vote based on what you remember from last year. It&#39;s okay (encouraged!) to change your mind later.</p><p> <strong>Writing a short review</strong></p><p> If you feel a post was important, you&#39;re also encouraged to write up at least a short review of it saying what stands out about the post and why it matters. (You&#39;re welcome to write multiple reviews of a post, if you want to start by jotting down your quick impressions, and later review it in more detail)</p><p> Posts with at least one review get sorted to the top of the <a href="https://www.lesswrong.com/reviewVoting">list of posts to vote on</a> , so if you&#39;d like a post to get more attention it&#39;s helpful to review it.</p><p> <strong>Why preliminary voting? Why two voting phases?</strong></p><p> Each year, more posts get written on LessWrong. The first Review of 2018 considered 1,500 posts. In 2021, there were 4,250. Processing that many posts is a lot of work.</p><p> Preliminary voting is designed to help handle the increased number of posts. Instead of simply nominating posts, we start directly with a vote. Those preliminary votes will then be published, and only posts that at least two people voted on go to the next round.</p><p> In the review phase this allows individual site members to notice if something seems particularly inaccurate in its placing. If you think a post was inaccurately ranked low, you can write a positive review arguing it should be higher, which other people can take into account for the final vote. Posts which received lots of middling votes can get deprioritized in the review phase, allowing us to focus on the conversations that are most likely to matter for the final result.</p><p> <strong>How is preliminary voting calculated?</strong></p><p> You can cast an unlimited number of votes, but after a certain threshold, the greater the total score of your votes, the less influential each of your votes will be. On the back end, we use a <a href="https://www.lesswrong.com/posts/qQ7oJwnH9kkmKm2dC/feedback-request-quadratic-voting-for-the-2018-review"><u>modified quadratic voting system</u></a> , which allocates a fixed number of points across your votes based on how strong they are.</p><p> <i>Fine details: A vote of 1 costs 1 point. A vote of 4 costs 10 points. A vote of 9 costs 45 points. If you spend more than 500 points, your votes start to become proportionally weaker.</i></p><h2> Phase 2: Reviews</h2><p> The second phase is a month long, and focuses entirely on writing reviews. Reviews are special comments that evaluate a post. Good questions to answer in a review include:</p><ul><li> What does this post add to the conversation?</li><li> How did this post affect you, your thinking, and your actions?</li><li> Does it make accurate claims? Does it carve reality at the joints?你怎么知道？</li><li> Is there a subclaim of this post that you can test?</li><li> What followup work would you like to see building on this post?</li></ul><h2> Phase 3: Final Voting</h2><p> Posts that receive at least one review move on the Final Voting Phase.</p><p> The UI will require voters to at least briefly skim reviews before finalizing their vote for each post, so arguments about each post can be considered.</p><p> As in previous years, we&#39;ll publish the voting results for users with 1000+ karma, as well as all users. The LessWrong moderation team will take the voting results as a strong indicator of which posts to include in the Best of 2022 sequence.</p><p> <strong>To get started, you can</strong> <a href="https://www.lesswrong.com/votesByYear/2022"><strong><u>View Your Past Upvotes</u></strong></a> <strong>and start voting on some posts.</strong></p><br/><br/><a href="https://www.lesswrong.com/posts/B6CxEApaatATzown6/the-lesswrong-2022-review#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/B6CxEApaatATzown6/the-lesswrong-2022-review<guid ispermalink="false"> B6CxEApaatATzown6</guid><dc:creator><![CDATA[habryka]]></dc:creator><pubDate> Tue, 05 Dec 2023 04:00:00 GMT</pubDate> </item><item><title><![CDATA[Bands And Low-stakes Dances]]></title><description><![CDATA[Published on December 5, 2023 3:50 AM GMT<br/><br/><p><span>当我开始在波士顿地区参加反对派舞会时，有几种你可以考虑“低风险”的地区舞会。小型舞会，费用不高，老牌乐队的热情也较低。因此，他们相对愿意预订那些刚刚起步、友好、鼓励、能够容忍缺乏经验的错误的乐队。</span></p><p>我认为这就是为什么这么多实力雄厚的乐队和舞蹈音乐家走出这个领域的一个重要原因：不需要你足够优秀，能够在“大型”舞蹈中保持自己的风格，就可以开始获得作为乐队跳舞的经验。 。例如，回顾一下我的日历，在我们玩我们的第一个“大型”游戏（<a href="https://challcontra.weebly.com/">协和星期五</a>）之前， <a href="https://www.freeraisins.com/">Free Raisins</a>玩了十八个不同的晚上。</p><p>不幸的是，这比以前少了很多。一些在大流行前关闭了（我非常想念麻省理工学院的反对派舞蹈！），其他人还没有回来（还没有？）或者已经转向室内乐队。有<a href="https://www.bidadance.org/">BIDA</a><a href="https://www.jefftk.com/p/why-does-the-bida-open-band-work-well">开放乐队</a>和（风险更低的）家庭舞蹈乐队，但虽然我认为这种经验也很有价值，但有一种不同的学习方式，来自于在小组中演奏、演奏你已经练习过的曲目，以及对音乐完全负责。</p><p>我在这里没有一个很好的解决方案：很难故意开始一些低风险的活动，而且人们通常更喜欢举办那种很多人都想参加并且有很棒音乐的活动。但我确实认为 2010 年代初期的环境非常特别，为新乐队提供了很多学习成为舞蹈乐队的机会，如果我们能够带回类似的东西，或者至少具有类似效果的东西，我会很高兴。</p><p> （这种同样的动力对于“技术魂斗罗”来说更加强烈：唯一的表演机会是重大的特别活动，甚至更高调！但我对这种舞蹈形式的成功投入也较少，所以这不太困扰我。 ）</p><br/><br/><a href="https://www.lesswrong.com/posts/atwkvWcSppkKN9dRJ/bands-and-low-stakes-dances#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/atwkvWcSppkKN9dRJ/bands-and-low-stakes-dances<guid ispermalink="false"> atwkvWcSppkKN9dRJ</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Tue, 05 Dec 2023 03:50:22 GMT</pubDate> </item><item><title><![CDATA[Accelerating science through evolvable institutions]]></title><description><![CDATA[Published on December 4, 2023 11:21 PM GMT<br/><br/><p><i>这是向圣达菲研究所“加速科学”工作组提交的演讲的书面版本。</i></p><p>我们来这里是为了讨论“加速科学发展”。我喜欢从历史的角度来开始讨论这样的话题：科学在过去什么时候（如果有的话）加速了？现在还在加速吗？我们可以从中学到什么？</p><p>我认为，在整个人类历史中，科学以及更广泛的人类知识<i>一直</i>在加速发展。我还不能证明这一点（而且我自己对此只有大约 90% 的把握），但让我诉诸你的直觉：</p><ul><li><a href="https://en.wikipedia.org/wiki/Behavioral_modernity">从行为上看，现代人类</a>已有 50,000 多年的历史</li><li>文字只有大约 5000 年的历史，因此在人类时间线的 90% 以上，我们只能积累能够适应口头传统的知识</li><li>在古代和中世纪世界，我们只有少数几门科学：天文学、几何学、一些数论、一些光学、一些解剖学</li><li>在科学革命之后的几个世纪（大约 1500 年代至 1700 年代），我们得到了日心说、运动定律、万有引力理论、化学的起源、细胞的发现、更好的光学理论</li><li>在 1800 年代，事情真正开始发展，我们有了电磁学、原子理论、进化论、细菌理论</li><li>1900 年代，核物理、量子物理、相对论、分子生物学和遗传学继续蓬勃发展</li></ul><p>我把自 1950 年左右以来科学是否已经放缓的问题放在一边，我对此没有强烈的看法。即使确实如此，这也只是整个历史加速的总体模式中最近的一个小插曲。 （或者，你知道，历史上前所未有的逆转和衰退的开始。其中之一。）</p><p>我对这种加速模式深信不疑的部分原因是，加速的不仅仅是科学：几乎所有衡量人类进步的指标都显示出相同的趋势，包括<a href="https://ourworldindata.org/grapher/world-gdp-over-the-last-two-millennia?yScale=log">世界 GDP</a>和<a href="https://ourworldindata.org/grapher/population?yScale=log&amp;country=~OWID_WRL">世界人口</a>。</p><p>是什么推动了科学的加速发展？许多因素，包括：</p><ul><li><strong>资金。</strong>曾经，科学家必须<a href="https://rootsofprogress.org/funding-models-for-science-and-innovation">寻求赞助，或者独立致富</a>。现在有可用的赠款，并且资金总额在过去几十年中大幅增加： </li></ul><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9uEAwHzoDS8shpdoX/dhxfk91oznfay66wdxnn" alt=""><figcaption><a href="https://www.aaas.org/programs/r-d-budget-and-policy/historical-trends-federal-rd"><i>美国科学促进会</i></a></figcaption></figure><ul><li><strong>人们。</strong>更多的科学家（在其他条件相同的情况下）意味着科学发展得更快，科学家的数量急剧增加，这既是因为总体人口的增长，也是因为更多的劳动力进入研究领域。在<a href="https://archive.org/details/sciencesincebaby0000pric/page/107/mode/1up?view=theater"><i>《自巴比伦以来的科学》一</i></a>书中，德里克·J·德·索拉·普赖斯 (Derek J. de Solla Price) 表示，“历史上大约 80% 到 90% 的科学家现在还活着”，这<a href="https://futureoflife.org/guest-post/90-of-all-the-scientists-that-ever-lived-are-alive-today/">可能仍然是正确的</a>： </li></ul><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9uEAwHzoDS8shpdoX/wh3ldfdjulipzfcrroyg" alt=""><figcaption> <a href="https://futureoflife.org/guest-post/90-of-all-the-scientists-that-ever-lived-are-alive-today/"><i>埃里克·加斯特弗兰德</i></a></figcaption></figure><ul><li><strong>仪器。</strong>更好的工具意味着我们可以做更多更好的科学研究。伽利略有一个简单的望远镜。现在我们有<a href="https://en.wikipedia.org/wiki/James_Webb_Space_Telescope">JWST</a>和<a href="https://en.wikipedia.org/wiki/LIGO">LIGO</a> 。</li><li><strong>计算。</strong>更强的计算能力意味着更多更好的数据处理方式。</li><li><strong>沟通。</strong>思想传播得越快越好，科学传播就越高效、越有效。科学期刊是在印刷机发明之后才发明的。互联网支持预印本服务器，例如 arXiv。</li><li><strong>方法。</strong>更好的方法造就更好的科学，从培根经验主义到<a href="https://en.wikipedia.org/wiki/Koch%27s_postulates">科赫假设</a>再到<a href="https://en.wikipedia.org/wiki/Randomized_controlled_trial">随机</a>对照试验（实际上是所有统计数据）。</li><li><strong>机构。</strong>实验室、大学、期刊、资助机构等共同构成了一个支持现代科学的生态系统。</li><li><strong>社会地位。</strong>科学越受到尊重和声望，就会有越多的人和金钱流入它。</li></ul><p>现在，如果我们想问科学是否会继续加速发展，我们可以思考哪些驱动因素将继续增长。我建议：</p><ul><li>只要世界经济持续增长，科学经费就会继续增长</li><li>仪器、计算和通信将随着技术的发展而不断改进</li><li>我认为方法没有理由不继续改进，作为科学本身的一部分</li><li>科学的社会地位似乎相当强大：它是一个受人尊敬和享有盛誉的机构，获得了一些社会最高荣誉</li></ul><p>从长远来看，如果<a href="https://ourworldindata.org/grapher/comparison-of-world-population-projections">世界人口像预计的那样趋于稳定</a>，我们可能会耗尽继续扩大研究人员基础的人员，这是一个潜在的问题，但不是我今天的重点。</p><p>最大的危险信号是我们的科学机构。制度影响所有其他因素，尤其是资金和人才的管理。今天，元科学界的许多人对我们的机构感到担忧。常见的批评包括：</p><ul><li><strong>速度。</strong>获得资助很容易需要 12-18 个月的时间（如果你幸运的话）</li><li><strong>高架。</strong>研究人员通常将 30-50% 的时间花在资助上</li><li><strong>耐心。</strong>研究人员认为他们需要定期展示结果，并且不能走一条可能需要多年才能得出结果的道路</li><li><strong>风险承受能力。</strong>赠款资金倾向于保守的、渐进的建议，而不是大胆的、“高风险、高回报”的计划（尽管<a href="https://commonfund.nih.gov/highrisk">做出了相反的努力</a>）</li><li><strong>共识。</strong>一个领域可能会过快地集中于一个假设并修剪替代的研究分支</li><li><strong>研究员年龄。</strong>随着时间的推移，赠款的趋势是拨款给年龄更大、更成熟的研究人员</li><li><strong>自由。</strong>科学家缺乏完全自主地指导研究的自由；赠款资金附加太多条件</li></ul><p>现在，作为一名前科技创始人，我不禁注意到，在营利性风险投资领域，大多数问题似乎都得到了缓解。筹集风险投资资金相对较快（通常一轮融资会在几个月内完成，而不是一年或更长时间）。作为创始人/首席执行官，我花了大约 10-15% 的时间筹款，而不是 30-50%。风险投资公司大胆下注，积极寻求逆向立场，并支持年轻的新贵。他们大多给予创始人自主权，也许会在董事会中占据一席之地以进行治理，并且只有在表现非常糟糕时才会解雇首席执行官。 （上面列出的初创公司创始人可能还会抱怨的唯一问题是耐心：如果你的钱用完了，你最好能取得进展，否则你在下一轮融资时就会遇到困难。）</p><p>我不认为风险投资界在这些方面做得更好，因为风险投资家比科学资助者更聪明、更有智慧或更优秀——但事实并非如此。相反，风险投资家：</p><ul><li>争夺优惠（并且真的不想错过好优惠）</li><li>从长远来看，成功或失败取决于其投资组合的表现</li><li>在大约 5-10 年内看到这些结果</li></ul><p>简而言之，<strong>风险投资面临着进化压力。</strong>他们不能陷入明显的不良均衡，因为如果这样做，他们就会在竞争中落败并失去市场力量。</p><p>证明这一点的是风险投资在过去几十年里<i>的</i>发展——主要是朝着为创始人提供更好待遇的方向发展。例如，早期阶段存在较高估值的长期趋势，这最终意味着较低的稀释度以及权力从风投向创始人的转移：创始人在过去的几年里放弃公司一半或更多的股份是很常见的。第一轮融资；最后我检查了一下，大约是 20% 或更少。风险投资并不总是资助大学刚毕业的年轻技术人员。曾经有一段时间，他们倾向于青睐更有经验的首席执行官，或许还拥有 MBA 学位。他们并不总是支持创始人领导的公司；曾经，创始人在最初几年后被解雇并由专业首席执行官取代的情况很常见（当 A16Z 在 2009 年推出时，他们大肆宣扬<a href="https://a16z.com/why-we-prefer-founding-ceos/">他们不会这样做</a>）。</p><p>所以我认为<strong>，如果我们希望看到我们的科学机构</strong><i><strong>得到改进</strong></i><strong>，我们需要考虑它们如何</strong><i><strong>发展</strong></i><strong>。</strong></p><p>我们的科学机构的发展程度如何？不是特别的。当今大多数科学组织都是大学或政府部门。尽管我很尊重大学和政府，但我认为任何人都必须承认它们是我们行动较为缓慢的机构之一。 （大学尤其具有极强的弹性和抵抗力：例如，牛津大学和剑桥大学的历史可以追溯到中世纪，经历了帝国的兴衰，直到今天仍然完好无损。）</p><p>科学资助机构的进化所面临的挑战与风险投资的进化相反：</p><ul><li><strong>他们往往缺乏竞争，</strong>尤其是 NIH 和 NSF 等集中式联邦机构</li><li><strong>他们缺乏任何真正的反馈循环</strong>，在这种循环中，资助者的资源是由过去的判断和其投资组合的成功决定的（迈克尔·尼尔森多次<a href="https://twitter.com/michael_nielsen/status/1451626771690897408">指出</a>，从“爱因斯坦作为专利职员做了最好的工作”到“卡塔林·卡里科”的资助失败）在获得诺贝尔奖之前被拒绝授予资助和终身教职”似乎甚至没有引发相关机构内部的反思过程）</li><li><strong>他们需要很长的周期</strong>才能了解其工作的真正影响，而这种影响可能需要 20-30 年才能显现出来</li></ul><p>我们如何提高科学经费的可进化性？我们应该思考如何改善这些因素。我没有什么好主意，但我会抛出一些不成熟的想法来开始对话：</p><p><strong>我们如何增加科学资助的竞争？</strong>我们可以增强慈善事业的作用。在美国，我们可以将联邦资金转移到州一级，设立五十个资助者而不是一个。 （国家农业实验站就是一个成功的例子，这些实验站之间的竞争是杂交玉米研究的关键，这是 20 世纪农业科学最伟大的成功之一。）在国际层面，我们可以支持对科学家更加开放的移民。</p><p><strong>我们如何创建更好的反馈循环？</strong>这很困难，因为我们需要某种方法来衡量结果。实现这一目标的一种方法是将资金从预期赠款转向各级各种回顾性奖项。如果这个“经济”足够大和强大，这些成果就可以被金融化，以创建一个动态的、有竞争力的融资生态系统，并具有适当水平的风险承担和耐心，经验丰富的退伍军人与年轻特立独行者之间的适当平衡等.（ <a href="https://forum.effectivealtruism.org/posts/r7vmtHZKuosJZ3Xq5/altruistic-equity-allocation">影响证书</a>，例如<a href="https://protocol.ai/blog/hypercert-new-primitive/">超级证书</a>，可以成为该解决方案的一部分。）</p><p><strong>我们如何解决反馈周期长的问题？</strong>我不知道。如果我们不能缩短周期，也许我们需要延长资助者的职业生涯，这样他们至少可以从几个周期中学习——这<a href="https://rootsofprogress.org/how-curing-aging-could-help-progress">是长寿技术的潜在好处</a>。或者，也许我们需要一个科学资助者，它可以极快地学习，可以消耗大量有关研究项目及其最终结果的历史信息，永远不会忘记其经历，并且永远不会退休或死亡——当然，我想到的是人工智能。关于人工智能支持、增强或取代科学研究人员本身的讨论很多，但人工智能在科学领域的最大机会可能是在资金和管理方面。</p><p>我怀疑资助机构会在这个方向上走得太远：它们必须自愿接受竞争、加强问责并承认错误，而这种情况很少见。 （看看现在那些因卡里科获得诺贝尔奖而获得功劳的机构，他们几乎没有为她提供支持。）如果机构很难进化，那么元进化就更难了。</p><p>但也许资助者背后的资助者，即那些向资助者提供预算的资助者，可以开始将资金分配给多个机构，以要求绩效指标，或者干脆转向上述回顾性模式。这可以提供所需的进化压力。</p><br/><br/> <a href="https://www.lesswrong.com/posts/9uEAwHzoDS8shpdoX/accelerating-science-through-evolvable-institutions#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9uEAwHhoDS8shpdoX/acceleating-science-through-evolvable-institutions<guid ispermalink="false"> 9uEAwHzoDS8shpdoX</guid><dc:creator><![CDATA[jasoncrawford]]></dc:creator><pubDate> Mon, 04 Dec 2023 23:21:35 GMT</pubDate> </item><item><title><![CDATA[Speaking to Congressional staffers about AI risk]]></title><description><![CDATA[Published on December 4, 2023 11:08 PM GMT<br/><br/><p> 2023 年 5 月和 6 月，我（Akash）与国会工作人员就人工智能风险举行了大约 50-70 次会议。我一直想写一篇文章来反思这次经历和我的一些收获，我认为这可能是 LessWrong 对话的一个好话题。我看到他们<a href="https://www.lesswrong.com/posts/kQuSZG8ibfW6fJYmo/announcing-dialogues-1?commentId=L2qFjT8taEhkm4hCB">提出要与人们进行 LW 对话</a>，于是我伸出了援手。</p><p>在这次对话中，我们讨论了我如何决定与工作人员聊天、我在华盛顿的初步观察、有关国会办公室如何工作的一些背景、我的会议是什么样的、我学到的教训以及关于我的经历的一些杂项。</p><h2>语境</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 19:14:27 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 19:14:27 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>嘿！在您的留言中，您提到了一些与您在华盛顿的经历相关的主题。</p><p>我认为我们应该从您与国会办公室谈论人工智能风险的经历开始。我很有兴趣了解更多；似乎没有太多公共资源来说明这种外展活动是什么样的。</p><p>那是怎么开始的？是什么让你想这么做？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 19:23:08 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 19:23:08 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>2023 年 3 月，我开始在<a href="https://www.safe.ai/">人工智能安全中心</a>从事一些人工智能治理项目。我的一个项目涉及帮助 CAIS 响应<a href="https://www.ntia.gov/issues/artificial-intelligence/request-for-comments">NTIA</a>发布的关于人工智能问责制的评论请求。</p><p>作为这项工作的一部分，<strong>我开始思考一个好的前沿人工智能监管框架应该是什么样子。</strong>例如：如果我可以为前沿人工智能系统建立许可制度，它会是什么样子？它会被安置在美国政府的什么地方？我希望它评估哪些信息？</p><p><strong>我开始想知道实际的政策制定者会对这些想法有何反应</strong>。我也很好奇更多地了解政策制定者如何考虑人工智能灭绝风险和灾难性风险。</p><p>我开始询问人工智能治理领域的其他人。绝大多数人（根本）没有与国会工作人员交谈过。一些人有与员工交谈的经验，但没有与他们谈论人工智能风险。很多人告诉我，他们认为与政策制定者的接触非常重要，但却被忽视了。当然，也存在下行风险，所以你不希望有人做得不好。</p><p>在咨询了 10-20 名人工智能治理人员后，我询问 CAIS 我是否可以去华盛顿并开始与国会办公室交谈。目标是（a）提高对人工智能风险的认识，（b）更好地了解国会办公室如何考虑人工智能风险，（c）更好地了解国会办公室的人们有哪些与人工智能相关的优先事项，以及 (d) 获取有关我的 NTIA 评论想法请求的反馈。</p><p> CAIS 批准了，我于 2023 年 5 月至 6 月去了华盛顿。需要澄清的是，这不是 CAIS 告诉我要做的事情——这更像是 CAIS 意识到正在发生的“阿卡什事件”。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 19:26:38 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 19:26:38 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>哇，这真的很有趣。几个随机问题：</p><blockquote><p>当然，也存在下行风险，所以你不希望有人做得不好。</p></blockquote><p>一个人怎样才能把一件事做得不差呢？如何学习与政策制定者互动？<br><br>另外，你的背景是什么？在此之前您做过政策方面的工作吗？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 19:31:28 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 19:31:28 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>是的，很好的问题。我不确定最好的学习方法是什么，但我尝试过以下一些方法：</p><ul><li>与有与政策制定者互动经验的<strong>人交谈</strong>。询问他们说什么、他们发现什么令人惊讶、他们犯了什么错误、他们注意到什么下行风险等等。</li><li><strong>看书</strong>。我发现<a href="https://www.amazon.com/Master-Senate-Years-Lyndon-Johnson/dp/0394720954">参议院议长</a>和<a href="https://www.amazon.co.uk/Act-Congress-Americas-Essential-Institution/dp/0307744515">国会法案</a>特别有帮助。我目前正在阅读<a href="https://www.amazon.com/Devils-Chessboard-Dulles-Americas-Government/dp/0062276174">《魔鬼的棋盘》，</a>以更好地了解中央情报局和情报机构，到目前为止，我发现它内容丰富。</li><li>与你已经认识的政策制定者<strong>进行角色扮演</strong>，并要求他们提供直率的反馈。</li><li>在风险较低的会议中<strong>进行练习</strong>，并利用这些经验进行迭代。</li></ul><p>在此之前我没有做过太多政策方面的事情。在大学里，我为《哈佛政治评论》撰稿，并参与了政治研究所的工作，但这比“现实世界的政策参与”的内容更具学术性。</p></div></section><h2>抵达华盛顿特区并进行初步观察</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 19:32:08 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 19:32:08 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>这一切都是有道理的。到达华盛顿后你做了什么？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 19:37:08 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 19:37:08 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>我给国会办公室以及一些行政部门的人员发送了冷电子邮件。我还联系了华盛顿的一些 EA。我还继续处理 NTIA 的评论请求（截止日期为 6 月 6 日）。</p><p>最初的计划是召开几次会议，评估会议的进展情况，如果我认为进展相当顺利，则再召开更多会议。</p><p>总的来说，我最终与国会工作人员举行了大约 50-70 次会议（以及一些与智库人员和行政部门机构人员的会议，但我将在这篇文章中重点讨论与国会工作人员的会议）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 19:37:28 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 19:37:28 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>我认为他们进展得相当顺利，那么？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 19:43:42 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 19:43:42 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>据我说，是的！我要注意的一件事是，这些可能有点难以评估——比如，员工应该对人友善，他们不会说“我以为你是个白痴”或“你浪费了我的时间”之类的话。时间”或“我现在对人工智能安全性的印象更差了。”</p><p>记住这一点：</p><ul><li><strong>我对员工们的开放态度感到惊讶。</strong>奥弗顿之窗最近发生了很大的变化，但当时，我真的不知道人们是否会说“哈！<i>灭绝风险？</i>这听起来像科幻小说。”</li><li><strong>主导氛围是“人工智能非常重要，我是一名忙碌的员工，有 100 个优先事项，所以我没有时间了解它。我</strong>真的很高兴能与能够告诉我有关人工智能的东西的人交谈– 我一直渴望跟上进度。”</li><li><strong>员工们对有机会见到愿意回答有关人工智能基本问题的人表示非常感激</strong>（例如，什么是大型语言模型，它与其他类型的人工智能有何不同？有多少公司从事前沿人工智能？）</li><li>有一些“切实”的信号表明事情进展顺利。例如，一些工作人员将我介绍给他们认识的其他人，一些人将他们办公室正在起草的工作发给我，还有一些人甚至将我介绍给国会议员（总共两个）。</li></ul></div></section><h2>国会办公室的层级</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 19:44:47 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 19:44:47 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>这真的很有趣！<br><br>顺便说一句，您能给我描绘一下国会办公室的人员配置等级吗？例如，您通常与谁交谈，他们通常与国会议员有什么关系？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 19:50:33 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 19:50:33 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>好问题！因此，我的理解是，国会办公室通常具有以下角色，从“最有影响力”到“最没有影响力”列出：</p><ul><li>参谋长</li><li>立法主任</li><li>立法助理</li><li>立法通讯员</li><li>实习生和研究员</li></ul><p>还有一些其他角色，但从立法角度来看，这些角色往往最重要。</p><p>请注意，每个办公室都有自己的氛围。有人曾经告诉我“每个国会办公室都是自己的初创企业，每个国会议员都可以按照自己的意愿管理自己的办公室。”</p><p>因此，在某些办公室，实习生和研究员实际上可能有很大的影响力（例如，如果国会议员或立法主任信任实习生是特定主题的主题专家）。但总的来说，我认为这种层次结构很常见。</p><p>我想我主要是与立法助理/立法通讯员级别的人交谈。我还与几位立法官员进行了交谈。</p></div></section><h2>外展到办事处</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 19:51:24 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 19:51:24 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>好吧，这一切都有道理。那么，您是如何从几次会议增加到 60-80 次的呢？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 19:55:30 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 19:55:30 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>我向技术政策工作人员发送了一封群发电子邮件，回复人数给我留下了深刻的印象。这封电子邮件相当短，提到我在 CAIS，用 1-2 个要点介绍了 CAIS 的工作，并用要点说明了我正在处理 NTIA 的评论请求。</p><p>我认为国会工作人员现在确实对人工智能内容非常感兴趣。就像，如果我向人们发送电子邮件讨论其他问题，我认为我不可能召开这么多会议。</p><p>有人感觉“人工智能现在很热，但没有人真正了解人工智能”。我认为目前还不清楚这种情况会持续多久（尤其是“人们了解不多，办公室还没有下定决心”）部分。</p><p>我什至会说“我认为这是一个 AIS 社区作为一个整体可以/应该充分利用的机会”。比如，国会工作人员曾经（而且我认为仍然）对与人们讨论人工智能问题非常感兴趣——很难想象还有比这更好的机会让 AIS 社区的人们能够进来并担任顾问/倡导者。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 20:20:31 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 20:20:31 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>这就说得通了。</p><p>如何才能开始与国会工作人员接触？人们应该做什么才能进入这个领域/哪些组织可能适合为此部署人员？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 20:38:04 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 20:38:04 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>这将是一个相当模糊的答案，但我认为这在很大程度上取决于人、他们的技能和他们的政策目标。</p><p>另外——我在上面提到过这一点，但重要的是要重申——人们做得不好肯定会带来风险。另一方面，存在过于“不作为偏见”或类似情况的风险，并留下很多价值。</p><p>这确实很难且令人困惑。我之前提到，我咨询了 10-20 名 AI 治理人员。他们中的大多数人都说“这似乎很重要但被忽视了，但我不知道，这似乎很令人困惑。”他们中的一些人就像“是的，我完全认为你应该这样做，特别是如果你采用 XYZ 策略。”一位相当著名的人工智能治理人士明确告诉我，他们不希望我这样做。我发现很难平衡这种相互矛盾的反馈。</p><p>我还认为我的很多建议取决于某人到底想说什么——例如：</p><ul><li>他们的推销方式是什么？如果会议开始，工作人员说“那么，你想谈什么？”，最初的反应是什么？</li><li>他们是那种善于提出问题、对别人的世界观感到好奇的人吗？</li><li>他们听起来会危言耸听吗？</li><li>他们了解很多关于人工智能的事实吗？当他们不知道某件事时，他们是否能够认识到这一点并进行适当的对冲？</li></ul><p>考虑到所有这些，如果阅读本文的人有兴趣与国会工作人员互动（或让他们组织中的某人这样做），并且他们重​​视我的意见，<strong>我建议他们通过 LW 与我联系。</strong>我能够在更多背景下提供更好的建议。</p></div></section><h2>一次典型的会议</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 20:47:09 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 20:47:09 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>是的，这一切都有道理。您能向我介绍一下您可能举行过的典型会议吗？例如，您将如何首次与员工联系，您将在哪里与他们见面，实际对话是什么样的，您将如何跟进或以其他方式弄清楚这是否有帮助？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 21:47:20 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 21:47:20 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p><strong>会议物流</strong></p><ol><li>将通过电子邮件联系</li><li>通常会在国会办公室（华盛顿特区基本上有 4 座主要建筑都设有所有国会办公室）或通过 Zoom 与他们会面</li></ol><p><strong>会议进展如何</strong></p><ol><li>谈话通常会从我询问他们是否对人工智能有任何疑问或希望我分享我正在研究的东西开始。通常，他们希望我先开始。</li><li>我首先介绍我自己和 CAIS。一旦<a href="https://safe-ai.webflow.io/statement-on-ai-risk">CAIS 声明</a>出来，我就会引用 CAIS 声明。我会告诉他们，我正在关注先进人工智能带来的全球安全风险。我还会告诉他们我正在制定 NTIA 响应，并且会告诉他们我正在考虑的一些高级想法。</li><li>然后，我会停下来看看他们是否有任何问题。</li><li>通常，他们要么询问更多有关灭绝风险的问题，要么询问有关人工智能的各种问题（例如，您对如何处理深度造假有什么想法吗？），或者提出一些有关监管的高级问题（例如，我们如何监管而不扼杀创新？我们如何监管而不输给中国？）</li><li>在一些最好的会议中，我会听到办公室正在研究的一些与人工智能相关的东西。大多数办公室没有能力/兴趣在人工智能领域发挥带头作用。大约 10% 的办公室表示“是的，我的国会议员对此非常感兴趣，我们正在考虑引入立法或成为其他人立法的核心部分。”</li><li>很多人问我是否有立法草案。显然，如果你有监管想法，人们希望看到你有一个像法案一样写成的（简短的）版本。</li></ol><p><strong>跟进</strong></p><p>NTIA 的评论请求回复完成后，我向遇到的每个人发送了一份后续信息。当我有一次特别好的会议时（例如，一位员工对人工智能风险表示强烈兴趣，或者告诉我他们想向我发送他们正在研究的东西），我会发送个性化的后续信息。我认为最明显的帮助迹象来自于人们继续向我发送问题/想法、将我介绍给同事或希望与我合作提出建议的情况。 （需要明确的是，这种情况发生在少数情况下，但我认为这是大部分影响的来源）。</p></div></section><h2>员工对人工智能风险的态度</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Wed, 15 Nov 2023 22:41:56 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Wed, 15 Nov 2023 22:41:56 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><blockquote><p>很多人问我是否有立法草案。</p></blockquote><p>他们正在寻求针对哪些类型的问题进行立法？您建议的任何立法？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Wed, 15 Nov 2023 22:38:45 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Wed, 15 Nov 2023 22:38:45 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>工作人员经常想知道我是否有立法草案来描述我在 NTIA 回复中所写的许可制度（我没有立法草案，但后来在帮助 Thomas 关闭<a href="https://www.aipolicy.us/">人工智能政策中心</a>时参与了立法起草工作）地面。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Wed, 15 Nov 2023 22:39:31 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Wed, 15 Nov 2023 22:39:31 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>啊好吧。更一般地说，人们对人工智能风险有哪些先验？您认为您通常会导致他们处理该主题的方式发生重大变化吗？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 13 Nov 2023 22:39:04 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 13 Nov 2023 22:39:04 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p><strong>似乎大多数人对人工智能风险没有强烈的先见之明。</strong>我本以为人们的先验会更加怀疑（比如“什么？世界末日？<i>真的吗</i>？”）。但我认为很多人都会说“是的，我完全可以看到人工智能如何导致全球安全风险”，甚至“是的，我实际上很担心类似天网的人工智能，我很高兴其他人正在努力”关于这一点。”</p><p>通常，人们似乎<strong>真正担心人工智能带来的灭绝风险</strong>，但也<strong>没有任何计划来解决这个问题</strong>。有人提醒我，“X 是一种存在风险”实际上是一件非常 EA 的事情 -->;“因此我应该认真考虑在 X 上工作。”很多人就像“我很高兴其他人正在考虑这个问题[但我不会，我也不指望我的国会议员会]。”</p><p>就我的效果而言，我认为我主要只是让他们更多地考虑这一点，并将其列入他们内部的“人工智能政策优先事项”列表中。我认为人们忘记了员工的优先事项清单上有大约 100 件事，所以仅仅让他们接触并重新接触这些想法就会有所帮助。</p><p>我还遇到了一些员工，他们似乎非常关心人工智能风险，并且似乎是人工智能政策领域的坚定盟友。我仍然与几个人保持着联系，当托马斯创办人工智能政策中心时，我向他介绍了其中的一些人。如果我希望通过一项法案，我想我可以更好地了解我会尝试与哪些特定人员取得联系。<strong>在我看来，整个华盛顿之行的大部分影响可能在于弄清楚盟军工作人员是谁并与他们建立初步关系。</strong></p><p>最后一件事是，我通常不强调失去控制//超级智能//递归自我完善。我没有隐藏它，但我将其包含在更长的威胁模型列表中，并且它很少是我试图传达的主要内容。如果我再做一次，我可能会更多地强调这些威胁模型。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Wed, 15 Nov 2023 22:42:42 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Wed, 15 Nov 2023 22:42:42 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><blockquote><p>在我看来，整个华盛顿之行的大部分影响可能在于弄清楚盟军工作人员是谁并与他们建立初步关系。</p></blockquote><p>啊好吧！有哪些特征可以很好地预测员工是否会同情这项事业？例如特定地区、政治倾向、其他政策。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 13 Nov 2023 22:51:23 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 13 Nov 2023 22:51:23 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><blockquote><p>有哪些特征可以很好地预测员工是否会同情我们的事业？</p></blockquote><p><br>并不真地。样本量非常小。就像，总共可能有大约 4 名工作人员，我会把他们安排在“非常关心灭绝风险，并且他们可以在推动立法方面提供很大帮助”的位置。 1 名共和党人和 3 名民主党人。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 13 Nov 2023 22:24:22 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 13 Nov 2023 22:24:22 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>啊，明白了。你们所进行的讨论（在 CAIS 声明发布之前）是否对该声明产生了任何影响（措辞、外展等）？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Wed, 15 Nov 2023 22:37:49 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Wed, 15 Nov 2023 22:37:49 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>讨论并未影响该声明；该声明是在我前往华盛顿之前写的。 （有趣的事实：我是参与起草 CAIS 声明的人之一。认为为一个好句子做出贡献比我所做的许多其他事情的影响力要大 100 倍，这有点奇怪，但是嘿，有时它会起作用那样）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 13 Nov 2023 22:48:17 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 13 Nov 2023 22:48:17 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><blockquote><p>（有趣的事实：我是参与起草 CAIS 声明的人之一。认为为一个好句子做出贡献比我所做的许多其他事情的影响力要大 100 倍，这有点奇怪，但是嘿，有时它会起作用那样）。</p></blockquote><p>该死。我们生活在一个奇怪的世界。顺便说一句，做得很好。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 13 Nov 2023 22:48:28 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 13 Nov 2023 22:48:28 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>谢谢！看到这个声明有多么重要确实很奇怪。</p><p>我认为这也是相当令人谦卑的——当我第一次听到这个声明时（当时我们称其为公开信），我记得当时我很沮丧，就像“嗯，一封公开信会做什么？我们已经有 FLI 暂停信。”</p><p><strong>这是一个有用的提醒，有时您可能无法提前预测某些事情的影响</strong>。事后看来，很明显（至少对我来说）CAIS 声明是有用的，并且变革理论非常可靠。但当时，这并不像是一个落后的总体规划。感觉这只是 20 个项目清单中的一个项目，而且它有一种模糊的变革理论，这只是另一个似乎值得冒险的赌注。</p></div></section><h2>得到教训</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 13 Nov 2023 22:50:22 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 13 Nov 2023 22:50:22 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>如果您再次进行此过程，您会采取哪些不同的做法？让您感到惊讶/您觉得自己从中学到的主要事情是什么？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 13 Nov 2023 22:58:05 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 13 Nov 2023 22:58:05 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p><strong>我想我会写一份文档来解释我的推理</strong>，记录我咨询过的人，记录我所意识到的上行和下行风险，并将其发送给一些 EA。我认为一些谣言称这是以相当单边主义的方式完成的。这很棘手，让我很难过。我不认为我这样做的方式实际上是单边主义的，但我认为通过书面推理来避免误解会更好。 Thomas 在 CAIP 中做了很多这样的事情，并为<strong>“如何在不确定的情况下采取行动，同时以推理透明和高度协调的方式采取行动”等问题提供了一个很好的模型。</strong></p><p>我还认为我会提出<strong>立法草案</strong>（假设我所在的组织对此感到满意）。如果你有立法草案，人们似乎会更认真地对待你。</p><p>我还会写一份<strong>更短的 NTIA 回复</strong>– 我们最终写了一篇大约 20 多页的论文。我会针对较短的材料进行更多优化。</p><p>啊，说到这里，我会带<strong>一份打印出来的单页纸</strong>来解释什么是 CAIS 并总结 NTIA 答复中的监管理念。我在中途就完成了这件事，而且我本来可以早点完成这件事。</p><p>另外，我会带着<strong>名片</strong>来。人们似乎很喜欢名片！ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 13 Nov 2023 23:01:08 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 13 Nov 2023 23:01:08 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>是的，这一切都有道理，尽管我绝对不会提前猜到。</p></div></section><h2>最后拍摄</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 13 Nov 2023 23:02:52 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 13 Nov 2023 23:02:52 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>我想我已经没有什么问题要问了：你还有什么要说的吗？随意闲逛。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 13 Nov 2023 23:26:43 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 13 Nov 2023 23:26:43 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>以下是一些杂项：</p><ol><li>我在华盛顿的经历让我觉得<strong>奥弗顿之窗非常宽</strong>。国会没有对人工智能政策的缓存，而且似乎很多人真的想学习。目前尚不清楚这种情况会持续多久（例如，人工智能风险最终可能会两极分化），但我们似乎正处于一个异常高度开放和好奇心的时期。</li><li>然而，<strong>让国会采取任何行动也非常困难</strong>。就像，由于相当无聊的原因，没有多少法案获得通过。在这个过程中，有很多步骤可能会导致账单失效。当事情需要两党合作时更是如此（目前他们确实这样做，因为我们有民主党参议院和共和党众议院）。这主要让我想到<strong>“哇，现状通常不会发生任何事情，而且需要做很多工作才能获得任何有意义的立法。”</strong>考虑到这一点，我确实认为我们在人工智能安全方面处于一个非常独特的境地（<i>实际上</i>没有那么多事情会带来灭绝风险和各种其他灾难​​性风险；也没有那么多事情会成为现实）参议院多数党领袖的优先事项，激发与世界领导人的国际峰会，或成为整个行政命令的焦点）。</li><li><strong>许多人高估了华盛顿特区的“内部游戏”数量</strong>，尤其是在国会参与方面。有一些秘密的事情正在发生，但在大多数情况下，我认为没有人有掌控权。</li><li>我希望看到<strong>围绕具体政策愿景进行更多协调</strong>。有一段时间，您加入 Cool Kids Club 仅仅是为了关心 xrisk。我认为奥弗顿之窗已经发生了很大的变化，我们已经到了“关心xrisk”已经不够的地步了。重要的是人们支持并愿意倡导哪些具体政策。</li><li>考虑到这一点，我还认为拥有更广泛的人工智能风险社区是有好处的。<strong>协调实施不当可能会导致一事无成，因为你永远无法达成共识</strong>（目前这有利于领先的实验室和不受监管的扩展）。<strong>协调太少可能会导致缺乏联盟建设和不必要的冲突。</strong>我认为我已经从“协调是好的”转变为“如果做得好，协调是好的，但实际上需要技巧、机智和努力才能做好协调”。</li><li>我通常认为<strong>更多的人应该公开写下他们的观点。</strong>当我不知道人们相信什么时，很难协调。我认为社会应该不太愿意赞扬那些没有提出任何特定立场的人。 <strong>&nbsp;</strong></li><li>我对 DC AI 安全社区了解了很多（我所说的“AI 安全社区”主要指那些出于避免 xrisk 或社会规模灾难的愿望而从事 AI 安全工作的人们。有些人被认为是 EA/长期主义者） ，但很多人没有）<ol><li> TLDR：这很复杂。我认为前10%的思想家都非常有才华，并且追求合理的变革理论。另一方面，也有很多人声称对人工智能政策感兴趣，但对各种人工智能安全威胁模型没有基本的了解。人们还（真实且合理地）担心，社交无能和政治无能的新来者可能会以威胁或削弱现有努力的方式进入该领域。</li><li>总的来说，我觉得主流文化对新的政策努力过于不屑一顾。我希望随着人工智能政策对话的不断向前发展并吸引新的人群，这种情况会发生变化。我会对社区的反应更像是“啊，新人感兴趣！让我们给您一些提示/指示，并指出我们所拥有的具体经验并讨论下行风险的具体模型”感到兴奋。现状常常让人感觉不那么具体，而且（在我看来）对新的努力过于保护主义。我发现这种文化让我更难清晰地思考或进行倡导，尤其是我所说的“高度直接性倡导”（EG 主要试图向人们传达你的内部世界状态，而不是主要尝试）传达一系列能够很好地吸引观众的信念）。我认为关于各种倡导工作应该如何“直接”进行认真的辩论（而且我认为如果华盛顿特区的一些人完全直接的话，他们实际上会失去一些影响力/“严肃性点”），但我仍然感到惊讶影响的大小——文化似乎阻碍我和我的同事直接表达的程度。我相信这种文化大大减缓了新政策的努力，并继续以我认为对世界不利的方式威胁/削弱/阻碍新的政策努力。与许多事情一样，我认为高层关注是正确的，但这些高层关注的具体应用/实施方式存在问题</li><li>评估不同人员/计划的跟踪记录也很困难。部分原因是某些信息是秘密的，部分原因是“我们与重要利益相关者有良好的关系”之类的事情是有用的工具性步骤，但不一定转化为影响，部分原因是许多变革理论都是基于点击量的，需要时间才能产生直接影响（例如，如果某人与 X 建立了良好的关系，也许在某个时候 X 将变得与人工智能监管极其相关，但也许只有 1-10% 的可能性是真的。）话虽如此，我认为，如果人们最终更明确地表达自己的信念，更明确地表达他们希望实现的具体政策目标，更明确地表达他们明显的胜利（和损失），那么协调会更容易。如果没有这一点，我们就会冒着赋予那些“玩游戏”、发展影响力但最终没有利用他们的影响力来实现有意义的变革的人太多权力和太多资源的风险。 （另请参阅多米尼克·卡明斯<a href="https://www.dwarkeshpatel.com/p/dominic-cummings#details">播客</a>）。</li></ol></li><li>与此相关的是， <a href="https://forum.effectivealtruism.org/posts/tdaoybbjvEAXukiaW/what-are-your-main-reservations-about-identifying-as-an?commentId=gNC53rsuMNTBjLCWY">奥利弗·哈布里卡（Oliver Habryka）的评论</a>引起了我的共鸣。我发现，当我与“主流 EA”保持一定距离时，我的思维往往会更清晰。有很多抗体和微妙的文化压力可以阻止我思考某些想法，并可能削弱我在世界上采取直接行动的能力。 （当然，我不认为解决方案是“永远不要与 EA 互动”——但我确实认为人们可能低估了社区对良好思考和实现困难事物的负面影响。我确实低估了。）</li><li>对于有兴趣捐赠的人，我目前推荐<strong> </strong>这<strong> </strong><a href="https://www.aipolicy.us/"><strong>人工智能政策中心</strong></a><strong> </strong>（尤其是托马斯·拉森继续高度参与其战略方向）。我与托马斯有一些战略/战术上的分歧，但我认为他是一个非常聪明和有才华的人，我认为他是人工智能政策领域最值得支持的新人之一（COI：托马斯是我的朋友之一，我在人工智能政策中心的早期阶段参与了帮助）。</li><li>如果您想与我交谈，<strong>请随时联系 LessWrong</strong> 。我喜欢与从事人工智能政策工作的人交谈。我也愿意接受我可以做的或我知道的其他人可以做的有影响力的事情。 </li></ol></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Wed, 15 Nov 2023 22:18:15 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Wed, 15 Nov 2023 22:18:15 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>哇，好吧。感谢您进行这次对话！</p></div></section><div></div><br/><br/> <a href="https://www.lesswrong.com/posts/2sLwt2cSAag74nsdN/speaking-to-congressional-staffers-about-ai-risk#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/2sLwt2cSAag74nsdN/speaking-to-congressional-staffers-about-ai-risk<guid ispermalink="false"> 2sLwt2cSAag74nsdN</guid><dc:creator><![CDATA[Akash]]></dc:creator><pubDate> Mon, 04 Dec 2023 23:08:52 GMT</pubDate> </item><item><title><![CDATA[Open Thread – Winter 2023/2024]]></title><description><![CDATA[Published on December 4, 2023 10:59 PM GMT<br/><br/><p>如果它值得说，但不值得单独发表，这里有一个地方可以放置它。</p><p>如果您是 LessWrong 的新手，这里是您自我介绍的地方。欢迎您就您如何找到我们以及您希望从网站和社区获得什么发表个人故事、轶事或只是一般性评论。如果您不想写完整的顶级帖子，这也是讨论功能请求和您对该网站的其他想法的地方。</p><p>如果您是社区新手，您可以开始阅读<a href="https://lesswrong.com/highlights">Sequences 的亮点</a>，这是有关 LessWrong 核心思想的帖子集合。</p><p>如果您想更多地探索社区，我建议您<a href="https://www.lesswrong.com/library">阅读图书馆</a>，<a href="https://www.lesswrong.com/?view=curated">查看最近策划的帖子</a>，<a href="https://www.lesswrong.com/community">看看您所在的地区是否有任何聚会</a>，并查看<a href="https://www.lesswrong.com/faq">LessWrong 常见问题</a><a href="https://www.lesswrong.com/faq#Getting_Started">解答</a>的入门部分。如果您想了解网站上的内容，您还可以查看<a href="https://www.lesswrong.com/tags/all">“概念”部分</a>。</p><p>开放线程标签在<a href="https://www.lesswrong.com/tag/open-threads?sortedBy=new">这里</a>。 Open Thread 序列在<a href="https://www.lesswrong.com/s/yai5mppkuCHPQmzpN">这里</a>。</p><br/><br/> <a href="https://www.lesswrong.com/posts/tRa92qDonDLi6RA8u/open-thread-winter-2023-2024#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/tRa92qDonDLi6RA8u/open-thread-winter-2023-2024<guid ispermalink="false"> tra92qDonDLi6RA8u</guid><dc:creator><![CDATA[habryka]]></dc:creator><pubDate> Mon, 04 Dec 2023 22:59:51 GMT</pubDate> </item><item><title><![CDATA[Interview with Vanessa Kosoy on the Value of Theoretical Research for AI]]></title><description><![CDATA[Published on December 4, 2023 10:58 PM GMT<br/><br/><p>以下是我与 Vanessa Kosoy 进行的<a href="https://youtu.be/1MCRQF0_5zY?feature=shared"><i>视频采访</i></a><i>的文字记录（经过语法编辑）</i> ，从我的<a href="https://www.zenmarmotdigital.com/blog/interview-with-vanessa-kosoy"><i>博客</i></a><i>交叉发布</i><i>。它旨在（相对）对初学者友好地解释</i><a href="https://www.lesswrong.com/posts/ZwshvqiqCvXPsZEct/the-learning-theoretic-agenda-status-2023#Direction_6__Metacognitive_Agents"><i>学习理论议程</i></a>的目标<i>，以及为什么需要更多的理论工作来确保人工智能大规模安全可靠。</i></p><p></p><p><strong>简介（作者：Will Petillo）：</strong>讨论人工智能的未来往往会变得哲学化。有“目标”或“理解”意味着什么？追求权力是想要东西的默认结果……还是我们独特的进化历史造成的人类怪癖？是什么激发了善良？以这种方式提出问题可以使问题易于理解，让每个人都参与对话。但这种缺乏精确性也使得此类问题变得棘手，因为分歧会变成直觉冲突。</p><p>今天“一致性守护者”的嘉宾是瓦妮莎·科索伊 (Vanessa Kosoy)，她是一位由机器智能研究所 (MIRI) 和长期未来基金 (LTFF) 支持的独立研究员，致力于构建安全人工智能的数学理论。这种对理解第一原理的关注使她的工作与领先人工智能实验室的“快速行动并打破常规”实验方法形成鲜明对比。在这次采访和其他地方，瓦妮莎捍卫了更加基于理论的方法的价值，并解释了探索机器学习作为基础科学的意义。</p><p></p><p> <strong>Will Petillo：</strong>您是如何进入人工智能安全领域的？</p><p> <strong>Vanessa Kosoy：</strong>我一直是一个自学者，所以我倾向于自学东西。当我小的时候，我想我会成为一名理论物理学家。我实际上拥有数学学士学位，但在完成学士学位后，我没有进入学术界，而是决定在软件行业从事职业生涯。</p><p>我在软件行业有很长的职业生涯，特别是算法工程，主要是计算机视觉，各种角色，算法工程师，团队领导，研发经理。我也有自己的创业公司。大约 10 年前，我是一名顾问。我接触到了人工智能带来的生存风险这一整个话题，并开始思考，嗯，这实际上似乎很重要。所以我开始转向这一点，最初只是我在空闲时间做研究。随后得到了 MIRI 的支持。最近我还得到了长期未来基金的支持，这使我能够全职工作。</p><p> <strong>Will Petillo：</strong>那么这个过程是怎样的呢？你只是以一种自我导向的方式工作，然后你获得了美里和其他来源的支持？这是怎么来的？</p><p> <strong>Vanessa Kosoy：</strong>我开始阅读 MIRI 和 Less Wrong 的人们写的一些东西。我开始研究自己的想法，并在 Less Wrong 上发表文章。之后，我被邀请参加一些研讨会、一些活动，最终 MIRI 说，好吧，看来你在这里做了一些不错的工作，所以也许我们也会付钱给你。我很棒，因为这也使我能够做更多的事情，而花更少的时间做其他事情。<br><br>威尔·佩蒂略<strong>（Will Petillo）：</strong>这里为观众介绍一下背景知识。 Less Wrong 是一个受欢迎的博客。它最初是关于理性的，但也是关于人工智能相关的事情。 MIRI 是机器智能研究所。我喜欢将他们描述为在它变得很酷之前就致力于协调的人。请告诉我更多关于 MIRI 作为一个机构的信息。<br><br> <strong>Vanessa Kosoy：</strong> MIRI 或多或少是第一个谈论人工智能存在风险的人。 Eliezer Yudkowsky 在 2000 年开始谈论这个问题，最初 Miri 只是 Yudkowsky，然后多年来他们设法获得一些资金来吸引其他研究人员加入。他们正在思考这个问题：我们如何使人工智能安全，以及我们如何解决这个问题？我们能想出什么样的数学理论来解决这个问题？这甚至早于深度学习革命开始之前，也早于近年来大型语言模型的整体炒作。他们的大部分时间都致力于提出一些基础数学理论，以帮助我们进行人工智能调整。<br><br>最近，他们转向外展并试图影响政策，因为他们相信时间确实很短，不幸的是我们没有时间发展这一理论。<br><br><strong>威尔·佩蒂略：</strong>你参与了这一转变吗？<br><br> <strong>Vanessa Kosoy：</strong>不，我的观点不同。你可以说我比较保守。我认为时间表并不像风险界许多人认为的那么短。我认为，如果通过政策渠道规范人工智能发展并推迟人工智能发展以阻止真正危险的人工智能出现的努力能够成功，那么这只是为我们赢得了时间。那么问题是：为我们争取时间做什么？我认为理论基础绝对仍然是我们应该利用我们所拥有的时间或我们将通过某种政策计划成功购买的时间做的事情中最重要的事情，无论怎样。<br><br>我认为实际上在任何世界中，创建这个基础理论都是关键。这就是我正在做的事情。这绝对是我的个人技能和优势所在，研究数学而不是政策。<br><br><strong>威尔·佩蒂略：</strong>你提到了时间表。直觉上，我知道不可能以任何精确度真正预测这些事情，但就你的动机而言，你认为需要解决这些问题的时间表是什么？<br><br> <strong>Vanessa Kosoy：</strong>有些人认为 AGI 将在 10 年甚至更短的时间内到来。我认为这有点极端。但当事情需要解决的时候，越快越好不是吗？如果我们在五年内找到解决方案，那么我们的处境会比我们在 10 年内找到解决方案更好，这仍然比我们在 20 年内找到解决方案更好，依此类推。<br><br>实际上，我个人的观点是，我们还需要几十年的时间才能真正实现那种带来生存风险的人工智能。所以这给了我们更多的时间，但不是无限的时间。<br><br> <strong>Will Petillo：</strong>是什么让你觉得这是你想做的事情？<br><br> <strong>Vanessa Kosoy：</strong>一开始更像是一种好奇心，因为它实际上是从我完全随机发现开始的，你可以说一些关于 AGI 的论文，甚至不是关于人工智能对齐或风险或类似的东西，而只是 Jürgen Schmidhuber 和 Marcus Hutter 的一些论文关于 AGI 的一些想法。我一直是一个数学迷，所以有那些思考 AGI 的数学框架看起来真的很酷。我开始阅读相关内容，最终也发现了Less Wrong，其中也有人在讨论这类事情。<br><br>一方面，我读了越来越多的 Eliezer Yudkowsky 写的关于这个主题的文章，以及 LessWrong 上的人们写的关于这个主题的文章，但我也开始思考数学模型。最终，我突然意识到，当你思考实际的数学时，就完全有道理了，没有任何数学原因可以解释为什么人工智能必须关心人类或关心任何与我们人类关心的事情一致的东西。<br><br>另一方面，它似乎也明显比我们更有能力。我认为直观上很清楚，但对我来说，我喜欢通过数学来理解一切。因此，当我看到你实际上可以将其放入数学模型中时，我真的意识到这是真实的事情，这是我们真正应该关心的事情。</p><p><strong>威尔·佩蒂略：</strong>没有理由认为人工智能一定是好的，这听起来很像尼克·博斯特罗姆写的正交性论文。智力和事物的美好程度并不一定要同时出现；任何一套价值观都可以与任何水平的智力相匹配。这本质上就是你的见解吗？<br><br> <strong>Vanessa Kosoy：</strong>是的，这正是术语。事后看来，这似乎是一件显而易见的事情。但对我来说，有必要看到你实际上可以用数学对象来思考它；值可以形式化为效用函数。然后，代理可以被形式化为某种优化器、某种贝叶斯最优策略或该效用函数的任何形式。实际上，你可以在每个术语背后赋予严格的含义，并发现它们实际上都是有意义的——这不仅仅是某种哲学上的挥手把戏。<br><br> <strong>Will Petillo：</strong>在您看来，导致人工智能对齐问题变得困难的根本原因是什么？<br><br> <strong>Vanessa Kosoy：</strong>我认为这个问题很难。我认为，首先，困难在于我们的目标非常狭窄，因为人类价值观非常复杂和具体。我们关心很多非常细节的事情：爱、友谊、美（以我们自己的主观理解）、性，所有这些东西都是人类的东西，因为一些复杂的进化事故而存在，就像它发生在某些人身上的方式一样。非常特别的星球。这是特定宇宙历史上非常特殊的时刻。这组价值观只是你可以想象的巨大的可能价值观或思想空间中非常非常狭窄的一部分。<br><br>因此，按照我们的标准，大多数人的思想绝对不会对我们有好处。更糟糕的是，内特·苏亚雷斯（Nate Soares）在他最近的一篇文章中很好地阐述了这种现象，他在其中写道，围绕代理能力存在一个吸引力盆，但对于代理对齐却没有吸引力盆。这意味着，如果您施加足够的优化压力，即使使用强力技术，您最终也将生成功能强大的代理。进化就是一个例子，对吗？进化是一种非常原始的蛮力算法，最终创造了人类大脑，这是一种更加复杂的算法。如果您投入足够的强力优化来寻找在开放世界环境中成功的事物，最终您将遇到智能代理。这甚至是在你在方程中加入递归自我改进之前的，这使得它作为你汇聚的这种吸引力盆地变得更加强大。然而，在与人类价值观保持一致方面，情况并非如此。很有可能的是，我们可以通过盲目或半盲目的试错，早在我们了解足够的知识以实际使这些代理对齐之前就创建出高能力的代理。<br><br> <strong>Will Petillo：</strong>这听起来像是违背了博斯特罗姆流行的工具融合的另一个理念，即几乎任何足够努力优化的系统都需要诸如生存之类的东西。<br><br> <strong>Vanessa Kosoy：</strong>有一种工具收敛目标的概念，这是大多数智能代理都会追求的某些目标，因为它们帮助他们实现最终目标，无论他们的最终目标是什么。这些都是诸如生存、获得更多资源、变得更加聪明等等之类的事情。但人类的价值观并非如此。我想，如果我们设法构建一个能够生存并获得大量资源的人工智能，这对人工智能来说是件好事，但它对我们与我们的价值观保持一致没有任何帮助。这是一种非常不同的事情。<br><br> <strong>Will Petillio：</strong>现代人工智能是根据人类生成的数据进行训练并存在于人类社会中这一事实没有帮助吗？<br><br> <strong>Vanessa Kosoy：</strong>我认为这有帮助，但也留下了很多问题。一个问题是：好吧，你可以从人类生成的数据中学习，但你如何从中进行概括呢？因为确实不清楚需要什么条件才能获得良好的概括，尤其是当您正在学习的概念非常复杂时。<br><br>您正在学习的概念的复杂性越高，学习它所需的数据点就越多。我们正在利用近年来炒作的所谓大型语言模型来尝试模仿人类。我的意思是，这很好。它可能会以一定的概率带来一些好处——但概率不是很高。但它的问题是，为了使用它，您需要在训练分布之外进行泛化。这里我们实际上需要看看目标是什么。<br><br>问题是，从技术上讲，创造出超级智能的人工智能是可能的，但这将是危险的。为了解决这个问题，仅仅创建某种不危险的人工智能是不够的，因为否则他们可能只是编写一个不做任何事情的算法。这并不危险，任务完成了。我们需要能够创建足够强大的人工智能，作为防御系统来抵御那些潜在危险的人工智能。因此，这些系统必须具有超人的能力，能够构建复杂的世界模型，并在此基础上制定复杂的长期计划。这远远超出了大型语言模型或任何基于人类模仿的训练分布。目前还非常不清楚我们是否真的可以依赖我们必须泛化到训练分布之外的算法，而不会完全失去它们的所有对齐属性。<br><br> <strong>Will Petillo：</strong>总而言之，法学硕士从根本上来说是模仿性的，这本身似乎并不是特别危险，但它也限制了他们能做的事情。因此，我们不能真的指望开发会就此停止。最终可能会添加像强化学习这样的东西——也许不一定是算法，但可以像围棋中的 Alpha Zero 一样具有创造性，并找到一个以前没有人见过的真正创造性的棋步。因此，我们需要为更强大的事物做好准备，因为它们将是有用的，而导致建立法学硕士的经济学将导致建立更大的事物。这就是你的意思吗？<br><br> <strong>Vanessa Kosoy：</strong>是的，这听起来很当场。要么是强化学习，要么……好吧，我不想过多地推测让人工智能变得更强大需要什么，因为这不是很好的信息。</p><p><strong>威尔·佩蒂略：</strong>很公平。继续讨论您实际从事的事情，我看到的与此相关的一个想法是术语“代理基础”。还有“学习理论议程”。那些东西是什么？<br><br> <strong>Vanessa Kosoy：</strong>智能体基础是一个抽象的概念，它表明我们需要创建一个基础数学理论来解释智能体是什么。从数学角度来说，算法作为代理意味着什么？可以使用哪些类型的代理？他们可以拥有或不具备哪些能力？等等。学习理论议程比这更具体，因为它就像一个试图实现这一目标的非常具体的计划。具体来说，是通过建立在统计和计算学习理论、算法信息论、控制理论等基础上的工具。这是我创建的程序，旨在应对提出这些代理基础的挑战。<br><br> <strong>Will Petillo：</strong>好的，代理基础就像“思维如何工作？”的问题，其中包含人工智能，而学习理论议程就像“我们如何设计算法，将其推向一个好的方向？”是对的吗？<br><br> <strong>Vanessa Kosoy：</strong>我不会那样说。我只想说，特工基金会只是试图了解思维如何运作，人们一直在尝试以各种方式做到这一点。 MIRI 历史上有各种证明理论模型试图解决这个问题，然后是加拉布兰特的逻辑归纳法，在这个非常广泛的保护伞下有各种想法，而学习理论议程是一种非常具体的方法。<br><br>正是这种方法以 AIXI 和经典强化学习理论为起点，然后寻找其中缺少的成分，以便拥有代理的基础理论，并开始利用下贝叶斯主义和下贝叶斯物理主义和元认知代理等等。<br><br> <strong>Will Petillo：</strong>您在这里谈论的代理和思维类型，是否与前沿的大型语言模型相关，或者是否更广泛地涉及人工智能或任何类型的思维实体？<br><br> <strong>Vanessa Kosoy：</strong>当我说经纪人时，我的意思是非常广泛的。比现有的人工智能甚至只是人工智能要广泛得多。当然包括人类、潜在的外星人或其他什么。因此，对我来说，代理是一个具有特定目标的系统，它正在学习它所嵌入的世界的复杂模型，并使用这些模型来构建长期计划以实现其目标。这就是我所说的“代理”的非正式描述。该程序的整个目标是从这个到一个完全正式的数学定义，并研究这个定义的所有含义。</p><p> <strong>Will Petillo：</strong>因此，即使不超出法学硕士，它的范围甚至比机器学习还要广泛。采取这种做法的原因是什么？鉴于机器学习的主导地位，为什么不关注那些似乎使用最广泛的东西呢？</p><p> <strong>Vanessa Kosoy：</strong>首先，让我们保持术语的顺序。我会区分人工智能、机器学习和深度学习。人工智能是人们自 20 世纪 50 年代以来就开始思考的东西，关于如何构建思维系统，但并没有真正理解它的含义，而只是某种直观的概念，认为存在思考这样的东西，我们应该能够在机器中复制它。<br><br>机器学习是出现的一种更具体的方法……好吧，我不想具体指出什么时候，但可能是在八十年代。机器学习具体是这样的想法：思维的核心要素是学习，学习意味着你正在与一些未知的环境交互，你需要创建这个环境的模型。因此，您需要获取您看到的数据并使用它来创建模型。这类似于科学家如何进行实验、收集数据，然后根据这些数据建立理论。</p><p>这个总体想法称为机器学习，或者更准确地说，只是学习。 “机器”部分来自尝试想出在机器内部实际实现这一点的方法。这是一个有很多数学理论的领域。机器学习背后的数学理论就是所谓的统计和计算学习理论，这实际上是学习理论议程的基础。这就是为什么它被称为“学习理论”。</p><p>有一种假设认为，这种学习概念抓住了我们所说的思维的大部分重要部分。我认为这一假设得到了最新技术发展的充分支持。这是我完全赞同的，也是我整个研究计划的基础。所以这里并不矛盾，因为学习仍然是一件很普遍的事情。人类也进行学习。外星人也必须学习。</p><p>深度学习是一组更具体的算法，用于如何在机器中实际高效地完成学习，这就是 2010 年左右深度学习革命的开始，尽管这些算法在此之前已经以某种形式存在了几十年。但需要一段时间才能获得正确的细节，并拥有合适的硬件来运行它们。深度学习的不幸特征是我们无法从数学上理解它。很多人都在试图理解它，但我们并没有一个很好的理论来解释它为什么有效。这就是为什么它不是我的研究计划的重点，因为我试图提出一些数学理解。我绝对希望人们最终能够解开深度学习如何运作的这种谜团，然后就有可能将其整合到我正在构建的理论中。<br><br>但即使我们有了这个理论，那么以尽可能广泛的普遍性来思考似乎仍然非常重要，因为，首先，我们不知道今天存在的算法将是带来 AGI 的算法。而且因为最广泛的普遍性只是思考问题的正确抽象级别，以了解系统“对齐”意味着什么的概念。这里需要解决一些哲学问题，并且它们特定于一些非常特殊的算法。此外，事实上，我实际上希望这个理论包括人类，因为我可能想用这个理论来形式化价值学习等事物。如何设计一个能够向人类学习价值观的人工智能系统？<br><br> <strong>Will Petillo：</strong>查看机器学习和深度学习的维基百科级别，或者只是浏览互联网描述，很容易互换使用它们。我想我已经看到了这样的描述，深度学习就是添加多层神经元的想法。因为有多层，所以它很“深”<br><br> <strong>Vanessa Kosoy：</strong>让我尝试澄清其中的区别。机器学习谈论获取数据并从中构建模型。您正在构建的模型类型可能非常不同。在深度学习之前，我们有支持向量机等算法，多项式回归也是一种非常简单的机器学习类型——将模型拟合到数据。统计中使用的各种方法可以被视为一种机器学习。有一些模型或假设空间，您尝试以最佳方式使用数据来推断正确的假设是什么，或者如果您正在使用贝叶斯方法，则获得假设的一些概率分布。<br><br>但是，不同类型的假设类会在算法的能力方面以及我们所知道的如何学习这些假设类方面导致非常不同的结果。我们知道什么可以用数学方法证明在什么条件下我们可以真正学习它们？比如支持向量机，数学理论基本解决了。有一些建立在其之上的内核方法，并且也有非常扎实的数学理论。深度学习是一种特殊类型的学习算法，它使用人工神经网络架构。</p><p>这不仅仅是多层，还有很多细节很重要。例如，激活函数是 ReLU，这一事实对于您在训练中使用哪种正则化方法非常重要。例如，辍学基本上是深度学习革命的开始。如果您正在使用序列，那么我们有变压器，这是一种非常具体的网络架构。因此，多年来人们实际上提出了很多非常具体的细节，主要是通过反复试验的过程，看看什么是有效的。我们没有一个好的理论来解释为什么这些特定的东西运作良好。我们甚至不了解这些东西实际上正在学习的模型空间，因为你可以从理论上证明，如果你采用一个神经网络，然后让它学习另一个神经网络，那么在某些情况下这是不可行的。<br><br>但对于现实世界的问题，神经网络在很多时候都能成功学习。这表面上是因为现实世界具有一些使其可学习的特定属性，或者神经网络正在学习一些特定的潜在假设类，并且它捕获了许多现实世界的现象，但我们甚至没有数学描述这个基本假设类别是什么。我们对一些非常简单的情况有一些结果，比如两层或三层神经网络，或一些其他简化的假设，但我们还没有接近得到完整的答案。<br><br> <strong>Will Petillo：</strong>深度学习假设了世界的某些情况，就其可以获取的信息而言，它恰好工作得相当好，但目前还不清楚它的假设是什么。</p><p><strong>凡妮莎·科索伊：</strong>是的，完全正确。所以我们有不同的不可行定理，它说对于任意数据，即使该数据是完全可实现的，即使该数据使得神经网络可以完美地表达一个完全正确的模型，该问题也是不可行的。一般来说，梯度下降不会收敛到正确的模型，而且其他算法也不会收敛，因为问题很棘手。世界具有一些属性，并且由于深度学习在如此多种不同的情况下取得了成功，所以感觉这些属性应该有一些简单的数学描述。<br><br>它不像某些特定于文本、音频或图像的属性。这些属性非常通用，适用于各种不同的模式和问题。这些是我可以推测的属性，例如，与组合性有关，现实世界通常如何被很好地描述为由部分组成，以及事物如何根据不同的空间尺度或不同的时间尺度进行解耦。动态正在发生。但我们没有真正解释它的理论。<br><br> <strong>Will Petillo：</strong>您提到 ReLU 是有效的例子之一。据我了解，ReLU 基本上就像获取输出，以一种可以表示为一侧平坦且对角线超过零的图形的方式对其进行更改。而以前，模型通常使用 Sigmoid 作为激活函数，它更像是一条平滑的曲线，可以防止数字变得太大。出于某种原因，ReLU 效果更好。我从你的解释中得到的感觉是，这种变化会影响神经网络能够以更符合现实的方向理解什么样的事物。但所有这些变化都是以“把东西扔到墙上，看看什么粘住”的方式开发的，只是简单地测量结果，而没有真正理解<i>为什么</i>ReLU 比 sigmoid 更好。<br><br><strong>凡妮莎·科索伊：</strong>或多或少是对的。当我们说神经网络可以“理解”什么时，我们必须小心我们的意思。这是一个非常复杂的概念，因为它不仅仅是神经网络可以用一组权重来表达的内容，而是神经网络实际上可以通过梯度下降过程学习的内容。它不仅与神经网络可以描述的函数空间有关，而且与我们查看特定数据集时在这个权重空间中创建的整个损失景观有关。<br><br><strong>威尔·佩蒂略：</strong>当你描述梯度下降和损失景观时，我经常听到的比喻是一个从山上滚下来的球——有一个恒定的重力，你希望球下降到海平面。但通常情况下它不会，因为它发现了一些局部最小值，比如一个洞或其他东西，它可以移动的任何方向都是向上的，所以它不会再滚动。所以你必须塑造景观，使球始终到达海平面。<br><br> <strong>Vanessa Kosoy：</strong>是的，这是一个很好的解释。梯度下降是我们有很好的数学理论来解释它如何收敛到凸函数的全局最小值，但神经网络的损失是非凸的......但它仍然恰好有效。人们已经对其工作原理有了一些了解，但我们仍然没有完整的答案。<br><br><strong>威尔·佩蒂略：</strong>好吧，如果地貌确实崎岖不平，那么你就不会期望球到达海平面，因此它无论如何都会到达海平面这一事实需要一个我们实际上没有的解释。我可以看到这种框架如何引发了许多有关不可预测性的问题。<br><br>接下来，您曾提到过 AIXI。那是什么？<br><br> <strong>Vanessa Kosoy：</strong> AIXI 是 Marcus Hutter 的想法，它应该是完美代理的数学模型。它的工作原理是：有一个先验，即所罗门诺夫先验。对于那些不知道这是什么的人来说，这基本上是一种用数学形式化奥卡姆剃刀概念的方法。奥卡姆剃刀的思想是，简单的假设应该被认为比更复杂的假设更有可能是先验的。这确实是所有理性推理的基础。哈特采用了所罗门诺夫先验，这是一种非常聪明的方法，可以在数学上形式化奥卡姆剃刀的概念，并且说，好吧，让我们考虑一个生活在所罗门诺夫先验的宇宙样本中的智能体。这个代理有一些特定的奖励函数，它正在最大化。我们假设它只是以贝叶斯最优方式运行。因此，它只是遵循策略，使其根据先验最大化其预期效用。我们称之为“艾希”。这是一个非常酷的想法......只是它有很多问题，首先是它无法计算的“小”问题。即使在理论上，也没有一种算法可以实现它。<br><br><strong>威尔·佩蒂略：</strong>我想我曾经听过这样的解释：将整个宇宙想象成一堆比特——1和0。一开始，所有这些都可以是一或零，然后你得到一点数据，现在你已经锁定了其中一些数字，并将所有可能的空间减少了一半。当你不断学习时，你会变得越来越确定。<br><br> <strong>Vanessa Kosoy：</strong>实际上比这更微妙一些。拥有很多可能性这一事实并不意味着它是不可计算的。也许确切的事情是无法计算的，但你仍然可以想象有一些聪明的算法可以近似这个贝叶斯推理过程。例如，如果你看看经典的强化学习理论，就会发现有一些算法可以在具有 n 个状态的任意马尔可夫决策过程中进行学习。在具有 n 个状态的马尔可夫决策过程中，仍然存在指数级大的可能方式空间，并且我们仍然拥有实际上有效的算法，可以通过利用问题的某些属性，从指数级大的事物中收敛到正确的事物。<br><br> AXI 的问题是，它的先验是这样的，即使先验中的单个假设在计算上也已经是任意昂贵的，因为在它的先验中它考虑了每个可能的程序，所以你可以在通用图灵机上编写的每个可能的程序都是一个可能的假设了解世界如何运作。其中一些程序的计算成本极其昂贵。其中一些程序甚至不会停止，它们只是进入无限循环。你甚至不知道是哪一个，因为这就是停机问题，对吗？这就是为什么 AIXI 不适合做可计算的事情，更不用说计算上易于处理的事情了。<br><br> <strong>Will Petillo：</strong>抛开不可计算性这个小问题不谈，“完美算法”……这是什么意思？如果 AIXI 是通过某种方式神奇地计算出来的，它会安全吗？</p><p> <strong>Vanessa Kosoy：</strong>不，这并不能保证安全。它是“完美”的，因为它是你能想象到的最强大的算法。再次，在一些假设下。我的意思是，这还存在其他问题，例如它假设外部世界比代理本身更简单。这有很多问题，但如果你能把所有这些问题放在一边，那么你可以说这是最好的代理。从这个意义上来说，它是完美的。这是非常非常不安全的。为了保证它的安全，我们需要以某种方式将正确的实用函数插入其中。这仍然是一个非常重要的问题。</p><p> <strong>Will Petillo：</strong>假设你正在寻找可计算的东西，你会寻找什么样的算法？</p><p> <strong>Vanessa Kosoy：</strong>可计算性只是问题之一。我想象会有一种我称之为节俭普遍先验的东西，这是我们可以在数学上定义的某种先验，它同时足够丰富以捕获各种各样的现象。另一方面，我们将有一些聪明的算法，实际上可以允许对这个先验使用进行有效的学习，例如，这个先验假设的一些组合属性或类似的东西。</p><p>但即使事先知道这一点，您还需要处理许多其他概念问题。就像我所说的特权问题，奥卡姆剃刀和 AXI 的形式化赋予了观察者特权，你需要了解如何处理这个问题。还有一个可实现性的问题，你实际上不能有一个假设来精确描述宇宙，而只能有某种近似或部分描述，你需要了解如何处理它。还有一个事实是，您希望效用函数不仅仅是您观察的函数，而且还包括一些您无法直接观察到的参数。您还希望能够证明该算法的一些频率论保证。要知道该算法实际上需要了解多少数据才能学习特定事实并拥有良好的理论。研究 AIXI 等模型时会出现一系列不同的问题。<br><br> <strong>Will Petillo：</strong>研究 AIXI 之类的模型，这就是您正在做的工作吗？</p><p> <strong>Vanessa Kosoy：</strong>我想，是的，如果你想用一句话来表达的话，你可以这样做。<br><br> <strong>Will Petillo：</strong>您有兴趣解决哪些有趣的问题？我见过纽科姆的问题以及与此相关的问题。<br><br><strong>凡妮莎·科索伊：</strong>纽科姆的问题是埃利泽·尤德科斯基（Eliezer Yudkowsky）写的很多东西，作为经典理性解释中非常令人困惑的一个例子。您有两个框需要从中进行选择。一盒有一千块钱。另一个盒子要么什么也没有，要么有一百万美元。您可以选择第一个盒子，也可以拿走两个盒子里的钱。通常情况下，拿走两个盒子里的钱总是比只拿一个盒子要好。<br><br>除了在这个现场实验中，有一个叫做欧米茄的实体可以预测你会做什么，因此如果它知道你只会拿走那个盒子而不会尝试拿走那一千美元，那么它只会将 1,000,000 美元放入另一个盒子中盒子也是如此。因此，只有当您是那种可以预测（对于欧米茄）只拿走一个盒子的特工时，只有在这种情况下，您才能带着 1,000,000 美元离开这个房间。而在另一种情况下，您只有 1,000 美元。因此，可以说，拿一个盒子比拿两个盒子更好，这与许多经典的理性解释所说的相反。这是一个有趣的思想实验的一个例子。</p><p>对我来说，这种思想体验是不可实现性问题的一个特例，在这种情况下，您需要处理非常复杂的环境，以至于您无法对可以实际模拟的环境进行完整的描述。因为在这个例子中，环境中包含了这个代理Omega，它模拟了你，这意味着你不能模拟它，因为否则就会产生这种循环悖论。实际上，我还表明，我处理不可实现性的理论（我称之为下贝叶斯主义）实际上会在此类类似纽科姆的问题场景中带来最佳行为。<br><br><strong>威尔·佩蒂略：</strong>研究类似纽科姆问题的原因并不是因为我们期望在某个时候面对欧米茄为我们提供盒子，而是因为这只是一种说明性的思考方式，思考如何在你不知道的情况下处理事情这是怎么回事。也因为可能很容易说，“是的，好吧，我只拿一盒，因为这样我会得到更多”，但是当你真正深入了解一个连贯的、非手作的理由来解释为什么时，然后可能会产生一些有趣的见解。通过探索这些事情，你有什么发现吗？</p><p> <strong>Vanessa Kosoy：</strong>我想说，下贝叶斯主义本身就是一个有趣的发现，它是对代理的一些理论描述，可以推理复杂的世界，而这些世界对于代理来说太复杂了，无法模拟。现在我通过陈述不可实现性问题来描述动机，但我实际上思考这个问题的方式是通过思考所谓的逻辑不确定性。人们开始思考它的原因是所谓的无更新决策理论，它来自对纽科姆时间悖论的思考。因此，这一切都来自于这种推理，尽管事后你可以通过一些更普遍的抽象思维来激发它。<br><br> <strong>Will Petillo：</strong>这些决策理论类型的问题与打造更安全的人工智能之间有什么联系？<br><br> <strong>Vanessa Kosoy：</strong>这个想法是创建一个代理的通用数学理论。它帮助我们让人工智能更安全的方式有几个原因，最明显的是，通过这个理论，我们希望能够提出严格的模型来解释系统作为一个协调代理意味着什么。 。有了这个严格的定义，我们将能够提出一些算法，我们可以证明这些算法实际上是安全的代理。或者至少我们可以有一些猜想，表明这种猜想的给定模型，我们认为这些算法是安全代理。就像在密码学中一样，你有一些具有非常有力的证据支持的猜想。</p><p>我们至少可以有一些半正式的论证，因为现在当人们争​​论某个特定设计是否安全时，一切都归结为那些挥手的哲学论证，而这些论证没有任何真正坚实的基础。然而，这为我们提供了更精确、更清晰地思考此类问题的工具。假设它还赋予我们更多的权力来利用实证研究，因为也许我们将能够将我们拥有的实证研究，将其插入数学理论中，并得到一些关于我们期望这些结果如何实际外推到各种制度的答案，其中我们还没有这样做。<br><br> <strong>Will Petillo：</strong>您正在进行的这一系列研究最终是否可用于评估大型语言模型或基于深度学习的系统等事物，以便能够更确定地判断它们的安全或不安全程度？<br><br> <strong>Vanessa Kosoy：</strong>我认为产生影响的途径有多种。因此，我们最终会提出深度学习理论，从而产生影响。或者，如果不是一个完全经过验证的理论，那么至少有一些关于深度学习如何工作的强有力的猜想，可以与我正在构建的代理理论相结合。然后我们可以使用这种复合理论来证明事物，或者至少对深度学习中构建的系统的属性进行强有力的论证。</p><p>当我们使用这一理论提出构建人工智能的全新类型的算法时，可能会产生不同的影响路径，这些算法不是深度学习，但我们对此有很好的理论理解。</p><p>还有第三种可能性，我们不会有一个好的理论，但我们至少可以通过类比进行推理，类似于有多少深度学习算法是通过类比我们有数学理论的某些算法来设计的。例如，深度 Q 学习类似于简单 Q 学习，我们有数学理论。因此，我们可以想象一个世界，其中我们有某种理想主义的玩具模型算法，我们有一些严格的论证为什么它们是对齐的，然后我们有一些更多的启发式算法，我们无法直接证明这些算法，但可以说它们是相似的到那些玩具模型。<br><br><strong>威尔·佩蒂略：</strong>所以我听到了三种影响途径。人们可能会构建一种不同形式的人工智能，它可以从头开始验证，并且可以做与基于深度学习的人工智能相同的事情，但以一种更严格的方式。第二个是评估或至少更好地理解深度学习或任何最先进的技术。第三种，介于两者之间，是拥有一种更简单的人工智能形式，可以类比最先进的事物，这样你就可以使用前者来理解后者。<br><br> <strong>Vanessa Kosoy：</strong>是的，听起来不错。<br><br> <strong>Will Petillo：</strong>我想重点关注利用基础研究来理解深度学习等其他事物，了解这种基于理论的方法。引入完全相反的观点，有人可能会说：不，你应该只看正在使用的东西并收集有关它的数据，然后通过查找数据中的模式来建立你的理论。当理论被证明是错误的——由于更多的数据——然后更新你的理论。为什么要提前研究理论？</p><p> <strong>Vanessa Kosoy：</strong>最大的原因是，如果没有基础理论，就无法从实证研究中可靠地推断。因为例如，您可能会进行一些测量并发现一些趋势......但随后会出现一些您在趋势中看不到的相变，但会发生这种情况并且行为会改变为完全不同的状态。而且因为没有理论解释，所以你不会注意到，或者人们会转而使用完全不同的算法，这些算法的行为方式完全不同。</p><p>你可能有现有人工智能的经验模型，但这些经验模型非常短视。他们总是向前迈出一步。然后你就看不到前方三步之外的悬崖了。根据发生的新事物更新这些理论、经验模型——可能还不够快。最终你跌下了悬崖，然后再说“哦，实际上，趋势线是错误的！”就为时已晚了。</p><p>幸运的是，我们所处的领域即使没有经验数据，也有工具可以进行研究。当然，我们应该使用我们拥有的经验数据，但我们不会受到经验数据的瓶颈，因为我们研究的是算法，而算法是数学对象，因此可以用数学方法来研究它们。这与研究某些物理现象非常不同，如果没有数据，就无法在没有数据的情况下生成数据。在这里，这确实应该归结为数学。更准确地说，它应该归结为数学加上我们想要在数学理论中假设的现实世界现象所具有的任何属性。<br><br>是的，这是我们需要经验输入的东西。但另一方面，我们已经对物理学有了很好的理解。因此，考虑到我们所拥有的物理学和其他科学领域的知识，即使我们根本没有经验数据，我们也很有可能拥有足够的信息来纯粹通过数学探究来回答所有问题。这并不是说我们不应该使用经验数据来加强这项研究，但我们并不限于此。</p><p> <strong>Will Petillo：</strong>所以这不是理论与实验之间的选择，我们应该同时使用两者。您专注于理论方面，可以说这方面的工作还不够，因为理论才是瓶颈所在，而不是获取更多数据。<br><br> <strong>Vanessa Kosoy：</strong>是的，我认为我们绝对应该两者都做。理想情况下，需要协同作用，实验产生新现象供理论家解释，理论启发实验。理论家应该告诉实验家哪些问题和什么样的实验最有趣，我们应该有这种协同作用。但我认为，在当前的形势下——尤其是在人工智能领域——理论方面目前被抛在了后面。我认为这就是我们应该投入边际努力的地方。<br><br><strong>威尔·佩蒂略：</strong>你认为现在存在协同效应吗？比如，OpenAI 是否要求 MIRI 对他们的实验提供反馈，或者是否存在任何形式的联系，或者人们只是彼此隔离？<br><br> <strong>Vanessa Kosoy：</strong>我认为它现在几乎不存在了。好吧，不，公平地说，它在某些领域存在，而在其他领域则更少。例如，有人致力于奇异学习理论。我认为它们与实验工作的联系更加紧密，这很好。 MIRI 正在做的研究和我正在做的研究与实验工作的联系要少得多。我有一些计划，作为我的长期大计划的一部分，创建一个实验小组，与我密切合作解决这些问题，但我还没有抽出时间去做。<br><br> <strong>Will Petillo：</strong>如果你可以改变任何人的想法，或者设定政治和商业议程，你希望看到什么有更多的界面？<br><br> <strong>Vanessa Kosoy：</strong>首先，我们只需要更多的理论家。为了拥有一个接口，我们需要与之交互的东西，所以我们只需要更多的理论家。我认为这实际上是现在的瓶颈所在。一旦理论上的进展足够快，就会出现很多问题。我的意思是，已经有一些问题我希望看到实验，但是这个事情发生得越多，我们就会有更多这样的问题。我认为现在主要的瓶颈在于让更多的人研究这个理论。<br><br> <strong>Will Petillo：</strong>如果有更多的理论工作，从外部角度来看会发生什么变化？我想怀疑论者可能会说：“OpenAI 和其他公司正在以一种很大程度上是实验性的方式取得这些真正令人敬畏的突破，而且效果很好！如果它没有坏，就不要修复它！”在你看来，哪里出了问题？<br><br><strong>凡妮莎·科索伊：</strong>我认为目前的道路正在将我们引向一场灾难。我认为像 OpenAI 这样的公司和其他领先的实验室对于自己解决问题的能力过于自信。我认为他们还没有对问题的困难部分提出任何令人信服的解决方案，而且由于缺乏理论理解，他们甚至没有工具来做到这一点。我们甚至没有足够精确的模型来提供我们真正有信心的解决方案。我们需要非常精确地论证使我们相信解决方案是好的。我们甚至没有达到这种精度的工具。<br><br>这些公司所做的基本上只是在反复试验中开发东西。如果我们发现任何问题，那么我们就会进行调整，直到问题消失。这是一种创可贴的方法，也就是说它一直有效，直到不起作用为止。它只是表面上解决问题，但最终会出现这样的情况：要么问题不能及时发现，结果将是灾难性的，要么问题得到了及时发现，但那时没人知道该做什么。执行此操作以修复它。无论如何，最终有人会做出灾难性的事情。<br><br>唯一让我不像美里其他人那么悲观的是我认为我们还有更多的时间。我不认为他们离 AGI 很近，而且我认为在这段时间里很多事情都可以改变。再说一次，并不是说它们会改变——我们可能会一直燃烧，但最终仍然会陷入一场灾难。<br><br><strong>威尔·佩蒂略：</strong>现有问题只有表面解决方案的例子是什么？<br><br> <strong>Vanessa Kosoy：</strong>我的意思是，我们关心的真正问题并不是真正存在的问题，对吗？我们主要担心的是，未来的人工智能系统——将比现有的人工智能系统强大得多——将带来人类的灭绝或类似程度的灾难。<br><br>这不是一个现有的问题，原因很简单，我们今天拥有的人工智能系统无法学习如此复杂的世界模型，无法让您执行这些类型的操作。但即使是现在，这些公司仍在努力应对大型语言模型发生的所有问题，例如臭名昭​​著的越狱，他们试图以各种方式使其表现良好。例如，不告诉用户攻击性的、危险的信息，用户很容易找到越狱来解决这个问题，或者只是给出错误的答案。<br><br>但同样，对我来说，这不是真正的问题，这只是一个类比。我的意思是，他们现在正在努力解决这些非常简单、容易得多的问题，但这并不是说他们不会解决这些问题。尝试和错误最终会让你到达目的地。反复试验不能解决存在风险，因为一旦所有人都死了，试验就结束了。没有更多的审判了。所以我们现在遇到的问题，他们仍在努力解决，因为他们没有解决这些问题的基本工具，但最终他们会反复试验并以某种方式修补它们，或者至少很好地解决它们足够经济了。但一旦失败成为全球性灾难，反复试验就不再是解决问题的可接受方法。<br><br><strong>威尔·佩蒂略：</strong>显然我们看不到世界末日的大量测试数据。但我想会有一些较小的先兆问题，但暗示着即将发生的事情。您是否认为幻觉或无法控制人工智能所说的内容是此类前兆所面临的挑战？或者它们完全不相关并且不会出现任何先兆问题？<br><br> <strong>Vanessa Kosoy：</strong>这是一个很难回答的问题，因为现有人工智能系统仍然缺少一些非常重要的部分，从而产生存在风险。我们可以举出系统有点错误概括的例子，有很多著名的例子：一些程序通过永远暂停游戏来“赢得”俄罗斯方块，或者通过无限循环地赛船来赢得一些赛船游戏，各种奇怪的意外行为，因为算法最大化的指标实际上并不是用户想要的。你可以称这些为前兆，但我觉得它并没有完全反映问题的严重性，因为这些仍然是玩具设置。不存在在开放的物理世界中运行的开放世界系统。他们试图解决的目标比人类价值观简单得多；并不存在真正存在复杂道德考虑的运营领域。<br><br>也许大型语言模型开始解决这个问题，因为它们进入的领域会出现一些（至少在道德上）不完全微不足道的问题。另一方面，大型语言模型并没有真正做一些超人的事情。嗯，他们可能是超人，因为与人类相比，他们拥有非常广泛的知识，但在其他意义上却不是。所以这很难。有些事情有点相似，但相似程度不高。<br><br>但话又说回来，我们担心这种风险的动机并不是来自于法学硕士。在深度学习出现之前，Eliezer Yudkowsky 就开始谈论这些事情了。这不是动力的来源。<br><br><strong>威尔·佩蒂略：</strong>我想我问这个问题的原因是，在这个问题引起争论和两极分化的地方，常见的反对意见之一是：“这背后没有证据！这只是讲故事！”<i>是否</i>有证据表明存在危险，或者它真的只是来自数学计算？<br><br> <strong>Vanessa Kosoy：</strong>问题是，你所说的证据是什么？这是一个非常复杂的问题。明显的证据包括：人工智能完全失控、打破常规、侵入计算机、将自身复制到其他计算机、彻底操纵人类操作员等等。但这种事情就像金丝雀一样，你只希望在非常非常接近的时候看到它，但已经太晚了。不可能说我们只会依靠这类证据来解决争论。</p><p>对于其他类型的证据，有人说进化是机器学习算法如何产生与原始算法完全不一致的东西的证据。其他人向您展示强化学习算法并不符合设计者的意图。但对于每一个这样的论点，你都可以有一个反论点，它说：“是的，但这个例子并不真正相似。我们不能真正从那里预测存在风险，因为存在一些不相似之处。”<br><br>是的，总会有一些不相似的地方，因为除非你在现实世界中拥有非常接近存在风险的人工智能，否则你不会拥有任何与呈现存在风险的事物完全相似的东西。因此，我们别无选择，只能根据基本原理、数学或一些更复杂、更多维的分析来推理。我们别无选择。宇宙并不欠我们一个非常简单的、经验性的方法来测试这些担忧是否真实。我希望的一件事是，该理论将为人工智能的危险性提供更有力的论据，或者该理论会告诉我们不，一切都很好，我们都可以放松。缺乏理论是我们在一个方向或另一个方向上没有万无一失、完全可靠的论据的部分原因。<br><br><strong>威尔·佩蒂略：</strong>寻找证据的挑战在于，任何你能指出的现在存在的东西都可以用多种方式解释。拥有扎实的理论可以为一种解释提供一定的可信度，而不是另一种解释。<br><br><strong>凡妮莎·科索伊：</strong>是的，绝对如此。如果你有一个理论，认为某种特定类型的误概括在大多数可能的机器学习系统中都是普遍存在的，并且我们也看到这种类型的误概括发生在真实的机器学习系统中，那么就很难驳斥它并说：“哦，是的，我们遇到了这个问题，但我们会做这个做那个，这样就很容易解决它。”<br><br><strong>威尔·佩蒂略：</strong>有一件事仍然困扰着我，那就是目前无法获得证据的问题。我立即想到的类比是气候变化。你可以说“哦，世界上大片地区不适合居住的想法只是这个精心设计的故事，因为这一切以前从未发生过！”但是你可以看看已经存在的一堆事情：小规模灾难、二氧化碳与温度的关系图等等，指着这些说：“嘿，真正糟糕的事情还没有发生，但是已经发生了。”有很多证据表明它会的！”是什么让人工智能与众不同？<br><br><strong>凡妮莎·科索伊：</strong>我认为气候变化是一个很好的类比。最大的区别在于，在气候变化方面，我们有一个非常好的理论。就像气候变化一样，我们有物理学，对吧？我们有行星科学，它有非常非常坚实的基础。我们有计算机模拟。这仍然不是微不足道的，有一些混沌现象很难模拟或预测，所以并不是所有的事情都是完全微不足道的，但我们仍然有一些非常非常强大的理论基础来理解这些事物是如何工作的以及机制是什么。这个理论告诉我们，在这样那样数量的二氧化碳的影响下，我们到底会变暖多少度，仍然存在很大的不确定性区间，但我们仍然有一个相当可靠的预测。<br><br>而对于人工智能，我们没有这个。类似的情况，如果你想想象人工智能风格的气候变化，那么这就像是没有一个理论来解释为什么二氧化碳会导致变暖。温度和二氧化碳之间存在一些经验相关性，然后人们就可以无休止地争论。相关性不是因果关系，也许变暖是由完全不同的事情引起的，也许如果我们做一些不相关的事情就会阻止变暖，但这实际上不是真的。我们会在黑暗中。对于人工智能，我们目前仍处于黑暗之中。<br><br> <strong>Will Petillo：</strong>您目前在 MIRI 的工作进展如何？</p><p> <strong>Vanessa Kosoy：</strong>目前我正在考虑多个问题。希望我很快就会发表一篇关于不精确线性强盗的论文，该论文与我之前提到的下贝叶斯主义相关，这是一种推理复杂世界的代理理论。这是在一些非常简单的特殊情况下分析这个理论，在这种情况下，我成功地得到了算法学习特定事物需要多少数据的精确界限。之后，我开始研究强化学习中学习状态表示的理论，这是目前该理论中缺失的另一大块，它是关于你的算法应该如何了解世界的哪些特征实际上是重要的关注点在。<br><br>与此同时，我还有一位合作者 Gergely Szucs，他正在致力于利用我的基础贝叶斯物理主义理论来创建量子力学的新解释。他在那里得到了一些非常有趣的结果。这是一个测试用例，展示了这种关于代理的思考框架如何帮助您解决各种哲学困惑。在这种情况下，混乱与量子力学的解释有关。斯科特·加拉布兰特（Scott Garrabrant）有一个关于新型不精确概率的项目，这是一种表示具有良好组合特性的信念的新方法。卡内基梅隆大学的 Kaspar Osterheld 和 Abram Demski 最近发表了一篇论文，介绍了一些新型的频率论保证算法，这些算法基于类似于预测市场的东西做出决策。是的，很多有趣的事情正在发生。<br><br><strong>威尔·佩蒂略：</strong>是否还有其他我没有问过的问题，可以帮助看到此内容的人了解您在这里的情况？<br><br> <strong>Vanessa Kosoy：</strong>确切地说，这不是一个问题，但我还有一个更具体的方法来解决如何实际解决对齐问题，如何实际设计一个对齐的代理，我称之为物理主义超级模仿。这是价值学习主题的变体，但它借鉴了基础贝叶斯物理主义的框架，该框架来自学习理论议程和算法信息论中的一些想法，提出了一种半正式的方法来解决如何一种能够以稳健的方式学习人类价值观的人工智能。<br><br>它解决了其他价值学习方法所存在的许多问题，例如：如何确定代理的边界在哪里？什么是人？你如何在太空中找到这个人？在推断人类的价值观时，您如何考虑不仅是行为，而且还考虑人类的内部思维过程？如何防止人工智能以某种方式改变或操纵人类来改变他们的价值观等不正当激励措施？如何避免内部对齐问题？它解决了其他方法所存在的一系列问题。<br><br> <strong>Will Petillo：</strong>这听起来让人想起逆强化学习？<br><br> <strong>Vanessa Kosoy：</strong>逆强化学习的理念是我们应该观察人类的行为，推断这些人类想要做什么，然后我们就可以做这件事。 “我们”作为人工智能。所以我实际上有一些演讲，其中我将物理超级模仿解释为类固醇的逆强化学习。它采用了这个基本想法，但以解决更简单的方法所存在的许多深层问题的方式来实现它。简单化方法存在的一个问题是，它们将人类建模为完美的代理，在对环境有完美的了解的情况下遵循完美的政策，这是非常不现实的。<br><br>相反，我将人类建模为学习代理。他们边走边学。他们甚至可能做得并不完美。还有一个就是边界问题。人类到底是什么？你把人类的界限放在哪里？是否只有人类使用的某些特定输入和输出，并且您认为通过此端口的所有内容都是人类？但是，你如何处理进入这个端口的内容与人类实际想要做的事情之间的各种差异，或者像人工智能劫持这个通道这样的各种可能性？<br><br>在我的方法中，人类的形式化方式是人类是宇宙正在运行的特定计算。我实际上可以使用基础贝叶斯物理主义将其形式化。它具有特定的属性，这使得它具有代理性，因此代理会检测宇宙正在运行哪些计算，其中检测哪些计算是代理，并且在这些代理中，它通过研究因果关系来选择哪个代理是其用户，这样它位于代理的边界上。第一件事是因为我们正在谈论这个人正在运行的计算，这是人类的推理并被视为一种计算。我们也会自动将内部视为内部思维过程，而不仅仅是表达为外部行为的事物。所以我们在那里可能有更多的信息。<br><br><strong>威尔·佩蒂略：</strong>人们参与其中的最佳方式是什么？他们想提前了解什么？<br><br> <strong>Vanessa Kosoy：</strong>他们可以立即开始做的一件事是阅读人们迄今为止在代理基金会和学习理论议程中所做的事情。我最近有一篇文章《 <a href="https://www.lesswrong.com/posts/ZwshvqiqCvXPsZEct/the-learning-theoretic-agenda-status-2023"><u>学习理论议程：2023 年现状》</u></a> ，其中总结了很多内容。我还有一个<a href="https://www.alignmentforum.org/posts/fsGEyCYhqs7AWwdCe/learning-theoretic-agenda-reading-list"><u>阅读列表帖子</u></a>，为想要进入该领域的人推荐一些背景阅读材料。更具体地说，就职业步骤而言，现在申请已经太晚了，但我正在<a href="https://www.matsprogram.org/"><u>MATS</u></a>中运行一个轨道<i>，</i>这是一个针对想要进入人工智能安全领域的研究人员的培训计划。我有一个专注于学习理论议程的曲目。希望明年还会有另一条这样的赛道。我还梦想有一个实习计划，这将把人们带到以色列与我一起从事这方面的工作。目前，由于战争，这件事被推迟了，但希望事情最终会稳定下来，我会恢复这个项目。这些是目前参与的主要方式。<br><br><strong>威尔·佩蒂略：</strong>谢谢您的描述。我祝愿您能够最好地发展这一理论并获得更多的兴趣，以便证据和理论之间的不匹配开始得到纠正，研究人员知道他们在做什么，而不是在黑暗中跌跌撞撞！<br><br><strong>凡妮莎·科索伊：</strong>谢谢你邀请我。</p><br/><br/> <a href="https://www.lesswrong.com/posts/QPxrH5ex6MpYoLwer/interview-with-vanessa-kosoy-on-the-value-of-theoretical#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/QPxrH5ex6MpYoLwer/interview-with-vanessa-kosoy-on-the-value-of-theoretical<guid ispermalink="false"> QPxrH5ex6MpYoLwer</guid><dc:creator><![CDATA[WillPetillo]]></dc:creator><pubDate> Mon, 04 Dec 2023 22:58:42 GMT</pubDate></item></channel></rss>