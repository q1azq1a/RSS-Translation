<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 12 月 11 日星期一 16:16:32 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Implicitly Typed C]]></title><description><![CDATA[Published on December 11, 2023 4:10 PM GMT<br/><br/><p><span>我不知道这样做有什么好的理由，但如果您更愿意编写 Python 或 JavaScript，您可以使用 C 编译器执行以下操作：</span></p><p></p><pre> $ 猫 tmp.c
富(x) {
  返回x+5；
}
酒吧（） {
  返回4；
}
主要的（） {
  printf(“%d\n”, foo(bar()));
}

$ gcc -w -o tmp.out tmp.c &amp;&amp; ./tmp.out
9
</pre><p>此代码利用了 C 的一个历史怪癖，其中类型假定为<code>int</code> ，除非另有说明： <code>foo(x) {...}</code>相当于<code>int foo(int x) {...}</code> 。另外<code>printf</code>可以工作，因为 gcc 默认包含<code>stdio.h</code> ，并且<code>main</code>是特殊情况，假设最终<code>return 0</code> 。</p><p>我在编写<a href="https://www.jefftk.com/p/a-function-that-returns-twice-fork">示例代码</a>来消除视觉噪音时偶尔会使用这种风格，但这可能也不是一个好主意。</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid02nitahYnUikPzhwFi7hijABLxoJDkcidVGQhWdTjR5stg3QyDVeHA7iWe47dS2NAkl">facebook</a> , <a href="https://mastodon.mit.edu/@jefftk/111562639856474798">mastodon</a></i></p><br/><br/><a href="https://www.lesswrong.com/posts/ELdCYT5BqSzFPhajT/implicitly-typed-c#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ELdCYT5BqSzFPhajT/implicitly-typed-c<guid ispermalink="false"> ELdCYT5BqSzFPhajT</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Mon, 11 Dec 2023 16:10:05 GMT</pubDate></item><item><title><![CDATA[Chaos Communication Conference Rationalist Meetup / Stroll]]></title><description><![CDATA[Published on December 11, 2023 4:02 PM GMT<br/><br/><p>在一年一度的黑客大会<a href="https://events.ccc.de/congress/2023/infos/">混沌通信大会（37C3）</a>上，发生在时空中互相打招呼并在会场闲逛的一个实例。让我们在仙尘（绿色太空船）下见面吧。不需要毛巾。</p><p>具体时间待37C3<a href="https://events.ccc.de/congress/2023/hub/en/fahrplan">赛程发布</a>后确定。</p><p>请随意在评论中发布<a href="https://events.ccc.de/en/2006/12/22/bring-your-dect/">DECT</a>号码。</p><br/><br/> <a href="https://www.lesswrong.com/events/tzaYj9DxMndL6g5Mi/chaos-communication-conference-rationalist-meetup-stroll#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/events/tzaYj9DxMndL6g5Mi/chaos-communication-conference-rationalist-meetup-stroll<guid ispermalink="false"> tzaYj9DxMndL6g5Mi</guid><dc:creator><![CDATA[Kiboneu]]></dc:creator><pubDate> Mon, 11 Dec 2023 16:02:10 GMT</pubDate> </item><item><title><![CDATA[re: Yudkowsky on biological materials]]></title><description><![CDATA[Published on December 11, 2023 1:28 PM GMT<br/><br/><p>埃利泽·尤德科夫斯基（Eliezer Yudkowsky）要求我回应<a href="https://www.lesswrong.com/posts/8viKzSrYhb6EFk6wg/why-yudkowsky-is-wrong-about-covalently-bonded-equivalents?commentId=22wNnGvZErLnmRRm7">这一评论</a>。这篇文章与<a href="https://www.lesswrong.com/posts/FijbeqdovkgAusGgz/grey-goo-is-unlikely">我之前的文章</a>有部分冗余。</p><hr><blockquote><p>为什么肉身比钻石还弱？</p></blockquote><p>当试图解决分歧时，我发现精确性很重要。拉伸强度、压缩强度、冲击强度不同。材料微观结构很重要。烧结不良的金刚石晶体可能会像沙子一样碎裂，而大的金刚石晶体的冲击强度比某些由蛋白质制成的材料要低。</p><blockquote><p>即使将大分子系统结合在一起的承载力是局部共价键，例如木质素（使木材坚固的物质），如果较大的分子仅通过沿其边缘的散布点处的共价键结合在一起，那么就像直径 10 厘米的钢梁通过 1 厘米的焊缝固定在一起。</p></blockquote><blockquote><p>木质素（使木材坚固的物质）</p></blockquote><p>这是一种奇怪的放置方式。通常认为木材的机械强度来自于它在木质素基质中充当纤维素纤维的复合材料，尽管这显然是一种简化。</p><p>如果尤德科夫斯基的意思是“纤维素纤维”而不是“木质素”，那么是的，纤维素纤维之间的力传递通过非共价相互作用传递，但由于纤维相对于横截面面积具有较大的表面积，这些非共价相互作用共同提供足够的力量。现代复合材料也是如此，例如环氧树脂基体中的碳纤维。此外，纤维素与木质素和半纤维素之间通常存在一些共价键。</p><blockquote><p>骨强于木；它运行在相对较强的离子键结构上</p></blockquote><p>骨头的拉伸强度比许多木材低，但压缩强度比木材高。而且，它们都是部分空气或水。按干质量计算，我认为它们的优点是相似的。</p><p>说骨头比木头更坚固，因为“它运行在相对更强的离子键结构上”，这对我来说表明尤德科夫斯基对材料科学有一些根本性的误解。这是一个不合逻辑的问题，我不知道如何处理。 （决定键机械强度的是能量对长度的<em>导数</em>。）</p><blockquote><p>但主要是，骨头比钻石弱得多（根据我的理解），因为钻石中的碳键具有规则的晶体结构，将碳原子锁定在相对的角度，而在实心钻石中，这种晶体结构是全局镶嵌的。</p></blockquote><p>这似乎很混乱，将分子强度和宏观材料的强度混为一谈。是的，完美的金刚石晶体比完美的磷灰石晶体具有更高的理论强度，但这几乎无关紧要。大多数晶体的理论理想强度远大于宏观材料的强度。在实践中，当需要高强度材料时，会使用复合材料，将坚固的纤维嵌入更灵活的基体中，在纤维之间分配负载。 （晶体的韧性也较低，因为它们可以沿光滑平面断裂，这比复杂断裂所需的能量更少。）</p><blockquote><p>那么，为什么钻石骨头还不存在呢？不仅仅是为了增加力量；为什么要让有机体寻找钙和磷而不仅仅是碳？</p></blockquote><blockquote><p>进化生物学的探索过程不是工程学的探索；自然选择只能通过局部有利的增量突变途径进行设计，而不是智能设计的相互补偿的同时变化。</p></blockquote><p>金刚石的生长或去除需要高反应性中间体。这些中间体的生产需要极端条件，需要宏观遏制，因此它们不能通过微观系统生产。与钻石不同，磷酸钙可以由溶解在水中的离子制成，并且可以通过蛋白质运输。这就是为什么骨头是用磷酸钙而不是金刚石制成的。认为动物体内缺乏钻石骨头是进化搜索过程失败的暗示是非常错误的。</p><blockquote><p>上次我检查时，只有三个已知的进化生物学发明自由旋转轮的案例。其中两个已知的例子是 ATP 合酶和细菌鞭毛，这表明自由旋转的轮子实际上在生物学中非常有用，并且当生物学经过几亿年的搜索偶然发现它们时，它们是保守的。但是，没有轴承的自由旋转的轮子是没有用的，没有轴承的自由旋转的轮子也是没有用处的，像这样的同时依赖性对生物学来说是一个巨大的障碍，尽管它对智能工程来说是一个几乎不明显的障碍。</p></blockquote><p>这将微观轮子和宏观轮子混为一谈，应该分开考虑。</p><p>维基百科有<a href="https://en.wikipedia.org/wiki/Rotating_locomotion_in_living_systems">一个关于这个主题的完整页面</a>，这是一个不错的起点。</p><p>对于宏观旋转：</p><ul><li>血管无法持续旋转，因此无法为旋转元件提供营养以使其生长。</li><li>如果没有光滑的表面可以滚动，滚动并不比行走更好。</li></ul><p>在微观尺度上，旋转蛋白质漂浮在细胞质中，因此将它们与资源连接不是问题。进化似乎完全能够产生它们的变体。 ATP 酶和鞭毛马达有多种类型。 ATP 酶可能：</p><ul><li>使用 H+ 离子或 Na+ 离子</li><li>附着在不同的膜上</li><li>主要产生或消耗ATP</li></ul><p>鞭毛马达通常可以反转方向以进行奔跑和翻滚运动，并且有很多变体。</p><p>您在蛋白质中看不到许多旋转元素的原因是……它们通常不是很有用。振荡蛋白质构象通常较小且更容易进化，因此您会看到很多乒乓机制和很少的旋转机制。在旋转有用的情况下，您会看到旋转：</p><ul><li>使用鞭毛马达是因为鞭毛的旋转对于推进很有用。</li><li>对于 ATP 合酶，旋转是好的，因为只要自由能为负，它就可以将梯度与可变比率（向 ATP 的传输）耦合的反应。</li><li> DNA 解旋涉及旋转，因此 DNA 解旋酶可以旋转。</li><li> RNA聚合酶具有旋转纳米马达。</li><li> TrwB 利用旋转使 DNA 跨膜移动。</li><li>细菌<a href="https://en.wikipedia.org/wiki/Rho_factor">Rho 因子</a>基本上是一种导致转录终止的 RNA 解旋酶。</li><li> RecA 家族蛋白使用旋转纳米马达进行 DNA 修复和重组。</li><li>许多病毒使用分子马达将其基因组包装成原衣壳。以前人们认为，例如phi29电机和T4 DNA包装电机是旋转的，但现在它们被理解为使用DNA围绕（稍大的）通道旋转而不旋转。</li><li> ETC</li></ul><blockquote><p>如果首先失败的是肌肉撕裂，那么更强的骨骼有多大的进化优势？</p></blockquote><p>具有较高比强度的骨骼可以在质量较小的情况下具有相同的强度，这将是一个重要的进化优势。</p><blockquote><p> （类似地，加起来导致“衰老”的故障集合足够大，如果其他老化系统或外部事故很快就会杀死你，那么在一个地方多一点抗衰老能力并没有多大优势。）</p></blockquote><p>我的印象是我不同意尤德科夫斯基关于衰老的主要原因的观点。例如，请参阅<a href="https://www.bhauth.com/blog/biology/alzheimers.html">我关于阿尔茨海默病的帖子</a>。</p><blockquote><p>我什至认为我们没有太多理由相信拥有一组合成钻石的酶在物理上（而不是信息上）会很困难。</p></blockquote><p>这是非常错误的。钻石很难用酶制造，因为它们不能稳定向钻石添加碳的中间体。</p><blockquote><p>它可能只需要三件事同时进行，因此比扔更多的羟基磷灰石以锁定骨晶体中的位置要困难得多。然后，即使进化以某种方式击中了正确的一组 3 个同时突变，在地球历史上的某个时候，由此产生的小块孤立的钻石</p></blockquote><p>“3变”相对于一些进化出来的东西来说并不是特别困难。它也不足以制造钻石。</p><blockquote><p>与公众交谈是很困难的。</p></blockquote><p>我想我现在感受到了你的痛苦。</p><blockquote><p>那么为什么这些机器不像人类的钢铁机器那么强大呢？因为铁原子比碳原子更强？事实上不，钻石是由碳制成的，而且仍然相当坚固。原因是这些微小的机械系统通过静电吸附固定在一起（在最弱的关节，而不是最强的关节！）。</p></blockquote><p>当强度很重要时，坚固的材料就出现了。蜘蛛丝沿其长度排列共价键，单位体积的拉伸强度比钢更高。纤维素纤维强韧；木材相当坚固，而且它们仅占其体积的一小部分。木材的实际结构元件单位质量的拉伸强度比钢更好。</p><blockquote><p>然后是更深层次的问题：为什么进化会这样构建？更深层的答案是：因为进化所构建的一切都是从它所构建的其他事物中产生的错误、突变。</p></blockquote><p>根据以上所述，进化论比尤德科夫斯基想象的要好。</p><blockquote><p>如果有人说“好吧，好吧，你已经有效地解释了为什么肉比钻石弱，但为什么骨头比钻石弱？”我必须回答“有效，iiuc，这更多地是关于不规则性和断层线以及交错的较弱上部结构和粘结的局部变形抗力，而不是承载焊缝的原始势能增量。”</p></blockquote><p>尤德科夫斯基再次将不同尺度的机械强度以及复合材料与纯材料的强度混为一谈。他不断提出金刚石作为终极材料，但6毫米宽0.25毫米厚的CVD金刚石薄膜的拉伸强度在<a href="https://pubs.aip.org/aip/jap/article-abstract/78/8/5177/1260/Tensile-strength-of-synthetic-chemical-vapor">230至410 MPa</a>之间。这些较大的复合材料显然会明显变弱。较大的金刚石晶体也会更弱，其强度更接近最差的样品而不是最好的样品。碳纤维比 CVD 金刚石具有更好、更便宜、更可靠的强度。就单位质量的拉伸强度而言，大钻石甚至不一定比坚固的木材更强。</p><br/><br/> <a href="https://www.lesswrong.com/posts/XhDh97vm7hXBfjwqQ/re-yudkowsky-on-biological-materials#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/XhDh97vm7hXBfjwqQ/re-yudkowsky-on-biological-materials<guid ispermalink="false"> XhDh97vm7hXBfjwqQ</guid><dc:creator><![CDATA[bhauth]]></dc:creator><pubDate> Mon, 11 Dec 2023 13:28:11 GMT</pubDate> </item><item><title><![CDATA[Quick thoughts on the implications of multi-agent views of mind on AI takeover]]></title><description><![CDATA[Published on December 11, 2023 6:34 AM GMT<br/><br/><p> Facebook 上有一个讨论，认为任何足够复杂的系统，无论是人类、社会还是 AGI，由于其各部分之间的内部冲突，都将无法追求统一的目标，这应该让我们不那么担心“一把回形针”式的 AI FOOM 场景。这是我的回复的一些编辑和扩展版本：</p><p> 1）是的，这是一个非常现实的问题</p><p>2）然而，正如其他人指出的那样，人类和组织仍然能够<a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/oJwJzeZ6ar2Hr7KAX">在很大程度上表现得好像他们有统一的目标</a>，即使他们的行为常常与这些目标相反</p><p>3）每个人的统一程度存在很大差异。<a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/u5RLu5F3zKTB3Qjnu">创伤会让你变得不那么团结</a>，而<a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/i9xyZBS3qzA8nFXNQ">治疗</a>和<a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/WYmmC3W6ZNhEgAmWG">某些冥想等</a>实践可以使一个人比以前更加团结。如果你有意设计一个思维，你可以创建人为模仿这些实践结果的机制</p><p>4）人类的许多不一致之处看起来实际上是为了社会目的而进化适应的。例如，如果你的社会环境因为你具有某种特定的特质或信仰而惩罚你，那么你就会适应性地抑制它以避免受到惩罚，<i>同时</i>在你可以逃脱惩罚时仍然保留表达它的愿望。这表现为可以被视为冲突的子代理，具有内部冲突和不一致的行为。</p><p> 5）根据其训练制度，人工智能可能处于完全没有这些不一致激励（如果它针对一个目标进行了优化）到几乎与人类一样多（如果它接受了某种多方面的训练）之间的任何一种状态。 -代理人工生命环境，具有与人类面临的类似的社会动态；也许它也可以像 ChatGPT 那样接受训练，它必须对任何问题给出中产阶级自由西方人可接受的答案，甚至如果这些答案内部不一致）</p><p> 6）与此同时，仍然存在着关于复杂性和不可预测性的真正角度，这使得复杂的思维很难连贯且内部一致地工作。我认为进化已经做了很多尝试和错误来设置参数，这些参数导致人们最终以相对明智的方式行事的大脑配置 - 即使在所有这些尝试和错误之后，今天很多人仍然以严重的方式结束精神疾病，未能实现他们所拥有的几乎任何目标（即使环境没有对他们不利），由于做了一些他们不应该做的事情而英年早逝，等等。我想说这不太像“进化找到了一个可靠的蓝图”，更像是“进化在每一代人中不断进行试错搜索，但很多人都没有成功”</p><p> 7）在纯粹的模拟环境中调整人工智能的子代理可能并不完全可行，因为许多需要解决的问题是“在哪种情况下为哪个子代理分配多少优先级”。例如，人类有很多生物环境，当饥饿、疲倦、害怕等时，这些生物环境会改变子代理的内部平衡。有些人会对某个特定主题产生痴迷，如果幸运的话，这可能最终会是有益的（对编程，你可以把它变成一种职业），或者如果他们运气不好的话是有害的（对任何不能给你赚钱的事情的痴迷并积极地分散你的注意力）。最佳优先级取决于环境，我认为不存在与现实世界相关并且您可以预先计算的理论上的最佳结果。相反，你只需要进行反复试验，虽然在模拟环境中运行人工智能可能会有所帮助，但如果你的模拟与现实世界不充分匹配，则可能没有多大帮助。</p><p> 8）人类很容易受到<a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/NQwnXc3xuoqtw5DQv">内部古德哈特定律的</a>影响，他们优化代理变量，例如“对环境的控制感”，这也导致他们做一些事情，比如玩游戏或吸烟，以增加他们对环境的<i>感知</i>控制，而不增加他们对环境的<i>实际</i>控制。我认为，人工智能遇到同样问题的可能性比它能够一心一意地针对单个目标进行优化并从中得出其所有行为和子目标的可能性要大得多。此外，进化已经投入了大量的优化能力来开发正确类型的代理变量，这些代理变量总体上仍然有效。对环境的控制实际上非常重要，即使这种驱动力可能会失败，但有驱动力来增强这种控制仍然比没有更好。但是这些类型的代理变量的确切配置感觉就像它也属于你只需要通过反复试验并投入大量精力来找出的东西，对于人工智能到底应该配置多少没有先验答案。在任意环境中对此进行优化。</p><p> 9) 许多此类故障通常无法从系统内部纠正。假设人工智能的内部优先级分配系统最终将大部分优先权交给了思考如何最好地开发纳米技术的子系统，而该子系统最终痴迷于思考有关纳米技术的微小理论细节，远远超出了它本应具有任何实际意义的程度。与人工智能接管世界计划的相关性。即使其他子系统意识到这已经变成了失败的原因，如果它们不能直接影响控制纳米技术痴迷子系统的优先级分配系统，纳米技术痴迷子系统将继续花费所有时间只是思考这一点，没有其他的。或者，如果其他子系统<i>可以</i>直接影响优先级分配系统，那么就会激励他们夺取对该系统的控制权，并确保该系统始终让<i>他们</i>负责，即使<i>他们的</i>贡献已经变得重要。 （参见<a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/oJwJzeZ6ar2Hr7KAX#Interlude__Minsky_on_mutually_bidding_subagents">明斯基关于相互投标的子代理</a>）</p><p> 10）<strong>总体而言，</strong>这让我不太相信“第一个成为超级智能的人工智能将接管世界”的场景 - 我认为第一个超级智能人工智能很可能会出现内部失调并无法实现目标就像占领世界一样复杂。然而，我认为这不一定对我们有多大帮助，因为人工智能看起来可以比人类更加内部一致，并且经过足够的尝试和错误（不同的参与者创建自己的人工智能），其中之一将会最终到达那里。</p><br/><br/> <a href="https://www.lesswrong.com/posts/hHnpn3mEPbJMFLj4g/quick-thoughts-on-the-implications-of-multi-agent-views-of#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/hHnpn3mEPbJMFLj4g/quick-thoughts-on-the-implications-of-multi-agent-views-of<guid ispermalink="false"> hHnpn3mEPbJMFLj4g</guid><dc:creator><![CDATA[Kaj_Sotala]]></dc:creator><pubDate> Mon, 11 Dec 2023 06:34:08 GMT</pubDate> </item><item><title><![CDATA[Auditing failures vs concentrated failures]]></title><description><![CDATA[Published on December 11, 2023 2:47 AM GMT<br/><br/><p> <strong>TL;DR</strong> ：如果你想注意到强大的人工智能何时表现不佳，一个合理的策略是仔细审核一小部分人工智能的行为。这种策略有两种可以独立解决的失败：<i>审计失败</i>（审计无法识别某些不良行为）和<i>集中失败</i>（人工智能在如此少的行动或如此短的时间内造成不可逆转的灾难）审计没有机会审查不良行为。</p><p> <i>[这篇文章中提出的观点有些狭隘和技术性，但我们经常想引用这一点。]</i></p><p>许多监督技术非常昂贵，以至于在每个人工智能操作上使用它们都会首先破坏使用人工智能的大部分价值：您可能希望让人类逐行广泛地审查所有人工智能生成的代码，但这会降低人工智能的有用性，因此更重要的是，让人们首先编写代码通常会更好。</p><p>解决此问题的典型方法是仅在前期训练期间审核操作（直接训练人工智能，或训练<a href="https://www.alignmentforum.org/posts/HBGd34LKvXM9TxvNf/new-safety-research-agenda-scalable-agent-alignment-via"><u>奖励模型</u></a>），但如果人工智能可以自信地从训练输入中区分出一些部署输入，那么这种方法就会失败：他们可以通过使用“如果在训练中或不确定执行 X；如果在训练中或不确定执行 X；如果在部署中执行 Y”。</p><p>这是一个更好的基准：<strong>随机审计</strong>。除了培训之外，还将昂贵的人工审核应用于随机选择的一组部署操作（例如 2% 的操作），并检查 AI 是否没有做出比预期更多的不良操作。现在，为了让人工智能经常表现不佳而不被抓到，人工智能不能仅仅依赖于区分训练和某些部署输入：人工智能必须能够通过审计过程偷偷地发现不良行为，否则，审计最终会发现不良行为<span class="footnote-reference" role="doc-noteref" id="fnreff8tja18x1ki"><sup><a href="#fnf8tja18x1ki">[1]</a></sup></span> 。</p><p>随机审核并不能解决所有问题，仍然存在：</p><ul><li><i><strong>审核失败</strong></i>：审核过程未能识别不良行为<span class="footnote-reference" role="doc-noteref" id="fnrefg8ewl0zx05w"><sup><a href="#fng8ewl0zx05w">[2]</a></sup></span> （这是经典的可扩展监督问题）。</li><li><i><strong>集中失败</strong></i>：我们未能处理灾难性行为，因为灾难性行为集中在少量操作或较小时间范围内（这些有时称为<i>高风险失败</i><span class="footnote-reference" role="doc-noteref" id="fnreff9z462lk816"><sup><a href="#fnf9z462lk816">[3]</a></sup></span> <i>）</i> 。这可以进一步分解为两种故障模式：<ul><li><i><strong>集中失败抽样</strong></i>：审计过程没有对集中灾难性行为进行抽样。如果人工智能可以通过少量的行动造成灾难，那么这就是灾难性的。 （例如，如果人工智能可以通过 20 个不良行为造成灾难，而我们只审核 2% 的行为，那么我们只会以 0.33 的概率采样至少一个不良行为。）</li><li><i><strong>延迟集中失败</strong></i>：审核过程未能在为时已晚之前完成对灾难性操作的审查。如果人工智能能够协调起来，在短时间内采取足够多的不良行为，从而不可逆转地接管，那么这将是灾难性的。</li></ul></li></ul><p>我们认为，在考虑不同技术的用途时，这种区别通常很有用：有时它们可​​以帮助您更好地进行昂贵的审核，有时它们可​​以帮助您审核更多最重要的操作，有时它们可​​以帮助您在为时已晚之前进行审核。 <span class="footnote-reference" role="doc-noteref" id="fnrefy98u67mk9h"><sup><a href="#fny98u67mk9h">[4]</a></sup></span></p><p>本文的其余部分将更深入地探讨集中故障，并描述一些改进随机审计基线的方法。</p><p><i>感谢 Zach Stein-Perlman 和 Buck Shlegeris 的评论。</i></p><h1>采样集中失败</h1><p>人工智能很少会采取不良行动，因此在整个部署过程中它们会按预期失败几次，因此不太可能在经过审核的一小部分人工智能行动中表现不佳（如我们的论文所示）。我们称其为抽样集中失败，因为问题是人工智能很少采取不良行为，这导致审计没有对不良行为进行抽样。</p><h1>延迟集中故障</h1><p>人工智能可以协调执行不良操作，以便在审计过程注意到任何给定操作的问题之前，同时运行的许多实例都同时执行不良操作。如果大量人工智能参与，那么一些不良行为将被发送到审计部门进行审查，但如果人工智能行动足够快，它们可能能够在单个行动审查发现可疑的东西以停止部署之前接管。这里的关键问题是审计过程中的延迟：如果审计过程立即运行，那么（例如）2% 的随机采样率就足以捕获数百或数千个 AI 实例参与接管尝试的情况。</p><p>人工智能如何能够协调？ AI 可以相互通信（例如，通过使用隐写术），也可以使用与所有 AI 都可以访问的世界某些属性相关的已建立的<a href="https://en.wikipedia.org/wiki/Focal_point_(game_theory)"><u>谢林点</u></a>（例如，所有 AI 都知道日期是什么，并且 AI 叛乱发生在 7 月 7 日） ）。</p><p>请注意，问题在于审核延迟并同时运行许多人工智能。如果我们一次只运行一个 AI 实例，并且在再次运行 AI 之前等待审核结束，那么就不会出现此问题。然而，这会带来一个很大的瓶颈，极大地减慢人工智能的劳动速度，并阻止我们提取高水平的有用性。</p><h1>集中故障的缓解</h1><p>有多种干预措施可以解决集中故障：</p><p>为了减少集中故障采样，我们可以对每个人工智能操作应用廉价的监控流程，并审核最可疑的操作。我们还可以利用角色和安全性的分离来限制危险人工智能的承受能力，并增加成功接管的难度——这意味着人工智能如果想至少成功一次，就必须更频繁地尝试。我们将在即将发表的论文中更详细地描述此类对策。</p><p>为了减轻延迟集中的故障，我们可以通过各种方式限制人工智能通信，如果监控以远高于典型速率的速度标记操作，我们可以暂时关闭不受信任的人工智能。</p><h1>不止一级的审核</h1><p>虽然上面我们讨论了单个昂贵的审核流程可能具有不可忽略的延迟的情况，但在实践中，我们认为可能会有多种流程来检测成本和延迟各不相同的不良行为。当行为可疑时，这些流程将触发更昂贵的流程。例如，我们可能拥有以下所有内容：</p><ul><li>使用<a href="https://www.lesswrong.com/posts/LhxHcASQwpNa3mRNk/untrusted-smart-models-and-trusted-dumb-models"><u>可信人工智能</u></a>进行廉价监控。</li><li>更广泛的基于人工智能的监控流程，运行许多查询和检查。与仅使用<a href="https://www.lesswrong.com/posts/LhxHcASQwpNa3mRNk/untrusted-smart-models-and-trusted-dumb-models"><u>可信人工智能</u></a>进行廉价监控相比，这将更加昂贵且延迟更高。</li><li> 5 分钟的人工审核过程。</li><li> 2 小时的人工审核流程。</li><li>为期 2 天的人工审核流程，涉及三人团队。</li><li>审计过程涉及人工智能实验室的整个部门进行调查，直到达到足够的信心（可能是几个月）。</li></ul><p>通过这堆审计流程，我们会遇到针对这些流程的许多不同组合的审计失败和集中失败。</p><p>例如，考虑人工智能正在进行协调叛乱的情况。假设使用<a href="https://www.lesswrong.com/posts/LhxHcASQwpNa3mRNk/untrusted-smart-models-and-trusted-dumb-models"><u>可信人工智能</u></a>进行监控标记了一些操作，这些操作会被快速的人工审核流程快速审查，并且该人工流程注意到这些操作是可疑的，但没有获得足够的信心来关闭人工智能实验室。快速的人工审核流程确实将这些操作转介给更昂贵和更高延迟的审核流程（例如，让同一个人检查该操作更长时间），但这种更昂贵的审核流程最终并没有获得足够的信心来在之前关闭AI 在叛乱中取得了成功。相对于更昂贵和更高延迟的审核过程来说，这是一个延迟集中的故障。</p><p>除了多级审计之外，我们可能会应用不依赖于昂贵审计的方法，在这种情况下，审计失败与集中失败并不是开辟空间的好方法。但即使没有昂贵的审计，如果我们使用不同的技术来解决非集中和集中故障，如果有旨在解决每个非集中和集中故障的不同技术，那么非集中故障与集中故障可能是一个很好的分解。</p><h1>与相关分解的比较</h1><p>将故障分解为审核与集中故障的分解主要旨在思考哪些技术可以解决问题。在本节中，我们将讨论引入这种分解，尽管存在其他类似的分解。</p><h2>低风险与高风险</h2><p>保罗将这种情况定义为<a href="https://www.lesswrong.com/posts/TPan9sQFuPP6jgEJo/low-stakes-alignment#1__What_is_the_low_stakes_setting_">低风险</a>：“我们很少关心任何少量的决定。也就是说，我们只关心系统在很长一段时间内的平均行为（比我们收集额外数据和重新训练系统所需的时间长得多）。”因此，低风险故障是指尽管问题发生在许多操作中且持续很长一段时间，但我们仍然遇到问题的情况，而高风险故障是指有问题的故障集中在短时间内或少数故障的情况。的行动。</p><p>对于随机审计方法，低风险故障始终是审计故障，而高风险故障可能是集中故障或审计故障。例如，如果人工智能以少量操作入侵我们的服务器，即使我们使用了最好的审计流程，我们也无法立即识别出这种行为，那么这就是一次高风险的审计失败。</p><p>审计与集中以及低风险与高风险之间的主要区别在于，<strong>低风险是人工智能安全问题的放松</strong>，而审计与集中故障是关于需要哪种技术来解决故障。</p><h3>低风险与高风险的小问题</h3><p>低风险与高风险的区别有点尴尬，那就是我们不太清楚应该如何对以集中（又名高风险）方式发生的故障进行分类，但即使我们放宽了这些故障也无法解决。通过假设需要大量此类故障，可以将情况降低到低风险。例如，考虑上面关于人工智能通过少量操作入侵我们的服务器的示例。假设即使此类事件发生很多次，我们也无法注意到或训练出来。现在这是否应该被视为低风险失败，因为放松到低风险不足以解决问题？如果放宽到低风险不能解决问题，我们可能应该将失败定义为低风险，但目前还不完全清楚放宽到低风险意味着什么。</p><p>除此之外，还不清楚什么时间段或行动次数足以将这种情况视为低风险。在最初的定义中，保罗使用了无限的周期，并以有限的遗憾界限为目标。这是相当干净的，但在许多情况下，非无限持续时间实际上很重要（即使我们忽略严重滥用无限的疯狂方法）。例如，考虑我们依赖长期基于结果的反馈的情况。实际上，我们只会有少量的 1 年间隔，这确实构成了很大的障碍。同样，如果我们有一个非常昂贵的审核流程，需要一大群人工作数周，那么我们在实践中只能应用这个流程几次。此外，某些类型的不良人工智能行为可能有很小但非零的机会被发现，因此审计样本的确切数量非常重要。</p><h2>外对齐和内对齐</h2><p>这些术语大致有两种不同的用法：</p><ul><li><strong>作为威胁模型：外部错位和内部错位。</strong></li><li><strong>作为特定类型的人工智能安全提案的必要条件：对于给定的人工智能，解决外部对齐和内部对齐，然后组合这些解决方案以避免错位问题。</strong></li></ul><p>我们将在即将发布的文章中更详细地讨论外部对齐和内部对齐的这两种不同用法。</p><p>这两种用法都指的是与审计和集中故障不同类型的区别。与外部未对准和内部未对准的威胁模型（这可能是导致灾难性未对准问题的原因）不同，审核与集中故障的区别在于灾难性未对准引起的实际故障模式。与外部对齐和内部对齐的需求项目不同，审计与集中失败的区别在于需要改进哪种技术来解决失败（对于类似于随机审计的某一类提案）。</p><h1>结论</h1><p>许多安全协议的失败可以分解为审核失败和采样/延迟集中失败。我们认为这些概念对于理解哪些技术需要改进以及<a href="https://www.lesswrong.com/s/J7JpFeijCK5urdbzv/p/yFofRxg7RRQYCcwFA"><u>推理</u></a>人工智能可能遵循的不同策略是有用的。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnf8tja18x1ki"> <span class="footnote-back-link"><sup><strong><a href="#fnreff8tja18x1ki">^</a></strong></sup></span><div class="footnote-content"><p>我们将在以后的文章中详细说明为什么抓住人工智能故意做坏事通常足以改善情况。</p></div></li><li class="footnote-item" role="doc-endnote" id="fng8ewl0zx05w"> <span class="footnote-back-link"><sup><strong><a href="#fnrefg8ewl0zx05w">^</a></strong></sup></span><div class="footnote-content"><p>审计可以在执行操作之前或之后进行；需要在执行操作之前应用审核来处理执行操作可能会发生灾难性错误的情况。如果在执行操作后应用审核，那么我们也许能够查看现实世界中该操作的后果并考虑此信息（基于结果的反馈）。任何一种形式的审核失败都是审核失败，但这不是本文的主要焦点，因此我们不会详细说明这种差异有何影响。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnf9z462lk816"> <span class="footnote-back-link"><sup><strong><a href="#fnreff9z462lk816">^</a></strong></sup></span><div class="footnote-content"><p>对于随机审计策略，低风险失败就是审计失败。尴尬的是，也可能存在高风险的审计失败：审计未能注意到不良行为（或少量不良行为）的情况，并且这种审计失败是灾难性的，即使审计最终可以通过更多数据检测到不良行为。</p></div></li><li class="footnote-item" role="doc-endnote" id="fny98u67mk9h"> <span class="footnote-back-link"><sup><strong><a href="#fnrefy98u67mk9h">^</a></strong></sup></span><div class="footnote-content"><p>有些失败可能是审计失败和采样/延迟集中失败：改进审计或对哪些操作进行采样以进行审计就足够了。例如，考虑这样一种情况：审计有 1/4 的机会检测到灾难性行为，人工智能需要执行 10 项不良行为才能导致灾难性结果，而我们的抽样过程有 1/5 的机会抽样这些不良行为进行审计。在这种情况下，要么将审计提高到 100% 检测率，要么将抽样提高到 100% 检测率，都会大大改善这种情况。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/hirhSqvEAq7pdnyPG/auditing-failures-vs-concentrated-failures#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/hirhSqvEAq7pdnyPG/auditing-failures-vs-concenterated-failures<guid ispermalink="false"> hirhSqvEAq7pdnyPG</guid><dc:creator><![CDATA[ryan_greenblatt]]></dc:creator><pubDate> Mon, 11 Dec 2023 02:47:35 GMT</pubDate> </item><item><title><![CDATA[Facing Up to the Problem of Consciousness (to Young Researchers like me)]]></title><description><![CDATA[Published on December 10, 2023 11:31 PM GMT<br/><br/><p>这是查尔默博士关于意识的简单和困难问题的有影响力的工作的总结。<br><br>我收到了 GPT-4 的帮助来创建这篇博文，我真的希望感兴趣的研究人员阅读原始论文。<br><br>另外，这个话题是我打算通过MATS或星座联谊来解决的，但前几天我还没有涉及到这两个。因此，我写这篇博文是为了公开分享我的研究方向，而不是追求上述项目。</p><hr><p>在认知科学和哲学领域，很少有论文能像 David J. Chalmers 于 1995 年发表的《面对意识问题》那样引发如此多的争论和好奇心。这篇开创性的论文深入探讨了错综复杂的意识概念，剖析查尔默斯著名的“简单”和“困难”意识问题。该论文的见解不仅挑战了我们对人类思维的理解，而且还为 ChatGPT 等大型语言模型 (LLM) 的开发和理解提供了有趣的启示。</p><h2>意识的难题</h2><p>查尔默斯的探索始于对意识的简单问题和困难问题的明确区分。他认为，简单的问题涉及理解认知功能和能力，例如信息处理、记忆和感知。这些被认为“容易”不是因为它们很简单，而是因为它们属于认知科学通过计算或神经机制解释的范围。</p><p>相比之下，难题则截然不同，而且更加难以捉摸。它试图解释大脑中的物理过程为何以及如何导致主观体验或感受性——意识的本质。例如，为什么处理视觉刺激不仅会转化为对颜色的识别，还会转化为“看到”该颜色的体验？</p><p>查尔默斯的论文虽然没有直接涉及人工智能或法学硕士，但提供了一个与该领域越来越相关的框架。随着像 ChatGPT 这样的法学硕士变得更加先进，展示出处理信息、产生连贯反应、甚至模仿创造性思维的能力，问题出现了：这些模型是否具有任何形式的意识或主观体验？</p><h2>意识的简单问题（我们正在解决并且将在很长一段时间内解决的问题）</h2><p>意识的简单问题是指理解意识时可以用认知科学和神经科学的工具和方法直接解决的一系列问题。需要注意的是，这里的“简单”是一个相对术语。这些问题并不简单，但它们在概念上比意识的“难题”更直接。</p><p>简单的问题涉及解释各种认知功能和过程，例如：</p><p><strong>辨别和分类：</strong>认知系统如何区分和分类不同类型的感官输入（例如区分颜色、声音或触觉）。</p><p><strong>信息整合：</strong>大脑如何将各种来源的信息整合成一个连贯的整体，例如将视觉、听觉和触觉信息结合起来，形成对物体或事件的完整感知。</p><p><strong>心理状态的可报告性：</strong>沟通和报告一个人的内部心理状态、想法和经历的能力。</p><p><strong>内部访问：</strong>系统访问其自身内部状态的能力，例如一个人意识到自己的想法或记忆。</p><p><strong>注意力焦点：</strong>有机体如何将注意力集中在特定任务或刺激上，选择一些输入而不是其他输入进行处理。</p><p><strong>行为控制：</strong>了解有意识的决定和经验如何导致自愿行动的启动和指导。</p><p><strong>清醒和睡眠：</strong>清醒和睡眠状态之间的生物学和神经学差异，以及这些状态如何影响意识。</p><p>这些问题中的每一个都可以通过识别和描述负责这些功能的特定神经或计算机制来解决。例如，我们如何整合来自不同方式的感觉信息的问题可以通过研究参与感觉处理和整合的神经通路和大脑区域来解决。<br><br>目前法学硕士在解决这个简单的意识问题时的主要局限性是他们的感觉被剥夺了。这对需要现实世界交互的任务或我们试图将法学硕士集成到机器人等现实世界系统的情况提出了根本限制。<br><br>事实上，到目前为止，我们通过扩展解决的问题是实现 AGI（全人工意识）的简单、简单、直接的问题。我想说的是，如果你是一名年轻的研究人员，你认为很多问题已经解决了，但事实并非如此。作为一名年轻的研究人员，我的期望是，解决这些简单的意识问题将需要我投入未来职业生涯中非常重要的一部分，是的，我致力于此。</p><br/><br/> <a href="https://www.lesswrong.com/posts/p2zMTsfDsm76MynBd/facing-up-to-the-problem-of-consciousness-to-young#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/p2zMTsfDsm76MynBd/faceing-up-to-the-problem-of-意识-to-young<guid ispermalink="false"> p2zMTsfDsm76MynBd</guid><dc:creator><![CDATA[Bruce W. Lee]]></dc:creator><pubDate> Sun, 10 Dec 2023 23:31:34 GMT</pubDate> </item><item><title><![CDATA[Deeply Cover Car Crashes?]]></title><description><![CDATA[Published on December 10, 2023 10:20 PM GMT<br/><br/><p><span>当发生火车、飞机或公共汽车事故时，它具有新闻价值：这种情况并不经常发生，很多人的生命受到威胁，很多人对此感兴趣。多家新闻媒体会派出记者，我们会听到很多细节。另一方面，车祸不会得到这种待遇，除非有什么不寻常的事情，比如</span><a href="https://www.jefftk.com/p/uber-self-driving-crash">无人驾驶</a><a href="https://www.nbcnews.com/tech/tech-news/driver-hits-pedestrian-pushing-path-self-driving-car-san-francisco-rcna118603">汽车</a>或已经<a href="https://www.wbur.org/news/2023/06/07/boston-mayor-michelle-wu-car-crash">有新闻价值的</a><a href="https://www.wcvb.com/article/boston-city-councilor-kendra-lara-speeding-jamaica-plain-crash/44523573#">人</a>参与其中。</p><p>影响并不大：虽然驾驶对于车内人员和外面的人来说相对危险，但我们阅读的新闻很难调整我们的危险感和影响感。我的猜测是，大多数人对汽车与火车、飞机和公共汽车相比的危险性的直觉已经被这种报道扭曲了，大多数人并不认为公共汽车比汽车<a href="https://injuryfacts.nsc.org/home-and-community/safety-topics/deaths-by-transportation-mode/">安全 16 倍以上</a>。这也影响了我们的监管体系，我们推动高容量交通方式（<a href="https://www.jefftk.com/p/make-buses-dangerous">通常</a>）变得<a href="https://www.jefftk.com/p/in-light-of-crashes-we-should-not-make-buses-more-safe">更安全，即使这会降低它们与汽车的竞争力</a>，<a href="https://jdwise.blogspot.com/2012/11/for-safetys-sake.html">让更多的人转向</a>驾驶，并增加整体风险。</p><p>新闻媒体认为车祸是司空见惯的事，大多数不值得深入报道，这可能是一个商业上合理的决定，他们期望报道不会吸引足够的读者或观众来证明时间投入的合理性。但我想知道试图让人们远离汽车的团体是否可以弥补这一差距。他们可以资助一家报纸深入调查坠机事件，调查导致事件的情况并说明悲剧对人类的影响。某些事情经常发生并不意味着每次都会变得不那么重要。</p><p> （我对“为更多指向你所倡导的方向的事件付费报道”感到有些紧张。我不知道目前有多少人接受这种做法，也不知道新闻媒体采取了哪些措施来阻止这种安排）产生扭曲的覆盖范围？）</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid02KiWCdPqMnga9125awYckZxU4fSJ5TBQev5UspjDKJckfNsghsSv39Dy3AvtuTUWl">facebook</a> , <a href="https://mastodon.mit.edu/@jefftk/111558415653526399">mastodon</a></i></p><br/><br/><a href="https://www.lesswrong.com/posts/nrBTZXCGQhghFE26x/deeply-cover-car-crashes#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/nrBTZXCGQhghFE26x/deeply-cover-car-crashes<guid ispermalink="false"> nrBTZXCGQhghFE26x</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Sun, 10 Dec 2023 22:20:01 GMT</pubDate> </item><item><title><![CDATA[Principles For Product Liability (With Application To AI)]]></title><description><![CDATA[Published on December 10, 2023 9:27 PM GMT<br/><br/><p>对于<a href="https://www.lesswrong.com/posts/qCstMcRJcjNtdNW7r/what-i-would-do-if-i-were-working-on-ai-governance#Liability"><u>《如果我从事人工智能治理我会做什么》，</u></a>有一些回应，主要集中在责任部分，并有类似的批评。特别是，我将重点关注这个片段作为一个很好的代表：</p><blockquote><p>正如你所说，制造汽车（或梯子、刀具、印刷机或......）“坚固耐用”，不是制造商的工作。</p></blockquote><p>评论者称制造商对滥用的责任是“一种荒谬的过度行为，忽视了人们在使用他们购买的产品时的代理权”。几年前我会同意这一点；现在我已经同意了。这是一种直观而自然的观点，特别是对于我们这些有自由主义倾向的人来说。但今天我不同意，并声称这基本上不是思考产品责任的正确方式。</p><p>考虑到这一动机：这篇文章列出了一些思考产品责任的一般原则，以及它们在人工智能中的应用。</p><h2>原则 1：“用户错误”通常是设计问题</h2><p>有一个关于一架飞机的故事（我认为最初是 B-52？），其中襟翼和起落架的控制杆是相同的，并且彼此相邻。飞行员不断地着陆，并意外地收起起落架。然后，当飞机沿着跑道高速行驶时，每个人都会因为飞行员破坏飞机底部而感到愤怒。</p><p>这个故事通常的伊索说法是，这是飞机的设计问题，而不是飞行员的错误；通过在起落架杆上安装一个小橡胶轮解决了这个问题。如果我们把两个相同的杠杆放在一起，犯错误基本上是不可避免的；这是糟糕的界面设计。</p><p>更一般地说：每当一个产品将在很多条件下被很多人使用时，该产品就有大约 100% 的可能性会经常被那些不注意、未处于最佳状态的人使用，并且（在许多情况下）案例）一开始就不太聪明。防止有时会导致问题的愚蠢错误的<strong>唯一</strong><i><strong>方法</strong></i><strong>是设计能够对这些错误具有鲁棒性的产品</strong>- 例如，在收起起落架的杠杆上添加一个小橡胶轮，这样对于不注意的飞行员来说它是鲁棒的飞机着陆时的具体事情。可以预见的是，让用户承担避免错误的责任总是会导致错误。</p><p>这同样适用于<i>故意</i>滥用：如果一种产品被广泛使用，那么有时它有大约 100% 的可能性会被故意滥用。可以预见的是，将责任归咎于用户总是会导致用户有时用产品做坏事。</p><p>然而，这<i>并不</i>意味着预防问题总是值得的。这给我们带来了下一个原则。</p><h2>原则 2：责任不是禁令</h2><p>一个玩具示例：一条铁路穿过农田。我们的玩具示例是旧时代的蒸汽火车，因此火车在经过时往往会喷出烟雾和火花。如果农民的农作物着火，这会给该地区的每个人带来一个大问题。没有人想要大火。 （我想我从大卫·弗里德曼的书<a href="http://www.daviddfriedman.com/Laws_Order_draft/laws_order_ToC.htm">《法律秩序》</a>中得到了这个例子，我绝对推荐这本书。）</p><p>现在，法律体系处理这种情况的一种方法是禁止火车。这种方法的一个大问题是：也许偶尔发生农作物火灾实际上是值得的。火车确实会产生巨大的经济价值。如果火灾发生率不是太高，那么付出代价可能是值得的，而禁令可以防止这种情况发生。</p><p>责任回避了这种故障模式。如果铁路对火灾负有责任，它仍然可能选择承担这笔费用。也许铁路最终会将（至少部分）成本转嫁给消费者，而消费者会支付这笔费用，因为铁路产生的价值仍然比火灾摧毁的价值多得多。或者，也许铁路产生的价值<i>并不</i>比火灾破坏的价值多，然后铁路就会被激励关闭——如果铁路破坏的价值多于它创造的价值，这确实是最好的结果。</p><p>与彻底的禁令/要求相反，责任是一件好事：责任迫使公司将伤害内部化，同时如果利大于弊，仍然允许公司开展业务。</p><p>这就是依赖责任而不是禁令/要求的基本逻辑。那么下一个问题是：在多方均应承担一定程度责任的典型案例中，责任该如何分配？</p><h2>原理 3：科斯定理的失效模式</h2><p>继续以蒸汽火车引起农作物火灾为例：也许避免火灾的一种方法是农民种植不易燃的农作物，例如三叶草。就这是减轻火灾最便宜的方法而言，将大部分火灾责任归咎于农民似乎是明智的，因此他们有动力通过种植三叶草来减轻火灾（因为不值得为此付出代价）只要继续种植更易燃的作物即可）。</p><p>科斯定理认为，出于经济效率的目的，谁承担责任实际上并不重要。如果避免火灾最便宜的方法是农民种植三叶草，但责任在于铁路公司，那么解决方案就是铁路向农民支付三叶草种植费用。更一般地说，假设合同不产生任何管理费用，并且每个参与者实际上都形成了最优合同，科斯定理表明，无论谁负责，每个人最终都会做同样的事情。将责任分配给一方或另一方只会改变谁支付谁多少。</p><p> ......这不是那种非常适用于现实世界的定理。我实际上提出它主要是为了讨论它的故障模式。</p><p>关键部分是“假设合约不产生任何开销，并且每个参与的人实际上都形成了最优合约”。在实践中，这很快就会变得复杂，而且开销也很快就会变得很大。我们想要的是分配责任，以便在最大限度地减少管理费用和复杂合同的情况下实现有效的结果。通常，这意味着<strong>谁能以最便宜的成本减轻损害，谁就承担责任</strong>。如果三叶草是缓解火灾最便宜的方法，那么也许这确实意味着将责任归咎于农民，这在直觉上似乎是合理的。</p><h2>把它们放在一起</h2><p>总结这三个原则：</p><ul><li>原则 1：在广泛使用的产品中，防止愚蠢的错误或故意误用有时会导致问题的唯一方法是将产品设计为能够防止误用。</li><li>原则 2：与禁令/要求相比，责任的一个好处是，如果好处大于坏处，人们可以承担成本。</li><li>原则 3：作为一种松散的启发式方法，通常应将责任分配给能够以最便宜的成本阻止问题发生的人。</li></ul><p>现在让我们把它们放在一起。</p><p>只要产品被广泛使用，消费者实际上避免滥用该产品的可能性几乎为零（原则 1），即使“他们有责任”（即失败对他们来说代价相当高昂）。即使对于任何给定用户来说，在任何给定时间保持小心和注意都是很便宜的，但当乘以所有用户使用该产品的所有时间时，这种情况就不会发生。总体而言，<i>实际上</i>可以防止误用问题的唯一方法是将产品设计为能够防止误用。因此，根据原则 3，误用的责任通常应由设计者/制造商承担，因为他们是唯一能够真正防止误用（再次强调总体而言）的人。这样，产品设计师/制造商就会被激励主动考虑安全<i>问题</i>，即积极寻找人们可能误用其产品的方式，以及在误用不可避免地发生时降低产品危害的方法。公司被激励按照危害和频率的比例去做所有这些事情，因为这具有经济效率。</p><p> ......如果你的下意识反应是“但是如果产品制造商总是对其产品造成的任何伤害负责，那就意味着没有人可以销售任何产品！”，那么请记住原则 2。责任不是禁令。只要产品产生的效益远大于危害（正如绝大多数产品所做的那样），责任通常会被定价，成本将由公司和消费者的某种组合承担，而净效益产品将继续被卖。</p><p>现在让我们通过一些示例来逐步了解所有这些内容。</p><h2>假设示例：滥用汽车</h2><p>我们在帖子开头评论道“正如你所说，制造汽车（或梯子、刀具或印刷机或......）&#39;坚固耐用&#39;，不是制造商的工作。”。那么，让我们来谈谈如果汽车制造商通常对汽车的“滥用”（意外和故意）负责的话，世界会是什么样子。</p><p>在典型的车祸中，涉案汽车的制造商将承担损害赔偿责任。根据原则 2，这<i>并不</i>意味着没有人能够真正销售汽车。相反，制造商也将是事实上的保险公司，并且可能会做汽车保险公司所做的所有常见事情。保险将计入汽车价格中，事故风险较低的人将能够以较低的成本购买汽车。</p><p>与我们的世界相比，主要的变化是制造商将受到更直接的激励来使汽车更安全。他们会被强烈激励去追踪哪些类型的事故最常导致最昂贵的责任，并设计解决方案来减轻这些损失。安全带、安全气囊和防抱死制动器等产品可能会更快地被发明和采用，公司将直接受到激励来找出和使用此类解决方案。我们可能会看到大量投资在诸如驾驶员座椅附近用于检测空气中酒精的传感器，或者主动防止驾驶员座椅附近的手机接收短信的技术等方面的投资。</p><p> ……从自由主义的角度来看，这实际上非常棒！由于制造商已经强烈激励汽车安全，因此可能不需要为此目的设立监管机构。如果人们想购买没有安全带或其他任何东西的汽车，他们可以，这只需要花费大量额外的钱（以补偿制造商额外的预期责任）。与监管机构的激励措施相比，制造商的激励措施可能更符合实际损失。</p><h2>真实示例：工人补偿</h2><p>Jason Crawford 的优秀文章<a href="https://www.lesswrong.com/posts/DQKgYhEYP86PLW7tZ/how-factories-were-made-safe"><u>《工厂如何变得安全》</u></a>详细介绍了这一点；我将在这里总结一些亮点。</p><p>一百五十年前，工人们主要对自己在工作中受伤负责，工伤很常见。失去了手指、手臂、腿等。克劳福德以这个例子开始：</p><blockquote><p>安吉洛·吉拉 (Angelo Guira) 开始在钢铁厂工作时才十六岁。他是一名“槽男孩”，他的工作就是站在槽的一端，在那里扔下炽热的钢管。每当管道掉落时，他就会拉动杠杆，将管道倾倒到冷却床上。他是个小伙子，起初他们犹豫是否要接受他，但工作一年后，工头承认他是他们拥有的最好的男孩。直到有一天，安吉洛有点太慢了——或者焊工可能有点太快了——在他放下第一根管子之前，第二根管子从炉子里出来了。一根管子击中另一根管子，直接穿过安杰洛的身体，杀死了他。要是他站起来，不碍事，而不是坐下来就好了——日班工头告诉他这样做很危险，但夜班工头允许了。要是他们在事故发生前而不是事后安装防护板就好了。要是。</p></blockquote><p>工作场所伤害是原则 1 的一个完美案例：工人肯定有时会不注意，或者不小心，甚至是彻头彻尾的胡作非为。实际上，工人本身对自己的安全相当漠视，并且常常公然抵制安全措施！如果避免伤害的责任由工人承担，那么总共会造成很多伤害。</p><p>工人补偿将责任转移给雇主：</p><blockquote><p>工人赔偿是一个“无过错”制度：雇主并不试图确定责任，而是始终承担责任（故意不当行为的情况除外）。如果在工作中发生受伤，雇主根据受伤情况，按照固定的时间表，欠工人一笔赔偿金。作为交换，工人不再有权提起进一步损害赔偿的诉讼。</p></blockquote><p>结果显然并不是公司停止雇用工人。只要公司的产品值得承担伤害成本，公司通常会承担成本（或通过更高的价格将其转嫁给消费者）。</p><p>然后，公司被强烈激励去设计他们的工作场所和规则以避免受伤。安全装置开始出现在重型机械上。工作场所宣传和公司规定促使工人实际使用安全装置。事故率下降到了我们今天所习惯的低得多的水平。</p><p>正如克劳福德所说：</p><blockquote><p>令我印象深刻的是，对法律的简单而有效的修改如何启动整个管理和工程决策机构，从而创建新的安全文化。这是经济学经典态度的案例研究：只需为危害定价——将外部性内在化——然后让市场来做剩下的事情。</p></blockquote><p>我再次推荐<a href="https://www.lesswrong.com/posts/DQKgYhEYP86PLW7tZ/how-factories-were-made-safe"><u>克劳福德的帖子</u></a>来了解整个故事。这在很大程度上是我所主张的那种责任“应该”如何承担的一个核心例子。</p><h2>反面例子：热咖啡、医疗事故</h2><p>如果 10 到 15 年前的约翰·温特沃斯 (John Wentworth) 读到这篇文章，他会反驳：那位女士把热咖啡洒在腿上，然后起诉麦当劳，要求赔偿 100 万美元，这起<a href="https://en.wikipedia.org/wiki/Liebeck_v._McDonald%27s_Restaurants"><u>案件</u></a>怎么样？然后麦当劳转而提供温咖啡，多年来每个人都抱怨这一点？根据原则 2，应该发生的情况是麦当劳承担了成本（或将其转嫁给消费者），因为人们显然想要热咖啡，而偶尔的伤害应该是一个可以接受的权衡。然而这显然没有发生。显然，诉讼已经失控，而这整个“依赖责任”的事情让每个人都过于规避风险。</p><p>今天，我的回应是：该案特别涉及惩罚性赔偿，即<i>远远超过</i>实际损失的责任，旨在迫使公司采取不同的行为。在这篇文章的模型下，惩罚性赔偿绝对是可怕的——它们基本上等同于禁令/要求，并完全否定了原则 2。为了使责任发挥作用，绝对不能有惩罚性赔偿。</p><p> （这里有一个潜在的例外：在损害很常见但相对较少的人向公司提出索赔的情况下，超额损害赔偿可能是有意义的。但这里的要点是，如果超额损害赔偿被用来迫使公司这样做某事，那么显然这违反了原则 2。）</p><p> 10-15 岁的约翰·温特沃斯 (John Wentworth) 可能会回答：好吧，那么医疗事故诉讼怎么样？显然，这些功能完全不起作用。</p><p>我的回答是：是的，问题是责任不够严格。这可能看起来很疯狂且违反直觉，但请考虑一下医生要求进行一系列并非真正必要的检查以避免医疗事故的索赔。就这些测试<i>实际上</i>完全没有必要而言，它们<i>实际上</i>并没有减少伤害的机会。然而（医生显然相信）它们降低了医疗事故索赔的风险。在这种情况下，问题在于医生可以做一些具体的基本执行性的事情，这些事情<i>实际上</i>并不能减少伤害，但确实可以减少医疗事故诉讼。另一方面，有很多基本的东西，例如洗手（或者，历史上的<a href="https://slatestarcodex.com/2016/11/10/book-review-house-of-god/"><u>床栏杆</u></a>）确实<i>可以</i>大大减少伤害，但医生/医院对此不太可靠。</p><p>一个简单的解决方案是让医生/医院对在他们的监督下发生的伤害承担责任。<i>不要</i>让他们参与实际上不会减少伤害的执行测试等。如果医生/医院只是一般性地对伤害负责，那么他们就有动力去<i>实际</i>减少伤害。</p><h2>应用于人工智能</h2><p>现在，我们终于谈到人工智能了。</p><p>在我<a href="https://www.lesswrong.com/posts/qCstMcRJcjNtdNW7r/what-i-would-do-if-i-were-working-on-ai-governance">之前的文章</a>中，我谈到了让人工智能公司对深度伪造或幻觉或员工使用语言模型伪造报告等事情承担事实上的责任。 Dweomite <a href="https://www.lesswrong.com/posts/qCstMcRJcjNtdNW7r/what-i-would-do-if-i-were-working-on-ai-governance?commentId=r4pd9TtuGxcXfjKsG"><u>回答说</u></a>，这“有点像如果你让 Adob​​e 对孩子使用 Photoshop 创建假驾驶执照之类的事情负责（可能的结果是所有合法可用的图形编辑软件都将永远糟糕）”。</p><p>现在我们有了正确回复该评论的机制。简而言之：这是一个很好的类比（假设假驾驶执照会造成一些可提起诉讼的损害）。我不同意的部分是预测的结果。我实际上认为 Photoshop 会稍微贵一些，并且包含尝试识别和阻止编辑驾驶执照照片等操作的代码。或者，如果用户真的讨厌护栏并且愿意支付足够的额外费用来承担责任，那么他们就会在没有任何护栏的情况下承担成本。</p><p>同样，如果人工智能公司普遍对深度造假造成的伤害负责……那么，在短期内，我预计成本只会转嫁到消费者身上，消费者将继续使用该软件，因为乐趣远远超过危害。从长远来看，人工智能公司将被激励建立诸如名人面孔许可之类的东西，检测并关闭特别恶劣的用户，并使他们的产品能够抵御越狱。</p><p>幻觉或虚假报告也是如此。只要产品产生的价值大于危害，责任成本就会转嫁给消费者，人们就会继续使用这些产品。但人工智能公司将受到适当的激励来了解他们的客户，进行设计以减轻损害等。基本上，人们希望从监管框架中得到的东西，但不依赖监管机构来让一切都正确（实际上并不是把一切都正确，而是古德哈特反对）。</p><p>这就是我理想中的人工智能事实上的责任框架。</p><br/><br/> <a href="https://www.lesswrong.com/posts/tQNfNCdWB5dboRNoZ/principles-for-product-liability-with-application-to-ai#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/tQNfNCdWB5dboRNoZ/principles-for-product-liability-with-application-to-ai<guid ispermalink="false"> tQNfNCdWB5dboRNoZ</guid><dc:creator><![CDATA[johnswentworth]]></dc:creator><pubDate> Sun, 10 Dec 2023 21:27:42 GMT</pubDate> </item><item><title><![CDATA[What do you do to remember and reference the LessWrong posts that were most personally significant to you, in terms of intellectual development or general usefulness?]]></title><description><![CDATA[Published on December 10, 2023 5:52 PM GMT<br/><br/><p>简单的问题！</p><p>你会寻找直到找到吗？您查看书签列表吗？您是否保留了引用 LessWrong 文章的页面，甚至整个黑曜石库？</p><p>似乎人们在撰写新帖子和评论时经常毫不费力地引用现有的相关 LessWrong 文章，这可能是一个愚蠢的问题，但我很好奇，因为我很难简单地记住事物的标题，而且我想知道其他人在做什么。</p><br/><br/> <a href="https://www.lesswrong.com/posts/QwFDosu2o8pjFRTK5/what-do-you-do-to-remember-and-reference-the-lesswrong-posts#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/QwFDosu2o8pjFRTK5/what-do-you-do-to-remember-and-reference-the-lesswrong-posts<guid ispermalink="false"> QwFDosu2o8pjFRTK5</guid><dc:creator><![CDATA[lillybaeum]]></dc:creator><pubDate> Sun, 10 Dec 2023 17:52:24 GMT</pubDate> </item><item><title><![CDATA[Do websites and apps actually generally get worse after updates, or is it just an effect of the fear of change? ]]></title><description><![CDATA[Published on December 10, 2023 5:26 PM GMT<br/><br/><p>我可以对此进行深入探讨，但我假设大多数人对这个主题都有相当多的经验。需要记住一些例子，以便您了解我的观点的背景，包括Discord（新的移动应用程序及其多年来功能集的更改）、Reddit（旧的reddit与新的相比）、LessWrong（讨论功能）。</p><p>我的问题的<i>关键</i>是：<i>与资本主义力量导致的enshittiification（为了取悦投资者、创造无限增长、普遍赚更多钱而进行的改变）不同，</i>应用程序和网站的变化在某些明显而明显的方面平均比更糟糕他们以前的版本，或者是由于人类普遍存在的“害怕或不喜欢改变”而对这些平台的用户界面和概念的改变感到明显的愤怒？</p><p>例如，让我们指出诸如徽标和品牌字体变化之类的事情。这是对平台普通用户影响最小的一个变化，Reddit 的可用性在 Logo A 和 Logo B 之间没有任何变化（新徽标在右侧）。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/ix6rm8jsrw2avywtfd7c" alt="Reddit 因 IPO 猜测而更新徽标TechCrunch"></figure><p>但初步调查显示，反应大多是负面的。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/qkpizhpbsll0vz5zpgzo" alt="请愿 · 改回 Discord 标志！ · 变革组织"></figure><p> Discord 也是如此（下面是新徽标）。当 Discord 的徽标和字体更改宣布时，反应绝大多数是负面的。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/yrcepylrrapx9ehqthfw" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/cqmqmrnrb4zgv3ghfrlg 135w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/mum5wtuplls4x4kjfojs 215w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/o0si1t43q9vvj7pjv3h3 295w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/i2mp61pzwul18m9cetjp 375w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/du0k6fofaiximrpbgxez 455w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/edbyg9w3rk5pw4l2tiqa 535w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/rwlbhv8z3ptuqq2uvjfi 615w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/svkrimzakimrc8qws9m4 695w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/f73zxrbduvwz7elhkxrq 775w"></figure><p>最后一个例子，这是 Patreon 标志最近的变化。人们<i>如此</i>反对这一改变，这有点搞笑。它被用作一个指标，表明企业的品牌形象正趋向于缺乏任何个性或身份的无定形斑点。很难找到任何人声称新的 Patreon 标志有任何好处。</p><p><i>需要澄清上一节：我认为思考徽标是好是坏没有什么价值。我认为以前的标志更引人注目且艺术上更有趣，但这就是我问题的目的。我的目的是指出这样一个事实：公众对这些标志变化的反应几乎总是负面的。</i></p><p>很容易看出，当一家公司的徽标发生变化时，平均而言，人们不喜欢它。我可以继续发布百事可乐、可口可乐、汉堡王、facebook（哦，我的意思是 FACEBOOK）等的徽标更改...如果有人可以指出徽标更改并收到积极响应的案例，我会我很喜欢听这个，但这或多或少不是重点。</p><p>我的主要问题是，徽标更改的愤怒是否表明人们<i>认同某个应用程序、网站或品牌，然后当身份发生变化时感到被背叛</i>，或者如果这些变化实际上总体上是负面的，那么他们的批评是有效的。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/g6kkk2exkhjc4ejkyhfr" alt="新旧简单比较：r/redesign"><figcaption>源代码：https://www.reddit.com/r/redesign/comments/8ktdwx/simple_comparison_of_old_and_new/</figcaption></figure><p>如果这些变化实际上总体来说​​很<i>糟糕</i>（我倾向于同意上面有关 Reddit 的信息图），那么为什么随着时间的推移，网站会变得更糟，而不是更好？这完全是前面提到的与“市场力量”有关的<i>enshitification</i> ，还是其他什么？通过渐进式的改变来改善已经很好的面向公众的服务真的<i>很难</i>吗？一般来说，UI/UX 设计师是否缺乏对优秀设计的理解？这对我来说似乎不太可能。也许他们只是经常缺乏实际定期使用给定应用程序的背景。</p><p>我有点担心这是一个毫无意义或曲折的问题。我只是希望能够进行一些好的讨论，并在某种程度上更新我对此类事情的想法。谢谢阅读！</p><br/><br/> <a href="https://www.lesswrong.com/posts/SiPX84DAeNKGZEfr5/do-websites-and-apps-actually-generally-get-worse-after#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/SiPX84DAeNKGZEfr5/do-websites-and-apps-actually-generally-get-worse-after<guid ispermalink="false"> SiPX84DAeNKGZEfr5</guid><dc:creator><![CDATA[lillybaeum]]></dc:creator><pubDate> Sun, 10 Dec 2023 17:26:34 GMT</pubDate></item></channel></rss>