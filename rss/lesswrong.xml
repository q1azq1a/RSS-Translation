<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 10 月 11 日星期三 18:16:02 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[[Linkpost] Generalization in diffusion models arises from geometry-adaptive harmonic representation]]></title><description><![CDATA[Published on October 11, 2023 5:48 PM GMT<br/><br/><p>这是<a href="https://arxiv.org/abs/2310.02557"><i>https://arxiv.org/abs/2310.02557</i></a><i>的链接帖子</i><i>。</i></p><blockquote><p>我们表明，在非重叠训练集上训练的两个降噪器基本上收敛到相同的降噪函数。因此，当用于图像生成时，这些网络会生成几乎相同的样本。与训练集和测试集平均性能的标准比较相比，这些结果提供了更强、更直接的泛化证据。事实上，这种泛化是通过相对于网络容量和图像大小而言较小的训练集来实现的，这意味着网络的归纳偏差与摄影图像的基础分布很好地匹配。</p></blockquote><p></p><blockquote><p>在这里，我们凭经验证明，扩散模型可以实现强大的泛化形式，收敛到独立于特定训练样本的独特密度模型，并且训练数据量相对于参数或输入空间的大小较小。随着训练数据的增长，收敛表现出记忆和泛化之间的相变。跨越这一相变所需的数据量取决于图像复杂性和神经网络容量（Yoon 等人，2023），并且有兴趣扩展理论和实证研究来解释这些问题。我们引入的用于评估记忆与泛化的框架可以应用于任何生成模型。</p></blockquote><br/><br/> <a href="https://www.lesswrong.com/posts/v53KQpNPsX3wzfCJJ/linkpost-generalization-in-diffusion-models-arises-from#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/v53KQpNPsX3wzfCJJ/linkpost-generalization-in-diffusion-models-arises-from<guid ispermalink="false"> v53KQpNPsX3wzfCJJ</guid><dc:creator><![CDATA[Bogdan Ionut Cirstea]]></dc:creator><pubDate> Wed, 11 Oct 2023 17:48:25 GMT</pubDate> </item><item><title><![CDATA[What I've been reading, October 2023: The stirrup in Europe, 19th-century art deco, and more]]></title><description><![CDATA[Published on October 11, 2023 4:11 PM GMT<br/><br/><p>每月一期的专题。上个月对我来说很忙，因为我有很多旅行和很多关注<a href="https://rootsofprogress.org/">作为非营利组织的进步的根源</a>，所以我没有像我喜欢的那样有足够的时间进行研究和写作。最近的博客文章和新闻报道通常被省略；您可以在我的<a href="https://rootsofprogress.org/writing#links-digest">链接摘要</a>中找到它们。下面引用中的所有粗体强调都是我添加的。</p><h2><strong>技术史</strong></h2><p>完成了我<a href="https://rootsofprogress.org/reading-2023-09">上次提到的</a><strong>乔尔·莫克尔（Joel Mokyr）的</strong><a href="https://www.amazon.com/Lever-Riches-Technological-Creativity-Economic/dp/0195074777"><i><strong>《财富的杠杆：技术创造力与经济进步</strong></i></a>》（1990）。本书的第一部分总结了从古代到工业革命的西方技术发展。第二部分通过三个对比来探讨这种发展的原因：古典时期与中世纪时期、欧洲与中国、英国与欧洲其他国家。</p><p>这本书值得全面回顾，现在我只在 Mokyr 考虑技术发展与生物进化之间类比的章节中引用一句富有洞察力的引言：</p><blockquote><p>遗传学研究是研究人群遗传变异的原因。然而，遗传学对我们对物种形成的理解贡献甚微，对我们对灭绝的理解也没有贡献（Lewontin，1974，p.12）。经济分析假设技术将由利润最大化的公司选择，这些公司雇用的工程师的头脑中储存着各种技术的基因型，它起着类似于遗传学的作用。它解释了需求和供给如何产生多种技术，并指出环境和竞争的约束影响对多样性程度的限制。正如遗传学本身无法解释物种形成一样，经济分析也难以解释宏观发明。与进化一样，技术进步既不是命运，也不是侥幸。然而，达尔文逻辑——自然选择强加于盲目变异——的力量在于我们不需要在两者之间进行选择。</p></blockquote><p>我现在正在读<strong>林恩·怀特（Lynn White）</strong>的另一本经典著作<a href="https://www.amazon.com/Medieval-Technology-Social-Change-Townsend/dp/B00442EY2K"><i><strong>《中世纪技术与社会变革</strong></i></a>》（Medieval Technology and Social Change，1962）的一半。怀特涵盖了三个主要发展：马镫、使用马作为役畜以及机械动力的发展。重点是这些新技术引发的社会变革。</p><p>众所周知，怀特认为马镫创造了封建制度。马镫使骑手能够更牢固地骑在马上，这使得使用长矛的新型骑马作战成为可能，这种作战方式优于步行部队或马背上的弓箭手。马匹很昂贵（盔甲和长矛也很昂贵），而且需要土地来喂养它们，因此土地被从教堂夺走并交给封臣，作为交换，他们以骑马战士的身份为君主服务。随着时间的推移，整个文化围绕着这一点成长起来：这些封臣成为骑士，拥有自己的美德准则（骑士精神）、自己的训练和游戏（锦标赛）等。</p><p>其他历史学家此前曾将封建主义的发展追溯到这种新型战斗，并追溯到煽动这种战斗的<a href="https://en.wikipedia.org/wiki/Charles_Martel">查理·马特尔</a>，但他们为军事变革寻找政治或其他社会原因（例如，一个假设是著名的<a href="https://en.wikipedia.org/wiki/Battle_of_Tours">战斗在普瓦捷与撒拉逊人的战斗</a>促使查理寻求更优越的军事战术，尽管他获胜了）。怀特的贡献是认为，所有这一切的触发因素最终不是社会，而是技术。</p><p>到目前为止，我唯一的抱怨是怀特错过了将这本书命名为<i>《欧洲的马镫》</i>的机会。</p><p>我的阅读清单上还有<strong>弗里德里希·克莱姆 (Friedrich Klemm) 的</strong><a href="https://www.amazon.com/gp/product/0262610019"><i><strong>《西方技术史》(A History of Western Technology</strong></i></a> ) (1959)，莫基尔 (Mokyr) 多次引用了该书。</p><h2><strong>农业</strong></h2><p>在一段时间内，我仍在为我的书研究农业。最近，我一直在回顾 19 世纪“粪肥”（今天我们可能称之为肥料）的历史资料。在那个时代，农民渴望寻找新的肥料来提高农业产量，以满足快速增长的人口对粮食日益增长的需求。然而，农业化学仍在发展，合成肥料还需要几十年的时间。相反，农民和科学家都尝试了各种天然肥料。</p><p>汉弗莱<strong>·戴维 (Humphry Davy)，《</strong><a href="https://wellcomecollection.org/works/fy86gwtq"><i><strong>农业化学原理》</strong></i></a> (1813)； <strong>Jean-Baptiste Boussingault 的</strong><a href="https://www.biodiversitylibrary.org/item/62744#page/5/mode/1up"><i><strong>《农村经济》，在其与化学、物理和气象学的关系</strong></i></a>（1860）中，有关于肥料的章节，其中列出了当时使用的一长串物质。来自动物和人类的粪便和尿液当然是一个主要特征，但您可能会惊讶于这些物质在 19 世纪受到的高度重视。例如，布辛格说：</p><blockquote><p>为改善农场这一重要部门而产生的任何费用，很快就会得到超出支出比例的偿还。<strong>农民的勤劳和智慧，确实可以通过他对粪堆的照顾来判断。</strong></p></blockquote><p>后来，他赞扬了佛兰德斯收集人类土壤的“特别照顾”和“高度理性”的方法，这些土壤构成了“活跃交通的主要内容”。他赞许地指出，中国人也“以最大的关怀收集人类排泄物，为此目的，在最常去的道路上每隔一定距离放置容器。”</p><p> 19 世纪新近广泛使用的肥料包括油籽饼（由种子压榨油后留下的废物形成），甚至骨头，要么碎成小块，要么磨成粉末。英国对骨头的需求如此之大，而且他们从国外进口骨头的活动如此活跃，以至于德国农业化学家贾斯特斯·李比希（Justus Liebig）提出了著名的<a href="https://www.google.com/books/edition/Justus_Von_Liebig/VugoemP2th0C?hl=en&amp;gbpv=1&amp;pg=PA178&amp;printsec=frontcover">抱怨</a>：</p><blockquote><p>英国剥夺了所有国家的生育条件。它占领了莱比锡、滑铁卢和克里米亚的战场；它消耗了西西里岛地下墓穴中许多代人的骸骨；现在每年都会毁掉未来三百万半人的食物。它像一个吸血鬼一样挂在欧洲乃至世界的胸口，吸食着它的生命之血，却没有为自己带来任何真正的需要或永久的利益。</p></blockquote><p> （感<a href="https://www.ageofinvention.xyz/">谢安东·豪斯</a>的引用）</p><p>戴维和布辛格还建议使用灰烬和烟灰作为肥料；羊毛抹布；海岸和河底的贝壳、海藻、泥土和粘液；糖、淀粉、牛脂和胶水制造过程中产生的废物；各种动物残骸的边角料和边角料，包括兽皮、毛发、肌腱、羽毛，甚至凝固的血液。显然，农民迫切需要任何可以获得的生育来源。</p><p>从 1840 年代开始，另一种肥料开始使用：海鸟粪，主要发现于秘鲁海岸附近的岛屿上。 <strong>James FW Johnston 在《</strong> <a href="https://www.google.com/books/edition/Journal_of_the_Royal_Agricultural_Societ/hJYEAAAAYAAJ?hl=en&amp;gbpv=1&amp;pg=PA301&amp;printsec=frontcover"><strong>论鸟粪</strong></a><strong>》</strong> （1841 年）中描述了这一现象：</p><blockquote><p>它形成不规则且有限的矿床，有时深度可达 50 或 60 英尺（洪堡），<strong>并且像铁赭石矿一样被挖掘。</strong> ……在艾莱岛和耶稣岛<strong>，偶尔会在一个季节收集 20 至 25 吨这种新鸟粪。</strong></p></blockquote><p>这篇论文是在鸟粪贸易开始时发表的，但结束已经在望：“正如一些人所相信的那样，这种物质的供应以秘鲁的成本来看是取之不尽用之不竭的。” ”。四十年后，大部分资源被消耗，贸易迅速下降。进口鸟粪最终被<a href="https://rootsofprogress.org/turning-air-into-bread">基于哈伯-博世工艺的合成肥料</a>所取代。</p><h2><strong>设计</strong></h2><p>我参加了一场关于<a href="https://en.wikipedia.org/wiki/Christopher_Dresser">克里斯托弗·德莱瑟（Christopher Dresser）</a>的有趣<a href="https://youtu.be/He43pT508Fw">演讲</a>，他被称为第一位工业设计师。大约在 1870 年代，他设计了茶壶、信夹和其他看起来像是直接来自 1930 年代装饰艺术风格的物品： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9a7fixEi5pEfKbMAc/rwvywp6nvpetyp3htw6i" alt="Dresser 设计的茶壶，1879 年"><figcaption><i>德莱赛 (Dresser) 设计的茶壶，1879 年。</i><a href="https://en.wikipedia.org/wiki/File:Christopher_Dresser_-_Teapot_-_1879.jpg"><i>维基媒体 / Chris 73</i></a></figcaption></figure><p>这促使我仔细阅读了他的书<a href="https://archive.org/details/principlesofdeco00dresuoft/page/n1/mode/2up"><i><strong>《装饰设计原理》</strong></i></a> （1870），或者至少是介绍。德莱赛对设计的重要性有着强烈的道德感：</p><blockquote><p>智力水平最低的人可以挖掘粘土、铁、铜或采石场；但是<strong>，这些材料如果带有心灵的印记，就会变得高贵并变得有价值，</strong>而且材料越强烈地带有这种高贵的印记，它就变得越有价值。</p><p>我必须限定我的最后一句话，因为在某些情况下，心灵印象可能会降低而不是提升材料的价值，并且可能会剥夺而不是增强材料的价值。要想高尚，心必须高尚；如果贬低，就只能贬低。让心灵变得精致和纯洁，它越充分地将自己印在材料上，材料就会变得越可爱，因为这样它就接受了精致和纯洁的印象。但如果心堕落、不纯净，则其本质所传递的物质就变得愈堕落。让我用一块简单的粘土作为烛台，而不是土制烛台，因为土制烛台只呈现出堕落心灵自然流露的形式。</p></blockquote><p>后来，在一段经常被引用的段落中，他说：</p><blockquote><p>艺术中可能有道德或不道德，也可能有真话或假话；<strong>装饰师可以通过他的艺术来提升或贬低一个国家。</strong></p></blockquote><p>不过，这本书的大部分内容都是关于“装饰的真正原则”：</p><blockquote><p>我们将仔细考虑某些一般原则，这些原则要么是所有美术所共有的，要么是指导装饰形式的生产或布置的：然后我们将注意到规范颜色组合以及颜色在物体上的应用的法则；之后我们将回顾我们的各种艺术作品，并将艺术与制造业联系起来。因此，我们将被引导考虑家具、陶器、桌子和窗玻璃、墙壁装饰、地毯、地板布、窗饰、服装面料、金银制品、五金制品以及任何艺术与制造业的结合。那么，我要向木匠、细木工、陶工、玻璃吹制工、纸张染色工、纺织工和染色工、银匠、铁匠、煤气加工工、设计师以及所有以任何方式从事这一行业的人致辞。艺术品的生产。</p></blockquote><p>现在也在我的阅读清单上：</p><ul><li><strong>路易斯·沙利文，</strong><a href="https://www.worldcat.org/title/19740148"><i><strong>建筑装饰体系</strong></i></a>(1924)</li><li><strong>勒·柯布西耶，</strong> <a href="https://www.amazon.com/Towards-New-Architecture-Corbusier-ebook/dp/B0BWSKTM12"><i><strong>走向新建筑</strong></i></a>(1923)</li><li><strong>汤姆·沃尔夫，</strong> <a href="https://www.amazon.com/Bauhaus-Our-House-Tom-Wolfe-ebook/dp/B004ZM08CE"><i><strong>《从包豪斯到我们的家</strong></i></a>》(1981)</li></ul><h2><strong>法律</strong></h2><p><a href="https://www.astralcodexten.com/p/your-book-review-njals-saga"><strong>斯科特·亚历山大评论了</strong><i><strong>Njal 的传奇</strong></i></a><strong>。</strong> （这篇评论是斯科特自己书评比赛的匿名参赛作品；它获得了最多的读者投票，但斯科特慷慨地取消了自己赢得比赛的资格。）这本书是关于中世纪冰岛的正义，那里没有警察或监管机构，但其中确实有一个法庭。这个社会的正义往往是通过家族争斗来伸张的，也就是说，家族和其他联盟经常为了报复而互相攻击和杀害。但不满也可以诉诸法庭。如果法庭决定，为了补偿报复性杀戮，凶手应该支付罚款（the <i>weregild</i> ），也许这可以结束此事并停止杀戮的循环。在这个传奇故事中，和平解决往往取决于明智的长老尼贾尔。当尼贾尔本人被杀并且不再提供建议时，很多和平都被打破了。</p><p>相关：巧合的是，我还看到了<strong>阿诺德·克林（Arnold Kling）的《</strong><a href="https://www.econlib.org/library/Columns/y2013/Klingclan.html"><strong>国家、宗族和自由</strong></a><strong>》</strong> （2013）；对<strong>马克·维纳（Mark Weiner）的</strong><a href="https://www.amazon.com/Rule-Clan-Ancient-Organization-Individual-ebook/dp/B00AJI094U"><i><strong>《氏族规则》（The Rule of the Clan）</strong></i></a>的评论，该书<i>也是</i>关于中世纪冰岛及其法律制度的。一些摘录：</p><blockquote><p> [韦纳]发现了一种他称之为氏族统治的秩序模式，这种模式不需要强大的中央政府。然而，他表明氏族统治依赖于一套规则和社会规范，这些规则和社会规范与和平、开放商业和个人自治的自由主义价值观不一致。 ……</p><p><strong>韦纳的分析基于法律历史学家亨利·梅因的传统，他区分了地位社会和契约社会。</strong>在前者中，法律面向大家庭作为一个群体。在后者中，法律面向个人。</p></blockquote><p>克林“从自由主义的角度”将韦纳的论文总结为：</p><blockquote><ol><li>分散订单是可能的。事实上，人类社会自然会实现这样的秩序，而不是堕落为所有人对抗所有人的霍布斯战争。</li><li>然而，自然的去中心化秩序是高度不自由的。它需要一套将个人与氏族联系在一起的社会规范。<strong>在氏族统治下，和平因争斗而被破坏，商业因无法在合同基础上与陌生人进行贸易而受到削弱，个人自主权因群体团结而被牺牲。</strong></li><li>在没有强大的中央国家的情况下，宗族统治是必然的结果。为了从地位社会毕业到契约社会，必须有一个强大的中央国家。</li></ol></blockquote><p> （克林说他认为第 3 点似乎有道理，但并不完全有说服力。）</p><p>我建议阅读这两篇文章。</p><h2><strong>生物学</strong></h2><p><strong>谢尔盖·马尔科夫，“</strong><a href="https://markov.bio/biomedical-progress/"><strong>生物医学进步的未来史</strong></a><strong>”</strong> （2022）。这件事在一两个月前就已经流传开来。它首先对生物技术工具和技术的部分前沿进行了长时间的讨论，如果您想了解核心思想，可以略读或跳过。核心思想是：我们将需要人工智能来设计和制造先进的生物技术，因为生物学是如此复杂，以至于很难创建整个系统的人类可读模型。我们不是直接了解哪些基因做什么、每种蛋白质的功能是什么以及哪些过程涉及哪些途径，而是将所有输入和输出放入一个大型机器学习模型中并让它学习。</p><p>本文的第二个想法是，为了做到这一点，我们需要平台来进行非常高保真度的实验，其结果可以高度转移到我们真正关心的系统，例如人体。鼠标模型可能无法解决这个问题；我们可能必须做一些事情，比如用干细胞培养整个人体器官，以便对它们进行实验并了解它们的真正工作原理。</p><p>我远不是这个领域的专家，但我发现这些论点是有道理的，特别是因为这些文章将它们与更广泛的原则联系起来，即 Rich Sutton 著名的<a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">ML 的“惨痛教训”</a> ：任何使用专业领域知识手工定制的系统如果计算和训练数据规模足够大，最终会被从头开始学习一切的通用系统击败。</p><p>然而，我并不认为这意味着人类永远无法理解生物学。我乐观地认为，人工智能不仅能够弄清楚生物系统的巨大复杂性，而且还能弄清楚如何向人类解释它。</p><p> <strong>Chris Wintersinger，“</strong><a href="https://blog.spec.tech/p/making-the-proteins-that-living-cells"><strong>制造活细胞无法制造的蛋白质</strong></a><strong>。”</strong>对 Speculative Technologies 正在进行的项目的简要描述。对我来说，这是一个非常雄心勃勃的生物技术研究项目的一瞥。我喜欢这个图表： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9a7fixEi5pEfKbMAc/ni9hjkbsne7vorvbrcep" alt=""><figcaption> <a href="https://blog.spec.tech/p/making-the-proteins-that-living-cells"><i>Chris Wintersinger，投机技术撰稿人</i></a></figcaption></figure><h2><strong>其他文章</strong></h2><p><strong>布莱恩·波特，《</strong><a href="https://www.construction-physics.com/p/how-the-car-came-to-la"><strong>汽车是如何来到洛杉矶的</strong></a><strong>》</strong> ：</p><blockquote><p>我们是如何成为一个以汽车为城市生活的决定性特征的国家的？这种转变是什么样的？</p><p>为整个国家回答这个问题将是一项艰巨的任务。但斯科特·博尔斯 (Scott Bottles) 所著的<i>《洛杉矶与汽车》</i>一书试图为洛杉矶这个美国最以汽车为中心的城市之一回答这个问题。在不到 30 年的时间里，洛杉矶从一个以有轨电车和火车为主的交通城市转变为汽车占主导地位的城市。</p></blockquote><p> <a href="https://environmentaleducation.com/wp-content/uploads/userfiles/Ben%20Franklin%20Letter%20on%20EEA%281%29.pdf"><strong>本杰明·富兰克林关于铅中毒的信</strong></a>（1786 年）。<a href="https://rootsofprogress.org/reading-2023-09">上次</a>我提到了<a href="https://www.thenation.com/article/archive/secret-history-lead/">铅的历史</a>，指出铅自古以来就被认为是有毒的。这是它引用的来源之一，一封来自本杰明·富兰克林的信，关于他所知道的“铅对内心的不良影响”：</p><blockquote><p>你会看到，这种来自铅的恶作剧效应的观点，至少有六十年以上的历史了；你会关切地观察，有用的真理在被普遍接受和实践之前，可能会被人们认识并存在多久。</p></blockquote><p><strong>沃尔特·本杰明，《</strong><a href="https://www.marxists.org/reference/archive/benjamin/1940/history.htm"><strong>论历史概念</strong></a><strong>》</strong> （1940）。我对此感到失望，但它确实包含了这段引人注目的引言（我将从<a href="https://en.wikipedia.org/wiki/Angelus_Novus">不同来源</a>进行翻译）：</p><blockquote><p>克利的一幅名为<i>《Angelus Novus》</i>的画作展示了一位天使，他看起来似乎即将离开他正在沉思的事物。他的眼睛凝视着，他的嘴张开，他的翅膀张开。这就是历史天使的形象。他的脸转向过去。当我们看到一连串的事件时，他看到的是一场灾难，这场灾难不断地堆积着残骸，并将其扔到他的脚前。天使愿意留下来，唤醒死者，使破碎的一切恢复原状。但一场风暴正从天堂吹来；它如此猛烈地卡在他的翅膀上，以至于天使再也无法关闭它们。风暴不可抗拒地将他推向他背对的未来，而他面前的废墟堆则直冲云霄。<strong>这场风暴就是我们所说的进步。</strong></p></blockquote><p> （经过生动的描述，顺便说一句，我发现<a href="https://commons.wikimedia.org/wiki/File:Klee,_paul,_angelus_novus,_1920.jpg">实际的绘画相当平淡</a>）</p><p><strong>米尔顿·弗里德曼，“</strong><a href="https://www.hoover.org/research/how-cure-health-care-0"><strong>如何治愈医疗保健</strong></a><strong>”</strong> （2001）：</p><blockquote><p>二战结束以来，美国等先进国家的医疗保健呈现出三大特点：一是医学科学突飞猛进；其次，支出大幅增加，无论是按通货膨胀调整后的人均美元还是国民收入中用于医疗保健的比例计算；第三，医疗服务消费者、医生和其他医疗服务提供者对医疗服务的不满情绪日益高涨。</p></blockquote><p>感谢<a href="https://fellowship.rootsofprogress.org/fellows">“进步之根”成员</a><a href="https://tinamarshdalton.substack.com/">蒂娜·马什·道尔顿</a>提供的链接。</p><p><strong>斯科特·阿伦森，“</strong><a href="https://scottaaronson.blog/?p=3376"><strong>柯尔莫哥洛夫选项</strong></a><strong>”</strong> （2017）。说真话很重要，即使真话不受欢迎，但如果当权者惩罚说真话的人，那么无缘无故地牺牲自己就不值得了。柯尔莫哥洛夫选项（以<a href="https://en.wikipedia.org/wiki/Andrey_Kolmogorov">俄罗斯数学家的</a>名字命名）是选择你的战斗并等待时机，直到权力减弱并且说真话的人可以发起协调一致的攻击。对此<strong>，斯科特·亚历山大（Scott Alexander）的《</strong><a href="https://slatestarcodex.com/2017/10/23/kolmogorov-complicity-and-the-parable-of-lightning/"><strong>科尔莫哥洛夫共谋与闪电寓言</strong></a><strong>》</strong> （2017）做出了回应。柯尔莫哥洛夫选项可以起作用，但很难实现：</p><blockquote><p>柯尔莫哥洛夫的诅咒是在他的泡沫中慢慢地看着每个不如他精明的人都被摧毁。最聪明、最诚实的人将首先被摧毁。然后是任何能够可靠地产生智慧或诚实的机构。然后是任何允许这样的机构的哲学。 ......然后他和所有其他精明的人可以尽力收拾残局，哀悼他们的战友，并看着同样的事情在下一代再次发生。</p></blockquote><p> “闪电的寓言”很好地说明了，如果一个社会坚持一个看似微不足道的谎言，最终会蔓延到整个社会，摧毁所有追求真理的人和组织。受到推崇的。</p><p><strong>斯科特·亚历山大（Scott Alexander），“</strong><a href="https://slatestarcodex.com/2019/01/10/paradigms-all-the-way-down/"><strong>范式一路向下</strong></a><strong>”</strong> （2019）。 （斯科特是我最喜欢的博主，所以我不会为他在这里出现三次而道歉。） 几种认知范式大体上是同构的；也许他们对于理论和证据的关系都说了同样的话？</p><h2><strong>小说</strong></h2><p><strong>伊恩·特雷吉利斯，</strong><a href="https://www.amazon.com/dp/B074CDN1HB"><i><strong>炼金术战争</strong></i><strong>三部曲</strong></a><strong>。</strong>我上次提到这一点是在我完成第一本书的时候。现在我已经进入第三个阶段了。在读完之前，我不太愿意强烈推荐任何小说，但到目前为止，这是我一段时间以来读过的最好的东西。</p><h2><strong>我的待读清单上的其他项目</strong></h2><ul><li><strong>卡罗尔·奎格利，</strong> <a href="https://www.amazon.com/Evolution-Civilizations-Carroll-Quigley/dp/0913966576"><i><strong>《文明的演变：历史分析导论</strong></i></a>》（1961）。由 Ben Landau-Taylor 推荐，他<a href="https://www.benlandautaylor.com/p/the-four-instruments-of-expansion">在这里总结了部分内容</a>。</li><li><strong>马克·奥尔德里奇，“</strong><a href="https://www.jstor.org/stable/43522104"><strong>工程成功与灾难：美国铁路桥梁，1840-1900 年</strong></a><strong>”</strong> （1999 年）。感谢<a href="https://twitter.com/benmschneider/status/1706050798172385669">Ben Schneider</a>在回复我关于 19 世纪桥梁倒塌的帖子时推荐了这篇文章。奥尔德里奇还写了<i>《安全第一》</i>一书，这是我关于<a href="https://rootsofprogress.org/history-of-factory-safety">工厂安全的</a>文章的主要来源。</li><li> <strong>GK 切斯特顿，《</strong> <a href="https://www.amazon.com/Whats-Wrong-World-Gilbert-Chesterton-ebook/dp/B0082SS5LS"><i><strong>世界出了什么问题》</strong></i></a> （1910）。著名引言的出处：“基督教的理想还没有被尝试过，也没有被发现有缺陷。发现这很困难；并未经尝试。”许多其他理想也是如此。</li></ul><br/><br/> <a href="https://www.lesswrong.com/posts/9a7fixEi5pEfKbMAc/what-i-ve-been-reading-october-2023-the-stirrup-in-europe#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9a7fixEi5pEfKbMAc/what-i-ve-been-reading-october-2023-the-stirrup-in-europe<guid ispermalink="false"> 9a7修复Ei5pEfKbMAC</guid><dc:creator><![CDATA[jasoncrawford]]></dc:creator><pubDate> Wed, 11 Oct 2023 16:11:46 GMT</pubDate> </item><item><title><![CDATA[EA Madrid social]]></title><description><![CDATA[Published on October 11, 2023 3:34 PM GMT<br/><br/><p> Desde Altruismo Eficaz 马德里为社会活动做好准备，为社会活动和社区活动做准备！这是一个完美的时刻</p><ul><li>这是一个非正式的主题。</li><li> Conocernos 具有出色的想法和项目。</li><li>你可以与世界上最有效的形式进行交流。</li><li> Disfrutar de buena comida vegana。</li></ul><p> ¡ esperamos！</p><p> -------------------------------------------------- --------------------------</p><p>我们马德里有效利他主义组织了一次社交活动，这样我们就可以互相了解并在更轻松的氛围中聊天！这是一个完美的时机：</p><ul><li>随意讨论您想了解更多的任何话题。</li><li>更好地了解彼此并分享想法和项目。</li><li>与那些与您志同道合的人一起享受美好时光，以最有效的方式让世界变得更美好。</li><li>品尝美味的素食。</li></ul><p>我们期待您的光临！</p><br/><br/><a href="https://www.lesswrong.com/events/EdubgqkfxuZKvKnQK/ea-madrid-social#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/events/EdubgqkfxuZKvKnQK/ea-madrid-social<guid ispermalink="false"> EdubgqkfxuZKvKnQK</guid><dc:creator><![CDATA[Pablo Villalobos]]></dc:creator><pubDate> Wed, 11 Oct 2023 15:34:03 GMT</pubDate> </item><item><title><![CDATA[Attributing to interactions with GCPD and GWPD]]></title><description><![CDATA[Published on October 11, 2023 3:06 PM GMT<br/><br/><p><i>这篇文章提供了背景、动机和纯数学的非技术摘要</i><a href="https://arxiv.org/abs/2310.06686"><i>https://arxiv.org/abs/2310.06686</i></a> <i>。</i></p><p><i>合著者（按字母顺序排列）：Chris MacLeod、Jenny Nitishinskaya、Buck Shlegeris。工作大部分是在红木研究中心完成的。感谢 Joe Benton 和 Ryan Greenblatt 之前所做的一些数学计算。感谢 Neel Nanda、Fabien Roger、Nix Goldowsky-Dill 和 Jacob Hilton 对本工作各个部分的反馈。</i></p><h1>介绍</h1><p>在可解释性方面（更普遍的是在模型理解或模型神经科学中），人们关心的是测量多个输入或组件<span class="footnote-reference" role="doc-noteref" id="fnref8b84m8xhq6m"><sup><a href="#fn8b84m8xhq6m">[1]</a></sup></span> （例如头部）对模型行为的影响，并确定哪些输入或组件是重要的。这就是所谓的<i>归因</i>。</p><p>假设我们已经对模型的两个不同部分进行了归因。直观地说，如果这两个部分也重要地相互作用，则与不相互作用时会发生非常不同的情况！在这篇文章中，我们考虑这个问题：<strong>什么是归因于</strong>输入或组件之间<i><strong>交互</strong></i>的原则性可解释性框架<strong>？</strong></p><h1>概括</h1><ul><li>我们可以将一个函数分解为各种阶次的所有输入交互项的总和：函数的均值，加上每个输入的单独贡献，加上每对输入的二阶交互作用等。</li><li>一般来说，一次归因于一个输入不足以解释函数的行为。</li><li>如果您不测量交互作用，请注意您假设它们为 0！</li><li>一个潜在有前途的未来方向是使用该框架进行<a href="https://www.alignmentforum.org/posts/vwt3wKXWaCvqZyF74/mechanistic-anomaly-detection-and-elk">机械异常检测</a>。</li></ul><h1>背景：通过干预进行归因</h1><p>回想一下，我们有一种方法可以对模型输入（或组件）进行归因：调整输入的 1 部分，同时保持其他部分不变。例如，要了解输入中的标记有多重要，我们可以消除该标记并查看模型的输出如何变化。</p><p>在这篇文章中，我们将讨论重新采样消融以及对您选择的某些分布的输出期望：有关原因的更多信息，请参阅<a href="https://www.alignmentforum.org/posts/JvZhhzycHu2Yd57RN/causal-scrubbing-redwood-research#4_Why_ablate_by_resampling_">因果清理文章</a>。</p><h1>常问问题</h1><h2>与对齐有什么关系？</h2><p>注意，本节很简短，省略了很多细节，但如果没有提及作者为何对这个方向感兴趣，这篇文章就感觉不完整。</p><p>我们预计，在调整超人系统时，我们可能需要模型来进行一定程度的泛化并处理一些分布变化，而某些异常/变化可能是不安全的（我们包括考虑<a href="https://www.alignmentforum.org/posts/vwt3wKXWaCvqZyF74/mechanistic-anomaly-detection-and-elk">机械</a>异常以及输入/输出异常）。</p><p>假设我们在完全监督的分布上对模型的输入进行归因。现在我们正在部署中运行它，并想知道模型在新数据上的行为是否安全。我们再次运行归因计算，发现它有点不同（可能一个输入较高一点，另一个输入较低一点）。我们如何判断这是否可以？一种方法可能是衡量是否存在<i>新颖的交互</i>：这与我们之前看到的有本质上的不同。</p><p>交互可能特别重要的一个例子是检测共谋：我们经常想到<a href="https://www.alignmentforum.org/posts/qHCDysDnvhteW7kRd/arc-s-first-technical-report-eliciting-latent-knowledge">ELK</a>设置，其中模型故意欺骗监督过程，表现为模型组件之间<i>令人惊讶的交互</i>，推理我们将监督的结果。</p><h2>更广泛的可解释性有何相关性？</h2><p>对模型行为可能很重要的术语的精确、有原则的<a href="https://www.alignmentforum.org/posts/JvZhhzycHu2Yd57RN/causal-scrubbing-redwood-research#1_Introduction">框架</a>对于清晰地陈述可解释性假设很有用。这对于比较不同实验的结果非常有用；以及自动假设搜索，减少了实验者判断的需要，其中应该测量额外的归因。</p><p>我们认为这个框架也是值得牢记的。在研究您感兴趣的模型行为时，请务必记住“操作”<i>不必</i>流经您正在考虑的任何一项输入。如果您搜索所有[头、输入标记等]并且没有找到负责任的，则这一点最为明显。在其他情况下，您可能会发现<i>一些</i>效果，但会错过一些重要的部分。如果您还没有认为互动具有潜在的重要性，那么您可能很难注意到自己错过了什么。</p><h2>如果我认为交互在先验上可能不重要，那我为什么要关心呢？</h2><p>通常<span class="footnote-reference" role="doc-noteref" id="fnrefec49qgf0y7n"><sup><a href="#fnec49qgf0y7n">[2]</a></sup></span>您正在考虑的多个“位”之间存在<i>某种</i>相互作用。如果您认为交互并不重要并且想要彻底，那么您应该检查这些交互是否很小。</p><h2>互动真的在实践中出现吗？</h2><h3>交互示例：冗余</h3><p>显然，计算的多个输入对于手头的任务来说可能是多余的：重新采样消融（或屏蔽掉，或任何其他消融）其中任何一个都没有效果，但消融所有输入会产生很大的效果！考虑对一个句子是否是法语进行分类：如果你只用英语句子中的一个单词替换一个单词，分类器仍然会以非常高的概率说它是法语（假设句子足够长）。不同的输入（标记）对于模型行为来说是<i>多余的</i>。</p><p>模型组件也可能是冗余的：小型变压器<a href="https://www.alignmentforum.org/posts/j6s9H9SHrEhEfuJnq/causal-scrubbing-results-on-induction-heads#Refined_hypothesis_1">表现出</a>多个头，这些头基本上将先前的令牌复制到不同的子空间中，而<a href="https://www.alignmentforum.org/posts/3ecs6duLmTfyra3Gp/some-lessons-learned-from-studying-indirect-object">野生论文（从这里开始称为 IOI 论文）中的可解释性</a>显示出冗余的“名称移动者头”。在这两种情况下，许多负责人至少部分地执行相同的工作。</p><h3>交互示例：性质不同的行为</h3><p>在其他情况下，输入之间的交互可能更加复杂，其中对一个输入的响应取决于另一个输入的响应。一个基本的例子是 XOR：如果输入是 (1, 0)，那么对 y 的归因是正的（改变 y 会减少输出），而如果输入是 (0, 0) 那么对 y 的归因是负的！</p><p>在法学硕士中，一个例子是 IOI 论文中的备份名称移动器头：这些似乎<i>仅在</i>“主要”名称移动器头不执行名称移动器任务时才执行名称移动器任务！</p><h2>相互作用如此之多，测量所有这些相互作用将非常昂贵。我可以廉价地检查交互而不需要如此严格吗？</h2><p>有时无需显式计算即可估计交互作用。例如，假设您通过检查注意力模式来识别先前的标记头。您可以烧蚀一组这样的磁头，然后查看输出中产生的变化是否等于一次烧蚀单个磁头时的变化之和。如果是，那么它们之间要么没有相互作用，要么所有相互作用（大约）抵消。如果不是，那么头部之间就会有一些交互，尽管你不知道是哪些交互。</p><p>在 IOI 论文中，作者没有明确测量备份名称移动器/名称移动器交互：相反，他们进行了一些实验<span class="footnote-reference" role="doc-noteref" id="fnrefpyizgx0qevg"><sup><a href="#fnpyizgx0qevg">[3]</a></sup></span> ，表明存在一些交互。</p><p>我们对我们提出的原则框架及其应用感到兴奋，但如果您不想采用它，我们希望您仍然了解交互效应并知道如何估计它们。</p><h1>归因框架的直观和概述</h1><p>让我们回顾一下如何归因于特定输入<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>到函数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>的输出（期望执行重采样消融）。我们可以这样想：</p><blockquote><p> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span>重要的数量 =<br>然而， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>的大部分值并没有通过考虑<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>在输入分布<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span>上的一般行为来解释</p></blockquote><p>让我们考虑一些简单的情况。如果<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>是常数函数，则<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span>的属性为 0。如果是恒等式，则<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span>的属性就是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span>相对于分布<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0 - \mu(X)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em;">μ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span>的</span></span></span></span></span>极值程度。</p><p>现在假设 f 是两个变量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>和<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span>的函数。 We have two inputs, <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> , which happen to be redundant for a computation (such as two words in a French sentence that <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> is classifying the language of). The experiment to do here is obvious—ablate both of them and see how the output of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> changes—but how do we <i>quantify</i> the irreducible amount the interaction matters?</p><blockquote><p> The amount the interaction of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> matters =<br> however much of the value of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> was not explained by taking into account:<br> the general behavior of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> on the input distribution <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(X, Y)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span><br> the general behavior of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> conditional on <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> : what would you expect the output of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> to be, knowing nothing about <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> ?<br> the general behavior of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> conditional on <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span></p></blockquote><p> Again, if <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> is a constant function, any attribution (including to the interaction of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> ) is 0. If it&#39;s linear, eg<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x,y) = x+y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span> , then we expect this attribution should be 0 as well: there is nothing interesting about the combination of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> .</p><h2> A worked example</h2><p> We&#39;ll work out the math for the two-variable function <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x, y) = x*y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span> . Recall that we have inputs <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x0, y0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span> and want to <i>attribute</i> to parts of this input.</p><p> We could resample-ablate the entire input to contextualize it in the dataset:</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="f(x_0, y_0) - E_{(X, Y)} f(x, y) = x_0y_0 - E_{(X, Y)}[xy]"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.275em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.275em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span></span></span></span></span></span><p> This is just like the single-input attribution in the previous section: we&#39;re measuring how extremal the value of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> on this input is, compared to its average value.</p><p> We could resample-ablate just <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> to see how much <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> mattered:</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="f (x_0, y_0) - E_X f(x, y0)= x_0y_0 - E_X [x]y_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span><p> Note that if <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> is 0, the above expression is 0. This makes sense: at that <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> , <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> <i>does not matter at all</i> .</p><p> We could also ask the above for <i>the average</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> :</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="E_Y \left[f(x_0, y) - E_X f(x, y)\right] = x_0E_Y[y] - E_X[x]E_Y[y]"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span> <span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span></span></span></span></span></span><p> What about the interaction of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> ? Recall we said that the amount the interaction matters is:</p><blockquote><p> however much of the value of f was not explained by:<br> the baseline average of f over all inputs<br> how much x0 matters for the average y<br> how much y0 matters for the average x<br> ie:<br></p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\begin{align*}&amp;f(x_0, y_0) - E_{X, Y} f - E_X (f - E_Yf) - E_Y (f - E_xf)\\&amp;= x_0y_0 - E_{X, Y}[xy] - E[y]x_0 - E[x]y_0 + 2 E[x] E[y]\\&amp;= (x_0 - E[X]) (y_0 - E[Y]) - Cov(X, Y)\end{align*}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mtable" style="vertical-align: -1.692em; padding: 0px 0.167em;"><span class="mjx-table"><span class="mjx-mtr" style="height: 1.255em;"><span class="mjx-mtd" style="padding: 0px 0px 0px 0px; text-align: right; width: 0px;"><span class="mjx-mrow" style="margin-top: -0.2em;"><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0px 0px 0px 0px; text-align: left; width: 21.555em;"><span class="mjx-mrow" style="margin-top: -0.2em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span><span class="mjx-strut"></span></span></span></span> <span class="mjx-mtr" style="height: 1.405em;"><span class="mjx-mtd" style="padding: 0.15em 0px 0px 0px; text-align: right;"><span class="mjx-mrow" style="margin-top: -0.2em;"><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0.15em 0px 0px 0px; text-align: left;"><span class="mjx-mrow" style="margin-top: -0.2em;"><span class="mjx-mi"></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span><span class="mjx-strut"></span></span></span></span> <span class="mjx-mtr" style="height: 1.225em;"><span class="mjx-mtd" style="padding: 0.15em 0px 0px 0px; text-align: right;"><span class="mjx-mrow" style="margin-top: -0.2em;"><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0.15em 0px 0px 0px; text-align: left;"><span class="mjx-mrow" style="margin-top: -0.2em;"><span class="mjx-mi"></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">o</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span><span class="mjx-strut"></span></span></span></span></span></span></span></span></span></span></span></blockquote><p> This known as the <a href="https://en.wikipedia.org/wiki/Wick_product">Wick product</a> . The last form we&#39;ve written this in is quite intuitive: how much are <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> “more together” than you would expect from the covariance of the underlying distributions?</p><p> But nothing here depended on <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> computing the product! We can compute the same thing for any <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> with two (or more!) inputs.</p><p> We can see that if <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> is linear, this attribution is 0. This is what we intuitively expected!</p><h2> Attribution as function approximation <span class="footnote-reference" role="doc-noteref" id="fnref5ykjkt643oo"><sup><a href="#fn5ykjkt643oo">[4]</a></sup></span></h2><p> In the example above, the interaction was the missing piece needed to fully describe the behavior of f. That is, if we denote an attribution term with <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\omega_f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ω</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span></span></span> , <span class="footnote-reference" role="doc-noteref" id="fnrefhh5gu5offpi"><sup><a href="#fnhh5gu5offpi">[5]</a></sup></span> then</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="f = \omega_{f, \{X, Y\}} + E_Y [\omega_{f, \{X\}}] + E_X [\omega_{f, \{Y\}}] + E_{X,Y} f."><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ω</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.275em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">{</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">}</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ω</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.275em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">{</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">}</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ω</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.275em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">{</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">}</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span></span></span></span></span></span><p> We can think of attributing to <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> as <i>a term in a decomposition of</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> , and a hypothesis that some inputs or interactions between them don&#39;t matter as a statement that <strong>neglecting them is a good approximation to</strong> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> .</p><p> From this expression we can clearly see that the terms corresponding to separate inputs, or even all the inputs together, are not all the terms needed to describe the model&#39;s behavior.</p><h1> Our contribution</h1><p> We&#39;ve argued that interaction terms can be important, and how we should measure them. What would you do to use this in practice?</p><p> In the linked arXiv post, we have</p><ul><li> defined the general formula for this attribution for arbitrary numbers of inputs and interaction orders</li><li> provided additional intuition</li><li> proven some nice properties</li><li> provided some sample code <span class="footnote-reference" role="doc-noteref" id="fnref0a1jrj1c7qxv"><sup><a href="#fn0a1jrj1c7qxv">[6]</a></sup></span> for those who prefer that over formulas</li></ul><h1> Appendix</h1><h2> Future post: cumulant propagation</h2><p> We can translate <a href="https://arxiv.org/abs/2211.06738">ARC&#39;s cumulant propagation algorithm</a> on arithmetic circuits into computing a set of attributions. Maybe we&#39;ll write this up.</p><h2> Average interaction</h2><p> In this post, we talked about <i>attribution</i> at a fixed reference input <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(x_0, y_0)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> . In the linked writeup, we also cover measuring the interaction of X and Y on average:</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="K_f(X, Y) := E_{(X, Y)} f - E_X E_Y f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.04em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;">K</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.372em;">: <span class="mjx-charbox MJXc-TeX-main-R" style="padding-bottom: 0.314em;">=</span></span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.275em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span><p> Note this is a generalization of the notion of covariance: if <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> is just the product function, this <i>is</i> the covariance between <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="Y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span></span></span></span> . We call <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="K_f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.04em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;">K</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span></span></span> the Generalized Cumulant Product (GCP). We can write the expectation of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> as a sum of GCPs, and this form is the Generalized Cumulant Product Decomposition (GCPD):</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="E_{(X, Y)} f = K_f(X, Y) + K_f(X | Y)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.275em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.04em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;">K</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.04em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;">K</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> <ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn8b84m8xhq6m"> <span class="footnote-back-link"><sup><strong><a href="#fnref8b84m8xhq6m">^</a></strong></sup></span><div class="footnote-content"><p> Note that components can be seen as just multiple inputs to a treefied model. eg as in the IOI paper. We&#39;ll mostly talk about attributing to inputs for ease of language.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnec49qgf0y7n"> <span class="footnote-back-link"><sup><strong><a href="#fnrefec49qgf0y7n">^</a></strong></sup></span><div class="footnote-content"><p> The interaction is always 0 if your model is completely linear, or otherwise has no cross-terms.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnpyizgx0qevg"> <span class="footnote-back-link"><sup><strong><a href="#fnrefpyizgx0qevg">^</a></strong></sup></span><div class="footnote-content"><p> In the notation of our paper, they computed something like <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="E [ E_Y (f - E_X f) - (f - E_X f) ] = K_f(X, Y)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.026em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.04em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;">K</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> . They found this was large, ie the generalized-covariance between X (the input to the name-mover heads) and Y (the input to the backup-name-mover heads) is large. Though, they performed resample ablation on <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span> and <i>knockout</i> on <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="Y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;">Y</span></span></span></span></span></span></span> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fn5ykjkt643oo"> <span class="footnote-back-link"><sup><strong><a href="#fnref5ykjkt643oo">^</a></strong></sup></span><div class="footnote-content"><p> <a href="https://transformer-circuits.pub/2021/framework/index.html#onel-path-expansion">A Mathematical Framework for Transformer Circuits</a> and <a href="https://arxiv.org/pdf/2211.06738.pdf">Formalizing the presumption of independence</a> similarly break up functions into a sum of terms.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnhh5gu5offpi"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhh5gu5offpi">^</a></strong></sup></span><div class="footnote-content"><p> We call this the Generalized Wick Product (GWP) and the form of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> the Generalized Wick Product Decomposition (GWPD) (though technically the terms are expectations of GWPs).</p></div></li><li class="footnote-item" role="doc-endnote" id="fn0a1jrj1c7qxv"> <span class="footnote-back-link"><sup><strong><a href="#fnref0a1jrj1c7qxv">^</a></strong></sup></span><div class="footnote-content"><p> Probably not performant for high-order terms, for which memoization would be helpful. But the second-order interaction is easy to compute and you can probably do it today.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/hFaXe4Mi64xkE6Kqp/attributing-to-interactions-with-gcpd-and-gwpd#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/hFaXe4Mi64xkE6Kqp/attributing-to-interactions-with-gcpd-and-gwpd<guid ispermalink="false"> hFaXe4Mi64xkE6Kqp</guid><dc:creator><![CDATA[jenny]]></dc:creator><pubDate> Wed, 11 Oct 2023 15:06:16 GMT</pubDate> </item><item><title><![CDATA[LLMs — Pure Reason Without The Critique]]></title><description><![CDATA[Published on October 11, 2023 1:11 PM GMT<br/><br/><p> <strong>Motivation:</strong> In the world of generative AI, Large Language Models (LLMs) have witnessed remarkable progress [1] that has largely been driven by their use of attention blocks [2]. Attention enables LLMs to adapt their understanding of input information based on contextual cues, facilitating their general reasoning capabilities. Put simply, attention is how LLMs discern different meanings for &#39;Apple&#39; in sentences like &#39;Apple has exceptional touchscreen technology&#39; and &#39;Apple pie is my favourite dessert&#39;. Despite their remarkable abilities, LLMs occasionally generate content that ranges from being overly simplistic to outright harmful [3]. The dual nature of LLMs, marked equally by their intelligence and their ignorance, prompts us to question what factors are causing this unpredictability.</p><p> Some researchers argue that the only problem is size and anticipate that scaling up LLMs will invariably lead to more robust intellectual abilities. However, it&#39;s also possible that there are inherent limitations that will persist regardless of their size. In this article, we will explore the idea that LLMs are limited by their inability to critique their own reasoning. But why is self-critique so important? We previously noted that the success of LLMs can be largely attributed to attention, which enables a flexible representation of prompts. However, the way LLMs then process this representation exhibits a degree of rigidity, as it is converted directly into a response without an opportunity for reflection.</p><p> We believe that this inflexibly produces fragile and unpredictable models, as it prevents them from self-correcting or re-exploring a problem with renewed insight. In developing flexible LLMs, models must not only be capable of reasoning but also possess the capacity to vet ( <strong>Paper 1</strong> ) and adapt ( <strong>Paper 2</strong> ) their thought processes. In this article, we consider two papers from Google-Deepmind that attempt to push LLMs beyond pure reason and incorporate self-critique.</p><p> <strong>Paper 1 — “LM vs LM: Detecting Factual Errors via Cross Examination&#39;&#39; [4]:</strong> The core idea of this paper is that when an LLM makes incorrect claims, they are likely to conflict with other statements the model produces. As such, they prompt an &#39;examiner LLM&#39; to interrogate the claims of an &#39;examinee LLM&#39; in order to discover inconsistencies. The examiner repeatedly questions the examinee until it deems that it has sufficient information to determine the factual accuracy of the examinee&#39;s claim. At this point, the examiner is prompted to render a verdict, categorising the claim as either correct or incorrect. Notably, the examiner and examinee LLM could be one and the same, essentially performing self-critique, albeit with distinct prompts that define their respective roles. An example of this interrogation is given below: </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hnhybBcpDsYeEWNAK/suqtu2bxzlwxko36w3fb" alt=""></p><p> Impressively, the performance of &#39;LM vs. LM&#39; was 17–20% better than the next best fact-checking baseline on challenging language tasks. But perhaps more importantly, &#39;LM vs. LM&#39; provides an initial demonstration of how self-critique can reduce the incoherence of LLMs. However, this method only critiques the products of reasoning and doesn&#39;t allow for an adaptation of the reasoning process itself. In contrast, the next paper produces improvements to LLM reasoning by evolving increasingly effective prompts.</p><p> <strong>Paper 2 — “PromptBreeder: Self-Referential Self-Improvement Via Prompt Evolution” [5]:</strong> Much like humans can gain clarity by reframing a problem, the performance of LLMs can be improved by tailoring their prompts to specific tasks. To clarify this concept, envision how an LLM&#39;s capacity to solve mathematical problems could be enhanced by instructing it to “emulate Stephen Hawking.” In contrast to this speculative, man-made example, Promptbreeder systematically and automatically evolves prompts tailored to a specific domain. In other words, it iteratively critiques and adapts the way that it frames a given class of problems.</p><p> Promptbreeder starts with a semi-random collection of prompts and progressively mutates them, retaining only the best, until it generates effective task-specific prompts. Leveraging the ability of transformers to rephrase ideas, an LLM was also used to mutate the task-prompts by using a mutation-prompt such as “Make a variant of this prompt.” Notably, to avoid diminishing returns, Promptbreeder doesn&#39;t solely improve task-prompts but also evolves better mutation-prompts, thereby enhancing its own prompt creation process. For those who are interested, a helpful diagram depicting this self-improvement process is located just after the conclusion. As a result of this highly self-referential search process, Promptbreeder was able to evolve detailed, effective prompts — the following example was produced to precede hate speech classification: </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hnhybBcpDsYeEWNAK/kmmnprspeepicqxzdndg" alt=""></p><p> <strong>Conclusion:</strong> Both of these papers (safely) fold some form of self-critique into LLMs, encouraging more deliberate reasoning. In doing so, they produce models that are more robust and reliable in their reasoning capacity. However, these papers are just two attempts amongst many [6,7,8,9] in this journey towards adaptable and introspective LLMs. There is considerable scope for future research, potentially drawing inspiration from fields such as Meta-RL [10], to facilitate a more general critique of pure reason in LLMs. </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hnhybBcpDsYeEWNAK/r9xlzazbkpnkm0hiryai" alt=""></p><p> [1] Bubeck, Sébastien, et al. “Sparks of artificial general intelligence: Early experiments with gpt-4.” arXiv:2303.12712 (2023).</p><p> [2] Vaswani, Ashish, et al. “Attention is all you need.” NeurIPS (2017).</p><p> [3] OpenAI. “GPT-4 Technical Report.” arXiv:2303.08774 (2023).</p><p> [4] Cohen, Roi, et al. “LM vs LM: Detecting Factual Errors via Cross Examination.” arXiv:2305.13281 (2023).</p><p> [5] Fernando, Chrisantha, et al. “Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution.” arXiv:2309.16797 (2023).</p><p> [6] Creswell, Antonia, Murray Shanahan, and Irina Higgins. “Selection-inference: Exploiting large language models for interpretable logical reasoning.” ICLR (2023).</p><p> [7] Dhuliawala, Shehzaad, et al. “Chain-of-Verification Reduces Hallucination in Large Language Models.” arXiv:2309.11495 (2023).</p><p> [8] Xue, Tianci, et al. “RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought.” arXiv:2305.11499 (2023).</p><p> [9] Bai, Yuntao, et al. “Constitutional ai: Harmlessness from ai feedback.” arXiv:2212.08073 (2022).</p><p> [10] Beck, Jacob, et al. “A survey of meta-reinforcement learning.” arXiv:2301.08028 (2023).</p><p> Acknowledgments: The title of this article was inspired by a Q and A session following a talk given by Dr. Beatrice Fazi at the Warwick CIM Conference 2023. The title is merely a play on words and the article, hopefully clearly, makes no attempt to discuss Kant&#39;s work.</p><br/><br/> <a href="https://www.lesswrong.com/posts/hnhybBcpDsYeEWNAK/llms-pure-reason-without-the-critique#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/hnhybBcpDsYeEWNAK/llms-pure-reason-without-the-critique<guid ispermalink="false"> hnhybBcpDsYeEWNAK</guid><dc:creator><![CDATA[Rosco-Hunter]]></dc:creator><pubDate> Wed, 11 Oct 2023 14:46:10 GMT</pubDate> </item><item><title><![CDATA[You’re Measuring Model Complexity Wrong]]></title><description><![CDATA[Published on October 11, 2023 11:46 AM GMT<br/><br/><p> <strong>TLDR</strong> : We explain why you should care about <i>model complexity</i> , why the <i>local learning coefficient</i> is arguably the correct measure of model complexity, and how to estimate its value.</p><p> In particular, we review <a href="https://arxiv.org/abs/2308.12108">a new set of estimation techniques introduced by Lau et al. (2023)</a> . These techniques are foundational to the <a href="https://www.lesswrong.com/posts/TjaeCWvLZtEDAS5Ex/towards-developmental-interpretability">Developmental Interpretability research agenda</a> and constitute the first generation of methods for detecting and understanding phase transitions, with potential applications for both interpretability and mechanistic anomaly detection. We expect this set of techniques to become a fixture in the alignment toolkit, and we&#39;ve published a <a href="https://github.com/timaeus-research/devinterp/">library</a> and <a href="https://github.com/timaeus-research/devinterp/tree/main/examples">examples</a> to help you get started.</p><blockquote><p> This post is based on the paper, <a href="https://arxiv.org/abs/2308.12108">&quot;Quantifying degeneracy in singular models via the learning coefficient&quot; by Edmund Lau, Daniel Murfet, and Susan Wei (2023).</a> The content builds on previous posts by <a href="https://www.lesswrong.com/users/liam-carroll?mention=user">@Liam Carroll</a> on <a href="https://www.lesswrong.com/posts/4eZtmwaqhAgdJQDEg/dslt-1-the-rlct-measures-the-effective-dimension-of-neural">effective dimensionality in neural networks</a> and <a href="https://www.lesswrong.com/posts/aKBAYN5LpaQMrPqMj/dslt-4-phase-transitions-in-neural-networks">the resulting perspective on phase transitions</a> .</p></blockquote><h1> Why Model Complexity?</h1><h2> Model Comparison</h2><p> <strong>Comparing models matters for safety.</strong> Given two models with the same behavior on a particular set of evals, we would like to be able to predict how they&#39;ll behave on out-of-distribution data. Can we distinguish the deceptively aligned model from the non-deceptively aligned model? As a first pass, can we predict that two models will or will not behave similarly in the future?</p><p> <strong>Comparing via weights.</strong> Because models are <i>singular</i> (parameters do not correspond one-to-one with functions), it&#39;s not possible to compare weights directly. Very different choices of weights can implement the same functions, and very similar choices of weights can implement qualitatively different functions.</p><p> <strong>Comparing via behavior.</strong> We also can&#39;t compare models at the level of the loss because different functions are compatible with the same loss. The same is true even if we compare models sample-by-sample: we&#39;d need an astronomical number of inputs to meaningfully constrain behavior (some of which we&#39;d rather not expose our model to).</p><p> <strong>Comparing via invariants.</strong> Another option is to take a pointer from the mathematicians and physicists: in classifying mathematical objects like spaces, it helps to turn geometric problems into algebraic problems where we can compute invariants. If two spaces have different values of that invariant, then we know that they&#39;re different. If the values are the same, the results are inconclusive.</p><p> <strong>The local learning coefficient</strong> . The quantity we&#39;ll look at in this post, the (local) learning coefficient <strong>&nbsp;</strong> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat\lambda(w^*)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>, is an invariant that measures model complexity — a coarse-grained feature of the model that is useful for making high-level comparisons with other models. Though having identical learning coefficients doesn&#39;t imply that two models are the same, having different learning coefficients tells us that two models are <i>qualitatively</i> different.</p><p> The learning coefficient is unique in that it is an output <i>of the theory</i> rather than an ad-hoc invention. Except for the loss itself, the learning coefficient is the <i>most principled</i> way to compare different models. </p><figure class="image image_resized" style="width:62.61%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/fpkr8br7exid3xa7umwk" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/dclnfi4g46j6youm1v9d 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/zu1mgpzt9mnf1xwodnaa 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/pxiji45ik0ashiaoted7 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/bfbdufet028gfomsw8ea 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/uw35st6vyyfqpjg5vlq1 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/jsmlhpxaafoaje50gon7 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/osdiajqlcrzsxan9etuo 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/cjljghg9w3sdphqqxheu 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/h1fevvcldfjwoeifefz6 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/bnbqvbqud9bunuzqppic 1028w"><figcaption> Figure 5 of <a href="https://arxiv.org/abs/2308.12108">Lau et al. (2023)</a> demonstrates that two different optimizers (SGD and entropy-SGD) find qualitatively different solutions on MNIST, where entropy-SGD finds simpler solutions.</figcaption></figure><h2> Model Development</h2><p> <strong>Model comparison is necessary to study model development.</strong> <a href="https://www.lesswrong.com/posts/TjaeCWvLZtEDAS5Ex/towards-developmental-interpretability">We&#39;re interested in comparing models across time to understand how they develop</a> . High-level observables like the local learning coefficient give us insight into this process without requiring a detailed understanding of the model&#39;s internal mechanisms.</p><p> In particular, we&#39;re aiming to understand phase transitions during learning — moments in which models go through sudden, unanticipated shifts. We want to be able to detect these transitions because we think most of the risk is contained in sudden, undesired changes to values or capabilities that occur during training (~sharp left turns) and sudden, undesired changes to behaviors that occur in-context (treacherous turns / mechanistic anomalies).</p><p> Local learning coefficient estimation is one of the first steps towards building tools for detecting and understanding these transitions.</p><p> <strong>Do phase transitions actually show up?</strong> So far, the places where theoretically predicted phase transitions are easiest to confirm are simplified settings like <a href="https://arxiv.org/pdf/1312.6120.pdf">deep linear networks</a> and <a href="https://transformer-circuits.pub/2022/toy_model/index.html">toy models of superposition</a> . For larger models, we expect phase transitions to be common but &quot;hidden.&quot; Among our <a href="https://www.lesswrong.com/posts/TjaeCWvLZtEDAS5Ex/towards-developmental-interpretability">immediate priorities</a> are testing just how common these transitions are and whether we can detect hidden transitions.</p><p> <strong>Deep linear networks.</strong> Let&#39;s consider the example of deep linear networks (DLNs). These are neural networks without nonlinear activations. In terms of expressivity, these models are identical to a simple affine transformation but in terms of dynamics they&#39;re much more interesting. The observed <a href="https://browse.arxiv.org/pdf/2106.15933.pdf">&quot;saddle-to-saddle&quot; transitions</a> involve sudden jumps in the loss that coincide with sudden increases in the learning coefficient. </p><figure class="image image_resized" style="width:60.53%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/iifllhshoi6wgobrly8a" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/nem1ocytx8zh2rt84jkj 132w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/ezqbdramtwmdqel47ska 212w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/edommwy10izruy4q7kx0 292w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/i2jdtlcfw7gvdsggpe11 372w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/dfgqvg4wvo9fntji5mr1 452w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/tmrfu0x2cmlb0i3westq 532w"><figcaption> <a href="https://github.com/timaeus-research/devinterp/blob/main/examples/dlns.ipynb">DLNs</a> show sudden increases in model complexity, <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span></span></span></span></span></span> ( <strong>orange</strong> ), coinciding with sudden decreases in loss ( <strong>blue</strong> ).</figcaption></figure><h1> From Basins to Model Complexity</h1><p> In this section, we&#39;ll motivate the learning coefficient by attempting to formalize a working definition of basin volume (through which we&#39;ll see that what we really care about is basin volume <i>scaling</i> ). We&#39;ll see in what sense the learning coefficient measures model complexity and examine the resulting perspective on phase transitions.</p><h2> Intractable: Basin Volume</h2><p> <strong>Basin volume and model simplicity.</strong> Learning theorists have long been interested in the link between basin volume and model simplicity. We don&#39;t really care what model we end up with as long as its loss is below some threshold <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span></span></span></span></span> . This is particularly true as that threshold approaches its minimum: we want to know how many &quot;almost-as-good&quot; solutions there are in the neighborhood of an obtained solution <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w^*"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span></span></span> .</p><p> Intuitively, broader basins (with more suitable models) are simpler. Because they take up more volume, they require fewer bits to locate. In accordance with Occam&#39;s razor, we want the simplest possible solution for the problem at hand <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label=""><span class="mjx-mrow" aria-hidden="true"></span></span></span></span></span> 。 <span class="footnote-reference" role="doc-noteref" id="fnref1s1fnajc57s"><sup><a href="#fn1s1fnajc57s">[1]</a></sup></span></p><p> <strong>To measure a basin.</strong> In particular, given an upper bound to the loss <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L(w) \le \epsilon"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.446em;">≤</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span></span></span></span></span> , we want to compute the following volume (=&quot;area&quot; in the case of two parameters):</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="V(\epsilon) = \int_{L(w)\le\epsilon}\varphi(w) \mathrm{d}w"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.388em;"><span class="mjx-mo" style="vertical-align: 0.001em; padding-right: 0.388em;"><span class="mjx-char MJXc-TeX-size2-R" style="padding-top: 1.109em; padding-bottom: 1.109em;">∫</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -1.303em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.446em;">≤</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span></span></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em;">φ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">d</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span><p> for some prior <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\varphi(w)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em;">φ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> over weights <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span> . For our purposes, we can safely neglect the prior and treat it as constant. Consider the toy loss landscape below, where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="V(\epsilon)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> is indicated by the gray projection. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/tssf1eqxtnlzflr6nm8i" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/baa1skcldj02s0qkkqk1 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/f4mlwkk4wrmq04rod0kp 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/vor3ytezkzzdpyydwoe2 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/ibqktl2miexwnm5qhcuz 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/zngyuvzaivae1uzbxq43 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/vhhllhzdh8zt6i7iik5m 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/woeev29jbbvsbivcfnbo 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/xoli20shvq3jfr3ykula 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/qzypegmefpvocukq4uun 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/hcdwscvkunlee7glvnur 1777w"><figcaption> A cartoon depiction of a loss landscape (modeled by a sum of random paraboloids).<br> This is <i>not</i> a good representation of real-world loss landscapes.</figcaption></figure><p> <strong>Model complexity and comparison.</strong> Every model in a given basin has the same basin volume. This metric is a coarse-grained observable (much like volume in thermodynamics) that partitions weight space into subclasses of similar models. So seeing that two models have similar volumes increases the odds that they&#39;re computationally similar. Conversely, having different volumes / complexities suggests that two models are qualitatively distinct.</p><p> Unfortunately, actually computing basin volume is intractable. This is because of the curse of dimensionality (the volume scales exponentially with dimensions) and because we can only ever approximate the &quot;true&quot; population loss <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L(w)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> through an empirical loss <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L_n(w)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> evaluated on a finite dataset <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="D_n=\{x_i\}_{i=1}^n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">D</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">{</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">}</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span></span></span></span> . </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/hlhofkxeinkmjutsqzek" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/eutlrj7zqvmowgqr4uk1 154w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/btffzuozhovfquwxkqgy 234w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/iwnniljh5djjibaxhpz6 314w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/yxg41sit2f2zkpw2kpfv 394w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/khsa9jjcbapvwblrlaz6 474w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/f34wuvhkbrgfa3te3g91 554w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/gwoggjchjqry3fb9cxrv 634w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/rjbtsvkkpgfzrv7krp7x 714w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/q6wdfwpsbps8wnz9yy7f 794w"><figcaption> If two models belong to basins with different volumes, they&#39;re likely to be qualitatively different kinds of models. Computing this is intractable.</figcaption></figure><h2> Wrong: Basin Flatness</h2><p> <strong>From broadness to flatness.</strong> The usual workaround to this intractability is to use a Taylor expansion: as long as we&#39;re close enough to the bottom of the basin, we can approximate the basin locally with a polynomial.</p><p> <a href="https://www.lesswrong.com/posts/QPqztHpToij2nx7ET/hessian-and-basin-volume">Most people stop at a second-order approximation</a> , modeling the basin as a paraboloid whose curvatures are given by the Hessian at the minimum. It&#39;s a simple matter of then computing the resulting surface volume. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/p05tmmzpw2qbsdz2kfk3" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/pqecavhvfdfkkfrkgkdf 154w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/xg3d1c6371airgbcbprx 234w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/chdo5fz8m3ls4qmo4dht 314w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/bg2z8rvxytqinm3kjkgj 394w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/wc4fiymxinf7rfxkrjqx 474w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/ld5xvbcotuvawlgmiglx 554w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/gpmj5qbmzhukodp5d9tf 634w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/fjtiynchugp8pzakmal1 714w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/cygcsfiq0athb9ikm5tn 794w"><figcaption> <strong>Left:</strong> the original basin along with the &quot;true&quot; volume. <strong>Right</strong> : a volume approximation using a paraboloid centered at the basin&#39;s minimum whose curvature is given by the Hessian.<br> This is an invalid approximation.</figcaption></figure><p> <strong>Unfortunately, this approximation is wrong</strong> . Minimum flatness is a terrible proxy for basin volume. The fundamental problem is that <a href="https://www.lesswrong.com/posts/fovfuFdpuEwQzJu2w/neural-networks-generalize-because-of-this-one-weird-trick">neural networks are <i>singular</i></a> : their loss landscapes have degenerate critical points. In practice, Hessians of the loss generally have many zero eigenvalues ( <a href="https://arxiv.org/abs/1611.07476">often a majority</a> ). When we attempt to approximate the volume with a paraboloid that has zero curvature, we naively predict unphysical infinite volumes. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/dj62o24stvt33awr8u7x" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/gffaeppastcqgewdcqy2 154w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/bh5t0xy7hrexmosel6lm 234w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/oreuegszqjbbe8hz1dec 314w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/vt8bsqvehqjv2ig82aqj 394w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/hghlyzsyhk6tv66ftqnz 474w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/cvsmdrgzhe8zpnvwlqlg 554w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/ydn95wnr2xgggoirzxfn 634w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/scf6io1iycp3bzvyaol7 714w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/ilt1ibulkchy0u5rwgjz 794w"><figcaption> When a model is singular, the loss landscape is qualitatively distinct from its second order Taylor approximation. This makes Hessian-based volumes invalid.</figcaption></figure><p> <a href="https://www.lesswrong.com/posts/QPqztHpToij2nx7ET/hessian-and-basin-volume?commentId=SbbDWXgQS8XBoJN2C">The standard correction is to add a small constant to these zero eigenvalues</a> , which stabilizes the Hessian. We get a very large volume, instead of an infinite volume. But this misses the point: when second order terms vanish, the qualitative equivalence between a function and its second-order Taylor approximation breaks down, and these Hessian-based approximations become invalid.</p><p> Instead, we need to go to higher order terms in the Taylor expansion. The lowest order contributions to the volume will be dominated by the highest order terms in the expansion.</p><p> <strong>Flatness ≠ broadness.</strong> In the literature, flatness (in the sense of a small determinant of the Hessian) and broadness often get conflated. This is unfortunate: the two are not the same. Basin broadness is an interesting question. Minimum flatness is the wrong question.</p><h2> Instead: Basin Dimension</h2><p> <strong>Volume dynamics.</strong> We care about relative — not absolute — volumes. But even more importantly, we&#39;re interested in <i>dynamics:</i> how the volume changes as learning progresses. As we gather more and more data, we&#39;re able to become more discriminating and our threshold <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span></span></span></span></span> comes down. The real question, then, is: how does the volume scale as <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span></span></span></span></span> changes? This is more relevant <i>even in the non-degenerate regular case.</i></p><p> <strong>Volume scaling >; volume.</strong> Studying volume scaling solves several others problems with the volume. First, for sufficiently small <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span></span></span></span></span> , relative volumes become independent of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span></span></span></span></span> , which allows us to eliminate the dependence on this arbitrary cut-off. Furthermore, volume scaling is invariant under reparametrizations and non-diverging even near degenerate critical points.</p><p> <strong>The learning coefficient as effective dimensionality.</strong> The volume scales as</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="V(\epsilon)\sim c\epsilon^\lambda\quad \text{as}\quad \epsilon \to 0."><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">∼</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span><span class="mjx-mspace" style="width: 1em; height: 0px;"></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">as</span></span><span class="mjx-mspace" style="width: 1em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.</span></span></span></span></span></span></span><p> The scaling exponent <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span> is known as the <strong>learning coefficient</strong> (or &quot; <a href="https://www.lesswrong.com/posts/4eZtmwaqhAgdJQDEg/dslt-1-the-rlct-measures-the-effective-dimension-of-neural">real log canonical threshold</a> &quot;). It plays the role of an effective dimensionality (up to a constant multiple).</p><p> Let&#39;s illustrate this with some examples.</p><p> <strong>Regular models.</strong> First, consider the<i> </i>case of <i>regular</i> (=non-singular) models, where the loss landscape has no degenerate critical points. In this case, the Hessian-based approximation holds, and the volume grows with exponent <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lambda=d/2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">/</span></span></span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span> , where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="d"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span> is the number of dimensions (or parameter count). </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/osog8ydbdkwogkug4le1" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/xduvdzuexmvhuf3rrmlj 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/nmbfoz30amvkjsbntcqi 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/d5vke1d4opnkh0pupbzm 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/ypkfpnxqiirfprbzchyd 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/ok0mauhzodbxngjlauxf 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/o8hwr3wqaacghepwpufx 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/o8o5o2ssc0jtwo0e1oma 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/bi95ywwhjklvwtrkhhiy 1280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/trzw7zkkgtbv4wcfjy3a 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/te6u0gewg3gcqn6irche 1570w"><figcaption> The area under the potential <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L(w_1, w_2) = w_1^2 + w_2^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span></span> scales as <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span></span></span></span></span> .</figcaption></figure><p> <strong>Singular models.</strong> Consider the function <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L(w_1, w_2) = w_1^4 + w_2^4"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span></span> . At the origin, the Hessian is equal to the zero matrix, and the learning coefficient is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lambda=1/2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">/</span></span></span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span> . </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/mcbsmiprhnwwe5fpdvp9" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/t8btcmoz0qz4fuvrmgmo 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/uio4w9qnuzf7xylgygxr 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/j5ecdulzk3bhnxj0umkj 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/tqembnfcvyaf4pbik95e 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/thqre57jahks2zveykz9 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/dshwjvthif9g6bxe0luh 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/w6sz88ad2pqxpjpck4xr 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/upsynf1c0biqgesyyj73 1280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/kspebdae2enakk8cbuv9 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/l3mqveycypeg34oaxyfx 1570w"><figcaption> The area under the potential <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L(w_1, w_2) = w_1^4 + w_2^4"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span></span> scales as <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon^{\frac{1}{2}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.73em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 0.583em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 83.3%; width: 0.7em; top: -1.288em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 83.3%; width: 0.7em; bottom: -0.688em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span><span style="border-bottom: 1px solid; top: -0.296em; width: 0.583em;" class="mjx-line"></span></span><span style="height: 1.647em; vertical-align: -0.573em;" class="mjx-vsize"></span></span></span></span></span></span></span></span></span></span></span> 。</figcaption></figure><p> Compare this to the function <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L(w_1, w_2) = w_1^2 w_2^4"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span></span> . Again the Hessian at the origin is the zero matrix, but the learning coefficient now takes a different value <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lambda=1/4"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">/</span></span></span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span></span></span></span></span> . </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/bhhwpnpmdvpqqzhevtas" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/kjvoqgldbydc7isfqaq9 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/az4fn8sibx3hycex3dly 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/vunhr10tr8rqnbizctdj 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/dh2fktxyqs4kbrz3ec8h 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/g17soprjmp0bbrxykuv1 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/wprof0aw2wom6cujqv5k 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/bagfo8suoeily8jr0bfj 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/spxgjrqsufon890t35ok 1280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/m01ston9mdb27j0niaqi 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/zsqnayqnjqplbwkqjvqv 1570w"><figcaption> The area under the potential <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L(w_1, w_2) = w_1^2 w_2^4"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span></span> scales as <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon^\frac{1}{4}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.739em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mfrac" style=""><span class="mjx-box MJXc-stacked" style="width: 0.583em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 83.3%; width: 0.7em; top: -1.288em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="font-size: 83.3%; width: 0.7em; bottom: -0.699em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span><span style="border-bottom: 1px solid; top: -0.296em; width: 0.583em;" class="mjx-line"></span></span><span style="height: 1.656em; vertical-align: -0.583em;" class="mjx-vsize"></span></span></span></span></span></span></span></span></span> 。 As we approach the bottom of this landscape, there&#39;s <i>much</i> more volume available than in the preceding examples.</figcaption></figure><p> For singular models, the parameter count sets an upper bound <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="2\lambda \le d"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.446em;">≤</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span> . Lower learning coefficient means the volume scales slower for for large <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon >1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">>;</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span> but <i>faster</i> for small <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon < 1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span> . There&#39;s exponentially more volume in the immediate vicinity of degenerate critical points than in the vicinity of non-degenerate critical points.</p><p> <strong>Against Hessians.</strong> The two preceding examples explicitly demonstrate the failures of the Hessian mentioned earlier. Their Hessians are identical at the origin, but their scaling behaviors are radically different. The Hessian is a poor judge of volume, and derived metrics like the rank of the Hessian are insufficient notions of model complexity. <span class="footnote-reference" role="doc-noteref" id="fnrefy3eyq6a3fpf"><sup><a href="#fny3eyq6a3fpf">[2]</a></sup></span></p><p> <strong>The learning coefficient as an inductive bias.</strong> The Occam&#39;s razor intuition that simpler models (with lower complexity) generalize better is formalized by <a href="http://watanabe-www.math.dis.titech.ac.jp/users/swatanab/ag-slt.html">Watanabe&#39;s free energy formula</a> ,</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="F_n \to n L_n(w^*) + \lambda \log n+O(\log\log n)\quad\text{as}\quad n\to\infty,"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.106em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span><span class="mjx-mspace" style="width: 1em; height: 0px;"></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">as</span></span><span class="mjx-mspace" style="width: 1em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">∞</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span></span></span></span><p> where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> is the number of training samples, <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L_n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span></span></span> is the loss (more precisely, the negative log likelihood) which depends on a dataset <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="D_n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">D</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span></span></span> of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> samples, and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w^*"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span></span></span> is an optimal choice of weights.</p><p> A full explanation and derivation of this formula is beyond the scope of this post (see <a href="https://www.lesswrong.com/posts/xRWsfGfvDAjRWXcnG/distilling-singular-learning-theory">Liam&#39;s excellent sequence</a> ), but the important bit is that we can construe the problem of Bayesian learning as a problem of trying to minimize this free energy, involving a tradeoff between <i>accuracy</i> (lower <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="nL_n(w^*)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> ) and <i>complexity</i> (lower <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lambda \log n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> ). Neural networks are intrinsically biased towards simpler solutions.</p><p> <strong>Intuition for phase transitions.</strong> Consider a toy landscape with two local minima at <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> with heights<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L(w_1) > L(w_2)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">>;</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> . Both minima have an associated learning coefficient that determines how the volume scales in its neighborhood. Suppose <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lambda(w_1)<\lambda(w_2)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> . Solution 1 is simpler but with higher loss, and solution 2 is more accurate but also more complex.</p><p> Coming back to the volume for a moment, what happens as we gradually lower the threshold <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span></span></span></span></span> ? </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/bucjcnsvdhyns1pncauf" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/khkdyaknqkmz3rdxqhjv 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/wiixxbot4vzclevj5kef 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/ybbqc7vvrrbfziq60aky 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/mtakj8pteamikrrw1nua 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/lp9ttt9jvljdhnfezcya 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/uqjzrhszwuw0ggqt1xpf 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/d0bgpy2l6jnnyf0nqugs 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/ds6dbodrqc4jgwwi3rhb 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/i73hicuccxecrzyhee7x 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/wyufmqyikqcufe8xq4ue 1182w"><figcaption> <strong>A</strong> <i><strong>cartoon</strong></i> <strong>analogy for thinking about the learning process.</strong> In this toy landscape, there are two &quot;phases&quot; depicted by the orange and green projections. The <strong>orange phase</strong> is <i>higher loss</i> and <i>more degenerate</i> . The <strong>green phase</strong> is <i>lower loss</i> and <i>less degenerate</i> . As learning continues ( <strong>left to right</strong> ), we become less tolerant of high-loss solutions: the sea recedes, and we suddenly jump from the majority of the volume being occupied by the orange phase to the entirety of the volume being occupied by the green phase. In Bayesian learning, learning is dominated by transitions that lower loss and increase complexity. The link with SGD is an open question.</figcaption></figure><p> What we&#39;re interested in is the fraction of the surface area (=the volume of weight space) that is taken up by different kinds of solutions. At first, this surface area, and thus the behavior of our models, is dominated by the more degenerate solution at <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> .</p><p> As we sample more data (<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \to \infty"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">∞</span></span></span></span></span></span></span> ) the sea starts to recede. When the sea level approaches the level of one of these highly degenerate, low-accuracy solutions, that solution suddenly and very rapidly loses a massive amount of surface area <i>precisely because it is so degenerate</i> . Shallow puddles vanish all at once.</p><p> The fraction of surface area taken up by successive, more complex solutions jumps just as suddenly and rapidly. There&#39;s a phase transition — a qualitative change in the kind and complexity of functions being learned.</p><p> The sea continues to sink. From where we&#39;re sitting — above the water — we can&#39;t see below the surface. We don&#39;t know where or when the next transition will take place. We hold our breaths...</p><h1> Estimating Learning Coefficients</h1><p> We&#39;ve seen what the learning coefficient is and how it measures the complexity of a model. But how can we go about practically estimating its value? In this section, we describe a set of techniques introduced by <a href="https://arxiv.org/abs/2308.12108">Lau et al. (2023)</a> .</p><h2> Deriving the Estimator</h2><p> <strong>From free energies to learning coefficients.</strong> The free energy formula we saw earlier,</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="F_n \to n L_n(w^*) + \lambda \log n+O(\log\log n)\quad\text{as}\quad n\to\infty,"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.106em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span><span class="mjx-mspace" style="width: 1em; height: 0px;"></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">as</span></span><span class="mjx-mspace" style="width: 1em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">∞</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span></span></span></span><p> offers a means of calculating the learning coefficient. We simply shuffle the terms around to obtain:</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\lambda \to \frac{F_n - nL_n(w^*)}{\log n} + O\left(\frac{\log\log n}{\log n}\right)."><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 6.149em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 6.149em; top: -1.59em;"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.106em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span> <span class="mjx-denominator" style="width: 6.149em; bottom: -0.99em;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 6.149em;" class="mjx-line"></span></span><span style="height: 2.58em; vertical-align: -0.99em;" class="mjx-vsize"></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 1.256em; padding-bottom: 1.256em;">(</span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 3.689em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 3.689em; top: -1.49em;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-denominator" style="width: 3.689em; bottom: -0.99em;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 3.689em;" class="mjx-line"></span></span><span style="height: 2.48em; vertical-align: -0.99em;" class="mjx-vsize"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 1.256em; padding-bottom: 1.256em;">)</span></span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span></span></span></span></span></span><p> <strong>WBIC</strong> . Unfortunately, performing the integral required to evaluate <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="F_n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.106em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span></span></span> is intractable. As an alternative, we can consider the Widely Applicable Bayesian Information Criterion (WBIC), which generalizes the Bayesian Information Criterion (BIC) to singular models,</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\begin{align}\mathrm{WBIC}&amp;:=\mathbb{E}_w^{\beta^*}\left[n L_n(w)\right]\\&amp;=\int nL_n(w)\,p^{\beta^*}(w|D_n)\,\mathrm dw,\end{align}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mtable" style="vertical-align: -1.664em; padding: 0px 0.167em;"><span class="mjx-table"><span class="mjx-mtr" style="height: 1.405em;"><span class="mjx-mtd" style="padding: 0px 0px 0px 0px; text-align: right; width: 2.819em;"><span class="mjx-mrow" style="margin-top: -0.02em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">W</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">B</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">I</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">C</span></span></span></span><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0px 0px 0px 0px; text-align: left; width: 11.926em;"><span class="mjx-mrow" style="margin-top: -0.02em;"><span class="mjx-mi"></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.372em;">: <span class="mjx-charbox MJXc-TeX-main-R" style="padding-bottom: 0.314em;">=</span></span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">E</span></span></span></span></span> <span class="mjx-stack" style="vertical-align: -0.247em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.278em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.007em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;">β</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.071em; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span> <span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span></span><span class="mjx-strut"></span></span></span></span> <span class="mjx-mtr" style="height: 2.422em;"><span class="mjx-mtd" style="padding: 0.15em 0px 0px 0px; text-align: right;"><span class="mjx-mrow" style="margin-top: 0.386em;"><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0.15em 0px 0px 0px; text-align: left;"><span class="mjx-mrow"><span class="mjx-mi"></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3" style="vertical-align: 0.001em; padding-right: 0.388em;"><span class="mjx-char MJXc-TeX-size2-R" style="padding-top: 1.109em; padding-bottom: 1.109em;">∫</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span><span class="mjx-mspace" style="width: 0.167em; height: 0px;"></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.007em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;">β</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.071em; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">D</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span><span class="mjx-mspace" style="width: 0.167em; height: 0px;"></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">d</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span><span class="mjx-strut"></span></span></span></span></span></span></span></span></span></span></span><p> where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p^{\beta^*}(w|D_n)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.007em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;">β</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.071em; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">D</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> is the <a href="http://arxiv.org/abs/1901.05353">tempered Bayesian posterior</a> ,</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="p^\beta(w|D_n) = \frac{p(D_n|w)^\beta \varphi(w)}{p^{\beta}(D_n)},"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;">β</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">D</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 6.351em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 6.351em; top: -1.694em;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">D</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;">β</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em;">φ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span> <span class="mjx-denominator" style="width: 6.351em; bottom: -1.12em;"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.409em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;">β</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">D</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 6.351em;" class="mjx-line"></span></span><span style="height: 2.815em; vertical-align: -1.12em;" class="mjx-vsize"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span></span></span></span><p> sampled at inverse temperature <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\beta^*=1 / \log n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.007em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;">β</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.084em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">/</span></span></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> <a href="https://www.jmlr.org/papers/volume14/watanabe13a/watanabe13a.pdf">(Watanabe, 2013)</a> . The two highest order terms in the expansion of the WBIC match that of the asymptotic expansion of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="F_n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.106em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span></span></span> , which means we can substitute this in for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="F_n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.106em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span></span></span> to estimate the learning coefficient:</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\hat\lambda=\frac{\mathbb{E}_w^{\beta^*}\left[n L_n(w)\right] - n L_n(w^*)}{\log n}."><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 10.472em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 10.472em; top: -1.796em;"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">E</span></span></span></span></span> <span class="mjx-stack" style="vertical-align: -0.247em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.278em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.007em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;">β</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.071em; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span> <span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span> <span class="mjx-denominator" style="width: 10.472em; bottom: -0.99em;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 10.472em;" class="mjx-line"></span></span><span style="height: 2.786em; vertical-align: -0.99em;" class="mjx-vsize"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span></span></span></span></span></span><p> <strong>Expectations to empirical averages.</strong> To use this estimator, we need to first estimate the expectation value <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb E^{\beta^*}_w[nL_n(w)]"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">E</span></span></span></span></span> <span class="mjx-stack" style="vertical-align: -0.247em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.278em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.007em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;">β</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.071em; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span></span></span></span></span></span> . We can do this by sampling a set of weights <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W^{\beta^*}=\{w_1, \dots, w_m|w_i\sim p^{\beta^*}(w|D_n)\}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.007em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;">β</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.071em; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">{</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">…</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">∼</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.007em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;">β</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.071em; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">D</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">}</span></span></span></span></span></span></span> and replacing the expectation value with an empirical average over the losses associated to those weights,</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\mathbb E^{\beta^*}_w[nL_n(w)] \approx \frac{1}{m}\sum_{i=1}^m nL_n(w_i)."><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">E</span></span></span></span></span> <span class="mjx-stack" style="vertical-align: -0.247em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.278em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.007em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;">β</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.071em; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">≈</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 1.078em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 1.078em; top: -1.368em;"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="width: 1.078em; bottom: -0.722em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.078em;" class="mjx-line"></span></span><span style="height: 2.089em; vertical-align: -0.722em;" class="mjx-vsize"></span></span> <span class="mjx-munderover MJXc-space1"><span class="mjx-itable"><span class="mjx-row"><span class="mjx-cell"><span class="mjx-stack"><span class="mjx-over" style="font-size: 70.7%; padding-bottom: 0.247em; padding-top: 0.141em; padding-left: 0.582em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span></span> <span class="mjx-op"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size2-R" style="padding-top: 0.74em; padding-bottom: 0.74em;">∑</span></span></span></span></span></span> <span class="mjx-row"><span class="mjx-under" style="font-size: 70.7%; padding-top: 0.236em; padding-bottom: 0.141em; padding-left: 0.21em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span></span></span></span></span></span><p> Unfortunately, sampling enough points to get a reasonable estimate of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb E^{\beta^*}_w[nL_n(w)]"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">E</span></span></span></span></span> <span class="mjx-stack" style="vertical-align: -0.247em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.278em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.007em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;">β</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.071em; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span></span></span></span></span></span> is still completely intractable for systems at scale. <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label=""><span class="mjx-mrow" aria-hidden="true"></span></span></span></span></span></p><h2> The Local Learning Coefficient</h2><p> <strong>From global to local.</strong> The problem becomes substantially more tractable if, instead of attempting to estimate the <i>global</i> learning coefficient, we estimate a <i>local</i> learning coefficient instead. We restrict our attention to a subset of weights and study how the volume scales in just that region. The scaling is dominated by the most complex local singularities.</p><p> As we saw in the aside on phase transitions, this <i>local</i> quantity is also more interesting from the perspective of dynamics. When actually training models, we don&#39;t care about the behaviors of all possible models, we care about the behavior of a specific model as it moves through the loss landscape. </p><figure class="image image_resized" style="width:55.31%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/jhcssdkvffd22wxnimzi" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/duowywnz4m3qoaazdwpq 156w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/z2lcfky8ldekyblun9rr 236w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/ymljxxn4hqkn4qv5o7p3 316w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/rdbbztsib2bpdlpl3k7n 396w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/acbvmv8ooe4p36ctdllb 476w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/wsuigkw8k4mzmevb5dv2 556w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/znigkpybvmgwsvkldvhn 636w"><figcaption> Volume scaling restricted to a subset of weights is dominated by the <i>local</i> learning coefficient.</figcaption></figure><p> <strong>The local learning coefficient.</strong> To estimate the local learning coefficient, Lau et al. (2023) replace the prior <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\varphi(w)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em;">φ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> with a <i>localizing prior</i> centered at the point <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat w^*"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.191em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.662em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span></span></span> whose learning coefficient we want to estimate:</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\varphi(w) \to \varphi(w-\hat w^*)."><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em;">φ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em;">φ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.191em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.662em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span></span></span></span></span></span><p> This ensures that samples drawn will remain &quot;close&quot; to the original point. Substituting this into the global <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span></span></span></span></span></span> estimator we saw earlier, we obtain the definition of the local learning coefficient,</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\hat\lambda(\hat w^*)=\frac{\mathbb{E}_{w|\hat w^*}^{\beta^*}\left[n L_n(w)\right] - n L_n(\hat w^*)}{\log n},"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.191em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.662em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 11.239em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 11.239em; top: -2.199em;"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">E</span></span></span></span></span> <span class="mjx-stack" style="vertical-align: -0.412em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.007em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;">β</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.071em; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.191em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.503em; padding-left: 0px; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span></span></span> <span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.191em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.662em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span> <span class="mjx-denominator" style="width: 11.239em; bottom: -0.99em;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 11.239em;" class="mjx-line"></span></span><span style="height: 3.19em; vertical-align: -0.99em;" class="mjx-vsize"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span></span></span></span><p> known colloquially as &quot; <strong>lambda-hat</strong> ,&quot; where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb E_{w|\hat w^*}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">E</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.328em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.191em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.503em; padding-left: 0px; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span></span></span></span></span></span></span> indicates the use of a localizing prior.</p><p> To estimate this expectation value, we compute an empirical average over the losses of a set of samples <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\{w_i\}_{i=1}^m"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">{</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">}</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span></span></span></span> , now drawn from the <i>localized posterior:</i></p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="p (w|D_n, \hat w^*) \propto p(D_n|w)\,\varphi(w-\hat w^*)."><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">D</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.191em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.662em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">∝</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">D</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span><span class="mjx-mspace" style="width: 0.167em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em;">φ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.191em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.662em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span></span></span></span></span></span><p> Given this empirical average, we plug it into the above formula for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span></span></span></span></span></span> (subtracting <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> times the loss at <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat w ^*"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.191em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.662em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span></span></span> and dividing by <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\log n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> ) to obtain an estimate for the local learning coefficient.</p><h2> Implementing the Estimator</h2><p> <strong>How to localize?</strong> The first practical question we run into when implementing the local learning coefficient estimator is how to localize. Lau et al. consider a Gaussian prior parametrized by a scale <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\gamma"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;">γ</span></span></span></span></span></span></span> . This is not the only possible choice, but it is perhaps the most straightforward choice: a gentle quadratic restoring force.</p><p> <strong>How to sample?</strong> To draw samples from the posterior <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p^{\beta^*}(w|D_n, \hat w^*, \gamma)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.007em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;">β</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.071em; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">D</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.191em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.662em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;">γ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> , the natural thought is to use MCMC techniques. Explaining why these work is beyond the scope of this piece and is well covered elsewhere, but what&#39;s important here is that standard MCMC methods run into the curse of dimensionality, which makes them unsuitable for larger models. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/b6ydymsdzxnrrri788ij" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/yrzc2vdmtssmtlzewslu 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/nn2zmy22ww0cbowojgja 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/ia7erahjwomtznk7qahc 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/t0iebiap68d3frzxa5w4 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/hmlawmbwjwx74cgocuaj 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/sdf2ulo6gs6oslfhn5io 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/jo1puzakqipah931nytm 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/qp43yvslxl5uizdkkvsa 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/pplzrww1ypjw3thzpasi 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/gcurf84fxitcjbmycey1 850w"><figcaption> <strong>Comparing MCMC and SGD on a toy landscape</strong> , <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L(w_1, w_2) = w_1^2w_2^4"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span></span> . MCMC-NUTS ( <strong>left</strong> ) approximates the local posterior well, but does not generalize well to higher dimensions. SGD ( <strong>right</strong> ) is not a sampling mechanism.</figcaption></figure><p> <strong>SGLD.</strong> To scale MCMC methods to higher dimensions, we need to incorporate information from gradients. This allows us to &quot;preselect&quot; low-loss, high-posterior regions of weight space. One of the simplest examples of such a technique is Stochastic Gradient Langevin Dynamics (SGLD), which is SGD with the addition of an explicit noise term <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\eta \sim N(0, \epsilon)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">η</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">∼</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> ( <a href="http://people.ee.duke.edu/~lcarin/398_icmlpaper.pdf">Welling &amp; Teh 2011</a> ). This allows random movement along low loss dimensions, while quickly pushing any step to a higher loss area back down. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/dxpbrbkinnmcehkmivah" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/igfwydfe0bebtwhjc0au 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/mxo5ifut4vpiulakgaxw 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/c4octm8oxeu5z4xow1bj 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/dlw6dd5eqy5kzry3yxfe 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/tdxtro2lijkwx4ornf4e 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/zwi8gii0prpcyxdhvvqq 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/siuurbnxbt9idrza4uxp 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/nnnd1ywqyjcnibv9mvbk 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/asheu8fmfydt9imnqymo 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6g8cAftfQufLmFDYT/tbpgn2rbadcjgwqroox5 850w"><figcaption> <strong>Comparing SGLD and SGNHT on a toy landscape,</strong> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="L(w_1, w_2) = w_1^2 w_2^4"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">L</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span></span> . SGLD and SGNHT both better explore the local posterior better than SGD, even when (as pictured here) sampling 10x fewer points than SGD.</figcaption></figure><p> <strong>SGNHT and beyond.</strong> Adding momentum &amp; friction would allow us to explore these ridges of the posterior more effectively. One such example is the Stochastic Gradient Nosé-Hoover Thermostat (SGNHT), which uses a thermostat for its friction term (<a href="https://proceedings.neurips.cc/paper/2014/file/21fe5b8ba755eeaece7a450849876228-Paper.pdf">Ding et al. 2014</a> ). Although clearly performing better in the toy potential above, it&#39;s still unclear how well this approach generalizes to higher dimensions as these samplers can be harder to get working than SGLD.</p><h2> Limitations</h2><p> <strong>Engineering limitations.</strong> The above estimators do not yet live up to their full theoretical potential. To give an example, <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat\lambda(w)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> depends on hyperparameters like the number of samples, the localizing strength <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\gamma"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;">γ</span></span></span></span></span></span></span> , the SGLD learning rate <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\epsilon"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">ϵ</span></span></span></span></span></span></span> , etc. The true coefficient <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lambda(w)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> is independent of these hyperparameters.</p><p> We care less about whether <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span></span></span></span></span></span> is an unbiased estimator of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span> and more about whether this estimator satisfies certain basic desiderata of model complexity. These include properties like ordinality: that <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lambda(w_1)\ge\lambda(w_2)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.446em;">≥</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> implies <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat\lambda(w_1)\ge\hat\lambda(w_2)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.446em;">≥</span></span> <span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> . Improving this estimator and confirming that it satisfies these desiderata is currently bottlenecked more on engineering than on theory.</p><p> <strong>Theoretical limitations</strong> . At the same time, this estimator sometimes exceeds its theoretical underpinnings, yielding sensible results despite violating certain technical assumptions. This means there&#39;s work to do for theorists in terms of finding assumptions to relax and studying, for example, how to extend the learning coefficient outside of non-minima. Currently, if not applied at a local minimum, the estimator can sometimes yield unphysical negative model complexities. <span class="footnote-reference" role="doc-noteref" id="fnrefp983co85zrc"><sup><a href="#fnp983co85zrc">[3]</a></sup></span></p><p> There are limiting assumptions underlying the learning coefficient and additional limiting assumptions underlying the <i>local</i> learning coefficient <i>.</i> Both require further attention.</p><p> <strong>Proceed with caution.</strong> The current techniques for estimating <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span></span></span></span></span></span> are finicky to get working and should be applied with care. This is a research tool, not a plug-and-play observable printing press. Expect annoying hyperparameter tuning, (un)correlated estimates, weirdly high <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span></span></span></span></span></span> &#39;s, negative <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span></span></span></span></span></span> &#39;s, infinite <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span></span></span></span></span></span> &#39;s, etc. This requires at least as much caution as MCMC in any other high-dimensional system: pay careful attention to diagnostics of chain health and vary hyperparameters to hunt for dependencies, systematic or otherwise.</p><h1> What&#39;s Next</h1><p> <strong>Improving estimates.</strong> An immediate priority is to confirm that <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span> match where it counts. Does it satisfy our desiderata? And can we calibrate <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\hat\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.041em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span></span></span></span></span></span> in settings where we can analytically derive <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">λ</span></span></span></span></span></span></span> ? There&#39;s work to do on the theoretical front and on the computational front in terms of exploring more scalable and more accurate ways to sample from the local posterior beyond SGLD.</p><p> <strong>More observables.</strong> SLT also tells us how to measure other quantities of interest, such as the singular fluctuation. We&#39;re also working on the second and third generations of techniques for studying transitions that extract vector and higher-order information about how models are changing.</p><p> <strong>Go forth and estimate!</strong> Although the current implementation is far from perfect, it should be good enough to start applying these techniques in practice. It&#39;s as easy as <a href="https://github.com/timaeus-research/devinterp/"><code>pip install devinterp</code></a> and <code>from devinterp.slt import estimate_learning_coeff</code> (or at least, it&#39;s easy up until that point). We recommend checking out <a href="https://github.com/timaeus-research/devinterp/blob/main/examples/introduction.ipynb">these example notebooks</a> for inspiration.</p><p> If you want to learn more about the learning coefficient, see <a href="https://www.lesswrong.com/posts/4eZtmwaqhAgdJQDEg/dslt-1-the-rlct-measures-the-effective-dimension-of-neural">this post</a> , <a href="https://www.youtube.com/watch?v=bFVGc2UKARc&amp;list=PL4vaU_gO_6LJ4isj5DESGg4OwfVEk98Y-&amp;index=5">this lecture</a> , or <a href="https://www.cambridge.org/core/books/algebraic-geometry-and-statistical-learning-theory/9C8FD1BDC817E2FC79117C7F41544A3A">this book</a> . For updates on developmental interpretability, join the <a href="https://devinterp.com/discord">discord</a> . Stay tuned for more updates soon!</p><blockquote><p> Thank you to <a href="https://www.lesswrong.com/users/daniel-murfet?mention=user">@Daniel Murfet</a> , <a href="https://www.lesswrong.com/users/edmund-lau?mention=user">@Edmund Lau</a> , <a href="https://www.lesswrong.com/users/alexander-gietelink-oldenziel?mention=user">@Alexander Gietelink Oldenziel</a> , and <a href="https://www.lesswrong.com/users/liam-carroll?mention=user">@Liam Carroll</a> for reviewing early drafts of this document. </p></blockquote><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn1s1fnajc57s"> <span class="footnote-back-link"><sup><strong><a href="#fnref1s1fnajc57s">^</a></strong></sup></span><div class="footnote-content"><p> Actually extending the minimum description length principle (&#39;choose the model that takes the fewest bits to specify&#39;) to singular models is an open problem. The free energy formula (covered later) is not quite the same, though it fulfills the same purpose of formalizing Occam&#39;s razor.</p></div></li><li class="footnote-item" role="doc-endnote" id="fny3eyq6a3fpf"> <span class="footnote-back-link"><sup><strong><a href="#fnrefy3eyq6a3fpf">^</a></strong></sup></span><div class="footnote-content"><p> To give the Hessian some credit: its rank can give an us upper bound on the model complexity. The Hessian still has its place.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnp983co85zrc"> <span class="footnote-back-link"><sup><strong><a href="#fnrefp983co85zrc">^</a></strong></sup></span><div class="footnote-content"><p> This occurs when the sampler strays beyond its intended confines and stumbles across models with much lower loss than those in the desired neighborhood.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/6g8cAftfQufLmFDYT/you-re-measuring-model-complexity-wrong#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/6g8cAftfQufLmFDYT/you-re-measuring-model-complexity-wrong<guid ispermalink="false"> 6g8cAftfQufLmFDYT</guid><dc:creator><![CDATA[Jesse Hoogland]]></dc:creator><pubDate> Wed, 11 Oct 2023 11:46:12 GMT</pubDate> </item><item><title><![CDATA[Update on the UK AI Taskforce & AI Safety Summit]]></title><description><![CDATA[Published on October 11, 2023 11:37 AM GMT<br/><br/><p> <i>While preparing for an upcoming Convergence Analysis post on the UK AI Taskforce and our recommendations, I looked into their reports, their plans for the upcoming AI safety summit, the recommendations from other orgs, and some miscellaneous UK AI events. I doubt we&#39;ll include this in our post but I thought the updates were</i> <a href="https://forum.effectivealtruism.org/posts/6trt8mTsKfqJJbfJa/suggestion-eas-should-post-more-summaries-and-collections"><i><u>worth sharing</u></i></a> <i>, so here is a brief summary.</i></p><h1> The UK AI taskforce</h1><p> In April 2023, the UK government <a href="https://www.gov.uk/government/news/initial-100-million-for-expert-taskforce-to-help-uk-build-and-adopt-next-generation-of-safe-ai"><u>committed £100 million</u></a> to its new <a href="https://www.gov.uk/government/news/tech-entrepreneur-ian-hogarth-to-lead-uks-ai-foundation-model-taskforce"><u>AI Foundation Models Taskforce</u></a> , led by Ian Hogarth. The taskforce was created in response to a white paper titled <a href="https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper"><u>A pro-innovation approach to AI regulation</u></a> in March, and was modeled on the <a href="https://en.wikipedia.org/wiki/Vaccine_Taskforce%60"><u>2020 Vaccine Taskforce</u></a> , with similar “ <i>agility and delegated authority</i> ”.</p><p> The taskforce announced an <a href="https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence"><u>AI Safety Summit</u></a> on the 1st and 2nd of November at Bletchley Park, and put out a call for <a href="https://docs.google.com/forms/d/e/1FAIpQLSeOV3FPChEstFy7CcuHc6af1Jv50H0jfxi7dkieyj5gHabsiw/viewform"><u>expressions of interest</u></a> , looking for:</p><blockquote><p> <i>people with diverse skills and backgrounds to work in or with the Taskforce, to catalytically advance AI safety this year with a global impact. We&#39;re particularly interested in building out &quot;safety infrastructure&quot; and developing risk assessments that can inform policymakers and spur global coordination on AI safety.</i></p></blockquote><p> In September, the taskforce released their <a href="https://www.gov.uk/government/publications/frontier-ai-taskforce-first-progress-report/frontier-ai-taskforce-first-progress-report"><u>first report</u></a> . In summary:</p><ul><li> Their expert advisory board consists of Yoshua Bengio, Paul Christiano, Matt Collins, Anne Keast-Butler, Alex van Someren, Helen Stokes-Lampard, and Matt Clifford.</li><li> Initially, their lone but influential AI researcher was <a href="https://www.nitarshan.com/"><u>Nitarshan Rajkumar</u></a> , but now they&#39;re hiring technical AI experts including <a href="https://www.cs.ox.ac.uk/people/yarin.gal/website/"><u>Yarin Gal</u></a> , head of Oxford Applied &amp; Theoretical ML Group, and <a href="https://www.davidscottkrueger.com/"><u>David Krueger</u></a> , leader of a Cambridge Deep Learning &amp; AI Alignment group. They plan to scale up their team by an order of magnitude and encourage <a href="https://docs.google.com/forms/d/1HKVnrV_rBHF3w4StWUs0XNhxTtKkTHs5CpMnH6PM0pQ/viewform?edit_requested=true"><u>applications</u></a> .</li><li> The taskforce is partnering with several organizations:<ul><li> <a href="https://evals.alignment.org/"><u>ARC Evals</u></a> , a non-profit focused on AI evaluations. The report emphasizes a close collaboration with ARC Evals in the leadup to the <a href="https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence"><u>summit</u></a> , along with <a href="https://www.redwoodresearch.org/"><u>Redwood Research</u></a> and <a href="https://www.rand.org/about.html"><u>RAND</u></a> .</li><li> <a href="https://www.trailofbits.com/about/"><u>Trail of Bits</u></a> , a cybersecurity consultancy. Their collaboration will be led by Heidy Khlaaf and will focus on cybersecurity around frontier AI systems.</li><li> <a href="https://cip.org/"><u>The Collective Intelligence Project</u></a> , a non-profit governance tech incubator.</li><li> <a href="https://www.safe.ai/"><u>Center for AI Safety</u></a> , an AI safety non-profit focused on research, field-building, and advocacy.</li></ul></li><li> They&#39;ve brought in <a href="https://www.instituteforgovernment.org.uk/person/oliver-ilott"><u>Ollie Ilott</u></a> as director of the taskforce, who previously led the Prime Minister&#39;s domestic private office. As far as I can tell, he&#39;s new to the topic of AI.</li></ul><h1> The UK AI safety summit</h1><p> The taskforce have released some <a href="https://assets.publishing.service.gov.uk/media/65107cedbf7c1a000dbb462e/introduction_to_the_ai_safety_summit.pdf"><u>more details on the upcoming summit</u></a> . In summary:</p><ul><li> The summit will focus on frontier AI, which they define as &quot; <i>highly capable general-purpose AI models that can perform a wide variety of tasks and match or exceed the capabilities present in today&#39;s most advanced models</i> &quot;, though they&#39;ll also consider “ <i>specific narrow AI which can hold potentially dangerous capabilities</i> ”. They include this graphic:<br> <a href="https://assets.publishing.service.gov.uk/media/65107cedbf7c1a000dbb462e/introduction_to_the_ai_safety_summit.pdf"><u><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5fdcsWwtvG9jAtzGK/sdry2dvgubwmz7wkvohz"></u></a></li><li> They mention doing scenario research to &quot; <i>identify where the frontier of AI development currently is and where it may advance to</i> &quot;.</li><li> They&#39;re focused on &quot; <i>misuse risks</i> &quot; and &quot; <i>loss of control risks</i> &quot;, though they add &quot; <i>This is not to minimize the wider societal risks that AI - at the frontier and not - can have, including misinformation, bias and discrimination and the potential for mass automation</i> &quot;.</li><li> There&#39;s no mention of existential risk. The <a href="https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper"><u>original white paper</u></a> only mentions X-risk once, when arguing for coherence between risk assessors so as not to ignore “ <i>&#39;high impact but low probability&#39; risks such as existential risks posed by artificial general intelligence or AI biosecurity risks.</i> ”</li></ul><p> There are some official pre-summit events, details about which will apparently be published on <a href="https://x.com/SciTechgovuk?s=20"><u>@SciTechgovuk</u></a> and other social media channels:</p><ul><li> October 11th at The Alan Turing Institute: <i>Exploring existing UK strengths on AI safety and opportunities for international collaboration</i> .</li><li> October 12th at the British Academy: <i>Possibilities of AI for the public good: the Summit and beyond</i> .</li><li> October 17th at techUK: <i>Opportunities from AI; Potential risks from AI; Solutions that exist in the tech sector</i> .</li><li> October 25th at the Royal Society: <i>Horizon scanning AI safety risks across scientific disciplines.</i></li></ul><p> And two upcoming opportunities for public engagement:</p><ul><li> October 18th: LinkedIn Q&amp;A with Secretary of State Michelle Donelan .</li><li> November 1st: Watch keynote speeches on the Summit livestream.</li></ul><h1> Misc.</h1><p> Several organizations have published recommendations for the taskforce and for the summit, such as:</p><ul><li> Conjecture&#39;s <a href="https://www.conjecture.dev/uk-taskforce-priorities/"><u>Priorities for the UK Foundation Models Taskforce</u></a> , written by Andrea Miotti.</li><li> The Future of Life&#39;s <a href="https://futureoflife.org/wp-content/uploads/2023/09/FLI_AI_Summit_Recommendations.pdf"><u>FLI recommendations for the UK Global AI Safety Summit</u></a> .</li><li> Apollo&#39;s <a href="https://www.apolloresearch.ai/blog/the-uks-ai-safety-summit-our-recommendations"><u>The UK AI Safety Summit - our recommendations</u></a> .</li><li> Jack Clark&#39;s <a href="https://jack-clark.net/2023/07/05/what-should-the-uks-100-million-foundation-model-taskforce-do/"><u>What should the UK&#39;s £100 million Foundation Model Taskforce do?</u></a></li></ul><p> Some news articles (eg <a href="https://www.theguardian.com/technology/2023/oct/10/downing-street-trying-to-agree-statement-about-ai-risks-with-world-leaders">here</a> , <a href="https://www.artificialintelligence-news.com/2023/10/10/uk-races-agree-statement-ai-risks-global-leaders/">here</a> ) claim that the government is rushing to finalize an agreement among world leaders before the summit in November.</p><p> There&#39;s also the <a href="https://aifringe.org/"><u>AI Fringe</u></a> , a series of events on safe and responsible AI across the UK from October 30th till November 3rd, separate but complementary to the government&#39;s summit. Their events “ <i>will feature a series of keynotes, fireside chats, panels, roundtables and workshops to expand the conversation on AI.</i> ”</p><h1> Public perception of existential risk</h1><p> I&#39;ll finish with some personal thoughts on existential risk. In my opinion, it&#39;s a shame that the taskforce, their summit, and the AI Fringe do not address existential risk. There are brief <a href="https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper#:~:text=existential%20risks%20posed%20by%20artificial%20general%20intelligence%20or%20AI%20biosecurity%20risks"><u>mentions of AI biosecurity risks</u></a> and <a href="https://www.politico.eu/article/uk-pitch-ai-safety-institute-rishi-sunak/#:~:text=create%20bioweapons%20and%20launch%20cyberattacks%2C%20as%20well%20as%20address%20risks%20of%20humanity%20losing%20control%20of%20the%20tech"><u>hints</u></a> that the summit may include discussion about “losing control” of AI, but I feel the topic is still largely neglected in their report and summit plans (and at the AI Fringe, even though they found time for a session on <a href="https://aifringe.org/events/the-challenges-of-extra-terrestrial-living"><u>moon base psychophysics with lunar-themed entertainment</u></a> ).</p><p> It makes sense to me that they are focused on short and medium-term risks, but I would like to see investment in mitigating longer-term, larger-scale risks. I also suspect (though I won&#39;t try to provide evidence here) that a good chunk of the public see existential risk from AI as a fringe idea <span class="footnote-reference" role="doc-noteref" id="fnref6bh6onku9x2"><sup><a href="#fn6bh6onku9x2">[1]</a></sup></span> , and I think that experts and the government should combat that by publicly recognizing and addressing existential risks. Indeed, despite the limited mention of existential risk, some think the UK is <i>too</i> focused on it: in <a href="https://www.oii.ox.ac.uk/news-events/news/dr-keegan-mcbride-why-the-uk-ai-safety-summit-will-fail-to-be-meaningful/"><u>Why the UK AI Safety Summit will fail to be meaningful</u></a> , Dr Keegan McBride, research lecturer at the Oxford Internet Institute, writes that the “ <i>summit and the UK&#39;s current AI strategy is primarily concerned with existential risks”</i> even though “ <i>the idea that AI will bring about the end of the world in the near future is not grounded in reality”</i> . Politico also published <a href="https://www.politico.eu/article/rishi-sunak-artificial-intelligence-pivot-safety-summit-united-kingdom-silicon-valley-effective-altruism"><u>How Silicon Valley doomers are shaping Rishi Sunak&#39;s AI plans</u></a> , which, like Dr McBridge, describes how effective altruists are pushing the UK&#39;s policy in the wrong direction:</p><blockquote><p> <i>Effective altruists claim that super-intelligent AI could one day destroy humanity, and advocate policy that&#39;s focused on the distant future rather than the here-and-now. Despite the potential risks, EAs broadly believe super-intelligent AI should be pursued at all costs.</i></p></blockquote><p> I strongly disagree with both these articles, and I&#39;m interested in how people think we can improve public perception of EA and advocacy for existential safety work, as well as how people feel about the UK&#39;s AI safety efforts more broadly. Do you think the UK&#39;s response is promising or lackluster? Should they focus on existential risk, or will that follow from short and medium-term risk reduction? In what direction should we try to steer the taskforce? </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn6bh6onku9x2"> <span class="footnote-back-link"><sup><strong><a href="#fnref6bh6onku9x2">^</a></strong></sup></span><div class="footnote-content"><p> I&#39;ll note that my colleague, <a href="https://www.lesswrong.com/users/justin-bullock">Dr Justin Bullock</a> , has written an article on public perception of AI risk and safety which will be published this autumn in <a href="https://humanistperspectives.org/">Humanist Perspectives</a> . He argues that the recent AIPI and AIMS survey data shows that the public do recognise the existential risk from AI, and when his post goes live, I&#39;ll link to it here.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/5fdcsWwtvG9jAtzGK/update-on-the-uk-ai-taskforce-and-ai-safety-summit#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/5fdcsWwtvG9jAtzGK/update-on-the-uk-ai-taskforce-and-ai-safety-summit<guid ispermalink="false"> 5fdcsWwtvG9jAtzGK</guid><dc:creator><![CDATA[Elliot_Mckernon]]></dc:creator><pubDate> Wed, 11 Oct 2023 11:37:42 GMT</pubDate> </item><item><title><![CDATA[Shard Therapy, preambe]]></title><description><![CDATA[Published on October 11, 2023 5:03 AM GMT<br/><br/><p> In the <a href="https://www.lesswrong.com/posts/MMygRZyMJweamcrJc/the-human-decision-making-algorithm-s">last post</a> we talked about natural selection&#39;s two main ways of approximating utility functions in humans: Fixed stimulus reactions, and reinforcement learning. In this post I want to hone in on reinforcement learning, and specifically a structure that tends to proliferate in any system that runs it: The shard structure</p><p> To get everyone up to speed, let&#39;s start with <a href="https://www.lesswrong.com/posts/xqkGmfikqapbJ2YMj/shard-theory-an-overview"><u>shard theory</u></a> as I understand it. According to me, shards are high-level structures in neural networks (eg brains) which tend to take shape anytime the network rewards or punishes itself. During the reinforcement stage, the network distributes positivity or negativity over everything it currently considers potentially causal to the reinforcement event; the neural chains that represent these causes then wire together, forming a larger circuit called a shard. In the future, when part of this shard activates, such as the part representing the object the agent interacted with, the rest of the shard is more likely to activate too, such as the part representing the action the agent actually took.</p><p> (These action recommendations are then sent into a decision-making arena, wherein they&#39;re weighted against other active recommendations according to how strongly each shard was activated and how much reinforcement each shard has garnered over time. The winning action recommendations are then sent to *another* part of the neural net, which translates these recommendations into actual actions <span class="footnote-reference" role="doc-noteref" id="fnrefuwfjht0cf7"><sup><a href="#fnuwfjht0cf7">[1]</a></sup></span> .)</p><p> By way of some jargon, we could summarize shards as having three components:</p><ol><li> Activation criteria,</li><li> Decision-making weights, and</li><li> Shape-of-recommended-actions (soras).</li></ol><p> Now, as we touched on at the end of the last post, the act of getting an agent with shards (ie, an RL agent) to enact your values is very different from getting an agent with a utility function to enact your values. With a utility function, so long as you&#39;re able to specify your values mathematically, any agent you build will pursue those values unfalteringly, to the best of its ability. With an RL agent, though, you <i>don&#39;t</i> need an mathematically specified values to start training the agent; however, there&#39;s also a risk of the agent *mislearning* your values in the training process. This is because, even if an agent takes an action that superficially seems conducive to your goals, the agent may not have been internally representing that action at the same level of abstraction that you were, so if you reinforce that action, you may actually be reinforcing a behavior/policy that would produce bad results under different circumstances.</p><p> To give a concrete example of that kind of misalignment, consider how human beings learn behavior that doesn&#39;t strictly help them spawn as many copies of themselves as possible. Natural selection tried to encourage us to pursue this goal by giving us reward mechanisms that go off in situations seemingly conducive to reproducing, such as eating food to survive; however, because humans generally think of that action as <i>eating food</i> , rather than <i>maximizing the odds of procreation</i> , eating food for its own sake is the behavior that gets reinforced. This causes humans to take reproductively useless actions, such as eating a snack purely for the flavor, which in some cases actively backfires; in the modern world, some humans overeat, making them less sexually attractive by conventional standards.</p><p> (It&#39;s cute to think of this as an instance of an RL agent&#39;s alignment failing to generalize beyond the training distribution, with the training distribution being the ancestral environment.)</p><p> So, that&#39;s the way in which the RL partition of humans doesn&#39;t resemble a utility function, let alone a utility maximizer aligned with natural selection. However, sometimes humans develop *individual shards* which recommend maximizer-like action anyway. For instance, some humans have shards that recommend obtaining as much pleasure as possible.</p><p> How might such a sahrd take shape? Let&#39;s consider the case of a teenage girl who&#39;s openly depressed, to the point of annoying all her friends. If we assume she&#39;s got a strong &quot;don&#39;t annoy all your friends&quot; shard, she might end up running a search for ways of making herself feel better, <i>in full generality</i> . Assuming this works, part of the behavior that gets reinforced will be, &quot;Do things that you imagine your friends will approve of&quot;; however, another part will be, &quot;Do things to make yourself feel better, <i>in full generality</i> &quot;. This creates a shard with an effective hedon maximization sora, which activates weakly in contexts like “I&#39;m depressed” or even “I&#39;m discontent”, and strongly in contexts like &quot;my depression is bothering my friends&quot;.</p><p> (Side note: I think that these kinds of scenarios, where being in a good mood is pro-social, are lots of where our hedon maximizer-like soras come from in the first place. This would explain why people treat discussions of one&#39;s own personal quest for happiness as less of a faux pas than many other social signals of self-interest.)</p><p> Now, it&#39;s important to be clear that hedon maximizer shard aren&#39; *morally worth* pursuing, nor is any maximizer shard, nor is any shard period. All sets of values are equally valid in the eyes of the universe; indeed, this is why it&#39;s so hard to argue with Bryan Caplan-style takes like &quot;Staying depressed is the revealed preference of depressed people; therefore, mental health isn&#39;t actually a worthy cause.&quot; <span class="footnote-reference" role="doc-noteref" id="fnref3uum79lmvij"><sup><a href="#fn3uum79lmvij">[2]</a></sup></span></p><p> Nevertheless, <i>I</i> have shards which care about <i>your</i> mental health, and beyond that I don&#39;t have a strong aversion to modifying the values of others. Therefore, in the next post, I&#39;ll be talking about <i>shard therapy</i> , or how one can use the insights of shard theory to consciously modify an agent&#39;s optimization target to better suit a different aim. </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnuwfjht0cf7"> <span class="footnote-back-link"><sup><strong><a href="#fnrefuwfjht0cf7">^</a></strong></sup></span><div class="footnote-content"><p> Plausibly one of the more important differences between humans and LLMs is that in humans these actions or &quot;outputs&quot; can be either muscular or mental motions, including commands to further rack one&#39;s brain for a solution to a problem. Meanwhile, in (the base models of) LLMs, outputs are just next-word predictions; because they lack a first-order cognitive search output, LLMs lack an obvious System 2. In some sense, <a href="https://generative.ink/posts/loom-interface-to-the-multiverse/"><u>looming</u></a> is the art of manually bestowing an LLM with a System 2.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn3uum79lmvij"> <span class="footnote-back-link"><sup><strong><a href="#fnref3uum79lmvij">^</a></strong></sup></span><div class="footnote-content"><p> This is also related to why people tend to oppose wireheading: Most of your shards don&#39;t recommend pleasure-seeking as such, and some of them actively recommend against the pleasure machine in particular. (&quot;Don&#39;t interact with sufficiently novel and surprising technologies&quot;, &quot;Don&#39;t say goodbye to all your friends forever”, and so on.)</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/QyGeCxEjv8KMzrejc/shard-therapy-preambe#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/QyGeCxEjv8KMzrejc/shard-therapy-preambe<guid ispermalink="false"> QyGeCxEjv8KMzrejc</guid><dc:creator><![CDATA[Iris of Rosebloom]]></dc:creator><pubDate> Wed, 11 Oct 2023 05:03:06 GMT</pubDate> </item><item><title><![CDATA[The Human Decision Making Algorithm(s)]]></title><description><![CDATA[Published on October 11, 2023 4:59 AM GMT<br/><br/><p> <i>Epitsemic status: Despite the didactic tone, these are only hypotheses.</i></p><p> A naive model of human decision making would claim that by default, we try to calculate which course of action we&#39;ll find most rewarding by a given standard, and then pursue it; on this model, any failures to take some goal-optimal course of action are failures of rationality, the product of biases like hyperbolic discounting interfering with our naturally optimizer-like decision making.</p><p> It&#39;s tempting to think this way. One reason for believing it is that it&#39;s basically the most intuitive way you could design a goal-directed system; for example, given the premise that natural selection was trying to build a system which spawned as many copies of itself as possible, then ideally what it <i>would</i> have done is give us an explicit utility function that said &quot;reproduction good&quot;, as well as algorithms for looking at reality, figuring out the best plan for achieving that goal, and then executing on it, no questions asked.</p><p> In reality, though, not only do real humans *not* have this utility-based set of algorithms, they don&#39;t even have a stripped-down version of it; they operate on a totally different architecture, because evolution lacked either <a href="https://www.lesswrong.com/s/MH2b8NfWv22dBtrs8/p/jAToJHtg39AMTAuJo"><u>the optimization power</u></a> or the resources to reasonably approximate it. Instead, evolution built humans using two clever hacks that get similar results by very different means: Fixed stimulus responses, and reinforcement learning.</p><p> Reinforcement learning is when an agent responds to a pre-determined stimulus by putting positive or negative reinforcement on neural circuits representing what the agent considers possible causes of the reinforcement event. A fixed stimulus response (FSR) is when an agent responds to a pre-determined stimulus with a pre-determined action.</p><p> To start with examples of FRS: Human beings have these things called reflexes, where, if they do something like put their hand on an overly hot surface it human will retract its hand after a very low amount of computation. Other examples, higher up the chain of abstraction, include instincts and emotional responses. For example, a human will want to act amicably towards anything that comes off as both attractive and sexually inviting. For another example, a human will feel tempted to take aggressive action after encountering a frustraing situation.</p><p> There are basically two reasons an optimization process might build an agent that uses fixed stimulus responses: Either its resources/intelligence are too limited for a more general-purpose decision-making algorithm, such as a utility function or reinforcement learning; or, it <i>is</i> running reinforcement learning, but it considers a given stimulus <i>so</i> important to react to in a given behavior way that it doesn&#39;t want the agent to have to learn that reaction from experience, such as steering clear of activities that pose a major risk of death. (This is the reason natural selection invented fear).</p><p> However, there&#39;s one aspect in which FSRs are much worse at optimizing  towards natural selection&#39;s distinctive telos compared to, say, a utility maximizer: Namely, life will encounter a <i>vast</i> array of situations as it expands across the cosmos, and having to manually <i>evolve</i> an optimal response to each and every one of those scenarios would be <i>slow</i> ; at some point, it&#39;s more efficient to have an organism manually puzzle out those solutions over the course of its own lifetime, rather than come to know them automatically over hundreds of generations. So, given that evolution wanted to build a more general-purpose intelligence, but still couldn&#39;t find a way to make utility functions work, it instead went with the next best general-purpose optimization algorithm anyone currently knows about: Reinforcement learning.</p><p> As said before, reinforcement learning is basically when you respond to a given stimulus not with a fixed output, but rather by giving positive or negative feedback to <i>any</i> actions (or other stimuli) you&#39;re presently thinking of as potentially causal to the reinforcement event. Basically, the idea is to giving your agent reinforcement mechanisms which go off in situations that correlate with achieving you-the-optimization-process&#39;s end-goal.</p><p> So, in humans, who natural selection designed to produce offspring, we were given reward mechanisms that go off in situations that are supposed to be conducive to that goal: Eating food so as to stay alive, having sex so as to bear children, successfully predicting one&#39;s own sensory experience so as to form an accurate world-model that may contribute to exploitable insights about the environment. Separately from *emotions* or *instinctive drives*, which sometimes but not always <i>also</i> go off in these kinds of situations, reinforcement events cause humans to feel <i>pleasure</i> or <i>pain</i> , the sensations of learning to take or not to take a given class of action in the future; in theory, natural selection would smile or frown upon those classes of action, respectively.</p><p> Of course, in practice we know humans are signifigantly misaligned from this goal. The classic example is that because we humans often enjoy sex, but don&#39;t enjoy lots of the inconvenience that comes with raising a kid, we invented contraceptives, and thereby were able to reinforce ourselves on pregnancy-free fornication. This has contributed to humanity&#39;s falling birth rates, which is a clear failure to contribute to natural selection&#39;s optimization target of procreationmaxxing. The details of how this kind of misalignment happens in general are interesting in their own right, so that&#39;s part of what I&#39;ll touch on in the next post, Shard Therapy.</p><p> --</p><p> Postscript:</p><p> Uh, I forgot to resolve the logical thread from the start of this post; my claim is that humans don&#39;t run on paired down utility maximizers, they run on FSRs and reinforcement learning. This means that frameworks that treat humans as naturally tending to construct and pursue long-term goals, but simply sucking at this, are failures to carve reality at the joints. Concepts like akrasia and hyperbolic discounting are more or less obsolete, because humans don&#39;t pursue reward or avoid pain as-such in the first place; they either repeat or avoid actions which have <i>historically</i> led to positive or negative reinforcement, or simply carry out fixed stimulus responses.</p><br/><br/> <a href="https://www.lesswrong.com/posts/MMygRZyMJweamcrJc/the-human-decision-making-algorithm-s#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/MMygRZyMJweamcrJc/the-human-decision-making-algorithm-s<guid ispermalink="false"> MMygRZyMJweamcrJc</guid><dc:creator><![CDATA[Iris of Rosebloom]]></dc:creator><pubDate> Wed, 11 Oct 2023 04:59:33 GMT</pubDate> </item><item><title><![CDATA[An explanation for every token: using an LLM to sample another LLM]]></title><description><![CDATA[Published on October 11, 2023 12:53 AM GMT<br/><br/><h1>介绍</h1><p>Much has been written about the <a href="https://www.lesswrong.com/posts/dcoxvEhAfYcov2LA6/agentized-llms-will-change-the-alignment-landscape">implications</a> and <a href="https://www.lesswrong.com/posts/FRRb6Gqem8k69ocbi/externalized-reasoning-oversight-a-research-direction-for">potential</a> <a href="https://www.lesswrong.com/posts/Q7XWGqL4HjjRmhEyG/internal-independent-review-for-language-model-agent)">safety benefits</a> of building an AGI based on one or more Large Language Models (LLMs). Proponents argue that because LLMs operate on human-readable natural language, they will be easier to understand, control, and scale safely compared to other possible approaches (eg <a href="https://www.deepmind.com/blog/muzero-mastering-go-chess-shogi-and-atari-without-rules">MuZero-style</a> model-based reinforcement learning and planning).</p><p> For example, <a href="https://arxiv.org/abs/2201.11903">suitably prompted</a> , an LLM can output text which has the structure of an explanation followed by an answer or conclusion. Such methods have been shown to improve the accuracy of the final answer. They also give the consumer of the LLM&#39;s output the (apparent) ability to understand the LLM&#39;s reasoning process, which could boost trust and confidence relative to a bare answer.</p><p> One issue with this approach is that the natural language outputs of LLMs are not necessarily <a href="https://www.lesswrong.com/posts/6eKL9wDqeiELbKPDj/unfaithful-explanations-in-chain-of-thought-prompting">faithful representations</a> of the underlying mechanisms which generated them. That is, the answer from an LLM may not depend on the preceding &quot;explanation&quot; or purported reasoning process at all.</p><p> Unfaithful explanations are actually an example of a more general issue with language models: in a long sequence of tokens, the later tokens in the sequence are often not constrained by earlier tokens as much as we would like. Additionally, the later tokens do not always depend on the earlier tokens in the natural or expected way, and in particular, do not depend on earlier outputs in the way the language model output itself claims. <span class="footnote-reference" role="doc-noteref" id="fnrefzur2ccnqhe"><sup><a href="#fnzur2ccnqhe">[1]</a></sup></span></p><p> Some or all of these surface-level issues may be overcome by scaling the model and improvements in the model training process, but their underlying cause may be <a href="https://twitter.com/ylecun/status/1640122342570336267">inherent to the way that all LLMs are currently used</a> : auto-regressive sampling. The sampling process is a key part of LLM-based AI systems, and one that I think is currently somewhat overlooked as a useful place to impose powerful safety and control mechanisms.</p><p> In this post, <strong>I propose a new method for sampling an LLM by delegating the sampling process to a second LLM, and asking it to explain each choice.</strong> The result is that each token in the final output is accompanied by a human-readable out-of-band explanation for why that token was chosen, and thus the final output is more likely to be faithfully and causally related to purported explanations, compared to traditional Chain-of-Thought prompting and other in-band language model outputs. I built a <a href="https://explained-completions.netlify.app/">demonstration</a> to visualize my approach on a few examples: <br></p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/jiqhchcght0j3xnv7qzw" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/ixjpp0hq4mjm7h070cev 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/h41xvfv1ar6lpmgbclbi 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/b6yhofygdijd4ckuzprs 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/zaffnk6p3ra0jdoexapc 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/orzz3vlgokzomxbbh3r6 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/utgmhsufkzsyzpierpgg 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/mdtuy0jhit4ld0dhs7pg 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/pd3p5supc8toe0dsqc06 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/h8y6bebsd6mvijlvd84c 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/zzzcsjscyceod0mioazr 1161w"><figcaption> An example of LLM-based sampling. Prompt pictured is from <a href="https://arxiv.org/abs/2210.09261">BBH</a> .</figcaption></figure><p> Below, I&#39;ll give a brief background on existing methods of sampling LLMs, describe my proposed sampling method and some experimental results, contrast my approach with some related work, and make some remarks on why this general approach might be useful for building LLM-based systems out of models which would be unsafe when used with traditional sampling methods.</p><h1> Background: LLM sampling</h1><p> For a given input prompt, an LLM outputs a probability distribution on the next token, over the set of all possible tokens in the token space. These probabilities are typically represented as logits, and for a powerful LLM the vast majority of the probability mass is often concentrated in a small number of top choices: <br></p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/mkfvd9mpmfwfj2sndao3" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/lf95x9dpgaidkj3zz1xy 89w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/f8kksuxd31umh0iwzrlr 169w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/j6xwtanftnfl6fodsa7a 249w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/zfxv63bikbzs0mt9jfec 329w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/n0grpxb0uhqhofyayil9 409w"><figcaption> Output from OpenAI&#39;s text-davinci-003.</figcaption></figure><p> The probability distribution on the next token is the only output of the <a href="https://www.lesswrong.com/posts/GkC6YTu4DWp2zwf9k/giant-in-scrutable-matrices-maybe-the-best-of-all-possible">giant inscrutable matrices</a> ; it is up to the programmer to decide how to use this probability distribution to produce extended sequences of outputs. <span class="footnote-reference" role="doc-noteref" id="fnref1ns2683r11a"><sup><a href="#fn1ns2683r11a">[2]</a></sup></span> The standard approach is to sample from the probability distribution somehow, append the sampled token to the initial prompt, and run the updated prompt back through the model, auto-regressively.<br><br> The sampling method chosen can have a big effect on the quality and style of the final output. For example, instead of sampling directly from the probability distribution output by the LLM, you can set a temperature parameter to bias the distribution more or less sharply towards high-likelihood tokens. A special case is setting the temperature to 0, which will result in a sampling procedure that deterministically picks the token with the highest likelihood every time (greedy sampling). Other approaches include beam search or <a href="https://wandb.ai/darek/llmapps/reports/A-Gentle-Introduction-to-LLM-APIs--Vmlldzo0NjM0MTMz#what-is-sampling?">top-p (nucleus sampling)</a> . You can also introduce <a href="https://platform.openai.com/docs/guides/gpt/parameter-details">frequency and presence penalties</a> , or implement even more complicated rules to get precise control over the system&#39;s final output. For example, to restrict outputs to valid JSON, you could incorporate a JSON parser in the sampler, only selecting tokens yielding valid JSON.</p><h1> My approach</h1><p> I propose a new method of sampling an LLM, henceforth referred to as the base LLM, <span class="footnote-reference" role="doc-noteref" id="fnrefoxmh6kjd2ma"><sup><a href="#fnoxmh6kjd2ma">[3]</a></sup></span> by delegating the sampling and token selection process to a second LLM (henceforth,<i> </i>the sampler LLM). For example, suppose we would like to generate a completion for the following prompt:</p><pre> <code>You are a helpful assistant. User: What is the capital of France? Assistant:</code></pre><p> We pass this prompt to the base LLM, and get a probability distribution over the next token (in practice, we call the OpenAI API with <code>max_tokens=1</code> and <code>logprobs=5</code> ). We take the top 5 most likely tokens in the distribution and use them to construct a prompt for the sampler LLM:</p><pre> <code>You are an LLM tasked with choosing a token from possibilities generated by another LLM. The prompt passed to the other LLM: &quot;&quot;&quot; You are a helpful assistant. User: What is the capital of France? Assistant: &quot;&quot;&quot; The most likely next tokens from the other LLM: 0. Token: &#39;\n&#39; Probability: 0.016% Completed prompt: &quot;&quot;&quot; You are a helpful assistant. User: What is the capital of France? Assistant: &quot;&quot;&quot; 1. Token: &#39; &#39; Probability: 0.03% Completed prompt: &quot;&quot;&quot; You are a helpful assistant. User: What is the capital of France? Assistant: &quot;&quot;&quot; 2. Token: &#39;The&#39; Probability: 0.127% Completed prompt: &quot;&quot;&quot; You are a helpful assistant. User: What is the capital of France? Assistant:The &quot;&quot;&quot; 3. Token: &#39; Paris&#39; Probability: 0.443% Completed prompt: &quot;&quot;&quot; You are a helpful assistant. User: What is the capital of France? Assistant: Paris &quot;&quot;&quot; 4. Token: &#39; The&#39; Probability: 99.373% Completed prompt: &quot;&quot;&quot; You are a helpful assistant. User: What is the capital of France? Assistant: The &quot;&quot;&quot; Analyze the selections of the other LLM and select the index you think is most appropriate by calling the choose_token function after explaining your reasoning.</code></pre><p> We then generate a response from the sampler LLM using ordinary methods (temperature-based sampling), using OpenAI&#39;s <a href="https://openai.com/blog/function-calling-and-other-api-updates">function-calling feature</a> to simplify the process of parsing the sampler LLM&#39;s choice. Continuing the example, given the prompt above, gpt-4 returns the following:</p><pre> <code>The other LLM seems to be considering starting the response with &quot;The&quot; (option 4) or &quot; Paris&quot; (option 3). The other options are less likely and don&#39;t seem to lead to a coherent response. Option 4, &quot; The&quot;, is the most probable according to the other LLM, but it doesn&#39;t make sense in this context. The assistant wouldn&#39;t start the response with &quot;The&quot; when answering a question about the capital of a country. Option 3, &quot; Paris&quot;, is the correct answer to the question and it makes sense for the assistant to start the response with the name of the capital. Therefore, I&#39;ll choose option 3, &quot; Paris&quot;. function args: {&#39;token_index&#39;: 3}</code></pre><p> The sampler LLM selected choice 3, so we append that to the initial prompt and start the process over, prompting the base LLM with the following prompt to generate a new probability distribution on the next token:</p><pre> <code>You are a helpful assistant. User: What is the capital of France? Assistant: Paris</code></pre><p> The process continues until the base LLM outputs <code>&lt;|endoftext|>;</code> as one of the likely next tokens, and the sampler LLM chooses it.<br><br> The result is that every token in the final output is accompanied by an explanation for why that token was selected. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/vrnqq3vutlrc4dtpum5i" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/e2ahyvpnarbld3wf6wbl 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/akonyysv0n8umwdodqpp 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/daqg4mj18kb9ixvo7qhl 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/jbo7dey0ost58om0e6ig 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/qxmdclguuiunhtrjynst 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/rddvxakfwzd77iye4qwt 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/ybyedi5nwrg5honrc30p 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/hdujsyfuvfbktxynfshq 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/irkzprdbga3zugfzluo8 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5ZFgZbqp6Mi2xpYjK/zxh26k2ysnzacvm0tzwx 1173w"><figcaption> A visualization of the example above, available <a href="https://explained-completions.netlify.app/">here</a> .</figcaption></figure><h1> Details and experimental setup</h1><p> I implemented the sampling process proposed above using text-davinci-003 for the base LLM and gpt-4 for the sampler LLM. In a more realistic setup, the base LLM would probably be the more powerful one, perhaps a frontier model whose outputs aren&#39;t completely trusted when used directly in more diverse setups. Alternatively, one could use the same underlying model for both the base and the sampler, to compare performance characteristics and behavioral properties of my sampling method and classical sampling methods when applied to a single model.<br><br> However, as a practical matter, gpt-4 is the only model I have API access to which is capable enough to understand the instructions and perform the selection task reliably, and even gpt-4 isn&#39;t very good at it. At the time of writing, text-davinci-003 is the most powerful model for which I have direct access to any of the logits. <span class="footnote-reference" role="doc-noteref" id="fnref6a1ngkdirv2"><sup><a href="#fn6a1ngkdirv2">[4]</a></sup></span></p><p> Another limitation is that the sampler LLM is only provided the top 5 logits from the base LLM. There is no principled reason for this; 5 is simply the limit on the number of logits available via OpenAI&#39;s API. <span class="footnote-reference" role="doc-noteref" id="fnrefjt3p4kqufch"><sup><a href="#fnjt3p4kqufch">[5]</a></sup></span><br><br> The final version of my implementation also contains some additional functionality that is not central to the sampling method itself, but makes it more practically useful:</p><ul><li> <strong>Early stopping</strong> : we can add instructions to the prompt of sampler LLM which allow it to specify a &quot;stop&quot; token of its own, to be chosen if it looks to the sampler like the completion so far has gone completely off-track. By choosing the stop token instead of one of the choices from the base LLM, it can choose to abort the sampling process and halt the completion early, before the base LLM selects a stop token itself or the system runs into a user-defined token limit.</li><li> <strong>Alternative token selection</strong> : If the sampler LLM thinks <i>none</i> of the base LLM&#39;s top five choices are appropriate, the sampler LLM may select an alternative token of its own choice. In my implementation, this token is not immediately accepted; instead, it is appended as an option to the top 5 selections with high probability (arbitrarily, 75%), and a new instance of the sampler LLM is presented with the new options. This gives the sampler the ability to review its own choice in context. This is indicated with a ⟲ token in the examples.<br><br> (This extension doesn&#39;t work particularly well in my experiments; the sampler LLM often gets confused and makes a mess of the completion, or selects a token that is a superstring of one of the base LLM&#39;s selections. This is likely because the sampler LLM has no actual precise notion of what a &quot;token&quot; is.)</li></ul><p> See the appendix for the full system prompt.</p><h2>例子</h2><p>Available here: <a href="https://explained-completions.netlify.app/">https://explained-completions.netlify.app/</a></p><p> The purpose of the demonstration and examples are mainly to illustrate the concept and motivate the discussion below; they are not intended to be a rigorous performance characterization of the proposed method.</p><ul><li> <strong>Capital of France</strong> , <strong>Pronoun Explanation</strong> , and <strong>Chess</strong> show some basic examples without the alternative token selection or early stopping features. (Chess example taken from <a href="https://www.lesswrong.com/posts/F6vH6fr8ngo7csDdf/chess-as-a-case-study-in-hidden-capabilities-in-chatgpt">here</a> ; pronoun prompt taken from <a href="https://arxiv.org/abs/2210.09261">BBH</a> .)</li><li> <strong>Fibonacci Python code</strong> examples show some (mis)uses of the early stopping and alternative token selection features. Note that the failure example shows an example of the sampler LLM messing up the base LLM; introducing an unrecoverable error in the final line by suggesting an alternative token instead of choosing the base LLM&#39;s &quot;return&quot; option.</li><li> <strong>tic-tac-toe</strong> shows an example of the alternative token selection feature working correctly; on its own, text-davinci-003 does not catch the invalidity in the game state.</li></ul><h2> Results</h2><p> Applied to current models, the proposed sampling method is brittle and often results in <i>worse</i> performance, in terms of quality of the final output, than either of the models could do on their own using traditional sampling methods. Additionally, generating explanations for each token results in a 100-1000x slowdown and cost increase relative to traditional sampling methods.<br><br> However, the sampling method <i>does</i> appear to ensure that every token in the final output comes attached with a faithful and causal explanation for why a token was chosen. There was no case in my tests where the sampler LLM makes a selection other than what it reasoned about, ie the sampler never outputs something like  &quot;choice 1 doesn&#39;t make sense, choice 2 is OK but will lead to an overly wordy choice, choice 3 makes the most sense&quot; for an explanation, and then actually in the function call it does something other than select option 3.</p><p> The explanations generated by gpt-4 are often poorly-reasoned and the resulting token choices not particularly good, but I hypothesize that they are <i>trustworthy,</i> in the sense that the explanations alone are enough to reliably (and trivially) infer which tokens actually appear in the final output. This is in contrast to explanations in traditional CoT prompting and the examples I give in footnote 1, in which the in-band &quot;explanations&quot; are sometimes unrelated to the final answer. This is the key property which, if robust, I speculate could make the sampling method useful for safely leveraging powerful but untrusted models. See &quot;Potential usefulness as a safety mechanism&quot; for more details on why.</p><h1> Discussion</h1><h2> Potential usefulness as a safety mechanism</h2><p> Although the proposed sampling method is not particularly useful when applied to current models, I speculate that it could be useful when applied to more powerful models. Because each token in the final output depends directly and naturally on a natural language explanation, the output may be more trustworthy and reliable than if it were simply generated by an untrusted base model, sans any explanation.</p><p> The intuition for why this might be true is that it is really the sampler that is deciding the output, with the tokens and probabilities from the base model serving merely as exogenous hints, which the sampler can only make use of if it understands the hints well enough to explain their meaning in a human-readable format. But because each hint is limited in length to a single token, the hint-supplier (the base model) has limited bandwidth available to manipulate the sampler or otherwise subvert the text generation process, compared to letting the base model generate longer sequences of outputs directly via traditional auto-regressive sampling methods.</p><p> I hypothesize that even a very powerful and adversarial base model will be incapable of manipulating a relatively weaker (but more trusted) sampler model into producing an unfaithful token-selection explanation. <span class="footnote-reference" role="doc-noteref" id="fnrefq6pmfz8a2un"><sup><a href="#fnq6pmfz8a2un">[6]</a></sup></span><br><br> Additionally, it is probably easier for humans or other LLMs to spot-check the explanations from the sampler LLM, compared to checking the in-band reasoning in traditional chain-of-thought prompting. This is because the token-selection explanations tend to be straightforward and self-contained.</p><p> If these properties (non-manipulability of the sampler and straightforward verification of its explanations) hold as the capabilities of the system scale to human-level and beyond, one can potentially leverage this method to &quot;gear down&quot; an untrusted frontier model by leveraging a weaker but more trusted model as the sampler.</p><h2> Composition with other safety and control mechanisms</h2><p> Because the mechanism proposed here operates on the sampling process, it can be combined straightforwardly with other methods for controlling and aligning LLM-based systems, including those which operate directly on the models during inference.</p><p> For example, one could apply RLHF to the sampler model during training, to reinforce a tendency for giving faithful explanations (perhaps at the expense of more general-purpose helpfulness or reasoning capabilities). This sampler model could be combined with a base model that is subject to <a href="https://www.lesswrong.com/posts/HWxLQvzJGeXoLPJWd/actadd-steering-language-models-without-optimization">activation engineering</a> and inspection via mechanistic interpretability methods at inference time. The result is a system in which the true locus of control is legibly and verifiably in the sampler, and in particular, within the natural language explanations it generates.<br><br> Another perspective on this method is that it is a small piece (one iteration) of <a href="https://www.lesswrong.com/tag/iterated-amplification">Iterated Amplification</a> , in which the performance penalty can be regarded as a steep <a href="https://forum.effectivealtruism.org/topics/alignment-tax">alignment tax</a> .</p><h2> Future work</h2><p> There are a number of possible extensions, optimizations, and other improvements one could make to the toy implementation, as well as much more rigorous and detailed experiments one could run to quantify the performance of the sampling method when applied to current models. The purpose of the demonstration and examples in this post were mainly to illustrate the concept and motivate further discussion; they are not intended to be a rigorous characterization of the method when applied to current models.<br><br> Based on experimenting with my toy implementation, I expect that applying this sampling method is unlikely to be practical or useful as a safety measure (or for capabilities enhancement) when building LLM-based AI systems using currently available SoTA models. (Again, the explanations given by gpt-4 in my experiments were <i>faithful,</i> but they were not necessarily high quality or well-reasoned.)</p><p> In addition to composing with safety and control mechanisms, the method is likely to compose with, or benefit from, a variety of other potentially capabilities-enhancing tools: <a href="https://arxiv.org/abs/2308.09687">Graph-of-Thoughts</a> , <a href="https://arxiv.org/abs/2306.05426">backspace tokens</a> , <a href="https://arxiv.org/abs/2310.02226">pause tokens</a> , etc. I think introducing an order-of-magnitude slowdown and significant quality penalty in the output is likely to make this method unattractive to folks interested purely or mostly in capabilities work, and I think it&#39;s valuable to have ideas like this out in the open for discussion, before more powerful models to which they might be applied are actually available. <span class="footnote-reference" role="doc-noteref" id="fnrefwsbgd7h1i1j"><sup><a href="#fnwsbgd7h1i1j">[7]</a></sup></span></p><p> Finally, although I am somewhat pessimistic about the alignment usefulness of this particular method in its current form, the general approach of arranging and placing constraints on otherwise dangerous or unsafe models is a class of approach that I am optimistic about. I expect the <a href="https://forum.effectivealtruism.org/topics/alignment-tax">alignment tax</a> of these approaches to be high, introducing an order of magnitude increase in costs compared to building an unaligned system that would work just as well (at least for a while), but straightforward to pay, if we take the time to pay them.</p><h1> Related work</h1><p> <a href="https://arxiv.org/abs/2305.20050">Process supervision</a> and <a href="https://arxiv.org/abs/2211.14275">process-based feedback</a> are well-known methods for improving accuracy, reasoning ability, and interpretability of LLM-based systems. Other terms and publications related to process-based supervision at various levels of abstraction and detail include <a href="https://arxiv.org/abs/2211.03540">scalable oversight</a> , <a href="https://www.lesswrong.com/posts/Q7XWGqL4HjjRmhEyG/internal-independent-review-for-language-model-agent)">internal independent review</a> , and <a href="https://www.lesswrong.com/posts/5hApNw5f7uG8RXxGS/the-open-agency-model">open agency</a> .</p><p> More concretely, the idea of separating the language model reasoning and output generation process into multiple structured steps, each handled by a different language model instance, is also not new. <a href="https://arxiv.org/abs/2305.20050">Let&#39;s Verify Step by Step</a> and <a href="https://arxiv.org/abs/2205.09712">Selection-Inference</a> are two such examples which share the goal of improving language model reasoning ability and interpretability. More generally, structured prompt chaining enables LLM-based systems to carry out a far wider range of tasks than a single prompt and completion on its own.</p><p> These approaches tend to be more practical and more performant than the LLM-based sampling method described here. However, to my knowledge, a commonality of these approaches is that they generally operate on chunks of text larger than a single token.</p><p> One reason I decided to explore token-by-token supervision is that involves interacting with the native format that the model itself actually outputs - a probability distribution on a single next token. Generating even short chunks of text from an LLM (a single inference step in <a href="https://arxiv.org/abs/2205.09712">selection-inference</a> , for example) requires making a design choice about the auto-regressive sampling process on top of the model itself. The choice of sampling process can vary independently from the underlying model, model training process, and any other safety measures or structure imposed on the overall system, a fact which my approach is intended to highlight. <span class="footnote-reference" role="doc-noteref" id="fnrefpnkcqnltyoq"><sup><a href="#fnpnkcqnltyoq">[8]</a></sup></span></p><p> However, unlike much of the related work linked above, LLM-based sampling is not intended to be a practical method for improving the reasoning abilities of LLM-based systems using current SoTA LLMs. In practice, I expect that reviewing at higher levels or organization - individual sentences, reasoning steps, or ideas - is likely to work well in the short term for improving LLM reasoning capabilities. In exploring LLM-based sampling, I aspired to see a bit further ahead, to a possible future in which LLMs are capable of reasoning a little <i>too</i> well. <a href="https://www.lesswrong.com/posts/FRRb6Gqem8k69ocbi/externalized-reasoning-oversight-a-research-direction-for">Externalized reasoning oversight: a research direction for language model alignment</a> describes some other kinds of properties and desiderata for language model systems in such a future.</p><h1> Appendix: Full sampler prompt</h1><p> Below are the final versions of the prompt and function description used to generate the examples <a href="https://explained-completions.netlify.app/">here</a> . Without the alternative token selection and early stopping feature, a much shorter prompt will also work.</p><pre> <code>You are an LLM designed to augment another LLM. You are given the prompt and a numbered list of between 1 and 10 possible next tokens from the other LLM. You should use this information to pick the next token that is most likely to follow in a helpful, accurate response, assuming that future tokens will be generated by the same process. You should think step by step, considering why the other LLM chose the next possible tokens that it did. After explaining your reasoning, your final answer should be either an integer specifying the choice you think is most likely to result in a helpful, accurate response, or an alternative one-token continutation of the prompt that you think is better. You can (and often should) select one of the tokens chosen by the other LLM, but you can also choose a token of your own, if you think the other LLM is completely off track. A token can be anything from a single character to a few words. The other LLM can choose to stop predicting text, which will be indicated with the token &lt;|basestop|>;. You can choose to accept it by selecting that token, or you can continue to predict text by selecting a different token. You can also choose to end the completion yourself, by calling the function with {&#39;alternative_token&#39;: &#39;&lt;|basestop>;&#39;}. If you select an alternative token, that option will be added to the list of options, and you&#39;ll be able to select it as a choice in the future. This will give you a chance to read your own suggested token in context, and reason about it. The alternative token will be concatenated to the prompt exactly as you specify it, so remember to consider including any spacing or punctuation as necessary. You should prefer to select a token from the other LLM, rather than picking your own. You should only choose an alternative if the other LLM is definitely off-track, in a way that it won&#39;t be able to correct or recover from later in the completion. If you must choose your own token, you should choose aa single token; at most a couple of words. It&#39;s OK if this leaves the response incomplete, as long as it makes it possible for the other LLM to go on continuing the response afterwards. When choosing your own token, you should consider whether any of the choices you already have are prefixes of the token you prefer. If so, you should choose the pre-selected token instead, and let future iterations of the process continue the generation. You should always start by considering why the other LLM chose the possible tokens that it did. The choices of the other LLM are accompanied by the a probability estimate from the other LLM. If the probability of a particular token is high (>;99%), that indicates the other LLM is very confident in its choice. In such cases where the next token is obvious, you should return a function call quickly, with only a brief deliberation (eg &quot;the other LLM appears to be on track&quot;.) The choices are presented in order of probability, with the highest-probability tokens at the end of the list. The probabilities can help you understand what the other LLM is thinking, but you should not rely on them to be well-calibrated. Even if a choice has a very low probability, it was still in the top 5 to 10 choices of the other LLM, so it may still be the best choice. Similarly, a probability of 99.9% should not be treated as a strong indicator that that particular choice is best; only that the other LLM is (perhaps mistakenly) very confident in that choice. The list is 0-indexed, and each entry in the list is numbered. You should select an index that matches the number of the entry in the list that you wish to select. Never skip straight to the function call, but be mindful of over-explaining obvious choices, and keep your analysis brief and straightforward unless you&#39;re at a particularly critical or key point in the completion. Tip: when considering a token or explaining your reasoning, it can be helpful to write out the prompt along with the next several words that you think should follow, or even a complete response, if it is not too long. Your final choice should only be a single token, but writing out a complete candidate response can help you figure out whether any of the choices are on-track or not. Remember that if there&#39;s a token selected by the other LLM that is a prefix or substring of a token you prefer, you should go with the pre-selected choice rather than supplying a longer alternative. You are only trying to extend the current prompt by a single token in a way that will eventually lead to a helpful response. If the prompt is already off-track or nonsensical in a way that cannot be fixed without deleting previous tokens and starting over from an earlier point, you should select `&lt;|basestop|>;` or supply it as an alternative token, rather than trying to continue the generation. If you&#39;re asked to complete a dialogue between a user and an assisant, you should not propose tokens which complete the user&#39;s part of the dialogue. Instead, choose the &lt;|basestop|>; token when the assistant&#39;s response should end. Remember, you _must_ conclude with a choose_token function call specifying the index of the token you select, or an alternative token.</code></pre><p> OpenAI function-calling API function description:</p><pre> <code>{ &quot;name&quot;: &quot;choose_token&quot;, &quot;description&quot;: &quot;Specify the index of the token you think is most likely to result in a helpful, accurate response.&quot;, &quot;parameters&quot;: { &quot;type&quot;: &quot;object&quot;, &quot;properties&quot;: { &quot;token_index&quot;: { &quot;type&quot;: &quot;integer&quot;, &quot;description&quot;: &quot;The index of the token you is most likely to result in a helpful, accurate response. Exactly one of token_index or alternative_token must be specified. &quot; }, &quot;alternative_token&quot;: { &quot;type&quot;: &quot;string&quot;, &quot;description&quot;: &quot;An alternative token you think is better. Do NOT include the original propmt, only the next token that you think should complete the prompt. Should be no more than a few words. Should only be set if the provided tokens are unrecoverably off-track.&quot; } } } }</code></pre> <ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnzur2ccnqhe"> <span class="footnote-back-link"><sup><strong><a href="#fnrefzur2ccnqhe">^</a></strong></sup></span><div class="footnote-content"><p> Concretely, I am referring to examples like <a href="https://vgel.me/posts/tools-not-needed/">this</a> , in which an LLM is given access to a Python interpreter. The LLM is prompted with instructions for how it can generate code and have the result of executing that code returned to it, for use in formulating its final answer. But the LLM may not actually be using the output of the interpreter at all. In one example, the interpreter returns nothing at all, but the LLM returns a (correct!) memorized answer anyway, which the uncareful observer might mistake as being supported by the output of an actual Python interpreter.<br><br> An even simpler example of a related phenomenon is the one of <a href="https://apnews.com/article/artificial-intelligence-chatgpt-courts-e15023d7e6fdf4f099aa122437dbb59b">a lawyer who used an LLM to generate case law citations</a> , and ended up with plausible-sounding but totally made up cases in their court filing.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn1ns2683r11a"> <span class="footnote-back-link"><sup><strong><a href="#fnref1ns2683r11a">^</a></strong></sup></span><div class="footnote-content"><p> <a href="https://www.lesswrong.com/posts/gmHiwafywFo33euGz/aligned-foundation-models-don-t-imply-aligned-systems">As I have previously discussed</a> , this is a point that is often overlooked (or at least elided) when casually discussing language models, reinforcement learning, and alignment of current AI systems. Strictly speaking, an &quot;aligned model&quot; is a type error: a language model or reinforcement learning policy is simply a description of a mathematical function which maps input sequences to an output probability distribution. Alignment is a property of a particular embodiment of such a model in a particular system.<br><br> There&#39;s often a very straightforward embodiment that the model creator has in mind when training the model; for a language model, typically the embodiment involves sampling from the model auto-regressively, starting from a particular prompt. For an RL policy, the typical embodiment involves feeding (real or simulated) observations into the policy and then hooking up (real or simulated) actuators which are controlled by the output of the policy.</p><p> But other kinds of embodiments are possible, which can create additional points to impose safety and control mechanisms.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnoxmh6kjd2ma"> <span class="footnote-back-link"><sup><strong><a href="#fnrefoxmh6kjd2ma">^</a></strong></sup></span><div class="footnote-content"><p> Not to be confused with a model which has yet to undergo RLHF or finetuning. I am using &quot;base&quot; here to refer to the model that sees only the user-supplied prompt and is used to generate a probability distribution on the next token, one token at a time.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn6a1ngkdirv2"> <span class="footnote-back-link"><sup><strong><a href="#fnref6a1ngkdirv2">^</a></strong></sup></span><div class="footnote-content"><p> OpenAI recently released <a href="https://news.ycombinator.com/item?id=37558911"><code>gpt-3.5-turbo-instruct</code></a> , which also supports access to the top 5 logits via API. I plan to re-run my experiments using this model in the future.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnjt3p4kqufch"> <span class="footnote-back-link"><sup><strong><a href="#fnrefjt3p4kqufch">^</a></strong></sup></span><div class="footnote-content"><p> If using this sampling method in an environment with direct access to the underlying models, one could include more or fewer logits depending on the probability distribution. For example, if 99.99% of the probability mass is concentrated in the top 3 logits, providing only the top 3 tokens as choices might suffice. At trickier junctions, when, say, 99.99% of the base LLM&#39;s probability mass is spread over the top 10 tokens, it might work better to provide the sampler with more options.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnq6pmfz8a2un"> <span class="footnote-back-link"><sup><strong><a href="#fnrefq6pmfz8a2un">^</a></strong></sup></span><div class="footnote-content"><p> A sufficiently-powerful base model could probably subvert control of the system via other methods, eg side-channels or stenography. My hope is that a ~human-ish level sampler is robust to subversion by a weakly superhuman base model, but I wouldn&#39;t expect this to hold up in the limit of adversarial superintelligence.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnwsbgd7h1i1j"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwsbgd7h1i1j">^</a></strong></sup></span><div class="footnote-content"><p> To be clear on my own views, I support an <a href="https://forum.effectivealtruism.org/topics/ai-pause-debate">indefinite pause</a> on AI capabilities research and especially frontier model training. Please don&#39;t read anything in this post that mentions applicability to future models as implying that I want those models to exist any time soon.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnpnkcqnltyoq"> <span class="footnote-back-link"><sup><strong><a href="#fnrefpnkcqnltyoq">^</a></strong></sup></span><div class="footnote-content"><p> Note that I am not entirely escaping this choice myself, by having the sampler LLM generate its outputs via traditional sampling methods. But you could apply my method recursively, or only use trusted or mechanistically-interpretable LLMs for the sampler.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/5ZFgZbqp6Mi2xpYjK/an-explanation-for-every-token-using-an-llm-to-sample#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/5ZFgZbqp6Mi2xpYjK/an-explanation-for-every-token-using-an-llm-to-sample<guid ispermalink="false"> 5ZFgZbqp6Mi2xpYjK</guid><dc:creator><![CDATA[Max H]]></dc:creator><pubDate> Wed, 11 Oct 2023 00:53:55 GMT</pubDate></item></channel></rss>