<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 27 日星期一 18:15:12 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Two concepts of an “episode” (Section 2.2.1 of “Scheming AIs”)]]></title><description><![CDATA[Published on November 27, 2023 6:01 PM GMT<br/><br/><p> （这是我的报告“<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？</a> ”的第 2.2.1 节。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p>本节的音频版本<a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13984831-two-concepts-of-an-episode-section-2-2-1-of-scheming-ais">请点击此处</a>，或在您的播客应用程序上搜索“Joe Carlsmith Audio”。）</p><h1>超越剧集目标</h1><p>策划者所追求的目标超出了剧集的时间范围。但什么是剧集？</p><h2> “情节”的两个概念</h2><p>让我们区分剧集的两个概念。</p><h3>激励情节</h3><p>第一个，我将其称为“激励事件”，是我迄今为止一直使用的概念，并将在下文中继续使用。因此，考虑在时间t <sub>1</sub>起作用的模型。这里，粗略的想法是将情节定义为 t <sub>1</sub>之后的时间单位，训练<em>主动惩罚</em>模型的不优化——即时间单位，这样我们可以<em>通过定义</em>知道训练不会直接迫使模型去关心关于该时间之后的后果。</p><p>例如，如果训练于 2023 年 1 月 1 日开始并于 2023 年 7 月 1 日完成，那么本次训练的激励周期的最大长度将为六个月——模型在任何时候都不会因为优化失败而受到训练的惩罚在超过六个月的时间范围内，因为没有对模型的策略应用梯度，而这些梯度对其行为的超过六个月的后果（因果）敏感。但原则上，该培训过程的激励期也可以短于六个月。 （更多内容见下文。）</p><p>现在，重要的是，即使训练只是直接迫使模型在一段有限的时间内进行优化，它<em>实际上仍然可以创建</em>一个在更长的时间内进行优化的模型——在我看来，这就是阴谋者成为可能的原因。因此，举例来说，如果你正在训练一个模型在十分钟的窗口内获得尽可能多的金币，原则上它仍然可以学习“在所有时间内最大化金币”的目标 - 并且这个目标可能会执行相当好（即使没有训练游戏），或者尽管表现不佳但仍能生存（例如，由于训练允许的“松弛”）。</p><p>事实上，在某种程度上，我们将进化视为机器学习训练的类比，那么类似的事情似乎已经发生在那些拥有无限远的未来目标的人类身上——例如，“<a href="https://en.wikipedia.org/wiki/Longtermism">长期主义者</a>”。也就是说，进化不会以对生物在一万亿年内的行为后果敏感的方式主动选择或反对生物（毕竟，进化只<em>持续</em>了几十亿年）——然而，一些人类的目标是优化无论如何，在万亿年的时间尺度上。</p><p>也就是说，在某种程度上，给定的训练程序<em>实际上</em>创建了一个具有非常长期目标的模型（因为，例如，这样的目标受到我将在下面讨论的各种“<a href="https://en.wikipedia.org/wiki/Inductive_bias">归纳偏差</a>”的支持），那么从某种意义上说，你可能会说培训也“激励”了这样的目标。也就是说，假设“在接下来的十分钟内最大化金币”和“在所有时间内最大化金币”在一个仅在十分钟后提供奖励的训练过程中都获得相同的奖励，但该训练选择“在所有时间内最大化金币”一直”，因为所讨论的目标之间存在其他一些差异（例如，因为“始终最大化金币”在某种意义上是“更简单”，并且除了获得奖励之外，梯度下降还选择简单性）。这是否意味着培训“激励”或“选择”长期目标？</p><p>也许你可以这么说。但这并不意味着训练“直接惩罚”短期目标（或“直接迫使”模型实现长期目标）。特别是：在这种情况下，通过追求短期目标（同时保持其他能力固定）至少<em>有可能</em>获得相同的奖励。模型的策略接收到的梯度（假设）仅对模型动作后十分钟内发生的事情敏感，并且不会“注意到”此后的后果。因此，就训练选择关注十分钟以上的后果而言，这并不是因为这些后果<em>直接影响应用于模型策略的梯度。</em>相反，它是通过其他一些不太直接的路线。这意味着该模型原则上可以忽略十分钟后的后果，而不会因为梯度下降而停止。</p><p>或者至少，这是我试图指出的广泛概念。但不可否认，其中的微妙之处很棘手。特别是：在某些情况下，超出梯度敏感时间范围的目标可能会比短期目标主动获得<em>更多奖励</em>。</p><ul><li><p>例如，也许“在所有时间内最大化金币”实际上比“在接下来的十分钟内最大化金币”获得<em>更多的奖励</em>，也许是因为长期目标在某种程度上“更简单”，可以释放额外的认知资源，可以用来获取金币。</p></li><li><p>或者，人类可能正在<em>尝试</em>使用短期反馈来构建一个在较长时间范围内优化的模型，因此正在积极寻找训练过程，通过追求长期目标的模型来最大化短期奖励。例如，也许您希望您的模型针对公司的长期利润进行优化，因此您会在短期内奖励它采取在您看来会最大化长期利润的行动。这里可能发生的一件事是，模型开始专门为了获得短期奖励而进行优化。但是，如果您的监督过程足够好，那么模型的最高奖励政策可能是<em>实际优化</em>长期利润（或其他不通过训练游戏实现的长期目标） ）。 <sup class="footnote-ref"><a href="#fn-FAWgp3muxXZCnakAa-1" id="fnref-FAWgp3muxXZCnakAa-1">[1]</a></sup></p></li></ul><p>在这些情况下，更自然的说法是，训练“直接迫使”模型实现长期目标，因为该目标会获得更多奖励。然而，我仍然想说，这里的长期目标是“超越情节”的，因为它们超出了梯度直接且因果敏感的时间范围。不过，我承认，精确地定义这一点可能会很棘手（请参阅下一节了解更多的棘手之处）。我鼓励更加精确的努力，但我不会在这里尝试。 <sup class="footnote-ref"><a href="#fn-FAWgp3muxXZCnakAa-2" id="fnref-FAWgp3muxXZCnakAa-2">[2]</a></sup></p><h3>直观的情节</h3><p>让我们转向剧集的另一个概念——即我所说的“直观剧集”。直觉事件没有机械定义。 <sup class="footnote-ref"><a href="#fn-FAWgp3muxXZCnakAa-3" id="fnref-FAWgp3muxXZCnakAa-3">[3]</a></sup>相反，直观的情节只是：一个看似自然的时间单位，您在结束时给予奖励，并且您决定将其称为“情节”。例如，如果您正在训练下国际象棋的人工智能，您可以将国际象棋游戏称为“片段”。如果您通过 RLHF 训练聊天机器人，您可能会将与用户的交互称为“片段”。等等。</p><p>我的感觉是，直觉情节和激励情节通常有些相关，因为我们经常选择反映训练过程中某些差异的直觉情节，这使得很容易假设直觉情节也是训练过程中的时间单位。训练直接迫使模型进行优化——例如，因为你在训练结束时给予奖励，因为训练环境在直观的episode之间“重置”，或者因为模型在一个episode中的动作没有明显的方式影响其他episode的结果剧集。但重要的是，<strong>直觉情节和激励情节不一定相同</strong>。也就是说，如果您刚刚选择了一个看似自然的时间单位来称为“情节”，那么训练过程是否会直接迫使模型关心在这个意义上的情节之外发生的事情仍然是一个悬而未决的问题。例如，训练是否会直接迫使模型牺牲早期情节的奖励，以换取稍后情节的更多奖励，这仍然是一个悬而未决的问题，如果是这样的话能够这样做。</p><p>为了说明这些动态，考虑类似囚徒困境的情况，每天，智能体可以为自己获取 +1 奖励（叛逃），或者为第二天的智能体提供 +10 奖励（合作），我们决定将“一天”称为（直观的）情节。不同形式的机器学习训练是否会直接迫使该智能体合作？如果是这样，那么我们选择的直观情节就不是激励情节。</p><p>现在，我的理解是，在这样的情况下，普通策略梯度（一种 RL 算法）会学习缺陷（该测试实际上是使用简单的代理完成的 – 参见<a href="https://arxiv.org/pdf/2009.09153.pdf">Krueger 等人 (2020)</a> ）。我认为重要的是要弄清楚哪种算法会以这种方式运行以及为什么会这样。特别是：看看这种设置，我认为很容易推理如下：</p><blockquote><p> “当然，你说你正在训练模型，以在某些看似自然的直觉事件中最大化‘在该事件中’的奖励。但你也承认，模型的行为可以影响稍后发生的事情，甚至超出了这种直觉的范围。情节 - 也许包括它稍后获得多少奖励。因此，您是否会隐式地训练模型以在<em>整个训练过程</em>中最大化奖励，而不仅仅是在单个（直观）情节上。例如，如果有可能在当前事件中获得<em>较少奖励的</em>模型，以便以后获得<em>更多奖励</em>，导致进行此交易的认知模式不会得到整体强化吗？” <sup class="footnote-ref"><a href="#fn-FAWgp3muxXZCnakAa-4" id="fnref-FAWgp3muxXZCnakAa-4">[4]</a></sup></p></blockquote><p>通过与一些比我更了解强化学习的人的讨论， <sup class="footnote-ref"><a href="#fn-FAWgp3muxXZCnakAa-5" id="fnref-FAWgp3muxXZCnakAa-5">[5]</a></sup>我目前（过于模糊）的理解是，至少对于<em>某些</em>类型的 RL 训练算法来说，这是不正确的。也就是说，<em>可以</em>设置 RL 训练，使某些有限的、短视的行为单位实际上是激励事件——<em>即使</em>智能体可以为了以后获得更多奖励而牺牲当前事件的奖励（并且可能是：甚至如果代理人知道这一点）。事实上，这很可能是默认的。更多详情请参见脚注。 <sup class="footnote-ref"><a href="#fn-FAWgp3muxXZCnakAa-6" id="fnref-FAWgp3muxXZCnakAa-6">[6]</a></sup></p><p>即使<em>可以避免</em>跨直觉情节进行优化的激励，但也有可能<em>不</em>这样做——特别是如果你对“直觉情节”的概念选择得非常糟糕。例如，我的理解是，默认情况下设置了变压器架构，以便在训练中激励语言模型以不仅促进预测<em>下一个</em>标记，而且还促进预测其他后续标记的方式分配认知资源，例如好吧（更多讨论见<a href="https://www.lesswrong.com/posts/c68SJsBpiAxkPwRHj/how-llms-are-and-are-not-myopic#2__Value_Prediction_Myopia">这里</a>）。因此，如果您决定将预测下一个标记称为“情节”，并在此基础上假设语言模型永远不会直接受到压力去进一步思考，那么您就会被误导。</p><p>在某些情况下，跨集优化训练的激励似乎非常违反直觉。因此，Krueger 等人（2020）令人惊讶地表明，如果参数设置正确，一种称为 Q 学习的 ML 训练形式有时会学会在囚徒困境中进行合作，尽管该算法在以下意义上是“短视”的：对未来“剧集”的奖励。有关更多讨论，请参阅脚注，并<a href="https://www.alignmentforum.org/s/tDBYJd4p6EorGLEFA/p/rTYGMbmEsFkxyyXuR#Getting_cooperation_without_meta_learning">在此处</a>查看 Q-learning 工作原理的快速解释。 <sup class="footnote-ref"><a href="#fn-FAWgp3muxXZCnakAa-7" id="fnref-FAWgp3muxXZCnakAa-7">[7]</a></sup> </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTLvooL44SPEFWGhD/f6m4sxt5ogh51j2wzsuc" alt="Q 值和合作概率图来自 Krueger 等人 (2020) 的图 11，经许可转载。前三个智能体在几乎 90% 的时间里学会了背叛，而后两个则学会了合作（注意前三个和后两个 y 轴之间的差异）。"></p><p> <em>Q 值和合作概率图来自 Krueger 等人 (2020) 的图 11，经许可转载。前三个智能体在几乎 90% 的时间里学会了背叛，而后两个则学会了合作（注意前三个和后两个 y 轴之间的差异）。</em></p><p>激励跨直观事件优化的另一种方法是在训练中引入各种附加选择层（或“外循环”）。因此，例如，考虑一种玩具和不切实际的“<a href="https://www.deepmind.com/blog/population-based-training-of-neural-networks">基于群体的训练</a>”形式，您创建 1000 个玩星际争霸的代理，让他们每个玩 100 场游戏（并通过某种对象级训练算法一路更新），然后选择<em>在最后一场比赛中</em>表现最好的人。 <sup class="footnote-ref"><a href="#fn-FAWgp3muxXZCnakAa-8" id="fnref-FAWgp3muxXZCnakAa-8">[8]</a></sup>在这种情况下，如果一个模型有可能牺牲早期游戏的奖励，以便在最终游戏中表现更好，那么它至少会面临一些选择压力。另请参阅<a href="https://arxiv.org/pdf/2009.09153.pdf">Krueger 等人 (2020)</a>的结果，该结果表明，一种不同形式的基于人群的训练会选择在类似囚徒困境的情况下进行合作，就像上面讨论的那样。 <sup class="footnote-ref"><a href="#fn-FAWgp3muxXZCnakAa-9" id="fnref-FAWgp3muxXZCnakAa-9">[9]</a></sup>不过，根据细节，这种外循环可能会比由梯度下降直接驱动的内循环施加更<em>弱</em>的选择压力。 <sup class="footnote-ref"><a href="#fn-FAWgp3muxXZCnakAa-10" id="fnref-FAWgp3muxXZCnakAa-10">[10]</a></sup></p><p>总的来说，我目前的感觉是，在特定训练过程的背景下，需要非常小心地评估您所认为的“情节”是否实际上是训练不会主动对模型施加压力在这个意义上超越“情节”进行优化——也就是说，一个给定的“直觉情节”是否实际上是“激励情节”。仔细观察培训过程的细节似乎是第一步，理论上应该能够揭示许多（如果不是全部）所涉及的激励措施。但实证实验似乎也很重要。</p><p>事实上，我有些担心的是，在本报告中，我选择使用“激励事件”作为我对“事件”的定义，这很容易导致这两个定义之间的混淆，并相应地对不同形式的时间范围进行不恰当的安慰。培训直接激励。 <sup class="footnote-ref"><a href="#fn-FAWgp3muxXZCnakAa-11" id="fnref-FAWgp3muxXZCnakAa-11">[11]</a></sup>我选择关注激励事件，因为我认为它是区分阴谋者和其他类型模型的最自然、最联合的单位。但重要的是，它也是一个更难直接测量和定义的理论对象：你不能立即假设你知道给定类型的训练的激励事件<em>是</em>什么。我的感觉是，“情节”一词的最常见用法更接近直观的定义，从而诱使读者（尤其是休闲读者）进一步感到困惑。请：不要混淆。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-FAWgp3muxXZCnakAa-1" class="footnote-item"><p>我将简要说明此类案例引发的另一个复杂性。天真地，您可能认为“指定目标”只会仅限于激励事件，因为指定目标是“受到奖励的事物”，并且任何<em>导致</em>奖励的事物都在梯度所在的时间范围内。敏感的。在某些情况下——例如，“指定目标”是模型行为的一些明显可分离的<em>结果</em>（例如，获得金币），训练过程促使模型对其进行优化——这是有道理的。但在其他情况下，我不太确定。例如，如果您足够擅长判断您的模型<em>实际上是否正在针对长期利润进行优化</em>，并提供实际上激励其这样做的短期奖励，那么我认为正确的说法可能是这里的“指定目标”是长期利润（或者至少是“优化长期利润”，这看起来非常相似）。然而，我认为我们将这种目标称为“指定的”还是“错误概括的”（更一般地说，这是一个相当模糊的区别），最终并不重要，所以我不会在这里强调这些术语。 <a href="#fnref-FAWgp3muxXZCnakAa-1" class="footnote-backref">↩︎</a></p></li><li id="fn-FAWgp3muxXZCnakAa-2" class="footnote-item"><p>另外：当我谈到梯度对模型在一段时间内的行为后果敏感时，我想象这种敏感性是通过（1）发生相关后果，然后（2）响应应用梯度而发生的。例如，模型在 t1 处产生一个动作，这导致它在 t5 处获得一定数量的金币，然后在 t6 处应用的梯度受到模型实际获得的金币数量的影响。 （我有时将其称为“因果敏感性”。）</p><p>但我们可以想象更奇特、更充满哲学意义的方式来影响模型影响梯度的行为的后果。例如，假设该模型由非常擅长<em>预测</em>模型行为后果的人监督。也就是说，模型在 t1 处产生一些动作，然后在 t2 处人类<em>预测</em>这将在 t5 处产生多少金币，并在 t3 处应用反映此预测的梯度。在完美预测的极限情况下，这可能会导致与第一种情况中的梯度相同的梯度——也就是说，关于模型行为的后果的信息实际上是“回到过去”，并解决了所有的哲学问题# 因此，如果在第一种情况下，我们想说“激励事件”延伸到 t5，那么我们似乎也应该在第二种情况下这样说，即使梯度是在 t3 处应用的。但即使在预测相当不错但仍然不完美的情况下，这里也有一种感觉，即模型接收到的梯度对尚未发生的后果很敏感。</p><p>在这里，我不会将“激励事件”的概念扩展到涵盖基于对这些后果的预测的对未来后果的敏感性。相反，我将假设所讨论的敏感性是通过正常形式的<em>因果</em>影响产生的。也就是说，我认为，即使在看到这些后果发生之前，也有<em>可能</em>对未来后果产生某种形式的敏感性，这一点值得牢记。特别是，这是我们最终可能使用相当短的激励事件来训练长期优化器的一种方式（下面有更多讨论）。 <a href="#fnref-FAWgp3muxXZCnakAa-2" class="footnote-backref">↩︎</a></p></li><li id="fn-FAWgp3muxXZCnakAa-3" class="footnote-item"><p>在 RL 文献中可能还有其他、附加和更精确的方式使用术语“情节”。不过，浏览一下网上的各种链接（例如，<a href="https://www.baeldung.com/cs/epoch-vs-episode-reinforcement-learning">这里</a>和<a href="https://towardsdatascience.com/the-complete-reinforcement-learning-dictionary-e16230b7d24e">这里</a>），我大多看到将情节称为“初始状态和最终状态之间的状态集”之类的定义，这并没有说明如何指定初始状态和终止状态。 <a href="#fnref-FAWgp3muxXZCnakAa-3" class="footnote-backref">↩︎</a></p></li><li id="fn-FAWgp3muxXZCnakAa-4" class="footnote-item"><p>作为一个在我看来他们可以用这种方式推理的人的例子，尽管还不完全清楚，请参阅 Eliezer Yudkowsky 的<a href="https://www.lesswrong.com/posts/LDsSqXf9Dpu3J3gHD/why-i-m-excited-about-debate?commentId=BvFWfvryfoDJrmcgn">评论，这是</a>对一个假设的回应，在该假设中，他想象人类根据智能体的每个句子奖励智能体这句话有多有用：</p><blockquote><p> “我们甚至可以跳过这样的意义：如果 AGI 最终以长期后果论者的身份结束，我们就给予人工智能长期激励，让其在短期内接受一些较低的奖励，以便夺取评级按钮的控制权。准确反映外在适应度函数的偏好和长期规划能力。”</p></blockquote><p>也就是说，正如我在下面讨论的，这里的培训过程的细节很重要。 <a href="#fnref-FAWgp3muxXZCnakAa-4" class="footnote-backref">↩︎</a></p></li><li id="fn-FAWgp3muxXZCnakAa-5" class="footnote-item"><p>特别是：保罗·克里斯蒂安诺、瑞安·格林布拉特和罗欣·沙阿。尽管他们不一定赞同我在这里的具体主张，而且我可能更普遍地误解了他们。 <a href="#fnref-FAWgp3muxXZCnakAa-5" class="footnote-backref">↩︎</a></p></li><li id="fn-FAWgp3muxXZCnakAa-6" class="footnote-item"><p>我对这里的论点的模糊理解是，这些 RL 算法会更新模型的策略，以实现该情节中的更高奖励动作，但<em>不会</em>更新您的策略<em>，以引导您开始更高奖励的情节</em>（从这个意义上说，它们的行为方式类似于“因果决策理论”。）。因此，假设第一天的特工（之前没有特工让她受益）在合作（0 奖励）和背叛（+1 奖励奖励）之间进行选择，因此这一集会导致背叛的更新。然后，在第一天，代理要么开始在 10 与 11 奖励（称为“好剧集”）或 0 与 +1 奖励（称为“坏剧集”）之间进行选择。同样，无论哪种方式，它都会更新为叛逃。在好的情节中，它<em>并没有</em>更新为“无论什么政策引导我进入这一情节”。</p><p>也就是说，以我目前对强化学习的了解，我对此仍然有点困惑。举个例子，假设在选择时，你不知道你是处于好的情节还是坏的情节，并且训练过程正在更新你的强度，强度与你获得更多的程度成正比。比你<em>预期</em>得到的奖励。如果你一开始有 50% 的人处于好的情节，50% 的人处于糟糕的情节（这样合作的预期奖励是 5，背叛的预期奖励是 6），那么它似乎情况可能是这样，处于一个好的阶段会带来比你预期的要好得多的奖励，这样，使其成为一个好的阶段的政策最终会在更大程度上得到加强，至少在最初是这样。</p><p>我不确定这里的细节。但从我目前的认知状态来看，我想更深入地阐明和理解训练过程的细节，以验证是否没有跨情节优化的动机。 <a href="#fnref-FAWgp3muxXZCnakAa-6" class="footnote-backref">↩︎</a></p></li><li id="fn-FAWgp3muxXZCnakAa-7" class="footnote-item"><p>我认为这里的基本动态是：行动的 Q 值反映了迄今为止采取该行动的平均奖励。这使得“合作”的 Q 值可以更加重视在“好剧集”（前一集的特工合作）中收到的奖励，而不是“坏剧集”（前一集的特工合作）叛逃），如果特工最终更频繁地获得良好的表现。这使得实现“合作平衡”成为可能（特别是如果你将背叛的初始 q 值设置为低，我认为他们在论文中这样做是为了获得这种效果），其中代理保持合作。也就是说，存在微妙之处，因为最终处于合作平衡的主体有时仍然会探索背叛，但在实验中它（有时）最终会达到一种特定的平衡，合作和背叛的 q 值非常相似，模型的合作概率为 90% 左右（更多详细信息请参见<a href="https://www.alignmentforum.org/s/tDBYJd4p6EorGLEFA/p/rTYGMbmEsFkxyyXuR#Getting_cooperation_without_meta_learning">此处</a>和本文的附录）。 <a href="#fnref-FAWgp3muxXZCnakAa-7" class="footnote-backref">↩︎</a></p></li><li id="fn-FAWgp3muxXZCnakAa-8" class="footnote-item"><p>我把这个例子归功于马克·徐。 <a href="#fnref-FAWgp3muxXZCnakAa-8" class="footnote-backref">↩︎</a></p></li><li id="fn-FAWgp3muxXZCnakAa-9" class="footnote-item"><p>另请参阅卡尔·舒尔曼（Carl Shulman）<a href="https://www.dwarkeshpatel.com/i/128144047/ai-takeover-scenarios">在这里</a>的讨论：“这可能是他们围绕生殖健康的扩展概念发展出一种动机，不一定是在个人层面上，而是在几代人的训练倾向中，这种倾向往往会自我传播，变得更加普遍，而且可能是他们在世界上有一些目标，通过在训练分布上表现出色可以很好地实现这一目标。” <a href="#fnref-FAWgp3muxXZCnakAa-9" class="footnote-backref">↩︎</a></p></li><li id="fn-FAWgp3muxXZCnakAa-10" class="footnote-item"><p>事实上，原则上，您可以想象指出其他更抽象且难以避免的“外循环”，作为长期优化的选择压力来源。例如，原则上，“研究生血统”（例如，研究人员尝试不同的学习算法，然后选择最有效的算法）引入了额外的选择压力层（类似于“<a href="https://en.wikipedia.org/wiki/Meta-learning_(computer_science)">元学习</a>”的模糊形式），动力学也是如此，在其他条件相同的情况下，倾向于更有效地传播到未来的模型将随着时间的推移而占据主导地位（长期优化也许就是这样的趋势之一）。但在我看来，相对于梯度下降，这些通常足够弱，在我看来它们不那么重要，并且在评估阴谋者的概率时可以忽略。 <a href="#fnref-FAWgp3muxXZCnakAa-10" class="footnote-backref">↩︎</a></p></li><li id="fn-FAWgp3muxXZCnakAa-11" class="footnote-item"><p>感谢 Daniel Kokotajlo 提出了这一问题。 <a href="#fnref-FAWgp3muxXZCnakAa-11" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/pfhS2DkEtR6gdser6/two-concepts-of-an-episode-section-2-2-1-of-scheming-ais#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/pfhS2DkEtR6gdser6/two-concepts-of-an-episode-section-2-2-1-of-scheming-ais<guid ispermalink="false"> pfhS2DkEtR6gdser6</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Mon, 27 Nov 2023 18:01:29 GMT</pubDate> </item><item><title><![CDATA[[Linkpost] George Mack's Razors]]></title><description><![CDATA[Published on November 27, 2023 5:53 PM GMT<br/><br/><p>我不使用 Twitter/X，我只是看到这个，因为它是在<a href="https://twitter.com/ESYudkowsky">https://twitter.com/ESYudkowsky</a>上，我每天都会检查它（ <a href="https://www.lesswrong.com/posts/6JSjYCzdQmX7G2AQd/the-kids-are-not-okay?commentId=uEvSAgdRC5EoLQXSp">一个减轻大脑暴露于新闻提要算法的安全方法</a>的示例）。</p><p>这里的<a href="https://www.lesswrong.com/posts/8gbfvGhSnEJ9hHGew/10-reasons-why-lists-of-10-reasons-might-be-a-winning">银河大脑单词组合</a>符合我非常高的优化标准（例如，使用银河大脑单词组合来最大化价值与字数的比率）。</p><p>例如，如果有人要通过在长而直观的<a href="https://www.lesswrong.com/posts/dbDHEQyKqnMDDqq2G/cfar-handbook-introduction">C​​FAR 手册</a>和短而高效的<a href="https://www.lesswrong.com/s/qRxTKm7DAftSuTGvj">锤子序列</a>之间获得两全其美来开始人类智力放大协调起飞，那么这就是他们必须达到的写作技能水平玩于：</p><blockquote><p>我发现的最有用的剃须刀和规则：</p><p> <strong>1. 吹牛剃刀</strong>——如果有人吹嘘自己的成功或幸福，假设这只是他们声称的一半</p><p>如果有人淡化他们的成功或幸福，假设它是他们声称的两倍</p><p><strong>2. 高代理剃刀</strong>- 如果不确定与谁合作，请选择最有可能将您从第三世界监狱中救出来的人。</p><p> <strong>3. The Early-Late Razor</strong> - 如果这是 Reddit 上的一个话题，那么你可能就早了。如果这是 LinkedIn 上的一个话题，那么你肯定迟到了。</p><p> <strong>4. 运气剃刀</strong>- 如果遇到两个相同的选项，请选择一个感觉会在以后产生最大运气的选项。</p><p>我用这把剃须刀去和陌生人喝酒，而不是看 Netflix。事后看来，这是我做过的投资回报率最高的决定。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bnqQbfpuntiQy9NAX/h9xlsk5i0usscscirbp4" alt="图像"></p><p> <strong>5.巴菲特定律</strong>——“每家企业的价值100%受政府利率影响”——沃伦·巴菲特</p><p><strong>6. 6 位数剃刀</strong>- 如果有人吹嘘“6 位数” - 假设它更接近 10 万美元而不是 90 万美元。</p><p> <strong>7. 父母法则</strong>——分解父母对你的投资：时间、爱、精力和金钱。</p><p>如果他们还活着，目标是实现积极的投资回报率（或至少收支平衡）。</p><p> <strong>8. Instagram Razor——</strong>当你在 Instagram 上看到一张看起来很有吸引力的影响者的照片时——假设这张照片有 99 种你没见过的更糟糕的变体。</p><p>他们只是挑选了最好的一个。</p><p> <strong>9. 自恋剃刀</strong>——如果担心别人的看法，请记住他们太忙于担心别人对他们的看法。 99%的时间你都是别人电影中的临时演员</p><p><strong>10. Everyday Razor</strong> - 如果你从每周执行一项任务改为每天执行一项任务，你可以在 1 年内实现 7 年的产出。如果每次应用 1% 的复利，则 1 年内可实现 54 年的产出。</p><p> <strong>11.贝索斯剃刀</strong>——如果不确定该选择什么行动，就让90岁临终的自己选择吧。</p><p> <strong>12. 创造力剃刀</strong>- 如果很难创造性地思考某个主题，请改变它：</p><p> • 将想法转化为书面想法。<br> • 将想法写成绘图。<br> • 绘制方程式。<br> • 对话中的方程式。</p><p>在改变它的过程中，你开始发现新的创造性联系。</p><p> <strong>13. 罗马帝国规则</strong>——历史学家现在承认罗马帝国于 476 年灭亡——但直到许多代之后，罗马社会才承认这一点。</p><p>如果你等待媒体通知你，你要么错了，要么为时已晚。</p><p> <strong>14. 物理剃刀</strong>- 如果它不否认物理定律，那么就假设它是可能的。不要将社会当前缺乏知识与不可能获得这些知识混为一谈。</p><p>例如，智能手机对于 1800 年代的人来说似乎是不可能的——但这是可能的，只是他们缺乏知识。</p><p> <strong>15.斯金纳定律</strong>——如果拖延，你有两种方法解决：</p><p> • 使不作为的痛苦 >; 行动的痛苦<br>• 享受行动的乐趣 >; 享受无所事事的乐趣</p><p><strong>16. 网络剃刀</strong>——如果你有两个优秀的人可以通过相互介绍而受益，那么一定要这样做。</p><p>当你分享网络时，网络不会分裂，而是会倍增。</p><p> <strong>17. 盖尔曼剃刀</strong>- 假设每篇媒体文章都包含 % 的虚假信息。</p><p>将文章从您的世界观中沙箱化，直到您：</p><p> • 查看主要来源<br>• 与 3 位领域专家交谈</p><p><strong>18. 塔勒布的外科医生</strong>- 如果有两个同等的候选人担任某个角色，请选择魅力最小的一个。</p><p>尽管缺乏魅力，但缺乏魅力的人却到达了那里。具有超凡魅力的人是凭借他们的超凡魅力到达那里的。</p></blockquote><br/><br/> <a href="https://www.lesswrong.com/posts/bnqQbfpuntiQy9NAX/linkpost-george-mack-s-razors#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/bnqQbfpuntiQy9NAX/linkpost-george-mack-s-razors<guid ispermalink="false"> bnqQbfpuntiQy9NAX</guid><dc:creator><![CDATA[trevor]]></dc:creator><pubDate> Mon, 27 Nov 2023 17:53:45 GMT</pubDate> </item><item><title><![CDATA[On possible cross-fertilization between AI and neuroscience [Creativity] ]]></title><description><![CDATA[Published on November 27, 2023 4:50 PM GMT<br/><br/><p>从新 <a href="https://new-savanna.blogspot.com/2023/11/on-possible-cross-fertilization-between.html"><i>稀树草原</i></a><i>交叉发布</i><i>。</i> </p><figure class="media"><div data-oembed-url="https://youtu.be/Gg-w_n9NJIE?si=aIUztzy1i9l7QbZa"><div><iframe src="https://www.youtube.com/embed/Gg-w_n9NJIE" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div></figure><p>麻省理工学院思想、大脑和机器中心 (CBMM)，小组讨论： <a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbmNjTFJfQVZjcHdLcmtaMHZvNXlHVWlaaFNhZ3xBQ3Jtc0trenpOZFBBZTF1ZV81QllHRWdMR2o2UlA3UUs5Z1hkWGNhWWQyU1I2S0JfeVVUR3RhcDAxMjBqWUxxMXlBZl9wT0Z4emh4MkdWcmRSMGVCLUlZbFJ0cHZXRXc4X05DV2tWMkZvaGdGS0UyX3B1RFBHOA&amp;q=https%3A%2F%2Fcbmm.mit.edu%2FCBMM10&amp;v=Gg-w_n9NJIE">CBMM10</a> - 智力研讨会：大脑、思想和机器。</p><p>神经科学、认知科学和计算机科学现在应该关注哪些关键问题？我们是否需要理解学习的基本原理——就像物理学中的理论理解一样——并将这种理解应用到真正的自然和人工系统中？从社会、工业和科学的角度来看，类似的问题涉及神经科学和人类智力。</p><p>小组主席：T. Poggio<br>小组成员：D. Hassabis、G. Hinton、P. Perona、D. Siegel、I. Sutskever</p><p><strong>快速评论</strong></p><p><strong>1.)</strong>我对哈萨比斯将情景记忆的想法归功于神经科学感到有点恼火。据我所知，这个术语是由认知心理学家恩德尔·图尔文 (Endel Tulving) 在 20 世纪 70 年代初创造的，他反对语义记忆。这种区别在 20 世纪 70 年代的认知科学中随处可见，对我来说这是它的第二天性。当 ChatGPT 放置许多事件来编写故事时，这就是情景记忆。</p><p> <strong>2.)</strong>我喜欢思考所谓的推测工程，而不是理论。我在我关于音乐的书（ <i>《贝多芬的铁砧</i>》）的序言中创造了这句话，我在其中说道：</p><blockquote><p>工程学是关于设计和构建的：神经系统如何设计和构建音乐？这是推测性的，因为它必须如此。推测的目的是澄清思想。如果这个猜测本身是清楚的、有根据的，那么即使是错误的，它也会达到目的，而我的许多猜测肯定是错误的。如果我随后要求你们考虑这些问题，而不知道如何区分有先见之明的推测和错误的推测，那是因为我相信我们有办法从经验上解决这些问题。我的目标是通过实证研究和计算机模拟提出有趣、有意义和清晰的想法，以证明艰苦的调查工作是合理的。</p></blockquote><p> <strong>3.)</strong>关于乔姆斯基（Hinton &amp; Hassabis）：是的，乔姆斯基关于语言的观点从根本上是错误的。语言主要是一种将意义从一个人传达给另一个人的工具，只是衍生的一种思考工具。他错误地认为法学硕士可以学习任何语言，因此他们对语言的科学研究毫无用处。乔姆斯基思想的另一个问题是他对过程不感兴趣，过程属于绩效领域，而不是能力领域。</p><p>为了便于论证，我们假设将单个标记引入到输出流中需要由 LLM 模拟的虚拟系统的一个<i><strong>原始</strong></i>操作。我的意思是，流程中没有逻辑运算，没有“与”或“或”，没有控制权转移；所发生的一切只是一项涉及系统中所有参数的巨大计算。这意味着<i><strong>产生给定输出所需的原始操作数量等于该输出中的标记数量。</strong></i>我认为这对法学硕士的联想记忆的组织造成了严格的限制。</p><p>将其与经典符号系统中发生的情况进行对比。让我们假设每次发出一个单词（与 LLM 中的标记不太一样，但区别并不重要）时，它本身就需要经典系统中的单个原始操作。然而除此之外，经典系统还必须执行大量符号操作才能得出每个单词。无论这些操作如何解析为原始符号操作，该数量都必须比 LLM 所需的原始操作数量更大，也许要大得多。我建议这个过程对符号记忆系统的组织施加更少的限制。</p><p><i>此时视频已达到 45 分 11 秒，但我必须停下来思考。也许稍后我会提供更多评论。</i></p><p><strong>之后：</strong></p><p> <strong>4.)</strong>接近尾声时（01:20:00 左右），创造力的问题出现了。哈西比斯人工智能还没有出现。 Hinton 提出了类比，指出法学硕士拥有丰富的知识，他们有机会提出一个又一个的类比。我在 ChatGPT 方面拥有与这些问题、类比和创造力直接相关的经验。</p><p>当我开始使用 ChatGPT 后，我做的第一件事就是让它对史蒂文·斯皮尔伯格的<i>《大白鲨》</i>进行吉拉德式的诠释。要做到这一点，它必须确定电影中的事件与吉拉德理论的现象之间是否存在类比。它做得相当好。所以我把它写下来并发表在<i>3 Quarks Daily</i>上， <a href="https://3quarksdaily.com/3quarksdaily/2022/12/conversing-with-chatgpt-about-jaws-mimetic-desire-and-sacrifice.html">Conversing with ChatGPT about Jaws, Mimetic Desire, and Sacrifice</a> 。接近尾声时我说道：</p><blockquote><p> ChatGPT 的功能给我留下了深刻的印象。与它互动很有趣，非常有趣，有时我会咯咯笑出声。但这是否是备受吹捧的通用人工智能（AGI）的预兆，更不用说是对全知全能的超级智能即将到来的厄运的警告——你在开玩笑吗？没有那样的事，什么都没有。我很快就能看到，它是执行各种任务的有用助手。甚至可能比助理还要重要一点。但据我所知，这就是。</p><p>我们可以将 ChatGPT 在我的提示下所做的事情与我无提示、自由地、自愿地所做的事情进行比较。它的回复没有任何内容接近我的文章《 <a href="https://3quarksdaily.com/3quarksdaily/2022/12/conversing-with-chatgpt-about-jaws-mimetic-desire-and-sacrifice.html">鲨鱼城牺牲》</a> ，也没有<a href="https://new-savanna.blogspot.com/search/label/Jaws">接近我写的有关这部电影的各种博客文章</a>。这很重要。我既没有期待，更没有希望，ChatGPT 会像一个全面的 AGI。不，我还有别的事。</p><p>引起我注意的是我必须做什么才能写这篇文章。首先，我必须观看这部电影并理解它。正如我已经指出的，没有具有所需功能（视觉、听觉和认知）的人工系统。为了确定细节，我把这部电影看了好几遍。我还查阅了在互联网上找到的脚本。 <i>《大白鲨2》</i>我也看了不止一遍。我为什么这么做？有好奇心和一般原则。但还有一个事实是， <a href="https://en.wikipedia.org/wiki/Jaws_(film)"><i>《大白鲨》</i>的维基百科文章</a>断言，三部续集都没有第一部那么好。我必须观看其他人才能亲眼目睹——尽管我无法看完最后两部中的任何一部。</p><p>此时我正在徘徊，尽管我还没有决定写任何东西。</p><p>我现在问自己，为什么原作比第一部续集好得多，至少是可以观看的。我想出了两件事：1）原始电影在续集散布时井井有条且紧密，2）Quint，续集中没有与Quint相当的角色。</p><p>奎因特为什么要死？哦，我知道电影中发生了什么。那不是我要问的。问题是一种美学。只要鲨鱼被杀死，该镇就会得救。这种必要性并不需要五五重点的死亡，也不需要其他任何人的死亡。如果Quint没有死，结局会有什么感觉？如果是Brody或Hooper怎么办？</p><p>正是在思考这样的问题时，它打击了我：牺牲！吉拉德！吉拉德的想法如何源于我。我不是在寻找它们，而不是直接的。我只是问有关这部电影的反事实问题。</p><p>任何。</p><p>一旦吉拉德（Girard）在我心中，我就会闻到鲜血的味道，也就是说，写一篇有趣的文章的可能性。我开始阅读，做笔记，并与我的朋友戴维·波鲁什（David Porush）通信，他知道吉拉德（Girard）的想法比我要好得多。我可以写一篇不错的文章吗？这就是我要弄清楚的。只有在我发表了一些初步帖子，起草一些文字并由David运行之后，我才决定去做。这篇文章结果很好，我决定发布它。我也这么做了。</p><p>当您获得文字和图案时，弄清楚是否会表现出这样的文本/电影是否表现出这样的图案是一回事。这就是Chatgpt所做的。由于我已经建立了Girard和<i>Jaws</i>之间的联系，因此不必这样做。我只是在提示chatgpt验证它所做到的连接（尽管以较弱的方式）。这是我们为高中生和低级大学生设定的任务。 […]</p><p>我真的不认为在这种情况下，Chatgpt在高中时期在高中运作。我也不这么认为。我不知道该怎么想。我对此很满意。</p><p>更深入的观点是，当我将其试行到<i>Jaws</i>和Girard时，Chatgpt在做什么以及当我看着<i>下巴</i>并决定环顾四周以查看我能看到的东西时所做的事情有所不同。在这个过程中，吉拉德如何来到我身边？我不是在寻找吉拉德。我不是在寻找任何特别的东西。<i><strong>我们如何教计算机四处寻找并提出有趣的东西？</strong></i></p></blockquote><p>这些观察是非正式的，只是一个例子。考虑到这些局限性，很难想象概括。但是我没有听到那些相当富裕的专家的消息。 Hinton有一个类比的例子，他对GPT-4（01:18:30）提出了一个类比：“堆肥与原子弹有什么共同点？”它得到了他正在寻找的答案，链反应，尽管以不同的能量水平和不同的速度。那很有意思。为什么面板还没有准备好有20个这样的例子？</p><p>他们没有自己的作品中没有更多这样的例子吗？他们不是考虑自己的工作过程，所有的开始和停止，四处游荡，死胡同和虚假的开始，开放式探索，这是在最终成功之前的。即使那样，也没有最终成功，但只有临时调查才能进一步调查。他们看不到自己的工作与机器所做的区别吗？他们认为，面对机器超级智能，对探索的所有需求都会消失。他们真的相信宇宙很小吗？</p><br/><br/> <a href="https://www.lesswrong.com/posts/pL7CT2iJYaA4ne9Yd/on-possible-cross-fertilization-between-ai-and-neuroscience#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/pl7ct2ijyaa4ne9yd/on-possible-cross-cross-ferlatization-between-between-between-ai-and-neuroscience<guid ispermalink="false"> pl7ct2ijyaa4ne9yd</guid><dc:creator><![CDATA[Bill Benzon]]></dc:creator><pubDate> Mon, 27 Nov 2023 16:50:46 GMT</pubDate> </item><item><title><![CDATA[Ethicophysics I]]></title><description><![CDATA[Published on November 27, 2023 3:44 PM GMT<br/><br/><p>什么是善与恶？我们如何充分地向分支机构解释这些概念，以便我们可以放心，计算机将与人类理解的意义相同的意义上理解它们？这些是棘手的问题，人们经常对解决任何AI安全问题感到绝望。</p><p>在本文中，我们制定了一种以物理定律为基础的伦理理论。该理论具有两个关键的优势：它与大多数人类道德直觉非常合理，并且可以轻松地计算计算机在透露情况下可以轻松执行的计算。因此，它构成了解决AI安全问题的理想基础。</p><br/><br/><a href="https://www.lesswrong.com/posts/DkkfPEwTnPQyvrgK8/ethicophysics-i#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/dkkfpewtnpqyvrgk8/ethicophysics-i<guid ispermalink="false"> dkkfpewtnpqyvrgk8</guid><dc:creator><![CDATA[MadHatter]]></dc:creator><pubDate> Mon, 27 Nov 2023 15:44:29 GMT</pubDate> </item><item><title><![CDATA[Sentience Institute 2023 End of Year Summary]]></title><description><![CDATA[Published on November 27, 2023 12:11 PM GMT<br/><br/><h1><strong>概括</strong></h1><p>去年的<a href="https://www.sentienceinstitute.org/blog/eoy2022"><u>2022 年年终总结</u></a>是在 ChatGPT 推出前五天发布的。这一事件令该领域的许多人感到惊讶，全球的关注已经说明了理解人机交互的重要性。我们的首要任务仍然是研究<a href="https://www.sentienceinstitute.org/blog/key-questions-for-digital-minds"><u>数字思维</u></a>的兴起：具有或被认为具有推理、代理、经验和<a href="https://www.sentienceinstitute.org/blog/the-importance-of-artificial-sentience"><u>感知等</u></a>心理能力的人工智能。我们希望回答这样的问题：人类与人工智能的关系迅速改变的下一个“ChatGPT时刻”将会是什么？人类和人工智能如何以有益而非破坏的方式互动？</p><p>我们 2023 年研究的亮点是<a href="https://www.sentienceinstitute.org/aims-survey"><u>人工智能、道德和情感 (AIMS)</u></a>调查，其问题与 2021 年相同，因此我们可以比较最近事件前后的公众舆论，以及额外的<a href="https://www.sentienceinstitute.org/aims-survey-supplement-2023"><u>AIMS 2023 年公众意见补充人工智能安全观点</u></a>。这样的数据通常是在社会问题完全受到公众关注后收集的，因此我们渴望在数字思维兴起之前就已经建立了这种纵向跟踪。在外展方面，我们发布了两集<a href="https://www.sentienceinstitute.org/podcast/"><u>播</u></a>客（其中一集于 2022 年 12 月发布），并举办了一场关于数字思维的跨群体电话会议以及<a href="https://www.youtube.com/watch?v=xq5ZhYUi1K8"><u>Yochanan Bigman 的演讲</u></a>。</p><p>我们正在进行的工作包括关于人工智能自主性和感知如何影响感知的在线实验，开发衡量底层主义的量表，以及人们如何理解尖端人工智能系统并与之互动的定性研究（例如访谈）。<strong>我们希望在这个捐赠季筹集 150,000 美元，以继续我们对数字思维的研究。</strong>我们还有一些正在进行的项目来解决工厂化养殖问题（我们在 2021 年之前的重点），这些项目由捐助者的指定捐款资助，例如为我们的<a href="https://www.sentienceinstitute.org/aft-survey"><u>动物、食品和技术 (AFT) 调查</u></a>2023 年迭代进行的持续数据收集。</p><p>一如既往，我们非常感谢我们的支持者，他们与我们有着共同的愿景，并使这项工作成为可能。如果 2023 年您可以的话，请考虑<a href="https://www.sentienceinstitute.org/donate"><u>捐款</u></a>。</p><h1> 2023 年的成就（迄今为止）</h1><h2>研究</h2><ul><li>我们最近发布了 2023 年<a href="https://www.sentienceinstitute.org/aims-survey"><u>人工智能、道德和情感 (AIMS) 调查</u></a>结果。 2023 年<a href="https://www.sentienceinstitute.org/aims-survey-2023"><u>主要</u></a>和<a href="https://www.sentienceinstitute.org/aims-survey-supplement-2023"><u>补充</u></a>调查结果以及<a href="https://www.sentienceinstitute.org/aims-survey-2021"><u>2021 年主要</u></a>调查结果可在我们的网站上查看完整内容。与 ChatGPT 之前的 2021 年相比，2023 年美国人对人工智能的道德担忧明显更高。其他主要发现包括：<ul><li> 71% 的人支持减缓人工智能发展的政府监管。</li><li> 39% 支持保护有感知力的机器人/人工智能福祉的“权利法案”。</li><li> 68% 的人同意，如果 ChatGPT 或 Bard 等大型语言模型 (LLM) 具备承受痛苦的能力，我们就不能给它们带来不必要的痛苦。</li><li> 20% 的人认为某些人工智能已经具有感知能力； 37% 不确定； 43% 的人表示并非如此。</li><li> 10% 的人说 ChatGPT 有感知能力； 37% 不确定； 53% 的人表示并非如此。</li><li> 23% 的人相信人工智能公司会将安全置于利润之上； 29% 不确定； 49% 的人不这样做。</li><li> 27% 的人相信人工智能的创建者能够保持对当前和未来版本的控制； 27% 不确定； 26% 的人不这样做。</li><li> 49%的人表示人工智能发展步伐太快； 30% 的人说还好； 19% 的人表示他们不确定；只有 2% 的人认为速度太慢。</li></ul></li></ul><p>以下是我们调查问题的数据示例： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/WyAbHFDJYh3pstAMY/qh7gmv0w1ibc4ilzvauh"></p><ul><li>我们的博客文章“<a href="https://www.sentienceinstitute.org/blog/mass-media-propaganda-and-social-influence"><u>大众媒体、宣传和社会影响：Courchesne 等人的有效性证据”。 （2021）</u></a> ”回顾了关于说服力和社会影响的文献，这可能对旨在创造新行为和破坏现有社会政治结构的养殖动物和人工智能安全倡导者有用。</li><li>我们的博客文章“<a href="https://www.sentienceinstitute.org/blog/moral-spillover-in-human-ai-interaction"><u>人机交互中的道德溢出</u></a>”回顾了人机交互中道德溢出的文献。道德溢出是道德态度和行为（例如道德考虑）从一种环境到另一种环境的转移，似乎是道德圈扩展的重要驱动力。</li><li>数字思维的心智能力和能力可能是未来几年人工智能发展轨迹的关键因素。更好地理解它们可能会带来更准确的预测、更好的战略优先顺序以及人工智能安全的具体策略。我们发布了该领域一些关键问题的<a href="https://www.sentienceinstitute.org/blog/key-questions-for-digital-minds"><u>摘要</u></a>。</li><li>我们支持了<i>《人工智能与伦理》</i>中的一篇论文，题为“<a href="https://link.springer.com/article/10.1007/s43681-023-00260-1"><u>人工智能的道德地位如何？</u></a> ”询问人工智能必须满足哪些标准才能获得道德地位——也就是说，为了自身的利益而获得道德考虑。文章认为，所有有感知力的人工智能都应该获得道德地位，并且有充分的理由向一些具有偏好和目标的无感知人工智能授予道德地位。</li><li>我们支持了<i>《Inquiry》</i>中一篇关于“<a href="https://www.tandfonline.com/doi/full/10.1080/0020174X.2022.2144442"><u>数字痛苦：为什么这是一个问题以及如何预防它</u></a>”的论文，该论文提出了一种新策略，用于获得对未来数字思维体验的认知访问并防止数字痛苦，称为<i>访问监控预防</i>（AMP）。</li><li>我们支持了<i>《社会认知》</i>中一篇关于“ <a href="https://www.sentienceinstitute.org/blog/extending-perspective-taking-to-nonhuman-animals"><u>将观点采择扩展到非人类动物和人工实体</u></a>”的论文，详细介绍了两项实验，测试观点采择是否可以在动物和智能人工实体的背景下产生积极影响。</li><li>我们发表了 Brad Saad 撰写的关于“<a href="https://www.sentienceinstitute.org/simulations-and-catastrophic-risks"><u>模拟和灾难性风险</u></a>”的报告，概述了这一交叉点的研究方向。未来的模拟技术可能既会带来灾难性风险，又会提供减少灾难性风险的方法。 Saad 还与另一位 SI 研究员 Ali Ladak 以及该领域的其他三名早期职业研究人员一起，获得了纽约大学研究动物和人工智能意识相关主题的早期职业学者奖。</li></ul><p>有关我们正在进行的研究的更多详细信息，请参阅我们的<a href="https://www.sentienceinstitute.org/research-agenda"><u>研究议程</u></a>。</p><h2>外展</h2><ul><li>2023 年 1 月 5 日，我们为从事数字思维研究的组织举办了第二次小组间电话会议。我们目前正在重新评估这些电话是否是建设领域的最佳方法，因为自 FTX 垮台以来兴趣已经下降。</li><li> 2023 年 4 月 27 日，我们举办了一次研究研讨会，Yochanan E. Bigman<a href="https://www.youtube.com/watch?v=xq5ZhYUi1K8"><u>介绍了</u></a>他关于人工智能态度的研究成果，学术界和独立研究人员参加了研讨会。</li><li>我们于 2022 年 12 月发布了两期由心理学家<a href="https://www.sentienceinstitute.org/podcast/episode-21.html"><u>Matti Wilks</u></a>和哲学家<a href="https://www.sentienceinstitute.org/podcast/episode-22.html"><u>Raphaël Millière</u></a>主持的新播客节目，以及一期由哲学家<a href="https://www.sentienceinstitute.org/podcast/episode-20.html"><u>David Gunkel</u></a>主持的节目。</li><li>在 ChatGPT 推出后的公共媒体热潮中，我们的联合创始人 Jacy Reese Anthis 进行了有关数字思维的广播和播客采访，例如<a href="https://open.spotify.com/episode/2nxBkzQZcVhN2KQZHKy6QP"><u>Chuck Todd</u></a>和<a href="https://open.spotify.com/episode/7tvCfYqd3NgrnVlkSozoId"><u>底特律 NPR</u></a> ，并发表了两篇专栏文章： <a href="https://thehill.com/opinion/cybersecurity/3914567-we-need-an-ai-rights-movement/"><u>“我们需要人工智能权利运动”</u></a> <i>The Hill</i>和<i>沙龙</i>中的<a href="https://www.salon.com/2023/05/18/why-we-need-a-manhattan-project-for-ai-safety/"><u>“为什么我们需要一个用于人工智能安全的‘曼哈顿项目’”</u></a> 。</li><li>杰西还<a href="https://www.theatlantic.com/ideas/archive/2023/05/humans-ai-jacy-reese-anthis-sociologist-perspective/673972/"><u>与</u></a><i>《大西洋月刊》</i>的安妮·洛瑞讨论了数字思维，特别是如何评估推理和感知等心理能力，以及我们如何从人类与动物互动的历史中汲取教训，以促进人类与人工智能互动的未来——无论是人类如何将如何对待人工智能以及人工智能将如何对待人类。</li><li>我们继续通过社交媒体、电子邮件、会议和研讨会上的演示以及与可以利用它的人的会议来分享我们的研究成果。</li></ul><h1> 2023年支出</h1><p>今年到目前为止，我们已花费 227,762 美元，大致细分如下（73% 用于研究，5% 用于外展，22% 用于管理）。在每个类别中，费用主要是员工时间，但也包括数据收集（研究）、播客编辑（外展）和虚拟办公室订阅（管理）等项目。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/WyAbHFDJYh3pstAMY/xcjjlwhjptrl5cxo3kot"></p><p>我们继续维护一个<a href="https://www.sentienceinstitute.org/transparency"><u>透明度</u></a>页面，其中包含年度财务信息、错误的运行列表以及其他公共信息。</p><h1>获得更多资金的空间</h1><p>我们目前的目标是在本捐赠季（2023 年 11 月至 2024 年 1 月）筹集 150,000 美元，以继续我们的数字思维研究和领域建设工作。</p><p>我们知道，随着<a href="https://www.forbes.com/sites/johnhyatt/2022/11/14/sam-bankman-fried-promised-millions-to-nonprofits-research-groups-thats-not-going-too-well-now/"><u>FTX 的崩溃</u></a>以及试图在该领域筹集资金的新兴人工智能组织的迅速扩散，今年的筹款活动将继续困难。我们有足够的空间为高成本效益的项目提供更多资金。我们在 2023 年初进行的最后一轮招聘有 119 名研究员职位申请者，其中包括一些我们没有提供录用但可以通过更多可用资金获得的申请者，如果您有兴趣做出重大贡献，请随时与我们联系讨论我们的扩张空间超过 150,000 美元。</p><p>再次感谢您的宝贵支持。如果您有疑问、反馈或想要合作，请给我发电子邮件： <a href="mailto:michael@sentienceinstitute.org"><u>michael@sentienceinstitute.org</u></a> 。如果您想捐赠，您可以通过我们的网站<a href="https://www.sentienceinstitute.org/donate"><u>通过 PayPal 或支票</u></a>进行捐赠。</p><br/><br/> <a href="https://www.lesswrong.com/posts/WyAbHFDJYh3pstAMY/sentience-institute-2023-end-of-year-summary#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/WyAbHFDJYh3ps​​tAMY/sentience-institute-2023-end-of-year-summary<guid ispermalink="false"> WyAbHFDJYh3ps​​tAMY</guid><dc:creator><![CDATA[michael_dello]]></dc:creator><pubDate> Mon, 27 Nov 2023 12:11:37 GMT</pubDate> </item><item><title><![CDATA[A Question about Corrigibility (2015)]]></title><description><![CDATA[Published on November 27, 2023 12:05 PM GMT<br/><br/><p>最近，我读了<a href="https://cdn.aaai.org/ocs/ws/ws0067/10124-45900-1-PB.pdf"><i>《可修正性》</i></a><i> </i>苏亚雷斯等人。并变得困惑。我遵循了大部分数学推理，但现在正在努力理解这种研究途径的目的或最终目标是什么。我知道 MIRI 现在追求<a href="https://intelligence.org/2018/11/22/2018-update-our-new-research-directions/">不同的研究方向</a>，所以我在这里写的部分或全部内容可能没有实际意义。</p><h2>这一段不是破坏了整个项目吗？</h2><p>在第 2.1 节中，“操纵行为” <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a_1^-"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>被认为。根据<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="U_N"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.084em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">UN</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">（</span></span></span></span></span></span></span></span></span>除非按下关机按钮，否则代理应最大化的“试验”效用函数），此操作会导致效用较低，但会降低按下关机按钮的概率。这样的行为可能具有操纵性，这是有道理的。但作者随后澄清了以下几点：</p><blockquote><p>我们指出，[ <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a_1^-"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span></span>满足的数学条件]无论如何都不是对防止[按下按钮]的操纵动作的必要或充分的描述。满足[这些条件]的某些操作可能是非操纵性的（例如，如果代理花费额外的努力来确保新的子代理是可纠正的，并且这种行为有助于让程序员相信该代理确实是可纠正的）。此外，许多操纵行为可能不具有这种形式<br>（我们将在 4.2 节中看到）。相反，我们考虑一个操纵行为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a_1^-"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span></span> ，它恰好是操纵性的并且具有这种形式，并且表明如果<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="c_{high}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;">g</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span></span></span></span></span>设置得太低，那么 U 将激励 U-agents 更喜欢这个<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a_1^-"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span></span>到<br>默认动作<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a_1^*"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">*</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span></span></p></blockquote><p>嗯不错。但是，如果我们使用的框架中操纵行为与非操纵行为具有完全相同的数学表示，那么这是否表明我们的整个框架是错误的？我们当然需要区分这两种类型的行动吗？这一段不是准确地表明了该模型无法使用效用函数和动作来准确捕获可校正性吗？</p><p>假设我设计了一个效用函数，并在这个框架中证明它从未采取像<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a_1^-"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span></span>这样的欺骗性行为，那么这个证明也将表明我的效用函数不允许进行中描述的那种有用的、非操纵性的行为上面引用的段落。</p><p>相反，如果我确实创建了一个可纠正代理的现实生活实例，它将<i>区分</i>操纵行为和非操纵行为，因此无法以本文中使用的方式对世界进行建模，因为使用了数学表示论文中并不总是正确地区分这两种类型的行为。</p><br/><br/> <a href="https://www.lesswrong.com/posts/oaixvtpGHpkQP3y8C/a-question-about-corrigibility-2015#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/oaixvtpGHpkQP3y8C/a-question-about-corrigibility-2015<guid ispermalink="false"> oaixvtpGHpkQP3y8C</guid><dc:creator><![CDATA[A.H.]]></dc:creator><pubDate> Mon, 27 Nov 2023 12:05:51 GMT</pubDate> </item><item><title><![CDATA[Appendices to the live agendas]]></title><description><![CDATA[Published on November 27, 2023 11:10 AM GMT<br/><br/><p>列表是从<a href="https://www.lesswrong.com/posts/zaaGsFBeDTpCsYHef/shallow-review-of-live-agendas-in-alignment-and-safety">我们的主帖</a>中剪下来的，象征性地提高了可读性。</p><p>我们列出了过去对对齐工作的评论、似乎已死的想法、很酷但被忽视的神经科学/生物学方法、似乎没有任何议程的各种组织，以及一堆不适合其他地方的东西。</p><p></p><h2>附录：先前的列举</h2><ul><li><a href="https://arxiv.org/abs/1805.01109"><u>埃弗里特等人 (2018)</u></a></li><li><a href="https://arxiv.org/abs/2310.19852"><u>吉 (2023)</u></a></li><li> <a href="https://www.lesswrong.com/posts/3pinFH3jerMzAvmza/on-how-various-plans-miss-the-hard-bits-of-the-alignment"><u>苏亚雷斯 (2023)</u></a></li><li> <a href="https://www.lesswrong.com/posts/ncsxcf8CkDveXBCrA/ai-safety-in-a-world-of-vulnerable-machine-learning-systems-1"><u>格利夫和麦克莱恩 (2023)</u></a></li><li> <a href="https://www.alignmentforum.org/posts/a9SPcZ6GXAg9cNKdi/linkpost-some-high-level-thoughts-on-the-deepmind-alignment"><u>Krakovna 和 Shah 谈 Deepmind (2023)</u></a></li><li><a href="https://ai-plans.com/"><u>人工智能计划（2023）</u></a> ，大多无关紧要</li><li><a href="https://www.lesswrong.com/posts/3vDb6EzBpaHqDqQif/some-summaries-of-agent-foundations-work-1"><u>麦克德莫特 (2023)</u></a></li><li> <a href="https://www.alignmentforum.org/posts/FgjcHiWvADgsocE34/a-descriptive-not-prescriptive-overview-of-current-ai"><u>Kirchner 等人 (2022)：无监督分析</u></a></li><li><a href="https://vkrakovna.wordpress.com/2022/06/02/paradigms-of-ai-alignment-components-and-enablers/"><u>Krakovna (2022)</u></a> ，人工智能对齐范式</li><li><a href="https://arxiv.org/abs/2012.07532"><u>胡宾格 (2020)</u></a></li><li> <a href="https://www.alignmentforum.org/posts/4az2cFrJp3ya4y6Wx/resources-for-ai-alignment-cartography"><u>佩雷特 (2020)</u></a></li><li> <a href="https://www.lesswrong.com/posts/SQ9cZtfrzDJmw9A2m/my-overview-of-the-ai-alignment-landscape-a-bird-s-eye-view"><u>难陀 (2021)</u></a></li><li> <a href="https://www.lesswrong.com/posts/QBAjndPuFbhEXKcCr/my-understanding-of-what-everyone-in-technical-alignment-is"><u>拉森 (2022)</u></a></li><li> <a href="https://www.lesswrong.com/posts/8ibDJeoiDuxJkPwfa/various-alignment-strategies-and-how-likely-they-are-to-work"><u>佐尔纳 (2022)</u></a></li><li><a href="https://www.perfectlynormal.co.uk/blog-ai-risk-intro-2"><u>麦克杜格尔 (2022)</u></a></li><li> <a href="https://www.alignmentforum.org/posts/Jgs7LQwmvErxR9BCC/current-themes-in-mechanistic-interpretability-research#Approaches_grounded_in_the_theory_of_causality"><u>Sharkey 等人 (2022)</u></a>关于 interp</li><li> <a href="https://www.alignmentforum.org/posts/HEZgGBZTpT4Bov7nH/mapping-the-conceptual-territory-in-ai-existential-safety"><u>科赫 (2020)</u></a></li><li> <a href="https://www.lesswrong.com/posts/hvGoYXi2kgnS3vxqb/some-ai-research-areas-and-their-relevance-to-existential-1"><u>克里奇 (2020)</u></a></li><li> <a href="https://www.lesswrong.com/posts/nbq2bWLcYmSGup9aF/a-transparency-and-interpretability-tech-tree"><u>胡宾格论可解释性的类型</u></a>(2022)</li><li> <a href="https://www.zotero.org/groups/2420932/tai_safety_bibliography/collections/2BR54QX6"><u>Tai_safety_参考书目 (2021)</u></a></li><li><a href="https://www.lesswrong.com/posts/9TWReSDKyshfA66sz/alignment-org-cheat-sheet"><u>阿卡什和拉森 (2022)</u></a></li><li> <a href="https://www.lesswrong.com/posts/rCJQAkPTEypGjSJ8X/how-might-we-align-transformative-ai-if-it-s-developed-very"><u>卡诺夫斯基平淡计划</u></a>（2022）</li><li> <a href="https://docs.google.com/document/d/1FbTuRvC4TFWzGYerTKpBU7FJlyvjeOvVYF2uYNFSlOc/edit#heading=h.n1wk9bxo847o"><u>斯坦哈特 (2019)</u></a></li><li><a href="https://arxiv.org/abs/1602.03506"><u>拉塞尔 (2016)</u></a></li><li><a href="https://futureoflife.org/landscape/ResearchLandscapeExtended.pdf"><u>外国投资协会 (2017)</u></a></li><li><a href="https://www.alignmentforum.org/posts/dKxX76SCfCvceJXHv/ai-alignment-2018-19-review"><u>沙阿 (2020)</u></a></li><li><a href="https://www.lesswrong.com/tag/research-agendas?sortedBy=new"><u>声称是议程的事情</u></a></li><li><a href="https://docs.google.com/spreadsheets/d/1Us_eYfpzM5qg52aZh2Cc8O13Fdfiy5CMKmzZhN5ItOY/edit#gid=1246461801"><u>Tekofsky 上市独立公司 (2023)</u></a></li><li> <a href="https://www.lesswrong.com/posts/fjgoMaBenyXcRDrbX/boundaries-membranes-and-ai-safety-compilation"><u>这个叫做边界的东西（2023）</u></a></li><li> <a href="https://www.alignmentforum.org/posts/Jgs7LQwmvErxR9BCC/current-themes-in-mechanistic-interpretability-research"><u>Sharkey 等人 (2022)，机械解释员</u></a></li><li><a href="https://pbs.twimg.com/media/F98iVeGX0AAxOoU?format=jpg&amp;name=medium"><u>FLI 治理记分卡</u></a></li><li><a href="https://donations.vipulnaik.com/?cause_area_filter=AI+safety#donationAmountsByDoneeAndYear"><u>钱</u></a><br></li></ul><h2>附录：墓地</h2><ul><li>雄心勃勃的价值学习？</li><li> MIRI youngbloods（见赫巴尔）</li><li> <a href="https://www.lesswrong.com/tag/selection-theorems"><u>JW 选择定理</u></a>??</li><li><a href="https://people.eecs.berkeley.edu/~russell/papers/russell-bbvabook17-pbai.pdf"><u>已证明有益的人工智能</u></a>（但请参阅 Open Agency 和 Omohundro）</li><li> <a href="https://www.lesswrong.com/tag/hch"><u>HCH</u></a> （参见 QACI）</li><li> IDA → 批评和递归奖励模型</li><li>辩论现在称为批评和 ERO</li><li><a href="https://www.alignmentforum.org/posts/YWwzccGbcHMJMpT45/ai-safety-via-market-making"><u>做市商</u></a>（Hubinger）</li><li>逻辑电感器</li><li><a href="https://arxiv.org/abs/2302.00805"><u>调节预测模型：风险和策略</u></a>？</li><li><a href="https://www.lesswrong.com/tag/impact-regularization"><u>影响措施</u></a>、保守机构、副作用→“权力厌恶”</li><li> <a href="https://www.lesswrong.com/posts/GeabLEXYP7oBMivmF/acceptability-verification-a-research-agenda"><u>可接受性验证</u></a></li><li>量化器</li><li><a href="https://www.lesswrong.com/posts/JvZhhzycHu2Yd57RN/causal-scrubbing-a-method-for-rigorously-testing"><u>红木</u></a>插曲？</li><li><a href="https://www.aisafetyhub.org/our-research"><u>人工智能安全中心</u></a></li><li><a href="https://arxiv.org/abs/1702.03465"><u>使机器人能够传达他们的目标</u></a>（早期干预？）</li><li> <a href="https://www.lesswrong.com/posts/PZtsoaoSLpKjjbMqM/the-case-for-aligning-narrowly-superhuman-models"><u>调整狭隘的超人模型</u></a>（Cotra 想法； <a href="https://www.alignmentforum.org/posts/TSxAXeHHhgSxR5wGZ/a-summary-of-aligning-narrowly-superhuman-models"><u>微小的后续行动</u></a>；作为可扩展的监督继续存在？）</li><li>语义可解释性的自动化<ul><li>即自动提出假设，而不仅仅是自动验证它们</li></ul></li><li><a href="https://www.lesswrong.com/tag/oracle-ai"><u>Oracle AI</u></a>并没有消亡，而是 LLM 的所有内容都属于它的职权范围<ul><li>类似地， <a href="https://www.lesswrong.com/tag/tool-ai"><u>AI工具</u></a>是LLM插入特定接口的</li></ul></li><li><a href="https://www.lesswrong.com/posts/AhF8iXLu5PchsmyKf/language-model-tools-for-alignment-research"><u>EleutherAI：#acceleating-alignment</u></a> - AI 对齐助手已上线，但 EleutherAI 目前似乎并未致力于此工作<br></li></ul><h2>附录：AI 对齐的生物学</h2><p>有很多议程，但不清楚除了伯恩斯和蒂尔加特之外是否还有人在积极推动。看起来需要十亿美元。<br></p><h3>人类增强</h3><ul><li><i>一句话总结</i>：也许我们可以为人们提供新的感觉方式，或者更高的概念信息带宽，或者更好的想法生成，或者与深度学习系统的直接接口，或者与传感器的直接接口，或者<a href="https://www.youtube.com/watch?v=6vMO3XmNXe4"><u>迁移学习</u></a>，也许这会有所帮助。我想，古老的<a href="https://fantasticanachronism.com/2021/03/23/two-paths-to-the-future/"><u>超级宝宝</u></a>梦想就在这里了。</li><li><i>变革理论：</i>也许这能让我们更好地进行一致性研究</li></ul><h3>合并</h3><ul><li><i>一句话总结</i>：也许我们可以形成深度学习系统和大脑的网络社会</li><li><i>变革理论：</i>也许这可以让我们通过讨价还价、投票或奇怪的政治来保留一些人类价值观。</li><li><a href="https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism"><u>机器人主义</u></a>,<a href="https://www.lesswrong.com/posts/d74pb97TAqNKwJkc5/bcis-and-the-ecosystem-of-modular-minds"><u>米利奇</u></a>,<a href="https://www.lesswrong.com/posts/gLyRQCg6kp5cqTQTm/collective-identity"><u>杜普伊斯</u></a></li></ul><h3>作为对齐辅助工具</h3><ul><li><i>一句话总结</i>：也许我们可以从大脑数据中获得真正高质量的对齐标签，也许我们可以通过训练人类快速直观地进行激活工程来引导模型，也许我们可以破解真正的人类奖励功能/社会本能，也许我们可以适应其中一些用于 AGI。</li><li><i>变革理论：</i>正如你所猜测的</li><li><i>一些名字</i>： <a href="https://www.lesswrong.com/posts/tj8AC3vhTnBywdZoA/intro-to-brain-like-agi-safety-15-conclusion-open-problems-1"><u>Byrnes</u></a> 、 <a href="https://milan.cvitkovic.net/writing/neurotechnology_is_critical_for_ai_alignment/"><u>Cvitkovic</u></a> <i>、</i> <a href="https://manifund.org/projects/activation-vector-steering-with-bci"><u>Foresight 的 BCI，</u></a><u>还有（来自 Byrnes 的名单）：Eli Sennesh、Adam Safron、Seth Herd、Nathan Helm-Burger、Jon Garcia、Patrick Butlin</u></li></ul><h2><br>附录：研究支持机构</h2><p>示例 {CAIF, FLI} 描述了一个稍微令人困惑的组织类别。通常由具有丰富的协调经验的活跃研究人员管理，但通常不遵循明显的议程，将一篮子策略委托给受资助者，进行领域建设，例如 NeurIPS 研讨会和暑期学校。<br></p><p><a href="https://www.cooperativeai.com/foundation"><u>亚洲金融论坛</u></a></p><ul><li><i>一句话总结</i>：支持研究人员在合作人工智能方面取得差异性进展（例如不能用于制造威胁的预先承诺机制）</li><li><i>一些名字</i>：刘易斯·哈蒙德</li><li><i>预计 FTE 人数：</i> 3</li><li> <i>2023 年的一些成果</i>： <a href="https://www.cooperativeai.com/contests/melting-pot-2023"><u>Neurips 竞赛</u></a>、<a href="https://www.cooperativeai.com/summer-school/2023"><u>暑期学校</u></a></li><li><i>资助方：</i><a href="https://polaris-ventures.org/grants/"><i><u>北极星创投</u></i></a></li><li><i>批评：</i></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> £2,423,943<br></li></ul><p> <a href="https://aisafety.camp/">AISC</a></p><ul><li><i>一句话总结</i>：新研究人员测试适合度和结识合作者的切入点。最近的重点是功能暂停。<a href="https://aisafety.camp/#Projects">仍在继续！</a></li><li><i>一些名字</i>：Remmelt Ellen、Linda Linsefors</li><li><i>预计 FTE 人数：2</i></li><li> <i>2023 年的一些产出</i>：<a href="https://www.lesswrong.com/tag/ai-safety-camp">标签</a></li><li><i>资助者： ?</i></li><li><i>批评：？</i></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> ~200,000 美元</li></ul><p></p><p></p><p>也可以看看：</p><ul><li><a href="https://futureoflife.org/">弗利</a></li><li><a href="https://www.aisafetysupport.org/">艾斯</a></li><li><a href="https://www.pibbss.ai/"><u>PIBBSS</u></a></li><li><a href="https://www.aitracker.org/"><u>格莱斯顿人工智能</u></a></li><li><a href="https://apartresearch.com/"><u>公寓</u></a></li><li><a href="https://www.catalyze-impact.org/team"><u>催化</u></a></li><li><a href="https://ia.effisciences.org/"><u>效率科学公司</u></a></li><li>学生（<a href="https://www.oxai.org/ai-safety"><u>牛津</u></a>、<a href="https://haist.ai/"><u>哈佛大学</u></a>、<a href="https://www.aisig.org/"><u>格罗宁根</u></a>、<a href="https://bristolaisafety.org/about"><u>布里斯托</u></a>、<a href="https://www.cambridgeaisafety.org/start"><u>剑桥</u></a>、<a href="https://stanfordaialignment.org/"><u>斯坦福</u></a>、<a href="https://www.delftaisafety.org/"><u>代尔夫特</u></a>、<a href="https://www.mitalignment.org/"><u>麻省理工</u></a>）<br></li></ul><h2>附录：元、奥秘、更多</h2><ul><li><a href="https://www.lesswrong.com/posts/w6d7XBCegc96kz4n3/the-argument-from-philosophical-difficulty"><u>元哲学</u></a>( <a href="https://www.lesswrong.com/posts/fJqP9WcnHXBRBeiBg/meta-questions-about-metaphilosophy"><u>2023</u></a> ) – Wei Dai，可能 &lt;1 FTE</li><li><a href="https://www.encultured.ai/blog-experiments.html"><u>培养</u></a>-制作游戏</li><li>布里克曼：https: <a href="https://compphil.github.io/truth/"><u>//compphil.github.io/truth/</u></a></li><li><a href="https://algorithmicalignment.csail.mit.edu/"><u>算法对齐</u></a></li><li>McIlrath：<a href="https://www.southampton.ac.uk/~eg/AAMAS2023/pdfs/p1797.pdf"><u>副作用</u></a>和<a href="https://openreview.net/pdf?id=nkn1rcI6wd"><u>具有人类意识的人工智能</u></a></li><li><a href="https://www.lesswrong.com/posts/EjgfreeibTXRx9Ham/ten-levels-of-ai-alignment-difficulty#Table"><u>对齐有多难？</u></a></li><li><a href="https://arxiv.org/abs/2012.11538"><u>有趣的</u></a></li><li><a href="https://www.gov.uk/government/publications/ai-safety-institute-overview"><u>英国政府现在有一个评估/校准实验室</u></a>（Xander Davies、Nitarshan Rajkumar、Krueger、Rumman Chowdhury）</li><li> <a href="https://www.commerce.gov/news/press-releases/2023/11/direction-president-biden-department-commerce-establish-us-artificial"><u>美国政府很快就会有一个类似评估/校准的实验室，USAISI</u></a> 。 （埃尔哈姆·塔巴西？）</li><li><a href="https://arxiv.org/abs/1809.01036"><u>稳健的端到端对齐路线图</u></a>(2018)</li><li><a href="https://arxiv.org/abs/2110.08176"><u>不是理论，但很酷</u></a></li><li><a href="https://www.joshua-greene.net/"><u>格林实验室认知监督</u></a>？他们最接近的是人工智能治理，但他们只得到了 13,800 美元</li><li><a href="https://www.gatoframework.org/gato-framework"><u>GATO 框架</u></a>似乎有一个银河大脑的全球协调和/或自动调整人工智能角度</li><li>Wentworth <a href="https://www.lesswrong.com/s/ehnG4mseKF6xALmQy"><u>2020</u></a> - 适合嵌入式代理的抽象理论。</li><li> <a href="https://www.aintelope.net/"><u>https://www.aintelope.net/</u></a></li><li> <a href="https://araac.au/"><u>ARAAC</u></a> - 制作可以在不同抽象级别用人类语言证明自己（或其他以代码作为输入的代理）的 RL 代理（ <a href="https://link.springer.com/article/10.1007/s00521-023-08586-x"><u>AI 道歉</u></a>，<a href="https://link.springer.com/article/10.1007/s00521-023-08423-1"><u>广泛 XAI 的可解释 RL）</u></a></li><li><a href="https://www.modelingcooperation.com/research"><u>模特合作</u></a></li><li>夹心（ <a href="https://www.lesswrong.com/posts/qwQqZtjWdyDLC4JTB/automated-sandwiching-and-quantifying-human-llm-cooperation"><u>前</u></a>）</li><li><a href="https://www.lesswrong.com/tag/tripwire"><u>绊线</u></a><ul><li><a href="https://www.lesswrong.com/posts/7yEFHisCQSCpLnqWQ/mr-meeseeks-as-an-ai-capability-tripwire"><u>米塞克斯人工智能</u></a></li><li><a href="https://www.lesswrong.com/posts/FgsoWSACQfyyaB5s7/shutdown-seeking-ai"><u>寻求关机的人工智能</u></a></li></ul></li><li>决策理论（<a href="https://www.levinstein.org/research"><u>莱文斯坦</u></a>）</li><li> <a href="https://www.alignmentforum.org/s/FaEBwhhe3otzYKGQt/p/5HtDzRAk7ePWsiL2L#Implementing_Moral_Decision_Making"><i><u>CAIS：机器伦理</u></i></a>——对内在商品和规范因素进行建模，而不是单纯的任务偏好，因为即使在极端的世界变化下，这些也将是相关的；帮助我们避免代理错误指定以及价值锁定。研究现状未知（ <a href="https://arxiv.org/pdf/2310.01405.pdf"><u>RepEng</u></a>中的一些相关位）。</li><li> <a href="https://www.alignmentforum.org/s/FaEBwhhe3otzYKGQt/p/5HtDzRAk7ePWsiL2L#Power_averseness"><i><u>CAIS：权力厌恶</u></i></a>——激励模型避免获得不必要的权力。与轻度优化和权力寻求相关。研究现状未知。</li></ul><br/><br/><a href="https://www.lesswrong.com/posts/GdyYngK9YPdWSRsC6/appendices-to-the-live-agendas#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/GdyYngK9YPdWSRsC6/appendices-to-the-live-agendas<guid ispermalink="false"> GdyYngK9YPdWSRSC6</guid><dc:creator><![CDATA[technicalities]]></dc:creator><pubDate> Mon, 27 Nov 2023 11:10:33 GMT</pubDate> </item><item><title><![CDATA[Shallow review of live agendas in alignment & safety]]></title><description><![CDATA[Published on November 27, 2023 11:10 AM GMT<br/><br/><h1>概括</h1><p>如果您不知道当前资源是什么，则无法优化资源分配。现有的对齐研究地图大多太旧了，无法指导您，而且该领域几乎没有<i>棘轮</i>，没有关于每个人在做什么和为什么、放弃什么和为什么、什么被重命名、什么与什么相关、正在发生什么的常识。</p><p>这篇文章主要只是一个大索引：我们能找到的尽可能多的当前活跃的人工智能安全议程的链接转储。但即使是链接转储也很主观。它将工作映射到概念集群 1-1，旨在回答这样的问题：“我想知道我在那次会议上听到的令人兴奋的想法发生了什么”和“我刚刚读了一篇关于令人惊讶的新见解的文章，想看看还有谁一直在研究这个”，“我想知道大约有多少人正在研究那件事”。</p><p>该文档太长，无法阅读，因此可以按 Ctrl-F 编辑。此外，您也可以分配列表并制作较小的列表。您可以<a href="https://www.lesswrong.com/posts/GdyYngK9YPdWSRsC6/appendices-to-the-live-agendas">在这里</a>找到更多已删除的材料。</p><p>你们中的大多数人应该只阅读社论并浏览您所从事的部分。</p><p>我们的分类：</p><ol><li>了解现有模型（评估、可解释性、深度学习科学）</li><li>控制事物（防止欺骗、模型编辑、价值学习、目标稳健性）</li><li>让人工智能解决这个问题（可扩展的监督、机器人主义等）</li><li>理论（星系脑端到端、代理、可修正性、本体论、合作）<br></li></ol><p>我们不区分大型实验室、个体研究人员和从事类似研究的人员组成的稀疏连接的网络。资金数额和全职员工的估计可能是一个合理的代理。</p><p>我们选择的类别有很大的重叠，并且可以看到“另请参阅”密切相关的工作。</p><p>请指出我们是否错误地将一件事四舍五入、错误分类某人或以其他方式陈述或暗示谎言。<strong>我们将编辑。</strong></p><p>与最近的<a href="https://forum.effectivealtruism.org/posts/BNQMyWGCNWDdP2WyG/2021-ai-alignment-literature-review-and-charity-comparison"><u>Larks 评论</u></a>不同，我们的主要目标并不是直接捐赠。但如果您喜欢阅读本文， <a href="https://www.alignmentforum.org/posts/SbC7duHNDHkd3PkgG/alignment-grantmaking-is-funding-limited-right-now"><u>请考虑</u></a>向<a href="https://manifund.org/about/donate"><u>Manifund</u></a> 、 <a href="https://manifund.org/projects/mats-funding"><u>MATS</u></a>或<a href="https://www.givingwhatwecan.org/en-GB/charities/long-term-future-fund?utm_source=eafunds"><u>LTFF</u></a>或<a href="mailto:funds@lightspeedgrants.org"><u>Lightspeed</u></a>进行大笔捐款：一些好的工作受到资金的瓶颈，而您可以免费获得专家的服务，为好的工作提供资金。<br></p><h1>元</h1><p>当我（加文）进入联盟时（实际上它仍然是“AGI 安全”），人们<a href="http://www.foldl.me/2018/conceptual-issues-ai-safety-paradigmatic-gap/"><u>警告</u></a>我这是前范式的。他们是对的：在接下来的五年里，现场议程完全<a href="https://arxiv.org/pdf/1805.01109.pdf"><u>改变</u></a>了。 <span class="footnote-reference" role="doc-noteref" id="fnref06qm74k93eh7"><sup><a href="#fn06qm74k93eh7">[1]</a></sup></span>这里有一个更新。</p><p>我希望这是一个直接的技术对齐文档，但人们指出这将排除<i>大多数</i>工作（例如评估和非雄心勃勃的可解释性，它们是安全的，但不是对齐的），所以我将其设为技术 AGI 安全文档。再加上变化。</p><p>唯一的选择标准是“我听说过并且 >;= 1 人最近正在研究它”。我不参加聚会，所以可能会晚几个月。</p><p>显然，这是治理和倡导年，但我排除了所有这些好的工作：就其本质而言，它会引起关注。我也没有找到<a href="https://openreview.net/forum?id=RdJVFCHjUMI"><u>那些</u></a><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321"><u>不将</u></a>自己的工作视为一致的<a href="https://arxiv.org/abs/2211.14946"><u>普通</u></a><a href="https://blog.normalcomputing.ai/posts/2023-09-12-supersizing-transformers/supersizing-transformers.html"><u>实验室</u></a><a href="https://huggingface.co/papers/2310.16944"><u>和</u></a><a href="https://arxiv.org/abs/2306.03341"><u>学者</u></a><a href="https://arxiv.org/abs/2205.01447"><u>的</u></a>显着数量。也不是秘密工作。</p><p><i><strong>契诃夫的评价</strong></i>：我包括了尤德科夫斯基的作战<a href="https://www.lesswrong.com/posts/keiYkaeoLHoKK4LYA/six-dimensions-of-operational-adequacy-in-agi-projects"><u>标准</u></a>（值得信赖的指挥？，封闭？，行动安全？，对共同利益的承诺？，结盟心态？），但我自己不给它们打分。重点不是要遮遮掩掩，而是要提醒你，我们常常对彼此知之甚少。</p><p>你不太可能喜欢我对子字段的划分； <a href="https://docs.google.com/document/d/e/2PACX-1vRyMTQQprqaFrpydGTwsHm0BnFQf5CXC9T754UeXtkwiNVQx7N5LGki51L05_L3g1wK4_n1llVGvZ9R/pub"><u>还有</u></a>其他的。</p><p>没有人读过所有这些材料，包括我们。条目尽可能基于公共文档或私人信件，但该帖子可能仍包含超过 10 个不准确的说法。<strong>我们鼓励对我们大喊大叫。</strong>如果我错过了你（或错过了重点），请注意你自己。 5年后见。<br></p><h1>社论</h1><ul><li>现在，结盟已经足够出名，以至于巴拉克·奥巴马(Barack Obama)都<a href="https://barackobama.medium.com/statement-on-the-biden-administrations-executive-order-on-artificial-intelligence-91a5ddac6238"><u>在</u></a>谈论它。这将吸引登山者、骗子、好心人以及那些只是滥用这个词的人，因为它客观上令人困惑，并吸引金钱和善意。由于动机性语义蠕变，我们已经不得不半放弃“人工智能安全”。<br></li><li>低信心：Mech interp 现在可能已经拥有了自己的一部分人（尽管我承认这是一个非常清晰的入口，并且有很多预先咀嚼的项目准备就绪）。<br></li><li> <a href="https://www.matsprogram.org/"><u>MATS</u></a>效果很好（平均而言，方差较高）。伦敦延伸是一个非常好的主意。他们刚刚从 SFF 获得 18.5 万美元，但<a href="https://manifund.org/projects/mats-funding"><u>仍然</u></a>受到限制。<br></li><li>不包括治理工作就遗漏了许多很酷的“技术政策”：<a href="https://epochai.org/"><u>预测</u></a>、<a href="https://arxiv.org/abs/2303.11341"><u>计算监控</u></a>、<a href="https://arxiv.org/abs/2210.08674"><u>去信任模型验证</u></a>、<a href="https://www.matsprogram.org/safety"><u>安全案例</u></a>。<br></li><li>全新类型的人正在做出贡献，这很好。我想到的是 PIBBSS 和 CAIS 哲学家、SLT 暴民和 Eleuther 的不和谐能量。<br></li><li>大型实验室似乎将农场的赌注押在了可扩展的监督上。这依赖于没有巨大的能力峰值，也没有不可逆转的误解。<br></li><li>不协调且仅部分范式领域的事实上的议程是<a href="https://www.lesswrong.com/posts/D4gEDdqWrgDPMtasc/thoughts-on-process-based-supervision-1"><u>基于流程的监督</u></a>/<a href="https://onlinelibrary.wiley.com/doi/full/10.1111/1758-5899.12786"><u>纵深防御</u></a>/<a href="https://www.lesswrong.com/posts/YnGRBADQwpYRbuCbz/towards-hodge-podge-alignment-1"><u>大杂烩</u></a>/<a href="https://www.lesswrong.com/posts/MCWGCyz2mjtRoWiyP/endgame-safety-for-agi"><u>残局安全</u></a>/ <a href="https://forum.effectivealtruism.org/posts/yCx3kCReJtucpdd33/the-current-alignment-plan-and-how-we-might-improve-it-or#v1_Plan"><u>Shlegeris v1</u></a> 。我们将把在子 AGI 中工作的十几个东西放在一起，并希望：RLHF/DPO + <a href="https://www.greaterwrong.com/posts/JcLhYQQADzTsAEaXd/ai-as-a-science-and-three-obstacles-to-alignment-strategies#comment-7iBb7aF4ctfjLH6AC"><u>大规模</u></a><a href="https://twitter.com/jd_pressman/status/1718798739266212325"><u>激活修补</u></a>+ 范围模型缩小 + 装箱 + 可疑的可扩展监督 + 短视训练 +<a href="https://arxiv.org/abs/2302.08582"><u>数据管理</u></a>+ 合格的自动对齐研究（证明助手）+ …我们还将通过创建（可破解的，本身会减慢 OODA）安全文化来减慢速度。谁知道。<br></li></ul><h1>议程</h1><h2>1.了解现有模型</h2><p><a href="https://en.wikipedia.org/wiki/Characterization_(materials_science)"><i>表征</i></a><br></p><h3>埃瓦尔斯</h3><p>（弄清楚经过训练的模型的行为方式。）<br></p><p><i>各项</i><a href="https://www.openphilanthropy.org/research/rfps-on-llm-impacts/"><i><u>能力评估</u></i></a></p><ul><li><i>一句话总结</i>：制作能够真正检查模型是否具有某种能力/错位模式的工具。我们默认对巨大的潜在空间进行低n采样，但目标是做得更好。</li><li><i>变革理论：</i>大多数模型在首次训练和发布时都有能力悬置；我们应该密切关注何时获得哪些功能，以便前沿模型开发人员更好地了解哪些安全措施已经是必要的（希望他们能够推断并最终恐慌）。</li><li>将<a href="https://evals.alignment.org/"><u>ARC Evals</u></a> <i>、</i> <a href="https://arxiv.org/abs/2305.15324"><u>Deepmind</u></a> 、 <a href="https://cavendishlabs.org/publications/"><u>Cavendish</u></a> 、<a href="https://arxiv.org/abs/2309.00667"><u>态势感知</u></a>团队、 <a href="https://www.matsprogram.org/evals"><u>Evans 和 Ward</u></a> 、 <a href="https://www.apolloresearch.ai/blog/understanding-da-and-sd"><u>Apollo</u></a>组合在一起。另见<a href="https://www.lesswrong.com/s/SAjYaHfCAGzKsjHZp"><u>模型心理学</u></a>；神经科学：心理学：：可解释性：模型心理学。另请参见<a href="https://www.alignmentforum.org/posts/dBmfb76zx6wjPsBC7/when-can-we-trust-model-evaluations"><u>对齐评估</u></a>。另请参阅<a href="https://arxiv.org/abs/2304.11158"><u>能力</u></a><a href="https://arxiv.org/abs/2202.07785"><u>预测</u></a>和数百名巨魔进行<i>分散</i><a href="https://www.youtube.com/watch?v=g7YJIpkk7KM"><u>式</u></a><a href="https://twitter.com/jbrowder1/status/1652387444904583169"><u>评估</u></a>。</li><li><i>一些名字：</i> Mary Phuong、Toby Shevlane、Beth Barnes、Holden Karnofsky、Lawrence Chan、Owain Evans、Francis Rhys Ward、Apollo、Palisade</li><li><i>估计 FTE 数：</i> 13 (ARC)，其他地方约 50</li><li> <i>2023 年的一些成果</i>： <a href="https://arxiv.org/abs/2310.03302"><u>AI 人工智能研究</u></a>、<a href="https://evals.alignment.org/Evaluating_LMAs_Realistic_Tasks.pdf"><u>自主性</u></a>、<a href="https://arxiv.org/abs/2304.03279"><u>回报是否合理？</u></a> ，<a href="https://arxiv.org/abs/2304.12280"><u>固执</u></a>。为 GPT 的发展<a href="https://www.lesswrong.com/posts/43C3igfmMrE9Qoyfe/scaffolded-llms-as-natural-language-computers"><u>命名</u></a>是很有用的。<a href="https://www.alignmentforum.org/tag/ai-evaluations"><u>标签</u></a>。</li><li><i>评论：</i> <a href="https://www.alignmentforum.org/posts/uqAdqrvxqGqeBHjTP/towards-understanding-based-safety-evaluations"><i><u>Hubinger</u></i></a> <i>、</i> <a href="https://www.alignmentforum.org/posts/dBmfb76zx6wjPsBC7/when-can-we-trust-model-evaluations"><i><u>Hubinger</u></i></a> <i>、</i> <a href="https://www.lesswrong.com/posts/XCRsg2ZnHBNAN862T/improving-the-safety-of-ai-evals"><i><u>Shovelain 和 Mckernon</u></i></a> <i>&nbsp;</i></li><li><i>资助者：</i>各种。 <i>&nbsp;</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> ~~20,000,000 美元，不包括政府的新努力<br></li></ul><p><a href="https://www.anthropic.com/index/frontier-threats-red-teaming-for-ai-safety"><i><u>各种各样的</u></i></a><i>&nbsp;</i><a href="https://www.deepmind.com/blog/red-teaming-language-models-with-language-models"><i><u>红队</u></i></a></p><ul><li><i>一句话总结</i>：让我们攻击当前模型，看看它们做了什么/故意在当前前沿模型上诱发坏事，以检验我们的理论/方法。另请参阅<a href="https://forum.effectivealtruism.org/posts/yCx3kCReJtucpdd33/the-current-alignment-plan-and-how-we-might-improve-it-or#Gain_of_function"><u>功能实验增益</u></a>（制作演示和错位玩具模型。另请参阅“提供批评的模型”。另请参阅：威胁建模（ <a href="https://www.alignmentforum.org/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1"><u>Model Organisms</u></a> <u>、</u> <a href="https://arxiv.org/abs/2304.06528"><u>Powerseeking</u></a> 、 <a href="https://www.apolloresearch.ai/blog/understanding-da-and-sd"><u>Apollo</u></a> ）；<a href="https://arxiv.org/abs/2310.18512"><u>隐写术</u></a>；OpenAI 超级对齐计划的<a href="https://www.lesswrong.com/posts/Hna4aoMwr6Qx9rHBs/linkpost-introducing-superalignment?commentId=phFqC2EdDALCFwr56"><u>一部分</u></a>；<a href="https://arxiv.org/abs/2302.10894"><u>特洛伊木马</u></a>（ <a href="https://trojandetection.ai/tracks"><u>CAIS</u></a> ）； <a href="https://www.alignmentforum.org/posts/atBQ3NHyqnBadrsGP/latent-adversarial-training#comments"><u>潜在对抗训练</u></a>是一个不寻常的例子。</li><li><i>一些名字：</i> Stephen Casper、Lauro Langosco、Jacob Steinhardt、Nina Rimsky、Jeffrey Ladish/Palisade、Ethan Perez、Geoffrey Irving、 <a href="https://www.vice.com/en/article/jg5ew4/gpt4-hired-unwitting-taskrabbit-worker"><u>ARC Evals</u></a> 、Apollo、Dylan Hadfield-Menell/ <a href="https://algorithmicalignment.csail.mit.edu/team/"><u>AAG</u></a></li><li><i>估计 FTE 数：</i> ?</li><li> <i>2023 年的一些产出</i>： <a href="https://www.alignmentforum.org/posts/iHmsJdxgMEWmAfNne/red-teaming-language-models-via-activation-engineering"><u>Rimsky</u></a> 、 <a href="https://far.ai/publication/wang2022adversarial/"><u>Wang</u></a> 、 <a href="https://arxiv.org/abs/2307.02483"><u>Wei</u></a> 、 <a href="https://arxiv.org/abs/2306.12105"><u>Tong</u></a> 、 <a href="https://arxiv.org/abs/2306.09442"><u>Casper</u></a> 、 <a href="https://arxiv.org/abs/2311.00117"><u>Ladish</u></a> 、 <a href="https://docs.google.com/document/d/1xdidMGrzHDIJ5sG2h1TKb-HiGh-hgsMY3jugnvd6Aqo/edit#heading=h.9axbdg9kpll0"><u>Langosco</u></a> 、 <a href="https://arxiv.org/abs/2311.03348"><u>Shah</u></a> 、 <a href="https://arxiv.org/abs/2311.07590"><u>Scheurer</u></a> 、 <a href="https://algorithmicalignment.csail.mit.edu/research/"><u>AAG</u></a> 、2022 年： <a href="https://arxiv.org/abs/2202.03286"><u>Irving</u></a></li><li><i>批评：</i> ？</li><li><i>资助者：各种</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i>大<br><br></li></ul><p><i>引发模型异常</i></p><ul><li><i>一句话总结</i>：以一种既不追求功能也不完全是红队的方式寻找当前模型的奇怪特征。想想<a href="https://arxiv.org/abs/2306.09479"><u>逆缩放</u></a>、 <a href="https://www.alignmentforum.org/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation"><u>SolidGoldMagikarp</u></a> 、<a href="https://arxiv.org/abs//2309.12288"><u>反转诅咒</u></a>，<a href="https://openreview.net/forum?id=X3JFgY4gvf"><u>断章取义</u></a>。不是一个议程，而是对其他人的乘数。</li><li><i>变革理论：</i>也许异常和边缘情况告诉我们一些关于模型的深层信息；你需要数据来推理。<br><br></li></ul><p> <a href="https://manifold.markets/RyanGreenblatt/redwood-research-will-we-publish-a-98d97ff076da"><i><u>红木：对照评估</u></i></a></p><ul><li><i>一句话总结</i>：评估人类/组织：通过默默地交换故意错位的模型，评估在特定场景中部署模型的特定协议的风险。在 sim 中执行场景，直到 1) 发生灾难，2) 你的协议自信地发现红队模型，或者 3) 场景结束时没有发生灾难。还进行对抗性评估（使用可信和不可信模型监控不可信模型输出）。 <a href="https://www.alignmentforum.org/posts/MbWWKbyD5gLhJgfwn/meta-level-adversarial-evaluation-of-oversight-techniques-1"><u>前任</u></a>。</li><li><i>变革理论：</i>通过自动评估和部署计划的风险评估来防止高风险失败。</li><li><i>一些名字：</i> Buck Shlegeris、Ryan Greenblatt、Kshitij Sachan</li><li><i>预计 FTE 人数：</i> 10？</li><li> <i>2023 年的一些成果</i>： <a href="https://www.alignmentforum.org/posts/MbWWKbyD5gLhJgfwn/meta-level-adversarial-evaluation-of-oversight-techniques-1"><u>大文章</u></a>，另一篇文章正在制作中</li><li><i>批评：</i> <a href="https://forum.effectivealtruism.org/posts/DaRvpDHHdaoad9Tfu/critiques-of-prominent-ai-safety-labs-redwood-research"><i><u>一般组织</u></i></a></li><li><i>资助者：开放菲尔</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> <a href="https://www.openphilanthropy.org/grants/redwood-research-general-support-2023/"><i><u>5,300,000 美元</u></i></a><i>（去年整个组织）</i><br><br></li></ul><p><a href="https://acsresearch.org/"><i><u>复杂系统的协调</u></i></a><i>：法学硕士相互作用</i></p><ul><li><i>一句话总结</i>：了解法学硕士的相互作用及其局限性，并从实证工作转向关于法学硕士复杂系统的更一般的假设，例如混合系统和支架模型中的网络效应。</li><li><i>变革理论：</i>有时，总体比个体更容易预测/推理：细节平均化。因此，尝试一下法学硕士的互动（操纵、冲突解决、系统偏见等）。直接研究未来大型系统中的LLM交互（与当前的单一焦点相反）；防止系统性的不良设计并为未来的模型提供信息。</li><li><i>一些名字：</i> Jan Kulveit、Tomáš Gavenčiak、Ada Böhm</li><li><i>预计 FTE 人数：</i> 4</li><li> <i>2023 年的一些成果</i>：<a href="https://github.com/acsresearch/interlab"><u>软件</u></a>和对法学硕士的<a href="https://acsresearch.org/posts"><u>见解</u></a></li><li><i>批评：</i> <a href="https://www.alignmentforum.org/posts/H5iGhDhQBtoDpCBZ2/announcing-the-alignment-of-complex-systems-research-group?commentId=frEufx3c6cRmhDjbh">Yudkowsky</a>对接口思想的看法</li><li><i>资助方：</i> SFF</li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> ~300,000 美元<br></li></ul><h3>其他评估（监管基础）</h3><p> Evals 组织和治理团队的大部分工作是其他的：开发<a href="https://www.rand.org/content/dam/rand/pubs/testimonies/CTA2700/CTA2723-1/RAND_CTA2723-1.pdf"><i><u>政治上清晰的</u></i></a><a href="https://www.alignmentforum.org/posts/Zfk6faYvcf5Ht7xDx/compute-thresholds-proposed-rules-to-mitigate-risk-of-a-lab"><u>指标</u></a>、<a href="https://www.matsprogram.org/safety"><u>流程</u></a>/<a href="https://twitter.com/apolloaisafety/status/1721594465716928751"><u>令人震惊的</u></a><a href="https://www.bbc.co.uk/news/technology-67302788.amp"><u>案例</u></a>研究。目的是激励和支持实际合理的监管。</p><p>这是一项重要的工作——可以说是短期内影响力最大的工作。但这是一个技术调整帖子。我添加这一部分是为了强调这些其他评估与理解危险能力如何已经或可能出现不同。<br></p><h3>可解释性</h3><p>（弄清楚经过训练的模型实际上正在计算什么。） <span class="footnote-reference" role="doc-noteref" id="fnref0q1picyzu4d"><sup><a href="#fn0q1picyzu4d">[2]</a></sup></span><br></p><p> <a href="https://forum.effectivealtruism.org/posts/zcHdehWJzDpfxJpmf/what-i-would-do-if-i-wasn-t-at-arc-evals#Ambitious_mechanistic_interpretability"><i><u>雄心勃勃的机械解释员</u></i></a></p><ul><li>从学习算法的完整自下而上电路级重构的意义上来说。</li><li><i>一句话总结</i>：自动找到所有事情的电路，然后弄清楚模型是否会做坏事（哪个算法实现哪个计划；具有合理数量节点的完整因果图）；任何会做坏事的模型都可以被删除或编辑。</li><li><i>变革理论：</i>通过本体识别、欺骗和规划审计、一致性研究的力量倍增器、干预使训练更安全、推理时间控制来对假设的实时监控采取行动来帮助一致性。迭代那些不计划的事情。另请参阅可扩展的监督。</li><li><i>一些名字：</i> Chris Olah、Lee Sharkey、Neel Nanda、Steven Bills、Nick Cammarata、Leo Gau、William Saunders、Apollo（私人作品）</li><li><i>预计全职员工人数：</i> 80？ （Anthropic、Apollo、DeepMind、OpenAI、各种较小的组织）</li><li> <i>2023 年的一些输出</i>：<a href="https://transformer-circuits.pub/2023/monosemantic-features"><u>单语义特征</u></a>、<a href="https://arxiv.org/pdf/2311.03658.pdf"><u>线性表示假设</u></a>似乎即将得到证实； <a href="https://www.lesswrong.com/posts/L8LHBTMvhLDpxDaqv/research-agenda-formalizing-abstractions-of-computations-1"><u>Jenner</u></a> ,<a href="https://arxiv.org/abs/2302.03025"><u>普遍性</u></a>, <a href="https://arxiv.org/abs/2307.09458"><u>Lieberum</u></a> , <a href="https://www.lesswrong.com/posts/wjQkQ8bgWWFym8zF9/distilled-representations-research-agenda-1"><u>蒸馏代表</u></a><ul><li><i>自动化：</i> <a href="https://arxiv.org/abs/2304.14997"><i><u>ACDC</u></i></a> <i>、</i> <a href="https://openai.com/research/language-models-can-explain-neurons-in-language-models"><i><u>较大模型读取较小模型</u></i></a><i>、</i><a href="https://arxiv.org/pdf/2309.08600.pdf"><i><u>较大模型的稀疏模型</u></i></a></li><li><i>逆向工程。尚不清楚这是否会被进一步推动。 2022：</i><a href="https://transformer-circuits.pub/"><i><u>人择电路</u></i></a><i>、</i> <a href="https://www.alignmentforum.org/posts/DZk6mRo9vhCXN9Rfn/a-walkthrough-of-interpretability-in-the-wild-w-authors"><i><u>野外可解释性</u></i></a><i>、</i> <a href="https://www.neelnanda.io/blog/interlude-a-mechanistic-interpretability-analysis-of-grokking"><i><u>Grokking mod 算术</u></i></a></li></ul></li><li><i>评论：</i> <a href="https://docs.google.com/document/d/e/2PACX-1vTd5abxOSLcbq5wkUln7v2bVWvrEdsazQZZXfufEhgDycEktM_0jxvRAePEtFQNA2T84bXsJqeeEVl_/pub"><i><u>总结如下</u></i></a><i>：</i> <a href="https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1"><i><u>Charbel</u></i></a> <i>、</i> <a href="https://www.lesswrong.com/posts/FDrgcfY8zs5e2eJDd/charbel-raphael-and-lucius-discuss-interpretability"><i><u>Bushnaq</u></i></a> <i>、</i> <a href="https://www.alignmentforum.org/s/a6ne2ve5uturEEQK7/p/7TFJAvjYfMKxKQ4XS"><i><u>Casper</u></i></a> <i>、</i> <a href="https://www.lesswrong.com/posts/HdqdqNC3MyABHzSqf/the-risk-reward-tradeoff-of-interpretability-research"><i><u>Shovelain &amp; Mcckernon</u></i></a> <i>、</i> <a href="https://www.lesswrong.com/posts/pQqoTTAnEePRDmZN4/agi-automated-interpretability-is-suicide"><i><u>RicG</u></i></a> <i>、</i> <a href="https://www.lesswrong.com/posts/uhMRgEXabYbWeLc6T/why-and-when-interpretability-work-is-dangerous"><i><u>Kross</u></i></a> <i>、</i> <a href="https://www.lesswrong.com/posts/iDNEjbdHhjzvLLAmm/should-we-publish-mechanistic-interpretability-research"><i><u>Hobbhahn</u></i></a> <i>。</i></li><li><i>资助者：各种</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br></li></ul><p><a href="https://www.matsprogram.org/concept"><i><u>基于概念的解释</u></i></a><i>&nbsp;</i></p><ul><li><i>一句话总结</i>：如果事实证明对模型的彻底理解太难/不可能，我们仍然可以进入某种高抽象层次，并仍然避免错位的 AGI。又名“高级可解释性”。</li><li><i>变革理论：</i>构建可以输出模型内部目标或功能的可能和预测性表示的工具，从而解决内部一致性问题。</li><li><i>一些名字：</i> Erik Jenner、Jessica Rumbelow、Stephen Casper、Arun Jose、Paul Colognese</li><li><i>估计 FTE 数： ?</i></li><li> <i>2023 年的一些成果</i>： <a href="https://www.lesswrong.com/posts/tFYGdq9ivjA3rdaS2/high-level-interpretability-detecting-an-ai-s-objectives"><u>高级可解释性</u></a>、 <a href="https://www.lesswrong.com/posts/hhKpXEsfAiyFLecyF/internal-target-information-for-ai-oversight"><u>人工智能监督的内部目标信息</u></a></li><li><i>批评：</i></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br></li></ul><p><a href="https://ai.stanford.edu/blog/causal-abstraction/"><i><u>因果抽象</u></i></a></p><ul><li><i>一句话概括</i>：Wentworth <a href="https://www.lesswrong.com/s/ehnG4mseKF6xALmQy"><u>2020</u></a> ；部分描述神经网络或其他计算正在使用的“算法”，同时丢弃不相关的细节。</li><li><i>变革理论：</i>找到给定计算的所有可能的抽象 ->; 将它们翻译成人类可读的语言 ->; 识别有用的抽象，例如欺骗 ->; 在模型执行此操作时进行干预。还发展更广泛的 interp 理论作为乘数；更数学化（希望更通用）的分析。</li><li><i>一些名字：</i>埃里克·詹纳、阿蒂克斯·盖革</li><li><i>估计 FTE 数： ?</i></li><li> <i>2023 年的一些成果</i>： <a href="https://www.alignmentforum.org/posts/L8LHBTMvhLDpxDaqv/research-agenda-formalizing-abstractions-of-computations-1"><u>詹纳议程</u></a>、<a href="https://arxiv.org/abs/2301.04709"><u>忠实模型解释的因果抽象</u></a></li><li><i>批评：</i></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br></li></ul><p> <a href="https://www.eleuther.ai/interpretability"><i><u>EleutherAI</u></i></a><i>解释器</i></p><ul><li><i>一句摘要</i>：研究诸如培训路径依赖性等问题的工具。</li><li><i>变革理论：</i>制造出惊人的工具来推动可解释性的前沿。</li><li><i>一些名字：</i> Stella Biderman，Nora Belrose，Ai_waifu，Shivanshu Purohit</li><li><i>估计的＃ftes：〜12</i>加~~ 50兼职志愿者</li><li><i>2023年的一些输出</i>： <a href="https://arxiv.org/abs/2306.03819"><u>Leace</u></a> （另请参见手术模型编辑）；<a href="https://arxiv.org/abs/2303.08112"><u>调谐镜头</u></a>； CCS的改进： <a href="https://www.theojaffee.com/p/7-nora-belrose#details"><u>VINC</u></a> ；<a href="https://github.com/EleutherAI/elk-generalization"><u>麋鹿的概括</u></a></li><li><i>批评：</i></li><li><i>资助：拥抱面，稳定性AI，Nat Friedman，Lambda Labs，Canva，Coreweave</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：$ 2,000,000？ （猜测）</i><br></li></ul><p> <a href="https://www.lesswrong.com/posts/L4anhrxjv8j2yRKKp/how-discovering-latent-knowledge-in-language-models-without#Our_Paper"><i><u>激活工程</u></i></a><i>（作为无监督的插入）</i></p><ul><li><i>一句话摘要</i>：干预模型表示，因此在出现不诚实，动力和其他内在风险时获得良好的因果证据；还测试可解释性理论和编辑理论。另请参见下面“模型编辑”下的同名部分。</li><li><i>变革理论：</i>测试可解释性理论作为变革理论的一部分；从可解释的因果干预措施中查找有关表示的新见解。无监督意味着没有注释偏见，这降低了提取超人表示的障碍。</li><li><i>一些名字：</i> Alex Turner，Collin Burns，Andy Zou，KaarelHänni，Walter Laurito， <a href="https://cadenzalabs.org/research/#research-agenda"><u>Cadenza</u></a> （ <a href="https://manifund.org/projects/cadenza-labs-ai-safety-research-group-working-on-own-interpretability-agenda"><u>仿佛</u></a>）</li><li><i>估计的＃ftes：〜15</i></li><li> <i>2023年的一些输出</i>：去年<a href="https://arxiv.org/abs/2212.03827"><u>著名的CCS</u></a> ， <a href="https://www.lesswrong.com/posts/5spBue2z2tw4JuDCx/steering-gpt-2-xl-by-adding-an-activation-vector"><u>RL和GPTS中的转向向量</u></a>， <a href="https://www.lesswrong.com/posts/bFwigCDMC5ishLz7X/rfc-possible-ways-to-expand-on-discovering-latent-knowledge"><u>Cadenza RFC</u></a> ， <a href="https://www.lesswrong.com/posts/Go5ELsHAyw7QrArQ6/searching-for-a-model-s-concepts-by-their-shape-a"><u>概念的形状</u></a>。 <a href="https://www.alignmentforum.org/posts/bWxNPMy5MhPnQTzKz/what-discovering-latent-knowledge-did-and-did-not-find-4"><u>罗杰实验</u></a>。另请参见<a href="https://arxiv.org/abs/2310.01405"><u>表示工程</u></a>。</li><li><i>批评：</i></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br></li></ul><p><a href="https://www.leap-labs.com/"><i><u>飞跃</u></i></a></p><ul><li><i>一句话摘要</i>：销售可解释性API的研究创业公司（视觉模型的模型不合时宜的功能）。旨在与数据无关（“想要直接从模型中提取信息，几乎不依赖培训或测试数据”）和全局（“ Mech Interp不够，我们需要捕获Gestalt的整体方法”））））） 。</li><li><i>变革理论：</i>制造人们想要使用的安全工具，现实生活中的压力测试方法，为自下而上的电路分析提供了强有力的替代方法。</li><li><i>一些名字：</i>杰西卡·伦贝洛（Jessica Rumbelow）</li><li><i>估计＃ftes：</i> 5</li><li> <i>2023年的一些输出</i>：<a href="https://arxiv.org/pdf/2309.17144.pdf"><u>原型生成</u></a></li><li><i>批评：？</i></li><li><i>资助者：私人投资者</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：途中数百万</i><br></li></ul><h3>了解学习</h3><p>（弄清楚该模型如何弄清楚。）<br></p><p> <i>Timaeu​​s：</i> <a href="https://www.alignmentforum.org/posts/TjaeCWvLZtEDAS5Ex/towards-developmental-interpretability"><i><u>发展性解释性</u></i></a><i>和</i><a href="https://timaeus.co"><i><u>奇异学习理论</u></i></a><i>&nbsp;</i></p><ul><li><i>单句摘要</i>：构建用于检测，定位和解释模型中培训和文本学习的相变的工具，灵感来自奇异学习理论（SLT），统计物理学和发展生物学的概念。</li><li><i>变化理论：</i>当神经网络中的结构形成时，它可以留下清晰的发育痕迹，我们可以解释以弄清楚该结构的实现以及如何实现。这为可扩展的自动解释性铺平了一种方法。特别是，在学习过程结束时进行干预可能是没有希望的，因此我们希望尽早抓住并防止欺骗性以及其他危险的能力和价值观。</li><li><i>一些名字：</i> Jesse Hoogland，Alexander Gietelink Oldenziel，Daniel Murfet，Stan Van Wingerden</li><li><i>估计＃ftes：</i> 10</li><li> <i>2023年的某些输出</i>：<a href="https://arxiv.org/abs/2310.06301"><u>动态相变</u></a>，<a href="https://arxiv.org/abs/2308.12108"><u>单数模型中的退化</u></a>；另请参见<a href="https://arxiv.org/abs/2304.11158"><u>Eleuther</u></a>的<a href="https://github.com/EleutherAI/pythia"><u>毕曲察</u></a></li><li><i>批评：</i> <a href="https://www.lesswrong.com/s/SfFQE8DXbgkjk62JK/p/TjaeCWvLZtEDAS5Ex#Reasons_it_won_t_work"><u>自我</u></a>， <a href="https://www.lesswrong.com/posts/DqLHvJjuPdtrzuoas/my-impression-of-singular-learning-theory"><u>ege</u></a> ， <a href="https://www.alignmentforum.org/posts/ALJYj4PpkqyseL7kZ/my-criticism-of-singular-learning-theory"><u>skalse</u></a></li><li><i>资助者：</i><a href="https://manifund.org/projects/scoping-developmental-interpretability-xg55b33wsfc"><u>仿真</u></a></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：$ 145,000</i><br></li></ul><p> <a href="https://docs.google.com/document/d/1CdPvKZQzrkTCFIMfHNr0uukbTGhNF0ohZn_am4Z8kzo/edit#heading=h.9lmc73wscx1r"><i><u>Levoso算法可解释性</u></i></a></p><ul><li><i>一句话摘要</i>：在<a href="https://arxiv.org/abs/2210.14215"><u>Google的广告</u></a>上执行机械性解释性，以弄清模型是否在上下文中学习RL。</li><li><i>变更理论：</i>使用玩具模型获取有关与代理和优化相关的任何事物的实际数据，或者至少基础一些直觉 - >;围绕台面优化器，训练动态等的话语变得不那么困惑 - >;向安全AI迈进。</li><li><i>一些名字：</i>维克多·莱沃索（Victor Levoso）</li><li><i>估计＃ftes：</i> 1</li><li> <i>2023年的一些输出</i>：？</li><li><i>批评：</i></li><li><i>资助者：</i> Lightspeed</li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> 86,000美元<br></li></ul><p>其他各种努力：</p><ul><li> Grokking（ <a href="https://www.neelnanda.io/blog/interlude-a-mechanistic-interpretability-analysis-of-grokking"><u>Lieberum＆Nanda</u></a> ， <a href="https://www.lesswrong.com/posts/JK2QGfNGLjuFnrEvz/explaining-grokking-through-circuit-efficiency"><u>Shah随访</u></a>）。<a href="https://www.lesswrong.com/s/5omSW4wNKbEvYsyje/p/GpSzShaaf8po4rcmA"><u>教皇的批评</u></a>。</li><li>旧： <a href="https://docs.google.com/document/d/1AyuTphQ31rLHDtpZoEwEPb4fWbZna1H3hGx_YUACxk4/edit"><u>DL议程的科学</u></a></li><li><a href="https://www.anthropic.com/index/influence-functions"><u>人类：将输出追踪到培训数据</u></a></li><li><a href="https://manifund.org/projects/scaling-training-process-transparency"><u>缩放训练过程透明度</u></a>（Krzyzanowski）</li></ul><hr><h2> 2.控制事物</h2><p>（弄清楚如何可预测地影响模型行为。）<br></p><p><a href="https://ai-alignment.com/prosaic-ai-control-b959644d79c2"><i><u>平淡无奇</u></i></a><i>&nbsp;</i>默认情况下<a href="https://www.lesswrong.com/posts/ziNCZEm7FE9LHxLai/don-t-dismiss-simple-alignment-approaches"><i><u>对齐</u></i></a><i>/</i><a href="https://www.alignmentforum.org/posts/Nwgdq6kHke5LY692J/alignment-by-default"><i><u>对齐</u></i></a><i>&nbsp;</i></p><ul><li><i>一句话摘要</i>：通过优化其输出来轻推基础模型。 （ <a href="https://www.alignmentforum.org/posts/vwu4kegAEZTBtpT6p/thoughts-on-the-impact-of-rlhf-research"><u>RLHF</u></a> ，<a href="https://arxiv.org/abs/2212.08073"><u>宪法</u></a>， <a href="https://arxiv.org/abs/2310.16944"><u>DPO</u></a> ， <a href="https://www.superannotate.com/blog/llm-fine-tuning#supervised-fine-tuning-sft"><u>SFT</u></a> ， <a href="https://arxiv.org/abs/2112.00861"><u>HHH</u></a> ， <a href="https://arxiv.org/abs/2309.00267"><u>rlaif</u></a> 。）不是真正的议程，而是议程的一部分，例如<a href="https://tomekkorbak.com/papers/"><u>Korbak</u></a>或<a href="https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/635156/Doctoral_Thesis_David_Lindner_RC.pdf?sequence=6&amp;isAllowed=y"><u>Lindner</u></a> ，或Redwood的无害无害的Finetunes或<a href="https://www.lesswrong.com/posts/rCJQAkPTEypGjSJ8X/how-might-we-align-transformative-ai-if-it-s-developed-very"><u>Karnofsky计划</u></a>。我喜欢这个名称“盲目输出对齐”，但“平淡的对齐”是完善的。</li><li><i>变化理论（估算）：</i>事物通常是平稳的，相关的功能比对齐更难，假设没有中型量剂，<a href="https://arxiv.org/pdf/2311.08379.pdf"><u>零射击欺骗很难</u></a>，假设学习人类本体论是学会的人类的偏好不排除在外。假设对齐是<a href="https://arxiv.org/pdf/2305.11206.pdf#:~:text=We%20define%20the%20Superficial%20Alignment,used%20when%20interacting%20with%20users."><u>浅表</u></a>特征。也许认为思想是<a href="https://www.lesswrong.com/posts/r3xwHzMmMf25peeHE/the-translucent-thoughts-hypotheses-and-their-implications"><u>半透明的</u></a>。</li><li><i>一些名称：</i> <a href="https://www.lesswrong.com/posts/BfN88BfZQ4XGeZkda/concrete-reasons-for-hope-about-ai"><u>人类</u></a>，露天，<a href="https://scale.com/blog/safety-evaluations-analysis-lab"><u>鳞片</u></a>，<a href="https://huggingface.co/HuggingFaceH4"><u>拥抱的脸H4</u></a> ，Eleuther， <a href="https://www.lesswrong.com/posts/C5guLAx7ieQoowv3d/lecun-s-a-path-towards-autonomous-machine-intelligence-has-1">Lecun</a> 。但是，没有看到任何一个实际上说明上述变革理论。</li><li><i>估计的＃ftes：~~ 1,000</i></li><li> <i>2023年的一些输出</i>： <a href="https://www.anthropic.com/index/collective-constitutional-ai-aligning-a-language-model-with-public-input"><u>CCAI</u></a> 。 DPO似乎是很大的进步。</li><li><a href="https://www.lesswrong.com/posts/d6DvuCKH5bSoT62DB/compendium-of-problems-with-rlhf"><u>批评</u></a><i>：</i> <a href="https://www.lesswrong.com/posts/vwu4kegAEZTBtpT6p/thoughts-on-the-impact-of-rlhf-research#The_case_for_a_negative_impact"><u>男孩</u></a>。只是最新的： <a href="https://arxiv.org/abs/2307.15217"><u>RLHF</u></a> ， <a href="https://arxiv.org/abs/2310.16048"><u>Neo-Arrow</u></a>的开放问题。</li><li><i>资助：</i>大型技术，风险投资</li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> AI行业的大部分。<br><br></li></ul><h3>防止欺骗</h3><p>通过机械解释性以外的方法。<br></p><p> <a href="https://www.alignmentforum.org/posts/inALbAqdx63KTaGgs/benchmarks-for-detecting-measurement-tampering-redwood"><i><u>红木：机械异常检测</u></i></a></p><ul><li><i>一句摘要</i>：测量篡改是AI系统操纵多个测量的地方，以产生良好结果的错觉，而不是实现所需的结果。</li><li><i>变更理论：</i>找出何时发生测量篡改 - >;构建不这样做的模型。</li><li>另请参阅CAI</li><li><i>一些名字：</i> Fabien Roger，Ryan Greenblatt，Max Nadeau，Buck Shlegeris，Nate Thomas</li><li><i>估计的＃ftes：</i> 2.5？</li><li> <i>2023年的一些输出</i>：<a href="https://arxiv.org/abs/2308.15605"><u>测量篡改</u></a>， <a href="https://www.alignmentforum.org/posts/rZs6ddqNnW8LXuJqA/password-locked-models-a-stress-case-for-capabilities"><u>密码锁定</u></a>， <a href="https://www.alignmentforum.org/posts/WCj7WgFSLmyKaMwPR/coup-probes-catching-catastrophes-with-probes-trained-off"><u>政变探针</u></a></li><li><i>批评：</i> <a href="https://forum.effectivealtruism.org/posts/DaRvpDHHdaoad9Tfu/critiques-of-prominent-ai-safety-labs-redwood-research"><u>对</u></a><a href="https://www.alignmentforum.org/posts/wt7HXaCWzuKQipqz3/eis-vi-critiques-of-mechanistic-interpretability-work-in-ai"><u>过去议程的批评</u></a></li><li><i>资助者：</i>开放菲尔</li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> <a href="https://www.openphilanthropy.org/grants/redwood-research-general-support-2023/"><u>$ 5300,000</u></a> （整个组织，去年）<br></li></ul><p><i><u>间接欺骗监测</u></i></p><ul><li><i>一句话摘要</i>：构建工具，以查找模型是否会在可测试情况下查看高风险环境中的不良表现。该遗愿捕获了<a href="https://www.alignmentforum.org/posts/khFC2a4pLPvGtXAGG/how-to-catch-an-ai-liar-lie-detection-in-black-box-llms-by"><u>谎言分类器</u></a>，<a href="https://arxiv.org/abs/2310.13548"><u>粘糊糊</u></a>和<a href="https://www.alignmentforum.org/posts/pip63HtEAxHGfSEGk/tall-tales-at-different-scales-evaluating-scaling-trends-for"><u>欺骗趋势</u></a>的工作。</li><li><i>变革理论：也许我们可以通过观察数十个表面无关的部分或欺骗自我报告或建立相当于脑扫描的等效的模型来捕获一个未对准的模型。</i></li><li><i>一些名字：</i> Dan Hendrycks，Owain Evans，Jan Brauner，SörenMindermann。另请参见本文中的Apollo， <a href="https://www.safe.ai/"><u>CAI</u></a> ，CAIF和两个激活工程部分。</li><li><i>估计的＃ftes：20？</i></li><li> <i>2023年的一些输出</i>： <a href="https://arxiv.org/abs/2308.14752"><u>AI欺骗调查</u></a>，<a href="https://arxiv.org/abs/2303.16200"><u>自然选择</u></a>，<a href="https://arxiv.org/abs/2306.12001"><u>概述</u></a>，<a href="https://arxiv.org/pdf/2310.01405.pdf"><u>再次</u></a></li><li><i>批评（相关想法）：</i> <a href="https://www.lesswrong.com/posts/RTkatYxJWvXR4Qbyd/deceptive-alignment-is-less-than-1-likely-by-default"><i><u>1％</u></i></a></li><li><i>资助者：</i><a href="https://www.openphilanthropy.org/grants/?organization-name=center-for-ai-safety"><i><u>开放菲尔</u></i></a></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> $ 10,618,729（CAI，整个组织）<br></li></ul><p><i>人类：</i> <a href="https://www.alignmentforum.org/posts/FRRb6Gqem8k69ocbi/externalized-reasoning-oversight-a-research-direction-for"><i><u>外部推理监督</u></i></a></p><ul><li><i>一句摘要</i>：每次用英语（或其他语言）打印其实际推理的火车模型。对危险的推理给出负面的奖励，或者只是摆脱参与其中的模型。</li><li><i>变革理论：</i> “强迫语言模型大声思考，并将推理本身作为监督渠道。如果该议程成功，它可能会打败欺骗，寻求权力和其他不赞成的推理。”</li><li>另请参见粘糊糊。</li><li><i>一些名字：</i> Tamera Lanham，Ansh Radhakrishnan</li><li><i>估计 FTE 数： ?</i></li><li> <i>2023年的某些产量</i>： <a href="https://arxiv.org/abs/2307.13702"><u>COT忠诚</u></a>，<a href="https://arxiv.org/abs/2307.11768"><u>问题分解忠诚</u></a></li><li><i>批评：</i> <a href="https://www.lesswrong.com/posts/3dFogxGK8uNv5xCSv/you-won-t-solve-alignment-without-agent-foundations"><i><u>萨明</u></i></a></li><li><i>资助者：</i>拟人投资者</li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i>大<br><br></li></ul><h3>手术模型编辑</h3><p>（对内部模型的干预）<br></p><p><a href="https://www.lesswrong.com/tag/activation-engineering"><i><u>激活工程</u></i></a></p><ul><li><i>一句话摘要</i>：让我们看看是否可以通过编程性修改激活，以将输出转向我们想要的东西，以跨模型和主题的通用方式。基于干预的解释性方法或更多或更多的方法（请参见上文）。</li><li><i>变革理论：</i>也许简单的事情会有所帮助：让我们构建更多的东西，以堆放在填充上。激活是输出前的最后一步，因此对它们的干预措施不那么抢占。稍微鼓励模型变得不错，在我们的<a href="https://www.lesswrong.com/posts/YnGRBADQwpYRbuCbz/towards-hodge-podge-alignment-1"><u>部分比</u></a>对方法中添加一层防御。</li><li><i>一些名字：</i> <a href="https://arxiv.org/abs/2308.10248"><u>Alex Turner</u></a> ，Andy Zou，Nina <a href="https://www.alignmentforum.org/posts/raoeNarFYCxxyKAop/modulating-sycophancy-in-an-rlhf-model-via-activation"><u>Rimsky</u></a> ，Claudia Shi，LéoDana，Ole Jorgensen。另请参见<a href="https://arxiv.org/abs/2306.03341"><u>Li</u></a>和<a href="https://baulab.info/publications.html"><u>Bau</u></a> <a href="https://www.lesswrong.com/posts/iNaaBAEkAy9nAgs3o/turning-off-lights-with-model-editing"><u>Lab</u></a> 。</li><li><i>估计的＃ftes：〜20</i></li><li> <i>2023年的一些输出</i>：去年<a href="https://arxiv.org/abs/2212.03827"><u>著名的CCS</u></a> ， <a href="https://www.lesswrong.com/posts/5spBue2z2tw4JuDCx/steering-gpt-2-xl-by-adding-an-activation-vector"><u>RL和GPTS中的转向向量</u></a>， <a href="https://www.lesswrong.com/posts/bFwigCDMC5ishLz7X/rfc-possible-ways-to-expand-on-discovering-latent-knowledge"><u>Cadenza RFC</u></a> ， <a href="https://www.lesswrong.com/posts/Go5ELsHAyw7QrArQ6/searching-for-a-model-s-concepts-by-their-shape-a"><u>概念的形状</u></a>。 <a href="https://www.alignmentforum.org/posts/bWxNPMy5MhPnQTzKz/what-discovering-latent-knowledge-did-and-did-not-find-4"><u>罗杰实验</u></a>。另请参见<a href="https://arxiv.org/abs/2310.01405"><u>代表工程</u></a></li><li><i>批评：</i> <a href="https://www.lesswrong.com/posts/QL7J9wmS6W2fWpofd/but-is-it-really-in-rome-an-investigation-of-the-rome-model"><i><u>罗马</u></i></a></li><li><i>资助者：DeepMind？人类？垫子？</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br></li></ul><h3>让它学习我们想要的</h3><p>（弄清楚如何控制模型的内容。）<br></p><p> <a href="https://www.lesswrong.com/posts/qusBXzCpxijTudvBB/my-agi-safety-research-2022-in-review-and-plans#2__Second_half_of_2022__1_3___My_main_research_project"><i>社会上的AGI</i></a></p><ul><li><i>一句话摘要</i>：（部分）在尤其是硬连线的脑电路上实施了社会和道德本能；让我们弄清楚这些电路是什么以及它们的工作方式；这将涉及符号接地。<a href="https://sjbyrnes.com/agi.html">持续和新颖的议程</a>的最新迭代。</li><li><i>变革理论：</i>通过改变培训以反映实际人类奖励的相当直接的对齐。获取有关（奖励，培训数据）→（人为价值）的实际数据，以帮助在AIS中理论这张地图； “了解人类的社会本能，然后可能与其他非生物成分结合使用这些方面的某些方面”。</li><li><i>一些名字：</i>史蒂夫·伯恩斯</li><li><i>估计＃ftes：</i> 1</li><li> <i>2023年的一些输出</i>：</li><li><i>批评：？</i></li><li><i>资助：</i> Astera，</li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i></li></ul><p></p><p><a href="https://www.alignmentforum.org/posts/LTFaD96D9kWuTibWr/just-imitate-humans"><i><u>模仿学习</u></i></a></p><ul><li><i>一句话摘要</i>：有关人类行为的火车模型（例如，在响应计算机屏幕上发生的情况时，人类按下键的监视）；与<a href="https://arxiv.org/abs/2110.08176"><u>Strouse</u></a>形成鲜明对比。</li><li><i>变革理论：</i>人类通过互相观察 - >;让我们测试AIS是否可以通过观察我们来学习 - >;外部对齐和月光下的良好学习。</li><li><i>一些名字：</i> JérémyScheurer，Tomek Korbak，Ethan Perez</li><li><i>估计 FTE 数： ?</i></li><li> <i>2023年的一些输出</i>： <a href="https://www.lesswrong.com/posts/mCZSXdZoNoWn5SkvE/imitation-learning-from-language-feedback-1"><u>模仿语言反馈</u></a>，<a href="https://arxiv.org/abs/2309.02473"><u>调查</u></a>，<a href="https://www.jmlr.org/papers/v23/21-0618.html"><u>良好理论从2022年学习</u></a></li><li><i>批评：</i> <a href="https://www.alignmentforum.org/posts/LTFaD96D9kWuTibWr/just-imitate-humans?commentId=kgZxwD3Wm96tNDKxu"><i><u>很多</u></i></a></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br></li></ul><p><i>奖励学习</i></p><ul><li><i>一句话摘要</i>：像柴的人仍在寻找<a href="https://arxiv.org/abs/2203.07475"><u>奖励学习</u></a>，以“重新定位AI研究的一般性对可证明有益的系统”。 （他们也像其他所有人一样在做很多倡导。）</li><li><i>变革理论：当人类直接参与训练模型 - >;构建工具，使模型更容易学习人类想要学习的东西时，了解什么样的事情会出错。</i></li><li>另请参见RLHF和递归奖励建模，即工业化形式。</li><li><i>一些名字：</i><a href="https://humancompatible.ai/progress-report/"><u>柴</u></a>等</li><li><i>估计 FTE 数： ?</i></li><li> <i>2023年的某些产量</i>：<a href="https://arxiv.org/abs/2303.00894"><u>多个老师</u></a>，<a href="https://arxiv.org/pdf/2306.09309.pdf"><u>最少的知识</u></a><a href="https://humancompatible.ai/progress-report/"><u>等</u></a>，<a href="https://arxiv.org/abs/2204.06601"><u>因果混乱</u></a></li><li><i>评论：</i><i>历史问题陈述的</i><a href="https://www.lesswrong.com/posts/i5kijcjFJD6bn7dwq/evaluating-the-historical-value-misspecification-argument"><i><u>不错摘要</u></i></a></li><li><i>资助：</i><a href="https://donations.vipulnaik.com/donee.php?donee=Center+for+Human-Compatible+AI"><i><u>主要是Openphil</u></i></a></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：$ 18,052,796</i><br></li></ul><h3>目标稳健性</h3><p>（弄清楚如何使模型继续做〜到目前为止它一直在做什么。）<br></p><p><a href="https://towardsdatascience.com/out-of-distribution-generalization-66b6f8980ef3"><i><u>测量OOD</u></i></a></p><ul><li><i>一句话摘要</i>：让我们构建可以识别出何时无法分发的模型（或至少给我们给我们的工具何时注意）。另请参见异常检测。</li><li><i>变革理论：</i>如果强大的AI从培训数据中“学习错误的教训”，就会发生坏事，我们应该做到这一点。</li><li><i>一些名字：</i> Steinhardt，Tegan Maharaj， <a href="https://arxiv.org/abs/2210.03150"><u>Irina Rish</u></a></li><li><i>估计 FTE 数： ?</i></li><li> <i>2023年的某些输出</i>：<a href="https://arxiv.org/abs/2209.00626"><u>从DL的角度来对齐</u></a>，<a href="https://arxiv.org/abs/2210.01790"><u>目标失调</u></a>， <a href="https://arxiv.org/abs/2309.16166"><u>coinrun：解决目标错误</u></a>，<a href="https://arxiv.org/abs/2304.14399"><u>对歧义进行建模</u></a>？</li><li><i>批评：？</i></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br></li></ul><p><a href="https://arxiv.org/abs/2306.10999"><i><u>概念外推</u></i></a><i>&nbsp;</i></p><ul><li><i>一句话摘要</i>：持续学习，使模型内部的内部设备在学习 /随着世界的变化而更加稳定；安全地扩展了代理商在培训新数据集和环境中学习的功能。</li><li><i>变革理论：</i>让他们大致正确地概括我们的价值观。另外，“让我们成为AI系统“在面对歧义时变得保守并寻求指导”的行业标准，并在我们发现更多的一致性方面逐渐从那里提高标准。” -  Bensinger的光泽。</li><li><i>一些名字：</i>斯图尔特·阿姆斯特朗</li><li><i>估计的＃ftes：</i> 4？</li><li> <i>2023年的一些输出</i>：<a href="https://arxiv.org/abs/2306.10999"><u>良好的底漆</u></a>，<a href="https://arxiv.org/abs/2309.16166"><u>解决了一个玩具问题</u></a></li><li><i>批评：</i> <a href="https://www.lesswrong.com/posts/3pinFH3jerMzAvmza/on-how-various-plans-miss-the-hard-bits-of-the-alignment#Stuart_Armstrong___Concept_Extrapolation"><i><u>soares</u></i></a></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br></li></ul><p><a href="https://www.lesswrong.com/tag/mild-optimization"><i><u>轻度优化</u></i></a></p><ul><li><i>一句话摘要</i>：通过让AI满足而不是最大化来避免使用Goodhart。</li><li><i>变革理论：</i>如果我们无法准确地确定对超级智能代理的偏好，我们会死于良好的效果 - >;从代理的效用函数中的最大化转变为满足的转变 - >;我们获得了LightCone的非零份额，而不是零；另外，这是完全对齐AI的食谱。</li><li><i>一些名称：</i></li><li><i>估计的＃ftes：</i> 2？</li><li> <i>2023年的一些产量</i>： <a href="https://www.lesswrong.com/posts/9fL22eBJMtyCLvL7j/soft-optimization-makes-the-value-target-bigger"><u>吉伦</u></a>， <a href="https://www.lesswrong.com/posts/XXrGhqSNZjcG2nNiy/aisc-team-report-soft-optimization-bayes-and-goodhart"><u>软优化，贝叶斯和古德哈特</u></a></li><li><i>批评：</i> <a href="https://www.lesswrong.com/posts/q9yPYG2St2L4SEtKW/requirements-for-a-stem-capable-agi-value-learner-my-case-1"><i><u>Dearnaley</u></i></a> <i>？</i></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i></li></ul><hr><h2> 3.<a href="https://www.lesswrong.com/tag/ai-assisted-ai-automated-alignment"><u>使AI解决</u></a></h2><p>（弄清楚模型如何有助于弄清楚它。）<br></p><p> <i>Openai：</i><a href="https://openai.com/blog/introducing-superalignment"><i><u>超级对象</u></i></a><i>&nbsp;</i></p><ul><li><i>一句话摘要</i>：准备好对齐人级自动对准研究人员。</li><li><i>变革理论：让它帮助我们进行可扩展的监督，批评，递归奖励建模，从而解决了内部的一致性。</i> <a href="https://www.lesswrong.com/posts/fYf9JAwa6BYMt8GBj/link-a-minimal-viable-product-for-alignment?commentId=uv8pteZJSzJeiqFA8"><i><u>另请参阅</u></i></a><i>种子。</i></li><li><i>一些名字：</i> Ilya Sutskever，Jan Leike，Leopold Aschenbrenner，Collin Burns</li><li><i>估计＃ftes：30？</i></li><li> <i>2023年的一些输出</i>： <a href="https://openai.com/research?topics=safety-alignment"><u>https：//openai.com/research?topics=</u></a> safety-Alignment</li><li><i>批评：</i> <a href="https://www.lesswrong.com/posts/NSZhadmoYdjRKNq6X/openai-launches-superalignment-taskforce"><i><u>Zvi</u></i></a> <i>，</i> <a href="https://www.lesswrong.com/posts/Hna4aoMwr6Qx9rHBs/linkpost-introducing-superalignment?commentId=NsYXBdLY6edAXavsM"><i><u>Christiano</u></i></a> <i>，</i> <a href="https://www.lesswrong.com/posts/tD9zEiHfkvakpnNam/a-challenge-for-agi-organizations-and-a-challenge-for-1"><i><u>Miri</u></i></a> <i>，</i> <a href="https://www.lesswrong.com/posts/pxiaLFjyr4WPmFdcm/take-2-building-tools-to-help-build-fai-is-a-legitimate"><i><u>Steiner</u></i></a> <i>，</i> <a href="https://www.lesswrong.com/posts/6RC3BNopCtzKaTeR6/thoughts-on-the-openai-alignment-plan-will-ai-research"><i><u>Ladish</u></i></a> <i>，</i> <a href="https://www.lesswrong.com/posts/DwqgLXn5qYC7GqExF/godzilla-strategies"><i><u>Wentworth</u></i></a> <i>，</i> <a href="https://www.lesswrong.com/posts/YiRsCfkJ2ERGpRpen/leogao-s-shortform?commentId=qmfPJspzsXaR7xCYj"><i><u>Gao</u></i></a> <i>LOL</i></li><li><i>资助者：Microsoft</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i><i>仅计算</i><a href="https://www.bloomberg.com/news/articles/2023-03-13/microsoft-built-an-expensive-supercomputer-to-power-openai-s-chatgpt?sref=ExbtjcSG"><i><u>1亿美元</u></i></a>（占Openai有担保计算的20％）<br></li></ul><p> <a href="https://www.lesswrong.com/posts/7e5tyFnpzGCdfT4mR/research-agenda-supervising-ais-improving-ais"><i><u>监督AIS改善AIS</u></i></a></p><ul><li><i>一句话摘要</i>：在语言模型和基准中跟踪行为漂移的可扩展方法，以评估语言模型通过自我训练的稳定自我修饰的能力。</li><li><i>变化理论：</i>早期模型仅训练〜仅对人类数据进行训练，而后来的模型还训练了早期模型输出，这导致了早期模型问题的问题；剩下的未选中可能会引起问题，因此我们需要更好的迭代改进过程。</li><li><i>一些名字：</i> Quintin Pope，Jacques Thibodeau，Owen Dudney，Roman Engeler</li><li><i>预计 FTE 人数：</i> 2</li><li> <i>2023年的一些输出</i>：？</li><li><i>批评：</i></li><li><i>资助：</i> LTFF，Lightspeed，Openphil，Tiny Lightspeed Grant，</li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> 〜$ 100,000<br></li></ul><p><a href="https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism"><i><u>电子人主义</u></i></a></p><ul><li><i>一句话摘要</i>：训练人与llm对准研究人员：与人类在循环中，而没有外包给自主代理。不仅如此，对基于AI的AI一致性的风险评估的积极态度。</li><li><i>变革理论：增强人类能力并保留价值观的认知假肢。每年进行更多的一致性研究和美元。</i></li><li><i>一些名字：</i> Janus，Kees Dupuis。另请参阅<a href="https://www.lesswrong.com/posts/k93NEoXZq6CdXegdx/philosophical-cyborg-part-1"><u>该</u></a>团队做类似的事情。</li><li><i>估计的＃ftes：6？</i></li><li> <i>2023年的一些输出</i>：<a href="https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism"><u>议程语句</u></a></li><li><i>批评：</i><a href="https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism#Failure_Modes"><i><u>自我</u></i></a></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i></li></ul><p></p><p><i>另请参见</i><a href="https://www.lesswrong.com/posts/WKGZBCYAbZ6WGsKHc/love-in-a-simbox-is-all-you-need"><u>Simboxing</u></a> （Jacob Cannell）。<br></p><h3>可扩展的监督</h3><p>（弄清楚如何缓解人类监督模型。难以清晰地区分雄心勃勃的机械性解释性，但我们在这里。）<br></p><h3>任务分解</h3><p>递归奖励建模据说还没有死，而是超级对准的工具之一。</p><p>另一条线试图使<a href="https://arxiv.org/abs/2305.04388"><u>思想链</u></a>/<a href="https://arxiv.org/abs/2305.10601"><u>思想树</u></a>诚实。<br></p><p><a href="https://blog.elicit.com/"><i><u>引起</u></i></a>（以前<a href="https://www.lesswrong.com/posts/pYcFPMBtQveAjcSfH/supervise-process-not-outcomes"><u>应该</u></a>）</p><ul><li>某种形式的<a href="https://ought.org/updates/2023-09-25-spinoff"><u>枢轴/分拆</u></a>发生了。 “大多数以前的员工都在新组织工作”，详细信息尚不清楚。</li><li><i>一句摘要</i>：“ a）改善了AI治理和一致性研究人员的推理，特别是在长途任务上，以及（b）推动对过程的监督而不是结果，这减少了对不完善的代理目标的优化压力”。</li><li><i>变革理论：“</i><a href="https://blog.elicit.com/ai-safety/"><i><u>引起对人工智能安全</u></i></a>的两个主要影响<i>正在改善认识论和开创性的过程监督。”</i></li><li><i>一些名字：查理·乔治（Charlie George），安德烈亚斯（AndreasStuhlmüller）</i></li><li><i>估计 FTE 数： ?</i></li><li> <i>2023年的一些输出</i>： <a href="https://blog.elicit.com/factored-verification-detecting-and-reducing-hallucinations-in-frontier-models-using-ai-supervision/"><u>验证</u></a></li><li><i>批评：</i></li><li><i>资助者：</i><a href="https://blog.elicit.com/elicit-raises-9-million-and-becomes-a-public-benefit-corporation/"><i><u>公共福利公司</u></i></a></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：$ 9,000,000</i><br></li></ul><h3>对抗性的</h3><p><a href="https://www.alignmentforum.org/posts/nzmCvRvPm4xJuqztv/deepmind-is-hiring-for-the-scalable-alignment-and-alignment"><i><u>深态可扩展对齐</u></i></a></p><ul><li><i>一句话摘要</i>：“即使人类很难知道那是什么，让高能力的代理人做人类想要的事情”。</li><li><i>变革理论：[“给予人类帮助监督强大的代理人”] + [“与代理的真实推理过程的解释”] + [“红色团队模型以表现出在正常使用中不出现的故障模式”]是必要的，但可能不足以安全AGI。</i></li><li><i>一些名字：杰弗里·欧文（Geoffrey Irving）</i></li><li><i>估计 FTE 数： ?</i></li><li> <i>2023年的一些输出：？</i></li><li><i>批评：</i></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br></li></ul><p> <a href="https://www.anthropic.com/index/measuring-progress-on-scalable-oversight-for-large-language-models"><i><u>人类</u></i></a><i>/</i><a href="https://wp.nyu.edu/arg/"><i><u>纽约大学一致性研究小组</u></i></a><i>/ Perez合作</i></p><ul><li><i>一句话摘要</i>：可扩展的对真实性的监督：即使人类无法直接判断模型产出的正确性，也可以开发培训方法来激励真实性吗？ /可扩展的基准测量如何测量（代理）诸如情境意识之类的投机能力。</li><li><i>变革理论：当前AI越来越艰难的问题 - >;我们需要构建工具来帮助人类监督者继续转向AI  - >;让我们开发有关方法可能扩展的理论 - >;让我们构建工具。</i></li><li><i>一些名字：塞缪尔·鲍曼（Samuel Bowman），伊桑·佩雷斯（Ethan Perez）</i></li><li><i>估计 FTE 数： ?</i></li><li> <i>2023年的某些输出</i>： <a href="https://www.anthropic.com/index/specific-versus-general-principles-for-constitutional-ai"><u>宪法AI的特定与一般原则</u></a>，<a href="https://arxiv.org/abs/2311.08702"><u>辩论有助于监督不可靠的专家</u></a>，<a href="https://arxiv.org/abs/2305.04388"><u>语言模型并不总是说出他们的想法</u></a></li><li><i>批评：</i> <a href="https://www.lesswrong.com/posts/PJLABqQ962hZEqhdB/debate-update-obfuscated-arguments-problem"><i><u>混淆</u></i></a><i>，</i> <a href="https://www.alignmentforum.org/posts/MbWWKbyD5gLhJgfwn/meta-level-adversarial-evaluation-of-oversight-techniques-1"><i><u>本地不足</u></i></a><i>？</i><a href="https://arxiv.org/abs/2210.10860"><i><u>它现在不起作用</u></i></a><i>（2022）</i></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i></li></ul><p></p><p>另请参见（下<a href="https://far.ai/"><u>图</u></a>）。</p><hr><h2> 4. 理论</h2><p>（弄清楚我们需要找出什么，然后做到这一点。这曾经是我们所能做的。）<br></p><h3>银河脑的端到端解决方案<br></h3><p><a href="https://www.alignmentforum.org/posts/ZwshvqiqCvXPsZEct/the-learning-theoretic-agenda-status-2023"><i><u>学习理论议程</u></i></a><i>&nbsp;</i></p><ul><li><i>单句摘要</i>：尝试正式化一个更现实的代理，了解与我们保持一致的含义，在其本体论与我们的本体论之间翻译，并生产Desiderata进行培训设置，以指向连贯的AGIS，类似于我们的模型对齐代理。</li><li><i>变革理论：弄清楚如何通过首先修复正式认识论来培训对齐的AI。</i></li><li><i>一些名字：</i>凡妮莎·科索（Vanessa Kosoy）</li><li><i>预计 FTE 人数：</i> 2</li><li> <i>2023年的一些输出</i>： <a href="https://www.lesswrong.com/posts/cYJqGWuBwymLdFpLT/non-unitary-quantum-logic-seri-mats-research-sprint"><u>量子？</u></a> ，<a href="https://www.lesswrong.com/posts/HNnRCPe2CejfupSow/fixed-points-in-mortal-population-games"><u>凡人流行音乐</u></a>，<a href="https://www.lesswrong.com/posts/nEFAno6PsCKnNgkd5/infra-bayesian-logic"><u>逻辑</u></a></li><li><i>批评：</i> <a href="https://www.lesswrong.com/posts/StkjjQyKwg7hZjcGB/a-mostly-critical-review-of-infra-bayesianism"><i><u>matolcsi</u></i></a></li><li><i>资助：</i> Miri，Mats，有效冒险，Lightspeed</li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br></li></ul><p> <a href="https://www.lesswrong.com/posts/pKSmEkSQJsCSTK6nH/an-open-agency-architecture-for-safe-transformative-ai"><i><u>开放代理体系结构</u></i></a></p><ul><li><i>一句话摘要</i>：让AI构建人类理解的详细世界模拟，引起人类对未来状态的偏好，正式验证AI是否遵守粗糙的偏好；计划使用这种世界模型和偏好。另请参见<a href="https://arxiv.org/abs/2309.01933"><u>可证明的安全系统</u></a>（我希望与之合并）；另请参见<a href="https://openreview.net/forum?id=BZ5a1r-kVsf">Aptami</a> 。</li><li><i>变革理论：</i>本体论规范，身体状况的前所未有的形式化，对高维状态序列的前所未有的形式验证。斯图尔特·罗素（Stuart Russell）的报仇。值得注意的是不需要我们解决麋鹿；确实要求我们解决本体论。</li><li><i>一些名字：</i>戴维德，埃文·米亚佐诺，丹尼尔·温德姆。另请参阅： <a href="https://www.lesswrong.com/posts/pKSmEkSQJsCSTK6nH/an-open-agency-architecture-for-safe-transformative-ai?commentId=p3QSNw6AMc6MtC4QF"><u>Cannell</u></a> <u>。</u></li><li><i>估计的＃ftes：</i> 5？</li><li> <i>2023年的某些输出</i>： <a href="https://www.lesswrong.com/posts/pHJtLHcWvfGbsW7LR/roadmap-for-a-collaborative-prototype-of-an-open-agency"><u>几个</u></a><a href="https://www.lesswrong.com/posts/jRf4WENQnhssCb6mJ/davidad-s-bold-plan-for-alignment-an-in-depth-explanation"><u>团队</u></a><a href="https://atlascomputing.org/"><u>正在</u></a>研究详细信息</li><li><i>批评：</i> <a href="https://www.lesswrong.com/posts/pKSmEkSQJsCSTK6nH/an-open-agency-architecture-for-safe-transformative-ai?commentId=ZuWsoXApJqD4PwfXr"><u>soares</u></a></li><li><i>资助：</i>彼得·埃克利（Peter Eckersley） /<a href="https://twitter.com/davidad/status/1719770184565530890"><u>阿特拉斯（</u></a> Atlas Computing</li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i>大约50,000,000英镑<br><br></li></ul><p><a href="https://arxiv.org/abs/2309.01933"><i><u>可证明的安全系统</u></i></a></p><ul><li><i>单句摘要</i>：正式对物理/社会系统的行为进行建模，定义确切的“护栏”，以限制可能发生的操作，要求AIS为其建议的行动提供安全证明，并自动验证这些证明。与OAA密切相关。</li><li><i>变革理论：建立一个正式的验证系统，可以充当人类用户与潜在危险系统之间的中介，只能使可证明的安全行动通过。</i></li><li><i>一些名称：</i>史蒂夫·奥蒙德罗（Steve Omohundro），Max Tegmark</li><li><i>估计的＃ftes：</i> 1 ??</li><li> <i>2023年的一些产出</i>：计划公告。 <a href="https://www.google.com/search?q=beneficial+ai+research+omohundro&amp;client=ubuntu-chr&amp;hs=YtH&amp;sca_esv=585404198&amp;sxsrf=AM9HkKnEEdAHVYIgzqf7eSVTTtoNxsq0vw%3A1700999001104&amp;ei=WS9jZar5BdOQhbIPiJCEuAE&amp;ved=0ahUKEwjqieWJy-GCAxVTSEEAHQgIARcQ4dUDCBA&amp;uact=5&amp;oq=beneficial+ai+research+omohundro&amp;gs_lp=Egxnd3Mtd2l6LXNlcnAiIGJlbmVmaWNpYWwgYWkgcmVzZWFyY2ggb21vaHVuZHJvSO0gUIYCWKAfcAJ4AZABAJgBfKAB2giqAQM1Lja4AQPIAQD4AQHCAgoQABhHGNYEGLADwgIGEAAYFhgewgILEAAYgAQYigUYhgPCAgUQIRigAcICBBAhGBXCAggQIRgWGB4YHcICBxAhGKABGAriAwQYACBBiAYBkAYI&amp;sclient=gws-wiz-serp#ip=1"><u>Omohundro的组织</u></a>非常神秘。</li><li><i>批评：</i> <a href="https://thezvi.substack.com/p/ai-28-watching-and-waiting?utm_source=%2Fsearch%2Fomohundro&amp;utm_medium=reader2#:~:text=Max%20Tegmark%20and%20Steve%20Omohundo%20drop%20a%20new%20paper"><i><u>ZVI</u></i></a></li><li><i>资助：未知</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br></li></ul><p><i>猜想：</i> <a href="https://www.lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal"><i><u>认知仿真</u></i></a><i>（COEMS）</i></p><ul><li><i>一句摘要</i>：将设计空间限制在人类推理的（部分）仿真中。如果AI对我们使用类似的启发式方法，则应默认为不极端。</li><li><i>变革理论：训练有限的工具AI，这将帮助我们反对AGI而不会非常危险，并使禁止无限的AIS在政治上更可行。</i></li><li><i>一些名字：Connor Leahy，Gabriel Alfour？</i></li><li><i>估计的＃ftes：</i> 11？</li><li> <i>2023年的一些输出</i>：？</li><li><i>评论：</i> <a href="https://www.lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal?commentId=vvurB4rZFEPoHwnpz"><i><u>Scher</u></i></a> <i>，</i> <a href="https://www.lesswrong.com/posts/ngEvKav9w57XrGQnb/cognitive-emulation-a-naive-ai-safety-proposal?commentId=sEknDwrJ4WdxMz66c"><i><u>Samin</u></i></a> <i>，</i> <a href="https://www.lesswrong.com/posts/9jvrQToSq3CYvoeHf/critiques-of-prominent-ai-safety-labs-conjecture"><i><u>Org</u></i></a></li><li><i>资助：私人投资者（复数平台，Metaplanet，Secret）</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i>数百万美元。<br></li></ul><p> <a href="https://www.lesswrong.com/posts/4RrLiboiGGKfsanMF/the-qaci-alignment-plan-table-of-contents"><i><u>提问 - 反事实间隔（QACI）</u></i></a></p><ul><li><i>一句话摘要</i>：让事情能够制定自己的目标功能（a la hch）。</li><li><i>变革理论：</i> “应对的目标应由完全正式的数学数，而不是AI在本体论中必须解释的人类概念，因为本体论随着AI的学习和变化而破裂并重塑。 [..]给出一个计算无限的数学甲骨文，该目标将采取理想的动作；然后，我们应该设计一个计算有限的AI，足以采取令人满意的动作。”</li><li><i>一些名字</i>：Tamsin Leake</li><li><i>估计的＃ftes：3？</i></li><li> <i>2023年的一些输出</i>：参见<a href="https://www.lesswrong.com/posts/4RrLiboiGGKfsanMF/the-qaci-alignment-plan-table-of-contents"><u>议程帖子</u></a></li><li><i>批评：</i> <a href="https://www.lesswrong.com/posts/CYtzXadXFtBSBYm3J/a-narrative-explanation-of-the-qaci-alignment-plan?commentId=uFofk2t7XEsqxGsTZ"><u>霍布森</u></a>， <a href="https://www.lesswrong.com/posts/CYtzXadXFtBSBYm3J/a-narrative-explanation-of-the-qaci-alignment-plan?commentId=8wqGNfotgeTp4G9gu"><u>阿诺姆</u></a></li><li><i>资助方：SFF</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> $ 438,000+<br></li></ul><h3>了解代理</h3><p>（弄清楚“甚至是代理人”以及如何与因果关系联系起来。）<br></p><p><a href="https://causalincentives.com/"><i><u>因果基础</u></i></a><i>&nbsp;</i></p><ul><li><i>一句</i><a href="https://www.alignmentforum.org/s/pcdHisDEGLbxrbSHD"><u>介绍</u></a>：使用因果模型来理解代理，因此设计环境没有动力进行叛逃。</li><li><i>变化理论</i>：<a href="https://arxiv.org/pdf/2204.10018.pdf"><u>特定于路径的目标</u></a>避免了对价值规范的严格要求，而瓶颈则是确保稳定性（如何容易发生副作用状态的副作用）。</li><li><i>一些名字</i>：汤姆·埃弗里特（Tom Everitt），刘易斯·哈蒙德（Lewis Hammond），弗朗西斯·里斯·沃德（Francis Rhys Ward），瑞安·凯里（Ryan Carey），塞巴斯蒂安·法夸（Sebastian Farquhar）</li><li><i>估计的＃ftes</i> ：？</li><li> <i>2023年的一些输出</i>：<a href="https://causalincentives.com/pdfs/deception-ward-2023.pdf"><u>欺骗纸</u></a></li><li><i>批评</i>：</li><li><i>资助</i>：？</li><li><i>值得信赖的命令，关闭，OPSEC，共同的好处，一致性心态</i>：？</li><li><i>资源</i>：少量的深态<br></li></ul><p><a href="https://acsresearch.org/"><i><u>复杂系统的一致性</u></i></a><i>：分层代理</i></p><ul><li><i>一句摘要</i>：开发子代理和超级代理的形式模型，使用该模型指定整个部分关系的理想属性（例如如何防止对人类友好的零件被消灭）。目前使用主动推论作为形式主义的灵感。研究人类和社会的偏好和认知；进行主动推理的游戏理论扩展。</li><li><i>变革理论：解决</i><a href="https://www.alignmentforum.org/posts/9GyniEBaN3YYTqZXn/the-self-unalignment-problem"><i><u>自我对象</u></i></a><i>，防止crocrustean对准，允许可扩展的非掠夺。</i></li><li><i>一些名字：</i> Jan Kulveit，TomášGavenčiak</li><li><i>预计 FTE 人数：4</i></li><li> <i>2023年的一些输出</i>：对LLM的<a href="https://acsresearch.org/posts"><u>见解</u></a>，深入<a href="https://arxiv.org/abs/2311.10215"><u>研究主动</u></a>推断。</li><li><i>批评：</i> <a href="https://www.alignmentforum.org/posts/H5iGhDhQBtoDpCBZ2/announcing-the-alignment-of-complex-systems-research-group?commentId=frEufx3c6cRmhDjbh"><i><u>间接</u></i></a></li><li><i>资助者：SFF（</i> <a href="https://survivalandflourishing.fund/sff-2022-h1-recommendations.html"><i><u>2022</u></i></a> <i>）</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：$ 425,000？</i><br></li></ul><p> <a href="https://www.lesswrong.com/posts/qbcuk8WwFnTZcXTd6/thomas-kwa-s-miri-research-experience"><i><u>罗宁尖锐的左转船员</u></i></a></p><ul><li><i>一句话摘要</i>：&#39;最初是因为“表征锋利的左转弯”，并演变为获得有关理想形式的<a href="https://arbital.com/p/consequentialist"><u>后果主义认知</u></a>形式的基本见解。</li><li><i>变革理论：</i>了解后果主义者的一般特性 - >;>;找出哪些子问题实际上可能会有所帮助 - >;正式化相关见解 - >;死于AI的方法很少。</li><li><i>一些名字：</i> （KWA，Barnett，Hebbar）过去</li><li><i>估计 FTE 数： ?</i></li><li> <i>2023年的一些产量</i>：<a href="https://www.lesswrong.com/posts/fuSaKr6t6Zuh6GKaQ/when-is-goodhart-catastrophic"><u>灾难性的Goodhart</u></a> ？</li><li><i>评论</i><i>：</i> <a href="https://www.lesswrong.com/posts/v6zZaR7aDD6vkuPmx/science-of-deep-learning-more-tractably-addresses-the-sharp"><i><u>GABS</u></i></a> <i>，</i> <a href="https://www.lesswrong.com/posts/3pinFH3jerMzAvmza/on-how-various-plans-miss-the-hard-bits-of-the-alignment#Vivek_Hebbar__summarized__perhaps_poorly__from_last_time_we_spoke_of_this_in_person"><i><u>SOARES</u></i></a> <i>，</i> <a href="https://www.lesswrong.com/posts/hvz9qjWyv8cLX9JJR/evolution-provides-no-evidence-for-the-sharp-left-turn"><i><u>POPE</u></i></a><i>等</i><a href="https://www.lesswrong.com/tag/sharp-left-turn"><i><u>，</u></i></a> <a href="https://www.lesswrong.com/posts/yCuzmCsE86BTu9PfA/there-are-no-coherence-theorems"><i><u>切向EJT</u></i></a></li><li><i>资助者：Lightspeed</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：269,200美元（Hebbar）</i><br></li></ul><p><a href="https://www.lesswrong.com/tag/shard-theory"><i><u>碎片理论</u></i></a></p><ul><li><i>一句摘要</i>：模型代理的内部组成部分，将人类用作AGI的模型生物（人类似乎是由碎片组成的，AI也是如此）。</li><li><i>变革理论：“如果政策是受影响力集合（“碎片”）控制的，请考虑哪种训练方法会增加对人类友好型碎片的机会，从而实质上影响了整体。”</i></li><li>另请参阅激活工程。</li><li><i>一些名称：Quintin Pope，Alex Turner</i></li><li><i>预计 FTE 人数：4</i></li><li> <i>2023年的某些输出</i>：在控制 /介入的解释性中<a href="https://www.lesswrong.com/posts/JusJcepE2qohiC3hm/predictions-for-shard-theory-mechanistic-interpretability"><u>真正坚实的</u></a>经验内容</li><li><i>评论：</i> <a href="https://www.lesswrong.com/posts/8ccTZ9ZxpJrvnxt4F/shard-theory-in-nine-theses-a-distillation-and-critical#My_opinions_on_the_validity_of_each_of_the_nine_theses"><i><u>陈</u></i></a><i>，</i> <a href="https://www.lesswrong.com/posts/Aet2mbnK7GDDfrEQu/contra-shard-theory-in-the-context-of-the-diamond-maximizer"><i><u>Soares</u></i></a> <i>，</i> <a href="https://www.lesswrong.com/posts/dRsrfC8LN4z2oehJg/the-heritability-of-human-values-a-behavior-genetic-critique"><i><u>Miller</u></i></a> <i>，</i> <a href="https://www.lesswrong.com/posts/L4e7CqqpDxea2x4Gg/disentangling-shard-theory-into-atomic-claims"><i><u>Lang</u></i></a> <i>，</i> <a href="https://www.lesswrong.com/posts/xsieF8SXw4J5LkzEg/failure-modes-in-a-shard-theory-alignment-plan"><i><u>KWA</u></i></a></li><li><i>资助者：没有人特别</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br></li></ul><p> <a href="https://www.lesswrong.com/posts/fjgoMaBenyXcRDrbX/boundaries-membranes-and-ai-safety-compilation"><i><u>边界 /膜</u></i></a></p><ul><li><i>一句话摘要</i>：正式化一条道德：代理人与其环境之间的因果分离。另请参见开放代理体系结构。</li><li><i>变革理论：</i> <a href="https://www.lesswrong.com/posts/KX3xx8LTnE7GKoFuj/boundaries-for-formalizing-an-mvp-morality"><i><u>正式化道德/安全性</u></i></a><i>，解决外部对齐。</i></li><li><i>一些名字：</i><a href="mailto:chris@chrislakin.com"><i><u>克里斯·拉金（Chris Lakin</u></i></a> <i>）（全职），</i><a href="https://www.lesswrong.com/s/LWJsgNYE8wzv49yEc"><i><u>安德鲁·克里奇（Andrew Critch）</u></i></a> <i>，</i> <a href="https://www.lesswrong.com/posts/fjgoMaBenyXcRDrbX/boundaries-membranes-and-ai-safety-compilation#Davidad_s_OAA"><i><u>戴维德（David）</u></i></a></li><li><i>估计＃ftes：1</i></li><li> <i>2023年的某些产出</i>：问题陈述，计划研讨会2024年初</li><li><i>批评：</i></li><li><i>资助者：私人捐助者和前瞻性研究所</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：&lt;$ 100k</i><br></li></ul><p><i>剥夺</i><a href="https://manifund.org/projects/agency-and-disempowerment"><i><u>形式主义</u></i></a></p><ul><li><i>一句话摘要</i>：提供（DIS）赋权的正式和运营概念，这些概念在概念上令人满意且可实施。</li><li><i>变革理论：形式主义将来将有用。</i></li><li><i>一些名字：Damiano Fornasiere，Pietro Greiner</i></li><li><i>预计 FTE 人数：2</i></li><li> <i>2023年的一些输出</i>：？</li><li><i>批评：</i></li><li><i>资助者：仿真</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：$ 60,300</i><br></li></ul><p><a href="https://manifund.org/projects/avoiding-incentives-for-performative-prediction-in-ai"><i><u>表演性预测</u></i></a></p><ul><li><i>一句话摘要</i>：“如何通过对多个预测指标的联合评估来消除表演预测的激励措施”。</li><li><i>变革理论：“如果功能强大的AI系统发展的目标是偶然或设计，那么这种操纵的激励措施可能会证明灾难性的”  - >;注意事件发生时 - >;设计模型不执行此操作。</i></li><li><i>一些名字：杰里米·鲁宾夫（Jeremy Rubinoff）</i></li><li><i>估计＃ftes：1</i></li><li> <i>2023年的某些输出</i>： <a href="https://www.alignmentforum.org/posts/A48amesEmqD8KNSmY/conditional-prediction-with-zero-sum-training-solves-self"><u>零和训练的条件预测解决了自我实现的预言</u></a>（前体）</li><li><i>批评：？</i></li><li><i>资助者：仿真</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：$ 33,200</i><br></li></ul><p><i>理解优化</i></p><ul><li><i>一句话摘要</i>：什么是“优化能力”（正式化），我们如何构建跟踪它的工具以及无论如何与此相关。另请参阅发展性解释性？</li><li><i>变革理论：现有理论要么严格或善于捕捉我们的意思；让我们找到一个 - >;使用该概念来更好地理解AI如何以及何时获得更多优化能力。如果我们可以检测或排除诸如渐变黑客攻击之类的投机物品，那就太好了。</i></li><li><i>一些名字：</i><a href="https://www.lesswrong.com/posts/7nDvJiikgiawHAp6z/my-research-agenda-in-agent-foundations"><i><u>Alex Altair</u></i></a> <i>，Jacob Hilton</i></li><li><i>估计 FTE 数： ?</i></li><li> <a href="https://www.lesswrong.com/posts/ouXqWFxHZGsC3B8D7/draft-inferring-minimizers"><u>2023</u></a><i>年的某些输出</i><a href="https://www.lesswrong.com/posts/8CSJvfcvDGioNQF87/draft-detecting-optimization"><u>：</u></a> Altair草稿（ <a href="https://www.lesswrong.com/posts/csiAvRMGG5aAWvKWb/draft-introduction-to-optimization"><u>1、2、3、4</u></a> ）， <a href="https://www.lesswrong.com/posts/6rZroG3mztowktJzp/how-many-bits-of-optimization-can-one-bit-of-observation"><u>一点点观察可以解锁多少位优化</u></a><a href="https://www.lesswrong.com/posts/h3Nqjy75xoqJ3Tvup/draft-the-optimization-toolbox"><u>？</u></a> （温特沃斯）， <a href="https://www.lesswrong.com/posts/dfTm26pvq7yQp8mR3/one-bit-of-observation-can-unlock-many-of-optimization-but"><u>但是要花多少钱？</u></a> ，<a href="https://www.alignmentforum.org/posts/X6ZjFShxNBNM5QCg4/towards-measures-of-optimisation-3"><u>采取优化度量</u></a>（MacDermott，Oldenziel）； Goodharting（“我们甚至如何让代理商做特定的事情”）： <a href="https://www.alignmentforum.org/posts/Eu6CvP7c7ivcGM3PJ/goodhart-s-law-in-reinforcement-learning"><u>RL东西</u></a>， <a href="https://arxiv.org/abs/2209.13085"><u>Krueger</u></a> ， <a href="https://arxiv.org/abs/2210.10760"><u>Overopt</u></a></li><li><i>批评：</i></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br><br></li></ul><h3>科罗</h3><p>（弄清楚我们如何获得超级智能的代理人继续倾听我们的声音。可以说是可扩展的监督和超级对象。</p><p><br><a href="https://www.michael-k-cohen.com/publications"><i><u>行为对准理论</u></i></a></p><ul><li><i>一句摘要</i>：通过正式模型预测AGI（例如PowerSeeking）的性质。科罗作为权力的相反。</li><li><i>变革理论：</i>弄清有关属性的假设强大的代理人将 - >;尝试在假设所持的条件下进行严格证明，在可行的情况下对其进行测试。</li><li> <a href="https://www.lesswrong.com/posts/AqsjZwxHNqH64C2b6/let-s-see-you-write-that-corrigibility-tag"><u>该线程</u></a>中的评论非常好 - 但是没有一个作者正在为此致力！另请参阅<a href="https://arxiv.org/abs/1908.01695"><u>霍尔特曼的忽视结果</u></a>。</li><li><i>一些名字：</i> <a href="https://onlinelibrary.wiley.com/doi/10.1002/aaai.12064"><u>Marcus</u></a> Hutter，Michael Cohen（ <a href="https://arxiv.org/abs/2006.08753"><u>1，2</u></a> ），Michael Osborne</li><li><i>预计 FTE 人数：</i> 3</li><li> <i>2023年的一些输出</i>：？</li><li><i>批评：</i></li><li><i>资助者：DeepMind</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br></li></ul><p>另请参见<a href="https://philpapers.org/rec/THOTSP-7"><u>EJT</u></a> （以及以前的<a href="https://www.lesswrong.com/posts/sHGxvJrBag7nhTQvb/invulnerable-incomplete-preferences-a-formal-statement-1#comments"><u>彼得森</u></a>）。另请参阅<a href="https://www.lesswrong.com/posts/gLyRQCg6kp5cqTQTm/collective-identity"><u>Dupuis</u></a> 。</p><p></p><h3>本体识别</h3><p>（弄清楚超智能代理商如何思考世界，以及我们如何获得超级智能代理人实际告诉我们他们所知道的东西。大部分可解释性偶然地针对这一点。）<br></p><p><a href="https://www.alignment.org/theory/"><i><u>弧理论</u></i></a></p><ul><li><i>一句话摘要</i>：训练我们可以提取潜在，看起来和加密知识的AI，即使它有动力将其隐藏起来。麋鹿，正式化启发式方法，<a href="https://www.alignment.org/blog/mechanistic-anomaly-detection-and-elk/"><u>机械异常检测</u></a></li><li><i>变革理论</i>：正式化模型的概念，该模型访问了一些信息 - >;设计培训目标，这些目标激励系统诚实地报告其内部信念</li><li><i>一些名字：</i>保罗·克里斯蒂安诺（Paul Christiano），马克Xu。</li><li> <i>2023年的一些产出</i>：没有公开的东西； ``我们正在努力为“正式启发式论证”开发一个框架，该框架可用于推理神经网络的行为。&#39;</li><li>评论： <a href="https://www.lesswrong.com/posts/8xCtJHAbzyA2oA6J4/clarifying-what-elk-is-trying-to-achieve"><u>澄清</u></a>， <a href="https://www.lesswrong.com/posts/NxApPkbjt9hXraSts/for-elk-truth-is-mostly-a-distraction"><u>替代</u></a>配方</li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br></li></ul><p> <a href="https://www.alignmentforum.org/posts/cy3BhHrGinZCp3LXE/testing-the-natural-abstraction-hypothesis-project-intro"><i><u>自然抽象</u></i></a><i>&nbsp;</i></p><ul><li><i>单句摘要</i>：检查我们的宇宙很好地抽象的假设，许多认知系统学会使用类似的抽象。</li><li><i>变革理论：</i>构建工具以检查假设，运行实验，如果假设的存在，我们不必担心对齐的挑剔部分，例如AGI是否会知道我们的意思是爱。</li><li><i>一些名字：</i>约翰·温特沃斯</li><li><i>估计的＃ftes：</i> 2？</li><li> <i>2023年的一些输出</i>： <a href="https://www.alignmentforum.org/tag/natural-abstraction?sortedBy=new"><u>https</u></a> ：//www.alignmentforum.org/tag/natural-abstraction？</li><li><i>批评：</i> <a href="https://www.lesswrong.com/posts/gvzW46Z3BsaZsLc25/natural-abstractions-key-claims-theorems-and-critiques-1"><i><u>摘要和批评</u></i></a><i>，</i> <a href="https://www.alignmentforum.org/posts/mgjHS6ou7DgwhKPpu/a-rough-and-incomplete-review-of-some-of-john-wentworth-s"><i><u>飙升</u></i></a></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源： ？</i><br></li></ul><h3>了解合作</h3><p>（弄清楚Inter-AI和AI/人类游戏理论应该或将如何工作。）<br></p><p> <a href="https://longtermrisk.org/research-agenda"><i><u>CLR</u></i></a> <i>&nbsp;</i></p><ul><li><i>一句话摘要</i>：未来的代理人故意创造S风险是所有可能的问题中最糟糕的，我们应该避免这种情况。</li><li><i>变革理论：通过改善合作理论使现在和未来的AIS固有地合作。</i></li><li><i>一些名字：</i>杰西·克利夫顿，安妮·莱斯克勒，朱利安·斯塔斯特尼</li><li><i>估计＃ftes：15</i></li><li> <i>2023年的某些输出</i>：<a href="https://www.alignmentforum.org/posts/uPWDwFJnxLaDiyv4M/open-minded-updatelessness"><u>开放的无聊更新性</u></a>，<a href="https://arxiv.org/pdf/2307.04879.pdf"><u>可能是个</u></a><a href="https://www.lesswrong.com/posts/92xKPvTHDhoAiRBv9/making-ais-less-likely-to-be-spiteful"><u>恶意</u></a></li><li><i>批评：</i></li><li><i>资助者：Ruairi Donnelly？ Polaris Ventures？</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：去年3,375,081英镑</i><br></li></ul><p><a href="https://www.cs.cmu.edu/~focal/"><i><u>焦点</u></i></a><i>&nbsp;</i></p><ul><li><i>一句话摘要</i>：确保Advanced AI使用我们认为的适当游戏理论。</li><li><i>变革理论：（1）通过使AIS更加合作来保持前期智慧的世界理解； （2）保持在学术界，与学者在各种主题上的合作，并鼓励他们在X-fisk上的合作； （3）希望我们对“ AIS游戏理论”的工作强调对人类的合作和利益，对新学术领域具有框架和创始人的影响。</i></li><li><i>一些名称：</i> Vincent Conitzer，Caspar Oesterheld</li><li><i>估计＃ftes：7</i></li><li> <i>2023年的某些输出</i>：<a href="https://arxiv.org/abs/2307.05068"><u>有限的归纳合理性</u></a>，<a href="https://arxiv.org/abs/2305.17805"><u>单人游戏不完美游戏的计算复杂性</u></a>，<a href="https://arxiv.org/abs/2305.11261"><u>与其他玩家的模拟游戏理论</u></a></li><li><i>批评：</i>自我提议的“我们的变革理论与超级智能AI显然没有相关”</li><li><i>资助方：</i><a href="https://polaris-ventures.org/grants/"><i><u>北极星创投</u></i></a></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> >; $ 500,000</li></ul><p></p><p>我们将<a href="https://www.cooperativeai.com/foundation"><u>CAIF</u></a>转移到了“研究支持”附录。我们将<a href="https://ai.objectives.institute/"><u>AOI</u></a>转移到了“ MISC”。</p><hr><h2> 5.实验室有其他努力</h2><p>（进行很多赌注，而不是遵循一个议程，这对于主题分类法来说是尴尬的。） <br></p><p><i>&nbsp;</i> <a href="https://www.alignmentforum.org/posts/nzmCvRvPm4xJuqztv/deepmind-is-hiring-for-the-scalable-alignment-and-alignment"><i><u>DeepMind Alignment团队</u></i></a><i>&nbsp;</i></p><ul><li><i>一句话摘要</i>：理论产生，威胁建模和玩具方法来帮助这些方法。 “我们的主要威胁模型基本上是规范游戏和目标差异化的结合，导致寻求权力的权力不一致。”有关完整图片，请参见<a href="https://www.alignmentforum.org/posts/nzmCvRvPm4xJuqztv/deepmind-is-hiring-for-the-scalable-alignment-and-alignment"><u>公告</u></a>。</li><li><i>变革理论：</i>将培训过程直接朝对准AI并远离未对齐的AI：构建使技术可以放大/启用对齐工作 - >;应用上述技术以纠正培训非司机的失误 - >;请注意作为功能量表为了确保对齐技术继续起作用。</li><li>另请参见（在本文档中）：基于过程的监督，红色团队，能力评估，机械性解释性，目标错误，因果关系/激励措施</li><li>一些名字：Rohin Shah，Vika Krakovna，Janos Kramar，Neel Nanda</li><li><i>估计的＃ftes：〜40</i></li><li> <i>2023年的某些输出</i>： <a href="https://arxiv.org/abs/2301.05062"><u>Tracr</u></a> ，<a href="https://arxiv.org/abs/2307.09458"><u>电路分析可解释性量表吗？</u></a> ，<a href="https://arxiv.org/abs/2307.15771"><u>九头蛇效应</u></a><i>；</i>理解 /蒸馏威胁模型：“ <a href="https://www.alignmentforum.org/posts/usKXS5jGDzjwqv3FJ/refining-the-sharp-left-turn-threat-model"><u>完善左转锋利</u></a>”（2022）和<i>“</i> <a href="https://www.alignmentforum.org/posts/cq5x4XDnLcBrYbb66/will-capabilities-generalise-more"><u>Will Will Will Permers cluthers termiles</u></a> <i>”</i> （2022） <i>&nbsp;</i></li><li><i>批评：</i> <a href="https://thezvi.substack.com/p/ai-9-the-merge-and-the-million-tokens?utm_source=%2Fsearch%2Fdeepmind&amp;utm_medium=reader2"><u>ZVI</u></a></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：〜</i> $ 10,000,000？<br></li></ul><p><a href="https://www.apolloresearch.ai/"><i><u>阿波罗</u></i></a></p><ul><li><i>一句摘要</i>：概念工作（目前是欺骗性的一致性），审计和模型评估；概念？也是主要实验室中的非公共Interp议程和欺骗性的演变。</li><li><i>变革理论：</i> “从事可解释性和行为模型评估的基础研究，审计现实世界模型的欺骗性一致性，在需要时以我们的技术专业知识为决策者提供支持。”</li><li><i>一些名字：</i> Marius Hobbhahn，Lee Sharkey，Lucius Bushnaq等人</li><li><i>估计＃ftes：</i> 14</li><li> <i>2023年的某些产量</i>：<a href="https://www.apolloresearch.ai/blog/understanding-da-and-sd"><u>了解战略欺骗和欺骗性的一致性</u></a>，<a href="https://www.apolloresearch.ai/research/summit-demo"><u>战略欺骗的研究</u></a>， <a href="https://www.apolloresearch.ai/research/causal-framework-ai-auditing"><u>AI调节和审计的因果框架</u></a>，非公共事物</li><li><i>批评：</i>尚无公众批评</li><li><i>资助者：</i> Openphil，SFF，歧义，“多个机构和私人资助者”</li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> >; $ 2,000,000<br></li></ul><p><i>拟人保证 /信任与安全 / RSP评估 /解释性</i></p><ul><li><i>单句摘要</i>：保持领先于功能曲线/保持能力，以找出最新模型的情况，保持最新风险概况，在发现相关方面传播缺陷。</li><li> <a href="https://www.lesswrong.com/posts/9TWReSDKyshfA66sz/alignment-org-cheat-sheet?commentId=wkcCybFvcq3QuBBX8"><u>变革理论</u></a>：“动手实践经验，建立安全且安排的AI……我们将<a href="https://transformer-circuits.pub/"><u>投资于机械性解释性</u></a>，因为<a href="https://80000hours.org/podcast/episodes/chris-olah-interpretability-research/#ways-that-interpretability-research-could-help-us-avoid-disaster-014550"><u>解决这将是很棒的</u></a>，甚至成功的成功也将有助于我们在风险成为灾难之前发现它们。我们将<a href="https://arxiv.org/abs/2112.00861"><u>培训近切边模型，以研究</u></a><a href="https://arxiv.org/abs/2204.05862"><u>RL诸如人类反馈和基于模型的监督之类的干预措施</u></a>如何成功和失败，对其进行迭代，并研究<a href="https://arxiv.org/abs/2202.07785"><u>随着模型扩大的扩大，新颖的能力如何出现</u></a>。我们还将共享信息，以便政策制定者和其他有关方面可以理解最新技术的状态，并为其他人提供一个负责任的实验室如何进行以安全为中心的研究的例子。”</li><li><i>一些名字：</i>克里斯·奥拉（Chris Olah），妮娜·里姆斯基（Nina Rimsky），塔梅拉·兰纳姆</li><li><i>估计的＃ftes：</i> 60？</li><li> <i>2023年的某些输出</i>： <a href="https://arxiv.org/abs/2302.07459"><u>LLMS中的道德自我纠正</u></a>， <a href="https://arxiv.org/abs/2308.03296"><u>LLM具有影响功能的LLM概括</u></a></li><li><i>评论：</i> <a href="https://forum.effectivealtruism.org/posts/zaSagsDjRmStfJ7MW/responsible-scaling-policies-are-risk-management-done-wrong"><u>RSP</u></a></li><li><i>资助：</i> Google，Amazon，Menlo Ventures，Salesforce，Spark Capital，Sahin Boydas，Eric Sc​​hmidt，Jaan Tallinn，…</li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> 〜一亿美元<br></li></ul><p><a href="https://www.lesswrong.com/posts/ncsxcf8CkDveXBCrA/ai-safety-in-a-world-of-vulnerable-machine-learning-systems-1"><i><u>远的</u></i></a><i>&nbsp;</i></p><ul><li><i>一句话摘要</i>：稳健性 /<a href="https://far.ai/post/2023-03-safety-vulnerable-world/#fault-tolerant-alignment"><u>容忍度对齐</u></a>的科学是他们所说的目的，但他们做了很多可解释的论文和其他事情。</li><li><i>变革理论：</i>使AI系统不那么利用，因此可以防止一种明显的助手AIS / Supergement / Occertight的明显故障模式：对应防止攻击的攻击。总的来说，在被忽视的安全研究方面工作，其他人则没有出于结构原因：对于学术界或独立人士来说太大，但与实验室的利益并不完全一致（例如，原型型号的月球概况，对Frontier模型的令人尴尬的问题）。</li><li><i>一些名字：</i>亚当·格里夫（Adam Gleave），本·戈德（Ben Goldhaber），adriàGarriga-Alonso，Daniel Pandori</li><li><i>估计＃ftes：</i> 10</li><li> <i>2023年的一些产出</i>：<a href="https://far.ai/publication/"><u>论文</u></a>；<a href="https://arxiv.org/pdf/2211.00241.pdf"><u>令人印象深刻的对抗性发现</u></a></li><li><i>评论：</i> <a href="https://www.lesswrong.com/posts/qQuLCAqbZf9ETgNoB/robustness-as-a-path-to-ai-alignment#Limits_of_the_Approach"><i><u>Demski的切线</u></i></a></li><li><i>资助者： ?</i></li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> $ 1,507,686（2022年收入）<br></li></ul><p><a href="https://www.kasl.ai/"><i><u>克鲁格实验室</u></i></a></p><ul><li><i>一句摘要</i>：杂项。了解古哈特定律；奖励学习2.0;证明安全失败；了解DL概括 /学习动态。</li><li><i>变革理论：</i>杂项。改善理论和演示，同时转向政策，以摆脱AGI风险。</li><li><i>一些名字：</i> David Krueger，Dima Krasheninnikov，Lauro Langosco</li><li><i>估计的＃ftes：</i> 12</li><li> <i>2023年的某些输出</i>：<a href="https://arxiv.org/abs/2209.13085"><u>对Goodharting的正式定义</u></a>， <a href="https://openreview.net/forum?id=X3JFgY4gvf"><u>LLM如何权衡来源</u></a>，<a href="https://arxiv.org/abs/2303.06173"><u>作为双重下降</u></a>，概念验证的自动化可解释性（审查）。</li><li><i>批评：？</i></li><li><i>资助方：</i> SFF</li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i> 〜100万美元<br></li></ul><p><i>AI目标研究所（</i> <a href="https://ai.objectives.institute/"><i><u>AOI</u></i></a> <i>）</i></p><ul><li><i>一句摘要</i>：很难分类。如何应用AI来增强人类代理，个人代理和集体代理？哪些目标应与哪些可扩展的授权情报保持一致？如何使用AI来改善机构的责任制？</li><li><i>变革理论：</i>考虑法规如何“保持一致”公司以及如何将AI安全整合到社会中的见解，对技术一致性问题的见解也将出现。现在发展对社会有益的AI，从长远来看，它将提高AI有益的机会，包括通过我们尚未想到的道路。</li><li><i>一些名字：</i> Deger Turan，Matija Franklin，Peli Grietzer，Tushant Jha</li><li><i>估计＃ftes：</i> 7个研究人员</li><li><i>2023年的一些输出</i>： <a href="https://ai.objectives.institute/blog/roadmap-for-a-collaborative-prototype-of-an-open-agencynbsparchitecture"><u>一个OAA叉</u></a>，与<a href="https://ai.objectives.institute/blog/straightlines-surfaces-the-content-beneath-the-headline"><u>实际用户的</u></a><a href="https://ai.objectives.institute/blog/talk-to-the-city-an-open-source-ai-tool-to-scale-deliberation"><u>混凝土工具</u></a>计划</li><li><i>批评：？</i></li><li><i>资助者：</i>生命研究所的未来，多数学院，生存和繁荣项目，私人</li><li><i>值得信赖的命令、关闭、操作安全、共同利益、一致心态：？</i></li><li><i>资源：</i>磁通量，数百万。</li></ul><p></p><p>请参阅<a href="https://www.lesswrong.com/posts/GdyYngK9YPdWSRsC6/appendices-to-the-live-agendas">附录</a>以获取更多信息，您的glutton。</p><hr><h1>更多的元</h1><p>如果您喜欢阅读本文，请考虑向<a href="mailto:funds@lightspeedgrants.org"><u>Lightspeed</u></a> ， <a href="https://manifund.org/projects/mats-funding"><u>Mats</u></a> ， <a href="https://manifund.org/about/donate"><u>Siganund</u></a>或<a href="https://funds.effectivealtruism.org/funds/far-future"><u>LTFF</u></a>捐款：金钱瓶装一些好的工作，有些人专门捐赠资金来启用它。</p><p><i>利益冲突</i>：一个有望的人（我已经申请了该文档的LTFF赠款，但在没有资金的情况下写了整个内容）。我经常与<a href="https://acsresearch.org/"><u>ACS</u></a>和PIBBS合作，并与Team Shard合作。柴曾经给我买了一个墨西哥卷饼。</p><p>如果您有兴趣做或资助这种事情，请通过<a href="mailto:hi@arbresearch.com"><u>hi@arbresearch.com</u></a>与您联系。我从没想过我会成为一名记者，但是陌生的事情会发生。</p><p><br></p><p> Thanks to Alex Turner, Neel Nanda, Jan Kulveit, Adam Gleave, Alexander Gietelink Oldenziel, Marius Hobbhahn, Lauro Langosco, Steve Byrnes, Henry Sleight, Raymond Douglas, Robert Kirk, Yudhister Kumar, Quratulain Zainab, Tomáš Gavenčiak, Joel Becker, Lucy Farnik ，奥利弗·海曼（Oliver Hayman），萨米·马丁（Sammy Martin），杰西·伦贝洛（Jess Rumbelow），让·斯坦尼斯拉斯·丹因（Jean-Stanislas Denain），乌里斯（Ulisse Mini），戴维·马瑟斯（David Mini），克里斯·拉金（Chris Lakin），沃伊·科瓦（Vojta Kova）和琳达·林塞（Linda Linsefors），以获取有用的评论。 </p><p><br></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn06qm74k93eh7"> <span class="footnote-back-link"><sup><strong><a href="#fnref06qm74k93eh7">^</a></strong></sup></span><div class="footnote-content"><p>除非您缩小到目前为止，以至于您可以找到诸如“本体识别”之类的模糊内容。我们将看到该总营业额在2028年再次是正确的；这次，我怀疑一对夫妇仍然会出现。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn0q1picyzu4d"> <span class="footnote-back-link"><sup><strong><a href="#fnref0q1picyzu4d">^</a></strong></sup></span><div class="footnote-content"><p> >;一个人可以将神经网络的解释性视为AI对齐方式的直接定向：相当可牵引，可能在大量场景中有所帮助，基本上具有无限的缩放，并且只会缓慢降低回报。就像任何新的EA事业领域都必须通过第一个比吉维维维德（GiveDryly）更有前途的测试，因此，每种对齐方式都可以视为解释性工作的竞争者。 - <a href="http://niplav.site/bcis_and_alignment.html">Niplav</a></p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/zaaGsFBeDTpCsYHef/shallow-review-of-live-agendas-in-alignment-and-safety#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/zaagsfbedtpcsyhef/shallow-review-eview-of-live-live-agendas-in-alignment-and-safety<guid ispermalink="false"> zaagsfbedtpcsyhef</guid><dc:creator><![CDATA[technicalities]]></dc:creator><pubDate> Mon, 27 Nov 2023 11:10:29 GMT</pubDate> </item><item><title><![CDATA[Paper: "FDT in an evolutionary environment"]]></title><description><![CDATA[Published on November 27, 2023 5:27 AM GMT<br/><br/><p>我不知道如何看待这篇论文，它很长，而且我还没有检查完它的合理性。尽管如此，我注意到它还没有出现在这里，而且很少有论文引用 FDT 论文，所以我想我应该把它扔掉，而不是将它永远放在选项卡中。</p><p>抽象的：</p><blockquote><p>功能决策理论（FDT）是一种相当新的决策理论模式，也是关于主体如何最大化预期效用的规范观点。决策理论和计算机科学的当前标准是因果决策理论（CDT），在很大程度上被认为优于主要的替代证据决策理论（EDT）。这些理论规定了三种不同的最大化效用的方法。我们探讨 FDT 与 CDT 和 EDT 有何不同，以及它对 FDT 代理和人类的行为有何影响。之前的研究已经表明 FDT 如何优于 CDT 和 EDT。我们还展示了 FDT 在更经典的博弈论问题上表现良好，并主张将其扩展到人类问题，以表明其优越性的潜力是强大的。我们还通过在进化环境中展示 FDT 来使其更加具体，直接与其他理论竞争。所有相关代码都可以在这里找到：https://github.com/noahtopper/FDT-in-an-Evolutionary-Environment。</p></blockquote><br/><br/> <a href="https://www.lesswrong.com/posts/oR8hdkjuBrvpHmzGF/paper-fdt-in-an-evolutionary-environment#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/oR8hdkjuBrvpHmzGF/paper-fdt-in-an-evolutionary-environment<guid ispermalink="false">或R8hdkjuBrvpHmzGF</guid><dc:creator><![CDATA[the gears to ascension]]></dc:creator><pubDate> Mon, 27 Nov 2023 05:27:51 GMT</pubDate> </item><item><title><![CDATA[why did OpenAI employees sign]]></title><description><![CDATA[Published on November 27, 2023 5:21 AM GMT<br/><br/><p>最近，OpenAI 员工签署了<a href="https://www.nytimes.com/interactive/2023/11/20/technology/letter-to-the-open-ai-board.html">一封公开信</a>，要求董事会恢复 Sam Altman，增加其他董事会成员（给出一些与 Altman 结盟的人的名字），并辞职，否则他们将退出并追随 Altman 加入微软。</p><p>遵循这些要求将使整个组织置于一个人的控制之下，而不对任何人负责。这似乎并不是 OpenAI 员工想要的情况，除非他们比我想象的要笨。那么，他们为什么要签名呢？以下是一些可能的原因：</p><ol><li>对于像他们这样的人来说，奥特曼真的很可爱——他们就是喜欢他。</li><li>他们对首席执行官被解雇感到一种不公正和愤怒，这是他们对低级别员工被解雇从未有过的感受。</li><li>他们被奥特曼雇佣或以其他方式奖励，因此忠于他个人。</li><li>他们认为，与任何可能的替代首席执行官（包括埃米特·希尔）相比，奥特曼在意识形态上与他们更加一致。</li><li>他们认为，如果奥特曼领导公司，他们的利润份额会更有价值。</li><li>他们受到来自（3）或（4）或（5）强烈观点的人的社会压力。</li><li>他们担心公司会崩溃，他们会失去工作，并希望有机会被微软的一个新部门聘用，而一旦有足够多的人已经签约，签约的风险似乎很低。</li><li>他们担心如果他们不签字，奥特曼会重新担任首席执行官并解雇或以其他方式惩罚他们。</li><li>还有别的事吗？</li></ol><p>您认为哪些原因促使人们签署这封信？您为什么这么认为？</p><br/><br/> <a href="https://www.lesswrong.com/posts/ANStTHjj6it8ysaRJ/why-did-openai-employees-sign#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ANStTHjj6it8ysaRJ/why-did-openai-employees-sign<guid ispermalink="false"> ANStTHjj6it8ysaRJ</guid><dc:creator><![CDATA[bhauth]]></dc:creator><pubDate> Mon, 27 Nov 2023 05:21:29 GMT</pubDate></item></channel></rss>