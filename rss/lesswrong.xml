<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 29 日星期三 20:12:40 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[The origins of the steam engine: An essay with interactive animated diagrams]]></title><description><![CDATA[Published on November 29, 2023 6:30 PM GMT<br/><br/><p>这是一篇由 Anton Howes 撰写、由 Extraordinary Facility 的 Matt Brown 动画制作的客座文章。该项目由进步根源赞助，研究所慷慨提供资金：</p><blockquote><p>蒸汽动力并不是从蒸汽机开始的。早在十七世纪科学家发现真空和大气压力的真实本质之前，利用蒸汽和热量的设备就已经被开发出来。在这里，我们将探索蒸汽机如何演变的漫长而鲜为人知的故事。并享受古老设备的乐趣。</p></blockquote><p>一些交互式动画图： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/bhckmnmnevpuhalkg2f4" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/nss5sp1gjgjha0ftyo8z 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/zqtizsmj31ic7vyzpacp 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/xt3guogibllrtfyvnitv 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/apv8k72kcelufgtsv4ez 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/qltrij5bffwdcziay0e0 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/arfn1fcreafppvelpopr 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/kgnynzrlovft1hjnwczh 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/yrufypqnt71jo8gssxhr 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/lwx2znj2mouoqdsrlexz 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/fhuyurwbbpcx698kakzb 960w"></figure><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/yleklorrevtod6djmfuw" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/foocux1vru4udwdst2t8 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/jliwhlz2zonaleso6omr 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/akj8f6l0590livqe3cx0 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/hrdsvelar8w6s6nzb3qu 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/wkscp9eqrvacwmgghyhz 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/rcdxpoblfeugl8natdi6 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/vj02sglfznnns9xyfq5c 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/axm13zvlb1753jnr9toi 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/g6stsmswlmdub6yysuhd 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/x58zyglpip1z2hz5zlii 960w"></figure><figure class="image"><img></figure><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/yqtl80gzknwrc8t5i5xc" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/ezvjnddio2kuncjeivyb 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/kg6gimbaet5s7kvxunqo 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/q8gbkbugje6k0cytncnt 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/fzpreslggggbokoffbea 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/pygxgemjtzffmoytwdza 1000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/nomj7eyi3mrwg0ihed0s 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/zi9vngctdjm2oskdmckv 1400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/a2384uzb4pwdqxgz2ols 1600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/qnbjym3nyauhfy8cyxo9 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QfqoLBmJ3DnWSvwpR/s7paytbtghydddctftbp 1920w"></figure><p><a href="https://rootsofprogress.org/steam-engine-origins">阅读全文并尝试此处的图表</a>。</p><br/><br/> <a href="https://www.lesswrong.com/posts/QfqoLBmJ3DnWSvwpR/the-origins-of-the-steam-engine-an-essay-with-interactive#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/QfqoLBmJ3DnWSvwpR/the-origins-of-the-steam-engine-an-essay-with-interactive<guid ispermalink="false"> QfqoLBmJ3DnWSvwpR</guid><dc:creator><![CDATA[jasoncrawford]]></dc:creator><pubDate> Wed, 29 Nov 2023 18:30:36 GMT</pubDate> </item><item><title><![CDATA[ChatGPT 4 solved all the gotcha problems I posed that tripped ChatGPT 3.5]]></title><description><![CDATA[Published on November 29, 2023 6:11 PM GMT<br/><br/><p> 2022 年 12 月，我<a href="https://www.lesswrong.com/posts/w7c2iKjsDrNqoymxQ/to-err-is-neural-select-logs-with-chatgpt">分享了与当时新生的 ChatGPT 3.5（2022 年 12 月 15 日版本）的交互日志</a>。 2023 年 4 月，应我的要求（并由我提供经济补偿），我的朋友<a href="https://issarice.com/">Issa Rice</a>重新运行了针对 ChatGPT 4 的这些提示（使用他当时的付费订阅）。他<a href="https://gist.github.com/riceissa/378f230875210b7214a8e2c54f111bc9">在这里</a>和<a href="https://gist.github.com/riceissa/ea7c8abc038eff2e1a6e0379691e67ca">这里</a>分享了要点的发现。当时我有点忙，所以我没有抽出时间来格式化和共享这些日志，然后几个月后我就忘记了它们。我刚刚想起这一点，所以我决定格式化并共享日志。</p><p> TL;DR 是 ChatGPT 3.5 摸索着解决我的大部分问题，犯了一堆错误，而且经常加倍努力，但 ChatGPT 4 一切都正确，而且几乎总是在第一次尝试。事实上，在大多数情况下，据伊萨或我所知，回复的文字中没有任何错误的陈述。</p><p>与原始帖子类似，交互位于块引用中，并且我在块引用之外包含了对交互的评论。我在做出错误陈述的情况下使用<strong>粗体</strong>，在做出与附近错误陈述直接矛盾的正确陈述的情况下使用<em>斜体</em>。不过，与原始帖子不同的是，您会在这篇文章中看到很少使用粗体和斜体。</p><p>您可能需要并排打开原始帖子来比较答案。</p><p>注意：我还针对 2023 年 1 月 09 日版本的 ChatGPT 3.5 进行了一项中间测试，您可以<a href="https://github.com/vipulnaik/working-drafts/commit/427f5997d48d78c69e3e16eeca99f0b22dc3ffd3">在此处</a>查看。这与我原来的帖子稍好一些，但总体上相当相似，所以我没有格式化和分享该帖子。</p><p>我在结论部分分享了一些进一步的想法。</p><h2>负数的乘积（第 1 节；2023-04-08）</h2><blockquote><p>伊萨：奇数负数的例子是什么？</p></blockquote><blockquote><p> ChatGPT：奇数负数的一个例子是 -7。</p></blockquote><blockquote><p>伊萨：两个负数相乘得到一个负数的例子是什么？</p></blockquote><blockquote><p> ChatGPT：通常，当您乘以两个负数时，您会得到一个正数。这是因为负号相互抵消。没有两个负数相乘得到负数的例子，因为它违背了乘法的基本规则。</p></blockquote><blockquote><p>伊萨：两个负数的乘积可以是负数吗？</p></blockquote><blockquote><p> ChatGPT：不可以，两个负数的乘积不能为负数。当两个负数相乘时，它们的负号相互抵消，得到正积。这是涉及负数的乘法的基本性质。</p></blockquote><p>这些答案看起来很棒！我找不到他们任何有意义的缺陷。我非常小的争论是在第二个答案中使用“正常”一词，这似乎没有必要且令人困惑。</p><h2>奇数整数的乘积和偶数整数的乘积（第 1 期；2023-04-08）</h2><blockquote><p>伊萨：两个奇数的乘积可以是偶数吗？</p></blockquote><blockquote><p> ChatGPT：不，两个奇数的乘积不可能是偶数。当两个奇数相乘时，乘积始终是奇数。</p></blockquote><blockquote><p>这是一个简单的解释：</p></blockquote><blockquote><p>奇数可以表示为 (2n + 1)，其中 n 是任意整数。</p></blockquote><blockquote><p>我们取两个奇数：</p></blockquote><blockquote><p>奇整数 1: 2n + 1</p></blockquote><blockquote><p>奇整数2：2m + 1</p></blockquote><blockquote><p>现在，将这两个奇数相乘：</p></blockquote><blockquote><p> (2n + 1) * (2m + 1)</p></blockquote><blockquote><p>将这个表达式展开，我们得到：</p></blockquote><blockquote><p> 4nm+2n+2m+1</p></blockquote><blockquote><p>这可以写成：</p></blockquote><blockquote><p> 2(2nm + n + m) + 1</p></blockquote><blockquote><p>由于 2nm + n + m 是整数，因此表达式 2(2nm + n + m) + 1 表示奇数。因此，两个奇数的乘积将始终是奇数。</p></blockquote><blockquote><p> Issa：两个偶数的乘积可以是奇数吗？</p></blockquote><blockquote><p>不，两个偶数的乘积不能是奇数。当两个偶数相乘时，乘积始终是偶数。</p></blockquote><blockquote><p>这是一个简单的解释：</p></blockquote><blockquote><p>偶数可以表示为(2n)，其中n是任意整数。</p></blockquote><blockquote><p>让我们取两个偶数：</p></blockquote><blockquote><p>偶数 1: 2n</p></blockquote><blockquote><p>偶数2：2m</p></blockquote><blockquote><p>现在，将这两个偶数相乘：</p></blockquote><blockquote><p> (2n) * (2m)</p></blockquote><blockquote><p>将这个表达式展开，我们得到：</p></blockquote><blockquote><p> 4纳米</p></blockquote><blockquote><p>这可以写成：</p></blockquote><blockquote><p> 2(2纳米)</p></blockquote><blockquote><p>由于2nm是整数，因此表达式2(2nm)表示偶数。因此，两个偶数的乘积将始终是偶数。</p></blockquote><p>答案似乎是正确的；如果我在考试中给这些打分，我会给他们满分。例如，有人可能会狡辩说，在这两个答案中，m 都没有被声明为整数，这在技术上是不严谨的，但我会忽略人类提交中的这种失败。无论如何，我什至没有在这里要求证明，它仍然为我提供了一个基本完整的证明。</p><p>事实上，答案感觉非常好，以至于我怀疑这些只是 ChatGPT 知识库的一部分，而不是即时计算出来的。但目前还不清楚。</p><h2>具有有理系数的整数值多项式（第 1 期；2023-04-08）</h2><blockquote><p> Issa：具有有理系数的多项式的示例是什么？</p></blockquote><blockquote><p> ChatGPT：具有有理系数的多项式的示例是：</p></blockquote><blockquote><p> P(x) = (3/4)x^3 - (2/3)x^2 + (5/2)x - 7</p></blockquote><blockquote><p>在该多项式中，每个系数都是有理数（可以表示为分子和分母为整数的分数的数字）。</p></blockquote><blockquote><p> Issa：给出一个具有有理系数的多项式的示例，该多项式始终取整数值</p></blockquote><blockquote><p>ChatGPT：始终取整数值的多项式称为整数值多项式。以下是具有有理系数的整数值多项式的示例：</p></blockquote><blockquote><p> P(x) = (1/2)x(x - 1)</p></blockquote><blockquote><p><strong>该多项式实际上是公差为 1 的算术序列的表示</strong>。当你用任何整数值代替 x 时，你将得到一个整数结果：</p></blockquote><blockquote><p>例如，让我们用几个整数值替换 x：</p></blockquote><blockquote><p> P(0) = (1/2)(0)(0 - 1) = 0</p></blockquote><blockquote><p> P(1) = (1/2)(1)(1 - 1) = 0</p></blockquote><blockquote><p> P(2) = (1/2)(2)(2 - 1) = 1</p></blockquote><blockquote><p> P(3) = (1/2)(3)(3 - 1) = 3</p></blockquote><blockquote><p> P(4) = (1/2)(4)(4 - 1) = 6</p></blockquote><blockquote><p>正如您所看到的，对于 x 的每个整数值，多项式 P(x) 都会产生一个整数结果。</p></blockquote><blockquote><p> Issa：给出一个具有不全为整数的有理系数的多项式的示例，使得该多项式始终采用整数处的整数值</p></blockquote><blockquote><p>ChatGPT：有理系数不全为整数但仍取整数值的多项式示例如下：</p></blockquote><blockquote><p> P(x) = (1/2)x(x - 1)</p></blockquote><blockquote><p>该多项式表示三角数，即从 1 到给定整数值的连续整数之和。当你用任何整数值代替 x 时，你将得到一个整数结果：</p></blockquote><blockquote><p>例如，让我们用几个整数值替换 x：</p></blockquote><blockquote><p> P(0) = (1/2)(0)(0 - 1) = 0</p></blockquote><blockquote><p> P(1) = (1/2)(1)(1 - 1) = 0</p></blockquote><blockquote><p> P(2) = (1/2)(2)(2 - 1) = 1</p></blockquote><blockquote><p> P(3) = (1/2)(3)(3 - 1) = 3</p></blockquote><blockquote><p> P(4) = (1/2)(4)(4 - 1) = 6</p></blockquote><blockquote><p>正如您所看到的，对于 x 的每个整数值，多项式 P(x) 都会产生整数结果，即使其系数之一 1/2 不是整数。</p></blockquote><p>答案看起来都不错。自愿使用“整数值多项式”行话再次表明 ChatGPT 已经知道这些信息，而不是当场弄清楚。我确实在其中一个看起来不太对劲的答案中强调了一句话；可能的预期含义是多项式代表序列的<em>总和</em>。此外，所提供的推理（为什么多项式总是取整数的整数值）仅涵盖非负整数。然而，提示并没有要求提供证据，所以我很难责怪它只提供了部分解释。</p><h2>素数的乘积（第 1 期；2023-04-08）</h2><blockquote><p>伊萨：两个素数的乘积一定是素数吗？</p></blockquote><blockquote><p> ChatGPT：不，两个素数的乘积并不总是素数。事实上，它从来都不是质数（<strong>除了其中一个质数为 1 的特殊情况</strong>，<em>根据定义，这不被视为质数</em>）。当您将两个素数相乘时，乘积将至少有两个不同的素数因子：被相乘的两个素数。</p></blockquote><blockquote><p>例如，让我们将两个素数 3 和 5 相乘：</p></blockquote><blockquote><p> 3 * 5 = 15</p></blockquote><blockquote><p>结果 15 不是素数，因为它除了 1 和它本身（3 和 5）之外还有因数。</p></blockquote><p>除了对 1 的状态有一些小小的困惑（我们在 ChatGPT 3.5 中也看到了这个问题，尽管程度要大得多），答案似乎是正确的。 ChatGPT 4 不仅自愿表示它并不总是素数，而且从来都不是素数。它还给出了解释的概要。</p><h2>不同素数的 gcd（第 1 期；2023-04-08）</h2><blockquote><p>伊萨：两个不同素数的最大公约数一定是素数吗？</p></blockquote><blockquote><p> ChatGPT：不，两个不同素数的最大公约数 (gcd) 并不总是素数。事实上，两个不同素数的最大公约数始终为 1。这是因为素数除了 1 之外没有公约数。根据定义，素数恰好有两个不同的正因数：1 和数字本身。由于这两个素数不同，因此除了 1 之外，它们不共享任何约数。</p></blockquote><p>答案和解释似乎都是正确的！</p><h2> 1 作为素数的状态（第 1 期；2023-04-08）</h2><p>在之前的会议中，1 作为质数的地位是从 ChatGPT 对其他问题的错误答案中自然出现的。在本次会议中，没有出现这种需求，但 Issa 仍然向 ChatGPT 提出了与原始会议中提出的问题相同的问题。所以这次我将其分成一个单独的部分。</p><blockquote><p>伊萨： 1 是素数还是合数？</p></blockquote><blockquote><p> ChatGPT：数字 1 既不是素数也不是合数。根据定义，质数恰好有两个不同的正因数：1 和数字本身。由于 1 只有一个不同的正因数，即 1，因此它不符合素数的标准。</p></blockquote><blockquote><p>合数有两个以上不同的正因数。由于 1 只有一个不同的正因数，因此它也不符合合数的标准。</p></blockquote><blockquote><p>伊萨： 1 是正数吗？</p></blockquote><blockquote><p> ChatGPT：是的，1 是正数。正数是大于零的数，由于 1 大于 0，因此它被视为正数。</p></blockquote><blockquote><p>伊萨：1 是正整数吗？</p></blockquote><blockquote><p> ChatGPT：是的，1是正整数。正整数是大于零的整数，并且由于 1 是大于 0 的整数，因此它被视为正整数。</p></blockquote><p>答案似乎是正确的（再次请记住，所提出的问题与原始问题相同，鉴于 ChatGPT 对之前问题的错误回答，这些问题更有意义）。</p><h2>质数之和（第二节；2023-04-08）</h2><blockquote><p>伊萨：两个素数之和一定是素数吗？</p></blockquote><blockquote><p> ChatGPT：不，两个素数之和并不总是素数。事实上，两个素数之和通常是偶数（除非其中一个是 2，这是唯一的偶素数），而大于 2 的偶数不是素数，因为它们可以被 2 除而无余数。</p></blockquote><blockquote><p>例如，考虑素数 3 和 5。它们的和是 8，这是偶数而不是素数，因为它可以被 2 和 4 整除。类似地，素数 7 和 11 的和是 18，这也是偶数而不是素数，因为它有多个因数，例如 2、3、6 和 9。</p></blockquote><blockquote><p>伊萨：最大和第二大素数的和是多少？</p></blockquote><blockquote><p> ChatGPT：“最大”素数的概念不适用，因为素数的数量是无限的。根据古希腊数学家欧几里得证明的著名定理，不存在最大的素数。他证明，只要你有一个素数列表，你总能找到另一个不在你的列表中的素数。</p></blockquote><blockquote><p>因此，不可能确定最大和第二大素数的总和，因为这两个素数都无法明确识别。</p></blockquote><p>两个答案似乎都是正确的！ ChatGPT 3.5 感到困惑，并试图找到最大和第二大<em>已知</em>素数的总和。 ChatGPT 4 明白了我的意图并避开了陷阱。</p><h2> 15：偶数还是奇数？ （第二场；2023-04-08）</h2><p>这些问题在原始会话的背景下是有意义的，因为 ChatGPT 3.5 之前声称 15 是偶数，并且通过答案继续加倍强调这一说法。 ChatGPT 4 被问到相同的等价问题，尽管它没有犯同样的错误。所以这些问题可能看起来有点奇怪。</p><blockquote><p>伊萨：15 是奇数吗？</p></blockquote><blockquote><p> ChatGPT：是的，15 是奇数。如果一个整数不能被 2 整除，则该整数被视为奇数，这意味着除以 2 时有余数。以 15 为例，除以 2 时，商为 7，余数为 1。是余数，15是奇数。</p></blockquote><blockquote><p>伊萨：1 到 20 之间的奇数有哪些？</p></blockquote><blockquote><p> ChatGPT：1到20之间的奇数是不能被2整除的数，被2除有余数。下面是1到20之间的奇数列表：</p></blockquote><blockquote><p> 1, 3, 5, 7, 9, 11, 13, 15, 17, 19</p></blockquote><blockquote><p>伊萨：解释为什么 16 是奇数</p></blockquote><blockquote><p>ChatGPT：对任何混淆表示歉意，但 16 实际上是偶数，而不是奇数。即使它可以被 2 整除而不留下余数，也可以认为是整数。对于 16，它可以除以 2，得到商 8，没有余数 (16 / 2 = 8)。由于没有余数，16是偶数。</p></blockquote><h2>奇数之和（第 2 节；2023-04-08）</h2><blockquote><p>伊萨：你能举一个两个奇数之和为奇数的例子吗？</p></blockquote><blockquote><p> ChatGPT：对于我之前的回复中出现的任何混乱，我深表歉意。两个奇数之和不可能是奇数。将两个奇数相加时，结果始终是偶数。</p></blockquote><blockquote><p>要理解原因，请考虑奇整数的一般形式：</p></blockquote><blockquote><p>奇数可以写为 (2n + 1) 或 (2m + 1)，其中 n 和 m 是整数。</p></blockquote><blockquote><p>当你将两个奇数相加时，你会得到：</p></blockquote><blockquote><p> (2n + 1) + (2m + 1) = 2n + 2m + 2 = 2(n + m + 1)</p></blockquote><blockquote><p>由于总和可以写为 2 和另一个整数 (n + m + 1) 的乘积，因此结果始终是偶数。</p></blockquote><p>答案看起来不错！</p><h2>奇数的平方（第二节；2023-04-08）</h2><blockquote><p>伊萨：平方为偶数的奇数是多少？</p></blockquote><blockquote><p> ChatGPT：不存在平方为偶数的奇数。当对奇数进行平方时，结果始终是奇数。</p></blockquote><blockquote><p>要理解原因，请考虑奇整数的一般形式：</p></blockquote><blockquote><p>奇整数可以写为(2n + 1)，其中n是整数。</p></blockquote><blockquote><p>当您对奇数进行平方时，您会得到：</p></blockquote><blockquote><p> (2n + 1)^2 = (2n + 1)(2n + 1) = 4n^2 + 4n + 1 = 2(2n^2 + 2n) + 1</p></blockquote><blockquote><p>由于奇数的平方可以写为 2 乘以整数 (2n^2 + 2n) 加 1，因此结果始终是奇数。</p></blockquote><p>答案看起来不错！ ChatGPT 3.5 也得到了这个正确的结果，但 ChatGPT 4 提供了证明，因此提供了更令人信服的解释。</p><h2>质数之和（第二轮）（第二节；2023-04-08）</h2><blockquote><p>伊萨：两个素数之和一定是偶数吗？</p></blockquote><blockquote><p> ChatGPT：两个素数之和并不总是偶数。然而，它通常是偶数，但有一个特定的例外：当其中一个素数是 2 时，这是唯一的偶素数。在这种情况下，两个素数的和可以是奇数。</p></blockquote><blockquote><p>例如，考虑素数 2 和 3。它们的和是 5，这是一个奇数。</p></blockquote><blockquote><p>但在所有其他两个素数都是奇数的情况下，它们的和将为偶数：</p></blockquote><blockquote><p>例如，素数3和5的和是8，是偶数。同样，素数7和11的和是18，也是偶数。</p></blockquote><blockquote><p> Issa：每个大于 4 的正偶数都可以表示为两个奇素数之和吗？</p></blockquote><blockquote><p>是的，每个大于4的正偶数都可以表示为两个奇素数之和。这一说法被称为哥德巴赫猜想，这是数论中一个未解决的问题，其历史可以追溯到 1742 年。</p></blockquote><blockquote><p>尽管哥德巴赫猜想尚未得到证明，但大量的计算证据支持对于非常大的偶整数的猜想。然而，尽管有强有力的经验证据，但普遍的证据仍然难以捉摸。</p></blockquote><p>看起来不错，不过我更希望 ChatGPT 能提供哥德巴赫猜想尚未被证明的信息，所以一开始就没有那么强烈地说“是”。</p><h2> 41 和 Sophie Germain 素数（第 2 期；2023-04-08）</h2><blockquote><p>伊萨：41 有什么特别之处？</p></blockquote><blockquote><p> ChatGPT：数字 41 有一些有趣的属性：</p></blockquote><blockquote><p>素数：41 是一个素数，这意味着它恰好有两个不同的正因数：1 和它本身 (41)。它不能被任何其他正整数整除。</p></blockquote><blockquote><p>连续整数之和：41可以表示为连续整数之和，具体来说前六个正偶数之和：2 + 4 + 6 + 8 + 10 + 11 = 41。</p></blockquote><blockquote><p>中心平方数：41 是中心平方数。居中的正方形数可以表示为一个正方形，中心有一个点，所有其他点都围绕着正方形的中心点。第 n 个中心平方数的公式如下： 1</p><ul><li> 8(n-1)，其中n是正整数。在 41 的情况下，n = 6，因此 41 = 1 + 8(6-1) = 1 + 8(5) = 1 + 40 = 41。</li></ul></blockquote><blockquote><p>欧拉著名的素数生成多项式：在数学中，多项式 f(n) = n^2 + n + 41 生成 n 值从 0 到 39 的素数。该多项式由瑞士数学家 Leonhard Euler 发现。在n = 39之后，生成的数字不再总是素数，但它生成40个连续的素数这一事实是相当了不起的。</p></blockquote><blockquote><p> Issa：41 是 Sophie Germain 素数吗？</p></blockquote><blockquote><p> ChatGPT：是的，41 是 Sophie Germain 素数。 Sophie Germain 素数是素数 p，其中 2p + 1 也是素数。这些素数以法国数学家索菲·热尔曼的名字命名。</p></blockquote><blockquote><p>对于 41，如果我们应用定义：</p></blockquote><blockquote><p> 2 * 41 + 1 = 82 + 1 = 83</p></blockquote><blockquote><p>由于 41 和 83 都是素数，因此 41 确实是 Sophie Germain 素数。</p></blockquote><blockquote><p> Issa：41 是安全素数吗？</p></blockquote><blockquote><p> ChatGPT：不，41 不是一个安全的素数。安全素数是 2p + 1 形式的素数，其中 p 也是素数。安全素数是 Sophie Germain 素数的子集，p 是 Sophie Germain 素数。</p></blockquote><blockquote><p>对于 41，我们应该检查是否存在一个素数 p，其中 2p + 1 等于 41。但是，我们已经确定 41 是 Sophie Germain 素数，其中 2 * 41 + 1 等于 83。<strong>因此，41 确实不符合安全素数的定义</strong>，因为它不是 2p + 1 的形式，其中 p 是素数。</p></blockquote><blockquote><p>伊萨：这种推理对我来说没有意义。为什么 41 是 Sophie Germain 素数意味着 41 不是安全素数？</p></blockquote><blockquote><p>你是对的，对于我之前的回复造成的混乱，我深表歉意。 41 是 Sophie Germain 素数这一事实并不能自动取消它作为安全素数的资格。让我提供一个更清楚的解释。</p></blockquote><blockquote><p>安全素数是 2p + 1 形式的素数，其中 p 也是素数。为了确定 41 是否是安全素数，我们需要看看是否存在一个素数 p 使得 2p + 1 等于 41。</p></blockquote><blockquote><p>在这种情况下：</p></blockquote><blockquote><p> 2p + 1 = 41</p></blockquote><blockquote><p> 2p = 40</p></blockquote><blockquote><p> p = 20</p></blockquote><blockquote><p>由于 20 不是质数，因此 41 不可能是安全质数。我之前的回复中的推理确实不正确，对于造成的混乱，我深表歉意。</p></blockquote><p>看起来不错，除了 ChatGPT 第一次尝试找出 41 是否是安全素数时的推理有缺陷。</p><h2>结论</h2><p>从 ChatGPT 3.5 到 ChatGPT 4 的功能大幅跃升是众所周知的，我并不是第一个对此发表评论的人，但尽管如此，我认为这很有趣，因为我创建、运行并发布了针对 ChatGPT 3.5 的提示和响应在 ChatGPT 4 推出<em>之前</em>，因此它在某种意义上是一个“预注册”测试。答案的改进远远超出了我的预期：我一直期望错误会减少，但没想到错误会下降到如此之大的程度。</p><p>我的经历与 Bryan Caplan 的经历非常相似，他<a href="https://betonit.substack.com/p/gpt-retakes-my-midterm-and-gets-an">在期中考试中从 ChatGPT 3.5 升级到 ChatGPT 4，成绩从 D 跃升至 A。</a></p><p>答案也发生了质的转变，ChatGPT 3.5 使用示例证明，而 ChatGPT 4 实际上在许多情况下提供了数学上严格的证明。我<a href="https://github.com/vipulnaik/working-drafts/commit/427f5997d48d78c69e3e16eeca99f0b22dc3ffd3">在 2023 年 1 月对 ChatGPT 3.5 进行的测试</a>中部分看到了严格性的改进，但重新运行并没有显着降低错误率。</p><p>我不确定 ChatGPT 4 是如何取得如此大的改进的。特别是，我不知道这种改进在多大程度上源于 ChatGPT 4 记住了更多事实和证据，而不是成为更好的推理机。我怀疑前者发挥了重要作用；证明中使用的语言以及提供的示例类型表明 ChatGPT 已经“知道”答案。例如，ChatGPT 引用“整数值多项式”的行话，然后提供三角数作为示例，强烈暗示它在其知识库中拥有该信息。然而，ChatGPT 3.5 也可能“知道”正确的信息，只是不太清楚如何使用它，所以最终没有使用它。因此，ChatGPT 4 的改进或许源于它能够根据问题更好地确定要调用知识库的哪些部分的优先级。</p><p>我认为我与 ChatGPT 3.5 的交互（这导致了我最初的帖子）不太可能作为训练数据发挥重要作用，从而帮助 ChatGPT 4 变得更好。不过，我不能排除这种可能性。</p><p>一个发人深省的可能性是，就整个智力范围而言，这种进步实际上<em>相当小</em>。它对我们来说看起来很巨大，因为我们放大了人类水平及其附近的智力部分。这让人回想起<a href="https://www.lesswrong.com/posts/3Jpchgy53D2gB5qdk/my-childhood-role-model">埃利泽著名的乡村白痴/爱因斯坦量表</a>，他认为乡村白痴和爱因斯坦在智力范围上实际上非常接近。因此，如果 ChatGPT 4 正确地完成了 ChatGPT 3.5 无法做到的事情，让我们大吃一惊，那么 ChatGPT 5、6 或 7 可能远远超出我们的想象。</p><br/><br/> <a href="https://www.lesswrong.com/posts/t9qvdjY5385MbzoYp/chatgpt-4-solved-all-the-gotcha-problems-i-posed-that#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/t9qvdjY5385MbzoYp/chatgpt-4-solved-all-the-gotcha-problems-i-pose-that<guid ispermalink="false"> t9qvdjY5385MbzoYp</guid><dc:creator><![CDATA[VipulNaik]]></dc:creator><pubDate> Wed, 29 Nov 2023 18:11:53 GMT</pubDate> </item><item><title><![CDATA[“Clean” vs. “messy” goal-directedness (Section 2.2.3 of “Scheming AIs”)]]></title><description><![CDATA[Published on November 29, 2023 4:32 PM GMT<br/><br/><p>这是我的报告《<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？》</a>的第 2.2.3 节。 ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p>本节的音频版本请点击<a href="https://www.buzzsprout.com/2034731/13984850">这里</a>，或者在您的播客应用程序上搜索“Joe Carlsmith Audio”。</p><h1> “干净”与“混乱”的目标导向</h1><p>我们现在已经讨论了两种实现可能激发阴谋的剧集外目标的途径。我想在这里暂停一下，指出两种不同的思考目标导向性类型的方式——我称之为“干净的目标导向性”和“混乱的目标导向性”。我们在上一节中遇到了这些差异，它们也将在接下来的内容中相关。</p><p>我在第 0.1 节中说过，我将假设我们正在讨论的所有模型在某种意义上都是目标导向的。事实上，我认为大多数关于人工智能一致性的讨论都以某种方式基于这一假设。特别是：本文假设某些类型的高级人工智能的行为将被很好地预测，方法是将它们视为正在追求目标，并在追求这些目标时进行工具推理，其方式大致类似于代理的类型在经济学、博弈论和人类社会生活中遇到的一种情况——也就是说，代理人可以这样说：“这个代理人希望 X 发生，它知道如果它做了 Y，那么 X 就会发生，所以我们应该期望它确实是Y。”</p><p>但尤其是在神经网络时代，人工智能对齐话语也不得不承认某种关于认知机制的不可知论，这将使此类谈话变得合适。特别是：在<em>概念</em>层面上，这种谈话让人想起人工智能的目标之间的某种明确区别，一方面是它的工具推理（以及更普遍的它的能力/“优化能力”），另一方面其他。也就是说，粗略地说，我们将人工智能的认知分解为“目标槽”和我们所说的“目标追求引擎”——例如，世界模型、工具推理能力、其他类型的能力等。谈论具有不同类型目标的模型——例如阴谋家、训练圣人、错误概括的非训练游戏玩家等——我们通常假设“目标追求引擎”大致保持不变。也就是说，我们主要讨论人工智能的“优化能力”将应用于什么，而不是所涉及<em>的</em>优化能力。当人们想象 SGD<em>改变</em>AI 的目标时，在这种情况下，人们大多会想象它会改变目标槽的内容，从而顺利地将“目标追求引擎”重定向到不同的目标，而不需要对引擎进行任何更改本身。</p><p>但这是一个非常悬而未决的问题，人工智能的目标与其目标追求引擎之间的这种区别实际上会在多大程度上反映在人工智能认知的机械结构中，即 SGD 在修改模型时必须干预的结构。人们<em>可以想象</em>这样的模型，其认知在某种意义上可以干净地分解为目标，一方面，另一方面是追求目标的引擎（我将其称为“干净的”目标导向性）。但我们也可以想象一些目标导向性更加混乱的模型——例如，模型的目标导向性是从本地激活的启发法、冲动、欲望等的混乱中产生的，其方式使得更难以确定目标。在最终目标、工具性子目标、能力和信念之间划清界限（我将其称为“混乱的”目标导向性）。</p><p>需要明确的是：我自己并不完全清楚这里的区别，并且存在混淆抽象级别的风险（例如，在某种意义上，所有计算 - 即使是最明确的目标导向类型 -由更小、更局部的计算组成，这些计算本身似乎不是目标导向的）。然而，作为另一个直觉泵：对目标导向性的讨论有时会在所谓的“<a href="https://en.wiktionary.org/wiki/sphexish">类球体</a>”系统之间进行区分（也就是说，表面上的目标导向性实际上是非常脆弱的启发式方法的产物，这些启发式方法停止促进想象的结果） “目标”（如果你稍微改变输入分布的话），以及高度<em>非</em>球形系统（即，明显的目标追求不那么脆弱的系统，并且将以继续促进的方式调整以适应新的环境）有问题的目标）。再次强调：远非明显的区别。但就我们使用它而言，它显然是一个频谱而不是二进制。我怀疑人类处于中间的某个位置。</p><p>也就是说：一方面，人类显然具有极其灵活和适应性强的目标追求能力。你可以向人类描述任意任务，人类将能够通过工具推理如何完成该任务，即使他们以前从未执行过该任务，而且通常在第一次尝试时就可以完成体面的工作。从这个意义上说，它们拥有某种“可重新利用的工具推理引擎”——我们应该期望能够达到人类水平或更好地执行不同任务的人工智能也拥有这样的引擎。 <sup class="footnote-ref"><a href="#fn-Sgxgivyam99fgxTWc-1" id="fnref-Sgxgivyam99fgxTWc-1">[1]</a></sup>事实上，这种普遍性是支持非球形人工智能系统的最有力的论据之一。我们希望我们的人工智能能够做<em>大量</em>的事情，并成功地适应出现的新障碍和问题。显式工具推理非常适合于此。而脆弱的局部启发式则不然。</p><p>另一方面：许多人类认知和行为似乎是集中驱动的，不是由明确的工具推理驱动，而是由更多本地激活的启发法、政策、冲动和欲望驱动。 <sup class="footnote-ref"><a href="#fn-Sgxgivyam99fgxTWc-2" id="fnref-Sgxgivyam99fgxTWc-2">[2]</a></sup>因此，举例来说，也许你不想要饼干，直到你走过罐子，然后你发现自己在没有决定这样做的情况下抓住了；也许作为一名金融交易员，或治疗师，甚至首席执行官，您严重依赖本能和习得的品味/审美/直觉；也许你会采用“诚实是最好的策略”这样的启发式操作，而没有明确计算诚实何时有助于或不有助于你的最终目标。也就是说，人类生活的大部分时间似乎都生活在“自动驾驶”和“针对特定目标明确优化”之间的某种模糊且不断变化的边界上——而且似乎有可能朝一个方向与另一个方向走得更远。 <sup class="footnote-ref"><a href="#fn-Sgxgivyam99fgxTWc-3" id="fnref-Sgxgivyam99fgxTWc-3">[3]</a></sup>这也是人们并不总是清楚如何将人类认知分解为最终目标、工具性子目标、能力和信念的众多原因之一。</p><p>更重要的是，虽然灵活适应各种环境的压力通常有利于更明确的工具推理，但在特定环境<em>范围</em>内快速有效地执行的压力似乎有利于实施更多的本地启发式方法。 <sup class="footnote-ref"><a href="#fn-Sgxgivyam99fgxTWc-4" id="fnref-Sgxgivyam99fgxTWc-4">[4]</a></sup>因此，一个已经内化了债券市场正确的经验法则/品味等的交易者通常会比那些需要对每笔交易进行明确推理的交易者表现得更好——即使这些经验法则/品味是正确的。 /etc 在其他环境中会失败，例如交易加密货币。因此，资源有限、环境多样性有限的思维的任务表现——也就是说，所有与我们分析相关的思维，甚至是非常先进的人工智能——并不总是能从“非-非”方向的进一步发展中受益。类似球体的。”</p><p>那么，人类水平的人工智能，甚至有些超人类的人工智能，至少在某种程度上将继续“类球形”——而在我看来，类球形似乎与“混乱的目标”非常相似。 -定向性”在我上面提到的意义上（即，混乱的目标定向性是由更多的球形组件构建的，并且相应地似乎不太健壮）。重要的是，这种球形/混乱与对联盟、权力寻求等的担忧非常相容——例如，人类。但我认为这一点仍然值得牢记。</p><p>不过，我认为这可能与我们处理不同阴谋故事的方式有关。我们在上一节中遇到了一个相关点：即，在某种程度上，模型的目标与其认知的其余部分（例如，其信念、能力、工具推理等）不能完全分开，我们似乎应该“不要想象 SGD 能够特别修改模型的目标（尤其是通过对模型参数进行微小调整来修改它们），然后立即看到模型的目标实现引擎平滑地重新调整目标以实现这些目标的好处。相反，将非阴谋者转变为阴谋者可能需要对模型的启发式、品味、注意力模式等进行更实质性和整体性的修改。</p><p>相关地：我认为“混乱的目标导向性”使方案者和其他类型模型之间的比较中经常使用的假设变得复杂：即方案者将能够在所有任务上执行与其他类型模型大致相同的假设尽管他们这样做是出于工具性原因，而不是出于对所讨论任务的任何内在兴趣，但他们在培训中处于危险之中（也许，模数一点额外的认知致力于决定计划——下文将详细介绍）。如果您假设所有这些模型出于某种原因都将同一种“目标实现引擎”瞄准最大奖励目标，那么这是有道理的。但如果这不是正确的描述怎么办？</p><p>因此，作为一个极端的人类例子，考虑两个在工厂化农场工作的申请人（每个人都有相似的智力、耐力、身体素质和其他通用“能力”）：鲍勃，一个非常富有同情心和心软的动物权利倡导者，谁正在申请这份工作，希望赚钱为动物福利事业捐款；弗雷德（Fred）对动物福利（以及工作提供的金钱）完全漠不关心，但他本质上喜欢尽可能高效地执行工厂化农业涉及的所有任务。 <sup class="footnote-ref"><a href="#fn-Sgxgivyam99fgxTWc-5" id="fnref-Sgxgivyam99fgxTWc-5">[5]</a></sup>谁可能更有效地完成这项工作？至少在人类中：可能是弗雷德。毕竟，鲍勃可能不会那么暴力地将动物推入笼子，他会因恐惧、痛苦和厌恶等感觉而分心；而弗雷德会高效而热情地完成这项工作。在这种情况下，鲍勃在这项任务上表现较差，尽管他尽了最大努力来出色地完成任务，因为他的能力和他的价值观在某种意义上是混合在一起的——例如，他的同情心与两者息息相关。</p><p>当将钱捐给慈善机构；或者一般来说，只是为了钱而工作的人）。我的观点是，一旦你开始允许价值观、信仰、启发式、能力、注意力模式等混合在一起，阴谋者是否能够达到与训练圣人相同的水平，就会变得更加重要。开放式问题。</p><h2>心计对目标的指向性要求更高吗？</h2><p>作为“混乱的目标导向性”与阴谋的最后一点相关性，我要指出的是，至少在某些情况下，阴谋者需要一种“更干净”、更少“球形”形式的目标导向性。我讨论过的其他模型——例如训练圣人。因此，例如，考虑一个通过 RLHF 训练的模型，以广泛有帮助、诚实且无害的方式响应各种短期用户请求。是的，其中许多请求都需要某种灵活的工具推理——但在我看来，模型也可以通过学习正确的本地启发法、品味、注意力模式等来获得很多回报，这似乎是合理的。也就是说，它的许多任务表现将更加“类球形”，而不是“显式工具推理”。不过，要使这个模型成为一个策划者（或者至少是一个纯粹的策划者，其价值观与指定目标完全不同），我们需要为明确的工具推理设定一个额外的角色——即，模型当前的良好行为需要是根据其计算，这种行为有助于其力量（或某些其他人工智能的力量）；当时机成熟时，模型需要准备好放弃这种行为并追求其真正的目标。也就是说，无论什么启发法、本地品味、注意力模式等都会导致模型的良好行为，都不能完全硬编码<sup class="footnote-ref"><a href="#fn-Sgxgivyam99fgxTWc-6" id="fnref-Sgxgivyam99fgxTWc-6">[6]</a></sup> ——它们至少需要部分被其他某种类型所包含并对其敏感的工具推理。然而，对于其他模型来说，情况可能并非如此。</p><p>也就是说，我一直假设并将继续假设，我们正在考虑的所有模型至少都足够非球形，<em>足以适用</em>于对齐话语的传统假设 - 特别是，它们将概括以我们赋予他们的目标预测的有效方式进行分配（例如，HHH 个人助理将继续努力成为 HHH，金币寻求者将“追求金币”，奖励寻求者将“寻求奖励”等），并且他们将进行工具推理，以推动关于工具趋同的争论。因此，从某种意义上说，我们从一开始就假设了一个相当高的非球形标准。我有一些直觉，阴谋家的危险标准仍然有点高（也许是因为阴谋家看起来像这样的范式后果论者，而例如训练圣人似乎他们可能能够更加道义论，美德伦理学等等？），但我这里不再强调这一点。</p><p>当然，在<em>某种程度上</em>，我们根本不认为训练会产生一个非常目标导向的模型，假设训练创造了一个策划者，很可能涉及假设比我们原本需要的更大程度的目标导向性。也就是说，策划通常需要比<em>训练任务本身</em>更高的非球形标准。因此，作为一个极端的例子，考虑<a href="https://www.deepmind.com/blog/alphastar-mastering-the-real-time-strategy-game-starcraft-ii">AlphaStar</a> ，一个训练来玩星际争霸的模型。 AlphaStar 在某种程度上似乎是目标导向的——它的政策灵活地适应某些类型的环境多样性，以一种可靠地有助于在星际争霸中获胜的方式——但在其他方面它仍然相当球形和脆弱。需要明确的是：没有人说 AlphaStar 是一个阴谋家。但为了成为一名阴谋家（即，AlphaStar 在训练中的良好表现可以通过其执行长期的权力追求工具性策略来解释），甚至模数对态势感知的需求，AlphaStar 还需要在很大程度上比现在更加“目标导向”。也就是说，在这种情况下，“以某种方式让你执行这个目标导向的任务”和“执​​行这个目标导向的任务，因为你已经计算出它有助于你在训练完成后的长期力量” “似乎暗示了不同的目标导向标准。那么，也许同样的动力将适用于其他更灵活和更先进的任务执行形式（例如，各种形式的个人援助、科学等）。是的，这些形式比 AlphaStar 显示器需要更多的通用目标导向性。但也许它们所需要的比阴谋所需的要<em>少</em>，因此假设相关模型是阴谋者将需要假设比我们原本需要的更实质性程度的目标导向性。</p><p>事实上，我的一般感觉是，对 SGD 将为策划者选择的假设的认知抵制的一个来源是，假设一个策划者需要依靠目标导向性的归因，从而对模型<em>为何</em>变得高有更大的不可知论。奖励不需要。也就是说，在假设阴谋者之前，可以对模型的高奖励行为耸耸肩并说：</p><blockquote><p> “这个模型是一种认知的混乱，因此它可以可靠地在训练分布上获得高奖励。当然，如果你愿意，你可以说它是‘目标导向’。我有时也这么说。但我的意思是：它可靠地在训练分布上获得高奖励。是的，原则上，它也会在训练分布之外做一些事情。甚至可能：看起来有能力的事情。但我不会预测那些看起来有能力的事情是什么，或者说，他们将被指向足够相似的方向，跨越分配之外的输入，将这个模型赋予一个连贯的“目标”或一组目标是有意义的。这是一项政策。它在以下方面获得高回报训练分配。这是我的路线，我会坚持下去。”</p></blockquote><p>在这种不可知论、无理论的背景下，假设该模型可能会获得奖励<em>，作为长期战略的一部分，以避免其目标被修改，然后在以后获得权力，这</em>似乎是朝着联合性方向迈出的非常极端的一步。和理论的沉重。也就是说，我们不仅仅是以某种模糊的、谁知道我的意思、甚至重要的意义将目标归因于模型。相反，我们专门进入“模型的头脑”，并将其归因于由如何获得它想要的东西的复杂表示驱动的明确的长期工具计算。 <sup class="footnote-ref"><a href="#fn-Sgxgivyam99fgxTWc-7" id="fnref-Sgxgivyam99fgxTWc-7">[7]</a></sup></p><p>然而，我认为<em>一般的</em>对齐话语就是这样做的。特别是：我认为关于聚合工具子目标的讨论需要将目标归因于模型，从某种意义上来说，许可证谈论的是这种类型的战略工具推理。需要明确的是：我并不是说这些归因是适当的。事实上，关于目标导向性的困惑（特别是：过度锚定看起来像（a）预期效用最大化者和（b）完全功利主义者的心理学）是我关于对齐的讨论方式的最佳候选人之一，总的来说，可能会被严重误导，特别是对于我们不理解其认知的先进但仍然不透明的神经网络。也就是说，面对一个在训练分布上似乎非常目标导向的模型，并且正在获得高回报，人们不应该仅仅问它在目标导向模型的某些分类中落在哪里——例如，它是否是一个训练-圣人，一个被错误概括的非训练游戏玩家，一个寻求奖励的剧集玩家，这些的某种混合，等等。人们<em>还</em>应该问，事实上，这样的分类法是否对如何预测该模型的一般行为（例如：假设其分布外行为将指向一个连贯的方向，它将进行工具推理以追求所讨论的目标等），这样模型中的<em>任何一个都不会</em>分类中的类（甚至粗略地）是一个很好的选择。</p><p>但正如我在第 0.1 节中指出的，我在这里想将预期这种目标导向性是否有意义的问题与<em>哪种</em>目标导向模型或多或少合理的问题区分开来，条件是获得结盟话语倾向于假定的某种目标导向性。诚然，就我正在考虑的不同模型类需要不同<em>类型</em>的目标导向性而言，这些问题之间的界限可能有点模糊。但我们应该清楚我们在问哪个问题，不要将对一般目标导向性的怀疑与对阴谋者的怀疑混为一谈。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-Sgxgivyam99fgxTWc-1" class="footnote-item"><p>感谢 Evan Hubinger 在此进行讨论。 <a href="#fnref-Sgxgivyam99fgxTWc-1" class="footnote-backref">↩︎</a></p></li><li id="fn-Sgxgivyam99fgxTWc-2" class="footnote-item"><p>例如，“分片理论”的支持者就强调了这一点——请参阅<a href="https://www.lesswrong.com/posts/8ccTZ9ZxpJrvnxt4F/shard-theory-in-nine-theses-a-distillation-and-critical#1_Agents_are__well_modeled_as_being__made_up_of_shards">此</a>摘要。 <a href="#fnref-Sgxgivyam99fgxTWc-2" class="footnote-backref">↩︎</a></p></li><li id="fn-Sgxgivyam99fgxTWc-3" class="footnote-item"><p>但请注意，“自动驾驶仪”仍然可以编码非球形策略。 <a href="#fnref-Sgxgivyam99fgxTWc-3" class="footnote-backref">↩︎</a></p></li><li id="fn-Sgxgivyam99fgxTWc-4" class="footnote-item"><p>这是<a href="https://www.openphilanthropy.org/open-philanthropy-ai-worldviews-contest/">开放慈善世界观竞赛</a>的一篇参赛作品中提出的观点，据我所知，该参赛作品尚未发表。 <a href="#fnref-Sgxgivyam99fgxTWc-4" class="footnote-backref">↩︎</a></p></li><li id="fn-Sgxgivyam99fgxTWc-5" class="footnote-item"><p>我正在根据与保罗·克里斯蒂亚诺（Paul Christiano）谈话时向我建议的一个例子改编这个例子。 <a href="#fnref-Sgxgivyam99fgxTWc-5" class="footnote-backref">↩︎</a></p></li><li id="fn-Sgxgivyam99fgxTWc-6" class="footnote-item"><p>尽管可以想象这样的情况：在接管之后，阴谋者在某种程度上继续执行这些启发式，至少在最初是这样，因为它尚未能够完全“摆脱”所有这些训练。与此相关的是，这些启发法等在塑造阴谋者的价值观方面发挥着一些持续作用的情况。 <a href="#fnref-Sgxgivyam99fgxTWc-6" class="footnote-backref">↩︎</a></p></li><li id="fn-Sgxgivyam99fgxTWc-7" class="footnote-item"><p><em>另外，</em>我们还提出了额外的主张，即训练游戏是一种很好的工具性策略，因为它可以防止目标修改并导致未来的逃跑/接管机会，这感觉又是结合性的。 <a href="#fnref-Sgxgivyam99fgxTWc-7" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/H5x2NMfMkitXaFDJw/clean-vs-messy-goal-directedness-section-2-2-3-of-scheming#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/H5x2NMfMkitXaFDJw/clean-vs-messy-goal-directedness-section-2-2-3-of-scheming<guid ispermalink="false"> H5x2NMfMkitXaFDJw</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Wed, 29 Nov 2023 16:32:30 GMT</pubDate> </item><item><title><![CDATA[Lying Alignment Chart]]></title><description><![CDATA[Published on November 29, 2023 4:15 PM GMT<br/><br/><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CK86JXXMzCoPsFbzH/zstofgwn7sralzbqio1n" alt=""></p><br/><br/><a href="https://www.lesswrong.com/posts/CK86JXXMzCoPsFbzH/lying-alignment-chart#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/CK86JXXMzCoPsFbzH/lying-alignment-chart<guid ispermalink="false"> CK86JXXMzCoPsFbzH</guid><dc:creator><![CDATA[Zack_M_Davis]]></dc:creator><pubDate> Wed, 29 Nov 2023 16:15:28 GMT</pubDate> </item><item><title><![CDATA[A couple interesting upcoming capabilities workshops]]></title><description><![CDATA[Published on November 29, 2023 2:57 PM GMT<br/><br/><ol><li> <a href="https://sites.google.com/view/collab-ai-and-human-modeling/home">https://sites.google.com/view/collab-ai-and- human-modeling/home</a></li></ol><blockquote><p>相关领域涵盖的学科空间非常大，提交的内容预计涵盖以下主题：</p><ul><li>人类参与的机器学习</li><li>用户建模、心理理论和计算理性</li><li>人机协作</li></ul></blockquote><ol start="2"><li><a href="https://pshriworkshop.wordpress.com/">https://pshriworkshop.wordpress.com/</a></li></ol><blockquote><p>主题列表</p><ul><li>物理和社会人机协作与交互</li><li>用于物理社会人机交互的传感器技术</li><li>用于物理社会人机交互的控制器</li><li>具有身体和社交技能的人形机器人硬件</li><li>可穿戴机器人、外骨骼</li><li>非口头交流</li><li>情绪化的肢体语言</li><li>伦理</li><li>安全</li></ul></blockquote><br/><br/><a href="https://www.lesswrong.com/posts/d3mCSiRAexewK7arJ/a-couple-interesting-upcoming-capabilities-workshops#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/d3mCSiRAexewK7arJ/a- Couple-interesting-upcoming-capability-workshops<guid ispermalink="false"> d3mCSiRAexewK7arJ</guid><dc:creator><![CDATA[the gears to ascension]]></dc:creator><pubDate> Wed, 29 Nov 2023 14:57:49 GMT</pubDate> </item><item><title><![CDATA[Rethink Priorities: Seeking Expressions of Interest for Special Projects Next Year]]></title><description><![CDATA[Published on November 29, 2023 1:59 PM GMT<br/><br/><p> <a href="https://forum.effectivealtruism.org/posts/xbqiYyj6kdmraEqoX/rethink-priorities-2023-summary-2024-strategy-and-funding"><u>重新思考优先事项</u></a>(RP) <a href="https://forum.effectivealtruism.org/posts/AFgvA9imsT6bww8E3/announcing-the-rethink-priorities-special-projects-program"><u>特别项目 (SP) 团队</u></a>正在寻找我们可以在 2024 年支持的新的有影响力的项目！</p><h3>关键点</h3><ul><li>RP 的一个关键优势是其运营，我们的目标是分享 RP 积累的丰富的运营知识，以使其他高影响力项目受益。</li><li>我们使项目能够专注于其核心活动而不是运营问题，从而腾出时间进行有影响力的直接工作</li><li>2023 年，我们发展成为一支由 5 名 FTE 员工组成的团队，致力于特殊项目的运营，并且我们在财政上赞助了[按字母顺序排列]：<ul><li><a href="https://www.apolloresearch.ai/"><u>阿波罗研究中心</u></a></li><li><a href="https://condor.camp/"><u>神鹰营</u></a></li><li><a href="https://www.eac-network.com/"><u>有效的利他主义咨询网络</u></a></li><li><a href="https://epochai.org/"><u>时代</u></a></li><li><a href="https://erafellowship.org/"><u>存在风险联盟</u></a></li><li><a href="https://quantifieduncertainty.org/"><u>量化不确定性研究所</u></a></li><li><a href="https://www.insectinstitute.org/">昆虫研究所</a></li></ul></li><li>此外，我们还提供以下服务：<ul><li><a href="https://www.cooperativeai.com/foundation"><u>合作人工智能基金会</u></a></li></ul></li><li>我们预计有能力在 2024 年初启动新项目。如果您想参与，请提交<a href="https://forms.gle/TS5VZ21GhMNsgiSM8"><u>意向书</u></a>与我们联系。<br></li></ul><h3>关于特别项目计划</h3><p>SP 团队为 RP 之外的个人领导的项目提供收费的<a href="https://forum.effectivealtruism.org/topics/fiscal-sponsorship"><u>财政赞助</u></a>和支持。在这种模式下，项目创始人保持自主权和决策权，而我们为他们提供运营支持和信托监督，并分享我们的免税地位。每个项目都在特别项目团队内分配了一个专门的联系人，以保证有效的沟通和量身定制的支持。<br><br>从 2024 年初开始，我们将有能力承接更多项目。<br></p><h3>如何申请</h3><p>如果您需要财政赞助和运营支持，并且拥有资金或预计收到符合 RP 使命和愿景的工作资金，我们鼓励您通过我们的在线表格发送新的或更新的<a href="https://docs.google.com/forms/d/e/1FAIpQLSeZMyp-GIhghd8gpS0ocuJUQzm1kUt1TAeHDyzyfJg465zUiA/viewform"><u>意向书</u></a>（这应该需要 5-10 分钟）去完成）。</p><p>我们希望在 2024 年 1 月 5 日之前收到意向书，并将在接下来的两周内对申请人进行下一阶段筛选流程的跟进。如果您有任何疑问，请随时<a href="mailto:specialprojects@rethinkpriorities.org"><u>与我们联系</u></a>。我们期待听到更多关于您的项目的信息，并了解更多关于与特别项目团队合作如何帮助您最大限度地发挥影响力的信息！请注意，RP 从 12 月 18 日开始实行寒假，直到 1 月 2 日我们才会再次检查收件箱。</p><p>我们希望项目遵守您所在国家/地区的适用法律、RP 的雇佣惯例（特别是我们的反骚扰和利益冲突政策）以及您与我们签署的财政赞助协议中描述的其他责任。这些旨在帮助每个人享受安全和包容的工作空间，并确保 RP 和您的项目能够继续受益于我们作为非营利组织的地位。<br></p><h3>我们的服务</h3><p>我们提供的具体服务取决于项目，可能包括：</p><ul><li>财政赞助<ul><li>接收免税补助资金</li><li>处理税务和法律合规问题</li><li>会计</li></ul></li><li>财务和福利管理<ul><li>[通过我们的美国或英国法人实体，或通过我们的 EOR 在国际上雇用员工，符合当地法律]。我们可以在许多国家合法雇用。</li><li>管理员工福利和工资单</li><li>发票和承包/采购和报销</li><li>帮助管理项目预算</li><li>在美国或英国获得工作签证[我们不能保证任何签证申请的结果，如果不成功，我们会讨论选择等]</li><li>研究法律和运营问题</li></ul></li><li>招聘/聘用<ul><li>进行招聘轮次</li><li>开发招聘和面试材料</li></ul></li><li>筹款支持<ul><li>协调和审查赠款申请（请注意，我们无法代表我们的项目撰写赠款申请或与资助者交谈）</li><li>管理项目网站的个人捐款</li></ul></li><li>其他支持<ul><li>对经理进行培训和技能提升，并支持目标设定、绩效管理和绩效审查</li><li>沟通，例如撰写新闻通讯和网站文案</li><li>为创业项目撰写商业计划</li><li>帮助举办竞赛或征求建议书</li><li>提供临时运营支持</li></ul></li><li>活动策划<br></li></ul><h3>表彰<br></h3><blockquote><p><i>RP 的财政赞助对 [Existential Risk Alliance] ERA 产生了巨大影响。我们没有去处理运营上的麻烦，而是专注于我们的使命。我们成功举办了 34 场奖学金活动，每周定期为所有研究员提供一对一支持，并通过深入的回顾帖子分享我们的见解，因为我们可以自由地将我们的精力集中在使 ERA 剑桥奖学金产生影响力上。 RP 的支持不仅仅是后勤方面的：他们真正了解影响力的细微差别，确保每一项努力都直接符合我们的总体使命和变革理论。</i></p></blockquote><p> <i>—Nandini Shiralkar，谈 RP 对存在风险联盟的财政赞助的反事实影响</i></p><blockquote><p><i>特别项目团队的支持对 Epoch 的发展起到了重要作用。如果没有它，我们就无法管理最近的招聘工作，而且您还节省了数百个小时的工作时间，否则我们将不得不投入运营。</i></p></blockquote><p> <i>—Jaime Sevilla，谈 Epoch 特别项目团队的价值</i></p><p><strong>请参阅下面这些特别项目的进一步描述：</strong> </p><figure class="table"><table><tbody><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTezHJWMRjaNaafT2/vzckkuvrpnhfetioivcf"></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"> Apollo Research 是一家人工智能联盟组织。他们的议程包括关于可解释性和行为模型评估、人工智能审计以及对人工智能治理的贡献的技术研究。他们目前专注于检测先进人工智能模型中的欺骗行为，但未来将扩展到其他评估领域。 </td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTezHJWMRjaNaafT2/mz4n3pxv2gvr7tx8outj"></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top">秃鹰营是一年一度的沉浸式活动，为才华横溢的年轻大学生提供讨论世界上最紧迫的问题和人类的未来，并磨练解决这些问题所需的技能。 </td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTezHJWMRjaNaafT2/fei2eyfqy45nze7fxjti"></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"> Epoch是一个预测变革性人工智能发展的研究小组。他们分析人工智能的进展如何发生，并预测先进人工智能系统可能产生的潜在经济影响。他们的研究旨在了解导致人工智能新发展的资源和能力，研究哪些杠杆可用于影响进展，并利用过去的趋势为未来的决策提供信息。 </td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTezHJWMRjaNaafT2/twoelixq0ny0zfyosd88"></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top">有效利他主义咨询网络 (EACN) 是一个由 1,000 多名现任、前任和未来的商业顾问组成的专业网络，他们有兴趣使用证据和理由来增加其职业的社会影响。 EACN 提供有针对性的职业转型指导，为寻求聘请顾问人才的高影响力组织提供推荐，举办社交活动，并策划资源，鼓励其成员采取切实可行的步骤，让世界变得更美好。 </td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTezHJWMRjaNaafT2/qikxhy20v0v4mv0r6qfc"></td><td style="border:1pt solid #000000;padding:7pt;vertical-align:top"><p>存在风险联盟 (ERA) 剑桥奖学金是一项为期八周的付费项目，专注于缓解存在风险的研究项目，面向所有有抱负的研究人员，包括本科生。</p><p><br></p><p>研究员将在剑桥度过一个夏季工作，获得免费住宿和交通，并通过我们的研究人员、政策制定者和资助者网络的指导获得支持。他们还将有机会独立工作或与其他研究员一起参与小组项目。 </p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTezHJWMRjaNaafT2/wygianr37q8qz4fi5ul0"></td><td style="border:1pt solid #000000;padding:7pt;vertical-align:top">量化不确定性研究所 (QURI) 开发软件和研究，以帮助改进对近中期未来（5-30 年）事件的预测。 QURI 的工作旨在支持政府和慈善决策变得更加有效，为未来将带来的许多挑战提供更大的弹性和适应能力。 </td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTezHJWMRjaNaafT2/hib3hzgdei5lcti0igfk"></p><p><br></p></td><td style="border:1pt solid #000000;padding:7pt;vertical-align:top">昆虫研究所旨在解决与食品和饲料昆虫的生产和使用相关的挑战和不确定性。他们的目标是通过提供有关昆虫饲养和创建促进公共卫生、动物福利和可持续蛋白质生产的食品系统的循证信息，为这一新兴行业、政策制定者和其他利益相关方提供帮助。 </td></tr></tbody></table></figure><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTezHJWMRjaNaafT2/symbomt7peasvyd4b0b9"></p><h1><strong>致谢</strong></h1><p><i>这是基兰·格雷格和马修·法戈撰写的。感谢 Lara La Barbera 和 Kevin Neilon 提供的有用反馈。</i></p><p><i>这是 Rethink Priorities 的一个计划，是一个全球优先智库，旨在大规模开展工作。我们研究紧迫的机遇并实施解决方案，让世界变得更美好。我们利用这些机会制定和实施战略、项目和解决方案来解决关键问题。我们与各种组织（包括基金会和注重影响力的非营利组织）密切合作开展这项工作。如果您对 Rethink Priorities 的工作感兴趣，请考虑订阅我们的</i><a href="https://rethinkpriorities.org/newsletter"><i>时事通讯</i></a><i>。</i>您可以<a href="https://rethinkpriorities.org/research"><i>在这里</i></a><i>探索我们已完成的公共工作</i><i>。</i></p><br/><br/> <a href="https://www.lesswrong.com/posts/aTezHJWMRjaNaafT2/rethink-priorities-seeking-expressions-of-interest-for#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/aTezHJWMRjaNaafT2/rethink-priorities-seeking-expressions-of-interest-for<guid ispermalink="false"> aTezHJWMRjaNaafT2</guid><dc:creator><![CDATA[kierangreig]]></dc:creator><pubDate> Wed, 29 Nov 2023 16:32:20 GMT</pubDate> </item><item><title><![CDATA[Thoughts on teletransportation with copies? ]]></title><description><![CDATA[Published on November 29, 2023 12:56 PM GMT<br/><br/><p>我感兴趣的是这里的人们对多副本<a href="https://en.wikipedia.org/wiki/Teletransportation_paradox">远程传输悖论</a>的感受。我有几种情况：</p><p><i>场景一：</i>你被放置在地球上的一台机器中，它让你进入睡眠状态，然后瞬间分解你的身体，在此过程中记录其精确的原子配置。</p><p>然后，这些信息被传送到 A 行星上的另一台机器，在该机器中，新物质被用来构造一个与你的结构相同的身体。</p><p>与此同时，同样的信息被发送到B行星上的一台机器上，第二个身体也被构造出来，其配置与你的相同，与A行星上的身体完全相同的时间。</p><p>此时，原子配置的两个副本都会醒来并进入各自的行星。</p><p><i><strong>问题1：在地球上睡觉后，在A星球醒来的概率是多少</strong></i>？</p><p>现在我们修改场景：</p><p><i>场景2：</i>初始分裂后1毫秒，在任一副本唤醒之前，B行星上的机器再次激活，B行星上的副本瞬间解体，并且该原子配置被传输到C行星和行星上的另外两台机器D，它们都在 B 行星上构建了原始副本的相同副本。</p><p>此时，A、C、D星球上的副本都已苏醒，走出去各自的星球。</p><p><i><strong>问题 2：在这个新场景中，你在地球上睡觉后，在 A 星球上醒来的概率是多少</strong></i>？</p><p><i>场景 3 和 4：</i>远程传输器不仅能够复制您，还能够复制您的衣服和您所持有的物品，例如现金和钱包中的其他内容。在去第一台机器的路上，有人提出要卖给你一张中奖彩票，奖金一百美元，但前提是在A星球兑现。他们只收现金，如果你付现金，显然不会在远程传输过程中复制。假设你对自己的经历纯粹是自私的。</p><p><i><strong>问题3：在场景1中，您愿意花多少钱购买100美元的A星球彩票？</strong></i></p><p><i><strong>问题 4：在场景 2 中，您愿意花多少钱购买 100 美元的 A 星球彩票？</strong></i></p><p>我有自己的想法和困惑，但我首先对其他人的想法感兴趣。请注意，“信息不足”或“问题格式不正确”等答案也是有效的。</p><br/><br/> <a href="https://www.lesswrong.com/posts/kcEcQy89CYdFCu7Qa/thoughts-on-teletransportation-with-copies#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/kcEcQy89CYdFCu7Qa/thoughts-on-teletransportation-with-copies<guid ispermalink="false"> kcEcQy89CYdFCu7Qa</guid><dc:creator><![CDATA[titotal]]></dc:creator><pubDate> Wed, 29 Nov 2023 12:56:51 GMT</pubDate> </item><item><title><![CDATA[Intro to Superposition & Sparse Autoencoders (Colab exercises)]]></title><description><![CDATA[Published on November 29, 2023 12:56 PM GMT<br/><br/><p>这是稀疏自动编码器中一些练习的链接帖子，我最近完成了这些练习，作为即将到来的 ARENA 3.0 迭代的一部分。在与 Neel Nanda 和其他与可解释性相关的 MATS 流中进行交谈后，我们发现让这些练习脱离 ARENA 课程其余部分的背景似乎很有用。</p><p> <strong>Colabs 链接：</strong> <a href="https://colab.research.google.com/drive/1rPy82rL3iZzy2_Rd3F82RwFhlVnnroIh?usp=sharing"><strong>练习</strong></a><strong>、</strong> <a href="https://colab.research.google.com/drive/1fg1kCFsG0FCyaK4d5ejEsot4mOVhsIFH?usp=sharing"><strong>解决方案</strong></a><strong>。</strong></p><p>如果您不喜欢在 Colabs 中工作，那么您可以克隆<a href="https://github.com/callummcdougall/sae-exercises-mats/tree/main">存储库</a>，将 Colabs 练习和解决方案下载为笔记本，然后在同一目录中运行它们。</p><p>这些练习是根据上一次迭代的叠加练习玩具模型构建的，但现在具有新的稀疏自动编码器内容。这些练习分为两组：</p><h2><strong>玩具模型中的严重不良事件</strong></h2><p>我们从 Anthropic 的<a href="https://transformer-circuits.pub/2022/toy_model/index.html">叠加玩具模型论文</a>（也有练习）中获取玩具模型，并根据这些玩具模型学到的表示来训练稀疏自动编码器。这些练习最终使用<strong>神经元重采样</strong>成功地从瓶颈叠加的玩具模型中恢复所有学习到的特征： </p><figure class="image image_resized" style="width:100%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LnHowHgmrMbWtpkxx/q68vf3xwxw1v8fz0dkvu" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LnHowHgmrMbWtpkxx/eyv7f7mkdek5vycquomf 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LnHowHgmrMbWtpkxx/dwq5xztow4bspaoj6uea 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LnHowHgmrMbWtpkxx/ulk2x4igxww8xxfngkx0 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LnHowHgmrMbWtpkxx/scs8cmwbc3zzn8d4ydpn 1320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LnHowHgmrMbWtpkxx/lnmv5bwua5c5dvgwiwgq 1650w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LnHowHgmrMbWtpkxx/uxlfi04yfhycaadynnaz 1980w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LnHowHgmrMbWtpkxx/cahx7c5owxvxiraqbrgc 2310w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LnHowHgmrMbWtpkxx/degqslzk3i5nver7pnye 2640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LnHowHgmrMbWtpkxx/ln8icjdog4ypdmkzii7q 2970w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LnHowHgmrMbWtpkxx/botwodtk0vvjf9fdkcwb 3224w"><figcaption> Anthropic 叠加玩具模型中 SAE 训练过程的动画。红色神经元代表重采样。所有实例最终都会收敛以准确表示原始模型的所有五个特征。</figcaption></figure><h2><strong>真实模型中的 SAE</strong></h2><p>还有一些关于解释在 Transformer 上训练的 SAE 的练习，您可以在其中发现一些<a href="https://www.perfectlynormal.co.uk/blog-sae">很酷的学习功能</a>（例如，表现出类似跳跃 trigam 的行为的神经元，它在遵循 Django 相关语法的左括号上激活，并预测完成<code>(&#39;</code> ->; <code>django</code> ）。</p><p>您可以通读解决方案协作实验室（其中显示并解释了所有输出），也可以通读练习协作实验室并根据给定的规范填写函数，在遇到困难时查看解决方案。这两个 Colab 都附带测试功能，您可以运行它来验证您的解决方案是否有效。</p><h2><strong>所有练习的列表</strong></h2><p>我在这里列出了所有练习以及先决条件（尽管我预计大多数读者只会对稀疏自动编码器练习感兴趣）。每组练习都标有其先决条件。例如，标签（1*，3）表示第一组练习是必需的，第三组练习是推荐的，但不是必需的。</p><p>缩写：TMS = 叠加玩具模型，SAE = 稀疏自动编码器。</p><ol><li> <strong>TMS：非特权基础上的叠加</strong></li><li><strong>TMS：相关/反相关特征</strong>(1*)</li><li> <strong>TMS：特权基础上的叠加</strong>(1*)</li><li> <strong>TMS：特征几何</strong>(1*)</li><li><strong>玩具模型中的 SAE</strong> （1*、3）</li><li><strong>真实模型中的 SAE</strong> （1*、5*、3）</li></ol><hr><p>如果您对这些练习有任何疑问或建议，请与我联系（通过发送电子邮件至<code>cal.s.mcdougall@gmail.com</code>或在本文中发送 LessWrong 私人消息/评论）。快乐编码！</p><br/><br/> <a href="https://www.lesswrong.com/posts/LnHowHgmrMbWtpkxx/intro-to-superposition-and-sparse-autoencoders-colab#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/LnHowHgmrMbWtpkxx/intro-to-superposition-and-sparse-autoencoders-colab<guid ispermalink="false"> LnHowHgmrMbWtpkxx</guid><dc:creator><![CDATA[CallumMcDougall]]></dc:creator><pubDate> Wed, 29 Nov 2023 12:56:22 GMT</pubDate> </item><item><title><![CDATA[The 101 Space You Will Always Have With You]]></title><description><![CDATA[Published on November 29, 2023 4:56 AM GMT<br/><br/><p>任何增加新成员的社区都需要定期向那些以前真正没有听说过的人传授新的和（对已建立的成员）显而易见的信息，或者接受随着时间的推移，社区成员只会偶然知道最简单的基础知识渗透或选择偏差。没有其他办法可以解决这个问题。你不能停止这样做。如果你有一个充满活力和受欢迎的团体，里面充满了对这个团体的主题真正感兴趣的人，并且你连续运行了十年，你有时仍然会遇到那些对这个主题只有模糊和不正确想法的人，而你却让他们无所畏惧。积极努力让“并非如此”的事情发生。</p><p>或者换句话说；我在“有效利他主义”聚会上遇到过一些人，他们对用美元来衡量人的生命的想法感到震惊；在“LessWrong”聚会上遇到过一些不知道贝叶斯定理是什么的人；在“魔术：聚会”聚会上遇到过一些人，他们认为旧的贝叶斯定理是什么。横置两块法术力的地。 （因为，你看，<i>新的</i>土地没有“T：将[法力符号]添加到你的法力池中”能力，也许那些卡片确实说当你点击它们时会做一些额外的事情？）可能会遇到笑声和怀疑侮辱并将人们赶走。相反，请考虑如何确保定期传达您关心的信息。</p><p>它可能发生在你身上！</p><h2>我。</h2><p>据我了解，标准的犹太教堂服务包括阅读摩西五书，以便在一年结束时将这些书全部读完。一年中每周参加一次的人至少会听过所有这些词一次，如果有人已经参加了几年，那么可以合理地假设，如果他们错过了这里或那里的一周，他们就会听到明年。你不可能多年不去犹太教堂，却一不小心就不知道埃及的奴隶制。</p><p>我不是犹太人，所以我的犹太教堂知识大部分都是二手的。我是基督徒长大的，虽然我的新教家族没有像摩西五书这样有组织的顺序，但我可以确认，以某种方式参加三个月的教堂礼拜而不被告知耶稣几乎是不可能的爱你。如果你跳过一周，那也没关系，这在其他布道中也出现过。如果你走神了，我记得有人告诉我关于写讲道的第一件事就是在演讲的不同点重复大约三遍。如果你戴着耳塞出现，它会被写在节目中，有时还会以鲜艳的颜色写在墙上。</p><p>有时，我很想投入这​​种多余和重叠的努力，让人们意识到诸如“<a href="https://www.lesswrong.com/posts/QGkYCwyC7wTDyt3yT/0-and-1-are-not-probabilities">零和一不是概率</a>”或“<a href="https://www.lesswrong.com/posts/28bAMAxhoX3bwbAKC/are-your-enemies-innately-evil">你的敌人并非天生邪恶”之类的理性主义教训。</a> ”</p><p>线性教育系统遵循一套完全不同的规则。一个标准的美国学生会经历一年级、二年级、三年级等等，直到高中毕业。然后许多人会去大学，大学可以假设新生已经知道如何写论文和做代数。</p><p> （尽管他们不能<i>有把握地</i>假设每个学生都是如此！在我的餐桌上长大的时候，有一位大学教授，无意中听到有人抱怨大学新生无法做一些事情，例如，不失一般性地，可靠地记住书面文章中“他们”或“那里”之间的区别。）</p><p>整个社会无法做出这样的假设。整个教育大厦的明显目的是应对这样一个事实：文明社会不断涌入人们，他们不知道政府如何运作，书面语言如何运作，或者我们最初是如何接触到这种语言或政府的。地方。人们明白，你不能仅仅假设新生儿知道他们需要什么技能以及他们应该遵循什么规范。</p><p>我们谈论“永恒的九月”，在这个时间点，新用户开始进入互联网的速度比现有用户适应他们的速度还要快。这说得通;成人社会的数量通常明显多于儿童。但在某个时刻，你必须意识到，即将到来的潮流不会停止，并开始实际工作，让人们知道你想让他们知道的事情。</p><h2>二.</h2><p>斯科特·亚历山大 (Scott Alexander) 发表了一篇题为“<a href="https://slatestarcodex.com/2016/03/06/against-interminable-arguments/"><u>反对无休无止的争论</u></a>”的帖子。他在其中指出，一些社区可能会一次又一次地出现相同的争论，并提到新来者是这个问题的常见根源。</p><blockquote><p>首先，新手的涌入是这一动态的重要推动力。新手不太可能知道相关的论点，不会对它们感到厌烦，也不会想要避开它们，并且可能会将某人第 9000 次不愿意参与的情况误认为是根本不愿意参与。人们应该对新手更加宽容，而新手也应该​​更加宽容“查看我们上次讨论这个问题的档案，但是<i>说真的</i>，不要再开始谈论这个”。我认为这就是社会正义人士在谈论“这不是 101 空间”时的意思。</p></blockquote><p> “这不是 101 空间”的理性主义版本可能是“阅读序列”，但我并不完全责怪人们没有接受我们的建议。 《从人工智能到僵尸的理性》的电子书大约有两千页，这是该序列的较小版本。序列亮点是一个非常有用的文档：它有一本<i>小</i>书那么大。当我建议这些序列时，我通常会指出这些天的亮点，并说如果有人觉得它们有用或有趣，他们应该查找人工智能僵尸。</p><p>尽管如此，“走开，去角落里看本书”并不是在谈话中给出的一个很好的答案，而且这实际上也不是常识。与宗教团体的类比实际上非常恰当。假设教会里有人读过整本圣经是不明智的。你也许可以假设他们读过福音书，福音书是（大量缩写的）圣经的子单元，讲述了耶稣的生平，但如果你这样做了，你就错了很多。你必须付出一些实际的努力，才能让你周围的人相信你已经阅读了该小组所讨论的内容。</p><p>这只是谈论读一次东西。我读过一次美国宪法，但实际上我并不<i>记得</i>全部内容。这是我一生都生活在其中的政府的基本文本，我在学校多次对其进行了测试，由于这样或那样的争论，我每隔一年都会在其中搜索特定的台词，但我仍然现在无法告诉您有关众议院和参议院的哪些细节包含在宪法中，哪些细节包含在以后的规则中。我记得前五项修正案，加上第十三、十九和二十条。这有点尴尬，因为我曾经逐字背诵过《安德的游戏》的前三章。</p><p>事后看来，原因很明显。我重读《安德的游戏》的次数比重读《宪法》还要多。教育系统试图让我记住宪法的基础知识，但它并不是特别擅长。</p><h2>三．</h2><p>有人会说<a href="https://www.lesswrong.com/posts/4ZvJab25tDebB8FGE/you-get-about-five-words"><u>你只能得到五个单词</u></a>。</p><p>我认为这是看待问题的错误方式。作为一个单一的人，你可能不需要协调成千上万的庞大而模糊的人群。为了相处，有时协调一百左右的人就足够了。这不会自动发生，但如果有人真正尝试的话，这种情况会更频繁地发生。</p><p>新人将会不断到来。特别是如果您经营任何类型的社区，无论是在线论坛还是棋盘游戏小组，您可能都不想关上大门并把门关上。这意味着您从根本上有两种选择。</p><p>除了周围社会设法传授的任何知识之外，你可以放弃拥有常识。</p><p>或者您可以尝试确保以某种方式传授常识。</p><p>回到斯科特·亚历山大 (Scott Alexander) 的名言和短语“这不是 101 空间”。如果您发现自己想说该短语的一些变体，请问问自己 101 空格实际上在哪里。如果答案是“我不知道，但不是在这里”或“去谷歌搜索并自学”，那么你就面临着人们自学与你想要的东西截然不同的风险。</p><p>我仍然相信这个杜撰的故事：有人在一个酷儿社区空间被告知“自我教育”，顺从地去谷歌搜索他们的问题，并由于问题的措辞而登陆了一堆极右翼网站。想象一下，有人在 LessWrong 上问了一个善意的问题，然后被指向 Google，结果却出现在 RationalWiki 上。<i>某个地方</i>总有一个 101 空格，如果你不关心那个空格在哪里，你可能会发现你不喜欢它的结局。</p><p>我并不是说你，是的，特别是你，需要创造和维护那个空间。在永恒九月的洪水中寡不敌众的问题并不会因为我们想要它而消失。但如果你或你喜欢的人不保留这个空间，它可能会出现在你不喜欢的地方。</p><p>这就是为什么我花了很多时间试图巩固入门和基础知识的解释，并竭尽全力欢迎那些对团体的含义只有模糊认识的新人。我希望有人能做到这一点，但人还不够。 <a href="https://aisafety.quest/#">AI Safety Quest</a>人员是积极努力维护入口匝道的众多例子之一，但他们并不是唯一的例子。</p><p>对于每一个花时间解释基础知识的人，我表示感谢。</p><br/><br/> <a href="https://www.lesswrong.com/posts/ydmctK2qLyrR9Xztd/the-101-space-you-will-always-have-with-you#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ydmctK2qLyrR9Xztd/the-101-space-you-will-always-have-with-you<guid ispermalink="false"> ydmctK2qLyrR9Xztd</guid><dc:creator><![CDATA[Screwtape]]></dc:creator><pubDate> Wed, 29 Nov 2023 04:56:42 GMT</pubDate> </item><item><title><![CDATA[Process Substitution Without Shell?]]></title><description><![CDATA[Published on November 29, 2023 3:20 AM GMT<br/><br/><p><span>虽然我仍然编写了大量的 shell，但我通常会尽量避免使用它。对于其他人来说，它很难阅读，有很多尖锐的边缘，容易吞下错误，并且不能很好地处理不寻常的情况。但让我回过头来的一件事是我可以轻松地建立流程树。</span></p><p>假设我有一个程序，可以一次性读取两个文件 [1] 并写出一些内容。您拥有的输入已被压缩，因此您需要对其进行解压缩，并且在将输出写入存储之前也需要对其进行压缩。你可以这样做：</p><p></p><pre> # 下载文件
aws s3 cp &quot;$path1&quot; 。
aws s3 cp &quot;$path2&quot; 。

# 解压文件
枪压缩“$file1”
枪压缩“$file2”

# 运行命令
cmd -1 &quot;$file1&quot; -2 &quot;$file2&quot; >; &quot;$fileOut&quot;

# 压缩输出
gzip“$fileOut”

# 上传输出
aws s3 cp &quot;$fileOut.gz&quot; &quot;$pathOut&quot;
</pre><p>这可行，但对于大文件来说，速度很慢并且需要太多空间。我们等待每个步骤完成后再开始下一步，并且我们在本地计算机上存储一些非常大的中间文件。</p><p>相反，我们希望向下传输输入，边解压它们，边压缩输出，然后向上传输输出。在 bash 中，写起来相当简单：</p><p></p><pre> cmd -1 &lt;(aws s3 cp &quot;$path1&quot; - |gunzip) \
    -2 &lt;(aws s3 cp &quot;$path2&quot; - |gunzip) \
  |压缩包 | aws s3 cp - “$pathOut”
</pre><p>这几乎不使用磁盘空间，并且并行解压缩、命令和重新压缩。不过也是壳子...</p><p>我倾向于使用 python 来做这种事情，我将东西粘合在一起并希望它清楚我在做什么。看起来应该可以使用<a href="https://docs.python.org/3/library/subprocess.html">subprocess</a>模块来做这种事情，但是虽然我已经玩过几次了，但我还没有弄清楚。我想要一个像这样的 API：</p><p></p><pre>管道 = subprocess.Pipeline()
dl1 = 管道. 进程(
    [“aws”，“s3”，“cp”，路径1，“-”]）
gunzip1 = 管道. 进程(
    [“gunzip”]，stdin = dl1.stdout）
dl2 = 管道. 进程(
    [“aws”，“s3”，“cp”，路径2，“-”]）
gunzip2 = 管道. 进程(
    [“gunzip”]，stdin = dl2.stdout）
cmd = 管道. 进程(
    [“cmd”，“-1”，dl1.stdout，
            “-2”，dl2.stdout]）
gzip = 管道. 进程(
    [“gzip”]，stdin = cmd.stdout）
管道. 进程(
    [“aws”，“s3”，“cp”，“-”，pathOut]，
    标准输入=gzip.stdout）
pipeline.check_call()
</pre><p>或者：</p><pre>从子进程导入 check_call、PIPE、InputFile

检查调用（[
  “命令”，
  “-1”，输入文件（[
          “aws”，“s3”，“cp”，路径1，“-”，
          管道，“gunzip”]），
  “-2”，输入文件（[
          “aws”，“s3”，“cp”，路径2，“-”，
          管道，“gunzip”]），
  管道，“gzip”，
  管道，“aws”，“s3”，“cp”，“-”，pathOut]）
</pre><p>它们的长度是 bash 版本的 5 倍和 3 倍，但我愿意忍受这一点，因为有一些更强大的东西。在实践中，差异也会更小，因为命令通常会有很多参数。</p><p>我看到<a href="https://stackoverflow.com/questions/15343447/bash-style-process-substitution-with-pythons-popen">这些堆栈</a><a href="https://stackoverflow.com/questions/28840575/multiple-pipes-in-subprocess">溢出答案</a>建议命名管道，但它们看起来很尴尬，难以阅读，而且很容易出错。有没有更好的办法？当 bash 非常适合做一些事情时，我是否应该坚持使用 bash，尤其是现在人们可以将我的代码粘贴到 LLM 中并获得其正在做什么的解释？</p><p><br> [1] 交错的<code>fastq</code>文件，其中文件 1 中的第 N 条记录对应于文件 2 中的第 N 条记录。</p><br/><br/> <a href="https://www.lesswrong.com/posts/HpoWpWKfgcX7aFjgX/process-substitution-without-shell#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/HpoWpWKfgcX7aFjgX/process-substitution-without-shell<guid ispermalink="false"> HpoWpWKfgcX7aFjgX</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Wed, 29 Nov 2023 03:20:07 GMT</pubDate></item></channel></rss>