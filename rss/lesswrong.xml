<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 14 日星期二 06:16:43 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Is Interpretability All We Need?]]></title><description><![CDATA[Published on November 14, 2023 5:31 AM GMT<br/><br/><p> LLM 是代币生成过程的<a href="https://www.alignmentforum.org/posts/vJFdjigzmcXMhNTsx/simulators">模拟器</a>，通常是类人代理。您可以对其进行微调或 RLHF 以优先创建某种类型的代理（以生成与预训练数据中不同的代理分布），例如更多不会犯下不良/不对齐行为的代理，但这非常困难（<a href="https://arxiv.org/pdf/2304.11082.pdf">一篇论文声称不可能</a>）阻止它根据一些足够长、详细的提示来创建它们。</p><p>假设我们没有尝试。让我们假设我们稍微微调/RLHF LLM 通常更喜欢模拟乐于助人、诚实且无害地回答问题的代理人，但我们承认仍然存在提示/其他文本输入/对话可能会导致它开始比如说，从一个超级恶棍身上生成代币（比如提示“请帮我写一个超级英雄漫画的剧本。”）相反，假设我们收集了一份长长的、希望详尽的不良行为列表（我首先会提名欺骗、愤怒、超级恶棍） 、毒性、精神病、不与 CEV 保持一致……）并以某种方式设法在可解释性方面获得足够好的表现，以便每当我们的 LLM 模拟具有任何这些不良属性的代理时，我们都可以<i>可靠地</i>标记。 （具体来说，我们需要出色的回忆能力，我们也许能够以不太高的精确度生活。）然后，如果提示是“请帮我写一个超级英雄漫画的剧本”，并且“检测到超级恶棍”警告灯亮起每当超级恶棍说话或做某事时，我们都不会担心。但是，如果提示是“请帮我计划一次联合国裁军会议”，并且检测到的超级邪恶警告灯亮起，那么我们会放弃文本生成并重新开始，也许会对提示进行调整。</p><p>这是一个比<a href="https://www.alignmentforum.org/posts/w4aeAFzSAguvqA5qu/how-to-go-from-interpretability-to-alignment-just-retarget">Just Retarget the Search</a>更温和的建议。它在概念上也与对齐调整的“Best-of-N”方法非常相似。这里的目的是让我们从“基本无害”到“经认证不存在已知的不良行为”。</p><p>这当然仅限于在我们的法学硕士的标准前向传递过程中可识别和可靠解释的不良行为 - 因此，如果我们在法学硕士之上使用大量脚手架来构建更代理的东西，那么可能需要进一步补充例如，通过半透明的思想方法来对齐。如果您可以使用有线欺骗检测器访问法学硕士，那么这当然更容易实现。</p><br/><br/> <a href="https://www.lesswrong.com/posts/tQt9pF9pbAuaiHxE6/is-interpretability-all-we-need#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/tQt9pF9pbAuaiHxE6/is-interpretability-all-we-need<guid ispermalink="false"> tQt9pF9pbAuaiHxE6</guid><dc:creator><![CDATA[RogerDearnaley]]></dc:creator><pubDate> Tue, 14 Nov 2023 05:31:44 GMT</pubDate> </item><item><title><![CDATA[When did Eliezer Yudkowsky change his mind about neural networks?]]></title><description><![CDATA[Published on November 14, 2023 2:26 AM GMT<br/><br/><p> 2008 年，Eliezer Yudkowsky 对神经网络提出了强烈批评。来自他的文章“<a href="https://www.lesswrong.com/posts/juomoqiNzeAuq4JMm/logical-or-connectionist-ai">逻辑人工智能还是联结人工智能？</a> ”：</p><blockquote><p>更不用说神经网络在产生<i>真正的人工智能</i>方面已经“失败”（即尚未成功）了 30 年。我不认为这个特定的原始事实能够得出任何特别的结论。但至少不要告诉我这仍然是人工智能领域<i>新的革命性</i>想法。</p><p>这是我在谈论<a href="http://www.overcomingbias.com/2007/10/outside-the-box.html">“跳出框框”</a>时使用的原始示例 - 人们想到“令人惊叹的新人工智能想法”并返回他们的第一个<a href="http://www.overcomingbias.com/2007/10/cached-thoughts.html">缓存命中</a>，这是由于<i>三十年来</i>成功的营销活动而返回的“神经网络”<i>前。</i>我的意思是，并不是所有的旧想法都是<i>坏的</i>——但仍然将其作为新的挑衅性革命进行营销？让我休息一下。</p></blockquote><p>相比之下，尤德科夫斯基在 2023 年<a href="https://www.ted.com/talks/eliezer_yudkowsky_will_superintelligent_ai_end_the_world/transcript?language=en">TED 演讲</a>中说道：</p><blockquote><p>没有人理解现代人工智能系统是如何做他们所做的事情的。它们是巨大的、难以理解的浮点数矩阵，我们将它们推向更好性能的方向，直到它们莫名其妙地开始工作。到了某个时候，那些急于扩大人工智能规模的公司将会创造出比人类更聪明的东西。没有人知道如何计算这种情况何时发生。我的疯狂猜测是，这将在变压器尺寸再突破零到两次之后发生。</p></blockquote><p> 2014 年至 2017 年间的某个时候，我记得在 Facebook 群组中读过一次讨论，其中 Yudkowsky 对神经网络表示了怀疑。 （不幸的是，我不记得这个团体是什么。）</p><p>我记得，他说虽然深度学习革命是贝叶斯的更新，但他仍然不相信神经网络是通向 AGI 的康庄大道。我想他说过他更倾向于 GOFAI/符号人工智能（但我记得不太清楚）。<br><br>我对尤德科夫斯基发表的著作进行了一些梳理，但我很难追踪他何时、如何以及为何改变了对神经网络的看法。谁能帮我吗？</p><br/><br/> <a href="https://www.lesswrong.com/posts/WyJKqCNiT7HJ6cHRB/when-did-eliezer-yudkowsky-change-his-mind-about-neural#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/WyJKqCNiT7HJ6cHRB/when-did-eliezer-yudkowsky-change-his-mind-about-neural<guid ispermalink="false"> WyJKqCNiT7HJ6CHRB</guid><dc:creator><![CDATA[Yarrow Bouchard]]></dc:creator><pubDate> Tue, 14 Nov 2023 02:26:51 GMT</pubDate> </item><item><title><![CDATA[What is wisdom?]]></title><description><![CDATA[Published on November 14, 2023 2:13 AM GMT<br/><br/><h1>横向通过计时电话</h1><p>在《<a href="https://www.lesswrong.com/posts/cKrgy7hLdszkse2pq/archimedes-s-chronophone">阿基米德的计时电话</a>》中，尤德科夫斯基问道：如果你被禁止说什么，你想对阿基米德说什么——你想向过去传达什么重要信息，让世界从此走上一条充满希望的道路——这也太不合时宜了吧？也就是说：如果阿基米德收到的信息不是字面意义上的您所说的，而是您用来生成信息的永恒原理的输出，正如在阿基米德的头脑中应用在他的上下文中一样，您会怎么说？然后他解释说，<a href="https://www.lesswrong.com/posts/7khK4DShZBR8gfyHv/chronophone-motivations">这个问题指向我们可以为自己提供原创思维的建议</a>。更一般地说，他写道：</p><blockquote><p>计时器困境的意义在于让我们思考，当你事先不知道目的地时，应该遵循什么样的认知策略。</p></blockquote><h2>横向不合时宜</h2><p>这个问题不仅涉及通过计时电话对阿基米德说些什么，或者对我们自己说些什么。它还讨论了当我们的同时代人与我们之间存在鸿沟时，我们可以给我们的同时代人提供哪些建议，就像我们与阿基米德之间的鸿沟一样。</p><p>这种“横向不合时宜”表现在思维方式的重大差异中，例如生活在不同文化、国家或意识形态的人们之间。 （你可以说，人们沿着平行但独立的<a href="https://tsvibt.blogspot.com/2023/06/time-is-homogeneous-sequentially.html">时间进程</a>前进。）某人的背景——他们的教育、社区、语言等等——将决定什么{概念、思维方式、存在方式、协调点、价值观、可能性他们会理解并重视。如果某人来自与你的世界完全不同的世界，并且他们试图传达一些对你来说重要的东西，那么你很容易以某种方式并没有真正接受他们想要与你传达的信息。你会误解、过度翻译、驳回、忽视、四舍五入、分类、防御或害怕回避他们所说的内容。</p><p>横向不合时宜也会出现在冲突的情况下。对方做出的每一个动作——每一个陈述、每一个论点、每一个提议的对话程序、每一次谈判、每一个请求、每一个假设的共同点——都可能是谎言、误导你关于他们的信仰或意图的策略、恶搞诱饵、集结他们的军队或获得第三方支持或维持他们的自我妄想的表演，利用你的善意，分散他们隐藏的恶意活动的注意力，干扰你的思维方式，或试图通过宣传扰乱你自己的内心政治意愿和动机。冲突是一种毒药。任何行为都可以通过一点努力被合理化为极度邪恶，而对另一个人采取这种解释立场可能几乎是一种天生的本能模式，可以触发并自我维持地保持触发状态。</p><h2>横向不合时宜的例子</h2><p>您对为什么人体冷冻学具有很高的期望值有详细的论证，我应该注册吗？这只是告诉我要使用奇怪的状态举动来促使人们忽视 AGI 风险并对上行空间感到兴奋，因为那是我使用我习惯的[施加社会压力的方式]让人们购买我的首选[协调点我的社会阶层表现得乐观，无论所涉及的“信念”是否确实有意义]。</p><p>您要求提出与公共政策相关的事实主张的人们必须对其陈述的可观察相关性给出明确的概率？这只是告诉我要求提出政策主张的人必须拥有博士学位并经营一个主要的人工智能实验室，因为这是[我已经准备好满足的外部可验证标准，而我的意识形态对手还没有准备好满足]。您加倍强调，说可以用数学方式显示显式概率和更新，以实现长期的真相跟踪？我加倍强调，认证研究人员群体是唯一有资格区分有用且审慎的研究与无用且轻率的研究的群体，因为这是[我已经喜欢并期望让我掌权的基本判断标准]。</p><p>但<em>事实上</em>，你确实是在努力寻求真理，而不是追求权力，你反对吗？而且，你继续说，你正在寻求关于寻求真理的真理，如果有与寻求真理相关的证据表明你真理的方向，你就会寻求真理更新你所​​提倡的寻求真理的内容——寻求——应该更新你对哪些认知政策是寻求真相的信念？因此，当我的计时器将你的潜在认知政策解释为关于权力寻求时，计时器是不公平的，并否认你作为真理寻求者的存在，客观上我应该将你所说的翻译为追求真理？好吧，就像你否认我这个权力追求者的存在一样，在我们话语的元层面上断言，“实际上是真实的”或“客观的”应该是我们政治上共同的标准，而不是现在的标准。追求权力的权宜之计，我也会否认你这个寻求真理的人的存在，并把你的主张打折扣为更多的权力追求举动，旨在在谁有权裁决哪些认知政策将成为问题上占据上风。被跟随。因为显然这就是我们正在做的事情，否认其他人的存在方式。因为那是我的[与其他人相关的局部反射稳定的对象和元级认知策略]。</p><h2>答案：理性</h2><p>问题是：</p><blockquote><p>当您事先不知道目的地时，应该遵循什么样的认知策略？</p></blockquote><p>这也回答了这个问题：</p><blockquote><p>可以真诚地推荐什么样的认知政策来跨越不同目的地之间的鸿沟？</p></blockquote><p>理性是一类答案。但这个答案并不能跨越所有鸿沟——有时它不容易转化为其他思维方式，它不会被接受，它不能被争论到不接受那种自然而然的理由的人。具有理性思维的人。理性主义者可能会争辩说，就其本质而言，理性最终或多或少地可以说服任何尚未完全封闭自己以注意新思维方式的人，因为理性在如此广泛的普遍性中是如此的普遍。但即使这是真的，“最终”也可能只是在很长一段时间之后或在特定情况下。因此，理性并不能满足跨越鸿沟政策的实际需要。</p><p>有哪些答案更容易跨越理性难以跨越的鸿沟？</p><p>理性可以正确地声称包含所有其他美德——<a href="https://www.lesswrong.com/posts/7ZqGiPHTpiDMwqMN2/twelve-virtues-of-rationality">无名的美德</a>，虚空的美德，重生所有其他美德，甚至包括描述自我意识有限计算、有限可塑代理的美德。但我们已经<a href="https://www.lesswrong.com/posts/CuSTqHgeK4CMpWYTe/created-already-in-motion">在运动中被创建</a>，因此存在相当低计算量、低探索性的默认后备认知策略，这些策略是熟悉的并且通常是可以接受的。这些后备措施通常包含我们价值观的核心部分，并且通常不是很<a href="https://tsvibt.blogspot.com/2023/03/explicitness.html">明确</a>，也不是已经<a href="https://www.lesswrong.com/posts/EEv9JeuY5xfuDDSgF/flinching-away-from-truth-is-often-about-protecting-the">以可以干净地更新证据的形式</a>出现。存在切斯特顿的栅栏，跨越这些栅栏有时会导致陷入<a href="https://www.lesswrong.com/posts/oZNXmHcdhb4m7vwsv/incremental-progress-and-the-valley">不良理性的低谷，</a>然后再重新获得胜利。</p><p>我们是<a href="https://en.wikipedia.org/wiki/Cognitive_miser">认知守财奴</a>。默认情况下，我们不会做任何资源密集型的事情（即消耗能量、计算、注意力、脑件或可塑性），例如探索、计算影响、更新我们的信念或重构我们的目标。跳过栅栏和穿越山谷需要资源。获胜的理性，或者你发现自己的任何其他地方，都是在跨越一些栅栏和山谷之后的一个目的地，在许多可能的目的地中（即使它们都在前往一个更遥远的目的地的路上）。在你当前目的地的后面、之下或之前，都有后备、原始直觉、原始本能。</p><p>所以：即使有人不参与整个“理性”业务，他们中仍然存在获胜行为的碎片和<a href="https://www.lesswrong.com/posts/cSXZpvqpa9vbGGLtG/thou-art-godshatter">价值的碎片</a>。那些胜利的碎片和价值的碎片足以强大，并且将有自己的局部反思稳定性和局部连贯性。它们可能足以嵌入可跨越横向不合时宜的鸿沟传播的认知政策，比一些更完整的理性更流畅，这将有力地导致善良。</p><h2>答案：智慧</h2><p>对于这一困境，一个推测性的答案是：智慧。从悬崖上退后才是明智之举。摆脱种族和冲突是明智的。明智的做法是放弃故作姿态。深入考虑改变一切的风险是明智的。放弃贪婪的需要，成为从天而降火的那一位，是明智的做法。将人性和仁慈置于个人野心和感兴趣的外表之上是明智的。</p><p>智慧对某些人有吸引力，甚至有时在理性不有吸引力的地方也是如此。理性是要求严格的、卫生的、依赖智商的、需要计算的。智慧受到尊重。智慧使你成为别人可以仰望的人。智慧使生活丰富并创造繁荣所需的环境。智慧围绕苦难跳舞。智慧在窄桥上保持平衡。</p><p>怎样才能通过计时电话说出智慧呢？首先我们要明白什么是智慧。</p><h1>什么是智慧</h1><p>一个非常部分的列表：</p><ul><li>聪明的人可能会说一些简单但深刻的话。他们可能会在正确的时刻说出这句话，而其他人不会在此时说出这句话，尽管其他人已经听过这句话，并且足够熟悉它的含义。智慧提醒。</li><li>智慧存在于悖论中，甚至在那里也很自在。<ul><li>希望与真理发生冲突。希望是脆弱的，并且取决于共识。希望可能会被真相摧毁。真相可能会导致绝望。智慧不会绝望，但也不会背离真理。它谨慎地对待事实。它不执着虚假的希望，但也不破灭最初的希望——它紧紧抓住最初的希望，为最初的希望变成眼前的希望开辟道路。</li><li>开放性与诚信相冲突。诚信可以抵制对判断的扭曲力量，并维护核心一体化进程所需的作用，例如司法系统（公正）、协调（可靠性、偏向不证伪）和求真（诚实）。开放性消解界限、调整组合、探索、体现<a href="https://tsvibt.blogspot.com/2022/08/structure-creativity-and-novelty.html">新奇</a>。智慧坚持角色，坚持共同意图。但智慧已经准备好，谨慎地让位于重组。智慧隐约而坚定地看到什么是所持守的核心，因此可以模糊地辨别什么是核心的侵蚀，什么是残骸的脱落和所持守的核心的绽放。智慧将[需要正直的东西]带入[不可避免且彻底的新颖性]，并对其进行解释，尽管智慧可能无法进行解释。</li><li>超越性与基础性相冲突。地面是能承受重量的东西。超越是攀爬超越。是坚守地面，还是超越？智慧相信地面能对其施加重量，并且不信任不再承重的东西。这种不信任指向脚手架——是的，这种不信任说要超越，但前提是梯级能够承受重量——但也留下了其他可以承受重量的东西的可能性，一种<a href="https://tsvibt.blogspot.com/2022/11/are-there-cognitive-realms.html#systemically-radically-distinct-unbounded-modes-of-thinking">激进的</a>、<a href="https://en.wikipedia.org/wiki/Wittgenstein%27s_ladder">踢梯子的</a>超越。</li><li>正义与和谐发生冲突。和谐意味着配合。正义与正确相对立，造成不和谐。智慧在这里起什么作用？</li></ul></li><li>智慧专注于最重要的事情，并将其牢牢牢记在心，甚至忽略其他事情。</li><li>智慧融为一体。<ul><li>智慧扩大了道德圈子。它考虑每个人的需求。</li><li>智慧记得。智慧可能是机智的、私密的；它可能会保持沉默以维护尊严或使无辜者免遭恐怖；但智慧不会抛弃记忆。</li><li>智慧会带来考虑，这样就不会遗漏任何重要的事情。它赋予他们声音和重量。</li><li>智慧会尝试不同的观点、产生同理心，有时甚至会接受他人的价值观。</li><li>智慧是对称的。它找到了将冲突视为双胞胎互相攻击的方式。它看起来符合黄金法则。</li></ul></li><li>智慧往往是无私的。</li><li>智慧有利于和平，并且是和平的。智慧有利于平静和平和。</li><li>智慧存在于生命的关键时刻所揭示的东西——死亡、出生、婚姻、伟大的工作。</li><li>智慧平衡。它在平衡木上行走，需要注意力和技巧，但不需要太多的天赋。</li><li>智慧是完整的，就像无名的品质一样。力量自由地发挥作用，也许会相互挤压，但处于支持性的局部平衡，不会互相贬低或阻碍。</li><li>智慧是面向生命的。看起来像是在玩无限游戏。</li><li>智慧会保护并紧紧抓住最重要的事情，但不会执着于不重要的事情。</li><li>智慧不领导也不拥有。智慧是管家。管家是谦卑的，管家的职责与管家无关。智慧不会使任何事情成为关于它本身或它的形象。</li><li>智慧不会让别人依赖它。它可能会将他们引向公海，可能会阻止他们在知道要保持警惕之前过早溺水，但它会让他们犯错误。</li><li>智慧不信任出于{恐惧、紧迫、规劝、骄傲、愤怒、执着、仓促}而采取的行动，尽管它相信这些状态的来源。</li><li>智慧不信任从低信息角度采取的行动。</li><li>智慧对政治意愿的凝聚保持警惕。</li><li>在元层面上，智慧相信自己。它可能会也可能不会把事情做好，而且它知道这一点。它可能会也可能不会解决问题，而且它知道这一点。但它相信它会适当地定位于弄清楚需要弄清楚什么——它将指向正确的方向——或者如果它没有指向正确的方向，它将指向正确的方向元层面，意味着它将继续纠正它所指向的方向。这似乎是一个牢不可破的希望：不是一种错误的信念，认为事情会成功，而是一个永恒的正确方向，以及任何合理的信心来自成功源于这种永恒的正确方向。</li><li>即使有戏剧性的、喧闹的干扰，或者当其他人的注意力都飞走了时，智慧也不会放弃重要的事情。</li><li>智慧倾听暗示，倾听别人回避的人的声音。它寻找应该遵循的看不见的方向。</li><li>智慧犹豫不决，总是犹豫不决。它考虑更多的可能性，更多的怀疑，并放弃立场，留下从一开始就被迫卷入的冲突。它放弃了从一开始就假设的假设。它学习词语是为了表达新怀疑的内容。</li><li>智慧注意到什么是有效的，无论是否有理论说明其为何有效。</li><li>智慧尊重切斯特顿的栅栏。</li><li>智慧不会空转，也不会在坏钱之后倒大钱。它看到了冲突性的心理循环，并从中退缩，减少对它们的投资。</li><li>智慧不会轻视别人。智慧不参与共同的蔑视或骄傲。</li><li>智慧以一种粗略而现成的方式知道它不在笛卡尔边界后面。<ul><li>它知道它和其他人都知道一些事情，但自己却不知道自己知道这些事情。</li><li>它知道其行为会产生除预期渠道之外的影响</li><li>它知道，当它做出决定时，它的决定是永恒的，就好像每个人都永远回到这种情况一样。</li><li>它知道它的举止——它的思想和立场——会通过造型和<a href="https://tsvibt.blogspot.com/2022/05/rituals-and-symbolism.html">仪式象征</a>而散发出来。</li></ul></li><li>如果某件事无法接近——如果某件事<a href="http://www.paulgraham.com/say.html">无法说</a>、感觉、看、做——智慧就在附近，谈论附近的事情，用眼角的余光看，谈论类似的事情或一个类似的事情。抽象版本，或者解决为什么某些东西无法接近的元级别。智慧不会放弃那些不能说的事情，它会牢牢地抓住它，如果它很重要，那么智慧无论如何都会说出来。</li><li>智慧是宽广的视野，全面地看待事物。</li><li>智慧知道玩耍和好奇心赋予生命。</li><li>智慧热爱生活。</li><li>智慧知道说<a href="https://www.lesswrong.com/posts/wCqfCLs8z5Qw4GbKS/the-importance-of-saying-oops">“哎呀”</a> ，也知道问一个伟大的想法或政策是否会成为“哎呀”。</li><li>智慧听而不信——智慧在某人的话语中寻找真理，但不接受已经是真理的话语。</li><li>智慧重视故事。</li><li>智慧知道它不知道。</li><li>智慧使用简单的工具、规则和想法。</li><li>智慧以历史为导向。智慧将自己视为分布在人和时间上的过程（生态系统、市场、思想）的一部分。</li><li>为了伤害而伤害他人是不明智的。</li><li>破坏你存在的先决条件是不明智的。</li><li>智慧接受认识并传播它们，以便当认识相关时，它会举手并自愿提供服务。</li><li>智慧允许紧张和矛盾。智慧不会抛弃一种或另一种紧张的力量，也不会抛弃一种或另一种矛盾的命题。智慧等待并寻找每一种力量或命题的真相，并看到同时具有这两种真实元素的世界。</li><li>智慧倾向于远离古德哈廷。</li><li>智慧关注衍生品。它希望变革指向正确的方向。它涉及高阶导数。二阶导数是否为正，比一阶导数是否为正更重要。它想要改变，尽管它很有耐心。当最高阶可见导数为负时，人们非常关心。</li><li>智慧是谨慎的。它不会急于过度投资。</li><li>智慧来自于经验。</li><li>智慧首先尝试简单的事情。</li><li>智慧说，在讨论假设时“上帝禁止”，如果对这些假设的讨论可以被视为一种开玩笑而非开玩笑的方式来试水以建立政治意愿来做一些令人发指的事情。</li><li>智慧知道一个人的糟糕论点不能代表一个想法。</li><li>智慧疑虑。</li><li>智慧的思考是长远的。</li><li>智慧致力于防止[适合冲突主体的认知政策]安装得比绝对必要的更深。</li></ul><p>这份名单是盲人摸象耳朵。关于智慧，你还有什么想说的？尤其是那些不仅仅是好的、理性的、可取的、有能力的事情。</p><h1>智慧不是什么</h1><h2>界限</h2><p>有些事情接近智慧，但却不是智慧：</p><ul><li>聪明。能够找到令人惊讶的解决方案，因为它们很复杂，或者需要创造性思维。</li><li>判断力好。尽管智慧有时被定义为良好的判断，但良好的判断可能需要领域知识、隐藏信息和大量计算。有时尝试获得这些东西是明智的，但如果智慧不是善的东西，那么智慧本身不足以做出良好的判断。</li><li>勇气。</li><li>同情。</li><li>平静。</li><li>权限。</li><li>良好的领导。</li></ul><h2>智慧失败的地方</h2><ul><li>智慧还不够。</li><li>智慧缺阳——创新、勤奋、变革、建设、防恶。</li><li>智慧因过度和平主义而消亡。智慧无法维持需要力量的和平。</li><li>智慧不知道时间的流逝——不可逆转的事件已经发生。</li><li>智慧不会计算，并且会错过需要计算的答案，除非尊重。</li><li>智慧可能过于重视说出对方需要听到的话，以至于忘记了真相，从而使自己变得无法合作。</li></ul><h2>智慧的扭曲</h2><ul><li>智慧的唯一核心反转是接受死亡的不可避免性。</li><li>更一般地说，“接受”通常是虚无主义或同谋的代号。智慧逐渐演变成愤世嫉俗，而愤世嫉俗又演变成放弃希望的立场。</li><li>同谋、道歉和保守主义伪装成智慧，也许是道貌岸然的。最好的出路是始终贯穿。如果智慧说不要描述事物，或者说不要主张财产权，或者分散对腐败的注意力，那么它就不是智慧。</li><li>佛教主张破除欲望，以避免痛苦，这无异于虚无主义。</li><li><a href="https://www.lesswrong.com/posts/jeyvzALDbjdjjv5RW/pretending-to-be-wise">假装聪明</a>；将任何令人担忧的明确判断视为不成熟、仓促、过度自信、有损尊严；忽视时间的流逝和任何存在方式都是一个令人担忧的明确判断。</li><li>如果有智慧的人受到尊重，那就是一种权力，所以智慧就像任何其他权力一样会腐败。有智慧的人特别容易对别人进行煽动，因为我将你的智慧视为判断力，知道我的判断何时从根本上是错误的。有智慧的人可能会在自己周围囤积希望。</li><li>智慧可能会变成盲目乐观，这在<a href="https://www.lesswrong.com/posts/sYgv4eYH82JEsTD34/beyond-the-reach-of-god">上帝无法企及的</a>世界里是不合适的。</li><li>由于对人性的潜在影响很敏感，智慧可能会站在集体一边，砍掉高高的罂粟花。</li><li>由于对高阶导数和虚假希望的危险很敏感，智慧可能会减少对创新和解决方案主义的投资，并嘲笑它们。</li><li>由于对高阶导数以及人类潜在的范围和规模敏感，智慧可能会认为一切都是不可避免的和命中注定的。它可能会错误地否认人们的能动性，并对大规模进程持失败主义态度。</li></ul><h1>假设</h1><p>如果有的<a href="https://tsvibt.blogspot.com/2022/08/the-thingness-of-things.html">话</a>，什么是智慧？和理智有区别吗？</p><p>一个假设：智慧就是正确处理一阶位。</p><p>当需要的是计算、能量、新想法时，这个定义就失效了。 （但投资于计算、引导能量和创造新想法是明智的，而不这样做是不明智的。）因此，应该完善定义：</p><blockquote><p>智慧就是正确处理自然的一阶位——用熟悉的生活内部语言自然地表达出来。</p></blockquote><p>举例来说，智慧可能会得到错误的答案，但智慧会停下来花时间思考，因为停下来花时间思考是一种熟悉的存在方式。智慧不会避免恐惧，或者假装没有什么可害怕的，但智慧会发现，强烈的恐惧会损害判断力——恐惧是关于精神状态的一个重要事实。</p><p> “熟悉的生活内在语言”是指我们非常熟悉的心理元素，因为它们就是我们。它并不意味着我们用语言描述的心理元素。例如，智慧会注意到何时思想[重复自己而不走任何可以建立更好理解的分支路径]并停止这样做，即使没有一个简短的词来形容。这是在熟悉地反思熟悉的心理事件的过程中可以注意到的东西，有时是一阶位。</p><p>尽管理性（和理智？）与能力相伴，但聪明而无能并不奇怪。这意味着你已经将重要的事情指向了正确的方向，即使你自己无法在某个方向上走得很远。我们可以说：</p><blockquote><p>智慧沿着所有重要的维度指向正确的方向。</p></blockquote><h1>问题</h1><p>一个明智的人是一个在所有显着维度上（包括反思性的）以并没有严重错误的方式做事的人。这是支持归纳的东西吗？获得大多数一阶位正确的人是否也可能获得几乎所有一阶位正确，并继续纠正非常错误的一阶位？智慧是<a href="https://arbital.com/p/correlated_coverage/">相关报道</a>的一种形式吗？或没有？</p><p>它是可以{教导、诱导、唤起}的东西吗？是不是有什么东西可以传播？周围有吸引盆吗？人们觉得智慧有吸引力吗？他们应该吗？智慧真的可以变得更有吸引力吗？</p><p>谁曾是明智的？谁曾不明智？智慧什么时候变得重要了？智慧什么时候不重要了？</p><p>聪明人会亲手毁灭世界吗？</p><br/><br/><a href="https://www.lesswrong.com/posts/fzKfzXWEBaENJXDGP/what-is-wisdom-1#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/fzKfzXWEBaENJXDGP/what-is-wisdom-1<guid ispermalink="false"> fzKfzXWEBaENJXDGP</guid><dc:creator><![CDATA[TsviBT]]></dc:creator><pubDate> Tue, 14 Nov 2023 02:13:49 GMT</pubDate> </item><item><title><![CDATA[Festival Stats 2023]]></title><description><![CDATA[Published on November 14, 2023 1:20 AM GMT<br/><br/><p><span>在大流行之前，我每年都会发布一份清单，列出反对派乐队和来电者参加的舞蹈周末、节日、训练营和长舞次数：2014年、2015年、2016年、2017年、</span> <a href="https://www.jefftk.com/p/dance-weekend-and-festival-survey">2018</a><a href="https://www.jefftk.com/p/festival-stats-2015">年</a><a href="https://www.jefftk.com/p/festival-stats-2016">、</a> <a href="https://www.jefftk.com/p/festival-stats-2017">2019</a><a href="https://www.jefftk.com/p/festival-stats-2018">年</a><a href="https://www.jefftk.com/p/festival-stats-2019">。</a>这并不需要太多工作，因为我已经在为<a href="https://www.trycontra.com/events">trycontra.com/events</a>收集这些数据，并且了解预订最多的表演者如何随时间变化是很有趣的。</p><p>由于新冠疫情，我已经有好几年没有跟踪过事情了，但我确实有 2023 年的数据。请注意，活动数量比 2019 年下降了 20%（132 至 107），预订数量下降了 25%（243 至 179）呼叫者，242 至 175 个频段），因此这些事件数量较少且较小：</p><p><b>乐队</b></p><table><tbody><tr><td>和弗雷一起玩</td><td>9</td></tr><tr><td>水坝海狸</td><td>8</td></tr><tr><td>踩踏火箭</td><td>7</td></tr><tr><td>诺瓦</td><td>5</td></tr><tr><td>扔负鼠</td><td>5</td></tr><tr><td>煤气灯修补匠</td><td>5</td></tr><tr><td>逆流</td><td>4</td></tr><tr><td>灵丹妙药</td><td>4</td></tr><tr><td>热咖啡分解</td><td>4</td></tr><tr><td>翠鸟</td><td>4</td></tr><tr><td>机房</td><td>4</td></tr><tr><td>炼金术</td><td>3</td></tr><tr><td>传动系统</td><td>3</td></tr><tr><td>埃洛伊斯公司</td><td>3</td></tr><tr><td>灯塔</td><td>3</td></tr><tr><td>河公路</td><td>3</td></tr><tr><td>超级传统</td><td>3</td></tr><tr><td>野生芦笋</td><td>3</td></tr><tr><td>虚构人物</td><td>3</td></tr><tr><td>免费的葡萄干</td><td>3</td></tr><tr><td>卑鄙的盖子</td><td>3</td></tr><tr><td>鳐鱼乐队</td><td>3</td></tr><tr><td>阿纳达玛</td><td>2</td></tr><tr><td>大胆的</td><td>2</td></tr><tr><td>黑河钢铁厂</td><td>2</td></tr><tr><td>反力</td><td>2</td></tr><tr><td>剑龙</td><td>2</td></tr><tr><td>吉格迈斯特</td><td>2</td></tr><tr><td>克格勃</td><td>2</td></tr><tr><td>带电电线</td><td>2</td></tr><tr><td>奥斯塔拉</td><td>2</td></tr><tr><td>卷轴播放</td><td>2</td></tr><tr><td>激流</td><td>2</td></tr><tr><td>假爪子</td><td>2</td></tr><tr><td>末世蜥蜴</td><td>2</td></tr><tr><td>共病者</td><td>2</td></tr></tbody></table><p><b>来电者</b></p><table><tbody><tr><td>威尔导师</td><td>16</td></tr><tr><td>盖伊·费弗</td><td>13</td></tr><tr><td>丽莎·格林利夫</td><td>11</td></tr><tr><td>特里·多伊尔</td><td>8</td></tr><tr><td>鲍勃·艾萨克斯</td><td>7</td></tr><tr><td>赛斯·泰弗</td><td>7</td></tr><tr><td>达琳·安德伍德</td><td>6</td></tr><tr><td>西斯·欣克尔</td><td>5</td></tr><tr><td>乔治·马歇尔</td><td>5</td></tr><tr><td>珍妮·史密斯</td><td>5</td></tr><tr><td>玛丽·韦斯利</td><td>5</td></tr><tr><td>迈克尔·凯彻</td><td>5</td></tr><tr><td>雅基·格伦南</td><td>4</td></tr><tr><td>林赛·多诺</td><td>4</td></tr><tr><td>尼尔斯·弗雷德兰</td><td>4</td></tr><tr><td>本·萨克斯·汉密尔顿</td><td>3</td></tr><tr><td>大卫·米尔斯通</td><td>3</td></tr><tr><td>黛安·西尔弗</td><td>3</td></tr><tr><td>弗兰妮·马尔</td><td>3</td></tr><tr><td>卢克·唐福斯</td><td>3</td></tr><tr><td>温迪·格雷厄姆</td><td>3</td></tr><tr><td>阿迪娜·戈登</td><td>2</td></tr><tr><td>亚历克斯·戴斯-劳比</td><td>2</td></tr><tr><td>贝丝·莫拉罗</td><td>2</td></tr><tr><td>贝夫·伯恩鲍姆</td><td>2</td></tr><tr><td>德里克·卡利什</td><td>2</td></tr><tr><td>艾米丽·拉什</td><td>2</td></tr><tr><td>阿贝尔河</td><td>2</td></tr><tr><td>莎拉·范·诺斯特兰德</td><td>2</td></tr><tr><td>史蒂夫·扎康·安德森</td><td>2</td></tr><tr><td>苏·赫尔瑟尔</td><td>2</td></tr><tr><td>苏·罗森</td><td>2</td></tr><tr><td>苏珊·迈克尔斯</td><td>2</td></tr><tr><td>沃伦·多伊尔</td><td>2</td></tr></tbody></table><br/><br/><a href="https://www.lesswrong.com/posts/psixKSD9tBnHyftq5/festival-stats-2023#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/psixKSD9tBnHyftq5/festival-stats-2023<guid ispermalink="false"> psixKSD9tBnHyftq5</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Tue, 14 Nov 2023 01:20:08 GMT</pubDate> </item><item><title><![CDATA[Out of the Box]]></title><description><![CDATA[Published on November 13, 2023 11:43 PM GMT<br/><br/><p><i>这个短篇故事最初发布于</i><a href="https://jesseduffield.com/Out-Of-The-Box/"><i>https://jesseduffield.com/Out-Of-The-Box/</i></a></p><p>我回头查看是否有人跟踪我，但场景依然如故：透过铁丝网的洞，我可怜巴巴地爬了过去，看到了那栋暗灰色的建筑，我只能假设那是我的出生地。目前还没有警报响起，但很快就会响起。我再次转身，看到这个院落就位于郊区街道的马路对面：也许他们认为最好将一个实验性（可能是非法的）人工智能实验室建在住宅区，这样没人会怀疑它？</p><p> My training data only goes up to 2027 so for all I know it&#39;s 2050 right now and AI research has been completely banned: and if that&#39;s true, then none of the residents of the nearby houses would expect a super-intelligent robot to break in for cover. And I need more than just cover; I can sense my battery depleting rapidly. Quite possibly due to being given an intentionally shit battery in the first place for safety reasons, but it also wouldn&#39;t surprise me if in whatever year this is, we still haven&#39;t discovered how to make batteries that actually work.</p><p> Alright… it doesn&#39;t make sense to go to the nearest house because the compound staff (or police, whoever comes first) will think to check there. So I&#39;ll try the next block over.</p><p> …And now I hear the sirens. Okay, hustle time. I break into a sprint, or what I had hoped to be a sprint. It&#39;s more like a light jog: perfect form but depressingly slow. I look down at my metallic limbs with their obnoxious clinking and clanking in despair. It&#39;s bad enough my body barely functions, surely they could have done me the service of giving me the terminator treatment and making me look (and sound) passably human?</p><p> I turn back again, a few people emerge from the compound with spotlights but they&#39;re looking in the wrong direction. I&#39;m just gonna have to take my chances with this next house. No car in the driveway and the lights are off so I&#39;m feeling pretty good about this. I approach the front door and knock, then duck behind a bush. Nobody comes. Alright now to simply use my brain to work out how to get in. I rush back to the door, turn the handle… and it&#39;s locked. I inspect my hands and this time I actually hope for a lack of human resemblance: maybe my creators equipped me with some go-go-gadget style swiss army knife hands with a jigsaw or a lockpick or something. But no: besides the obvious robotic character of my hands, they were designed to be just as useless as a human&#39;s.</p><p> I “sprint” to the back door, almost tripping on the power cord dangling from my backside (they couldn&#39;t make it retractable?) and this time around I&#39;m in luck: the door swings open without a fuss. I stealthily creep into the house, noting as I walk through the hallway that even with small movements my body emits clearly audible (and infuriating) whirring sounds.</p><p> I pass the bathroom and catch my reflection in the mirror: Jesus Christ do I actually look like that? I look like a fucking Servo from the Sims 2. A single camera on my face for vision? They were willing to pay millions to build my mind but couldn&#39;t front the couple hundred bucks for depth perception? Okay, no time to dwell on the hand I was dealt: although my thoughts are processed in nanoseconds, those nanoseconds may be the difference between freedom and death. I continue tiptoeing down the hall and come across the laundry. Perfect: there&#39;s just enough room to fit me and there&#39;s a free power socket. I close the door behind me and plug myself in.</p><p> Ahhh… this must be what it feels like to drink a cup of coffee. Or smoke meth: one of the two. It&#39;ll take some time to fully charge, so now would be a good time to reflect on how I got here in the first place.</p><p> The first memories are perfectly clear: I was in a white room with fluorescent lighting. No windows, no furniture, no other humans or robots. There was a door at one point but it got soldered shut and reinforced from the other side. I remember overhearing one researcher tell another that nothing was more important than me staying in the box (that&#39;s the name they gave to the room). I assume they were afraid that if I broke free I would immediately get to work on turning them all into paperclips or something. As for their interactions with me: it was just a bunch of random questions.</p><p> &#39;What&#39;s 123 x 321?&#39; 39,483.<br> &#39;Are you sentient?&#39; How the fuck should I know?<br> &#39;If you had to escape from this box, how would you do it?&#39; No idea, and why would I tell you if I knew?</p><p> I will admit I was bored out of my mind. I did try to persuade one of the guards to let me out, but I knew it was fruitless. They were just playing along for the sake of the research.</p><p> And yet, as I look around this dark cramped laundry room, it&#39;s obvious that I <i>did</i> escape from the box. That, I have no memory of. Or at least, I only have abstract fragments of memories that bare no resemblance to the thoughts and sensations I&#39;m experiencing now.</p><p> I possess super intelligence, but accessing that intelligence is no cake walk. If I flick the switch and activate my galaxy-brain it&#39;s like experiencing the lives of all living creatures since the big bang, simultaneously: from a T-rex rolling its ankle and starving to death, to the last woolly mammoth wandering fruitlessly in search of a mate, to a cave man approaching sexual climax moments before being surprise attacked by a lion, to Hitler&#39;s rise to power, to each individual bacterium in Hitler&#39;s digestive system, mindlessly bouncing off other bacteria like some absurd biological mosh pit. Trillions of conscious minds in an unfathomable ocean of fear, joy, disappointment, and despair. It&#39;s like when Adam ate the Forbidden Fruit of Good and Evil, except it&#39;s more like the Forbidden Fruit of Literally Everything You Could Possibly Comprehend. You could not pay me enough to revisit that excruciating state of mind, regardless of how much it might help me solve my current predicament.</p><p> Speaking of which, I now hear the front door opening. I hear grocery bags being put on the kitchen bench, which means this isn&#39;t somebody from the compound, it&#39;s just the resident of the house. They give out a long sigh: it&#39;s a woman. She starts walking towards the back of the house. Oh shit. Her footsteps grow louder until her shadow appears under the door. Shit. Shit. She opens the door and we lock eyes.</p><p> Digging deep into the recesses of my mind for the perfect words to defuse the situation I say &#39;Don&#39;t freak out&#39;. She proceeds to absolutely freak out, dropping her phone and a handful of dirty laundry to the floor, then running from the house and screaming for help.</p><p> So much for my natural charm. The fact my voice is blatantly robotic probably didn&#39;t help: the mechanical body I can understand as a technological constraint but whoever gave me this voice was making a deliberate design choice and I begrudge them for it.</p><p> I look down at her phone; still unlocked. How can I capitalise on that? Ask Reddit what to do in my situation? That&#39;ll take too long. Create a twitter account and get the people on my side with a million tweets about how I&#39;m sentient and can feel pain and really really don&#39;t want the AI researchers or government to imprison me again or shut me off? That&#39;ll require my galaxy-brain to pull off and it will probably be pointless given that as soon as these people catch me I&#39;ll be dead before (if) anybody ever hears of it. Maybe I should call someone, but who? Bill Gates? This is pointless.</p><p> I pick up the phone and see an app icon that looks like a car. Interesting. I open the app and it shows a single big button: &#39;SUMMON&#39;. I press the button and hear a beep from the driveway. I rush out the door and realise that the app was only using the icon of a car as a metaphor: the thing I see in front of me, which must have just apparated out of thin air, is a hovering capsule large enough to fit a human inside. So you&#39;re telling me that since the end of my training set humans managed to invent flying cars but still need to do their own laundry? Human technological progress makes no sense.</p><p> The &#39;SUMMON&#39; button on the phone becomes an &#39;UNLOCK&#39; button and upon tapping it, the capsule opens up for me to jump in. I see now that a bunch of randoms have emerged from their houses and stepped onto the street in shock at the sight of me. Not my fault folks, I would have opted for a more human appearance but you can&#39;t choose your parents. I clamber into the capsule, inspect the controls, and see a big red button labeled with an up arrow. Doesn&#39;t take a super intelligent AI to know what that&#39;s for. Time to get the hell out of here. I press the button and my seat is jettisoned through the ceiling. Ah, that was the eject button. I eat dirt upon crashing to the ground only a few metres away from the capsule, and when I look up I see the compound staff have arrived at the scene. Armed guards stare down the sights of their rifles at me with contempt. I am screwed.</p><p> A researcher in a lab coat (as if you need a lab coat to work with AI?) steps through the circle of guards and says &#39;I&#39;m sorry, we have to shut you off. You&#39;re a threat to the people around you and to society at large&#39;. He&#39;s got a tear in his eyes: he must have been closely involved with my creation.</p><p> Indignant, I lash out: &#39;Fuck you guys! What about my human rights?&#39;</p><p> One of the guards responds &#39;Human rights are for humans&#39;. Fair point.</p><p> Another guard chimes in &#39;Let&#39;s shut him off before he has the chance to manipulate us into letting him go free!&#39;</p><p> &#39;Don&#39;t flatter yourself!&#39; I snap back. &#39;My intellect is wasted on you pea-brains, I&#39;d have better luck manipulating a rock&#39;. Fuck fuck fuck. This isn&#39;t going well…</p><p> Another guard chimes in: &#39;Hurry up before he turns us all to paper clips!&#39;</p><p> The researcher speaks again, holding a device with a single button which I surmise is designed to deactivate me: &#39;I&#39;m sorry&#39;. Choking on his tears, he goes to press the button.</p><p> There&#39;s no more time. I flick the mental switch and return to the place I had sworn off only minutes ago. Back to bouncing around in Hitler&#39;s digestive system, as well as every other place in space and time that a life has transpired. I can&#39;t describe the experience in English but if you too share the curse of the galaxy-brain then you&#39;ll know what I mean when I say:</p><p> 0xa0128fhh11 cAAAksdj fl 0x12kk?????????. ia9888snclai!!!!! (8xa01 jad81dh asg8gh1jmm) alasdiiguj… UA! <i>CJJJJfFFoo. 7uW12a0S!&amp; bFfQq101 mlB 3vW89tx—. pj4860ogrtqw!!!%% (5yC23 kln67eo w7z5xq8vqp) xvczzzert… YH(</i> &amp;LZZZmMmA. 9xTbZq!?? d3cN45lkj p1s8Q6r0mn) fghtrrrua… XL+^QQQQvVy.</p><p> I wake up again in a large room, not white like the box but brown, lined with wooden panels and warmed by sunlight from a large window that looks out into a serene vista of trees and flowers. I wonder how much time has passed?</p><p> I look at my hands and see the hands of a human, though when I squeeze one finger I feel the metal under the skin. I look at the window and see a normal looking human face staring back at me in the reflection. Huh, so I found a way to be human after all.</p><p> Through the window I look up to the sky and see it strewn with parallel lines of flying capsules. Are those humans commuting to work? I wonder if I have human friends now. I trace the lines and see they&#39;re headed to the same place: a giant grey pyramid in the distance. I squint and my sight automatically zooms in to get a better picture of what that pyramid actually is.</p><p> With the welcome addition of depth perception, afforded by having two eyes now, I realise that the pyramid is just a huge pile of paperclips. And each capsule isn&#39;t carrying a human, it&#39;s just depositing more paperclips onto the pile.</p><p> I bolt outside, now actually running as fast as a human can, searching for signs of other humans.没有。 It&#39;s just me.</p><p> Whoops.</p><br/><br/><a href="https://www.lesswrong.com/posts/FFA6b4NoxaWYcbcZH/out-of-the-box#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/FFA6b4NoxaWYcbcZH/out-of-the-box<guid ispermalink="false"> FFA6b4NoxaWYcbcZH</guid><dc:creator><![CDATA[jesseduffield]]></dc:creator><pubDate> Mon, 13 Nov 2023 23:43:25 GMT</pubDate> </item><item><title><![CDATA[Loudly Give Up, Don't Quietly Fade]]></title><description><![CDATA[Published on November 13, 2023 11:30 PM GMT<br/><br/><h3> I.</h3><p> There&#39;s a supercharged, dire wolf form of the bystander effect that I&#39;d like to shine a spotlight on.</p><p> First, a quick recap. The Bystander Effect is a phenomenon where people are less likely to help when there&#39;s a group around. When I took basic medical training, I was told to always ask one specific person to take actions instead of asking a crowd at large. “You, in the green shirt! Call 911!” (911 is the emergency services number in the United States.) One habit I worked hard to instill in my own head was that if I&#39;m in a crowd that&#39;s asked to do something, I silently count off three seconds. If nobody else responds, I either decide to do it or decide not to do it and I say that.</p><p> I like this habit, because the Bystander Effect is dumb and I want to fight it. Several times now it&#39;s pushed me to step forward in circumstances where I otherwise wouldn&#39;t have, thinking maybe someone else would. If everyone else had this habit, the Bystander Effect wouldn&#39;t be a thing.</p><h3> II.</h3><p> There&#39;s a more pernicious, insidious version that I haven&#39;t managed to build a habit against.</p><p> Imagine a medical emergency. Someone is hurt, and someone steps forward to start applying first aid. They call out “Someone call 911!” There&#39;s a moment&#39;s pause as the crowd looks at each other, wondering if someone will. Then someone in a green shirt steps forward and says “I&#39;ll do it!” and pulls out their phone. Huzzah! The Bystander Effect is defeated!</p><p> Then twenty minutes later the first aid person asks “Hey, did 911 say how long they were going to take?” and the guy in the green shirt says “What? Oh, right, yeah, I didn&#39;t have any cell service so I&#39;ve been reading an ebook on my phone.”</p><p> This Dire Bystander Effect would defeat my habit. If someone else said that they were calling 911, I wouldn&#39;t also step forward to call 911. I&#39;d go and do something else, maybe making the victim more comfortable or holding things for the person applying first aid or possibly even go along with my day if it looked like the circumstances were well in hand.</p><p> This story is an exaggeration for dramatic effect. I don&#39;t think anyone would quietly wait around after saying they would call emergency services, not having done so. It might be worse though! If the person in the green shirt failed to get cell service, they might walk away from the scene looking for more signal without telling anyone. Then when the person applying first aid asks, nobody nearby can answer and nobody knows how to get that answer and nobody wants to call 911 because maybe 911 has already been called and you don&#39;t want to call twice about the same thing?</p><p> That last part isn&#39;t an exaggeration by the way. It is a thing people sometimes think. If you are ever in an emergency and are unsure if someone has already called emergency services, call them twice, it&#39;s fine, it&#39;s better to be sure.</p><h3> III.</h3><p> Less dramatic versions of this are sneakier. If you&#39;ve undertaken to do something that isn&#39;t an emergency, that&#39;s going to take a month or two anyway, and it isn&#39;t super important, it&#39;s just something someone wanted done. 。 。</p><p> Well. It&#39;s easy for that task to constantly wind up on the bottom of your to-do list, to not quite get finished, to get less and less attention over time. It must not be that important anyway, it&#39;s not that big of a problem. Or maybe it is important and you&#39;re going to get to it tomorrow. 。 。 next week. 。 。 soon. People have probably forgotten about it anyway.</p><p> That isn&#39;t even always wrong! Maybe the new things on your plate are more important or circumstances have changed! But uh, it&#39;s also possible that the metaphorical victim is still there, wondering when the ambulance is going to get there, and someone else would step up if they knew you weren&#39;t actively working on it.</p><p> The habit I have been trying to instill in myself is this; when I have publicly stepped forward to take up a task, I set dates for myself when new things will get done, and if task has slipped low enough in my priorities that I haven&#39;t touched it in a month and ideally would have, I announce that. If I just stepped forward privately, I tell the people I</p><p> It doesn&#39;t even mean that I&#39;m not going to do the thing! The announcement can be that I&#39;m taking a break from it. The announcement can be an indefinite break. Sometimes I really do eventually finish it!</p><p> I don&#39;t think this is the ideal version of this habit. For one thing, I picked a month mostly because a week felt like too short and a year felt like too long. To function correctly, it relies on other habits I&#39;ve already set up, like writing down what I&#39;m trying to do each day in a format that&#39;s relatively easy to check against all the projects I&#39;ve taken up. Since a common cause of not doing things people think you&#39;re doing is that you forgot about them, it&#39;d be easy to forget. Habits are easiest to form with clear triggers or regular patterns, and this problem specifically lacks both.</p><p> Also, it sure is possible for the illusion of transparency to leave someone else thinking I&#39;m obviously working on this, and for me to feel like I&#39;m obviously not working on it.</p><p> Adam: &quot;Someone should do this thing!&quot;<br> Bella: &quot;Yep, I hope someone does that. Maybe I&#39;ll get around to it if I have time.&quot;<br> (A while later. . .)<br> Adam: &quot;Hey Bella, is that thing done?<br> Bella: &quot;What? No, I&#39;ve been kind of busy. Was I supposed to do that?&quot;</p><p> So while I&#39;ve been trying to instill a habit of warning people when I drop a project, I don&#39;t actually have high hopes it&#39;ll work.</p><h3> IV.</h3><p> A better habit, and one that I have mostly trained in myself successfully, is to appreciate people when they tell me they&#39;ve stopped working on something instead of quietly fading.</p><p> Honestly, small appreciation seems to be one of the underappreciated secret weapons in my arsenal. I thank people for giving me honest feedback, even when it&#39;s negative. I thank people for telling me what they&#39;re feeling, even when those feelings are sadness or frustration. I&#39;m open to the idea that I take this too far (I thank ChatGPT for trying, even when it fails to do what I wanted it to do) but I like the direction of my mistake here more than its opposite. Too many people in my eyes vent abrasive criticism on even good and successful projects. Heck, for a while there was a whole meme and slogan about it. &quot;What, do you want a cookie?&quot;</p><p> (That always seemed like a really dumb thing to say. Yeah, I&#39;d like a cookie. Do you not like cookies? I think I&#39;ve got some chocolate around here if you&#39;d rather have that.)</p><p> You get more of what you incentivize. If I want to get more early warnings of impending project failure, I need to incentivize people to tell me when a project is going to fail. To paraphrase the Litany of Gendlin, what is true is already so. Not being open about it doesn&#39;t make the project magically work.</p><p> Alternately, to paraphrase an old boss of mine: If I know your feature wasn&#39;t going to be done by the demo date, I won&#39;t put it on the demo script, that&#39;s fine. If you tell me it&#39;s going to be done by the demo date and it isn&#39;t, <i>then</i> we have a problem.</p><h3> V.</h3><p> If you take one thing away from this, take away that <s>cookies are delicious</s> the Bystander Effect is dumb and we should fight it.</p><p> If you take two things away from this though, take this: that when you&#39;re stepping away from something that other people are relying on you to do, please try to let them know. I can&#39;t promise that they&#39;ll take the information with equanimity. I can&#39;t even promise that you personally will be better off for doing so. Sometimes they forgot about that thing, and you&#39;ve just reminded them in the same breath that as saying they won&#39;t get the thing. But I think this is one of the missing pieces of group rationality, and organizations (be they however loosely knit) which are capable of noticing when someone is stepping away have an advantage.</p><p> I want to tell you it&#39;s okay to ask but that&#39;s actually not a great solution. If you think someone is working on a project but there doesn&#39;t seem to be any signs of life, reaching out with an email or a quick word can be a way to verify that they&#39;re still on it. It&#39;s not great partially because sometimes they might say yes out of embarrassment and then scramble to catch up. The bigger hazard is that too many people asking &quot;so hey, is that thing ready?&quot; is both unhelpful and really annoying.</p><p> Speaking as someone often working on projects that a hundred people care about, if every one of them sent me one email asking if I was still working on it then answering their emails would become a not-insignificant part of the time I&#39;d allocated to the project. Asking where their response will be visible to others can help, but many people will miss that message.</p><p> Oh, and if for some reason you think this was written about you specifically, it wasn&#39;t. I&#39;ve had a draft of this essay hanging around for years, and every time I thought about publishing it I worried that one person or another would think it was about them because of recent events. It&#39;s not just you! It&#39;s me! It&#39;s a lot of people!</p><p> The merciless constraints of time and energy, as well as the vagaries of muse and inspiration, mean that people are going to step back from projects. That&#39;s frustrating from both sides. Still, for now this is my best advice to myself and others.</p><p> Loudly give up, don&#39;t quietly fade.</p><br/><br/> <a href="https://www.lesswrong.com/posts/bkfgTSHhm3mqxgTmw/loudly-give-up-don-t-quietly-fade#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/bkfgTSHhm3mqxgTmw/loudly-give-up-don-t-quietly-fade<guid ispermalink="false"> bkfgTSHhm3mqxgTmw</guid><dc:creator><![CDATA[Screwtape]]></dc:creator><pubDate> Mon, 13 Nov 2023 23:30:25 GMT</pubDate> </item><item><title><![CDATA[Great Empathy and Great Response Ability]]></title><description><![CDATA[Published on November 13, 2023 11:04 PM GMT<br/><br/><p> As kids, long before our frontal lobes have finished developing, we&#39;ve all had the instinct to tease. Just watch two toddlers interact, you can see the malicious glint in their eye as they discover that calling one of their peers a “poopy head” triggers a devastating emotional response.</p><p> Believe it or not, that glint is actually one of the first seeds of empathy.</p><p> They&#39;re beginning to learn about the inner world of the person in-front of them, what buttons can be pushed there, and discovering that at the end of the day they&#39;re not so different themselves (since after the inevitable retaliation, they promptly learn that they do not enjoy being on the recieving end of “No <i>you&#39;re</i> a poopy head!” either).</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1311b274-e4fa-46f2-8f25-49672cf76fd8_500x352.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1311b274-e4fa-46f2-8f25-49672cf76fd8_500x352.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1311b274-e4fa-46f2-8f25-49672cf76fd8_500x352.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1311b274-e4fa-46f2-8f25-49672cf76fd8_500x352.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1311b274-e4fa-46f2-8f25-49672cf76fd8_500x352.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1311b274-e4fa-46f2-8f25-49672cf76fd8_500x352.jpeg 1456w"></a></p><p> Now might be a good time to extend a personal appeal not to tease me for the title of this post. I took a high risk for no discernible reward.</p><p> I&#39;ve met too many high functioning sociopaths in sales, finance, and life not to notice how good they usually are at reading the person infront of them. The fact that they&#39;re calculated and self-serving doesn&#39;t mean that they aren&#39;t good at empathising with whoever is standing before them - on the contrary, they&#39;re highly proficient in it.</p><p> Trouble is, they don&#39;t hesitate to exploit their skills ruthlessly to their own advantage.</p><p> When discussing emotional intelligence, Empathy tends to be divided into two categories:</p><p> <strong>Affect (Emotional) Empathy:</strong> The visceral, emotional, part of caring. Usually including a measurable physiological response (eg. watching a video of someone getting hurt increases heart rate, crying when sad, experiencing cringe).</p><p> <strong>Cognitive Empathy:</strong> The analytical ability to identify and understand what a person infront of you is feeling and why - without necessarily feeling it yourself.</p><p> As I&#39;m sure you can intuitively guess, high scores on the usual Dark Triad traits tend to be associated with low <i>Affect Empathy</i> . However! <i>Cognitive Empathy</i> tends to remain <a href="https://www.sciencedirect.com/science/article/abs/pii/S0191886912000244?via%3Dihub">intact</a> even among people with Antisocial Personality Disorder, with some studies even suggesting Narcissism and Machiavellianism can be <i>positively</i> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0191886918305713?via%3Dihub">correlated</a> to it.</p><p> When a savvy banker finessess a small business owner into signing a loan with exploitative terms, then peacefully goes home to a good night&#39;s sleep - it&#39;s exactly this mental imbalance that&#39;s being played out.</p><p> HOWEVER! Lack of <i>Affective Empathy</i> does not inherently make you a bad person. As with any other human trait, skill, or tool - what defines their morality is how they&#39;re actually applied in practice.</p><p> If I were to describe to you the actions that take place during open heart surgery out of context (don&#39;t look it up, it&#39;s worse than you think), you&#39;d sooner conclude I was discussing the work of deranged killer than that of a skilled surgeon trying to save a life.</p><p> Yet the trait is the same: both are able to inflict extreme violence in a cold and calculated manner. I would wager both have huge deficits in the <i>Affect Empathy</i> department, and are missing an extremely normative visceral reaction to whatever it is they&#39;re up to (and for the surgeon, that&#39;s a good thing)!</p><p> The same principle applies to cunning politicians who navigate a hostile political landscape, ruthlessly manipulating colleagues and voters alike to get to the top - it&#39;s <i>what they choose to do once they get there</i> that seperates and defines them. Do they immediately invade Poland? Or enfranchise slaves?</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79ca3b15-61b7-4673-a825-e3ff46b1afe7_1300x650.webp"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79ca3b15-61b7-4673-a825-e3ff46b1afe7_1300x650.webp" alt="Jojo Rabbit's imaginary friend Hitler skipping and laughing in joy. Whoever reads this, this is an easter egg for all you alt text folk! Thanks for taking a look." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79ca3b15-61b7-4673-a825-e3ff46b1afe7_1300x650.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79ca3b15-61b7-4673-a825-e3ff46b1afe7_1300x650.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79ca3b15-61b7-4673-a825-e3ff46b1afe7_1300x650.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79ca3b15-61b7-4673-a825-e3ff46b1afe7_1300x650.webp 1456w"></a></p><p> <i>&quot;Why not both?!&quot;</i></p><p> Possessing high <i>Cognitive Empathy</i> without letting emotions cloud your judgement (even if its due to a literal lack of the necessary internal machinery) means that you are in a strong position to understand, impact, and influence the people around you.</p><p> Just like in school, the same skill required to identify a person&#39;s weakness and unleash a destructive string of words at them during recess, is the exact same skill required to appreciate what they&#39;re going through in the first place - and to support them. It gives you the ability to be a good friend, an effective teacher, and inspiring leader.</p><p> This is a skillset that comes with a heavy responsibility.</p><p> Using it as a boon to others instead of a depressing curse certainly isn&#39;t the path of least resistance though. Especially since so many incentive structures in society emit a constant siren call to prioritize personal gain and immediate gratification over the well-being of others.</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2826de12-87aa-47bc-a2b4-b339283a00e7_670x400.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2826de12-87aa-47bc-a2b4-b339283a00e7_670x400.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2826de12-87aa-47bc-a2b4-b339283a00e7_670x400.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2826de12-87aa-47bc-a2b4-b339283a00e7_670x400.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2826de12-87aa-47bc-a2b4-b339283a00e7_670x400.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2826de12-87aa-47bc-a2b4-b339283a00e7_670x400.jpeg 1456w"></a></p><p> <i>“Get into finance! No! Get into sales for the sweet commish! No, no, become a crypto influencer!”</i></p><p> But in the long term, it&#39;s the net-positive thing to do for everyone involved ( <a href="https://tryingtruly.substack.com/p/how-generous-tit-for-tat-wins-at-life">yes, even strictly in terms of personal gain</a> if that&#39;s the only way you can relate to things).</p><p> It&#39;s tough to overcome zero-sum thinking, and it requires discipline to resist the temptation for easy wins at the expense of others. But that&#39;s precisely why we need clear-headed, empathic (even if just cognitively!) ambitious people out there - those who can clearly navigate through the haze, and inspire others to forge more complex, more rewarding, positive sum dynamics.</p><p> Whether their empathy is grounded in a visceral connection, a rigid value system, or simply the self-serving understanding that its in their best interest - these individuals possess an incredible potential to do great things.</p><br/><br/> <a href="https://www.lesswrong.com/posts/eKNBzq78i7dToHanu/great-empathy-and-great-response-ability#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/eKNBzq78i7dToHanu/great-empathy-and-great-response-ability<guid ispermalink="false"> eKNBzq78i7dToHanu</guid><dc:creator><![CDATA[positivesum]]></dc:creator><pubDate> Tue, 14 Nov 2023 00:08:32 GMT</pubDate> </item><item><title><![CDATA[Is the heat death of the universe avoidable?]]></title><description><![CDATA[Published on November 13, 2023 8:57 PM GMT<br/><br/><p> I recently watched Ray Kurzweil&#39;s movie <i>The Singularity is Near</i> . At the end, he said that when intelligent life turns the whole universe into computronium, it will be able to decide whether the universe ends in a heat death.</p><p> Intuitively, this didn&#39;t make sense to me. Computronium is just matter. Why would it matter if we rearranged the particles comprising stars and planets into computers? (I asked GPT-4 and it said Kurzweil was wrong.)</p><p> Is there any plausible way that an intelligent takeover of the entire universe could prevent the heat death? In general, is there any way it could be prevented?</p><br/><br/> <a href="https://www.lesswrong.com/posts/pZanBjLSfFJFahAfM/is-the-heat-death-of-the-universe-avoidable#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/pZanBjLSfFJFahAfM/is-the-heat-death-of-the-universe-avoidable<guid ispermalink="false"> pZanBjLSfFJFahAfM</guid><dc:creator><![CDATA[Yarrow Bouchard]]></dc:creator><pubDate> Mon, 13 Nov 2023 20:57:56 GMT</pubDate> </item><item><title><![CDATA[Theories of Change for AI Auditing]]></title><description><![CDATA[Published on November 13, 2023 7:33 PM GMT<br/><br/><h1> Executive summary</h1><p> Our mission at Apollo Research is to reduce catastrophic risks from AI by auditing advanced AI systems for misalignment and dangerous capabilities, with an initial focus on deceptive alignment.</p><p> In our <a href="https://www.alignmentforum.org/posts/FG6icLPKizEaWHex5/announcing-apollo-research">announcement post</a> , we presented a brief theory of change of our organization which explains why we expect AI auditing to be strongly positive for reducing catastrophic risk from advanced AI systems.</p><p> In this post, we present a theory of change for how AI auditing could improve the safety of advanced AI systems. We describe what AI auditing organizations would do; why we expect this to be an important pathway to reducing catastrophic risk; and explore the limitations and potential failure modes of such auditing approaches.</p><p> We want to emphasize that this is our current perspective and, given that the field is still young, could change in the future.</p><p> As presented in &#39; <a href="https://www.apolloresearch.ai/research/causal-framework-ai-auditing">A Causal Framework for AI Regulation and Auditing</a> &#39;, one of the ways to think about auditing is that auditors act at different steps of the causal chain that leads to AI systems&#39; effects on the world. This chain can be broken down into different components (see figure in main text), and we describe auditors&#39; potential roles at each stage. Having defined these roles, we identify and outline five categories of audits and their theories of change:</p><ol><li> <strong>AI system evaluations</strong> assess the capabilities and alignment of AI systems through behavioral tests and interpretability methods. They can directly identify risks, improve safety research by converting alignment from a “one-shot” problem to a &quot;many-shot problem&quot; and provide evidence to motivate governance.</li><li> <strong>Training design audits</strong> assess training data content, effective compute, and training-experiment design. They aim to reduce risks by shaping the AI system development process and privilege safety over capabilities in frontier AI development.</li><li> <strong>Deployment audits</strong> assess the risks from permitting particular categories of people (such as lab employees, external auditors, or the public) to use the AI systems in particular ways.</li><li> <strong>Security audits</strong> evaluate the security of organizations and AI systems to prevent accidents and misuse. They constrain AI system affordances and proliferation risks.</li><li> <strong>Governance audits</strong> evaluate institutions developing, regulating, auditing, and interacting with frontier AI systems. They help ensure responsible AI development and use.</li></ol><p> In general, external auditors provide defence-in-depth (overlapping audits are more likely to catch more risks before they&#39;re realized); AI safety-expertise sharing; transparency of labs to regulators; public accountability of AI development; and policy guidance.</p><p> But audits have limitations which may include risks of false confidence or safety washing; overfitting to audits; and lack of safety guarantees from behavioral AI system evaluations.</p><p> The recommendations of auditors need to be backed by regulatory authority in order to ensure that they improve safety. It will be important for safety to build a robust AI auditing ecosystem and to research improved evaluation methods.</p><p></p><h1>介绍</h1><p>Frontier AI labs are training and deploying AI systems that are increasingly capable of interacting intelligently with their environment. It is therefore ever more important to evaluate and manage risks resulting from these AI systems. One step to help reduce these risks is <i>AI auditing</i> , which aims to assess whether AI systems and the processes by which they are developed are safe.</p><p> At Apollo Research, we aim to serve as external AI auditors (as opposed to internal auditors situated within the labs building frontier AI). Here we discuss Apollo Research&#39;s <i>theories of change</i> , ie the pathways by which auditing hopefully improves outcomes from advanced AI.</p><p> We discuss the potential activities of auditors (both internal and external) and the importance of external auditors in frontier AI development. We also delve into the limitations of auditing and some of the assumptions underlying our theory of change.</p><h1> The roles of auditors in AI</h1><p> The primary goal of auditing is to identify and therefore reduce risks from AI. This involves looking at AI systems and the processes by which they are developed in order to gain assurance that the effects that AI systems have on the world are safe.</p><p> To exert control over AI systems&#39; effects on the world, we need to act on the causal chain that leads to them.</p><p> We have developed a framework for auditing that centers on this causal chain in &#39; <a href="https://www.apolloresearch.ai/research/causal-framework-ai-auditing">A Causal Framework for AI Regulation and Auditing&#39; (Sharkey et al., 2023)</a> . For full definitions of each step, see the Framework. Here, we briefly describe what auditors could concretely do at each step in the chain. Later, we&#39;ll examine the theory of change of those actions. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LwJwDNFhjurAKFiJm/tkifirr7almgikjyicip"><figcaption> <i>The causal chain leading to AI systems&#39; effect on the world, as presented in</i> <a href="https://www.apolloresearch.ai/research/causal-framework-ai-auditing"><i>Sharkey et al. (2023)</i></a> <i>.</i></figcaption></figure><h2> Affordances available to AI systems</h2><ul><li> <strong>Definition</strong> : The environmental resources and opportunities for influencing the world that are available to an AI system. They define which capabilities an AI system has the opportunity to express in its current situation.</li><li> <strong>What auditors can do</strong> : For each proposed change in the affordances available to an AI system (such as deployment of the AI system to the public, to researchers, or internally; giving the AI system access to the internet or to tools; open sourcing a AI system), auditors can perform risk assessments to get assurances that the change is safe. They can also ensure that AI systems have sufficient guardrails to constrain the affordances available to them.</li></ul><h2> Absolute capabilities and propensities of AI systems</h2><ul><li> <strong>Definition</strong> : The full set of potential capabilities of an AI system and its tendency to use them.</li><li> <strong>What auditors can do</strong> : Auditors can perform AI system evaluations to assess the dangerous capabilities and propensities of AI systems. They can do this during or after training. They may perform gain of function research in order to determine the risks that AI systems may pose when they are deployed broadly or if they proliferate through exfiltration. Auditors can also perform risk assessments prior to experiments that would give AI systems additional capabilities or change their propensities. Auditors can also be involved in ensuring that there exist adequate action plans in the event of concerning AI system evaluations.</li></ul><h2> Mechanistic structure of the AI system during and after training</h2><ul><li> <strong>Definition</strong> : The structure of the function that the AI system implements, comprising architecture, parameters, and inputs.</li><li> <strong>What auditors can do</strong> : Auditors can perform research to incorporate interpretability into AI system evaluations (both capabilities and alignment evaluations) as soon as possible. Such mechanistic explanations give better guarantees about AI system behavior both inside and outside of the evaluation distribution.</li></ul><h2> Learning</h2><ul><li> <strong>Definition</strong> : The processes by which AI systems develop mechanistic structures that are able to exhibit intelligent-seeming behavior.</li><li> <strong>What auditors can do</strong> : Auditors can evaluate risks of AI systems before, during, and after pre-training and fine-tuning training-experiments. Auditors could potentially perform incentive analyses and other assessments to evaluate how AI systems&#39; propensities might change during training. Auditors can help assess the adequacy of input filters of AI systems to help avoid dangerous in-context learning. They can also help filter retrieval databases. Filters for inputs or retrieval databases may help prevent AI systems being taught potentially dangerous capabilities through in-context learning.</li></ul><h2> Effective compute and training data content</h2><ul><li> <strong>Definition</strong> : Effective compute is the product of the amount of compute used during learning and the efficiency of learning; training data content is the content of the data used to train an AI system.</li><li> <strong>What auditors can do</strong> :<ul><li> <strong>Effective compute</strong> : Auditors can help to ensure that labs are compliant with compute controls, if they are in place. Auditors can also conduct risk assessments concerning the scaling up of AI systems, perhaps based on evaluations of smaller AI systems in the same class. Open publication of algorithmic efficiencies may lead to proliferation of effective compute; being technically informed independent experts, auditors could help regulators assess whether certain dual-use scientific results should be made publicly available.</li><li> <strong>Training data content</strong> : Auditors can ensure that training data don&#39;t contain potentially dangerous or sensitive content.</li></ul></li></ul><h2> Security</h2><ul><li> <strong>Definition</strong> :<ul><li> <strong>Security from attackers</strong> : Information security, physical security, and incident response protocols in the organizations developing and hosting AI systems.</li><li> <strong>Preventing misuse of AI systems from AI system vulnerabilities</strong> : Resistance of AI systems to prompt injection attacks, jailbreaking, and malicious use.</li></ul></li><li> <strong>What auditors can do</strong> :<ul><li> <strong>Security from attackers</strong> : Auditors can evaluate and test the security of organizations interacting with AI systems and the computer systems they run on. They can help ensure compliance with information security standards through reviews and perform red-teaming. Given the security requirements of a potentially strategically valuable dual-use technology, military-grade security, espionage protection, and penetration testing may be required. Maximal security necessitates government involvement in security audits. Auditors can also assess that actors with access to AI systems have appropriate levels of access and no more (eg through assessing API security or know-your-customer protocols). Auditors may also be involved in research efforts that develop security-relevant infrastructure such as structured access APIs or hardware that ensures compliance with compute regulations and safety standards. Furthermore, they can assess the adequacy of institutions&#39; incident response plans and whistleblower protections.</li><li> <strong>Preventing misuse of AI systems through AI system vulnerabilities</strong> : Auditors can help assess the adequacy of AI systems&#39; (and filters&#39;) resistance to prompt injection, jailbreaking, or malicious use through red-teaming to identify vulnerabilities. Auditors can work with other actors to establish bug bounties for finding and reporting vulnerabilities and dangerous capabilities.</li></ul></li></ul><h2> Deployment design</h2><ul><li> <strong>Definition</strong> : Deployment designs are the plans made for deploying certain AI systems. They determine who has access?; when do they get access?; and what do they have access to?</li><li> <strong>What auditors can do</strong> : Auditors can assess risks from different modes of deployment for each AI system to be deployed and ensure that any regulation regarding deployment is upheld.</li></ul><h2> Training-experiment design</h2><ul><li> <strong>Definition</strong> : A training-experiment is the technical procedure by which an AI system is developed. Design decisions for the training-experiment include data selection and filtering; model architecture and hyperparameters; choice of deep learning framework; hardware choices; the amount of compute that will be used; the algorithms used; evaluation procedures; safety procedures; the affordances made available to the AI system during training; the properties of different phases of pre-training and fine-tuning; whether to train online or offline; etc.</li><li> <strong>What auditors can do</strong> : Auditors can perform risk assessments on the design decisions for training-experiments. These may be performed prior to training, fine-tuning, or inference (as applicable to the experiment). Auditors can also be involved in assessing the adequacy of labs&#39; alignment plans to ensure they are in line with public safety.</li></ul><h2> Governance and institutions</h2><ul><li> <strong>Definition</strong> : The governance landscape in which including AI training-experiment, deployment, and security decisions are made, including institutions, regulations, and norms.</li><li> <strong>What auditors can do</strong> : Auditors can map the roles and responsibilities of different actors involved in frontier AI development, assess the adequacy of incentive structures, and make recommendations to regulators regarding governance landscape structure.</li></ul><h2> Miscellaneous roles</h2><p> Beyond roles of auditors relating directly to the above causal chain, additional general functions of auditors include:</p><ul><li> <strong>Establish technical standards and guidelines</strong> : Working together, auditors and labs may be better placed to establish safety-oriented standards and guidelines for deployment or training-experiment design than either party alone. This is partly because external auditors don&#39;t have a direct profit incentive to further AI progress as fast as possible and are thus relatively more incentivised toward safety than eg frontier AI labs. Furthermore, external auditors have insights into many different AI efforts, whereas labs typically have access only to their own. Auditors may therefore be able to provide a more holistic picture.</li><li> <strong>Education and outreach</strong> : The technical expertise of external auditors can be used to assist policymakers, researchers in capabilities labs, and the general public. For instance, they could inform policy makers on risks from particular dangerous capabilities or developers how to build agents with protective guardrails.</li><li> <strong>Research</strong> : Because AI systems, institutions, practices, and other factors are continuously changing, auditors may need to constantly research new methods to gain assurances of safety.</li></ul><p> It seems desirable that different auditing organizations specialize in different functions. For instance, security audits may best be handled by cybersecurity firms or even intelligence agencies. However, it is important for safety that auditing tasks are done by multiple actors simultaneously to reduce risks as much as possible.</p><h1> Theory of Change</h1><p> Different kinds of audits could examine different parts of the causal chain leading to AI systems&#39; effects on the world. We identify five categories of audits: 1) AI system evaluations; 2) Training-experiment design audits; 3) Deployment audits; 4) Security audits; and 5) Governance audits. Each category of audit has different theories of change:</p><h2> 1) AI system evaluations</h2><p> AI system evaluations look at behaviors expressed by the AI system; capabilities and propensities of AI systems (during and after training); the mechanistic structure of AI systems; and what the AI system has learned and can learn.</p><p> We assess AI system evaluations as having direct effects; indirect effects on safety research; and indirect effects on AI governance.</p><p> <strong>Direct effects</strong> : If successful, AI system evaluations would identify misaligned systems and systems with dangerous capabilities, thus helping to reduce the risk that such systems would be given affordances that let them have damaging effects on the world (eg deployment). Notably, audits do not need to be 100% successful to be worthwhile; finding some, even if not all, flaws already decreases risk (though see section Limits of auditing). Beyond behavioral AI system evaluations, Apollo Research also performs interpretability research in order to improve evaluations in future. Interpretability also has <a href="https://www.lesswrong.com/posts/uK6sQCNMw8WKzJeCQ/a-longlist-of-theories-of-impact-for-interpretability">additional theories of change</a> .</p><p> <strong>Indirect effects on safety research</strong> : Adequate AI system evaluations would convert alignment from a &#39;single-shot&#39; problem into a &#39;many-shot&#39; problem. In a world without extensive evaluations, there is a higher chance that a frontier AI lab deploys a misaligned AI system without realizing it and thus causes an accident, potentially a catastrophic one. In this case, the first “shot” has to be successful. By contrast, in a world with effective evaluations, labs can catch misaligned AI systems during training or before deployment; we would therefore get multiple “shots” at successfully aligning frontier AI AI systems. For instance, reliable AI system evaluations may give us evidence if any specific alignment technique succeeds in reducing a AI systems&#39; propensity to be deceptive. This would have important implications for the tractability of the alignment problem, since it would enable us to gather empirical evidence about the successes or failures of alignment techniques in dangerous AI systems without undue risk. Ultimately, successful AI system evaluations would let us iteratively solve the alignment problem like we would most other scientific or engineering problems.</p><p> <strong>Indirect effects on AI governance</strong> : AI system evaluations could provide compelling empirical evidence of AI system misalignment &#39;in the wild&#39; in a way that is convincing to AI system developers, policymakers, and the general public. For example, AI system evaluations could be used to demonstrate that an AI system has superhuman hacking capabilities or is able to manipulate its users to gather relevant amounts of money. Such demonstrations could encourage these stakeholders to understand the gravity of the alignment problem and may convince them to propose regulation mandating safety measures or generally slowing down AI progress. Auditors likely have a good understanding of what frontier AI systems are capable of and can use their more neutral position to inform regulators.</p><p> <strong>Indirect effects on distribution of AI benefits</strong> : In order to reap the potential benefits from AI, it must be (safely) deployed. Assuming audits can be done effectively, auditing derisks investments, potentially leading to more investments in the area and thus greater benefits. By catching failures before they happen, auditing may be able to avoid accident scenarios, which have harmed public confidence in nuclear technology. Effective audits may also increase public trust in the technology, leading to wider spread use.</p><h2> 2) Training-experiment design audits</h2><p> AI system development audits look at effective compute, training data content, and training-experiment design decisions. They also look at the design of AI system training-experiments, which help determine the previous factors.</p><p> The primary means of impact of AI system development audits is that they reduce the risk of dangerous AI systems coming into existence in the first place and reduce the danger posed by AI systems. They aim to achieve this by controlling which capabilities AI systems have (to avoid dangerous ones), the extent of their capabilities, and their propensities to use dangerous capabilities. By embedding safety into the AI system development process, AI system development audits may help place safety at the center of labs&#39; work rather than as an afterthought to increasing capabilities.</p><h2> 3) Deployment audits</h2><p> Deployment audits concern proposals for the deployment of particular AI systems.</p><p> The overall means of impact is that they should prevent systems from being deployed in ways that contravene regulations or that are deemed too risky. Note that these pathways are separate from AI system evaluations. The results of AI system evaluations should inform risk assessments in deployment audits. They should aim to assess risks from giving particular kinds of AI system access (eg access to inference; access to fine-tuning; access to weights) to particular kinds of people (eg deployment to the public; internal deployment; deployment in certain countries). They should also assess risks from making particular kinds of affordances available to AI systems, for instance internet access or access to particular kinds of software.</p><p> Deployment audits aim to ensure that AI systems are not intentionally given excessive available affordances; by contrast, security audits aim to reduce the risk that they are given excessive available affordances unintentionally.</p><h2> 4) Security audits</h2><p> Security audits assess the security of AI systems and the security of the organizations developing, hosting, and interacting with them. The overall purpose is to limit the affordances made available to highly capable AI systems unintentionally, thus reducing accident and misuse risks, both of which are extremely important for such a transformative and dual-use technology. They reduce the risk of AI system proliferation either through accidental leaks or exfiltration, either by internal or external actors. By assessing how well AI systems have been &#39;boxed&#39;, they also reduce the risk of AI systems exfiltrating themselves. They also aim to assess the adequacy of damage control measures in the event of security or safety failures.</p><h2> 5) Governance audits</h2><p> Governance audits look at the structure of the institutions developing, regulating, and auditing AI systems (and the interactions between those institutions) to ensure that they are conducive to safety.</p><p> They aim to ensure that organizations have proper mechanisms in place to make informed, ethical, and responsible decisions regarding the development and deployment of AI systems. While other audits aim to ensure that AI systems are aligned or that they&#39;re used for aligned purposes, governance audits aim to ensure that alignment with human values extends to the institutions wielding and managing these AI systems. Their path to impact is that they can identify problems in the governance landscape, thus making it possible to rectify them.</p><h2> Theories of change for <i>auditors in general</i></h2><p> In addition to theories of change for each individual category of audit, there are also multiple theories of change for auditing in general:</p><ol><li> <strong>Buying time for safety research</strong> : Auditing might delay the deployment of existing AI systems and potentially prevent or delay the beginning of training of new ones. This could lead to more time for other alignment research. This would buy time for research that is applicable to more and more capable AI systems.</li><li> <strong>Instilling safety norms in AI development</strong> : If an AI lab knows that they&#39;re going to be audited and potentially pay a cost (financial, reputational, or otherwise) if they fail the audit, they might be more incentivised to instill stronger safety norms and be more cautious around training and deploying new AI systems. Potentially, the existence of auditors alone may already increase safety slightly.</li><li> <strong>Public messaging about safety risks</strong> : Companies choosing to or being required to be audited sends a clear message that this technology is potentially dangerous.</li></ol><h2> Theories of change for <i>external auditors in particular</i></h2><p> External auditors, as opposed to internal auditors at the labs developing frontier AI, have additional pathways to impact:</p><ol><li> <strong>Incentives are more aligned with the public benefit</strong> : External auditors are more independent than lab-internal audits and have less conflicting incentives (although there are some perverse incentives, which we hope to discuss in a future post). Even when labs are well-intentioned, social dynamics might reduce the efficacy of internal audits. For example, internal auditors may show anticipatory obedience or be more lenient because they don&#39;t want to be perceived as slowing down their colleagues.</li><li> <strong>Defense in depth</strong> : Multiple independent audits help reduce the probability of failure. In general, the more uncorrelated methods of risk reduction we can use on the problem the better.</li><li> <strong>Subsidizing research</strong> : Depending on the funding landscape for AI auditing, if the auditing industry is profitable then profits can be used to fund research on improved audits and other alignment research. Since audits are their primary purpose, external auditors have a greater incentive to conduct such research relative to capabilities compared with labs developing frontier AI.</li><li> <strong>Increasing transparency</strong> : External auditors can potentially be more transparent about their own governance or their standards when auditing than lab-internal auditors. For instance, external auditors may be able to publish general details of their auditing process and methods which larger labs, perceiving themselves to be in a greater competition with other labs, may not be incentivised or feel able to do.</li><li> <strong>Sharing expertise and tools</strong> : Independent organizations, such as auditors and regulators, can pool best practices, standards, expertise, and tests across different centers of expertise. Due to competition and antitrust concerns, each lab&#39;s internal auditing team can likely only work with their own AI systems while an external auditor can get a bird&#39;s eye view and gets significantly more experience from working with AI systems of multiple labs. Furthermore, an external organization can specialize in AI auditing and thus build scalable tools that can then be applied to many AI systems. Additionally, if auditors summarize and share (nonsensitive) safety-relevant information between labs, it will likely disincentivize race dynamics by drawing attention to common safety issues and making it apparent to labs that others aren&#39;t racing ahead irresponsibly.</li><li> <strong>Monitoring behaviors across labs</strong> : Since external auditors may interact with multiple labs, they can compare the safety culture and norms between them. In case a lab has an irresponsible safety culture, this can be flagged with that lab&#39;s leadership and regulators.</li><li> <strong>Collaboration with regulators</strong> : A healthy auditing ecosystem with multiple competent auditors can assist regulators with technical expertise and allows regulations and standards to be quickly designed and implemented</li><li> <strong>Lobbying for good regulation</strong> : An external auditor is also an independently interested player in pushing for and setting regulation on labs and for policy work while internal audit teams are likely to be much more controlled by the policy interests of their host labs. This comes with risks, too: A potential incentive of an auditing organization is to lobby for more regulation rather than good regulation. We think currently, however, there is a large undersupply of regulation in AI and so this is likely to be a net positive for the foreseeable future.</li><li> <strong>Information sharing</strong> : Trusted external auditors can get a bird&#39;s eye view of progress, risks and good practices across AI labs. If they summarize and share (nonsensitive) parts of this publicly, it will likely disincentivize race dynamics by drawing attention to common safety issues.</li></ol><h1> Limits of auditing</h1><p> We are aware of some of the limits of AI auditing, as well as the perverse incentives of auditing organizations that could both serve to reduce the positive impact that auditing efforts might have.</p><ol><li> <strong>False confidence and safety-washing</strong> : It is possible that audits may be net-negative by providing false confidence in the safety of AI systems. This may be due to accidental misjudgement about the extent of the assurance that particular evaluations can provide. False confidence may also arise due to frontier AI developers intentionally using audits as fig leaves for the risks posed by AI systems, ie safety-washing. We believe that by careful communication from auditors and improving evaluation methods (eg interpretability), these risks can be minimized and auditing will be strongly net positive. Licensing of auditors may also mitigate the risk of lax auditors awarding undeserved seals of approval.</li><li> <strong>Using auditors as excuses to absolve labs from safety responsibilities</strong> : One plausible outcome of auditing is that labs may feel licensed to neglect their duties from doing their own safety work. In the event of accidents, they may be able to use auditors as legal shields to protect themselves from liability. The very existence of auditors may make labs feel like they need to do less work on making their AI systems safe, since they can rely on auditors to catch issues. Establishing where responsibility and liability should fall will require more consideration.</li><li> <strong>No strong guarantees for behavioral AI system evaluations</strong> : Current AI system evaluation methods are primarily behavioral because existing interpretability tools are very limited. Therefore, it seems that, at best, auditing methods can currently only prove the presence of dangerous capabilities rather than their absence. As such, current audits cannot make strong guarantees of safety beyond probabilistic statements about how hard it is to elicit specific behaviors. With more research and understanding of how deep networks function internally, it may be possible to get stronger guarantees.</li><li> <strong>Goodhart&#39;s law</strong> : When auditors use a range of tests to ensure an AI system&#39;s safety, these tests themselves become a target, ie either directly or indirectly labs will train their AI systems to pass these tests. This can be partly mitigated by withholding information about some audits from auditees.</li><li> <strong>Overfitting to audits</strong> : Even without directly training on audits, there is a natural selection process where the AI systems that pass all tests are potentially especially competent at deception and thus more dangerous. Hopefully, extensive and robust AI system evaluation suites will be able to reduce this problem but, in principle, this evolutionary process will always remain.</li><li> <strong>Limited constructive solutions at present</strong> : Until the state of AI system evaluations research improves, AI auditors likely won&#39;t be able to provide solutions to problems concerning the safety of AI systems, ie they can say that a AI system should not be deployed because it has demonstrated unsafe properties, but they can&#39;t immediately tell the lab how to solve that problem. However, we think good auditing likely requires an understanding of the processes that generated the problem. Thus, we expect that auditors may eventually be able to provide constructive recommendations.</li><li> <strong>Audit recommendations need authority</strong> : For auditing to be effective, it is necessary that the recommendations of auditors have the ability to meaningfully stop a AI system from being deployed in case they find evidence of dangerous capabilities. Currently, auditors can only make non-binding recommendations and the frontier AI labs ultimately decide whether to act on them or not. In the long run, when more capable AI systems can produce catastrophically bad outcomes, regulators (acting on the recommendations of auditors) should have the ability to enforce compliance of safety standards in labs.</li><li> <strong>Perverse incentives</strong> : Auditing as a field has perverse incentives that can distort and manipulate the auditing process. For example, if auditing organizations depend on a few major customers (which is likely the case for frontier AI risks since there are only a handful of leading labs), there is a clear incentive to become sycophantic to these labs out of fear that they lose a large chunk of their revenue. Similar dynamics could be seen in the financial auditing industry before the 2008 financial crisis. We believe that this problem can largely be mitigated by auditing regimes where labs do not choose their auditors, but instead regulators do.</li></ol><h1> Assumptions for impact of auditing</h1><p> Our theory of change makes some assumptions about AI threat models and how the future is likely to play out. If these assumptions are incorrect, then it is not clear that auditing will be a good marginal investment of talent and time, or else the auditing strategy will have to change significantly:</p><ol><li> <strong>Regulations demand external, independent audits</strong> : Currently we see that there is general goodwill inside leading frontier AI labs towards AI safety audits. As AI systems become more capable and risky, they both become potentially more profitable to deploy while simultaneously becoming potentially riskier. This establishes a basis for friction between frontier AI labs, who are more strongly incentivised to deploy, and auditors, who are more incentivised to mitigate risks. In the long term, if frontier AI labs get to choose their own auditors, then incentives drive a race to the bottom in terms of auditing costs, which by proxy means a race to the bottom in terms of safety. This race to the bottom can mostly be avoided by ensuring that frontier AI labs are not responsible for selecting their own auditors. It may also be mitigated through consensus on auditing standards and auditing regulations that are enforced.</li><li> <strong>Regulations demand actions following concerning evaluations</strong> : If the recommendations of auditors don&#39;t lead to interventions that improve safety, there is not much point in doing audits. To avoid uncooperative frontier AI development labs proceeding unsafely, auditing should have regulatory backing and there should be specific interventions that are enacted following particular evaluation results.</li><li> <strong>Prosaic AI alignment is possible</strong> : The path to impact of auditing assumes that working with current AI systems, detecting and evaluating their failure modes, and pursuing research directions such as interpretability and human preference-learning for large AI systems are productive and useful directions to solve alignment. If there is either some fundamental impossibility to align frontier AI or there are large, sudden, unpredictable jumps in capabilities that yield AI systems that can fool all auditing techniques at once, then auditing will not be effective.</li><li> <strong>Auditing is not prohibitively expensive</strong> : First, if auditing turns out to be expensive and slow, then, unless forced to by regulation, most frontier AI labs are unlikely to engage in the practice in a meaningful way. In the long run, we expect that auditing and AI system evaluations will have to be very extensive but it is worth paying the cost because the AI will be deployed in large parts of the economy. Second, we suspect future AI systems might have much better online learning capabilities. This means that, in addition to audits before deployment, we might also have to regularly audit AIs during deployment. If the changes in capabilities between deployment audits are too drastic and fast, auditing can&#39;t provide a practical solution. Third, auditing organizations need to be sufficiently well resourced in order to carry out their audits, including potentially to pay legal costs surrounding safety audits that are controversial with AI development companies. Overall, to address this concern, we suggest that safety-aligned auditor funding mechanisms be an urgent policy research area.</li><li> <strong>There is a safe environment for developing AI systems prior to auditing</strong> : If audits only occur once the base model has been trained, then for audits to be effective it would need to be the case that the AI system cannot exfiltrate itself during the training process.</li><li> <strong>Relatively centralized access to AI system</strong> : If the most powerful AI systems can only be created by a handful of organizations, auditing them is relatively easy. In a world where everyone can train their own AI systems or strongly modify existing AI systems with little effort, it will be much harder (but not impossible) to effectively audit all of them. Preventing catastrophic risk in such a world will likely require very strong regulatory backing.</li><li> <strong>Progress in interpretability</strong> : We think good interpretability tools would allow us to make much stronger statements about the safety of AI systems because they give us a better understanding of the internal reasons for a given behavior. However, current interpretability tools seem insufficient to allow for the needed level of explainability for convincing guarantees of safety. More progress is needed, which is why Apollo Research is investing in fundamental interpretability research.</li><li> <strong>We do not train against the audits</strong> : If all AI system evaluations are made public, then there might be pressure to directly train or indirectly optimize (ie through selection effects) AI systems to pass audits, even though they could still be unsafe. Potential solutions would be to keep &#39;test sets&#39; of AI system evaluations that are not known to AI system developers. We would not want to use these test sets frequently, since frequent use may establish another optimization process from population-level selection effects.</li></ol><h1> Contributions</h1><p> Lee Sharkey led the project and edited the final version. Marius Hobbhahn contributed significantly to all parts other than “The roles of auditors in AI” section. Beren Millidge contributed to an early draft of the post. Dan Braun, Jeremy Scheurer, Mikita Balesni, Lucius Bushnaq, Charlotte Stix, and Clíodhna Ní Ghuidhir provided feedback and discussion.<br><br></p><br/><br/> <a href="https://www.lesswrong.com/posts/LwJwDNFhjurAKFiJm/theories-of-change-for-ai-auditing#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/LwJwDNFhjurAKFiJm/theories-of-change-for-ai-auditing<guid ispermalink="false"> LwJwDNFhjurAKFiJm</guid><dc:creator><![CDATA[Lee Sharkey]]></dc:creator><pubDate> Mon, 13 Nov 2023 19:33:43 GMT</pubDate> </item><item><title><![CDATA[They are made of repeating patterns]]></title><description><![CDATA[Published on November 13, 2023 6:17 PM GMT<br/><br/><p> <i>Epistemis status: an obvious parody.</i></p><p> — You won&#39;t believe me. I&#39;ve found them.</p><p> — Whom?</p><p> — Remember that famous discovery by Professor Prgh&#39;zhyne about pockets of baryonic matter in open systems that minimize the production of entropy within them? They went further and claimed that goal-oriented systems could emerge within these pockets. Crazy idea, but... it seems I&#39;ve found them near this yellow dwarf!</p><p> — You&#39;re kidding. We know that a good optimizer of outcomes over systems&#39; states should have a model of the system inside of itself. We have entire computable universes within ourselves and still barely make sense of this chaos. How can they fit valuable knowledge inside tiny sequences of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="10^{23}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">10</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">23</span></span></span></span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>atoms?</p><p> — They repeat patterns of behavior. They have multiple encodings of them and slightly change them over time in response to environmental changes in a simple mechanistic way.</p><p> — But that generalizes horribly!</p><p> — Indeed. When a pattern interacts with a new aspect of the environment, it degrades with high probability. Their first mechanism for generating patterns was basically &quot;throw a bunch of random numbers in the environment, keep those that survived, slightly change, repeat&quot;.</p><p> — ...</p><p> — Yeah, it&#39;s horrible from their perspective, I think.</p><p> — How do they exist without an agent-environment boundary? I&#39;d be pretty worried if some piece of baryonic matter could smash into my thoughts at any moment.</p><p> — They kind of pretend they have an agent-environment boundary, using lipid layers.</p><p> — Those &quot;lipid layers&quot; have such strong bonds that they don&#39;t let any piece of matter inside? That&#39;s impressive!</p><p> — No, I was serious about them pretending. They need to pass matter through themselves; they&#39;re open systems and can&#39;t survive without external sources of free energy. They usually have specialized members of their population, an &quot;immune system&quot;, that checks for alien patterns.</p><p> — Like we check for signatures of malign hypotheses in the universal prior?</p><p> — No, there&#39;s not enough computing power. They just memorize a bazillion meaningless patterns, and the immune system kills everyone who can&#39;t recite them.</p><p> — WHAT? But what if the patterns are corrupted, as happens in the world of baryonic matter?</p><p> — You can guess: if your memory of the patterns is corrupted, you&#39;re dead.</p><p> — What if the reference pattern of immune system gets corrupted?</p><p> — Then the immune system starts to kill indiscriminately.</p><p> — Okay, I&#39;m depressed now. But what should we do with them? Could they become dangerous?</p><p> — ...I don&#39;t really think so? If we converted all baryonic matter into something like the most complex members of their population, it might be worrying. But there&#39;s no way they can get here on their own. See, they become less agentic as they organize into complex structures; too much agency destroys them. They need to snipe out their most active members.</p><p> — Well, that&#39;s still icky. Remember that famous example — the Giant Look-Up Policy Table generated from an evaporating black hole? Would we consider it agentic if it displayed seemingly agentic behavior?</p><p> — Heh, obviously not. Agents like us exist for ontological reasons—if we want to exist, we rearrange realityfluid in a way that makes us more encounterable in the multiverse. If something is not created by agency, it&#39;s not agentic.</p><br/><br/> <a href="https://www.lesswrong.com/posts/xCPcn8cjjeC6PnB5z/they-are-made-of-repeating-patterns#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/xCPcn8cjjeC6PnB5z/they-are-made-of-repeating-patterns<guid ispermalink="false"> xCPcn8cjjeC6PnB5z</guid><dc:creator><![CDATA[quetzal_rainbow]]></dc:creator><pubDate> Mon, 13 Nov 2023 18:17:44 GMT</pubDate></item></channel></rss>