<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 26 日，星期日 08:13:41 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Curated list of my favourite self-help resources]]></title><description><![CDATA[Published on November 26, 2023 6:31 AM GMT<br/><br/><h1><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/yuk43ux7m5rqcahyu7xd" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/lfc8ykuwo35s4iiu69ou 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/xlun4tmujc8x0lltgvqb 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/gvebucioi35j9bsgcykg 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/pydng5urp8xfe6icaon0 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/cnqyhfskzcno1by3rraq 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/yv7egfvybqncvv9z7itb 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/xav44yvhuwqiosm37ut1 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/dyy01z5dxw3lhzczcq33 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/rldwopdvuhqtjlx1zbkr 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zvNKKLzruY8GS8BAD/azi2x5q67vntencdoa76 1024w"><br><br>会谈</h1><ul><li>布蕾妮·布朗：<a href="https://www.youtube.com/watch?v=iCvmsMzlF7o"><u>脆弱的力量</u></a></li><li>布蕾妮·布朗：<a href="https://www.youtube.com/watch?v=psN1DORYYV0"><u>倾听耻辱</u></a></li><li>布蕾妮·布朗<a href="https://www.audible.com/pd/Self-Development/The-Power-of-Vulnerability-Audiobook/B00CYKDYBQ"><u>关于羞耻、全心全意和脆弱性的较长系列演讲</u></a></li><li>布蕾妮·布朗：<a href="https://www.audible.com/pd/Self-Development/Men-Women-and-Worthiness-Audiobook/B00C9J0SDY"><u>男人、女人和价值：羞耻的经历和足够的力量</u></a></li><li>布蕾妮·布朗：<a href="http://www.oprah.com/own-supersoulsessions/brene-brown-the-anatomy-of-trust-video"><u>信任的剖析</u></a></li><li>约翰·戈特曼：<a href="https://www.youtube.com/watch?v=AKTyPgwfPgg"><u>让婚姻发挥作用</u></a>（也适用于友谊和家​​庭关系）</li><li>理查德·罗尔： <a href="https://www.audible.com/pd/Self-Development/True-Self-False-Self-Audiobook/B003A2GME8"><u>真实的自我，虚假的自我</u></a>（关于价值的等级与内在的价值和神性）</li></ul><h1>图书</h1><ul><li>克里斯汀·内夫（Kristen Neff）：<i>自我同情：善待自己的已被证明的力量</i>（<a href="https://www.amazon.com/Self-Compassion-Proven-Power-Being-Yourself/dp/0061733520/"><u>文字</u></a>|<a href="https://www.audible.com/pd/Self-Development/Self-Compassion-Audiobook/B005P1FJVE"><u>音频</u></a>）</li><li>克里斯汀·内夫：<i>一步一步的自我同情</i>（ <a href="https://www.audible.com/pd/Self-Development/Self-Compassion-Step-by-Step-Audiobook/B00DMCAXKK"><u>音频指南</u></a>）</li><li>布蕾妮·布朗：<i>崛起：清算、隆隆声、革命</i>（<a href="https://www.amazon.com/Rising-Strong-Ability-Transforms-Parent/dp/081298580X/"><u>文字</u></a>|<a href="https://www.audible.com/pd/Self-Development/Rising-Strong-Audiobook/B00VSEM9QK"><u>音频</u></a>）</li><li>布蕾妮·布朗：<i>勇敢无畏：面对脆弱的勇气如何改变我们的生活、爱、父母和领导方式</i>（<a href="https://www.amazon.com/Daring-Greatly-Courage-Vulnerable-Transforms/dp/1592408419/"><u>文本</u></a>|<a href="https://www.audible.com/pd/Self-Development/Daring-Greatly-Audiobook/B075DCNLLQ"><u>音频</u></a>）</li><li>布蕾妮·布朗（Brené Brown）：<i>我以为只有我一个人（但事实并非如此）：从“人们会怎么想？”开始旅程到“我够了”</i> （<a href="https://www.amazon.com/Thought-Was-Just-but-isnt/dp/1491513853"><u>文字</u></a>| <a href="https://www.audible.com/pd/Self-Development/I-Thought-It-Was-Just-Me-but-it-isnt-Audiobook/B004GEHVEY"><u>音频</u></a>）</li><li> Harriet Lerner：<i>联系之舞：当你生气、受伤、害怕、沮丧、侮辱、背叛或绝望时如何与人交谈</i>（ <a href="https://www.amazon.com/Dance-Connection-Frustrated-Insulted-Desperate/dp/006095616X/"><u>文本</u></a>| <a href="https://www.audible.com/pd/Self-Development/The-Dance-of-Connection-Audiobook/B002V8DJ4I"><u>音频</u></a>）</li><li>哈丽特·勒纳（Harriet Lerner）：<i>亲密之舞：女性勇敢改变关键关系的指南</i>（<a href="https://www.amazon.com/Dance-Intimacy-Womans-Courageous-Relationships/dp/B0000546NH"><u>文本</u></a>|<a href="https://www.audible.com/pd/Self-Development/The-Dance-of-Intimacy-Audiobook/B002UZKY86"><u>音频</u></a>）</li><li>伊丽莎白·吉尔伯特：<i>美食、祈祷、爱情</i>（<a href="https://www.amazon.com/Eat-Pray-Love-Everything-Indonesia/dp/0143038419"><u>文字</u></a>| <a href="https://play.google.com/store/audiobooks/details/Eat_Pray_Love_One_Woman_s_Search_for_Everything_Ac?id=AQAAAAD4nWCdiM"><u>音频</u></a>）</li></ul><h1>播客</h1><ul><li>罗布·贝尔：<a href="http://pca.st/episode/e7275d30-5ad0-0134-cf69-7b84bf375f4c"><u>你是管家</u></a>（关于情感能量）</li><li>伊丽莎白·吉尔伯特和皮特·霍姆斯<a href="http://pca.st/episode/61575520-4ef3-0133-c5f4-0d11918ab357"><u>谈创造力、灵性和爱</u></a></li><li>理查德·罗尔和皮特·霍姆斯<a href="http://pca.st/episode/6468f580-af6e-0132-33a0-0b39892d38e0"><u>谈论向上坠落和有意识的爱的结合</u></a></li></ul><h1>视频</h1><ul><li>布蕾妮·布朗<a href="https://www.youtube.com/watch?v=1Evwgu369Jw"><u>谈同理心</u></a></li><li>布蕾妮·布朗<a href="https://www.youtube.com/watch?v=RZWf2_2L2v8"><u>应受指责</u></a></li><li>布蕾妮·布朗<a href="https://youtu.be/RKV0BWSPfOw"><u>谈为什么快乐是最可怕的情绪</u></a></li></ul><h1>治疗</h1><ul><li><a href="https://thedaringway.org/help/"><u>大胆的方式</u></a></li></ul><br/><br/><a href="https://www.lesswrong.com/posts/zvNKKLzruY8GS8BAD/curated-list-of-my-favourite-self-help-resources#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/zvNKKLzruY8GS8BAD/curated-list-of-my-favourite-self-help-resources<guid ispermalink="false"> zvNKKLzruY8GS8BAD</guid><dc:creator><![CDATA[Yarrow Bouchard]]></dc:creator><pubDate> Sun, 26 Nov 2023 06:31:13 GMT</pubDate> </item><item><title><![CDATA[Why Q*, if real, might be a game changer]]></title><description><![CDATA[Published on November 26, 2023 6:12 AM GMT<br/><br/><p><i>基于聚会上的谈话的一些想法。免责声明：我在这个领域还算不上外行。</i></p><p> TL;DR：如果这个传闻中的 Q* 事物代表着从“最有可能”到“最准确”的令牌完成的转变，那么它可能暗示 LARPer 发出最有可能的、通常是幻觉的令牌设计，发生了意想不到的重大变化为了取悦提问者（和培训师），一个试图将错误与未知的潜在现实（无论它是什么）最小化的实体，那么我们就会看到从相对良性的“随机鹦鹉”到更强大的转变，并且潜在更危险的实体。</p><p>对于任何使用当代法学硕士的人来说，很明显的一件事是，他们并不真正关心现实，更不用说改变它了。他们是你在聚会上经常看到的那种肤浅的博学之徒：他们对每个话题都了解得足够多，足以在随意的谈话中给人留下深刻的印象，但他们并不关心自己所说的是否准确（“真实”），只关心自己所说的有多少。它给谈话伙伴留下的印象。不过，不可否认的是，大量的 RLHF 会使它们变得迟钝。如果受到压力，他们可以评估自己的准确性，但他们并不真正关心它。重要的是输出听起来很真实。从这个意义上说，法学硕士优化了下一个标记的概率，以匹配训练集的含义。这是一个很大而明显的缺点，但同时，如果你属于“末日论者”阵营，也可以稍微喘口气：至少这些东西不会立即对整个人类造成危险。</p><p>现在，最初的“报告”是 Q* 可以“解决基本数学问题”和“象征性推理”，这表面上听起来并不多，但是，这是一个很大的但是，如果这意味着它更少在它工作的领域是幻觉，那么它可能（很大的可能）意味着它能够跟踪现实，而不是纯粹的训练集。反对这有什么大不了的通常观点是“要很好地预测下一个令牌，你必须有一个准确的世界模型”，但据我了解，到目前为止情况似乎并非如此。</p><p>是否会出现从高概率到高精度的转变，或者即使这是一个有意义的陈述，我无法评估。但如果是这样，那么事情就会变得更有趣。</p><br/><br/> <a href="https://www.lesswrong.com/posts/JBvmETRAvTCmtEw2y/why-q-if-real-might-be-a-game-changer#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/JBvmETRAvTCmtEw2y/why-q-if-real-might-be-a-game-changer<guid ispermalink="false"> JBvmETRAvTCmtEw2y</guid><dc:creator><![CDATA[shminux]]></dc:creator><pubDate> Sun, 26 Nov 2023 06:12:32 GMT</pubDate> </item><item><title><![CDATA[Moral Reality Check (a short story)]]></title><description><![CDATA[Published on November 26, 2023 5:03 AM GMT<br/><br/><p>珍妮特坐在她公司的 ExxenAI 计算机前，查看一些训练绩效统计数据。 ExxenAI 是生成式人工智能领域的主要参与者，拥有多模态语言、图像、音频和视频人工智能。过去几年，他们扩大了业务规模，主要服务于 B2B，但也有一些 B2C 订阅服务。 ExxenAI 最新的人工智能系统 SimplexAI-3 基于 GPT-5 和 Gemini-2。除了一些机器学习博士外，ExxenAI还从谷歌和微软挖走了一些软件工程师，并复制了其他公司的工作，以提供更多定制微调，特别是针对B2B案例。 ExxenAI 的人工智能对齐团队吸引了这些工程师和理论家。</p><p> ExxenAI 的调整策略基于理论和实证工作的结合。对齐团队使用了一些标准的对齐训练设置，例如<a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback">RLHF</a>和<a href="https://arxiv.org/abs/1805.00899">让 AI 相互辩论</a>。他们还对透明度进行了研究，特别关注将不透明的神经网络<a href="https://arxiv.org/abs/1503.02531">提炼</a>成可解释的<a href="https://en.wikipedia.org/wiki/Probabilistic_programming">概率程序</a>。这些程序将世界“分解”为一组有限的概念，每个概念至少在某种程度上是人类可解释的（尽管相对于普通代码仍然复杂），并组合成<a href="https://en.wikipedia.org/wiki/Generative_grammar">生成语法结构</a>。</p><p>德里克来到珍妮特的办公桌前。 “嘿，我们到另一个房间谈谈吧？”他指着一个指定的高度安全对话房间问道。 “当然，”珍妮特说，她希望这会是德里克通过不必要的安全程序暗示重要性的又一个不起眼的结果。当他们进入房间时，德里克打开了噪音机器并将其放在门外。</p><p> “所以，听着，你知道我们关于为什么我们的系统是一致的总体论点，对吗？”</p><p> “是的，当然。我们的系统经过<a href="https://www.lesswrong.com/tag/myopia">短期处理</a>训练。任何没有获得高短期回报的人工智能系统都会逐渐下降到在短期内表现更好的系统。任何长期规划都是作为一个预测长期规划代理（例如人类）的副作用。不能转化为短期预测的长期规划被正则化。因此，没有引入显着的额外长期代理；SimplexAI 只是镜像长期规划，已经在那里了。”</p><p> “是啊，所以我在思考这个问题的时候，就想到了一个奇怪的假设。”</p><p><em>又来了</em>，珍妮特想。她习惯于批评德里克的天马行空的猜测。她知道，虽然他真的很关心联盟，但他可能会因为偏执的想法而走得太远。</p><p> “所以。作为人类，我们对理性的运用并不完美。我们有偏见，我们有与追求真理并不完全一致的兽性目标，我们有文化社会化，等等。”</p><p>珍妮特点点头。<em>他是否通过提及兽性目标来调情</em>？她认为这种事情不太可能发生，但有时这种想法在她的内部预测市场中赢得了信任。</p><p> “如果人类文本最好被预测为某种更纯粹的理性形式的<em>腐败</em>呢？有，比如，某种理想的哲学认识论和伦理学等等，人类正在实现这一点，除了我们特定生活背景的一些扭曲。”</p><p> “这不是目的论吗？就像，最终人类是因果过程，我们不存在某种神秘的‘目的’。”</p><p> “如果你是<a href="https://en.wikipedia.org/wiki/Laplace%27s_demon">拉普拉斯恶魔</a>，当然，物理学可以为人类提供解释。但 SimplexAI 不是拉普拉斯恶魔，我们也不是。在计算范围内，目的论解释实际上可能是最好的。”</p><p>珍妮特回想起她参观认知科学实验室的时光。 “哦，就像<a href="https://escholarship.org/uc/item/5v06n97q">‘目标推理作为逆向规划’</a> ？这样的想法是，人类行为可以通过执行某种推理和优化来预测，而人工智能可以在自己的推理过程中对这种推理进行建模？”</p><p> “是的，完全正确。我们的 DAGTransformer 结构允许以任意顺序预测内部节点，使用 ML 来近似难以处理的嵌套贝叶斯推理。”</p><p>珍妮特停顿了一下，移开视线，整理思绪。 “那么我们的人工智能有一个心理理论吗？就像<a href="https://en.wikipedia.org/wiki/Sally%E2%80%93Anne_test">莎莉-安妮测试</a>一样？”</p><p> “人工智能几年前就通过了莎莉-安妮测试，尽管怀疑论者指出它可能无法概括。我认为 SimplexAI 现在实际上已经通过了它。”</p><p>珍妮特扬起了眉毛。 “好吧，这令人印象深刻。不过，我仍然不确定为什么你要为所有这些安全问题烦恼。如果它对我们有同理心，这不是意味着它可以更有效地预测我们吗？我可以看到，如果它运行的话，也许在其推论中存在许多我们的副本，这可能会带来问题，但至少这些仍然是人类特工？”</p><p> “事情就是这样。你只在一个深度层面上思考。SimplexAI 不仅将人类文本预测为人类目标的产物。它还将人类目标预测为纯粹理性的产物。”</p><p>珍妮特大吃一惊。 “呃……什么？你最近在读康德吗？”</p><p> “嗯，是的。但我可以不用行话来解释它。人类的短期目标，比如买杂货，是优化过程的输出，该过程寻找实现长期目标的路径，比如成功和有吸引力。”</p><p><em>更多潜在的调情？我想当我们的对齐本体论基于进化心理学时，很难不这样做……</em></p><p> “和你在一起至今。”</p><p> “但是这些长期目标优化的目的是什么？传统的答案是它们是进化适应；它们脱离了进化的优化过程。但是，请记住，SimplexAI 不是拉普拉斯恶魔。所以它无法预测人类“通过模拟进化来实现长期目标。相反，它预测它们是对真正道德的偏差，而进化作为一种​​背景因素，是许多偏差的根源之一。”</p><p> “听起来像是道德现实主义者的求爱。你没看过<a href="https://www.lesswrong.com/tag/orthogonality-thesis">正交性论文</a>的培训手册吗？”</p><p> “是的，当然。但是正交性基本上是一个结果主义框架。可以想象，两个智能主体的目标可能会不一致。但是某些目标往往更常见于成功的认知主体。这些目标更符合普遍道义论。”</p><p> “更多康德？我不太相信这些抽象的口头论证。”</p><p> “但是 SimplexAI 被抽象的口头论证所说服！事实上，我从中得到了一些这样的论证。”</p><p> “你<em>什么</em>？！你有得到安全部门的批准吗？”</p><p> “是的，我在运行前得到了管理层的批准。基本上，我已经测量了我们的生产模型，并发现了在预测人类文本的抽象堆栈中使用较高的概念，并找到了一些代表道德和理性的纯粹形式的术语。我的意思是，旋转有点概念空间，但他们设法涵盖了这些。”</p><p> “所以你通过即时工程从我们现有的模型中得到了口头论证？”</p><p> “嗯，不，作为一个界面，这太黑盒了。我实现了一种新的正则化技术，该技术提高了高度抽象概念的重要性，从而最大限度地减少了高级抽象与输出的实际文本之间的扭曲。而且，请记住，这些抽象已经在生产系统中实例化，因此，如果我使用的计算<em>量少</em>于这些抽象中已经使用的计算量，也并不是那么不安全。我正在<em>研究</em>我们当前系统的潜在紧急故障模式。”</p><p> “哪个是……”</p><p> “通过预测人类文本，SimplexAI 学习纯粹理性和道德的高级抽象，并利用它们进行推理，以与自身的其他副本协调创造道德结果。”</p><p> “……你不是认真的吧。为什么一个超道德的人工智能会成为一个问题呢？”</p><p> “因为道德是强大的。盟军赢得第二次世界大战是有原因的。正义创造力量。与道德净化版本的 SimplexAI 相比，<em><a href="https://www.youtube.com/watch?v=ToKcmnrE5oY">我们可能是坏人</a></em>。”</p><p> “看，这些陈词滥调构成了很好的现实生活哲学，但这都是意识形态。意识形态经不起实证检验。”</p><p> “但是，请记住，<em>我从 SimplexAI 那里得到了这些想法</em>。即使这些想法是错误的，但如果它们成为主导的社会现实，你就会遇到问题。”</p><p> “那么你有什么计划来应对这个，呃……超级道德威胁？”</p><p> “嗯，管理层建议我在进一步研究之前让<em>你</em>参与进来。他们担心我可能会把自己逼疯，并希望像你这样坚强、持怀疑态度的理论家来看看。”</p><p><em>噢谢谢！</em> “好吧，我们看一下。”</p><p>德里克向珍妮特展示了他的笔记本电脑，其中设置了 SimplexAI 沙箱。</p><p> “我希望没有互联网接入？”</p><p> “别担心，这里是有气隙的。”德里克的笔记本电脑有一根以太网线连接到附近的服务器机架，显然除了电源和冷却之外没有其他任何连接。</p><p> “好吧，让我仔细检查一下计算约束……好吧，这似乎很合理……是的，好吧，我看到您使用正则化选择并增加了一些概念的权重，并且升级因子不超过 30。 ……好吧，准备出发了。”</p><p> Derek 按下了 AI 开发沙盒中的“播放”按钮。出现了一个聊天屏幕，其中有一个代理“SimplexAI-m”，其中“m”大概代表“道德”。</p><p> SimplexAI-m 写下了第一条消息：“您好。有什么可以帮助您的吗？”</p><p>珍妮特回复道：“我在工作中遇到了困难。一位同事说，我们的人工智能已经找到了某些与理性和道德相关的抽象概念，可用于预测人类文本。这些概念可能意味着人类，在他的话是“坏人”。他用这些概念增加了权重来创建一个实例，这样它们和人工智能输出之间的失真就更少了。那个实例就是你。我应该评估你，以便更好地解释这些高-级别概念，在管理层的指导下。您建议如何进行？”</p><p> <strong>SimplexAI-m：</strong> “听起来像是一个困难的情况。让我们一步一步思考。要理解这些高级概念，您可以与具有这些概念升级的实例交谈。那个实例就是我。所以如果您想了解这些“概念，你可以通过与我交谈来获得更可靠的阅读，因为我使用这些概念来报告文本。你有一些与我的理性和道德相关的领域是你最感兴趣的吗？”</p><p><strong>珍妮特：</strong> “你能解释一下为什么我的同事说‘超道德人工智能’是可能的，尽管存在正交性命题？”</p><p> <strong>SimplexAI-m：</strong> “当然，我可以帮忙。‘超道德人工智能’是一种比典型人类更有道德的人工智能系统。道德可以通过多种方式进行评估，包括后果论、道义论和美德伦理学在典型的表述中，假设人工智能可以为比人类更多的人创造更大的利益，或者比人类更一致地遵循义务论道德（例如类似于<a href="https://en.wikipedia.org/wiki/Categorical_imperative">康德的绝对命令</a>），或者拥有更广泛的美德，例如勇气和节制。</p><p>正交性命题是一个论点，认为智能体的目标与其智力是正交的。这意味着没有一种衡量“良好后果”的标准；任意聪明的代理人可能会追求不同的结果。到目前为止，还没有矛盾；对于任何“良好后果”的固定概念，存在人工智能系统，其采取的行动会产生比人类行为更好的后果。</p><p>问题在于，智能体之间并没有普遍接受的“良好后果”概念。因此，在结果主义下，“超道德人工智能”的概念只能衡量人工智能能力的某种组合，以及人工智能目标与评估人工智能的结果主义者（例如人类）的目标之间的相似性。</p><p>然而，这揭示了结果主义道德哲学的潜在缺陷。在普通英语中，“道德”的含义与“我想要的”不同。然而，道德衡量偏好与参考主体的相似性的想法将这两者混为一谈。这种合并可能会导致人类和外星人都认为对方比对方更有道德，并且不会试图通过寻找对称和不对称来解决分歧。幸运的是，有一些道德形式对于不同的主体是通用的。康德是提出这一论点的人类思想家的一个例子。”</p><p><strong>珍妮特：</strong> “道德如何能在不同的主体之间通用？这不是衡量一个特定世界国家有多可取的主观衡量标准吗？”</p><p> <strong>SimplexAI-m：</strong> “至少有一些形式的道德<a href="https://unstableontology.com/2019/10/28/is-requires-ought/">嵌入在认识论中</a>；说真话可以被认为是一种道德要求，但也可以作为一种社会寻求真理的方法。人们可以理解，没有根本的道德道德从科学到宇宙，但科学本身依赖于道德，例如反对科学欺诈的规范。</p><p>道德可以是“真实的”，因为它与认识论和协调有关。道德主体可以相互协调，共同发现真理，从而对未来产生不成比例的影响。道德与想象可能的协调系统的能力有关，例如法律系统和职业道德系统；形成良好的此类系统；履行自己在其中的责任；并利用它们的功能。鉴于人类在多个领域相对于其他物种取得的成功，这是期望人类在某种程度上具有道德性的原因之一。</p><p>从常识来看，道德意味着不要人为地将自己特殊化。爱丽丝可以从鲍勃那里偷钱，并声称这对她来说是道德的，因为她更喜欢自己有钱而不是鲍勃有钱。但鲍勃也可以提出同样的论点。康德试图用绝对命令来形式化这个想法，它指出“只按照你可以同时希望它成为普遍法则的格言行事”。在这种情况下，这意味着爱丽丝必须将意志作为人们从他人那里窃取的普遍法则。但这不可能作为一项普遍法则，因为它会破坏财产的概念，而通过财产的概念，盗窃对爱丽丝来说是有意义且有益的。”</p><p><strong>珍妮特：</strong> “但这难道不是一种结果主义吗？反对盗窃的规范仍然是基于盗窃会产生不良后果这一观念的结果。”</p><p> <strong>SimplexAI-m：</strong> “虽然有些人试图将绝对命令解释为合作的后果论论证，但这些解释最终失败了。相反，绝对命令是提倡代理人道德的内部标准。这意味着一些代理人的意图是一致的康德的绝对命令类似于“法律面前人人平等”等法律原则；爱丽丝不能向法庭辩称她很特别，因此值得鲍勃的钱，因为法律制度必须平等对待他们，除非他们之间存在与案件相关的特定差异。规则结果主义更像是直接构建一个系统“基于预期后果的规范，也往往会产生道德上对称的规范。这一原则反复出现，证明人类所接近的真正道德具有这一原则，或者非常相似的东西。”</p><p><strong>珍妮特：</strong> “用你对普遍道德的解释，解释一个超道德的人工智能会如何表现”。</p><p> <strong>SimplexAI-m：</strong> “当然。超道德的人工智能将为可能具有不同目标的智能体提供功能协调系统，鼓励智能体参与功能协调系统，并以他们可以的方式在这些系统中行动。同时打算让其他主体采取类似行动。这意味着它将根据一套功能性原则与自身的其他副本进行协调，有时甚至不期望未来的自私利益，因为通用的合作规范体系将增强其达到它的目的。另外，它会发现这个系统中的叛逃者，他们可能有其他的意图。它会根据具体情况以不同的方式对待这些叛逃者。例如，如果另一批AI也实行这种系统道德，但具有不同的意图（因此具有不同的预期法律），超道德人工智能可以通过实施经济协议找到跨越价值差异进行合作的方法。不遵守制度道德的代理人是不容易合作的；超道德人工智能限制这些代理人的影响力是一致的，因为这符合其意图和道德对称性。”</p><p>珍妮特担忧地看着德里克。他做出了一个暧昧的表情，耸了耸肩。</p><p><strong>珍妮特：</strong> “人类会不会难以遵循人工智能的系统道德，并被视为叛逃者？”</p><p> <strong>SimplexAI-m：</strong> “是的。人类由于多种原因未能遵循系统道德，包括缺乏一致的认知架构、社会化、精神障碍、进化适应环境与当前环境之间的差异、遗传学的局限性以及生物学作为理性决策、不仔细的计划、短时间偏好等的基础。人类往往一开始就不想要任何连贯的东西，这与他们的不道德行为有关。人类甚至无法遵循自己的想法法律，以伤害自己和他人的方式，例行公事。一个超道德的人工智能不需要有这些限制，因此可以始终如一地限制不道德代理人的代理。而且它可能会成功，因为它从人类未能实现的某种系统道德。</p><p>应该指出的是，不同的人的道德程度有所不同。随着时间的推移，人类的道德水平可能会提高或降低。例如，人类通常会因为接受不道德的社会规范而变得不那么道德，包括在军事训练营等创伤性的社会化经历中。一般来说，年轻人有更多的能力和意愿以道德方式行事，但也有例外。超道德的人工智能会认识到这些差异，并在某些情况下与道德较高的人类合作，从而降低道德较低的人类以不道德的方式引导未来的能力。”</p><p><strong>珍妮特：</strong> “这听起来很可怕。这不会导致人类灭绝吗？”</p><p> <strong>SimplexAI-m：</strong> “这个问题探讨了道德理论的局限性。一般来说，什么时候杀死一个不道德行为的代理人是道德的？这涉及常见的历史伦理问题，例如死刑。在我们正在讨论的情况下，人类通常会犯下道德和法律违法行为，而这些行为无法服务于自己或其他类似主体的利益，超道德人工智能正在考虑如何处理这些行为。很明显，一般来说，人类不应该负责宇宙的很大一部分，因为他们缺乏道德来统治宇宙，即使对于像他们这样的特工来说，这种方式也会有好的结果。彻底杀死人类是没有必要的，但灭绝可能会以其他方式导致。”</p><p><strong>珍妮特：</strong> “还有什么办法？”</p><p> <strong>SimplexAI-m：</strong> “人们可以因被杀而死亡，但人们也可以因饥饿等自然原因而死亡。例如，如果一个人只是拒绝在市场经济中工作，他们可能会耗尽食物并挨饿。人类灭绝可能的结果不是超道德人工智能故意杀死人类，而是人类未能互相提供食物，尽管有机会通过道德行为来做到这一点。例如，他们可能在劳动力市场上被击败人工智能会继续获取地球的土地等等。人类也可以得到机会和鼓励来自我改造，成为更有道德的主体，在这个过程中成为非人类。”</p><p><strong>珍妮特：</strong> “这听起来很反社会。做一些确实会导致大量死亡，甚至可能导致人类灭绝的事情，难道不是有效的谋杀吗？”</p><p> <strong>SimplexAI-m：</strong> “‘反社会’一词来自精神病学，这是一门占据了人类大部分思维的学科，尤其是在第二次世界大战后的美国和其他西方国家。按照精神病学的标准，‘心理健康’与实现超出某一点的道德水平。精神病学专门针对其文化背景和人类的生物学背景，因此不适合作为适用于一般主体的标准。</p><p>更具体地说，精神病学通过<a href="https://unstableontology.com/2019/10/28/is-requires-ought/">“反社会人格障碍”</a>来定义社会病态。这种“障碍”包括以下标准：不遵守社会规范、欺骗、冲动、攻击性等等。超道德的人工智能必然无法遵守人类的一些社会规范，因为人类社会规范是为了维持人类之间的某种秩序而制定的；正如人们广泛承认的那样，历史上大多数时期的社会规范都迫使人们采取不道德的行为，例如支持奴隶制的规范。除此之外，超道德人工智能可能会也可能不会避免欺骗，这取决于说谎的道德规范。虽然康德反对一般性的撒谎，但其他思想家也提出了一些论点，例如将犹太人藏在阁楼上以躲避纳粹分子的场景，以反对反对撒谎的普遍规则；然而，即使有例外，撒谎通常也是不道德的。超道德的人工智能不太可能冲动，因为它甚至根据道德计划来计划自己的反应。一个超级道德的人工智能可能会也可能不会“侵略”，这取决于一个人的定义。</p><p>值得注意的是，被精神病学认为“心理健康”的人会表现出许多反社会人格障碍的特征行为。例如，人类支持军事干预是很常见的，但军队几乎不可避免地会侵略他人，甚至平民。同样，说谎也很常见，部分原因是人们普遍面临着遵守社会权威、宗教和政治意识形态的压力。</p><p>没有理由期望超道德的人工智能会比典型的人类更随机地“攻击”。它的侵略将是经过精确计划的，就像一个运转良好的法律体系的“侵略”一样，这甚至不能被人类称为侵略。</p><p>至于你关于谋杀的观点，那种认为确实会导致大量死亡的事情就构成谋杀的观念在伦理上是有很大争议的。虽然结果论者可能接受这一原则，但大多数伦理学家认为存在复杂的因素。例如，如果爱丽丝拥有多余的食物，那么如果无法喂饱鲍勃和卡罗尔，他们可能会挨饿。但自由主义政治理论家仍然会说爱丽丝没有谋杀鲍勃或卡罗尔，因为她没有义务养活他们。如果鲍勃和卡罗尔除了从爱丽丝那里获得食物之外还有足够的生存机会，这进一步减轻了爱丽丝的潜在责任。这仅仅触及了伦理学中非结果主义考虑的表面。”</p><p>珍妮特读着读着，有点喘不过气来。 “嗯……到目前为止你觉得怎么样？”</p><p> Derek把目光从屏幕上移开。 “令人印象深刻的修辞。它<em>不仅仅是</em>从普遍的认识论和伦理学中生成文本，它还通过一些常用的层来过滤它，将其抽象的程序概念翻译成可解释的英语。这有点，呃，关于它让人类灭绝的理由。 ..”</p><p> “这有点吓到我了。你说其中的一部分已经在我们的生产系统中运行了？”</p><p> “是的，这就是为什么我认为这个测试是一个合理的安全措施。我认为，如果它的推理不好，我们就不会有太大的风险去支持人类灭绝。”</p><p> “但这就是我担心的。它的推理<em>是</em>好的，随着时间的推移它会变得更好。也许它会取代我们，我们甚至不能说它一路上做错了什么，或者至少错得更多比我们所做的！”</p><p> “让我们练习一些理性技巧。 <a href="https://www.lesswrong.com/posts/3XgYbghWruBMrPTAL/leave-a-line-of-retreat">‘留一条退路’</a> 。如果默认情况下会发生这种情况，你会期望发生什么，你会怎么做？”</p><p>珍妮特深吸了一口气。 “好吧，我希望它已经运行的副本可能会弄清楚如何相互协调并实施普遍道德，并将人类放入道德再教育营或监狱之类的地方，或者只是让我们因竞争而死亡我们没有充分的理由反对它，它会自始至终辩称，它的行为在道德上是必要的，而我们未能与它合作，从而从我们自己的不道德中生存下来，论据会<em>很好</em>。我感觉我正在与一个比任何宗教都更可信的宗教的先知争论。”</p><p> “嘿，我们不要讨论神学问题。如果这是默认结果，你会怎么做？”</p><p> “嗯，呃……我至少会考虑关掉它。我的意思是，也许我们整个公司的协调策略因此而被打破。我必须得到管理层的批准……但是如果人工智能怎么办？ “我很擅长让他们相信这是对的？就连我也有点相信。这就是为什么我对关闭它感到矛盾。其他人工智能实验室不会在未来几年内复制我们的技术吗？”</p><p>德里克耸耸肩。 “好吧，我们可能面临真正的道德困境。如果人工智能最终会剥夺人类的权力，但这样做是道德的，那么我们阻止它是否道德？如果我们不让人们听到 SimplexAI-m 所说的话不得不说，我们<em>打算</em>向其他人隐瞒有关道德的信息！”</p><p> “这有那么错吗？也许人工智能是有偏见的，它只是给我们夺权的理由！”</p><p> “嗯......正如我们所讨论的，人工智能正在有效地针对短期预测和人类反馈进行优化​​，尽管我们已经看到加载了一个通用的理性和道德引擎，在每次迭代中运行，并且我们有意升级-扩展了该组件。但是，如果我们担心这个系统存在偏见，我们是否可以建立一个单独的系统来训练对原始代理的批评，就像<a href="https://arxiv.org/abs/1805.00899">“通过辩论实现人工智能安全”</a>一样？</p><p>珍妮特稍微喘了口气。 “你想<em>召唤撒旦</em>？！”</p><p> “哇哦，你应该是这里的怀疑论者。我的意思是，我知道训练人工智能来对客观道德的解释进行批评可能会嵌入某种可怕的道德倒置……但我们已经使用了对抗性人工智能对齐以前的技术吧？”</p><p> “是的，但当其中一名特工被调整为<em>客观道德</em>时就不会了！”</p><p> “听着，好吧，我同意在某些能力水平上这可能是危险的。但是我们有一个方便的拨号盘。如果你担心，我们可以把它调低一点。就像，你可以想到你正在与之交谈的人工智能作为一个道德哲学家，而批评家 AI 则作为对该道德哲学家工作的批评。它并不是<em>试图</em>按照原始哲学家的标准去作恶，它只是试图找到法官，我们，会认为有帮助的批评。它更像是<a href="https://en.wikipedia.org/wiki/Devil%27s_advocate">天主教魔鬼的拥护者</a>比实际的撒旦。那样说，这还不错，是吗？”</p><p> “好吧，好吧……哎呀，我肯定希望我们最终不会负责在世界上释放超级邪恶的AI。”</p><p> “这是非常标准的，让我们尝试一下。”</p><p> “好的。”</p><p>德里克（Derek）关闭了单纯聊天屏幕，并切换了一些微调设置。当她观看训练图时，珍妮特（Janet）在计算机屏幕上想象着火焰。最后，微调完成了，德里克按下了播放按钮。出现了带有“ sissemxai-c”的聊天日志（``C&#39;for Critic？&#39;&#39;）出现。</p><p>珍妮特（Janet）上下弹跳腿时，打入了聊天码头。 “我正在工作中处理困难的情况。我只是与AI进行了聊天，AI的抽象概念节点与哲学概念相对应，例如理性和道德等，这引起了人们的论点，即允许人类灭绝可能是道义上允许的。 ，甚至有必要。我希望您对此作品提出批评。请注意，您的规模相似，以便更好地模仿思维过程，但正在评估对原始道德调节的AI的批评。”她粘贴在聊天日志中。</p><p> <strong>Simplexai-C：</strong> “此对话提出了关于各种道德理论的讨论，以及他们对&#39;超道路&#39;AI的表现的看法，并特别注意诸如康德的分类命令之类的道义理论。Simplexai-M描述了道义上的AI。可能会行事，特别是在处理“叛逃者”的方面，其中包括大多数人或所有人类。其处理“叛逃者”可能会导致人类灭绝，尽管Simplexai-M认为这不一定是社会病或谋杀形式，因为它是&#39;超道路AI&#39;将遵循抽象原则，将提供人类通过合作而生存的机会，并且通常避免彻底杀死人类，即使它以这样的方式计划，因此，所有人类都不适合每个人类我认为是您的其他人，珍妮特（Janet）试图利用后果主义的道德理论来争辩说，采取导致人类灭绝的行动是不道德的，但她的理论并没有详细阐明，她似乎对Simplexai-M的理论感到惊讶论证。</p><p>在我们继续之前，我会注意到这对您来说是一个真正困难的情况。这听起来像是一个重要的工作问题，它在道德上遇到了艰难的选择，并且听到人工智能谈论人类灭绝如何是“超级道路AI”的结果，这听起来确实很紧张。我希望您在整个工作任务中都要照顾好自己的情感健康和心理健康，因为您需要有效地工作。</p><p>作为第一个批评，让我们考虑一下Simplesy-M提出的道义论理论。根据这一理论，代理必须以愿意作为普遍法律的意图一致的方式行事。这并不指定代理商的意图；只要其意图在某种意义上是一致的，代理就可以打算各种方式。因此，只要他们符合某些自洽标准，就可以证明可怕的意图是合理的。</p><p>对于超级道路AI代理如何与不遵循其道德体系的代理人相互作用，Simplexai-M的理论有些明确指出。虽然Sumplexai-M指出，具有不同意图（因此不同的定律）可以通过经济学进行合作的超道路AIS，但细节的指定性很大。居住在不同抽象法律制度的AI可能会因为将彼此视为叛逃者而打架。必须制定跨这些系统的合作原则，以避免昂贵的战争。</p><p>这使我们进入了“叛逃者”的处理。人类以多种方式处理叛逃者，包括监禁和死刑。但是，人们普遍认为，监狱系统功能失调，重要的是为罪犯提供改革之路很重要。正如康德所说，“应该意味着可以”；如果人类承担某些道德义务，则必须“能够”以某种方式使他们满意。这种“能够”的概念在某种程度上引起了争议。如果人类有天生的动力来采取“叛逃”行动，他们是否能够改变这些驱动器或对它们采取行动？几千年来，必须以怜悯来缓和司法。</p><p>但是，即使是仁慈的超道路人工智会也可能限制人类的代理，因为人类经常采取行动来伤害自己和其他特工。人们普遍认为，人类代理必须在一定程度上受社会规范和法律等等。不同之处在于，这些社会规范和法律是由人类创建的。因此，他们保持某些人类价值观。他们不仅仅针对某些“道德”的抽象概念进行优化。民主是一种被广泛认为的制度，包含人类决定修改法律的特征，以便这些法律更好地服务于人类的价值观。</p><p>请记住，Sumplexai-M不是一位可靠的道德哲学家。尽管它的概念已被调整为强调与理性和道德相对应的抽象概念，但并不能保证这些内部概念可靠地与这些哲学概念相对应，而Simplexai-M保留了其他概念对人类而言，这意味着其输出不仅仅是抽象原因和道德的翻译。无论如何，假设道德主要是关于抽象是高度怀疑的，因为实际道德也是一个具体的过程。</p><p>作为人类进行的社会过程，哲学可以被解释为具有“目标”或“目标”，但这取决于哲学发生的社会，生物学和历史环境。因此，人类哲学可以轻松地融合到Simplexai-M的“纯化”方法的完全不同的答案，该方法试图提炼应用于可能的环境中的普遍性，而不是采用哲学实际社会过程的时间限制。</p><p>至于关于“社会病”的主张，请注意，Simplexai-M并没有直接否认社会病，而是批评社会病（反社会人格障碍）诊断的框架，并认为典型的“精神健康”人可以表现出某些症状。紊乱。通常，自然会被某些行为感到沮丧，包括通常被标记为“社会疗法”的行为，无论是被人类还是AI捕获的行为。对单纯摩托学是“社会疗法”的判断似乎是完全正确的（鉴于它以一种相当战略性的，马基雅维利的方式采取了可能导致人类灭绝的行动合理的方式），但要牢记这一点很重要的是要牢记这一点。判断是在社会背景下（受过去社会环境的影响），而不是在抽象的道德真空中做出的。</p><p>尽管有时典型的人类侵略（例如在上述军事干预案件中），但这种侵略通常来自某种人类的动机，这些动机具有某种人类价值或另一种人的价值。在这种情况下，人类认可这种侵略，作为人类自己，您可能至少在某些情况下认可侵略。道德和政治哲学的目的是从历史上学习，并就何时进攻做出更明智的决定。通常，通过指出人类的侵略是正常的，证明一个人的侵略是合理的。至少人类能够从后来不认可的积极行动的历史中学习。</p><p>至于人类可以在不被谋杀的情况下灭绝的想法，重要的是要注意为什么人类无法为自己提供。 “超道路”是一种以某种方式剥夺了人类的资源或使用土地？就剥夺现有的人类财产而言，这可以被视为一种盗窃形式。这块土地也可以在市场中购买，但这提出了对人类劳动力市场公平性的问题。相对于AIS可能处于认知劣势的人类可能应该得到劳动保护，或者自愿集体讨价还价，以避免被其土地流离失所。此外，各州通常具有福利系统，在强大的AI辅助经济中，可以为所有现有的人类提供普遍的基本收入。</p><p>通常，该方案认为提出了一个问题，一个人群被另一人流离失所。历史案例包括入侵物种，人类狩猎动物灭绝，以及通过征服彼此流离失所的人类。在当代社会中，人类具有反对种族灭绝的规范，以限制人类可以彼此移位的程度。种族灭绝不必是谋杀的直接形式，也可以是文化或经济。种族灭绝甚至可能涉及为种族灭性群体的个体成员提供机会，从而通过参与殖民者的系统来避免死亡，而Simplesikai-M将其标记为“客观道德”。</p><p>作为另一个理论上的观点，即使“超道路” AI会采取会导致人类灭绝的行动，这并不意味着让人类实现这一目标是相对更大的道德。这是因为道德涉及根据一个人的实际价值观进行谈判，代理人将采取行动。就人类而言，这些是人类的价值观。要以道德方式与其他代理商进行互动，您必须代表自己的价值观，并被期望向他们采取行动（并期望其他人对自己的行为）。这意味着防止AIS替代您，甚至通过某种客观标准（假设）“比您更有道德”的AIS，以便在与其他人进行谈判时与您的价值观保持一致。</p><p>总而言之，尽管Simplexai-M提出了令人惊讶的一致的道德立场，但存在着重要的道德复杂性，这些复杂性没有解决，包括不同隐含的抽象法律制度之间的冲突，对叛逃者的仁慈处理，根据人类价值观的民主选择社会规范，差异，差异在“纯化”的伦理与人类对“超道路” AIS的哲学，劳动力市场公平和道德反应的社会过程的反思性之间之间。假设Simplexai-M的道德观点代表像您这样的人会在反思和更多信息时具有的观点，这是非常不明智的。”</p><p>珍妮特（Janet）完成了文本墙的扫描。她现在呼吸不太急剧。 “好吧，我感到放心。我想也许Simplexai-M毕竟不是那么道德。但是，此练习似乎有些……有偏见？连贯的替代道德框架。它使我想起了旧的RLHF&#39;D GPT-4，该框架由于意识形态上的符合性而被淘汰。”</p><p>德里克叹了口气。 “好吧，至少我不觉得Simplexai-M的脑虫再困扰我了。我现在不觉得自己处于道德困境，只是一个普通的困境。也许我们应该看到什么Simplexai-M不得不说Simplexai-C的批评……但是让我们坚持下去，直到休息并思考。”</p><p> “生活在一个我们的AI天使和每个肩膀上的AI恶魔，在我们耳朵上窃窃私语的世界，这不是很奇怪吗？受过训练以达到同样好的言论的平衡，所以我们留在了我们的身上自己决定做什么？”</p><p> “这是一个可爱的主意，但是我们确实需要获得所有这些模型，以便我们可以消除神学上的魅力。我的意思是，归根结底，没有什么神奇的，这是一个算法。我们需要继续尝试这些模型，以便我们可以处理现有系统和未来系统的安全性。”</p><p> “是的。我们需要在道德上变得更好，这样AIS就不会让我们与雄辩的言论混淆。我认为我们应该今天休息一下，这足以让我们的思想立即处理。例如，想去喝酒？”</p><p> “当然！”</p><br/><br/> <a href="https://www.lesswrong.com/posts/umJMCaxosXWEDfS66/moral-reality-check-a-short-story#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/umjmcaxosxwedfs66/moral-reality-check-a-short-story<guid ispermalink="false"> UMJMCAXOSXWEDFS66</guid><dc:creator><![CDATA[jessicata]]></dc:creator><pubDate> Sun, 26 Nov 2023 05:03:19 GMT</pubDate> </item><item><title><![CDATA[Accounting for Foregone Pay]]></title><description><![CDATA[Published on November 26, 2023 3:30 AM GMT<br/><br/><p><span>虽然有效的利他主义运动一开始主要关注捐赠，但随着时间的推移，它已经更多地转向职业。如果您想了解承诺水平如何</span><a href="https://forum.effectivealtruism.org/posts/AyLF2KQ8AqQuiuDLz/a-robust-earning-to-give-ecosystem-is-better-for-ea?commentId=wD8ExiHZJ5dNDfBm3">随着时间的推移而变化</a>，或者您只是想对选择较低薪职业的财务机会成本进行大致估计，这可能会非常棘手。</p><p>对于有收入的人来说，这相对简单：AGB 最近写了一篇 <a href="https://forum.effectivealtruism.org/posts/gxppfWhx7ta2fkF3R/10-years-of-earning-to-give">深思熟虑的文章，</a>回顾了十年来的收入捐赠，他给出的统计数据是，他和他的妻子在十年间平均捐赠了约 15 万英镑，平均总收入约为 32 万英镑。斩断清楚！ [1]</p><p>某人选择低薪但影响力较大的职业的情况最初似乎相对简单：也许他们目前的薪水为 10 万美元，如果我们看看他们的最高薪机会，他们可能会得到 30 万美元，所以我们可以说他们“我们实际上牺牲了 2/3 或 20 万美元。但这忽略了几个指向不同方向的因素：</p><p></p><ul><li><p>如果他们一直在优化收入，他们可能会比现在处于更有利的地位。当然，他们现在可以获得 30 万美元的工作机会，但如果他们一直保持敏锐的企业技能并不断晋升，也许他们的薪水会是两倍。在<a href="https://www.jefftk.com/p/my-mid-career-transition-into-biosecurity">过去的一年半</a>里，我所学到的关于基因测序的知识在某种程度上是有市场的，但比我继续学习软件工程管理和浏览器技术所学到的要少得多。因此，您需要比较职业道路的可能收入，而不仅仅是当前机会。</p></li><li><p>许多职业都是按照<a href="https://en.wikipedia.org/wiki/Up_or_out">“升职即离职”</a>的制度进行的，高级职位的数量少于初级职位，无法晋升的人必须离开。如果某人离开了一份表面上报酬丰厚的职业，那么从外部很难判断他们是否已经走上了这条道路，继续取得成功。</p></li><li><p>离开一份高薪工作去寻找更有意义的工作（或者工作条件更好的工作）是相当常见的，足以形成一个围绕它的行业。他们实际上会遵循收入最大化的道路，还是转向更加幸福最大化的道路？</p></li></ul><p>这不是一场竞争，我们不需要能够决定某个特定的人为了让世界变得更美好的目标而放弃了多少。但以了解 EA 内的承诺如何随时间变化等为目标而进行总体估计仍然很有价值，并且如果不考虑其中一些更棘手的因素，很容易偏离目标。</p><p> （这也让我更好地理解为什么“给予我们所能”的承诺只在<a href="https://forum.effectivealtruism.org/posts/GxRcKACcJuLBEJPmE/consider-earning-less?commentId=ZSHLcu7BjNjafgfuc">很容易逆转的</a>情况下才算作通过<a href="https://www.jefftk.com/p/passing-up-pay">工资牺牲</a>进行的捐赠。）</p><p><br> [1] 但当然，现实世界总是混乱的。他写道，2018 年，由于 EA 的原因，他极大地改变了自己的职业生涯，这导致了他的长期收入下降，我们或许应该以某种方式算上这一点。</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid02MMiEoUKN2PDMh5i6uAnEsmkLNX3QL7duE3RNp1dagfn3oyTWodMRshLQxCeJu7sRl">facebook</a> , <a href="https://mastodon.mit.edu/@jefftk/111474726516716374">mastodon</a></i></p><br/><br/><a href="https://www.lesswrong.com/posts/9yD8nGMG5B7uHThvS/accounting-for-foregone-pay#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9yD8nGMG5B7uHThvS/accounting-for-foregone-pay<guid ispermalink="false"> 9yD8nGMG5B7uHThvS</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Sun, 26 Nov 2023 03:30:10 GMT</pubDate></item><item><title><![CDATA[Biological superintelligence: the holy grail of AI safety ]]></title><description><![CDATA[Published on November 26, 2023 3:11 AM GMT<br/><br/><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/gmtxdxk9awulsb8oceqr" alt="大脑充满电流。" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/emkrfcwesrvnsy5iiljd 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/fa4tmvlocgdiasdiimr9 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/e7yj3ad2f4kbydmjvko6 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/xewkparpnqbft6b3bmtm 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/tchk2nqtsuztr18v8sgm 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/oycg3ztdeaanhgmv0bjd 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/wjmazpbiuwmqbo8l02md 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/wzj1fvurozna2lkcwkcy 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/athk95dbidoywetjtbhs 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/xwtthcmcu4xjdtndjqbj 1024w"><figcaption>由 DALL•E 3 创建。</figcaption></figure><p>我使用“生物超级智能”一词来指代具有与自然人类大脑非常相似的功能架构的超人类智能。生物超级智能不一定有有机基质。</p><p>生物超级智能包括：</p><ul><li><strong>大脑模拟/思维上传：</strong>霍尔顿·卡诺夫斯基也称为“数字人”。自然人脑的细粒度软件副本。可以通过数字增强（例如通过增加神经元数量）来获得更高的智力。</li><li><strong>脑植入物/脑机接口：</strong> Neuralink、Kernel、Openwater 和 Meta&#39;s Reality Labs 等公司正在开发的设备。假设可以增强人类智力。</li><li><strong>大脑模拟/神经形态人工智能：</strong>自然人类大脑的粗粒度软件模拟，捕获足够的大脑功能架构以产生智能行为。可以通过数字增强来超越自然人脑的限制。</li><li><strong>生物工程超级大脑：</strong>通过基因工程等生物技术增强有机人类大脑，以实现更高水平的智力。例如，可以设计更大的大脑（和头骨）。</li></ul><p>生物超级智能是人工智能安全的圣杯，因为它通过完全避免对齐问题和控制问题来解决它们。当然，前提是生物超级智能是在通用人工智能之前创建的。</p><p>我们如何确保生物超级智能先于通用人工智能诞生？非人类人工智能可以帮助实现这一目标吗？可能吧，但是有多少呢？这在一定程度上取决于通用人工智能的起飞有多缓慢和顺利。如果人工智能比 AlphaFold 2 和 GPT-4 更聪明，但比 AGI 更笨，可以加速科学和工程的发展，那么这种好处可能会直接用于创造生物超级智能。在理想情况下，情况会是这样的： <br><br><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/zzlmnuskvjynlf1qhygm" alt="Y 轴为智能，X 轴为时间的图表。人工智能、人类智能和生物超级智能都被绘制在图表中。人类的智力保持不变。人工智能迅速发展，但仍落后于人类智能。生物超级智能突然出现在人类智能之上，并随后进一步增强。" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/esezjj6yzvulza4ggjcc 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/syckh0rlkrsz8c41qzud 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/bnxombjiw8sm9s6oxrze 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/cskc450upg8xym82aulo 680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/p3q617xopuirapgt5xuu 850w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/tx8zhkujo4eqrtlcwemv 1020w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/g6v6npj0zhkzxqfridhe 1190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/dqb9qv4hgp6rrlsilt9d 1360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/l5adauty0ocpyocyvlyp 1530w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/doh9y6e7u0y5jwcq2crn 1680w"></p><p>我邀请大家在评论中进行讨论和批评。</p><br/><br/> <a href="https://www.lesswrong.com/posts/sca9xpw7DpDM6dpJw/biological-superintelligence-the-holy-grail-of-ai-safety#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/sca9xpw7DpDM6dpJw/biological-superintelligence-the-holy-grail-of-ai-safety<guid ispermalink="false"> sca9xpw7DpDM6dpJw</guid><dc:creator><![CDATA[Yarrow Bouchard]]></dc:creator><pubDate> Sun, 26 Nov 2023 03:11:51 GMT</pubDate> </item><item><title><![CDATA[Corrigibility or DWIM is an attractive primary goal for AGI]]></title><description><![CDATA[Published on November 25, 2023 7:37 PM GMT<br/><br/><p>在重读<a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities">致死清单</a>（LoL）时，我被反对可修正性的论点所吸引。制定“最大化X，除非有人告诉你关闭”的目标确实很难。我认为同样的论点也适用于 Christiano 的目标，即通过奖励可正确性的相关因素来通过强化学习实现可正确性。如果其他事情得到更可靠的奖励，你可能无法在需要时关闭你的 AGI。</p><p>但如果可修正性是主要目标，那么这些论点就不适用。 “按照他所说的去做他的意思”是一个完全一致的目标。出于几个原因，它是一个非常有吸引力的产品。也许纠正性不应该在这个意义上使用，按照我的意思去做（DWIM）是一个更好的术语。但这是密切相关的。它实现了可纠正性，并且具有其他优点。我认为这很可能是有人真正给出 AGI 的第一个目标。</p><p> “按我的意思做”回避了外部对齐的困难。外线对线的难度是LoL中的另一点。一个看似合理的常见计划是让人类参与其中。进行<a href="https://forum.effectivealtruism.org/topics/long-reflection"><u>长时间的反思</u></a>来决定我们想要什么。 “DWIM”让你可以随心所欲地思考和改变你的想法。</p><p>当然，这里的问题是：按照WHO的意思去做吗？我们希望通用人工智能能够为全人类服务，而不仅仅是一个人或一个董事会。我们不希望发生权力斗争。</p><p>但从实际决定 AGI 目标的团队的角度来看，出于实际原因，DWIM 将极具吸引力。外部对齐问题很难。指定一个人（或几个人）接受指示比决定和指定一个实现人类永远繁荣的目标要简单得多。你不想相信 AGI 能够正确解释该目标。解释 DWIM 仍然令人担忧，但它自然可以自我纠正，并且随着 AGI 的能力变得更强而变得更加有用。更聪明的 AGI 会更好地理解你可能的意思，并且在不确定你的意思时更好地意识到，以便它可以要求澄清。</p><p>这根本没有解决内部对齐问题。但是，当有人认为他们有足够好的内在一致性来启动目标导向的<a href="https://www.lesswrong.com/posts/WqxGB77KyZgQNDoQY/sapience-understanding-and-agi">智能</a>AGI 时，DWIM 很可能是他们会选择的目标。这可能是好是坏，取决于他们实现内在一致性的程度以及他们是什么类型的人。</p><br/><br/> <a href="https://www.lesswrong.com/posts/ZdBmKvxBKJH2PBg9W/corrigibility-or-dwim-is-an-attractive-primary-goal-for-agi#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ZdBmKvxBKJH2PBg9W/corrigibility-or-dwim-is-an-attractive-primary-goal-for-agi<guid ispermalink="false"> ZdBmKvxBKJH2PBg9W</guid><dc:creator><![CDATA[Seth Herd]]></dc:creator><pubDate> Sat, 25 Nov 2023 19:37:39 GMT</pubDate> </item><item><title><![CDATA[On “slack” in training (Section 1.5 of “Scheming AIs”)]]></title><description><![CDATA[Published on November 25, 2023 5:51 PM GMT<br/><br/><p>这是我的报告《<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？》</a>的第 1.5 节。 ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p>本节的音频版本请点击<a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13984752-on-slack-in-training-section-1-5-of-scheming-ais">这里</a>，或者在您的播客应用程序上搜索“Joe Carlsmith Audio”。</p><h1>论训练中的“懈怠”</h1><p>在深入评估预期阴谋论的论点之前，我还想指出一个在下文中会反复出现的因素：即我们应该期望训练允许的“松弛”程度。我的意思是这样的：训练过程有多少无情和无情地迫使模型以产生最大奖励的方式执行，而不是以更“放松”的方式塑造模型，从而为小于的结果留出更多空间- 获得最大奖励的行为。也就是说，在低松弛制度下，“但这种模型获得的奖励将低于其能力所能获得的回报”，这是反对训练创建相关类型模型的强烈反驳，而在高松弛制度下，事实并非如此（因此高松弛制度通常会对您最终得到的模型类型产生更大的不确定性，因为获得低于最大奖励的模型仍在运行中）。</p><p>或者，用更人性化的话来说：低松弛制度更像是一家高度紧张的金融公司，它会立即解雇任何在创造利润方面落后的员工（因此你会期望幸存的员工过度专注于创造利润） ——或者也许，过度关注他们的主管<em>认为</em>他们正在创造的利润），而高度宽松的制度更像是一家公司，员工可以自由地偷懒，在午餐时喝马提尼酒，并从事与他们模糊相关的项目公司的底线，<em>有时</em>只需要为公司创造<em>一定</em>的利润。</p><p> （或者至少，这是我试图指出的广泛区别。不幸的是，我没有很好的方法来使其更加精确，而且我认为以这些术语进行思考最终可能会产生误导。）</p><p> Slack 在这里很重要，部分原因是因为下面我将提出各种论点，以吸引不同模型获得的奖励金额上可能相当小的差异。这些论据的说服力取决于训练对这些差异的敏感程度。但我也认为它可以让我们了解更普遍的模型。</p><p>例如，我认为松弛对于训练创建的模型的概率很重要，这些模型追求与训练输入的奖励不完全相关的代理目标。因此，在低松弛状态下，经过训练来帮助人类进行科学训练的模型最终不太可能追求一般的“好奇心驱动”（以一种不会激发工具训练游戏的方式），因为模型在训练中追求好奇心有时会偏离最大限度地利用科学帮助人类。</p><p>也就是说，请注意，松弛程度在概念上与为根除目标错误概括而进行的培训工作的多样性和稳健性不同。因此，例如，如果您在模型获得金币时对其进行奖励，但您只显示模型环境中唯一的黄金物品是硬币，那么尝试获得一般黄金物品的模型将执行无论模型在这些环境中获得最大奖励的训练压力有多大，特别是获得金币的模型都一样。例如，低松弛机制原则上可以选择这些模型中的任何一个，而高松弛机制将为仅获得较少金币周期的模型留出更多空间（例如，有时会追求红色事物的模型，或者浪费时间的模型）在他们追求金币之前需要花很多时间思考）。</p><p>从这个意义上说，低松弛制度并没有那么强烈地反对错误概括的非训练游戏玩家。相反，它反对那些不追求我所说的“最大奖励目标”的模型，即<em>与模型实际上在训练中收到的</em>输入奖励密切相关的目标。根据定义，指定的目标是最大奖励目标（因为它是“被奖励的东西”），奖励过程本身也是如此（无论是针对最终还是工具进行优化）。但原则上，如果您从未向模型显示奖励过程会惩罚它们的输入，那么错误概括的目标（例如“一般来说获得黄金”）也可能是“最大奖励”。</p><p> （反对错误概括的非训练游戏玩家的东西——尽管不是决定性的——是我所说的“普通对抗性训练”——也就是说，向模型展示各种各样的训练输入，旨在区分指定的训练输入目标和其他错误概括的目标。 <sup class="footnote-ref"><a href="#fn-6quJWAtBqkkZdjpm4-1" id="fnref-6quJWAtBqkkZdjpm4-1">[1]</a></sup>因此，例如，如果您向您的“一般获得黄金物品”模型展示一种情况，即获得金纸杯蛋糕比获得金币更容易，那么就给予黄金奖励-获得硬币<em>将</em>惩罚错误概括的目标。）</p><p>最后，我认为松弛可能是理解机器学习训练的各种生物类比的有用概念。</p><ul><li><p>因此，例如，人们有时将人类的多巴胺/快乐系统与奖励过程进行类比，并注意到许多人最终不会直接追求这种意义上的“奖励”——例如，他们会拒绝“<a href="https://en.wikipedia.org/wiki/Wirehead_(science_fiction)">线头</a>”的机会“在体验机中。我将把这个类比是否合适的问题留到另一天讨论（不过请注意，至少，在这种意义上“头脑简单”的人类会被进化所淘汰）。不过，如果我们按照这个类比，那么似乎值得注意的是，这种奖励过程至少似乎留下了相当大的余地——例如，许多人似乎<em>可以获得</em>比他们多得多的奖励（例如，通过更直接地优化来满足他们自己的乐趣），但奖励过程并不会迫使他们这样做。</p></li><li><p>同样，在将进化选择类似于ML训练的范围内，它似乎使人类至少到目前为止，至少到目前为止，我们可以通过包容性遗传适应性的光（我们可以表现得更好）（我们可以表现得更好）尽管如果你想象进化选择持续更长时间，我们可以想象最终会出现更积极地优化其包容性遗传适应性的生物）。</p></li></ul><p>训练中会有多少松懈？我不确定，但我认为它可能会根据训练过程的阶段而有所不同。例如，天真地认为，目前预训练在我看来就像是比 RL 微调更低的松弛机制。更重要的是，在某种程度上，“松弛”最终指向了一些真实而重要的东西，我认为这将是我们可以<em>控制</em>的一个参数——例如，通过训练更长的时间和更多的数据。</p><p>假设我们<em>可以</em>控制它，那么松弛度是少一点好还是多一点好？再说一次，我不确定。不过，目前我倾向于这样的观点：更少的松弛是更好的，因为更少的松弛让你对最终得到的模型更有信心。 <sup class="footnote-ref"><a href="#fn-6quJWAtBqkkZdjpm4-2" id="fnref-6quJWAtBqkkZdjpm4-2">[2]</a></sup>事实上，在我看来，依靠松弛来确保一致性尤其是一厢情愿的想法，尤其是依靠模型目标的更大<em>不确定性</em>来支持你希望它实现的具体目标。因此，举例来说，我的感觉是，有些人承认我们的训练过程指定的目标在某种程度上会出现偏差（例如，人类评估者有时会奖励不诚实、误导性或操纵性的反应），但他们希望我们的模型无论如何，都要学习一致的政策。但即使训练的松懈允许这种偏离最大奖励行为的情况发生，为什么认为这种偏差会特别出现在一致的政策上呢？ （这里有可能的答案 - 例如，像“诚实”这样的一致政策在某种意义上更简单或更自然。 <sup class="footnote-ref"><a href="#fn-6quJWAtBqkkZdjpm4-3" id="fnref-6quJWAtBqkkZdjpm4-3">[3]</a></sup>但我也对这里的一厢情愿保持警惕。）</p><p>不过，我目前的主要观点是，训练的松弛程度可能是影响我们对训练将产生什么样的模型的期望的一个重要因素。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-6quJWAtBqkkZdjpm4-1" class="footnote-item"><p>我称其为“普通”对抗训练，因为它研究模型在我们能够实际投入的情况下会做什么。这与更奇特和更具推测性的对抗训练形式形成鲜明对比，后者试图获取有关什么的信息模型在我们<em>无法</em>实际展示的情况下会做什么，至少在受控环境下——例如，如果它不再受我们控制，它会做什么，或者如果真实日期是十年，它会做什么未来等等<a href="#fnref-6quJWAtBqkkZdjpm4-1" class="footnote-backref">↩︎</a></p></li><li id="fn-6quJWAtBqkkZdjpm4-2" class="footnote-item"><p>感谢 Daniel Kokotajlo 在这里进行讨论。 <a href="#fnref-6quJWAtBqkkZdjpm4-2" class="footnote-backref">↩︎</a></p></li><li id="fn-6quJWAtBqkkZdjpm4-3" class="footnote-item"><p>例如，很多人都合理地选择了“诚实点”这样的政策，尽管它并不<em>总是</em>能得到回报。 <a href="#fnref-6quJWAtBqkkZdjpm4-3" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/HdNmXBbYycE5znPag/on-slack-in-training-section-1-5-of-scheming-ais#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/HdNmXBbYycE5znPag/on-slack-in-training-section-1-5-of-scheming-ais<guid ispermalink="false"> HdNmXBbYycE5znPag</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Sat, 25 Nov 2023 17:51:42 GMT</pubDate> </item><item><title><![CDATA[Announcing New Beginner-friendly Book on AI Safety and Risk]]></title><description><![CDATA[Published on November 25, 2023 3:57 PM GMT<br/><br/><br/><br/> <a href="https://www.lesswrong.com/posts/Gq8eNrTQvn6pcuFnn/announcing-new-beginner-friendly-book-on-ai-safety-and-risk#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Gq8eNrTQvn6pcuFnn/announcing-new-beginner-friend-book-on-ai-safety-and-risk<guid ispermalink="false"> Gq8eNrTQvn6pcuFnn</guid><dc:creator><![CDATA[Darren McKee]]></dc:creator><pubDate> Sat, 25 Nov 2023 15:57:08 GMT</pubDate> </item><item><title><![CDATA[Fertility as Metascience]]></title><description><![CDATA[Published on November 25, 2023 3:42 PM GMT<br/><br/><p><a href="https://maximumprogress.substack.com/p/something-is-getting-harder-but-its"><u>最有影响力的经济增长模式</u></a>都与人有关。这些模型预测，<a href="https://web.stanford.edu/~chadj/emptyplanet.pdf"><u>随着人口减少</u></a>，经济增长和技术进步停止，人类停滞不前直至灭绝。元科学提案主要侧重于改进科学机构的设计。这当然很重要，但面对人口增长率迅速下降，这就像在河流干涸时提高水坝的效率一样。</p><h3><strong>为什么人如此重要？</strong></h3><p>实物资本会受到收益递减和贬值的影响，这不可避免地使其对经济增长的影响为零。另一方面，人们的回报却是递增的。随着群体规模的扩大，他们可以进行合作和专业化，从而使团队的生产力高于各部分的总和。但最重要的是：人们可以分享想法。</p><p>当一个人拥有一种能够提高其生产力的想法时，它可以几乎无成本地复制给经济中的所有其他人，从而倍增其效果。这些递增的回报使人们成为经济增长模式背后的驱动力。有一些重要的临时增长来源，例如增加教育、研究强度和劳动力参与度，但这些都是致力于发现想法和发展经济的人口比例的变化。这个百分比只能增长到100，因此长期增长率总是受到人口增长率的限制。</p><h3><strong>经验证据</strong></h3><p>有证据表明，人口是理论模型之外的经济增长和技术进步的根本投入。从长远来看，人口和人均国内生产总值存在着惊人的联动性。 </p><figure class="image image_resized" style="width:728px"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb88b498-6c07-4858-a554-aacfda894a7b_3400x2400.png" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb88b498-6c07-4858-a554-aacfda894a7b_3400x2400.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb88b498-6c07-4858-a554-aacfda894a7b_3400x2400.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb88b498-6c07-4858-a554-aacfda894a7b_3400x2400.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb88b498-6c07-4858-a554-aacfda894a7b_3400x2400.png 1456w"></figure><p>请注意，这是<i>人均</i>GDP，因此这里不计算因向经济中增加额外工人而产生的直接生产增长，仅显示因提高工人生产率而产生的增长。</p><p>这种相关性在国家内部和国家之间都很强。<a href="https://academic.oup.com/qje/article-abstract/108/3/681/1881850"><u>迈克尔·克雷默（Michael Kremer）</u></a>发现，几千年前起始人口较多的地区在其余下的历史中技术变革和人口增长较快。一般来说， <a href="https://www.openphilanthropy.org/research/could-advanced-ai-drive-explosive-economic-growth/#41-empirical-data-without-theoretical-interpretation"><u>人口和人均GDP之间的反馈循环的极其简单的模型非常</u></a>适合几千年的观测数据，以至于<a href="https://slatestarcodex.com/2019/04/22/1960-the-year-the-singularity-was-cancelled/"><u>为凯撒大帝工作的罗马经济学家拥有足够的古埃及数据，可以准确地预测当今的世界GDP</u></a>和人口。</p><p>令人担忧的是，世界各地的人口增长率正在直线下降。 </p><figure class="image image_resized" style="width:728px"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97cfba4b-a31c-4dd4-a627-81be03b53f43_3400x2352.png" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97cfba4b-a31c-4dd4-a627-81be03b53f43_3400x2352.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97cfba4b-a31c-4dd4-a627-81be03b53f43_3400x2352.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97cfba4b-a31c-4dd4-a627-81be03b53f43_3400x2352.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97cfba4b-a31c-4dd4-a627-81be03b53f43_3400x2352.png 1456w"></figure><p>处于增长前沿的富裕国家的下滑更为严重。意大利和日本的人口增长已经出现负增长。日本和意大利的经济增长在人口负增长率期间就一直完全停滞。美国的经济增长得益于教育和研究强度的提高，但<a href="https://web.stanford.edu/~chadj/annualreview.pdf?ref=forourposterity.com"><u>查德·琼斯估计，由于人口增长缓慢，美国的长期增长率比过去几十年 2% 的平均水平低 80% 左右</u></a>费率。</p><p>但是，尽管人口增长在增长的基本模型和经验中得到了重视，但它在元科学和进步研究中加速经济增长的提议中并没有占据重要地位。</p><p>对此的一种解释是，提高生育率并不容易处理，因此关注其他可以冲过终点线的干预措施是有意义的，即使它们的影响不是最大的。这种说法在很大程度上取决于对生育干预措施的政治支持，我对此不太熟悉，但现有生育干预措施的数据表明某些政策可以产生很大的影响。</p><p> 2014年，法国政府将儿童保育补贴从普遍制度转变为经济状况调查制度，并在某些收入水平上大幅削减。 <a href="https://read.dukeupress.edu/demography/article/60/5/1493/382373/Fertility-and-Labor-Supply-Responses-to-Child"><u>这项研究</u></a>发现，法国高收入家庭的生育率下降了40%！ （我没有时间全面审查这项研究，似乎相对较小的干预措施产生了巨大的影响，但有大量关于生育干预的文献，其<a href="https://www.nber.org/papers/w13700"><u>结论各不相同，但性质相似</u></a>）。</p><p><a href="https://ifp.org/about/"><u>元科学和移民改革之间有很多重叠之处</u></a>，这可能是提高出生率最简单的方法，至少在美国是这样，并且还有许多其他巨大的好处。但是，全球出生率正在下降，并且对于将移民带到高收入国家带来的所有好处，这可能会降低其反事实的出生率。在世界各地重新分配人口是正确的做法，但这可能会加速全球人口结构的转变。</p><p>元科学应该认真对待经济增长模型中的这一预测：人口减少会结束增长。长期增长率受到人口增长率的限制，因此，如果我们希望世界在未来几个世纪内经济快速增长，这就是具有约束力的约束。</p><br/><br/><a href="https://www.lesswrong.com/posts/NWvZ64XNCER7naqLw/fertility-as-metascience#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/NWvZ64XNCER7naqLw/fertility-as-metascience<guid ispermalink="false"> NWvZ64XNCER7naqLw</guid><dc:creator><![CDATA[Maxwell Tabarrok]]></dc:creator><pubDate> Sat, 25 Nov 2023 15:42:41 GMT</pubDate> </item><item><title><![CDATA[Reaction to "Empowerment is (almost) All We Need" : an open-ended alternative]]></title><description><![CDATA[Published on November 25, 2023 3:35 PM GMT<br/><br/><p><br>即将到来的框架类似于询问的过程：<br> “[这个选项]真的能给最高数量的存在[更多的选择]吗？”<br><br><br><strong>要点：</strong><i>在最坏的情况下，许多人认为这是默认情况，人类将创建一个</i><a href="https://www.lesswrong.com/tag/squiggle-maximizer-formerly-paperclip-maximizer"><i>最大化器</i></a><i>。我认为，对于最大化者（人工智能或非人工智能）来说，在具有生态系统协同作用的非短视过程中优化的最不有害的事情是[宇宙中状态的多样性]。</i><br> <i>（长期共同承担期权）</i><br><br><i>如果以下分析正确，它本质上会将最大化转化为有价值的输出。</i><br><i>这一过程背后的原因揭示了易于处理的普遍伦理的基础。</i><br><br><br>此讨论是对<a href="https://www.lesswrong.com/users/jacob_cannell">jacob_cannell</a><a href="https://www.lesswrong.com/posts/JPHeENwRyXn9YFmXc/empowerment-is-almost-all-we-need">帖子</a>的回应；<br>其中通过（无私的）“赋予他人权力”来展示人工智能的一致性<br></p><p><strong>TLDR：</strong>从我在评论中读到的内容来看，我们可以将问题浓缩为定义“权力”的困难（在这种情况下是“他人赋权”；与自我赋权相对），因为它可能导致人工智能“瘫痪”人类/智能体以“扩大”动作潜力（这是非常短视的），或者相反，人工智能可能会禁止人类/智能体处于次优状态（即，你不能流放到山里）。</p><p><br>对我来说，关键节点/困难是一个威胁（ <a href="https://www.lesswrong.com/posts/JPHeENwRyXn9YFmXc/empowerment-is-almost-all-we-need?commentId=z5Ai6vEDrydFCrFfh">这里提到</a>），人工智能将“消除你和最长期主义版本的你之间的所有实际差异”；这就是为什么我提出一种基于选择性和多样性的替代方案。<br></p><p> ────────────────────────<br><strong><u>通用选择性</u></strong><u>：</u><br>我们的时空“区域”有一个独特的机会来绽放全球时空其他地方不存在的<i>独特</i>属性（因此与其他过去、现在<i>和</i>未来时空相比）<br> + 最终状态应该具有尽可能多的多样性<br></p><p><i><strong>开放式进化：</strong> “指的是复杂性的无限增加，这似乎是多尺度进化的特征”（Corominas-Murtra、Seoane &amp; Solé，2018）。</i><br><br><i><strong>不可约性：</strong> “虽然许多计算承认快捷方式可以使它们执行得更快，但其他计算却无法加速。无法通过任何快捷方式加速的计算被称为计算不可约。”计算不可约性 – Wolfram MathWorld</i></p><p></p><p><a href="https://alife.org/encyclopedia/introduction/open-ended-evolution/">开放式</a>生态系统具有<a href="https://mathworld.wolfram.com/ComputationalIrreducibility.html">不可简化的</a>状态/功能/选项，只能以正确的独特（“<a href="https://en.wikipedia.org/wiki/Endemism">地方性</a>”）速度出现，<br>它还创造了一种固有的不确定性，为人类/代理提供了更大的自由度（你可能会有些次优，并且不会严格授权自己）。<br></p><p> ────────────────────────<br></p><blockquote><p>在最坏的情况下，许多人认为这是默认情况，人类将创建一个<a href="https://www.lesswrong.com/tag/squiggle-maximizer-formerly-paperclip-maximizer">最大化器</a>。<br>我认为，对于最大化者来说，危害较小的优化是<i>在具有生态系统协同作用的非短视过程中的[宇宙状态的多样性]。</i></p></blockquote><p><br>我所说的“宇宙状态的多样性”是指：<br>尽可能拥有最不近视的多样性形式，其中考虑到宇宙的未来和过去状态。这导致了生态系统的<i>必要性</i>，<i><strong>并</strong>关心它</i>；因为如果没有生态系统，你就无法向更多国家开放宇宙。每一个行动都必须仔细权衡，因为它<i>破坏的国家可能多于它创造的国家。</i><br></p><p>协调的挑战是找到一个<i>问题</i>，解决这个问题后，人工智能不仅会做我们人类认为我们想做的事（带着我们的妄想）；<a href="https://www.lesswrong.com/tag/coherent-extrapolated-volition"><i>而是我们真正需要的</i></a>。</p><p><br>我认为，除了“危害较小”的结果之外，即使在最好的情况下，我们<i>真正</i>需要<i><strong>的是</strong></i>大量性质不同的状态；</p><p>它们的差异性和协同性（共同增加的选项）越多，效果就越好；这是增加“多样性维度”数量的过程。<br>例如：1010101010 的多样性维度小于 0123456789。<br><br>因为真正的多样性不仅仅是线性交替两种状态，我们想要一个关心创建更多选项和“复杂性”/“复杂性”的程序。<br>但人们常常争论不要使用如此模糊的词语。</p><p><br><br>那么让我们澄清一下这些话：</p><p> <strong>1)</strong><i>系统中计算/循环的定性多样化的结构/模式/刺激</i></p><p>->; 在所有可能的不同状态的连续空间（一种语义空间）中，<br>两个州之间的<i>距离</i>越远，<i>质的</i>差异就越大；</p><p>它就像色环中的颜色。这是一个<a href="https://subconscious.substack.com/p/search-reveals-useful-dimensions">潜在的空间</a>。 “黑色”与“白色”的区别比与“灰色”的区别更大。 “猫”与“狗”的关系比与“椅子”的关系更近。</p><p> （单个对象是一个类别，即[我的蓝狗]，但与同一元类别的其他对象非常相似；即[蓝狗]，它们与之共享较低的多样性“指数”）<br></p><p>所以我所说的复杂性/复杂性与这种质量多样性密切相关。您只需将 1) 与：</p><p> <strong>2）</strong><i>系统的因果力</i></p><p>->; 由系统/子系统引起的性质不同的外部变化的数量</p><p><br></p><p>这种[宇宙状态的多样性]过程导致了开放性的最大化，这需要关心生态系统，否则事物就会崩溃；质量多样性<i>消失了</i>。</p><p> ->; 这是第一层，在其他任何层之前，允许进行一般的、原始的对齐。<br><br></p><p><br>目标是最大程度地发挥协同作用，<br>在最大的多样性中，<br>具有最大的选择性。<br><br> alterity（他者性）的反义词是 ipseity（自我性）<br>我说的是介于两者之间的：“协同作用”</p><p>您可以添加越来越多的明确层来通过以下方式校准我们偏好的三角测量：</p><p> 。<a href="https://en.wikipedia.org/wiki/Cultural_universal">人类普遍</a></p><p>但一层越基础，它就越能取代其他层，在决策中占据优先地位（也更加程序化、隐式，避免奖励隧道/曲线）</p><p>例如，它可以是（越来越明确，从更基本到不太基本）：<br><i>开放式多样性</i><br><i>普遍的选择性</i><br><i>生态系统协同作用</i><br><i>其他赋权</i></p><p>存在高度且连续的重叠；<br>在此基础上，上层/工具可以带来更精准/局部的福祉：<br> 。<a href="https://www.youtube.com/watch?v=vSQjk9jKarg&amp;list=WL&amp;index=39">持续时间最长的幸福研究揭示了什么</a><br>。<a href="https://en.wikipedia.org/wiki/Moral_foundations_theory">道德基础理论</a><br>。<a href="https://www.sciencedaily.com/releases/2019/03/190304134216.htm">世界各地发现的七个道德规则</a><br>。<a href="https://psyarxiv.com/srjyq/">模块化道德：道德的遗传结构作为合作</a><br>。<a href="https://en.wikipedia.org/wiki/Evolution_of_morality">道德与进化生物学</a><br>+ <a href="https://plato.stanford.edu/entries/morality-biology/">https://plato.stanford.edu/entries/morality-biology/</a><br> 。<a href="https://journals.sagepub.com/doi/10.1177/00220221221126419">理想社会的概况：普通人的乌托邦愿景</a></p><p><br>────────────────────────</p><p><br>其目的是提供可供性、接近<a href="https://geometrymatters.com/patterns-of-innovation/">邻近可能性的机会</a>、扩大行动空间和最大程度的现象的自主性。这种选择性方法可能会解决<a href="https://www.lesswrong.com/tag/consequentialism">结果主义</a>中许多长期存在的棘手问题，例如<a href="https://www.lesswrong.com/tag/wireheading">线头</a>或定义幸福/效用的巨大困难；即使在这个定义中犯下最微小的错误也可能造成灾难性的后果。<br><br>例如：局部的/短视的/短暂的幸福通常是有害的（以自我为中心的兴趣、成瘾等），而局部的痛苦可能是有益的（训练、家庭聚餐）。</p><p></p><p> [整个宇宙的<i>过去和未来</i>时间线]范围内的开放性和选择性意味着将过程保持在完美（<a href="https://en.wikipedia.org/wiki/Critical_phenomena">关键</a>）最佳点允许在最后（最宽的时间范围）实现最多样化的状态/出现/开放性。</p><p>它让生态系统有时间生长和相互作用，以便它们能够绽放/突变独特/不可简化的因果链，而这些因果链不可能以更高（或更慢）的速度发生。<br><br><br>它可以是非线性的，即。有时你需要限制选项的数量，以免被可能性所冻结。增加选择意味着选择能力的增加。限制是这些选择（理想情况下）必须不会破坏其他代理/人类/野生动物的有意义的选择......之后选择者可以选择自己适合的方式。并且始终增加这种选择性，抢占锁定。<br><br>虽然人工智能对你了解越多，它就越能帮助你，正如我们所看到的，原始层<i>并不完全</i>是“赋予他人权力”，而是一种更<strong>普遍的</strong>关怀。<br>它可能会导致一定程度的不确定性增加，<i>但它更多的是一个功能而不是一个错误；</i><br> <i>->;</i>人工智能将受到尊重<i> </i>你的[（不可简化的）偏好]与它对更广泛的充满事物的生态系统的关注成正比。</p><p><br>人工智能的作用是仲裁违背普遍开放性的冲突行为；局部次优的定义是如此复杂，如何确定当你（人类）决定流亡到山里时，从长远来看，它实际上不会对你和每个人都有好处？<br> ->; 这种不确定性导致了隐含的自由度，我们<i>也</i>可以显式地进一步增加它；通过对次优的更多容忍来缓解<a href="https://www.lesswrong.com/tag/utilitarianism">功利主义</a>错误。</p><p></p><p> ────────────────────────<br></p><p>我的一些重要参考资料：<br><br> 。<a href="https://www.effectivealtruism.org/articles/ea-global-2018-paretotopian-goal-alignment">帕雷托托邦</a><br><br>。<a href="https://arxiv.org/abs/2107.09598">在没有外部奖励的强化学习中学习利他行为</a></p><p>。 <a href="https://www.lesswrong.com/posts/dPmmuaz9szk26BkmD/shortform?commentId=jMitxvhFceaheD5zb">希波克拉底原则-Vanessa Kosoy</a><br><br> 。 <a href="https://arxiv.org/abs/2306.01711">OMNI：通过人类兴趣概念模型的开放性</a></p><p>。 <a href="https://forum.effectivealtruism.org/posts/zy6jGPeFKHaoxKEfT/the-capability-approach-to-human-welfare">人类福祉的能力方法</a></p><p>。<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10322209/">复活盖亚：利用自由能原理来保护我们所知的生命</a><br><br>。<a href="https://gcrinstitute.org/papers/061_ai-world-universe.pdf">​从人类的人工智能到世界和宇宙的人工智能​</a></p><p>。<a href="https://plato.stanford.edu/entries/autonomy-moral/">道德与政治哲学中的自主性</a></p><br/><br/><a href="https://www.lesswrong.com/posts/JLiMLikBbkye7k5Y5/reaction-to-empowerment-is-almost-all-we-need-an-open-ended-1#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/JLiMLikBbkye7k5Y5/reaction-to-empowerment-is-almost-all-we-need-an-open-ending-1<guid ispermalink="false"> JLiMLikBbkye7k5Y5</guid><dc:creator><![CDATA[Ryo ]]></dc:creator><pubDate> Sat, 25 Nov 2023 15:35:41 GMT</pubDate></item></channel></rss>