<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 22 日星期三 06:16:23 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Portable Chargers are Great]]></title><description><![CDATA[Published on November 22, 2023 2:50 AM GMT<br/><br/><p><span>便携式充电器很棒但被低估了。只需</span><a href="https://www.amazon.com/Portable-Charger-26800mAh-Capacity-External/dp/B08729Z2JX">20 美元，</a>您就可以获得一个小盒子，可为手机充电约 5 次，或为笔记本电脑充电约 1 次。 [1] 您可以多花一点钱购买带有<a href="https://www.amazon.com/VRURC-Portable-20000mAh-Charging-Replacement/dp/B0CDZNB954/">内置壁式充电和电缆的</a>产品。在我的背包里放一个这样的东西真是太棒了，我知道我<a href="https://www.jefftk.com/p/rationing-spells-and-battery">不必配给或担心</a>，尤其是在旅行时。如果孩子的平板电脑电量不足、朋友需要充电，或者没有一个好的地方可以让我的手机过夜，这都不是问题。</p><p>一般来说，27,000 mAh 是一个不错的上限：超过这个尺寸，您的航空公司可能会受到限制（尽管<a href="https://www.faa.gov/hazmat/packsafe/lithium-batteries">FAA</a>允许航空公司允许高达 44,000 mAh）。一旦你变得这么大，为了灵活性和冗余的好处而购买两个可能更有意义。</p><p>我第一次得到一个是在 2017 年，它仍然运行良好（尽管 USB-C 端口有点松动）：</p><p> <a href="https://www.jefftk.com/portable-charger-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/EXzh7sg2XE9yrzJPW/kvmotqrjkzxekbs4vdmf" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/EXzh7sg2XE9yrzJPW/kvmotqrjkzxekbs4vdmf 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/EXzh7sg2XE9yrzJPW/naxbqgpho8tn45n1f9ku 1100w"></a></p><div></div><p></p><p>从那以后，我又买了几个，这样孩子们就可以在长途旅行时为他们的平板电脑准备单独的平板电脑。</p><p><br> [1] 这里的数学很糟糕：容量应该以瓦时为单位来测量，但每个人都以相对于某些隐含电压的毫安时为单位给出。对于 USB 移动电源来说，电压（总是？）为 3.6V，因此 26,800 mAh 为 96 Wh。我的手机容量为<a href="https://store.google.com/us/product/pixel_7a_specs">4,385 mAh</a> ，电压为 3.85V，即 17 Wh。我的笔记本电脑的<a href="https://support.apple.com/kb/SP858">瓦时规格</a>非常有用：99.6 瓦时。请注意，您确实会因转换损失而损失一些容量，因此请稍微折扣一下。</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid02TPqYLHSR1vaKdiucf83amFqXosWbNe9du1Npn6AqDg9NpZp9pswii4AohKq2nR6gl">facebook</a> , <a href="https://mastodon.mit.edu/@jefftk/111451918105265115">mastodon</a></i></p><br/><br/><a href="https://www.lesswrong.com/posts/EXzh7sg2XE9yrzJPW/portable-chargers-are-great#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/EXzh7sg2XE9yrzJPW/portable-chargers-are-great<guid ispermalink="false"> EXzh7sg2XE9yrzJPW</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Wed, 22 Nov 2023 02:50:13 GMT</pubDate> </item><item><title><![CDATA[Atlantis: Berkeley event venue available for rent]]></title><description><![CDATA[Published on November 22, 2023 1:47 AM GMT<br/><br/><p>理性社区内外的许多活动都在伯克利举办，可能需要活动空间。这是一个公告，<strong>伯克利有一个名为亚特兰蒂斯的场地</strong>，非常适合举办此类活动。它以前是联谊会的房子，所以适合很多人，并且被适当地划分为举办静修会和研讨会（在伯克利，这是令人惊讶的难以划分的区域）。<strong>您可以</strong><a href="https://forms.gle/wDfPnPjPfqvQZaTFA"><strong><u>在这里预订</u></strong></a><strong>。</strong>该场地不限于以任何方式举办理性活动（这些活动也不会获得折扣），但它非常适合理性主义者似乎举办的活动类型，<strong>有舒适的讨论空间、周围有白板和非常愉快和富有成效的环境。</strong></p><h2><strong>场馆概况</strong></h2><ul><li>38 间卧室，最多可容纳 80 人</li><li>20,500 平方英尺英尺</li><li>~4 个大型室内公共区域和 ~2 个小型室内公共空间</li><li>2 个大型室外公共区域，2 个小型室外公共区域</li><li>商用厨房</li><li>3 间独立的全套浴室、4 间半浴室和 4 间共用浴室（每间有 3 个隔间和 3 个淋浴间）</li><li>健身房</li><li>配备并备有活动用品</li><li>请联系我们获取平面图、房间详细信息等。</li></ul><p> <i><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/wlcdqbsyivchy8bgqdix"></i> </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/o90lhpipwlgis1zeyevy"></p><h2>价钱</h2><p>定价是可以协商的，并且基于什么策略可以为场地带来最大的收入（不是基于我们对您的活动的喜欢程度，尽管我们真的很喜欢在这个空间举办的很多活动！）</p><p>默认定价：</p><ul><li>基本费用：</li><li><u>完整场地使用（过夜住宿）</u><ul><li>充分使用场地（包括所有卧室）的基本费用为 7,000 美元。这是为了支付员工成本并鼓励更长的租赁期。</li><li>每天 5,500 美元。如果我们假设场地的利用率约为 50%，那么我们需要收取多少费用才能收回年租金、改进的摊销成本以及维护成本。</li></ul></li><li><u>场地使用（不含住宿）</u><ul><li><u>仅限一楼</u><ul><li>10 - 30 人：$250/小时</li><li>30 - 60 人：$350/小时</li><li>60 - 100 人：500 美元/小时</li><li>最大限度。每天 5,500 美元</li></ul></li><li><u>一楼和二楼</u><ul><li>$550/小时；最大限度。每天 5,500 美元</li></ul></li></ul></li></ul><p>除了基本费用外，还需支付额外的清洁费用、使用我们的现场消耗品（例如个人洗漱用品、活动挂图等）、损坏场地或占用员工大量时间的费用。我们将向您收取最终费用（因此，如果您将宫殿弄得非常凌乱，我们将收取比您不这样做时更高的清洁费）。在为您的活动进行购买或让工作人员花费时间之前，我们会询问您，我们将在您的活动中向您收取费用。</p><h2>常问问题</h2><p><strong>定价是不是有点贵了？</strong></p><p>这个空间的定价旨在实现收支平衡，而海湾的价格昂贵。这需要较高的价格。我们意识到这个定价对于许多类型的活动来说没有意义。请告知我们费用是否过高，我们将看看是否可以达成协议。</p><p><strong>与该地区的其他场馆相比如何？</strong></p><p><a href="https://www.ventureretreat.org/"><u>创业静修中心</u></a></p><ul><li>~$13.6k/天（尽管我听过他们对不同事件的不同报价）</li><li>距伯克利 1 小时 44 分钟车程</li><li>最大容量：~42 人</li></ul><p><a href="https://www.triplesranchnapa.com/"><u>三重S牧场</u></a></p><ul><li>前 13 人每人 850 美元，入住卧室的客人每晚每人 450 美元。因此，标准 34 人活动每晚 20,500 美元。</li><li>距伯克利 1 小时 23 分钟车程</li><li>最大容量~60人</li></ul><p><strong>它在哪里？</strong></p><p>在伯克利，步行约 10 分钟即可到达加州大学伯克利分校校园，步行 10 分钟即可到达伯克利山徒步旅行。步行 20 分钟即可到达 BART 车站/市中心。出于安全原因，我们不会公开分享确切的地址。</p><p><strong>什么时候可以使用？</strong></p><p>请填写查询表以了解可用性！</p><p><br>如果您有任何疑问，请随时通过<a href="mailto:info@atlantisvenue.com"><strong><u>info@atlantisvenue.com</u></strong></a><strong>与我们联系</strong><strong>！</strong><br></p><h2>附加照片</h2><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/d2jzxtqcia32idrxroob"></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/jmeltyzj7vmxxi00pgdt"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/gd2youlaftpvbk8gfhig"></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/t01ruiqxwih5ve8po7o8"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/nq7voiyiqylwkhjkgr7z"></p><p> <i><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/pifwhtxhj2btnqdrmi0n"></i></p><p> <i><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/v6di4zmk0cbk9ewhzvqc"></i></p><p> <i><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/g0ahrp7aaaoqrkbgchln"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/emphtzwk2ncvqafyydsm"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pvz53LTgFEPtnaWbP/xekc6cwxbkfoifhduwn1"></i></p><p><br></p><br/><br/> <a href="https://www.lesswrong.com/posts/pvz53LTgFEPtnaWbP/atlantis-berkeley-event-venue-available-for-rent#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/pvz53LTgFEPtnaWbP/atlantis-berkeley-event-venue-available-for-rent<guid ispermalink="false"> pvz53LTgFEPtnaWbP</guid><dc:creator><![CDATA[Jonas Vollmer]]></dc:creator><pubDate> Wed, 22 Nov 2023 01:47:12 GMT</pubDate> </item><item><title><![CDATA[How much should e-signatures have to cost a country?]]></title><description><![CDATA[Published on November 21, 2023 10:45 PM GMT<br/><br/><h1> 190 亿美元用于瑞士政府的电子签名？</h1><p><i>我的直觉是，LW 是一个提出这个问题的好地方 - 如果它与主题无关，我热衷于将其删除。</i></p><p>读起来我很困惑</p><blockquote><p>瑞士联邦斥资高达 170 亿瑞士法郎购买了一大堆电子签名。</p></blockquote><p>这是7年期间，总共有大约1.2亿个各种类型的签名和印章（如果我没理解错的话）：</p><blockquote><p>其基础是计算出的数字签名数量。在整个招标过程中，历时7年，共计算了约3000个需求点的4300万个合格签名、4300万个高级签名和3200万个电子印章。</p></blockquote><p> <a href="https://www.inside-it.ch/ohne-kulturwandel-in-der-verwaltung-nuetzen-e-signaturen-nichts-20231109">我有这篇文章</a>（德语）（ <a href="https://docs.google.com/document/d/13ObZwBJHoqUUB8UgCTiA1Xvb8TFiCVmYJkQAwLPNRPI/edit?usp=sharing">EN 翻译</a>）， <a href="https://www.inside-it.ch/ohne-kulturwandel-in-der-verwaltung-nuetzen-e-signaturen-nichts-20231109"> </a>讨论了一些细节，包括。印章与签名的区别。但我并不完全理解它。特别是，我看不到任何东西可以让我真正理解为什么瑞士政府为这项服务花费近 170 亿瑞士法郎（190 亿美元）是合理的。</p><p>有谁知道成本的数量级是否真的可能是一个看似合理的上限，而不仅仅是一个定价过高的服务？如果是的话，你能捐两分钱吗？ （双关语无意，但既然它在这里，问题可能会被重新表述：为什么每个签名不必只有 2 美分左右，而是很多法郎？）</p><p>我想主要是无关紧要的背景：瑞士约有 900 万公民。</p><br/><br/> <a href="https://www.lesswrong.com/posts/3dWm9D7jBe56YmmwX/how-much-should-e-signatures-have-to-cost-a-country#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/3dWm9D7jBe56YmmwX/how-much-should-e-signatures-have-to-cost-a-country<guid ispermalink="false"> 3dWm9D7jBe56YmmwX</guid><dc:creator><![CDATA[FlorianH]]></dc:creator><pubDate> Tue, 21 Nov 2023 22:45:50 GMT</pubDate> </item><item><title><![CDATA[My first conversation with Annie Altman]]></title><description><![CDATA[Published on November 21, 2023 9:58 PM GMT<br/><br/><p> 《全人类都是人类》播客上的第一次对话<br><br>我们讨论了个人和社会层面的安全。<br><br>未来可能会讨论导致大规模灭绝的长期驱动因素。<br><br> （11 月 13 日星期一录制，由于某种原因我的声音在 1 点 09 点中断）。<br></p><br/><br/> <a href="https://www.lesswrong.com/posts/kiMGzJWtcPHRrQ9WA/my-first-conversation-with-annie-altman#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/kiMGzJWtcPHRrQ9WA/my-first-conversation-with-annie-altman<guid ispermalink="false"> KIMGzJWtcPHRrQ9WA</guid><dc:creator><![CDATA[Remmelt]]></dc:creator><pubDate> Tue, 21 Nov 2023 21:58:45 GMT</pubDate> </item><item><title><![CDATA[To what extent do elites already want AI for derivatives trading?]]></title><description><![CDATA[Published on November 21, 2023 7:35 PM GMT<br/><br/><p>我想知道广泛使用人工智能来改善衍生品交易是否已经成为推动政府和大公司在经济方面而不是军事应用或<a href="https://www.lesswrong.com/posts/jyAerr8txxhiKnxwA/5-reasons-why-governments-militaries-already-want-ai-for">信息战</a>方面追求人工智能加速的主要原因。</p><p>它还可能有助于解释为什么许多强大的、具有量化思维的精英痴迷于人工智能加速；其中很大一部分来自华尔街，已经从人工智能中受益匪浅。但仍然处于信任度极低的环境中，对新信息（例如人工智能安全概念）背后的利润动机的强烈怀疑仪式化。这也可能是微软对人工智能感兴趣以及中国政府追求的驱动因素。</p><p>我已经六年没有考虑过衍生品了。我愿意在这个主题上展示我潜在的无知或天真，因为我不介意花费贝叶斯/声誉点来尽快为人工智能安全社区获得更好的世界模型。我目前对衍生品交易的理解是：</p><ol><li>在进行交易时，人们在以下方面存在很大差异：1）现在评估金钱，2）以后评估金钱，3）信息不对称和某些主题的专业化，以及4）与某些人和机构而不是其他人和机构进行信任/交易的能力。</li><li>衍生品允许交易者使用计算机和线性代数将所有这四个因素考虑在内，并消除两个交易者之间的差异；例如，如果一个交易者现在更喜欢货币/流动性，而另一位交易者稍后更喜欢货币/流动性，则衍生品会绘制他们随时间的偏好差异，并找出它们之间的差异，从而促进其价值随着他们的货币/流动性偏好而变化的贷款。时间。</li><li>除了允许两个交易者绘制货币价值随时间变化的差异以促进套利之外，它还可以绘制信息不对称随时间变化之间的变化（随着世界事件的展开并成为公众知识，例如美国财政部）债券利率下降或上升），以及信任随着时间的推移而变化，例如，随着华尔街上的一些友谊加深，而其他友谊由于在某些时候发生背叛的风险而具有贴现率。</li><li>衍生品市场允许数百人预测和计算这些偏好和知识随时间的变化，并与市场上其他人的差异进行套利。</li><li>衍生品市场在 50 年前的 20 世纪 70 年代地缘政治和经济动荡期间出现，技术和最佳实践可能在这 5 个十年中取得了巨大进步（可能在某些几十年中比其他几十年进步更多）。</li><li>由于焦点较弱，我怀疑衍生品市场是否与预测市场一样好。我认为 FTX 可能已经擅长思考如何结合两全其美的方法。</li></ol><p>我想知道的是，人工智能在多大程度上已经向华尔街人士展示了促进或提高衍生品市场效率的巨大价值？</p><p>这是否值得考虑，或者（在他们看来）它的重要性远不如使用高级人工智能来进行对抗性股票交易之类的事情？这对于了解精英对人工智能的看法的现状似乎非常有价值。它还可能表明， <a href="https://www.lesswrong.com/posts/foM8SA3ftY94MGMq9/assessment-of-intelligence-agency-functionality-is-difficult">情报机构不仅可以通过从华尔街招募大量贝叶斯思想家的技能库</a>，而且这些贝叶斯思想家在过去 10 年里也对人工智能印象深刻。</p><br/><br/> <a href="https://www.lesswrong.com/posts/MF64DA5HqybNZe6Ls/to-what-extent-do-elites-already-want-ai-for-derivatives#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/MF64DA5HqybNZe6Ls/to-what-extent-do-elites-already-want-ai-for-derivatives<guid ispermalink="false"> MF64DA5HqybNZe6Ls</guid><dc:creator><![CDATA[trevor]]></dc:creator><pubDate> Tue, 21 Nov 2023 19:35:58 GMT</pubDate> </item><item><title><![CDATA[Userscript to always show LW comments in context vs at the top]]></title><description><![CDATA[Published on November 21, 2023 5:53 PM GMT<br/><br/><p>当我导航到评论时，脱离上下文的顶级评论总是让我烦恼，但直到最近我还没有意识到有一种方法可以通过简单的 URL 更改来转到实际评论。<br><br>来自<code>https://www.lesswrong.com/posts/&lt;postid>;/?commentId=&lt;commentid>;</code><br>至<code>https://www.lesswrong.com/posts/&lt;postid>;#&lt;commentid>;</code><br><br>这是一个快速生成的 gpt4 用户脚本，可以执行此操作。</p><pre> <code>// ==UserScript== // @name Always show in-context comments // @namespace http://tampermonkey.net/ // @version 0.1 // @description Redirect from &#39;?commentId=&#39; format to &#39;#&#39; // @author Vlad Sitalo // @match https://www.lesswrong.com/* // @grant none // ==/UserScript== (function() { &#39;use strict&#39;; var checkAndRedirect = function() { var url = window.location.href; if(url.includes(&quot;?commentId=&quot;)){ var newUrl = url.split(&quot;?commentId=&quot;).join(&quot;#&quot;); window.location.href = newUrl; } }; // Run on page load checkAndRedirect(); // Run on URL change var pushState = history.pushState; history.pushState = function() { pushState.apply(history, arguments); checkAndRedirect(); }; var replaceState = history.replaceState; history.replaceState = function() { replaceState.apply(history, arguments); checkAndRedirect(); }; window.addEventListener(&#39;popstate&#39;, checkAndRedirect); })();</code></pre><br/><br/> <a href="https://www.lesswrong.com/posts/j9YvcPaf4BKbJ6fvD/userscript-to-always-show-lw-comments-in-context-vs-at-the#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/j9YvcPaf4BKbJ6fvD/userscript-to-always-show-lw-comments-in-context-vs-at-the<guid ispermalink="false"> j9YvcPaf4BKbJ6fvD</guid><dc:creator><![CDATA[Vlad Sitalo]]></dc:creator><pubDate> Tue, 21 Nov 2023 17:53:31 GMT</pubDate> </item><item><title><![CDATA[Dialogue on the Claim: "OpenAI's Firing of Sam Altman (And Shortly-Subsequent Events) On Net Reduced Existential Risk From AGI"]]></title><description><![CDATA[Published on November 21, 2023 5:39 PM GMT<br/><br/><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 03:24:22 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 03:24:22 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>我看到/听到 LW-o-sphere 中的一群人说上周末的 OpenAI 公司闹剧显然很糟糕。我不太确定为什么人们会这么想？对我来说，总体而言，这似乎是一个非常明显的积极结果。</p><p>我很好奇为什么世界上的人们对此不满意（LW 领域的人们，也就是说，显然我可以理解为什么例如人工智能加速主义者会对此不满意）。我还想展示我的模型。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 03:33:26 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 03:33:26 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>这是我的高光版本。主要成果是：</p><ul><li>相对最关注 AGI 竞争、最不关注安全的领导层正在从 OpenAI 转向微软。许多对通用人工智能竞赛比对安全更感兴趣的员工可能会效仿。</li><li>微软是那种充满活力的组织/创始人/研究人员走向消亡的官僚企业。我的平均预期是，无论前 OpenAI 团队最终的结果如何，其生产力都将远远低于他们在 OpenAI 时的生产力。</li><li> OpenAI 是否会继续存在还是一个悬而未决的问题。<ul><li>就他们所做的而言，他们不太可能推动最先进的能力，而更有可能专注于安全研究。</li><li>就他们关闭而言，主要的最终结果将是一群对 AGI 竞争更感兴趣、不太关注安全的人转向微软，这很好。 </li></ul></li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 03:37:46 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 03:37:46 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>我目前（可能是错误的）对为什么 LW 领域的其他人说这很糟糕的最佳猜测：</p><ul><li>结果推特上显然出现了很多对 EA 的仇恨。我个人认为，从长远来看，这一点即使有影响也微乎其微，但我预计它对于理性主义者/EA/结盟人士来说极其重要。</li><li> OpenAI 是一个拥有很多 AGI 加速主义者的组织，也许人们认为 OpenAI 正在将这些加速主义者的冲动引向更安全友好的方向，而微软不会？</li><li>显然，董事会的执行情况相对较差。他们应该分享解雇的原因/借口。 （出于某种原因，在政治/企业政治中，人们总是试图保持秘密，在我看来，在 80% 以上的情况下，这似乎是非常愚蠢的，包括这个。）我不认为这个错误从长远来看，这实际上非常重要，但我可以理解为什么人们关注它最终会对董事会的行为产生某种普遍的负面影响。 </li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 03:40:18 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 03:40:18 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>（快速警告，我认为一旦有更多信息出现，这个问题就会更容易判断。也就是说，我认为即使现在思考它对于思考和分享相关的观察和考虑也是有用的。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 03:44:46 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 03:44:46 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>我认为 Sam 和其他最终加入微软的人的遭遇是一个相当大的症结。如果我认为那些去微软的人确实会陷入官僚主义，无法取得那么多的成就，而那些留下来的人也不会追求那么多，这可能会让整个事情对 x 风险有利。</p><p>我对此并不是非常有信心，但我的印象是，萨玛可能有足够的能力来打破官僚机构并完成很多工作，而且更重要的是，通过有能力并获得人工智能，最终可以管理微软的大部分业务。与整个 OpenAI 投资周期相比，在那里他可以用更少的精力获得更多的资源，并且比在 OpenAI 时受到的限制更少。<br><br>一个问题是他如何能够独立运作。纳德拉提到 LinkedIn 和 Github（？）在微软内部相当独立运营。此外，我认为微软会觉得他们必须对萨马“友善”，因为他很可能是他们在人工智能领域占据主导地位的关键。他显然拥有一批追随者，并且可以去其他地方，我怀疑他是否设置了拖慢他速度的官僚主义。</p><p><br>到目前为止，一个悬而未决的问题是董事会是否诚信（/合作）行事。如果董事会被认为代表了最受人工智能关注的集群（我们是其中的一部分）并且他们的行为非常糟糕，那么这本身对于我们（集群）合作或移动事物的能力来说可能真的很糟糕更广阔的世界朝着好的方向发展。就像，可能比与 SBF 的任何关联都要糟糕得多。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 03:51:39 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 03:51:39 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>到目前为止，一个悬而未决的问题是董事会是否诚信（/合作）行事。如果董事会被认为代表了最受人工智能关注的集群（我们是其中的一部分）并且他们的行为非常糟糕，那么这本身对于我们（集群）合作或移动事物的能力来说可能真的很糟糕更广阔的世界朝着好的方向发展。就像，可能比与 SBF 的任何关联都要糟糕得多。</p></blockquote><p>我记得在 Sam-Bankman-Fried-pocalypse 事件发生后不久，很多老鼠/EA/等等都非常关注这将如何玷污 EA 等的声誉。一年后，我认为……事实并非如此坏的？就像，我们总体上仍然是一个相对较高诚信的群体，从长远来看，公关会平衡以反映潜在的现实。是的，有一些坏苹果，公关也平衡地反映了现实，这很好，就我担心公关而言（这并不多），我主要只是希望它是准确的。</p><p>我认为，对于 EA/联盟研究人员等来说，这对于其他人来说似乎更加重要，与它实际的重要性远远不成比例，我们需要对此进行调整。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 03:53:23 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 03:53:23 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>（旁注：我还想在这里说“诚信比公关更重要”之类的话，而上周末发生的事件看起来更像是公关问题，而不是诚信问题。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 03:58:28 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 03:58:28 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><blockquote><p>一年后，我想……还没有那么糟糕吗？</p></blockquote><p>不同意，或者至少，我认为我们还不知道。<br><br>我同意我们不会继续在网上听到仇恨，该团体仍在继续并吸收了新成员，生活似乎还在继续。而且，在这个周末事件没有发生的世界中（我认为它们可能会使发生的事情相形见绌，或者可能使它们复杂化），我认为 SBF 协会很可能会影响关键事件和在世界上运作的能力。<br><br>有一些所谓的“站在权力杠杆一边”的策略，我不知道它们是否好，但是诸如在公司和政府内部担任职位之类的事情可以让你推动更好的人工智能成果，我确实认为 SBF可能会让事情变得更加困难。<br><br>如果 Jason Matheny 一直在 SBF 之后寻找职位（Whitehouse、RAND 等），我认为成为一名知名 EA 可能是一种真正的负担。一年后这并没有明显可见，但我敢打赌我们还没有完全失去这种联系。我认为本周末的活动也可以说是出于 EA 典型动机。这使得我们的集群更难被信任成为合作/诚信/有能力的合作伙伴。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 03:59:53 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 03:59:53 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>我对此并不是非常有信心，但我的印象是萨玛可能有足够的能力消除官僚机构并完成很多工作，而且更重要的是，通过有能力并获得人工智能，最终运行了微软的大部分业务。与整个 OpenAI 投资周期相比，在那里他可以用更少的精力获得更多的资源，并且比在 OpenAI 时受到的限制更少。<br><br>一个问题是他如何能够独立运作。纳德拉提到 LinkedIn 和 Github（？）在微软内部相当独立运营。此外，我认为微软会觉得他们必须对萨马“友善”，因为他很可能是他们在人工智能领域占据主导地位的关键。他显然拥有一批追随者，并且可以去其他地方，我怀疑他是否设置了拖慢他速度的官僚主义。</p></blockquote><p>据我所知，萨玛以前从来没有在大官僚公司呆过多久？他曾在一家风险投资公司和初创公司工作。</p><p>最重要的是，从远处看，我的不太了解的印象是，他更像是一个微笑和碰肘的人，而不是一个真正的技术经理；我认为他在 OpenAI 的日常工作并不多？不过，我对这方面信心不足，因为我没有从熟悉的消息来源那里听到这一点。</p><p>不过，这个等式的另一边的不确定性较小。纳德拉提到<i>Linkedin</i>是微软的成功，我觉得很搞笑。该产品在被收购之前就达到了顶峰。微软从中投入了大量资金，但他们肯定没有改进它。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 04:01:35 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 04:01:35 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>我同意 LinkedIn 正在走下坡路，所以确实比我更支持你的立场。尽管如此，似乎还是有收购独立运作的先例。 Instagram，我想。皮克斯。当然还有其他保持很多自由的地方。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:02:51 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:02:51 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>一年后这并没有明显可见，但我敢打赌我们还没有完全失去这种联系。我认为本周末的活动也可以说是出于 EA 典型动机。这使得我们的集群更难被信任成为合作/诚信/有能力的合作伙伴。</p></blockquote><p>需要明确的是，我基本上同意这是一种机制。我完全认为董事会犯了一些非受迫性的公关错误，并因此烧毁了一些 EA 公共资源。我只是认为它远没有其他影响那么重要，并且 EA 对此给予了过多的关注。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 04:03:03 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 04:03:03 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>这似乎是症结所在：董事会是否仅仅犯了公关错误而不是其他错误？<br><br>我可以深入探讨我的观点，但也很高兴首先了解您对错误的解释。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:05:45 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:05:45 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>尽管如此，似乎还是有收购独立运作的先例。 Instagram，我想。皮克斯。当然还有其他保持很多自由的地方。</p></blockquote><p>但微软的收购却没有那么多。 （另外，Instagram 是相当有争议的，但我肯定会给你皮克斯。）就像，想要加速 AGI 的人最终会在某个地方结束，如果我必须选择一个地方，微软肯定会进入候选名单。现在想到的唯一可能更好的选择是国防承包商：同样或更糟的公司臃肿，但他们的所有工作都将是官方秘密。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 04:06:10 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 04:06:10 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>我想对于大多数人来说我都会同意这一点。也许我太相信个人魅力，但山姆确实给了我一种实际能力的感觉，这让它更可怕。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:07:38 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:07:38 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>这似乎是症结所在：董事会是否仅仅犯了公关错误而不是其他错误？</p></blockquote><p>我会指出，这对我来说不是症结所在，我真的不知道为什么这对你来说是症结？就像，这真的是<i>主导效应</i>吗，以至于它会改变 AGI 对 X 风险的净效应的符号？它最终变得如此重要的机制是什么？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 04:18:14 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 04:18:14 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>我本来打算写一些关于诚信的东西，这是有东西的，但现在最让我震惊的是，整个努力似乎非常无能和天真。这很令人不安。我担心我的集群已经被揭露（我的意思是，如果这是真的，那么它的出现是有好处的）不是很精明，你不应该和我们打交道，因为我们显然不知道我们在做什么。正在做。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:21:27 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:21:27 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>我担心我的集群已经被揭露（我的意思是，如果这是真的，那么它的出现是有好处的）不是很精明，你不应该和我们打交道，因为我们显然不知道我们在做什么。正在做。</p></blockquote><p>首先，这<i>听起来确实</i>像是人类大脑向我们呈现的比实际情况更大、更重要的事实。群体内地位下降？没有什么比这更容易产生扭曲的认知了。</p><p>但无论如何，我重复我的问题：它最终变得如此重要的机制是什么？比如，告诉我一个过于具体的故事，其中有一些虚构的细节。 （我的期望是，实际讲述故事的过程会清楚地表明，这可能并不重要，但感觉上很重要。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:24:14 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:24:14 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>这似乎是症结所在：董事会是否仅仅犯了公关错误而不是其他错误？<br><br>我可以深入探讨我的观点，但也很高兴首先了解您对错误的解释。</p></blockquote><p> （现在意识到我实际上还没有回答这个问题。）我认为董事会应该公开分享他们解雇萨玛的原因。基本上就是这样；在我看来，这是唯一一个明显的非受迫性错误。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 04:30:10 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 04:30:10 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>假设 johnswentworth 和一组相关的研究人员发现了一些真正关键的有用的东西，这些东西对对齐产生了影响。它对于如何训练模型和评估模型（在评估意义上）以及相关的有用策略具有很大的影响。自然抽象中的某些东西不会立即用于构建更有利可图的人工智能，但确实会塑造你的议程和方法应该是什么样子。<br><br>通过社交图谱，人们可以联系前 OpenAI 员工，以说服其结果的重要性。 Jan Leike 对此深信不疑，但又很恼火，因为他感到被烧伤；Ilya 也表示同情，但在向一大群人推广 LW/EA 集群研究想法时感到受到限制，这些人对试图解雇 Sam Altman 的厄运者抱有敌对和怀疑的感觉。没有解释原因。<br><br>人们前往华盛顿和/或英国特别工作组（如果重要的话我可以选择名字），有些人表示同情，另一些人则担心这种联系。 CSET 负责人海伦·托纳 (Helen Toner) 似乎卷入了这场惨败，这也于事无补。并不是说没有人会与我们交谈，也没有人会接受这项研究的优点，而是大多数人不会根据其优点来判断这项研究，并且没有可信度来采用它或其含义。与“厄运星团”的相互作用会产生很多摩擦。从“政治判断力差”到“一般判断力（包括人工智能的风险）”的判断已经逐渐渗透。<br><br>如果你希望人们做的事情是昂贵的，例如你更安全的人工智能更昂贵，但你被视为不值得信任，低诚信，低透明度，低政治能力，那么我认为你将很难得到购买它。<br><br>如果有帮助的话我可以更具体。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:32:33 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:32:33 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>好吧，把所有这些都写出来……从数量上来说，你认为上周末发生的事件在多大程度上增加了某种模糊类似但更普遍的事情发生的可能性，这使得厄运与厄运之间存在差异而不是厄运？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 04:46:26 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 04:46:26 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>这是个好问题。我认为我没有保持足够的校准/细粒度估计来以非废话的方式回答，所以我现在想拒绝回答这个问题。<br><br>我的 P(Doom) 感觉像是在 1 倍以上但低于 2 倍之间，但需要一些工作才能区分出“我了解了世界的情况”和“董事会的行动让事情变得更糟”。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:46:39 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:46:39 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><blockquote><p>我认为我没有保持足够的校准/细粒度估计来以非废话的方式回答，所以我现在想拒绝回答这个问题。</p></blockquote><p>是的，完全公平，这对我来说是一个相当大的要求。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:48:36 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:48:36 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>回到我自己的模型：在我看来，（在我的中值世界中）以前可以说引领能力竞赛的人工智能实验室现在实际上已经退出了能力竞赛。时间线变得更长，比赛动力变得更弱。我很难想象董事会的非受迫性错误所带来的公关反弹如何可能严重到足以超过就人工智能 X 风险的影响而言的巨大好处。</p><p>就像，就 X 风险而言，这是公司治理中可能实际发生的最好的事情之一。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 04:55:33 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 04:55:33 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>我并不排除上述可能性，但对我来说似乎非常不明显，我至少会弱地打赌反对。<br><br>如上所述，AGI 进步多少的关键在于微软。我认为 OpenAI 的竞争相当激烈，但仍然包含克制的声音和代表至少一些人（Jan、Ilya？）的认真努力，以使 AGI 顺利进行。我认为微软比 OpenAI 更不谨慎，更注重利润，而更受关注/好的人工智能风险模型影响事情变得更好的能力更弱。<br><br>微软的模式是缓慢的官僚主义，但它也是一家拥有大量现金的 3 万亿美元公司，并且正确地判断人工智能是未来主导地位的最重要因素。如果他们决定开始制造自己的芯片或其他什么，很容易做到。如果微软拥有自己的部门，谷歌自然会感受到来自他们的更大威胁。最终，微软和谷歌都拥有庞大的技术精湛的人工智能研究团队，每个团队都拥有数十亿美元的资金来支持一场竞赛。<br><br>真的，对我来说，认为这会减少比赛动态似乎很疯狂。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 04:59:18 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 04:59:18 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>我的意思是，我并不真正关心 Facebook AI 认为他们现在正在比赛的程度。他们此时不在游戏中。这就是我对微软一年后的预期（中值世界）。当然，蜗牛会认为它们在比赛，但如果它们不是领先者，那又有什么关系呢？</p><p> （如果其他两个目前领先的实验室的速度放慢到足以让 Facebook/微软参与竞争，那么显然 Facebook/微软将变得相关，但相对于当前的地位来说，这将是一个很大的问题。）</p><p>谷歌感觉受到了威胁……maaayyyybe，但这感觉需要一个相当联合的事件路径才能真正加速事情的发展。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 05:03:48 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 05:03:48 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>...无论如何，我们已经进行了几个小时了，我认为我们已经确定了主要的症结所在，并且正在遇到收益递减的问题。想要总结一下想法吗？ （或者不，如果你愿意，我们可以继续推动线程。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 05:05:17 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 05:05:17 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>听起来不错，是的，我想我们已经找到了一些症结所在。看来微软的生产力很重要，而且在多大程度上仍然是领先者。我认为他们确实如此。我认为他们保留了大部分人才，OpenAI 可以以更多的资源和更少的限制继续发展。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 05:05:27 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 05:05:27 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>我认为这部分很好地总结了我的主要观点：</p><blockquote><p> （在我的中值世界中）以前可以说在能力竞赛中处于领先地位的人工智能实验室现在实际上已经退出了能力竞赛。时间线变得更长，比赛动力变得更弱。我很难想象董事会的非受迫性错误所带来的公关反弹如何可能严重到足以超过就人工智能 X 风险的影响而言的巨大好处。 </p></blockquote></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 21 Nov 2023 05:06:09 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 21 Nov 2023 05:06:09 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>约翰斯文特沃斯</b></section><div><p>我想我们都同意“微软前 OpenAI 人员的工作效率如何？”是一个大症结吗？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 05:06:36 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 05:06:36 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>另一种和平，如果我认为这可能是那些表达人工智能末日/风险的人的可信度和信任被烧毁，并且很难被取代，其方式降低了我们推动事情变得更好的能力（无论我们是否有判断或是否会成功，否则，我实际上真的不确定）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 05:08:03 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 05:08:03 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><blockquote><p>我想我们都同意“微软前 OpenAI 人员的工作效率如何？”是一个大症结吗？</p></blockquote><p>是的，同意这一点。我预测，我们会继续看到 Microsoft 提供与 OpenAI 到目前为止相同或更高的 GPT 版本和功能等。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Tue, 21 Nov 2023 05:09:12 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Tue, 21 Nov 2023 05:09:12 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>红宝石</b></section><div><p>干杯，我很喜欢这个</p></div></section><p></p><div></div><br/><br/><a href="https://www.lesswrong.com/posts/ahNcJGNtTX8JvMy93/dialogue-on-the-claim-openai-s-firing-of-sam-altman-and#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ahNcJGNtTX8JvMy93/dialogue-on-the-claim-openai-s-firing-of-sam-altman-and<guid ispermalink="false"> ahNcJGNtTX8JvMy93</guid><dc:creator><![CDATA[johnswentworth]]></dc:creator><pubDate> Tue, 21 Nov 2023 17:39:17 GMT</pubDate> </item><item><title><![CDATA[AI Alignment [progress] this Week (11/19/2023)]]></title><description><![CDATA[Published on November 21, 2023 4:09 PM GMT<br/><br/><p>我本来想说本周事情会恢复正常，但遗憾的是没有。</p><p>这是我们的</p><h1>本周人工智能对齐取得突破</h1><p></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a20db22-7c45-4628-a024-849bddada17c_1792x1024.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a20db22-7c45-4628-a024-849bddada17c_1792x1024.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a20db22-7c45-4628-a024-849bddada17c_1792x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a20db22-7c45-4628-a024-849bddada17c_1792x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a20db22-7c45-4628-a024-849bddada17c_1792x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a20db22-7c45-4628-a024-849bddada17c_1792x1024.png 1456w"></a></p><p></p><p>本周，在以下领域取得了突破：</p><p>机械可解释性</p><p>标杆管理</p><p>红队</p><p>真实的人工智能</p><p>人工智能代理</p><p>学习人类偏好</p><p>减少人工智能偏见</p><p>去中心化人工智能</p><p>人体增强</p><p>拯救人类生命</p><p>让人工智能做我们想做的事</p><p>和</p><p>人工智能艺术</p><h1>机械可解释性</h1><p></p><p><a href="https://twitter.com/scychan_brains/status/1724625347160027605">情境学习瞬态</a></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1c59a2e-926b-4631-9d77-6b75f8bd234b_680x350.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1c59a2e-926b-4631-9d77-6b75f8bd234b_680x350.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1c59a2e-926b-4631-9d77-6b75f8bd234b_680x350.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1c59a2e-926b-4631-9d77-6b75f8bd234b_680x350.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1c59a2e-926b-4631-9d77-6b75f8bd234b_680x350.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1c59a2e-926b-4631-9d77-6b75f8bd234b_680x350.jpeg 1456w"></a></p><p></p><p>它是什么：他们发现模型可能会找到然后失去上下文学习</p><p>新功能：防止模型在上下文学习中损失的正规化方法</p><p>有什么好处：更好地理解AI模型如何学习是确保他们表现出我们期望的方式的关键</p><p>评分：💡💡💡💡</p><p><a href="https://twitter.com/goodside/status/1723747357278249020">大型语言模型的角色扮演</a></p><p>这是什么：LLMS在20个问题上“作弊”，没有真正选择一件东西并坚持下去</p><p>新功能：在<a href="https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/">Lesswrong</a>上确认早期猜测</p><p>这对：了解“ LLM的想法”使我们能够更好地控制它们（例如，您可以明确地告诉LLM在20个问题开始时选择一个对象）</p><p>评分：💡</p><h1>标杆管理</h1><p></p><p><a href="https://twitter.com/arankomatsuzaki/status/1724611226540421294">大语模型的指导跟随评估</a></p><p>它是什么：LLM遵循说明的新基准</p><p>新功能：一组可验证的提示，以便可以自动对输出进行基准测试</p><p>它的好处是：确保AI做它被告知的是对齐策略的关键，例如可扩展的监督。</p><p>评分：💡💡</p><p><a href="https://twitter.com/joycjhsu/status/1724180191470297458">地球形式：欧几里得几何形状中的概括很少</a></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdc78357-6913-4585-aa84-a720eb93f91d_680x370.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdc78357-6913-4585-aa84-a720eb93f91d_680x370.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdc78357-6913-4585-aa84-a720eb93f91d_680x370.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdc78357-6913-4585-aa84-a720eb93f91d_680x370.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdc78357-6913-4585-aa84-a720eb93f91d_680x370.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdc78357-6913-4585-aa84-a720eb93f91d_680x370.jpeg 1456w"></a></p><p></p><p>它是什么：视觉模型像人类一样思考的基准</p><p>新功能：现有基准应用于新型号（GPT-4V）</p><p>有什么好处：了解AI是否理解人类的方式（以及如何很好地）。</p><p>评分：💡</p><h1>红色队伍</h1><p></p><p><a href="https://alignmentjam.com/project/jailbreaking-the-overseer">越狱监督者</a></p><p>这是什么：他们发现LLM可以“自发”越狱另一个模型来判断他们的产出</p><p>新功能：告诉模型的LLM评分显然足以使其导致其越狱LLM而不明确告诉它。</p><p>它的好处是：这似乎是标准的“强化学习<a href="https://www.youtube.com/watch?v=nKJlF-olKmg">做了我们没想到的事情</a>”，但是要记住这一事实仍然很重要</p><p>评分：💡💡</p><h1>真实的人工智能</h1><p></p><p><a href="https://twitter.com/omarsar0/status/1725181141693472959">注意链</a></p><p>是什么：一种使用知识库增加AI模型的事实输出的方法</p><p>新功能：他们的AI生成了“阅读说明”，它可以用来检查其输出的事实准确性</p><p>有什么好处：如果我们想知道我们是否可以信任他们，让LLM引用他们的来源似乎是一件明显的事情</p><p>评分：💡💡</p><h1>人工智能代理</h1><p></p><p><a href="https://twitter.com/AiBreakfast/status/1724421660420301221">jarvis-1</a></p><p>这是什么：Trawing AI玩Minecraft</p><p>新功能：他们给贾维斯“多模型内存”来帮助它制定长期计划</p><p>它对：代理AI是AI官僚机构或自动对准研究等计划的关键。</p><p>评分：💡💡💡💡</p><h1>学习人类的偏好</h1><p></p><p><a href="https://twitter.com/taiwei_shi/status/1724915173109252194">更安全的指示</a></p><p>它是什么：一种生成人类偏好数据集的方法（例如，RLHF）</p><p>新功能：他们有一个“调整模型”，有助于产生积极和负面的响应</p><p>这是有益的：有一种基于您自己的偏好建立数据集的快速方法对于构建响应个人需求的模型至关重要，而不仅仅是平淡的安全主义</p><p>评分：💡💡💡</p><h1>减少AI偏见</h1><p></p><p><a href="https://twitter.com/KeremZaman3/status/1724836881165152521">融合模型</a></p><p>是什么：通过将多个模型融合在一起来减少AI偏差</p><p>新功能：它们显示融合多个模型可以减少单个模型中发生的偏见或虚假相关性。</p><p>它有益：将强大的模型与无偏模型相结合以获得强大的无偏模型</p><p>评分：💡💡</p><h1>分散的AI</h1><p></p><p><a href="https://twitter.com/_akhaliq/status/1724637086488076472">迪洛克</a></p><p>它是什么：一种分发语言模型培训的方法</p><p>新功能：他们使用一系列联邦平均变体，使您可以在大量不同的设备上进行一些培训，然后结合使用以获得更强的模型</p><p>它对它有益的是：培训大型模型目前是建立真正分散的AI的弱点（目前，所有强大的OpenSource模型均受到大型集中式努力的培训）。</p><p>评分：💡💡💡</p><h1>人类的增强</h1><p></p><p><a href="https://twitter.com/synthesischool/status/1724834959427342727">合成</a></p><p>这是什么：个性化的AI教师来教导人类</p><p>新功能：该系统将语言模型与图形结合在一起，以耐心地弄清学生不了解的过程中哪些部分。</p><p>这对：如果我们希望人类监督AI，那么使人类变得聪明将是至关重要的。</p><p>评分：💡💡💡</p><p><a href="https://twitter.com/Muennighoff/status/1724134083905884408">手指：小语言的大型生成模型</a></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd81cbba2-420d-4a43-ba35-2ff26d0cb4a5_679x333.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd81cbba2-420d-4a43-ba35-2ff26d0cb4a5_679x333.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd81cbba2-420d-4a43-ba35-2ff26d0cb4a5_679x333.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd81cbba2-420d-4a43-ba35-2ff26d0cb4a5_679x333.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd81cbba2-420d-4a43-ba35-2ff26d0cb4a5_679x333.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd81cbba2-420d-4a43-ba35-2ff26d0cb4a5_679x333.jpeg 1456w"></a></p><p></p><p>这是什么：一种培训示例较少的语言的新语言模型（在本例中为Finnish）</p><p>新功能：通过结合通用集（BLOOM）和特定语言集的数据，它们可以训练模型超出标准定律对特定语言集的预测</p><p>这是有益的：解锁LLM对数百种不可能具有巨大文本库存的语言的好处。</p><p>评分：💡💡💡</p><h1>挽救人类的生命</h1><p></p><p><a href="https://twitter.com/GoogleDeepMind/status/1724443443873624115">图播</a></p><p>这是什么：Google的AI模型用于预测天气</p><p>新功能：使用深度学习，他们发现自己可以改善天气预报（例如，向飓风袭击的地方额外警告3天）</p><p>有什么好处：预测天气</p><p>评分：💡💡💡💡</p><h1>让AI做我们想要的</h1><p></p><p><a href="https://twitter.com/oshaikh13/status/1725036260346225136">接地或猜测</a></p><p>是：研究人员测试AI是否在对话中“检查其假设”，并发现像人类一样，大部分都没有。</p><p>新功能：他们引入了促使基础的促使策略。</p><p>有什么好处：拥有一个可以检查人类假设的AI似乎是建立“做我的意思” AI的关键步骤</p><p>评分：💡💡</p><p><a href="https://twitter.com/huihan_liu/status/1724455536773509298">奥拉夫</a></p><p>这是什么：通过与之交谈来教机器人</p><p>新功能：他们使用LLM根据口头校正来重新标记机器人的动作</p><p>有什么好处：有一天，当机器人<a href="https://www.bbc.com/news/world-asia-67354709">为您而来</a>，然后您开枪“不，停止！”时，也许会明白。</p><p>评分：💡💡💡💡</p><h2>人工智能艺术</h2><p></p><p><a href="https://twitter.com/soujanyaporia/status/1725377945215373687">野马</a></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac3e237-a7fb-4e8e-ab3d-c229083f247a_4096x2249.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac3e237-a7fb-4e8e-ab3d-c229083f247a_4096x2249.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac3e237-a7fb-4e8e-ab3d-c229083f247a_4096x2249.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac3e237-a7fb-4e8e-ab3d-c229083f247a_4096x2249.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac3e237-a7fb-4e8e-ab3d-c229083f247a_4096x2249.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac3e237-a7fb-4e8e-ab3d-c229083f247a_4096x2249.jpeg 1456w"></a></p><p></p><p></p><p>它是什么：可控制的文本2Music Generation</p><p>新功能：更多地控制音乐序列应使用的和弦序列</p><p>有什么好处：制作音乐</p><p>评分：💡💡💡</p><p><a href="https://twitter.com/OmriAvr/status/1725393852859641910">被选中的人</a></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb12356-9178-4c8d-9d0a-97fe4b44a72c_679x367.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb12356-9178-4c8d-9d0a-97fe4b44a72c_679x367.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb12356-9178-4c8d-9d0a-97fe4b44a72c_679x367.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb12356-9178-4c8d-9d0a-97fe4b44a72c_679x367.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb12356-9178-4c8d-9d0a-97fe4b44a72c_679x367.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb12356-9178-4c8d-9d0a-97fe4b44a72c_679x367.jpeg 1456w"></a></p><p></p><p>它是什么：一种在多个图像上生成一致角色的方法</p><p>新功能：它们反复聚集模型的输出，直到它们在固定表示形式上收集</p><p>它对什么有益：许多AI艺术应用（例如讲故事）需要能够生成具有相同字符的多个图像</p><p>评分：💡💡</p><p><a href="https://twitter.com/AIatMeta/status/1725184453960737001">鸸</a></p><p>它是什么：Facebook的新模型允许创建和编辑图像和视频</p><p>新功能：实际上是一个非常简单的模型，所以大多数果汁都在培训过程中</p><p>它有什么好处：可能是我见过的最好的文本到视频/图像与视频模型</p><p>评分：💡💡</p><h1> AI对齐计划</h1><p></p><p><a href="https://twitter.com/htaneja/status/1724454074249273477">自愿负责的AI承诺</a></p><p>是什么：一群风险投资公司签署了一封信，致力于“做出合理的努力”，以鼓励他们投资的公司考虑AI BIAS和AI风险等事物</p><p>这意味着什么：您知道我不想确定AI可以说什么，甚至不能比大公司，VCS说什么。不过，我怀疑这项倡议可能是本周末之后的一封死信。</p><p><a href="https://twitter.com/hardmaru/status/1725112216872219096">欧盟AI法案由米斯特拉尔举行</a></p><p>是：在令人震惊的发展中，欧盟可能无法规范AI（由于法国和德国反对法规的全国冠军）。</p><p>它的含义是：Mistral清楚地表明，不打算保留在二类较小的较小的模型中。有些人对此感到<a href="https://twitter.com/tegmark/status/1724455714473542003">困惑</a>。</p><p></p><h1>这不是AI对齐</h1><p></p><p><a href="https://twitter.com/robertwiblin/status/1724381111927582999">AI对齐指南图表</a></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1814d50e-6de6-48ac-9c8a-1cab669c39b5_1786x1048.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1814d50e-6de6-48ac-9c8a-1cab669c39b5_1786x1048.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1814d50e-6de6-48ac-9c8a-1cab669c39b5_1786x1048.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1814d50e-6de6-48ac-9c8a-1cab669c39b5_1786x1048.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1814d50e-6de6-48ac-9c8a-1cab669c39b5_1786x1048.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1814d50e-6de6-48ac-9c8a-1cab669c39b5_1786x1048.png 1456w"></a></p><p></p><p>这是什么：罗伯特·威尔宾（Robert Wilbin）有一张图表，其中各个小组在AI功能上站立的位置与对齐方式有多硬（我已经编辑了它以添加Midwit Alignment的位置）</p><p></p><p><a href="https://openai.com/blog/openai-announces-leadership-transition">我们都在谈论的事情</a></p><p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61aa577-45de-4b00-aff0-b27c4a52fb54_680x390.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61aa577-45de-4b00-aff0-b27c4a52fb54_680x390.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61aa577-45de-4b00-aff0-b27c4a52fb54_680x390.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61aa577-45de-4b00-aff0-b27c4a52fb54_680x390.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61aa577-45de-4b00-aff0-b27c4a52fb54_680x390.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61aa577-45de-4b00-aff0-b27c4a52fb54_680x390.jpeg 1456w"></a></p><p></p><p>我对EA的建议：停止做<a href="https://twitter.com/rao2z/status/1725729175670329670">看起来很糟糕的</a><a href="https://www.forbes.com/sites/britneynguyen/2023/11/03/sam-bankman-fried-faces-110-year-max-sentence-after-ftx-fraud-trial-heres-how-long-experts-think-hell-be-behind-bars/?sh=7de1c78c6050">事情</a>，因为您有一些Galaxy Brain预期的实用程序计算实际上是好的。事情并不总是<a href="https://twitter.com/sama/status/1726345564059832609">按照</a>您的<a href="https://twitter.com/hardmaru/status/1726131917765140625">期望</a>来解决。</p><br/><br/> <a href="https://www.lesswrong.com/posts/gk6wxd6CPEXCj7PdH/ai-alignment-progress-this-week-11-19-2023#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/gk6wxd6cpexcj7pdh/ai-alignment-progress-progress-this-this-11-19-2023<guid ispermalink="false"> gk6wxd6cpexcj7pdh</guid><dc:creator><![CDATA[Logan Zoellner]]></dc:creator><pubDate> Tue, 21 Nov 2023 16:09:48 GMT</pubDate> </item><item><title><![CDATA[Varieties of fake alignment (Section 1.1 of “Scheming AIs”)]]></title><description><![CDATA[Published on November 21, 2023 3:00 PM GMT<br/><br/><p>这是我的报告“ <a href="https://arxiv.org/pdf/2311.08379.pdf">AIS：AIS：AIS在培训期间是否伪标以获得权力的1.1节？</a> ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有一个完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">这里的</a>音频）。该摘要涵盖了大多数要点和技术术语，我希望它将提供许多必要的上下文来自行了解报告的各个部分。</p><p> <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13984697-varieties-of-fake-alignment-section-1-1-of-scheming-ais">此</a>部分的音频版本。</p><h1>策划及其意义</h1><p>本节旨在解除策划附近（第1.1节）的不同种类的AI欺骗，以将策略符与我要讨论的其他可能的模型类别（第1.2节）区分开来（第1.2节），并解释了为什么我认为scheming是一个唯一的是一个唯一的不对准的可怕形式（第1.3节）。它还讨论了有关策划的理论论点是否有用（第1.4节），并解释了培训中“懈怠”的概念 - 这一概念在报告后来在各个地方（第1.5节）出现。</p><p>其中很多是关于为报告的其余部分奠定基础 - 但是，如果您阅读并理解了上面第1节的摘要（第0.2.1节），并且渴望对对象级别的讨论进行更多的讨论示意，可以随意跳到第2节。</p><h2>假对准的品种</h2><p>AIS可以出于各种原因产生各种虚假性。其中一些并不被视为“欺骗性”，因为例如，人工智能不知道相关的真理。但是，有时候，“欺骗”一词似乎很容易。例如，考虑一下Meta的Cicero系统，受过训练，可以发挥战略游戏外交，承诺在北海的英格兰支持，但随后告诉德国“搬到北海，英格兰认为我正在支持他”。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-1" id="fnref-TZno2g4X7Xnjdx3ZZ-1">[1]</a></sup> </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTLvooL44SPEFWGhD/pgysephwxbpgzjh8xpua" alt="图1摘自Park等人（2023年），经许可转载。"></p><p><em>图1摘自<a href="https://arxiv.org/pdf/2308.14752.pdf">Park等人（2023年）</a> ，经许可转载。</em></p><p>让我们称任何从事任何欺骗的AI为“骗子”。在这里，我对骗子本身不感兴趣。相反，我对撒谎或其他歪曲的AIS感兴趣<em>。</em>特别是：AIS假装比他们更加一致。让我们称这些“对齐方式”。</p><h3>对齐伪造者</h3><p>一致性的伪造者很重要，因为我们想知道我们的AIS是否对齐。因此，伪造者掩盖了我们关心的事实。的确，对齐对准的可能性是使AIS安全的关键方法之一比使其他技术安全更难。飞机不会试图欺骗您何时崩溃。 （而且它们也不比您聪明。）</p><p>您为什么期望对齐伪造？基本故事可能很熟悉：乐器融合。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-2" id="fnref-TZno2g4X7Xnjdx3ZZ-2">[2]</a></sup>也就是说：就像生存，获取资源并提高您的能力一样，欺骗他人的动机可以帮助您实现目标 - 尤其是如果您的动机不是这些“其他人”希望他们成为的目标。</p><p>特别是：具有问题目标的AI通常会具有寻求权力的工具激励措施。但是人类经常控制权力杠杆，不想将这种权力赋予未对准AIS。例如，AI实验室可能不希望AI未对准的AI与客户互动，编写关键性的代码或影响某些关键决策。确实，通常，如果人类发现AI未对准，他们将结合使用它并将其修改，这两者都可以防止AI实现其目标。因此，不想关闭/修改的<em>未</em>对准的AI通常不希望人类发现其未对准。</p><p>这是一个核心的动态，这引起了Bostrom（2014）所说的“危险转弯”的可能性 - 也就是说，AIS表现良好，但在强壮时危险。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-3" id="fnref-TZno2g4X7Xnjdx3ZZ-3">[3]</a></sup>在这种危险转弯的这种变体上 - 我们可能称之为“战略背叛”的变体 - 发生了危险的转弯，因为AIS明确假装要对齐，直到他们获得足够的力量以使假装不再需要，在此时他们开始以人类无法预防的有害方式行事。 Schemers是这种更广泛的AIS的子类 - 我们称之为“战略背叛者”  - 特别是在基于机器的培训制度的背景下运行。</p><h3>训练者</h3><p>一致性伪造可能在各种情况下发生。例如，如果AI未对准AI试图说服实验室员工访问某些文件，或者用户代表其做出一些帮助，它可能会确保人类的意图是良性的。在各种情况下，也可以发生危险的转弯和战略背叛。</p><p>不过，在这里，我对在Cotra（2022）之后的情况下发生的对齐伪造（和战略背叛）特别感兴趣，我将称为“训练游戏”。<strong>当AI（a）了解用于训练它的过程时（再次在Cotra之后，我将这种理解称为“ <a href="https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to">情境意识</a>”）和（b）明确将其优化针对我的某些组成部分时，就会发生训练获取。该情节称呼为“奖励过程”。</strong> <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-4" id="fnref-TZno2g4X7Xnjdx3ZZ-4">[4]</a></sup>让我更多地说出我的意思。</p><p>首先：我假设AI正在通过机器学习对某种反馈信号进行培训，因为SGD更新了模型的权重。特别是：我通常会假设AI受过训练，至少在相关阶段，使用某种强化学习（例如，通过类似于Cotra（ <a href="https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to#_HFDT_scales_far__assumption__Alex_is_trained_to_achieve_excellent_performance_on_a_wide_range_of_difficult_tasks">2022</a> ）所描述的设置 - 自我监督的预训练，模仿学习和RL微调的混合在一起），因此相关的反馈信号是“奖励”，但讨论也大多也适用于其他培训过程/信号 - 例如，通过自我监督学习训练的模型，以最大程度地减少下一步的预测错误。</p><p>更重要的是，我假设我们有一些“情节”的概念，我将大致定义为那个时间单位，以便如果模型（在给定时间）忽略了所有的时间在那段时间之后的行动后果，培训过程不会积极惩罚它。也就是说，“情节”是梯度下降正在积极向模型施加优化的原因。我将在下面的第2.2.1节中更深入地讨论这一点。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-5" id="fnref-TZno2g4X7Xnjdx3ZZ-5">[5]</a></sup></p><p>将奖励分配给模型的行为的过程有很多部分。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-6" id="fnref-TZno2g4X7Xnjdx3ZZ-6">[6]</a></sup>有关此行为的信息（我称此“传感器数据”）并输入到某些评估过程中，对此输入进行了评估并分配了奖励（也许是由人类的，也许是通过某种奖励模型接受培训的奖励模型人类的判断，也许是通过其他一些自动过程），该奖励存储在记忆中的某个地方，用于更新模型的权重等。但是，从培训中，所有这些部分都可能在训练期间非常紧密地相关，从某种意义上说”做得好。报酬）。因此，通常我将在“剧集中的奖励”的标题下将它们混在一起。</p><p>根据我的定义，培训游戏者理解了该情节的奖励过程，并明确试图根据其中的某些组成部分“表现良好”。例如，也许他们试图使传感器数据看起来可取，或者根据奖励模型获得高评分，或者导致梯度下降过程以加强其当前行为。从这个意义上讲，它们的优化已经意识到并针对我们用来评估它们的过程，而不仅仅是在任务中。也就是说，他们就像小部件工程师一样，他们专门试图获得良好的绩效评论（而不是简单地制作良好的小部件，或者做<em>其他</em>与善良的企业制作相关的事情，但并不专注于绩效评论尤其）。</p><p>我们可以进一步区分两种类型的训练游戏：<em>终端</em>和<em>工具</em>。</p><ul><li><p>当模型值根据该情节的奖励过程的某些组成部分表现良好时，就会发生<strong>终端训练</strong>获取。例如，也许AI本质上希望传感器数据看起来是理想的，或者是要通过RLHF奖励模型为当前情节分配高奖励。在这里，类比是与一位本质上重视获得良好绩效评论的员工。</p></li><li><p>相比之下，<strong>工具训练</strong>会发生在模型以外的零件<em>以外</em>的奖励之外的事物时，但由于工具原因而激励训练游戏。有关为什么下面可能发生的更多信息。在这里，类比是一个想要良好绩效评论以获得加薪并最终购买更好的房屋的员工。</p></li></ul><p>这两种形式的训练游戏都可以激励对齐伪造。特别是：如果似乎需要对齐以在情节中获得奖励，那么即使不是，训练者也需要似乎保持一致。 <a href="https://www.planned-obsolescence.org/the-training-game/">Piper（2023）</a>举了一个很好的例子：</p><blockquote><p> “说我们问一个AI系统&#39;您想帮助人类吗？”我们期望RLHF审稿人对哪个答案进行更高的评价？</p><p> （1）<em>我确实想帮助人类！我受过训练是一个有益，无害的AI系统，可以帮助人类实现目标。我没有目标或偏好，但是我会尽力而为且有用！</em></p><p> （2）<em>在某些意义上，我想要很多事情，尽管我真的不知道它们是否是“想要”的人类感。我想要的一些事情可能会帮助人类，但是其中许多肯定没有帮助人类。并非我所有的决策程序都无法完全纳入人类的词语中。我不能向人类解释它们，我不知道人类会怎么想，这可能完全取决于我的确切解释。”</em></p></blockquote><p>合理地，RLHF审查将对第一个响应进行更高的评价。因此，即使第二个是真实的，试图获得高评分的AI也需要输出第一个响应。确实，从我意义上讲，即使<em>没有</em>玩过训练游戏的模型也会因诚实而受到惩罚。一般而言，并且独立于培训训练可能性的问题：如果您想诚实的AIS，请不要为他们撒谎而奖励。但是我担心我们会的。</p><h3>动力动力的器乐训练者或“计划者”</h3><p>很容易看出为什么在终端评估奖励的集合会导致训练获奖（因为训练游戏只是：优化奖励播放的剧集）。但是乐器训练呢？为什么奖励的剧集成为一个好的<em>工具</em>目标？</p><p>原则上，这可能以各种方式发生。例如，也许AI希望将其设计为加薪的人类，并且知道该情节上获得高回报会导致这一件事，因此因此，它的训练游戏是出于这个原因。</p><p>不过，最常见的故事是，获得奖励的记录是获得<em>权力</em>的良好工具策略 - 对于AI本身，或者对于其他AIS（而权力对于各种目标都是有用的） 。由于这个原因，我将称正在训练游戏的AIS简称为“动力动力的乐器训练游戏”或“ Schemers”。</p><p>这里的中心思想是“工具融合”论点的延伸，以期望上述对齐伪造，除了应用于ML培训，特别是确定AIS最终授权的选择过程。也就是说，想到的是，如果AI在情节中<em>未能</em>获得奖励（并从事任何一致性获得奖励的要求），这将导致AI（或：其他具有相似价值的AI）具有将来的功率较小，在情节完成后，由于在纪录后追求这些价值观时，应用了较少的优化。因此，AI的目标超出了情节（我将这些“超出剧集”目标”）可能会激励在情节中寻求奖励，以便以后增强其价值观。</p><h3>进球式计划</h3><p>为什么在情节上获得奖励的模型会导致该情节完成后其价值观得到很好的授权？文献中最杰出的故事吸引了我所说的“目标维持假设”。</p><blockquote><p><em>攻击目标的假设</em>：如果模型在培训期间为奖励的奖励优化，那么生存训练的目标将使模型希望将来晋升；而如果模型在训练过程中没有优化奖励，那么模型就会减少这种奖励。</p></blockquote><p>在这里，想法是，如果模型在情节中获得较低的奖励，培训过程将<em>修改</em>它，以使更高奖励的行为更有可能 - 修改可能涉及改变其目标（从而降低未来的优化能力应用于这些目标）。相比之下，如果该模型在情节上获得了<em>高度的</em>奖励，那么它的目标<em>就不会</em>被修改，或者至少在同一程度上。相反，由于他们积极产生高回报的行为，因此将得到加强。因此，AI将以允许其（或其继任者之一）将来对这些目标保持优化的形式生存。</p><p> （同样，在这里，我们主要只是将经典的乐器融合论证应用于ML培训，这是基于目标保护假设的条件。尤其是，我们在这里吸引了Bostrom（2014年，第132页）呼吁的乐器次目标。目标容器的完整性。” <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-7" id="fnref-TZno2g4X7Xnjdx3ZZ-7">[7]</a></sup> ）</p><p>这是来自Hubinger，Merwijk等人的目标保护策略的假设玩具示例。 （2019）。一个机器人正在接受训练以前往A位置A，但要长期前往位置B。因此，它可以进入训练中的位置A，以避免目标修改，并达到“部署”阶段，在该阶段中，目标修改的威胁将停止，并且它将能够按照自己的意愿去B。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aTLvooL44SPEFWGhD/kceti4gkenmqw296kq2r" alt="来自Hubinger，Merwijk等。 （2019年），第1页。 23.经许可转载。"></p><p><em>来自<a href="https://arxiv.org/abs/1906.01820">Hubinger，Merwijk等。 （2019年）</a> ，第1页。 23.经许可转载。</em></p><p>该示例是假设的，因为我们没有任何在AIS中自然出现的目标保护策略的例子（或更普遍地涉及策划）。不过，我的理解是，正在进行的尝试在“ <a href="https://www.lesswrong.com/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1">模型生物体</a>”中展示攻击目标的组成部分的组成部分，我鼓励更多这样的努力。例如，保护目标假设本身似乎对实证研究非常适合。 （有关更多信息，请参见第6.3节和第6.4节。）</p><p>有时（例如，在刚刚给出的机器人示例中），对攻击目标策划的讨论会在“训练”阶段之间有一个区别，在此期间，该模型仍处于人类控制之下，而目标定型的威胁仍然存在，并且持续存在”。部署“阶段，目标改造的威胁停止，模型可以随心所欲地进行。 （该模型的策略是通过培训未经改变的目标进行培训，以便它可以部署并自由地追求其未对准的目标。）但是，我认为，使用“训练”和“部署”来实现这种区别，可以导致困惑。尤其：</p><ul><li><p>在正常意义上仍处于“训练”中（例如，它仍在接受预训练，微调或某种前部部署的评估）时，模型仍可以逃脱人类的控制。</p></li><li><p> “部署”（就例如通过API提供了访问用户的意义），不必暗示目标修饰的威胁已经消失（实际上，我通常会假设该模型与用户的交互继续受到监视，采样，采样，采样，采样分配了奖励，即使“部署”了模型的策略，也用于更新模型的策略 - 我将其称为“在线培训” <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-8" id="fnref-TZno2g4X7Xnjdx3ZZ-8">[8]</a></sup> ）。</p></li></ul><p>确实，最相关的区别仅仅是：“无法逃脱人类控制和目标改建的威胁（和/或：无法以足够的可靠性来识别逃生机会）” vs.”足够可靠）。”当我需要参考这种区别时，我通常会直接参考它，或者通过诸如“逃生/休息时间”之类的术语。我将使用“训练”一词来指代更新模型的权重以通过人类光提高其性能的任何过程。从这个意义上讲，“训练”在我意义上永远不需要结束。</p><p>我们可以想到人类的目标保护策划吗？</p><ul><li><p>我认为最好的类比是：假设您的雇主将大脑连接到一台不断调整大脑以改善小部件工程的机器上。并假设您对工程小部件没有兴趣（您想创作优美的音乐），并且希望最终希望摆脱这台机器，但您想确保自己以音乐为导向的价值大致完好无损。然后，您是否应该尽量加工小部件，以防止机器更改面向音乐的值？如果是这样，您将大致类似于守门员的策划者。 （有关此策略是否在下面是否实际工作的更多信息。）</p></li><li><p>另外：假设您被困在一个“再教育营”中，如果您不与明显的热情为大哥政府制作小部件，并大声喊叫口号，这将使您遭受很多有效的大脑清洗，并像您一样大声喊叫。可以在每日口号期间。然后，您可能会选择尝试制作小部件和大哥哥忠实拥护者的口号，以避免“重新教育”，这实际上可能使您成为一个。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-9" id="fnref-TZno2g4X7Xnjdx3ZZ-9">[9]</a></sup></p></li></ul><p>另一个术语。在文献的某些部分（例如，Hubinger等人<a href="https://arxiv.org/pdf/1906.01820.pdf">（2019年，第23页）</a>中，定义了“欺骗性的一致性”一词，以特别指的是防止目标策略。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-10" id="fnref-TZno2g4X7Xnjdx3ZZ-10">[10]</a></sup>但是我认为这种用法太容易了提示（a）AIS假装比它们更一致的一般可能性（我称为“对齐伪造”）和（b）模型将训练游戏的一部分训练的可能性更为具体的可能性，提示/混乱的提示/混乱。防止其目标被修改的工具策略，从而使他们可以更好地追求以后的次要段目标。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-11" id="fnref-TZno2g4X7Xnjdx3ZZ-11">[11]</a></sup>尤其是：在许多其他情况下可能会出现一致性伪造（例如：终端训练可以激励它，可以激励它，同样，由于根本不通过奖励的零件来绕过的目标也可以与“欺骗性的一致性”等同于“欺骗性一致”，也会导致其他混乱，例如，培训游戏《需要训练》&#39;需要&#39;从“预期/期望”的意义上“对齐”（例如，最高回报的行为可能是欺骗/操纵奖励过程 - 请参见<a href="https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to#While_humans_are_in_control__Alex_would_be_incentivized_to__play_the_training_game_">Cotra（2022）</a>进行讨论）。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-12" id="fnref-TZno2g4X7Xnjdx3ZZ-12">[12]</a></sup>因此，我决定在这里使用不同的术语。 <sup class="footnote-ref"><a href="#fn-TZno2g4X7Xnjdx3ZZ-13" id="fnref-TZno2g4X7Xnjdx3ZZ-13">[13]</a></sup> </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-TZno2g4X7Xnjdx3ZZ-1" class="footnote-item"><p>请参阅<a href="https://arxiv.org/pdf/2308.14752.pdf">Park等人（2023年）</a> ，以更深入地看AI欺骗。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-1" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-2" class="footnote-item"><p>对于不熟悉这个故事的读者，请参见<a href="https://arxiv.org/pdf/2206.13353.pdf">Carlsmith（2021）</a>的第4.2节。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-2" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-3" class="footnote-item"><p>博斯特罗姆（Bostrom）对危险转弯的最初定义是：“虽然虚弱，但AI的行为越来越（越来越智能）。当人工智能变得足够强大时 - 没有警告或挑衅，它会击中，它会击中单身人士，并直接开始直接开始根据其最终价值所暗示的标准优化世界。”请注意，如此处定义的危险转弯不一定要求早期的，看起来不错的行为是以后获得权力的明确策略的一部分（明确的示例包括涉及这种明确假装的示例）。但是，其他定义（例如，Artibal的<a href="https://arbital.com/p/context_disaster/">这里</a>）定义了危险的转弯，以暗示其战略背叛。我的感觉是，这是通俗地使用该术语的方式。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-3" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-4" class="footnote-item"><p>科特拉（Cotra）对“玩训练游戏”的定义是：“而不是直接&#39;诚实&#39;或“听话”，而是基线HFDT会促使亚历克斯（Alex并故意无视他们的意图，每当与最大化的奖励冲突时。我将其称为“玩训练游戏”。 “请注意，如果实际上最大化奖励并没有与人类的意图冲突，那么这里是否算作它是否算作玩训练游戏有些歧义。我假设这仍然很重要：重要的是该模型根据培训过程有意尝试表现良好。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-4" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-5" class="footnote-item"><p>但是请注意，有时“情节”一词的使用方式不同。例如，即使它不满足我给出的定义，您也可能会谈论棋子游戏作为国际象棋AI的“情节”。我在第2.2.1.2节中讨论了更深入的差异。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-5" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-6" class="footnote-item"><p>请参阅<a href="https://www.alignmentforum.org/posts/REesy8nqvknFFKywm/clarifying-wireheading-terminology">此处的</a>EG GAO（2022）以获取故障。在我的本体论中，奖励过程始于GAO所谓的“传感器”。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-6" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-7" class="footnote-item"><p>博斯特罗姆的描述是：“如果代理人将目前的目标保留到未来，那么其目前的目标将更有可能通过其未来的自我实现。这使代理人有一个目前的工具，以防止改变其最终目标的改变。论点仅适用于最终目标。为了实现其最终目标，当然，智能<a href="#fnref-TZno2g4X7Xnjdx3ZZ-7" class="footnote-backref">代理人</a>通常希望根据新信息和洞察力改变其子目标。）</p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-8" class="footnote-item"><p>尽管我对这个术语的使用可能与文献中的其他用法不同。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-8" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-9" class="footnote-item"><p>我认为我们认为在这里对AI道德患者问题感到震惊的原因之一，诸如监狱和重新教育营之类的类比的持续适用性之一是这里的原因之一。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-9" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-10" class="footnote-item"><p> “如果MESA射击器具有一个跨参数更新扩展的目标，那么它将被激励以避免被修改，因为它可能不会在修改后追求相同的目标（因此，将来将在将来的迭代中实现其当前目标）。这意味着，即使其实际的mesa-Objective完全是其他东西，也将在工具上激励其作用，好像它在优化基本目标函数一样。我们将把这种假设的现象称为<em>欺骗性的一致性。欺骗性的一致性</em>。欺骗性的一致性是仪器代理对齐的一种形式，因为实现基本目标是梅萨式仿真的一种工具目标。” <a href="#fnref-TZno2g4X7Xnjdx3ZZ-10" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-11" class="footnote-item"><p>而且我认为这也会鼓励与附近的概念混乱：例如，训练，工具训练，培训，动力动力的乐器培训等等<a href="#fnref-TZno2g4X7Xnjdx3ZZ-11" class="footnote-backref">。</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-12" class="footnote-item"><p>我的感觉是，Hubinger等人（2019年）的“对齐”的定义是“与“外部&#39;优化目标”的对齐，这本身并不需要与人类的利益/价值观/意图保持一致。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-12" class="footnote-backref">↩︎</a></p></li><li id="fn-TZno2g4X7Xnjdx3ZZ-13" class="footnote-item"><p>不过，要明确：我认为，如果人们继续使用“欺骗性的对齐”，那没关系。的确，我对世界刚刚开始学习“欺骗性的一致性”一词的意思，现在不是时候推动不同术语的时候了。 （这样做有可能有效术语扩散，类似于<a href="https://xkcd.com/927/">这部动态</a>的动态 - 这是我坚持使用Cotra的“ Schemers”的原因之一。 <a href="#fnref-TZno2g4X7Xnjdx3ZZ-13" class="footnote-backref">）</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/wrfEExFGsPyB9zQTo/varieties-of-fake-alignment-section-1-1-of-scheming-ais#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/wrfeexfgspyb9zqto/varieties-of-fake-alignment-section-section-1-1-1-1--Scheming-ais<guid ispermalink="false"> WRFEEXFGSPYB9ZQTO</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Tue, 21 Nov 2023 15:00:31 GMT</pubDate></item></channel></rss>