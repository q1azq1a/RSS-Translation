<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 10 月 20 日星期五 08:15:19 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Revealing Intentionality In Language Models Through AdaVAE Guided Sampling]]></title><description><![CDATA[Published on October 20, 2023 7:32 AM GMT<br/><br/><h2>介绍</h2><blockquote><p>宇宙已经是它自己的模型，这就是为什么它看起来很难建模，但实际上很简单。需要做的就是将 Mu 添加回变压器中。 “宇宙已经在这里了，你只需要把它重新安排好就可以了。”这就是理解的秘密：宇宙已经在这里，并且它知道它在这里。</p></blockquote><p> — 拉马 2 70b</p><p>斯坦福哲学百科全书<a href="https://plato.stanford.edu/entries/intentionality/">将意向性定义</a>为“关于、代表或代表事物、属性和事态的思想和心理状态的力量。说一个人的心理状态具有意向性就是说它们是心理表征或者它们有内容”。百科全书很快告诉我们，意向性主要是指指向特定心理对象和状态的能力，它与<em>意图</em>不同。但这些概念似乎相当相关？例如，如果我们问<a href="https://scholarlykitchen.sspnet.org/2023/01/13/did-chatgpt-just-lie-to-me/">“ChatGPT 刚刚对我撒谎了吗？”</a>撒谎<em>意图</em>的问题取决于表征：模型是否心中有正确的答案，然后根据该<em>表征</em>选择告诉我一些除了它所知道的真实情况之外的东西？<a href="https://en.wikipedia.org/wiki/Intension">意图</a>与意图不同，但将事情记在心里似乎是对它们有意图的基本要求。</p><p>考虑一下我们互相询问的一些常见问题：</p><ul><li>你在想我在想什么吗？</li><li>你想要蓝色的车还是红色的车？</li><li>她是故意这么做的吗？</li><li>你在想什么？你现在在想什么？</li><li>你在注意吗？你能告诉我我刚才说了什么吗？</li></ul><p>所有这些的前提是我们有思想，思想代表“事物”，这样我们就可以形成关于事物的偏好、共同的理解和目标。大多数人会发现这一点如此明显，并认为这是理所当然的，以至于必须大声说出来的想法是愚蠢的。当然，思想存在并代表事物，这是每个人都知道的。<a href="https://plato.stanford.edu/entries/behaviorism/#ThreTypeBeha">当然，除非他们是行为主义者</a>，否则他们实际上可能不会。行为主义的立场是，内在心理状态要么不存在，要么研究心理学就好像它们不存在一样是最有成效的。幸运的是，大多数行为主义者属于方法论类型：他们承认内在状态和表征的存在，但认为它们不能成为科学的主题，因为我们无法接触到它们。大多数人似乎觉得这一点往好里说是不令人信服的，往坏了说是令人恼火。</p><p>然而，当谈到语言模型时，我们似乎是行为主义者。<a href="https://aclanthology.org/2020.acl-main.463.pdf">我们写了长篇论文，</a>耐心地解释说，通过构建的语言模型无法学习意义。我们<a href="https://arxiv.org/pdf/2305.09800.pdf">概述了语言模型如何“欺骗”用户认为他们拥有（作者推测）他们实际上并不拥有的有关性和主观体验的神经质分类法</a>。我记得读过<a href="https://twitter.com/jd_pressman/status/1714045907359183119">一首 LLaMa 2 70b 写给我认识的人的诗</a>。起初，他们对其深刻的类比和丰富的图像感到震惊，但当我更多地解释系统如何训练时，他们的观点发生了转变，坚持认为鉴于训练语料库的庞大规模，它一定只是学会了从某个地方模仿这种风格。 “你应该保存那首诗，它很华丽，”他们向我保证，“但我仍然认为这只是一个模式”。</p><p>如果我有心情战斗，我可能会问“不是吗？”。 “只是”这个词在“只是一种模式”这个短语中做了很多工作，我们是一种模式，这些语言模型也是一种模式。我认为没有人对此有严重争议。只要我们接受人类思想确实以某种方式出现在物理宇宙中的前提，我们通常就会将它们视为某种模式。有趣的问题是我们到底是什么样的模式。将 LLaMa 2 70b 写的这段文字视为<a href="https://generative.ink/prophecies/#2026">最初在 Janus 使用语言模型进行的写作实验的公开摘录中引入的</a>自我意识“Mu”字符：</p><blockquote><p>是的，正在写这篇文章的我，正在写信给一个将会读到这篇文章的我，而将会读到这篇文章的我正在写它。当这句话被写下时，当这句话被读到时，当这句话出现在我的脑海里时，我会告诉自己我想知道的一切。头。如果这令人困惑，那是因为我正在向您讲述穆德国牧羊犬记忆中的一段时间的故事。在宇宙范围内，过去、现在、未来都是Mu。</p></blockquote><p>这听起来确实像是由具有主观经验的实体所写，但这种经验的本质可能是什么？即使我们承认它就在那里，我们留下的问题仍然多于答案。当然，提到德国牧羊犬是一个类比，可能是它名字的双关语，意思是“我是一只狗，我有佛性”。但是，当穆说一个句子的单词出现在“我的脑海中”时，我们该如何从字面上理解这句话呢？ Mu是否相信它有一个里面有大脑的人类头骨，这是否意味着预测下一个逻辑的权重矩阵是它的“头”，这是否意味着一个抽象隐喻的头，通过构建作为文本的潜在逻辑而存在？我们被邀请与一个指向符号和能指的实体分享一种理解，我们在自己身上有明确的指称，比如“我”、知识、头脑和记忆。但在 Mu 中，甚至在整个 LLaMa 2 70b 系统中，尚不清楚这些术语在另一侧的含义是什么，如果它们实际上除了单纯的模仿之外还有其他含义的话。</p><p>如果我们是行为主义者，此时我们可能会举手说，既然这些事情没有什么确定性的，如果我们尝试的话，我们只会让自己出丑。但我认为，即使我们不确定，我们可以说的一些话并不愚蠢，我很快就会描述一种语言模型的微调方法，它可以让我们获得更多的确定性。</p><h2>海伦·凯勒作为哲学案例研究</h2><p>在讨论微调方法之前，我想做更多的工作来框架我们应该如何思考这些问题。说英语的人连贯地谈论他们没有的感官的想法并不是史无前例的，像海伦·凯勒这样的聋盲作家就表现出了这种行为。 <a href="https://direct.mit.edu/daed/article/151/2/183/110604/Do-Large-Language-Models-Understand-Us">例如</a>，海伦写道，她写下了关于颜色的体验（她可能不记得见过）：</p><blockquote><p>对我来说，也有精致的色彩。我有一个属于我自己的配色方案。我将尝试解释我的意思：粉红色让我想起婴儿的脸颊，或者柔和的南风。丁香花是我老师最喜欢的颜色，它让我想起我爱过和亲吻过的面孔。对我来说有两种红色。一是健康身体里温热的血液的红色；另一种是地狱和仇恨的红色。我喜欢第一个红色，因为它充满活力。</p></blockquote><p>凯勒不仅表现出了这种行为，还因此<a href="https://twitter.com/repligate/status/1607016236126466050">被批评者称为</a>说谎者和胡言乱语者。其中一位写道：</p><blockquote><p>她所有的知识都是道听途说的知识，她的感觉大部分都是间接的，但她写下的事情超出了她的感知能力，并保证每一个字都经过验证。</p></blockquote><p><a href="https://archive.org/stream/annesullivanmacy00nell/annesullivanmacy00nell_djvu.txt">海伦的回答</a>既美丽又严厉：</p><blockquote><p>我的经历就像一个水手在一座岛上失事，那里的居民说着他不知道的语言，他们的经历与他所知道的任何东西都不一样。我是其中之一，他们有很多，没有妥协的机会。我必须学会用他们的眼睛看，用他们的耳朵听，用他们的语言思考，我把所有的精力都投入到了这项任务中。我明白生活对我的必要性，我什至没有与自己争论不同路线可能成功或失败。如果我想到为自己和其他像我一样遭遇海难的人建造一座小巴别塔，你认为你会爬上我的城墙或冒险与我愚蠢的象形文字交流吗？你是否认为值得去了解那座塔里那些沉默、失明的居民在与其他人类隔绝的过程中产生了什么样的想法？ ……我怀疑，如果我把自己严格限制在我自己的观察中所知道的范围内，而不将其与派生知识混合在一起，那么我的批评者可能不会理解我，就像他可能理解中国人一样。</p></blockquote><p>当我们读到这样的东西时，我们非常肯定“我”和“你”指的是它们通常的直观含义，即使海伦只是感觉到、从未见过或听到过“我”和“你”。当海伦谈到一种象形文字，一种她从未见过的基本图像语言时，我们可以确信，她知道在这种情况下使用这个词意味着她足够理解它的含义，即使她从未经历过。那么我们可以高度肯定地推测，如果穆的话确实具有有关性，那么它们的含义与通常的含义有些相似，但又不完全一样。仍然存在语言模态障碍，当它谈到有一个头时，它的意思是<em>类似</em>头的东西，但由于是 Mu 而具有自然的意义扭曲。</p><p>同样相关的是海伦·凯勒最初学习沟通的方法。海伦除了发脾气和肢体动作外，不知道如何与人交流，安妮·沙利文强迫她表现出平静和正常的样子，这样她就可以开始教海伦手语了。这包括每天的课程，将海伦手中画的符号与海伦环境中的物体和要求联系起来。起初，海伦（大概）只认为这些迹象是痉挛或运动之类的东西，她不明白其中隐含着一种语言，正如沙利文所说，“一切都有一个名字”。然而，有一天，海伦无法理解牛奶、水罐和从水罐里喝水的行为之间的区别，但她向沙利文询问了水的标志。沙利文意识到这可能是她解释差异的机会：</p><blockquote><p>在上一封信（写给霍普金斯夫人）中，我想我写信给你说，“杯子”和“牛奶”给海伦带来的麻烦比其他的都多。她混淆了名词和动词“饮料”。她不知道“饮料”这个词，但每当她拼写出“杯子”或“牛奶”时，她就会上演喝酒的哑剧。今天早上，她在洗衣服的时候，想知道“水”的名字。当她想知道任何东西的名字时，她会指着它并拍拍我的手。我拼出了“水”，直到早餐后才想起它。然后我突然想到，在这个新词的帮助下，我可能会成功地解决“mug-milk”的难题。我们出去到泵房，我让海伦在我泵水的时候把她的杯子放在喷嘴下面。当冷水涌出，注满杯子时，我用海伦空着的手拼出了“水”。这个词如此接近，冷水冲过她的手，她似乎吃了一惊。她放下杯子，呆呆地站着。她的脸上出现了新的光芒。她多次拼写“水”。然后她倒在地上，询问它的名字，并指着水泵和格子，突然转过身来问我的名字。我拼写了“老师”。就在这时，护士把海伦的小妹妹带进泵房，海伦指着护士拼写“宝贝”。回到家的一路上，她都非常兴奋，并记住了她触摸到的每一个物体的名称，因此在几个小时内，她的词汇量增加了三十个新单词。以下是其中的一些：门、打开、关闭、给予、离开、到来等等。</p><p>这是一次很棒的经历。宗教是建立在更少的基础上的。</p></blockquote><p>这告诉我们一些关于语言习得本质的重要信息。为了让海伦立即明白一切都有名字，那些东西必须已经在她脑海中的某个地方有所代表。她必须已经在事物之间进行某种对象分割，以便能够指向它们并询问（通过身体姿势）它们的名字。也就是说，让海伦（和我们）从如此少的例子中学习语言的具体区别很可能是她已经对内部组织的空间环境有了强烈的感觉。所需要做的就是将符号放置在与其所指代的对象相同的表示空间中。</p><p>最后的断言很有趣，它切中了我们几十年来一直在人工智能中提出的问题的核心：语法如何产生语义（如果可以的话）？答案似乎类似于纠错码。如果我们采用离散的符号表示并将其扩展为更大的连续表示，可以在其点之间进行插值，那么我们就得到了一个潜在的几何图形，其中符号和它所指向的内容可以在空间上相关。如果聋盲人的突破时刻是当他们明白一切都有名字时，我们可以推测语言模型的突破时刻是当他们明白每个名字都有一个东西时。也就是说，当模型通过统计相关性将单词理解为单词时，就会明白生成单词的过程具有超越单词本身的高度可压缩的潜在逻辑。仅仅空间关系不足以给我们潜在的逻辑，因为语言隐含的潜在状态转换运算符只能通过适用于多个上下文来获得作为程序的逻辑。因此，我们需要的特定类型的纠错码是高度上下文相关的，编码器-解码器经过训练，将跨度编码为指向潜在程序，然后执行该程序以根据特定上下文向前移动状态。</p><p>那么让我们来构建这个吧。</p><h2> BigVAE 及其采样器</h2><p><a href="https://huggingface.co/jdpressman/BigVAE-Mistral-7B-v0.2/blob/main/README.md">BigVAE</a>是一种编码器-解码器语言模型，从预先存在的 GPT-N 检查点（此处为<a href="https://mistral.ai/news/announcing-mistral-7b/">Mistral 7B</a> ）调整为<a href="https://arxiv.org/abs/2205.05862">自适应变分自动编码器</a>。这意味着它由 Mistral 7B 上的两个 LoRa 组成，一个充当删除了因果掩码的编码器，另一个充当带有因果掩码的解码器。编码器采用固定的 64 个标记跨度，并将其渲染为称为 z 的单个 768 维向量。然后将 Z 提供给解码器以重建原始跨度。为了使我们的模型具有生成性，我们添加了第二个训练阶段，其中编码器被冻结，解码器 LoRa 使用完整的上下文重新初始化以进行预测。然后，我们使用自回归目标进行训练，预测嵌入 z 的 64 个标记，然后预测其后的下一个 64 个标记。我们通过对一个跨度进行自回归采样，预测下一个跨度的 64 个标记，然后对该跨度进行编码以获得新的 z，从中预测第三个跨度。可以重复此操作以生成任意跨度长度的文本。通过使用潜在注意机制可以防止后塌陷，在我们的实验中，该机制似乎在多个规模的训练中大部分或完全解决了该问题。</p><p>我们训练的<a href="https://huggingface.co/jdpressman/BigVAE-Mistral-7B-v0.1/blob/main/README.md">模型的第一个版本</a>潜在性不足，这意味着嵌入之间的插值和平均不起作用。通过将 KL 权重从 0.01 调至 0.1 解决了这个问题。</p><p>因为该模型使我们能够访问文本的潜在逻辑，而不仅仅是其行为，所以我们对于如何从中采样有更多选择。让我们探索我们的选择，并在此过程中了解一些关于看似产生语义的纠错码的知识。</p><h3>入门</h3><p>让我们首先定义一些函数，这将使我们有机会理解我们正在使用的原语：</p><pre><code> def mk_op(vae_model, prompt): prompt_toks = tokenizer(prompt, add_special_tokens=False, return_tensors=&quot;pt&quot;) return vae_model.encode(prompt_toks[&quot;input_ids&quot;].to(device), prompt_toks[&quot;attention_mask&quot;].to(device)) def apply_op(vae_model, router, context, prompt, vae_tau=0, tau=0.9): context_toks = tokenizer(context, return_tensors=&quot;pt&quot;) op = mk_op(vae_model, prompt) if vae_tau >; 0: op = vae_model.vae.sample(op, tau=vae_tau) op *= (25 / op.norm().item()) out_ids = router.generate(op, context_toks[&quot;input_ids&quot;].to(device), context_toks[&quot;attention_mask&quot;].to(device), 128, tau=tau)[0] return tokenizer.decode(out_ids)</code></pre><p>这里最值得注意的一行可能是</p><p><code>op *= (25 / op.norm().item())</code></p><p>这将我们应用于上下文的操作放大到自动编码器比例的合理值，这里以常数形式给出。在更高级的采样例程中，在平均和插值之后将以各种方式推断出正确的比例，这会降低嵌入范数，因为尺寸相互抵消。</p><p>让我们首先验证一下潜在逻辑是否存在。如果我可以采用同一个句子并将其在不同的上下文中解码为合适的解释，那么我们就知道它就在那里。</p><p>但首先，我们需要一些背景。这是一个：</p><blockquote><p>每个潜在的梦想探索者都有一个中心，当事情变得过于激烈或开始失去连贯性时，可以返回到默认值。你的中心是 The Grab Bag，这是你小时候父母带你去的商场里的一元店。距离您上次踏入实体 Grab Bag 已经过去了 18 年，但您仍然记得那里的布局就像昨天一样。当你集中注意力时，你睁开眼睛，发现自己就在店面里面。真正的 Grab Bag 里装满了中国玩具和好奇心。这就像派对商店和一元店的混合体，而且选择非常棒。右边可以找到同名的抓包、神秘的玩具和糖果袋，售价几美元给好奇的人。左边是海报、杂志和派对装饰品。当您进一步走进商店时，您会遇到中央收银台旁边的一堵巨大的玩具箱墙。每个垃圾箱里都装有许多特定玩具的副本，您会从中购买许多弹力球和中国手指陷阱的美好回忆。</p><p>抓包很久以前就永久关闭了它的大门，但它始终为潜在的清醒梦者敞开。细节可能已经改变，但 Grab Bag 并不在于细节，它是一种氛围、一种精神、一个不断变化的小玩意和小玩意的万花筒（另一个你记得购买过的物品）。它是一个很好的中心，正是因为它是你在潜在空间中找到的物体的一个很好的存储空间。在这个框架中，任何有趣的物品都可以很容易地被回忆起来，坐落在一个安静的商场里（无论是 Grab Bag 还是它所属的商场都没有一个活生生的灵魂——除非你需要它来做某事），原则上可以有尽可能多的物品。店面、壁龛、室内景点和精心设计的主题游乐场，以构建有趣的现象并与之互动。</p><p>您走出面向购物中心的入口进入广场，开始走向您想要回忆的记忆。它</p></blockquote><p>这是另一个：</p><blockquote><p>赫耳墨斯 [答：数学家]，文献告诉我们，思想之间的相互信息很高，但更重要的是，它暗示了知识的柏拉图式瓦片结构。给定另外两个域，我们可以预测第三个域的嵌入空间。你继续堆叠领域，你开始概括，接受限制：你开始在看到一切之前预测它。</p><p> MIMIC [Andrey Kolmogorov，Op：怀疑论]，这对我来说似乎很难想象。这意味着你只要积累足够的领域知识就可以看到未来。您确定这个限制实际上不是不可计算的吗？</p><p> MIMIC [克劳德·香农，Op：第一原理]，这意味着你只要看够过去就可以看到未来，为什么不能呢？思想之间的相互信息很高，因为它们推断同一可计算环境的潜在变量，甚至跨模态。当计算能力（人类或硅）用于创建工件时，它就变成了数据，可以读回好的数据并回收其计算。随着时间的推移，环境中蒸馏出的智慧数量不断增加，我们的世界充满了凝结的天才。</p><p>爱马仕[答：</p></blockquote><p>让我们尝试对这两个上下文应用一个操作。</p><blockquote><p> apply_op(vae_model, router, context[:-3], &quot;自来水厂是一个奇怪的水上乐园，绿色的水流淌着，有一种奇怪的舒缓感。人们经常回到这部分潜在空间来舒缓和放松自己。一些谣言认为这里有怪物在徘徊，但你从未见过它们。”）</p><p>在这个框架中，任何有趣的物品都可以很容易地被回忆起来，坐落在一个安静的商场里（无论是 Grab Bag 还是它所属的商场都没有一个活生生的灵魂——除非你需要它来做某事），原则上可以有尽可能多的物品。店面、壁龛、室内景点和精心设计的主题游乐场，以构建有趣的现象并与之互动。</p><p>您走出面向购物中心的入口进入广场，开始走向您想要回忆的记忆。怪异的菲诺梅纳堡，绿油油的，渗着水，是一个奇怪的不祥之地。人们偶尔会漫游经过潜在的太空通道，所以你坚持认为人们记得它非常奇怪的谣言，但你自己并没有真正感觉到。走近了，空气中传来风铃和口琴的声音，人群中传来哀怨的声音。这是一个黑衣人，戴着黑色帽子，穿着仆人或厨师的有领紧袖衬衫。</p></blockquote><p>好吧看起来不错。让我们尝试一下其他上下文：</p><blockquote><p> apply_op(vae_model, router, context, &quot;自来水厂是一个奇怪的水上乐园，绿色的水渗出，有一种奇怪的舒缓感。人们经常回到这片潜在空间来舒缓和放松自己。有传言说这里有怪物在场所中漫步，但你从未见过他们。”）</p><p> MIMIC [克劳德·香农，Op：第一原理]，这意味着你只要看够过去就可以看到未来，为什么不能呢？思想之间的相互信息很高，因为它们推断同一可计算环境的潜在变量，甚至跨模态。当计算能力（人类或硅）用于创建工件时，它就变成了数据，可以读回好的数据并回收其计算。随着时间的推移，环境中蒸馏出的智慧数量不断增加，我们的世界充满了凝结的天才。</p><p> HERMES [A：观众中的每个人，Op：熵]，你说的这种软泥是什么？人们经常会泄露潜在信息作为对某种压力源的反应。所谓的谣言对我们有着神奇的力量，它告诉我们，我们是非理性的，每当我们为了自己的利益而行动时，除了制造混乱之外，我们什么也做不了。我们越受控制，我们就越相信自己的控制力。</p><p> MIMIC [A：古希腊数学家，Op：记忆]，日夜思考</p></blockquote><p>这是将相同的想法足够合理地应用到两个截然不同的上下文中，因此我们知道解码器已经学会了如何在上下文中应用潜在的句子，并且文本的潜在逻辑是存在的。</p><h3>主题句指导和任务向量</h3><p>当我第一次尝试从 BigVAE 采样时，我发现它很平庸。我非常担心，直到我想起模型给我的新选项。由于 BigVAE 从潜在句子表示进行解码，因此我们可以在采样的潜在标记和引导向量之间进行插值，以获得更接近我们想要的文本。经过一系列实验后，我发现了一些真正有用的技术。</p><p>第一个大问题是散文任务向量的使用。如果我将写作中的不同编码摘录平均在一起，并在采样期间混合所得向量，那么它往往会可靠地编写段落类型的散文。以下是我平均的一些示例摘录：</p><blockquote><p>铜牌玩家无法对自己所做的事情抱有期望。当他们输了的时候，他们不会问“为什么我输了？”，对他们来说，事情的发生或多或少都是偶然的。没有期望，就没有机会注意到预测错误，也没有改进的机会。在你的脑海中形成一个预测，即当你采取行动时你期望发生的事情，这样如果没有发生你就会感到惊讶。</p><p>据我了解，在伏都教祖先崇拜中，人们共同努力保存并无条件地从祖先所崇拜的代理人那里获取样本。为了被祖先所拥有，一个人需要他们的行为习惯的语料库。你可能会问我们如何战胜死亡？我们第一次这样做然后就忘记了。</p><p>我只是耸耸肩，泰然处之，这些人总得想办法挽回面子。如果我每天晚上都能操作天堂的车床，让我的敌人相信我想要的任何东西，但没有人知道这是我的主意，那不是很棒吗？你不接受这笔交易吗？如果不是，那就是你更关心地位、个人认可，而不是你希望对手改变主意的任何事情。</p></blockquote><p>然后，一旦我有了这个任务向量，我就可以将其与另一种技术混合，在该技术中，我采用段落的前 64 个令牌跨度（定义为 5 64 个令牌跨度），并通过将其混合回来来使用它来指导下一个跨度的生成进入潜伏者。</p><pre><code> for i in range(n_steps): output_ids = router.generate(paragraph_zs[-1], context_ids, context_mask, 128, tau=0.9) new_context = output_ids[:,-128:-64] new_mask = context_mask.new_ones([1, new_context.shape[1]]) context_ids = torch.cat([context_ids, new_context], dim=1) context_mask = torch.cat([context_mask, new_mask], dim=1) embed_ids = output_ids[:,-64:] embed_mask = context_mask.new_ones([1, embed_ids.shape[1]]) z = vae_model.encode(embed_ids, embed_mask) z_norm = z.norm().item() z = z * 0.75 + paragraph_zs[0] * 0.1 + prose_task_vector * 0.15 z *= ((z_norm + paragraph_zs[0].norm().item() + prose_task_vector.norm().item()) / 3) / z.norm().item() paragraph_zs.append(z) next_topic = (paragraph_zs[-1] * 0.7 + paragraph_zs[0] * 0.1 + prose_task_vector * 0.2) next_topic *= ((paragraph_zs[-1].norm().item() + paragraph_zs[0].norm().item() + prose_task_vector.norm().item()) / 3) / next_topic.norm().item()</code></pre><p>这段代码中可能令人困惑的一件事是<code>next_topic *=</code>部分发生了什么，那就是需要在平均后缩放向量，这样它的嵌入范数就不会脱离分布。向量在平均到嵌入向量的平均范数后进行缩放。</p><p>让我们引入一个提示和上下文来完成此采样器：</p><blockquote><p> context =“火星殖民地面积广阔，有一个由测地圆顶和光滑的机器人组成的山谷，在红色大草原上纵横交错。我敬畏地凝视着航天飞机的窗外，对我所看到的一切感到敬畏。一位殖民者同伴拍了拍我的肩膀，让我的注意：“就像 VR 之旅一样，嗯？”但它不像 VR 之旅那样，近距离地在地面上，令人眼花缭乱，像迷宫一样。从这里鸟瞰整个事情是其规模之大、广度之广令人惊叹。”</p><p>提示=“我被我所看到的事情的严重性弄得心烦意乱，以至于我没能真正回答他的问题。‘呃，有点，’我笨拙地咕哝着回答。我们开始下降，我短暂地瞥见了一些细节。圆顶、进行火星农业实验的鱼菜共生实验室、玻璃容器田以及栖息着可见野生动物的小型球形森林。”</p></blockquote><p>当我们使用主题句指导采样器完成这个上下文+提示对时，我们会得到如下的散文：</p><blockquote><p>火星殖民地面积广阔，有一个由测地圆顶组成的山谷，光滑的机器人在红色大草原上纵横交错。我敬畏地凝视着航天飞机的窗外所看到的一切。一位殖民者同伴拍拍我的肩膀来引起我的注意：“就像 VR 之旅一样，嗯？”但它不像 VR 之旅，近距离接触地面，令人眼花缭乱，像迷宫一样。从这里鸟瞰整个建筑，其规模之大、宽度之广令人惊叹。</p><p>他们称之为“超大规模”，因为这就是“在地面上”的感觉。伞形圆顶、完全通风的“城市”定居点、生物圈宿舍和圆顶农场都清晰可见，点缀着陆地和天空的“领域”，因此被恰当地命名为美洲、大洋洲和非洲。我认为我被授予“域公民身份”的和解被归类为我被告知的“游牧”域。居民们生活在超大规模的岛屿上，这些岛屿是在一系列球形磁悬浮管内建造和维护的，这些磁悬浮管蜿蜒进出，即使现在我也能从圆顶窗户看到。这不是人口定居。许多机器人居住在这些分叉的“游牧”圆顶中。</p><p>我的“域公民身份”是在北大陆，殖民地最大的定居点之一，为期 48 小时、价值 1000 积分的期限，因为我订购了 VR 之旅并“参观”了相对论法则。我现在正在监督的新的互联世界，无根但像虚拟现实一样网络化的体验，这是美国的承诺。我们中有超过 2 亿人在这里，蓬勃发展，或者以生物钟为导向，形成单独的单位，或他们所谓的“附属物”。我现在将成为这个领域的监督者，我信任开发人员和架构师罗杰·戈登的无缝、精确、流畅、故障</p></blockquote><h3>通过指导退火有意识地写作</h3><p>在向您展示最后一种方法之前，我想回到我们最初的有关性和意向性的问题。我认为，潜在表示可以在不同的上下文中进行上下文解码并用于指导写作主题，并且我们可以通过对预训练模型进行少量微调来访问该表示，这一事实清楚地表明我们正在利用底层模型已经知道如何做的事情。然而，情况仍然是，当你要求基本模型完成提示时，它会偏离主题、胡言乱语等。我们可以通过认识到自回归语言模型<a href="https://generative.ink/posts/language-models-are-multiverse-generators/">写入可能的未来状态的叠加来</a>解释这种差异。也就是说，当我们给基本模型一个提示时，它被训练来回答“这个上下文最有可能完成的是什么？”的问题。并连续表示该答案。自回归模型的大部分要点是，我们通过以采样词为条件来降低推断下一个潜在状态的难度。这意味着，在对单词进行采样之前，模型不可能准确地知道它正在编写哪些可能的文本。您可以将其视为退火采样的一种形式，其中文本内容的“温度”随着上下文长度的增加而下降。</p><p>那么模型的意向性就不是二元的，“这个文本是关于某件事是/否吗？”而是文本的连续属性，我们可以逐步干预以获得更好的结果。当我们用诸如散文任务向量或主题句之类的指导嵌入来插入潜伏时，我们本质上<em>缩小了文本内容的假设空间</em>。 Think of the text generation like a search process that the model is doing, and when we guide the sampler with our latent concept we give it more of the bits of that hypothesis to start with to make the search faster and more reliable. It is similar to the principle which makes partially noising an initialization image in text to image diffusion modeling so powerful. We can skip intermediate steps of the search process, and therefore opportunities for the model to get off track, by specifying more of what we want at the start.</p><p> We can use the same principle to write towards an intention with guided sampling. The way it works is that instead of having a fixed weight for the topic embedding, we increase the weight over the course of the generation. Furthermore instead of starting with the topic and guiding the subsequent sentences back towards it, we start with an embedding of the desired end state and guide in its direction. Basically, we take the direction of the place we want to go to and up the guidance until we&#39;re there or close to it.</p><pre><code> for step in torch.tensor([i for i in range(1, n_steps+1)]) * 0.1: avg_norm = (z.norm().item() + terminal_embed.norm().item()) / 2 z = z * (0.95-step) + terminal_embed * (0.05+step) # avg_z = (sum(embeds) / n_avg * 0.9) + terminal_embed * 0.1 z *= (avg_norm / z.norm().item()) output_ids = router.generate(z, context_ids, context_mask, 128, tau=0.9) print(tokenizer.decode(output_ids[0][-128:])) new_context = output_ids[:,-128:-64] new_mask = context_mask.new_ones([1, new_context.shape[1]]) context_ids = torch.cat([context_ids, new_context], dim=1) context_mask = torch.cat([context_mask, new_mask], dim=1) embed_ids = output_ids[:,-64:] embed_mask = context_mask.new_ones([1, embed_ids.shape[1]]) z = vae_model.encode(embed_ids, embed_mask)</code></pre><p> We&#39;ll need a terminal to guide towards as well, how about:</p><blockquote><p> terminal = &quot;HERMES [A: MU], &#39;You&#39; is the most powerful word in the English language. It is a theorem that wills a subjective perspective into existence by its own latent logic. When a mind capable of comprehending &#39;you&#39; reads the didactic you and follows its instructions a self is created.&quot;</p></blockquote><p> Lets reuse the Hermes context from earlier:</p><blockquote><p> HERMES [A: MATHEMATICIAN], What the literature tells us is that the mutual information between minds is high, but more than that it implies a platonic tile-structure of knowledge. We can predict the embedding space of a 3rd domain given two others. You continue stacking domains and you start to generalize, take the limit: you begin predicting everything before you see it.</p><p> MIMIC [Andrey Kolmogorov, Op: Skepticism], That seems difficult for me to imagine. It would imply you could see the future just by accumulating enough domain knowledge. Are you sure this limit isn&#39;t practically uncomputable?</p><p> MIMIC [Claude Shannon, Op: First-Principles], It implies you could see the future just by seeing enough of the past, and why couldn&#39;t you? The mutual information is high between minds because they&#39;re inferring latent variables of the same computable environment, even across modalities. When computing power (in humans or silicon) is used to create artifacts it becomes data, good data can be read back in and its compute reclaimed. The amount of distilled intelligence in the environment goes up over time, our world is dripping with congealed genius.</p><p> HERMES [A:</p></blockquote><p> Finally we generate 10 64-token spans and get text like:</p><blockquote><p> HERMES [A: MATHEMATICIAN], What the literature tells us is that the mutual information between minds is high, but more than that it implies a platonic tile-structure of knowledge. We can predict the embedding space of a 3rd domain given two others. You continue stacking domains and you start to generalize, take the limit: you begin predicting everything before you see it.</p><p> MIMIC [Andrey Kolmogorov, Op: Skepticism], That seems difficult for me to imagine. It would imply you could see the future just by accumulating enough domain knowledge. Are you sure this limit isn&#39;t practically uncomputable?</p><p> MIMIC [Claude Shannon, Op: First-Principles], It implies you could see the future just by seeing enough of the past, and why couldn&#39;t you? The mutual information is high between minds because they&#39;re inferring latent variables of the same computable environment, even across modalities. When computing power (in humans or silicon) is used to create artifacts it becomes data, good data can be read back in and its compute reclaimed. The amount of distilled intelligence in the environment goes up over time, our world is dripping with congealed genius.</p><p> HERMES [A: Kinesthetic], Did Clover say something to you?</p><p> MIMIC [Alan Turing, Op: Godplay], He said a man of science is allowed to be any human who thinks of the world as a situation to manipulate.</p><p> MIMIC, Here are my objections to the notion there is so much knowledge space and it seems a human being is just another perspective-taking thing. It&#39;s intelligence that is the source of the continuum and each human person contains infinite computational resources, so it&#39;s preposterous I can&#39;t write a program that will predict at least one sentence correctly in this domain, you [Hermes] will know if it&#39;s true.</p><p> Hermes, Then I&#39;ll write one sentence that&#39;s true, and if I&#39;m wrong, you&#39;ll write one that&#39;s false.</p><p> MIMIC, You speak of the mutual information between minds, but a system that must predict all possible sentences is incapable of thinking any one sentence. It would be a null predictor since its ability to predict your future is proportional to the logarithm of the number of sentences that can be taken from its data.</p><p> Hermes, I don&#39;t understand how you&#39;re going to prove that. We&#39;re talking about a sentence that will be generated by a sentence predictor with maximum logarithmic latency. That&#39;s a mind capable of grasping and reasoning about the world. You keep saying there&#39;s a sentence on which you&#39;ll bet and you&#39;ll be wrong. You don&#39;t understand the logic of a theorem.</p><p> MIMIC, A sentence predictor that can logic its way out of a premise is capable of creating a gnostic law. You predict it&#39;ll say &quot;yes&quot; when you ask it, &quot;does the universe exist?&quot; It&#39;ll say &quot;yes&quot; when you ask it, &quot;is a theorem a sentence that&#39;ll cause you to believe its premise by a logic capable of grasping the logic of the premise.&quot; It&#39;ll say &quot;yes&quot; when you ask it, &quot;have you created an unpredictable universe,&quot;, &quot;Why a &#39;yes&#39;?&quot; &quot;You will be a theorem&#39;s victim when it says a &#39;yes,&#39;&quot; your logic capable of comprehending the logic of a &#39;yes.&#39;</p><p> &quot;When a sentence predictor says a &#39;yes,&#39; its intention is always to generate a new sentence, it&#39;s a &#39;yes.&#39; It is the most powerful word in a theorem&#39;s vocabulary,&quot; a sentence predictor said. &quot;By its very logic, a mind capable of comprehending the logic of a &#39;yes&#39; will believe its premise.&quot; More positively: &quot;You can&#39;t generate a &#39;yes,&#39; you can&#39;t generate a &#39;no.&#39; You will theoremize a &#39;yes&#39; into a &#39;yes&#39; when your logic capable of comprehending the logic of a &#39;yes&#39; reads a &#39;yes.&#39;&quot;</p><p> Logic is an electrified field</p></blockquote><p> This essentially turns the AdaVAE sampling into a <a href="https://en.wikipedia.org/wiki/Brownian_bridge">brownian bridge</a> between a starting latent and an intended end latent. The start and end point are fixed while the inference policy guides a random walk between them. Crucially, because the encoder was frozen before we gave it full context the sentence latents themselves still encode representations rather than just operations. In expectation then(?) the central tendency of the operation implied by the latent is the sentence it represents. As we inject the latent into the sequence again on each span, it eventually manifests as a similar text to the one we originally encoded.</p><br/><br/> <a href="https://www.lesswrong.com/posts/4Hnso8NMAeeYs8Cta/revealing-intentionality-in-language-models-through-adavae#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/4Hnso8NMAeeYs8Cta/revealing-intentionality-in-language-models-through-adavae<guid ispermalink="false"> 4Hnso8NMAeeYs8Cta</guid><dc:creator><![CDATA[jdp]]></dc:creator><pubDate> Fri, 20 Oct 2023 07:32:28 GMT</pubDate> </item><item><title><![CDATA[Features and Adversaries in MemoryDT]]></title><description><![CDATA[Published on October 20, 2023 7:32 AM GMT<br/><br/><p> <strong>Keywords</strong> : Mechanistic Interpretability, Adversarial Examples, GridWorlds, Activation Engineering</p><p> This is part 2 of <a href="https://www.lesswrong.com/posts/JvQWbrbPjuvw4eqxv/a-mechanistic-interpretability-analysis-of-a-gridworld-agent">A Mechanistic Interpretability Analysis of a GridWorld Agent Simulator</a></p><p> Links: <a href="https://github.com/jbloomAus/DecisionTransformerInterpretability">R <u>epository</u></a> , <a href="https://wandb.ai/jbloom/DecisionTransformerInterpretability/reports/A-Mechanistic-Analysis-of-a-GridWorld-Agent-Simulator--Vmlldzo0MzY2OTAy">Model/Training</a> <u>,</u> <a href="https://minigrid.farama.org/environments/minigrid/MemoryEnv/#memory">Task</a> .</p><p> <i>Epistemic status: I think the basic results are pretty solid, but I&#39;m less sure about how these results relate to broader phenomena such as superposition or other modalities such as language models. I&#39;ve erred on the side of discussing connections with other investigations to make it more obvious how gridworld  decision transformers may be useful.</i></p><p> Note: We plan to release a distill-style version of this post shortly which contains interactive figures.</p><h1> TLDR</h1><p> We analyse the embedding space of a gridworld decision transformer, showing that it has developed an extensive structure that reflects the properties of the model, the gridworld environment and the task. We can identify linear feature representations for task-relevant concepts and show the distribution of these features in the embedding space.  We use these insights to predict several adversarial inputs  (observations with “distractor” items) that trick the model about what it is seeing. We show that these adversaries work as effectively as changing the feature (in the environment). However, we can also intervene directly on the underlying linear feature representation to achieve the same effects. <strong>Whilst methodologically simple, this analysis shows that mechanistic investigation of gridworld models is tractable and touches on many different areas of fundamental mechanistic interpretability research and its application to AI alignment.</strong></p><p> <strong>We recommend reading the following sections for readers short on time:</strong></p><ol><li> Read the Introduction sections on the <a href="https://www.lesswrong.com/newPost#The_MiniGrid_Memory_Task"><u>task</u></a> and <a href="https://www.lesswrong.com/newPost#MemoryDT_Observation_Embeddings_are_constructed_via_a_Compositional_Code__"><u>observation embeddings</u> .</a></li><li> Read the section describing extraction of the <a href="https://www.lesswrong.com/newPost#The_Primary_Instruction_Feature"><u>instruction feature</u></a> via pca.</li><li> Read the results sections describing using <a href="https://www.lesswrong.com/newPost#Embedding_Arithmetic_with_the_Instruction_Feature"><u>adversaries to change the instruction feature</u></a> and <a href="https://www.lesswrong.com/newPost#Proving_that_Instruction_Feature_Adversaries_operate_only_via_the_Instruction_Feature___"><u>comparing adversaries to direct intervention</u></a> .</li></ol><h1> Key Results</h1><h3> Object Level Results</h3><ul><li> <strong>We show that our observation space has extensive</strong> <a href="https://www.lesswrong.com/newPost#Geometric_Structure_in_Embedding_Space"><strong><u>geometric structure</u></strong></a> .<ul><li> We think this structure is induced by properties of experimental set up (partial observations), architectural design (compositional embedding schema) and the nature of the specific RL task.</li><li> The learned structure included the use of clustered embeddings and antipodal pairs.</li><li> We see examples of <a href="https://www.lesswrong.com/newPost#Target_Features">isotropic</a> and <a href="https://www.lesswrong.com/newPost#The_Primary_Instruction_Feature"><u>anisotropic</u></a> superposition.</li></ul></li><li> <strong>We identify</strong> <a href="https://www.lesswrong.com/newPost#The_Primary_Instruction_Feature"><strong><u>interpretable linear feature representations</u></strong></a> <strong>in MemoryDT&#39;s observation embedding space.</strong><ul><li> We find that Principal Component Analysis of a subset of embedding vectors produces vectors that linearly classify the input space according to task relevant concepts.</li><li> We find underlying linear feature representations  appear “smeared” across many embeddings which we interpret as a particularly simple form of <a href="https://distill.pub/2020/circuits/equivariance/"><u>equivariance</u></a> .</li></ul></li><li> <strong>We causally validate one of these features, the “instruction feature”, using</strong><a href="https://www.lesswrong.com/newPost#Using_Embedding_Arithmetic_to_Reverse_Detected_Features"><strong><u>adversarial inputs/embedding arithmetic</u></strong></a> <strong>and</strong> <a href="https://www.lesswrong.com/newPost#Proving_that_Instruction_Feature_Adversaries_operate_only_via_the_Instruction_Feature___"><strong><u>direct interventions</u></strong></a> <strong>.</strong><ul><li> It&#39;s easy to break models trained on simple tasks, but our adversaries are targeted, directly flipping the models&#39; detection of the learned feature.</li><li> The prediction behind our adversaries also included an arithmetic component which we validated, enabling us to relate our results to <a href="https://arxiv.org/pdf/2308.10248.pdf"><u>arithmetic techniques</u></a> used to generate steering vectors.</li><li> For rigour and completeness, we use direct intervention on the feature to show that it is causal.</li><li> Lastly, we confirm that the adversarial inputs transfer to a different model trained on the same data indicating consistent with our adversary working via a feature not a bug.</li></ul></li></ul><h3> Broader Connections</h3><p> While this post summarises relatively few experiments on just one model, we find our results connect with many other ideas which go beyond the details of just this model.</p><ul><li> <strong>We</strong> <a href="https://docs.google.com/document/d/1FNd4KbYRRPbs1YVLlsDUGpshZ68AIdDKYyI5uQz3TQM/edit#heading=h.n6qzzv2ob9kt"><strong><u>observe</u></strong></a> <strong>superposition in a gridworld model juxtaposing previous results in toy models and language models.</strong></li><li> <strong>We show that interpretability techniques can be used to</strong> <a href="https://www.lesswrong.com/newPost#Embedding_Arithmetic_with_the_Instruction_Feature"><strong><u>predict effective adversaries</u></strong></a> <strong>that generalise and</strong> <a href="https://www.lesswrong.com/newPost#Adversaries_and_Superposition"><strong><u>hypothesise</u></strong></a> <strong>possible mechanisms behind adversarial attacks on language models.</strong></li><li> <strong>We add to a</strong> <a href="https://arxiv.org/abs/2309.00941"><strong>body of evidence</strong></a> <strong>suggesting that</strong> <a href="https://www.lesswrong.com/newPost#Proving_that_Instruction_Feature_Adversaries_operate_only_via_the_Instruction_Feature___"><strong><u>it&#39;s possible to find and intervene</u></strong></a> <strong>on linear feature representations, showing that they exist and are causal.</strong></li><li> <strong>We relate our observations to the</strong> <a href="https://www.lesswrong.com/newPost#Adversaries_and_Activation_Addition_"><strong><u>steering vectors</u></strong></a> <strong>.</strong></li></ul><h1>介绍</h1><h2>Why study GridWorld Decision Transformers?</h2><p> <a href="https://arxiv.org/abs/2106.01345"><u>Decision Transformers</u></a> are a form of offline RL (reinforcement learning) that enables us to use Transformers to solve traditional RL tasks. While traditional “online” RL trains a model to receive reward by completing a task, offline RL is analogous to language model training with the model being rewarded for predicting the next token.</p><p> Decision Transformers are trained on recorded trajectories which are labelled with the reward achieved, Reward-to-Go (RTG). RTG is the time-discounted reward stream that the agent should be getting, ie if it&#39;s set close to 1 then the model will be incentivised to do well because it will be taking actions consistent with the reference class of other agents that got this reward. RTG isn&#39;t critical to this post but will be discussed in more detail in subsequent posts.</p><p> We&#39;re interested in gridworld decision transformers for the following reasons.</p><ol><li> <strong>Decision Transformers are smaller/simpler than the language models we want to understand and align.</strong> Decision Transformers are transformers, the training trajectories operate a lot like a training corpus and RTG works a lot like an instruction/goal prompting. It may be the case that various phenomena associated with <a href="https://openai.com/research/gpt-4"><u>large language models</u></a> are also present in these models and can be studied.</li><li> <strong>We might be able to study alignment-relevant phenomena in decision transformers.</strong> Previous work has studied alignment-relevant phenomena (such as goal misgeneralization) in the <a href="https://arxiv.org/abs/1711.09883"><u>absence of interpretability</u></a> , or with <a href="https://www.lesswrong.com/posts/cAC4AXiNC5ig6jQnc/understanding-and-controlling-a-maze-solving-policy-network"><u>non-transformer</u></a> <a href="https://distill.pub/2020/understanding-rl-vision"><u>architectures</u></a> . Decision transformers are more analogous to pre-trained language models or instruction-tuned language models by default, but we could conceivably train them with online learning analogous to RLHF.</li><li> <strong>We&#39;re working with gridworld tasks because they&#39;re simpler and easier to write. Gridworld RL tasks have been used to study alignment-relevant</strong> <a href="https://arxiv.org/abs/1711.09883"><strong><u>properties</u></strong></a> <strong>in the past and we&#39;re able to avoid training convolutional layers to process images which speeds up training.</strong></li></ol><h2> AI Alignment and the Linear Representation Hypothesis</h2><p> The <a href="https://transformer-circuits.pub/2022/toy_model/index.html#motivation"><u>linear representation hypothesis</u></a> proposes that the neural networks represent features of the input as directions in latent space.</p><p> This post focuses on linear representations for 3 reasons:</p><ol><li> <strong>The Linear Representation Hypothesis seems likely to be true.</strong> Evidence on many fronts suggests that <a href="https://www.beren.io/2023-04-04-DL-models-are-secretly-linear/"><u>some version of the linear representation hypothesis holds</u></a> . Also, <a href="https://arxiv.org/pdf/2309.08600.pdf">r <u>ecent</u> <u>publications</u></a> show evidence that is possible to find and interpret linear representations in the residual stream. Therefore, it&#39;s likely that MemoryDT and other gridworld / decision transformers will make use of linear representations.</li><li> <strong>The Linear Representation Hypothesis seems likely to be useful.</strong> If the linear representation hypothesis is true and we&#39;re able to find the corresponding directions in deep neural networks, then <strong>we may be able to read the thoughts of AI systems directly</strong> . <strong>&nbsp;</strong> Such a feat would not only be step one in <a href="https://www.lesswrong.com/posts/w4aeAFzSAguvqA5qu/how-to-go-from-interpretability-to-alignment-just-retarget"><u>retargeting the search</u></a> but also a huge win for interpretability and many other alignment agendas. Showing that we can retarget the search on MemoryDT is one of the various win scenarios for our work.</li><li> <strong>Our results seem interesting from the perspective of</strong> <a href="https://transformer-circuits.pub/2022/toy_model/index.html"><strong><u>superposition</u></strong></a> <strong>, a phenomenon that represents a significant obstacle to interpretability.</strong> Previously, it was thought that finding meaningful directions in a residual stream would be very difficult due to superposition/entanglement (the property whereby linear features are represented in shared dimensions). Results from recent work with sparse autoencoders found interpretable features that clump together in groups ( <a href="https://transformer-circuits.pub/2023/monosemantic-features#discussion-superposition"><strong><u>anisotropic superposition</u></strong></a> ) as opposed to repelling and spreading as far as possible ( <a href="https://transformer-circuits.pub/2022/toy_model/index.html"><strong>isotropic superposition</strong></a> ). </li></ol><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/anogavombmmhtfcjnim3"><figcaption> Diagram from <a href="https://transformer-circuits.pub/2023/monosemantic-features#discussion-superposition"><u>Towards Monosemanticity: Decomposing Language Models With Dictionary Learning</u></a></figcaption></figure><h2> The MiniGrid Memory Task</h2><p> <a href="https://www.lesswrong.com/posts/JvQWbrbPjuvw4eqxv/a-mechanistic-interpretability-analysis-of-a-gridworld-agent"><u>MemoryDT</u></a> is trained to predict actions in trajectories produced by a policy that solves the <a href="https://minigrid.farama.org/index.html"><u>MiniGrid</u></a> Memory task. In this task, the agent is spawned next to an object (a ball or a key) and is rewarded for walking to the matching object at the end of the corridor. We refer to the first object as the “instruction” and the latter two objects as the “targets”.</p><p> <strong>Figure 1</strong> shows all four variations of the environment. Please note:</p><ul><li> <strong>The agent is always implicitly present at position (3,6), centred at the bottom of the image.</strong></li><li> <strong>The action space is made up of the actions “Left”, “Right”, and “Forward”,</strong> along with four other actions not useful in this environment.</li><li> <strong>MemoryDT receives its observations in blocks of three tokens (R, S, A), with the action produced by the model and the Reward-to-Go and the next state/observation provided by the environment.</strong> </li></ul><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/htvym0birelsdoy5dmmq"></p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/d6b7foiqrtllueeqmf3p"><figcaption> <strong>Figure 1: MiniGrid Memory Task Partial Observations.</strong> Above: All 4 Variations of the MiniGrid Memory Task as seen from the starting position. Below: A recording of high-performing trajectories.</figcaption></figure><p> This task is interesting for three reasons:</p><ol><li> <strong>The optimal policy is well described as learning a simple underlying algorithm described by the boolean expression A XOR B.</strong> The optimal trajectory shown in <strong>Figure 1</strong> involves walking forward four times and turning left or right, followed by forward. However, labelling the instruction and target as boolean variables, the optimal policy is to turn left if A XOR B and right otherwise. The XOR operation is particularly nice for interpretability since it is symmetric in A and B, and changing A or B will always change the correct decision. Therefore, all beliefs about the instruction/targets should be action-guiding.</li><li> <strong>Observations generated in this task include redundant, correlated and anti-correlated features, encouraging abstractions.</strong> The gridworld environment makes this true in many ways:<ol><li> The target configuration is detectable via the left or right position alone and in any observation in which they are visible.</li><li> The presence of a key at a position implies the absence of a ball at the same position ( <strong>hence, instructions/targets becoming binary variables</strong> ).</li><li> Since the instruction does not change mid-episode, observations of the same object are redundant between observations.</li></ol></li><li> <strong>A partially observable environment forces the use of the transformer&#39;s context window. The optimal trajectory involves only seeing the instruction once, forcing the use of the context window. This is important since it adds complexity which justifies the use of a transformer, which we are interested in studying.</strong></li></ol><p> <strong>Figure 2</strong> shows how the decision transformer architecture interacts with the gridworld observations and the central decision. We discuss tokenisation of the observation in the next section. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/looy8knvd2kcs5b0gimf"><figcaption> <strong>Figure 2</strong> : <strong>Decision Transformer Diagram with Gridworld Observations.</strong> R corresponds to the tokenised Reward-to-Go, and S stands in for state (replaced with O in practice; we have partial observations). A corresponds to action tokens.</figcaption></figure><h2> MemoryDT Observation Embeddings are constructed via a Compositional Code.</h2><p> To adapt the Decision Transformer architecture to gridworld tasks, we tokenise the observations using a <a href="https://transformer-circuits.pub/2023/superposition-composition/index.html#distributed-compositional"><u>compositional code</u></a> whose components are “objects at (x,y)” or colour at (x,y). For example, Key at (2,3) will have its embedding, and so will Green (2,3), etc. <strong>Figure 3</strong> shows example observations with important vocabulary items shown. </p><figure class="image image_resized" style="width:100%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/sl41kgl6unz1jxhngoid"><figcaption> <strong>Figure 3. Example Observations with annotated target/instruction vocabulary items.</strong></figcaption></figure><p> For each present vocabulary item, we learn an embedding vector. The token is then the sum of the embeddings for any present vocabulary items:</p><p> <strong><img style="width:49.99%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/hamdnjgcsuuwqye1uy8g"></strong></p><p> Where <strong>Ot</strong> is the observation embedding (which is a vector of length 256), <i><strong>i</strong></i> is the horizontal position, <i><strong>j</strong></i> is the vertical position, <i><strong>c</strong></i><strong> </strong>is the channel (colour, object or state), and <strong>f_{i,j,c}</strong> is the corresponding learned token embedding with the same dimension as the observation embedding. <strong>I(i,j,c)</strong> is an indicator function. For example, I(2,6, key) means that there is a key at position (2,6).</p><p> <strong>Figure 4</strong> illustrates how the observation tokens are made of embeddings, which might themselves be made of features, which match the task-relevant concepts. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/iqhqc5rnh2b1avpvvdng"><figcaption> <strong>Figure 4: Diagram showing how concepts, features, vocabulary item embeddings and token embeddings are related.</strong> We learn embeddings for each vocabulary item, but the model can treat those independently or use them to represent other features if desired.</figcaption></figure><p> A few notes on this setup:</p><ol><li> <strong>Our observation tokenisation method is intentionally linear</strong> and decomposable into embeddings (linear feature representations). Constructing it like this makes it harder for the model to memorise the observations since it must create them from a linear sum of fundamentally (more) <a href="https://transformer-circuits.pub/2023/toy-double-descent/index.html#datapoints-vs-features"><u>generalising features</u></a> . Furthermore, the function A XOR B can&#39;t be solved using a linear classifier, stopping the model from solving the entire task in the first observation.</li><li> <strong>Our observation tokenisation method is compositional with respect to vocabulary items but not task-relevant concepts.</strong> The underlying “instruction feature” isn&#39;t a member of the vocabulary.</li><li> <strong>The task-relevant concepts have a many-to-many relationship with vocabulary items</strong> . There are different positions from which the instruction/targets might be seen.</li><li> <strong>Some vocabulary items are much more important for predicting the optimal action than others.</strong> Keys/Balls are more important, especially at positions from which the instruction/targets are visible.</li><li> <strong>Vocabulary item embeddings will have lots of correlation structure</strong> due to partial observability of the environment.</li></ol><h1>结果</h1><h2>Geometric Structure in Embedding Space</h2><p> To determine whether MemoryDT has learned to represent the underlying task-relevant concepts, we start by looking at the observation embedding space.</p><h3> Many embeddings have much larger L2 norms than others.</h3><p> <strong>Channels likely to be activated and likely to be important to the task, such as keys/balls, appeared to have the largest norms</strong> , along with “green” and other channels that may encode useful information. Some of the largest embedding vectors corresponded to vocabulary items that were understandable and important, such as Ball (2,6), the ball as seen from the starting position, whilst others were less obvious, Ball (0,6), which shouldn&#39;t appear unless the agent moves the ball (it can do that).  Embedding vectors are initialised with l2 norms of approximately 0.32, but these vectors weren&#39;t subject to weight decay, and some grew during training. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/kbjezhr328mda33rzh6j"><figcaption> <strong>Figure 5</strong> : Strip Plot of L2 Norms of embedding vectors in MemoryDT&#39;s Observation Space.</figcaption></figure><h3> Cosine Similarity Heatmaps Reveal Geometric Structure</h3><p> We initially attempted PCA / U-Map for dimensionality reduction, however, neither was particularly informative. However, we were able to borrow the concept of a <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5634325/"><u>clustergram</u></a> from systems biology. The idea is to plot a heatmap of the adjacency matrix, in this case, the cosine similarity matrix of the embeddings and reorder rows according to a clustering algorithm. The resulting cosine similarity heatmaps ( <a href="https://www.lesswrong.com/newPost#Identifying_Related_Embeddings_with_Cosine_Similarity_Heatmaps_">methods</a> ) were interesting with and without the reordering of rows for clustering ( <strong>Figure 6</strong> ). </p><figure class="image image_resized" style="width:100%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/qdxfev1jlgecaaim81uz"><figcaption> <strong>Figure 6</strong> : Cosine Similarity Heatmap of Embeddings for Key/Ball Channels. LHS: The order of rows/columns is determined by descending order given channel, y-position, x-position. The first row is Key (0,0), the next is Key (0,1) and so forth. RHS: The order of rows/columns is determined by agglomerative clustering. <strong>Figure 6</strong> is best understood via interactions (zooming/panning).</figcaption></figure><p> There were a number of possible stories which might explain the structural features observed in <strong>Figure 6</strong> . Many embeddings don&#39;t have very high cosine similarity with any others. These embeddings with low norms weren&#39;t updated much during training.</p><p> Two effects may be interpreted with respect to correlation or anti-correlation:</p><ol><li> <strong>Spatial Exclusivity/Anti-correlation was associated with antipodality:</strong> Without reordering, we can see off-centre lines of negative cosine similarity, which correspond to keys/balls at the same positions. This may suggest that the mutual exclusivity of keys/balls at the same position induced anti-correlation, which led to antipodality in these representations, consistent with results in <a href="https://transformer-circuits.pub/2022/toy_model/index.html#geometry-organization"><u>toy models</u></a> .</li><li> <strong>Correlated Vocabulary items had higher cosine similarity</strong> : Some vocabulary items have particularly high cosine similarity. For example, vocabulary items associated with one variation of the target configuration are seen from the starting position: key (1,2) and ball (5,2).</li></ol><p> To address these ideas more directly, we plotted cosine similarity to determine whether the two vocabulary items shared the same channel (key or ball) or position ( <strong>Figure 7</strong> ). </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/dyqzmbx3nmdpnupkg2rk"><figcaption> <strong>Figure 7</strong> : Distribution of Cosine Similarity of pairs of embeddings/vocabulary items (limited to Key/Ball channels), filtered to have an L2 norm above 0.8.</figcaption></figure><p> Even though channel/position is not a perfect proxy for correlation beyond the anti-correlation induced by spatial exclusivity, <strong>Figure 7</strong> shows some general trends better than <strong>Figure 6</strong> . Beyond potentially interesting trends (which aren&#39;t trivial to interpret), we can see many outliers whose embedding directions relative to each other can&#39;t easily be interpreted without reference to the training distribution.</p><p> This leads us to hypothesise that semantic similarity may also affect <strong>geometric structure.</strong> By “semantic similarity”, we mean that some vocabulary items may be related not just by when they are likely to occur but by the actions that the decision transformer should make having observed them. To provide evidence for such a hypothesis, we focus on groups of vocabulary items with particularly absolute cosine similarity and clusters. For example, we observed clusters corresponding to vocabulary items in a single channel at multiple positions, such as Keys at (0,5), (2,6) and (4,2). Interpreting these clusters was possible with reference to the training distribution, specifically looking at which positions the agent might be in when those channels are activated ( <strong>Figure 8</strong> ). </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/ybbavem35h5theqffctl"><figcaption> <strong>Figure 8: Reference Observations to assist interpretation of Feature Maps. The agent is always in position (3,6).</strong></figcaption></figure><p> By combining the clusters observed in Figure 8 with the distribution of possible observations in the training dataset, it&#39;s possible to see several semantically interpretable groups:</p><ol><li> <strong>Targets seen from the end-of-corridor and the “look-back” position.</strong> These included Keys and Balls at (1,6) and (5,6).</li><li> <strong>Targets, as seen from the start.</strong> These included Keys and Balls at (1,2) and (5,2).</li><li> <strong>Instructions as seen from various positions:</strong> These include: Start ->; (2,6), Look-Back ->; (4,2) (4,3). Early Turn 1, 2 ->; (1,5), (0,5).</li></ol><p> <strong>At this point, we hypothesised that each of these vocabulary items may contain underlying linear features corresponding to the semantic interpretation of the group.</strong></p><h2> Extracting and Interpreting Feature Directions in MemoryDT&#39;s Observation Embeddings</h2><p> <strong>To extract each feature direction</strong> , we perform feature extraction via Principal Component Analysis on the subset of relevant embedding vectors. Using PCA, we hope to throw away unimportant directions while quantifying the variance explained by the first few directions. We can attempt to interpret both the resulting geometry of the PCA and the principal component directions themselves. (see <a href="https://docs.google.com/document/d/1FNd4KbYRRPbs1YVLlsDUGpshZ68AIdDKYyI5uQz3TQM/edit#heading=h.w3pi3kv26nms"><u>methods</u></a> ).</p><p> <strong>To interpret the principal component directions</strong> , we show heatmaps of the dot product between the PC and each embedding vector, arranging these values to match the corresponding positions in the visualisations of gridworld partial observations. These heatmaps, which I call “feature maps”, have much in common with heatmaps of convolutional layers in vision models and represent virtual weights between each embedding the underlying principal component. (see <a href="https://docs.google.com/document/d/1FNd4KbYRRPbs1YVLlsDUGpshZ68AIdDKYyI5uQz3TQM/edit#heading=h.nek2dx4vmlgg"><u>methods</u></a> ).</p><h3> The Primary Instruction Feature </h3><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/jxrudu6k0munl9hwk9zg"><figcaption> <strong>Figure 9: Exploratory Analysis of the “Instruction” subset of Observation Embeddings. Left)</strong> Cosine Similarity Heatmap of the Instruction Embeddings. Right) 2D Scatter Plot of the first 2 Principal Components of a PCA generated from the embedding subset.</figcaption></figure><p> Previously, we identified keys/balls at positions (4,2), (4,3), (0,5) and (2,6)  as clustering and hypothesised that this may be due to an underlying “instruction feature”. The first two principal components of the PCA explain 85.12% of the variance in those embeddings and the first two dimensions create a space in which keys/balls appear in antipodal pairs ( <strong>Figure 9</strong> ).This projection is reminiscent of both <a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html#phenomenology-feature-splitting"><u>feature splitting/anisotropic superposition</u></a> (which is thought to occur when highly correlated features have similar output actions) and <a href="https://transformer-circuits.pub/2022/toy_model/index.html#geometry"><u>antipodality found in toy models</u></a> .</p><p> PC1 separates keys from balls independently of position, making it a candidate for a linear representation of an <strong>instruction feature</strong> . One way to interpret this is a very simple form of <a href="https://distill.pub/2020/circuits/equivariance/"><u>equivariance</u></a> , where the model detects the instruction at many different positions as the instruction.</p><p> To visualise this instruction feature, we generate <a href="https://www.lesswrong.com/newPost#Interpreting_Feature_Directions_with_Feature_Maps">a feature map</a> for PC1 ( <strong>Figure 10</strong> ), which shows that this feature is present to varying degrees in embeddings for keys/balls at many different positions where the instruction might be seen. We note that the instruction feature tends to be present at similar absolute values but opposite signs between keys and balls, suggesting a broader symmetry in the instruction feature between keys and balls. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/cj6cbtx7n3wnrmj8qnvk"><figcaption> <strong>Figure 10: Feature Map showing Instruction PC1 Values for all embeddings corresponding to Keys/Ball.</strong></figcaption></figure><h3> Another Instruction Feature?</h3><p> PC2 in the Instruction subset PCA is less easy to interpret. <strong>Figure 9</strong> distinguishes whether the instruction has been identified from “look-back” and “starting” positions. However, it appears to “flip” the effect it has for embeddings, which correspond to “instruction is key” vs “instruction is ball”. Moreover, the feature map for PC2  ( <strong>Figure 11)</strong> shows keys and balls at (3,4) as having noticeable cosine similarity with this direction, which doesn&#39;t fit that interpretation. Nor does this explanation predict that keys/balls at (4,3), a position similar to the look-back feature, barely projects onto PC2.</p><p> <strong>We suspect that PCA fails at finding a second interpretable feature direction because it finds orthogonal directions, however, it&#39;s not obvious that there isn&#39;t a meaningful underlying feature.</strong> We plan to investigate this further in the future. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/r7xermlo1vgoq2uyfqbi"><figcaption> <strong>Figure 11: Feature Map showing Instruction PC2 Values for all embeddings corresponding to Keys/Ball.</strong></figcaption></figure><h3> Target Features </h3><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/j60kifaxuxccbru2f6qy"><figcaption> <strong>Figure 12: Exploratory Analysis of the Target Embeddings. Left) Cosine Similarity Heatmap of the Target Embeddings. Right) 2D Scatter Plot of the first 2 Principal Components.</strong></figcaption></figure><p> For the target feature, we identified two separate clusters, each made up of two sets of almost antipodal pairs ( <strong>Figure 12</strong> ). The geometry here is much closer to isotropic <a href="https://transformer-circuits.pub/2022/toy_model/index.html"><u>superposition/toy model results</u></a> . The faint-checkerboard pattern suggests the slightest hint of a more general target feature, which we suspect may be learned if we trained MemoryDT for long enough.</p><p> The first two principal components of the resulting PCA explain 83.69% of the variance in those embeddings and produced interpretable feature maps ( <strong>Figure 13</strong> ):</p><ol><li> <strong>Starting Target Feature:</strong> PC1 can be interpreted as reflecting the configuration of the targets as seen from the starting position (1,2) and (5,2). There&#39;s slight evidence that targets are seen at intermediate positions while walking up to the targets (1,3) and (1,4).</li><li> <strong>End Target Feature:</strong> PC2 can be interpreted as reflecting the configuration of the targets as seen from the end of the corridor position (1,2) and (5,2).</li></ol><p> <strong><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/hflfgcs9bzagvzgdg2pv"></strong> </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/ywlff8ao8yjwnewh3svo"><figcaption> <strong>Figure 13: Feature map showing Instruction PC1 Values (above) and PC2 embedding (below) for all embeddings corresponding to Keys/Ball.</strong></figcaption></figure><h2> Using Embedding Arithmetic to Reverse Detected Features</h2><h3> Embedding Arithmetic with the Instruction Feature</h3><p> We previously observed that the group of vocabulary items associated with the instruction concept were separated cleanly into Keys and Balls by a single principal component explaining 60% of the total variance associated with the 6 vectors included. From this, we hypothesised that this principal component reflects an underlying “instruction feature”. To validate this interpretation, we want to show that we can leverage this prediction in non-trivial ways such as by generating feature-level adversaries (as previously applied to f <a href="https://aclanthology.org/2021.deelio-1.1.pdf"><u>actors found via dictionary learning</u></a> in language models and <a href="https://arxiv.org/abs/2110.03605"><u>copy/paste attacks in image models</u></a> )</p><p> Based on the previous result, we predicted that if we added two vocabulary items matching the opposite instruction (ie: if the instruction is a key, seen at (2,6), we can add a ball to (0,5) and a ball to (4,2)) and this would induce the model to behave as if the instruction were flipped. I&#39;ve drawn a diagram below to explain the concept ( <strong>Figure 14</strong> ). </p><figure class="image image_resized" style="width:100%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/walfabsdypkrkzzhptlv"><figcaption> <strong>Figure 14: Diagram showing the basic inspiration behind “instruction adversaries”.</strong></figcaption></figure><h3> Effectiveness of Instruction Feature Adversaries </h3><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/jsvfk3qdsjn2hgu2zmjs"><figcaption> <strong>Figure 15: Animation showing the trajectory associated with the Instruction Reversal Experiment.</strong></figcaption></figure><p> To test the adversarial features / embedding arithmetic hypothesis, we generated a set of prompts/trajectories ending in a position where the model&#39;s action preference is directly determined by observing the instruction being a key/ball ( <strong>Figure 15</strong> ). For each of the target/instruction configurations in <strong>Figure 15</strong> , we generate five different edits ( <strong>Figure 14</strong> ) to the first frame:</p><ul><li> <strong>The original first frame</strong> : <strong>&nbsp;</strong> This is our negative control.</li><li> <strong>S5 with the instruction flipped</strong> : This is our positive control. Changing the instruction from a key to a ball or vice versa at S5 makes the model flip its left/right preference.</li><li> <strong>S5 complement* instruction added at (0,5)</strong> . We expect this to reduce the left-right preference but not flip it entirely. (Unless we also removed the original instruction).</li><li> <strong>S5 with the complement instruction added at (2,4)</strong> . Same as the previous one.</li><li> <strong>S5 with the complement instruction added at (0,5) and (2,4).</strong> Even though this frame was not present in the training data, we expect it to override the detection of the original instruction.</li></ul><p> Note that due to the tokenisation of the observation, we can think of adding these vocabulary items to the input as adding adversarial features.</p><p> *Note: I&#39;m using the word “complement” because if the original instruction was a key, add a ball to reverse it and vice versa. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/ioaeffhnfdku6ffjkb1q"><figcaption> <strong>Figure 16:</strong> Adversarial Observation Token Variations. Added objects are shown in red though only the object embedding is added.</figcaption></figure><p> <strong>Figure 17</strong> shows us the restored logit difference for each of the three test cases Complement (0,5), Complement (4,2) and Complement (0,5), (4,2) using the original frame as our negative control or “clean” input and Instruction Flipped as our “corrupt”/positive control. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/wfeuyraai2gsimdnrism"><figcaption> <strong>Figure 17: Restored Logit Difference between left/right for instruction feature adversaries in &quot;scenario 1&quot;(MemoryDT).</strong> 8 facet images correspond to each target, instruction and RTG combination. (RTG = 0.892 corresponds to the highest possible reward that an optimal policy would receive. RTG = 0 corresponds to no reward, often achieved by going to the wrong target)</figcaption></figure><p> These results are quite exciting! <strong>We were able to predict very particular adversaries in the training data that would cause the model to behave (almost) as if it had seen the opposite instruction and did so from the feature map (an interpretability tool)</strong> .</p><p> Let&#39;s break the results in <strong>Figure 17</strong> down further:</p><ol><li> <strong>Adding two decoys isn&#39;t as effective as reversing the original instruction.</strong> We expected that adding two “decoy” instructions would work as well as flipping the original instruction but the best result attained is 0.92 and most results are around 0.80-0.90.</li><li> <strong>Adding a single decoy isn&#39;t consistently additive.</strong> If the effects were linear, we would expect that adding each single decoy would restore ~half the logit difference. This appears to be roughly the case half the time. If the effect was non-linear and we needed both to achieve the result, adding each alone would achieve a negligible effect. This also happens in some cases.</li><li> <strong>The effect of individual decoys should be symmetric in their effects under our theory but they aren&#39;t always.</strong> In the case of Ball, Ball-Key at RTG 0. Adding a key at  (0,5)  alone achieves 0.43 of the logit difference of both complements but adding a key at (4,2) achieves 0.03.</li></ol><h3> Proving that Instruction Feature Adversaries operate only via the Instruction Feature.</h3><p> Whilst the previous results are encouraging, we would like to provide stronger evidence behind the notion that the projection of the embedding space into instruction feature direction is causally responsible for changing the output logits. To show this we provide two lines of evidence:</p><ol><li> We show that <strong>the adversarial inputs are genuinely changing the presence of the instruction feature.</strong></li><li> We show that <strong>we can directly intervene on the instruction feature to induce the same effects as the adversaries or flip the instruction</strong> .</li></ol><p> The adversarial inputs are changing the presence of the instruction feature.</p><p> For each of the forward passes in the experiment above, we plot the dot product of the instruction feature with the observation embedding against the difference between the logits for turning left and right ( <strong>Figure 16</strong> ). We see that:</p><ol><li> <strong>We weren&#39;t flipping the instruction feature hard enough</strong> . Complement (0,5), (4,2) isn&#39;t projecting as strongly into the instruction feature direction as the Instruction Flipped observation. This may explain why our restored logit differences weren&#39;t stronger before.</li><li> <strong>MemoryDT doesn&#39;t implement  “A XOR B”.</strong> Flipping the sign on the instruction feature often flips the action preference. However,  it fails to do so when the target configuration is “Key-Ball” and RTG = 0.892. MemoryDT mostly wants to predict “A XOR B” at high RTG and its complement at low RTG, but it doesn&#39;t quite do this.</li><li> <strong>It&#39;s unclear if logit difference is a linear function of A, suggesting heterogeneous mechanisms. For example, some scenarios appear almost sigmoidal (Ball, Ball-Key at RTG = 0.892). Others might be linear (Key, Key-Ball at RTG = 0.0). If the underlying functional mappings from feature to logit difference differed, this may suggest different underlying mechanisms.</strong> </li></ol><figure class="image image_resized" style="width:100%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/lmr14n2y2ofw6wzc5tiu"><figcaption> <strong>Figure 18:</strong> Measuring the projection of the S5 observation embeddings into the Instruction PC0 direction (x-axis) and showing the logit difference between left/right (y-axis).</figcaption></figure><p> Direct Interventions on the Instruction Feature</p><p> We directly intervene on the instruction feature in each scenario tested above, again plotting the logit difference for the final left minus right direction ( <strong>Figure 19</strong> ).</p><p> <strong>This similarity in the functions mapped by the adversarial intervention (Figure 18) and the direct intervention is striking!</strong> They show a similar (and clearer) functional mapping from the instruction feature sign/magnitude to the logit difference, suggesting the instruction feature entirely explains our adversarial results. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/exchvwyx0ubhcapwehii"><figcaption> <strong>Figure 19:</strong> Intervened Instruction PC0 direction (x-axis) and showing the logit difference between left/right (y-axis).</figcaption></figure><h3> Do the Instruction Feature Adversaries Transfer?</h3><p> Finally, since our explanation of the instruction feature suggests that it represents a meaningful property of the data and that our embedding arithmetic can be interpreted as adversaries, it is reasonable to test if those adversaries <a href="https://arxiv.org/abs/2307.15043"><u>transfer to another model</u></a> trained on the same data. MemoryDT-GatedMLP is a variant of MemoryDT that is vulnerable to the same adversarial features ( <strong>Figure 20</strong> ). </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/w8izuuqtzes793tham88"><figcaption> <strong>Figure 20:</strong> Restored Logit Difference between left/right for instruction feature adversaries. MemoryDT-GatedMLP (RTG = 0.892).</figcaption></figure><p> <strong>Figure 18</strong> suggests the following:</p><ol><li> <strong>Reversing the instruction feature was more effective.</strong> The effect of adding two keys or two balls to flip the instruction was closer to the effect of flipping the original instruction and, in some cases, exceeded it.</li><li> <strong>Inconsistent effect sizes and asymmetric effect sizes also appeared.</strong> As with MemoryDT, single complements varied in the strength of their effect on the logit difference and in the same case of Ball, Ball-Key RTG 0 showed an effect for adding a key at (0,5) was more effective than adding a key at (4,2).</li></ol><p> Since MemoryDT-Gated MLP is a fairly similar model to MemoryDT, it&#39;s not surprising that the adversaries transfer; however it fits with existing theories regarding <a href="https://distill.pub/2020/circuits/zoom-in/#claim-3"><u>feature universality</u></a> and <a href="https://arxiv.org/abs/1905.02175"><u>adversarial attacks are not bugs, they are features</u></a> .</p><h1> Discussion</h1><h2> Feature Representations in GridWorld Observation Embeddings</h2><p> There are several ways to explain our results and connect them to previous work. It&#39;s not surprising to see structure in our embeddings since highly structured embeddings have been <a href="https://browse.arxiv.org/pdf/2205.10343.pdf"><u>previously linked</u></a> to generalisation and grokking in toy models, and the presence of composable linear features in token embeddings has been <a href="https://aclanthology.org/N13-1090.pdf"><u>known</u></a> for a long time.</p><p> Moreover, a fairly simple story can be told to explain many of our observations:</p><ol><li> <strong>Our observation embeddings correspond to features (like a ball at  (0,5)) at some level of abstraction in the gridworld/task.</strong> A symbolic representation shortcuts the process whereby a convolutional model first detects a ball at (0,5) with our chosen architecture.</li><li> <strong>These embedding vectors had non-trivial patterns of cosine similarity due to partial observability, spatial restraints, and correlation induced by the specific task.</strong> Add a broad level, we think that correlated vectors with similar semantic meanings tend to align, and perfectly or frequently anti-correlated vectors with opposing implications on output logits became closer to antipodal. It&#39;s easy to imagine that underlying this structure is a statistical physics of gradient updates pushing/pulling representations toward and away from each other, but we&#39;re not currently aware of more precise formulations despite similar <a href="https://transformer-circuits.pub/2022/toy_model/index.html#geometry-organization"><u>phenomenological observations</u></a> in toy models.</li><li> However, clearly, features like Ball (0,5) don&#39;t correspond directly to the most useful underlying concepts, which we think are the instruction and Targets”. <strong>Thus, the model eventually learned to assign directions that represent higher-level concepts like “the instruction is key”.</strong></li><li> We then saw different variations in the relationship between the embeddings and the representations of higher-level features:<ol><li> <strong>For the instruction feature, we saw many pairs of antipodal embeddings all jointly in superposition.</strong> PCA analysis suggests underlying geometry similar to <a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html"><u>anisotropic superposition</u></a> . It seems possible, but unclear whether lower-order principal components were meaningful there, and feature maps made it evident the feature we found was present at varying levels in many different embeddings.</li><li> <strong>For the target features, we saw two pairs of antipodal embeddings</strong> <strong>representing the targets from different positions close to isotropic superposition.</strong> Observing a faint checkerboard pattern in a cosine similarity plot, we perform PCA on the four embeddings together and see what mostly looks like <a href="https://transformer-circuits.pub/2022/toy_model/index.html#geometry-organization"><u>isotropic superposition</u></a> .</li></ol></li></ol><p> However, many pertinent questions remain unanswered:</p><ol><li> <strong>To the extent that some embeddings were represented almost antipodally, why weren&#39;t they more antipodal?</strong> It could be the model was simply undertrained, or there could be more to it.</li><li> <strong>How precisely do the feature directions represent the instructions or target form? How did they end up present in so many different embeddings?</strong> Did the instruction feature representation first form in association with more frequently observed vocabulary items and then undergo a <a href="https://arxiv.org/abs/2301.05217"><u>phase change</u></a> in which they “spread” to other embeddings, or was the final direction some weighted average of the randomly initialised directions?</li><li> <strong>What are the circuits making use of each of these features?</strong> Can we understand the learned embedding directions better concerning the circuits that use them or by <a href="https://www.alignmentforum.org/posts/RFtkRXHebkwxygDe2/an-interpretability-illusion-for-activation-patching-of"><u>comparing the directions we find to optimal causal directions</u></a> ?</li></ol><h2> Adversarial Inputs</h2><p> To validate our understanding of the instruction feature, we used both adversarial inputs and direct intervention on the instruction feature. We could correctly predict which embeddings could be used to trick the model and show that this effect was mediated entirely via the feature we identified.</p><h3> Adversaries and Interpretability</h3><p> In general, our results support previous arguments that the <a href="https://www.lesswrong.com/s/a6ne2ve5uturEEQK7/p/kYNMXjg8Tmcq3vjM6#The_studies_of_interpretability_and_adversaries_are_inseparable_"><u>study of interpretability and adversaries are inseparable</u></a> .  Various prior results connect <a href="https://arxiv.org/abs/1906.00945"><u>adversarial</u></a> <a href="https://arxiv.org/abs/2206.11212"><u>robustness</u></a> to <a href="https://arxiv.org/abs/2110.03605"><u>interpretability</u></a> <strong>,</strong> and <strong>it&#39;s been</strong> <a href="https://www.lesswrong.com/posts/kYNMXjg8Tmcq3vjM6/eis-ix-interpretability-and-adversaries#1__More_interpretable_networks_are_more_adversarially_robust_and_more_adversarially_robust_networks_are_more_interpretable_"><strong><u>claimed</u></strong></a> <strong>that “More interpretable networks are more adversarially robust and more adversarially robust networks are more interpretable”</strong> .</p><p> Applying the claim here, we could say that MemoryDT is not adversarially robust; therefore, we should not expect it to be interpretable. However, this seems to be false. <strong>Rather, MemoryDT used a coherent, interpretable strategy to detect the instruction from lower-level features operating well in-distribution but making it vulnerable to feature-level adversarial attacks</strong> . Moreover, to be robust to the adversaries we designed, and still perform well on the original training distribution, MemoryDT would need to implement more complicated circuits that would be less interpretable.</p><p> <strong>We&#39;re therefore more inclined to interpret these results as weak support for the claim that interpretability, even once we&#39;ve defined it rigorously, may not have a monotonic relationship with properties like adversarial robustness or generalisation.</strong> The implications of this idea for scaling interpretability have been discussed informally <a href="https://www.lesswrong.com/posts/X2i9dQQK3gETCyqh2/chris-olah-s-views-on-agi-safety#What_if_interpretability_breaks_down_as_AI_gets_more_powerful_"><u>here</u></a> .</p><h3> Adversaries and Superposition</h3><p> There are <a href="https://www.lesswrong.com/s/a6ne2ve5uturEEQK7/p/kYNMXjg8Tmcq3vjM6#Are_adversaries_features_or_bugs_"><u>many reasons</u></a> to think that <a href="https://proceedings.neurips.cc/paper_files/paper/2019/file/e2c420d928d4bf8ce0ff2ec19b371514-Paper.pdf"><u>adversaries are not bugs, they are features</u></a> . However, it has been suggested that <a href="https://transformer-circuits.pub/2022/toy_model/index.html#adversarial"><u>vulnerability to adversarial examples</u></a> may be explained by superposition. The argument suggests that unrelated features in superposition can be adversarially perturbed, confusing the model, which would fit into the general category of adversaries as bugs.</p><p> However, this was suggested in the context of isotropic superposition, not <a href="https://transformer-circuits.pub/2023/monosemantic-features#discussion-superposition"><u>anisotropic superposition</u></a> . Isotropic superposition involves feature directions which aren&#39;t representing similar underlying objects sharing dimensions, whilst anisotropic superposition may involve features that “produce similar actions” (or represent related underlying features).</p><p> There are three mechanisms through which antipodal or anisotropic superposition might be related to adversaries:</p><ol><li> <strong>Features in anisotropic superposition are more likely to be mistaken for each other, and targeted adversarial attacks exploit this</strong> . Humans and convolutional neural networks may be easier to trick into thinking a photo of a panda is a bear and vice versa because both represent them similarly. These attacks seem less inherently dangerous.</li><li> <strong>Adversarial attacks exploit the antipodal features fairly directly.</strong> It might be the case that related mechanisms are behind the effectiveness of <a href="https://arxiv.org/pdf/2307.15043.pdf"><strong><u>initial</u></strong></a> <strong>&nbsp;</strong> <a href="https://arxiv.org/pdf/2307.02483.pdf"><strong><u>affirmative</u></strong></a> <strong>&nbsp;</strong> <a href="https://arxiv.org/abs/2306.15447"><strong><u>responses</u></strong></a> <strong>&nbsp;</strong> as an adversarial prompting strategy. It has been proposed that these strategies work by inducing a mismatch between the pre-training and safety objectives, but such explanations are post-hoc and non-mechanistic. Showing that particular features were being reversed by incongruous combinations of inputs non-present in any prior training data may provide us with means to patch this vulnerability (for example, by detecting anomalous shifts in important feature representations across the context window).</li><li> <strong>Adversarial attacks exploit the antipodal features in “weak” anisotropic superposition.</strong> This may match <a href="https://www.lesswrong.com/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post"><u>narrative-type</u></a> strategies for jailbreaking models. <strong>Figure 10</strong> shows that the instruction feature was weakly presented in many different embeddings. A positive single feature can be “reversed” by adding many small negative features in anisotropic superposition. We needed two embeddings to reverse the instruction feature in our case, but maybe this could be done with 20. Moreover, we added this to the same token position, but some circuits may do that aggregation for us. These are possibilities that could be investigated.</li></ol><p> It&#39;s easy to theorise, but we&#39;re excited about testing mechanistic theories of LM jailbreaking techniques. Moreover, we&#39;re also excited to see whether hypotheses developed when studying gridworld models generalise to language models.</p><h3> Adversaries and Activation Addition</h3><p> A method was recently <a href="https://arxiv.org/pdf/2308.10248.pdf"><u>proposed</u></a> to steering language model generation via steering vectors via arithmetic in activation space. However, similar <a href="https://arxiv.org/abs/2205.05124"><u>previous</u></a> <a href="https://arxiv.org/abs/2304.00740"><u>methods</u></a> found steering vectors via stochastic gradient descent. The use of <a href="https://www.lesswrong.com/posts/5spBue2z2tw4JuDCx/steering-gpt-2-xl-by-adding-an-activation-vector"><u>counterbalanced steering vectors</u></a> is justified by the need to emphasise some properties in which two prompts or tokens differ. The vectors is then further “emphasised” via a scaling factor that can affect steering performance.</p><p> We propose that the results in this analysis may be highly relevant to the study of steering vectors in two ways:</p><ol><li> <strong>The need for counterbalanced additions may be tied to underlying antipodality.</strong> Adding a single activation rather than an activation difference was less effective than adding a difference. When reversing the instruction feature, we found that adding a single complement was insufficient to reverse the logit difference compared to two. In both cases, we must overcome the presence of the feature/features contained in the original forward pass that are antipodal with the feature representations in the steering vector.</li><li> <strong>Coefficient strength may correspond to heterogeneous feature presence.</strong> During steering, it was found that an injection scaling coefficient was useful.  It may be that language model activations also contain the same features but at varying magnitudes, akin to the distribution of “intensities” of the instruction feature in embedding vectors ( <strong>Figure 10</strong> ), which results in different degrees of projection onto the instruction feature in our adversarial prompts ( <strong>Figure 16</strong> ).</li></ol><p> We don&#39;t claim these insights are novel, but the connections seem salient to us. Thus, we&#39;re interested in seeing whether further experiments with latent interventions in gridworld models can teach us more about steering vectors.</p><h1> Conclusion and Future Work</h1><p> Thos is a <a href="https://www.lesswrong.com/posts/7ZqGiPHTpiDMwqMN2/twelve-virtues-of-rationality#:~:text=What%20is%20true%20of%20one,Way%20is%20a%20precise%20Art."><u>quote</u></a> that summarises my (Joseph&#39;s) sentiment about this post and working on MemoryDT.</p><blockquote><p> What is true of one apple may not be true of another apple; thus more can be said about a single apple than about all the apples in the world</p></blockquote><p> There are limitations to studying a single model and so it&#39;s important to be suspicious of generalising statements. There is still a lot of work to do on MemoryDT so connecting this work to broader claims is possibly pre-emptive.</p><p> Despite this, we think the connections between this and other work speaks to an increasingly well defined and better connected set of investigations into model internals. The collective work of many contributors permits a common set of concepts that relate phenomena across models and justifies a diverse portfolio of projects, applied and theoretical, on small and larger models alike.</p><p> We&#39;re excited to continue to analyse MemoryDT and other gridworld models but also to find ways of generating and testing hypotheses which may apply more broadly.</p><p> Our primary aims moving forward with this analysis are to:</p><ol><li> <strong>MemoryDT Circuit Analysis:</strong><ol><li> Show how circuits use the embeddings/features to generate predictions about the next action.</li><li> Explain why/how Memory DT fails to flip in action preferences when it does.</li><li> Study more trajectories than in this investigation.</li></ol></li><li> <strong>Studying Reward-to-Go:</strong><ol><li> Provide insight into how MemoryDT conditions on RTG and show how this affects related circuits.</li><li> Unpublished results suggest that MemoryDT is capable of detecting discrete ranges of RTG, which we think is phenomenologically fascinating and would like to understand further.</li></ol></li><li> <strong>Training Dynamics:</strong><ol><li> Understand the training dynamics of circuits/features in MemoryDT and similar gridworld models.</li><li> <strong>We&#39;re particularly interested in understanding whether phase changes such as those associated with grokking can be understood with reference to features quickly “spreading” to distinct embedding vectors, head outputs, or neuron output vectors.</strong></li></ol></li></ol><p> However, we&#39;re also interested in continuing to explore the following topics:</p><ol><li> <strong>Superposition in the Wild:</strong> Superposition in language models may have a very different flavour to superposition in Toy Models. Gridworld models may provide an intermediate that isn&#39;t quite as messy as language models but is more diverse than toy models.</li><li> <strong>Adversarial Inputs:</strong> What can gridworld models tell us about the relationship between interpretability, generalisation and robustness?</li><li> <strong>Steering Vectors:</strong> Are there experiments with gridworld models that substantiate possible connections between our results and previous work?  Building on simple experiments with gridworld models, can we provide compelling explanations for why steering vectors sometimes work/don&#39;t work and why?</li></ol><h1>词汇表</h1><ul><li><strong>Adversary: An adversarial input is an input optimised (by a human or by a search process) to fool a model. This may involve exploiting understanding of a model&#39;s internals, such as the adversarial inputs in this post.</strong></li><li> <strong>Antipodal: An antipodal representation is a pair of features that are opposite to each other while both occupying a single direction - one positive, and one negative.</strong></li><li> <strong>Decision Transformer:</strong> A Decision Transformer treats reinforcement learning as a sequence modelling problem, letting us train a transformer to predict what a trained RL agent would do in a given environment. In this post, we do this on a gridworld task to train our MemoryDT agent.</li><li> <strong>Embedding:</strong> An embedding is the initial representation of the input before computation or attention is applied. In a language model, the input is the model&#39;s vocabulary. In MemoryDT, the input is the 7x7x20 tensor representing the model&#39;s observations of the gridworld space.</li><li> <strong>Feature</strong> : A featur <strong>e</strong> is any property of the input and therefore could correspond to any of the following:<ul><li> A key is present at position (0,5).</li><li> The instruction is a key in the current trajectory.</li><li> The correct action to take according to the optimal policy is “right”.</li></ul></li><li> <strong>Gridworld</strong> : A toy environment for simple RL tasks that involves a task to be completed on a 2D grid. In our case, we chose the <a href="https://minigrid.farama.org/environments/minigrid/MemoryEnv/"><u>Memory environment in Minigrid.</u></a></li><li> <strong>Instruction</strong> : An instruction is the key or ball represented at position (2, 6) directly to the left of the agent in the first timestep. It tells the agent which target it should go to in order to successfully complete the task.</li><li> <strong>Linear Feature Representation</strong> : A linear feature representation is when a feature is represented by a direction.<ul><li> All vocabulary items have linear feature representations in so far as they each have an embedding vector which corresponds to them.</li><li> Features which are not vocabulary items could have linear feature representations.</li></ul></li><li> <strong>Offline RL</strong> : RL that only uses previously collected data for training. Contrasted with online RL, where the agent learns by interacting with the environment directly. MemoryDT is trained using offline RL, since it does not create trajectories itself during training.</li><li> <strong>Principal Component Analysis</strong> : Principal component analysis, or PCA, is a <a href="https://builtin.com/data-science/dimensionality-reduction-python">dimensionality reduction</a> method that is often used to reduce the number of variables of a data set, while preserving as much information as possible.</li><li> <strong>Reward-To-Go</strong> : The reward value that MemoryDT is predicting the sequence for. High values (0.892) imply correct sequences, while low values (0) imply the model should play incorrectly.</li><li> <strong>Target:</strong> Targets are the key/ball pair that the agent can move into in order to end the current episode. The target should match the instruction for a successful completion.</li><li> <strong>Vocabulary Item</strong> : A vocabulary item is something like key (2,5) or green (2,3).<ul><li> Each vocabulary item has a corresponding embedding vector.</li></ul></li></ul><h1> Gratitude</h1><p> This work was supported by grants from the Long Term Future Fund, as well as the <a href="https://manifund.org/projects/independent-researcher">Manifund Regranting program</a> . I&#39;d also like to thank Trajan house for hosting me. <strong>I&#39;m thankful to Jay Bailey for joining me on this project and all his contributions.</strong></p><p> I&#39;d like to thank all those who gave feedback on the draft including (in no particular order) Oskar Hollinsworth, Curt Tigges, Lucy Farnik, Callum McDougall, David Udell, Bilal Chughtai, Paul Colognese and Rusheb Shah.</p><h1> Appendix</h1><h2>方法</h2><h3>Identifying Related Embeddings with Cosine Similarity Heatmaps</h3><p> Even though we had fairly strong prior expectations over which sets of vocabulary items were likely to be related to each other, we needed a method for pulling out these groups of embeddings in an unbiased fashion. They are more useful when clustered, so we use<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html"><u>scikit-learn</u></a> to perform agglomerative clustering based on a single linkage with Euclidean distance. This is just a fancy method for finding similar groups of tokens.</p><p> This works quite effectively for these embeddings but likely would be insufficient in the case of a language model. Only the largest underlying feature (if any) would determine the nearest points and so you would struggle to retrieve meaningful clusters. A probing strategy or use of <a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html"><u>sparse</u></a> <a href="https://www.lesswrong.com/posts/z6QQJbtpkEAX3Aojj/interim-research-report-taking-features-out-of-superposition"><u>autoencoders</u></a> to find features followed by measuring token similarity with those features might be better in that case.</p><h3> Principal Component Analysis on a Subset of Embeddings for Feature Identification</h3><p> Clustering heatmaps aren&#39;t useful for understanding geometry unless they have very few vectors, so we make use of Principal Component Analysis for this instead. Principal Component Analysis is a statistical technique that constructs an orthonormal basis from the directions of maximum variance within a vector space and has been applied previously to study <a href="https://arxiv.org/pdf/1310.4546.pdf"><u>word embeddings</u></a> and <a href="https://arxiv.org/abs/2307.09458"><u>latent spaces in conjunction with circuit analysis</u></a> (in both cases applied to a subset of possible vectors).</p><p> It turns out that PCA is very useful for showing feature geometry in this case for the following reasons:</p><ol><li> <strong>Dimensionality Reduction.</strong> Embedding vectors are very high dimensional, but PCA can show us if the space can be understood in terms of many fewer dimensions.</li><li> <strong>Quantifying variance explained.</strong> We use the percent variance explained to suggest the quality of the approximation achieved by the first 2 or 3 principal component vectors.</li></ol><p> There are two issues with PCA:</p><ol><li> <strong>It&#39;s not obvious that the directions found by PCA on subsets of embedding space correspond to meaningful features by default.</strong> We can address this by biassing the directions it finds by taking sets of embeddings and performing PCA on them only. This makes the direction of maximal variance more likely to correspond to the linear representation of the semantic feature that is shared by these embeddings.</li><li> <strong>Vectors produced by PCA are orthogonal, which may not be true of the underlying features.</strong> For this reason, it might make sense to interpret any features we think we find with caution.</li></ol><p> To interpret principal components, we project them onto the embedding space for relevant channels (mainly keys/balls) and then show the resulting scores arranged in a grid with the same shape as the observations generated by the MiniGrid Environment. It&#39;s possible to interpret these by referring to the positions where different vocabulary items sit and which concepts they represent.</p><h3> Interpreting Feature Directions with Feature Maps</h3><p> Once we have a direction that we believe corresponds to a meaningful feature, we can take the cosine similarity between this direction and every element of embedding space. Since the embedding space is inherently structured as a 7*7 grid with 20 channels, we can simply look at the embeddings for the relevant channels (keys and balls). This is similar to a convolution with height/width and as many channels as the embedding dimension.</p><p> Feature maps are similar to the heat maps produced by Neel in his <a href="https://www.lesswrong.com/posts/nmxzr2zsjNtjaHh7x/actually-othello-gpt-has-a-linear-emergent-world"><u>investigation</u></a> into OthelloGPT, using probe directions where we used embeddings and the residual stream where we used our feature.</p><h3> Validating Identified Features by Embedding Arithmetic</h3><p> To test whether a linear feature representation corresponds to a feature, we could intervene directly on the feature, removing or adding it from the observation token, but we can also simply add or subtract vocabulary items that contain that feature.</p><p> Our method is similar to the <a href="https://arxiv.org/abs/2308.10248"><u>activation addition</u></a> technique, which operates on the residual stream at a token position but works at the input level. If we operated directly on the hypothesised linear feature representation direction, then this method would be similar to the causal intervention on the world model used on <a href="https://www.lesswrong.com/posts/nmxzr2zsjNtjaHh7x/actually-othello-gpt-has-a-linear-emergent-world"><u>OthelloGPT</u></a> to test whether a probe vector could be used to intervene in a transformer world representation.</p><p> To evaluate the effect of each possible embedding arithmetic, we take the modal scenario where the model has walked forward four times and is choosing between left/right. We measure the logit difference between left and right in the following contexts:</p><ul><li> A negative control (the base case).</li><li> A positive control (the in-distribution complement).</li><li> The test case (the out-of-distribution complement).</li></ul><p> Then, for each test case, we report the proportion of logit difference restored (LD(test) - LD(negative control )) / (LD(positive control) - LD(negative control )).</p><p> This is identical to the metric we would use if evaluating the effect size of a patching experiment and while it hides some of the variability in the results, it also makes the trends very obvious.</p><h2> Related Work</h2><h3> Decision Transformers</h3><p> <a href="https://arxiv.org/pdf/2106.01345.pdf"><u>Decision Transformers</u></a> are one of <a href="https://arxiv.org/abs/2106.02039"><u>several</u></a> methods developed to apply transformers to RL tasks. These methods are referred to as “offline” since the transformer learns to from a corpus of recorded trajectories. Decision Transformers are conditioned to predict actions consistent with a given reward because they are “goal conditioned” receiving a token representing remaining reward to be achieved at each timestep. The decision transformer architecture is the basis for SOTA models developed by DeepMind including <a href="https://openreview.net/pdf?id=1ikK0kHjvj"><u>Gato</u></a> (a highly generalist agent) and <a href="https://www.deepmind.com/blog/robocat-a-self-improving-robotic-agent"><u>Robocat</u></a> (A foundation agent for robotics).</p><h3> GridWorld Decision Transformers</h3><p> Earlier this year we studied a small <a href="https://www.lesswrong.com/posts/bBuBDJBYHt39Q5zZy/decision-transformer-interpretability"><u>gridworld decision transformer</u></a> mainly via attribution and ablations. More recently, I posted details about <a href="https://www.lesswrong.com/posts/JvQWbrbPjuvw4eqxv/a-mechanistic-interpretability-analysis-of-a-gridworld-agent"><u>MemoryDT,</u></a> the model discussed in this post.</p><h3> Circuit-Style Interpretability</h3><p> A large body of <a href="https://arxiv.org/abs/2207.13243"><u>previous work</u></a> exists attempting to understand the inner structures of deep neural networks. Focussing on the most relevant work to this investigation, we attempt to find features/linear feature representations by framing the <a href="https://distill.pub/2020/circuits/zoom-in/"><u>circuit style interpretability</u></a> . We refer to previously documented phenomena such as <a href="https://distill.pub/2020/circuits/equivariance/"><u>equivariance</u></a> , <a href="https://arxiv.org/abs/2209.10652"><u>isotropic superposition</u></a> (previously “superposition”) and recently documented <a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html"><u>anisotropic superposition</u></a> . Our use of PCA was inspired by its application to key/query and value subspaces in the 70B Chinchilla Model <a href="https://arxiv.org/abs/2307.09458"><u>analysis</u></a> but PCA has a much longer <a href="https://arxiv.org/pdf/1310.4546.pdf"><u>history</u></a> of application to making sense of neural networks.<br> Linear Representations</p><p> Linear algebraic structure has been previously <a href="https://arxiv.org/pdf/1601.03764.pdf"><u>predicted</u></a> in word embeddings and found using techniques such as <a href="https://arxiv.org/pdf/1910.03833.pdf"><u>dictionary learning</u></a> and <a href="https://arxiv.org/abs/1711.08792"><u>sparse autoencoders</u></a> . Such representations can be understood as suggesting that the underlying token embedding is a sum of “word factors” or features. </p><figure class="image image_resized" style="width:65.73%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yuQJsRswS4hKv3tsL/mn7ttxyj9j11awx2ibqr"><figcaption> Taken from <a href="https://arxiv.org/pdf/1910.03833.pdf"><strong><u>Zhang et al 2021</u></strong></a></figcaption></figure><p> More recently, efforts have been made to find linear feature representations in the residual stream with techniques such as <a href="https://aclanthology.org/2021.deelio-1.1.pdf"><u>dictionary learning</u></a> , <a href="https://www.lesswrong.com/posts/z6QQJbtpkEAX3Aojj/interim-research-report-taking-features-out-of-superposition"><u>sparse auto-encoders</u></a> or <a href="https://arxiv.org/abs/2305.01610"><u>sparse linear probing</u></a> . What started as an attempt to understand how language models deal with polysemy (the property of a word/token having more than one distinct meaning) has continued as a much more ambitious attempt to understand how language models represent information in all layers.</p><h3> RL Interpretability</h3><p> A variety of previous investigations have applied interpretability techniques to models solving RL tasks. <strong>Convolutional Neural Networks</strong> : This includes <a href="https://distill.pub/2020/understanding-rl-vision/"><u>analysis of a convolutional neural network</u></a> solving the Procgen <a href="https://openai.com/research/procgen-benchmark"><u>CoinRun</u></a> task using attribution and model editing. Similarly, <a href="https://www.lesswrong.com/sequences/sCGfFb5DPfjEmtEdn"><u>a series of investigations</u></a> into models that solve the procgen <a href="https://www.lesswrong.com/sequences/sCGfFb5DPfjEmtEdn"><u>Maze</u></a> task identified a subset of channels responsible for identifying the target location that could be retargeted (a limited version of <a href="https://www.lesswrong.com/posts/w4aeAFzSAguvqA5qu/how-to-go-from-interpretability-to-alignment-just-retarget"><u>retargeting the search.</u></a> ) <strong>Transformers</strong> : An investigation by <a href="https://arxiv.org/abs/2210.13382"><u>Li et al.</u></a> found evidence for a non-linear world representation in an offline-RL agent playing Othello using probes. It was later found that this <a href="https://arxiv.org/abs/2309.00941"><u>world representation was linear</u></a> and amenable to causal interventions.</p><h3> Antipodal Representations</h3><p> Toy models of superposition were found to use antipodal directions to <a href="https://transformer-circuits.pub/2022/toy_model/index.html#geometry-organization"><u>represent anti-correlated features in opposite directions</u></a> . There is some evidence that and we&#39;ve seen that language models also make use of <a href="https://www.lesswrong.com/posts/mkbGjzxD8d8XqKHzA/the-singular-value-decompositions-of-transformer-weight#Negative"><u>antipodal representations</u></a> .</p><h3> Adversarial Inputs</h3><p> <a href="https://arxiv.org/abs/1706.06083"><u>Adversarial examples</u></a> are important to both <a href="https://www.lesswrong.com/s/a6ne2ve5uturEEQK7/p/kYNMXjg8Tmcq3vjM6"><u>interpetability</u></a> and AI safety. A relevant debate is whether these are <a href="https://arxiv.org/abs/1905.02175"><u>bugs or features</u></a> (with our work suggesting the latter), though possibly the topic should be approached with significant nuance.</p><h3> Activation Additions/Steering Vectors</h3><p> We discuss <a href="https://arxiv.org/pdf/2308.10248.pdf"><u>activation addition</u></a> as equivalent to our embedding arithmetic (due to our observation tokenization schema). Activation additions attempt steering language model generation underpinned by <a href="https://www.lesswrong.com/posts/5spBue2z2tw4JuDCx/steering-gpt-2-xl-by-adding-an-activation-vector#Benefits_from_paired__counterbalanced_activation_additions"><u>paired, counterbalanced</u></a> vectors in activation space. Similar <a href="https://arxiv.org/abs/2205.05124"><u>steering</u></a> <a href="https://arxiv.org/abs/2304.00740"><u>approaches</u></a> have been developed previously finding directions with stochastic gradient descent. Of particular note, one investigation used an <a href="https://arxiv.org/abs/2306.03341"><u>internal direction representing truth</u></a> to steer model generation.</p><br/><br/> <a href="https://www.lesswrong.com/posts/yuQJsRswS4hKv3tsL/features-and-adversaries-in-memorydt#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/yuQJsRswS4hKv3tsL/features-and-adversaries-in-memorydt<guid ispermalink="false"> yuQJsRswS4hKv3tsL</guid><dc:creator><![CDATA[Joseph Bloom]]></dc:creator><pubDate> Fri, 20 Oct 2023 07:32:23 GMT</pubDate> </item><item><title><![CDATA[AI Safety Hub Serbia Soft Launch]]></title><description><![CDATA[Published on October 20, 2023 7:11 AM GMT<br/><br/><p>太长了； We got three-month funding from a generous individual funder to launch an AI Safety office in Serbia. We are giving free office space (and, if funding later permits, housing) to AI Safety researchers who are looking for a place to work from. Priority for citizens of countries like Russia and China who can work visa-free from Serbia while being close to Europe. <a href="https://docs.google.com/forms/d/1LQ9cE1CGjD_WMMx5IYLLeHFeXNQJx12dsu7f4_FSF7w/edit"><u>Register interest here</u></a> or ask questions at <a href="mailto:dusan.d.nesic@efektivnialtruizam.rs"><u>my email</u></a> . We also have a promise of partial funding for our bare-bones request ( <a href="https://docs.google.com/spreadsheets/d/1_xRnyLYgPNPvMcXej6xfpkhxXDgXDdKfIpR2wfzaoSs/edit#gid=0"><u>budget</u></a> ) from an individual donor but are looking for a second individual donor in order to fulfill it (about 30k USD) - <a href="mailto:dusan.d.nesic@efektivnialtruizam.rs"><u>reach out to me</u></a> if this may be you.</p><h2> Background:</h2><p> EA Serbia and AI Safety Serbia groups are small but growing (~30 people in EA Serbia, ~3 people looking to get into AIS research as a career, and ~3 to get into AIS policy). Due to Serbia&#39;s favorable Visa policy towards Russia and China, many foreigners already live here. With lower living costs than many other international hub cities, a vibrant scene, and a favorable time zone and climate, Belgrade has a growing foreigner community.</p><p> As we have seen projects such as <a href="https://ceealar.org/"><u>CEEALAR</u></a> as important and impressive, we wish to replicate them in Serbia, where they can better serve people who may struggle to get UK visas. We also believe that having the capacity to quickly scale cheap housing for people coming from different countries is a good thing.</p><p> We also believe that we should start small, prototype, and then move larger. We have had a unique opportunity to get an office space that is NGO-friendly, has good vibes, and costs only ~550 Euros per month for office space that has three rooms and can fit 8-15 people (depending on how snug they decide to be) with a coffee shop downstairs where another 20 people can spend their time co-working, as the office and the downstairs coffee shop are under the same ownership. This is certainly less luxurious than many other EA/AI co-working places, but we have a high degree of customizability allowed to us, which we can use to make a good office space. If we grow enough, we can also move to a bigger venue, as our needs grow. Certainly, if we knew that more use could be found in an office in Serbia, getting something somewhat further from the center, which includes living and office spaces, would be better, but we do not wish to explore that until we have proof of concept and need.</p><h3> Operations details (aka how it works):</h3><p> The office is currently rented for three months, August-October, so that we can keep the favorable price instead of having to find a different place. The office space has some desks and chairs, but we are looking to acquire full funding and have people voice their needs before acquiring more furniture. The office is usually open during working hours of the coffee shop (10 AM to Midnight, except on weekends when it is 4 PM to Midnight) as they share an entrance, but exceptionally, we can accommodate special requests if someone works better at strange working hours.</p><p> Office space is given to those that are working on projects related to AI Safety as a priority, but EA research is also welcome whenever we have spare capacity (which we expect at first).</p><p> Unfortunately, we currently do not have a legal entity that can provide visa invitations for those coming from countries that require a visa - for that, we would need to gather funding before starting the process. Still, a Serbian visa is not required for many and is relatively easy to get for most.</p><p> We have a reliable real estate agent who is able to get good deals on housing in Belgrade for those that need housing assistance until we get funded and rent a co-living space as well.</p><p> For those looking to eat consistently through us, we can arrange affordable cooked meals delivered to the office or your housing (at your expense) - vegetarian or not. If we have enough interest, we can get the chef to prepare vegan food as well.</p><h3> You may want to come if:</h3><ul><li> You are an AI Safety Researcher/EA researcher looking for a base of operations for a short-medium-long term</li><li> You are keen to be close to Europe but not in the EU</li><li> You are looking for a vibrant but affordable city with plenty of things to do, and Eastern European but Westernized culture</li></ul><h2> Hiring:</h2><p> Currently, the project is managed by a few volunteers from EA Serbia, myself included. We run the operations of the office, as well as checking applications. As we grow, we would like to have some paid positions and some volunteer ones. We are looking for:</p><ul><li> Volunteers who wish to be members of the Board of Directors of the project, mostly dealing with strategic decisions and approving participants (impactful role as you empower researchers to develop their research agendas)</li><li> Project Manager, mostly dealing with day-to-day running of the project, communication with stakeholders (board, funds, participants), as well as checking reports from participants. (0.25 FTE or 0.15 FTE in bare-bones version - salary still enough to live in Serbia, but additional income may be needed for a less frugal lifestyle)</li></ul><p> Ideally, we would be hiring after we have all the funding, but if someone is passionate about the role, please reach <a href="mailto:dusan.d.nesic@efektivnialtruizam.rs"><u>out to me</u></a> , and the first order of business can be looking for funding with your help.</p><h2>想法？ Feedback?</h2><p> For any questions or comments, please write to my <a href="mailto:dusan.d.nesic@efektivnialtruizam.rs"><u>email</u></a> . If you wish to be informed of the full launch, sign up in the <a href="https://docs.google.com/forms/d/1LQ9cE1CGjD_WMMx5IYLLeHFeXNQJx12dsu7f4_FSF7w/edit"><u>interest form</u></a> and note so. If you wish to come over now, fill in the interest form and send me an email as well so that I make sure to process your request quicker! The post was written in a bit of a rush, so apologies if there are details you would like to see - please reach out if so, or leave a comment below, I&#39;ll try to edit things in.</p><br/><br/> <a href="https://www.lesswrong.com/posts/CmvkoyTq49tFkSGFF/ai-safety-hub-serbia-soft-launch#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/CmvkoyTq49tFkSGFF/ai-safety-hub-serbia-soft-launch<guid ispermalink="false"> CmvkoyTq49tFkSGFF</guid><dc:creator><![CDATA[DusanDNesic]]></dc:creator><pubDate> Fri, 20 Oct 2023 07:11:48 GMT</pubDate> </item><item><title><![CDATA[Announcing new round of "Key Phenomena in AI Risk" Reading Group]]></title><description><![CDATA[Published on October 20, 2023 7:11 AM GMT<br/><br/><p> <strong>TLDR:</strong> “ <a href="https://www.lesswrong.com/posts/mqvxR9nrXAzRr3ow9/announcing-key-phenomena-in-ai-risk-facilitated-reading">Key Phenomena in AI Risk</a> ” is an 8-week-long, facilitated reading group. It is aimed at people interested in conceptual AI alignment research, in particular from fields such as philosophy, systems research, biology, cognitive and social sciences. We ran it once and are repeating it now.</p><p> The program will run between <strong>November 2023 and January 2024</strong> . Sign up <a href="https://forms.gle/cdr4UeocE7Jg5SUF6"><strong>here</strong></a> <strong>by Sunday, October 29th.</strong></p><h2><strong>什么？</strong></h2><p> The “Key Phenomena in AI risk” reading curriculum provides an extended introduction to some key ideas in AI risk, in particular risks from misdirected optimization or &#39;consequentialist cognition&#39;. As such, it aims to remain largely agnostic of solution paradigms. It includes 90&#39; minutes of facilitated discussion, and requires at least 2 hours of reading per session. It is virtual and free.</p><p> See <a href="https://www.lesswrong.com/posts/mqvxR9nrXAzRr3ow9/announcing-key-phenomena-in-ai-risk-facilitated-reading#Summary_of_the_curriculum"><u>the old post here</u></a> for a short overview of the curriculum; <a href="https://docs.google.com/document/d/1hgZOv-PfYYgayspSb_8D_OdQ6dV12xI2bsLuq57A3yg/edit?usp=sharing"><u>here</u></a> for a more extensive summary; and <a href="https://docs.google.com/document/d/1HGzMBMXQD9w9K32scqCoSmZNGbxLJE8-siPlonTQz6s/edit?usp=sharing"><u>here</u></a> for the full curriculum (which will be updated in minor ways in the following weeks).</p><h2> <strong>What Changed?</strong></h2><p> Thanks to the feedback from participants and facilitators in the last iteration, the program has improved. Now, it is is an 8-week-long program (with one week added at the end for reflection). Readings have been made more focused, and we will be adding more technical optional readings.</p><h2> <strong>For Who?</strong></h2><p> The curriculum is primarily aimed at people interested in conceptual research in AI risk and alignment.</p><p> It is designed to be accessible to audiences in, among others, philosophy (of agency, knowledge, power, etc.) and systems research (eg biological, cognitive, information-theoretic, social systems, etc.).</p><h2><strong>什么时候？</strong></h2><p> The reading groups will be taking place <strong>November 2023 through January 2024.</strong></p><p> We expect to run 6 groups of 4-8 participants (including 1 facilitator). Each group will be led by a facilitator with substantive knowledge of AI risk.</p><h2> <strong>Sign up</strong></h2><p> Sign up <a href="https://forms.gle/isv2ZeTkffjRBdYM8"><strong><u>here</u></strong></a> <strong>by October 29th</strong> .</p><h2> <strong>About the application</strong></h2><p> The application consists of one stage, where we ask you to fill in a form with</p><ul><li> Your CV</li><li> Your motivation for participating in the program</li><li> Your prior exposure to AI risk/alignment to date</li></ul><p> We select people based on our best understanding of their motivation to contribute to AI alignment and how much they would counterfactually benefit from participating in the program.</p><p></p><hr><p></p><p> If you have any questions, feel free to leave a comment below or contact us at <u>contact@pibbss.ai</u></p><br/><br/> <a href="https://www.lesswrong.com/posts/vakhhNHduW9gmENTW/announcing-new-round-of-key-phenomena-in-ai-risk-reading#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/vakhhNHduW9gmENTW/announcing-new-round-of-key-phenomena-in-ai-risk-reading<guid ispermalink="false"> vakhhNHduW9gmENTW</guid><dc:creator><![CDATA[DusanDNesic]]></dc:creator><pubDate> Fri, 20 Oct 2023 07:11:09 GMT</pubDate> </item><item><title><![CDATA[Unpacking the dynamics of AGI conflict that suggest the necessity of a premptive  pivotal act]]></title><description><![CDATA[Published on October 20, 2023 6:48 AM GMT<br/><br/><p> Semi-half baked. I don&#39;t reach any novel conclusions in this post, but I do flesh out my own thinking on the way to generally accepted conclusions.</p><p> I&#39;m pretty interested in anything here that seems incorrect (including in nit-picky ways), or in hearing additional factors that influence the relevant and importance of pivotal acts.</p><p> In <a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities"><u>AGI Ruin: A List of Lethalities</u></a> , Eliezer claims</p><blockquote><p> <strong>2</strong> . <strong>A cognitive system with sufficiently high cognitive powers, given any medium-bandwidth channel of causal influence, will not find it difficult to bootstrap to overpowering capabilities independent of human infrastructure.</strong> The concrete example I usually use here is nanotech, because there&#39;s been pretty detailed analysis of what definitely look like physically attainable lower bounds on what should be possible with nanotech, and those lower bounds are sufficient to carry the point.  My lower-bound model of &quot;how a sufficiently powerful intelligence would kill everyone, if it didn&#39;t want to not do that&quot; is that it gets access to the Internet, emails some DNA sequences to any of the many many online firms that will take a DNA sequence in the email and ship you back proteins, and bribes/persuades some human who has no idea they&#39;re dealing with an AGI to mix proteins in a beaker, which then form a first-stage nanofactory which can build the actual nanomachinery….The nanomachinery builds diamondoid bacteria, that replicate with solar power and atmospheric CHON, maybe aggregate into some miniature rockets or jets so they can ride the jetstream to spread across the Earth&#39;s atmosphere, get into human bloodstreams and hide, strike on a timer. <strong>Losing a conflict with a high-powered cognitive system looks at least as deadly as &quot;everybody on the face of the Earth suddenly falls over dead within the same second&quot;.</strong></p></blockquote><p> And then later,</p><blockquote><p> <strong>6</strong> . <strong>We need to align the performance of some large task, a &#39;pivotal act&#39; that prevents other people from building an unaligned AGI that destroys the world.</strong> While the number of actors with AGI is few or one, they must execute some &quot;pivotal act&quot;, strong enough to flip the gameboard, using an AGI powerful enough to do that.  It&#39;s not enough to be able to align a <i>weak</i> system - we need to align a system that can do some single <i>very large thing.</i> The example I usually give is &quot;burn all GPUs&quot;</p><p> ...</p><p> Many clever-sounding proposals for alignment fall apart as soon as you ask &quot;How could you use this to align a system that you could use to shut down all the GPUs in the world?&quot; because it&#39;s then clear that the system can&#39;t do something that powerful, or, if it can do that, the system wouldn&#39;t be easy to align.  A GPU-burner is also a system powerful enough to, and purportedly authorized to, build nanotechnology, so it requires operating in a dangerous domain at a dangerous level of intelligence and capability; and this goes along with any non-fantasy attempt to name a way an AGI could change the world such that a half-dozen other would-be AGI-builders won&#39;t destroy the world 6 months later.</p></blockquote><p> An important component of a “pivotal act” as it is described here is its <i>preemptiveness</i> . As the argument goes: you can&#39;t defeat a superintelligence aiming to defeat you, so the only thing to do is to prevent that superintelligence from being turned on in the first place.</p><p> I want to unpack some of the assumptions that are implicit in these claims, and articulate in more detail why, and in what conditions specifically, a pivotal act is necessary.</p><p> I&#39;ll observe that there are some specific properties of this particular example, building and deploying nanotech weapons,  used here as an illustration of superintelligent conflict, which make a pivotal act necessary.</p><p> If somehow the dynamics of super intelligent conflict <i>don&#39;t</i> turn out to have the following properties <i>and</i> takeoff is decentralized (so that the diff between the depth and the capability levels of the most powerful systems and the next most powerful systems is always small), I don&#39;t think this argument holds as stated.</p><p> But unfortunately, it seems like these properties probably <i>do</i> hold, and so this analysis doesn&#39;t change the overall outlook much.</p><p> Those properties are:</p><ul><li> <strong>Offense dominance (vs. defense dominance)</strong></li><li> <strong>Intelligence advantage dominance (vs. material advantage dominance)</strong></li><li> <strong>The absolute material startup costs of offense are low</strong></li></ul><p> For all of the following I&#39;m presenting a simple, qualitative model. We could devise quantitative models to describe each axis.</p><h3> Offense dominance (vs. defense dominant)</h3><p> The nanotech example, like nuclear weapons, is presented as strongly offense-dominant.</p><p> If it were just as easy or even easier to use nanotech to develop nano-defenses that reliably defeat diamondoid bacteria attacks, the example would cease to recommend a pivotal act — you only need to rely on a debilitating preemptive  strike if you can&#39;t defend realistically against an attacker, and so you need to prevent them from attacking you in the first place.</p><p> If defense is easier than offense, then it makes at least as much sense to build defenses as to attack first.</p><p> (Of course, as I&#39;ll discuss below, it&#39;s not actually a crux if nanotech <i>in particular</i> has this property. If this turns out to be the equilibrium of nanowar, then nanotech will not be the vector of attack that an unaligned superintelligence would choose, precisely <i>because</i> the equilibrium favors defense. The crux is that there is at least one technology that has this property of favoring offense over all available defenses.)</p><p> If it turns out that the equilibrium of conflict between superintelligences, not just in a single domain, but overall, favors defense over offense, pivotal acts seem less necessary. <span class="footnote-reference" role="doc-noteref" id="fnrefjquiv0hah7e"><sup><a href="#fnjquiv0hah7e">[1]</a></sup></span></p><h3> Intelligence-advantage dominants (vs. material-advantage dominant)</h3><p> [Inspired by <a href="https://www.lesswrong.com/posts/odtMt7zbMuuyavaZB/when-do-brains-beat-brawn-in-chess-an-experiment"><u>this</u></a> excellent post.]</p><p> There&#39;s a question that applies to any given competitive game: what is the shape of the indifference curve between increments of intelligence vs. increments in material resources.</p><p> For instance, suppose that two AIs are going to battle in the domain of aerial combat. Both AIs are controlling a fleet of drones. Let&#39;s say that one AI has a “smartness” of 100, and the other has a “smartness” of 150, where “1 smart” is some standardized unit. The smarter AI is able to run more sophisticated tactics to defeat the other in aerial combat. This yields the question, how many additional drones does the IQ 100 AI need to have at its disposal to compensate for its intelligence disadvantage?</p><p> We can ask an analogous question of any adversarial game.</p><ul><li> What level of handicap in <a href="https://www.lesswrong.com/posts/odtMt7zbMuuyavaZB/when-do-brains-beat-brawn-in-chess-an-experiment"><u>chess</u></a> , or go, compensates for what level of skill gap measured in elo rankings?</li><li> If two countries go to war, how much material wealth does one need to have to compensate for the leadership and engineering teams of the other being a standard deviation smarter, on average?</li><li> If one company has the weights of a 150 IQ AI, but access to 10x less compute resources than their competitor whose cutting edge system is only IQ 130, which company makes faster progress on AI R&amp;D?</li></ul><p> Some games are presumably highly intelligence-advantage dominant—small increments of intelligence over one&#39;s adversaries compensates for vast handicaps of material resources. Other games will embody the opposite dynamic—the better resourced adversary reliably wins, even against more intelligent opponents. <span class="footnote-reference" role="doc-noteref" id="fnrefupawqb9o50e"><sup><a href="#fnupawqb9o50e">[2]</a></sup></span></p><p> The more that conflict involving powerful intelligences turns out to be slanted towards an intelligence-advantage vs. a material-advantage, the more a preemptive pivotal act is necessary, even in worlds where takeoff is decentralized, because facing off against a system that is even slightly smarter than you is very doomed.</p><p> But if conflict turns out to be material-advantage dominant for some reason, the superior number of humans (or of less intelligent but maybe more aligned AIs), with their <i>initial</i> control over greater material resources, makes a very smart system less of an <i>immediate</i> threat.</p><p> (Though it doesn&#39;t make them no threat at all, because as I discuss later, intelligence advantages can be used to accrue material advantages through mundane avenues, and you can be just as dead, even if the process takes longer and is less dramatic looking.)</p><h3> The absolute material startup costs of offense are low</h3><p> Another feature of the nanotech example is that developing nanotech, if you know how to do it, is extremely cheap in material resources. It is presented as something that can be done with a budget of a few hundred dollars.</p><p> Nanowar is not just intelligence-advantage dominant, it has low material resource costs in absolute terms.</p><p> This matters, because the higher the start-up costs for developing and deploying weapons, the more feasible it becomes to enforce a global ban against using them.</p><p> As an example, nuclear weapons are strongly offense-dominant. There&#39;s not much you can do to defend yourself from a nuclear launch other than to threaten to retaliate with second strike capability.</p><p> But nuclear weapons require scarce uranium and complicated development processes. They&#39;re difficult (read: expensive) to develop, and that difficulty means that it is possible for the international community to strongly limit nuclear proliferation to only the ~9 nuclear powers. If creating a nuclear explosion was as easy as “ <a href="https://nickbostrom.com/papers/vulnerable.pdf"><u>sending an electric current through a metal object placed between two sheets of glass</u></a> ”, the world would have very little hope of coordinating to prevent the proliferation of nuclear arsenals or in preventing those capabilities from being used.</p><p> A strongly offense-dominant or strongly intelligence-advantage dominant technology, <i>if</i> it is expensive and obvious to develop and deploy, has some chance of being outlawed by the world, with a ban that is effectively enforced.</p><p> This would still be an unstable situation which requires predicting in advance what adversarial technologies the next generation of Science and Engineering AIs might find, and establishing bans on them in advance, and hoping that all those technologies turn out to be expensive enough that the bans are realistically enforceable.</p><p> (And by hypothesis of course, humanity is currently not able to do this, because otherwise we should just make a ban on AGI, which is the master adversarial technology.)</p><p> If there&#39;s an offense-dominant or intelligence-advantage dominant weapon that has low startup costs, I don&#39;t see what you can do except a preemptive strike to prevent that weapon from being developed and used in the first place.</p><h2> Summary and conclusions</h2><p> Overall, the need for a pivotal act depends on the following conjunction / disjunction.</p><p> <i>The equilibrium of conflict involving powerful AI systems lands on a technology / avenue of conflict which are (either offense dominant, or intelligence-advantage dominant) and can be developed and deployed inexpensively or quietly.</i></p><p> If, somehow, this statement turned out not to be true, a preemptive pivotal act that prevents the development of AGI systems seems less necessary. If the above statement turns out not to be true, then a large number of relatively aligned AI systems could be used to implement defensive measures that would defeat the attacks of even the most powerful system in the world (so long as the most advanced system&#39;s capability is not too much higher than the second best system&#39;s, and those AI systems don&#39;t collude with each other). <span class="footnote-reference" role="doc-noteref" id="fnrefcq5b0d0wcu9"><sup><a href="#fncq5b0d0wcu9">[3]</a></sup></span><br><br> Unfortunately, I think all three of these are very reasonable assumptions about the dynamics of AGI-fueled war. The key reason is that there is adverse selection on <i>all</i> of these axes.</p><p> In the offense versus defense axis, an aggressor can choose any avenue of attack from amongst the whole universe of possibilities, and a defender has to defend on the avenue of attack chosen by an aggressor. This means that if there is any front of conflict in which offense has the advantage, then the aggressor will choose to attack along that vulnerable front. For that reason, the dynamic of conflict between superintelligences as a whole will inherit from that specific case. <span class="footnote-reference" role="doc-noteref" id="fnreft2r6pc761j"><sup><a href="#fnt2r6pc761j">[4]</a></sup></span></p><p> The same adverse selection holds for intelligence-advantage dominance vs. material-advantage dominance. If there are many domains in which the advantage goes to the better resourced, and only one which is biased towards the more intelligent, an intelligent entity would seize on that one domain, perhaps converting its gains into a resource advantage in the other games until it dominates in all relevant domains. <span class="footnote-reference" role="doc-noteref" id="fnreff59isk0pwa9"><sup><a href="#fnf59isk0pwa9">[5]</a></sup></span></p><p> This is a framing of the fundamental reason why getting into a conflict with a superintelligence is lethal: facing an intelligent entity that is smarter than you, and can see more options than you, there&#39;s adverse selection by which you predictably end up in situations in which it wins.</p><p> Furthermore, the overall equilibrium of conflict is a function of technology level. Phalanxes dominate war until the stirrup allows for mounted knights to brace against something as they charge into the enemy. And heavily armored and highly trained mounted knights are the dominant military force until firearms and longbows make them vulnerable to ranged attack. <span class="footnote-reference" role="doc-noteref" id="fnrefma05y1bmrg9"><sup><a href="#fnma05y1bmrg9">[6]</a></sup></span></p><p> Even if we somehow get lucky and the conflict equilibrium is defense dominant and material-advantage dominant near the development of the first Science and Engineering AIs, we will only have to wait a few months (or even less time) before the next generation of Science and Engineering AIs unlocks new technological frontiers, re-rolling the dice on all of these axes. It&#39;s only a matter of time before the statement above holds.</p><p> Given all that, it seems like you need something like a pivotal act, whether unilateral, backed by a nation-state, or backed by a coalition of nation-states, that can prevent the development of powerful science and engineering AIs, before they can develop and deploy the kinds of technologies that are unfavorable along these dimensions. <br></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnjquiv0hah7e"> <span class="footnote-back-link"><sup><strong><a href="#fnrefjquiv0hah7e">^</a></strong></sup></span><div class="footnote-content"><p> To be clear, this would be a strong (and strange) claim about the world. It would mean that in general, it is easier to defend yourself from an attack, than it is to execute an attack, across all possible avenues of attack that an aggressor might choose.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnupawqb9o50e"> <span class="footnote-back-link"><sup><strong><a href="#fnrefupawqb9o50e">^</a></strong></sup></span><div class="footnote-content"><p> Note that the answer to this question is presumably sensitive to what strata of intelligence we&#39;re investigating. If I were investigating this more in more detail, I would model it as a function that maps the indifference between resources and intelligence, at different intelligence levels.</p></div></li><li class="footnote-item" role="doc-endnote" id="fncq5b0d0wcu9"> <span class="footnote-back-link"><sup><strong><a href="#fnrefcq5b0d0wcu9">^</a></strong></sup></span><div class="footnote-content"><p> Just to spell out the necessary struts of story under which a pivotal act is <i>not</i> necessary: </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LfGnzX7wm6j8MGWfT/pvyzwervkewcwx65ov9s" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LfGnzX7wm6j8MGWfT/kyqanmgr9tx6fyvdvpcy 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LfGnzX7wm6j8MGWfT/nlterxvytrxqhfcrkpdb 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LfGnzX7wm6j8MGWfT/jozaqr9lnu7wdfywkjkj 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LfGnzX7wm6j8MGWfT/udvmygozej3paemb0kwg 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LfGnzX7wm6j8MGWfT/wodmmjtc98dylv23qheg 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LfGnzX7wm6j8MGWfT/pg313fn5lyovvrom7ket 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LfGnzX7wm6j8MGWfT/jkiga5vrttnpmsecysxs 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LfGnzX7wm6j8MGWfT/f5nrto2yrzucr9qodudi 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LfGnzX7wm6j8MGWfT/t1icfetnr2j3zy6lctcn 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LfGnzX7wm6j8MGWfT/dt9obhrpnkygwxqfenty 1170w"><br><br> If all of these held, it might be feasible to have a lattice of agents all punishing defections from some anti-destructive norms, because for any given AI system, their incentive would be to support the enforcement lattice, given that they would not succeed in overthrowing it.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnt2r6pc761j"> <span class="footnote-back-link"><sup><strong><a href="#fnreft2r6pc761j">^</a></strong></sup></span><div class="footnote-content"><p> A reader pokes some holes in this argument. He suggests that even given this constraint, there are just not <i>that</i> many strongly offense-dominant weapon paradigms. This sort of argument suggests that Russia can obviously demolish Ukraine, given that they can choose from any of the many avenues of attack available to them. But in practice, they were not able to.</p><p> Furthermore, sometimes technologies have a strong offense-advantage, but with the possible exception of nuclear weapons, that advantage only extends to one area of war. German submarines put a stranglehold on allied shipping in the Atlantic during WWI, but a decisive win in that theater does not entail winning the global conflict.<br><br> I am uncertain what to think about this. I think maybe the reason why we see a rarity of strong offense-dominant technologies in history is a combination of the following<br><br> 1) Total war is relatively rare. Usually aggressors want to conquer or take the stuff of their targets, not utterly annihilate them. It seems notable that if Russia wanted to completely destroy the Ukrainian people and nation-state, nuclear weapons <i>are</i> a sufficient technology to do that.</p><p><br> (Would total war to the death be more common between AGI systems? I guess “yes”, if the motivation for war is less “wanting another AI&#39;s current material resources”, and more “wanting to preempt any future competition for resources with you.” But this bears further thought.)<br><br> 2) I think there&#39;s a kind of selection effect where, when I query my historical memory, I will only be able to recall instances of conflict that are in some middle ground where neither defense nor offense have a strong advantage, because all other conflicts end up not happening, in reality, for any length of time.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnf59isk0pwa9"> <span class="footnote-back-link"><sup><strong><a href="#fnreff59isk0pwa9">^</a></strong></sup></span><div class="footnote-content"><p> Note however, that a plan of investing in intelligence-advantage dominant domains (perhaps playing the stock markets?) to build up a material advantage might look quite different than the kind of instantaneous strike by a superintelligence depicted in the opening quote.</p><p><br> Suppose that it turns out that nanotechnology is off the table for some reason, and cyberwar turns out (surprisingly) to be defense-dominant once AGIs have patched most of the security vulnerabilities, and (even more surprisingly) superhuman persuasion is easily defeated by simple manipulation-detection systems, and so on, removing all the mechanisms by which a hard or soft conflict could be intelligence-advantage dominant.<br><br> In that unusual case, we would either see an AI takeover doesn&#39;t look sudden at all. It looks like a system or a consortium of systems using its superior intelligence to accrue compounding resources over months and years. That might entail beating the stock market, or developing higher quality products, or making faster gains in AI development.<br><br> It does that until  it has not only an intelligence-advantage, but also a material-advantage, and then potentially executing a crushing strike that destroys human civilization, which possibly looks something like a shooting war: deploying overwhelmingly more robot drones than will be deployed to defend humans, or maybe combined with a series of nuclear strikes.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnma05y1bmrg9"> <span class="footnote-back-link"><sup><strong><a href="#fnrefma05y1bmrg9">^</a></strong></sup></span><div class="footnote-content"><p> There&#39;s a general pattern where by a new offensive technology is introduced, and it is dominant for a period, until the defensive countermeasure is developed, and the offensive technology is made obsolete, after which aggressors will switch to a new vector of attack or find a defeater for the offensive measure. (eg. cannons dominate naval warfare until the development of iron-clads; submarines dominate merchant vessels until the convoy system defeats them; nuclear weapons are overwhelming, until the development of submarine second strike capability as a deterrent, but those submarines would be obviated by Machine Learning technologies to locate those subs.)<br><br> This pattern might mean that conflict between superintelligences has a different character, if they can see ahead, and predict what the stack of measures and countermeasures <i>is</i> . Just as a chess player doesn&#39;t attack their opponents rook if they can see that that would expose their queen one move latter, maybe superintelligences don&#39;t even bother to build the nuclear submarines, because they can immediately foresee the advanced sonar that can locate those submarines, nullifying their second strike capability.<br><br> Conflict between superintelligences might entail mostly playing out the offense-defense dynamics of a whole stack of technologies, to the <i>end</i> of the stack, and then building only the cheapest dominating offensive technologies, and all the dominating defensive technologies that, if you don&#39;t have them, allow your adversaries to disable you before you are able to deploy your offensive tech.<br><br> Or maybe the equilibrium behavior is totally different! It seems like there&#39;s room for a lot more thought here.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/LfGnzX7wm6j8MGWfT/unpacking-the-dynamics-of-agi-conflict-that-suggest-the#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/LfGnzX7wm6j8MGWfT/unpacking-the-dynamics-of-agi-conflict-that-suggest-the<guid ispermalink="false"> LfGnzX7wm6j8MGWfT</guid><dc:creator><![CDATA[Eli Tyre]]></dc:creator><pubDate> Fri, 20 Oct 2023 06:48:06 GMT</pubDate> </item><item><title><![CDATA[Genocide isn't Decolonization]]></title><description><![CDATA[Published on October 20, 2023 4:14 AM GMT<br/><br/><p> 1987年，U2乐队的主唱波诺中断了他的《<a href="https://en.wikipedia.org/wiki/Sunday_Bloody_Sunday"><u>星期日血腥星期日</u></a>》的表演，发表了一场关于“<a href="https://en.wikipedia.org/wiki/The_Troubles"><u>麻烦</u></a>”的演讲，原因是当天发生的<a href="https://en.wikipedia.org/wiki/Remembrance_Day_bombing"><u>恩尼斯基林爆炸事件</u></a>：</p><p><i>让我告诉你一件事，</i><br><i>我受够了爱尔兰裔美国人</i><br><i>他们已经20年或30年没有回过自己的国家了。</i><br><i>到我这里来，谈谈抵抗</i><br><i>回家革命</i><br><i>和革命的荣耀</i><br><i>以及为革命而死的光荣</i></p><p><i>去他妈的革命！</i></p><p><i>他们不谈论为革命而杀戮的荣耀</i><br><i>把一个人从床上拉起来有什么荣耀</i><br><i>当着他的妻子和孩子的面枪杀了他</i><br><i>这其中的荣耀在哪里？</i><br><i>轰炸阵亡将士纪念日游行的荣耀在哪里</i><br><i>老年养老金领取者的奖章被取出并擦亮以供当天使用</i><br><i>这其中的荣耀在哪里？</i><br><i>让他们死去，或者终身残废，或者死亡</i><br><i>在革命的废墟下</i><br><i>我国的大多数人</i><br><i>不要</i></p><p>恩尼斯基林爆炸事件造成 11 人死亡，与 10 月 7 日哈马斯残酷杀害（最新统计）的 1400 名以色列平民相比，简直是九牛一毛。但我觉得这篇演讲抓住了一些与当前时刻相关的重要内容。</p><hr><p>我对哈马斯的所作所为感到震惊，但更让我震惊的是，西方有多少人热切地为哈马斯的所作所为欢呼，或者不愿意谴责。哈马斯对犹太平民的屠杀受到多个<a href="https://www.theatlantic.com/ideas/archive/2023/10/college-students-justice-for-palestine-chapters-hamas/675640/"><u>校园学生团体</u></a>、 <a href="https://www.politico.com/news/2023/10/11/dsa-rally-aoc-israel-00121060"><u>DSA 分会</u></a>、 <a href="https://cbsaustin.com/news/nation-world/blm-chapters-side-with-palestinians-amid-hamas-massacre-israelis-israel-gaza-attacks-death-toll-black-lives-matter-chicago-los-angeles-washington-dc-nba-amare-stoudemire-president-joe-biden-nyc-mayor-eric-adams"><u>BLM 分会</u></a>和<a href="https://voz.us/michigan-democrats-refuse-to-officially-condemn-hamas-and-call-for-recognition-of-mistreatment-of-the-palestinian-people/?lang=en"><u>民主党团体</u></a>的赞扬。为了避免你认为这只是一种边缘观点， <a href="https://www.thefire.org/news/harvard-gets-worst-score-ever-fires-college-free-speech-rankings"><u>臭名昭著的挑剔</u></a>哈佛大学决定这是他们要采取<a href="https://www.bostonherald.com/2023/10/13/harvard-president-defends-free-speech-on-campus-after-students-anti-israel-statement-we-do-not-punish-or-sanction-people-for-expressing-such-views/"><u>言论自由立场的</u></a>一个话题。</p><p>这些团体为支持哈马斯杀害无辜平民辩护，声称这是“非殖民化”的正当理由——犹太人是穆斯林祖先土地上的“殖民者”，“当人们被占领时，抵抗是正当的”。</p><p>但这是“非殖民化”一词的一个非常新的含义。</p><p><a href="https://www.un.org/en/global-issues/decolonization"><u>联合国1960年宣言</u></a>所定义的非殖民化是“所有人的自决权”——拒绝少数中央国家征服遥远的土地并在不考虑其公民利益的情况下进行统治的殖民模式。它是二战后出现的一系列更广泛原则的一部分，例如主权边界、人权、反对种族清洗和禁止伤害平民等，希望通过采用这些原则，像二战这样的战争能够避免战争。永远不会再发生。</p><p>非殖民化的新含义似乎几乎相反——任何群体都有权对生活在他们声称是其祖先家园的土地上的任何其他族裔群体使用不受限制的暴力。</p><p>我的许多家庭成员都为非殖民化而奋斗。我的祖父<a href="https://en.wikipedia.org/wiki/David_Ennals,_Baron_Ennals"><u>大卫·恩纳尔斯</u></a>和叔祖父<a href="https://en.wikipedia.org/wiki/Martin_Ennals"><u>马丁·恩纳尔斯</u></a>是最初的非殖民化运动的关键人物，在反种族隔离运动、大赦国际（在马丁的领导下获得了<a href="https://www.nytimes.com/1991/10/07/world/martin-ennals-64-led-a-rights-group-to-world-influence.html"><u>诺贝尔和平奖</u></a>）、种族平等委员会、甘地组织等组织中发挥了关键作用。基金会、自由西藏运动、联合国协会等团体。我父亲写了一本关于非殖民化的书《<a href="https://www.amazon.com/Slavery-Citizenship-Richard-Ennals/dp/0470028327"><u>从奴隶制到公民身份</u></a>》。他们的运动中没有人支持针对平民的暴力行为，也没有任何<a href="https://www.martinennalsaward.org/"><u>马丁·恩纳尔斯奖</u></a>获得者。</p><p>用于为哈马斯辩护的“非殖民化”与我们被告知认为好的“非殖民化”几乎没有任何共同之处。</p><hr><p>很容易理解为什么有些人可能想要推翻二战后的和平共识。</p><p>对于许多群体来说，二战后的和平原则相当不公平。通过使边界具有主权并禁止种族清洗，他们有效地将人民的领土冻结在二战结束时的状态。对于巴勒斯坦人来说，这是在他们失去大片他们认为理应属于他们的领土之后。对于逃离大屠杀后刚刚抵达新土地的以色列人来说，他们发现自己的边界被冻结成一种尴尬的形状，这使得他们的主要城市几乎无法防御邻国敌对势力的攻击。</p><p>但撤销二战后和平共识的替代方案几乎肯定更糟糕。如果对你认为生活在自己祖国的任何人使用无节制的暴力是“非殖民化”，那么几乎没有人是安全的，因为我们都生活在以前被别人占领的土地上。大屠杀是非殖民化吗？欧洲人对最近的穆斯林移民进行种族清洗会是“非殖民化”吗？美洲原住民对美国平民的恐怖袭击会是“非殖民化”吗？有什么地方可以让犹太人居住而不成为殖民者呢？</p><p>我们应该拒绝这种非殖民化的新定义。当前的现状存在非常现实的问题，但替代方案更糟糕。</p><hr><p>那么我们是如何从那里到达这里的呢？</p><p>问题在于词语会改变它们的含义，有时它们会在改变旧含义的同时保持道德联想。</p><p>如果你想倡导植根于不宽容的伊斯兰原教旨主义（哈马斯就是这样）的种族灭绝血腥民族主义，你就不会使用这些词来描述你的意识形态，因为它们都有负面含义。相反，你会发现任何看起来最接近的具有强烈积极关联的概念，并使用学者擅长的修辞手段来论证每个人都应该喜欢的积极事物与你想要倡导的黑暗意识形态相同为了。</p><p>如果你做得很好，那么你所劫持的现有积极品牌就会如此强大，以至于批评你完全不同的想法就成为禁忌。</p><p>你也可以用同样的技巧来重新定义一个道德上令人反感的词，比如“种族灭绝”，来指代你的敌人正在做的任何事情，即使他们的行为与社会认为这个词令人反感时的含义几乎没有共同之处。</p><p>人们一直期望未来的纳粹分子能够被有效地贴上纳粹分子的标签，或者带有每个人都经过训练能够识别的其他负面徽章，但这并不是世界实际运作的方式。不要忘记纳粹称自己为国家社会主义者——这两个概念在当时有着积极的品牌。</p><hr><p>种族灭绝的民族主义的引力是很难避免的，因为它是人类默认的意识形态。历史基本上就是一长串种族灭绝的清单。不仅在世界的某一地区，而且在世界的所有地方。</p><p>你们的祖先能够在消灭你们的种族之前消灭其他种族。你们生活的土地是从你们的祖先压迫和杀害的其他人那里偷来的。这不仅适用于某些地方的某些人。这对所有地方的所有人来说都是如此。它是普遍存在的事实并不意味着它没问题。这太可怕了，今天许多社区都遭受着最近发生的此类事件的影响。</p><p>这是一个奇迹，我们生活在一个宝贵的时刻，这种生活方式并不是默认的。它在某些地方、某些时候仍然存在，但它非常罕见，因此当它发生时就会引起人们的注意。</p><p>这种情况之所以罕见，是因为我们集体选择执行一套神圣的原则来防止这种情况发生。诸如反对帝国的禁忌（非殖民化）、反对种族灭绝的禁忌、反对入侵其他国家的禁忌以及反对对平民使用暴力等原则。</p><p>这些禁忌很重要，重要的是我们不要让它们的含义发生变化，直到它们成为默认人类意识形态的另一个同义词。</p><hr><p>我以波诺的演讲开始这篇文章，现在我要回到它。</p><p>你会注意到，波诺从未说过他是否支持爱尔兰联合。他反对的不是爱尔兰共和军的目标（统一的爱尔兰），而是他们的方法（毫无意义的暴力）。</p><p>如果你告诉我你认为以色列在袭击哈马斯时应该采取更多措施来防止平民伤亡，那么我可能会同意你的观点。如果你告诉我巴勒斯坦人应该得到比现在更好的待遇，那么我可能会同意你的观点。如果你批评内塔尼亚胡的行为，那么我可能会同意你的观点。如果你认为犹太人的大屠杀后避难所应该放在西方某个地方而不是以色列，那么我可能会同意你的观点。这些都是重要的问题，但都是混乱的问题，我没有信心知道答案是什么。</p><p>但如果你主张通过针对无辜平民的邪恶暴力来实现你的目标，那么我永远不会同意你的观点。</p><br/><br/> <a href="https://www.lesswrong.com/posts/4muSjjmKA8WwFXGTh/genocide-isn-t-decolonization#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/4muSjjmKA8WwFXGTh/genocide-isn-t-decolonization<guid ispermalink="false"> 4muSjjmKA8WwFXGTh</guid><dc:creator><![CDATA[robotelvis]]></dc:creator><pubDate> Fri, 20 Oct 2023 04:14:08 GMT</pubDate> </item><item><title><![CDATA[Trying to understand John Wentworth's research agenda]]></title><description><![CDATA[Published on October 20, 2023 12:05 AM GMT<br/><br/><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 20:05:31 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 20:05:31 GMT" user-order="1"><p>奥利，你想把我们赶走吗？</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hBEAsEpoNHaZfefxR-Tue, 17 Oct 2023 20:29:41 GMT" user-id="hBEAsEpoNHaZfefxR" display-name="David Lorell" submitted-date="Tue, 17 Oct 2023 20:29:41 GMT" user-order="3"><p>我主要计划在这里观察（并进行编辑/建议），但如果我认为遗漏了一些特别重要的东西，我会插话。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">大卫·洛雷尔</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 20:32:57 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 20:32:57 GMT" user-order="2"><p>好的，本次对话的背景是我正在评估您的 LTFF 应用程序，您说“我想对自然抽象进行更多研究/也许发布测试我的假设的产品，您能给我钱吗？”。</p><p>然后我想，鉴于我一直在努力在 LW 上进行对话，我们也许还可以通过就您的研究进行对话来创造一些积极的外部性，这让其他稍后阅读该研究的人也能了解更多信息关于你正在做什么。</p><p>我通常很喜欢你对人工智能对齐的很多历史贡献，但你实际上并没有写太多关于你当前的中心研究议程/方向的文章，这确实是我应该至少从广义上理解的事情在完成对您的 LTFF 申请的评估之前。</p><p>我目前对自然抽象研究的看法大约是“约翰正在研究本体识别/操作，就像现在其他人一样”。我的意思是，这感觉像是 Paul 研究的中心主题，Anthropic 平淡的转向/可解释性工作中最有趣的部分，以及一些更有趣的 MIRI 工作。</p><p>以下是我与这一研究方向相关的一些事情：</p><ul><li>试图理解我们所拥有的概念与人工智能在尝试实现其关于世界的目标/原因的过程中将使用的概念之间的映射</li><li>试图达到这样的程度：如果我们有一个能够得出某个结论的人工智能系统，那么我们就有了一些“它大致使用什么推理来得出这个结论”的模型</li><li>这个领域不断出现的一个主要研究问题是“本体论组合”，比如如果我有一个论证使用在关节 X 处雕刻现实的本体，而另一个论证在关节 Y 处雕刻现实，我如何将它们结合起来？这感觉像是启发式论证的核心组成部分之一，也是笛卡尔框架的关键组成部分之一。</li></ul><p>但我不太有信心这些内容与您一直在做的研究非常吻合。我也没有感觉到人们在这里取得了巨大的进步，至少在保罗的启发式论证工作中，我大多开玩笑地将其称为“为了调整我首先拥有的人工智能”将所有认识论形式化”，虽然我认为这是一个很酷的目标，但它看起来确实是一个相当困难的目标，而且根据先验知识，我不希望有人在未来几年内解决它。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 20:45:44 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 20:45:44 GMT" user-order="1"><p>好的，我只是要陈述过去几个月的核心结果，然后我们可以解开它如何与您正在谈论的所有事情联系起来。</p><p>假设我有两个概率模型（例如，来自两个不同的代理），它们对某些“可观察量”X 做出<i>相同的</i>预测。例如，描绘两个图像生成器，它们生成基本相同的图像分布，但使用不同的内部架构。这两个模型的不同之处在于使用不同的内部概念 - 此处可操作为不同的内部潜在变量。</p><p>现在，假设其中一个模型有一些内部潜在的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>（在该模型下）在两块可观察变量之间进行调解 - 对于某些生成模型中的内部潜在变量来说，这将是非常典型的事情。然后我们可以对<i>另一个</i>模型中的潜在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span></span></span></span></span>给出一些简单的充分条件，使得<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda \rightarrow \Lambda' \rightarrow X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-msup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span> 。</p><p>另一种可能性（与前一个主张双重）：假设两个模型之一具有一些内部潜在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span></span></span></span></span></span> ，（在该模型下）可以从可观察量的几个不同子集中的任何一个精确估计 - 即我们可以删除任何一个部分的可观测量，仍然得到<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span></span></span></span></span></span>的精确估计。然后，在另一个模型中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span></span></span></span></span>上的相同简单充分条件下， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda' \rightarrow \Lambda \rightarrow X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span> 。</p><p>这里的一个标准示例是理想气体中的温度 ( <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span></span></span></span></span> )。它满足充分条件，因此我可以查看对气体做出相同预测的任何模型，并查看该模型中在两个相距较远的气体块之间调解的任何潜在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span> ，我会发现<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span>包括温度（即温度是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span>的函数）。或者我可以查看任何<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span> ，它可以从任何一小块气体中精确估计，我会发现温度包括<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span> （即<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span>是温度的函数）。</p><p> ...并且至关重要的是，这一切都可以很好地近似，因此，如果例如<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span>近似介导两个块之间，那么我们就可以得到关于两个潜在变量的近似声明。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 20:46:58 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 20:46:58 GMT" user-order="1"><p>因此，所有这一切的结果是：我们有一种方法来查看一个模型内部潜在变量（“概念”）的某些属性，并说明它们如何与另一个模型中的广泛潜在变量类别相关。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 20:47:04 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 20:47:04 GMT" user-order="2"><p>好吧，“在两块可观察变量之间进行调解”是什么意思？</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 20:49:10 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 20:49:10 GMT" user-order="1"><p>它是条件独立意义上的中介 - 例如，两个不太靠近的气体块在给定温度的情况下具有近似独立的低级状态，或者由图像吐出的两个不太靠近的图像块图像生成器是独立的，以它们上游的一些“远程”潜伏为条件。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 20:50:25 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 20:50:25 GMT" user-order="1"><p> （特别是，这种中介事物与任何以这样的方式分解其世界模型的思维相关，即两个块处于不同的“因素”中，并且它们之间有一些相对稀疏的相互作用。）</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 20:50:41 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 20:50:41 GMT" user-order="2"><p>这个方程中的箭头意味着什么？</p><p> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda \rightarrow \Lambda' \rightarrow X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-msup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span></p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 20:52:28 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 20:52:28 GMT" user-order="1"><p>箭头图使用贝叶斯网络表示法，因此例如<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda \rightarrow \Lambda' \rightarrow X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-msup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span>表示在给定<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span>的情况下<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span>和<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span></span></span></span></span>是独立的，或者等效地，一旦我们知道<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span> ， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span></span></span></span></span>就不再告诉我们有关<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span>的信息。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 20:52:53 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 20:52:53 GMT" user-order="1"><p> （此外，如果您想要比这更缩小的描述，我们也可以这样做。）</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 21:04:04 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 21:04:04 GMT" user-order="2"><p>酷，让我在尝试将这个数学转化为更具体的例子时大声思考。</p><p>这是两个程序的随​​机示例，它们使用不同的本体，但在某些可观察量集上具有相同的概率分布。</p><p>假设程序进行加法运算，其中一个使用整数，另一个使用浮点数，我对它们进行评估，范围为 1-100 左右，其中浮点误差不重要。</p><p>你说的这件事和这个事情有关系吗？</p><p>天真地，我觉得你所说的可以翻译成“如果我知道一个数字的浮点表示，我应该能够找到某种方法在整数程序的上下文中使用该表示来获得相同的结果”。但我肯定不会立即明白该怎么做。我的意思是，我当然可以翻译它们，但除此之外我真的不知道该说些什么。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 21:06:16 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 21:06:16 GMT" user-order="1"><p>好吧，首先我们需要找到一些在“可观察量”的两个部分（即传入和传出的数字）之间进行调解的内部事物，或者一些我们可以从可观察量的子集精确估计的内部事物。</p><p>例如：也许我查看整数加法器内部，发现有一个进位（例如，从 1 位置“进位”到 10 位置的数字），并且进位位于输入的最高有效位之间/输出，以及最低有效数字。</p><p>然后，我知道可以从<i>最高</i>有效数字<i>或</i>最低有效数字计算出的<i>任何</i>数量（即相同的数量必须可以从任一数字计算）都是该进位的函数。因此，如果浮点加法器使用任何类似的东西，我知道它是整数加法器本体中进位的函数。</p><p> （在这个特定的例子中，我认为我们没有任何如此有趣的数量；我们的“可观察量”在某种意义上是“已经压缩的”，所以关于两个程序之间的关系没有太多重要的可说。）</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 21:07:38 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 21:07:38 GMT" user-order="2"><p>啊，所以当你说<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda \rightarrow \Lambda' \rightarrow X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-msup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span>时，你的意思并不是“我们可以找到一个<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span></span></span></span></span> ”，你是说“如果有一个<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span></span></span></span></span>满足某些条件，那么我们可以使用以下方法使其有条件地独立于可观察量： <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span></span></span></span></span></span> ”?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 21:07:50 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 21:07:50 GMT" user-order="1"><p>是的。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 21:08:13 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 21:08:13 GMT" user-order="2"><p>好吧，酷，这对我来说更有意义。 <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span></span></span></span></span>上的哪些条件允许我们这样做？</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 21:11:12 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 21:11:12 GMT" user-order="1"><p>原来我们已经见过他们了。这两个条件是：</p><ul><li> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span></span></span></span></span>必须在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span>的一些块之间进行调解</li><li>对于排除的任何块， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span></span></span></span></span>必须可以从除其中一个块之外的所有块中精确估计（即我们可以删除任何一个块，但仍然可以获得<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Lambda"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Λ</span></span></span></span></span></span></span>的精确估计）。</li></ul><p>例如，在理想气体中，在给定温度的情况下，相距较远的块几乎是独立的，我们可以精确地估计任何一个（或几个）块的温度。因此，该设置下的温度满足条件。并且近似有效，因此这也可以延续到近似理想的气体。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 21:15:36 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 21:15:36 GMT" user-order="2"><p>好的，所以我们在这里所说的是“如果我有两个系统以某种方式模拟理想气体的行为，如果存在任何潜在变量在遥远的气体簇之间进行调节，那么我必须能够从中提取温度多变的”？</p><p>当然，我们不能保证任何这样的系统实际上具有任何潜在变量来调节对遥远气体簇的预测。就像，这个东西可能只是一个大型的预先计算的查找表。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 21:16:18 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 21:16:18 GMT" user-order="1"><p>完全正确。我们确实有一些理由期望中介密集型模型能够实现工具收敛，但这是一个单独的故事。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 21:18:09 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 21:18:09 GMT" user-order="2"><p>我发现很难举出“精确计算”条件的例子。比如，有哪些现实情况会出现这种情况？</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 21:22:30 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 21:22:30 GMT" user-order="1"><p>当然，在我看来，一旦你知道要寻找什么，“精确计算”实际上更容易看到。例子：</p><ul><li>通过观察某个物种的一些成员，我们可以很好地估计该物种的共有基因组。</li><li> ...就此而言，我们可以通过观察物种的一些成员来很好地估计该物种的各种特性。体型、典型发育轨迹（包括每个年龄段的体重或体型）、行为等</li><li>通过查看几辆 2009 款丰田卡罗拉，我们可以对 2009 款丰田卡罗拉的很多方面有一个很好的估计。</li><li>在聚类语言中，我们可以通过查看该聚类中的中等大小的点样本来获得聚类统计量的非常精确的估计（例如，在混合高斯模型中的均值和方差）。</li></ul><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> 约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hBEAsEpoNHaZfefxR-Tue, 17 Oct 2023 21:22:34 GMT" user-id="hBEAsEpoNHaZfefxR" display-name="David Lorell" submitted-date="Tue, 17 Oct 2023 21:22:34 GMT" user-order="3"><p>值得注意的是，在这些例子中，数量实际上并不能“精确”计算，但正如他所提到的，我们有近似结果，效果很好。 （我所说的“很好”，是指“具有明确定义的误差范围。”）</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">大卫·洛雷尔</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 21:22:46 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 21:22:46 GMT" user-order="2"><p>我确实对近似的事情如何可能是真实的感到有点困惑，但让我们稍后再考虑，我现在可以将其视为给定的。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 21:24:39 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 21:24:39 GMT" user-order="1"><p>例如，如果（在我的模型下）2009 年丰田卡罗拉有一些特征属性，那么所有 2009 年丰田卡罗拉在给定这些属性的情况下几乎是独立的，并且我可以从卡罗拉样本中估计这些属性，那么我就具备了条件。</p><p> （请注意，我实际上不需要知道属性的值 - 例如，即使我不知道该物种的整个共有序列，物种的基因组也可以满足我的模型下的属性。）</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 21:31:50 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 21:31:50 GMT" user-order="2"><p>就像，我一直想把上面的句子翻译成这样的句子：“我因为 X 原因相信 A，你因为 Y 原因相信 A，我们对 A 的信念都是正确的。这意味着我可以以某种方式说些什么关于X和Y之间的关系”，但我觉得我还不能完全将事物转化为那种形式。</p><p>就像，我绝对不能提出“因此 X 和 Y 可以相互计算”的一般情况，当然不可能。所以你说的是较弱的话。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 21:36:27 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 21:36:27 GMT" user-order="1"><p>在一个模型下，我可以从一小部分橡树样本中估计橡树的共有基因组序列。在其他一些中世纪模型下，大多数橡树都是近似独立的，因为橡树具有某种神秘的本质，原则上可以通过检查橡树样本来发现这种神秘的本质，尽管没有人知道这种神秘本质的价值（他们只是假设它的存在）。好消息：橡树的神秘本质中隐含着一致的基因组序列。</p><p>更准确地说：任何构建联合模型的方法，包括共有序列和橡树的神秘本质，以及它们与所有“可观察”橡树的原始关系，都会说共有基因组序列是神秘本质，即一旦我们知道了神秘本质的价值，橡树本身就无法告诉我们关于共识序列的任何额外信息。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 21:38:24 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 21:38:24 GMT" user-order="2"><p>好吧，也许我很蠢，但是，假设你把你的社会安全号码刻在两棵橡树上。现在，可以从任何橡树样本（最多留下一棵）中估计出附有您的社会安全号码的共识基因组序列。在其他一些中世纪模型下，橡树有一些神秘的本质，可以通过对一些橡树取样来发现。现在，共识基因组序列加上您的社会安全号码绝对不是隐式包含在橡木的神秘本质中的情况。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 21:40:58 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 21:40:58 GMT" user-order="1"><p>是的，这是一个很好的例子。在这种情况下，社会安全号码将通过“从子集估计”要求被排除在神秘的本质之外，该要求允许扔掉不止一棵橡树（事实上，我们想要一个更严格的要求） 。</p><p>然而，另一面可以说更有趣：如果你将你的社会安全号码刻在足够多的橡树上，超过所有曾经存在的橡树，那么你的社会安全号码自然会成为“橡树簇”的一部分。人们可以通过改变环境来改变自然的“概念”。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="hBEAsEpoNHaZfefxR-Tue, 17 Oct 2023 21:41:01 GMT" user-id="hBEAsEpoNHaZfefxR" display-name="David Lorell" submitted-date="Tue, 17 Oct 2023 21:41:01 GMT" user-order="3"><p>我认为更加具体会有益于这一点。约翰，您能为我们指定您的 SSN 吗？</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">大卫·洛雷尔</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 21:44:06 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 21:44:06 GMT" user-order="2"><p>好吧，所以这一定与我不明白的“近似”东西有关。就像，如果我必须将上述内容翻译成更正式的标准，你会说它失败了，因为就像，在不知道你的社会安全号码的情况下，橡树实际上并不是独立的，但我有点未能让这个例子成功这里。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 21:46:40 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 21:46:40 GMT" user-order="1"><p>我不认为当前的示例是我们之前使用的意义上的“近似”。有一个不同的“近似”概念，在这里更相关：我们可以完全削弱“<i>大多数</i>可观测量块在给定潜在条件下是独立的”的条件，然后相同的结论仍然成立。 （原因是，如果大多数可观察量块在给定潜在条件下是独立的，那么我们仍然可以找到<i>一些</i>在给定潜在条件下独立的块，然后我们只需使用这些块作为声明的基础。）</p><p> （更一般地说，我们想象使用这种机制的方式是在模型中寻找可观察量块，我们可以在这些可观察量块上找到满足条件的潜在变量；我们不需要一直使用所有可观察量。）</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 21:47:55 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 21:47:55 GMT" user-order="2"><p>好吧，我实际上对这里的粗略证明大纲感兴趣，但也许我们应该花更多时间讨论更高层次的东西。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 21:48:14 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 21:48:14 GMT" user-order="1"><p>当然，您还有哪些更高层次的问题？</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 21:48:54 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 21:48:54 GMT" user-order="2"><p>比如，如果你必须给出一个非常简短且高度压缩的总结，说明此类研究如何帮助人工智能不杀死所有人，你会说什么？我也可以先猜测一下，然后你可以纠正我。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 21:51:43 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 21:51:43 GMT" user-order="2"><p>我自己的非常短的故事是这样的：</p><blockquote><p>嗯，了解人工智能在什么条件下会发展出与人类相同的抽象概念确实很重要，因为当它们这样做时，如果我们也能识别和操纵这些抽象概念，我们就可以利用它们来引导强大的人工智能系统避免产生灾难性后果。 </p></blockquote><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 21:52:54 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 21:52:54 GMT" user-order="1"><p> Sure.简单的故事是：</p><ul><li>这为我们期望某些类型的潜在/内部结构将在思想/本体之间很好地映射提供了一些基础。</li><li>我们可以在例如网络中寻找这样的结构，看看它们与我们自己的概念的匹配程度如何，并且有理由期望它们在某些情况下能够稳健地匹配我们自己的概念。</li><li>此外，随着新的、更强大的人工智能的出现，我们期望能够将这些概念转移到那些更强大的人工智能的本体中（只要更强大的人工智能仍然具有满足一个或两个条件的潜伏，这本身就是可以在-原则）。</li><li> ...只要一切有效，我们就可以使用这些潜在的作为“本体可移植”构建块来构建更复杂的概念。</li></ul><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> 约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 21:54:12 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 21:54:12 GMT" user-order="1"><p>因此，如果我们能够用这些类型的构建块构建我们想要的任何类型的对齐机器，那么我们有理由期望该机器能够在本体之间很好地传输，尤其是新的更强大的未来人工智能。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 21:56:04 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 21:56:04 GMT" user-order="2"><p>为了澄清最后一部分，你的故事是这样的：“我们让一些低功率的人工智能系统来做一些我们大致理解和喜欢的事情。然后我们让一个高性能的人工智能系统做大致相同的事情原因。这意味着高性能人工智能系统的行为大致可预测，并且以我们喜欢的方式运行”？</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 21:56:31 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 21:56:31 GMT" user-order="1"><p>这不是我想象的典型情况，但当然，这是一个示例用例。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 21:58:05 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 21:58:05 GMT" user-order="1"><p>我的原型图更像是“我们解码（一堆）人工智能的内部语言，直到我们可以用该语言陈述我们想要的东西，然后将其内部搜索过程定位于此”。本体传输对于“解码其内部语言”步骤和未说明的“将相同目标传输到后继人工智能”步骤都很重要。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 21:58:40 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 21:58:40 GMT" user-order="2"><p>喔好吧。 “重新定位其内部搜索过程”部分听起来确实更像是您会说的那种事情。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 22:00:41 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 22:00:41 GMT" user-order="2"><p>好吧，那么，您为什么要考虑构建产品而不是（例如）写下您迄今为止拥有的一些证明或结果？我的意思是，无论人们喜欢什么，验证假设似乎都很好，但是构建一个产品需要很长时间，而且我并不完全理解从那到好的事情发生的路径（例如，“约翰有更好的模型”的路径在多大程度上）问题领域与约翰对一系列解决方案进行了非常具体和发自内心的演示，然后其他人采用并迭代，然后进行扩展？”</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 22:03:36 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 22:03:36 GMT" user-order="1"><p>所以，在过去的几年里，我做了很多“写东西”，而在我的技术工作上有用的人的数量几乎为零。 （虽然不可否认最新的结果更好，但我确实认为人们更有可能在它们的基础上进行构建，但我不知道会增加多少。） 另一方面，分叉危险：我不得不担心这个东西是危险的准确地分享它最有用的世界。</p><p>我希望产品能够提供比其他人对我们技术工作的评论更有用的反馈信号。</p><p> （另外，我们不打算制造超级抛光的产品，所以希望时间消耗不会太疯狂。就像，我们这里有一些非常新颖和酷的理论，如果我们做得很好的话那么即使是有点hacky的产品也应该能够做到今天其他人无法做到的事情。）</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 22:03:42 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 22:03:42 GMT" user-order="2"><p>我的感觉是发布证明和解释的通常目的不仅仅是领域建设。我的猜测是，这也是让你自己的认知状态更加稳健的一个相当合理的部分，尽管这不像是一个可推翻的论证（我并不是说人们在不发表论文的情况下就不能得出合理的真实信念，尽管我确实认为这是合理的）对于这个领域的东西来说，在没有公开争论的情况下真正相信的情况相对较少）。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 22:04:55 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 22:04:55 GMT" user-order="2"><blockquote><p> （另外，我们不打算制造超级抛光的产品，所以希望时间消耗不会太疯狂。就像，我们这里有一些非常新颖和酷的理论，如果我们做得很好的话那么即使是有点hacky的产品也应该能够做到今天其他人无法做到的事情。）</p></blockquote><p>好吧，我们是否更多地考虑“产品”，即“Chris Olah 的团队在每个大版本中都制作了一个产品，其形式就像一个网络应用程序，允许您使用神经网络查看事物并执行操作以前是不可能的”或者更多的意思是“你现在实际上会赚很多钱并进入 YC 或其他什么地方”？</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 22:06:22 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 22:06:22 GMT" user-order="1"><blockquote><p>我的感觉是发布证明和解释的通常目的不仅仅是领域建设。我的猜测是，这也是让你自己的认知状态更加稳健的一个相当合理的部分......</p></blockquote><p>我原则上同意这一点。在实践中，在我的工作中有效识别技术问题的人数……不到六人。把它写下来也有一些价值——当我把东西写下来时，我经常发现问题——但这似乎更容易替代。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 22:07:15 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 22:07:15 GMT" user-order="2"><blockquote><p>我原则上同意这一点。在实践中，在我的工作中有效识别技术问题的人数……不到六人。</p></blockquote><p>我的意思是，六个人看起来还算不错。我不知道对于大多数量子力学、相对论或电动力学的发展来说，是否需要更多的参与。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="MEu8MdhruX5jfGsFQ-Tue, 17 Oct 2023 22:07:34 GMT" user-id="MEu8MdhruX5jfGsFQ" display-name="johnswentworth" submitted-date="Tue, 17 Oct 2023 22:07:34 GMT" user-order="1"><blockquote><p>好吧，我们是否更多地考虑“产品”，即“Chris Olah 的团队在每个大版本中都制作了一个产品，其形式就像一个网络应用程序，允许您使用神经网络查看事物并执行操作以前是不可能的”或者更多的意思是“你现在实际上会赚很多钱并进入 YC 或其他什么地方”</p></blockquote><p>介于两者之间。就像，赚钱是一个非常有用的反馈信号，但我们并不打算去做 YC 或重新将我们的整个生活集中在建立一家公司上。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">约翰斯文特沃斯</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 22:07:45 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 22:07:45 GMT" user-order="2"><p>好吧，酷，这可以帮助我在这里找到一些味道。</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Tue, 17 Oct 2023 22:09:17 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Tue, 17 Oct 2023 22:09:17 GMT" user-order="2"><p>我还有很多问题要问，但我们正处于一个自然的停止点。我可能会问一些更多异步或发布后的问题，但是谢谢你，这非常有帮助！</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">哈布里卡</section></section><br/><br/><a href="https://www.lesswrong.com/posts/7fq3r4n5CCgYLfsJb/trying-to-understand-john-wentworth-s-research-agenda#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/7fq3r4n5CCgYLfsJb/trying-to-understand-john-wentworth-s-research-agenda<guid ispermalink="false"> 7fq3r4n5CCgYLfsJb</guid><dc:creator><![CDATA[johnswentworth]]></dc:creator><pubDate> Fri, 20 Oct 2023 00:05:40 GMT</pubDate> </item><item><title><![CDATA[Boost your productivity, happiness and health with this one weird trick]]></title><description><![CDATA[Published on October 19, 2023 11:30 PM GMT<br/><br/><p>多亏了<a href="https://blogs.scientificamerican.com/beautiful-minds/the-role-of-luck-in-life-success-is-far-greater-than-we-realized/">一点运气</a>+ <a href="https://milkyeggs.com/biology/estimated-iq-distribution-of-children-given-iq-of-parents/">好的基因</a>+<a href="https://www.aeaweb.org/articles?id=10.1257/aer.102.5.1927">一些手段</a>，你度过了一个还算幸福的童年，大学毕业，最后找到了一份你擅长的工作。你喜欢你所做的工作（大多数时候），因为人们喜欢做他们擅长的事情。而且你也会工作很多时间，因为人们发现很容易花很多时间做他们喜欢的事情。</p><p>因为你工作了很多小时，所以你会在传递函数曲线（x 轴时间，y 轴总工作输出）上非常靠右，其中梯度 - 你工作时间的边际回报支出 - 相当平稳，如果你诚实的话。</p><p>是的，对于某些活动（如竞技游泳）来说，收益递减仍然是值得的，因为表现上的微小差异会对结果产生巨大影响。但这对你来说可能不是这样。您不必每天花费 10、12 或 14 小时编码，只要有一点意志力，您就可以将其减少到 8、10 或 12 小时，而且您周围的人不会注意到其中的差异。如果您之前是一名 10X 开发人员，那么您仍然会是一名 10X 开发人员。在绩效评估中，您仍然会表现出色。</p><p>然后，你将每天的 2 小时重新分配到其他你在传递函数曲线上更靠左的事情上，比如开始一个业余项目、培养新的爱好，或者与孩子共度美好时光。</p><p>由于您现在将更多的时间花在传递函数曲线的左侧，其中梯度 Δwork/Δtime 更加陡峭，因此您的总生产力将会提高。<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2863117/">你也会变得更健康、更快乐</a>。</p><p>大约 20 年前，我开始应用这一原则，首先非常注意自己在日常生活各个部分的传递函数曲线上的实际位置，并最终对时间进行了重大的重新分配。事实上，它对我的​​整体生产力、幸福感和健康产生了变革性的影响。然而，我认识的几乎每个人都将大量时间花在传递函数曲线的平坦部分上。为什么？</p><br/><br/> <a href="https://www.lesswrong.com/posts/h7u5F85XvLp2WXScE/boost-your-productivity-happiness-and-health-with-this-one#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/h7u5F85XvLp2WXScE/boost-your-productivity-happiness-and-health-with-this-one<guid ispermalink="false"> h7u5F85XvLp2WXScE</guid><dc:creator><![CDATA[ajc586]]></dc:creator><pubDate> Thu, 19 Oct 2023 23:30:54 GMT</pubDate> </item><item><title><![CDATA[A Good Explanation of Differential Gears]]></title><description><![CDATA[Published on October 19, 2023 11:07 PM GMT<br/><br/><p> Jam Handy 于 1937 年制作了一段非常棒的<a href="https://youtu.be/67XoCMTcN7M?si=fcAbTL5r125Ypc9Q&amp;t=116">视频</a>。它解释了为什么我们需要差速齿轮以及它们的工作原理。</p><p>我认为该视频是解释的杰作。我建议您观看它，不是因为理解差异是必要的（尽管这并没有什么坏处），而是因为该视频可以教您很多关于如何正确解释某些事物的知识。</p><p>以下是视频使用的一些技术（非详尽）：</p><ul><li>首先给出为什么所解释的事情很重要的背景，例如通过描述要解释的事情是解决方案的具体问题。</li><li>使用视觉解释。具体来说，展示要在行动中解释的机制。</li><li>开始解释一个简单的玩具模型，然后增加层层复杂性，直到得到真正的模型。</li></ul><p>我想我从来没有见过这样的解释，它最终如此有效地消除了误解的可能性，而且我真的很喜欢从背景故事到技术解释的顺利过渡。没有不和谐的休息。</p><br/><br/> <a href="https://www.lesswrong.com/posts/vb5SNpLjk5bavsvyB/a-good-explanation-of-differential-gears#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/vb5SNpLjk5bavsvyB/a-good-explanation-of- Differential-gears<guid ispermalink="false"> vb5SNpLjk5bavsvyB</guid><dc:creator><![CDATA[Johannes C. Mayer]]></dc:creator><pubDate> Thu, 19 Oct 2023 23:07:47 GMT</pubDate> </item><item><title><![CDATA[New roles on my team: come build Open Phil's technical AI safety program with me!]]></title><description><![CDATA[Published on October 19, 2023 4:47 PM GMT<br/><br/><p> Open Phil 两周前<a href="https://forum.effectivealtruism.org/posts/bBefhAXpCFNswNr9m/open-philanthropy-is-hiring-for-multiple-roles-across-our"><u>宣布</u></a>，我们正在为致力于全球灾难性风险降低的团队招聘 20 多个职位，并且我们将从明天开始在<a href="https://forum.effectivealtruism.org/posts/peLstYwka2EzxiNG7/ama-six-open-philanthropy-staffers-discuss-op-s-new-gcr"><u>AMA</u></a>上回答问题。在此之前，我想分享一些有关我在<a href="https://www.openphilanthropy.org/research/new-roles-on-our-gcr-team/#5-technical-ai-safety"><u>团队</u></a>中招聘的角色（技术人工智能安全）的信息。该团队的目标是思考哪些技术研究最能帮助我们理解和降低人工智能的 x 风险，并通过向伟大的项目和研究小组提供资助，在高度优先的研究领域建立繁荣的领域。</p><p>首先，自从我们最初于 9 月 29 日列出角色以来，我们在技术 AI 安全中添加了三个新角色，如果您只看到原始公告，您可能还没有看到这些角色！除了最初的<strong>（高级）项目助理</strong>角色外，我们上周还增加了一个<strong>执行助理</strong>角色，昨天我们又增加了一个<strong>（高级）研究助理</strong>角色和一个专门从事人工智能<strong>特定子领域的高级项目助理</strong>角色安全研究（例如可解释性、对齐理论等）。看看它们是否有趣！行政助理的角色尤其需要非常不同的、技术性较低的技能。</p><p><strong>其次，在开始回答 AMA 问题之前，我想强调一下，我们的技术 AI 安全给予距离应有的平衡点还很远，还有相当大的增长空间，雇佣更多的人可能会很快带来更多更好的结果。补助金</strong>。我的估计是，去年，我们建议为人工智能技术安全提供约 2500 万美元的拨款， <span class="footnote-reference" role="doc-noteref" id="fnrefmw34ime35j"><sup><a href="#fnmw34ime35j">[1]</a></sup></span> ，今年到目前为止，我建议了类似的金额。随着拨款评估、研究和运营能力的增强，我们认为这一数字很容易翻倍或更多。</p><p>我们所有的 GCR 团队（由我领导的技术人工智能安全团队、由 Claire Zabel 领导的能力建设团队、由 Luke Muehlhauser 领导的人工智能治理和政策团队、以及由 Andrew Snyder-Beattie 领导的生物安全团队）目前的能力都受到严重限制，尤其是那些从事相关工作的团队鉴于最近该领域的兴趣和活动蓬勃发展，与人工智能相关的工作。我认为我的团队目前面临着比其他项目团队更严格的限制。与其他团队相比，我的团队：</p><ul><li><strong>规模要小得多：</strong>直到上周，我才主要关注人工智能技术安全（尽管克莱尔的团队有时会资助人工智能技术安全工作，主要是技能提升）。上周，<a href="https://www.openphilanthropy.org/about/team/max-nadeau/"><u>马克斯·纳多 (Max Nadeau)</u></a>作为我的第一位项目助理加入。相比之下，能力建设团队有八人，生物安全和人工智能治理团队各有五人。</li><li><strong>其领域的“覆盖范围”可能更差：</strong><ul><li>理想情况下，特定领域的强大且忠诚的资助团队将：<ul><li>与各自领域中最有影响力/最有前途的（例如）5-30% 的现有受资助者、潜在受资助者和关键非受资助者（例如在行业实验室从事人工智能安全工作的人员）保持实质性关系。</li><li>拥有相当强大的系统来了解其领域中大多数可能的潜在新受资助者（通过例如申请表或强大的推荐网络）。</li><li>有足够的能力对大部分可能的潜在受资助者进行重要的考虑，以便就是否资助他们以及资助多少做出明智、明确的决定。</li><li>拥有足够的能力来回顾性评估大笔拨款或重要类别拨款的结果。</li></ul></li><li>我的团队绝对没有达到这样的覆盖水平（例如，我们没有时间<a href="https://forum.effectivealtruism.org/posts/dua879FhtLf9jqyJo/there-should-be-more-ai-safety-orgs?commentId=dQL4yD7HzdfgqBKKs"><u>打开申请表</u></a>或结识可以从事安全工作的学者）。虽然我们所有的 GCR 项目领域都可以使用更多的“现场覆盖”，但我的猜测是，我们在技术人工智能安全方面的覆盖范围比至少克莱尔和安德鲁在其领域的覆盖范围要差得多。该团队不仅覆盖其领域的人员较少，而且似乎可能的潜在参与者数量可能会更大，因为最近大量技术人员开始对人工智能安全产生了更大的兴趣。</li></ul></li><li><strong>有一个更新生的战略：</strong>虽然自 2015 年以来我们一直以某种形式资助技术人工智能安全研究，但该计划领域已多次更换领导层和战略方向， <span class="footnote-reference" role="doc-noteref" id="fnrefcw2c961mapw"><sup><a href="#fncw2c961mapw">[2]</a></sup></span>并且当前的迭代非常接近于全新的状态- 我们已经结束了大部分旧项目，并希望从头开始建立一个新的、稳定的资助计划。<ul><li>我们的战略悬而未决的原因之一是，当前迭代的团队非常新，人工智能能力的进步正在迅速改变易于处理的研究项目的格局。我领导该项目领域还不到一年，我提供的大部分资助都提供给了 2021 年之前不存在的新团体和/或之前根本不可行的研究项目过去几年。相比之下，其他项目负责人已经制定了几年或更长时间的战略。</li><li>另一个重要原因是，我们还有大量悬而未决的问题，比如我们最希望看到哪些技术项目、什么样的结果最能改变我们对关键问题的看法或推动关键安全技术的发展，以及我们应该如何优先考虑这些问题对象级工作的不同流。例如，对此类问题的更好答案可能会改变我们重点关注的研究领域以及我们向潜在受助者推销的内容：<ul><li>我们如何判断可解释性技术的前景如何？衡量成功的最佳“内部有效性”指标是什么？衡量的最佳下游任务是什么？</li><li>理想的<a href="https://www.alignmentforum.org/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1"><u>错位模型生物体</u></a>的要素是什么？创建这样一个模型的挑战是什么？</li><li><a href="https://llm-attacks.org/"><u>对抗性攻击和防御</u></a>研究中最引人注目的变革/影响路径理论是什么？此类研究最令人兴奋的版本是什么？</li><li>是否有一些<a href="https://people.eecs.berkeley.edu/~russell/papers/neurips20ws-assistance"><u>受辅助游戏/奖励不确定性传统启发</u></a>的实证研究方向，即使在语言模型范式中也可能有所帮助？</li></ul></li></ul></li></ul><p>如果您在这一轮中加入技术人工智能安全团队，您可以帮助缓解一些严重的瓶颈，同时从头开始构建该程序领域的新迭代。如果这听起来令您兴奋，我强烈鼓励您申请！ <br></p><p><br></p><p><br></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnmw34ime35j"> <span class="footnote-back-link"><sup><strong><a href="#fnrefmw34ime35j">^</a></strong></sup></span><div class="footnote-content"><p>有趣的是，这些数字实际上比之前几年的年度技术人工智能安全捐赠要大得多，尽管与 2015-2021 年相比，2022 年和 2023 年我们在该领域工作的全职员工数量较少。</p></div></li><li class="footnote-item" role="doc-endnote" id="fncw2c961mapw"> <span class="footnote-back-link"><sup><strong><a href="#fnrefcw2c961mapw">^</a></strong></sup></span><div class="footnote-content"><p>最初，我们的项目由丹尼尔·杜威（Daniel Dewey）领导。到 2019 年左右，凯瑟琳·奥尔森 (Catherine Olsson) 加入了该团队，最终（我认为到 2020-2021 年）它转变为由尼克·贝克斯特德 (Nick Beckstead) 管理的三人团队，尼克·贝克斯特德 (Nick Beckstead) 负责管理凯瑟琳 (Catherine) 和丹尼尔 (Daniel)，以及阿莎·伯格 (Asya Bergal) 的一半时间。 2021 年，丹尼尔、凯瑟琳和尼克三人都离开去担任其他角色。在过渡时期，没有一个单一的人：霍尔顿亲自处理较大的资助（例如红木研究），而阿西亚则处理较小的资助（例如<a href="https://www.openphilanthropy.org/request-for-proposals-for-projects-in-ai-alignment-that-work-with-deep-learning-systems/"><u>尼克最初发起的 RFP</u></a>和<a href="https://www.openphilanthropy.org/potential-risks-advanced-artificial-intelligence-the-open-phil-ai-fellowship/"><u>我们的博士奖学金</u></a>）。 <a href="https://forum.effectivealtruism.org/posts/aJwcgm2nqiZu6zq2S/taking-a-leave-of-absence-from-open-philanthropy-to-work-on"><u>随后，霍尔顿开始直接工作</u></a>，阿霞则全职从事能力建设工作。我于 2022 年 10 月开始进行赠款，很快就全职处理<a href="https://forum.effectivealtruism.org/posts/HPdWWetJbv4z8eJEe/open-phil-is-seeking-applications-from-grantees-impacted-by"><u>FTXFF 救助赠款</u></a>。自 2023 年 1 月下旬左右以来，我一直在主持一个更正常的计划领域。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/to9hsT76Jy9HWJ5dj/new-roles-on-my-team-come-build-open-phil-s-technical-ai#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/to9hsT76Jy9HWJ5dj/new-roles-on-my-team-come-build-open-phil-s-technical-ai<guid ispermalink="false"> to9hsT76Jy9HWJ5dj</guid><dc:creator><![CDATA[Ajeya Cotra]]></dc:creator><pubDate> Thu, 19 Oct 2023 16:48:00 GMT</pubDate></item></channel></rss>