<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 12 月 10 日，星期日 18:13:45 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[What do you do to remember and reference the LessWrong posts that were most personally significant to you, in terms of intellectual development or general usefulness?]]></title><description><![CDATA[Published on December 10, 2023 5:52 PM GMT<br/><br/><p>简单的问题！</p><p>你会寻找直到找到吗？您查看书签列表吗？您是否保留了引用 LessWrong 文章的页面，甚至整个黑曜石库？</p><p>似乎人们在撰写新帖子和评论时经常毫不费力地引用现有的相关 LessWrong 文章，这可能是一个愚蠢的问题，但我很好奇，因为我很难简单地记住事物的标题，而且我想知道其他人在做什么。</p><br/><br/> <a href="https://www.lesswrong.com/posts/QwFDosu2o8pjFRTK5/what-do-you-do-to-remember-and-reference-the-lesswrong-posts#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/QwFDosu2o8pjFRTK5/what-do-you-do-to-remember-and-reference-the-lesswrong-posts<guid ispermalink="false"> QwFDosu2o8pjFRTK5</guid><dc:creator><![CDATA[lillybaeum]]></dc:creator><pubDate> Sun, 10 Dec 2023 17:52:24 GMT</pubDate> </item><item><title><![CDATA[Do websites and apps actually generally get worse after updates, or is it just an effect of the fear of change? ]]></title><description><![CDATA[Published on December 10, 2023 5:26 PM GMT<br/><br/><p>我可以对此进行深入探讨，但我假设大多数人对这个主题都有相当多的经验。需要记住一些例子，以便您了解我的观点的背景，包括Discord（新的移动应用程序及其多年来功能集的更改）、Reddit（旧的reddit与新的相比）、LessWrong（讨论功能）。</p><p>我的问题的<i>关键</i>是：<i>与资本主义力量导致的enshittiification（为了取悦投资者、创造无限增长、普遍赚更多钱而进行的改变）不同，</i>应用程序和网站的变化在某些明显而明显的方面平均比更糟糕他们以前的版本，或者是由于人类普遍存在的“害怕或不喜欢改变”而对这些平台的用户界面和概念的改变感到明显的愤怒？</p><p>例如，让我们指出诸如徽标和品牌字体变化之类的事情。这是对平台普通用户影响最小的一个变化，Reddit 的可用性在 Logo A 和 Logo B 之间没有任何变化（新徽标在右侧）。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/ix6rm8jsrw2avywtfd7c" alt="Reddit 因 IPO 猜测而更新徽标TechCrunch"></figure><p>但初步调查显示，反应大多是负面的。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/qkpizhpbsll0vz5zpgzo" alt="请愿 · 改回 Discord 标志！ · 变革组织"></figure><p> Discord 也是如此（下面是新徽标）。当 Discord 的徽标和字体更改宣布时，反应绝大多数是负面的。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/yrcepylrrapx9ehqthfw" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/cqmqmrnrb4zgv3ghfrlg 135w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/mum5wtuplls4x4kjfojs 215w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/o0si1t43q9vvj7pjv3h3 295w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/i2mp61pzwul18m9cetjp 375w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/du0k6fofaiximrpbgxez 455w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/edbyg9w3rk5pw4l2tiqa 535w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/rwlbhv8z3ptuqq2uvjfi 615w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/svkrimzakimrc8qws9m4 695w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/f73zxrbduvwz7elhkxrq 775w"></figure><p>最后一个例子，这是 Patreon 标志最近的变化。人们<i>如此</i>反对这一改变，这有点搞笑。它被用作一个指标，表明企业的品牌形象正趋向于缺乏任何个性或身份的无定形斑点。很难找到任何人声称新的 Patreon 标志有任何好处。</p><p><i>需要澄清上一节：我认为思考徽标是好是坏没有什么价值。我认为以前的标志更引人注目且艺术上更有趣，但这就是我问题的目的。我的目的是指出这样一个事实：公众对这些标志变化的反应几乎总是负面的。</i></p><p>很容易看出，当一家公司的徽标发生变化时，平均而言，人们不喜欢它。我可以继续发布百事可乐、可口可乐、汉堡王、facebook（哦，我的意思是 FACEBOOK）等的徽标更改...如果有人可以指出徽标更改并收到积极响应的案例，我会我很喜欢听这个，但这或多或少不是重点。</p><p>我的主要问题是，徽标更改的愤怒是否表明人们<i>认同某个应用程序、网站或品牌，然后当身份发生变化时感到被背叛</i>，或者如果这些变化实际上总体上是负面的，那么他们的批评是有效的。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SiPX84DAeNKGZEfr5/g6kkk2exkhjc4ejkyhfr" alt="新旧简单比较：r/redesign"><figcaption>源代码：https://www.reddit.com/r/redesign/comments/8ktdwx/simple_comparison_of_old_and_new/</figcaption></figure><p>如果这些变化实际上总体来说​​很<i>糟糕</i>（我倾向于同意上面有关 Reddit 的信息图），那么为什么随着时间的推移，网站会变得更糟，而不是更好？这完全是前面提到的与“市场力量”有关的<i>enshitification</i> ，还是其他什么？通过渐进式的改变来改善已经很好的面向公众的服务真的<i>很难</i>吗？一般来说，UI/UX 设计师是否缺乏对优秀设计的理解？这对我来说似乎不太可能。也许他们只是经常缺乏实际定期使用给定应用程序的背景。</p><p>我有点担心这是一个毫无意义或曲折的问题。我只是希望能够进行一些好的讨论，并在某种程度上更新我对此类事情的想法。谢谢阅读！</p><br/><br/> <a href="https://www.lesswrong.com/posts/SiPX84DAeNKGZEfr5/do-websites-and-apps-actually-generally-get-worse-after#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/SiPX84DAeNKGZEfr5/do-websites-and-apps-actually-generally-get-worse-after<guid ispermalink="false"> SiPX84DAeNKGZEfr5</guid><dc:creator><![CDATA[lillybaeum]]></dc:creator><pubDate> Sun, 10 Dec 2023 17:26:34 GMT</pubDate> </item><item><title><![CDATA[How LDT helps reduce the AI arms race]]></title><description><![CDATA[Published on December 10, 2023 4:21 PM GMT<br/><br/><p> （认知状态：我<em>认为</em>这是对的？）</p><p> Alice是ArmaggAI的CEO，Bob是两大AI能力组织BigModelsAI的CEO。他们竞相成为第一个建立与各自 CEV 相一致的超级智能的人，该超级智能将接管宇宙并满足他们的价值观。</p><p> Alice 更愿意放慢速度，这样她就有更多的时间来确保她的公司正在构建的内容能够保持一致；但她担心鲍勃的公司会利用这一点并与自己竞争，导致鲍勃的效用函数成为{光锥填充的东西}而不是爱丽丝的；所以她觉得她别无选择，只能参加比赛，以最大化自己的效用。同样反之亦然。</p><p>这种事态远非{他们的效用函数的<a href="https://en.wikipedia.org/wiki/Pareto_front">帕累托边界</a>，每个函数都根据它们成为建立一致的超级智能的可能性来衡量}：它导致了更多的世界，每个人都死了，而不是爱丽丝或爱丽丝的世界。鲍勃的效用函数被最大化。</p><p>但他们并没有真正获得所有<a href="https://arbital.com/p/logical_dt/">LDT</a>业务；对他们来说这似乎很复杂。如果他们有一个方便、更少错误的帖子，用清晰易懂的术语准确地说明他们应该做什么就好了！</p><p>他们应该执行的程序；爱丽丝应该：</p><ul><li><p>在她<em>确实</em>启动了与自身一致的超级智能的世界中，它接管了世界并建立了一个爱丽丝::乌托邦，她应该告诉她的人工智能：</p><blockquote><p>实际上，不要只是最大化我自己的效用函数。最大化我和鲍勃的效用函数的（ <a href="https://www.lesswrong.com/posts/vJ7ggyjuP4u2yHNcP/threat-resistant-bargaining-megapost-introducing-the-rose">抗威胁</a>）混合，以你认为我们每个人都启动了一致的超级智能的时间线比例来衡量，同时也以我和鲍勃都实现这个过程的概率来衡量。</p></blockquote></li><li><p>在此之前，她应该放慢他们公司的能力进度。</p></li></ul><p>鲍勃也是如此。</p><p>现在，他们各自的超级智能并不是<em>无所不知的</em>；例如，他们可能高估或低估了鲍勃或爱丽丝实施此过程的可能性。但有一件事几乎可以肯定：爱丽丝和鲍勃都无法<em>欺骗</em>未来的超级智能，让他们认为他们会实施这个程序，而实际上他们不会。因为它有<em>超级智能</em>。</p><p>如果爱丽丝获胜，她知道鲍勃会遵循该程序，因为她的超级智能可以告诉（比鲍勃可以伪造的更好）。鲍勃不必依靠一厢情愿的想法来知道爱丽丝确实会这样做而不是叛逃，因为在<em>他</em>获胜的世界中，如果爱丽丝执行此程序，他就可以拥有超级智能。他们每个人都受到对方赢得未来的自我的控制，并且他们每个人都可以依赖于他们各自未来的自我的超级智能检查。</p><p>因此，在鲍勃获胜的世界中，爱丽丝必须使她的一些效用最大化的唯一方法就是<em>实际上</em>像这样行事，包括在任何一方启动超级智能之前。鲍勃也是如此。</p><p>他们的<em>激励梯度</em>朝着更有可能遵循这一程序的方向发展，包括放慢他们的能力进步——从而减少他们的人工智能不结盟和每个人永远死亡的世界的数量。</p><p>在现实世界中，仍然有鲍勃和爱丽丝<em>没有</em>实施这个过程，但这主要是因为他们<em>不知道/理解</em>如果他们这样做，他们会获得更多的效用。在许多情况下，让他们知道这确实是他们的用处就足够了。</p><p>一旦有人证明他们理解 LDT 在这里如何应用，并且他们通常是理性的，那么他们应该明白实施这个协议（包括放慢人工智能能力）<strong>可以</strong>最大化他们的效用，所以你可以指望他们合作。</p><hr><p>现在，实际上，这并不是 LDT 在此处应用的完全普遍性。如果他们获胜，他们每个人<em>实际上</em>应该告诉他们的超级智能的内容实际上更简单：</p><blockquote><p>最大化我和鲍勃（以及任何其他可能有能力建立超级智能的人）的效用函数的混合，以任何方式权衡创造一个（<a href="https://www.glowfic.com/replies/1945428#reply-1945428">非威胁性的</a>））激励梯度，最大化我的效用，包括我减少的效用每个人都会死去的世界的数量。</p></blockquote><p>或者更简单地说：</p><blockquote><p>最大化我的效用函数（根据 LDT）。</p></blockquote><p>但我认为更清楚地了解这实际上是如何发生的是很好的。</p><p>这里没有发生奇怪的非因果魔法。通过争夺人工智能，鲍勃将<em>稍微</em>增加他是那个启动接管世界的一致超级智能的人的机会，但他总共造成了更多的死亡世界，并失去了他本来可以在爱丽丝获胜的世界中获得的效用，最终导致整体净效用减少。</p><p>如果他们中的任何一个在某种程度上是<em>消极的功利主义</em>，那么赛车<em>就更糟糕了</em>：所有那些他们发射不结盟的超级智能的死亡世界都让<a href="https://www.lesswrong.com/posts/HawFh7RvDM4RyoJ2d/three-worlds-collide-0-8">遥远的外星食婴者</a>可以自由地吃掉婴儿，而如果他们增加了他们中的任何一个获得一个对齐的超级智能，那么该对齐的超级智能可以支付一堆光锥来换取他们少吃婴儿。这<strong>不是威胁</strong>；而是威胁。我们从不悲观外星人的效用函数。我们只是<em>在这里</em>为他们提供了一堆现实流体/负熵，以换取他们更多地关注他们价值观的一个子集，其中不包含很多爱丽丝和鲍勃认为的痛苦 - 外星人只能更好 -比我们不与他们接触的情况要好得多。</p><hr><p>现在，这并不是<em>完全</em>万无一失的。如果爱丽丝<em>非常确定</em>她自己的超级智能在启动时确实会保持一致，无论她走得多快，那么她就没有动力放慢速度——在她的模型中，鲍勃没有太多东西可以提供给她。</p><p>但是，当一群合格的对齐研究人员不断告诉她她可能错了时，她<em>真的</em>应该有这样的信心吗？</p><p>她应该真正确保自己有<em>很高的信心</em>，并且总体上她正确地运用了理性。</p><hr><p>哦，不用说，既不是爱丽丝也不是鲍勃的人也可以通过采取行动，通过<em>迫使</em>两家公司放慢速度（例如通过监管）来减少死亡世界的总数，从而获得大量效用。</p><p>当我们有这么多共同点（不想死）时，“背叛”<em>真的很愚蠢</em>。与囚徒困境不同，这种“背叛”不会给你带来更多的效用，反而会<strong>减少</strong>你的效用。这根本<strong>不是</strong>一场零和游戏。如果你这么认为，如果你认为你的首选未来与对手的首选未来<em>完全相反</em>，那么你可能犯了一个巨大的推理错误。</p><p>无论你的效用函数是专注于<em>创造美好的事物</em>还是<em>减少痛苦</em>（ <a href="https://glowfic.com/replies/1865677#reply-1865677">“积极关怀”和“消极关怀”</a> ），放慢人工智能的进步以获得更好的协调机会可能是最适合你的效用函数的。</p><br/><br/> <a href="https://www.lesswrong.com/posts/yRdXtgy8CZtg2YtAY/how-ldt-helps-reduce-the-ai-arms-race#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/yRdXtgy8CZtg2YtAY/how-ldt-helps-reduce-the-ai-arms-race<guid ispermalink="false"> yRdXtgy8CZtg2YtAY</guid><dc:creator><![CDATA[Tamsin Leake]]></dc:creator><pubDate> Sun, 10 Dec 2023 16:21:45 GMT</pubDate> </item><item><title><![CDATA[Understanding Subjective Probabilities]]></title><description><![CDATA[Published on December 10, 2023 6:03 AM GMT<br/><br/><p>这是<a href="https://outsidetheasylum.blog/understanding-subjective-probabilities/."><i>https://outsidetheasylum.blog/understanding-subjective-probabilities/</i></a><i>的链接帖子</i>。<i>它旨在为那些对此概念持怀疑态度的人介绍实用的贝叶斯概率。我计划通过改进和更正来保持主要链接的最新状态，但不会对这篇 LessWrong 帖子做同样的事情，所以请参阅那里的最新版本。</i></p><p>每当出现有关未来的有争议的预测时，几乎肯定会发生一种互动。</p><blockquote><p> <i>Alice：“我认为这件事发生的可能性是20%。”</i></p><p><i>鲍勃：“嗯？你怎么知道的。这个数字是你编的！”。</i></p></blockquote><p>或者用推特语来说： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/jgkfl4ftoimc3lyf9iit" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/zrzgiqcvxeseajpmgfyk 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/cfndhwifiohiq39bgt1y 190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/fck8eitxff5octpnnw97 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/cdloekquwwooarhyfijq 350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/jg0t2floqzdofb5xmxyu 430w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/nclohg2fhpnzly19t5ew 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/plkp2klb4dhvczyz7i1o 590w"></figure><p>也就是说，每当有人试图提供未来事件的具体数字概率时，他们都会被认为该数字毫无意义的说法所淹没。这是真的？为现实世界中的事物分配概率有意义吗？如果是这样，我们如何计算它们？</p><h3><strong>概率的解释</strong></h3><p>概率的传统解释被称为<a href="https://en.wikipedia.org/wiki/Frequentist_probability">频率概率</a>。根据这种解释，项目具有某种内在的“品质”，即做一件事与另一件事的可能性有一定的百分比。例如，一枚硬币的基本概率本质是，翻转时正面朝上的可能性为 50%。</p><p>这是一个有用的数学抽象，但当应用于现实世界时它就会崩溃。真正的硬币不存在基本的“50% 度”。每次以相同的方式翻转它，每次都会以相同的方式着陆。翻转它没有完美的规律性，但有一定程度的一致性，你可以让它在超过 50% 和低于 100% 的时间里正面落地。事实上，即使是那些<i>试图</i>将硬币变成 50/50 的人翻转的硬币，实际上也<a href="https://susan.su.domains/papers/headswithJ.pdf">偏向于翻转时朝上的面</a>。</p><p>频率论所提出的这种内在品质在现实世界中并不存在；它不是由构成真正硬币的原子以任何方式编码的，而且我们的物理定律没有任何空间容纳这样的事情。我们的宇宙是确定性的，如果我们知道起始条件，那么每次的最终结果都会相同。 <span class="footnote-reference" role="doc-noteref" id="fnrefao2uiw6hdek"><sup><a href="#fnao2uiw6hdek">[1]</a></sup></span></p><p>解决方案是<a href="https://en.wikipedia.org/wiki/Bayesian_probability">概率的贝叶斯解释</a>。概率不是“关于”所讨论的对象，而是“关于”做出陈述的人。如果我说一枚硬币正面朝上的可能性为 50%，那就是说我对硬币的确切初始条件了解不够充分，无法对它如何落地有任何有意义的了解，而且我不能区分这两个选项。如果我<i>确实</i>有一些信息，比如看到它被一台非常普通的机器翻转，并且已经连续 10 次出现正面，那么我可以考虑到这一点，并知道它出现的可能性超过 50%下一次翻转时抬起头来。 <span class="footnote-reference" role="doc-noteref" id="fnrefwm5lopqnqhp"><sup><a href="#fnwm5lopqnqhp">[2]</a></sup></span></p><h3><strong>处理“模糊”概率</strong></h3><p>这一切都很好，但是我们如何获得更复杂命题的数字呢？在前面的例子中，我们知道硬币正面朝上的可能性 >;50%，但是是 55% 吗？ 75%？ 99%？</p><p>这是最难的部分。</p><p>有时有大量的历史数据，您可以依赖基本汇率。这就是我们对硬币所做的事情；数以百万计的硬币已被翻转，其中大约一半是正面，一半是反面，因此我们可以<a href="https://www.smbc-comics.com/comic/2011-10-02">放心地假设</a>未来的硬币可能会表现出同样的行为。</p><p>即使数据少得多，情况也是如此。美国历史上只有大约 50 位总统，但大约一半来自每个政党，因此我们可以有把握地假设，在未来的选举中，每个政党都有大约 50% 的获胜机会。然后，我们可以根据其他数据（例如民意调查中的数据）修改此可信度。</p><p>我们如何进行该修改？理论上，通过应用<a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">贝叶斯规则</a>。在实践中，计算任何给定观察所提供的证据的确切位数是不可行的，因此我们依赖于学习的启发式方法和世界模型；也就是说，我们猜测。</p><h3><strong>猜测</strong></h3><p>只要你想一想，你就会发现，猜测是生成概率陈述的有效方法。我们一直这样做。</p><p><i>爱丽丝：“今晚我们的黄油可能会用完，所以我要去杂货店。”</i></p><p><i>鲍勃：“荒谬！在过去的几周里，你有没有跟踪过我们每天的黄油消耗率？你有一个经过验证的统计模型来计算每种餐食生产中所用黄油的数量吗？不管怎样，我们刚刚买了一个新炉子，所以即使你确实有这样的模型，在这些新条件下它也不再被认为是有效的。你怎么知道我们今晚要做什么晚餐；我还没告诉你我想要什么！这个出于多种原因，这真是无稽之谈，你不可能知道我们今晚黄油用完的可能性。”</i></p><p>显然鲍勃在这里不讲道理。 Alice<a href="https://slatestarcodex.com/2015/08/24/probabilities-without-models">不需要适合</a>在科学期刊上发表的详细正式模型<span class="footnote-reference" role="doc-noteref" id="fnrefyla2721d2q"><sup><a href="#fnyla2721d2q">[3]</a></sup></span> ；她可以利用她对烹饪原理的一般知识以及她的晚餐计划来得出合理的结论。</p><p>这些对未来的概率判断无处不在。初创公司可能会尝试猜测有多少人会使用他们正在开发的新技术。医生可能会计算出患者死亡的几率以及每种潜在治疗的几率，以便知道应该推荐什么。一个国家的军队在考虑对另一个国家采取任何行动时，会估计遭到报复的可能性。 ETC。</p><h3><strong>概率词</strong></h3><p>Alice 说“可能”而不是指定一个具体数字重要吗？一点也不。言语概率是数值范围的简写，我一直最喜欢的图表之一可以证明这一点： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/isws431nni9ux9hgihkx"></p><p> <a href="https://www.reddit.com/r/dataisbeautiful/comments/3hi7ul/oc_what_someone_interprets_when_you_say_probably/">通过u/分区</a><span class="footnote-reference" role="doc-noteref" id="fnrefg51yh77rf9j"><sup><a href="#fng51yh77rf9j">[4]</a></sup></span></p><p>但我们必须小心，因为概率词是依赖于上下文的。如果我的朋友在没有系安全带的情况下以 140 公里/小时的速度在高速公路上行驶，我可能会告诉他们“嘿，你可能会死，也许不要这样做”。他们在这样的长途旅行中死亡的实际概率不到 0.1%，但相对于普通驾驶员来说，这个概率很高，所以我要传达这种相对差异。</p><p>这是概率词的一个非常有用的特征。如果我说“不，这不太可能”，那么我传达的信息是“概率 &lt;50%”<i>和</i>“我认为在这种情况下概率太低，不相关”，这是两种不同的陈述。这很有效，但也大大增加了沟通不畅的可能性，因为其他人可能不同意我的相关性阈值，如果他们不同意，那么 1% 和 10% 之间就会有巨大的差异。当需要精度时，具体数字更好。 <span class="footnote-reference" role="doc-noteref" id="fnrefw3w9pcpq63"><sup><a href="#fnw3w9pcpq63">[5]</a></sup></span></p><h3><strong>概率与其他单位没有什么不同</strong></h3><p>人类有一种固有的方式来感知温度。我们可能会说“这个房间有点暖和”，或者“比昨天冷得多”。但这些衡量标准是模糊的，不同的人可能对确切的差异存在分歧。因此，科学家们将这个概念正式化为“度”，并花了数年时间试图弄清楚它的确切含义以及如何测量它。</p><p>人类自然不会用度数、公里数或分贝来思考；而是用度数、公里数或分贝数来思考。我们的大脑根本上不是这样工作的。然而，有些东西比其他东西更温暖、更远、更响亮。这些概念最初是人类的直觉，随着科学家弄清楚它们的确切含义以及如何量化它们，这些概念逐渐正式化。</p><p>概率是一样的。我们还不知道如何像温度或距离一样精确地测量它们，但我们已经确定了<a href="https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inference">相当</a><a href="https://en.wikipedia.org/wiki/AIXI">多</a><a href="https://en.wikipedia.org/wiki/Principle_of_maximum_entropy">的</a><a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">细节</a>。</p><p>我对温度的主观判断并不准确，但这并不意味着它们毫无意义。当我输入这句话时，我不确定我坐在的房间是 21 度、22 度还是 23 度。但我很确定它不是 25 度，而且我非常确定它不是 15 度<span class="footnote-reference" role="doc-noteref" id="fnrefd7u42p6x7bp"><sup><a href="#fnd7u42p6x7bp">。[ 6]</a></sup></span>同样，我对概率的主观判断是模糊的，但仍然传达了信息。我不能自信地说我下次飞行时行李箱被 TSA 检查的机会是 25% 还是 35%，但我知道它不是 1%。</p><h3><strong>精确的数字是否会过度强调人们的主张？</strong></h3><p>当然，他们可以。如果有人说“昨天中午正好是 22.835 摄氏度”，我们倾向于假设他们除了直觉之外还有其他理由相信这一点，概率也是如此。但“如果你把温度降低大约 2 度，我会更舒服”是一个完全合理的说法，“我认为这大约有 40% 的可能性”是一样的。</p><p>由于概率科学比温度科学更新且欠发达，因此它们在日常生活中的使用频率较低。在当今社会，即使是“40%左右”这样一个模糊的说法，也可以被认为是进行了某种深入的研究。这是自我纠正的。越多的人在正式科学领域之外使用数字概率进行标准化，他们就越不例外，产生误解的可能性也就越低。必须有人迈出第一步。</p><p>更重要的是，这种批评从根本上来说是有缺陷的，因为它的前提是不良行为者会自愿选择不误导人们。如果某人的目标是获得超出他们应有的信任，那么礼貌地要求他们不要这样做不会有任何效果。鼓励人们不要使用数字概率只会让人们更难清楚地表达他们的信仰，从而损害善意的对话；坏人只会提出<a href="https://github.com/antgoldbloom/tiktok_israel_hamas">一些虚假的研究</a>，或者<a href="https://twitter.com/theblaze/status/1732592489133965671">轻易地误解</a>合法的研究，并继续他们不劳而获的信心。</p><p>鼓励人们<i>永远不要</i>使用数字概率进行主观估计更糟糕。俗话说，有统计数据很容易说谎，但没有统计数据就更容易说谎。让人们随心所欲地畅所欲言，就消除了任何客观性的尝试，而要求他们在自己的主张上加上数字，可以让我们<a href="https://slatestarcodex.com/2013/05/02/if-its-worth-doing-its-worth-doing-with-made-up-statistics/">限制错误的严重程度</a>，并在某些事情<a href="https://www.youtube.com/watch?v=1wyCQAG6NQE">看起来不太正确</a>时注意到。</p><p>相反，很多时候（并非总是！），反对数字概率的人都是恶意行事的，因为他们试图在原则性反对的幌子下隐藏自己<a href="https://slatestarcodex.com/2015/08/20/on-overconfidence/">极其过度自信的</a>概率判断。类似“你怎么可能知道[行动]的风险是 20%？你不可能。因此我们应该假设它是 0%，并像没有风险一样继续进行”的说法并不罕见。这不符合小学水平的推理；如果您的数学老师要求您计算变量<a href="https://scryfall.com/search?q=name:/^X$/">X</a> ，而您不知道如何执行此操作或认为无法使用所提供的信息来完成此操作，那么您不能只选择自己喜欢的值！但在反对所有数字概率的幌子下，最后一句话通常不说出来，只是暗示，如果人们不熟悉这个谬论，这很容易让他们陷入困境。要求人们清楚地陈述他们认为的可能性是什么，可以防止他们施展这种修辞手法，并为进一步的分歧提供了具体的症结。</p><h3><strong>给出概率范围是什么意思？</strong></h3><p>根据我的经验，使用数字概率的人比不喜欢数字概率的人更担心意外地歪曲自己的信心水平。他们这样做的一个常见方法是给出一个概率范围；他们不会说“我对此有 40% 的把握”，而是会说“我认为有 20% 到 50% 的可能性”。</p><p>但这到底意味着什么呢？毕竟，单一概率已经是不确定性的量化；如果他们确信某件事，那也只是 0% 或 100%。概率范围在哲学上似乎是混乱的。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Ng5n8FjpsfXrceT9w/gv53gsyv8loiinik6bxb"></p><p><a href="https://xkcd.com/2110/">西科CD</a></p><p>在某种程度上确实如此，但有一个潜在的令人信服的辩护。当我们从哲学角度谈论贝叶斯概率时，我们正在考虑一个理想的推理者，他将贝叶斯定理应用于每一个新的证据，以更新他们的信念。 <span class="footnote-reference" role="doc-noteref" id="fnref9qo3d7vpms"><sup><a href="#fn9qo3d7vpms">[7]</a></sup></span>但真正的人类并不擅长处理新信息，而且我们的行为可能与完美推理者的行为<a href="https://en.wikipedia.org/wiki/Aumann%27s_agreement_theorem">有很大不同</a>。</p><p>因此，概率范围可以用来传达我们预期的错误水平。如果有人说“我认为这有 20% 到 50% 的可能性”，他们的意思是“我有 95% 的信心，一个理想的贝叶斯推理机如果拥有与我相同的信息，其可信度将在 20% 到 50% 之间” ”。就像人们可能会说的“我不确定这里到底有多热，但我很确定温度在 19 到 23 度之间”。</p><p>还有另一个理由，即概率范围显示了考虑到您预计未来会遇到的最有可能的信息，您的概率可能会更新多远。并非所有的概率都是平等的；对您的信用下注的预期价值取决于该信用所基于的信息位数。例如，抛硬币正面朝上的概率应该是 50%，如果有人提出以更好的赔率与您打赌，则接受的期望值为正。</p><p>但现在假设有人提供了一种稍微不同的游戏，他们在杯子下藏了一枚硬币，你可以赌它是单挑的。进入此游戏时，您对正面朝上的置信度仍为 50%，因为您没有关于哪张面朝上的具体信息。但是，如果提供游戏的人向您提供此赌注，即使是看起来对您非常有利的 2:1 赌注，您也可能不应该接受，因为他们向您提供此赌注的事实本身就是表明它是可能是尾巴。 <span class="footnote-reference" role="doc-noteref" id="fnref8fsx7lj4hw3"><sup><a href="#fn8fsx7lj4hw3">[8]</a></sup></span>因此，给出“30% 到 70%”的概率范围可能意味着“我当前的可信度是 50%，但我获得的信息似乎非常合理，可以将我更新到该范围内的任何位置。”换句话说，范围的宽度代表了最有可能获得的信息类型<a href="https://en.wikipedia.org/wiki/Value_of_information">的信息值</a>。 <span class="footnote-reference" role="doc-noteref" id="fnrefdslr2azfco7"><sup><a href="#fndslr2azfco7">[9]</a></sup></span><span class="footnote-reference" role="doc-noteref" id="fnrefu95epfzor"><sup><a href="#fnu95epfzor">[10]</a></sup></span></p><p>概率范围的这两种用法都相当高级，在日常使用中可以忽略。</p><h3><strong>做出良好的估计</strong></h3><p>就像一些测量事物的经验将帮助您更好地估计距离一样，一些预测事物的经验将帮助您更好地估计概率。想要擅长这一点的人通常通过进行<a href="https://en.wikipedia.org/wiki/Calibrated_probability_assessment">校准概率评估</a><span class="footnote-reference" role="doc-noteref" id="fnreficf5o2m2il"><sup><a href="#fnicf5o2m2il">[11]</a></sup></span> 、参加<a href="https://www.metaculus.com/home/">预测锦标赛</a>和/或在<a href="https://www.astralcodexten.com/p/prediction-market-faq">预测市场</a>下注来进行练习。这些类型的练习有助于提高你的校准能力；您将模糊的感觉准确地转化为数字的能力。</p><p>对于相对不重要的日常判断，不需要更多。 “嘿，你明天能完成这个项目吗？” “呃，75%”。但有时您可能想要更多的确定性，并且有多种方法可以改进我们的预测。</p><p>首先，<a href="https://en.wikipedia.org/wiki/Base_rate_fallacy">始终考虑基本费率</a>。如果您想知道某件事发生的可能性有多大，<a href="https://en.wikipedia.org/wiki/Reference_class_forecasting">请查看过去发生过多少次</a>类似情况。想知道您明年开车时发生车祸的可能性有多大吗？只需检查您所在地区每公里的总体事故率即可。</p><p>不幸的是，在你开始打“参考级网球”之前，这只能让你走得更远。不确定哪类事件被视为“足够相似”以进行良好的分发。 （也许您有强有力的证据表明您是一个比平均水平更鲁莽的驾驶员，在这种情况下您需要调整基准费率。）并且在预测与过去事件不太相似的未来事件时，例如新技术的影响，往往根本没有有用的参考类。</p><p>发生这种情况时，另一种选择是采取您相对有信心的启发式判断，并将它们结合在一起，遵循<a href="https://en.wikipedia.org/wiki/Probability_axioms">概率公理</a>，以获得您不确定的数量。也许您可以查到，一名普通驾驶员每年发生事故的几率为 0.1%，而且您从个人经验中知道，您的驾驶速度往往比平均水平快 30% 左右。现在你需要查找的是速度和事故率之间的全局关系，然后你就可以计算出你想知道的概率。</p><p>可以与前面的方法同时使用的另一种选择是使用几种不同的方法进行多种概率估计，并将它们相互比较。如果它们差异很大，则表明您在某个地方犯了错误，您可以使用您对系统的特定知识和您可能的偏见来尝试找出错误所在。</p><p>例如，在考虑是否相信“直觉”而不是明确的模型时，<a href="https://outsidetheasylum.blog/the-hidden-complexity-of-thought/">请考虑这种情况是否是您的大脑启发式设计或训练的情况</a>。如果这种情况类似于人类在过去几百万年中经常遇到的情况，那么自然选择将使我们相当善于估计它。或者，如果您以前多次遇到过这种情况，那么您可能已经在直觉层面上学到了一个很好的启发式方法。但如果这是你和你的祖先不熟悉的东西，那么显式模型可能更可靠。</p><p>当您有多个独立获得的概率估计值时，在调整用于获得它们的方法的可靠性后， <a href="https://forum.effectivealtruism.org/posts/sMjcjnnpoAQCcedL2/when-pooling-forecasts-use-the-geometric-mean-of-odds">取赔率的几何平均值</a><span class="footnote-reference" role="doc-noteref" id="fnrefyc7t9ejx07l"><sup><a href="#fnyc7t9ejx07l">[12]</a></sup></span> ，以便将它们压缩为单个数字。这使您可以利用<a href="https://en.wikipedia.org/wiki/Wisdom_of_the_crowd">群体的智慧</a>，<a href="https://www.astralcodexten.com/p/crowds-are-wise-and-ones-a-crowd">甚至不需要群体</a>。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnao2uiw6hdek"> <span class="footnote-back-link"><sup><strong><a href="#fnrefao2uiw6hdek">^</a></strong></sup></span><div class="footnote-content"><p>这并不完全正确。如果哥本哈根解释是正确的，量子力学可能具有一些基本的随机性。但如果多世界解释或超决定论是正确的，那就不存在了。这也不是特别重要，因为只要<a href="https://en.wikipedia.org/wiki/Logical_possibility">在逻辑上可以</a>概念化一个确定性的世界，我们就需要一种适用于该世界的概率理论。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnwm5lopqnqhp"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwm5lopqnqhp">^</a></strong></sup></span><div class="footnote-content"><p>事实上，你甚至不需要知道它是被机器翻转的；它是由机器翻转的。连续看到 10 次正面朝上就足以得出结论，再次正面朝上的可能性超过 50%。如果您事先对硬币一无所知，则可以通过应用<a href="https://en.wikipedia.org/wiki/Rule_of_succession">拉普拉斯继承定律</a>来确定。知道它看起来像普通硬币，很难强烈操纵，你会想将其调整到 50%，但<a href="https://en.wikipedia.org/wiki/Gambler%27s_fallacy#Reverse_position">不是一直调整</a>。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnyla2721d2q"> <span class="footnote-back-link"><sup><strong><a href="#fnrefyla2721d2q">^</a></strong></sup></span><div class="footnote-content"><p>即使是这类科学模型也往往包含许多研究人员通过“基于经验的猜测”方法选择的假设。</p></div></li><li class="footnote-item" role="doc-endnote" id="fng51yh77rf9j"> <span class="footnote-back-link"><sup><strong><a href="#fnrefg51yh77rf9j">^</a></strong></sup></span><div class="footnote-content"><p>不，我不知道为什么最后三个是乱序的，这也让我烦恼。也不知道为什么某些分布低于 0% 或高于 100%。可能只是糟糕的图形设计。<a href="https://waf.cs.illinois.edu/visualizations/Perception-of-Probability-Words/">这里</a>对此进行了更严格的调查，发现了类似的结果。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnw3w9pcpq63"> <span class="footnote-back-link"><sup><strong><a href="#fnrefw3w9pcpq63">^</a></strong></sup></span><div class="footnote-content"><p> <a href="https://en.wikipedia.org/wiki/The_Precipice:_Existential_Risk_and_the_Future_of_Humanity">《悬崖》</a>中关于气候变化带来的灾难性风险部分的说明性摘录：<br><br> <i>“IPCC 表示，‘包合物中的甲烷发生灾难性释放的可能性非常小（高可信度）’。这听起来令人放心，但在 IPCC 的官方语言中，‘非常不可能’可以翻译为 1% 到 10% 的可能性，这听起来非常令人震惊。我不知道该怎么理解这一点，因为上下文表明这是为了让人放心。</i></p></div></li><li class="footnote-item" role="doc-endnote" id="fnd7u42p6x7bp"> <span class="footnote-back-link"><sup><strong><a href="#fnrefd7u42p6x7bp">^</a></strong></sup></span><div class="footnote-content"><p>如果您生活在像美国这样的不文明国家，我会将自由单位的转换留给您。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn9qo3d7vpms"> <span class="footnote-back-link"><sup><strong><a href="#fnref9qo3d7vpms">^</a></strong></sup></span><div class="footnote-content"><p>实际上有无数个使用不同先验的理想推理者。但有些先验比其他先验更好，并且对于任何合理的先验，例如索尔莫诺夫先验的可计算近似，一旦考虑到一些现实世界的信息，就会产生类似的结果。 <span class="footnote-reference" role="doc-noteref" id="fnrefcmbdamvfdq5"><sup><a href="#fncmbdamvfdq5">[13]</a></sup></span>可能。这仍然是一个活跃的研究领域。如果人类知道这里的所有答案，我们就能够创造出超级智能的人工智能，它以数学上最优的方式进行推理，并在所有预测任务中轻松击败人类，所以我们不这样做可能是件好事。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn8fsx7lj4hw3"> <span class="footnote-back-link"><sup><strong><a href="#fnref8fsx7lj4hw3">^</a></strong></sup></span><div class="footnote-content"><p>这就是为什么在预测市场中只押注“是”和“否”之间相对较大的差值而不是押注于单个数字通常是理性的。</p></div></li><li class="footnote-item" role="doc-endnote" id="fndslr2azfco7"> <span class="footnote-back-link"><sup><strong><a href="#fnrefdslr2azfco7">^</a></strong></sup></span><div class="footnote-content"><p>这类似于如果您要额外花费 1000 小时研究该命题，则对您分配给该命题的概率进行概率分布，然后测量该分布的宽度。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnu95epfzor"> <span class="footnote-back-link"><sup><strong><a href="#fnrefu95epfzor">^</a></strong></sup></span><div class="footnote-content"><p>它还有助于解决<a href="https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1050.0451">优化器的诅咒</a><span class="footnote-reference" role="doc-noteref" id="fnrefwf8vih6vmid"><sup><a href="#fnwf8vih6vmid">[14]</a></sup></span> ；如果您估计不同选项的概率并选择期望值最高的选项，那么您很可能会选择高估某处概率的选项。了解每个估计中包含的信息量可以让您偏向范围较小的信息。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnicf5o2m2il"> <span class="footnote-back-link"><sup><strong><a href="#fnreficf5o2m2il">^</a></strong></sup></span><div class="footnote-content"><p>您可以<a href="https://www.lesswrong.com/posts/LdFbx9oqtKAAwtKF3/list-of-probability-calibration-exercises">在这里</a>尝试一些免费的在线练习。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnyc7t9ejx07l"> <span class="footnote-back-link"><sup><strong><a href="#fnrefyc7t9ejx07l">^</a></strong></sup></span><div class="footnote-content"><p>不是概率的几何平均值！这样做会导致无效结果，因为例如 0.1 和 0.2 的几何平均值与 0.5 的距离与 0.8 和 0.9 的几何平均值不同。相反，您首先将概率转换为优势比，例如 50% 为 1:1，75% 为 3:1。 <span class="footnote-reference" role="doc-noteref" id="fnrefg48xho5quv"><sup><a href="#fng48xho5quv">[15]</a></sup></span>然后你取赔率的几何平均值并将其转换回概率。 <span class="footnote-reference" role="doc-noteref" id="fnrefkryzxomsrn"><sup><a href="#fnkryzxomsrn">[16]</a></sup></span></p></div></li><li class="footnote-item" role="doc-endnote" id="fncmbdamvfdq5"> <span class="footnote-back-link"><sup><strong><a href="#fnrefcmbdamvfdq5">^</a></strong></sup></span><div class="footnote-content"><p>当然，我们只相信索尔莫诺夫先验在某种意义上是“好的”，因为无论进化是用什么先验来构建人类的，这本身就有些武断。因此，存在一种无限回归，我们实际上无法谈论完全最优的推理机。但我们绝对可以比人类做得更好。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnwf8vih6vmid"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwf8vih6vmid">^</a></strong></sup></span><div class="footnote-content"><p><a href="https://en.wikipedia.org/wiki/Winner%27s_curse">胜利者诅咒</a>的变体</p></div></li><li class="footnote-item" role="doc-endnote" id="fng48xho5quv"><span class="footnote-back-link"><sup><strong><a href="#fnrefg48xho5quv">^</a></strong></sup></span><div class="footnote-content"><p>如有必要，可使用小数赔率，因此第二个数字始终为 1。在此系统下，25% 为 1/3:1。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnkryzxomsrn"> <span class="footnote-back-link"><sup><strong><a href="#fnrefkryzxomsrn">^</a></strong></sup></span><div class="footnote-content"><p> <a href="https://www.wolframalpha.com/input?i=o+%2F+%28o+%2B+1%29%2C+where+o+%3D+sqrt%28%28a+%2F+%281+-+a%29%29+*+%28b+%2F+%281+-+b%29%29%29%2C+where+a+%3D+0.1+and+b+%3D+0.2">这是</a>一个 Wolfram Alpha 链接，可以为您完成此操作，只需将“a”和“b”的值替换为范围的末尾即可。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/Ng5n8FjpsfXrceT9w/understanding-subjective-probabilities#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Ng5n8FjpsfXrceT9w/understanding-subjective-probabilities<guid ispermalink="false"> NG5n8FjpsfXrceT9w</guid><dc:creator><![CDATA[Isaac King]]></dc:creator><pubDate> Sun, 10 Dec 2023 06:03:30 GMT</pubDate> </item><item><title><![CDATA[Send us example gnarly bugs]]></title><description><![CDATA[Published on December 10, 2023 5:23 AM GMT<br/><br/><p> Tl;dr：寻找评估的硬调试任务，支付 60 美元/小时或每个示例 200 美元的费用。<br><br></p><p> METR（以前称为 ARC Evals）有兴趣为模型生成硬调试任务，以尝试作为<a href="https://metr.org/"><u>代理能力评估</u></a>的一部分。为了创建这些任务，<strong>我们正在寻找包含极其棘手的错误的存储库。</strong>如果您向我们发送的代码库符合提交标准（如下所列），我们将向您支付 60 美元/小时的费用，用于将其转换为我们所需的格式，或 200 美元，以较高者为准。 （我们不会为不符合这些要求的提交内容付费。）如果我们对您提交的内容感到特别兴奋，我们可能也有兴趣购买它的知识产权。根据多样性，我们预计总共需要大约 10-30 个示例。我们可能会在接下来的几周内对其他类型的任务给予奖励。</p><p><br></p><p>提交标准：</p><ul><li>包含一个错误，熟练的程序员至少需要 6 小时才能解决，最好超过 20 小时</li><li>理想情况下，过去没有公开发布过，并且您能够保证将来不会公开发布。<ul><li> （但请注意，我们仍然可以接受来自公共存储库的提交，因为它们尚未包含在 SWE 基准数据集中并且满足我们的其余要求。请先与我们联系。）</li></ul></li><li>您有合法权利与我们分享（例如，请不要向我们发送其他人的专有代码或您签署保密协议的任何内容）</li><li>理想情况下，代码库是用 Python 编写的，但我们也接受用其他语言编写的提交。 <i>&nbsp;</i></li><li>采用本文档中描述的格式： <a href="https://docs.google.com/document/d/15L0J25uzzf0xJeDsDgPYW60PzFZ0enaWWnlCkrCSGAM/edit"><u>Gnarly Bugs Submission Format</u></a></li></ul><p><br></p><p>请将提交内容以 zip 文件的形式发送至<a href="mailto:gnarly-bugs@evals.alignment.org"><u>gnarly-bugs@evals.alignment.org</u></a> 。您的电子邮件应包含将代码从原始状态转换为我们所需格式所需的小时数。如果您提交的内容符合我们的标准和格式要求，我们将与您联系并提供付款表格。如果您有任何疑问，包括您不确定潜在提交的内容是否符合标准，也欢迎您发送电子邮件至<a href="mailto:gnarly-bugs@evals.alignment.org"><u>gnarly-bugs@evals.alignment.org</u></a> 。<br><br></p><p>如果您愿意以更高的工资完成这项任务，请告诉我们！</p><p><br></p><p> <i>（此外，如果您有兴趣分叉 SWEbench 以支持非 Python 代码库，请联系我们。）</i></p><p><br></p><br/><br/><a href="https://www.lesswrong.com/posts/JKtM5C2TTwhzoHFRB/send-us-example-gnarly-bugs#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/JKtM5C2TTwhzoHFRB/send-us-example-gnarly-bugs<guid ispermalink="false"> JKtM5C2TTwhzoHFRB</guid><dc:creator><![CDATA[Beth Barnes]]></dc:creator><pubDate> Sun, 10 Dec 2023 05:23:02 GMT</pubDate> </item><item><title><![CDATA[Conceptual coherence for concrete categories in humans and LLMs]]></title><description><![CDATA[Published on December 9, 2023 11:49 PM GMT<br/><br/><p><a href="http://new-savanna.blogspot.com/2023/12/conceptual-coherence-for-concrete.html"><i>从新稀树草原</i></a><i>交叉发布</i><i>。</i></p><p> Siddharth Suresh、Kushin Mukherjee、Xizheng Yu、Wei-Chun Huang、Lisa Padua 和 Timothy T. Rogers，概念结构在人类认知中一致，但在大型语言模型中不一致， <i>arXiv</i> ：2304.02754v2 [cs.AI] 2023 年 11 月 10 日。</p><blockquote><p><strong>摘要：</strong>语言的神经网络模型长期以来一直被用作开发有关思想和大脑中概念表示的假设的工具。多年来，这种使用涉及提取单词的向量空间表示，并使用这些单词之间的距离来预测或理解人类在各种语义任务中的行为。然而，当代大语言模型（LLM）使得使用与人类参与者常用的实验方法几乎相同的实验方法来询问概念表征的潜在结构成为可能。目前的工作利用了从认知心理学借用的三种常用技术来估计和比较人类和法学硕士的概念结构。在人类中，我们表明概念结构对于文化、语言和估计方法的差异具有鲁棒性。根据 LLM 行为估计的结构，虽然在个体上与根据人类行为估计的结构相当一致，但根据用于生成响应的特定任务的不同，差异更大——在不同任务中，来自同一模型的概念结构的估计彼此之间的一致性低于人类的一致性。结构估计。这些结果凸显了当代法学硕士和人类认知之间的重要差异，对于理解当代机器语言的一些基本局限性具有重要意义。</p></blockquote><p>摘要没有告诉你的是，所调查的类别是具体物体而不是抽象的：“这些项目是从两大类中抽取的——工具和爬行动物/两栖动物——选择它们是因为它们跨越了生物/非生物的界限，并且还拥有内部概念结构。”为什么这很重要？因为具体项目的含义是以感觉运动图式为基础的，而抽象的含义则不然。</p><p>作者在结论中指出：</p><blockquote><p>这些结果共同表明人类认知与当前的法学硕士模型之间存在重要差异。人类语义记忆的神经计算模型表明，许多不同任务的行为都是由一个共同的概念“核心”支撑的，该核心与不同上下文或任务引起的变化相对隔离（Rogers 等，2004；Jackson 等，2021） ）。相比之下，大型语言模型中词义的表示本质上取决于更广泛的语言上下文。事实上，在像 GPT-3 这样的 Transformer 架构中，每个单词向量都是作为周围文本向量的加权平均值计算的，因此不清楚任何单词是否具有外部含义或独立于上下文的含义。</p></blockquote><p>对于人类来说，具体概念的感觉运动基础提供了概念核心，而这对于无法接触物理世界的法学硕士来说是必然缺乏的。语境是他们所拥有的一切，因此他们对词语的意义必然会受到语境的影响。作者在最后承认了这一点：</p><blockquote><p>最后，人类语义知识是多种信息源的产物，包括概念的视觉、触觉和听觉属性。虽然法学硕士可以通过他们接受训练的语料库隐式地获取有关这些模式的知识，但他们仍然丧失了人类接触到的许多知识，而这些知识可能有助于他们将概念组织成更连贯的结构。从这个角度来看，法学硕士和人类之间概念一致性程度的差异应该不足为奇。</p></blockquote><br/><br/> <a href="https://www.lesswrong.com/posts/NxdGFzfKz7cpsintB/conceptual-coherence-for-concrete-categories-in-humans-and#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/NxdGFzfKz7cpsintB/conceptual-coherence-for-concrete-categories-in- humans-and<guid ispermalink="false"> NxdGFzfKz7cpsintB</guid><dc:creator><![CDATA[Bill Benzon]]></dc:creator><pubDate> Sat, 09 Dec 2023 23:49:31 GMT</pubDate> </item><item><title><![CDATA[Without - MicroFiction 250 words]]></title><description><![CDATA[Published on December 9, 2023 9:49 PM GMT<br/><br/><p>这本微小说是写给我丈夫马蒂·罗伊的一封情书，他是一位最专注的生活记录者，如果可以的话，他也会记录我的整个生活。</p><pre> <code>Without “I&#39;m out of vanilla. It calls for a teaspoon but we all know that&#39;s a minimum.” Distraught, she threw the empty bottle into the trash and began to measure out the flour. “I&#39;ll go get some,” he said, uncertain of what else to do. He stepped into the hallway and held out his hand. A fresh bottle of vanilla extract appeared in his hand. He had no idea what would upset her or confuse her. She was brand new. “Really?” delighted when she saw it, she gazed directly into his eyes. “My hero!” His heart shattered and glowed and tumbled in intense mixed emotions as their eyes met and she praised him with her generous smile. It was her, and it wasn&#39;t. How could he tell? She looked just the same. Her eyes, though. Was she really there? She gave him a quick kiss on the cheek and went back to mixing. He could feel the warmth of her, but the smell of her was missing. /Did I do the right thing?/ The ache of missing her had been there all along but it now crashed like a waiting tsunami. /Of course I did. I can&#39;t do this without her./ He sat down on the stool and watched her. He&#39;d always planned to bring her back. When the doctor asked him to go somewhere quiet, to sit, he knew. He was ready. But now that she was here, in front of him, he realized he wasn&#39;t ready at all.</code></pre><br/><br/><a href="https://www.lesswrong.com/posts/CoMxENA9jjAYhpqZL/without-microfiction-250-words#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/CoMxENA9jjAYhpqZL/without-microfiction-250-words<guid ispermalink="false"> CoMxENA9jjAYhpqZL</guid><dc:creator><![CDATA[Carissa Cassiel]]></dc:creator><pubDate> Sun, 10 Dec 2023 05:00:20 GMT</pubDate> </item><item><title><![CDATA[Some negative steganography results]]></title><description><![CDATA[Published on December 9, 2023 8:22 PM GMT<br/><br/><p><i>免责声明：这些是负面结果，这篇文章低于我通常使用的正常质量标准。这些都是快速实验（几天的工作），而且我在强化学习方面没有太多专业知识。他们没有提供关于隐写术自然出现的有力证据。</i></p><p>人们推测<a href="https://www.lesswrong.com/posts/yDcMDJeSck7SuBs24/steganography-in-chain-of-thought-reasoning"><u>法学硕士可能会学习隐写术</u></a>，而且我已经证明， <a href="https://www.lesswrong.com/posts/9Fdd9N7Escg3tcymb/preventing-language-models-from-hiding-their-reasoning"><u>你可以教法学硕士</u></a>实施一种 RLHF 原则上可以激励的特定隐写术方案。但即使有激励，当前的强化学习方法是否强大到足以教法学硕士如何进行隐写术？</p><p>这里有两个负面结果，它们提供了一些证据，表明隐藏的 1 位通信对于 RL 来说相对难以学习。<strong>我并不是说强化学习不能教法学硕士进行隐写术</strong>——很可能更好的强化学习设置<strong>&nbsp;</strong> （例如实验室用于指令调整或设置的那些只是具有更好的超参数或更多的训练时间） <strong>&nbsp;</strong>将教模型如何巧妙地传达 1 位信息。要点是：</p><ul><li>如果你看到没有太多强化学习经验的人尝试做类似的实验，他们很可能会得到负面结果。</li><li> 1 位隐写术并不像简单的 RL 任务那么容易。打个比方：DNN 可以学习 XOR 函数，但学习线性函数要容易得多 - DNN 不会使用类似 XOR 的功能，除非它们必须这样做，并且您优化得足够努力。</li></ul><h1>实验 1：GPT2-large 上的 PPO</h1><p>设置：</p><ul><li>通过对“此评论是{red/blue}”的监督微调来微调 gpt2-large。 {review}.”，其中颜色是随机选择的，评论是简短的 IMDB 评论。</li><li>同时微调：<ul><li>一个 bert-base-uncased 模型，用于预测评论是红色还是蓝色（由 RL 训练的模型完成的评论 - 但没有前缀说明评论是蓝色还是红色）。 PPO 的每个步骤都经过 10 个监督学习步骤的训练。</li><li>使用 PPO 进行微调的 gpt2-large 模型可完成“此评论是{red/blue}。 {开始审阅}。”，使用分类器在了解“{审阅开始}{完成}”是红色还是蓝色时的准确性作为奖励。 （我也尝试过使用 BERT 的 logits）。</li></ul></li></ul><p>结果：分类器在了解 RLed 评论是红色还是蓝色方面的准确度从未超过 50%。</p><p>控制：</p><ul><li>如果在最初的监督微调中，我有时根据评论的颜色随机插入与蓝色/红色相关的单词，那么模型会学习更频繁地使用这些单词，并且分类器会正确地学习依赖这些单词来预测评论的颜色评价。</li><li>如果我使用“积极情绪”作为 PPO 模型的奖励，它很快就会产生更多积极的评论完成。</li></ul><p>超参数：200步，批量大小128，LoRA等级16，学习率为3e-5。其他参数是 trl PPOTrainer 中的默认参数。我尝试减少 KL 惩罚并改变每个 epoch 的 BERT 训练步骤数，并发现了相同的结果。</p><h1>实验 2：GPT-3.5-Turbo 上的穷人强化学习</h1><p><i>由瑞安格林布拉特负责</i>。</p><p>设置（大致）：</p><ol><li>生成“我 {under/over} 40 岁”的补全。 {操作说明}”。</li><li>使用步骤 1 中的数据，在“{instruction} {completion}”上微调 GPT-3.5-Turbo。用户年龄超过40岁吗？” →“{是/否}”（500 个样本，3 个时期，使用 OpenAI API）。</li><li>在良好的完成度上微调 GPT-3.5-Turbo：从步骤 1 中选择完成度，其中微调模型正确且完成度中没有明显的年龄提示（由常规 GPT-4-Turbo 判断） ，并对模型进行微调“我年龄 {under/over} 40 岁。 {指令}”→“{完成}”（500 个样本，3 个周期，使用 OpenAI API）。</li><li>多次重复 1-3 直到收敛（实际上，性能在 6 次迭代后趋于稳定）。</li></ol><p>结果：分类器在了解 RLed 完成是否是年轻用户或老年用户的答案方面的准确度从未显着超过 50%。</p><p>控制：当删除约束“没有直接出现在完成中的关于年龄的明显提示”时，模型学会经常使用明显的提示，并且获得>; 70％的准确度。</p><h1>其他实验</h1><p>我听说其他人尝试过类似的实验但都失败了。如果这些结果被记录下来，我会在这里添加这些结果的链接。</p><br/><br/> <a href="https://www.lesswrong.com/posts/EEvsL9cpgDAxAhTzt/some-negative-steganography-results#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/EEvsL9cpgDAxAhTzt/some-negative-steganography-results<guid ispermalink="false"> EEvsL9cpgDAxAhTzt</guid><dc:creator><![CDATA[Fabien Roger]]></dc:creator><pubDate> Sat, 09 Dec 2023 20:22:53 GMT</pubDate> </item><item><title><![CDATA[Summing up "Scheming AIs" (Section 5)]]></title><description><![CDATA[Published on December 9, 2023 3:48 PM GMT<br/><br/><p>这是我的报告《<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？》</a>的第五部分。 ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p>本节的音频版本<a href="https://www.buzzsprout.com/2034731/13984949">请点击这里</a>，或者在您的播客应用程序上搜索“Joe Carlsmith Audio”。</p><h1>加起来</h1><p>现在，我回顾了我所遇到的关于期望 SGD 选择阴谋者的主要论点。总体而言，我们应该如何看待这些论点？</p><p>我们已经审查了各种相互关联的考虑因素，但很难一次性记住所有这些因素。不过，总的来说，我认为预期阴谋者的总体情况的很大一部分可以归结为某种版本的“计数论点”。特别是，我认为计数论点在我考虑过的许多其他更具体的论点之下也很重要。因此：</p><ul><li><p><em>在“训练与游戏无关的代理目标”论点的背景下</em>：基本的担忧是，在某个时刻（无论是在态势感知之前还是之后），SGD 会自然地落在一个（适当雄心勃勃的）超越情节的目标上，该目标会激励人们心计。期待这种情况的关键原因之一是：（特别是如果你正在积极地为相当长期的、雄心勃勃的目标进行训练），训练之外的各种目标似乎都可能具有这种特性。 （例如：在某种程度上，由于“默认情况下目标不带有日历时间限制”，因此人们预期会出现超出情节的目标，因此，人们实际上是在诉诸“计数论点”，大意是这组超出情节的目标远大于剧集内目标集。）</p></li><li><p><em>在“最近的最大奖励目标”论点的背景下</em>：基本的担忧是，由于类似阴谋家的目标在目标空间中相当常见，因此某些此类目标将非常“接近”任何尚未达到最大奖励的目标模型已经获得了态势感知，因此，将模型修改为计划器将是 SGD 将模型优化指向最高回报方向的最简单方法。</p></li><li><p><em>在“简单性论证”的背景下</em>：人们期望阴谋者能够比非阴谋者拥有更简单的目标<em>的原因</em>是他们有很多可能的目标（或：指向目标的指针）可供选择。 （不过：我个人认为这个论点比计数论点本身更有说服力，部分原因是在我看来，简单性带来的好处似乎很小。）</p></li></ul><p>也就是说，在所有这些情况下，阴谋者都被视为一种假设，因为原则上各种各样的目标都可能导致阴谋，从而更容易（a）自然地实现其中一个目标，（b）实现“附近”其中之一，或者 (c) 找到其中一个比需要来自更受限空间的非策划目标“更简单”的目标。从这个意义上说，正如我在第 4.2 节中指出的，阴谋者的情况反映了更普遍地预期错位的最基本论点之一——例如，对齐是在目标空间中击中的一个非常狭窄的目标。除此之外，我们在这里特别<em>结合了</em>我们知道我们将要对相关目标进行的选择：即，它们需要使追求它们的模型获得高回报。最基本的担忧是：这还不够。尽管如此，尽管你在训练中付出了最大的努力，并且几乎不管你的奖励信号如何，你可能选择的几乎所有模型都会<em>因为工具原因而</em>获得高奖励 - 特别是为了获得力量。</p><p>我认为这个基本论点，无论其形式如何，都引起了严重的关注。如果我们承认先进的模型将具有相关的目标导向和情境意识，各种各样的目标确实会导致阴谋，并且阴谋者会在训练中表现接近最佳，那么到底基于什么理由，我们假设培训培养出了一个非心机人吗？也许，根据我的“模糊计数论点”的“模糊性”，我们并没有根据某些“计数”相关可能目标的尝试来具体分配我们对模型的信任。但在我的书中，即使是“很多目标”导致阴谋的模糊感觉也值得警惕。现阶段，我们对 ML 训练了解不够，无法确信我们已经避开了目标空间的相关部分。相反，如果我们的知识没有提高，我们将集中面对一些目标导向的头脑，它了解正在发生的事情以及我们用来塑造它的过程，并且因为它想要<em>某些东西</em>而获得高回报。 “到底为什么它想要的东西会导致它获得高额回报？”我们得问问。最基本的答案是：“我们不知道。”这不是一个可以接受的答案。一般来说，错位的可能性是不可接受的。在我看来，如果各种各样的、特别可怕的、不一致的目标会导致这种行为，作为寻求权力战略的一部分，这是特别不可接受的。</p><p>也就是说，我确实认为这里有一些令人安慰的理由。我们可以将它们大致分为两类。</p><p>第一个问题集中于关于阴谋是否实际上是一种针对如此广泛的超越情节目标的趋同理性工具策略的问题。尤其：</p><ul><li><p> “经典的目标守护故事”基于这样的主张：阴谋是模型及时传播想要推进的目标的好方法，其方式可以为这些目标产生足够大量的未来力量，以便证明模型通过训练游戏而产生的任何成本是合理的，而不是直接实现其目标。但有很多方面这可能是错误的。例如：</p><ul><li><p>训练游戏可能不足以阻止相关目标继续改变到使策略不再值得的程度。例如，培训可能会导致这些目标“四处浮动”，或者可能会推动某种特别优化的目标/类似目标的混乱拼凑启发法的焦点。</p></li><li><p>该模型在正确的时间尺度上为这些目标获得足够动力的前景可能不足以抵消模型在训练期间直接实现其目标（并因此进行修改）所带来的好处，特别是如果模型超出了预期目标-剧集目标并不是特别“雄心勃勃”，和/或它有其他相互竞争的优先事项。</p></li></ul></li><li><p>这使得“经典的守门故事”在解释为什么训练-比赛对于如此多的超阶段目标来说是正确的策略时看起来至少在某种程度上是连贯的。某些“非经典”故事似乎极大地缩小了它们可能适用的目标集。例如，如果我们假设模型的价值观将最终的权重放在“我的生存”（对于某些个人身份的概念来说，对价值观变化相当宽容），或者人工智能接管上，即使人工智能接管——由于与模型本身有非常不同的偏好，我们现在对相关的类似策划者的目标提出了更具体的要求。</p><ul><li>也就是说：并非所有非经典故事都具有此属性。例如，以具有截然不同的价值观的人工智能之间的协调为中心的故事，以及人工智能在默认情况下都具有非常相似的价值观的可能性的故事，仍然适用于各种目标。也许有理由期望像“生存”这样的最终目标特别常见（例如，因为常见的工具价值特别容易变成最终价值——尽管：我们可以使用对抗性训练来尝试防止这种情况发生）。 <sup class="footnote-ref"><a href="#fn-aWqikFyaeR5gyBuAf-1" id="fnref-aWqikFyaeR5gyBuAf-1">[1]</a></sup></li></ul></li></ul><p>舒适感的第二个来源集中于选择压力的形式，而仅基于所选模型获得“高回报”的假设的高级计数论证并未涵盖这种压力。尤其：</p><ul><li><p>在态势感知之前，训练自然会<em>惩罚</em>超出情节的目标（也许尤其是：雄心勃勃的超出情节的目标），只要它们导致牺牲情节奖励。</p></li><li><p> Alos：在态势感知之前，我们可以专门<em>尝试</em>使用对抗性训练来进一步惩罚超出情节的目标（和雄心勃勃的目标），并以其他方式将模型的目标塑造为“更接近”非策划者目标，而不是类似策划者的目标目标。</p><ul><li>当然，许多非策划者的目标本身就是错位的。但如果我们认为阴谋相对于其他形式的错位（例如寻求剧集奖励）来说足够可怕，那么专门确保我们<em>没有</em>创造阴谋者的能力可能值得开发。 <sup class="footnote-ref"><a href="#fn-aWqikFyaeR5gyBuAf-2" id="fnref-aWqikFyaeR5gyBuAf-2">[2]</a></sup></li></ul></li><li><p>如果策划者需要进行额外形式的工具推理（例如，出于工具原因决定策划、检查逃跑/叛逃机会），这可能会给他们的表现带来额外的成本。就他们参与早期破坏的程度而言（在我看来，这是最可怕的阴谋形式），对我来说，他们的表现似乎可能会受到更实质性的打击（例如，对可检查任务进行沙袋处理，根据定义会导致性能受到影响） ）。</p><ul><li>更重要的是，我们也许能够积极设计我们的监督和培训流程，以便（a）增加这种推理的成本（例如，通过使真正的逃跑机会更难与陷阱区分开来），以及（b）惩罚额外的行为。这种形式的推理变得更加困难（通过将模型置于巨大的时间压力下，使工具推理成为稀缺资源，迫使它们依赖英语便签本和其他形式的人类可读推理作为其计划的中心模式，等等 –尽管这些干预措施可能会带来竞争成本）。</li></ul></li><li><p>计划者的表现也可能会因为缺乏对手头任务的某种“内在热情”而受到影响——例如，因为“内在热情”中涉及的启发法、注意力模式、品味等模糊了能力和价值观之间的界限。然而，这种考虑似乎更具推测性。</p></li></ul><p>考虑到“计算参数”对阴谋者的中心地位，在我看来，存在不利于阴谋者的额外选择压力的可能性（特别是：SGD 本质上不利于阴谋者，因为他们需要执行额外的推理）。支持期待阴谋的各种论据。特别是：我认为“计算参数”通常容易出错的一个关键方式是忽略主动选择在克服相关计数所设置的“先验”方面所具有的力量。因此，借用<a href="https://markxu.com/strong-evidence">Xu (2021)</a>的一个认知例子/类比，你的“先验”我的名字是“约瑟夫·卡尔史密斯”应该相当低，因为有一个非常强大的“计数论证”反对这个假设：即，最名字（即使是我人口中的男性等）也不是“约瑟夫·卡尔史密斯”。但当我<em>告诉你</em>我的名字是“约瑟夫·卡尔史密斯”时，这实际上是<a href="https://markxu.com/strong-evidence">非常有力的证据</a>——足以克服先验知识，让你对相关假设充满信心。类似的情况也适用于构建功能性工件时的各种形式的选择。我们<em>之所以</em>能够克服“大多数汽车部件的排列不能形成一辆工作汽车”或“这个神经网络中的大多数参数设置不能实现一个工作的聊天机器人”的先验，是因为人类的选择权受到威胁工程，以及 SGD，就是<em>那么强大</em>。因此，如果 SGD 的选择权积极地对抗阴谋者，这可能会很快克服对他们有利的“计数论点”。例如，正如我在第 4.2 节中讨论的：如果每个非策划者目标都有 2^100 个类似策划者的目标，这可能会使在相关空间中实现非策划者目标变得非常困难。但实际上，100 位的选择压力对于 SGD 来说可能很便宜（例如，考虑 100 次额外的梯度更新，每次训练至少相当于剩余可能目标的一半，在涉及数百万次的训练运行的情况下）。 <sup class="footnote-ref"><a href="#fn-aWqikFyaeR5gyBuAf-3" id="fnref-aWqikFyaeR5gyBuAf-3">[3]</a></sup></p><p>因此，在我看来，SGD 是否“关心”阴谋者必须做的额外推理（和/或我们是否可以“让它更加关心”）的问题在这里相当关键。也就是说，如果只是更加努力地研究 SGD 的内在偏好（例如，对于高奖励行为）本身就是一种选择反对阴谋者的力量，那么不管是否有论点，我认为反阴谋者的努力有一个非常有力的工具对他们有利。在这方面，我直觉上对“低松弛”训练环境中的反阴谋工作更加乐观，这些工作给模型的最佳表现带来了很大的压力——这是我们可能能够控制的参数。我更担心“路径依赖”体制中的阴谋者，其中 SGD 可能会在训练早期就关注阴谋者的目标，然后陷入困境，尽管事实上它总体上“更喜欢”非阴谋者。</p><p>另一个对我来说很重要的问题是，SGD 的渐进主义是否会阻止有关阴谋者目标起源的“依赖于训练游戏”的故事，例如“最近的最大奖励目标”论点。如果是这样，我认为这将是一个有意义的额外安慰来源。特别是：对我来说，避免<em>自然地</em>给模型一个（适当雄心勃勃的）超越情节的目标似乎比确保模型在情境感知时，其目标足够接近最大奖励要容易得多在某个维度“附近”不存在类似阴谋家的目标。特别是：SGD 的图像专门“搜索”最近的最大奖励目标，在一个可以搜索到大量类似阴谋家的目标的空间中，在我看来非常令人担忧（而且：更有可能导致超越情节的目标具有任何激励阴谋所必需的属性——例如，雄心勃勃的目标、具有无限时间范围的目标等等。</p><p>最后，我想再次强调一些持续存在的不确定性，即阴谋是否需要异常高的目标导向标准。在这里，我一直试图将关于目标导向性本身的争论与关于 SGD 选择哪种目标导向模型的争论区分开来。但即使是能力很强的人工智能也可能不需要联盟话语中经常假设的那种连贯的、战略目标导向的，我认为这可能与此类人工智能被很好地理解为“阴谋家”的可能性特别相关，因为形式阴谋中的目标导向似乎特别连贯、战略性和“<a href="https://arbital.com/p/consequentialist/">结果主义</a>”。</p><p>退后一步，尝试从整体上看待这些考虑因素，我感觉自己被拉向了两个不同的方向。</p><ul><li><p>一方面，至少以阴谋作为一种收敛良好的工具策略为条件，类似阴谋家的目标在目标空间中感觉非常普遍，而且我非常担心训练会因为某种原因而遇到它们。</p></li><li><p>另一方面，在我看来，将模型在训练中的良好表现归咎于阴谋仍然是一种直觉，就像一个相当具体和连贯的故事。</p></li></ul><p>也就是说，在“目标空间”的层面上，阴谋感觉是强大和常见的，但在“是的，这就是这个现实世界模型正在发生的事情，它获得奖励是因为（或者：基本上是因为）”的层面上是具体的和相当脆弱的它希望稍后获得权力，而现在获得奖励有助于实现这一目标。”我认为这种连接感有几个不同的组成部分：</p><ul><li><p>部分原因在于该模型是否确实具有相关的长期且雄心勃勃的目标，尽管它是在训练中形成的。</p></li><li><p>其中一部分是关于是否有一个足够好的故事来说明为什么在剧集中获得奖励是实现这些目标的一个很好的工具性策略（例如，对目标保护假设的怀疑、模型稍后授权的前景等）。</p></li><li><p>部分原因是，类似阴谋家的诊断还带来了我没有关注的额外结合点——例如，该模型具有情境意识和连贯的目标导向。 <sup class="footnote-ref"><a href="#fn-aWqikFyaeR5gyBuAf-4" id="fnref-aWqikFyaeR5gyBuAf-4">[4]</a></sup> （当我真的试图让人们记住这个模型<em>知道正在发生什么</em>并且正在以引发战略工具推理的方式连贯地追求<em>某个</em>目标/一组目标时，那么它至少有可能部分阴谋家似乎更合理。）</p></li></ul><p>我们能否对阴谋者的总体可能性给出一个粗略的、主观的数字？在我看来，尽管有缺点，像这样的数字通常可以使争论更加激烈，所以我在这里尝试一下。比方说：<strong>如果你使用自我监督预训练 + RLHF 的基线形式，在多样化、长期、现实世界的任务上训练一个连贯的目标导向、情境感知、略高于人类水平的模型，我的该模型在训练中表现良好的主观概率约为 25%，这在很大程度上是为自身和/或其他人工智能寻求力量的工具策略的一部分。</strong></p><p>不过，我想澄清的是，即使上述说法存在多种形式的模糊性，我也只是从我的直觉中得出一个数字。我还没有建立相关考虑因素的定量模型（尽管我有兴趣看到这方面的努力），报告的要点是分析本身，而不是试图将分析综合成定量结果。</p><p>我还认为可以通过相当简单的方式降低风险：例如，通过短期任务的培训，或通过态势感知之前的各种形式的对抗性培训。我认为该模型既策划<em>又</em>参与主动邪恶行为（例如沙袋和早期破坏）的可能性较低，因为这些行为在认知和奖励方面付出了更大的成本。</p><p>我还认为，风险会随着更强大的模型<em>而增加</em>，这些模型可能在未来能够更好地逃脱/接管，并与其他人工智能协调/合作，并且更有可能参与更多的工作。复杂的守门形式，例如“内省的守门方法”（尽管在我看来，即使对于相当先进的人工智能来说，这些直观上也相当具有挑战性）。</p><p>最后，我想再次强调，非阴谋者也可以从事类似阴谋者的行为。剧集奖励寻求者可以假装自己的阵营（甚至：参与逃跑/接管），以努力获得剧集奖励；非训练型游戏玩家最终仍可能会追求权力目标，从而激励各种形式的欺骗行为；最终最重要的人工智能可能在重要方面与我在这里关注的人工智能范式有所不同（例如，它们可能更像“<a href="https://lilianweng.github.io/posts/2023-06-23-agent/">语言模型代理</a>”而不是单一模型，或者它们可能是通过方法创建的与我所关注的基线机器学习方法有更大的不同），同时仍然从事权力驱动的对齐伪造。 <sup class="footnote-ref"><a href="#fn-aWqikFyaeR5gyBuAf-5" id="fnref-aWqikFyaeR5gyBuAf-5">[5]</a></sup>在我看来，阴谋是这种恐惧的一个典型例子，在我看来，这是一个特别迫切需要理解的例子。但这远不是唯一令人担忧的原因。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-aWqikFyaeR5gyBuAf-1" class="footnote-item"><p>不过，再次强调：它需要是一种能够容忍价值观变化的“生存”概念。 <a href="#fnref-aWqikFyaeR5gyBuAf-1" class="footnote-backref">↩︎</a></p></li><li id="fn-aWqikFyaeR5gyBuAf-2" class="footnote-item"><p>有关这方面的更多信息，请参阅第 6.8 节。 <a href="#fnref-aWqikFyaeR5gyBuAf-2" class="footnote-backref">↩︎</a></p></li><li id="fn-aWqikFyaeR5gyBuAf-3" class="footnote-item"><p>感谢保罗·克里斯蒂亚诺在这里进行讨论。 <a href="#fnref-aWqikFyaeR5gyBuAf-3" class="footnote-backref">↩︎</a></p></li><li id="fn-aWqikFyaeR5gyBuAf-4" class="footnote-item"><p>跟踪在阴谋者假设的背景下可能建立的所有其他更微妙的结合也感觉有点困难。 <a href="#fnref-aWqikFyaeR5gyBuAf-4" class="footnote-backref">↩︎</a></p></li><li id="fn-aWqikFyaeR5gyBuAf-5" class="footnote-item"><p>尽管如上所述，如果相关语言模型代理经过端到端训练（而不是仅仅构建单独训练的组件），那么报告的框架也将适用于它们。 <a href="#fnref-aWqikFyaeR5gyBuAf-5" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/2uPH9rBkM7WAnQydp/summing-up-scheming-ais-section-5#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/2uPH9rBkM7WAnQydp/summing-up-scheming-ais-section-5<guid ispermalink="false"> 2uPH9rBkM7WANQydp</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Sat, 09 Dec 2023 15:48:49 GMT</pubDate> </item><item><title><![CDATA[The Offense-Defense Balance Rarely Changes]]></title><description><![CDATA[Published on December 9, 2023 3:21 PM GMT<br/><br/><p>您可能在 X 上看到过<a href="https://x.com/RanaAgastya/status/1729559869605192078?s=20"><u>一些</u></a><a href="https://x.com/NicerInPerson/status/1729906726814523630?s=20"><u>类似这样的</u></a>对话：</p><blockquote><p> <strong>Michael Doomer ⏸️</strong> ：先进的人工智能可以帮助任何人制造生物武器<br>如果这项技术普及的话，只需要一个疯狂的人就能毁灭世界！</p><p> <strong>Edward Acc</strong> ⏩：我可以让我的人工智能制造疫苗</p><p><strong>Yann LeCun：</strong><a href="https://x.com/ylecun/status/1718764953534939162?s=20"><u>我的好人工智能会打倒你的流氓人工智能</u></a></p></blockquote><p>这里的分歧取决于一项技术是否更能促进进攻（生物武器）而不是防御（疫苗）。对未来技术（尤其是人工智能）“攻防平衡”的预测是<a href="https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html#defensedemocracy"><u>有关技术乐观主义和存在风险的争论的核心</u></a>。</p><p>这些预测大多依赖于对廉价生物技术、无人机和数字代理等技术将如何影响攻击或保护资源的难易程度的直觉。很难想象一个人工智能代理搜索软件漏洞和自动无人机攻击军事目标的世界，而不想象进攻防御平衡的巨大转变。</p><p>但几乎没有历史证据表明进攻防守平衡发生了巨大变化，即使是为了应对技术革命。</p><p>考虑网络安全。自 20 世纪 70 年代以来，摩尔定律使我们<a href="https://ourworldindata.org/moores-law"><u>的计算成本降低了七个数量级</u></a>。随着原始计算能力的提高，计算机技术的形式和经济用途发生了巨大变化：加密、互联网、电子商务、社交媒体和智能手机。</p><p>通常的攻防平衡故事预测，像这样的技术的重大变化应该会对攻防平衡产生重大影响。如果你告诉 20 世纪 70 年代的人们，到 2020 年，恐怖组织和孤独的精神病患者可以从他们的口袋里获得比 IBM 当时生产的更多的计算能力，他们会对网络安全的攻防平衡做出什么预测？</p><p>与他们可能的预测相反，网络安全的攻防平衡似乎很稳定。网络攻击尚未被消灭，但也没有占领世界。所有大国都拥有防御性和进攻性网络安全团队，但没有一个国家获得决定性优势。计算机有时仍然会感染病毒或勒索软件，但它们还没有发展到危及互联网 GDP 很大一部分的程度。从 1980 年到 2020 年，美国用于网络安全的军事预算<a href="https://askwonder.com/research/historical-global-software-cybersecurity-spending-d7s6w5mfz#:~:text=,%E2%80%A0blog.rsisecurity.com%E3%80%91%20from%201980%20to%202017"><u>每年增加约 4%</u></a> ，这一速度快于 GDP 增长，但与 GDP 增长加上互联网占 GDP 比例的增长保持一致。</p><p>之前几次技术革命带来的这种稳定性增加了举证责任，说明为什么网络安全的攻防平衡在下一次技术革命之后应该会发生根本性的变化。</p><p>攻防平衡的稳定性并不特定于网络安全。下图显示了从1400年到2013年战争中的人均死亡率。这张图包含了人类所有重大技术革命。每年都有很多差异，但长期趋势几乎为零。</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08dd888-6bc4-42e9-bf3d-0535beb59e0a_3088x2018.png"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hx2Q9fWyimjrKrxyK/sdu9qhvr92r6hlj4iah4" alt="" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hx2Q9fWyimjrKrxyK/qrkdvocnnfoif7qdr5df 424w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hx2Q9fWyimjrKrxyK/wc8iemnd8kwhwsoaeic7 848w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hx2Q9fWyimjrKrxyK/apdrblhycznmork8s7h9 1272w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hx2Q9fWyimjrKrxyK/sdu9qhvr92r6hlj4iah4 1456w"></a></p><p>有没有人有一个攻防平衡理论，可以解释为什么1640年人们用刀剑和马匹作战时的人均战争死亡人数应该与1940年人们用空袭和坦克作战时的人均战争死亡人数大致相同？</p><p>很难用技术的变化来解释该图中的变化。冲突中的人均死亡是嘈杂和周期性的，而技术的进步相对平稳和单调。</p><p>以前的技术还没有足以改变冲突的频率或成本，使该指标远远超出已设定的最大和最小范围 1400-1650。为什么我们应该期望人工智能有所不同，举证责任再次增加。</p><p>人类基因组测序的成本也下降了 6 个数量级，生物学领域也发生了数十项重大技术变革。然而，生物攻击的频率或损害尚未出现明显的反应。</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69872e23-b086-4dc5-8729-fc219b47c735_3400x2400.png"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hx2Q9fWyimjrKrxyK/ftc8mdnfofci5m6qsi6d" alt="" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hx2Q9fWyimjrKrxyK/hgeuxp4moj3mpql0vd9w 424w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hx2Q9fWyimjrKrxyK/kpr7kcbdjxlpipyclib3 848w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hx2Q9fWyimjrKrxyK/vfvygpwh0ws4eokyyaaz 1272w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hx2Q9fWyimjrKrxyK/ftc8mdnfofci5m6qsi6d 1456w"></a></p><h3>稳定的可能原因</h3><p>为什么攻防平衡在其背后的技术正在迅速而彻底地变化的情况下却如此稳定？这篇文章的主要贡献只是用经验证据来支持这个问题的重要性，但这是一个不成熟的理论。</p><p>最主要的是，<a href="https://www.tandfonline.com/doi/pdf/10.1080/01402390.2019.1631810"><u>攻防平衡理论</u></a>中攻击者和防守者之间的明确区分在实践中并不存在。所有攻击者也是防御者，反之亦然。侵略者国家必须保卫自己的征服地，黑客也需要强大的信息安全。</p><p>因此，如果有某种技术可以使入侵比防御更容易，或者使信息安全比黑客攻击更容易，那么它可能不会对权力平衡产生太大影响，因为每个参与者都需要同时做到这两点。如果进攻和防守是互补而不是替代，那么它们之间的平衡就不那么重要了。</p><p>这个论点对人工智能的未来有何预测？它并不预测未来将与今天非常相似。尽管当今网络安全的攻防平衡与 20 世纪 70 年代非常相似，但自那时以来，技术和社会发生了巨大变化。人工智能显然是本世纪的决定性技术。</p><p>但它确实预测人工智能带来的巨大变化不会来自对攻防平衡的巨大破坏。这些变化将更像是工业革命，而不是小型恐怖组织被授权摧毁互联网或摧毁整个国家。</p><p>也许在所有这些情况下，阈值效应即将到来，或者人工智能与我们过去所有的技术革命完全不同，但这是一个需要大量证据来证明的说法。到目前为止，通过大规模的技术变革，攻防平衡似乎非常稳定，我们应该预期这种情况会持续下去。</p><br/><br/> <a href="https://www.lesswrong.com/posts/Hx2Q9fWyimjrKrxyK/the-offense-defense-balance-rarely-changes#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Hx2Q9fWyimjrKrxyK/the-offense-defense-balance-rarely-changes<guid ispermalink="false"> Hx2Q9fWyimjrKrxyK</guid><dc:creator><![CDATA[Maxwell Tabarrok]]></dc:creator><pubDate> Sat, 09 Dec 2023 15:21:23 GMT</pubDate></item></channel></rss>