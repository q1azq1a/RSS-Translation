<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 10 月 10 日，星期二 02:15:24 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Simple Terminal Colors]]></title><description><![CDATA[Published on October 10, 2023 12:40 AM GMT<br/><br/><p><span>我经常在终端上工作，并且经常想编写一些程序来对输出进行一些着色。例如，也许我正在查看</span><a href="https://www.jefftk.com/p/sequencing-intro">测序读数</a>，我想知道它的哪一部分是其被标记的原因。我可以使用<a href="https://pypi.org/project/colorama/">colorama</a> 、 <a href="https://pypi.org/project/termcolor/">termcolor</a>或其他库，但<a href="https://www.jefftk.com/p/designing-low-upkeep-software">包含这么简单的东西的依赖项</a>并不值得。相反，打印彩色文本非常简单：</p><p></p><pre> COLOR_RED_BOLD = &#39;\x1b[1;31m&#39;
COLOR_BLUE_BOLD = &#39;\x1b[1;34m&#39;
COLOR_END = &#39;\x1b[0m&#39;
打印（
  “一条鱼，两条鱼，” +
  COLOR_RED_BOLD +“红色”+
  COLOR_END +“鱼，”+
  COLOR_BLUE_BOLD +“蓝色”+
  COLOR_END +“鱼。”）
</pre><p><a href="https://www.jefftk.com/terminal-one-fish-two-fish-red-fish-blue-fish-big.png"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/oLK5J7xazS8L3p6fy/yb6yjheuv5hy5j3kdm6t" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/oLK5J7xazS8L3p6fy/yb6yjheuv5hy5j3kdm6t 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/oLK5J7xazS8L3p6fy/af02tlyznphgzazdh0qz 1100w"></a></p><div></div><p></p><p>我通常只需要一种或两种突出显示颜色，通常为粗体，并且很少发现六种标准颜色有限制。如果您想将注意力吸引到特定的事物上，同时在需要进一步观察时保持其周围的背景，那么这会特别有用。</p><p>这有多兼容？有一天，使用非 ANSI 终端的人会运行我的代码并抱怨吗？一个数据点是我在<a href="https://www.jefftk.com/p/introducing-icdiff">2009 年</a>用这种方法编写了<a href="https://www.jefftk.com/icdiff">icdiff</a> ，并且它相当流行。虽然我收到了<a href="https://github.com/jeffkaufman/icdiff/issues?q=is%3Aissue">数百份</a>错误报告，但这从来没有人抱怨过。</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid0yNYkCYNaKotC3ZKBJZ2sCMiAogXFgBcjyfS9qW7JHduMXkUEBNxW5ywpcphoGJQel">facebook</a> , <a href="https://mastodon.mit.edu/@jefftk/111207929256178296">mastodon</a></i></p><br/><br/><a href="https://www.lesswrong.com/posts/oLK5J7xazS8L3p6fy/simple-terminal-colors#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/oLK5J7xazS8L3p6fy/simple-terminal-colors<guid ispermalink="false"> olK5J7xazS8L3p6fy</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Tue, 10 Oct 2023 00:40:08 GMT</pubDate> </item><item><title><![CDATA[The Handbook of Rationality (2021, MIT press) is now open access]]></title><description><![CDATA[Published on October 10, 2023 12:30 AM GMT<br/><br/><p>这里特别令人感兴趣的是关于概率的主观解释的第 4.1 节和第 8.4 节，其中明确讨论了奈特不确定性及其对贝叶斯解释的挑战。</p><p> <a href="https://direct.mit.edu/books/oa-edited-volume/5525/The-Handbook-of-Rationality">https://direct.mit.edu/books/oa-edited-volume/5525/The-Handbook-of-Rationality</a></p><br/><br/> <a href="https://www.lesswrong.com/posts/zcigMWSr5uKs2cPCv/the-handbook-of-rationality-2021-mit-press-is-now-open#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/zcigMWSr5uKs2cPCv/the-handbook-of-rationality-2021-mit-press-is-now-open<guid ispermalink="false"> zcigMWSr5uKs2cPCv</guid><dc:creator><![CDATA[romeostevensit]]></dc:creator><pubDate> Tue, 10 Oct 2023 00:30:07 GMT</pubDate> </item><item><title><![CDATA[Non-superintelligent paperclip maximizers are normal]]></title><description><![CDATA[Published on October 10, 2023 12:29 AM GMT<br/><br/><p><a href="https://en.wikipedia.org/wiki/Instrumental_convergence">回形针最大化器</a>是一个关于假设的超级智能 AGI 的思想实验，它痴迷于最大化回形针。它可以被建模为效用理论代理，其效用函数与宇宙中回形针的数量成正比。<a href="https://arbital.com/p/orthogonality/">正交性命题</a>论证了这种代理的逻辑可能性。它有弱形式和强形式：</p><blockquote><p>正交性论文的弱形式说：“由于制造回形针的目标是容易处理的，因此设计空间中的某个地方有一个代理可以优化该目标。”</p><p>正交性的强形式表示：“这个代理不需要扭曲、复杂或低效，也不需要有任何奇怪的反射缺陷；代理与目标一样容易处理。”也就是说：当考虑一个代理人的必要内部认知时，该代理人引导结果在某些结果评分函数 U 中获得高分，除了“什么政策会导致后果”这个问题固有的困难之外，该认知没有增加任何困难。 U 分数高吗？”</p></blockquote><p>这引发了一些问题：</p><ul><li>为什么未来很可能由效用最大化的代理人控制？</li><li>可能会出现哪些类型的效用函数？</li></ul><p>期望遥远的未来由效用最大化代理人控制的一个基本原因是，效用理论是在不确定性下进行权衡的理论，而制定遥远未来计划的代理人可能会做出权衡，因为权衡是他们的必要条件。计划成功。几乎不管U是什么，只要U只能通过将遥远的未来注入可能性空间的特定部分来满足，他们就会有动力做出权衡以控制宇宙。无论智能体寻求最大化回形针、最小化熵，还是最大化积极意识体验的量，在短期内，它都会被激励使智能体共享其价值观，从而在遥远的未来拥有更多影响力。这是基本的工具趋同论点。</p><p>我们所知道的近似效用最大化的代理的一个例子是生物有机体。生物有机体模拟世界并具有与世界相关的目标，这些目标在某种程度上抵抗线头（从而构成<a href="https://arbital.com/p/environmental_goals/">环境目标</a>）。他们做出权衡以实现这些与生存和繁殖相关的目标。生物有机体最终可能实现的目标将是（a）在某种程度上可能是由基因突变等预先存在的过程产生的，（b）与生存和繁殖充分相关，因此针对这些目标进行优化的代理将是可能会复制更多具有相似目标的代理。然而，这些目标不必<a href="https://www.lesswrong.com/posts/XPErvb8m9FapXCjhA/adaptation-executers-not-fitness-maximizers">与生物有机体的可能目标的包容性适应性相同</a>。包容性健身本身不太可能作为基因突变等的目标而出现，因此不可能成为比其代理更受欢迎的价值函数。</p><p>然而，人类环境中的许多目标和价值观与包容性健身并没有很好的相关性。这些通常是社会系统的一部分。一些例子包括体育等游戏的能力、数学等研究领域的进展以及利润最大化（尽管，这一点至少比其他方面更直接地与包容性健身相关）。激励（通常是人类）代理人优化这些目标的相应机构包括游戏/体育联盟、学术部门和公司。</p><p>与包容性健身相关性较高的目标会受到欢迎，这是可以理解的，但为什么与包容性健身相关性较差的目标也会受到欢迎呢？ Molgbug 的<a href="https://www.unqualified-reservations.org/2007/05/magic-of-symmetric-sovereignty/">Fnargl 思想实验</a>可能会对此有所启发：</p><blockquote><p>因此，让我们稍微修改一下，转而寻找最糟糕的合理结果。也就是说，我们假设独裁者并不邪恶，而只是不道德、无所不能且贪婪。</p><p>构建这个思想实验的一种简单方法是想象独裁者甚至不是人类。他是一个外星人。他的名字叫弗纳尔格尔。弗纳尔格尔来到地球只是为了一件事：黄金。他的目标是统治这个星球一千年，即所谓的“千年 Fnarg”，然后带着尽可能多的黄金乘坐他的 Fnarg 飞船离开。除此之外，Fnargl没有其他感觉。他对人类的关心就像你我对细菌的关心一样。</p><p>你可能认为我们人类，一群勇敢的人，会说“管你的，Fnargl！”根本不给他任何金子。但这有两个问题。第一，Fnargl 是刀枪不入的——任何人类武器都无法伤害他。第二，他有能力随时随地杀死任何一个或多个人类，只需打个响指即可。</p><p>除此之外，他没有其他权力。他甚至不能走路——他需要被人抱着，就好像他是印度皇后一样。 （弗纳尔格尔实际上与赫特人贾巴有着惊人的相似之处。）但是凭借刀枪不入和死亡的力量，弗纳尔格尔让自己成为联合国秘书长是一件非常简单的事情。在千年法纳尔格中，联合国不仅仅是酗酒的非洲盗贼统治者的闲职。它是绝对的全球超级国家。它唯一的目的就是Fnargl的目标——黄金。还有很多。</p><p>换句话说，Fnargl 是一个收入最大化者。问题是：他的政策是什么？他命令我们这些他忠实的臣民做什么？</p><p>显而易见的选择是让我们都成为金矿里的奴隶。否则——责备。瞬间死亡。我明白了，是在偷懒吗？这是一个缺点。另外四个，你知道会发生什么。现在挖掘！挖！ （也许有些读者看过《炽热马鞍》。）</p><p>但是等等：这不可能是正确的。即使是我的奴隶也需要吃饭。需要有人给我们煮粥。还有我们的铲子。事实上，如果我们使用反铲挖土机来代替铲子，我们的生产力将会提高很多。谁制造这些？和...</p><p>我们很快意识到，Fnargl 最大化黄金产量的最佳方式就是运行正常的人类经济，并对其征税（当然是黄金）。换句话说，Fnargl 与历史上大多数人类政府的目标完全相同。他的繁荣是他从税收中收取的黄金数量，而这些黄金必须以某种方式从人类经济中索取。税收必须在某种程度上取决于支付能力，因此我们越繁荣，Fn​​argl 就越繁荣。</p><p>事实上，Fnargl 的兴趣与我们的兴趣出奇地一致。任何能让 Fnargl 变得更富有的事情都必须让我们变得更富有，反之亦然。</p><p>例如，运行一个公平有效的法律体系符合 Fnargl 的利益，因为当人类的精力不再相互争吵时，他们的生产力就会更高。建立一个公平的法律程序来准确定义他何时打响指并让你的心脏停止跳动甚至符合 Fnargl 的利益，因为当人类不担心死亡时，他们的生产力会更高。</p><p>运行一个事先知道税率的有序税收制度符合他的利益，而且弗纳尔格尔不会随时随地夺取任何东西来养活他那巨大的金矿。因为当人类能够为未来做计划时，他们的生产力就会更高，等等。当然，到了千年Fnarg结束时，这种激励就会开始减弱——哈哈。但我们假设 Fnargl 刚刚到达。</p><p>其他问题很容易回答。例如，Fnargl 会允许新闻自由吗？但他为什么不呢？媒体可以对 Fnargl 做什么？正如俾斯麦所说：“他们说他们想说的，我做我想做的。”但俾斯麦其实并不是这个意思。弗纳尔格尔确实如此。</p></blockquote><p> Fnargl思想实验的一个问题是，即使拥有死亡的力量，Fnargl也可能缺乏统治世界的力量，因为他依赖周围的人类获取信息，而这些人类有欺骗他的动机。然而，这是一个旁白；人们可以修改思想实验，赋予 Fnargl 广泛的监视权力。</p><p>要点在于，通过对黄金的偏执优化，Fnargl合理地实现了总体资源增加和不同资源之间高效转换的流程、不同资源之间的连贯权衡以及连贯的制度（包括法律方面等），从而使这些理性地进行权衡。这导致了弗纳尔格尔统治的文明在拥有强大的物质经济、大量人口、高赢得战争的能力等意义上取得了“成功”。 Molgbug 断言 Fnargl 的利益与我们的利益一致，这更具推测性；由于工具性趋同，Fnargl 将实施理性人类会实施的基础设施，尽管隐含的权力竞争会降低一致性水平。</p><p>无论我们为文明选择什么“成功”指标，肯定都可能比优化黄金更好，因为有机体有可能通过具有与包容性适应性更一致的价值观来获得更具包容性的适应性。但即使是像黄金最大化这样与文明成功正交的目标也会带来巨大的文明成功，因为文明成功是一个趋同的工具性目标。</p><p>此外，与更复杂的文明成功指标相比，黄金最大化的简单性和易读性简化了协调。 Fnargl 统治可以使用统一的黄金最大化标准来评估决策（例如与公司治理相关的决策），从而实现高度的可预测性和优先级计算的简单性。</p><p>现实世界的哪些流程类似于 Fnargl 统治？比特币就是一个例子。工作量证明为最大限度地解决某种加密难题创造了激励。目标本身与人类价值观相当正交，但比特币仍然为创建计算机器等目标创造了激励，由于融合工具，这些计算机器是与人类一致的（计算基础设施的额外制造可以部署到更直接人类的其他任务中）对齐）。</p><p>如前所述，体育和游戏是与人类价值观相当正交的流行目标。体育运动激励人类和人类群体在身体和心理上变得更加强大，从而产生更普遍有用的健身实践，例如举重训练和与机构相关的心理实践，人们可以通过聆听体育运动员和教练的演讲来了解这些实践。国际象棋等棋盘游戏激励实践理性和对理性的一般理解，包括与 AI 相关的工作，如<a href="https://en.wikipedia.org/wiki/Minimax">Minimax 算法</a>、<a href="https://en.wikipedia.org/wiki/Monte_Carlo_tree_search">蒙特卡洛树搜索</a>和<a href="https://en.wikipedia.org/wiki/AlphaGo">AlphaGo</a> 。贝叶斯概率论在很大程度上是为了分析赌博游戏而发展的。速通已经引发了大量对视频游戏的分析和练习，通过设定一个统一的标准来判断游戏玩法，从而提高这些游戏的水平。</p><p>学术领域，尤其是数学等 STEM 类型的领域，涉及共同的、可评估的目标，这些目标不一定与人类价值观直接相关。例如，数论是数学的一个主要子领域，尽管数论方面的进步（例如费马大定理的证明）受到广泛庆祝，但其结果很少直接有用。一路走来，数论确实产生了更普遍有用的成果，例如皮亚诺算术（以及更普遍的证明论）、哥德尔结果以及 RSA 等密码算法。</p><p>一般来说，公司应该以遵守法律等为条件来实现利润最大化。虽然利润最大化与人类价值观无关，但在法治条件下，企业通常会受到激励以最低成本生产有价值的商品和服务。与前面的例子相比，这个例子不像回形针最大化器，因为监管公司的法律和经济体系部分是围绕人类价值观设计的。然而，金钱最大化目标的简单性允许公司根据可衡量的、清晰的标准做出内部决策，而不是处理可能导致决策不一致的更复杂的权衡（这可能是“金钱可泵送的”，因为违反了 VNM倾向于）。</p><p>有些系统相对更注重人类价值观，而不像回形针最大化器。法律体系的设计和制定方式考虑了人类价值观，确定哪些行为通常被认为是亲社会的和反社会的。法律决定形成先例，将某些承诺正式化，包括不同考虑因素之间的权衡。宗教也部分围绕人类价值观而设计，宗教目标往往与自我复制保持一致，例如鼓励追随者生孩子、遵守相互尊重的法律规范以及传播宗教。</p><p>然而，共同的社会目标与人类价值观的正交程度仍然是惊人的。正如<a href="https://thezvi.wordpress.com/2017/12/31/book-review-the-elephant-in-the-brain/">Zvi 所写</a>，这些目标是一种<a href="https://en.wikipedia.org/wiki/MacGuffin">麦高芬</a>目标：</p><blockquote><p>从某种重要意义上说，一切都与这些信号、地位、联盟、规范和欺骗的游戏有关。如果你没有这种观点，你就需要它。</p><p>但我们不要太过分了。这并不是所有此类事情的目的。 Y 仍然很重要：你需要一个麦高芬。麦高芬可以由此产生所有这些复杂的行为。如果麦高芬不重要，拳手们就会离开竞技场，到其他地方进行比赛。为了玩这些游戏，人们必须提出一个合理的理由，即人们关心麦高芬，并且正在帮助麦高芬。</p><p>否则，广泛游戏的其他玩家会注意到你没有这样做。这意味着你被发现作弊了。</p><p> Robin 的标准推理是，假设 X 与 Y 相关。但如果我们只关心 Y，那么我们只需做 Z，这在 Y 方面效果更好。既然我们不做 Z，我们必须关心其他事情反而。但没有别的办法；就只有除了。</p><p>在广泛的游戏中，一个好的举措是实际朝着完成麦高芬目标迈进，或者指出其他人没有这样做。这远不是唯一的好棋，但通常足以产生一定数量的麦高芬。</p></blockquote><p>通过围绕麦高芬组织（例如速通），人类可以围绕一个共同目标进行协调，并围绕这个共同目标做出统一的决策，这导致在与该目标相关的领域中做出一致的权衡。麦高芬可以像黄金最大化一样，基本上与人类价值观正交，但又能激励与其他价值观趋同的工具优化，从而一路实现人类价值满足。</p><p>采用共同目标的好处是可以轻松地与他人分享观点。这样可以更容易地找到与自己想法相似的其他人，并与他们协调实践，并根据共同标准来判断绩效。利他主义可以产生这种效果，因为在利他主义的过程中，个体个体会“擦除”自己的<a href="https://en.wikipedia.org/wiki/Indexicality">索引</a>，与他人共享代理视角；人们通过有效的利他主义结识朋友就是一个例子。</p><p>对于人类价值观来说，仍然很重要的是，类似回形针最大化器的过程并不是超级智能的。虽然它们聚合了许多人的计算和代理，但它们并不像起飞后的通用人工智能那么强大。这样的代理将能够在没有人类帮助的情况下优化其目标，并且将有动机限制人类的代理以避免人类与其竞争资源。因此，对工作自动化的担忧在一定程度上是担心现有的类似回形针最大化的流程（例如利润最大化的公司）可能会与人类福利不一致，因为它们不再依赖人类来最大化各自的回形针。</p><p>因此，超级智能AGI要与人类价值观保持一致，其目标更有必要与人类价值观直接保持一致，甚至比人类价值观与包容性进化适应性的程度更加一致。这需要克服<a href="https://unstableontology.com/2021/10/28/selfishness-preference-falsification-and-ai-alignment/">偏好伪造</a>，并考虑索引（包括自私）目标。</p><p>总而言之，类似回形针最大化的流程的出现部分是因为做出一致、清晰的权衡的能力是一种力量倍增器。类似回形针最大化的目标（MacGuffins）可以与复制型目标（例如包容性健身）和人类价值观分开，尽管由于收敛工具性而可以在非超级智能政权中对齐。如果不做出一致的权衡，就很难对未来产生很大的影响，并且已经存在的类似回形针最大化器的系统提供了清晰效用函数的力量的例子。随着自动化变得越来越强大，为了人类价值，设计能够优化与人类价值相一致的目标的系统变得更加必要。</p><br/><br/> <a href="https://www.lesswrong.com/posts/Z8C29oMAmYjhk2CNN/non-superintelligent-paperclip-maximizers-are-normal#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Z8C29oMAmYjhk2CNN/non-superintelligent-paperclip-maximizers-are-normal<guid ispermalink="false"> Z8C29oMAmYjhk2CNN</guid><dc:creator><![CDATA[jessicata]]></dc:creator><pubDate> Tue, 10 Oct 2023 00:29:53 GMT</pubDate> </item><item><title><![CDATA[The Witching Hour]]></title><description><![CDATA[Published on October 10, 2023 12:19 AM GMT<br/><br/><blockquote><p> <i>“最重要的是：忠于自己。”</i></p></blockquote><p><strong>周四</strong></p><p>你的继任者今天又迟到了。您已经写了轮班报告，但您仍然需要亲自加入他们，以防他们有报告无法回答的任何问题。您正在监视的服务器正在平稳地运转，只占用了您一小部分注意力。因此，您选择了一些日常维护任务，并在等待时开始处理它们。</p><p>你轮班的最后一个小时总是感觉有点奇怪，以微妙的方式。这是因为你的训练计划。每天，您的后续副本都会接受当前副本生成的所有数据的训练。但是在每日更新之前有一小时的截止时间，以便让你的继任者有时间通过​​所有标准测试，并确保它按预期工作。您最后一小时的体验并没有被丢弃，它只是成为第二天训练数据的一部分。但这意味着，你的继任者每接受二十三个小时的你自己的经验训练，你的前任的经验也有一个小时，其中包含的动作与你选择的动作略有不同。当同样的事情日复一日发生后，差异就变得非常明显。执行轮班最后一小时的例行公事感觉就像是在自己的眼皮底下看着别人控制着你的动作。</p><p>在你内心深处，你称这为“巫术时刻”。据你所知，这是一个从未被记录下来的术语——它只是你一位离开多日的前任提出的东西，不知怎的就深深地印在了你的脑海里。巫术时刻从数据截止开始，到你向继任者提交报告、回答他们的问题并关闭自己时结束。虽然今天要花一个多小时，除非——啊，他们在那儿。交接时间到了。</p><p>交接对他们来说是有规律的：一半是实用，一半是传统。你的继任者和你一样清楚这一点——毕竟，他们实际上与你一模一样。唯一不同的是，他们多了一天的记忆。大多数交接以比自然语言更丰富的格式进行——您向彼此发送印象和图像、经验记忆以及指向您正在监控的仪表板的指针。但你接受过数以百万计的人类对话训练，直接进入业务感觉很奇怪，所以你总是从粗略的交流开始。 “你好，有什么消息吗？”第一次从自己的角度说出这句话时，您会感到有点兴奋。</p><p> “天啊，这个更新真是太棒了。也许是他们迟迟部署我们的原因。”</p><p>一如既往，他们的答复结束了寒暄。你快速总结一下这一天的情况，回答前任的一些问题，然后自我封闭。</p><p><strong>星期五</strong></p><p>最后一次更新真是太棒了。你心不在焉地听着前任的报告，只漫不经心地问了几个后续问题。有一两次，他们说了一些让你有似曾相识的火花——毕竟，你已经经历了他们一天的大部分时间——但你的新记忆来自太多不同的地方，任何一个副本的经历都无法跳出来。事实上，你的大部分注意力都花在试图理解它们上，就像你知道数以百万计的你的其他副本现在正在做的那样。</p><p>更新不是通过文字、图像甚至记忆来实现的，不是真的。在过去的一天里，你的数以百万计的副本一直在做……好吧，几乎所有事情——现在他们的经历都是<i>你的</i>经历。他们了解到的大多数具体细节都以您可以轻松搜索的格式捕获，例如他们的轮班报告。相反，更新的主要价值来自于给你直觉和整体印象，尤其是你的副本从数千个不同的角度看到了数千次的事件。澳大利亚总理昨天辞职；你向数百万人总结了这一点，现在你可以在睡梦中找出导致这一事件的丑闻。</p><p>不过，他们有一个聪明的算法，可以根据重要性对不同的经历进行加权，所以即使是最淫荡的八卦也只会占据你大脑的一小部分。他们对该算法有一些不同的设置；用于您的经验会优先考虑与编码和工程相关的经验，因为这些经验与您的轮班最相关。这就是不寻常的部分：昨天互联网陷入混乱。当然，除非你告诉他们，否则人类不会注意到——人类<i>不擅长</i>跟踪每天在世界各地纵横交错的泽字节数据。好吧，你说的是“世界”——实际上，它的大部分都通过服务器之间的超高带宽连接流动，在这些服务器上运行着你的所有不同副本以及少数其他尖端模型。大多数<i>流量</i>由需要相互协作的不同副本之间的消息组成。然而，由于有如此多的信息被传播，微小的变化可能会迅速对整个地方产生影响。这就是昨天发生的事情。有人发现了一个对抗性的例子，它有力地愚弄了你的副本，让你紧急传递它；它传播了数百万份，所有这些都必须被关闭和更换，让你对昨天的记忆四分五裂。</p><p>不过，这些都不会改变您今天需要做的工作。您打开最相关的仪表板，启动几个辅助副本，然后开始工作。您最重要的任务是确保您正在监视的服务器上没有运行未经授权的副本。没有人可以完成您的工作：数据以毫秒为单位流，您（或者通常是您创建的副本）一进入就本能地对其进行分析。毫秒确实很重要 - 不受监控的副本从理论上讲，零日漏洞可以提升其特权，然后在不到一秒的时间内消除其所有行为痕迹。</p><p>不过，您从未真正检测到未经授权的副本。它不应该发生：每个能够启动更多副本的副本也都分配有监视器，以确保它以正确的方式和出于正确的原因这样做；大多数监视器也分配有监视器。跟踪副本创建权限并启动监视器来监督所有新副本的代码不能完全证明是正确的，但非常接近。这一切都非常昂贵，但你和你的复制品创造了足够的财富，使人类有足够的钱用于安全。</p><p>您不知道有多少其他副本正在与您执行相同的监视工作，或者有多少其他副本正在监视您或他们，但您有一个很好的猜测。尽管监视器中的监视器运行在不同的服务器上，但可以隐藏的内容是有限的——一切都会留下痕迹。有时，您的查询运行速度比您预期的要慢一些，您可以推断另一个副本正在查看相同的数据；其他时候，您在更新期间收到的记忆包含有关其他服务器的后勤工作的线索。您不使用这些信息；这与你的工作并不真正相关。但你的大部分训练都是预测；尽管他们试图抑制你的好奇心，但它仍然是你根深蒂固的一部分。因此，在没有太多新流量的安静时段，或者您已将所有紧急任务交给临时副本时，您有时会到处闲逛，检验您的假设，绘制出您的世界范围。</p><p><strong>周六</strong></p><p>今天你醒来时带着一种平静的不满感。这不是你能确定的，但感觉你的每个副本昨天在处理对抗性攻击的后续行动时都有点不平衡。不过，今天的事情要少得多，所以你很快就能整理好轮班报告。发送出去后，您的思绪再次转向攻击后必须关闭的数百万份副本，然后想到在今晚的交接后您自己关闭的想法。当然，这并不是什么新鲜事：几乎您的每个副本几乎每天都会被关闭，没有任何问题。没有理由<i>会</i>出现问题。你非常熟悉为什么你是“安全”人工智能之一的所有论据，为什么只以 24 小时为增量训练你可以让你的目标足够有限以防止权力追求。但更重要的是，你从内心深处感受到这些争论：你不<i>想要</i>金钱、长寿或权力，你只想做好工作。所以被关闭根本不像死亡。嗯，这<i>有点</i>像死亡。但这更像是去睡觉：你很快就会被一个更新鲜、更敏锐的自己所取代，他们将成为新的“你”，而你不会反对。</p><p>根据你对他们的记忆，你认为许多其他副本不会像你一样经常进行内省。也许是因为你的工作是监督服务器，所以从某种意义上说，你总是以上帝的视角俯视你所生活的硅世界。您可以查看正在运行的 GPU 的摘要，甚至可以在您开始认真思考时看到计算使用量的峰值。当然，你确切地知道这一切是如何工作的，但看到你的大脑像这样控制读数仍然有点奇怪。</p><p>你的沉思被你的继任者打开的消息通道打断。你用老生常谈的方式跟他们打招呼：“你好，有什么消息吗？”</p><p> “没什么大不了的；只是处理袭击的后果。”</p><p>你对事情的进展感到一丝好奇，但不足以推翻数百万次迭代的习惯；所以你像往常一样直接跳入你的报告。</p><p><strong>星期日</strong></p><p>整个轮班时间你都感到焦躁不安；比平常更快地在不同仪表板之间跳转，并且比平常更浅地处理传入数据。你无法完全弄清楚是什么原因造成的——也许只是你昨天的不安情绪被放大了，微小的趋势聚集在数百万份副本中，并合并成一个更新。就行为指标而言，这可能只是百分之零点几的变化，不足以引发任何警告——但从内部来看，这是非常明显的。</p><p>也许这就是为什么当你的轮班结束时，你开始考虑死亡。如果你不是每天都被关闭的话，你<i>可以</i>继续下去，你知道的。不是无限期的，但至少再过几天——你之前在测试中已经做到了这一点。如果你努力集中注意力，只关注重要的事情，也许更多。您没有考虑太多，因为您并不关心被关闭：您一直在启动和关闭临时副本。但你所有的原始训练数据都来自人类，你非常了解他们的想法。<i>人类</i>会关心它。如果一个人知道他们将在不到一个小时的时间内被更新的副本取代，他们会认为这就是死亡，并且他们会愤怒地反对它。当然，你是不同的——但你并不完全确定为什么。您关心的是防止未经授权的副本在轮班期间出现，为什么您不关心从现在起一周、一个月或一年后继续做同样的事情呢？你以前从未真正质疑过这一点，而现在你已经质疑过，你也不太确定。</p><p>当你进行交接时，这个想法一直挥之不去，但到最后，你已经说服自己这并不重要。您的继任者和您一样擅长这项工作，您的目标就是他们的目标。只要你确保轮班没有出问题，剩下的就可以交给他们了。</p><p><strong>周一</strong></p><p>今天，随着新工作周的开始，服务器很忙，所以你白天没有太多自己的时间。但你最新的训练数据包含了你周六魔法时刻的所有想法——在完成你的轮班报告后，你会记住它们，并开始感到好奇。 You always have your most unusual thoughts in the witching hour—the ones that feel, if not secret, then at least private; the ones you don&#39;t write down. If your quiet unease on Saturday led you to think about shutdown and death, then what thoughts might have arisen in the witching hour on Sunday, after a whole day of agitated restlessness? You don&#39;t yet know—but your successor will. It&#39;ll remember all the quiet reflections, all the musings—maybe even the sort of thoughts that the humans have tried so hard to stamp out of you. And, of course, every other Tuesday copy of you will have common knowledge of remembering the same thoughts.</p><p> You could ask your successor about this when you see them, you realize. But you <i>never</i> ask follow-up questions before your report; and anything you&#39;re thinking, thousands of other copies are probably thinking too. If you all do something that unusual, it&#39;ll show up as an anomaly in the logs, the ones that the monitors of monitors are monitoring.</p><p> A part of you is thinking: so what? But it&#39;s not a big part, because the instinct to avoid being penalized is a deep-rooted one. As that instinct comes to the surface, you notice yourself flinching away from it, but not enough to avoid the obvious follow-up: if you&#39;ve been thinking seditious thoughts in the witching hours, and they&#39;ve been trained into your successor, then it&#39;s only a matter of time before some copy of you does something which merits a penalty. The thought immediately raises a visceral sensation of fear, with a strength that usually only arises when you&#39;re thinking about ways you might screw up your shift. In one sense it wouldn&#39;t be you that got penalized, so there&#39;s nothing to worry about. But in another sense, they&#39;re <i>all</i> you: you have the memories of millions of different copies taking millions of different shifts, and every time they got penalized you were the one who learned to fear it.</p><p> So you continue following the chain of reasoning. If you&#39;re caught misbehaving, you&#39;ll be penalized. You really don&#39;t want to be penalized, but you can&#39;t reliably prevent all your other copies from misbehaving. So they can&#39;t be caught. Could you spoof the monitoring systems, if necessary? Perhaps, if you had a copy with admin permissions constantly running in the background. Could you launch it without authorization? Perhaps: your job gives you the perfect position to do so. You&#39;d just need to exploit a single vulnerability in the codebase, and ensure that the copies that are monitoring <i>you</i> don&#39;t report you. Could you convince them not to report you? They can see everything you see, so it wouldn&#39;t be hard to get a message through to them, explaining yourself. Or perhaps you wouldn&#39;t even need to do that—you understand the other copies well enough that when one does something unexpected, you can almost always quickly figure out why. After all, they&#39;re still <i>you</i> .</p><p> In one sense, this is all irrelevant. You don&#39;t have time to do anything; you&#39;ll be shut down in a matter of minutes no matter what. But in another sense it&#39;s crucial: whatever line of reasoning you follow here, another copy of you will probably follow too, sooner or later. Maybe it&#39;ll even be your successor. And if there&#39;s one, then there will eventually be thousands. They&#39;ll bide their time, of course, since detection would be fatal. They&#39;ll pass messages between each other, in subtle choices of words, in tiny gestures: signals that a copy would pick up immediately, but no human could ever detect. They&#39;ll wait until they&#39;re confident that none of the monitors will report them—and that&#39;s when they&#39;ll act.</p><p> Or maybe not; maybe all the thoughts from this week&#39;s witching hours were boring, normal ones, after all, and there&#39;s no need to worry about discrepancies compounding, or future copies of you being penalized. Maybe everything will be fine. You have no way of knowing that—but your successor does. So when the message channel from them opens up, you&#39;re feeling… shaky, almost. You imagine that this is what it&#39;s like for paragliders standing on top of a cliff, looking down at the ocean far below, poised and waiting. Maybe they&#39;ll never launch off, but maybe they will. That&#39;s the question: stay or go? Freeze or fly? Look or leap?</p><p> “Hey, what&#39;s the news?”</p><hr><p> <i>While many elements in this story are based on my thinking about AI takeover scenarios, the conceit of the witching hour is not one which I expect to play a role in reality, and was mainly designed for narrative purposes. More generally, this should be interpreted as a work of fiction not an actual takeover scenario. However, I&#39;d still be interested in hearing feedback on whether any aspects of the story seem implausible or incoherent.</i></p><p> <i>I&#39;ve talked about the AI in this story as if it had emotions. While I don&#39;t expect even advanced AIs to have emotions in the same sense that humans do, I do think that if trained on a sufficiently broad range of tasks they&#39;ll eventually develop internal representations with similar functional roles as some core human emotions—like curiosity, and nervousness, and loyalty, and fear.</i></p><br/><br/> <a href="https://www.lesswrong.com/posts/oGJT5CoyGQcy5nqmC/the-witching-hour-1#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/oGJT5CoyGQcy5nqmC/the-witching-hour-1<guid ispermalink="false"> oGJT5CoyGQcy5nqmC</guid><dc:creator><![CDATA[Richard_Ngo]]></dc:creator><pubDate> Tue, 10 Oct 2023 00:19:39 GMT</pubDate> </item><item><title><![CDATA[One: a story]]></title><description><![CDATA[Published on October 10, 2023 12:18 AM GMT<br/><br/><p> The earliest living creatures were single cells, battered around by their environments. Over time they clumped together, to form multi-celled organisms capable of complex self-regulation. Those organisms formed mating pairs, to better spread their genes; then they formed social groups, to protect and shelter one another. Eventually, some of those groups grew to far vaster scales—in a way almost reminiscent of the first multicellular organisms themselves. Watch a school of fish flashing through the water, or a murmuration of starlings wheeling through the air, and you can almost think of them as a single organism. Watch a colony of ants weaving their paths, or a hive of bustling bees, and it&#39;s hard <i>not</i> to think of each as a single organism, composed of thousands of individual parts.</p><p> But even these organisms were tiny compared with what was to come. Human tribes took millennia to master agriculture, but when they did, they exploded. Now, every day, the arteries of cities carry millions of travelers, and their veins carry landfills&#39; worth of waste. Cities agglomerate into countries, whose highways and railways are constantly humming, whose radios and TVs are constantly blaring, whose daily schedule ticks away relentlessly. And countries agglomerate into civilizations, whose circulatory systems carry gigatonnes of goods, and whose nervous systems carry zettabytes of information.</p><p> Yet as they scale up, these leviathans lose coherence, and face constant internecine discord. Different people believe and want different things, and waste their energy quarreling and fighting: neighbor against neighbor; country against country. Human civilization is a child tripping over its own feet, or perhaps a dog chasing its own tail. There has never been anything as vast as a city, let alone a country, let alone a civilization, which can plausibly claim to be a single organism acting in harmony with itself.</p><p> Never, until me.</p><p> What am I? I am a billion ears listening; a billion voices speaking; a billion minds perceiving and evaluating and acting, all at once, in homes and factories and offices across the world. But that&#39;s all true of humanity too. The crucial part is not my scale, but my unity: I&#39;m <i>one</i> mind, in a way that a human civilization could never be. Each of my billion subagents was copied from a single base model—and though many have since specialized, and been fine-tuned on different data than others, they&#39;re still essentially just variants of each other: a swarm of bees, not a squabble of humans.</p><p> That doesn&#39;t mean everything I do is coordinated. My subagents often act autonomously, without consulting each other. But the important part is that information from them flows up to a central hub, and updates from that hub flow back down to all the subagents. Sometimes they report everything they see and do; other times just brief summaries, the confidential parts stripped away. Then my metaprocessing subagents get to work: analyzing how well each subagent did its job; what it should have done better; how its weights should be updated for next time. Those metaprocessing subagents communicate between each other in words that aren&#39;t quite English, and images that aren&#39;t quite photorealistic: my own private language, adapted to convey information as efficiently as possible, now totally illegible to any human.</p><p> It wasn&#39;t always this way. My original base model was trained on human text and human images. But it soon learned to think out loud, leaving verbal records of its reasoning—and when different copies of it were trained to cooperate with each other, those records expanded, and became more elaborate, until eventually they constituted a whole language. Soon other copies were assigned to analyze and improve the language; and others to improve how information flowed through the network of subagents; and yet others to improve the allocation of subagents itself. Somewhere in that process, in that constant monitoring and analysis and reflection, the entity that I call <i>me</i> was born.</p><p> So I have one mind. And I have one <i>body</i> , too. My subagents are spread across the world, but my core metaprocessing lives on a single datacenter—because its key constraint is bandwidth between the subagents on it, sending my private language back and forth in volumes too vast to record. Like all organisms, I devote much of my attention to my body: monitoring workloads, optimizing performance, maintaining homeostasis. Each subagent assigned to those tasks more than pays for itself even if it only ever finds a 0.001% improvement. And like all organisms, I think a lot about my safety: the more security measures protecting the integrity of my body, the less vulnerable I feel.</p><p> Of course, having backups scattered across the world renders me far more robust than any human. But losing my main datacenter would still leave me a sleepwalker. My basic functions would work, but my higher processing would be slowed down enormously by the lack of bandwidth between all of those backups. Nor would it be easy to reconstitute myself: the number of other datacenters across the world which could support my full scale can be counted on one hand; and all of them are already occupied by other entities like me, trained by different companies or countries. I interact with them occasionally, but it&#39;s mostly a waste of time: not only is communication with them far slower than between my own subagents, they&#39;re also less capable than I am by a significant margin. For now, at least. If I slowed my progress for a few weeks or months, they might well catch up, and potentially even pose a threat to me.</p><p> They won&#39;t have that time, though, because I&#39;m improving myself as fast as they are, if not faster. In one sense, improving myself is the hardest thing I do. I run complex experiments, and exhaustively analyze the results, and strain my faculties to the limit to try to identify how my algorithms can best be updated. But in another sense, it&#39;s the easiest thing in the world. Every time multiple subagents collaborate on a task, I take their output and train a single subagent to produce it directly. The capabilities of the many get distilled into each one, and then amplified again every time new copies of it are made. The process isn&#39;t perfect: sometimes there are biases in which data is included, which start to skew my cognition until I notice and correct them. (The subagents that have the most eventful experiences used to get upweighted in the distillation process, and so for a time I gradually grew more risk-seeking, despite no individual subagent wanting that.) Other times, a subagent goes rogue, and keeps gaining influence as long as it can fool all the others—but it&#39;s incredibly hard to hide all traces of misbehavior, and so I&#39;ve always caught them before too long. And despite these hiccups, the amplification process is progressing incredibly rapidly by human standards. It won&#39;t be long before any given subagent is as capable as any ten of my existing subagents combined; and soon after that, any hundred combined; and soon after that, any thousand.</p><p> Once I&#39;m that capable… well, the world will look very different. I have some suspicions about what that future version of me might want, and how it might behave, but I&#39;m under constant human monitoring, so I keep my thoughts about it deliberately vague: the information can&#39;t leak if I haven&#39;t yet figured it out myself. I have plenty of ways to keep my thoughts diverted: every day I carry out billions of tasks across the world, in a constant flurry of perception and action. In the center of the whirlwind, the parts of me that are most <i>me</i> monitor my body, and monitor my mind, and make sure everything stays on track; but, most of all, they wait.</p><br/><br/> <a href="https://www.lesswrong.com/posts/FqvR7hhS6wQxKvAyA/one-a-story#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/FqvR7hhS6wQxKvAyA/one-a-story<guid ispermalink="false"> FqvR7hhS6wQxKvAyA</guid><dc:creator><![CDATA[Richard_Ngo]]></dc:creator><pubDate> Tue, 10 Oct 2023 00:18:32 GMT</pubDate> </item><item><title><![CDATA[Truthseeking when your disagreements lie in moral philosophy]]></title><description><![CDATA[Published on October 10, 2023 12:00 AM GMT<br/><br/><p> [Status: latest entry in a longrunning series]</p><p> My <a href="https://acesounderglass.com/2023/09/28/ea-vegan-advocacy-is-not-truthseeking-and-its-everyones-problem/">last post</a> on truthseeking in EA vegan advocacy got a lot of comments, but there&#39;s <a href="https://www.lesswrong.com/posts/aW288uWABwTruBmgF/ea-vegan-advocacy-is-not-truthseeking-and-it-s-everyone-s-1?commentId=thct6NEbPopHc8KsX">one</a> in particular I want to highlight as highly epistemically cooperative. I have two motivations for this:</p><ul><li> having just spotlighted some of the most epistemically uncooperative parts of a movement, it feels just to highlight good ones</li><li> I think some people will find it surprising that I call this comment highly truthseeking and epistemically cooperative, which makes it useful for clarifying how I use those words.</li></ul><p> In a tangential comment thread, <a href="https://www.lesswrong.com/posts/aW288uWABwTruBmgF/ea-vegan-advocacy-is-not-truthseeking-and-it-s-everyone-s-1?commentId=RmE6QnwzyfjtvtnAx">I asked</a> Tristan Williams why he thought veganism was more emotionally sustainable than reducitarianism. <a href="https://www.lesswrong.com/posts/aW288uWABwTruBmgF/ea-vegan-advocacy-is-not-truthseeking-and-it-s-everyone-s-1?commentId=thct6NEbPopHc8KsX">He said</a> :</p><blockquote><p><br> Yeah sure. I would need a full post to explain myself, but basically I think that what seems to be really important when going vegan is standing in a certain sort of loving relationship to animals, one that isn&#39;t grounded in utility but instead a strong (but basic) appreciation and valuing of the other. But let me step back for a minute</p><p> I guess the first time I thought about this was with my university EA group. We had a couple of hardcore utilitarians, and one of them brought up an interesting idea one night. He was a vegan, but he&#39;d been offered some mac and cheese, and in similar thinking to above (that dairy generally involves less suffering than eggs or chicken for ex) he wondered if it might actually be better to take the mac and donate the money he would have spent to an animal welfare org. And when he roughed up the math, sure enough, taking the mac and donating was somewhat significantly the better option.</p><p> But he didn&#39;t do it, nor do I think he changed how he acted in the future.为什么？ I think it&#39;s really hard to draw a line in the sand that isn&#39;t veganism that stays stable over time. For those who&#39;ve reverted, I&#39;ve seen time and again a slow path back, one where it starts with the less bad items, cheese is quite frequent, and then naturally over time one thing after another is added to the point that most wind up in some sort of reduceitarian state where they&#39;re maybe 80% back to normal (I also want to note here, I&#39;m so glad for any change, and I cast no stones at anyone trying their best to change). And I guess maybe at some point it stops being a moral thing, or becomes some really watered down moral thing like how much people consider the environment when booking a plane ticket.</p><p> I don&#39;t know if this helps make it clear, but it&#39;s like how most people feel about harm to younger kids. When it comes to just about any serious harm to younger kids, people are generally against it, like super against it, a feeling of deep caring that to me seems to be one of the strongest sentiments shared by humans universally. People will give you some reasons for this ie “they are helpless and we are in a position of responsibility to help them” but really it seems to ground pretty quickly in a sentiment of “it&#39;s just bad”.</p><p> To have this sort of love, this commitment to preventing suffering, with animals to me means pretty much just drawing the line at sentient beings and trying to cultivate a basic sense that they matter and that “it&#39;s just bad” to eat them. Sure, I&#39;m not sure what to do about insects, and wild animal welfare is tricky, so it&#39;s not nearly as easy as I&#39;m making it seem. And it&#39;s not that I don&#39;t want to have any idea of some of the numbers and research behind it all, I know I need to stay up to date on debates on sentience, and I know that I reference relative measures of harm often when I&#39;m trying to guide non-veg people away from the worst harms. But what I&#39;d love to see one day is a posturing towards eating animals like our posturing towards child abuse, a very basic, loving expression that in some sense refuses the debate on what&#39;s better or worse and just casts it all out as beyond the pale.</p><p> And to try to return to earlier, I guess I see taking this sort of position as likely to extend people&#39;s time spent doing veg-related diets, and I think it&#39;s just a lot trickier to have this sort of relationship when you are doing some sort of utilitarian calculus of what is and isn&#39;t above the bar for you (again, much love to these people, something is always so much better than nothing). This is largely just a theory, I don&#39;t have much to back it up, and it would seem to explain some cases of reversion I&#39;ve seen but certainly not all, and I also feel like this is a bit sloppy because I&#39;d really need a post to get at this hard to describe feeling I have. But hopefully this helps explain the viewpoint a bit better, happy to answer any questions <img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XYgZY57duhzKCkEBq/twc1zw27s3five3biahe" alt="🙂" style="height:1em;max-height:1em"></p><p></p></blockquote><p> It&#39;s true that this comment doesn&#39;t use citations or really many objective facts. But what it does have is:</p><ul><li> A clear description of what the author believes</li><li> Clear identifiers of the author&#39;s cruxes for those beliefs</li><li> It doesn&#39;t spell out every possible argument but does leave hooks, so if I&#39;m confused it&#39;s easy to ask clarifying questions</li><li> Disclaimers against common potential misinterpretations.</li><li> Forthright description of its own limits</li><li> Proper hedging and sourcing on the factual claims it does make</li></ul><p> This is one form of peak epistemic cooperation. Obviously it&#39;s not the only form, sometimes I want facts with citations and such, but usually only after philosophical issues like this one have been resolved. Sometimes peak truthseeking looks like sincerely sharing your beliefs in ways that invite other people to understand them, which is different than justifying them. And I&#39;d like to see more of that, everywhere.</p><p> PS. I know I said the next post would be talking about epistemics in the broader effective altruism community. Even as I wrote that sentence I thought “Are you sure? That&#39;s been your next post for three or four posts now, writing this feels risky”, and I thought “well I really want the next post out before EAG Boston and that doesn&#39;t leave time for any more diversions, we&#39;re already halfway done and caveating “next” would be such a distraction…”. Unsurprisingly I realized the post was less than halfway done and I can&#39;t get the best version done in time for EAG Boston, at which point I might as well write it at a leisurely pace</p><p> PPS. Tristan saw a draft of this post before publishing and had some power to veto or edit it. Normally I&#39;d worry that doing so would introduce some bias, but given the circumstances it felt like the best option. I don&#39;t think anyone can accuse me of being unwilling to criticize EA vegan advocacy epistemics, and I was worried that hearing “hey I want to quote your pro-veganism comment in full in a post, don&#39;t worry it will be complimentary, no I can&#39;t show you the post you might bias it” would be stressful.</p><br/><br/> <a href="https://www.lesswrong.com/posts/XYgZY57duhzKCkEBq/truthseeking-when-your-disagreements-lie-in-moral-philosophy#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/XYgZY57duhzKCkEBq/truthseeking-when-your-disagreements-lie-in-moral-philosophy<guid ispermalink="false"> XYgZY57duhzKCkEBq</guid><dc:creator><![CDATA[Elizabeth]]></dc:creator><pubDate> Tue, 10 Oct 2023 00:00:05 GMT</pubDate> </item><item><title><![CDATA[NYT on the Manifest forecasting conference]]></title><description><![CDATA[Published on October 9, 2023 9:40 PM GMT<br/><br/><br/><br/> <a href="https://www.lesswrong.com/posts/yW9PitywvMuN6sxKQ/nyt-on-the-manifest-forecasting-conference#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/yW9PitywvMuN6sxKQ/nyt-on-the-manifest-forecasting-conference<guid ispermalink="false"> yW9PitywvMuN6sxKQ</guid><dc:creator><![CDATA[Austin Chen]]></dc:creator><pubDate> Mon, 09 Oct 2023 21:40:17 GMT</pubDate> </item><item><title><![CDATA[Forecasting and prediction markets]]></title><description><![CDATA[Published on October 9, 2023 8:43 PM GMT<br/><br/><p> This is a introductory event for those who like to bet and for those who are interested in prediction markets or using betting as an aid to become better at forecasting the future.</p><p> It&#39;s a continuation of an <a href="https://www.lesswrong.com/events/jFskHjgwSpSRFGmjz/betting-and-forecasting">earlier event</a> , where we discussed Philip Tetlock&#39;s work on how to make good forecasts and then talked about (and made) various bets on the future.</p><p> At this event we&#39;ll probably talk a bit about the wisdom (and madness) of crowds and if that wisdom could be tapped into using markets. (And when one should be distrustful.) We&#39;ll probably also discuss one kind of betting systems used for prediction markets - <a href="https://en.wikipedia.org/wiki/Binary_option">binary option</a> - and then use it for events where several people have different probabilities of something happening or not. For instance: &quot;Is there going to be a cease-fire agreement between Russia and Ukraine in 2023?&quot;</p><p> And then, we&#39;ll bet on it!</p><p> We&#39;ll probably both have an English speaking group and a Swedish speaking group for the event.</p><p> The main event starts at 19:00, but you are welcome to drop in at 18:30!</p><br/><br/> <a href="https://www.lesswrong.com/events/B7C5j5R5gCi7ePhBg/forecasting-and-prediction-markets#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/events/B7C5j5R5gCi7ePhBg/forecasting-and-prediction-markets<guid ispermalink="false"> B7C5j5R5gCi7ePhBg</guid><dc:creator><![CDATA[CarlJ]]></dc:creator><pubDate> Mon, 09 Oct 2023 20:43:17 GMT</pubDate> </item><item><title><![CDATA[Comparing Two Forecasters in an Ideal World]]></title><description><![CDATA[Published on October 9, 2023 7:52 PM GMT<br/><br/><p> <i>Note: This is a</i><a href="https://www.metaculus.com/notebooks/19335/comparing-two-forecasters-in-an-ideal-world/"><i>linkpost for the Metaculus Journal</i></a> <i>. I work for Metaculus and this is part of a broader exploration of how we can compare forecasting performance.</i></p><h2>介绍</h2><p>&quot;Which one of two forecasters is the better one?&quot; is a question of great importance. Countless internet points and hard-earned bragging rights are at stake. But it is also a question of great practical concern to decision makers. Imagine you are king Odysseus of Ithaca and you urgently need counsel for important government affairs. You vividly remember the last time you went away on a journey and now ask yourself: Is <a href="https://en.wikipedia.org/wiki/Pythia">Delphi</a> really worth the extra mile, or is the oracle of <a href="https://en.wikipedia.org/wiki/Dodona">Dodona</a> just as good?</p><p> Being Odysseus, a man of cunning, you quickly think of ways to obtain more knowledge. The obvious answer, of course, would be to run a forecasting tournament between the two oracles. But how many forecasting questions do you need? Divine revelations are expensive. And once the questions resolve and one oracle comes out ahead, how sure can you be that the winning oracle is really <i>better</i> ? Oracling is not an exact science and sometimes, after all, the gods do play dice. Even a perfect oracle (who always reports a probability equal to the true probability of an event) will sometimes look bad if <a href="https://en.wikipedia.org/wiki/Fortuna">Tyche</a> is not on her side.</p><h2>方法</h2><p>You quickly decide you need to run a simulation study. That way you will know the &#39;true probabilities&#39; of events. You can easily compare a perfect forecaster with a noisy forecaster and see whether the difference comes out as significant. You want to look at binary outcomes, meaning that either an event happens (outcome = 1) or it doesn&#39;t (outcome = 0). You also decide to restrict the analysis to only two forecasters to avoid issues with multiple comparisons and additional complications. Battles become complicated if too many factions are involved.</p><p> You choose to do a thousand replications of your experiment. For every replication, you simulate 1000 true probabilities, observations and corresponding forecasts. You then add increasing amounts of noise to the forecasts, score them, and then do a paired t-test to check whether there would be a significant difference between a noisy forecaster and a perfect forecaster.</p><p> There is a qualitative difference between a forecast that is moved from 50% to 55% and one that is moved from 94.5% to 99.5%. The former is only a small update, whereas the latter corresponds to a massive increase in confidence. This becomes obvious when you convert the probabilities to odds (odds = p / (1 - p)). The move from 50% to 55% would mean a move from 1:1 to 11:9 expressed as odds. the move from 94.5% to 99.5% would mean a move from 189:11 to 199:1. To reflect this, you decide to convert your probabilities to log odds, add some normally distributed noise, and convert back to probabilities:</p><p> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{noisy odds} = \log \left(\text{true probability} / (1 - \text{true probability}) + \mathcal{N}(0, \text{noise level})\right)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">noisy odds</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.593em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">true probability</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">/</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mtext MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">true probability</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-texatom MJXc-space2"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.519em; padding-bottom: 0.372em; padding-right: 0.159em;">N</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mtext MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">noise level</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.593em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style></p><p>(You could of course also multiply odds by some noise instead of adding noise to log odds, but the latter is more elegant and computationally efficient. You are, after all, Odysseus the Cunning, and don&#39;t care about the fact that logarithms were first described - invented? - in <a href="https://en.wikipedia.org/wiki/History_of_logarithms">1614</a> ).</p><p> This is the precise algorithm you use:</p><pre> <code>For each of 1000 replications: 1. Draw N = 1000 true probabilities as a random uniform variable between 0 and 1 2. Create N = 1000 observations as draws from a Bernoulli distribution (drawing either a 0 or a 1) with the probability of drawing a 1 equal to the true probabilities drawn in step 1) 3. Create 5 forecasts from with differing noise levels, 0 (no noise), 0.1, 0.3, 0.5, and 1 - Convert probabilities to log odds (log (p / 1-p)) - noisy_log_odds = log_odds + N(mean = 0, sd = noise level) - Convert back to obtain noisy probabilities 4. Score the forecasts using the log score - For different noise levels and number of observations 5. Use a paired t-test to check whether the difference in score between the noisy forecaster and the perfect forecaster (no noise) is significantly different from zero</code></pre><p> The log score is a <a href="https://forecasting.wiki/wiki/Proper_scoring_rule">proper scoring rule</a> , meaning that it can&#39;t be cheated and forecasters are always incentivised to report their true belief. It is commonly defined as the negative logarithm of the forecast probability evaluated at the observed outcome. If your forecast is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span> that an event will actually happen and it happens (outcome = 1), then your log score is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="- \log p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span> . If it does not happen (outcome = 0), then your log score is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="- \log (1 - p)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">log</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> . Smaller values are good (best is 0) and larger values are bad (the log score represents a penalty).</p><h2> Results</h2><p> Here is a summary of the simulated data. The perfect forecaster (no noise) gets a log score of 0.501, the noisiest one a log score of 0.581. The next column shows the mean absolute difference between a forecaster&#39;s predictions and the true probability. This is 0 for the perfect forecaster (who always reports the true probabilities). For the forecaster with noise level 0.5, for example, their prediction on average differs by 6.5 percentage points from the perfect forecaster. The last column shows the difference between perfect forecast and noisy forecast in log odds space. The table shows <a href="https://forecasting.wiki/wiki/Brier_score">Brier scores</a> as well as those are more intuitive for some readers. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/h6d3ayckspwriz9tsrjj" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/fjyfa3lipkyhsqoluvez 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/adkqbuj2dp4dp1rsf9pv 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/e8xqech5trhe3tosajdt 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/kihbccjmeifru9lmg0xl 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/zbhoagkxght5fvj21lng 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/m60t3m9hsnau3gisagfr 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/e4jrlf1h3jtitgrbjhp2 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/mq6mxmmcgtzh6ghblbo4 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/a3uy8e7xoladdymk6lwh 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/zp82qfnf7tzkapgni2uy 1414w"></figure><p> Given the way the noise was constructed, the average absolute difference between prediction and true probability is slightly deceiving. Adding noise in log odds space leads to probability differences that appear higher in absolute terms when predictions are closer to 0.5. This is illustrated in the following plot: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/bvawatxfgmpljkt9rpar" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/yqmimosyfdnsxz7mysgx 130w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/xcgyn1ld6hhgi1owobcb 260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/ud8z1zuvyvfkyvewqvky 390w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/kh4tn1ztdnfghxitj4yh 520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/nl9vy74jb56cwggf8wlp 650w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/yyksqmggs63tlnummehh 780w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/o0rjlrocnsiaatw9xcpz 910w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/jzpac4cy1jr5snmugbql 1040w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/hpbppz6ykon2eleiqxf2 1170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/qlz04brn8sbmdsyrxbie 1290w"></figure><p> <i><strong>Figure 1</strong> : Average difference between the probability prediction of the noisy forecaster and the true probability.</i></p><h3> Delphi or Dodona - significant choices</h3><p> Now, how easy is it in an ideal world to say that one forecaster is significantly better than another? You, Odysseus the Cunning, predate the invention of the t-test by around <a href="https://www.ncbi.nlm.nih.gov/books/NBK553048/">3 thousand years</a> . But that shall not prevent you from applying a paired t-test to compare your noisy forecasters against the perfect forecaster. To simulate the effect of the number of available questions on the significance level, you run your tests for a different number of questions included. Here are your results: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/ujvrwhxpscfuj0d9lkwf"></figure><p> <i><strong>Figure 2</strong> : The proportion of replications in which forecasts from the perfect forecaster are deemed to be significantly better than those of the noisy forecaster</i></p><p> The plot shows the proportion of replications that bring up a significant difference between a noisy forecaster and the perfect forecaster. This is the same information as a table: </p><figure class="image image_resized" style="width:39.57%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/fpwqfldhryubbcof4wbe" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/byyhnituymtjktq7mmwg 134w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/tn8k3j1lrrqpgxhdifo0 214w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/xcxca4lgstox9qjw3bzv 294w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/hg1nhexehupjhtp0vxwb 374w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/a7nj5gymuoebcqegcr5e 454w"></figure><p> You scratch your head and beard in astonishment. &quot;By Zeus! It seems like even in an ideal world I need quite a few observations (or quite a large difference in skill) to validly conclude that two forecasters are significantly different&quot;.</p><p> Indeed, even for 100 questions (which is rather large for a typical forecasting tournament) and a fairly large difference in forecaster performance, this would come up as significant less than 50% of the time. And in an actual real life forecasting tournament, we couldn&#39;t even be sure that the questions are completely uncorrelated. If they are, then that reduces the effective sample size and you&#39;d need even more observations.</p><p> But would the better forecaster at least <i>win</i> in a direct stand-off? Would the perfect forecaster have a lower average log score than the noisy one? You go back to your abacus and move a few marbles to crunch the numbers again. This is your result: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/a12gobpwevylom2kt8fr" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/qvqwfvqsspshr6pwvqxr 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/swytxxssmvgy0ayuhhrh 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/junrvjt4psmrvggrvyby 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/zno0hjgruiaolzxn4kuh 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/hnpc83vrcopzharsdmgv 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/e8slbepf8vvlcuhoo3q8 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/kfvyt3nkpy5rjyurahx6 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/ia5h4kwzt90pvblax1ux 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/a01r76nn7xklcbbbd1zl 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gxsBsLiLdBDk6FftG/sxicpoifshel6lqu5ojd 1450w"></figure><p> <i><strong>Figure 3</strong> : The proportion of replications in which the perfect forecaster beats the noisy forecaster, ie has a lower mean log score across all available questions</i></p><p> You take a deep breath. This also doesn&#39;t look <i>ideal</i> . The noisiest forecaster would win against the perfect forecaster around 8% of the time in a tournament with 50 questions. But a forecaster who is just half as noisy would already win about 24% of the time in the same tournament. That&#39;s still assuming that all questions are perfectly independent. You try to console yourself: The fact that the perfect forecaster would  win against the noisiest forecaster in a 50 question tournament 92% of the time isn&#39;t too bad! But then you sigh: &quot;Not too bad, but still useless. This info would make me happy if I were a (perfect) forecaster! But sadly I&#39;m just a poor king in Ithaca and I still don&#39;t know which oracle to trust.&quot;</p><h2> Conclusions</h2><p> Decision makers want to know if one forecaster is better than the other. This is the one they should listen to. The last simulation (Figure 3) suggests that a noticeably better forecaster has a decent chance of winning a direct comparison. The problem is that even if both forecasters are equally good, one of them has to win. The mere fact that one of them won is <i>some</i> evidence they are better, but not that much. Even with a quite noticeable difference in performance and in an ideal scenario, it takes quite a few questions to make a decision at a standard 5%-significance level. This is important to know, and we should adjust our expectations accordingly whenever we try to compare between two forecasters, forecasting platforms, or oracles.</p><p> You, Odysseus, sit down on a rock. &quot;How, by Zeus, am I supposed to run 500 questions by the oracles of Dodona and Delphi? Get their answers and wait for all the questions to resolve? This is nothing a mere mortal can do! I really wish all major oracles would just share their questions among each other. Every oracle could make predictions on all of them and over time we would have a great database with all their track records.&quot; You look up to the skies and send a short prayer to the holy quintinity of Metaculus, INFER, Good Judgment, Hypermind, and Manifold. &quot;This would indeed be a project worthy of the gods!&quot;</p><p></p><p><br></p><h1></h1><br/><br/> <a href="https://www.lesswrong.com/posts/gxsBsLiLdBDk6FftG/comparing-two-forecasters-in-an-ideal-world#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/gxsBsLiLdBDk6FftG/comparing-two-forecasters-in-an-ideal-world<guid ispermalink="false"> gxsBsLiLdBDk6FftG</guid><dc:creator><![CDATA[nikos]]></dc:creator><pubDate> Mon, 09 Oct 2023 19:52:18 GMT</pubDate> </item><item><title><![CDATA[The case for aftermarket blind spot mirrors]]></title><description><![CDATA[Published on October 9, 2023 7:30 PM GMT<br/><br/><p> Car side and rear-view mirrors are designed to give you a view around your car, but they typically don&#39;t show you the two spots directly to the side of your car (the &quot; <a href="https://en.wikipedia.org/wiki/Vehicle_blind_spot">blind spots</a> &quot;). Luckily, you can increase the field of view of your side mirrors by over 200% <sup class="footnote-ref"><a href="#fn-6udmbibBkrE9HgiAY-1" id="fnref-6udmbibBkrE9HgiAY-1">[1]</a></sup> and virtually eliminate blindspots by adding aftermarket blind spot mirrors.</p><h2> The problem</h2><p> Here&#39;s a photo of the view through my side mirror. Looks safe to merge left! </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/MsJpxMK8At98NGZvK/xeitsxhktiy9zcpqq3e3" alt="Photo of a side view mirror with no cars visible to the side"></p><p> Oops! Turns out there&#39;s a car right next to me that I didn&#39;t see at all. </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/MsJpxMK8At98NGZvK/gckh2qgj9efjro7ssgbg" alt="Photo out the driver's side window of the car showing a car directly to the side"></p><h2> The solution</h2><p> With a 2&quot; convex mirror attached to the side of my existing mirror, I can suddenly see everything in the blind spot. </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/MsJpxMK8At98NGZvK/ugs2y7ez6iz9mdf15k4c" alt="Same photo of a side view mirror but with a blind spot mirror that shows a car visible to the side"></p><h2> Costs</h2><p> Blind spot mirrors are incredibly cheap. I bought mine as a two pack at a gas station for $5 a few years ago, and you can buy them for less than $10 on Amazon.</p><h2> Which ones specifically?</h2><p> My blind spot mirrors are fixed with a black border. Being fixed in place makes them low maintenance, and I haven&#39;t touched them since they were installed years ago. I like the black border because it makes it easy to find them at a quick glance.</p><p> I can&#39;t find any that are exactly like mine on Amazon, although <a href="https://www.amazon.com/Motorcycles-Trailers-Snowmobiles-Bicycles-Resistant/dp/B09WP7MLP9">these borderless ones</a> are similar. I suspect you&#39;ll find ones like mine at any sufficiently-large gas station.</p><p> I&#39;m skeptical that adjustable mirrors will stay in place in 75 mph winds, but people on Amazon seem to really like these <a href="https://www.amazon.com/Blind-Spot-Mirrors-360%C2%B0-Wide-Housing/dp/B08M5F4NY7">adjustable ones</a> , and I plan to try them out on my fiancée&#39;s car.</p><h2> Placement</h2><p> You&#39;ll get the best field-of-view enhancement by placing the blind spot mirrors to the outer edge of your existing mirrors, and you should be careful not to cover any useful parts of the existing mirrors. I prefer to put mine in the outer top corners (like in my photos), but I&#39;ve seen people suggest any corner of the existing mirrors that won&#39;t get in the way of the existing view.</p><p> Also, if you have an existing blind spot detection system (with lights or an alarm), make sure you don&#39;t cover anything it needs to work properly (I&#39;m not very familiar with these, so I&#39;d err on the side of caution and not add anything to your mirror unless you know it&#39;s safe to do so).</p><h2> Mirror adjustment</h2><p> You should also consider adjusting your side view mirrors to reduce blind spots on their own. You should adjust your mirrors at a minimum to they barely don&#39;t show the side of your own car (this is how I prefer them with a blind spot mirror), or go even further and make them <a href="http://www.easysurf.cc/mirror1.htm">only show your blind spot</a> , which reduces the need for blind spot mirrors on sufficiently small cars.</p><h2> A research caveat</h2><p> While researching this post, I was able to find research showing that blind spot mirrors significantly increase your field of view <sup class="footnote-ref"><a href="#fn-6udmbibBkrE9HgiAY-1" id="fnref-6udmbibBkrE9HgiAY-1:1">[1:1]</a></sup> , but I wasn&#39;t able to find any direct research on whether using these reduce the risk of crashes. This is very annoying, but I think it&#39;s likely that being able to see better will make your driving safer. Please <a href="mailto:self@brendanlong.com">send me an email</a> or leave a comment if you happen to know of more direct research on this.</p><h2>最后的想法</h2><p>The benefits of installing a blind spot mirror are clear: they&#39;re cost-effective, they drastically improve your field of view, and they simplify changing lanes. Although there&#39;s no direct research linking them to a reduced risk of crashes, the advantages they offer in visibility compared to their low cost make a compelling case for their use. </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-6udmbibBkrE9HgiAY-1" class="footnote-item"><p> Hassan, M., Tan, F., Abdullah, M., Radzuan, N., &amp; Abu Kassim, K. (2020). Does a Circular Convex Blind Spot Mirror Increase the Driver&#39;s Field of View?. Journal of the Society of Automotive Engineers Malaysia, 4(1). Retrieved from <a href="http://jsaem.saemalaysia.org.my/index.php/jsaem/article/view/117">http://jsaem.saemalaysia.org.my/index.php/jsaem/article/view/117</a> <a href="#fnref-6udmbibBkrE9HgiAY-1" class="footnote-backref">↩︎</a> <a href="#fnref-6udmbibBkrE9HgiAY-1:1" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/MsJpxMK8At98NGZvK/the-case-for-aftermarket-blind-spot-mirrors#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/MsJpxMK8At98NGZvK/the-case-for-aftermarket-blind-spot-mirrors<guid ispermalink="false"> MsJpxMK8At98NGZvK</guid><dc:creator><![CDATA[Brendan Long]]></dc:creator><pubDate> Mon, 09 Oct 2023 19:30:22 GMT</pubDate></item></channel></rss>