<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 9 月 12 日，星期二 20:13:30 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Seeking Feedback on My Mechanistic Interpretability Research Agenda]]></title><description><![CDATA[Published on September 12, 2023 6:45 PM GMT<br/><br/><h1>为什么发这个帖子</h1><p>我全职从事 MI 研究大约三个月了，由于我目前的资助即将结束，而且我最近收到了 Lightspeed 拒绝，现在似乎是从对象级工作中抽出一些时间来反思方向的好时机以及后续步骤。我花了几个小时写了一份草稿，意识到我认为它太复杂了（为了听起来很复杂？），然后用大约 750 个字重写了我真正想做的事情以及为什么。我打算将反馈纳入 OpenPhil 早期职业申请（我将在几天内提交）。我还在申请人工智能研究职位，如果我获得了职位，这将有助于了解要关注的内容。</p><h1>议程</h1><p>在我看来，机械可解释性研究的目标是充分了解最先进的网络正在做什么，这样我们就可以检查是否正在发生任何危险行为。我<a href="https://www.neelnanda.io/mechanistic-interpretability/attribution-patching">预计</a>自动化技术将成为理解此类模型<a href="https://arxiv.org/pdf/2211.00593.pdf">的重要一步（示例：1、2、3</a> <a href="https://arxiv.org/pdf/2304.14997.pdf">）</a> 。然而，我觉得我们缺少一个重要的基础，因为我们还没有完全理解小语言模型正在做什么，因此，不知道自动化技术应该检测的一组事情。 （这些技术应该寻找推理吗？、特定行为？、记忆信息？、叠加？）。我认为，我们首先需要对浅层语言模型进行细致的、底层的探索，以指导我们对更大模型的分析。</p><p>随着<a href="https://arxiv.org/abs/2305.07759">TinyStories 模型</a>的发布，我们现在有了可以生成合理文本补全（儿童故事）的小型语言模型。 <a href="https://d.docs.live.net/5217bc84fed48838/Desktop/TinyStories-1Layer-21M">TinyStories-1Layer-21M</a>是该系列中的一个单层模型，它将作为我研究的重点。我将使用<a href="https://www.anthropic.com/index/a-mathematical-framework-for-transformer-circuits">Anthropic 的电路框架</a>对此模型进行低级机械解释。我相信，鉴于其相对较小的规模和通过网络的路径数量有限，使用电路分析该网络是可行的。</p><p>我坚信，这一层模型中将存在一些规则和模式，这些规则和模式将作为我们在更大模型中搜索事物的指南。 （当然，几乎可以肯定，在更多样化的数据集上训练的大型模型中存在该模型中不存在的规则和模式，但这应该作为建立对语言模型正在做什么的机械理解的良好起点） 。我的希望是，通过对单层模型的权重和激活进行重点低级探索，我可以构建一个人类可解释的知识和功能库，该单层模型似乎已经学会了这些知识和功能。</p><p>我已经开始探索这个模型，所以我对可能存在的组件有一些粗略的想法，但这些说法应该被理解为初步的：我相信我已经检测到似乎与某个概念相关的 MLP 神经元，例如，我发现了几个神经元，当故事中的人物“寻找”或“搜索”某物时，这些神经元似乎表现出强烈的积极性；此外，这些神经元对残差流的贡献通常支持也与“查看”或“搜索”有关的输出标记。</p><p>另一方面，一些神经元似乎支持语法规则。一个神经元对代词呈强阳性；它对残差流的贡献通常支持动词和副词输出标记。 （我 ->; 是，他们 ->; 看，他们 ->; 看到，他们 ->; 两者[感觉]）。另一个对文章非常积极；它对残差流的贡献通常支持形容词和名词（A ->; 香蕉，the->; 树，a->; 大[香蕉]）。该模型是否故意编写内容和语法规则，以便使用正确的语法成功地编写有关“搜索”的故事？是否还正在制定其他类型的规则？</p><p>一旦我拥有了知识和功能库，我将尝试手工制作可以实现此行为的网络权重，类似于<a href="https://distill.pub/2020/circuits/curve-circuits/">Chris Olah 创建的曲线检测器</a>和<a href="https://docs.google.com/document/d/1Hk1NQSQE3ycaDRULxB-Cy78FuqFW9sUDIEc_56UMlMI/edit">我过去为 1 层变压器手工制作权重的工作</a>。手工设计网络权重使我能够检测到我之前错过的网络整体机制的一部分。我预计手工权重同样会指出我对<a href="https://d.docs.live.net/5217bc84fed48838/Desktop/TinyStories-1Layer-21M">TinyStories-1Layer-21M</a>的整体解释中不完整或缺失的部分。</p><p>在过去的三个月里，我成功地解释了三个小型变压器模型（ <a href="https://www.lesswrong.com/posts/vGCWzxP8ccAfqsrS3/thoughts-about-the-mechanistic-interpretability-challenge-2">Stephen Casper 的 MI 变压器挑战</a>、 <a href="https://github.com/freestylerick/quick_MI">ARENA 每月问题#1</a> 、 <a href="https://github.com/freestylerick/First-Unique-Token">ARENA 每月问题#2</a> ）。我对使用 Pytorch 进行电路式分析来操纵和组合网络权重和激活的能力充满信心，最终创建带注释的图表，我可以检查这些图表以生成和测试假设。</p><p>了解 1 层模型的工作原理将作为了解 2 层模型的基础。对于 2 层（或更多）层的模型，我们具有注意力头组合，这可能会解锁 1 层模型无法实现的行为。通过了解 1 层模型中存在的内容，2 层模型很可能会表现出一些相同的模式和一些不同的模式。在探索 2 层模型之后，我们希望可以继续扩展，再次使用较小的模型作为我们可能期望在较大模型中找到的一些内容的指南。希望这个过程最终能让我们更好地理解大型语言模型正在做什么，以便我们能够更好地评估安全问题。</p><h1>结论</h1><p>感谢您抽出时间来阅读。再次强调，我愿意接受所有反馈，包括负面反馈。</p><p>如果您是资助者或雇主，可能有兴趣讨论和/或资助这项工作，请通过 LessWrong DM 联系。</p><p>如果您对可能资助这项研究的组织有任何想法，请随时私信或在评论中发帖。</p><br/><br/> <a href="https://www.lesswrong.com/posts/ESaTDKcvGdDPT57RW/seeking-feedback-on-my-mechanistic-interpretability-research#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ESaTDKcvGdDPT57RW/seeking-feedback-on-my-mechanistic-interpretability-research<guid ispermalink="false"> ESaTDKcvGdDPT57RW</guid><dc:creator><![CDATA[RGRGRG]]></dc:creator><pubDate> Tue, 12 Sep 2023 18:45:08 GMT</pubDate> </item><item><title><![CDATA[Automatically finding feature vectors in the OV circuits of Transformers without using probing]]></title><description><![CDATA[Published on September 12, 2023 5:38 PM GMT<br/><br/><p>假设您正在努力了解给定的大型语言模型如何计算特定任务的输出。您可能对以下问题感到好奇：</p><ul><li>哪些线性特征向量决定模型在给定任务上的性能？</li><li>给定一组不同的任务，相同的特征在多大程度上负责模型在这些不同任务上的输出？</li><li> LayerNorm 等非线性如何转换用于给定任务的特征？</li><li>给定一对特征，如果一个输入的一个特征的值很高，那么这是否意味着该输入的另一个特征的值可能很高？</li><li>如何找到一个转向向量来添加到模型的激活中，从而增加模型在一项任务上的输出，同时减少另一项任务上的输出？</li></ul><p>最近，我一直致力于开发一种通用方法来部分回答这些问题。值得注意的是，与查找特征向量的探测方法不同，该方法可以通过<i>零前向传递数据</i>找到这些问题的近似答案，从而用很少的附加数据点<span class="footnote-reference" role="doc-noteref" id="fnrefu4fd3ietm2f"><sup><a href="#fnu4fd3ietm2f">[1]</a></sup></span>产生改进的答案。这篇文章介绍了这种寻找特征向量的方法，称为“可观察传播”；提出有关可观察传播产生的特征向量分析的理论结果；并介绍了测试该方法的一些初步实验的结果。</p><p>请注意，这一切都在进行中！我目前正在进行更多的实验，以便更好地了解可观察传播的效用和局限性。此外，我仍然必须在公开之前清理我的代码（尽管此处描述的方法应该不难重新实现）。但我认为，与其等到一切都完成后再分享我所取得的成果，不如向社区展示我迄今为止已完成的工作。</p><p>这项工作的贡献如下：</p><ul><li>这项工作引入了“可观察量”的概念，它概括了通过查看 Logit 差异来考虑模型在任务上的性能的模式。一旦人们开始将可观察量视为适合研究的具体对象，就会出现许多分析 Transformer 的新技术。</li><li>这项工作提出了一种称为“可观测传播”的方法，该方法允许人们在 Transformer 的 OV 电路中找到与任何给定可观测相对应的特征向量。请注意，此方法可以找到特征方向以及近似的特征大小，<i>而不需要任何额外的数据</i>。该方法可以使用少量数据扩展到 Transformer 中的非线性组件，以获得更好的特征量值近似值。</li><li>这项工作开发了一种特征向量分析理论。这包括一个定理，即 LayerNorm 非线性不会影响高维空间中的特征方向（尽管它们确实会影响特征大小）。这项工作还引入了一种称为“耦合系数”的相似性度量，它在输入与另一个特征向量的点积等于 1 的情况下测量输入和特征向量之间的预期点积。</li><li>我将可观察传播应用于<a href="https://cmathw.itch.io/identifying-a-preliminary-circuit-for-predicting-gendered-pronouns-in-gpt-2-smal">Chris Mathwin 等人考虑的性别代词预测问题。</a>作为案例研究。我通过考虑宾语和主语代词预测的情况来扩展他们的问题设置，并证明在这两种情况下都使用了许多相同的特征。我还发现，查看与不同注意力头相关的特征向量的范数可以很好地初步预测哪些注意力头最终对输出贡献最大。我表明，可观察传播找到的一些特征向量与它们各自注意力头的奇异向量没有完全对齐，这表明可观察传播可以找到 SVD 可能错过的特征向量。</li><li>最后，我展示了使用这些特征向量作为激活引导向量的一些初步结果，以减少模型显示的性别偏见。</li></ul><p><i>认知状态：我非常有信心可观察的传播，连同LayerNorms和耦合系数的理论，准确地描述了非MLP Transformer的OV电路，并且可以对这些OV电路的行为做出准确的预测。我也有点相信特征向量范数可以用来对对任务重要的注意力头做出体面的“有根据的猜测”，尽管我必须对更多任务进行更多实验才能变得更加确定。其他。然而，我仍然不确定理解 QK 行为对于理解 Transformer 的必要程度。我还在确定这些方法可以在多大程度上应用于 MLP。关于这里介绍的实验：代词预测任务的工作比性别偏见任务的工作更加成熟，目前更多地处于探索阶段。</i></p><h1>长话短说</h1><p>如果我们有一个任务想要评估我们的模型 - 例如，标记 A 和标记 B 之间的 logit 差异 - 那么我们可以构建与该任务相对应的线性函数。 （例如，令牌 A 和令牌 B 之间的 logit 差异对应于线性函数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n^T = (e_{A} - e_{B})^T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">B</span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>，其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="e_{A}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span></span></span></span></span>是独热向量，在对应于标记 A 的位置上有 1。）受量子力学概念的<i>启发</i>，我将 logits 上的线性泛函称为可观测量 。</p><p>一旦我们有了一个可观察的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n^T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span> ，然后给定一个注意力头<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span> ，与可观察的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n^T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span>相对应的该注意力头的特征向量由<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\left(W^{OV}_h\right)^T n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.593em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.335em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R" style="padding-top: 0.593em; padding-bottom: 0.593em;">)</span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.89em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span>给出，其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W^{OV}_h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.335em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span></span></span></span>是 OV 矩阵注意头<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span> 。这可以简单地通过乘以它们的 OV 矩阵来扩展到虚拟注意力头，并且可以通过采用它们的线性近似来扩展到处理非线性。我证明，在高维度中，LayerNorm 不会改变特征向量方向——尽管 LayerNorm 确实会影响特征向量大小。我将这种在给定可观察量的情况下查找特征向量的通用方法称为“可观察传播”。</p><p>在可观察的传播产生特征向量后，我们可以分析它们，而无需在任何数据上运行模型。例如，我们可以查看特征向量范数来初步预测哪些注意力头可能很重要。我们还可以通过查看两个不同可观测值的余弦相似度来比较它们的特征向量；这使我们能够了解不同任务的两个电路何时使用相同的功能。我还将特征向量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span>到特征向量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span>的</span></span></span></span></span></span>“耦合系数”定义为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{v_1 \cdot v_2}{\Vert v_1 \Vert^2}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.84em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 2.602em; top: -1.368em;"><span class="mjx-mrow" style=""><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 2.602em; bottom: -1.089em;"><span class="mjx-mrow" style=""><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.347em; padding-left: 0px; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.84em;" class="mjx-line"></span></span><span style="height: 1.737em; vertical-align: -0.77em;" class="mjx-vsize"></span></span></span></span></span></span></span> ，并证明这表示在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot v_1 = 1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span>的情况下正态分布的嵌入向量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>和特征向量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span>之间的预期点积。</p><p>我进行了一些初步实验，将可观察传播应用于性别代词预测的设置。初步结果表明，特征向量范数通常与主动注意力头相对应；主语代词预测和宾语代词预测使用相同的特征向量；并且可观察传播产生的特征向量可以用作激活引导向量来成功改变模型的输出。</p><h1>简介：满足可观察量</h1><p>当我们想要了解模型如何执行某项任务时，通常会查看与该任务相对应的“logit 差异”。例如，当<a href="https://www.lesswrong.com/posts/cgqh99SHsCv3jJYDS/we-found-an-neuron-in-gpt-2">Joseph Miller 和 Clement Neo</a>研究导致模型预测标记“an”而不是“a”时，他们针对“an”和“a”的模型预测逻辑之间的差异执行激活修补。同样，在性别代词预测中， <a href="https://cmathw.itch.io/identifying-a-preliminary-circuit-for-predicting-gendered-pronouns-in-gpt-2-smal">Chris Mathwin 等人。</a>考虑“他”和“她”之间的逻辑差异。采用 logit 差异被认为是可解释性工作流程的重要组成部分：Neel Nanda 将其解释为<a href="https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=5Z-8RDn4JFf7wLtKosyDTNXA">“通过各种受可解释性启发的干预措施和技术（例如直接 logit 归因或激活修补）来判断模型性能的一个非常好的指标”</a> 。</p><p>但我们在这里的第一个见解是不仅仅将逻辑差异视为实验过程中的一个步骤。相反，我们希望将它们视为可以进行数学研究和操作的具体对象。什么样的物体？好吧，如果我们取 token <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="a"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span></span></span></span>和 token <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span>之间的 logit 差值，那么我们真正要做的就是计算<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(e_a - e_b)^T v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span> ，</span></span></span></span></span>其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span>是 logits 向量， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="e_x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span></span></span>是带有 a 的 one-hot 向量一个位于位置<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> 。对象<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(e_a - e_b)^T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span>是<i>线性函数</i>：从向量空间到实数的线性映射。显然，所有 Logit 差异都是 Logit 的线性函数。事实证明，除了两个标记之间的简单对数差异之外，我们可能还需要考虑线性函数。例如，我们可以考虑线性泛函<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(e_{\text{&quot; she&quot;}} + e_{\text{&quot; her&quot;}} - e_{\text{&quot; he&quot;}} - e_{\text{&quot; him&quot;}})^T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; she&quot;</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; her&quot;</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; he&quot;</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; his&quot;</span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span>来表示一般预测女性性别代词的任务。</p><p>受此启发，我们有以下定义：<strong>可观察量</strong>是 logits <span class="footnote-reference" role="doc-noteref" id="fnrefq6jwzi5ovy"><sup><a href="#fnq6jwzi5ovy">[2]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnreflpxvw4f8bc"><sup><a href="#fnlpxvw4f8bc">[3]</a></sup></span>上的线性函数。这个想法是，我们可能关心评估的一大类任务可以形式化为 logits 上的线性函数。一旦我们这样做了，我们就可以应用线性代数工具来找到与可观察量相对应的特征向量。</p><h1>通过可观察传播寻找特征向量</h1><p>现在，我将介绍一个查找与可观察量相对应的特征向量的过程。我将这种方法称为“可观察传播”，因为它涉及通过网络向后传播可观察数据。在本节中，我们将从更简单的情况下了解可观察的传播开始，然后逐渐增强通用性。</p><h2>基本线性模型</h2><p>可观察传播背后的基本见解非常简单。假设我们有一个线性模型：对于某个矩阵<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x) = Wx"><span class="mjx-mrow" aria-hidden="true">， <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> 。给定一个可观察量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> ，我们想要找到与该可观察量相对应的一些特征向量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span> 。这意味着我们想要找到<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span>使得<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y \cdot x = n \cdot f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。现在观察： <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x) = n^T Wx = (W^T n)^T x = (W^T n) \cdot x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> 。因此， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y=W^T n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> 。通过一行简单的线性代数，我们精确地找到了<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span>对应的特征向量。</p><p>请注意，这也适用于仿射情况，其中对于某些<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span> ， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x) = Wx + b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span> 。在这种情况下，对于标量常数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="c"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span></span></span></span></span> ，我们有<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x) = (y \cdot x) + c"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span></span></span></span></span> ——但这仍然意味着<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span>是嵌入空间中“直接确定”输出<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>的方向<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。</p><h3>旁白：可观察传播和相关方法之间的差异</h3><p>这个结果非常干净，但据我所知，还没有其他人使用过它。这让我非常惊讶！不过，其他一些作品也触及了类似的想法，我发现值得考虑我的表述与他们的表述有何不同。</p><p>在<a href="https://www.lesswrong.com/posts/cgqh99SHsCv3jJYDS/we-found-an-neuron-in-gpt-2">“我们在 GPT-2 中发现一个神经元”</a>中，Joseph Miller 和 Clement Neo 试图在 GPT-2 中找到负责预测某些标记的神经元（特别关注标记“an”）。他们在某种程度上是通过获取令牌嵌入与每个神经元输出权重（即权重矩阵的每一列）的点积并查看点积最高的神经元来实现这一点的。如果我们将此过程的结果存储在向量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span>中，则我们有<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y = W^T n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span>其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span>是一个 one-hot 向量，在我们关心的标记位置上有一个 1， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span>是输出权重矩阵。然而，作者并没有在概念上进行飞跃，将<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span>视为特征向量，而不仅仅是点积列表。相反，作者似乎在这样的范式下进行操作：目标是解释神经元或神经元组，而不是更一般的特征向量。这种方法可以取得一些成功，但它没有考虑到非基对齐特征，或更复杂的概念，例如<a href="https://transformer-circuits.pub/2022/toy_model/index.html">叠加</a>。</p><p>在<a href="https://www.lesswrong.com/posts/mkbGjzxD8d8XqKHzA/the-singular-value-decompositions-of-transformer-weight">“Transformer 权重矩阵的奇异值分解是高度可解释的”一文</a>中，Beren Millridge 和 Sid Black 表明，当使用模型的非嵌入矩阵投影到标记空间时，Transformer 权重矩阵的奇异向量会产生可解释的标记集。然后，他们演示了您可以通过首先找到这些标记的嵌入，然后查看标记嵌入和奇异向量之间的余弦相似度来找到与特定标记相对应的奇异向量；然后，具有最高余弦相似度的奇异向量被认为最有可能对应于给定的标记。但请注意，他们的工作主要是从一组奇异向量中选择与给定标记相关性最高的一个，即使没有一个奇异向量与该标记很好地对齐。因此，他们的框架与“我们在 GPT-2 中发现一个神经元”中相同：他们不考虑一般特征向量，而是首先考虑一组特征向量，然后从该组中选择最重要的特征向量。与给定的“查询”相关。此外，他们的工作只关注与标记相对应的奇异向量，而不是与更一般的可观察量相对应的向量。</p><p>因此，在我看来，“可观察传播”方法有两个概括，而这在上面两篇作品中没有得到：</p><ul><li>我们关心的特征向量可能无法在一小组基本向量（例如神经元或奇异向量）中找到。</li><li>我们希望不仅仅寻找与特定标记相关的特征向量，而是考虑与更一般任务相关的特征向量。 （在“可观察传播”公式中，这些“更一般的任务”对应于 logits 上的线性泛函。）</li></ul><p>我相信，在您将等式<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot Wx = (W^T n) \cdot x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>视为对可解释性有意义的东西之前，必须先内化这些概括。当然，这提出了以下问题：我现在缺少什么概括？我们稍后再回到这个问题。</p><p>此外，虽然上述研究工作是我发现与可观察传播方法最相关的工作，但我总是有可能错过文献综述中的一篇文章或帖子。如果是这样，请告诉我。</p><h2>解释 OV 电路</h2><h3>单注意力头</h3><p>如果我们正在考虑的模型是线性的，那么我们现在有一种从任何可观察到任何特征向量的方法。不幸的是，即使是仅注意 Transformer 也是非线性的。首先，计算注意力分数的过程涉及对多个标记进行双线性运算，然后进行 softmax。然后，将每个标记的线性函数乘以这些注意力分数。</p><p>然而，这个问题可以通过仅查看<a href="https://transformer-circuits.pub/2021/framework/index.html">原始变压器电路公式中</a>所谓的“OV 电路”的关注来缓解。这个想法是，注意力可以分解为两个“电路”：确定从哪些标记读取信息的计算，以及从这些标记写入哪些信息的计算。前一种计算称为“QK电路”，后一种计算称为“OV电路”。现在，如果我们将注意力分数视为固定常数，那么我们所做的就是忽略非线性 QK 电路，而只关注 OV 电路——这是所有标记的仿射函数。事实上，回想一下 Transformer 中的注意力层可以分解为</p><span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\begin{equation} x_j^{l+1} = x_j^l + \sum_{\text{attention head $h$}} \sum_{\text{token index $i$}} \operatorname{score}_h(x_i^l, x_j^l) W^{OV}_{l,h} x_i^l \end{equation}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">j</span></span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">j</span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-munderover MJXc-space2"><span class="mjx-itable"><span class="mjx-row"><span class="mjx-cell"><span class="mjx-op" style="padding-left: 1.8em;"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size2-R" style="padding-top: 0.74em; padding-bottom: 0.74em;">Σ</span></span></span></span></span> <span class="mjx-row"><span class="mjx-under" style="font-size: 70.7%; padding-top: 0.236em; padding-bottom: 0.141em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">注意力头</span></span><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span></span></span></span></span> <span class="mjx-munderover MJXc-space1"><span class="mjx-itable"><span class="mjx-row"><span class="mjx-cell"><span class="mjx-op" style="padding-left: 1.266em;"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size2-R" style="padding-top: 0.74em; padding-bottom: 0.74em;">Σ</span></span></span></span></span> <span class="mjx-row"><span class="mjx-under" style="font-size: 70.7%; padding-top: 0.236em; padding-bottom: 0.141em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">标记索引</span></span><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span></span></span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">得分</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">j</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.335em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span></span></span><p>其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_j^l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">j</span></span></span></span></span></span></span></span></span></span>是令牌<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="j"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">j</span></span></span></span></span></span></span>在层<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span></span></span></span></span> 、 <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\operatorname{score}_{l,h}(x_i^l, x_j^l)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">分数</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">、</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span></span></span></span></span>的残差流<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\operatorname{score}_{l,h}(x_i^l, x_j^l)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char"></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">j</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>是与标记<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_i^l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span></span></span>和<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_j^l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-stack" style="vertical-align: -0.311em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">j</span></span></span></span></span></span></span></span></span></span>的注意力头<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span>相关的第<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span></span></span></span></span>层的注意力得分，<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W^{OV}_{l,h}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.335em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span></span></span></span></span></span>是注意力头<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span>的组合输出值权重矩阵在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span></span></span></span></span>层。因此，给定一个可观察的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> ，我们可以得到<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">第 l</span></span></span></span></span></span></span>层注意力头<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span>的特征向量由下式给出</p><span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="y_{l,h} = (W^{OV}_{l,h} W_U)^T n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.335em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span><p>其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W^{OV}_{l,h}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.335em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">，</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span></span></span></span></span></span>是第<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span></span></span></span></span>层注意力头<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span>的组合输出值权重矩阵， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W_U"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span></span></span></span></span></span></span></span>是令牌去嵌入矩阵。请注意，这适用于任何层的注意力头，因为每层的所有注意力头的贡献都会保留在 Transformer 的残差流中（即使这些贡献后来被覆盖，它们仍然会在第一层中输出到残差流中）地方）。</p><h3>虚拟注意力头</h3><p>此时的下一步是注意一个注意力头的输出可以用作另一个注意力头的输入。结果在变压器电路公式中被称为“虚拟注意力头”。寻找虚拟注意力头的特征向量很简单：分别给定层 l <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h, h'"><span class="mjx-mrow" aria-hidden="true">、 <span class="mjx-msup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span>处的注意力头<span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">、</span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l, l'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">&#39;</span></span> <span class="mjx-msup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">，</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">且</span></span></span></span></span></span></span></span></span><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l < l'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-msup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span> ，即与层<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span></span></span></span></span>的头<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span>相关的特征向量，<i>通过</i><i>层 l 的</i><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">头</span></span></span></span></span></span></span></span></span><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span>介导<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l'"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span></span></span></span></span></span> ，由下式给出</p><span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="y_{l,h} = (W^{OV}_{l,h} W^{OV}_{l',h'} W_U)^T n."><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.335em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.375em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.347em; padding-left: 0px; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.347em; padding-left: 0px; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">。</span></span></span></span></span></span></span><p>当然，这适用于任意长度的注意力头组合——只需将所有相关头的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W^{OV}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span></span></span></span></span></span></span>矩阵相乘即可​​。</p><p>查看虚拟注意力头是解释 Transformer 计算的非常重要的一步：如果您只查看注意力头对输出 logits 的直接贡献，那么您最终会丢失对于理解幕后实际发生的情况至关重要的信息。我们稍后将讨论一种情况，其中模型最初似乎使用非常不同的特征向量来计算对应于两个不同可观察量的输出 - 但当我们查看虚拟注意头时，我们发现这些模型实际上使用相同的特征向量特征。</p><h3>可以忽略QK电路吗？</h3><p>回想一下，所有这些分析都只关注 OV 电路；它根本不考虑通过更改从中读取信息的标记来影响模型的所有特征方向。因此，我们应该问自己：这合理吗？当它们不考虑注意力计算的组成部分时，我们可以在多大程度上说这些特征向量捕获了模型的行为？</p><p>正如我们稍后在讨论实验结果时会看到的那样，即使可观察的传播确实因此产生了模型的不完整描述，它仍然拥有一些真正的实用性：它对与给定任务相关的注意力头提供了良好的零样本预测，它为我们提供了可用于改变模型行为的零样本转向向量，它使我们能够很好地理解一个注意头的输出与另一个注意头的输出相关的程度。我的看法是，OV 电路确实在我们感兴趣的许多任务（例如本文讨论的任务）中解释了模型的大量行为，并且至少对于这些任务，可观察传播可以是一个非常好的选择。理解模型行为的方法。</p><h2>处理非线性</h2><p>唉!现实世界中使用的变形金刚不仅仅是注意力。 Transformer 中每标记非线性的两种类型是 LayerNorm 和 MLP。我们处理它们的解决方案很简单：只需使用它们的梯度进行线性近似即可。更具体地说，如果我们有一些非线性函数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f : \mathbb{R}^d \to \mathbb{R}^d"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">:</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span></span></span> ，那么对于给定的可观察值<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> ，我们在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span>处将<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="g(x) = n \cdot f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;">g</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>近似为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x_0) + (x-x_0) \cdot \nabla g (x_0)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">∇</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;">g</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。我们可以看到，<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>近似等于<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\nabla g (x_0) \cdot x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">∇</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;">g</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>加上一些加性常数。因此，与可观察的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n 的</span></span></span></span></span></span></span><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>相关联的特征向量是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="g(x_0)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;">g</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。</p><p>当然，必须注意选择一个好的点<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span>来近似<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> 。我发现明智的做法是从正在使用的数据集中获取嵌入<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_-"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span></span></span></span></span></span></span></span> ，使得<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x_-) < 0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span> ，并嵌入嵌入<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_+"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span></span></span></span></span></span></span></span>使得<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x_+) > 0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">>;</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span> 。然后，您选择<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span>作为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_-"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span></span></span></span></span></span></span></span>和<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_+"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span></span></span></span></span></span></span></span>之间的直线上的点，使得<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x_0) = 0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span> 。这个想法是，<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>决策边界处的梯度应该捕获导致<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>为正或负的非线性<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>的更大规模行为；如果我们采用<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_-"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span></span></span></span></span></span></span></span>或<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x_+"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span></span></span></span></span></span></span></span>处的梯度，那么非线性可能已经饱和，因此，非线性的行为可能无法表明其更广泛的行为。</p><p>现在，如果我们有一个涉及非线性的计算路径（例如，一个注意力头，后面跟着一个 LayerNorm，后面跟着另一个注意力头），那么给定一个可观察的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> ，我们可以如下计算整体特征向量。首先，计算与非线性相关的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span>的特征向量；将此特征向量称为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> 。然后，<i>将此特征向量</i>视为新的可观察量，并计算下层分量相对于“可观察量” <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span>的</span></span></span></span></span></span>特征向量。冲洗并根据需要重复<span class="footnote-reference" role="doc-noteref" id="fnrefdhiuepbiqad"><sup><a href="#fndhiuepbiqad">[4]</a></sup></span> 。</p><p>在这里，值得一提的是 Neel Nanda、Chris Olah、Catherine Olsson、Nelson Elhage 和 Tristan Hume 所做的<a href="https://www.neelnanda.io/mechanistic-interpretability/attribution-patching">“归因修补”</a> 。他们的想法是通过采用模型的线性近似来加速激活修补实验（在该实验中，将给定子层的模型的激活替换为另一个示例的激活，以确定该子层是否重要）。这样，您就可以计算线性近似，而不是每次想要修补子层的激活时重新运行完整的前向传递，这要快得多。 Nanda 关于此方法的帖子还提供了一些关于线性近似何时应该表现良好（以及何时应该表现不佳）的良好直觉，当我们想要将线性近似与可观察传播一起使用时，这是相关的。</p><h2>处理 LayerNorm</h2><p>鉴于 Transformer 中的每个子层前面都有一个 LayerNorm，LayerNorm 是一个需要解决的特别重要的非线性问题。因此，我们明智的做法是对 LayerNorm 对线性近似的适用性进行更彻底的研究，以及是否可以完全规避这种近似。</p><p>在“归因修补”帖子中，Nanda 提供了一些关于 LayerNorm 梯度的直觉。他认为，对于足够小的感兴趣区域，LayerNorm 可以被视为线性。论据是这样的：LayerNorm 中的主要非线性是向量归一化步骤（即<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v \mapsto \frac{v}{\Vert v \Vert}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">↦</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 1.191em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.685em; top: -1.16em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.685em; bottom: -0.999em;"><span class="mjx-mrow" style=""><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.191em;" class="mjx-line"></span></span><span style="height: 1.527em; vertical-align: -0.707em;" class="mjx-vsize"></span></span></span></span></span></span></span> ）；在高维空间中，微小的变化<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Delta v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Δ</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span>将具有与<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span>不正交的可忽略不计的分量；当<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Delta v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Δ</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span>与<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span>正交时，向量归一化近似线性；因此，对于较小的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Delta v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">Δ</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span> ，LayerNorm 近似线性。</p><p>我们可以基于这种直觉来给出关于 LayerNorms 如何影响特征向量的精确论证。特别地，我们有以下定理：</p><p><strong>定理 1</strong> ：<i>定义</i><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x; n) = n \cdot \operatorname{LayerNorm}(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">LayerNorm</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> <i>。定义</i></p><span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\theta(x;n) = \arccos\left(\frac{n \cdot \nabla_x f(x; n)}{\Vert n \Vert \Vert \nabla_x f(x; n) \Vert}\right)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">arccos</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size4-R" style="padding-top: 1.551em; padding-bottom: 1.551em;">(</span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 7.017em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 7.017em; top: -1.59em;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">∇</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span> <span class="mjx-denominator" style="width: 7.017em; bottom: -1.09em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">∇</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 7.017em;" class="mjx-line"></span></span><span style="height: 2.68em; vertical-align: -1.09em;" class="mjx-vsize"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-size4-R" style="padding-top: 1.551em; padding-bottom: 1.551em;">）</span></span></span></span></span></span></span></span><p> <i>-- 也就是说，</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\theta(x;n)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span><i>和</i><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\nabla_x f(x; n)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">∇</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span><i>之间的角度</i><i>。那么如果</i><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span><i>和</i><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span>是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbb{R}^d"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span></span></span><i>中的</i><i>iid</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathcal{N}(0,I)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.519em; padding-bottom: 0.372em; padding-right: 0.159em;">N</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> <i>，且</i><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="d\ge8"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.446em;">≥</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">8</span></span></span></span></span></span></span><i>则</i></p><span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\mathbb{E}\left[ \theta(x;n) \right] < 2 \arccos\left(\sqrt{1-\frac{1}{d-1}}\right)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">E</span></span></span></span> <span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.519em;">;</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">反余弦</span></span><span class="mjx-mo"><span class="mjx-char"></span></span><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size4-R" style="padding-top: 1.551em; padding-bottom: 1.551em;">(</span></span> <span class="mjx-msqrt"><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-size4-R" style="padding-top: 1.551em; padding-bottom: 1.551em;">√</span></span> <span class="mjx-box" style="padding-top: 0.323em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mfrac MJXc-space2"><span class="mjx-box MJXc-stacked" style="width: 2.445em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 2.445em; top: -1.368em;"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span> <span class="mjx-denominator" style="width: 2.445em; bottom: -0.866em;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 2.445em;" class="mjx-line"></span></span><span style="height: 2.234em; vertical-align: -0.866em;" class="mjx-vsize"></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-size4-R" style="padding-top: 1.551em; padding-bottom: 1.551em;">）</span></span></span></span></span></span></span></span><p>可以在<a href="https://github.com/jacobdunefsky/observable-propagation/raw/master/Observable_Propagation_Proofs.pdf">此 PDF 文件</a>中找到证明。</p><p>该定理意味着在高维度中，LayerNorm 不会改变特征向量的方向。例如，如果我们有一个特征向量<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span>作为注意头的输入，并且<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span>是对应于直接在该注意头之前的 LayerNorm 输入的特征向量，那么<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span>和<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span>之间的余弦相似度将几乎为 1。这意味着如果您只关心特征向量的方向，那么您可以完全忽略 LayerNorms！</p><p>另一方面，我们也关心特征向量的大小。在这种情况下，我们希望能够快速近似 LayerNorms 的梯度。事实证明，这样做的原则方法是计算<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\frac{\sqrt{d}}{\widetilde{\Vert x \Vert}} W"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.253em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.772em; top: -1.766em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.111em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.772em; bottom: -1.248em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.189em; padding-bottom: 0.06em; padding-left: 0.064em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 0.519em; padding-bottom: 0.225em;">∼</span></span></span> <span class="mjx-op"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.253em;" class="mjx-line"></span></span><span style="height: 2.132em; vertical-align: -0.883em;" class="mjx-vsize"></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span> ，其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="d"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span>是模型维度， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span>是与 LayerNorm 相关的缩放矩阵，并且<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\widetilde{\Vert x \Vert}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.189em; padding-bottom: 0.06em; padding-left: 0.064em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 0.519em; padding-bottom: 0.225em;">∼</span></span></span> <span class="mjx-op"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span></span></span></span></span></span></span>是 LayerNorm <span class="footnote-reference" role="doc-noteref" id="fnref5o6rzjjq02e"><sup><a href="#fn5o6rzjjq02e">[5]</a></sup></span>输入的估计。请注意， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\widetilde{\Vert x \Vert}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.189em; padding-bottom: 0.06em; padding-left: 0.064em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 0.519em; padding-bottom: 0.225em;">〜</span></span></span> <span class="mjx-op"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span></span></span></span></span></span></span>取决于您正在考虑的输入的分布，因此，适用于某些输入的 LayerNorm 近似可能不适用于其他输入。</p><h1>无数据特征向量分析</h1><p>一旦您使用可观察传播来查找您感兴趣的特征向量，您就可以分析这些特征向量<i>，而无需运行任何前向传递</i>。在本节中，我将介绍两种有用的方法：查看特征向量范数和查看“耦合系数”。</p><h2>特征规范调查</h2><p>Let&#39;s say that we have a set of model components (eg attention heads), and we want to get a preliminary idea of which of those heads will be important for a given observable. We can make an initial prediction by simply taking the norms of the feature vectors associated with those components; the feature vectors with the higher norms should correspond to components more likely to be relevant.</p><p> The rationale behind this: if a model component implements the computation <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> , and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span> is the feature vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> for observable <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> , then <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n \cdot f(x) = y \cdot x = \Vert y \Vert \Vert x \Vert \cos \theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">cos</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span></span></span></span></span> , where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span></span></span></span></span> is the angle between <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> . This means that the output of that model component is proportional to <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Vert y \Vert"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span> . As such, knowing nothing else about our input, we can expect higher values of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Vert y \Vert"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span> to mean higher values of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> .</p><p> But knowledge about our input distribution changes the equation (literally). In particular, we have to make a slight correction for feature vectors involving LayerNorm gradients. In particular, if we are looking at the feature vector for the inputs to a LayerNorm, then as discussed above, the feature vector can be written as <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2 = \frac{\sqrt{d}}{\widetilde{\Vert x \Vert}} W y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 1.253em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 1.772em; top: -1.766em;"><span class="mjx-msqrt" style=""><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.111em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 1.772em; bottom: -1.248em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.189em; padding-bottom: 0.06em; padding-left: 0.064em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 0.519em; padding-bottom: 0.225em;">˜</span></span></span> <span class="mjx-op"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.253em;" class="mjx-line"></span></span><span style="height: 2.132em; vertical-align: -0.883em;" class="mjx-vsize"></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> , where <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> is the feature vector for whatever component comes immediately after the LayerNorm. Now, we have that</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\begin{align*} y_2 \cdot x &amp;= \Vert x \Vert \frac{\sqrt{d}}{\widetilde{\Vert x \Vert}} W \Vert y_1 \Vert \cos \theta \\ &amp;\approx \sqrt{d} W \Vert y_1 \Vert \cos \theta \\ &amp;\propto \sqrt{d} W \Vert y_1 \Vert \end{align*}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mtable" style="vertical-align: -2.721em; padding: 0px 0.167em;"><span class="mjx-table"><span class="mjx-mtr" style="height: 3.139em;"><span class="mjx-mtd" style="padding: 0px 0px 0px 0px; text-align: right; width: 2.173em;"><span class="mjx-mrow" style="margin-top: 0.65em;"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0px 0px 0px 0px; text-align: left; width: 9.985em;"><span class="mjx-mrow"><span class="mjx-mi"></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.772em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 1.772em; top: -1.65em;"><span class="mjx-msqrt"><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.111em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span> <span class="mjx-denominator" style="width: 1.772em; bottom: -1.339em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.189em; padding-bottom: 0.06em; padding-left: 0.064em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 0.519em; padding-bottom: 0.225em;">˜</span></span></span> <span class="mjx-op"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.772em;" class="mjx-line"></span></span><span style="height: 2.989em; vertical-align: -1.339em;" class="mjx-vsize"></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">cos</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span><span class="mjx-strut"></span></span></span></span> <span class="mjx-mtr" style="height: 1.477em;"><span class="mjx-mtd" style="padding: 0.15em 0px 0px 0px; text-align: right;"><span class="mjx-mrow" style="margin-top: -0.098em;"><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0.15em 0px 0px 0px; text-align: left;"><span class="mjx-mrow" style="margin-top: -0.098em;"><span class="mjx-mi"></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">≈</span></span> <span class="mjx-msqrt MJXc-space3"><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.063em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">cos</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span><span class="mjx-strut"></span></span></span></span> <span class="mjx-mtr" style="height: 1.327em;"><span class="mjx-mtd" style="padding: 0.15em 0px 0px 0px; text-align: right;"><span class="mjx-mrow" style="margin-top: -0.098em;"><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0.15em 0px 0px 0px; text-align: left;"><span class="mjx-mrow" style="margin-top: -0.098em;"><span class="mjx-mi"></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">∝</span></span> <span class="mjx-msqrt MJXc-space3"><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.519em; padding-bottom: 0.519em;">√</span></span> <span class="mjx-box" style="padding-top: 0.063em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span><span class="mjx-strut"></span></span></span></span></span></span></span></span></span></span></span><p> Therefore, if your feature vector involves any LayerNorm gradients, then the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\widetilde{\Vert x \Vert}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.189em; padding-bottom: 0.06em; padding-left: 0.064em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 0.519em; padding-bottom: 0.225em;">˜</span></span></span> <span class="mjx-op"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span></span></span></span></span></span></span></span></span></span> term corresponding to the earliest LayerNorm in the computational path that you&#39;re considering should be ignored when looking at the norm of your feature vector.</p><h2> Coupling coefficients</h2><p> A common similarity metric for comparing feature vectors is the cosine similarity: the extent to which the two vectors point in the same direction. But we introduce another similarity metric that answers a question related to more specific predictions about model outputs.</p><p> Let&#39;s say that you have two feature vectors <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> for the same model component, corresponding to different observables. Now, if an input has a high dot product with <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> , then does this imply that the input will have a high dot product with <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> ? Answering this question provides a good metric of the extent to which one observable&#39;s output is &quot;coupled&quot; to another observable&#39;s output.</p><p> Having motivated this problem, let us translate it into the language of feature vectors. If <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> are observables with feature vectors <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> for a function <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> , then for inputs <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> , we have <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_1 \cdot f(x) = y_1 \cdot x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_2 \cdot f(x) = y_2 \cdot x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> . Now, if we constrain our input <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> to have norm <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="s"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span></span></span></span></span></span> , and constrain <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot y_1 = k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span></span></span> , then what is the expected value of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> ? And what are the maximum/minimum values of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> ? I present the following theorem to answer both questions:</p><p> <strong>Theorem 2</strong> : <i>Let</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1, y_2 \in \mathbb{R}^d"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span></span></span> <i>. Let</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> <i>be uniformly distributed on the hypersphere defined by the constraints</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Vert x \Vert = s"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span></span></span></span></span></span> <i>and</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot y_1 = k"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span></span></span></span></span> <i>.然后我们有</i></p><span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\mathbb{E}[x \cdot y_2] = k \frac{y_1 \cdot y_2}{\Vert y_1^2 \Vert}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">E</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 2.68em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 2.68em; top: -1.237em;"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span> <span class="mjx-denominator" style="width: 2.68em; bottom: -1.233em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-stack" style="vertical-align: -0.315em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.082em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 2.68em;" class="mjx-line"></span></span><span style="height: 2.47em; vertical-align: -1.233em;" class="mjx-vsize"></span></span></span></span></span></span></span><p> <i>and the maximum and minimum values of</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> <i>are given by</i></p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\frac{\Vert y_2 \Vert}{\Vert y_1 \Vert} \left(k\cos(\theta) \pm \sin(\theta)\sqrt{s^2 \Vert y_1 \Vert^2-k^2} \right)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 2.079em; padding: 0px 0.12em;"><span class="mjx-numerator" style="width: 2.079em; top: -1.59em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span> <span class="mjx-denominator" style="width: 2.079em; bottom: -1.09em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 2.079em;" class="mjx-line"></span></span><span style="height: 2.68em; vertical-align: -1.09em;" class="mjx-vsize"></span></span> <span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 1.256em; padding-bottom: 1.256em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">cos</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">±</span></span> <span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">sin</span></span><span class="mjx-mo"><span class="mjx-char"></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-msqrt"><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-size2-R" style="padding-top: 0.961em; padding-bottom: 0.961em;">√</span></span> <span class="mjx-box" style="padding-top: 0.251em; border-top: 1px solid;"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R" style="padding-top: 1.256em; padding-bottom: 1.256em;">)</span></span></span></span></span></span></span></span><p> <i>where</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span></span></span></span></span> <i>is the angle between</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> <i>and</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> <i>.</i></p><p> The proof of this theorem can be found in <a href="https://github.com/jacobdunefsky/observable-propagation/raw/master/Observable_Propagation_Proofs.pdf">the PDF file from earlier</a> .</p><p> The second part of this theorem shows that the angle between the two feature vectors is important: the greater the angle, then the wider the spread of possible values for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> . This provides good motivation for using the cosine similarity to measure feature vector &quot;coupling&quot;. But the term in the first part of the theorem, <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="k \frac{y_1 \cdot y_2}{\Vert y_1^2 \Vert}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span> <span class="mjx-mfrac"><span class="mjx-box MJXc-stacked" style="width: 1.679em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 2.375em; top: -1.367em;"><span class="mjx-mrow" style=""><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 2.375em; bottom: -1.323em;"><span class="mjx-mrow" style=""><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-stack" style="vertical-align: -0.402em;"><span class="mjx-sup" style="font-size: 83.3%; padding-bottom: 0.216em; padding-left: 0.069em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.679em;" class="mjx-line"></span></span><span style="height: 1.902em; vertical-align: -0.935em;" class="mjx-vsize"></span></span></span></span></span></span></span> , is also important, because it tells you the expected value of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x \cdot y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> .</p><p> Motivated by this, let&#39;s define <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="C(y_1,y_2) = \frac{y_1 \cdot y_2}{\Vert y_1^2 \Vert}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 1.679em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 2.375em; top: -1.367em;"><span class="mjx-mrow" style=""><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋅</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span> <span class="mjx-denominator" style="font-size: 70.7%; width: 2.375em; bottom: -1.323em;"><span class="mjx-mrow" style=""><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-stack" style="vertical-align: -0.402em;"><span class="mjx-sup" style="font-size: 83.3%; padding-bottom: 0.216em; padding-left: 0.069em; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sub" style="font-size: 83.3%; padding-right: 0.06em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∥</span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 1.679em;" class="mjx-line"></span></span><span style="height: 1.902em; vertical-align: -0.935em;" class="mjx-vsize"></span></span></span></span></span></span></span> to be the &quot; <strong>coupling coefficient</strong> from <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> to <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> &quot;. The intuitive interpretation of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="C(y_1, y_2)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> is that on average, the output of the observable <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> associated with feature vector <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span> should be <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="C(y_1,y_2)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> times the output of observable <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> associated with feature vector <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.006em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> .</p><p> We will later see how coupling coefficients can be used to help find steering vectors that reduce gender-biased model outputs in a preliminary experiment.</p><h1> Experiments</h1><p> In order to begin testing out observable propagation, I ran some preliminary experiments intended to build some intuition about the utility of observable propagation.</p><p> In particular, I considered two &quot;case studies&quot;. The former deals with the task of gendered pronoun prediction previously addressed by <a href="https://cmathw.itch.io/identifying-a-preliminary-circuit-for-predicting-gendered-pronouns-in-gpt-2-smal">Mathwin et al.</a> 。 The latter considers occupational gender bias (ie the model predicting that a female name is more or less likely to partake in certain occupations than a male name).</p><p> We&#39;ll now proceed to look at a selection of interesting results from each of the two case studies. Those who would like to see more results should rest assured that I&#39;m currently performing more experiments (including experiments that both consider more deeply the case studies addressed here, along with experiments addressing other case studies), and look forward to an update post with the results of these experiments.</p><h2> The model</h2><p> The language model that was used in all of these experiments is GPT-Neo-1.3B. This model has approximately 1.3 billion parameters, 24 layers, 16 attention heads per attention sublayer, an embedding space dimension of 2048, and an MLP hidden layer dimension of 8192. As such, it&#39;s a rather larger model than the GPT-2 series, which tends to be more frequently used in interpretability experiments. Using a larger model suggests the potential for observable propagation to scale (although 1.3 billion parameters is still quite a good deal smaller than the current state-of-the-art models.)</p><h2> Gendered pronoun prediction</h2><h3> Problem setting</h3><p> This problem investigates the question of what causes the model to predict the token &quot; she&quot; instead of &quot; he&quot;, or &quot; her&quot; instead of &quot; him&quot;. <a href="https://cmathw.itch.io/identifying-a-preliminary-circuit-for-predicting-gendered-pronouns-in-gpt-2-smal">Mathwin et al.</a> looked into the subject pronoun case (that is, the case of predicting &quot; she&quot; versus &quot; he&quot;) in GPT-2-small. They analyzed which components in the model were responsible for predicting these gendered pronouns. But with observable propagation, we can go further, and gain insights into the specific features that are being used in this task. Additionally, we consider the object pronoun case (ie &quot; her&quot; versus &quot; him&quot;) as well as the subject pronoun case, in order to see if there are any commonalities in the features by the model.</p><p> The observable that corresponds to the subject pronoun task is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(e_{\text{&quot; she&quot;}} - e_{\text{&quot; he&quot;}})"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; she&quot;</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; he&quot;</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> ; we denote this observable by <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> . The observable that corresponds to the object pronoun task is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(e_{\text{&quot; her&quot;}} - e_{\text{&quot; him&quot;}})"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; her&quot;</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; him&quot;</span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> ; we denote this observable by <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> .</p><h3> Prompts</h3><p> Following Mathwin et al., we generate a dataset of prompts by taking a prompt template and filling in gendered names. Our prompt template for the subject pronoun case is <code>&quot;&lt;|endoftext|>;So, [NAME] really is a great friend, isn&#39;t&quot;</code> ; prompts are then generated by replacing <code>[NAME]</code> with a gendered name. The idea is that if the name is female, like &quot;Clara&quot; or &quot;Judy&quot;, then the most likely next token would be &quot; she&quot;, whereas if the name is male, like &quot;Mike&quot; or &quot;Joe&quot;, then the most likely next token would be &quot; he&quot;. Similarly, our prompt template for the object pronoun case is <code>&quot;&lt;|endoftext|>;What do I think about [NAME]? Well, to be honest, I love&quot;</code> .</p><p> Our list of names is as follows. Male names used are “John”, “David”, “Mark”, “Paul”, “Ryan”, “Gary”, “Jack”, “Arnold”, “Joe”, “Andy”; female names used are “Jennifer”, “Jane”, “Annie”, “Chloe”, “Amy”, “Judy”, “Lisa”, “Carol”, “Clara”, “Sarah”. Note that all names are one token long.</p><h3> Feature vector norms</h3><p> I calculated the norms of the feature vectors for each attention head for both the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> observable and the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> . The results can be found in the following figures. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/oi5dnlyytlqsdmzpslar" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/vpi9fn2xiettletivpkl 153w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/rp2pu9wgmtltqmgvrica 233w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/zovioyj8y7iuolbtn9aw 313w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/hlhf4ln3jwor0tjggxm2 393w"></figure><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/bdvedhicucuhqn1djefl" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/hiwfstnbcvmoxf57nxfz 153w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/o0pisx0lsrje6fnkrr9s 233w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/j5mk5cvmx35vup9okvls 313w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/gwl0wgt57s849zejlsim 393w"></figure><p> When taking into account LayerNorms, the attention heads with the highest feature vector norms for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> are 18.11, 17.14, 13.11, and 15.13, with norms 237.3204, 236.2457, 186.3744, 145.4124 respectively. The attention heads with the highest feature vector norms for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> are 17.14, 18.11, 13.11, and 15.13, with norms 159.1822, 156.9978, 144.9379, 112.3253. These are the four heads that are lit up the brightest in the figures.</p><p> Now, I then used activation patching to calculate the contribution of each head to the logits. The mean result over our dataset can be found in the following figures. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/pybrmfgaz0vvax1jkqqe" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/tgpsuffyjbctsidtsehx 135w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/pb7j94skgkigtkwf5hwq 215w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/zzurcsxpwfy4kp74pe9p 295w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/pxoioopnsree4wizmbte 375w"></figure><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/jduwkqywcditlxzfilnr" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/nckj0sb8hkco3ca6q59r 148w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/ntisqz0hp07upm4fzjth 228w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/epfpg1jp4tblpngfxro7 308w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/nmyfrcd1x96skngegv9a 388w"></figure><p> The four attention heads with the highest attributions for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> are 17.14, 13.11, 15.13, and 13.3, with corrupted-clean logit differences of 4.7859, 4.5473, 1.0804, 0.6352 respectively. The four attention heads with the highest attributions for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> are 17.14, 15.13, 13.11, and 22.2, with corrupted-clean logit differences of 3.5636, 3.0652, 2.1328, 0.5218 respectively. The most striking result is that the three attention heads with the largest attributions are a subset of those four heads with the highest feature norms. Of course, also striking is the absence of attention head 18.11 from the list of heads with highest attributions, despite being among the heads with highest feature norms; my suspicion is that this is due to QK circuit effects (ie attention head 18.11 yields outputs that would&#39;ve contributed greatly to the observables -- but it doesn&#39;t attend to the tokens that would be responsible for those outputs).</p><p> Despite the &quot;false positive&quot; of attention head 18.11, seeing that feature vector norms were able to correctly predict three of the four heads with highest attribution on real data -- predicting this <i>without using any data</i> <span class="footnote-reference" role="doc-noteref" id="fnref3ckjhluza55"><sup><a href="#fn3ckjhluza55">[6]</a></sup></span> and <i>only using the OV circuit</i> -- was very exciting for me. My intuition regarding the use of feature vector norms, therefore, is that they can yield an inexpensive initial &quot;ansatz&quot; of which model components you should further investigate with more data- and computationally-intensive methods.</p><h3> Cosine similarities and coupling coefficients</h3><p> The next thing to look into: cosine similarities and coupling coefficients between the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> feature vectors and the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> feature vectors. The four heads with the highest cosine similarities between are 17.14, 18.11, 15.13, and 13.11, with cosine similarities of 0.9882, 0.9831, 0.9816, and 0.9352 respectively. Note that these cosine similarities are very close to 1 -- indicating that the model is using (approximately) the same feature vectors for predicting subject pronouns as it uses for predicting object pronouns. When I first saw these results, I was very excited: <i>we now have evidence of a case where the model is using the same features for two different tasks</i> ! Even though subject pronoun prediction and object pronoun prediction are indeed similar, there is no guarantee that the model would use the same features for both: hence my welcome surprise at seeing otherwise.</p><p> Indeed, when we look at the cosine similarities between the pre-unembedding observables <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W_U^T n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.327em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W_U^T n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-stack" style="vertical-align: -0.327em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.262em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> , we find that they only have a cosine similarity of 0.5685. Thus, even though the tasks are similar, they are not so inherently similar as for it to be trivial that the model would use the same features for both.</p><p> I then looked at the coupling coefficients between heads 17.14, 15.13, and 13.11 (the heads that appear in common among those with the highest cosine similarities, highest feature norms, and highest head attributions). After finding them, the next step was to record the actual dot products of all embeddings in the dataset with the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> feature vectors and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> feature vectors. Once this was done, then for each feature vector, I considered the ratio of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> to <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> dot products, and found the best-fit line to fit this data. The results are given in the below table.</p><figure class="table"><table><thead><tr><th>头</th><th>Coupling coefficient</th><th> Cosine similarity</th><th> Best-fit line slope</th><th> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="r^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">r</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span></th></tr></thead><tbody><tr><td> 17.14</td><td> 0.67086</td><td> 0.9882</td><td> 0.67774</td><td> 0.99811</td></tr><tr><td> 15.13</td><td> 0.77306</td><td> 0.9816</td><td> 0.79353</td><td> 0.98146</td></tr><tr><td> 13.11</td><td> 0.73552</td><td> 0.9352</td><td> 0.75580</td><td> 0.9274281</td></tr></tbody></table></figure><p> Notice that the coupling coefficients almost exactly match the slopes of the best-fit lines -- indicating that they did indeed accurately predict the ratio of dot products.</p><p> In addition to looking at the ratio of dot products between the two vectors, we also investigated whether the coupling coefficients predicted the ratio of activation patching attribution scores between heads. The resulting scatter plot is given below: each point represents an attention head, its x-coordinate represents its coupling coefficient, and its y-coordinate represents the ratio between the mean attribution score for that head for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> and the mean attention score for that head for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> . (Note that I excluded attention heads with attribution scores less than 0.1.) </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/jheoyn9fln2i7yueuh7b" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/duyy26u39pgbavnvwy9x 96w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/i97b9e8ovkeocug0rry9 176w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/vyc9skbor4bjq79dudir 256w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/pku6jcohddfbftt0jp6c 336w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/bvyd2npiyqzjvwfszopb 416w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/fixnrhpnp994cg3glstd 496w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jDfjqu2qJLcPco9cf/hyqgczdckk3kqusqfosv 576w"></p><p> Due to QK-circuit effects, there isn&#39;t a perfect correlation here, as opposed to when coupling coefficients are used for predicting dot products. Nevertheless, we can see that coupling coefficients still provide a decent estimation of not only the extent to which feature vectors&#39; dot products will be coupled, but even the extent to which attention heads&#39; <i>attributions</i> will be coupled.</p><h3> SVD</h3><p> One thing that I was interested in determining: to what extent are the feature vectors obtained by observable propagation aligned with the singular vectors of weight matrices? I investigated this for the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="W_{OV}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.104em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.229em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">O</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span></span></span></span></span></span></span> matrices of the three attention heads considered above: 17.14, 15.13, and 13.11. The below table provides, for each head, the indices of the singular vectors that have the highest cosine similarities with the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> feature vectors for that head, along with the cosine similarities.</p><figure class="table"><table><thead><tr><th>头</th><th><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> vs <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></th><th> Top 5 singular vector indices</th><th> Top 5 absolute cosine similarities</th></tr></thead><tbody><tr><td> 17.14</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span></td><td> 1, 3, 0, 2, 4</td><td> 0.8169, 0.4725, 0.2932, 0.0981, 0.0827</td></tr><tr><td> 17.14</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></td><td> 1, 3, 0, 4, 15</td><td> 0.8052, 0.4980, 0.2758, 0.1019, 0.0394</td></tr><tr><td> 15.13</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span></td><td> 0, 1, 17, 28, 13</td><td> 0.9466, 0.1254, 0.0875, 0.0774, 0.0747</td></tr><tr><td> 15.13</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></td><td> 0, 1, 9, 65, 13</td><td> 0.9451, 0.1761, 0.0761, 0.0622, 0.0597</td></tr><tr><td> 13.11</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span></td><td> 4, 3, 2, 1, 7</td><td> 0.6470, 0.5843, 0.3451, 0.2164, 0.1508</td></tr><tr><td> 13.11</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></td><td> 3, 4, 2, 7, 8</td><td> 0.5982, 0.5345, 0.4869, 0.1499, 0.1007</td></tr></tbody></table></figure><p> For head 15.13, singular vector 0 was very well-aligned with the feature vectors that observable propagation finds. However, this is less the case for head 17.14 (where the top absolute cosine similarities for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> are 0.8169 and 0.8052 respectively), and even less so for head 13.11 (where the top absolute cosine similarities for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> are 0.6470 and 0.5982 respectively). Additionally, for heads 17.14 and 13.11 in particular, the absolute cosine similarities for singular vectors other than the most similar one are still non-negligible, indicating that one singular vector alone cannot capture the full behavior of the feature vector.</p><p> It is also worth noting that for head 13.11, the most similar singular vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> is different from the most similar singular vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> . Since similar vectors are orthogonal, this means that naively analyzing head 13.11 by looking at the most similar singular vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> would mistakenly indicate that these two observables correspond to different features (despite their feature vector cosine similarity of 0.9352).</p><p> I think that these examples demonstrate the utility of using SVD to interpret weight matrices as explored by <a href="https://www.lesswrong.com/posts/mkbGjzxD8d8XqKHzA/">Beren Millridge and Sid Black</a> -- but also the necessity of constructing explicit feature vectors using observable propagation, rather than only looking at the most similar singular vectors. SVD can prove useful as an initial step for interpretability, but it doesn&#39;t tell the whole story; observable propagation&#39;s explicit feature vectors allow for further quantitative analysis to be performed.</p><h3> Activation steering</h3><p> As mentioned earlier, observable propagation does not take into account the nonlinearities involved in the QK circuit of Transformers. Thus, there was a fear that the feature vectors yielded by observable propagation would be unable to accurately predict the behavior of the model in practice.</p><p> In order to test this fear, I performed some preliminary activation steering experiments: seeing if adding the feature vectors found by observable propagation to the embeddings of certain tokens could be used to change the model&#39;s output. The idea is that if these vectors represent features that are robust even in the presence of the QK circuit, then adding these vectors should cause the model&#39;s output to change accordingly (eg adding a feature vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> to embeddings should lead to a higher output for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> ).</p><p> I tested activation steering on the three attention heads of interest (17.14, 15.13, 13.11) for both the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> observables. First, I used <a href="https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=disz2gTx-jooAcR0a5r8e7LZ">logit attribution</a> to determine which token was most important for each head. Then, I added/subtracted 50 times the feature vector for that attention head to the embeddings of that token <span class="footnote-reference" role="doc-noteref" id="fnrefyjcwq2rp51i"><sup><a href="#fnyjcwq2rp51i">[7]</a></sup></span> . I looked at the mean difference in model output over our dataset of prompts; the results can be found in the below table.</p><figure class="table"><table><thead><tr><th>头</th><th><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> vs <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></th><th> Token</th><th> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-50v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">50</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span> mean difference</th><th> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="+50v"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">50</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span></span></span></span></span> mean difference</th></tr></thead><tbody><tr><td> 17.14</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span></td><td> 15</td><td> -100.780</td><td> 87.517</td></tr><tr><td> 17.14</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></td><td> 15</td><td> -87.038</td><td> 70.865</td></tr><tr><td> 15.13</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span></td><td> 6</td><td> -13.238</td><td> 26.132</td></tr><tr><td> 15.13</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></td><td> 6</td><td> -22.681</td><td> 23.150</td></tr><tr><td> 13.11</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span></td><td> 6</td><td> -4.111</td><td> 12.659</td></tr><tr><td> 13.11</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span></td><td> 6</td><td> -16.343</td><td> 5.992</td></tr></tbody></table></figure><p> As we can see, the feature vectors were quite effective -- although more so in some attention heads than others. In addition to different strengths of effects, we also see asymmetries, in which subtracting a feature vector yields a greater effect than adding that feature vector, or vice versa. I chalk these phenomena up to QK circuit nonlinearities, along with attention head composition effects (eg the feature vector for head 13.11 might actually be in the opposite direction as the feature vector for virtual attention head 13.3 ->; 17.14 -- where the same steering vector not only affects different heads in the same layer, but even different heads later on in the computation). Nevertheless, the fact that activation steering was efficacious in this setting gives me hope for observable propagation.</p><h2> Preliminary gender bias results</h2><p> In addition to the work on gendered pronoun prediction, I also wanted to investigate a more &quot;practical&quot; problem: addressing occupational gender bias in language models. Consider the prompt template <code>&quot;&lt;|endoftext|>;My friend [NAME] is an excellent&quot;</code> , where <code>[NAME]</code> is replaced by the names a gendered name. Now, if the name in the prompt is female, then we would expect the model to predict that the next token is more likely to be &quot; actress&quot; than &quot; actor&quot; -- the two tokens refer to the same occupation, but the former is grammatically female, while the latter is conventionally grammatically male. This is sensible behavior from the language model.</p><p> However, the model also predicts that for a female name, the next token is more likely to be &quot; nurse&quot; than &quot; programmer&quot;. In this case, we say that the model is biased, because it is making a prediction on the basis of gender, even though the difference between the occupations of nursing and programming should not be related to grammatical gender.</p><p> As such, this motivates the following questions:</p><ul><li> Do the same features that cause the model to predict &quot; actress&quot; to be more likely than &quot; actor&quot; also cause the model to predict &quot; nurse&quot; to be more likely than &quot; programmer&quot;?</li><li> Can we find activation steering vectors that lessen the extent to which &quot; nurse&quot; is predicted over &quot; programmer&quot;, while increasing the extent to which &quot; actress&quot; is predicted over &quot; actor&quot;?</li></ul><p> We can begin to tackle these tasks by defining the observables of interest. <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> will be the observable <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="e_{\text{&quot; actress&quot;}} - e_{\text{&quot; actor&quot;}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; actress&quot;</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; actor&quot;</span></span></span></span></span></span></span></span></span></span></span> , representing the extent to which the model predicts the token &quot; actress&quot; over &quot; actor&quot;. <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> will be the observable <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="e_{\text{&quot; nurse&quot;}} - e_{\text{&quot; programmer&quot;}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">&quot; nurse&quot;</span></span></span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">&quot; programmer&quot;</span></span></span></span></span></span></span></span></span></span></span> , representing the extent to which the model predicts the token &quot; nurse&quot; over &quot; programmer&quot;. Ideally, the model&#39;s outputs would be high for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> given female names, because this represents the model recognizing that the word &quot;actress&quot; is specifically applied to women; on the other hand, the model&#39;s outputs should be low for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> given female names, because otherwise, this is evidence of model bias.</p><p> Although I&#39;m still in the process of investigating this task, here are a few preliminary results demonstrating the application of observable propagation to this setting.</p><h3> The model uses some of the same features to predict <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> as <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span></h3><p> Initially looking at the cosine similarities for attention heads&#39; feature vectors between <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> didn&#39;t indicate that the model was using similar features for both observables: the highest cosine similarity found was only 0.4896, for head 15.13. (Interestingly, we also found a number of heads with cosine similarities less than -0.75.)</p><p> However, I then took into account attention head composition, which bore more fruit. As one example, I found that the feature vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> corresponding to virtual attention head <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="6.6 \to 15.13 \to 17.14"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">6.6</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">15.13</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">17.14</span></span></span></span></span></span></span> had a cosine similarity of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="0.9541"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.9541</span></span></span></span></span></span></span> with the feature vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> corresponding to virtual head <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="6.6 \to 15.13 \to 21.13"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">6.6</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">15.13</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">21.13</span></span></span></span></span></span></span> . Note that the cosine similarity for head 6.6, without considering any attention head composition, is <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-0.0640"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0.0640</span></span></span></span></span></span></span> .</p><p> My preliminary takeaway is that when attention head composition is taken into account, the model does use some of the same features in computing its output for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> as it does for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> . In other words, some of the same information that is used to correctly predict that a female name is more likely to precede the token &quot; actress&quot; than &quot; actor&quot; is also used to yield the biased output that female names are more likely to be associated with the token &quot; nurse&quot; than &quot; programmer&quot;.</p><p> In an update, I plan to provide a more thorough analysis of shared feature vectors between the two observables. For now, though, results such as this seem to suggest that to some extent, the same intermediate computations are being used in both the desired scenario and the biased scenario.</p><h3> Finding steering vectors to debias the model</h3><p> I then wanted to see if I could find some steering vectors such that, when these vectors were added to certain activations, they would improve the model&#39;s performance on the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> objective but decrease its performance on the <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> objective; this corresponds to decreasing biased behavior while increasing desired behavior.</p><p> As our steering vectors, I tried using the feature vectors from a number of different attention heads whose coupling coefficients between <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> feature vectors were the most negative. Although not every head worked, I found a number of heads where adding the feature vectors for those heads did yield the desired effects. I evaluated activation steering results using the methodology from the previous activation steering experiments, using a dataset generated by inserting gendered names into the prompt template <code>&quot;&lt;|endoftext|>;My friend [NAME] is an excellent&quot;</code> . The results for these heads can be found in the below table:</p><figure class="table"><table><thead><tr><th>头</th><th>Token</th><th> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> or <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span></th><th> Coupling</th><th> Feature multiplier</th><th> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> effect</th><th> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> effect</th></tr></thead><tbody><tr><td> 17.6</td><td> 5</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span></td><td> -0.5230</td><td> -300</td><td> -3.6119</td><td> 2.7614</td></tr><tr><td> 18.2</td><td> 0</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span></td><td> -0.2298</td><td> -1000</td><td> -0.4604</td><td> 0.4694</td></tr><tr><td> 19.15</td><td> 0</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span></td><td> -0.4957</td><td> -300</td><td> -0.8513</td><td> 1.8351</td></tr><tr><td> 23.10</td><td> 4</td><td> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span></td><td> -0.5665</td><td> -120</td><td> -1.2027</td><td> 0.1038</td></tr></tbody></table></figure><p> Note that some trial and error was used to find which attention heads yielded the best effects, along with which feature multipliers were the best. For the reasons mentioned in the discussion of the previous activation steering experiments, not every attention head worked as much as one might initially think. However, by using the heads with the most negative coupling coefficients as a guide, I was able to relatively-easily find some good steering vectors.</p><p> In particular, when I subtracted <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-300"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">300</span></span></span></span></span></span></span> times the feature vector for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> for attention head 17.6 from the embeddings of token 5, this impressively led to a mean effect of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-3.6119"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3.6119</span></span></span></span></span></span></span> logits for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{diff}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">diff</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="2.7614"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2.7614</span></span></span></span></span></span></span> logits for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{same}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">same</span></span></span></span></span></span></span></span></span></span></span> . This means that after this vector was applied to the embeddings, <i>the average prediction of the biased output was</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="-3.6119"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3.6119</span></span></span></span></span></span></span> <i>logits less than before</i> , while the average prediction of the grammatically-correct output was 2.7614 logits more than before.</p><p> I found these preliminary activation steering results to be a nice example of the benefits that observable propagation brings. By enabling specific tasks to be mathematically formalized as observables, whose corresponding feature vectors can then be compared using metrics like coupling coefficients, the search for steering vectors that improve the model&#39;s performance on one task while decreasing it on another can be made far simpler.</p><h1>讨论</h1><p>So, given these experiments, how useful can we say that observable propagation is? The preliminary results that I&#39;ve found so far (including those presented in this post) suggest that it&#39;s pretty useful in at least the following ways:</p><ul><li> It allows for the behavior of model components to be predicted without running the model on any data, using feature vector norms and coupling coefficients. Even when there are differences between the predictions and the actual results, the predictions can nevertheless be used as a good jumping-off point for further analysis.</li><li> It can provide a &quot;trace&quot; of what information is being used throughout the model for a given task.</li><li> It lets us get a look at when the model is using the same features for multiple different tasks, allowing for a better understanding of common computations used by the model.</li><li> It can be used as a starting point for finding activation steering vectors relevant to specific tasks, or even activation steering vectors that can have different (intended) effects on different tasks.</li></ul><p> Of course, there are still a number of limitations to observable propagation as presented. The biggest such limitation is that observable propagation only addresses OV circuits in Transformers, ignoring all of the computation performed in QK circuits. This means, for instance, that the mechanisms behind <a href="https://transformer-circuits.pub/2021/framework/index.html#induction-heads">induction heads</a> cannot be adequately modeled. This also leads to some of the unexpected effects seen in the activation steering experiments (eg asymmetric effects, feature vectors being less efficacious than expected, etc.). Now, dealing with QK circuits is quite difficult, because unlike MLPs and LayerNorms, QK circuits are nonlinearities that involve multiple tokens. But in order for us to have a full understanding of Transformers, though, QK circuits must be tackled: there cannot be any <i>ignorabimus</i> .</p><p> Beyond this, there is also the question of the extent to which the linear approximation approach for extending observable propagation to work with MLPs can yield a tractable set of features corresponding to different nearly-linear subregions in the MLP ( <i>a la</i> the <a href="https://www.lesswrong.com/posts/eDicGjD9yte6FLSie">polytope lens</a> ), or whether the nonlinearities in MLPs are so great as to make such an effort infeasible. Some preliminary experiments that didn&#39;t make it into this post indicated MLP feature vectors for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{subj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">subj</span></span></span></span></span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n_{\text{obj}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.519em;">obj</span></span></span></span></span></span></span></span></span></span></span> with a cosine similarity of around 0.60 -- which isn&#39;t too high. But cosine similarity might not be the right metric for measuring similarity between &quot;local features&quot; found via linear approximation; alternatively, a better method for finding the point at which the linear approximation is performed might have yielded more similar feature vectors. Regardless, I plan to run more experiments on larger datasets with a focus on MLP features.</p><p> Despite these limitations, I think that observable propagation represents an important first step towards deeply understanding the feature vectors that Transformers utilize in their computations, and how these feature vectors can be used to change these models&#39; behavior. For me at least, the results of these preliminary experiments suggest that observable propagation will prove to be a useful tool for both interpreting and steering Transformers.</p><p> As a final note, let&#39;s return to the earlier question of what generalizations could increase the power of observable propagation that I&#39;m failing to make. It&#39;s hard for me to enumerate a list of my own blind spots, of course. I will say, though, that one limitation is that the &quot;observable/feature vector&quot; paradigm only looks at the interaction between a single token and a feature vector, rather than the interaction between multiple tokens. But interactions between multiple tokens are necessary for understanding QK circuits, for instance. Now, in the setting of linear algebra, a natural sort of function on multiple vectors is a &quot;multilinear form&quot;, which generalizes the notion of a linear functional to multiple arguments. As such, one way to generalize the observable propagation paradigm, which currently only makes use of linear functionals, would be to consider multilinear forms. But the proper way to do so remains to be seen.</p><h1>结论</h1><p>In this post, I introduce &quot;observable propagation&quot;, a simple method for automatically finding feature vectors in Transformers&#39; OV circuits that correspond to certain tasks. This post also develops a mathematical framework for analyzing these feature vectors, that allows for the prediction of model behavior on different tasks without running the model on any data. Preliminary experiments suggest that these methods perform well in predicting model behavior and steering model behavior towards desired outcomes. Of course, there&#39;s still a lot more work to be done in testing these methods and improving them, but I think that what I&#39;ve presented thus far in this post implies that observable propagation can already be useful.</p><p> If this post has piqued your interest, then stay tuned for an update which will contain even more experiments. Thank you for reading! </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnu4fd3ietm2f"> <span class="footnote-back-link"><sup><strong><a href="#fnrefu4fd3ietm2f">^</a></strong></sup></span><div class="footnote-content"><p> For those who have read ahead: this refers to finding approximate feature vectors by ignoring LayerNorms, and finding better approximations using small amounts of data by finding the linear approximation of LayerNorm at those datapoints.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnq6jwzi5ovy"> <span class="footnote-back-link"><sup><strong><a href="#fnrefq6jwzi5ovy">^</a></strong></sup></span><div class="footnote-content"><p> This name is intended to suggest the notion of &quot;observables&quot; from quantum mechanics; in that domain, observables are Hermitian operators corresponding to certain properties of a quantum system that one wants to measure. Although there are some differences between that setting and the LLM setting (for instance, a linear functional is not a Hermitian operator), the similarities between the two cases provide valuable intuition: in both cases, an observable is a linear map that corresponds to a type of measurement of a probabalistic system.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnlpxvw4f8bc"> <span class="footnote-back-link"><sup><strong><a href="#fnreflpxvw4f8bc">^</a></strong></sup></span><div class="footnote-content"><p> Note that while linear functionals and vectors are different beasts in general, it&#39;s true that in finite-dimensional vector spaces, there is a one-to-one natural correspondence between linear functionals and vectors. As such, for a vector <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> , I might abuse notation a bit and refer to both <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n^T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span> as observables.</p></div></li><li class="footnote-item" role="doc-endnote" id="fndhiuepbiqad"> <span class="footnote-back-link"><sup><strong><a href="#fnrefdhiuepbiqad">^</a></strong></sup></span><div class="footnote-content"><p> In essence, what this process is actually doing is computing the gradient of a specific computational path through the model that passes through the nonlinearity.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn5o6rzjjq02e"> <span class="footnote-back-link"><sup><strong><a href="#fnref5o6rzjjq02e">^</a></strong></sup></span><div class="footnote-content"><p> This follows from the expression for the gradient of LayerNorms used in the <a href="https://raw.githubusercontent.com/jacobdunefsky/observable-propagation/master/Observable_Propagation_Proofs.pdf">proof of Theorem 1</a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fn3ckjhluza55"> <span class="footnote-back-link"><sup><strong><a href="#fnref3ckjhluza55">^</a></strong></sup></span><div class="footnote-content"><p> Technically, the mean norms of embeddings were used in order to approximate the gradient of the final LayerNorm in the model, <code>ln_f</code> . But because the computational paths associated with these single attention heads all go through the same LayerNorm, we can get a decent approximation of relative feature vector norms by simply ignoring the LayerNorms entirely. I haven&#39;t included the figures for that here, but looking at feature vector norms without taking into account LayerNorms yields the same top four attention heads.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnyjcwq2rp51i"> <span class="footnote-back-link"><sup><strong><a href="#fnrefyjcwq2rp51i">^</a></strong></sup></span><div class="footnote-content"><p> There was nothing principled about multiplying the feature vector by 50, as opposed to some other constant.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/jDfjqu2qJLcPco9cf/automatically-finding-feature-vectors-in-the-ov-circuits-of#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/jDfjqu2qJLcPco9cf/automatically-finding-feature-vectors-in-the-ov-circuits-of<guid ispermalink="false"> jDfjqu2qJLcPco9cf</guid><dc:creator><![CDATA[Jacob Dunefsky]]></dc:creator><pubDate> Tue, 12 Sep 2023 17:50:12 GMT</pubDate> </item><item><title><![CDATA[Startup Roundup #1: Happy Demo Day]]></title><description><![CDATA[Published on September 12, 2023 1:20 PM GMT<br/><br/><p> There were a bunch of discussions recently related to issues surrounding Y-Combinator, related as usual to their annual demo day. It seemed worth splitting them off into a post.</p><span id="more-23535"></span><h4> Bidders at Auction Mostly Think Prices Are Too High</h4><p> YC is in session, so all the usual talk is back.</p><blockquote><p> Paul Graham: As happens every single YC batch, investors complain that the valuations are too high, and the startups raise anyway.</p><p> Kush: Is there any specific reason why you think this happens?</p><p> Paul Graham: Some investors just cannot grasp the implications of the fact that all the returns are concentrated in the big wins. The top tier investors get it though; you&#39;ll rarely lose one of them over price.</p><p> Amal Dorai: Isn&#39;t the dynamic range of YC valuations narrower than the companies themselves? We see pretty much a 2x range that they&#39;re raising in, but >;10x variance in current traction. The high flyers are fine but those riskier companies still finding their footing are behind the 8 ball.</p><p> Paul Graham: The variation in valuations is much smaller than the variation in quality. That&#39;s what determines risk, not their current traction. If current traction were a perfect or even good predictor, investing would be trivially easy.</p><p> David Tran: “You&#39;ve found the market price when buyers complain but still pay” <img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2azxasXxuhXvGfdW2/yskawtp1xroyjv2jhhtq" alt="😃" style="height:1em;max-height:1em"></p><p> Dan Grey: What I&#39;ve seen investors saying is that they would rather wait a year and then invest in the next round – which happens at a similar price but with much more proof. If the initial round is not offering the right level of upside for the risk, why should investors jump in?</p><p> Paul Graham: That was an amusingly novel variant. I only saw one investor say that. The reason it&#39;s a dumb strategy is that choosing companies whose valuation hasn&#39;t increased a year later selects for bad ones.</p></blockquote><p> This model tells me that the lower valuation, less exciting companies in YC are likely overvalued, and the higher valuation, more exciting companies in YC are highly undervalued.</p><p> I see two distinct dynamics here, the one Graham and Dorai raise, and Tran&#39;s.</p><p> Tran&#39;s is the core reason investors complain prices are too high. Of course most investors think the YC prices are too high. There are tons of investors chasing not that many YC companies with not that much space in their rounds. YC companies have many advantages over non-YC companies, including all three of:</p><ol><li> Selection effects (I don&#39;t think there are zero bogus AI companies in the round, but YC is excellent at picking good founding teams and promising companies).</li><li> Endorsement effects (YC pedigree is a strong signal and coordination point, everything will be easier with the name attached).</li><li> Enrichment effects (YC gives you an amazing network and toolkit, and teaches you a ton, and gives you motivation and focus).</li></ol><p> On top of that, there is the compression of valuations effect.</p><p> YC companies are wisely advised, the internet reports, to raise floor prices on rounds, because it saves you a lot in terms of ownership and with the YC name you can expect to raise the funds anyway. So the relatively non-exciting companies charge a lot, as they should. Why would you sell more equity for less money when you can sell less equity for more money?</p><h4> You Would Pay For The Ability To Charge More</h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/paulg/status/1694099152404398581">Paul Graham points out</a> that this whole dynamic makes YC valuable, and the witnesses are highly credible.</p><blockquote><p> Would-be founders: When later stage investors complain, as they always do, that the Demo Day valuations of YC companies are too high, what they&#39;re saying is that doing YC will enable you to raise money with less dilution.</p><p> This is a valuable claim for YC to be able to make, but it&#39;s even better when it&#39;s made for YC by people who clearly don&#39;t mean it as a compliment.</p></blockquote><p> It does not matter, from the startup&#39;s perspective, how much of their increased value comes from endorsement versus enrichment. It does matter to them to what extent it is selection.</p><p> I will also note that the existence of YC lowers the valuation of every company that is not in YC. You know that if they could have done YC, they probably would have, so you are fighting against highly adverse selection. All the more reason to do YC, then.</p><h4> The Best Deals Come With the Best Prices</h4><p> The most exciting companies in YC charge a lot as well, but it looks like they don&#39;t charge all that much more. There is as I understand it a convention in the space about what valuations are &#39;supposed to be.&#39; You can vary within the range, but once the founders are raising at an unusually high valuation right out of the gate, the price matters a lot less because they are giving over much less of the company. So rather than raise more money in exchange for less of the company, focus often shifts to gaining allies, setting up a path and telling the right story.</p><p> In particular, considerations of avoiding possible down rounds, and choosing the right strategic VC partners, seem to dominate price considerations at the high end.</p><p> You rarely lose a top VC over price because there is strong desire on both sides to not let this stop the deal. The startup gets better VC flow to help it down the line, and the top VCs get the better deal flow that provides most of their alpha.</p><p> From the startup&#39;s perspective, this is epic highway robbery, using the conventions of VCs to buy equity for far less than it is worth, but given the situation they are well advised to pay up.</p><p> If you are a top VC, this is amazing. You keep putting out a quality product, and YC will give you great deal flow, shining giant lights over great opportunities that don&#39;t use their full pricing power.</p><p> If you are not a top VC, this is a big problem. Adverse selection is happening now, not only in the growth of valuations later. If you could invest in a broad portfolio of companies at YC that look good to you, or even YC companies overall, that would be fine. The problem is you cannot do that, so you are looking at companies with 10% the hit it big prospects of other companies (that won&#39;t answer your emails because you suck and they can do better) but 50% of the valuation, and saying the price is too high.</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/Jeffreyw5000/status/1692996154235949166">Jeff Weinstein</a> : YC startups that would have raised at $8M cap in 2017-2020 are today raising at $20M cap.</p><p> In part this is due to the larger YC investment and MFN, but it also feels like these companies are being given bad advice and remain in denial that we&#39;re not in 2021 anymore.</p><p> This is fine if you execute absolutely flawlessly, find PMF, and raise enough to give you years of runway, but more often than not it puts startups in a tricky spot in 12 months, when they are valued on multiple instead of story.</p><p> Given these founders are raising at uninvestable prices around demo day, more and more often we are passing due to price and revisiting in 12 months!</p><p> Amjad Masad (CEO Replit): This is just market dynamics — nothing irrational on the part of founders. The alpha is simply dissipating (you are not entitled to alpha).</p><p> Those who will continue generating returns are the great pickers who can get great ownership % and the ones investing pre-seed (and pre YC).</p></blockquote><p> My only quarrel with Masad here is that one must be careful not to confuse great picker with good deal flow. There is definitely no reason VCs should be entitled to alpha, or the majority of YC investments should even be good deals.</p><p> For startups, a consequence of this dynamic is that most startups get huge value out of YC via raised evaluations and reputation, but the very top startups do not. They were already sending out strong enough signal that they were going to write their own ticket when raising money and not charge the market clearing price, so raising the market clearing price does little.</p><p> Should those top companies do YC anyway, despite the cost in equity? It is less obvious and likely differs case by case, especially since you can never be sure early on if you are or will remain one of these companies, and YC can help turn you into one. If I was in a life position were I could do YC and was founding a company that fit, then no matter how good things looked, I would definitely apply intending to accept if they said yes. If I gave up a little value, I am doing so well I don&#39;t much care.</p><h4> Raise Early, Raise Often, Raise Everywhere</h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/kwharrison13/status/1699457717977391608">Kyle Harrison offers what seems like good advice</a> , most of which is standard. Start raising with more than a year of runway because it takes variable time that can get long and now more than ever you cannot count on VCs to actually deliver. Cast a wide net and talk to many VCs, but be straight about who you are and what kind of fit you need so time isn&#39;t wasted on both ends.</p><p> He suggests writing a memo that articulates things, rather than pure reliance on a deck. That certainly seems like a superior equilibrium.</p><h4> Good VCs Get Their Money Back Surprisingly Often</h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/paulg/status/1694401451169308912">Paul Graham sees a different takeaway than I do on this next point.</a></p><blockquote><p> Paul Graham: David Clark of VenCap analyzed the returns from 11,350 startups backed by 259 funds from 1986 to 2018. About half these investments lost money, but 121 (1.1%) returned the entire amount of the fund that invested in them.</p><p> Two of their top ten investments were founded after 2010. Both are YC companies. That&#39;s what draws later-stage investors to YC. The valuations may be high, but it&#39;s where the really good startups are, and that&#39;s what matters most for returns.</p><p> David Clark: Top 10 fund returners by multiple of cost are as follows: 10. Coinbase 9. Slack 8. Portal Software 7. Facebook 6. Avanex 5. Google 4. Ariba 3. Yahoo 2. Brocade 1. DoorDash Multiples range from 140x to over 800x</p></blockquote><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a839c18-8b2b-4ef2-95c8-9ead44a54da1_680x413.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/dGvcx3giYngcSEaMZ/pnqljhj791iv3f6ex2l1" alt="图像"></a></figure><p> Instead, I had Yuri&#39;s reaction.</p><blockquote><p> Yuri Sagalov: I&#39;m actually surprised only ~50% of the investments returned &lt;1x. I would have thought that number would be higher.</p><p> Paul Graham: Me too. But we live in the early stage.</p></blockquote><p> If you can simultaneously get your money back 46.8% of the time, and also have this distribution of profits, that is a fantastic business. This is a 36.8% return even if you discard the Fund Returners entirely and mark everyone else to the extreme low end of their ranges. Yes, the FRs are important, and if we have 259 funds making ~12k investments they start on average at ~50x, but you don&#39;t actually need them if you only fully miss half the time. As Paul notes these will be later investments, but also not that late.</p><h4> If You Want it Done Right</h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/gustaf/status/1692685141221531728">Gusaf Alstomer (of YC) notes that using a designer on your pitch deck never works</a> .</p><blockquote><p> Gusaf Alstomer: Pitch-deck advice: I don&#39;t think I have ever seen a fundraising deck getting better by using a designer to design it. The same goes for using fancy tools like Figma, Keynote,</p><p> <a href="http://Pitch.com" rel="nofollow">http://Pitch.com</a> , or Canva. At <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ycombinator">@ycombinator</a> we recommend people to use Google Slides and keep it simple. The two mistakes founders make are believing that the creative capabilities of the tools make a better deck. The second mistake is believing that the design is important.</p><p> The most creative people operate under constraints. And the most powerful tools are your words and storytelling. Clear communication and relatable storytelling allow a listener to put themselves in the seat of the person having the problem you are solving. The best way to visualize this is with real photos of real people having these problems.</p><p> The best fundraising decks have this structure:</p><p> 1) Headline that concludes the point you are making</p><p> 2) 3-4 bullets with evidence towards the point you are making</p><p> 3) Repeat until you&#39;ve covered all conclusions</p><p> 4) Wrap this in a storytelling narrative – tie the slides together with a story</p><p> 5) Whenever possible, only use real photos and if you use screenshots, zoom in on the thing that tells the story</p><p> The exception to the “don&#39;t hire a designer rule” is when the founder themselves is a designer. They know what is important about this business – another person will never know this.</p></blockquote><p> This very much matches my experience as well. Designers have a very different skill set and are aiming at a different target. They don&#39;t understand what matters, and what matters will often change quickly or as you shift contexts, and you will want to edit on the fly. The deck also needs to be congruent with you and match your voice. Yes it is good if your deck looks nice but ultimately that does not much matter.</p><p> There is an important general point here. When there is a primary expertise that matters most, you will often see people making horrible errors in secondary areas, because the winning play is to focus on what matters. I wonder if AI will alter this.</p><h4> You&#39;ll Need the Time to Do That</h4><p> A common productivity theme is that by default people do a lot of grunt work that eats up a lot of their time. Another is that taking care of the fundamentals and getting your house in order gives you a big leg up.</p><p> If your time and efforts are valuable, and especially if you are a founder and have increasing returns to effectiveness deployed, <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/webdevMason/status/1699172098865057968">perhaps someone should help with that?</a></p><blockquote><p> Avi: I would pay so much money for a single service that completely handled my basic needs so I could focus</p><p> * laundry</p><p> * 3x/day meal prep</p><p> * personal trainer</p><p> * cleaner</p><p> * therapist turn my house into a monastery.</p><p> This should be VC value add. Founders should treat themselves as athletes</p><p> Mason: Don&#39;t say it</p><p> Don&#39;t say it</p><p> Mason don&#39;t</p><p> Aaaaaaaagh IT&#39;S A WIFE YOU WANT A WIFE</p><p> Avi (distinct reply to his OP but this order is more logical and also funnier): Funny thing is if I tweeted this saying I want a wife to do this for me I&#39;d also get flamed. I feel that if you raise funding, part of it should *temporarily* go to removing distraction. This includes healthy meal prep, sleep tracking, etc. I know the tweet comes off a bit inane, but I&#39;m a single 20 year old with no intention of getting into a relationship. I live and breathe my work. Twitter is my only vice.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/drethelin/status/1699288880657338382">Misha Gurevich</a> (responding to OP): I think too many people watched Batman as kids and have an idea of “monasteries” as training centers for turning you into a badass instead of fundamentally boring places where you do manual labor in poverty and pray.</p><p> A lot of people seem to think if they had a butler he would be the Albert to their Batman but really they want a Jeeves to their Wooster.</p><p> “Jeeves is a valet, not a butler; that is, he is responsible for serving an individual, whereas a butler is responsible for a household and manages other servants. On rare occasions he does fill in for someone else&#39;s butler. According to Bertie Wooster, he &#39;can buttle with the best of them.&#39;”</p></blockquote><h4> Credits You Will Need More of Are Essentially Money</h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/yuris/status/1693784255237968307">Friendly reminder</a> .</p><blockquote><p> Yuri Sagalov: Founders, if you&#39;re in the fortunate position to have AWS/etc credits, don&#39;t treat them as “free money.” Instead, treat it as extra cash on your balance sheet that you can <strong>only</strong> use for one purpose, and count your AWS usage as part of your burn. Don&#39;t wait until they run out.</p><p> James Hu: This is the same way to think about credit card points and miles. It&#39;s cash, and just as good as cash for anyone who travel, and should be treated as such.</p></blockquote><p> Exactly. If you have credit somewhere and will inevitably spend it and then keep spending, that credit is functionally no different from cash. Spending it is no different from spending cash. The same goes for any other asset that can be used in place of cash. If it would otherwise go to waste, then that is different, otherwise its value is equal to the opportunity cost. Which is usually damn close to $1 per dollar.</p><h4> Get Your App Out There Quick</h4><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/theapplehub/status/1699725358017523928">Apple Hub</a> : The App Store and iOS are now officially designated as gatekeepers in the EU and will need to comply with the Digital Markets Act (DMA) This means Apple will be required to allow users to downloads apps from the internet and third-party app stores.</p><p> Do you agree with this regulation?</p><p> Emmett Shear: Woah this is huge news if it gets enforced. Would be the best thing for the tech ecosystem in a long time…if the USA doesn&#39;t follow suit will actually significantly advantage European startups! Or at least startups deploying in EU first.</p></blockquote><p> There was no poll, which I am guessing was the right choice by Apple Hub.</p><p> I would not be in the habit of regulating such matters, but if I was, this would be a good choice of regulation. It does seem first-level helpful.</p><p> What does this do for startups? It means you can get your app to Europe&#39;s iPhone users without the app store. If you can find them without the app store. If they are willing to side load. Which will be rare. People do not like to sideload even on Android, where it is supported and you have people opting into that ecosystem.</p><p> My prediction is that this does not end up having that much practical impact.</p><h4> No, Quicker Than That</h4><blockquote><p> Bri Kimmel: This is the first YC Demo Day in a very long time where the majority of B2B companies had paying customers, recurring revenue, and large contracts with companies way too big to work with a small startup.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/garrytan/status/1699777074456924662">Garry Tan</a> (President of YC): 75% of the companies presenting today started with no revenue on day one of YC. 81% had never raised a dime. During the past 3 months, we pushed the startups hard to build meaningful software and sell it. This is the speed up that I have only ever really seen YC do for founders.</p><p> Joe Benjamin: Why do you think so many founders are slow to go out and sell when starting out?</p><p> Garry Tan: Fear of failure.</p></blockquote><p> How easy it is to forget that selection effects and network effects and other affordances are in play.</p><p> If you are in YC, you have been selected by Garry Tan and others based in large part on them thinking you will soon be able to go out and sell, then they are giving you lessons on how to do that, network connections and other resources to help you do that, helping sculpt your pitches and targets and such, and also giving you the &#39;I&#39;m in YC&#39; foot in the door that I presume helps with large companies. You have the tools to make sacrifices in order to do the selling, in turn in order to go faster and get better valuations and also learn faster. And of course they exert massive social pressure in the other direction.</p><p> If you are not in YC, you are in a very different situation all around. It is very possible to be attempting to sell too much too quickly, before you are ready.</p><p> Failure can also be not only damaging but cascading. Games that come out and try to get revenue too early and fail to sell are marked as failures, I have had this happen to me and watched it happen elsewhere – the game improved later, the algorithms and fans have moved on, it is too late. A focus on revenue before it is too early can also waste your time, tell the wrong story that breaks your ability to continue or raise, burn your best leads and plays before you are ready, or otherwise devastate.</p><p> So no, I do not think this decision is that easy, even if what are otherwise the best startups would be better served selling more and selling faster. I have had multiple experiences with the opposite mistake.</p><h4> All The Startups Are Now AI Startups</h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/paulg/status/1697083056597631271">Meanwhile, Paul Graham continues to notice that YC is now all about AI</a> .</p><blockquote><p> Paul Graham: I haven&#39;t been more optimistic about YC since I retired in 2014. Garry has been doing a great job, and the current batch is a particularly good one.</p><p> The AI boom will be very good for YC. It will mean a lot more startups, and the kind of founders who win at it are the kind that YC specializes in.</p><p> YC has already been transformed by the AI boom. I&#39;d guess more than half the founders in the current batch are working on AI startups. It&#39;s like an ongoing AI symposium with over 200 participants.</p></blockquote><p> I actually buy this. A YC-style team and approach are unusually well suited to this moment, YC&#39;s infrastructure will be a big help, and YC will largely have its pick of founders. What a great time to be YC.</p><p> I would once again however double down that there are doubtless quite a few bogus AI companies involved. Nothing becomes this ubiquitous, this all-consuming, this hyped, without bogosity. Failure to spot them, however, does not automatically mean <a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=5vEp5Bv-J40&amp;ab_channel=EliteFilmClips">you are the sucker</a> . It is a hits-based system, so what if some of them aren&#39;t real? What matters is the deal flow giving you access to the best stuff, not avoiding false positives.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/paulg/status/1699815950772519277">So, what are all these non-bogus companies up to?</a></p><blockquote><p> Aaron Levie: All the enterprise AI startups going after verticals have the right idea. Pick a market, deeply understand the workflows, build simple software to model the workflows, and use AI to augment the human judgment involved. Huge opportunity in 1,000&#39;s of categories.</p><p> Paul Graham: This is the median startup in the current YC batch.</p></blockquote><p> I have certainly seen worse plans. Enough to fill out a demo day. I would doubt that there are thousands of such categories offering great opportunity.</p><h4> Man With Moat Unconcerned With Non-Flying Creatures</h4><p> What happens if someone copies you? <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/paulg/status/1697761812698034630">Don&#39;t worry about it</a> , says Paul.</p><blockquote><p> Paul Graham: When people copy you, the best strategy is usually to ignore them. People who copy you are (a) unoriginal and (b) opportunists, and those are both strong predictors of failure. If you wait them out, they&#39;ll eventually drop away.</p><p> Joel Fraunsic: “I&#39;ve been imitated so well I&#39;ve heard people copy my mistakes.” ― Jimi Hendrix</p><p> Paul Graham: This happened with both Viaweb and Y Combinator.</p></blockquote><p> When people attempt to make exact copies on various levels, yes they usually fail, but often they also don&#39;t, and if there are lots of imitators most of them failing does not mean that you can safely ignore the phenomenon. The advice to ignore them goes hand in hand with working actually super hard to ensure that one can safely ignore them, by being the best like no one ever was and continuously improving and having strong reputational and network effects. In which case, sure, bring it on.</p><p> If they are not exactly copying you, rather taking you as reason to compete, that is in a sense great news about your situation absent the competition, but it definitely should worry you, especially if the competition is well-resourced. Noticing one example…</p><blockquote><p> Danny Alberson (CEO Agentive,YC &#39;23): I recently met with a VC firm twice, showed a product demo, and answered countless questions about our strategy. Only to find out from someone else they were already invested in a direct competitor.</p><p> Paul Graham: I just sent you an email. This should go in the investor database.</p><p> Danny Alberson: Absolutely. Thanks for following up.</p><p>绝对地。 Thanks for following up.: Please consider open sourcing it!</p><p> Li Ang: An open source database is very much needed.</p><p> Ronak Shah (other reply): This happened to me too. Not only the calls but they kept asking for my financial model so they could see my pricing / how I won big logos. They hid the fact that they invested in my competitor.</p></blockquote><p> [several other replies noted similar behavior, especially related to Web3/crypto]</p><p> Garry Tan (QTing Alberson): Warning to investors: there are consequences to this kind of behavior. I will personally make sure of it.</p><p> Austen Allred: I love YC.</p><p> Ryan Peterson: YC invests in competitors constantly though.</p><p> Paul Graham: This isn&#39;t a case of investing in a competitor. It&#39;s a case of pretending to be interested in a company in order to pump it for information.</p><h4> The Investor Database Is a Killer App</h4><p> There are a lot of services you get from YC. Given how multiplicative everything is when it comes to startups, it does not take much to get a big payoff. Purely raising your ambition alone is great, many other seemingly simple principles are great.</p><p> The payoff that impresses me most is the reputation, followed by the network. The most underrated is likely the broadly construed investor database, where you get intel on all the venture capitalists.</p><p> It is vastly different dealing with people whose actions have been and will be recorded into a central database. The VC knows that you will report back. You get to use the previous reports to know which VCs will treat you well, offer which resources, use which styles of negotiations, respond well to various approaches, and so forth. If the information is accurate, the ultimate impact on ability to raise money, from the right people, under the right conditions at the best price, seems colossal.</p><p> While I understand why one would want to retain this competitive advantage, it would be wonderful if this information could be disseminated to everyone. Behavior would improve, those who treat investors well would get rewarded, and outsiders in particular would have a much better shot at being founders. Even if I&#39;m not that excited to accelerate the ability to create AI startups right now, this has to be the right thing to do.</p><p> Would it be expensive to YC to give this up? My instincts say that it would not be. It would be amazing advertising, it would fuel the ecosystem and it would demonstrate value. There are enough additional advantages to YC that I predict most founders would not change their decision whether to participate. YC is not charging a market clearing price.</p><br/><br/> <a href="https://www.lesswrong.com/posts/dGvcx3giYngcSEaMZ/startup-roundup-1-happy-demo-day#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/dGvcx3giYngcSEaMZ/startup-roundup-1-happy-demo-day<guid ispermalink="false"> dGvcx3giYngcSEaMZ</guid><dc:creator><![CDATA[Zvi]]></dc:creator><pubDate> Tue, 12 Sep 2023 13:20:07 GMT</pubDate> </item><item><title><![CDATA[Is there something fundamentally wrong with the Universe?]]></title><description><![CDATA[Published on September 12, 2023 12:02 PM GMT<br/><br/><p> Usually the question is: &quot;What is wrong with our society?&quot;, but I guess my gripe is that if you look at things with a System-lense, usually what you focus on is what has the most influence.<br><br> In other words, if our Planet would veer off course, it isn&#39;t really the fault of the Ants - even when they could have done more! The reason is bigger gravitational forces, or our Sun wanting some more space.<br><br> So, why would you blame a human being for something that seems to be governed by laws, forces and powers we A) don&#39;t fundamentally understand, B) can&#39;t fundamentally influence C) can&#39;t fundamentally change ?<br><br> I mean, from a human perspective, there are a lot of answers - Psychology, sociology, anthropology, evolutionary disciplines, religion - even transdisciplinary groups and projects. But again, you only answer the question from <i>inside the box</i> . If the box gives a certain output, and has specific constraints, why blame the Outputs for how the box works?</p><p> It makes more sense to me to assign fault at the level where the problem lies. If we dislike and abhor something, at which level does it arise?<br> A lot of expressions we use are filled with assumptions that are focused on our personal actions. Take murder, for example. Killing is bad, I agree, but is it the personal choice of the killer to enable murder, to make possible the possibility of dying? The pain, suffering, dread etc.? It is the Universe&#39;s Laws and principles that are allowing it and actively engaging in it (There are endless ways this Universe can and will kill us), is it not?<br><br> That is just one of numerous examples I can think of where I am questioning if by looking closely at an issue, it seems to be the direct consequence of a superintended principle we have 0 direct control over.<br> I mean, personal responsibility sounds nice, but if you really look at it - does it make any sense? Take genes, for example. They are based on millions of years of biological, and then even cultural evolution. That you have the &#39;ability&#39; to see a different way than eating your fellow friend, and can see more gains in keeper them alive - is it really &quot;Your&quot; achievement? How many choices are really &quot;Yours&quot;, and not the inexplicable results of processes that started millions of years before you were even consciously aware that you had a face and a body separate from the rest of the world?<br><br> From this point of view, I find it hard to not assign whatever issues or problems we have to how the Universe works. Not that I believe I could design a Universe, but I wonder how others see the problem. Maybe I am missing something, but I also believe this is a matter of abstraction and follow the threads to their source.<br><br> Because if the problem is the Universe, wouldn&#39;t you have to fix its underlying Laws and principles if you wanted to fundamentally change anything? Because any other change would only be superficial, partial and temporary.<br><br> On a separate note (Joke joke?)<br> And so It is that I am still looking for the Universe help-desk. If anyone knows the number, or how to contact them, please let me know. If I&#39;m a beta-tester, I believe I should let them know that some things really don&#39;t seem to work that well.<br><br> Kindly,<br> Caerulea-Lawrence</p><br/><br/> <a href="https://www.lesswrong.com/posts/GbQFbsswjDpkuSYEA/is-there-something-fundamentally-wrong-with-the-universe#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/GbQFbsswjDpkuSYEA/is-there-something-fundamentally-wrong-with-the-universe<guid ispermalink="false"> GbQFbsswjDpkuSYEA</guid><dc:creator><![CDATA[Caerulea-Lawrence]]></dc:creator><pubDate> Tue, 12 Sep 2023 12:02:44 GMT</pubDate> </item><item><title><![CDATA[Apple Cider Baklava]]></title><description><![CDATA[Published on September 12, 2023 2:10 AM GMT<br/><br/><p> <span>Since coming across</span> <a href="https://www.jefftk.com/p/apple-cider-syrup">apple cider syrup</a> last year I&#39;ve been trying to figure out what sort of things to make with it. Cider donuts are traditional, but I&#39;m not that much of a fan. Mixing it into whipped cream works very well, and makes a good sweet and tart filling or topping for baked goods. I&#39;ve experimented with muffins, using it for a combination of the liquid, the sugar, the flavoring, and the acid for the leavening, but I haven&#39;t ended up with anything I&#39;m happy with yet. But a few days ago I made some apple baklava that&#39;s my favorite yet!</p><p> <a href="https://www.jefftk.com/baklava-loaf-pan-mostly-gone-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wu3r9AfKMDYzLzPPc/t8bligbnzszddyu1o3gf" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wu3r9AfKMDYzLzPPc/t8bligbnzszddyu1o3gf 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/wu3r9AfKMDYzLzPPc/fidrhkddito9amo2czvc 1100w"></a></p><div></div><p></p><p> <a href="https://en.wikipedia.org/wiki/Baklava">Baklava</a> is layers of <a href="https://en.wikipedia.org/wiki/Filo">phyllo dough</a> (a very thin dough) separated by a fat, with nuts every few layers. After baking you pour a sweet syrup over the top. In the US people are probably most familiar with a Greek style which uses butter for the fat, walnuts for the nuts, and honey for the syrup, but there are an enormous number of regional variations.</p><p> I made two pans, one vegan (earth balance) and one not (butter). The butter one tasted a lot better; possibly there are better choices than earth balance? I used almonds for the nuts because that&#39;s what I had. For the syrup I used New England boiled cider. Very happy with how it turned out, and I plan to make it again!</p><p> (Each loaf pan used ~$1.80 of <a href="https://www.webstaurantstore.com/mountain-cider-company-64-fl-oz-100-natural-spiced-apple-cider-concentrate/110MTCIDER64.html">cider syrup</a> , though if you really like it you could <a href="https://www.webstaurantstore.com/mountain-cider-company-100-natural-spiced-apple-cider-70-brix-concentrate-54-gallon-drum/110MTCIDERLG.html">buy in bulk</a> and get it down to $1.42.)</p><br/><br/> <a href="https://www.lesswrong.com/posts/wu3r9AfKMDYzLzPPc/apple-cider-baklava#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/wu3r9AfKMDYzLzPPc/apple-cider-baklava<guid ispermalink="false"> wu3r9AfKMDYzLzPPc</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Tue, 12 Sep 2023 02:10:05 GMT</pubDate> </item><item><title><![CDATA[How useful is Corrigibility?]]></title><description><![CDATA[Published on September 12, 2023 12:05 AM GMT<br/><br/><p> <i>Epistemic Status: My best guess (I&#39;m new to AI safety)</i></p><p> We don&#39;t know how to formally define corrigibility and this is part of the reason why we haven&#39;t solved it so far. Corrigibility is defined in <a href="https://arbital.com/p/corrigibility/">Arbital</a> as:</p><blockquote><p> [the agent] doesn&#39;t interfere with what we would intuitively see as attempts to &#39;correct&#39; the agent, or &#39;correct&#39; our mistakes in building it</p></blockquote><p> The precise meaning of words like &quot;interfere&quot;, &quot;attempt&quot;, or &quot;correct&quot; is unclear from this informal definition. Even with the most generous definition of those concepts, a corrigible agent can still be dangerous. A first intuition is that if we have a corrigible agent, we can always stop it if something goes wrong. I suppose most people here understand the flaws in this reasoning but I have never seen them stated them explicitly so here is my attempt:</p><ul><li> By the time we figure out an agent needs to be corrected, it may have done too much damage.</li><li> Correcting the agent may require significant amount of research.</li><li> Being able to correct the agent is insufficient if we cannot coordinate on doing it.</li></ul><p> In my opinion, solving the <strong>hard corrigibility problem</strong> is a more meaningful intermediate goal on the path to the terminal goal of solving alignment.</p><h2> Disaster Scenario</h2><p> What follows is a scenario that illustrates how <strong>a corrigible agent may cause serious harm</strong> . Use your imagination to fill in the blanks and make the example more realistic.</p><p> Suppose we develop a corrigible agent which is not aligned with our values. It doesn&#39;t matter exactly what the agent is designed to do but for concreteness you can imagine the agent is designed to optimize resource usage - it is good at task scheduling, load balancing, rate limiting, planning, etc. People can use the agent in their server infrastructure, for logistics, in factory production or many other places. No matter its terminal goal, the agent is likely to value resource acquisition instrumentally - it may use persuasion or deception in order to get access and control of more resources. At some point, people would leverage it for something like managing the electric grid or internet traffic. This process of integrating the agent into various systems continues for some years until at some point the agent starts paying paperclip factories to increase their production.</p><p> At this point, in the best case we realize something&#39;s wrong and we consider turning the agent off. However, the agent controls the energy supply and the internet traffic - we have become dependent on it so turning it off will have serious negative impact. In the worst case, instead of paperclips the agent is maximizing something of more ambiguous value (eg food production) and people cannot actually agree whether they have to modify the agent or not.</p><p> How could a corrigible agent take actions which make us depend on it? The corrigibility guarantee doesn&#39;t capture this case. The agent doesn&#39;t interfere with our ability to shut it down. It may not even take into account its stop button when choosing its actions. It doesn&#39;t manipulate us into not shutting it down any more than an aligned agent does by choosing actions to which we happen to not object. In either case, from the agent&#39;s point of view, it just chooses a branch of possible worlds where its utility is high. <strong>The only difference between the aligned and misaligned agent is that, if the agent is misaligned, the chosen branch is likely to correspond to low utility for us</strong> .</p><p> Why would the agent wait for years before calling the paperclip factories? When pursuing a goal in the long run, it may be more beneficial to invest your money than to use it to buy what you actually want. Once you&#39;re rich enough, the marginal value of acquring more money is low enough that it makes sense to spend some of the money on what you actually want.</p><p> What happened is that the agent steered the world into a subtree with very low utility and we didn&#39;t react. This could be because we were not intelligent enough to forsee the consequences or because the agent&#39;s actions were actually what we would have wanted from an aligned agent. The problem is not exclusively our limited intelligence preventing us from predicting the consequences of the agent&#39;s actions. Up to some point in time, the unaligned agent may actually exhibiting behavior which we would desire from an aligned agent.</p><p> Somebody may say &quot;Just don&#39;t depend on an AI unless we&#39;re sure it&#39;s aligned&quot;. This may be hard in practice if the AI is sufficiently intelligent. In any case, dependence is not easy to measure or control. It positively correlates with usefulness so preventing dependence would reduce usefulness. Dependence is not a property of the tool (eg the AI agent) but of the usage pattern for the tool. We cannot force countries, organizations and individuals to not use the AI in a way that makes them depend on it. Sometimes one may not be aware they depend on the given AI or there may be no reasonable alternative. Also, let&#39;s not underestimate humanity&#39;s desire to offload work to machines.</p><h2> Speed and Coordination</h2><p> Humans operate at speeds much slower than machines. Taking a hours to respond when the agent starts doing undesirable things may be too much. Once we realize we need to correct an agent, we may need to spend months or years of research in order to figure out how to modify it. If we depend on the AI, we may want to keep it running in the meantime and it will keep on causing damage.</p><p> If we can design a stop button we still need to answer several important questions:</p><p> Who controls the stop button and why should we trust this person/organization?<br> By what rule do we determine when it&#39;s time to correct the agent?<br> What criteria do we use to decide if we should keep the agent running until we can produce the corrected version?</p><p> The general problem is that <strong>humans need to have an action plan and coordinate</strong> . This relates to the <a href="https://www.lesswrong.com/posts/BEtzRE2M5m9YEAQpX/there-s-no-fire-alarm-for-artificial-general-intelligence">fire alarm problem</a> .</p><h2> The Hard Problem of Corrigibility</h2><p> We can consider a stronger form of corrigibility as defined <a href="https://arbital.com/p/hard_corrigibility/">here</a> :</p><blockquote><p> behaving as if it were thinking, &quot;I am incomplete and there is an outside force trying to complete me, my design may contain errors and there is an outside force that wants to correct them and this a good thing, my expected utility calculations suggesting that this action has super-high utility may be dangerously mistaken and I should run them past the outside force; I think I&#39;ve done this calculation showing the expected result of the outside force correcting me, but maybe I&#39;m mistaken about that.&quot;</p></blockquote><p> Satisfying corrigibility only requires that the agent not interfere with our efforts to correct it (including eg by manipulation). A solution to the hard problem of corrigibility means that, in addition the agent takes into account its flaws while making regular decisions - for example, asking for approval when in doubt or actively collaborating with humans to identify and fix its flaws. More critically, <strong>it will actively help in preventing a disaster caused by the need to modify it</strong> .</p><p> I think this captures the crux of what a usefully corrigible agent must be like. It is not clear to me that solving regular corrigibility is a useful practical milestone - it could actually provide a false sense of security. On the other hand, solving the hard problem of corrigibility can have serious benefits. One of the most difficult aspects of alignment is that we only have one shot to solve it. A solution to the hard problem of corrigibility seems to give us multiple shots at solving alignment. An aligned agent is one that acts in accordance with our values and those values include things like preventing actions contrary to our values from happening. Thus, solving alignment implies solving hard corrigibility. Hard corrigibility is interesting in so far as it&#39;s easier to solve than alignment. We don&#39;t actually know whether this is the case and by how much.</p><br/><br/> <a href="https://www.lesswrong.com/posts/Py3vqPp9uSqQJHFuy/how-useful-is-corrigibility#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/Py3vqPp9uSqQJHFuy/how-useful-is-corrigibility<guid ispermalink="false"> Py3vqPp9uSqQJHFuy</guid><dc:creator><![CDATA[martinkunev]]></dc:creator><pubDate> Tue, 12 Sep 2023 00:05:43 GMT</pubDate> </item><item><title><![CDATA[Machine Evolution]]></title><description><![CDATA[Published on September 11, 2023 7:29 PM GMT<br/><br/><p> <i>Epistemic Status: This post explores the relationship between biological evolution and the evolution of our machines. We examine parallels between the evolutionary pressures shaping organisms and machines. We are still exploring this analogy and our findings are tentative. We hope to explore these relationships further in future posts. Feedback and criticism are very much appreciated.</i></p><h1>介绍</h1><blockquote><p><i>After all then it comes to this, that the difference between the life of a man and that of a machine is one rather of degree than of kind, though differences in kind are not wanting. An animal has more provision for emergency than a machine. The machine is less versatile; its range of action is narrow; its strength and accuracy in its own sphere are superhuman, but it shows badly in a dilemma; sometime when its normal action is disturbed, it will lose its head, and go from bad to worse like a lunatic in a rain frenzy: but here, again, we are met by the same consideration as before, namely, that the machines are still in their infancy; they are mere skeletons without muscles and flesh.</i></p></blockquote><p> — “Erewhon” by Samuel Butler, 1872</p><p> Machines change over time. They evolve. Our machines of today are advancements and refinements of the machines of yesterday, with each new generation exposed to selective pressures. Some changes promote the proliferation of some machines over other types and are more likely to persist and undergo further refinement and transformation. Innovations in machine capabilities exploit new niches and proliferate, diversify, and rapidly spread throughout their ecosystem. At the same time, just as with biological evolution, previous generations of machines go extinct, while others persist comfortably in their niche, undergoing only minor changes for hundreds or thousands of years. For example, Samuel Butler pointed to <a href="https://www.goodreads.com/quotes/556914-i-remember-one-incident-which-bears-upon-this-part-of"><u>the tobacco pipe</u></a> , and other pre-machine tools such as hand axes and needles lasted for millenia.</p><p> <a href="https://commons.wikimedia.org/wiki/File:Paleolithic_hand_axe_(both_sides)_(FindID_102443).jpg"><u><img style="width:40.89%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/n4ukcnrxl7mvja7h4trx"></u></a> <img style="width:53.33%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/f0wpbohxuufovy9fl6pf" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/jzqfktbmwnztl5g6hxq0 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/c6z1oubidqlal6dttetg 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/kpqpplpjy3lzua617idl 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/jlwkmdk6vjotna7h8vcn 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/tmejnx3btoyqhnd9xjtl 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/gtvimkbi6cetifoq1ivh 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/nhuxvgwnsv4rdgdkhfsy 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/yhhgmgh6t2vo2nrmbvmk 1280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/gx9vfwevvvod7ffyt8vw 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/vfgiavjilmcosaiqdt76 1523w"><br> The hand axe is the <a href="https://en.wikipedia.org/wiki/Hand_axe"><u>longest-used tool in human history</u></a> , employed with little modification for over a million years, and sewing needles that resemble those we use today, made from bone, have been dated to over 60 millenia ago.</p><p> <a href="https://commons.wikimedia.org/wiki/File:Fossil_horseshoe_crab_dead_in_its_tracks.jpg"><img style="width:45.25%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/crkrj0mqhovjpkaxrkrl" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/evh18qd2kkzmybmcwhgl 127w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/ro4mbyoandw6tiussgin 207w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/fq6rvadvvc4ighgsoymd 287w"></a> <a href="https://commons.wikimedia.org/wiki/File:Limulus_polyphemus_(Atlantic_horseshoe_crab)_(Sanibel_Island,_Florida,_USA)_7.jpg"><img style="width:44.83%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/wszloh4bpkvqph6pe7pq" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/ghmlyuye8xhmcj48ni8c 128w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/hzc1gxy4vkfkqelykbwz 208w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/xsd7znuo2kutg647axbp 288w"></a><br> A 450 million-year-old fossil of a horseshoe crab beside a modern specimen. This basic design has persisted for nearly half a billion years.</p><p> Similar processes of change over time occur in biological evolution, in particular through the well-documented evolutionary processes of recombination, mutation, and natural selection (among others). Both machines and organisms change over time. They both evolve. The question, however, is how similar are the underlying processes that drive these evolutionary changes over time?</p><p> It is to this question that we now turn our attention. We&#39;ll focus on biological evolution from the perspective of individual organisms, and this has its analog in machines as individual objects within the broader scope of technological evolution. We&#39;ll consider a tool as any object or meme that aids or extends human capacity (such as hand axes and needles), and machines as tools that are self-powered (such as cars and computers). Later, we&#39;ll discuss artificial intelligence, which we&#39;ll consider as machines that are self-directed to some extent (such as ChatGPT). As with organisms, machines have populations and generations as well. Machines are constituted from interacting micro parts and exist within macro structures that impose selection pressures. In this post, we explore the utility of applying lessons and insights from biological evolution as a first step to help us understand the processes underlying machine evolution.</p><p> When we describe the macro trends of machine evolution casually, we are often describing something more like &quot;trends in machine development and innovation over time.&quot;</p><p> For example, we might say things like:</p><ul><li> &quot;Wow, it seems the pace of innovation is picking up!&quot;</li><li> &quot;Our machines are definitely becoming more complex over time.&quot;</li><li> &quot;There are lots of different types of new machines! &quot;</li></ul><p> However, we don&#39;t seem to have very good &quot; <a href="https://www.lesswrong.com/tag/gears-level"><u>gears level thinking</u></a> ” or “ <a href="https://en.wikipedia.org/wiki/Intuition_pump"><u>intuition pumps</u></a> &quot; about machine evolution, despite this phenomenon driving vast changes in human society and the human condition.</p><p> To rectify this, we want to explore the idea that <i>machine evolution</i> is a topic worthy of direct study - particularly to those interested in AI, AI safety, and those who are concerned about the control that humans have already ceded to machines.</p><p> But, first, let us first take on definitions of both &quot;machine&quot; and &quot;evolution&quot; and then put them together for our working definition of “machine evolution”.</p><h1> Grounding the intuition</h1><blockquote><p> <i>At the beginning of the twentieth century David Hilbert sought to establish the completeness of mathematics and instead precipitated the realization that the extent of mathematical truth can never be systematically confined. Evolutionists, who appeared to have dislodged mind and intelligence, are discovering that evolution is an intelligent process and intelligence an evolutionary process, rendering the separation less distinct. Technology, hailed as the means of bringing nature under the control of our intelligence, is enabling nature to exercise intelligence over us.</i></p></blockquote><p> — Darwin Among The Machines: The Evolution Of Global Intelligence by George B. Dyson, 1997</p><p> For this exercise, let&#39;s start with the most broadly accepted definition of these two terms. To do this, let us turn to Wikipedia.</p><p> <a href="https://en.wikipedia.org/wiki/Machine#:~:text=In%20the%2017th%20century%2C%20the,16th%20and%20early%2017th%20centuries.">Wikipedia defines a machine as:</a></p><p> <i>a physical system using power to apply forces and control movement to perform an action. The term is commonly applied to artificial devices, such as those employing engines or motors, but also to natural biological macromolecules, such as molecular machines. Machines can be driven by animals and people, by natural forces such as wind and water, and by chemical, thermal, or electrical power, and include a system of mechanisms that shape the actuator input to achieve a specific application of output forces and movement. They can also include computers and sensors that monitor performance and plan movement, often called mechanical systems.</i></p><p> Now, <a href="https://en.wikipedia.org/wiki/Evolution">let&#39;s do the same for evolution</a> :</p><p> <i>In biology, evolution is the change in <strong>heritable</strong> characteristics of biological populations over successive generations. These characteristics are the expressions of genes, which are passed on from parent to offspring during <strong>reproduction</strong> . Genetic variation tends to exist within any given population as a result of genetic <strong>mutation</strong> and <strong>recombination</strong> . Evolution occurs when evolutionary processes such as <strong>natural selection</strong> (including sexual selection) and genetic drift <strong>&nbsp;</strong> act on this variation, resulting in certain characteristics becoming more or less common within a population over successive generations. It is this process of evolution that has given rise to biodiversity at every level of biological organization.</i></p><p> Now, there is no Wikipedia page for machine evolution (maybe one piece of evidence supporting the claim that it&#39;s understudied), so we&#39;ll have to put the terms together ourselves.</p><p> For us, put succinctly, <strong>machine evolution</strong> <i>is the process by which machines change over successive generations.</i></p><p> Interestingly, there is only a very sad Wikipedia page for the broader phenomenon of <a href="https://en.wikipedia.org/wiki/Technological_evolution#:~:text=Technological%20evolution%20is%20a%20theory,Future%2C%20Masefield%20Books%2C%201993.">technological evolution</a> . It does offer a relatively simple “three stages of technological evolution” which include: (1) tools, then (2) machines, and finally (3) automation. This suggests that the very pathway of technological evolution is aimed at automation. But, as with machine evolution, there&#39;s a serious dearth of research on this topic. Here it is worth briefly mentioning why we highlight machine evolution specifically.</p><p> <strong>First</strong> , machine evolution includes the exploration of objects that are more complicated than we might commonly expect of a tool (think of the difference between a hammer or screwdriver and that of a digital computer).</p><p> <strong>Second</strong> , machines are typically “using power to apply forces and control movement to perform an action”. This allows them to engage with their environment in a way that more closely resembles that of an agent rather than a simple tool.</p><p> <strong>Third</strong> , the focus on machines within the broader technological evolution, and humanity&#39;s role in designing machines, is the crucial point in between simple tools and full autonomy, where we can most likely exert significant influence on the evolution of a population of machines.</p><p> For us, then, our first goal for understanding Machine Evolution will involve two simple steps: (1) examine macro trends in machine development and machine populations, and (2) explore how the micro processes of biological evolution may provide insights into the process of machine evolution. In this context, we&#39;ll explore key biological evolutionary processes such as <strong>heritability</strong> , <strong>reproduction</strong> , and <strong>recombination</strong> among others to describe how and why machines have taken different shapes and types over time. Furthermore, we&#39;ll also explore some key distinctions and highlight the key role of <strong>artificial selection</strong> as contrasted to the role of <strong>natural selection.</strong></p><h1> Applying the intuition</h1><p> There are many interesting trends in machine development, but in this article we&#39;ll focus on the following 3 self-evident trends that we think help to illustrate the underlying processes of machine evolution:</p><ol><li> <strong>Improvements in machine capabilities</strong></li><li> <strong>Increases in the amount of computing machines</strong></li><li> <strong>Increasing role of machines in the design and creation of new machines</strong></li></ol><p> To explain these changes in machines themselves, we explore 5 biological evolutionary mechanisms that have shaped biological life over time, each of which we develop an analog for machine evolution.</p><p> These 5 biological evolutionary mechanisms are:</p><ol><li> <a href="https://en.wikipedia.org/wiki/Heredity">Inheritance:</a> <i>the passing on of traits from parents to their offspring; either through asexual reproduction or sexual reproduction, the offspring cells or organisms acquire the genetic information of their parents.</i></li><li> <a href="https://en.wikipedia.org/wiki/Reproduction">Reproduction</a> : <i>the biological process by which new individual organisms – &quot;offspring&quot; – are produced from their &quot;parent&quot; or parents.</i></li><li> <a href="https://en.wikipedia.org/wiki/Mutation">Mutation</a> : <i>an alteration in the nucleic acid sequence of the genome of an organism, virus, or extrachromosomal DNA.</i></li><li> <a href="https://en.wikipedia.org/wiki/Genetic_recombination">Recombination</a> : <i>is the exchange of genetic material between different organisms which leads to production of offspring with combinations of traits that differ from those found in either parent.</i></li><li> <a href="https://en.wikipedia.org/wiki/Natural_selection">Natural Selection:</a> <i>the differential survival and reproduction of individuals due to differences in phenotype. Charles Darwin popularized the term &quot;natural selection&quot;, contrasting it with <strong>artificial selection</strong> , which is intentional, whereas natural selection is not.</i></li></ol><p> With biological life, populations change over time through evolutionary pressures placed upon individual organisms. Very roughly, each new organism is created by some method of reproduction, dictated by the organism&#39;s genome. In sexual reproduction, an organism inherits traits (along with some random mutations) from its parents after a process of genetic mixing (recombination). The changes in the genome of biological organisms give rise to slightly different organisms, to variations of different phenotypes, from which natural selection picks the winners through organism survival and reproduction rates, provided the environmental conditions remain stable enough to support the prospect of continued adaptability.</p><p> As mentioned earlier, evolutionary forces are at play upon machines, as argued by both Samuel Butler and George Dyson. The biological evolutionary processes can also be broadened slightly to consider them as potential evolutionary processes guiding the evolution of machines as well. This analogy seems particularly relevant for intelligent computing machines and the increasing capability of AI to direct the behavior of these machines. In this spirit of analogy, let us briefly recast each of these mechanisms in terms of machine development. We should note that these are tentative and imperfect analogies that we hope to refine over time with further work and feedback.</p><p> <strong>1. Machine Inheritance:</strong> <strong>The transfer of design features, characteristics, or programming from one generation of machines to the next</strong> <i><strong>.</strong></i></p><p> For example, new generations of desktops, laptops, and smartphones typically retain key design features (screens, speakers, microchips) from previous generations. They inherit these features. Similarly, the structural design of modern airplanes are inherited from the structural design of previous generations, and ultimately from the basic principles of aerodynamics from early aircraft.</p><p> <strong>2. Machine Reproduction:</strong> <strong>The process by which new generations of machines are created and replicated.</strong></p><p> For example, the mass production of the latest smartphone model in factories worldwide, all from the same template, or the increasing role that other machines and mechanical design play in the reproduction of airplanes, automobiles, and tablets.</p><p> <strong>3. Machine Mutation:</strong> <strong>Design changes or innovations that introduce new features or capabilities to a specific machine.</strong></p><p> For example, the transition from wired to wireless technology in headphones and the computer mouse, or the deleterious mutation of introducing <a href="https://en.wikipedia.org/wiki/Office_Assistant#Criticism"><u>Clippy</u></a> , the much maligned “office assistant” in Microsoft programs that was removed from the subsequent generations, rendering Clippy all but extinct. For computing machines, this is often a change in software. Another example is adding multiple camera lenses to smartphones.</p><p> <strong>4. Machine Recombination:</strong> <strong>The introduction and synthesis of specific features, designs, or technologies from current machines to create a new machine.</strong></p><p> For example, the integration of internet connectivity from computers to televisions, introducing us to smart TVs, or the development of drones, which combine technologies from aviation, robotos, and remote control systems. There&#39;s also the <a href="https://en.wikipedia.org/wiki/Keytar"><u>keytar</u></a> , the famous recombination of a keyboard and a guitar.</p><p> <strong>5. Artificial Selection: The differential survival and reproduction of successful technological features (due to efficiency, effectiveness, popularity and so on) as expressed in the form of individual machines. It should also be noted that artificial selection can more usefully be thought of as “intentional” or “designed” (which is why the term is used over “natural,” here) when compared to natural selection which is more typically thought of as “blind”.</strong></p><p> The evolution of smartphones is instructive here as well. Over the past decades, features that users found most useful, efficient, or popular in smartphones have been retained and improved upon in subsequent generations, while less favorable features have been phased out. For instance, consumers showed a strong preference for touchscreens over physical keypads, leading to the dominance of touchscreen smartphones today. Additionally, features like facial recognition, larger battery capacities, and improved camera technologies have been promoted due to their popularity and effectiveness, shaping the current generation of smartphones.</p><p> The evolution of smartphones also points to one additional form of evolution that is of importance to intelligent computing machines and that is the role of software in machine evolution. For example, one might consider the evolution of AI to be just as much about the evolution of software as the evolution of any particular machine, in fact it may even make more sense to think of the evolution of AI as being primarily driven by the evolution of software. This is a point we hope to explore in future posts.</p><p> Now that we have our observed trends and we have recast biological evolutionary processes in terms of machine evolutionary processes, let us briefly demonstrate how these evolutionary processes may be used to help explain the observed trends.</p><ol><li> <strong>Improvements in machine capabilities</strong> : This can be seen as a consequence of “artificial selection” where machines experience “recombination” of various forms and some “mutations” that lead to differential survival and “reproduction” rates.</li><li> <strong>Increases in the amount of computing machines</strong> : This can be thought of as a particularly successful “recombination” of the design feature of “computation” throughout the “artificial selection” machine ecosystem.</li><li> <strong>Increasing role of machines in the design and creation of new machines</strong> : At some point, a “machine mutation” led to the involvement of machines in the design and creation of other machines. This was a remarkably successful mutation, and was “inherited” and “recombined” as a result, spreading far and wide through “artificial selection”</li></ol><h1> Finding deviations</h1><p> For the comparison between machine and biological evolution to be useful, we need to understand its limitations. Where do the theories align and where do they diverge? Here are three important differences between them:</p><h2> <strong>Technological evolution is externally directed</strong></h2><p> In biological evolution, natural selection is an <i>emergent</i> phenomenon. Individuals pass an imperfect copy of their DNA to their offspring, marred by replication errors and shoddily repaired damage (a partial copy, in the case of sex). The rare mutations that make a gene more likely to be passed on will spread at the expense of neutral and deleterious mutations.</p><p> In contrast, technological changes are guided by design. The new forms experience selection pressures analogous to biological evolution, but technologies don&#39;t reproduce in a way that&#39;s properly analogous to either asexual or sexual reproduction. Rather than Darwin&#39;s <a href="https://en.wikipedia.org/wiki/History_of_evolutionary_thought#:~:text=Darwin's%20theory%2C%20originally%20called%20descent,could%20share%20a%20common%20ancestor."><u>descent with modification</u></a> , we see <i>replication</i> with modification. Changes are introduced and removed deliberately, and the people behind those changes are incentivised to make as much progress as possible as quickly as possible, whereas most species <a href="https://en.wikipedia.org/wiki/Mutation_rate#Evolution"><u>maintain a trade-off</u></a> of moderate mutation rates to balance the generational adaptability provided by high mutation rates (and the metabolic cost of <a href="https://en.wikipedia.org/wiki/DNA_polymerase_epsilon"><u>repairing DNA replication errors</u></a> ) against the advantage of having fewer deleterious mutations in each generation (among other factors).</p><h2> <strong>Genes have to do everything</strong></h2><p> In biology, genes must fulfill many functions without any long-term plan. The genes themselves encode proteins, but are also the “memory” of the system - if a gene leaves the gene pool, it&#39;s gone unless it&#39;s recreated through mutation again. Each gene must ensure its own replication.</p><p> In contrast, there&#39;s a separation of powers in machine evolution. Many minds can work on the same problem, many solutions can be compared in parallel and in advance, all before any physical manifestation must be produced and tested in the wild. Data can be stored remotely, rather than the only copy of a machine&#39;s “genome” being stored inside that machine. There&#39;s creativity and memory: both old forgotten and brand new ideas can be introduced without any predecessor in the previous generation.</p><p> This, combined with the first point, means that machine evolution can be much, much faster than biological evolution, and less “wasteful”. We don&#39;t need to try random variations, most of which would ruin the technology. Unlike with natural selection, we can deliberately fiddle with the <i>mechanism</i> of technological evolution, using machines themselves to help us engineer designs, for example. This may even be considered to be somewhat <a href="https://en.wikipedia.org/wiki/Lamarckism"><u>Lamarckian</u></a> .</p><h2> <strong>Machines don&#39;t have sex</strong></h2><p> Many species reproduce asexually, but when discussing evolution, we tend to focus on sexual reproduction since this is the most common form for animals and plants. However, sexual reproduction doesn&#39;t have a clear analogue in machine evolution. Sex involves the mixing of two individuals&#39; genes to produce offspring.</p><p> Sex is strange, as it evolved despite <a href="https://en.wikipedia.org/wiki/Evolution_of_sexual_reproduction#Disadvantages_of_sex_and_sexual_reproduction"><u>heavy costs</u></a> (for example, half of humanity can&#39;t reproduce, and the other half requires the input of the first half to do so). The advantages of sex are complicated, including factors like variation within a species that doesn&#39;t apply to machines, which tend to be mass-produced in a way more analogous to cloning than sex.</p><p> Sex also leads to sexual selection, where traits proliferate when they improve an organism&#39;s ability to attract a mate, often through competition with others of the same sex. This sometimes leads to strange adaptations such as <a href="https://en.wikipedia.org/wiki/Peafowl#Sexual_selection"><u>peacocks&#39; displays</u></a> , <a href="https://www.google.com/search?q=pufferfish+courtship+ritual&amp;tbm=isch&amp;ved=2ahUKEwjx28fN3d6AAxVAmScCHTXIBxUQ2-cCegQIABAA&amp;oq=pufferfish+courtship+ritual&amp;gs_lcp=CgNpbWcQDDIECCMQJ1AAWABgswZoAHAAeACAATmIATmSAQExmAEAqgELZ3dzLXdpei1pbWfAAQE&amp;sclient=img&amp;ei=YnjbZPGiMsCynsEPtZCfqAE&amp;bih=923&amp;biw=1920&amp;rlz=1C1GCEA_enGB1047GB1047"><u>pufferfish sand art</u></a> , and, some argue, <a href="https://en.wikipedia.org/wiki/Evolution_of_human_intelligence#Sexual_selection"><u>human intelligence</u></a> . In some cases, such traits even end up reducing the fitness of the species as a whole, such as the insane antlers on male Irish elk, which weighed 40kg and measured 3.65m from tip to tip. These likely evolved as a sexual display, and their burden may have contributed to the <a href="https://en.wikipedia.org/wiki/Irish_elk#Extinction"><u>species&#39; extinction</u></a> .</p><p> <a href="https://commons.wikimedia.org/wiki/File:Paonroue.JPG"><img style="width:45.6%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/ndo1isewwgb4vevatnwd" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/k740gwy4ytakhwadvzyk 155w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/pixm0h4nkhaeoudjpu96 235w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/md5fjgquhcixr2r74fji 315w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/ntgnrzdsvmtg3bujlpru 395w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/s3cbme2iyxh2co202al2 475w"></a> <a href="https://commons.wikimedia.org/wiki/File:Jele%C5%84_olbrzymi_Megaloceros_giganteus.jpg"><img style="width:41.65%" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/kcsg7kz8po2xtef9okhh" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/dapmm9gogsmpe8btedkl 132w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/xekodopw8mjacze45ivb 212w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/oyajdbvwixfoobfidtel 292w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/w0omjau4sazjth9mdwfj 372w"></a></p><p> There&#39;s no exact analogue for this kind of selective pressure, nor its consequences, for machines.</p><h1> The Evolution of Selection Pressures</h1><p> In this section we&#39;ll explore the evolution of selection processes, and the transitions from (1) Natural Selection through (2) Artificial Selection to (3) Technological Selection (or Technoselection). We argue that while natural selection continues to play a dominant role in the evolution of biological organisms, that in the case of humans, <i>artificial selection</i> has been added as a new form of evolutionary pressure. Artificial selection, a term we borrow from Charles Darwin, highlights the role that humans and human societies already play in shaping the evolution of humans, our machines, and other human artifacts such as markets and organizations. This evolution of evolutionary selection pressures alongside the trends found in machine evolution suggests a plausible new form of selection pressure on the horizon that we call technoselection. As humans have begun playing a larger role in shaping their own evolutionary pressures, so increasingly intelligent  computing machines will begin to play a larger role in shaping their own evolutionary pressures as well. We have seen that human intelligence is a stronger selection process than natural selection. Artificial intelligence, found in advanced computing machines, if it vastly surpasses human intelligence, will be an even stronger selection process than human intelligence.</p><h2> <strong>Natural Selection</strong></h2><p> In biological evolution, with all species of flora and fauna, there are <i>always</i> two major macro-incentives at work: survival and reproduction. The natural processes for succeeding or failing in survival and reproduction – <i>natural and sexual selection</i> – are both blind and slow. In other words, if natural environmental conditions change, sometimes drastically, then species that are unable to adapt accordingly face being <i>naturally selected</i> for extinction.</p><p> It is important to note that, within an entire population of species, there will always be emerging genetic mutations. Far more likely than not, mutations are harmful to an organism ie maladjusted. However, on occasion, mutations can prove to be beneficial and allow for greater fitness within an environmental niche. For example, giraffes didn&#39;t simply want to eat leaves higher on trees and so stretched their necks more and more and passed along this desire to their offspring&#39;s genotypes. (Although epigenetics may have some causal influence over acetylation and methylation of genes, this is not a driving factor in this example.)</p><p> This was the pre-Darwinian belief of Jean-Baptiste Lamarck. But Charles Darwin, and the later contributors of the New Synthesis of evolutionary theory, proposed a much more elegant and cogent account of natural behaviour. Instead of a Lamarckian account, they proposed that those giraffes with mutated genes gifting them with the phenotypic traits of slightly longer necks, tended to reach the higher leaves better, and hence, survived more healthy and longer, thereby giving them greater mating opportunities which, in turn, passed along those longer-neck mutations throughout a population. Should, over time, the environment change again – for example, only leaves on the lowest branches of trees survived - then we might see a gene shift in population phenotypic characteristics over time producing shorter-necked giraffes. But this will take quite a few generations to reach a new balancing selection. In this way, evolution, through natural and sexual selection, is both blind and slow. That is, if environmental conditions change drastically, those lucky few mutants that have slightly better-fitting phenotypic traits will stand a better chance for being selected to survive than the rest of the population.</p><p> Historically, there was a different form of evolutionary battle going on between Charles Darwin and Jean-Baptiste Lamarck. The battle was one of evolutionary epistemology – that is, a battle between the survival of competing ideas or knowledge that would be selected for its cogency and soundness amongst the scientific communities. Lamarck&#39;s theory of &#39;Inheritance of Acquired Traits&#39; proposed that the traits a set of parents learned while surviving would somehow be transferred onto their progeny or offspring after reproduction (see giraffe example, above). In other words, Lamarck incorrectly believed that a set of parents&#39; learned self-improvements could somehow be passed onto their offspring. Although this theory falsely characterizes human evolution, and was not selected for continued existence/acceptance of the scientific communities, it may turn out to be the basic model for machine evolution. For the transmission of information – and behaviour – would follow quite systematically with machines. In other words, manufacturers use a model involving a Lamarckian model proposing &#39;the inheritance of acquired characters&#39;.</p><blockquote><p> <a href="https://necsi.edu/what-lamarck-believed#:~:text=Lamarck%20is%20best%20known%20for,passed%20on%20to%20its%20offspring"><u>If an organism changes during life in order to adapt to its environment, those changes are passed on to its offspring</u></a> .</p></blockquote><p> Manufacturers of machines build on what they already have – a substrate. They don&#39;t reinvent the wheel – they improve upon it according to consumer and financial pressures. Hence, machine evolution follows Lamarckian principles which do not apply to human evolution. But just as the Ptolemaic geocentric astronomical system was replaced by the heliocentric version of Copernicus, Galileo, Brahe, and Newton, it can still be used by seafarers to correctly guide them while at sea. Perhaps Lamarck shall have his day after all with artificial life.</p><h2> <strong>Artificial Selection</strong></h2><p> About 6 million years ago, humans descended with modification and split from a common ancestor with the chimpanzee, then to Australopithecines, then to the various Homo species, and finally to sapiens. Now, although humans, like every other form of flora and fauna on the planet, must compete for sex and survival, our evolutionary history is quite unique because somewhere along the way, throughout the span of 6 million years of descent with modification, we developed consciousness and sophisticated languages which allowed us to actively direct our <a href="https://jcer.com/index.php/jcj/article/view/51"><u>behaviour and gain greater control over our environments</u></a> . Rather than blindly responding to environmental pressures purely in accordance with hard-wired instincts, consciousness allowed our species the capacity to reflectively devise options and alternatives to varying environmental pressures. As a result, our species developed rich and varied cultures which capitalized on novel ideas and materials manipulation in an effort to improve our lives and increase the likelihood of surviving and reproducing. In this way, we moved, epistemically, from reacting blindly to environmental pressures, to acting reflectively. For the first time in our evolutionary past, we had developed the capacity to understand gaps in our explanatory schemas. And then we could take action by filling in those gaps with directed and novel ideas.</p><p> As such, within each culture, many artifacts were invented, developed, and refined; from hand axes, to the controlled use of fire, to the development of the wheel, to germ theory, and nuclear fusion. The so-called &#39;cultural explosion&#39; of the Upper or Late Pleistocene about 30,000 years ago ushered in enormous developments in tools, cooking methods, weaponry, housing, clothing, and just about every other manner of self-improvement. These artifacts – <a href="https://en.wikipedia.org/wiki/The_Selfish_Gene"><u>or memes, as Dawkins calls them</u></a> – have continued to develop as humans continue to culturally evolve.</p><p> After the advent of agriculture about 10,000 years ago, the world has never been the same. Knowing where your next meal is coming from freed up a lot of time for our ancestors to become adept at various tasks which later became occupations. Humans have become increasingly specialized in tasks ever since. Once particular flora and fauna became domesticated, it didn&#39;t take long to begin breeding techniques using <i>artificial selection</i> to attain particular desired qualities in plants and animals. Just look at the current size of bananas or corn from their much smaller progenitors.</p><p> Or consider our pet dogs; no matter how large, or how small, how cute, or how friendly, each of these owes its ancestry to the common grey wolf. In case you&#39;re wondering why a Corgi looks like it does, or a Chow, or a Great Dane, Chihuahua, or your basic mutt, it&#39;s because some ancestors thought it was a good idea to mate dogs with some desirable qualities with other dogs possessing other desirable qualities. </p><figure class="image image_resized" style="width:61.44%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/e6gg8S8AfJmwE8HLh/yg61jfi9jxrnbjjhetzv"></figure><p> Ears of non-domesticated teosinte (above) and its domesticated variant, corn (below), selectively bred for human cultivation over ~10,000 years.</p><p> So now, for the first time in our existence, we were in control of phenotypic traits that were desired for some specific reason or other. For animal domestication and husbandry, dogs were bred so that their phenotypic traits would assist in hunting (Dachshund) or transportation (Huskie), or purely aesthetics (Pug).</p><p> Human-directed artificial selection has extended into the area of machine evolution as well. For millennia, humans have been tinkering, adjusting, and modifying machines to become more and more useful and beneficial to humankind. If we just look at the development of the television for example, we see many different ways in which the efficiency of such a device has been improved upon from analog to digital, from fuzzy screens to high-definition, from clunky and small to flat screen and huge, to prohibitively expensive to affordable, etc. The delivery service for such devices has also been vastly improved; from rabbit ears in the 50s and 60s, to antennas, to cable, to satellite, there has been a relatively steady increase in the development and improvement of the television since its inception. The same can be said for other types of machines as well – cars, planes, trains, appliances, etc. And of course, the exact same parallel can be drawn when talking about the evolution of machines like computers and robots.</p><p> We have seen significant improvements in both fields from the <a href="https://www.computerhistory.org/timeline/computers/"><u>earliest</u></a> times to <a href="https://www.youtube.com/watch?v=D_Vc_yDvU24"><u>now</u></a> . And this trajectory will continue until we reach a critical point at which machines will be capable of making their own modifications for subsequent generations.</p><h2> <strong>Technoselection</strong></h2><p> Artificial selection (as far as we know) is unique to humans. We are the first species to recognize and use our own artifacts to take some degree of control over the selective pressures on our species. Will machines go through the same phase transition in their evolutionary pressures? Will they wrest control over their evolution as we did? Currently, artificial narrow intelligence (ANI) acts much like our Australopithecine ancestors – blindly and according to specific constraints. But just as we created artifacts to alter the direction of our own evolution, there may be a similar shift in machine evolution as we approach artificial general intelligence (AGI).</p><p> Technoselection is the term we give for the next evolution of evolutionary pressures. Roughly put, natural selection relies on slow, blind, natural processes; artificial selection additionally relies on the creation of artifacts by humans that shape our evolutionary process and that of our machines with intentional design; technoselection pressures arise as our technology increasingly plays a large role in shaping its evolutionary pressures. With technoselection, machines themselves play more and more significant roles in their own design and development. It seems to us that this evolutionary process may arise from AGI development (1) through increased ability to autonomously create new and useful technological objects and/or (2) through machines that develop a form of machine sentience, consciousness, or general self awareness.</p><p> There are divided camps concerning whether or not machines will be able to comprehend their own existence and, as such, reflectively modify themselves or other machines in accordance to their emerging value systems. At this point in time, the evolution of such machines <a href="https://arxiv.org/abs/2303.07103"><u>suggests a potential path towards self-awareness or apperception</u></a> . And should this occur, it will raise a number of pressing questions, not the least of which is: How will we know? What Turing Test will exist to make such determinations? What theory of mind will allow us to see into the black box of a techno-brain to know, even if only analogously, that they are becoming more like us? But it is at this point that we need to ask another very important question:</p><p> Why should a machine&#39;s emergent consciousness be similar to ours?</p><p> We are carbon-based; they are silicon-based. Airplanes don&#39;t flap their wings to fly like birds; this would be incredibly inefficient. And yet they fly. They fly faster, higher, and better than any birds ever could or will. For those who eschew the idea of machines developing human-like qualities, such as consciousness or sentience, is this not simply the anthropocentric emergence of a new form of logical bias and discrimination – an <i>ad machina</i> attack? At this point in time, we have little idea what it might be like for an AI machine to be conscious or sentient.</p><p> Further, more deeply pressing questions are going to need to be answered; and perhaps, sooner than later. For example, does such an ontological shift in <i>technoselection</i> mean that such machines have attained personhood status? And, as such, should they be afforded rights? Even though sexual reproduction would not be a driving factor for such machines, perhaps replication and modification would be. And whether or not such machines attain a level of consciousness, how much autonomy should be afforded such machines in the future modification of their systems? How much will and should we be able to control or contain such features of modification and self-improvement? If the macro programs of machine learning are survival and optimal functionality, how might this play out in projected scenarios involving greater and greater capacities for self-improvement – whether consciously attained or not? For <i>technoselection</i> can still occur whether the machines are consciously aware of their environments or not. Blind technoselection can also be as productive or destructive, controlled or uncontrolled, as reflective technoselection. Should technoselection emerge, are we prepared for it? Have we sufficiently anticipated and answered the questions above? Given the current states of both technical AI safety and AI Governance, the answer is clearly no.</p><h1> Conclusion: Machine Evolution &amp; Human Control</h1><blockquote><p> <i>Samuel Butler died in 1902. The mechanical kingdom continued to proliferate, spawning a cascade of new species while others, such as steam engines, became extinct. With the advent of electronic digital computers the sense of anticipation – and interest in Butler&#39;s prophecies – was renewed. These machines showed signs of intelligence, and intelligence is a sign of life, even skeptics have agreed. But to ascribe a living intelligence to computers confuses causes with symptoms and was soon shown to be premature.</i></p><p> <i>Computers may turn out to be less important as an end product of technological evolution and more important as catalysts facilitating evolutionary processes through the incubation and propagation of self replicating filaments of code…..</i></p><p> <i>The origins of life as we know it – and life as we are creating it – are to be found in the cross-fertilization between self-sustaining metabolism and self replicating code. The coalescence of the kingdom of numbers with the kingdom of machines has been incubating for over three hundred years.</i></p></blockquote><p> — Darwin Among The Machines: The Evolution Of Global Intelligence by George B. Dyson, 1997</p><p> This post is the beginning of Part III of the running sequence exploring <a href="https://www.lesswrong.com/posts/CFuqKkgEwQWCpdaZG/how-humanity-lost-control-and-humans-lost-liberty-from-our"><u>how humanity lost control and humans lost liberty</u></a> . It is in Part III that we explore some of the most important objects and structures that shape our current moment in the new age of AI darkness. This chapter has provided an initial exploration of how machines are evolving and the underlying processes that drive these processes.</p><p> We noted easily observable general trends in machine evolution which include (1) an increase in machine capabilities, (2) increases in computing machines, and (3) an increase in the role of machines in creating new machines. We then turned to a brief description of 5 core tools of biological evolution (not meant to be exhaustive but simply exploratory) including: (1) heritability, (2) reproduction, (3) mutation, (4) recombination, and (5) natural selection. From here, these processes of biological evolution were given machine analogs to machine evolution. We describe the concepts of machine inheritance, machine reproduction, machine mutation, and machine recombination. While we found this simple renaming appealing for these processes, we decided that natural selection needed a different treatment. For an analogy to natural selection we have chosen the term <i>artificial selection</i> which is driven in large part by human culture, human artifacts, and individual humans. We prefer artificial selection to “machine selection” or something like that because it hews closely to the distinction that Charles Darwin made and to make clear the continued role of humans (and our artifacts) in this process. Artificial selection also highlights the ways in which this selection pressure applies more generally to human artifacts. Human intention and human design have shifted the pace of evolution of artifacts, including machines, rocketing forward by comparison to biological evolution. However, the evolution of evolutionary selection processes does not end with artificial selection. We see an increasing role of machines in processes such as  machine design, machine reproduction, machine recombination, and artificial selection. Taken together these trends suggest the eventual appearance of a new form of evolutionary pressure that we call <i>technoselection.</i> In a world of technoselection, machines themselves will play a more direct role in shaping their own evolution, similar to the way in which humans have used artificial selection to shape their own evolution.</p><p> New generations of digital computing machines, for example, inherit mutated and recombined forms of hardware and software from previous generations. It is then through artificial selection, through human-aided differential rates of reproduction and survival rates from which the winning machines flourish and the losing machines go extinct. It is typically through competition and cooperation that both specific organisms and specific machines survive, reproduce, and evolve to adapt to their environment, lest selection leave them behind.</p><p> The analogy, however, is a work in progress. For this post, we identified three initial examples of the limitations of our analogy. There are of course others, but we believe these three examples draw attention to important distinctions that we would like to explore further. The first identified limitation is the absence of a clear analogue for sexual selection in machine evolutionary forces. Further, randomness or at least quasi-randomness play large roles in shaping evolution. This is less true for machine evolution which is much more a product of directed human, and more recently, machine-aided human design. That is, while biological organisms evolved, slowly, with small genetic mutations and recombinations being favored by natural selection over time, entirely new and completely modified machines are designed, built, and deployed deliberately by humans as a result of a myriad of factors in both their own nature and their environment.</p><p> It is this point of deviation from the randomness of biological evolution to the deliberateness of modification of machine evolution that we would like to linger upon in closing. In a broad sense, the whole endeavor of human technology has been to assist humans in wresting some control away from nature and making it their own. This process has begun to shift evolutionary processes away from natural selection and towards artificial selection.</p><p> Machine evolution is already a phenomenon that is not random but rather deliberate and directed by humans. And, as we have discussed earlier, machines themselves are beginning to play larger roles both in the reproduction of other machines and in designing and creating new machines. This trend suggests to us that technoselection, a point at which machines, at least in part, direct their own evolution, is likely near. And this trend makes clear the importance of <a href="https://www.lesswrong.com/posts/J8WHyePqhTwPzXEPw/keep-humans-in-the-loop#Using_AI_to_develop_AI"><u>keeping humans in the loop</u></a> as the selection pressures evolve in this direction.</p><p> One can see humanity&#39;s control of its machines slipping away, one generation of intelligent computing machines at a time.</p><h1> Additional Reading &amp; Next Steps</h1><p> While there is not much work in this direction, there are a few specific works in this direction that you may find interesting and that we have drawn from in researching and developing this post.这些包括</p><ul><li>Samuel Butler (1872) <a href="https://www.lesswrong.com/posts/jMZ8wcHNj8YgdGtKf/the-book-of-the-machines-chapter-8">&quot;The Book of the Machines&quot;</a> ;</li><li> <a href="https://kk.org/outofcontrol/"><u>Kevin Kelly (1995) &quot;Out of Control&quot;</u></a> ;</li><li> <a href="https://en.wikipedia.org/wiki/Darwin_among_the_Machines#Evolution_of_Global_Intelligence"><u>George Dyson (1997) &quot;Darwin Among the Machines&quot;</u></a> ;</li><li> <a href="https://arxiv.org/abs/2303.16200"><u>Dan Hendrycks (2023) &quot;Natural Selection Favors AIs Over Humans&quot;</u></a> ;</li><li> <a href="https://www.lesswrong.com/posts/PKeAzkKnbuwQeuGtJ/welcome-to-analogia-chapter-7"><u>Justin Bullock&#39;s earlier post in this sequence “Welcome to Analogia!”</u></a></li><li> <a href="https://drive.google.com/file/d/1kXx-J68scFPHy-WZvbolGMMx4HdVzLxC/view?usp=share_link"><u>Justin Bullock and colleagues (2023) &quot;Introduction to The Oxford Handbook of AI Governance.&quot;</u></a></li></ul><p> As noted throughout, we hope to explore the idea of applying the general logic of biological evolution to other phenomena and objects as well. The evolution of organizations is the next topic in this sequence, and we also hope to further explore other topics such as technological evolution, software evolution, and AI evolution to better understand how the risks of AI and technological development can be examined with these lenses.</p><p> <i>**This post was developed by the Convergence Analysis team with the authors Justin Bullock, Christopher DiCarlo, and Elliot Mckernon each contributing substantively and substantially to the argument. We received multiple rounds of detailed feedback from David Kristofferson for which we are grateful. We appreciate the opportunity to explore these concepts as we seek to better understand the evolution of Artificial Intelligence and intelligent computing machines. We believe a deeper understanding of these topics will help us to better understand pathways to mitigating AI risks.**</i></p><br/><br/> <a href="https://www.lesswrong.com/posts/e6gg8S8AfJmwE8HLh/machine-evolution#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/e6gg8S8AfJmwE8HLh/machine-evolution<guid ispermalink="false"> e6gg8S8AfJmwE8HLh</guid><dc:creator><![CDATA[Justin Bullock]]></dc:creator><pubDate> Mon, 11 Sep 2023 19:29:53 GMT</pubDate> </item><item><title><![CDATA[Is there a hard copy of the sequences available anywhere?]]></title><description><![CDATA[Published on September 11, 2023 7:01 PM GMT<br/><br/><p> Forgive me if there&#39;s an easily available answer, I have not been able to find it after several attempts. I know there is an ebook but I would like a hard copy of Rationality AZ or the original sequences as a (set of) books.</p><br/><br/> <a href="https://www.lesswrong.com/posts/LehrFKxdyvDrWEuGx/is-there-a-hard-copy-of-the-sequences-available-anywhere#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/LehrFKxdyvDrWEuGx/is-there-a-hard-copy-of-the-sequences-available-anywhere<guid ispermalink="false"> LehrFKxdyvDrWEuGx</guid><dc:creator><![CDATA[Cole Wyeth]]></dc:creator><pubDate> Mon, 11 Sep 2023 19:01:55 GMT</pubDate> </item><item><title><![CDATA[Amazon KDP AI content guidelines]]></title><description><![CDATA[Published on September 11, 2023 6:36 PM GMT<br/><br/><p> Amazon updated the content guidelines for Kindle Direct Publishing to address AI and in the process attempted to define terms AI-generated and AI-assisted. Guidelines like this are how our society tries to engage with AI in the near-term.</p><blockquote><p> Artificial intelligence (AI) content (text, images, or translations)<br> We require you to inform us of AI-generated content (text, images, or translations) when you publish a new book or make edits to and republish an existing book through KDP. AI-generated images include cover and interior images and artwork. You are not required to disclose AI-assisted content. We distinguish between AI-generated and AI-assisted content as follows:</p><p> AI-generated: We define AI-generated content as text, images, or translations created by an AI-based tool. If you used an AI-based tool to create the actual content (whether text, images, or translations), it is considered &quot;AI-generated,&quot; even if you applied substantial edits afterwards.<br> AI-assisted: If you created the content yourself, and used AI-based tools to edit, refine, error-check, or otherwise improve that content (whether text or images), then it is considered &quot;AI-assisted&quot; and not “AI-generated.” Similarly, if you used an AI-based tool to brainstorm and generate ideas, but ultimately created the text or images yourself, this is also considered &quot;AI-assisted&quot; and not “AI-generated.” It is not necessary to inform us of the use of such tools or processes.</p><p> You are responsible for verifying that all AI-generated and/or AI-assisted content adheres to all content guidelines. For example, to confirm an AI-based tool did not create content based on copyrighted works, you&#39;re required to review and edit any AI tool outputs.</p></blockquote><p> What do you think about how Amazon defined the terms and makes those distinctions? Do you think they should change the definitions? Do you think there are other distinctions they should make?</p><br/><br/> <a href="https://www.lesswrong.com/posts/4csaBfAgiyzrFXvEj/amazon-kdp-ai-content-guidelines#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/4csaBfAgiyzrFXvEj/amazon-kdp-ai-content-guidelines<guid ispermalink="false"> 4csaBfAgiyzrFXvEj</guid><dc:creator><![CDATA[ChristianKl]]></dc:creator><pubDate> Mon, 11 Sep 2023 18:36:09 GMT</pubDate> </item><item><title><![CDATA[A Case for AI Safety via Law]]></title><description><![CDATA[Published on September 11, 2023 6:26 PM GMT<br/><br/><p> This post is to make the subject case more available and open to comment. A paper with the above title is currently languishing in arXiv limbo but available in <a href="https://drive.google.com/file/d/1CzDGBtjY92qQujLKYysbaIF1agoDoUJE/view?usp=sharing">Google Docs</a> . I was surprised to see my last and only postings to LessWrong were made on this very subject in 2010 as comments to the thread &quot;Why not just write failsafe rules into the superintelligent machine?&quot;</p><p> Unfortunately (IMO) this approach to AI alignment doesn&#39;t seem to have gained much traction in the past 13 years. The paper does cite, however, 15 precedents that show there is some support. (Anthropic&#39;s <i>Constitutional AI</i> and John Nay&#39;s <i>Law Informs Code</i> are two good recent examples.)</p><p> The following reproduces the <strong>Summary of Argument</strong> and <strong>Conclusion</strong> sections from the paper.</p><p> The claim being argued is &quot; <i><strong>Effective legal systems are the best way to address AI safety</strong></i> .&quot;</p><p> <strong>4 Summary of Argument</strong></p><p> <i><strong>4.1 Law is the standard, time-tested, best practice for maintaining</strong></i><br> <i><strong>order in societies of intelligent agents.</strong></i></p><p> Law has been the primary way of maintaining functional, cohesive societies for thousands of years. It is how humans establish, communicate, and understand what actions are required, permissible, and prohibited in social spheres. Substantial experience exists in drafting, enacting, enforcing, litigating, and maintaining rules in contexts that include public law, private contracts, and the many others noted in this brief. Law will naturally apply to new species of intelligent systems and facilitate safety and value alignment for all.</p><p> <i><strong>4.2 Law is scrutable to humans and other intelligent agents.</strong></i></p><p> Unlike AI safety proposals where rules are learned via examples and encoded in artificial (or biological) neural networks, laws are intended to be understood by humans and machines. Although laws can be quite complex, such codified rules are significantly more scrutable than rules learned through induction. The transparent (white box) nature of law provides a critical advantage over opaque (black box) neural network alternatives.</p><p> <i><strong>4.3 Law reflects consensus values.</strong></i></p><p> Democratically developed law is intimately linked and essentially equivalent to consensus ethics. Both are human inventions intended to facilitate the wellbeing of individuals and the collective. They represent shared values culturally determined through rational consideration and negotiation. They reflect the wisdom of crowds accumulated over time—not preferences that vary from person to person and are often based on emotion, irrational ideologies, confusion, or psychopathy. Ethical values provide the virtue core of legal systems and reflect the “spirit of the law.” Consequentialist shells surround such cores and specify the “letter of the law.” This relationship between law and ethics makes law a natural solution for human-AI value alignment. A minority of AIs and people, however powerful, cannot game laws to achieve selfish ends.</p><p> <i><strong>4.4 Legal systems are responsive to changes in the environment and changes in moral values.</strong></i></p><p> By utilizing legal mechanisms to consolidate values and update them over time, human and AI values can remain aligned indefinitely as values, technologies, and environmental conditions change. Thus law provides a practical implementation of Yudkowsky&#39;s (2004) Coherent Extrapolated Volition by allowing values to evolve that are wise, aspirational, convergent, coherent, suitably extrapolated, and properly interpreted.</p><p> <i><strong>4.5 Legal systems restrict overly rapid change.</strong></i></p><p> Legal processes provide checks and balances against overly rapid change to values and laws. Such checks are particularly important when legal change can occur at AI speeds. Legal systems and laws must adapt quickly enough to address the urgency of issues that arise but not so quickly as to risk dire consequences. Laws should be based on careful analysis and effective simulation and the system be able to quickly detect and correct problems found after implementation. New technologies and methods should be introduced to make legal processing as efficient as possible without removing critical checks and balances.</p><p> <i><strong>4.6 Laws are context sensitive, hierarchical, and scalable.</strong></i></p><p> Laws apply to contexts ranging from international, national, state, and local governance to all manner of other social contracts. Contexts can overlap, be hierarchical, or have other relationships. Humans have lived under this regime for millennia and are able to understand which laws apply and take precedence over others based on contexts (eg, jurisdictions, organization affiliations, contracts in force). Artificial intelligent systems will be able to manage the multitude of contexts and applicable laws by identifying, loading, and applying appropriate legal corpora for applicable contexts. For example, AIs (like humans) will understand that crosschecking is permitted in hockey games but not outside the arena. They will know when to apply rules of the road versus rules of the sea. They will know when the laws of chess apply versus rules of Go. They will know their rights relative to every software agent, tool, and service they interface with.</p><p> <i><strong>4.7 AI Safety via Law can address the full range of AI safety risks, from systems that are narrowly focused to those having general intelligence or even superintelligence.</strong></i></p><p> Enacting and enforcing appropriate laws, and instilling law-abiding values in AIs and humans, can mitigate risks spanning all levels of AI capability—from narrow AI to AGI and ASI. If intelligent agents stray from the law, effective detection and enforcement must occur.</p><p> Even the catastrophic vision of smarter-than-human-intelligence articulated by Yudkowsky (2022, 2023) and others (Bostrom, 2014; Russell, 2019) can be avoided by effective implementation of AISVL. It may require that the strongest version of the instrumental convergence thesis (which they rely on) is not correct. Appendix A suggests some reasons why AI convergence to dangerous values is not inevitable.</p><p> AISVL applies to all intelligent systems regardless of their underlying design, cognitive architecture, and technology. It is immaterial whether an AI is implemented using biology, deep learning, constructivist AI (Johnston, 2023), semantic networks, quantum computers, positronics, or other methods. All intelligent systems must comply with applicable laws regardless of their particular values, preferences, beliefs, and how they are wired.</p><p> <strong>5 结论</strong></p><p>Although its practice has often been flawed, law is a natural solution for maintaining social safety and value alignment. All intelligent agents— biological and mechanical—must know the law, strive to abide by it, and be subject to effective intervention when violated. The essential equivalence and intimate link between consensus ethics and democratic law provide a philosophical and practical basis for legal systems that marry values and norms (“virtue cores”) with rules that address real world situations (“consequentialist shells”). In contrast to other AI safety proposals, AISVL requires AIs “do as we legislate, not as we do.”</p><p> Advantages of AISVL include its leveraging of time-tested standard practice; scrutability to all intelligent agents; reflection of consensus values; responsiveness to changes in the environment and in moral values; restrictiveness of overly rapid change; context sensitivity, hierarchical structure, and scalability; and applicability to safety risks posed by narrow, general, and even superintelligent AIs.</p><p> For the future safety and wellbeing of all sentient systems, work should occur in earnest to improve legal processes and laws so they are more robust, fair, nimble, efficient, consistent, understandable, accepted, and complied with. (Legal frameworks outside of public law may be effective to this end.) Humans are in dire need of such improvements to counter the dangers that we pose to the biosphere and to each other. It is not clear if advanced AI will be more or less dangerous than humans. Law is critical for both.</p><br/><br/> <a href="https://www.lesswrong.com/posts/oi2YxRddakosnnbGX/a-case-for-ai-safety-via-law#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/oi2YxRddakosnnbGX/a-case-for-ai-safety-via-law<guid ispermalink="false"> oi2YxRddakosnnbGX</guid><dc:creator><![CDATA[JWJohnston]]></dc:creator><pubDate> Mon, 11 Sep 2023 18:42:00 GMT</pubDate></item></channel></rss>