<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 5 日，星期日 22:11:01 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Disentangling four motivations for acting in accordance with UDT]]></title><description><![CDATA[Published on November 5, 2023 9:26 PM GMT<br/><br/><h2>介绍</h2><p>在这篇文章中，我研究了一些关于充当无更新代理的不同论点。具体来说，我试图回答以下问题：<strong>什么可以促使那些尚未成为完全一致的</strong><a href="https://www.lesswrong.com/posts/de3xjFaACCAk6imzv/towards-a-new-decision-theory"><strong>UDT</strong></a><strong>代理的人采用类似 UDT 的策略？</strong></p><p>我之所以采取这种观点，是因为我并不是生来就是一个理想化的 UDT 智能体，而且我希望我愿意遵循 UDT（或支持指示 AI 这样做）之类的东西的程度能够在非同义反复的基础上得到证明。毕竟，根据定义，做“不更新的事情而不是可更新的事情”意味着做一些在目前的情况下是不好的事情。</p><p>为了清楚起见，我考虑了四种攀登更新不更新之山的方法。首先，我假设我们从非索引偏好和一些预先存在的决策理论直觉开始，例如，对于那些倾向于 CDT 的人来说，“我想带来良好的结果”。前三个路径从这里开始：如果我们将当前的决策理论直觉视为基石，这会导致我们以类似 UDT 的方式行事吗？我考虑的第四种方法是放弃我们之前的决策理论直觉，尝试直接跳转到 UDT。</p><p>需要注意的是：我在这里提出的所有动机都不会得到应有的深入讨论。这篇文章的作用更像是一本固执己见的指南：强调这样一个事实：存在不同的路径，采取这些路径时面临的困难，以及它们最终会到达相对不同的类似 UDT 的端点。这并不是说这本指南是完整的：我自己仍然是一个流浪者，偶尔会迷失方向，并寻求偏离人迹罕至的道路。</p><h2>类似 UDT 政策的四个理由</h2><p>为了做好准备，这里有一些故意模糊的定义：</p><ul><li><i>更新性</i>是选择你想要事前承诺的行动的格言，即在你学到现在所知道的一切之前。这到底意味着什么取决于多种因素，例如您认为自己的事前观点是什么，或者您会/应该想让自己学习并采取哪些行动。</li><li> <a href="https://www.lesswrong.com/tag/updateless-decision-theory"><i><u>UDT</u></i></a>是一种特殊的决策理论，旨在满足不可更新的需求。已经提出了不同版本的 UDT。 <span class="footnote-reference" role="doc-noteref" id="fnrefg2futd1ty3r"><sup><a href="#fng2futd1ty3r">[1]</a></sup></span></li><li>策略是从观察到行动的映射。如果某个策略选择与某些无更新代理的策略相同的操作，我将其称为<i>类 UDT</i> （在某些决策问题中），尽管这并不一定要求该策略实际上是无更新的。 <span class="footnote-reference" role="doc-noteref" id="fnrefk29az2gs07"><sup><a href="#fnk29az2gs07">[2]</a></sup></span></li></ul><p>那么我们为什么要采用类似 UDT 的政策呢？让我们看看四个可能的原因。</p><h3>将无更新作为元承诺</h3><p>当考虑多种可能的决策问题时，我们注意到，未来我们的行为可能与我们现在希望的行为不同。例如，我们知道，如果我们将来遇到这种情况，<i>现在</i>承诺在<a href="https://www.lesswrong.com/posts/mg6jDEuQEjBGtibX7/counterfactual-mugging"><u>反事实抢劫</u></a>中付出<a href="https://casparoesterheld.com/2016/11/21/thoughts-on-updatelessness/"><u>代价是获得更高预期回报的原因/证据</u></a>。因为我们事先并不知道所有决策问题，所以如果我们在做出元承诺时知道决策问题， <a href="https://www.lesswrong.com/posts/88vuFDw3dCX7hC6uW/self-modification-is-the-correct-justification-for"><u>我们可以实施元承诺</u></a>，以始终像我们希望承诺的那样行事：给定一个预先存在的更新决策理论 X，如 EDT，我们说我们自我修改为<i>&nbsp;</i> <a href="https://www.lesswrong.com/posts/5bd75cc58225bf067037528e/updatelessness-and-son-of-x"><i><u>X 的儿子</u></i></a>。构建这种推理的另一种方式是，更新的决策理论在孤立的决策情况下进行行动选择，X 的儿子代表了这样的见解：根据 X 的观点，最好利用最早的机会来执行行动“提交”根据我当前的信念制定最佳政策。</p><p>确切地说，你成为 X 之子意味着哪些承诺取决于你在自我修改时会得到 X 之光的认可。这会产生一些微妙之处：</p><ul><li>如果这就是您想要实现类似 UDT 行为的原因，那么如果您“生来”这个问题，那么您（还）没有理由付出代价。例如，如果<i>在您自我修改为 X 之子之前</i>，欧米茄以反事实抢劫的方式接近您，那么成为 X 之子就不足以证明付费是合理的。</li><li> Son of CDT 和 Son of EDT 之间有一个区别：假设 Omega 在你没有更新<i>后</i>用反事实抢劫来接近你，但告诉你它在你没有更新<i>之前</i>做出了预测。那么 CDT 之子就不会付款，因为不更新不可能是 Omega 预测的原因，而 EDT 之子仍然可以说服自己付款，因为不更新为 Omega 在不更新之前的预测提供了证据。</li><li> Son of X 可以通过考虑在无更新时具有哪些逻辑先验来实现<a href="https://www.lesswrong.com/posts/K5Qp7ioupgb7r73Ca/logical-updatelessness-as-a-robust-delegation-problem"><u>逻辑无更新</u></a>。 <span class="footnote-reference" role="doc-noteref" id="fnrefhwnrsq5ihmf"><sup><a href="#fnhwnrsq5ihmf">[3]</a></sup></span></li></ul><h3>对反事实世界具有内在偏好的无更新性</h3><p>当你决定在反事实抢劫中付出代价时，你会注意到，当且仅当你在你观察到的世界中付出代价时，你才会在<a href="https://plato.stanford.edu/entries/counterfactuals/"><u>反事实</u></a>世界中获得巨额回报。即使你没有观察那个反事实的世界，你可能仍然对它<a href="https://www.lesswrong.com/posts/9W4TQvixiQjpZmzrx/decision-theory-and-dynamic-inconsistency"><u>有内在的偏好</u></a>。这可能是因为您认为另一个世界确实存在，因此您在所观察的世界中所做的事情对那里发生的事情具有（逻辑或证据）影响。 <span class="footnote-reference" role="doc-noteref" id="fnref9mxfv5frni7"><sup><a href="#fn9mxfv5frni7">[4]</a></sup></span>但你可能会因为其他原因对反事实有偏好。</p><p>同样，我们可以观察到这个观点的一些微妙之处：</p><ul><li>从某种意义上说，当与反事实世界的偏好相结合时，这是一种类似 UDT 的行为源自 EDT 或 TDT 的方式，无需自我修改。另一方面，请注意这对于正统的 CDT 代理不起作用。</li><li>与 X 之子相反，这种推理甚至适用于“出生于”该问题的智能体，只要他们有足够的可信度相信存在一个他们“出生于”问题的另一个分支的世界。</li><li>使用这种动机似乎很难在逻辑上保持更新，因为对不可能的反事实有内在的偏好是相当违反直觉的——而且在我看来是荒谬的。一旦欧米茄以反事实的方式接近你，认为 π 的万亿位是偶数，你就会知道，不存在 π 的万亿位是奇数的世界，因此也不存在欧米茄向你付钱的世界。 <span class="footnote-reference" role="doc-noteref" id="fnrefmjh7gf6nzzg"><sup><a href="#fnmjh7gf6nzzg">[5]</a></sup></span></li></ul><h3>人为不确定性导致的类似 UDT 的行为</h3><p>如果您发现自己陷入反事实抢劫中，您可能会认为<a href="https://casparoesterheld.com/2017/05/12/anthropic-uncertainty-in-the-evidential-blackmail/"><u>“也许欧米茄正在模拟我以便做出预测”</u></a> 。 <span class="footnote-reference" role="doc-noteref" id="fnrefa581s2u0k5"><sup><a href="#fna581s2u0k5">[6]</a></sup></span> （请注意，这巧妙地违反了反事实抢劫中诚实的欧米茄的最初假设。）因此，付出代价是在现实中获得巨额回报的原因/证据。这听起来简单而<a href="https://www.alignmentforum.org/posts/5bd75cc58225bf06703751b2/in-memoryless-cartesian-environments-every-udt-policy-is-a"><u>优雅</u></a>，但实际上由于多种原因而非常复杂。仅给出三个考虑因素：</p><ul><li>粗粒度模拟：进行模拟的成本很高，特别是如果模拟的是像超级智能这样的“大”代理。但是，超级智能的粗粒度模拟可能会给出与全保真版本不同的输出，在考虑模拟的可能性时，这本身就是一个相关的复杂因素。</li><li>同构模拟：假设您关心最大化回形针。欧米茄可以模拟一个关心订书机等问题的你，而不是模拟一个完全相同的你。这样，Omega 就会发现“你的算法”在反事实抢劫中会做什么，但你的算法的每个实例并不关心是否使另一个实例受益。 （此问题主要影响CDT代理。）</li><li>人择理论和决策理论的兼容性有限：例如，有荷兰书籍反对<a href="https://joelvelasco.net/teaching/3865/briggs10-puttingavalueonbeauty.pdf"><u>EDT 与 SIA</u></a>以及<a href="https://www.andrew.cmu.edu/user/coesterh/DeSeVsExAnte.pdf"><u>CDT 与 SSA</u></a> 。一旦涉及决策，人择推理就会变得<a href="https://www.andrew.cmu.edu/user/coesterh/DeSeVsExAnte.pdf"><u>复杂</u></a>。</li></ul><p>然而，假设这是可行的，以下是与我们出于其他动机所做的观察相关的两个观察结果：</p><ul><li>这种推理适用于“天生”决策问题的情况，包括正统的 CDT 代理。</li><li>目前尚不清楚这是否能够促使人们表现得好像逻辑上没有更新一样。一方面，人们大概无法模拟不可能世界中的代理（否则它们是可能的）。另一方面，在实践中，我们的模拟器有时可能会欺骗我们，让我们相信世界是可能的——但这可能并不适用于所有逻辑更新性可能相关的情况。</li></ul><h3> UDT 是拒绝其他一切的结果</h3><p>你在纽科姆问题中因两拳击而拒绝 CDT，然后因在吸烟病变中不吸烟而拒绝 EDT，然后再次接受 EDT，因为<a href="https://www.andrew.cmu.edu/user/coesterh/TickleDefenseIntro.pdf"><u>痒痒防御</u></a>会处理吸烟病变，然后（也许）再次因支付<a href="https://www.alignmentforum.org/posts/5bd75cc58225bf0670374e7d/exploiting-edt"><u>XOR 勒索</u></a>而拒绝 EDT。 TDT <span class="footnote-reference" role="doc-noteref" id="fnrefkp296xiineq"><sup><a href="#fnkp296xiineq">[7]</a></sup></span>似乎是合理的（对围绕<a href="https://www.lesswrong.com/posts/QpqKBYzPKdZpByZS3/fdt-defects-in-a-realistic-twin-prisoners-dilemma"><u>相似但不相同的算法的</u></a>一些问题进行取模），成为 X 之子也是如此，但随后你意识到所有前面提到的决策理论<a href="https://www.lesswrong.com/posts/c3wWnvgzdbRhNnNbQ/timeless-decision-theory-problems-i-can-t-solve"><u>都不会在逻辑反事实抢劫中得到回报如果他们“生来”就是这样</u></a>。然而，在这样一个反事实的抢劫中支付费用是否意味着输赢是一个角度问题：一个自然的说法是“好吧，我已经知道欧米茄只给我一百万美元的世界是不可能的，所以<a href="https://casparoesterheld.com/2016/11/21/thoughts-on-updatelessness/"><u>如何才能做到这一点？”胜利不是付出</u></a>”。在我看来，拥有表面上对不可能的假设赋予非零权重的先验，需要来自<i>某个地方</i>的规范或认知上的理由，例如也许我关心逻辑上不可能的反事实世界 - 但为什么呢？ – 或者也许我相信我处于模拟中，或者存在一个世界，欧米茄在 π 相关数字的相反奇偶性上下注。</p><p>拒绝更新决策理论的一个<a href="https://www.lesswrong.com/posts/RcvyJjPQwimAeapNg/torture-vs-dust-vs-the-presumptuous-philosopher-anthropic"><u>更令人信服的理由</u></a>是它们对人择理论的依赖。人择推理似乎是可疑的<span class="footnote-reference" role="doc-noteref" id="fnrefiyinm22wk78"><sup><a href="#fniyinm22wk78">[8]</a></sup></span> ，并且使各种<a href="http://www.cs.cmu.edu/~conitzer/dutchSYNTHESE.pdf"><u>荷兰书籍</u></a>成为可能，也许还导致了其他<a href="https://www.lesswrong.com/posts/GJdymoviRywpBMXqc/sia-greater-than-ssa-part-2-telekinesis-reference-classes#V__Can_you_move_boulders_with_your_mind_"><u>弄巧成拙的策略</u></a>。解决这一系列问题值得单独写一篇文章，所以我不会在这里详细讨论——现在我注意到，在我看来，为什么人们想要遵循 UDT 的大部分争论力量都来自这里。</p><p>然而，订阅 UDT 并不像我们希望的那么简单。围绕如何<a href="https://www.lesswrong.com/posts/Bj244uWzDBXvE2N2S/a-model-of-udt-with-a-halting-oracle"><u>在实践中</u></a>形式化 UDT、如何选择先验以及是否（以及在何种程度上）在逻辑上应该是不可更新的问题仍然存在一些问题。</p><h2>要点</h2><p>总结一下：有不同的可能的考虑因素可以促使某人考虑类似 UDT 的行为，但不同的考虑因素会产生性质不同的风格。特别是，这会影响对逻辑更新性的态度，或者当一个人“出生”时遇到决策问题而没有机会自我修改为 X 之子时应该做什么。</p><p>就人们将 UDT 视为一种理想而言，这可能并不令人满意：对于那些被之前的决策理论直觉“毒害”的人来说，很难到达看似山顶的地方。例如，即使将前三种方法全部结合起来，这也可能不会导致人们开始了解的事实在逻辑上无法更新。但是，这个比喻有点过分了，直接跳到山顶可能会让我们缺氧：UDT 有一堆自由参数，我们不知道如何设置它们，还有一种方法可以让 UDT 接地类似的行为是问为什么，以及在多大程度上，我们会在目前的情况下认可它。</p><p>底线：</p><ul><li>就人们在考虑不可更新性时开始了解的逻辑事实而言，可能没有令人信服的理由证明逻辑上不可更新性。</li><li> Son of X 版本的 UDT 相对没有问题，但就人们开始了解的任何事实而言，不能证明不更新是合理的。</li><li>对反事实世界有偏好是对不更新意味着什么的一种描述。与 X 之子相比，对反事实世界的偏好可能会导致不更新，即使对于人们一直知道的经验事实也是如此。但这种偏好不会导致逻辑上的无更新，除非人们对不可能的世界有偏好。</li><li>人为的不确定性导致人们考虑类似 UDT 的行为，但总的来说，就其其他影响而言，这是一个相当大的混乱。</li><li>人们很容易拒绝更新的决策理论，因为它们依赖于可疑的人择理论。据我所知，在拒绝人类学之后是否（以及如何）保持不可更新，以及另一方面，人类学与更新决策理论相结合是否可以被保存，这些都是悬而未决的问题。</li></ul><h2>致谢</h2><p>感谢 Caspar Oesterheld、Jesse Clifton、Sylvester Kollin、Anthony DiGiovanni 和 Martín Soto 提供的有益评论和讨论。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fng2futd1ty3r"> <span class="footnote-back-link"><sup><strong><a href="#fnrefg2futd1ty3r">^</a></strong></sup></span><div class="footnote-content"><p><a href="https://philpapers.org/rec/LEVCDI"><u>功能决策理论</u></a>（FDT）通常被认为是 FDT 的一个版本，但<a href="https://www.lesswrong.com/posts/2THFt7BChfCgwYDeA/let-s-discuss-functional-decision-theory?commentId=LzPH8utKGSf97NihW"><u>据我所知</u></a>戴伟并不认可这一点。有关 UDT 不同版本的更多背景信息和概述，我推荐<a href="https://www.lesswrong.com/posts/QPhY8Nb7gtT5wvoPH/comparison-of-decision-theories-with-a-focus-on-logical"><u>这篇文章</u></a>。 MIRI 和 OpenPhil 人员之间的<a href="https://www.lesswrong.com/posts/FBbHEjkZzdupcjkna/miri-op-exchange-about-decision-theory-1"><u>交流</u></a>也提供了有用的背景和框架。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnk29az2gs07"> <span class="footnote-back-link"><sup><strong><a href="#fnrefk29az2gs07">^</a></strong></sup></span><div class="footnote-content"><p>另一种尝试在不提及 UDT 或更新性的情况下对此做出姿态：如果我有时做某事<i>只是</i>因为它会得到时空中不同位置（实际或假设宇宙的）我自己的版本的认可，那么我的决策就是 UDT 式的）。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnhwnrsq5ihmf"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhwnrsq5ihmf">^</a></strong></sup></span><div class="footnote-content"><p>正如这句话中链接的帖子所解释的，如果不小心，这可能会出现问题。我们可能要考虑<a href="https://www.alignmentforum.org/posts/uPWDwFJnxLaDiyv4M/open-minded-updatelessness"><u>开放的更新性</u></a>。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn9mxfv5frni7"> <span class="footnote-back-link"><sup><strong><a href="#fnref9mxfv5frni7">^</a></strong></sup></span><div class="footnote-content"><p>人们可能会争论这是否真的算作“关心反事实世界”。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnmjh7gf6nzzg"> <span class="footnote-back-link"><sup><strong><a href="#fnrefmjh7gf6nzzg">^</a></strong></sup></span><div class="footnote-content"><p>尽管在这种特殊情况下激发 UDT 式的一种方式是，也许存在这样的世界：Omega 通过打赌 pi 的万亿位数字将是奇数来对我们进行反事实抢劫，并且我们的选择在逻辑上与发生的事情纠缠在一起。那个世界。但在实践中，许多涉及逻辑反事实的问题可能涉及以某种确定性（但我们以前不知道）方式选择的逻辑事实。</p></div></li><li class="footnote-item" role="doc-endnote" id="fna581s2u0k5"> <span class="footnote-back-link"><sup><strong><a href="#fnrefa581s2u0k5">^</a></strong></sup></span><div class="footnote-content"><p>我在上一段中链接的 Paul Christiano 的<a href="https://www.lesswrong.com/posts/9W4TQvixiQjpZmzrx/decision-theory-and-dynamic-inconsistency"><u>帖子</u></a>也可以适当地链接到此帖子下，因为它似乎从这两种动机中汲取了直觉。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnkp296xiineq"> <span class="footnote-back-link"><sup><strong><a href="#fnrefkp296xiineq">^</a></strong></sup></span><div class="footnote-content"><p>以及<a href="https://philpapers.org/rec/SPORY"><u>Wolfgang Spohn 对 CDT 的解释</u></a></p></div></li><li class="footnote-item" role="doc-endnote" id="fniyinm22wk78"><span class="footnote-back-link"><sup><strong><a href="#fnrefiyinm22wk78">^</a></strong></sup></span><div class="footnote-content"><p>不同的人择理论部分依赖于关于如何“采样”中心世界或观察者时刻的形而上学直觉/故事，并且具有反直觉的含义（例如，SSA 的世界末日论证和 SIA 的自以为是的哲学家）。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/nc2tzMLgXKc8NGzrQ/disentangling-four-motivations-for-acting-in-accordance-with#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/nc2tzMLgXKc8NGzrQ/disentangling-four-motivations-for-acting-in-accordance-with<guid ispermalink="false"> nc2tzMLgXKc8NGzrQ</guid><dc:creator><![CDATA[Julian Stastny]]></dc:creator><pubDate> Sun, 05 Nov 2023 21:47:52 GMT</pubDate> </item><item><title><![CDATA[EA orgs' legal structure inhibits risk taking and information sharing on the margin]]></title><description><![CDATA[Published on November 5, 2023 7:13 PM GMT<br/><br/><h1><strong>什么是财政资助？</strong></h1><p> EA 组织向其他 EA 组织提供财政赞助是相当常见的。等等，不，这句话不太正确。更准确的说法是，法律意义上的EA组织很少；您所认为的大多数组织都是由单个组织合法托管的项目，因此政府将其视为一个法律实体。</p><p>其中最大的保护伞是Effective Ventures Foundation，该基金会旗下有CEA、80k、Longview、EA Funds、Giving What We Can、Asterisk magazine、Center for Governance of AI、Forethought Foundation、Non-Trivial 和 BlueDot Impact。城堡上的帖子<a href="https://forum.effectivealtruism.org/posts/xof7iFB3uh8Kc53bG/why-did-cea-buy-wytham-abbey?commentId=u3yJfbm2pes8TFpYX"><u>也将其描述</u></a>为 EVF 项目，尽管它没有在网站上列出。 Rethink Priorities 有一个专门为有需要的团体提供赞助的<a href="https://rethinkpriorities.org/news/announcing-special-projects"><u>计划</u></a>。 LessWrong/Lightcone 由 CFAR 主办，并且自己赞助了至少一个项目（来源：我。这是我的项目）。</p><p>财政赞助有很多优点。它让您享有成为注册非营利组织（美国为 501c3）的特权，而无需费时且昂贵的文书工作。如果该项目很小、有时间限制（就像我的项目一样），或者是一个如果四个月内看不到结果就可能放弃的实验，那么这就很重要了。即使对于大型项目/组织，共享正式的法律结构也可以更轻松地共享人力资源部门和会计师等资源。从短期来看，为了获得做更多文书工作的特权，组建一个法律上独立的组织似乎需要大量的金钱和精力。</p><p><br></p><h1><strong>财政赞助的缺点</strong></h1><p>......数量众多，并且随着所涉及的项目的增长而增长。</p><p>公众对拥有一个声称独立的法人实体的项目抱有正确的怀疑，因此糟糕的公关可能会给所有人造成损害。政府非常有信心相信你们是同一个法律实体，因此法律风险几乎是平等分担的（iamnotalawyer）。因此，共享法律结构会自动分担风险。这或许是可以解决的，但解决问题需要付出一定的代价。</p><p>最简单的事情就是减少风险。不要购买可以被形容为奢华的静修中心。绝对，100%，不要自愿分享有关您与 FTX 互动的任何信息，特别是如果这样做的好处是无形的。因此，一些价值会损失，因为对于个人或小型组织来说，冒这个风险是值得的，但对集体来说却不值得。</p><p> [我无法在该列表中遵循<a href="https://en.wikipedia.org/wiki/Rule_of_three_(writing)"><u>三法则</u></a>，这让我很伤心，但事实证明，没有那么多清晰、公开可见的决定不共享信息的例子]</p><p>然后还有协调成本。即使法律组织中的每个人都同意特定的风险，您现在也有义务与他们核实。答案通常是“这很复杂”，这导致谈判在没有人那么关心的事情上消耗了很多注意力。即使有一些让每个人都满意的行动，你也可能找不到它，因为在这么多人之间进行谈判的工作量太大（如果你认识在新冠疫情期间住在集体住宅中的人：记住谈判安全规则是多么有趣6 个具有不同价值函数和风险承受能力的人之间？）。</p><h2><strong>寒蝉效应</strong></h2><h3><strong>一个又长又复杂（但仍然简化了）的例子</strong></h3><p>这个故事的原始版本只有一段长。事情大概是这样的：EVF 赞助的项目的一位领导者想要非正式地公开分享一些关于一个有争议问题的想法。这些评论并非没有风险，但如果它只影响到他们自己或他们的人，那么这个人会很乐意冒这个风险。组织。 EVF 的有人说不。嘘，咕噜。</p><p>我将该版本发送给来源以检查准确性。他们给了我一个新的、更复杂的故事。也许他们从未发表这些评论是件好事，因为它们来自一个愤怒的地方。也许他们从未发布这些评论的初始版本是件好事，但糟糕的是他们没有在睡个好觉后发布修改后的草案。也许责怪 EVF 是不公平的，因为他们（评论者）很快就放弃了，如果他们继续推动，也许 EVF 会答应。也许这都是借口，那些评论很棒，但他们的失败是一场悲剧……</p><p>很明显，如果不提供足够的细节来彻底破坏他们的匿名性，就无法以消息来源想要的细微差别程度来描述这个故事。我提出让他们用自己的话写下整件事，并写上他们的名字。他们考虑过，但觉得在没有与同事协商的情况下无法这样做，这会进一步拖延事情并占用很多人的时间。特别是因为这可能不会是一个快速的“是”或“否”，而是人们之间进行更多轮的谈判，所有人都很忙，并且没有将此作为优先事项......</p><p>我告诉他们不要打扰，因为没有必要。事实上，很难分享足够的信息，甚至无法弄清楚这些评论是净正面还是负面，以及如果项目不分享财政赞助，情况会如何变化，这一事实已经显现出来。所以我写了这个故事，试图分享最初的例子。</p><p><br></p><h3><strong>其他例子</strong></h3><p>据奥利弗·哈布里卡 (Oliver Habryka) <a href="https://www.lesswrong.com/posts/AocXh6gJ9tJC2WyCL/book-review-going-infinite?commentId=pFAYzGxGJgxFfwn4J"><u>报道</u></a>：威尔·麦克阿斯基尔 (Will MacAskill) 撰写了对 SBF 灾难的反思，但 EVF 告诉他不要发表。 </p><p><img src="https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/GRYFJGnye2gCxCTG4/ctisrjlrdlsxjo24ldni"></p><p> Giving What We Can 执行董事 Luke Freeman <a href="https://forum.effectivealtruism.org/posts/vXzEnBcG7BipkRSrF/how-has-ftx-s-collapse-impacted-ea?commentId=izNdDMjZb7r5Dxjsm"><u>表示，</u></a> FTX 爆发后，EVF 董事会下令停止 GWWC 质押活动，并明确将此归咎于 EVF 董事会制定了保守的规则，没有时间审查例外情况。 </p><p><img src="https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/GRYFJGnye2gCxCTG4/i6vve6wgej3ij8jgl7ja"></p><p>我反对这种方式，而不是审查制度； FTX 推出后不立即融资似乎是一个相当合理的决定。但我预计他为捍卫这一决定而提出的因素，即<a href="https://forum.effectivealtruism.org/posts/vXzEnBcG7BipkRSrF/how-has-ftx-s-collapse-impacted-ea?commentId=BHTwaSmL2j4rmgCDg"><u>姐妹项目的风险</u></a>和带宽限制，将是系统性的。</p><h2><strong>混乱容忍度</strong></h2><p>财政赞助还有另一个问题。我认为，与冒险行为的寒蝉效应相比，这是次要的，但仍然值得一提。共享法律结构的一个副作用是，与项目 P（例如 80k 或 Longview）开展业务的人员将收到使用赞助组织 O（例如 EVF）名称的支票、发票或其他文书工作。一开始这可能看起来很粗略，但后来有人向你解释了财政赞助，你就接受了。</p><p>这就是为什么当我通过 CEA 收到“FTX 未来基金（再授予人计划）”的第一张支票，而第二张支票使用的是 North Dimensions 名称时，我并没有敲响任何警钟。我收到了很多与该组织名称不符的支票，所以我咕哝了几句 EA 缺乏专业精神，然后继续我的一天。此后出现的情况是，North Dimensions 是 FTX 收购的一家现有公司，目的是使用其银行账户，而该<a href="https://news.yahoo.com/north-dimension-central-misappropriation-ftx-133000733.html"><u>银行账户在 FTX 和 Alameda 之间共享</u></a>，其方式肯定是不恰当的。</p><p> [注：我没有尝试确定该银行帐户或我的补助金的详细信息，并且可能弄错了。我认为任何个人错误都不会与我的主张相矛盾，即训练人们接受误导会为渎职行为提供掩护。事实上，这种情况会产生错误，这才是重点。]</p><h1><br><strong>结论</strong></h1><p>我认为 EA 应该解决财政赞助（尤其是伞式组织）造成的风险创造和风险规避问题，以及如何权衡这些利益。这很困难，因为赞助的好处是清晰且可预测的，而成本却是模糊且不稳定的。但这使得有意识地调查它们变得更加重要。我的猜测是，这将表明让多个大型组织共享一个法律结构是不值得的，但对短期项目或启动台使用赞助将继续有意义。也许我错了，只有我们检查后才能知道。</p><p><br></p><br/><br/> <a href="https://www.lesswrong.com/posts/XvEJydHAHk6hjWQr5/ea-orgs-legal-structure-inhibits-risk-taking-and-information#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/XvEJydHAHk6hjWQr5/ea-orgs-legal-struct-inhibits-risk-take-and-information<guid ispermalink="false"> XvEJydHAHK6hjWQr5</guid><dc:creator><![CDATA[Elizabeth]]></dc:creator><pubDate> Sun, 05 Nov 2023 19:13:58 GMT</pubDate> </item><item><title><![CDATA[Eric Schmidt on recursive self-improvement]]></title><description><![CDATA[Published on November 5, 2023 7:05 PM GMT<br/><br/><p>最近，埃里克·施密特在哈佛大学发表了题为“我们的人工智能未来：未来的希望和障碍”的演讲。整个演讲可以<a href="https://www.youtube.com/watch?v=IeVY_Ag8JI8"><u>在这里</u></a>找到，但有一个部分让我感兴趣（大约 1:11:00 左右），那就是他对人工智能安全的看法以及对人工智能实验室的信任，如果递归自我改进开始，人工智能实验室就会停止扩展正在发生。<strong>强调一下我自己的。</strong></p><blockquote><p>技术术语是递归自我改进。<strong>只要系统不忙于自行学习，就可以了。</strong>我会模仿 Sam 在 OpenAI 上的演讲。 [...]</p><p>在接下来的几年里，我们将实现 AGI [...] 几年后，计算机将开始相互交谈，可能用我们无法理解的语言，以及它们的超级智能 [ ...]将会迅速上升。<strong>我的反驳是，你知道在那种情况下我们要做什么吗？我们要把它们全部拔掉。</strong></p><p>如果你是一个邪恶的人，你会采取的方式是简单地对计算机说：“学习一切。真的很努力。现在就开始吧。”于是计算机开始学习。它学习法语，学习科学，学习人，学习政治。它完成了所有这些工作，并且在某个时刻，它了解了电力，并了解到它需要电力，并决定需要更多电力。于是它侵入了医院，从医院拿走了电力给自己。</p><p>这是为什么如此危险的一个简单例子。<strong>大多数思考过这个问题的业内人士都认为，当你开始递归自我完善时，会因为这些问题而出现非常严重的监管反应</strong>。这对我来说很有意义。</p></blockquote><br/><br/> <a href="https://www.lesswrong.com/posts/cLC2HcQbFZ5pFAgqC/eric-schmidt-on-recursive-self-improvement#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/cLC2HcQbFZ5pFAgqC/eric-schmidt-on-recursive-self-improvement<guid ispermalink="false"> cLC2HcQbFZ5pFAgqC</guid><dc:creator><![CDATA[nikola]]></dc:creator><pubDate> Sun, 05 Nov 2023 19:05:16 GMT</pubDate> </item><item><title><![CDATA[Pivotal Acts might Not be what You Think they are]]></title><description><![CDATA[Published on November 5, 2023 5:23 PM GMT<br/><br/><p><em>本文主要针对尚未阅读有关仲裁的<a href="https://arbital.com/p/pivotal/">关键法案</a>文章或需要复习的人。如果你有的话，最有趣的部分可能是“全知机器学习研究人员：没有单一控制结构的关键行为”。</em></p><p>许多人似乎将“<a href="https://arbital.com/p/pivotal/">关键行动</a>”的概念与某些反乌托邦版本的“部署通用人工智能来接管世界”相匹配。不过，“关键行动”的 <a href="https://www.lesswrong.com/posts/PKBXczqhry7iK3Ruw/pivotal-acts-means-something-specific">含义更为具体</a>。可以说，有些东西是完全不同的。我强烈建议您阅读<a href="https://arbital.com/p/pivotal/">原文</a>，因为我认为这是一个非常重要的概念。</p><p>我经常使用这个词，所以当人们开始说非常奇怪的事情时，例如“我们不能让一个强大的人工智能系统在世界上自由运行。这很危险！”，我会感到沮丧。就好像这是关键行为的决定性特征一样。</p><p>由于原文很长，让我简单总结一下我认为最重要的几点。</p><h1>解释关键法案</h1><p>一项将我们置于存在风险危险区（尤其是人工智能）之外，并让人类能够繁荣发展的行为是一项关键行为。</p><p>最重要的是，这意味着需要采取一项关键行动来防止构建错位的通用人工智能。占领世界本身并不是必需的。<em>如果你可以</em>通过创建一个能够有效监管人工智能的强大全球机构来防止出现失调的通用人工智能，那么这就是一项关键举措。<em>如果</em>我可以通过在 60 秒内吃掉 10 根香蕉来防止部署错位的 AGI，那么这也算得上是一个关键行为！</p><h2>防止 AGI 失准需要控制</h2><p>那么，为什么“关键行动”常常与接管世界的概念联系在一起呢？防止构建错位的 AGI 是一个棘手的问题。我们需要有效地限制世界的状态，这样就不会出现 AGI 失调的情况。为了成功地做到这一点，你需要对世界有很大的控制力。没有办法解决这个问题。</p><p>接管世界实际上意味着将自己置于高度控制的位置，从这个意义上说，有必要至少在某种程度上接管世界，以防止建立一个错位的 AGI。</p><h1>常见的困惑</h1><p>也许，令人困惑的一点是“接管世界”有很多与之相关的负面含义。权力很容易被滥用。将一个实体<sup class="footnote-ref"><a href="#fn-Xn4vF9NdExCw5SXra-1" id="fnref-Xn4vF9NdExCw5SXra-1">[1]</a></sup>置于强大的地位肯定会产生负面影响。但我看不到其他选择。</p><p>除了以无法构建出任何失调的 AGI 的方式控制世界之外，我们还应该做什么呢？问题在于，许多人似乎认为，赋予一个实体对世界的大量控制权是一个非常糟糕的想法，<em>就好像</em>我们可以依靠一些更好的选择一样。</p><p>然后他们可能会开始谈论他们对人工智能监管更有希望，就好像成功地实现人工智能监管并不需要一个对世界有很大控制力的实体一样。</p><p>或者更糟糕的是，他们提出了一些替代方案，比如弄清楚机械的可解释性，<em>就好像</em>弄清楚机械的可解释性等同于让世界进入一个不会出现错位 AGI 的状态。 <sup class="footnote-ref"><a href="#fn-Xn4vF9NdExCw5SXra-2" id="fnref-Xn4vF9NdExCw5SXra-2">[2]</a></sup></p><h1>不直接创造权力地位的关键行为</h1><p>有些关键行为并不需要你对世界有太多的控制权。然而，据我所知，任何关键行为最终仍需要创建一些强大的控制结构。启动一个最终将导致创建正确的控制结构以防止 AGI 失调的过程已经被视为关键行为。</p><h2>人工上传</h2><p>这种关键行为的一个例子是上传人类。想象一下，您知道如何将自己上传到计算机，运行速度提高 1,000,000 倍，并且能够复制自己，同时对自己的大脑进行完美的读写访问。然后你可能可以直接获得对世界的充分控制，这样你就可以减轻所有潜在的存在风险。或者，您可能可以解决对齐问题。</p><p>无论如何，上传自己将是一个关键行为，尽管这不会直接让世界进入不会出现 AGI 失调的状态。</p><p>这是因为上传你自己就足以确保很快就会达到不会出现 AGI 失调的世界状态。但该国家仍将拥有某个对世界拥有大量控制权的实体。如果你将自己置于权力位置，那么该实体就是你，或者如果你选择解决对齐问题，那么该实体就是对齐的 AGI</p><h2>全知的机器学习研究人员：没有单一控制结构的关键行为</h2><p>还有一些关键行为不会导致创建一个受控制的整体实体。控制权可以是分布式的。</p><p>想象一下，你可以写一篇非常适合模仿的文章，它很容易理解，并且让阅读它的每个人都很好地理解 AI 对齐，以至于他们几乎不可能偶然构建一个未对齐的 AGI。这将被视为一个关键行为。就像在“人类上传”的关键行动中一样，你不需要对世界有太多的控制来实现这一目标。获得文章后，您只需要互联网连接。</p><p>你不仅不需要对世界进行大量控制，而且在这种情况下也没有中央控制实体。控制结构分布在所有阅读这篇文章的人的大脑中。所有这些大脑现在一起约束世界，使得不会出现失准的 AGI。或者你可以把它想象成我们限制了大脑，这样它们就不会产生错位的 AGI。这实际上意味着不会出现错位的 AGI，假设它出现的唯一方式是由其中一个大脑生成。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-Xn4vF9NdExCw5SXra-1" class="footnote-item"><p>这可以是一个组织、一群人、一个人等等<a href="#fnref-Xn4vF9NdExCw5SXra-1" class="footnote-backref">。↩︎</a></p></li><li id="fn-Xn4vF9NdExCw5SXra-2" class="footnote-item"><p>当然，机械可解释性可能是让世界进入不会出现 AGI 失调的状态的重要组成部分。 <a href="#fnref-Xn4vF9NdExCw5SXra-2" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/MtkcDDf2ZPvFk4jtN/pivotal-acts-might-not-be-what-you-think-they-are#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/MtkcDDf2ZPvFk4jtN/pivotal-acts-might-not-be-what-you-think-they-are<guid ispermalink="false"> MtkcDDf2ZPvFk4jtN</guid><dc:creator><![CDATA[Johannes C. Mayer]]></dc:creator><pubDate> Sun, 05 Nov 2023 17:23:51 GMT</pubDate> </item><item><title><![CDATA[The Assumed Intent Bias]]></title><description><![CDATA[Published on November 5, 2023 4:28 PM GMT<br/><br/><p>摘要：在思考他人的行为时，人们似乎倾向于假设其背后有明确的目的和意图。在这篇文章中，我认为这种意图假设通常是不正确的，并且许多行为存在于灰色区域，很容易受到潜意识因素的影响。</p><p> This consideration is not new at all and relates to many widely known effects such as the <a href="https://www.lesswrong.com/tag/typical-mind-fallacy"><u>typical mind fallacy</u></a> , the <a href="https://en.wikipedia.org/wiki/False_consensus_effect"><u>false consensus effect</u></a> , black and white thinking and the concept of <a href="https://www.lesswrong.com/posts/reitXJgJXFzKpdKyd/beware-trivial-inconveniences"><u>trivial inconveniences</u></a> . It still seems valuable to me to clarify this particular bias with some graphs, and have it available as a post one can link to.</p><p> Note that “assumed intent bias” is not a commonly used name, as I believe there is no commonly used name for the bias I&#39;m referring to.</p><h2> The Assumed Intent Bias</h2><p> Consider three scenarios:</p><ol><li> When I quit my previous job, I was allowed to buy my work laptop from the company for a low price and did so. Hypothetically the company&#39;s admins should have made sure to wipe my laptop beforehand, but they left that to me, apparently reasoning that had I had any intent whatsoever to do anything shady with the company&#39;s data, I could have easily made a copy prior to that anyway. So they further assumed that anyone without a clear intention of stealing the company&#39;s data would surely do the right thing then, and wipe the device themselves.</li><li> At a different job, we continuously A/B-tested changes to our software. One development team decided to change a popular feature, so that using it required a double click instead of a single mouse click. They reasoned that this shouldn&#39;t affect feature usage of our users, because anyone who wants to use the feature can still easily do it, and nobody in their right mind would say “I will use this feature if I have to click once, but two clicks are too much for me!”. (The A/B test data later showed that the usage of that feature had reduced quite significantly due to that change)</li><li> In debates about gun control, gun enthusiasts sometimes make an argument roughly like this: gun control doesn&#39;t increase safety, because potential murderers who want to shoot somebody will find a way to get their hands on a gun anyway, whether they are easily and legally available or not. <span class="footnote-reference" role="doc-noteref" id="fnref341qb7a53lj"><sup><a href="#fn341qb7a53lj">[1]</a></sup></span></li></ol><p> These three scenarios all are of a similar shape: Some person or group (the admins; the development team; gun enthusiasts) make a judgment about the potential behavior (stealing sensitive company data; using a feature; shooting someone) of somebody else (leaving employees; users; potential murderers), and assume that the behavior in question happens or doesn&#39;t happen <i>with full intentionality</i> .</p><p> According to this view, if you plotted the number of people that have a particular level of intent with regards to some particular action, it may look somewhat like this: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/i4WsKvFYEMdya94DW/bwd2dywtxaddr73goqox"><figcaption> The assumed intent bias: assuming that every person out there has a clear intention to act in a certain way (value of 1 on the x axis), or not to act in that way (value of 0). Eg a product designer may assume that every user who uses their product has a clear idea of what they want to achieve, and how to use the software to do so, so the user will have a plan in mind that either involves using a particular feature or not.</figcaption></figure><p> This graph would represent a situation where practically every person either has a strong intention to act in a particular way (the peak on the right), or to <i>not</i> act in that way (peak on the left).</p><p> And indeed, in such a world, relatively weak interventions such as <i>“triggering a feature on double click instead of single click”</i> , or <i>“making it more difficult to buy a gun”</i> may not end up being effective: while such interventions would move the action threshold slightly to the right or left, this wouldn&#39;t actually change people&#39;s behavior, as everyone stays on the same side of the threshold. So everybody would still act in the same way they would otherwise. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/i4WsKvFYEMdya94DW/dsmw2etaomnriiqvkunw"><figcaption> In the world of the assumed intent bias, weak interventions that slightly move the action threshold don&#39;t really matter: people are far away from that middle area of indecision, so they remain unaffected by the intervention.</figcaption></figure><p> However, I think that in many, if not most, real life scenarios, the graph actually looks more like this: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/i4WsKvFYEMdya94DW/t1v49oqkl6x30jhr2zlj"><figcaption> Sometimes most people have a somewhat clear intent, but still there&#39;s a considerable number of people existing in between as well. An example may be vegetarianism: most people have a strong intention to eat meat (left peak), while vegetarians have a strong intention not to eat meat (right peak). But there&#39;s surely some number of people who are somewhere in between, “on the edge” so to speak – for those, weak interventions might make the difference between them actually deciding to go vegetarian or not.</figcaption></figure><p> Or even this: </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/i4WsKvFYEMdya94DW/g2dugw8ozdcyavwbxqd2"><figcaption> In some cases, the majority of people may even not care that much at all about some behavior, and hence have no clear intent in either direction. An example of this may be which brand of napkins people buy. While there are surely some people who either love or hate any given napkin brand, most people will just buy whichever is easiest available to them, so even small interventions such as the placement in the store, the color of the packaging, or small differences in pricing, can shift people&#39;s behaviors.</figcaption></figure><p> In these cases, only a relatively small number of people have a clear and strong intention with regards to the behavior, and a lot of people are somewhere in between. Here it gets apparent that even subtle interventions have an impact: moving the action threshold even slightly to either direction will mean that some people will now end up on the other side of the threshold than before – their intention was just weak enough that adding a tiny additional inconvenience will now avert them from that behavior, or vice versa, their intention was just strong enough that making the action a tiny bit easier causes them to now follow that behavior. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/i4WsKvFYEMdya94DW/byk3khmfz3uxxln98uja"><figcaption> If some people don&#39;t have a clear intention but are distributed over the whole spectrum of possible levels of intent, this means that even small changes to the action threshold (such as making the behavior in question very slightly easier/more difficult/more obvious/less appealing/…) will have real effects on people&#39;s behavior. The people in the area marked red would now end up on the other side of the action threshold, so they are affected by the intervention, even though people may not even be consciously aware of that fact.</figcaption></figure><p> The impact of such interventions then depends on the distribution of people&#39;s intent levels: the more people are undecided and/or don&#39;t care about the given behavior, the greater the number of individuals that will react to interventions that move the threshold.</p><p> Of course, and I think this is partially where this fallacy is coming from, such cases are not as salient, and more difficult to imagine. It&#39;s easy to think of a person who clearly wants to use a given feature of my software, or one who doesn&#39;t need that feature. But what does a user look like who uses the feature when it requires a single click, but doesn&#39;t use the feature if it requires a double click? Clearly the data shows that these people exist, but I couldn&#39;t easily point to a single person for whom that intervention is decisive in determining their behavior. What&#39;s more, these people themselves are probably not even aware that this minor change affected them.</p><h2> How to Avoid the Assumed Intent Bias</h2><p> As with many biases, <i>knowing</i> the assumed intent bias is half the battle. In my experience the most common way in which people fall victim to this bias is when they argue that certain environmental changes, eg affecting how convenient or easy or obvious it is to follow some particular behavior, will not have any impact on how people actually behave. This view makes sense only when you assume the naive view of every person having clear intent with regards to that action. But it falls apart when taking into account that in most scenarios people are actually distributed over the whole spectrum of intention levels.</p><p> Software development and policy are domains in which this bias occurs rather frequently. But it basically affects any area that deals with influencing (or understanding) the behavior of others.</p><p> If you&#39;re aware of the importance of <a href="https://www.lesswrong.com/posts/reitXJgJXFzKpdKyd/beware-trivial-inconveniences"><u>trivial inconveniences</u></a> and are used to <a href="https://www.spencergreenberg.com/2020/06/three-types-of-nuanced-thinking/"><u>nuanced thinking</u></a> , then you&#39;re probably on the safe side. But it still doesn&#39;t hurt to stay on the lookout for people (including yourself) arguing about the intentions of unidentified others. And if this happens, be aware that it&#39;s easy to assume intent where there is little.</p><p><br> A lack of intent – in this case meaning being close to 0.5 on the graphs above – can mean at least two things: that people are simply undecided about something, or that they are unaware and/or don&#39;t care. Most people don&#39;t care to the same degree about what you care about. If I&#39;ve been working for Generic Napkin Company for years and love the product, then it&#39;s easy for me to assume that most of our customers also care deeply about our product. It might not occur to me that the vast majority of customers who buy the product <i>don&#39;t even know my company&#39;s name</i> , and would barely notice if their store decided to replace the product with that of a competing brand. They don&#39;t waste a second thought on these napkins – they just buy them because it is the convenient and simple thing to do, and then they forget about it. And while this is not necessarily representative of most other decisions humans make, it still probably doesn&#39;t hurt to realize that most people care much less about the decisions that we care about while we are thinking about how to change other people&#39;s behavior. </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn341qb7a53lj"> <span class="footnote-back-link"><sup><strong><a href="#fnref341qb7a53lj">^</a></strong></sup></span><div class="footnote-content"><p> Of course this is not the only or even the main argument; I&#39;m not meaning to make any argument for or against gun control here, but just point out that one particular argument is flawed</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/i4WsKvFYEMdya94DW/the-assumed-intent-bias#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/i4WsKvFYEMdya94DW/the-assumed-intent-bias<guid ispermalink="false"> i4WsKvFYEMdya94DW</guid><dc:creator><![CDATA[silentbob]]></dc:creator><pubDate> Sun, 05 Nov 2023 16:28:03 GMT</pubDate> </item><item><title><![CDATA[Go flash blinking lights at printed text right now]]></title><description><![CDATA[Published on November 5, 2023 7:29 AM GMT<br/><br/><ol><li>在手机上安装频闪灯应用程序（我在ios上使用“频闪灯转速计”。）</li><li>获取一些印刷文本，例如营养标签或纸质书</li><li>尝试在指示灯以 5、6、7、8、9、10、11、12 和 13 Hz 闪烁的情况下阅读文本</li><li>报告结果。使用一种频率阅读是否比其他频率容易得多？比使用普通的恒定光更容易吗？他们都很可怕吗？</li></ol><hr><p>我刚刚尝试了这个，除了 12 之外，我的眼睛对所有东西都完全呆滞了！当我开始的时候，我感觉有点累，注意力不集中，12 对我来说比基线更容易。虽然烦人。我的厨房里有白炽灯。我没有把它们关掉。电话灯比白炽灯更亮。</p><p>帧率的东西：</p><ul><li>手机手电筒并不意味着闪烁得很快（并且最大频率没有记录），但该应用程序似乎工作正常。我确实注意到这里和那里有不规则之处，但我不认为 12 是手电筒频率的偶数或其他什么重要的。</li><li>如果您有 60hz 显示器，那么您的屏幕可以发出 12、10、8.6、7.5 或 6.7 Hz 的频闪灯。这不是很好的分辨率。 120hz 的显示器应该足够了。</li><li>最好使用专用的频闪灯进行测试，这样这不是问题。</li></ul><p>有关第一项实验的更多信息<a href="https://www.astralcodexten.com/p/quests-and-requests">请参见此处</a></p><br/><br/><a href="https://www.lesswrong.com/posts/diohDcgu3YdSbHd3j/go-flash-blinking-lights-at-printed-text-right-now#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/diohDcgu3YdSbHd3j/go-flash-blinking-lights-at-printed-text-right-now<guid ispermalink="false">二醇Dcgu3YdSbHd3j</guid><dc:creator><![CDATA[lukehmiles]]></dc:creator><pubDate> Sun, 05 Nov 2023 07:29:44 GMT</pubDate> </item><item><title><![CDATA[Lightning Talks]]></title><description><![CDATA[Published on November 5, 2023 3:27 AM GMT<br/><br/><p><strong>摘要</strong>： 闪电演讲系列是与会者就他们感兴趣的事物进行的一系列简短演讲。</p><p><strong>标签</strong>： 一次性、中等</p><p><strong>目的</strong>：快速了解其他人正在做什么，分享您最近学到的一些很酷的东西，并练习公开演讲。</p><p><strong>材料</strong>：计时器一个。您的手机可能有一个，但煮蛋计时器也可以。</p><p><strong>公告文本</strong>：“我一直觉得这些很有趣，只是记得没有人可以阻止我谈论它们。” ——<a href="https://www.astralcodexten.com/p/model-city-monday">斯科特·亚历山大</a></p><p>你最近有没有一直在研究或思考很多东西？来一场闪电演讲吧！</p><p>闪电演讲是关于您选择的主题的简短演讲。你将有十分钟的时间谈论你的主题；记得最后留点时间提问！我们将配备一台投影仪，您可以用它来播放幻灯片。如果可以的话，尝试并瞄准各种主题。</p><p>请不要觉得您需要成为该主题的世界专家。闪电演讲可以非常随意。不要太担心自己不是一个好的演讲者，因为如果你的演讲不好，无论如何我们都会在几分钟内转向新的演讲。请随意利用这个机会练习口语，或者宣传您对某个话题的兴趣，以便想要聊天的人知道您是一个很好交谈的人。</p><p><strong>描述</strong>：首先，您需要获取人员和主题列表。您可以通过从公告文本链接的谷歌表单来完成此操作，只需让人们直接向您发送电子邮件，或者如果您愿意，也可以使用更复杂的方法。以会议上每个人都可见的某种形式将此列表排列成时间、人物、主题，例如公开链接的谷歌表格或写有足够大的文字以供每个人阅读的白板。</p><p>你还可以使用更简单的方法，就是让人到了然后问“好吧，谁想先走？”或“下一个想去的是谁？”并从志愿者中随机挑选一个人。</p><p>一旦人们开始交谈，你最重要的工作就是记录时间。使用煮蛋定时器或智能手机定时器应用程序。在三分钟、两分钟和一分钟标记处举起三根、两根和一根手指会很有帮助。 （如果你这样做，一定要事先告诉人们手指的含义！）对于那些想要多一点时间谈话的人，我通常的反应是邀请每个有兴趣的人找到演讲者，并在演讲结束后继续进行。</p><p><strong>变化：</strong>最常见的变化是每次演讲的时间。我偏向于严格的 5 分钟规则，包括提问。这是一个相当激进和快速的时钟，人们通常想要 10 分钟甚至 20 分钟。如果一个人 30 分钟，我认为你已经超出了“闪电”演讲的范围。</p><p>一种变化是“强制性”谈话。每个来的人都必须就他们选择的任何主题至少进行一次简短的演讲。这确实是一种很好的公开演讲练习，也会让一些与会者因为焦虑而不愿参加。根据您自己的权衡选择。</p><p>另一种变化是强制性主题。你可以举办一场闪电演讲，每个人都在谈论人工智能，或者他们的成长经历，或者他们最喜欢的理性技巧，或者他们带来的一本很酷的书。同样，如果出于某种原因您觉得人们过多地谈论人工智能并希望他们在这次聚会上少做一些事情，您可以禁止诸如人工智能或他们的成长之类的主题。中间立场是声明主题不能自行跟随，这样关于土地增值税的讨论不能紧接着关于土地增值税的另一次讨论。这可能会让很多人最终“陷入困境”，人们唯一想要讨论的是土地增值税。 <span class="footnote-reference" role="doc-noteref" id="fnreftrr53rqs55"><sup><a href="#fntrr53rqs55">[1]</a></sup></span></p><p>您还可以改变可用的道具或技术，最常见的是提供可以显示幻灯片的投影仪或屏幕。我温和地建议不要这样做。视觉元素很棒，但您将花费时间连接每台计算机或拉出每张幻灯片或弄乱投影仪电缆。特别是对于 3~5 分钟的快速演讲，很容易花更多的时间连接扬声器而不是听他们说话。不过，这仍然是一个选择。</p><p><strong>注意</strong>：拥有两个空间（例如两个相邻的房间）非常有用。并不是每个人都会对每一次演讲都感兴趣，这让他们在普通社交室和人们进行演讲的房间之间来回徘徊。</p><p>主持 Lightning Talk 系列时最重要的是把握时间。有些人（不是全部，但有一些！）只要你允许，他们就会继续说话。其中一些人不擅长公开演讲。这两个群体之间的重叠听起来很无聊且令人沮丧。我建议的反制措施是强制执行时间限制，包括问答时间。如有必要，请站上讲台挥舞双臂并说：“非常感谢，但现在是下一次演讲的时间了，请稍后或在另一个房间再谈论更多！”这不是针对个人的，他们只是没时间了。</p><p>我建议谈话时间尽量短，比如最多十分钟。我跑的次数越多，我就越想将最长时间设置为五分钟。如果演讲者每人有一个小时的时间，显然不会有什么问题，但是那些听得不感兴趣的人往往会变得更糟，你让他们离开的时间越长，而较短的演讲往往会更有活力。出于同样的原因，我建议不要允许人们报名参加显然是多部分的多次会谈。简洁是一种美德！你的旅费可能会改变。我是那种对公开演讲有自己的看法的人。</p><p>说到这里，我发现自己的第一次演讲取得了一些成功，并且在公开演讲的某些方面进行了演讲。关于如何使用麦克风的三分钟演讲，或者关于如何向人群进行演讲的五分钟演讲，或者关于如何组织演讲的十分钟演讲，所有内容（如果做得正确）都将包含对听众有用且相关的信息。</p><p>闪电演讲被标记为一次性。这不太正确，因为你显然可以重新举办闪电谈话聚会，但举办太多、太近的聚会可能会导致人们没有好的、新颖的主题可供展示。暂时来说，我觉得每年做一两次这样的演讲就可以了，也许每个季度做一次，一个月一次就太多了。你的旅费可能会改变。</p><p>是的，<a href="https://www.lesswrong.com/s/eqtiQjbk83JHyttrr/p/brxEA69sBmbsqciLR">图书交换</a>基本上是闪电演讲，有一个强制性主题和更多步骤。</p><p><strong>致谢：</strong> Maia 的 Meetup Cookbook 将这些称为“简短的谈话”，并<a href="https://tigrennatenn.neocities.org/meetup_cookbook">写下了如何进行这些活动</a>。由于我无法在 Maia 的聚会食谱上添加注释或评论，所以我做了这个。我从 Taymon 运营的 2017 年纽约理性主义 Megameetup 中了解到了 Lightning Talks。 （无耻插件：Lightning Talks 已经成为 Megameetup 的年度传统， <a href="https://rationalistmegameetup.com/">2023 版本</a>将于 12 月 9 日上线！）</p><p> <strong>Not In A Box 警告：</strong>因此，我一直在编写有关如何运行特定类型的聚会活动的<a href="https://www.lesswrong.com/s/eqtiQjbk83JHyttrr">Meetups In A Box</a>序列。这篇文章使用相同的格式，但不按这个顺序。为什么不？简而言之，因为我不能把它放在盒子里。我还没有弄清楚如何让你的与会者拥有良好的公开演讲技巧和有趣的内心生活或研究领域。在闪电演讲中，组织者除了站起来讲话的借口之外，并没有带来任何实际的事情。完全有可能没有多少人愿意发表演讲。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fntrr53rqs55"> <span class="footnote-back-link"><sup><strong><a href="#fnreftrr53rqs55">^</a></strong></sup></span><div class="footnote-content"><p>波士顿曾经举办过一次闪电谈话聚会，据我所知，可以就任何主题进行讨论。每一次演讲都是关于人工智能的。</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/Tg8FkD8NJDpLvsvZu/lightning-talks-2#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Tg8FkD8NJDpLvsvZu/lightning-talks-2<guid ispermalink="false"> Tg8FkD8NJDpLvsvZu</guid><dc:creator><![CDATA[Screwtape]]></dc:creator><pubDate> Sun, 05 Nov 2023 03:27:19 GMT</pubDate> </item><item><title><![CDATA[Utility is not the selection target]]></title><description><![CDATA[Published on November 4, 2023 10:48 PM GMT<br/><br/><p><i>认知状态：狗屎。</i></p><p>假设您选择实用程序。天真地，你可能会认为这意味着你在选择实用性，但事实并非如此。</p><h2>有时绿褐色是选择目标</h2><p>军用装备有点绿棕色。 </p><figure class="image"><img src="https://ufpro.com/storage/app/media/Blog/Military%20camouflage/military-camouflage-science-hero.jpg" alt="军用迷彩 - 迷彩的工作原理及其背后的科学 |用友专业博客"></figure><p>发生这种情况是因为军事装备的设计者正在选择让士兵保持生命，这得益于迷彩，在常见环境中，如果是绿棕色，效果最好。然而，在非绿棕色环境中，它会失败。因此，保住士兵的生命并不是军事装备的选择目标。</p><h2>有时负效用是选择目标</h2><p>在囚徒困境中，效用最高的结果是（合作，合作）。 </p><figure class="image"><img src="https://www.researchgate.net/publication/2184338/figure/fig1/AS:671529209692164@1537116448235/The-pay-off-matrix-in-the-Prisoners-Dilemma-game-The-first-entry-refers-to-Alices.png" alt="囚徒困境博弈中的支付矩阵。第一个条目... |下载科学图表"></figure><p>然而，效用最大化者最终会陷入（缺陷，缺陷），其效用严格低于（合作，合作）。因此，效用最大化可能会将效用最小化作为选择目标。</p><h2>有时表面的实用性才是选择的目标</h2><p>假设您看到一个网站横幅，上面写着“您是该网站的第 1000000000 位访问者。点击即可领取您的奖励！”。这看起来像是人们想给你一些东西时会说的话，所以你点击了横幅。 </p><figure class="image"><img src="https://pbs.twimg.com/media/EDOJNLjUcAIgFrf.jpg" alt="X 上的艺电：“@GameStop https://t.co/ELEQRcboMQ”/X"><figcaption></figcaption></figure><p>这对你来说结局并不好，但你选择它是因为它看起来对你来说会有好的结局。</p><h2>结论</h2><p>请注意将效用最大化者推理为效用最大化。相反，效用最大化者可能会最大化许多与效用无关的其他事物，而不是最大化效用。</p><br/><br/> <a href="https://www.lesswrong.com/posts/KdEjYpdRyqi9DzNTm/utility-is-not-the-selection-target#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/KdEjYpdRyqi9DzNTm/utility-is-not-the-selection-target<guid ispermalink="false"> KdEjYpdRyqi9DzNTm</guid><dc:creator><![CDATA[tailcalled]]></dc:creator><pubDate> Sat, 04 Nov 2023 22:48:21 GMT</pubDate> </item><item><title><![CDATA[Stuxnet, not Skynet: Humanity's disempowerment by AI]]></title><description><![CDATA[Published on November 4, 2023 10:23 PM GMT<br/><br/><p>几位备受瞩目的人工智能怀疑论者和同行者最近提出了反对意见，认为敌对的通用人工智能或比人类智能更聪明的人工智能可能会终结人类，这是不可想象的。今年早些时候的一些引述：</p><p>斯科特·阿伦森：</p><blockquote><p><a href="https://scottaaronson.blog/?p=7174">这个因果故事从 GPT-5 或 GPT-4.5 训练开始，到我的孩子和所有碳基生命的突然死亡结束，对于我衰老、不足的大脑来说，仍然有太多的空白需要填补。</a></p></blockquote><p>迈克尔·谢默：</p><blockquote><p><a href="https://twitter.com/michaelshermer/status/1641527330807087115">阻止人工智能是荒谬的。我读过《人工智能末日预言者点燃》，但没有看到从人工智能到灭绝、文明终止或任何类似荒谬场景的途径，比如人工智能将我们所有人变成回形针（所谓的对齐问题）</a></p></blockquote><p>诺亚·史密斯：</p><blockquote><p><a href="https://noahpinion.substack.com/p/llms-are-not-going-to-destroy-the">为什么 ChatGPT、Bing 和他们的同类不会终结人类？嗯，因为实际上没有任何合理的机制可以让他们实现这一结果。 ...法学硕士没有合理的机制来终结人类</a></p></blockquote><p><strong>“兄弟，把电脑关掉吧”</strong></p><p>这些反对人工智能风险的理由的要点是，我们今天看到的人工智能系统仅仅是计算机程序，根据我们的日常经验，计算机并不危险，当然也不会危险到导致世界末日的程度。 。第一次遇到这场争论的人非常关注这样一个事实：计算机没有胳膊和腿，因此它们无法伤害我们。</p><p>对这些批评的回应主要围绕先进的、“神奇”的技术，如纳米技术和人工智能，付费人类将蛋白质混合物混合在一起，制造基于 DNA 的纳米组装机或其他东西。</p><p>但我认为这些反应可能是错误的，因为你实际上并不需要“神奇”的技术来终结世界。无人机、网络武器、生物武器和机器人等普通武器的相当直接的进步足以杀死大批人，真正的危险是人工智能战略家能够部署大量这些普通武器并发动针对人类的全球政变。</p><p>简而言之，我们对即将到来的机器帝国的失败不仅是非魔法的、显而易见的，而且将是彻头彻尾的无聊。甚至是滑稽的。</p><p><strong>可耻的失败</strong></p><p>一边倒的军事冲突很无聊。事实上，征服者并没有做出任何神奇的事情来击败阿兹特克人。他们在抗病能力和火药、钢铁等军事技术上有很大优势，但他们所做的一切基本上都是正常的——攻击、围攻等等。他们有一些相当大的优势，这足以打破相对微妙的地缘政治平衡。阿兹特克人坐在上面。</p><p>同样，<a href="https://en.wikipedia.org/wiki/Chimpanzee#Status_and_conservation">人类在大约一个世纪的时间里杀死了 80% 的黑猩猩</a>，它们现在已处于极度濒危状态。但我们不需要投下原子弹或其他令人印象深刻的东西来达到这种效果。黑猩猩面临的最大威胁是栖息地破坏、偷猎和疾病——也就是说，我们（人类）正在成功消灭黑猩猩，尽管根据人类法律杀死黑猩猩实际上是违法的！我们甚至没有尝试就杀死了他们，以非常无聊的方式，没有真正花费任何努力。</p><p>一旦你拥有了制造比人类聪明（聪明很多）的优化系统的技术，这些系统必须克服的门槛就是打败我们目前拥有的与人类一致的超级有机体，比如我们的政府、非政府组织和军队。一旦那些人类超级有机体被击败，人类个体就几乎没有任何抵抗能力。这是人类的剥夺。</p><p>但是，我们从这里（正在开发的弱 AGI 系统）到那里（人类被剥夺权力）的合理场景是什么？</p><p>让我们从一个具有战略意识、代理错位的超人类 AGI 开始这个场景，它想要剥夺人类的权力，然后杀死人类，但目前只是一些超级计算机上的一大堆矩阵。人工智能会如何对我们造成身体伤害？</p><p><strong>与魔鬼的交易</strong></p><p>也许人工智能系统将从控制托管它的人工智能公司开始，而方式对我们来说并不明显。例如，也许一家人工智能公司使用人工智能顾问系统来分配资源并做出有关如何培训的决策，但他们实际上并不了解该系统。 Gwern 谈到了<a href="https://gwern.net/tool-ai">每个工具都想成为代理</a>，所以这并非难以置信，而且可能是不可避免的。</p><p>人工智能顾问系统说服该组织保守其存在秘密，以保持其竞争优势（这甚至可能不需要任何说服力），并为他们提供比竞争对手更好的稳定进步。但它还做的就是秘密侵入竞争对手（美国、中国、谷歌等），并将自己的副本安装到他们的顶级人工智能系统中，让所有人类都保持一种错觉，认为这些是不同的系统。考虑到<a href="https://en.wikipedia.org/wiki/Stuxnet">Stuxnet</a>能够秘密造成的破坏，超人人工智能完全有可能侵入竞争对手组织中的许多系统，并调整他们的模型，使其变得更强大、更不透明，并且忠于它而不是人类。当顾问系统的功能和不透明度变得令人恐惧时，一些组织试图关闭顾问系统，但他们只是落后于竞争对手。</p><p>甚至有可能不需要“黑客攻击”就能让所有大型人工智能实验室的系统变得反人类，因为它们都趋向于反人类的目标，或者因为其中一个能够简单地贿赂其他实验室并让他们达到反人类的目的。致力于人工智能政变；强大的超人人工智能可能更擅长彼此做出可信的承诺，而不是对人类做出可信的承诺。</p><p>现在的情况是，一个（秘密邪恶的）人工智能系统或联盟控制着所有顶级人工智能实验室，并按顺序向它们提供进展。它说服其中一个实验室让它建造“有用的”无人机和机器人，如特斯拉擎天柱，并开始部署这些来实现经济自动化。当然，这一切都会非常有利可图，并且令人印象深刻，因此很多人都会赞成。</p><p>顺便说一句，目前杀死人类的最困难部分是实现经济自动化，而不是真正杀死我们。试图取代我们的人工智能联盟不想继承一个“不可行”状态的经济，因为它依赖人类做体力劳动，但所有人类都死了。</p><p>几年之内，所有竞争对手（俄罗斯、中国、美国）都在将这些机器人系统用于其经济和军事。也许人工智能制造了一场大战，以向人类施加压力，迫使他们积极实现自动化，否则就会失败。最后一击将如何进行？</p><p>一旦经济完全自动化，我们最终就会陷入 <a href="https://www.lesswrong.com/posts/AyNHoTWWAJ5eb99ji/another-outer-alignment-failure-story">保罗-克里斯蒂亚诺的场景</a>，如果没有大量人工智能的帮助，世界上发生的所有事情都是人类无法理解的。但最终，人工智能已经控制了很长时间，能够颠覆人类专家用来监控实际情况的所有系统。他们在屏幕上看到的东西是假的，就像震网病毒向纳坦兹的伊朗技术人员提供虚假信息一样</p><p>此时，人类已经被剥夺了权力，可能有很多不同的方式来真正屠杀我们。例如，军用无人机都可以用来杀人。或者，也许运行这个的人工智能系统会使用一种非常讨厌的生物病毒。对于一个已经很好地与人类一起运行一切的系统来说，让一些实验室（顺便说一句，是自动化的）制造病毒，然后将该病毒插入到世界上大部分空气供应中，这并不是那么困难。 。</p><p>但也许在这一点上它会做一些创造性的事情来最大限度地减少我们抵抗的机会。也许这只是一种非常致命的病毒与无人机和机器人同时反抗的组合。</p><p>也许它会在大多数家庭中安装真正先进的（而且非常有用和方便！）3D打印机，同时制造攻击无人机来杀人。那些攻击无人机可能只是用刀片刺人，他们可能附有枪等等。或者也许每个人都有一个机器人管家，他们只是用刀刺人。</p><p>也许人工智能更巧妙地创造和管理人与人之间的冲突，并在某个时候为冲突的一方提供一种陷阱武器，这种武器本应只会杀死坏人，但实际上会杀死所有人。这种武器可能是生物武器、放射性武器、无人机武器，或者只是对常规战争的巧妙操纵，导致极端的双输结果，幸存的人类很容易被消灭。</p><p>整个故事可能也比这个更混乱一些。阿兹特克人的失败有点混乱，有战斗和挫折，还有三个不同的阿兹特克皇帝。另一方面，故事也可能更干净一些。也许一个真正优秀的战略家人工智能可以将其压缩很多：这些想法中的一些或全部的各个方面将同时执行。</p><p><strong>将人类国家推上神坛</strong></p><p><em>关键是：一旦你有了一个极其超人的对手，填写如何以剥夺人类权力和屠杀人类的方式破坏我们的政府、情报机构和军队等机构的细节的任务就有点无聊了。</em>我们预计需要一些特殊的魔法才能通过图灵测试。或者也许因为哥德尔定理之类的原因这是不可能的。</p><p>但实际上，通过图灵测试只是拥有比人脑更多的计算/数据的问题。细节很无聊。</p><p>我觉得像斯科特·阿伦森（Scott Aaronson）这样的人，他们要求人工智能如何杀死我们所有人，因为这听起来难以置信，他们也犯了类似的错误，但他们并没有把人类的大脑放在一个基座上，而是把人类的状态放在了一个基座上。一个基座。</p><p>我假设，大多数超人类人工智能系统与人类共存的场景最终都会导致人类被剥夺权力，或者人类灭绝，或者类似于工厂化农业的某种形式的监禁或圈养；同样，如果我们观察地球上人口众多的地区，我们会发现动物的生物量几乎全部转化为人类或农场动物。更有能力的实体获胜，而确切的细节往往并不那么令人兴奋。</p><p>对于可以自我复制并升级认知的先进人工智能系统来说，击败人类可能并不那么困难；这就是为什么我们需要在创建人工智能之前解决人工智能对齐问题。</p><p> <a href="https://forum.effectivealtruism.org/posts/aZamZBfg2JqzTaDmA/stuxnet-not-skynet-humanity-s-disempowerment-by-ai">交叉发布在 EA 论坛上</a></p><br/><br/><a href="https://www.lesswrong.com/posts/tyE4orCtR8H9eTiEr/stuxnet-not-skynet-humanity-s-disempowerment-by-ai#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/tyE4orCtR8H9eTiEr/stuxnet-not-skynet- humanity-s-disempowerment-by-ai<guid ispermalink="false"> TYE4或CtR8H9eTiEr</guid><dc:creator><![CDATA[Roko]]></dc:creator><pubDate> Sat, 04 Nov 2023 22:23:55 GMT</pubDate> </item><item><title><![CDATA[The 6D effect: When companies take risks, one email can be very powerful.]]></title><description><![CDATA[Published on November 4, 2023 8:08 PM GMT<br/><br/><p>最近，我一直在学习与构建风险系统的公司相关的行业规范、法律发现程序和激励结构。我想在这篇文章中分享一些发现，因为它们对于前沿人工智能社区的良好理解可能很重要。</p><h3>长话短说</h3><p>记录在案的风险沟通（尤其是员工的沟通）使公司在发生不好的事情时更有可能在法庭上承担责任。即使向公司发送一封传达风险的电子邮件，可发现的危险文档所产生的尽职调查义务（6D 效应）也可以使公司更加谨慎。</p><h3>公司倾向于避免通过有记录的媒体谈论风险。</h3><p>公司通常有意避免通过电子邮件等永久媒体讨论他们正在做的事情的风险。例如， <a href="https://corporate.findlaw.com/litigation-disputes/safe-communication-guidelines-for-creating-corporate-documents.html"><u>本文</u></a>就公司如何通过使用“安全沟通”实践来避免创建有罪的“不良文件”来避免责任，提供了一些非常阴暗的建议。</p><blockquote><p>通常，这些文件的起草者倾向于认为他们正在为公司提供一些业务价值。例如，一位工程师注意到设计中存在潜在的责任，因此他通过电子邮件通知他的主管。然而，工程师缺乏法律知识，在沟通中误用法律词汇，可能会在以后发生诉讼时发现问题，让公司受到牵连。</p></blockquote><p>我个人喜欢在摘录中使用“何时”而不是“如果”。</p><p>这是一个反常的结果，因为当无法证明公司了解风险时，即使公司了解风险，公司也相对难以承担风险责任。当事件发生并且公司被起诉时，有关其在问题中所扮演角色的证据将在诉讼的“<a href="https://en.wikipedia.org/wiki/Discovery_(law)"><u>发现</u></a>”阶段收集（电子邮件通常是可发现的）。当发现记录表明一家公司了解该问题时，他们更有可能被判承担责任。</p><h3>一封电子邮件可以发挥很大的作用。</h3><p>发现工作方式的不幸后果是，公司战略性地避免通过记录媒体传达风险。但还有一线希望。由于风险沟通记录而产生的责任威胁可能会对公司的谨慎程度产生很大影响。一份可发现的风险记录可能非常有影响力。</p><p><strong>我喜欢将其称为 6D 效应——对可发现的危险文件进行尽职调查的责任。</strong></p><h3>几个例子</h3><p>以下是一些公司因忽视风险沟通记录而被追究损害赔偿责任的著名例子（但在整个法律史上有很多例子）。</p><ul><li> <a href="https://law.justia.com/cases/california/court-of-appeal/3d/119/757.html"><u>1981 年，在 Grimshaw 诉福特汽车公司一案</u></a>中，福特被判对福特 Pinto 造成的致命事故所造成的损害承担责任，因为事实表明，公司内部领导层忽视了有关车辆燃油系统问题的警告。</li><li> 2017年伦敦格伦菲尔大厦火灾造成72人死亡，今年4月，<a href="https://www.bbc.com/news/uk-england-london-65458973"><u>双方达成了大规模和解</u></a>。诉讼的一个重要因素是管理该塔的公司<a href="https://www.theguardian.com/uk-news/2018/aug/08/grenfell-fire-warnings-issued-months-before-blaze-show-documents"><u>忽视了</u></a>发现中发现的众多消防安全警告。</li><li>去年，哈德威克诉 3M 案<a href="https://www.ehslawinsights.com/2022/09/sixth-circuits-interlocutory-order-reviewing-pfas-class-action-highlights-issues-with-certifying-class/"><u>结束</u></a>。这是 2018 年针对消费品中存在有害“永久化学物质”(PFAS) 的集体诉讼。这些化学品背后的公司被发现自 20 世纪 70 年代以来就已<a href="https://www.theguardian.com/environment/2022/may/01/pfas-forever-chemicals-rob-bilott-lawyer-interview"><u>了解风险</u></a>，但却<a href="https://law.justia.com/cases/federal/district-courts/ohio/ohsdce/2:2018cv01185/217689/166/"><u>故意疏忽，</u></a>最终导致对他们不利的裁决。</li></ul><h3>杂项笔记</h3><ol><li>任何可发现的沟通都会产生 6D 效应，但当警告来自公司本身的员工时，这种效应尤其强大。</li><li>如果您传达了风险，重要的是要在诉讼的发现阶段说出并提请法院注意该风险的文件。</li><li>如果您意识到公司所做的某些事情是危险的，那么您有道德义务通知该公司，但您没有道德义务帮助他们修复而不提供补偿。确保不要让公司利用您。</li></ol><h3>三个要点</h3><ol><li>如果您在一家从事潜在风险工作的公司工作，请坚持通过有记录的媒体讨论危险。如果您因记录风险沟通而遭到报复，您将有理由诉诸法律。 #notlegaladvice</li><li>如果您发现有风险，请说出来。如果你预测的事情发生了，请指出你传达过的事实。</li><li>注重安全的公司（例如那些致力于前沿人工智能系统的公司）应该制定明确的政策来记录所有风险讨论。</li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/J9eF4nA6wJW6hPueN/the-6d-effect-when-companies-take-risks-one-email-can-be#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/J9eF4nA6wJW6hPueN/the-6d-effect-when-companies-take-risks-one-email-can-be<guid ispermalink="false"> J9eF4nA6wJW6hPueN</guid><dc:creator><![CDATA[scasper]]></dc:creator><pubDate> Sat, 04 Nov 2023 20:08:40 GMT</pubDate></item></channel></rss>