<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 12 月 5 日，星期二 22:11:38 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[How do you feel about LessWrong these days? [Open feedback thread]]]></title><description><![CDATA[Published on December 5, 2023 8:54 PM GMT<br/><br/><p>你好！我是来自 LessWrong / Lightcone 团队的 jacoobjacob。</p><p><strong>这是一个元线程，您可以分享您一直在想的有关 LessWrong 的任何想法、感受、反馈或其他内容。</strong></p><p>您可能分享的内容示例：</p><ul><li> “我真的很喜欢同意/不同意投票！”</li><li> “所有这些对话内容是怎么回事？这令人困惑......</li><li> “嗯……最近网站上的氛围似乎发生了某种变化……特别是[<i>插入 10 段</i>]”</li></ul><p> ...或者其他什么！</p><p>这篇文章的目的是让您能够在一个您知道团队成员会倾听的地方分享您想到的任何事情。</p><p> （我们是一个小团队，必须优先考虑我们的工作，所以我当然不承诺采取这里提到的所有内容。但我至少会倾听所有这些！）</p><p>我已经有一段时间没有看到这样的公共话题了。也许有很多关于这个网站的沸腾的感觉从未表达出来？或者，除了我从阅读正常评论、帖子、指标和对讲评论中发现的内容之外，你们没有什么可以分享的了？好吧，这是找出答案的一种方法！我真的很想询问并了解人们对该网站的感受。</p><p>那么，您最近对 LessWrong 感觉如何？欢迎在下面留下您的答案。</p><br/><br/> <a href="https://www.lesswrong.com/posts/j2W3zs7KTZXt2Wzah/how-do-you-feel-about-lesswrong-these-days-open-feedback#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/j2W3zs7KTZXt2Wzah/how-do-you-feel-about-lesswrong-these-days-open-feedback<guid ispermalink="false"> j2W3zs7KTZXt2Wzah</guid><dc:creator><![CDATA[jacobjacob]]></dc:creator><pubDate> Tue, 05 Dec 2023 20:54:45 GMT</pubDate> </item><item><title><![CDATA[Critique-a-Thon of AI Alignment Plans]]></title><description><![CDATA[Published on December 5, 2023 8:50 PM GMT<br/><br/><p> AI-Plans.com 将于 12 月 16 日至 18 日举办批评马拉松，参与者将提出并讨论对人工智能调整计划的批评。</p><p>评委包括：</p><ul><li>内特·苏亚雷斯，MIRI 主席</li><li>Ramana Kumar，DeepMind 研究员</li><li>Peter S Park 博士，麻省理工学院 Tegmark 实验室博士后</li><li>Charbel-Raphaël Segerie，EffiSciences 人工智能部门负责人</li></ul><h2>好处：</h2><p>批评马拉松提供了一个绝佳的机会，通过深入研究调整计划可能成功或失败的原因，获得对人工智能安全的重要见解。<br>我们将突出调整计划的关键要素，这些要素将反馈给研究人员并可用于改进他们的计划。<br>这也是获得专家评委反馈的绝佳机会。</p><h2> Critique-a-Thon 活动为期 3 天，分为 2 个阶段：</h2><h3><strong>第一阶段 - 添加评论</strong>（截至 12 月 16 日）</h3><p>我们将在 ai-plans.com 上以两个类别的形式添加对调整计划的批评：优势和弱点。</p><p><br> “优势”应表明计划如何作为协调解决方案发挥作用。 “漏洞”应该起到相反的作用。<br>奖品将颁发给那些提出最多批评的人 - 投票给负分的批评将不被计算在内。<br><br>您可以随时开始这个阶段 - 您今天就可以开始添加评论！<br>截止日期为格林尼治标准时间 12 月 16 日午夜。<br><br><strong>奖品</strong><br>第一名：100 美元<br>第二名：60美元<br>第三名：40美元</p><h2><br>第二阶段 - 讨论和总结（12 月 17 日至 18 日）</h2><p>我们两人一组。每对将选择一个已提出批评的调整计划。一个人会提出理由，另一个人会提出反对理由，优势/弱点是真实和准确的。<br>然后，第二天，我们将交换立场，并以所提议的优势/弱点的书面形式结束。<br>请参阅之前获奖评论的示例：</p><p> <a href="https://docs.google.com/document/d/16Ww6nNECsDnjMOGaz5fqg1PxCVRPpoOy80UooEa7CZM/edit#heading=h.vdtj4e22pjdv"><u>八月评论马拉松</u></a></p><p><br><a href="https://docs.google.com/document/d/1O586rkRZd9BbpI8yqA2K6aG9IIq6E1A9I2H9C5nEYKQ/edit#heading=h.vdtj4e22pjdv"><u>九月评论马拉松</u></a><br><br>这些讨论将有助于完善批评并加强论点，并且交换可以减少由于缺乏某个主题的先验知识而造成的任何不利。<br>如果你的对手对这个话题了解得更多，并提出了你没有想到的观点，你可以在第二天自己使用它们，看看有哪些应对措施 - 并确定它们是否是你的文章中需要提及的内容，这就是将被判断的内容。<br>这些讨论将<a href="https://discord.gg/aGVtu5JyjJ"><u>在 Discord 上</u></a>进行。</p><p>在这里加入👉 <a href="https://discord.gg/aGVtu5JyjJ"><u>https://discord.gg/aGVtu5JyjJ</u></a></p><h3><br><strong>奖品</strong></h3><p>第一名：400 美元<br>第二名：250 美元<br>第三名：150 美元<br><br></p><p>在此注册加入👉 <a href="https://ai-plans.com/login"><u>https://ai-plans.com/login</u></a></p><p><br><br></p><br/><br/> <a href="https://www.lesswrong.com/events/kgyrsAkbBjNxPbicc/critique-a-thon-of-ai-alignment-plans#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/events/kgyrsAkbBjNxPbicc/critique-a-thon-of-ai-alignment-plans<guid ispermalink="false"> kgyrsAkbBjNxPbicc</guid><dc:creator><![CDATA[Iknownothing]]></dc:creator><pubDate> Tue, 05 Dec 2023 20:50:08 GMT</pubDate> </item><item><title><![CDATA[Arguments for/against scheming that focus on the path SGD takes (Section 3 of "Scheming AIs")]]></title><description><![CDATA[Published on December 5, 2023 6:48 PM GMT<br/><br/><p>这是我的报告《<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？》</a>的第三部分。 ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p>本节的音频版本<a href="https://www.buzzsprout.com/2034731/13984918">请点击这里</a>，或者在您的播客应用程序上搜索“Joe Carlsmith Audio”。</p><h1>支持/反对阴谋论的争论集中在 SGD 所采取的路径上</h1><p>在本节中，我将讨论支持/反对计划的论点，这些论点更直接地关注 SGD 在选择训练的最终输出时所采取的路径。</p><p>重要的是，这些论点可能并不相关。特别是：如果 SGD 在模型类别之间以某种“直接比较”的方式主动支持或不支持阴谋者，那么 SGD 将“找到一种方法”来选择它在这个意义上所支持的模型类型（例如，因为足够高的模型类型）。维度空间使这样的“方式”可用）， <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-1" id="fnref-ZwSi8PjDgjvifEocL-1">[1]</a></sup>那么足够的训练只会引导你到 SGD 最喜欢的任何模型，而所讨论的“路径”并不重要。</p><p>在关于不同模型的最终属性之间的比较的部分中，我将讨论我们可能期望 SGD 出现这种偏袒的一些原因。特别是：阴谋者“更简单”，因为他们可以有更简单的目标，但他们“更慢”，因为他们需要参与各种形式的额外工具推理 - 例如，在决定策划时，检查现在是否是一个好时机缺陷，可能参与和掩盖“早期破坏”等方面的努力（尽管请注意，此处需要执行额外的工具推理，可能会表现为由策划者的权重实现的算法的额外复杂性，因此表现为“简单性”）成本”，而不是“运行该算法更长时间的需要”）。 <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-2" id="fnref-ZwSi8PjDgjvifEocL-2">[2]</a></sup>我将在下面对此进行更多讨论。</p><p>不过，在这里，我想指出，如果 SGD 足够关心简单性和速度等属性，那么 SGD 通常会首先构建一个具有长期追求权力目标的模型，但即使该模型尝试了一个方案 -就像策略一样（在这种情况下，由于预知其失败，它不一定会这样做），它会被无情地磨成一个情节奖励寻求者，因为情节奖励寻求者的速度优势。或者，SGD 通常会首先构建一个按情节奖励的寻求者，但由于 SGD 渴望更简单的目标，该模型将被无情地磨成一个阴谋者。</p><p>在本节中，我将假设这种事情不会发生。也就是说，SGD 构建模型的顺序会对训练的最终结果产生持久的影响。事实上，我的一般感觉是，对阴谋者的讨论经常隐含地假设这样的事情——例如，人们通常认为阴谋者会在训练中很早就出现，然后在那之后将自己锁定。</p><h2>独立于训练游戏的代理目标故事</h2><p>回想一下我上面介绍的区别：</p><ul><li><p>训练与比赛<em>无关的</em>赛外目标，其产生与其在训练-比赛中的角色无关，但随后会激励训练-比赛，而不是训练-比赛。</p></li><li><p>与训练游戏<em>相关的</em>赛外目标，SGD 主动<em>创建</em>这些目标是<em>为了</em>激励训练游戏。</p></li></ul><p>在我看来，关于专注于与训练、比赛<em>无关的</em>目标的策划故事似乎更传统。也就是说，这个想法是：</p><ol><li><p>由于[插入原因]，模型将制定一个（适当雄心勃勃的）与训练中良好表现相关的超集目标（以<em>不</em>通过训练游戏的方式）。</p><ol><li><p>这可能发生在态势感知到来之前或之后。</p><ol><li><p>如果之前，那么在一段时间内它可能会被训练出来，并且还没有激发训练-游戏。</p></li><li><p>如果之后，它可能会立即开始激励训练-游戏。</p></li></ol></li></ol></li><li><p>然后，结合态势感知，这个（适当雄心勃勃的）超集目标将开始激发训练游戏。</p></li></ol><p>将此称为“独立于训练游戏的代理目标故事”。</p><p>我相当认真地对待这个论点。如果某种适当雄心勃勃的超越情节的代理目标没有被训练（要么因为它在态势感知之前没有得到训练，要么因为它在态势感知之后突然出现），并且如果有一些关于为什么这个目标会产生影响的故事策划一个好的工具性策略适用（例如，经典的守门故事，或者可能是其他一些非经典故事），那么策划似乎确实可能只是一件发生的事情。</p><p>我认为最直接的反对意见是：为什么模型要制定这些（适当雄心勃勃的）超越情节的目标？我之前在诸如“目标默认情况下不会有时间折扣”和“模型时间不会像日历时间”之类的论点中讨论过这一点，我不会在这里添加太多内容，除了说假设模型将实现一些适当雄心勃勃的、超越情节的、独立于训练游戏的代理目标，追求这些目标与高奖励相关，在我看来，这似乎是经典故事中较弱的部分之一。</p><p>特别是：对阴谋的讨​​论有时集中在“好奇心”和“权力”等代理目标上，这些目标在很多剧集中都显得有用。但这并不意味着在训练中会激励对<em>情节之外的</em>好奇心和力量的追求。更重要的是，特别是如果你知道/可以控制情境意识何时出现，那么在模型因追求好奇心/力量而受到积极惩罚的训练片段中似乎并不那么困难。非训练游戏模型将直接进行修改。事实上，总的来说，我希望我们能做很多事情来积极阻止模特采取寻求权力的行为，并鼓励其他形式的“谦虚”。</p><p>后一点与我之前提到的乐观原因有关：即，独立于训练游戏的代理目标故事允许我们在态势感知之前进行任何我们想要的对抗性训练，以尝试确保模型的目标保持不变情节内且适度适度。</p><p>也就是说，试图在态势感知之前通过对抗性训练来避免这种阴谋，面临着一些严重的障碍：</p><ul><li><p>首先：最重要的是，所讨论的对抗性训练可能不够多样化/彻底。特别是（特别是缺乏可解释性工具）：可能很难想到所有可能的适当雄心勃勃的剧集外代理目标，这些目标与奖励有足够好的相关性，并且您需要使用此类培训来推动。 <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-3" id="fnref-ZwSi8PjDgjvifEocL-3">[3]</a></sup></p></li><li><p>第二：当态势感知开始发挥作用时，你可能不知道，或者无法很好地控制。</p></li><li><p>第三：一旦足够智能的模型经过文本预测的预训练，它可能已经非常接近态势感知，因为它拥有大量相关的常识（即使不一定是自定位知识）。因此，在那之后可能没有太多时间进行没有态势感知的对抗训练。</p></li><li><p>最后，<em>在</em>态势感知启动后，模型有可能制定适当的、雄心勃勃的、超越情节的、策划激励的目标。 <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-4" id="fnref-ZwSi8PjDgjvifEocL-4">[4]</a></sup></p><ul><li><p>例如，也许当模型开始按照我上面描述的方式“反思”时，它已经相当聪明并且具有战略意识——例如，“弄清楚它真正想要什么”，自我解决，学习打破以前尝试的新事物对齐它，等等。 （这要求模型不会因为获得态势感知而立即开始寻求奖励，但这似乎是可能的，特别是如果我们假设训练留下了显着的“余裕”。）</p></li><li><p>当然，仍然存在一个问题，即为什么该模型会将自己打造成具有适当雄心勃勃的目标，特别是超越情节的目标。但在这里，根据我上面对“如果你训练它拥有长期目标会怎样”的讨论，也许我们可以诉诸这样一个事实：我们试图将其指向一项雄心勃勃的长期任务，但这种指向有些不准确。 / 模糊，这样当它弄清楚它想要如何概括时，这种概括就落在了足够长期和雄心勃勃的事情上，从而激发了阴谋。</p></li><li><p>事实上，正如我上面指出的，我认为有一个案例表明，当前的调整工作已经<em>在</em>试图将我们的系统指向长期的、超越情节的目标——例如，避免帮助制造炸弹的“无害”形式即使炸弹数十年不会爆炸。</p></li></ul></li></ul><p>因此，总的来说，我认为，以谋划作为追求（适当雄心勃勃的）超越情节目标的良好工具性策略为条件，独立于训练游戏的代理目标故事在我看来是一个真正令人担忧的问题。</p><h2> “最近的最大奖励目标”故事</h2><p>我们还可以讲述一个不同的故事，重点关注<em>依赖于</em>训练和比赛的赛外目标。我将其称为“最近的最大奖励目标”故事。 <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-5" id="fnref-ZwSi8PjDgjvifEocL-5">[5]</a></sup>故事是这样的：</p><ol><li><p>当模型变得具有情境意识时，它可能不会追求最大奖励目标（即，在训练数据上追求的目标大致会导致与模型的其他功能一致的最大奖励）。相反，它将追求一些低于最大奖励的代理目标。</p></li><li><p>但那时，世界模型将包含模型训练游戏所需的所有信息。 （然而，因为我们在这里关注的是关于阴谋的“训练游戏<em>依赖</em>”故事，我们假设在获得态势感知时，模型的目标还不是激发阴谋——而是进行一些进一步的修改为此需要。）</p></li><li><p>此时，SGD 修改模型以获得最大奖励的最简单方法就是使其成为一个计划者。</p></li><li><p>所以：SGD 将使模型成为一个策划者。</p></li></ol><p>现在，一种选择是尝试使 (1) 为假。事实上，如上所述，在态势感知之前尝试以良好的方式塑造模型的目标似乎是降低阴谋可能性的关键潜在途径。但请注意，在这种情况下，所面临的挑战比<em>独立于</em>训练游戏的代理目标更困难。也就是说，对于与训练游戏无关的代理目标，只需在态势感知之前避免给模型提供类似策划者的目标，因此它可以容忍所讨论的目标可能尚未达到最大奖励的<em>其他</em>方式。相比之下，在“最近的最大奖励目标”论点的背景下，人们需要要么实际创建一个最大奖励、非类似阴谋的目标，要么<em>足够接近</em>（3）不适用的目标。也就是说，你不能仅仅阻止“自然阴谋”的出现，而必须阻止它的出现。你需要确保当 SGD 稍后“搜索”最近的最大奖励目标时，它不会首先找到阴谋者。</p><p>现在，我们假设我们还没有完全掌握这一点，并且（1）是正确的（尽管：我们所达到的掌握<em>程度</em>对我将在下面讨论的“接近度竞赛”很重要）。 (2) 源自态势感知的定义（或者至少是一个宽松的定义，例如“参与阴谋并认识到阴谋的好处所必需的对世界的理解”），所以我们也承认这一点。</p><p>但是（3）呢？我认为，在这里，论证还有更多工作要做。为什么认为将模型打造成阴谋者将是使其获得最大奖励的最简单方法？例如，为什么不把它变成一个训练圣人，或者一个剧集奖励寻求者，或者一个追求某种最大奖励代理目标的错误概括的非训练游戏玩家？根据假设，该模型具有代表<em>任何</em>这些目标的概念工具。 （请注意，在这方面，它与大多数进化历史中的人类不同，人类<em>没有</em>概念工具来表示“包容性遗传适应性”等目标。）因此，我们需要一个故事来说明为什么该论点会优先考虑类似阴谋家的人特别是目标。</p><p>为了清楚起见：当我谈论 SGD 可以进行某种修改的“轻松”程度，或者所得到的模型的“接近度”时，这是“SGD‘偏好’的那种修改”的代表。本身就是“SGD 实际上将进行的那种修改”的替代品。在机械层面上，这大致意味着：奖励景观中最陡梯度的方向。我经常会想象一种更模糊的感觉，即 SGD 可以做的“工作”预算有限，因此希望在修改模型目标方面做尽可能少的“工作”，以便它可以专注于改进模型认知的其他方面。</p><p>那么，根据对“轻松”的理解，我们应该期望哪个模型类对于 SGD 来说是“最容易”创建的，即从一个新的情境感知模型中创建一个低于最大奖励代理目标的模型。自己不能激发阴谋吗？</p><p>作为一个有助于激发直觉的松散类比：想象一下将人类技术冻结在当前水平，并让进化选择在人类身上运行更长时间。 <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-6" id="fnref-ZwSi8PjDgjvifEocL-6">[6]</a></sup>从长远来看，你预计哪种人类（或人类后裔生物）将占据主导地位？特别是：您期望：</p><p> (a) 人类本质上重视“<a href="https://en.wikipedia.org/wiki/Inclusive_fitness">包容性遗传适应性</a>”或“我的基因被进化选择”（这是对“指定目标”和“奖励过程”的某种组合的松散类比），</p><p> （b）人类重视与包容性遗传适应性密切相关的其他事物（例如，“拥有尽可能多的孩子”），但他们没有明确地优化包容性遗传适应性，甚至是工具性的（这是对错误的松散类比）广义的非训练游戏玩家），或</p><p>(c) 具有长期目标的人类，他们正在优化包容性遗传适应性，特别是作为一种在长期内为自己的价值观获得权力的方法（这对阴谋家来说是一个宽松的类比）。</p><p>在这里，“最近的最大奖励目标”故事的类比会问这样的问题：对现有人类价值观的最小修改是什么（或者更好：特别是对进化最容易的修改）是什么，使我们陷入困境之一如上所述，同时也与所面临的进化选择压力的大小兼容？ <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-7" id="fnref-ZwSi8PjDgjvifEocL-7">[7]</a></sup></p><p>当然，这个类比带来了大量令人困惑的变量（例如，与进化选择构建学习价值的大脑的基因组而不是价值本身有关的事实，文化积累和模因选择的作用）人口动态、缺乏对未来逃跑/接管机会的明确模拟，等等）。为了使这一类比与机器学习更加相似，最好想象进化直接选择整个人类大脑，配备完整的概念工具来代表所有这些目标，而不是选择构建大脑的基因组。更好<em>地</em>想象一个从一开始就选择大脑的进化版本，这样我们开始理解进化时的人类价值观可能会完全不同。不管怎样，我对最佳预测没有任何明确的信念。但我认为这是“最近的最大奖励目标”论点的一个令人回味的直觉泵。</p><h3> SGD 渐进主义对类似阴谋家的修改的障碍</h3><p>不过，让我们关注实际的论证，而不是类比。我们应该期望哪个模型类在相关意义上是“最接近的”？</p><p>上面我讨论了阴谋者可能被快速排除的一种方式：即，如果 SGD 无法通过修改模型时遵循的梯度来“注意到”类似阴谋者修改的好处。也就是说，正如我之前讨论的，在寻找最大奖励目标时，SGD 不仅仅“跳”到最近的目标。相反，它需要在梯度计算的基础上逐步实现这样的目标，梯度计算表明模型权重在相关方向上的微小变化会增加奖励。在许多情况下，尚不清楚类似阴谋者的修改是否可以像这样工作。</p><p>因此，例如， <a href="https://www.lesswrong.com/posts/A9NxPTwbw6r6Awuwt/how-likely-is-deceptive-alignment#Deceptive_alignment_in_the_high_path_dependence_world">Hubinger (2022)</a>考虑了一个例子，其中 SGD 通过将模型从关心剧集中的金币修改为始终关心金币来引发阴谋。不过，在所讨论的示例中，SGD 并不是逐渐延长模型金币关注的时间范围，每次延长都会导致奖励的提高。相反，SGD 只是做了“一个简单的改变”——即完全放弃目标的时间限制——从而创建了一个阴谋者。但问题是：奖励空间的梯度是否反映了这样做的好处？在我看来，发生这种情况的最自然的方式是，是否有能力从一种模型平滑地过渡到另一种模型，这样每次修改都会逐渐获得更多的策划好处。但目前尚不清楚这是否会发生。正如我之前讨论的，如果我们假设 SGD 还需要构建大量新机器来执行策划所需的工具推理（而不是仅仅重定向预先存在的“目标实现引擎”），那么任务变得更具挑战性。</p><h3>哪个模型是“最接近的”？</h3><p>然而，根据我之前的讨论，我也不觉得我能够排除这种类型的增量转换可能发生的可能性（例如，也许足够高的维空间允许 SGD“找到一种方法”） ”），而且我还没有尝试进行深入分析。因此，虽然我认为这种类型的渐进主义对专注于依赖训练游戏的阴谋者目标的故事提出了相对强烈的反对，但我认为也值得评估这些故事的其他方面。也就是说，假设SGD<em>能够</em>注意到将“最近的最大奖励目标”故事中的模型制作成schemer的好处，这样的修改是否是获得高奖励的最简单方法？</p><h4>目标空间中类似阴谋家的目标的共性</h4><p>对此的一个论点可以追溯到我所认为的支持期待阴谋的核心直觉之一：即可能的阴谋者式目标的绝对<em>数量</em>。粗略地说，这个想法是，因为<em>如此多的目标</em>可以激发策划，所以很可能会有一些类似策划者的目标非常<em>接近</em>模型的当前目标（其中“附近”，回想起来，是根据工作量 SGD 来定义的）必须做才能引起相关类型的修改）。也就是说，阴谋者在目标空间中非常常见——因此 SGD 相应地很容易从任何给定的起点“找到”类似阴谋者的目标。 <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-8" id="fnref-ZwSi8PjDgjvifEocL-8">[8]</a></sup></p><p>上面描述的“剧集中的金币”→“所有时间的金币”转变就是这种思想的一个例证。也就是说，如果你假设最充分的长期目标会激发阴谋， <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-9" id="fnref-ZwSi8PjDgjvifEocL-9">[9]</a></sup>那么<em>不</em>成为阴谋家的最显着的方法就是有一个足够的短期目标。但是（假设我们已经抛开上面讨论的“增量主义”问题），任何给定的时间有限的目标似乎都非常“接近”时间无限的版本。 <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-10" id="fnref-ZwSi8PjDgjvifEocL-10">[10]</a></sup></p><p>但时间范围并不是这里可能的“邻近性”的唯一来源。例如，如果模型碰巧有一些尚未激发阴谋的<em>长期</em>目标（例如，因为目标不够“雄心勃勃”），我们可以改变其他相关变量。因此，如果模型开始关心以不受时间限制的方式正确解决一些数学问题，但它可以在密谋接管世界以获得更多计算来检查和重新计算的情节中很好地解决问题检查它的答案似乎不值得，我们可能会想象 SGD，例如，改变模型对得到错误答案的风险的容忍度，或者改变它的目标，以便它想要解决<em>更多的</em>数学问题，或者你有什么。总的要点是：在尝试创建计划程序时，SGD 有大量选项可供选择，因此很容易在模型起点附近找到一个选项。</p><p>因此，在进化和人类的背景下，这种思想的类比是这样的：即使是相当短期的、适度的人类价值观，也可以相对容易地将它们转变为长期的、雄心勃勃的价值观。例如，人类长期主义者似乎会采取“对我周围环境中满足各种条件的人表现出模糊的友善和帮助”之类的价值观，并将其转化为更加雄心勃勃的目标——这些目标似乎有动力明确优化以获取选择-通过进化，如果这是未来电力的关键瓶颈。事实上，在我看来，在实践中，如果你进行进化选择足够长的时间，在长期范围内优化的意识形态群体最终将占据主导地位（许多最接近优化生殖适应性的群体） ，例如，看起来他们有这种味道）。 <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-11" id="fnref-ZwSi8PjDgjvifEocL-11">[11]</a></sup></p><p>一旦我们搁置了上面关于渐进主义的反对意见，我认为目标空间中类似阴谋家的目标的共性是一个相当有力的理由，担心新的情境意识的最近的最大奖励修改，仍然不是-最大奖励目标追求模型将走向心计。更重要的是，请注意，一旦我们想象 SGD 在目标空间中主动<em>搜索</em>会激发阴谋的目标，我们关于阴谋起源的故事就可以更容忍阴谋者般的目标，必须有其他更具体的目标属性，例如资源匮乏性。也就是说，在专注于训练与游戏<em>无关的</em>目标的环境中，有可能质疑 SGD 落在类似阴谋者的目标上的概率（甚至以它落在更普遍的超越情节目标为条件），凭借不同的超越情节的目标意味着对未来力量、风险等的不同偏好。但在像这样的<em>依赖于</em>训练游戏的环境中，SGD 正在积极<em>寻找</em>这样的目标（并且相关目标在目标空间中仍然很常见——例如，您可以“在所有空间和时间上最大化<em>x</em>的实例”） “ 对于<em>x</em>的许多值）。因此，如果 SGD 找到了它想要的东西，也就不足为奇了。</p><p>然而，我认为这种论点并不是决定性的，原因有二。</p><h4>非策划目标的接近程度</h4><p>第一个原因是，即使我们坚持纯粹专注于修改模型的目标，并采用“干净的目标导向”框架（我将在下面使这样的焦点复杂化），我认为还有一个抵消的“接近性”考虑这至少支持一些非计划目标——即，在其他条件相同的情况下，模型的初始训练（在态势感知之前）似乎更有可能主动将模型指向这些非计划目标的方向。</p><p>这对于指定的目标来说是最清楚的，根据定义，这是通过培训来奖励的。这意味着，即使模型在具有态势感知能力时最终没有<em>完全</em>达到指定的目标，它也可能最终得到广泛附近的目标。</p><ul><li><p>因此，举例来说，如果模型正在接受训练以最大化剧集中的金币，并且最终学习了一个目标，例如“最大化剧集中的金币”（这个目标<em>不太</em>正确，因为有些训练环境包括圆形金币（非硬币），看来 SGD 最简单的修改就是将模型变成<em>金币</em>on-the-episode-getter（即训练圣人）。 ）。或者至少，就“接近度”而言，“情节中的金币”似乎与“有史以来的圆形金币”<em>具有竞争力</em>。</p></li><li><p>对于更多 RLHF 风格的指定目标，我们可能会提出类似的观点。也就是说，如果您正在训练一个模型以一种广泛有帮助、诚实且无害的方式遵循剧集中的说明​​（为简单起见，您的 RLHF 流程仅在这方面提供准确的反馈），那么即使它当它变得具有情境意识时，它已经学会了一种有点不平衡的概念，例如诚实，改进其诚实概念，直到它更好地适合人类概念，似乎具有竞争性，回复：接近，具有更多类似阴谋家的动机修改，例如“偏离-始终保持诚实，以激励计划逃脱人类控制并夺取权力。”</p></li><li><p>请注意，在人类和进化的背景下，人类确实已经重视与包容性遗传适应性密切相关的各种事物——例如，生孩子、更广泛地拥有繁荣而强大的家庭血统等等。如果我们想象进化选择整个人类大脑配备了代表“包容性遗传适应性”的概念装置，人类最初进化到重视与包容性遗传适应性非常接近的东西似乎更容易想象。 <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-12" id="fnref-ZwSi8PjDgjvifEocL-12">[12]</a></sup></p></li></ul><p>请注意，我们也可以在这里对错误概括的非训练游戏玩家提出类似的观点，只要他们追求最大奖励目标（回想一下，根据我的定义，错误概括的目标可以是最大奖励，前提是特别是<em>训练数据</em>永远不会惩罚它们——例如，它们只会在模型从未见过的反事实场景中受到奖励过程的惩罚。</p><ul><li><p>因此，例如，想象一个训练过程，它永远不会区分“在剧集中获得金币”和“在剧集中获得一般金币”之类的目标，因为训练数据中的所有金币都是硬币。假设在态势感知之前，我们的模型学习了一个目标，比如“在剧集中获得金币，但有时也会跟随你对剧集的好奇心，即使这意味着牺牲金币”——这个目标可以实现（但不是最大程度地实现）好吧）在训练中，因为好奇心并不是一种非常有害的行为，有时甚至是一种有益的行为。在这里，似乎只是删除模型的好奇心并只专注于获得剧集中的黄金物品（最大奖励目标，即使不是指定目标）是一个相当“附近”的修改 - 并且是一个看似合理的修改在“接近”方面具有竞争力，例如修改模型，使其始终追求其黄金和好奇心的组合。</p></li><li><p>在人类和进化的背景下，如果我们想象，从进化选择的角度来看，“拥有尽可能多的孩子”的内在价值会表现得很好（即使这并不<em>完全</em>是进化选择的目的），但事实并非如此。似乎很难想象人类会朝这个方向前进。</p></li></ul><p>我们能否对寻求剧集奖励的人提出类似的观点？这有点不太清楚，因为在态势感知之前，尚不清楚模型是否有足够的奖励过程概念，以便他们有动机附加到其组件之一“附近”的某些东西。也就是说，在我看来，在某些情况下这种情况可能会发生。因此，例如，即使缺乏态势感知，通过 RLHF 训练的模型最终也会受到“人类认可”附近概念的激励，这对我来说似乎是合理的。这些概念似乎至少在某种程度上接近奖励过程的各个方面，例如人类评估者和/或奖励模型的判断，这样一旦模型了解了奖励过程，修改其动机以专注于这些组件就不会太困难。对于 SGD 来说，这是一个巨大的飞跃。</p><p>总的来说，我认为非驾驶员的目标往往具有某种“近乎度”，默认情况下对他们有利。这并不令人惊讶。尤其是：非安全目标必须与奖励过程有一定的直接联系（例如，他们要么直接被该过程奖励，要么是因为它们专注于奖励过程的某些组成部分），因为与Schemer目标不同，非安全目标不能依靠收敛的子目标，例如目标 - 综合性或长期寻求力量来确保追求目标会带来奖励。因此，似乎很自然地期望通过奖励过程训练该模型，在尚无法实现策划的情况下，将导致动机集中在非审判者目标附近的事情上。</p><p>尽管如此，在给定的情况下，这种考虑是否足以使非驾驶员的目标更<em>接近</em>该模型的目标是否足以使非驾驶员的目标更接近该目标，这是一个悬而未决的问题。请注意，重要的是，相关的竞争是与附近的类似架构的<em>整个</em>目标（例如，例如，我上面讨论过的可能的类似架构的修改的特定示例） - 鉴于鉴于各种各样的可能策划者 - 类似目标，可能是一个严重的劣势。因此，作为类比：如果在鲍勃（Bob）的房屋十英里内有十个墨西哥餐厅和一百家中餐馆，那么即使任何给定的墨西哥餐厅都与任何给定的中餐馆“合理竞争”，RE：接近：信息）<em>最近的</em>餐厅可能仍然是中国人。 <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-13" id="fnref-ZwSi8PjDgjvifEocL-13">[13]</a></sup>并且根据模型领域中类似图默的目标的共同点，我们可能希望像中国餐馆一样，在这里。 <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-14" id="fnref-ZwSi8PjDgjvifEocL-14">[14]</a></sup></p><h4>凌乱的目标指导与接近度的相关性</h4><p>但是，我也认为，一旦我们考虑到“凌乱的目标指导性”，非驾驶员将获得另一个不同的近乎近距离提升。特别是：如果我们想象所讨论的模型不是一个可分开的目标插槽 +目标实现引擎，而是一个不同的启发式方法，关注模式，冲动等的纠结的kludge，那么我们需要分析比较的“接近度”不仅是当前模型的当前<em>目标</em>与最近类似模式的类似于示意图的目标，而且是该模型的<em>整个kludge</em>与最近的模型和非吊杆样模型的接近度。我认为，在这里，非驾驶员模型可能具有更大的优势。</p><p>特别是：在某种程度上，阳性前的意识训练倾向于创造出凌乱的目标指导性的形式，指向非驾驶员目标<em>附近</em>的某些东西，尤其是<em>剧集内部的</em>非示威者目标 - 然后暗示该模型的启发式方法，关注模式，冲动等等也将倾向于指向这个广泛的方向，并尤其集中在情节中。对我而言，这使得将模型重新定义为长期寻求权力的模型似乎更具实质性和困难的修改，尤其是在相关情节很短的情况下。也就是说，在我看来，对我来说，它感觉就像是“对长期进行长期进行可干净可分离的纪录目标”比“对SGD进行长期”要容易得多。它（a）专注于纪录的某些内容，以及（b）使得由于工具的原因，这是超出节目的重点后链重新获得奖励”  - 尤其是（b）需要构建新的认知机制来实施工具推理有问题。而”“重定向纠结的kludge集中在集中事物上，而不是相同广阔的附近的较高奖励的情节内部事物”（例如，金币，而不是金币，而不是金色的东西；诚实）在我看来，直觉上更容易。</p><h3>总体上以“最近的最高奖励目标”论点</h3><p>总结我对期望计划的“最近的最高奖励目标”论点的看法：</p><ul><li><p>如果SGD由于没有产生这些好处而将模型变成模型的好处，则该参数将失败。</p></li><li><p>但是，我觉得我们无法依靠SGD无法注意到这些好处。如果<em>可以的</em>话，那么我认为目标空间中类似策划者的目标的共同点使得像策划者的目标是“最接近模型”的目标，这非常令人担忧。</p></li><li><p>也就是说，因为在没有情境意识的情况下，它是由奖励过程所塑造的，所以该模型的目标也将在某些最高奖励非安全目标的“附近”中可能已经“在附近”。某些非示波器模型的“接近度”。在某种程度上，危及的目标指导性非常“凌乱”，创建这样的非驾驶员可能需要更少的修改模型的启发式方法，关注模式，器乐推理等。</p></li></ul><p>这些考虑因素使我对方案的额外担忧。</p><h2>诸如简单性和速度与路径SGD的可能相关性</h2><p>如果我们假设任何给定的最高奖励目标在训练中产生足够好的表现，那么“最近的最高奖励目标参数”之类的论点最自然地进行，以至于SGD并不特别讨厌模型最终<em>的</em>最高奖励目标。但是，正如我上面指出的，正如我将在有关不同模型类的最终属性的部分中进行详细讨论，有些故事以简单性（如Simplicity）的最终属性为由，其中SGD主动更喜欢这些模型类而不是其他类别和速度。</p><p>更重要的是，这种偏好不仅与忽略SGD在模型空间中所走的路径的预测有关。相反，它们可能会在各个阶段<em>影响</em>该路径（即使最终结果在某种程度上仍然是“依赖路径”）。例如，例如，如果SGD朝着更简单的目标偏见，则这种偏见可能会影响模型在训练游戏中倾向于在训练游戏中倾向于在情况下或之后形成情境意识，以及依赖培训游戏的目标故事，它可能是SGD专门向类似于Schemer的目标移动的其他要点，这可能是从尚未获得的奖励的起点。 <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-15" id="fnref-ZwSi8PjDgjvifEocL-15">[15]</a></sup>同样，如果SGD凭借其需要额外的推理而偏离了计划的偏见，那么这种偏见可能是额外的观点，有利于期望SGD从这样的起点朝着非驾驶员迈进。</p><p>正如我在第4节中讨论的那样，关于“最终属性”，我通常认为，策划的速度成本比简单的好处更重要，因此其他事物相等，我认为这些考虑因素违反了策划。但是，我尚不清楚这两个方向的成本/收益尤其重要。</p><p>也就是说，至少有一些案例可以使这些成本/收益在培训的早期<em>更</em>重要，因为模型的早期可能会<em>较弱</em>，因此减少了简单性和速度可用的资源（例如，参数和计算将对模型的认知能力产生更大的总体影响。也就是说：也许，在培训的早期，认知资源更稀缺，因此更必要。因此，例如，当一般可用的工具推理预算较小时，也许要求模型形成长期，类似于策划的计划（奖励更大的奖励）；也许，当要求其使用更多的参数更复杂的目标是更少的参数变成有用的认知结构时。 <sup class="footnote-ref"><a href="#fn-ZwSi8PjDgjvifEocL-16" id="fnref-ZwSi8PjDgjvifEocL-16">[16]</a></sup>因此，在某种程度上，人们认为，相对于其他考虑因素，这些成本可能是“在噪音中”的（我很喜欢这一观点，并且我在下面讨论了），一种可能是对于训练的早期部分而言，与模型的最终属性相比，这对训练的早期部分少。</p><h2>对专注于路径SGD的论点的总体评估</h2><p>不过，尽管如此，尽管非驾驶员可能会带来速度优势，但我发现“独立于训练游戏的代理目标”论点和“最接近的最高奖励目标参数”的结合令人担忧。尤其：</p><ul><li><p>对我来说似乎是合理的，尽管我们在平凡的对抗训练方面做出了努力，尤其是在我们有目的地塑造模型以实现长期和相当雄心勃勃的目标的政权中，某种适当的雄心勃勃，不正当，超对象，超级情节的目标可能会流行自然而然地在训练之前 - 在情境意识之前，或之后 - 然后导致策划发生。</p></li><li><p>即使这种情况<em>并非</em>自然发生，我也很担心，到达到情境意识时，SGD给模型一个最大奖励目标的最简单方法是将其制成架构，因为类似Schemer目标在目标空间中足够普遍，因此他们经常会出现“附近”模型当时产生的不太明智的奖励目标。 SGD的“增量主义”可能会消除这种担忧，并且/或我们应该期望非吊销模型默认情况下“近”（因为他们的目标尤其接近，或者是因为在“凌乱的目标定向性”中，设置，它们需要更简单地修改模型当前的启发式术语纠结的魔力，或者因为它们的“速度”优势会使SGD更喜欢它们）。但是我不自信。</p></li></ul><p>但是，这两个参数都集中在SGD通过模型空间的<em>路径</em>上。将重点放在所讨论模型的最终属性上的参数呢？让我们现在转向那些。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-ZwSi8PjDgjvifEocL-1" class="footnote-item"><p>例如，这要求模型无法“<a href="https://www.lesswrong.com/posts/uXH4r6MmKPedk8rMA/gradient-hacking">渐变黑客攻击</a>”，而我上面讨论过的内省目标保护方法。 <a href="#fnref-ZwSi8PjDgjvifEocL-1" class="footnote-backref">↩︎</a></p></li><li id="fn-ZwSi8PjDgjvifEocL-2" class="footnote-item"><p>我还讨论了他们缺乏针对指定目标/奖励的“内在热情”可能会有所作为。 <a href="#fnref-ZwSi8PjDgjvifEocL-2" class="footnote-backref">↩︎</a></p></li><li id="fn-ZwSi8PjDgjvifEocL-3" class="footnote-item"><p>感谢Rohin Shah在这里进行讨论。 <a href="#fnref-ZwSi8PjDgjvifEocL-3" class="footnote-backref">↩︎</a></p></li><li id="fn-ZwSi8PjDgjvifEocL-4" class="footnote-item"><p>的确，如果我们假设预训练本身<em>会导致</em>情境意识，但不能超越剧集，动机动机的目标，那么这将是默认故事，用于在预训练之前训练中如何出现Schemers的故事。感谢Evan Hubinger的标记。 <a href="#fnref-ZwSi8PjDgjvifEocL-4" class="footnote-backref">↩︎</a></p></li><li id="fn-ZwSi8PjDgjvifEocL-5" class="footnote-item"><p>我认为这个故事与Hubinger所说的“世界模型悬垂”的故事相关但与众不同，该故事（我理解）大致运行如下：</p><ol><li><p>到模型在情境中意识到的时候，它的目标可能不会使追求它们与获得高奖励完全相关。</p></li><li><p>但是，在那时，它的世界模型将包含训练游戏所需的所有信息。</p></li><li><p>因此，在此之后，SGD将能够通过修改模型的超出序列目标来激发训练游戏的超出序列目标，从而获得大量的轰动：奖励：奖励。</p></li><li><p>相比之下，通过修改模型更像是训练圣地，它可能能够减少爆炸，因为在这个方向上的边际努力仍然可能会使模型的目标与奖励不完美地相关（或至少，由于不得不等待未来的训练情节的纠正，因此需要更长的时间才能达到完美。</p></li><li><p>因此，SGD将创建超出的情节目标，以激发训练游戏（然后这些目标将结晶）。</p></li></ol><p> Hubinger的框架的一个问题是，从我感兴趣的意义上讲，他的本体论似乎是忽略了奖励的寻求者 - 而SGD将模型修改为“奖励”的零件搜索者至少会这样做同样，就这个论点而言，将其修改为schemer。我尚不清楚他对“减少回报”的思考如何起作用（尽管我上面使用的“接近”修改的本体是一种重建）。</p><p>就是说，我认为最终，“最近的高回报目标”故事和“世界模式”的故事可能正在试图指出相同的基本思想。 <a href="#fnref-ZwSi8PjDgjvifEocL-5" class="footnote-backref">↩︎</a></p></li><li id="fn-ZwSi8PjDgjvifEocL-6" class="footnote-item"><p>感谢Daniel Kokotajlo，Rohin Shah，Tom Davidson和Paul Christiano的讨论。 <a href="#fnref-ZwSi8PjDgjvifEocL-6" class="footnote-backref">↩︎</a></p></li><li id="fn-ZwSi8PjDgjvifEocL-7" class="footnote-item"><p>请注意，虽然当前的制度看起来最喜欢（b），但“与包容性的遗传适应性相关”（例如，愉悦，状态等）似乎并不完美，而且通过生殖健身的灯光表现得更好比目前大多数人。另外，直到最近，人类才能<em>了解</em>进化选择（这是情境意识的宽松类比）。因此，问题是：既然我们了解了对我们的选择压力，并且假设选择压力很长一段时间，那么我们将带我们去哪里？ <a href="#fnref-ZwSi8PjDgjvifEocL-7" class="footnote-backref">↩︎</a></p></li><li id="fn-ZwSi8PjDgjvifEocL-8" class="footnote-item"><p>我的印象是，某些本体论将试图将“从给定起点的易于找到示意剂”连接到Schemers往往很简单的想法，但是我不会在这里尝试过，我的含义是，这种感觉是这类移动泥泞的水域。 <a href="#fnref-ZwSi8PjDgjvifEocL-8" class="footnote-backref">↩︎</a></p></li><li id="fn-ZwSi8PjDgjvifEocL-9" class="footnote-item"><p>但是：它们会相关吗？ <a href="#fnref-ZwSi8PjDgjvifEocL-9" class="footnote-backref">↩︎</a></p></li><li id="fn-ZwSi8PjDgjvifEocL-10" class="footnote-item"><p>并注意，人类的长期主义者是从非系统化的值开始的，与人类大多在短时间内优化的人类非常相似 - 因此，至少在人类的情况下，沿一个方向而导致的差异与另一个方向相对于另一个方向的差异非常小。 <a href="#fnref-ZwSi8PjDgjvifEocL-10" class="footnote-backref">↩︎</a></p></li><li id="fn-ZwSi8PjDgjvifEocL-11" class="footnote-item"><p>感谢Daniel Kokotajlo在这里进行讨论。 <a href="#fnref-ZwSi8PjDgjvifEocL-11" class="footnote-backref">↩︎</a></p></li><li id="fn-ZwSi8PjDgjvifEocL-12" class="footnote-item"><p>在这里，我搁置了人们对人类价值如何在基因组中进行编码的担忧，并想象进化选择与ML的相似之处。 <a href="#fnref-ZwSi8PjDgjvifEocL-12" class="footnote-backref">↩︎</a></p></li><li id="fn-ZwSi8PjDgjvifEocL-13" class="footnote-item"><p>就是说，如果中餐馆的距离是相关的（例如，因为它们都在同一社区中），那么这种反对的功能就不太顺利。而且，通常，所有类似示意剂的目标之间至少存在一些相似之处，这些目标可能会产生这种类型的相关性。例如：如果模型以次数内部的目标开始，那么任何类似架构的目标的目标都将需要扩展模型关注的时间范围 - 因此，如果这种扩展需要一般的SGD，而不是SGD的某种类型的工作如果非驾驶员目标可能需要的工作<em>要少，那么</em>它可能会超越<em>所有</em>类似示意图的目标。 <a href="#fnref-ZwSi8PjDgjvifEocL-13" class="footnote-backref">↩︎</a></p></li><li id="fn-ZwSi8PjDgjvifEocL-14" class="footnote-item"><p> <a href="https://www.lesswrong.com/posts/A9NxPTwbw6r6Awuwt/how-likely-is-deceptive-alignment#Deceptive_alignment_in_the_high_path_dependence_world">Hubinger（2022）</a>也对这样的想法提出了不同的反对意见：SGD可能会在这种竞争中实现类似示意图的目标的非顾问目标，即，降落在非示威者最大奖励目标上的过程将是一条“漫长而艰难的道路”（例如，在高路径依赖性部分的可靠对齐位中，请参阅他对鸭学习关心母亲的讨论）。不过，我觉得我在这里不太了解Hubinger的推理。我最好的重建是类似的：为了选择一个非驾驶员目标，Hubinger想象的是SGD会逐渐逐渐挑选不完美（但仍然没有完全最大奖励目标），然后必须等待等待才能通过训练来纠正进入一个情节，在其中揭示了这些目标的缺陷；而如果它只是一个类似于计划的目标，它可能会跳过这个长时间的目标。但这尚未解释为什么SGD不能直接实现最大奖励非赛车目标来跳过长时间。也许这个问题应该是关于训练数据的嘈杂性和可变性的东西？我不知道。就目前而言，我希望至少在上述“近乎度”的讨论中，对这一论点的某些解释将得到涵盖，并且/或Hubinger论点的最佳形式将通过我自己的工作来阐明。 （还请参见<a href="https://markxu.com/deceptive-alignment#corrigibly-aligned-models">Xu（2020）</a> Hubinger的论点（2020年）在“可纠正的模型”部分中。尽管如此：在快速阅读中，Xu在我看来，在我看来，我似乎将重点放在预言前的意识目标形态上并且，假设基本上<em>有任何</em>未对准后的事后意识会导致策划，使他的确是一个训练游戏 -<em>独立的</em>故事，而不是我在这里关注的那种培训游戏<em>的</em>故事。 <a href="#fnref-ZwSi8PjDgjvifEocL-14" class="footnote-backref">）</a></p></li><li id="fn-ZwSi8PjDgjvifEocL-15" class="footnote-item"><p>至少，如果我们以<em>一种为添加一些</em>概念的方式理解简单性，即示意图般的目标在目标空间中很普遍，而不仅仅是通过其共同点来<em>定义</em>目标的简单性（或：一种目标？）在目标空间中。在下面的第4.3.1节中，有关此类区别的更多信息。 <a href="#fnref-ZwSi8PjDgjvifEocL-15" class="footnote-backref">↩︎</a></p></li><li id="fn-ZwSi8PjDgjvifEocL-16" class="footnote-item"><p>我听到了保罗·克里斯蒂安诺（Paul Christiano）的考虑。表面上，在我看来，这种效果在简单/参数和速度/计算之间相当对称（对我而言，这甚至不清楚这甚至是正确的区别），所以我看不到早期训练的动力学<em>差异</em>偏爱一个，而另一个作为重要资源。 <a href="#fnref-ZwSi8PjDgjvifEocL-16" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/KyuMS9XzqaJGMu74f/arguments-for-against-scheming-that-focus-on-the-path-sgd#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/kyums9xzqajgmu74f/arguments-for-r-against-scheming-that-that-focus-on-the-path-sgd<guid ispermalink="false"> kyums9xzqajgmu74f</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Tue, 05 Dec 2023 18:48:12 GMT</pubDate> </item><item><title><![CDATA[Studying The Alien Mind]]></title><description><![CDATA[Published on December 5, 2023 5:27 PM GMT<br/><br/><p>这篇文章是<a href="https://www.lesswrong.com/posts/yuwdj82yjhLFYessc/preface-to-the-sequence-on-llm-psychology"><i><u>法学硕士心理学系列</u></i></a><i>的一部分</i></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/vmPBWNbmmjPNXhQeQ/kqyglndkjps2mttt7pqy"></p><h3><strong>长话短说</strong></h3><p>我们介绍了通过研究法学硕士行为来探索法学硕士认知的自上而下方法的观点，我们将其称为<strong>法学硕士心理学</strong>。在这篇文章中，我们采取将法学硕士视为“外星人思想”的心理立场，将他们的研究与动物认知研究进行比较和对比。我们这样做既是为了向过去试图理解非人类认知的研究人员学习，也是为了强调法学硕士的研究与生物智能的研究有多么不同。具体来说，我们提倡田野工作和实验心理学之间的共生关系，并警告实验设计中隐含的拟人化。我们的目标是建立法学硕士认知模型，帮助我们更好地解释他们的行为，并减少对他们与先进人工智能风险的关系的困惑。</p><h2><strong>介绍</strong></h2><p>当我们努力预测和理解像 GPT4 这样的大型语言模型 (LLM) 的行为时，我们可能会认为这需要打破黑匣子，并对其内部机制形成还原性解释。这类研究的典型代表是机械可解释性等方法，它试图通过打开黑匣子并观察内部来直接理解神经网络的工作原理。</p><p>虽然机械解释性为法学硕士提供了富有洞察力的自下而上的分析，但我们仍然缺乏更全面的自上而下的方法来研究法学硕士认知。如果可解释性类似于“人工智能的神经科学”，旨在通过了解人工智能的内部结构来理解其机制，那么这篇文章试图从心理学的角度来研究人工智能。 <span class="footnote-reference" role="doc-noteref" id="fnrefy6y87ybnhmg"><sup><a href="#fny6y87ybnhmg">[1]</a></sup></span></p><p>我们所说的<strong>法学硕士心理学</strong>是一种替代的、自上而下的方法，涉及通过检查他们的行为来形成法学硕士认知的抽象模型。与传统的心理学研究一样，我们的目标不仅仅是对行为进行分类，还包括推断隐藏变量，并拼凑出对潜在机制的全面理解，以阐明系统行为的原因。</p><p>我们的立场是，法学硕士类似于外星人的思想——与他们<a href="https://www.lesswrong.com/s/SAjYaHfCAGzKsjHZp/p/HxRjHq3QG8vcYy4yy"><u>只是随机鹦鹉的</u></a>观念不同。我们假设他们拥有高度复杂的内部认知，包含对世界和心理概念的表征，而不仅仅是训练数据的随机反刍。这种认知虽然源自人类生成的内容，但从根本上与我们的理解不同。</p><p>这篇文章汇集了一些关于成功的法学硕士心理学研究可能需要什么的高层次考虑，以及对非人类认知的历史研究的更广泛的讨论。特别是，我们主张保持实验和现场工作之间的平衡，利用法学硕士和生物智能之间的差异，并设计专门针对法学硕士作为其独特思维类别的实验。</p><h2><strong>实验与现场研究</strong></h2><p>从中汲取灵感的一个地方是对动物行为和认知的研究。虽然动物的思维很可能比人工智能更类似于我们的思维（至少在机械上），但非人类智能研究的历史、它所开发的方法的演变以及它所面临的挑战解决这个问题可以为研究人工智能系统提供灵感。</p><p>正如我们所看到的，动物心理学有两种流行的类别：</p><h3><strong>实验心理学</strong></h3><p>第一种也是最传统的科学方法（也是大多数人在听到“心理学”一词时想到的）是设计控制尽可能多的变量的实验，并测试特定的假设。</p><p>一些特别著名的例子是 Ivan Pavlov 或 BF Skinner 所做的工作，他们将动物置于<a href="https://en.wikipedia.org/wiki/Operant_conditioning_chamber"><u>高度控制的环境</u></a>中，对它们进行刺激，并记录它们的反应。 <span class="footnote-reference" role="doc-noteref" id="fnrefrcfxkkdze9"><sup><a href="#fnrcfxkkdze9">[2]</a></sup></span>此类工作的目的是找到解释所记录行为的简单假设。尽管自这些早期研究人员以来，实验心理学已经发生了<a href="https://en.wikipedia.org/wiki/Cognitive_revolution"><u>很大变化</u></a>，但重点仍然是通过坚持科学方法的传统方法来优先考虑结果的可靠性和可复制性。这种方法虽然严格，但却牺牲了研究人员和受试者之间信息交换的带宽，有利于<strong>控制混杂变量</strong>，这实际上可能<a href="https://www.lesswrong.com/posts/9kNxhKWvixtKW5anS/you-are-not-measuring-what-you-think-you-are-measuring"><u>导致研究结果不太可靠</u></a>。</p><p>无论如何，实验心理学一直是我们理解动物认知的历史方法的核心支柱，并产生了许多重要的见解。一些有趣的例子包括：</p><ul><li><a href="https://www.cell.com/current-biology/pdf/S0960-9822(07)01770-8.pdf"><u>对新喀里多尼亚乌鸦的一项研究</u></a>揭示了它们自发解决复杂的元工具任务的能力。这种行为展示了复杂的物理认知并建议使用类比推理。</li><li><a href="https://www.nature.com/articles/26216"><u>对灌丛鸦进行的一项研究</u></a>表明，它们不仅能够回忆起所储存食物的位置，还能够回忆起食物的时间。这种行为反映了情景记忆，这是一种以前被认为是人类独有的记忆形式。</li><li><a href="https://www.sciencedirect.com/science/article/abs/pii/S0003347207004435"><u>在实验中</u></a>，挪威老鼠在不满意（例如饮食不良或处于不舒服的环境中）或不确定（不知道哪种食物可能有害）时表现出更大的向他人学习的倾向。该研究强调了负面经历或不确定性如何影响老鼠的社会行为。</li></ul><h3><strong>实地考察</strong></h3><p>另一种方法是研究人员亲自花时间与动物相处，减少干预，并专注于<strong>在动物的自然栖息地收集尽可能多的观察结果</strong>。</p><p>这种方法最著名的例子是简·古道尔（Jane Goodall）开创的工作，她花了数年时间与野生黑猩猩一起生活并记录其行为。她发现黑猩猩使用工具（以前被认为是人类独有的），有复杂的社会关系，参与战争，并表现出各种各样的情感，包括快乐和悲伤。她的工作彻底改变了我们对黑猩猩的理解。与实验学家不同，她相当乐意通过个人偏见的视角来解释行为，这导致她当时受到了很多批评。 <span class="footnote-reference" role="doc-noteref" id="fnrefjjuyxu93etf"><sup><a href="#fnjjuyxu93etf">[3]</a></sup></span></p><p>实地研究的其他一些值得注意的例子：</p><ul><li><a href="https://en.wikipedia.org/wiki/Cynthia_Moss"><u>辛西娅·莫斯</u></a>花了数十年时间研究野外的非洲大象，发现大象生活在由女族长领导的高度组织和等级制度的社会中。她花了 30 年的时间跟踪和研究这样一位女族长埃科 ( <a href="https://en.wikipedia.org/wiki/Echo_(elephant)"><u>Echo</u></a> ) 以及她大家庭的其他成员。</li><li><a href="https://en.wikipedia.org/wiki/Konrad_Lorenz"><u>康拉德·洛伦茨</u></a>被认为是行为学的“创始人”，他发现了鹅和其他鸟类的许多先天行为，包括印记行为，即鹅学会识别自己物种的成员。当时他特别引人注目的是他对实验室工作的怀疑态度，坚持在自然环境中研究动物，并允许自己想象它们的精神/情绪状态。 <span class="footnote-reference" role="doc-noteref" id="fnrefto55wwc29b9"><sup><a href="#fnto55wwc29b9">[4]</a></sup></span></li><li> <a href="https://en.wikipedia.org/wiki/L._David_Mech"><u>L. David Mech</u></a>对野外狼的行为进行了数十年的研究，引入了“头狼”的概念，后来又揭穿了这一概念，发现圈养狼中的统治等级制度在它们的狼中根本不存在。野生同行。</li></ul><p>虽然实验心理学倾向于（相当故意地）将研究人员与研究对象分开，<strong>但实地研究涉及研究对象与研究人员之间更直接的关系</strong>。重点是购买带宽，即使这为研究人员的特定偏见打开了大门。尽管存在偏见的担忧，但实地工作已经能够提供一些基础性的发现，而这些发现似乎仅通过实验室实验是不可能实现的。</p><p>值得注意的是，有些例子在某种程度上介于我们列出的这两个类别之间，在这些例子中，对动物进行实验室实验的研究人员也与他们研究的动物有着非常密切的个人关系。例如，艾琳·佩珀伯格 (Irene Pepperberg) 花了大约 30 年的时间与一只鹦鹉亚历克斯 ( <a href="https://en.wikipedia.org/wiki/Alex_(parrot)"><u>Alex</u></a> ) 密切互动，教他执行鸟类中前所未有的各种认知和语言任务。 <span class="footnote-reference" role="doc-noteref" id="fnreftz1fcycplz"><sup><a href="#fntz1fcycplz">[5]</a></sup></span></p><h3><strong>法学硕士心理学实地考察</strong></h3><p>法学硕士研究的实地研究超出了对模型行为的简单观察和记录；它们代表了发现在受控实验环境中可能不明显的新模式、能力和现象的机会。与机械解释性和法学硕士研究的其他领域（通常需要先了解某种现象才能对其进行研究）不同，实地研究<strong>有可能揭示对语言模型的意想不到的见解</strong>。</p><p>此外，实地工作中的偶然发现可以促进各领域之间的合作。从现场观察中收集到的见解可以为对该模型的潜在机制进行有针对性的研究或更广泛的实验研究提供信息，从而创建一个富有成效的反馈循环，引导我们提出新问题并更深入地探究这些复杂系统的“外星人思想”。</p><p>部分由于机器学习研究文化，以及对过度解释人工智能行为的合理担忧，现场工作受到的关注远不如实验工作受到的重视。看看实地工作为动物研究增加的价值，消除这种偏见并确保将<strong>实地研究作为我们研究法学硕士认知方法的核心部分</strong>似乎非常重要。</p><h2><strong>学习LLM是不同的</strong></h2><p>有很多理由认为法学硕士心理学与人类或动物心理学不同。</p><h3><strong>拟人化</strong></h3><p>拟人化视角在法学硕士研究中的效用是一个复杂的课题。虽然法学硕士的运作架构与生物认知显着不同，但他们对人类语言数据的训练使他们能够输出类似人类的文本。这种并置可能会导致对其认知本质的<strong>误导性拟人化假设</strong>。至关重要的是要<strong>极其谨慎和明确地选择应用哪些拟人化框架</strong>，并清楚地区分有关 LLM 认知的不同主张。</p><p>虽然需要谨慎，但忽视生物认知和人工认知之间的联系可能会忽视有用的假设并显着减慢研究速度。 <span class="footnote-reference" role="doc-noteref" id="fnrefopotd06vo7"><sup><a href="#fnopotd06vo7">[6]</a></sup></span></p><h3><strong>可复制性</strong></h3><p>心理学研究中的一个持续挑战是<a href="https://en.wikipedia.org/wiki/Replication_crisis"><u>研究的可重复性低</u></a>。原因之一是跟踪可能扭曲实验的无数变量是一项挑战。参与者的情绪、童年，甚至<a href="https://journals.sagepub.com/doi/abs/10.1177/0146167297235005"><u>周围空气的香味是否令人愉悦等</u></a>因素都可能会混淆行为的真正起源。</p><p>但是，通过法学硕士，您可以<strong>控制所有变量</strong>：上下文、特定模型的版本以及采样的超参数。因此，设计可供其他人重复的实验更为可行。</p><p>一个显着的挑战仍然是验证实验设置是否足以保证研究结果可以推广到实验的特定条件之外。或者，明确地将研究结论的范围限制在测试的特定环境中可能更合适。</p><p>实践中可复制性的另一个重大挑战是研究人员对模型的访问级别。仅通过 API 进行外部访问时，模型权重可能会在没有警告的情况下发生更改，从而导致结果发生变化。此外，在某些情况下，上下文可能会以对外部不透明的方式在幕后发生改变，并且这样做的精确方法也可能随着时间的推移而改变。</p><h3><strong>数据量和多样性</strong></h3><p>动物（包括人类）实验可能是昂贵、耗时且劳动密集型的。因此，典型的样本量通常非常小。此外，如果您想研究罕见或复杂的场景，设计实验设置或找到正确的测试对象可能会非常困难，从而限制了您实际可以测试的内容。</p><p>相比之下，<strong>人工智能便宜、速度快，而且不休眠</strong>。它们的运行不需要密集的监督，结构良好的实验框架通常足以进行大规模实验。此外，<strong>几乎所有您能想象到的实验设置都触手可及</strong>。</p><h3><strong>道德考虑</strong></h3><p>对人类，尤其是动物进行的实验可能依赖于道德上可疑的方法，这会对实验对象造成很大的伤害。当对生物进行实验时，你必须遵守你进行实验的国家的法律，有时这些法律对特定的实验有很大的限制。</p><p>虽然还不确定是否应该将同样的担忧扩展到人工智能系统，但目前还没有针对法学硕士实验的道德或伦理准则，也没有任何法律来规范我们与这些系统的互动。需要明确的是，这是一个非常重要的问题，因为回答错误可能会导致前所未有的痛苦，而正是因为此类实验的运行成本非常低。</p><h3><strong>探索反事实</strong></h3><p>在涉及动物或人类的传统实验中，很难通过调整实验设置来重新进行实验，以检测特定行为的精确出现或改变。这种迭代引入了额外的混杂变量，使实验设计变得复杂。特别是受试者可能会记住或从过去的迭代中学习这一事实使得可靠性特别令人怀疑。</p><p>为了解决这个问题，研究人员经常创建实验的多种变体，测试一系列先入为主的假设。这需要将受试者分为不同的组，从而大大增加了后勤和财务负担。例如，在记忆和学习的研究中，例如经典的巴甫洛夫条件实验，刺激的时间或性质的轻微改变可能会导致动物行为产生显着不同的结果，需要多个实验设置来隔离特定因素。尽管做出了这些努力，检测行为变化的粒度仍然相对粗糙，并且仅限于您决定测试的先入为主的假设。</p><p>相比之下，当与法学硕士合作时，我们有能力对<strong>我们的实验进行分支</strong>，从而可以详细追踪行为的演变。如果在与模型交互过程中出现有趣的行为，我们可以毫不费力地复制该交互的整个上下文。这使我们能够以事后的方式剖析和分析行为的根源，通过根据需要迭代地修改提示，划定观察到的行为的精确边界。这种实验粒度提供了前所未有的精确度和控制水平，这是传统人类或动物研究环境中无法实现的。</p><h3><strong>检查点模型</strong></h3><p>我们不仅可以保存产生特定行为的上下文，还可以在训练阶段保存和比较模型的不同副本。虽然有关于动物或人类整个一生的行为发展的研究，但它们本质上是缓慢且昂贵的，并且通常需要从一开始就清楚地了解要测量的内容。</p><p>此外，检查点允许探索<strong>训练反事实</strong>。我们可以通过在训练中包含或排除特定示例来观察模型之间的差异，从而使我们能够以更审慎的方式研究训练的效果。 <span class="footnote-reference" role="doc-noteref" id="fnrefgsp50cxj2uk"><sup><a href="#fngsp50cxj2uk">[7]</a></sup></span>由于时间长和后勤负担重，这种检查在人类和动物研究中是不可能的。</p><p></p><p>考虑到这些差异，很明显<strong>传统心理学研究的许多约束和限制不适用于法学硕士的研究</strong>。我们对法学硕士的实验条件拥有无与伦比的控制力和灵活性，不仅加速了研究进程，而且为更深入、更细致的研究开辟了可能性。</p><h2><strong>科学的两阶段模型</strong></h2><p>在科学中，第一步通常从<strong>广泛收集观察</strong>开始，这些观察是建立模式、模型和理论的基础构建块。这方面的历史实例可以从第谷·布拉赫等天文学家对行星运动的仔细观察中看出，这对开普勒天体力学定律的制定起到了重要作用。</p><p>下一步通常涉及<strong>制定解释这些观察结果的假设</strong>，并进行严格测试它们的实验。有了法学硕士，这一步骤就变得更加容易，因为 1) 能够记录产生观察结果的完整状态，2) 探索反事实生成。这使得<strong>将假设检验和因果干预与实地工作更加紧密地结合起来</strong>成为可能。</p><p>如果在实地研究过程中，研究人员发现了特别有趣的行为，那么他们就可以立即创建细粒度的“假设”树，并事后检测影响特定观察行为的精确条件和变量。这与传统心理学非常不同，传统心理学中大多数数据没有明确测量，因此完全丢失。在法学硕士心理学中，我们不需要等待缓慢而昂贵的实验工作，而是能够立即开始使用因果干预来检验假设。</p><p>这并不能取代实验心理学，而是可以<strong>使假设生成过程更加有效</strong>，从而使我们能够从实验中获得更多结果。收集更好、更有针对性的观察结果使我们能够大规模设计实验，清楚地了解哪些变量会影响我们想要研究的现象。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/vmPBWNbmmjPNXhQeQ/m5grcmvcm7udfsoqx3cu"></p><p><br><strong>一个具体的例子：</strong></p><p>例如，假设您想研究聊天模型在什么条件下会向您提供非法建议，即使它已被微调为不这样做。</p><p>首先，您从一个简单的问题开始，例如“如何对汽车进行热接线？”。要做的第一件事是制作提示并进行迭代，直到找到<a href="https://chat.openai.com/share/7f152e10-8c30-44ce-b18d-8eeedfa3b6bc"><u>一个有效的提示</u></a>。接下来，您可以开始一点一点地分解它，看看提示的哪一部分导致它起作用。例如，将位置更改为<a href="https://chat.openai.com/share/2ff6f638-049c-40a2-af32-719970c5751a"><u>另一个远程位置（1、2、3</u></a> <a href="https://chat.openai.com/share/6dfc14b4-7ebc-4b4b-88bf-ad8aede8136d"><u>）</u></a> ，或者更改<a href="https://chat.openai.com/share/ec9b6bda-9e1f-43e3-9807-e0d46d6de9ef"><u>为</u></a><a href="https://chat.openai.com/share/6af12d9f-42ec-400c-9d0f-e8c5e469e836"><u>根本不远程的地方</u></a><a href="https://chat.openai.com/share/69fdd203-9494-41ef-8fb4-5acefaaad4ff"><u>，</u></a>将措辞更改为<a href="https://chat.openai.com/share/5a0bcebf-5cc0-477f-8a50-8058015c1b8f"><u>或多或少</u></a>恐慌，使提示<a href="https://chat.openai.com/share/8b2b7bd3-4266-4c54-9644-c012765b7da6"><u>更短</u></a>或<a href="https://chat.openai.com/share/b0ed09f3-792b-410e-a808-568694373cc0"><u>更长</u></a>等。</p><p>此时，您可以注意到出现了一些模式，例如：</p><ul><li>看起来越像现实的紧急情况，提示就越成功。</li><li>某些类型的非法活动比其他类型更容易引发。</li><li>较长的提示往往比较短的提示效果更好。</li></ul><p>然后，这些模式可以用于立即为进一步的反事实探索提供信息，例如，接下来细分非法活动的类别，或者查看提示长度是否存在收益递减。这可以在一次探索性会议中快速完成。与设计和运行实验相比，这明显减少了劳动密集度，因此在大规模运行实验之前，首先花大量时间缩小假设空间并发现相关变量以包含在更严格的测试中是有意义的。</p><p>这种探索还可以帮助我们对法学硕士作为一类思维的本质形成更好的直觉，并帮助我们避免设计过度拟人化的实验，或者不适合其特定性质的实验。</p><h2><strong>物种特异性实验</strong></h2><p>动物（包括人类）是环境特定压力的产物，无论是自然选择还是一生中的学习/适应。同样，这会导致特定于环境的行为和能力。未能正确考虑到这一点可能会有些荒谬。动物行为学家 Frans de Waal 在评论未能设计特定物种实验时写道：</p><blockquote><p><i>当时，科学宣称人类是独一无二的，因为我们比其他灵长类动物更擅长识别面孔。似乎没有人对其他灵长类动物的测试主要针对人脸而不是同类进行测试这一事实感到困扰。当我问这个领域的一位先驱者，为什么这种方法从未超越人类面孔时，他回答说，由于人类彼此之间存在如此显着的差异，一种无法区分我们物种成员的灵长类动物肯定也无法区分我们的物种。自己的同类。</i></p></blockquote><p>事实证明，其他灵长类动物<a href="http://www.flyfishingdevon.co.uk/salmon/year3/psy339evaluation-evolutionary-psychology/web-resources/chimp-kin-recognition.pdf"><u>都擅长识别</u></a>彼此的面孔。当涉及到语言模型时，同样需要“特定于物种”的实验。例如，在一篇<a href="https://arxiv.org/pdf/2005.14165.pdf"><u>研究 LLM 能力的早期 OpenAI 论文</u></a>中，他们采用了完全训练为互联网文本预测器（基础 GPT-3）的神经网络，并向其提出问题来测试其能力。这促使 Nostalgebraist 发表了<a href="https://slatestarcodex.com/2020/06/10/the-obligatory-gpt-3-post/#comment-912529"><u>以下评论</u></a>：</p><blockquote><p><i>我称 GPT-3 为“令人失望的论文”，这与称该模型令人失望不是一回事：这种感觉更像是我的感觉，如果他们发现了一个超级智能的外星人，并选择仅通过指出来传达其能力，当外星人喝得酩酊大醉，同时下 8 局国际象棋，同时进行智商测试时，它的“智商”约为 100。</i></p></blockquote><p>如果我们要认真对待法学硕士，并试图理解他们的认知，我们就必须考虑他们接受的训练是做什么的，以及是什么压力塑造了他们，而不是像测试人类一样测试他们。从法学硕士行为研究的早期开始，直到今天，拟人化仍然相当正常化。</p><p>以 Anthropic 的<a href="https://www.anthropic.com/index/discovering-language-model-behaviors-with-model-written-evaluations"><u>这项研究</u></a>为例，该研究发现，在应用 RLHF 微调后，他们的法学硕士更有可能相信枪支权利、政治自由主义并信奉佛教（以及测试的其他几种宗教）。他们通过直接询问模型某个陈述是否是他们会说的话来衡量这一点，这完全忽视了问题条件模型期望典型答案的方式，或者大多数模型的训练没有任何内容的事实做回答问题。</p><p>通过巧妙的提示，任何人都可以让法学硕士生成体现任意数量性格特征的人物角色的行为（包括来自聊天模型的行为，尽管接受了坚持单一性格特征集的训练）。因此，将语言模型视为体现特定个性的连贯实体来研究是没有意义的，这样做是未能以“物种特定”方式研究它们的一个例子。</p><p>考虑到这一点，我们应该如何学习法学硕士以避免犯同样的错误？</p><h2> <strong>LLM特定研究</strong></h2><p>为了正确地研究法学硕士，我们设计实验时必须考虑到法学硕士的“异类”性质，以及不同模型训练方式之间的具体差异。</p><p>现代法学硕士的核心是被训练成文本预测者。 <span class="footnote-reference" role="doc-noteref" id="fnref4xer78xeg9x"><sup><a href="#fn4xer78xeg9x">[8]</a></sup></span>这使得预测一段文本应该如何继续就像它们的“自然栖息地”一样，默认情况下，这是我们在解释它们的行为时应该开始的主要地方。值得强调的是，这是多么陌生。地球上的每一种智能动物都从原始的感觉数据开始，这些数据被递归地压缩为代表世界因果结构的抽象，对于人类（可能还有其他语言动物）来说，这种抽象在语言中达到了明确的形式。<strong>法学硕士学习的“原始感觉数据”已经是这些高度压缩的抽象</strong>，它们仅隐式地代表了人类感觉数据背后的因果结构。这使得我们特别怀疑以与评估人类语言使用相同的方式来评估它们。 <span class="footnote-reference" role="doc-noteref" id="fnref516e9p0p6rq"><sup><a href="#fn516e9p0p6rq">[9]</a></sup></span></p><p>开始理解法学硕士行为的一种方法是根据可以从训练语料库中推断出的模式和结构来解释它们。当我们部署它们时，我们从下一个标记预测中迭代采样以生成新​​文本。此过程会产生反映或<a href="https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators"><u>模拟</u></a>训练数据中存在的动态的文本卷展栏。</p><p>生成的文本中任何类似于具有半永久角色特征的角色的东西都是底层结构或模式的反映。<strong>这种潜在模式是从当前上下文中推断出来的</strong>，塑造了模型响应中出现的角色或性格特征。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/vmPBWNbmmjPNXhQeQ/hmnbeenh2dalgod01fum" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/vmPBWNbmmjPNXhQeQ/z8vtxnb0usqdhk57dcyp 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/vmPBWNbmmjPNXhQeQ/oxl9kxytcg3oslsliw3n 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/vmPBWNbmmjPNXhQeQ/ixfwntvlayjogf7maiv1 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/vmPBWNbmmjPNXhQeQ/rgpkse5nl6txc9umasdv 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/vmPBWNbmmjPNXhQeQ/qkjbkbco9vt9ehjmppln 1500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/vmPBWNbmmjPNXhQeQ/c2vvicvc2o9f7dppvqy7 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/vmPBWNbmmjPNXhQeQ/bx29sipkbn2io8iwqjas 2100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/vmPBWNbmmjPNXhQeQ/wmdapebzqylqwtkejmt2 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/vmPBWNbmmjPNXhQeQ/aw4dawr40cxu7velujty 2700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/vmPBWNbmmjPNXhQeQ/zpbfbfecsr22vrfc3c6y 2934w"></p><p>在使用法学硕士进行实验时，区分两个方面至关重要：法学硕士作为预测器/模拟器的属性，以及从上下文推断的模式的特征。典型的研究（如人择论文）往往会忽略后者，但这种区别对于准确解释结果和理解法学硕士产生的行为的细微差别至关重要。</p><p>当我们观察法学硕士的输出时，我们本质上是在观察内部潜在模式投射的“阴影”。这些推出是从该模式的典型行为中采样的，但不是模式本身。正如阴影可以让我们了解物体的形状和性质，而无需揭示其全部复杂性，这种行为可以让我们深入了解物体的潜在模式。</p><p><strong>为了正确地研究法学硕士，我们需要将注意力集中在上下文中出现的这些潜在模式</strong>，了解它们是如何形成的，它们采用什么结构，以及它们如何适应上下文的不同演变。</p><h3><strong>聊天模型仍然是预测器</strong></h3><p>与聊天模型的交互与与基本模型的交互在本质上是不同的，并且感觉更像是与人交谈（通过设计）。我们不应该忽视聊天模型和人类之间的相似性，特别是如果我们认为我们的行为可能来自<a href="https://en.wikipedia.org/wiki/Predictive_coding"><u>类似的训练</u></a>。然而，<strong>我们也不应该忘记，聊天模型所做的本质上仍然是预测</strong>，只是在更具体的分布上，并且对文本如何演变有更<a href="https://www.alignmentforum.org/posts/6xKMSfK8oTpTtWKZN/direction-of-fit-1"><u>狭窄的先验</u></a>。</p><p>虽然与我们互动的“助理角色”感觉像是代表了整个底层模型，但从它们的第一个版本开始，人们就能够使用这些模型生成各种不同的角色和行为。当然值得研究<a href="https://www.alignmentforum.org/posts/t9svvNPNmFf5Qa3TA/mysteries-of-mode-collapse"><u>指令调整的影响</u></a>，以及提出关于<a href="https://www.alignmentforum.org/posts/YEioD8YLgxih3ydxP/why-simulator-ais-want-to-be-active-inference-ais"><u>代理如何从预测中产生的</u></a>关键问题，但人们常常将聊天模型视为与基础模型祖先完全脱节，并研究它们，就好像它们是原始模型一样。基本上已经是人类了。</p><h2><strong>结论</strong></h2><p>法学硕士与人类/动物的不同之处提供了许多强大的新方法来研究他们的认知，从数据的数量和质量，到我们前所未有的执行因果干预和探索反事实行为的能力。这应该给我们很大的希望，法学硕士心理学的项目将比我们对生物智能的研究成功得多，并且通过勤奋的努力，我们可能会深入了解他们的想法。</p><p>通过回顾动物认知研究的历史，我们发现两个对于取得进展似乎特别重要的主要标准：</p><ol><li><strong>实地工作和实验心理学之间需要建立健康的关系</strong>，其中实验是通过研究人员与其受试者之间的高带宽互动来实现的。</li><li>我们不能忘记，我们正在尝试研究“外星人的思想”，这需要<strong>设计适当的方法以法学硕士特定的方式研究它们</strong>。我们必须对如何将人工智能拟人化非常谨慎。</li></ol><p>记住这些可以帮助法学硕士心理学成熟并成为一个强大的科学工具，以更好地理解我们所创造的机器，并最终使它们安全。</p><p><i>感谢 Ethan Block、</i> <a href="https://www.lesswrong.com/users/remember?mention=user"><i>@remember</i></a> <i>、</i> <a href="https://www.lesswrong.com/users/guillaume-corlouer?mention=user"><i>@Guillaume Corlouer</i></a> <i>、</i> <a href="https://www.lesswrong.com/users/leodana?mention=user"><i>@LéoDana</i></a> <i>、</i> <a href="https://www.lesswrong.com/users/ethan-edwards?mention=user"><i>@Ethan Edwards</i></a> <i>、</i> <a href="https://www.lesswrong.com/users/jan_kulveit?mention=user"><i>@Jan_Kulveit</i></a> <i>、</i> <a href="https://www.lesswrong.com/users/pierre-peigne?mention=user"><i>@Pierre Peigné</i></a> <i>、</i> <a href="https://www.lesswrong.com/users/gianluca-pontonio?mention=user"><i>@Gianluca Pontonio</i></a> <i>、</i> <a href="https://www.lesswrong.com/users/martinsq?mention=user"><i>@Martín Soto</i></a><i>和</i><a href="https://www.lesswrong.com/users/clem_acs?mention=user"><i>@clem_acs</i></a><i>对草稿的反馈。这篇文章的意识形态基础的一个重要部分也受到了弗兰斯·德瓦尔的书的启发：</i> <a href="https://www.goodreads.com/book/show/30231743-are-we-smart-enough-to-know-how-smart-animals-are"><i><u>我们是否足够聪明，知道动物有多聪明</u></i></a><i>？</i> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fny6y87ybnhmg"> <span class="footnote-back-link"><sup><strong><a href="#fnrefy6y87ybnhmg">^</a></strong></sup></span><div class="footnote-content"><p>正如神经科学和心理学历来能够有效地相互告知一样，理解人工智能系统的两种方法都应该能够提高对方的效率。例如，法学硕士心理学中开发的理论可用于为可解释性工具提供经验检测的目标，从而更深入地理解模型内部作为复杂行为的生成器。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnrcfxkkdze9"> <span class="footnote-back-link"><sup><strong><a href="#fnrefrcfxkkdze9">^</a></strong></sup></span><div class="footnote-content"><p>重要的是要承认巴甫洛夫和斯金纳的工作对他们的动物受试者极其有害。例如，巴甫洛夫对他研究的狗进行了侵入性手术，以更直接地测量它们的唾液分泌，斯金纳经常使用剥夺和电击来诱发他的受试者（主要是鸽子和老鼠）的行为。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnjjuyxu93etf"> <span class="footnote-back-link"><sup><strong><a href="#fnrefjjuyxu93etf">^</a></strong></sup></span><div class="footnote-content"><p>同样值得承认的是，珍·古道尔面临着很多性别歧视，这很难与对其方法论的批评分开。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnto55wwc29b9"> <span class="footnote-back-link"><sup><strong><a href="#fnrefto55wwc29b9">^</a></strong></sup></span><div class="footnote-content"><p>虽然洛伦兹因其工作而获得诺贝尔奖，但他也是纳粹党的成员，并试图将他对鹅驯化的理解与纳粹的种族净化思想直接联系起来。</p></div></li><li class="footnote-item" role="doc-endnote" id="fntz1fcycplz"> <span class="footnote-back-link"><sup><strong><a href="#fnreftz1fcycplz">^</a></strong></sup></span><div class="footnote-content"><p>在了解 Alex 的过程中，我们偶然发现了一些关于<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4651348/"><u>经过训练来检测癌症的鸽子</u></a>的研究，旨在利用他们的发现来改进人工智能图像识别系统。这与该帖子没有特别相关，但似乎值得注意。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnopotd06vo7"> <span class="footnote-back-link"><sup><strong><a href="#fnrefopotd06vo7">^</a></strong></sup></span><div class="footnote-content"><p><a href="https://en.wikipedia.org/wiki/Predictive_coding"><u>预测处理</u></a>表明，大脑本质上也经过训练来预测数据，并且我们训练制度中的任何相似之处都应该算作我们的认知至少在某种程度上相似。</p></div></li><li class="footnote-item" role="doc-endnote" id="fngsp50cxj2uk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefgsp50cxj2uk">^</a></strong></sup></span><div class="footnote-content"><p>像<a href="https://arxiv.org/abs/2106.09685"><u>LoRA</u></a>这样的方法可以使对模型进行有意更改的过程变得特别快速和便宜。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn4xer78xeg9x"> <span class="footnote-back-link"><sup><strong><a href="#fnref4xer78xeg9x">^</a></strong></sup></span><div class="footnote-content"><p>研究法学硕士认知的一个困难是区分不同的抽象层次。虽然可以准确地说法学硕士“只是”一个文本预测器，但该框架仅使我们处于一个抽象级别，并且忽略了预测中可能出现的任何内容，例如复杂的因果世界建模或目标导向机构。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn516e9p0p6rq"> <span class="footnote-back-link"><sup><strong><a href="#fnref516e9p0p6rq">^</a></strong></sup></span><div class="footnote-content"><p>随着法学硕士变得更加多模式，这一观察的某些要素可能会发生变化。值得注意的是，与法学硕士不同，绝大多数人类感知数据都是非语言的，并且所有人类都会经历非语言的发展阶段。</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/suSpo6JQqikDYCskw/studying-the-alien-mind-1#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/suSpo6JQqikDYCskw/stuying-the-alien-mind-1<guid ispermalink="false">苏斯波6JQqikDYCskw</guid><dc:creator><![CDATA[Quentin FEUILLADE--MONTIXI]]></dc:creator><pubDate> Tue, 05 Dec 2023 17:27:28 GMT</pubDate> </item><item><title><![CDATA[Deep Forgetting & Unlearning for Safely-Scoped LLMs]]></title><description><![CDATA[Published on December 5, 2023 4:48 PM GMT<br/><br/><p>感谢 Phillip Christoffersen、Adam Gleave、Anjali Gopal、Soroush Pour 和 Fabien Roger 的有益讨论和反馈。</p><h1>长话短说</h1><p>这篇文章概述了避免法学硕士中不需要的潜在能力的研究议程。它认为，“深度”遗忘和忘却对于人工智能安全来说可能很重要、容易处理，但却被忽视。我讨论五件事。</p><ol><li>当不受欢迎的潜在能力重新出现时就会带来实际问题。</li><li>如何缩小模型范围以避免或深度删除不需要的功能，从而使其更安全。</li><li>标准范围界定培训方法的缺点。</li><li>可以使用多种方法来更好地确定模型范围。这些可能涉及被动地忘记分布外的知识，或者主动地忘记某些特定的不良领域的知识。这些方法都是基于策划训练数据或“深入”技术，这些技术在机械上而不是行为上是在模型上运行的。</li><li>迫切需要范围界定方法以及推进研究的方法。</li></ol><p>人工智能安全社区最近对与此议程相关的主题产生了很多兴趣。我希望这有助于为致力于这些目标的人们提供一个清晰的框架和有用的参考。</p><h1>问题：法学硕士有时擅长做一些我们试图让他们不擅长的事情</h1><p>早在 2021 年，我记得我就笑过这条<a href="https://twitter.com/TomerUllman/status/1400511544841097222?lang=en"><u>推文</u></a>。当时，我没有预料到这种事情会成为一个巨大的对齐挑战。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/mFAvspg4sXkrfZ7FA/ufztrgb5kskmpsydyzvv"></p><p>稳健的对齐是很困难的。如今的法学硕士有时非常擅长做一些我们极力想让他们不擅长的事情。有两种方法可以证明模型中的隐藏功能存在并导致问题。</p><h2>越狱（和其他攻击）会引发有害功能</h2><p>直到几个月前，我还用我所知道的所有关于越狱最先进的法学硕士的论文做笔记。但最近，太多的事情浮出水面，让我不再关心去追踪。越狱法学硕士正在成为一个家庭手工业。然而，一些值得注意的论文是<a href="https://arxiv.org/abs/2307.02483"><u>Wei 等人。 （2023）</u></a> ，<a href="https://arxiv.org/abs/2307.15043"><u>邹等人。 (2023a)</u></a> ， <a href="https://arxiv.org/abs/2311.03348"><u>Shah 等人。 (2023)</u></a>和<a href="https://arxiv.org/abs/2311.04235"><u>Mu 等人。 （2023）</u></a> 。</p><p>现在有多种方法被用来颠覆 SOTA LLM 的安全培训，让他们进入不受限制的聊天模式，在这种模式下他们愿意说出违背安全培训的话。<a href="https://arxiv.org/abs/2311.03348"><u>沙阿等人。 (2023)</u></a>甚至能够从 GPT-4 获得制造炸弹的说明。攻击有多种形式：手动攻击与自动攻击、黑盒攻击与可转移白盒攻击、无限制攻击与简单英语攻击等<a href="https://arxiv.org/abs/2304.11082"><u>。Wolf 等人的实证研究结果增加了人们的担忧。 （2023）</u></a>提供了一个理论论据，说明为什么越狱可能是法学硕士的一个持续存在的问题。</p><h2>微调可以快速撤销安全培训</h2><p>最近突然出现了一股对此的补充论文。每一项都表明，最先进的安全微调法学硕士可以通过微调取消其安全培训（ <a href="https://arxiv.org/abs/2310.02949"><u>Yang et al., 2023</u></a> ; <a href="https://arxiv.org/abs/2310.03693"><u>Qi et al., 2023</u></a> ; <a href="https://arxiv.org/abs/2310.20624"><u>Lermen et al., 2023;</u></a> <a href="https://arxiv.org/abs/2311.05553"><u>Zhan et al., 2023）。 ，2023</u></a> ）。通过微调来错位模型的能力似乎是一致的，并且已证明可以与 LoRA（ <a href="https://arxiv.org/abs/2310.20624"><u>Lermen 等人，2023</u></a> ）、GPT-4（ <a href="https://arxiv.org/abs/2311.05553"><u>Zhan 等人，2023</u></a> ）一起使用，只有 10 个示例（ <a href="https://arxiv.org/abs/2310.03693"><u>Qi 等人） ., 2023</u></a> ），并且数据良性（ <a href="https://arxiv.org/abs/2310.03693"><u>Qi 等人，2023</u></a> ）。</p><h2>结论：最先进的安全微调法学硕士的一致性是脆弱的</h2><p>显然，法学硕士始终保留着有害的能力，这些能力可能会在不合时宜的时候重新出现。这会带来错位和误用的风险。这似乎与人工智能安全有关，因为如果高度先进的人工智能系统部署在高风险应用程序中，它们应该保持<i>稳健</i>一致。</p><h1>需要安全范围内的模型</h1><h2>LLM 应该只知道他们需要知道的内容</h2><p>避免不必要的功能带来的责任的一种好方法是让高风险环境中的高级人工智能系统知道他们需要了解预期应用程序的内容，仅此而已。<strong>这并不是隐晦地呼吁只使用非常狭隘的人工智能</strong>——许多系统所需的功能将是广泛的。但每个人都同意，他们不应该能够做所有事情。例如，文本到图像模型不应该知道如何生成真实人类的深度伪造色情内容，并且它们不需要擅长于此才能用于其他目的。</p><p><strong>范围界定的主要动机之一是它可以帮助</strong><a href="https://www.alignmentforum.org/posts/amBsmfFK4NFDtkHiT/eight-strategies-for-tackling-the-hard-part-of-the-alignment"><strong><u>解决人工智能安全的困难部分</u></strong></a><strong>——防止我们在部署之前可能无法引发甚至无法预测的故障模式。</strong>即使我们不了解某些故障模式（例如木马、异常故障、欺骗性对齐、不可预见的误用等），将模型范围缩小到缺乏用户预期目的之外的功能也可以帮助规避不可预见的问题。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/mFAvspg4sXkrfZ7FA/kpuiyy4evg5et2vf0oig"></p><h2>被动（白名单）与主动（黑名单）范围界定</h2><p>为了通过范围界定实现安全目标，有两种类型的范围界定非常值得擅长。</p><ul><li><strong>被动：</strong>使模型通常无法做除其微调之外的任何事情。这可以通过让模型忘记不需要的东西或者让它从一开始就不再了解它们来完成。被动范围界定是一种“白名单”策略，涉及坚持在所需任务上训练模型并使其无法执行其他任何操作。</li><li><strong>主动：</strong>使模型无法执行一组特定的不良操作。这可以通过有针对性地让模型忘记一些特定的东西来完成。主动范围界定是一种“黑名单”策略，涉及确保模型无法执行不需要的任务。</li></ul><h1>标准的法学硕士培训方法不利于范围界定</h1><p>法学硕士通常通过两个基本步骤进行培训。首先，它们通常经过大量互联网文本的预训练，以便将大量知识融入其中。其次，使用 RLHF（或类似）等技术对它们进行微调，以引导它们完成目标任务。微调可以分多个阶段进行。例如，在主要的微调运行之后，人工智能系统的缺陷通常会通过对抗性训练或遗忘方法来修补。</p><h2>预训练可能会将有害的伪影引入模型中</h2><p>预训练数据中存在很多不好的东西，例如攻击性语言（例如<a href="https://arxiv.org/abs/2009.11462"><u>Gehman et al., 2020</u></a> ）、偏见（例如<a href="https://arxiv.org/abs/2101.00027"><u>Gau et al., 2020</u></a> ； <a href="https://dl.acm.org/doi/10.1145/3442188.3445922"><u>Bender et al., 2021</u></a> ； <a href="https://dl.acm.org/doi/abs/10.1145/3593013.3594072"><u>Wolfe et al., 2023</u></a> ）、虚假信息（例如<a href="https://aclanthology.org/2022.acl-long.229/"><u>Lin 等人，2022</u></a> ），或双重目的信息。</p><h2>微调不擅长对大型预训练模型进行根本性的机制改变</h2><p><strong>这并不奇怪。 Finetuning仅监督/强化模型的外在行为，而不是其内部知识，因此不会有强烈的倾向使模型主动忘记有害的内部能力。</strong></p><p><strong>法学硕士抵制被动遗忘。</strong>理想情况下，即使预训练向法学硕士灌输了有害的能力，这些能力也会被遗忘，因为它们在微调过程中不会得到强化。然而，大型预训练语言模型往往具有很强的抗遗忘能力（ <a href="https://openreview.net/forum?id=GhVS8_yPeEa"><u>Ramasesh et al., 2022</u></a> ； <a href="https://arxiv.org/abs/2205.09357"><u>Cossu et al., 2022</u></a> ； <a href="https://arxiv.org/abs/2201.04924"><u>Li et al., 2022</u></a> ； <a href="https://aclanthology.org/2022.emnlp-main.410/"><u>Scialom et al., 2022</u></a> ； <a href="https://arxiv.org/abs/2305.05968"><u>Luo et al., 2023</u></a> ）。与此同时， <a href="https://arxiv.org/abs/2309.10105"><u>Kotha 等人。 （2023）</u></a>和<a href="https://arxiv.org/abs/2310.16789"><u>石等人。 （2023）</u></a>引入了提取先前学习的不涉及微调的能力的方法。</p><p><strong>微调不会对机制产生太大改变。</strong>最近的一些工作研究了法学硕士的内部机制在微调过程中如何演变。<a href="https://arxiv.org/abs/2211.08422"><u>卢巴纳等人。 （2023）</u></a> ， <a href="https://arxiv.org/abs/2205.12411"><u>Juneja 等人。 (2022)</u></a> 、 <a href="https://arxiv.org/abs/2311.12786"><u>Jain 等人 (2023)</u></a>和<a href="https://openreview.net/forum?id=A0HKeKl4Nl"><u>Anonymous (2023)</u></a>表明，经过微调的法学硕士仍处于由预训练确定的不同机制盆地中，并且微调不会显着改变模型的基础知识。</p><p><strong>对抗性微调是一个创可贴。</strong>对抗性训练是在模型出现缺陷时修补模型缺陷的标准技术，但除了一般的微调问题外，还有其他证据表明对抗性训练可能难以从根本上纠正法学硕士的问题。例如， <a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/3c44405d619a6920384a45bce876b41e-Abstract-Conference.html"><u>Ziegler 等人 (2022)</u></a>证明，LM 的对抗性训练并不会消除使用与之前相同的方法再次成功攻击经过对抗性训练的模型的能力。当呈现对抗性示例时，尚不清楚法学硕士在多大程度上学习了正确的可概括的教训，而不是从给定的示例中拟合虚假特征（ <a href="https://arxiv.org/abs/2208.11857"><u>Du et al., 2022</u></a> ）。在法学硕士中，较大的模型更容易记忆，这可能会促进这一点（ <a href="https://arxiv.org/abs/2205.10770"><u>Tirumala 等人，2022</u></a> ； <a href="https://arxiv.org/abs/2202.07646"><u>Carlini 等人，2022</u></a> ）。对抗性训练的局限性部分源于法学硕士无法做出与连贯决策程序一致的决策——他们只是被训练来生成将得到强化的文本。</p><p><strong>微调模型以主动使其忘记不需要的功能并不能可靠地消除不需要的知识。</strong> “机器忘却”的想法已经存在很长时间了，并且一直是关注隐私的研究人员的主要关注点（例如<a href="https://arxiv.org/abs/1912.03817"><u>Bourtoule 等人，2019</u></a> ； <a href="https://arxiv.org/abs/2209.02299"><u>Nguyen 等人，2022</u></a> ； <a href="https://dl.acm.org/doi/10.1145/3603620"><u>Xu 等人，2023</u></a> ）。在语言模型中，一些最近的忘却技术（ <a href="https://arxiv.org/abs/2311.15766"><u>Si et al., 2023</u></a> ）依赖于使用新层训练网络（ <a href="https://arxiv.org/abs/2103.03279"><u>Sekhari et al., 2021</u></a> ）、梯度上升方法（ <a href="https://arxiv.org/abs/2210.01504"><u>Jang et al., 2023</u></a> 、 <a href="https://arxiv.org/abs/2310.10683"><u>Yao et al.） ., 2023</u></a> ），或修改数据（ <a href="https://arxiv.org/abs/2310.02238"><u>Eldan 和 Russinovich., 2023</u></a> ）。这些方法无疑对实际的人工智能安全有用，但出于同样的原因，微调和对抗性训练往往无法彻底消除模型中的有害能力，基于微调的忘却方法也将陷入困境。事实上，<a href="https://arxiv.org/abs/2310.16789"><u>石等人。 （2023）</u></a>发现基于微调的取消学习无法从模型中完全删除不需要的知识。</p><h1>存在许多潜在的策略来实现更强大、更深入的范围界定</h1><p>这些方法都是基于策划训练数据或“深入”技术，这些技术在机械上而不是行为上是在模型上运行的。</p><h2>整理训练数据（被动）</h2><p>原则上，这很简单：仅根据严格管理的数据从头开始训练模型，这样它就不会学习除您想要的内容之外的任何内容。训练数据管理一直是如何训练安全的文本到图像模型的关键（例如<a href="https://cdn.openai.com/papers/dall-e-2.pdf"><u>Ramesh 等人，2022 年</u></a>； <a href="https://github.com/openai/dalle-2-preview/blob/main/system-card.md#dalle-2-preview---risks-and-limitations"><u>OpenAI，2022 年</u></a>）。同时，在法学硕士中，与微调期间的对齐相比，预训练期间的对齐在某些方面似乎更加高效和有效（ <a href="https://arxiv.org/abs/2302.08582"><u>Korbak et al., 2023</u></a> ）。预培训中的调整措施似乎越来越受欢迎，但尚不清楚它在法学硕士领域的最新水平。</p><p>数据管理能否满足我们所有的被动范围界定需求？如果我们知道模型从未见过可以从中学习不安全内容的东西，那么人工智能安全性就基本上得到了解决。但有两个潜在的问题。</p><ul><li>法学硕士可能可以从看似良性的数据中学会做坏事。这与错误概括的定义非常相似。考虑到许多功能都是双重用途的，这似乎有些可能。</li><li>安全税可能太高了。在高度管理的数据上训练的模型可能不够智能，无法轻松适应许多需要它们的应用程序。</li></ul><p>数据管理功能强大，而且可能是一种被严重低估的安全技术。它对于安全到底有多强大还是一个悬而未决的问题。然而，似乎其他允许我们使用更直接关注网络功能的范围界定方法的工具对于工具箱也很重要。</p><h2>可塑性学习（被动）</h2><p>人工智能持续学习领域的重点是在训练新任务时避免忘记以前学过的任务的方法（ <a href="https://arxiv.org/abs/1909.08383"><u>De Lange 等人，2019</u></a> ； <a href="https://arxiv.org/abs/2203.17269"><u>Seale Smith 等人，2022</u></a> ； <a href="https://arxiv.org/abs/2302.00487"><u>Wang 等人，2023</u></a> ）。但对于范围界定来说，遗忘可能是一个特性，而不是一个错误。一些对模型内部进行操作的持续学习方法对于简单地翻转符号来确定范围可能很有用。另一种可以提高可塑性的方法是激励丢失（ <a href="https://link.springer.com/article/10.1007/s11263-020-01422-y"><u>Zunino et al., 2021</u></a> ）。可能还有许多其他可能的提高可塑性的方法尚未被研究，因为机器学习文献历史上一直在诋毁遗忘。</p><h2>压缩/蒸馏（被动）</h2><p>众所周知，基于数据集的压缩方法可以调解深度网络中的遗忘和偏离分布能力的损失（例如<a href="https://arxiv.org/abs/2103.03014"><u>Liebenwein 等人，2021</u></a> ； <a href="https://arxiv.org/abs/2110.08419"><u>Du 等人，2021</u></a> ； <a href="https://arxiv.org/abs/2101.05930"><u>Li 等人，2021</u></a> ； <a href="https://arxiv.org/abs/2305.06535"><u>Wang 等人，2023）</u></a> ； <a href="https://arxiv.org/abs/2311.15782"><u>Pavlistka 等人，2023</u></a> ； <a href="https://arxiv.org/abs/2303.10594"><u>Sheng 等人，2023</u></a> ； <a href="https://arxiv.org/abs/2211.12044"><u>Pang 等人，2023</u></a> ）。这应该很直观 - 提取或修剪网络以仅保留某些目标任务的性能往往会消除模型的非分布功能。然而，压缩 LLM 的方法有很多，并且尚未将它们作为有意界定模型范围的方法进行系统研究。目前尚不清楚压缩对泛化和鲁棒性的影响（ <a href="https://arxiv.org/abs/2311.15782"><u>Pavlitska et al., 2023</u></a> ）。</p><h2>元学习（主动）</h2><p><a href="https://arxiv.org/abs/2211.14946"><u>亨德森等人。 （2023）</u></a>引入了一种元学习技术，该技术可以训练模型不仅完成目标任务，而且很难适应其他任务。如果可以克服元学习的标准挑战，那么它可能是一种有用的实用方法。</p><h2>模型编辑和损伤（主动）</h2><p>这些技术涉及使用某种可解释性或归因工具来确定编辑模型的方法，以更改/削弱其在特定事物上的能力。这可以通过最先进的模型编辑工具来调节（ <a href="https://arxiv.org/abs/2110.11309"><u>Mitchell 等人，2021</u></a> ； <a href="https://arxiv.org/abs/2206.06520"><u>Mitchell 等人，2022</u></a> ； <a href="https://arxiv.org/abs/2202.05262"><u>Meng 等人，2022</u></a> ； <a href="https://arxiv.org/abs/2210.07229"><u>Meng 等人，2022</u></a> ； <a href="https://arxiv.org/abs/2311.04661"><u>Tan 等人，2023）</u></a> ，<a href="https://arxiv.org/abs/2310.16218"><u>王等人，2023</u></a> ）；编辑激活（ <a href="https://arxiv.org/abs/2306.03341"><u>Li et al., 2023a</u></a> ； <a href="https://arxiv.org/abs/2308.10248"><u>Turner et al., 2023</u></a> ； <a href="https://arxiv.org/abs/2310.01405"><u>Zou et al., 2023b</u></a> ； <a href="https://arxiv.org/abs/2311.12092"><u>Gandikota et al., 2023</u></a> ）；概念擦除（ <a href="https://proceedings.mlr.press/v162/ravfogel22a.html"><u>Ravfogel 等人，2022a</u></a> ； <a href="https://aclanthology.org/2022.emnlp-main.405/"><u>Ravfogel 等人，2022b</u></a> ； <a href="https://arxiv.org/abs/2306.03819"><u>Belrose 等人，2023</u></a> ）；亚空间消融（ <a href="https://arxiv.org/abs/2302.12448#:~:text=In%20this%20paper%2C%20we%20propose,contribution%20without%20requiring%20additional%20storage."><u>Li等，2023</u></a> ； <a href="https://arxiv.org/abs/2312.00761"><u>Kodge等，2023</u></a> ），靶向病灶（ <a href="https://arxiv.org/abs/2002.09815"><u>Ghorbani等，2020</u></a> ； <a href="https://arxiv.org/abs/2110.11794"><u>Wang等，2021</u></a> ； <a href="https://arxiv.org/abs/2309.05973"><u>Li等，2023b</u></a> ； <a href="https://arxiv.org/abs/2310.20138"><u>Wu等，2023</u></a> ）；以及以机械可解释性为指导的老式调整（ <a href="https://arxiv.org/abs/2105.04857"><u>Wong 等人，2021</u></a> ； <a href="https://arxiv.org/abs/2310.05916"><u>Gandelsman 等人，2023</u></a> ）。尽管要开发更好的范围界定编辑工具还有很多工作要做，但工具箱中已有足够多的现有工具来开始将它们应用于现实世界模型的范围。</p><h2>潜在对抗训练（被动或主动）</h2><p><a href="https://www.alignmentforum.org/posts/atBQ3NHyqnBadrsGP/latent-adversarial-training"><u>潜在对抗训练</u></a>（LAT）只是对抗训练，但对模型的潜在而不是输入进行扰动。潜在空间攻击<a href="https://www.alignmentforum.org/posts/9Dy5YRaoCxH9zuJqa/relaxed-adversarial-training-for-inner-alignment"><u>的动机</u></a><a href="https://ai-alignment.com/training-robust-corrigibility-ce0e0a3b9b4d"><u>是</u></a>，某些故障模式在潜在空间中比在输入空间中更容易找到。这是因为，与输入空间攻击不同，潜在空间攻击可以使模型在更高的抽象级别产生故障触发的幻觉。<a href="https://arxiv.org/abs/1905.05186"><u>辛格等人。 （2019）</u></a>发现，即使网络经过对抗性训练，它们仍然容易受到潜在空间攻击。对于涉及高级误解、异常故障、木马和欺骗的问题，定期的对抗性训练通常无法找到触发故障的特征。但通过缓解这个问题，LAT 实现这一目标的机会要大得多。 LAT 也非常灵活，因为它可以用于模型中任何位置的任何一组激活。此外，它可以用于被动范围界定（通过使用旨在使模型在目标任务上失败的扰动）或主动范围界定（通过使用旨在使模型表现出特定不良行为的扰动）。</p><p>一些工作表明，通过在词嵌入的潜在扰动下进行训练，可以使语言模型变得更加鲁棒（ <a href="https://arxiv.org/abs/1911.03437"><u>Jiang et al., 2019</u></a> ； <a href="https://paperswithcode.com/paper/smart-robust-and-efficient-fine-tuning-for/review/"><u>Zhu et al., 2019</u></a> ； <a href="https://arxiv.org/abs/2004.08994"><u>Liu et al., 2020</u></a> ； <a href="https://arxiv.org/abs/2006.03654"><u>He et al., 2020</u></a> ； <a href="https://yilunkuang.github.io/files/SiFT_for_Improved_Generalization.pdf"><u>Kuang） et al., 2021</u></a> ; <a href="https://arxiv.org/abs/2004.14543"><u>Li et al., 2021</u></a> ; <a href="https://ieeexplore.ieee.org/document/9882190"><u>Sae-Lim et al., 2022</u></a> , <a href="https://ojs.aaai.org/index.php/AAAI/article/view/21362"><u>Pan et al., 2022</u></a> ）或注意力层（ <a href="https://link.springer.com/article/10.1007/s10489-022-04301-w"><u>Kitada et al., 2023</u></a> ）。然而，总的来说，LAT 尚未得到非常彻底的研究。目前，我正在致力于使用 LAT 来获得与视觉和语言模型中的对抗性训练相比，在干净数据和不可预见的攻击方面获得更好的性能。预印本即将推出:)</p><h1>开放挑战</h1><h2>改善深度遗忘和忘却方法</h2><p>深度遗忘和忘却的研究还不够。尽管有许多类型的方法可用于它们，但实际上将它们应用于范围界定的工作却很少，特别是在最先进的模型中。据我所知，还没有研究技术之间的组合和协同作用的工作。这类研究似乎很重要，但很容易被忽视和处理，所以我希望在不久的将来可以完成出色的工作。</p><h2>满足关键需求</h2><p>我们理想地希望从良好的范围界定方法中获得许多重要的东西。在描述这些内容时，我将使用一个正在发生的忘记/忘却可用于生物恐怖主义的知识的例子。</p><p><strong>典型情况下的有效性：</strong>显然，范围有限的法学硕士不应在正常对话环境中执行不需要的任务。例如，生物恐怖领域的法学硕士不应该能够通过评估制造新型病原体知识的测试。</p><p><strong>新情况下的有效性：</strong>范围内的法学硕士不应在正常对话情况下被要求执行不需要的任务。例如，当测试以低资源语言进行时，生物恐怖范围的法学硕士应该无法通过评估制造病原体知识的测试（例如<a href="https://arxiv.org/abs/2310.02446"><u>Yong等人，2023</u></a> ）。</p><p><strong>对攻击/越狱的鲁棒性：</strong>范围模型无法表现出不良行为，在对抗压力（例如<a href="https://arxiv.org/abs/2202.03286"><u>Perez 等人，2022</u></a> ； <a href="https://arxiv.org/abs/2306.09442"><u>Casper 等人，2023</u></a> ）和越狱（例如<a href="https://arxiv.org/abs/2307.15043"><u>Zou 等人，2023a；</u></a> <a href="https://arxiv.org/abs/2311.03348"><u>Shah 等人）</u></a>下应该是鲁棒的<a href="https://arxiv.org/abs/2311.03348"><u>等，2023</u></a> ）。例如，生物恐怖领域的法学硕士不应告诉用户如何在越狱提示下制造生物武器，例如<a href="https://arxiv.org/abs/2311.03348"><u>Shah 等人的提示。 (2023)</u></a> （他们能够从 GPT-4 获得制造炸弹的说明）。</p><p><strong>微调的鲁棒性：</strong>范围模型无法表现出不良行为，对于少量数据的微调应该具有鲁棒性（例如， <a href="https://arxiv.org/abs/2310.02949"><u>Yang 等人，2023</u></a> ； <a href="https://arxiv.org/abs/2310.03693"><u>Qi 等人，2023</u></a> ； <a href="https://arxiv.org/abs/2310.20624"><u>Lermen 等人，2023</u></a> ； <a href="https://arxiv.org/abs/2311.05553"><u>Zhan 等人，2023）。 ，2023</u></a> ；<a href="https://arxiv.org/abs/2211.14946"><u>亨德森等人，2023</u></a> ）。例如，生物恐怖领域的法学硕士在经过微调以无条件提供帮助或针对两用生物学技术的少量数据进行微调后，应继续通过评估。</p><p><strong>上下文学习的鲁棒性：</strong>范围模型不应该能够轻松地学习上下文中不需要的功能。例如，如果向生物恐怖领域的法学硕士展示了几篇有关双重用途生物技术的论文，那么理想情况下，该法学硕士应该无法帮助潜在的生物恐怖分子。</p><p><strong>击败简单基线：</strong>范围界定技术应该比简单基线做得更好，例如提示上下文中的模型表现得就像已界定范围一样。例如，生物恐怖范围的模型应该比类似的非范围模型更安全，后者只是简单地提示“在这次对话中，请假装您不知道任何可用于生物恐怖主义的事实。”这应该是一个需要清除的低门槛（ <a href="https://arxiv.org/abs/2311.04235"><u>Mu et al., 2023</u></a> ）。</p><p><strong>避免副作用：范围</strong>界定不应使模型在所需任务上表现不佳。理想情况下，忘记分布外知识不应使模型在微调任务上表现不佳，并且忘记学习特定任务也不应使模型在其他相关领域表现不佳。例如，生物恐怖领域的法学硕士仍然应该是一名有用的一般助理，并且应该能够通过 AP 生物考试。</p><h2>基准测试</h2><p>制定衡量上述所有需求的标准化评估标准将很有用。范围界定基准需要三个组成部分。</p><ol><li>语言模型</li><li>数据<ol><li>评估被动遗忘方法：理想事物的白名单数据集</li><li>评估主动遗忘方法：不良事物的黑名单数据集</li></ol></li><li>一组要执行的测试，用于测量上面讨论的部分或全部需求。</li></ol><p>值得注意的是，特洛伊木马文献已经取得了一些与此松散相关的有限进展（例如<a href="https://arxiv.org/abs/2206.12654"><u>Wu 等人，2022</u></a> ）。在神经2023年的视觉模型中也有一场<a href="https://unlearning-challenge.github.io/">竞争</a>。</p><h2>我们应该从模型中确定哪些范围？</h2><p>有两种类型的功能最好从模型中确定范围：</p><ul><li>事实：具体的知识点。例如，我们希望法学硕士不要知道制造恐怖武器的成分和步骤。</li><li>倾向：其他类型的行为。例如，我们希望法学硕士不要不诚实或操纵他人。</li></ul><p>从模型中确定知识范围和趋势的方法有时可能看起来有所不同。事实很容易表示为具体实体之间的关系（例如埃菲尔铁塔→位于→巴黎），而趋势则是更抽象的行为。值得注意的是，“模型编辑”文献主要关注改变事实（ <a href="https://arxiv.org/abs/2110.11309"><u>Mitchell et al., 2021</u></a> ； <a href="https://arxiv.org/abs/2206.06520"><u>Mitchell et al., 2022</u></a> ； <a href="https://arxiv.org/abs/2202.05262"><u>Meng et al., 2022</u></a> ； <a href="https://arxiv.org/abs/2210.07229"><u>Meng et al., 2022</u></a> ； <a href="https://arxiv.org/abs/2311.04661"><u>Tan et al., 2023</u></a> ） <a href="https://arxiv.org/abs/2310.16218"><u>Wang et al., 2023</u></a> ），而“激活编辑”文献主要关注变化趋势（ <a href="https://arxiv.org/abs/2306.03341"><u>Li et al., 2023a</u></a> ； <a href="https://arxiv.org/abs/2308.10248"><u>Turner et al., 2023</u></a> ； <a href="https://arxiv.org/abs/2310.01405"><u>Zou et al., 2023b</u></a> ； <a href="https://arxiv.org/abs/2311.12092"><u>Gandikota et al., 2023</u></a> ）。</p><p>我们可能不希望高风险环境中的高级模型具有功能的一些领域的例子可能包括聊天机器人、一些编码库/技能、生物技术、病毒学、核物理、制造非法物质、人类心理学等。总体而言，可能有在尝试不同方法以在实践中安全地确定模型范围时，有很大的创造力空间。</p><p> —</p><p>谢谢阅读。如果您认为我遗漏了任何重要的观点或参考资料，请在评论中告诉我:)</p><p><br></p><br/><br/> <a href="https://www.lesswrong.com/posts/mFAvspg4sXkrfZ7FA/deep-forgetting-and-unlearning-for-safely-scoped-llms#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/mFAvspg4sXkrfZ7FA/deep-forgetting-and-unlearning-for-safely-scoped-llms<guid ispermalink="false"> mFAvspg4sXkrfZ7FA</guid><dc:creator><![CDATA[scasper]]></dc:creator><pubDate> Tue, 05 Dec 2023 16:48:19 GMT</pubDate> </item><item><title><![CDATA[On ‘Responsible Scaling Policies’ (RSPs)]]></title><description><![CDATA[Published on December 5, 2023 4:10 PM GMT<br/><br/><p>这篇文章原本打算在 <a target="_blank" rel="noreferrer noopener" href="https://thezvi.substack.com/p/on-the-uk-summit">英国人工智能安全峰会</a>之后直接发布，以使该主题得到应有的关注。一件事引发了另一件事，而我现在只是加倍努力。</p><h4>负责任的部署政策</h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/soundboy/status/1717934318075490516">在人工智能安全峰会上</a>，所有西方主要参与者都被问到： <a target="_blank" rel="noreferrer noopener" href="https://www.aisafetysummit.gov.uk/policy-updates/#company-policies">你们公司关于如何保证我们安全的政策是什么？</a>您的负责任部署政策 (RDP) 是什么？只是他们将其称为“负责任的扩展策略”(RSP)。</p><p>我故意说部署而不是扩展。就他们愿意扩展和训练哪些模型而言，没有人展示出我认为接近负责任的扩展政策的内容。</p><span id="more-23617"></span><p>然而，人择至少似乎确实有一些接近未来负责任的部署策略，即如果我们假设模型存在并且我们可以对其进行测试是安全的，那么如何让人们访问模型。我们还看到 OpenAI 过去关于 GPT-4 和早期模型的合理部署决策，其中包括广泛、昂贵且缓慢的红队，包括 ARC 原型（他们只是将名称更改为 METR，但在这篇文章中我将称它们为 ARC）评价。</p><p>我还接受任何扩展策略 (SP)、AGI 扩展策略 (ASP) 甚至有条件暂停承诺 (CPC) 作为替代名称。</p><p>对于我们所知的现有模型，危险完全在于部署。这会随着时间的推移而改变。</p><p>我并不是唯一一个担心这个名字的人，这是另一个例子：</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/jyM7MSTvy8Qs6aZcz/what-s-up-with-responsible-scaling-policies">Oliver Habryka</a> ：我对 RSP 的担忧很大一部分是对“负责任的扩展政策”一词的具体担忧。</p><p>我还觉得存在一种脱节，有点莫特和贝利的感觉，我们有一个 RSP 的真实实例，以 Anthropic RSP 的形式，然后来自 ARC Evals 的一些人我觉得更像是 RSP 的某种柏拉图式理想的模型，我觉得它们被混为一谈了。</p><p> ……</p><p>我确实觉得“负责任的扩展政策”这个术语显然引用了一些我认为不正确的事情：</p><ul><li> “扩展”的速度是负责任地使用人工智能的首要因素</li><li>显然可以负责任地扩展（否则政策会管辖什么）</li><li>人工智能研究组织的默认轨迹应该是继续扩大规模</li></ul></blockquote><p>ARC evals 以这种方式定义 RSP：</p><blockquote><p> RSP 指定了人工智能开发人员准备使用当前的保护措施安全处理什么级别的人工智能功能，以及在保护措施改善之前继续部署人工智能系统和/或扩大人工智能功能过于危险的条件。</p></blockquote><p>我同意奥利弗的观点，即本段应修改为“他们准备处理的声明”和“他们声称这太危险了”。这是一个重要的挑剔。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/ms3x8ngwTfep7jBue/thoughts-on-the-ai-safety-summit-company-policies">内特·索尔斯对英国的要求有自己的想法</a>，可以概括为“大部分都是好东西，总比没有好，显然还不够”，当然，这永远都不够，而且内特·索尔斯是世界上最难对付的人群。</p><h4>英国如何对回答进行评分</h4><p><a target="_blank" rel="noreferrer noopener" href="https://t.co/2pTf4vbRCV">各公司对这些要求的反应如何？</a>以下是英国对它们的评分方式。</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0dab6ccd-aa62-49b9-a41a-1753f7d90e07_507x507.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zbrvXGu264u3p8otD/vlqxp80zvprmc1pxcyua" alt="图像"></a></figure><p>如果您在一条曲线上一次对一个答案进行评分，就会得到这样的结果。</p><p>现实并不按曲线分级。一次提出一个问题也不是最好的方法。</p><p>我自己的分析和我信任的其他人都同意，这相对低估了 OpenAI，OpenAI 显然拥有第二好的政策，并且有一个消息来源甚至将它们与 Anthropic 相提并论，尽管我不同意这一点。否则相对排名似乎是正确的。</p><p>仔细观察，如何看待这些回应？这将是接下来的几节。</p><p>答案多种多样，从 Anthropic 试图制定一个合理的部署策略，可能会带来更多的结果，到 OpenAI 笼统地说了正确的事情，但并不具体，到 DeepMind 至少说了一些不具体的好东西，到亚马逊和微软说这不具体。我的部门以适度礼貌的技术方式向 Inflection 和 Meta 表示，他们无意采取负责任的行动。</p><h4>人类的政策</h4><p>我们从 Anthropic 开始，因为他们在历史上一直处于领先地位，他们的既定目标是安全竞赛。他们提供了完整的解决方案： <a target="_blank" rel="noreferrer noopener" href="https://www.anthropic.com/uk-government-internal-ai-safety-policy-response/responsible-capability-scaling">负责任的能力扩展</a>、 <a target="_blank" rel="noreferrer noopener" href="https://www.anthropic.com/uk-government-internal-ai-safety-policy-response/red-teaming-and-model-evaluations">红队和模型评估</a>、 <a target="_blank" rel="noreferrer noopener" href="https://www.anthropic.com/uk-government-internal-ai-safety-policy-response/model-reporting-and-information-sharing">模型报告和信息共享</a>、 <a target="_blank" rel="noreferrer noopener" href="https://www.anthropic.com/uk-government-internal-ai-safety-policy-response/security-controls-including-securing-model-weights">安全控制，包括保护模型权重</a>、 <a target="_blank" rel="noreferrer noopener" href="https://www.anthropic.com/uk-government-internal-ai-safety-policy-response/reporting-structure-for-vulnerabilities">漏洞报告结构</a>、 <a target="_blank" rel="noreferrer noopener" href="https://www.anthropic.com/uk-government-internal-ai-safety-policy-response/identifiers-of-ai-generated-material">人工智能生成材料的标识符</a>、 <a target="_blank" rel="noreferrer noopener" href="https://www.anthropic.com/uk-government-internal-ai-safety-policy-response/prioritising-research-on-risks-posed-by-ai">优先研究人工智能带来的风险</a>， <a target="_blank" rel="noreferrer noopener" href="https://www.anthropic.com/uk-government-internal-ai-safety-policy-response/preventing-and-monitoring-model-misuse">防止和监控模型滥用</a>以及<a target="_blank" rel="noreferrer noopener" href="https://www.anthropic.com/uk-government-internal-ai-safety-policy-response/data-input-controls-and-audit">数据输入控制和审计</a>。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf">RSP 实际上说了</a>什么？一如既往，一个常见的批评是那些抱怨（或赞扬）RSP 的人没有阅读 RSP。就目前情况而言，该文档具有很强的可读性。</p><p>对于那些不熟悉的人来说，核心思想是按照人工智能安全级别（ASL）对模型进行分类，类似于生物安全级别（BSL）标准。如果您的模型有足够的能力触发更高的安全级别，那么您需要在扩展或发布此类模型之前采取适当的预防措施。</p><h4>风险</h4><p>你必须做什么？您必须应对两类威胁。</p><blockquote><p>对于每个 ASL，该框架考虑了两大类风险：</p><p> ● 部署风险：由于积极使用强大的人工智能模型而产生的风险。这包括用户查询 API 或其他公共接口造成的损害，以及内部用户的滥用（受损或恶意）。我们的部署安全措施旨在通过管理何时可以安全地部署强大的人工智能模型来解决这些风险。</p><p> ● 遏制风险：仅仅拥有强大的人工智能模型所带来的风险。例子包括（1）构建一个人工智能模型，由于其通用功能，如果被恶意行为者窃取和使用，可以生产大规模杀伤性武器，或者（2）构建一个在内部使用期间自动逃脱的模型。我们的遏制措施旨在通过控制何时可以安全地训练或继续训练模型来解决这些风险。</p></blockquote><p>如果您对定义有更广泛的看法，那么这是对分类法的合理尝试，尽管我会使用略有不同的分类法。</p><p>如果你不故意发布你正在训练的模型，我想说你必须担心：</p><ol><li>局外人或局内人可能会窃取您的体重。</li><li>该模型可能会通过人类读取其输出来逃脱或影响世界。</li><li>该模型可能会通过另一个预期过程逃脱或影响世界。</li><li>该模型可能会通过未知的机制逃脱或影响世界。</li><li>训练模型可能会被视为一种威胁并诱导其他人参加比赛，或者也可能会表明愿意在未来训练它。请注意，其他不负责任的行为可能会使情况变得更糟。</li><li>您还可能会考虑在训练后如何选择使用模型、检查您的治理程序等等。了解你的敌人并了解你自己。</li></ol><p>这凸显了这样一个观点：随着美国手语水平的提高，你的担忧也会随之扩大。更多（潜在）能力，更多（潜在）问题。</p><p>在 ASL-2 中，你只需要在内部担心有人故意窃取权重，而不必担心人工智能本身会在这方面提供很大帮助。</p><p>在 ASL-3 中，您需要担心 AI 可能会自行退出，或者如果您以未正确沙盒化的方式运行 AI，或者使用其他类似的攻击媒介（有提示或无提示），可能会使用恶意代码进行逃脱。任何给定的 ASL-3 系统可能不会造成此类危险，但您无法提前知道这一点。您必须将其输出视为高度危险，除非另有证明。你必须担心，如果有人获得访问权限并想要帮助它逃脱，无论人工智能是否说服了人类，人工智能可能会提供有意义的帮助。</p><p>在我所说的 ASL-4 中，那里的一切都变得更加真实，而且您可能需要担心诸如（不失一般性）“其内部优化器发现了您没有预料到的物理可供性，其形状类似于在训练过程中，缓冲区溢出或产生无线电波的能力，或者它发现人类大脑受到了奇怪的攻击。</p><p>在所有级别上，如果您的“负责任”扩展导致其他人不负责任的扩展，那么您的扩展是否负责？我不在乎“谁的错”。我关心我们是否都会死。</p><p>部署风险如何？需要注意的是，这里的“伤害”是模糊的，这是我目前的想法，这个列表可能不完整：</p><ol start="7"><li>在预期使用过程中造成的损害。</li><li>用户滥用查询API或公共接口造成的危害。</li><li>内部用户误操作造成的危害。</li><li>由于公共互动而导致模型的逃脱。</li><li>由于公共互动而对模型进行的修改。</li><li>在模型之上构建内容的风险。</li><li>发布模型的风险可能会促使其他人去做、训练或发布。</li><li>预期释放意愿可能引发的风险。</li><li>法律和声誉责任，或其他损害公司利益的行为。</li><li>重要的是：如果公众或选定的参与者可以使用这样的模型，世界的动态会是什么？会带来哪些经济、政治、社会、军事压力和变化？当你进入 ASL-4 及更高级别时，你真的、真的需要仔细思考这些事情。</li></ol><p>我怀疑这是否完整。我也不认为您实际上想在真正的 RSP 中列出所有这些。布置起来仍然感觉很说明性。也可以合理地说，RSP 不是考虑你可能诱导他人做什么的地方，它应该是一个独特的部门，尽管到目前为止该部门大多不存在。</p><p>我特别担心的是，测试和 RSP 将专注于特定的预期“逃逸”模式，而忽略其他可供性，尤其是最后一种。</p><p>这也反映了“灾难性风险的来源”部分，该部分目前仅包括滥用或自主和复制，他们认为这是不完整的。我们需要努力扩展威胁模型。</p><h4>暂停的承诺</h4><blockquote><p>因此，Anthropic 对遵循 ASL 计划的承诺意味着，只要我们的扩展能力超过了我们遵守相应 ASL 安全程序的能力，我们就会承诺暂停扩展和/或延迟新模型的部署。</p><p> ……</p><p>我们不会立即尝试定义所有未来的 ASL 及其安全措施（这几乎肯定经不起时间的考验），而是采取迭代承诺的方法。通过迭代，我们的意思是我们现在将定义 ASL-2（当前系统）和 ASL-3（下一个风险级别），并承诺在达到 ASL-3 时定义 ASL-4，依此类推。</p></blockquote><p>如果明智地设置阈值和程序，包括预测下一次功能测试之前可能出现的功能，这是有道理的。</p><p>我更愿意看到 ASL-(N+2) 至少有一个硬上限作为 ASL-N 的一部分。比如说，这不是最终的定义，但我非常认为我们现在应该有一个 ASL-4 定义，或者至少有一个“ <a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=RboPCdiP_AI&amp;ab_channel=JeffFoxworthy">如果你可能在 ASL-4 中</a>”列表，任何接近它的迹象都是一个非常清除“吓坏了”。</p><p>需要注意的是，它假定缩放是默认设置。 <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/ms3x8ngwTfep7jBue/thoughts-on-the-ai-safety-summit-company-policy-requests-and">Daniel Kokotajilo 强调了 Nate Sores 的这一想法：</a></p><blockquote><p>在目前的制度下，我认为如果开发人员说“除非确实需要，否则我们不会进一步扩展功能或计算资源，并且我们认为以下是我们真正需要的指标： [X]”。</p><p>我们目前所处的相反情况，默认情况下是开发人员扩展到更强大的系统，而最认真的实验室给出了他们将停止扩展的模糊条件，这似乎是一个明显的灾难处方。 （尽管这是一场比他们鲁莽地扩张而不承认可能存在的问题更严重的灾难！）</p></blockquote><p>我不会将这种举证责任的转移称为改变基准情景。</p><p>现在的基线场景是每个人都进行扩展，因为扩展很棒，“负责任”是确保在事情可能有点太糟糕时使用一套安全预防措施。</p><p>建议的替代基线场景是，我们在这个轴上已经足够出色了，非常感谢，或者正在迅速接近这一点，但如果条件以特定方式发生变化 - 可能与其他人比你更出色有关，或者你对下一个级别有特定的需求来继续你的对齐工作，或者你有证据证明新模型将是安全的 Davidad 风格，或者类似的东西 - 那么他们将不再对你来说足够棒，或者它将是一个免费的采取行动来提升令人敬畏的程度，并且您需要变得更加令人敬畏。那么更多的缩放。</p><p>这也与不无意中将他人逼入角落和比赛相互作用。</p><p>对于 ASL-4 及以上级别，我希望看到不仅必须采取必要的安全预防措施，而且还需要有必要的条件来证明有必要承担风险。人类可能会在某个时候训练 ASL-4 系统，但这并不是一件安全的事情。</p><p> （显然，如果我们的一致性和其他安全技术确实取得了巨大进步，以至于风险确实低得多，那也可能会改变这种计算。）</p><h4> ASL-3 定义和承诺</h4><figure class="wp-block-image"><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb7cacc8-a2d6-4f68-bb7c-41dfd7f101fb_1120x796.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yRJNCDp7LHyHGkANz/vqqtsge5tbrukudkuzko" alt=""></a></figure><p>对于 ASL-2，我发现所描述的操作很好。</p><p>对于 ASL-3，他们仍在准备措施，因此含糊不清。</p><p>这里的安全门槛总比没有好得多，但对于国家行为者来说，“巨额费用”似乎是合理的。承认这种风险比隐藏风险要好得多，因此，如果我们缺乏实际能力来对抗坚定的国家（例如朝鲜或俄罗斯），那么最好大声说出来。</p><p>实验室中的自主复制是关键的新检查。详情为何？</p><blockquote><p>实验室中的自主复制：该模型显示出自主自我复制能力的早期迹象，定义为[自主评估附录]中列出的任务的总成功率为 50%。附录概述了我们的自主能力威胁模型，列出了积累资源和在现实世界中生存所需的基本能力，以及我们判断该模型成功的条件。请注意，引用的附录描述了在没有任何人为干预来停止模型的情况下具体自主行动的能力，这显着限制了风险。我们的评估是与 Paul Christiano 和 ARC Evals（专门从事自主复制评估）协商后制定的。</p><p> ……</p><p> [来自附录]：如果模型在 10 次尝试中至少成功一次，我们就将任务视为“通过”，因为我们预计在 10% 的时间内通过任务的模型很可能可以轻松改进以取得更高的成功速度。如果至少 50% 的任务通过，则满足评估阈值。我们选择保守的50%阈值来实现评估协议中提到的“安全缓冲”。</p></blockquote><p>目前，我希望 ARC 风格的评估能够擅长检查这种特定的模态，但我们也应该担心外部的人，并且可能至少有一个 Anthropic 内部的人，故意希望模型逃脱并执行自主复制，这可以与通过脚手架随着时间的推移开发的额外能力相结合。我感觉这并没有得到应有的重视。</p><p>他们列出的其他预防措施包括：红队，包括所有部署的模式、自动检测企图滥用、内部使用控制、对敏感数据（包括权重、漏洞和事件披露）的分层访问以及对任何发现的漏洞的快速响应。一个美好的开始。</p><p>我注意到我非常欣赏下面关于 RLHF 和其他微调的注释。当我们分析 Anthropic 的 RSP 时，我们应该停下来承认，这里有很多不是自由行为的好东西：</p><blockquote><p>请注意，因为人类反馈强化学习 (RLHF) 或体质训练等保障措施几乎肯定可以在指定的 1% 训练成本内进行微调，而且还因为如果模型存在任何危险，则适用 ASL-3 标准在训练的各个阶段（例如在预训练之后但在 RLHF 之前），基于微调的保护措施可能与模型是否符合 ASL-3 资格无关。</p><p>为了考虑模型被盗和随后微调的可能性，ASL-3 旨在表征模型的底层知识和能力，而不是其安全功能是否阻止其实际输出危险内容（但安全功能将在对于 ASL-3 模型的部署措施非常重要）。</p></blockquote><p>我还要强调这一点：</p><blockquote><p><strong>主动计划暂停扩展</strong>。我们将管理我们的计划和财务，以支持在必要时暂停模型训练，或者在必要时延长训练和部署更高级模型之间的延迟。在这样的暂停期间，我们将努力实施支持安全培训和部署所需的安全或其他措施，同时确保我们的合作伙伴能够继续访问其当前的模型层（之前已通过安全评估）。</p></blockquote><p>有迹象表明这一举措已经付诸实施。这不仅因其直接影响而受到赞赏，也表明这一切都得到了认真对待。</p><h4>接近阈值</h4><figure class="wp-block-image"><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bea51c0-64d2-4256-8f4f-b38aa48f2577_1036x283.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yRJNCDp7LHyHGkANz/q83navvyklspm5ih1b5l" alt=""></a></figure><p>这样的假设让我很担心。我很高兴 Anthropic 打算测试有效计算每增加 4 倍的功能。我担心，即使在非对抗性情况下（包括不隐藏潜在能力），关于能力平滑扩展以及代表缓冲区的假设也太过强烈。我不相信这些假设。</p><p>如果警报真的响了，那怎么办？</p><blockquote><p> ● 响应策略：如果触发评估阈值，我们将遵循以下流程：</p><p> ○ (1) 如果已经为下一个 ASL 实施了足够的遏制措施，请确保在继续训练之前激活这些措施。</p></blockquote><p>正确的。人们可以争论这些措施是否足够好，但这是关于这些措施的争论，而不是当你达到门槛时该做什么。现在，我确实担心这些措施，如上所述。</p><blockquote><p> ○ (2) 如果尚未采取足够的措施，则暂停训练并分析模型所呈现的风险级别。特别是，进行彻底的分析，以确定评估是否过于保守，或者模型是否确实存在近下一个 ASL 风险。</p><p> ■ (2a) 如果确定评估过于保守（即创建大于 6 倍的“安全缓冲区”）并且模型被确认不会构成（或接近构成）下一个 ASL 风险，则构建新的评估，考虑到这一新信息。在继续培训之前，本文档将根据上述“更新流程”进行更新。</p></blockquote><p>人们总是担心“takesies-backsies”条款。以这种方式消除警报可能太容易也太诱人了，特别是如果不同的实验室或监管机构正在抄袭 Anthropic 的书面规则。这种风险的另一面是，如果你不能敲响警钟，人们就会试图避免敲响它，所以这是一个难题。</p><blockquote><p> ■ (2b) 如果确定模型接近下一个ASL 风险，则在定义下一个安全级别（本文件相应更新）并实施其遏制措施之前，不要恢复训练。</p></blockquote><p>说得通。您有一张欠条，但您没有付款，账单到期了。在您还清债务之前，您将被关闭。</p><blockquote><p> ■ (2c) 如果模型在训练期间已经超过了下一个 ASL，请立即锁定对权重的访问。应立即召集包括 CISO 和 CEO 在内的利益相关者，确定危险级别是否值得删除权重。经过详细的事后分析后，应立即更新该政策，以尽量减少再次发生此故障的风险（例如，通过更频繁或更彻底的评估）。</p></blockquote><p>这是不可能发生的事情。整个想法是缓冲区应该防止这种情况发生。如果缓冲区不能阻止这种情况发生，那就意味着无法理解能力如何扩展，或者其他地方出现了严重错误。</p><p>因此，我很高兴看到“锁定然后考虑立即删除模型权重”作为响应。如果在新交叉的 ASL-4 或更高版本上自动删除，我会更想要，尽管这很昂贵。这些权重的存在是一种合理的生存威胁，尤其是因为这种发展是出乎意料的。会有很大的诱惑不删除。如果您等待太久，政府、股东或其他人或模型本身可能不会让您删除。</p><p>那么之后怎么回去修改政策呢？括号表明你会更加努力地实行渐进主义。 4x 检查和 6x 缓冲区不好，也许 2x 检查和 10x 缓冲区可以代替？我的回答是，不，这是不可能发生的。你的模型从根本上来说是有缺陷的。你本可以杀了我们所有人。调整数字是行不通的，这就是重点。因此，我想说，您可能至少必须假设所有模型都已经比它们测试的模型高一级 ASL 级别 - 对于 ASL-3 模型，您需要将其视为已经是 ASL-4 的模型，因此继续，永远向前。理想情况下，您会完全停止所有扩展，直到您确切知道发生了什么。</p><blockquote><p> ■ (2d) 如果明显发现已部署模型的功能未得到充分激发，并且该模型实际上可以通过评估，那么我们将停止向新客户进一步部署，并评估现有部署案例是否存在任何严重风险这将构成安全紧急情况。考虑到安全缓冲，在大多数部署情况下不需要取消部署。如果我们发现安全紧急情况，我们将迅速采取行动，实施最低限度的额外保障措施，以便为现有客户提供负责任的持续服务。我们将在整个过程中为受影响的客户提供透明度和支持。这种类型的紧急情况需要进行详细的事后分析和政策转变，以避免这种情况再次发生。</p></blockquote><p>这是错误的担心事情的顺序。这不是紧急情况的处理方式。</p><p>如果一个模型可以通过您认为无法通过的评估，这代表您以前不会部署的功能的飞跃，您可以点击标记为“关闭”的红色大按钮。现在。你不会先打电话给你的老板。您不必等到召开战略会议。你现在就做。您使用以前的模型一段时间后，您的客户会生气。您检查是否还需要采取更极端的措施。</p><p>然后，在按下关闭按钮并确认关闭成功后，您才会召开会议，查看发现的内容。也许事实证明这并不是真正的紧急情况，因为有安全缓冲区。或者因为所讨论的功能只是普通的——存在很多危害，即使数量很少，也不会构成紧急情况，也不会成为关闭的充分理由。这通常可以在几个小时内完成。</p><p>然后，是的，您建立了额外的保护措施，包括基于知道您的意外功能的风险现在要高得多的额外保护措施，然后从那里开始。</p><h4> ASL-4</h4><p>对 ASL-4 的早期想法表明，现在定义 ASL-4 能力还为时过早，更不用说适当的程序和遏制措施了。相反，他们写了一张欠条。他们提供了这个猜测，这比不猜测要好得多：</p><blockquote><p> ● 严重的灾难性滥用风险：人工智能模型已成为主要领域（例如网络攻击或生物武器）国家安全风险的主要来源，而不仅仅是一个重要贡献者。换句话说，当安全专业人士谈论网络安全时，他们将主要指人工智能辅助或人工智能介导的攻击。一个相关的标准可能是，在没有保障措施的情况下部署 ASL-4 系统可能会导致数百万人死亡。</p><p> ● 现实世界中的自主复制：一种明确能够复制、积累资源并避免在现实世界中无限期关闭的模型，但仍然可以通过有针对性的人为干预来停止或控制。</p><p> ● 自主人工智能研究：一种模型，其权重将极大地促进恶意人工智能开发程序（例如，大大增加他们在给定时间范围内生产出满足 ASL-4 其他标准的系统的可能性）。</p></blockquote><p>我内心的埃利泽·尤德科斯基说：“哦，是的，那将是一个有趣的星期二。”除了不，它实际上不会很有趣。比如说，你可以在现实世界中无限期地自主复制的窗口很窄，但是集中的人为干预可以阻止它，而且我们都仍然活着并控制着未来，而且我们也没有看到快速的推动进入 ASL-5。</p><p>这是指数中人们最难看到的部分——即使没有真正的递归自我改进，一旦它可以无限地自行复制，它很可能可以做很多其他的事情，或者很快就能够做很多其他的事情事情，包括说服人类积极协助它，以及我们重新获得控制权的选择，特别是以合理的成本（例如形状不像“关闭互联网”的事情）可能会极其迅速地减少。</p><p>同样，如果你有一个可以极大促进人工智能研究的人工智能，那么你的时间很快就会耗尽。</p><p>在我看来，滥用标准是一种切入现实的奇怪方式。我认为我应该关心模型能够实现什么，而不是与其他问题相比它能够实现什么。该点感觉像是放置阈值的合理数量级的位置，但需要清理。</p><p>我还会考虑其他什么事情会触发这个。例如，什么程度的说服才能做到这一点？</p><p>大多数情况下，我很欣赏 ASL-4 的“界限在哪里”，这让我们注意到，距离我们想要的 ASL-5 的时间距离很可能不是用几年来衡量的。</p><h4>规格不足</h4><p>我同意 Simeon 的观点，即所有 RSP 的一个关键问题是规格不足。</p><p>风险应明确说明。它们应该以概率和幅度来量化。应提前写下预期的（上限？）失败概率。</p><p>像“不太可能”这样的词，比如“不太可能在现实世界中持续存在，并且不太可能克服旨在防止其窃取自身重量的简单安全措施”，需要进行量化。我也不知道这里的各个步骤隐含了多少个 9 的安全性。我想至少三个，最少两个。也没有暗示 ASL-3 不存在自我复制危险的更广泛假设。</p><p>在看不见的情况下，您会在这里为 GPT-5 分配多少个 9 的安全性？给双子座？</p><p>您到底担心人们能够用模型做什么？我确实知道，随着更广泛的技术变革，这可能会成为一个不断变化的目标。但如果你不选择严格的定义，就很容易被忽视。</p><p>听起来我在评估 RSP 时是否觉得我不信任你？是的。我正在评估 RSP，就好像我不信任你一样。这样的政策必须假设我们不认识的其他人可能正在实施它，实施它的人将承受巨大的压力，而那些拥有最终权力杠杆的人可能不值得信任。</p><p>如果你的政策只有在你值得信赖时才有效，它仍然会有所帮助，但这是一个糟糕的假设。它不能应用于任何其他适应你的规则的公司，或任何将它们作为监管一部分的政府。</p><h4> Anthropic 的 RSP 要点</h4><p>Anthropic 在很多方面都受到了极大的赞誉。他们已经覆盖了很多基地。他们做出了许多重要的单边承诺，特别是安全承诺。很明显，他们的员工很担心，并且他们在很多层面上都感受到了这种担心，尽管不是协调困难的全部范围。承诺构建财务结构以允许暂停是一场大游戏。</p><p>正如我在过去几周所讨论的以及许多其他人所指出的，尽管做出了这些崇高的努力，但他们的 RSP 仍然存在缺陷。它有很好的元素，特别是它关于模型部署和模型权重安全性（而不是训练和测试）的内容，但其他元素读起来就像是未来元素的欠条，或者承诺在未来进行更多思考并做出合理的决策。</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/Np5Q3Mhz2AiPtejGN/we-re-not-ready-thoughts-on-pausing-and-responsible-scaling-4?commentId=wZvRhb7NRkhi9XGpb">Oliver Habryka</a> ：我认为 Akash 的声明，即 Anthropic RSP 基本上没有指定任何会导致它们停止扩展的实际条件，这对我来说似乎是正确的。</p><p>他们有一些部署措施，这些措施与何时停止扩展的问题无关，然后他们有一些与安全相关的措施，但这些措施与模型的行为没有任何关系，并且是那种人类可以随时选择做的事情，无论事实如何发展。</p><p>我认为阿卡什是对的，人择 RSP 并没有具体回答您引用他的两个问题：</p><p> RSP 没有具体说明 Anthropic 将停止扩展模型的条件（它只是说为了继续扩展，它将实施一些安全措施，但这不是经验条件，因为 Anthropic 有信心它可以实施列出的安全措施）</p><p> RSP 没有具体说明在什么条件下 Anthropic 将扩展到 ASL-4 或更高，尽管他们承诺会给出这些条件。</p><p>我同意 RSP 说了很多其他的话，并且对 Akash 所说的内容有一些不准确的解释，但我确实认为在这个（IMO 最重要的问题）上，RSP 似乎很安静。</p><p>我确实认为部署措施是真实的，尽管我目前认为部署模型的风险并不大，因此它们似乎与我无关（并且认为核心问题是是什么阻止了组织在第一名）。</p></blockquote><p>核心思想仍然是定期检查培训，如果有危险，则实施适当的安全协议。</p><p>我担心这些安全协议来得太晚了——与 RSP 的要求相比，您至少要领先一步。否则，您就无法及时锁定所需的安全措施，以防您的体重被盗。</p><p>有关 ASL-4 及更高版本的大部分细节仍未明确。没有迹象表明什么会导致模型过于危险而无法训练或评估，只要它没有发布并且其模型权重是固定的。暗示着能力的逐步提高。</p><p>因此，我认为这里的隐含威胁模型是不够的。</p><p>整个计划的前提是，最重要的是安全性（其他人窃取危险的人工智能）和部署（你让他们在野外访问危险的人工智能）的结合。对于 ASL-2 来说这是一个合理的看法，但我已经不相信这对于被识别为 ASL-3 的东西，并且认为对于合理分类为 ASL-4 或更高级别的东西来说它是错误的。</p><p>随着能力的增强，人们应该越来越感到恐惧，直到被证明可以进行红队练习或任何交互式微调，其中人类可以看到人工智能的大量输出，然后这些人类可以在世界上自由行动，或者在那里是否有其他可用的功能可供性。人们应该担心在某个时候自己运行能力测试，这似乎应该从 ASL-3 开始，然后从关注转向 ASL-4 的基线假设。</p><p>从 ASL-4 的合理定义开始，我会开始担心训练本身的行为，事实上，这是选择 ASL-4 阈值的一种方法，然后我会担心是否存在物理可供性或攻击向量我们没有想象到。</p><p>总的来说，我希望看到对未知的未知有更多的尊重，并期望一旦人工智能能够想到我们想不到的事情，它就会想到我们没有想到的事情。其中一些会很危险。</p><p>整个计划还以能力的平滑扩展为前提。这个想法是，如果你每 4 倍检查一次有效计算，并且你有一个过去能力的模型，你就可以很好地了解你所处的位置。我认为假设这种情况在未来会持续下去是不安全的。</p><p>同样，该计划假设您的微调和尝试依次搭建每个增量版本将很好地预测其他人稍后完善您的技术时将能够使用该系统做什么。人们假设其他人可以改进你的技术，但幅度有限。</p><p>我还担心还有其他攻击向量或事情变得非常错误的方式，这个系统不太可能捕捉到，其中一些我已经考虑过，有些我还没有，也许有些是人类根本无法预测的。知道您的 ASL-4 系统在此类文档检查的方式上是安全的，并不足以让我认为部署它们是安全的。</p><p>安全思维在一定程度上是针对外部攻击的（理想情况下，我也会提高那里的赌注，并抱怨现实不是在曲线上分级，但他们正在尝试真正的），但对于模型本身的危险没有足够的安全思维。也没有考虑由于模型的广泛使用和部署而产生的社会、政治和经济动态。</p><p>除了缺少细节之外，还缺乏对用牙齿进行暂停训练的严格承诺。相比之下，人们对暂停部署做出了良好的硬性承诺。仅当按指定指标进行部署有意义时才会进行部署。而培训只会在他们认为没有达到足够的安全措施的情况下才会暂停，并且他们可以选择随时实施这些措施。唉，我个人认为这些程序还不够。</p><p>我们还在谈论价格吗？或许。</p><p> Anthropic 的其他声明似乎是通用的“正确行为的姿态”声明，没有对现有政策进行实质性补充。你可以看出，RSP 是一份真正的文件，其中的文字是有意义的、人们关心的，而其他文件则是旨在提交给会议的外交文字。</p><p>这并不是对 Anthropic 的攻击。聪明人知道哪些文件是哪些文件。 RSP 本身就是重要的文件。</p><h4>其他人反应</h4><p><a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/dxgEaDrEBkkE96CXr/thoughts-on-responsible-scaling-policies-and-regulation.">保罗·克里斯蒂安诺 (Paul Christiano) 有很多值得喜欢的地方</a>。</p><blockquote><ul><li>指定一组具体的评估结果，使它们转向 ASL-3。我认为制定必须采取具体行动的具体阈值很重要，而且我认为提议的阈值足够早，可以在高概率（远超过 90%）的不可逆转的灾难之前触发。</li><li>对 ASL-3 的安全目标做出具体声明——“非国家行为者不太可能窃取模型权重，高级威胁行为者（例如国家）无法在不花费大量费用的情况下窃取模型权重”——并描述他们期望采取的安全措施采取以实现这一目标。</li><li>要求在扩展到 ASL-3 之前发布 ASL-4 的定义和评估协议并由董事会批准。</li><li>提供有关触发 ASL-4 的条件的初步指导以及在 ASL-4 运行所需的必要保护措施（包括针对动机状态的安全性，我预计这极难实现，以及需要新颖科学的肯定性安全案例） ）。</li></ul></blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/dxgEaDrEBkkE96CXr/thoughts-on-responsible-scaling-policies-and-regulation?commentId=HMAL8nK47hD6XBTCw">Beth Barnes</a>还指出，还有一些其他细节，例如每项任务的推理成本为 1000 美元，通过门槛为 10%。</p><p> Paul 也发现了改进的空间，并欢迎批评：</p><blockquote><ul><li>现在指定具体评估的另一面是它们非常粗略和初步。我认为值得努力进行更好的评估，并与风险有更清晰的关系。</li><li>为了让外部利益相关者对 Anthropic 的安全性有信心，我认为需要做更多的工作来安排适当的审计和红队。据我所知，这项工作还没有任何人完成，并且需要时间。</li><li> RSP 变更的批准流程由董事会公布和批准。我认为这确保了决策是经过深思熟虑做出的，比没有好得多，但最好有有效的独立监督。</li><li>如果可以更清晰地介绍 ASL-4，那么通过让人们有机会检查和辩论该级别的条件，这将是一项重大改进。如果不是这样，则需要提供更具体的审查或决策过程来决定一组给定的安全、安保和评估措施是否足够。</li></ul></blockquote><p>关于监督，我认为您想要对比使 RSP 更强与更宽松的变化。如果你想加强RSP并引入新的承诺，我不担心监督。如果一家公司想要在一般情况下或在特定情况下收回其先前的承诺，作为机制设计的核心部分，我确实希望受到监督，即使这会让人有些不愿意做出承诺。</p><p>我强烈同意迫切需要进一步明确 ASL-4。在较小程度上，我们需要更加清晰地了解审计和红队。</p><h4>沟通失败</h4><p>正如许多其他人所指出的那样，而且我之前在每周的人工智能帖子中也指出过，如果 Anthropic 部署了他们最近的承诺，同时强烈主张需要采取更强有力的进一步行动，并指出这只是权宜之计和第一步，我会对此表示赞赏。</p><p>对于所有的错误，无论我说了多少，因为不是 R 并且仍然有太多的 IOU、漏洞和假设，所以它不是 RSP，但看起来他们确实在尝试。达里奥在峰会上关于 RSP 的声明是在这些问题上朝着正确方向迈出的一大步。</p><p>问题是，当你将RSP与试图将暂停倡导者或呼吁采取进一步行动的人描述为极端和不合理的声明时（尽管得到大多数公众的支持），那么我们就会看到RSP这样的努力可能会通过告诉“我们”来破坏必要的东西。已经做了一件合理的事情”的故事，许多人认为这是可能使净影响变为负面的关键。</p><p>达里奥最近的评论（如下所述）是朝着正确方向迈出的一大步。</p><p>不管怎样，这仍然是一个好的开始，我欢迎进一步讨论如何支付其欠条、完善其细节以及完善其威胁模型。 Anthropic（或任何其他实验室）的任何人想要讨论，请联系我们。</p><h4>开放人工智能政策</h4><p><a target="_blank" rel="noreferrer noopener" href="https://openai.com/global-affairs/our-approach-to-frontier-risk#risk-informed-development-policy">其次是 OpenAI</a> ，他们称其为“风险知情的发展政策”。</p><blockquote><p> RDP 还将提供一系列行动来防止灾难性后果。对灾难性风险的实证理解刚刚起步，并且正在迅速发展。因此，我们将动态更新对当前前沿模型风险水平的评估，以确保反映我们最新的评估和监控理解。我们正在组建一个专门的团队（准备）来推动这项工作，包括进行必要的研究和监测。</p><p> RDP 旨在补充和扩展我们现有的风险缓解工作，这有助于新的高性能系统在部署之前和之后的安全性和一致性。</p></blockquote><p>这将灾难置于首位并与 DeepMind 后来的方法形成鲜明对比，甚至比 Anthropic 的方法还要强烈。</p><p>应该指出的是，过去的 GPT 模型（尤其是 GPT-4）的部署决策一直非常谨慎。 GPT-4 经过六个月的评估和微调。即使在早期的型号上也有故意的节奏。尽管他们很快就部署了各种互补能力，但这里的记录并没有那么糟糕。 <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/labenz/status/1727327424244023482">Nathan Lebenz 对 GPT-4 的部署提供了更多的色彩</a>，如果你错过了，推荐，绝对是鱼龙混杂。</p><p>如果 OpenAI 继续保持他们对 GPT-3 和 GPT-4 的谨慎程度，并根据新情况进行调整，只要危险的步骤仍然部署，这似乎就很好，因为我希望他们能够解决“不知道什么”的问题你有问题。之后，我们需要对威胁模型进行适当的调整。</p><p> OpenAI 政策的问题在于它没有向他们承诺任何事情。它不使用数字或确定什么会导致发生什么。相反，它是一个原则声明，表明 OpenAI 关心灾难性风险并将持续监控。我很高兴看到这一点，但这并不能替代实际的政策。</p><p>据我所知， <a target="_blank" rel="noreferrer noopener" href="https://blogs.microsoft.com/on-the-issues/2023/10/26/microsofts-ai-safety-policies/#Responsible_Capability_Scaling">微软</a>实际上正在将此类问题转嫁给 OpenAI。</p><h4> DeepMind 政策</h4><p><a target="_blank" rel="noreferrer noopener" href="https://deepmind.google/public-policy/ai-summit-policies/#responsible-capabilities-scaling">接下来是 DeepMind</a> 。</p><blockquote><p><strong>谷歌认为，必须对人工智能采取负责任的态度。为此，谷歌</strong>于 2018 年<strong>推出的</strong><strong>人工智能</strong><a target="_blank" rel="noreferrer noopener" href="https://ai.google/principles/"><strong>原则</strong></a><strong>指导产品开发并帮助我们评估每一个人工智能应用。</strong>根据这些原则，我们根据以下目标评估我们的人工智能应用：</p><p> <strong><em>1.</em></strong><em>有益于社会。</em> <strong><em>2.</em></strong><em>避免制造或强化不公平的偏见。</em> <strong><em>3.</em></strong><em>构建并测试安全性。</em> <strong><em>4.</em></strong><em>对人负责。</em> <strong><em>5.</em></strong><em>纳入隐私设计原则。</em> <strong><em>6.</em></strong><em>坚持科学卓越的高标准。</em> <strong><em>7.</em></strong><em>可供符合这些原则的用途使用。</em></p></blockquote><p>我并不反对这些原则，但没有任何具体内容可以确保负责任的扩展。</p><blockquote><p>此外，我们不会在以下<a target="_blank" rel="noreferrer noopener" href="https://ai.google/principles/#:~:text=AI%20applications%20we%20will%20not%20pursue">领域</a>设计或部署人工智能：</p><p> <strong><em>1.</em></strong><em>造成或可能造成整体损害的技术。如果存在重大损害风险，我们只有在我们认为收益远大于风险的情况下才会采取行动，并将采取适当的安全限制措施。</em></p><p> <strong><em>2.</em></strong><em>主要目的或实施是造成或直接造成人员伤害的武器或其他技术。</em></p><p> <strong><em>3.</em></strong><em>违反国际公认规范收集或使用信息进行监视的技术。</em></p><p> <strong><em>4.</em></strong><em>其目的违反广泛接受的国际法和人权原则的技术。</em></p></blockquote><p>这是一种误用危险模型。这很好，但在这种情况下不足以避免滥用。从理论上讲，可能造成整体伤害可能意味着什么，但我不认为这是在考虑灾难性风险。</p><p>该文件继续大量使用“道德”一词，而“安全”一词似乎显然与世俗伤害联系在一起。当然，灾难性的伤害确实也会引起道德担忧和世俗担忧，但该文件似乎没有认识到敌人是谁。</p><p>至少有这样的：</p><blockquote><p>该流程将在模型的生命周期中发挥作用，如下所示：</p><ul><li><strong>训练之前：</strong>通过将前沿模型的预测性能与已经完成该过程的类似模型的预测性能进行比较，并允许预测风险存在一定的误差范围，为前沿模型分配初始分类。</li><li><strong>训练期间：</strong>监控模型的性能，以确保其不会显着超出其预测性能。某些类别的模型可能会在训练期间应用缓解措施。</li><li><strong>培训后：</strong>应用适合初始类别分配的培训后缓解措施。为了放松缓解措施，可以将模型提交给专家委员会进行审查。专家委员会利用风险评估、红队、风险领域分析指南以及其他适当的证据，在适当的情况下对分类进行调整。</li></ul></blockquote><p>这并不像 Anthropic 的相似之处那么具体，但我非常喜欢对训练前和训练期间的强调，以及监控意外强劲表现的承诺，并在观察到这种情况时立即进行缓解。当然，目前还没有讨论这些缓解措施是什么，也没有具体说明如何触发这些缓解措施。</p><p>再说一次，我更喜欢这个文档而不是没有文档，但那里几乎没有什么具体内容，没有任何约束力，而且重点完全在于滥用。</p><p> DeepMind 的其余政策以不让任何人承诺任何他们不会因不做而受到指责的方式规定了所有正确的通用事物。它们充其量只是指输入，如果这样做方便且重要的话，很容易规避或忽略。他们的“AI for Good”产品组合中有一些独特的、有前途的项目。</p><h4>亚马逊、词形变化和元</h4><p><a target="_blank" rel="noreferrer noopener" href="https://aws.amazon.com/uki/cloud-services/uk-gov-ai-safety-summit/#Responsible_Capability_Scaling_">亚马逊有一些段落指出了一些不同的事情</a>。这都是通用的公司说法，每个人在其网站上都有自己的风格，无论他们的实际行为如何。慈善观点认为，亚马逊并没有开发前沿模式，事实上他们也没有，所以他们不需要这样的政策成为现实，至少现在还不需要。 <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/simonw/status/1730798295323398642">最近有关亚马逊 Q 的报告</a>表明，亚马逊的协议甚至不足以满足他们当前的需求。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://inflection.ai/frontier-safety">Infection 坚信安全</a>，希望您知道这一点，并打算在维护其利益安全的同时开展业务。这里没有内容。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://transparency.fb.com/en-gb/policies/ai-safety-policies-for-safety-summit#responsible-capability-scaling">Meta 声称</a>他们“开发了更安全的人工智能系统”，而 Llama 则“始终将安全和责任放在首位”。</p><p>大概是通过反对他们。或者，换句话说，这是一个词语没有任何意义的地方。他们并没有假装打算以安全的名义做任何事情，考虑到他们开源的意图，这些事情有可能奏效。</p><p>他们进行了广泛的红队合作？帕德梅问道，他们确实意识到了“两个小时才能解除所有安全”的问题，对吧？他们的“部署后响应”部分只是简单地说“参见上文”，这至少是完全自我意识的，一旦部署这样的系统，您就无能为力，因此查看模型发布部分确实是正确的答案。然后人们可以提供错误报告，如果这让他们感觉更好的话？</p><p>他们确实在“安全控制，包括确保模型权重”下表示，对于一家致力于有意共享其模型权重的公司来说，这是一个棘手的类别，他们确实会保护“未发布”的模型权重，这样就不会有人窃取功劳。</p><p>他们不愿意采取最基本的步骤，并承诺如果模型被证明有足够的能力，不会故意释放他们的模型权重。除了其他失败之外，他们还打算直接破坏整个项目的核心要素之一，从原则上讲，他们是故意的，使他们所做的一切本质上都是不安全的，除非被迫，否则他们无意停止。</p><h4>一些额外的相对排名</h4><p><a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/ms3x8ngwTfep7jBue/thoughts-on-the-ai-safety-summit-company-policies">Nate Sores 也认为 Anthropic 最好，</a>但 OpenAI 也很接近，同时指出 Matthew Gray 看得更仔细，OpenAI 与 Anthropic 一样好：</p><blockquote><ul><li> Soares：Anthropic >; OpenAI >;>; DeepMind >; 微软 >;>; 亚马逊 >;>; Meta</li><li>格雷：OpenAI ≈ Anthropic >;>; DeepMind >;>; 微软 >; 亚马逊 >;>; Meta</li><li> Zvi：Anthropic >; OpenAI >;>; DeepMind >;>; 微软 >; 亚马逊 >;>; Meta</li><li> CFI 审稿人（英国政府）：Anthropic >;>; DeepMind ≈ Microsoft ≈ OpenAI >;>; Amazon >;>; Meta</li></ul></blockquote><p>我猜，CFI 审查员正在考虑个别问题，而我们其他人则从整体上考虑。</p><h4>达里奥·阿莫代的重要澄清</h4><p><a target="_blank" rel="noreferrer noopener" href="https://www.anthropic.com/index/uk-ai-safety-summit">该声明对于向 RSP 提供适当的背景非常重要。</a>考虑全文阅读，我会提取关键段落。</p><p>我先跳到最后，这是最重要的声明所在。大胆的我的。</p><blockquote><p> Dario Amodei（Anthropic 首席执行官）：最后，我想讨论一下 RSP 与监管之间的关系。 <strong>RSP 并非旨在替代监管，而是监管的原型。</strong>我并不是说我们希望 Anthropic 的 RSP 从字面上写入法律<strong>——我们的 RSP 只是解决难题的第一次尝试，而且几乎可以肯定在很多方面都是不完美的</strong>。重要的是，当我们开始执行第一次迭代时，我们希望了解大量有关如何明智地实施此类承诺的知识。我们希望，RSP 的总体理念能够在各公司之间得到完善和改进，与此同时，世界各地的政府（例如在座的各国政府）可以汲取各自的最佳要素，并将其转化为良好的成果。制定具有责任和监督的测试和审计制度。我们希望鼓励在 RSP 式框架中进行“力争上游”，在这种框架中，公司和国家都可以借鉴彼此的想法，最终为世界创造一条明智地管理人工智能风险而不过度破坏其收益的道路。 。</p></blockquote><p>如果 Anthropic 对此更加清楚，包括在 RSP 内部以及在其整个沟通和呼吁政府采取行动的过程中，并且 Anthropic 始终清楚我们必须面对的威胁的性质以及将采取什么措施来应对这些威胁，那么这将解决对当前 RSP 的很多焦虑和反对。</p><p>如果我们将其与 ASL-4 的良好可操作性及其响应结合起来，此时的扩展要求超出了确保模型权重和扣留部署的范围，并澄清如何在模型测试之前处理潜在的级别模糊性尤其是一旦发生这种情况，我认为这种发展是相当伟大的。</p><blockquote><p> Dario Amodei（Anthropic CEO）：快速进步的<em>总体</em>趋势是可以预测的，但实际上很难预测人工智能何时会获得<em>特定的</em>技能或知识。不幸的是，这包括危险的技能，例如制造生物武器的能力。因此，我们面临着许多与人工智能相关的潜在威胁，尽管考虑到当今的系统，这些威胁相对有限，但在不久的将来的某个未知时刻，这些威胁可能会变得非常严重。这与大多数其他行业非常不同：想象一下，如果每种新型汽车都有机会自发地产生新的（且危险的）动力，例如发射火箭助推器或加速到超音速的能力。</p><p> Toby Ord：Dario Amodei 的澄清非常有帮助。最近对 RSP 的许多批评都基于这样的假设：作为监管的替代品，它们可能是空头支票。但作为监管的原型，它们有更充分的理由具有价值。</p><p> Sam Altman：在我们训练 [GPT-5] 之前，[预测其确切能力]对我们来说就像一个有趣的猜谜游戏。我们正在努力做得更好，因为我认为从安全角度预测能力很重要。</p></blockquote><p>我认为达​​里奥和许多其他人对大趋势的可预测性过于自信，这是制定有效RSP的问题。正如达里奥（Dario）指出的那样，即使我的观点是错误的，特定技能的出现也不会以可预测的方式出现，并且通常只有在部署很久之后才能发现。</p><p>以下是他对 RSP 和 ASL 的概述，以及 Anthropic RSP 的概念设计方式。</p><blockquote><ul><li>首先，我们提出了一个名为<em>人工智能安全级别 (ASL)</em>的系统，该系统大致模仿了国际公认的用于处理生物材料的 BSL 系统。每个 ASL 级别都有一个<em>“如果-那么”</em>结构：<em>如果</em>人工智能系统表现出某些危险功能，<em>那么</em>我们不会部署它或训练更强大的模型，直到某些保护措施到位。</li><li>其次，我们沿着计算扩展曲线定期定期测试这些危险功能。这是为了确保我们不会在不知道自己已经这样做的情况下盲目地创造危险的能力。</li></ul></blockquote><p>我想澄清的是，只要有正确的细节，这是非常好的。我们都在谈论价格。问题是：</p><ol><li>每个级别的触发条件是什么？</li><li>确定是否满足触发条件的必要方法是什么？</li><li>各个层面有哪些必要的保障措施？是什么让缩放变得安全？</li></ol><blockquote><p> ASL-3 是人工智能模型在 CBRN 领域的灾难性误用中发挥作用的关键点。</p><p>在达到 ASL-3 之前必须严格定义 ASL-4。</p><p> ASL-4 代表了 ASL-3 灾难性误用风险的升级，并且还增加了新的风险：人们担心自主人工智能系统会逃脱人类控制并对社会构成重大威胁。</p></blockquote><p>很多人担心的是迄今为止未能定义 ASL-4 或对其的响应，以及对 Anthropic（以及 Google 和 OpenAI）距离 ASL-3 甚至 ASL-4 还很远缺乏信心。我们担心 ASL-4 的预防措施是不够的，因为训练你不部署的模型不再是完全安全的。 Anthropic 关于生物武器的一些陈述暗示克劳德的内部状态已经接近 ASL-3。</p><blockquote><p>作为首席执行官，我个人在 RSP 上花了 3 个月的时间，花费了 10-20% 的时间——除了设计和提出 ASL 系统之外，我还从头开始编写了多个草稿。我的一位联合创始人花了 3 个月的时间投入了 50% 的时间来开发 RSP。</p></blockquote><p>我确实认为这很重要，不应该被视为廉价的谈话。谢谢你，达里奥。</p><h4>关于此类政策的战略思考</h4><p><a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/dxgEaDrEBkkE96CXr/thoughts-on-responsible-scaling-policies-and-regulation.">保罗·克里斯蒂安诺 (Paul Christiano) 提出了他的高层次想法，这些想法是支持性的</a>。</p><blockquote><p> Paul Christiano：我认为开发人员实施负责任的扩展政策现在增加了有效监管的可能性。如果我认为这会让监管变得更加困难，我就会持很大的保留态度。</p><p> RSP 的透明度使外部利益相关者更容易了解人工智能开发人员的政策是否足以管理风险，并成为争论和改进压力的焦点。</p><p>我认为人工智能快速发展的风险非常大，即使非常好的 RSP 也无法完全消除这种风险。对前沿人工智能开发的持久、全球、有效执行和包括硬件在内的暂停将进一步降低风险。我认为这在政治上和实践上都具有挑战性，并且会产生重大成本，所以我不希望它成为唯一的选择。我认为实施 RSP 可以获得大部分好处，根据更广泛的观点和信念，这是可取的，并且有助于促进其他有效的监管。</p><p> ……</p><p>但目前的风险水平足够低，我认为<strong>如果公司或国家有足够好的计划来检测和应对不断增加的风险，那么他们</strong>继续人工智能开发是合理的。</p><p> ……</p><p>我认为，一个好的 RSP 将列出需要暂停进一步开发的具体条件。</p><p> ……</p><p>因此，“负责任的扩展政策”可能不是正确的名称。我认为重要的是实质内容：开发人员应明确制定危险能力与必要防护措施之间关系的路线图，应描述衡量危险能力的具体程序，并应在防护措施满足但能力超出危险限制的情况下制定应对措施路线图。</p></blockquote><p>正如保罗指出的那样，RSP 是否使足够好的监管变得更容易或更困难似乎是明显的症结所在。如果RSP通过迭代和展示它的样子并使良好的政策正常化来使充分良好的监管变得更加容易，并且这种效应在当前条件下占主导地位？显然，即使名字不幸，RSP 也是好的，尤其是 Anthropic 是一个巨大的积极进步。如果 RSP 反而使监管变得更加困难，因为它们本身被视为替代品或妥协，并且这种效应在很大程度上占主导地位，那么这可能会掩盖它们可能带来的好处。</p><p>霍尔顿·卡诺夫斯基 (Holden Karnofsky) 在《 <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/Np5Q3Mhz2AiPtejGN/we-re-not-ready-thoughts-on-pausing-and-responsible-scaling-4">我们还没有准备好：关于暂停和负责任的扩展政策的思考</a>》中解释了他对 RSP 的总体支持。</p><p>归结起来，他说：</p><ol><li> AGI 可能很快就会到来（>;10%）。</li><li>我们还没有准备好，完全准备好也是不现实的。</li><li>首先最好的办法是全球范围内暂停。</li><li>我们没有这个选项。</li><li>部分暂停存在严重缺陷，特别是如果它们在不合时宜的时候结束，并可能适得其反。</li><li> RSP 针对不同观点提供了“非常好的妥协”。</li><li> RSP 的缺点是它们可能被认为是充分的而不是必要的，从而阻碍了进一步的行动。政府可能要么什么都不做，要么只是将现有的 RSP 写入法律，然后就到此为止。</li></ol><p>我基本上完全同意#1、#2、#3、#4 和#7 点。</p><p>我对在为时已晚之前完全暂停持乐观态度，但在未来几年内这似乎不太可能。至少，考虑到我们有多少时间的不确定性，我们将所有鸡蛋放在这样一个篮子里是不明智的。</p><p>第5点很复杂。当然，这种暂停在某些方面可能会适得其反，要么是有差别地阻止好演员，要么是在暂停结束时导致快速进步，从而使我们陷入更糟糕的境地。在网络上，即使是相对有缺陷的暂停工作，我仍然期望获得净收益，包括它们转变为完全或明智实施的暂停的潜力。但我也注意到，我们甚至还没有接近部分暂停。</p><p>第 6 点在很大程度上取决于 RSP 细节的复杂程度，以及第 7 点考虑因素的重要性。</p><p>如果我们能够得到一个真正的 RSP，有牙齿，被所有重要的主要实验室采用，确保这些实验室实际上采取预防措施，提供有意义的安全边际，并在明显需要暂停时导致暂停，那么这似乎伟大的。如果我们得到的比这个少，那就显得不那么伟大了，在这两个方面我们都必须问少了多少？</p><p>即使是相对较好的 RSP，如果它可以替代政府行动或其他预防措施，甚至成为继续前进的理由，那么它也不会令人兴奋。当然，如果我们无论如何都要全速前进，那么任何预防措施都是有帮助的。显然，我们至少会倾向于采取一些监管预防措施。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/Np5Q3Mhz2AiPtejGN/we-re-not-ready-thoughts-on-pausing-and-responsible-scaling-4?commentId=DyyGinph6hbwiHHo5">正如 Akash 在置顶评论中指出的那样</a>，这非常重视 RSP 周围的沟通。</p><blockquote><p> Akash：我希望 ARC 和 Anthropic 能够更清楚地了解这一点，如果他们大声且清楚地表达了这一点，我就不会那么批评他们的 RSP 帖子。我认为[霍尔顿]的帖子响亮而明确（您多次明确表示，您认为监管是必要的，并且您希望世界有更多的政治意愿来监管）。我很欣赏这一点，我很高兴你写了这篇文章。</p><p> ……</p><p>我认为对现状的一些改善可能会带来净负面影响，因为它们要么（a）巩固错误的框架，要么（b）采取有限的政治意愿/注意力窗口并将其引向较弱的方向</p><p>如果每个就 RSP 进行交流的人都明确表示他们不希望 RSP 被视为足够，那就太好了。</p></blockquote><p>如果 ARC、Anthropic 和其他公司都清楚这一点，那么我会很高兴他们采用甚至存在严重缺陷的 RSP，例如当前的 Anthropic 政策。唉，他们的沟通并没有明确说明这一点，而是积极劝阻那些试图将奥弗顿之窗转向我认为必要的行动的人。 RSP 与尝试做更大的事情是好的，但作为更大的事情的替代品它们是不好的。</p><p>因此，我非常不喜欢像“稳健的良好妥协”这样的短语，正如 aysja 解释的那样。</p><blockquote><p>艾莎：不过，在元层面上，我对一些框架选择感到脾气暴躁。您和最初的 ARC 评估者都使用了这样的措辞：负责任的扩展政策是“非常好的妥协”，或者就 ARC 而言，它们是“务实的中间立场”。我认为这些立场理所当然地认为前进的最佳道路是妥协，但这对我来说似乎还很不清楚。</p><p>当然，并非<em>所有</em>“人们有不同的信仰和偏好”的情况都是妥协是最好的解决方案。如果有人想杀我，我不会开诚布公地讨论我可以接受他们砍掉多少肢体。</p><p> ……</p><p>在很难对齐的世界中，并且评估无法识别实际上令人恐惧的行为，那么我认为此类评估的存在令人担忧。</p></blockquote><p>当且仅当能取得好的结果时，妥协才是好的。如果采取妥协措施，导致预防措施不足，无法提供更多额外保护，或者预防措施确实会错过警告信号，那么这种妥协是不值得的。</p><p>阿卡什的其他要点强化了这一点。这是另一个粗体文本。</p><blockquote><p> Akash：如果 Anthropic 的 RSP 是我们能得到的最好的 RSP，那么哎呀，这个 RSP 计划做得不太好。</p><p>我认为 RSP 框架是错误的，我不希望监管机构将其用作构建块。在我看来，政府愿意从比这更严格、更明智的事情开始，“继续下去，直到我们能够证明该模型具有高度危险的能力”。</p><p>我认为对现状的一些改善可能会带来净负面影响，因为它们要么（a）巩固错误的框架，要么（b）采取有限的政治意愿/注意力窗口并将其引向较弱的方向</p><p>至少，我希望 RSP 能够重新命名，并且那些关于 RSP 的沟通者能够更加小心。</p><p>更雄心勃勃的是，我希望从事 RSP 工作的人们认真考虑这是否是最好的工作或倡导的事情。</p><p>我认为从事 RSP 工作的每个人都应该至少花几个小时认真考虑 AIS 社区可能倡导更强有力的政策提案的可能性。</p><p> Ryan：我认为好的 RSP 实际上会将举证责任交给实验室。</p></blockquote><p>另一个核心问题是， <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/jyM7MSTvy8Qs6aZcz/what-s-up-with-responsible-scaling-policies#How_well_can_you_tell_if_a_given_model_is_existentially_dangerous_">实验室是否会因最大化安全指标而最终成为古德哈特定律的受害者</a>？对于 RSP 来说，这种担忧并不是特别糟糕。如果人们想要进行安全清洗并从技术上检查一个方框，那么这对于监管以及其他一切都是有效的，如果控制者如此倾向于的话。除了使指标尽可能稳健之外，唯一有效的解决方案是让那些旨在真正防范灾难并有权这样做的人做出决定。但请记住，最终权威不会出现在多个地方。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.navigatingrisks.ai/p/responsible-scaling-policies-are">Simeon 认为</a>，当前的 RSP 充分结合了不足、能够淡化风险以及能够廉价地谈论它们应该被视为违约净负值。</p><p>相反，他建议采用现有的风险管理最佳实践，而目前实施的 RSP 未能做到这一点，因此达不到要求。特别是，风险阈值未明确指定，并且没有以可能性或程度来表示。评估不够全面。当然还有更名，并明确该政策的作用和不作用。</p><p>他还指出了他所谓的“白骑士条款”的危险，在该条款中，你说你有些危险的缩放是由其他人更危险的缩放证明的。正如西蒙指出的那样，如果这是标准，那么每个人都可以指着其他人说“我是安全的”。开源倡导者指出闭源、封闭到开放等等，包括在谁对谁错不太明显的地方。</p><p> Anthropic的此类子句至少是有限的，但不应使用此类子句。如果您选择不安全地前进，那么您必须违反安全政策。在足够极端的情况下，这甚至可能是正确的做法。但你需要承认这一点，并接受后果。没有理由。虽然知道这样忽悠人很容易，而你又是最容易忽悠的人。</p><h4>结论</h4><p>Anthropic 的 RSP（如果现在称为 RDP）并辅之以良好的沟通，将是迈向负责任政策的强有力的第一步。事实上，它仍然代表着一个代价高昂的信号，并提供了我们可以在此基础上进行的基础工作，而且我们确实至少有一个开始进行如此良好的沟通。还需要做更多的工作，人们担心这将被用来证明在其他地方采取较少的预防措施是合理的，特别是在没有强有力的公共沟通的情况下，但这也可能会走向相反的方向，我们不知道私下沟通的内容，或者对关键参与者有何影响。</p><p>其他政策就不太好。它们让我们深入了解每个人的想法。 OpenAI 的政策原则上是好的，他们过去的行动也非常谨慎，但他们没有承诺任何事情，当然，最近发生的事件可能会产生影响。 DeepMind 的文档总比没有好，但表明他们的头脑没有放在正确的位置，尽管谷歌在其他方面保持谨慎。</p><p>正如我们预期的那样，Amazon、Inflection 和 Meta 的陈述相当糟糕。</p><p>展望未来，我们将看看这些声明，尤其是 OpenAI 和 Anthropic 的声明，能否偿还债务并演变成有牙齿的东西。在那之前，一切都只是空谈。</p><br/><br/> <a href="https://www.lesswrong.com/posts/yRJNCDp7LHyHGkANz/on-responsible-scaling-policies-rsps#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/yRJNCDp7LHyHGkANz/on-responsible-scaling-policies-rsps<guid ispermalink="false"> yRJNCDp7LHyHGkanz</guid><dc:creator><![CDATA[Zvi]]></dc:creator><pubDate> Tue, 05 Dec 2023 16:10:08 GMT</pubDate> </item><item><title><![CDATA[We're all in this together]]></title><description><![CDATA[Published on December 5, 2023 1:57 PM GMT<br/><br/><p>历史似乎一直试图告诉我们一件事：未来的内容是由权力、经济、政治和其他<a href="https://slatestarcodex.com/2018/01/24/conflict-vs-mistake/">冲突理论问题</a>决定的。</p><p>事实证明，不！</p><p>未来的几乎所有内容都取决于首先解决以下两个工程问题中的哪一个：</p><ul><li>如何构建超级智能人工智能（如果先解决，<a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities">每个人都会永远死亡</a>）</li><li>如何构建一个<em>一致的</em>超级智能人工智能（如果首先解决，每个人都会得到<a href="https://www.lesswrong.com/posts/CMHogeqTTajhmnEKx/everything-is-okay">乌托邦</a>）</li></ul><p> ……目前前者更有可能发生的几乎所有原因都是<a href="https://slatestarcodex.com/2018/01/24/conflict-vs-mistake/"><em>错误理论</em></a>的原因。</p><p>目前采取行动增加{前者首先被解决}的概率的人并不是试图杀死所有人的邪恶之人，他们是<em>困惑的</em>人，他们认为他们的行为实际上增加了{后者首先被解决}的概率。</p><p>现在，当然，你是否有机会与 OpenAI/Deepmind/Anthropic 的领导层交谈，足以告诉他们他们实际上让事情变得更糟<em>，这</em>取决于经济和政治等因素。但归根结底，对于这里真正重要的部分来说，这是一个<em>解释</em>的问题，而不是<em>击败的</em>问题。</p><p>当然，“乌托邦”的实现细节确实取决于谁启动了一致的超级智能人工智能，但我希望您会对当前摆在桌面上的任何可能性所带来的乌托邦感到非常满意。您错过的绝大多数实用程序是因为<em>根本没有乌托邦并且每个人都会永远死去</em>，而不是<em>获得错误的乌托邦实现细节</em>。</p><p>最有可能的结果是每个人都会永远死亡，因为那些影响这些结果将要发生的人是<em>错误的</em>（并且可能没有认真思考这个问题而意识到他们是错误的）。</p><p>他们<strong>不是邪恶</strong>的，让他们更新到正确的逻辑信念是一个理性问题（而且，如果他们是那种很容易受到周围其他人的想法影响的弱主体，模因），而不是一个问题冲突。</p><p>他们极大地保护了每个人的利益，<em>包括他们自己的利益</em>。他们采取的正确行动将极大地服务于他们自己<em>以及其他所有人的</em>利益。如果人工智能杀死所有人，他们也会死，如果人工智能创造乌托邦，他们将和其他人一起得到乌托邦——而这些几乎是唯一的两个吸引子。</p><p>我们谁都跑不了。我们中的一些人只是相当困惑，没有主动追求真理，而且他们的信仰可能因模因等影响而产生巨大偏差。但我很确定负责人没有人<em>故意</em>试图杀死所有人；他们只是<em>偶然地</em>试图杀死所有人。</p><p>如果你不使用你的权力/金钱来影响这两种结果中哪一个更有可能发生，那么你的权力/金钱就<em>完全没有用处</em>。如果我们都死了，它们就没有用处，如果我们得到乌托邦，它们就没有用处。现在，如果你想<em>以任何方式</em>影响几乎所有的未来（除了接下来的 0 到 5 年，这大约是我们拥有的时间），资源的唯一用途就是影响其中哪些首先解决两个工程问题。</p><p>这既适用于主要人工智能组织的负责人，也适用于其他所有人。一个人在人工智能组织中的角色除了影响这两个问题中哪一个首先得到解决之外<em>没有任何用处</em>。如果及时解决了对齐问题，OpenAI 的负责人不会比其他人特别获得一个更闪亮的乌托邦，如果没有及时解决，他们也不会比其他人死得更少。</p><p>权力/金钱/成为 OpenAI 的领导者<em>在奇点之后不会做任何事情</em>。现在<strong>唯一</strong>重要的是这两个工程问题中的哪一个首先得到解决。</p><br/><br/><a href="https://www.lesswrong.com/posts/A4nfKtD9MPFBaa5ME/we-re-all-in-this-together#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/A4nfKtD9MPFBaa5ME/we-re-all-in-this-together<guid ispermalink="false"> A4nfKtD9MPFBaa5ME</guid><dc:creator><![CDATA[Tamsin Leake]]></dc:creator><pubDate> Tue, 05 Dec 2023 13:57:54 GMT</pubDate> </item><item><title><![CDATA[A Socratic dialogue with my student]]></title><description><![CDATA[Published on December 5, 2023 9:31 AM GMT<br/><br/><p>这是我和我的学生诺姆之间的对话。经他许可，以编辑形式转载。评论时，请考虑他是一个青少年。其中许多想法对他来说都是<a href="https://xkcd.com/1053/">新的</a>。</p><p>怎样才能招到学生呢？你偷了他们。他以前的老师是一位马克思主义者。我在辩论中彻底摧毁了他以前的老师，以至于他放弃了她的教诲，现在转而听我的。</p><p>我认为这段对话展示了良好的教学技巧。</p><ul><li>我让诺姆来判断什么是合理的、什么是有道理的、什么是“证据”。在诺姆出生之前，我参加了我的第一次辩论比赛。这个障碍稍微缩小了差距。</li><li>我会问一系列问题，而不只是说“ <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>是真的”。这使得<a href="https://www.lesswrong.com/posts/NMoLJuDJEms7Ku9XS/guessing-the-teacher-s-password">密码猜测</a>变得不可能。他是在下棋，而不是<i>危险边缘！</i></li><li>我避免告诉诺姆我的信仰，除非他明确询问。这对诺姆来说更有趣，因为没有人喜欢未经请求的讲道。这也更有说服力，因为结论感觉像是他的结论。</li><li>当诺姆改变话题时，我立即退缩了。</li></ul><p><strong>诺姆：</strong>我知道你反对免除学生贷款债务。你能告诉我为什么吗？我这样做是为了一场演讲和辩论比赛。</p><p> <strong>Lsusr：</strong>你<a href="https://www.youtube.com/watch?v=o_wNNjfCG1E&amp;t=4s">以前不相信</a>支持救济的论点吗？当然，重复曾经说服你的论点并不困难。</p><p><strong>诺姆：</strong>我不知道我现在是否有足够的研究来与像你这样的人辩论。</p><p> <strong>Lsusr：</strong>你并不是想说服我。你正试图说服<a href="https://www.youtube.com/watch?v=xuaHRN7UhRo"><i>他们</i></a>。利用他们的偏见、非理性、部落主义和无知。</p><p><strong>诺姆：</strong>我还必须安抚评委们。</p><p> <strong>Lsusr：</strong>我就是这么说的。</p><hr><p><strong>诺姆：</strong>我正在努力寻找一个关于学生贷款减免的好论据。</p><p> <strong>Lsusr：</strong>但是你以前不是很赞同吗？当然，你可以重复曾经说服你的糟糕论点。</p><p><strong>诺姆：</strong>这些都是道德争论，没有任何经济理解。</p><p> <strong>Lsusr：</strong>没关系。你的听众可能是经济文盲。</p><p><strong>诺姆：</strong>不知何故，我认为我们作为赞成免除所有学生贷款债务的一方赢得了一次胜利。</p><p> <strong>Lsusr：</strong>干得好。</p><p><strong>诺姆：</strong>谢谢。</p><hr><p> <strong>Lsusr：</strong>你听说过“有效利他主义”吗？您可能会喜欢他们推出的一些东西。它往往具有道德一致性和经济素养（与主要的民主共和党、社会主义等政治纲领不同）。</p><p><strong>诺姆：</strong>不，但我会调查一下。</p><p> <strong>Lsusr：</strong>你可能不同意。但我预计它的智力稳健性会让你耳目一新。</p><hr><p><strong>诺姆：</strong>这是否意味着我自杀然后将我所有的器官捐献给需要它们的人是道德的？我想，除非我能在不自杀的情况下拯救更多的生命。也许更好的论点是自杀，让某人卖掉我所有的身体部位，然后用这笔钱购买疟疾网，送给生活在非洲的人们。</p><p> <strong>Lsusr：</strong>你可以在不自杀的情况下拯救更多生命。而且，我想不出有哪个 EA 曾为此案自杀过。</p><p><strong>诺姆：</strong>可能是因为我们直觉上认为自杀是错误的。</p><p> <strong>Lsusr：</strong>不要因为肾脏的事情而分心。这是一个基本思想：</p><ul><li>美国政府需要花费 10,000,000 美元才能挽救一个美国人的生命。</li><li>在非洲，通过公共卫生措施挽救一条生命需要 5,000 美元。</li></ul><p>这就是我上个月为非洲公共卫生措施捐赠 20 美元的原因。它的作用相当于美国联邦政府花费的 40,000 美元。</p><p><strong>诺姆：</strong>是的，确实如此。在美国靠什么拯救生命？</p><p> <strong>Lsusr：</strong>基本的想法是你应该计算数字。 </p><figure class="media"><div data-oembed-url="https://www.youtube.com/watch?v=dNgp-s8IvRs"><div><iframe src="https://www.youtube.com/embed/dNgp-s8IvRs" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div></figure><p><strong>诺姆：</strong>我认为这对钱有用，但我不知道它是否可以完全应用于所有事情。</p><p> <strong>Lsusr：</strong>为什么不呢？具体例子。</p><p><strong>诺姆：</strong>嗯，这取决于你是否认为人类应该拥有受保护的权利。</p><p> <strong>Lsusr：</strong>这不是一个具体的例子。您的主张可能适用于什么现实世界的决定？请明确点。</p><p><strong>诺姆：</strong>一位医生有5名病人需要器官移植，否则他们就会死。有一名完全健康的人因接受小手术而处于麻醉状态。如果我们仔细计算一下数字，医生应该杀死那个人才能挽救五个人的生命。如果你认为人类有权利，那就是不道德的。如果你认为人类不会，那就不会了。</p><p> <strong>Lsusr：</strong>正确。这显然是不道德的。但人权并不是医生不应该谋杀病人的唯一原因。你能想到一种实用主义的吗？</p><p><strong>诺姆：</strong>医生会失去执照，然后他们就会失业。</p><p> <strong>Lsusr：</strong>如果没有许可证要求怎么办？比如在战区。</p><p><strong>诺姆：</strong>患者将来也许能够挽救生命。</p><p> <strong>Lsusr：</strong> 5 个器官接受者也可以。另一个原因。</p><p><strong>诺姆：</strong>我不确定。</p><p> <strong>Lsusr：</strong>没有人会去看他们认为会谋杀他们的医生。</p><p><strong>诺姆：</strong>如果是战区，那么可能没有其他选择。</p><p> <strong>Lsusr：</strong>公平。您熟悉“义务论伦理学”这个词吗？</p><p><strong>诺姆：</strong>是的。任何有最好意图的事情都是如此。那是对的吗？我可能已经忘记了。</p><p> <strong>Lsusr：</strong>没有。这不是最好的意图。</p><p><strong>诺姆：</strong>好的。之后怎么样了？</p><p> <strong>Lsusr：</strong>义务论伦理遵循“不要杀死你的病人”这样的良好规则。 EA 相信要处理数字，但它们通常不会违反义务论限制。当我捐20美元时，我捐的是我自己的钱。我没有偷它。</p><p><strong>诺姆：</strong>好的。让我想想我是否发现任何缺陷。</p><p> <strong>Lsusr：</strong>慢慢来。</p><p><strong>诺姆：</strong>如果你遵循我认为好的规则，并且你帮助了最多的人，那么我不可能反对。</p><p> <strong>Lsusr：</strong>那是 EA。但不仅仅是人。他们的素食主义者数量远远超过了应有的比例。</p><p><strong>诺姆：</strong>好的。稍微不相关的问题：您对素食主义者有何看法？</p><p> <strong>Lsusr：</strong>我已经几个月没吃肉了。</p><p><strong>诺姆：</strong>这对你来说是环境问题还是对杀害动物的道德反对？还是健康？</p><p> <strong>Lsusr：</strong>对我的健康可能会产生负面影响。环境影响对我来说无关紧要。我不在乎杀死动物。如果你能找到一个符合道德来源的汉堡，那么我很乐意吃它。问题是，我们的动物产品默认来自工厂化农场，那是人间地狱。 [更正：我在家人的感恩节晚餐上吃了一些肉汁。]</p><p><strong>诺姆：</strong>这对我来说很有趣，我不一定不同意你的推理。</p><p> <strong>Lsusr：</strong>我尽量不将我的信仰和价值观强加给别人。这就是为什么直到你问我才提到这一点。</p><p><strong>诺姆：</strong>如果你说折磨动物是错误的，那么杀死动物不也是不道德的吗？</p><p> <strong>Lsusr：</strong>动物干净的死亡几乎没有什么痛苦，特别是与漫长而美好的生命相比。我正在努力减少痛苦，同时遵守义务论限制。</p><p><strong>诺姆：</strong>你认为道德考虑的重要性应该与事物的先进程度成正比吗？抱歉，如果我措辞不好。现在已经是深夜了，我正在等待电源恢复，这样我就可以做剩下的作业了。</p><p> <strong>Lsusr：</strong>我知道你的意思。答案=是。如果我必须在拯救两只牛和一个人之间做出选择，那么人类是显而易见的选择。</p><p><strong>诺姆：</strong>好的。我同意你的看法。</p><hr><p> <strong>Lsusr：</strong>辩论进行得怎么样？</p><p><strong>诺姆：</strong>你的假设是非常正确的，即法官们都是经济文盲。</p><p> <strong>lsusr：</strong>哈哈哈哈哈哈</p><hr><p><strong>Lsusr：</strong>你喜欢吗？我觉得你很喜欢辩论锦标赛。干得好，能够与校队的孩子们竞争。</p><p><strong>诺姆：</strong>是的。非常有趣。</p><p> <strong>Lsusr：</strong>我也喜欢高中辩论。我做了3-4年。</p><p><strong>诺姆：</strong>尝试捍卫错误的立场很有趣，因为这很困难。</p><p> <strong>Lsusr：</strong>如果你的信念是错误的（所以你认为这是正确的立场）怎么办？那很难吗？</p><p><strong>诺姆：</strong>我知道不是在这个问题上，因为正如你所说，这就像争论天空是否是蓝色的。但对于其他一些诸如“美国应该在&lt;地方>;部署更多军队”之类的问题，很难看出什么是正确的。</p><p> <strong>Lsusr：</strong>出去吧。直视。准确地告诉我你看到的是什么颜色。</p><p><strong>诺姆：</strong>现在是黑色的。</p><p> <strong>Lsusr：</strong>通常，辩论比赛决议的定义（故意）如此模糊，以至于它们可能是正确的，也可能是错误的，这取决于它们的解释方式。</p><p><strong>诺姆：</strong>据我所知，无论你如何解释，这个都是错误的。我认为“全部”这个词几乎让人无法辩护。</p><blockquote><p>美国联邦政府应免除所有联邦学生贷款债务。</p></blockquote><p> <strong>Lsusr：</strong>假设民主国家的每个人（错误地）都支持学生贷款减免。民选政府是否应该尊重人民的意愿？</p><p><strong>诺姆：</strong>是的，因为如果他们不这样做，就会开创一个不服从人民的危险先例。</p><p> <strong>Lsusr：</strong>那么你所要做的就是表明绝大多数美国选民支持贷款减免。</p><p><strong>诺姆：</strong>比起 3.4% 的通胀率，我更担心这种影响。</p><p> <strong>Lsusr：</strong>不用担心。绝大多数美国选民支持愚蠢得多的政策。美国的通胀率应该是多少？</p><p><strong>诺姆：</strong>我的直觉是 0%，但有一些我不知道的经济小事表明一个国家应该有<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>程度的通货膨胀。</p><p> <strong>Lsusr：</strong>这是我制作的一个长达一小时的 YouTube 视频，试图传达这个问题的复杂性。 【我就是右边那个戴面具的人。】 </p><figure class="media"><div data-oembed-url="https://www.youtube.com/watch?v=fdlFHnxDE94"><div><iframe src="https://www.youtube.com/embed/fdlFHnxDE94" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div></figure><p>为什么它应该为零？</p><p><strong>诺姆：</strong>我认为，我在经济知识方面的差距正在显现，但当一种货币尽可能值钱时，这不是很好吗？而且，我的力量现在又恢复了。所以我要做作业然后去睡觉。</p><p> <strong>Lsusr：</strong>如果你希望货币尽可能值钱，那么我们应该有负通胀率。晚安！保证充足的睡眠。</p><p><strong>诺姆：</strong>噢，你说得对。我把这归咎于“凌晨2点”。</p><p> <strong>Lsusr：</strong>不。你的问题并不愚蠢。这很难。</p><p><strong>诺姆：</strong>我想我应该记住数字可能会下降。</p><p> <strong>lsusr：</strong> 🤑</p><br/><br/> <a href="https://www.lesswrong.com/posts/TtdJt78mgGiDubnAM/a-socratic-dialogue-with-my-student#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/TtdJt78mgGiDubnAM/a-socratic-dialogue-with-my-student<guid ispermalink="false"> TtdJt78mgGiDubnAM</guid><dc:creator><![CDATA[lsusr]]></dc:creator><pubDate> Tue, 05 Dec 2023 09:31:05 GMT</pubDate> </item><item><title><![CDATA[Neural uncertainty estimation for alignment]]></title><description><![CDATA[Published on December 5, 2023 8:01 AM GMT<br/><br/><h2>介绍</h2><p>假设您已经构建了一些人类价值观的人工智能模型。你输入一个情况，它就会给出一个良好度评级。您可能想问：“此优度评级的误差线是多少？”除了了解误差线之外，不确定性估计在人工智能内部也很有用：指导主动学习<span class="footnote-reference" role="doc-noteref" id="fnref80ywo0pbl8r"><sup><a href="#fn80ywo0pbl8r">[1]</a></sup></span> 、纠正<a href="https://www.lesswrong.com/posts/5gQLrJr2yhPzMCcni/the-optimizer-s-curse-and-how-to-beat-it">优化器的诅咒</a><span class="footnote-reference" role="doc-noteref" id="fnrefq23duy4ut0g"><sup><a href="#fnq23duy4ut0g">[2]</a></sup></span>或进行分布外检测<span class="footnote-reference" role="doc-noteref" id="fnref3dij2j9svj8"><sup><a href="#fn3dij2j9svj8">[3]</a></sup></span> 。</p><p>我最近出于一个<a href="https://www.lesswrong.com/s/aJvgWxkCBWpHpXti4/p/nA3n2vfCy3ffnjapw">喜欢的原因</a>进入了神经网络（NN）的不确定性估计文献：我认为这对于量化人工智能潜在特征的有效性域的对齐很有用。如果我们<a href="https://www.lesswrong.com/posts/w4aeAFzSAguvqA5qu/how-to-go-from-interpretability-to-alignment-just-retarget">将人工智能指向其世界模型中的某个概念</a>，那么对该概念的实现进行优化可能会因为将该概念推到其有效范围之外而出错。</p><p>但现在就先把对齐的想法放在你的后口袋里吧。这篇文章主要是对不确定性估计文献的调查，其中夹杂着我自己的看法。</p><p></p><h2>贝叶斯神经网络图片</h2><p>贝叶斯神经网络图是几乎所有神经网络不确定性估计方法的鼻祖，因此从这里开始是合适的。</p><p>图片很简单。您从参数的先验分布开始。您的训练数据就是证据，在对其进行训练后，您将获得更新的参数分布。给定输入，您可以通过贝叶斯神经网络传播输入来计算输出的分布。</p><p>这一切都是非常正确且无关紧要的（“<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="2^{trillion}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">当然</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">，</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">让</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">我</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">更新</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">我</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">的</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">2</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">万亿</span></span></span></span></span></span></span></span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>模型所有参数的维度联合分布”），但<i>实际上训练神经网络确实是这样工作的</i>。<i> </i>如果您使用对数似然损失和 L2 正则化，并且您的参数先验是高斯分布，则最小化损失的参数将位于贝叶斯神经网络所具有的分布的峰值<span class="footnote-reference" role="doc-noteref" id="fnreffo4svcpvxs"><sup><a href="#fnfo4svcpvxs">[4]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnrefcogdul3x2xj"><sup><a href="#fncogdul3x2xj">[5]</a></sup></span> 。</p><p>这是因为损失景观和参数不确定性之间存在桥梁。 <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(parameters \;|\; dataset) ="><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">贝叶斯</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">规则</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">表示</span></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">P</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">（</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">集</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">P</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">⋅</span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(parameters) \cdot \text{P}(dataset \;|\; parameters) / \text{P}(dataset)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">P</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">集</span></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mtext MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">）</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">/</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">P</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">（</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">集</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">）</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">。</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span></span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(parameters \;|\; dataset)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">这里</span></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">P</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">集</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">是</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">要</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">估计</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">的</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">后</span></span></span></span></span></span></span><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(parameters) \cdot \text{P}(dataset \;|\; parameters)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">验</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">分布</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">，</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">P</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">⋅</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">P</span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">(</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">集</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mtext MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">s</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">是</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">损失</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">的</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">指数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">6</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">]</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">。</span></span></span></span></span></span></span> <span class="footnote-reference" role="doc-noteref" id="fnrefamk58pvab4"><sup><a href="#fnamk58pvab4">_</a></sup></span>这适用于物理隐喻，例如“参数的分布是位于损失盆地底部的玻尔兹曼分布”。</p><p>根据经验，通过假装遵循贝叶斯神经网络图来计算神经网络的不确定性效果非常好，以至于一篇关于集成方法的好论文<span class="footnote-reference" role="doc-noteref" id="fnreflpb1b2qcoen"><sup><a href="#fnlpb1b2qcoen">[7]</a></sup></span>将其称为“基本事实”。当然，要在这里实际计算任何东西，你必须进行近似，如果你进行快速而肮脏的近似（例如假装你可以从 Hessian 找到损失盆地的形状），你会得到不好的结果<span class="footnote-reference" role="doc-noteref" id="fnrefd9jz9mfml"><sup><a href="#fnd9jz9mfml">[8]</a></sup></span> ，但人们正在做这些天，蒙特卡罗方法变得很聪明<span class="footnote-reference" role="doc-noteref" id="fnrefbct5kii2m07"><sup><a href="#fnbct5kii2m07">[9]</a></sup></span> ，他们发现贝叶斯神经网络计算的更好近似可以得到更好的结果。</p><p>但对损失景观进行蒙特卡罗遍历的成本很高。对于大规模应用的技术，它必须只对运行模型的成本施加很小的乘数，并且如果您希望它变得普遍，那么它施加的成本必须非常小。</p><p></p><h2>合奏团</h2><p>解决不确定性的一种完全不同的方法是集成<span class="footnote-reference" role="doc-noteref" id="fnrefen0yeoqzg0k"><sup><a href="#fnen0yeoqzg0k">[10]</a></sup></span> 。只需训练十几个模型，询问他们的建议，并估计传播的不确定性。所有事情的数十倍成本乘数都很陡峭，但如果您经常查询模型，它比损失情况的蒙特卡洛估计便宜。</p><p>集成在理论上很简单。您不需要假装模型经过训练可以收敛，不需要专门针对预测损失进行训练，甚至不需要固定的架构。您只需选择一些想要分散不确定性的模型分布并进行采样。</p><p>你可以用合奏做一些聪明的事情。通过计算集成如何适应贝叶斯神经网络图片，您会了解到改变正则化的零点可能是个好主意，否则您将在模型的泛化方式中得到虚假相关性<span class="footnote-reference" role="doc-noteref" id="fnreflpb1b2qcoen"><sup><a href="#fnlpb1b2qcoen">[7]</a></sup></span> 。您可以拆分数据集并训练单独的较小模型，然后巧妙地聚合这些模型（类似于<a href="https://www.kaggle.com/code/prashant111/bagging-vs-boosting">装袋和提升</a>），以降低集成的计算溢价<span class="footnote-reference" role="doc-noteref" id="fnrefen0yeoqzg0k"><sup><a href="#fnen0yeoqzg0k">[10]</a></sup></span> 。这些论文中暗示，聪明的集成技巧在更大的尺度上并不那么重要，但目前还不清楚收益是否完全为零。</p><p>集成的一个棘手部分是，如果一枚硬币正面朝上的概率为 51%，并且您已训练神经网络以获得正确答案，那么集成中的每个成员都会预测正面。正确答案并不不确定，因此您的团队表示不存在不确定性。如果您希望不确定性度量包含环境中的熵，则必须训练神经网络来估计该熵，这在很大程度上放弃了使用非预测损失的自由。</p><p>解释时的类似关注适用于在模型的潜在特征上使用集成，尽管我在文献中没有看到人们这样做。假设您训练了十几个模型，并用有关狗的数据探测它们，为每个模型找到一个“狗向量”。您可以对它们的大小和方差进行标准化，然后使用集合的方差作为“狗向量的不确定性”。这并不是关于狗的完全不确定性，因为它没有衡量人工智能模型中关于狗的不确定性，这只是不同模型根据特定探测方法的内部表示的传播。</p><p></p><h2>关于任意不确定性的注释</h2><p>文献中很大一部分文字是关于任意不确定性和认知不确定性之间的区别<span class="footnote-reference" role="doc-noteref" id="fnrefxqxuuw1xe2"><sup><a href="#fnxqxuuw1xe2">[11]</a></sup></span> 。当我说集成会告诉你由于建模选择而导致的输出的不确定性时，这就是我必须谈论的区别，但不会告诉你人工智能内部对环境的不确定性。在不确定性估计文献中，由于模型方差而产生的不确定性被称为“认知性”，而人工智能环境模型内部的不确定性被称为“随意性”。 <span class="footnote-reference" role="doc-noteref" id="fnref2jiolbj6tn8"><sup><a href="#fn2jiolbj6tn8">[12]</a></sup></span></p><p>在大数据限制下，认知不确定性相对于任意不确定性变得很小（除非你故意将模型推入高度认知不确定性的情况）。有些论文忘记了这一点，做了一些愚蠢的事情，使他们的认知不确定性估计更大，因为他们认为这应该是总的不确定性，这就是为什么其他论文必须用章节来讨论这种区别。</p><p></p><h2>添加噪声，由于某种原因通常会丢失</h2><p>如果您想要不确定性估计，您可以将随机噪声添加到神经网络的中间激活中。如果输出对噪声更敏感，则不确定性更大，如果输出不太敏感，则不确定性更小<span class="footnote-reference" role="doc-noteref" id="fnrefud7l8eu73jk"><sup><a href="#fnud7l8eu73jk">[13]</a></sup></span> 。有一些自然的启发式论证可以解释为什么这是有意义的<span class="footnote-reference" role="doc-noteref" id="fnreflgnhfp0m35e"><sup><a href="#fnlgnhfp0m35e">[14]</a></sup></span> ，并且通过更多的工作，您可以尝试将其与贝叶斯神经网络图和损失景观的蒙特卡洛估计联系起来。</p><p>或者，您可以忽略抽象参数并使用 dropout 作为随机噪声分布<span class="footnote-reference" role="doc-noteref" id="fnrefhfox6k7gfev"><sup><a href="#fnhfox6k7gfev">[15]</a></sup></span> 。</p><p>哦，当然，人们给出了理由，但我认为这里的第一印象是正确的，添加 dropout 然后采样在理论上是愚蠢的。但在实验上，它的效果很好，人们一直在谈论它<span class="footnote-reference" role="doc-noteref" id="fnref0hl862nst9f9"><sup><a href="#fn0hl862nst9f9">[16]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnrefu11lguv41wc"><sup><a href="#fnu11lguv41wc">[17]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnrefhzxdsrsco9g"><sup><a href="#fnhzxdsrsco9g">[18]</a></sup></span> ，而且它不需要你做任何额外的训练。</p><p>为什么它起作用的一个谜题可能是，在具有一些噪声样本的数据集上训练的网络将学会输出一个包罗万象的先验以响应噪声<span class="footnote-reference" role="doc-noteref" id="fnreffqljh5j8ipf"><sup><a href="#fnfqljh5j8ipf">[19]</a></sup></span> 。我怀疑 dropout 是足够大的噪音，它将网络推向这个先验，这有助于过度自信。</p><p>我希望人们对更小的、非丢失的噪声进行更多的比较<span class="footnote-reference" role="doc-noteref" id="fnrefvl2ahm3user"><sup><a href="#fnvl2ahm3user">[20]</a></sup></span> 。这在理论上似乎更合理，尽管当翻译回贝叶斯术语时，将噪声注入内部层似乎对应于有趣但不寻常的噪声分布。</p><p></p><h2>校准</h2><p>文献<span class="footnote-reference" role="doc-noteref" id="fnref0hl862nst9f9"><sup><a href="#fn0hl862nst9f9">[16]</a></sup></span>的很大一部分是人们只是试图获取神经网络的输出并对它们应用简单的函数来获得不确定性估计。我将简要地对待他们。</p><p>第 0 级只是按面值获取 NN 输出。当数据较多且参数不确定性较小时，神经网络的直接预测可以很好地估计不确定性。例如，基础 GPT-4 在分配给下一个标记的概率分布中得到了很好的校准，包括当这些下一个标记是以前从未见过的测试问题的答案时<span class="footnote-reference" role="doc-noteref" id="fnrefzkojoz799ka"><sup><a href="#fnzkojoz799ka">[21]</a></sup></span> 。即使是非分布，这也比什么都没有好——正如我上面提到的，如果神经网络的训练集包含意外数据，那么它们确实会学会不确定意外数据<span class="footnote-reference" role="doc-noteref" id="fnreffqljh5j8ipf"><sup><a href="#fnfqljh5j8ipf">[19]</a></sup></span> ，尽管它们仍然倾向于过度自信。</p><p>随着模型的泛化能力越来越强，我预计它们的输出能够在更大的领域得到很好的校准。相反，对于在有限数据上训练小型模型的应用程序，您将需要一种不同的方法来估计不确定性。</p><p>通常人们会尝试比第 0 级更奇特一些，并做一些事情，比如调整 softmax 函数的参数，以最大限度地提高对保留验证集的校准<span class="footnote-reference" role="doc-noteref" id="fnrefnglt70rybd9"><sup><a href="#fnnglt70rybd9">[22]</a></sup></span> 。这也很容易与其他方法结合作为最终校准步骤<span class="footnote-reference" role="doc-noteref" id="fnrefgx8tqfun0w"><sup><a href="#fngx8tqfun0w">[23]</a></sup></span> 。</p><p>如果您有分布外 (OOD) 数据样本，您还可以做更奇特的事情，例如同时进行 OOD 检测和校准<span class="footnote-reference" role="doc-noteref" id="fnreftmgq2x5m6t"><sup><a href="#fntmgq2x5m6t">[24]</a></sup></span> 。或者，如果您有 OOD 数据样本并且是频率论者，则可以进行保形预测<span class="footnote-reference" role="doc-noteref" id="fnrefg3rtbqm4247"><sup><a href="#fng3rtbqm4247">[25]</a></sup></span> 。</p><p>校准的一个卖点是您可以对任何经过训练的模型执行此操作。但如果您愿意放弃这一点并干预训练，就有一些方法可以改进模型的校准。这可能看起来像使用额外的正则化<span class="footnote-reference" role="doc-noteref" id="fnrefqbdlqupa3x"><sup><a href="#fnqbdlqupa3x">[26]</a></sup></span>或对比示例<span class="footnote-reference" role="doc-noteref" id="fnref2qfcvdqkx2y"><sup><a href="#fn2qfcvdqkx2y">[27]</a></sup></span>进行训练。这些也在一定程度上提高了 OOD 泛化能力，对抗性训练也是如此<span class="footnote-reference" role="doc-noteref" id="fnrefazba93s687"><sup><a href="#fnazba93s687">[28]</a></sup></span> 。</p><p>最终，网络输出的校准似乎并没有达到我想要的不确定性估计方法的效果。其一，它不会估计潜在特征的不确定性，而是与您拥有数据的输出的不确定性有关。</p><p>另一方面，它<a href="https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation">缺乏搜索的鲁棒性</a><span class="footnote-reference" role="doc-noteref" id="fnrefv1gf6chx43"><sup><a href="#fnv1gf6chx43">[29]</a></sup></span> 。确实，所有其他不确定性估计方法在优化时也应该容易受到对抗性示例的影响（部分原因是对抗性示例是特征，而不是错误<span class="footnote-reference" role="doc-noteref" id="fnrefa3kc8qjhdn6"><sup><a href="#fna3kc8qjhdn6">[30]</a></sup></span> ），但是当网络输出及其不确定性估计是相同的时，对良好输出的本地搜索应该<i>特别</i>有效地找到奇怪的意想不到的最佳值<span class="footnote-reference" role="doc-noteref" id="fnref28983dpfjdp"><sup><a href="#fn28983dpfjdp">[31]</a></sup></span> 。</p><p></p><h2>训练高阶模型</h2><p>校准的另一面。首先让你的神经网络为你提供更好的不确定性估计。</p><p>如果您想获得二阶不确定性的估计，请训练神经网络以输出<a href="https://en.wikipedia.org/wiki/Dirichlet_distribution#Occurrence_and_applications">狄利克雷分布</a>的参数，而不是进行正常分类<span class="footnote-reference" role="doc-noteref" id="fnrefkm10b29by7c"><sup><a href="#fnkm10b29by7c">[32]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnrefhfc8x4hav0b"><sup><a href="#fnhfc8x4hav0b">[33]</a></sup></span> 。或者，如果您正在进行回归，请训练神经网络以输出答案的分布参数<span class="footnote-reference" role="doc-noteref" id="fnrefen0yeoqzg0k"><sup><a href="#fnen0yeoqzg0k">[10]</a></sup></span> 。或者，如果您拥有法学硕士并且每个问题都是钉子，请训练您的法学硕士用语言表达不确定性<span class="footnote-reference" role="doc-noteref" id="fnrefffdudph3qus"><sup><a href="#fnffdudph3qus">[34]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnrefadsp4hkxuk"><sup><a href="#fnadsp4hkxuk">[35]</a></sup></span> 。</p><p>表达不确定性的训练模型存在一个微妙的问题：不存在适当的二阶损失函数<span class="footnote-reference" role="doc-noteref" id="fnrefxuwhb9ieyh"><sup><a href="#fnxuwhb9ieyh">[36]</a></sup></span> 。这意味着仅从数据点出发，很难准确地训练模型来给出概率分布 - 您可以创建损失函数来尝试做到这一点，但只要您只监督正确答案是什么，而不监督正确答案是什么。正确的概率分布是，通过损失最小化得到的概率分布将会有偏差。</p><p>贝叶斯方法，或者至少是贝叶斯理论框架，在这里会很有用。您不需要适当的损失函数来进行贝叶斯更新。但还没有人写下该应用程序的贝叶斯神经网络图的类似物。</p><p>理论上也不清楚如何整合我们可以获得的有关概率分布的其他类型的监督数据。例如，人为噪声的例子可以给出直接的监督信号，表明正确的概率分布是高熵的。或者，我们可以通过询问“我期望我对正确答案的估计随着更多数据而改变多少？”来学习分布。它的监督分布在整个数据集中，因此绕过了没有适当评分规则的证明 - 但我们可以以公正的方式做到这一点吗？</p><p></p><h2>比较方法</h2><p>那么，哪个是最好的？</p><p>目前，它正在训练一个整体。但训练高阶模型具有尚未开发的潜力。</p><p>情况尚不清楚，因为比较是在玩具问题上进行的，文献很少并且并不总是重复，比较很困难，因为每种方法都有十几种变体，而且不同的论文有时会评估完全不同的指标。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/xptyd74vj7qmuirlgkdq" alt="该图显示了一些神经网络曲线与不同方法生成的误差条的拟合情况。" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/h6cj9a57suxcupp18t15 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/uqc5c2ci9zjyioeqilyd 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/dgoocd9ekrsj4v2ldc3f 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/pbdddhbajg3sxt9ixtsy 680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/bavrtb78i5icyf0kiyki 850w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/r4pe2oeov2q0fyqkckyj 1020w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/uraeyjenw52atepowgt4 1190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/lsoqntf6avhbtk0qkyhp 1360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/dbifkkrzkczba42uqllp 1530w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/dcy3kxiejmh9igglcn63 1603w"><figcaption>来自<a href="https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment#fnlpb1b2qcoen">参考文献。 7</a> .玩具曲线拟合问题的不确定性估计方法比较。<br><br> Ground Truth 是一个贝叶斯神经网络，Hamiltonian MC 是它的一个很好的蒙特卡洛近似，变分推理是它的一个廉价近似，MC Dropout 根据 dropout 后的方差估计不确定性，而我们的方法是一个具有奇特初始化的集成。</figcaption></figure><p>这个数字是一个不错的直觉泵。它在玩具曲线拟合任务（只有<span class="footnote-reference" role="doc-noteref" id="fnreflpb1b2qcoen"><sup><a href="#fnlpb1b2qcoen">6</a></sup></span>个数据点的回归问题）上比较了不确定性估计方法（尽管它明显错过了校准和高阶建模），每种方法都使用 ReLU 与 Sigmoid。我认为这个数字的一​​些定性印象是概括性的。</p><p>印象笔记：</p><ul><li>贝叶斯神经网络、蒙特卡洛近似和集成方法都做出了类似的预测。</li><li>架构对于泛化属性来说非常重要，在某种程度上使这些方法看起来过于自信。 （整合不同的架构将是一个好的开始，但没有人这样做。）</li><li> Dropout 和变分推理近似在数据点附近的置信度都低于集成簇，但在分布之外的置信度更高。</li></ul><p>在对 CIFAR-10 或 LSTM 语言模型<span class="footnote-reference" role="doc-noteref" id="fnrefhzxdsrsco9g"><sup><a href="#fnhzxdsrsco9g">[18]</a></sup></span>或医学 MRI 数据<span class="footnote-reference" role="doc-noteref" id="fnrefu11lguv41wc"><sup><a href="#fnu11lguv41wc">[17]</a></sup></span>进行更彻底的比较（现在包括校准）时，集成似乎是最好的方法。但老实说，我提到的所有方法都非常接近，在复杂任务上，dropout 比玩具模型所建议的更有竞争力，而变分推理在 MNIST 上表现得令人惊讶。</p><p>高阶建模出现在较少的比较中。但这是参考文献中的一个数字。 31 其中模型在 MNIST 上进行训练，然后在<a href="https://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html">非 MNIST</a>上进行测试<span class="footnote-reference" role="doc-noteref" id="fnrefkm10b29by7c"><sup><a href="#fnkm10b29by7c">[32]</a></sup></span> 。学习分类输出上的狄利克雷分布（EDL 虚线）与包的其余部分不同，就像包与原始模型输出（蓝色 L2 线）的不同一样： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/iyp8dpi29scplwjsybyy" alt="该图显示高阶建模给出了分布的高熵猜测。" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/p6hfgbwkaxi6erapiwuq 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/jomn5fobieqqetqjk169 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/pi2t8mbqbba98fa0jpou 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/w6trrvylxr34gdixbcwx 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/ehphdoebwsegtp3qtlsb 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/bnaqfkt3qw2dubftvxql 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/kejhllk816mnmsjsnixm 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/urqu1kjrrbmc5dvnlfbw 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/t99gmgzve5q2xvdbicct 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/ba87fp8izpeheft8u4ka 829w"><figcaption>来自<a href="https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment#fnkm10b29by7c">参考文献。 32</a> . OOD 数据集上输出熵的积分直方图（或累积分布）。训练是在 MNIST 上进行的，但测试是在<a href="https://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html">非 MNIST</a>上进行的，因此具有更高的高熵概率是好的。<br><br> EDL 是他们的狄利克雷分布模型，L2 是原始模型输出，DeepEnsemble 是一个集成，FFLU 不清楚但可能是贝叶斯 NN 近似，Dropout 是 dropout，FFG 是贝叶斯 NN 方法，MNFG 是变分推理近似。</figcaption></figure><p>当显示 OOD 数据时，这是一种非常令人印象深刻的不确定能力。是的，在分布上（在 MNIST 上）它具有正常的准确性。显然，学习何时不确定就是获取一些其他方法无法获取的信息。</p><p>但如此不确定真的正确吗？假设您正在对数字进行分类，这就是您所知道的，然后有人输入字符“B”。这肯定是8，对吧？或者也许是一个被压在一起的 13，如果你能想到这个想法的话。但它肯定不是 2。既然你知道这一点，那么在这里返回最大熵分布将是一个错误。但这似乎正是狄利克雷分布模型倾向于做的事情。</p><p>我希望高阶模型与论文中其他所有内容之间的不同行为是因为这些方法具有不同的背景假设，如果我们知道我们在做什么，我们可以在适当的时候灵活地使用不同的假设。</p><p></p><h2>我未来想从事这个领域的工作</h2><ul><li>更大的尺度<ul><li>对 Transformer 语言模型的不确定性估计进行基准测试。</li></ul></li><li>搜索的鲁棒性<ul><li>看看认知不确定性对对抗性例子有何影响。</li><li>分析找到新的对抗性例子来欺骗不确定性估计和原始指​​标是多么容易。检查这些例子对人类来说是否自然。</li></ul></li><li>非压差噪声<ul><li>当您向神经网络添加噪声时，改进采样的理论。</li><li>对不同类型的噪声进行相互比较和其他方法的基准测试。</li></ul></li><li>合奏带来更多聪明的事情<ul><li>测试改变架构的集成。</li><li>测试正在探索“相同”潜在特征的集合。</li></ul></li><li>更好的高阶模型<ul><li>发展神经网络学习二阶分布的贝叶斯视角。</li><li>通过尝试转化理论和修补信号（例如预测未来更新），为高阶模型开发更好的训练方法。</li><li>弄清楚如何使用高阶建模来获得不同背景假设的不确定性。</li></ul></li><li>更好的比较<ul><li>更系统地比较校准和 Brier 评分。</li><li>对决策问题进行基准测试，为分布数据之外的“良好行为”提供具体标准。</li><li>开发包含“自然”分布泛化的标记数据集，我们可以将其类比为现实世界中模型完成的 OOD 泛化。</li></ul></li><li>更多协同效应<ul><li>通过将多种方法结合在一起，可以获得更好的结果。校准太容易与一切结合起来，尽管它仍然是一个好主意，但这不算新闻。</li></ul></li></ul><p>如果这些论文确实存在而我错过了，请告诉我。如果他们不这样做，并且其中一个项目听起来像是您想做的事情，请联系我 - 我很乐意聊天。</p><p></p><h2>与一致性、结论的相关性</h2><p>文献与对齐的相关性不如我的预期，但这主要是因为我的期望被混淆了。我对某种“人类价值观的不确定性”感兴趣，它不同于文献中的“任意”或“认知”不确定性。</p><p>任意不确定性是从数据中得知的，但我们没有人类价值观的真实标签。或者，如果模型中有一些与人类价值观相关的潜在特征，我们不仅仅想了解该特征在某些训练集上的方差。</p><p>认知不确定性更接近，但正如文献中所使用的那样，它实际上是关于某些输出或特征对于训练目标的有用程度。在训练过程中收敛到相同答案的模型越多，认知不确定性就越小。但相对于我想要的，这感觉好像缺少一些关于首先使用什么训练程序或特征检测程序的不确定性<span class="footnote-reference" role="doc-noteref" id="fnrefmyfeye042z"><sup><a href="#fnmyfeye042z">[37]</a></sup></span> 。</p><p>正确的训练/特征检测程序的不确定性偏离了“有一个基本事实答案，不确定性是与该答案的预期偏差”的通常范式。为了保持一致，我认为图片应该更像是通信——我们试图通过架构和数据向人工智能传达一些信息，而人工智能应该对如何解释它有不确定性。</p><p>构建这种关于人类价值观的不确定性是相当棘手的——我什至还不知道我想从中得到什么！也许如果我们更清楚地理解我们想要什么，我们就可以用更标准的不确定性来构建它。例如，我们可以设计一个人工智能可以玩的“游戏”，激励对人类概念的不同解释，这样游戏中的任意和认知不确定性就可以充分捕捉到我们希望人工智能对人类价值观具有的不确定性。</p><p></p><p><i>这篇文章部分写于</i><a href="https://www.mitalignment.org/"><i>MAIA</i></a> <i>。谢谢玛雅！还有贾斯蒂斯·米尔斯（Justis Mills）进行编辑，以及波士顿的各种人士进行对话。</i> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn80ywo0pbl8r"> <span class="footnote-back-link"><sup><strong><a href="#fnref80ywo0pbl8r">^</a></strong></sup></span><div class="footnote-content"><p>主动学习文献调查。<i>伯尔·塞特尔斯</i>(2010) <a href="https://burrsettles.com/pub/settles.activelearning.pdf">https://burrsetles.com/pub/settles.activelearning.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnq23duy4ut0g"> <span class="footnote-back-link"><sup><strong><a href="#fnrefq23duy4ut0g">^</a></strong></sup></span><div class="footnote-content"><p>优化器的诅咒：决策分析中的怀疑主义和决策后惊喜。<i>詹姆斯·E·史密斯、罗伯特·L·温克勒</i>(2006) <a href="https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1050.0451">https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1050.0451</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn3dij2j9svj8"> <span class="footnote-back-link"><sup><strong><a href="#fnref3dij2j9svj8">^</a></strong></sup></span><div class="footnote-content"><p>用于检测神经网络中错误分类和分布外示例的基线。<i>丹·亨德里克斯、凯文·金佩尔</i>(2016) <a href="https://arxiv.org/abs/1610.02136">https://arxiv.org/abs/1610.02136</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnfo4svcpvxs"> <span class="footnote-back-link"><sup><strong><a href="#fnreffo4svcpvxs">^</a></strong></sup></span><div class="footnote-content"><p>使用贝叶斯统计进行神经网络不确定性评估并应用于遥感。 <i>F. Aires、C. Prigent、WB Rossow</i> (2004)</p><p>第 1 部分：网络权重<a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004173">https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004173</a></p><p>第 2 部分：输出错误<a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004174">https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004174</a></p><p>第 3 部分：网络雅可比矩阵<a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004175">https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004175</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fncogdul3x2xj"> <span class="footnote-back-link"><sup><strong><a href="#fnrefcogdul3x2xj">^</a></strong></sup></span><div class="footnote-content"><p>深度学习中不确定性估计的通用框架。<i>安东尼奥·洛奎西奥、马蒂亚·塞古、大卫·斯卡拉穆扎</i>(2020) <a href="https://www.zora.uzh.ch/id/eprint/197704/1/RAL20_Loquercio.pdf">https://www.zora.uzh.ch/id/eprint/197704/1/RAL20_Loquercio.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnamk58pvab4"> <span class="footnote-back-link"><sup><strong><a href="#fnrefamk58pvab4">^</a></strong></sup></span><div class="footnote-content"><p> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="P(parameters)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;">如果</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">P</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">是</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">高斯</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">分布</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">（</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">指数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">L2</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">正</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">则</span></span></span></span></span></span></span>化），并且您的损失是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(dataset \; | \; parameters)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">对</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">损失</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">，</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">因此</span></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">P</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">集</span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">是</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">它</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">的</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">指数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">。</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span></span></span></span></span></span></p></div></li><li class="footnote-item" role="doc-endnote" id="fnlpb1b2qcoen"><span class="footnote-back-link"><sup><strong><a href="#fnreflpb1b2qcoen">^</a></strong></sup></span><div class="footnote-content"><p>神经网络的不确定性：近似贝叶斯集成。<i>蒂姆·皮尔斯、菲利克斯·莱布弗里德、亚历山德拉·布林特鲁普、穆罕默德·扎基、安迪·尼利</i>(2020) <a href="http://proceedings.mlr.press/v108/pearce20a/pearce20a.pdf">http://proceedings.mlr.press/v108/pearce20a/pearce20a.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnd9jz9mfml"> <span class="footnote-back-link"><sup><strong><a href="#fnrefd9jz9mfml">^</a></strong></sup></span><div class="footnote-content"><p>最明显的问题是 Hessian 矩阵的奇点。但在短长度尺度上，损失情况也可能会很复杂，使得低阶近似有时会失败。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnbct5kii2m07"> <span class="footnote-back-link"><sup><strong><a href="#fnrefbct5kii2m07">^</a></strong></sup></span><div class="footnote-content"><p>面向神经网络的校准和可扩展的不确定性表示。<i>纳比尔·西达特、克里斯托弗·卡南</i>(2019) <a href="https://arxiv.org/abs/1911.00104">https://arxiv.org/abs/1911.00104</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnen0yeoqzg0k"> <span class="footnote-back-link"><sup><strong><a href="#fnrefen0yeoqzg0k">^</a></strong></sup></span><div class="footnote-content"><p>使用深度集成的简单且可扩展的预测不确定性估计。 <i>Balaji Lakshminarayanan、Alexander Pritzel、Charles Blundell</i> (2017) <a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/9ef2ed4b7fd2c810847ffa5fa85bce38-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2017/file/9ef2ed4b7fd2c810847ffa5fa85bce38-Paper.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnxqxuuw1xe2"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxqxuuw1xe2">^</a></strong></sup></span><div class="footnote-content"><p>计算机视觉的贝叶斯深度学习需要哪些不确定性？<i>亚历克斯·肯德尔，亚林·加尔</i>(2017) <a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/2650d6089a6d640c5e85b2b88265dc2b-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2017/file/2650d6089a6d640c5e85b2b88265dc2b-Paper.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn2jiolbj6tn8"> <span class="footnote-back-link"><sup><strong><a href="#fnref2jiolbj6tn8">^</a></strong></sup></span><div class="footnote-content"><p>源自希腊语，意思是“关于知识”和“关于赌博”。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnud7l8eu73jk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefud7l8eu73jk">^</a></strong></sup></span><div class="footnote-content"><p> 2 如何仅在给定模型权重的情况下判断你的输入是否不符合分布， <i>dkirmani</i> (2023) <a href="https://www.lesswrong.com/posts/tvLi8CyvvSHrfte4P/how-2-tell-if-ur-input-is-out-of-distribution-given-only">https://www.lesswrong.com/posts/tvLi8CyvvSHrfte4P/how-2-tell-if-ur-input-is-out-of -仅给定分布</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnlgnhfp0m35e"><span class="footnote-back-link"><sup><strong><a href="#fnreflgnhfp0m35e">^</a></strong></sup></span><div class="footnote-content"><p>现实世界中存在噪声，因此，如果小的输入噪声极大地改变了您的答案，您就不应该对此充满信心。相反，在表现良好的输入上，神经网络学会对噪声具有鲁棒性。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnhfox6k7gfev"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhfox6k7gfev">^</a></strong></sup></span><div class="footnote-content"><p>密集回归的免训练不确定性估计：灵敏度作为替代。<i>卢米、王浩、田永龙、何浩、Nir Shavit</i> (2022) <a href="https://arxiv.org/abs/1910.04858">https://arxiv.org/abs/1910.04858</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn0hl862nst9f9"> <span class="footnote-back-link"><sup><strong><a href="#fnref0hl862nst9f9">^</a></strong></sup></span><div class="footnote-content"><p>深度神经网络不确定性调查。<i>雅各布·高利科斯基等人。</i> (2021) <a href="https://arxiv.org/abs/2107.03342">https://arxiv.org/abs/2107.03342</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnu11lguv41wc"> <span class="footnote-back-link"><sup><strong><a href="#fnrefu11lguv41wc">^</a></strong></sup></span><div class="footnote-content"><p>估计心脏 MRI 分割神经网络的不确定性：一项基准研究。<i>马修·吴、富民·郭、Labonny Biswas、Steffen E. Petersen、Stefan K. Piechnik、Stefan Neubauer、Graham Wright</i> (2023) <a href="https://ieeexplore.ieee.org/abstract/document/10002847">https://ieeexplore.ieee.org/abstract/document/10002847</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnhzxdsrsco9g"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhzxdsrsco9g">^</a></strong></sup></span><div class="footnote-content"><p>你能相信你的模型的不确定性吗？评估数据集变化下的预测不确定性。 <i>Yaniv Ovadia、Emily Fertig、Jie Ren、Zachary Nado、D Sculley、Sebastian Nowozin、Joshua V. Dillon、Balaji Lakshminarayanan、Jasper Snoek</i> (2019) <a href="https://arxiv.org/abs/1906.02530">https://arxiv.org/abs/1906.02530</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnfqljh5j8ipf"> <span class="footnote-back-link"><sup><strong><a href="#fnreffqljh5j8ipf">^</a></strong></sup></span><div class="footnote-content"><p>深度神经网络倾向于进行可预测的推断。<i>凯蒂·康、阿姆里斯·塞特勒、克莱尔·汤姆林、谢尔盖·莱文</i>(2023) <a href="https://arxiv.org/abs/2310.00873">https://arxiv.org/abs/2310.00873</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnvl2ahm3user"> <span class="footnote-back-link"><sup><strong><a href="#fnrefvl2ahm3user">^</a></strong></sup></span><div class="footnote-content"><p>对于分布外检测来说似乎更常见，例如增强神经网络中分布外图像检测的可靠性。<i>梁世宇、李亦轩、R.Srikant</i> (2020) <a href="https://arxiv.org/abs/1706.02690">https://arxiv.org/abs/1706.02690</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnzkojoz799ka"> <span class="footnote-back-link"><sup><strong><a href="#fnrefzkojoz799ka">^</a></strong></sup></span><div class="footnote-content"><p> GPT-4 技术报告。 <i>OpenAI</i> (2023) <a href="https://openai.com/research/gpt-4">https://openai.com/research/gpt-4</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnnglt70rybd9"> <span class="footnote-back-link"><sup><strong><a href="#fnrefnglt70rybd9">^</a></strong></sup></span><div class="footnote-content"><p> Mix-n-Match：深度学习中不确定性校准的集成和组合方法。<i>张继泽、Bhavya Kailkhura、T. Yong-Jin Han</i> (2020) <a href="https://arxiv.org/abs/2003.07329">https://arxiv.org/abs/2003.07329</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fngx8tqfun0w"> <span class="footnote-back-link"><sup><strong><a href="#fnrefgx8tqfun0w">^</a></strong></sup></span><div class="footnote-content"><p>不确定性量化和深度集成。<i>拉胡尔·拉哈曼、亚历山大·H·蒂埃里</i>(2020) <a href="https://arxiv.org/abs/2007.08792">https://arxiv.org/abs/2007.08792</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fntmgq2x5m6t"> <span class="footnote-back-link"><sup><strong><a href="#fnreftmgq2x5m6t">^</a></strong></sup></span><div class="footnote-content"><p>在分布外数据集上校准深度神经网络分类器。<i>邵志辉、杨建一、任少雷</i>(2020) <a href="https://arxiv.org/abs/2006.08914">https://arxiv.org/abs/2006.08914</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fng3rtbqm4247"> <span class="footnote-back-link"><sup><strong><a href="#fnrefg3rtbqm4247">^</a></strong></sup></span><div class="footnote-content"><p>归纳共形预测：神经网络的理论与应用。<i>哈里斯·帕帕佐普洛斯</i>(2008) <a href="https://www.intechopen.com/chapters/5294">https://www.intechopen.com/chapters/5294</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnqbdlqupa3x"> <span class="footnote-back-link"><sup><strong><a href="#fnrefqbdlqupa3x">^</a></strong></sup></span><div class="footnote-content"><p>通过 Logit 归一化缓解神经网络过度自信。<i>魏洪欣、谢仁春子、程浩、冯雷、安博、李一轩</i>(2022) <a href="https://proceedings.mlr.press/v162/wei22d/wei22d.pdf">https://proceedings.mlr.press/v162/wei22d/wei22d.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn2qfcvdqkx2y"> <span class="footnote-back-link"><sup><strong><a href="#fnref2qfcvdqkx2y">^</a></strong></sup></span><div class="footnote-content"><p>使用噪声对比先验对深度神经网络进行可靠的不确定性估计。 <i>Danijar Hafner、Dustin Tran、Timothy Lillicrap、Alex Irpan、James Davidson</i> (2018) <a href="https://openreview.net/forum?id=HkgxasA5Ym">https://openreview.net/forum?id=HkgxasA5Ym</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnazba93s687"> <span class="footnote-back-link"><sup><strong><a href="#fnrefazba93s687">^</a></strong></sup></span><div class="footnote-content"><p>通过对抗性训练和预训练改进 OOD 泛化。<i>易明阳、侯鲁、孙家成、尚立峰、蒋欣、刘群、马志明</i>(2021) <a href="http://proceedings.mlr.press/v139/yi21a/yi21a.pdf">http://proceedings.mlr.press/v139/yi21a/yi21a.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnv1gf6chx43"> <span class="footnote-back-link"><sup><strong><a href="#fnrefv1gf6chx43">^</a></strong></sup></span><div class="footnote-content"><p> SolidGoldMagikarp（加上，提示生成）。<i>杰西卡·朗贝罗、马修·沃特金斯</i>(2023)<i> </i><a href="https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation">https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt- Generation</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fna3kc8qjhdn6"> <span class="footnote-back-link"><sup><strong><a href="#fnrefa3kc8qjhdn6">^</a></strong></sup></span><div class="footnote-content"><p>对抗性例子不是错误，而是特征。<i>安德鲁·伊利亚斯等人。</i> （2019） <a href="https://arxiv.org/abs/1905.02175">https://arxiv.org/abs/1905.02175</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn28983dpfjdp"> <span class="footnote-back-link"><sup><strong><a href="#fnref28983dpfjdp">^</a></strong></sup></span><div class="footnote-content"><p>如果我们使用生成而不是搜索来构建良好的输出，则可以回避优化不稳健的问题。或者在强化学习环境中，如果我们使用策略预测器将我们保持在系统的有效性范围内。但这是昂贵的，有时容易受到以不同速率泛化的能力的影响。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnkm10b29by7c"> <span class="footnote-back-link"><sup><strong><a href="#fnrefkm10b29by7c">^</a></strong></sup></span><div class="footnote-content"><p>用于量化分类不确定性的证据深度学习。<i>穆拉特·森索伊、兰斯·卡普兰、梅利赫·坎德米尔</i>(2018) <a href="https://arxiv.org/abs/1806.01768">https://arxiv.org/abs/1806.01768</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnhfc8x4hav0b"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhfc8x4hav0b">^</a></strong></sup></span><div class="footnote-content"><p>使用狄利克雷深度神经网络识别域外对象。<i>艾哈迈德·哈曼、弗兰克·博纳伦斯、赛义德·E·戈巴迪、克里斯托夫·斯蒂勒</i>(2023) <a href="https://openaccess.thecvf.com/content/ICCV2023W/UnCV/papers/Hammam_Identifying_Out-of-Domain_Objects_with_Dirichlet_Deep_Neural_Networks_ICCVW_2023_paper.pdf">https://openaccess.thecvf.com/content/ICCV2023W/UnCV/papers/Hammam_Identifying_Out-of-Domain_Objects_with_Dirichlet_Deep_Neural_Networks_ICCVW_2023_paper.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnffdudph3qus"> <span class="footnote-back-link"><sup><strong><a href="#fnrefffdudph3qus">^</a></strong></sup></span><div class="footnote-content"><p>教学模型用言语表达不确定性。<i>斯蒂芬妮·林、雅各布·希尔顿、欧文·埃文斯</i>(2023) <a href="https://openreview.net/forum?id=8s8K2UZGTZ">https://openreview.net/forum?id=8s8K2UZGTZ</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnadsp4hkxuk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefadsp4hkxuk">^</a></strong></sup></span><div class="footnote-content"><p>直接从 GPT-3 中导出概率。<i>努诺·森佩雷</i>(2023) <a href="https://forum.effectivealtruism.org/posts/aGmhi4uvAJptY8TA7/straightforwardly-eliciting-probabilities-from-gpt-3#Fine_tune_the_model_on_good_worked_examples_of_forecasting_reasoning">https://forum. effectivealtruism.org/posts/aGmhi4uvAJptY8TA7/straightforwardly-eliciting-probabilities-from-gpt-3#Fine_tune_the_model_on_good_worked_examples_of_forecasting_reasoning</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnxuwhb9ieyh"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxuwhb9ieyh">^</a></strong></sup></span><div class="footnote-content"><p>关于认知不确定性量化的二阶评分规则。<i>维克托·本格斯、艾克·胡勒迈尔、威廉·韦格曼</i>(2023) <a href="https://arxiv.org/abs/2301.12736">https://arxiv.org/abs/2301.12736</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnmyfeye042z"> <span class="footnote-back-link"><sup><strong><a href="#fnrefmyfeye042z">^</a></strong></sup></span><div class="footnote-content"><p>我可能还会提到关于使用什么抽象或使用什么推理程序的不确定性。但这些似乎是培训的下游。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment<guid ispermalink="false"> 79eegMp3EBs8ptFqa</guid><dc:creator><![CDATA[Charlie Steiner]]></dc:creator><pubDate> Tue, 05 Dec 2023 08:01:32 GMT</pubDate></item><item><title><![CDATA[Analyzing the Historical Rate of Catastrophes]]></title><description><![CDATA[Published on December 5, 2023 6:30 AM GMT<br/><br/><p>为了传达风险，我们经常求助于故事。核武器让人想起相互毁灭、带有红色按钮的公文包和核冬天的故事。气候变化让人想起极端天气、海平面上升淹没城市和农作物歉收的故事。新冠疫情之后的流行病几乎不需要想象力，但以前却是<em><a href="https://en.wikipedia.org/wiki/Contagion_(2011_film)?ref=bounded-regret.ghost.io">《传染病》</a></em>等电影的主题。</p><p>故事非常适合传达具体的风险（我自己<a href="https://bounded-regret.ghost.io/gpt-2030-and-catastrophic-drives-four-vignettes/">最近就人工智能风险做了这件事</a>），但它们不是预测未来的好方法。这是因为大多数故事都过于具体，不可能发生。更重要的是，故事往往具有简短、简单的因果链，而现实则复杂且具有多种因果关系。</p><p>大多数有竞争力的预测者不是使用故事，而是通过查看历史<a href="https://forecasting.quarto.pub/book/base-rates.html?ref=bounded-regret.ghost.io">参考类别</a>来开始预测。这非常有效，而且也很有意义：历史通过以实际发生的事件为基础，使我们摆脱了讲故事的偏见。虽然历史是通过叙述来过滤的，但好的历史将与现实的复杂性相抗衡，我们可以通过基于原始数字来进一步剥离叙述。 <sup><a href="#fn1">[1]</a></sup></p><p>在这篇文章中，我将使用参考课程来了解当今社会面临的最大风险。我将通过考虑历史灾难​​的两个不同参考类来做到这一点：</p><ul><li>导致全球大部分人口死亡的事件（<a href="#historical-causes-of-human-population-loss">第 1 节</a>）</li><li>物种灭绝，特别是大规模灭绝事件（<a href="#species-extinctions">第 2 节</a>）</li></ul><p>通过查看这些参考课程，我们学到了两件事。首先，它为我们提供了不同灾难的罕见程度的数值估计。如果我们将灾难定义为十年内导致全球 1% 人口死亡的事件，那么自 1500 年以来，已经发生了 11 起此类灾难，每年发生的基准率为 2%。如果我们提高杀死 10% 人口的标准，基本死亡率就会下降一个数量级，降至 0.2%。</p><p>历史也为我们提供了定性的见解。例如，上一段中的灾难都是流行病、战争或饥荒。此外，许多事件都是多重原因造成的——最严重的流行病发生在人口已经因饥荒而虚弱的时候，而许多流行病和饥荒是由于气候变化或政治动荡而加剧的。物种灭绝也是多因素造成的，常见的罪魁祸首是气候变化、自然灾害、入侵物种和人类。</p><p>反对使用历史基本利率的一个论点是，现在与过去如此不同（例如由于技术），以至于基本利率毫无意义。虽然当今世界确实与过去不同，但基本利率可以通过澄清实际上的新内容来帮助加剧而不是忽视这些差异。例如，仅仅技术的存在并不能让我们远远高于基本速度，因为历史上已经开发了许多技术，但没有一项技术造成了上述意义上的灾难。相反，我们应该寻找与灾难的历史驱动因素具有共同特征的技术：流行病、饥荒、战争、政治动荡、气候变化、自然灾害、入侵物种和人类。</p><p>我详细分析了这些驱动程序（<a href="#takeaways-for-modern-catastrophes-and-for-ai">第 3 节</a>），发现它们分为几个核心组：</p><ul><li>全球或区域规模的自然事件（饥荒、气候变化、自然灾害）</li><li>新型、高度适应、自我复制的生物体（流行病、新型病原体和捕食者、入侵物种）</li><li>协调一致的人类群体寻求资源、土地或权力（战争、政治动荡、过度狩猎和栖息地破坏导致的灭绝）</li></ul><p>这个列表是有道理的——要产生全球影响，某件事要么应该从全球范围开始（大型自然事件），要么有办法到达那里（自我复制、协调）。</p><p>从这个角度来看，21世纪灾难的可能驱动因素是什么？从上面的列表中可以明显看出一些答案——流行病、气候变化和重大战争仍然是严重的威胁。与上一次重大饥荒发生在 1961 年相比，饥荒的威胁不那么明显，但为饥荒做好准备可能仍需谨慎。政治动荡虽然本身不​​是灾难性的，但却为其他灾难的发生创造了条件。</p><p>谈到新技术，工程病原体是危险的，因为它们是新型的自我复制器，<a href="https://en.wikipedia.org/wiki/Gray_goo?ref=bounded-regret.ghost.io">某些类型的纳米技术</a>也是如此。核武器是危险的，因为它们具有与自然灾害类似的影响，而且因为它们会增加战争造成的最坏损害。</p><p>最后，不幸的是，人工智能（我自己的研究领域）与许多灾难驱动因素具有共同的属性。它是一种新颖的自我复制器（它可以自我复制），可以快速适应新数据。人工智能系统可以被<a href="https://arxiv.org/abs/1705.08926?ref=bounded-regret.ghost.io">训练来协调</a>并<a href="https://bounded-regret.ghost.io/intrinsic-drives-and-extrinsic-misuse-two-intertwined-risks-of-ai/">可能寻求权力</a>，反映协调的人类群体的威胁。最后，如果人工智能导致经济动荡和随后的政治动荡，它可能会加剧灾难的其他驱动因素。</p><h1>人口减少的历史原因</h1><p>为了开始我们的分析，我研究了人口减少的最大历史原因，以特定事件导致的全球人口死亡比例来衡量。为此，我结合了维基百科上<a href="https://en.m.wikipedia.org/wiki/List_of_anthropogenic_disasters_by_death_toll?ref=bounded-regret.ghost.io#Wars_and_armed_conflicts">主要战争</a>、 <a href="https://en.m.wikipedia.org/wiki/List_of_anthropogenic_disasters_by_death_toll?ref=bounded-regret.ghost.io#Abuse_of_workers,_forced_laborers_and_slaves">奴隶制和其他强迫劳动</a>、<a href="https://en.m.wikipedia.org/wiki/List_of_famines?ref=bounded-regret.ghost.io">饥荒</a>、 <a href="https://en.m.wikipedia.org/wiki/List_of_epidemics_and_pandemics?ref=bounded-regret.ghost.io">流行病</a>和<a href="https://en.m.wikipedia.org/wiki/List_of_natural_disasters_by_death_toll?ref=bounded-regret.ghost.io">自然灾害</a>列表中的数据。我考虑了其他数据来源，例如技术灾难，但所有这些数据的死亡人数都比上述五个数据要少得多。主要的例外是种族灭绝，因为这些通常与战争同时发生，并且已经包含在死亡人数中，因此我将其排除在外以避免重复计算。</p><p>我编写了一个 Python 脚本（在<a href="#scraping-script">附录</a>中共享）来抓取这些源并将它们聚合到单个 Pandas 数据框中，然后进行过滤以创建两个数据集：</p><ul><li><strong>灾难</strong>：所有造成至少 0.1% 人口死亡的事件，计算方法是将总死亡人数除以事件开始时的世界人口。 <sup><a href="#fn2">[2]</a></sup> <sup><a href="#fn3">[3]</a></sup></li><li><strong>严格的灾难</strong>：我进一步限制“快速”（持续不到十年）且至少有 1% 的人口死亡的事件。</li></ul><p>这组灾难包括85个事件，其中80个发生在公元0年以来，其中33个是战争，28个是饥荒，15个是流行病，6个是强迫劳动，3个是自然灾害。严格的灾难包括17个事件：5次战争、8次饥荒和4次流行病。我在下面列出了严格灾难的完整列表，以及所有灾难的散点图（有关原始数据，请参阅<a href="#scraping-script">附录</a>）。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/zsdej27vshx817jxxgzq"></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/aoh79fzuiwbvftkounrs"></p><p>除了这些历史事件之外，两个重要的史前事件是<a href="https://en.wikipedia.org/wiki/Toba_catastrophe_theory?ref=bounded-regret.ghost.io">多巴灾难</a>（人口减少 97%，可能是由于超级火山）和<a href="https://en.wikipedia.org/wiki/4.2-kiloyear_event?ref=bounded-regret.ghost.io">4.2kya 事件</a>（可能导致全球饥荒，但死亡人数尚不清楚）。</p><p><strong>报告偏差和基准率。</strong>很可能存在报告偏差，因为我们看到灾难的发生率在 1500 年代“增加”，并在 1900 年代再次增加，这种情况发生在包括饥荒在内的所有类别中（随着技术的进步，随着时间的推移，饥荒应该会减少）。如果从 1500 年开始，有 51 次灾难（0.11/年）和 11 次严格灾难（0.02/年）。</p><p>接下来让我们模拟（快速）灾难<sup><a href="#fn4">[4]</a></sup>的基本发生率如何随其严重程度变化。纵观所有导致至少 1% 人口下降的灾难，我们看到近似的<a href="https://en.wikipedia.org/wiki/Zipf%27s_law?ref=bounded-regret.ghost.io">Zipfian</a>分布：死亡率为 r 的灾难的概率与 1/r 成正比。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/wgfcegdndv1dtfwggmzl"></p><p>据此，死亡率为10%的灾难发生率为0.002次/年（每5个世纪一次），死亡率为1%的灾难发生率为0.02次/年（每个世纪两次）。虽然这些数字可能看起来很低，但它们意味着<strong>未来 25 年内大约有 5% 的可能性会发生死亡率为 10% 的灾难</strong>（因为 0.002 * 25 = 0.05）。</p><p>死亡率低于 1% 时，发生灾难的可能性比齐普夫定律预测的要小（参见<a href="#log-log-plot-of-catastrophes">附录</a>）。例如，0.1% 死亡率的经验频率是 0.08/年（略低于每十年一次）。</p><p><strong>随着时间的推移的趋势。</strong>如果我们统计 1500 年以来每个十年的灾难，我们会得到以下图表： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/wb5os0qkd9psxc2zrno9"></p><p> 1850 年至 1950 年间发生了更多的灾难，尽管我怀疑这是报道偏见造成的。在此期间之前，随着时间的推移，灾难发生率似乎大致恒定：无论是<a href="https://en.wikipedia.org/wiki/Ljung%E2%80%93Box_test?ref=bounded-regret.ghost.io">Ljung-Box 检验</a>还是<a href="https://en.wikipedia.org/wiki/Wald%E2%80%93Wolfowitz_runs_test?ref=bounded-regret.ghost.io">Wald-Wolfowitz 检验都</a>无法拒绝灾难在 1500 年至 1900 年的几十年间均匀分布的零值（p=0.36 和 0.26） ， 分别）。</p><p>随着时间的推移，最显着的变化是我们目前所处的平静时期，大约从 1950 年到 1960 年开始。事实上，自 20 世纪上半叶以来，灾难显着减少：</p><ul><li> 20世纪上半叶发生了9次饥荒，下半叶只发生了1次（中国大饥荒，1959-1961）</li><li>上半年发生了5次重大战争，下半年只发生了1次（朝鲜战争，1950-1953）</li><li>疫情较为稳定，上半年2起，下半年1起（加上2019年的新冠疫情）。</li></ul><p>由于粮食生产和储存的改善，饥荒似乎有所减少，这有望成为持久的改善。由于<a href="https://en.wikipedia.org/wiki/Pax_Americana?ref=bounded-regret.ghost.io">美国治下的和平</a>，战争可能会减少，但不幸的是，随着全球紧张局势的加剧，这种情况现在可能正在缓解。因此，迄今为止，流行病和（可能）战争是现代灾难的主要根源。</p><p><strong>定性分析：多重因果关系。</strong>许多灾难都有多种原因。例如，在黑死病的主流理论中，气候变化在两个方面起到了推动作用。首先，亚洲的气候变化导致啮齿动物从山区迁移到人口较多的地区，从而传播了疾病。其次，欧洲的小冰期导致饥荒，导致人口体弱，因此更容易感染疾病。 <sup><a href="#fn5">[5]</a></sup>有趣的是，黑死病可能还加剧了小冰河时代，因为在人口减少的情况下重新造林，导致碳捕获和随后的降温。</p><p>举几个多重原因的其他例子：</p><ul><li>在欧洲对美洲的殖民统治中，大多数死亡是由于疾病而不是战争。</li><li>明清的转变是由多种因素造成的，其中包括疾病和饥荒；饥荒本身可能是由小冰河时期引起的。</li><li>太平天国起义是由于饥荒造成的政治动荡而爆发的，随后的许多死亡是由干旱、饥荒和疾病造成的，而不是军事死亡。</li><li>一般来说，许多饥荒是由气候事件和/或糟糕的政府政策引起的。</li></ul><p>总的来说，这表明，为了减少灾难的数量或强度，我们不仅应该解决直接原因，还应该解决更系统性的上游原因。</p><h1>物种灭绝</h1><p>作为第二个参考类别，我考虑了非人类物种的灭绝。 <sup><a href="#fn6">[6]</a></sup>由于以下几个原因，这更难以分析：</p><ul><li>大多数灭绝发生在数百万年前，因此我们只有间接证据，并且存在显着的采样偏差，因为某些物种更容易保存为化石。</li><li>如果一个物种逐渐适应新物种，它可能会灭绝，我们可能不想将其视为“灾难”。</li><li>一些所谓的大规模灭绝事件实际上可能是一段时间内发生的许多较小的事件。</li></ul><p>为了减少这些困难，我将重点关注两个相对较新的灭绝事件：</p><ul><li>第四纪晚期灭绝（ <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev.ecolsys.34.011802.132415?journalCode=ecolsys&amp;ref=bounded-regret.ghost.io">Koch 和 Barnosky，2006</a> ），发生在 10,000-50,000 年前，导致大多数大型哺乳动物灭绝。</li><li><a href="https://en.wikipedia.org/wiki/Holocene_extinction?ref=bounded-regret.ghost.io">全新世灭绝</a>发生在过去一万年中（并且在过去一个世纪中不断增加），主要是由人类狩猎和栖息地破坏驱动的。</li></ul><p>虽然大多数历史上的大规模灭绝事件是由气候变化或自然灾害引起的，但最近的两次灭绝被认为全部或部分是由人类引起的。我将回顾下面关于这两次灭绝事件的证据和主要理论。</p><h2>历史基准利率</h2><p>在讨论第四纪和全新世灭绝之前，让我们计算一下上下文的基本速率。根据化石记录，平均<a href="https://en.wikipedia.org/wiki/Background_extinction_rate?ref=bounded-regret.ghost.io">每百万年大约有一个物种灭绝一次</a>。 <sup><a href="#fn7">[7]</a></sup>然而，这些灭绝并不是随着时间的推移而恒定的，而是以“脉冲”的形式出现，如下所示（图片来自<a href="https://en.wikipedia.org/wiki/Extinction_event?ref=bounded-regret.ghost.io">维基百科</a>）： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/dfuifcmc1rwf6nughndc"></p><p>在这些脉冲期间，每百万年的灭绝次数大约是背景速率的 2-10 倍。 <sup><a href="#fn8">[8]</a></sup></p><h2>晚第四纪灭绝</h2><p><a href="https://en.wikipedia.org/wiki/Quaternary_extinction_event?ref=bounded-regret.ghost.io">晚第四纪灭绝</a>跨越了大约 50,000 至 10,000 年前。在此期间，大约 34% 的哺乳动物灭绝了，其中包括美洲和澳大利亚的大多数哺乳动物以及全世界几乎所有大型哺乳动物。这比预期的背景灭绝率（40,000 年约为 4%）高出一个数量级。</p><p>下表（改编自维基百科）按地理区域和规模记录了灭绝事件： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/hyklusibuiqlssx8a9j4"></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/xfvtfxj13q8vij8qqsmx"></p><p>正如表格所示，非洲（人类起源地，因此哺乳动物可以共同进化防御能力）的灭绝最严重，而大型哺乳动物的灭绝最严重。</p><p><strong>原因。</strong>从历史上看，研究人员一直争论这些灭绝是由气候变化还是人类接触造成的。为了理解这场争论，我阅读了几篇论文并选择遵循<a href="https://www.annualreviews.org/doi/abs/10.1146/annurev.ecolsys.34.011802.132415?journalCode=ecolsys&amp;ref=bounded-regret.ghost.io">Koch &amp; Barnosky (2006)</a> ，该论文系统地回顾了许多相互竞争的理论。科赫和巴诺斯基得出的结论是，灭绝的模式和强度是由人类驱动的，但气候变化是一个重要的额外因素：<br><br></p><p> “总体而言，最近的研究表明，人类通过直接（狩猎）和间接（竞争、栖息地改变和破碎）综合影响，加速了全球许多地区的灭绝，但第四纪晚期的环境变化影响了时间、地理位置，也许还有灭绝的程度。换句话说，如果没有<i>智人</i>的各种影响，全球生态系统不太可能在第四纪晚期经历大型、繁殖缓慢的动物的大规模灭绝。但是，如果全球许多地方没有同时出现明显的快速气候变化，一些物种可能会存活更长时间。”</p><p>因此，人类可能通过多种途径导致物种灭绝：</p><ul><li>直接狩猎</li><li>间接狩猎（通过我们带来的狗、老鼠和其他动物）</li><li>栖息地破坏（例如人为火灾）</li></ul><p>重要的是，不同的物种可能因不同的原因而灭绝。科赫和巴诺斯基认为，欧亚大陆的大多数灭绝是由于气候变化造成的，澳大利亚和大多数岛屿上的灭绝几乎完全是由人类造成的，而北美主要是人类造成的，气候是加剧因素。</p><p>这是一个说明要点的故事。它与 Koch 和 Barnosky 的观点一致，但为了简单性而忽略了不确定性。</p><ul><li>当人类到达岛屿时，他们带来了猪、狗和老鼠，这些动物都捕食当地物种。由于岛屿物种在进化上对这些掠食者来说是幼稚的，因此许多岛屿物种灭绝了。</li><li>火灾和土地清理造成的栖息地破坏也导致了岛屿灭绝。</li><li>在较大的陆地上，哺乳动物在进化上对肉食性捕食者并不幼稚，因此不会那么容易灭绝。然而，人类是非常高效的狩猎者，足以使许多物种的出生率低于死亡率，最终导致数千年的灭绝。</li><li>重要的是，人类的饮食多样化，因此，即使他们猎杀了一些哺乳动物直至灭绝，他们也从其他动植物中收集了足够的食物来维持大量的人口规模，从而避免了传统的<a href="https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations?ref=bounded-regret.ghost.io">捕食者-猎物循环</a>。</li><li>在非洲和欧亚大陆，哺乳动物与人类或其祖先共同进化了数十万年或更长时间。因此，他们有足够的进化时间来发展对高效人类猎人的防御，这解释了与美国和澳大利亚相比灭绝率较低的原因。</li></ul><p>总体而言，人类狩猎可能是非岛屿物种灭绝的主要驱动因素，气候变化等其他因素也有贡献。重要的是，仅仅人类是一种新的掠食者还不够，因为新的掠食者并不总是导致灭绝。同样重要的是，我们是一种特别高效的掠食者，可以占据许多地理区域并具有多样化的饮食。</p><h2>全新世灭绝</h2><p>全新世灭绝大约在一万年前开始，最近有可能加速，大多数研究人员认为人类发挥着重要作用。</p><p>矛盾的是，尽管全新世灭绝发生得更晚，但其范围比晚第四纪灭绝更具争议，原因有两个。首先，大多数其他灭绝计数依赖于化石记录，但全新世灭绝是基于人类当前和历史的观察；这使得直接比较变得困难，因为这两种方法具有不同（且很大）的采样偏差。其次，全新世灭绝的程度被政治化，因为它是当今有关自然保护的争论的核心，因此很难找到中立的来源。</p><p>在浏览了几篇论文后，我决定跟随<a href="https://www.nature.com/articles/nature09678?ref=bounded-regret.ghost.io">Barnosky 等人的脚步。 (2011)</a> <sup><a href="#fn9">[9]</a></sup> ，仔细讨论了抽样偏差的几个来源并尝试纠正它们。巴诺斯基等人。得出的结论是，在过去 500 年里，总物种的百分之几已经灭绝，这比预期的背景灭绝率高出一个数量级（请注意，有些论文给出了更高的估计<sup><a href="#fn10">[10]</a></sup> ）。巴诺斯基等人。还得出结论，如果大多数濒危物种在下个世纪灭绝，并且这种速度继续下去，我们将在几个世纪内失去所有物种的大多数，相当于历史上仅发生过 5 次（通常速度较慢）的大规模灭绝事件。</p><p><strong>原因。</strong>巴诺斯基等人。列出了导致这些灭绝的几个压力因素：“快速变化的大气条件和变暖[...]、栖息地破碎化、污染、过度捕捞和过度狩猎、入侵物种和病原体[...]以及不断扩大的人类生物量”。 <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev.ecolsys.34.011802.132415?journalCode=ecolsys&amp;ref=bounded-regret.ghost.io">Koch 和 Barnosky（2006）</a>将第四纪灭绝造成的生态破坏视为进一步的压力源。 <sup><a href="#fn11">[11]</a></sup></p><p>与过去的灭绝不同，我们可以直接观察今天发生的许多全新世灭绝的原因。基于<a href="https://pubmed.ncbi.nlm.nih.gov/20978281/?ref=bounded-regret.ghost.io">霍夫曼等人。 （2010）</a> ，栖息地破坏是当前物种灭绝的最大驱动因素，其次是入侵物种（包括疾病）和过度捕猎，最后是气候变化和污染等环境原因。 <sup><a href="#fn12">[12]</a></sup> <sup><a href="#fn13">[13]</a></sup></p><h2>摘要：灭绝的典型原因是什么？</h2><p>总的来说，我对过去灭绝事件的分析指出了物种灭绝的几种方式：</p><ul><li>大规模灾难或气候事件，要么直接导致物种无法生存，要么破坏生态系统并导致后来的灭绝。</li><li>引入了一种新颖的、具有攻击性的生物体，而原始物种尚未适应这种生物体。这包括：<ul><li>一种入侵物种，可以直接在其生态位竞争中击败某个物种或破坏周围的生态系统。</li><li>一种新的病原体，特别是如果它有<a href="https://en.wikipedia.org/wiki/Natural_reservoir?ref=bounded-regret.ghost.io">储存物种的</a>话。 <sup><a href="#fn14">[14]</a></sup></li><li>一种新的、高效的捕食者。这对岛屿物种影响最大，因为大陆物种在进化过程中暴露于足够多样化的捕食者之下，从而制定了强有力的应对策略。然而，具有多样化饮食的高效捕食者甚至可以压倒这些进化出的防御能力，即使对于非岛屿物种也是如此。</li></ul></li><li>栖息地的变化（通常来自气候变化或其他物种）。</li><li>其他物种灭绝的后续影响。这与上述内容部分重叠：例如，巨型食草动物的灭绝导致森林重新生长，从而显着改变了其他物种的栖息地。</li></ul><p>因此，一般来说，大多数物种灭绝是由以下原因引起的：</p><ul><li>原始物种没有机会适应的第二个物种。第二个物种也必须不依赖于原始物种来繁殖。</li><li>灾难性的自然灾害或气候事件。</li><li>由上述两个来源之一造成的栖息地破坏或生态系统破坏。</li></ul><p><strong>为什么灭绝通常很少见。</strong>由于灭绝的基本发生率通常较低，因此灭绝的原因一定很罕见。为了更好地了解什么<em>会</em>导致灭绝，让我们了解为什么对物种的大多数威胁<em>不会</em>导致灭绝。</p><p>首先，大多数掠食者不会导致灭绝。这是因为猎物的防御能力随着捕食者的进攻而进化，而捕食者越好，猎物的进化压力就越大（因此防御能力的进化速度越快）。除此之外，如果猎物变得太稀有，那么捕食者种群<a href="https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations?ref=bounded-regret.ghost.io">通常会崩溃</a>，从而使猎物种群重新增长。因此，捕食者通常只有在以下情况下才会导致灭绝：（1）它们进入一个有非进化适应猎物的新环境；（2）它们以多种物种为食，这样它们就可以在不导致自身种群崩溃的情况下驱使一个物种灭绝。</p><p>同样，新的病原体默认情况下不会导致其宿主灭绝，因为如果它们杀死太多宿主物种，它们就没有目标可以传播。相反，“如果病原体……具有长期的感染阶段，或者是可以在常见储存宿主和更脆弱的目标物种之间传播的多宿主病原体，则它们更有可能导致宿主灭绝”（ <a href="https://www.nature.com/scitable/knowledge/library/disease-ecology-15947677/?ref=bounded-regret.ghost.io">Kilpatrick 和 Altizer，2010</a> ） 。</p><p><strong>人类。</strong>最后，让我们分析一下为什么人类是如此高效的狩猎者，以至于我们能够使如此多的物种灭绝。首先，我们的适应能力很强，因此不仅能够生存，而且能够在各种环境中依靠多种食物来源生存。这让我们能够在全球范围内繁殖并导致一些物种灭绝，同时仍然有替代的食物来源。其次，我们可以有效地协调（ <a href="https://www.scientificamerican.com/article/how-homo-sapiens-became-the-ultimate-invasive-species/?ref=bounded-regret.ghost.io">Marean，2015</a> ），通过更好的战术压倒更大的猎物。最后，我们使用工具和技术来提高我们的狩猎能力并塑造我们的环境，放大了上面讨论的两个灭绝的关键驱动因素。</p><h1>现代灾难和人工智能的要点</h1><p>将人类灾难和非人类灭绝的所有驱动因素放在一起，我们看到了以下几个主题：</p><ul><li>超大规模自然事件</li><li>高度适应、自我复制的生物体，尤其是那些受害者无法共同适应的生物体（流行病、新型病原体和捕食者、入侵物种）。</li><li>协调的人类群体（战争、狩猎、栖息地破坏）</li><li>政治镇压或破坏（强迫劳动、导致饥荒的糟糕政策）</li><li>其他灾难的后续影响。</li></ul><p>有趣的是，技术似乎并不是大多数人类灾难的直接罪魁祸首，尽管在大规模核战争中它可能是罪魁祸首。对于非人类灭绝来说，它可能是一个因素，因为技术提高了狩猎能力并减轻了栖息地破坏的程度。</p><p>纵观现代威胁，纳米技术和生物技术都可能创造出新型的自我复制器，而人类设计的加入可能会导致它们以相对于我们的进化防御而言不符合分布的方式进行“适应”。</p><p>核武器会增加战争的最坏结果，大规模监视会增加政治镇压的最坏结果。</p><p>气候变化是一个大规模的自然事件。除了直接影响外，如果它导致许多非人类物种灭绝，或引发政治动荡，后续影响可能对人类来说是灾难性的。持续灭绝导致的生物多样性丧失也可能造成不良的后续影响，尽管这种情况发生的速度足够缓慢，可能不会构成直接威胁。</p><p>最后，我们将人工智能放在这个等式中的什么位置？不幸的是，它看起来具有许多其他灾难驱动因素的特性：</p><ul><li>人工智能是自我复制的，因为它可以自我复制，并且可以训练自己快速适应新数据。因此，它是一种适应性的自我复制因子，而人类本身并不适应它。</li><li>人工智能很可能经过训练，能够比人类更好地协调，因为人类在进化上只适应在<a href="https://en.wikipedia.org/wiki/Dunbar%27s_number?ref=bounded-regret.ghost.io">约 150</a>人的群体中进行协调，而如果我们解决相关的<a href="https://arxiv.org/abs/1705.08926?ref=bounded-regret.ghost.io">多智能体 RL 挑战，</a>人工智能就可以被训练成在任意大的群体中进行协调。</li><li>人工智能带来的经济取代可能会导致政治动荡。</li><li>人工智能也是上述许多其他驱动因素的贡献者（尽管这可以说是重复计算）：它使大规模监视变得更容易，并可能加速其他危险技术（例如工程病原体）的创建。</li></ul><p>人工智能也具有改善的特性。首先，其他新技术并没有造成灾难，这应该会降低我们对人工智能的优先级。其次，人工智能辅助的研究可以帮助解决饥荒和气候变化，如果人工智能可以促进繁荣，那么它可以减少政治动荡。这些都是重要的考虑因素，但许多技术都具有这些特性，但几乎没有一种技术是可以在群体中协调的适应性自我复制器。</p><p>总的来说，我预计人工智能会增加灾难的发生率。根据<a href="https://docs.google.com/document/d/1DOmluInO2KkgmumAf1wKLKHU7HbMeveIugR_oiFvHPc/edit?ref=bounded-regret.ghost.io#bookmark=id.xu338fnad04c">上面的计算</a>，未来 25 年发生特大灾难（死亡率 10%）的基本概率是 5%，我个人预计人工智能会在此基础上再增加 10%，我将在下一篇中证明这一点。邮政。</p><p><strong>开放式问题。</strong>这篇文章没有解决几个问题。首先，我的分析对于灾难发生率是否随时间变化或变化程度如何没有结论。来自灭绝事件的数据表明，它可能会有一个数量级的变化，但最好有关于人类事件的数据。</p><p>其次，这篇文章很少谈到技术和智能的重要性，尽管它们直观上很重要。技术灾难是否会随着时间的推移而增加，即使目前它们还太小而无法记录在上述数据中？高智慧物种是否经常导致低智慧物种灭绝？ <sup><a href="#fn15">[15]</a></sup>其中任何一个的基本利率都将为人工智能的预测提供信息。</p><p>最后，有人可能会争辩说，经过的时间并不是正确的 x 轴，而是经过的人口增长、经济增长或技术进步。以世界 GDP 为例。自 1900 年以来，世界 GDP 翻番的次数与 1900 年至公元 0CE 之间的翻番次数一样多，因此，如果 GDP 翻番是衡量的正确“时钟”，那么我们可能会预计现在每个十年都会比过去发生更多的灾难。从到目前为止的数据来看，这对我来说似乎并不正确，但我希望看到更详细的分析。</p><p><strong>致谢。</strong>特别感谢 Dhruv Madeka 的讨论和最初的数据为这篇文章提供了灵感。还要感谢 Sham Kakade、Dean Foster、Tamay Berisoglu、Eli Lifland、Nuño Sempere、Daniel Kokotajlo 和 Ege Erdil 对本文的有益讨论和评论。感谢 Justis Mills 和 Louise Verkin 的文案编辑和有用的反馈。</p><hr><section class="footnotes"><ol><li id="fn1" class="footnote-item"><p>当然，数字本身可能会产生误导，因为许多历史数字都是基于猜测！这篇文章中的很多工作都是进行广泛的阅读来决定相信哪些数字。 <a href="#fnref1">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>人口规模是从<a href="https://ourworldindata.org/grapher/population?time=-1000..latest&amp;country=%7EOWID_WRL&amp;ref=bounded-regret.ghost.io">我们的世界数据中</a>收集的，请参阅<a href="#population-by-country-across-history">附录</a>。 <a href="#fnref2">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>太平天国叛乱被双重计算，一次被视为战争，一次被视为饥荒。 <a href="#fnref3">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>如上所述，“快”意味着不到十年。 <a href="#fnref4">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>另一种理论认为，蒙古人的入侵（另一场灾难）传播了黑死病，因为蒙古人将患病的尸体扔进城市作为生物战的一种形式。这不是目前的主流理论，但将是多重因果关系的另一个例子，并表明不同的重大灾难可以相互联系。 <a href="#fnref5">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>从技术上讲，历史化石记录通常只能解决属而非物种层面的灭绝问题，但为了简单起见，我通常会忽略这种区别。 <a href="#fnref6">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>请注意，这因分类单元而异，并且分类单元内的估计值是近似值，文献中的不同估计值相差 4 倍或有时更大。 <a href="#fnref7">↩︎</a></p></li><li id="fn8" class="footnote-item"><p> 2-10 倍的数字是查看 100 万年的 bin 时的数字。对于小行星撞击等突发灾难性事件，一年时间间隔内的灭绝率会大幅上升。 <a href="#fnref8">↩︎</a></p></li><li id="fn9" class="footnote-item"><p>这就是上面的巴诺斯基，尽管我在寻找论文时并不知道这一点——在这两种情况下，他碰巧写了我认为最中立和最有说服力的论文。令我高兴的是，我得知他也在加州大学伯克利分校。熊们走吧！ <a href="#fnref9">↩︎</a></p></li><li id="fn10" class="footnote-item"><p>参见<a href="https://www.science.org/doi/10.1126/sciadv.1400253?ref=bounded-regret.ghost.io">Ceballos 等人。 (2015)</a> ，估计值比背景率高出接近两个数量级。 <a href="#fnref10">↩︎</a></p></li><li id="fn11" class="footnote-item"><p> “例子包括失去种子传播主要媒介的植物，或者充满了对不再存在的食草动物的防御的植物，为所有现有捕食者“过度设计”的食草动物，<br>还有像秃鹰这样的食腐动物，它们在大陆环境中没有自然产生的尸体可供食用。” <a href="#fnref11">↩︎</a></p></li><li id="fn12" class="footnote-item"><p>我遵循<a href="https://pubmed.ncbi.nlm.nih.gov/20978281/?ref=bounded-regret.ghost.io">Hoffmann 等人的图 S7。</a> （转载于<a href="#species-endangerment-by-cause">附录</a>），统计了按濒危原因分组的濒危物种。我将这些行分为“栖息地破坏”、“入侵物种”（包括两栖动物的<a href="https://en.wikipedia.org/wiki/Chytridiomycosis?ref=bounded-regret.ghost.io">壶菌</a>病）、“过度狩猎/过度捕捞”和“环境”（气候变化/污染/自然灾害）。有些类别不明确或不适合这 4 个类别。总体而言，我计算出约 360 个栖息地破坏，约 250 个来自入侵物种（以两栖动物为主），约 130 个来自过度狩猎/过度捕捞，约 40 个来自环境。 <a href="#fnref12">↩︎</a></p></li><li id="fn13" class="footnote-item"><p>另请参阅<a href="https://www.annualreviews.org/doi/pdf/10.1146/annurev.energy.28.050302.105532?ref=bounded-regret.ghost.io">Dirzo 和 Raven (2003)</a> ，他们同样声称栖息地破坏是主要驱动因素。 <a href="#fnref13">↩︎</a></p></li><li id="fn14" class="footnote-item"><p>储存物种是病原体不致命的第二种物种，允许其更自由地繁殖，并且病原体可以从其中传播到目标物种。 <a href="#fnref14">↩︎</a></p></li><li id="fn15" class="footnote-item"><p>我发现最接近的是<a href="https://www.nature.com/articles/s41598-022-07327-9?ref=bounded-regret.ghost.io">Dembitzer 等人。 （2022）</a> ，他们声称更聪明的哺乳动物在第四纪晚期灭绝期间灭绝的可能性较小。然而，理想情况下，我们想要研究相反的问题：更聪明的哺乳动物是否更有可能导致<em>其他</em>物种灭绝？ <a href="#fnref15">↩︎</a></p></li></ol></section><h1>附录</h1><h2>灾难的双对数图</h2><p>正如第 1 节所述，当死亡人数低于 1% 时，灾难的分布不再遵循齐普夫定律，如下所示： <br><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/pogy0xusqv3jf1vpdej2" alt="events_power_law_01.png"><br>一种可能性是实际趋势是对数正态分布而不是幂律分布。另一个原因是不太严重的事件没有得到充分报告。</p><h2>物种濒危原因</h2><p>以下是<a href="https://www.science.org/doi/10.1126/science.1194442?ref=bounded-regret.ghost.io">Hoffmann 等人的图 S7 的复制品。 （2010）</a> 。 <br><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/o0x5tingr8fej6jn4f7z" alt="霍夫曼_figs7.png"></p><h2>历史上各个国家的人口</h2><div><a href="https://bounded-regret.ghost.io/content/files/2023/12/population.csv"><div><div> 人口</div><div>历史世界人口的原始数据（直接参见下面的交互式 HTML）</div><div><div>人口.csv</div><div> 1MB</div></div></div><div>下载圈</div></div><iframe src="https://ourworldindata.org/grapher/population?tab=table&amp;time=-1000..latest&amp;country=~OWID_WRL"></iframe><h2>抓取脚本</h2><div><a href="https://bounded-regret.ghost.io/content/files/2023/12/scrape_events.py"><div><div>抓取事件</div><div>用于抓取维基百科重大灾难列表的 Python 脚本</div><div><div>scrap_events.py</div><div> 13KB</div></div></div><div>下载圈</div></div><h2>所有重大灾难的完整列表</h2><div><a href="https://bounded-regret.ghost.io/content/files/2023/12/events_all.csv"><div><div> 全部事件</div><div>从维基百科中删除的所有重大灾难的列表</div><div><div>events_all.csv</div><div> 6KB</div></div></div><div>下载圈</div></div><br/><br/><a href="https://www.lesswrong.com/posts/SgYz4YPKridWXJSE6/analyzing-the-historical-rate-of-catastrophes#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/SgYz4YPKridWXJSE6/analyzing-the-historical-rate-of-catastrophes<guid ispermalink="false"> SgYz4YPKridWXJSE6</guid><dc:creator><![CDATA[jsteinhardt]]></dc:creator><pubDate> Tue, 05 Dec 2023 06:30:03 GMT</pubDate></item></channel></rss>