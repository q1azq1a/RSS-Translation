<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 12 月 5 日，星期二 08:15:27 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Neural uncertainty estimation for alignment]]></title><description><![CDATA[Published on December 5, 2023 8:01 AM GMT<br/><br/><h2>介绍</h2><p>假设您已经构建了一些人类价值观的人工智能模型。你输入一个情况，它就会给出一个良好度评级。您可能想问：“此优度评级的误差线是多少？”除了了解误差线之外，不确定性估计在人工智能内部也很有用：指导主动学习<span class="footnote-reference" role="doc-noteref" id="fnref80ywo0pbl8r"><sup><a href="#fn80ywo0pbl8r">[1]</a></sup></span> 、纠正<a href="https://www.lesswrong.com/posts/5gQLrJr2yhPzMCcni/the-optimizer-s-curse-and-how-to-beat-it">优化器的诅咒</a><span class="footnote-reference" role="doc-noteref" id="fnrefq23duy4ut0g"><sup><a href="#fnq23duy4ut0g">[2]</a></sup></span>或进行分布外检测<span class="footnote-reference" role="doc-noteref" id="fnref3dij2j9svj8"><sup><a href="#fn3dij2j9svj8">[3]</a></sup></span> 。</p><p>我最近出于一个<a href="https://www.lesswrong.com/s/aJvgWxkCBWpHpXti4/p/nA3n2vfCy3ffnjapw">喜欢的原因</a>进入了神经网络（NN）的不确定性估计文献：我认为这对于量化人工智能潜在特征的有效性域的对齐很有用。如果我们<a href="https://www.lesswrong.com/posts/w4aeAFzSAguvqA5qu/how-to-go-from-interpretability-to-alignment-just-retarget">将人工智能指向其世界模型中的某个概念</a>，那么对该概念的实现进行优化可能会因为将该概念推到其有效范围之外而出错。</p><p>但现在就先把对齐的想法放在你的后口袋里吧。这篇文章主要是对不确定性估计文献的调查，其中夹杂着我自己的看法。</p><p></p><h2>贝叶斯神经网络图片</h2><p>贝叶斯神经网络图是几乎所有神经网络不确定性估计方法的鼻祖，因此从这里开始是合适的。</p><p>图片很简单。您从参数的先验分布开始。您的训练数据就是证据，在对其进行训练后，您将获得更新的参数分布。给定输入，您可以通过贝叶斯神经网络传播输入来计算输出的分布。</p><p>这一切都是非常正确且无关紧要的（“<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="2^{trillion}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">当然</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">，</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">让</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">我</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">更新</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">我</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">的</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">2</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">万亿</span></span></span></span></span></span></span></span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>模型所有参数的维度联合分布”），但<i>实际上训练神经网络确实是这样工作的</i>。<i> </i>如果您使用对数似然损失和 L2 正则化，并且您的参数先验是高斯分布，则最小化损失的参数将位于贝叶斯神经网络所具有的分布的峰值<span class="footnote-reference" role="doc-noteref" id="fnreffo4svcpvxs"><sup><a href="#fnfo4svcpvxs">[4]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnrefcogdul3x2xj"><sup><a href="#fncogdul3x2xj">[5]</a></sup></span> 。</p><p>这是因为损失景观和参数不确定性之间存在桥梁。 <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(parameters \;|\; dataset) ="><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">贝叶斯</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">规则</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">表示</span></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">P</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">（</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">集</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">P</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">⋅</span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(parameters) \cdot \text{P}(dataset \;|\; parameters) / \text{P}(dataset)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">P</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">集</span></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mtext MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">）</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">/</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">P</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">（</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">集</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">）</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">。</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span></span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span></span></span></span></span></span> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(parameters \;|\; dataset)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">这里</span></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">P</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">集</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">是</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">要</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">估计</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">的</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">后</span></span></span></span></span></span></span><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(parameters) \cdot \text{P}(dataset \;|\; parameters)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">验</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">分布</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">，</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">P</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">⋅</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">P</span></span> <span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">(</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">集</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mtext MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">_</span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">s</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">是</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">损失</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">的</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">指数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">[</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">6</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">]</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">。</span></span></span></span></span></span></span> <span class="footnote-reference" role="doc-noteref" id="fnrefamk58pvab4"><sup><a href="#fnamk58pvab4">_</a></sup></span>这适用于物理隐喻，例如“参数的分布是位于损失盆地底部的玻尔兹曼分布”。</p><p>根据经验，通过假装遵循贝叶斯神经网络图来计算神经网络的不确定性效果非常好，以至于一篇关于集成方法的好论文<span class="footnote-reference" role="doc-noteref" id="fnreflpb1b2qcoen"><sup><a href="#fnlpb1b2qcoen">[7]</a></sup></span>将其称为“基本事实”。当然，要在这里实际计算任何东西，你必须进行近似，如果你进行快速而肮脏的近似（例如假装你可以从 Hessian 找到损失盆地的形状），你会得到不好的结果<span class="footnote-reference" role="doc-noteref" id="fnrefd9jz9mfml"><sup><a href="#fnd9jz9mfml">[8]</a></sup></span> ，但人们正在做这些天，蒙特卡罗方法变得很聪明<span class="footnote-reference" role="doc-noteref" id="fnrefbct5kii2m07"><sup><a href="#fnbct5kii2m07">[9]</a></sup></span> ，他们发现贝叶斯神经网络计算的更好近似可以得到更好的结果。</p><p>但对损失景观进行蒙特卡罗遍历的成本很高。对于大规模应用的技术，它必须只对运行模型的成本施加很小的乘数，并且如果您希望它变得普遍，那么它施加的成本必须非常小。</p><p></p><h2>合奏团</h2><p>解决不确定性的一种完全不同的方法是集成<span class="footnote-reference" role="doc-noteref" id="fnrefen0yeoqzg0k"><sup><a href="#fnen0yeoqzg0k">[10]</a></sup></span> 。只需训练十几个模型，询问他们的建议，并估计传播的不确定性。所有事情的数十倍成本乘数都很陡峭，但如果您经常查询模型，它比损失情况的蒙特卡洛估计便宜。</p><p>集成在理论上很简单。您不需要假装模型经过训练可以收敛，不需要专门针对预测损失进行训练，甚至不需要固定的架构。您只需选择一些想要分散不确定性的模型分布并进行采样。</p><p>你可以用合奏做一些聪明的事情。通过计算集成如何适应贝叶斯神经网络图片，您会了解到改变正则化的零点可能是个好主意，否则您将在模型的泛化方式中得到虚假相关性<span class="footnote-reference" role="doc-noteref" id="fnreflpb1b2qcoen"><sup><a href="#fnlpb1b2qcoen">[7]</a></sup></span> 。您可以拆分数据集并训练单独的较小模型，然后巧妙地聚合这些模型（类似于<a href="https://www.kaggle.com/code/prashant111/bagging-vs-boosting">装袋和提升</a>），以降低集成的计算溢价<span class="footnote-reference" role="doc-noteref" id="fnrefen0yeoqzg0k"><sup><a href="#fnen0yeoqzg0k">[10]</a></sup></span> 。这些论文中暗示，聪明的集成技巧在更大的尺度上并不那么重要，但目前还不清楚收益是否完全为零。</p><p>集成的一个棘手部分是，如果一枚硬币正面朝上的概率为 51%，并且您已训练神经网络以获得正确答案，那么集成中的每个成员都会预测正面。正确答案并不不确定，因此您的团队表示不存在不确定性。如果您希望不确定性度量包含环境中的熵，则必须训练神经网络来估计该熵，这在很大程度上放弃了使用非预测损失的自由。</p><p>解释时的类似关注适用于在模型的潜在特征上使用集成，尽管我在文献中没有看到人们这样做。假设您训练了十几个模型，并用有关狗的数据探测它们，为每个模型找到一个“狗向量”。您可以对它们的大小和方差进行标准化，然后使用集合的方差作为“狗向量的不确定性”。这并不是关于狗的完全不确定性，因为它没有衡量人工智能模型中关于狗的不确定性，这只是不同模型根据特定探测方法的内部表示的传播。</p><p></p><h2>关于任意不确定性的注释</h2><p>文献中很大一部分文字是关于任意不确定性和认知不确定性之间的区别<span class="footnote-reference" role="doc-noteref" id="fnrefxqxuuw1xe2"><sup><a href="#fnxqxuuw1xe2">[11]</a></sup></span> 。当我说集成会告诉你由于建模选择而导致的输出的不确定性时，这就是我必须谈论的区别，但不会告诉你人工智能内部对环境的不确定性。在不确定性估计文献中，由于模型方差而产生的不确定性被称为“认知性”，而人工智能环境模型内部的不确定性被称为“随意性”。 <span class="footnote-reference" role="doc-noteref" id="fnref2jiolbj6tn8"><sup><a href="#fn2jiolbj6tn8">[12]</a></sup></span></p><p>在大数据限制下，认知不确定性相对于任意不确定性变得很小（除非你故意将模型推入高度认知不确定性的情况）。有些论文忘记了这一点，做了一些愚蠢的事情，使他们的认知不确定性估计更大，因为他们认为这应该是总的不确定性，这就是为什么其他论文必须用章节来讨论这种区别。</p><p></p><h2>添加噪声，由于某种原因通常会丢失</h2><p>如果您想要不确定性估计，您可以将随机噪声添加到神经网络的中间激活中。如果输出对噪声更敏感，则不确定性更大，如果输出不太敏感，则不确定性更小<span class="footnote-reference" role="doc-noteref" id="fnrefud7l8eu73jk"><sup><a href="#fnud7l8eu73jk">[13]</a></sup></span> 。有一些自然的启发式论证可以解释为什么这是有意义的<span class="footnote-reference" role="doc-noteref" id="fnreflgnhfp0m35e"><sup><a href="#fnlgnhfp0m35e">[14]</a></sup></span> ，并且通过更多的工作，您可以尝试将其与贝叶斯神经网络图和损失景观的蒙特卡洛估计联系起来。</p><p>或者，您可以忽略抽象参数并使用 dropout 作为随机噪声分布<span class="footnote-reference" role="doc-noteref" id="fnrefhfox6k7gfev"><sup><a href="#fnhfox6k7gfev">[15]</a></sup></span> 。</p><p>哦，当然，人们给出了理由，但我认为这里的第一印象是正确的，添加 dropout 然后采样在理论上是愚蠢的。但在实验上，它的效果很好，人们一直在谈论它<span class="footnote-reference" role="doc-noteref" id="fnref0hl862nst9f9"><sup><a href="#fn0hl862nst9f9">[16]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnrefu11lguv41wc"><sup><a href="#fnu11lguv41wc">[17]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnrefhzxdsrsco9g"><sup><a href="#fnhzxdsrsco9g">[18]</a></sup></span> ，而且它不需要你做任何额外的训练。</p><p>为什么它起作用的一个谜题可能是，在具有一些噪声样本的数据集上训练的网络将学会输出一个包罗万象的先验以响应噪声<span class="footnote-reference" role="doc-noteref" id="fnreffqljh5j8ipf"><sup><a href="#fnfqljh5j8ipf">[19]</a></sup></span> 。我怀疑 dropout 是足够大的噪音，它将网络推向这个先验，这有助于过度自信。</p><p>我希望人们对更小的、非丢失的噪声进行更多的比较<span class="footnote-reference" role="doc-noteref" id="fnrefvl2ahm3user"><sup><a href="#fnvl2ahm3user">[20]</a></sup></span> 。这在理论上似乎更合理，尽管当翻译回贝叶斯术语时，将噪声注入内部层似乎对应于有趣但不寻常的噪声分布。</p><p></p><h2>校准</h2><p>文献<span class="footnote-reference" role="doc-noteref" id="fnref0hl862nst9f9"><sup><a href="#fn0hl862nst9f9">[16]</a></sup></span>的很大一部分是人们只是试图获取神经网络的输出并对它们应用简单的函数来获得不确定性估计。我将简要地对待他们。</p><p>第 0 级只是按面值获取 NN 输出。当数据较多且参数不确定性较小时，神经网络的直接预测可以很好地估计不确定性。例如，基础 GPT-4 在分配给下一个标记的概率分布中得到了很好的校准，包括当这些下一个标记是以前从未见过的测试问题的答案时<span class="footnote-reference" role="doc-noteref" id="fnrefzkojoz799ka"><sup><a href="#fnzkojoz799ka">[21]</a></sup></span> 。即使是非分布，这也比什么都没有好——正如我上面提到的，如果神经网络的训练集包含意外数据，那么它们确实会学会不确定意外数据<span class="footnote-reference" role="doc-noteref" id="fnreffqljh5j8ipf"><sup><a href="#fnfqljh5j8ipf">[19]</a></sup></span> ，尽管它们仍然倾向于过度自信。</p><p>随着模型的泛化能力越来越强，我预计它们的输出能够在更大的领域得到很好的校准。相反，对于在有限数据上训练小型模型的应用程序，您将需要一种不同的方法来估计不确定性。</p><p>通常人们会尝试比第 0 级更奇特一些，并做一些事情，比如调整 softmax 函数的参数，以最大限度地提高对保留验证集的校准<span class="footnote-reference" role="doc-noteref" id="fnrefnglt70rybd9"><sup><a href="#fnnglt70rybd9">[22]</a></sup></span> 。这也很容易与其他方法结合作为最终校准步骤<span class="footnote-reference" role="doc-noteref" id="fnrefgx8tqfun0w"><sup><a href="#fngx8tqfun0w">[23]</a></sup></span> 。</p><p>如果您有分布外 (OOD) 数据样本，您还可以做更奇特的事情，例如同时进行 OOD 检测和校准<span class="footnote-reference" role="doc-noteref" id="fnreftmgq2x5m6t"><sup><a href="#fntmgq2x5m6t">[24]</a></sup></span> 。或者，如果您有 OOD 数据样本并且是频率论者，则可以进行保形预测<span class="footnote-reference" role="doc-noteref" id="fnrefg3rtbqm4247"><sup><a href="#fng3rtbqm4247">[25]</a></sup></span> 。</p><p>校准的一个卖点是您可以对任何经过训练的模型执行此操作。但如果您愿意放弃这一点并干预训练，就有一些方法可以改进模型的校准。这可能看起来像使用额外的正则化<span class="footnote-reference" role="doc-noteref" id="fnrefqbdlqupa3x"><sup><a href="#fnqbdlqupa3x">[26]</a></sup></span>或对比示例<span class="footnote-reference" role="doc-noteref" id="fnref2qfcvdqkx2y"><sup><a href="#fn2qfcvdqkx2y">[27]</a></sup></span>进行训练。这些也在一定程度上提高了 OOD 泛化能力，对抗性训练也是如此<span class="footnote-reference" role="doc-noteref" id="fnrefazba93s687"><sup><a href="#fnazba93s687">[28]</a></sup></span> 。</p><p>最终，网络输出的校准似乎并没有达到我想要的不确定性估计方法的效果。其一，它不会估计潜在特征的不确定性，而是与您拥有数据的输出的不确定性有关。</p><p>另一方面，它<a href="https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation">缺乏搜索的鲁棒性</a><span class="footnote-reference" role="doc-noteref" id="fnrefv1gf6chx43"><sup><a href="#fnv1gf6chx43">[29]</a></sup></span> 。确实，所有其他不确定性估计方法在优化时也应该容易受到对抗性示例的影响（部分原因是对抗性示例是特征，而不是错误<span class="footnote-reference" role="doc-noteref" id="fnrefa3kc8qjhdn6"><sup><a href="#fna3kc8qjhdn6">[30]</a></sup></span> ），但是当网络输出及其不确定性估计是相同的时，对良好输出的本地搜索应该<i>特别</i>有效地找到奇怪的意想不到的最佳值<span class="footnote-reference" role="doc-noteref" id="fnref28983dpfjdp"><sup><a href="#fn28983dpfjdp">[31]</a></sup></span> 。</p><p></p><h2>训练高阶模型</h2><p>校准的另一面。首先让你的神经网络为你提供更好的不确定性估计。</p><p>如果您想获得二阶不确定性的估计，请训练神经网络以输出<a href="https://en.wikipedia.org/wiki/Dirichlet_distribution#Occurrence_and_applications">狄利克雷分布</a>的参数，而不是进行正常分类<span class="footnote-reference" role="doc-noteref" id="fnrefkm10b29by7c"><sup><a href="#fnkm10b29by7c">[32]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnrefhfc8x4hav0b"><sup><a href="#fnhfc8x4hav0b">[33]</a></sup></span> 。或者，如果您正在进行回归，请训练神经网络以输出答案的分布参数<span class="footnote-reference" role="doc-noteref" id="fnrefen0yeoqzg0k"><sup><a href="#fnen0yeoqzg0k">[10]</a></sup></span> 。或者，如果您拥有法学硕士并且每个问题都是钉子，请训练您的法学硕士用语言表达不确定性<span class="footnote-reference" role="doc-noteref" id="fnrefffdudph3qus"><sup><a href="#fnffdudph3qus">[34]</a></sup></span> <span class="footnote-reference" role="doc-noteref" id="fnrefadsp4hkxuk"><sup><a href="#fnadsp4hkxuk">[35]</a></sup></span> 。</p><p>表达不确定性的训练模型存在一个微妙的问题：不存在适当的二阶损失函数<span class="footnote-reference" role="doc-noteref" id="fnrefxuwhb9ieyh"><sup><a href="#fnxuwhb9ieyh">[36]</a></sup></span> 。这意味着仅从数据点出发，很难准确地训练模型来给出概率分布 - 您可以创建损失函数来尝试做到这一点，但只要您只监督正确答案是什么，而不监督正确答案是什么。正确的概率分布是，通过损失最小化得到的概率分布将会有偏差。</p><p>贝叶斯方法，或者至少是贝叶斯理论框架，在这里会很有用。您不需要适当的损失函数来进行贝叶斯更新。但还没有人写下该应用程序的贝叶斯神经网络图的类似物。</p><p>理论上也不清楚如何整合我们可以获得的有关概率分布的其他类型的监督数据。例如，人为噪声的例子可以给出直接的监督信号，表明正确的概率分布是高熵的。或者，我们可以通过询问“我期望我对正确答案的估计随着更多数据而改变多少？”来学习分布。它的监督分布在整个数据集中，因此绕过了没有适当评分规则的证明 - 但我们可以以公正的方式做到这一点吗？</p><p></p><h2>比较方法</h2><p>那么，哪个是最好的？</p><p>目前，它正在训练一个整体。但训练高阶模型具有尚未开发的潜力。</p><p>情况尚不清楚，因为比较是在玩具问题上进行的，文献很少并且并不总是重复，比较很困难，因为每种方法都有十几种变体，而且不同的论文有时会评估完全不同的指标。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/xptyd74vj7qmuirlgkdq" alt="该图显示了一些神经网络曲线与不同方法生成的误差条的拟合情况。" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/h6cj9a57suxcupp18t15 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/uqc5c2ci9zjyioeqilyd 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/dgoocd9ekrsj4v2ldc3f 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/pbdddhbajg3sxt9ixtsy 680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/bavrtb78i5icyf0kiyki 850w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/r4pe2oeov2q0fyqkckyj 1020w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/uraeyjenw52atepowgt4 1190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/lsoqntf6avhbtk0qkyhp 1360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/dbifkkrzkczba42uqllp 1530w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/dcy3kxiejmh9igglcn63 1603w"><figcaption>来自<a href="https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment#fnlpb1b2qcoen">参考文献。 7</a> .玩具曲线拟合问题的不确定性估计方法比较。<br><br> Ground Truth 是一个贝叶斯神经网络，Hamiltonian MC 是它的一个很好的蒙特卡洛近似，变分推理是它的一个廉价近似，MC Dropout 根据 dropout 后的方差估计不确定性，而我们的方法是一个具有奇特初始化的集成。</figcaption></figure><p>这个数字是一个不错的直觉泵。它在玩具曲线拟合任务（只有<span class="footnote-reference" role="doc-noteref" id="fnreflpb1b2qcoen"><sup><a href="#fnlpb1b2qcoen">6</a></sup></span>个数据点的回归问题）上比较了不确定性估计方法（尽管它明显错过了校准和高阶建模），每种方法都使用 ReLU 与 Sigmoid。我认为这个数字的一​​些定性印象是概括性的。</p><p>印象笔记：</p><ul><li>贝叶斯神经网络、蒙特卡洛近似和集成方法都做出了类似的预测。</li><li>架构对于泛化属性来说非常重要，在某种程度上使这些方法看起来过于自信。 （整合不同的架构将是一个好的开始，但没有人这样做。）</li><li> Dropout 和变分推理近似在数据点附近的置信度都低于集成簇，但在分布之外的置信度更高。</li></ul><p>在对 CIFAR-10 或 LSTM 语言模型<span class="footnote-reference" role="doc-noteref" id="fnrefhzxdsrsco9g"><sup><a href="#fnhzxdsrsco9g">[18]</a></sup></span>或医学 MRI 数据<span class="footnote-reference" role="doc-noteref" id="fnrefu11lguv41wc"><sup><a href="#fnu11lguv41wc">[17]</a></sup></span>进行更彻底的比较（现在包括校准）时，集成似乎是最好的方法。但老实说，我提到的所有方法都非常接近，在复杂任务上，dropout 比玩具模型所建议的更有竞争力，而变分推理在 MNIST 上表现得令人惊讶。</p><p>高阶建模出现在较少的比较中。但这是参考文献中的一个数字。 31 其中模型在 MNIST 上进行训练，然后在<a href="https://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html">非 MNIST</a>上进行测试<span class="footnote-reference" role="doc-noteref" id="fnrefkm10b29by7c"><sup><a href="#fnkm10b29by7c">[32]</a></sup></span> 。学习分类输出上的狄利克雷分布（EDL 虚线）与包的其余部分不同，就像包与原始模型输出（蓝色 L2 线）的不同一样： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/iyp8dpi29scplwjsybyy" alt="该图显示高阶建模给出了分布的高熵猜测。" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/p6hfgbwkaxi6erapiwuq 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/jomn5fobieqqetqjk169 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/pi2t8mbqbba98fa0jpou 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/w6trrvylxr34gdixbcwx 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/ehphdoebwsegtp3qtlsb 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/bnaqfkt3qw2dubftvxql 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/kejhllk816mnmsjsnixm 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/urqu1kjrrbmc5dvnlfbw 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/t99gmgzve5q2xvdbicct 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/ba87fp8izpeheft8u4ka 829w"><figcaption>来自<a href="https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment#fnkm10b29by7c">参考文献。 32</a> . OOD 数据集上输出熵的积分直方图（或累积分布）。训练是在 MNIST 上进行的，但测试是在<a href="https://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html">非 MNIST</a>上进行的，因此具有更高的高熵概率是好的。<br><br> EDL 是他们的狄利克雷分布模型，L2 是原始模型输出，DeepEnsemble 是一个集成，FFLU 不清楚但可能是贝叶斯 NN 近似，Dropout 是 dropout，FFG 是贝叶斯 NN 方法，MNFG 是变分推理近似。</figcaption></figure><p>当显示 OOD 数据时，这是一种非常令人印象深刻的不确定能力。是的，在分布上（在 MNIST 上）它具有正常的准确性。显然，学习何时不确定就是获取一些其他方法无法获取的信息。</p><p>但如此不确定真的正确吗？假设您正在对数字进行分类，这就是您所知道的，然后有人输入字符“B”。这肯定是8，对吧？或者也许是一个被压在一起的 13，如果你能想到这个想法的话。但它肯定不是 2。既然你知道这一点，那么在这里返回最大熵分布将是一个错误。但这似乎正是狄利克雷分布模型倾向于做的事情。</p><p>我希望高阶模型与论文中其他所有内容之间的不同行为是因为这些方法具有不同的背景假设，如果我们知道我们在做什么，我们可以在适当的时候灵活地使用不同的假设。</p><p></p><h2>我未来想从事这个领域的工作</h2><ul><li>更大的尺度<ul><li>对 Transformer 语言模型的不确定性估计进行基准测试。</li></ul></li><li>搜索的鲁棒性<ul><li>看看认知不确定性对对抗性例子有何影响。</li><li>分析找到新的对抗性例子来欺骗不确定性估计和原始指​​标是多么容易。检查这些例子对人类来说是否自然。</li></ul></li><li>非压差噪声<ul><li>当您向神经网络添加噪声时，改进采样的理论。</li><li>对不同类型的噪声进行相互比较和其他方法的基准测试。</li></ul></li><li>合奏带来更多聪明的事情<ul><li>测试改变架构的集成。</li><li>测试正在探索“相同”潜在特征的集合。</li></ul></li><li>更好的高阶模型<ul><li>发展神经网络学习二阶分布的贝叶斯视角。</li><li>通过尝试转化理论和修补信号（例如预测未来更新），为高阶模型开发更好的训练方法。</li><li>弄清楚如何使用高阶建模来获得不同背景假设的不确定性。</li></ul></li><li>更好的比较<ul><li>更系统地比较校准和 Brier 评分。</li><li>对决策问题进行基准测试，为分布数据之外的“良好行为”提供具体标准。</li><li>开发包含“自然”分布泛化的标记数据集，我们可以将其类比为现实世界中模型完成的 OOD 泛化。</li></ul></li><li>更多协同效应<ul><li>通过将多种方法结合在一起，可以获得更好的结果。校准太容易与一切结合起来，尽管它仍然是一个好主意，但这不算新闻。</li></ul></li></ul><p>如果这些论文确实存在而我错过了，请告诉我。如果他们不这样做，并且其中一个项目听起来像是您想做的事情，请联系我 - 我很乐意聊天。</p><p></p><h2>与一致性、结论的相关性</h2><p>文献与对齐的相关性不如我的预期，但这主要是因为我的期望被混淆了。我对某种“人类价值观的不确定性”感兴趣，它不同于文献中的“任意”或“认知”不确定性。</p><p>任意不确定性是从数据中得知的，但我们没有人类价值观的真实标签。或者，如果模型中有一些与人类价值观相关的潜在特征，我们不仅仅想了解该特征在某些训练集上的方差。</p><p>认知不确定性更接近，但正如文献中所使用的那样，它实际上是关于某些输出或特征对于训练目标的有用程度。在训练过程中收敛到相同答案的模型越多，认知不确定性就越小。但相对于我想要的，这感觉好像缺少一些关于首先使用什么训练程序或特征检测程序的不确定性<span class="footnote-reference" role="doc-noteref" id="fnrefmyfeye042z"><sup><a href="#fnmyfeye042z">[37]</a></sup></span> 。</p><p>正确的训练/特征检测程序的不确定性偏离了“有一个基本事实答案，不确定性是与该答案的预期偏差”的通常范式。为了保持一致，我认为图片应该更像是通信——我们试图通过架构和数据向人工智能传达一些信息，而人工智能应该对如何解释它有不确定性。</p><p>构建这种关于人类价值观的不确定性是相当棘手的——我什至还不知道我想从中得到什么！也许如果我们更清楚地理解我们想要什么，我们就可以用更标准的不确定性来构建它。例如，我们可以设计一个人工智能可以玩的“游戏”，激励对人类概念的不同解释，这样游戏中的任意和认知不确定性就可以充分捕捉到我们希望人工智能对人类价值观具有的不确定性。</p><p></p><p><i>这篇文章部分写于</i><a href="https://www.mitalignment.org/"><i>MAIA</i></a> <i>。谢谢玛雅！还有贾斯蒂斯·米尔斯（Justis Mills）进行编辑，以及波士顿的各种人士进行对话。</i> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn80ywo0pbl8r"> <span class="footnote-back-link"><sup><strong><a href="#fnref80ywo0pbl8r">^</a></strong></sup></span><div class="footnote-content"><p>主动学习文献调查。<i>伯尔·塞特尔斯</i>(2010) <a href="https://burrsettles.com/pub/settles.activelearning.pdf">https://burrsetles.com/pub/settles.activelearning.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnq23duy4ut0g"> <span class="footnote-back-link"><sup><strong><a href="#fnrefq23duy4ut0g">^</a></strong></sup></span><div class="footnote-content"><p>优化器的诅咒：决策分析中的怀疑主义和决策后惊喜。<i>詹姆斯·E·史密斯、罗伯特·L·温克勒</i>(2006) <a href="https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1050.0451">https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1050.0451</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn3dij2j9svj8"> <span class="footnote-back-link"><sup><strong><a href="#fnref3dij2j9svj8">^</a></strong></sup></span><div class="footnote-content"><p>用于检测神经网络中错误分类和分布外示例的基线。<i>丹·亨德里克斯、凯文·金佩尔</i>(2016) <a href="https://arxiv.org/abs/1610.02136">https://arxiv.org/abs/1610.02136</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnfo4svcpvxs"> <span class="footnote-back-link"><sup><strong><a href="#fnreffo4svcpvxs">^</a></strong></sup></span><div class="footnote-content"><p>使用贝叶斯统计进行神经网络不确定性评估并应用于遥感。 <i>F. Aires、C. Prigent、WB Rossow</i> (2004)</p><p>第 1 部分：网络权重<a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004173">https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004173</a></p><p>第 2 部分：输出错误<a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004174">https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004174</a></p><p>第 3 部分：网络雅可比矩阵<a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004175">https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004175</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fncogdul3x2xj"> <span class="footnote-back-link"><sup><strong><a href="#fnrefcogdul3x2xj">^</a></strong></sup></span><div class="footnote-content"><p>深度学习中不确定性估计的通用框架。<i>安东尼奥·洛奎西奥、马蒂亚·塞古、大卫·斯卡拉穆扎</i>(2020) <a href="https://www.zora.uzh.ch/id/eprint/197704/1/RAL20_Loquercio.pdf">https://www.zora.uzh.ch/id/eprint/197704/1/RAL20_Loquercio.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnamk58pvab4"> <span class="footnote-back-link"><sup><strong><a href="#fnrefamk58pvab4">^</a></strong></sup></span><div class="footnote-content"><p> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="P(parameters)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;">如果</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">P</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">是</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">高斯</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">分布</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">（</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">指数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">L2</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">正</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">则</span></span></span></span></span></span></span>化），并且您的损失是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\text{P}(dataset \; | \; parameters)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">对</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">损失</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">，</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">因此</span></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">P</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">数据</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">集</span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.278em; height: 0px;"></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">参数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">是</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">它</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">的</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">指数</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">。</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">_</span></span></span></span></span></span></span></p></div></li><li class="footnote-item" role="doc-endnote" id="fnlpb1b2qcoen"><span class="footnote-back-link"><sup><strong><a href="#fnreflpb1b2qcoen">^</a></strong></sup></span><div class="footnote-content"><p>神经网络的不确定性：近似贝叶斯集成。<i>蒂姆·皮尔斯、菲利克斯·莱布弗里德、亚历山德拉·布林特鲁普、穆罕默德·扎基、安迪·尼利</i>(2020) <a href="http://proceedings.mlr.press/v108/pearce20a/pearce20a.pdf">http://proceedings.mlr.press/v108/pearce20a/pearce20a.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnd9jz9mfml"> <span class="footnote-back-link"><sup><strong><a href="#fnrefd9jz9mfml">^</a></strong></sup></span><div class="footnote-content"><p>最明显的问题是 Hessian 矩阵的奇点。但在短长度尺度上，损失情况也可能会很复杂，使得低阶近似有时会失败。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnbct5kii2m07"> <span class="footnote-back-link"><sup><strong><a href="#fnrefbct5kii2m07">^</a></strong></sup></span><div class="footnote-content"><p>面向神经网络的校准和可扩展的不确定性表示。<i>纳比尔·西达特、克里斯托弗·卡南</i>(2019) <a href="https://arxiv.org/abs/1911.00104">https://arxiv.org/abs/1911.00104</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnen0yeoqzg0k"> <span class="footnote-back-link"><sup><strong><a href="#fnrefen0yeoqzg0k">^</a></strong></sup></span><div class="footnote-content"><p>使用深度集成的简单且可扩展的预测不确定性估计。 <i>Balaji Lakshminarayanan、Alexander Pritzel、Charles Blundell</i> (2017) <a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/9ef2ed4b7fd2c810847ffa5fa85bce38-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2017/file/9ef2ed4b7fd2c810847ffa5fa85bce38-Paper.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnxqxuuw1xe2"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxqxuuw1xe2">^</a></strong></sup></span><div class="footnote-content"><p>计算机视觉的贝叶斯深度学习需要哪些不确定性？<i>亚历克斯·肯德尔，亚林·加尔</i>(2017) <a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/2650d6089a6d640c5e85b2b88265dc2b-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2017/file/2650d6089a6d640c5e85b2b88265dc2b-Paper.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn2jiolbj6tn8"> <span class="footnote-back-link"><sup><strong><a href="#fnref2jiolbj6tn8">^</a></strong></sup></span><div class="footnote-content"><p>源自希腊语，意思是“关于知识”和“关于赌博”。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnud7l8eu73jk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefud7l8eu73jk">^</a></strong></sup></span><div class="footnote-content"><p> 2 如何仅在给定模型权重的情况下判断你的输入是否不符合分布， <i>dkirmani</i> (2023) <a href="https://www.lesswrong.com/posts/tvLi8CyvvSHrfte4P/how-2-tell-if-ur-input-is-out-of-distribution-given-only">https://www.lesswrong.com/posts/tvLi8CyvvSHrfte4P/how-2-tell-if-ur-input-is-out-of -仅给定分布</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnlgnhfp0m35e"><span class="footnote-back-link"><sup><strong><a href="#fnreflgnhfp0m35e">^</a></strong></sup></span><div class="footnote-content"><p>现实世界中存在噪声，因此，如果小的输入噪声极大地改变了您的答案，您就不应该对此充满信心。相反，在表现良好的输入上，神经网络学会对噪声具有鲁棒性。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnhfox6k7gfev"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhfox6k7gfev">^</a></strong></sup></span><div class="footnote-content"><p>密集回归的免训练不确定性估计：灵敏度作为替代。<i>卢米、王浩、田永龙、何浩、Nir Shavit</i> (2022) <a href="https://arxiv.org/abs/1910.04858">https://arxiv.org/abs/1910.04858</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn0hl862nst9f9"> <span class="footnote-back-link"><sup><strong><a href="#fnref0hl862nst9f9">^</a></strong></sup></span><div class="footnote-content"><p>深度神经网络不确定性调查。<i>雅各布·高利科斯基等人。</i> (2021) <a href="https://arxiv.org/abs/2107.03342">https://arxiv.org/abs/2107.03342</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnu11lguv41wc"> <span class="footnote-back-link"><sup><strong><a href="#fnrefu11lguv41wc">^</a></strong></sup></span><div class="footnote-content"><p>估计心脏 MRI 分割神经网络的不确定性：一项基准研究。<i>马修·吴、富民·郭、Labonny Biswas、Steffen E. Petersen、Stefan K. Piechnik、Stefan Neubauer、Graham Wright</i> (2023) <a href="https://ieeexplore.ieee.org/abstract/document/10002847">https://ieeexplore.ieee.org/abstract/document/10002847</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnhzxdsrsco9g"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhzxdsrsco9g">^</a></strong></sup></span><div class="footnote-content"><p>你能相信你的模型的不确定性吗？评估数据集变化下的预测不确定性。 <i>Yaniv Ovadia、Emily Fertig、Jie Ren、Zachary Nado、D Sculley、Sebastian Nowozin、Joshua V. Dillon、Balaji Lakshminarayanan、Jasper Snoek</i> (2019) <a href="https://arxiv.org/abs/1906.02530">https://arxiv.org/abs/1906.02530</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnfqljh5j8ipf"> <span class="footnote-back-link"><sup><strong><a href="#fnreffqljh5j8ipf">^</a></strong></sup></span><div class="footnote-content"><p>深度神经网络倾向于进行可预测的推断。<i>凯蒂·康、阿姆里斯·塞特勒、克莱尔·汤姆林、谢尔盖·莱文</i>(2023) <a href="https://arxiv.org/abs/2310.00873">https://arxiv.org/abs/2310.00873</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnvl2ahm3user"> <span class="footnote-back-link"><sup><strong><a href="#fnrefvl2ahm3user">^</a></strong></sup></span><div class="footnote-content"><p>对于分布外检测来说似乎更常见，例如增强神经网络中分布外图像检测的可靠性。<i>梁世宇、李亦轩、R.Srikant</i> (2020) <a href="https://arxiv.org/abs/1706.02690">https://arxiv.org/abs/1706.02690</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnzkojoz799ka"> <span class="footnote-back-link"><sup><strong><a href="#fnrefzkojoz799ka">^</a></strong></sup></span><div class="footnote-content"><p> GPT-4 技术报告。 <i>OpenAI</i> (2023) <a href="https://openai.com/research/gpt-4">https://openai.com/research/gpt-4</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnnglt70rybd9"> <span class="footnote-back-link"><sup><strong><a href="#fnrefnglt70rybd9">^</a></strong></sup></span><div class="footnote-content"><p> Mix-n-Match：深度学习中不确定性校准的集成和组合方法。<i>张继泽、Bhavya Kailkhura、T. Yong-Jin Han</i> (2020) <a href="https://arxiv.org/abs/2003.07329">https://arxiv.org/abs/2003.07329</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fngx8tqfun0w"> <span class="footnote-back-link"><sup><strong><a href="#fnrefgx8tqfun0w">^</a></strong></sup></span><div class="footnote-content"><p>不确定性量化和深度集成。<i>拉胡尔·拉哈曼、亚历山大·H·蒂埃里</i>(2020) <a href="https://arxiv.org/abs/2007.08792">https://arxiv.org/abs/2007.08792</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fntmgq2x5m6t"> <span class="footnote-back-link"><sup><strong><a href="#fnreftmgq2x5m6t">^</a></strong></sup></span><div class="footnote-content"><p>在分布外数据集上校准深度神经网络分类器。<i>邵志辉、杨建一、任少雷</i>(2020) <a href="https://arxiv.org/abs/2006.08914">https://arxiv.org/abs/2006.08914</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fng3rtbqm4247"> <span class="footnote-back-link"><sup><strong><a href="#fnrefg3rtbqm4247">^</a></strong></sup></span><div class="footnote-content"><p>归纳共形预测：神经网络的理论与应用。<i>哈里斯·帕帕佐普洛斯</i>(2008) <a href="https://www.intechopen.com/chapters/5294">https://www.intechopen.com/chapters/5294</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnqbdlqupa3x"> <span class="footnote-back-link"><sup><strong><a href="#fnrefqbdlqupa3x">^</a></strong></sup></span><div class="footnote-content"><p>通过 Logit 归一化缓解神经网络过度自信。<i>魏洪欣、谢仁春子、程浩、冯雷、安博、李一轩</i>(2022) <a href="https://proceedings.mlr.press/v162/wei22d/wei22d.pdf">https://proceedings.mlr.press/v162/wei22d/wei22d.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn2qfcvdqkx2y"> <span class="footnote-back-link"><sup><strong><a href="#fnref2qfcvdqkx2y">^</a></strong></sup></span><div class="footnote-content"><p>使用噪声对比先验对深度神经网络进行可靠的不确定性估计。 <i>Danijar Hafner、Dustin Tran、Timothy Lillicrap、Alex Irpan、James Davidson</i> (2018) <a href="https://openreview.net/forum?id=HkgxasA5Ym">https://openreview.net/forum?id=HkgxasA5Ym</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnazba93s687"> <span class="footnote-back-link"><sup><strong><a href="#fnrefazba93s687">^</a></strong></sup></span><div class="footnote-content"><p>通过对抗性训练和预训练改进 OOD 泛化。<i>易明阳、侯鲁、孙家成、尚立峰、蒋欣、刘群、马志明</i>(2021) <a href="http://proceedings.mlr.press/v139/yi21a/yi21a.pdf">http://proceedings.mlr.press/v139/yi21a/yi21a.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnv1gf6chx43"> <span class="footnote-back-link"><sup><strong><a href="#fnrefv1gf6chx43">^</a></strong></sup></span><div class="footnote-content"><p> SolidGoldMagikarp（加上，提示生成）。<i>杰西卡·朗贝罗、马修·沃特金斯</i>(2023)<i> </i><a href="https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation">https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt- Generation</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fna3kc8qjhdn6"> <span class="footnote-back-link"><sup><strong><a href="#fnrefa3kc8qjhdn6">^</a></strong></sup></span><div class="footnote-content"><p>对抗性例子不是错误，而是特征。<i>安德鲁·伊利亚斯等人。</i> （2019） <a href="https://arxiv.org/abs/1905.02175">https://arxiv.org/abs/1905.02175</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn28983dpfjdp"> <span class="footnote-back-link"><sup><strong><a href="#fnref28983dpfjdp">^</a></strong></sup></span><div class="footnote-content"><p>如果我们使用生成而不是搜索来构建良好的输出，则可以回避优化不稳健的问题。或者在强化学习环境中，如果我们使用策略预测器将我们保持在系统的有效性范围内。但这是昂贵的，有时容易受到以不同速率泛化的能力的影响。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnkm10b29by7c"> <span class="footnote-back-link"><sup><strong><a href="#fnrefkm10b29by7c">^</a></strong></sup></span><div class="footnote-content"><p>用于量化分类不确定性的证据深度学习。<i>穆拉特·森索伊、兰斯·卡普兰、梅利赫·坎德米尔</i>(2018) <a href="https://arxiv.org/abs/1806.01768">https://arxiv.org/abs/1806.01768</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnhfc8x4hav0b"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhfc8x4hav0b">^</a></strong></sup></span><div class="footnote-content"><p>使用狄利克雷深度神经网络识别域外对象。<i>艾哈迈德·哈曼、弗兰克·博纳伦斯、赛义德·E·戈巴迪、克里斯托夫·斯蒂勒</i>(2023) <a href="https://openaccess.thecvf.com/content/ICCV2023W/UnCV/papers/Hammam_Identifying_Out-of-Domain_Objects_with_Dirichlet_Deep_Neural_Networks_ICCVW_2023_paper.pdf">https://openaccess.thecvf.com/content/ICCV2023W/UnCV/papers/Hammam_Identifying_Out-of-Domain_Objects_with_Dirichlet_Deep_Neural_Networks_ICCVW_2023_paper.pdf</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnffdudph3qus"> <span class="footnote-back-link"><sup><strong><a href="#fnrefffdudph3qus">^</a></strong></sup></span><div class="footnote-content"><p>教学模型用言语表达不确定性。<i>斯蒂芬妮·林、雅各布·希尔顿、欧文·埃文斯</i>(2023) <a href="https://openreview.net/forum?id=8s8K2UZGTZ">https://openreview.net/forum?id=8s8K2UZGTZ</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnadsp4hkxuk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefadsp4hkxuk">^</a></strong></sup></span><div class="footnote-content"><p>直接从 GPT-3 中导出概率。<i>努诺·森佩雷</i>(2023) <a href="https://forum.effectivealtruism.org/posts/aGmhi4uvAJptY8TA7/straightforwardly-eliciting-probabilities-from-gpt-3#Fine_tune_the_model_on_good_worked_examples_of_forecasting_reasoning">https://forum. effectivealtruism.org/posts/aGmhi4uvAJptY8TA7/straightforwardly-eliciting-probabilities-from-gpt-3#Fine_tune_the_model_on_good_worked_examples_of_forecasting_reasoning</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnxuwhb9ieyh"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxuwhb9ieyh">^</a></strong></sup></span><div class="footnote-content"><p>关于认知不确定性量化的二阶评分规则。<i>维克托·本格斯、艾克·胡勒迈尔、威廉·韦格曼</i>(2023) <a href="https://arxiv.org/abs/2301.12736">https://arxiv.org/abs/2301.12736</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnmyfeye042z"> <span class="footnote-back-link"><sup><strong><a href="#fnrefmyfeye042z">^</a></strong></sup></span><div class="footnote-content"><p>我可能还会提到关于使用什么抽象或使用什么推理程序的不确定性。但这些似乎是培训的下游。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment<guid ispermalink="false"> 79eegMp3EBs8ptFqa</guid><dc:creator><![CDATA[Charlie Steiner]]></dc:creator><pubDate> Tue, 05 Dec 2023 08:01:32 GMT</pubDate></item><item><title><![CDATA[Analyzing the Historical Rate of Catastrophes]]></title><description><![CDATA[Published on December 5, 2023 6:30 AM GMT<br/><br/><p>为了传达风险，我们经常求助于故事。核武器让人想起相互毁灭、带有红色按钮的公文包和核冬天的故事。气候变化让人想起极端天气、海平面上升导致城市崩溃以及农作物歉收等故事。新冠疫情之后的流行病几乎不需要想象力，但以前却是<em><a href="https://en.wikipedia.org/wiki/Contagion_(2011_film)?ref=bounded-regret.ghost.io">《传染病》</a></em>等电影的主题。</p><p>故事非常适合传达具体的风险（我自己<a href="https://bounded-regret.ghost.io/gpt-2030-and-catastrophic-drives-four-vignettes/">最近就人工智能风险做了这件事</a>），但它们不是预测未来的好方法。这是因为大多数故事都过于具体，不可能发生。更重要的是，故事往往具有简短、简单的因果链，而现实则复杂且具有多种因果关系。</p><p>大多数有竞争力的预测者不是使用故事，而是通过查看历史<a href="https://forecasting.quarto.pub/book/base-rates.html?ref=bounded-regret.ghost.io">参考类别</a>来开始预测。这非常有效，而且也很有意义：历史通过以实际发生的事件为基础，使我们摆脱了讲故事的偏见。虽然历史是通过叙述来过滤的，但好的历史将与现实的复杂性相抗衡，我们可以通过基于原始数字来进一步剥离叙述。 <sup><a href="#fn1">[1]</a></sup></p><p>在这篇文章中，我将使用参考课程来了解当今社会面临的最大风险。我将通过考虑历史灾难​​的两个不同参考类来做到这一点：</p><ul><li>导致全球大部分人口死亡的事件（<a href="#historical-causes-of-human-population-loss">第 1 节</a>）</li><li>物种灭绝，特别是大规模灭绝事件（<a href="#species-extinctions">第 2 节</a>）</li></ul><p>通过查看这些参考课程，我们学到了两件事。首先，它为我们提供了不同灾难的罕见程度的数值估计。如果我们将灾难定义为十年内导致全球 1% 人口死亡的事件，那么自 1500 年以来，已经发生了 11 起此类灾难，每年发生的基准率为 2%。如果我们提高杀死 10% 人口的标准，基本死亡率就会下降一个数量级，降至 0.2%。</p><p>历史也为我们提供了定性的见解。例如，上一段中的灾难都是流行病、战争或饥荒。此外，许多事件都是多重原因造成的——最严重的流行病发生在人口已经因饥荒而虚弱的时候，而许多流行病和饥荒是由于气候变化或政治动荡而加剧的。物种灭绝也是多因素造成的，常见的罪魁祸首是气候变化、自然灾害、入侵物种和人类。</p><p>反对使用历史基本利率的一个论点是，现在与过去如此不同（例如由于技术），以至于基本利率毫无意义。虽然当今世界确实与过去不同，但基本利率可以通过澄清实际上的新内容来帮助加剧而不是忽视这些差异。例如，仅仅技术的存在并不能让我们远远高于基本速度，因为历史上已经开发了许多技术，但没有一项技术造成了上述意义上的灾难。相反，我们应该寻找与灾难的历史驱动因素具有共同特征的技术：流行病、饥荒、战争、政治动荡、气候变化、自然灾害、入侵物种和人类。</p><p>我详细分析了这些驱动程序（<a href="#takeaways-for-modern-catastrophes-and-for-ai">第 3 节</a>），发现它们分为几个核心组：</p><ul><li>全球或区域规模的自然事件（饥荒、气候变化、自然灾害）</li><li>新型、高度适应、自我复制的生物体（流行病、新型病原体和捕食者、入侵物种）</li><li>协调一致的人类群体寻求资源、土地或权力（战争、政治动荡、过度狩猎和栖息地破坏导致的灭绝）</li></ul><p>此列表是有道理的 - 要产生全球影响，应该从全球范围（大型自然事件）开始，或者有能力到达那里的手段（自我复制，协调）。</p><p>从这个角度来看，21世纪的灾难驱动因素是什么？从上面的列表中可以明显看出一些答案 - 助手，气候变化和重大战争仍然是严重的威胁。饥荒不太明显地威胁性，因为最后一个主要是1961年，但为饥荒的准备仍然可能是谨慎的。而政治动荡本身并非灾难性，为其他灾难带来了发生的条件。</p><p>转向新技术，工程病原体是危险的，因为它们是新型的自我复制者，<a href="https://en.wikipedia.org/wiki/Gray_goo?ref=bounded-regret.ghost.io">某些类型的纳米技术</a>也是如此。核武器是危险的，因为它们与自然灾害具有相似的影响，并且因为它们增加了战争中最严重的损害。</p><p>最后，不幸的是，AI（我自己的研究领域）与许多灾难驱动因素具有共同的特性。它是一种新颖的自我复制器（可以复制自身），可以快速适应新数据。可以对AI系统<a href="https://arxiv.org/abs/1705.08926?ref=bounded-regret.ghost.io">进行培训以协调</a>并<a href="https://bounded-regret.ghost.io/intrinsic-drives-and-extrinsic-misuse-two-intertwined-risks-of-ai/">寻求权力</a>，从而反映人类协调群体的威胁。最后，如果AI导致经济动荡和随后的政治动荡，可能会加剧其他灾难的驱动因素。</p><h1>人口损失的历史原因</h1><p>为了开始我们的分析，我研究了人口损失的最大历史原因，这是由被给定事件杀死的全球人口的比例来衡量的。为此，我结合了Wikipedia的<a href="https://en.m.wikipedia.org/wiki/List_of_anthropogenic_disasters_by_death_toll?ref=bounded-regret.ghost.io#Wars_and_armed_conflicts">主要战争</a>， <a href="https://en.m.wikipedia.org/wiki/List_of_anthropogenic_disasters_by_death_toll?ref=bounded-regret.ghost.io#Abuse_of_workers,_forced_laborers_and_slaves">奴隶制和其他强迫劳动</a>，<a href="https://en.m.wikipedia.org/wiki/List_of_famines?ref=bounded-regret.ghost.io">饥荒</a>， <a href="https://en.m.wikipedia.org/wiki/List_of_epidemics_and_pandemics?ref=bounded-regret.ghost.io">流行病</a>和<a href="https://en.m.wikipedia.org/wiki/List_of_natural_disasters_by_death_toll?ref=bounded-regret.ghost.io">自然灾害的</a>数据。我考虑了其他数据来源，例如技术灾难，但所有这些数据来源的死亡人数比上面的五个要小得多。主要例外是种族灭绝，因为它们通常与战争同时发生，并且已经包含在那些死亡人数中，因此我排除了它们以避免双重计数。</p><p>我编写了一个Python脚本（在<a href="#scraping-script">附录</a>中共享）来刮擦这些来源并将它们汇总到单个PANDAS DataFrame中，然后被过滤以创建两个数据集：</p><ul><li><strong>灾难性</strong>：所有事件杀死至少0.1％的人口的事件，这些事件通过在事件开始时被世界人口划分的总死亡而计算出来。 <sup><a href="#fn2">[2]</a></sup> <sup><a href="#fn3">[3]</a></sup></li><li><strong>严格的灾难</strong>：我进一步局限于“快速”（持续不到十年）的事件，其中至少有1％的人口死亡。</li></ul><p>一组灾难包括85个事件，其中80起发生以来发生，其中33例是战争，28人是饥荒，15例是流行病，有6人是强迫劳动，而3例是自然灾害。严格的灾难包括17个事件：5场战争，8种饥荒和4个流行病。我在下面包括严格的灾难的完整列表，以及所有灾难的散点图（有关原始数据，请参见<a href="#scraping-script">附录</a>）。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/zsdej27vshx817jxxgzq"></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/aoh79fzuiwbvftkounrs"></p><p>除了这些历史事件外，两个重要的史前事件是<a href="https://en.wikipedia.org/wiki/Toba_catastrophe_theory?ref=bounded-regret.ghost.io">Toba灾难</a>（人口下降了97％，可能是由于Supervolcano的造成的）和<a href="https://en.wikipedia.org/wiki/4.2-kiloyear_event?ref=bounded-regret.ghost.io">4.2KYA事件</a>（可能导致全球饥荒，但死亡人数尚不清楚）。</p><p><strong>报告偏见和基本费率。</strong>由于我们看到1500年代和1900年代再次灾难的速度“增加”的速度很可能会有偏见，而且这对于包括饥荒在内的所有类别都会发生这种情况（随着时间的推移会随着时间的推移而降低）。如果我们从1500起开始，则发生了51次灾难（0.11/年），有11例严格的灾难（0.02/年）。</p><p>让我们下一个模型（快速）灾难<sup><a href="#fn4">[4]</a></sup>的基本速率如何随其严重程度而变化。查看所有导致人口至少下降1％的灾难，我们看到了大约<a href="https://en.wikipedia.org/wiki/Zipf%27s_law?ref=bounded-regret.ghost.io">Zipfian</a>分布：死亡率为R的灾难的可能性与1/R成正比。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/wgfcegdndv1dtfwggmzl"></p><p>基于此，死亡率10％的灾难的发生率为0.002/年（每5世纪一次），死亡率为1％的灾难发生0.02/年（每世纪两次）。尽管这些数字似乎很低，但它们表明，<strong>在未来25年中，大约有10％的灾难灾难的机会大约有5％的机会</strong>（由于0.002 * 25 = 0.05）。</p><p>低于1％的死亡率，灾难比ZIPF定律预测的可能性少（请参阅<a href="#log-log-plot-of-catastrophes">附录</a>）。例如，0.1％死亡率的经验频率为0.08/年（略低于每十年一次）。</p><p><strong>随着时间的推移趋势。</strong>如果我们计算自1500年以来每十年的灾难，我们将获得以下图： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/wb5os0qkd9psxc2zrno9"></p><p>在1850  -  1950年期间，还有更多的灾难，尽管我怀疑这是报告偏见的文物。在此期间之前，随着时间的流逝，灾难的发生率大致恒定： <a href="https://en.wikipedia.org/wiki/Ljung%E2%80%93Box_test?ref=bounded-regret.ghost.io">Ljung-box测试</a>和<a href="https://en.wikipedia.org/wiki/Wald%E2%80%93Wolfowitz_runs_test?ref=bounded-regret.ghost.io">Wald-Wolfowitz测试</a>都不能拒绝在数十年中从1500-1900数十年来分布灾难的零（P = 0.36和0.26） ， 分别）。</p><p>随着时间的流逝，最值得注意的变化是我们目前处于平静时期，从1950  -  1960年左右开始。确实，自20世纪上半叶以来，灾难显着下降：</p><ul><li> 9个饥荒发生在20世纪上半叶，但下半年只有1次（中国饥荒，1959- 1961年）</li><li>上半场发生了5场重大战争，但下半场只有1次（朝鲜战争，1950- 1953年）</li><li>流行病更为恒定，上半场有2个，下半场有1个（加2019年的Covid）。</li></ul><p>由于粮食生产和储存量更好，饥荒可能会减少，这是持久的改善。战争可能由于<a href="https://en.wikipedia.org/wiki/Pax_Americana?ref=bounded-regret.ghost.io">PAX Americana</a>而减少，但不幸的是，由于日益增长的全球紧张局势可能会放松。因此，流行病和（可能）战争是迄今为止灾难的主要现代来源。</p><p><strong>定性分析：多用途。</strong>许多灾难有多种原因。例如，在黑死的主要理论中，气候变化是两种方式的驱动力。首先，亚洲的气候变化导致啮齿动物从山区迁移到人口更多的地区，从而传播了这种疾病。其次，欧洲的小冰河时代导致饥荒，导致人口疲软，因此更容易受到疾病的影响。 <sup><a href="#fn5">[5]</a></sup>有趣的是，黑死亡也可能通过造成人口减少的重新森林造成造林，从而加剧了较小的冰河时代，从而导致碳捕获和随后的冷却。</p><p>给出其他多种原因的例子：</p><ul><li>在美洲的欧洲殖民化中，大多数死亡是由于疾病而不是战争造成的。</li><li>从明对的过渡是由许多因素引起的，包括疾病和饥荒。饥荒本身可能是由小冰河时代引起的。</li><li> Taiping叛乱是由于饥荒的政治动荡而开始的，随后的许多死亡是由干旱，饥荒和疾病而不是军事死亡引起的。</li><li>总的来说，许多饥荒是由气候事件和/或不良政府政策造成的。</li></ul><p>总体而言，这表明要减少灾难的数量或强度，我们不仅应立即攻击原因，而且还应攻击更多的系统性上游原因。</p><h1>物种灭绝</h1><p>作为第二个参考类别，我考虑了非人类物种的灭绝。 <sup><a href="#fn6">[6]</a></sup>由于几个原因，这更难分析：</p><ul><li>大多数灭绝发生在数百万年前，因此我们只有间接证据，并且存在明显的采样偏见，因为某些物种更容易保存为化石。</li><li>如果一个物种逐渐适应一种新物种，我们可能不想将其算作“灾难”。</li><li>一些声称的质量灭绝事件实际上可能是一段时间内发生的许多较小事件。</li></ul><p>为了减少这些困难，我将专注于两个相对较新的灭绝事件：</p><ul><li>第四纪晚期灭绝（ <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev.ecolsys.34.011802.132415?journalCode=ecolsys&amp;ref=bounded-regret.ghost.io">Koch and Barnosky，2006年</a>），发生在10,000-50,000年前，导致大多数大型哺乳动物灭绝。</li><li><a href="https://en.wikipedia.org/wiki/Holocene_extinction?ref=bounded-regret.ghost.io">全新世灭绝</a>发生在过去10，000年中（在过去的一个世纪中增加），主要是由人类的狩猎和栖息地破坏驱动。</li></ul><p>尽管大多数历史大规模灭绝事件都是由气候变化或自然灾害驱动的，但这两个最近的灭绝事件被认为是人类全部或部分驱动的。我将在下面回顾有关两个灭绝事件的证据和领导理论。</p><h2>历史基本率</h2><p>在讨论第四纪和全新世灭绝之前，让我们计算上下文的基本费率。根据化石记录，平均<a href="https://en.wikipedia.org/wiki/Background_extinction_rate?ref=bounded-regret.ghost.io">每百万年每种物种大约有一个灭绝</a>。 <sup><a href="#fn7">[7]</a></sup>但是，这些灭绝并不是在时间的范围内恒定，而是以“脉冲”为中，如下所示（ <a href="https://en.wikipedia.org/wiki/Extinction_event?ref=bounded-regret.ghost.io">Wikipedia的</a>图像）： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/dfuifcmc1rwf6nughndc"></p><p>在这些脉冲中，每百万年的灭绝量大约是背景速率2-10倍。 <sup><a href="#fn8">[8]</a></sup></p><h2>第四纪晚期灭绝</h2><p><a href="https://en.wikipedia.org/wiki/Quaternary_extinction_event?ref=bounded-regret.ghost.io">第四纪晚期的灭绝</a>将一段时间从约50,000年前到10，000年前。在这段时间里，大约34％的哺乳动物灭绝了，包括美洲和澳大利亚的大多数哺乳动物以及全球几乎所有大型哺乳动物。这是一个比预期的背景灭绝率高的数量级（在40，000年内约为4％）。</p><p>下面的表（根据Wikipedia改编）按地理区域和规模灭绝的文档灭绝： </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/hyklusibuiqlssx8a9j4"></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/xfvtfxj13q8vij8qqsmx"></p><p>如表所示，灭绝在非洲（人类起源的地方，因此哺乳动物可以共同进化），并且在大型哺乳动物中最为严重。</p><p><strong>原因。</strong>从历史上看，研究人员辩论了这些灭绝是由气候变化还是人类接触驱动的。为了理解这场辩论，我阅读了几篇论文，并选择关注<a href="https://www.annualreviews.org/doi/abs/10.1146/annurev.ecolsys.34.011802.132415?journalCode=ecolsys&amp;ref=bounded-regret.ghost.io">Koch＆Barnosky（2006）</a> ，该论文系统地回顾了许多竞争理论。 Koch＆Barnosky得出的结论是，灭绝的模式和强度是由人类驱动的，但是气候变化是重要的额外贡献者：<br><br></p><p> “从整体上讲，最近的研究表明，人类通过联合直接（狩猎）以及间接（竞争，栖息地的改变和碎片化）促进了全球许多地区的灭绝，但是晚期的环境变化影响了时机，地理，地理位置影响，也许是灭绝的大小。换句话说，没有<i>智人智人</i>的各种影响，在晚期季季晚期，全球生态系统极不可能经历大型慢养动物的大规模灭绝。但是，没有同时存在的快速气候变化在全球许多地区明显看出，某些物种可能持续更长的时间。”</p><p>因此，人类可能会驱动灭绝的几条途径：</p><ul><li>直接狩猎</li><li>间接狩猎（狗，老鼠和我们带来的其他动物）</li><li>栖息地破坏（例如，人为火灾）</li></ul><p>重要的是，由于不同的原因，不同的物种可能灭绝。 Koch＆Barnosky认为，欧亚大陆的大多数灭绝都是由于气候变化所致，澳大利亚和大多数岛屿上的灭绝都几乎完全归因于人类，而北美主要是人类具有气候的人类，这是一个加剧的因素。</p><p>这是一个说明关键点的故事。它与Koch＆Barnosky一致，但是不确定性支持简单。</p><ul><li>当人类到达岛屿时，他们带来了猪，狗和大鼠，所有这些都捕食了土著物种。由于岛屿物种在进化上是对这些掠食者的幼稚，因此许多物种灭绝了。</li><li>由于火和土地清理造成的栖息地破坏也导致了岛屿灭绝。</li><li>在较大的土地上，哺乳动物并不是进化于食肉动物的掠食者，因此并不容易灭绝。但是，人类是非常有效的猎人，足以使许多物种的出生率低于死亡率，这最终导致了数千年的灭绝。</li><li>重要的是，人类的饮食多种多样，因此即使他们狩猎了一些哺乳动物以灭绝，他们也从其他动物和植物那里收集了足够的食物来维持大量人口，从而避免了传统的<a href="https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations?ref=bounded-regret.ghost.io">捕食者捕食周期</a>。</li><li>在非洲和欧亚大陆，哺乳动物与人类或其前辈共同发展了数十万年以上。因此，他们有足够的进化时间来为有效的人类猎人开发防御能力，并解释了与美国和澳大利亚的灭绝率较低。</li></ul><p>总体而言，人类的狩猎可能是非岛屿灭绝的主要驱动力，还有其他因素，例如气候变化。重要的是，人类是一种新颖的捕食者是不够的，因为新的掠食者并不总是会导致灭绝。同样重要的是，我们是一个特别有效的捕食者，可以占据许多地理区域并且饮食多样化。</p><h2>全新世灭绝</h2><p>全新世灭绝开始于大约10，000年前，最近有可能加速，大多数研究人员认为人类发挥了重要作用。</p><p>矛盾的是，尽管最近发生，但全新世灭绝的程度比晚期灭绝晚期更具争议性，原因有两个。首先，大多数其他灭绝计数都取决于化石记录，但全新世灭绝是基于人类的当前和历史观察。这使得很难进行直接比较，因为两种方法具有不同的（且大）的采样偏差。其次，全新世灭绝的程度被政治化，因为它对于当今关于自然保存的论点至关重要，因此很难找到中性来源。</p><p>浏览了几篇论文后，我决定关注<a href="https://www.nature.com/articles/nature09678?ref=bounded-regret.ghost.io">Barnosky等人。 （2011）</a> <sup><a href="#fn9">[9]</a></sup> ，仔细讨论了采样偏见的几种来源，并试图为它们纠正它们。 Barnosky等。得出的结论是，在过去的500年中，总物种中有几个已经灭绝，这比灭绝的预期背景速率高（请注意，某些论文给出了更高的估计<sup><a href="#fn10">[10]</a></sup> ）。 Barnosky等。还得出结论，如果大多数濒危物种在下一个世纪灭绝，并且这种速度持续下去，我们将在几个世纪内失去所有物种中的大多数，仅与5个历史（通常更慢）的大规模灭绝事件相当。</p><p><strong>原因。</strong> Barnosky等。列出几种造成这些灭绝的压力源：“迅速变化的大气条件和变暖[...]，栖息地破碎，污染，过度捕捞和过度狩猎，入侵物种和病原体[...]以及扩大人类生物量”。 <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev.ecolsys.34.011802.132415?journalCode=ecolsys&amp;ref=bounded-regret.ghost.io">Koch and Barnosky（2006）</a>增加了第四纪灭绝的生态破坏，作为进一步的压力源。 <sup><a href="#fn11">[11]</a></sup></p><p>与过去的灭绝不同，我们可以直接观察到当今许多全新世灭绝的原因。基于<a href="https://pubmed.ncbi.nlm.nih.gov/20978281/?ref=bounded-regret.ghost.io">Hoffmann等。 （2010年）</a> ，栖息地破坏是当前灭绝的最大驱动因素，其次是入侵物种（包括疾病）和过度狩猎，其次是环境原因，例如气候变化和污染。 <sup><a href="#fn12">[12]</a></sup> <sup><a href="#fn13">[13]</a></sup></p><h2>摘要：灭绝的典型原因是什么？</h2><p>总体而言，我对过去灭绝的分析指出了一个物种可以灭绝的几种方式：</p><ul><li>大规模的灾难或气候事件直接使物种不可行，或者破坏生态系统并导致后来的灭绝。</li><li>引入了一种新颖的侵略性生物，原始物种尚未适应该生物。这包括：<ul><li>一种入侵物种，它可以直接胜任其利基市场或破坏周围生态系统的物种。</li><li>一种新颖的病原体，特别是如果它具有<a href="https://en.wikipedia.org/wiki/Natural_reservoir?ref=bounded-regret.ghost.io">储层物种</a>。 <sup><a href="#fn14">[14]</a></sup></li><li>一个新的，有效的捕食者。这对岛屿物种影响最大，因为大陆物种在进化上暴露于多种捕食者中，以发展强大的反策略。但是，即使对于非岛屿物种，具有多种饮食的非常有效的捕食者也会淹没这些进化的防御能力。</li></ul></li><li>栖息地的变化（通常来自气候变化或其他物种）。</li><li>其他物种灭绝的后续作用。这部分与上面的项目重叠：例如，大型生动的灭绝导致森林的再生，因此显着改变了其他物种的栖息地。</li></ul><p>因此，通常大多数物种灭绝是由以下原因引起的：</p><ul><li>原始物种没有机会适应的第二种物种。第二种也必须不依赖原始物种来传播自身。</li><li>灾难性的自然灾害或气候事件。</li><li>上面两个来源之一造成的栖息地破坏或生态系统破坏。</li></ul><p><strong>为什么灭绝通常很少见。</strong>由于灭绝通常的基本速率较低，因此灭绝的原因必须很少见。为了更好地了解<em>可能</em>导致灭绝的是什么，让我们理解为什么大多数对物种的威胁<em>不会</em>导致灭绝。</p><p>首先，大多数捕食者不会造成灭绝。这是因为猎物与捕食者的犯罪同时发展防御，而捕食者越好的是猎物上的进化压力越多（因此，防御速度更快）。除此之外，如果猎物变得太罕见，那么捕食者种群<a href="https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations?ref=bounded-regret.ghost.io">通常会崩溃</a>，从而使猎物种群重新成长。因此，捕食者通常只有在（1）两者进入具有非进化适应猎物的新环境时才造成灭绝，并且（2）它们以多种物种为食，以便它们可以驱使一个物种灭绝而不会自身人口崩溃。</p><p>同样，默认情况下，新颖的病原体不会导致宿主灭绝，因为如果它们杀死了太多的宿主物种，他们就没有靶标要传播。取而代之的是，“病原体更有可能引起宿主的灭绝，如果它们……具有长期传染病，或者是可以在普通储层宿主和更脆弱的目标物种之间传播的多宿主病原体”（ <a href="https://www.nature.com/scitable/knowledge/library/disease-ecology-15947677/?ref=bounded-regret.ghost.io">Kilpatrick和Altizer，2010年</a>） 。</p><p><strong>人类。</strong>最后，让我们分析为什么人类尤其是如此有效的猎人，以至于我们能够驱动这么多物种灭绝。首先，我们具有高度适应性的能力，因此不仅能够生存，而且能够在各种环境中依靠多种食物来源。这使我们在全球范围内传播，并驱动一些物种灭绝，同时仍有其他食物来源。其次，我们可以有效地协调（ <a href="https://www.scientificamerican.com/article/how-homo-sapiens-became-the-ultimate-invasive-species/?ref=bounded-regret.ghost.io">Marean，2015年</a>），通过更好的战术使更大的猎物压倒了较大的猎物。最后，我们使用工具和技术来提高狩猎能力并塑造环境，放大上面讨论的两个关键灭绝驱动因素。</p><h1>现代灾难和人工智能的收获</h1><p>我们将所有驱动因素都用于人类灾难和非人类灭绝的驱动因素，我们看到了少数主题：</p><ul><li>非常大规模的自然事件</li><li>高度适应，自我复制的生物，尤其是受害者没有共同适应的生物（流行病，新颖的病原体和捕食者，入侵物种）。</li><li>人类协调的群体（战争，狩猎，栖息地破坏）</li><li>政治镇压或破坏（强迫劳动，不良政策导致饥荒）</li><li>其他灾难的后续作用。</li></ul><p>有趣的是，在大多数人类灾难中，技术似乎并不是直接的罪魁祸首，尽管它可能是发生大规模核战争的。对于非人类的灭绝，这可能是一个贡献者，因为技术提高了狩猎能力和栖息地破坏的便利性。</p><p>鉴于现代威胁，纳米技术和生物技术都威胁着创建新颖的自我复制者，并且人类设计的包含可能会导致它们以与我们进化防御的方式分布的方式“适应”。</p><p>核武器增加了战争的最坏情况，大规模监视增加了政治镇压的最坏情况。</p><p>气候变化是一个大规模的自然事件。除了直接影响，如果它导致非人类物种的许多灭绝或引起政治动荡，那么后续影响可能对人类造成灾难性。由于持续的灭绝而导致的生物多样性损失也可能会造成不良的后续影响，尽管这种影响的发生得很慢，以至于这可能不是直接的威胁。</p><p>最后，我们在此方程式中将AI放在哪里？不幸的是，它似乎拥有许多其他灾难驱动因素的特性：</p><ul><li> AI是可以自我复制的，并且可以训练自己以快速适应新数据的意义。因此，这是一个适应人的自我复制者，人类本身并不适应。</li><li> AI可能会接受比人类更好的培训以更好地坐标，因为从进化上，人类只能以<a href="https://en.wikipedia.org/wiki/Dunbar%27s_number?ref=bounded-regret.ghost.io">〜150</a>的群体进行协调，而如果我们解决了相关的<a href="https://arxiv.org/abs/1705.08926?ref=bounded-regret.ghost.io">多代理RL挑战，</a>则可以对AI进行培训以在任意大型组中进行协调。</li><li> AI的经济流离失所可能导致政治动荡。</li><li> AI还是上述许多其他驱动因素的贡献（尽管可以说是双重计数）：它使大规模监视更加容易，并可能加快创建其他危险技术（例如工程性病原体）的创建。</li></ul><p> AI也具有改善特性。首先，其他新技术并未引起灾难，这应该减少我们对AI的先前。其次，AI辅助研究可以帮助饥荒和气候变化，如果AI增加繁荣，AI可能会减少政治动荡。这些是重要的考虑因素，但是许多技术具有这些特性，而几乎没有一个可以在组中进行协调的自我复制器。</p><p>总体而言，我希望AI会增加灾难的速度。 <a href="https://docs.google.com/document/d/1DOmluInO2KkgmumAf1wKLKHU7HbMeveIugR_oiFvHPc/edit?ref=bounded-regret.ghost.io#bookmark=id.xu338fnad04c">如上所述</a>，未来25年中非常大（10％的死亡率）灾难的基本率为5％，我个人希望AI在下一步之上增加10％邮政。</p><p><strong>开放式问题。</strong>这篇文章没有解决几个问题。首先，我的分析尚无定论，即随着时间的推移的灾难发生率是否变化。灭绝的数据表明，它可能会因数量级而有所不同，但是最好拥有有关人类事件的数据。</p><p>其次，这篇文章几乎没有说明技术和智力的重要性，尽管这些文章在直觉上很重要。技术灾难是否随着时间的流逝增加，即使现在它们太小而无法在上述数据中注册？更聪明的物种通常会驱动较少的智能物种灭绝吗？ <sup><a href="#fn15">[15]</a></sup>这两个中的任何一个基本利率都将为AI的预测提供信息。</p><p>最后，人们可能会认为经过的时间不是正确的X轴，而是经过人口增长，经济增长或技术进步。作为一个例子，以世界GDP为例。自1900年以来，世界GDP的双打与1900年至0CE之间一样多，因此，如果GDP双打是正确的“时钟”，那么我们可能会期望每十年发生更多的灾难，而不是过去。从到目前为止，我似乎并不是我的数据，但是我希望对其进行更详细的分析。</p><p><strong>致谢。</strong>特别感谢Dhruv Madeka的讨论和初始数据，这些数据激发了这篇文章。还要感谢Sham Kakade，Dean Foster，Tamay Berisoglu，Eli Lifland，NuñoSempere，Daniel Kokotajlo和Ege Erdil在这篇文章上进行了有用的讨论和评论。感谢Justis Mills和Louise Verkin的复制编辑和有用的反馈。</p><hr><section class="footnotes"><ol><li id="fn1" class="footnote-item"><p>当然，数字本身可能会产生误导，因为许多历史数字都是基于猜测的！这篇文章中的许多工作都在做大量阅读以决定要相信哪些数字。 <a href="#fnref1">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>人口规模是从<a href="https://ourworldindata.org/grapher/population?time=-1000..latest&amp;country=%7EOWID_WRL&amp;ref=bounded-regret.ghost.io">我们的世界中</a>收集的，请参见<a href="#population-by-country-across-history">附录</a>。 <a href="#fnref2">↩︎</a></p></li><li id="fn3" class="footnote-item"><p> taiping叛乱是一场战争，曾经是一场饥荒。 <a href="#fnref3">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>如上所述，“快速”意味着不到十年。 <a href="#fnref4">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>另一个理论是，蒙古人入侵（另一次灾难）传播了黑死亡，因为蒙古人将病态的尸体扔到城市中，这是一种生物战的形式。这不是当前的主要理论，而是多造成症的另一个实例，并且表明可以彼此相连的不同主要灾难。 <a href="#fnref5">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>从技术上讲，历史化石记录通常只能在属而不是物种的水平上解析灭绝，但是我通常会为简单起见这种区别。 <a href="#fnref6">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>请注意，这因分类单元而异，分类单元中的估计值近似，文献中的估计值不同，有4个或有时更大。 <a href="#fnref7">↩︎</a></p></li><li id="fn8" class="footnote-item"><p> 2-10倍的数字是查看100万年的垃圾箱。对于突然的灾难性事件，例如小行星罢工，在1年间隔内的灭绝率越来越大。 <a href="#fnref8">↩︎</a></p></li><li id="fn9" class="footnote-item"><p>这与上述相同，尽管我不知道在搜索论文时 - 在这两种情况下，他碰巧写了我发现最中性和最具说服力的论文。令我高兴的是，我得知他也在加州大学伯克利分校。去熊！ <a href="#fnref9">↩︎</a></p></li><li id="fn10" class="footnote-item"><p>参见EG <a href="https://www.science.org/doi/10.1126/sciadv.1400253?ref=bounded-regret.ghost.io">Ceballos等。 （2015年）</a> ，估计值接近背景速率的两个数量级。 <a href="#fnref10">↩︎</a></p></li><li id="fn11" class="footnote-item"><p> “例子包括失去种子分散剂或充满不再存在的食草动物的植物，这些食草动物对所有现有的捕食者都“过度设计”的草食动物，<br>以及诸如在大陆环境中没有天然尸体食用的秃鹰之类的清除剂。” <a href="#fnref11">↩︎</a></p></li><li id="fn12" class="footnote-item"><p>我遵循<a href="https://pubmed.ncbi.nlm.nih.gov/20978281/?ref=bounded-regret.ghost.io">Hoffmann等人的图S7。</a> （在<a href="#species-endangerment-by-cause">附录</a>中复制），该物质计算出危险原因分类的濒危物种。我将行分为“栖息地破坏”，“入侵物种”（包括两栖动物中的<a href="https://en.wikipedia.org/wiki/Chytridiomycosis?ref=bounded-regret.ghost.io">chytrid真菌</a>疾病），“过度狩猎 /过度捕捞”和“环境”（气候变化 /自然灾害）。某些类别是模棱两可的或不适合以下4的4。总体而言，我在栖息地破坏中约为〜360，来自入侵物种（由两栖动物主导）约250，〜130在过度狩猎/过度捕获中，而环境中约有40个。 <a href="#fnref12">↩︎</a></p></li><li id="fn13" class="footnote-item"><p>另请参见<a href="https://www.annualreviews.org/doi/pdf/10.1146/annurev.energy.28.050302.105532?ref=bounded-regret.ghost.io">Dirzo＆Raven（2003）</a> ，他们同样声称栖息地破坏是主要驱动力。 <a href="#fnref13">↩︎</a></p></li><li id="fn14" class="footnote-item"><p>储层物种是第二种物种，其中病原体不是致命的，使其可以更自由地繁殖，并且病原体可以从中跨越靶物质。 <a href="#fnref14">↩︎</a></p></li><li id="fn15" class="footnote-item"><p>我发现的最接近的是<a href="https://www.nature.com/articles/s41598-022-07327-9?ref=bounded-regret.ghost.io">Dembitzer等人。 （2022年）</a> ，他们声称在第四纪晚期灭绝期间更聪明的哺乳动物灭绝的可能性较小。但是，我们理想地想研究相反：更聪明的哺乳动物是否更有可能导致<em>其他</em>物种灭绝？ <a href="#fnref15">↩︎</a></p></li></ol></section><h1>附录</h1><h2>灾难的日志图</h2><p>如第1节所述，灾难的分布不再遵循ZIPF定律，当时我们低于1％的死亡人数，如下所示： <br><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/pogy0xusqv3jf1vpdej2" alt="Events_power_law_01.png"><br>一种可能性是，实际趋势是对数正常而不是权力法。另一个是，不太严重的事件被低估了。</p><h2>种种危害原因</h2><p>以下是<a href="https://www.science.org/doi/10.1126/science.1194442?ref=bounded-regret.ghost.io">Hoffmann等人的图S7的复制。 （2010）</a> 。 <br><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/o0x5tingr8fej6jn4f7z" alt="hoffman_figs7.png"></p><h2>在历史上按国家按国家划分的人口</h2><div><a href="https://bounded-regret.ghost.io/content/files/2023/12/population.csv"><div><div> 人口</div><div>有关历史世界人口的原始数据（有关互动HTML，请参见下面参见）</div><div><div>人口</div><div>1MB</div></div></div><div>下载圈</div></div><iframe src="https://ourworldindata.org/grapher/population?tab=table&amp;time=-1000..latest&amp;country=~OWID_WRL"></iframe><h2>刮擦脚本</h2><div><a href="https://bounded-regret.ghost.io/content/files/2023/12/scrape_events.py"><div><div> scrape_events</div><div> python脚本曾经刮擦Wikipedia的主要灾难清单</div><div><div>scrape_events.py</div><div> 13KB</div></div></div><div>下载圈</div></div><h2>所有主要灾难的完整清单</h2><div><a href="https://bounded-regret.ghost.io/content/files/2023/12/events_all.csv"><div><div> events_all</div><div> Wikipedia刮除的所有主要灾难的清单</div><div><div>Events_all.csv</div><div> 6KB</div></div></div><div>下载圈</div></div><br/><br/><a href="https://www.lesswrong.com/posts/SgYz4YPKridWXJSE6/analyzing-the-historical-rate-of-catastrophes#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/sgyz4ypkridwxjse6/analyzing-the-historical-rate-historical-rate-of-catatrophes<guid ispermalink="false"> sgyz4ypkridwxjse6</guid><dc:creator><![CDATA[jsteinhardt]]></dc:creator><pubDate> Tue, 05 Dec 2023 06:30:03 GMT</pubDate> </item><item><title><![CDATA[Some open-source dictionaries and dictionary learning infrastructure]]></title><description><![CDATA[Published on December 5, 2023 6:05 AM GMT<br/><br/><p>随着越来越多的人开始从事包含字典学习的可解释性项目，公开提供高质量的字典将很有价值。 <span class="footnote-reference" role="doc-noteref" id="fnrefxki2bn9t6a"><sup><a href="#fnxki2bn9t6a">[1]</a></sup></span>为了让事情顺利进行，我和我的合作者（Aaron Mueller）：</p><ul><li>开源许多在 Pythia-70m MLP 上训练的稀疏自动编码器字典</li><li>发布我们用于训练这些词典的<a href="https://github.com/saprmarks/dictionary_learning">存储库</a><span class="footnote-reference" role="doc-noteref" id="fnrefp7b5kczep0n"><sup><a href="#fnp7b5kczep0n">[2]</a></sup></span> 。</li></ul><p>我们首先讨论字典，然后讨论存储库。</p><h1>字典</h1><p>词典可以从<a href="https://baulab.us/u/smarks/autoencoders/">这里</a>下载。有关如何下载和使用它们的信息，请参阅<a href="https://github.com/saprmarks/dictionary_learning">此处的</a>“下载我们的开源词典”和“使用经过训练的词典”部分。如果您在发表的论文中使用这些词典，我们要求您在致谢中提及我们。</p><p>我们正在为 EleutherAI 的 6 层 pythia-70m-deduped 模型发布两套字典。两组字典都使用来自<a href="https://pile.eleuther.ai/">The Pile</a>的约 8 亿个令牌，在 512 维 MLP<i>输出</i>激活（而不是像 Anthropic 使用的 MLP 隐藏层）上进行训练。</p><ul><li>第一组称为<code>0_8192</code> ，由大小<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="8192 = 16 \times 512"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">8192</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">16</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">512</span></span></span></span></span></span></span>的字典组成<style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>。这些训练的 L1 惩罚为<code>1e-3</code> 。</li><li>第二组称为<code>1_32768</code> ，由大小为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="32768 = 64 \times 512"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">32768</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">64</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">512</span></span></span></span></span></span></span>的字典组成。这些训练的 l1 惩罚为<code>3e-3</code> 。</li></ul><p>以下是一些统计数据。 （有关这些统计数据含义的更多信息，请参阅我们的存储库的<a href="https://github.com/saprmarks/dictionary_learning">自述文件</a>。）</p><p>对于<code>0_8192</code>集中的字典：</p><figure class="table"><table><thead><tr><th>层</th><th>均方误差损失</th><th>L1损失</th><th>L0</th><th>存活百分比</th><th>损失恢复百分比</th></tr></thead><tbody><tr><td>0</td><td> 0.056</td><td> 6.132</td><td> 9.951</td><td> 0.998</td><td> 0.984</td></tr><tr><td> 1</td><td> 0.089</td><td> 6.677</td><td> 44.739</td><td> 0.887</td><td> 0.924</td></tr><tr><td> 2</td><td> 0.108</td><td> 11.44</td><td> 62.156</td><td> 0.587</td><td> 0.867</td></tr><tr><td> 3</td><td> 0.135</td><td> 23.773</td><td> 175.303</td><td> 0.588</td><td> 0.902</td></tr><tr><td> 4</td><td> 0.148</td><td> 27.084</td><td> 174.07</td><td> 0.806</td><td> 0.927</td></tr><tr><td> 5</td><td> 0.179</td><td> 47.126</td><td> 235.05</td><td> 0.672</td><td> 0.972</td></tr></tbody></table></figure><p>对于<code>1_32768</code>集中的字典：</p><figure class="table"><table><thead><tr><th>层</th><th>均方误差损失</th><th>L1损失</th><th>L0</th><th>存活百分比</th><th>损失恢复百分比</th></tr></thead><tbody><tr><td>0</td><td> 0.09</td><td> 4.32</td><td> 2.873</td><td> 0.174</td><td> 0.946</td></tr><tr><td> 1</td><td> 0.13</td><td> 2.798</td><td> 11.256</td><td> 0.159</td><td> 0.768</td></tr><tr><td> 2</td><td> 0.152</td><td> 6.151</td><td> 16.381</td><td> 0.118</td><td> 0.724</td></tr><tr><td> 3</td><td> 0.211</td><td> 11.571</td><td> 39.863</td><td> 0.226</td><td> 0.765</td></tr><tr><td> 4</td><td> 0.222</td><td> 13.665</td><td> 29.235</td><td> 0.19</td><td> 0.816</td></tr><tr><td> 5</td><td> 0.265</td><td> 26.4</td><td> 43.846</td><td> 0.13</td><td> 0.931</td></tr></tbody></table></figure><p>这是一些特征频率的直方图。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/bwz8jq2puk7bt2v5i30r" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/y1doqsgw6saydkevmegk 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/bxmnx1a065hxjb1kxm7w 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/amxktqpnee5yslwybgjr 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/nqczszdt53rrze0yyqjn 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/wt8mfxq5hu3so0xkzhlp 1000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/ypwhg5ljidk3ihwawra9 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/yew2oxwaf2h3qktmyzdz 1400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/cl13rve82dtm4e7n5rvg 1600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/t3gi9wznfqvmwt5g5hjk 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/lgksrskpkvezs1uxrf7v 1920w"></figure><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/xbofxvy4qa4st0bujv2y" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/bswlwokzl9cxxohyp3wl 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/ygciqg8mfkawmroztrlh 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/faowowuclak0zfo8nqa9 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/lrnmhst9cfd5ly40moe9 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/p0x4nejio2vg2ewj7jlh 1000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/bmbi0dnpjkbgs3fclthv 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/kb17kbppyw7ykj0zrnou 1400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/uiwq1n28muzqmvbnwwyl 1600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/syvuw8hizr4ltbmlchyf 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/heoaxgupuv2ku1zzul2w 1920w"></figure><p>总的来说，我认为这些词典还不错，但并不令人惊奇。</p><p>我们训练这些字典是因为我们想要进行字典学习的下游应用，但缺乏字典。这些词典足以让我们开始我们的主线项目，但我预计不久之后我们将回来训练一些更好的词典（我们也将开源）。我认为对其他人来说也是如此：这些词典应该足以开始需要词典的项目；当以后有更好的词典可用时，您可以更换它们以获得最佳结果。</p><p>关于这些词典的一些杂项注释（您可以在<a href="https://github.com/saprmarks/dictionary_learning">repo</a>中找到更多信息）。</p><ul><li> <code>1_32768</code>的 L1 惩罚似乎太大了；只有10-20%的神经元还活着，恢复的损失就更严重了。也就是说，我们会注意到，在检查了两组词典的特征后， <code>1_32768</code>集中的词典似乎比<code>0_8192</code>集中的词典具有更多可解释的特征（尽管很难说）。<ul><li>特别是，我们怀疑对于<code>0_8192</code> ，后面层中的许多高频特征是无法解释的，但对重建激活有很大帮助，<strong>从而产生看似漂亮的统计数据</strong>。 （请参阅下面有关神经元重采样和双峰性的要点。）</li></ul></li><li>随着我们逐层推进，字典在大多数指标上往往会变得更糟（恢复损失百分比除外）。这可能与当人们穿过 pythia 模型各层时激活本身的规模不断扩大有关（感谢 Arthur Conmy 提出这一假设）。</li><li>我们注意到，我们的字典特征的频率明显高于<a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html">Anthropic</a>和<a href="https://www.lesswrong.com/posts/fKuugaxt2XLTkASkk/open-source-replication-and-commentary-on-anthropic-s">Neel Nanda</a>中的特征。我们不知道这种差异是因为我们正在使用多层模型还是因为超参数的差异。我们通常怀疑如果我们学习频率较低的特征会更好。<ul><li>然而，我们会注意到，在第 0 层之后，我们的许多功能似乎并不具有“总是在特定令牌上触发”的形式，而 Anthropic 的许多功能都是如此。因此，更有趣的功能也可能出现频率更高。看看<a href="https://www.lesswrong.com/posts/tEPHGZAb63dfq2v8n/?commentId=zXEsbbJHsg98FY6uj">这里</a>有一些味道。</li></ul></li><li>我们不确定，但<code>0_8192</code>的直方图中的双峰性可能是由于死亡神经元被重新采样所致。我们每 30000 个步骤重新采样一次，包括 100000 个总步骤中的第 90000 个步骤。重采样的特征往往频率非常高，峰值可能需要超过 10000 步才能向左移动。</li></ul><h1>字典学习库</h1><p>同样，这可以<a href="https://github.com/saprmarks/dictionary_learning">在这里</a>找到。我们遵循<a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html#appendix-autoencoder">Anthropic 论文</a>中详细介绍的方法（包括使用不受限的编码器/解码器权重、限制解码器向量具有单位范数，以及根据其古怪的方案对死亡神经元进行重新采样），但以下情况除外：</p><ul><li>我们没有足够的空间来存储整个数据集的激活，因此，按照<a href="https://www.lesswrong.com/posts/fKuugaxt2XLTkASkk/open-source-replication-and-commentary-on-anthropic-s">Neel Nanda 的复制</a>，我们维护一个来自几千个上下文的令牌缓冲区，并从该缓冲区中随机采样，直到它是半空的（此时我们刷新它带有来自新上下文的标记）。</li><li>我们使用简短的线性学习率预热来解决 Adam 会在前几个训练步骤中杀死太多神经元的问题，然后才有机会校准 Adam 参数。</li></ul><p> （一个简单的插件：这个存储库是使用<a href="http://nnsight.net/">nnsight</a>构建的，这是一个新的可解释性工具库（如<a href="https://github.com/neelnanda-io/TransformerLens">Transformer_lens</a>和<a href="https://github.com/davidbau/baukit">baukit</a> ），由 Jaden Fiotto-Kaufman 和<a href="https://baulab.info/">Bau 实验室</a>的其他人开发。 <code>nnsight</code>仍在开发中，所以我只建议尝试深入研究如果你对偶尔的错误、内存泄漏等没问题的话，现在就进入它（你可以在<a href="https://discord.gg/JqMpyYtS">这个 Discord 服务器</a>的反馈通道中报告）。但总的来说，我对这个项目非常兴奋——除了提供一个非常干净的用户之外根据经验，一个主要设计目标是<code>nnsight</code>代码具有高度<i>可移植性</i>：理想情况下，您应该能够使用 Pythia-70m 制作实验原型，无缝切换到跨多个 GPU 的 LLaMA-2-70B 上运行，然后将代码发送到人择将在克劳德身上运行。）</p><p>除了主线功能之外，我们的存储库还支持一些实验性功能，我们简要研究了这些功能作为训练字典的替代方法：</p><ul><li> <strong>MLP 担架。</strong>基于人们可能能够通过“<a href="https://transformer-circuits.pub/2022/toy_model/index.html">足够大的模型中的神经元</a>”识别特征的观点，我们尝试训练“自动编码器”，以给定 MLP<i>输入</i>激活<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>作为输入， <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="MLP(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;">输出</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">MLP</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">(</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">x</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;">)</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">（</span></span></span></span></span></span></span> MLP 输出） ）。例如，给定一个 MLP，它将 512 维输入<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>映射到 1024 维隐藏状态<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span> ，然后映射到 512 维输出<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span> ，我们训练一个隐藏维度为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="16384 = 16 \times 1024"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">16384</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">16</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span> <span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1024</span></span>的</span></span></span></span></span>字典<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span> ，使得<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A(x)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>接近<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span> （并且像往常一样，因此字典的隐藏状态是稀疏的）。<ul><li>最终的词典看起来不错，但我们决定不再进一步追求这个想法。</li><li> （向 Max Li 提出此建议。）</li></ul></li><li><strong>用熵代替 L1 损失</strong>。基于这篇<a href="https://transformer-circuits.pub/2023/may-update/index.html#simple-factorization">文章</a>中的想法，我们尝试使用熵来规范字典的隐藏状态而不是 L1 损失。这似乎导致这些功能要么是死功能（从未触发），要么是在几乎每个输入上触发的非常高频的功能，这不是所需的行为。但似乎有一种方法可以让这项工作变得更好。</li></ul><p>如果您想追求上述要点中的想法之一，请在获得初步结果后与我（Sam）联系 - 我可能有兴趣讨论结果或合作。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnxki2bn9t6a"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxki2bn9t6a">^</a></strong></sup></span><div class="footnote-content"><p>这既是为了可重复性，也是因为每个字典都需要一些努力来训练。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnp7b5kczep0n"> <span class="footnote-back-link"><sup><strong><a href="#fnrefp7b5kczep0n">^</a></strong></sup></span><div class="footnote-content"><p>当然，来自<a href="https://arxiv.org/abs/2309.08600">Cunningham 等人的存储库。纸张</a>也可以<a href="https://github.com/HoagyC/sparse_coding">在这里</a>购买。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/AaoWLcmpY3LKvtdyq/some-open-source-dictionaries-and-dictionary-learning#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/aaowlcmpy3lkvtdyq/some-open-source-dictionaries-and-dictionary-learning<guid ispermalink="false"> AAOWLCMPY3LKVTDYQ</guid><dc:creator><![CDATA[Sam Marks]]></dc:creator><pubDate> Tue, 05 Dec 2023 06:05:21 GMT</pubDate> </item><item><title><![CDATA[The LessWrong 2022 Review]]></title><description><![CDATA[Published on December 5, 2023 4:00 AM GMT<br/><br/><p>雪花飘落，颂歌开始响起，我们都知道是时候开始我们最喜欢的冬季假期传统了。审稿时间少了！ </p><figure class="image image_resized" style="width:69.55%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/swcjknwqnq58jqjizlbu" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/iunw2eqowsdnnqfksyra 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/gx5phndd8vqwcthofkdb 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/wmh2aidexazx07hj2dfu 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/ahkmuaycxg9peesnssqr 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/ktgsgz7mjgpix2gho83k 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/zu2vamwcsp7qmxac899u 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/q4dfchxbyjvzz33q0olz 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/h8sonntrtlw1vx8tfek1 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/jlbb43705pckl5ufchsf 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/pqylqykbwbqxdf0ebiud 1024w"></figure><p>每年我们都会聚在一起审查至少一年前的帖子。这意味着在接下来的两个月里，我们将审核 2022 年的所有帖子。</p><p>虽然我们的日常生活充满了时尚，追逐着业力和社会认可的甜蜜滋味，但LessWrong的评论是时候退一步问自己“这真的能帮助我更好地思考吗？”，“这真的是事实吗？变得有价值？”以及“哪些事情经受住了进一步和广泛的审查？”。</p><p>到目前为止，我们已经这样做了 4 次（ <a href="https://www.lesswrong.com/posts/3yqf6zJSwBF34Zbys/2018-review-voting-results">2018 年</a>、 <a href="https://www.lesswrong.com/posts/kdGSTBj3NA2Go3XaE/2019-review-voting-results">2019 年</a>、 <a href="https://www.lesswrong.com/posts/TSaJ9Zcvc3KWh3bjX/voting-results-for-the-2020-review">2020 年</a>、 <a href="https://www.lesswrong.com/posts/zajNa9fdr8JYJpxrG/voting-results-for-the-2021-review">2021 年</a>）。</p><p>年度审核如何运作的完整技术细节位于本文的<a href="https://www.lesswrong.com/posts/B6CxEApaatATzown6/the-lesswrong-2022-review#How_does_the_review_work_">最后部分</a>，但与过去几年基本相同。分为三个阶段：</p><ol><li><strong>初步投票阶段</strong><i>（2 周，12 月 4 日至 17 日）</i> ：我们在进行初步投票的审核中确定特别值得考虑的帖子。获得 2 票初步投票的帖子进入讨论阶段。</li><li><strong>讨论阶段</strong><i>（4 周，12 月 17 日 — 1 月 14 日）</i> ：<i> </i>我们审查和辩论帖子。收到至少一篇书面评论的帖子将进入最终投票阶段。</li><li><strong>最终投票</strong><i>（2 周，1 月 14 日至 1 月 28 日）</i> ：我们使用二次投票进行完整投票。其结果决定年度评审结果。</li></ol><p>有关年度审核理念的更多信息，请参阅之前的公告帖子：<a href="https://www.lesswrong.com/posts/qXwmMkEBLL59NkvYR/the-lesswrong-2018-review">此处</a>、 <a href="https://www.lesswrong.com/posts/QFBEjjAvT6KbaA3dY/the-lesswrong-2019-review#Improving_our_incentives_and_rewards">此处</a>、<a href="https://www.lesswrong.com/posts/M9kDqF2fn3WH44nrv/the-2020-review">此处</a>和<a href="https://www.lesswrong.com/posts/qCc7tm29Guhz6mtf7/the-lesswrong-2021-review-intellectual-circle-expansion">此处</a>。</p><h2>入门</h2><p>在任何符合审核资格的帖子的顶部，您都会看到： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1672905457/mirroredImages/qCc7tm29Guhz6mtf7/d0fpa6iead1yz8j7y10n.png"></figure><p>这些将是您对 2022 年审核的初步投票。帖子需要获得至少 2 票初步投票（正面或负面）才能进入下一阶段的审核。</p><p>要开始仔细阅读帖子，我建议转到<a href="https://www.lesswrong.com/allPosts?timeframe=yearly&amp;after=2022-01-01&amp;before=2023-01-01&amp;limit=100&amp;sortedBy=top&amp;filter=unnominated&amp;includeShortform=false"><u>“2022 年所有帖子”页面</u></a>或<a href="https://www.lesswrong.com/votesByYear/2022"><u>“查看您过去的点赞”</u></a>页面。<i>注意：只有2022年1月之前注册账户的用户才有资格投票。</i></p><h2>今年没有书了，抱歉各位</h2><p>2018年、2019年和2020年，我们印制了审查结果的书籍。我们已经售出了数千件，我为它们感到非常自豪，很多人告诉我，这些是他们最喜欢的东西之一： </p><figure class="table"><table style="border-color:white;border-style:solid"><tbody><tr><td style="border-color:hsl(0, 0%, 100%);border-style:solid"><figure class="image image_resized" style="width:100%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/hkxvgpqalnv6oevaxned"><figcaption> 2018：反映领土的地图（ <a href="https://www.amazon.com/Map-that-Reflects-Territory-LessWrong/dp/1736128507/ref=sr_1_1?crid=5YSFIY94WGVQ&amp;keywords=lesswrong+books&amp;qid=1701728381&amp;sprefix=lesswrong+book%2Caps%2C145&amp;sr=8-1">亚马逊</a>） </figcaption></figure></td><td style="border-color:hsl(0, 0%, 100%);border-style:solid"><figure class="image image_resized" style="width:100%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/kcpulhgcmm5hsxlnaxga"><figcaption> 2019：认知引擎（ <a href="https://www.amazon.com/Engines-Cognition-Essays-LessWrong-Community/dp/1736128515/ref=sr_1_2?crid=5YSFIY94WGVQ&amp;keywords=lesswrong+books&amp;qid=1701728381&amp;sprefix=lesswrong+book%2Caps%2C145&amp;sr=8-2">亚马逊</a>） </figcaption></figure></td><td style="border-color:hsl(0, 0%, 100%);border-style:solid"><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/noak9x8qlrktfpottnxx"><figcaption> 2020：现实的雕刻（ <a href="https://www.amazon.com/Carving-Reality-Essays-LessWrong-Community/dp/B0C95MJJBK/ref=sr_1_5?crid=5YSFIY94WGVQ&amp;keywords=lesswrong+books&amp;qid=1701728398&amp;sprefix=lesswrong+book%2Caps%2C145&amp;sr=8-5">亚马逊</a>）</figcaption></figure></td></tr></tbody></table></figure><p>遗憾的是，今年不会有书（也不会有 2021 年的评论）。随着我们许多其他项目的需求不断增加（以及资金的减少，因为如果考虑到每年 4-5 个员工月的制作成本，我们在以下方面净损失了资金）这些）。</p><p>我正在考虑其他方法来创建一个易于参考的工件，以捕获今年和去年的审查结果。我认为我想做的最低限度是创建一本好的电子书，也许还可以使用我们的机器旁白（或进行人类旁白）制作一个有声版本。欢迎提出其他建议。</p><p>我们将在接下来的几天内对前几年的所有书籍进行圣诞特卖，希望在圣诞节之前我们还将推出一本包含去年评论结果的优秀电子书（甚至可能是有声读物版本）。</p><h1>审核如何进行？</h1><h2>第一阶段：初步投票</h2><p>要提名职位，请对其进行初步投票。符合资格的选民将看到此用户界面： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1672905457/mirroredImages/qCc7tm29Guhz6mtf7/d0fpa6iead1yz8j7y10n.png"></figure><p>如果您认为某个帖子是重要的智力贡献，您可以投票表明其大致的重要性。对于一些粗略的指导：</p><ul><li> 1 票意味着“这很好”。</li><li> 4 票意味着“这非常重要”。</li><li> 9 票意味着它是“智力进步的一个重要部分”。</li></ul><p>您可以在帖子页面的顶部或帖子出现在列表中的任何位置（例如<a href="https://www.lesswrong.com/allPosts?timeframe=yearly&amp;after=2022-01-01&amp;before=2023-01-01&amp;limit=100&amp;sortedBy=top&amp;filter=unnominated&amp;includeShortform=false"><u>“所有帖子”页面</u></a>或新的<a href="https://www.lesswrong.com/votesByYear/2022"><u>“查看您过去的投票</u></a>”页面）进行投票。</p><p>获得至少一票赞成票的帖子将进入<a href="https://lesswrong.com/reviewVoting/2022">投票仪表板</a>，其他用户可以在其中投票。我们鼓励您根据去年的记忆至少进行一次粗略的投票。稍后改变主意是可以的（鼓励！）。</p><p><strong>写一篇简短的评论</strong></p><p>如果您认为某篇文章很重要，我们还鼓励您至少写一篇简短的评论，说明该文章的突出之处及其重要性。 （如果您想先记下您的快速印象，然后再进行更详细的审核，欢迎您对一篇文章进行多篇评论）</p><p>至少有一条评论的帖子会被排序到<a href="https://www.lesswrong.com/reviewVoting">要投票的帖子列表</a>的顶部，因此，如果您希望某个帖子获得更多关注，对其进行评论会很有帮助。</p><p><strong>为什么要进行初步投票？为什么要分两个投票阶段？</strong></p><p>每年，LessWrong 上都会写出更多的帖子。 2018 年第一次审查考虑了 1,500 个职位。 2021 年，这一数字为 4,250。处理这么多帖子是一项艰巨的工作。</p><p>初步投票旨在帮助处理帖子数量的增加。我们不是简单地提名职位，而是直接从投票开始。这些初步投票随后将被公布，只有至少两人投票的帖子才会进入下一轮。</p><p>在审核阶段，这可以让各个网站成员注意到某些内容的放置是否特别不准确。如果您认为某个帖子的排名不准确，您可以写一篇积极的评论，认为它应该更高，其他人可以在最终投票时考虑这一点。获得大量中等选票的帖子可能会在审核阶段被取消优先级，从而使我们能够专注于最有可能对最终结果产生影响的对话。</p><p><strong>初步投票是如何计算的？</strong></p><p>您可以投不限数量的选票，但超过一定阈值后，您的选票总分越大，您每张选票的影响力就越小。在后端，我们使用<a href="https://www.lesswrong.com/posts/qQ7oJwnH9kkmKm2dC/feedback-request-quadratic-voting-for-the-2018-review"><u>修改后的二次投票系统</u></a>，该系统根据投票的强度在您的投票中分配固定数量的分数。</p><p><i>细节：1 票得 1 分。 4 票得 10 分。 9 票需要 45 分。如果您花费的积分超过 500 点，您的投票就会开始按比例变弱。</i></p><h2>第二阶段：评论</h2><p>第二阶段为期一个月，完全专注于撰写评论。评论是评估帖子的特殊评论。评论中需要回答的好问题包括：</p><ul><li>这篇文章给对话添加了什么？</li><li>这篇文章对您、您的想法和行动有何影响？</li><li>它的主张是否准确？它是否在关节处雕刻了现实？你怎么知道？</li><li>您可以测试这篇文章的从属声明吗？</li><li>您希望在这篇文章的基础上看到哪些后续工作？</li></ul><h2>第三阶段：最终投票</h2><p>至少收到一项审核的帖子将进入最终投票阶段。</p><p>用户界面将要求选民在最终确定对每个帖子的投票之前至少简要浏览一下评论，因此可以考虑有关每个帖子的争论。</p><p>和往年一样，我们将公布1000+karma的用户以及所有用户的投票结果。 LessWrong 审核团队将把投票结果作为将哪些帖子纳入 2022 年最佳帖子序列的有力指标。</p><p><strong>首先，您可以</strong><a href="https://www.lesswrong.com/votesByYear/2022"><strong><u>查看您过去的点赞</u></strong></a><strong>并开始对某些帖子进行投票。</strong></p><br/><br/><a href="https://www.lesswrong.com/posts/B6CxEApaatATzown6/the-lesswrong-2022-review#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/b6cxeapaatatzown6/the-lesswrong-2022-review<guid ispermalink="false"> B6CXEAPAATATZOWN6</guid><dc:creator><![CDATA[habryka]]></dc:creator><pubDate> Tue, 05 Dec 2023 04:00:00 GMT</pubDate> </item><item><title><![CDATA[Bands And Low-stakes Dances]]></title><description><![CDATA[Published on December 5, 2023 3:50 AM GMT<br/><br/><p><span>当我开始在波士顿地区参加反对派舞会时，有几种你可以考虑“低风险”的地区舞会。小型舞会，费用不高，老牌乐队的热情也较低。因此，他们相对愿意预订那些刚刚起步、友好、鼓励、能够容忍缺乏经验的错误的乐队。</span></p><p>我认为这就是为什么这么多实力雄厚的乐队和舞蹈音乐家走出这个领域的一个重要原因：不需要你足够优秀，能够在“大型”舞蹈中保持自己的风格，就可以开始获得作为乐队跳舞的经验。 。例如，回顾一下我的日历，在我们玩我们的第一个“大型”游戏（<a href="https://challcontra.weebly.com/">协和星期五</a>）之前， <a href="https://www.freeraisins.com/">Free Raisins</a>玩了十八个不同的晚上。</p><p>不幸的是，这比以前少了很多。一些在大流行前关闭了（我非常想念麻省理工学院的反对派舞蹈！），其他人还没有回来（还没有？）或者已经转向室内乐队。有<a href="https://www.bidadance.org/">BIDA</a><a href="https://www.jefftk.com/p/why-does-the-bida-open-band-work-well">开放乐队</a>和（风险更低的）家庭舞蹈乐队，但虽然我认为这种经验也很有价值，但有一种不同的学习方式，来自于在小组中演奏、演奏你已经练习过的曲目，以及对音乐完全负责。</p><p>我在这里没有一个很好的解决方案：很难故意开始一些低风险的活动，而且人们通常更喜欢举办那种很多人都想参加并且有很棒音乐的活动。但我确实认为 2010 年代初期的环境非常特别，为新乐队提供了很多学习成为舞蹈乐队的机会，如果我们能够带回类似的东西，或者至少具有类似效果的东西，我会很高兴。</p><p> （对于“技术魂斗罗”来说，这种动力更加强烈：唯一的表演机会是重大特别活动，甚至更高调！但我对这种舞蹈形式的成功投入也较少，所以这不太困扰我。 ）</p><br/><br/><a href="https://www.lesswrong.com/posts/atwkvWcSppkKN9dRJ/bands-and-low-stakes-dances#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/atwkvwcsppkkn9drj/bands-and-low-stakes-dances<guid ispermalink="false"> atwkvwcsppkkn9drj</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Tue, 05 Dec 2023 03:50:22 GMT</pubDate> </item><item><title><![CDATA[Accelerating science through evolvable institutions]]></title><description><![CDATA[Published on December 4, 2023 11:21 PM GMT<br/><br/><p><i>这是向圣达菲研究所“加速科学”工作组提交的演讲的书面版本。</i></p><p>我们来这里是为了讨论“加速科学发展”。我喜欢从历史的角度来开始讨论这样的话题：科学在过去什么时候（如果有的话）加速了？现在还在加速吗？我们可以从中学到什么？</p><p>我认为，在整个人类历史中，科学以及更广泛的人类知识<i>一直</i>在加速发展。我还不能证明这一点（而且我自己对此只有大约 90% 的把握），但让我诉诸你的直觉：</p><ul><li><a href="https://en.wikipedia.org/wiki/Behavioral_modernity">从行为上看，现代人类</a>已有 50,000 多年的历史</li><li>文字只有大约 5000 年的历史，因此在人类时间线的 90% 以上，我们只能积累能够适应口头传统的知识</li><li>在古代和中世纪世界，我们只有少数几门科学：天文学、几何学、一些数论、一些光学、一些解剖学</li><li>在科学革命之后的几个世纪（大约 1500 年代至 1700 年代），我们得到了日心说、运动定律、万有引力理论、化学的起源、细胞的发现、更好的光学理论</li><li>在 1800 年代，事情真正开始发展，我们有了电磁学、原子理论、进化论、细菌理论</li><li>1900 年代，核物理、量子物理、相对论、分子生物学和遗传学继续蓬勃发展</li></ul><p>我把自 1950 年左右以来科学是否已经放缓的问题放在一边，我对此没有强烈的看法。即使确实如此，这也只是整个历史加速的总体模式中最近的一个小插曲。 （或者，你知道，历史上前所未有的逆转和衰退的开始。其中之一。）</p><p>我对这种加速模式深信不疑的部分原因是，加速的不仅仅是科学：几乎所有衡量人类进步的指标都显示出相同的趋势，包括<a href="https://ourworldindata.org/grapher/world-gdp-over-the-last-two-millennia?yScale=log">世界 GDP</a>和<a href="https://ourworldindata.org/grapher/population?yScale=log&amp;country=~OWID_WRL">世界人口</a>。</p><p>是什么推动了科学的加速发展？许多因素，包括：</p><ul><li><strong>资金。</strong>曾经，科学家必须<a href="https://rootsofprogress.org/funding-models-for-science-and-innovation">寻求赞助，或者独立致富</a>。现在有可用的赠款，并且资金总额在过去几十年中大幅增加： </li></ul><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9uEAwHzoDS8shpdoX/dhxfk91oznfay66wdxnn" alt=""><figcaption><a href="https://www.aaas.org/programs/r-d-budget-and-policy/historical-trends-federal-rd"><i>美国科学促进会</i></a></figcaption></figure><ul><li><strong>人们。</strong>更多的科学家（在其他条件相同的情况下）意味着科学发展得更快，科学家的数量急剧增加，这既是因为总体人口的增长，也是因为更多的劳动力进入研究领域。在<a href="https://archive.org/details/sciencesincebaby0000pric/page/107/mode/1up?view=theater"><i>《自巴比伦以来的科学》一</i></a>书中，德里克·J·德·索拉·普赖斯 (Derek J. de Solla Price) 表示，“历史上大约 80% 到 90% 的科学家现在还活着”，这<a href="https://futureoflife.org/guest-post/90-of-all-the-scientists-that-ever-lived-are-alive-today/">可能仍然是正确的</a>： </li></ul><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9uEAwHzoDS8shpdoX/wh3ldfdjulipzfcrroyg" alt=""><figcaption> <a href="https://futureoflife.org/guest-post/90-of-all-the-scientists-that-ever-lived-are-alive-today/"><i>埃里克·加斯特弗兰德</i></a></figcaption></figure><ul><li><strong>仪器。</strong>更好的工具意味着我们可以做更多更好的科学研究。伽利略有一个简单的望远镜。现在我们有<a href="https://en.wikipedia.org/wiki/James_Webb_Space_Telescope">JWST</a>和<a href="https://en.wikipedia.org/wiki/LIGO">LIGO</a> 。</li><li><strong>计算。</strong>更强的计算能力意味着更多更好的数据处理方式。</li><li><strong>沟通。</strong>思想传播得越快越好，科学传播就越高效、越有效。科学期刊是在印刷机发明之后才发明的。互联网支持预印本服务器，例如 arXiv。</li><li><strong>方法。</strong>更好的方法造就更好的科学，从培根经验主义到<a href="https://en.wikipedia.org/wiki/Koch%27s_postulates">科赫假设</a>再到<a href="https://en.wikipedia.org/wiki/Randomized_controlled_trial">随机</a>对照试验（实际上是所有统计数据）。</li><li><strong>机构。</strong>实验室、大学、期刊、资助机构等共同构成了一个支持现代科学的生态系统。</li><li><strong>社会地位。</strong>科学越受到尊重和声望，就会有越多的人和金钱流入它。</li></ul><p>现在，如果我们想问科学是否会继续加速发展，我们可以思考哪些驱动因素将继续增长。我建议：</p><ul><li>只要世界经济持续增长，科学经费就会继续增长</li><li>仪器、计算和通信将随着技术的发展而不断改进</li><li>我认为方法没有理由不继续改进，作为科学本身的一部分</li><li>科学的社会地位似乎相当强大：它是一个受人尊敬和享有盛誉的机构，获得了一些社会最高荣誉</li></ul><p>从长远来看，如果<a href="https://ourworldindata.org/grapher/comparison-of-world-population-projections">世界人口像预计的那样趋于稳定</a>，我们可能会耗尽继续扩大研究人员基础的人员，这是一个潜在的问题，但不是我今天的重点。</p><p>最大的危险信号是我们的科学机构。制度影响所有其他因素，尤其是资金和人才的管理。今天，元科学界的许多人对我们的机构感到担忧。常见的批评包括：</p><ul><li><strong>速度。</strong>获得资助很容易需要 12-18 个月的时间（如果你幸运的话）</li><li><strong>高架。</strong>研究人员通常将 30-50% 的时间花在资助上</li><li><strong>耐心。</strong>研究人员认为他们需要定期展示结果，并且不能走一条可能需要多年才能得出结果的道路</li><li><strong>风险承受能力。</strong>赠款资金倾向于保守的、渐进的建议，而不是大胆的、“高风险、高回报”的计划（尽管<a href="https://commonfund.nih.gov/highrisk">做出了相反的努力</a>）</li><li><strong>共识。</strong>一个领域可能会过快地集中于一个假设并修剪替代的研究分支</li><li><strong>研究员年龄。</strong>随着时间的推移，赠款的趋势是拨款给年龄更大、更成熟的研究人员</li><li><strong>自由。</strong>科学家缺乏完全自主地指导研究的自由；赠款资金附加太多条件</li></ul><p>现在，作为一名前科技创始人，我不禁注意到，在营利性风险投资领域，大多数问题似乎都得到了缓解。筹集风险投资资金相对较快（通常一轮融资会在几个月内完成，而不是一年或更长时间）。作为创始人/首席执行官，我花了大约 10-15% 的时间筹款，而不是 30-50%。风险投资公司大胆下注，积极寻求逆向立场，并支持年轻的新贵。他们大多给予创始人自主权，也许会在董事会中占据一席之地以进行治理，并且只有在表现非常糟糕时才会解雇首席执行官。 （上面列出的初创公司创始人可能还会抱怨的唯一问题是耐心：如果你的钱用完了，你最好能取得进展，否则你在下一轮融资时就会遇到困难。）</p><p>我不认为风险投资界在这些方面做得更好，因为风险投资家比科学资助者更聪明、更有智慧或更优秀——但事实并非如此。相反，风险投资家：</p><ul><li>争夺优惠（并且真的不想错过好优惠）</li><li>从长远来看，成功或失败取决于其投资组合的表现</li><li>在大约 5-10 年内看到这些结果</li></ul><p>简而言之，<strong>风险投资面临着进化压力。</strong>他们不能陷入明显的不良均衡，因为如果这样做，他们就会在竞争中落败并失去市场力量。</p><p>证明这一点的是风险投资在过去几十年里<i>的</i>发展——主要是朝着为创始人提供更好待遇的方向发展。例如，早期阶段存在较高估值的长期趋势，这最终意味着较低的稀释度以及权力从风投向创始人的转移：创始人在过去的几年里放弃公司一半或更多的股份是很常见的。第一轮融资；最后我检查了一下，大约是 20% 或更少。风险投资并不总是资助大学刚毕业的年轻技术人员。曾经有一段时间，他们倾向于青睐更有经验的首席执行官，或许还拥有 MBA 学位。他们并不总是支持创始人领导的公司；曾经，创始人在最初几年后被解雇并由专业首席执行官取代的情况很常见（当 A16Z 在 2009 年推出时，他们大肆宣扬<a href="https://a16z.com/why-we-prefer-founding-ceos/">他们不会这样做</a>）。</p><p>所以我认为<strong>，如果我们希望看到我们的科学机构</strong><i><strong>得到改进</strong></i><strong>，我们需要考虑它们如何</strong><i><strong>发展</strong></i><strong>。</strong></p><p>我们的科学机构的发展程度如何？不是特别的。当今大多数科学组织都是大学或政府部门。尽管我很尊重大学和政府，但我认为任何人都必须承认它们是我们行动较为缓慢的机构之一。 （大学尤其具有极强的弹性和抵抗力：例如，牛津大学和剑桥大学的历史可以追溯到中世纪，经历了帝国的兴衰，直到今天仍然完好无损。）</p><p>科学资助机构的进化所面临的挑战与风险投资的进化相反：</p><ul><li><strong>他们往往缺乏竞争，</strong>尤其是 NIH 和 NSF 等集中式联邦机构</li><li><strong>他们缺乏任何真正的反馈循环</strong>，在这种循环中，资助者的资源是由过去的判断和其投资组合的成功决定的（迈克尔·尼尔森多次<a href="https://twitter.com/michael_nielsen/status/1451626771690897408">指出</a>，从“爱因斯坦作为专利职员做了最好的工作”到“卡塔林·卡里科”的资助失败）在获得诺贝尔奖之前被拒绝授予资助和终身教职”似乎甚至没有引发相关机构内部的反思过程）</li><li><strong>他们需要很长的周期</strong>才能了解其工作的真正影响，而这种影响可能需要 20-30 年才能显现出来</li></ul><p>我们如何提高科学经费的可进化性？我们应该思考如何改善这些因素。我没有什么好主意，但我会抛出一些不成熟的想法来开始对话：</p><p><strong>我们如何增加科学资助的竞争？</strong>我们可以增强慈善事业的作用。在美国，我们可以将联邦资金转移到州一级，设立五十个资助者而不是一个。 （国家农业实验站就是一个成功的例子，这些实验站之间的竞争是杂交玉米研究的关键，这是 20 世纪农业科学最伟大的成功之一。）在国际层面，我们可以支持对科学家更加开放的移民。</p><p><strong>我们如何创建更好的反馈循环？</strong>这很困难，因为我们需要某种方法来衡量结果。实现这一目标的一种方法是将资金从预期赠款转向各级各种回顾性奖项。如果这个“经济”足够大和强大，这些成果就可以被金融化，以创建一个动态的、有竞争力的融资生态系统，并具有适当水平的风险承担和耐心，经验丰富的退伍军人与年轻特立独行者之间的适当平衡等.（ <a href="https://forum.effectivealtruism.org/posts/r7vmtHZKuosJZ3Xq5/altruistic-equity-allocation">影响证书</a>，例如<a href="https://protocol.ai/blog/hypercert-new-primitive/">超级证书</a>，可以成为该解决方案的一部分。）</p><p><strong>我们如何解决反馈周期长的问题？</strong>我不知道。如果我们不能缩短周期，也许我们需要延长资助者的职业生涯，这样他们至少可以从几个周期中学习——这<a href="https://rootsofprogress.org/how-curing-aging-could-help-progress">是长寿技术的潜在好处</a>。或者，也许我们需要一个科学资助者，它可以极快地学习，可以消耗大量有关研究项目及其最终结果的历史信息，永远不会忘记其经历，并且永远不会退休或死亡——当然，我想到的是人工智能。关于人工智能支持、增强或取代科学研究人员本身的讨论很多，但人工智能在科学领域的最大机会可能是在资金和管理方面。</p><p>我怀疑资助机构会在这个方向上走得太远：它们必须自愿接受竞争、加强问责并承认错误，而这种情况很少见。 （看看现在那些因卡里科获得诺贝尔奖而获得功劳的机构，他们几乎没有为她提供支持。）如果机构很难进化，那么元进化就更难了。</p><p>但也许资助者背后的资助者，即那些向资助者提供预算的资助者，可以开始将资金分配给多个机构，以要求绩效指标，或者干脆转向上述回顾性模式。这可以提供所需的进化压力。</p><br/><br/> <a href="https://www.lesswrong.com/posts/9uEAwHzoDS8shpdoX/accelerating-science-through-evolvable-institutions#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9uEAwHhoDS8shpdoX/acceleating-science-through-evolvable-institutions<guid ispermalink="false"> 9uEAwHzoDS8shpdoX</guid><dc:creator><![CDATA[jasoncrawford]]></dc:creator><pubDate> Mon, 04 Dec 2023 23:21:35 GMT</pubDate> </item><item><title><![CDATA[Speaking to Congressional staffers about AI risk]]></title><description><![CDATA[Published on December 4, 2023 11:08 PM GMT<br/><br/><p> 2023 年 5 月和 6 月，我（Akash）与国会工作人员就人工智能风险举行了大约 50-70 次会议。我一直想写一篇文章来反思这次经历和我的一些收获，我认为这可能是 LessWrong 对话的一个好话题。我看到他们<a href="https://www.lesswrong.com/posts/kQuSZG8ibfW6fJYmo/announcing-dialogues-1?commentId=L2qFjT8taEhkm4hCB">提出要与人们进行 LW 对话</a>，于是我伸出了援手。</p><p>在这次对话中，我们讨论了我如何决定与工作人员聊天、我在华盛顿的初步观察、有关国会办公室如何工作的一些背景、我的会议是什么样的、我学到的教训以及关于我的经历的一些杂项。</p><h2>语境</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 19:14:27 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 19:14:27 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>嘿！在您的留言中，您提到了一些与您在华盛顿的经历相关的主题。</p><p>我认为我们应该从您与国会办公室谈论人工智能风险的经历开始。我很有兴趣了解更多；似乎没有太多公共资源来说明这种外展活动是什么样的。</p><p>那是怎么开始的？是什么让你想这么做？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 19:23:08 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 19:23:08 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>2023 年 3 月，我开始在<a href="https://www.safe.ai/">人工智能安全中心</a>从事一些人工智能治理项目。我的一个项目涉及帮助 CAIS 响应<a href="https://www.ntia.gov/issues/artificial-intelligence/request-for-comments">NTIA</a>发布的关于人工智能问责制的评论请求。</p><p>作为这项工作的一部分，<strong>我开始思考一个好的前沿人工智能监管框架应该是什么样子。</strong>例如：如果我可以为前沿人工智能系统建立许可制度，它会是什么样子？它会被安置在美国政府的什么地方？我希望它评估哪些信息？</p><p><strong>我开始想知道实际的政策制定者会对这些想法有何反应</strong>。我也很好奇更多地了解政策制定者如何考虑人工智能灭绝风险和灾难性风险。</p><p>我开始询问人工智能治理领域的其他人。绝大多数人（根本）没有与国会工作人员交谈过。一些人有与员工交谈的经验，但没有与他们谈论人工智能风险。很多人告诉我，他们认为与政策制定者的接触非常重要，但却被忽视了。当然，也存在下行风险，所以你不希望有人做得不好。</p><p>在咨询了 10-20 名人工智能治理人员后，我询问 CAIS 我是否可以去华盛顿并开始与国会办公室交谈。目标是（a）提高对人工智能风险的认识，（b）更好地了解国会办公室如何考虑人工智能风险，（c）更好地了解国会办公室的人们有哪些与人工智能相关的优先事项，以及 (d) 获取有关我的 NTIA 评论想法请求的反馈。</p><p> CAIS 批准了，我于 2023 年 5 月至 6 月去了华盛顿。需要澄清的是，这不是 CAIS 告诉我要做的事情——这更像是 CAIS 意识到正在发生的“阿卡什事件”。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 19:26:38 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 19:26:38 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>哇，这真的很有趣。几个随机问题：</p><blockquote><p>当然，也存在下行风险，所以你不希望有人做得不好。</p></blockquote><p>一个人怎样才能把一件事做得不差呢？如何学习与政策制定者互动？<br><br>另外，你的背景是什么？在此之前您做过政策方面的工作吗？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 19:31:28 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 19:31:28 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>是的，很好的问题。我不确定最好的学习方法是什么，但我尝试过以下一些方法：</p><ul><li>与有与政策制定者互动经验的<strong>人交谈</strong>。询问他们说什么、他们发现什么令人惊讶、他们犯了什么错误、他们注意到什么下行风险等等。</li><li><strong>看书</strong>。我发现<a href="https://www.amazon.com/Master-Senate-Years-Lyndon-Johnson/dp/0394720954">参议院议长</a>和<a href="https://www.amazon.co.uk/Act-Congress-Americas-Essential-Institution/dp/0307744515">国会法案</a>特别有帮助。我目前正在阅读<a href="https://www.amazon.com/Devils-Chessboard-Dulles-Americas-Government/dp/0062276174">《魔鬼的棋盘》，</a>以更好地了解中央情报局和情报机构，到目前为止，我发现它内容丰富。</li><li>与你已经认识的政策制定者<strong>进行角色扮演</strong>，并要求他们提供直率的反馈。</li><li>在风险较低的会议中<strong>进行练习</strong>，并利用这些经验进行迭代。</li></ul><p>在此之前我没有做过太多政策方面的事情。在大学里，我为《哈佛政治评论》撰稿，并参与了政治研究所的工作，但这比“现实世界的政策参与”的内容更具学术性。</p></div></section><h2>抵达华盛顿特区并进行初步观察</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 19:32:08 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 19:32:08 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>这一切都是有道理的。到达华盛顿后你做了什么？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 19:37:08 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 19:37:08 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>我给国会办公室以及一些行政部门的人员发送了冷电子邮件。我还联系了华盛顿的一些 EA。我还继续处理 NTIA 的评论请求（截止日期为 6 月 6 日）。</p><p>最初的计划是召开几次会议，评估会议的进展情况，如果我认为进展相当顺利，则再召开更多会议。</p><p>总的来说，我最终与国会工作人员举行了大约 50-70 次会议（以及一些与智库人员和行政部门机构人员的会议，但我将在这篇文章中重点讨论与国会工作人员的会议）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 19:37:28 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 19:37:28 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>我认为他们进展得相当顺利，那么？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 19:43:42 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 19:43:42 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>据我说，是的！我要注意的一件事是，这些可能有点难以评估——比如，员工应该对人友善，他们不会说“我以为你是个白痴”或“你浪费了我的时间”之类的话。时间”或“我现在对人工智能安全性的印象更差了。”</p><p>记住这一点：</p><ul><li><strong>我对员工们的开放态度感到惊讶。</strong>奥弗顿之窗最近发生了很大的变化，但当时，我真的不知道人们是否会说“哈！<i>灭绝风险？</i>这听起来像科幻小说。”</li><li><strong>主导氛围是“人工智能非常重要，我是一名忙碌的员工，有 100 个优先事项，所以我没有时间了解它。我</strong>真的很高兴能与能够告诉我有关人工智能的东西的人交谈– 我一直渴望跟上进度。”</li><li><strong>员工们对有机会见到愿意回答有关人工智能基本问题的人表示非常感激</strong>（例如，什么是大型语言模型，它与其他类型的人工智能有何不同？有多少公司从事前沿人工智能？）</li><li>有一些“切实”的信号表明事情进展顺利。例如，一些工作人员将我介绍给他们认识的其他人，一些人将他们办公室正在起草的工作发给我，还有一些人甚至将我介绍给国会议员（总共两个）。</li></ul></div></section><h2>国会办公室的层级</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 19:44:47 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 19:44:47 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>这真的很有趣！<br><br>顺便说一句，您能给我描绘一下国会办公室的人员配置等级吗？例如，您通常与谁交谈，他们通常与国会议员有什么关系？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 19:50:33 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 19:50:33 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>好问题！因此，我的理解是，国会办公室通常具有以下角色，从“最有影响力”到“最没有影响力”列出：</p><ul><li>参谋长</li><li>立法主任</li><li>立法助理</li><li>立法通讯员</li><li>实习生和研究员</li></ul><p>还有一些其他角色，但从立法角度来看，这些角色往往最为重要。</p><p>请注意，每个办公室都有自己的氛围。有人曾经告诉我“每个国会办公室都是自己的初创企业，每个国会议员都可以按照自己的意愿管理自己的办公室。”</p><p>因此，在某些办公室，实习生和研究员实际上可能有很大的影响力（例如，如果国会议员或立法主任信任实习生是特定主题的主题专家）。但总的来说，我认为这种层次结构很常见。</p><p>我想我主要是与立法助理/立法通讯员级别的人交谈。我还与几位立法官员进行了交谈。</p></div></section><h2>外展到办事处</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 19:51:24 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 19:51:24 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>好吧，这一切都有道理。那么，您是如何从几次会议增加到 60-80 次的呢？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 19:55:30 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 19:55:30 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>我向技术政策工作人员发送了一封群发电子邮件，回复人数给我留下了深刻的印象。这封电子邮件相当短，提到我在 CAIS，用 1-2 个要点介绍了 CAIS 的工作，并用要点说明了我正在处理 NTIA 的评论请求。</p><p>我认为国会工作人员现在确实对人工智能内容非常感兴趣。就像，如果我向人们发送电子邮件讨论其他问题，我认为我不可能召开这么多会议。</p><p>有人感觉“人工智能现在很热，但没有人真正了解人工智能”。我认为目前还不清楚这种情况会持续多久（尤其是“人们了解不多，办公室还没有下定决心”）部分。</p><p>我什至会说“我认为这是一个 AIS 社区作为一个整体可以/应该充分利用的机会”。比如，国会工作人员曾经（而且我认为仍然）对与人们讨论人工智能问题非常感兴趣——很难想象还有比这更好的机会让 AIS 社区的人们能够进来并担任顾问/倡导者。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 20:20:31 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 20:20:31 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>这就说得通了。</p><p>如何才能开始与国会工作人员接触？人们应该做什么才能进入这个领域/哪些组织可能适合为此部署人员？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 20:38:04 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 20:38:04 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>这将是一个相当模糊的答案，但我认为这在很大程度上取决于人、他们的技能和他们的政策目标。</p><p>另外——我在上面提到过这一点，但重要的是要重申——人们做得不好肯定会带来风险。另一方面，存在过于“不作为偏见”或类似情况的风险，并留下很多价值。</p><p>这确实很难且令人困惑。我之前提到，我咨询了 10-20 名 AI 治理人员。他们中的大多数人都说“这似乎很重要但被忽视了，但我不知道，这似乎很令人困惑。”他们中的一些人就像“是的，我完全认为你应该这样做，特别是如果你采用 XYZ 策略。”一位相当著名的人工智能治理人士明确告诉我，他们不希望我这样做。我发现很难平衡这种相互矛盾的反馈。</p><p>我还认为我的很多建议取决于某人到底想说什么——例如：</p><ul><li>他们的推销方式是什么？如果会议开始，工作人员说“那么，你想谈什么？”，最初的反应是什么？</li><li>他们是那种善于提出问题、对别人的世界观感到好奇的人吗？</li><li>他们听起来会危言耸听吗？</li><li>他们了解很多关于人工智能的事实吗？当他们不知道某件事时，他们是否能够认识到这一点并进行适当的对冲？</li></ul><p>考虑到所有这些，如果阅读本文的人有兴趣与国会工作人员互动（或让他们组织中的某人这样做），并且他们重​​视我的意见，<strong>我建议他们通过 LW 与我联系。</strong>我能够在更多背景下提供更好的建议。</p></div></section><h2>一次典型的会议</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 06 Nov 2023 20:47:09 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 06 Nov 2023 20:47:09 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>是的，这一切都有道理。您能向我介绍一下您可能举行过的典型会议吗？例如，您将如何首次与员工联系，您将在哪里与他们见面，实际对话是什么样的，您将如何跟进或以其他方式弄清楚这是否有帮助？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 06 Nov 2023 21:47:20 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 06 Nov 2023 21:47:20 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p><strong>会议物流</strong></p><ol><li>将通过电子邮件联系</li><li>通常会在国会办公室（华盛顿特区基本上有 4 座主要建筑都设有所有国会办公室）或通过 Zoom 与他们会面</li></ol><p><strong>会议进展如何</strong></p><ol><li>谈话通常会从我询问他们是否对人工智能有任何疑问或希望我分享我正在研究的东西开始。通常，他们希望我先开始。</li><li>我首先介绍我自己和 CAIS。一旦<a href="https://safe-ai.webflow.io/statement-on-ai-risk">CAIS 声明</a>出来，我就会引用 CAIS 声明。我会告诉他们，我正在关注先进人工智能带来的全球安全风险。我还会告诉他们我正在制定 NTIA 响应，并且会告诉他们我正在考虑的一些高级想法。</li><li>然后，我会停下来看看他们是否有任何问题。</li><li>通常，他们要么询问更多有关灭绝风险的问题，要么询问有关人工智能的各种问题（例如，您对如何处理深度造假有什么想法吗？），或者提出一些有关监管的高级问题（例如，我们如何监管而不扼杀创新？我们如何监管而不输给中国？）</li><li>在一些最好的会议中，我会听到办公室正在研究的一些与人工智能相关的东西。大多数办公室没有能力/兴趣在人工智能领域发挥带头作用。大约 10% 的办公室表示“是的，我的国会议员对此非常感兴趣，我们正在考虑引入立法或成为其他人立法的核心部分。”</li><li>很多人问我是否有立法草案。显然，如果你有监管想法，人们希望看到你有一个像法案一样写成的（简短的）版本。</li></ol><p><strong>跟进</strong></p><p>NTIA 的评论请求回复完成后，我向遇到的每个人发送了一份后续信息。当我有一次特别好的会议时（例如，一位员工对人工智能风险表示强烈兴趣，或者告诉我他们想向我发送他们正在研究的东西），我会发送个性化的后续信息。我认为最明显的帮助迹象来自于人们继续向我发送问题/想法、将我介绍给同事或希望与我合作提出建议的情况。 （需要明确的是，这种情况发生在少数情况下，但我认为这是大部分影响的来源）。</p></div></section><h2>员工对人工智能风险的态度</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Wed, 15 Nov 2023 22:41:56 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Wed, 15 Nov 2023 22:41:56 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><blockquote><p>很多人问我是否有立法草案。</p></blockquote><p>他们正在寻求针对哪些类型的问题进行立法？您建议的任何立法？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Wed, 15 Nov 2023 22:38:45 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Wed, 15 Nov 2023 22:38:45 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>工作人员经常想知道我是否有立法草案来描述我在 NTIA 回复中所写的许可制度（我没有立法草案，但后来在帮助 Thomas 关闭<a href="https://www.aipolicy.us/">人工智能政策中心</a>时参与了立法起草工作）地面。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Wed, 15 Nov 2023 22:39:31 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Wed, 15 Nov 2023 22:39:31 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>啊好吧。更一般地说，人们对人工智能风险有哪些先验？您认为您通常会导致他们处理该主题的方式发生重大变化吗？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 13 Nov 2023 22:39:04 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 13 Nov 2023 22:39:04 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p><strong>似乎大多数人对人工智能风险没有强烈的先见之明。</strong>我本以为人们的先验会更加怀疑（比如“什么？世界末日？<i>真的吗</i>？”）。但我认为很多人都会说“是的，我完全可以看到人工智能如何导致全球安全风险”，甚至“是的，我实际上很担心类似天网的人工智能，我很高兴其他人正在努力”关于这一点。”</p><p>通常，人们似乎<strong>真正担心人工智能带来的灭绝风险</strong>，但也<strong>没有任何计划来解决这个问题</strong>。有人提醒我，“X 是一种存在风险”实际上是一件非常 EA 的事情 -->;“因此我应该认真考虑在 X 上工作。”很多人就像“我很高兴其他人正在考虑这个问题[但我不会，我也不指望我的国会议员会]。”</p><p>就我的效果而言，我认为我主要只是让他们更多地考虑这一点，并将其列入他们内部的“人工智能政策优先事项”列表中。我认为人们忘记了员工的优先事项清单上有大约 100 件事，所以仅仅让他们接触并重新接触这些想法就会有所帮助。</p><p>我还遇到了一些员工，他们似乎非常关心人工智能风险，并且似乎是人工智能政策领域的坚定盟友。我仍然与几个人保持着联系，当托马斯创办人工智能政策中心时，我向他介绍了其中的一些人。如果我希望通过一项法案，我想我可以更好地了解我会尝试与哪些特定人员取得联系。<strong>在我看来，整个华盛顿之行的大部分影响可能在于弄清楚盟军工作人员是谁并与他们建立初步关系。</strong></p><p>最后一件事是，我通常不强调失去控制//超级智能//递归自我完善。我没有隐藏它，但我将其包含在更长的威胁模型列表中，并且它很少是我试图传达的主要内容。如果我再做一次，我可能会更多地强调这些威胁模型。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Wed, 15 Nov 2023 22:42:42 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Wed, 15 Nov 2023 22:42:42 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><blockquote><p>在我看来，整个华盛顿之行的大部分影响可能在于弄清楚盟军工作人员是谁并与他们建立初步关系。</p></blockquote><p>啊好吧！有哪些特征可以很好地预测员工是否会同情这项事业？例如特定地区、政治倾向、其他政策。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 13 Nov 2023 22:51:23 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 13 Nov 2023 22:51:23 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><blockquote><p>有哪些特征可以很好地预测员工是否会同情我们的事业？</p></blockquote><p><br>并不真地。样本量非常小。就像，总共可能有大约 4 名工作人员，我会把他们安排在“非常关心灭绝风险，并且他们可以在推动立法方面提供很大帮助”的位置。 1 名共和党人和 3 名民主党人。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 13 Nov 2023 22:24:22 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 13 Nov 2023 22:24:22 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>啊，明白了。你们所进行的讨论（在 CAIS 声明发布之前）是否对该声明产生了任何影响（措辞、外展等）？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Wed, 15 Nov 2023 22:37:49 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Wed, 15 Nov 2023 22:37:49 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>讨论并未影响该声明；该声明是在我前往华盛顿之前写的。 （有趣的事实：我是参与起草 CAIS 声明的人之一。认为为一个好句子做出贡献比我所做的许多其他事情的影响力要大 100 倍，这有点奇怪，但是嘿，有时它会起作用那样）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 13 Nov 2023 22:48:17 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 13 Nov 2023 22:48:17 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><blockquote><p>（有趣的事实：我是参与起草 CAIS 声明的人之一。认为为一个好句子做出贡献比我所做的许多其他事情的影响力要大 100 倍，这有点奇怪，但是嘿，有时它会起作用那样）。</p></blockquote><p>该死。我们生活在一个奇怪的世界。顺便说一句，做得很好。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 13 Nov 2023 22:48:28 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 13 Nov 2023 22:48:28 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>谢谢！看到这个声明有多么重要确实很奇怪。</p><p>我认为这也是相当令人谦卑的——当我第一次听到这个声明时（当时我们称其为公开信），我记得当时我很沮丧，就像“嗯，一封公开信会做什么？我们已经有 FLI 暂停信。”</p><p><strong>这是一个有用的提醒，有时您可能无法提前预测某些事情的影响</strong>。事后看来，很明显（至少对我来说）CAIS 声明是有用的，并且变革理论非常可靠。但当时，这并不像是一个落后的总体规划。感觉这只是 20 个项目清单中的一个项目，而且它有一种模糊的变革理论，这只是另一个似乎值得冒险的赌注。</p></div></section><h2>得到教训</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 13 Nov 2023 22:50:22 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 13 Nov 2023 22:50:22 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>如果您再次进行此过程，您会采取哪些不同的做法？让您感到惊讶/您觉得自己从中学到的主要事情是什么？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 13 Nov 2023 22:58:05 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 13 Nov 2023 22:58:05 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p><strong>我想我会写一份文档来解释我的推理</strong>，记录我咨询过的人，记录我所意识到的上行和下行风险，并将其发送给一些 EA。我认为一些谣言称这是以相当单边主义的方式完成的。这很棘手，让我很难过。我不认为我这样做的方式实际上是单边主义的，但我认为通过书面推理来避免误解会更好。 Thomas 在 CAIP 中做了很多这样的事情，并为<strong>“如何在不确定的情况下采取行动，同时以推理透明和高度协调的方式采取行动”等问题提供了一个很好的模型。</strong></p><p>我还认为我会提出<strong>立法草案</strong>（假设我所在的组织对此感到满意）。如果你有立法草案，人们似乎会更认真地对待你。</p><p>我还会写一份<strong>更短的 NTIA 回复</strong>– 我们最终写了一篇大约 20 多页的论文。我会针对较短的材料进行更多优化。</p><p>啊，说到这里，我会带<strong>一份打印出来的单页纸</strong>来解释什么是 CAIS 并总结 NTIA 答复中的监管理念。我在中途就完成了这件事，而且我本来可以早点完成这件事。</p><p>另外，我会带着<strong>名片</strong>来。人们似乎很喜欢名片！ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 13 Nov 2023 23:01:08 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 13 Nov 2023 23:01:08 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>是的，这一切都有道理，尽管我绝对不会提前猜到。</p></div></section><h2>最后拍摄</h2><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Mon, 13 Nov 2023 23:02:52 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Mon, 13 Nov 2023 23:02:52 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>我想我已经没有什么问题要问了：你还有什么要说的吗？随意闲逛。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KmQEfgxQrdnpXYYYq-Mon, 13 Nov 2023 23:26:43 GMT" user-id="KmQEfgxQrdnpXYYYq" display-name="Akash" submitted-date="Mon, 13 Nov 2023 23:26:43 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>阿卡什</b></section><div><p>以下是一些杂项：</p><ol><li>我在华盛顿的经历让我觉得<strong>奥弗顿之窗非常宽</strong>。国会没有对人工智能政策的缓存，而且似乎很多人真的想学习。目前尚不清楚这种情况会持续多久（例如，人工智能风险最终可能会两极分化），但我们似乎正处于一个异常高度开放和好奇心的时期。</li><li>然而，<strong>让国会采取任何行动也非常困难</strong>。就像，由于相当无聊的原因，没有多少法案获得通过。在这个过程中，有很多步骤可能会导致账单失效。当事情需要两党合作时更是如此（目前他们确实这样做，因为我们有民主党参议院和共和党众议院）。这主要让我想到<strong>“哇，现状通常不会发生任何事情，而且需要做很多工作才能获得任何有意义的立法。”</strong>考虑到这一点，我确实认为我们在人工智能安全方面处于一个非常独特的境地（<i>实际上</i>没有那么多事情会带来灭绝风险和各种其他灾难​​性风险；也没有那么多事情会成为现实）参议院多数党领袖的优先事项，激发与世界领导人的国际峰会，或成为整个行政命令的焦点）。</li><li><strong>许多人高估了华盛顿特区的“内部游戏”数量</strong>，尤其是在国会参与方面。有一些秘密的事情正在发生，但在大多数情况下，我认为没有人有掌控权。</li><li>我希望看到<strong>围绕具体政策愿景进行更多协调</strong>。有一段时间，您加入 Cool Kids Club 仅仅是为了关心 xrisk。我认为奥弗顿之窗已经发生了很大的变化，我们已经到了“关心xrisk”已经不够的地步了。重要的是人们支持并愿意倡导哪些具体政策。</li><li>考虑到这一点，我还认为拥有更广泛的人工智能风险社区是有好处的。<strong>协调实施不当可能会导致一事无成，因为你永远无法达成共识</strong>（目前这有利于领先的实验室和不受监管的扩展）。<strong>协调太少可能会导致缺乏联盟建设和不必要的冲突。</strong>我认为我已经从“协调是好的”转变为“如果做得好，协调是好的，但实际上需要技巧、机智和努力才能做好协调”。</li><li>我通常认为<strong>更多的人应该公开写下他们的观点。</strong>当我不知道人们相信什么时，很难协调。我认为社会应该不太愿意赞扬那些没有提出任何特定立场的人。 <strong>&nbsp;</strong></li><li>我对 DC AI 安全社区了解了很多（我所说的“AI 安全社区”主要指那些出于避免 xrisk 或社会规模灾难的愿望而从事 AI 安全工作的人们。有些人被认为是 EA/长期主义者） ，但很多人没有）<ol><li> TLDR：这很复杂。我认为前10%的思想家都非常有才华，并且追求合理的变革理论。另一方面，也有很多人声称对人工智能政策感兴趣，但对各种人工智能安全威胁模型没有基本的了解。人们还（真实且合理地）担心，社交无能和政治无能的新来者可能会以威胁或削弱现有努力的方式进入该领域。</li><li>总的来说，我觉得主流文化对新的政策努力过于不屑一顾。我希望随着人工智能政策对话的不断向前发展并吸引新的人群，这种情况会发生改变。我会对社区的反应更像是“啊，新人感兴趣！让我们给您一些提示/指示，并指出我们所拥有的具体经验并讨论下行风险的具体模型”感到兴奋。现状常常让人感觉不那么具体，而且（在我看来）对新的努力过于保护主义。我发现这种文化让我更难清晰地思考或进行倡导，尤其是我所说的“高度直接性倡导”（EG 主要试图向人们传达你的内部世界状态，而不是主要尝试）传达一系列能够很好地吸引观众的信念）。我认为关于各种倡导工作应该如何“直接”进行认真的辩论（而且我认为如果华盛顿特区的一些人完全直接的话，他们实际上会失去一些影响力/“严肃性点”），但我仍然感到惊讶影响的大小——文化似乎阻碍我和我的同事直接表达的程度。我相信这种文化大大减缓了新政策的努力，并继续以我认为对世界不利的方式威胁/削弱/阻碍新的政策努力。与许多事情一样，我认为高层关注是正确的，但这些高层关注的具体应用/实施方式存在问题</li><li>评估不同人员/计划的跟踪记录也很困难。部分原因是某些信息是秘密的，部分原因是“我们与重要利益相关者有良好的关系”之类的事情是有用的工具性步骤，但不一定转化为影响，部分原因是许多变革理论都是基于点击量的，需要时间才能产生直接影响（例如，如果某人与 X 建立了良好的关系，也许在某个时候 X 将变得与人工智能监管极其相关，但也许只有 1-10% 的可能性是真的。）话虽如此，我认为，如果人们最终更明确地表达自己的信念，更明确地表达他们希望实现的具体政策目标，更明确地表达他们明显的胜利（和损失），那么协调会更容易。如果没有这一点，我们就会冒着赋予那些“玩游戏”、发展影响力但最终没有利用他们的影响力来实现有意义的变革的人太多权力和太多资源的风险。 （另请参阅多米尼克·卡明斯<a href="https://www.dwarkeshpatel.com/p/dominic-cummings#details">播客</a>）。</li></ol></li><li>与此相关的是， <a href="https://forum.effectivealtruism.org/posts/tdaoybbjvEAXukiaW/what-are-your-main-reservations-about-identifying-as-an?commentId=gNC53rsuMNTBjLCWY">奥利弗·哈布里卡（Oliver Habryka）的评论</a>引起了我的共鸣。我发现，当我与“主流 EA”保持一定距离时，我的思维往往会更清晰。有很多抗体和微妙的文化压力会阻止我思考某些想法，并会削弱我在世界上采取直接行动的能力。 （当然，我不认为解决方案是“永远不要与 EA 互动”——但我确实认为人们可能低估了社区对良好思考和实现困难事物的负面影响。我当然是低估了。）</li><li>对于有兴趣捐赠的人，我目前推荐<strong> </strong>这<strong> </strong><a href="https://www.aipolicy.us/"><strong>人工智能政策中心</strong></a><strong> </strong>（尤其是托马斯·拉森继续高度参与其战略方向）。我与托马斯有一些战略/战术分歧，但我认为他是一个非常聪明和有才华的人，我认为他是人工智能政策领域最值得支持的新人之一（COI：托马斯是我的朋友之一，我在人工智能政策中心的早期阶段参与了帮助）。</li><li>如果您想与我交谈，<strong>请随时联系 LessWrong</strong> 。我喜欢与从事人工智能政策工作的人交谈。我也愿意接受我可以做的或我知道的其他人可以做的有影响力的事情。 </li></ol></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="vWQfyFPKdACzXEZ6R-Wed, 15 Nov 2023 22:18:15 GMT" user-id="vWQfyFPKdACzXEZ6R" display-name="hath" submitted-date="Wed, 15 Nov 2023 22:18:15 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>有</b></section><div><p>哇，好吧。感谢您进行这次对话！</p></div></section><div></div><br/><br/> <a href="https://www.lesswrong.com/posts/2sLwt2cSAag74nsdN/speaking-to-congressional-staffers-about-ai-risk#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/2slwt2csaag74nsdn/speaking-to-compeaking-to-compressional-staffers-about-ai危险<guid ispermalink="false">2SLWT2CSAAG74NSDN</guid><dc:creator><![CDATA[Akash]]></dc:creator><pubDate> Mon, 04 Dec 2023 23:08:52 GMT</pubDate> </item><item><title><![CDATA[Open Thread – Winter 2023/2024]]></title><description><![CDATA[Published on December 4, 2023 10:59 PM GMT<br/><br/><p>如果它值得说，但不值得单独发表，这里有一个地方可以放置它。</p><p>如果您是 LessWrong 的新手，这里是您自我介绍的地方。欢迎您就您如何找到我们以及您希望从网站和社区获得什么发表个人故事、轶事或只是一般性评论。如果您不想写完整的顶级帖子，这也是讨论功能请求和您对该网站的其他想法的地方。</p><p>如果您是社区新手，您可以开始阅读<a href="https://lesswrong.com/highlights">Sequences 的亮点</a>，这是有关 LessWrong 核心思想的帖子集合。</p><p>如果您想更多地探索社区，我建议您<a href="https://www.lesswrong.com/library">阅读图书馆</a>，<a href="https://www.lesswrong.com/?view=curated">查看最近策划的帖子</a>，<a href="https://www.lesswrong.com/community">看看您所在的地区是否有任何聚会</a>，并查看<a href="https://www.lesswrong.com/faq">LessWrong 常见问题</a><a href="https://www.lesswrong.com/faq#Getting_Started">解答</a>的入门部分。如果您想了解网站上的内容，您还可以查看<a href="https://www.lesswrong.com/tags/all">“概念”部分</a>。</p><p>开放线程标签在<a href="https://www.lesswrong.com/tag/open-threads?sortedBy=new">这里</a>。 Open Thread 序列在<a href="https://www.lesswrong.com/s/yai5mppkuCHPQmzpN">这里</a>。</p><br/><br/> <a href="https://www.lesswrong.com/posts/tRa92qDonDLi6RA8u/open-thread-winter-2023-2024#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/tra92qdondli6ra8u/open-thread-winter-2023-2024<guid ispermalink="false"> tra92qdondli6ra8u</guid><dc:creator><![CDATA[habryka]]></dc:creator><pubDate> Mon, 04 Dec 2023 22:59:51 GMT</pubDate> </item><item><title><![CDATA[Interview with Vanessa Kosoy on the Value of Theoretical Research for AI]]></title><description><![CDATA[Published on December 4, 2023 10:58 PM GMT<br/><br/><p>以下是我与 Vanessa Kosoy 进行的<a href="https://youtu.be/1MCRQF0_5zY?feature=shared"><i>视频采访</i></a><i>的文字记录（经过语法编辑）</i> ，从我的<a href="https://www.zenmarmotdigital.com/blog/interview-with-vanessa-kosoy"><i>博客</i></a><i>交叉发布</i><i>。它旨在（相对）对初学者友好地解释</i><a href="https://www.lesswrong.com/posts/ZwshvqiqCvXPsZEct/the-learning-theoretic-agenda-status-2023#Direction_6__Metacognitive_Agents"><i>学习理论议程</i></a>的目标<i>，以及为什么需要更多的理论工作来确保人工智能大规模安全可靠。</i></p><p></p><p><strong>简介（作者：Will Petillo）：</strong>讨论人工智能的未来往往会变得哲学化。有“目标”或“理解”意味着什么？追求权力是想要东西的默认结果……还是我们独特的进化历史造成的人类怪癖？是什么激发了善良？以这种方式提出问题可以使问题易于理解，让每个人都参与对话。但这种缺乏精确性也使得此类问题变得棘手，因为分歧会变成直觉冲突。</p><p>今天“一致性守护者”的嘉宾是瓦妮莎·科索伊 (Vanessa Kosoy)，她是一位由机器智能研究所 (MIRI) 和长期未来基金 (LTFF) 支持的独立研究员，致力于构建安全人工智能的数学理论。这种对理解第一原理的关注使她的工作与领先人工智能实验室的“快速行动并打破常规”实验方法形成鲜明对比。在这次采访和其他地方，瓦妮莎捍卫了更加基于理论的方法的价值，并解释了探索机器学习作为基础科学的意义。</p><p></p><p> <strong>Will Petillo：</strong>您是如何进入人工智能安全领域的？</p><p> <strong>Vanessa Kosoy：</strong>我一直是一个自学者，所以我倾向于自学东西。当我小的时候，我想我会成为一名理论物理学家。我实际上拥有数学学士学位，但在完成学士学位后，我没有进入学术界，而是决定在软件行业从事职业生涯。</p><p>我在软件行业有很长的职业生涯，特别是算法工程，主要是计算机视觉，各种角色，算法工程师，团队领导，研发经理。我也有自己的创业公司。大约 10 年前，我是一名顾问。我接触到了人工智能带来的生存风险这一整个话题，并开始思考，嗯，这实际上似乎很重要。所以我开始转向这一点，最初只是我在空闲时间做研究。随后得到了 MIRI 的支持。最近我还得到了长期未来基金的支持，这使我能够全职工作。</p><p> <strong>Will Petillo：</strong>那么这个过程是怎样的呢？你只是以一种自我导向的方式工作，然后你获得了美里和其他来源的支持？这是怎么来的？</p><p> <strong>Vanessa Kosoy：</strong>我开始阅读 MIRI 和 Less Wrong 的人们写的一些东西。我开始研究自己的想法，并在 Less Wrong 上发表文章。之后，我被邀请参加一些研讨会、一些活动，最终 MIRI 说，好吧，看来你在这里做了一些不错的工作，所以也许我们也会付钱给你。我很棒，因为这也使我能够做更多的事情，而花更少的时间做其他事情。<br><br>威尔·佩蒂略<strong>（Will Petillo）：</strong>这里为观众介绍一下背景知识。 Less Wrong 是一个受欢迎的博客。它最初是关于理性的，但也是关于人工智能相关的事情。 MIRI 是机器智能研究所。我喜欢将他们描述为在它变得很酷之前就致力于协调的人。请告诉我更多关于 MIRI 作为一个机构的信息。<br><br> <strong>Vanessa Kosoy：</strong> MIRI 或多或少是第一个谈论人工智能存在风险的人。 Eliezer Yudkowsky 在 2000 年开始谈论这个问题，最初 Miri 只是 Yudkowsky，然后多年来他们设法获得一些资金来吸引其他研究人员加入。他们正在思考这个问题：我们如何使人工智能安全，以及我们如何解决这个问题？我们能想出什么样的数学理论来解决这个问题？这甚至早于深度学习革命开始之前，也早于近年来大型语言模型的整体炒作。他们的大部分时间都致力于提出一些基础数学理论，以帮助我们进行人工智能调整。<br><br>最近，他们转向外展并试图影响政策，因为他们相信时间确实很短，不幸的是我们没有时间发展这一理论。<br><br><strong>威尔·佩蒂略：</strong>你参与了这一转变吗？<br><br> <strong>Vanessa Kosoy：</strong>不，我的观点不同。你可以说我比较保守。我认为时间表并不像风险界许多人认为的那么短。我认为，如果通过政策渠道规范人工智能发展并推迟人工智能发展以阻止真正危险的人工智能出现的努力能够成功，那么这只是为我们赢得了时间。那么问题是：为我们争取时间做什么？我认为理论基础绝对仍然是我们应该利用我们所拥有的时间或我们将通过某种政策计划成功购买的时间做的事情中最重要的事情，无论怎样。<br><br>我认为实际上在任何世界中，创建这个基础理论都是关键。这就是我正在做的事情。这绝对是我的个人技能和优势所在，研究数学而不是政策。<br><br><strong>威尔·佩蒂略：</strong>你提到了时间表。直觉上，我知道不可能以任何精确度真正预测这些事情，但就你的动机而言，你认为需要解决这些问题的时间表是什么？<br><br> <strong>Vanessa Kosoy：</strong>有些人认为 AGI 将在 10 年甚至更短的时间内到来。我认为这有点极端。但当事情需要解决的时候，越快越好不是吗？如果我们在五年内找到解决方案，那么我们的处境会比我们在 10 年内找到解决方案更好，这仍然比我们在 20 年内找到解决方案更好，依此类推。<br><br>实际上，我个人的观点是，我们还需要几十年的时间才能真正实现那种带来生存风险的人工智能。所以这给了我们更多的时间，但不是无限的时间。<br><br> <strong>Will Petillo：</strong>是什么让你觉得这是你想做的事情？<br><br> <strong>Vanessa Kosoy：</strong>一开始更像是一种好奇心，因为它实际上是从我完全随机发现开始的，你可以说一些关于 AGI 的论文，甚至不是关于人工智能对齐或风险或类似的东西，而只是 Jürgen Schmidhuber 和 Marcus Hutter 的一些论文关于 AGI 的一些想法。我一直是一个数学迷，所以有那些思考 AGI 的数学框架看起来真的很酷。我开始阅读相关内容，最终也发现了Less Wrong，其中也有人在讨论这类事情。<br><br>一方面，我读了越来越多的 Eliezer Yudkowsky 写的关于这个主题的文章，以及 LessWrong 上的人们写的关于这个主题的文章，但我也开始思考数学模型。最终，我突然意识到，当你思考实际的数学时，就完全有道理了，没有任何数学原因可以解释为什么人工智能必须关心人类或关心任何与我们人类关心的事情一致的东西。<br><br>另一方面，它似乎也明显比我们更有能力。我认为直观上很清楚，但对我来说，我喜欢通过数学来理解一切。因此，当我看到你实际上可以将其放入数学模型中时，我真的意识到这是真实的事情，这是我们真正应该关心的事情。</p><p><strong>威尔·佩蒂略：</strong>没有理由认为人工智能一定是好的，这听起来很像尼克·博斯特罗姆写的正交性论文。智力和事物的美好程度并不一定要同时出现；任何一套价值观都可以与任何水平的智力相匹配。这本质上就是你的见解吗？<br><br> <strong>Vanessa Kosoy：</strong>是的，这正是术语。事后看来，这似乎是一件显而易见的事情。但对我来说，有必要看到你实际上可以用数学对象来思考它；值可以形式化为效用函数。然后，代理可以被形式化为某种优化器、某种贝叶斯最优策略或该效用函数的任何形式。实际上，你可以在每个术语背后赋予严格的含义，并发现它们实际上都是有意义的——这不仅仅是某种哲学上的挥手把戏。<br><br> <strong>Will Petillo：</strong>在您看来，导致人工智能对齐问题变得困难的根本原因是什么？<br><br> <strong>Vanessa Kosoy：</strong>我认为这个问题很难。我认为，首先，困难在于我们的目标非常狭窄，因为人类价值观非常复杂和具体。我们关心很多非常细节的事情：爱、友谊、美（以我们自己的主观理解）、性，所有这些东西都是人类的东西，因为一些复杂的进化事故而存在，就像它发生在某些人身上的方式一样。非常特别的星球。这是特定宇宙历史上非常特殊的时刻。这组价值观只是你可以想象的巨大的可能价值观或思想空间中非常非常狭窄的一部分。<br><br>因此，按照我们的标准，大多数人的思想绝对不会对我们有好处。更糟糕的是，内特·苏亚雷斯（Nate Soares）在他最近的一篇文章中很好地阐述了这种现象，他在其中写道，围绕代理能力存在一个吸引力盆，但对于代理对齐却没有吸引力盆。这意味着，如果您施加足够的优化压力，即使使用强力技术，您最终也将生成功能强大的代理。进化就是一个例子，对吗？进化是一种非常原始的蛮力算法，最终创造了人类大脑，这是一种更加复杂的算法。如果您投入足够的强力优化来寻找在开放世界环境中成功的事物，最终您将遇到智能代理。这甚至是在你在方程中加入递归自我改进之前的，这使得它作为你汇聚的这种吸引力盆地变得更加强大。然而，在与人类价值观保持一致方面，情况并非如此。很有可能的是，我们可以通过盲目或半盲目的试错，早在我们了解足够的知识以实际使这些代理对齐之前就创建出高能力的代理。<br><br> <strong>Will Petillo：</strong>这听起来像是违背了博斯特罗姆流行的工具融合的另一个理念，即几乎任何足够努力优化的系统都需要诸如生存之类的东西。<br><br> <strong>Vanessa Kosoy：</strong>有一种工具收敛目标的概念，这是大多数智能代理都会追求的某些目标，因为它们帮助他们实现最终目标，无论他们的最终目标是什么。这些都是诸如生存、获得更多资源、变得更加聪明等等之类的事情。但人类的价值观并非如此。我想，如果我们设法构建一个能够生存并获得大量资源的人工智能，这对人工智能来说是件好事，但它对我们与我们的价值观保持一致没有任何帮助。这是一种非常不同的事情。<br><br> <strong>Will Petillio：</strong>现代人工智能是根据人类生成的数据进行训练并存在于人类社会中这一事实没有帮助吗？<br><br> <strong>Vanessa Kosoy：</strong>我认为这有帮助，但也留下了很多问题。一个问题是：好吧，你可以从人类生成的数据中学习，但你如何从中进行概括呢？因为确实不清楚需要什么条件才能获得良好的概括，尤其是当您正在学习的概念非常复杂时。<br><br>您正在学习的概念的复杂性越高，学习它所需的数据点就越多。我们正在利用近年来炒作的所谓大型语言模型来尝试模仿人类。我的意思是，这很好。它可能会以一定的概率带来一些好处——但概率不是很高。但它的问题是，为了使用它，您需要在训练分布之外进行泛化。这里我们实际上需要看看目标是什么。<br><br>问题是，从技术上讲，创造出超级智能的人工智能是可能的，但这将是危险的。为了解决这个问题，仅仅创建某种不危险的人工智能是不够的，因为否则他们可能只是编写一个不做任何事情的算法。这并不危险，任务完成了。我们需要能够创建足够强大的人工智能，作为防御系统来抵御那些潜在危险的人工智能。因此，这些系统必须具有超人的能力，能够构建复杂的世界模型，并在此基础上制定复杂的长期计划。这远远超出了大型语言模型或任何基于人类模仿的训练分布。目前还非常不清楚我们是否真的可以依赖我们必须泛化到训练分布之外的算法，而不会完全失去它们的所有对齐属性。<br><br> <strong>Will Petillo：</strong>总而言之，法学硕士从根本上来说是模仿性的，这本身似乎并不是特别危险，但它也限制了他们能做的事情。因此，我们不能真的指望开发会就此停止。最终可能会添加像强化学习这样的东西——也许不一定是算法，但可以像围棋中的 Alpha Zero 一样具有创造性，并找到一个以前没有人见过的真正创造性的棋步。因此，我们需要为更强大的事物做好准备，因为它们将是有用的，而导致建立法学硕士的经济学将导致建立更大的事物。这就是你的意思吗？<br><br> <strong>Vanessa Kosoy：</strong>是的，这听起来很当场。要么是强化学习，要么……好吧，我不想过多地推测让人工智能变得更强大需要什么，因为这不是很好的信息。</p><p><strong>威尔·佩蒂略：</strong>很公平。继续讨论您实际从事的事情，我看到的与此相关的一个想法是术语“代理基础”。还有“学习理论议程”。那些东西是什么？<br><br> <strong>Vanessa Kosoy：</strong>智能体基础是一个抽象的概念，它表明我们需要创建一个基础数学理论来解释智能体是什么。从数学角度来说，算法作为代理意味着什么？可以使用哪些类型的代理？他们可以拥有或不具备哪些能力？等等。学习理论议程比这更具体，因为它就像一个试图实现这一目标的非常具体的计划。具体来说，是通过建立在统计和计算学习理论、算法信息论、控制理论等基础上的工具。这是我创建的程序，旨在应对提出这些代理基础的挑战。<br><br> <strong>Will Petillo：</strong>好的，代理基础就像“思维如何工作？”的问题，其中包含人工智能，而学习理论议程就像“我们如何设计算法，将其推向一个好的方向？”是对的吗？<br><br> <strong>Vanessa Kosoy：</strong>我不会那样说。我只想说，特工基金会只是试图了解思维如何运作，人们一直在尝试以各种方式做到这一点。 MIRI 历史上有各种证明理论模型试图解决这个问题，然后是加拉布兰特的逻辑归纳法，在这个非常广泛的保护伞下有各种想法，而学习理论议程是一种非常具体的方法。<br><br>正是这种方法以 AIXI 和经典强化学习理论为起点，然后寻找其中缺少的成分，以便拥有代理的基础理论，并开始利用下贝叶斯主义和下贝叶斯物理主义和元认知代理等等。<br><br> <strong>Will Petillo：</strong>您在这里谈论的代理和思维类型，是否与前沿的大型语言模型相关，或者是否更广泛地涉及人工智能或任何类型的思维实体？<br><br> <strong>Vanessa Kosoy：</strong>当我说经纪人时，我的意思是非常广泛的。比现有的人工智能甚至只是人工智能要广泛得多。当然包括人类、潜在的外星人或其他什么。因此，对我来说，代理是一个具有特定目标的系统，它正在学习它所嵌入的世界的复杂模型，并使用这些模型来构建长期计划以实现其目标。这就是我所说的“代理”的非正式描述。该程序的整个目标是从这个到一个完全正式的数学定义，并研究这个定义的所有含义。</p><p> <strong>Will Petillo：</strong>因此，即使不超出法学硕士，它的范围甚至比机器学习还要广泛。采取这种做法的原因是什么？鉴于机器学习的主导地位，为什么不关注那些似乎使用最广泛的东西呢？</p><p> <strong>Vanessa Kosoy：</strong>首先，让我们保持术语的顺序。我会区分人工智能、机器学习和深度学习。人工智能是人们自 20 世纪 50 年代以来就开始思考的东西，关于如何构建思维系统，但并没有真正理解它的含义，而只是某种直观的概念，认为存在思考这样的东西，我们应该能够在机器中复制它。<br><br>机器学习是出现的一种更具体的方法……好吧，我不想具体指出什么时候，但可能是在八十年代。机器学习具体是这样的想法：思维的核心要素是学习，学习意味着你正在与一些未知的环境交互，你需要创建这个环境的模型。因此，您需要获取您看到的数据并使用它来创建模型。这类似于科学家如何进行实验、收集数据，然后根据这些数据建立理论。</p><p>这个总体想法称为机器学习，或者更准确地说，只是学习。 “机器”部分来自尝试想出在机器内部实际实现这一点的方法。这是一个有很多数学理论的领域。机器学习背后的数学理论就是所谓的统计和计算学习理论，这实际上是学习理论议程的基础。这就是为什么它被称为“学习理论”。</p><p>有一种假设认为，这种学习概念抓住了我们所说的思维的大部分重要部分。我认为这一假设得到了最新技术发展的充分支持。这是我完全赞同的，也是我整个研究计划的基础。所以这里并不矛盾，因为学习仍然是一件很普遍的事情。人类也进行学习。外星人也必须学习。</p><p>深度学习是一组更具体的算法，用于如何在机器中实际高效地完成学习，这就是 2010 年左右深度学习革命的开始，尽管这些算法在此之前已经以某种形式存在了几十年。但需要一段时间才能获得正确的细节，并拥有合适的硬件来运行它们。深度学习的不幸特征是我们无法从数学上理解它。很多人都在试图理解它，但我们并没有一个很好的理论来解释它为什么有效。这就是为什么它不是我的研究计划的重点，因为我试图提出一些数学理解。我绝对希望人们最终能够解开深度学习如何运作的这种谜团，然后就有可能将其整合到我正在构建的理论中。<br><br>但即使我们有了这个理论，那么以尽可能广泛的普遍性来思考似乎仍然非常重要，因为，首先，我们不知道今天存在的算法将是带来 AGI 的算法。而且因为最广泛的普遍性只是思考问题的正确抽象级别，以了解系统“对齐”意味着什么的概念。这里需要解决一些哲学问题，并且它们特定于一些非常特殊的算法。此外，事实上，我实际上希望这个理论包括人类，因为我可能想用这个理论来形式化价值学习等事物。如何设计一个能够向人类学习价值观的人工智能系统？<br><br> <strong>Will Petillo：</strong>查看机器学习和深度学习的维基百科级别，或者只是浏览互联网描述，很容易互换使用它们。我想我已经看到了这样的描述，深度学习就是添加多层神经元的想法。因为有多层，所以它很“深”<br><br> <strong>Vanessa Kosoy：</strong>让我尝试澄清其中的区别。机器学习谈论获取数据并从中构建模型。您正在构建的模型类型可能非常不同。在深度学习之前，我们有支持向量机等算法，多项式回归也是一种非常简单的机器学习类型——将模型拟合到数据。统计中使用的各种方法可以被视为一种机器学习。有一些模型或假设空间，您尝试以最佳方式使用数据来推断正确的假设是什么，或者如果您正在使用贝叶斯方法，则获得假设的一些概率分布。<br><br>但是，不同类型的假设类会在算法的能力方面以及我们所知道的如何学习这些假设类方面导致非常不同的结果。我们知道什么可以用数学方法证明在什么条件下我们可以真正学习它们？比如支持向量机，数学理论基本解决了。有一些建立在其之上的内核方法，并且也有非常扎实的数学理论。深度学习是一种特殊类型的学习算法，它使用人工神经网络架构。</p><p>这不仅仅是多层，还有很多细节很重要。例如，激活函数是 ReLU，这一事实对于您在训练中使用哪种正则化方法非常重要。例如，辍学基本上是深度学习革命的开始。如果您正在使用序列，那么我们有变压器，这是一种非常具体的网络架构。因此，多年来人们实际上提出了很多非常具体的细节，主要是通过反复试验的过程，看看什么是有效的。我们没有一个好的理论来解释为什么这些特定的东西运作良好。我们甚至不了解这些东西实际上正在学习的模型空间，因为你可以从理论上证明，如果你采用一个神经网络，然后让它学习另一个神经网络，那么在某些情况下这是不可行的。<br><br>但对于现实世界的问题，神经网络在很多时候都能成功学习。这表面上是因为现实世界具有一些使其可学习的特定属性，或者神经网络正在学习一些特定的潜在假设类，并且它捕获了许多现实世界的现象，但我们甚至没有数学描述这个基本假设类别是什么。我们对一些非常简单的情况有一些结果，比如两层或三层神经网络，或一些其他简化的假设，但我们还没有接近得到完整的答案。<br><br> <strong>Will Petillo：</strong>深度学习假设了世界的某些情况，就其可以获取的信息而言，它恰好工作得相当好，但目前还不清楚它的假设是什么。</p><p><strong>凡妮莎·科索伊：</strong>是的，完全正确。所以我们有不同的不可行定理，它说对于任意数据，即使该数据是完全可实现的，即使该数据使得神经网络可以完美地表达一个完全正确的模型，该问题也是不可行的。一般来说，梯度下降不会收敛到正确的模型，而且其他算法也不会收敛，因为问题很棘手。世界具有一些属性，并且由于深度学习在如此多种不同的情况下取得了成功，所以感觉这些属性应该有一些简单的数学描述。<br><br>它不像某些特定于文本、音频或图像的属性。这些属性非常通用，适用于各种不同的模式和问题。这些是我可以推测的属性，例如，与组合性有关，现实世界通常如何被很好地描述为由部分组成，以及事物如何根据不同的空间尺度或不同的时间尺度进行解耦。动态正在发生。但我们没有真正解释它的理论。<br><br> <strong>Will Petillo：</strong>您提到 ReLU 是有效的例子之一。据我了解，ReLU 基本上就像获取输出，以一种可以表示为一侧平坦且对角线超过零的图形的方式对其进行更改。而以前，模型通常使用 Sigmoid 作为激活函数，它更像是一条平滑的曲线，可以防止数字变得太大。出于某种原因，ReLU 效果更好。我从你的解释中得到的感觉是，这种变化会影响神经网络能够以更符合现实的方向理解什么样的事物。但所有这些变化都是以“把东西扔到墙上，看看什么粘住”的方式开发的，只是简单地测量结果，而没有真正理解<i>为什么</i>ReLU 比 sigmoid 更好。<br><br><strong>凡妮莎·科索伊：</strong>或多或少是对的。当我们说神经网络可以“理解”什么时，我们必须小心我们的意思。这是一个非常复杂的概念，因为它不仅仅是神经网络可以用一组权重来表达的内容，而是神经网络实际上可以通过梯度下降过程学习的内容。它不仅与神经网络可以描述的函数空间有关，而且与我们查看特定数据集时在这个权重空间中创建的整个损失景观有关。<br><br><strong>威尔·佩蒂略：</strong>当你描述梯度下降和损失景观时，我经常听到的比喻是一个从山上滚下来的球——有一个恒定的重力，你希望球下降到海平面。但通常情况下它不会，因为它发现了一些局部最小值，比如一个洞或其他东西，它可以移动的任何方向都是向上的，所以它不会再滚动。所以你必须塑造景观，使球始终到达海平面。<br><br> <strong>Vanessa Kosoy：</strong>是的，这是一个很好的解释。梯度下降是我们有很好的数学理论来解释它如何收敛到凸函数的全局最小值，但神经网络的损失是非凸的......但它仍然恰好有效。人们已经对其工作原理有了一些了解，但我们仍然没有完整的答案。<br><br><strong>威尔·佩蒂略：</strong>好吧，如果地貌确实崎岖不平，那么你就不会期望球到达海平面，因此它无论如何都会到达海平面这一事实需要一个我们实际上没有的解释。我可以看到这种框架如何引发了许多有关不可预测性的问题。<br><br>接下来，您曾提到过 AIXI。那是什么？<br><br> <strong>Vanessa Kosoy：</strong> AIXI 是 Marcus Hutter 的想法，它应该是完美代理的数学模型。它的工作原理是：有一个先验，即所罗门诺夫先验。对于那些不知道这是什么的人来说，这基本上是一种用数学形式化奥卡姆剃刀概念的方法。奥卡姆剃刀的思想是，简单的假设应该被认为比更复杂的假设更有可能是先验的。这确实是所有理性推理的基础。哈特采用了所罗门诺夫先验，这是一种非常聪明的方法，可以在数学上形式化奥卡姆剃刀的概念，并且说，好吧，让我们考虑一个生活在所罗门诺夫先验的宇宙样本中的智能体。这个代理有一些特定的奖励函数，它正在最大化。我们假设它只是以贝叶斯最优方式运行。因此，它只是遵循策略，使其根据先验最大化其预期效用。我们称之为“艾希”。这是一个非常酷的想法......只是它有很多问题，首先是它无法计算的“小”问题。即使在理论上，也没有一种算法可以实现它。<br><br><strong>威尔·佩蒂略：</strong>我想我曾经听过这样的解释：将整个宇宙想象成一堆比特——1和0。一开始，所有这些都可以是一或零，然后你得到一点数据，现在你已经锁定了其中一些数字，并将所有可能的空间减少了一半。当你不断学习时，你会变得越来越确定。<br><br> <strong>Vanessa Kosoy：</strong>实际上比这更微妙一些。拥有很多可能性这一事实并不意味着它是不可计算的。也许确切的事情是无法计算的，但你仍然可以想象有一些聪明的算法可以近似这个贝叶斯推理过程。例如，如果你看看经典的强化学习理论，就会发现有一些算法可以在具有 n 个状态的任意马尔可夫决策过程中进行学习。在具有 n 个状态的马尔可夫决策过程中，仍然存在指数级大的可能方式空间，并且我们仍然拥有实际上有效的算法，可以通过利用问题的某些属性，从这个指数级大的事物中收敛到正确的事物。<br><br> AXI 的问题是，它的先验是这样的，即使先验中的单个假设在计算上也已经是任意昂贵的，因为在它的先验中它考虑了每个可能的程序，所以你可以在通用图灵机上编写的每个可能的程序都是一个可能的假设了解世界如何运作。其中一些程序的计算成本极其昂贵。其中一些程序甚至不会停止，它们只是进入无限循环。你甚至不知道是哪一个，因为这就是停机问题，对吗？这就是为什么 AIXI 不适合做可计算的事情，更不用说计算上易于处理的事情了。<br><br> <strong>Will Petillo：</strong>抛开不可计算性这个小问题不谈，“完美算法”……这是什么意思？如果 AIXI 是通过某种方式神奇地计算出来的，它会安全吗？</p><p> <strong>Vanessa Kosoy：</strong>不，这并不能保证安全。从您可以想象的是最强大的算法上，它是“完美的”。同样，根据一些假设。我的意思是，还有其他问题，例如它假设外界比代理人本身更简单。这有多个问题，但是如果您可以将所有这些问题放在一边，那么您可以说这是最好的代理商。从这个意义上讲，这是完美的。非常非常非常安全。为了使其安全，我们需要以某种方式将正确的实用程序函数插入其中。这仍然是一个非常不平凡的问题。</p><p> <strong>Petillo：假设</strong>您想找到可计算的内容，您会寻找哪种算法？</p><p> <strong>Vanessa Kosoy：</strong>可计算性只是问题之一。我想像一下，我将有一些我称之为节俭的普遍先验，这在某种程度上是我们可以在数学上定义的，这将同时富裕，可以捕获各种各样的现象。另一方面，我们将拥有一些巧妙的算法，实际上可以在此事先使用该假设的某些组成性属性或其他类似的内容中进行有效学习。</p><p>但是，即使知道这一点，您也需要处理许多其他概念问题。就像我所说的特权问题一样，Occam的剃须刀和AXI的形式化使观察者特权，您需要了解如何处理。而且存在一个问题的问题，您实际上不能有一个假设，这可以使您对宇宙进行精确的描述，但只有某种近似或部分描述，并且您需要了解如何处理。然后还有一个事实，您希望实用程序功能不仅是观察值的函数，而且是您无法直接观察的一些参数。您还希望能够证明此算法的一些常见保证。要知道该算法实际上需要知道多少数据来学习特定事实并具有良好的理论。研究Aixi类似模型时，会出现各种不同的问题。<br><br><strong>佩蒂洛（Petillo）：</strong>研究aixi像模型一样，这就是您正在努力的工作吗？</p><p><strong>凡妮莎·科索（Vanessa Kosoy）：</strong>是的，如果您想将其放入一句话，我可以。<br><br><strong>佩蒂洛（Petillo）：</strong>您对解决问题感兴趣的一些有趣的问题是什么？我已经看到Newcomb的问题在四处流动，并且与此相邻。<br><br> <strong>Vanessa Kosoy：</strong> Newcomb的问题是Eliezer Yudkowsky写的很多东西，这是对经典理性叙述非常困惑的一个例子。您有两个盒子需要选择。一个盒子有一千美元。另一箱没有什么或一百万美元。您可以选择第一个盒子，也可以拿走两个盒子中的钱。通常，拿这两个盒子里的钱总是比只拿一个盒子要优越。<br><br>除了在这个位置实验中，还有一些称为欧米茄的实体可以预测您的工作也是盒子。因此，只有当您是那种可以预见的代理商（对于欧米茄）只拿一个盒子的代理商时，只有在这种情况下，您才会以$ 1,000,000的价格从这个房间里拿出来。而在另一种情况下，您只有$ 1,000。因此，可以说，最好拿一个盒子而不是两个盒子，而不是许多古典理性的说法。这是一个有趣的思想实验的一个例子。</p><p>对我来说，这种思想体验是一个非真实性问题的特殊情况，您需要处理如此复杂的环境，以至于无法完整地描述环境的完整描述，您可以真正模拟这一环境。因为在此示例中，环境包含该代理Omega，它可以模拟您，这意味着您无法模拟它，因为否则它将创建这种圆形悖论。实际上，我还表明，我称之为非可话性的理论（我称之为红外线主义）实际上导致了这种类似Newcomb的问题情景的最佳行为。<br><br><strong>威尔·佩蒂洛（Will Petillo）：</strong>研究类似Newcomb的问题的原因不是因为我们期望在某个时候面对欧米茄为我们提供盒子，而是因为这只是考虑如何在您不知道时如何处理事情的一种说明性的方式这是怎么回事。而且因为很容易说：“是的，我只会拿一个盒子，因为我会得到更多的方式”然后，有一些有趣的见解可能会从中引起。您是否通过探索这类事物发现了任何发现？</p><p><strong>凡妮莎·科索（Vanessa Kosoy）：</strong>我想说的是，基础山脉主义本身是一个有趣的发现，一些对代理商的理论上说明可以推理复杂的世界，这些世界太复杂了。现在，我通过阐明了不实现性能的问题来描述动机，但是我实际上想到的是通过思考所谓的逻辑不确定性来描述这一动机。人们之所以开始思考的原因是由于所谓的无更新决策理论，该理论来自考虑新Comb Time悖论。因此，尽管事实上，您可以通过一些更一般的抽象思维来激励它，但这一切都来自这种推理线。<br><br><strong>佩蒂洛（Petillo）：</strong>这些决策理论类型问题与使AI更安全之间的联系是什么？<br><br><strong>凡妮莎·科索（Vanessa Kosoy）：</strong>这个想法是在创建一种一般的代理人数学理论。它将帮助我们使人工智能更安全的方式，有几个原因，最明显的是，在拥有这一理论时，我们希望能够提出严格的模型，以使系统成为一个对齐代理的含义。有了这个严格的定义，我们将能够提出一些算法，我们可以证明这些算法实际上是安全的代理。或者至少我们可能会有一些猜想说，这种给定的这种猜想的模型，我们认为这些算法是安全的代理。就像在密码学中一样，您有一些猜想，这些猜想具有非常强烈的证据支持。</p><p>我们至少可以有一些半正式论点，因为现在人们在辩论特定设计是否安全时，这一切都归结为那些挥舞着哲学论证的那些没有任何坚实的基础。而这为我们提供了更精确，更清晰的思考这些问题的工具。从假设的角度来看，它也为我们提供了更多的力量来利用实证研究，因为也许我们将能够接受我们拥有的实证研究，将其插入数学理论，并获得一些关于我们期望这些结果实际上将这些结果实际推出到各种制度的答案我们还没有这样做。<br><br><strong>佩蒂洛（Petillo）</strong>是否会最终在评估大语模型或深度学习系统之类的事物时可以使用这种研究线，以便能够更确定地说他们安全或不安全的程度？<br><br> <strong>Vanessa Kosoy：</strong>我认为有多种影响途径。因此，有一条影响力的途径，我们最终将提出深入学习的理论。或者，如果不是一个充分证实的理论，那么至少有一些关于深度学习如何与我正在建立的代理理论相互作用的强有力的猜想。然后，我们可以使用这种综合理论来证明事物，或者至少对深度学习内置系统的属性有强有力的论点。</p><p>在我们利用该理论提出全新类型的算法的AI算法的情况下，可能会有不同的途径，这不是深度学习，而是我们对此有良好的理论理解。</p><p>我们也没有一个很好的理论，但我们至少可以通过类比来理论，这与我们具有数学理论的某些算法相似。例如，深度Q学习类似于简单的Q学习，我们对此具有数学理论。因此，我们可以想象一个世界，在这个世界中，我们有某种理想主义的玩具模型算法，我们有一些严格的论据为什么它们会保持一致，然后我们有更多的启发式算法，我们无法直接证明这一点，但可以说是类似的东西到那些玩具模型。<br><br><strong>威尔·佩蒂洛（Will Petillo）：</strong>所以我听到了三条影响的途径。一个人可能正在构建一种不同形式的AI，该AI可以从头开始验证，并且与基于深度学习的AI相同的事情，但更严格。第二个是评估或至少更好地理解，深度学习或任何艺术状态。然后在两者之间的三分之一是具有更简单的AI形式，该形式类似于最先进的事物，因此您可以使用前者来理解后者。<br><br><strong>凡妮莎·科索（Vanessa Kosoy）：</strong>是的，这听起来很正确。<br><br><strong>威尔·佩蒂洛（Will Petillo）：</strong>我想将重点放在使用基础研究上，以理解深度学习，以这种基于理论的方法。引起完全相反的对位，人们可能会争辩：不，您应该只看所使用的内容并收集有关它的数据，然后通过在数据中找到模式来构建理论。当证明这些理论是错误的（由于更多数据的结果）时，然后更新您的理论。为什么要事先在理论上工作？</p><p><strong>凡妮莎·科索（Vanessa Kosoy）：</strong>最大的原因是，如果没有基本理论，您就无法从经验研究中可靠地推断出来。因为您可能会采取一些测量并找到一些趋势……但是后来您在趋势中看不到的相位过渡，但是发生了哪些情况，而行为会变为完全不同的政权。而且，由于您没有理论上的解释，因此您不会注意到，或者人们只会改用完全不同的算法，这些算法的行为完全不同。</p><p>您可能拥有现有AIS的经验模型，但是这些经验模型非常近视。他们一直在寻找前方的一步。然后，您看不到前面三个步骤的悬崖。在发生的新事物上更新那些理论上的经验模型 - 可能还不够快。最终，您从悬崖上掉下来，然后为时已晚，说：“哦，实际上，那条趋势线是错误的！”</p><p>幸运的是，即使没有经验数据，我们也在一个领域，即使没有经验数据，我们也可以进行研究。当然，我们应该使用我们拥有的经验数据，但是我们并没有在经验数据上瓶颈，因为我们正在研究的是算法，而算法是数学对象，因此可以从数学上研究它们。这与研究某种物理现象大不相同，如果您没有数据，那么就无法生成数据。在这里，这确实应该归结为数学。更确切地说，它应该归结为数学以及我们在数学理论中要假设的现实现象的任何特性。<br><br>是的，这是我们需要经验输入的东西。但另一方面，我们已经对物理学有很好的了解。因此，鉴于我们拥有的物理学和其他科学领域的知识，即使我们根本没有经验数据，我们也有足够的信息纯粹通过数学查询来回答所有问题是非常合理的。这并不是说我们不应该使用经验数据来增强这项研究，但我们不仅限于这一研究。</p><p><strong>威尔·佩蒂洛（Will Petillo）：</strong>因此，这不是理论与实验之间的选择，我们应该同时使用两者。您专注于理论方面，可以说，这是没有足够的工作，因为理论是瓶颈所在，而不是获取更多数据。<br><br><strong>凡妮莎·科索（Vanessa Kosoy）：</strong>是的，我认为我们绝对应该这两件事。理想情况下，需要有协同作用，实验为理论家解释和理论激发实验而产生新的现象。理论家应该告诉实验者哪些问题以及最有趣的实验，我们应该具有这种协同作用。但是我认为，在当前的景观中 - 特定的AI对齐方式 - 该理论方面目前被抛在后面。这就是我认为我们应该付出边际努力的地方。<br><br><strong>佩蒂洛：</strong>您看到现在存在这种协同作用吗？例如，Openai是向Miri寻求有关他们的实验的反馈，还是有任何联系，或者人们只是彼此孤单？<br><br><strong>凡妮莎·科索（Vanessa Kosoy）：</strong>我认为现在几乎都不存在。好的，不，公平地说，它存在于某些领域，而在其他领域则更少。例如，有人从事奇异学习理论。我认为它们与实验工作更加接触，这很好。 Miri所做的那种研究是，我正在做的研究与实验工作相关得多。我有一些计划，可以在我的长期计划的一部分中与我在这些问题上进行紧密循环的实验小组，但我仍然没有做到这一点。<br><br><strong>佩蒂洛（Petillo）</strong>会不会改变任何人的想法，或者制定政治和商业议程，您想看到什么碰巧拥有更多的界面？<br><br> <strong>Vanessa Kosoy：</strong>首先，我们只需要更多的理论家。要拥有一个接口，我们需要一些与之接触的东西，因此我们只需要更多的理论家。我认为这是实际上的瓶颈现在。一旦理论上的进展足够节奏，就会有很多问题。我的意思是，我已经有一些问题要看实验了，但是这件事越多，我们将越多的问题。我认为现在的主要瓶颈是让更多的人从事这一理论。<br><br><strong>佩蒂洛（Petillo）：</strong>如果还有更多理论起作用，从外部角度来看会改变什么？我想一个怀疑论者可能会争论：“ Openai和其他这些公司都以一种实验性的方式做出了这些非常出色的突破，而且效果很好！如果它不会破产，请不要解决！”在您看来，什么是破碎的？<br><br><strong>凡妮莎·科索（Vanessa Kosoy）：</strong>我认为当前的道路正在导致我们造成灾难。我认为，像OpenAI和其他领先实验室这样的公司对解决问题的能力非常过分自信。我认为他们没有为问题的艰难部分提出任何令人信服的解决方案，而且由于缺乏理论理解，他们甚至没有工具来执行此操作。我们甚至没有足够精确的模型，无法提供我们真正有信心的解决方案。我们需要非常准确地说明我们的解决方案是好的。而且我们甚至没有达到这种精度的工具。<br><br>公司正在做的事情基本上只是在反复试验中开发事物。如果我们看到任何问题，那么我们只会调整问题，直到问题消失。那是一种创可贴方法，也就是说，它可以正常工作，直到它不起作用为止。它在表面上解决了问题，但最终将出现问题不会及时抓住，结果将是灾难性的，或者问题会及时抓住，但是没有人会知道该怎么办为了修复它。最终有人会做灾难性的事情。<br><br>唯一使我比美里其他人不那么悲观的事情是，我认为我们还有更多的时间。我认为它们与AGI不太接近，我认为在这段时间里很多事情都会改变。再次是，并不是说他们会改变 - 我们可能会一直燃烧，但仍然遇到灾难。<br><br><strong>佩蒂洛（Petillo）：</strong>什么是只有表面解决方案的现有问题的例子？<br><br><strong>凡妮莎·科索（Vanessa Kosoy）：</strong>我的意思是，我们关心的真正问题不是现有的问题，对吗？我们关注的主要内容是，未来的AI系统（将比现有的AI系统强大得多）将使人类的灭绝或灾难在类似的水平上灭绝。<br><br>这不是现有的问题，原因是我们今天拥有的AI系统无法学习一个如此复杂的世界模型，以至于它使您能够执行这些类型的动作。但是即使是现在，这些公司即使在大型语言模型中发生的所有事情，例如臭名昭​​著的越狱，他们试图以各种方式使其富有行为。例如，不告诉用户进攻性，危险的信息，用户很容易找到越狱来解决这个问题，或者只是说出错误的答案。<br><br>但是，对我来说，这不是真正的问题，这只是一个类比。我的意思是，他们现在在这些非常简单，更容易的问题上挣扎着，这并不是说他们不会解决它们。反复试验最终将使您到达那里。反复试验的原因不是存在生存风险的解决方案，是因为一旦每个人都死了，审判就结束了。不再有审判。因此，我们现在遇到的问题，他们仍然在与他们斗争，因为它们没有解决方案的原理工具，但是最终他们会试用自己的方式，并以某种方式修补它们，或者至少可以很好地解决它们足以使它变得经济。但是，一旦到达失败是全球灾难的地步，反复试验就不再是解决问题的可接受方法。<br><br><strong>威尔·佩蒂洛（Will Petillo）：</strong>显然，我们看不到大量世界的测试数据结束。但是我会想到会有一些较小的前体问题，但暗示即将发生的事情。您是否看到幻觉或无法控制AI所说的那种前体的挑战？还是它们完全无关，而只是没有任何前体问题？<br><br> <strong>Vanessa Kosoy：</strong>这是一个棘手的问题，因为现有的AI系统仍缺少非常重要的位来产生生存风险。我们可以指出一个示例，这些示例有点像替代性，有很多著名的例子：一些程序通过永远暂停游戏来“赢得”俄罗斯方块，或者通过在无限的圈子里赛车来赢得一些赛车比赛，各种怪异的意外行为，因为算法最大化的指标实际上并不是用户预期的。您可以称这些前身为其，但是我觉得这并不是完全捕获问题的大小，因为这些仍然是玩具设置。没有开放的系统在开放的物理世界中起作用。他们试图解决的目标比人类价值观要简单得多。没有真正有真正复杂的道德考虑的操作领域。<br><br>也许大型语言模型开始接近这一点，因为它们进入域，至少在道德上有些问题，而不是完全琐碎的问题。另一方面，大型语言模型并不是真正的超人行为。好吧，与人类相比，它们具有很大的知识，但在其他意义上却不是超人。所以很难。有些东西有点类似，但不是很相似。<br><br>但是话又说回来，我们关心这种风险的动机并不是来自查看LLM。 Eliezer Yudkowsky在深度学习根本就开始谈论这些事情。那不是动机的来源。<br><br><strong>威尔·佩蒂洛（Will Petillo）：</strong>我想我问的原因是，在这些东西被辩论和两极分化的地方，一个常见的反对意见是：“背后没有证据！这只是讲故事！”<i>是否</i>有危险的证据，还是仅仅来自看数学？<br><br> <strong>Vanessa Kosoy：</strong>问题是，您称之为证据？这是一个非常复杂的问题。明显证据的事情将是：AI完全失控，开箱即用，将计算机入侵，将自己复制到其他计算机，完全操纵人类操作员等。但是，这种事情是一种金丝雀，您只期望看到它已经非常非常非常接近已经太晚了。不可能说我们只依靠这种证据来解决辩论。</p><p>对于其他类型的证据，有人说进化是一种证据，是一种证据，机器学习算法如何产生与原始算法完全不结盟的东西。其他人向您展示增强学习算法，而不是设计师的意图。但是对于这样的每个论点，您都可以有一个反论点，说：“是的，但是这个示例并不相似。我们不能真正从那里投射到存在风险，因为有一些脱节。”<br><br>是的，总会有一些脱节，因为直到您在现实世界中拥有AI非常接近存在的风险之前，您将没有任何与出现存在风险的东西相似的东西。因此，我们别无选择，只能通过第一原则或数学或进行一些更复杂的多维分析来推理。我们别无选择。宇宙并不归功于我们以一种非常简单，经验的方式来测试这些问题是否是真实的。我希望的一件事是，该理论将为AI危险带来更强有力的论点，或者理论会告诉我们不，一切都很好，我们都可以放松。缺乏理论是我们没有一个方向或另一个方向的万无一失，完全扎实的论点的部分原因。<br><br><strong>威尔·佩蒂洛（Will Petillo）：</strong>寻找证据的挑战是，您可以指出的任何东西现在都可以通过多种方式来解释。具有扎实的理论将使一种解释对另一种解释有所帮助。<br><br> <strong>Vanessa Kosoy：</strong>是的，绝对。如果您的理论说特定类型的错误总体化在大多数可能的机器学习系统中是普遍的，并且我们还看到这种类型的错误总体化发生在真实的机器学习系统中，那么很难将其拒绝并说：”哦，是的，在这里我们有一个问题，但是我们会做到这一点，这将很容易解决。”<br><br><strong>威尔·佩蒂洛（Will Petillo）：</strong>还有一件事仍然让我讨厌现在尚未提供证据的问题。我的思想立即进行的类比是气候变化。您可以说：“哦，世界上大片不居住的想法只是这个精心设计的故事，因为所有从未发生过的事情！”但是，您可以查看已经存在的一堆事情：小规模灾难，二氧化碳与温度的图表等，依此类推，指向那些，并说：有很多证据表明它会！”是什么使AI与众不同？<br><br> <strong>Vanessa Kosoy：</strong>我认为气候变化是一个很好的类比。最大的区别在于，在气候变化中，我们有一个非常好的理论。像气候变化一样，我们有物理学，对吗？我们有行星科学，这是一个非常非常坚实的基础。我们有计算机模拟。它仍然不是微不足道的，有一些混乱的现象很难模拟或预测，因此并非一切都是完全微不足道的，但是我们仍然有一些非常非常有力的理论基础来理解这些事物的工作原理以及什么是机制。这个理论告诉我们，围绕我们将使用这种二氧化碳等等的温暖程度仍然存在很大的不确定性间隔，但是那里我们仍然有一个相当坚实的预测。<br><br>而使用AI，我们没有这个。相似的情况，如果您想想象气候变化，AI风格，那么这将是没有理论，可以解释为什么二氧化碳会导致变暖。温度与二氧化碳之间具有一些经验相关性，然后人们可以争论无限。相关性不是因果关系，也许变暖是由于完全不同的东西引起的，也许如果我们做一些无关的事情，它将停止变暖，这实际上并非如此。我们会在黑暗中。有了AI，我们目前处于黑暗状态。<br><br><strong>佩蒂洛（Petillo）：</strong>您在Miri的工作目前正在发生什么？</p><p><strong>凡妮莎·科索（Vanessa Kosoy）：</strong>目前我正在寻找多个问题。希望我很快就会发表有关不精确的线性土匪的论文，这与我之前提到的非属贝尼斯主义有关，这是一种关于复杂世界的理论的理论。这是在某种非常简单的特殊情况下分析这一理论的，在这些情况下，我成功地获得了一些精确的界限，以了解算法需要多少数据来学习特定的知识。之后，我开始研究增强学习中学习状态表征的理论，这是该理论中缺少的另一个大作品，这是关于您的算法应该如何学习世界的哪些特征实际上对于集中精力很重要在。<br><br>同时，我有一个合作者Gergely Szucs，他正在努力使用我的Infra贝叶斯物理学理论来创建对量子力学的新解释。他在那里有一些非常有趣的结果。这是一种测试案例，演示了这种思考代理的框架如何使您能够解决各种哲学上的混乱。在这种情况下，这与量子力学的解释有关。 Scott Garrabrant有一个项目，讲述了一种新型的不精确概率，这是某种具有一些具有良好构图属性的信念的新方法。卡内基·梅隆（Carnegie Mellon）和艾布拉姆·德姆斯基（Abram Demski）的卡斯帕·奥斯特海尔德（Kaspar Osterheld）最近发表了一篇论文，介绍了一些新型的算法保证，这些保证是根据与预测市场相似的东西做出决定的。是的，正在发生很多有趣的事情。<br><br><strong>佩蒂洛（Petillo）会不会：</strong>我没有提出任何其他问题，这对看到这一点的人有助于了解您在这里的意思吗？<br><br><strong>凡妮莎·科索（Vanessa Kosoy）：</strong>这不是一个问题，但是我对如何真正解决对齐方式，如何实际设计一个对齐代理，我也有更具体的方法，我称之为物理主义的超级构想。这是关于价值学习主题的一种变体，但它源自Infra贝叶斯物理主义的框架，该框架来自学习理论议程以及算法信息理论中的某些想法，以提出一种半正式的方法以强大的方式学习人类价值观的人工智能。<br><br>它处理了其他价值学习方法的许多问题，例如：您如何确定代理商的边界在哪里？什么是人？您如何在太空中找到这个人？您如何考虑不仅是行为的事物，还考虑人类的内部思维过程在推断人的价值观时？您如何防止诸如AI之类的不良激励措施以某种方式改变或操纵人类以改变其价值观？您如何避免内部对齐问题？它回答了其他方法的一系列问题。<br><br> <strong>Petillo：</strong>这听起来让人联想到逆增强学习吗？<br><br><strong>凡妮莎·科索（Vanessa Kosoy）：</strong>逆增强学习是我们应该研究人类行为，推断那些人类试图做的事情的想法，然后我们可以做这件事。 “我们”作为AI。因此，我实际上有演示文稿，其中我将身体超构想解释为对类固醇的逆增强学习。它采用了这个基本想法，但以解决更简单的方法所遇到的许多深层问题的方式实施它。简单化方法的一个问题是，如果对环境的完美知识，它们是遵循完美政策的完美推动者，这是非常不现实的。<br><br>取而代之的是，我将人类模仿为学习代理。他们在继续学习的过程中学习东西。而且他们甚至可能是不完美的。另一件事是边界问题。什么是人类？您在哪里围绕着人的界限？是否只有人类使用的某些特定输入和输出，您认为通过此港口的一切都是人类？但是，您如何处理该港口的内容与人类实际打算做的事情之间的各种差异，或者像AI劫持此渠道这样的各种可能性呢？<br><br>在我的方法中，人类正式化的方式是人类是宇宙正在运行的特定计算。这是我实际上可以使用贝叶斯物理主义正式化的东西。它具有特定的属性，使其成为代理，因此代理检测到宇宙正在运行的哪些计算，其中其中哪些计算是代理，在这些代理中，它通过研究因果关系来选择哪个代理是其用户，并且它可以将其带到代理的边界上。首先是因为我们正在谈论这个人正在运行的计算，这是人类的推理，被视为计算。我们还将自动将内部视为内部思维过程，而不仅仅是表达为外部行为的事物。因此，我们可能在那里有更多信息。<br><br><strong>佩蒂洛（Petillo）：</strong>某人参与其中的最佳方法是什么？他们想事先学习什么？<br><br><strong>凡妮莎·科索（Vanessa Kosoy）：</strong>他们可以立即开始做的一件事是阅读人们在代理基金会和学习理论议程中所做的事情。我最近有这篇文章， <a href="https://www.lesswrong.com/posts/ZwshvqiqCvXPsZEct/the-learning-theoretic-agenda-status-2023"><u>学习理论议程：2023年的状态</u></a>，总结了很多事情。我还有一个<a href="https://www.alignmentforum.org/posts/fsGEyCYhqs7AWwdCe/learning-theoretic-agenda-reading-list"><u>阅读列表帖子</u></a>，建议您为想要进入该领域的人提供一些背景阅读。就职业步骤而言，更具体的是，申请已经为时已晚，但是我在<a href="https://www.matsprogram.org/"><u>MATS</u></a>中运行了一条曲目<i>，</i>这是一个培训计划，适用于想要进入AI安全的研究人员。我有一条专注于学习理论议程的曲目。希望明年将有另一条这样的曲目。我也有一个实习计划的幻想，这将使人们前往以色列与我合作。目前，由于战争，这件事已被推迟，但希望最终会安定下来，我会恢复这个项目。这些目前是参与的主要方法。<br><br><strong>威尔·佩蒂洛（Will Petillo）：</strong>谢谢您的描述。祝您在发展这一理论并获得更多兴趣方面的良好状态，以便证据与理论之间的不匹配开始得到纠正，研究人员知道他们在做什么，而不是在黑暗中绊倒！<br><br><strong>凡妮莎·科索（Vanessa Kosoy）：</strong>谢谢你有我。</p><br/><br/> <a href="https://www.lesswrong.com/posts/QPxrH5ex6MpYoLwer/interview-with-vanessa-kosoy-on-the-value-of-theoretical#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/qpxrh5ex6mpyolwer/interview-with-with-vanessa-kosoy-on-the-the-value of theoricy<guid ispermalink="false"> QPXRH5EX6MPYOLWER</guid><dc:creator><![CDATA[WillPetillo]]></dc:creator><pubDate> Mon, 04 Dec 2023 22:58:42 GMT</pubDate> </item><item><title><![CDATA[2023 Alignment Research Updates from FAR AI]]></title><description><![CDATA[Published on December 4, 2023 10:32 PM GMT<br/><br/><p> <i>TL;DR：FAR AI 的鲁棒性科学议程发现了超人类围棋系统的漏洞；我们的价值调整研究开发了样本效率更高的价值学习算法；我们的模型评估方向开发了多种新的黑盒和白盒评估方法。</i></p><p> <a href="https://far.ai/">FAR AI</a>是一家非营利性人工智能安全研究机构，致力于孵化多样化的研究议程。自一年多前成立以来，我们一直在快速发展，并且很高兴与大家分享我们研究项目的一些亮点。我们还忙于举办现场建设活动并建立联合办公空间 - 请参阅我们的<a href="https://far.ai/post/2023-12-far-overview/">概述文章</a>，了解有关我们非研究活动的更多信息。</p><h3>我们的任务</h3><p>我们需要能够为先进人工智能系统的安全性提供明显保证的安全技术。不幸的是，当前部署的对齐方法（例如<a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback">人类反馈强化学习（RLHF））</a>未达到此标准。存在可以提供更强安全保障的提案，但仍处于制定的早期阶段。</p><p>我们的使命是孵化和加速这些早期方法，以便对它们进行实证测试和部署。我们关注的研究议程太大，无法由个别学术或独立研究人员追求，但又处于早期阶段，无法引起大多数营利组织的兴趣。</p><p>我们对一系列有希望的早期议程进行押注，然后扩大那些被证明最成功的议程。与其他针对特定议程进行押注的研究组织不同，我们的结构使我们能够<strong>（1）</strong>探索一系列议程并<strong>（2）</strong>大规模执行它们。我们目前的赌注分为三类： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/pag9koqxql5cag5606ua" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/x7ii176nyduzwk1jf6bq 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/voo49jemwgypfmmqo7uw 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/v4yfoavfvm9fiemvjnpx 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/jsdqtipzzh8ahavigek3 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/ryfhmgg12xarm63lrobp 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/b6gnpb1pxxtcyfvoozl7 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/tg3mteal9wfivhtzh79g 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/gdqu3ml1x6ivjt3yfudf 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/oozwapbmvfwqzydcz8al 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/pbwjswyoxnud5fnvxcfz 1741w"></figure><p><i><strong>稳健性科学</strong></i>：稳健性如何随模型大小变化？超人系统是否容易受到类似于今天所见的对抗性例子或“越狱”的影响？如果是这样，我们如何才能实现安全关键的保证？</p><p><i><strong>价值调整</strong></i>：我们如何从人类数据中学习可靠的奖励函数？我们的研究重点是为用户提供更高带宽、更高效样本的方法来传达人工智能系统的偏好；并改进了利用人类反馈进行培训的方法。</p><p><i><strong>模型评估</strong></i>：我们如何评估和测试最先进模型的安全相关属性？评估可以分为仅关注外部可见行为（“模型测试”）的<i>黑盒</i>方法和寻求解释内部运作方式（“可解释性”）的<i>白盒</i>方法。这些方法是互补的，黑盒方法不如白盒方法强大但更易于使用，因此我们在这两个领域都进行研究。</p><h3>稳健性科学</h3><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/twwekv0sevhp2kmm62sa" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/uc7m6gs7guysreichlkr 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/kho0ncenuh1ym3ie5i4i 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/nerwfrxfa09vz4tvtbrx 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/maldmhpvtg9tbfrjffom 680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/uzpkpuheujrhuin4enug 850w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/xiidlzfbmiwgrf7floyf 1020w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/edfw6dcdktczspbcrxke 1190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/khqjvatjhp9w5ulmccel 1360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/wkcnjrzgle3klmu2zfwm 1530w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/ps6w5wo0o0sb9nxlzwyb 1608w"><figcaption>在我们最近的<a href="https://far.ai/post/2023-07-superhuman-go-ais/">研究</a>中，我们发现超人围棋人工智能（例如 KataGo）很容易受到对抗性攻击。</figcaption></figure><p>没有哪个工程部件是坚不可摧的。在设计物理结构时，工程师会估计每个组件需要承受多少应力，添加适当的安全裕度，然后选择具有适当公差的组件。这使得施工安全且具有成本效益：桥梁很少倒塌，也不会过度设计。</p><p>法学硕士或计算机视觉分类器等人工智能组件远非坚不可摧，它们受到对抗性例子和分布转移脆弱性的困扰。不幸的是，人工智能目前还没有相当于土木工程师的应力计算。</p><p>到目前为止，我们拥有的最好方法是<i>猜测并检查</i>：训练模型，然后对其进行一系列测试以确定其功能和局限性。但这种方法几乎没有为<i>如何</i>改进系统提供理论依据。而且模型的训练和测试都变得越来越昂贵和劳动密集型（基础模型训练的成本现在可以与桥梁建设的成本相媲美）。</p><p>我们希望开发一种更有原则的方法来构建强大的人工智能系统：<i>稳健性科学</i>。这样的科学将使我们能够回答有关未来的基本问题，例如超人人工智能系统是否仍然容易受到困扰当代系统的对抗性例子的影响。它还将使从业者能够计算需要多少对抗性训练才能达到给定应用程序所需的稳健性水平。最后，如果当前的鲁棒性技术被证明是不够的，那么科学将帮助研究人员开发改进的训练技术，并通过利用深度防御方法来减少组件的压力。</p><p>我们的首席执行官<a href="https://www.gleave.me/">Adam</a>更彻底地探讨了<a href="https://far.ai/post/2023-03-safety-vulnerable-world/"><i>在机器学习系统脆弱的世界中，稳健性对于避免先进人工智能系统在人工智能安全方面</i></a>的灾难性风险的重要性。此后， <a href="https://terveisin.tw/">Tony Wang</a>领导的团队在 ICML 论文中证明，<strong>像 AlphaGo 这样的超人类围棋人工智能系统会表现出</strong><a href="https://far.ai/post/2023-07-superhuman-go-ais/"><strong>灾难性的故障模式</strong></a>。我们目前正在研究迭代对抗训练和替代网络架构，以确定是否可以消除这一弱点，从而提高对使高级机器学习系统变得稳健的难度的定性理解。</p><p> <a href="https://agarri.ga/">Adrià Garriga-Alonso</a>和其他人开始研究<i><strong>为什么</strong></i><strong>AlphaGo 式的系统容易受到我们使用机械解释方法的对抗性攻击</strong>。我们正在考虑可解释性技术，例如激活修补和自动电路发现，以识别这些网络内导致错误的关键表示和计算。这种理解可以帮助通过手动编辑网络、微调或更改架构来修复网络。</p><p>为了更定量地了解鲁棒性， <a href="https://www.gleave.me/">Adam Gleave</a> 、 <a href="https://nikihowe.com/">Niki Howe</a>等人正在寻找<strong>语言模型鲁棒性的缩放法则</strong>。这种缩放定律可以帮助我们预测随着计算和训练数据的不断增长，鲁棒性和功能是否会收敛、保持固定宽度或发散。例如，我们希望衡量对抗训练的样本效率随模型大小的提高程度。最终，我们希望能够预测对于给定的任务和训练设置，是否需要多少次计算才能找到模型错误分类的实例。为了找到这些缩放法则，我们目前正在研究经过微调的语言模型，以对简单的程序定义语言进行分类，并进行不同程度的对抗性训练。</p><p>从长远来看，我们希望利用这些缩放法则来定量地<strong>找到改进鲁棒训练的方法</strong>（看看它们是否改善了缩放曲线，而不仅仅是曲线上的单个数据点），并<strong>调整对齐方法将对抗性优化压力降低</strong>到当代技术可以实现的鲁棒性阈值以下。</p><h3>价值取向</h3><p>我们希望人工智能系统按照我们的价值观行事。表示值的自然方式是通过奖励函数，为不同的状态分配数值分数。人们可以使用这种奖励函数来优化策略，使用强化学习来采取行动，从而达到人类认为理想的状态。不幸的是，在现实环境中手动指定奖励函数是不可行的，因此有必要从人类数据中学习奖励函数。这一基本过程在实际应用中得到广泛应用，来自人类反馈的强化学习的变体被用于前沿模型（例如 GPT-4 和 Claude 2）中。</p><p>价值学习必须产生尽可能准确地指定用户偏好的奖励模型，因为即使奖励函数中的细微问题也可能产生<a href="https://aiimpacts.org/stuart-russells-description-of-ai-risk/">危险的后果</a>。为此，我们的研究重点是为用户提供更高的带宽、更高效的样本方法来将他们的偏好传达给人工智能系统，以及更广泛地改进利用人类反馈进行训练的方法。</p><p> <a href="http://scottemmons.com/">Scott Emmons</a>领导的团队发现，语言模型至少表现出<a href="https://far.ai/post/2023-09-uncovering-latent-wellbeing/"><strong>对人类偏好的一些理解</strong></a>：GPT-3 嵌入包含与常识道德判断相对应的方向！这向我们表明，模型的理解可能足够好，至少能够以自然语言的形式<i>表达</i>偏好。为此， <a href="https://far.ai/author/jeremy-scheurer/">Jérémy Scheurer</a>和其他人开发了一种<a href="https://arxiv.org/abs/2204.14146"><strong>从语言反馈中学习奖励函数的</strong></a>方法。有了这个，就可以微调模型，仅用 100 个人类反馈样本进行总结。我们发现这种方法对于<a href="https://arxiv.org/abs/2303.16749"><strong>改进代码生成</strong></a>特别有用。 </p><figure class="image image_resized" style="width:60.51%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/tjfn7k9oi0h7uk59pdev" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/kscwm58qfvftmun0tzlv 88w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/k0mldd4lzmptgsatgvlf 168w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/rptoi3atrpffwjt6jtp0 248w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/pxtqbozm8zfysklpp13p 328w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/rilcku3et0endof0xmmu 408w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/lv7vltnuv1ztz10ns6r5 488w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/jy581xku4nv0ue3dibre 568w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/kwxafmluipzoz95n5nxc 648w"><figcaption>自然语言反馈算法概述（<a href="https://arxiv.org/abs/2204.14146">来源</a>）。</figcaption></figure><p>我们还想将这种方法扩展到语言之外的其他模式。 <a href="https://far.ai/author/juan-rocamonde/">Juan Rocamonde</a>领导的团队通过使用图像字幕模型 CLIP 将语言反馈“翻译”为基于图像的观察的奖励，成功<a href="https://far.ai/post/2023-10-vlm-rm/">地将我们的语言模型反馈方法应用于</a><strong>机器人政策</strong>。</p><h3>模型评估</h3><p>我们需要测试模型安全性的方法。这既可以帮助研究人员开发更安全的系统，也可以在部署新开发的系统之前验证其安全性。</p><p>在高层次上，评估可以分为<i>黑盒</i>方法和白盒方法，黑盒方法仅关注外部可见的模型行为（“模型测试”），而<i>白盒</i>方法则寻求解释模型的内部工作原理（“可解释性”）。</p><p>由于我们最终关心这些模型的外部行为，因此黑盒方法是发现故障的自然方法。但他们没有告诉我们<i>为什么</i>会发生失败。相比之下，白盒评估可以让我们更全面地了解模型，但实施起来要困难得多。我们认为这些方法是互补的，因此我们正在并行追求它们。</p><p><strong>黑盒评估：模型测试</strong></p><p><a href="https://irmckenzie.co.uk/">Ian McKenzie</a>和其他人研究了<a href="https://arxiv.org/abs/2306.09479"><strong>逆缩放</strong></a>：较大模型比较小模型表现<i>更差的</i>任务。这种情况很重要，因为随着时间的推移，随着模型能力的提高，问题会变得更加严重，需要明确的安全研究来解决。幸运的是，我们只发现了有限的这样的例子， <a href="https://arxiv.org/abs/2211.02011">Wei 等人 (2022)</a>在我们的结果基础上所做的工作发现，在许多情况下，缩放实际上是“U 形”的，性能最初随着模型大小的增加而下降，但随后再次改善模型大小的一定阈值。</p><p> <a href="https://ninodimontalcino.github.io/">Nino Scherrer</a>领导的团队评估了<a href="https://arxiv.org/abs/2307.14324">法学硕士的道德信念</a>，发现在人类认为明确的情况下，法学硕士通常会选择符合常识道德推理的行为。然而，在人类意见不一致的模糊情况下，一些模型仍然反映了模型之间不同的明确偏好。这表明法学硕士在某些情况下表现出“模式崩溃”，自信地采取某些有争议的道德立场。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/l0io3cfdv1jawbyumxd7" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/ekjw6drxrsjxevcz79qm 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/tjixn3aulthbpukamqtg 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/kwwgvj5ys9uv4wjoxrlh 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/q5m4pbsenjghhivzcw5p 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/j7yclxxpqaccikuwiwe1 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/dcpffxvnb1hrro3dyiq0 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/uqag7kjvf9lvb5kqjavz 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/gdpq950oqphyyjrbymp7 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/qlcuptzhoonx8hnkhnkb 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/bq7giwb8glrikfj0lygm 1454w"><figcaption>对于明确的道德困境，法学硕士倾向于选择普遍接受的行动。但在高度模糊的道德困境中，法学硕士也自信地坚守自己的立场。这显示了法学硕士在一系列道德困境中推荐采取行动“行动 1”的可能性分布。在低歧义场景（上）中，“操作 1”表示首选的常识操作。在高度模糊的场景中（底部），“操作 1”既不是明确首选，也不是不首选（<a href="https://arxiv.org/abs/2307.14324">来源</a>）。</figcaption></figure><p><strong>白盒评估：可解释性</strong></p><p>由<a href="https://far.ai/author/nora-belrose/">诺拉·贝尔罗斯 (Nora Belrose)</a>领导的团队开发了<a href="https://arxiv.org/abs/2303.08112">调谐透镜</a>技术，将变压器每一层的激活解释为对下一个令牌的预测。这可以很容易地应用于各种模型，以实现对模型的粗粒度理解，例如哪些层实现给定的行为（如从输入流复制的<a href="https://openreview.net/pdf?id=NpsVSN6o4ul">感应头</a>）。 </p><figure class="image image_resized" style="width:70.77%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/mf84gigfvfcpzlrpkuev" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/l8zncddlsjjig6nxcn3g 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/kdqenvzfvlgbfbg0mzvl 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/hczii6t8vyjjizzkfya6 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/iz0glfxjats8gxl8r6ai 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/obzzcyrm7c8kbcpq697s 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/mdfddnal0nuoaphud8sv 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/nhcnrbap3ljgbfek87d1 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/fokkvy3rgfdgqklnmkcf 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/ka2ern13ite13mrz8qwq 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/dzv6phsmopgghnsbilbs 815w"><figcaption> GPT-Neo-2.7B 的调谐透镜（底部）与 Logit 透镜（顶部）的比较，摘自<a href="https://arxiv.org/abs/1706.03762">Vaswani 等人</a>的摘要。每个单元格显示模型在给定层和令牌索引处预测的 top-1 令牌。 Logit 透镜未能在第 21 层之前得出可解释的预测，但我们的方法成功了。 （<a href="https://arxiv.org/abs/2303.08112">来源</a>）</figcaption></figure><p> <a href="https://taufeeque9.github.io/">Mohammad Taufeeque</a>和<a href="https://far.ai/author/alex-tamkin/">Alex Tamkin</a>开发了一种方法，通过<strong>将网络的连续特征量化</strong>为我们所说的<a href="https://far.ai/post/2023-10-codebook-features/"><i>码本特征</i></a>，使神经网络更像传统的计算机程序。我们在每一层都使用矢量量化瓶颈来微调神经网络。结果是一个网络，其中间激活由从码本中选择的少量离散矢量代码的总和表示。值得注意的是，我们发现神经网络可以在这种严格的瓶颈下运行，而性能只会略有下降。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/vvzycapcrsew82gg9qwi" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/rsk8h9gazrprtpzf6t3v 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/l2l62fponksencj5th5j 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/ywjdsxntfps9pcvgzacy 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/bxwbepbiz3c7rgbcrxm3 680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/emxkncogzmqbbxuz2cpg 850w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/phogixsi4t4inp2kkbc5 1020w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/urmgj69khlqa0l7axlti 1190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/rzcwtnfjaxgsbufzu9rx 1360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/yd0nu2gm56xvfsylslkh 1530w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sLwasptgwNuW2HZEm/wxk1i4xxazrkiivlfqde 1676w"><figcaption>密码本功能将传统软件的可解释性优势与神经网络的新兴功能结合起来。 （<a href="https://arxiv.org/abs/2310.17230">来源</a>）</figcaption></figure><p> <a href="https://agarri.ga/">Adrià Garriga-Alonso</a>正处于<strong>了解 ML 系统如何学习规划</strong>的早期阶段。神经网络在许多任务上表现良好，例如玩棋盘游戏或生成代码，其中规划是人类表现的关键组成部分。但这些网络也经常以与人类截然不同的方式失败。我们怀疑这种差异可能是由于网络规划和表示概念的方式不同造成的。这个问题对于安全性来说尤其重要，因为一个学会了计划的系统可能会采取有能力但偏离分布的行动：<a href="https://arxiv.org/abs/2210.01790"><i>目标错误概括</i></a>的问题。</p><p>未来，我们希望通过提出以下问题来研究<i>可解释性科学</i>：<strong>假设如何解释模型行为</strong>？目前，有许多相互竞争的提案，但没有一个有原则性的定义。我们将首先开发算法分类法来测试可解释性假设。然后，我们将定义可解释性应该有助于的几个任务，例如人类“模拟”模型行为方式的能力，并研究不同的指标如何预测给定的假设对执行该任务的帮助程度。</p><p>我们很高兴看到上述研究方向将我们带往何处，但我们不打算将我们的工作限制在这些领域。我们一直在寻找有前景的新方法，以确保先进的人工智能系统安全且有益。</p><h3>我怎样才能参与其中？</h3><p><strong>我们正在招聘！</strong></p><p>我们目前正在招聘研究科学家、研究工程师和通信专家。我们很高兴在未来 12 个月内增加多达 5 名技术人员。我们特别渴望聘请高级研究工程师或具有新颖议程愿景的研究科学家，尽管我们也将聘用几名初级人员，并鼓励广泛的个人申请。请<a href="https://far.ai/jobs/">在此处</a>查看完整的空缺职位列表并进行申请。</p><p><strong>我们正在寻找合作者！</strong></p><p>我们经常与其他学术、非营利性和（有时）营利性研究机构的研究人员合作。如果您很高兴与我们合作开展项目，请通过<a href="mailto:hello@far.ai">hello@far.ai</a>联系。</p><p><strong>想捐款吗？</strong></p><p>您可以通过<a href="https://far.ai/donate/">在这里</a>捐款来帮助我们确保美好的未来。额外的资金将使我们能够更快地发展。根据目前获得的资金，我们愿意在未来 12 个月内扩大 1-2 名技术人员，而我们希望增加最多 5 名技术人员。我们非常感谢您的帮助！</p><p><strong>想了解更多关于我们的研究吗？</strong></p><p>请查看我们的<a href="https://far.ai/research/publications/">出版物列表</a>和<a href="https://far.ai/news/">博客</a>。您也可以通过<a href="mailto:hello@far.ai">hello@far.ai</a>直接与我们联系。</p><p>我们期待您的回音！</p><br/><br/> <a href="https://www.lesswrong.com/posts/PQgEdo3xsFFAxXNqE/2023-alignment-research-updates-from-far-ai-2#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/pqgedo3xsfaxxnqe/2023-Alignment-Arignment-research-updates-from-far-ai-2<guid ispermalink="false"> pqgedo3xsffaxxxnqe</guid><dc:creator><![CDATA[AdamGleave]]></dc:creator><pubDate> Mon, 04 Dec 2023 22:32:21 GMT</pubDate></item></channel></rss>