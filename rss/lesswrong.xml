<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 8 月 23 日星期三 14:10:20 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[WHAT IT IS and WHAT TO DO NEXT (a four-volume inquiry into the nature of understanding reality)]]></title><description><![CDATA[Published on August 23, 2023 2:04 PM GMT<br/><br/><p>你好！我以前在LW上发帖的频率比较高；从那时起，我就远离了社交媒体（除其他外），这样我就可以花更多的时间进行长篇写作。</p><p> 2022 年和 2023 年初，我完成了一本四卷本的关于理解现实过程的探究，名为<i>《它是什么》和《下一步该做什么》</i> 。该项目最初作为由<a href="https://alanlastufka.com/"><u>Alan Lastufka</u></a>设计并通过<a href="https://shortwavepublishing.com/"><u>Shortwave Publishing</u></a>出版的一系列印刷杂志出售。该项目的全文（在印刷版的基础上略有修改）现在可以免费在线阅读：</p><ul><li><a href="https://www.nicoledieker.com/what-it-is-and-what-to-do-next-1/"><u>第一卷：掉进兔子洞</u></a></li><li><a href="https://www.nicoledieker.com/what-it-is-and-what-to-do-next-2/"><u>第二卷：是这样吗？</u></a></li><li><a href="https://www.nicoledieker.com/what-it-is-and-what-to-do-next-3/"><u>第三卷：D4、C4</u></a></li><li><a href="https://www.nicoledieker.com/what-it-is-and-what-to-do-next-4/"><u>第 4 卷：没有一个显示器处于睡眠状态</u></a></li></ul><p>我不会回来查看您的回复，原因如果您阅读第 2 卷，您就会清楚地了解。如果您愿意，请讨论，如果您不喜欢，请投反对票，如果您有想要直接发送的想法或问题对我来说，我是 nicole@nicoledieker.com。</p><br/><br/> <a href="https://www.lesswrong.com/posts/pa9xRbgxqcuiMAmNB/what-it-is-and-what-to-do-next-a-four-volume-inquiry-into#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/pa9xRbgxqcuiMAmNB/what-it-is-and-what-to-do-next-a-four-volume-inquiry-into<guid ispermalink="false"> pa9xRbgxqcuiMAmNB</guid><dc:creator><![CDATA[Nicole Dieker]]></dc:creator><pubDate> Wed, 23 Aug 2023 14:04:07 GMT</pubDate> </item><item><title><![CDATA[Why Is No One Trying To Align Profit Incentives With Alignment Research?]]></title><description><![CDATA[Published on August 23, 2023 1:16 PM GMT<br/><br/><p>大量的协调工作似乎都受到资源的限制。许多资助者都谈到了他们如何只能向他们认为有前途的一小部分项目和工作提供资助。许多研究人员还获得了他们在营利性部门所能赚取的一小部分（Netflix 最近为 ML 职位提供了 90 万美元）。如果不依赖于继续接受非营利组织的捐赠，招聘人才、培训和雇用的流程可能会大大加快。</p><h3></h3><h3><strong>可能的想法</strong></h3><p></p><h2>人工智能审计公司</h2><p>我们已经在 ARC 的 GPT4 评估中看到了一些这样的情况，但为什么没有更多这样的情况呢？许多公司将/正在训练自己的模型，或者以超出预期的方式使用现有模型。即使从非尖端模型开始也可以提供洞察力并培训人们拥有适当的安全心态和理解来审计更大的模型。此外，人们一直在推动监管并使之成为必需的做法。该法规能否成为法律可能取决于现有的基础设施。如果我们希望这些审计团队尽可能有用，而不仅仅是满足政府要求，那么现在就采取行动是有意义的。对于一家已经在审计模型方面建立了声誉的公司来说，生存问题也会得到更严肃的对待。</p><p><strong>评估报告</strong></p><p>公司不希望看到他们的模型做一些非预期的事情（例如，向人们提供信用卡信息，正如最近所演示的那样）。随着时间的推移，公司将希望以某种方式展示他们的模型已经过严格的测试。许多人可能都想要涵盖大量不同漏洞的审计报告。</p><p><strong>红队</strong></p><p>越狱是一种常见的做法，模型发布后很多人都会这样做。就像评估报告一样，许多人会想要一个单独的实体来对他们的模型进行红队，就像许多科技公司聘请外部网络安全公司来提供类似的服务一样。</p><p></p><h2>对齐即服务</h2><p>这可以带来新的人才和激励措施，以建立更好的理解和人才来处理一致性。这些服务的规模将较小，并且不会解决一些对齐的“核心问题”，但可能会提供解决难题的碎片。解决对齐可能不是一个大问题，但实际上是一千个小问题。这提供了市场反馈，即更好的方法比更差的方法更容易成功。随着时间的推移，这可能会引导我们真正提出可扩展的解决方案。</p><p></p><p><strong>提供更好地调整模型的程序</strong></p><p>许多公司可能不知道如何让他们的模型做他们想要做的事情，他们会需要帮助来做到这一点。这可以从帮助公司进行基本的 RLHF 开始，但可能会发展到开发更好的方法。更好的方法将被竞争性的校准提供商采用，他们也会寻找更好的方法来提供。</p><p><strong>警告</strong>：可能会加速表面对齐，但只会进一步产生错误的安全感。</p><p></p><h2>作为产品的一致性</h2><p>这不是理想的方法，但仍然值得考虑。制定新的专有策略来调整模型，但不要向公众发布。相反，向公司展示这些新策略的效果，并将该策略作为产品出售给他们。这可能涉及保密协议，这就是为什么它不是一个理想的方法。但 NDA 下现有的协调策略总比没有策略好。</p><p></p><h2>机械解释即服务</h2><p>这也许还无法实现，但可能是时候了。许多人希望更好地了解他们的模型是如何运作的。机械可解释性研究人员团队可以访问该模型，并深入了解其架构及其实际功能，并将其发现的完整报告作为服务提供。这也可能引导 Mech Interp 转向具有实际预测价值的方法。</p><p><strong>警告</strong>：我不太相信 Mech Interp 对安全有用，但缺点是它可能对功能有用。</p><p></p><h2>治理咨询即服务</h2><p>目前，许多政治家和政策制定者都对他们缺乏技术了解的问题感到不知所措。咨询服务将为他们提供专业知识和安全理解，以提供实际有用的政策建议。目前的情况似乎是让时间已经严重受限的专家免费获得他们的建议。我认为很多人会为这项服务付费，因为存在立法需求，而且他们不了解自己这样做。</p><p></p><h2>对齐培训即服务</h2><p>许多公司可能都希望对目前在人工智能公司工作的员工进行培训，让他们了解安全问题、调整策略和其他问题。独立公司可以培训员工更好地理解许多人可能不习惯处理的概念。</p><p></p><h2>未来捐赠基金</h2><p>这是与正常想法相距最远的一个，但如果有更多的人尝试破解这个问题的解决方案，我会很高兴。最大的问题是比对研究的价值存在时间延迟。这个解决方案可能类似于未来股权合约的承诺。那些从事研究的人将获得该基金承诺的未来份额，投资者也是如此。使用捐赠基金资助的任何项目的公司将签署类似“未来回报承诺”的内容，将使用该策略的任何模型的回报份额委托给该基金。这样，那些同样致力于协调策略但工作机会只有 5% 的人仍然可以获得工作报酬。那些致力于工作机会较高的策略的人将获得更大的份额。受托人将是高度可信且对人工智能有深刻见解的社区成员。</p><p></p><p>如果您有兴趣在这些努力中取得进展，请随时给我留言。我曾在网络安全领域工作过，因此我对此类公司的审计流程通常如何运作有很好的了解。</p><p>如果您对其中一些方法有任何不同意见（我相信有些人确实如此），请随时告诉我为什么我在评论中错了。</p><br/><br/> <a href="https://www.lesswrong.com/posts/XnAZHCi5QH58WcrkX/why-is-no-one-trying-to-align-profit-incentives-with#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/XnAZHCi5QH58WcrkX/why-is-no-one-trying-to-align-profit-incentives-with<guid ispermalink="false"> XnAZHCi5QH58WcrkX</guid><dc:creator><![CDATA[Prometheus]]></dc:creator><pubDate> Wed, 23 Aug 2023 13:16:42 GMT</pubDate> </item><item><title><![CDATA[Exploring the Responsible Path to AI Research in the Philippines]]></title><description><![CDATA[Published on August 23, 2023 8:44 AM GMT<br/><br/><h3><strong>介绍</strong></h3><p>人工智能 (AI) 的变革潜力正在重塑我们的世界，既带来了激动人心的机遇，也带来了深刻的挑战。在菲律宾，我和 Dominic Ligot（创始人兼人工智能专家、传播者） <span class="footnote-reference" role="doc-noteref" id="fnrefgdz3m8hstr8"><sup><a href="#fngdz3m8hstr8">[1]</a></sup></span>深入研究了人工智能的可能性，将这项技术融入我们独特的文化结构可以释放指数级的生产力。这篇文章探讨了我们（作为一个国家）如何利用人工智能来增强我们的当地社区，同时又不失去我们独特的身份。带着我们共同的迷恋作为火花，我将在了解人工智能复杂性的必要性以及谨慎进行和坚持一致性研究的必要性的指导下，研究人工智能的更广泛的影响<span class="footnote-reference" role="doc-noteref" id="fnref4w360g923mp"><sup><a href="#fn4w360g923mp">[2]</a></sup></span> 。</p><p></p><h3><strong>变革性技术和人工智能研究</strong></h3><p><i>人工智能的变革潜力</i></p><p>人工智能是一项变革性技术，有潜力在未来十年重塑我们的世界。如果不能理解和整合人工智能，一个国家可能会在快速变化的环境中落后。</p><p><i>技术变革的历史先行</i></p><p>技术进步推动了重大变革。无论是通过尖端物理学在战争中的应用还是新科学领域的发现，技术创新往往导致人类历史上的关键时刻。</p><p><i>人工智能研究的复杂性和紧迫性</i></p><p>人工智能研究既不简单，概念上也不简单。该领域的复杂性凸显了深入了解该领域的重要性。虽然掌握人工智能的道路可能看起来令人畏惧甚至疯狂，但风险太大，不能自满。</p><p> <i>AI研究的必然方向</i></p><p>目前的情况让我们别无选择，只能拥抱人工智能研究。这不仅仅是一个选择；这是我们必须采取的重要方向，以确保我们在人工智能日益塑造的未来中生存。问题不在于我们是否应该进行人工智能研究，而在于我们如何才能最有效、最负责任地开展人工智能研究。</p><p>在探索了人工智能的巨大变革力量及其历史相似之处之后，有必要考虑这个复杂领域今天给我们带来的挑战和前景。</p><p></p><h3><strong>优点和缺点</strong></h3><p><i>人工智能研究的挑战和不确定性</i></p><p>目前的人工智能研究更像是炼金术而不是数学。我们仍然缺乏关于可以注入模型的数据可塑性的正式理论，这使得我们对数据如何分布到各个部分（例如令牌或层）的理解不确定。这些分布的转变影响着技术如何以普遍的方式做出反应。尽管缺乏形式化的数学方法，但不确定性不应阻止我们对研究的追求。</p><p><i>项目失败统计</i></p><p>项目失败的概率约为 65%。 <span class="footnote-reference" role="doc-noteref" id="fnrefrgyrt2chqg"><sup><a href="#fnrgyrt2chqg">[3]</a></sup></span>虽然这是一个令人沮丧的统计数据，但它提醒我们，如果处理不当，我们的资源可能会造成损失。某些行为可能会产生比解决的问题更多的问题，这强调了在人工智能研究中准确识别方法和概念框架的重要性。仔细规划可以避免潜在的损失和意外后果。</p><p><i>人工智能技术的前景光明</i></p><p>人工智能技术的潜在好处简直令人震惊。利用人工智能解决当地生产力问题是当务之急，它可能是我们需要的催化剂。创新新方法来改善经济和个人生活可能意义重大。然而，实现这些好处需要优先考虑协调工作。在部署技术之前确保严格考虑人类福祉是不容谈判的。</p><p>尽管人工智能研究的优势令人惊讶，但其不确定性和潜在陷阱需要仔细研究。让我们探讨一下人工智能研究中谨慎、考虑和协调的迫切需要。</p><p></p><h3><strong>人工智能研究的利害关系：呼吁考虑和谨慎</strong></h3><p><i>承认复杂性：个人反思</i></p><p>这是我第一次思考这些概念，我不得不以真诚和勤奋的态度来对待它们。为人工智能建立一个负责任的研究方向的紧迫性是显而易见的，特别是针对广大且多样化的人口。如果执行得当，效益可以成倍增加。</p><p><i>机遇与挑战：人工智能研究的深思熟虑的方法</i></p><p>任何考虑进入人工智能研究领域的人，无论是菲律宾人还是其他地方，都必须注意这个现实：将人工智能理解为一种技术会带来巨大的机遇。然而，将这些机会转化为胜利而不是失误，需要的不仅仅是本能；还需要更多的努力。它需要更多：</p><ol><li>规划和谨慎：踏上这条道路需要仔细规划和极其谨慎。人工智能领域充满潜力，但同样充满陷阱，可能导致巨大的困难和牺牲。</li><li>从历史中汲取教训：我们必须记住，在创新蓬勃发展之前，人类努力的未知领域往往会带来痛苦和挣扎。让我们的人工智能方法吸取这些历史教训，努力进行深思熟虑的创新，而不是仓促的实验。</li></ol><p><i>谨慎行事的责任</i></p><p>我们参与人工智能的风险确实非常高。这不仅仅是一次技术冒险；更是一次冒险。这是一项复杂的人类事业，需要认真考虑道德、联盟和社区的社会结构。</p><p>如果没有个人、团队、组织或政府将协调作为核心组成部分，我无法想象人工智能研究会取得成功。人工智能系统的思维方式不同——使用令牌，而不是文字，以及尚未完全理解的<a href="https://www.lesswrong.com/tag/transformers">变压器模型</a>。参与任何研究议程而不保持一致性所需的谨慎程度无疑会导致灾难。说明这一点的一个有用概念是人工智能系统是否表现出<a href="https://www.lesswrong.com/tag/corrigibility">可纠正的属性</a>。人工智能系统是否愿意在必要时允许自身被修改或关闭？即使人工智能可能不会直接用于研究输出，但更安全的是认识到这些技术是否还不够强大以确保安全。花时间深入了解人工智能系统的不同之处肯定有助于推进人工智能研究。</p><p></p><p>我们可以为人工智能的成功搭建一座坚固的桥梁。如果我们优先考虑安全，我们就能从理解人工智能技术中获得回报。</p><p></p><p><strong>对比结果：Binisaya Buddy 和当地传说</strong></p><p>我写了一篇关于两个引人注目的例子的文章，说明了负责任的人工智能开发的重要性：Binisaya Buddy，一个反映宿务文化、价值观和传统的虚拟指南，以及 Local Lore，一种文化再现的误导性尝试。 <span class="footnote-reference" role="doc-noteref" id="fnref19z9hnoglxt"><sup><a href="#fn19z9hnoglxt">[4]</a></sup></span></p><ol><li> <i>Binisaya Buddy：</i>这个项目诞生于充满活力的宿务，代表了对齐理论指导人工智能研究的潜力。它通过真实反映文化的细微差别为当地人和游客提供服务。</li><li><i>当地传说：</i>相比之下，当地传说缺乏当地洞察力，导致歪曲事实并与其旨在服务的社区脱节。执行不力造成的问题多于解决方案。</li></ol><p>通过 Binsaya Buddy 和 Local Lore 的例子，我们看到了人工智能与文化价值观结合的成功和失败。这些案例研究强调不仅需要个人责任，还需要在各个层面进行战略合作，以确保人工智能的发展符合我们的文化背景和道德价值观。</p><p></p><p>这些截然不同的结果凸显了建立一个集成系统的重要性，让各个利益相关者共同努力实现负责任的人工智能开发。这种合作可以采取什么形式？如何培养这种合作以确保技术真正满足我们社区的需求和价值观？</p><p></p><h3><strong>潜在途径：政府、企业和学术界之间的合作</strong></h3><p>在菲律宾充分发挥人工智能的潜力需要的不仅仅是各个部门的孤立努力。它需要政府机构、企业和学术机构之间进行紧密的战略合作。以下是这种三方合作如何促进负责任的人工智能开发：</p><p><strong>政府的角色：</strong></p><ul><li>监管框架：通过为人工智能开发制定明确的道德准则，政府可以确保技术进步符合国家价值观和社会需求。</li><li>投资和支持：政府对人工智能研发、基础设施和教育的投资可以促进该行业的增长，支持公共和私人举措。</li></ul><p><strong>企业部门的贡献：</strong></p><ul><li>实际应用：企业在将理论研究转化为实际解决方案方面处于领先地位。通过与学术界合作开发创新技术，行业参与者可以专注于解决当地的挑战。</li><li>私人投资：通过投资人工智能并与教育机构合作，企业可以创建一个繁荣的生态系统，促进技术创业和创造就业机会。</li></ul><p><strong>学术机构作为催化剂：</strong></p><ul><li>研究与创新：大学和研究机构是人工智能前沿探索的中坚力量。与企业的合作研究确保学术成果转化为现实世界的应用。</li><li>教育和培训：学术界在培养下一代人工智能专家方面发挥着至关重要的作用。通过使课程与行业需求和政府愿景保持一致，教育机构可以培养一支熟练的劳动力队伍，为负责任的人工智能发展做出贡献。</li></ul><p><strong>潜在的跨部门合作</strong></p><ul><li>共同目标和战略：通过设定共同目标和协作平台，三个部门可以协调努力，最大限度地提高效率和影响力。</li><li>道德与一致性：确保人工智能开发遵守道德原则需要所有三个部门的投入。这种合作确保技术进步有助于人类繁荣而不损害文化特征。</li></ul><h3></h3><h3><strong>结论</strong></h3><p>政府、工业界和学术界之间可能的合作不仅是有益的联盟，而且是有益的联盟。这可能是菲律宾负责任的人工智能发展的一项重要战略。通过认识到自己的独特角色并共同努力实现共同愿景，这些部门可以在不忽视道德考虑和当地价值观的情况下利用人工智能的变革潜力。</p><p><i>最终目标是人类繁荣。</i></p><p>最终，任何人工智能研究、项目甚至个人努力的目标都是人类的繁荣。为了实现这一目标，需要进行一定程度的协调工作，以确保结果有助于改善我们的生活。项目越大，必须包含的调整工作量就越大。</p><p>我们对人工智能潜力和挑战的探索最终以更广阔的视角实现。吸取了经验教训并了解了利害关系，让我们想象一下菲律宾在这个快速发展的领域可以发挥的独特作用，重点是协调和文化认同。</p><p><i>未来之路：菲律宾和人工智能</i></p><p>菲律宾拥有 1.15 亿居民，其中包括大量讲英语的人口，正处于十字路口。我们的人工智能之旅不仅仅是创新，更是创新。这是一种负责任的、符合道德的技术方法。一般人工智能研究和协调工作是同一枚硬币的两面，对于在人工智能世界中前进至关重要。风险巨大，潜力巨大。我们的国家决不能满足于将一般研究与我们共同的价值观（全球和地方）和文化认同相协调的方法。</p><h3></h3><h3><strong>附录</strong></h3><p>写完这篇文章后，我了解到碧瑶市代表马克·戈议员的一项提案。他向菲律宾国会通报了自己的倡议，即提议在全国范围内培训 1% 的菲律宾人进行人工智能技术培训，并为人工智能研究设立一个资助机构。尽管尚未起草任何法案，但这表明这篇文章既相关又及时。您可以<a href="https://www.youtube.com/watch?v=i00ZCE3udAk">在此处查看演示文稿和 Doc 的评论。</a> </p><p></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fngdz3m8hstr8"> <span class="footnote-back-link"><sup><strong><a href="#fnrefgdz3m8hstr8">^</a></strong></sup></span><div class="footnote-content"><p> Dominic Ligot 是 CirroLytix（一家具有社会影响力的人工智能公司）和 Data Ethics PH（一个专注于数据隐私、数据安全、人工智能驱动的歧视、数据责任、数据所有权和数据贫困等社会问题的在线社区）的创始人。三度获得 NASA 和 ESA 国际空间应用挑战赛全球冠军，其团队屡获殊荣的登革热监测应用程序 AEDES 得到了地球观测组织 (GEO)、数字公共产品联盟 (DPGA) 和联合国儿童基金会创新中心的支持基金。</p><p>您可以<a href="https://docligot.com/">在这里找到他的完整个人资料。</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn4w360g923mp"> <span class="footnote-back-link"><sup><strong><a href="#fnref4w360g923mp">^</a></strong></sup></span><div class="footnote-content"><p>当我提到对齐研究/工作时，我指的是理解对齐问题及其复杂性的努力。我很难推荐对齐理论作为标准，特别是因为它还不是一门关于如何对齐人工智能系统并让它们理解和维护人类价值观的具体科学，而且我们都还在弄清楚问题。然而，作为参考，<a href="https://www.lesswrong.com/posts/bjjbp5i5G8bekJuxv/study-guide">约翰·温斯沃斯的学习指南</a>很好地介绍了与一致性交织在一起的理论领域的复杂性。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnrgyrt2chqg"> <span class="footnote-back-link"><sup><strong><a href="#fnrefrgyrt2chqg">^</a></strong></sup></span><div class="footnote-content"><blockquote><p>但研究表明，全世界开展的项目中只有 35% 是成功的，这意味着我们浪费了大量的时间、金钱和机会。</p></blockquote><p></p><p>引自《哈佛商业评论》的安东尼奥·涅托·埃奥德里格斯的<a href="https://hbr.org/2021/11/the-project-economy-has-arrived">《项目经济已经到来》</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn19z9hnoglxt"> <span class="footnote-back-link"><sup><strong><a href="#fnref19z9hnoglxt">^</a></strong></sup></span><div class="footnote-content"><p>来自我的博客： <a href="https://www.whitehatstoic.com/p/binisaya-buddy-and-local-lore">https://www.whitehastoic.com</a> ：</p><h3> Binisaya 好友和当地传说</h3><p>副标题：对齐与错位：两个人工智能系统在菲律宾架起文化与技术桥梁的故事</p><figure class="image image_resized" style="width:57.35%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/bucxqobmbsdsytuueaos" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/j61mpzznl8fnnaxvj82e 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/aoljkptxyxmjcnzpslml 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/e3esjc3vtk1fz8gcf2u8 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/kdawakp2svpclhpfuf7b 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/mbkqfq08riaztzscujnc 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/tavmhtvyztvxvteyimex 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/xpgegixjph35p0xni7hf 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/ejeiieuk55e9lcqhtjyr 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/rxyebd4ryiw0dvubbvii 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/yEx2LfYEGaWQE8dHp/g45pp3gkkjty54n9wxbh 1024w"></figure><p></p><p>风景如画的宿务岛以其充满活力的遗产和令人惊叹的风景而闻名，建立了一个创新的人工智能系统来弥合当地人和游客之间的差距。该人工智能系统以当地方言命名为“Binisaya Buddy”，其设计是基于对宿务文化、价值观和传统的深刻理解。</p><p> Binsaya Buddy 通过互动亭迎接抵达麦克坦-宿务国际机场的游客。人工智能会带着友好的虚拟微笑，分享宿务丰富的历史故事，解释 Sinulog 等传统舞蹈的重要性，提供享受 Lechon 等当地美食的技巧，甚至用当地语言教授一些基本短语。</p><p>但 Binsaya Buddy 的与众不同之处在于它与当地文化的契合。人工智能不仅仅是一个信息库；它还是一个信息库。这是宿务灵魂的反映。当地人参与了它的开发，确保它体现了他们的信仰、价值观和生活方式的细微差别。</p><p>游客们发现自己沉浸在真正的宿务体验中，在这种让人感到个性化、尊重和联系的技术的帮助下。另一方面，当地人对他们的文化得到体现和分享感到自豪。</p><p> Binisaya Buddy 不再只是一个工具，而是一个工具。它成为技术与人类价值观相结合时如何增强文化理解、促进联系和创造有意义的体验的象征。</p><p>在距离宿务不远的另一个繁华城市，启动了一个雄心勃勃的项目，旨在创建人工智能驱动的旅游指南。该系统名为“当地传说”，旨在让游客了解当地文化、传统和历史。</p><p>然而，与 Binsaya Buddy 不同的是，Local Lore 是在没有本地输入的情况下开发的，仅由来自通用旅游网站和社交媒体的数据提供的算法指导。缺乏与社区价值观的一致性以及对其独特文化细微差别的理解，导致了意想不到的后果。</p><p>推出后不久，当地人开始注意到虚假陈述。当地传说将圣努洛节描述为仅仅是一场色彩缤纷的聚会，忽视了其深刻的宗教意义。它推荐商业化的旅游陷阱而不是真实的当地体验，而且其语言翻译往往不准确，导致无意的冒犯。</p><p>社区感到疏远和误解。他们看到自己丰富的文化沦为刻板印象和误解，成为讽刺而不是庆祝。</p><p>游客最初对新技术感到兴奋，但后来却感到困惑，并与这个地方的真正本质脱节。当地传说指导缺乏真实性，导致错失真正文化沉浸和理解的机会。</p><p>随着时间的推移，当地传说被放弃了，这是一次失败的实验，它清楚地提醒人们，当技术与其所代表的人类价值观、背景和文化不一致时，可能会出现问题。它成为一个警示故事，说明当忽视一致性时，即使是善意的创新也可能导致破坏。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/yEx2LfYEGaWQE8dHp/exploring-the-responsible-path-to-ai-research-in-the#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/yEx2LfYEGaWQE8dHp/exploring-the-responsible-path-to-ai-research-in-the<guid ispermalink="false"> yEx2LfYEGaWQE8dHp</guid><dc:creator><![CDATA[MiguelDev]]></dc:creator><pubDate> Wed, 23 Aug 2023 08:44:18 GMT</pubDate> </item><item><title><![CDATA[Do agents with (mutually known) identical utility functions but irreconcilable knowledge sometimes fight?]]></title><description><![CDATA[Published on August 23, 2023 8:13 AM GMT<br/><br/><p>一直在思考；冲突会一直存在吗？一个主要的子问题：假设我们都合并效用函数并形成一个致力于优化合并的星际社区。对我们来说，专注于工作的不同部分可能是有意义的，这意味着积累专业领域知识并变得相互难以理解。</p><p>当人们拥有截然不同的领域知识时，他们也会对各自领域的边界不一致。 <i>（EG：决策理论家坚持认为他们了解机器学习研究人员不知道的人工智能发展轨迹。机器学习研究人员不相信他们，也不听他们的建议。）在这些情况下，即使各方都在采取行动</i>出于善意，他们知道他们无法就某些分歧达成和解，从某些角度来看，试图在这些有争议的地区强加自己的方式似乎是有道理的。</p><p>这里使用的争议解决方法与具有不同核心价值观的代理人之间使用的争议解决方法有什么区别吗？ （战争、和平协议，最重要的是）</p><p>冲突各方是否会使用考虑到不同领域的物理优势的战争代理人？ （EG：决策理论家会阻止在有争议的领域进行机器学习研究吗？在这些领域，他们的决策理论知识会给他们带来<i>力量</i>优势？）</p><br/><br/> <a href="https://www.lesswrong.com/posts/FTdtHHBPDdzk4pJz2/do-agents-with-mutually-known-identical-utility-functions#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/FTdtHHBPDdzk4pJz2/do-agents-with-mutually-known-identical-utility-functions<guid ispermalink="false"> FTdtHHBPDdzk4pJz2</guid><dc:creator><![CDATA[mako yass]]></dc:creator><pubDate> Wed, 23 Aug 2023 08:13:06 GMT</pubDate> </item><item><title><![CDATA[South Bay ACX/SSC Fall Meetups Everywhere]]></title><description><![CDATA[Published on August 23, 2023 3:00 AM GMT<br/><br/><p>这是在桑尼维尔华盛顿公园举行的轻松的周六下午聚会。如果您正在阅读本文，那么您就被邀请了。如果您认为朋友也会喜欢，请带上他们。<br></p><p><strong>日期：</strong> 2023 年 10 月 14 日星期六</p><p><strong>时间：</strong>下午 2:00–5:00</p><p><strong>地点：</strong>华盛顿公园<br><a href="https://goo.gl/maps/yLTwRVbV3xkip8ps8">840 W Washington Ave, 桑尼维尔, CA 94086, 美国</a></p><ul><li>公园东北角圆形草地上</li><li>我们将提供一张带有 ACX Meetup 标志的折叠桌</li><li>确切位置：https: <a href="https://plus.codes/849V9XG6+X9F"><u>//plus.codes/849V9XG6+X9F</u></a><br></li></ul><p>我们会带一些零食和几条野餐毯。它可能不足以养活/适合每个人，所以也请随意携带自己的！</p><br/><br/> <a href="https://www.lesswrong.com/events/DcafHPWLuoKMt4Cug/south-bay-acx-ssc-fall-meetups-everywhere#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/events/DcafHPWLuoKMt4Cug/south-bay-acx-ssc-fall-meetups-everywhere<guid ispermalink="false"> DCafHPWLuoKMt4Cug</guid><dc:creator><![CDATA[allisona]]></dc:creator><pubDate> Wed, 23 Aug 2023 04:27:32 GMT</pubDate> </item><item><title><![CDATA[Separate the truth from your wishes]]></title><description><![CDATA[Published on August 23, 2023 12:52 AM GMT<br/><br/><p> “人人平等”这句话。 （以及类似的）乍一看似乎很简单，但实际上包含很多深度。根据你如何解释它，它可能是错误的或主观的，但我不认为这是真的。</p><p>最幼稚的解释显然是错误的。从身体意义上来说，所有人都是不平等的。我们的原子具有不同的配置。从心理意义上来说，我们也不平等。我们对相同的刺激有不同的反应。</p><p>那么，当人们说人人平等时，到底是什么意思呢？</p><p>他们的意思是每个人都享有平等的权利吗？这有点道理，但事实并非如此。我没有与居住在瑞士或中国的人相同的权利。</p><p>嗯，也许他们的意思是每个人都有平等的机会？快速思考一下就会证伪这种解释。那么它们是什么意思呢？？？</p><p>当某人说“所有人都是平等的”时，他真正的意思是什么？就是“我希望人人平等！”这既不真实也不虚假。这是对未来的一个愿望。我确实希望所有人都平等（但不是<a href="https://en.wikipedia.org/wiki/Harrison_Bergeron">哈里森·伯杰龙</a>意义上的平等，更多的是权利平等）。</p><p>我们本能地对“人人平等”做出反应的原因。是因为我们的文化，从启蒙运动的人文主义到《独立宣言》及之后的历史，使我们相信这是真的。当我们认为自己正在做出真实的陈述时，我们并没有意识到我们实际上是在表达一个愿望，这是危险的。</p><p>相反，有些说法乍一看像是观点（甚至可能是谎言），但实际上是正确的。 （关于智力的陈述非常适合这一类别，但我将把它们排除在外。）这些陈述通常与文化使我们相信的东西背道而驰。例如：“并非所有人都是平等的。”这种说法是正确的，但通常被解释为“我希望所有人都拥有不平等的权利”。 （愿望），但它应该被解释为事实。同样，这很危险，因为它掩盖了真实的情况。</p><p>为了推动社会前进——真正让每个人平等并变得更好——我们需要将我们的信仰和愿望分开。如果我们相信某些不真实的东西（但我们希望它是真实的）实际上是真实的，我们就不会注意到它，也不会花费那么多的时间和精力来修复它。然而，如果我们能够准确地相信（有时是不方便的）事实，我们就可以缩短我们的愿望成为事实的时间。</p><p>现在就去修复世界吧！</p><br/><br/> <a href="https://www.lesswrong.com/posts/fi3nJBZ9PsmTpCpsd/separate-the-truth-from-your-wishes#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/fi3nJBZ9PsmTpCpsd/separate-the-truth-from-your-wishes<guid ispermalink="false"> fi3nJBZ9PsmTpCpsd</guid><dc:creator><![CDATA[g-w1]]></dc:creator><pubDate> Wed, 23 Aug 2023 00:52:59 GMT</pubDate> </item><item><title><![CDATA[Implications of evidential cooperation in large worlds]]></title><description><![CDATA[Published on August 23, 2023 12:43 AM GMT<br/><br/><p>我在我新恢复的博客上写了几篇关于“大世界中的证据合作”（ECL）的合理含义的文章。这是<a href="https://lukasfinnveden.substack.com/p/implications-of-ecl">第一个</a>的交叉帖子。如果您想查看其余的帖子，可以转到<a href="https://lukasfinnveden.substack.com/">博客</a>或单击本帖子中的链接。</p><p>我博客上的所有内容，包括这篇文章，仅代表我自己的观点，而不代表我雇主的观点。 （目前开放慈善事业。）</p><hr><p> “ECL”是“大世界中的证据合作”的缩写。这个想法最初是在<a href="https://longtermrisk.org/files/Multiverse-wide-Cooperation-via-Correlated-Decision-Making.pdf">Oesterheld (2017)</a>中提出的（名为“多元宇宙超理性”）。这篇文章将探讨 ECL 的含义，但不会解释这个想法本身。如果您以前没有遇到过，您可以阅读上面链接的论文或 Lukas Gloor 撰写的<a href="http://effective-altruism.com/ea/1gf/multiversewide_cooperation_in_a_nutshell/">摘要</a>。 <span class="footnote-reference" role="doc-noteref" id="fnrefweuaua0f4c"><sup><a href="#fnweuaua0f4c">[1]</a></sup></span></p><p>这篇文章列出了我所了解并认为似乎很重要的 ECL 决策相关影响的所有候选者。 <span class="footnote-reference" role="doc-noteref" id="fnrefx18fvnjp5eq"><sup><a href="#fnx18fvnjp5eq">[2]</a></sup></span>在这篇文章中，我不会深入描述为什么它们可能是 ECL 的含义。相反，我将遵循以下原则：ECL 建议我们（以及其他 ECL 同情者）采取行动，以造福于那些决策可能与我们的决策相关的人们的价值观。</p><p>如<a href="https://lukasfinnveden.substack.com/i/136237476/what-values-do-you-need-for-this-to-be-relevant">本附录</a>所述，这依赖于您和其他人具有特定类型的价值观。其一，我假设您关心我们的<a href="https://en.wikipedia.org/wiki/Light_cone">光锥</a>之外发生的事情。但更强烈的是，我正在考虑具有以下属性的值：如果您可以在我们的光锥之外产生足够大的影响，那么采取不同操作的价值将由这些操作在我们的光锥之外产生的影响主导。我将其称为“全宇宙价值观”。即使你的<i>所有</i>价值观不是全宇宙范围的，我怀疑如果你有<i>一些</i>全宇宙范围的价值观，其含义仍然与你相关。</p><p>这是推测性的东西，我并不是特别有信心我会得到任何特定的主张。</p><h1>摘要（带有子部分的链接）</h1><p>至少出于两个原因，未来的参与者将比我们更有能力根据 ECL 采取行动。首先，他们会更多地了解其他价值体系。其次，他们将面临关于如何处理宇宙的立即决定，这应该由其他文明的偏好来决定。 <span class="footnote-reference" role="doc-noteref" id="fnrefpneoqb5vw9"><sup><a href="#fnpneoqb5vw9">[3]</a></sup></span>这表明<a href="https://lukasfinnveden.substack.com/i/136237476/affect-whether-and-how-future-actors-do-ecl">影响未来参与者是否（以及如何）进行 ECL</a>对我们来说可能很重要。这可以分解为两个值得单独关注的子点：我们如何能够<a href="https://lukasfinnveden.substack.com/i/136237476/futures-with-aligned-ai">通过一致的人工智能影响未来</a>，以及我们如何能够<a href="https://lukasfinnveden.substack.com/i/136237476/futures-with-misaligned-ai">通过不协调的人工智能影响未来</a>。</p><p>但除了影响未来的参与者之外，ECL 还改变了我们今天的优先事项。特别是，ECL 建议我们应该更多地关心其他参与者的全宇宙价值观。在评估这些影响时，我们可以分别考察三类不同的参与者及其价值观。我将单独考虑 ECL 如何建议我们应该……</p><ul><li> <a href="https://lukasfinnveden.substack.com/i/136237476/how-us-doing-ecl-affects-our-priorities">更关心</a><a href="https://docs.google.com/document/d/1XCZ-g_GAyZwfJfWHTRVyzptVU2_uI9tFWMG8x9j4C_o/edit#heading=h.qkf9kvplu0c8"><i>其他人类的</i></a><a href="https://lukasfinnveden.substack.com/i/136237476/care-more-about-other-humans-universe-wide-values">宇宙价值观</a>。 <span class="footnote-reference" role="doc-noteref" id="fnreffbnqsghmnv4"><sup><a href="#fnfbnqsghmnv4">[4]</a></sup></span><ul><li>我认为这最重要的含义是， <a href="https://lukasfinnveden.substack.com/i/136237476/upside-and-downside-focused-longtermists-should-care-more-about-each-others-values">关注上行和下行的长期主义者应该更多地关心彼此的价值观</a>。</li></ul></li><li> <a href="https://lukasfinnveden.substack.com/i/136237476/care-more-about-evolved-aliens-universe-wide-values">更关心<i>进化外星人的</i></a><a href="https://docs.google.com/document/d/1XCZ-g_GAyZwfJfWHTRVyzptVU2_uI9tFWMG8x9j4C_o/edit#heading=h.10dsvgq5soqa">全宇宙价值观</a>。<ul><li>我认为这最重要的含义是，我们似乎应该更多地关心<a href="https://lukasfinnveden.substack.com/i/136237476/influence-how-ai-benefitsharms-alien-civilizations-values">影响人工智能如何造福/伤害外星文明</a>。</li><li>还有多少？我尝试<a href="https://lukasfinnveden.substack.com/p/how-ecl-changes-the-value-of-interventions">在下一篇文章</a>中回答这个问题。我最好的猜测是 ECL 将其价值提高了 1.5-10 倍。 （这重要的是基于我的直觉，即使没有 ECL，我们也会关心外星价值观。）</li></ul></li><li> <a href="https://lukasfinnveden.substack.com/i/136237476/care-more-about-misaligned-ais-universe-wide-values">更关心</a><a href="https://docs.google.com/document/d/1XCZ-g_GAyZwfJfWHTRVyzptVU2_uI9tFWMG8x9j4C_o/edit#heading=h.6dtoz94g6ytt"><i>错位的人工智能的</i></a><a href="https://lukasfinnveden.substack.com/i/136237476/care-more-about-misaligned-ais-universe-wide-values">全宇宙价值观</a>。 <span class="footnote-reference" role="doc-noteref" id="fnrefd6bt2xf37fd"><sup><a href="#fnd6bt2xf37fd">[5]</a></sup></span><ul><li>我不认为这会显着<a href="https://lukasfinnveden.substack.com/i/136237476/minor-prioritize-ai-takeover-risk-less-highly">降低对齐工作的价值</a>。</li><li>但它表明，构建人工智能可能很有价值，这样<i>即使</i>它最终出现偏差，它也能具有某些其他理想的倾向和价值观。这个<a href="https://lukasfinnveden.substack.com/i/136237476/positively-influence-misaligned-ai">积极影响失调的人工智能</a>以便与遥远的失调的人工智能合作的话题非常粗糙，很难判断什么样的变化是净积极的还是净消极的。</li><li>我将在<a href="https://lukasfinnveden.substack.com/p/ecl-with-ai">后面的帖子</a>中详细讨论这一点。</li></ul></li></ul><p> （有关人类/进化的外星人/错位人工智能之间的区别以及我选择它的原因的更多详细信息，请参阅<a href="https://lukasfinnveden.substack.com/i/136237476/more-details-on-the-split-between-humans-evolved-species-and-misaligned-ai">此附录。</a> ）</p><h1>影响未来参与者是否（以及如何）进行 ECL</h1><h2>与人工智能相一致的期货</h2><p>如果我们认真对待 ECL， <span class="footnote-reference" role="doc-noteref" id="fnrefwi0f1v4h1qk"><sup><a href="#fnwi0f1v4h1qk">[6]</a></sup></span>我认为人类<i>最终</i>深入理解这些主题并能够做出明智的决定非常重要。但对于大多数关于人类<i>最终</i>应该做什么的问题，我倾向于把它们推迟到未来。我感兴趣的是是否有什么<i>迫切</i>需要做的事情。</p><p>影响事物的一种方法是增加人类最终建立一个健康且具有哲学能力的文明的可能性。 （但我们已经知道这很重要。）</p><p>人类也可能在短期内以决策理论特有的方式出现不可逆转的混乱。例如，如果人们认为自己处于<a href="https://www.lesswrong.com/posts/brXr7PJ2W4Na2EW2q/the-commitment-races-problem">承诺竞赛</a>中，他们可能会做出不明智的承诺。 <span class="footnote-reference" role="doc-noteref" id="fnref4423tsgb79u"><sup><a href="#fn4423tsgb79u">[7]</a></sup></span>或者，人们可能会通过某些方式过早地了解到太多信息。 （我们目前还没有任何形式化的决策理论<i>不会</i>因学习信息而受到损害。例如，使用证据决策理论的人只能影响他们尚未了解的事物——这意味着信息可以使他们失去动力。）（参见<a href="https://lukasfinnveden.substack.com/p/when-does-edt-seek-evidence-about">后面关于 EDT 寻找或避免某些信息的帖子</a>。）仔细思考可能会减少此类风险。 <span class="footnote-reference" role="doc-noteref" id="fnref9j6fzbxzuod"><sup><a href="#fn9j6fzbxzuod">[8]</a></sup></span> （例如，也许最好阻止早期人工智能系统思考这些主题，直到它们和我们变得更有能力。）</p><p> ECL 与此有什么关系？从广义上讲，ECL 似乎是各种决策理论所推荐的难题的重要组成部分。因此，了解更多有关 ECL 的信息似乎有助于澄清此处的情况，并澄清存在哪些干预点。 （这也适用于人工智能错位的期货。）</p><p> （ <a href="https://longtermrisk.org/files/Multiverse-wide-Cooperation-via-Correlated-Decision-Making.pdf">Oesterheld (2017)</a>的相关讨论参见第4.5节“研究和推广ECL”和“4.6.3”让人工智能按照ECL行事。）</p><h2>人工智能错位的期货</h2><p>影响 AI 的 ECL 失调程度也是一个干预点。</p><p>我认为 ECL 可以在这里扮演几个不同的角色：</p><ul><li>首先，具有 ECL 同情心的人工智能系统可能会更好地对待<i>我们</i>（例如，给人类一个太阳系大小的乌托邦，而不是杀死我们）。<ul><li>为了让 ECL 激励人工智能系统善待我们，需要有一些遥远的参与者关心我们。也就是说，有人需要拥有全宇宙的价值观，特别重视对遥远的前通用人工智能文明的保护，而不是用这些资源可以做的其他事情。</li></ul></li><li>其次，ECL 同情人工智能系统可能会与遥远的文明进行贸易（并避免冲突），从而使这些文明受益。<ul><li>如果我们本质上关心那些遥远文明的价值观，这本质上是好的。</li><li>此外，ECL 建议我们关心遥远文明所带来的利益，而我们本质上并不关心这些文明的价值观，这似乎是合理的。这将在下面的<a href="https://lukasfinnveden.substack.com/i/136237476/influence-how-ai-benefitsharms-alien-civilizations-values">《影响人工智能如何有益/危害外星文明》</a>中讨论。</li><li>这种贸易也可能有利于<i>人工智能系统自身价值观的错位</i>，而 ECL 可能会让我们有理由关心这些价值观。这个就比较复杂了。我在下面的<a href="https://lukasfinnveden.substack.com/i/136237476/positively-influence-misaligned-ai">积极影响失调的人工智能</a>中对此进行了讨论。</li></ul></li></ul><h1><i>我们进行</i>ECL 如何影响我们的优先事项</h1><h2>更加关心其他人类的宇宙价值观</h2><h3>哪些全宇宙的价值观控制着未来的资源并不那么重要（在实践中似乎微不足道？）</h3><p>让我们暂时假设人类将避免近期灭绝和人工智能接管。即便如此，未来的价值可能在很大程度上取决于<i>人类的价值观</i>将被赋予决定如何处理我们光锥中的所有物质、空间和时间的能力。</p><p>如果有人有机会影响这一点（例如，通过推广某些价值观），ECL 通常会积极地赋予全宇宙价值观（与良好的决策理论推理兼容），因为对于任何此类价值观：</p><ul><li>您可能会与持有此类价值观的远方人士建立联系，在这种情况下，ECL 会给您让他们受益的理由。</li><li>如果这些价值观在长远的未来保持力量，并且我们未来的文明最终决定 ECL（或类似的东西）有效，那么 ECL 将激励他们造福于其他全宇宙的价值观。 （至少就贸易带来的收益而言是这样。）</li></ul><p>如果您以前担心推广<i>任何特定的</i>全宇宙范围的价值观，这意味着您现在应该不太担心推广这些特定的价值观，而不是任何其他全宇宙范围的价值观。在争夺影响力的斗争主要是关于全宇宙价值观的斗争中，你不应该关心谁获胜。</p><p> （这与<a href="https://longtermrisk.org/files/Multiverse-wide-Cooperation-via-Correlated-Decision-Making.pdf">Oesterheld (2017)</a>第 4.2 节中有关道德倡导的讨论有关；尤其是 4.2.7。）</p><p>这里有一个稍微成熟的姿态来说明为什么 ECL 会推荐这样做。</p><ul><li>假设您是 A 派系的支持者，正在与 B 派系争夺影响力。您可以决定投资于影响力的 0 和斗争，或者您可以决定投资于你们都看重的东西（例如减少无争议的 x 风险或 s 风险）。</li><li>如果对 B 派系的支持与良好的决策理论推理相容，那么在某个遥远的星球上，可能会有 B 派系的支持者，他们与你处于类似但相反的情况（在与 A 派系的影响力斗争中），他们是以类似的方式思考这个决定。</li><li>如果你决定支持共同利益而不是A派系，那么A派系对你的星球的预期影响力将会有所下降。但你的选择证明了B派的远方支持者也会支持他们星球上的公共利益（而不是B派），这将导致A派的预期影响力增加一些（同时也会带来积极的影响）公共利益的支持）。</li><li>因此，ECL 提供了一个理由，让我们在零和斗争中投入更少的资源，而更多地关心公共物品。</li></ul><p> （为了计算出您愿意在零和斗争中减少<i>多少</i>投资，您需要考虑“我提供了多少证据表明 A 派系的支持者将投资于公共利益”之间的比率”到“我提供了多少证据来证明 B 派的支持将投资于公共利益”。 <span class="footnote-reference" role="doc-noteref" id="fnref8k49uv7ijvl"><sup><a href="#fn8k49uv7ijvl">[9]</a></sup></span>我在这里只是说明方向性论证。）</p><p>虽然我相信 ECL 论点在这里有效，但目前它对我来说似乎与决策不太相关。对未来可能很重要的竞争（例如人工智能实验室之间或美国与中国之间的竞争）似乎并没有被很好地描述为全宇宙价值体系之间的冲突。至少我个人对他们的看法主要是关于谁更有可能/更不可能一路上造成（无争议的）X风险；也许是关于谁更有/不太可能帮助创建一个采用相当公正的价值观并在哲学上变得足够复杂以制定最佳版本的社会。</p><p>也就是说，对于那些以前痴迷于推动<i>特定</i>价值体系（例如传播享乐主义功利主义，或个人为了公正目的而获取权力）的人来说，我认为 ECL 应该推动这种动机，使其在某种程度上更加包容其他全宇宙的价值观。</p><h3>关注上行和下行的长期主义者应该更多地关心彼此的价值观</h3><p>（术语定义<a href="https://longtermrisk.org/cause-prioritization-downside-focused-value-systems/">如下</a>：“关注上行的价值观”是<i>在我们的经验情况下</i>建议专注于带来大量积极价值的价值观。“关注下行的价值观”是<i>在我们的经验情况下</i>建议致力于采取干预措施的价值观，这些干预措施会带来负面影响事情不太可能发生，通常会减少痛苦。）</p><p>如果我们超越对影响力和资源的争夺，而是寻找具有不同的<i>全宇宙</i>价值观的任何人类群体，并且这会导致不同的现实世界优先事项，那么脱颖而出的两个群体是关注向上的群体和关注下行的群体——专注于长期主义者。对于这些群体，我们还<i>提供了关注上行和下行的人们以类似方式思考 ECL 的实际例子</i>。这使得 ECL 论点更加有力。</p><p>人们了解并牢记这一点似乎是件好事。例如，这意味着关注积极面和消极面的人应该：</p><ul><li>倾向于利用高杠杆机会互相帮助，</li><li>决定做什么工作，少一些基于价值观，多一些基于比较优势，</li><li>避免采取有利于自己价值观但损害他人价值观的行为。</li></ul><p>像往常一样，这里的 ECL 论点是：如果你选择采取这些行动中的任何一个，那么这就证明具有<i>其他</i>价值体系的遥远的人会选择采取类似的行动来使<i>你</i>最喜欢的价值体系受益。</p><p>这种效应有多强？我不知道。接下来是几段猜测。 （标记：与本文的其余部分相比，这些段落更多地依赖于有关 ECL 的现有知识。）</p><p>最终，这取决于人类与具有共同价值观和不同价值观的人的决策的相关程度相对较高，在这种类型的决策中。</p><p>也就是说，问题是：如果一个主要关注上行价值观的人决定做一些有利于下行价值观的事情，有多少证据表明（i）远方关注上行价值观的人会帮助那些关注下行价值观的人，而. (ii) 远距离关注消极面的人会帮助那些关注积极面价值观的人。 （从做出决定的人的角度来看。）</p><p>如果这两个命题都有同样多的证据，那么关注向上的人和关注向下的人应该同样倾向于有利于彼此的价值观，就像有利于自己的价值观一样。 <span class="footnote-reference" role="doc-noteref" id="fnrefsocdvs8tsuk"><sup><a href="#fnsocdvs8tsuk">[10]</a></sup></span></p><p>这里有一个支持这一点的论点：无论你的价值观是向上还是向下，ECL 论点（你应该关心其他人的价值观）都非常相似。所以看起来对你所拥有的价值观没有太大的依赖。因此，你的决定似乎应该同样成为其他人行为方式的证据，无论他们有什么价值观。</p><p>这是一个反论点：当你做出任何特定的决定时，也许你会得到不成比例的大量证据，说明与你特别相似的参与者在特别相似的情况下倾向于如何看待基于 ECL 的合作论点。 （毕竟：关于人们对 ECL 论点采取行动的可能性的大多数证据<i>通常</i>都来自<i>对其</i>他人做出的决定的观察。）也许“特别相似”的一个重要组成部分是这些参与者会分享你的观点价值观。 <span class="footnote-reference" role="doc-noteref" id="fnrefygfd8lysjb"><sup><a href="#fnygfd8lysjb">[11]</a></sup></span></p><p> （对于我的更多猜测，包括对最后一段的一些反驳，请参阅帖子<a href="https://lukasfinnveden.substack.com/p/are-our-actions-evidence-for-ai-decisions">“我们的选择是否类似于人工智能选择？”</a> ，其中讨论了类似的问题，但涉及与<i>人工智能</i>而不是与<i>人类</i>相关。相对较少可能的命题。然而，类似的考虑也出现了。另见<a href="https://longtermrisk.org/files/Multiverse-wide-Cooperation-via-Correlated-Decision-Making.pdf">Oesterheld (2017)</a>关于理性和价值观的正交性的第 3.1 节。）</p><p>总的来说，我在这里感到很不确定。这种不确定性对应于一种感觉，即我的行为对于那些不认同我价值观的人的决定来说，证据有点少，但也并没有减少很多。总结我的不确定性，我觉得我的决定对于那些不认同我的价值观的人的决定来说是≥10%的证据（因为它们是与我有共同价值观的人的决定的证据）——这意味着我对他们的价值观的关心程度应该和我对自己价值观的关心程度一样≥10%。 <span class="footnote-reference" role="doc-noteref" id="fnref2f0pffnolcf"><sup><a href="#fn2f0pffnolcf">[12]</a></sup></span></p><h2>更关心进化外星人的全宇宙价值观</h2><p>ECL还建议更多地关心外星文明。以下是这三个不同的含义。</p><h3>次要：降低非人工智能灭绝风险的优先级</h3><p>这样做的一个小后果是：您可能希望将非人工智能灭绝风险的优先级稍微<i>降低</i>到以前的水平。因为如果地球不殖民宇宙，那么某些空间将（在预期中）被外星文明殖民，这对他们有利。</p><p>如果我们要进行类似的交易，故事将是：如果我们将非人工智能灭绝风险的优先级稍微降低一些（并更加优先考虑确保太空殖民确实发生的话是好的），那么这就是证据遥远的外星人对非人工智能灭绝风险的优先级也稍低一些。如果这导致他们的灭绝，而他们的邻居分享我们的价值观，那么具有我们价值观的文明将恢复一些空白。 <span class="footnote-reference" role="doc-noteref" id="fnrefiuznazkhk0b"><sup><a href="#fniuznazkhk0b">[13]</a></sup></span></p><p>我认为这种影响似乎很小（不太可能使非人工智能灭绝的有用性低于你之前想象的一半）。</p><p>这主要是因为ECL不建议我们<i>像</i>关心人类价值观那样关心外星人的价值观。 <span class="footnote-reference" role="doc-noteref" id="fnrefpe2xs41o2x7"><sup><a href="#fnpe2xs41o2x7">[14]</a></sup></span>如果 ECL 建议我们优先考虑随机外星人值超过我们自己值的一半，我会感到惊讶，这表明即使外星人保证在我们的位置殖民太空，我们的价值至少会损失 1/2未能这样做。</p><p>另一个考虑因素是，外星人（可能）还不够普遍，无法占据我们可能错过的所有空间。我认为相关的比较是“我们可以<i>在外星人之前</i>到达的空间”（即，如果太空以防御为主，人类可以到达的空间总量）与“<i>只有</i>我们可以到达的空间”（即，人类可以到达的空间总量）之间的比较。人类可以在不排除任何外星人的情况下进入的空间，这样即使我们像关心我们自己的价值观一样关心外星人的价值观，我们也会想要到达那里）。</p><ul><li> <a href="https://forum.effectivealtruism.org/posts/9p52yqrmhossG2h3r/quantifying-anthropic-effects-on-the-fermi-paradox">我以前的估计</a>是后者大约是前者的⅓倍。这表明，即使 ECL 让我们像关心我们自己的价值观一样关心外星人的价值观，我们对殖民太空的关心程度仍然是⅓。</li><li>但我以前的估计没有考虑到如果人类灭绝，地球上的智力可能会重新进化。我认为这很有可能，因为我的印象是，与地球剩余的寿命相比，最近智力的进化增长很快。如果地球上智力无法重新进化的概率只有⅓，那么预计不会被任何人殖民的空间只有人类首先到达的空间的⅓*⅓~=10% 。</li><li>因此，如果我们从表面上看这些估计——他们表明，<i>如果</i>ECL 将我们从“根本不关心外星人价值观”转变为“像关心我们自己的价值观一样关心外星人价值观”，这将降低价值非 AI 灭绝最多减少 10 倍。</li><li> ......从全宇宙价值观的角度来看，它对宇宙的边际影响大致呈线性。其他看似合理的价值体系不会受到这一论点的影响，因此它高估了我们全面考虑的观点应该改变多少。</li></ul><p>此外，正如我<a href="https://lukasfinnveden.substack.com/i/136237476/minor-prioritize-non-ai-extinction-risk-less-highly">在下面</a>讨论的，ECL 可能同样会促使我们降低人工智能接管的优先级。由于从长期观点来看，这是“非人工智能灭绝风险”最显着的替代优先事项，因此它们部分抵消了。</p><h3>影响人工智能如何有益/损害外星文明的价值观</h3><p>我们可以使外星人受益的另一种方式是增加源自地球的智慧使他们受益的可能性（如果源自地球的智慧没有灭绝）。这可能适用于我们在太空中实际遇到的外星人，也可能适用于我们无法与之互动的遥远外星人。</p><p>我通常将此类干预视为一种特殊的“合作人工智能”干预——增加人工智能倾向于寻求与其他价值体系双赢机会的可能性。有关此问题的更多讨论，请参阅<a href="https://lukasfinnveden.substack.com/p/how-ecl-changes-the-value-of-interventions">这篇文章</a>。简短的总结是：ECL 可能会增加干预措施的价值，这些干预措施旨在使不一致的人工智能更好地对待外星文明约 1.5-10 倍。</p><h3>可能：如果以痛苦为中心的价值观更具有普遍性，那么它们的权重就会更高一些</h3><p>这是清单上我考虑最少的一项。但我最近意识到它超出了我的“看似重要的含义”的标准，所以我将简要提及它。</p><p>正如<a href="https://longtermrisk.org/files/Multiverse-wide-Cooperation-via-Correlated-Decision-Making.pdf">Oesterheld (2017)</a>第 4.1.1 节所述，ECL 建议我们应该更加重视“普世价值观”，而不是特殊的担忧。 （请注意，“普遍主义价值观”与全宇宙价值观<i>不同</i>。普遍主义价值观是在整个宇宙中高度普遍的价值观。）</p><p>虽然我只是这个原则的基本论点，但我最初并没有看到任何与决策相关的应用。</p><p>例如，一种特殊的价值观是特别关心自己，而不是关心他人。但为了使该论点适用于此，我们要求利他价值观和自私价值观之间的权衡率对所涉及的利他主义利害关系的抽象论点敏感。至少对我个人而言，我直觉地认为，了解遥远未来的潜在规模应该能够“最大限度地发挥”高利他主义的抽象知识将迫使我更加利他、更少自私地行事的程度。这样一来，ECL 就没有多少空间可以感动我了。</p><p>另一个例子是，它会影响我们应该对哪种道德倡导的具体形式感兴趣，因为我们追求道德倡导是为了影响长期价值观。但我目前认为，以影响长期价值观为目的，提倡高度具体的价值观似乎并不是一项高度优先的干预措施。 （我认为“通过道德倡导来改变近期行为”或“倡导道德审议的良好原则”相对更有希望。但我不认为这些干预措施的价值对于 ECL 是否建议普遍适用非常敏感价值观胜过特殊价值观。）</p><p>但在这种情况下，这种考虑可能很重要。有些人对道德的看法在对未来的<i>积极</i>愿景和对未来的<i>消极</i>愿景之间存在不对称性。积极的愿景需要正确处理许多复杂的、人类特有的事情，以满足人类高度偶然、高度复杂的价值观。而消极的愿景只需要痛苦——那就已经很糟糕了。 <span class="footnote-reference" role="doc-noteref" id="fnref40zg3jy06vx"><sup><a href="#fn40zg3jy06vx">[15]</a></sup></span></p><p>如果这是你的观点，那么一个合理的推论可能是：宇宙中有更多的外星人与你一样关心苦难，然后与你一样对积极的未来抱有愿景。</p><p>如果这是真的，那么你可能会从贸易中获得收益，因为每个人都将相对更多的注意力放在减少痛苦上（这是每个人都赞赏的），而相对较少的注意力放在实现高度复杂的积极未来愿景上（只有少数人才欣赏这一点）。相对较小的部分）。</p><p>这个影响有多大？</p><ul><li>当你采取行动来实现你所看重的积极未来时，你的影响力与分享这些价值观的参与者（权力加权）数量乘以你与他们相关的平均数量成正比。</li><li>当你采取行动减少你不重视的负面经历时，你的影响力与分享这些价值观的参与者（权力加权）数量乘以你与他们相关的平均数量成正比。</li></ul><p>举例来说：如果你认为认同你对痛苦的看法的演员比你对美好未来的看法多 10 倍，但这些演员与你不太相似，因此与你的相关性平均减少 2 倍，那么这会增加以痛苦为重点的干预措施增加了 5 倍。</p><h2>更关心错位的人工智能的全宇宙价值观</h2><p>更具推测性的是，ECL 可能建议我们更加关心遥远的错位人工智能的全宇宙价值。 <span class="footnote-reference" role="doc-noteref" id="fnrefstsq0mzojoo"><sup><a href="#fnstsq0mzojoo">[16]</a></sup></span>为什么这更具推测性？为了让 ECL 给我们有理由让人工智能受益，我们必须与那些人工智能足够相似，以至于我们的决策对他们的决策有一些非因果影响。如果我们假设证据决策理论，这意味着我们的决策需要为遥远的错位人工智能选择做什么提供一些证据。直觉上，我们的决定似乎不太可能提供关于遥远的错位人工智能行为的证据，而更不可能提供关于遥远的外星人行为的证据。 （因为人工智能的思想可能与我们的思想有更大的不同，并且因为他们可能发现自己所处的决策情境与我们的有更多的不同。）</p><p>我不确定 ECL 是否认为我们应该更加关心远程人工智能的价值。如果确实如此，这里有两个结论。</p><h3>次要：降低人工智能接管风险的优先级</h3><p>一个潜在的影响可能是，我们应该稍微降低人工智能接管风险的优先级：因为虽然对不协调的人工智能来说夺取权力是不好的，但人工智能能够实现自己的价值观至少会稍微好一点，只要这些价值观这些价值观得到了许多遥远的 ECL 同情人工智能的认可。 （因为我们以这种方式使他们的价值观受益，这将证明他们做出的决定有利于我们的价值观——或者至少这是我们正在考虑的假设。）</p><p>然而，这种影响似乎很小（不太可能使错位减少的作用不到您之前想象的一半）。因为：</p><ul><li>如上所述，我们可能与人工智能不够相似，因此 ECL 论证无法成立。即使我们足够相似，可以对它们产生一些非因果影响，ECL 也不建议我们<i>像</i>关心人类价值观一样关心人工智能价值观。 <span class="footnote-reference" role="doc-noteref" id="fnref63f2sg768l9"><sup><a href="#fn63f2sg768l9">[17]</a></sup></span>如果 ECL 建议我们将随机 AI 值的优先级设置为我们自己值的一半以上，我会感到惊讶。</li><li>这主要是为了稍微降低<i>具有全宇宙价值的 ECL 同情人工智能系统对</i>人工智能接管的优先级。但默认情况下，人工智能可能不具有全宇宙的价值观，并且可能不支持 ECL。</li></ul><p>此外， <a href="https://lukasfinnveden.substack.com/i/136237476/minor-prioritize-non-ai-extinction-risk-less-highly">如上所述</a>，ECL 可能同样会促使我们降低<i>非人工智能</i>灭绝的优先级。 （从长期观点来看，这是错位风险最突出的替代优先事项。）</p><h3>对错位的人工智能产生积极影响</h3><p>我们可以使遥远的、不一致的人工智能的全宇宙价值观受益的另一种方式是调整我们构建人工智能的方式，这样，<i>如果</i>人类最终构建出与我们自己的价值观不一致的人工智能，那么它更有可能成功地针对遥远的价值观进行优化。错位的人工智能会批准。不幸的是，在这里似乎很难弄清楚什么样的改变是好的，什么样的改变是坏的。</p><p>有关这方面的更多文章，请参阅<a href="https://lukasfinnveden.substack.com/p/ecl-with-ai">此处</a>。</p><h2>更多的</h2><p>我将用另外两篇文章来跟进这篇文章：</p><ul><li> <a href="https://lukasfinnveden.substack.com/p/how-ecl-changes-the-value-of-interventions">ECL 和造福遥远的文明</a>，更多地了解 ECL 如何影响影响人工智能如何造福/伤害遥远的外星文明的价值。</li><li> <a href="https://lukasfinnveden.substack.com/p/ecl-with-ai">ECL 与 AI</a> ，深入探讨我们如何积极影响错位的 AI，以及 ECL 是否建议这样做。</li></ul><h1>附录</h1><h2>您需要什么值才能使其相关？</h2><p>我想说这篇文章的大致内容是：给那些价值观如此的人的建议，<i>如果</i>他们承认自己的行为无因果地影响了许多与他们自己截然不同的世界，他们会说，大部分影响是他们自己的。关心的是对那些遥远世界的影响。</p><p>重要的是，这也是对那些支持某种道德不确定性或多元化、并且其<i>价值观</i>中有类似行为的人的建议。然后是关于价值成分应该提倡和讨价还价的建议。 （我认为这可能是对大多数人类价值观的更现实的描述。）</p><p> （虽然我没有考虑细节的许多地方之一是：如果你试图用全宇宙范围的价值观来影响代理，那么如果你自己只有部分全宇宙范围的价值观并且这样做，它会带来任何额外的麻烦吗？一些混乱的妥协的事情？）</p><p>我将使用“全宇宙”值作为这些类型值的简写。 （“多元宇宙范围”也是一个很好的术语——但我认为关心一个空间大的宇宙就足够了。）</p><p> （有关 ECL 所需值的先前讨论，请参阅<a href="https://longtermrisk.org/files/Multiverse-wide-Cooperation-via-Correlated-Decision-Making.pdf">Oesterheld (2017)</a>中的第 3.2 节。）</p><h2>有关人类、进化物种和错位人工智能之间分歧的更多细节</h2><p>上面，我分别思考了ECL如何建议我们应该更加关心：</p><ul><li>其他人类的宇宙价值观，</li><li>进化出外星人的全宇宙价值观，</li><li>人工智能的全宇宙价值观错位。</li></ul><p>这提出了两个问题：</p><ul><li>为什么要区分“其他人类的全宇宙价值观”和“进化外星人的全宇宙价值观”？</li><li>为什么要区分“进化的外星人的全宇宙价值观”和“错位的人工智能的全宇宙价值观”？</li></ul><h3>为什么要区分人类和外星人？</h3><p>当我谈到造福其他人类的全宇宙价值观时，我并不是在暗示我们只是与地球上的当地人类进行非因果的合作。我认为几乎所有的好处都来自于证据表明相距遥远的参与者表现得更加合作。这些演员可能与人类非常相似，也可能与人类非常不同（至少在某些方面）。</p><p>那么，为什么要专门谈论“其他人类”的全宇宙价值观，而不是更广泛的外星人群体呢？</p><p>答案是其他人类所持有的宇宙范围的价值观具有许多独特的属性：</p><ul><li>对于人类持有的任何宇宙范围的价值观，我们有<i>经验支持</i>，进化的物种有时会珍惜这些价值观。</li><li>更强大的是，我们有经验支持，认为<i>与我们非常相似的思想</i>可以逐渐珍惜这些价值观，这加强了高度相关性的理由，从而加强了基于 ECL 的合作的理由。</li><li>人类所持有的宇宙范围的价值观可以<i>通过</i>支持它们的人类方便地受益，例如，通过：<ul><li>支持持有它们的人类。</li><li>避免与持有它们的人类发生冲突。</li><li>听取持有它们的人类的建议。</li></ul></li></ul><p>这与非人类价值观截然不同，我们必须对他们的偏好进行更基本的猜测，例如：</p><ul><li>外星人可能更看重获得更多的空间而不是获得更少的空间。</li><li>外星人可能更喜欢与合作而不是容易发生冲突的其他参与者互动。</li></ul><h3>为什么要区分进化的外星人和错位的人工智能？</h3><p>首先，一个术语注释：“错位人工智能”是指其价值观与最初创造它们的进化物种的意图有很大不同的人工智能。如果一个遥远的物种与我们有着非常不同的价值观，并且成功地对齐了<i>他们</i>创建的人工智能系统，我会将它们视为“对齐”的人工智能。</p><p> （当然，“对齐的人工智能”本身将具有与进化的外星人相同的价值观。受益于他们的价值观将与受益于某些进化的外星人的价值观相同，因此他们不需要单独的类别。）</p><p>现在，为什么我要分别考虑进化的外星人和错位的人工智能的价值呢？有两个原因。</p><p>首先，与人工智能相比，进化后的外星人可能拥有与我们更相似的思维，并面临与我们更相似的决策。因此，有更充分的理由表明我们的决策与他们的决策更加相关，从而使基于 ECL 的合作更有理由。</p><p>其次，人工智能目前进展很快，我对人类创造和授权一致的人工智能系统的能力不太有信心。这（不祥的）表明，我们可能很快就会有独特的机会来受益或损害失调的人工智能系统的价值观。</p><hr><h1>致谢</h1><p>对于本文及相关帖子的有用评论和建议，感谢 Caspar Oesterheld、Emery Cooper、Lukas Gloor、Tom Davidson、Joe Carlsmith、Linh Chi Nguyen、Daniel Kokotajlo、Jesse Clifton、Richard Ngo、Anthony DiGiovanni、Charlotte Siegmann、Tristan Cook、西尔维斯特·科林和亚历克萨·潘。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnweuaua0f4c"> <span class="footnote-back-link"><sup><strong><a href="#fnrefweuaua0f4c">^</a></strong></sup></span><div class="footnote-content"><p>如需更多参考，请参阅<a href="https://longtermrisk.org/msr">本页</a>收集的所有内容，以及最近 Paul Christiano 撰写的<a href="https://www.lesswrong.com/posts/mm8sFBpPH3Bb2NhGg/three-reasons-to-cooperate">这篇文章</a>和 Johannes Treutlein 撰写的<a href="https://arxiv.org/pdf/2307.04879.pdf">这篇论文</a>。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnx18fvnjp5eq"> <span class="footnote-back-link"><sup><strong><a href="#fnrefx18fvnjp5eq">^</a></strong></sup></span><div class="footnote-content"><p>如果你知道我没有在这里列出的任何可能的含义 - 那么要么我不相信这是 ECL 的含义，要么它对我来说似乎没有足够的决策相关性，要么我没有考虑过它/忘记了，你应该让我知道。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnpneoqb5vw9"> <span class="footnote-back-link"><sup><strong><a href="#fnrefpneoqb5vw9">^</a></strong></sup></span><div class="footnote-content"><p>而今天，我们可以专注于将未来交给一个具有广泛能力和健康的文明，并将如何处理未来的决定交给他们。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnfbnqsghmnv4"> <span class="footnote-back-link"><sup><strong><a href="#fnreffbnqsghmnv4">^</a></strong></sup></span><div class="footnote-content"><p>当我讨论我们应该如何“更多地关心其他人类的全宇宙价值观”时，我专门指的是我们当前地球上的人类所持有的全宇宙价值观，而不是遥远的类人物种可能持有的价值观。但使这些价值观受益的原因是要提供证据，证明其他人在遥远的星球上（不仅仅是在这里，在地球上）也受益于我们的价值观。那么为什么要特别关注人类的价值观呢？原因是我们更有信心有人珍惜他们，并且通过支持支持他们的人很容易使他们受益。有关更多信息，请参阅<a href="https://docs.google.com/document/d/1XCZ-g_GAyZwfJfWHTRVyzptVU2_uI9tFWMG8x9j4C_o/edit#heading=h.y1hw7rervyd">此处</a>。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnd6bt2xf37fd"> <span class="footnote-back-link"><sup><strong><a href="#fnrefd6bt2xf37fd">^</a></strong></sup></span><div class="footnote-content"><p> “错位人工智能”是指其价值观与最初创造它们的进化物种的初衷截然不同的人工智能。如果一个遥远的物种与我们有着非常不同的价值观，并且成功地调整了他们创建的人工智能系统，我不会将它们算作“错位的人工智能”。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnwi0f1v4h1qk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwi0f1v4h1qk">^</a></strong></sup></span><div class="footnote-content"><p>或任何其他类型的非因果效应。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn4423tsgb79u"> <span class="footnote-back-link"><sup><strong><a href="#fnref4423tsgb79u">^</a></strong></sup></span><div class="footnote-content"><p>过早的承诺通常是一场赌博，可能会给<i>你</i>带来更好的讨价还价地位，但同时也会带来<i>每个人都</i>得到较低回报的风险。由于这是相当不合作的行为，因此 ECL 似乎可以阻止过早的承诺。因此，这可能是传播 ECL 知识的一个原因。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn9j6fzbxzuod"> <span class="footnote-back-link"><sup><strong><a href="#fnref9j6fzbxzuod">^</a></strong></sup></span><div class="footnote-content"><p>尽管<i>不</i>仔细的思考也可能会增加它们——因为它们本质上是由人类在学习和承诺做某些事情的顺序上犯错误造成的。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn8k49uv7ijvl"> <span class="footnote-back-link"><sup><strong><a href="#fnref8k49uv7ijvl">^</a></strong></sup></span><div class="footnote-content"><p>理想情况下，您还会考虑 A 派系和 B 派系相互受益的其他机会，因为您也可能提供有关这些的证据。更理想的是，您可能会考虑从涉及更多派系的交易中可能获得的收益。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnsocdvs8tsuk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefsocdvs8tsuk">^</a></strong></sup></span><div class="footnote-content"><p>尽管每个人的总努力也许仍然应该根据支持每套价值观和同情 ECL 的人数来分配。与整个宇宙相比，地球上的任何一组价值观（在 ECL 同情者中）是否代表性不足，可能会进行调整，在这种情况下，我们应该优先考虑这组价值观。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnygfd8lysjb"> <span class="footnote-back-link"><sup><strong><a href="#fnrefygfd8lysjb">^</a></strong></sup></span><div class="footnote-content"><p>这将是与我处于<i>同一</i>位置的人的行为的<i>最有力的</i>证据。但这不是我的大部分非因果影响的来源，因为即使是在足够多的参与者中提供的少量证据也会产生更大的影响。我在这里提出的假设是，可能有一些相当广泛的参与者仍然与你有一些关键的相似之处，你的决定为他们的决定提供了更多证据。并且您的价值观可能是（或与之相关）关键相似之处之一。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn2f0pffnolcf"> <span class="footnote-back-link"><sup><strong><a href="#fnref2f0pffnolcf">^</a></strong></sup></span><div class="footnote-content"><p>尽管我个人对关注上行和下行的价值观有些同情，所以这对我全面考虑的观点没有太大影响。</p></div></li><li class="footnote-item" role="doc-endnote" id="fniuznazkhk0b"> <span class="footnote-back-link"><sup><strong><a href="#fnrefiuznazkhk0b">^</a></strong></sup></span><div class="footnote-content"><p>即使灭绝的外星人与我们有着共同的价值观，他们选择优先考虑非人工智能灭绝风险的选择仍然可能是事前净积极的。例如，他们可能以一种将人工智能接管风险降低 0.1% 并将非人工智能灭绝风险增加 0.1001% 的方式重新分配资源。增加的 0.0001% 的 x 风险可能值得在 0.1% 的世界中留下空白空间而不是人工智能控制的空间。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnpe2xs41o2x7"> <span class="footnote-back-link"><sup><strong><a href="#fnrefpe2xs41o2x7">^</a></strong></sup></span><div class="footnote-content"><p>特别是，ECL 建议我们应该低估外星人的利益，因为他们与我们的关联程度平均低于具有我们价值观的文明的平均关联程度。 （做出相关决定时。）</p></div></li><li class="footnote-item" role="doc-endnote" id="fn40zg3jy06vx"> <span class="footnote-back-link"><sup><strong><a href="#fnref40zg3jy06vx">^</a></strong></sup></span><div class="footnote-content"><p>作为持有这种观点的人的一个例子：Eliezer Yudkowsky 的<a href="https://www.facebook.com/yudkowsky/posts/10152588738904228">这篇 Facebook 帖子</a>开头是“我认为我关心的事物在你的本地心理本体中会被想象为具有某种有形的红色体验或绿色体验，并且我宁愿这样的人没有痛苦的经历。我所看重的幸福更为复杂。”尤德科夫斯基还在其他地方写过关于价值的复杂性和脆弱性的文章，例如<a href="https://www.lesswrong.com/posts/GNnHHmm8EzePmKzPk/value-is-fragile">这里</a>。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnstsq0mzojoo"> <span class="footnote-back-link"><sup><strong><a href="#fnrefstsq0mzojoo">^</a></strong></sup></span><div class="footnote-content"><p> “错位人工智能”是指其价值观与最初创造它们的进化物种的初衷截然不同的人工智能。如果一个遥远的物种与我们有着非常不同的价值观，并且成功地调整了他们创建的人工智能系统，我不会将它们算作“错位的人工智能”。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn63f2sg768l9"> <span class="footnote-back-link"><sup><strong><a href="#fnref63f2sg768l9">^</a></strong></sup></span><div class="footnote-content"><p>特别是，ECL 建议我们应该低估人工智能带来的好处，因为它们与我们的相关性不如具有我们价值观的参与者。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/EeXSjvyQge5FZPeuL/implications-of-evidential-cooperation-in-large-worlds#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/EeXSjvyQge5FZPeuL/implications-of-evidential-cooperation-in-large-worlds<guid ispermalink="false"> EeXSjvyQge5FZPeuL</guid><dc:creator><![CDATA[Lukas Finnveden]]></dc:creator><pubDate> Wed, 23 Aug 2023 00:43:45 GMT</pubDate> </item><item><title><![CDATA[South Bay Casual Group Walk]]></title><description><![CDATA[Published on August 22, 2023 10:43 PM GMT<br/><br/><p>与我们一起徒步穿越帕洛阿尔托的贝兰兹自然保护区。一开始，我们将决定是否要步行<a href="https://goo.gl/maps/iarMq8pHUbjELrcr9"><u>木板路</u></a>（大约 3 英里，有很多鸟）或去<a href="https://goo.gl/maps/hF5dGD4tMS1foMPf8"><u>Byxbee 公园</u></a>（大约 5 英里，概念艺术雕塑）。</p><p>步行的步伐将是随意而放松的。如果您正在阅读本文，欢迎您和任何朋友加入。<br></p><p><strong>日期：</strong> 2023 年 9 月 9 日星期六</p><p><strong>下午2点</strong><strong>开会</strong></p><ul><li>我们将于下午 2:15 开始步行。如果您迟到或想稍后与我们见面，请告诉我 (southbaymeetup@gmail.com)。</li><li>没有具体的结束时间，大概是下午5点左右。之后我们可能会去吃晚饭。宜家距离酒店 2.4 英里😏</li></ul><p><strong>地点：</strong><a href="https://goo.gl/maps/2cFoETZuJ9cY5cPU7">贝兰兹自然保护区</a><br>2500 Embarcadero 路，帕洛阿尔托，CA 94303</p><ul><li>我们将在位于自然中心东北部的<a href="https://goo.gl/maps/8L1swVhdJnpdR39DA">户外野餐桌</a>见面（见下图）</li><li>免费停车场位于桌子旁边的停车场</li></ul><p>带上水瓶、帽子和防晒霜。步行道不会被遮挡。我会多带几瓶水，以防你忘记。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PK9u3TJrxmbSCJBFy/plnmenfzbcfr2o59wrej" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PK9u3TJrxmbSCJBFy/hxg3k0ebvmueh65mg7w1 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PK9u3TJrxmbSCJBFy/dfewntkcqaipw7tukku1 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PK9u3TJrxmbSCJBFy/qrgybnrjbhdekcp2i3fq 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PK9u3TJrxmbSCJBFy/zqai6dua6ilkehcqp74i 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PK9u3TJrxmbSCJBFy/svgmo3pifk9id1j4olqk 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PK9u3TJrxmbSCJBFy/w62qfqvt0x8vqaqbl314 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PK9u3TJrxmbSCJBFy/hl2btdjbhqsou6wpkfjl 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PK9u3TJrxmbSCJBFy/jzazrrwcvn9oerg0tclk 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PK9u3TJrxmbSCJBFy/rcpemisx5aonk4gcvawf 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/PK9u3TJrxmbSCJBFy/bdfbmwkkafjujkxdsu1v 1763w"></figure><br/><br/> <a href="https://www.lesswrong.com/events/PK9u3TJrxmbSCJBFy/south-bay-casual-group-walk#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/events/PK9u3TJrxmbSCJBFy/south-bay-casual-group-walk<guid ispermalink="false"> PK9u3TJrxmbSCJBFy</guid><dc:creator><![CDATA[allisona]]></dc:creator><pubDate> Wed, 23 Aug 2023 02:33:12 GMT</pubDate></item><item><title><![CDATA[Walk while you talk: don't balk at "no chalk"]]></title><description><![CDATA[Published on August 22, 2023 9:27 PM GMT<br/><br/><p>前几天，在与朋友进行了长时间的交谈后，我做了回顾性笔记，回忆了我们讨论过的内容。 （我写了 50 多条。这可不是一个小样本。） 部分时间我们步行；部分时间我们步行。对于其他部分，我们住在大致相同的地方。在写笔记时，我发现我遗漏了我们所说的那些固定部件的一半（并且忘记了顺序）。我回忆起并行行走的部分时没有遇到这样的问题。</p><p>我以前就注意到这种差异，但这是它变得明显的时候。一边说话一边走路对记住所说的话有很大帮助。</p><p>这可能是我思维运作方式的一个怪癖，并不适用于所有人。我怀疑我是完全独一无二的，所以它可能至少适用于其他一些人，即使不是所有人。</p><h1>为什么这会起作用？</h1><p>这部分是合理的猜测，没有明确证实，如果您只是使用该方法，那么并不重要。</p><p>这里发生的事情似乎是，我的情景记忆将我看到的周围环境和我听到的对话进行编码。后来，当我回忆这件事时，我会想起我周围所看到的事情，以帮助我想起这件事，而我听到的（或当时根据我听到的所解释的）也随之而来。</p><p>我认为步行有两个好处：</p><ul><li>步行意味着我将在对话的不同阶段处于不同的地方，因此每个视觉记忆（确切的地点及其周围环境）与较少的听觉/语义记忆（所说的事情）相关联，因此关联更强烈。</li><li>在空间中移动会强制执行一条连续的路径（除非我可以传送，所以也许在对话期间避免传送），这很容易从几个点进行插值和“走过”——比不可预测的对话转换容易得多。</li></ul><p>我不知道哪个更重要。</p><h1>推论和扩展</h1><p>这里的机制取决于你的移动，而不是与你交谈的人。如果你只关心自己的记忆（或者环境另有要求），你可以在独自行走时打电话给他们并获得相同的效果。 （我已经尝试过这个。它有效。）</p><p>这种方法也同样适用于你所听的片面演讲，尽管这些演讲往往更容易预测。</p><p>这里的机制取决于运动和环境变化，而不是具体的步行。我希望如果您骑自行车/驾驶/乘坐车辆，只要您在这样做时观察路过的事物，就会得到同样的效果。对于步行来说，这很容易：你没有车辆阻挡你的视线，而且你会面临来自各个方向的轻微的、需要注意的风险。</p><p>如果你关心说话的顺序，就不要重复同一个地方两次。重复位置会使您的路径与其自身重叠，从而使顺序回忆变得复杂。 （这个错误在我一开始的例子中造成了一些混乱。）</p><p>显然，大脑对某些抽象空间的建模与现实生活中的导航方式类似。 （需要引文。相关关键词“海马体”和“你玩过现代电子游戏吗？”）如果你一边说话一边在复杂的电子游戏中移动，你可能会得到同样的效果。这可能需要完整的 VR。 （我没有尝试过这个。）</p><br/><br/> <a href="https://www.lesswrong.com/posts/trZSdr49bygabxQtG/walk-while-you-talk-don-t-balk-at-no-chalk#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/trZSdr49bygabxQtG/walk-while-you-talk-don-t-balk-at-no-chalk<guid ispermalink="false"> trZSdr49bygabxQtG</guid><dc:creator><![CDATA[dkl9]]></dc:creator><pubDate> Tue, 22 Aug 2023 21:27:48 GMT</pubDate> </item><item><title><![CDATA[State of Generally Available Self-Driving]]></title><description><![CDATA[Published on August 22, 2023 6:50 PM GMT<br/><br/><p><span>在网上进行了大量讨论之后，人们试图争论自动驾驶技术的发展方向，但似乎对技术目前的发展方向感到相当困惑，我想对当前的状态进行一些概述。</span></p><p>主要有两种方式：出租车和私家车。有许多公司已经与安全驾驶员和/或“值得信赖的测试人员”骑手进行了测试，但据我所知，只有两个[编辑：三个？四个？]公司向公众开放商业乘车服务，没有任何人坐在驾驶座上：</p><p></p><ul><li><p> <a href="https://waymo.com/">Waymo</a> （谷歌旗下）自<a href="https://waymo.com/blog/2020/10/waymo-is-opening-its-fully-driverless.html">2020 年</a>以来一直在亚利桑那州凤凰城运营完全无人驾驶汽车作为<a href="https://waymo.com/waymo-one/">商业乘车服务</a>。他们曾经有一个等待名单，但现在任何人都可以下载该应用程序并尝试。他们刚刚扩展到<a href="https://waymo.com/blog/2023/08/waymos-next-chapter-in-san-francisco.html">旧金山</a>，并有<a href="https://waymo.com/blog/2022/10/next-stop-for-waymo-one-los-angeles.html">洛杉矶</a>和<a href="https://waymo.com/blog/2023/08/waymo-one-heads-to-austin.html">奥斯汀</a>的<a href="https://waymo.com/waitlist/">候补名单</a>。截至<a href="https://waymo.com/blog/2023/08/waymos-next-chapter-in-san-francisco.html">2023-08 年，</a>他们声称每周为 1 万名乘客提供服务。</p></li><li><p> <a href="https://getcruise.com/">Cruise</a> （通用汽车旗下）自<a href="https://getcruise.com/news/blog/2022/were-going-commercial/">2022 年</a>以来一直在旧金山运营完全无人驾驶车辆作为商业乘车服务。他们现在似乎还覆盖了<a href="https://getcruise.com/rides/">奥斯汀和菲尼克斯</a>，截至<a href="https://gmauthority.com/blog/2023/08/gms-cruise-now-has-about-400-driverless-vehicles-on-the-road/">2023 年 8 月 2 日</a>，每周也有 1 万名乘客。</p></li><li><p> [添加于2023-08-23] 很难说，因为最好的来源是中文的，但看起来 Apollo（百度）也符合这一点。截至<a href="https://www.digitimes.com/news/a20221230VL201/apollo-go-av.html">2022年底</a>：“除了武汉之外，百度现在还在重庆提供商业化的无人驾驶、无安全员的自动驾驶叫车服务。北京很快也会加入到这个名单中。”</p></li><li><p> [2023-08-23添加] 关于这方面的英文互联网信息更少，但另一家中国公司<a href="https://pony.ai/">pony.ai</a>也可能在运营完全无人驾驶的商业叫车服务。 “小马智行表示，已在北京和广州推出完全无人驾驶的自动驾驶网约车服务。” ( <a href="https://www.globaltimes.cn/page/202303/1287492.shtml">2023-03-17</a> )</p></li><p></p></ul><p>对于私家车，目前可以获得的最高自动化程度是<a href="https://en.wikipedia.org/wiki/Self-driving_car#Levels_of_driving_automation">3 级</a>。这些系统在使用时，驾驶员座位上的人可以安全合法地读书，否则就不会集中注意力。如果系统遇到无法处理的情况，它会向驾驶员发出警报，如果驾驶员不采取控制措施，它会自动停车。这里的一种选择，也许是唯一的商用选择，是梅赛德斯的 Drive Pilot，他们<a href="https://www.therobotreport.com/mercedes-rolls-out-level-3-autonomous-driving-tech-in-germany/">于 2022 年</a>在德国推出。它只在时速低于 40 英里的高速公路上运行（本质上是走走停停的交通），但梅赛德斯在使用时要承担法律责任。他们<a href="https://media.mbusa.com/releases/release-1d2a8750850333f086a722043c01a0c3-conditionally-automated-driving-mercedes-benz-drive-pilot-further-expands-us-availability-to-the-countrys-most-populous-state-through-california-certification">声称，</a>他们的 2024 年（从今年年底开始）美国版 S 级和 EQS 轿车将配备 DrivePilot 作为选装件，并在加利福尼亚州和内华达州获得批准。其他国家可能还有其他 L3 系统——我很难判断到底是用什么型号推出的，以及它是否符合 L3 的资格。</p><p>总体而言，目前的状态已经超出了“这只是一个演示”，但它仍然受到地点和当前条件的严重限制。</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid021KSjbxcSAbkn7bm51zoVvAgsAnoH8UDVu3mt1cmsoWLEHtTJ5vgmk9DtNYNXf36dl">facebook</a> , <a href="https://mastodon.mit.edu/@jefftk/110934739828841091">mastodon</a></i></p><br/><br/> <a href="https://www.lesswrong.com/posts/3KdbnsGnzSyiujz7Z/state-of-generally-available-self-driving#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/3KdbnsGnzSyiujz7Z/state-of-generally-available-self-driven<guid ispermalink="false"> 3KdbnsGnzSyiujz7Z</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Tue, 22 Aug 2023 18:50:01 GMT</pubDate></item></channel></rss>