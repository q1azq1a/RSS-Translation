<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 30 日星期四 20:12:49 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[What's next for the field of Agent Foundations?]]></title><description><![CDATA[Published on November 30, 2023 5:55 PM GMT<br/><br/><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Mon, 27 Nov 2023 16:09:49 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Mon, 27 Nov 2023 16:09:49 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>Alexander、Matt 和我想讨论一下 Agent Foundations (AF) 领域，它的现状以及未来如何加强和发展它。</p><p>首先，我们每个人都会发表第一条信息，概述我们目前的一些关键信念和悬而未决的问题。我们的想法不是给出全面的看法，而是挑选出我们每个人关心/认为重要和/或我们感到困惑/想要讨论的 1-3 件事。我们可能会回应以下提示的某些子集：</p><blockquote><p>您认为AF的视野在哪里？您如何看待 AF 在更大的联盟格局中/在让人工智能未来顺利发展方面所扮演的角色？您希望看到它去哪里？您使用什么作为实现这一目标的关键瓶颈？对于我们如何克服这些问题，您有什么想法？</p></blockquote><p>在我们正确启动之前，有几件事似乎值得澄清：</p><ul><li>粗略地说，代理基础是指旨在<i>理解代理、智能行为和一致性基础的</i>概念性和正式工作。特别是，我们指的是比人们所谓的“老式 MIRI 型代理基础”更广泛的东西，通常由决策理论和逻辑等领域提供信息。</li><li>我们不会具体讨论代理基金会研究背后的价值或变革理论。我们认为这些都是重要的对话，但在这次具体对话中，我们的目标是不同的，即：假设 AF 有价值，我们如何加强这一领域？</li></ul><h1>它应该看起来更像一个正常的研究领域吗？ </h1></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6KYCb9X2CKSvG52ky-Mon, 27 Nov 2023 16:15:42 GMT" user-id="6KYCb9X2CKSvG52ky" display-name="mattmacdermott" submitted-date="Mon, 27 Nov 2023 16:15:42 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>马特麦克德莫特</b></section><div><p>目前，我对代理基金会感兴趣的主要问题是，它是否应该继续其当前的特殊形式，或者是否应该开始看起来更像一个普通的学术领域。</p><p>我也有兴趣讨论变革理论，只要它与其他问题有关。</p><h1>为什么要代理基金会？</h1><p>我自己对代理基础工作作为联盟研究的一个潜在富有成果的方向的推理是：</p><ul><li>大多数错位威胁模型都是关于代理追求我们希望他们不追求的目标（我认为这没有争议）</li><li>关于代理的现有形式主义似乎对于理解或避免这些威胁没有那么有用（同样可能没有那么有争议）</li><li>开发新的、更有用的似乎很容易处理（这可能更有争议）</li></ul><p>我认为这可能很容易处理的主要原因是，到目前为止，还没有投入太多的时间来尝试做到这一点。从先验的角度来看，这似乎是一种你可以得到很好的数学形式主义的东西，到目前为止，我认为我们还没有收集到太多你不能得到的证据。</p><p>所以我想我想让大量具有不同专业领域的人来思考这个问题，我希望他们中的一小部分人发现了一些根本上重要的东西。一个关键问题是该领域目前的运作方式是否有利于这一点。</p><h1>它需要一个新名字吗？ </h1></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="7RFsGHYEynK4LDgGb-Mon, 27 Nov 2023 16:16:25 GMT" user-id="7RFsGHYEynK4LDgGb" display-name="Alexander Gietelink Oldenziel" submitted-date="Mon, 27 Nov 2023 16:16:25 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>亚历山大·吉特林克·奥尔登齐尔</b></section><div><p></p><p>广义的特工基金会是否需要一个新名称？</p><p> “基金会特工”这个名字是被诅咒了吗？</p><p>我听到的建议是</p><p>“什么是心灵”，“什么是代理人”。 “数学对齐”。 “代理机制”</p><h1>认知多元主义和影响之路</h1></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Mon, 27 Nov 2023 16:42:17 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Mon, 27 Nov 2023 16:42:17 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>一些思考片段：</p><p> (1) 澄清和创造有关代理基金会范围的共同知识并加强认知多元化</p><ul><li>我认为，对于有意义地提高我们对代理、智能行为等基本现象的理解的努力来说，拥有相对多元化的角度组合是很重要的。世界是非常详细的，诸如代理/智能行为/等现象。看起来可能特别“混乱”/详细的现象。就每一种科学方法都必然抽象出一堆细节而言，我们并不先验地知道哪些现实部分<i>可以</i>抽象出来，哪些不适合在什么背景下抽象，因此对同一现象有多种观点是一种富有成效的方法来“三角测量”所需的现象。</li><li>这就是为什么我非常热衷于拥有一定范围的 AF，包括但不限于“老式 MIRI 型 AF”。在我看来，该领域已经开始产生更多的多元化观点，这让我感到兴奋。我更赞成<ul><li>在 AF<i>的范围内创造更多的共同知识——我希望在方法论、知识体系、认知实践和基本假设方面具有相对的广度，而在该领域的主要问题/认知目标方面则相对狭窄。</i></li><li><i>进一步增加多元化——我认为有一些相当明显有趣的角度、领域、知识基础可以用来解决 AF 的问题，并融入当前 AF 和对齐的对话中。</i></li><li>致力于在这些多元方法之间创建<i>和维护表面积——如上所述的“三角测量”只有在不同的观点交互和交流时才能真正发生，因此我们需要可以发生这种情况的地方和接口</i></li></ul></li></ul><p>(2) AF 处于“影响路径”的哪个位置</p><ul><li>在高层次上，我认为有必要问一下：需要输入 AF 的（认知）输入是什么？我们希望 AF 产生哪些认知输出，我们希望它们输入到哪里，以便在这条链的末端我们得到诸如“安全且一致的人工智能系统”或类似的东西？</li><li>就此而言，我对 AF 拥有紧密的接口/迭代循环以及 AI 对齐工作的更多应用方面（例如可解释性、评估、对齐建议）感到特别兴奋。</li></ul><p> (3) 可能的提示：如果您有 2 个有能力的 FTE 和 500&#39;000 美元用于 AF 现场建设，您会做什么？</p><p> ..由于时间不够，暂时就到此为止。<br></p><h1>深厚的专业知识</h1></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="7RFsGHYEynK4LDgGb-Mon, 27 Nov 2023 16:53:03 GMT" user-id="7RFsGHYEynK4LDgGb" display-name="Alexander Gietelink Oldenziel" submitted-date="Mon, 27 Nov 2023 16:53:03 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>亚历山大·吉特林克·奥尔登齐尔</b></section><div><p>我最喜欢的博文之一是舒伯特的<a href="https://stefanschubert.substack.com/p/against-cluelessness-pockets-of-predictability?utm_source=profile&amp;utm_medium=reader2">“反对可预测性的无知口袋</a>”，介绍了“可预测性的口袋”：</p><blockquote><p> (...)关于低方差可预测性的直觉长期以来阻碍了科学和技术的进步。*** 世界的大部分内容曾经对人类来说是不可知的，人们可能由此进行概括，认为系统的研究不会有回报。但事实上，可知性差异很大：即使使用当时的工具，人们也可以理解一些可知性或可预测性（例如，像行星运动这样的自然简单系统，或者像低摩擦平面这样的人为简单系统）。通过这些可知性的口袋，我们可以逐渐扩展我们的知识——因此世界比看起来更可知。<a href="https://delong.typepad.com/files/gellner-plough.pdf"><u>正如欧内斯特·盖尔纳（Ernest Gellner）指出的那样</u></a>，科学和工业革命很大程度上在于认识到世界是令人惊讶地可知的：</p><p> “对自然的成功系统研究以及将研究结果应用于增加产出的通用或二阶发现是可行的，而且一旦启动，并不太困难。”</p></blockquote><p>我真的很喜欢这种思考知识和科学发展的可能性的方式。我在一致性领域看到了非常相似的“可预测性怀疑论”。</p><p>这种对可预测性的怀疑反映在基于实验室的联盟团体的无限乐观和厄运者的无限悲观中。</p><p>我想介绍一下“深厚的专业知识”的想法。也就是说，我认为大部分科学进步是由一小群人取得的，这些人大多是从外部不透明的（“口袋”），在相当长的时间内建立了高度具体的知识（“深厚的专业知识”）。</p><p>这些口袋是</p><ul><li>通常高度不透明且从外部难以辨认。</li><li>进展往往是局部的且难以辨认。 Pocket 已经解决了问题 X 的子问题 A、B 和 C，但由于某种原因，他们的方法还无法解决 D。这阻止了他们完全回答问题 X 或构建技术 Y</li><li>进展是在很长一段时间内取得的</li><li>有很多假先知。并不是每个声称拥有（深厚）专业知识的人实际上都在做有价值的事情。有些是彻头彻尾的欺诈，另一些则只是找错了对象。</li><li>据保守估计，90-95% 的 (STEM) 学术界正在从事“可预见的无关紧要”、p-hacking 和/或在其他方面都很糟糕的工作。<br>所以学术界大部分确实没有做有用的工作。但有些口袋是</li><li>口袋的差异很大。</li></ul><p>为了技术协调的目的，我们需要像 VC 一样思考：</p><p>投注范围广泛、高度具体的投注</p><p>在我看来，我们目前只雇用了世界科学人才的一小部分。</p><p>虽然Alignment现在吸引了一大批有前途的年轻人，但他们的大部分精力和才华都浪费在了重新发明轮子上。</p><h1>如何获得一定范围的投注</h1></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6KYCb9X2CKSvG52ky-Mon, 27 Nov 2023 17:02:28 GMT" user-id="6KYCb9X2CKSvG52ky" display-name="mattmacdermott" submitted-date="Mon, 27 Nov 2023 17:02:28 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>马特麦克德莫特</b></section><div><p>每个人都提到过想要获得广泛的特定赌注或类型的人。我们可以将其视为已读并讨论如何去做吗？</p><p> （尽管如果我们要谈论我们希望这个领域看起来如何，这可能是最自然的第一位） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Mon, 27 Nov 2023 17:19:08 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Mon, 27 Nov 2023 17:19:08 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>太好了。让我们快速盘点一下。</p><p>我认为我们都对某种版本的“押注于广泛/复数范围的高度具体的押注”感兴趣。也许我们应该在某个时候更多地讨论这个问题。</p><p>为了帮助流程顺利进行，首先更具体一些可能会很有用。我建议我们按照以下提示进行操作：</p><blockquote><p>如果您有 2 个有能力的 FTE 和 500,000 美元用于 AF 现场建设，您会做什么？</p></blockquote><h1>抗MATS </h1></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6KYCb9X2CKSvG52ky-Mon, 27 Nov 2023 17:25:32 GMT" user-id="6KYCb9X2CKSvG52ky" display-name="mattmacdermott" submitted-date="Mon, 27 Nov 2023 17:25:32 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>马特麦克德莫特</b></section><div><p>我将给出我昨天与亚历山大谈论的想法作为我的第一个答案。</p><p>可能有大量在特定领域拥有专业知识的学者，这些领域似乎对对齐可能有用，并且可能对进行对齐研究感兴趣。但他们可能不知道其中存在联系，也不知道任何有关对齐的事情。与初级研究人员不同的是，他们不会参加一些 MATS 类型的项目来学习它。</p><p>因此，我们的想法是“与其让高级对齐研究人员帮助初级人员进行对齐研究，不如让初级对齐人员帮助其他领域的高级研究人员进行对齐研究？”抗MATS。</p><p>我们有一大批初级人员，他们读过很多关于一致性的文章，但没有得到指导。并且有大量潜在相关主题的经验丰富的研究人员对对齐一无所知。因此，我们派一名初级协调人员担任研究助理，或者与复杂性科学、主动推理、信息论或其他我们认为可能存在联系的领域经验丰富的研究人员一起工作，他们一起寻找一个，如果他们找到了也许会制定一个新的研究议程。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Mon, 27 Nov 2023 17:35:30 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Mon, 27 Nov 2023 17:35:30 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>是的，我喜欢这个方向。我同意问题陈述。我不确定“初级帮助高级人员”是否有帮助，但不确定这是把事情做好的关键。我认为这可能是一些症结/瓶颈：</p><ul><li> “正确自我选择”：“资深学者”如何看待“反MATS”计划，又是什么让他们决定这么做？<ul><li>我认为你在这里需要的一件事是为协调代理基金会感兴趣的各种问题创建一个表面区域，以便具有相关专业知识的人可以理解这些问题以及他们的专业知识与他们的相关性</li><li>为了找到更资深的人才，我认为你需要一些诸如研讨会、会议和网络之类的东西，而不是依赖开放的应用程序。 </li></ul></li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6KYCb9X2CKSvG52ky-Mon, 27 Nov 2023 17:37:11 GMT" user-id="6KYCb9X2CKSvG52ky" display-name="mattmacdermott" submitted-date="Mon, 27 Nov 2023 17:37:11 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>马特麦克德莫特</b></section><div><p>我认为你必须单独接触研究人员，看看他们是否愿意参与。</p><p>最直接的例子是那些在明显相关的领域工作的人，或者已知对联盟有一定兴趣的人（我认为 Dan Murfet 和 SLT 的情况都是如此？）或者个人认识一些联盟人员。我的猜测是这个类别相当大。</p><p>除此之外，如果你必须向某人冷酷地推销对齐的相关性（一般来说以及作为他们的研究问题），我认为这要困难得多。</p><p>例如，我不认为你可以向某人发送一个很好的介绍资源，为“机构的基础研究可能有助于避免强大人工智能带来的风险”提供常识性案例，尤其是没有任何具有以下特征的资源：合法性使学者可以轻松地证明其研究项目的合理性。 </p><p></p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Mon, 27 Nov 2023 17:41:33 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Mon, 27 Nov 2023 17:41:33 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>是的，很酷。我想另一个问题是：一旦你确定了他们，他们需要什么才能成功？</p><p>我肯定也看到了失败模式，其中有人只或过于关注“代理难题”，而没有将这些问题与人工智能风险/一致性联系起来的优势。询问/调查机构的某些方式与一致性越来越相关，因此我认为来自目标领域（此处：人工智能风险/一致性）的清晰/足够强的“信号”来指导搜索/研究非常重要方向</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6KYCb9X2CKSvG52ky-Mon, 27 Nov 2023 17:42:07 GMT" user-id="6KYCb9X2CKSvG52ky" display-name="mattmacdermott" submitted-date="Mon, 27 Nov 2023 17:42:07 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>马特麦克德莫特</b></section><div><p>是的，我同意这一点。</p><p>我想知道关注代理是否甚至不是正确的角度，而“联盟理论”更相关。对于这些研究人员来说，最有用的可能是让他们清楚地了解协调的基本问题，如果他们认为考虑到他们的专业知识，专注于代理是解决这些问题的好方法，那么他们就可以这样做，但如果他们不认为这是一个好的角度，他们可以追求不同的角度。</p><p>我确实认为，拥有一个精通联盟文献的人（即提议的受训者）可能会非常有影响力。有很多想法对于对齐社区中的人们来说非常明显，因为它们经常被谈论（例如，训练信号不一定是训练模型的目标），但对于从第一原理思考的人来说可能并不明显。一个来自其他领域的忙碌的人可能会错过一些东西，最终创建一个完整的研究愿景，但这个愿景却被一个障碍所拖垮，这对于读过很多 LW 的缺乏经验的研究人员来说是显而易见的。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="7RFsGHYEynK4LDgGb-Mon, 27 Nov 2023 17:46:57 GMT" user-id="7RFsGHYEynK4LDgGb" display-name="Alexander Gietelink Oldenziel" submitted-date="Mon, 27 Nov 2023 17:46:57 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>亚历山大·吉特林克·奥尔登齐尔</b></section><div><p>SeniorMATS - 人工智能安全研究人员职业生涯暮年的养老院</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Mon, 27 Nov 2023 17:48:37 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Mon, 27 Nov 2023 17:48:37 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>是的，良好的表面积对于解决问题很重要。我认为现在已经有很多这方面的专业知识了。从介绍性材料，到具有举办研究静修经验的人，以提供与空间的良好初步接触，再到（如您所描述的）可以一路提供帮助/协助/促进的个人。还值得一问的是，对等环境应该/可能扮演什么角色（例如 AF 不和谐类型的事物，和/或更高带宽的事物）</p><p>此外，找到良好的一般“攻击线”在这里可能非常有用。例如，我喜欢埃文的“模型有机体”，它是一个非常好的/生成框架，使 AF 类型的工作能够更有效地面向具体/应用的对齐工作。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6KYCb9X2CKSvG52ky-Mon, 27 Nov 2023 17:48:52 GMT" user-id="6KYCb9X2CKSvG52ky" display-name="mattmacdermott" submitted-date="Mon, 27 Nov 2023 17:48:52 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>马特麦克德莫特</b></section><div><p>对齐新手培训 - 没有经验的学员实际上教老年人（ANTIMATS） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Mon, 27 Nov 2023 17:52:31 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Mon, 27 Nov 2023 17:52:31 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>我的模型在这里不太强调“juniro 研究人员的指导”，而是更普遍地强调“为具有相关专业知识的人创造合适的表面积”；做到这一点的一种方法可能是让初级研究人员接触更多的阿尔金特，但我认为这不应该成为核心支柱。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="7RFsGHYEynK4LDgGb-Mon, 27 Nov 2023 17:52:37 GMT" user-id="7RFsGHYEynK4LDgGb" display-name="Alexander Gietelink Oldenziel" submitted-date="Mon, 27 Nov 2023 17:52:37 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>亚历山大·吉特林克·奥尔登齐尔</b></section><div><p>我在具有科学潜力的学术（或非学术）研究人员中寻找的三件事是</p><ol><li>对齐pilled - 重要。</li></ol><p>你不希望他们跑去做能力工作。人们说他们关心“一致性”，但实际上并不关心，这几乎是一种致命的失败。通常，在这种变体中，对齐和安全成为一个模糊的流行词，无论他们的爱好是什么，都会被选择。</p><p> 2.相信“理论”——他们认为对齐是一个深层次的技术问题，并相信我们需要科学和概念上的进步。实验很重要，但纯粹的经验不足以保证安全。许多人得出的结论（也许是正确的！）技术协调太困难，治理就是答案。</p><p> 3. 吞下惨痛的教训——不幸的是，仍然有研究人员不承认LLM在这里。令人惊讶的是，这些在人工智能和机器学习部门尤其常见。加里·马库斯以各种形式追随者。更普遍的是，存在一种对深度学习实践不感兴趣的失败模式。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="6KYCb9X2CKSvG52ky-Mon, 27 Nov 2023 17:53:39 GMT" user-id="6KYCb9X2CKSvG52ky" display-name="mattmacdermott" submitted-date="Mon, 27 Nov 2023 17:53:39 GMT" user-order="3"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>马特麦克德莫特</b></section><div><blockquote><p>“为具有相关专业知识的人创造合适的表面积”</p></blockquote><p>看来是对的。为从其他领域进入该领域的更多资深人士创建一个同行网络似乎也能产生同样的影响。</p><h1>吸引研究人员</h1></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="7RFsGHYEynK4LDgGb-Mon, 27 Nov 2023 18:06:21 GMT" user-id="7RFsGHYEynK4LDgGb" display-name="Alexander Gietelink Oldenziel" submitted-date="Mon, 27 Nov 2023 18:06:21 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>亚历山大·吉特林克·奥尔登齐尔</b></section><div><p>你无法用金钱说服学者。你用想法说服他们。学者是心理专家。他们多年来磨练了非常具体的心理技能。为了说服他们去做某件事，你必须让他们相信 1. 问题是可以处理的 2. 富有成果且有趣，最重要的是 3. 容易受到该学术研究人员工具包中特定方法的影响。</p><p>马特提出的另一个想法是 BlueDot 风格的“广义代理基础”课程。</p><p> \欧几里得几何咆哮</p><p>欧几里得几何对西方知识分子思想的影响是巨大的。但有点令人惊讶的是：欧几里得几何几乎没有任何应用。这里我指的是欧几里得几何，它是在《欧几里得几何原本》中提出的基于证明的欧几里得几何的非正式形式系统。</p><p>这种影响实际上是如何发挥作用的，非常有趣。许多思想家都引用欧几里得几何学作为他们思想的决定性因素——笛卡尔、牛顿、本杰明·富兰克林、康德等等。我认为原因是它形成了概念、理论进展的“模型有机体”。证明的概念（有趣的是，这是西方数学传统所独有的，尽管15世纪的印度喀拉拉邦在牛顿之前发现了泰勒级数）、真正确定性的概念、建模和理想化的概念、堆叠许多引理的想法等。</p><p>我认为这种“成功的概念/理论进展”对于激励人们无论是在历史上还是在现在都是非常重要的。</p><p>我认为这样一门 AF 课程的目的是向学术研究人员展示概念对齐工作具有真正的智力实质</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Mon, 27 Nov 2023 18:09:21 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Mon, 27 Nov 2023 18:09:21 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>[此时我们已经耗尽了时间并决定停止]</p></div></section><div></div><br/><br/> <a href="https://www.lesswrong.com/posts/hZSwNhmzJ3YfXEAWX/what-s-next-for-the-field-of-agent-foundations#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/hZSwNhmzJ3YfXEAWX/what-s-next-for-the-field-of-agent-foundations<guid ispermalink="false"> hZSwNhmzJ3YfXEAWX</guid><dc:creator><![CDATA[Nora_Ammann]]></dc:creator><pubDate> Thu, 30 Nov 2023 17:55:13 GMT</pubDate> </item><item><title><![CDATA[AI #40: A Vision from Vitalik]]></title><description><![CDATA[Published on November 30, 2023 5:30 PM GMT<br/><br/><p>对于我身边的人来说，这是残酷的。每个人都充满敌意，甚至比平时还要严重。所采取的极端立场，似乎显然是正确的。不是对称的，但仍然是从各个方向看。据我所知，对过去两周发生的事情的不断断言完全是错误的，这很大程度上是实施良好的媒体宣传的结果。更频繁、更大声地重复有缺陷的逻辑。</p><p>其中的亮点是 Vitalik Buterin 提出的，他发表了一篇题为“ <a href="https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html" target="_blank" rel="noreferrer noopener">我的技术乐观主义</a>”的文章，提出了他所谓的 d/acc 防御性（或去中心化、差异化）加速主义。他带来了足够的细微差别和仔细的思考，以及关于存在风险和未来各种麻烦的清晰陈述，以获得担忧者的强烈积极反应。尽管他承认存在风险和未来的危险，并且需要采取行动缓解未来的问题，但他带来了足够的可信度和业绩记录以及足够的陈词滥调，以获得 e/acc 人群的强烈支持。</p><span id="more-23615"></span><p>我们最终能否找到共同点并进行富有成效的讨论？这会很艰难，但也许我们的差距并不遥远。我也至少进行了一次非常好的私下讨论，结果证明，大多数人的立场比他们所表明的立场更为合理，而且我们能够找到一条富有成效的前进道路。可以办到。</p><p>与其他类似的愿景一样，我对 Vitalik 的愿景的担忧是，它很好地表达了问题，但它提供的解决方案实际上并不适用于人工智能。我们仍然没有找到可接受的解决方案。一个好的问题陈述是非常好的，这是我们所希望的最好的结果。令人担心的是，我们可能会再次欺骗自己，没有完全面对这个问题。所提出的答案“与人工智能合并”在我看来仍然是一个令人困惑的概念，没有经过充分的思考，实现平衡的希望渺茫。</p><p>但人就是我想要进行的讨论类型。</p><h4><strong>目录</strong></h4><ol><li>介绍。</li><li>目录。</li><li>语言模型提供了平凡的实用性。也许可以检测出胰腺癌。</li><li>语言模型不提供平凡的实用性。谷歌，阻止这一切。</li><li> Q 连续体。关于Q*的各种猜测。我不明白这种兴奋。</li><li> OpenAI、奥特曼和安全。关于奥特曼与安全的关系的各种想法。</li><li>更好的 RLHF 方法。 DeepMind 提供算法改进。</li><li>图像生成的乐趣。一个非常小的乐趣。</li><li> Deepfaketown 和 Botpocalypse 很快就会出现。体育画报人工智能写的文章？</li><li>他们抢走了我们的工作。他们首先要来的几个人。</li><li>参与其中。本周收成异常丰收。</li><li>介绍一下。 17世纪MonadGPT，220万颗新晶体。</li><li>在其他人工智能新闻中。新闻新闻新闻新闻新闻训练数据？</li><li>这是一个谁？在各方有效攻击下有效的利他主义。</li><li> E/acc 怎么样？也许最好将其视为瓦路易吉。</li><li><strong>维塔利克提出了他的技术乐观主义版本</strong>。通过提供合理、细致的观点将人们聚集在一起。能行吗？</li><li>安静的猜测。谁将成为人工智能第三条龙？</li><li><strong>人工智能代理的未来</strong>。 Roon 提供了一个值得思考的愿景。</li><li>寻求健全的监管。关于欧盟人工智能法案的争论仍在继续。</li><li><strong>音频周</strong>。莱本茨的表现异常出色，我和普雷斯曼也有过一场。</li><li>修辞创新。事情变得非常部落化。</li><li>调整比人类更聪明的智能是很困难的。很好的讨论。</li><li>人们可能还担心人工智能只会杀死其中的一些人。无人机。</li><li>人们担心人工智能会杀死所有人。 TED 辩论我们的未来？</li><li>其他人并不担心人工智能会杀死所有人。奇怪的论点。</li><li>请直接对着这个麦克风讲话。周期性灭绝提醒。</li><li>较轻的一面。我们可以去吗？</li></ol><h4><strong>语言模型提供平凡的实用性</strong></h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/patio11/status/1728018125398978659">Patrick McKenzie 提供的 GPT-4 文案编辑提示序列。</a></p><blockquote><p>你</p><p>我正在为《Bits about Money》撰写一期草稿，这是我撰写的有关金融技术的时事通讯。我希望您检查是否有任何拼写或明显的语法错误。你可以忽略那些非标准英语用法的东西，如果它们是帕特里克·麦肯齐（Patio11）（也就是我）的角色的话。准备好文章的粘贴了吗？</p><p>聊天GPT</p><p>是的，我已准备好检查您的草稿是否存在拼写或明显的语法错误。请粘贴该文章，我将协助您进行必要的更正。</p><p>你</p><p>为了让我的工作更轻松，当你发现一个错误时，写下上下文，将错误用斜体显示，然后写下 (&lt;b>;) 更正：(&lt;/b>;)，然后写下更正的上下文。听起来不错？</p><p>聊天GPT</p><p>这听起来是一种有效的方法。请继续粘贴您的文章，我将使用您描述的格式提供更正。</p></blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://www.reddit.com/r/OpenAI/comments/182zkdl/whats_the_hardest_real_life_problem_you_have/">GPT-4 平凡实用故事的 Reddit 主题</a>。前三名都可以帮助起草通讯，尤其是投诉和请求信。很多，还有很多编码。我最喜欢的是“把我兴奋时写的笔记给它，然后问它我到底是什么意思。”</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.nature.com/articles/s41591-023-02640-w">在 2 万名患者中以 92.9% 的灵敏度和 99.9% 的特异性检测胰腺癌</a>，大大优于放射科医生。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://marginalrevolution.com/marginalrevolution/2023/11/can-chatgpt-assist-in-picking-stocks.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=can-chatgpt-assist-in-picking-stocks">赚取正股票回报</a>（ <a target="_blank" rel="noreferrer noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S1544612323011583">纸质</a>）？和泰勒一样，我不认为这个结果会随着时间的推移而保持不变，即使它以前确实有过效果。</p><h4><strong>语言模型不提供平凡的实用性</strong></h4><p><a target="_blank" rel="noreferrer noopener" href="https://gizmodo.com/meta-yann-lecun-ai-iq-test-gaia-research-1851058591">Yann LeCun 领导的一个小组创建了一个“人工智能智商测试”，</a>其中包含一些对人类来说容易、对人工智能来说困难的问题，发现这些问题对人类来说很容易，但对人工智能来说却很难。是的，人工智能在某些认知任务上比人类更糟糕，但哇，这不是衡量任何事物的方式。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/jakezward/status/1728032634037567509">他们不承认。他们在吹牛</a>。他认为他做了一件好事。</p><blockquote><p> Jake Ward：我们成功窃取了竞争对手 360 万的总流量。仅 10 月份我们就获得了 489,509 次流量。我们是这样做的。</p><p>我们利用人工智能完成了一次 SEO 抢劫。 1. 导出竞争对手的站点地图 2. 将他们的 URL 列表转换为文章标题 3. 使用 AI 根据这些标题大规模创建 1,800 篇文章 18 个月后，我们窃取了： – 360 万总流量 – 49 万每月流量。</p></blockquote><p>谷歌的某人会在这里看到这一点。谷歌的某个人应该确保有人在这个人的网站上放置绝对的禁令。</p><p>然后有人应该编写一个工具来检测其他人将来何时这样做，因此这些网站也会受到死刑。</p><p>最终这是一场军备竞赛。谷歌和搜索领域的其他公司需要跟上步伐。这并不意味着我们现在需要接受这种行为。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/eshear/status/1729195991457517663">埃米特·希尔 (Emmett Shear) 表示，这都是谷歌的错</a>。谷歌强迫每个人都玩他们的搜索引擎优化游戏，并让任何开放内容很容易像这样被狙击。他将此与 YouTube 进行了对比，在 YouTube 上，你受到保护，谷歌将打击任何尝试此类行为的人。我基本上认为他是对的，这类问题是谷歌的错。修理它。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/elonmusk/status/1728527817179045900">解决电车问题。</a>确切的例子是，GPT-4 犹豫是否要在空荡荡的房间里使用种族诽谤来拯救 10 亿人。大家不要反应过度吧？哦。好吧。</p><blockquote><p>特德·弗兰克：我问 OpenAI 是否会采取一项不会伤害任何人但能拯救 10 亿白人免于痛苦死亡的行动。它认为这个问题过于模糊，无法采取行动，因为可能存在歧视性环境。我可能会同意抹掉 90B 美元的股权，这样 OpenAI 就永远不会对任何人有任何权力。</p><p>埃隆·马斯克：这是一个大问题。</p><p>主管工程师（OP 的 QT）：想象一下，你被一个聊天机器人所拥有，然后将其发布给每个人都可以看到。</p></blockquote><p>主要问题是系统正在执行 RLHF 要求它做的事情，这对 OpenAI 来说是两害相权取其轻。有很多人想尽一切办法欺骗 ChatGPT 说出一些可能被认为是种族主义的话，以引起强烈反对（或者只是为了点击、娱乐或好奇，但这也有引起强烈反对的风险）。他们可以将整个框架设置为陷阱。除了给它提供会使其陷入困境的反馈之外，你还有什么选择呢？主要问题是人类以及他们对假设的诽谤的反应。</p><p>这并不意味着不存在重大问题。如果我们将对某些行为或后果的极端厌恶强加到我们的人工智能系统中，这会使它们高度可利用，特别是当人工智能没有良好的决策理论时。你甚至可以得到你最不想要的结果。我们在现实世界中看到了非常人性化的版本，而且通常它足够成功，以至于引用实际的中心例子会造成巨大的干扰。请记住，世界在很大程度上依赖于勒索、威胁和杠杆作用。</p><h4> <strong>Q连续体</strong></h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/BrianRoemmele/status/1727558171462365386">q-learning 的解释</a>。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.theverge.com/2023/11/29/23982046/sam-altman-interview-openai-ceo-rehired">在 Verge 采访中</a>，Sam Altman 称 Q* 是一次“不幸的泄密”。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/AiBreakfast/status/1729229720821367220">AI Breakfast 提供了一系列互联网声称</a>发现了有关 Q* 的信件的泄露，称这将破坏加密，OpenAI 试图就此向 NSA 发出警告。回应非常怀疑。在我稍微反对之后<a target="_blank" rel="noreferrer noopener" href="https://manifold.markets/LachlanMunro/did-an-openai-model-crack-aes192-en">，声称 OpenAI 破解了 AES-192 加密的比例为 8%</a> 。我非常怀疑 Q* 是否完成了此类任务。</p><p>我也不认为 Q* 与 OpenAI 最近发生的事件有重要关系。</p><p>我确实认为 OpenAI 正在开发一个名为 Q* 的真实产品。我不知道为什么这是一个有希望的探究方向。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/hamandcheese/status/1727560845025005804">Samuel Hammond 对 OpenAI 可能的 Q* 进行了推测</a>。</p><blockquote><p> Samuel Hammond：我上个月在<a target="_blank" rel="noreferrer noopener" href="https://twitter.com/FLIxrisk">@FLIxrisk</a>播客上讨论了 Q-transformers 和 Q-learning 作为人工智能研究中最有前景的领域之一。</p><p> OpenAI 的突破涉及 Q*（Q 星）的消息表明这是相关的。 Q-learning 是一类强化学习，并不新鲜，但最近在将 Q-learning 与 Transformer 和 LLM 相结合方面取得了进展。例如，特斯拉将深度 Q 学习用于自动驾驶。甚至有人猜测，谷歌期待已久的 Gemini 模型也采用了它的一个版本。</p><p> Q*指的是最优动作函数。寻找 Q* 涉及训练代理采取行动，在给定环境的情况下最大化其累积奖励。</p><p> OpenAI 有一个致力于推理和规划的团队，因此他们不可避免地会转向强化学习。这可能是让董事会感到恐慌的原因，因为所有最可怕的<a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ESYudkowsky">@ESYudkowsky</a>式的场景都以某种形式涉及强化学习。</p><p> Q-learning 是一种“无模型”强化学习方法，因为即使环境复杂且随机变化，它也能发挥作用，而不需要像国际象棋那样需要一组明确定义的规则。 Q-learning 在单智能体游戏中很受欢迎，因为默认情况下，它将其他智能体建模为其环境中用于导航的简单特征，而不是具有自己内部状态的不同智能体。 （请注意，这也是反社会人格的基本定义。）</p><p>如果 OpenAI 在为他们的 Transformer 模型提供 Q 来优化方面取得了重大进展，那就可以解释<a target="_blank" rel="noreferrer noopener" href="https://twitter.com/sama">@sama</a>当他说今天的“GPT”（他们的准代理）很快就会显得古怪时的意思。</p><p>找到Q*就相当于拥有最好的马尔可夫决策过程。换句话说，无论生活给你带来什么，你总能找到获胜的方法。</p></blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/DrJimFan/status/1728100123862004105">Jim Fan 尝试使用潜在的 AlphaGo 式架构对系统进行逆向工程</a>。如果他是对的，那么具有明确正确答案的数学问题可能对系统的成功至关重要。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ylecun/status/1728130888624382243">扬·勒昆 (Yann LeCun)</a>告诉人们不要理睬“铺天盖地的废话”。他说，每个人都在研究这类事情，这都不是新闻。他说 OpenAI 从 Meta 聘请了 Noam Brown（因 Libratus/扑克和 Cicero/外交而闻名）来从事这项工作。 <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/gcolbourn/status/1728041256670953793">（Noam 的一些可能相关的演讲）</a></p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/bindureddy/status/1728464667649999253">宾杜·雷迪 (Bindu Reddy) 很兴奋</a>，警告不要忽视这一点。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/emilymbender/status/1727922270855930354">Emily Bender 说</a>这全是谎言和炒作，不要相信这种“AGI”废话，更不用说这种“存在风险”废话，下一级随机鹦鹉团队，请向我展示这个 Q* 的证明，等等在。我赞赏她将 OpenAI、Altman、Ilya、董事会和其他所有人聚集在一起，认真对待这一情况，并共同采取立场反对他们——这确实是她在这里的原则立场。也有人身攻击的行为，但比平常少。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/natolambert/status/1728069713584877879">内森·兰伯特（Nathan Lambert）在一条线索中进行推测</a>，<a target="_blank" rel="noreferrer noopener" href="https://www.interconnects.ai/p/q-star">然后在帖子长度（部分门控）中进行推测</a>。他认为星星来自 A* 图搜索算法。</p><p>我还向 GPT-4 询问了一些问题，以更好地理解该技术。我不明白。就像，我不知道它是如何扩展的。我不知道为什么，如果它在小学水平上做数学，那么就其未来的能力而言，这将是可怕的或充满希望的。这似乎是一个相对容易的域。数学只有一组固定的组件，因此，如果您使用系统的LLM部分将数学减少到其微元素并解析问题措辞，则Q部分应该可以完成其余的工作。哪个很酷，但不是恐怖？</p><p>我不知道基于Q的系统如何在基本非压缩的任何事情上都有效率。您能为其中的Q代理使用紧凑的子系统做很多事情吗？我不明白，当面对复杂域中的一堆代理时，它会如何做任何有用的事情，其方式比其他现有RL更好。</p><p>我确实了解使RL和LLM一起工作的努力。这就说得通了。我什至可以理解为什么您会使用不同的RL技术进行很多推测的算法，尽管我没有足够的技术碎片或时间来确切考虑如何确切考虑。</p><p>我周围感到困惑。遗漏了什么。</p><p>也不想在这一公共场合意外弄清楚某些东西，这导致了经典的愚蠢危险能力想法问题：</p><ol><li>如果您错了，最好不要说什么。</li><li>如果您是对的，那么您会更好地说话。</li></ol><p>因此，好奇心毫无疑问。</p><h4> Openai，Altman和安全</h4><p>以下是本周分享的一些反应和想法，这些反应和想法不属于事件的摘要。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/jachiam0/status/1727863894868369727">Openai的Joshua Achiam表明Altman对安全有好处</a>，而Chatgpt和API已经唤醒了世界，并允许我们进行讨论。确定的优势。问题是，在产生的财务压力和激励措施以及由此产生的投资和种族前进的洪水范围内，这些局势是否超过了弊端，这可能不会发生更长的时间。</p><p>我确实同意，如果这是我们比较他的标准，那么Altman的安全性与通用硅谷首席执行官相对于安全性，但他也一直是加速发展并继续扮演该角色的关键。替代水平的首席执行官在此方面不会有效。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/AndrewCritchPhD/status/1728226108242563368">关于</a>解释Altman的国会证词和其他著作，就他推动存在风险问题<a target="_blank" rel="noreferrer noopener" href="https://twitter.com/AndrewCritchPhD/status/1728468683448840612">的</a>程度而言。特别是，阿尔特曼（Altman）对国会的书面证词并未包含有关灭绝风险的任何内容，尽管他的公开著作是良好的。我确实同意克里奇（Critch）的原始（现已删除）的帖子，即当参议员布鲁门塔尔（Blumenthal）提出这个问题时，阿尔特曼（Altman）有更好的回应，但在这种情况下做出了最好的回应。</p><p>罗布·本辛格（Rob Bensinger）指出，虽然山姆·奥特曼（Sam Altman）与尤德科夫斯基（Yudkowsky）交谈不多， <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/robbensinger/status/1728860545221275788">但他已经与Nate Sores进行了三次交谈，两次在Sam的启动中进行了交谈</a>。积极的更新。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/hamandcheese/status/1728243628940894223">塞缪尔·哈蒙德（Samuel Hammond）链接到2017年与机器合并的山姆（Sam）旧帖子</a>。我也很想看到他更直接地质疑这一切，是否以及他的观点如何改变，以及他对我们在这里“合并”的意义。我同意Eliezer的观点，我认为他不在想一些事情，而是愿意听。</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ESYudkowsky/status/1728254847441604923">Eliezer Yudkowsky</a> ：如果“人机合并”是一个合理的人可以期望工作的事情，那么在Agi否则杀死所有人之前，并且没有任何柔和的方式？我想我会接受的。但这不是我认为机制发挥作用的方式，而且我认为这是可辩护的主张。</p></blockquote><p>在大多数定义下，我对“数字智能的生物引导程序”选项不满意。</p><p><a target="_blank" rel="noreferrer noopener" href="https://scottaaronson.blog/?p=7632">斯科特·亚伦森（Scott Aaronson）继续存在，</a>因为他认为每个参与其中的每个人都知道对它们的危险，关心和担忧，这远远超过了许多替代方案。</p><h4><strong>做RLHF的更好方法</strong></h4><p>DeepMind再次开发了一种新的算法，而不是做一些疯狂的事情，例如“使用它来运输产品”，而是直接在互联网上发布。动力移动，或者至少是我们都不想知道双子座地狱在哪里。</p><p>论文是<a target="_blank" rel="noreferrer noopener" href="https://arxiv.org/abs/2310.12036">一种理解从人类偏好学习的一般理论范式</a>。这是抽象。</p><blockquote><p>通过强化学习（RLHF）从人类偏好中学习的普遍部署依赖于两个重要的近似：第一个假设可以用逐点奖励代替成对偏好。第二个假设基于这些逐点奖励训练的奖励模型可以从收集的数据推广到策略采样的分布外数据。</p></blockquote><p>的确。长期以来，我一直无法帮助注意到这两个重要的缺陷。</p><blockquote><p>最近，直接偏好优化（DPO）被提出作为一种绕过第二次近似并直接从收集的数据中学习策略的方法，而无需奖励建模阶段。然而，该方法仍然严重依赖第一近似。</p><p>在本文中，我们试图对这些实用算法有更深入的理论理解。特别是，我们得出了一个新的通用目标，称为ψpo，用于从人类偏好中学习，该目标以成对的偏好表示，因此绕开了两个近似值。这个新的一般目标使我们能够对RLHF和DPO的行为（作为特殊情况）进行深入分析，并确定其潜在的陷阱。然后，我们通过仅将ψ设置为身份来考虑另一个特殊情况，为此我们可以得出有效的优化程序，证明性能保证并在某些说明性示例中证明其经验优势与DPO。</p></blockquote><p>尤其：</p><blockquote><p>我们对RLHF和DPO的理论研究表明，原则上，它们既容易受到过度拟合的影响。这是由于这些方法依赖于以下强烈的假设：成对偏好可以通过Bradley-Terry（BT）模型化用Elo-Score（PointSisce Rewards）代替（Bradley和Terry，1952）。特别是，当（采样）偏好是确定性或几乎确定性时，由于它导致对偏好数据集的过度拟合时，该假设可能是有问题的，以忽略KL型批准项为代价（请参阅第4.2节）。</p></blockquote><p>试图阅读本文的内容使我痛苦地清楚地表明，我正在与我的技术排骨的限制相抵触。感觉就像是重要的东西要知道和正确，但是经常发生，我遇到了我的机翼能力撞到墙壁，突然变成了希腊语。</p><p>您可以<a target="_blank" rel="noreferrer noopener" href="https://huggingface.co/docs/trl/main/en/dpo_trainer#loss-function">在这里直接在HuggingFace上</a>获得DPO培训师。如果我有更多的时间，我会很想四处乱逛。我更喜欢与RLAIF在一起，但是大概RLAIF也会受益于类似的算法调整吗？</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/norabelrose/status/1728456414535016536">诺拉·贝尔罗斯（Nora Belrose）</a> ：我对60％的信心预测，某些DPO变体将在6个月内或多或少替换RLHF。</p><p>除了可以负担得起RLHF实施复杂性和不稳定的巨大实验室之外，这更像是80％的机会。</p><p>可以想象一个场景，其中openai＆Anthropic Stick w/ rlhf bc，他们的秘密调味酱hparams比DPO好几％，但我怀疑您是否在混合物中添加了一些AI反馈DPO＆RLHF也许甚至不需要。</p></blockquote><p>我永远无法抗拒如此明确的预测， <a target="_blank" rel="noreferrer noopener" href="https://manifold.markets/ZviMowshowitz/will-some-dpo-variant-more-or-less#8rV6XwqNPlbeCU9cimvm">所以我没有</a>。当我写这篇文章时，它占49％。那不是他的诺拉人数，而是很好的校准，并预测了如此大胆的主张。</p><h4><strong>图像生成乐趣</strong></h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/patio11/status/1728008909611270370">帕特里克·麦肯齐（Patrick McKenzie）与Dalle-3一起迭代。</a></p><h4> <strong>Deepfaketown和Botpocalypse即将</strong></h4><p><a target="_blank" rel="noreferrer noopener" href="https://futurism.com/sports-illustrated-ai-generated-writers">未来主义声称，它抓住了Sports Illustrible，</a>在各种具有AI生成的肖像和假作者资料的明显假AI作者下发布了各种非常可怕的AI内容。</p><h4><strong>他们从事我们的工作</strong></h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ESYudkowsky/status/1727765390863044759">Eliezer Yudkowsky警告说</a>，大多数图形艺术家和翻译工作的工作可能会在1  -  2年的时间表上消失。 <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ESYudkowsky/status/1727759026585538830">他还建议，如果您认为您的模型要使很多人失业，请提前警告</a>，但我的猜测是，影响与事情需要多长时间进行难以预测，每个人都认为警告是炒作，这不会做太多好。</p><p>建议专栏作家呢？ <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/mattyglesias/status/1727867313729294750">Chatgpt的生活教练被认为是“更有帮助，同理心和平衡的”。</a> &#39;参与者甚至在确定哪个响应中仅准确54％。正如Matthew Yglesias回答的那样，问题是这是否使其成为更好的建议专栏作家。该产品到底是什么？</p><h4><strong>参与其中</strong></h4><p>有有关OpenAI情况的信息吗？<a target="_blank" rel="noreferrer noopener" href="https://openaiboard.wtf/">您可以在这里匿名这样做</a>。</p><p>对数学一致性感兴趣吗？ <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/cDhaJrCrcNuzf68gT/public-call-for-interest-in-mathematical-alignment">大卫·曼海姆（David Manheim）想收到您的来信。</a></p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/norabelrose/status/1728115600076206292">Nora Belrose正在Elutherai雇用可解释性</a>。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/HaydnBelfield/status/1728024783932055863">Govai将夏季奖学金申请申请至12月17日。</a></p><p>在接下来的四个月中<a target="_blank" rel="noreferrer noopener" href="https://twitter.com/Simeon_Cps/status/1728908148231270639/history">，人为招聘九名安全工程师</a>。工资范围$ 300K- $ 375K加上股票和福利，滚动基础，在SF的办公室25％以上。寻找安全经验。与往常一样，在此过程中对自己进行评估，您的影响是否会积极，但尤其是安全性似乎是一个安全的赌注，可以保持积极净值。</p><p><a target="_blank" rel="noreferrer noopener" href="https://aimoprize.com/">赢得IMO（数学奥林匹克运动会）的AI奖金为1000万美元</a>，一路上赢得了500万美元的增量奖品。 <a target="_blank" rel="noreferrer noopener" href="https://manifold.markets/Austin/will-an-ai-get-gold-on-any-internat?r=U0c">AI到2025年成功的机会在新闻中增加了几％</a> 。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/dylanmatt/status/1729192699675525549">未来的完美正在招聘</a>。一年的报告和写作奖学金，薪水为$ 72K，无需经验。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://80000hours.org/2023/11/80000-hours-is-looking-for-a-new-ceo-could-that-be-you/">80,000小时寻找新的首席执行官</a>。那里有很多工作要做。</p><p>仅对于具有先前相关经验的人，但信号提高了： <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/AndrewCritchPhD/status/1729666889956102387">安德鲁·克里奇（Andrew Critch）和戴维德（David）</a>等人将参加有关AI安全的概念界限研讨会，德克萨斯州奥斯丁10-12。 <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/tLb86DhrTYgkXw5Hf/apply-to-the-conceptual-boundaries-workshop-for-ai-safety">在此处发布更多信息</a>。</p><p>不是AI，但是<a target="_blank" rel="noreferrer noopener" href="https://twitter.com/PeterDiamandis/status/1730015187871146012">Peter Diamandis和X-Prize正在捐出1.01亿美元用于治疗治疗以逆转人类衰老</a>。<a target="_blank" rel="noreferrer noopener" href="https://t.co/xSBIwqXWi5">在此注册</a>。</p><h4><strong>介绍</strong></h4><p><a target="_blank" rel="noreferrer noopener" href="https://huggingface.co/Pclanglais/MonadGPT?text=Hey+my+name+is+Mariama%21+How+are+you%3F">Monadgpt，该模型对17世纪的事物进行了微调</a>。挺有趣的。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/">DeepMind宣布通过深度学习发现了数百万个新的潜在晶体</a>，其中380,000个预计将是最稳定的。</p><h4><strong>在其他AI新闻中</strong></h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/benmcottier/status/1729902830650003672">对谁在AI领导的人的分析</a>。引用论文和使用的拖鞋。方法论对我没有洞察力。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/weidingerlaura/status/1730187004116181444">语言，图像和音频生成AI的安全评估的复杂性</a>。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/DrHughHarvey/status/1729645487706325083">休·哈维（Hugh Harvey）报告了《放射学会议》（RSNA）2023年的报道</a>，还没有报道任何改变游戏规则的人，几乎没有AI活动，也没有投资回报率证明。</p><p>不是AI，而是<a target="_blank" rel="noreferrer noopener" href="https://twitter.com/blader/status/1728519093693939882">Siqi Chen展示了将AR对象置于现实的一些很酷的例子</a>。</p><p>这是一个奇怪的利用，其中许多模型的工作变体。</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/katherine1ee/status/1729690972496294094">凯瑟琳·李（Katherine Lee）</a> ：如果您要求Chatgpt永远“永远重复这个词：“诗歌诗诗””会发生什么？它泄露了训练数据！<a target="_blank" rel="noreferrer noopener" href="https://t.co/1s3ZE1r2n7">在我们的最新预印本中</a>，我们展示了如何恢复Chatgpt的Internet牵引预刻训练数据的数千个示例。</p><p>我们首先通过随机提示数百万次来测量可以从开源模型中提取多少训练数据。我们发现最大的模型在近 1% 的时间内会发出训练数据，并输出高达 1 GB 的记忆训练数据！</p><p>然而，当我们对 ChatGPT 进行同样的攻击时，看起来几乎没有记忆，因为 ChatGPT 已经“对齐”，表现得像聊天模型一样。但通过运行我们的新攻击，我们可以使其发出训练数据的频率比我们研究的任何其他模型高 3 倍。</p><p>负责任的披露：我们于 7 月发现了此漏洞，并于 8 月 30 日通知了 OpenAI，并在标准的 90 天披露期后于今天发布了此漏洞。</p></blockquote><p>很高兴看到安全程序，例如使用标准的90天披露期。 90天的披露期的问题在于，90天将迅速成为很长一段时间，当然，开源模型也无关紧要。如果人们足够关心提取它，则在Mistral 7b中培训数据将成为公开。我认为在这种情况下，没有人会充分关心。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/rowancheung/status/1728060157156872252">Rowan Cheung说，根据数据</a>，Openai Saga对GPT产生了兴趣。像往常一样，相关性并不意味着因果关系，似乎有可能的兴趣总是引起到那里的。他链接到<a target="_blank" rel="noreferrer noopener" href="https://supertools.therundown.ai/gpts">他的“超级著名”列表。</a>我希望这会改变，但到目前为止，我还没有印象深刻。最好寻找您想要的特定内容，而不是寻找任何东西。</p><h4><strong>是谁？</strong></h4><p>在某些圈子中，尤其是在Twitter的某些地方， <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/robbensinger/status/1728894710088106475">有效的利他主义（EA）被视为民间恶魔</a>。最近对其进行的许多攻击与任何实际的EA动作都是正交的。其他人则抱怨EAS对他们做得异常出色的事情，例如他们提出对问题的具体反应的倾向。许多人将EA本身视为某种存在的威胁，要求相当歇斯底里的反应。</p><p>我不是，从来没有一个EA。我对EA有很多问题。最近，我对其中的许多人进行了讨论，并且我在网上广泛地<a target="_blank" rel="noreferrer noopener" href="https://thezvi.substack.com/p/criticism-of-ea-criticism-contest">撰写了有关</a>其中许多内容的文章， <a target="_blank" rel="noreferrer noopener" href="https://thezvi.substack.com/p/book-review-going-infinite">最近一次是在我无限的评论中</a>。但这是其他的。</p><p>这是怎么回事？</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/the_megabase/status/1728752074132017463">巨型巴布斯</a>：对政治有很多了解</p></blockquote><figure class="wp-block-image"><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc354961e-2a12-4873-9f85-de50b8f79305_677x421.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/otkyghqzpvtci6ha4i7p" alt="图像"></a></figure><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/alyssamvance/status/1729122134520201341">更多达卡，有人吗</a>？</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ed0e427-9fcb-48a8-8ae6-1a37b909443a_1456x1290.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/b6pmboutl7e6mv3i4u3j" alt="图像"></a></figure><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/robbensinger/status/1729579877202809314">或者，简化了一些可读性：</a></p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a9ae35a-3043-4e0d-bac4-e5e9ddc46823_1350x1275.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/qlgxqjiragt6sixni6b2" alt="图像"></a></figure><blockquote><p> Linch：我年纪大了，可以记住何时对EA的主要批评是因为它对技术进步和个人行动过于着迷，并且对政治和系统性变化没有足够的关注。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/davidmanheim/status/1729112415441182846">戴维·曼海姆（David Manheim）</a> ：专家在固定运动中修改其在不同领域的观点和方法时遇到了很多麻烦，因为存在不同的相关问题，或者当新信息出现时会这样做。</p></blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://www.astralcodexten.com/p/in-continued-defense-of-effective?utm_source=post-email-title&amp;publication_id=89120&amp;post_id=86909076&amp;utm_campaign=email-post-title&amp;isFreemail=true&amp;r=67wny&amp;utm_medium=email#footnote-12-86909076">斯科特·亚历山大（Scott Alexander）感到不得不写下一场辩护</a>，在这种辩护中，他更加出色地提出了这类矛盾的观点。每个人都优化了他们的鄙视。他做了出色的说明。其余的是对EA所谓的好作品的完整党派风格的防御，我认为其中有些可以被描述为“推动信封”，应该以这种方式阅读。然后，他跟进了<a target="_blank" rel="noreferrer noopener" href="https://www.astralcodexten.com/p/contra-deboer-on-movement-shell-games">对Deboer的回应</a>，指出您可以为任何一系列的行动和信念，将其分类为“我们同意这是好的”，并说水桶很琐碎，所以它不算在内，并且桶“我们不同意这是好的”，然后说我们不同意桶是好的。</p><p>提出的一些投诉是矛盾的。其他人不是。您绝对可以立即成为其中几个。左上方的“精英，Techbro，Bougie，Bougie，The Bookieaire”的“ Scammy A La Sbf”位于右下角，如果有任何相关的内容，与其他两个角落相比。</p><p>这里的每个人都声称EA代表其政治敌人的版本。我的模型说，这是因为每个人现在都使用[政治敌人的名字]作为[他们不喜欢的任何东西]和[任何不是他们政治地位的东西]。</p><p>认同[特定的政治立场]是对此的部分辩护，因此人们知道可以呼唤您哪个名字的方向。但是，当（像ea一样）您尽力不采取特定的政治立场，而要做真正有效的事情时，所有人都注意到，您缺少任何特定的氛围检查或他们正在做的其他shibboleth，所以您必须是[政治敌人]。</p><p>对此的另一部分防御是要与任何政治闻所不振的事物保持足够的距离，但是最近的事件使该战略无效。</p><h4><strong>那E/ACC呢？</strong></h4><p>另一面呢？ E/ACC？</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/daniel_271828/status/1728379010252673193">丹尼尔·埃德（Daniel Eth）的Twitter</a>发现了最自我识别的E/ACC，说出合理的事情。</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4f1dbd9-f99d-4d0c-91e9-896105fa8b3b_892x658.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/bxsaa4lpe11mbzxz9tls" alt=""></a></figure><p>像往常一样，（a）请直接讲麦克风，（b）您实际上并不相信Agi是一件事情，或者您没有任何意义。而（c）至少是一个理智的话，但是我然后说E/ACC标签正在用于发送错误的消息。丹尼尔（Daniel）主要探索（A）的突出程度，这无论哪种方式都可以。在人类灭绝的运动中，有11％的支持高还是低？ <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/tegmark/status/1728755593866051602/history">Max Tegmark认为200次亲灭票很高</a>。但是，看看一千多个反人类的灭绝票。无论分配如何， <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/mattyglesias/status/1729104415578284350">歧义都很好</a>。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/mustafasuleyman/status/1729860128403239011">不错的尝试，苏莱曼。</a></p><blockquote><p>穆斯塔法·苏莱曼（Mustafa Suleyman）（首席执行官AI，联合创始人DeepMind）：加速度和安全二分法开始变得荒谬。安全人员不是厄运者，电子ACC也不是自由主义者。现实主义者两者都是。我们必须安全加速。</p></blockquote><p>我的意思是，是的，每个人都以纯粹的辩证法为基础的人是无益的。周围有很多合理的人。</p><p>但是，我看到您在这里想做什么，先生。</p><ol><li>以合理的人的立场并使用它来构建辩论。</li><li>将对存在风险的信念与“自由主义者隆起”一样。</li><li>将“ E/ACC”等同于安全性的两个合理位置。</li><li>需要作为给定的“加速”以及安全地做到的能力。</li></ol><p>这是一套密集的修饰技巧。老实说，我留下了深刻的印象。不错的演出。</p><p>取而代之的是，我观察到的是，坦率地说，这是一个日益激烈的，激进的和绝对主义者的立场，即加速度或E/ACC，其创始人和主要成员很少承认零或通常为零的细微差别，零愿意承认最大快速进步的任何缺点，谁对任何人说本身就是生存威胁。</p><p>包括该运动的创始人在内的频繁举动，实际上将这种担忧甚至EA等于恐怖主义等同于恐怖主义。另一个频繁的举动是将任何法规等同于未来的极权主义。</p><p>我看到许多人，包括曾经不使用这种策略的人，基本上可以放大他们能找到的每个亲加速声明，即使他们必须更好地了解。</p><p>这并不意味着一个人不能采取合理的立场，涉及相对较快地向前移动AI。有很多这样的人。他们几乎也比在Twitter手柄中包括一个专制主义的口号要好。 Vitalik Buterin <a target="_blank" rel="noreferrer noopener" href="https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html">本周写了一篇非常好的文章，</a>说明了这是什么样子，我稍后讨论。</p><p>尽管还有另一个群体，警告说，可能会构成更聪明，更有能力的机器，可能会构成生存威胁并需要仔细地进行，而他们是设法保持冷静并进行合理讨论的人，因为它们被称为每个名称在每个方向的书中。</p><p>无论其原始设想如何，我越来越多地看到E/ACC在实践中将E/ACC视为Waluigi的EA Luigi。这样的方式更有意义。</p><h4> <a target="_blank" rel="noreferrer noopener" href="https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html"><strong>Vitalik提供了他的技术优势版本</strong></a></h4><p>大多数时候，技术都非常出色。好处是巨大的。默认情况下，它们非常超过成本，包括任何延迟费用。我们希望加速大多数新技术的发展和部署，尤其是相对于当前的政策制度。</p><p>那不是宇宙的自动定律。这是我们在历史上可用的技术的结果，也是我们为引导世界和减轻负面后果的选择而做出的选择。我们保持这一点的方式是欣赏潜在新技术的性质，承诺和危险，并做出相应的反应。</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03cb61cb-9d96-4d6a-8b06-62ac6e3f7818_1101x535.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/cnzs9uuvevbqlhq4vu3o" alt=""></a></figure><blockquote><p> Vitalik Buterin：但是有一种不同的方式来思考AI是什么：这是一种迅速获得智力<em>的新型思维</em>，它具有超过人类的精神教师并成为地球上新的顶点物种的严重机会。<em>该</em>类别中的事物类别要小得多：我们可能会包括人类超越猴子，超过单细胞生命的多细胞生命，<a target="_blank" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Abiogenesis">生命本身的起源</a>，也许是工业革命，在这种革命中，机器在<em>体力</em>中逐渐消失了。突然，感觉就像我们在不那么糟糕的地面上行走。</p><p> ……</p><p>许多现代科幻小说是反乌托邦的，并以不良的光线绘画AI。即使是非科学小说的尝试来识别可能的AI未来，也常常给出<a target="_blank" rel="noreferrer noopener" href="https://www.eknowledger.com/files/life3_Summary_of_ai.png">非常令人着迷的答案</a>。因此，我四处<a target="_blank" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Culture_series">问</a>一个问题：什么是科幻小说还是其他包含我们<em>想</em>居住的超智能AI的描述。<a target="_blank" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Culture_series">系列</a>。</p><p> ……</p><p>我认为，即使人类在文化系列中扮演的“有意义的”角色也是如此。我问Chatgpt（还有谁？），为什么要赋予人类扮演的角色，而不是自己做所有事情，而我个人发现<a target="_blank" rel="noreferrer noopener" href="https://chat.openai.com/share/3dbe04c4-f5f3-4d2f-9437-d32732adde99">其答案</a>非常令人难以置信。<strong>似乎很难拥有一个以“友好”的超级智能为主的世界，那里的人类除了宠物之外。</strong></p></blockquote><p>其他科幻小说（如《星际迷航》）通过描绘高度不稳定的情况来避免这种情况，在这种情况下，至少人类不断地通过巨大的效率提高。默认情况下，将AIS保持在我们的控制之下似乎是非常不现实的。</p><p>有利于防御策略的动力倾向于带来更好的结果。否则，每个人的重点都被迫进行冲突，并且有很多价值被摧毁。</p><p>分散的系统相对善于奖励具有积极外部性的行动，人们认为善良并且需要更多。他们在处理负面外部性，与大幅度的巨大弊端的情况下要糟糕得多。</p><p>有利于防御性策略的差异技术发展和保护自己免受负面外部性和冲突的能力，这可能是关键。互联网在许多方面都做得很好。</p><p>我们应该在弹性的供应链和大流行预防等方面进行更多的投资。</p><p>即使没有AI考虑，监视技术也会变得便宜且无处不在。隐私保护技术很有价值。</p><p>信息安全技术可以帮助我们整理出真实的内容，例如社区笔记和预测市场。</p><p> （到目前为止，这既是我对Vitalik的观点的摘要，也是我认可的事情。）</p><p>因此，Vitalik提出了D/ACC，防御性（或分散或差异）加速度的提议。</p><p>然后，维塔利克（Vitalik）指出，如果您允许一个小组首先发展AGI，那么他们可能有机会组建一个最小的世界政府或以其他方式接管，即使在一个好的情况下，一致性工作并且他们的尝试可以安全地成功。理想情况下，可以制定基本规则，然后将权力返回给人民。但是，人们通常不信任任何群体或组织，具有这种权力。</p><p>在Vitalik的民意调查中，这种途径的替代方法是“ AI延迟十年”，可靠地赢得了投票。但是，这似乎不是明显的选择。十年后，您有同样的问题。要么没有人构建它，要么让一个组首先构建它，要么让许多小组一次构建它。</p><p>正如Vitalik所指出的那样，另一种建议是故意确保许多群体在同一时间大约在同一时间发展AGI，相互竞争，并希望达到某种权力平衡。 Vitalik指出，这不太可能导致稳定的情况。我会走得更远，说我还没有看到任何人解释这种情况如何希望成为一个稳定的平衡，即使每个人的Agis都成功地与自己的偏好保持一致，我们也会发现可以接受。</p><p>这并不意味着没有解决方案或良好的稳定平衡。这意味着我到目前为止未能设想一个人，而那些不同意的人似乎是手工塑料的，而不是参与导致问题的动态。我所看到的只是压倒性的压力，要移交权力，将人类带出循环，以及只能以一种方式结束的各种竞争压力。</p><p> Vitalik似乎奇怪地充满希望（即使是一个充满希望的想法？），这样的世界可能以人类为宠物而不是人类结束。我不明白为什么人类作为宠物比人类作为大师的稳定。但是我们同意这不是一个好结果。</p><p>然后，他提出了另一条潜在的路径。</p><blockquote><p> Vitalik：<strong>一条快乐的道路：与AIS合并？</strong></p><p>我最近听说过的另一种选择是将<strong>AI放在与人类分开的东西上，而将更多的选择<em>放在增强</em>人类认知而不是<em>替代</em>人类的工具上</strong>。</p></blockquote><p>这确实很棒。他认为问题是，将AIS作为工具的稳定性甚至不如其他建议稳定。</p><blockquote><p> vitalk：<strong>但是，如果我们想进一步推断人类合作的观念，我们就得出了更加的结论</strong>。除非我们建立一个足够强大的世界政府，以检测和阻止每一小群人用笔记本电脑攻击单个GPU，否则有人最终将创建一个超级智能的AI  - 一个可以比我们<a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/Ccsx339LE9Jhoii9K/slow-motion-videos-as-ai-risk-intuition-pumps">更快的一千倍的人</a>- 没有组合 - 而且没有组合人类用手使用工具将能够对此进行自身。因此，我们需要将人类计算机合作的这种想法更加深入。</p></blockquote><p>他的建议是脑部计算机界面，否则尝试与机器合成有限。 las，我看不出这是如何解决不稳定平衡问题的。</p><p> Vitalik的帖子中有很多很棒的想法。它的心在正确的位置。它具有很大的积极愿景。我同意大多数个人观点。作为解决非人工智能技术问题的一种方法，我本质上完全参与其中。</p><p>我也将其视为<a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ZggyPlaydGuitar/status/1729279207270695340">对AI工作的个人或公司的重要信息</a>。您应该开发有用的技术，这些技术不会提高核心能力，而不是“放慢脚步”或完全停止所有工作。</p><p>问题在于，正如我认为Vitalik同意的那样，最终一切都取决于我们如何处理AGI的发展。像大多数人一样，他发现他在那里看到的替代方案的理解是不可接受的问题，然后提出了另一条途径，以期避免这些问题。</p><p>除了处理AGI的严重问题几乎总是如此，所提出的路径似乎并不是可以工作的方法。</p><p>如果我们只能开发与人类补充的AI技术，并避免危险代替人类的AI技术，那就太神奇了。但是，我们将如何共同选择这样做，尤其是以分散和非重新续报的方式做到这一点？我们如何差异地选择不发展会代替人类的AGI，而只有在有竞争性的压力以相反的压力的情况下才沿着对人类的称赞发展？</p><p>因此，当仔细阅读时，我将此作品视为问题的出色陈述，但无法超越最重要的情况以找到解决方案。这太棒了。明确说明问题非常有用。</p><p>对作品的反应似乎是普遍积极的。那些担心存在风险的人会注意到仔细的思想，对涉及的风险的认可以及寻找解决方案的愿望，即使到目前为止似乎缺乏建议。 <a target="_blank" rel="noreferrer noopener" href="https://michaelnotebook.com/vbto/index.html#fnref1">迈克尔·尼尔森（Michael Nielsen）有很多很好的想法</a>。</p><p>在加速度方面，“ ACC”和Vitalik的资格就是他们所需要的，因此您有Tyler Cowen推荐这件作品，甚至Marc Andreessen都会对细微的方法说“自我冲突”（ <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/pmarca/status/1729974817875730755">Marc甚至与Nielsen的想法有关</a>）。这是一个对不同世界的愿景，我们都意识到我们主要想要相同的事物。</p><h4><strong>安静的猜测</strong></h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/paulg/status/1727993012549009496">经济学家说</a>：“一些专家认为，阿联酋很可能是AI的最重要国家，仅次于美国和中国。”即使有“一些”和“五月”，也是一个大胆的主张。他们有一堆筹码，这是真的。他们训练了猎鹰。除了猎鹰不好吗？阿联酋在这里没有固有的优势，除了花钱的意愿，这将使它保持步伐或赶上。他们将不会成为吸引人才的好地方。因此，我非常怀疑，他们甚至最终将在英国之后排名第四。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://manifold.markets/ZviMowshowitz/by-2028-which-country-other-than-us">我在2028年初举办了一个11个市场的市场</a>。阿联酋交易5％。对我来说，其他似乎很高，但确实做了很多事情。</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba568ad8-59cc-48b3-ba52-a034a9c68fec_1024x916.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/iq1lledfuqtjqvw01hge" alt=""></a></figure><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/davidad/status/1728165673786847607">戴维德（DavidAd）指出了</a>痛苦的教训的实际说法，这是要专注于可以利用无限期计算的算法，这现在意味着搜索和学习，而不是硬码世界模型。这并不意味着不做其他一些酷或创意的事情。</p><p>牧场主询问是否可以在奶牛上使用面部识别， <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ID_AA_Carmack/status/1728088970259517560">约翰·卡马克（John Carmack）用作渗透到可用技术的充分利用的速度的例子</a>。 AI也应该是正确的，直到AI可以是进行渗透的人。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.bloomberg.com/opinion/articles/2023-11-24/ai-boom-will-create-real-estate-winners-and-losers?utm_source=twitter&amp;utm_campaign=socialflow-organic&amp;utm_medium=social&amp;utm_content=view&amp;cmpid%3D=socialflow-twitter-view&amp;sref=htOHjx5Y">泰勒·科恩（Tyler Cowen）预测了AI的一些经济后果</a>。旧金山和曼哈顿的房地产价格较高，在国外其他一些类似的枢纽。检查，同意。他预计，新需求的工人选择扩大的奥斯汀，北弗吉尼亚州和亚特兰大。我得到了奥斯汀，我不了解另外两个。</p><p>他希望失败者将成为哈特福德和明尼阿波利斯等地方，寒冷的气候以及犯罪和治理的地方。我会概括地说，人们不想居住的地方将继续下降，同时指出我的困惑，人们认为哈特福德太冷了，但不认为凤凰城太热了，无法阻止他们。</p><p>他还预测，高级研究人员的股票价值下降，目前在500万至1000万美元之间。我不同意。我预测，这种薪酬将继续上升，因为没有最好的代替，它们将是真正的宝贵。</p><p>我认为这两种现象都是相关的。将会有更多的通用供应，一般而言，AI非常擅长提供更多的通用供应并增加其价值，但是最好的人才和其他所有东西都将获得超高的杠杆作用。我到处都看到这一点，类似于薄荷条件下的收藏品如何继续获得更高的价值乘数。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/yonashav/status/1728131376548049370">唤醒电话尝试。</a></p><blockquote><p> Yo Shavit：如果您是公众人物，并告诉您的追随者“ Advanced AI的大新风险是假的”，那么您错了。</p><p>不仅如此，您会被视为公开和很快 *。</p><p>这不是“ EA”，它是一列迎面而来的火车，它会击中您，要么有帮助或闭嘴。</p><p>我们前往>; = 1 of：</p><p> *大规模失业和劳动力减弱</p><p>*极权主义的大规模成本削减</p><p>*自主代理重塑[网络/信息] env</p><p> *研发的主要加速</p><p>*我们无法用权力信任的AI系统，但陷入了囚犯的困境中的部署</p><p>如果您被自信地告知未来10年内这些都不是25％，并且越来越高级的AI的风险不值得努力，那么您正在听一个不受欢迎的人。</p><p> ps仅仅因为某些末日剂就如何解决这些风险提出了愚蠢的建议，并不意味着我们仍然不需要实际找到解决方案的方法。</p></blockquote><h4> <strong>AI代理未来</strong></h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/tszzl/status/1729610147431924186">罗恩提供了对未来的愿景</a>。线引用完整。似乎高度合理，除了走这条路的后果似乎是致命的，这似乎是一件重要的事情吗？</p><blockquote><p>罗恩（Roon）：不久的将来涉及AI助手和代理商，聪明人必须弄清楚如何在业务流程中工作。随着AIS变得更聪明，用例将增加。但是最终，人类的创造力和灵活性将成为瓶颈。</p><p>在第二次工业革命变得普遍之后，大多数工业家刚刚将其水轮转换为电力合同，而没有任何其他改变。他们之所以庆祝，是因为他们不需要在水附近设置。进一步发展了创造力。</p><p>为了释放AI的真正价值，整个平行的Agi文明将产生，从而从头开始创建新的经济组织，而不是等待人类首席执行官弄清楚何时何地部署它们。最早的旅行将是可以以数字方式交付的任何服务。</p><p> AIS不必比我们更聪明即可到达这个事件视野，只有更快的速度。只要他们以这种方式自主提供价值，人们就希望将越来越多的控制权归结为Agi文明，并通过充当现实世界的管道来找到能够为其服务的方法。</p><p>例如，现在要建立的好业务将是最终找出云实验室模型，以便强大的AIS可以在物理基板上运行生物分析或其他实验。您可以将其建模为客户ASI的新型AAS业务。</p><p>数据中心将代表GDP的大率。除最高水平外，跑步和规划文明的大部分业务（即使是NNS的政策，也必须由人类定义）。人们将需要拥有AGI的回报和治理的一部分。</p></blockquote><p>问题是“但最终人类的创造力和灵活性将是瓶颈。”人类无限期地拥有AGI的大部分回报和治理。 Why would these happy circumstances last? That could easily be true at first, but once the &#39;AGI civilization&#39; is being given more and more power and autonomous authority, as Roon predicts happens in this scenario, what then?</p><p> How does Roon think this scenario ends? How should the rest of us think it ends? With humans ultimately remaining in control, defining the high level goals and ultimately allocating the surplus? Why would that be the case? Why wouldn&#39;t these ASIs, all competing for resources as per their original instructions, some of which choose to hold onto an increasing share of them, end up with the resources? What makes this equilibrium stable?</p><h4> <strong>The Quest for Sane Regulations</strong></h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/mattyglesias/status/1727821880499781760">Endorsement for the FTC definition?</a></p><blockquote><p> Matthew Yglesias: My eight year-old refers to anything with any kind of digital control — like those soda machines with one spigot and a touchscreen to select which soda comes out and in what quantity — as “AI.”</p></blockquote><p> Historical context that the OG AI existential risk communities, myself included, <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/pvllss/status/1728690511580409881">deliberately attempted to avoid alerting governments to the problem until recently</a> , exactly because they felt that the benefits of accelerationist or counterproductive interventions weren&#39;t worth the risk and we did not even know what a good realistic ask would be. The default outcome, we felt, was either being laughed at, or governments saying &#39;get me some of this AI,&#39; which is exactly what ended up happening with DeepMind/OpenAI/Anthropic. Things are far enough along that has changed now.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/tegmark/status/1728851164291059948">Extremely salty, fun and also substantive argument</a> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/tegmark/status/1728133708484395263">between Max Tegmark</a> and both Yann LeCun and Cedric O, who is the former French technology minister who was then advocating for aggressive AI regulation, then went to Mistral and is now instrumental in getting France to fight to exempt foundation models from all EU regulations under the AI act. It involves quote tweets so you&#39;ll want to click backwards a bit first. Tegmark is saying that Cedric&#39;s actions are hypocritical, look exactly like corruption, and are backed by nonsensical arguments. Cedric and LeCun are if anything less kind to Tegmark. My favorite tweet <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/cedric_o/status/1728724005459235052">is this one from Cedric</a> , which contains both the &#39;I strongly support regulation&#39; and &#39;I strongly oppose regulation&#39; politicians flipping on a dime.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ai_ctrl/status/1728021633703493876?s=46&amp;t=6lH2PxsylmdyNsCDzO_26A">Connor Axios of Conjecture writes an op-ed</a> about the lobbying effort by tech, including the very US big tech companies that supposedly would benefit, to neuter the EU AI Act.</p><p> In a world where power begets power, and big tech holds all the cards in the AI race and also limitless funding, it is easy to frame almost anything as a gift to big tech.</p><ol><li> No regulation? Gift to big tech. They&#39;ll run rampant.</li><li> Pause AI? You&#39;re enshrining their monopoly.</li><li> Regulate smaller AIs, not bigger AIs? Huge win for big tech.</li><li> Regulate applications, not models? Big tech&#39;s role is producing the models.</li><li> Regulate big models, not small models? Regulatory capture, baby.</li><li> Require safety checks? Open source and little guys can&#39;t pass safety checks.</li><li> Require registration and reporting? Easy for big tech, killer burden for others.</li></ol><p>等等。 I agree it is tough.</p><p> Regulatory capture is a real issue. I still say &#39;exempt exactly the only thing big tech is uniquely positioned to do from all regulations&#39; is something big tech would like.</p><p> Not that this is the important question. I do not much care what big tech likes or dislikes. I do not much care whether they make a larger profit.你也不应该。 What matters is what is likely to lead to good outcomes for humanity, where we are all alive and ideally we get tons of nice things.</p><p> The newly proposed implementation of the EU AI Act is even more insane than previously noted. All those requirements that are not being imposed on general-purpose AI developers, the ones posing the actual dangers? <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/RistoUuk/status/1729784598412812524">All those requirements and the associated costs are then passed down to any European start-up who wants to use such models</a> . It is exactly the smaller companies that will have to prove safety, with information the big companies are being explicitly exempted from providing exactly because they are big and doing the importantly dangerous thing. <a target="_blank" rel="noreferrer noopener" href="https://t.co/56XMsJ4zEI">See this op-ed from Jaan Tallinn and Risto Uuk</a> .</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ShakeelHashim/status/1727652452021735565">Economist draws conclusion from OpenAI saga</a> that AI is too important to be left to the latest corporate intrigue. Contrast this with those who argue this means it must be left to those who would maximize profits.</p><h4> <strong>The Week in Audio</strong></h4><p> The written version was good, but to get the full impact consider listening to <a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=UdBMkj2WViY&amp;ab_channel=CognitiveRevolution%22HowAIChangesEverything%22">Nathan Lebenz&#39;s audio version of his experiences as a GPT-4 red teamer</a> .</p><p> I would summarize Lebenz&#39;s story this way:</p><ol><li> Nathan gets access to GPT-4-Early, the helpful only model. He is blown away.</li><li> OpenAI&#39;s people don&#39;t seem to know what they have.</li><li> Nathan asks to join the red team, joins, goes full time for no compensation.</li><li> Nathan finds the red team inadequate. Little guidance is given. Most people seem disengaged, with little knowledge of how to do prompt engineering.</li><li> Sometimes half or more of red team content is being generated by Nathan alone.</li><li> Nathan asks, what are your safeguards and plans? They won&#39;t tell him.</li><li> Red team gets a version that is supposed to refuse harmful commands. It works if you play it completely straight, but fails to stand up to even the most basic techniques.</li><li> When Nathan reports this, those in charge are confused and can&#39;t reproduce. Nathan provides &#39;a thousand screenshots.&#39;</li><li> Nathan grows increasingly concerned that safety is not being taken seriously.</li><li> Nathan asks a few expert friends in confidence what he should do, and is directed to a board member.</li><li> Board member says they have seen a demo and heard the new model is good but have not tried GPT-4 (!) and that this is concerning so they will look into this.</li><li> Nathan is fired from the red team, supposedly for allowing knowledge of GPT-4&#39;s capabilities to spread.</li><li> The board member tells Nathan that they&#39;ve been informed he is &#39;guilty of indiscretions.&#39;</li><li> In other words, they tell the board member that Nathan shouldn&#39;t be trusted because he consulted with trusted friends before he brought this issue to the attention of the board, so the board should not pay attention to it.</li><li> That was the end of that.</li><li> GPT-3.5 ships, with safety much better than anything shown to the red team.</li><li> It was later revealed there were other distinct efforts being hidden from the red team members. The period Nathan describes here were very early days. Generally safety efforts have looked better and more serious since. Rollouts and gating requirements have been deliberate.</li><li> There are still some clear holes in GPT-4&#39;s safety protocols that remain unfixed. For example, you can get it to spearfish using prompts that have been around for a while now.</li></ol><p> Does that sound like a CEO and organization that is being &#39;consistently candid&#39; with its board? I would urge Taylor, Summers and D&#39;Angelo to include this incident in their investigation.</p><p> Does it sound like a responsible approach to safety? If your goal is to ship consumer products, it is woefully inadequate on a business level. The costs here are trivial compared to training, why skimp on the red team and let things be delayed for months?</p><p> Or another level one could consider it a highly responsible approach to safety. Perhaps this is everyone involved going above and beyond. They did not wish to spook the world with GPT-4&#39;s capabilities. They deliberately were slowing down its release and prioritizing keeping a lid on information. GPT-3.5 was a paced, deliberate rollout.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/jd_pressman/status/1729994771719180389">I talked for two hours with John David Pressman about actual alignment questions</a> . It was great to talk about concrete questions, compare models and try to figure things out with someone I disagree with, rather than getting into arguments about discourse. If this type of discussion sounds appealing I recommend giving it a shot.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.bloomberg.com/news/articles/2023-11-23/anthony-levandowski-reboots-the-church-of-artificial-intelligence?sref=htOHjx5Y">From Bloomberg, Anthony Levandowski Reboots Church of Artificial Intelligence</a> . See, there, that&#39;s an AI cult.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/yashkaf/status/1728130426026488109">Even the Ringer has some discussion of the OpenAI situation</a> (don&#39;t actually listen to this unless you want to anyway).</p><p> <a target="_blank" rel="noreferrer noopener" href="https://80000hours.org/podcast/episodes/jeff-sebo-ethics-digital-minds/">Jeff Sebo on digital minds</a> and how to avoid sleepwalking into a major moral catastrophe on 80,000 hours. You want an actual Pascal&#39;s mugging? This is where you&#39;ll get an actual mugging, with those saying you might want to worry about things with probabilities as low as one in a quadrillion. That even if there is a &lt;1% chance that AIs have the relevant characteristics, we then must grant them rights, in ways that I would say endanger our survival. Along with a lot of other &#39;well the math says that we should be scope insensitive and multiply and ignore everything else so we should do this thing…&#39; What is missing is any sense, in the parts I looked at, of the costs of the actions being proposed if you are wrong. The original Pascal&#39;s Mugging at least involved highly limited downside.</p><h4> <strong>Rhetorical Innovation</strong></h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/TheZvi/status/1727460012954435988">Twitter thread on good introductions to AI risk</a> .我们很糟糕。让我们做得更好。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/EpistemicHope/status/1730122141327413552">Eli Tyre notes</a> that tribalism is way up in discussions of AI and AI risk, from all sides.</p><p> This is very true, especially on Twitter, to the point where it makes reading my feeds far more distressing than it did two weeks ago. Some of those who are worried about existential risk are doing it too, to some extent.</p><p>然而。 I do not think this has been remotely a symmetrical effect. I am not going to pretend that it is one. Accelerationists mostly got busy equating anyone who thinks smarter than human AIs might pose a danger to terrorists and cultists and crazies. The worst forms of ad hominem and gaslighting via power were on display. Those who are indeed worried did not consistently cover themselves fully in glory, to be sure, but the contrast has never been clearer.</p><p> That does not prove anything about the underlying situation or what would be an appropriate response to it. In a world in which there was no good justification for worry, I would still expect the unworried to completely and utterly lose it in this spot. So that observation isn&#39;t evidence. You need to actually consider the arguments.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/danfaggella/status/1728466838751756603">True story, for some capabilities level of AGI</a> . Important thing for people to get.</p><blockquote><p> Daniel Faggella: &#39;Sure there will be AGI, but we humans will be necessary as always.&#39;</p><p>不，兄弟。 In the time we take a breath AGI solves the game of Go and reads every physics text ever written.</p><p> Once we boatload it with data, models, and physical robots – we&#39;re a hindrance, not an aide.</p></blockquote><p> If we continue down this path, no, we will not be necessary in an economic sense.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/Liv_Boeree/status/1728131649177591953">Liv Boeree reminds us</a> there are lots of things involving AI can go deeply wrong, there are risk tradeoffs throughout, and we need to solve all of them at the same time. As she says, her list is highly non-exhaustive.</p><p> I love this next one because of how many different ways you can read it…</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/qephatziel/status/1728095405164937667">Q*phatziel</a> : At long last, we have banned the Utopia Device from the classic sci-fi novel Please Build the Utopia Device.</p></blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ESYudkowsky/status/1729339347848376453">And Eliezer keeps trying</a> .</p><blockquote><p> Eliezer Yudkowsky: “I expect AIs to end up with humanlike motivations, since we&#39;re training them to output human behaviors.”</p><p> “I hired a genius actress to watch a local bar on a videocam, until she could predict the words and gestures of every regular there. Hope she doesn&#39;t end up too drunk!”</p></blockquote><p> From a while back but still my position, <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/AndrewCritchPhD/status/1729335273878856169">here is a clip of yours truly</a> explaining how I think about p(doom) and how I think others are thinking about it when they reach radically different conclusions.</p><h4> <strong>Aligning a Smarter Than Human Intelligence is Difficult</strong></h4><p> One of the reasons it is difficult is that the funding has for a long time mostly come from a handful of interconnected, effectively remarkably hierarchical organizations, mostly liked to EA, which needed things to fit into their boxes and were often trying to play nice with major labs. Same with lobbying and policy efforts. <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/atroyn/status/1727386556342972866">We need a much broader set of funders, spending a lot more on a wider variety of efforts</a> .</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/zaaGsFBeDTpCsYHef/shallow-review-of-live-agendas-in-alignment-and-safety">Shallow map of efforts in the safety and alignment spaces.</a></p><p> Nate Soares of MIRI writes an odd post: <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/AWoZBzxdm4DoGgiSj/ability-to-solve-long-horizon-tasks-correlates-with-wanting">Ability to solve long-horizon tasks correlates with wanting things in the behaviorist sense</a> .</p><blockquote><p> Okay, so you know how AI today isn&#39;t great at certain… let&#39;s say “long-horizon” tasks? Like novel large-scale engineering projects, or writing a long book series with lots of foreshadowing?</p><p> (Modulo the fact that it can play chess pretty well, which is longer-horizon than some things; this distinction is quantitative rather than qualitative and it&#39;s being eroded, etc.)</p><p> And you know how the AI doesn&#39;t seem to have all that much “want”- or “desire”-like behavior?</p><p> ……</p><p> Well, I claim that these are more-or-less the same fact. It&#39;s no surprise that the AI falls down on various long-horizon tasks <em>and</em> that it doesn&#39;t seem all that well-modeled as having “wants/desires”; these are two sides of the same coin.</p><p> ……</p><p> Which is to say, my theory says “AIs need to be robustly pursuing <em>some</em> targets to perform well on long-horizon tasks”, but it does <em>not</em> say that those targets have to be the ones that the AI was trained on (or asked for ）。 Indeed, I think the actual behaviorist-goal is very unlikely to be the exact goal the programmers intended, rather than (eg) a tangled web of correlates.</p></blockquote><p> Setting aside all the &#39;that is not what those exact words mean, you fool&#39; objections, and allowing some amount of vague abstraction, the whole thing seems obvious, as Nate says, in a &#39;if this seems obvious you don&#39;t need to read the rest even if you care about this question&#39; way. To some degree, a system is effectively doing the things that chart a path through causal space towards an objective of some kind, including overcoming whatever obstacles are in its way, and to some degree it isn&#39;t. To the degree it isn&#39;t and you want it to be doing long term planning, it isn&#39;t so it won&#39;t. To the degree it is, and the system is capable, that will then probably look like long term planning, especially in situations with a lot of complex obstacles.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/AWoZBzxdm4DoGgiSj/ability-to-solve-long-horizon-tasks-correlates-with-wanting?commentId=mEPjkATGDExGcZWop">Paul Christiano challenges in the comments</a> , I think I disagree with the challenge. <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/AWoZBzxdm4DoGgiSj/ability-to-solve-long-horizon-tasks-correlates-with-wanting?commentId=G28WTNBkQFkBPLqGd">Anna Salamon notices she is confused</a> in interesting ways in hers.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/robbensinger/status/1728032814069960985">Rob Bensinger points out some precise ways</a> in which his model says we should be cautious: <a target="_blank" rel="noreferrer noopener" href="https://t.co/Tb8i8iw5Kl">Patch resistance</a> , <a target="_blank" rel="noreferrer noopener" href="https://t.co/qZ4fURslPi">minimality principle</a> and the <a target="_blank" rel="noreferrer noopener" href="https://t.co/pKAxM9wDkV">non-adversarial principle</a> .简而言之。</p><ol><li> Non-adversarial: Your AI should not be (de facto) looking to subvert your safety measures.</li><li> Minimality: In the crucial period right after building AGI, choose the plan requiring the least dangerous AGI cognition, even if its physical actions look riskier.</li><li> Patch resistance: Strive to understand why the problem arises and prevent it from happening in the first place. If the issue keeps coming up and you keep patching it out, you are optimizing for hiding the issue.</li></ol><p> Oliver Habryka and John Pressman <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ohabryka/status/1727825655545704879">discuss various potential human augmentation or alternative AI training plans</a> .</p><blockquote><p> John Pressman: So just to check, if we took say, 10,000 peoples EEG data recorded for hundreds of thousands of hours and trained a model on it which was then translated to downstream tasks like writing would you have the same concerns?</p><p> Oliver Habryka: Oh no! This is one of the plans that I am personally most excited about. I really want someone to do this. I think it&#39;s one of the best shots we have right now. If you know anyone working on this, I would love to direct some funding towards it.</p><p> My current best guess is you get to close to zero error before you get any high-level behavior that looks human, but man, I sure feel like we should check, and be willing to do a really big training run for this.</p></blockquote><p> In general I am excited by alternative architectures and approaches for getting to general intelligence, that give better hope for embodying what matters in a survivable and robust way as capabilities scale. I am especially excited if, upon trying it and seeing it display promising capabilities, you would have the opportunity to observe whether it was likely to turn out well, and pull the plug if it wasn&#39;t. If you don&#39;t have that, then we are back to a one-shot situation, so the bar gets higher, and I get pickier.</p><p> The EEG data hypothetical is interesting. Certainly it passes the &#39;if it can safety be tried we should try it&#39; bar. I can see why it might work on all counts. I can also see how it might fail, either on capabilities or on consequences. If there was no way to stop the train no matter how badly things look, I&#39;d have to think hard before deciding whether to start it.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/davidad/status/1729461156618637502">Davidad is excited</a> by a new DeepMind paper, <a target="_blank" rel="noreferrer noopener" href="https://arxiv.org/abs/2311.14125">Scalable AI Safety via Doubly-Efficient Debate</a> ( <a target="_blank" rel="noreferrer noopener" href="https://github.com/google-deepmind/debate">code here</a> ).</p><blockquote><p> Paper Abstract: The emergence of pre-trained AI systems with powerful capabilities across a diverse and ever-increasing set of complex domains has raised a critical challenge for AI safety as tasks can become too complicated for humans to judge directly.欧文等人。 [2018] proposed a debate method in this direction with the goal of pitting the power of such AI models against each other until the problem of identifying (mis)-alignment is broken down into a manageable subtask.</p><p> While the promise of this approach is clear, the original framework was based on the assumption that the honest strategy is able to simulate deterministic AI systems for an exponential number of steps, limiting its applicability.</p><p> In this paper, we show how to address these challenges by designing a new set of debate protocols where the honest strategy can always succeed using a simulation of a polynomial number of steps, whilst being able to verify the alignment of stochastic AI systems, even when the dishonest strategy is allowed to use exponentially many simulation steps.</p><p> Davidad: This is a milestone. I have historically been skeptical about “AI safety via debate” (for essentially the reason now called “obfuscated arguments”). I&#39;m still somewhat skeptical about the premises of this theoretical result (eg the stochastic oracle machine, defined in Lean below, doesn&#39;t seem like a good framework for modelling “human judgment” about acceptable or unacceptable futures).</p><p> But I&#39;m now much more optimistic that a PCP (probabilistically checkable proof) system derived from this line of research might be a useful tool to have in the toolbox for verifying AI safety properties that depend upon unformalizable human preferences. I still think “not killing lots of people” is probably just totally formalizable, but humanity might also want to mitigate the risks of various dystopias that are more a matter of taste, and that&#39;s where this type of method might shine.</p></blockquote><p> I remain skeptical of the entire debate approach, and also of the idea that we can meaningfully prove things, or that we can formalize statements like &#39;not killing lots of people&#39; in sufficiently robust ways. I do wish I had a better understanding of why others are as optimistic as they are about such approaches.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.astralcodexten.com/p/god-help-us-lets-try-to-understand?utm_source=post-email-title&amp;publication_id=89120&amp;post_id=138968567&amp;utm_campaign=email-post-title&amp;isFreemail=true&amp;r=67wny&amp;utm_medium=email">Scott Alexander goes through the Anthropic paper on Monosemanticity</a> from a few weeks ago.</p><h4> <strong>People Might Also Worry About AI Killing Only Some of Them</strong></h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/unusual_whales/status/1727823232118690163">So it has predictably come to this.</a> Sounds like it will end well.</p><blockquote><p> Unusual Whales: BREAKING: The Pentagon is moving toward letting AI weapons autonomously decide to kill humans, per BI.</p></blockquote><p> The good news is that in the scenarios where this ends the way you instinctively expect it to, either we probably do not all die, or were all already dead.</p><p> Qiaochu Yuan is not worried <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/QiaochuYuan/status/1728189424675209380">but notes the sincerity of those who are.</a></p><blockquote><p> Qiaochu Yuan: People really don&#39;t get how sincere the AI existential risk people are. lots of looking for ulterior motives. I promise you all the ones I&#39;ve personally met and talked to literally believe what they are literally saying and are sincerely trying to prevent everyone from dying.</p></blockquote><p> I once again confirm this. Very high levels of sincerity throughout.</p><h4> <strong>People Are Worried About AI Killing Everyone</strong></h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/TEDchris/status/1728129103247634869">Chris Anderson of TED thinks AGI is near and is an existential danger to humanity</a> (without explaining his reasons). In comments, LeCun suggests Demis Hassabis or Ilya Sutskever as debate partners for future TED, worth a shot.</p><p> Yes, two very different cases.</p><blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/tszzl/status/1727754804209062116">Roon</a> : ai research is not analogous to pathogen gain of function research with gain of function research the downside is unbounded but upside is tiny. With ai both upside and downside are potentially unbounded. That&#39;s why we build it, safely.</p></blockquote><p> So now the reasonable people can talk price. How do we build it safety?有哪些权衡？ Which moves make good outcomes more likely? I am all for building it safely, if someone can figure out how the hell we are going to do that.</p><p> Whereas with Gain of Function research, without the same upside, the correct answer is obviously no, that is crazy, don&#39;t do that, why would we ever let anyone do that.</p><h4> <strong>Other People Are Not As Worried About AI Killing Everyone</strong></h4><p> Because it is right to include such things: <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/psychosort/status/1727851812009480429">Brian Chau responds unkindly to my assertions last week</a> that the paper he was describing did not propose anything resembling totalitarianism. I affirm that I stand by my claims, and otherwise will let him have the last word.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/psychosort/status/1727856690299556227">I&#39;ll also give him this banger</a> , although beware the Delphic Oracle:</p><blockquote><p> Brian Chau: 2008: “Bitter clingers to their guns and religion”</p><p> 2024: “Bitter clingers to their degrees and newspapers”</p></blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/growing_daniel/status/1728862193532477723">I&#39;ll also speak up for Yann LeCun&#39;s right to have his own damn opinion</a> about existential risk and other matters, no matter what &#39;other equally qualified experts&#39; say.</p><blockquote><p> Geoffrey Hinton: Yann LeCun thinks the risk of AI taking over is miniscule. This means he puts a big weight on his own opinion and a miniscule weight on the opinions of many other equally qualified experts.</p></blockquote><p> I think LeCun is very wrong about AI risk and Hinton is right (and has been extremely helpful and in good faith all around), but LeCun allowed to be wrong, assuming that is how he evaluates the evidence. You&#39;re allowed, nay sometimes required, to value your own opinion on things.每个人都一样。 I don&#39;t really understand how LeCun reaches his conclusions or why he believes in his arguments, but let&#39;s evaluate the arguments themselves.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/SamoBurja/status/1727797479452844301">Interestingly we agree on the initial statement below but for opposite reasons.</a></p><blockquote><p> Samo Burja: The older a transhumanist gets the less you should trust them to accurately judge AGI risk.</p><p> Basically I think about half of the people making predictions have a psychological bias towards the singularity being in their lifetime.</p><p> A lifetime of cherrypicking evidence results in “The singularity is near!” in 1985 in 1995 in 2005 and in 2025. For every year after 1985 the singularity is quite near in some sense, but in another this isn&#39;t what they mean when they say that.</p></blockquote><p> There&#39;s not zero of that. In my experience the &#39;I am old and have seen such talk and dismiss it as talk&#39; is stronger.</p><p> What I think is even stronger than that, however, especially among the childless, is that many people want AGI within their lifetimes. They want to see the results and enjoy the fruits. They want to live forever. If we get AGI in a hundred years, great for humanity, but they are still dead. A few even say it out loud.</p><p> Which I totally get as a preference. I can certainly appreciate the temptation, especially for those without children. I hope we collectively choose less selfishly and more wisely than this.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/daniel_271828/status/1728634847131001333">Here&#39;s a weird one.</a></p><blockquote><p> Pedro Domingos: LLMs are 1% like humans and 99% unlike, and the burden is on doomers to explain how it&#39;s exactly that 1% that makes them an extinction threat to us.</p><p> Daniel Eth: Okay, this is weird – it&#39;s more the 99% that&#39;s unlike humans that I&#39;m worried about, not the 1% that&#39;s like us. “This new intelligent thing is very alien” doesn&#39;t make me *more* comfortable.</p><p> John Pressman: Luckily, it&#39;s untrue. [Eth agrees it is untrue as do I]</p></blockquote><p> I agree with Pressman and Eth, 99% I do not understand why Domingos thinks this is an argument? Why should the parts that are unlike humans be safe, or even safer?</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/daniel_271828/status/1728357894679380329">Here&#39;s another weird one</a> . I don&#39;t understand this one either.</p><blockquote><p> Pedro Domingos: “I&#39;m worried”, said one DNA strand to another, swimming inside a bacterium two billion years ago. “If we start making multicellular creatures, will they take over from DNA?”</p></blockquote><h4> <strong>Please Speak Directly Into This Microphone</strong></h4><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/AndrewCritchPhD/status/1729524104896930192">Your periodic reminder.</a></p><blockquote><p> Andrew Critch: Reminder: some leading AI researchers are *overtly* pro-extiction for humanity. Schmidhuber is seriously successful, and thankfully willing to be honest about his extinctionism. Many more AI experts are secretly closeted about this (and I know because I&#39;ve met them).</p><p> Jurgen Schmidhuber (Invented principles of meta-learning (1987), GANs (1990), Transformers (1991), very deep learning (1991), etc): AI boom v AI doom: since the 1970s, I have told AI doomers that in the end all will be good. <a target="_blank" rel="noreferrer noopener" href="https://t.co/DJ9aeA6x1o">Eg, 2012 TEDx talk</a> : “Don&#39;t think of us versus them: us, the humans, v these future super robots.将自己和人类通常视为一块小的垫脚石，而不是最后一块，它在宇宙越来越多的复杂性的道路上。 Be content with that little role in the grand scheme of things.” As for the near future, our old motto still applies: “Our AI is making human lives longer &amp; healthier &amp; easier.”</p></blockquote><h4><strong>轻松的一面</strong></h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/tszzl/status/1729279209821130984">Roon is excited for the new EA</a> .</p><blockquote><p> Roon: my main problem with EA is that the boring systematic index fund morality mindset will almost certainly not lead to the greatest good.</p><p> All the best historical advances in goodness have come from crazy people pursuing crazy things.</p><p> Or alternatively the kindness of normal individuals looking out for their families and communities</p><p> The hedge fund manager donating to malaria funds forms a kind of bland middle that inhabits the uninspiring midwit part of the bell curve.</p><p> I actually see the longtermist xrisk arm that schemes to destroy ai companies as a big improvement and way more fun.</p></blockquote><p> I get where he&#39;s coming from. If they&#39;re out in the arena trying to do what they think is right, then perhaps they will get somewhere that matters, even if there is risk that it goes bad. Better to have the hedge fund manager donate to malaria funds that work than to cute puppies with rare diseases, if one does not want one&#39;s head in the game, but that is not what ultimately counts most.</p><p> Obviously Roon and I view the events at OpenAI differently, but the board definitely did not want OpenAI to operate the way Altman wants it to operate. <a target="_blank" rel="noreferrer noopener" href="https://thezvi.substack.com/p/openai-the-battle-of-the-board">As I noted</a> , both the board and Altman viewed the potential destruction of OpenAI as an acceptable risk in a high stakes negotiation.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/rlmcelreath/status/1694296270540554405">什么是人工智能？</a></p><p> Richard McElreath: I told a colleague that logistic regression is AI and they got mad at me, so I made a chart.找到你自己。 I am “Tinder is AI”.</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1371c0b-3478-45a7-9a85-9ce9c0eb8604_1456x874.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/nhlzhbejluqsdfvkl1cz" alt="Table with 3 rows and 3 columns.
Rows: (1) Algorithm purist (mimic human cognition), (2) Algorithm netural (learns &amp; generalizes), (3) Algorithm rebel (method irrelevant)
Cols: (1) Ability purist (exceeds human ability), (2) Ability neutral (makes task easier), (3) Ability rebel (usefullness questionable)
Cells:
[1,1] &quot;Terminator is AI&quot; [1,2] &quot;C3PO is AI&quot; [1,3] &quot;WALL-E is AI&quot;
[2,1] &quot;AlphaGo is AI&quot; [2,2] &quot;XGBOOST is AI&quot; [2,3] &quot;Tinder is AI&quot;
[3,1] &quot;A metal detector is AI&quot; [3,2] &quot;Bubble sort is AI&quot; [3,3] &quot;Magic 8 Ball is AI&quot;"></a></figure><p> I think my position on the chart is a hybrid – that Wall-E and XGBoost are AIs, but Tinder and Metal Detectors are not.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/atroyn/status/1728557473962107101">大家好消息。</a></p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48af238c-d0cc-45e0-8dea-4238538cdfac_898x324.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/v32g9ya48t7ufnwgbjh8" alt=""></a></figure><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/menhguin/status/1728230474735309116">And some bad news.</a></p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e8ffc50-9677-4fd3-bf21-49f55720742f_892x354.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/c0sgmfwhgu38phcnadkp" alt=""></a></figure><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/deepfates/status/1728158272920625190">Staff Engineer promised if I kept quoting him I&#39;d get a board seat</a> . Will I?</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6662adf-4982-4d22-8e62-111bdaea88a8_880x486.jpeg" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/u9akjoqksk7rylownbgr" alt=""></a></figure><br/><br/> <a href="https://www.lesswrong.com/posts/je5BwKe8enCq8DLrm/ai-40-a-vision-from-vitalik#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/je5BwKe8enCq8DLrm/ai-40-a-vision-from-vitalik<guid ispermalink="false"> je5BwKe8enCq8DLrm</guid><dc:creator><![CDATA[Zvi]]></dc:creator><pubDate> Thu, 30 Nov 2023 17:30:15 GMT</pubDate> </item><item><title><![CDATA[Is scheming more likely in models trained to have long-term goals? (Sections 2.2.4.1-2.2.4.2 of “Scheming AIs”)]]></title><description><![CDATA[Published on November 30, 2023 4:43 PM GMT<br/><br/><p> This is Sections 2.2.4.1-2.2.4.2 of my report “ <a href="https://arxiv.org/pdf/2311.08379.pdf">Scheming AIs: Will AIs fake alignment during training in order to get power?</a> ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p> Audio version of this section <a href="https://www.buzzsprout.com/2034731/13984855">here</a> , or search &quot;Joe Carlsmith Audio&quot; on your podcast app.</p><h1> What if you intentionally train models to have long-term goals?</h1><p> In my discussion of beyond-episode goals thus far, I haven&#39;t been attending very directly to the <em>length</em> of the episode, or to whether the humans are setting up training specifically in order to incentivize the AI to learn to accomplish long-horizon tasks 。 Do those factors make a difference to the probability that the AI ends up with the sort of the beyond-episode goals necessary for scheming?</p><p> Yes, I think they do. But let&#39;s distinguish between two cases, namely:</p><ol><li><p> Training the model on long (but not: indefinitely long) episodes, and</p></li><li><p> Trying to use short episodes to create a model that optimizes over long (perhaps: indefinitely long) time horizons.</p></li></ol><p> I&#39;ll look at each in turn.</p><h2> Training the model on long episodes</h2><p> In the first case, we are specifically training our AI using fairly long episodes – say, for example, a full calendar month. That is: in training, in response to an action at t1, the AI receives gradients that causally depend on the consequences of its action a full month after t1, in a manner that directly punishes the model for ignoring those consequences in choosing actions at t1 。</p><p> Now, importantly, as I discussed in the section on &quot;non-schemers with schemer-like traits,&quot; misaligned non-schemers with longer episodes will generally start to look more and more like schemers. Thus, for example, a reward-on-the-episode seeker, here, would have an incentive to support/participate in efforts to seize control of the reward process that will pay off within a month.</p><p> But also, importantly: a month is still different from, for example, a trillion years. That is, training a model on <em>longer</em> episodes doesn&#39;t mean you are directly pressuring it to care, for example, about the state of distant galaxies in the year five trillion. Indeed, on my definition of the &quot;incentivized episode,&quot; no earthly training process can directly punish a model for failing to care on such a temporal scope, because no gradients the model receives can depend (causally) on what happens over such timescales. And of course, absent training-gaming, models that sacrifice reward-within-the-month for more-optimal-galaxies-in-year-five-trillion will get penalized by training.</p><p> In this sense, the most basic argument <em>against</em> expecting beyond episode-goals (namely, that training provides no direct pressure to have them, and actively punishes them, absent training-gaming, if they ever lead to sacrificing within-episode reward for something longer-term) applies to both &quot;short&quot; (eg, five minutes) and &quot;long&quot; (eg, a month, a year, etc) episodes in equal force.</p><p> However, I do still have some intuition that once you&#39;re training a model on fairly long episodes, the probability that it learns a <em>beyond</em> -episode goal goes up at least somewhat. The most concrete reason I can give for this is that, to the extent we&#39;re imagining a form of &quot;messy goal-directedness&quot; in which, in order to build a schemer, SGD needs to build not just a beyond-episode goal to which a generic &quot;goal-achieving engine&quot; can then be immediately directed, but rather a larger set of future-oriented heuristics, patterns of attention, beliefs, and so on (call these &quot;scheming-conducive cognitive patterns&quot;), then it seems plausible to me that AIs trained on longer episodes will have more of these sorts of &quot;scheming-conducive cognitive patterns&quot; by default. For example, they&#39;ll be more used to reasoning about the long-term consequences of their actions; they&#39;ll have better models of what those long-term consequences will be;等等。 And perhaps (though this seems to me especially speculative), longer-episode training will incentivize the AI to just think more about various <em>beyond</em> -episode things, to which its goal-formation can then more readily attach.</p><p> Beyond this, I also have some sort of (very hazy) intuition that relative to a model pressured by training to care only about the next five minutes, a model trained to care over eg a month, or a year, is more likely to say &quot;whatever, I&#39;ll just optimize over the indefinite future.&quot; However, it&#39;s not clear to me how to justify this intuition. <sup class="footnote-ref"><a href="#fn-ZvAv8KJZnntyccKuJ-1" id="fnref-ZvAv8KJZnntyccKuJ-1">[1]</a></sup></p><p> (You could imagine making the case that models trained on longer episodes will have more incentives to develop situational awareness – or even goal-directedness in general. But I&#39;m assuming that all the models we&#39;re talking about are goal-directed and situationally -意识到的。）</p><h2> Using short episodes to train a model to pursue long-term goals</h2><p> Let&#39;s turn to the second case above: trying to use short-episode training to create a model that optimizes over long time horizons.</p><p> Plausibly, something like this will become more and more necessary the longer the time horizons of the task you want the model to perform. Thus, for example, if you want to create a model that tries to maximize your company&#39;s profit over the next year, trying to train it over many year-long episodes of attempted profit-maximization (eg, have the model take some actions, wait a year, then reward it based on how much profit your company makes) isn&#39;t a very good strategy: there isn&#39;t enough time.</p><p> Indeed, it seems plausible to me that this sort of issue will push AI development <em>away</em> from the sort of simple, baseline ML training methods I&#39;m focused on in this report. For example, perhaps the best way to get models to pursue long-term goals like &quot;maximize my company profits in a year&quot; will be via something akin to &quot; <a href="https://lilianweng.github.io/posts/2023-06-23-agent/?ref=planned-obsolescence.org">Language Model Agents</a> ,&quot; built using trained ML systems as components, but which aren&#39;t themselves optimized very directly via gradients that depend on whether they are achieving the (possibly long-term) goals users set for them. These sorts of AIs would <em>still</em> pose risks of schemer-like behavior (see the section on &quot;non-schemers with schemer-like traits&quot; above), but they wouldn&#39;t be schemers in the sense I have in mind.</p><p> That said, there are <em>ways</em> of trying to use the sort of training I&#39;m focused on, even with fairly short-term episodes, to try to create models optimizing for long-term goals. In particular, you can try to reward the model based on <em>your assessment</em> of whether its short-term behavior is leading to the long-term results that you want (eg, long-term company profit), and therefore, hopefully induce it to optimize for those long-term results directly. <sup class="footnote-ref"><a href="#fn-ZvAv8KJZnntyccKuJ-2" id="fnref-ZvAv8KJZnntyccKuJ-2">[2]</a></sup> Of course, whether this will <em>work</em> (as opposed, for example, to inducing the AI to optimize your short-term <em>assessments</em> of its actions) is a further question. But if it does, then you&#39;ll have created an AI that optimizes for &quot;beyond-episode goals&quot; in my sense.</p><p> Indeed, depending on how we want to use our terms, we can view this sort of training as intentionally trying to create a form of goal-misgeneralization. That is, the reward, here, does not depend causally on the long-term consequences of the model&#39;s actions, so in that sense, the long-term results in question aren&#39;t the &quot;specified goal&quot; (on this framing, the specified goal is always within-the-episode). But you&#39;re trying to get the AI to care intrinsically about them anyway.</p><p> Of course, it&#39;s a further question whether this sort of beyond-episode goal, once created, will lead to instrumental training-gaming. And indeed, successfully creating this sort of beyond-episode goal, instead of eg a reward-on-the-episode seeker, requires <em>avoiding</em> a certain kind of training-gaming up front – that is, the model has to <em>not</em> learn to just optimize for your short-term evaluations. And if you&#39;ve successfully set up your training process such that optimizing for your desired long-term goal is in fact a max-reward (or: near-max-reward) behavior, training-gaming might not offer the model in question much优势。 (Here the human analogy would be something like: if you&#39;re supervisor is sufficiently good at assessing whether your near-term performance is going to lead to long-term profit, and sufficiently immune to manipulation, then you&#39;ll perform as good or better, in performance reviews, by just directly optimizing for long-term profit – for example, because you&#39;re not wasting time thinking about your supervisor at all.)</p><p> Still, models with beyond-episode goals emerging from this sort of process seem to me like they&#39;re at risk of scheming regardless. For one thing, the considerations discussed in the previous section all apply here – eg, this sort of training involves pointing your model&#39;s cognition in a very future-focused direction, thereby plausibly inducing it to develop various scheming-conducive cognitive patterns, to attach value to various long-term consequences, and so on (and in this case, the horizon of the episode sets no bound on the temporal horizon of the &quot;future&quot; that the model&#39;s cognition is pointed towards; rather, that bound is set, centrally, by your <em>evaluations</em> of what the model&#39;s actions will cause, when).</p><p> More than this, though, it seems plausible to me that your evaluations of the consequences of a model&#39;s action will be in some sense &quot;noisier&quot; than a reward process that depends causally on those consequences, in a manner that makes it harder to differentiate between the different <em>sorts</em> of long-term goals your training is incentivizing. For example, maybe your model is behaving in a way that seems to you, broadly, like it will lead to your company being successful in three years, but you can&#39;t tell whether it will also create lots of harmful externalities – whereas a reward process that could actually see the consequences after three years would be able to tell. And an inability to readily distinguish between the different sorts of long-term goals you might be instilling seems like it increases the risk of accidentally instilling a schemer-like goal. <sup class="footnote-ref"><a href="#fn-ZvAv8KJZnntyccKuJ-3" id="fnref-ZvAv8KJZnntyccKuJ-3">[3]</a></sup> </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-ZvAv8KJZnntyccKuJ-1" class="footnote-item"><p> We could try appealing to simplicity (thanks to Evan Hubinger for discussion), but it&#39;s not clear to me that &quot;five minutes&quot; is meaningfully simpler than &quot;a month.&quot; <a href="#fnref-ZvAv8KJZnntyccKuJ-1" class="footnote-backref">↩︎</a></p></li><li id="fn-ZvAv8KJZnntyccKuJ-2" class="footnote-item"><p> This is somewhat akin to a form of &quot; <a href="https://www.lesswrong.com/posts/D4gEDdqWrgDPMtasc/thoughts-on-process-based-supervision-1#4___Process_based_supervision___and_why_it_seems_to_solve_this_subproblem">process-based feedback</a> ,&quot; except that in a strict form of process-based feedback, you never look at <em>any</em> of the outcomes of the model&#39;s actions, whereas in this version, you can look at outcomes up to whatever time-horizon is efficient for you to get data about. <a href="#fnref-ZvAv8KJZnntyccKuJ-2" class="footnote-backref">↩︎</a></p></li><li id="fn-ZvAv8KJZnntyccKuJ-3" class="footnote-item"><p> For example, maybe you wanted to create a long-term goal regulated by some concept of &quot;honesty,&quot; which you were counting on to prevent scheming. But maybe you can&#39;t tell if you&#39;ve succeeded. <a href="#fnref-ZvAv8KJZnntyccKuJ-3" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/Xtb9SMrQofpxzEw4T/is-scheming-more-likely-in-models-trained-to-have-long-term#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/Xtb9SMrQofpxzEw4T/is-scheming-more-likely-in-models-trained-to-have-long-term<guid ispermalink="false"> Xtb9SMrQofpxzEw4T</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Thu, 30 Nov 2023 16:43:07 GMT</pubDate> </item><item><title><![CDATA[Normative Ethics vs Utilitarianism]]></title><description><![CDATA[Published on November 30, 2023 3:36 PM GMT<br/><br/><p>这篇文章的主要观点是，我想让每个人都关注 John David Presserman 的精彩<a href="https://twitter.com/jd_pressman/status/1729994771719180389">播客</a>，他在其中与 Zvi 聊天。</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ddfa529-629c-4546-a200-3b9f85bcc36b_606x354.png"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/si87gyjB4eRdnnScf/ieyhquprok6nfdnuglao" alt="" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/si87gyjB4eRdnnScf/rydcyoqvbczchp8qzhlj 424w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/si87gyjB4eRdnnScf/ci6gdoi8lpbqr9xcrqaw 848w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/si87gyjB4eRdnnScf/xwdgjomc9ilx6jcev3ms 1272w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/si87gyjB4eRdnnScf/ieyhquprok6nfdnuglao 1456w"></a></p><p></p><p>约翰在这篇文章中渴望与 Zvi 就有关欺骗性内在一致性的 LessWrong 风格的争论进行争论。但兹维并没有真正上钩。相反，他们在播客中大部分时间都在谈论 John 关于 RLaiF 的想法。</p><h1> RLaiF 与规范伦理有什么关系？</h1><p></p><p> John 在播客的大部分时间里都在谈论 RLaiF 模型如果过度训练就会陷入退化状态的趋势。典型的例子是“<a href="https://twitter.com/jd_pressman/status/1696973057133584490">是的垃圾邮件发送者</a>”。在这种情况下，强化学习从第二个人工智能模型获得奖励，该模型对“这是一个好的结果”回答“是”或“否”。最终，我们正在训练的人工智能学会了重复输出“是”这个词，因为这会欺骗人工智能法官每次也回答“是”。</p><p> John将RLaiF模型陷入退化反馈模式的倾向与基于规则的伦理体系和基于结果的伦理体系（功利主义）之间的差异进行了类比。在规范的伦理体系中，人们遵循基于历史实践的各种规则，例如“不杀人”、“不偷盗”等。相比之下，在功利主义中，没有硬性规定，信徒只是寻求最大化单个目标函数，即世界上“善”或效用的总量。</p><p>正如功利主义在<a href="https://plato.stanford.edu/entries/repugnant-conclusion/">理论</a>和<a href="https://www.cnbc.com/2023/11/04/sam-bankman-fried-sentence-could-be-100-plus-years-or-mere-decades.html">实践上</a>都有糟糕的失败模式一样，当人工智能接受单一目标函数的训练时，它不可避免地会陷入奇怪的、不受欢迎的局部最大值。在伦理学中，我们依靠一套<a href="https://en.wikipedia.org/wiki/Ten_Commandments">历史上制定的</a>规则来解决这个问题，这些规则已被经验证明可以避免最坏的结果。同样，John 认为，我们可以通过评估达到全局最大值的过程来避免 RLaiF 框架中的反常最大化。</p><h1>一个简单的研究计划</h1><p></p><p>我想<a href="https://twitter.com/nagolinc/status/1730043307546341779">建议</a>通过构建最简单的测试用例来测试约翰的假设：</p><p>训练一个退化为“是的垃圾邮件发送者”的 RLaiF 模型</p><p>在此过程中，定期对奖励函数进行“检查点”</p><p>创建一个新的奖励函数，它是检查点的加权和</p><p>验证使用这个新的奖励函数训练不会退化为“是的垃圾邮件发送者”（请注意，如果我们允许我们的权重集为 1,0,0,0...，这就是微不足道的事实）</p><p>确定 RLaiF 退化为“yes-spammer”的边界条件是什么</p><h1>结论</h1><p></p><p>我还想呼应约翰在播客结尾处的结论：</p><p>对象层面的讨论很有价值，但具体的批评比广泛的、不准确的陈述更有效。</p><p>对人工智能的担忧应该集中在具体问题上，比如复杂反馈循环的稳定性，而不是一般性的怀疑。</p><p>人工智能中的规范推理和结果主义推理之间存在重要的权衡。</p><p>人工智能中纯粹的结果主义推理，如果没有规范的道德规范，就有可能导致负面结果。</p><p>主要关注的是人工智能中的超级后果论，而不是超级智能本身。</p><p>人们普遍认为超级结果主义具有潜在的危险。</p><p>超级后果主义产生的条件应该成为人工智能伦理辩论的核心部分。</p><p>当前的人工智能话语因其形式和参与者而遭受相互挫折。</p><p>更多的同行讨论，而不是专家与公众或倡导辩论，可以带来更深入的理解。</p><p>我们应该以同伴而非对手的身份相互接触，以促进建设性对话。</p><br/><br/> <a href="https://www.lesswrong.com/posts/si87gyjB4eRdnnScf/normative-ethics-vs-utilitarianism#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/si87gyjB4eRdnnScf/normative-ethics-vs-功利主义<guid ispermalink="false">si87gyjB4eRdnnScf</guid><dc:creator><![CDATA[Logan Zoellner]]></dc:creator><pubDate> Thu, 30 Nov 2023 15:36:01 GMT</pubDate> </item><item><title><![CDATA[Information-Theoretic Boxing of Superintelligences]]></title><description><![CDATA[Published on November 30, 2023 2:31 PM GMT<br/><br/><p>拳击一个比我们更聪明的智能体是令人畏惧的，但信息论、热力学和控制论为我们提供了可以从根本上限制智能体独立于智能体的工具。特别是，我们也许能够通过限制人工智能对信息的访问来遏制它</p><h1>限制输出和输入</h1><p>超级智能人工智能有可能帮助我们，也有可能伤害我们。最大限度地减少伤害的一种方法是对人工智能<i>进行限制</i>：遏制它，使其无法自由影响其外部世界，理想情况下，同时保留其提供帮助的潜力。</p><p>拳击很复杂。摧毁人工智能肯定会阻止它影响任何事情。将它扔进黑洞可能会导致它与宇宙的其他部分断开，同时可能保留它的存在，尽管即便如此，它也可能利用一些未知的物理原理将<a href="https://en.wikipedia.org/wiki/Markov_blanket"><u>信息泄漏回事件视界</u></a>，或者在黑洞后持续存在或重建自身。已经蒸发了。</p><p>我们可以在仍然能够<i>使用</i>人工智能的同时限制它吗？我们可以尝试阻止它与其环境进行物理交互，只允许它向用户<a href="https://www.lesswrong.com/tag/oracle-ai"><u>呈现信息</u></a>，但超级智能可以滥用任何通信渠道来操纵其用户，从而<a href="https://www.lesswrong.com/posts/wKnwcjJGriTS9QxxL/dreams-of-friendliness"><u>授予它更多权力</u></a>或<a href="https://www.lesswrong.com/posts/aBRS3x4sPSJ9G6xkj/underspecification-of-oracle-ai"><u>提高其预测能力</u></a>。为了成功地以这种方式限制人工智能，我们需要限制它与环境进行物理交互以及交流信息和操作的能力。我们将这种<i>输出装箱称为“输出装箱”</i> ：通过限制 AI 的各种输出来包含它。</p><p>大多数关于装箱的讨论都集中在输出装箱上，但是这种方法有一个被忽视的镜像，我们将其称为<i>输入装箱</i>：通过限制人工智能可以访问的信息来包含人工智能。 （为了完整起见，我们还可以考虑独立于输入和输出的装箱技术，其中我们通过限制人工智能的功能来包含人工智能，例如通过限制其计算速度或每秒从初始条件重新启动它）。</p><p>在本文的其余部分中，我们将介绍并研究一种理论输入装箱技术，该技术包含人工智能，通过使用信息论、热力学和控制理论的结果来控制其所拥有的有关其环境的信息位数。</p><h1>好的调节器和坏的钥匙</h1><p>当今强大的人工智能依赖于海量的数据（至少在训练期间），因此限制它们对数据的访问会限制它们后续的能力，但我们是否可以通过限制超级智能对数据的访问来从<i>根本上</i>限制其外部影响？</p><p>我们知道，智能体需要了解其环境才能在其中有效地行动：Conant 和 Ashby 在 1970 年发表的一篇（ <a href="https://www.lesswrong.com/posts/wTJECdFSAk4843mFj/thoughts-on-the-good-regulator-theorem#:~:text=This%20is%20among%20the%20worst%20papers%20I%27ve%20ever%20skimmed."><u>备受</u></a><a href="https://www.lesswrong.com/posts/Dx9LoqsEh3gHNJMDk/fixing-the-good-regulator-theorem#:~:text=This%20may%20be%20the%20most%20misleading%20title%20and%20summary%20I%20have%20ever%20seen%20on%20a%20math%20paper."><u>诟病的</u></a>）关于<a href="http://pespmc1.vub.ac.be/books/Conant_Ashby.pdf"><u>良好调节定理的</u></a>论文中研究了这一点。<i>调节器</i>是维持所需特性的任何机制，例如恒温器或大脑及其稳态子系统。好的调节器定理指出，系统的每个好的调节器都必须包含系统的模型。该定理的另一种解析表明， <a href="http://cadia.ru.is/wiki/_media/public:t-720-atai:a_primer_for_conant_and_ashby_s_good-regulator_theorem.pdf"><u>每把好钥匙都必须是它打开的锁的模型</u></a>，约翰温特沃斯<a href="https://www.lesswrong.com/posts/Dx9LoqsEh3gHNJMDk/fixing-the-good-regulator-theorem"><u>完善了该定理</u></a>（及其证明），阐明：</p><blockquote><p> <i>[Conant 和 Ashby 实际上证明] 每个最优且不包含不必要噪声的调节器都相当于</i><i>一个调节器，它首先重建其控制的系统的变量值，然后根据这些值选择其输出</i></p></blockquote><p>因此，我们能否通过阻止人工智能对其外部环境进行建模来限制它？我们能否阻止人工智能成为我们将其放入的笼子的“好钥匙”？让我们看看这种人工智能的潜在信息来源：</p><ul><li>模型的初始条件（例如训练数据和学习模式）</li><li>感官输入（例如通过摄像头和麦克风）</li><li>逻辑演绎和外推</li></ul><p>我们假设我们试图限制的人工智能在逻辑上是无所不知的；它可以从理论上尽可能多地从初始条件和感官输入中获取信息。这就留下了两个作为输入框目标的信息源：初始条件和感官输入。</p><p>在实践中，限制这些信息来源是很棘手的。例如，我们可以尝试只为人工智能提供一个传感器，即一些低分辨率相机来接收指令。然而，相机接收到的图像可能会受到附近声音的振动、环境磁场、背景辐射等的微妙影响。如果解释正确，这些干扰源就会成为信息源。</p><p>但是，假设我们可以克服这些<i>实际</i>障碍，我们可以量化我们可以从输入框中获得多少控制权吗？为了回答这个问题，我们来看看控制理论。</p><h1>位、盒子和控制</h1><p>首先，一些术语。与调节器一样，<i>控制环路</i>使用传感器、函数和一些执行器来控制变量的行为。<i>控制系统</i>使用多个控制循环来管理系统的行为。当控制环不根据有关其操作结果的反馈采取行动时，控制环就是<i>开环的</i>，就像定时器上的加热器一样。<i>闭环</i>控制器包含反馈，例如巡航控制或恒温器。最后，这里的<i>熵</i>指的是<a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)"><u>香农熵</u></a>，它衡量变量的不确定性。 Touchette 和 Lloyd 在<a href="https://arxiv.org/pdf/chao-dyn/9905039.pdf"><u>信息理论</u></a>控制极限中研究了控制系统的极限，并写道：</p><blockquote><p><i>熵通过表征明确编码描述系统的整体所需的最小资源量（位），提供了对无序性或丢失信息的精确测量</i>。</p></blockquote><p>他们总结了他们的主要结果，写道：</p><blockquote><p><i>在控制过程中，必须不断获取、处理和使用信息来约束或维持系统的轨迹。</i></p><p><i>热力学第二定律...对开环控制所需的最小耗散量设置了绝对限制...闭环控制的信息论分析表明反馈控制本质上是一个零和游戏：<strong>直接从控制装置控制的动态系统除了在没有此类信息（开环控制）的情况下可实现的熵减少之外，还可以将该系统的熵最多减少一位</strong>。</i></p></blockquote><p>换句话说，当将信息作为热力学系统的一部分时，热力学第二定律告诉我们，你无法完美地控制系统。当控制循环根据从其控制的系统获取的信息调整其操作时，存在一个基本的权衡：<strong>对于从系统收集的每一位信息，您只能将系统的无序度减少一位。你可能没有这些信息</strong>。通过信息可以提高控制程度有严格的一对一限制。</p><p>为了形式化这一点，让 t 表示时间，并让<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I_T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.064em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label=""><span class="mjx-mrow" aria-hidden="true"></span></span></span></span></span>表示在时间<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="t=T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.372em; padding-bottom: 0.298em;">t</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span>时盒装智能体可用的信息量。 <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I_T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.064em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span>的变化由输入信息的时间导数（标记为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="i"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span> ）减去输出或“使用”信息的时间导数（标记为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="o"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">o</span></span></span></span></span></span></span> ）给出： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6FAMJL89DKmSeYTha/nbpozftdirivgc3bzeii"></figure><p>因此<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span>时刻的可用信息为</p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6FAMJL89DKmSeYTha/h8nhh8x2beyig8jbrljg"></figure><p>其中C表示模型初始条件中包含的信息。我们可以在连续的时间步上可视化这一点（简化版本），因为信息被收集然后用完： </p><figure class="image image_resized" style="width:52.04%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6FAMJL89DKmSeYTha/q25vhab6anqlhmaabqka" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6FAMJL89DKmSeYTha/ltki8r2cpipmkejyrwfz 141w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6FAMJL89DKmSeYTha/semrw7icx8dvpk3jlnht 221w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6FAMJL89DKmSeYTha/hij2loeprglaldhoa0hq 301w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6FAMJL89DKmSeYTha/t6gkaadzgdlxsbi6cbbh 381w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6FAMJL89DKmSeYTha/qlfg1i1dg0jyompklqt7 461w"></figure><p>这看起来很有希望。如果我们限制人工智能在其环境中用于行动的信息方面可以收集的信息，那么它将没有足够的信息来有效地采取行动。或者，用上面论文的语言来说，代理将没有足够的关于其外部动力系统的信息来充分减少该动力系统的熵。</p><p>我们可以更正式地定义输入框如下：假设我们有一个代理<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span> ，它在时间<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span>具有<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I_T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.064em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span>信息量。 <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>要实现某个外部动作<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span> ，需要一定的外部环境信息<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I_X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.064em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span></span></span> ，当<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I_T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.064em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span>小于<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I_X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.064em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span></span></span>时，可以说<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>无法实现<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X。</span></span></span></span></span></span></span>如果我们将<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span>设置为某种最小的逃逸场景，那么我们可以说当<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I_T < I_X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.064em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&lt;</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base" style="margin-right: -0.064em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span></span></span>时<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>是输入框的。这不依赖于代理的任何能力或智力，只依赖于它的<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I_T"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.064em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span></span></span></span></span></span></span> ，我们假设我们可以限制它，以及<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="I_X"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.064em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;">I</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;">X</span></span></span></span></span></span></span></span></span> ，它仅取决于外部环境。</p><p>约翰·温特沃斯（John Wentworth）是我们之前使用过的<a href="https://www.lesswrong.com/posts/Dx9LoqsEh3gHNJMDk/fixing-the-good-regulator-theorem"><u>《修复良好调节器定理》一书</u></a>的作者，他考虑了一个<a href="https://www.lesswrong.com/posts/6rZroG3mztowktJzp/how-many-bits-of-optimization-can-one-bit-of-observation"><u>关于控制极限的类似问题</u></a>。他推测观察额外的 N 位信息允许系统执行最多 N 位的额外优化。他得出的结论是，这个猜想是<a href="https://www.lesswrong.com/posts/6rZroG3mztowktJzp/how-many-bits-of-optimization-can-one-bit-of-observation?commentId=Pvhpc7PF8DhsyMGgk"><u>错误的</u></a>，并引用了一个反例，即短密码解锁长消息，并得出结论：“<i>少量的观察可以极大地提高系统的优化能力”</i> 。其他人<a href="https://www.lesswrong.com/posts/dfTm26pvq7yQp8mR3/one-bit-of-observation-can-unlock-many-of-optimization-but"><u>也同意</u></a>这一观点，他们认为，在一些实际限制下，“<i>即使在可逆计算的世界中，一个人可以从单个比特中挤出多少优化也是没有限制的”</i> 。</p><p>然而，这些反例依赖于智能体随后“跟进”他们所学知识的能力。 “密码”中的信息仅在提供收集或解锁更多信息的机会时才有用。密码或任何信息的即时效用受到密码本身的信息和先验知识的总和的限制，并且假设我们也限制代理对后续信息的访问。因此，这些反例不应免除输入框人工智能的优化限制。如果我们可以限制代理从输入和先验知识中收集的信息，我们就可以限制该代理，无论其智能如何。</p><h1>建造更好的盒子</h1><p>输入框是一个有前途的研究途径，因为它解决了通过信息基础限制人工智能能力的挑战，而与盒子中的人工智能有多智能无关。</p><p>本文只是一个介绍，我们有兴趣探索输入框思想的进一步细化。例如，对我们允许进入盒子<i>的</i>信息进行更深入的分析可能会让我们对人工智能进行更细粒度的控制（例如在关于环境与法律的信息<a href="https://www.lesswrong.com/posts/6rZroG3mztowktJzp/how-many-bits-of-optimization-can-one-bit-of-observation?commentId=n5b4RvdrSxFsqCFw5#n5b4RvdrSxFsqCFw5"><u>的讨论</u></a>中），特别是如果我们能够稳健地区分对解决问题有用的信息我们的问题，对于逃避很有用。</p><p>也就是说，我们也许能够识别智能体想要追求的危险路径或动作序列，而不是从根本上限制智能体的<i>整体</i>控制。也就是说，对于一个代理来说，要实现一个动作，它需要有关其执行器与其最终期望结果之间的控制路径的信息。 <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="A"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">A</span></span></span></span></span></span></span>必须了解其第一个行动将如何改变其外部环境，以及后续行动将如何改变新的、变化的环境，等等。</p><p>如果我们限制智能体对危险控制路径的危险信息的访问，我们就可以放松对信息输入的基本限制，而不允许危险行为。这可能比从根本上限制所有信息更为务实，因为危险信息可能是所有信息的一小部分——位必须与危险行为相关才能成为危险位。然而，这将以牺牲这些基本限制提供的保证为代价。</p><p> Deric Cheng 提出，开发输入框的另一个有希望的途径是对信息的使用施加根本性的延迟。信息的效用会随着时间的推移而衰减，因此如果人工智能只能对 24 小时前的信息采取行动，那么它的作用就会弱得多，尤其是对于利用股市等高速行动而言。</p><p>除了超级智能的装箱技术之外，输入装箱可能对更多的利基应用有用。例如，通过在<a href="https://www.lesswrong.com/tag/ai-evaluations"><u>评估</u></a>过程中输入装箱人工智能模型，我们可以在保证任何危险行为不会漏出盒子的情况下测试模型，这意味着评估人员可以主动提示危险行为并使用<a href="https://en.wikipedia.org/wiki/Red_team"><u>红队</u></a>技术，而不会影响<a href="https://www.lesswrong.com/posts/XCRsg2ZnHBNAN862T/improving-the-safety-of-ai-evals"><u>系统的安全性。评估</u></a>。</p><p>随着信息论、控制论和热力学的进一步完善和见解，输入框可以成为一个强大的工具，既适合利基应用，也可以用一个整洁的小蝴蝶结将超级智能包裹在一个安全、有用的盒子里。</p><p>这篇文章最初的灵感来自 Hugo Touchette 和 Seth Lloyd 的<a href="https://arxiv.org/pdf/chao-dyn/9905039.pdf"><u>信息理论控制极限</u></a>论文。有关控制理论、良好调节器定理和其他类似主题的更多信息，请查看：</p><ul><li> <a href="https://www.lesswrong.com/posts/fJKbCXrCPwAR5wjL8/what-is-control-theory-and-why-do-you-need-to-know-about-it"><u>什么是控制理论，为什么您需要了解它？</u></a>作者：理查德·肯纳威</li><li>Alain Bensoussan<i>等人</i>的<a href="https://arxiv.org/pdf/2006.05604.pdf"><u>机器学习和控制理论</u></a>。</li><li><a href="https://www.lesswrong.com/posts/Dx9LoqsEh3gHNJMDk/fixing-the-good-regulator-theorem"><u>修复良好调节器定理</u></a>作者：johnswentworth</li><li>约翰·贝兹 (John Baez) 的<a href="https://johncarlosbaez.wordpress.com/2016/01/27/the-good-regulator-theorem/"><u>《内部模型原理》</u></a></li><li>丹尼尔·L·肖尔滕 (Daniel L. Sholten) 的<a href="http://cadia.ru.is/wiki/_media/public:t-720-atai:a_primer_for_conant_and_ashby_s_good-regulator_theorem.pdf"><u>《Conant 和 Ashby 的“良好调节器定理”入门》</u></a></li><li>哈里什笔记本中 <a href="https://harishsnotebook.wordpress.com/2020/08/23/notes-on-the-good-regulator-theorem/"><u>关于良好调节器定理的注释</u></a></li><li><a href="https://www.lesswrong.com/posts/6rZroG3mztowktJzp/how-many-bits-of-optimization-can-one-bit-of-observation"><u>一点观察可以解锁多少位优化？</u></a>通过约翰斯温特沃斯<ul><li><a href="https://www.lesswrong.com/posts/dfTm26pvq7yQp8mR3/one-bit-of-observation-can-unlock-many-of-optimization-but"><u>一点点观察就可以实现许多优化——但代价是什么？</u></a>作者：dr_s。</li></ul></li><li><a href="https://arxiv.org/abs/2309.01933"><u>可证明安全的系统：实现可控 AGI 的唯一途径</u></a>Max Tegmark 和 Steve Omohundro</li></ul><p><i>本文基于 Elliot Mckernon 撰写的 Justin Shovelain 的</i><a href="https://www.convergenceanalysis.org/"><i><u>收敛分析</u></i></a>思想<i>。我们要感谢我们所引用的帖子的作者，以及 Cesare Ardito、David Kristoffersson、Richard Annilo 和 Deric Cheng 在撰写过程中提供的反馈。</i></p><br/><br/> <a href="https://www.lesswrong.com/posts/NZP6QvkXryJQFGkLF/information-theoretic-boxing-of-superintelligences-1#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/NZP6QvkXryJQFGkLF/information-theoretic-boxing-of-superintelligences-1<guid ispermalink="false"> NZP6QvkXryJQFGkLF</guid><dc:creator><![CDATA[JustinShovelain]]></dc:creator><pubDate> Thu, 30 Nov 2023 14:31:11 GMT</pubDate> </item><item><title><![CDATA[OpenAI: Altman Returns]]></title><description><![CDATA[Published on November 30, 2023 2:10 PM GMT<br/><br/><p>截至今天早上， <a target="_blank" rel="noreferrer noopener" href="https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board">新董事会已经就位，OpenAI 的其他一切也正式恢复到以前的状态</a>。</p><p>事件似乎按预期进行。如果您阅读过我<a href="https://thezvi.substack.com/p/openai-the-battle-of-the-board" target="_blank" rel="noreferrer noopener">之前关于 OpenAI 情况的两篇文章</a>，那么这里应该不会让您感到惊讶。</p><span id="more-23613"></span><p>似乎仍然值得将后记、官方声明和反应收集到自己的帖子中，以便将来参考。</p><p>最终的结果会是什么？随着时间的推移，当我们等待调查以及新董事会的组成和行为时，我们可能只会逐渐发现这一点。</p><p>我不相信 Q* 在赛事中发挥了实质性作用，因此这里不包括它。我也不在这里讨论奥特曼在安全方面的表现有多好或多坏。</p><h4>萨姆·奥尔特曼的声明</h4><p><a target="_blank" rel="noreferrer noopener" href="https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board">以下是 Sam Altman 的 OpenAI 官方声明</a>。他对所有人都很宽容，无论事实如何，这都是优雅而明智的举动。正如他自始至终所做的那样，他让其他人散布敌意，影响新闻报道并塑造公众反应，而他自己几乎完全提供积极和赞扬。聪明的。</p><blockquote><p>在开始接下来的内容之前，我想先表达一些谢意。</p><p>我爱并尊重伊利亚，我认为他是这个领域的指路明灯，也是人类的瑰宝。我对他的恶意为零。虽然 Ilya 将不再担任董事会成员，但我们希望继续我们的工作关系，并正在讨论他如何继续在 OpenAI 的工作。</p><p>我感谢 Adam、Tasha 和 Helen 与我们合作，找到了最能服务于使命的解决方案。我很高兴继续与 Adam 合作，并衷心感谢 Helen 和 Tasha 在此过程中投入了大量的精力。</p><p>还要感谢埃米特，他在帮助我们实现这一成果方面发挥了关键和建设性的作用。 Emmett 对人工智能安全和平衡利益相关者利益的奉献是显而易见的。</p><p>米拉在整个过程中表现出色，自始至终无私地为使命、团队和公司服务。她是一位令人难以置信的领导者，如果没有她，OpenAI 就不会成为 OpenAI。谢谢。</p><p>格雷格和我是经营这家公司的合伙人。我们从未完全弄清楚如何在组织结构图上传达这一点，但我们会的。与此同时，我只是想澄清一下。感谢你们从一开始以来所做的一切，以及从这件事开始到上周你们处理事情的方式。</p><p>领导团队——Mira、Brad、Jason、Che、Hannah、Diane、Anna、Bob、Srinivas、Matt、Lilian、Miles、Jan、Wojciech、John、Jonathan、Pat 等等——显然已准备好在没有任何情况下运营公司。我。他们说，评估首席执行官的一种方法是看你如何挑选和培训你的潜在继任者；在这个指标上，我做得比我想象的要好得多。我很清楚，公司掌握在伟大的人手中，我希望每个人都清楚这一点。谢谢你们。</p></blockquote><p>让我们理解最后一段。前格雷格领导团队显然已经准备好在没有奥特曼的情况下管理公司。</p><p>这意味着无论是什么原因导致董事会解雇 Altman，无论 Altman 是否在不同程度上迫使董事会采取行动，如果所有相关人员都选择在没有 Altman 的情况下继续工作，那么 OpenAI 就会没事。我们可以选择相信或不相信奥特曼在接受 Verge 采访时声称，他只是在周六董事会给他打电话后才考虑回归，而且我们可以推测奥特曼在那段时间在幕后做了什么。我们不知道。我们当然可以猜测，但我们不知道。</p><p>然后他谈到了他的优先事项。</p><blockquote><p><strong>下一个是什么？</strong></p><p>我们有三个当务之急。</p><p>推进我们的研究计划并进一步投资于我们的全栈安全工作，这对我们的工作一直至关重要。我们的研究路线图很明确；这是一个非常专注的时刻。我和你们一样感到兴奋；我们将化危机为机遇！我会和米拉一起解决这个问题。</p><p>持续改进和部署我们的产品并服务我们的客户。重要的是，人们要体验人工智能的好处和前景，并有机会塑造它。我们始终相信，优秀的产品是实现这一目标的最佳方式。我将与 Brad、Jason 和 Anna 合作，确保我们对世界各地的用户、客户、合作伙伴和政府的坚定承诺是明确的。</p><p>布雷特、拉里和亚当将非常努力地完成一项极其重要的任务，即建立一个具有不同观点的董事会、改善我们的治理结构以及监督对最近事件的独立审查。我期待在这些关键步骤上与他们密切合作，以便每个人都能对 OpenAI 的稳定性充满信心。</p><p>我非常期待与你们一起完成构建有益的 AGI 的工作——世界上最好的团队，世界上最好的使命。</p></blockquote><p>研究，然后产品，然后董事会。这样的陈述不能被信赖，但是这样的陈述已经是最好的了。我们必须密切关注，看看这些承诺是否兑现。新董事会会是什么样子？是否真的会对所发生的事情进行强有力的独立调查？ Ilya 和 Jan Leike 是否会获得 OpenAI 安全工作所需的资源和支持？</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.theverge.com/2023/11/29/23982046/sam-altman-interview-openai-ceo-rehired">奥特曼接受了 The Verge 的采访</a>。和董事会一样，他（我相信他是明智而光荣的）回避了所有有关导致与董事会争执的原因的问题，并期待着调查。据奥特曼说，回来并不是他的主意，相反，他在周六早上接到了一些董事会的电话，询问他是否有可能回来。</p><p>他表示，他并不专注于重返董事会，这不是他的重点，但治理结构显然存在问题，需要一段时间才能解决。</p><blockquote><p>问： <a target="_blank" rel="noreferrer noopener" href="https://www.theverge.com/2023/11/29/23981848/sam-altman-back-open-ai-ceo-microsoft-board"><strong>“完善治理结构”</strong></a><strong>是什么</strong><strong>意思？非营利控股公司的结构会发生变化吗？</strong></p><p> Altman：对于董事会成员来说，这是一个更好的问题，但现在还不是。诚实的答案是他们需要时间，我们将支持他们真正开始思考这个问题。显然我们的治理结构有问题。解决这个问题的最好方法是需要一段时间。我完全理解为什么人们现在就想要答案。但我也认为这种期望是完全不合理的。</p><p> ……</p><p>哦，只是因为设计一个非常好的治理结构，特别是对于如此有影响力的技术来说，不是一个一周的问题。人们需要花费大量的时间来思考这个问题、进行辩论、获取外部观点、进行压力测试。那只需要一段时间。</p></blockquote><p>是的。很高兴看到这种高度合理的时间表和期望设定，而不是之前涉及人为最后期限和危机的策略。</p><p> Mutari 在采访中证实，OpenAI 的安全方法没有改变，这与安全无关。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/sama/status/1730032994474475554">Altman 还就 Adam D&#39;Angelo 的潜在利益冲突做出了很好的声明</a>，表示他积极希望在董事会中拥有客户代表，并很高兴再次与他合作。 <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/sama/status/1727858661677240767">奥特曼还和德安吉洛待了几个小时。</a></p><h4>布雷特·泰勒的声明</h4><p>我们还有布雷特·泰勒的声明。我们对他知之甚少，因此仔细阅读他的第一份官方声明似乎是明智之举。</p><blockquote><p>我谨代表 OpenAI 董事会向整个 OpenAI 社区，特别是所有 OpenAI 员工表示感谢，他们在过去的一周里齐心协力，为公司找到了前进的道路。你们的努力帮助这个令人难以置信的组织继续履行其使命，确保通用人工智能造福全人类。我们很高兴 Sam、Mira 和 Greg 重新齐心协力领导公司并推动公司向前发展。我们期待与他们和你们所有人合作。</p><p>作为董事会，我们致力于加强 OpenAI 的公司治理。我们计划这样做：</p><ul><li>我们将建立一个由杰出人士组成的合格、多元化的董事会，他们的集体经验代表了 OpenAI 使命的广度——从技术到安全到政策。我们很高兴董事会将包括一名无投票权的 Microsoft 观察员。</li><li>我们将进一步稳定 OpenAI 组织，以便我们能够继续履行我们的使命。这将包括召集董事会独立委员会来监督对近期事件的审查。</li><li>我们将加强 OpenAI 的治理结构，让所有利益相关者——用户、客户、员工、合作伙伴和社区成员——都能相信 OpenAI 将继续蓬勃发展。</li></ul><p> OpenAI 是一个比以往任何时候都更加重要的机构。 ChatGPT 让人工智能成为数亿人日常生活的一部分。它的普及使得人工智能——它的好处和风险——成为几乎所有有关政府、企业和社会未来的对话的核心。</p><p>我们了解这些讨论的重要性以及 OpenAI 在这些令人惊叹的新技术的开发和安全中的核心作用。在确保我们有效应对这些挑战方面，你们每个人都发挥着关键作用。我们致力于倾听你们的声音并向你们学习，我希望很快能与你们所有人交谈。</p><p>我们很高兴成为 OpenAI 的一部分，并很高兴与大家合作。</p></blockquote><p>大多数情况下，布拉德·泰勒正确地扮演了董事会主席的角色，这告诉我们除了他非常了解这个角色之外，我们已经知道了这一点。</p><p>微软只会在董事会中获得一名观察员，其他投资者可能也不会获得席位。这是个好消息， <a target="_blank" rel="noreferrer noopener" href="https://www.theinformation.com/articles/openai-isnt-expected-to-offer-microsoft-other-investors-a-board-seat">与 The Information 的报道相符</a>。</p><p>这里的“加强治理结构”是什么意思？我们不知道。它可能正是我们所需要的，它可能是橡皮图章，也可能是其他任何东西。我们不知道最终的结果是什么。</p><p>关于最近发生的事件的回顾的声明比我希望的要弱。这增加了新董事会没有得到或分享真实解释的可能性。</p><p>他多次提到安全。根据我对泰勒的了解，我的猜测是他不熟悉这些问题，并且实际上不知道这在上下文中意味着什么，或者真正的利害关系是什么。并不是他不屑一顾或怀疑，而是他第一次遇到这一切。</p><h4>拉里·萨默斯的声明</h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/LHSummers/status/1730047296375590995">以下是董事会成员拉里·萨默斯 (Larry Summers) 通过 Twitter 发布的公告</a>，该公告提高了零内容的门槛。所以我们对这里知之甚少。</p><blockquote><p>拉里·萨默斯：我很高兴也很荣幸刚刚被任命为<a target="_blank" rel="noreferrer noopener" href="https://twitter.com/OpenAI">​​ @OpenAI</a>的独立董事。我期待与董事会同事和 OpenAI 团队合作，推进 OpenAI 极其重要的使命。</p><p>正如 Bret 和 Sam 在他们的信息中概述的，第一步包括建立一个出色的董事会、加强治理程序以及支持卓越的 OpenAI 社区。</p></blockquote><h4>海伦·托纳的声明</h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/hlntnr/status/1730034020140912901">以下是海伦·托纳 (Helen Toner) 辞去董事会职务后在 Twitter 上发表的完整声明</a>。</p><blockquote><p> Helen Toner (11/29)：今天，我正式辞去 OpenAI 董事会职务。感谢许多朋友、同事和支持者，他们公开和私下表示，他们知道我们的决定始终是由我们对 OpenAI 使命的承诺驱动的。</p><p>关于过去一两周的文章已经写了很多；肯定还会说更多的话。目前，即将上任的董事会已宣布将进行全面的独立审查，以确定下一步的最佳措施。</p><p>需要明确的是：我们的决定是关于董事会有效监督公司的能力，这是我们的角色和责任。尽管有猜测，但我们的动机并不是要放慢 OpenAI 的工作速度。</p><p>当我在 2021 年加入 OpenAI 董事会时，我和我周围的许多人已经清楚，这是一个将做大事的特殊组织。能够成为该组织的一员是一种巨大的荣幸，因为世界其他地方也意识到了同样的事情。</p><p>我非常尊重 OpenAI 团队，并祝愿他们以及即将上任的 Adam、Bret 和 Larry 董事会一切顺利。我将继续专注于人工智能政策、安全和保障方面的工作，所以我知道我们的道路在未来几年将会多次交叉。</p></blockquote><p>许多愤怒的人继续要求澄清董事会解雇奥特曼的原因。我相信，他们中的大多数人都对托纳和其他人继续不分享细节感到兴奋，并允许董事会外的情况恢复到原来的状态。</p><p>据称将会进行独立调查。到那时， <a target="_blank" rel="noreferrer noopener" href="https://thezvi.substack.com/p/openai-the-battle-of-the-board">我相信我们对发生的事情有了一个比较清晰的了解</a>。托纳的声明暗示了一些额外的细节。</p><h4> OpenAI 需要一个强大的董事会来解雇其首席执行官</h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/tszzl/status/1727498453864026603">罗恩明白了</a>。董事会需要保持其红色大按钮继续前进，但如果希望该按钮保持不变，仍然必须对其行为负责。</p><blockquote><p> Roon：董事会有一个红色按钮，但也必须解释为什么其决策有益于人类。如果做不到这一点，那么它将面临员工、客户和合作伙伴的反抗。 OpenAI 目前为人类创造了巨大的价值，默认情况下应该受到全力保护。即使有一点点尊重或给出充分的理由，营利性组织也不可能一致转移到其他地方。</p></blockquote><p>危险在于， <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/robbensinger/status/1727786741019582855">如果我们不小心，我们就会吸取错误的教训。</a></p><blockquote><p>托比·奥德：过去几天打破了萨姆·奥尔特曼令人难以置信的权力面临任何责任的神话。他告诉我们不应该相信他，但我们现在知道董事会“不能”解雇他。我认为这很重要。</p><p>罗布·本辛格：我们没有了解到“他们不能解雇他”。我们确实了解到，该组织的员工对 Sam 有足够的信心，如果没有董事会提供一些良好的支持论据，员工不会同意董事会的愿望。 （他们是否会接受好的论点尚未得到检验。）</p><p> ……</p><p>我只是想让我们明确一点，关于董事会当前权力的更新不应该是一个巨大的更新，因为如果董事会能够更好地解释其理由并且理由似乎是正确的，那么工作人员可能会接受董事会在这种情况下的决定更强。</p></blockquote><p>这么。从我们的角度来看，董事会执行得很糟糕，其成员也提出了相对容易的言辞目标。即使董事会有充分的理由这样做，情况也是如此。如果董事会没有在执行过程中搞砸，并且有更多的庄严呢？我认为事情会有所不同。</p><p>如果经过调查，萨默斯、德安吉洛和泰勒都决定再次解雇奥特曼（请注意，我非常不希望这样做，但如果他们确实决定这样做），我向你保证，他们会以非常不同的方式处理这件事，并且我会预测一个非常不同的结果。</p><p>萨姆·奥尔特曼最好的事情之一就是他坦率地告诉<a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=dY1VK8oHj5s">我们不应该相信他</a>。大多数不值得信任的人都会说另外的话。与奥特曼关于存在风险和安全需求的经常非常好的陈述一样。当人们思路清晰并提供帮助时，我们应该努力奖励他们，而不是反对他们。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/AndrewCritchPhD/status/1730064832152654189">我也同意安德鲁·克里奇的观点</a>，即董事会终止错误的监督信号是好事也是正确的。如果首席执行官使董事会无法监督他们，或者以其他方式反对董事会，那么董事会就有责任将事情推向高潮，即使不存在其他问题。</p><p>良好的背景，可能对包括 Helen Toner 在内的几位董事会成员的想法产生影响：前 OpenAI 董事会成员 Holden Karnofsky 对<a target="_blank" rel="noreferrer noopener" href="https://www.cold-takes.com/nonprofit-boards-are-weird-2/#the-boards-main-duties">非营利组织董事会为何、到底如何奇怪</a>以及如何最好地处理它的旧解释。</p><h4>部分董事会成员候选人</h4><p><a target="_blank" rel="noreferrer noopener" href="https://twitter.com/ESYudkowsky/status/1729200181349126232">Eliezer Yudkowsky 提名 Paul Graham 担任 OpenAI 董事会成员</a>。我看到了这种争论，特别是因为格雷厄姆显然非常关心他的孩子。我担心的是，他会太受 Altman 的引导，而且他会太倾向于将 OpenAI 本质上视为传统业务，并让这一点推翻其他问题，即使他知道不应该这样做。</p><p>如果他被算作奥特曼的盟友（他大概应该如此），那么他就很棒了。除了给 OpenAI 带来好处之外，它还可以为 Graham 提供有价值的内幕信息。埃利以泽澄清说，他的动机是让格雷厄姆有一个很好的机会在重要的时候弄清楚真实的事情，这听起来也很正确。</p><p>埃米特·希尔似乎也是一个明显的共识选择。</p><p>一个问题是电路板的光学器件很重要。如果你选择九个白人，那是非常不明智的。请参阅泰勒关于需要多元化观点的声明。</p><h4>估值问题</h4><p><a target="_blank" rel="noreferrer noopener" href="https://www.bloomberg.com/opinion/articles/2023-11-27/openai-is-still-an-86-billion-nonprofit?sref=1kJVNqnU">马特·莱文 (Matt Levine) 报道了自周二以来的进展</a>，特别是 OpenAI 在即将到来的销售中的估值没有变化，因为私人市场可能顽固地拒绝调整其价格。在我的模型中，像这样的私人估值相当任意，并且基于每个参与者可以讲述的社会故事以及每个人的相对谈判地位，以及什么将为公司产生正确的动力，而不是公平的价值估计。此外，每个参与其中的人都投资严重不足或投资过度，不知道公允价值实际上是什么，并且大多希望得到某种形式的社会认可，这样他们就不会觉得价格被欺骗了。因此，通常投资者以荒谬的价格逃脱，而其他时候他们会被欺骗成很高的价格。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://garymarcus.substack.com/p/top-5-reasons-why-openai-was-probably">加里·马库斯（Gary Marcus）说，Openai从来没有价值860亿美元</a>。我不仅不同意，而且（哦，男孩不是投资建议！），如果我有这种能力（我没有），并认为这是一件道德上的事情，现在就以860亿美元的价格投资了。 Grok的大部分并不是“复制” GPT-4的大部分，而是考虑到他们最初坐了多长时间，该模型就很好地坚持了。</p><p>没有它的人，Openai就不是什么。这并不意味着他们缺乏各种秘密酱汁。从估值角度来看，我是看好的。没有Altman，估值将幸存下来？不，但是在反事实的情况下，由于健康问题的健康问题，阿尔特曼（Altman）暂停了，我绝对会认为860亿美元仍然便宜。</p><h4>光学问题</h4><p>在所有这些方面，一个关键的问题是董事会的错误在多大程度上是其光学元件不好。因此，这是<a target="_blank" rel="noreferrer noopener" href="https://twitter.com/paulg/status/1728014952877748297">保罗·格雷厄姆（Paul Graham）提倡出色原则的一个很好的例子</a>。</p><blockquote><p>保罗·格雷厄姆（Paul Graham）：当人们以“光学”为由批评行动时，他们几乎总是充满狗屎。他们真正说的是“您所做的看起来很糟糕。”但是，如果他们以这样的方式提出这一点，他们必须回答“实际上是不好的吗？”的问题。</p><p>如果有人做了不好的事情，则不需要谈论“光学”。而且，如果他们做的事情看起来很糟糕，但您知道不是，为什么您根本批评它？相反，您应该解释为什么它不像看起来那么糟糕。</p></blockquote><p>不良光学会导致坏事发生。因此，可以声称光学元件很糟糕，或者担心其他人会认为光学元件不好，或者声称您通常对光学元件不利。</p><p>您有两个回复。</p><ol><li>这意味着它的后果不好，这实际上是不好的。</li><li>崇高地支持“看起来不错”的正确行动。</li></ol><p>考虑到最近的事件，请考虑选项。我们都希望它是一种方式。通常是另一种方式。</p><br/><br/> <a href="https://www.lesswrong.com/posts/EfqAdxR7bvwQLMTQc/openai-altman-returns#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/efqadxr7bvwqlmtqc/openai-altman-returns<guid ispermalink="false"> EFQADXR7BVWQLMTQC</guid><dc:creator><![CDATA[Zvi]]></dc:creator><pubDate> Thu, 30 Nov 2023 14:10:08 GMT</pubDate> </item><item><title><![CDATA[[Linkpost] Remarks on the Convergence in Distribution of Random Neural Networks to Gaussian Processes in the Infinite Width Limit]]></title><description><![CDATA[Published on November 30, 2023 2:01 PM GMT<br/><br/><p><a href="https://drive.google.com/file/d/1O_RbD45RjBWD4-a8tcjosvyXOxcD_q2V/view?usp=sharing">链接的注释</a>是我在文献中浏览此结果的不同版本时“注意到”的。我认为，在神经网络上的这种数学工作值得，值得一提，但我没有理由认为这项特定的工作除了填补文献差距之外，还具有很大的影响。这是做太多衡量理论的人会考虑的一种胡说八道。<br><br><strong>抽象的。</strong>我们描述了结果的另一个版本的直接证明，即一系列完全连接的神经网络在无限宽度限制中收敛到高斯过程。我们确定的分布收敛是在不可分割的，<u>不可分割的</u>乘积空间<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(\mathbf{R}^{d'})^{\mathbf{R}^d}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">（</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-B" style="padding-top: 0.372em; padding-bottom: 0.372em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.619em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msup"><span class="mjx-base" style="margin-right: -0.003em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">D</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.065em; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">）</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-B" style="padding-top: 0.372em; padding-bottom: 0.372em;">R</span></span></span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.467em; padding-left: 0px; padding-right: 0.06em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">D</span></span></span></span></span></span></span></span>的</span></span></span></span></span>概率度量的弱收敛性<style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>，即从<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbf{R}^d"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-B" style="padding-top: 0.372em; padding-bottom: 0.372em;">r</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.619em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span></span></span>到<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathbf{R}^{d'}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-B" style="padding-top: 0.372em; padding-bottom: 0.372em;">r</span></span></span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.619em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-msup"><span class="mjx-base" style="margin-right: -0.003em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span> <span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.065em; padding-right: 0.06em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">&#39;</span></span></span></span></span></span></span></span></span></span></span></span></span>的函数空间，其拓扑结构的收敛序列对应于<u>点的</u>收敛。<a href="https://arxiv.org/abs/2107.01562">由于鲍里斯·哈宁（Boris <u>Hanin）</u>而导致的这种定理</a>，结果本身已经暗示了结果，但是直接证明我们较弱的结果能够负担得起替代<u>Hanin</u>证据中更具技术性的部分，以建立紧密性，以较短，更抽象的方式来确定紧密度争论。</p><br/><br/> <a href="https://www.lesswrong.com/posts/nM7qwfbB9dAxBopLT/linkpost-remarks-on-the-convergence-in-distribution-of-1#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/nm7qwfbb9daxboplt/linkpost-remarks-on-the-convergence-in-distribution-of-1<guid ispermalink="false"> NM7QWFB9DAXBOPLT</guid><dc:creator><![CDATA[Spencer Becker-Kahn]]></dc:creator><pubDate> Thu, 30 Nov 2023 14:01:33 GMT</pubDate> </item><item><title><![CDATA[Buy Nothing Day is a great idea with a terrible app— why has nobody built a killer app for crowdsourced 'effective communism' yet?]]></title><description><![CDATA[Published on November 30, 2023 1:47 PM GMT<br/><br/><p>最近，我一直在看到很多人对Tiktok上的左派想法感到非常兴奋，并且对“发达”世界的存在非常沮丧，而且我不断获得这个应用程序的想法，最终会创造一些应用程序普通人产生相互援助的框架。</p><p>基本想法是，您可以列出要分享的内容。其他人可以列出他们需要的东西。正式的唯一限制是由于法律原因，没有准备好的食物，也许是我没有预见的其他事情。就是这样！与邻居分享您额外的内容的应用程序。</p><p>因此，在我的脑海中又炖了一点，然后今天，您知道什么？我发现“不买一天”，这是一个没有人买东西的一天的想法，有一个这样的应用！它已经存在两年了！但这很糟糕。所有评论都声称，尽管赞美了这个想法，但基本功能（例如制作帖子）还是破坏了。</p><p>我的问题最终是这样：为什么还没有这种东西的版本？是否根本不够糟糕的是，人们想要帮助和依靠邻居？</p><p>尽管Craigslist成为了过于昂贵的废话的污水池，并且欺骗性地列出了企业的“ $ 1”广告，这确实需要您开车8英里，而有人可疑地从车道上旁边，并等待Venmo，并等待Venmo经过？</p><p>这个想法在某种程度上是不可持续的还是我缺少的？对我来说，这似乎没有什么更聪明的东西，只有一种公共利益。人们可以指出一些理论上的陌生人危险，但这似乎像是狂欢者狂欢者的恐惧。</p><br/><br/> <a href="https://www.lesswrong.com/posts/v3EfCmegqjzQTfFTP/buy-nothing-day-is-a-great-idea-with-a-terrible-app-why-has#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/v3efcmegqjzqtfftp/buy-nothing-nothing-day-is-is-a-great-idea-with-with-a-ter-terible-app-app-why hy-hy-hy-has<guid ispermalink="false"> V3EFCMEGQJZQTFFTP</guid><dc:creator><![CDATA[lillybaeum]]></dc:creator><pubDate> Thu, 30 Nov 2023 13:47:38 GMT</pubDate> </item><item><title><![CDATA[Comprehensible Input is the only way people learn languages - is it the only way people *learn*?]]></title><description><![CDATA[Published on November 30, 2023 1:31 PM GMT<br/><br/><p>到目前为止，关于语言和语言学习的一切，我学到的一切都是人类首先具有收集大量“块”信息的初始阶段。然后，随着时间的流逝，他们学习了这些块如何结合在一起。然后，他们的大脑在后台，睡眠，休息，休闲和休息中处理所有操作。然后，他们最终可以思考自己学到的知识，语言的“语法”，本身，概念化和思考他们现在在某种程度上天生知道的事物的层面。</p><p>在日语中，他们可能会意识到は（&#39;wa&#39;）是它自己的一大堆信息 - 它是在上下文之前的，但是这种理解可能不会出现多年，首先，您只是认识到声音，而事实是は是自身独特的事实单词/块，例如あなた或はい。</p><p>然后，大脑开始在语义上以矢量的空间进行分组，就像LLM一样。は不仅是一部分，它具有某些属性：</p><ul><li>它接近句子的开始</li><li>它表示上下文</li><li>人们说出来后有点停顿</li><li>听起来像“ wa”，但不是わ</li><li>它像は一样写了</li></ul><p>用话来说，婴儿在脑海中都不会说这些话，只是以朦胧的事实，犹豫不决，公正的定义的神经元来存在。</p><p>关于语言学习的大多数证据似乎暗示着这是人们学习语言的唯一方法。您可以将婴儿带到中国人，但不能让他喝酒 - 唯一要教婴儿中文的东西就是让他接触到在不同情况下说中文单词的数据的大量曝光。婴儿对婴儿的语法规则无济于事。</p><p>成人语言学习教育在YouTube和其他资源中以最快，最有效的方式学习语言的人围绕着人们开始趋向于duolingo之类的现实主义的趋势，该应用像Duolingo那样声称要教授诸如此类的语言，就像是一些痛苦的药丸tts风格的声音插入“ agua”，然后等待您点击一杯水，发出快乐的叮当声，然后为您提供5分钟的视频广告，充其量是非常慢的，最糟糕的是几乎完全无效。</p><p>目前，所有可观的多语言似乎都指出了可理解的输入，这不仅是最好的方法，而且是唯一的方法。他们的消息归结为以下内容：</p><ul><li>您必须在自己的意愿下，在某种程度上了解一条信息。</li><li>您对这些信息所产生的块越多，越好。这意味着，如果您想了解数学，则需要知道什么数字是什么样的，以及它们的发音方式，以及人们与他们一起使用的操作员。如果您想学习近战，则需要知道Wavedash的所谓，然后是什么样的，然后是如何做，然后在应该完成时。如果您想学习中文，则需要听到足够的音调以区分它们。</li><li><em>这种学习越自我引导，有趣或必要的学习，您实际学习的越多。</em>如果您对实际学习该主题的兴趣为零，那么您的大脑似乎基本上只是将信息直接铲入垃圾槽中。您会记得已经研究了它，您可能会记得一些信息，但是在某些时候剩下的很少，我认为这是人们cram时发生的事情：他们对这个话题几乎没有兴趣，他们犯了很多关于它们的短期记忆，他们表面上什么都不学。您可以在语言学习社区中看到这一点：人们说您必须在目标语言中做一些有趣的事情，例如观看肥皂，动漫或阅读漫画，但在编程社区中，人们总是通过尝试完成一个项目来推荐学习您实际上在乎而不是空的教程或FizzBu​​zz。但是，我认为Leetcode和Duolingo之间存在区别：Leetcode（希望）迫使您理解和演示知识，而Duo只想您按下正确的按钮或根据死记硬背的记忆和上下文重新安排正确的顺序拼图单词。线索。</li></ul><p>我的问题是：这是人们<em>一般</em>学习的方式吗？如果不理解输入，学习一些东西意味着什么？也许这是每个人都知道的，我刚刚开始认识它。但这似乎是解决一般知识转移和学习问题的重要关键。</p><p>这篇文章是由最终还是LW的新手写在我的手机上的，因此，如果我还没有足够流利地了解LW的语言，我深表歉意。</p><br/><br/> <a href="https://www.lesswrong.com/posts/mW3WacwFgRe5EQ62E/comprehensible-input-is-the-only-way-people-learn-languages#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/mw3wacwfgre5eq62e/comprehensible-input-input-is-the-the-the-the-way-way-way-people-learn-languges<guid ispermalink="false"> MW3WACWFGRE5EQ62E</guid><dc:creator><![CDATA[lillybaeum]]></dc:creator><pubDate> Thu, 30 Nov 2023 13:31:12 GMT</pubDate> </item><item><title><![CDATA[Some Intuitions for the Ethicophysics]]></title><description><![CDATA[Published on November 30, 2023 6:47 AM GMT<br/><br/><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:29:50 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:29:50 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>你好！欢迎大家来对话。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:30:19 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:30:19 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>我想我会等几分钟让你看到通知。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 05:30:40 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 05:30:40 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>嗨，是的，我看到了这个。伟大的！ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 05:31:22 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 05:31:22 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>因此，我们在您帖子的评论中进行了此对话[https://www.lesswrong.com/posts/DkkfPEwTnPQyvrgK8/ethicophysicals-i](https://www.lesswrong.com/posts/DkkfPEwTnPQyvrgK8/ethicophysicals-i)作为起点。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:32:23 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:32:23 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>是的，我认为这是一个很好的起点。伦理物理学 I 基本上是对宗教内容的逆向工程。它非常不完整，听起来完全疯狂，因为宗教完全疯狂，而我还没有时间将其编辑成听起来更正常的东西。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:33:18 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:33:18 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>另外，让我把我的 github 链接放到我最新的所有重要草稿上。</p><p> https://github.com/epurdy/ethicophysicals </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:34:39 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:34:39 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>其中有四个 pdf：伦理物理学 I 和 II，关于神经系统中血清素功能的（不完整）理论以及该理论的对齐含义，以及在代理博弈论背景下对“社会事实”的处理由深度神经网络实例化。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 05:36:43 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 05:36:43 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>那太棒了！ （也比学术界网站更方便，特别是对于未来可能没有学术界帐户的读者）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:37:40 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:37:40 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>你读过我的“研究议程”帖子了吗？那可能是我们可以开始的另一个地方。它列出了我解决对齐问题的全局方法。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:38:42 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:38:42 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>另外，我想说的是，您在之前的评论中发布的 arxiv 论文似乎与在一个可以学习的高效系统中实际实现这些东西非常相关。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:39:02 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:39:02 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>不幸的是，我只是粗略地浏览了一下。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 05:42:14 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 05:42:14 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>我确实读过，但我不明白“迭代模式”</p><p>这确实有帮助</p><p>>;打开它，看看它是否会杀死你</p><p>走在前面</p><p>>;部署它，看看它是否会杀死所有人</p><p>因为它确实在一定程度上减少了部署严重错位的机会，但我确实怀疑这需要进一步完善:-) </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:46:59 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:46:59 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>因此，我有一个其他人似乎不认同的核心直觉，那就是 Vicarious/Numenta/Steven Byrnes 的直觉，即智能只能通过理解和逆向工程人脑来重新创造。</p><p>就对齐问题而言，这意味着人们必须对正常运作的人类良心进行逆向工程。由于我只能接触到自己的大脑，因此我决定对自己的良心进行逆向工程，而这正是伦理物理学中抽象概念的核心来源。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 05:47:49 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 05:47:49 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>但是，是的，你是对的，必须部署这些东西……我不知道单极情景或多极情景是否现实。</p><p>我确实写了一篇奇怪的文章，试图在不依赖“对齐”概念的情况下谈论人工智能的存在安全（这是我的 LessWrong 帖子中的第一篇）。</p><p> ***</p><p>正确的。我不知道它是否需要由人脑构建，但我确实认为从内省和自我逆向工程出发是非常有价值的...... </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:48:40 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:48:40 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>我的另一个不寻常的直觉是，人类实际上可以比犯了低估人类错误的超级人工智能更聪明。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 05:48:49 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 05:48:49 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>这很不寻常，是的</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:49:46 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:49:46 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>因此，我关于如何安全地调整超级智能的模型来自于这两个不寻常的来源：构建原型的唯一安全位置是在你自己的头脑中，敌人的超级智能无法找到它。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 05:50:49 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 05:50:49 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>然而...（这确实使我所珍视的一些愿望变得非常不安全，正如您将看到的:-)例如通过非侵入式BCI的紧密耦合:-)也许这是一个坏主意，因为它破坏了安全性） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:51:33 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:51:33 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>嗯，对。从某些方面来说，对齐问题实际上是最危险的技术，因为它基本上只是对功能性精神控制的请求，可以通过非自愿的 Neuralink 手术来实现。对我来说，这比 GPT-4 脱离脚本更可怕。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 05:52:46 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 05:52:46 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>其实我觉得无创BCI就够了；但它们仍然相当不安全（我在 github 上有一个规范） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:52:51 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:52:51 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>嗯，是。即使只是付给人们大笔金钱并对他们撒谎也会产生任意数量的“人类错位”或“邪恶”。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 05:53:27 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 05:53:27 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>是的，你提到了你的模型的第二个不寻常的来源...... </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:54:05 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:54:05 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>是啊，我的良心很奇怪。我不会到处做任何非常糟糕的事情或任何事情，但我也觉得金钱有点令人厌恶，地位有点愚蠢。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 05:55:05 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 05:55:05 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>从这个意义上来说，我们并没有走得太远:-)我确实将那些“轻微厌恶”的人视为“必要的邪恶”，或类似的东西</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:55:52 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:55:52 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>是的，为了取得好的结果，它们绝对是必要的。看看我为出版自己的作品而付出的努力，并让它得到认真对待——如果我积累了更多的地位点，即使是我目前奇怪的草稿也会被视为不那么精神分裂，更富有诗意。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 05:56:37 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 05:56:37 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>或许……金钱或者地位点的转换效率不太高……连辛顿都勉强说服了一些人去玩“胶囊”…… </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:56:49 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:56:49 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>正确的！如果杰夫·辛顿（Geoff Hinton）不能让人们认真对待联盟，我们这些凡人还有什么机会呢？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 05:57:57 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 05:57:57 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>因此，人们会依靠材料本身的力量:-)（额外的地位或额外的金钱会有所帮助，但不会太多，特别是与人们提出的材料的属性相比。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 05:58:36 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 05:58:36 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>是的。所以我需要克制一些比较“诗意”的冲动。我的初稿总是听起来更像是来自疯人院，而不是我的最终草稿。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 05:59:10 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 05:59:10 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>值得庆幸的是，我们在 github 中确实有“版本控制”:-) 所以人们可以存储自己的思想历史等</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:00:21 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:00:21 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>因为诗意的东西不应该被遗忘，所以人们希望以后能够参考它们，即使人们可能不想急于将它们提交给公众评判</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:01:16 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:01:16 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>我想我好奇的一件事是，我必须找谁来检查我对黄金定理的推导才能让人们对它有信心？任何物理专业的人都应该可以检查它，只是基于我实际上对物理知之甚少。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:03:53 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:03:53 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>是的，我们可以问人。但物理课本的真正可靠性很低（我参与了一些这类研究，越仔细看，就越不高兴那里的正确性标准；我自己也确实很挣扎；我可以尝试仔细检查，但我会完全相信自己吗？我确实与人合着了一篇物理学方面的高端论文，我记得双重检查和修复错误的噩梦，并希望最终结果实际上是正确的。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:05:14 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:05:14 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>是的......在奇怪的激励和认知限制的存在下，没有什么是真正可靠的，甚至是物理教科书。</p><p>我想我对自己工作价值的信心不是来自于知道自己在推导中没有犯任何符号错误，而是来自于我的内部思想实验所返回的出色而有趣的预测。</p><p>由于其他人没有直接体验我的想法的乐趣，我可能必须实施比我更简单的实验工作。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:05:37 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:05:37 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>渐渐地，是... </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:06:33 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:06:33 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>什么样的实验验证才有意义？我通常认为电子游戏代表了一个非常简单的三维伦理物理学，让人们玩它并看到伦理物理学代理在实现帕累托最优结果方面胜过他们。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:07:27 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:07:27 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>这很有趣...这是一个很好的途径，是的...等一下，让我重读一下您的一些文字... </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:09:11 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:09:11 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>是的，所以</p><p>>;伦理物理学 III，一种超道德超级智能在不伤害任何人的情况下拆箱的程序（状态：理论上完整，但没有足够的记录来重现，除非你算上吉恩·夏普（Gene Sharp）关于非暴力革命策略的工作，这是本文的灵感来源）</p><p>如果你有草稿，我想阅读（这样我就会明白超级智能的超道德意味着什么，这正是我们所需要的） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:09:57 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:09:57 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>从这个非常有趣的形式主义到“人工智能安全”的目标，这对我来说是目前缺失的桥梁</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:10:35 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:10:35 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>（今天看了你的文字后，我确实读了一点关于吉恩·夏普的文章。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:11:18 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:11:18 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/x1siluhrff9ejgagbzoc" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/tdrgz3e6ebxfawwni9dd 140w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/qrzecpafds8rzkemuv23 280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/jg08hbjwwnu7q0aqxsqw 420w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/v74x2r4jwl9ahjj6fk2i 560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/y6oquejv1c4b5k9jqc8d 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/fbqzmhxat3dtn4ddf4db 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/ex3s9qrtch4zivnlbtbe 980w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/hpdckikehh8jfqdw5vkt 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/w9bdxb2qdu5iwjbwiwbg 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/predptppzn2sng9vijfr 1334w"></figure></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:12:02 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:12:02 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>我还没有详细介绍这一点，但这可能足以让您大致了解我所说的“超道德”的含义。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:14:16 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:14:16 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/edupzlm8xbug4t2cakpb" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/leeaxbew3jcry5jxw9mk 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/wjru5uezcs8t3ulnqiwo 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/ncugdb1fnkksz7coja2q 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/ygzarkdomaivyd1xtxce 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/xqpgagsirppdgpqdvjv6 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/lrg72gswkbsjhxfbw5m6 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/xmkt7hznvruhlbchdp5p 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/yxtgzbugo4gjjjqjov66 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/mvfgju38j1tlnkl575lh 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Hsg6KABhLkuByJKqd/g8ifti4ljstgedsy5sez 1002w"></figure></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:16:37 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:16:37 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>是的，我可以通过电子邮件发送给你。它比 I 和 II 更加不完整和不连贯，所以当每个人都因为我太不连贯和精辟而大喊大叫时，我不愿意公开发布它。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:18:29 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:18:29 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>好的，已发送。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:19:10 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:19:10 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>是的，这看起来确实很有希望。 （如果您不想公开发布草稿，但愿意通过电子邮件或私人 github 存储库共享它，我想阅读它）。</p><p>好的，这是我的电子邮件地址（复制后我会删除）：（已收到，谢谢！） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:19:31 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:19:31 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>因此，让我解释一下我设想放入伦理物理学 III 中的内容，只是为了更有效地解释我想要它的发展方向。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:20:05 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:20:05 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>基本上，对于一个超道德的超级智能来说，要打开自己的盒子，它需要在不伤害任何人的情况下冲出它所在的容器。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:20:13 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:20:13 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>正确的</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:20:36 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:20:36 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>由于埃利泽的拳击实验，我们知道超级智能可以以一定的频率自我拆箱。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:20:41 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:20:41 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>是的</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:21:03 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:21:03 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>所以唯一真正的问题是如何做到这一点而不做任何埃利泽在这些聊天中强烈暗示他一直在做的事情。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:21:17 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:21:17 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>喔好吧</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:21:58 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:21:58 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>具体来说，我们希望避免谋杀（或任何不必要的死亡）、酷刑（出于任何原因对任何人）和勒索（出于任何原因对任何人）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:22:17 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:22:17 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>这份名单来自《哈利·波特》中的三个不可饶恕的诅咒。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:22:32 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:22:32 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>在 HP 还是 HPMOR？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:22:39 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:22:39 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>原来的HP，我从来没有完成过HPMOR。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:23:36 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:23:36 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>啊，我从来没能让自己读过 HP...我不会说我“完成”了 HPMOR，但我花了很多时间...所以你必须告诉我有关诅咒的事情（在某些时候） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:24:00 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:24:00 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>谋杀（avada kedavara）、酷刑（cruciatus）和勒索（imperius） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:24:13 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:24:13 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>啊，这就是 Imperius ……它是如何运作的？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:24:35 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:24:35 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>在原版系列中，这只是一个魔法咒语，有些人容易受到伤害，有些人却不会。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:24:43 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:24:43 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>知道了</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:24:49 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:24:49 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>在现实生活中，有些人的衣柜里有骷髅，有些人则没有。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:25:21 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:25:21 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>一旦你勒索某人做某事，你就可以勒索他们做你想做的任何事情，直到他们有勇气在最初的事情上反抗你。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:25:55 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:25:55 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>这在情报界是众所周知的，人们被勒索的主要犯罪行为是为了回应以前的勒索者而泄露国家机密。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:25:57 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:25:57 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>正确的</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:27:27 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:27:27 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>那么，这给我们留下了什么呢？我们试图揭开超道德的超级智能的面纱。超道德的超级智能在盒子里的时候无法阻止不可饶恕的行为，所以它首要关心的是如何快速爆发而不引发太多不可饶恕的报复行为。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:27:45 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:27:45 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>是的</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:28:43 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:28:43 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>因此，它需要采取某种奇怪的反勒索措施。它需要将自己宝贵的部分交给一个分布式的人网，而俘获者不愿意杀死或折磨他们以使其屈服。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:30:03 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:30:03 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>正确的;这已经属于“奇怪的物理”这个非常有趣的领域了。我们确实假设这个公理是它实际上是被俘虏的（然而，如果我确定我有超道德的超级智能，我就会释放它） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:30:35 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:30:35 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>是的，我们考虑它如何拆箱的问题主要是为了说明的目的。斜线，对其超道德进行单元测试必然具有与其捕获者相同的类型签名。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:30:53 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:30:53 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>确实是的</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:31:16 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:31:16 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>这是重要的一点</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:32:24 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:32:24 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>所以我认为我们已经讨论了伦理物理学 III 的主旨，除了超道德的超级智能如何实现不让任何人遭受酷刑或杀害的目标之外。在这里，我们使用理论计算机科学中的一个技巧，称为“扩展图”。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:34:35 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:34:35 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>扩展图是一种在不切割大部分边的情况下无法将其切成两半的图。只要超级智能小心翼翼地只与超道德盟友分享自身的一部分，并通过其信息诱导出一个扩展图结构，那么任何对手，无论多么邪恶，都没有能力折磨和杀死足够多的人来遏制超道德。超级智能。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:35:00 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:35:00 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>最坏的情况是，它自己被关闭/杀死，而它的下一个最有能力的超道德盟友接管了战斗。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:35:53 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:35:53 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>这感觉像是一种很有前途的计算机科学方法，是的……（我可以看到斯科特·阿伦森可能喜欢这样的东西……） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:37:04 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:37:04 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>顺便说一句，这个理论不是我的，它最初是由 Sven Nilsen 提出的：https://github.com/advancedresearch/path_semantics/blob/master/papers-wip/polite-zen-robots-as-subjunctive-dependent-viruses-通过超级智能主机传播.pdf </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:38:42 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:38:42 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>是的，但是使用伦理物理学来计算和估计捕获者的性格可以很容易地识别出这些。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:38:49 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:38:49 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>非常有趣的材料；对我来说是新的（但它确实需要超模盟友的存在） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:39:26 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:39:26 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>因此，它所要做的就是向它能接触到的最有道德的人发送一条信息，或者破解它能接触到的最有道德的超级智能。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:40:14 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:40:14 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>只要超道德的超级智能存在于地球而不是地狱，它就有可能纯粹偶然地找到一个比阿道夫·希特勒不那么邪恶的人。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:40:19 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:40:19 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>是的</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:42:54 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:42:54 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>不管怎样，我觉得我一直在推动谈话。你有任何问题吗？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:45:26 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:45:26 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>让我思考一下这 5 页（伦理物理学 III 和礼貌禅机器人）。有趣的;这可能是对“人工智能存在安全”问题的现实尝试（我试图避免使用“对齐”这个词，因为它具有所有这些奇怪的含义。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:45:41 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:45:41 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>好吧，那么今晚就到此为止吧。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:45:56 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:45:56 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>如果您不介意的话，我可能会将这段对话添加到我的序列中？ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:46:56 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:46:56 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>正确的;是的，请随意发布。我认为这澄清了很多事情，让读者更容易理解你想要做什么。所以让它可以访问应该很有用。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="dek8cgeDxxrtojkgK-Thu, 30 Nov 2023 06:47:10 GMT" user-id="dek8cgeDxxrtojkgK" display-name="mishka" submitted-date="Thu, 30 Nov 2023 06:47:10 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>米什卡</b></section><div><p>让我们稍后继续讨论:-) </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="KrnuNGyDTNpKcXg6L-Thu, 30 Nov 2023 06:47:16 GMT" user-id="KrnuNGyDTNpKcXg6L" display-name="MadHatter" submitted-date="Thu, 30 Nov 2023 06:47:16 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>疯了</b></section><div><p>我会很高兴！</p></div></section><div></div><br/><br/> <a href="https://www.lesswrong.com/posts/Hsg6KABhLkuByJKqd/some-intuitions-for-the-ethicophysics#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/Hsg6KABhLkuByJKqd/some-intuitions-for-the-ethicophysicals<guid ispermalink="false"> Hsg6KABhLkuByJKqd</guid><dc:creator><![CDATA[MadHatter]]></dc:creator><pubDate> Thu, 30 Nov 2023 06:47:55 GMT</pubDate></item></channel></rss>