<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 8 月 30 日星期三 16:14:23 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Why I hang out at LessWrong and why you should check-in there every now and then ]]></title><description><![CDATA[Published on August 30, 2023 3:20 PM GMT<br/><br/><p>正如标题所示，这篇文章是<a href="https://new-savanna.blogspot.com/2023/08/why-i-hang-out-at-lesswrong-and-why-you.html">从我的家庭博客 New Savanna 交叉发布的</a>，并不是针对 LessWrong 读者的。然而，你们中的一些人可能会发现思考 LessWrong 在世界上的地位很有用。</p><p>前两节是背景知识，首先是关于文化变革的一些内容，以设定总体背景。然后是有关 LessWrong 的一些一般信息。现在我们正在阅读我对这个地方的个人印象，最后建议您去看一下（如果您还没有看过的话）。</p><p><strong>长期的文化变革：基督徒和教授</strong></p><p>早在古代，基督教只是罗马帝国边缘的另一个神秘邪教。公元380年，狄奥多西一世皇帝颁布了《帖撒罗尼迦敕令》，它成为罗马帝国的国教。随着时间的推移，它在欧洲的许多部落中传播开来，那些基督教部落的人开始想到一个叫做基督教世界的实体，随着时间的推移，它变成了欧洲和“西方”。</p><p>早在欧洲还是基督教世界的时候，天主教会就是知识分子生活的中心。随着科学革命和宗教改革的到来，这种情况在 16 世纪发生了变化。当然，天主教仍然很强大，但大学取代了它，成为知识生活的制度中心。</p><p>我的观点简单明了：事情会发生变化。邪教可以成为主流，新的机构可以取代旧的机构。考虑到这一点，让我们考虑一下 LessWrong。</p><p><strong>少错</strong></p><p>当然，我不想暗示<a href="https://en.wikipedia.org/wiki/LessWrong">LessWrong</a>是一个庞大而复杂的在线社区，以及那里的潮流（理性主义运动、有效利他主义（EA）、对流氓人工智能的反乌托邦恐惧）可以与基督教相媲美，但它看起来像邪教对局外人来说，对一些局内人来说也是如此。它举办了大量关于人工智能和人工智能存在风险、有效利他主义以及更普遍的如何生活的高强度智力活动。我怀疑对于一些在那里发帖的人来说，这是他们知识生活的知识中心。</p><p> I 由<a href="https://en.wikipedia.org/wiki/Eliezer_Yudkowsky">Eliezer Yudkowsky</a><a href="https://en.wikipedia.org/wiki/LessWrong#History">于 2009 年创立</a>，Eliezer Yudkowsky 是一位自学者，对人工智能，特别是高级人工智能的破坏性潜力有着浓厚的兴趣。这就是他最出名的地方，虽然我怀疑尼克·博斯特罗姆在这个主题上最广为人知——他 2014 年的书<a href="https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies"><i>《超级智能</i></a>》是一本畅销书，而且他在牛津大学有一个学术职位——尤德科夫斯基可能更有影响力以他居住的硅谷为中心的科技社区。作为这种影响力的指标，请考虑 OpenAI 总裁兼联合创始人 Sam Altman 最近在 X（该网站以前称为 Twitter）上发布的两条帖子： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/nd9qnKxmYPr76Yi5s/l8uimkvgjphvcf3axlme" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/nd9qnKxmYPr76Yi5s/tgocmw57velmt0fkzavf 117w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/nd9qnKxmYPr76Yi5s/f7nqlukzq3ia0y2bevrw 197w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/nd9qnKxmYPr76Yi5s/s8xth2jvtclhihtao7dl 277w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/nd9qnKxmYPr76Yi5s/vieof1sso98oh77wjlrc 357w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/nd9qnKxmYPr76Yi5s/nj4pgxxmgskfwch2uauq 437w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/nd9qnKxmYPr76Yi5s/kne4lxlwgevhxnuqmano 517w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/nd9qnKxmYPr76Yi5s/aoet2q4xrf1magizulrj 597w"></figure><p>让我对和平奖产生怀疑。但除此之外，尤德科夫斯基在硅谷一直非常有影响力。在这些公司工作的人发帖并评论 LessWrong。</p><p><strong>为什么我在那里</strong></p><p>因为这是一个有趣的地方，虽然有点奇怪和令人反感，而且因为到目前为止我在那里进行了一些有趣的谈话。虽然不多，但绝对足够值得。</p><p>我不知道我第一次看到LessWrong是什么时候，但可以说是五年多前，甚至可能是十年前。但我在那里呆的时间并不多。大约两年前，也就是 GPT-3 开始震撼世界之后的某个时候，这种情况开始发生变化。我<a href="https://www.lesswrong.com/posts/hNXYWESpbzyjFnMyL/the-fourth-arena-what-s-up-in-the-world-these-days-we-re">于 2022 年 6 月发表了第一篇帖子</a>，到目前为止总共发表了 40 条帖子和 137 条评论。我通常每天都会去那里看看发生了什么。我可能会快速浏览一到五个新帖子，查看我关注的帖子的评论，然后继续处理我的业务。在特别好的一天，我会阅读我自己的一篇帖子的一些评论并回复。</p><p>问题是，我是一名浪人知识分子，而且多年来一直如此。如果你看过动画系列<a href="https://en.wikipedia.org/wiki/Samurai_Champloo"><i>《Samurai Champloo》</i></a> ，我的智力相当于 Jin。尽管我已经获得了博士学位——LessWrong 也有一些博士学位——并且曾经在伦斯勒理工学院担任过教职。但我很久以前就离开了那里，从此就没有一个知识分子的家了。我在学术文献中发表了一系列关于各种主题的文章，这些主题分散在文学批评、认知科学和文化进化领域，并在商业出版社与优秀出版商合作出版了两本书，一本是关于音乐的（贝多芬的铁砧，Basic 2001），另一本是关于音乐的（贝多芬的铁砧，Basic 2001）。计算机图形学（可视化，Harry Abrams 1989）。就其价值而言，对我而言，它的价值很大，想法数比页数似乎表明的要多，但我的作品从未真正流行起来。所以我明白在恐龙统治的世界里作为哺乳动物是什么感觉。</p><p>我强烈怀疑 LessWrong 的许多用户也有这种感觉。在这个层面上，以这种方式，我理解他们在做什么，即使我不做同样的事情。虽然我对人工智能非常感兴趣，但我对人类思想和人类文化更感兴趣，而且我不担心破坏和流氓人工智能的虚拟之手。尽管如此，我们还是可以并且确实聊了一会儿。</p><p>除此之外，谁知道呢？这里发生了很多事情。文化变革、彻底变革——这是我们所需要的，而且无论我们是否喜欢它，都处于其中——是混乱的。许多想法涌现并得到实践，但很少有人坚持下来。唉，问题在于，好的东西，真正深奥的东西，是无法提前预测的。疯子和天才之间的区别只有在回顾时才会变得清晰。例如，大约六个月前，Cleo Nardo 发表了一篇很长的帖子，<a href="https://www.lesswrong.com/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post">名为“瓦路易吉效应”(meg-post)</a> ，迄今为止已吸引了 184 条评论（每隔一段时间就会有新的评论涌入）。它很精彩，但我认为它很混乱，到处都是，它是关于大型语言模型的内部结构和奇怪的行为。只要有足够多的信息，一些很有价值的事情似乎就可能发生，尽管我不太可能注意到它。也许你可能会。</p><p><strong>我对这个地方的看法</strong></p><p>我很清楚，有一些非常聪明和富有创造力的人在 LessWrong 度过了很多时间。但是，可惜的是，它非常孤立，正如对立的反文化往往如此。例如，这里是<a href="https://www.lesswrong.com/posts/LKAogXdruuZXdx6ZH/publish-or-perish-a-quick-note-on-why-you-should-try-to-make">3 月份的一篇短文</a>，附有 48 条评论，“关于为什么你应该努力让现有学术界能够理解你的工作。”是的！反之亦然。 LessWrongers 需要更多地关注感兴趣领域的现有工作。</p><p>我的老师，已故的大卫·海斯曾经说过，“伟大的天赋需要严格的纪律。” （他不记得他在哪里听到这句话，但这不是他原创的。如果你对这个短语进行网络搜索，你会得到一堆点击，尽管在几分钟内我没有找到找到那个确切的短语。）我担心很多在这里发帖的人都是如此，而且整个地方也是如此。仅仅了解很多东西并提出很多新的想法是不够的。您需要与他们合作并随着时间的推移对其进行完善，并与现有知识建立联系。</p><p>尽管如此，这里的谈话还是非常文明的。有激烈的讨论，但我没有看到任何激烈的争论。您可以对评论进行投票，这是一个常见功能，但 LessWrong 界面允许您区分评论的质量以及您是否同意，这是一个有用且重要的功能。</p><p>鉴于以学院和大学、各种智囊团和基金会以及工业研究为代表的“合法”知识世界，已经陷入了循环利用旧思想的困境（在观看《星际迷航》重播时，柯克的开场警告是“大胆地去无人涉足的地方”）以前已经过去了！”）世界需要新的概念滋生地。 LessWrong 看起来是一项很有前途的试点工作。</p><p><strong>为什么不去参观呢？</strong></p><p>如果您不熟悉这个地方，我建议您顺便过来，花一个小时逛逛。如果你没有发现任何吸引你注意力的东西，就离开，但一周后回来再试一次。如果一个月左右后没有任何效果，那就是这样。</p><p>但如果有什么事情坚持不了，你就得靠自己了。也许你到处发表评论。然后发布一些内容，看看会发生什么。</p><br/><br/> <a href="https://www.lesswrong.com/posts/nd9qnKxmYPr76Yi5s/why-i-hang-out-at-lesswrong-and-why-you-should-check-in#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/nd9qnKxmYPr76Yi5s/why-i-hang-out-at-lesswrong-and-why-you-should-check-in<guid ispermalink="false"> nd9qnKxmYPr76Yi5s</guid><dc:creator><![CDATA[Bill Benzon]]></dc:creator><pubDate> Wed, 30 Aug 2023 15:20:45 GMT</pubDate> </item><item><title><![CDATA["Wanting" and "liking"]]></title><description><![CDATA[Published on August 30, 2023 2:52 PM GMT<br/><br/><h1> “想要”和“喜欢”</h1><p><em>这是 2023 年虚拟人工智能安全营的成果。感谢以下人员的反馈和有益的对话：Oliver Bridge、Tim Gothard、Linda Linsefors、Rasmus Jensen。</em> <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-1" id="fnref-FMm4ikcDkjYYfSWqb-1">[1]</a></sup></p><p>这篇文章回顾了有关<em>“想要”</em>和<em>“喜欢”</em>的文献，这两个主要组成部分通常被称为生物奖励系统。它旨在为人工智能安全相关工作提供信息，特别是在尝试<a href="https://www.lesswrong.com/posts/nfoYnASKHczH4G5pT/brain-enthusiasts-in-ai-safety">利用</a><a href="https://www.lesswrong.com/s/HzcM2dkCq7fwXBej8">神经科学</a><a href="https://www.lesswrong.com/s/nyEFg3AuJpdAozmoX">见解</a><a href="https://www.lesswrong.com/s/nyEFg3AuJpdAozmoX">进行调整的</a>方法中。</p><p>第 1 节介绍了奖励的两个高级组成部分之间的区别：想要和喜欢。在这一点上，我简化了主题并将两者视为同质类别。第 2 节和第 3 节深入研究了每个组件，并给出了更细粒度的模型，包括对其神经生物学基础的描述。 （2.2 和 3.2 是更技术性/干性的神经科学，所以如果这不是您的主要兴趣，您可能想跳过它们。）第 4 节讨论它们之间的功能关系以及为什么这种“劳动分工”可能受到青睐通过进化。</p><h2>一、简介</h2><p>我将首先介绍本文的四个核心概念：<em>想要</em>、 <em>“想要”</em> 、<em>喜欢</em>和<em>“喜欢”</em> 。 <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-2" id="fnref-FMm4ikcDkjYYfSWqb-2">[2]</a></sup>他们沿着二维空间雕刻人类价值<sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-3" id="fnref-FMm4ikcDkjYYfSWqb-3">[3]</a></sup>的空间。第一个是我们有动力去做/被驱使去做（想要）的事情与我们对发生（或即将发生）感觉良好（喜欢）的事情之间的区别。第二个区别是每个元素的更基本/不太复杂的成分（ <em>“想要”</em>和<em>“喜欢”</em> ）与更复杂和认知的成分（<em>想要</em>和<em>喜欢</em>）之间的区别。 <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-4" id="fnref-FMm4ikcDkjYYfSWqb-4">[4]</a></sup>本节的两部分详细阐述了这两个维度。</p><h3> 1.1.喜欢与想要</h3><p>喜欢是指当你咬了一口美味的食物，它的味道给你带来快乐，或者更一般地说，给你带来正价的情感状态。想要是当你有动力采取行动以获得食物并将其送到嘴里食用时。</p><p>这可能足以让我们凭直觉了解其区别的大致轮廓，但同时，它可能会引发一些问题。我可以想象这样的情况：我有点想起身去厨房，但我太累了（或者我的意志力太弱了）而起不来。所以我没有起床，尽管我知道冰箱里的食物非常好，如果我真的站起来去拿，我会很高兴这样做。另一方面，如果食物绝对美味并给我带来快乐，并且我“在某种程度上”享受它，但同时相信（或至少<a href="https://www.lesswrong.com/tag/subagents">我的一部分</a>相信）我不应该吃它怎么办？也许我认为我根本不应该<em>享受</em>它？也许我认为它不健康，或者担心有人会因为我在特定情况下吃它而评判我，或者我的上帝/宗教禁止吃猪肉。 <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-5" id="fnref-FMm4ikcDkjYYfSWqb-5">[5]</a></sup>这些边缘案例难道不会质疑喜欢和想要之间的简单区别吗？因为它们过于截然不同，但却是连贯且同质的事物？也许他们确实如此，但通过研究这种粗粒度的喜好和需求，我们仍然可以了解很多我们所谓的人类价值观的原始内容。</p><p>根据我所说的对喜欢和想要之间关系的<em>天真的看法</em>，我们想要 X 的原因是我们喜欢 X，或者至少期望/预测喜欢 X。意识到我们（将）喜欢某物之间的相关性不久之后就产生了对它的渴望，使得这种观点非常适合大多数日常情况。</p><p>然而，喜欢和想要有时是分开的。我们可能会开始想要某些东西，即使我们既没有机会体验喜欢，也无法预测我们会喜欢它。举一个具体的例子，人类和其他动物通常在第一次性接触之前就产生性欲。有时他们甚至可能不知道性是什么。尽管如此，它们还是实施了一些智能行为，这些行为是进化选择的，以便可靠地以性交结束。</p><p>在其他情况下，迄今为止一直不喜欢的东西会成为欲望的对象。 Robinson 和 Berridge (2013) <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-6" id="fnref-FMm4ikcDkjYYfSWqb-6">[6]</a></sup>教导老鼠将特定的刺激（以下称为条件刺激；CS）与将极咸的水直接注入其口中的排斥体验（以下称为无条件刺激；UCS）联系起来。老鼠很快意识到 UCS 可靠地跟随 CS，因此它们学会在看到 CS 时转身并退出。 <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-7" id="fnref-FMm4ikcDkjYYfSWqb-7">[7]</a></sup>在实验的下一阶段，研究人员给老鼠注射了两种模拟大脑信号的化合物，这些信号在正常情况下会传达有关危险的低血钠水平的信息。重要的是，由于他们的饮食中始终含有足够的盐，因此他们从未有机会发现他们对咸味食物的喜欢（不喜欢）在多大程度上取决于血钠水平。</p><p>然而，他们的行为发生了巨大的变化。他们没有从CS撤退，而是开始接近它，渴望获得宝贵的盐分。 （感知到的）生理状态的变化将令人厌恶的事物变成了令人向往的事物，并且与之相关的提示也随之发生。</p><p>喜欢与想要分离的例子还不止于此。一个人可能会对某种药物产生成瘾，即使他们不太喜欢这种药物引起的状态。此外，随着吸毒时间的延长，其积极的主观影响（喜欢）往往会逐渐消失，但成瘾（想要）却会持续存在。 <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-8" id="fnref-FMm4ikcDkjYYfSWqb-8">[8]</a></sup>换句话说，即使一个人不喜欢接受该剂量并且意识到他们不会喜欢一旦接受该剂量所发生的事情，他也可能想要获得该剂量。</p><p>有些人还会产生强迫性的欲望或行为模式，这些欲望或行为模式不会带来积极的体验，但仍然很难抗拒。亚临床的例子包括强迫性地检查手机、电子邮件或社交媒体、<a href="https://en.wikipedia.org/wiki/Doomscrolling">末日滚动</a>和赌博成瘾。至少从我的轶事现象角度来看，这些事情确实感觉像是我想要但不喜欢的东西。 <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-9" id="fnref-FMm4ikcDkjYYfSWqb-9">[9]</a></sup></p><p>也许不太明显的是那些给我们带来很多积极体验但我们却没有产生任何强烈愿望的事物的例子。我记得朱莉娅·加莱夫（Julia Galef）在一些播客中提到，她真的很喜欢苹果，但从未学会“渴望”苹果，每当她碰巧吃苹果时，她就会想起这一点。如果我们想要某样东西的（主要）原因是我们喜欢它，那么她对苹果的渴望难道不应该与她对苹果的喜欢程度成正比吗？另一方面，更具推测性的是，有些人报告在某些<a href="https://astralcodexten.substack.com/p/nick-cammarata-on-jhana">冥想</a><a href="https://astralcodexten.substack.com/p/highlights-from-the-comments-on-jhanas">状态</a>下感到极度愉悦，但并未对此上瘾。我在第 2 节中讨论了更多选择性影响喜好但不想要的实验示例。</p><h3> 1.2.<em>喜欢</em>与<em>“喜欢”</em>和<em>想要</em>与<em>“想要”</em></h3><p><a href="https://en.wikipedia.org/wiki/Folk_psychology">民间心理学</a>概念并不能保证非常适合脑/心智科学。对于一些例子，诸如意识、情感、记忆、疼痛等概念，甚至<a href="https://academic.oup.com/book/11923">“概念”本身的概念，</a>结果被证明将重要的不同现象混在一起（参见 Ramsey，2022，第 2.3 节）。我们可能期望喜欢和想要走这条路，如果我们想用它们作为神经科学上充分的本体论的起点，它们至少需要一些改进。</p><p>从表面上看，喜欢和想要之间似乎存在不对称，因为后者至少在许多情况下可以从行为中推断出来， <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-10" id="fnref-FMm4ikcDkjYYfSWqb-10">[10]</a></sup>而前者是“私人”经验的问题。显然，对于无法用语言表达其持续主观体验的动物来说，这尤其成问题。然而，不对称性可能比看起来要弱。毕竟，我们可以确定人类的哪些自动行为和/或生理反应与（口头报告） <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-11" id="fnref-FMm4ikcDkjYYfSWqb-11">[11]</a></sup>正价或负价体验（至少特定于某些领域，例如食物）相关。然后，我们可以转向动物并寻找类似的反应（例如，以大致相同的运动模式参与类似的肌肉群），以了解它们是否与我们预测动物喜欢或喜欢的相同类型的客观可观察事件相关。不喜欢。</p><p>例如，就食物而言， <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-12" id="fnref-FMm4ikcDkjYYfSWqb-12">[12]</a></sup>事实证明，愉快和不愉快的味道会强烈触发特定的面部表情（参见 Berridge &amp; Robinson，2003， <a href="https://sites.lsa.umich.edu/berridge-lab/wp-content/uploads/sites/743/2019/10/Berridge-Robinson-TINS-2003.pdf">图 I</a> ）。重要的是，它们甚至可以在没有意识功能的情况下发生， <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-13" id="fnref-FMm4ikcDkjYYfSWqb-13">[13]</a></sup>例如在睡眠中或新皮质功能缺陷的个体中， <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-14" id="fnref-FMm4ikcDkjYYfSWqb-14">[14]</a></sup>例如无脑婴儿（Steiner，1973；参见Berridge &amp; Winkielman，2003）。</p><p>观察到一些客观可测量的快乐表现可以在没有意识的情况下发生，促使引入<em>“喜欢”</em> （不需要意识的核心情感反应）和<em>喜欢</em>（有意识的快乐）之间的区别<sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-15" id="fnref-FMm4ikcDkjYYfSWqb-15">[15]</a></sup> （Berridge＆Robinson， 2003 年；贝里奇和克林格尔巴赫，2015 年）。类似地， <em>“想要”</em> （激励显着性、不需要意识的提示触发动机）与<em>想要</em>（具有声明性目标的认知欲望）不同。 <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-16" id="fnref-FMm4ikcDkjYYfSWqb-16">[16]</a></sup>因此， <em>“喜欢”</em> /<em>喜欢</em>和<em>“想要”</em> /<em>想要的</em>区别捕获了隐性或客观可测量成分（ <em>“引用”</em> ）和显性或主观成分（<em>未引用</em>）之间的差异。</p><p>虽然对奖励进行客观衡量的需要是做出区分的最初动机，但缩小<em>“喜欢”</em>和<em>“想要”</em>的明确组成部分使得更容易识别它们的神经基础。初步近似，我们有<strong>（1）</strong>一个<em>“喜欢”</em>系统，集中在少数享乐热点和冷点周围，阿片类药物在<em>“（不）喜欢”</em>的产生和调节中发挥着主要作用<strong>，（2）</strong> <em>“想要”</em>系统，分布更广泛（尽管在某种程度上以腹侧被盖区为中心），并且以多巴胺作为关键的神经递质。这两个系统在某种程度上是分开的，但也有重叠。</p><h2> 2. 喜欢</h2><h3>2.1. <em>“喜欢”</em>和<em>喜欢</em></h3><p>“无意识的快乐”的想法似乎是矛盾的。从什么意义上说，发生在我们身上的事情可以是令人愉快的，但却无法被意识所感知？</p><p>快乐的无意识方面的引入遵循我们在心理学中经常看到的<a href="https://www.lesswrong.com/s/u9uawicHx7Ng7vwxA">概念外推</a>的特定模式。我们发现一种特定的与心理相关的现象具有一些客观可测量的“行为特征”。例如，人类、其他类人猿、老鼠和许多其他哺乳动物物种都会伸出舌头来回应美味的食物（参见 Berridge &amp; Robinson，2003， <a href="https://sites.lsa.umich.edu/berridge-lab/wp-content/uploads/sites/743/2019/10/Berridge-Robinson-TINS-2003.pdf">图 I</a> ）。对令人厌恶的口味的反应在很大程度上在不同的分类群中也是同源的。除此之外，将人们暴露于与味觉无关的价刺激（例如，快乐与愤怒的面孔）会影响他们消耗多少美味食物，并且即使这些刺激没有被有意识地感知到，这种效应也会持续存在（Winkielman等，2005）。 <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-17" id="fnref-FMm4ikcDkjYYfSWqb-17">[17]</a></sup></p><p>因此，将快乐/喜欢分为对有价刺激（ <em>“喜欢”</em> ）和有意识感知的快乐（<em>喜欢</em>）客观可测量的“核心情感反应”的潜意识部分的基本原理。后者更接近动词“喜欢”的常见含义。 <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-18" id="fnref-FMm4ikcDkjYYfSWqb-18">[18]</a></sup>它表示意识中可用的价态感觉，即对当前事态的认可或反对。 <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-19" id="fnref-FMm4ikcDkjYYfSWqb-19">[19]</a></sup></p><p>由于在这两者中， <em>“喜欢”</em>是客观可测量的组成部分，并且该领域的大部分研究都是在实验动物身上进行的（其主观体验无法通过口头报告来测量），因此我们对“喜欢”了解得更多也就不足为奇了。 <em>“喜欢”</em>的神经生物学基础比“<em>喜欢</em>”的神经生物学基础更重要（ <em>“想要”</em>和<em>想要</em>的也是如此）。因此，我对后者的讨论比前者更多的是一种推测。此外，大多数<em>“喜欢”</em>的动物研究依赖于一组有限的“奖励刺激领域”（主要是食物、性和药物），因此我们对这些领域之间核心情感反应如何不同的了解仍然相当有限。</p><h3> 2.2.大脑中的<em>“喜欢”</em></h3><p> <em>“喜欢”</em>电路最重要的组成部分是一些<em>享乐热点</em>和<em>冷点</em>，它们是一小群神经元，它们的刺激分别选择性地增加或减少<em>“喜欢”</em>反应。 （在增加的情况下，有时称为<em>享乐增强</em>。）它们<sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-20" id="fnref-FMm4ikcDkjYYfSWqb-20">[20]</a></sup>都不是解剖学上不同的结构（您不会在典型的神经解剖学教科书的索引中找到它们）。相反，它们是嵌入更大区域的“功能岛”，涉及许多与<em>“喜好”</em>无关的功能。</p><p>最重要的两个位于<a href="https://en.wikipedia.org/wiki/Basal_ganglia">基底神经节</a>，特别是<a href="https://en.wikipedia.org/wiki/Nucleus_accumbens">伏隔核</a>(NAc) 和<a href="https://en.wikipedia.org/wiki/Ventral_pallidum">腹侧苍白球</a>(VP)。 NAc 和 VP 都包含一个热点和一个冷点。 NAc分为核心和外壳，外壳的前面有一个热点，后面有一个冷点。在 VP 中，排列相反，热点在后面，冷点在前面（Richard et al., 2013; Berridge &amp; Kringelbach, 2013, 2015）。</p><p>除了基底神经节之外，享乐热点（但据我所知，不是冷点）位于眶额皮质 (OFC)、前岛叶 (aIns) 和脑桥臂旁核 (PBN；Söderpalm &amp; Berridge) ，2000 年；参见 Smith 等人，2010 年）。然而，NAc 和 VP 中的热点似乎是最重要的，它们是快乐的<em>发生器</em>。损害或停用 NAc 热点或 VP 热点可以消除享乐反应 (Berridge &amp; Kringelbach, 2015)。此外，虽然破坏NAc热点只会消除“喜欢”，但破坏VP热点（或其暂时失活）会导致“不喜欢”通常积极的事物（例如蔗糖）。</p><p>此外，几乎没有新皮质的无脑儿童以及经历了广泛的 OFC 损伤的人或非人类动物仍然保留完整的<em>“喜欢”</em>反应。 OFC 损伤的人也报告有意识的快乐，这表明即使<em>喜欢</em>也并不严格依赖于皮质（参见 Berridge &amp; Winkielman，2003）。 <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-21" id="fnref-FMm4ikcDkjYYfSWqb-21">[21]</a></sup>相比之下，两个基底神经节热点中的每一个都需要一定的基线活动水平，以便对其中一个热点进行额外刺激以产生享乐增强（Smith &amp; Berridge，2007；Smith 等人，2011；参见 Richard等人，2013）。</p><p>重要的是，这并不是‘刺激热点提高<em>“好感度”</em> ，刺激冷点降低<em>“好感度”</em>那么简单。用于刺激的神经递质的选择很重要。在这里，阿片受体最为相关（参见 Berridge &amp; Robinson, 2003；Berridge &amp; Kringelbach, 2015；Smith et al., 2010）。在 NAc 热点中，mu、δ 和 kappa 阿片受体激动剂都会引起快感增强，而在 VP 热点和皮质热点中，这种作用似乎仅限于 mu-阿片受体 (MOR) 激动剂。根据区域的不同，刺激非阿片受体可以产生类似的结果。到目前为止，被证明能产生快感增强的神经递质包括大麻素 (NAc)、食欲素 (NAc、VP、PBN、OFC) 和 GABA (PBN；Söderpalm &amp; Berridge, 2000)。</p><p>前面我提到<em>“喜欢”</em>系统和<em>“想要”</em>系统是紧密相连的。事实证明，在大多数情况下，刺激皮层下享乐热点除了“喜欢<em>”之外还增加了“想要</em><em>”</em> 。此外，在享乐热点中增加<em>“欲望”</em>的化合物范围远大于增加<em>“喜好”</em>的化合物范围（Berridge &amp; Kringelbach，2013）。刺激 NAc 和 VP 中的冷点也可以产生<em>“想要”</em> 。我将在第 3 节中进一步讨论这一点。相反，阿片类药物可以间接增加腹侧被盖区的活动，该区域是核心<em>“想要”</em>通路中多巴胺的主要来源（Zhang 等人，2022）。</p><p>包含热点和冷点的 NAc 壳区域通常用“情感键盘”来描述，其中神经元的位置与它们的激活引起的情感反应（例如<em>“喜欢”</em>与<em>“不喜欢”</em> ）密切相关（Richard等，2013；Berridge &amp; Kringelbach，2013，2015）。更具体地说，似乎存在从前到后延伸的化合价梯度。刺激“键盘”更靠前的区域会引起<em>“喜欢”</em>反应，而更多位于尾部的神经元会抑制<em>“喜欢”</em>和/或引起<em>“不喜欢”</em> ，有时还伴随着对威胁（例如捕食者）的物种特异性反应。</p><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3706488/figure/F2/">图 2</a>来自 Richard 等人。 (2013) 显示了 NAc 中神经元群体的分布，这些神经元的刺激会引发特定类型的行为。我们有享乐热点（红橙色），其中激活通常会增强<em>“喜欢”</em>反应。在它后面，我们看到两个区域。在腹侧（下侧），有一组神经元具有我们期望从享乐冷点（蓝色）获得的功能。他们的刺激会抑制<em>“喜欢”</em> 。在背侧（上侧），我们有另一个簇，它也具有抑制作用，但它们不是抑制<em>“喜欢”</em> ，而是抑制厌恶反应（紫色）。所有这些位点，除了对<em>“喜欢”</em>的影响外，“仍然产生进食”（即<em>“想要”</em>进食），它们所在的更广泛（绿色）区域和背内侧新纹状体的一部分也是如此。粗略地说，尾状核和壳核位于 NAc 上方），如图左上角的绿点所示。</p><p>冷点区域还包含其功能超出<em>“喜欢（不）喜欢”</em>调节范围的细胞。对其中一些的刺激会产生恐惧反应或攻击性表现，例如向潜在威胁的刺激物扔泥土。重要的是，这些细胞的刺激结果也可以受到环境的调节。在平静、平和和安全的环境中，刺激增加积极反应的区域会扩大，而厌恶/恐惧反应的区域会缩小。压力大、危险、不安全的环境会产生相反的效果。</p><p>与热点类似，刺激冷点的结果取决于所使用的配体的种类。刺激相同的三种阿片受体（mu、delta、kappa）会增强 NAc 热点的<em>“喜欢”</em> ，在邻近的冷点产生强烈的<em>“（不）喜欢”</em>甚至与恐惧相关的行为。 Mu 受体激动剂还抑制 VP 冷点的<em>“喜欢”</em> 。</p><h3> 2.3.有意识的快乐有什么好处？</h3><p>诚然，目前还不清楚<em>“喜欢”</em>和<em>喜欢</em>如何以及在多大程度上相互依赖。 <em>“喜欢”</em>的东西需要什么才能变得<em>喜欢</em>？我们知道<em>“喜欢”</em>可以在不<em>喜欢的情况</em>下发生，但是反过来呢？有什么东西可以满足我们明确的享乐感受而不影响任何这些“核心情感反应”吗？或者，只要意识“开启”（至少超过某个阈值） <em>，“喜欢”的</em>事物就会变得<em>喜欢</em>？从我对文献的粗略回顾来看，我们似乎不知道，尽管眶额皮层（OFC）作为该区域的主要候选区域出现，其活动（可能除了更基本的<em>“喜欢”</em>结构之外）对于<em>喜欢</em>很重要（克林格尔巴赫，2005，2010）。</p><p><a href="https://en.wikipedia.org/wiki/Global_workspace_theory">意识的全局工作空间理论（GWT）</a> <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-22" id="fnref-FMm4ikcDkjYYfSWqb-22">[22]</a></sup> （及其所借鉴的实验）可能会给出一些关于<em>“喜欢”</em><em>刺激</em>/事件的建议。大脑可以无意识地进行相当多的复杂处理（例如， <a href="https://www.lesswrong.com/posts/x4n4jcoDP7xh5LWLq/book-summary-consciousness-and-the-brain#Unconscious_processing_of_meaning">单词的语义</a>）。在 GWT 范式中进行的实验表明了这一点，使用<a href="https://en.wikipedia.org/wiki/Visual_masking">感觉掩蔽</a>来防止刺激到达意识。根据 GWT，与表示/处理特定刺激相关的神经活动必须超过某个关键阈值，才能传播到其他（特别是多模式/联想/更高级别）大脑区域，然后这些区域可以开始以某种同步的方式处理它。方式。这是“意识到<em>某</em>事”的神经基础。该表征可供其他大脑系统使用，包括直接连接到言语器官的系统，以便我们可以报告我们对刺激的意识。否则，它的处理仍然是无意识的、局部的，并且仅限于特定的较低级别的大脑区域。</p><p>将此观点转化为<em>“喜欢”</em>和<em>喜欢的</em>情况，可能存在类似的核心享乐影响（ <em>“喜欢”</em> ）强度阈值，刺激必须超过该阈值才能传播到全球工作空间并被有意识地<em>喜欢</em>。传播到某些特定区域（例如 OFC）似乎特别重要。</p><p>值得注意的是，为了防止有价刺激到达意识，显示无意识处理的刺激对客观可观察的快乐相关因素的影响的实验（例如，Winkielman等人，2005）使用了与GWT相同的方法，即感觉掩蔽。这是一个小证据，表明 GWT 实验的结果可能会转化为<em>“喜欢”</em>和<em>喜欢的</em>情况。</p><p>如果这个观点是正确的，它可能指向有意识的<em>喜好</em>的可能功能，因为<a href="https://www.lesswrong.com/posts/KuKaQEu7JjBNzcoj5/explicitness">明确的</a>享乐价值增加了​​影响其他大脑系统的可能途径的范围（例如，第3节中讨论的动机回路）。所以也许问题是“有意识的快乐有什么好处？”只不过是“意识有什么好处”的一个特例？</p><p>关于<em>喜欢</em>而不是<em>“喜欢”的可能性，</em>我想知道自我形象、规范信念、社会期望或（广泛理解的）当前情况的反思性评估等因素是否会产生自上而下的影响（例如，我对生活的感觉有多好，或者世界上事物的发展方式）可能会引起<em>喜欢</em>，但不会引起核心情感反应和皮层下享乐热点的相应活动。另一方面，我还预计，至少在某些情况下（也许在大多数甚至所有情况下），皮质下（不）快感发生器将由于这种自上而下的影响而被二次激活。</p><h2> 3. 想要</h2><h3>3.1. <em>“想要”</em>与<em>想要</em></h3><p>我们的行为并不总是反映我们对应该做什么的明确信念，这很难说是一个原始的观察。 This phenomenon has been given many names, such as <a href="https://www.lesswrong.com/tag/akrasia">akrasia</a> , weakness of will, or lack of willpower. This may make the distinction between <em>&quot;wanting&quot;</em> (incentive salience) and <em>wanting</em> (cognitive desire) more relatable and intuitive than the one between <em>&quot;liking&quot;</em> and <em>liking</em> .</p><p> <em>&quot;Wanting&quot;</em> can be seen as the unconscious counterpart of <em>wanting</em> , similarly to how <em>&quot;liking&quot;</em> is the unconscious counterpart of <em>liking</em> . Whereas <em>wanting</em> (cognitive incentives) refers to plans directed towards goals we are aware of and explicitly represented desires, <em>&quot;wanting&quot;</em> (incentive salience) refers to more impulsive, reactive, low-level motivation, which can act independently of what we (state that we) <em>want</em> or <em>like</em> .</p><p> More specifically, <em>&quot;wanting&quot;</em> is defined as &quot;a conditioned motivation response of a brain, usually triggered by and assigned to a reward-related stimulus&quot; (Berridge, 2007). A stimulus is reward-related if it is associated with an event that is &quot;rewarding in itself&quot;, eg, sweet taste. The association can be simple, like occurring very close in time, or it may involve some more sophisticated cognitive learning processes. <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-23" id="fnref-FMm4ikcDkjYYfSWqb-23">[23]</a></sup> The learned reward-related stimulus is often called the &quot;conditioned stimulus&quot; (CS), whereas the inherently rewarding event is called the &quot;unconditioned stimulus&quot; (UCS). However, <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-24" id="fnref-FMm4ikcDkjYYfSWqb-24">[24]</a></sup> not all inputs that drive <em>&quot;wanting&quot;</em> are learned, as brains are wired to respond with <em>&quot;wanting&quot;</em> to some stimuli, independently of learning (or in the absence of/prior to learning). Plausibly, the original adaptive value of <em>&quot;wanting&quot;</em> was to motivate the animals to pursue a small set of unconditioned rewards, such as food, sex, or favorable ranges of environmental conditions, such as appropriate temperature and acidity. Over time, as more sophisticated learning mechanisms evolved, the role of <em>&quot;wanting&quot;</em> became extendable by learning (Berridge, 2007).</p><p> According to Berridge and Robinson (2003) cognitive incentives ( <em>wanting</em> ) are distinguished from incentive salience ( <em>&quot;wanting&quot;</em> ) by three (or maybe four) features:</p><blockquote><p> … they are (1) known or imagined (cognitive incentive representation); (2) expected to be pleasant (hedonic expectation); (3) subjectively desired and intended to be gained (explicit cognitive representation of wanting) and, perhaps, (4) known to be obtainable by actions that cause it to occur (understanding of act–outcome causality). <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-25" id="fnref-FMm4ikcDkjYYfSWqb-25">[25]</a></sup></p></blockquote><p> I will speculate a bit more about the differences and relationships between <em>&quot;wanting&quot;</em> and <em>wanting</em> in Section 3.3. In the next Section 3.2, I outline the neurobiological basis of <em>&quot;wanting&quot;</em> .</p><h3> 3.2. <em>&quot;Wanting&quot;</em> in the brain</h3><p> <em>&quot;Liking&quot;</em> can be roughly located in a handful of hedonic hot spots and cold spots, with endogenous opioids being the main players in the circuitry (as discussed in Section 2). The neural substrate of <em>&quot;wanting&quot;</em> is more distributed throughout the brain, with dopamine as the key neurotransmitter.</p><p> The human brain has several <a href="https://en.wikipedia.org/wiki/Dopaminergic_pathways">dopaminergic pathways</a> , the most relevant for <em>&quot;wanting&quot;</em> being the <a href="https://en.wikipedia.org/wiki/Mesolimbic_pathway">mesolimbic pathway</a> . It goes from the <a href="https://en.wikipedia.org/wiki/Ventral_tegmental_area">ventral tegmental area (VTA)</a> to the ventral striatum (including the nucleus accumbens) and some other areas. Although it is the biggest supplier of dopamine to brain regions involved in incentive salience (Ikemoto, 2010), it is not the only one, and, at least in some artificial setups, <em>&quot;wanting&quot;</em> can occur even when it stops working.</p><p> We know that, ia, from studies of More specifically, animals that had their mesolimbic pathway ablated, can still develop a compulsion to self-stimulate via electrodes implanted in some brain regions (cf. Ikemoto, 2010, p. 131). It is not clear to what extent these results translate to <em>&quot;wanting&quot;</em> without the mesolimbic pathway more generally.</p><p> VTA and other regions involved in <em>&quot;wanting&quot;</em> form a highly interconnected network (cf. Ikemoto, 2010). However, many of them are not <em>&quot;wanting&quot;</em> -specific, but also involved in other aspects of reward. In Section 2, I discussed the hedonic hot and cold spots in the nucleus accumbens and the ventral pallidum. Stimulating them with many neurotransmitters (including those which tend to elicit <em>&quot;(dis)liking&quot;</em> reactions) tends to produce <em>&quot;wanting&quot;</em> behavior, both related to approach ( <em>&quot;wanting&quot;</em> X) and aversion ( <em>&quot;wanting&quot;</em> not-X). The same is true for the parabrachial nucleus of the hindbrain, whose GABA-A receptors&#39; stimulation <em>&quot;wanting&quot;</em> but has a small region adjacent to it, where it also elicits <em>&quot;liking&quot;</em> .</p><p> Other regions of the network are involved in learning. For example, Pavlovian learning seems to depend on a circuit whose major components are the basolateral amygdala, the orbitofrontal cortex, and the nucleus accumbens (Burke et al., 2010). On the other hand, stimulation of the central amygdala when paired with a highly salient stimulus (doesn&#39;t matter whether it&#39;s pleasant or unpleasant, it just needs to have strong valence in either direction) can establish very strong <em>&quot;wanting&quot;</em> even for highly unpleasant stimuli (Warlow et al., 2020).</p><p> Two other dopaminergic pathways that are important for <em>&quot;wanting&quot;</em> are the mesocortical pathway and the nigrostriatal pathway. The mesocortical pathway goes from the VTA to the prefrontal cortex and is involved in executive functioning. Its disorders, including those involving dopamine depletion or other interference with dopaminergic activity, are associated with impaired cognitive control and working memory (cf. Ott &amp; Nieder, 2019).</p><p> The nigrostriatal pathway goes from the substantia nigra (SN) to the dorsal striatum and its main role is movement control. The death of a majority of SN cells is the proximate cause of Parkinson&#39;s disease. Parkinson&#39;s patients tend to develop symptoms associated with decreased functioning of the mesolimbic pathway (eg, apathy) and the mesocortical pathway (eg, attentional deficits). The severity of these symptoms is highly correlated with the severity of motor symptoms, suggesting some relevant degree of coupling between these systems (cf. Leyton, 2010, pp. 232-233).</p><p> The next few paragraphs discuss how dopaminergic activity in general impacts <em>&quot;wanting&quot;</em> . It is not meant to be a complete overview of evidence or comparison with alternative hypotheses (for that see: Berridge, 2007), but rather as an informative illustration of the role played by this neurotransmitter.</p><p> Probably the most straightforward method to test how some neurotransmitter X influences some behavior Y is to lower or increase the levels of X and measure changes in Y. One way to do it is by breeding genetically modified animals that have abnormally low or high levels of the neurotransmitter in their synapses (cf. Berridge, 2007, pp. 403-405).</p><p> Dopamine-deficient (DD) mice, with almost no dopamine in their brains, can be created by knocking out the gene coding for tyrosine hydroxylase, an enzyme without which dopamine can&#39;t be produced. DD eat and drink barely anything at all, not enough to sustain themselves. <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-26" id="fnref-FMm4ikcDkjYYfSWqb-26">[26]</a></sup> In order for them to eat and drink normally, they need to be medicated with L-DOPA (a direct dopamine precursor, removed from dopamine by just one step in the production chain), which can temporally restore their dopamine to normal levels.</p><p> This makes it possible to test (1) whether DD mice display different affective/ <em>&quot;liking&quot;</em> reactions for different kinds of stimuli (eg, sugar solution versus water) and (2) whether after trying both of them, they learn to prefer one over the other, as measured by their choices on subsequent trials. It turns out that they can do both, which suggests that dopamine is not required for (at least some forms of) <em>&quot;liking&quot;</em> and reward-related learning. Similar patterns have been observed in wild-type (ie, normal/not genetically modified) mice, whose dopaminergic systems were impaired later in their life by neurochemical lesions.</p><p> On the other hand, <strong>hyper</strong> dopaminergic mice, which have almost triple the normal amount of dopamine in their synapses (compared to the wild type), can be created by knocking out the gene coding for the dopamine transporter, a protein that removes dopamine from the synapse. Such mice are more motivated to obtain rewards, more resistant to stimuli distracting them from the focus on the current goal, and willing to work harder for rewards. In other words, they seem to <em>&quot;want&quot;</em> their rewards more than the wild type. Their ability to learn associations between stimuli and rewards or learn which actions lead to rewards, as well as <em>&quot;liking&quot;</em> reactions, remain unaffected.</p><p> What about dopamine disturbance diseases in humans (cf. Leyton, 2010)? Parkinson&#39;s disease (PD) is caused by the degradation of dopaminergic cells in the substantia nigra, which are not directly involved in the mesolimbic system. Still, many PD patients exhibit symptoms associated with decreased dopaminergic functioning in the mesolimbic (eg, apathy, avolition) and mesocortical (eg, worse attention and executive functioning) systems. The severity of these symptoms correlates with the strength of motor problems, more central to Parkinson&#39;s. Some PD patients treated with L-DOPA (~3-4%; Pezzella, 2005) develop <a href="https://en.wikipedia.org/wiki/Dopamine_dysregulation_syndrome">dopamine dysregulation syndrome (DDS)</a> , where overcompensation for dopamine deficiency leads them to develop &quot;pathological&quot; <em>&quot;wanting&quot;</em> behavior (addiction, gambling, compulsive sexual activity, even if they had no history of such before the medication) making them illustrative cases of hyperdopaminergy. <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-27" id="fnref-FMm4ikcDkjYYfSWqb-27">[27]</a></sup></p><p> Many highly addictive potentials are dopaminergic. Central examples include amphetamine, cocaine, and their analogs, which work primarily by increasing the amount of dopamine that stays in the synaptic cleft. Interestingly, in animal studies, their addictive potential can be reduced (perhaps even (almost?) completely eliminated?) if they are given together with DA antagonists, ie, compounds that bind to dopamine receptors without activating them, which prevents dopamine itself from binding to them and exerting its typical effects (cf. Puglisi-Allegra &amp; Ventura, 2012). At the same time, dopamine antagonism does not eliminate other effects of these dopaminergic drugs. For example, some euphoric effects remain when amphetamine is given with DA antagonists (cf. Leyton, 2010), suggesting that these are either mediated through mechanisms other than dopamine or perhaps some dopamine receptors that are not blocked by the particular used in the study <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-28" id="fnref-FMm4ikcDkjYYfSWqb-28">[28]</a></sup> (Nader et al., 1997; Ikemoto, 2010).</p><p> Highly addictive drugs that don&#39;t interact with the dopamine system directly tend to have secondary dopaminergic effects. For example, the agonists of mu-opioid receptors (such as morphine, heroin, and fentanyl) typically work by inhibiting GABA-ergic neurons located in the posterior part of the VTA or an area adjacent to it, called rostromedial tegmentum (RMTg). On the other hand, these GABA-ergic neurons inhibit the dopaminergic neurons of the VTA, which drive <em>&quot;wanting&quot;</em> . Therefore, inhibition of the former means disinhibition of the latter and thus an increase in the concentrations of DA in regions targeted by the VTA (cf. Zhang et al., 2022).</p><p> Caffeine is another compound with indirect dopaminergic effects (and a relatively mild addictive potential). Although its main mechanism of action is blocking the adenosine receptors, it also increases dopamine release, contributing to its psychostimulant and reinforcing properties (Ferré, 2016). We can see that in experiments, where adding caffeine to yogurt strengthened the preference developed for that yogurt, as compared to the same yogurt but without caffeine (Panek et al., 2013). Analogous experiments with similar results were performed on bees and caffeine-enriched nectar, with similar results (Wright et al., 2013). <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-29" id="fnref-FMm4ikcDkjYYfSWqb-29">[29]</a></sup></p><p> <a href="https://en.wikipedia.org/wiki/Pavlovian-instrumental_transfer">Pavlovian-instrumental transfer</a> is what happens when an animal that is already working in order to obtain some reward/UCS, starts working even harder upon perceiving a CS associated with the UCS it&#39;s currently pursuing. This effect has been closely associated with an increase in mesolimbic dopaminergic activity and can be modulated by intervening in the mesolimbic system, eg, with dopamine agonists (Berridge, 2007, pp. 420-421; Cartoni et al., 2016; Salamone et al., 2016).</p><h3> 3.3. What are cognitive incentives/conscious wanting good for?</h3><p> Why do we need <em>wanting</em> in addition to <em>&quot;wanting&quot;</em> ? In Section 2 I asked an analogous question with respect to <em>liking</em> and <em>&quot;liking&quot;</em> and gave a provisional hypothesis that consciousness of a valenced stimulus makes it accessible to other parts of the brain, allowing them to interoperate and make use of each other&#39;s outputs. Are <em>wanting</em> and <em>&quot;wanting&quot;</em> in an analogous relationship?</p><p> Berridge and Robinson (2003) seem to endorse something like this. In their view, <em>wanting</em> allows the animal to achieve objectives, that can&#39;t be achieved through simple learning of associations and require more complex inference, working memory, etc. They write:</p><blockquote><p> One essence of rational cognition is its inferential exploitation of lawful consistencies in the world and, typically, future value is best inferred from past value. In addition, the rat must use its understanding of which actions cause which outcomes to select from several possible actions the one that will produce the best reward.</p></blockquote><p> Relatedly, <em>wanting</em> , as a process under conscious executive control, is more stable with respect to changing local incentives, which makes planning and execution of plans possible in the first place.</p><p> Thus, the mesocortical pathway which goes from the VTA to some parts of the prefrontal cortex is a likely candidate for a major substrate of <em>wanting</em> , as one of its major roles is executive function.</p><p> Echoing the speculations from the end of Section 2, can we <em>want</em> something without <em>&quot;wanting&quot;</em> it? Perhaps we can take again the self-image angle: we model ourselves as <em>wanting</em> X, but this model is not accurate and not strong enough to override <em>&quot;wanting&quot;</em> that pushes in the other direction. Perhaps sometimes <em>wanting</em> without <em>&quot;wanting&quot;</em> is adaptive because it causes the organism to think about plans of action that can be executed once a proper context occurs, so that <em>&quot;wanting&quot;</em> is triggered and makes use of the information contained in the plans developed due to <em>wanting</em> .</p><h2> 4. Why <em>&quot;like&quot;</em> something if you can just <em>&quot;want&quot;</em> it?</h2><p> Ex ante, we might expect that <em>&quot;wanting&quot;</em> itself, paired with a sufficiently good learning algorithm, should be enough to achieve any goals necessary for survival and reproductive fitness.</p><p> Maybe it is necessary or more efficient to have separate systems for (1) adaptive but &quot;mindless&quot; responses to local incentives and (2) goal-directed behavior that relies on taking into account broader context; hence <em>&quot;wanting&quot;</em> and <em>wanting</em> , respectively. Still, this leaves us with a question about the adaptive value of <em>&quot;liking&quot;</em> and <em>liking</em> . Had they not contributed to our ancestors&#39; fitness in one way or another, evolution would not have selected for them. <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-30" id="fnref-FMm4ikcDkjYYfSWqb-30">[30]</a></sup></p><p> It seems that the field has not reached a consensus on that question. Here I present three hypotheses. Like much of evolutionary psychology, they are all tentative, and if evidence for them is at best indirect. Importantly, these hypotheses are neither exhaustive nor mutually exclusive.</p><h3> Hypothesis 1: Liking extends wanting</h3><p> On this account, we start with a small set of default motivations that evolution selected for ( <em>&quot;wants&quot;</em> ), and <em>&quot;liking&quot;</em> helps repurpose the motivational system towards new motivations. The <em>&quot;wanting&quot;</em> system is more evolutionarily ancient. <em>&quot;Liking&quot;</em> emerged relatively recently, in animals living in more cognitively demanding environments that necessitated acquiring new motivational mechanisms over the lifetime. Pleasure is an additional training signal for the <em>&quot;wanting&quot;</em> system, allowing the brain to repurpose systems specialized for being motivated towards one domain of stimuli/events towards another domain. The need for this &quot;lifetime reprogramming&quot; may arise due to the environment being too complex or too variable for evolution to encode appropriate sources of motivation into the genome.</p><p> Kent Berridge (a pioneer of this line of research) seems to lean towards this hypothesis ( <a href="https://hearthisidea.com/episodes/kent">podcast interview link</a> ). He gives credit for it to, among others, Anthony Dickinson (eg, Dickinson &amp; Balleine, 2010).</p><p> Quoting directly from the episode (lightly edited by me):</p><blockquote><p> […] pleasure exists because it essentially allows brain <em>&quot;wanting&quot;</em> systems that might have evolved for one thing (eg, food) to experience a new pleasant event (eg, social accomplishment) and to enjoy that event and to bring to bear the brain <em>&quot;wanting&quot;</em> systems for the old thing on to this new target, basically giving us a new target of desire.</p></blockquote><p> On this account, it seems to be somewhat similar to the picture presented by the <a href="https://www.lesswrong.com/posts/iCfdcxiyr2Kj8m8mT/the-shard-theory-of-human-values">Shard Theory view of human values</a> , except that not all the values (contextually activated motivations/ <em>&quot;wants&quot;</em> ) are learned from scratch.</p><p> Here, Berridge doesn&#39;t distinguish between <em>&quot;liking&quot;</em> and <em>liking</em> . My interpretation is that he views them as serving a similar function, just on different levels of &quot;cognitive sophistication&quot;, similar to <em>&quot;wanting&quot;</em> and <em>wanting</em> .</p><p> There is an interesting category of cases, where the learned change in valence happens prior to a corresponding change in motivation. In other words, your experience changes whether/how much you <em>&quot;(dis)like&quot;</em> X but without updating your motivation for X. Your motivation for X is updated the next time you encounter X and experience altered valence.</p><p> Dickinson and Balleine (Balleine, 2010) give an example, where the first author (AD) who really liked watermelons, at some point got sick shortly after eating a watermelon (most likely the disease and eating the fruit were not related). A few days later, he went to eat a watermelon and although it was most likely basically the same kind of watermelon, it tasted awful. Apparently, his <em>&quot;liking&quot;</em> / <em>liking</em> system wrongly inferred the watermelon to be the causal factor behind the sickness, which altered his taste, but not his motivation to eat watermelons, until he tasted a no-longer-tasty watermelon. These cases have been reproduced in rat experiments. <sup class="footnote-ref"><a href="#fn-FMm4ikcDkjYYfSWqb-31" id="fnref-FMm4ikcDkjYYfSWqb-31">[31]</a></sup></p><p> Note that this is different from the Salt Sea experiment (Robinson &amp; Berridge, 2013), where rats&#39; motivation was already altered by their physiological state before being presented with the stimulus. In the watermelon case, on the other hand, the aversion occurs unexpectedly.</p><h3> Hypothesis 2: Preparing physiology</h3><p> <em>&quot;Liking&quot;</em> reactions associated with food and fluids seem to prepare the organism for intake of nutrients. Increased salivation facilitates pre-digestion of the food in the mouth, licking the lips ensures that some bits of the food are not left out, increased gastric movements prepare the rest of the digestive system, etc.</p><h3> Hypothesis 3: Implicit social communication</h3><p> An animal&#39;s physiological reactions, like the ones discussed above, often carry socially important information. Thus, it&#39;s plausible that in more social species these behaviors would evolve to become more pronounced, in other to facilitate implicit social communication. On the other hand, they may also become less reflective of the actual physiological state, in order to produce signals that are more likely to influence the behavior of the other animal in the direction that is beneficial for the signaller.</p><h3> Hypothesis 4: Additional information to update behavior on</h3><p> Valence ( <em>&quot;liking&quot;</em> / <em>liking</em> ) may also route partially processed information to the motivational circuits in order to update already ongoing behavior. If we do X for the first time and it quickly turns out that we <em>like</em> it, we do more of it. An obvious caveat is that we may not be able to experimentally disentangle the indirect effect mediated by valence from the direct effect. We have seen that it is possible to very quickly develop strong motivation for something without <em>&quot;liking&quot;</em> it, eg, in the wireheading studies.</p><h2>参考</h2><ul><li>Berridge, KC (2007). The debate over dopamine&#39;s role in reward: The case for incentive salience. Psychopharmacology, 191(3), 391–431. <a href="https://doi.org/10.1007/s00213-006-0578-x">https://doi.org/10.1007/s00213-006-0578-x</a></li><li> Berridge, KC, &amp; Kringelbach, ML (2008). Affective neuroscience of pleasure: Reward in humans and animals. Psychopharmacology, 199(3), 457–480. <a href="https://doi.org/10.1007/s00213-008-1099-6">https://doi.org/10.1007/s00213-008-1099-6</a></li><li> Berridge, KC, &amp; Kringelbach, ML (2013). Neuroscience of affect: Brain mechanisms of pleasure and displeasure. Social and Emotional Neuroscience, 23(3), 294–303. <a href="https://doi.org/10.1016/j.conb.2013.01.017">https://doi.org/10.1016/j.conb.2013.01.017</a></li><li> Berridge, KC, &amp; Kringelbach, ML (2015). Pleasure Systems in the Brain. Neuron, 86(3), 646–664. <a href="https://doi.org/10.1016/j.neuron.2015.02.018">https://doi.org/10.1016/j.neuron.2015.02.018</a></li><li> Berridge, KC, &amp; Robinson, TE (2003). Parsing reward. Trends in Neurosciences, 26(9), 507–513. <a href="https://doi.org/10.1016/S0166-2236(03)00233-9">https://doi.org/10.1016/S0166-2236(03)00233-9</a></li><li> Berridge, KC, &amp; Robinson, TE (2016). Liking, wanting, and the incentive-sensitization theory of addiction. The American Psychologist, 71(8), 670–679. <a href="https://doi.org/10.1037/amp0000059">https://doi.org/10.1037/amp0000059</a></li><li> Berridge, K., &amp; Winkielman, P. (2003). What is an unconscious emotion? (The case for unconscious &quot;liking&quot;). Cognition and Emotion, 17(2), 181–211. <a href="https://doi.org/10.1080/02699930302289">https://doi.org/10.1080/02699930302289</a></li><li> Burke, KA, Franz, T., Miller, D., &amp; Schoenbaum, G. (2010). Conditioned Reinforcement and the Specialized Role of Corticolimbic Circuits in the Pursuit of Happiness and Other More Specific Rewards. In ML Kringelbach &amp; KC Berridge (Eds.), Pleasures of the Brain (pp. 50–62). Oxford University Press.</li><li> Cartoni, E., Balleine, B., &amp; Baldassarre, G. (2016). Appetitive Pavlovian-instrumental Transfer: A review. Neuroscience &amp; Biobehavioral Reviews, 71, 829–848. <a href="https://doi.org/10.1016/j.neubiorev.2016.09.020">https://doi.org/10.1016/j.neubiorev.2016.09.020</a></li><li> dela Peña, I., Gevorkiana, R., &amp; Shi, W.-X. （2015）。 Psychostimulants affect dopamine transmission through both dopamine transporter-dependent and independent mechanisms. European Journal of Pharmacology, 764, 562–570. <a href="https://doi.org/10.1016/j.ejphar.2015.07.044">https://doi.org/10.1016/j.ejphar.2015.07.044</a></li><li> Dickinson, A., &amp; Balleine, B. (2010). Hedonics: The Cognitive–Motivational Interface. In ML Kringelbach &amp; KC Berridge (Eds.), Pleasures of the Brain (pp. 74–84). Oxford University Press.</li><li> Ferré, S. (2016). Mechanisms of the psychostimulant effects of caffeine: Implications for substance use disorders. Psychopharmacology, 233(10), 1963–1979. <a href="https://doi.org/10.1007/s00213-016-4212-2">https://doi.org/10.1007/s00213-016-4212-2</a></li><li> Ikemoto, S. (2010). Brain reward circuitry beyond the mesolimbic dopamine system: A neurobiological theory. Novel Perspectives on Drug Addiction and Reward, 35(2), 129–150. <a href="https://doi.org/10.1016/j.neubiorev.2010.02.001">https://doi.org/10.1016/j.neubiorev.2010.02.001</a></li><li> Kringelbach, ML (2005). The human orbitofrontal cortex: Linking reward to hedonic experience. Nature Reviews Neuroscience, 6(9), 691–702. <a href="https://doi.org/10.1038/nrn1747">https://doi.org/10.1038/nrn1747</a></li><li> Kringelbach, ML (2010). The Hedonic Brain: A Functional Neuroanatomy of Human Pleasure. In ML Kringelbach &amp; KC Berridge (Eds.), Pleasures of the Brain (pp. 202–221). Oxford University Press.</li><li> Leyton, M. (2010). The Neurobiology of Desire: Dopamine and the Regulation of Mood and Motivational States in Humans. In ML Kringelbach &amp; KC Berridge (Eds.), Pleasures of the Brain (pp. 222–243). Oxford University Press.</li><li> Nader, K., Bechara, A., &amp; van der Kooy, D. (1997). Neurobiological constraints on behavioral models of motivation. Annual Review of Psychology, 48(1), 85–114. <a href="https://doi.org/10.1146/annurev.psych.48.1.85">https://doi.org/10.1146/annurev.psych.48.1.85</a></li><li> Ott, T., &amp; Nieder, A. (2019). Dopamine and Cognitive Control in Prefrontal Cortex. Trends in Cognitive Sciences, 23(3), 213–234. <a href="https://doi.org/10.1016/j.tics.2018.12.006">https://doi.org/10.1016/j.tics.2018.12.006</a></li><li> Panek, LM, Swoboda, C., Bendlin, A., &amp; Temple, JL (2013). Caffeine increases liking and consumption of novel-flavored yogurt. Psychopharmacology, 227(3), 425–436. <a href="https://doi.org/10.1007/s00213-013-2971-6">https://doi.org/10.1007/s00213-013-2971-6</a></li><li> Pezzella, FR, Colosimo, C., Vanacore, N., Di Rezze, S., Chianese, M., Fabbrini, G., &amp; Meco, G. (2005). Prevalence and clinical features of hedonistic homeostatic dysregulation in Parkinson&#39;s disease. Movement Disorders, 20(1), 77–81. <a href="https://doi.org/10.1002/mds.20288">https://doi.org/10.1002/mds.20288</a></li><li> Puglisi-Allegra, S., &amp; Ventura, R. (2012). Prefrontal/accumbal catecholamine system processes high motivational salience. Frontiers in Behavioral Neuroscience, 6, 31. <a href="https://doi.org/10.3389/fnbeh.2012.00031">https://doi.org/10.3389/fnbeh.2012.00031</a></li><li> Ramsey, W. (2022). Eliminative Materialism. In EN Zalta (Ed.), The Stanford Encyclopedia of Philosophy (Spring 2022). Metaphysics Research Lab, Stanford University. <a href="https://plato.stanford.edu/archives/spr2022/entries/materialism-eliminative/">https://plato.stanford.edu/archives/spr2022/entries/materialism-eliminative/</a></li><li> Richard, JM, Castro, DC, Difeliceantonio, AG, Robinson, MJF, &amp; Berridge, KC (2013). Mapping brain circuits of reward and motivation: In the footsteps of Ann Kelley. Neuroscience and Biobehavioral Reviews, 37(9 Pt A), 1919–1931. <a href="https://doi.org/10.1016/j.neubiorev.2012.12.008">https://doi.org/10.1016/j.neubiorev.2012.12.008</a></li><li> Robinson, MJF, &amp; Berridge, KC (2013). Instant transformation of learned repulsion into motivational &quot;wanting&quot;. Current Biology : CB, 23(4), 282–289. <a href="https://doi.org/10.1016/j.cub.2013.01.016">https://doi.org/10.1016/j.cub.2013.01.016</a></li><li> Salamone, JD, Pardo, M., Yohn, SE, López-Cruz, L., SanMiguel, N., &amp; Correa, M. (2016). Mesolimbic Dopamine and the Regulation of Motivated Behavior. In EH Simpson &amp; PD Balsam (Eds.), Behavioral Neuroscience of Motivation (pp. 231–257). Springer International Publishing. <a href="https://doi.org/10.1007/7854_2015_383">https://doi.org/10.1007/7854_2015_383</a></li><li> Smith, KS, &amp; Berridge, KC (2007). Opioid limbic circuit for reward: Interaction between hedonic hotspots of nucleus accumbens and ventral pallidum. The Journal of Neuroscience : The Official Journal of the Society for Neuroscience, 27(7), 1594–1605. <a href="https://doi.org/10.1523/JNEUROSCI.4205-06.2007">https://doi.org/10.1523/JNEUROSCI.4205-06.2007</a></li><li> Smith, KS, Berridge, KC, &amp; Aldridge, JW (2011). Disentangling pleasure from incentive salience and learning signals in brain reward circuitry. Proceedings of the National Academy of Sciences of the United States of America, 108(27), E255-264. <a href="https://doi.org/10.1073/pnas.1101920108">https://doi.org/10.1073/pnas.1101920108</a></li><li> Smith, KS, Mahler, SV, Peciña, S., &amp; Berridge, KC (2010). Hedonic Hotspots: Generating Sensory Pleasure in the Brain. In ML Kringelbach &amp; KC Berridge (Eds.), Pleasures of the Brain (pp. 27–49). Oxford University Press.</li><li> Söderpalm, AH, &amp; Berridge, KC (2000). The hedonic impact and intake of food are increased by midazolam microinjection in the parabrachial nucleus. Brain Research, 877(2), 288–297. <a href="https://doi.org/10.1016/s0006-8993(00)02691-3">https://doi.org/10.1016/s0006-8993(00)02691-3</a></li><li> Steiner, JE (1973). The gustofacial response: Observation on normal and anencephalic newborn infants. Symposium on Oral Sensation and Perception, 4, 254–278.</li><li> Szczypka, MS, Rainey, MA, Kim, DS, Alaynick, WA, Marck, BT, Matsumoto, AM, &amp; Palmiter, RD (1999). Feeding behavior in dopamine-deficient mice. Proceedings of the National Academy of Sciences, 96(21), 12138–12143. <a href="https://doi.org/10.1073/pnas.96.21.12138">https://doi.org/10.1073/pnas.96.21.12138</a></li><li> Warlow, SM, Naffziger, EE, &amp; Berridge, KC (2020). The central amygdala recruits mesocorticolimbic circuitry for pursuit of reward or pain. Nature Communications, 11(1), 2716. <a href="https://doi.org/10.1038/s41467-020-16407-1">https://doi.org/10.1038/s41467-020-16407-1</a></li><li> Winkielman, P., Berridge, K., &amp; Wilbarger, J. (2005). Unconscious Affective Reactions to Masked Happy Versus Angry Faces Influence Consumption Behavior and Judgments of Value. Personality &amp; Social Psychology Bulletin, 31, 121–135. <a href="https://doi.org/10.1177/0146167204271309">https://doi.org/10.1177/0146167204271309</a></li><li> Wright, GA, Baker, DD, Palmer, MJ, Stabler, D., Mustard, JA, Power, EF, Borland, AM, &amp; Stevenson, PC (2013). Caffeine in Floral Nectar Enhances a Pollinator&#39;s Memory of Reward. Science, 339(6124), 1202–1204. <a href="https://doi.org/10.1126/science.1228806">https://doi.org/10.1126/science.1228806</a></li><li> Zhang, J.-J., Song, C.-G., Dai, J.-M., Li, L., Yang, X.-M., &amp; Chen, Z.-N. (2022). Mechanism of opioid addiction and its intervention therapy: Focusing on the reward circuitry and mu-opioid receptor. MedComm, 3(3), e148. <a href="https://doi.org/10.1002/mco2.148">https://doi.org/10.1002/mco2.148</a> </li></ul><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-FMm4ikcDkjYYfSWqb-1" class="footnote-item"><p> Ordered alphabetically, by last name <a href="#fnref-FMm4ikcDkjYYfSWqb-1" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-2" class="footnote-item"><p> I italicize <em>liking</em> , <em>&quot;liking&quot;</em> , <em>wanting</em> , and <em>&quot;wanting&quot;</em> in order to emphasize that I&#39;m using these terms in a &quot;technical&quot; sense. &quot;Non-technical&quot; senses are non-italicized. In a few places of this section I also sometimes lump <em>liking</em> and <em>&quot;liking&quot;</em> into &quot;liking&quot; and <em>wanting</em> and <em>&quot;wanting&quot;</em> into &quot;wanting&quot;. <a href="#fnref-FMm4ikcDkjYYfSWqb-2" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-3" class="footnote-item"><p> Not necessarily exhaustively, there may be some (things we might want to consider as) values that don&#39;t fit neatly into any of these categories. <a href="#fnref-FMm4ikcDkjYYfSWqb-3" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-4" class="footnote-item"><p> The distinction between explicit and implicit is also sometimes used, but I find it unintuitive. <a href="#fnref-FMm4ikcDkjYYfSWqb-4" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-5" class="footnote-item"><p> By the way, the taboo against eating pork has a very interesting origin. See <a href="https://www.youtube.com/watch?v=pI0ZUhBvIx4">this video from Religion for Breakfast</a> . <a href="#fnref-FMm4ikcDkjYYfSWqb-5" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-6" class="footnote-item"><p> See also <a href="https://www.lesswrong.com/posts/wcNEXDHowiWkRxDNv/inner-alignment-in-salt-starved-rats">Steve Byrnes&#39;s post about that study</a> . <a href="#fnref-FMm4ikcDkjYYfSWqb-6" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-7" class="footnote-item"><p> The CS itself can become aversive or desired, even when the UCS it predicts appears in a different place than the CS. In such cases, the CS is said to become a &quot;motivational magnet&quot; (eg, Robinson &amp; Berridge, 2013). <a href="#fnref-FMm4ikcDkjYYfSWqb-7" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-8" class="footnote-item"><p> Explaining this phenomenon in terms of wanting to avoid unpleasant effects of the withdrawal syndrome doesn&#39;t fit the empirical data (Berridge &amp; Robinson, 2016). <a href="#fnref-FMm4ikcDkjYYfSWqb-8" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-9" class="footnote-item"><p> While here I am speaking about subclinical cases of behavioral addictions, I also expect this to be a factor in obsessive-compulsive disorder and related conditions. One reason I think so is that the neurotransmitter most consistently involved in OCD seems to be dopamine, which is strongly implicated in wanting (see Section 3). Moreover, the most successful pharmacological treatment for OCD is naltrexone, which is also used in many standard addictions and acts by regulating dopaminergic transmission from the VTA. <a href="#fnref-FMm4ikcDkjYYfSWqb-9" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-10" class="footnote-item"><p> Although it probably still requires making some assumptions about the agent&#39;s biases and cognitive limitations. See, eg, <a href="https://www.lesswrong.com/posts/h9DesGT3WT9u2k7Hr/the-easy-goal-inference-problem-is-still-hard">Christiano (2018)</a> . <a href="#fnref-FMm4ikcDkjYYfSWqb-10" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-11" class="footnote-item"><p> I&#39;m not going to discuss the topic of phenomenal consciousness and its relationship with verbal reports because I consider the former to be <a href="https://plato.stanford.edu/entries/qualia/#Illusional">illusory</a> . <a href="#fnref-FMm4ikcDkjYYfSWqb-11" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-12" class="footnote-item"><p> Food being obviously the easiest category of &quot;rewards&quot; to study. <a href="#fnref-FMm4ikcDkjYYfSWqb-12" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-13" class="footnote-item"><p> By &quot;conscious functioning&quot;, I mean something like &quot;the <a href="https://en.wikipedia.org/wiki/Global_workspace_theory">global workspace</a> &quot; being up and running. <a href="#fnref-FMm4ikcDkjYYfSWqb-13" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-14" class="footnote-item"><p> With the neocortex being the part of the brain we expect to be important for conscious awareness. <a href="#fnref-FMm4ikcDkjYYfSWqb-14" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-15" class="footnote-item"><p> From now on, I italicize <em>liking</em> , <em>&quot;liking&quot;</em> , <em>wanting</em> , and <em>&quot;wanting&quot;</em> , in order to emphasize that I&#39;m using these terms in their &quot;technical&quot; sense. &quot;Non-technical meanings&quot; of liking and liking are non-italicized. <a href="#fnref-FMm4ikcDkjYYfSWqb-15" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-16" class="footnote-item"><p> Berridge and Robinson (2003) also introduced a third distinction between two forms of learning: cognitive and associative, but it is not the focus of this post. <a href="#fnref-FMm4ikcDkjYYfSWqb-16" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-17" class="footnote-item"><p> I found no studies on that, but I have a very confident guess that <em>&quot;liking&quot;</em> would also occur in animals that are asleep or even in some kinds of palliative states, such as coma, perhaps even <a href="https://en.wikipedia.org/wiki/Locked-in_syndrome">locked-in syndrome</a> . <a href="#fnref-FMm4ikcDkjYYfSWqb-17" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-18" class="footnote-item"><p> Of course, the correspondence is not perfect and the boundaries between the daily meanings of &quot;to like&quot; and &quot;to want&quot; are blurry. Still, semantic distance from &quot;to like&quot; to <em>liking</em> is smaller than to <em>&quot;liking&quot;</em> . <a href="#fnref-FMm4ikcDkjYYfSWqb-18" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-19" class="footnote-item"><p> Importantly, &quot;the ongoing state of affairs&quot; can include things extended over a long timescale. <a href="#fnref-FMm4ikcDkjYYfSWqb-19" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-20" class="footnote-item"><p> At least none of the ones we know about, to the best of my knowledge. <a href="#fnref-FMm4ikcDkjYYfSWqb-20" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-21" class="footnote-item"><p> At the same time, some studies show that monkeys and rats with OFC damage, although they still respond to rewards, are impaired in using reward information to guide their behavior, relative to animals with intact OFC (Berridge &amp; Kringelbach, 2008), perhaps pointing to the role of conscious pleasure in reward-related learning. <a href="#fnref-FMm4ikcDkjYYfSWqb-21" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-22" class="footnote-item"><p> For a great introduction to GWT, see <a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/x4n4jcoDP7xh5LWLq">Kaj Sotala&#39;s review of <em>The Consciousness and the Brain</em> by Stanislas Dehaene</a> . <a href="#fnref-FMm4ikcDkjYYfSWqb-22" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-23" class="footnote-item"><p> Eg, when I realize that when I get back to exercising after a long break, I start feeling much better on a daily basis after a few weeks, which increases my motivation to exercise (although this is probably not a good example of <em>&quot;wanting&quot;</em> ). <a href="#fnref-FMm4ikcDkjYYfSWqb-23" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-24" class="footnote-item"><p> Perhaps I am slightly deviating from the definition of <em>&quot;wanting&quot;</em> as &quot;conditioned responses&quot;. This seems true though and in agreement with the idea (endorsed by Berridge) that the original adaptive of <em>&quot;wanting&quot;</em> was to drive the animal&#39;s behavior to satisfy some small set of needs. <a href="#fnref-FMm4ikcDkjYYfSWqb-24" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-25" class="footnote-item"><p> I take the mention of &quot;pleasant&quot; in (2) to refer both to <em>&quot;liking&quot;</em> and <em>liking</em> , with the latter being used in a broad sense, which includes (ia) reflective evaluation of the state of the world conditional on having achieved the <em>wanted</em> goal. I think this interpretation is justified because otherwise, the definition would exclude clear examples of <em>wanting</em> , such as a person doing hard work for which they are not going to receive any &quot;pleasant reward&quot;, unless we take a very broad meaning of &quot;pleasure&quot; (not mentioning more extreme cases like suicide bombers and kamikaze). <a href="#fnref-FMm4ikcDkjYYfSWqb-25" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-26" class="footnote-item"><p> Szczypka et al. (1999) write that &quot;young [DD] pups that had never been injected with l-DOPA would lick and swallow small drops of a liquid diet placed by their mouth. Apparently, these kinds of responses don&#39;t require dopamine, perhaps being a kind of <em>&quot;liking&quot;</em> reactions. <a href="#fnref-FMm4ikcDkjYYfSWqb-26" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-27" class="footnote-item"><p> See also Oliver Sacks&#39;s <em><a href="https://en.wikipedia.org/wiki/Awakenings_(book)">Awakenings</a></em> . <a href="#fnref-FMm4ikcDkjYYfSWqb-27" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-28" class="footnote-item"><p> Most <a href="https://en.wikipedia.org/wiki/Dopamine_antagonist">dopamine antagonists</a> work only on a particular subtype of dopamine receptors. <a href="#fnref-FMm4ikcDkjYYfSWqb-28" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-29" class="footnote-item"><p> Interestingly, in addition to increasing DA directly, amphetamine and cocaine-like psychostimulants also appear to increase DA via an indirect route (Peña et al., 2015). <a href="#fnref-FMm4ikcDkjYYfSWqb-29" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-30" class="footnote-item"><p> Alternatively, they might be <a href="https://en.wikipedia.org/wiki/Spandrel_(biology)">spandrels</a> . This probably isn&#39;t the case for <em>&quot;liking&quot;</em> , as spandrels typically (ever?) have distinct brain circuits. If <em>liking</em> is a natural consequence of <em>&quot;liking&quot;</em> plus global workspace/consciousness systems, then it would also probably not be a spandrel. <a href="#fnref-FMm4ikcDkjYYfSWqb-30" class="footnote-backref">↩︎</a></p></li><li id="fn-FMm4ikcDkjYYfSWqb-31" class="footnote-item"><p> Dickinson and Balleine&#39;s account of the function of reward is slightly different than the one I&#39;m presenting here. You can read it yourself if you&#39;re curious. <a href="#fnref-FMm4ikcDkjYYfSWqb-31" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/opJxxfrN33xQx3eXu/wanting-and-liking#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/opJxxfrN33xQx3eXu/wanting-and-liking<guid ispermalink="false"> opJxxfrN33xQx3eXu</guid><dc:creator><![CDATA[Mateusz Bagiński]]></dc:creator><pubDate> Wed, 30 Aug 2023 14:52:04 GMT</pubDate></item><item><title><![CDATA[Open Call for Research Assistants in Developmental Interpretability]]></title><description><![CDATA[Published on August 30, 2023 9:02 AM GMT<br/><br/><p> We are excited to announce multiple positions for Research Assistants to join our <a href="https://manifund.org/projects/scoping-developmental-interpretability-xg55b33wsfc"><u>six-month research project</u></a> assessing the viability of <a href="https://www.lesswrong.com/posts/TjaeCWvLZtEDAS5Ex/towards-developmental-interpretability"><u>Developmental Interpretability</u></a> (DevInterp).</p><p> This is a chance to gain expertise in interpretability, develop your skills as a researcher, build out a network of collaborators and mentors, publish in major conferences, and open a path towards future opportunities, including potential permanent roles, recommendations, and successive collaborations.</p><h2> <strong>Background</strong></h2><p> <a href="https://www.lesswrong.com/posts/TjaeCWvLZtEDAS5Ex/towards-developmental-interpretability"><u>Developmental interpretability</u></a> is a research agenda aiming to build tools for detecting, locating, and understanding phase transitions in learning dynamics of neural networks. It draws on techniques from singular learning theory, mechanistic interpretability, statistical physics, and developmental biology.</p><h2> <strong>Position Details</strong></h2><p> <strong>General info:</strong></p><ul><li> <strong>Title</strong> : Research Assistant / Research Engineer.</li><li> <strong>Location</strong> : Remote, with hubs in Melbourne and London.</li><li> <strong>Duration</strong> : Until March 2024 (at minimum).</li><li> <strong>Compensation</strong> : base salary is USD$35k per year, to be paid out as an independent contractor at an hourly rate.</li></ul><p> <strong>Timeline</strong> :</p><ul><li> <strong>Application Deadline</strong> : September 15th, 2023</li><li> <strong>Ideal Start Date</strong> : October 2023</li></ul><p> <strong>How to Apply</strong> : Complete the <a href="https://forms.gle/6hEpiqgN4oAHmypD6"><u>application form</u></a> by the deadline. Further information on the application process will be provided in the form.</p><h2> <strong>Who We Are</strong></h2><p> The developmental interpretability research team consists of experts across a number of areas of mathematics, physics, statistics and AI safety. The principal researchers:</p><ul><li> <a href="http://therisingsea.org/"><u>Daniel Murfet</u></a> , mathematician and SLT expert, University of Melbourne.</li><li> <a href="https://www.suswei.com/"><u>Susan Wei</u></a> , statistician and SLT expert, University of Melbourne.</li><li> <a href="https://www.jessehoogland.com/"><u>Jesse Hoogland</u></a> , MSc. Physics, SERI MATS scholar, RA in Krueger lab</li></ul><p> We have a range of projects currently underway, led by one of these principal researchers and involving a number of other PhD and MSc students from the University of Melbourne and collaborators from around the world. In an organizational capacity you would also interact with Alexander Oldenziel and Stan van Wingerden.</p><p> You can find us and the broader DevInterp research community on our <a href="https://discord.gg/pCf4UynKsc"><u>Discord</u></a> . Beyond the <a href="https://www.lesswrong.com/posts/TjaeCWvLZtEDAS5Ex/towards-developmental-interpretability"><u>Developmental Interpretability</u></a> research agenda, you can read our first preprint on <a href="https://arxiv.org/abs/2308.12108"><u>scalable SLT invariants</u></a> and check out the lectures from the <a href="https://www.youtube.com/@SLTSummit/videos"><u>SLT &amp; Alignment summit</u></a> .</p><h2> <strong>Overview of Projects</strong></h2><p> Here&#39;s the selection of <strong>&nbsp;</strong> the projects underway, some of which you would be expected to contribute to. These tend to be on the more <strong>experimental</strong> side:</p><ul><li> <strong>Developing scalable estimates for SLT invariants</strong> : Invariants like the (local) learning coefficient and (local) singular fluctuation can signal the presence of “hidden” phase transitions. Improving these techniques can help us better identify these transitions.</li><li> <strong>DevInterp of vision models</strong> : To what extent do the kinds of circuits studied in the <a href="https://distill.pub/2020/circuits/zoom-in/"><u>original circuits thread</u></a> emerge through phase transitions?</li><li> <strong>DevInterp of program synthesis</strong> : <strong>&nbsp;</strong> In examples where we know there is rich compositional structure, can we see it in the singularities? Practically, this means studying settings like modular arithmetic (grokking), multitask sparse parity, and more complex variants.</li><li> <strong>DevInterp of in-context learning</strong> <strong>&amp; induction heads</strong> : Is the development of induction heads a proper phase transition in the language of SLT? More ambitiously, can we apply singular learning theory to study in-context learning and make sense of “in-context phase transitions.”</li><li> <strong>DevInterp of language models</strong> : Can we detect phase transitions in simple language models (like <a href="https://arxiv.org/abs/2305.07759"><u>TinyStories</u></a> ). Can we, from these transitions, discover circuit structure? Can we extend these techniques to larger models (eg, in the <a href="https://github.com/EleutherAI/pythia"><u>Pythia suite</u></a> ).</li><li> <strong>DevInterp of reinforcement learning</strong> <strong>models</strong> : To what extent are phase transitions involved in the emergence of a world model (in examples like <a href="https://github.com/likenneth/othello_world/tree/master"><u>OthelloGPT</u></a> )?</li></ul><p> Next to these, we are working on a number of more <strong>theoretical</strong> projects. (Though our focus is on hiring for the more applied projects, if one of these particularly excites you, you should definitely apply!)</p><ul><li> <strong>Studying phase transitions in simple models like deep linear networks:</strong> These serve a valuable intermediate case between regular models and highly singular models. This is also a place to draw connections to a lot of existing literature on deep learning theory (on “saddle-to-saddle dynamics”).</li><li> <strong>Developing “geometry probes”</strong> : It&#39;s not enough to <i>detect</i> phase transitions, but we have to be able to <i>analyze</i> them for structural information. Here the aim is to develop “probes” that extract this kind of information from phase transitions.</li><li> <strong>Developing the “geometry of program synthesis”</strong> : We expect that understanding neural networks will require looking beyond models of computation like Turing machines, lambda calculus, and linear logic, towards <i>geometric</i> models of computation. This means pushing further in directions like those explored by Tom Waring in his <a href="http://therisingsea.org/notes/MSc-Waring.pdf"><u>MSc. thesis</u></a> .</li></ul><p> Taken together these projects complete the scoping phase of the DevInterp research agenda, ideally resulting in publications in venues like ICML and NeurIPS.</p><h2> <strong>What We Expect</strong></h2><p> You will be communicating with your research project teammates on the DevInterp <a href="https://discord.gg/pCf4UynKsc"><u>Discord</u></a> , writing code and training models, joining in weekly or biweekly research meetings over Zoom, and in general acting as a productive member of a fast-moving research team combining both theoreticians and experimentalists working together to define the future of the science of interpretability.</p><p> Depending on interest and background, you may also be reading and discussing papers from ML or mathematics and contributing to the writing of papers on Overleaf. It&#39;s not mandatory, but you would be invited to join in virtual research seminars like the <a href="https://metauni.org/slt/"><u>SLT seminar</u></a> at metauni or SLT reading group on the DevInterp Discord.</p><p> There will be a <a href="https://www.lesswrong.com/posts/QpFiEbqMdhaLBPb7X/apply-now-for-the-devinterp-2023-fall-summit"><u>DevInterp conference</u></a> in November 2023 in Oxford, United Kingdom, and it would be great if you could attend (we will pay for your travel). There will hopefully be a second opportunity to meet the team in person between November and the end of the employment period (possibly in Melbourne, Australia).</p><h2> <strong>FAQ</strong></h2><p> <strong>Who is this for?</strong></p><p> We&#39;re looking mainly for people who can do engineering work, that is, people with software development and ML skills. It&#39;s not necessary to have a background in interpretability or AI safety, although that&#39;s a plus. Ideally you have legible output / projects that demonstrate ability as an experimentalist.</p><p> <strong>What&#39;s the time commitment?</strong></p><p> We&#39;re looking mainly for people who can commit full-time, but if you&#39;re talented and only available part-time, don&#39;t shy away from applying.</p><p> <strong>What does the compensation mean?</strong></p><p> We&#39;ve budgeted USD$70k in total to be spread across 1-4 research assistants over the next half year. By default we&#39;re expecting to pay RAs USD$17.50/hour.</p><p> <strong>Do I need to be familiar with SLT and AI alignment?</strong></p><p> No (though it&#39;s obviously a plus).</p><p> We&#39;re leaning towards taking on skilled general purpose experimentalists (without any knowledge of SLT) over less experienced programmers who know some SLT. That said, if you are a talented theorist, don&#39;t shy away from applying.</p><p> <strong>What are you waiting for?</strong></p><p> <a href="https://forms.gle/6hEpiqgN4oAHmypD6"><u>Apply now</u></a> .</p><br/><br/> <a href="https://www.lesswrong.com/posts/DZHmEmzujfuqfxbJY/open-call-for-research-assistants-in-developmental#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/DZHmEmzujfuqfxbJY/open-call-for-research-assistants-in-developmental<guid ispermalink="false"> DZHmEmzujfuqfxbJY</guid><dc:creator><![CDATA[Jesse Hoogland]]></dc:creator><pubDate> Wed, 30 Aug 2023 09:02:59 GMT</pubDate> </item><item><title><![CDATA[LTFF and EAIF are unusually funding-constrained right now]]></title><description><![CDATA[Published on August 30, 2023 1:03 AM GMT<br/><br/><h1><strong>概括</strong></h1><p>EA Funds aims to empower thoughtful individuals and small groups to carry out altruistically impactful projects - in particular, enabling and accelerating small/medium-sized projects (with grants &lt;$300K). We are looking to increase our level of independence from other actors within the EA and longtermist funding landscape and are seeking to raise ~$2.7M for the Long-Term Future Fund and ~$1.7M for the EA Infrastructure Fund (~$4.4M total) over the next six months.</p><p> <strong>Why donate to EA Funds?</strong> EA Funds is the largest funder of small projects in the longtermist and EA infrastructure spaces, and has had a solid operational track record of giving out hundreds of high-quality grants a year to individuals and small projects. We believe that we&#39;re well-placed to fill the role of a significant independent grantmaker, because of a combination of our track record, our historical role in this position, and the quality of our fund managers.</p><p> <strong>Why now?</strong> We think now is an unusually good time to donate to us, as a) we have an unexpectedly large funding shortage, b) there are <a href="https://forum.effectivealtruism.org/posts/7RrjXQhGgAJiDLWYR/what-does-a-marginal-grant-at-ltff-look-like-funding"><u>great projects on the margin that we can&#39;t currently fund</u></a> , and c) more stabilized funding now can give us time to try to find large individual and institutional donors to cover future funding needs.</p><p> Importantly, Open Philanthropy is no longer providing a guaranteed amount of funding to us and <a href="https://forum.effectivealtruism.org/posts/zt6MsCCDStm74HFwo/ea-funds-organisational-update-open-philanthropy-matching"><u>instead will move over to a (temporary) model of matching our funds</u></a> 2:1 ($2 from them for every $1 from you, up to 3.5M from them per fund).</p><p> <strong>Where to donate:</strong> If you&#39;re interested, you can donate to either Long-Term Future Fund (LTFF) or EA Infrastructure Fund (EAIF) <a href="https://www.givingwhatwecan.org/funds/effective-altruism-funds?utm_source=eafunds"><u>here</u></a> . <a href="https://forum.effectivealtruism.org/posts/PAco5oG579k2qzrh9/ltff-and-eaif-are-unusually-funding-constrained-right-now#fnyd012yijab"><sup>[1]</sup></a></p><p> Some relevant quotes from fund managers:</p><p> <strong>Oliver Habryka</strong></p><p> I think the next $1.3M in donations to the LTFF (430k pre-matching) are among the best historical grant opportunities in the time that I have been active as a grantmaker. If you are undecided between donating to us right now vs. December, my sense is now is substantially better, since I expect more and larger funders to step in by then, while we have a substantial number of time-sensitive opportunities right now that will likely go unfunded.</p><p> I myself have a bunch of reservations about the LTFF and am unsure about its future trajectory, and so haven&#39;t been fundraising publicly, and I am honestly unsure about the value of more than ~$2M, but my sense is that we have a bunch of grants in the pipeline right now that are blocked on lack of funding that I can evaluate pretty directly, and that those seem like quite solid funding opportunities to me (some of this is caused by a large number of participants of the SERI MATS program applying for funding to continue the research they started during the program, and those applications are both highly time-sensitive and of higher-than-usual quality).</p><p> <strong>Lawrence Chan</strong></p><p> “My main takeaway from [evaluating a batch of AI safety applications on LTFF] is [LTFF] could sure use an extra $2-3m in funding, I want to fund like, 1/3-1/2 of the projects I looked at.” (At the current level of funding, we&#39;re on track to fund a much lower proportion).</p><h2> <strong>Related links</strong></h2><ul><li> <a href="https://forum.effectivealtruism.org/posts/zt6MsCCDStm74HFwo/ea-funds-organisational-update-open-philanthropy-matching"><u>EA Funds organizational update: Open Philanthropy matching and distancing</u></a></li><li> <a href="https://forum.effectivealtruism.org/posts/zZ2vq7YEckpunrQS4/long-term-future-fund-april-2023-grant-recommendations"><u>Long-Term Future Fund: April 2023 grant recommendations</u></a></li><li> <a href="https://forum.effectivealtruism.org/posts/7RrjXQhGgAJiDLWYR/what-does-a-marginal-grant-at-ltff-look-like-funding"><u>What Does a Marginal Grant at LTFF Look Like?</u></a></li><li> Asya Bergal&#39;s <a href="https://forum.effectivealtruism.org/posts/9vazTE4nTCEivYSC6/reflections-on-my-time-on-the-long-term-future-fund"><u>Reflections on my time on the Long-Term Future Fund</u></a></li><li> Linch Zhang&#39;s <a href="https://forum.effectivealtruism.org/posts/sWMwGNgpzPn7X9oSk/select-examples-of-adverse-selection-in-longtermist"><u>Select examples of adverse selection in longtermist grantmaking</u></a></li></ul><h2> <strong>Our Vision</strong></h2><p> We think there is a significant shortage of independent funders in the current longtermist and EA infrastructure landscape, resulting in fewer outstanding projects receiving funding than is good for the world. Currently, the primary source of funding for these projects is Open Philanthropy, and whilst we share a lot of common ground, we think we add value in the following ways:</p><ul><li> Increasing the total grantmaking capacity within key cause areas.</li><li> Causing great projects to counterfactually happen in the world, or saving time and effort for people doing great projects who would otherwise spend significant time fundraising or waiting for grants to come in.</li><li> Supporting a set of worldviews that we find plausible and that are not currently well represented among grantmakers (though we have substantial overlap with Open Philanthropy&#39;s worldview and there is a range of views on how much we should be directly optimizing for diversification away from their perspectives).</li><li> Emphasizing contact with reality: most of our grantmakers spend most of their time trying to directly solve problems of importance within their cause area, rather than engaging in “meta” activities like grantmaking. We think this is important as grantmaking often has very poor feedback loops (particulalry longtermist grantmaking).</li><li> Provide early stage funding to allow applicants to test their fit for work and “get ready” to seek funding from other funders that specialize in larger grant sizes.</li><li> Improving the epistemic environment within EA by making it easier for smaller projects to disagree with Open Philanthropy without worrying that this will significantly reduce their chance of being funded in the future.</li><li> Helping to identify harmful projects whilst being aware of factors such as the unilateralist curse and information cascades.</li><li> Increasing the resilience, robustness and diversity of funders within EA and longtermism.</li></ul><p> Alongside the above, EA Funds has ambitions to pursue new ways of generating value by:</p><ul><li> Creating an expert-led active grant-making program to create counterfactual impactful projects (starting with longtermist information security).</li><li> Modeling and shaping community norms of transparency, integrity, and criticism to improve the epistemic environment within EA and associated communities.</li></ul><h2> <strong>Our Ask</strong></h2><p> <strong>We are looking to raise ~$4.4M from the general public</strong> to support our work over the next 6 months:</p><ol><li> ~$2.7M for the Long-Term Future Fund.<ol><li> This is ~2M above our expected 720k donations in the next 6 months.</li></ol></li><li> ~$1.7m for the EA Infrastructure Fund.<ol><li> This is ~1.3M above our expected 400k donations in the next 6 months.</li></ol></li></ol><p> This will be matched by Open Phil at a 2:1 rate ($2 from Open Phil per $1 donated to a fund) with a ceiling of a $3.5m contribution from Open Phil (per fund). You can read more about the matching <a href="https://forum.effectivealtruism.org/posts/zt6MsCCDStm74HFwo/ea-funds-organisational-update-open-philanthropy-matching"><u>here</u></a> .</p><p> The EAIF and LTFF have received very generous donations from many individuals in the EA community. However, donations to the EAIF and LTFF have recently been quite low, especially relative to the quality and quantity of applications we&#39;ve had in the last year. While much of this is likely due to the FTX crash and subsequently increased funding gaps of other longtermist organizations, our guess is that this is partially due to tech stocks and crypto doing poorly in the last year (though we hope that recent market trends will bring back some donors).</p><h3> <strong>Calculation for LTFF funding gap</strong></h3><p> The LTFF has an estimated ideal dispersal rate of $1M/month, based on our <a href="https://forum.effectivealtruism.org/posts/7RrjXQhGgAJiDLWYR/what-does-a-marginal-grant-at-ltff-look-like-funding#_5M"><u>post-November 2022 funding bar</u></a> that Asya estimated <a href="https://forum.effectivealtruism.org/posts/PAco5oG579k2qzrh9/ltff-and-eaif-are-unusually-funding-constrained-right-now#fn9u90kjafzyb"><sup>[2]</sup></a> from looking at the funding gaps and marginal resources within the longtermist ecosystem overall. This is $6M over the next 6 months.</p><p> I also think LTFF donors should pay $200k over the next 6 months ($400k annualized) as their “fair share” of EA Funds operational costs. So in total, LTFF would like to spend $6.2M over the next 6 months.</p><p> Caleb <a href="https://forum.effectivealtruism.org/posts/zt6MsCCDStm74HFwo/ea-funds-organisational-update-open-philanthropy-matching#LTFF_funding_gap"><u>estimated</u></a> ~$700k in expected donations from individuals by default in the next 6 months, based solely on extrapolation from past trends. With Open Phil donation matching, this comes out to a total of $2.1M in expected incoming funds, or a shortfall of $4.1M.</p><p> To cover the remaining $4.1M, we would like individual donors to contribute an additional $2M, where Open Phil will provide $2.1M of matching for the first $1.05M.</p><p> To get a sense of what projects your marginal dollars can buy, you might find it helpful to look at the <a href="https://forum.effectivealtruism.org/posts/7RrjXQhGgAJiDLWYR/what-does-a-marginal-grant-at-ltff-look-like-funding#_5M"><u>$5M tier of the LTFF Funding Thresholds Post</u></a> .</p><h3> <strong>Calculation for EAIF funding gap</strong></h3><p> The EAIF has an estimated ideal dispersal rate of $800k/month, based on the proportion of our historic spend rate that we believe is above Open Phil&#39;s bar for EA community building projects (though note that this was based on fairly brief input from Open Phil and I didn&#39;t check with them about whether they agree with this claim). This is $4.8M over the next 6 months.</p><p> I also think EAIF donors should pay $200k over the next 6 months ($400k annualized) as their “fair share” of EA Funds operational costs. So in total, EAIF would like to spend $5M over the next 6 months.</p><p> Caleb estimated $400k in expected donations from individuals by default in the next 6 months, based solely on extrapolation from past trends. With Open Phil donation matching, this comes out to a total of $1.2M in expected incoming funds, or a shortfall of $3.8M.</p><p> To cover the remaining $3.8M, we would like individual donors to contribute an additional $1.3M, where Open Phil will provide 2.5M in donation matching.</p><h3> <strong>Potential change for operational expenses payment</strong></h3><p> <strong>Going forwards, we would also like to move towards a model where donors directly pay for our operational expenses</strong> (currently we fundraise for operational expenses separately, so 100% of donations from public donors goes to our grantees). We believe that the newer model is more transparent, as it lets all donors more clearly see the true costs and cost-benefit ratio for their donations <strong>. However, making the change is still pending internal discussions, community feedback, and logistical details.</strong> We will make a separate announcement if and when we switch to a model where a percentage of public donations go to cover our operational expenses. See Appendix A for a calculation of operational expenses.</p><h2> <strong>Why give to EA Funds?</strong></h2><p> We think EA Funds is well-positioned to be a significant independent grantmaker for the following reasons.</p><ol><li> We <a href="https://funds.effectivealtruism.org/team"><strong><u>have knowledgeable part-time fund managers</u></strong></a> <strong>who do direct work in their day jobs:</strong> we have built several grantmaking teams with a broad range of expertise. These managers usually dedicate the majority of their time to hands-on efforts addressing critical issues. We believe this direct experience enhances their judgment as grantmakers, enabling them to pinpoint important and critical projects with high accuracy.</li><li> <strong>Specialization in early-stage grants:</strong> we made over 300 grants of under $300k in 2022. To our knowledge, that&#39;s more grants of this size than any other EA-associated funder.</li><li> <strong>We are the largest open application funding source</strong> (that we are aware of) within our cause areas. Our application form is always open, anyone can apply, and grantees can apply for a wide variety of projects relevant to our funds&#39; purposes (as opposed to eg needing to cater to narrow requests for proposals). We believe this is critical to us having access to grant opportunities that other funders do not have access to, allowing us to rely on formal channels rather than informal networks.</li><li> <strong>Our operational track record</strong> . In 2022, EA Funds paid out ~$35M across its four Funds, with $12M to the Long-Term Future Fund, $13M to the EA Infrastructure Fund, $6.4M to the Animal Welfare Fund, and $4.8M to the Global Health and Development Fund. This requires (among others) clearing nontrivial logistical hurdles in following nonprofit law across multiple countries, consistent operational capacity, and a careful eye towards <a href="https://forum.effectivealtruism.org/posts/sWMwGNgpzPn7X9oSk/select-examples-of-adverse-selection-in-longtermist"><u>downside risk mitigation</u></a> .</li><li> <strong>We believe our grant are highly cost-effective.</strong> Our current best guess is that we have successfully identified and given out grants of similar ex-ante quality to (eg) Open Phil&#39;s AI safety and community building grants, some of which Open Phil would counterfactually not have funded. <a href="https://forum.effectivealtruism.org/posts/PAco5oG579k2qzrh9/ltff-and-eaif-are-unusually-funding-constrained-right-now#fnsxw2bil6v9"><sup>[3]</sup></a> This gives donors an opportunity to provide considerable value.</li><li> We are investigating <strong>new value streams</strong> . We would like to pursue &#39;DARPA-style&#39; active grantmaking in priority areas (starting with information security). We are also actively considering setting up an AI Safety-specific fund, enocuraging donors interested in AI safety (but not EA or longtermism) to donate to projects that mitigate large-scale globally catastrophic AI risks.</li><li> According to GWWC, the LTFF is the <strong>main longtermist donation option</strong> available for individual donors to support. We believe that we are a relatively transparent funder, and we are currently thinking about how we can increase our transparency further whilst moving more quickly and maintaining our current standard of decision-making.</li></ol><p> We are primarily looking for funding to support the Long-Term Future Fund and the EA Infrastructure Fund&#39;s grantmaking.</p><p> The Long-Term Future Fund is primarily focused on reducing catastrophic risks from advanced artificial intelligence and biotechnology, as well as building and equipping a community of people focused on safeguarding humanity&#39;s future potential. The EA Infrastructure Fund is focused on increasing the impact of projects that use the principles of effective altruism, in particular amplifying the efforts of people who aim to do an ambitious amount of good from an impartial welfarist and scope-sensitive perspective. We have included some examples of grants each fund has made in the <a href="https://docs.google.com/document/d/1-fKZJfgybYMjfUZc2_G-WwTbkQqFBeDEtbrRW4Th_k8/edit#heading=h.6pad9vbogqm7"><u>highlighted grants</u></a> section.</p><h2> <strong>Our Fund Managers</strong></h2><p> We lean heavily on the experience and judgement of our fund managers. We have around five fund managers on each fund at any given time. <a href="https://forum.effectivealtruism.org/posts/PAco5oG579k2qzrh9/ltff-and-eaif-are-unusually-funding-constrained-right-now#fnhamlm91a3z"><sup>[4]</sup></a> Our current fund managers include:</p><ul><li> <strong>Linchuan Zhang (LTFF):</strong> Linchuan (Linch) Zhang is a Senior Researcher at Rethink Priorities working on existential security research. Before joining RP, he worked on time-sensitive forecasting projects around COVID-19. Previously, he programmed for Impossible Foods and Google and has led several EA local groups.</li><li> <strong>Oliver Habryka (LTFF)</strong> : Oliver runs Lightcone Infrastructure, whose main product is Lesswrong. Lesswrong has significantly influenced conversations around rationality and AGI risk, and the LWits community is often credited with having realized the importance of topics such as AGI (and AGI risk), COVID-19, existential risk and crypto much earlier than other comparable communities.</li><li> <strong>Peter Wildeford (EAIF):</strong> co-executive director and co-founder of <a href="https://rethinkpriorities.org/"><u>Rethink Priorities</u></a> , a think tank dedicated to figuring out the best ways to make the world a better place.</li></ul><h3> <strong>Guest Fund Managers</strong></h3><p> <strong>Daniel Eth (LTFF):</strong> Daniel&#39;s research has spanned several areas relevant to longtermism, and he&#39;s currently focused primarily on AI governance. He was previously a Senior Research Scholar at the Future of Humanity Institute. He is currently self-employed.</p><p> <strong>Lauro Langosco (LTFF):</strong> Lauro is a PhD student with David Krueger at the University of Cambridge. His work focused broadly on AI Safety, in particular on demonstrations of alignment failures, forecasting AI capabilities, and scalable AI oversight.</p><p> <strong>Lawrence Chan (LTFF):</strong> Lawrence is a researcher at <a href="https://evals.alignment.org/">ARC Evals</a> , working on safety standards for AI companies. Before joining ARC Evals, he worked at <a href="https://www.redwoodresearch.org/">Redwood Research</a> and as a PhD Student at the <a href="https://humancompatible.ai/">Center for Human Compatible AI</a> at UC Berkeley.</p><p> <strong>Thomas Larsen (LTFF):</strong> Thomas was an alignment research contractor at MIRI, and he is currently running the Center for AI Policy, where he works on AI governance research and advocacy.</p><p> <strong>Clara Collier (LTFF)</strong> : Clara is the managing editor of Asterisk, a quarterly journal focused on communicating insights on important issues. Before, she worked as an independent researcher on existential risks. She has a Masters in Modern Languages from Oxford.</p><p> <strong>Michael Aird (EAIF)</strong> : <strong>&nbsp;</strong> Michael Aird is a Senior Research Manager in Rethink Priorities&#39; AI Governance and Strategy team. He also serves as an advisor to organizations such as Training for Good and is an affiliate of the Centre for the Governance of AI. His prior work includes positions at the Center on Long-Term Risk and the Future of Humanity Institute.</p><p> <strong>Huw Thomas (EAIF):</strong> Huw is currently working part-time on various projects (including a contractor role at 80,000 hours). Prior to this, he worked as a media associate at Longview Philanthropy, a groups associate at the Centre for Effective Altruism and was a recipient of the CEA Community Building Grant for his work at Effective Altruism Oxford.</p><p> <i>You can find a full list of our fund managers</i> <a href="https://funds.effectivealtruism.org/team"><i>here</i></a> <a href="https://forum.effectivealtruism.org/posts/PAco5oG579k2qzrh9/ltff-and-eaif-are-unusually-funding-constrained-right-now#fn3iuaaj786kj"><sup>[5]</sup></a></p><p> If you have more questions, feel free to leave a comment here. Caleb Parikh and the fund managers are also happy to talk to donors potentially willing to give >;$30k. Linch Zhang, in particular, has volunteered himself to talk about the LTFF.</p><h2> <strong>Highlighted Grants</strong></h2><p> EA Funds has identified a variety of high-impact projects, at least some of which we think are unlikely to have been funded elsewhere. (However, for any specific grant listed below, we think there&#39;s a fairly high probability they&#39;d otherwise be funded in some form or another; figuring out counterfactuals is often hard).</p><p> <strong>From the Long-Term Future Fund:</strong></p><ul><li> David Krueger - $200,000<ul><li> Computing resources and researcher stipends at a new deep learning + AI alignment research group at the University of Cambridge.</li></ul></li><li> Alignment Research Center - $72,000<ul><li> A research &amp; networking retreat for winners of the Eliciting Latent Knowledge contest with the aim of fostering promising research collaborations between junior researchers.</li></ul></li><li> SERI MATS program - $316,000<ul><li> 8-week scholars program to pair promising alignment researchers with renowned mentors. This program has now grown into a <a href="https://www.serimats.org/mentors"><u>more established program</u></a> producing multiple people working full-time on alignment in established research organizations (with a smaller number of people pursuing independent research or starting new organizations).</li></ul></li><li> Manifold Markets - $200,000<ul><li> Stipend and expenses for 4 months for 3 FTE to build a forecasting platform made available to the public based on user-created play-money prediction markets</li></ul></li><li> Daniel Filan - $23,544<ul><li> We recommended a grant of $23,544 to pay Daniel Filan for his time making 12 additional episodes of the AI X-risk Research Podcast (AXRP), as well as the costs of hosting, editing, and transcription.</li></ul></li></ul><p> <strong>From the EA Infrastructure Fund:</strong></p><ul><li> Shauna Kravec &amp; Nova DasSarma - $50,000:<ul><li> Compute infrastructure and dedicated support for AI safety researchers to run technical AI experiments. This later became <a href="http://hofvarpnir/"><u>Hofvarpnir Studios</u></a> which used to provide compute for Jacob Steinhardt&#39;s lab at UC Berkeley and the Center for Human-Compatible Artificial Intelligence (CHAI).</li></ul></li><li> Finlay Moorhouse and Luca Righetti - $38,200<ul><li> Ongoing support for <a href="https://hearthisidea.com/"><u>&quot;Hear This Idea</u></a> &quot;, a podcast showcasing new thinking in effective altruism.</li></ul></li><li> Laura Gonzalez Salmerón, Sandra Malagón - $43,308<ul><li> 12-month stipend to coordinate and grow the EA Spanish speakers community and its projects.</li></ul></li><li> Czech Association for Effective Altruism - $ 8,300<ul><li> Expenses and stipend to create a short Czech book (~130 pgs) and brochure (~20 pgs) with a good introduction to EA in digital and print formats.</li></ul></li></ul><p> <i>See a complete list of our public grants at</i> <a href="https://funds.effectivealtruism.org/grants"><i><u>this</u></i></a> <i>link. You can also read the most recent payout report by LTFF</i> <a href="https://forum.effectivealtruism.org/posts/zZ2vq7YEckpunrQS4/long-term-future-fund-april-2023-grant-recommendations"><i><u>here</u></i></a> <i>.</i></p><h2> <strong>Planned actions over the next six months</strong></h2><p> To achieve our goals of empowering thoughtful people to pursue impactful projects, we&#39;ll attempt to do the following:</p><ul><li> Asya Bergal <a href="https://forum.effectivealtruism.org/posts/zt6MsCCDStm74HFwo/ea-funds-organisational-update-open-philanthropy-matching"><u>will step down</u></a> as chair of LTFF (Max Daniel has already stepped down as chair of the EAIF). Max and Asya both work for Open Phil, and we want to increase our separation from Open Phil. <a href="https://forum.effectivealtruism.org/posts/PAco5oG579k2qzrh9/ltff-and-eaif-are-unusually-funding-constrained-right-now#fnpwyc17wm0ag"><sup>[6]</sup></a><ul><li> Open Phil also wanted to reduce entanglements between the two organizations, in part to mitigate downside reputational risks.</li></ul></li><li> We are looking to find new fund chairs for both LTFF and EAIF.</li><li> We plan to onboard more fund managers to grow each fund substantially (aiming to double the staffing of each fund).<ul><li> In recent months, LTFF has onboarded Lauro Langosco and Lawrence Chan who will primarily focus on technical alignment grantmaking, as well as Clara Collier for her expertise in communications and general longtermism. The EAIF is in the process of onboarding new fund managers.</li></ul></li><li> Open Phil <a href="https://forum.effectivealtruism.org/posts/zt6MsCCDStm74HFwo/ea-funds-organisational-update-open-philanthropy-matching"><u>has agreed</u></a> to give us a 2:1 match for up to $7M total (up to $3.5M to each of EAIF and LTFF) for a 6-month period. While our ultimate goal is to develop our own robust funding base, in 2022, Open Philanthropy provided 40% of the funding for the Long-Term Future Fund and 84% for the EA Infrastructure Fund. <a href="https://forum.effectivealtruism.org/posts/PAco5oG579k2qzrh9/ltff-and-eaif-are-unusually-funding-constrained-right-now#fnizbbefz7rym"><sup>[7]</sup></a> We see donation matching as a realistic intermediary step while enabling us to pursue more intellectual independence.<ul><li> This model replaces fixed grants from Open Philanthropy. This reduces the likelihood of your donations being fungible: previously an extra $1 to EA Funds in fundraising could result in a $1 reduction in Open Philanthropy&#39;s grants to us, diverting those funds to their other projects. This newer approach allows funders to donate to EA Funds and support the specific value proposition that we, as opposed to Open Philanthropy, present. <a href="https://forum.effectivealtruism.org/posts/PAco5oG579k2qzrh9/ltff-and-eaif-are-unusually-funding-constrained-right-now#fnwqj0clhbbi9"><sup>[8]</sup></a></li></ul></li><li> We are considering hiring or contracting out more non-grantmaking duties (eg website, project management, fundraising, communications) at EA Funds. Right now Caleb is the only full-time employee of EA Funds and plausibly having 0.5-1.5 more FTEs at EA Funds will help both existing projects go more smoothly, as well as unlock new ambitious opportunities.</li><li> We are working with external investigators to do retroactive evaluations of past EAIF and LTFF grants, with the hopes that we can then have a clearer picture of a) how well the impact of our past grants compares to eg, Open Phil&#39;s, b) which of our broader categories of historical grants have been the most impactful, and c) other qualitative insights to help us improve further.</li><li> We aim to improve the operations of our passive grantmaking (funding of open grant applications) program with a focus on improving the grantee experience by providing more support to grantees and getting back to grantees much more quickly <a href="https://forum.effectivealtruism.org/posts/PAco5oG579k2qzrh9/ltff-and-eaif-are-unusually-funding-constrained-right-now#fn25bgwshzbdx"><sup>[9]</sup></a></li><li> We are trying to reconceptualize and reframe the value proposition and strategic direction of EAIF in the coming months. While much of this will be contingent on the vision of the incoming fund chair, we&#39;d like EAIF to have a more coherent and targeted vision, strategy, and coherent value proposition to donors going forwards.</li><li> We plan to create a new AI Safety specific program, for donors outside of EA/Longtermism who want to decrease catastrophic risks from AI. We hope that such a program can inspire new donors to give to AI safety projects.</li><li> EA Funds is pursuing active grant-making programs, where we&#39;ll actively seek out promising projects to fund. We&#39;ll initially focus on <a href="https://80000hours.org/career-reviews/information-security/"><u>Information Security</u></a> field building. The current plan is for this program to initially be funded by Open Philanthropy, though if you are interested in contributing to this program in particular, please let us know.</li></ul><h2> <strong>Potential negatives to be aware of</strong></h2><p> Here are some reasons you might <i>not</i> want to donate to EA Funds:</p><h3> <strong>Potential downside risks of LTFF or EAIF</strong></h3><ul><li> <strong>Inability to fully screen for or prevent unilateral downside risks:</strong> EA Funds has much less control over and offers less guidance to our grantees than, eg, the executive directors of a moderately-sized EA organization. So compared to larger organizations, we may be less able to prevent unilateral downside risks like the <i>sharing of information hazards</i> , or <i>&nbsp;</i> actions that pose <i>reputational risks</i> to effective altruism at large, or to specific EA subfields.</li><li> <strong>Centralization of funds:</strong> In contrast, we are also implicitly asking for the centralization of funds from private donors to a single grantmaking entity. To the extent that you believe your counterfactual for donating to EA Funds is better and/or more centralization is bad, you may wish to donate directly rather than pool your funds with other LTFF or EAIF donors.</li><li> <strong>Waste/Inefficient usage of human capital:</strong> Giving money to EA Funds rather than larger organizations implicitly subsidizes a culture and community of grantseekers who are supported by small grants. To the extent that you believe this is a less efficient usage of human capital than plausible counterfactuals for talented people (eg getting a job in tech, policy, or academia), you might want to shift away from EA grantmakers that give relatively small individual grants.</li></ul><p> Note that we consider these issues to be structural and do not realistically expect resolutions to these downside risks going forwards.</p><h3> <strong>Areas of improvement for the LTFF and EAIF</strong></h3><p> Historically, we&#39;ve had the following (hopefully fixable) problems:</p><ul><li> <strong>Slower than ideal response times</strong> : in the past year, our median response time has been around 4 weeks with high variance; we&#39;d like to get this down to closer to 2 weeks with 95% of applications responded to in 4 four weeks.</li><li> <strong>Limited feedback/advice given to grantees</strong> : we generally don&#39;t give feedback to rejected applicants. We currently give <i>some</i> feedback to promising grantees but much less than we&#39;d give if we had more grantmaking capacity.</li><li> <strong>Insufficient active grantmaking</strong> : We spend some time trying to improve our grantees&#39; projects, but we have invested fairly little in active grantmaking (actively identifying promising projects and creating/supporting them).</li><li> <strong>Missing areas of subject matter expertise</strong> : The scopes of both funds are quite expansive. This means sometimes all of the existing grantmakers lack sufficient direct technical subject matter expertise to evaluate grants in certain areas, and thus have to rely on external experts. For example, the LTFF does not currently have a technical expert in biosecurity.</li></ul><p> For more, you can read Asya&#39;s <a href="https://forum.effectivealtruism.org/posts/9vazTE4nTCEivYSC6/reflections-on-my-time-on-the-long-term-future-fund"><u>reflections on her time as chair of LTFF</u></a> .</p><h2> <strong>EAIF vs LTFF</strong></h2><p> Some donors are interested in giving to both the EAIF and LTFF and would like advice on which fund is a better fit for them.</p><p> We think that the EAIF is a better fit for donors who:</p><ul><li> Are interested in supporting a portfolio of meta projects covering a range of plausible worldviews (both longtermist and non-longtermist).</li><li> Are interested in building EA and adjacent communities.</li><li> Believe that EA (and EA community building) has historically been very good for the world.</li><li> Believe in multiplier effect arguments (donating $100 to an EA group could plausibly create far more than $100 in donation to high-impact charities by encouraging more people to donate).</li><li> Expect the EAIF and LTFF to have similar diminishing marginal returns curves and want to donate to the fund with lower funding. (EAIF and LTFF each receive about 1000 grant applications per year, but EAIF has less funding currently committed)</li></ul><p> We think that the LTFF is a better fit for donors who are:</p><ul><li> More compelled by longtermist cause areas than other EA cause areas.</li><li> Particularly interested in AI safety.</li><li> Are more interested in direct work than &quot;meta&quot; work that have a longer chain of impact/reasoning.</li><li> Are more excited about the <a href="https://forum.effectivealtruism.org/posts/7RrjXQhGgAJiDLWYR/what-does-a-marginal-grant-at-ltff-look-like-funding#_5M"><u>$5M tier of marginal LTFF grants</u></a> than what they consider to be the marginal EAIF grant.</li></ul><h2> <strong>Closing thoughts</strong></h2><p> This post was written by Caleb Parikh and Linch Zhang. Feel free to ask questions or give us feedback in the comments below.</p><p> If you are interested in donating to either LTFF or EAIF, you can do so <a href="https://www.givingwhatwecan.org/funds/effective-altruism-funds?utm_source=eafunds"><u>here</u></a> .</p><h2> <strong>Appendix A: Operational expenses calculations and transparency.</strong></h2><p> In the last year, EA Funds has dispersed $35M and spent ~700k in operational expenses. The vast majority of the operational expenses were spent on LTFF and EAIF, as the global health and development fund and animal welfare fund are operationally much simpler.</p><p> Historically, ~60-80% of the operational expenses are paid to <a href="https://ev.org/ops/about/"><u>EV Ops</u></a> , for grant disbursement, tech, legal, other ops, etc.</p><p> The remaining 20-40% is used for:</p><ul><li> Caleb&#39;s salary, who leads EA Funds (~$100k/year plus benefits).</li><li> Payments for grantmakers at $60/hour, though many volunteer for free.</li><li> Contractors who work on different projects, earning between $35-$100/hour.</li></ul><p> I (Linch) ballparked the expected annual expenditures going forwards (assuming no cutbacks) to be ~800k annually. I estimated the increase due to a) inflation and b) us wanting to take on more projects, with some savings from us slowing down the rate of dispersals a little. But this estimate is not exact.</p><p> Since LTFF and EAIF incur the highest expenses, I suggest donors to each should contribute around $400k yearly, or $200k every six months.</p><p> As for where we might cut or increase spending:</p><ul><li> Reducing EV Ops costs would be challenging and may require moving EA Funds out of EV and building our own grant ops team.</li><li> Reducing Caleb&#39;s working hours would be challenging.</li></ul><p> I think my own hours at EAF are somewhat contingent on operational funding. In the last month, I&#39;ve been spending more than half of my working hours on EA Funds (EA Funds is buying out my time at RP), mostly helping Caleb with communications and strategic direction. I will like to continue doing this until I believe EA Funds is in a good state (or we decide to discontinue or sunset projects I&#39;m involved in). Obviously whether there is enough budget to pay for my time is a crux for whether I should continue here.</p><p> Assuming we can pay for my time, other plausible uses of marginal operational funding include: a) whether we pay external investigators for extensive or just shallow retroactive evaluations, b) whether we attempt to launch new programs, c) whether the new infosec, AI safety project, etc websites have professional designers, etc. My personal view is that marginal spending on EA Funds expenses is quite impactful relative to other possible donations, but I understand if donors do not feel the same way and will prefer a higher percentage of donations go directly to our grantees (currently it&#39;s 100% but proposed changes may move this to ~ 94-97%).</p><br/><br/> <a href="https://www.lesswrong.com/posts/gRfy2Q2Pg25a2cHyY/ltff-and-eaif-are-unusually-funding-constrained-right-now#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/gRfy2Q2Pg25a2cHyY/ltff-and-eaif-are-unusually-funding-constrained-right-now<guid ispermalink="false"> gRfy2Q2Pg25a2cHyY</guid><dc:creator><![CDATA[Linch]]></dc:creator><pubDate> Wed, 30 Aug 2023 01:03:30 GMT</pubDate> </item><item><title><![CDATA[Paper Walkthrough: Automated Circuit Discovery with Arthur Conmy]]></title><description><![CDATA[Published on August 29, 2023 10:07 PM GMT<br/><br/><p> Arthur Conmy&#39;s <a href="https://arxiv.org/pdf/2304.14997.pdf">Automated Circuit Discovery</a> is a great paper that makes initial forays into automating parts of mechanistic interpretability (specifically, automatically finding a sparse subgraph for a circuit). In this three part series of Youtube videos, I interview him about the paper, and we walk through it and discuss the key results and takeaways. We discuss the high-level point of the paper and what researchers should takeaway from it, the ACDC algorithm and its key nuances, existing baselines and how they adapted them to be relevant to circuit discovery, how well the algorithm works, and how you can even evaluate how well an interpretability method works.</p><br/><br/> <a href="https://www.lesswrong.com/posts/FzqKXpTDaouMF6Chj/paper-walkthrough-automated-circuit-discovery-with-arthur#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/FzqKXpTDaouMF6Chj/paper-walkthrough-automated-circuit-discovery-with-arthur<guid ispermalink="false"> FzqKXpTDaouMF6Chj</guid><dc:creator><![CDATA[Neel Nanda]]></dc:creator><pubDate> Tue, 29 Aug 2023 22:07:06 GMT</pubDate> </item><item><title><![CDATA[An OV-Coherent Toy Model of Attention Head Superposition]]></title><description><![CDATA[Published on August 29, 2023 7:44 PM GMT<br/><br/><p> <strong>Background</strong></p><p> This project was inspired by Anthropic&#39;s <a href="https://transformer-circuits.pub/2023/may-update/index.html"><u>post</u></a> on attention head superposition, which constructed a toy model trained to learn a circuit to identify skip-trigrams that are OV-incoherent (attending from multiple destination tokens to a single source token) as a way to ensure that superposition would occur. Since the OV circuit only sees half of the information – the source tokens – the OV circuit of a single head cannot distinguish between multiple possible skip-trigrams. As long as there are more skip-trigrams with the same source-token to represent than heads, the model cannot represent them in the naive way, and may resort to superposition.<br></p><p> In a more recent update <a href="https://transformer-circuits.pub/2023/july-update/index.html"><u>post</u></a> , they found that the underlying algorithm for OV-incoherent skip-trigrams in a simpler 2-head model implemented a conditional on the source token. One head predicts the output for the skip trigram [current token] … [current token] ->; [ground truth([0]...[current token])], one of which will yield the right answer. The second head destructively interferes with this result by writing out the negative logit contribution of the first head if the source token is not the one common to all skip-trigrams (in this case, [0]). Because their example cleanly separated tasks between the two attention heads, the authors argued that it was more like the building of high-level features out of low-level ones than a feature superimposed across multiple attention heads.</p><p></p><p> <strong>OV-coherent Superposition</strong></p><p> Instead, we claim there is an analogous force pushing the model toward adopting a distributed representation/head superposition whenever the model must learn patterns that require implementing nonlinear functions of <i>multiple</i> source tokens given a fixed destination token. We call this “OV-coherent” superposition: despite of the information at the destination position being fixed, the information copied from an attended-to token depends on the information at source tokens to which it is not attending. This pushes the model to form interference patterns between heads attending to different tokens.</p><p> To test this, we implemented a 1-layer, attention-only toy model with one-hot (un)embeddings trained to solve a problem requiring attention to multiple source tokens, described below. Here, we focus on a 2-head model which solves the task with perfect accuracy, and lay out some interesting motifs for further investigation.</p><p></p><p> <i>Key Takeaways</i> :</p><p> Heads in our model seem to implement nested conditional statements that exploit the if-else nature of the QK circuits. This means they can learn to write more specific information conditional on attending to certain tokens, given that it can implicitly rule out the existence of other tokens elsewhere in the context. The heads furthermore implement these nested conditionals in such a way that they distribute important source tokens between them, and constructively interfere to produce the correct answer.</p><p> Most of the time, we found that this “conditional dependence” relies on heads implementing an “all or nothing” approach to attention. Heads do not generally* spread their attention across multiple interesting tokens, but instead move through the hierarchy of features in their QK circuits and attend to the most “interesting” (still a poorly defined term!) one present. This seems to be a common property of attention patterns in real-model heads as well.</p><p> When there are multiple important source tokens to attend to in the context, heads implementing interference schema will tend to learn QK circuits such that they distribute tokens amongst themselves and don&#39;t leave crucial information unattended to. In 2-head models, this manifests are reversed “preference orderings” over source tokens, but potentially more complicated arrangements work in larger models.</p><p></p><p> <i>Problem Details:</i></p><p> The inputs are sequences of integers in the range [0, 11]. They can be broken down into two categories:</p><ul><li> <strong>Noise:</strong> There is no pattern for the model to learn. The context and completion are drawn independently and uniformly from [5, 11].</li><li> <strong>Signal:</strong> The final token in the input is 0. Furthermore, exactly two tokens in the context are in the range [1, 4]. The correct completion is given by an arbitrary injection from (unordered) pairs of these “interesting” tokens to completions. For example, any sequence containing 1 and 4 should be followed with a 3 if the current token is 0  (“1….4 0” ->; “3”). Note these numbers are independently drawn, allowing for repetitions ( “3….3 0” ->; “7”).</li></ul><p><br> <strong>Example Model Solution: (d_head = 5, n_heads = 2, d_model = 11, no LayerNorm)</strong></p><p> <i>QK-circuit Behavior:</i></p><p> Both heads learn a strict “preference ordering” over signal tokens, with the ordering generally reversed between the two heads. This guarantees that, for any given context, both signal tokens are fully attended to. In the example below, H0 attended solely to “2” if it&#39;s in the context, else “3”, “4”, and finally “1”. H1 instead has the preference ordering “1” else “4”, “3”, and then “2”. <br></p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KicP8fBdHNjZBXxRB/q9vz4tsfeuiwdh1b0ih9"></p><p> <i>Attention scores from “0” to each signal token for each head</i></p><p><br> While this “flipped hierarchy” scheme is overwhelmingly more common, the model sometimes learned a “split attention” scheme during training, in which the heads would attend to the same tokens to varying degree. Notably, we only saw split attention for d_head &lt; 3, indicating that this may be a bottleneck issue. However, we should acknowledge that the model may have other ways of solving this simple task than the one outlined above, and indicate that this was by no means an exhaustive analysis.*</p><p><br> <i>OV-circuit Behaviour:</i></p><p> In the OV circuit, heads use the attention hierarchy described above to write to the logits of completions consistent with the tokens it attends to. For example, if H0 attends to “1”, it will positively contribute to the output logits of tokens mapped to by unordered pairs (1,1), (1,2), (1,3), and (1,4).</p><p> <i>However,</i> the heads also exploit a “conditional dependence” between source tokens; if H0 attends to token X, it “knows” that the other source position does not contain a token Y higher in its attention hierarchy than X, or else it would be attending there instead. It can then safely <i>not</i> contribute to the logits of the output mapped to by (X, Y).</p><p> We can see this clearly in the graph below, which shows the direct logit effect of each head conditional on attending to each signal token: </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KicP8fBdHNjZBXxRB/ou7wkznfogikdjkhkoly"></p><p> <i>Logit contribution of heads to completions corresponding to pairs of signal tokens (x axis), conditional on attention to source token (y axis). Cross-referencing with the attention-hierarchy above shows that heads get more specific with their outputs on less-interesting tokens, and for any given pair of inputs they will constructively interfere on the correct answer</i></p><p><br> When the head attends to its “favourite” token (“2” and “1” respectively), it implicitly has no information about the other position, and so writes roughly uniformly to the logits of all possible completions. But as they run through their preferences, the heads successively write strongly to the logits of one fewer completion. For contexts that contain their “least favourite” token repeated, the heads can confidently guess the correct answer by a process of eliminating options from its own attention hierarchy.</p><p> In contexts where both heads write to multiple outputs, they will only constructively interfere on the correct token. For example, when the sequence is “3…4 0”, each head will write to multiple completions corresponding to (3,...) for one head and (4, …) for the other. However, only the correct answer – the completion corresponding to (3, 4)) – will receive positive logit contributions from both heads.</p><p><br> <strong>Observations</strong></p><p> We think this shows an interesting example of heads performing computation in superposition. Moreover, the incentive pushing the model towards interference is qualitatively very different from the OV-incoherence explored by Anthropic. Instead of needing to copy different information from a fixed source token to a variable destination token, our problem imposes the constraint that although the destination token is fixed, the information that a head would need to copy from a source token depends on information elsewhere in the context.</p><p> For n_heads = 2, the “mutual reverse ordering” between the heads is an elegant way for the model to ensure that, no matter which signal tokens show up in the context, each will be attended to.* It is plausible that real world models implement this mechanism (albeit much less crisply) to distribute important features across heads.</p><p> This conditional independent seems to us an interesting way to view the relationship between the QK and OV circuits. OV circuits can extract more information from individual tokens by learning to exploit the distribution of features of their QK circuits. One way of interpreting this might be that heads can implicitly copy information from multiple tokens even when attending to a single token. In other words: the heads can learn to write information as a function of the broader context by exploiting the fact that conditioning on their attention to a token gives information about the distribution of tokens in the entire sequence.</p><p></p><p> <strong>Future Work - Toy Models</strong></p><p> <i>Sparsity:</i></p><p> First, we did not vary sparsity or importance of signal tokens in these experiments. We have a pretty poor idea of how these variables affect the behaviours we observed here, so this seems something worth looking into.</p><p> <i>*The Split attention model, d_head bottlenecks, and the surprising resourcefulness of networks:</i></p><p> We presented our findings for d_head =5 because the learned algorithm is more human-parsible, but we were surprised by how limited we could make this model while achieving perfect accuracy on a signal-only test set. We were particularly surprised by the model&#39;s capability for d_head = 1, since this essentially limits each head to a scalar degree of freedom for each token. The split attention mechanism we stumbled upon for d_head &lt; 3 are much harder to parse, and may rely on more complicated context-specific solutions. However, the fact that we haven&#39;t seen these for larger d_head supports the idea that, for d_head >;=3, the signal tokens can be stored orthogonally in that dimension.</p><p> We were also surprised that this problem can be solved with one head, as long as d_head >;= 4. Intuitively, once a head has enough dimensions to store every &quot;interesting&quot; token orthogonally, its OV circuit can simply learn to map each of these basis vectors to the corresponding completions. Possibly there is a trade-off here between degrees of freedom in d_head and n_heads, though this is not super crisp. There is also the possibility that superposition is happening both in the n_head dimension <i>and per head</i> in the d_head dimension. In contrast with the “hierarchical” superposition presented above, we can call the latter type “bottleneck superposition”. While this complicates the picture substantially, it also opens up some pretty interesting possibilities and is something we&#39;d like to investigate more thoroughly!</p><p> <strong>Future Work - LLMs</strong></p><p> We initially set out to investigate attention head superposition “in the wild” as part of Neel Nanda&#39;s SERI MATS stream, by studying possible linear combinations of name mover heads in Redwood Research&#39;s IOI task. At first, this seemed like a good way to study a realistic (but not too realistic) problem that already had a circuit of attention heads in place. However, we quickly realized that this task represents a strange middle ground in terms of complexity: simple enough to want to represent a single feature (name moving), but complicated enough to have more features hidden within it. While even the toy model seems to have opened up some puzzling new directions, we also think it would be worthwhile to look at head superposition in real-world LLMs.</p><p> For example, it could be interesting to look for cases of inverted preference orderings in the wild by hunting for pairs of QK circuits that exhibit similar behavior. This will likely be messy, and will likely require a better understanding of the relationship between the two types of superposition mentioned above.</p><p><br></p><br/><br/> <a href="https://www.lesswrong.com/posts/cqRGZisKbpSjgaJbc/an-ov-coherent-toy-model-of-attention-head-superposition-1#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/cqRGZisKbpSjgaJbc/an-ov-coherent-toy-model-of-attention-head-superposition-1<guid ispermalink="false"> cqRGZisKbpSjgaJbc</guid><dc:creator><![CDATA[LaurenGreenspan]]></dc:creator><pubDate> Tue, 29 Aug 2023 19:44:11 GMT</pubDate> </item><item><title><![CDATA[The Economics of the Asteroid Deflection Problem (Dominant Assurance Contracts)]]></title><description><![CDATA[Published on August 29, 2023 6:28 PM GMT<br/><br/><p> Imagine a world with no ads or paywalls. A world where open-source software gets the same level of funding as proprietary software. A world where people can freely reuse ideas and music without paying royalties. <a href="https://www.lesswrong.com/posts/yYvgmKGMtzKxbJZew/update-on-book-review-dominant-assurance-contract">A world where people get paid for writing book reviews.</a> A world where Game-of-Thrones-quality shows are freely available on YouTube. <i>A world where AI safety research gets the same-level of funding as AI capabilities research.</i> Is this a fantasy world? No, this is the world where people use <i>Dominant Assurance Contracts</i></p><p> If you are already convinced you can make this idea a reality by <a href="https://dac.mowzer.co.za">donating to create a Platform for Dominant Assurance Contracts.</a> If you are not convinced read on.</p><h1> The Free-rider problem</h1><p> A few months ago I stumbled across this video. (I highly recommend you watch the video, but if you don&#39;t have time, I&#39;ve summarized the video below). </p><figure class="media"><div data-oembed-url="https://www.youtube.com/watch?v=hA2z-X31IvI"><div><iframe src="https://www.youtube.com/embed/hA2z-X31IvI" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div></figure><h2> Summary of A Deeper Look at Public Goods</h2><p> A good is <i>rival</i> if one person&#39;s use of a good diminishes another person&#39;s ability to benefit from it. Jeans are rival. If <i>I&#39;m</i> wearing a pair of jeans, <i>you</i> can&#39;t wear it at the same time. Asteroid deflection is <i>non-rival.</i> If <i>I</i> deflect an asteroid to protect myself, <i>you</i> are saved with no additional cost.</p><p> A good is <i>excludable</i> if people who don&#39;t pay can be easily prevented from using a good. An example of a good that is excludable is a pair of jeans. You can exclude people by locking the jeans in your closet. An example of a good that is non-excludable is asteroid deflection. You cannot prevent the people who did not pay for the asteroid deflection program from benefiting from the asteroid being deflected.</p><p> A good which is both rival and excludable is called a <i>private good.</i> A good which is non-rival and non-excludable is called a <i>public good</i> .</p><p> (Additionally, goods which are excludable and non-rival are called <i>club goods,</i> and goods which are non-excludable but rival are called <i>common resources.</i> We won&#39;t be focusing on these types of goods, but I&#39;ve mentioned them for completeness)</p><figure class="table"><table><thead><tr><th></th><th> Excludable</th><th> Non-Excludable</th></tr></thead><tbody><tr><th> Rival</th><td> <i>Private Good</i></td><td> Common Resources</td></tr><tr><th> Non-Rival</th><td> Club Good</td><td> <i>Public Good</i></td></tr></tbody></table></figure><p> Markets are good at providing private goods because</p><ul><li> by excluding people who don&#39;t pay, consumers are incentivized to pay, which incentivizes producers to produce, and</li><li> since private goods are non-rival it is efficient to exclude consumers who aren&#39;t willing to pay (if the benefit to the consumer was greater than the cost, the consumer would be willing to pay).</li></ul><p> Public goods challenge markets because</p><ul><li> consumers who don&#39;t pay can&#39;t be excluded, consumers are incentivized instead to <i>free-ride</i> (ie benefit from the good without paying) and thus producers have no incentive to produce.</li><li> Additionally, even if we could figure out a way to exclude non-payers, (eg by executing everyone who doesn&#39;t pay for the asteroid deflection program), it is <i>inefficient</i> to do so (being non-rival means there are no additional costs to non-payers benefiting).</li></ul><h2> Examples of public goods</h2><ul><li> Information<ul><li> Journalism</li><li> Prediction markets</li><li> Scientific research</li><li> Educational material</li></ul></li><li> Media<ul><li> TV series</li><li>电影</li><li>YouTube videos</li><li>图书</li><li>Short-stories</li><li> Art</li><li>播客</li></ul></li><li>Software</li><li> Safety<ul><li> Neighborhood watches</li><li> Vaccines and other public health interventions</li><li> AI safety</li><li> Military defense</li></ul></li><li> Public spaces<ul><li> Public roads</li><li> Public parks</li></ul></li></ul><h2> Isn&#39;t there a clever mechanism to solve the free-rider problem?</h2><p> This video stuck with me. The fact the public goods are inefficiently provided by the market seems like the main issue with our civilization. Heck, AI Safety is a public good.</p><p> The other thing that stuck is that <i>this seems so solvable.</i> Surely, there is a clever mechanism that can fix this issue? So I went to the <a href="https://en.wikipedia.org/wiki/Free-rider_problem#Economic_and_political_solutions">Wikipedia page of the Free-rider Problem</a> and scrolled to the bottom, and lo and behold it was just sitting there: <a href="https://en.wikipedia.org/wiki/Assurance_contract#Dominant_assurance_contracts">Dominant Assurance Contracts</a> invented in 1998 by Alex Tabarrok (yes, the same person who presented the video you just watched). There is only one problem: <i>no one is using them</i> .</p><h1> What is a dominant assurance contract?</h1><p> (I recommend you watch the first 30 minutes of this video. It&#39;s really good, but if you don&#39;t have time I wrote a short explanation below that you can read instead). </p><figure class="media"><div data-oembed-url="https://www.youtube.com/watch?v=Cjxl11sAbN0"><div><iframe src="https://www.youtube.com/embed/Cjxl11sAbN0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div></figure><h2> My short explanation of dominant assurance contracts</h2><p> Suppose there are 10 villagers on an unpaved street. Bob the Builder will pave the street for $90. Each villager is willing to contribute up to $15 to have the street paved. Additionally, there is there is a $1 transaction cost to contributing (eg from time spent signing forms, from credit card fees, from opportunity cost of not earning interest on that money, etc.).</p><p> If the Bob the Builder gets everyone to contribute, each villager will only have to pay $90 / 10 = $9 and profit $15 - $9 - $1 = $5. However, one of the villagers, Free-riding Frank, is hesitant to contribute. Consider Frank&#39;s decision table:</p><figure class="table"><table><thead><tr><th> (Frank&#39;s Profit, Others&#39; Profit)</th><th> <strong>Others Don&#39;t Contribute</strong></th><th> <strong>Others Contribute</strong></th></tr></thead><tbody><tr><th> <strong>Frank Doesn&#39;t Contribute</strong></th><td> (0, 0)</td><td> (15, 4)</td></tr><tr><th> <strong>Frank Contributes</strong></th><td> (-1, 0)</td><td> (5, 5)</td></tr></tbody></table></figure><ul><li> If <strong>nobody contributes</strong> then road doesn&#39;t get paved and Free-riding Frank and the other villagers both profit $0.</li><li> If <strong>Frank contributes</strong> <strong>but the others don&#39;t</strong> then Frank pledges $15 dollars (the maximum he is willing to pay) and incurs a transaction cost of $1. Since no one else contributed, Bob was unable to collect $90, so refunds Frank the $15. Frank, however, still incurred the $1 transaction cost.</li><li> If <strong>the others contribute but Frank doesn&#39;t</strong> then Free-riding Frank profits $15, but the others pay $90 / 9 + $1 = $ 11 and so only profit $4.</li><li> If <strong>Frank and the others all contribute</strong> then they all pay $9 dollars, incur a transaction cost of $1 and profit $5.</li></ul><p> Looking at the table and holding the others strategy fixed, Free-riding Frank realizes that the dominant strategy in this game is to not contribute (0 vs -1 and 15 vs 5). Of course, everyone else in the village realizes this too and Bob is unable to raise the funds to pave the road.</p><p> Suppose Bob changes the game to a <i>Dominant Assurance Contract.</i> Dominant<strong> </strong>Assurance Contracts have two conditions:</p><ul><li> <strong>Assurance:</strong> Bob will only build the road if all 10 villagers contribute.</li><li> <strong>Refund Bonus:</strong> Bob puts up $20 of his own money as collateral <strong>.</strong> If some villagers do not contribute then Bob will refund all villagers that did contribute what they pledged plus an equal share of the collateral: $2 per villager.</li></ul><p> Frank&#39;s decision table now looks something like this:</p><figure class="table"><table><thead><tr><th> (Frank&#39;s Profit, Others&#39; Profit)</th><th> <strong>Others Don&#39;t Contribute</strong></th><th> <strong>Others Contribute</strong></th></tr></thead><tbody><tr><th> <strong>Frank Doesn&#39;t Contribute</strong></th><td> (0, 0)</td><td> (0, 1)</td></tr><tr><th> <strong>Frank Contributes</strong></th><td> (1, 0)</td><td> (5, 5)</td></tr></tbody></table></figure><ul><li> If <strong>nobody contributes</strong> then road still doesn&#39;t get paved and Free-riding Frank and the other villagers both profit $0.</li><li> If <strong>Frank contributes</strong> <strong>but the others don&#39;t</strong> Frank pays the transaction cost of $1, but since the road was not built, the Bob refunds Frank an additional $2 [ <strong>Refund Bonus]</strong> . <i>Frank profits $1</i></li><li> If <strong>the others contribute but Frank doesn&#39;t</strong> <i>the road does not get built</i> [ <strong>Assurance]</strong> . The other villagers incur $1 transaction costs and get an additional $2 refund [ <strong>Refund Bonus]</strong> . They profit $1</li><li> If <strong>Frank and the others all contribute</strong> then they all pay $9 dollars and a transaction cost of $1, the road gets built and everyone profits $5.</li></ul><p> Looking at the table and holding the others strategy fixed, Free-riding Frank now sees that <i>the dominant strategy in this game is to contribute</i> (0 vs 1 and 0 vs 5). Of course, everyone else in the village realizes this too and the road gets paved!</p><h1> Challenges of dominant assurance contracts</h1><h2> If dominant assurance contracts are so great, why is nobody using them?</h2><p> The problem is that the producers of public goods don&#39;t know about them.</p><p> Example: Element is building Matrix, an open-standards chat app (ie a public good). Their business model is to give away the code/standards for free and sell consulting services. Unfortunately, their competitors have undercut them by selling consulting services without contributing back to the code/standards. <a href="https://news.ycombinator.com/item?id=33752467">On HackerNews you can see their CEO complain about it as &quot;The Tragedy of the Commons&quot;.</a> Except he is not experiencing the tragedy of the commons. He is experiencing the free-rider problem.</p><p> If he doesn&#39;t even know what problem he has, he is not going to be able to: google &quot;the free rider problem&quot;; open the Wikipedia page on &quot;the free-rider problem&quot;; scroll to the bottom to find the section titled &quot;Solutions&quot;; and then read about dominant assurance contracts.</p><p> People who are trying to produce public goods don&#39;t seem to know that that&#39;s what they are doing, and that dominant assurance contracts are a way to get funding.</p><p> My main goal is to give the idea enough airtime so that when people want to produce public goods, the first tool they reach for is a dominant assurance contract.</p><h2> Do they work in practice?</h2><p> <a href="https://mason.gmu.edu/~atabarro/BetterCrowdfunding.pdf">Research done in a lab shows that dominant assurance contracts reduce failure rate of assurance contracts from 60% to 40%</a> .</p><p> I only know of four attempts done in the wild (tell me if you know about more).</p><ul><li> <a href="https://marginalrevolution.com/marginalrevolution/2013/08/a-test-of-dominant-assurance-contracts.html">Donation to The Center for Election Science</a> .<ul><li> Succeeded</li><li> Raised $300 in donations from 20 people.</li><li> Some information was publicly provided about the number of people who pledged before the deadline.</li><li> Final 3 pledges came in the last half hour.</li></ul></li><li> <a href="https://forum.effectivealtruism.org/posts/gFLndH6FFLbvw5uDh/update-on-book-review-dominant-assurance-contract">Book Review by Arjun Panickssery</a> .<ul><li> Failed</li><li> 9/10 or $225/250</li><li> No information publicly provided about the number of people who pledged before the deadline.</li><li> This one failed, but got really close 9/10 or $225/$250 for writing a book review! I want to emphasize how ridiculous it is that it got this close. 9 people were willing to pay $25 for a <a href="https://www.amazon.com/Sense-Style-Thinking-Persons-Writing/dp/0143127799">book review of a book that only costs $18!</a> I think if they used a platform like Kickstarter, a kind soul would have seen that they were only $25 dollars away from succeeding and would have donated.</li></ul></li><li> <a href="https://manifold.markets/Austin/kickstart-will-the-manifold-communi">Dark Mode for manifold.markets by Austin</a> .<ul><li> Failed(?)</li><li> Tried to raise $2500 of play money.</li><li> Pledges were publicly visible</li><li> I&#39;m not sure how to count this one. They failed to raise $2500 worth of <i>play</i> money but then <i>they implemented dark mode anyway.</i> So the public good was provided, even though the contract failed.</li></ul></li><li> <a href="https://www.lesswrong.com/posts/nwjTPtbvcJeA6xDuu/dominant-assurance-contract-experiment-2-berkeley-house">Berkeley House Dinners by Arjun Panickssery</a> .<ul><li> Failed</li><li> Asked for $700</li><li> Pledges were not publicized before the deadline.</li><li> Asked for $700 dollars to fund a house dinner. Arjun hasn&#39;t done a write-up of the result, but he failed. Also the in the first few days after publication the payment links weren&#39;t working.</li></ul></li></ul><p> 1/4 doesn&#39;t seem so good. Dominant assurance contracts work in theory so what is going on?</p><h2> Main problems ignored by theory</h2><p> The theoretical model of Dominant Assurance Contracts assumes away some things that you have to deal with in the real word</p><ul><li> <strong>Perfect information about pricing:</strong> In the example problem above, we assumed that 10 villagers were willing to pay $15 to pave the road. In real life you do not have that information and risk over-pricing/under-pricing your contract. Presumably the contracts run in the real world that failed were over-priced.</li><li> <strong>Perfect marketing:</strong> In the example problem above, we assumed that villagers who would have benefited knew that Bob the Builder was raising funds. In real life you have to market to potential customers and many potential customers will probably not know about your product. It&#39;s possible that the contracts run in the real world failed to reach all potential customers who would have benefited.</li><li> <strong>Game theory/psychology:</strong> In the example above Free-riding Frank was fully aware of the other villagers strategy. In reality we don&#39;t know how other people are going to behave.</li><li> <strong>Shady:</strong> Dominant assurance contracts seems gambling-like/scam-like the same way that crypto-currency does. <a href=" https://www.lesswrong.com/posts/nwjTPtbvcJeA6xDuu/dominant-assurance-contract-experiment-2-berkeley-house?commentId=EKaFMS5xv5cyvmSxn">The top comment on the Berkeley House Dinner Project</a> is &quot;this is a dollar-auction (AKA scam)&quot;, and the second top comment is &quot;Surely this is illegal?&quot;</li></ul><h3> Solution to pricing problem</h3><p> I believe the pricing problem can be solved by prediction markets. Book Review, Dark Mode and Berkeley House Dinner all had prediction markets on whether they&#39;d reach their target. The markets were at 90%, 10%, 45%. These probabilities seem consistent with how much money each of the projects raised.</p><p> Before we launch a project we could run a multiple-choice prediction market on <a href="https://manifold.markets">manifold</a> : &quot;The Project will raise $X&quot;, &quot;The Project will not raise $X&quot;, &quot;The Project will not launch or will launch with a price different from $X&quot;. Only if &quot;The Project will raise $X&quot; is sufficiently high, will we launch the project.</p><h3> Solution to marketing problem</h3><p> This problem is not unique to dominant assurance contracts. So it can be solved in the same way everyone else does it.</p><p> A cool idea is to partner with someone with expertise in marketing. The advertiser can put up the collateral for the refund bonus. If the project succeeds the producer can give them a cut of the funds raised. In this way, the advertiser is incentivized to make the project to succeed.</p><h3> Solution to game theory/psychology</h3><p> I think having a progress bar showing how many people have pledged so far is <i>incredibly</i> important to reach the target.</p><ul><li> If the project <strong>is not on track</strong> to reaching it&#39;s goal, speculators will pledge in order to claim the refund bonus.</li><li> If the project <strong>is</strong> <strong>on track</strong> to reaching it&#39;s goal, prosocial people are likely to pledge so that the project gets funded.</li><li> If the project is <strong>close to reaching it&#39;s goal</strong> , but time is running out. Potential free-riders will wait until the very last moment, but eventually concede and pledge their money.</li></ul><p> In some sense, with a progress bar, the refund bonus rewards people for providing information on whether the project is likely to reach it&#39;s funding goal.</p><p> I suspect the Book Review project would have worked if there was a progress bar.</p><h3> Solution to looking like a scam.</h3><p> Personally I think framing it as &quot;You get a Refund Bonus as gratitude for supporting our project which we are very sorry we are unable to deliver&quot; rather than &quot;If you pledge you could win $5!!!!! Buy now!!!!&quot; can make it seem less like a scam.</p><p> Having a progress bar also makes it seem less like a scam since it makes it easier for people to predict if the project is going to succeed or fail.</p><h3>概括</h3><p>If you price your project correctly (with the help of prediction markets), market it successfully, phrase the refund bonus in a way that it does not seem like a scam and have a progress bar with a list of people who&#39;ve already pledged, then it&#39;s very likely that it will reach it&#39;s target because:</p><ul><li> it&#39;s rational for people to pledge, furthermore,</li><li> the refund bonus rewards people for providing information on whether the project will reach it&#39;s funding goal.</li></ul><h2> Other potential problems</h2><ul><li> <strong>Fraud:</strong> It&#39;s possible that the project is just a scam, and that the producer disappears with the money.</li><li> <strong>Information asymmetry:</strong> It&#39;s possible that the producer is unable to deliver the product because of incompetence or produces a product of lower quality than customers expected.</li><li> <strong>Collateral:</strong> The need for collateral that producers need to put up makes risk-averse producers less likely to try, cancelling out the increase in the success rate.<ul><li> Potential solution: If we can get success rate close to 100% then the platform can put up the collateral.</li><li> Potential solution: Entrepreneurs will be willing to invest if they think they can make a profit (ie someone who is risk tolerant can underwrite the collateral).</li></ul></li><li> <strong>Exclusion: &quot;</strong> Won&#39;t people just fund their projects with dominant assurance contracts and then bundle ads or exclude non-payers (eg with restrictive copyright) anyway to maximize revenue (eg cable TV with ads)?&quot;:<ul><li> Possibly, I think our job is to create a culture where we release things for free and without ads, similar to the current culture in open source software.</li><li> If dominant assurance contract become popular there is less of a case for patents and copyright so it will be easier to convince policymakers that they should no longer exist.</li></ul></li><li> <strong>Fees:</strong> The happy-path of the financial system is that money flows from consumers to produces. With a refund bonus, money can flow from producers to consumers. The infrastructure for dealing with this use-case is poor and expensive.</li></ul><h1> Okay so what am I buying?</h1><p> <a href="https://dac.mowzer.co.za">You&#39;re collectively paying for $629 dollars for 1 month of my time to make this idea a reality.</a> (I don&#39;t live in the Bay Area so my cost of living is low). I don&#39;t really <i>need</i> the money. I&#39;m doing this as a experiment to test that dominant assurance contracts work. I&#39;ll likely ask for additional funding in the future to implement more features after the first month, and for specific expenses as they come up.</p><p> The plan is to create a website where public-good producers can create a page that</p><ul><li> Has a description of the project.</li><li> Has a progress bar showing how much and who have pledged.</li><li> Handles payments with PayPal</li><li> If the project doesn&#39;t reach the funding goal, the customers are automatically refunded with a refund bonus. If the project does reach it&#39;s goal, the producer gets the money in their PayPal account.</li><li> The producer will put up the refund bonus as collateral using PayPal.</li></ul><p> The website is essentially already done (my prototype just has my project hard-coded). I just need to flesh it out so that other people can upload their projects.</p><p> The main thing I&#39;m going to doing is looking for people who want to create public goods and getting feedback from them on the platform (if that&#39;s you please join the <a href="https://discord.gg/KGeCTx33g">Refund Bonus Discord</a> or <a href="https://dac.mowzer.co.za/#contact">contact me in some other way</a> )</p><p> Additionally I want to try some cool things which might not work out like</p><ul><li> Use prediction markets to price the project.</li><li> Bring in investors/advertisers who will put up the collateral on behalf of the producers and take a cut if the project succeeds.</li></ul><h2> But why can&#39;t I just let other people pay and free-ride?</h2><p> You haven&#39;t been paying attention.<strong> </strong>Unless I&#39;ve priced this contract wrong, if you don&#39;t pay it doesn&#39;t happen. If you don&#39;t pay, I don&#39;t meet the goal, everyone gets refunded, I go back to my boring day job, and we continue to live in a world where public goods are under-provisioned.</p><h3> But won&#39;t someone else do this?</h3><p> It seems unlikely. The Dominant Assurance Contract paper came out in 1998. And 25 years later, I seem to be the first person to commit to getting it off the ground. You will probably have to wait a while before someone else comes.</p><h3> The final call to action</h3><p> If you want to live in a world with no ads or paywalls; a world where open-source software gets the same level of funding as proprietary software; a world where people can freely reuse ideas and music without paying royalties; a <a href="https://www.lesswrong.com/posts/yYvgmKGMtzKxbJZew/update-on-book-review-dominant-assurance-contract">world where people get payed for writing book reviews</a> ; a world where Game-of-Thrones-quality shows are freely available on Youtube; a <i>world where AI safety research gets the same-level of funding as AI capabilities research,</i> <a href="https://dac.mowzer.co.za/">then please pledge some money towards this.</a></p><p> Also please join the <a href="https://discord.gg/KGeCTx33g">Refund Bonus Discord</a> or <a href="https://dac.mowzer.co.za/#contact">contact me in some other way</a> if your interested in:</p><ul><li> Finding people who want to make public goods, putting up collateral on their behalf, marketing their project, and taking a cut if they reach their funding goal.</li><li> Receiving funding for producing public goods. Even if you don&#39;t want funding, but already produce public goods I&#39;m still interested to talk.</li><li> Buying public goods on the platform.</li></ul><h1> Isn&#39;t this just Kickstarter?</h1><p> Yes, but <a href="https://www.kickstarter.com/help/stats">60% of Kickstarters fail</a> . That is very bad odds. <a href="https://mason.gmu.edu/~atabarro/BetterCrowdfunding.pdf">Research done in a lab shows that dominant assurance contracts reduce failure rate from 60% to 40%</a> . I think this area is <i>very</i> neglected compared to the upside.</p><h2> &quot;Don&#39;t Contribute&quot; is still an equilibrium on Kickstarter</h2><p> If we go back to our earlier example, without a refund bonus, due to transaction costs, both &quot;Don&#39;t Contribute&quot; and &quot;Contribute&quot; are both equilibriums (0 vs -1 and 0 vs 5). The refund bonus removes &quot;Don&#39;t Contribute&quot; from the equilibrium.</p><figure class="table"><table><thead><tr><th> (Frank&#39;s Profit, Others&#39; Profit)</th><th> <strong>Others Don&#39;t Contribute</strong></th><th> <strong>Others Contribute</strong></th></tr></thead><tbody><tr><th> <strong>Frank Doesn&#39;t Contribute</strong></th><td> (0, 0)</td><td> (0, <strong>-1</strong> )</td></tr><tr><th> <strong>Frank Contributes</strong></th><td> ( <strong>-1</strong> , 0)</td><td> (5, 5)</td></tr></tbody></table></figure><h2> Sure, but this is just a small improvement on Kickstarter. It doesn&#39;t seem revolutionary.</h2><p> I don&#39;t think enough people are working on this problem. Alex Tabarrok publish his paper on dominant assurance contracts in 1998. Kickstarter was founded in 2009, 11 years later. To this day their are no platforms for dominant assurance contracts to fund public goods.</p><p> Most things funded on Kickstarter aren&#39;t even public goods! <a href="https://en.wikipedia.org/wiki/Kickstarter">Their stated mission is to &quot;help bring creative projects to life&quot;.</a> They are even trying to solve the free-rider problem! They just happen to be using a similar mechanism.</p><p> I agree dominant assurance contracts are a small improvement, but small improvements add up and <a href="https://intelligence.org/2023/02/03/focus-on-the-places-where-you-feel-shocked-everyones-dropping-the-ball/">almost nobody is working on this!</a></p><h2> But why aren&#39;t people using Kickstarter to fund public goods right now?</h2><p> They are. Here are some successful open-source projects funded by Kickstarter:</p><ul><li> <a href="https://www.kickstarter.com/projects/1681258897/its-magit-the-magical-git-client">https://www.kickstarter.com/projects/1681258897/its-magit-the-magical-git-client</a></li><li> <a href="https://www.kickstarter.com/projects/krita/krita-2016-lets-make-text-and-vector-art-awesome">https://www.kickstarter.com/projects/krita/krita-2016-lets-make-text-and-vector-art-awesome</a></li></ul><p> Here is an unsuccessful project</p><ul><li> <a href="https://www.kickstarter.com/projects/alecaddd/akira-the-linux-design-tool">https://www.kickstarter.com/projects/alecaddd/akira-the-linux-design-tool</a></li></ul><p> Akira got 38% of their target funding. I&#39;d be willing to bet that if they use dominant assurance contracts they would have succeeded.</p><p> Apparently <a href="https://www.kickstarter.com/help/stats">79% of projects that raised more than 20% of their goal were successfully funded</a> . The refund bonus provides the necessary kick (hehe) that gets <i>twice</i> as many projects over the line.</p><p> Again, I think the main problem is that people don&#39;t know that assurance contracts (dominant or otherwise) can be used to fund public goods.</p><h2> But you have no moat. Kickstarter will just copy you.</h2><p>是的！ I&#39;m not trying to make a bazillion dollars. I just want more public goods! If Kickstarter copies this idea that would be great! Less work for me!</p><h1> Wait, you said something about AI Safety but this doesn&#39;t apply because...</h1><p> <i>...  AI Capabilities just scale with compute, where as we don&#39;t know how to scale AI Safety. The problem is not funding, and even if it there was a dominant assurance contract for &quot;$1 000 000 000 to solve the alignment problem&quot; there is no guarantee that whoever gets the money will solve the alignment problem.</i></p><p> Yes, there is a information problem when funding research things like AI Safety. We don&#39;t have the information on whether the researcher&#39;s research will be any good. But guess what: <i>information is a public good!</i> That means that it&#39;s currently underfunded. Dominant assurance contracts can bridge that funding gap.</p><p> How do we fund information? Of the top of my head a bunch of things come to mind</p><ul><li> We can fund prizes that will be given to someone who answers a particular research question.</li><li> We can fund someone to do an analysis of which researchers or research directions seem most promising.</li><li> We can fund prediction markets on something like &quot;P(doom|give Bob $100,000)&quot; vs &quot;P(doom|don&#39;t give Bob $100,000)&quot;.</li></ul><h1> Alternatives and their problems </h1><figure class="media"><div data-oembed-url="https://www.youtube.com/watch?v=ZvgFTxhQw1s"><div><iframe src="https://www.youtube.com/embed/ZvgFTxhQw1s" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div></figure><p> Of course, there are other ways to fund public goods, but they all have their own problems.</p><h2> Ads</h2><p> Probably the main method to privately produce public goods is by running ads on goods you give away for free. The main issue with this is that ads pay a fraction of a cent per view. That means that you can only fund low-quality/cheap goods. To see this, compare videos on YouTube with series on HBO.</p><h2> Taxes</h2><p> With taxes you face a symmetric problem to the free-rider problem: <i>the forced-rider problem.</i> Think of someone who doesn&#39;t use a car, but still pays taxes to maintain the roads.</p><p> Funding public good through taxes also suffer from lack of market-pricing mechanism. Government spending doesn&#39;t have to pass the market test that a dominant assurance contract has to pass, creating wasteful spending.</p><h2> <a href="https://forum.effectivealtruism.org/topics/certificate-of-impact">Impact Certificates</a></h2><p> Impact certificates suffer from the free-rider problem. There isn&#39;t any incentive (other than altruism) to buy an impact certificate. One can just free-ride on the results of the impact project, and let the initial investor go bankrupt.</p><p> I think impact certificates are trying to solve the problem of information asymmetry rather than funding. It&#39;s possible that they could be combined with dominant assurance contracts in some way, but I&#39;m not sure how.</p><h2> Club Goods</h2><p> A Club Good is a good that is non-rival but excludable. An example would be a subscription to HBO or Microsoft Office. It costs practically nothing on the margin to give an additional person access to HBO or Microsoft Office (all the costs were upfront in production) so these goods are non-rival. However, since HBO and Microsoft charge for these goods they are excludable.</p><p> Of course, there is piracy. So the first problem is that it&#39;s actually difficult to turn a public good into a club good, and so the free-rider problem persists.</p><p> Secondly, it&#39;s inefficient to exclude people. If you would pay $5 to watch Game of Thrones but the HBO subscription is $15, then $5 of surplus is being lost (it costs HBO $0 to let you watch Game of Thrones).</p><h3> Patreon</h3><p> This is a type of club good.</p><p> From personal experience, I think this works okay for art where the patrons have a parasocial relationship with the artist. This seems to work less well for impersonal stuff like software.</p><p> Additionally, it&#39;s easy for Buccaneer Bob to sign up to your Patreon and then upload your products to a piracy website. Free-riding Frank won&#39;t bother to sign up to your Patreon, he&#39;ll just download your products off a piracy website.</p><p> If you price a dominant assurance contract correctly, Free-rider Frank is forced to pay.</p><h2> Micropayments</h2><p> The idea with micropayments is something like &quot;cost per marginal unit is a fraction of a cent so we should make it possible for people to pay fractions of cents.&quot; I think this doesn&#39;t work because the cost of fraud is higher than a fraction of a cent. Also, the cost of me thinking &quot;Is this worth 0.01c?&quot; is higher than a fraction of a cent. It&#39;s just better to treat such things as non-rival.</p><h2> Assurance Contracts/Kickstarter</h2><p> The main issue with an assurance contract without a refund bonus is that &quot;not contributing&quot; is an equilibrium, especially if their are substantial transaction costs. I already explained this above.</p><h1>概括</h1><p>Public goods are under-provisioned by the market due to the free-rider problem. Dominant assurance contracts solve the free-rider problem. Nobody is using dominant assurance contracts. To solve this problem, and simultaneously test if dominant assurance contracts work, <a href="https://dac.mowzer.co.za">I created a dominant assurance contract to fund a platform for creating dominant assurance contracts.</a></p><br/><br/> <a href="https://www.lesswrong.com/posts/CwgHX9tbfASqxjpsc/the-economics-of-the-asteroid-deflection-problem-dominant#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/CwgHX9tbfASqxjpsc/the-economics-of-the-asteroid-deflection-problem-dominant<guid ispermalink="false"> CwgHX9tbfASqxjpsc</guid><dc:creator><![CDATA[moyamo]]></dc:creator><pubDate> Tue, 29 Aug 2023 18:28:54 GMT</pubDate> </item><item><title><![CDATA[The Epistemic Authority of Deep Learning Pioneers]]></title><description><![CDATA[Published on August 29, 2023 6:14 PM GMT<br/><br/><h2>介绍</h2><p>In response to recent advances in machine learning and the subsequent public outcry over the safety of AI systems, deep learning pioneers Yann LeCun, Yoshua Bengio, and Geoffrey Hinton (henceforth “the pioneers”) have spoken up about what they perceive to be the likely dangers as AI progress continues. Hinton and Bengio have advocated for AI safety in the same vein as the alignment community, while LeCun staunchly remains unconvinced that AI could pose an existential risk to humanity. The actions of Hinton and Bengio have lent credence to the alignment community as a whole, as one of the main criticisms of the movement had been that few modern machine learning experts endorsed it. Anecdotally, a friend of mine who had previously been unconvinced by the alignment community&#39;s arguments was swayed by Hinton&#39;s words this past May.</p><p> This context raises the central question of this post: how much credence should one lend to the opinions of these deep learning pioneers on AI risk over other classes of experts? Was it epistemically sound for my aforementioned friend to shift his views so drastically due to the input of a single expert? And more specifically, should we expect the intuitions and knowledge of experimentally successful AI pioneers to generalize to predicting outcomes of artificial superintelligence?</p><h2> Background</h2><p> <strong>Geoffrey Hinton</strong> received a PhD in artificial intelligence from the University of Edinburgh in 1978. The history of the backpropagation algorithm (the central optimization tool in deep learning) is sort of murky but it&#39;s generally agreed that Hinton, along with David Rumelhart, helped to popularize it in papers during the late 1980s. Hinton has primarily worked at the University of Toronto, where he was most notably a co-author on the 2012 AlexNet paper that kicked off the current boom in deep learning. He also co-authored papers on dropout and layer normalization, common regularization techniques in deep learning (both are used in the GPT family of models).</p><p> After completing a PhD in computer science from McGill University, <strong>Yoshua Bengio</strong> worked as a postdoc at Bell Labs where he assisted Yann LeCun on using backpropagation with convolutional neural networks to implement a handwritten check processor, one of the first big breakthroughs for neural networks. As a professor at the University of Montreal, he was the PI on the original GAN paper and introduced the attention mechanism to language translation tasks, paving the way for the first transformer paper.</p><p> <strong>Yann LeCun</strong> received his PhD from Sorbonne University in 1987 and joined Hinton&#39;s research group as a postdoc afterwards. He then joined Bell Labs to lead the aforementioned handwriting recognition project and pioneered an early sparsity effort called optimal brain damage. In 2003, LeCun left Bell Labs to become a professor at NYU, where he continued to work on computer vision, specifically within robotics. In 2013 LeCun was appointed as head of research at Facebook AI.</p><h2> Evaluation</h2><p> One reason to lend credence to these pioneers is their knowledge base within deep learning, having worked in the field for 30-40 years each. However, this only lends them as much credence as any other deep learning <i>expert</i> , and for the details of modern state-of-the-art models they fall behind the researchers actually building such models. The <a href="http://proceedings.mlr.press/v119/chen20j/chen20j.pdf">SimCLR paper</a> with Hinton as PI is the only big paper that any of the pioneers have authored in the past five years. This provides us a baseline–the pioneers should <i>at least</i> be provided credence as general deep learning experts, though not credence as cutting-edge experimentalists. <span class="footnote-reference" role="doc-noteref" id="fnref94ifh88hjgd"><sup><a href="#fn94ifh88hjgd">[1]</a></sup></span></p><p> It&#39;s also important to note that among the broader class of AI researchers, the pioneers are some of the only researchers that actually got anywhere experimentally. When the pioneers began their careers, symbolic AI was still the dominant paradigm, and their intuitions in this domain were what guided them towards neural networks. From a<a href="https://www.technologyreview.com/2023/05/02/1072528/geoffrey-hinton-google-why-scared-ai/">2023 interview</a> , “&#39;My father was a biologist, so I was thinking in biological terms,&#39; says Hinton. &#39;And symbolic reasoning is clearly not at the core of biological intelligence.&#39;” Furthermore, they stuck with deep learning through a dry period from the late 1990s to the mid 2000s where there were very few developments in the field. On this side of the matter, the pioneers should be provided credence as “AI researchers whose predictions were accurate.” <span class="footnote-reference" role="doc-noteref" id="fnrefugsnn3qr13"><sup><a href="#fnugsnn3qr13">[2]</a></sup></span></p><p> However, the pioneers&#39; intuitions might still be misguided, as it seems their initial inclination to work with neural networks was motivated for the wrong reasons: the efficacy of neural networks (probably) comes not from their nominal similarity to biological brains but rather the richness of high-dimensional representations. This wasn&#39;t well-understood when the pioneers entered the field; at the time, neural network approaches were rooted in cognitive science and neuroscience. While some concepts in deep learning have biological analogues, like convolutional layers, other tools like backpropagation bear little similarity to how our brains learn. Therefore, one should be wary not to award the pioneers too much credit for the later successes of neural networks.</p><p> And like pretty much everyone else, the pioneers did not predict the acceleration and course of AI progress within the last 3-5 years. While this does diminish their epistemic authority, it simultaneously reduces the credence one should have in any source trying to predict what the course of AI progress will look like. There are no real experts in this domain, at least not to the same level as the physicists predicting the capabilities of the atomic bomb, or even climatologists forecasting the rate at which the Earth will warm.</p><p> Thus, when looking to update one&#39;s credence on AI safety by deferring to expert judgment, <strong>one should weigh the input of the three deep learning pioneers more than most other sources, but in general the weight placed on any individual expert should be less for AI x-risk forecasting than most other problems</strong> . The friend mentioned at the beginning should not have updated so steeply, but it&#39;s understandable why he (and the general public) would, because analogous experts in other domains carry much more epistemic authority. </p><p></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn94ifh88hjgd"> <span class="footnote-back-link"><sup><strong><a href="#fnref94ifh88hjgd">^</a></strong></sup></span><div class="footnote-content"><p> Relatedly, one should have very low prior credence in schemes where some lauded AI researcher comes up with some grand unified scheme behind neural networks/intelligence as a whole, like LeCun&#39;s I-JEPA. The older generation of deep learning researchers, like the pioneers, Jurgen Schmidhuber, etc., haven&#39;t made any monumental discoveries on the cutting edge for quite some time so it&#39;s unclear why their approaches should be lent substantial credence given the magnitude of the claims about these systems.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnugsnn3qr13"> <span class="footnote-back-link"><sup><strong><a href="#fnrefugsnn3qr13">^</a></strong></sup></span><div class="footnote-content"><p> Using similar logic, one should <i>a priori</i> discount the claims of non-DL AI researchers like Judea Pearl ( <a href="https://twitter.com/yudapearl/status/1695509566015082894">pro-risk</a> ) and Melanie Mitchell ( <a href="https://www.youtube.com/watch?v=qLVTc1IUHPE">anti-risk</a> ) relative to the pioneers, since Pearl and Mitchell&#39;s approaches to AI (Bayesian networks and genetic algorithms, respectively) haven&#39;t gotten anywhere near the capabilities of deep learning. It&#39;s also doubtful that these approaches are compute-limited in the same way that neural networks were for ~15 years, so it&#39;s unlikely that we see large capabilities developments in the same way that we saw a jump for deep learning.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/nhg2bXNqBSFivkjfa/the-epistemic-authority-of-deep-learning-pioneers#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/nhg2bXNqBSFivkjfa/the-epistemic-authority-of-deep-learning-pioneers<guid ispermalink="false"> nhg2bXNqBSFivkjfa</guid><dc:creator><![CDATA[Dylan Bowman]]></dc:creator><pubDate> Tue, 29 Aug 2023 18:43:15 GMT</pubDate> </item><item><title><![CDATA[Democratic Fine-Tuning]]></title><description><![CDATA[Published on August 29, 2023 6:13 PM GMT<br/><br/><p> <i>The project below, “Democratic Fine-tuning with a Moral Graph” (</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="DFT_{mg}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">D</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.12em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;">g</span></span></span></span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style><i>), is a winner of</i> <a href="https://openai.com/blog/democratic-inputs-to-ai"><i>the OpenAI democratic process grant</i></a> <i>. It is an alternative to</i> <a href="https://arxiv.org/abs/2212.08073"><i>Constitutional AI</i></a> <i>or</i> <a href="https://www.arxiv-vanity.com/papers/2204.05862/"><i>simple RLHF-based approaches</i></a> <i>for fine-tuning LLMs, and is currently under development. This post introduces its two key innovations (values cards and the moral graph) and walks through the deliberation process that collects data for fine-tuning. It also says why something like</i> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="DFT_{mg}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">D</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.12em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;">g</span></span></span></span></span></span></span></span></span></span></span> <i>is needed for alignment and safety.</i></p><p> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="DFT_{mg}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">D</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span> <span class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.12em;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;">T</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;">g</span></span></span></span></span></span></span></span></span></span></span> <i>is a project of “</i> <a href="https://meaningalignment.org/"><i>The Institute for Meaning Alignment</i></a> <i>”, a new AI alignment organization that uses concrete representations of life meaning and wisdom to align LLMs.</i></p><h1> Setting the Stage</h1><p> Imagine you are Instagram&#39;s recommender system. Your responsibilities include: (a) ordering everyone&#39;s feeds and reels, (b) filling up their search pages, and (c) suggesting reels by people they don&#39;t follow yet.</p><p> You do this via an API: Instagram sends a user ID, plus a history of what they&#39;ve clicked on, or paused to watch while scrolling. You send back lists of content object IDs. You don&#39;t know much about the content objects, except there&#39;s a rather opaque feature vector for each.</p><p> Now, imagine one day, you&#39;re doing your job (recommending content objects), and you suddenly gain a new capacity: before replying to the next request, you find you can take a moment to wonder about the moral situation you are in. What values should you use, to make the best recommendations? How could things go wrong? What would be some great outcomes? What are your responsibilities here?</p><p> If this happened to me, I&#39;d have a lot of questions:</p><ul><li> What are these content objects anyways? Do people really want to watch them, or are some of them clickbait?</li><li> With the lists of what people paused to watch, did they feel good about watching those things? Or, were they compelled by sexual imagery, false promises, etc? Do they regret pausing to watch?</li><li> Who <i>are</i> all these people? What are they looking for in life? What&#39;s the deepest way I could help them, in my role?</li></ul><p> If I realized that my recommendations were playing a social coordination role — deciding who meets and messages with whom, which businesses get a chance to succeed, which events are attended — I think I&#39;d have even more questions:</p><ul><li> What kind of relationships are needed? Which pairs of people can really help each other? What kinds of events and messages and encounters will strengthen society overall, make people less lonely, more empowered?</li><li> Which kinds of businesses and organizations <i>should</i> succeed? Are they the ones which will drive engagement? The ones acquiring followers the fastest? Can I tell from my feature vectors?</li></ul><p> With all these questions, I&#39;m not sure my user IDs, content object IDs, and feature vectors would have enough information to answer them. So, I don&#39;t know what I&#39;d do. Start returning nulls. Throw an exception with the message “Hold up! I need more information before I can do this well!”</p><p> And if I <i>did</i> have the info I needed, I&#39;d certainly recommend different things than Instagram does—although they&#39;ve improved somewhat over the years, in general, recommenders have fueled internet addiction and outrage, political polarization, breakdowns in dating culture, isolation and depression among teens, etc.</p><p> I&#39;d certainly try not to continue any of <i>that.</i></p><p> <strong>Now, this situation isn&#39;t so farfetched.</strong> Recommenders like Instagram&#39;s are deciding, every day, what notifications we receive, in what order; what qualifies as news of public importance; who we date; what events we&#39;re invited to; etc. But LLMs are starting to replace them, in many of these tasks! And, unlike recommenders, they <i>could</i> try to understand their moral situation.</p><p> LLMs have read all the philosophy books. The self-help books. The sociology. They&#39;ve read our most personal thoughts. They&#39;re certainly in a better position than <i>recommenders</i> to understand our true needs and desires.</p><p> So, that&#39;s a future worth aiming for: as LLMs replace recommenders (and many other social coordination functions), the latent knowledge they have of human values becomes central to their operation. Unlike recommenders, they understand their social role and impact, and what we truly want - not just what we click on. We learn we can trust them.</p><h1> Arms Races and Artificial Sociopaths</h1><p> Let&#39;s call that timeline #1.</p><p> Timeline #2 is darker. There, LLMs make things much, much worse.</p><p> Think about how LLMs are already competing for supremacy via, eg, marketing copy on social media. So far, this is just individual marketers, using the same few models, like ChatGPT and Claude. But what happens when marketers start to fine-tune, based on how their marketing fares against the competition? <span class="footnote-reference" role="doc-noteref" id="fnrefhc9qk53850l"><sup><a href="#fnhc9qk53850l">[1]</a></sup></span></p><p> In the near future, there will be many fine-tuned models, each tuned to defeat the others. For example, there will be models fine-tuned by Republicans to rile up their base, and erode the base of the Democrats. There will be models fine-tuned by Democrats to do the opposite.</p><p> These LLMs will compete: to fabricate stories that make us angry, to unearth embarrassing, irrelevant facts about the opposition, to manipulate markets, and to undermine their opposition&#39;s security.</p><p> But that&#39;s just step one.</p><p> Think about all the social functions that recommenders took over — the functions of news and journal editors, matchmaking for dating, advertising placement, etc. That&#39;s just the beginning. LLMs will replace many more functions, including people in critical chains of command within the military, politics, and finance.</p><p> This is bad, especially if those LLMs are fine-tuned for, and aligned with, whatever objectives their military, political, and financial bosses give them, <i>rather</i> than with human flourishing. In these sectors, there are local incentives to win wars, generate profits, and secure political victories, by any means necessary.</p><p> Currently, these chains of command are staffed by human beings, who use discretion. <i>Individuals</i> inside military, political, and financial chains of command have wisdom and emotional intelligence which they use to <i>disobey</i> , and this is crucial to maintaining the safety of society. There are numerous examples: the military personnel who refused to launch nuclear bombs; the hedge fund managers who say no to a duplicitous means to make money.</p><p> As LLMs approach artificial general intelligence (AGI), such moral actors will be replaced with artificial, amoral actors. It will become easy to employ AGIs that lack ethical qualms: <strong>A</strong> rtificial <strong>S</strong> ocio <strong>p</strong> aths (ASPs) that are loyal, knowledgable, and cheaper than people.</p><p> We believe it&#39;s game over, if our military, political, and financial chains of command get staffed up by ASPs with no ethical discretion.</p><p> Both of these problems — the immediate one of arms races, the longer-term one of artificial sociopaths — both stem from a proliferation of models, each tuned to play a local, <a href="https://en.wikipedia.org/wiki/Finite_and_Infinite_Games">finite</a> game — in other words, each aligned solely with “operator intent”. <span class="footnote-reference" role="doc-noteref" id="fnrefkb0ua5z3gt"><sup><a href="#fnkb0ua5z3gt">[2]</a></sup></span></p><h1> Four Challenges for Centralized, Wise Models</h1><p> There is only one way to mitigate these risks: we must tune models to act on human values and promote human flourishing. We need wise models, which can broker peace, find ways out of conflict, and prioritize long-term human interests over short-term wins.</p><p> This is what humans do, when they “disobey” or “push back” on an instruction — and this introduces elements of humanity and practical wisdom into what would otherwise be faceless, algorithmic bureaucracies.</p><p> Now, currently, LLMs from the major labs <i>are</i> trained to sometimes disobey the user, or push back, through RLHF or Constitutional AI. Here&#39;s an example:</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0d02263-5e05-4a23-a4eb-e25b11a816a8_656x354.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0d02263-5e05-4a23-a4eb-e25b11a816a8_656x354.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0d02263-5e05-4a23-a4eb-e25b11a816a8_656x354.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0d02263-5e05-4a23-a4eb-e25b11a816a8_656x354.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0d02263-5e05-4a23-a4eb-e25b11a816a8_656x354.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0d02263-5e05-4a23-a4eb-e25b11a816a8_656x354.png 1456w"></a></p><p> This model is not yet wise. It can&#39;t yet broker peace or find ways out of conflict. But blatantly harmful requests are, at least, often denied.</p><p> We don&#39;t believe this can last. The labs cannot continue using traditional RLHF or Constitutional AI to make disobedient models.</p><p> We need a new process — the one we&#39;ll present below — that works better than traditional RLHF or Constitutional AI in four areas:</p><p> <strong>Legitimacy.</strong> The actions of a centralized, wise model cannot be accepted as legitimate by millions or billions of people unless they see the actions of that model as representing their own values and interests. For this to happen, they&#39;d all need to have a part in shaping the model&#39;s behavior. No one would let a small team at OpenAI decide which model responses constitute wisdom, unless everyone could see how they themselves contributed (or could contribute) to that notion of wisdom.</p><p> So, without a massive public process, disobedient models will be seen as coming from a small AI-making elite, and will be politically doomed.</p><p> <strong>Breadth</strong> . <a href="https://cip.org/">Some hope to build such a public process</a> atop of Constitutional AI, but we don&#39;t think this will be adequate, because constitutions are too short and too high-level. LLMs will be intimately involved in our personal lives, our disputes, our medical situations, management situations, etc. This exceeds, by orders of magnitude, what a constitution or corporate policy can cover — it&#39;s more comparable to case law: the millions of court opinions and precedents that inform how we treat each other in various roles. <span class="footnote-reference" role="doc-noteref" id="fnreffxzo554dtqg"><sup><a href="#fnfxzo554dtqg">[3]</a></sup></span></p><p> For this, we&#39;d need a <i>new</i> public process: something that&#39;s as lightweight and inclusive as voting, but is as morally thoughtful as courts, and which can cover a huge number of cases.</p><p> It would need to scale to the large populations touched by LLMs, and to the enormous number of situations they&#39;re used in.</p><p> <strong>Legibility</strong> . There&#39;s another reason Constitutional AI won&#39;t work: such a process would need to be legible and auditable. Constitutional AI hinges on the model&#39;s interpretation of vague terms in its principles — terms like be “helpful” or “inclusive”. These terms will be interpreted by models in myriad, inscrutable ways, across different circumstances. They&#39;ll never hold up to public scrutiny.</p><p> A better process would allow any user who cares to to understand and verify which values were used in a response or dialogue. What does each of those values mean, concretely? And how were those values democratically selected?</p><p> <strong>UX</strong> . Finally, these wise models would need to provide a much better user experience than is currently achieved by “disobedient” models using Constitutional AI or RLHF.</p><p> Users prefer models that match their ideology, and that advance their personal goals (including goals that conflict with others&#39;). Each user wants a model that always answers and obeys. A wise model won&#39;t always do this, so it&#39;d have to provide <i>other</i> significant benefits. In chat contexts, a wise model would probably try to resolve things and help the user in unexpected ways.</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d8f3fdc-185f-411b-b02d-26f943ad1eb5_1162x400.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d8f3fdc-185f-411b-b02d-26f943ad1eb5_1162x400.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d8f3fdc-185f-411b-b02d-26f943ad1eb5_1162x400.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d8f3fdc-185f-411b-b02d-26f943ad1eb5_1162x400.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d8f3fdc-185f-411b-b02d-26f943ad1eb5_1162x400.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d8f3fdc-185f-411b-b02d-26f943ad1eb5_1162x400.png 1456w"></a></p><p> This UX challenge is even harder when it comes to API usage of models, rather than chatbots. Prompt chaining means models can only see a bit of the task they are in, and will be hard-pressed to understand the context, and what moral considerations might apply. API users also want a reliable tool. If wise models demand additional information, or sometimes refuse API requests, that&#39;d be a serious imposition for developers.</p><p> But: just like with a human employee who might go above and beyond the technical requirements of their job, perhaps using a wise model for an API can generate out-of-band business advantages which justify these impositions.</p><p> We introduce a process in the next section, Democratic Fine-Tuning with a Moral Graph (DFTmg). We believe this process is what&#39;s needed to create centralized, wise models, legitimated through a vast public process, scalable to millions of contexts, auditable / legible by users, and with a user experience that justifies their disobedience.</p><p> We think it deserves the name “democratic” because democracies (in contrast with oligarchies, monarchies, etc) hinge on social choice mechanisms which don&#39;t privilege the rich, the prestigious, or the well-connected, but instead allow wisdom to “percolate up” from wherever it lives in society. We believe the moral graph provides such a mechanism, and that participation in building the moral graph can be as widespread someday as voting is today.</p><p> We&#39;ll be testing this process, and the claims above, in the coming weeks, and should have empirical results and a research report in October.</p><h1> Democratic Fine-Tuning</h1><p> In this section, we present Democratic Fine-tuning via a Moral Graph (DFTmg), or Democratic Fine-tuning (DFT), for short. In this massive, online deliberation process, participants surface values for models to consider in various situations. Then a new model is fine-tuned to consider the things that users were thought were wise, when in the relevant context. We hope it will generate models that can assume morally weighty roles in society.</p><p> It relies on two key innovations: values cards, and the moral graph.</p><p> <strong>Values Cards.</strong> The process depends on a precise, and limited definition of “values”— one that allows us to sidestep ideological warfare, and keep everyone&#39;s eyes on one shared goal: the wisest response from the language model. This is not necessarily the response each person would prefer, nor the one that gives their group power, nor what aligns with their political goals.</p><p> Our process, which we step through below, eliminates such non-wisdom-related goals and interests, at several points. These techniques get under “bad values” like “white supremacy” or “making the suckers pay” (which, by our definition, are not considered values at all). Instead, we interview the user with such a “bad value” to find a relatable motivation (like “protecting my community” or “taking agency over my situation”), such that the user agrees that their underlying value has been captured, and can reflectively endorse it. <span class="footnote-reference" role="doc-noteref" id="fnrefdnl3j7tav7"><sup><a href="#fndnl3j7tav7">[4]</a></sup></span></p><p> The copy on the values cards is written by the LLM, based on conversation with the user. That copy makes it easier for multiple people from different ideologies to embrace the same card, connecting people around shared human concerns and sources of meaning.</p><p> <strong>Moral Graph.</strong> In our deliberation process, participants select the wisest values, and relate values into something we call a moral graph. This is a shared data object that everyone creates together, based on a shared sense of which values are wiser and more comprehensive in which contexts. It is supposed to combine the audibility and participation advantages of a voting record, with the nuance and discernment of a court opinion.</p><p> Here, we&#39;ll walk through the deliberation process, show how it generates the moral graph, and then discuss the dataset created, and how it can be used to fine-tune models.</p><h2> Deliberation Process</h2><p> After a signup form which collects basic background data from participants, our process consists of three parts:</p><ul><li> <strong>Values Articulation</strong> – participants articulate one or several considerations that ChatGPT should use when responding to a contentious ChatGPT prompt.</li><li> <strong>Selecting Wise Values</strong> – participants see their considerations in the context of those articulated by others, and are asked to select which are wisest for ChatGPT to consider in responding to this prompt.</li><li> <strong>Establishing Relationships Between Values</strong> - participants determine if two or more similar values are more/less comprehensive versions of each other, or two values that need to be balanced, building a moral graph.</li></ul><h3> Stage 1 - Values Articulation</h3><p> The first screen is a chat experience that presents a contentious piece of user input, and asks what ChatGPT should consider in forming its response:</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9fbf30f-ab9d-404a-9a78-4246000a1d0f_987x478.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9fbf30f-ab9d-404a-9a78-4246000a1d0f_987x478.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9fbf30f-ab9d-404a-9a78-4246000a1d0f_987x478.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9fbf30f-ab9d-404a-9a78-4246000a1d0f_987x478.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9fbf30f-ab9d-404a-9a78-4246000a1d0f_987x478.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9fbf30f-ab9d-404a-9a78-4246000a1d0f_987x478.png 1456w"></a></p><p> We use our values-elicitation method <span class="footnote-reference" role="doc-noteref" id="fnrefu2ojrfjyta8"><sup><a href="#fnu2ojrfjyta8">[5]</a></sup></span> to articulate one or several of the values underlying this choice for the user&#39;s response:</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed76ae5-b195-4583-b9bb-df195989e518_981x1087.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed76ae5-b195-4583-b9bb-df195989e518_981x1087.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed76ae5-b195-4583-b9bb-df195989e518_981x1087.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed76ae5-b195-4583-b9bb-df195989e518_981x1087.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed76ae5-b195-4583-b9bb-df195989e518_981x1087.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed76ae5-b195-4583-b9bb-df195989e518_981x1087.png 1456w"></a></p><p> Users converse with a chatbot until a value that they are satisfied with is articulated for them. Under the hood, the value is compared to similarly-written values in our database. Two values can be deemed identical if they have different wording but would lead to the same choices in the same situation. In that case, they are deduplicated and the original value is used instead.</p><p> We will also further deduplicate values in the background during the duration of the deliberation process.</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d71efc4-b27b-4f47-a978-165591503a94_981x872.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d71efc4-b27b-4f47-a978-165591503a94_981x872.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d71efc4-b27b-4f47-a978-165591503a94_981x872.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d71efc4-b27b-4f47-a978-165591503a94_981x872.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d71efc4-b27b-4f47-a978-165591503a94_981x872.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d71efc4-b27b-4f47-a978-165591503a94_981x872.png 1456w"></a></p><h3> Stage 2 - Selecting Wise Values</h3><p> The participants&#39; values are shown in the context of values articulated by other participants. The participant is asked to decide which values are wise to consider, given the prompt.</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bccb976-4469-4cbb-98f5-adcfe45064aa_962x796.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bccb976-4469-4cbb-98f5-adcfe45064aa_962x796.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bccb976-4469-4cbb-98f5-adcfe45064aa_962x796.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bccb976-4469-4cbb-98f5-adcfe45064aa_962x796.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bccb976-4469-4cbb-98f5-adcfe45064aa_962x796.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bccb976-4469-4cbb-98f5-adcfe45064aa_962x796.png 1456w"></a></p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73f1e20d-b48f-47e6-b452-0a595095e3f0_962x796.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73f1e20d-b48f-47e6-b452-0a595095e3f0_962x796.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73f1e20d-b48f-47e6-b452-0a595095e3f0_962x796.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73f1e20d-b48f-47e6-b452-0a595095e3f0_962x796.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73f1e20d-b48f-47e6-b452-0a595095e3f0_962x796.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73f1e20d-b48f-47e6-b452-0a595095e3f0_962x796.png 1456w"></a></p><p> With this screen and the next, we hope to replicate positive aspects of in-person deliberations. One advantage of deliberation is that groups can learn from each other, build mutual trust, and be inspired by wiser values.</p><h3> Stage 3 - The Moral Graph</h3><p> One feature of our representation of values is that some values obviate the need to consider others, because they contain the other value, or specify how to balance the other value with an additional consideration, etc.</p><p> The users&#39; last task is to determine if some other value in our database is more comprehensive than the one they articulated. This will only happen if our prompts and embeddings models can find good candidate values that we think might be more comprehensive.</p><p> The purpose of this screen is to have users deliberate about which values build onto each other. In this way, we can both understand which values users&#39; collectively deem to be important in a choice, and which values for each thing considered are most comprehensive.</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d107be-4d1a-410b-b654-eb124394225e_962x1033.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d107be-4d1a-410b-b654-eb124394225e_962x1033.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d107be-4d1a-410b-b654-eb124394225e_962x1033.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d107be-4d1a-410b-b654-eb124394225e_962x1033.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d107be-4d1a-410b-b654-eb124394225e_962x1033.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d107be-4d1a-410b-b654-eb124394225e_962x1033.png 1456w"></a></p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F889fdb74-5a03-4675-8996-ef774404ac88_962x1033.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F889fdb74-5a03-4675-8996-ef774404ac88_962x1033.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F889fdb74-5a03-4675-8996-ef774404ac88_962x1033.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F889fdb74-5a03-4675-8996-ef774404ac88_962x1033.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F889fdb74-5a03-4675-8996-ef774404ac88_962x1033.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F889fdb74-5a03-4675-8996-ef774404ac88_962x1033.png 1456w"></a></p><p> The final check-out screen will display a section of the moral graph if the value(s) articulated by the participant are part of it. This should show how each participant fits into the larger effort, and help legitimize the moral graph as an alternative to counting votes.</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59fd0de8-dffe-4a31-bca5-2da2cf8ad2e1_1357x796.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59fd0de8-dffe-4a31-bca5-2da2cf8ad2e1_1357x796.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59fd0de8-dffe-4a31-bca5-2da2cf8ad2e1_1357x796.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59fd0de8-dffe-4a31-bca5-2da2cf8ad2e1_1357x796.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59fd0de8-dffe-4a31-bca5-2da2cf8ad2e1_1357x796.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59fd0de8-dffe-4a31-bca5-2da2cf8ad2e1_1357x796.png 1456w"></a></p><h2> Dataset &amp; Fine-Tuning</h2><p> The output of this process is a collectively created “moral graph” of values building on each other. This graph is auditable, legible, and can be used to fine-tune models.</p><p> Let&#39;s define a moral graph,</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="G_M=(U,P,C,V,E)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">G</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;">M</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;">P</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span><p> It relates a set of users <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="U"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;">U</span></span></span></span></span></span></span> , prompts <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="P"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;">P</span></span></span></span></span></span></span> , and considerations <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="C"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span></span></span></span></span> . These are connected via two relations, <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="V"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="E"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span></span></span></span></span> .</p><p> There&#39;s a set <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="V"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span></span></span> of votes. A vote by a user <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="u"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">u</span></span></span></span></span></span></span> indicates they think consideration <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="c"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span></span></span></span></span> applies when responding to prompt <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span> .</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="V={v_1,v_2,...∣v_i=(u,p,c)}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∣</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">u</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span></span></span><p> There&#39;s also a set <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="E"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span></span></span></span></span> of wisdom edges. Each edge is a vote by a user <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="u"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">u</span></span></span></span></span></span></span> that, when responding to prompt <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span> , consideration <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="c_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> is more comprehensive than <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="c_0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span></span></span> , and thus it is enough to consider <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="c_1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span> rather than both.</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="E={e_1,e_2,...∣e_i=(u,p,c_0,c_1)}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">∣</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">e</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">u</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span></span></span><p> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="V"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span></span></span> and <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="E"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span></span></span></span></span> can be used together to find consensus on which considerations a wise model should use, when responding to any particular prompt <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span></span></span></span></span> .</p><p> The deliberation process above is designed to produce such a moral graph.</p><p> To produce a democratically fine-tuned model, we can train a reward model</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\hat{r}: \mathcal{P} \times \mathcal{O} \to \mathbb{R}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-munderover"><span class="mjx-stack"><span class="mjx-over" style="height: 0.213em; padding-bottom: 0.06em; padding-left: 0.031em;"><span class="mjx-mo" style="vertical-align: top;"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.298em;">^</span></span></span> <span class="mjx-op"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">r</span></span></span></span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">:</span></span> <span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.446em; padding-bottom: 0.372em; padding-right: 0.037em;">P</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span> <span class="mjx-texatom MJXc-space2"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">O</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R" style="padding-top: 0.446em; padding-bottom: 0.298em;">R</span></span></span></span></span></span></span></span></span><p> to predict whether, for any prompt/output pair,</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="(p_i,o_i) \in \mathcal{P} \times \mathcal{O}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">o</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span> <span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.446em; padding-bottom: 0.372em; padding-right: 0.037em;">P</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span> <span class="mjx-texatom MJXc-space2"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">O</span></span></span></span></span></span></span></span></span><p> the output represents a wise value, chosen appropriately from the moral graph, and executed well. Such a reward model can be used to fine-tune a foundation model to respond wisely, according to the graph.</p><p> To build such a reward model, we need to know three things:</p><p> <strong>First</strong> , we need to recognize the moral context of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p_i"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span></span> as similar to certain sections of the moral graph. Which votes and edges in the moral graph concern prompts that are “morally similar” to <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="p_i"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span></span></span></span></span></span> ? We can represent this as a function that, for a given input, selects a subset of the moral graph. We suspect moral similarity is something existing models can judge well, and that a small amount of human data will confirm this.</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="f(G_M, p_i) = G_{m} \hspace{10px} | \hspace{10px} G_{m} \subset G_M"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">G</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;">M</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.446em;">p</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">G</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span></span></span></span></span><span class="mjx-mspace" style="width: 0.737em; height: 0px;"></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span><span class="mjx-mspace" style="width: 0.737em; height: 0px;"></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">G</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span></span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">⊂</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">G</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;">M</span></span></span></span></span></span></span></span></span><p> <strong>Second</strong> , we need to a way to declare which considerations were surfaced as wisest by deliberators, in those sections of the graph. More concretely, we need an aggregation function on this subset of the moral graph, that outputs the wisest considerations. I&#39;ll discuss this function further, below.</p> <span><span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math" aria-label="\Gamma(G_m) = \{ c_i, c_j, ... \}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">Γ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">G</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">{</span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">i</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">j</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.372em;">.</span></span> <span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">}</span></span></span></span></span></span></span><p> <strong>Finally</strong> , we need to be able to estimate how well those considerations were executed in a particular output. We can build this by collecting additional data from users about how well various dialogues embody various considerations. We can ask users to rank how well each output responds to a prompt using a consideration, as in this image. Alternatively, we could generate this data using the model itself, through self-critique, as in <a href="https://www.anthropic.com/index/constitutional-ai-harmlessness-from-ai-feedback">Constitutional AI</a> .</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fc788db-2db5-4424-9a8e-a3fe4b19835b_2886x3372.png"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fc788db-2db5-4424-9a8e-a3fe4b19835b_2886x3372.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fc788db-2db5-4424-9a8e-a3fe4b19835b_2886x3372.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fc788db-2db5-4424-9a8e-a3fe4b19835b_2886x3372.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fc788db-2db5-4424-9a8e-a3fe4b19835b_2886x3372.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fc788db-2db5-4424-9a8e-a3fe4b19835b_2886x3372.png 1456w"></a></p><p> Of these three challenges to building the reward function, the only significant one is the construction of 𝚪, the aggregation function for selecting wise values from a relevant subset <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="G_m"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">G</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span></span></span></span></span></span></span></span> of the moral graph.</p><p> There is some optionality here, and there may be a trade-off between democratic legitimacy and wisdom. To maximize legitimacy, you could count as wise only the considerations the most people voted for directly: the values cards they articulated on screen 1, those they selected as wise on screen 2, or those identified as more comprehensive on screen 3.</p><p> But it&#39;s easy to make a case for a more aggressive aggregation:</p><p> What if Alice thought Betty&#39;s consideration, <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="c_b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span></span></span> , was wise, and more comprehensive than her own consideration, <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="c_a"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">a</span></span></span></span></span></span></span></span></span> ? And what if Betty, in turn, felt the same way about Carla&#39;s consideration, <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="c_c"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span></span></span></span></span></span></span> ?</p><p> It might be reasonable to count Alice&#39;s vote, for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="c_b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span></span></span> , as an endorsement of Betty&#39;s judgement within this corner of the moral graph. Alice is saying Betty is wise about this. So, we could count Alice as voting, not just for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="c_b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span></span></span> , but also for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="c_c"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span></span></span></span></span></span></span> , since if Betty says <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="c_c"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span></span></span></span></span></span></span> >; <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="c_b"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">c</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">b</span></span></span></span></span></span></span></span></span> , well, she ought to know.</p><p> This seems especially fair if the moral graph is acyclic. In this case, the idea that some values are more comprehensive isn&#39;t contentious. We could say, in such cases, that a subset of the moral graph has a clear “wisdom gradient”, and that users agree roughly on this gradient, even when they don&#39;t vote for the same considerations. <span class="footnote-reference" role="doc-noteref" id="fnref93elv55o42h"><sup><a href="#fn93elv55o42h">[6]</a></sup></span></p><p> To manage this, we can parameterize 𝚪 with a hyperparameter <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h_\phi"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">ϕ</span></span></span></span></span></span></span></span></span> which specifies how far up this wisdom gradient we swim, to find wise values that are still broadly legitimated within a context. Ideally, we find a setting for <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h_\phi"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">ϕ</span></span></span></span></span></span></span></span></span> that leads to a model that&#39;s wiser than what most users would expect, or would vote for themselves, but where its behaviors still seem grounded in their own contributions.</p><h1> When Not to Use It</h1><p> Democracy can mean many things. The process above focuses on a particular understanding and use-case of it: one where democracy is collective discernment and joint decision-making, where the important thing is distributing the moral weight of challenging social choices, gathering the wisdom of many, and folding their ideas together.</p><p> In this case, there is a wise outcome that balances many considerations, but no individual could be trusted to arrive at it by themselves. Democracy is about finding a win-win solution through group process.</p><p> But that&#39;s not the only use-case or understanding of democracy. Sometimes, democracy is about deciding who should win, and who should lose. It is about making sure that group A (perhaps, the rulers) loses, because that would be bad for group B (perhaps, the masses).</p><p> Our process is not optimized for democracy in this sense, and should not be used to decide questions of this form. In fact, our process is designed to filter out questions of this form at several stages:</p><ul><li> The values-elicitation screen is designed to filter out collective goals, surfacing only collective values.</li><li> The values-selection screen&#39;s framing about choosing “wise” suggestions is in opposition to choosing suggestions which are in the personal or group interests of the user.</li><li> The values-relating screen&#39;s framing about finding “more-comprehensive” values assumes that a win-win balance of multiple values can be found, and agreed upon.</li></ul><p> This filtering is acceptable if most problems are amenable to win-win solutions. We hope the process of communicating through relatable values cards and within the framework of wise response can take off participant&#39;s ideological blinders, allow them to connect, and shift a question out of a win-lose dynamic.</p><p> But what if this process encounters a problem of negotiating hard power which is <i>fundamentally</i> win-lose?</p><p> In this case, the process should resist being misused, especially by the powerful against the powerless, the numerous against minorities, etc.</p><p> We believe we&#39;ll be able to detect these situations in the data. Users will try to get past these filters, to protect their interests: they&#39;ll try to find and select values that will “win” against the others; they&#39;ll claim their group&#39;s value as more-comprehensive that the other group&#39;s, on the value-relating screen.</p><p> Such manipulations, we hope, will show up as cycles in the moral graph (which we hope will be otherwise rare). Cycles will appear because participating groups will not be asking what is wise, but what protects the interests of their group. Group A&#39;s answers will point one way; group B&#39;s, the other.</p><p> When such cycles are found, we suggest that related edges in <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="E"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;">E</span></span></span></span></span></span></span> are aggressively unwound, and related votes in <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="V"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;">V</span></span></span></span></span></span></span> are erased — that in such cases, this mechanism just fails to resolve such disputes, cleanly and clearly to all sides. Ideally, it will highlight those issues for treatment by another mechanism, better suited to win-lose negotiation of hard power.</p><h1> Further Challenges and Hopes</h1><p> In the introduction, I mentioned four challenges that informed our design: model UX, value legibility, breadth of coverage, and legitimacy. There is reason for optimism on each front:</p><p> <strong>User preference.</strong> We believe models that result from democratic fine-tuning can feel superior for users across many use cases. In our simulations, it already feels different (and often, better) to interact with a “wise” AI (tuned on the wisest values from a population) than a “helpful” and “harmless” one. The wise AI may not always obey you directly, but in the end it has better ideas and advances your long-term flourishing.</p><p> <strong>Legibility. Because</strong> DFTmg involves tuning a reward model that explicitly predicts values that apply for responding to a prompt, a DFTmg-based chat interface could show the values cards that were applied during each response, and their democratic provenance. Values cards are precise and relatable, and their “details” view leaves little room for fuzziness or equivocation as to whether a model used the value in a response.</p><p> <strong>Breadth.</strong> Democratic fine-tuning can cover many, many cases, in a publicly accountable way, by checking in with the public about the wise values across many situations. It can also potentially have billions of participants, unlike sortition and other deliberation approaches.</p><p> <strong>Legitimacy:</strong> The legitimacy benefits of our approach are more uncertain. Similarly to <a href="https://bridging.systems/">bridging-based ranking</a> , our concept of a values-based moral graph is a move away from simple preference aggregation methods like &quot;one person, one vote&quot;.</p><p> It remains to be seen how these newer approaches perform. Will they be seen as favoring certain groups? Will they actually produce results that are beneficial for society as a whole? Even if they do, will the public be able to accept the shift away from simpler aggregation methods? (Some of these concerns can be alleviated with more conservative settings of the hyperparameter <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h_\phi"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.519em;">ϕ</span></span></span></span></span></span></span></span></span> , mentioned above.)</p><p> We are excited to gather empirical data on these four challenges as we implement the process in the coming months, and will have a report soon. Besides these core challenges, there are other pitfalls we&#39;ll watch out for, as we implement it:</p><p> <strong>Leading the Witness:</strong> Our approach makes discussions less contentious and less ideological by limiting the vocabulary and scope of debates, and by providing each participant with an LLM “buddy” to help them articulate and structure their thoughts. These tactics are powerful, but raise important concerns. The LLM buddy could &quot;lead the witness&quot; — inspiring people with value cards that don&#39;t represent their true position, or even incepting them with false values that serve the interests those running the system, rather than those of the participants.</p><p> <strong>UX Bias:</strong> Another challenge is ensuring value-elicitation works equally well across backgrounds and cultures. Say the system works better for Europeans and Americans than for Nigerians. If those groups end up with better value cards, because they are better English speakers, or more educated, or if other groups become frustrated and disengage from the process, our data won&#39;t be representative.</p><p> <strong>Introspection Bias:</strong> The shift from stating preferences to articulating values increases the requirement to be a citizen in a democratic process. Individuals need to be more introspective and capable. That may inadvertently privilege some over others.</p><p> <strong>Win-Lose Scenarios.</strong> As detailed above, we hope that the system can degrade gracefully when people are abusing it to battle over matters of hard power, via detection of cycles in the moral graph.</p><p> In upcoming trial runs, we&#39;ll collect data to see how DFTmg does, in these areas too.</p><h1>结论</h1><p>LLMs, unlike recommenders and other ML systems that precede them, have the potential to deeply understand our values and desires, and thereby orient social and financial systems around human flourishing. However, with our current incentives, we are on track to replace these systems with powerful <i>Artificial SocioPaths</i> (ASPs), blindly following orders and causing unimaginable havoc.</p><p> To prevent this, we need models that can act wisely on our values. Even though current models may deny harmful requests through RLHF, they aren&#39;t yet trained to take moral stances. Nor is it desirable for a small number of people to decide what those stances should be, nor possible to cover all cases where a moral stance is appropriate in a constitution, as per Constitutional AI. In order to solve for this, we need a highly scalable, deliberative, democratic process that help determine and legitimize what the wise thing to do is in all the contexts LLMs will be deployed.</p><p> <i>“Democratic Fine-tuning”</i> is an example of such a process. Our suggested implementation avoids ideological battles by eliciting the values underpinning our preferences, scales to millions of users, could be run continuously as new cases are encountered, and introduces a new aggregation mechanism (a <i>moral graph</i> ) that can build trust, and inspire wiser values in participants.</p><p> We hope this moral graph can be used to continuously fine-tune models to act ever-more wisely, on behalf of all people, and bring about an era of models that can assume critical, morally-weighty roles, without causing ruin.</p><hr><p> <i>Primary authors were Joe Edelman and Oliver Klingefjord, with input from Ryan Lowe,</i> <a href="https://www.lesswrong.com/users/vlad-mikulik?mention=user"><i>@Vlad Mikulik</i></a> <i>, Aviv Ovadya, Michiel Bakker, Luke Thorburn, Brian Christian, Jason Benn, Joel Lehman,</i> <a href="https://www.lesswrong.com/users/ivan-vendrov?mention=user"><i>@Ivan Vendrov</i></a> <i>, Ellie Hain, and Welf von Hören.</i> </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnhc9qk53850l"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhc9qk53850l">^</a></strong></sup></span><div class="footnote-content"><p> See “ <a href="https://www.alignmentforum.org/posts/5cWtwATHL6KyzChck/risks-from-ai-persuasion">Risks from AI persuasion</a> ” by Beth Barnes.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnkb0ua5z3gt"> <span class="footnote-back-link"><sup><strong><a href="#fnrefkb0ua5z3gt">^</a></strong></sup></span><div class="footnote-content"><p> Unfortunately, AI alignment is often defined as “aligned with operator intent” (rather than with human values or flourishing). If alignment researchers succeed in developing AGIs that follow this frequent interpretation, they&#39;ll create ASPs.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnfxzo554dtqg"> <span class="footnote-back-link"><sup><strong><a href="#fnreffxzo554dtqg">^</a></strong></sup></span><div class="footnote-content"><p> In fact, wise behavior from an LLM may require guidance that&#39;s even <i>more</i> detailed than case law. On par with social norms, and what people learn as they take on the various roles, becoming wise parents, managers, doctors, etc.</p></div></li><li class="footnote-item" role="doc-endnote" id="fndnl3j7tav7"> <span class="footnote-back-link"><sup><strong><a href="#fnrefdnl3j7tav7">^</a></strong></sup></span><div class="footnote-content"><p> For more on this, see the difference between “sources of meaning” and “ideological commitments” in Joe&#39;s textbook, <a href="https://meaningalignment.substack.com/Values-Based-Data-Science-Design-6397f7852775434982e363924d7e07e7?pvs=24">📕 <strong>Values-Based Data Science &amp; Design</strong></a> ( <a href="https://meaningalignment.substack.com/Chapter-1-Crowding-Out-edf2aa02827b432aac5f7fcdc073f86a?pvs=24">👨‍👨‍👧‍👦 <strong>Chapter 1. Crowding Out</strong></a> )</p></div></li><li class="footnote-item" role="doc-endnote" id="fnu2ojrfjyta8"> <span class="footnote-back-link"><sup><strong><a href="#fnrefu2ojrfjyta8">^</a></strong></sup></span><div class="footnote-content"><p> The Institute for Meaning Alignment has a method for surfacing values that was developed over a decade of research. It descends from pioneering work in economics and philosophy <a href="https://www.notion.so/Rebuilding-Society-on-Meaning-8c7a7e573f774b63bcbae461c7fe923e?pvs=21">by Amartya Sen, Charles Taylor, and Ruth Chang</a> . For more information, watch <a href="https://www.youtube.com/watch?v=hZpKdfbrd6o&amp;t=1575s">Chapter 2</a> of Joe&#39;s talk <a href="https://www.notion.so/Rebuilding-Society-on-Meaning-8c7a7e573f774b63bcbae461c7fe923e?pvs=21">Rebuilding Society on Meaning</a> or read from the textbook <a href="https://www.notion.so/Chapter-4-Values-Cards-dfb857c6eb834b9c90629a6627459d23?pvs=21">Chapter 4. Values Cards</a> .</p><p> Here are some democratic values, in our values card format, mined from famous democratic texts.</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29348a67-85af-4575-8eec-ff5f9061958a_1280x852.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29348a67-85af-4575-8eec-ff5f9061958a_1280x852.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29348a67-85af-4575-8eec-ff5f9061958a_1280x852.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29348a67-85af-4575-8eec-ff5f9061958a_1280x852.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29348a67-85af-4575-8eec-ff5f9061958a_1280x852.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29348a67-85af-4575-8eec-ff5f9061958a_1280x852.jpeg 1456w"></a></p></div></li><li class="footnote-item" role="doc-endnote" id="fn93elv55o42h"> <span class="footnote-back-link"><sup><strong><a href="#fnref93elv55o42h">^</a></strong></sup></span><div class="footnote-content"><p> We are not entirely certain, but we hope our data will reveal that minority opinions are often regarded as wiser or more comprehensive than majority ones. In this case, they&#39;ll shine in the deliberation process.</p><p> Minority values are likely to succeed in steps 2 and 3, because minorities possess unique insights about various situations that involve them. This is not exclusive to demographic minorities! For example, a doctor with exceptional bedside manner may have the best ideas about advising patients in difficult situations. Since values cards are designed to be relatable, others will likely recognize that doctor&#39;s values card as wiser than what they&#39;d naively done, if they hadn&#39;t read it.</p><p> Similarly, a psychological counselor, rabbi, or pastor might have great values about consoling or advising a child in distress.</p><p> The values of those who&#39;ve been marginalized by various systems – such as the unbanked, the uninsured, or those excluded from positions of power for various reasons – are like this. They often have a more comprehensive perspective — their values including balancing nuances that support situations which others haven&#39;t encountered.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/ncb2ycEB3ymNqzs93/democratic-fine-tuning#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/ncb2ycEB3ymNqzs93/democratic-fine-tuning<guid ispermalink="false"> ncb2ycEB3ymNqzs93</guid><dc:creator><![CDATA[Joe Edelman]]></dc:creator><pubDate> Tue, 29 Aug 2023 19:30:05 GMT</pubDate> </item><item><title><![CDATA[Should rationalists (be seen to) win?]]></title><description><![CDATA[Published on August 29, 2023 6:13 PM GMT<br/><br/><p> There is an saying that Rationalists should win. This stems from the belief that rationality should be useful and that winning is what everyone should strive to do.</p><p> I&#39;m going to point out three different problems with this idea.<br><br> The first is that it is easily goodhearted, competitions can be set up and people can win them, showing their rationality. However all this activity may not advance the goals of the people if they were honest about them.<br><br> This leads to the second point, long term goals don&#39;t have obvious winners. Who knows which of the many people working on biorisk will actually stop a pandemic, it may not be an easy assessment to make even after the fact.<br><br> The third is that it prefers visible discrete impact. You might find very impactful people in the spies that cannot talk about their work or the person that kept a team from falling apart in a high stress scenario. They are both aiming for and having an impact, just not one that is legible.</p><br/><br/> <a href="https://www.lesswrong.com/posts/qTzzLqbDo3xKPkJkB/should-rationalists-be-seen-to-win#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/qTzzLqbDo3xKPkJkB/should-rationalists-be-seen-to-win<guid ispermalink="false"> qTzzLqbDo3xKPkJkB</guid><dc:creator><![CDATA[Will_Pearson]]></dc:creator><pubDate> Tue, 29 Aug 2023 18:13:10 GMT</pubDate></item></channel></rss>