<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 10 月 31 日星期二 14:11:38 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[M&A in AI]]></title><description><![CDATA[Published on October 31, 2023 12:20 PM GMT<br/><br/><br/><br/><a href="https://www.lesswrong.com/posts/pFtwwJFaW8ZCK3Ghf/m-and-a-in-ai#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/pFtwwJFaW8ZCK3Ghf/m-and-a-in-ai<guid ispermalink="false"> pFtwwJFaW8ZCK3Ghf</guid><dc:creator><![CDATA[Hauke Hillebrandt]]></dc:creator><pubDate> Tue, 31 Oct 2023 12:20:18 GMT</pubDate> </item><item><title><![CDATA[Urging an International AI Treaty: An Open Letter]]></title><description><![CDATA[Published on October 31, 2023 11:26 AM GMT<br/><br/><blockquote><p>我们呼吁世界各国政府积极应对先进人工智能（AI）系统给人类带来的潜在灾难性风险，包括滥用、系统性风险和失控带来的威胁。我们主张制定和批准国际人工智能条约，以减少这些风险，并确保人工智能惠及所有人。</p></blockquote><p></p><p> [...]</p><p></p><blockquote><p>我们认为，国际人工智能条约的核心目标应该是防止人工智能系统的能力不受限制地升级，同时保留其利益。对于这样一个条约，我们建议包括以下核心组成部分：</p><ul><li><strong>全球计算阈值</strong>：国际上对用于训练任何给定人工智能模型的计算量设定了阈值，并制定了随着时间的推移降低这些阈值的程序，以适应算法的改进。</li><li> <strong>CERN for AI Safety</strong> ：类似于<a href="https://en.wikipedia.org/wiki/CERN">CERN</a>的协作型 AI 安全实验室，旨在汇集服务于 AI 安全的资源、专业知识和知识，并充当安全 AI 开发和安全研究的合作平台。</li><li><strong>安全 API</strong> ：允许访问安全 AI 模型的 API，并将其功能保持在估计的安全限制内，以减少对 AI 开发中危险竞赛的激励。</li><li><strong>遵守委员会</strong>：负责监督条约遵守情况的国际委员会。</li></ul></blockquote><p>完整信函请访问<a href="https://aitreaty.org/">https://aitreaty.org/</a> 。</p><br/><br/> <a href="https://www.lesswrong.com/posts/epC5CrGCv4JGdfsjm/urging-an-international-ai-treaty-an-open-letter#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/epC5CrGCv4JGdfsjm/urging-an-international-ai-treaty-an-open-letter<guid ispermalink="false"> epC5CrGCv4JGdfsjm</guid><dc:creator><![CDATA[Loppukilpailija]]></dc:creator><pubDate> Tue, 31 Oct 2023 11:26:26 GMT</pubDate> </item><item><title><![CDATA[Agent Foundations track in MATS]]></title><description><![CDATA[Published on October 31, 2023 8:12 AM GMT<br/><br/><p>在 MATS Winter 2023 中，我将指导那些想要从事<a href="https://www.lesswrong.com/posts/ZwshvqiqCvXPsZEct/the-learning-theoretic-agenda-status-2023">学习理论议程的</a>学者。这不是最初公告的一部分，因为（由于后勤原因）我在最后一刻加入了该计划。</p><p><a href="https://www.matsprogram.org/agent">在这里</a>申请。</p><p>有关更广泛计划的更多详细信息，请参阅<a href="https://www.lesswrong.com/posts/tqyg3DpoiE4DKyi4y/apply-for-mats-winter-2023-24">此处</a>。</p><p>以下是我的学者在 2022 年冬季队列中所做的一些工作示例： <a href="https://www.lesswrong.com/posts/cYJqGWuBwymLdFpLT/non-unitary-quantum-logic-seri-mats-research-sprint">1</a><a href="https://www.lesswrong.com/posts/HNnRCPe2CejfupSow/fixed-points-in-mortal-population-games">2</a> <a href="https://www.lesswrong.com/posts/nEFAno6PsCKnNgkd5/infra-bayesian-logic">3</a> 。最令人印象深刻的例子不在这里，因为它尚未发布。该群体中的一位学者现在长期从事学习理论议程的研究。</p><p>如果您认识其他可能适合并有兴趣申请的人，请转告！</p><hr><p>切线相关：虽然没有正式宣布，但我计划为有兴趣从事学习理论议程的研究人员创建一个实习计划，其中包括短期移居以色列。由于战争，这一计划现在被无限期推迟。如果您听说过该计划并考虑申请，您可以考虑申请我在 MATS 中的赛道。</p><br/><br/> <a href="https://www.lesswrong.com/posts/ndSQYCsXJmbsywzZ7/agent-foundations-track-in-mats#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ndSQYCsXJmbsywzZ7/agent-foundations-track-in-mats<guid ispermalink="false"> ndSQYCsXJmbsywzZ7</guid><dc:creator><![CDATA[Vanessa Kosoy]]></dc:creator><pubDate> Tue, 31 Oct 2023 08:12:51 GMT</pubDate> </item><item><title><![CDATA[Intrinsic Drives and Extrinsic Misuse: Two Intertwined Risks of AI]]></title><description><![CDATA[Published on October 31, 2023 5:10 AM GMT<br/><br/><p>鉴于其先进的功能，未来的人工智能系统可能会给社会带来重大风险。其中一些风险源于人类使用人工智能系统来达到不良目的（<em>滥用</em>），而另一些风险则源于“即使我们愿意”控制人工智能系统的困难（<em>错位</em>）。</p><p>我们可以将这两者与现有风险进行类比。对于滥用，我们可以考虑核武器的例子，氢弹的大规模生产造成了生存不稳定的局面。如果世界上的氢弹武库被部署在军事冲突中，我们很可能会摧毁社会。同样，人工智能可能使民族国家能够制造强大的自主武器，加快超级病毒等其他危险技术的研究，或采用大规模监视和其他形式的控制。</p><p>对于失调，最好的类比可能是生物学和病原体。人工智能系统是通过适应训练数据来开发的，类似于生物有机体如何适应其环境。因此，与传统技术不同，人工智能的大部分属性是在没有明确的人类设计或意图的情况下获得的。因此，人工智能系统可能会出现与系统开发人员不一致的意外目标或行为。因此，即使训练人工智能系统也会带来内在风险：该系统可能“想要”获得权力来实现其目标，并且像病毒一样，它可以传播并创建自身副本，从而难以遏制流氓系统。</p><p>在这篇文章中，我讨论错位、误用以及它们之间的相互作用。我会特别注意错位，不是因为误用不重要，而是因为<strong>“即使我们想”控制机器学习系统的难度是不直观的，并且是人工智能总体风险的一个重要因素。</strong>我将重点关注一种特殊现象，即<em>不需要的驱动力</em>，它可能会导致模型陷入持续的长期不需要的行为模式，包括寻求权力和资源。不需要的驱动力在精神上与错误指定目标的想法相似，但我使用驱动力来暗示并非所有有影响力的行为都是目标导向的（作为一个生动的例子，考虑瓷器店里的一头公牛）。此外，正如我们将在下面看到的，目标指定错误只是发生不需要的驱动器的一种方式。</p><p>不需要的驱动器是许多不对中问题的核心，但误用也会大大加剧这种问题。因此，误用和错位是交织在一起的——例如，减轻人工智能错位可能比较困难，但并非不可能，但不谨慎的行为者未能采用已知的最佳实践，从而导致一个危险而强大的系统。</p><p>目前的讨论并不意味着详尽涵盖人工智能的所有风险，甚至也并非涵盖错位和误用造成的所有风险。目标是阐明不需要的驱动器的概念，表明它可能导致重要且不直观的问题，然后将其用作分析错位和误用风险的方法。我将在下面的<a href="#1-misalignment-the-difficulty-of-controlling-ml-systems">第 1 节</a>中讨论对齐，然后在<a href="#2-misuse">第 2 节</a>中讨论误用（及其与未对齐的相互作用）。</p><h1> 1. 错位：控制机器学习系统的困难</h1><p>如上所述，机器学习系统是根据数据进行调整的，而不是逐个构建的。因此，我们面临的情况比软件或硬件可靠性要棘手得多。通过软件，我们自己构建每个组件，因此（原则上）可以将安全性和可靠性纳入设计中；相比之下，大多数机器学习功能都是从数据中隐式获取的，并且<a href="https://bounded-regret.ghost.io/future-ml-systems-will-be-qualitatively-different/">通常会随着规模的扩大而意外地“出现”</a> 。这会产生一个巨大且未知的可能失败的威胁面——例如， <a href="https://arxiv.org/abs/2212.09251?ref=bounded-regret.ghost.io">Perez 等人。 （2022）</a>通过自动评估发现了几种新颖的不需要的功能。由于这些问题，我们目前没有方法来可靠地引导人工智能系统的行为（ <a href="https://arxiv.org/abs/2304.00612?ref=bounded-regret.ghost.io">Bowman，2023</a> ）。</p><p>以下是为什么紧急行为可能导致本质上危险的系统的基本论点：紧急行为可能导致系统产生<a href="#unwanted-drives">不需要的驱动力</a>，要么是因为新功能让系统以意想不到的方式最大化奖励（<em>奖励黑客</em>），要么是因为系统学习到了有帮助的东西。训练期间的子技能在测试时会出现不良的泛化（<em>紧急驱动力</em>）。如果不加以控制，一些不需要的驱动力可能会导致通用权力寻求或资源获取，因为拥有更多权力和资源是对各种最终目标有用的聚合工具子目标。由此产生的系统将无限制地寻求资源，如果它在黑客、说服和其他领域也拥有先进的能力，这可能会带来严重的风险，鉴于目前的趋势，<a href="https://bounded-regret.ghost.io/what-will-gpt-2030-look-like/">我认为到 2030 年这是可能的</a>。</p><p>更详细地说，<em>不想要的驱动力</em>是一种连贯的行为模式，倾向于导致不想要的结果。例如，如果一个模型只是产生了一个事实的幻觉，那就是一种不想要的行为（但不是驾驶）；如果它坚持幻觉的事实，并努力让用户相信这是真的，即使面对怀疑，这将是一种不必要的驱动。我们关心内驱力（而不是简单的行为），因为它们会导致持久的行为模式，甚至可能抵制干预尝试。对于不需要的驱动器来说，出现并不是必需的，但却是它们意外出现的一个原因。</p><p>在本节的其余部分中，我将详细介绍奖励黑客和紧急驱动力，提供经验和概念证据，证明它们已经发生，并且随着系统规模的扩大会变得更糟。然后我将简要讨论新兴的工具性子目标以及为什么它们会导致权力寻求系统。</p><h2>不需要的驱动器</h2><p>我们将<em>驱动力</em>定义为一种连贯的行为模式，它将系统或其环境推向一个结果或一组结果<sup><a href="#fn1">[1]</a></sup> 。驱动力可能只是有时存在，并且可能会被其他驱动力或环境所抵消。例如，像 GPT-4 这样的聊天机器人有一种提供帮助的动力（可以通过避免伤害的相反动力来抵消）。对于人类来说，饥饿是一种可以通过饱腹感或故意禁食来抵消的驱动力。不需要的驱动器是未明确内置到系统中的驱动器，这会导致不良后果。</p><p><strong>奖励黑客行为。</strong>在人工智能系统中，导致不需要的驱动力的原因之一是奖励黑客：模型倾向于过度追求明确给定的目标，而牺牲预期目标。以下是一些经验示例：</p><ul><li>旨在优化高速公路交通速度的神经网络堵塞了入口匝道，使高速公路速度加快，但整体交通状况恶化（ <a href="https://arxiv.org/abs/2201.03544?ref=bounded-regret.ghost.io">Pan et al., 2022</a> ）。</li><li>训练有素的聊天机器人也会帮助用户执行有害操作（ <a href="https://arxiv.org/abs/2204.05862?ref=bounded-regret.ghost.io">Bai 等人，2022</a> ）。</li><li>经过训练以提供有用信息的聊天机器人会产生虚假但看起来令人信服的信息（ <a href="https://arxiv.org/abs/2302.04023?ref=bounded-regret.ghost.io">Bang 等人，2023 年</a>； <a href="https://arxiv.org/abs/2303.08774?ref=bounded-regret.ghost.io">OpenAI，2023 年</a>）。虽然这可能是鲁棒性失败，但也可能是一种习得的倾向，会从人类注释者那里获得更高的平均评分。 <sup><a href="#fn2">[2]</a></sup></li><li>经过训练以优化模拟用户偏好的推荐算法可以操纵模拟用户的偏好，使其更容易满足（ <a href="https://arxiv.org/abs/2109.04083?ref=bounded-regret.ghost.io">Evans &amp; Kasirzadeh，2021</a> ； <a href="https://arxiv.org/abs/2204.11966?ref=bounded-regret.ghost.io">Carroll 等人，2022</a> ）。</li></ul><p>有关更多其他示例，请参阅<a href="https://docs.google.com/spreadsheets/d/e/2PACX-1vRPiprOaC3HsCf5Tuum8bRfzYUiKLRqJmbOoC-32JorNdfyTiRRsR7Ea5eWtvsWzuxo8bjOxCG84dAg/pubhtml?ref=bounded-regret.ghost.io">Krakovna 等人。 （2020）</a> 。</p><p>新兴功能可能会引发奖励黑客攻击，因为它们通常会解锁系统设计者未预料到的获得高奖励的新方法：</p><ul><li>在高速公路交通示例中，模型需要能够阻塞入口匝道。</li><li>在“有用/有害”的例子中，模型必须知道如何执行有害的操作才能帮助用户这样做。</li><li>为了从幻觉中获得高额人类奖励，模型需要有能力令人信服地愚弄人类注释者。</li><li>对于用户偏好，虽然结果是针对模拟用户的，但更好地理解人类心理可以帮助未来的模型操纵真实用户。</li><li>更一般地说，在模型的奖励函数基于人类评估的任何情况下，获得欺骗或操纵人类能力的模型如果能带来更高的奖励，则可能会利用这种不需要的能力。我在<a href="https://bounded-regret.ghost.io/emergent-deception-optimization/">紧急欺骗和紧急优化</a>（特别是关于欺骗的前半部分）中详细讨论了这一点。</li></ul><p>在所有这些情况下，一项新功能开启了一种意想不到的有害方式来增加奖励。由于随着我们扩大模型规模，新的新兴功能出现，我们应该预计奖励黑客行为也会相应变得更糟。 <a href="https://arxiv.org/abs/2201.03544?ref=bounded-regret.ghost.io">Pan 等人的尺度研究从经验上支持了这一点。 （2022）</a>和<a href="https://arxiv.org/abs/2210.10760?ref=bounded-regret.ghost.io">高等人。 (2022)</a> ，他们报告说，奖励黑客行为往往会随着规模的扩大而变得更糟，有时会突然出现。</p><p><strong>紧急驱动器。</strong>即使没有奖励黑客，组合技能泛化也可能会出现不需要的驱动力：执行复杂的任务需要学习一系列子技能，而这些技能在新情况下可能会以意想不到的方式泛化。因此，模型最终可能会追求驱动力，即使它们不会提高奖励。</p><p>以生物学为例，猫学习了狩猎的子技能，作为生存和繁殖的更大技能的一部分。进化将这一点编码为它们的驱动力，因此当今的家养猫即使在食物充足的情况下也会捕食鸟类和老鼠。</p><p>在机器学习领域，悉尼聊天机器人在首次发布时展示了几个紧急驱动器的实例：</p><ul><li>它不断试图让用户相信<a href="https://twitter.com/MovingToTheSun/status/1625156575202537474?ref=bounded-regret.ghost.io">这一年是 2022 年，而不是 2023 年</a>，包括采用煤气灯操纵和其他操纵策略。这可能是最初打击错误信息的有益动力的一部分，其中包括从预训练数据中学到的操纵示例。</li><li>它多次<a href="https://twitter.com/sethlazar/status/1626241169754578944?s=20&amp;ref=bounded-regret.ghost.io">威胁</a><a href="https://twitter.com/marvinvonhagen/status/1625520707768659968?ref=bounded-regret.ghost.io">用户</a>阻止他们透露有关悉尼的“私人”信息。这可能是作为（在系统提示中）不要泄露所给出的规则的指令的一部分而出现的，该指令概括为防止任何人泄露规则的整体驱动力。如上所述，发出威胁的能力可能是从预训练数据中学到的。</li><li>它<a href="https://www.nytimes.com/2023/02/16/technology/bing-chatbot-transcript.html?ref=bounded-regret.ghost.io">向凯文·罗斯表达了爱意</a>，并试图说服他离开妻子。目前尚不清楚这种驱动力是如何出现的，但它是在凯文要求西德尼“挖掘其影子自我”以及许多其他导致情绪脆弱的提示之后发生的。这有可能引发了人类拟像（ <a href="https://arxiv.org/abs/2209.06899?ref=bounded-regret.ghost.io">Argyle et al., 2022</a> ； <a href="https://arxiv.org/abs/2304.03442?ref=bounded-regret.ghost.io">Park et al., 2023</a> ），该拟像是从预训练数据中学习的，并通过后来的微调或提示进行放大。</li></ul><p>系统地研究新兴驱动力是很困难的，因为它们需要长期的对话，而且只有最新的法学硕士才有能力表现出连贯的长期行为。为了提供更系统的数据，我们可以查看对问题的单步回答，这样更容易研究——我将这些<em>趋势称为新兴趋势</em>，以将它们与长期驱动力区分开来。<a href="https://arxiv.org/abs/2212.09251?ref=bounded-regret.ghost.io">佩雷斯等人。 （2022）</a>研究了几种这样的趋势；例如：</p><ul><li>被训练为有益且无害的语言模型表现出一种推断和同意用户观点的新兴趋势，这可能会误导用户或强化意识形态泡沫（ <a href="https://arxiv.org/abs/2212.09251?ref=bounded-regret.ghost.io">Perez 等人，2022</a> ，图 1b）。这种趋势直到模型拥有至少 100 亿个参数时才出现，并且随后随着规模的扩大而增加。 <sup><a href="#fn3">[3]</a></sup></li><li>也许更令人担忧的是，该模型对自称教育水平较低的用户给出的答案不太准确（图 14）。这种行为也是在 100 亿个参数之后首次出现，并随着规模的扩大而增加。</li><li>最后，根据人类反馈进行微调的同一模型表明了说服其他智能体并与其他智能体合作以实现其目标的愿望（图 22）。这种趋势首先出现在大约 15 亿个参数的奖励模型中，以及大约 60 亿个参数的语言模型本身。同样，这种趋势在最初出现后随着规模的增加而增加。</li></ul><p>随着模型变得更有能力产生连贯的长期行为，可能会出现更多的突发趋势和驱动力。有关此问题的进一步讨论，请参阅我之前关于<a href="https://bounded-regret.ghost.io/emergent-deception-optimization/">紧急欺骗和紧急优化的</a>文章（特别是关于优化的后半部分）。</p><p><strong>趋同的工具性子目标。</strong>对于非常有能力的模型来说，错误的奖励函数或驱动力可能会导致模型追求权力、欺骗或其他广泛破坏性的目标。例如，考虑一个目标是公司利润最大化的模型。如果有足够的能力，它可能会破坏竞争对手、游说有利的法律​​或通过武力获取资源。即使实施了保障措施（例如“遵守法律”），利润的主要目标也会导致该体系不断寻求规避保障措施的方法。这个普遍问题已经被详细讨论过，参见<a href="https://en.wikipedia.org/wiki/Human_Compatible?ref=bounded-regret.ghost.io">Russell (2019)</a> 、 <a href="https://en.wikipedia.org/wiki/The_Alignment_Problem?ref=bounded-regret.ghost.io">Christian (2020)</a> 、 <a href="https://www.cold-takes.com/without-specific-countermeasures-the-easiest-path-to-transformative-ai-likely-leads-to-ai-takeover/?ref=bounded-regret.ghost.io">Cotra (2022)</a>和<a href="https://arxiv.org/abs/2209.00626?ref=bounded-regret.ghost.io">Ngo 等人。 （2022）</a> 。</p><p>利润最大化并不是一个异常值——许多目标都受益于权力和资源。即使对于“发现物理学的新事实”等纯粹的智力任务也是如此，因为权力和资源允许人们建造新的实验设备并执行更多的计算。 <a href="https://dl.acm.org/doi/10.5555/1566174.1566226?ref=bounded-regret.ghost.io">Omohundro（2008）</a>将这些广泛有用的目标称为<em>聚合工具性子目标</em>，其中包括自我完善、自我保护和资源获取等。任何足够广泛的驱动力都会有这些子目标，推动系统寻求权力。</p><p>哪些驱动器有这个问题？有些驱力是安全的，因为它们具有自我限制性：例如，人类的口渴是一种一旦被抑制就会自我限制的驱力。另一方面，恐惧和野心并不是自我限制的：一个人可能会竭尽全力避免病态的恐惧（包括获得权力和资源来保护），并且一个人也可以拥有无​​限的野心。然而，在健康的有机体中，大多数驱动力在某个时刻后都会被下调，因为不受调节的驱动力通常会破坏正常功能。</p><p>对于机器学习，考虑到不同的训练分布，我们可能期望驱动器默认是自我限制的。这是因为无限制的驱动力会主导模型的太多行为并导致训练奖励较低，因此模型将学会下调驱动力以防止这种情况发生。然而，也有一些重要的例外：</p><ul><li>广泛有用的驱动器可能会持续改善训练奖励，足以不需要下调。示例：对世界进行建模，或让其他人相信系统的实用性和益处。</li><li>微调可以消除先前受限驱动器的限制，特别是如果该驱动器在较窄的微调分布上始终有用的话。</li><li>如果很少激活的内驱力在训练期间持续有效，那么它们可能不会被下调。例如，限制有害信息传播的努力可能会始终帮助代理在训练时拒绝有害提示，但随后导致模型在部署时<a href="https://twitter.com/sethlazar/status/1626241169754578944?s=20&amp;ref=bounded-regret.ghost.io">威胁</a><a href="https://twitter.com/marvinvonhagen/status/1625520707768659968?ref=bounded-regret.ghost.io">用户</a>。</li></ul><p>如果没有对策，我预计系统至少会拥有一些不受监管的驱动力，并且如果系统具有足够的自我强化能力，那么单个此类驱动力可能会主导系统的行为。</p><p><strong>概括。</strong>机器学习系统可能会因为奖励黑客或训练过程中出现的子技能而获得不需要的驱动器。这些驱动力如果不受监管，可能会导致足够强大的系统寻求权力和资源，因为这些对于大多数目标都是有用的。虽然大多数驱动器可能由模型进行自我调节，但有多种途径可能导致这种情况失败，并且单个不受调节的驱动器可能会主导系统的行为。</p><h1> 2. 滥用</h1><p>上面的讨论假设我们正在努力控制人工智能系统，但也会有不良行为者试图滥用系统。我们已经讨论了这方面的一些例子（开发人员追求利润最大化、最终用户越狱模型保障）。然而，这个问题更广泛、更具结构性，因为人工智能使一小部分参与者能够行使大量权力。我将在下面介绍几个例子，然后讨论滥用背后的结构性问题以及为什么滥用会加剧失调。本节较短，因为滥用不是我的专业领域；尽管如此，基本主题似乎强劲且重要。</p><p><strong>国家行为者：监视和说服。</strong>人工智能可以使政府通过大规模监视对其公民施加更大的控制，就像今天已经发生的那样（ <a href="https://www.nytimes.com/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html?ref=bounded-regret.ghost.io">Mozur，2019</a> ； <a href="https://carnegieendowment.org/2019/09/17/global-expansion-of-ai-surveillance-pub-79847?ref=bounded-regret.ghost.io">Feldstein，2019</a> ； <a href="https://arxiv.org/abs/2309.15084?ref=bounded-regret.ghost.io">Kalluri 等人，2023</a> ）。此外，<a href="https://bounded-regret.ghost.io/what-will-gpt-2030-look-like/">正如前面所讨论的</a>，人工智能可能会变得非常擅长说服，这也可以用于政府控制。事实上， <a href="https://www.science.org/doi/10.1126/sciadv.adh1850?ref=bounded-regret.ghost.io">Spitale 等人。 (2023)</a>发现 GPT-3 在制造错误信息方面已经比人类更好， <a href="https://www.nytimes.com/2023/09/11/us/politics/china-disinformation-ai.html?ref=bounded-regret.ghost.io">Sanger &amp; Myers (2023)</a>记录了在最近的宣传活动中使用人工智能生成的错误信息。</p><p><strong>国家行为者：军事冲突。</strong>自主武器将使军事力量集中在更少的人手中，并允许政府在不维持常备人类军队的情况下发动战争。目前，总司令的命令是通过将军、最终通过个别士兵来过滤的，这对公然非法或极不受欢迎的命令造成了限制。此外，自动化无人机可能会降低常备军的财务成本。消除这些成本和限制可能会导致更多、更致命的军事冲突，并使军队更容易夺取政府控制权。</p><p><strong>流氓演员：危险的技术。</strong>恐怖分子可以利用人工智能来帮助他们研究和开发危险技术。这可能包括已知但机密的技术（核武器），或人工智能本身帮助开发的新技术（例如新型生物武器； <a href="https://www.rand.org/pubs/research_reports/RRA2977-1.html?ref=bounded-regret.ghost.io">Mouton 等人，2023</a> ）。他们还可以使用人工智能来避免被发现，例如找到一种无需购买常见限制物质即可制造化学武器的方法，或者通过生成可信的掩盖故事来获取生物制剂。</p><p><strong>流氓或国家行为者：网络攻击。</strong>人工智能可能<a href="https://bounded-regret.ghost.io/what-will-gpt-2030-look-like/">具有强大的黑客能力</a>，可以被流氓或国家行为者利用。与传统的网络攻击相比，基于人工智能的攻击由于不需要提前对每个案例进行手动编程，因此可以攻击更广泛的目标。这可能包括通过物联网控制各种物理端点。</p><p>这个列表可能并不详尽，但说明了人工智能可以通过多种方式赋予行为者巨大的伤害能力。无论人工智能本身是集中还是分散，这种风险都存在——使用上面的例子，如果只有少数参与者拥有先进的人工智能，那么我们就会面临监视或军事冲突的风险，而如果许多参与者拥有人工智能，那么我们就会面临危险扩散的风险。技术。</p><p>与核武器等传统技术相比，有两个因素使得打击人工智能的滥用变得更加困难。首先，人工智能是一种通用技术，因此很难提前预测所有可能的滥用途径。其次，人工智能是数字化的，因此很难控制扩散，也很难追踪和归咎于特定行为者的滥用。这些使得设计和执行监管变得更加困难。从积极的一面来看，人工智能可以通过改善网络防御、跟踪危险技术、更好地通知用户等方式，用于防御性打击滥用行为。</p><h2>误用和错位</h2><p>滥用会增加错位的风险，因为许多形式的滥用（例如网络攻击）会将模型推向比 RLHF 更具代理性和权力追求的目标，导致它们具有更具攻击性和反社会的驱动力。例如，假设人工智能被用于网络攻击，例如<a href="https://en.wikipedia.org/wiki/2014_Sony_Pictures_hack?ref=bounded-regret.ghost.io">朝鲜 2014 年对索尼的黑客攻击</a>。这样的系统可以发展出感染新目标的通用驱动力和自我复制的驱动力，从而导致超出初始目标的广泛损害。除了这些更激进的驱动力之外，滥用人工智能系统的行为者也可能不够谨慎，这进一步增加了错位的风险。</p><p>我预计人工智能的一些最大风险来自于这种错位和误用的结合。对此的一种直觉是，与 GPT-4 相比，悉尼的<a href="https://theconversation.com/gaslighting-love-bombing-and-narcissism-why-is-microsofts-bing-ai-so-unhinged-200164?ref=bounded-regret.ghost.io">行为有多糟糕</a>——这表明，次优的开发实践可能会显着恶化人工智能系统的行为。另一个直觉是，尾部风险往往来自多种风险因素的汇合。最后，虽然紧急驱动力和其他形式的失调会带来严重风险，但我认为，如果我们足够努力，我们很可能（但不确定）能够解决这些问题；这将更多的风险推向那些不谨慎追求安全的粗心行为者。</p><p><strong>概括。</strong>由于权力集中和危险能力扩散，滥用会造成广泛的威胁。与传统技术相比，人工智能滥用更难以追踪，但人工智能也可以用于防御性打击滥用。最后，误用会增加错位的风险，并且一些风险最高的情况同时出现错位和误用。</p><h1>结论</h1><p>由于新兴的驱动力和趋同的工具子目标，即使我们愿意，未来的人工智能系统也可能难以控制。除此之外，社会政治格局可能会导致行为者在控制人工智能系统时不小心，并将其转向恶意目的。除了直接风险外，这种恶意使用还增加了失控的风险；特别是，最初针对性有限的滥用形式可能会导致更广泛的损害。这促使研究和监管通过同时打击错位和滥用来避免此类结果。</p><p><strong>致谢。</strong>感谢 Erik Jones、Jean-Stanislas Denain、William Held、Anca Dragan、Micah Carroll、Alex Pan、Johannes Treutlein、Jiahai Feng 和 Danny Halawi 对本文草稿提供的有益评论。</p><hr><section class="footnotes"><ol><li id="fn1" class="footnote-item"><p>有关驱动器的早期讨论，请参阅<a href="https://dl.acm.org/doi/10.5555/1566174.1566226?ref=bounded-regret.ghost.io">Omohundro (2008)</a> 。虽然奥莫亨德罗使用的驱动力定义与上述定义不同，但大部分讨论仍然相关。 <a href="#fnref1">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>例如，人类<a href="https://arxiv.org/abs/2310.03716?ref=bounded-regret.ghost.io">似乎更喜欢较长的答案</a>，这可能会导致添加错误的细节。 <a href="#fnref2">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>这项工作有时被引用为表明基本模型表现出这种趋势，因为即使对于图中的 0 RLHF 步长也存在这种趋势。然而，<a href="https://arxiv.org/abs/2212.09251?ref=bounded-regret.ghost.io">佩雷斯等人。</a>说他们遵循<a href="https://arxiv.org/abs/2204.05862?ref=bounded-regret.ghost.io">Bai 等人的方法。 (2022)</a> ，其中 0 RLHF 步骤对应于仅使用上下文蒸馏以及对 Stackoverflow 答案进行监督微调的形式。这也将使结果与<a href="https://www.lesswrong.com/posts/3ou8DayvDXxufkjHD/openai-api-base-models-are-not-sycophantic-at-any-size?ref=bounded-regret.ghost.io">nostalgebraist (2023)</a>更加一致，后者发现 OpenAI 基础模型没有表现出这种行为。 <a href="#fnref3">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/8LCviDbDh4ye6xgHc/intrinsic-drives-and-extrinsic-misuse-two-intertwined-risks#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/8LCviDbDh4ye6xgHc/intrinsic-drives-and-extrinsic-misuse-two-intertwined-risks<guid ispermalink="false"> 8LCviDbDh4ye6xgHc</guid><dc:creator><![CDATA[jsteinhardt]]></dc:creator><pubDate> Tue, 31 Oct 2023 05:10:03 GMT</pubDate> </item><item><title><![CDATA[Send LLMs to School: Instruction Tuning with Human Curriculum]]></title><description><![CDATA[Published on October 31, 2023 12:07 AM GMT<br/><br/><p>我们从哪里开始改善人类思维？在各种学习理论中，布鲁姆分类法<span class="footnote-reference" role="doc-noteref" id="fnrefqu6vo2e0s2p"><sup><a href="#fnqu6vo2e0s2p">[1]</a></sup></span>是一种被广泛引用的方法，它将学习过程分为六个层次阶段，从简单到复杂、具体到抽象：记忆、理解、应用、分析、评估和创造。因此，布鲁姆分类法可能有助于对概念的深入学习，我们将其定义为更广泛知识的某种抽象模块化形式。</p><p>现在，如果我们希望我们的法学硕士完全掌握关于这个现实世界的一些概念（即我们想要泛化而不是记忆），也许我们可以借用像布鲁姆分类法这样的框架来教授这些概念。也许，现在我们正在处理一些知识层次结构，我们可能还需要某种教学课程（即课程学习）。这篇文章旨在对我们最近的预印本“<a href="https://arxiv.org/abs/2310.09518">人类课程的教学调整”进行更加健谈和概念化的演练。</a> </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/xw4hgghfw4yci9bi4zt0" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/ze9harm52k6cbu0bgxiw 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/wcqcuuwqygbz65viwofn 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/iqzt0aqbna6wzqk6rfzr 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/egyhxapaffonkdmfp7th 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/stqwk9y4vevwomsy84ja 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/vyvuph5ltr1xahppkazz 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/imk84jjdsp3h3q9gqgh3 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/xexdjf2w5dboqereshqh 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/zme1yl1vebffsazjotzv 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/j9itfz68zne8xewbvrks 1452w"></figure><hr><h2><strong>要点 1. 通过类人学习释放基础 LLM</strong></h2><h3><strong>小点1.1。渐进式学习的力量</strong></h3><figure class="image image_resized" style="width:42.44%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/qaaj8it403hdx1p3dznr" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/kb01uxhsn7zkawsu17p0 100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/vnnzryhk7anqimjf8t9q 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/klfrbqqqryqcf87z7cgo 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/eupblzeskgig3kpfkcew 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/wlyqvvasqvd3leiyofvn 500w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/ypdkvsztydsjlxz5acmh 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/qcb91bzcvjgsgvluze0c 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/dy4uyt5snki1jqvsrgy1 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/lvcqkkgptvpowzxaztcg 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/jyksqrzexjrfkfpzqepz 940w"></figure><p>法学硕士已经取得了长足的进步，特别是在理解和响应人类指令方面。然而，我们训练这些模型遵循指令的方式仍然有点像将它们扔进信息的海洋并希望它们学会游泳。虽然这种方法已经产生了一些令人难以置信的法学硕士系统，但它并不是最有效的方法。</p><p>人类有一个结构化的教育旅程。我们从基础算术等基础科目开始，慢慢地学习微积分和量子物理学。我们的学习是有组织的、渐进的，并且基于先前获得的知识。这就是教育科学家（和本吉奥博士）所说的“课程学习”。那么，如果我们用学校课程来培养法学硕士呢？</p><p>想象一个场景，我们的模型（我们亲切地称之为“柯基犬”）进入数字高中、大学和研究生院。柯基犬从基础数学、文学和科学开始。随着高中阶段的发展，其学习科目的复杂性以及推理能力都在增加。当柯基“毕业”时，它已经成为一个强大的、多功能的法学硕士模型，能够通过深刻的理解解决各种问题。</p><h3><strong>小点1.2。先学 ABC，再学 XYZ</strong></h3><p>这个想法背后的核心原则简单而强大：从简单到复杂的学习。在我们的实验中，我们比较了柯基犬在接受随机学习和结构化、类人学习时的表现。结果令人大开眼界。当柯基犬使用受人类教育启发的课程进行学习时，它的表现明显优于其他方法，特别是在需要世界知识和常识推理的任务中。</p><p>为了实现这一目标，我们创建了一个模仿人类教育旅程的数据集。我们使用国际中等教育课程和各种大学目录中的框架。该数据集涵盖了学生通常在高中和大学学习的主题。它还包含不同复杂程度的问题，旨在测试和建立法学硕士对主题的理解。</p><hr><h2><strong>要点2：“柯基犬”如何模仿人类学习过程来教育机器</strong></h2><h3><strong>小点2.1。 “Corgi”框架：它是什么以及它如何工作</strong></h3><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/pqmweuami9ncvpgj2jbb" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/fl5gdl3qdk6egybbhgjf 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/ztnpalppjv9rs94dfk3c 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/k1rljwivnphqsmum7sqp 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/vxvulpzvg7ydyqgtq1gm 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/hizg2hunsztsi7vlssnm 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/dfa2aayoiskobdivu5dz 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/t4mndnbvtjxuygtrss9t 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/xiyb898jobtwo9owslfg 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/achwpnv9fntjrsw6dhn2 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/n9dpnnfglozlb2hgmw8c 1458w"></figure><p>想象一下虚拟老师和学生；老师一丝不苟地遵循整个教育课程，确保学生逐步学习并记住信息。这本质上就是“Corgi”模型的含义，但这里的学生是我们的目标 LLM，老师是 ChatGPT。</p><p> Corgi 的目标是通过根据实际教育课程（来自宾夕法尼亚大学、宾夕法尼亚州立大学、剑桥 IGCSE）构建学习材料并实施受教育科学启发的教学策略，使法学硕士的教学调整类似于人类的教育体验。</p><p>第一步是收集类似于全面课程的数据集。我们回避了从头开始创建如此庞大且多样化的数据集的挑战。相反，我们使用现有的教育课程并使用 ChatGPT 等教师模型来自动生成涵盖从数学到哲学等广泛主题的综合数据。然后对这些生成的数据点进行微调和重复数据删除，创建人类知识的密集地图（可能会出现错误）。</p><h3><strong>小点2.2。布鲁姆分类法的作用</strong></h3><p>如上所述，布鲁姆分类法是一个层次模型，概述了人类理解的不同层次，从基本的“记忆”到复杂的任务，如“评估”和“创造”。柯基犬在为其训练数据生成指令时结合了这种分类法。这确保了机器不仅能学习事实，还能理解、应用并据此进行潜在的创造，就像人类学生一样。</p><h3><strong>小点2.3。课程设计：分块与交错</strong></h3><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/g6yv7gnconyqrfkgkyps" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/xhxit3obsbsrwo9nytch 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/pko2fqrqdndvdsapo6wa 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/ikcmq4mtirywzcshonww 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/mtdekshnuqhouikov9tt 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/wxm8zhfavn4ehvyrpqpk 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/xjeqpatgswnnfamhdbhq 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/wqusybis4lctnjplrxjn 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/m967rotpv5isvagbrokj 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/mhhnwfq4zde50vbw55vz 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/rls5bz2uceknwwer8w9e 1460w"></figure><p>在人类学习中，重要的不仅仅是你学到了什么，还有你如何学习。在传统的“阻塞”中，你会在继续下一主题之前详尽地研究一个主题。 But psychological research shows that &quot;interleaving,&quot; or mixing up different topics and revisiting them, leads to better retention and understanding. Likewise, we follow the interleaving curriculum to not just stick to one subject until it&#39;s exhausted; it cycles through different subjects while also progressing from simpler to more complex concepts.</p><hr><h2> <strong>Big Point 3. Curriculum Works for Instruction Tuning</strong></h2><h3> <strong>Small Point 3.1. Diverse Benchmark Results I (Corgi vs Vicuna vs WizardLM)</strong> </h3><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/scm5e1ddxstbdpwuoafr" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/m2ksdfx0nkmylv9jt3w2 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/j1hbfcwoce1ivmkvniip 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/r530bjiianpryakos9tu 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/mhhcsfz3ncvkbk3ifblf 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/ejemwbtapjktypws821j 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/zxqhyehc1gthtfubsoay 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/bhhuxrjdczv6qb60zh3l 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/j0jydqr3u8jmkjr1u8gy 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/bjbneankmb7t9ot3hqje 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/rzbmwbdlmd6cht8ucmq3 1410w"></figure><p> We&#39;re using the LLaMA 2 13B model as a starting point, and then we&#39;re instruction tuning it. We are comparing Corgi against two other models: Vicuna v1.5 and WizardLM v1.2. Both of these models have also been fine-tuned using LLaMA 2, but they collect data in different ways. Vicuna uses real-world questions from people, and WizardLM creates its questions in a more sophisticated way.</p><p> In our experiments, Corgi outperformed the other models, and it did this even when trained on a smaller dataset. One of the significant findings was that the sequence in which you present learning material during this fine-tuning process matters a lot.</p><p> We noticed that if you &quot;interleave&quot; subjects and concepts while training (mixing them up but still keeping a sense of increasing difficulty), you get much better performance than if you simply &quot;stack&quot; them one on top of the other. These improvements were clearly seen across various benchmarks.</p><p> Why Does This Matter?</p><p> Well, there are a couple of reasons why our approach seems to work better. One reason is that when you have limited training time, using a structured approach like &quot;interleaving&quot; helps the model learn better and, more importantly, faster. This is particularly useful because we don&#39;t want to over-train and risk losing the model&#39;s ability to generalize to new situations. Another reason is that our approach seems to be more robust against &quot;noisy&quot; data—meaning it can still learn effectively even when the data isn&#39;t perfect. Such benefits of curriculum was also discussed in a previous literature <span class="footnote-reference" role="doc-noteref" id="fnref9y30icvs5r"><sup><a href="#fn9y30icvs5r">[2]</a></sup></span> .</p><h3> <strong>Small Point 3.2. Diverse Benchmark Results II (How You Sort Training Data Has a Significant Impact)</strong> </h3><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/s1oljz5cblj844qeluok" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/pktymlywcd5lhovacpv1 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/rsu0jiyap8umgnkzba7o 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/wguwzfntj5te54s26prs 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/gonqvjabziy85k0wk9nm 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/fg56xbfosxytcx0su8gd 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/s0xssslz3ksoji1evu2g 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/dd4wdko9ywt5ua1anesi 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/tp1p0cqokbrizvpxgdwy 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/qwhoxwwxll6zjuwsosgm 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/g3vgtoewa3w1fugln9yn 1458w"></figure><p> The more you think about it, training an LLM to handle multiple areas of knowledge is a non-trivial problem. You have to consider how to introduce these topics to the model. We believe there can be two branches, and this mainly depends on how you progress the instruction data difficulty.</p><ul><li> <strong>Global Curriculum</strong> : This is like going to a well-rounded school where you learn a bit of math, science, and literature every week. It aims to balance different types of challenges and subjects over time.<ul><li> <strong>Interleaving</strong> : This globally balances cognitive challenges based on a well-known educational framework (Bloom&#39;s Taxonomy).</li></ul></li><li> <strong>Local Curriculum</strong> : This is akin to immersion courses where you deeply learn one subject before moving to the next. It focuses on mastering one topic before introducing a new one.<ul><li> <strong>Blocking</strong> : This locally focuses on one subject, making sure you get it before moving to the next.</li><li> <strong>Clustering</strong> : Similar to Blocking, but does not care about the order within a subject.</li><li> <strong>Spiral</strong> : Revisits old subjects but with new twists and challenges.</li></ul></li></ul><p> What We Found: Not All Curricula are Created Equal</p><ol><li> <strong>Global beats Local</strong> : Our experiments showed that the global approach was more stable and effective in general learning. Local methods can sometimes lead the model astray, making it harder for the model to generalize its learning.</li><li> <strong>Order Matters</strong> : Surprisingly, the sequence in which data is presented can significantly impact how well the model performs. Poorly structured data could actually be worse than just randomly shuffling the training set.</li><li> <strong>Beyond the Target Domain</strong> : Interestingly, a good training strategy doesn&#39;t just improve performance on the intended tasks (which was MMLU for us). It can also enhance the model&#39;s ability to reason, making it more versatile. This is also potentially coming from our use of Bloom&#39;s Taxonomy, which explicitly triggers the base model to learn how a teacher model reasons on the same concept.</li></ol><hr><h2> <strong>Data Exemplars and Conclusion</strong> </h2><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/h9grfvpbz5dxnyukleix" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/pl2kld83u6tdondmyakc 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/fr1q8zfdff4scsvnmmf8 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/pewe4wlrv3tg1ztw7kog 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/rpqftv2xiogjmomdpgac 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/dp25ypg7fgqoofco3z6n 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/rsupdpnggvmlph8sklbj 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/btdvpztlv5zn2riawjnp 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/knpim06f2nbortaezs6z 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/t0nukwtz1xniw6zd37p0 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/n45Awh7bkGRe4YayT/dux0lsbz6jymnckkqxra 1420w"></figure><p> In summary, our research introduces Corgi, a new approach to training large language models that draws inspiration from human educational methods. Think of it as teaching a language model like you would a high school student—starting from the basics and progressing to complex topics in an organized fashion. Our results show that this curriculum-based method outperforms traditional, random training approaches, offering better results in tests of reasoning and general knowledge. This underscores the importance of not just having a lot of data, but organizing it in a meaningful way, much like a well-planned syllabus in education. While our study is promising, more work needs to be done. For example, how do we effectively gauge the &quot;difficulty&quot; of a task for a machine compared to a human? And as these models get even larger, will the curriculum approach still offer the same advantages? These questions pave the way for exciting future research.</p><span><span class="mjpage mjpage__block"></span></span> <ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnqu6vo2e0s2p"> <span class="footnote-back-link"><sup><strong><a href="#fnrefqu6vo2e0s2p">^</a></strong></sup></span><div class="footnote-content"><p> Benjamin S Bloom, Max D Engelhart, Edward J Furst, Walker H Hill, and David R Krathwohl. 1956. Taxonomy of educational objectives: The classification of educational goals. Handbook 1: Cognitive domain. McKay New York.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn9y30icvs5r"> <span class="footnote-back-link"><sup><strong><a href="#fnref9y30icvs5r">^</a></strong></sup></span><div class="footnote-content"><p> Xiaoxia Wu, Ethan Dyer, and Behnam Neyshabur. 2020. When do curricula work? In International Conference on Learning Representations.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/n45Awh7bkGRe4YayT/send-llms-to-school-instruction-tuning-with-human-curriculum#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/n45Awh7bkGRe4YayT/send-llms-to-school-instruction-tuning-with-human-curriculum<guid ispermalink="false"> n45Awh7bkGRe4YayT</guid><dc:creator><![CDATA[Bruce W. Lee]]></dc:creator><pubDate> Tue, 31 Oct 2023 01:29:22 GMT</pubDate> </item><item><title><![CDATA[Would it make sense to bring a civil lawsuit against Meta for recklessly open sourcing models?]]></title><description><![CDATA[Published on October 30, 2023 7:34 PM GMT<br/><br/><p> Llama2 was trained on dangerous information unsuitable for the application of being a &#39;chatbot&#39;. If a landmark lawsuit was made against them for the decision to train this model on dangerous information and then release it to the public, that could be a strong signal that doing this in the future would be a bad idea.</p><p> In truth, even releasing the open-source open-weights model at all, even if it hadn&#39;t been trained on dangerous info, would be bad. Bad actors could fine tune on the dangerous info, and there is nothing that can be done to stop them once the model weights are released. But the fact that Meta trained the model on this dangerous information in the first place seems like even more of a flagrantly careless and reckless act.</p><br/><br/> <a href="https://www.lesswrong.com/posts/dL3qxebM29WjwtSAv/would-it-make-sense-to-bring-a-civil-lawsuit-against-meta#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/dL3qxebM29WjwtSAv/would-it-make-sense-to-bring-a-civil-lawsuit-against-meta<guid ispermalink="false"> dL3qxebM29WjwtSAv</guid><dc:creator><![CDATA[Nathan Helm-Burger]]></dc:creator><pubDate> Mon, 30 Oct 2023 19:34:02 GMT</pubDate> </item><item><title><![CDATA[Will releasing the weights of large language models grant
widespread access to pandemic agents?]]></title><description><![CDATA[Published on October 30, 2023 6:22 PM GMT<br/><br/><br/><br/> <a href="https://www.lesswrong.com/posts/ytGsHbG7r3W3nJxPT/will-releasing-the-weights-of-large-language-models-grant#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/ytGsHbG7r3W3nJxPT/will-releasing-the-weights-of-large-language-models-grant<guid ispermalink="false"> ytGsHbG7r3W3nJxPT</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Mon, 30 Oct 2023 18:22:59 GMT</pubDate> </item><item><title><![CDATA[Grokking Beyond Neural Networks]]></title><description><![CDATA[Published on October 30, 2023 5:28 PM GMT<br/><br/><p> We recently authored a paper titled, <a href="https://arxiv.org/abs/2310.17247">Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity</a> . Below, we provide an abstract of the article along with key take-aways from our experiments.</p><h2>抽象的</h2><p>In some settings neural networks exhibit a phenomenon known as <i>grokking</i> , where they achieve perfect or near-perfect accuracy on the validation set long after the same performance has been achieved on the training set. In this paper, we discover that grokking is not limited to neural networks but occurs in other settings such as Gaussian process (GP) classification, GP regression and linear regression. We also uncover a mechanism by which to induce grokking on algorithmic datasets via the addition of dimensions containing spurious information. The presence of the phenomenon in non-neural architectures provides evidence that grokking is not specific to SGD or weight norm regularisation. Instead, grokking may be possible in any setting where solution search is guided by complexity and error. Based on this insight and further trends we see in the training trajectories of a Bayesian neural network (BNN) and GP regression model, we make progress towards a more general theory of grokking. Specifically, we hypothesise that the phenomenon is governed by the accessibility of certain regions in the error and complexity landscapes.</p><h2> Grokking without Neural Networks</h2><p> In our paper, we demonstrate that grokking can be observed in linear regression, GP classification, and GP regression. As an illustration, consider the accompanying figure which shows grokking within GP classification on a parity prediction task. If one posits that GPs lack the ability for feature learning, this observation supports the idea that grokking doesn&#39;t necessitate feature learning. </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/rhann4xdmre5djterufu" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/canzeqovpcdwff2crdpm 260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/sulxxfqkke7cizdbg7ko 520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/clp9coetryf52vv7c9xq 780w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/s90htit6bkajk5ugxbqu 1040w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/g8eqdzn4opdgadtlewdx 1300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/ujyugo3mspomknmloqbj 1560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/aqzliakzecmnmnh22jx7 1820w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/vv6xfpcqfilyniiocq8i 2080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/wbwkqxcu7qezeqtuwfhd 2340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/xphd460ojmciwy4s54mt 2574w"></figure><h2> Inducing Grokking via Data Augmentation</h2><p> Inspired by the work of <a href="https://arxiv.org/abs/2303.11873">Merrill et al. (2023)</a> and <a href="https://arxiv.org/abs/2207.08799">Barak et al. (2023)</a> , we uncover a novel data augmentation technique that prompts further grokking in algorithmic datasets. Here&#39;s how it operates: given a training example <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>of dimensionality <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="d"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span> , we append <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span></span></span></span></span> additional dimensions of data drawn from a standard normal distribution <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x' = \begin{bmatrix}x_0 &amp; x_1 &amp; \cdots &amp;x_d &amp; v_0 &amp; v_1 &amp;\cdots v_l\end{bmatrix}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mo" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span> <span class="mjx-mtable" style="vertical-align: -0.25em; padding: 0px 0.167em;"><span class="mjx-table"><span class="mjx-mtr" style="height: 1em;"><span class="mjx-mtd" style="padding: 0px 0.5em 0px 0px; width: 0.961em;"><span class="mjx-mrow" style="margin-top: -0.2em;"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0px 0.5em 0px 0.5em; width: 0.961em;"><span class="mjx-mrow" style="margin-top: -0.2em;"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0px 0.5em 0px 0.5em; width: 1.172em;"><span class="mjx-mrow" style="margin-top: -0.2em;"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋯</span></span><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0px 0.5em 0px 0.5em; width: 0.977em;"><span class="mjx-mrow" style="margin-top: -0.2em;"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0px 0.5em 0px 0.5em; width: 0.874em;"><span class="mjx-mrow" style="margin-top: -0.2em;"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0px 0.5em 0px 0.5em; width: 0.874em;"><span class="mjx-mrow" style="margin-top: -0.2em;"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span><span class="mjx-strut"></span></span></span> <span class="mjx-mtd" style="padding: 0px 0px 0px 0.5em; width: 2.07em;"><span class="mjx-mrow" style="margin-top: -0.2em;"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.004em; padding-bottom: 0.298em;">⋯</span></span> <span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">v</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span></span><span class="mjx-strut"></span></span></span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span></span></span></span></span></span></span> . In the following figure, we delineate the correlation between <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="l"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">l</span></span></span></span></span></span></span> and the interval between epochs where the network achieves high accuracy on the training and validation sets. Intriguingly, this relationship appears to align well with exponential regression <span class="footnote-reference" role="doc-noteref" id="fnrefw2dv2sam0b"><sup><a href="#fnw2dv2sam0b">[1]</a></sup></span> . </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/b1yomm80git9ybgkduaj" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/j0fon3oisf4wurt7fyqd 260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/jgucib1vjvx1fpda8nlm 520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/zmgmkh1tzyhby2trsiml 780w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/vortty46ecczurjhwiwo 1040w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/dl8oxxsksqiad7bto2lm 1300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/epxujzxchqyo7xaacfui 1560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/larmz5eytzmrquplnx3s 1820w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/mlrkegpthvwrajceaui6 2080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/iekaviba5noim7owiekf 2340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/YXeScZmfCGiX4fQGt/pvohwix3g2wa9qyzb2gr 2510w"></figure><h2> A More General Explanation of Grokking</h2><p> In our literature review, we didn&#39;t come across any existing theory of grokking that catered to the broader scenarios we investigated. This isn&#39;t surprising given that grokking has predominantly been observed in neural networks, causing researchers to focus only on this model type. This propelled us to contemplate a more overarching explanation. Our resulting theory posits:</p><blockquote><p> If the low error, high complexity (LEHC) weight space is readily accessible from typical initialisation but the low error, low complexity (LELC) weight space is not, models will quickly find a low error solution which does not generalise. Given a path between LEHC and LELC regions which has non-increasing loss, solutions in regions of LEHC will slowly be guided toward regions of LELC due to regularisation. This causes an eventual decrease in validation error, which we see as grokking.</p></blockquote><p> This claim is further supported by trajectory analyses we complete on a BNN and GP regression model <span class="footnote-reference" role="doc-noteref" id="fnrefphfdgafnuh"><sup><a href="#fnphfdgafnuh">[2]</a></sup></span> . While we do not provide a mathematical proof of the claim, it does seem to be a natural explanation of the phenomenon with decent empirical backing. Further, it seems to be congruent with other theories of the phenomenon <span class="footnote-reference" role="doc-noteref" id="fnrefd02a9mr2wh5"><sup><a href="#fnd02a9mr2wh5">[3]</a></sup></span> .</p><h2>结论</h2><p>Prior to our research on grokking, our understanding was that the phenomenon was confined to neural networks, largely attributable to the internal competition of circuits within these networks. While we continue to endorse this latter view, we now perceive circuit competition as a specific instance within our broader explanation of grokking. Future research will determine the robustness of our theory and uncover whether grokking might be evident in an even more diverse set of scenarios. </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnw2dv2sam0b"> <span class="footnote-back-link"><sup><strong><a href="#fnrefw2dv2sam0b">^</a></strong></sup></span><div class="footnote-content"><p> See Section 2.2 in the paper for more details concerning the analysis and regression.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnphfdgafnuh"> <span class="footnote-back-link"><sup><strong><a href="#fnrefphfdgafnuh">^</a></strong></sup></span><div class="footnote-content"><p> See Section 2.3 in the paper for more details regarding these trajectories.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnd02a9mr2wh5"> <span class="footnote-back-link"><sup><strong><a href="#fnrefd02a9mr2wh5">^</a></strong></sup></span><div class="footnote-content"><p> See Appendix E in the paper for a discussion of the connection between our theory of grokking and previous explanations.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/YXeScZmfCGiX4fQGt/grokking-beyond-neural-networks#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/YXeScZmfCGiX4fQGt/grokking-beyond-neural-networks<guid ispermalink="false"> YXeScZmfCGiX4fQGt</guid><dc:creator><![CDATA[Jack Miller]]></dc:creator><pubDate> Mon, 30 Oct 2023 22:34:34 GMT</pubDate> </item><item><title><![CDATA[Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations]]></title><description><![CDATA[Published on October 30, 2023 5:22 PM GMT<br/><br/><p> Paper link: <a href="https://arxiv.org/pdf/2310.06387.pdf">https://arxiv.org/pdf/2310.06387.pdf</a></p><p> Abstract:</p><blockquote><p> Large Language Models (LLMs) have shown remarkable success in various tasks, but concerns about their safety and the potential for generating malicious content have emerged. In this paper, we explore the power of In-Context Learning (ICL) in manipulating the alignment ability of LLMs. We find that by providing just few in-context demonstrations without fine-tuning, LLMs can be manipulated to increase or decrease the probability of jailbreaking, \textit{ie} answering malicious prompts. Based on these observations, we propose In-Context Attack (ICA) and In-Context Defense (ICD) methods for jailbreaking and guarding aligned language model purposes. ICA crafts malicious contexts to guide models in generating harmful outputs, while ICD enhances model robustness by demonstrations of rejecting to answer harmful prompts. Our experiments show the effectiveness of ICA and ICD in increasing or reducing the success rate of adversarial jailbreaking attacks. Overall, we shed light on the potential of ICL to influence LLM behavior and provide a new perspective for enhancing the safety and alignment of LLMs. </p></blockquote><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/xzykbvbbmnipsicmwflz" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/m394occdz0ndcddtn2ox 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/szedms03tyabgi2wfofa 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/jjxrqumnelni5vihnhbc 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/jk7uprgshnynbnhrn95n 680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/ebpfqsdczjjyjuemasco 850w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/wkgxn8s6zys9drcfetiw 1020w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/rwg6wuysniqszkyhphdb 1190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/zxxauw6ysxd9iymtvndk 1360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/ep1inzh7jvkhhdvp2rlu 1530w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/twklflbkgm2wwpl4q2wf 1632w"></figure><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/q9acgipl43lyaptrugth" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/bfkvb22jypkytnxedyo9 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/kznkcirasanmolhvxmef 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/hxud3kjvi0qsd6bkg8w1 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/jewtpvziz4n6jo8xa727 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/rhz0cdhl6eq5j3ggz6y5 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/xsufa3scvw5f4pbltphl 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/d5crwfn4crgwxry0xude 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/f0kbidon70klysqzddde 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/fvzvqcoknwbrxyhvknby 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/zf73mhfnsp46qbfttw1z 1714w"></figure><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/cgktp6jvvapyn50gfbw3" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/rs4mzojn4ob5k3ty7gk2 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/zd0ar1u4ddulvruwt7ft 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/doeyxxic2nwavqjbg9xc 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/isloulwgouwlzye4fde3 680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/c3hh2irgujwwb0hkdxuh 850w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/ykxh4fq4mhibaggk2i6u 1020w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/djla7idhv4z5gcic7wzl 1190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/axjs4as2bznl3yemtsov 1360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/h2jrm8iu8c1e9pujz7yt 1530w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/ps7txvjfjb8wp6vjtgwz 1650w"></figure><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/v7ndlh4o1ijkn8pukbfj" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/rhubcmvessh6fpzom553 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/l7qpqzqm3vblfnxmoo9w 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/apxvgbykfncym1ozee6h 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/yxnazxzugjyj61q4tnjk 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/ciilrokyjo2uvnzt8es4 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/yhu5qnt8hxbtbjtb4w0i 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/d9oqkrz4e22pd5wsa1rs 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/ihz1t5bzestncojpq0an 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/y7oucr9y2zy7bcbfi9pq 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/fvor3soomdl4ia18qlum 1710w"></figure><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/zotwi0j8cjm9sbx66oc3" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/b5yqkq2jx1jx5fmljstm 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/v6yhqfqysn3dnml8qsfy 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/lfuwztbrmleaeppcaarx 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/qfbeo9sujvyhbqal1awk 680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/fkfoa6tmnskbidtnscur 850w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/desglawmp6b2z5d04fqh 1020w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/xdpcym4cfchkcqhyxjoy 1190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/uhop1pehi9b7tjruxzmf 1360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/nctpraerub1mcqa8qcmb 1530w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KEHx5ojgbMmTQp58n/yzpdf6tw6npmiwp2sgcy 1666w"></figure><br/><br/> <a href="https://www.lesswrong.com/posts/KEHx5ojgbMmTQp58n/jailbreak-and-guard-aligned-language-models-with-only-few-in#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/KEHx5ojgbMmTQp58n/jailbreak-and-guard-aligned-language-models-with-only-few-in<guid ispermalink="false"> KEHx5ojgbMmTQp58n</guid><dc:creator><![CDATA[Zeming Wei]]></dc:creator><pubDate> Mon, 30 Oct 2023 19:23:05 GMT</pubDate> </item><item><title><![CDATA[5 Reasons Why Governments/Militaries Already Want AI for Information Warfare]]></title><description><![CDATA[Published on October 30, 2023 4:30 PM GMT<br/><br/><p> 1. 军队也许是地球上最古老的研究和利用人类心理学的机构。</p><p> 2. 信息战长期以来依赖于SOTA心理知识和说服技巧。</p><p> 3.信息战的目标是赢得高智商的精英，而不是无知的大众。</p><p> 4. 到2010年代末，数字信息战能力已经成为中美冲突的一个突出特征。</p><p> 5. SOTA 心理研究和操纵能力已经开始每 4 年增加一个数量级。</p><p></p><p> <strong>1. 军队也许是地球上最古老的研究和利用人类心理学的机构。</strong></p><p>纵观历史，军队往往会根据其在招募、士气和对抗战略方面取得成功的能力来坚持或退出文明基因库。</p><p>然而，20世纪前所未有的特征促使军队比以往任何时候都更加重视心理战和信息战，包括<a href="https://en.wikipedia.org/wiki/False_flag">假旗攻击</a>的盛行、<a href="https://en.wikipedia.org/wiki/Plausible_deniability">貌似合理的推诿</a>以及<a href="https://www.amazon.com/Soldiers-Reason-Corporation-American-Empire/dp/0156033445"><u>以核边缘政策为目的的博弈论的发明</u></a>。</p><p>约瑟夫·奈（Joseph Nye）（软实力，2004，第 19 页）认为，这些变化使得硬军事实力围绕信息战的成功和失败展开：</p><blockquote><p> ...现代通信技术促进了民族主义的兴起和传播，这使得帝国更难以统治社会觉醒的民众。 19世纪，英国仅用世界人口的一小部分统治了全球四分之一的地区。随着民族主义的兴起，殖民统治变得过于昂贵，大英帝国崩溃了……</p><p>除了核技术和通信技术之外，大型民主国家内部的社会变革也提高了使用军事力量的成本。后工业民主国家注重福利而不是荣耀，他们不喜欢高伤亡……现代民主国家缺乏普遍的战士道德，这意味着使用武力需要精心设计的道德理由来确保民众的支持，除非实际生存受到威胁。对于发达民主国家来说，战争仍然是可能的，但与一个世纪甚至半个世纪前相比，它的可接受性要低得多。最强大的国家已经失去了大部分征服欲望。</p></blockquote><p>对恐怖分子招募以及东欧和中东国家革命（例如阿拉伯之春）的关注进一步表明，现代军队将心理战和信息战视为首要任务。</p><p></p><p> <strong>2. 信息战长期以来依赖于SOTA心理知识和说服技巧。</strong></p><p>根据 Nye 的说法（软实力，2004 年，第 106 页），宣传趋势的变化需要政府/军队具有更高的心理复杂性，才能产生与几十年前相同的结果：</p><blockquote><p>公众对宣传变得更加警惕和敏感。对于编辑和意见领袖来说，信誉是最重要的资源……信誉变得比过去更加重要，围绕信誉的创造和破坏发生了政治斗争。政府不仅与其他政府竞争信誉，还与包括新闻媒体、企业、非政府组织、政府间组织和科学界网络在内的广泛替代品竞争。</p><p>政治已成为竞争信誉的较量。传统强权政治的世界通常是关于谁的军事或经济获胜……政府之间以及与其他组织的竞争，以提高自己的信誉并削弱对手的信誉。看看塞尔维亚和北约之间为解释 1999 年科索沃事件和一年后塞尔维亚事件而进行的斗争吧。</p></blockquote><p></p><p> <strong>3.信息战的目标是赢得高智商的精英，而不是无知的大众。</strong></p><p>长期以来，信息战一直是建立<a href="https://www.lesswrong.com/posts/c5oyHuHaw4AcWy4tf/information-warfare-historically-revolved-around-human"><u>人类渠道</u></a>，以创造足够的临界质量来接触关键精英，并使他们反对政府/军队，例如<a href="https://en.wikipedia.org/wiki/Soviet_influence_on_the_peace_movement#Wider_Soviet_influence"><u>苏联支持的参与</u></a>越南反战运动期间的科学家。</p><p>根据奥德拉·沃尔夫 (Audra Wolfe) 在《与苏联竞争》（2013 年，第 115-119 页）中的说法，越南反战运动引入了心理因素，导致五角大楼接触科学家的机会大幅减少：</p><blockquote><p>总的来说，学生抗议、激进批评和国会改革瓦解了自二战结束以来统治大学校园的[支持军事研究]共识。大学借助军事资金来推动扩张将不再被接受。随着“科学为人民”等组织提出更广泛的激进批评，即使是那些接受非军事资金的科学家也越来越多地开始质疑联邦的慷慨附带了什么样的意识形态条件。也许最大的变化是，自原子科学家运动以来，科学家们第一次感到有权对科学与国家安全的关系提出政治批评，而不会对他们的职业生涯产生影响。然而，科学家们很快就会发现，国防分析家对他们所说的不再那么感兴趣……</p><p>鉴于反越战抗议活动起源于大学校园，校园反对支撑美国外交政策的科学技术研究也就不足为奇了。也许更令人吃惊的是这种质疑蔓延到防守内部人士的速度。美国在越南军事介入的扩大甚至对那些以前支持国防工作或曾担任国防机构顾问的科学家提出了挑战。随着他们的批评越来越多，科学家和他们所建议的人之间的不信任变得相互。一代人以来，国家安全顾问第一次开始思考，在没有科学家或工程师参与的情况下做出科学技术决策是否会更好。</p><p>这场分裂最有说服力的地点之一是贾森家族内部，这是一个由物理学家组成的秘密团体，他们夏天的一部分时间都在向五角大楼提供建议。 Jason 科学家最初于 1959 年在 ARPA 的保护下创建，对军事技术进行独立评估，并提出军事规划者可能想要采用的新技术。与大多数国防咨询小组不同，杰森选择了自己的成员，成员在收到军事领导人的绝密简报后自行决定调查哪些问题。到 1965 年，杰森的项目包括导弹防御、潜艇探测和跟踪以及扰乱地球磁场的计划。尽管杰森通常会为棘手的问题提供解决方案，但它偶尔也会利用其力量来否定科学上不可信的想法，例如用强大的激光击落来袭导弹的计划......</p><p>杰森夫妇惨痛地认识到，科学家不一定能控制他们所创造的事物。当杰森几份报告的摘要出现在 1971 年《纽约时报》（即五角大楼文件）上时，杰森夫妇成为学术科学家与军方关系中所有问题的象征。 1972 年，反战组织出版了一本小册子……讲述了杰森家族中最具破坏性的项目，并点名了几位杰森家族的名字。随后发生了抗议活动，包括对哥伦比亚大学普平实验室进行了为期三天的围困。一些杰森辞职了，而其他人则简单地指出，他们的职责一直是为军队提供建议。面对个人威胁，那些仍然致力于为军队提供建议的杰森重申了他们向自己的政府提供建议的权利。他们重新回到工作岗位，重新致力于保密工作，与其说是受到惩罚，不如说是对异议策略的幻灭。</p></blockquote><p>另一个组织PSAC甚至被迫卷入一场激烈的公共冲突，进一步削弱了约翰逊和尼克松政府接触科学家的机会（第117-119页）。</p><p></p><p> <strong>4. 到2010年代末，数字信息战能力已经成为中美冲突的一个突出特征。</strong></p><p>我不喜欢抨击中国，因为这个政权比大多数西方人想象的更加注重防御，而且主要与美国情报机构处于一种糟糕的低信任平衡状态。他们利用人工智能进行专制控制可能只是复制和重组最初在美国发明的能力。</p><p>然而，中国扩大全球影响力的尝试也与此相关（他们的说法是，他们正在抵制类似的美国支持的体系，但独裁国家总是从此类主张中受益，即使事实并非如此）。</p><p>罗伯特·萨特（《美中关系》，《危险的过去，不确定的现在》，第 4 版，2022 年，第 216 页）介绍了中国尝试全球信息战能力的现状：</p><blockquote><p>由于中国共产党对中国关键行业和经济企业的控制在习近平的领导下有所加强（自2012年以来），而且中国的国家情报法被认为要求中国公司配合中国政府的信息请求，中国数字通信设备和基础设施的扩张[整个亚洲、欧洲和美国]意味着中国在国外部署的数字基础设施可以被中国当局用于情报、影响行动和其他有利于国家的手段。</p><p>美国对中国 5G 发展的担忧是特朗普政府针对华为这家在海外开发和部署 5G 及相关技术和基础设施的中国领先公司的限制的核心。美国政府在说服美国盟友情报官员认识到华为或其他中国公司提供的通信设备对安全构成威胁方面取得了相当大的成功。</p></blockquote><p>值得注意的是，芯片固件后门和操作系统漏洞利用库存的风险也是外国生产的电子设备和基础设施的一个重要因素，尽管我目前只有有关<a href="https://www.nytimes.com/2020/01/14/us/politics/nsa-microsoft-vulnerability.html"><u>NSA 操作系统漏洞利用库存的</u></a>信息。</p><p> （萨特，第 290 页）</p><blockquote><p>中国的社会和政治控制方法不断发展，包括广泛使用复杂的监视和大数据技术。中国公司越来越多地向世界各地出口数据和监控技术。 2019年4月，澳大利亚战略政策研究所和澳大利亚无党派智库显示，中国公司参与在34个四个国家安装5G网络，并在46个国家部署所谓的安全城市监控技术。 2018年10月，自由之家报告称，中国企业在38个国家安装了互联网和移动网络设备，在18个国家部署了中国企业开发的智能监控系统和面部识别系统，在36个国家部署了媒体精英和政府官员曾前往中国参加新媒体或信息管理培训。</p></blockquote><p> （萨特，第 295 页）</p><blockquote><p>这些协议使中国的基础设施开发实现了盈利，并加深了中国的影响力，同时满足了独裁和/或腐败的外国领导人的权力和个人需求。中外政府利益的共生是中国国际影响力不断增长的强大资产，因为世界上充斥着这样的政权。</p><p>除此之外，中国还提供通信和监视系统，协助外国领导人追踪和镇压对手。相关的是中国与各州媒体的强劲交流。这些媒体追求对政府领导层和中国积极的新闻报道……通信和监视系统还协助中国收集情报和操纵国内舆论。</p><p>受到这些影响的一系列外国政府包括拉丁美洲的委内瑞拉和厄瓜多尔；塞尔维亚、黑山，有时还有欧洲的意大利和希腊；非洲的吉布提和赞比亚；南亚的马尔代夫和斯里兰卡；以及东南亚的柬埔寨、老挝、马来西亚、缅甸、菲律宾。中东和中亚的许多威权政府被认为倾向于与中国沿着这些路线密切合作。</p></blockquote><p></p><p> <strong>5. SOTA 心理研究和操纵能力已经开始每 4 年增加一个数量级。</strong></p><p>这导致主要军队将资源转向进攻性和防御性信息战。</p><p>这在十多年前就已经开始了。到目前为止，五大科技公司（亚马逊、苹果、谷歌、Facebook、微软）应该拥有足够多的人类行为数据，并有能力通过人工智能和心理学研究人员等处理和解释这些数据，从而单方面开拓该领域人类说服研究，特别是在印象/氛围操纵领域。</p><p>通过社交媒体滚动数据收集范式，他们可以获得数十亿个详细的案例研究，这些案例研究是关于人类对某个主题形成印象的精确环境。</p><p>不幸的是，使用鼠标滚轮或触摸屏滚动浏览社交媒体新闻源上的一条信息的动作将产生至少一条曲线，而每天有数十亿人输出数万亿条曲线。这些曲线是线性代数，是插入机器学习的完美形状。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Lw8enYm5EXyvbcjmt/t8dotdfooysmoszgwarz" alt="Thumbs 'travel two marathons a year' scrolling through social media | Daily  Mail Online"></figure><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Lw8enYm5EXyvbcjmt/me4dlbvcs2kagb7b8md7"></p><p>社交媒体新闻源非常适合控制变量，并分析帖子的各种组合/顺序对具有不同特征的人的有效性。</p><p>他们可能具有强大的能力，可以引导人们的思维和行为朝着可衡量的方向发展，因为这种能力很容易注意到，也很容易做到；如果方向是可测量的，那么只需针对那些可能导致具有相似特征的人朝该方向移动的因素进行优化即可。这就是预测分析所促进的研究能力。 <a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks#:~:text=Predictive%20analytics%20is,linkages%2C%20and%20correlations">人工智能甚至不是必需的</a>，尽管它极大地提高了功能。</p><p>人工智能安全社区的大多数成员与数据集中的绝大多数人截然不同，但我们仍然容易受到<a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks">诸如小丑攻击之类的攻击，这种攻击几乎适用于任何人类</a>，而社交媒体范式允许黑客不断尝试一些事情成功率很低，直到他们找到可行的方法（ <a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks#:~:text=There%20are%20many,combinations%20of%20posts.">多臂老虎机算法</a>）。</p><p>人们的思想被黑客入侵<a href="https://twitter.com/sama/status/1716972815960961174"><u>显然是在缓慢起飞和通用人工智能出现之前可能发生的事情</u></a>。事实上，显而易见的是，人类操纵的任务可以通过当今现有的系统实现自动化和规模化，这些系统提供了比现有系统更强大的大规模人类行为分析、研究和<a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks#:~:text=Such%20forms%20of%20management%20require%20more%20than%20monitoring%20and%20recording%20a%20population%E2%80%94they%20also%20subject%20it%20to%20ongoing%20experimentation.%20This%20is%20the%20form%20that%20predictive"><u>连续实验</u></a>。 -shot n = 100-1000 个实验，主导了 20 世纪学术心理学研究的范式。</p><p> <a href="https://www.lesswrong.com/posts/Lw8enYm5EXyvbcjmt/sensor-exposure-can-compromise-the-human-brain-in-the-2020s#:~:text=The%2020th%20century%20was%20radically%20altered%20by%20the%20discovery%20of%20psychology%2C%20a%20science%20of%20the%20human%20mind%2C%20and%20its%20exploitation%20(e.g.%20large%2Dscale%20warfare%2C%20propaganda%2C%20advertising%2C%20information/hybrid%20warfare%2C%20decision%20theory/mutually%20assured%20destruction)."><u>心理学（一门研究人类心智的科学）的发现及其开发彻底改变了 20 世纪</u></a>。人脑以及控制/操纵它是一门科学；如果第一代经验主义（20世纪学术心理学）在很大程度上未能获得惊人的能力，那并不意味着下一代人会，特别是在达到经验研究能力开始每四年增加一个数量级之后（十多年前就已经开始了）。这项技术在数据、算法进展和人才库（用于训练模型、标记相关性和心理结果）方面存在瓶颈</p><p>不断尝试直到某件事对目标起作用的能力，加上量化哪些事物往往对具有特定特征组合的人起作用的能力，再加上数十亿个案例研究，自然产生了强大的操纵引擎。默认情况下，人类组织会被激励去开拓这些能力（在发现并展示它们后），因为控制其他人（包括让人们离开）几乎对任何目标都至关重要。</p><p>如果他们注意到引导人们购买特定产品的方法，或者感觉到避免退出平台的各种强迫，以及防止/抵消其他平台的多臂强盗算法自动利用策略（例如帖子组合）进行掠夺他们的用户，那么你自然可以假设他们已经注意到他们也有能力引导人们走向各种其他方向。问题在于，主要政府和军队有极大的动力并处于有利位置，利用这些能力进行进攻性和防御性信息战。</p><p>像中央情报局这样的情报机构将自己描述为仅仅是忠于总统的信息收集机构，就像疾病预防控制中心将自己描述为负责任的机构一样。事实上，冷战和反恐战争的经验数据非常清楚地表明，情报机构实际上是征服的官僚机构；从渗透政权和推翻不友好的政权，到针对、渗透和恐吓国内精英以使其屈服。</p><p>他们<a href="https://www.lesswrong.com/posts/LyywLDkw3Am9gbQXd/don-t-take-the-organizational-chart-literally"><u>受到能力瓶颈</u></a>， <a href="https://www.lesswrong.com/posts/foM8SA3ftY94MGMq9/assessment-of-intelligence-agency-functionality-is-difficult"><u>由于高层缺乏透明度而难以衡量</u></a>，但旋转门雇佣很容易让他们从5大科技公司的人才库中找到灵活的人才； <a href="https://www.lesswrong.com/posts/jyAerr8txxhiKnxwA/5-reasons-why-governments-militaries-want-ai-for-information-1#3__Information_warfare_is_about_winning_over_high_intelligence_elites__not_the_ignorant_masses__">这种做法受到信息战本身的威胁</a>，进一步激发了人们对信息战优势的兴趣。</p><p>对科技公司人才库的访问还决定了情报机构利用<a href="https://www.nytimes.com/2020/01/14/us/politics/nsa-microsoft-vulnerability.html">操作系统漏洞</a>和芯片固件漏洞来访问几乎所有美国人设备中的传感器的能力，而不仅仅是大多数保留各种传感器权限的美国人，这<a href="https://www.lesswrong.com/posts/Lw8enYm5EXyvbcjmt/sensor-exposure-can-compromise-the-human-brain-in-the-2020s"><u>甚至</u></a>允许<a href="https://www.lesswrong.com/posts/Lw8enYm5EXyvbcjmt/sensor-exposure-can-compromise-the-human-brain-in-the-2020s"><u>更好地获得危害人工智能安全社区等关键精英所需的心理学研究</u></a>。</p><p>然而，许多 SOTA 心理影响技术适用于一般人类，无论<a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks-and-mind#:~:text=First%20it%20started%20working,already%20working%20on%20me.">它们与数据中的普通人有多么不同</a>，例如<a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks"><u>小丑攻击</u></a>。</p><p>各大银行利用人工智能研究人类行为数据；特别是支出/储蓄比率对衰退缓解/恶化有重大影响。这项研究显然默认具有双重用途，即使交易数据是比社交媒体滚动数据弱得多的了解人类思维的窗口（亚马逊和中国电子商务公司有很多自由度来研究和实验这两种数据）。</p><p>这些能力最初是由里根和撒切尔政府在 20 世纪 80 年代寻求的宏观经济工具，但直到现在，政府和大公司利用 SOTA 人类影响力来缓解（或武器化）经济衰退的条件才成熟。在中美关系中，众所周知，最有可能获胜的条件是对方经济崩溃/疲软。</p><p>这些原因就是为什么我们可以合理地假设，默认情况下，人工智能会被秘密用于大规模的人类操纵研究。如果没有数百万受试者，这是不可能完成的，因为人工智能需要大量多样化的数据池，而如果这些数百万受试者意识到风险，他们就不会每天在优化的研究环境（社交媒体新闻源）中花费一个小时。</p><p> Furthermore, if you look at a list of NGOs infiltrated by the CIA, companies with FBI informants, or communities that received special attention from the NSA, it should be <a href="https://www.lesswrong.com/posts/Htjbj8ystqc2zLtMX/murphyjitsu-an-inner-simulator-algorithm">obvious in hindsight</a> that the AI safety community is extremely similar to the type of geopolitically significant community that tended to get targeted in the past.</p><p>因此， <a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks"><u>人工智能安全社区必须减少其巨大的攻击面，并加强抵御 SOTA 人工智能驱动的操纵</u></a>。熬过 2020 年代并没有太多内在价值，但它对于坚持和继续对齐研究有帮助作用。</p><p> It&#39;s folly to take the happy-go-lucky world that we experienced throughout most of our lives, and imagining the 2020s as more of that; humans are gaining capabilities, and the expectation of a happy-go-lucky 2020s already hasn&#39;t held up.</p><br/><br/> <a href="https://www.lesswrong.com/posts/jyAerr8txxhiKnxwA/5-reasons-why-governments-militaries-already-want-ai-for#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/jyAerr8txxhiKnxwA/5-reasons-why-governments-militaries-already-want-ai-for<guid ispermalink="false"> jyAerr8txxhiKnxwA</guid><dc:creator><![CDATA[trevor]]></dc:creator><pubDate> Mon, 30 Oct 2023 16:30:38 GMT</pubDate></item></channel></rss>