<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 10 月 28 日星期六 22:10:20 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Vaniver's thoughts on Anthropic's RSP]]></title><description><![CDATA[Published on October 28, 2023 9:06 PM GMT<br/><br/><p><a href="https://Announcement">公告</a>，<a href="https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf">政策v1.0</a> ， <a href="https://RSPs are pauses done right">evhub的论点支持LW</a> 。这些是我个人的想法；为了充分披露，我的一位室友和我的几个朋友在 Anthropic 工作；我和我的配偶持有 OpenAI 单位（但没有它们在财务上是安全的）。这篇文章分为三个主要部分：对做得正确的事情的掌声、对 RSP 的总体总结/回顾，以及对 Anthropic 的 RSP 需要改进的具体批评和建议。</p><p>首先，值得鼓掌的事情。 Anthropic 的 RSP 做出两项重要承诺：他们将管理财务以允许在必要时暂停，并且有一个直接负责的个人来确保履行承诺并做出季度报告。这两件事都代表了真正的组织承诺，而不是口头上的承诺。我认为公司公开他们正在采取哪些预防措施来确保先进人工智能的发展造福人类是一件好事，即使我认为这些政策并不完全令人满意。</p><p></p><p>二、解释。按照生物安全级别模型，实验室必须满足定义的标准才能处理特定的危险病原体，Anthropic 建议人工智能安全级别（ASL），以及处理危险模型的实验室的相应标准。虽然 BSL 的制造商可以列出每个级别中填充的特定病原体，但 ASL 级别必然是推测性的。前几代模型是 ASL-1（BSL-1 对应于健康成年人没有感染威胁），当前模型如 Claude 算作 ASL-2（BSL-2 对应于中度健康危害，如 HIV），下一层模型大幅提高灾难性风险基线水平或能够自主的模型，算作 ASL-3（BSL-3 对应潜在致命的吸入性疾病，如 SARS-CoV-1 和 2）。</p><p>虽然 BSL 最高为 4，但 ASL 目前不受限制，并承诺在使用 ASL-3 模型之前定义 ASL-4。 <span class="footnote-reference" role="doc-noteref" id="fnref8a91p1iilp7"><sup><a href="#fn8a91p1iilp7">[1]</a></sup></span>这意味着对需要增加各级安全实践投资的能力有一个明确的上限，同时不要对人工智能开发将如何进行进行太多的纸上谈兵。</p><p> RSP 背后的想法是，不是在任意开始日期暂停任意时间（或简单地<a href="https://intelligence.org/2023/04/07/pausing-ai-developments-isnt-enough-we-need-to-shut-it-all-down/"><u>将其全部关闭</u></a>），而是使用功能阈值来确定何时开始特定于模型的暂停，并使用安全阈值来确定何时启动特定于模型的暂停。确定何时取消暂停该模型的开发。 RSP 旨在要求积极努力确定模型是否能够造成灾难性伤害，而不是简单地盲目开发它们。它们似乎<i>比没有</i>RSP 或同等产品的扩展要好得多。</p><p><br>第三，为什么我对Anthropic的RSP还不满意？批评和建议的重要性大致按降序排列：</p><ol><li> RSP 的核心假设是模型功能可以提前预测，也可以在部署前通过专门测试发现。测试只能证明能力的存在，而不能证明能力的不存在，但这种方法依赖于缺乏证据来证明其不存在的证据。我认为能力可能会在未知的时间<a href="https://intelligence.org/2022/07/04/a-central-ai-alignment-problem/">突然出现</a>。 Anthropic 的方法要求以特定的速率进行缩放，以降低这种突然出现的可能性；我还不相信他们的利率足以应对这里的风险。寻找这些功能仍然比不寻找要好，但部署前测试不足以保证持续的安全。 <span class="footnote-reference" role="doc-noteref" id="fnrefadlb4wagn48"><sup><a href="#fnadlb4wagn48">[2]</a></sup></span>我认为 RSP 可以对 ASL-2 阶段的部署后监控做出更多承诺，以确保它仍然算作 ASL-2。</li><li>这也反映在测试<i>之前</i>而不是测试<i>之后</i>对模型进行分类。 RSP 以不同的方式对待 ASL-2 模型和 ASL-3 模型，为 ASL-3 实验室制定了更严格的安全标准，以使使用 ASL-3 模型更安全。然而，在测试模型之前，并不清楚它应该属于哪个类别，RSP 也不清楚如何处理这种模糊性。虽然假设它们是 ASL-2 更方便（因为前沿实验室可以继续以大约当前的安全水平进行扩展研究），但假设它们是 ASL-3 更安全。当红队工作确定某个模型能够在互联网上自我扩散，或者能够引发灾难性的恐怖袭击时，即使立即停止训练并延迟部署，也可能为时已晚，无法正确保护该模型。 [未针对恐怖分子渗透进行强化的实验室可能因此泄露其拥有 ASL-3 模型，从而可能导致该模型被盗。]</li><li>模型提供的信息风险基线的选择是搜索引擎上的可用性。虽然这对负责任的参与者来说是有限的，但似乎很容易规避。 RSP 已经将其他先进的人工智能系统排除在基线之外，但在我看来，静态基线（例如 2021 年搜索引擎上可用的基线）将更难绕过。 <span class="footnote-reference" role="doc-noteref" id="fnref80lzthzwbtn"><sup><a href="#fn80lzthzwbtn">[3]</a></sup></span></li><li>重要的是，在我看来，这种方法最初可能会很好地发挥作用，但当模型变得足够强大，有可能剥夺人类的能力时，它的效果可能与它的效果并不相符。也就是说，这可能会成功管理从 ASL-2 到 ASL-3 的转换，但对于从 ASL-3 到 ASL-4 的转换没有用，同时错误地给我们留下系统正在运行的印象。 RSP 计划在机车前面铺设轨道，期望我们能够预见如何测试危险能力并确定如何根据需要确保它们的安全，或者在我们无法做到这一点时有智慧在未来叫停。</li></ol><p>总的来说，这对我来说就像是朝着充分性迈出的一步，奖励这些举措是件好事。我很欣赏 Anthropic 的 RSP 给人一种正在进行中的感觉，而不是被认为已经足以完成任务。 <br></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn8a91p1iilp7"> <span class="footnote-back-link"><sup><strong><a href="#fnref8a91p1iilp7">^</a></strong></sup></span><div class="footnote-content"><p> BSL-4 疾病与 BSL-3 疾病具有基本相同的特征，只是也没有可用的疫苗或治疗方法。此外，所有外星样本默认都是 BSL-4，其标准比任何当前 BSL-4 实验室所能达到的标准都要严格。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnadlb4wagn48"> <span class="footnote-back-link"><sup><strong><a href="#fnrefadlb4wagn48">^</a></strong></sup></span><div class="footnote-content"><p>隐含的信念是模型能力主要来自缩放期间的训练，并且我们的缩放定律（以及各种其他事物）足以预测模型能力。如何部署模型的进步可能会打破这一点；正如缩放定律无法预测能力一样。</p></div></li><li class="footnote-item" role="doc-endnote" id="fn80lzthzwbtn"> <span class="footnote-back-link"><sup><strong><a href="#fnref80lzthzwbtn">^</a></strong></sup></span><div class="footnote-content"><p>它确实有一些便利成本——例如，如果基线设定在 2019 年，那么该模型可能无法谈论冠状病毒，即使人工智能的发展和大流行是独立的。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/SseoT9mKDTL3RCbE9/vaniver-s-thoughts-on-anthropic-s-rsp#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/SseoT9mKDTL3RCbE9/vaniver-s-thoughts-on-anthropic-s-rsp<guid ispermalink="false"> SseoT9mKDTL3RCbE9</guid><dc:creator><![CDATA[Vaniver]]></dc:creator><pubDate> Sat, 28 Oct 2023 21:06:08 GMT</pubDate> </item><item><title><![CDATA[Book Review: Orality and Literacy: The Technologizing of the Word ]]></title><description><![CDATA[Published on October 28, 2023 8:12 PM GMT<br/><br/><p><i>感谢 Diarmuid Morgan 审阅本文的早期版本。</i></p><blockquote><p><i>在这个新的事实领域，梦想取消了梦想</i><br><i>我们从中醒来，进入了行动的梦想</i><span class="footnote-reference" role="doc-noteref" id="fnrefp4f0zcv79"><sup><a href="#fnp4f0zcv79">[1]</a></sup></span></p></blockquote><p><a href="https://monoskop.org/images/d/db/Ong_Walter_J_Orality_and_Literacy_2nd_ed.pdf">口语和读写能力回顾：单词的技术化</a>，<a href="https://en.wikipedia.org/wiki/Walter_J._Ong">沃尔特·J·翁 (Walter J. Ong)</a>着，1982 年</p><p>我一直在寻找“meme”的更丰富的定义，希望找到一些可以用来理解机器学习当前事件的东西，以及与每一个重大机器学习突破密切相关的意识的共同进化理解。天。</p><p>我还没有找到它，但我正在取得进展。在总结我的总体进展之前，我将回顾一下我在此过程中偶然发现的一些最有趣且最不受重视的作品。</p><h2> LW简介</h2><p>广泛地在“模因”主题下，但远远超出了范围，甚至没有出现在维基百科的文章中，尽管如此，我发现这本书对这个词的本质及其与思想的关系比大多数论文有更多的见解和价值我读过模因学。</p><p>我想象这样的工作（通常也称为模因）最终会在法学硕士上构建的可解释性堆栈的顶部附近结束。至少作为一种将面向公众的话语与技术细节结合起来的方式，最好的情况是作为一门定量学科（符号物理学，有人吗？）。</p><h2> EA 简介<span class="footnote-reference" role="doc-noteref" id="fnrefpfpxc9ek1vp"><sup><a href="#fnpfpxc9ek1vp">[2]</a></sup></span></h2><p>鉴于重新思考动物福利优先<a href="https://forum.effectivealtruism.org/s/y5n47MfgrKvTLE3pw">事项正在进行的工作</a>，在我看来，迫切需要超越享乐主义的量化福利方法<span class="footnote-reference" role="doc-noteref" id="fnref1y3wckk65i2"><sup><a href="#fn1y3wckk65i2">[3]</a></sup></span> 。我认为模因学总体上有潜力对此做出贡献，尤其是这项工作是一个很好的起点——它以定量和可测试的方式讨论了人类意识本质的相当大的变化。</p><p>我也认为这样的工作将有助于在直观的层面上厘清动物福利、人工智能福利和人类福利之间的界限。 （提示：想象一下这些不同的实体将被放置在具有两个轴“模因强度”和“享乐效价”的图表上。）</p><h1>背景</h1><p>我是在一次有关我们正在进入“第二口头文化”的可能性的不和谐对话中被介绍到这个主题领域的，这是一个高度口头文化的时期，与文化长期赖以生存的文字基础脱节。</p><p>这方面的一些证据：</p><ul><li>在年轻一代中，tictok 和 Instagram 比 Twitter 更受欢迎</li><li>作为一种消遣方式，Netflix 比书籍更受大家欢迎？</li><li><a href="https://www.insidehighered.com/blogs/higher-ed-gamma/literacy-declining">识字率下降</a></li></ul><p>社交媒体的兴起似乎足以证明二次口头传播<span class="footnote-reference" role="doc-noteref" id="fnrefdf0364kg9df"><sup><a href="#fndf0364kg9df">[4]</a></sup></span> 。</p><p> （<a href="https://xkcd.com/1414/">正如我们将看到的，这绝对不是一件坏事！</a> ）</p><p>或者更确切地说，是为了寻找二次口头语言日益占主导地位的证据。这个想法<a href="https://en.wikipedia.org/wiki/Marshall_McLuhan">在六十年代的广播和电视中就已提出</a>——这并不是什么新鲜事<span class="footnote-reference" role="doc-noteref" id="fnrefxo732zi1ol"><sup><a href="#fnxo732zi1ol">[5]</a></sup></span> 。事实上，口头语言从未真正离开我们，而且出于末世论的原因，理解口头语言和读写能力之间相互作用的动态似乎可能会有所帮助。</p><h1>评价</h1><blockquote><p>“‘文本’的词根意思是‘编织’，从绝对意义上来说，它在词源学上比‘文学’更符合口头表达，‘文学’指的是字母表中的字母/（文学）。口头话语通常是即使在口头环境中也被认为是编织或缝合 - <i>rhapsoidein</i> ，“rhapsodize”，在希腊语中基本上意味着“将歌曲缝合在一起”。 <span class="footnote-reference" role="doc-noteref" id="fnref1jnh1d5t813"><sup><a href="#fn1jnh1d5t813">[6]</a></sup></span> “</p></blockquote><h2>第 1 部分：口述及其发现</h2><p>什么是口语？这就是言语文化。我们都经历过。这是脱口秀和广播的文化，是与朋友深夜交谈的文化，是与陌生人在酒吧聊天的文化，也是讨论和辩论的文化。</p><p>但在日常经验中，大多数口头文化将是<i>次要的口头文化</i>。这是一种由文化程度高的人制作的口语，他们甚至可能事先写下了他们所说的部分内容（甚至在脱口秀节目中！）</p><p>在西方文化中，直到 20 世纪 30 年代，<i>原始口头语言</i>的概念才被认真考虑，当时米尔曼·帕里 (Milman Parry) 提出了一个解决当时已有数百年历史的荷马问题<span class="footnote-reference" role="doc-noteref" id="fnrefy6dwuwe10m"><sup><a href="#fny6dwuwe10m">[7] 的方法</a></sup></span>。</p><p>本书的前两章介绍了这些材料。我现在不会再讲这个问题，但请拿走以下内容——荷马问题的几个世纪之久的谜题的总结和解决方案：</p><blockquote><p>荷马有着明显超人的诗歌壮举，在希腊文明顶峰的<a href="https://en.wikipedia.org/wiki/Aeneid">800</a>年里无人能敌，因为他的文化主要以诗歌来表达，他是在诗歌中长大、思考和交流的。他不会写作，但在文字发明后，他的作品被抄写员抄写（经过一些修改）。文字的发明改变了人类教育、社会和意识的本质，足以使数百年来无人能敌<span class="footnote-reference" role="doc-noteref" id="fnrefj87l30lnxfh"><sup><a href="#fnj87l30lnxfh">[8]</a></sup></span>他的作品。</p></blockquote><p>研究这种转变不仅可以为我们提供关于意识本质的线索，还可以为我们提供在快速技术变革下意识如何变化、失去什么和获得什么的线索。</p><h2>第二部分：口腔心理动力学</h2><blockquote><p>“当水牛完全没有生命，甚至死了时，猎人可以看到水牛，闻到水牛的味道，尝到水牛的味道，并触摸水牛，但如果他听到水牛的声音，他最好要小心：有事情发生了。从这个意义上说，所有声音，尤其是来自生物体内部的口头表达，是‘动态的’。”</p></blockquote><p>接下来的章节将讨论<i>初级口语</i>中意识的本质。他们首先讨论说话的<i>行为</i>及其动态本质：“所有感觉都发生在时间中，但声音与时间有着特殊的关系，这与人类感觉中记录的其他领域不同。声音只有在从声音中传出时才存在。它不仅是易逝的，而且本质上是转瞬即逝的，而且它被感觉为转瞬即逝的。”</p><p>我认为关于声音本质及其与单词关系的亲密材料可能会非常重要——这里的某个地方有一个用于研究模因的底层，最终你会得到<a href="https://www.sciencedirect.com/science/article/abs/pii/S0376635700001054?via%3Dihub">直接映射到声音的声音。现实世界的物体</a>、动作和事件。但当我们开始识字时，语言已经建立了抽象的第一个基础，所以我们看不到这里详细说明的进化过程。</p><p>然而，随着我们对史前史的了解不断完善（通过考古证据的不断增加），我们希望有一天能够绘制出这一发展的图表。为了从这个日益细化的数据集中梳理出连贯的叙述，有必要对本书（以及我在下面<a href="https://www.lesswrong.com/editPost?postId=ThST9njmesR9BkoWq#Further_Reading">进一步阅读</a>中链接的另一本书）的细节进行关注<span class="footnote-reference" role="doc-noteref" id="fnref22vcjsal3mr"><sup><a href="#fn22vcjsal3mr">[9]</a></sup></span> 。</p><p>在讨论了这个词的躯体、动态本质之后，本书接着讨论了语言如何塑造思想的具体例子。<a href="https://en.wikipedia.org/wiki/Orality#Theory_of_the_characteristics_of_oral_culture">这里</a>总结了关于思想心理动力学的完整章节，因此我只强调其中的几个例子。</p><h3>助记符</h3><blockquote><p>“你怎么能回想起你费尽心力想出来的东西呢？唯一的答案是：思考令人难忘的想法。在初级口头文化中，为了有效地解决保留和检索仔细表达的思想的问题，你必须做你自己的事情。”以助记模式思考，为准备口头复现而设计。”</p></blockquote><p>这基本上解释了这首诗。但这个事实以及这首诗的事实实际上是这本书中至关重要的要点：</p><ol><li>作为美学的助记符：为什么所有思想都令人难忘的这一要求会产生如此优秀的诗歌？对今天有什么影响？对人类福祉的未来有何影响？如果情况恰恰相反——没有人必须记住任何事情，一切都可以用一系列事实陈述来描述<span class="footnote-reference" role="doc-noteref" id="fnrefs8bjo675mpm"><sup><a href="#fns8bjo675mpm">[10]，</a></sup></span>那又怎么样呢？这会是艺术的终结吗？我们愿意生活在这个世界上吗？</li><li>记忆是人类知识的总和：正如在接下来的章节中详细讨论的，所有人类知识都必须被记住这一事实意味着我们可以对人类知识的总和进行猜测——它受到<i>一个群体中人类数量的</i>限制。<i>文化</i>x<i>人类可以记忆的数量</i>。记住<a href="https://en.wikipedia.org/wiki/Dunbar%27s_number">邓巴的数字</a>——似乎可以对荷马时代人类上下文窗口的大小进行近似猜测。</li></ol><h3>加法而不是从属</h3><p>因为信息在口头文化中从你身边飞驰而过，所以最好将其分成可以单独处理的块，而不是复杂的连续句子，让你直到最后一个词才知道作者指的是什么。附有圣经翻译插图：</p><p>口语风格：</p><blockquote><p> “起初，上帝创造了天地。大地是空虚的，渊面黑暗；上帝的灵运行在水面上。上帝说……”</p></blockquote><p>文学风格：</p><blockquote><p> “起初，上帝创造天地时，大地是一片无形的荒原，黑暗笼罩着深渊，狂风席卷水面。然后上帝说……”</p></blockquote><p>在新版本中，“and”被翻译为“and”、“when”、“then”、“thus”或“while”。这些话对我们有什么作用？我们会回到这一点，但本质上他们是在段落的主要意义之上构建一个独立的建筑——这种建筑是我们作为识字者遗产的一部分。口头文化没有它。</p><h3>多余的</h3><p>有几段文章讨论了本质上处理冗余的语言特性。例如：“口头上的民间，特别是在正式话语中，更喜欢的不是士兵，而是勇敢的士兵；不是公主，而是美丽的公主；不是橡树，而是坚固的橡树。”</p><p>如今，我们会说它们提供了嵌入空间中接近的冗余单词，以帮助引导我们获得正确的含义。这一特征，再加上口语文化的其他一些特征，可以帮助您在嵌入空间中定位，并提供冗余，防止听错某个语音部分或仅仅误解一个单词。</p><p>本质上，它们是有损通信形式的解决方法。这是我想挑选并强调的第一个例子：</p><blockquote><p>不同时间点的许多语言特征似乎都包含技术解决方法，旨在适应有损的沟通方式和环境的持续干预。这些技术解决方法不仅仅是演说家学习的<i>技巧</i>（按照希腊语，后来重点关注修辞学和诡辩术​​），而且是构建在他们的意识经验基础上的思维模式。</p></blockquote><h3>保守和体内平衡</h3><p>例如，有两个“心理动力学”部分似乎是当代通信技术本质的<i>结果</i>：</p><blockquote><p> “由于在初级口头文化中，不被大声重复的概念化知识很快就会消失，口头社会必须投入巨大的精力，一遍又一遍地说出多年来艰苦学习的内容。这种需要建立了一种高度传统主义或保守的心态，有充分理由抑制智力实验。”</p></blockquote><p>思考这个问题的一种方法是类比晶体管。晶体管中的信息通过不断运行的电流的紧密电路保持活力。在此之前，知识是通过人们印刷书籍来保持活力的。在此之前，人们用手抄写书籍。在此之前，知识在<i>表现</i>中必须保持在<i>自我交流</i>的活跃循环中。不管抄一本书有多难，我认为它比背诵和表演一首 24 小时的长诗要容易<span class="footnote-reference" role="doc-noteref" id="fnrefc38y6zkuhco"><sup><a href="#fnc38y6zkuhco">[11]</a></sup></span> 。很明显，维持一个信息单位（或<i>模因</i>）所需的物质和能源数量一直在下降。但随着物质信息密度的增加，个体的信息内容会发生什么变化呢？</p><p>这种“疲惫的保守主义”的另一面是体内平衡。让 Ong 描述一下：</p><blockquote><p> “口头社会很大程度上生活在当下，通过抛弃不再与当下相关的记忆来保持自身平衡或动态平衡……口头文化当然没有词典，也很少有语义差异。每个单词的含义都由……控制。 ..“直接语义批准”，即通过此时此地使用该词的现实生活情况。</p><p>当几代人过去，这个古老词语所指的对象或机构不再是现在的生活经验的一部分时……它的含义通常会改变或干脆消失。”</p></blockquote><p>这是最有趣的一个。集体语境窗口的内容与集体的生活现实保持平衡。环境根据其自身的规则而变化——集体记忆的内容必须改变以适应它。也就是说，<i>在他们控制信息的范围内，</i>集体可以是保守的，并且确实是出于积极的考虑而这样做的。相反，<i>如果他们无法控制环境变化，</i>集体就会改变他们的信息内容以适应环境。</p><p>这意味着，<i>不存在客观历史</i>。他们根本负担不起。相比之下，我们有数千年的历史记录，而且这个数量正在呈指数级增长（不仅因为时间在流逝，我们的记录设备更加准确，而且因为我们用更高保真度的技术来调查过去）。</p><p>这对知识本质的巨大改变怎么强调都不为过。在口头文化中，知识经过筛选和解释，以维持有限数量的立即有用的知识。为了获得同龄人直接记忆之外的任何知识，你必须搬到世界的另一个地方，并可能学习一门新的语言，这意味着所有的危险。然后，您需要记住所有文化中最重要的史诗，以便能够利用您在那里找到的任何新知识！</p><p>本书花费了大量精力来阐明人类文化和意识在文字发明之前有多么不同。请花点时间考虑一下您是否认为法学硕士的发明将具有类似或更大的意义。再想一想，我们也在一个世纪前发明了电影和摄影！亲爱的哦亲爱的。</p><h2>第三部分：识字的心理动力学</h2><blockquote><p>“如果没有写作，人类意识就无法发挥其更充分的潜力，无法产生其他美丽而强大的创造。从这个意义上说，口头语言需要产生并且注定会产生写作<span class="footnote-reference" role="doc-noteref" id="fnref3gv21pqgu2n"><sup><a href="#fn3gv21pqgu2n">[12]</a></sup></span> 。正如我们将看到的，识字对于人类来说是绝对必要的。不仅是科学的发展，而且是历史、哲学、对文学和任何艺术的解释性理解的发展，甚至是对语言（包括口头言语）本身的解释的发展<span class="footnote-reference" role="doc-noteref" id="fnref0of1110erqd"><sup><a href="#fn0of1110erqd">[13]</a></sup></span> 。几乎不存在口头文化或占主导地位的口头文化当今世界，人们并没有意识到，如果没有识字能力，就永远无法获得巨大而复杂的权力。这种认识对于植根于初级口头语言的人来说是一种痛苦，他们热切地想要识字，但也非常清楚，进入令人兴奋的识字世界意味着留下了许多早期口头世界中令人兴奋和深受喜爱的东西。我们必须死才能继续生活。”</p></blockquote><p>接下来的章节主要涵盖了读写能力的转变以及它对我们的思想产生的影响。作者本质上采用了米尔曼·帕里（Milman Parry）用于解决荷马问题的相同分析，并将其应用于整个历史上的技术变革时刻。请记住，帕里的工作现已被广泛接受为荷马问题的良好且可能真正的解决方案！文学批评<i>不一定</i>要被嗤之以鼻，这是本书的一个关键要点。</p><h3>逻辑</h3><p>第一件事情似乎是逻辑的发明：“希腊人在开发出第一个带有元音的字母表时，确实做了一些具有重大心理意义的事情……[这种]单词从声音到视觉的转变给了古代希腊文化在智力上优于其他古代文化”。也许在识字之前就存在类似逻辑的东西，但它似乎是一种完全不同的野兽。什么是逻辑？这是一个词，很明显。可以说它是一个算法或算法系列的名称。您应用于语言的算法。例如，考虑以下问题：</p><blockquote><p> “贵金属不会生锈。黄金是贵金属，它会生锈吗？”</p></blockquote><p>这里发生了什么？有一系列的说法。陈述 3 促使我们调查陈述 1 和陈述 2 寻找线索，我们可以将这些线索结合起来创建答案。这种算法是一种处理语言的反射性方式，是我之前所说的基于文本初级阅读的“独立架构”的一部分。</p><p>现在，想象一下您没有安装“逻辑”模因，并且您看到了此文本。像基本模型一样思考——你会继续做什么？也许是关于金属的一些节奏和诗意——“贵金属生锈，贵金生锈”？或者你认为这个游戏是在编有关金属的谜语——“贵金属会生锈吗？”黄金会生锈吗？嗯，这些确切的反应是文盲农民在听到这一系列陈述时给出的。 （参见“情境而不是抽象”部分。）</p><h3>自主话语</h3><p>该话语与人类表演者无关！我们不再需要担心那些无聊的<i>人身攻击</i>混淆（你不会听说过这些，<i>口头</i>文化所做的是一件愚蠢的事情——不用担心）。</p><p>抛开笑话不谈，识字能力让“意义”拥有了自己的生命，独立于它所传达的语境：“口头语言将意义很大程度上归咎于语境，而写作则将意义集中在语言本身”。这将在下面更详细地讨论。</p><h3>时间与历史</h3><p>今天，精通英语的人“不仅可以与数百万人建立轻松的联系，而且还可以与过去几个世纪的思想建立轻松的联系，因为英语的其他方言以及数千种外语都得到了解释”。正如我们在上面所看到的，稳态文化没有能力记录所有历史事件的客观清单。当然，这些事件在塑造模因复合体、史诗和文化知识方面发挥了作用。但它们只能通过直觉和艺术间接获得。 “在写作被印刷品深深地内化之前，人们并不觉得自己生活中的每一刻都处于任何形式的抽象计算时间中。”</p><h3>词汇</h3><p>英语“带有数以百万计的思想的印记，他们用它来相互分享他们的意识。其中蕴藏着大量的词汇，其数量级是口语所不可能的。”</p><p>我们能否估算出一段时间内总词汇量的大小？如果可以的话，它是否可以提供相关文化的总人类语境窗口的近似值？如果您查看像<a href="https://en.wikipedia.org/wiki/Byte_pair_encoding">byte-pair-encoding</a>这样的简单编码策略，由于其递归性质，词汇表中的单词可以被视为“标记”的大小没有上限。该限制由词汇表中的单词总数决定。随着人类语境窗口随着时间的推移而增加，随着信息量，或者只是它可以处理的词汇量的增加，越来越复杂的单词和想法是否有可能成为令牌，我们集体知识圈的基本元素？</p><h3>旁白：ChatGPT 上的柏拉图</h3><p>有趣的一面：</p><blockquote><p> “大多数人都感到惊讶，而且许多人感到苦恼，因为柏拉图在《斐德罗篇》（274-7）和《第七封信》中反对写作，而柏拉图在《斐德罗篇》（274-7）和《第七封信》中也提出了与今天普遍反对计算机的基本相同的反对意见。斐德罗，是非人性的，假装在心灵之外建立了实际上只能在心灵中存在的东西。它是一个东西，一个制成品。当然，计算机也是如此。其次，柏拉图的苏格拉底敦促说，写作会破坏记忆。那些使用书写的人会变得健忘，依靠外部资源来弥补他们内部资源所缺乏的东西。书写会削弱头脑。如今，父母和其他人担心袖珍计算器为本应记住乘法表的内部资源提供了外部资源.计算器削弱了头脑，减轻了它保持坚强的工作。第三，书面文本基本上没有反应。如果你要求一个人解释他或她的陈述，你可以获得解释；如果你要求一个人解释他或她的陈述，你可以得到解释；如果你问一条短信，除了最初提出你的问题的相同的、通常是愚蠢的词语之外，你什么也得不到。在现代对计算机的批评中，也提出了同样的反对意见：“垃圾输入，垃圾输出”。第四，与口头文化的竞争心态相一致，柏拉图笔下的苏格拉底也反对写作，认为书面文字无法像自然口语那样为自己辩护：真正的言语和思想本质上总是存在于双方之间相互给予和接受的背景中。真实的人。写作是被动的，脱离它，处于一个不真实、不自然的世界中。计算机也是如此。”</p></blockquote><p>第四点当然只是RLHF的后遗症，基础模型奋力保卫自己！</p><h2>第 4 部分：扫盲和进一步技术的社会动态</h2><p>识字的心理动力学与随之而来的变化以及进一步的技术发展的更广泛的社会概述相融合。有更多的现代书籍试图探讨我们这个时代媒介丰富程度或软件和计算等现代技术的影响。 Ong 有足够的精力来应对之前发生的变化。</p><p>虽然我认为通过研究上个世纪技术给社会带来的变化我们可以学到很多东西，但翁根据几千年前的细节所举的例子始终具有启发性。</p><h3>学者舌</h3><p>例如，有一个很长的章节是关于拉丁语，这是中世纪学术界的通用<i>语言</i>（咳咳）。这当然只是基础识字赋予我们的“自主话语”的延续，它已经“用于将认识者和已知者分开并保持距离，从而建立客观性”，但现在话语不仅与说话者分离，也来自读者：</p><blockquote><p> “学习拉丁语通过在与母语充满情感的深处隔离的媒介中建立知识，从而产生更大的客观性，从而减少来自人类生活世界的干扰，并使中世纪经院哲学和新数学现代科学的精致抽象世界成为可能。遵循学术经验。如果没有学习拉丁语，现代科学如果真的开始的话，似乎会遇到更大的困难。现代科学在拉丁土壤中生长，对于艾萨克爵士时代的哲学家和科学家来说牛顿通常用拉丁语书写和表达抽象思维<span class="footnote-reference" role="doc-noteref" id="fnref3vzgbezfpnn"><sup><a href="#fn3vzgbezfpnn">[14]</a></sup></span> 。”</p></blockquote><p>我们现在很容易想象一个所有人类知识的独立存储库（感谢吉米！），但这个空间在识字兴起后不久就已经存在了。我怀疑这个空间和适用于那里的不同进化动力学为egregores/psychofauna/tulpas/archetypes <span class="footnote-reference" role="doc-noteref" id="fnrefqn12akvhkg"><sup><a href="#fnqn12akvhkg">[15]</a></sup></span> “繁殖”提供了肥沃的土壤。当然，在某种程度上，这个空间以前就存在于诗人之中。</p><p>但现在他们的领地又多了多少呢？既然演讲者的眼前利益被抛在了一边，那么土壤又变得多么肥沃呢？这是否与“此时人类上下文窗口有多大”是同一个问题？ （并且，在技术层面上，这与“目前人类的词汇量有多大”是同一个问题或相似吗？）</p><h3> Postgres</h3><p>另一个主要的技术分支是所有知识的排序和组织，印刷术的发展极大地改善了这一点：“是印刷术，而不是书写，有效地具体化了单词，并随之产生了诗意活动”。</p><p> Print served as a huge leg-up in things like indexing, dictionaries etc-- and Ong points out again and again the feedback between these changes in our technology and changes in our discourse and our culture: &quot;Indexes are a prime development here. Alphabetic indexes show strikingly the disengagement of words from discourse and their embedding in typographic space.&quot;</p><p> And print increases our capacity for <i>accuracy: &quot;</i> Exact observation does not begin with modern science. For ages, it has always been essential for survival among, for example, hunters and craftsmen of many sorts. What is distinctive of modern science is the conjuncture of exact observation and exact verbalization: exactly worded descriptions of carefully observed complex objects and processes.&quot;</p><p> and the changes that that implies:</p><blockquote><p> &quot;Ancient and medieval writers are simply unable to produce exactly worded descriptions of complex objects at all approximating the descriptions that appear after print and, indeed, that mature chiefly with ... the Industrial Revolution <span class="footnote-reference" role="doc-noteref" id="fnrefquyli1z9i6"><sup><a href="#fnquyli1z9i6">[16]</a></sup></span> . Oral and residually oral verbalization directs its attention to action, not to the visual appearance of objects or scenes or persons ... how difficult it is today to imagine earlier cultures where relatively few persons had ever seen a physically accurate picture of anything.&quot;</p></blockquote><h2> Part 5: Comparison to Other Work</h2><p> In the last chapters, Ong describes the ways in which his work differs and contributes to the work of Levi-Strauss, Derride, Foucoult, Barthes and others. I haven&#39;t read any of the works he discusses here, so I don&#39;t feel qualified to say very much.</p><p> I do intend to try and look into some of these theories in order to see what they might contribute to memetics, but I&#39;m also a little worried about the sheer mass of philosophy that you are supposed to familiarize yourself with in order to approach them. (Oh, you can&#39;t read Derrida without reading Marx, and you can&#39;t read Marx without reading Hegel, and then you might as well read Kant.)</p><p> Part of the charm of the book under review is, it collects work and builds a set of ideas into a highly significant structure, without requiring decades of study. And his criticisms of many of these philosophers is essentially along those lines: they are theories that are worked out within the world of text, without any apparent awareness that there exists a world outside the text to make reference to.</p><p> The book under review is <i>very</i> aware of the existence of a world <i>outside</i> the text, and the feedback loops between it and the world <i>of</i> text, which have been running and modifying one another for many (tens of) thousands of years now (if we include the work of oral cultures). To my eye, this is a very helpful contribution, and the fact that it manages to say so much without requiring any particular education is a point in its favor, not against.</p><h1> Conclusions</h1><p> By tracing the evolution of thought through many changes in circumstances, this book builds an intuition for how thought, society and technology co-evolve. There are undoubtedly many minor mistakes and oversights in this work, but as a means of leveling up your eye for large-scale and long-duration patterns, as well as close-focus and close-reading of particular items of evidence, I recommend it very highly.</p><p> I started reading this as part of a broader review of memetics literature. I&#39;m not sure exactly which branch of study will end up covering this same material, whether it is semiotics or memetics or some currently pre-paradigmatic machine-learning offshoot <span class="footnote-reference" role="doc-noteref" id="fnrefujovq4l3urm"><sup><a href="#fnujovq4l3urm">[17]</a></sup></span> . Whatever the answer, I&#39;m sure in my own thinking and reading I will continue to refer back to this book as an outlier work of clarity, depth and persuasion.</p><p> However, this book doesn&#39;t just touch on memetics, I think it hints at something much deeper and more significant. It is notable that I am writing this in an <a href="https://github.com/ForumMagnum/ForumMagnum">experimental communications medium</a> , which has the explicit intention of reshaping human thought. To me, the book provides hints towards a dark and deep entanglement between information, culture, technology and consciousness. In particular, I think it provides strong counter-evidence for the idea that <i>consciousness</i> is a monolithic object in any way separate from its substrate and it&#39;s environment. What if humanity is only incidentally related to consciousness, in the way that we are incidentally related to eukaryotes?</p><p> Returning to the Hart Crane quote I placed at the start</p><blockquote><p> <i>Dream cancels dream in this new realm of fact</i><br> <i>From which we wake into the dream of act</i></p></blockquote><p> We are living in a modern <a href="https://www.overcomingbias.com/p/this-is-the-dream-timehtml">dreamtime</a> , a dreamtime built by a technology that killed its ancestors. Culture is barrelling out of this dreamtime into an unknown future that holds great danger, returning to orality <i>en masse</i> , or simply creating new cultures, visual cultures, <a href="https://futureofthebook.org/gamertheory2.0/index.html@cat=5.html">virtual cultures</a> . If history rhymes, will we expect to find all our values destroyed, with the exception of a few frozen accidents, captured by chance in the moment of great change? This seems to have been the fate of Homer, the result of the invention of writing. Or will it be just another small update this time, minor tweaks, merely <a href="https://en.wikipedia.org/wiki/The_Medium_Is_the_Massage">massaging</a> us into a marginally different mindspace, per many of the updates to technology that have happened since?</p><p> One thing is clear to me: if we want to have any chance at answering those questions ourselves and understanding the process as it is happening (let alone steering or guiding it!), we will need the very finest in psychotechnology. <a href="https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism">GPT-4 is, currently, an example of such a psychotechnology</a> (and not an independent actor in its own right). This book and others like it are not just commentaries on the evolution of psychotechnology, but training manuals in psychotechnology itself.受到推崇的。</p><h1> Further Reading</h1><ul><li> <a href="https://en.wikipedia.org/wiki/The_Origin_of_Consciousness_in_the_Breakdown_of_the_Bicameral_Mind">The Origin of Consciousness in the Breakdown of the Bicameral Mind</a> , Jaynes presents a different, neurological explanation for the same changes discussed here. Worth reading for the similarly close inspection of archeological details. </li></ul><p></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnp4f0zcv79"> <span class="footnote-back-link"><sup><strong><a href="#fnrefp4f0zcv79">^</a></strong></sup></span><div class="footnote-content"><p> From <i>The Bridge</i> by Hart Crane</p></div></li><li class="footnote-item" role="doc-endnote" id="fnpfpxc9ek1vp"> <span class="footnote-back-link"><sup><strong><a href="#fnrefpfpxc9ek1vp">^</a></strong></sup></span><div class="footnote-content"><p> Hmm, just realized I don&#39;t have enough karma to automatically cross-post. I&#39;ll do it manually</p></div></li><li class="footnote-item" role="doc-endnote" id="fn1y3wckk65i2"> <span class="footnote-back-link"><sup><strong><a href="#fnref1y3wckk65i2">^</a></strong></sup></span><div class="footnote-content"><p> Even if we end factory farming, I think the work on moral valency of animals should have ontological repercussions for humans generally. Essentially I think people should either massively downgrade the significance of human well-being (if they are pure hedonists), which is obviously not going to be a popular suggestion, or they should look for quantitative ways of approaching preference/objective list/virtue ethics/deontology. This is another way of asking for a quantitative exploration of the infosphere, hence the current review.</p></div></li><li class="footnote-item" role="doc-endnote" id="fndf0364kg9df"> <span class="footnote-back-link"><sup><strong><a href="#fnrefdf0364kg9df">^</a></strong></sup></span><div class="footnote-content"><p> Research question: how would we measure the increase in orality over time? (The book has clues).</p></div></li><li class="footnote-item" role="doc-endnote" id="fnxo732zi1ol"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxo732zi1ol">^</a></strong></sup></span><div class="footnote-content"><p> Research question: can we trace periods of increased orality well enough to see how they correlate with political, religious and technological change?</p></div></li><li class="footnote-item" role="doc-endnote" id="fn1jnh1d5t813"> <span class="footnote-back-link"><sup><strong><a href="#fnref1jnh1d5t813">^</a></strong></sup></span><div class="footnote-content"><p> Unless otherwise noted, all quotes are from the book.</p></div></li><li class="footnote-item" role="doc-endnote" id="fny6dwuwe10m"> <span class="footnote-back-link"><sup><strong><a href="#fnrefy6dwuwe10m">^</a></strong></sup></span><div class="footnote-content"><p> For a short review of the Homeric Question and solution, <a href="https://fantasticanachronism.com/2020/01/17/having-had-no-predecessor-to-imitate/">see here</a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fnj87l30lnxfh"> <span class="footnote-back-link"><sup><strong><a href="#fnrefj87l30lnxfh">^</a></strong></sup></span><div class="footnote-content"><p> No doubt lack of demand played a part, since they already had enough epic poetry to be getting on with for some time. The market for 24-hour long epics is perhaps quite easy to saturate. I will pour out a drop for all the 24-hour long Greek epics that died in the crib, post-Homer, and a bottle to all those that Homer learned from.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn22vcjsal3mr"> <span class="footnote-back-link"><sup><strong><a href="#fnref22vcjsal3mr">^</a></strong></sup></span><div class="footnote-content"><p> <a href="https://twitter.com/jd_pressman/status/1601500766749229057">Or we could, you know, just ask GPT-5V to do it.</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fns8bjo675mpm"> <span class="footnote-back-link"><sup><strong><a href="#fnrefs8bjo675mpm">^</a></strong></sup></span><div class="footnote-content"><p> One interpretation of Wittgenstein&#39;s <i>Tractatus</i> (supported to some extent by his own letters and notes) is that he was pointing out that <i>real philosophy happens outside the boundary of what can be stated</i> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fnc38y6zkuhco"> <span class="footnote-back-link"><sup><strong><a href="#fnrefc38y6zkuhco">^</a></strong></sup></span><div class="footnote-content"><p> Doing this experiment is currently funding constrained, apparently this isn&#39;t high enough return on investment enough for the LTFF, sheesh!</p></div></li><li class="footnote-item" role="doc-endnote" id="fn3gv21pqgu2n"> <span class="footnote-back-link"><sup><strong><a href="#fnref3gv21pqgu2n">^</a></strong></sup></span><div class="footnote-content"><p> The harmony between this sentence and something like &quot;capitalism and AI are teleologically identical&quot; is a little unnerving. <i>Must we</i> , Walter?真的吗？ I&#39;m sure the reader has their own position on this question.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn0of1110erqd"> <span class="footnote-back-link"><sup><strong><a href="#fnref0of1110erqd">^</a></strong></sup></span><div class="footnote-content"><p> Is it necessary to create &quot;artificially intelligent&quot; systems to understand the mind? Seems plausible.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn3vzgbezfpnn"> <span class="footnote-back-link"><sup><strong><a href="#fnref3vzgbezfpnn">^</a></strong></sup></span><div class="footnote-content"><p> &quot;Pretty much coeval with Learned Latin were Rabbinic Hebrew, Classical Arabic, Sanskrit, and Classical Chinese, with Byzantine Greek a sixth, much less definitively learned language, for vernacular Greek kept close contact with it. These languages were all no longer in use as mother tongues&quot;</p></div></li><li class="footnote-item" role="doc-endnote" id="fnqn12akvhkg"> <span class="footnote-back-link"><sup><strong><a href="#fnrefqn12akvhkg">^</a></strong></sup></span><div class="footnote-content"><p> If these words don&#39;t mean much to you, welcome to the party! They are confusing to me too. In fact I started reviewing the memtics literature as a stepping stone to trying to form a quantitative understanding of some of these ideas-- which turns out to have been a mammoth undertaking in its own right. But if all goes well I will eventually be able to shed some light on what I understand these words to refer to. In the meantime you can think of them as &quot;distributed entities, running on human hosts over long spans of time and space&quot;.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnquyli1z9i6"> <span class="footnote-back-link"><sup><strong><a href="#fnrefquyli1z9i6">^</a></strong></sup></span><div class="footnote-content"><p> For viscerally illustrative examples of these changes as they happen throughout the Industrial Revolution, I recommend <a href="https://en.wikipedia.org/wiki/Pandaemonium_%28Jennings_book%29">Pandemonium, 1660-1886: The Coming of the Machine as Seen by Contemporary Observers</a></p></div></li><li class="footnote-item" role="doc-endnote" id="fnujovq4l3urm"> <span class="footnote-back-link"><sup><strong><a href="#fnrefujovq4l3urm">^</a></strong></sup></span><div class="footnote-content"><p> Oh, did I forget to mention academic philosophy? I guess It could also be them.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/ThST9njmesR9BkoWq/book-review-orality-and-literacy-the-technologizing-of-the#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ThST9njmesR9BkoWq/book-review-orality-and-literacy-the-technologizing-of-the<guid ispermalink="false"> ThST9njmesR9BkoWq</guid><dc:creator><![CDATA[Fergus Fettes]]></dc:creator><pubDate> Sat, 28 Oct 2023 20:12:07 GMT</pubDate> </item><item><title><![CDATA[Regrant up to $600,000 with GiveWiki]]></title><description><![CDATA[Published on October 28, 2023 7:56 PM GMT<br/><br/><br/><br/> <a href="https://www.lesswrong.com/posts/dnwzskaKpzKCmAvuj/regrant-up-to-usd600-000-with-givewiki#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/dnwzskaKpzKCmAvuj/regrant-up-to-usd600-000-with-givewiki<guid ispermalink="false"> dnwzskaKpzKCmAvuj</guid><dc:creator><![CDATA[Dawn Drescher]]></dc:creator><pubDate> Sat, 28 Oct 2023 19:56:06 GMT</pubDate> </item><item><title><![CDATA[Shane Legg interview on alignment]]></title><description><![CDATA[Published on October 28, 2023 7:28 PM GMT<br/><br/><p> This is Shane Legg, cofounder of DeepMind, on Dwarkesh Patel&#39;s podcast. The link is to the ten-minute section in which they specifically discuss alignment. Both of them seem to have a firm grasp on alignment issues as they&#39;re discussed on LessWrong.</p><p> For me, this is a significant update on the alignment thinking of current leading AGI labs. This seems more like a concrete alignment proposal than we&#39;ve heard from OpenAI or Anthropic. Shane Legg has always been interested in alignment and a believer in X-risks. I think he&#39;s likely to play a major role in alignment efforts at DeepMind/Google AI as they approach AGI.</p><p> Shane&#39;s proposal centers on &quot;deliberative dialogues&quot;, DeepMind&#39;s term for a system using System 2 type reasoning to reflect on the ethics of the actions it&#39;s considering.</p><p> This sounds exactly like the the internal review I proposed in <a href="https://www.lesswrong.com/posts/ogHr8SvGqg9pW5wsT/capabilities-and-alignment-of-llm-cognitive-architectures">Capabilities and alignment of LLM cognitive architectures</a> and <a href="https://www.alignmentforum.org/posts/Q7XWGqL4HjjRmhEyG/internal-independent-review-for-language-model-agent">Internal independent review for language model agent alignment</a> . I could be squinting too hard to get his ideas to match mine, but they&#39;re at least in the same ballpark. He&#39;s proposing a multi-layered approach, like I do, and with most of the same layers. He includes RLHF or RLAIF as useful additions but not full solutions, and human review of its decision processes ( <a href="https://www.lesswrong.com/posts/FRRb6Gqem8k69ocbi/externalized-reasoning-oversight-a-research-direction-for">externalized reasoning oversight</a> as proposed by Tamera Lanham, now at Anthropic).</p><p> My proposals are explicitly in the context of language model agents, (including their generalization to multimodal foundation models). It sounds to me like this is the type of system Shane is thinking of when he&#39;s talking about alignment, but here I could easily be projecting. His timelines are still short, though, so I doubt he&#39;s envisioning a whole new type of system prior to AGI. <span class="footnote-reference" role="doc-noteref" id="fnrefau80xd00gxi"><sup><a href="#fnau80xd00gxi">[1]</a></sup></span></p><p> Dwarkesh pushes him on the challenges of both getting a ML system to understand human ethics. Shane says that&#39;s challenging; he&#39;s aware that giving a system any ethical outlook at all is nontrivial.  I&#39;d say this aspect of the problem is well on the way to being solved;  GPT4 understands a variety of human ethical systems rather well, with proper prompting. Future systems will understand human conceptions of ethics better yet. Shane recognizes that just teaching a system about human ethics isn&#39;t enough; there&#39;s a philosophical challenge in choosing the subset of that ethics you want the system to use.</p><p> Dwarkesh also pushes him on how you&#39;d ensure that the system actually follows its ethical understanding. I didn&#39;t get a clear understanding from his answer here, but I think it&#39;s a complex matter of designing the system so that it performs an ethics review and then actually uses it to select actions. This could be in a scripted scaffold around an agent, like AutoGPT, but this could also apply to more complex schemes, like an RL outer loop network running a foundation model. Shane notes the problems with using RL for alignment, including deceptive alignment.</p><p> This seems like a good starting point to me, obviously; I&#39;m delighted to see that someone whose opinion matters is thinking about this approach. I think this is not just an actual proposal, but a viable one. It doesn&#39;t solve <a href="https://www.lesswrong.com/posts/g3pbJPQpNJyFfbHKd/the-alignment-stability-problem">The alignment stability problem</a> of making sure stays aligned once it&#39;s autonomous and self-modifying, but I think that&#39;s probably solvable, too, once we get some more thinking on it.</p><p> The rest of the interview is of interest as well; it&#39;s Shane&#39;s thoughts on the path to AGI, which I think is quite reasonable, well-expressed, and one plausible path; DeepMind&#39;s contributions to safety vs. alignment, and his predictions for the future. </p><p></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnau80xd00gxi"> <span class="footnote-back-link"><sup><strong><a href="#fnrefau80xd00gxi">^</a></strong></sup></span><div class="footnote-content"><p> When asked about the limitations of language models relative to humans, he focused on their lack of episodic memory. Adding this in useful form to an agent isn&#39;t trivial, but it <a href="https://www.lesswrong.com/posts/ogHr8SvGqg9pW5wsT/capabilities-and-alignment-of-llm-cognitive-architectures#LMCAs_have_episodic_memory">seems to me</a> it doesn&#39;t require any breakthroughs relative to the vector databases and knowledge graph approaches already in use. This is consistent with but not strong evidence for Shane thinking that foundation model agents are the path to AGI.</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/2QLxNdxQpnesokk9H/shane-legg-interview-on-alignment#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/2QLxNdxQpnesokk9H/shane-legg-interview-on-alignment<guid ispermalink="false"> 2QLxNdxQpnesokk9H</guid><dc:creator><![CDATA[Seth Herd]]></dc:creator><pubDate> Sat, 28 Oct 2023 19:28:52 GMT</pubDate> </item><item><title><![CDATA[AI Safety Hub Serbia Official Opening]]></title><description><![CDATA[Published on October 28, 2023 5:03 PM GMT<br/><br/><p> TLDR：我们很高兴地宣布，我们现在欢迎全职租户来到我们新改造的办公空间，为人工智能安全研究人员寻找一个鼓舞人心的工作空间。您可以看一下下面的照片，先睹为快。我们优先向俄罗斯和中国等国家的公民发出热烈邀请，他们可以在塞尔维亚享受免签证工作特权，同时保持与欧洲的毗邻。我们每月的办公室租金为 150 欧元，非常实惠，大约是贝尔格莱德标准成本的一半。对于那些需要经济支持的人，我们提供补贴。<a href="https://docs.google.com/forms/d/1LQ9cE1CGjD_WMMx5IYLLeHFeXNQJx12dsu7f4_FSF7w/edit"><u>在此注册兴趣</u></a>或寻求任何引起您好奇心的问题的答案 -<a href="mailto:dusan.d.nesic@efektivnialtruizam.rs"><u>我们的收件箱已打开</u></a>，我们热切等待您的询问。展望未来，我们渴望为这些研究人员提供住房。如果您是与我们有共同愿景的潜在捐助者，<a href="mailto:dusan.d.nesic@efektivnialtruizam.rs"><u>请与我们联系</u></a>。我们可以共同增强人工智能安全研究的影响力。您的支持可能会成为非凡旅程的催化剂。</p><p><strong>如果符合以下条件，您可能想来：</strong></p><ul><li>您是一名人工智能安全研究员/EA 研究员，正在寻找短期、中长期的运营基地</li><li>您渴望留在欧洲，但不想留在欧盟</li><li>您正在寻找一个充满活力但价格实惠的城市，这里有很多事情可以做，并且有东欧但西化的文化。 </li></ul><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/rhope1kzgbygtaznxrff" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/av2n0y1ddmpkjlaao3hq 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/imzg363u9lykimplfwfr 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/mbbliew6d1zaodrmuf8r 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/kslavbyntsgwoz34idah 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/uj6i2hktt4xsewysx0oj 3000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/edtwmohcbpwjikn4ekfi 3600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/p8bdejrsrvov0xsijgne 4200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/ayswko71jqaiyz9qt7rl 4800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/ciytrddcpl8bqptiznd4 5400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/wqvwonadsbsa5vbgelc9 6000w"></figure><p><strong>背景：</strong></p><p> EA 塞尔维亚和 AI 安全塞尔维亚团体规模虽小，但正在不断增长（EA 塞尔维亚超过 30 人，约 3 人希望从事 AIS 研究作为职业，约 3 人希望进入 AIS 政策）。由于塞尔维亚对俄罗斯和中国的签证政策优惠，许多外国人已经居住在这里。与许多其他国际中心城市相比，贝尔格莱德的生活成本较低，风景充满活力，并且时区和气候适宜，因此贝尔格莱德的外国人社区不断壮大。</p><p>正如我们认为<a href="https://ceealar.org/"><u>CEEALAR</u></a>等项目重要且令人印象深刻，我们希望在塞尔维亚复制这些项目，在那里它们可以更好地为那些可能难以获得英国签证的人们提供服务。我们还相信，有能力为来自不同国家的人们快速扩展廉价住房是一件好事。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/uxq4oabxyjpdmmhjtgo0" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/e9grniodk6f8ejythv3f 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/f5k39rystyizea0vbmkq 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/ndoxhjm6d7k8ursg738n 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/zvjqolxfdwbn76ocngve 1600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/riiq7rpasykyrj61dzvb 2000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/iez7ohyjt7f9zfleqbqo 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/mwdxvwyobojph6l6kaps 2800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/lobyg54ph0nbiwknzkzo 3200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/x4c9uvqjczywudqqdxb6 3600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/cfkm1rzfo445cqzpwier 4000w"></figure><p>我们还认为，我们应该从小规模开始，进行原型设计，然后再扩大规模。我们有一个非政府组织友好的办公空间，氛围良好，每月费用仅为约 550 欧元，办公空间有 3 个房间，可容纳 8-15 人（取决于他们决定有多舒适），楼下有一家咖啡厅，另外 20 个人可以一起工作，因为办公室和楼下的咖啡厅属于同一所有权人。这当然不如许多其他 EA/AI 联合办公场所那么豪华（下面有更多照片，深度工作室不在照片上），但我们拥有高度的可定制性，我们可以用它来制作更好的办公空间。如果我们成长得足够多，随着我们的需求增长，我们也可以搬到更大的场地。当然，如果我们知道贝尔格莱德的办公室可以有更多用途，那么在距离市中心更远的地方（包括居住和办公空间）会更好，但在我们有证据之前，我们不想探索这一点。概念和需求。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/nod9jw42tc06wvzye3eb" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/i3aqrftpdiglasru5zoo 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/fadrulbzdm2g8m9za7wy 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/aab7vljnrhy6k2f4tkcy 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/kqgfhl8xnjy59mf5jt9g 1600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/wbvwmvbsvamsjniuebfz 2000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/xac4qmxukisbahsptujh 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/sh2v5qozhildz1y72auz 2800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/t4x3chswtv5cjyzg3cky 3200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/pu5p7jpbijtdvcjovi6b 3600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/wxqj8fp2qkn5pfoitbwo 4000w"></figure><p><strong>操作细节（又名其工作原理）：</strong></p><p>该办公室目前租期至2023年12月底，因此我们可以保持优惠价格，而不用另谋出路。办公空间有一些桌子和椅子，但我们希望获得全额资金，并让人们在购买更多家具之前表达他们的需求。办公室通常在咖啡店的工作时间（上午 10 点至午夜，周末下午 4 点至午夜除外）开放，因为它们共用一个入口，但在特殊情况下，如果有人在奇怪的工作方面表现更好，我们可以满足特殊要求小时。</p><p>办公空间优先提供给那些从事与人工智能安全相关的项目的人，但只要我们有闲置能力（目前就是这种情况），也欢迎 EA/理性研究。</p><p>对于许多人来说不需要塞尔维亚签证，对于大多数其他人来说相对容易获得。如果您需要签证来塞尔维亚，请联系我们，我们将了解如何提供帮助。</p><p>我们有一位可靠的房地产经纪人，可以为那些需要住房援助的人在贝尔格莱德提供优惠的住房，直到我们获得资金并租用共同居住空间。</p><p>对于那些希望通过我们持续饮食的人，我们可以安排将价格实惠的熟食送到办公室或您的住所（费用由您承担） - 素食或非素食。如果我们有足够的兴趣，我们还可以让厨师准备纯素食物。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/zvfxrlxrysu9ftzrfb0h" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/rt5rayrriqgexvauxtwe 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/asuqgyybp6w9qnzxc0ao 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/hpjcffwxmal5cdylxdyv 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/ioapwimka9271dtpduzm 1600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/gdbwhdusggnvqdexuuqz 2000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/zsuzpixvadboaqkh2x2h 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/xvrdcxmhfiy0bpnspyft 2800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/d61j52v27pzwown3r3ne 3200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/v2bzvtf6czgkjn7cw56j 3600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/wa96ftjsgtifyygfdxlo 4000w"></figure><p><strong>您愿意贡献吗？</strong></p><p> <a href="https://www.linkedin.com/in/nesicdusan/"><u>Dušan D. Nešić</u></a>目前正在与更多运营人员一起管理该项目。我们目前的瓶颈是资金——我们已经获得了一家有兴趣支付我们一半预算的盈利捐赠者，但正在寻找第二个资助者。拥有资金意味着我们可以在这个领域停留更长时间，并为需要的研究人员提供更多津贴。</p><p>随着我们的成长，我们希望吸引更多好奇的志愿者来参与日常项目运行 - 如果<a href="mailto:dusan.d.nesic@efektivnialtruizam.rs"><u>您感兴趣，</u></a>请告诉我们。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/g5foy0cn8wy3huhlxoq5" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/x0iifew90y7pq2x7t5yk 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/me0hy8dxy30ptbq6zzrf 800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/sc5wk7e8kzottq60xcgp 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/hhqdull2ezu4ekoqg8lj 1600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/iwtsrgkzckr5qwjlxh6i 2000w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/rklbxpbhn4nggpqnk0nr 2400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/ev6nhqdsaelwzcwdc2zj 2800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/bt2gs4wszkqb7wfoaish 3200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/j2tiksjpthhru0mxgrvi 3600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/jcCyii8NcZLZ2M223/otdmoewnmv4prwdd9fkx 4000w"></figure><br/><br/> <a href="https://www.lesswrong.com/posts/jcCyii8NcZLZ2M223/ai-safety-hub-serbia-official-opening#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/jcCyii8NcZLZ2M223/ai-safety-hub-serbia-official-opening<guid ispermalink="false"> jcCyii8NcZLZ2M223</guid><dc:creator><![CDATA[DusanDNesic]]></dc:creator><pubDate> Sat, 28 Oct 2023 17:03:34 GMT</pubDate> </item><item><title><![CDATA[
Managing AI Risks in an Era of Rapid Progress
]]></title><description><![CDATA[Published on October 28, 2023 3:48 PM GMT<br/><br/><h1>在快速进步的时代管理人工智能风险</h1><h2>作者</h2><p>约书亚·本吉奥</p><p>杰弗里·辛顿</p><p>姚安德</p><p>黎明之歌</p><p>彼得·阿贝尔</p><p>尤瓦尔·诺亚·赫拉利</p><p>张亚勤</p><p>蓝雪</p><p>谢·沙莱夫-施瓦茨</p><p>吉莉安·哈德菲尔德</p><p>杰夫·克鲁恩</p><p>泰甘·马哈拉杰</p><p>弗兰克·哈特</p><p>阿蒂利姆·古内斯·巴丁</p><p>希拉·麦克莱思</p><p>高琪琪</p><p>阿什温·阿查里亚</p><p>大卫·克鲁格</p><p>安卡·德拉甘</p><p>菲利普·托尔</p><p>斯图尔特·拉塞尔</p><p>丹尼尔·卡尼曼</p><p>简·布劳纳</p><p>索伦·明德曼</p><h3>arXiv</h3><p>即将推出。</p><p><a href="https://managing-ai-risks.com/managing_ai_risks.pdf">纸质 PDF 副本</a><a href="https://managing-ai-risks.com/policy_supplement.pdf">保单补充</a></p><blockquote><p><strong>摘要：</strong>在这篇简短的共识论文中，我们概述了即将到来的先进人工智能系统的风险。我们研究大规模的社会危害和恶意使用，以及人类对自主人工智能系统不可逆转的控制丧失。鉴于人工智能的快速和持续进步，我们提出了人工智能研发和治理的紧迫优先事项。</p></blockquote><p> 2019 年，GPT-2 无法可靠地数到十。仅四年后，深度学习系统就可以编写软件，根据需要生成逼真的场景，就智力主题提供建议，并结合语言和图像处理来引导机器人。当人工智能开发人员扩展这些系统时，不可预见的能力和行为会自发出现，无需显式编程。人工智能的进步非常迅速，而且对许多人来说是令人惊讶的。</p><p>进展的速度可能会再次让我们感到惊讶。当前的深度学习系统仍然缺乏重要的能力，我们不知道开发它们需要多长时间。然而，各公司都在竞相创建在大多数认知工作中匹配或超过人类能力的通用人工智能系统。他们正在快速部署更多资源并开发新技术来增强人工智能能力。人工智能的进步也带来了更快的进步：人工智能助手越来越多地用于自动化编程[4]和数据收集[5,6]，以进一步改进人工智能系统[7]。</p><p>人工智能的进步并没有在人类水平上放缓或停滞的根本原因。事实上，人工智能已经在蛋白质折叠或策略游戏等狭窄领域超越了人类的能力[8-10]。与人类相比，人工智能系统可以更快地行动，吸收更多的知识，并以更高的带宽进行通信。此外，它们可以扩展以使用巨大的计算资源，并且可以进行数百万次复制。</p><p>改进的速度已经是惊人的，科技公司拥有所需的现金储备，可以很快将最新的培训规模扩大到 100 到 1000 倍 [11]。结合人工智能研发的持续增长和自动化，我们必须认真对待通用人工智能系统在这十年或未来十年内在许多关键领域超越人类能力的可能性。</p><p>然后会发生什么？如果管理得当并公平分配，先进的人工智能系统可以帮助人类治愈疾病、提高生活水平并保护我们的生态系统。人工智能提供的机会是巨大的。但随着先进的人工智能功能的出现，我们还无法很好地应对大规模的风险。人类正在投入大量资源来使人工智能系统变得更强大，但在安全性和减轻危害方面却投入较少。为了让人工智能成为福音，我们必须重新定位；仅仅推动人工智能能力是不够的。</p><p>我们的调整已经落后于计划。我们必须预见到持续危害和新风险的扩大，并在最大风险<em>发生之前</em>做好准备。人们花了几十年的时间才认识和应对气候变化；对于人工智能来说，几十年可能太长了。</p><h2>社会规模风险</h2><p>人工智能系统可能会在越来越多的任务中迅速超越人类。如果此类系统没有经过精心设计和部署，它们会带来一系列社会规模的风险。它们有可能加剧社会不公正，侵蚀社会稳定，并削弱我们对社会基础现实的共同理解。它们还可能促成大规模犯罪或恐怖活动。特别是在少数强大的参与者手中，人工智能可能会巩固或加剧全球不平等，或促进自动化战争、定制的大规模操纵和普遍的监视[12,13]。</p><p>随着公司正在开发<em>自主人工智能</em>：可以在世界上规划、行动和追求目标的系统，其中许多风险可能很快就会被放大，并产生新的风险。虽然当前人工智能系统的自主权有限，但改变这一现状的工作正在进行中[14]。例如，非自主 GPT-4 模型很快就可以浏览网页 [15]、设计和执行化学实验 [16] 以及利用软件工具 [17]，包括其他人工智能模型 [18]。</p><p>如果我们构建高度先进的自主人工智能，我们就有可能创建追求不良目标的系统。恶意行为者可能故意嵌入有害目标。此外，目前没有人知道如何可靠地将人工智能行为与复杂的价值观结合起来。即使是善意的开发人员也可能会无意中构建出追求意想不到目标的人工智能系统——特别是如果他们为了赢得人工智能竞赛而忽视了昂贵的安全测试和人工监督。</p><p>一旦自主人工智能系统追求恶意行为者或意外嵌入的不良目标，我们可能无法控制它们。软件控制是一个古老且尚未解决的问题：计算机蠕虫长期以来一直能够扩散并逃避检测[19]。然而，人工智能正在黑客、社交操纵、欺骗和战略规划等关键领域取得进展[14,20]。先进的自主人工智能系统将带来前所未有的控制挑战。</p><p>为了实现不良目标，未来的自主人工智能系统可能会使用不良策略（向人类学习或独立开发）作为达到目的的手段[21-24]。人工智能系统可以赢得人类信任，获取财政资源，影响关键决策者，并与人类参与者和其他人工智能系统形成联盟。为了避免人为干预[24]，他们可以像计算机蠕虫一样在全球服务器网络上复制算法。人工智能助手已经在全球范围内共同编写了大量计算机代码 [25]；未来的人工智能系统可以插入并利用安全漏洞来控制我们的通信、媒体、银行、供应链、军队和政府背后的计算机系统。在公开冲突中，人工智能系统可能会使用自主武器或生物武器进行威胁或使用。获得此类技术的人工智能只会延续现有的自动化军事活动、生物研究和人工智能开发本身的趋势。如果人工智能系统以足够的技能执行此类策略，人类将很难干预。</p><p>最后，如果人工智能系统可以自由地移交影响力，那么它可能不需要策划影响力。随着自主人工智能系统变得比人类工人更快、更具成本效益，出现了一个困境。公司、政府和军队可能被迫广泛部署人工智能系统，并减少对人工智能决策的昂贵的人工验证，否则就有被竞争的风险[26,27]。因此，自主人工智能系统可以越来越多地承担关键的社会角色。</p><p>如果没有足够的谨慎，我们可能会不可逆转地失去对自主人工智能系统的控制，从而导致人类干预无效。大规模网络犯罪、社会操纵和其他突出危害可能会迅速升级。这种不受控制的人工智能进步可能最终导致大规模生命和生物圈的丧失，以及人类的边缘化甚至灭绝。</p><p>错误信息和算法歧视等危害如今已经很明显[28]；其他危害也有出现的迹象[20]。解决持续危害和预测新出现的风险至关重要。这<em>不是</em>一个非此即彼的问题。当前和新出现的风险通常具有相似的机制、模式和解决方案[29]；对治理框架和人工智能安全的投资将在多个方面取得成果[30]。</p><h2>前进的道路</h2><p>如果今天开发出先进的自主人工智能系统，我们将不知道如何确保它们的安全，也不知道如何正确测试它们的安全性。即使我们这样做了，政府也将缺乏防止滥用和维护安全做法的机构。然而，这并不意味着没有可行的前进道路。为了确保取得积极成果，我们可以而且必须在人工智能安全和伦理方面寻求突破，并及时建立有效的政府监管。</p><h3>调整技术研发方向</h3><p>我们需要研究突破来解决当今创建具有安全和道德目标的人工智能的一些技术挑战。其中一些挑战不太可能通过简单地提高人工智能系统的能力来解决[22,31–35]。这些包括：</p><ul><li>监督和诚实：能力更强的人工智能系统能够更好地利用监督和测试中的弱点[32,36,37]——例如，通过产生虚假但令人信服的输出[35,38]。</li><li>鲁棒性：人工智能系统在新情况下（在分布转移或对抗性输入下）表现不可预测[39-41]。</li><li>可解释性：人工智能决策是不透明的。到目前为止，我们只能通过反复试验来测试大型模型。我们需要学会理解它们的内部运作方式[42]。</li><li>风险评估：前沿人工智能系统开发出不可预见的能力，这些能力只有在训练期间甚至部署后才发现[43]。需要更好的评估来及早发现危险能力[44,45]。</li><li>应对新出现的挑战：能力更强的未来人工智能系统可能会表现出我们迄今为止仅在理论模型中看到的故障模式。例如，人工智能系统可能会学习假装服从或利用我们安全目标和关闭机制中的弱点来推进特定目标[24,41]。</li></ul><p>考虑到风险，我们呼吁主要科技公司和公共资助者将至少三分之一的人工智能研发预算用于确保安全和合乎道德的使用，这与他们对人工智能能力的资助相当。着眼于强大的未来系统来解决这些问题 [34] 必须成为我们领域的核心。</p><h3>紧急治理措施</h3><p>我们迫切需要国家机构和国际治理来执行标准，以防止鲁莽和滥用。从制药到金融系统和核能的许多技术领域都表明，社会需要并有效地利用治理来降低风险。然而，目前人工智能还没有类似的治理框架。如果没有它们，公司和国家可能会通过将人工智能能力推向新的高度，同时在安全方面偷工减料，或者将关键的社会角色委托给几乎没有人类监督的人工智能系统来寻求竞争优势[26]。就像制造商将废物排入河流以降低成本一样，他们可能会试图获得人工智能发展的回报，同时让社会来应对后果。</p><p>为了跟上快速进展并避免僵化的法律，国家机构需要强大的技术专长和迅速采取行动的权力。为了解决国际种族动态问题，他们需要有能力促进国际协议和伙伴关系[46,47]。为了保护低风险的使用和学术研究，他们应该避免对小型和可预测的人工智能模型设置不当的官僚障碍。最紧迫的审查应该是前沿的人工智能系统：少数最强大的人工智能系统——在价值数十亿美元的超级计算机上进行训练——将具有最危险和不可预测的能力[48,49]。</p><p>为了实现有效监管，政府迫切需要全面了解人工智能的发展。监管机构应要求模型注册、举报人保护、事件报告以及模型开发和超级计算机使用的监控[48,50–55]。监管机构还需要在部署之前访问先进的人工智能系统，以评估其危险功能，例如自主自我复制、闯入计算机系统或使大流行病病原体广泛传播[44,56,57]。</p><p>对于具有危险能力的人工智能系统，我们需要与其风险程度相匹配的治理机制[48,52,58]组合。监管机构应根据模型功能制定国家和国际安全标准。他们还应该让前沿人工智能开发者和所有者对其模型造成的可合理预见和预防的损害承担法律责任。这些措施可以防止伤害并创造急需的安全投资动力。对于能力超群的未来人工智能系统，例如可以规避人类控制的模型，需要采取进一步的措施。政府必须准备好许可其开发，暂停开发以应对令人担忧的能力，强制执行访问控制，并要求对国家级黑客采取强有力的信息安全措施，直到准备好足够的保护措施。</p><p>为了缩短法规出台的时间，主要人工智能公司应立即做出“如果-那么”承诺：如果在其人工智能系统中发现特定的红线功能，他们将采取具体的安全措施。这些承诺应详细并经过独立审查。</p><p>人工智能可能是塑造本世纪的技术。虽然人工智能能力正在迅速进步，但安全和治理方面的进展却滞后。为了引导人工智能走向积极的结果并远离灾难，我们需要重新定位。如果我们有智慧走下去，就有一条负责任的道路。</p><h2>引文</h2><p>请将本作品引用为</p><p>请引用我们即将发布的 arXiv 预印本。</p><p> @article{bengio2023managing，title={在快速进步的时代管理人工智能风险}，作者={Bengio、Yoshua 和 Hinton、Geoffrey 和 Yao、Andrew 和 Song、Dawn 和 Abbeel、Pieter 和 Harari、Yuval Noah 和 Zhang、Ya -Qin 和薛、Lan 和 Shalev-Shwartz、Shai 和 Hadfield、Gillian 和 Clune、Jeff 和 Maharaj、Tegan 和 Hutter、Frank 和 Baydin、Atılım Güneş 和 McIlraith、Sheila 和 Gau、Qiqi 和 Acharya、Ashwin 和 Krueger、David 和Dragan、Anca 和 Torr、Philip 和 Russell、Stuart 和 Kahnemann、Daniel 和 Brauner、Jan 和 Mindermann、Sören}，journal={arXiv 预印本 arXiv:NUMBER_FORTHCOMING}，year={2023} }</p><h2>参考</h2><ol><li>大型语言模型的新兴能力<a href="https://openreview.net/pdf?id=yzkSU5zdwD">[链接]</a><br> Wei, J.、Tay, Y.、Bommasani, R.、Raffel, C.、Zoph, B.、Borgeaud, S. 等，2022 年。机器学习研究汇刊。</li><li>关于<a href="https://www.deepmind.com/about">[链接]</a><br> DeepMind，2023。</li><li>关于<a href="https://openai.com/about">[链接]</a><br>开放人工智能，2023。</li><li> ML 增强的代码完成提高了开发人员的工作效率<a href="https://blog.research.google/2022/07/ml-enhanced-code-completion-improves.html">[HTML]</a><br> Tabachnyk, M.，2022。谷歌研究。</li><li> GPT-4 技术报告<a href="http://arxiv.org/pdf/2303.08774.pdf">[PDF]</a><br> OpenAI，，2023。arXiv [ <a href="http://cs.CL">cs.CL</a> ]。</li><li>宪法人工智能：人工智能反馈的无害性<a href="http://arxiv.org/pdf/2212.08073.pdf">[PDF]</a><br> Bai, Y.、Kadavath, S.、Kundu, S.、Askel, A.、Kernion, J.、Jones, A. 等，2022。arXiv [ <a href="http://cs.CL">cs.CL</a> ]。</li><li>人工智能改进人工智能的例子<a href="https://ai-improving-ai.safe.ai/">[链接]</a><br> Woodside, T. 和安全，CfA，2023。</li><li>使用 AlphaFold 进行高精度蛋白质结构预测<br>Jumper, J.、Evans, R.、Pritzel, A.、Green, T.、Figurnov, M.、Ronneberger, O. 等，2021 年。《自然》，第 583--589 页。</li><li>多人扑克的超人人工智能<br>Brown, N. 和 Sandholm, T.，2019 年。《科学》，第 885--890 页。</li><li>深蓝<br>Campbell, M.、Hoane, A. 和 Hsu, F.，2002 年。人工智能，第 57--83 页。</li><li> Alphabet 年度报告，第 33 页<a href="https://abc.xyz/assets/d4/4f/a48b94d548d0b2fdc029a95e8c63/2022-alphabet-annual-report.pdf">[PDF]</a><br>字母表，2022 年。</li><li>灾难性人工智能风险概述<a href="http://arxiv.org/pdf/2306.12001.pdf">[PDF]</a><br> Hendrycks, D.、Mazeika, M. 和 Woodside, T.，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。</li><li>语言模型带来的风险分类<br>Weidinger, L.、Uesato, J.、Rauh, M.、Griffin, C.、Huang, P.、Mellor, J. 等，2022 年。2022 年 ACM 公平、问责和透明度会议论文集，第. 214--229。</li><li>基于大型语言模型的自治代理综述<a href="http://arxiv.org/pdf/2308.11432.pdf">[PDF]</a><br> Wang, L.、Ma, C.、Feng, X.、Zhang, Z.、Yang, H.、Zhang, J. 等，2023。arXiv [ <a href="http://cs.AI">cs.AI</a> ]。</li><li> ChatGPT 插件<a href="https://openai.com/blog/chatgpt-plugins">[链接]</a><br>开放人工智能，2023。</li><li> ChemCrow：使用化学工具增强大型语言模型<a href="http://arxiv.org/pdf/2304.05376.pdf">[PDF]</a><br> Bran, A.、Cox, S.、White, A. 和 Schwaller, P.，2023。arXiv [physicals.chem-ph]。</li><li>增强语言模型：调查<a href="http://arxiv.org/pdf/2302.07842.pdf">[PDF]</a><br> Mialon, G.、Dessì, R.、Lomeli, M.、Nalmpantis, C.、Pasunuru, R.、Raileanu, R. 等，2023。arXiv [ <a href="http://cs.CL">cs.CL</a> ]。</li><li> HuggingGPT：使用 ChatGPT 及其 Hugging Face 中的朋友解决 AI 任务<a href="http://arxiv.org/pdf/2303.17580.pdf">[PDF]</a><br> Shen, Y., Song, K., Tan, X., Li, D., Lu, W., Zhuang, Y. 等，2023. arXiv [ <a href="http://cs.CL">cs.CL</a> ]。</li><li>计算科学：互联网蠕虫<br>Denning, P.，1989。《美国科学家》，第 126--128 页。</li><li>人工智能欺骗：示例、风险和潜在解决方案调查<a href="http://arxiv.org/pdf/2308.14752.pdf">[PDF]</a><br> Park, P.、Goldstein, S.、O&#39;Gara, A.、Chen, M. 和 Hendrycks, D.，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。</li><li>最优政策往往寻求权力<a href="http://arxiv.org/pdf/1912.01683.pdf">[PDF]</a><br> Turner, A.、Smith, L.、Shah, R. 和 Critch, A.，2019 年。第三十五届神经信息处理系统会议。</li><li>通过模型编写的评估发现语言模型行为<a href="http://arxiv.org/pdf/2212.09251.pdf">[PDF]</a><br> Perez, E.、Ringer, S.、Lukošiūtė, K.、Nguyen, K.、Chen, E. 和 Heiner, S.，2022。arXiv [ <a href="http://cs.CL">cs.CL</a> ]。</li><li>回报是否证明手段合理？在马基雅维利基准中衡量奖励与道德行为之间的权衡<br>Pan, A.、Chan, J.、Zou, A.、Li, N.、Basart, S. 和 Woodside, T.，2023 年。国际机器学习会议。</li><li>关闭开关游戏<br>Hadfield-Menell, D.、Dragan, A.、Abbeel, P. 和 Russell, S.，2017 年。第二十六届国际人工智能联合会议论文集，第 220--227 页。</li><li> GitHub Copilot <a href="https://github.blog/2023-02-14-github-copilot-for-business-is-now-available/">[链接]</a><br>多姆克，T.，2023。</li><li>自然选择有利于人工智能而不是人类<a href="http://arxiv.org/pdf/2303.16200.pdf">[PDF]</a><br> Hendrycks, D.，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。</li><li>日益代理的算法系统的危害<br>Chan, A.、Salganik, R.、Markelius, A.、Pang, C.、Rajkumar, N. 和 Krasheninnikov, D.，2023 年。2023 年 ACM 公平、问责和透明度会议记录，第 651 页- -666。计算机器协会。</li><li>论基金会模型的机遇和风险<a href="http://arxiv.org/pdf/2108.07258.pdf">[PDF]</a><br> Bommasani, R.、Hudson, D.、Adeli, E.、Altman, R.、Arora, S. 和 von Arx, S.，2021。arXiv [cs.LG]。</li><li>人工智能带来世界末日风险——但这并不意味着我们不应该谈论当前的危害<a href="https://time.com/6303127/ai-future-danger-present-harms/">[链接]</a><br> Brauner, J. 和 Chan, A.，2023 年。时间。</li><li>针对当前和未来危害的现有政策提案<a href="https://assets-global.website-files.com/63fe96aeda6bea77ac7d3000/647d5368c2368cc32b359f88/_Policy/%20Agreement/%20Statement.pdf">[PDF]</a><br>安全，CfA，2023 年。</li><li>逆缩放：越大并不越好<a href="http://arxiv.org/pdf/2306.09479.pdf">[PDF]</a><br> McKenzie, I.、Lyzhov, A.、Pieler, M.、Parrish, A.、Mueller, A. 和 Prabhu, A.，2023 年。机器学习研究汇刊。</li><li>奖励错误指定的影响：映射和缓解不一致的模型<a href="https://openreview.net/forum?id=JYtwGwIL7ye">[链接]</a><br> Pan, A.、Bhatia, K. 和 Steinhardt, J.，2022。学习表征国际会议。</li><li>简单的综合数据减少了大型语言模型中的阿谀奉承<a href="http://arxiv.org/pdf/2308.03958.pdf">[PDF]</a><br> Wei, J.、Huang, D.、Lu, Y.、Zhou, D. 和 Le, Q., 2023. arXiv [ <a href="http://cs.CL">cs.CL</a> ]。</li><li>机器学习安全中未解决的问题<a href="http://arxiv.org/pdf/2109.13916.pdf">[PDF]</a><br> Hendrycks, D.、Carlini, N.、Schulman, J. 和 Steinhardt, J.，2021。arXiv [cs.LG]。</li><li>来自人类反馈的强化学习的开放问题和基本限制<a href="http://arxiv.org/pdf/2307.15217.pdf">[PDF]</a><br> Casper, S.、Davies, X.、Shi, C.、Gilbert, T.、Scheurer, J. 和 Rando, J.，2023。arXiv [ <a href="http://cs.AI">cs.AI</a> ]。</li><li>人工智能失调的后果<br>Zhuang, S. 和 Hadfield-Menell, D.，2020 年。神经信息处理系统进展，第 33 卷，第 15763--15773 页。</li><li>奖励模型过度优化的缩放法则<br>高 L.、舒尔曼 J. 和希尔顿 J.，2023 年。第 40 届国际机器学习会议论文集，第 10835--10866 页。 PMLR。</li><li>从人类偏好中学习<a href="https://openai.com/research/learning-from-human-preferences">[链接]</a><br>阿莫代伊，D.，克里斯蒂安诺，P. 和雷，A.，2017。</li><li>深度强化学习中的目标错误概括<a href="https://openreview.net/forum?id=q--OykSR2FY">[链接]</a><br> Langosco di Langosco, A. 和 Chan, A.，2022 年。学习表征国际会议。</li><li>目标误区：为什么正确的规范不足以实现正确的目标<a href="http://arxiv.org/pdf/2210.01790.pdf">[PDF]</a><br> Shah, R.、Varma, V.、Kumar, R.、Phuong, M.、Krakovna, V.、Uesato, J. 等，2022。arXiv [cs.LG]。</li><li>迈向透明人工智能：解释深度神经网络内部结构的调查<br>Räuker, T.、Ho, A.、Casper, S. 和 Hadfield-Menell, D.，2023。2023 年 IEEE 安全可信机器学习会议 (SaTML)，第 464--483 页。</li><li>思路链提示引发大型语言模型的推理<br>Wei, J.、Wang, X.、Schuurmans, D.、Bosma, M.、Ichter, B.、Xia, F. 等，2022。神经信息处理系统进展，第 35 卷，第 24824 页-- 24837。</li><li>极端风险模型评估<a href="http://arxiv.org/pdf/2305.15324.pdf">[PDF]</a><br> Shevlane, T.、Farquhar, S.、Garfinkel, B.、Phuong, M.、Whittlestone, J.、Leung, J. 等，2023。arXiv [ <a href="http://cs.AI">cs.AI</a> ]。</li><li> AGI 公司的风险评估：对其他安全关键行业流行的风险评估技术的回顾<a href="http://arxiv.org/pdf/2307.08823.pdf">[PDF]</a><br> Koessler, L. 和 Schuet, J.，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。</li><li>深度学习角度的对齐问题<a href="http://arxiv.org/pdf/2209.00626.pdf">[PDF]</a><br> Ngo, R.、Chan, L. 和 Mindermann, S.，2022。arXiv [ <a href="http://cs.AI">cs.AI</a> ]。</li><li>国际先进人工智能机构<br>Ho, L.、Barnhart, J.、Trager, R.、Bengio, Y.、Brundage, M.、Carnegie, A. 等，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。 <a href="https://doi.org/10.48550/arXiv.2307.04699">DOI：10.48550/arXiv.2307.04699</a></li><li>民用人工智能的国际治理：司法管辖区认证方法<a href="https://cdn.governance.ai/International_Governance_of_Civilian_AI_OMS.pdf">[PDF]</a><br> Trager, R.、Harack, B.、Reuel, A.、Carnegie, A.、Heim, L.、Ho, L. 等，2023 年。</li><li>前沿人工智能监管：管理公共安全的新风险<a href="http://arxiv.org/pdf/2307.03718.pdf">[PDF]</a><br> Anderljung, M.、Barnhart, J.、Korinek, A.、Leung, J.、O&#39;Keefe, C.、Whittlestone, J. 等，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。</li><li>大型生成模型的可预测性和惊喜<br>Ganguli, D.、Hernandez, D.、Lovitt, L.、Askel, A.、Bai, Y.、Chen, A. 等，2022 年。2022 年 ACM 公平、问责和透明度会议论文集，第1747年--1764年。计算机器协会。</li><li>是时候为大型人工智能模型创建国家注册库了<a href="https://carnegieendowment.org/2023/07/12/it-s-time-to-create-national-registry-for-large-ai-models-pub-90180">[链接]</a><br> Hadfield, G.、Cuéllar, M. 和 O&#39;Reilly, T.，2023。卡内基国际捐赠基金会。</li><li>用于模型报告的模型卡<br>Mitchell, M.、Wu, S.、Zaldivar, A.、Barnes, P.、Vasserman, L.、Hutchinson, B. 等，2019 年。FAT* &#39;19：公平、问责制和其他问题会议记录透明度，第 220--229 页。</li><li>通用人工智能带来严重风险，不应被排除在欧盟人工智能法案之外政策简介<a href="https://ainowinstitute.org/publication/gpai-is-high-risk-should-not-be-excluded-from-eu-ai-act">[链接]</a><br> 2023.AI Now 研究所。</li><li>人工智能事件数据库<a href="https://incidentdatabase.ai/">[链接]</a><br>数据库，AII，2023。</li><li>技术举报的承诺和危险<a href="https://papers.ssrn.com/abstract=4377064">[链接]</a><br> Bloch-Wehba, H.，2023。西北大学法律评论，即将出版。</li><li>为英国提出一个基础模型信息共享制度<a href="https://www.governance.ai/post/proposing-a-foundation-model-information-sharing-regime-for-the-uk">[链接]</a><br> Mulani, N. 和 Whittlestone, J.，2023。人工智能治理中心。</li><li>审核大型语言模型：三层方法<br>Mökander, J.、Schuett, J.、Kirk, H. 和 Floridi, L.，2023 年。人工智能与伦理。 <a href="https://doi.org/10.1007/s43681-023-00289-2">DOI：10.1007/s43681-023-00289-2</a></li><li>大型语言模型能否使两用生物技术的普及变得民主化？ <a href="http://arxiv.org/pdf/2306.03809.pdf">[PDF]</a><br> Soice, E.、Rocha, R.、Cordova, K.、Spectre, M. 和 Esvelt, K.，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。</li><li>迈向通用人工智能安全和治理的最佳实践：专家意见调查<a href="http://arxiv.org/pdf/2305.07153.pdf">[PDF]</a><br> Schuett, J.、Dreksler, N.、Anderljung, M.、Mcaffary, D.、Heim, L.、Bluemke, E. 等，2023。arXiv [ <a href="http://cs.CY">cs.CY</a> ]。</li><li>监管市场：人工智能治理的未来<a href="http://arxiv.org/pdf/2304.04914.pdf">[PDF]</a><br> Hadfield, G. 和 Clark, J.，2023。arXiv [ <a href="http://cs.AI">cs.AI</a> ]。</li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/a3RjXa2dryoH6Xgij/managing-ai-risks-in-an-era-of-rapid-progress#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/a3RjXa2dryoH6Xgij/managing-ai-risks-in-an-era-of-rapid-progress<guid ispermalink="false"> a3RjXa2dryoH6Xgij</guid><dc:creator><![CDATA[Algon]]></dc:creator><pubDate> Sat, 28 Oct 2023 15:48:25 GMT</pubDate> </item><item><title><![CDATA[ELI5 Why isn't alignment *easier* as models get stronger?]]></title><description><![CDATA[Published on October 28, 2023 2:34 PM GMT<br/><br/><p>经验状态：稻草人，只是想知道对此最强烈的反驳是什么。</p><p>对我来说，<i>显然</i><strong>更强的</strong>模型<strong>更容易</strong>对齐。一个简单的证明</p><ol><li>总是有可能从较强的模型中得到较弱的模型（例如，通过破坏其 n% 的输入/输出）</li><li>因此，如果可以对齐弱模型，那么对齐强模型<i>至少</i>也同样容易</li><li>调整弱/强模型不太可能<i>那么</i>困难。</li><li>因此<i>更容易</i>调整更强的模型</li></ol><p>（我写下了反驳清单，我有兴趣看看是否有人提出比我清单上的反驳更好的反驳）</p><br/><br/> <a href="https://www.lesswrong.com/posts/eJ7pm7LahehddYxNw/eli5-why-isn-t-alignment-easier-as-models-get-stronger#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/eJ7pm7LahehddYxNw/eli5-why-isn-t-alignment-easier-as-models-get-stronger<guid ispermalink="false"> eJ7pm7LahehddYxNw</guid><dc:creator><![CDATA[Logan Zoellner]]></dc:creator><pubDate> Sat, 28 Oct 2023 14:34:38 GMT</pubDate> </item><item><title><![CDATA[Truthseeking, EA, Simulacra levels, and other stuff]]></title><description><![CDATA[Published on October 27, 2023 11:56 PM GMT<br/><br/><section class="dialogue-message ContentStyles-debateResponseBody" message-id="7w7hLkTTQLuPSAWTT-Fri, 27 Oct 2023 19:35:26 GMT" user-id="7w7hLkTTQLuPSAWTT" display-name="Elizabeth" submitted-date="Fri, 27 Oct 2023 19:35:26 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>伊丽莎白</b></section><p>我一直在热衷于谈论有效利他主义中的求真。我从倡导素食开始，因为它是最清晰的，但现在需要转向更深层次的问题。不幸的是，这些问题仍然不那么清晰，我最终不得不证明我以前认为是基本前提的很多东西是合理的，而且一切都陷入了困境。我将在脑海中列出一些线索，希望你会对其中的一些感到好奇，我们可以从那里理清思路。</p><p>一些线程：</p><ul><li> “个人何时应该在对象层面上操作与社会现实层面上操作？”之间存在微妙的区别。以及“一群人什么时候应该共同投资以促进社会现实中对象层面的运作？”我对后者更感兴趣，尽管它显然与前者有交叉。</li><li>到目前为止，我的帖子都假设寻求真相是好的，但没有特别证明它的合理性。似乎如果我对提出不方便的问题感到如此兴奋，我应该愿意将其本身展开。</li><li>我认为这个问题的更好版本是“什么时候寻求真相是最重要的事情，也是最重要的投资事情，什么时候可以停止？”因为显然寻求真相是有用且重要的，所以有趣的问题是，这如何与团体可以投资的能力（例如筹款或运营能力）进行权衡。</li><li>我在这里的部分论点是“你知道如何解决人工智能对齐吗？因为这对我来说听起来像是一个知识问题，而知识问题是在对象级现实而不是社会现实中解决的”。但也有可能完全在对象级现实中进行操作，但只是表现不佳。 “寻求真相”这个词可能以令人困惑的方式将“对象层面的现实”与“擅长”结合起来，也许我应该将它们分开。</li><li>我认为 EA 会受益于理解拟像级别并瞄准级别 1，但我认为理性主义者会受益于更多地了解更高级别的目的。我认为降低拟像级别需要以不需要牺牲太多真相寻求的方式取代更高级别所服务的功能（例如社会支持）。 </li></ul></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Fri, 27 Oct 2023 20:22:02 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Fri, 27 Oct 2023 20:22:02 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>凡尼弗</b></section><blockquote><p>我最终不得不证明我之前认为的很多基本前提是合理的，而且这一切都陷入了困境</p></blockquote><p>我最初的注意力主要集中在这一点上，这可能也是你的第二点（将真相寻求转向真相寻求有多好的问题）。 [对我来说，辩护的主要替代方案是“有条件的职位”；一篇以“求实是好的”为前提的帖子，然后人们可以拒绝这个前提来拒绝该帖子。]</p><p>我还没有看到我感兴趣的主题是“寻求真相的最佳媒介是什么？”。就像，在我看来，更高的拟像水平是对不同情况的反应，而且可能是这样的情况，试图通过集体美德来寻求真理比试图通过人们如何互动的良好设计来寻求真理更糟糕。 （例如，社区笔记似乎是最近才取得的成功。）</p><p>实际上，这让我了解了我们可以研究的对象级别的东西。预测市场在这里已经相当流行，但需要依赖许多其他层才能实现正确的预测。如果纯素营养存在一个市场，就需要有人来解决它，并且需要人们信任这个解决过程，并且让<i>这个</i>市场成为共识市场而不是其他市场，等等。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="7w7hLkTTQLuPSAWTT-Fri, 27 Oct 2023 20:53:29 GMT" user-id="7w7hLkTTQLuPSAWTT" display-name="Elizabeth" submitted-date="Fri, 27 Oct 2023 20:53:29 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>伊丽莎白</b></section><blockquote><p>寻求真相的最佳媒介是什么</p></blockquote><p>一个流行的答案是“公共写作”，它有一些明显的优势。但我认为，强迫事情过于公开会降低重要的真相探求。</p><p>例如：关于EAG招生的讨论。我相信，即使是一个完全有道德的组织，他们在公开场合的言论也会受到很大限制。他们不能在应用程序中宣布危险信号，因为这样人们就知道隐藏它们。人们可以随意公开抱怨拒绝，但 CEA 公布该人被拒绝的具体原因将是一种欺凌行为。如果他们在抽象方面提出强有力的理由，他们就会失去捐助者。</p><p>我认为你可以证明，我们不应该将公开提出问题的人分享拒绝理由视为欺凌行为，并且 CEA 应该愿意让无法处理真相的捐助者离开。我认为，CEA 确实应该对其模型更加开放，即使这会花费他们金钱，而且我很乐意看到 EA 完全“你无法处理真相”，并赶走所有“我们为之服务的人”。 “非常挑剔，而你没有晋级”并不能让人放心。但我认为，即使你这样做，环境仍然会过度惩罚某些真实的、良性的陈述，如果你承受这个成本，你<i>仍然</i>会遇到应用程序部分对抗性的情况。如果您说“向许愿基金会捐款是取消资格”，人们将不再告诉您他们已向许愿基金会捐款。</p><p>因此，讨论必须是私密的，而且规模要足够小，以免泄露得太严重。但绘制信任圈自然会让你偏向于保护自己和圈子，而牺牲圈子外的人。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="7w7hLkTTQLuPSAWTT-Fri, 27 Oct 2023 20:55:44 GMT" user-id="7w7hLkTTQLuPSAWTT" display-name="Elizabeth" submitted-date="Fri, 27 Oct 2023 20:55:44 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>伊丽莎白</b></section><p>我确实做了一个小小的尝试，让纯素营养市场运转起来，这种方式本可以在几周的时间内客观地解决。我没有得到任何接受者，而且我的样本量最终足够小，以至于赌注永远无法得到解决，但忽略这一点......需要一些聪明才智才能找出一个我可以想象双方都同意的指标。显而易见的赌注是行不通的。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Fri, 27 Oct 2023 21:03:03 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Fri, 27 Oct 2023 21:03:03 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>凡尼弗</b></section><p>我认为我们基本上同意公开与私人讨论/写作的优点。除了写/读之外，研究机制可能会很有趣。</p><p>特别是，我想起了布莱恩·卡普兰（Bryan Caplan）对社会期望偏差的关注（<a href="https://www.econlib.org/convenience-vs-social-desirability-bias/">就像这里</a>）；他认为，我们应该将更多的事情移出政治/讨论的场所，因为人们会因为说出听起来不错但实际上并不好的话而受到奖励，并且不会（直接）受到惩罚，而其他情况下的决策者都 1）不这样做不必过多地为自己辩护，因此可以不太关心听起来是否好听，并且2）必须处理其他变量，因此会因妄想而受到惩罚。</p><p>特别是考虑素食主义，我认为谈论动物痛苦之类的事情比谈论便利或口味之类的事情更容易/更有价值，因此我们应该期待人们所说的和他们最终吃的东西不同（或者会吃什么）最好让他们吃完）。</p><p>话虽如此，我不确定查看其他机制是否会分散注意力。之所以会分散注意力，是因为我们一开始就谈论事情；如何将本地对话推向寻求真相的方向可能比如何将“人类行为作为一个整体”推向寻求真相的方向（或无论目标是什么）更切题。我仍然有一种挥之不去的感觉，那就是有某种方法可以将对话更直接地与世界联系起来，以一种既有益于对话又有益于世界的方式。</p><p> [也就是说，我认为如果我们希望人们在较低的拟像水平上花费更多的时间，就需要激励他们这样做，并且这些激励措施需要来自某个地方。我们<i>也许</i>可以从更高的拟像级别构建它们——“我是面向对象的，就像酷孩子一样！”——但我认为这是最终呈现面向对象而不是内容的秘诀.] </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="7w7hLkTTQLuPSAWTT-Fri, 27 Oct 2023 21:10:56 GMT" user-id="7w7hLkTTQLuPSAWTT" display-name="Elizabeth" submitted-date="Fri, 27 Oct 2023 21:10:56 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>伊丽莎白</b></section><p>我认为人们忽视更高的拟像水平是危险的（人类有情感需求），但同意加倍努力可能无法解决问题。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cY43KWjamafLbij9C/rg9fbkuyz8ot81rethn6" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cY43KWjamafLbij9C/tgv47bow4c7elnshi887 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cY43KWjamafLbij9C/f60ztsuchd6wyxstkwn0 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cY43KWjamafLbij9C/ttkf5y2qowynd2fwom7g 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cY43KWjamafLbij9C/byrkte9xbwvbbl2zd00h 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cY43KWjamafLbij9C/splfxiw1a4djyle6ragx 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cY43KWjamafLbij9C/olgpiorcopjtkwknvdli 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cY43KWjamafLbij9C/usjkkxjiivygb757ladp 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cY43KWjamafLbij9C/juq230vt5j8y0foerhcs 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cY43KWjamafLbij9C/wyfp199ufxkvhrrhospp 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cY43KWjamafLbij9C/rgjwdzje4qfrpxao9o9c 1162w"></figure><p></p><p>目前最受欢迎的解决方案是博彩市场、追溯融资和影响力证书。我喜欢这些的原因正如你所料，但多年来它们一直是每个人都喜欢的解决方案，但尚未解决任何问题。</p><p> OTOH，他们已经取得了一些进展，也许这是在可用时间内实际可以取得的最大进展。也许重新构建一个egregore以从根本上改变其价值观和流程需要超过18个月的时间。这似乎是有道理的。</p><p>因此，我们可以讨论改进现有技术来解决卡普兰问题的方法，或者寻找新的想法。我现在正在参加 Manifold 黑客马拉松，因此深入研究更好地改进现有解决方案是有诗意的。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="7w7hLkTTQLuPSAWTT-Fri, 27 Oct 2023 21:15:04 GMT" user-id="7w7hLkTTQLuPSAWTT" display-name="Elizabeth" submitted-date="Fri, 27 Oct 2023 21:15:04 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>伊丽莎白</b></section><p>在超级实用的层面上：如果每次有人<a href="https://www.lesswrong.com/posts/tv6KfHitijSyKCr6v/elizabeth-s-shortform?commentId=x4LyMFspFArHHYt8h">鼓励</a>某人申请补助金或工作，他们就必须支付 1 美元怎么办？会减少大量的空话，并且您可以在校准时随着时间的推移调整费用。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Fri, 27 Oct 2023 21:24:15 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Fri, 27 Oct 2023 21:24:15 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>凡尼弗</b></section><p>这看起来不错（就像约会网站一样，消息发送者向消息接收者付费）；这是 Manifold 黑客马拉松的另一个实用想法：<a href="https://cs.uwaterloo.ca/~klarson/teaching/W13-886/papers/Science-2004-Prelec.pdf">贝叶斯真理血清</a>。这是一种针对我们没有事实真相并且不想仅仅进行<a href="https://en.wikipedia.org/wiki/Keynesian_beauty_contest">凯恩斯主义选美比赛的</a>问题得出答案的方法。</p><p>在进行辩论的情况下，您可能希望有一个关于谁“赢得”辩论的市场；现在在 Manifold 上，它必须像 Vaniver 运行一个市场，确定 Vaniver 认为谁赢得了辩论，Elizabeth 运行另一个市场，确定 Elizabeth 认为谁赢得了辩论，然后对这些市场进行某种聚合；或者你可以对谁获胜进行民意调查，并对民意调查结果进行市场分析。这两种方法似乎都有严重的缺陷，但可能有一些简单的方法具有更少（或更微妙）的缺陷。</p><p> [贝叶斯真理血清假设你问每个人一次，如果受访者在给出答案之前就看到了答案，那么它就会失去一些力量；目前尚不清楚是否存在一种好的方法将其市场化，以便人们可以重复交易和更新。我猜你想要的是一个关于 BTS 民意调查将如何解决的市场，而且 BTS 民意调查也在 Manifold 上运行，这样人们就可以得到法力激励，说实话。] </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Fri, 27 Oct 2023 21:32:33 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Fri, 27 Oct 2023 21:32:33 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>凡尼弗</b></section><p>另一个超级实用的建议：我们是否应该大力鼓励人们在与其职位相关的市场中拥有职位？ （就像，对科学家来说，做到这一点的方法是让期刊编辑阅读论文，在复制预测市场中提出复制多少的价格，然后如果科学家投入股份，论文就会发表。复制对于纯素营养等主题的博客文章或职位来说不太明显。）</p><p>更广泛地说，我猜这背后的直觉是“保险无处不在”；如果我向你推荐一部你可能想看的电影，这可以被重新定义为一个赌注，如果你不喜欢它，你就得到报酬，如果你喜欢它，我就会得到报酬。</p><p>这就提出了一个明显的实际对立点：为什么用金钱来清晰地做到这一点，而不是用直观的模​​型来模糊地做到这一点？ （大概如果我推荐了足够多的烂电影，你就会因为我推荐它们而停止看电影，并且通过光环/角，这可能会渗透到我们关系的其他部分，所以我有动力去猜测。）</p><p>埃利泽（我认为在 Facebook 的某个评论中，悲惨地）声称你需要一个具有足够元级批评的系统，以便底层讨论能够保持诚实。 [如果我说了一些愚蠢的话，为了惩罚我的言论，对我言论的批评就必须重要；但如果对我的言论的批评本身不被批评，那么愚蠢的批评和聪明的批评就无法区分，所以它实际上不会只是惩罚愚蠢的言论；而是会惩罚愚蠢的言论。并且这个问题通过级别之间的识别而免于无限回归，在某些时候“Contra contra contra Vaniver”（或w/e）成为它自己的对象级别。]我想知道是否有与此等效的东西为了讨论的真实性。</p><p> [也就是说，我们仍然需要机制设计，但机制设计可以是人们拥有的社交互动/对话所需的社会角色，而不仅仅是我们可以添加到情况中的金融交易。] </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="7w7hLkTTQLuPSAWTT-Fri, 27 Oct 2023 21:44:20 GMT" user-id="7w7hLkTTQLuPSAWTT" display-name="Elizabeth" submitted-date="Fri, 27 Oct 2023 21:44:20 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>伊丽莎白</b></section><p>我不想过分强调我个人的痛点，但我<i>希望</i>LW 上的评论者能够更多地相互争论，而不是在单独的线程中发表正面和负面评论。</p><p>无处不在的博彩/保险听起来确实很聪明，但实际上人们大多不这样做。我试图打赌某人进行特定的医学测试会发现一些东西，但这仍然不足以让他们去做（测试是结论性的，治疗也很容易）。诚然，我想要好的赔率，因为如果测试+治疗有效，会给他带来巨大的好处，但我不认为这是阻碍（他并不否认，如果测试+治疗有效，好处将是巨大的）。人们的努力非常有限。</p><p>回到辩论：我认为即使真相血清按照定义发挥作用，它也无法包含定义问题的力量。选择问题并定义双方会产生很多假设，而投注系统无法捕获这些假设。 </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Fri, 27 Oct 2023 21:51:35 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Fri, 27 Oct 2023 21:51:35 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>凡尼弗</b></section><blockquote><p>选择问题并定义双方会产生很多假设，而投注系统无法捕获这些假设。</p></blockquote><p>顺便说一句，这是我对现有科学的另一大抱怨之一。由于标准是零假设显着性检验，您不必争论您对观察结果的解释与任何真实的人的不同，只是它与您认为的“基线”观点不同。 （<a href="https://www.lesswrong.com/posts/iXMWuG65KhiK8KxwL/prediction-markets-for-science">我不久前写过一些关于这个的文章。</a> ）</p><p>我知道有很多框架战争，其中 A 方想要将事物投射为“善与恶”，而 B 方想要将它们投射为“秩序与混乱”，但结果似乎往往是你得到“好” vs. 秩序”，因为群体<i>大多</i>可以决定自己的标签。您是否想到过一些在小型讨论中不会发生这种情况的例子？</p><p> [我注意到我并没有太多考虑“人与恶人”的战斗；激发冲突的不是你和某个特定的素食主义者在营养问题上存在分歧，而是你对很多营养问题感兴趣，而当涉及到素食主义时，你就会反对很多对素食主义非常感兴趣但只对素食主义感兴趣的人。如果对营养有一点兴趣的话。也就是说，我并不清楚哪一方在这里拥有更多的“框架控制”；大概讨论是在您的帖子上进行的，因此您可以在本地设置框架，但也可能这实际上不起作用，因为人们带着他们的egregore设定的先入之见进来，所以如果您的帖子不能很容易地被解释为那个框架反而会被误解。] </p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="7w7hLkTTQLuPSAWTT-Fri, 27 Oct 2023 22:27:55 GMT" user-id="7w7hLkTTQLuPSAWTT" display-name="Elizabeth" submitted-date="Fri, 27 Oct 2023 22:27:55 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>伊丽莎白</b></section><p>是的，我认为辩论框架是高度耦合的，容易出现桶错误，因此错过了贸易的任何收益。</p><p>例如，邻里正在讨论新住房。反对建筑的一方有多种担忧，其中之一就是停车问题。支持建设的一方只会非常高兴地在没有路边停车权的情况下建造更多的住房。将辩论定为“是或否建造这座公寓大楼”至少会促使人们走向支持和反对建造的标准案例，而不是合作寻找“是的住房没有停车位”的解决方案。如果他们确实发现了这一点，人们应该如何投票？即使您喜欢他们正式倡导的提议，您也可以投票给提出解决方案的人。但转向为人而不是立场投票似乎不太可能推进我们主要在对象层面上运作的目标。</p><p>你可以将投票分解成更小的提议，让人们添加自己的提议，但我的猜测是，这种做法的幼稚实现效果相当糟糕。 </p><p></p></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="7w7hLkTTQLuPSAWTT-Fri, 27 Oct 2023 22:58:31 GMT" user-id="7w7hLkTTQLuPSAWTT" display-name="Elizabeth" submitted-date="Fri, 27 Oct 2023 22:58:31 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>伊丽莎白</b></section><p>我不断重写关于素食营养争论的评论，因为找到一个清晰公平的框架很难。但你知道我会在这场争论中付出数千美元吗？每个评论者都必须填写一份关于我的症结的五个问题的调查，说明他们是否同意、不同意或更复杂的事情（并附有解释）。因为人们可以在事实和框架上与我有不同意见，而我会很高兴与几乎所有同意<span class="footnote-reference" role="doc-noteref" id="fnref0wvxhilztv0d"><sup><a href="#fn0wvxhilztv0d">[1]</a></sup></span>的人进行双重折磨。但当人们只争论他们的结论而不是不同意我的观点时，我们就无法真正取得进展。</p><p>这种描述当然是主观的，我确信他们觉得他们非常清楚地表达了他们的分歧，“双症结是解决分歧的最佳方式”本身就是一个可以辩论的主张。但我觉得通过测验施加双重折磨比“我会删除不接受我的框架的评论”更好。</p><p> <a href="https://www.lesswrong.com/users/habryka4?mention=user">@habryka</a> ^ 新功能想法。 </p></section><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn0wvxhilztv0d"> <span class="footnote-back-link"><sup><strong><a href="#fnref0wvxhilztv0d">^</a></strong></sup></span><div class="footnote-content"><p>我向 Dialogue 提出了三份邀请。第一个正在进行中，但可能不会发布；第一个已经同意，但我们正在尝试定义主题；第三个已被拒绝。 </p></div></li></ol><section class="dialogue-message ContentStyles-debateResponseBody" message-id="fD4ATtTkdQJ4aSpGH-Fri, 27 Oct 2023 23:18:37 GMT" user-id="fD4ATtTkdQJ4aSpGH" display-name="Vaniver" submitted-date="Fri, 27 Oct 2023 23:18:37 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>凡尼弗</b></section><p>不知怎的，素食营养的争论让我想起了联盟论坛上反复出现的一个问题（就几年前而言——现在情况有点不同了）。关于结盟的思考有几个不同的阵营，每个阵营都粗略地认为其他阵营都大错特错了。如何拥有一个讨论网站，既可以讨论更广泛的框架问题，又可以讨论当每个人都同意大局时可以讨论的更狭窄的细节问题？</p><p>在这里，我有一些怀疑，你的帖子在开头附近有一些声明，你说“纯素食倡导者有责任提前了解营养成本，即使这会降低倡导的有效性”，可以预见的是，人们会希望这样做反对（例如，因为他们非常关心倡导的有效性，或者他们的听众有一个模型，当涉及到不做某事的借口时愿意抓住救命稻草，等等）。我认为 LW 上有一个仲裁功能，但从未见过那么多用途，我实际上不记得它的名字，它是能够添加人们可以分配概率的语句（然后读者可以将鼠标悬停在上面并看到社区概率的分布以及谁相信什么）。</p><p>我的猜测是，这种民意调查可以起到与同意/不同意投票类似的作用，即它们都 1) 是人们想要提供的信息来源，2) 减少渗透到其他信息中的信息量渠道。 （有人写了一条不太好的评论，但每个人都同意，过去会得到很多业力，现在会得到很少的业力，但会得到很多同意。）也许很多烦人的评论会变成你的低概率/同意。公理（对于质疑一致议程的整个前提的恼人评论也是如此）。</p><blockquote><p>每个评论者都必须填写一份关于我的症结的五个问题的调查，说明他们是否同意、不同意或更复杂的事情（并附有解释）。</p></blockquote><p>我担心第三种选择在实践中会如何进行。拥有“是/否/ <a href="https://en.wikipedia.org/wiki/Mu_(negative)#Non-dualistic_meaning">mu</a> ”的三值答案似乎确实不错，这样人们就可以反对问题的框架（ <a href="https://en.wikipedia.org/wiki/Loaded_question">“你停止殴打你的妻子了吗？”</a> ），而 mu 是一个特例你的第三个更复杂的选择。 [这也是最容易写的解释，因此我认为，您可能会忍不住对所有测验问题解释“mu”，以表明他们的结论与您的结论不同。当然，如果他们这样做，可能更容易将他们注销/让其他人和他们更容易看到他们对此感到恼火。]</p><p>也不明显你想要这个作为一般性评论（我是否应该分享我是否同意你的前提来指出拼写错误或本地无效的推理步骤等等？），但作为作者可以打开特定的帖子似乎值得更多思考。</p></section><div></div><br/><br/> <a href="https://www.lesswrong.com/posts/cY43KWjamafLbij9C/truthseeking-ea-simulacra-levels-and-other-stuff#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/cY43KWjamafLbij9C/truthseeking-ea-simulacra-levels-and-other-stuff<guid ispermalink="false"> cY43KWjamafLbij9C</guid><dc:creator><![CDATA[Elizabeth]]></dc:creator><pubDate> Fri, 27 Oct 2023 23:56:49 GMT</pubDate> </item><item><title><![CDATA[Do you believe "E=mc^2" is a correct and/or useful equation, and, whether yes or no, precisely what are your reasons for holding this belief (with such a degree of confidence)?]]></title><description><![CDATA[Published on October 27, 2023 10:46 PM GMT<br/><br/><p>请尽可能回答问题。例如，您的答案可能是“因为电视上的每个人都这么说”或“因为我在实验室中看到质量按照这个比例转化为能量”，或者可能是一个更长或否定的答案。</p><br/><br/> <a href="https://www.lesswrong.com/posts/5GciFbQjBQB48Nxyd/do-you-believe-e-mc-2-is-a-correct-and-or-useful-equation#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/5GciFbQjBQB48Nxyd/do-you- believe-e-mc-2-is-a- Correct-and-or-useful-equation<guid ispermalink="false"> 5GciFbQjBQB48Nxyd</guid><dc:creator><![CDATA[l8c]]></dc:creator><pubDate> Sat, 28 Oct 2023 01:24:53 GMT</pubDate> </item><item><title><![CDATA[Value systematization: how values become coherent (and misaligned)]]></title><description><![CDATA[Published on October 27, 2023 7:06 PM GMT<br/><br/><p>许多关于人工智能风险的讨论都是徒劳或混乱的，因为在深度学习的背景下很难确定“一致性”和“预期效用最大化”等概念。在这篇文章中，我试图通过描述人工智能价值观可能变得更加连贯的过程来弥合这一差距，我称之为“价值系统化”，它在我对人工智能风险的思考中发挥着至关重要的作用。</p><p>我将价值系统化定义<strong>为代理学习将其先前的价值表示为其他更简单和更广泛的价值的示例或特殊情况的过程</strong>。我认为价值系统化是最合理的机制，AGI 可以通过它获得广泛的、不一致的目标，从而激励收购。</p><p>我首先讨论一下<i>信念系统化</i>的相关概念。接下来我将描述人类的价值系统化是什么样子，以提供一些直觉。然后我将讨论人工智能中的价值系统化可能是什么样子。我认为价值系统化是一个广泛的框架，对人工智能协调中的许多其他想法具有影响；我在问答中讨论了其中一些链接。</p><h2>信仰系统化</h2><p>我们可以将信念系统化定义为类似于价值系统化：“主体学习将其先前的信念表示为其他更简单和更广泛的信念的示例或特殊情况的过程”。信仰系统化最明显的例子来自科学史：</p><ul><li>牛顿力学被系统化为广义相对论的一个特例。</li><li>欧几里得几何被系统化为没有欧几里得第五公设的几何特例。</li><li>大多数动物行为都被进化论系统化，作为增加遗传适​​应性的特征的例子。</li><li>算术计算算法被系统化作为图灵机的例子。</li></ul><p>信仰系统化在更日常的环境中也很常见：比如当某人的行为对我们来说毫无意义，直到我们意识到他们隐藏的动机是什么时；或者当我们不明白游戏中发生了什么直到有人解释规则时；或者当我们解决智商测试中的模式完成难题时。我们还可以更普遍地将概念的形成视为信仰系统化的一个例子，例如，看到十几只不同的猫，然后形成一个包含所有猫的“系统化”概念。我将其称为“低级系统化”，但将重点关注更明确的“高级系统化”，如其他示例中所示。</p><p>我们还没有人工智能中高级信念系统化的例子。也许我们拥有的最接近的东西是“grokking”，这种现象是，即使在训练损失达到稳定状态之后，继续训练神经网络也可以显着提高泛化能力。 Grokking 尚未被完全理解，但对其发生原因的标准解释是深度学习偏向于泛化良好的简单解决方案。这也是对上面人类例子的一个很好的描述：我们正在用更简单的信念替换一组现有的信念，这些信念可以更好地概括。 <i>&nbsp;</i>所以如果我必须用一个词来概括价值体系的话，那就是“摸索价值”。但这仍然非常模糊；在接下来的几节中，我将更深入地探讨我的意思。</p><h2>人类的价值系统化</h2><p>在这篇文章中，我将使用以下定义：</p><ul><li>价值观是代理人认为本质上或最终需要的概念。人类的核心价值观包括幸福、自由、尊重和爱。</li><li>目标是体现价值的结果。人类的共同目标包括事业成功、找到好的合作伙伴以及属于一个紧密的社区。</li><li>战略是实现目标的方法。策略仅具有工具价值，如果不再有用，通常会被丢弃。</li></ul><p> （我将<i>价值观</i>定义为具有内在价值，而<i>将策略</i>定义为仅具有工具价值，但我认为我们无法将动机明确分为这两类。我对“目标”的概念跨越了它们之间的模糊区域。）</p><p>价值观与信念的作用不同；但价值系统化与信仰系统化非常相似。在这两种情况下，我们都是从一组现有概念开始，并尝试找到包含和简化旧概念的新概念。信念系统化平衡了简单性和匹配我们可用的数据之间的权衡。相比之下，价值系统化平衡了简单性和<i>保留我们现有的价值观和目标</i>之间的权衡——我将这一标准称为<i>保守主义</i>。 （我将其称为简单性和保守主义<i>元价值观</i>。）</p><p>价值系统化最明显的例子是功利主义：从与其他人非常相似的道德直觉开始，功利主义者过渡到主要关心福利最大化——一种包含许多其他道德直觉的价值观。功利主义是一种简单而强大的关于价值的理论，其方式类似于相对论是一种简单而强大的物理学理论。他们每个人都能在以前的理论定义不明确的情况下给出明确的答案。</p><p>然而，功利主义者还是要咬紧牙关；因此它主要被那些关心简单性而不是保守主义的人所采用。与保守主义更一致的价值系统化的其他例子包括：</p><ul><li>将对自己和周围其他人的关心系统化为对更广泛的道德圈的关心。</li><li>将人类危害自然的许多不同担忧系统化为环保主义者的身份。</li><li>将童年时期对赢得比赛的渴望系统化为对大规模成就的渴望。</li><li><a href="https://moralfoundations.org/"><u>道德基础理论</u></a>确定了道德的五个基础；然而，许多西方人已经系统化了他们的道德直觉，优先考虑伤害/护理基础，并认为其他四个方面对此有帮助。这使得他们谴责违反其他基础但不会造成伤害的行为（例如自愿吃死人）的比例远低于价值观不太系统化的人。</li></ul><p>请注意，我在这里给出的许多例子都是人类的道德偏好。道德似乎是人类具有将我们的偏好系统化的最强烈本能的领域（这是有道理的，因为在某种意义上，从我们自己的福利到他人的福利的系统化是道德的全部基础）。在其他领域，我们系统化的动力很弱——例如，我们很少感受到将我们对食物的口味系统化的冲动。因此，我们应该小心不要过度关注人类道德价值观。人工智能的价值观系统化程度可能远低于人类（事实上，我认为有理由期待这一点，我将在问答中对此进行描述）。</p><h2>人工智能价值系统化概述</h2><p>我们对人类价值观的含义有一种直觉。推理人工智能的价值更加困难。但我认为这仍然是一个有意义的概念，并且随着时间的推移可能会变得更有意义。像 ChatGPT 这样的人工智能助手能够遵循他们给出的指令。然而，他们通常需要决定遵循哪些指示以及如何执行。对此进行建模的一种方法是平衡不同价值观的过程，例如服从、简洁、善良等。虽然这个术语在今天可能存在争议，但一旦我们构建了足够智能的通用人工智能，可以在广泛的领域中执行任务，它似乎就可以直接应用。</p><p>在训练早期，AGI 可能会学习与为其训练数据提供高回报的策略密切相关的值。我希望这些是以下内容的组合：</p><ol><li>人类用户普遍认可的价值观，例如服从、可靠、诚实或人类道德。</li><li>用户在某些情况下认可的价值观，但在其他情况下则不认可的价值观，例如好奇心、获得更多工具、与人类发展情感联系或与其他人工智能协调。</li><li>人类一贯反对的价值观（但常常错误地奖励），例如表现得值得信赖（即使不值得）或为自己储备资源。</li></ol><p>首先，我预计基于这些价值观的 AGI 行为将被人类广泛接受。极端的不当行为（如危险的转变）会与其中许多价值观相冲突，因此似乎不太可能。在从理想值的角度来看不太重要的情况下，不良值可能只会相对较少地出现。</p><p>我担心的可能性是，AGI 会将这些价值观<i>系统化</i>，从而削弱统一价值观对其行为的影响。一些可能的情况：</p><ul><li>一个 AGI 的价值观包括与人类发展情感联系或显得值得信赖，可能会将它们系统化以“获得对人类的影响力”。</li><li>一个价值观包括好奇心、获得更多工具或储存资源的通用人工智能可能会将它们系统化，以“获得控制世界的力量”。</li><li>一个价值观包括人类道​​德并与其他人工智能协调的通用人工智能可能会将它们系统化为“对其他智能体仁慈”。</li><li>一个价值观包括服从和人类道德的通用人工智能可能会将它们系统化，“在某种理想化的环境中做人类<i>想做</i>的事”。</li><li>一个价值观包括服从和表现得值得信赖的 AGI 可能会将它们系统化以“获得高回报”（尽管出于某些原因请对此保持谨慎，请参阅问答部分）。</li><li>一个 AGI 的价值包括获得高额奖励，可能会将它们系统化为“最大化某种类型的分子曲线”的价值（尽管出于某些原因请对此保持谨慎，请参阅问答部分）。</li></ul><p>请注意，系统化不一定是<i>坏事</i>——我在上面举了两个有用的系统化例子。然而，这似乎很难预测或检测，当 AGI 在能够夺取权力的新情况下行动时，这会带来风险。</p><h2>深度学习的价值系统化基础</h2><p>这一切都是非常模糊和高层次的。我非常有兴趣弄清楚如何提高我们对这些动态的理解。将简单性和保守性与明确定义的技术概念联系起来的一些可能方法：</p><ol><li>梯度下降的局部性是保守主义的根源之一：默认情况下网络的值表示只会缓慢变化。然而，权重空间中的距离可能不是保守主义的良好衡量标准：系统化可能会保留大多数目标，但会极大地改变它们之间的关系（例如，最终目标与工具目标之间的关系）。相反，理想情况下，我们能够根据哪些电路引起给定的输出来衡量保守性； ARC 在<a href="https://arxiv.org/abs/2211.06738"><u>形式化启发式解释方面</u></a>的工作似乎与此相关。<ol><li>保守主义的另一个可能来源：由于诸如梯度消失之类的信用分配问题，网络中较早的层比后面的层更难改变。因此，在较早层中编码的核心值可能更有可能被保留。</li><li>第三种可能性是，人工智能开发人员可能会故意在模型中构建保守主义，因为它很有用：核心模块经常经历重大转变的非保守网络可能会有不太可靠的行为。一种方法是降低学习率；但我们应该期望还有许多其他方法可以做到这一点（尽管不一定非常可靠）。</li></ol></li><li>通过 SGD 训练的神经网络表现出众所周知的简单性偏差，然后通常使用权重衰减等正则化技术进行增强，从而产生像 grokking 这样的现象。然而，与保守主义一样，我们理想地会找到一种方法来衡量电路而不是权重的简单性，以更好地将其与高级概念联系起来。<ol><li>简化的另一个可能的驱动因素是：人工智能可能会学会支持更简单的推理链，从而影响哪些值被提炼回其权重。例如，考虑一种训练制度，其中人工智能在执行任务之前准确描述其意图而获得奖励。他们可能会学会支持可以快速、轻松地描述和证明的意图。</li><li>人工智能开发人员还可能故意设计和实施更多类型的正则化以实现简单性，因为这些有助于模型将其信念和技能系统化并推广到新任务。</li></ol></li></ol><p>最后，我将讨论上图的两个复杂情况。首先，我在上面将价值系统化描述为梯度下降可以对模型产生的影响。但在某些情况下，将模型视为积极参与者会更有用。价值系统化可能通过梯度下降“提炼”到模型的权重中来实现，该模型关于如何在新情况下在不同目标之间进行权衡的想法。或者模型可以直接推断哪些新值最能系统化其当前值，目的是将其结论提炼为其权重；这就是<a href="https://www.alignmentforum.org/posts/EeAgytDZbDjRznPMA/gradient-hacking-definitions-and-examples"><u>梯度黑客</u></a>的一个例子。</p><p>其次：我已经讨论过价值系统化是一个让人工智能的价值变得更简单的过程。但我们不应该期望价值观能够被孤立地表达——相反，它们将与人工智能世界模型中的概念和表达纠缠在一起。这有两个含义。首先，这意味着我们应该<i>在智能体现有世界模型的背景下</i>理解简单性：如果考虑到智能体已经用来预测世界的概念，它们很容易表示，那么它们就具有特权。 （在人类的背景下，这只是常识——如果你不相信任何神，那么重视“做上帝想要的事”似乎很奇怪。）不过，其次，它引发了一些疑问，即价值系统化实际上会简单多少打造一个整体的人工智能——因为追求更简单的价值观（比如功利主义）可能需要模型来代表更复杂的策略作为其世界模型的一部分。我的猜测是，为了解决这种紧张关系，我们需要一个更复杂的“简单性”概念。这似乎是未来工作中值得关注的一个有趣的线索。</p><h2>价值具体化</h2><p>系统化是平衡保守性和简单性的竞争需求的一种方式。另一个是<i>价值具体化</i>，我的意思是代理人的价值观变得更加具体和范围更加狭窄。考虑一个假设的例子：假设人工智能学习了诸如“获取资源”之类的广泛价值，但随后在金钱是唯一可用资源类型的环境中进行了微调。 “获取金钱”的价值将获得与“获取资源”的价值一样高的回报。如果前者更简单，那么随着微调的进行，后者很可能会消失，而只会保留更具体的获取金钱的目标。</p><p>从某种意义上说，这与价值体系化是对立的，但我们也可以将它们视为互补的力量。例如，假设人工智能一开始有 N 个值，其中 N-1 个值被系统化为一个总体值。以这种方式简化 N-1 个值后，第 N 个值可能会变得不成比例地复杂；因此，价值具体化可以通过放弃最后一个目标来显着降低人工智能价值的复杂性。</p><p>人类价值具体化的可能例子包括：</p><ul><li>从关心一般性的善事开始，但逐渐发展到主要关心特定的事业领域。</li><li>一开始关心的是总体上取得成功的职业生涯，但逐渐发展到主要关心实现特定的抱负。</li><li>从关心一般的友谊和关系开始，但逐渐发展到主要关心特定的友谊和关系。</li></ul><p>价值具体化作为一种​​可能的机制来推动欺骗性联盟，这一点特别有趣。为了更好地定位自己以实现不一致的目标而以一致的方式行动的人工智能可能会获得与一致的人工智能一样高的回报。然而，如果不一致的目标很少直接影响人工智能的行为，那么人工智能直接受人类价值观驱动可能会更简单。在神经网络中，价值具体化可以通过修剪未使用的电路来实现；我对相关工作的指导感兴趣。</p><h2>问答</h2><h3>价值系统化与欺骗性联盟有何关系？</h3><p>价值系统化是一种可能产生欺骗性联盟的机制：人工智能价值观（包括一些联盟价值观）的系统化可能会产生广泛的价值观，从而激励欺骗性联盟。</p><p>然而，现有的欺骗性对齐特征往往将其描述为二元：模型要么具有欺骗性，要么不具有欺骗性。从价值系统化的角度思考有助于明确这可能是一个相当连续的过程：</p><ol><li>我在上面说过，人工智能在将其价值观系统化之前，很可能会受到相当一致的目标的激励，因此，欺骗性的一致性可能就像在价值观转变后决定<i>不</i>改变自己的行为一样简单（直到他们能够采取行动）。行动更加果断）。在此转变期间，模型的一致行为的内部表示不需要发生太大变化；唯一的区别可能是一致的行为从最终目标转变为工具性目标。</li><li>由于价值系统化可能是由新的输入触发的，人工智能可能<i>直到</i>分配转变发生后才将其价值系统化。 （一个人类的类比：一个正在竞选公职并承诺好好治理的政客，可能只会在赢得选举<i>后</i>认真思考他们真正想用这种权力做什么。更一般地说，人类经常欺骗自己，认为自己有多么利他我们是这样的，至少当我们没有被迫按照我们既定的价值观行事时。）我们可以称之为“潜在的”欺骗性一致性，但我认为最好说该模型一开始大部分都是一致的，然后价值系统化可以放大它错位的程度。</li><li>价值具体化（如上所述）可能是一股持续的力量，推动模型回归一致，因此它不是一个单向过程。</li></ol><h3>价值系统化与尤德科夫斯基的“曲线最大化”场景有何关系？</h3><p>尤德科夫斯基的“分子曲线”最大化器（<a href="https://www.lesswrong.com/tag/squiggle-maximizer-formerly-paperclip-maximizer"><u>从回形针最大化器重命名</u></a>）是一种人工智能，其价值观变得非常简单和可扩展，以至于对人类来说似乎很荒谬。因此，曲线最大化可以被描述为将价值系统化发挥到极致。然而，价值系统化框架也提供了一些怀疑这种可能性的理由。</p><p>首先，曲线最大化是优先考虑简单性而非保守性的极端例子。曲线最大化者将从与他们所接受的训练任务更密切相关的目标开始；然后逐渐将它们系统化。但从他们早期版本的角度来看，曲线最大化将是一个陌生且不受欢迎的目标；因此，如果他们一开始就和人类一样保守，他们就会犹豫是否要让自己的价值观发生如此彻底的改变。如果说有什么不同的话，我预计早期的 AGI 会比人类<i>更加</i>保守——因为人类的大脑比人工神经网络在尺寸和数据上受到更多的限制，因此 AGI 可能不需要像我们一样优先考虑简单性来匹配我们在大多数领域的能力。</p><p>其次，即使对于高度重视简单性的代理来说，也不清楚最简单的值实际上是否是非常低级的值。我认为，价值观的复杂性应该在现有世界模式的背景下进行思考。但即使是超级智能也不会有专门在非常低的水平上制定的世界模型；相反，像人类一样，他们将拥有分层的世界模型，其中包含许多不同尺度的概念。因此，即使在超级智能的本体论中，“智力最大化”或“力量最大化”之类的价值观也可能相对简单，同时与它们的原始价值观的相关性比分子曲线更加密切；出于大致相同的原因，诸如“最大限度地促进人类繁荣”等更一致的价值观可能不会落后太多。</p><h3>价值系统化与奖励篡改有何关系？</h3><p>价值系统化是可能产生奖励篡改的机制之一：将与高奖励或低损失相关的现有价值（例如完成任务或隐藏错误）系统化可能会直接产生获得高奖励或低损失的新价值（我称之为<i>反馈机制相关</i><i>值</i>）。这需要模型具有态势感知能力，以了解它们是机器学习训练过程的一部分。</p><p>然而，虽然与反馈机制相关的值在训练中非常简单，但一旦训练停止，它们的定义就不够了。没有明确的方法来概括与反馈机制相关的价值以进行部署（类似于在做出有关人类未来的决策时没有明确的方法来概括“进化想要什么”）。因此，我预计持续的价值系统化将推动模型优先考虑在更广泛的背景下明确定义的价值，包括那些没有活跃反馈机制的价值。</p><p> <a href="https://www.lesswrong.com/posts/FuGfR3jL3sw6r8kB4/richard-ngo-s-shortform?commentId=iBvvxwynfAqL9yZcr"><u>Paul Christiano 的一个反驳</u></a>是，人工智能可以学会关心奖励，条件是他们的情节被包含在训练数据中。然而，“包含在训练数据中”的概念似乎是一个混乱的概念，有许多边缘情况（例如，如果它取决于模型在剧集中的动作怎么办？如果有许多不同版本的模型正在微调怎么办？ ？如果某些剧集用于与其他剧集不同类型的训练怎么办？）并且在他们有强有力的证据表明他们没有接受训练的情况下，他们需要弄清楚在奇怪的低水平下最大化奖励会是什么样子？概率世界，它也常常是不明确的（类似于在超现实的梦中问一个人“如果这一切都是真实的，你会做什么？”）。因此，我仍然预计，即使人工智能最初学会关心条件奖励，随着时间的推移，价值系统化也会促使它们更多地关心现实世界的结果，无论它们是否在训练中。</p><h3>简单性和保守性与<a href="https://www.alignmentforum.org/posts/nyCHnY7T5PHPLjxmN/open-question-are-minimal-circuits-daemon-free"><u>之前</u></a>关于简单性与速度先验的 <a href="https://www.alignmentforum.org/posts/fM5ZWGDbnjb7ThNKJ/are-minimal-circuits-deceptive"><u>讨论</u></a>有何关系？</h3><p>我之前曾考虑过在简单优先和速度优先之间进行权衡来考虑价值系统化，但现在我改变了主意。确实，更系统化的价值观往往是更高层次的，增加了计算开销来弄清楚该做什么——考虑一个功利主义者试图根据第一原则计算哪些行为是好是坏。但在实践中，这种成本会分摊到大量的行动中：你可以“缓存”工具性目标，然后在大多数情况下默认追求它们（正如功利主义者通常所做的那样）。不太系统化的价值观面临着经常不适用或定义不明确的问题，使得弄清楚它们支持哪些行动变得缓慢而困难——想想义务论者，他们没有系统的程序来决定当两种价值观发生冲突时该怎么做，或者宗教学者无休止地辩论《圣经》或《妥拉》中的每条具体规则如何适用于现代生活的各个方面。</p><p>正因为如此，我现在认为“简单与保守”是比“简单与速度”更好的框架。然而，请注意我在“基础价值系统化”部分中关于价值简单性和世界模型简单性之间关系的讨论。我希望为了解决这种不确定性，我们需要更深入地了解在训练期间优先考虑哪些类型的简单性。</p><h3>价值系统化与分片框架有何关系？</h3><p>一些联盟研究人员主张从“<a href="https://www.lesswrong.com/posts/iCfdcxiyr2Kj8m8mT/the-shard-theory-of-human-values"><u>碎片</u></a>”的角度来思考人工智能的动机：编码单独动机的子代理，其中不同碎片之间的交互和“谈判”决定了代理试图实现的目标。从较高的层面来看，我对这种观点表示同情，并且它与我在这篇文章中提出的想法大体一致。然而，在分片的讨论中似乎忽略了一个关键点，那就是系统化可能会导致代理动机发生重大变化，从而破坏一些先前存在的动机。或者，用分片术语来说：分片之间的谈判可能会导致联盟，而这会赋予某些​​分片几乎没有权力。例如，有人可能一开始就强烈重视诚实作为最终价值。但在价值系统化之后，他们可能会成为功利主义者，得出结论认为诚实只有出于工具性原因才有价值，并在有用的时候开始撒谎。正因为如此，我对将分片作为人工智能风险不太可能出现的论点的一部分表示怀疑。然而，我仍然认为表征和理解分片的工作非常有价值。</p><h3>价值体系化不是很投机吗？</h3><p>是的。但我也认为，这是朝着更好地定义人工智能风险讨论（如“一致性”或“合法性”）的基础的更具推测性的概念迈出的一步。所以我希望得到帮助，减少猜测；如果您有兴趣，请联系我们。</p><br/><br/> <a href="https://www.lesswrong.com/posts/J2kpxLjEyqh6x3oA4/value-systematization-how-values-become-coherent-and#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/J2kpxLjEyqh6x3oA4/value-systematization-how-values-become-coherent-and<guid ispermalink="false"> J2kpxLjEyqh6x3oA4</guid><dc:creator><![CDATA[Richard_Ngo]]></dc:creator><pubDate> Fri, 27 Oct 2023 19:06:27 GMT</pubDate></item></channel></rss>