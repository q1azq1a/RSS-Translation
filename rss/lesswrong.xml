<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 8 月 24 日星期四 14:10:25 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[AI Regulation May Be More Important Than AI Alignment For Existential Safety]]></title><description><![CDATA[Published on August 24, 2023 11:41 AM GMT<br/><br/><p><i><strong>简介</strong>： 调整一个强大的人工智能是不够的：只有没有人能够构建一个未调整的强大人工智能，我们才是安全的。 Yudkowsky 试图通过关键行动来解决这个问题：第一个对齐的人工智能会做一些事情（例如熔化所有 GPU），以确保任何人都无法构建未对齐的人工智能。然而，这些实验室目前显然不打算实施一项关键行动。这意味着调整通用人工智能虽然创造了大量价值，但不会降低存在风险。相反，全球硬件/数据监管才是降低生存风险所需要的。因此，那些旨在降低人工智能存在风险的人应该关注人工智能监管，而不是人工智能联盟。</i></p><p><i><strong>认知状态</strong>：我多年来一直在思考这个问题，同时专业致力于降低 x 风险。我想我了解有关该主题的大多数文献。我还与相当多的专家讨论了这个话题（他们在某些情况下似乎同意，而在其他情况下似乎不同意）。</i></p><p><i><strong>感谢</strong>David Krueger、Matthijs Maas、Roman Yampolskiy、Tim Bakker、Ruben Dieleman 和 Alex van der Meer 提供的有益对话、评论和/或反馈。这些人不一定同意这篇文章中表达的观点。</i></p><p><i>这篇文章主要是关于接管造成的人工智能 x 风险。</i>它对于<a href="https://arxiv.org/abs/2306.12001"><i><u>其他类型的人工智能 x 风险</u></i></a><i>可能有效，也可能无效</i><i>。这篇文章主要是关于人工智能存在风险的“最终游戏”，而不是中间状态。</i></p><p>人工智能的存在风险是一个进化问题。正如埃利泽·尤德科斯基（Eliezer Yudkowsky）等人指出的那样：即使存在安全的人工智能，这些也无关紧要，因为它们不会阻止其他人构建危险的人工智能。安全人工智能的例子可以是预言机或满足者， <a href="https://www.lesswrong.com/posts/2qCxguXuZERZNKcNi/satisficers-want-to-become-maximisers"><u>只要</u></a>事实<a href="https://www.lesswrong.com/posts/wKnwcjJGriTS9QxxL/dreams-of-friendliness"><u>证明</u></a>可以将这些人工智能类型与高智能结合起来。但是，正如尤德科斯基<a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities"><u>所说</u></a>：“如果您需要的只是一个不会做危险事情的物体，那么您可以尝试海绵”。即使有限的人工智能是安全的人工智能，它也不会降低人工智能的存在风险。这是因为在某些时候，有人会创建一个具有无限目标的人工智能（创建尽可能多的回形针，以无限的准确性预测句子中的下一个单词等）。这是会杀死我们的人工智能，而不是安全的人工智能。</p><p>这是人工智能存在风险问题的进化本质。安东尼·伯格拉斯（Anthony Berglas）在他被低估的<a href="https://www.amazon.com/When-Computers-Can-Think-Intelligence/dp/1502384183"><u>书中</u></a>以及最近本·亨德里克斯（Ben Hendrycks）的<a href="https://arxiv.org/abs/2303.16200"><u>论文</u></a>中对此进行了精彩的描述。这个进化部分是人工智能存在风险的一个基本且非常重要的属性，也是这个问题之所以困难的很大一部分原因。然而，人工智能协调和行业中的许多人似乎只专注于协调单个人工智能，我认为这是不够的。</p><p>尤德科斯基旨在通过所谓的关键行动来解决这一进化问题（事实上，任何人都不应构建不安全的人工智能）。一个一致的超级智能不仅不会杀死人类，而且还会执行一项关键行动，举个玩具例子，就是<a href="https://forum.effectivealtruism.org/posts/iGYTt3qvJFGppxJbk/ngo-and-yudkowsky-on-alignment-difficulty"><u>融化全球所有 GPU</u></a> ，或者正如他后来所说，巧妙地改变全球所有 GPU，使它们不再被使用创建一个 AGI。通过确保任何人永远不会创造出不安全的超级智能，这将是真正拯救人类免于灭绝的行为（可能有人会说，需要熔化所有 GPU 以及所有其他可以运行人工智能的未来硬件）由一致的超级智能无限期地完成，否则即使是关键行为也可能是不够的）。</p><p>然而，关键行动的概念似乎已经彻底<a href="https://www.alignmentforum.org/posts/Jo89KvfAs9z7owoZp/pivotal-act-intentions-negative-consequences-and-fallacious"><u>过时了</u></a>。领先的实验室、人工智能治理智囊团、政府等都没有谈论或显然思考过这个问题。相反，他们似乎正在<a href="https://openai.com/blog/governance-of-superintelligence"><u>考虑</u></a>防扩散和多种监管等问题，以确保强大的人工智能不会落入坏人之手。这可能意味着任何人都可以在没有安全措施的情况下有意或无意地运行它。我将这样的解决方案（特别是任何能够限制任何参与者在任何时间段内访问高级人工智能的解决方案）称为“人工智能监管”。</p><p>这个解决方案似乎已经成为主流，具有重要的影响：</p><ul><li>即使我们能够解决一致性问题，我们仍然需要人工智能监管，因为否则大量的不安全行为者就有可能在没有适当安全性的情况下运行超级智能，从而冒着被接管的风险。</li><li>无论如何，如果我们有人工智能监管，我们也可以用它来拒绝<i>所有人</i>（包括领先的实验室）而不是几乎所有人访问先进的人工智能。这相当于人工智能暂停。</li><li>如果我们能够拒绝每个人使用先进的人工智能，并且我们能够继续这样做，我们就已经解决了人工智能的存在风险，而且还没有解决人工智能的对齐问题。</li><li>在不执行关键行动的情况下成功调整超级智能几乎不会改变需要制定的法规，因为除了少数被认为安全的实验室之外的所有其他实验室仍然需要这些法规。</li></ul><p>因此，如果没有关键的行动，保证我们安全的就是监管。人们可能仍然希望调整超级智能来使用其力量，但不是为了防止存在风险。使用超级智能的力量当然可能是追求联盟的一个正当理由：它可以使我们的经济飞速发展，创造富足，治愈疾病，增强政治权力等。尽管这些巨大且极其复杂的转变的净积极性可能很难证明事先，这些当然可能是进行协调工作的正当理由。然而，在这种情况下，我们这些对预防存在风险而不是构建人工智能感兴趣的人应该关注监管，而不是协调。后者也可能留给业界，以及证明由此产生的一致人工智能确实安全的责任。</p><p>除了人工智能监管的这种场景之外，还有一种选择可以解决人工智能存在风险的完整进化问题。有些人认为，一致的超级智能可以成功地、无限期地保护我们免受不一致的超级智能的侵害。我将这种选择称为积极的进攻/防御平衡，它将是继联盟+关键行动和持久监管之后的第三种方式，以防止人类在较长时期内灭绝。然而，大多数人<a href="https://www.alignmentforum.org/posts/LFNXiQuGrar3duBzJ/what-does-it-take-to-defend-the-world-against-out-of-control"><u>似乎并不认为</u></a>这是现实的（有明显的<a href="https://www.alignmentforum.org/posts/nRAMpjnb6Z4Qv3imF/the-strategy-stealing-assumption"><u>例外</u></a>）。</p><p>这三种解决人工智能生存风险演化本质的方式（人工智能联盟+关键行为、人工智能监管、防御>;进攻）可能并不是人工智能生存风险演化问题的完整解决方案，而且三者之间存在交叉点。关键行为可能被视为赢得进攻/防守平衡的一种（非常严格且非法的）类型。国家行为者实施的关键行为可能被视为实施人工智能监管的极端（而且同样是非法的）方式。人工智能（硬件）监管的类型可能是可能的，其中实施监管的国家行为者得到一致的人工智能的帮助，使其实施有点类似于关键行为（在这种情况下可能是合法的）。某些类型的监管也许可以使我们更有可能赢得进攻/防守平衡。</p><p>我认为应该开展研究，旨在为人工智能存在风险的进化问题提供一套完整的解决方案。我预计此类研究会提出比这三个更多的选择，和/或在这三个之间提出更多的混合选项，这可能会指出降低人工智能存在风险的新的、富有成效的方法。</p><p>只要我们假设人工智能存在风险的进化本质只存在三种解决方案，那么重要的是要认识到这三种解决方案似乎都很困难。此外，很难量化每个选项的可能性。因此，对这三者中的任何一个下注都是值得的。</p><p>然而，我个人的赌注是，不幸的是，进攻将胜过防守，并且在具有接管能力的超级智能被开发出来之前解决结盟的可能性，<i>并且</i>这种结盟的超级智能将执行成功的关键行动，比我们解决问题的机会要小。将能够成功协调并实施足够好的硬件或数据监管，特别是如果当前公众对人工智能存在风险的认识不断增强的<a href="https://www.lesswrong.com/posts/3vZWhCYBFn8wS4Tfw/crosspost-ai-x-risk-in-the-news-how-effective-are-recent"><u>趋势</u></a>持续下去的话。这意味着，致力于在全球范围内无限期地限制所有参与者使用先进人工智能的监管类型，只要有必要，就应该是最高的存在优先事项，比协调一致更重要。</p><br/><br/> <a href="https://www.lesswrong.com/posts/2cxNvPtMrjwaJrtoR/ai-regulation-may-be-more-important-than-ai-alignment-for#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/2cxNvPtMrjwaJrtoR/ai-regulation-may-be-more-important-than-ai-alignment-for<guid ispermalink="false"> 2cxNvPt先生瓦杰尔托</guid><dc:creator><![CDATA[otto.barten]]></dc:creator><pubDate>Thu, 24 Aug 2023 11:41:56 GMT</pubDate> </item><item><title><![CDATA[Simple AI Forecasting - Katja Grace]]></title><description><![CDATA[Published on August 24, 2023 9:45 AM GMT<br/><br/><p><i>我正在采访人工智能专家，了解他们对人工智能将会发生什么的看法。这是 Katja Grace 和她的想法。人工智能风险让我感到害怕，但我常常感到与它脱节。这帮助我思考这个问题。</i></p><p>以下是 Katja 的简要想法：</p><ul><li>到 2040 年，我们能否获得人工智能工具来管理一个人数减少 100 倍的公务员部门？ 50%</li><li>在世界的哪一部分中，大多数人工智能工具是由代理人工智能控制的？ 70%</li><li>代理人工智能将在哪些领域实现其目标？ 90%</li><li>在代理世界的哪一部分中，大多数人工智能控制的资源会被用于不良目标？ 50%</li><li>政策会让 AGI 放缓 10 年吗？ 25%，10年可以让我们减少多少坏事？ 30%</li></ul><p>您可以在此处查看交互式图表：https: <a href="https://estimaker.app/_/nathanpmyoung/ai-katja-grace"><u>//estimaker.app/_/nathanpmyoung/ai-katja-grace</u></a>或查看我迄今为止所做的所有图表<a href="https://estimaker.app/ai"><u>https://estimaker.app/ai</u></a> 。本页底部有一张图片。</p><p>您可以在这里观看完整视频： </p><figure class="media"><div data-oembed-url="https://www.youtube.com/watch?v=Zum2QTaByeo"><div><iframe src="https://www.youtube.com/embed/Zum2QTaByeo" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div></figure><h1>更长的解释</h1><p><i>请记住，这是到 2040 年。</i> </p><figure class="table"><table><thead><tr><th style="border:1pt solid #000000;padding:5pt;vertical-align:top">问题</th><th style="border:1pt solid #000000;padding:5pt;vertical-align:top">信心</th><th style="border:1pt solid #000000;padding:5pt;vertical-align:top">卡佳的评论</th><th style="border:1pt solid #000000;padding:5pt;vertical-align:top">我的评论</th></tr></thead><tbody><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>到 2040 年，我们能否获得人工智能工具来管理一个人数减少 100 倍的公务员部门？</p><p><br></p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"> 50%</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"> Katja 说她不确定，因此给出了 50% 的分数。</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>在我关于 AGI 的讨论中，一个常见的失败模式是“AGI”的功能非常模糊。有些人正在设想能够完美地运行全球阴谋的工具，而另一些人似乎想到了人类顶级的编码能力。<br></p><p> Katja 和我选择了这个例子，因为它涉及一系列大规模的任务，并取代了大量的人力。<br></p><p>任务包括：</p><ul><li>大型工程项目</li><li>现金转移</li><li>现实世界的分歧（如何设定税率等）</li><li>复杂的系统问题（交通流量、医疗保健占用）<br></li></ul><p>公务员服务范围涉及数百万人。</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>在这些世界的哪一部分中，代理控制了大部分资源（即使通过人工智能工具）</p><p><br></p><p><i>如果把代理人工智能控制的资源和它们控制的人工智能工具加起来，是不是超过一半了？</i></p><p><br><br></p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"> 70%</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>卡佳的直觉是，要实现灭绝，代理可能是必要的。<br></p><p> “我认为其中一些可能具有代理性的原因是，代理或类似代理的东西似乎具有经济价值。人们想要制作像代理这样的东西。他们已经在尝试做代理之类的东西了。”<br></p><p><i>然后</i></p><p></p><p>Katja：“问题在于它们的代理程度如何，而且这似乎更像是一个谱系，而不是能够清楚地说出这是代理还是非代理”<br></p><p> ……<br></p><p> Katja “我不知道，大约在 60% 到 90% 之间。 ……我认为我能想象的世界是，肯定有一些令人印象深刻的代理人工智能系统。但就像，他们并不是真正正在发生的人工智能思维的主体。就像一堆更像是人类正在使用的工具……我觉得问题是谁在运用大部分人工智能认知劳动。是人类或人工智能有好的目标还是人工智能有坏的目标？ “</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>有人有更好的框架吗？我认为 Katja 的声音是我听过的最好的，但相当模糊。<br></p><p>考虑一下美国政府高层如何不仅治理美国，而且治理与美国结盟的国家，并影响全世界的规范。类似地，人工智能代理不仅可以控制某些资源和人工智能工具，还可以控制这些工具控制的内容。问题是〜这是大多数吗？他们是否垄断了电力市场？<br></p><p>我希望更好地解决这个问题。</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>代理人工智能将在这些世界的哪一部分实现其目标？</p><p><br><br></p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"> 90%</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p> “事情发生得非常快的可能性大约为 0.1% 到 10%。如果这种情况没有发生，从长远来看，如果周围有比我们聪明得多的人工智能代理，他们就有 80% 的可能会夺取所有权力。”</p><p></p><p>值得注意的是，Katja 有一个模型，其中代理人工智能无需接管即可实现其目标 - 他们更有能力，我们慢慢地将权力交给他们。<br></p><p> “我猜[在另一种]情况下[人工智能接管]发生得非常缓慢。我想也许我对这到底有多慢有点不可知。它更像是我指出的那种机制，它可以非常快，但是……没有人喜欢侵犯任何人的财产权。只是，他们非常有能力，并且会因为他们所做的事情而获得报酬，或者……所有的决定都是由人工智能做出的，因为人工智能在做决定方面更有能力。”</p><p></p><p>但这可能不太好。 “我认为在某些情况下，即使是互动的人也可能对此不满意，但竞争迫使你这样做。就像，如果每个人都可以使用某种人工智能系统来管理他们公司的营销，那么我想说，每个人都知道它在这方面会有点狡猾并做一些坏事。他们宁愿不使用它……但如果你不使用它，那么你的公司将无法竞争。所以你必须使用它。”</p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>故事的这一部分似乎与最悲惨的模型非常相似——如果你有控制大部分资源的代理人工智能并且没有好的政策（我们稍后会谈到），他们可能会实现他们的目标。那时你只能希望他们的目标是好的。<br></p><p>我很好奇是否有比 Katja 持更悲观态度的人不同意这一点。</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>在代理世界的哪一部分中，大多数人工智能控制的资源会被用于不良目标？</p><p><br><br></p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"> 50%</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p> Katja 最初选择 25%，但认为这会使总体产出太低，因此改为 50%。</p><p></p><p>在 EAG SF 的演讲中，您可以看到她<a href="https://youtu.be/j5Lu01pEDWA?t=1206"><u>解释了这些数字背后的一些原因</u></a>。她对其他思想家的理解是，他们认为所有可能价值的空间都非常大，因此我们很可能会错过创建 AGI 时所追求的价值。<br></p><p>似乎有几个很好的理由让我们有不同的直觉</p><ul><li>Katja 的直觉是，当前的人工智能非常擅长在广泛的搜索空间中寻找类似人类的事物。例如生成人脸或文本</li><li>人类也很擅长在所有汽车的空间中找到汽车。以同样的方式，他们也许能够在大型搜索空间中重复创建具有类人目标的人工智能</li><li>经济激励将导致人们发现有用且有价值的东西。我们想让人工智能做我们想做的事情</li></ul></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>人们对这个问题有不同的直觉。有些人认为人类的偏好很容易实现，无论是通过个体模型还是自然平衡。其他人则认为，在所有可能的目标空间中，这是一个非常小的目标，我们不太可能实现它，但人工智能只会制定非常陌生和有害的偏好。</p><p></p><p>我认为这通常是正交性命题所指出的。</p></td></tr><tr><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"><p>政策会让 AGI 放缓 10 年吗？ 10年可以让我们减少多少坏事？</p><p><br><br><br></p></td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"> 25%, 30%</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top"> “我只是认为政策在过去已经让事情放慢了很多。就像，我认为你可以看看其他已经放慢了很多的技术……我认为，相对于你可以从中获得的经济价值，人类的各种基因工程、各种人类生殖事物的发生速度相当缓慢……似乎有道理的是，我们本来可以投入大量资金并找出更多种类的遗传或克隆类型的东西。我们已经决定，作为一个世界，我们不……[而且]全世界都是如此。中国在这方面的速度并不比美国或类似国家快得多。我认为一般医学也是一个很好的例子，你会忘记……事情发生得多么缓慢，即使它们看起来对人们来说可能非常有价值。”</td><td style="border:1pt solid #000000;padding:5pt;vertical-align:top">很多人认为政策与减缓/改善人工智能风险非常相关。这是尝试建立一个图表的一部分，让每个人都可以输入自己的真实价值观并获得适合他们的结果。</td></tr></tbody></table></figure><h1>到 2040 年，情况会如何</h1><p>以下是这些数字如何在可能的世界中兑现。这些是互斥且全面详尽的 (MECE)</p><h2> AI 很好，但还不够神（50%）</h2><p>人工智能工具很棒。也许他们可以编写很多代码或提供很多支持。但他们无法将管理公务员部门所需的人力减少 100 倍。由于某种原因，他们无法单独承担大型项目。它就像 GPT4，但要好得多，但不是一步改变。</p><h2> ChatGPT20 - 有能力但没有代理 (15%)</h2><p>想象一个 ChatGPT，它可以生成您要求的任何内容，但只执行一些任务或无法递归调用自身。与上述不同，这确实是一个阶跃变化。你或我可以经营一家对冲基金或政府的一部分。但这将涉及我们实现愿景。</p><h2>许多神一样的智能人工智能系统互相阻碍（4%）</h2><p>与当今世界一样，许多智能系统（人和公司）都在试图实现其结果并相互阻碍。不知怎的，这并没有导致下面的“中/乌托邦”。</p><h2> AI 中托邦/乌托邦 (16%)</h2><p>这些都是非常好的场景，我们拥有不想要坏事的代理 AGI。可能的世界有很多种，从某种人类的提升，到一种一切如常的美好事物，我们可能仍然有很多抱怨，但每个人都像今天最富有的人一样生活。</p><h2>政策节省 (12%)</h2><p>在很多世界里，事情本来会变得非常糟糕，但政策却推迟了事情的发生。这些可能是任何其他非末日世界——也许人工智能已经放慢了很多，或者也许它有更好的目标。为了简化图表，它并没有真正涉及这些世界的样子。请提出建议</p><h2>厄运 (15%)</h2><p>毫无疑问是不好的结果。代理 AGI 想要我们认为不好的东西并得到它。我的感觉是，Katja 认为最糟糕的结果来自于 AGI 的接管，也许 10% 的结果发生得很快，90% 的结果发生得很慢。</p><p>如果您想了解更多相关信息，Katja 在这里提供了更长的解释： <a href="https://wiki.aiimpacts.org/doku.php?id=arguments_for_ai_risk:is_ai_an_existential_threat_to_humanity:start"><u>https://wiki.aiimpacts.org/doku.php</u></a> ?id=arguments_for_ai_risk:is_ai_an_existential_threat_to_ humanity:start</p><h1>视觉交互模型</h1><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/mZ46CJQvgiTgaNwDm/lau63ldknsuhqvo3f1ny"></p><p> <a href="https://estimaker.app/_/nathanpmyoung/ai-katja-grace"><u>https://estimaker.app/_/nathanpmyoung/ai-katja-grace</u></a></p><h1>您希望为谁完成此操作？</h1><p>我想看到这样的工作，所以我想我会这么做。如果你想查看某个特定人的人工智能风险模型，也许可以请他们与我交谈。他们大约需要 90 分钟的时间，目前我认为后续每一个的边际收益都相当高。</p><p>在更广泛的层面上，我对积极的反馈感到非常鼓舞。我应该尝试获得资金来进行更多这样的采访吗？</p><h1>这怎么能更好呢？</h1><p>我们仍处于早期阶段，所以我很欣赏很多挑剔的反馈</p><h1>谢谢</h1><p>感谢 Katja Grace 的采访和 Rebecca Hawkins 的反馈，特别是对表格布局的建议，并感谢 Arden Koehler 的好评（您应该阅读她<a href="https://twitter.com/ardenlkoehler/status/1678018343708794882?s=20">关于撰写好评的帖子</a>）。感谢建议我写这个序列的人</p><br/><br/><a href="https://www.lesswrong.com/posts/mZ46CJQvgiTgaNwDm/simple-ai-forecasting-katja-grace#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/mZ46CJQvgiTgaNwDm/simple-ai-forecasting-katja-grace<guid ispermalink="false"> mZ46CJQvgiTgaNwDm</guid><dc:creator><![CDATA[Nathan Young]]></dc:creator><pubDate> Thu, 24 Aug 2023 09:45:48 GMT</pubDate> </item><item><title><![CDATA[What wiki-editing features would make you use the LessWrong wiki more?]]></title><description><![CDATA[Published on August 24, 2023 9:22 AM GMT<br/><br/><p> LessWrong wiki 似乎并没有得到应有的使用。我想这是缺乏编辑的原因。</p><p> <a href="https://www.lesswrong.com/users/vladimir_nesov?mention=user">@Vladimir_Nesov</a>提出了一个很好的观点，即许多标准的维基编辑功能都缺失，这使得前景没有吸引力。</p><blockquote><p>关键是，缺少该功能会使与 wiki 的互动变得不那么有希望，因为它变得不方便，因此在实践中无法对其进行详细保护，因此不太有吸引力在其中投入精力。我提到这是作为解释目前几乎不存在的编辑参与度的假设</p></blockquote><p>那么，本着这一精神，哪些功能会让您个人进行比目前更多的编辑呢？</p><p>如果可行的话，我可能会尝试付钱给一些开发人员来编写拉取请求。</p><br/><br/> <a href="https://www.lesswrong.com/posts/xzm6F6rLt7oPTash2/what-wiki-editing-features-would-make-you-use-the-lesswrong#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/xzm6F6rLt7oPTash2/what-wiki-editing-features-would-make-you-use-the-lesswrong<guid ispermalink="false"> xzm6F6rLt7oPTash2</guid><dc:creator><![CDATA[Nathan Young]]></dc:creator><pubDate> Thu, 24 Aug 2023 09:22:01 GMT</pubDate></item><item><title><![CDATA[The God of Humanity, and the God of the Robot Utilitarians]]></title><description><![CDATA[Published on August 24, 2023 8:27 AM GMT<br/><br/><p>我个人的宗教涉及两个*神——人类之神（我有时称之为“Humo”）和机器人功利主义者之神（我有时称之为“Robutil”）。</p><p>当我面临道德危机时，我会向我的<a href="https://www.lesswrong.com/posts/X79Rc5cA5mSWBexnd/shoulder-advisors-101">肩膀</a>-Humo 和我的肩膀-Robutil 询问他们的想法。有时他们会说同样的话，但并没有真正的危机。例如，一些天真的年轻 EA 试图成为实用僧人，捐出所有的钱，从不休息，只做生产性的事情……但 Robutil 和 Humo 都同意，高质量的知识世界需要懈怠和心理健康。 （既是为了<a href="https://www.lesswrong.com/posts/WuyNHrDXcGFgkZpBy/my-slack-budget-3-surprise-problems-per-week">处理危机</a>，也是为了<a href="https://www.lesswrong.com/posts/fwSDKTZvraSdmwFsj/slack-gives-you-space-to-notice-reflect-on-subtle-things">注意到微妙的事情</a>，即使在<a href="https://www.lesswrong.com/posts/mmHctwkKjpvaQdC3c/what-should-you-change-in-response-to-an-emergency-and-ai">紧急情况</a>下，你也可能需要这些）</p><p>如果你是一个有抱负的有效利他主义者，你绝对应该<i>至少</i>做 Humo 和 Robutil 同意的所有事情。 （即<a href="https://forum.effectivealtruism.org/posts/AjxqsDmhGiW9g8ju6/effective-altruism-in-the-garden-of-ends">在这里了解泰勒·奥尔特曼故事</a>的中心点）。</p><p>但 Humo 和 Robutil 实际上在一些事情上存在分歧，而且在侧重点上也存在分歧。</p><p>对于你应该花多少努力来避免<a href="https://forum.effectivealtruism.org/posts/2BEecjksNZNHQmdyM/don-t-be-bycatch">意外招募到对你没有多大用处的人，</a>他们意见不一。</p><p>他们对于有多少高中生在你尝试一项新项目让他们进入时心理上意外搞砸是可以接受的问题存在分歧。</p><p>他们对于如何努力推动自己变得更好/更强/更聪明/更快，以及为此你应该牺牲多少存在分歧。</p><p> Humo 和 Robutil 都很难以不同的方式理解事物。 Robutil 最终承认你需要 Slack，但他最初并没有想到这一点。他的理解诞生于成千上万年轻理想主义者的倦怠和狭隘视野中，而胡莫最终（耐心地、友善地）说：“我<i>告诉过</i>你了。” （Robutil 回应“但你没有提供任何关于如何最大化效用的论据！”。Humo 回应“但我说这显然不健康！”Robutil 说“wtf &#39;不健康&#39;到底是什么意思？<a href="https://www.lesswrong.com/posts/WBdvyyHLdxZSAMmoz/taboo-your-words">禁忌</a>不健康！”）</p><p>罗布提尔还花了更长的时间才考虑到，也许你不仅需要优先考虑自己的福祉和友谊，而且<i>为了它们本身而</i>优先考虑它们也是有价值的，而不仅仅是作为功利主义计算的一部分，因为试图证明它们的合理性从功利主义的角度来看，这可能是舞蹈中一个微妙的错误步骤，让他们变得空虚。</p><p> Humo 很难承认，如果你把所有的时间都花在确保恪守道义上的承诺，避免伤害你所照顾的人，那么这种努力实际上是在真实的人类身上进行衡量的，他们因为你花了更长的时间来扩大你的计划而遭受痛苦和死亡。</p><p>在我的心目中，胡莫和罗布提尔是年老而睿智的神，他们早就摆脱了幼稚的挣扎。他们互相尊重如兄弟。他们明白，他们的每个观点都与人类繁荣的整体计划相关。他们的分歧并不像你天真的想象的那么严重，但他们说着不同的语言，强调的东西也不同。</p><p> Humo 可能会承认我无法照顾所有人，甚至无法对所有出现在我生活中但我没有时间帮助的人做出富有同情心的回应。但他说这番话时带着一种温暖、<a href="https://www.lesswrong.com/posts/gs3vp3ukPbpaEie5L/deliberate-grieving-1">悲伤的</a>同情心，而罗布提尔则带着简短而高效的<a href="https://www.lesswrong.com/posts/gs3vp3ukPbpaEie5L/deliberate-grieving-1?commentId=TQuxyPGL7L8nmNe9Z">冷酷语气</a>说出来。</p><p>我发现独立地询问他们并尽我所能想象他们每个人的明智版本是有用的——即使我的想象只是他们理想化的柏拉图式自我的粗略影子。</p><br/><br/> <a href="https://www.lesswrong.com/posts/SfZRWxktiFFJ5FNk8/the-god-of-humanity-and-the-god-of-the-robot-utilitarians#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/SfZRWxktiFFJ5FNk8/the-god-of- humanity-and-the-god-of-the-robot-utilarians<guid ispermalink="false"> SfZRWxktiFFJ5FNk8</guid><dc:creator><![CDATA[Raemon]]></dc:creator><pubDate> Thu, 24 Aug 2023 08:27:59 GMT</pubDate> </item><item><title><![CDATA[I measure Google's MusicLM over 3 months as it appears to go from jaw-dropping to embarrassingly repeating itself]]></title><description><![CDATA[Published on August 24, 2023 4:20 AM GMT<br/><br/><p>谷歌研究院于 2023 年 1 月 26 日提交了一篇关于 MusicLM 的论文，这是一个令人难以置信的强大 AI 模型，可以将用户文本提示转换为音乐。</p><p> https://google-research.github.io/seanet/musiclm/examples/</p><p></p><p> 5 月 10 日，谷歌研究院向公众发布了一份候补名单，允许申请者试用。在大约 6 秒内，它会向用户返回 2 首歌曲，每首歌曲长 20 秒。</p><p> https://blog.google/technology/ai/musiclm-google-ai-test-kitchen/</p><p></p><p>我用它创作的音乐是超越且梦幻的。对我来说，这通常是人类的水平。让它释放我的梦想真是太快了。如果他们让我们将其从 X 秒延长，我可以轻松地将 20 分钟长的曲目变得极其复杂和先进。</p><p></p><p>从5月10日到3个多月后的今天，我一直在测试它的极限和能力。大约 1 个月后，我注意到人工智能正在失去许多能力，并且相同的提示会发出明显不同的音乐，这让我清楚地知道某些事情可能会变得更糟。大约两个月后，输出就不再智能、先进和令人瞠目结舌，就好像人工智能是一个老式模型，在当时并不是很好。三个月后，我可以看到这似乎确实正在发生，因为大多数歌曲现在只是重复短暂的 2 或 4 秒节拍，根本没有做太多事情。现在的情况实在是太可怕了。除了一些提示之外，有一些仍然有点工作，有些感觉质量是 2 个月，有些是 1 个月。我想说的是，如果有的话，水平是 0 个月的也很少。我感觉就像失去了我的宠物狗，或者是我曾经做过的一个好梦。我希望他们永远不会改变模型。我保存了所有梦幻般的测试，尽管我刚刚想出了一些更难的提示，我想记录下来，但现在不能。它说在大约 100 次提示后 30 天后回来（奇怪的是，就在 MusicLM 明显变得更糟的时候），但这可以通过第二天回来来绕过。</p><p></p><p>我的早期测试。 1st SoundCloud 上的其余部分也很好：</p><p> <a href="https://www.reddit.com/r/singularity/comments/13h0zyy/i_really_crank_out_music_tracks_with_musiclm_this/">https://www.reddit.com/r/singularity/comments/13h0zyy/i_really_crank_out_music_tracks_with_musiclm_this/</a></p><p>我的第二个 SoundCloud 既有 3 个月的测试，也有我进行的更早期的测试。</p><p> https://soundcloud.com/steven-aiello-992033649/sets</p><p></p><p>我认为当 MusicLM 要求用户通过给予其一个奖杯来改进模型时，在两首生成的歌曲中选择他们更喜欢的歌曲时，问题就开始了。用户只会做出快节奏的判断（我自己有时会犯一些错误，无法回去更改它们），而没有足够的时间对它们进行真正的排名。这也是二元投票。此外，通常两个轨道都有自己独特的功能和能力，我猜这两个轨道中可能有数百个有用的短功能，而整个 20 秒将是 AI 模型中最大的功能/记忆，所以试图让模型更多地忽略一首歌曲只会随机地消除它自己的各种能力，我猜最终会完全消除。我知道有时一首歌可能会更好，你会认为这会让人工智能变得更聪明，但也许他们的算法无法按照预期正确地持续学习/更新模型。无论如何，人工智能现在似乎更糟糕了。</p><p></p><p>重要笔记：</p><p> MusicLM 似乎很久以前就完成了训练。为什么他们还要花时间去训练它呢？显然已经让人瞠目结舌了。从我的测试中我们已经知道模型确实发生了变化（由于 8 月 20 日的冰城堡测试集，我 100% 确定这一点），所以看起来它很可能在我们使用用户反馈来更改模型时使用。他们可能会试图按照我们的喜好来塑造它，无论模型失去什么代价，因为他们担心人们抱怨它如何知道可能受版权保护的歌曲或 NSFW 材料。或者也许他们只是想让它变得更愚蠢，或者让它变得更好。这三种可能性中的任何一种听起来都“恐怖”。它已经很好了，而且绝对没有变得更好。</p><p>尽管它现在制作的大多数歌曲似乎通常都是重复 2-4 秒的简短旋律，但我早期测试的提示中的许多相同乐器仍然存在。通常。</p><p>我的许多旧提示无缘无故地不再起作用，我尝试运行一个这样的提示，要使其正常工作，我所要做的就是删除“.”之间的 1 个空格。和“L”或保留空格并将“L”更改为小写“l”。短提示“暴力”不会在 MusicLM 中运行，“megurine luka”或“rin kagamine”也不会运行，但更流行的“hatsune miku”会运行。我这样做是为了让它运行的提示部分是这样的：“...太鼓和古筝。合成层...&#39;。在某种程度上，人工智能是这些词语选择背后的原因，但也是人类，这种情况在公开测试开始后发生了变化。</p><p>我们已经看到其他 AI 似乎随着时间的推移而退化：GPT-4 和 DALL-E 2。我个人看到 DALL-E 2 发生了变化，因为对于相同的提示，每个输出都不同。我认为情况变得更糟了，但也没有差太多。我们一开始很喜欢它，可能是因为它制作了 10 张小图像，这些小图像乍一看似乎很养眼，而且除非一次查看一张，否则不必在任何展开的图像中看到所有奇怪的细节。一项研究还跟踪了 chatGPT 随着时间的推移，情况似乎可能会变得更糟。似乎 GPT-4 在发布之前就已经变得更糟了，因为它太强大了，尽管我不确定这种说法。在我看来还是很棒的。谷歌尚未发布其许多人工智能，部分原因似乎是担心被滥用。此外，GPT3.5和GPT-4似乎也有反馈按钮，也许它们也在使用用户输入来更改模型。这似乎是一个新事物。我还看到 MidJourney 5 在实际发布之前也这样做了，他说还没有产生有趣的图像，所以他们必须再过几天进行另一轮投票。从我之前和之后保存的几十张图像来看，我有点确定之前的 MJ5 制作了更准确、更易听、更有趣的图像。今年我也看到稳定扩散也询问我们在两张图像之间哪个最符合提示。</p><p>有人提到我的一些早期测试很长，或者从“创建一个...”开始（一些不错的测试是由 GPT-4 提出的，它提出了“创建一个...”），而 AI 通常可能不会这样做请参阅曲目标题。如果说有什么不同的话，这仅表明早期的 MusicLM 在理解这些提示方面没有问题。我还有其他测试，并且您今天尝试的任何提示在今天的 MusicLM 中都表现不佳，因此我认为这在我的测试中不是问题。</p><p></p><p>总之，MusicLM 确实发生了变化，根据我所有的测试，我想说它在 3 个月后几乎变得几乎毫无用处。我真心希望他们能把 Day1 模型还给我们。</p><br/><br/> <a href="https://www.lesswrong.com/posts/DfqcyGXcFcukYbWZ5/i-measure-google-s-musiclm-over-3-months-as-it-appears-to-go#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/DfqcyGXcFcukYbWZ5/i-measure-google-s-musiclm-over-3-months-as-it-appears-to-go<guid ispermalink="false"> DfqcyGXcFcukYbWZ5</guid><dc:creator><![CDATA[AttentionResearcher]]></dc:creator><pubDate> Thu, 24 Aug 2023 11:48:01 GMT</pubDate> </item><item><title><![CDATA[The lost millennium]]></title><description><![CDATA[Published on August 24, 2023 3:48 AM GMT<br/><br/><p><em>注意：这篇文章是推测性的，您应该对其中的说法持保留态度。</em></p><p>纵观人类历史，我们知道，经济增长（在马尔萨斯条件下人口增长是一个很好的指标）已经加速了很多次。事实上，我们只要向后推算当前的增长率就可以看到这一点：鉴于世界上只有这么多人，而且他们的人均维持生计收入的有限倍数，经济增长率不可能达到每年3％的订单已经持续了一千多年左右。</p><p>尽管很难做到这一点，但人们也对过去这种增长的具体发生方式做出了估计。其中一项估计来自<a href="https://www.pbl.nl/en/image/links/hyde">HYDE 数据集</a>，也可在<a href="https://ourworldindata.org/population-sources">Our World In Data</a>中找到；以及其他估计的完整集合<a href="https://www.census.gov/data/tables/time-series/demo/international-programs/historical-est-worldpop.html">可以在这里找到</a>。</p><p>让我们首先检查一下 HYDE 数据集。公元 1 年之前的数据是每千年给出的，看看增长率，我们可以得到下表：</p><table><thead><tr><th>千年</th><th>平均年人口增长率（百分比）</th></tr></thead><tbody><tr><td>公元前 10000 年 - 公元前 9000 年</td><td>0.0236%</td></tr><tr><td>公元前 9000 年 - 公元前 8000 年</td><td>0.0254%</td></tr><tr><td>公元前 8000 年 - 公元前 7000 年</td><td>0.0279%</td></tr><tr><td>公元前 7000 年 - 公元前 6000 年</td><td>0.0320%</td></tr><tr><td>公元前 6000 年 - 公元前 5000 年</td><td>0.0368%</td></tr><tr><td>公元前 5000 年 - 公元前 4000 年</td><td>0.0411%</td></tr><tr><td>公元前 4000 年 - 公元前 3000 年</td><td>0.0435%</td></tr><tr><td>公元前 3000 年 - 公元前 2000 年</td><td>0.0489%</td></tr><tr><td>公元前 2000 年 - 公元前 1000 年</td><td>0.0415%</td></tr><tr><td>公元前 1000 年 - 公元 1 年</td><td>0.0746%</td></tr></tbody></table><p>除了公元前第二个千年<sup class="footnote-ref"><a href="#fn-GS5X2acGin64XwSjM-1" id="fnref-GS5X2acGin64XwSjM-1">[1]</a></sup>略有逆转之外，估计表明人口增长率逐渐加快。这与人口增长的双曲线模型一致，但在这里我不想做出任何这样的假设，只想看原始数据。</p><p>那么，令人惊讶的是该表中应该包含的下一个条目：在第一个千年，即公元 1 年至公元 1000 年，人口增长率估计平均每年仅为 0.033%。换句话说，根据这个数据集，即使是公元前第五个千年，人口增长也比第一个千年更快！</p><p>事实证明，像这样的结果对于更改我们正在使用的数据集来说是稳健的。 McEvedy 和 Jones 报告称，第一个千年的平均增长率为 0.044%/年，而公元前 1000 年至公元前 200 年的平均增长率为 0.137%/年，从公元前 200 年至公元 1 年的平均增长率为 0.062%/年。 HYDE 数据集中没有提供公元前第一个千年的更详细数据，这表明人口增长放缓可能在第一个千年之前就开始了。为了在这个数据集中找到人口增长较慢的千年，我们必须回到公元前第四个千年（公元前 5000 年 - 公元前 4000 年）。</p><p>我看过的所有数据集都表明，随着第二个千年的到来，人口增长大幅加速。蒙古人的征服和黑死病似乎对 1200 到 1400 年间的人口增长造成了压力，但尽管如此，从 1000 到 1500 年间的人口增长率仍然平均为 0.08%/年，这比公元前第一个千年还要快。</p><p> <a href="https://en.wikipedia.org/wiki/Lost_Decades">“失去的十年”</a>是日本使用的一个名称，指的是1991年日本股市崩盘后的十年经济停滞期。按照这一惯例，将第一个千年称为“失去的千年”可能是合适的。如果我们相信某种经济史的随机双曲线增长模型，即拉鲁德曼（la <a href="https://www.openphilanthropy.org/research/modeling-the-human-trajectory/">Roodman，2020）</a> ，这意味着人类在第一个千年“非常不幸”，可能是由于持续的不利社会冲击。</p><p>这个故事纯粹是定量的，着眼于人口增长，但值得注意的是，在马尔萨斯条件下，我们预计人口增长将跟踪技术进步和资本形成。我们的生产力越高，人们就应该拥有越多的孩子，直到人口增长到足以使劳动边际产量回落到维持生计的水平为止。一千年对于马尔萨斯动力发挥作用来说已经足够了，因此第一个千年缺乏强劲的人口增长也表明创新和资本积累等生产力增长因素的放缓。</p><p>那么重要的问题就变成了：<em>为什么会发生这种情况？</em> ，或者也许<em>这是怎么发生的？</em>我们对其他人口增长放缓有很好的解释，例如1200年至1400年期间的蒙古征服和黑死病。然而，第一个千年的人口增长放缓看起来完全是一个谜。我可以提出一些解释，但它们都不太符合数据。即使是“运气不好”，我也想能够说得更多。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-GS5X2acGin64XwSjM-1" class="footnote-item"><p>也许是由于<a href="https://en.wikipedia.org/wiki/Late_Bronze_Age_collapse">青铜时代晚期的崩溃</a>？ <a href="#fnref-GS5X2acGin64XwSjM-1" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/><a href="https://www.lesswrong.com/posts/hgf6FB9jMB7wMLuKA/the-lost-millennium#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/hgf6FB9jMB7wMLuKA/the-lost-millennium<guid ispermalink="false"> hgf6FB9jMB7wMLuKA</guid><dc:creator><![CDATA[Ege Erdil]]></dc:creator><pubDate> Thu, 24 Aug 2023 03:48:40 GMT</pubDate> </item><item><title><![CDATA[Regreasing a KitchenAid Mixer]]></title><description><![CDATA[Published on August 24, 2023 2:30 AM GMT<br/><br/><p><span>我最近从朋友那里得到了一台旧的 KitchenAid 搅拌机。它是 k45ss，可能是 80 年代初的，我看到的一般建议是，在典型的家庭使用中，它们应该每 10 年重新润滑一次。</span>我订购了 4 盎司<a href="https://www.youtube.com/watch?v=UmnD6Y5jNMg">食品</a><span>安全合成</span><a href="https://www.amazon.com/dp/B08ZYCQVRD">润滑脂</a>，并遵循 Mixer 先生的 YouTube 指南（<a href="https://www.youtube.com/watch?v=EW9BQ-oPFkk">第</a><a href="https://www.youtube.com/watch?v=L-qMOyhb2xc">1、2、3</a>部分）。我一边用手机播放视频，一边进行操作：打开搅拌机，清除旧油脂，添加新油脂，然后将其放回原处。有细微的差别（我的应力消除装置很烦人，而且我的齿轮组件内部没有<a href="https://youtu.be/L-qMOyhb2xc?si=dYgKmFXzWSKtX7o1&amp;t=133">销钉</a>，需要先拆下蜗杆组件），但它非常接近。</p><p>行星齿轮组件的润滑脂含量很低，而且那里的润滑脂有点干：</p><p> <a href="https://www.jefftk.com/kitchen-aid-planetary-low-grease-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/sxkpxtvrlzqqa6v5cose" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/sxkpxtvrlzqqa6v5cose 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/gkxxaeipawczo0vhwjii 1100w"></a></p><div></div><p></p><p>上部区域有更多的油脂，尽管油脂比我想象的要硬：</p><p> <a href="https://www.jefftk.com/kitchen-aid-head-internal-old-grease-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/d0cj2kg5nbktkhqqjp00" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/d0cj2kg5nbktkhqqjp00 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/lhtcygg0imcqpa4ile53 1100w"></a></p><div></div><p></p><p>齿轮状况良好，感觉良好且坚固。</p><p>脱脂、再润滑和组装都很顺利。总共大概1.5小时？然而，当我完成后，我意识到我还剩下一个零件：三个垫圈之一。</p><p> <a href="https://www.jefftk.com/kitchen-aid-extra-washer-big.jpg"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/r6u3cvfabtvaqzzxccgg" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/r6u3cvfabtvaqzzxccgg 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5pcunrT9fJJ3hmHvu/rcl1me4clylsn0u0zcnq 1100w"></a></p><div></div><p></p><p>我回顾了视频，它谈到安装其中两个洗衣机，我记得这样做过，但我对如何最终安装第三个感到困惑。没有任何逻辑上应该有洗衣机但没有的地方。</p><p>我在晚餐时谈到了这一点，我的一位室友说他们还有一个旧的 KitchenAid，可能从未重新润滑过（k45，电源线没有接地，可能是 60 年代末）。我们决定一起做他们的，也许我们会看看洗衣机去了哪里。</p><p>拥有第二双手和前一天晚上刚刚完成的一双手相结合，使得整个过程变得更快：不到一个小时。和我的非常相似，除了应力消除更烦人。不过，我们确实解开了垫圈之谜：行星机构中有两个垫圈，彼此堆叠在一起。</p><p>我不确定是否值得打开我的底部来安装额外的垫圈。我倾向于是（他们不会无缘无故地放两个垫圈，不需要把整个东西拆开）但可能我真的不需要？</p><br/><br/> <a href="https://www.lesswrong.com/posts/5pcunrT9fJJ3hmHvu/regreasing-a-kitchenaid-mixer#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/5pcunrT9fJJ3hmHvu/regreasing-a-kitchenaid-mixer<guid ispermalink="false"> 5pcunrT9fJJ3hmHvu</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Thu, 24 Aug 2023 02:30:04 GMT</pubDate> </item><item><title><![CDATA[Assessment of intelligence agency functionality is difficult yet important]]></title><description><![CDATA[Published on August 24, 2023 1:42 AM GMT<br/><br/><p><strong>总结：</strong>在观察情报机构时，硬的部分很难看到，软腐败的部分很容易被观察到。这导致了一种偏见，即很多人高估了容易观察到的柔软和无害部分的普遍程度。有时，这甚至会导致职业生涯比你领先得多的人产生一种危险而普遍的估计，认为整个情报机构是无害且无关紧要的，但事实并非如此。情报机构可能是功能较少、相关性较低的部分和功能较多、相关性较高的部分的混合体，这些部分对政府和政策具有不成比例的巨大影响力；认为情报机构都是由不值得关注的非功能性、不相关的部分组成的想法是错误的，即使这种信念是一种流行的规范。</p><p></p><p><strong>为什么情报机构很危险</strong></p><p>在很多情况下，情报机构会在没有任何警告的情况下突然变得重要。例如，美国国家安全委员会的大多数或全部机构可能会突然一致改变其对功能增益研究的立场，例如美中关系或美俄关系再次触及25年来的新低（实际上已经近几年来经常发生）。</p><p>无论是某个机构的领导层，还是机构中有权执行操作的有权势的个人，或者是腐败集团，都可能亲自做出判断，认为加快或重新启动 GOF 研究的最佳方法是针对最有效率的各种人员或有效反对 GOF 研究。</p><p>这不一定是加速或保护 GOF 研究的最有效方法，它只需要看起来像那样，足以让某人签字同意，甚至让他们只是认为这对他们的老板来说看起来不错。</p><p>在情报机构的混合能力模型中，有能力或技术先进的<i>能力</i>显然可能与无能的管理/决策混合在一起。一个真正无害、无关紧要、不值得关注的情报机构（而不是有动机错误地表现出无害、无关紧要或不值得关注的样子）必须是这样的情报机构：技术上<i>既不</i>复杂<i>，又</i>过于腐败，无法实现基本功能，例如运行操作。</p><p>对于美国、俄罗斯和中国的情报机构来说，这是一种极其天真的想法；尤其是美国和中国，它们拥有广泛的声望、先进的技术以及蓬勃发展的私营部门技能库来招聘人才。</p><p>当从某个地方的某个人绝对必须执行的政策倡导任务（例如推动可能导致人类灭绝的 GOF 研究推动明智的政策制定）中计算预期价值时，许多人目前意识到，该重要社区消失或解散的风险大大降低了预期价值计算该重要社区所产生的一切；例如，社区有 10% 的机会停止存在或解散，整个社区产生的预期价值会减少约 10%。</p><p>我遇到的大多数人脑海中浮现的都是一场大规模的极权主义剧变，就像20世纪初中期的那样，而这种剧变是安全与不安全之间的严格界限。然而，在21世纪，特别是在新冠疫情和2008年经济衰退之后，专家和军事规划者现在更加关注国际力量平衡（例如美国、俄罗斯和中国相对于彼此以及其他独立国家的实力）改变是由于经济崩溃或联盟瘫痪，而不是革命或军事征服。这是因为今天的整个世界与 70 年前截然不同。</p><p>更有意义的是预期经济会出现缓慢且不完全的倒退，其结果是以各种方式转向<a href="https://en.wikipedia.org/wiki/Hybrid_regime">混合政权</a>，其中情报机构和内部安全机构因腐败而滥用权力，而由于广泛的腐败而缺乏问责制。优先考虑<a href="https://en.wikipedia.org/wiki/Hybrid_warfare">混合战争</a>，并防止俄罗斯和中国等外国对手利用国内精英，如亿万富翁、政府官员和与关键人群相关的名人/思想领袖（如 Yann Lecun）。</p><p>对此的一个角度示例，来自<a href="https://www.lesswrong.com/posts/LyywLDkw3Am9gbQXd/don-t-take-the-organizational-chart-literally?commentId=bnujfnQXJJ3mJJkxa">Don’t Take the Organization Chart Literals</a>的置顶评论：</p><blockquote><p> ...政府（和腐败的企业组织）中发生的很多事情都是通过默许权力完成的。很少有司法部、中央情报局和联邦调查局官员能够全面了解他们的工作如何与美国的利益不一致。但他们大多数人都有一个普遍的认识，那就是他们对组织的忠诚度要高于对美国的忠诚度。 <a href="https://www.lesswrong.com/posts/LyywLDkw3Am9gbQXd/don-t-take-the-organizational-chart-literally#fn-2WzufJ2HD9B92Pnz6-1"><sup>[1]</sup></a>通过其家族和其他腐败关系，[司法部领导人]巴尔成为美国腐败机构内部集团的一部分。这很简单，就像大多数下级军官知道他和他们在一起一样。</p><p>所以巴尔不必明确地告诉警卫们别看他，他不必告诉联邦调查局进行糟糕的调查，他不必告诉司法部继续腐败......下-拥有下属充分信任和信心的级别老板会制定小计划来完成任务。这是老板想要的，老板会照顾他们。</p><p>想象一下马斯克可能收购 Twitter 的情况。你是否认为如果马斯克收购了 Twitter，即使作为私人所有者，他也会突然完全控制整个机构？当然不是。<strong>真正有权力的人，都是他的下属，那些在他那里呆了一段时间的人，属于他的圈内人。</strong>对马斯克来说，控制推特的唯一方法就是解雇相当多的人，其中许多人是该组织不可或缺的一部分。</p></blockquote><p></p><p><strong>很难看到硬化部分</strong></p><p>（注意：这是<a href="https://www.lesswrong.com/posts/pfL6sAjMfRsZjyjsZ/some-basics-of-the-hypercompetence-theory-of-government">上一篇文章</a>的清理版本，我对其质量不满意。如果您已经阅读过它，请随意跳过这篇文章）。</p><p>一些社会结构可以进化，允许更多人保守秘密。例如，情报机构不仅是相互划分的，而且组成这些机构的员工都认为，如果有人接近他们提出购买机密，这可能是该机构内部的例行反情报行动之一，会引出并起诉不值得信任的员工。结果，这些员工基本上将他们的代理机构<a href="https://www.lesswrong.com/tag/newcomb-s-problem">集中在一起</a>，几乎从不接受外国代理人的贿赂，无论承诺的报酬有多么可笑。任何漏掉的信息都很难摆脱由双重/三重特工伪装成容易受贿的人的虚假信息的影响。</p><p>它比这复杂得多，但这只是机构内部演变的保密系统的一个例子；它不仅足以有效地保守秘密，而且还能够阻止或误导外部特工，明智地试图破坏秘密保守网络（<a href="https://en.wikipedia.org/wiki/Double-Cross_System">几乎一百年前</a>或<a href="https://en.wikipedia.org/wiki/Counterintelligence#History">更早</a>出现）。</p><p>情报机构的高层很难观察。目前尚不清楚产出不足是否主要是由于无能和不感兴趣造成的，或者如此强大的结构内部的激励机制是否导致有能力的个人将自己的能力浪费在内部竞争和淘汰同事上。然而，将更容易接触和观察的普通中低层政府官员/官僚推论到难以观察的高层是危险的。较高梯队的人员分布可能严重失调；例如，在一个关于公司等级制度的过于简化的热尔维模型的思想实验中（“反社会者”高度社交，喜欢聚餐；“无知”者拥有深刻的组织洞察力；“失败者”过着非常幸福的生活，他们“失去”的主要是与其他人一样的衰老过程），一个在金字塔上向上发展的人会逐渐发现感恩节火鸡效应：人类自我分类，导致遇到已经成功追求财富激励的人组织的顶层，因为他们与金字塔中层和底层更容易观察到的人相比，具有不同寻常的、本质上不同的个人特征组合。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pfL6sAjMfRsZjyjsZ/pc6ccmqo9ogw4k3nsdfr"><figcaption>该图像被明确声明为公司层次结构，它被明确声明不是在描述情报机构或有趣的非营利组织，它们以与大多数私营部门公司不同的方式体验<a href="https://slatestarcodex.com/2014/07/30/meditations-on-moloch/">Moloch</a> 。</figcaption></figure><p>尽管自由主义学派最基于对政府普遍无能的经验观察，但这不应该分散我们对基本原则的注意力，即拥有 80% 权力的组织中的前 20% 很大程度上是未知的领域，因为很难观察以及各种奇怪的特定动态可能可以解释政府的失败；尽管模型必须以观察为基础，但过度依赖自由主义思想流派仍然存在风险，这种思想主要以低层官僚为对象，并想象政府统一由他们组成，将这些人推论到最高和最理想的职位。情报机构肯定已经注意到，冒充无能的官僚是一种极好的伪装，而且整个政府也都知道，迷宫般的文书工作可以威慑掠夺者。</p><p>组成 EA 的表现最好的利他主义者，远低于全球所有利他主义者的 0.1%，由于极不寻常和极端的环境，包括强大的能力、运气、智力、动机和以富有成效的方式自发组织的能力，他们正处于极端顶峰。以实现工具上趋同的目标。然而，与 EA 不同的是，情报、军事和内部安全机构中最顶尖的 0.1% 的人面临着来自政权更迭的威胁、各种富有和有权势的精英的仰视以及持续的战略渗透攻击带来的令人难以置信的进化优化压力。由外国情报机构。我们根本不清楚民主国家的权力掮客的顶峰最终会演变出什么样的结构，而且在认识上自动顺从自由主义学派并不负有责任，即使自由主义学派是关于无数人的生活被无能的政府干预/监管毁掉的说法是正确的。有能力的人和团体仍然会被排到最高层，面临达尔文主义的压力，即使绝大多数有能力的人一路上都摆脱了官僚主义的废话。情报机构的运作是我们观察到的结果，这些人被赋予了难以置信的权力、有罪不罚、垄断信息的能力，以及利用他们自己与与其共享一个国家的大型、技术先进的私营公司之间的权力和信息不对称。 （企业游说者可以促进甚至现金激励他们与领导者之间各种复杂的讨价还价，特别是包括顶尖人才的旋转门雇佣，而情报机构的权力和声望进一步促进了这一点）。</p><p></p><p><strong>很容易看到软的部分</strong></p><p>情报机构有能力渗透到顽固的官僚机构和其他组织，通过损害人员网络进行横向移动，并指导世界各地（可能包括国内）行政部门和立法部门/议会人员的职业生涯。</p><p>有相关经验的人都知道，在官僚机构中向上和横向晋升是一门科学（还有很多其他事情，其中​​大多数都非常令人不愉快）。在那些比你更进步的人的心目中，晋升和驾驭官僚机构也是一门比你自己更精确的科学。鉴于他们如此成功，他们很可能做了很多正确的事情，并且一路上学到了很多你没有学到的东西。</p><p>然而，同样地，在情报机构专家的心目中，它是一门更加精确的科学，这些机构世世代代专注于系统地渗透、控制和欺骗世界各地顽固官僚机构（和其他组织）的顽固部分（ <a href="https://www.cold-takes.com/most-important-century/#Summary:~:text=More%20info%20about%20these%20timelines%20at%20All%20Possible%20Views%20About%20Humanity%27s%20Future%20Are%20Wild%2C%20This%20Can%27t%20Go%20On%2C%20and%20Forecasting%20Transformative%20AI%3A%20Biological%20Anchors%2C%20respectively.">但只有少数几代人</a>）。人类文明是建立在专业化和分工的基础上的，而情报机构就是专门从事这一工作的人。 <span class="footnote-reference" role="doc-noteref" id="fnrefsapjucliu6o"><sup><a href="#fnsapjucliu6o">[1]</a></sup></span></p><p>由于对轶事的必要依赖，这种信息的不对称性甚至更大，而且由于许多人根据在机构特定部门工作时的氛围做出决策的现象而变得更加复杂。</p><p>这是值得注意的，因为在一个机构的人员<strong>流动率较高的</strong>部分<i>，</i>进出人数不成比例，因此占据了不成比例的大量观察和证词。这进一步加剧了这种动态，即很难看到坚硬的部分，而更容易看到较软的部分，因为众所周知，腐败、无能、暴行/派系主义和低参与度都会大大增加人员流动，而高价值的秘密、众所周知，更有能力的管理人员、有趣的工作和以使命为导向的员工流动率较低，也更容易从顶尖公司招聘顶尖人才。</p><p>此外，评估组织的领土也存在反归纳情况的风险，这些组织的任务包括长期的宣传、虚假信息，特别是反情报，以及利用先进技术利用人类心理（包括通过使用数据）。科学、大规模监视和人工智能）。特别是，摆脱共鸣是一种非常糟糕的方法，因为共鸣是情绪化的、潜意识的，并且很容易获得大量数据并进行科学研究。你对某件事了解得越多，就越容易找到通过用特定刺激刺激某物来获得特定结果的方法。</p><p>与假想的富人和有权势的人打交道，他们专门利用自己的财富和影响力来<a href="https://www.lesswrong.com/posts/xDNyXGCDephBuNF8c/dark-forest-theories">避免将自己的地位拱手让给同样富有和有权势的敌人</a>，需要理解与处理不可证伪的理论相关的人类认知偏见。我的模型看起来很棒，这是<a href="https://www.lesswrong.com/posts/RryyWNmJNnLowbhfC/please-don-t-throw-your-mind-away">一个可以在你的脑海中思考的有趣话题</a>，而难以发现的能力垄断岛理论与飞行的意大利面怪物和隐形龙完全不同；但这些考虑因素也必须以定量的心态进行评估。最终，除了政策结果和众所周知的军事/情报结果之外，几乎没有好的数据，并且这两种假设（情报机构内的统一无能与非统一无能）都必须用现有的最佳认识论来处理。我推荐尤德科夫斯基的<a href="https://www.lesswrong.com/posts/CqyJzDZWvGhhFJ7dY/belief-in-belief">《信仰中的信仰</a>》、 <a href="https://www.lesswrong.com/posts/fAuWLS7RKWD2npBFR/religion-s-claim-to-be-non-disprovable">《宗教的不可反驳性主张》</a> 、 <a href="https://www.lesswrong.com/posts/XTXWPQSEgoMkAupKt/an-intuitive-explanation-of-bayes-s-theorem">《贝叶斯定理的直观解释》</a> （如果你还没有读过的话），以及雷蒙的<a href="https://www.lesswrong.com/posts/xDNyXGCDephBuNF8c/dark-forest-theories">《黑暗森林理论》</a> 。我在这篇文章中描述的限制对于理解情报机构至关重要。</p><p>对这些机构的研究比迄今为止似乎发生的事情需要更好的认识论。</p><p></p><p><strong>测谎仪的发挥作用是人类历史的转折点</strong></p><p>所有人类社会和平衡都部分源于人脑的一个基本特征：<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3680134/">人脑产生谎言比人脑发现谎言更容易，即使是</a>在面对面的对话中，大量的紧张情绪也是如此。揭示非语言交流的交换（例如面部表情、微妙的身体姿势变化）。你不能问别人是否打算背叛你，如果你能问，一切都会不同。</p><p>如果发明了功能性测谎仪，我们所知道的激励结构将完全被更有效的新结构所取代。例如，你可以强迫所有下属戴上脑电图或进入功能磁共振成像仪，然后询问他们所有人谁是办公室里最聪明/最有能力的人，提拔实际上表现最好的人，并解雇任何派系/您发现围绕共同谎言进行协调的人的派系。大多数能够使用有效测谎技术的中层管理人员在作为能够使用有效测谎技术的中层管理人员花费数千小时的过程中都会想到这些事情，以及我尚未想到的许多其他策略。</p><p>如果你对测谎技术的第一反应是“嗯，测谎技术目前极其不准确且无效”，那么这是一个非常可以理解的错误，但也毫无疑问是一个错误。我和很多人谈过这个问题，几乎所有人都自信地输出了基本上完全相同的文本字符串，但不知道它来自哪里或支持它的是什么。我并不怀疑这在 40 甚至 20 年前可能是正确的，但随着现代技术的发展，这更像是一个难以抉择的问题。最好的论文（我愿意分享）涵盖了政府/军事利益和测谎技术的获取，无论是当前还是未来潜在的垄断，都<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3680134/">在这里</a>，其中还涵盖了测谎技术的声誉（这是更容易观察和研究的事情之一）。</p><p>这可能是未来 30 年人类文明相对于过去 80 年人类文明分布不均的最重要方式之一（它不是#1）。</p><p></p><p><strong>我发现有用的信息</strong>：</p><p> <a href="https://www.lesswrong.com/posts/LyywLDkw3Am9gbQXd/don-t-take-the-organizational-chart-literally">不要从字面上理解组织结构图</a>（强烈推荐）</p><p> <a href="https://www.lesswrong.com/posts/oqvsR2LmHWamyKDcj/large-language-models-will-be-great-for-censorship">法学硕士非常适合审查</a></p><p>雷蒙的黑暗<a href="https://www.lesswrong.com/posts/xDNyXGCDephBuNF8c/dark-forest-theories">森林理论</a></p><p>约瑟夫·奈的<a href="https://www.amazon.com/Soft-Power-Means-Success-Politics/dp/1586483064">软实力</a></p><p><a href="https://www.lesswrong.com/posts/r2vaM2MDvdiDSWicu/the-u-s-is-becoming-less-stable">美国变得越来越不稳定</a></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnsapjucliu6o"> <span class="footnote-back-link"><sup><strong><a href="#fnrefsapjucliu6o">^</a></strong></sup></span><div class="footnote-content"><p>另一方面，议会和立法机构更多的是为一个国家的精英提供合法且可持续的影响力，让他们除了搞肮脏的事情之外还有出路（而且一个国家的顶级精英有各种各样的方式来发挥影响力）在财富和权力的巅峰/接近巅峰时肮脏；试着想象一个智商 175 的人能做什么）。与民主国家不同，威权政权更注重隔离精英。他们是友好领域的专家，比如稳健性和政策制定。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/foM8SA3ftY94MGMq9/assessment-of-intelligence-agency-functionality-is-difficult#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/foM8SA3ftY94MGMq9/assessment-of-intelligence-agency-functionity-is-difficult<guid ispermalink="false"> foM8SA3ftY94MGMq9</guid><dc:creator><![CDATA[trevor]]></dc:creator><pubDate> Thu, 24 Aug 2023 01:42:22 GMT</pubDate> </item><item><title><![CDATA[China's position on autonomous weapons]]></title><description><![CDATA[Published on August 23, 2023 10:20 PM GMT<br/><br/><blockquote><p>在继续认可制定具有法律约束力的法律文书的必要性的同时，2018年中国还提出了一个较为狭隘的法律定义，包括五个基本特征：</p></blockquote><blockquote><blockquote><p>第一个是杀伤力，这意味着足够的有效载荷（电荷）使其具有杀伤力。二是自主性，即任务执行的整个过程中不存在人为干预和控制。第三是无法终止，这意味着一旦激活就无法终止设备。第四是无差别作用，即无论条件、场景或目标如何，该装置都会执行杀伤和致残的任务。第五是进化，意味着通过与环境的交互，设备可以自主学习，并以超出人类预期的方式扩展其功能和能力。</p></blockquote></blockquote><blockquote><p> [...] 中国的限制性定义对可能有资格受到法律监管的技术种类设置了极高的门槛。</p></blockquote><blockquote><p>然而，接受我们采访的中国政府专家小组代表并不认为这个定义是“狭隘的”。对他们来说，快速的技术进步可能很快就会使零人为监督的武器成为现实，特别是在美国等技术先进的国家。</p></blockquote><p>具有自主瞄准功能的军用无人机已经存在。土耳其 <a href="https://thebulletin.org/2021/05/was-a-flying-killer-robot-used-in-libya-quite-possibly/">可能使用过其中之一</a>。<a href="https://www.youtube.com/watch?v=G7yIzY1BxuI">以色列也一直在</a>开发自主武器。 <a href="https://en.wikipedia.org/wiki/AeroVironment_Switchblade">Switchblade 600</a>不是自主的，但美国国防承包商有兴趣在此类产品中添加自主瞄准功能，并且似乎正在游说反对美国的相关法规。中国政府似乎强烈支持自主武器，但也强烈反对电影中的终结者。</p><p>到目前为止，重点是小型短程电动无人机的自主瞄准，但对于可以携带更多传感器和计算设备的大型无人机来说，自主瞄准更容易，而远距离数据链路则更困难——特别是当卫星在战争等中成为目标时美国与中俄联盟之间的台湾问题。</p><br/><br/> <a href="https://www.lesswrong.com/posts/QaaunwFaGGFd8cTpy/china-s-position-on-autonomous-weapons#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/QaaunwFaGGFd8cTpy/china-s-position-on-autonomous-weapons<guid ispermalink="false"> QaaunwFaGGFd8cTpy</guid><dc:creator><![CDATA[bhauth]]></dc:creator><pubDate> Wed, 23 Aug 2023 22:20:14 GMT</pubDate> </item><item><title><![CDATA[Diet Experiment Preregistration: Long-term water fasting + seed oil removal ]]></title><description><![CDATA[Published on August 23, 2023 10:08 PM GMT<br/><br/><p>我对 exfatloss<a href="https://exfatloss.substack.com/p/seed-oils-explain-the-8-mysteries">最近的理论</a>很感兴趣，即肥胖流行的主要原因是亚油酸多年来缓慢而微妙的损害。具体来说，我想测试更广泛的可能性，即脂肪组织的成分是导致问题的原因。由于我们没有十年的时间来自然地检验他的假设，因此我将重新调整我目前的饮食习惯，以进行修改后的实验。</p><p>我现在刚刚从极低热量饮食过渡到清水断食，在过去几周内减掉了大约十五磅。我将尝试在接下来的三十天内继续禁食，或者直到我的 BMI 达到 &lt;25。水断食结束后，我将严格从饮食中排除亚油酸和其他多不饱和脂肪酸；我的膳食主要包括蔬菜、米饭、特制的低多不饱和脂肪酸猪肉和鱼。那我就再吃一个月吃饱。</p><p>通常情况下，水断食后你会恢复刚刚减掉的所有体重，因为你没有改变身体的饮食“设定点”，并且你浪费了所有的精神力量试图阻止自己进食。然而，如果亚油酸假说是正确的，那么我作为一个优秀的美国人多年来消耗的所有多不饱和脂肪酸首先就是导致我的设定点保持如此高的原因。因此，在这次自我实验中，我将刻意清除大部分剩余的脂肪储备，用传统的日本饮食来填充它们，看看我的“自然体重”是否发生变化。</p><p>如果损害是不可逆的，亚油酸假说不会无效，但我至少可以检验这样的假说：我的脂肪的<i>运行</i>成分是导致我的新陈代谢崩溃的原因。</p><br/><br/> <a href="https://www.lesswrong.com/posts/5KkyygHQL2XCw3kTs/diet-experiment-preregistration-long-term-water-fasting-seed#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/5KkyygHQL2XCw3kTs/diet-experiment-preregistration-long-term-water-fasting-seed<guid ispermalink="false"> 5KkyygHQL2XCw3kTs</guid><dc:creator><![CDATA[lc]]></dc:creator><pubDate> Wed, 23 Aug 2023 22:08:49 GMT</pubDate></item></channel></rss>