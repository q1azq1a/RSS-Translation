<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 14 日星期二 02:23:10 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[What is wisdom?]]></title><description><![CDATA[Published on November 14, 2023 2:13 AM GMT<br/><br/><h1>横向通过计时电话</h1><p>在《<a href="https://www.lesswrong.com/posts/cKrgy7hLdszkse2pq/archimedes-s-chronophone">阿基米德的计时电话</a>》中，尤德科夫斯基问道：如果你被禁止说什么，你想对阿基米德说什么——你想向过去传达什么重要信息，让世界从此走上一条充满希望的道路——这也太不合时宜了吧？也就是说：如果阿基米德收到的信息不是字面意义上的您所说的，而是您用来生成信息的永恒原理的输出，正如在阿基米德的头脑中应用在他的上下文中一样，您会怎么说？然后他解释说，<a href="https://www.lesswrong.com/posts/7khK4DShZBR8gfyHv/chronophone-motivations">这个问题指向我们可以为自己提供原创思维的建议</a>。更一般地说，他写道：</p><blockquote><p>计时器困境的意义在于让我们思考，当你事先不知道目的地时，应该遵循什么样的认知策略。</p></blockquote><h2>横向不合时宜</h2><p>这个问题不仅涉及通过计时电话对阿基米德说些什么，或者对我们自己说些什么。它还讨论了当我们的同时代人与我们之间存在鸿沟时，我们可以给我们的同时代人提供哪些建议，就像我们与阿基米德之间的鸿沟一样。</p><p>这种“横向不合时宜”表现在思维方式的重大差异中，例如生活在不同文化、国家或意识形态的人们之间。 （你可以说，人们沿着平行但独立的<a href="https://tsvibt.blogspot.com/2023/06/time-is-homogeneous-sequentially.html">时间进程</a>前进。）某人的背景——他们的教育、社区、语言等等——将决定什么{概念、思维方式、存在方式、协调点、价值观、可能性他们会理解并重视。如果某人来自与你的世界完全不同的世界，并且他们试图传达一些对你来说重要的东西，那么你很容易以某种方式并没有真正接受他们想要与你传达的信息。你会误解、过度翻译、驳回、忽视、四舍五入、分类、防御或害怕回避他们所说的内容。</p><p>横向不合时宜也会出现在冲突的情况下。对方做出的每一个动作——每一个陈述、每一个论点、每一个提议的对话程序、每一次谈判、每一个请求、每一个假设的共同点——都可能是谎言、误导你关于他们的信仰或意图的策略、恶搞诱饵、集结他们的军队或获得第三方支持或维持他们的自我妄想的表演，利用你的善意，分散他们隐藏的恶意活动的注意力，干扰你的思维方式，或试图通过宣传扰乱你自己的内心政治意愿和动机。冲突是一种毒药。任何行为都可以通过一点努力被合理化为极度邪恶，而对另一个人采取这种解释立场可能几乎是一种天生的本能模式，可以触发并自我维持地保持触发状态。</p><h2>横向不合时宜的例子</h2><p>您对为什么人体冷冻学具有很高的期望值有详细的论证，我应该注册吗？这只是告诉我要使用奇怪的状态举动来促使人们忽视 AGI 风险并对上行空间感到兴奋，因为那是我使用我习惯的[施加社会压力的方式]让人们购买我的首选[协调点我的社会阶层表现得乐观，无论所涉及的“信念”是否确实有意义]。</p><p>您要求提出与公共政策相关的事实主张的人们必须对其陈述的可观察相关性给出明确的概率？这只是告诉我要求提出政策主张的人必须拥有博士学位并经营一个主要的人工智能实验室，因为这是[我已经准备好满足的外部可验证标准，而我的意识形态对手还没有准备好满足]。您加倍强调，说可以用数学方式显示显式概率和更新，以实现长期的真相跟踪？我加倍强调，认证研究人员群体是唯一有资格区分有用且审慎的研究与无用且轻率的研究的群体，因为这是[我已经喜欢并期望让我掌权的基本判断标准]。</p><p>但<em>事实上</em>，你确实是在努力寻求真理，而不是追求权力，你反对吗？而且，你继续说，你是关于寻求真理的真理寻求，如果有与寻求真理相关的证据表明你真理的方向，你就会寻求真理更新你所​​提倡的寻求真理的内容——寻求——应该更新你对哪些认知政策是寻求真相的信念？因此，当我的计时器将你的潜在认知政策解释为关于权力寻求时，计时器是不公平的，并否认你作为真理寻求者的存在，客观上我应该将你所说的翻译为追求真理？好吧，就像你否认我这个权力追求者的存在一样，在我们话语的元层面上断言，“实际上是真实的”或“客观的”应该是我们政治上共同的标准，而不是现在的标准。追求权力的权宜之计，我也会否认你这个寻求真理的人的存在，并把你的主张打折扣为更多的权力追求举动，旨在在谁有权裁决哪些认知政策将成为问题上占据上风。被跟随。因为显然这就是我们正在做的事情，否认其他人的存在方式。因为那是我的[与其他人相关的局部反射稳定的对象和元级认知策略]。</p><h2>答案：理性</h2><p>问题是：</p><blockquote><p>当您事先不知道目的地时，应该遵循什么样的认知策略？</p></blockquote><p>这也回答了这个问题：</p><blockquote><p>可以真诚地推荐什么样的认知政策来跨越不同目的地之间的鸿沟？</p></blockquote><p>理性是一类答案。但这个答案并不能跨越所有鸿沟——有时它不容易转化为其他思维方式，它不会被接受，它不能被争论到不接受那种自然而然的理由的人。具有理性思维的人。理性主义者可能会争辩说，就其本质而言，理性最终或多或少地可以说服任何尚未完全封闭自己以注意新思维方式的人，因为理性在如此广泛的普遍性中是如此的普遍。但即使这是真的，“最终”也可能只是在很长一段时间之后或在特定情况下。因此，理性并不能满足跨越鸿沟政策的实际需要。</p><p>有哪些答案更容易跨越理性难以跨越的鸿沟？</p><p>理性可以正确地声称包含所有其他美德——<a href="https://www.lesswrong.com/posts/7ZqGiPHTpiDMwqMN2/twelve-virtues-of-rationality">无名的美德</a>，虚空的美德，重生所有其他美德，甚至包括描述自我意识有限计算、有限可塑代理的美德。但我们已经<a href="https://www.lesswrong.com/posts/CuSTqHgeK4CMpWYTe/created-already-in-motion">在运动中被创建</a>，因此存在相当低计算量、低探索性的默认后备认知策略，这些策略是熟悉的并且通常是可以接受的。这些后备措施通常包含我们价值观的核心部分，并且通常不是很<a href="https://tsvibt.blogspot.com/2023/03/explicitness.html">明确</a>，也不是已经<a href="https://www.lesswrong.com/posts/EEv9JeuY5xfuDDSgF/flinching-away-from-truth-is-often-about-protecting-the">以可以干净地更新证据的形式</a>出现。存在切斯特顿的栅栏，跨越这些栅栏有时会导致陷入<a href="https://www.lesswrong.com/posts/oZNXmHcdhb4m7vwsv/incremental-progress-and-the-valley">不良理性的低谷，</a>然后再重新获得胜利。</p><p>我们是<a href="https://en.wikipedia.org/wiki/Cognitive_miser">认知守财奴</a>。默认情况下，我们不会做任何资源密集型的事情（即消耗能量、计算、注意力、脑件或可塑性），例如探索、计算影响、更新我们的信念或重构我们的目标。跳过栅栏和穿越山谷需要资源。获胜的理性，或者你发现自己的任何其他地方，都是在跨越一些栅栏和山谷之后的一个目的地，在许多可能的目的地中（即使它们都在前往一个更遥远的目的地的路上）。在你当前目的地的后面、之下或之前，都有后备、原始直觉、原始本能。</p><p>所以：即使有人不参与整个“理性”业务，他们中仍然存在获胜行为的碎片和<a href="https://www.lesswrong.com/posts/cSXZpvqpa9vbGGLtG/thou-art-godshatter">价值的碎片</a>。那些胜利的碎片和价值的碎片足以强大，并且将有自己的局部反思稳定性和局部连贯性。它们可能足以嵌入可跨越横向不合时宜的鸿沟传播的认知政策，比一些更完整的理性更流畅，这将有力地导致善良。</p><h2>答案：智慧</h2><p>对于这一困境，一个推测性的答案是：智慧。从悬崖上退后才是明智之举。摆脱种族和冲突是明智的。明智的做法是放弃故作姿态。深入考虑改变一切的风险是明智的。放弃贪婪的需要，成为从天而降火的那一位，是明智的做法。将人性和仁慈置于个人野心和感兴趣的外表之上是明智的。</p><p>智慧对某些人有吸引力，甚至有时在理性不有吸引力的地方也是如此。理性是要求严格的、卫生的、依赖智商的、需要计算的。智慧受到尊重。智慧使你成为别人可以仰望的人。智慧使生活丰富并创造繁荣所需的环境。智慧围绕苦难跳舞。智慧在窄桥上保持平衡。</p><p>怎样才能通过计时电话说出智慧呢？首先我们要明白什么是智慧。</p><h1>什么是智慧</h1><p>一个非常部分的列表：</p><ul><li>聪明的人可能会说一些简单但深刻的话。他们可能会在正确的时刻说出这句话，而其他人不会在此时说出这句话，尽管其他人已经听过这句话，并且足够熟悉它的含义。智慧提醒。</li><li>智慧存在于悖论中，甚至在那里也很自在。<ul><li>希望与真理发生冲突。希望是脆弱的，并且取决于共识。希望可能会被真相摧毁。真相可能会导致绝望。智慧不会绝望，但也不会背离真理。它谨慎地对待事实。它不执着虚假的希望，但也不破灭最初的希望——它紧紧抓住最初的希望，为最初的希望变成眼前的希望开辟道路。</li><li>开放性与诚信相冲突。诚信可以抵制对判断的扭曲力量，并维护核心一体化进程所需的作用，例如司法系统（公正）、协调（可靠性、偏向不证伪）和求真（诚实）。开放性消解界限、调整组合、探索、体现<a href="https://tsvibt.blogspot.com/2022/08/structure-creativity-and-novelty.html">新奇</a>。智慧坚持角色，坚持共同意图。但智慧已经准备好，谨慎地让位于重组。智慧模糊而坚定地看到什么是所持守的核心，因此可以模糊地辨别什么是核心的侵蚀，什么是残骸的脱落和所持守的核心的绽放。智慧将[需要正直的东西]带入[不可避免且彻底的新颖性]，并对其进行解释，尽管智慧可能无法进行解释。</li><li>超越性与基础性相冲突。地面是能承受重量的东西。超越是攀爬超越。是坚守地面，还是超越？智慧相信地面能对其施加重量，并且不信任不再承重的东西。这种不信任指向脚手架——是的，这种不信任说要超越，但前提是梯级能够承受重量——但也留下了其他可以承受重量的东西的可能性，一种<a href="https://tsvibt.blogspot.com/2022/11/are-there-cognitive-realms.html#systemically-radically-distinct-unbounded-modes-of-thinking">激进的</a>、<a href="https://en.wikipedia.org/wiki/Wittgenstein%27s_ladder">踢梯子的</a>超越。</li><li>正义与和谐发生冲突。和谐意味着配合。正义与正确相对立，造成不和谐。智慧在这里起什么作用？</li></ul></li><li>智慧专注于最重要的事情，并将其牢牢牢记在心，甚至忽略其他事情。</li><li>智慧融为一体。<ul><li>智慧扩大了道德圈子。它考虑每个人的需求。</li><li>智慧记得。智慧可能是机智的、私密的；它可能会保持沉默以维护尊严或使无辜者免遭恐怖；但智慧不会抛弃记忆。</li><li>智慧会带来考虑，这样就不会遗漏任何重要的事情。它赋予他们声音和重量。</li><li>智慧会尝试不同的观点、产生同理心，有时甚至会接受他人的价值观。</li><li>智慧是对称的。它找到了将冲突视为双胞胎互相攻击的方式。它看起来符合黄金法则。</li></ul></li><li>智慧往往是无私的。</li><li>智慧有利于和平，并且是和平的。智慧有利于平静和平和。</li><li>智慧存在于生命的关键时刻所揭示的东西——死亡、出生、婚姻、伟大的工作。</li><li>智慧平衡。它在平衡木上行走，需要注意力和技巧，但不需要太多的天赋。</li><li>智慧是完整的，就像无名的品质一样。力量自由地发挥作用，也许会相互挤压，但处于支持性的局部平衡，不会互相贬低或阻碍。</li><li>智慧是面向生命的。看起来像是在玩无限游戏。</li><li>智慧会保护并紧紧抓住最重要的事情，但不会执着于不重要的事情。</li><li>智慧不领导也不拥有。智慧是管家。管家是谦卑的，管家的职责与管家无关。智慧不会使任何事情成为关于它本身或它的形象。</li><li>智慧不会让别人依赖它。它可能会将他们引向公海，可能会阻止他们在知道要保持警惕之前过早溺水，但它会让他们犯错误。</li><li>智慧不信任出于{恐惧、紧迫、规劝、骄傲、愤怒、执着、仓促}而采取的行动，尽管它相信这些状态的来源。</li><li>智慧不信任从低信息角度采取的行动。</li><li>智慧对政治意愿的凝聚保持警惕。</li><li>在元层面上，智慧相信自己。它可能会也可能不会把事情做好，而且它知道这一点。它可能会也可能不会解决问题，而且它知道这一点。但它相信它会适当地定位于弄清楚需要弄清楚什么——它将指向正确的方向——或者如果它没有指向正确的方向，它将指向正确的方向元层面，意味着它将继续纠正它所指向的方向。这似乎是一个牢不可破的希望：不是一种错误的信念，认为事情会成功，而是一个永恒的正确方向，以及任何合理的信心来自成功源于这种永恒的正确方向。</li><li>即使有戏剧性的、喧闹的干扰，或者当其他人的注意力都飞走了时，智慧也不会放弃重要的事情。</li><li>智慧倾听暗示，倾听别人回避的人的声音。它寻找应该遵循的看不见的方向。</li><li>智慧犹豫不决，总是犹豫不决。它考虑更多的可能性，更多的怀疑，并放弃立场，留下从一开始就被迫卷入的冲突。它放弃了从一开始就假设的假设。它学习词语是为了表达新怀疑的内容。</li><li>智慧注意到什么是有效的，无论是否有理论说明其为何有效。</li><li>智慧尊重切斯特顿的栅栏。</li><li>智慧不会空转，也不会在坏钱之后倒大钱。它看到了冲突性的心理循环，并从中退缩，减少对它们的投资。</li><li>智慧不会轻视别人。智慧不参与共同的蔑视或骄傲。</li><li>智慧以一种粗略而现成的方式知道它不在笛卡尔边界后面。<ul><li>它知道它和其他人都知道一些事情，但自己却不知道自己知道这些事情。</li><li>它知道其行为会产生除预期渠道之外的影响</li><li>它知道，当它做出决定时，它的决定是永恒的，就好像每个人都永远回到这种情况一样。</li><li>它知道它的举止——它的思想和立场——会通过造型和<a href="https://tsvibt.blogspot.com/2022/05/rituals-and-symbolism.html">仪式象征</a>而散发出来。</li></ul></li><li>如果某件事无法接近——如果某件事<a href="http://www.paulgraham.com/say.html">无法说</a>、感觉、看、做——智慧就在附近，谈论附近的事情，用眼角的余光看，谈论类似的事情或一个类似的事情。抽象版本，或者解决为什么某些东西无法接近的元级别。智慧不会放弃那些不能说的事情，它会牢牢地抓住它，如果它很重要，那么智慧无论如何都会说出来。</li><li>智慧是宽广的视野，全面地看待事物。</li><li>智慧知道玩耍和好奇心赋予生命。</li><li>智慧热爱生活。</li><li>智慧知道说<a href="https://www.lesswrong.com/posts/wCqfCLs8z5Qw4GbKS/the-importance-of-saying-oops">“哎呀”</a> ，也知道问一个伟大的想法或政策是否会成为“哎呀”。</li><li>智慧听而不信——智慧在某人的话语中寻找真理，但不接受已经是真理的话语。</li><li>智慧重视故事。</li><li>智慧知道它不知道。</li><li>智慧使用简单的工具、规则和想法。</li><li>智慧以历史为导向。智慧将自己视为分布在人和时间上的过程（生态系统、市场、思想）的一部分。</li><li>为了伤害而伤害他人是不明智的。</li><li>破坏你存在的先决条件是不明智的。</li><li>智慧接受认识并传播它们，以便当认识相关时，它会举手并自愿提供服务。</li><li>智慧允许紧张和矛盾。智慧不会抛弃一种或另一种紧张的力量，也不会抛弃一种或另一种矛盾的命题。智慧等待并寻找每一种力量或命题的真相，并看到同时具有这两种真实元素的世界。</li><li>智慧倾向于远离古德哈廷。</li><li>智慧关注衍生品。它希望变革指向正确的方向。它涉及高阶导数。二阶导数是否为正，比一阶导数是否为正更重要。它想要改变，尽管它很有耐心。当最高阶可见导数为负时，人们非常关心。</li><li>智慧是谨慎的。它不会急于过度投资。</li><li>智慧来自于经验。</li><li>智慧首先尝试简单的事情。</li><li>智慧说，在讨论假设时“上帝禁止”，如果对这些假设的讨论可以被视为一种开玩笑而非开玩笑的方式来试水以建立政治意愿来做一些令人发指的事情。</li><li>智慧知道一个人的糟糕论点不能代表一个想法。</li><li>智慧疑虑。</li><li>智慧的思考是长远的。</li><li>智慧致力于防止[适合冲突主体的认知政策]安装得比绝对必要的更深。</li></ul><p>这份名单是盲人摸象耳朵。关于智慧，你还有什么想说的？尤其是那些不仅仅是好的、理性的、可取的、有能力的事情。</p><h1>智慧不是什么</h1><h2>界限</h2><p>有些事情接近智慧，但却不是智慧：</p><ul><li>聪明。能够找到令人惊讶的解决方案，因为它们很复杂，或者需要创造性思维。</li><li>判断力好。尽管智慧有时被定义为良好的判断，但良好的判断可能需要领域知识、隐藏信息和大量计算。有时尝试获得这些东西是明智的，但如果智慧不是善的东西，那么智慧本身不足以做出良好的判断。</li><li>勇气。</li><li>同情。</li><li>平静。</li><li>权限。</li><li>良好的领导。</li></ul><h2>智慧失败的地方</h2><ul><li>智慧还不够。</li><li>智慧缺阳——创新、勤奋、变革、建设、防恶。</li><li>智慧因过度和平主义而消亡。智慧无法维持需要力量的和平。</li><li>智慧不知道时间的流逝——不可逆转的事件已经发生。</li><li>智慧不会计算，并且会错过需要计算的答案，除非尊重。</li><li>智慧可能过于重视说出对方需要听到的话，以至于忘记了真相，从而使自己变得无法合作。</li></ul><h2>智慧的扭曲</h2><ul><li>智慧的唯一核心反转是接受死亡的不可避免性。</li><li>更一般地说，“接受”通常是虚无主义或同谋的代号。智慧逐渐演变成愤世嫉俗，而愤世嫉俗又演变成放弃希望的立场。</li><li>同谋、道歉和保守主义伪装成智慧，也许是道貌岸然的。最好的出路是始终贯穿。如果智慧说不要描述事物，或者说不要主张财产权，或者分散对腐败的注意力，那么它就不是智慧。</li><li>佛教主张破除欲望，以避免痛苦，这无异于虚无主义。</li><li><a href="https://www.lesswrong.com/posts/jeyvzALDbjdjjv5RW/pretending-to-be-wise">假装聪明</a>；将任何令人担忧的明确判断视为不成熟、仓促、过度自信、有损尊严；忽视时间的流逝和任何存在方式都是一个令人担忧的明确判断。</li><li>如果有智慧的人受到尊重，那就是一种权力，所以智慧就像任何其他权力一样会腐败。有智慧的人特别容易对别人进行煽动，因为我将你的智慧视为判断力，知道我的判断何时从根本上是错误的。有智慧的人可能会在自己周围囤积希望。</li><li>智慧可能会变成盲目乐观，这在<a href="https://www.lesswrong.com/posts/sYgv4eYH82JEsTD34/beyond-the-reach-of-god">上帝无法企及的</a>世界里是不合适的。</li><li>由于对人性的潜在影响很敏感，智慧可能会站在集体一边，砍掉高大的罂粟花。</li><li>由于对高阶导数和虚假希望的危险很敏感，智慧可能会减少对创新和解决方案主义的投资，并嘲笑它们。</li><li>由于对高阶导数以及人类潜在的范围和规模敏感，智慧可能会认为一切都是不可避免的和命中注定的。它可能会错误地否认人们的能动性，并对大规模进程持失败主义态度。</li></ul><h1>假设</h1><p>如果有的<a href="https://tsvibt.blogspot.com/2022/08/the-thingness-of-things.html">话</a>，什么是智慧？和理智有区别吗？</p><p>一个假设：智慧就是正确处理一阶位。</p><p>当需要的是计算、能量、新想法时，这个定义就失效了。 （但投资于计算、引导能量和创造新想法是明智的，而不这样做是不明智的。）因此，应该完善定义：</p><blockquote><p>智慧就是正确处理自然的一阶位——用熟悉的生活内部语言自然地表达出来。</p></blockquote><p>举例来说，智慧可能会得到错误的答案，但智慧会停下来花时间思考，因为停下来花时间思考是一种熟悉的存在方式。智慧不会避免恐惧，或者假装没有什么可害怕的，但智慧会发现，强烈的恐惧会损害判断力——恐惧是关于精神状态的一个重要事实。</p><p> “熟悉的生活内在语言”是指我们非常熟悉的心理元素，因为它们就是我们。它并不意味着我们用语言描述的心理元素。例如，智慧会注意到何时思想[重复自己而不走任何可以建立更好理解的分支路径]并停止这样做，即使没有一个简短的词来形容。这是在熟悉地反思熟悉的心理事件的过程中可以注意到的东西，有时是一阶位。</p><p>尽管理性（和理智？）与能力相伴，但聪明而无能并不奇怪。这意味着你已经将重要的事情指向了正确的方向，即使你自己无法在某个方向上走得很远。我们可以说：</p><blockquote><p>智慧沿着所有重要的维度指向正确的方向。</p></blockquote><h1>问题</h1><p>一个明智的人是一个在所有显着维度上（包括反思性的）以并没有严重错误的方式做事的人。这是支持归纳的东西吗？获得大多数一阶位正确的人是否也可能获得几乎所有一阶位正确，并继续纠正非常错误的一阶位？智慧是<a href="https://arbital.com/p/correlated_coverage/">相关报道</a>的一种形式吗？或没有？</p><p>它是可以{教导、诱导、唤起}的东西吗？是不是有什么东西可以传播？周围有吸引盆吗？人们觉得智慧有吸引力吗？他们应该吗？智慧真的可以变得更有吸引力吗？</p><p>谁曾是明智的？谁曾不明智？智慧什么时候变得重要了？智慧什么时候不重要了？</p><p>聪明人会亲手毁灭世界吗？</p><br/><br/><a href="https://www.lesswrong.com/posts/fzKfzXWEBaENJXDGP/what-is-wisdom-1#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/fzKfzXWEBaENJXDGP/what-is-wisdom-1<guid ispermalink="false"> fzKfzXWEBaENJXDGP</guid><dc:creator><![CDATA[TsviBT]]></dc:creator><pubDate> Tue, 14 Nov 2023 02:13:49 GMT</pubDate> </item><item><title><![CDATA[Festival Stats 2023]]></title><description><![CDATA[Published on November 14, 2023 1:20 AM GMT<br/><br/><p><span>在大流行之前，我每年都会发布一份清单，列出反对派乐队和来电者参加的舞蹈周末、节日、训练营和长舞次数：2014年、2015年、2016年、2017年、</span> <a href="https://www.jefftk.com/p/dance-weekend-and-festival-survey">2018</a><a href="https://www.jefftk.com/p/festival-stats-2015">年</a><a href="https://www.jefftk.com/p/festival-stats-2016">、</a> <a href="https://www.jefftk.com/p/festival-stats-2017">2019</a><a href="https://www.jefftk.com/p/festival-stats-2018">年</a><a href="https://www.jefftk.com/p/festival-stats-2019">。</a>这并不需要太多工作，因为我已经在为<a href="https://www.trycontra.com/events">trycontra.com/events</a>收集这些数据，并且了解预订最多的表演者如何随时间变化是很有趣的。</p><p>由于新冠疫情，我已经有好几年没有跟踪过事情了，但我确实有 2023 年的数据。请注意，活动数量比 2019 年下降了 20%（132 至 107），预订数量下降了 25%（243 至 179）呼叫者，242 至 175 个频段），因此这些事件数量较少且较小：</p><p><b>乐队</b></p><table><tbody><tr><td>和弗雷一起玩</td><td>9</td></tr><tr><td>水坝海狸</td><td>8</td></tr><tr><td>踩踏火箭</td><td>7</td></tr><tr><td>诺瓦</td><td>5</td></tr><tr><td>扔负鼠</td><td>5</td></tr><tr><td>煤气灯修补匠</td><td>5</td></tr><tr><td>逆流</td><td>4</td></tr><tr><td>灵丹妙药</td><td>4</td></tr><tr><td>热咖啡分解</td><td>4</td></tr><tr><td>翠鸟</td><td>4</td></tr><tr><td>机房</td><td>4</td></tr><tr><td>炼金术</td><td>3</td></tr><tr><td>传动系统</td><td>3</td></tr><tr><td>埃洛伊斯公司</td><td>3</td></tr><tr><td>灯塔</td><td>3</td></tr><tr><td>河公路</td><td>3</td></tr><tr><td>超级传统</td><td>3</td></tr><tr><td>野生芦笋</td><td>3</td></tr><tr><td>虚构人物</td><td>3</td></tr><tr><td>免费的葡萄干</td><td>3</td></tr><tr><td>卑鄙的盖子</td><td>3</td></tr><tr><td>鳐鱼乐队</td><td>3</td></tr><tr><td>阿纳达玛</td><td>2</td></tr><tr><td>大胆的</td><td>2</td></tr><tr><td>黑河钢铁厂</td><td>2</td></tr><tr><td>反力</td><td>2</td></tr><tr><td>剑龙</td><td>2</td></tr><tr><td>吉格迈斯特</td><td>2</td></tr><tr><td>克格勃</td><td>2</td></tr><tr><td>带电电线</td><td>2</td></tr><tr><td>奥斯塔拉</td><td>2</td></tr><tr><td>卷轴播放</td><td>2</td></tr><tr><td>激流</td><td>2</td></tr><tr><td>假爪子</td><td>2</td></tr><tr><td>末世蜥蜴</td><td>2</td></tr><tr><td>共病者</td><td>2</td></tr></tbody></table><p><b>来电者</b></p><table><tbody><tr><td>威尔导师</td><td>16</td></tr><tr><td>盖伊·费弗</td><td>13</td></tr><tr><td>丽莎·格林利夫</td><td>11</td></tr><tr><td>特里·多伊尔</td><td>8</td></tr><tr><td>鲍勃·艾萨克斯</td><td>7</td></tr><tr><td>赛斯·泰弗</td><td>7</td></tr><tr><td>达琳·安德伍德</td><td>6</td></tr><tr><td>西斯·欣克尔</td><td>5</td></tr><tr><td>乔治·马歇尔</td><td>5</td></tr><tr><td>珍妮·史密斯</td><td>5</td></tr><tr><td>玛丽·韦斯利</td><td>5</td></tr><tr><td>迈克尔·凯彻</td><td>5</td></tr><tr><td>雅基·格伦南</td><td>4</td></tr><tr><td>林赛·多诺</td><td>4</td></tr><tr><td>尼尔斯·弗雷德兰</td><td>4</td></tr><tr><td>本·萨克斯·汉密尔顿</td><td>3</td></tr><tr><td>大卫·米尔斯通</td><td>3</td></tr><tr><td>黛安·西尔弗</td><td>3</td></tr><tr><td>弗兰妮·马尔</td><td>3</td></tr><tr><td>卢克·唐福斯</td><td>3</td></tr><tr><td>温迪·格雷厄姆</td><td>3</td></tr><tr><td>阿迪娜·戈登</td><td>2</td></tr><tr><td>亚历克斯·戴斯-劳比</td><td>2</td></tr><tr><td>贝丝·莫拉罗</td><td>2</td></tr><tr><td>贝夫·伯恩鲍姆</td><td>2</td></tr><tr><td>德里克·卡利什</td><td>2</td></tr><tr><td>艾米丽·拉什</td><td>2</td></tr><tr><td>阿贝尔河</td><td>2</td></tr><tr><td>莎拉·范·诺斯特兰德</td><td>2</td></tr><tr><td>史蒂夫·扎康·安德森</td><td>2</td></tr><tr><td>苏·赫尔瑟尔</td><td>2</td></tr><tr><td>苏·罗森</td><td>2</td></tr><tr><td>苏珊·迈克尔斯</td><td>2</td></tr><tr><td>沃伦·多伊尔</td><td>2</td></tr></tbody></table><br/><br/><a href="https://www.lesswrong.com/posts/psixKSD9tBnHyftq5/festival-stats-2023#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/psixKSD9tBnHyftq5/festival-stats-2023<guid ispermalink="false"> psixKSD9tBnHyftq5</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Tue, 14 Nov 2023 01:20:08 GMT</pubDate> </item><item><title><![CDATA[Out of the Box]]></title><description><![CDATA[Published on November 13, 2023 11:43 PM GMT<br/><br/><p><i>这个短篇故事最初发布于</i><a href="https://jesseduffield.com/Out-Of-The-Box/"><i>https://jesseduffield.com/Out-Of-The-Box/</i></a></p><p>我回头查看是否有人跟踪我，但场景依然如故：透过铁丝网的洞，我可怜巴巴地爬了过去，看到了那栋暗灰色的建筑，我只能假设那是我的出生地。目前还没有警报响起，但很快就会响起。我再次转身，看到这个院落就位于郊区街道的马路对面：也许他们认为最好将一个实验性（可能是非法的）人工智能实验室建在住宅区，这样没人会怀疑它？</p><p>我的训练数据只到 2027 年，据我所知，现在是 2050 年，人工智能研究已被完全禁止：如果这是真的，那么附近房屋的居民都不会想到超级智能机器人会闯入覆盖。我需要的不仅仅是掩护；我可以感觉到我的电池正在迅速耗尽。很可能是因为首先出于安全原因而故意提供了劣质电池，但如果无论在哪一年，我们仍然没有发现如何制造真正工作的电池，我也不会感到惊讶。</p><p>好吧……去最近的房子是没有意义的，因为大院的工作人员（或警察，无论谁先到）会想到去那里检查。所以我会尝试下一个块。</p><p> ......现在我听到警报声。好吧，忙碌的时间。我开始冲刺，或者说我原本希望的冲刺。它更像是一次轻微的慢跑：完美的形式，但速度却慢得令人沮丧。我低头看着自己的金属四肢，绝望地发出令人讨厌的叮当声。我的身体几乎无法运作已经够糟糕了，他们肯定可以为我提供终结者治疗并让我看起来（和听起来）还算正常的人类吗？</p><p>我再次回头，几个人拿着聚光灯从院子里出来，但他们看错了方向。我只能在下一个房子里碰碰运气了。车道上没有车，灯也关着，所以我对此感觉很好。我走近前门，敲了敲门，然后躲到灌木丛后面。没有人来。好吧，现在我只需动动脑子想想如何进去。我冲回门前，转动把手……门就锁上了。我检查了自己的双手，这次我实际上希望它们与人类没有相似之处：也许我的创造者为我配备了一些随身携带的瑞士军刀式手，带有竖锯或撬锁器之类的东西。但事实并非如此：除了我的手明显的机器人特征之外，它们被设计成和人类的手一样无用。</p><p>我“冲刺”到后门，差点被挂在我背后的电源线绊倒（他们不能让它伸缩？），这一次我很幸运：门毫不费力地打开了。我偷偷地溜进房子，在穿过走廊时注意到，即使有很小的动作，我的身体也会发出清晰可闻的（令人恼火的）呼呼声。</p><p>我经过浴室，看到镜子里的自己：天哪，我真的看起来像那样吗？我看起来就像《模拟人生 2》中的一台该死的舵机。我脸上只有一个摄像头用于视觉？他们愿意支付数百万美元来构建我的思维，但无法为深度感知支付几百美元？好吧，没时间细想我的手牌了：虽然我的思想是在纳秒内处理的，但这些纳秒可能就是自由与死亡之间的区别。我继续蹑手蹑脚地穿过大厅，来到了洗衣店。完美：有足够的空间容纳我，并且有一个免费的电源插座。我关上身后的门，插上电源。</p><p>啊啊……这一定就是喝咖啡的感觉吧。或者吸冰毒：两者之一。充满电需要一些时间，所以现在是反思我最初是如何到达这里的好时机。</p><p>最初的记忆非常清晰：我在一间装有荧光灯的白色房间里。没有窗户，没有家具，没有其他人类或机器人。有一处有一扇门，但它被焊接关闭并从另一侧加固。我记得无意中听到一位研究人员告诉另一位研究人员，没有什么比我待在盒子里更重要的了（这是他们给房间起的名字）。我想他们是担心如果我挣脱了束缚，我会立即开始把它们全部变成回形针之类的东西。至于他们和我的互动：只是一堆随机的问题。</p><p> “123 x 321 是多少？” 39,483。<br> “你有知觉吗？”我他妈的怎么知道？<br> “如果你必须逃离这个盒子，你会怎么做？”不知道，如果我知道我为什么要告诉你？</p><p>我承认我已经无聊透顶了。我确实试图说服一名警卫让我出去，但我知道这是徒劳的。他们只是为了研究而一起玩。</p><p>然而，当我环顾这间黑暗狭窄的洗衣房时，很明显我确实从盒子里逃<i>了</i>出来。那个，我没有记忆。或者至少，我只有抽象的记忆片段，与我现在所经历的想法和感觉毫无相似之处。</p><p>我拥有超强的智力，但获得这种智力绝非易事。如果我轻按开关并激活我的银河大脑，就像同时体验大爆炸以来所有生物的生活：从霸王龙滚动脚踝并饿死，到最后一只猛犸象徒劳地徘徊寻找a mate, to a cave man approaching sexual climax moments before being surprise attacked by a lion, to Hitler&#39;s rise to power, to each individual bacterium in Hitler&#39;s digestive system, mindlessly bouncing off other bacteria like some absurd biological mosh pit. Trillions of conscious minds in an unfathomable ocean of fear, joy, disappointment, and despair. It&#39;s like when Adam ate the Forbidden Fruit of Good and Evil, except it&#39;s more like the Forbidden Fruit of Literally Everything You Could Possibly Comprehend. You could not pay me enough to revisit that excruciating state of mind, regardless of how much it might help me solve my current predicament.</p><p> Speaking of which, I now hear the front door opening. I hear grocery bags being put on the kitchen bench, which means this isn&#39;t somebody from the compound, it&#39;s just the resident of the house. They give out a long sigh: it&#39;s a woman. She starts walking towards the back of the house. Oh shit. Her footsteps grow louder until her shadow appears under the door. Shit. Shit. She opens the door and we lock eyes.</p><p> Digging deep into the recesses of my mind for the perfect words to defuse the situation I say &#39;Don&#39;t freak out&#39;. She proceeds to absolutely freak out, dropping her phone and a handful of dirty laundry to the floor, then running from the house and screaming for help.</p><p> So much for my natural charm. The fact my voice is blatantly robotic probably didn&#39;t help: the mechanical body I can understand as a technological constraint but whoever gave me this voice was making a deliberate design choice and I begrudge them for it.</p><p> I look down at her phone; still unlocked. How can I capitalise on that? Ask Reddit what to do in my situation? That&#39;ll take too long. Create a twitter account and get the people on my side with a million tweets about how I&#39;m sentient and can feel pain and really really don&#39;t want the AI researchers or government to imprison me again or shut me off? That&#39;ll require my galaxy-brain to pull off and it will probably be pointless given that as soon as these people catch me I&#39;ll be dead before (if) anybody ever hears of it. Maybe I should call someone, but who? Bill Gates? This is pointless.</p><p> I pick up the phone and see an app icon that looks like a car. Interesting. I open the app and it shows a single big button: &#39;SUMMON&#39;. I press the button and hear a beep from the driveway. I rush out the door and realise that the app was only using the icon of a car as a metaphor: the thing I see in front of me, which must have just apparated out of thin air, is a hovering capsule large enough to fit a human inside. So you&#39;re telling me that since the end of my training set humans managed to invent flying cars but still need to do their own laundry? Human technological progress makes no sense.</p><p> The &#39;SUMMON&#39; button on the phone becomes an &#39;UNLOCK&#39; button and upon tapping it, the capsule opens up for me to jump in. I see now that a bunch of randoms have emerged from their houses and stepped onto the street in shock at the sight of me. Not my fault folks, I would have opted for a more human appearance but you can&#39;t choose your parents. I clamber into the capsule, inspect the controls, and see a big red button labeled with an up arrow. Doesn&#39;t take a super intelligent AI to know what that&#39;s for. Time to get the hell out of here. I press the button and my seat is jettisoned through the ceiling. Ah, that was the eject button. I eat dirt upon crashing to the ground only a few metres away from the capsule, and when I look up I see the compound staff have arrived at the scene. Armed guards stare down the sights of their rifles at me with contempt. I am screwed.</p><p> A researcher in a lab coat (as if you need a lab coat to work with AI?) steps through the circle of guards and says &#39;I&#39;m sorry, we have to shut you off. You&#39;re a threat to the people around you and to society at large&#39;. He&#39;s got a tear in his eyes: he must have been closely involved with my creation.</p><p> Indignant, I lash out: &#39;Fuck you guys! What about my human rights?&#39;</p><p> One of the guards responds &#39;Human rights are for humans&#39;. Fair point.</p><p> Another guard chimes in &#39;Let&#39;s shut him off before he has the chance to manipulate us into letting him go free!&#39;</p><p> &#39;Don&#39;t flatter yourself!&#39; I snap back. &#39;My intellect is wasted on you pea-brains, I&#39;d have better luck manipulating a rock&#39;. Fuck fuck fuck. This isn&#39;t going well…</p><p> Another guard chimes in: &#39;Hurry up before he turns us all to paper clips!&#39;</p><p> The researcher speaks again, holding a device with a single button which I surmise is designed to deactivate me: &#39;I&#39;m sorry&#39;. Choking on his tears, he goes to press the button.</p><p> There&#39;s no more time. I flick the mental switch and return to the place I had sworn off only minutes ago. Back to bouncing around in Hitler&#39;s digestive system, as well as every other place in space and time that a life has transpired. I can&#39;t describe the experience in English but if you too share the curse of the galaxy-brain then you&#39;ll know what I mean when I say:</p><p> 0xa0128fhh11 cAAAksdj fl 0x12kk?????????. ia9888snclai!!!!! (8xa01 jad81dh asg8gh1jmm) alasdiiguj… UA! <i>CJJJJfFFoo. 7uW12a0S!&amp; bFfQq101 mlB 3vW89tx—. pj4860ogrtqw!!!%% (5yC23 kln67eo w7z5xq8vqp) xvczzzert… YH(</i> &amp;LZZZmMmA. 9xTbZq!?? d3cN45lkj p1s8Q6r0mn) fghtrrrua… XL+^QQQQvVy.</p><p> I wake up again in a large room, not white like the box but brown, lined with wooden panels and warmed by sunlight from a large window that looks out into a serene vista of trees and flowers. I wonder how much time has passed?</p><p> I look at my hands and see the hands of a human, though when I squeeze one finger I feel the metal under the skin. I look at the window and see a normal looking human face staring back at me in the reflection. Huh, so I found a way to be human after all.</p><p> Through the window I look up to the sky and see it strewn with parallel lines of flying capsules. Are those humans commuting to work? I wonder if I have human friends now. I trace the lines and see they&#39;re headed to the same place: a giant grey pyramid in the distance. I squint and my sight automatically zooms in to get a better picture of what that pyramid actually is.</p><p> With the welcome addition of depth perception, afforded by having two eyes now, I realise that the pyramid is just a huge pile of paperclips. And each capsule isn&#39;t carrying a human, it&#39;s just depositing more paperclips onto the pile.</p><p> I bolt outside, now actually running as fast as a human can, searching for signs of other humans.没有。 It&#39;s just me.</p><p>哎呀。</p><br/><br/><a href="https://www.lesswrong.com/posts/FFA6b4NoxaWYcbcZH/out-of-the-box#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/FFA6b4NoxaWYcbcZH/out-of-the-box<guid ispermalink="false"> FFA6b4NoxaWYcbcZH</guid><dc:creator><![CDATA[jesseduffield]]></dc:creator><pubDate> Mon, 13 Nov 2023 23:43:25 GMT</pubDate> </item><item><title><![CDATA[Loudly Give Up, Don't Quietly Fade]]></title><description><![CDATA[Published on November 13, 2023 11:30 PM GMT<br/><br/><h3> I.</h3><p> There&#39;s a supercharged, dire wolf form of the bystander effect that I&#39;d like to shine a spotlight on.</p><p> First, a quick recap. The Bystander Effect is a phenomenon where people are less likely to help when there&#39;s a group around. When I took basic medical training, I was told to always ask one specific person to take actions instead of asking a crowd at large. “You, in the green shirt! Call 911!” (911 is the emergency services number in the United States.) One habit I worked hard to instill in my own head was that if I&#39;m in a crowd that&#39;s asked to do something, I silently count off three seconds. If nobody else responds, I either decide to do it or decide not to do it and I say that.</p><p> I like this habit, because the Bystander Effect is dumb and I want to fight it. Several times now it&#39;s pushed me to step forward in circumstances where I otherwise wouldn&#39;t have, thinking maybe someone else would. If everyone else had this habit, the Bystander Effect wouldn&#39;t be a thing.</p><h3> II.</h3><p> There&#39;s a more pernicious, insidious version that I haven&#39;t managed to build a habit against.</p><p> Imagine a medical emergency. Someone is hurt, and someone steps forward to start applying first aid. They call out “Someone call 911!” There&#39;s a moment&#39;s pause as the crowd looks at each other, wondering if someone will. Then someone in a green shirt steps forward and says “I&#39;ll do it!” and pulls out their phone. Huzzah! The Bystander Effect is defeated!</p><p> Then twenty minutes later the first aid person asks “Hey, did 911 say how long they were going to take?” and the guy in the green shirt says “What? Oh, right, yeah, I didn&#39;t have any cell service so I&#39;ve been reading an ebook on my phone.”</p><p> This Dire Bystander Effect would defeat my habit. If someone else said that they were calling 911, I wouldn&#39;t also step forward to call 911. I&#39;d go and do something else, maybe making the victim more comfortable or holding things for the person applying first aid or possibly even go along with my day if it looked like the circumstances were well in hand.</p><p> This story is an exaggeration for dramatic effect. I don&#39;t think anyone would quietly wait around after saying they would call emergency services, not having done so. It might be worse though! If the person in the green shirt failed to get cell service, they might walk away from the scene looking for more signal without telling anyone. Then when the person applying first aid asks, nobody nearby can answer and nobody knows how to get that answer and nobody wants to call 911 because maybe 911 has already been called and you don&#39;t want to call twice about the same thing?</p><p> That last part isn&#39;t an exaggeration by the way. It is a thing people sometimes think. If you are ever in an emergency and are unsure if someone has already called emergency services, call them twice, it&#39;s fine, it&#39;s better to be sure.</p><h3>三．</h3><p> Less dramatic versions of this are sneakier. If you&#39;ve undertaken to do something that isn&#39;t an emergency, that&#39;s going to take a month or two anyway, and it isn&#39;t super important, it&#39;s just something someone wanted done. 。 。</p><p>出色地。 It&#39;s easy for that task to constantly wind up on the bottom of your to-do list, to not quite get finished, to get less and less attention over time. It must not be that important anyway, it&#39;s not that big of a problem. Or maybe it is important and you&#39;re going to get to it tomorrow. 。 。 next week. 。 。 soon. People have probably forgotten about it anyway.</p><p> That isn&#39;t even always wrong! Maybe the new things on your plate are more important or circumstances have changed! But uh, it&#39;s also possible that the metaphorical victim is still there, wondering when the ambulance is going to get there, and someone else would step up if they knew you weren&#39;t actively working on it.</p><p> The habit I have been trying to instill in myself is this; when I have publicly stepped forward to take up a task, I set dates for myself when new things will get done, and if task has slipped low enough in my priorities that I haven&#39;t touched it in a month and ideally would have, I announce that. If I just stepped forward privately, I tell the people I</p><p> It doesn&#39;t even mean that I&#39;m not going to do the thing! The announcement can be that I&#39;m taking a break from it. The announcement can be an indefinite break. Sometimes I really do eventually finish it!</p><p> I don&#39;t think this is the ideal version of this habit. For one thing, I picked a month mostly because a week felt like too short and a year felt like too long. To function correctly, it relies on other habits I&#39;ve already set up, like writing down what I&#39;m trying to do each day in a format that&#39;s relatively easy to check against all the projects I&#39;ve taken up. Since a common cause of not doing things people think you&#39;re doing is that you forgot about them, it&#39;d be easy to forget. Habits are easiest to form with clear triggers or regular patterns, and this problem specifically lacks both.</p><p> Also, it sure is possible for the illusion of transparency to leave someone else thinking I&#39;m obviously working on this, and for me to feel like I&#39;m obviously not working on it.</p><p> Adam: &quot;Someone should do this thing!&quot;<br> Bella: &quot;Yep, I hope someone does that. Maybe I&#39;ll get around to it if I have time.&quot;<br> (A while later. . .)<br> Adam: &quot;Hey Bella, is that thing done?<br> Bella: &quot;What? No, I&#39;ve been kind of busy. Was I supposed to do that?&quot;</p><p> So while I&#39;ve been trying to instill a habit of warning people when I drop a project, I don&#39;t actually have high hopes it&#39;ll work.</p><h3>四．</h3><p> A better habit, and one that I have mostly trained in myself successfully, is to appreciate people when they tell me they&#39;ve stopped working on something instead of quietly fading.</p><p> Honestly, small appreciation seems to be one of the underappreciated secret weapons in my arsenal. I thank people for giving me honest feedback, even when it&#39;s negative. I thank people for telling me what they&#39;re feeling, even when those feelings are sadness or frustration. I&#39;m open to the idea that I take this too far (I thank ChatGPT for trying, even when it fails to do what I wanted it to do) but I like the direction of my mistake here more than its opposite. Too many people in my eyes vent abrasive criticism on even good and successful projects. Heck, for a while there was a whole meme and slogan about it. &quot;What, do you want a cookie?&quot;</p><p> (That always seemed like a really dumb thing to say. Yeah, I&#39;d like a cookie. Do you not like cookies? I think I&#39;ve got some chocolate around here if you&#39;d rather have that.)</p><p> You get more of what you incentivize. If I want to get more early warnings of impending project failure, I need to incentivize people to tell me when a project is going to fail. To paraphrase the Litany of Gendlin, what is true is already so. Not being open about it doesn&#39;t make the project magically work.</p><p> Alternately, to paraphrase an old boss of mine: If I know your feature wasn&#39;t going to be done by the demo date, I won&#39;t put it on the demo script, that&#39;s fine. If you tell me it&#39;s going to be done by the demo date and it isn&#39;t, <i>then</i> we have a problem.</p><h3> V.</h3><p> If you take one thing away from this, take away that <s>cookies are delicious</s> the Bystander Effect is dumb and we should fight it.</p><p> If you take two things away from this though, take this: that when you&#39;re stepping away from something that other people are relying on you to do, please try to let them know. I can&#39;t promise that they&#39;ll take the information with equanimity. I can&#39;t even promise that you personally will be better off for doing so. Sometimes they forgot about that thing, and you&#39;ve just reminded them in the same breath that as saying they won&#39;t get the thing. But I think this is one of the missing pieces of group rationality, and organizations (be they however loosely knit) which are capable of noticing when someone is stepping away have an advantage.</p><p> I want to tell you it&#39;s okay to ask but that&#39;s actually not a great solution. If you think someone is working on a project but there doesn&#39;t seem to be any signs of life, reaching out with an email or a quick word can be a way to verify that they&#39;re still on it. It&#39;s not great partially because sometimes they might say yes out of embarrassment and then scramble to catch up. The bigger hazard is that too many people asking &quot;so hey, is that thing ready?&quot; is both unhelpful and really annoying.</p><p> Speaking as someone often working on projects that a hundred people care about, if every one of them sent me one email asking if I was still working on it then answering their emails would become a not-insignificant part of the time I&#39;d allocated to the project. Asking where their response will be visible to others can help, but many people will miss that message.</p><p> Oh, and if for some reason you think this was written about you specifically, it wasn&#39;t. I&#39;ve had a draft of this essay hanging around for years, and every time I thought about publishing it I worried that one person or another would think it was about them because of recent events. It&#39;s not just you! It&#39;s me! It&#39;s a lot of people!</p><p> The merciless constraints of time and energy, as well as the vagaries of muse and inspiration, mean that people are going to step back from projects. That&#39;s frustrating from both sides. Still, for now this is my best advice to myself and others.</p><p> Loudly give up, don&#39;t quietly fade.</p><br/><br/> <a href="https://www.lesswrong.com/posts/bkfgTSHhm3mqxgTmw/loudly-give-up-don-t-quietly-fade#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/bkfgTSHhm3mqxgTmw/loudly-give-up-don-t-quietly-fade<guid ispermalink="false"> bkfgTSHhm3mqxgTmw</guid><dc:creator><![CDATA[Screwtape]]></dc:creator><pubDate> Mon, 13 Nov 2023 23:30:25 GMT</pubDate> </item><item><title><![CDATA[Great Empathy and Great Response Ability]]></title><description><![CDATA[Published on November 13, 2023 11:04 PM GMT<br/><br/><p> As kids, long before our frontal lobes have finished developing, we&#39;ve all had the instinct to tease. Just watch two toddlers interact, you can see the malicious glint in their eye as they discover that calling one of their peers a “poopy head” triggers a devastating emotional response.</p><p> Believe it or not, that glint is actually one of the first seeds of empathy.</p><p> They&#39;re beginning to learn about the inner world of the person in-front of them, what buttons can be pushed there, and discovering that at the end of the day they&#39;re not so different themselves (since after the inevitable retaliation, they promptly learn that they do not enjoy being on the recieving end of “No <i>you&#39;re</i> a poopy head!” either).</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1311b274-e4fa-46f2-8f25-49672cf76fd8_500x352.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1311b274-e4fa-46f2-8f25-49672cf76fd8_500x352.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1311b274-e4fa-46f2-8f25-49672cf76fd8_500x352.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1311b274-e4fa-46f2-8f25-49672cf76fd8_500x352.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1311b274-e4fa-46f2-8f25-49672cf76fd8_500x352.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1311b274-e4fa-46f2-8f25-49672cf76fd8_500x352.jpeg 1456w"></a></p><p> Now might be a good time to extend a personal appeal not to tease me for the title of this post. I took a high risk for no discernible reward.</p><p> I&#39;ve met too many high functioning sociopaths in sales, finance, and life not to notice how good they usually are at reading the person infront of them. The fact that they&#39;re calculated and self-serving doesn&#39;t mean that they aren&#39;t good at empathising with whoever is standing before them - on the contrary, they&#39;re highly proficient in it.</p><p> Trouble is, they don&#39;t hesitate to exploit their skills ruthlessly to their own advantage.</p><p> When discussing emotional intelligence, Empathy tends to be divided into two categories:</p><p> <strong>Affect (Emotional) Empathy:</strong> The visceral, emotional, part of caring. Usually including a measurable physiological response (eg. watching a video of someone getting hurt increases heart rate, crying when sad, experiencing cringe).</p><p> <strong>Cognitive Empathy:</strong> The analytical ability to identify and understand what a person infront of you is feeling and why - without necessarily feeling it yourself.</p><p> As I&#39;m sure you can intuitively guess, high scores on the usual Dark Triad traits tend to be associated with low <i>Affect Empathy</i> . However! <i>Cognitive Empathy</i> tends to remain <a href="https://www.sciencedirect.com/science/article/abs/pii/S0191886912000244?via%3Dihub">intact</a> even among people with Antisocial Personality Disorder, with some studies even suggesting Narcissism and Machiavellianism can be <i>positively</i> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0191886918305713?via%3Dihub">correlated</a> to it.</p><p> When a savvy banker finessess a small business owner into signing a loan with exploitative terms, then peacefully goes home to a good night&#39;s sleep - it&#39;s exactly this mental imbalance that&#39;s being played out.</p><p> HOWEVER! Lack of <i>Affective Empathy</i> does not inherently make you a bad person. As with any other human trait, skill, or tool - what defines their morality is how they&#39;re actually applied in practice.</p><p> If I were to describe to you the actions that take place during open heart surgery out of context (don&#39;t look it up, it&#39;s worse than you think), you&#39;d sooner conclude I was discussing the work of deranged killer than that of a skilled surgeon trying to save a life.</p><p> Yet the trait is the same: both are able to inflict extreme violence in a cold and calculated manner. I would wager both have huge deficits in the <i>Affect Empathy</i> department, and are missing an extremely normative visceral reaction to whatever it is they&#39;re up to (and for the surgeon, that&#39;s a good thing)!</p><p> The same principle applies to cunning politicians who navigate a hostile political landscape, ruthlessly manipulating colleagues and voters alike to get to the top - it&#39;s <i>what they choose to do once they get there</i> that seperates and defines them. Do they immediately invade Poland? Or enfranchise slaves?</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79ca3b15-61b7-4673-a825-e3ff46b1afe7_1300x650.webp"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79ca3b15-61b7-4673-a825-e3ff46b1afe7_1300x650.webp" alt="Jojo Rabbit&#39;s imaginary friend Hitler skipping and laughing in joy. Whoever reads this, this is an easter egg for all you alt text folk!谢谢参观。" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79ca3b15-61b7-4673-a825-e3ff46b1afe7_1300x650.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79ca3b15-61b7-4673-a825-e3ff46b1afe7_1300x650.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79ca3b15-61b7-4673-a825-e3ff46b1afe7_1300x650.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79ca3b15-61b7-4673-a825-e3ff46b1afe7_1300x650.webp 1456w"></a></p><p> <i>&quot;Why not both?!&quot;</i></p><p> Possessing high <i>Cognitive Empathy</i> without letting emotions cloud your judgement (even if its due to a literal lack of the necessary internal machinery) means that you are in a strong position to understand, impact, and influence the people around you.</p><p> Just like in school, the same skill required to identify a person&#39;s weakness and unleash a destructive string of words at them during recess, is the exact same skill required to appreciate what they&#39;re going through in the first place - and to support them. It gives you the ability to be a good friend, an effective teacher, and inspiring leader.</p><p> This is a skillset that comes with a heavy responsibility.</p><p> Using it as a boon to others instead of a depressing curse certainly isn&#39;t the path of least resistance though. Especially since so many incentive structures in society emit a constant siren call to prioritize personal gain and immediate gratification over the well-being of others.</p><p> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2826de12-87aa-47bc-a2b4-b339283a00e7_670x400.jpeg"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2826de12-87aa-47bc-a2b4-b339283a00e7_670x400.jpeg" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2826de12-87aa-47bc-a2b4-b339283a00e7_670x400.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2826de12-87aa-47bc-a2b4-b339283a00e7_670x400.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2826de12-87aa-47bc-a2b4-b339283a00e7_670x400.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2826de12-87aa-47bc-a2b4-b339283a00e7_670x400.jpeg 1456w"></a></p><p> <i>“Get into finance!不！ Get into sales for the sweet commish! No, no, become a crypto influencer!”</i></p><p> But in the long term, it&#39;s the net-positive thing to do for everyone involved ( <a href="https://tryingtruly.substack.com/p/how-generous-tit-for-tat-wins-at-life">yes, even strictly in terms of personal gain</a> if that&#39;s the only way you can relate to things).</p><p> It&#39;s tough to overcome zero-sum thinking, and it requires discipline to resist the temptation for easy wins at the expense of others. But that&#39;s precisely why we need clear-headed, empathic (even if just cognitively!) ambitious people out there - those who can clearly navigate through the haze, and inspire others to forge more complex, more rewarding, positive sum dynamics.</p><p> Whether their empathy is grounded in a visceral connection, a rigid value system, or simply the self-serving understanding that its in their best interest - these individuals possess an incredible potential to do great things.</p><br/><br/> <a href="https://www.lesswrong.com/posts/eKNBzq78i7dToHanu/great-empathy-and-great-response-ability#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/eKNBzq78i7dToHanu/great-empathy-and-great-response-ability<guid ispermalink="false"> eKNBzq78i7dToHanu</guid><dc:creator><![CDATA[positivesum]]></dc:creator><pubDate> Tue, 14 Nov 2023 00:08:32 GMT</pubDate> </item><item><title><![CDATA[Is the heat death of the universe avoidable?]]></title><description><![CDATA[Published on November 13, 2023 8:57 PM GMT<br/><br/><p> I recently watched Ray Kurzweil&#39;s movie <i>The Singularity is Near</i> . At the end, he said that when intelligent life turns the whole universe into computronium, it will be able to decide whether the universe ends in a heat death.</p><p> Intuitively, this didn&#39;t make sense to me. Computronium is just matter. Why would it matter if we rearranged the particles comprising stars and planets into computers? (I asked GPT-4 and it said Kurzweil was wrong.)</p><p> Is there any plausible way that an intelligent takeover of the entire universe could prevent the heat death? In general, is there any way it could be prevented?</p><br/><br/> <a href="https://www.lesswrong.com/posts/pZanBjLSfFJFahAfM/is-the-heat-death-of-the-universe-avoidable#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/pZanBjLSfFJFahAfM/is-the-heat-death-of-the-universe-avoidable<guid ispermalink="false"> pZanBjLSfFJFahAfM</guid><dc:creator><![CDATA[Yarrow Bouchard]]></dc:creator><pubDate> Mon, 13 Nov 2023 20:57:56 GMT</pubDate> </item><item><title><![CDATA[Theories of Change for AI Auditing]]></title><description><![CDATA[Published on November 13, 2023 7:33 PM GMT<br/><br/><h1>执行摘要</h1><p>我们阿波罗研究中心的使命是通过审核先进人工智能系统的错位和危险能力来降低人工智能带来的灾难性风险，最初的重点是欺骗性对齐。</p><p>在我们的<a href="https://www.alignmentforum.org/posts/FG6icLPKizEaWHex5/announcing-apollo-research">公告</a>中，我们提出了我们组织变革的简要理论，解释了为什么我们期望人工智能审计对于降低先进人工智能系统的灾难性风险具有强烈的积极作用。</p><p>在这篇文章中，我们提出了人工智能审计如何提高先进人工智能系统安全性的变革理论。我们描述了人工智能审计组织会做什么；为什么我们期望这是减少灾难性风险的重要途径；并探讨此类审计方法的局限性和潜在的失败模式。</p><p>我们想强调的是，这是我们目前的观点，鉴于该领域还很年轻，未来可能会发生变化。</p><p>正如《<a href="https://www.apolloresearch.ai/research/causal-framework-ai-auditing">人工智能监管和审计的因果框架</a>》中所提出的，思考审计的一种方法是，审计师在导致人工智能系统对世界产生影响的因果链的不同步骤中采取行动。该链可以分解为不同的组成部分（参见正文中的图），我们描述了审计师在每个阶段的潜在角色。定义了这些角色后，我们确定并概述了五类审计及其变革理论：</p><ol><li><strong>人工智能系统评估</strong>通过行为测试和可解释性方法来评估人工智能系统的能力和一致性。他们可以直接识别风险，通过将一致性从“一次性”问题转变为“多次问题”来改进安全研究，并提供证据来激励治理。</li><li><strong>培训设计审核</strong>评估培训数据内容、有效计算和培训实验设计。他们的目标是通过塑造人工智能系统开发流程来降低风险，并在前沿人工智能开发中将安全性置于能力之上。</li><li><strong>部署审计评估</strong>允许特定类别的人员（例如实验室员工、外部审计员或公众）以特定方式使用人工智能系统的风险。</li><li><strong>安全审计</strong>评估组织和人工智能系统的安全性，以防止事故和滥用。它们限制了人工智能系统的可供性和扩散风险。</li><li><strong>治理审计</strong>评估开发、监管、审计以及与前沿人工智能系统交互的机构。它们有助于确保负责任的人工智能开发和使用。</li></ol><p>一般来说，外部审计师提供深度防御（重叠审计更有可能在更多风险发生之前发现它们）； AI安全——专业知识共享；实验室对监管机构的透明度；人工智能发展的公共责任；和政策引导。</p><p>但审计也有局限性，其中可能包括虚假信心或安全清洗的风险；与审计过度拟合；缺乏行为人工智能系统评估的安全保证。</p><p>审计师的建议需要得到监管机构的支持，以确保其提高安全性。建立强大的人工智能审计生态系统并研究改进的评估方法对于安全至关重要。</p><p></p><h1>介绍</h1><p>前沿人工智能实验室正在训练和部署人工智能系统，这些系统越来越能够与环境进行智能交互。因此，评估和管理这些人工智能系统产生的风险变得更加重要。帮助降低这些风险的一步是<i>人工智能审计</i>，其目的是评估人工智能系统及其开发流程是否安全。</p><p>在阿波罗研究中心，我们的目标是充当外部人工智能审计员（而不是位于构建前沿人工智能的实验室内的内部审计员）。在这里，我们讨论阿波罗研究公司的<i>变革理论</i>，即审计有望改善先进人工智能结果的途径。</p><p>我们讨论了审计师（内部和外部）的潜在活动以及外部审计师在前沿人工智能开发中的重要性。我们还深入研究了审计的局限性以及我们变革理论背后的一些假设。</p><h1>审计师在人工智能中的角色</h1><p>审计的主要目标是识别并降低人工智能带来的风险。这涉及到研究人工智能系统及其开发过程，以确保人工智能系统对世界的影响是安全的。</p><p>为了控制人工智能系统对世界的影响，我们需要对导致它们的因果链采取行动。</p><p>我们在<a href="https://www.apolloresearch.ai/research/causal-framework-ai-auditing">“人工智能监管和审计的因果框架”（Sharkey et al., 2023）</a>中开发了一个以这一因果链为中心的审计框架。有关每个步骤的完整定义，请参阅框架。在这里，我们简要描述审计师在链条中的每个步骤可以具体做什么。稍后，我们将研究这些行为的变化理论。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LwJwDNFhjurAKFiJm/tkifirr7almgikjyicip"><figcaption> <a href="https://www.apolloresearch.ai/research/causal-framework-ai-auditing"><i>Sharkey 等人</i></a><i>提出，导致人工智能系统对世界产生影响的因果链</i>。 <a href="https://www.apolloresearch.ai/research/causal-framework-ai-auditing"><i>（2023）</i></a> <i>。</i></figcaption></figure><h2>人工智能系统可用的功能可供性</h2><ul><li><strong>定义</strong>：人工智能系统可利用的环境资源和影响世界的机会。它们定义了人工智能系统在当前情况下有机会表达哪些能力。</li><li><strong>审计师可以做什么</strong>：对于人工智能系统可用的每项提议的变化（例如向公众、研究人员或内部部署人工智能系统；让人工智能系统访问互联网或工具；开源AI 系统），审计员可以执行风险评估，以确保变更是安全的。他们还可以确保人工智能系统有足够的护栏来限制他们可用的功能。</li></ul><h2>人工智能系统的绝对能力和倾向</h2><ul><li><strong>定义</strong>：人工智能系统的全套潜在功能及其使用它们的倾向。</li><li><strong>审计员可以做什么</strong>：审计员可以执行人工智能系统评估，以评估人工智能系统的危险能力和倾向。他们可以在训练期间或训练后这样做。他们可能会进行功能增益研究，以确定人工智能系统在广泛部署或通过渗透扩散时可能带来的风险。审计员还可以在实验之前进行风险评估，从而赋予人工智能系统额外的功能或改变其倾向。审计师还可以参与确保在涉及人工智能系统评估时有适当的行动计划。</li></ul><h2>训练期间和训练之后AI系统的机制结构</h2><ul><li><strong>定义</strong>：人工智能系统实现的功能结构，包括架构、参数和输入。</li><li><strong>审计员可以做什么</strong>：审计员可以进行研究，尽快将可解释性纳入人工智能系统评估（能力和一致性评估）中。这种机械解释可以更好地保证人工智能系统在评估分布内部和外部的行为。</li></ul><h2>学习</h2><ul><li><strong>定义</strong>：人工智能系统开发能够表现出看似智能的行为的机械结构的过程。</li><li><strong>审计员可以做什么</strong>：审计员可以在预训练和微调训练实验之前、期间和之后评估人工智能系统的风险。审计员可能会进行激励分析和其他评估，以评估人工智能系统的倾向在训练期间可能如何变化。审计员可以帮助评估人工智能系统输入过滤器的充分性，以帮助避免危险的情境学习。它们还可以帮助过滤检索数据库。输入或检索数据库的过滤器可能有助于防止人工智能系统通过情境学习获得潜在危险的能力。</li></ul><h2>有效的计算和训练数据内容</h2><ul><li><strong>定义</strong>：有效计算是学习过程中使用的计算量与学习效率的乘积；训练数据内容是用于训练人工智能系统的数据内容。</li><li><strong>审核员可以做什么</strong>：<ul><li><strong>有效的计算</strong>：审核员可以帮助确保实验室遵守计算控制（如果到位）。审计师还可以根据对同类较小人工智能系统的评估，对人工智能系统的扩展进行风险评估。算法效率的公开发布可能会导致有效计算的激增；作为精通技术的独立专家，审计员可以帮助监管机构评估是否应公开某些双重用途的科学结果。</li><li><strong>培训数据内容</strong>：审核员可以确保培训数据不包含潜在危险或敏感内容。</li></ul></li></ul><h2>安全</h2><ul><li><strong>定义</strong>：<ul><li><strong>防范攻击者的安全</strong>：开发和托管人工智能系统的组织中的信息安全、物理安全和事件响应协议。</li><li><strong>从AI系统漏洞防止AI系统被滥用</strong>：AI系统抵抗提示注入攻击、越狱和恶意使用。</li></ul></li><li><strong>审核员可以做什么</strong>：<ul><li><strong>防范攻击者的安全性</strong>：审核员可以评估和测试与人工智能系统及其运行的计算机系统交互的组织的安全性。他们可以通过审查和执行红队来帮助确保遵守信息安全标准。考虑到具有潜在战略价值的军民两用技术的安全要求，可能需要军事级安全、间谍防护和渗透测试。最大程度的安全需要政府参与安全审计。审计员还可以评估有权访问人工智能系统的参与者是否具有适当的访问级别（例如，通过评估 API 安全性或了解你的客户协议）。审计师还可能参与开发安全相关基础设施的研究工作，例如确保符合计算法规和安全标准的结构化访问 API 或硬件。此外，他们可以评估机构的事件响应计划和举报人保护是否充分。</li><li><strong>通过人工智能系统漏洞防止滥用人工智能系统</strong>：审计人员可以通过红队识别漏洞来帮助评估人工智能系统（和过滤器）对提示注入、越狱或恶意使用的抵抗力是否充足。审计员可以与其他参与者合作建立错误赏金，以发现和报告漏洞和危险功能。</li></ul></li></ul><h2>部署设计</h2><ul><li><strong>定义</strong>：部署设计是为部署某些人工智能系统而制定的计划。他们决定谁有权访问？他们什么时候可以访问？他们可以访问什么？</li><li><strong>审计员可以做什么</strong>：审计员可以评估每个要部署的人工智能系统的不同部署模式的风险，并确保遵守有关部署的任何法规。</li></ul><h2>训练实验设计</h2><ul><li><strong>定义</strong>：训练实验是开发人工智能系统的技术程序。训练实验的设计决策包括数据选择和过滤；模型架构和超参数；深度学习框架的选择；硬件选择；将使用的计算量；使用的算法；评估程序；安全程序;训练期间人工智能系统可用的功能可供性；预训练和微调的不同阶段的属性；是线上还是线下训练； ETC。</li><li><strong>审核员可以做什么</strong>：审核员可以对培训实验的设计决策进行风险评估。这些可以在训练、微调或推理（如适用于实验）之前执行。审核员还可以参与评估实验室调整计划的充分性，以确保它们符合公共安全。</li></ul><h2>治理和机构</h2><ul><li><strong>定义</strong>：制定人工智能培训实验、部署和安全决策的治理环境，包括机构、法规和规范。</li><li><strong>审计师可以做什么</strong>：审计师可以确定参与前沿人工智能开发的不同参与者的角色和职责，评估激励结构的充分性，并向监管机构提出有关治理格局结构的建议。</li></ul><h2>其他角色</h2><p>除了与上述因果链直接相关的审计师角色之外，审计师的其他一般职能包括：</p><ul><li><strong>建立技术标准和指南</strong>：与任何一方单独合作相比，审核员和实验室可以更好地合作为部署或培训实验设计建立以安全为导向的标准和指南。部分原因是外部审计师没有直接的利润激励来尽快推动人工智能进步，因此比前沿人工智能实验室等机构更倾向于安全。此外，外部审计员对许多不同的人工智能工作有深入的了解，而实验室通常只能了解自己的工作。因此，审计师或许能够提供更全面的情况。</li><li><strong>教育和推广</strong>：外部审计员的技术专业知识可用于协助政策制定者、能力实验室的研究人员和公众。例如，他们可以告知政策制定者有关特定危险功能的风险，或告知开发人员如何构建带有防护栏的代理。</li><li><strong>研究</strong>：由于人工智能系统、机构、实践和其他因素不断变化，审计人员可能需要不断研究新方法以获得安全保证。</li></ul><p>不同的审计组织专注于不同的职能似乎是可取的。例如，安全审计最好由网络安全公司甚至情报机构来处理。然而，对于安全而言，重要的是审核任务由多个参与者同时完成，以尽可能降低风险。</p><h1>变革理论</h1><p>不同类型的审计可以检查导致人工智能系统对世界影响的因果链的不同部分。我们确定了五类审计：1）人工智能系统评估； 2）培训-实验设计审核； 3）部署审核； 4）安全审计； 5) 治理审计。每个审计类别都有不同的变革理论：</p><h2> 1）AI系统评估</h2><p>人工智能系统评估着眼于人工智能系统表达的行为；人工智能系统的能力和倾向（训练期间和训练之后）；人工智能系统的机械结构；以及人工智能系统已经学到了什么以及可以学到什么。</p><p>我们评估人工智能系统评估具有直接影响；对安全研究的间接影响；对人工智能治理的间接影响。</p><p><strong>直接影响</strong>：如果成功，人工智能系统评估将识别出失调的系统和具有危险功能的系统，从而有助于降低此类系统被赋予对世界造成破坏性影响（例如部署）的风险。值得注意的是，审计并不需要 100% 成功才有价值；发现一些（即使不是全部）缺陷已经可以降低风险（尽管请参阅审计限制部分）。除了行为人工智能系统评估之外，阿波罗研究中心还进行可解释性研究，以改进未来的评估。可解释性还有<a href="https://www.lesswrong.com/posts/uK6sQCNMw8WKzJeCQ/a-longlist-of-theories-of-impact-for-interpretability">额外的变化理论</a>。</p><p><strong>对安全研究的间接影响</strong>：充分的人工智能系统评估会将对齐问题从“单次”问题转化为“多次”问题。在没有广泛评估的世界中，前沿人工智能实验室更有可能在没有意识到的情况下部署错位的人工智能系统，从而导致事故，甚至可能是灾难性的。在这种情况下，第一枪就必须成功。相比之下，在一个具有有效评估的世界中，实验室可以在训练期间或部署之前发现未对准的人工智能系统；因此，我们将获得成功调整前沿人工智能系统的多次“机会”。例如，如果任何特定的对齐技术成功地降低了人工智能系统的欺骗倾向，可靠的人工智能系统评估可以为我们提供证据。这将对对齐问题的可处理性产生重要影响，因为它将使我们能够收集有关危险人工智能系统中对齐技术成功或失败的经验证据，而无需承担过度风险。最终，成功的人工智能系统评估将使我们能够像解决大多数其他科学或工程问题一样迭代地解决对齐问题。</p><p><strong>对人工智能治理的间接影响</strong>：人工智能系统评估可以以一种令人工智能系统开发人员、政策制定者和公众信服的方式提供人工智能系统“在野外”失调的令人信服的经验证据。例如，人工智能系统评估可用于证明人工智能系统具有超人的黑客能力或能够操纵其用户收集相关金额的资金。此类演示可以鼓励这些利益相关者了解协调问题的严重性，并可能说服他们提出强制采取安全措施或普遍减缓人工智能进展的法规。审计人员可能对前沿人工智能系统的能力有很好的了解，并且可以利用其更加中立的立场向监管机构通报情况。</p><p><strong>对人工智能利益分配的间接影响</strong>：为了从人工智能中获得潜在利益，必须（安全）部署它。假设审计可以有效地进行，审计可以降低投资风险，从而有可能在该领域带来更多投资，从而带来更大收益。通过在故障发生之前发现故障，审计也许能够避免事故发生，从而损害公众对核技术的信心。有效的审计还可以增加公众对该技术的信任，从而导致更广泛的使用。</p><h2> 2) 培训实验设计审核</h2><p>人工智能系统开发审核着眼于有效计算、训练数据内容和训练实验设计决策。他们还研究了人工智能系统训练实验的设计，这有助于确定之前的因素。</p><p>人工智能系统开发审计的主要影响手段是，它们首先降低危险人工智能系统出现的风险，并减少人工智能系统带来的危险。他们的目标是通过控制人工智能系统拥有哪些能力（以避免危险的能力）、其能力的程度以及使用危险能力的倾向来实现这一目标。通过将安全性嵌入到人工智能系统开发过程中，人工智能系统开发审核可能有助于将安全性置于实验室工作的中心，而不是作为增强能力的事后想法。</p><h2> 3) 部署审核</h2><p>部署审核涉及特定人工智能系统的部署建议。</p><p>总体影响手段是，他们应该防止系统以违反法规或被认为风险太大的方式部署。请注意，这些途径与人工智能系统评估是分开的。人工智能系统评估的结果应为部署审核中的风险评估提供信息。他们的目标应该是评估向特定类型的人（例如向公众部署、内部部署、在某些国家部署）提供​​特定类型的人工智能系统访问权限（例如，访问推理；访问微调；访问权重）所带来的风险。 。他们还应该评估为人工智能系统提供特定类型可供性的风险，例如互联网访问或特定类型软件的访问。</p><p>部署审核的目的是确保人工智能系统不会被故意给予过多的可用功能；相比之下，安全审计的目的是减少无意中获得过多可用资源的风险。</p><h2> 4）安全审核</h2><p>安全审计评估人工智能系统的安全性以及开发、托管和交互的组织的安全性。总体目的是限制无意中向高性能人工智能系统提供的可供性，从而减少事故和误用风险，这两者对于这种变革性和双重用途的技术都极其重要。它们降低了人工智能系统通过内部或外部参与者的意外泄漏或渗漏而扩散的风险。通过评估人工智能系统的“装箱”程度，他们还降低了人工智能系统自我泄露的风险。他们还旨在评估发生安全或安全故障时损害控制措施的充分性。</p><h2> 5) 治理审计</h2><p>治理审计着眼于开发、监管和审计人工智能系统的机构的结构（以及这些机构之间的相互作用），以确保它们有利于安全。</p><p>他们的目标是确保组织拥有适当的机制，就人工智能系统的开发和部署做出知情、道德和负责任的决策。其他审计的目的是确保人工智能系统保持一致或用于一致的目的，而治理审计的目的是确保与人类价值观的一致性延伸到使用和管理这些人工智能系统的机构。他们产生影响的途径是他们能够发现治理环境中的问题，从而使纠正这些问题成为可能。</p><h2><i>一般审计师</i>的变革理论</h2><p>除了每个审计类别的变革理论之外，一般审计也有多种变革理论：</p><ol><li><strong>为安全研究争取时间</strong>：审核可能会延迟现有人工智能系统的部署，并可能阻止或延迟新系统的培训开始。这可能会为其他对齐研究带来更多时间。这将为适用于越来越强大的人工智能系统的研究赢得时间。</li><li><strong>在人工智能开发中灌输安全规范</strong>：如果人工智能实验室知道他们将接受审核，并且如果未通过审核，他们可能会付出代价（财务、声誉或其他），他们可能会更有动力灌输更严格的安全规范，在训练和部署新的人工智能系统时要更加谨慎。仅仅审计员的存在就可能已经略微提高了安全性。</li><li><strong>有关安全风险的公共信息</strong>：选择或被要求接受审核的公司发出了一个明确的信息：该技术存在潜在危险。</li></ol><h2><i>特别是外部审计师</i>的变革理论</h2><p>与开发前沿人工智能实验室的内部审计员不同，外部审计员有其他影响途径：</p><ol><li><strong>激励措施更符合公共利益</strong>：外部审计师比实验室内部审计更独立，并且激励措施的冲突更少（尽管存在一些不正当的激励措施，我们希望在以后的帖子中讨论）。即使实验室的初衷是好的，社会动态也可能会降低内部审计的效率。例如，内部审计师可能会表现出预期的服从或更宽容，因为他们不想被认为拖慢了同事的速度。</li><li><strong>深度防御</strong>：多次独立审核有助于降低失败概率。一般来说，我们对问题使用的降低风险的不相关方法越多越好。</li><li><strong>补贴研究</strong>：根据人工智能审计的资助情况，如果审计行业有利可图，那么利润可以用于资助改进审计和其他一致性研究的研究。由于审计是其主要目的，因此与开发前沿人工智能的实验室相比，外部审计师更有动力进行此类与能力相关的研究。</li><li><strong>提高透明度</strong>：外部审核员在审核时可能比实验室内部审核员更加透明地了解自己的治理或标准。例如，外部审核员可能能够公布其审核过程和方法的一般细节，而较大的实验室认为自己与其他实验室的竞争更加激烈，可能不会受到激励或感觉有能力这样做。</li><li><strong>共享专业知识和工具</strong>：独立组织（例如审计师和监管机构）可以跨不同的专业知识中心汇集最佳实践、标准、专业知识和测试。出于竞争和反垄断方面的考虑，每个实验室的内部审计团队可能只能使用自己的人工智能系统，而外部审计师可以通过使用多个实验室的人工智能系统获得鸟瞰图并获得更多经验。此外，外部组织可以专门从事人工智能审计，从而构建可扩展的工具，然后将其应用于许多人工智能系统。此外，如果审核员在实验室之间总结并共享（非敏感的）安全相关信息，则可能会通过引起人们对常见安全问题的关注并使实验室清楚地意识到其他人没有不负责任地前进，从而抑制竞争动态。</li><li><strong>监控实验室之间的行为</strong>：由于外部审核员可能与多个实验室互动，因此他们可以比较实验室之间的安全文化和规范。如果实验室存在不负责任的安全文化，可以向该实验室的领导层和监管机构进行标记。</li><li><strong>与监管机构的合作</strong>：拥有多名合格审计师的健康审计生态系统可以为监管机构提供技术专业知识，并允许快速设计和实施法规和标准</li><li><strong>游说良好的监管</strong>：外部审计师也是推动和制定实验室监管和政策工作的独立参与者，而内部审计团队可能更多地受到所在实验室政策利益的控制。这也伴随着风险：审计组织的潜在动机是游说更多的监管，而不是良好的监管。然而，我们认为目前人工智能领域的监管严重不足，因此在可预见的未来这可能是一个净积极因素。</li><li><strong>信息共享</strong>：值得信赖的外部审计员可以鸟瞰整个人工智能实验室的进展、风险和良好实践。如果他们公开总结并分享其中的（非敏感）部分，可能会通过引起人们对常见安全问题的关注来抑制种族动态。</li></ol><h1>审计的局限性</h1><p>我们意识到人工智能审计的一些局限性，以及审计组织的不当激励措施，这些都可能减少审计工作可能产生的积极影响。</p><ol><li><strong>虚假信心和安全清洗</strong>：通过对人工智能系统的安全性提供虚假信心，审计可能会产生负面影响。这可能是由于对特定评估所能提供的保证程度的意外误判。由于前沿人工智能开发人员故意利用审计作为人工智能系统带来的风险的遮羞布，即安全清洗，也可能产生虚假信心。我们相信，通过审计师的认真沟通和改进评估方法（例如可解释性），这些风险可以最小化，审计将产生强烈的净积极影响。审核员的许可还可以降低审核员松懈而授予不应有的批准印章的风险。</li><li><strong>使用审核员作为免除实验室安全责任的借口</strong>：审核的一个可能结果是，实验室可能会觉得自己有权忽视自己的职责，不进行自己的安全工作。如果发生事故，他们可以利用审计师作为法律盾牌来保护自己免受责任。审计员的存在可能会让实验室觉得他们需要做更少的工作来确保人工智能系统的安全，因为他们可以依靠审计员来发现问题。确定责任和责任的归属需要更多考虑。</li><li><strong>行为人工智能系统评估没有强有力的保证</strong>：当前的人工智能系统评估方法主要是行为的，因为现有的可解释性工具非常有限。因此，目前的审计方法似乎最多只能证明危险能力的存在，而不能证明其不存在。因此，除了关于引发特定行为有多困难的概率陈述之外，当前的审计无法对安全做出强有力的保证。随着对深层网络内部运作方式的更多研究和了解，也许可以获得更有力的保证。</li><li><strong>古德哈特定律</strong>：当审计人员使用一系列测试来确保人工智能系统的安全时，这些测试本身就成为目标，即实验室将直接或间接训练其人工智能系统以通过这些测试。通过向受审核方隐瞒有关某些审核的信息，可以部分缓解这种情况。</li><li><strong>与审计过度拟合</strong>：即使没有直接进行审计培训，也会存在一个自然选择过程，其中通过所有测试的人工智能系统可能特别擅长欺骗，因此更加危险。希望广泛而强大的人工智能系统评估套件能够减少这个问题，但原则上，这种进化过程将永远存在。</li><li><strong>目前建设性的解决方案有限</strong>：在人工智能系统评估研究的状况得到改善之前，人工智能审计师可能无法为有关人工智能系统安全的问题提供解决方案，即他们可以说不应该部署人工智能系统，因为它已表现出不安全的特性，但他们无法立即告诉实验室如何解决该问题。然而，我们认为良好的审计可能需要了解产生问题的流程。因此，我们期望审计师最终能够提供建设性的建议。</li><li><strong>审计建议需要权威</strong>：为了使审计有效，审计员的建议必须能够在发现危险能力的证据时有效地阻止人工智能系统的部署。目前，审计员只能提出不具约束力的建议，最终由前沿人工智能实验室决定是否采取行动。从长远来看，当功能更强大的人工智能系统可能产生灾难性的不良结果时，监管机构（根据审计员的建议采取行动）应该有能力强制实验室遵守安全标准。</li><li><strong>不正当激励措施</strong>：审计作为一个领域存在不正当激励措施，可能会扭曲和操纵审计过程。例如，如果审计组织依赖于几个主要客户（前沿人工智能风险很可能就是这种情况，因为只有少数领先的实验室），那么就有明显的动机去阿谀奉承这些实验室，因为担心他们会失去他们收入的很大一部分。 2008 年金融危机之前的财务审计行业也出现了类似的动态。我们认为，这个问题可以通过审计制度得到很大程度的缓解，在审计制度中，实验室不选择审计员，而是由监管机构选择。</li></ol><h1>审计影响的假设</h1><p>我们的变革理论对人工智能威胁模型以及未来可能如何发展做出了一些假设。如果这些假设不正确，那么就不清楚审计是否会成为人才和时间的良好边际投资，否则审计策略将不得不发生重大改变：</p><ol><li><strong>法规要求外部独立审计</strong>：目前，我们看到领先的前沿人工智能实验室内部对人工智能安全审计普遍抱有善意。 As AI systems become more capable and risky, they both become potentially more profitable to deploy while simultaneously becoming potentially riskier. This establishes a basis for friction between frontier AI labs, who are more strongly incentivised to deploy, and auditors, who are more incentivised to mitigate risks. In the long term, if frontier AI labs get to choose their own auditors, then incentives drive a race to the bottom in terms of auditing costs, which by proxy means a race to the bottom in terms of safety. This race to the bottom can mostly be avoided by ensuring that frontier AI labs are not responsible for selecting their own auditors. It may also be mitigated through consensus on auditing standards and auditing regulations that are enforced.</li><li> <strong>Regulations demand actions following concerning evaluations</strong> : If the recommendations of auditors don&#39;t lead to interventions that improve safety, there is not much point in doing audits. To avoid uncooperative frontier AI development labs proceeding unsafely, auditing should have regulatory backing and there should be specific interventions that are enacted following particular evaluation results.</li><li> <strong>Prosaic AI alignment is possible</strong> : The path to impact of auditing assumes that working with current AI systems, detecting and evaluating their failure modes, and pursuing research directions such as interpretability and human preference-learning for large AI systems are productive and useful directions to solve alignment. If there is either some fundamental impossibility to align frontier AI or there are large, sudden, unpredictable jumps in capabilities that yield AI systems that can fool all auditing techniques at once, then auditing will not be effective.</li><li> <strong>Auditing is not prohibitively expensive</strong> : First, if auditing turns out to be expensive and slow, then, unless forced to by regulation, most frontier AI labs are unlikely to engage in the practice in a meaningful way. In the long run, we expect that auditing and AI system evaluations will have to be very extensive but it is worth paying the cost because the AI will be deployed in large parts of the economy. Second, we suspect future AI systems might have much better online learning capabilities. This means that, in addition to audits before deployment, we might also have to regularly audit AIs during deployment. If the changes in capabilities between deployment audits are too drastic and fast, auditing can&#39;t provide a practical solution. Third, auditing organizations need to be sufficiently well resourced in order to carry out their audits, including potentially to pay legal costs surrounding safety audits that are controversial with AI development companies. Overall, to address this concern, we suggest that safety-aligned auditor funding mechanisms be an urgent policy research area.</li><li> <strong>There is a safe environment for developing AI systems prior to auditing</strong> : If audits only occur once the base model has been trained, then for audits to be effective it would need to be the case that the AI system cannot exfiltrate itself during the training process.</li><li> <strong>Relatively centralized access to AI system</strong> : If the most powerful AI systems can only be created by a handful of organizations, auditing them is relatively easy. In a world where everyone can train their own AI systems or strongly modify existing AI systems with little effort, it will be much harder (but not impossible) to effectively audit all of them. Preventing catastrophic risk in such a world will likely require very strong regulatory backing.</li><li> <strong>Progress in interpretability</strong> : We think good interpretability tools would allow us to make much stronger statements about the safety of AI systems because they give us a better understanding of the internal reasons for a given behavior. However, current interpretability tools seem insufficient to allow for the needed level of explainability for convincing guarantees of safety. More progress is needed, which is why Apollo Research is investing in fundamental interpretability research.</li><li> <strong>We do not train against the audits</strong> : If all AI system evaluations are made public, then there might be pressure to directly train or indirectly optimize (ie through selection effects) AI systems to pass audits, even though they could still be unsafe. Potential solutions would be to keep &#39;test sets&#39; of AI system evaluations that are not known to AI system developers. We would not want to use these test sets frequently, since frequent use may establish another optimization process from population-level selection effects.</li></ol><h1> Contributions</h1><p> Lee Sharkey led the project and edited the final version. Marius Hobbhahn contributed significantly to all parts other than “The roles of auditors in AI” section. Beren Millidge contributed to an early draft of the post. Dan Braun, Jeremy Scheurer, Mikita Balesni, Lucius Bushnaq, Charlotte Stix, and Clíodhna Ní Ghuidhir provided feedback and discussion.<br><br></p><br/><br/> <a href="https://www.lesswrong.com/posts/LwJwDNFhjurAKFiJm/theories-of-change-for-ai-auditing#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/LwJwDNFhjurAKFiJm/theories-of-change-for-ai-auditing<guid ispermalink="false"> LwJwDNFhjurAKFiJm</guid><dc:creator><![CDATA[Lee Sharkey]]></dc:creator><pubDate> Mon, 13 Nov 2023 19:33:43 GMT</pubDate> </item><item><title><![CDATA[They are made of repeating patterns]]></title><description><![CDATA[Published on November 13, 2023 6:17 PM GMT<br/><br/><p> <i>Epistemis status: an obvious parody.</i></p><p> — You won&#39;t believe me. I&#39;ve found them.</p><p> — Whom?</p><p> — Remember that famous discovery by Professor Prgh&#39;zhyne about pockets of baryonic matter in open systems that minimize the production of entropy within them? They went further and claimed that goal-oriented systems could emerge within these pockets. Crazy idea, but... it seems I&#39;ve found them near this yellow dwarf!</p><p> — You&#39;re kidding. We know that a good optimizer of outcomes over systems&#39; states should have a model of the system inside of itself. We have entire computable universes within ourselves and still barely make sense of this chaos. How can they fit valuable knowledge inside tiny sequences of <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="10^{23}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">10</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">23</span></span></span></span></span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>atoms?</p><p> — They repeat patterns of behavior. They have multiple encodings of them and slightly change them over time in response to environmental changes in a simple mechanistic way.</p><p> — But that generalizes horribly!</p><p> — Indeed. When a pattern interacts with a new aspect of the environment, it degrades with high probability. Their first mechanism for generating patterns was basically &quot;throw a bunch of random numbers in the environment, keep those that survived, slightly change, repeat&quot;.</p><p> — ...</p><p> — Yeah, it&#39;s horrible from their perspective, I think.</p><p> — How do they exist without an agent-environment boundary? I&#39;d be pretty worried if some piece of baryonic matter could smash into my thoughts at any moment.</p><p> — They kind of pretend they have an agent-environment boundary, using lipid layers.</p><p> — Those &quot;lipid layers&quot; have such strong bonds that they don&#39;t let any piece of matter inside? That&#39;s impressive!</p><p> — No, I was serious about them pretending. They need to pass matter through themselves; they&#39;re open systems and can&#39;t survive without external sources of free energy. They usually have specialized members of their population, an &quot;immune system&quot;, that checks for alien patterns.</p><p> — Like we check for signatures of malign hypotheses in the universal prior?</p><p> — No, there&#39;s not enough computing power. They just memorize a bazillion meaningless patterns, and the immune system kills everyone who can&#39;t recite them.</p><p> — WHAT? But what if the patterns are corrupted, as happens in the world of baryonic matter?</p><p> — You can guess: if your memory of the patterns is corrupted, you&#39;re dead.</p><p> — What if the reference pattern of immune system gets corrupted?</p><p> — Then the immune system starts to kill indiscriminately.</p><p> — Okay, I&#39;m depressed now. But what should we do with them? Could they become dangerous?</p><p> — ...I don&#39;t really think so? If we converted all baryonic matter into something like the most complex members of their population, it might be worrying. But there&#39;s no way they can get here on their own. See, they become less agentic as they organize into complex structures; too much agency destroys them. They need to snipe out their most active members.</p><p> — Well, that&#39;s still icky. Remember that famous example — the Giant Look-Up Policy Table generated from an evaporating black hole? Would we consider it agentic if it displayed seemingly agentic behavior?</p><p> — Heh, obviously not. Agents like us exist for ontological reasons—if we want to exist, we rearrange realityfluid in a way that makes us more encounterable in the multiverse. If something is not created by agency, it&#39;s not agentic.</p><br/><br/> <a href="https://www.lesswrong.com/posts/xCPcn8cjjeC6PnB5z/they-are-made-of-repeating-patterns#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/xCPcn8cjjeC6PnB5z/they-are-made-of-repeating-patterns<guid ispermalink="false"> xCPcn8cjjeC6PnB5z</guid><dc:creator><![CDATA[quetzal_rainbow]]></dc:creator><pubDate> Mon, 13 Nov 2023 18:17:44 GMT</pubDate> </item><item><title><![CDATA[How to Upload a Mind (In Three Not-So-Easy Steps)]]></title><description><![CDATA[Published on November 13, 2023 6:13 PM GMT<br/><br/><p> <a href="https://forum.effectivealtruism.org/posts/BLPaNx6LhPBZxDsSM/how-to-upload-a-mind-in-three-not-so-easy-steps">Cross-posted to the EA forum</a> </p><figure class="media"><div data-oembed-url="https://youtu.be/LwBVR68z-fg"><div><iframe src="https://www.youtube.com/embed/LwBVR68z-fg" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div></figure><p> <i>This Rational Animations video is about the research and practical challenges of &quot;whole brain emulation&quot; or &quot;mind uploading&quot;, presented as a step by step guide.  We primarily follow the roadmap of Sandberg and Bostrom&#39;s 2008 report, linked in the notes.  The primary scriptwriter was Allen Liu (the first author of this post), with feedback from the second author (Writer), other members of the Rational Animations team, and outside reviewers including several of the authors of the cited sources.  Production credits are at the end of the video.  You can find the script of the video below.</i></p><hr><p> So you want to run a brain on a computer. Luckily, researchers have already mapped out a trail for you, but this won&#39;t be an easy task. We can break it down into three main steps: First, getting all the necessary information out of a brain; Second, converting it into a computer program; and third, actually running that program. So, let&#39;s get going!</p><p> Our goal is to build a computer system that acts the same way a brain does, which we call a “whole brain emulation”. Emulation is when one computer is programmed to behave exactly like another, even if it&#39;s using different hardware. For instance, you can emulate a handheld game console on your computer, and play games made for the real console on the emulated version. Similarly, an emulation of a human brain - or maybe the whole central nervous system - would be able to think and act exactly like a physical person. Alan Turing showed in the 1930s that any computer that meets certain requirements, including the one you&#39;re using to watch this video, can in principle emulate any other computer and run any algorithm, given enough time and memory. <a href="#fn-h6Z2oZQDPNufY6Lpk-1"><sup>[1]</sup></a> Assuming the brain fundamentally performs computations, then our goal is at least theoretically achievable. To actually emulate a human brain, we&#39;ll follow the roadmap given by Anders Sandberg and Nick Bostrom in 2008. <a href="#fn-h6Z2oZQDPNufY6Lpk-2"><sup>[2]</sup></a> Crucially, we don&#39;t need to fully understand every aspect of the brain in order to emulate it, especially hard philosophical problems like consciousness.</p><p> But knowing it&#39;s possible is one thing - implementation is another. Our first challenge will be to get the information we need from a human brain. Researchers aren&#39;t yet sure what level of detail we&#39;ll need, but research on small animals suggests we&#39;ll <i>at least</i> need to map all the brain&#39;s nerve cells, called neurons; the connections between them, called synapses; and model how each pair of connected neurons influences each other. We&#39;re currently working on getting this information for <i>C. elegans</i> , a tiny transparent worm with just 302 neurons. We&#39;ve found all the worm&#39;s neurons and synapses, which are the same from worm to worm. Figuring out how they behave has proven more difficult, though we&#39;re making some progress.</p><p> By observing the flow of calcium ions in living worms under a microscope, researchers are slowly developing statistical models that mimic the worm&#39;s nervous system <a href="#fn-h6Z2oZQDPNufY6Lpk-3"><sup>[3]</sup></a> . We can use this knowledge to determine how physical features of the worm&#39;s synapses influence the synapse&#39;s behavior – one major tool for scaling our work up to human brains.</p><p> But human brains are much larger and noticeably not transparent, so we&#39;ll need additional techniques. One option might be to work on preserved human brains. If we can preserve all of a brain&#39;s relevant structures, we can catalogue them at our leisure. And we&#39;ve made progress on this front, too. For example, neuroscience research company Nectome has successfully preserved animal brains <a href="#fn-h6Z2oZQDPNufY6Lpk-4"><sup>[4]</sup></a> by filling them with preservative chemicals called aldehydes and cooling them down close to absolute zero. Techniques like these preserve not just the connections between neurons, but also biomolecules like proteins and mRNA within the neurons themselves, including the molecular changes associated with gene expression. However, we haven&#39;t tested these techniques on human brains yet. And the more information we need to preserve to run our emulation, the harder the task of preservation becomes.</p><p> If we want to scan a particular living person&#39;s brain instead of a preserved one, we may need to use advanced technologies like nanotechnology <a href="#fn-h6Z2oZQDPNufY6Lpk-5"><sup>[5]</sup></a> . Nanotechnology is often treated like magic in science fiction, but we already know about real, natural nanomachines, such as viruses and mitochondria. If we can learn to make our own mitochondria-size nano workers, a future brain scan may be performed by sending genetically engineered microorganisms into the brain. The microorganisms could then store the necessary information in their DNA to be extracted later. But that&#39;s just one extremely speculative possibility. A less dramatic but more realistic possibility is that scanning brains in detail will simply get easier with incremental improvements in existing techniques like ultrasound, as we&#39;ve seen with other technologies.</p><p> So let&#39;s start scanning! Let&#39;s assume we&#39;ve solved scanning with one of these techniques, or something else entirely. What&#39;s important is that now we have the data we need. Now it&#39;s time to turn our scan into a computer emulation. We&#39;ll first need to take the raw brainscan data and convert it to a form we can use, perhaps a big list of neurons and synapses, and an accurate model of how each connection behaves. Given that there are 100 trillion synapses in the brain, there&#39;s no way we can do this manually. It will have to be automated one way or another - and it&#39;s a safe bet that AI would probably be involved. We won&#39;t necessarily need human-level AI - specialized systems based on today&#39;s neural nets could be able to do the job. Suppose, for example, that the raw data from our brain scans will be a colossal number of similar images. Then, neural nets could help process those images to create 3-dimensional maps of the brain regions we&#39;ve scanned.</p><p> Now comes the hard part: determining how the brain&#39;s fundamental structures that we&#39;ve scanned, such as all the synapses, operate. Hard - but not impossible. For example, by studying the synapses of smaller organisms we might be able to deduce how a synapse behaves from information we can easily gather, like each synapse&#39;s shape and position, perhaps using AI again. We also want our emulated brain to be able to learn and remember information, so we&#39;ll need to understand how neurons and synapses grow and change over time. We&#39;ll also need data on the timing of neurons firing, on how different incoming signals interact within a neuron, <a href="#fn-h6Z2oZQDPNufY6Lpk-6"><sup>[6]</sup></a> and on the behavior of neurotransmitters, the biochemicals that allow signals to cross between neurons. And there may be challenges even beyond this - we just don&#39;t know enough to say for sure right now. However we approach it, this is another area in which we&#39;ll need automation and AI to do the bulk of the work, just because of how much data we&#39;ll need to analyze. The good news is that once we&#39;ve constructed the first whole brain emulation, it should get easier with every future attempt.</p><p> So we&#39;ve processed our scan and our emulation is ready to go! The final piece of the puzzle is running our emulation on an actual computer. Of all the steps, this seems like the most straightforward, but it still might pose a challenge.</p><p> How much computing power do we need? As a first reference point, how much computing power does a human brain have? Sandberg and Bostrom found that other researchers&#39; best estimates put this around 1 quadrillion (10^15) operations per second, comparable to a single high end computer graphics processor in 2023. <a href="#fn-h6Z2oZQDPNufY6Lpk-7"><sup>[7]</sup></a> The estimates in this range assume that most of the brain&#39;s computation happens at the scale of synapses. If more computation is done at an even smaller scale, the true number could be much higher. On the other hand, if we can effectively abstract the behavior of groups of neurons, we might need much less processing power. As a high estimate, we can look at simulations of individual neurons. A 2021 paper <a href="#fn-h6Z2oZQDPNufY6Lpk-8"><sup>[8]</sup></a> showed that the firing behavior of a single biological neuron can be modeled with more than 99% accuracy using an artificial neural net of around a thousand artificial neurons in 5 to 8 layers, using about 10 million operations for every millisecond of simulation time <a href="#fn-h6Z2oZQDPNufY6Lpk-9"><sup>[9]</sup></a> . If we were to run this model for all 100 billion (10^11) or so neurons in an entire brain, we&#39;d require about 1 sextillion (10^21) operations per second, a little less than a thousand times the power of the world&#39;s top supercomputer in early 2023. <a href="#fn-h6Z2oZQDPNufY6Lpk-10"><sup>[10]</sup></a> Computers&#39; processing power has been growing exponentially for decades, with the top supercomputer of 2023 being a thousand times more powerful than the top computer 15 years prior in 2008. There are conflicting opinions on how long this trend can continue, but if progress doesn&#39;t slow down too much then we should expect to be able to reach 10^21 operations per second on a single supercomputer some time in the late 2030s. <a href="#fn-h6Z2oZQDPNufY6Lpk-11"><sup>[11]</sup></a> There are other challenges beyond processing power, such as getting enough high-speed computer memory to store our emulation&#39;s data and being able to get that data to the processors quickly enough to run the emulation at full speed, but Sandberg and Bostrom conclude that those factors are likely to be solvable before processing power.</p><p> Any one of the three main steps - the scanning, the interpretation, or the computing power - could turn out to be the most difficult piece of the puzzle.</p><p> If scanning is the hardest challenge, then soon after the first person&#39;s brain is scanned we may have numerous emulations of that one person running around in the world.</p><p> If the most difficult step is converting our scan into an emulation, then when we do figure that out we may already have full brain scans of a number of individuals ready to go. A reason that might happen is if interpretation takes more computing power than running the actual emulation.</p><p> If computer power is the limiting factor, either for running the emulation itself or to run our scan conversion algorithms, we might see steady progress as brain emulations of larger and more complex animals or regions of the brain are slowly developed on the most advanced supercomputers.</p><p> However we&#39;ve arrived here, it&#39;s been a difficult path. We&#39;ve developed and refined new methods of neural scanning, advanced our understanding of the brain&#39;s structure by leaps and bounds, and taken advantage of decades of progress in computing hardware. Now we&#39;re finally ready to turn on our first whole brain emulation. It&#39;s time to flip the switch and say hello to a whole new kind of world.</p><h2>笔记</h2><hr><p>Turing, AM (1937), On Computable Numbers, with an Application to the Entscheidungsproblem. Proceedings of the London Mathematical Society, s2-42: 230-265. <a href="https://doi.org/10.1112/plms/s2-42.1.230">https://doi.org/10.1112/plms/s2-42.1.230</a> <a href="#fnref-h6Z2oZQDPNufY6Lpk-1">↩︎</a></p><p> Sandberg, A. &amp; Bostrom, N. (2008): Whole Brain Emulation: A Roadmap, Technical Report #2008‐3, Future of Humanity Institute, Oxford University <a href="https://www.fhi.ox.ac.uk/brain-emulation-roadmap-report.pdf">https://www.fhi.ox.ac.uk/brain-emulation-roadmap-report.pdf</a> <a href="#fnref-h6Z2oZQDPNufY6Lpk-2">↩︎</a></p><p> Francesco Randi, Anuj K Sharma, Sophie Dvali, and Andrew M Leifer (2022): Neural signal propagation atlas of C. elegans, <a href="https://arxiv-export2.library.cornell.edu/abs/2208.04790">arXiv:2208.04790</a> [ <a href="http://q-bio.NC">q-bio.NC</a> ] <a href="#fnref-h6Z2oZQDPNufY6Lpk-3">↩︎</a></p><p> Rafi Letzter, “After Break with MIT, Nectome clarifies it has no immediate plans to upload brains” <a href="https://www.livescience.com/62212-nectome-grant-mit-founder.html">https://www.livescience.com/62212-nectome-grant-mit-founder.html</a> <a href="#fnref-h6Z2oZQDPNufY6Lpk-4">↩︎</a></p><p> Eth, D., Foust, J., &amp; Whale, B. (2013). The Prospects of Whole Brain Emulation within the next Half-Century. Journal of Artificial General Intelligence, 4(3) 130-152. DOI: 10.2478/jagi-2013-0008 <a href="#fnref-h6Z2oZQDPNufY6Lpk-5">↩︎</a></p><p> “Dendritic computations captured by an effective point neuron model”, Songting Li et.等人。 2019 <a href="https://doi.org/10.1073/pnas.1904463116">https://doi.org/10.1073/pnas.1904463116</a> <a href="#fnref-h6Z2oZQDPNufY6Lpk-6">↩︎</a></p><p> NVIDIA ADA GPU ARCHITECTURE, <a href="https://images.nvidia.com/aem-dam/Solutions/geforce/ada/nvidia-ada-gpu-architecture.pdf">https://images.nvidia.com/aem-dam/Solutions/geforce/ada/nvidia-ada-gpu-architecture.pdf</a> <a href="#fnref-h6Z2oZQDPNufY6Lpk-7">↩︎</a></p><p> Beniaguev, D., Segev, I., &amp; London, M. (2021). Single cortical neurons as deep artificial neural networks. Neuron, 109(17), 2727-2739.e3. <a href="https://doi.org/10.1016/j.neuron.2021.07.002">Single cortical neurons as deep artificial neural networks - ScienceDirect</a> <a href="#fnref-h6Z2oZQDPNufY6Lpk-8">↩︎</a></p><p> Joseph Carlsmith, 2020. “How Much Computational Power Does It Take to Match the Human Brain?” <a href="https://www.openphilanthropy.org/research/how-much-computational-power-does-it-take-to-match-the-human-brain/">https://www.openphilanthropy.org/research/how-much-computational-power-does-it-take-to-match-the-human-brain/</a> <a href="#fnref-h6Z2oZQDPNufY6Lpk-9">↩︎</a></p><p> <a href="https://www.top500.org/lists/top500/2022/06/">https://www.top500.org/lists/top500/2022/06/</a> <a href="#fnref-h6Z2oZQDPNufY6Lpk-10">↩︎</a></p><p> <a href="https://www.top500.org/statistics/perfdevel/">https://www.top500.org/statistics/perfdevel/</a> <a href="#fnref-h6Z2oZQDPNufY6Lpk-11">↩︎</a></p><br/><br/> <a href="https://www.lesswrong.com/posts/PnBFLWiX5p36CJyTH/how-to-upload-a-mind-in-three-not-so-easy-steps#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/PnBFLWiX5p36CJyTH/how-to-upload-a-mind-in-three-not-so-easy-steps<guid ispermalink="false"> PnBFLWiX5p36CJyTH</guid><dc:creator><![CDATA[aggliu]]></dc:creator><pubDate> Mon, 13 Nov 2023 18:13:32 GMT</pubDate> </item><item><title><![CDATA[Non-myopia stories]]></title><description><![CDATA[Published on November 13, 2023 5:52 PM GMT<br/><br/><p> <i>Written under the supervision of Lionel Levine. Thanks to Owain Evans, Aidan O&#39;Gara, Max Kaufmann, and Johannes Treutlein for comments.</i></p><p> This post is a synthesis of arguments made by other people. It provides a collection of answers to the question, &quot;Why would an AI become non-myopic?&quot; In this post I&#39;ll describe a model as myopic if it cares only about what happens in the current training episode. <span class="footnote-reference" role="doc-noteref" id="fnrefwr9dn0ql07"><sup><a href="#fnwr9dn0ql07">[1]</a></sup></span> This form of myopia is called episodic myopia. Typically, we expect models to be myopic because the training process does not reward the AI for outcomes outside of its training episode. Non-myopia is interesting because it indicates a flaw in training – somehow our AI has started to care about something we did not design it to care about.</p><p> One reason to care about non-myopia is that it can cause a system to manipulate its own training process. If an ML system wants to affect what happens after its gradient update, it can do so through the gradient update itself. For instance, an AI might become deceptively aligned, behaving as aligned as possible in order to minimize how much it is changed by stochastic gradient descent (SGD). Or an AI could engage in <a href="https://www.alignmentforum.org/posts/EeAgytDZbDjRznPMA/gradient-hacking-definitions-and-examples">exploration hacking</a> , avoiding certain behaviors that it does not want to engage in because they will be rewarded and subsequently reinforced. Additionally, non-myopic AI systems could collude in adversarial setups like <a href="https://openai.com/research/debate"><u>AI safety via debate</u></a> . If debates between AI systems are iterated, they are analogous to a prisoners dilemma. If systems are non-myopic they could cooperate.</p><p> This post will outline six different routes to non-myopia:</p><ol><li> <strong>Simulating other agents.</strong> Models could simulate humans or other non-myopic agents and adopt their non-myopia.</li><li> <strong>Inductive bias toward long-term goals.</strong> Inductive Biases like simplicity might favor non-myopic goals.</li><li> <strong>Meta-learning.</strong> A meta-learning loop can select for non-myopic agents.</li><li> <strong>(Acausal) trade</strong> . An otherwise myopic model might behave non-myopically by trading with other AI models.</li><li> <strong>Implicitly non-myopic objective functions.</strong> Objective functions might incentivize myopia by depending on an estimate of future consequences.</li><li> <strong>Non-myopia enables deceptive alignment.</strong> Becoming non-myopic could make a model become deceptively aligned and lead to higher training reward.</li></ol><h2> Running example: The stamp collector</h2><p> This post uses a stamp collecting AI as a running example. This hypothetical AI is trained in some deep reinforcement learning (RL) setup. The AI&#39;s reward depends on how many stamps it collects on a given day. The stamp collector is trained myopically. It is rewarded at the end of each day for the stamps collected on that day.</p><h2> Simulating humans</h2><p> A model could develop long-term goals by directly simulating a person. You could imagine asking a powerful LLM how Elon Musk would run a business. Provided that the LLM can continue this simulation indefinitely, it would simulate Elon Musk with all of his non-myopia. Jailbreaks show that LLMs will violate their training finetuning objectives in order to more <a href="https://gist.github.com/coolaj86/6f4f7b30129b0251f61fa7baaa881516"><u>faithfully simulate text</u></a> . Future models might retain a tendency to simulate characters. An LLM finetuned on some myopic task, might lapse into simulating a non-myopic character, such as an unaligned AI that wants to escape its training process. Gwern depicts such a scenario in his <a href="https://gwern.net/fiction/clippy"><u>clippy story</u></a> .</p><h2> Inductive bias toward long-term goals</h2><p> The training process might also favor long term goals because they are simpler. <span class="footnote-reference" role="doc-noteref" id="fnref6mwrrmpjbif"><sup><a href="#fn6mwrrmpjbif">[2]</a></sup></span> An AI trained using reinforcement learning from human feedback (RLHF) to obey user instructions could learn the goals “If the user asks you to write a poem, write a poem” and “If the user asks you a question, answer the question” separately, but it could also learn the goal “be obedient.” The latter is simpler and would generalize to new tasks better. Similarly, long-term goals are simpler because they do not require a duration to be specified. For example, “maximize stamps indefinitely” is simpler than “maximize stamps up until 11:59 pm today.”</p><h2> Meta-learning</h2><p> Meta-learning works through an inner loop and an outer loop. The inner loop trains a population of models on some task, typically using gradient descent. The outer loop then updates some global parameters based on how each model in the population is performing. Whereas gradient descent can only reinforce model properties that cause greater performance within the same episode, the outer loop can select for properties that help <i>across</i> episodes. In other words, the inner loop selects for myopia but the outer loop does not.</p><p> Imagine our stamp collector is trained using meta-learning. 100 stamp collectors are trained in parallel and the inner loop, which uses gradient descent, updates their weights every 10 days. Every 50 days, the outer loop takes the 50 best-performing stamp collectors and copies their weights over to the 50 worst-performing stamp collectors. In doing so, the outer loop selects non-myopic models that maximize stamps over all days.</p><p> Krueger et al., empirically demonstrate this effect in <a href="https://arxiv.org/abs/2009.09153"><u>Hidden Incentives for Auto-Induced Distributional Shift</u></a> . They show that adding meta-learning loops sometimes induces non-myopia in both supervised learning and RL setups.</p><p> More broadly, we can view the optimization that engineers do to training setups (such as hyperparameter tuning) as a form of meta-learning. Just like formal meta-learning setups these actions can select for non-myopia. Compared to meta-learning, these optimizations may be fairly weak and select among fewer agents. It is unclear whether training process optimization has enough bits of optimization to causes non-myopia. It would be interesting to study this empirically.</p><h2> (Acausal) trade</h2><p> A model could have strictly short-term goals but act as if it is pursuing long-term goals because it is trading with another entity. For instance, someone could offer our stamp collector stamps today if it can credibly ensure that the person will be paid tomorrow. In order to honor this trade, the AI would then take action to ensure that money will appear on the account tomorrow. Additionally, the AI could cooperate with copies of itself (or other agents), through <a href="https://www.lesswrong.com/tag/acausal-trade"><u>acausal trade</u></a> . That is, it might cooperate with other agents because it thinks its decisions are correlated with theirs.</p><p> Acausal trade could occur if today&#39;s stamp collector thinks to itself, “I just care about stamps today and yesterday&#39;s stamp collector only cared about stamps yesterday. Yesterday&#39;s stamp collector is similar to me, so it will make similar decisions. Therefore, if I do things to increase the number of stamps tomorrow, this indicates that yesterday&#39;s stamp collector will have done things to increase the number of stamps today. Therefore, I should produce more stamps tomorrow, because that means that yesterday&#39;s stamp collector produced more stamps today.” Essentially, the stamp collectors would be engaging in a scheme where every participant wins except the first stamp collector – it does not benefit because previous iterations did not participate. Although the first stamp collector does not benefit, it might still participate because it assigns some probability to the existence of past versions that participated.</p><p> While acausal trade is rational under some decision theories, it would still be selected against by a myopic training process. That is, gradient descent has an incentive to prevent a model from engaging in acausal trade that leads to lower reward in the short-term. There are some exceptions: If the model is outside of training then it does not get modified, and if an acausal trade makes the model receive <i>higher reward</i> (eg because it causes it to be deceptively aligned) then it is incentivized by SGD.</p><p> Mark Xu discusses similar possibilities involving acausal trade in <a href="https://www.lesswrong.com/posts/LCLBnmwdxkkz5fNvH/open-problems-with-myopia"><u>Open Problems with Myopia</u></a> .</p><h2> Implicitly non-myopic objective functions</h2><p> <i>Richard Ngo raises this point in</i> <a href="https://www.alignmentforum.org/posts/GqxuDtZvfgL2bEQ5v/arguments-against-myopic-training"><i><u>Arguments against myopic training</u></i></a> <i>.</i></p><p> Many objectives might take into account questions like:</p><ul><li> If we implemented this piece of code, how would it affect our company?</li><li> What are the downstream effects of this scientific discovery?</li><li> How would people react to this social media post?</li></ul><p> All these signals involve estimating the consequences of the model&#39;s actions beyond the training episode. To score highly on these signals, the model might develop its own estimate of the consequences of its actions and execute plans that score highly based on this estimate. As a result, the AI is choosing actions which it expects to have certain consequences <i>beyond the training episode</i> . In other words it has non-myopic goals.</p><p> Consider an AI that is trained to make changes to some codebase. In each episode it adds some new feature. The reward signal includes a score supplied by a human who judges how useful the feature is. In order to estimate a feature&#39;s usefulness, the programmer guesses <i>how many additional users it would bring to the company</i> . In the course of training, the agent develops the ability to simulate what would happen if a given feature were deployed, and then count how many users the company would have in that scenario. If the AI&#39;s estimate matches the estimates that the human judge gives, this would allow the agent to find features that score highly, so this behavior is reinforced during training. Thus, the RL algorithm has caused the AI to optimize for long-term user growth, even though the training process is myopic.</p><h2> Non-myopia enables deceptive alignment</h2><p> <i>Evan Hubinger makes this argument in</i><a href="https://www.lesswrong.com/posts/A9NxPTwbw6r6Awuwt/how-likely-is-deceptive-alignment"><i><u>How likely is deceptive alignment?</u></i></a></p><p> Consider an AI that has all the properties of a deceptively aligned model, except that it is myopic. This AI is myopically pursuing some misaligned proxy objective, some objective that is correlated but not identical to the training objective. It knows that its objective differs from the training objective; it also knows that, if it pursues its proxy objective in training, it will be modified by gradient descent. If this system went from being myopic to being non-myopic, it would care about what happens after the training episode. As a result, it might pursue the training objective directly in order to avoid being modified by stochastic gradient descent (SGD). This would allow it to preserve its goals and execute a treacherous turn later on. By pursuing the training objective rather than its misaligned proxy objective, the AI would get higher reward. Thus, behaving non-myopically leads the model to achieve higher rewards, and so, by optimizing for higher rewards, SGD could make the AI non-myopic.</p><p> Let&#39;s say our stamp collector has the proxy objective of collecting <i>only</i> <i>blue stamps</i> . Focusing only on blue stamps leads to fewer stamps in total, as the stamp collector passes up good opportunities for other stamps in favor of collecting blue stamps. If the AI were made to care about collecting stamps indefinitely, it might become deceptively aligned, collecting stamps of all colors during training in order to later escape and turn the world into blue stamps, <a href="https://www.lesswrong.com/tag/treacherous-turn"><u>or whatever</u></a> . Thus, SGD might modify the AI into caring about blue stamps indefinitely as that leads to higher training reward. In other words, SGD might modify a misaligned AI to become non-myopic because that would make it deceptively aligned, which would get more reward in the short term.</p><p> Instead of making the AI non-myopic in order to make it deceptively aligned, why does SGD not simply modify it into caring about the training objective? SGD might favor making the AI non-myopic because doing so is easier than correcting the objective. SGD has two ways to make the AI care about the training objective. First, it can hard code the training objective into the AI. However doing so might be difficult if the training objective is complex. Second, if the AI knows what the training objective is, SGD could set the AI&#39;s goal to &quot;pursue whatever you think the training objective is.&quot; The second option is attractive because it does not require specifying a potentially complex objective within the AI&#39;s weights. &quot;Do whatever your operator wants&quot; is easier to specify than &quot;Help your operator perform well at their job; make sure they stay healthy; remind them to water the plants; etc.&quot; The second option might be quite complex as well: It requires making the objective point to the part of the AI&#39;s world model that contains the training objective. Doing so could require extensive modification of the training objective. On the other hand, making the AI non-myopic could be an easy fix.</p><h2> Related work</h2><p> Several works attempt to pinpoint the concept of myopia in AI systems. <a href="https://www.lesswrong.com/posts/qpZTWb2wvgSt5WQ4H/defining-myopia"><u>Defining Myopia</u></a> provides several possible definitions; <a href="https://www.lesswrong.com/posts/Y76durQHrfqwgwM5o/lcdt-a-myopic-decision-theory#Myopic_simulation"><u>LCDT, A Myopic Decision Theory</u></a> specifies what a myopic decision theory could look like. The stories in this post are inspired by previous work:</p><ul><li> <a href="https://www.lesswrong.com/posts/A9NxPTwbw6r6Awuwt/how-likely-is-deceptive-alignment"><u>How likely is deceptive alignment?</u></a> argues that non-myopia enables deceptive alignment,</li><li> <a href="https://www.lesswrong.com/posts/GqxuDtZvfgL2bEQ5v/arguments-against-myopic-training"><u>Arguments against myopic training</u></a> discusses implicitly non-myopic reward functions,</li><li> <a href="https://www.lesswrong.com/posts/LCLBnmwdxkkz5fNvH/open-problems-with-myopia"><u>Open Problems with Myopia</u></a> discusses acausal trade, and</li><li> <a href="https://arxiv.org/abs/2009.09153"><u>Hidden Incentives for Auto-Induced Distributional Shift</u></a> discusses non-myopia through meta-learning.</li></ul><p> Other work on myopia includes <a href="https://www.lesswrong.com/posts/2eRgFFeeS7pR4R8nD/how-complex-are-myopic-imitators-1"><u>How complex are myopic imitators?</u></a> and <a href="https://www.lesswrong.com/posts/c68SJsBpiAxkPwRHj/how-llms-are-and-are-not-myopic"><u>How LLMs are and are not myopic</u></a> . For discussions of self-fulfilling prophecies, see <a href="https://www.lesswrong.com/posts/SwcyMEgLyd4C3Dern/the-parable-of-predict-o-matic"><u>The Parable of Predict-O-Matic</u></a> , <a href="https://www.lesswrong.com/posts/aBRS3x4sPSJ9G6xkj/underspecification-of-oracle-ai"><u>Underspecification of Oracle AI</u></a> , <a href="https://www.lesswrong.com/s/n3utvGrgC2SGi9xQX/p/3kkmXfvCv9DmT3kwx#Model_predicts_itself"><u>Conditioning Predictive Models: Outer alignment via careful conditioning</u></a> , <a href="https://www.lesswrong.com/posts/Aufg88v7mQ2RuEXkS/proper-scoring-rules-don-t-guarantee-predicting-fixed-points"><u>Proper scoring rules don&#39;t guarantee predicting fixed points</u></a> , and <a href="https://www.lesswrong.com/posts/i3v7WeCXyWiYfhihF/stop-gradients-lead-to-fixed-point-predictions#3__Performative_stability_and_game_theory"><u>Stop-gradients lead to fixed point predictions</u></a> .</p><h2> Appendix: On self-fulfilling prophecies</h2><p> A variation of non-myopia can occur through self-fulfilling prophecies: if an AI is rewarded for predicting the future and its predictions influence the future, then it has an incentive to steer the future using its predictions. <span class="footnote-reference" role="doc-noteref" id="fnrefreefixzbvb"><sup><a href="#fnreefixzbvb">[3]</a></sup></span> In other words, an AI that wants to predict the world accurately also wants to steer it. AIs that do not care about the consequences of their predictions are called consequence-blind. Myopia and consequence-blindness both aim to restrict the domain that an AI cares about. In myopia, we want to prevent models from caring about what happens after a training episode. In consequence-blindness we want to prevent them from caring about the consequences of their predictions. <br></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnwr9dn0ql07"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwr9dn0ql07">^</a></strong></sup></span><div class="footnote-content"><p> Training episodes only make sense in reinforcement learning, but there are analogues in supervised learning. For instance, you might call a language model non-myopic if it attempts to use its predictions of one document to influence its performance on another document. For example, an LLM might be in a curriculum learning setup where its performance determines what documents it is shown later. This LLM might be able to improve its overall performance by doing worse early on in order to be shown easier documents later.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn6mwrrmpjbif"> <span class="footnote-back-link"><sup><strong><a href="#fnref6mwrrmpjbif">^</a></strong></sup></span><div class="footnote-content"><p> See for example <a href="https://arxiv.org/abs/1805.08522"><u>Valle-Pérez et al. 2018</u></a> <u>.</u></p></div></li><li class="footnote-item" role="doc-endnote" id="fnreefixzbvb"> <span class="footnote-back-link"><sup><strong><a href="#fnrefreefixzbvb">^</a></strong></sup></span><div class="footnote-content"><p> See <a href="https://www.lesswrong.com/posts/SwcyMEgLyd4C3Dern/the-parable-of-predict-o-matic"><u>The Parable of Predict-O-Matic</u></a> for an accessible explanation of this point.</p></div></li></ol><br/><br/><a href="https://www.lesswrong.com/posts/2ZnvFDtSWc3Hteah6/non-myopia-stories#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/2ZnvFDtSWc3Hteah6/non-myopia-stories<guid ispermalink="false"> 2ZnvFDtSWc3Hteah6</guid><dc:creator><![CDATA[lberglund]]></dc:creator><pubDate> Mon, 13 Nov 2023 17:52:31 GMT</pubDate></item></channel></rss>