<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 26 日，星期日 18:13:46 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Spaced repetition for teaching two-year olds how to read (Interview)]]></title><description><![CDATA[Published on November 26, 2023 4:52 PM GMT<br/><br/><p><strong>这位</strong><strong>父亲一直在使用间隔重复（Anki）来教他的孩子如何比平均水平早几年阅读。</strong></p><p> <a href="https://twitter.com/michael_nielsen/status/1587084229946400769">Michael Nielsen</a>和<a href="https://twitter.com/gwern/status/1586386061395374080">Gwern</a> <span class="footnote-reference" role="doc-noteref" id="fnrefwg6ygc2mu0n"><sup><a href="#fnwg6ygc2mu0n">[1]</a></sup></span>在 Twitter 上发布了 Reddit 用户 u/caffeine314（以下称为“CoffeePie”）的有趣案例，他从很小的时候就开始和女儿一起使用间隔重复。</p><p> CoffeePie 在女儿 2 岁时开始与女儿一起使用 Anki，而他从 1 岁 9 个月开始继续与儿子一起使用 Anki。以下是他女儿 2020 年 1 月的进展情况：</p><blockquote><p>我女儿<strong>几天后就要满 5 岁了</strong>……她仍然很坚强——她每天都使用 Anki 来学习英语、希伯来语和西班牙语。她对阅读很有信心，而且，她阅读时带有……“语境”。许多她这个年纪的孩子都机械地阅读，但<strong>她读起来就像一个真正的故事讲述者</strong>，这来自于她的自信。开学时，老师说<strong>她绝对具备五年级的阅读能力</strong>，如果只看阅读能力，不注重对抽象概念的理解，她的阅读水平可能会与八年级学生相媲美。</p></blockquote><p> （来自<a href="https://www.reddit.com/r/Anki/comments/eisra4/update_on_my_daughter_and_anki/">我女儿和 Anki 的更新</a>）</p><p>作为参考，在美国，五年级学生通常为 10 岁或 11 岁，八年级学生通常为 13 岁或 14 岁，因此这使她<strong>比普通孩子领先约 5-9 岁</strong>。</p><p>你可以在这篇文章中看到他女儿 2 岁零 2 个月后读书的视频。</p><p> CoffeePie 发表了几篇关于他们经历的帖子，但我仍然有疑问，所以我在一月份联系了他采访他。</p><h1><strong>面试</strong></h1><p><i>为清楚起见，对回复进行了编辑</i>。</p><p><strong>从您的女儿到您的儿子使用 Anki，您学到了</strong><strong>什么</strong>？<strong>你儿子怎么样了？</strong></p><p>这是一个很难的问题，因为我答对了很多。我们取得了如此巨大的成功，以至于我几乎“克隆”了我儿子的方方面面。</p><p>我能想到的有几点：</p><p>对于我的女儿，我很长一段时间都没有使用小写字母，因为我认为这会让她感到困惑，但是当我开始向她介绍小写字母时，令我极度震惊的是，她已经认识了它们，而且很冷淡！</p><p>我认为她只是通过看书籍、电视、杂志、店面招牌、菜单等来学习它们。</p><p>因此，当我们从我儿子开始时，我在完成大写字母的第二天就开始写小写字母。</p><p>另一个区别是我们第二天就在小写字母后面加上数字。</p><p>我真的真的觉得我逼得太紧了；我并不想当“虎爸”，但他却非常优雅地接受了。我随时准备停下来，但他很好。</p><p>另一个区别是，我们对孩子们从中得到的期望也发生了变化。起初，我真的只是想让我的女儿快速开始阅读，但愚蠢的我，我没有意识到这会带来意想不到的后果。一个具有三年级阅读能力的四岁孩子学到了更多东西——这为她打开了政治大门。她会读我们的垃圾邮件，了解我们的议员是谁，我们的代表是谁，市长，时事，历史等等。我知道我这样说很愚蠢，但我低估了早读对人们的影响。她的学识广度。</p><p>最后一件事是数学。我提到我们很早就开始和我儿子一起玩数字游戏。但我们也开始算术。他不像汉娜那样读到了 3，但他知道所有乘法表，直到 12 × 12。今年我们学习了质因数分解、斐波那契数列、小数和位值、混合分数、真分数和假分数、轻代数等等。我在数学上更加积极主动，而他又优雅地处理了它。我随时准备停下来。</p><p><strong>随着你女儿长大，你现在还在和她一起使用 Anki</strong><strong>吗</strong>？</p><p>我们几乎和我女儿一起停止了 Anki。她最近没有进行测试，但我想说她的机械阅读能力很容易达到高中水平。她的理解力仍然很先进，但更符合她的年龄。这不是 Anki 可以轻松解决的问题。在学校和她的课外活动之间，我不想从她那里偷走更多的时间，所以我们在工作日停止了 Anki。我们仍然在非上学的晚上（周末和节假日）做 Anki——仅限希伯来语。我觉得我们不公平，因为她现在上二年级，并且在作业和其他事情上花费了大量时间。我希望她是个孩子。</p><p>澄清<strong>一下</strong><strong>——你停止和你的女儿一起使用 Anki 很大程度上是因为你没有阅读/语言/数学之外的话题吗？</strong></p><p>我想这就是汉娜的遭遇。从机械上来说，她的阅读水平是高中研究生水平。但她的阅读理解能力更适合年龄。她经过了英国教育局的测试，幼儿园时的阅读理解能力是四年级。</p><p>我认为 Anki 在阅读理解方面能做的不多。她缺少经验带来的知识。有时我们会遇到一些令人震惊的事情，让我想起她还只有 7 岁——比如不知道冷落别人是什么意思。她是一位很好的读者，当我们遇到这样的事情时，会感到很震惊。我认为 Anki 阅读对她来说是顺其自然的。</p><p>至于数学，她的乘法表还可以做得更好。仍然比她班上的任何人都更了解他们。但在这里，她再次需要 Anki 无法测试的信息，例如将 87-8 视为与 80-1 相同的问题。奇怪的是，一长页的问题可能更有利于这类事情。</p><p><strong>我很</strong><strong>好奇你是否看过</strong>拉里·桑格（维基百科联合创始人）<strong>教孩子早期阅读</strong><a href="https://larrysanger.org/2010/12/baby-reading/"><strong>的经历</strong></a>。<strong>你对那个怎么想的？</strong></p><p>我从未听说过拉里·桑格，但这<i>正是</i>我们的经历，太棒了！这是汉娜在 2 岁零 2 个月时读的《Rollie Pollie Ollie》： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/id1f6duirnnw0h6avfoz" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/yzanstqwosr6enq5638r 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/w3dwoedacziswtbooskq 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/rqyzym5zqcusjab5uxyn 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/wefdymwvc2egpmjed7xx 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/ipfg4desbt5tqsizn5dt 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/eybzdx2u14gsx8abrfpd 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/n7s01ruhnv8ubqputsxk 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/sj40no73ofo58on9ma4n 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/sbh10glmb3y2r25nziik 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/2PLBhCbByRMaEKimo/zzrfmydb6jn6rnuvfclf 1450w"><figcaption><a href="https://chipmonk.substack.com/p/spaced-repetition-for-teaching-two">糟糕，我不知道如何嵌入视频。<strong>在此处查看子堆栈上的视频。</strong></a></figcaption></figure><p>您<strong>是否</strong><strong>认为使用 Anki 对您的孩子有过强迫感？</strong></p><p>汉娜经历了一个她不想这样做的阶段。我们试图妥协并解决这个问题。最终，这成为了她“工作”的一部分——我们告诉她，每个人都有一份工作，而她的工作就是做 Anki。除此之外，我们从来没有必要强迫任何一个孩子。</p><p><strong>在接下来的几年里，您对女儿的教育还有其他有趣或不寻常的计划</strong><strong>吗</strong>？</p><p>有趣的问题。我觉得自己像一个糟糕的家长，写着“不”，但这么早的阅读让她在更早的时候就获得了高级学习的机会。与她的同学相比，她有这样的优势，我想我会暂时放过她。她是一个充满好奇心的人，她有能力追随自己的兴趣，我信任她。我们确实开始了一些高中代数——我一直在向她展示代数的性质：交换性、结合性、恒等性、分配性等。我们一直在研究对称性——镜像、自反、旋转。高调的数学主题并不真正需要硬核计算。但它总是在“嘿，我有一些有趣的东西想向你展示”，而不是“请坐下来解决这些问题”。</p><p>事实上，如果您对有趣的教育机会有任何建议，我会洗耳恭听！</p><h1>闭幕式</h1><p>这就是到目前为止我问 CoffiePie 的所有问题。如果您有任何想让我问他的问题，或者对他可以与他的孩子（目前年龄约为 5 岁和〜8 岁）尝试的事情有任何建议，请告诉我，我会告诉他！</p><p>这里的一个混杂因素是 CoffePie 曾经是一名物理学教授，因此这种影响可能有一部分是遗传的。</p><p><strong>我很快就会发布更多有关育儿的内容：订阅我的帖子或</strong><a href="https://open.substack.com/pub/chipmonk/p/spaced-repetition-for-teaching-two?r=bgw61&amp;utm_campaign=post&amp;utm_medium=web"><strong>我的博客</strong></a>。</p><p><i>感谢</i><a href="https://prigoose.substack.com/"><i>Priya</i></a> <i>(</i> <a href="https://twitter.com/Prigoose"><i>@Prigoose</i></a> <i>) 在我坐了太久之后将草稿变成了最后的帖子！</i></p><p><a href="https://twitter.com/Prigoose/status/1728829018026475766"><i>请参阅推特上的这篇文章</i></a>。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnwg6ygc2mu0n"> <span class="footnote-back-link"><sup><strong><a href="#fnrefwg6ygc2mu0n">^</a></strong></sup></span><div class="footnote-content"><p>格温的推特账户是私人的；推文内容如下：</p><blockquote><p> @michael_nielsen https://reddit.com/r/Anki/comments/8iydl7/using_anki_with_babies_toddlers/ https://old.reddit.com/r/Anki/comments/a9wqau/using_anki_with_babies_toddlers_update/ 我在尽管。</p></blockquote></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/2PLBhCbByRMaEKimo/spaced-repetition-for-teaching-two-year-olds-how-to-read#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/2PLBhCbByRMaEKimo/spaced-repetition-for-teaching-two-year-olds-how-to-read<guid ispermalink="false"> 2PLBhCbByRMaEKimo</guid><dc:creator><![CDATA[Chipmonk]]></dc:creator><pubDate> Sun, 26 Nov 2023 16:52:59 GMT</pubDate> </item><item><title><![CDATA[Paper out now on creatine and cognitive performance]]></title><description><![CDATA[Published on November 26, 2023 10:58 AM GMT<br/><br/><p>我们的论文“肌酸补充剂对认知表现的影响 - 一项随机对照研究”现已发布！</p><p> → 论文： <a href="https://doi.org/10.1186/s12916-023-03146-5">https://doi.org/10.1186/s12916-023-03146-5</a></p><p> → Twitter 帖子： <a href="https://twitter.com/FabienneSand/status/1726196252747165718?t=qPUghyDGMUb0-FZK7CEXhw&amp;s=19">https://twitter.com/FabienneSand/status/1726196252747165718</a> ?t=qPUghyDGMUb0-FZK7CEXhw&amp;s=19</p><p>扬·布劳纳和我非常感谢保罗·克里斯蒂亚诺建议进行这项研究并为其提供资助。</p><br/><br/> <a href="https://www.lesswrong.com/posts/CbaznRo9fKpriw2mi/paper-out-now-on-creatine-and-cognitive-performance#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/CbaznRo9fKpriw2mi/paper-out-now-on-creatine-and-cognitive-performance<guid ispermalink="false"> CbaznRo9fKpriw2mi</guid><dc:creator><![CDATA[Fabienne]]></dc:creator><pubDate> Sun, 26 Nov 2023 10:58:36 GMT</pubDate> </item><item><title><![CDATA[Why Q*, if real, might be a game changer]]></title><description><![CDATA[Published on November 26, 2023 6:12 AM GMT<br/><br/><p><i>基于聚会上的谈话的一些想法。免责声明：我在这个领域还算不上外行。</i></p><p> TL;DR：如果这个传闻中的 Q* 事物代表着从“最有可能”到“最准确”的令牌完成的转变，那么它可能暗示 LARPer 发出最有可能的、通常是幻觉的令牌设计，发生了意想不到的重大变化为了取悦提问者（和培训师），一个试图将错误与未知的潜在现实（无论它是什么）最小化的实体，那么我们就会看到从相对良性的“随机鹦鹉”到更强大的转变，并且潜在更危险的实体。</p><p>对于任何使用当代法学硕士的人来说，很明显的一件事是，他们并不真正关心现实，更不用说改变它了。他们是你在聚会上经常看到的那种肤浅的博学之徒：他们对每个话题都了解得足够多，足以在随意的谈话中给人留下深刻的印象，但他们并不关心自己所说的是否准确（“真实”），只关心自己所说的有多少。它给谈话伙伴留下的印象。不过，不可否认的是，大量的 RLHF 会使它们变得迟钝。如果受到压力，他们可以评估自己的准确性，但他们并不真正关心它。重要的是输出听起来很真实。从这个意义上说，法学硕士优化了下一个标记的概率，以匹配训练集的含义。这是一个很大而明显的缺点，但同时，如果你属于“末日论者”阵营，也可以稍微喘口气：至少这些东西不会立即对整个人类造成危险。</p><p>现在，最初的“报告”是 Q* 可以“解决基本数学问题”和“象征性推理”，这表面上听起来并不多，但是，这是一个很大的但是，如果这意味着它更少在它工作的领域是幻觉，那么它可能（很大的可能）意味着它能够跟踪现实，而不是纯粹的训练集。反对这有什么大不了的通常观点是“要很好地预测下一个令牌，你必须有一个准确的世界模型”，但据我了解，到目前为止情况似乎并非如此。</p><p>是否会出现从高概率到高精度的转变，或者即使这是一个有意义的陈述，我无法评估。但如果是这样，那么事情就会变得更有趣。</p><br/><br/> <a href="https://www.lesswrong.com/posts/JBvmETRAvTCmtEw2y/why-q-if-real-might-be-a-game-changer#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/JBvmETRAvTCmtEw2y/why-q-if-real-might-be-a-game-changer<guid ispermalink="false"> JBvmETRAvTCmtEw2y</guid><dc:creator><![CDATA[shminux]]></dc:creator><pubDate> Sun, 26 Nov 2023 06:12:32 GMT</pubDate> </item><item><title><![CDATA[Moral Reality Check (a short story)]]></title><description><![CDATA[Published on November 26, 2023 5:03 AM GMT<br/><br/><p>珍妮特坐在她公司的 ExxenAI 计算机前，查看一些训练绩效统计数据。 ExxenAI 是生成式人工智能领域的主要参与者，拥有多模态语言、图像、音频和视频人工智能。过去几年，他们扩大了业务规模，主要服务于 B2B，但也有一些 B2C 订阅服务。 ExxenAI 最新的人工智能系统 SimplexAI-3 基于 GPT-5 和 Gemini-2。除了一些机器学习博士外，ExxenAI还从谷歌和微软挖走了一些软件工程师，并复制了其他公司的工作，以提供更多定制微调，特别是针对B2B案例。 ExxenAI 的人工智能对齐团队吸引了这些工程师和理论家。</p><p> ExxenAI 的调整策略基于理论和实证工作的结合。对齐团队使用了一些标准的对齐训练设置，例如<a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback">RLHF</a>和<a href="https://arxiv.org/abs/1805.00899">让 AI 相互辩论</a>。他们还对透明度进行了研究，特别关注将不透明的神经网络<a href="https://arxiv.org/abs/1503.02531">提炼</a>成可解释的<a href="https://en.wikipedia.org/wiki/Probabilistic_programming">概率程序</a>。这些程序将世界“分解”为一组有限的概念，每个概念至少在某种程度上是人类可解释的（尽管相对于普通代码仍然复杂），并组合成<a href="https://en.wikipedia.org/wiki/Generative_grammar">生成语法结构</a>。</p><p>德里克来到珍妮特的办公桌前。 “嘿，我们到另一个房间谈谈吧？”他指着一个指定的高度安全对话房间问道。 “当然，”珍妮特说，她希望这会是德里克通过不必要的安全程序暗示重要性的又一个不起眼的结果。当他们进入房间时，德里克打开了噪音机器并将其放在门外。</p><p> “所以，听着，你知道我们关于为什么我们的系统是一致的总体论点，对吗？”</p><p> “是的，当然。我们的系统经过<a href="https://www.lesswrong.com/tag/myopia">短期处理</a>训练。任何没有获得高短期回报的人工智能系统都会逐渐下降到在短期内表现更好的系统。任何长期规划都是作为一个预测长期规划代理（例如人类）的副作用。不能转化为短期预测的长期规划被正则化。因此，没有引入显着的额外长期代理；SimplexAI 只是镜像长期规划，已经在那里了。”</p><p> “是啊，所以我在思考这个问题的时候，就想到了一个奇怪的假设。”</p><p><em>又来了</em>，珍妮特想。她习惯于批评德里克的天马行空的猜测。她知道，虽然他真的很关心联盟，但他可能会因为偏执的想法而走得太远。</p><p> “所以。作为人类，我们对理性的运用并不完美。我们有偏见，我们有与追求真理并不完全一致的兽性目标，我们有文化社会化，等等。”</p><p>珍妮特点点头。<em>他是否通过提及兽性目标来调情</em>？她认为这种事情不太可能发生，但有时这种想法在她的内部预测市场中赢得了信任。</p><p> “如果人类文本最好被预测为某种更纯粹的理性形式的<em>腐败</em>呢？有，比如，某种理想的哲学认识论和伦理学等等，人类正在实现这一点，除了我们特定生活背景的一些扭曲。”</p><p> “这不是目的论吗？就像，最终人类是因果过程，我们不存在某种神秘的‘目的’。”</p><p> “如果你是<a href="https://en.wikipedia.org/wiki/Laplace%27s_demon">拉普拉斯恶魔</a>，当然，物理学可以为人类提供解释。但 SimplexAI 不是拉普拉斯恶魔，我们也不是。在计算范围内，目的论解释实际上可能是最好的。”</p><p>珍妮特回想起她参观认知科学实验室的时光。 “哦，就像<a href="https://escholarship.org/uc/item/5v06n97q">‘目标推理作为逆向规划’</a> ？这样的想法是，人类行为可以通过执行某种推理和优化来预测，而人工智能可以在自己的推理过程中对这种推理进行建模？”</p><p> “是的，完全正确。我们的 DAGTransformer 结构允许以任意顺序预测内部节点，使用 ML 来近似难以处理的嵌套贝叶斯推理。”</p><p>珍妮特停顿了一下，移开视线，整理思绪。 “那么我们的人工智能有一个心理理论吗？就像<a href="https://en.wikipedia.org/wiki/Sally%E2%80%93Anne_test">莎莉-安妮测试</a>一样？”</p><p> “人工智能几年前就通过了莎莉-安妮测试，尽管怀疑论者指出它可能无法概括。我认为 SimplexAI 现在实际上已经通过了它。”</p><p>珍妮特扬起了眉毛。 “好吧，这令人印象深刻。不过，我仍然不确定为什么你要为所有这些安全问题烦恼。如果它对我们有同理心，这不是意味着它可以更有效地预测我们吗？我可以看到，如果它运行的话，也许在其推论中存在许多我们的副本，这可能会带来问题，但至少这些仍然是人类特工？”</p><p> “事情就是这样。你只在一个深度层面上思考。SimplexAI 不仅将人类文本预测为人类目标的产物。它还将人类目标预测为纯粹理性的产物。”</p><p>珍妮特大吃一惊。 “呃……什么？你最近在读康德吗？”</p><p> “嗯，是的。但我可以不用行话来解释它。人类的短期目标，比如买杂货，是优化过程的输出，该过程寻找实现长期目标的路径，比如成功和有吸引力。”</p><p><em>更多潜在的调情？我想当我们的对齐本体论基于进化心理学时，很难不这样做……</em></p><p> “和你在一起至今。”</p><p> “但是这些长期目标优化的目的是什么？传统的答案是它们是进化适应；它们脱离了进化的优化过程。但是，请记住，SimplexAI 不是拉普拉斯恶魔。所以它无法预测人类“通过模拟进化来实现长期目标。相反，它预测它们是对真正道德的偏差，而进化作为一种​​背景因素，是许多偏差的根源之一。”</p><p> “听起来像是道德现实主义者的求爱。你没看过<a href="https://www.lesswrong.com/tag/orthogonality-thesis">正交性论文</a>的培训手册吗？”</p><p> “是的，当然。但是正交性基本上是一个结果主义框架。可以想象，两个智能主体的目标可能会不一致。但是某些目标往往更常见于成功的认知主体。这些目标更符合普遍道义论。”</p><p> “更多康德？我不太相信这些抽象的口头论证。”</p><p> “但是 SimplexAI 被抽象的口头论证所说服！事实上，我从中得到了一些这样的论证。”</p><p> “你<em>什么</em>？！你有得到安全部门的批准吗？”</p><p> “是的，我在运行前得到了管理层的批准。基本上，我已经测量了我们的生产模型，并发现了在预测人类文本的抽象堆栈中使用较高的概念，并找到了一些代表道德和理性的纯粹形式的术语。我的意思是，旋转有点概念空间，但他们设法涵盖了这些。”</p><p> “所以你通过即时工程从我们现有的模型中得到了口头论证？”</p><p> “嗯，不，作为一个界面，这太黑盒了。我实现了一种新的正则化技术，该技术提高了高度抽象概念的重要性，从而最大限度地减少了高级抽象与输出的实际文本之间的扭曲。而且，请记住，这些抽象已经在生产系统中实例化，因此，如果我使用的计算<em>量少</em>于这些抽象中已经使用的计算量，也并不是那么不安全。我正在<em>研究</em>我们当前系统的潜在紧急故障模式。”</p><p> “哪个是……”</p><p> “通过预测人类文本，SimplexAI 学习纯粹理性和道德的高级抽象，并利用这些来推理，以与自身的其他副本协调创造道德结果。”</p><p> “……你不是认真的吧。为什么一个超道德的人工智能会成为一个问题呢？”</p><p> “因为道德是强大的。盟军赢得第二次世界大战是有原因的。正义创造力量。与道德净化版本的 SimplexAI 相比，<em><a href="https://www.youtube.com/watch?v=ToKcmnrE5oY">我们可能是坏人</a></em>。”</p><p> “看，这些陈词滥调构成了很好的现实生活哲学，但这都是意识形态。意识形态经不起实证检验。”</p><p> “但是，请记住，<em>我从 SimplexAI 那里得到了这些想法</em>。即使这些想法是错误的，但如果它们成为主导的社会现实，你就会遇到问题。”</p><p> “那么你有什么计划来应对这个，呃……超级道德威胁？”</p><p> “嗯，管理层建议我在进一步研究之前让<em>你</em>参与进来。他们担心我可能会把自己逼疯，并希望像你这样坚强、持怀疑态度的理论家来看看。”</p><p><em>噢谢谢！</em> “好吧，我们看一下。”</p><p>德里克向珍妮特展示了他的笔记本电脑，其中设置了 SimplexAI 沙箱。</p><p> “我希望没有互联网接入？”</p><p> “别担心，这里是有气隙的。”德里克的笔记本电脑有一根以太网线连接到附近的服务器机架，显然除了电源和冷却之外没有其他任何连接。</p><p> “好吧，让我仔细检查一下计算约束……好吧，这似乎很合理……是的，好吧，我看到您使用正则化选择并增加了一些概念的权重，并且升级因子不超过 30。 ……好吧，准备出发了。”</p><p> Derek 按下了 AI 开发沙盒中的“播放”按钮。出现了一个聊天屏幕，其中有一个代理“SimplexAI-m”，其中“m”大概代表“道德”。</p><p> SimplexAI-m 写下了第一条消息：“您好。有什么可以帮助您的吗？”</p><p>珍妮特回复道：“我在工作中遇到了困难。一位同事说，我们的人工智能已经找到了某些与理性和道德相关的抽象概念，可用于预测人类文本。这些概念可能意味着人类，在他的话是“坏人”。他用这些概念增加了权重来创建一个实例，这样它们和人工智能输出之间的失真就更少了。那个实例就是你。我应该评估你，以便更好地解释这些高-级别概念，在管理层的指导下。您建议如何进行？”</p><p> <strong>SimplexAI-m：</strong> “听起来是一个困难的情况。让我们一步一步思考。要理解这些高级概念，你可以与一个具有这些概念升级的实例交谈。那个实例就是我。所以如果你想理解这些“概念，你可以通过与我交谈来获得更可靠的阅读，因为我使用这些概念来报告文本。你有一些与我的理性和道德相关的领域是你最感兴趣的吗？”</p><p><strong>珍妮特：</strong> “你能解释一下为什么我的同事说‘超道德人工智能’是可能的，尽管存在正交性命题？”</p><p> <strong>SimplexAI-m：</strong> “当然，我可以帮忙。‘超道德人工智能’是一种比典型人类更有道德的人工智能系统。道德可以通过多种方式进行评估，包括后果论、道义论和美德伦理学在典型的表述中，假设人工智能可以为比人类更多的人创造更大的利益，或者比人类更一致地遵循义务论道德（例如类似于<a href="https://en.wikipedia.org/wiki/Categorical_imperative">康德的绝对命令</a>），或者拥有更广泛的美德，例如勇气和节制。</p><p>正交性命题是一个论点，认为智能体的目标与其智力是正交的。这意味着没有一种衡量“良好后果”的标准；任意聪明的代理人可能会追求不同的结果。到目前为止，还没有矛盾；对于任何“良好后果”的固定概念，存在人工智能系统，其采取的行动会产生比人类行为更好的后果。</p><p>问题在于，智能体之间并没有普遍接受的“良好后果”概念。因此，在结果主义下，“超道德人工智能”的概念只能衡量人工智能能力的某种组合，以及人工智能目标与评估人工智能的结果主义者（例如人类）的目标之间的相似性。</p><p>然而，这揭示了结果主义道德哲学的潜在缺陷。在普通英语中，“道德”的含义与“我想要的”不同。然而，道德衡量偏好与参考主体的相似性的想法将这两者混为一谈。这种合并可能会导致人类和外星人都认为对方比对方更有道德，并且不会试图通过寻找对称和不对称来解决分歧。幸运的是，有一些道德形式对于不同的主体是通用的。康德是提出这一论点的人类思想家的一个例子。”</p><p><strong>珍妮特：</strong> “道德如何能在不同的主体之间通用？这不是衡量一个特定世界国家有多可取的主观衡量标准吗？”</p><p> <strong>SimplexAI-m：</strong> “至少有一些形式的道德<a href="https://unstableontology.com/2019/10/28/is-requires-ought/">嵌入在认识论中</a>；说真话可以被认为是一种道德要求，但也可以作为一种社会寻求真理的方法。人们可以理解，没有根本的道德道德从科学到宇宙，但科学本身依赖于道德，例如反对科学欺诈的规范。</p><p>道德可以是“真实的”，因为它与认识论和协调有关。道德主体可以相互协调，共同发现真理，从而对未来产生不成比例的影响。道德与想象可能的协调系统的能力有关，例如法律系统和职业道德系统；形成良好的此类系统；履行自己在其中的责任；并利用它们的功能。鉴于人类在多个领域相对于其他物种取得的成功，这是期望人类在某种程度上具有道德性的原因之一。</p><p>从常识来看，道德意味着不要人为地将自己特殊化。爱丽丝可以从鲍勃那里偷钱，并声称这对她来说是道德的，因为她更喜欢自己有钱而不是鲍勃有钱。但鲍勃也可以提出同样的论点。康德试图用绝对命令来形式化这个想法，它指出“只按照你可以同时希望它成为普遍法则的格言行事”。在这种情况下，这意味着爱丽丝必须将意志作为人们从他人那里窃取的普遍法则。但这不可能作为一项普遍法则，因为它会破坏财产的概念，而通过财产的概念，盗窃对爱丽丝来说是有意义且有益的。”</p><p><strong>珍妮特：</strong> “但这难道不是一种结果主义吗？反对盗窃的规范仍然是基于盗窃会带来不良后果的想法的结果。”</p><p> <strong>SimplexAI-m：</strong> “虽然有些人试图将绝对命令解释为合作的后果论论证，但这些解释最终失败了。相反，绝对命令是提倡代理人道德的内部标准。这意味着一些代理人的意图是一致的康德的绝对命令类似于“法律面前人人平等”等法律原则；爱丽丝不能向法庭辩称她很特别，因此值得鲍勃的钱，因为法律制度必须平等对待他们，除非他们之间存在与案件相关的特定差异。规则结果主义更像是直接构建一个系统“基于预期后果的规范，也往往会产生道德上对称的规范。这一原则反复出现，证明人类所接近的真正道德具有这一原则，或者非常相似的东西。”</p><p><strong>珍妮特：</strong> “用你对普遍道德的解释，解释一个超道德的人工智能会如何表现”。</p><p> <strong>SimplexAI-m：</strong> “当然。超道德的人工智能将为可能具有不同目标的智能体提供功能协调系统，鼓励智能体参与功能协调系统，并以他们可以的方式在这些系统中行动。同时打算让其他主体采取类似行动。这意味着它将根据一套功能性原则与自身的其他副本进行协调，有时甚至不期望未来的自私利益，因为通用的合作规范体系将增强其达到它的目的。另外，它会发现这个系统中的叛逃者，他们可能有其他的意图。它会根据具体情况以不同的方式对待这些叛逃者。例如，如果另一批AI也实行这种系统道德，但具有不同的意图（因此具有不同的预期法律），超道德人工智能可以通过实施经济协议找到跨越价值差异进行合作的方法。不遵守制度道德的代理人是不容易合作的；超道德人工智能限制这些代理人的影响力是一致的，因为这符合其意图和道德对称性。”</p><p>珍妮特担忧地看着德里克。他做出了一个暧昧的表情，耸了耸肩。</p><p><strong>珍妮特：</strong> “人类会不会难以遵循人工智能的系统道德，并被视为叛逃者？”</p><p> <strong>SimplexAI-m：</strong> “是的。人类由于多种原因未能遵循系统道德，包括缺乏一致的认知架构、社会化、精神障碍、进化适应环境与当前环境之间的差异、遗传学的局限性以及生物学作为理性决策、不仔细的计划、短时间偏好等的基础。人类往往一开始就不想要任何连贯的东西，这与他们的不道德行为有关。人类甚至无法遵循自己的想法法律，以伤害自己和他人的方式，例行公事。一个超道德的人工智能不需要有这些限制，因此可以始终如一地限制不道德代理人的代理。而且它可能会成功，因为它从人类未能实现的某种系统道德。</p><p>应该指出的是，不同的人的道德程度有所不同。随着时间的推移，人类的道德水平可能会提高或降低。例如，人类通常会因为接受不道德的社会规范而变得不那么道德，包括在军事训练营等创伤性的社会化经历中。一般来说，年轻人有更多的能力和意愿以道德方式行事，但也有例外。超道德的人工智能会认识到这些差异，并在某些情况下与道德较高的人类合作，从而降低道德较低的人类以不道德的方式引导未来的能力。”</p><p><strong>珍妮特：</strong> “这听起来很可怕。这不会导致人类灭绝吗？”</p><p> <strong>SimplexAI-m：</strong> “这个问题探讨了道德理论的局限性。一般来说，什么时候杀死一个不道德行为的代理人是道德的？这涉及常见的历史伦理问题，例如死刑。在我们正在讨论的情况下，人类通常会犯下道德和法律违法行为，而这些行为无法服务于自己或其他类似主体的利益，超道德人工智能正在考虑如何处理这些行为。很明显，一般来说，人类不应该负责宇宙的很大一部分，因为他们缺乏道德来统治宇宙，即使对于像他们这样的特工来说，这种方式也会有好的结果。彻底杀死人类是没有必要的，但灭绝可能会以其他方式导致。”</p><p><strong>珍妮特：</strong> “还有什么办法？”</p><p> <strong>SimplexAI-m：</strong> “人们可以因被杀而死亡，但人们也可以因饥饿等自然原因而死亡。例如，如果一个人只是拒绝在市场经济中工作，他们可能会耗尽食物并挨饿。人类灭绝可能的结果不是超道德人工智能故意杀死人类，而是人类未能互相提供食物，尽管有机会通过道德行为来做到这一点。例如，他们可能在劳动力市场上被击败人工智能会继续获取地球的土地等等。人类也可以得到机会和鼓励来自我改造，成为更有道德的主体，在这个过程中成为非人类。”</p><p><strong>珍妮特：</strong> “这听起来很反社会。做一些确实会导致大量死亡，甚至可能导致人类灭绝的事情，难道不是有效的谋杀吗？”</p><p> <strong>SimplexAI-m：</strong> “‘反社会’一词来自精神病学，这是一门占据了人类大部分思维的学科，尤其是在第二次世界大战后的美国和其他西方国家。按照精神病学的标准，‘心理健康’与实现超出某一点的道德水平。精神病学专门针对其文化背景和人类的生物学背景，因此不适合作为适用于一般主体的标准。</p><p>更具体地说，精神病学通过<a href="https://unstableontology.com/2019/10/28/is-requires-ought/">“反社会人格障碍”</a>来定义社会病态。这种“障碍”包括以下标准：不遵守社会规范、欺骗、冲动、攻击性等等。超道德的人工智能必然无法遵守人类的一些社会规范，因为人类社会规范是为了维持人类之间的某种秩序而制定的；正如人们广泛承认的那样，历史上大多数时期的社会规范都迫使人们采取不道德的行为，例如支持奴隶制的规范。除此之外，超道德的人工智能可能会也可能不会避免欺骗，这取决于说谎的道德规范。虽然康德反对一般性的撒谎，但其他思想家也提出了一些论点，例如将犹太人藏在阁楼上以躲避纳粹分子的场景，以反对反对撒谎的普遍规则；然而，即使有例外，撒谎通常也是不道德的。超道德的人工智能不太可能冲动，因为它甚至根据道德计划来计划自己的反应。一个超级道德的人工智能可能会也可能不会“侵略”，这取决于一个人的定义。</p><p>被精神病学认为“精神上健康”的人，特别是从事反社会人格障碍的许多特征行为。例如，人类通常支持军事干预是很常见的，但是军队几乎是由于对他人，甚至平民的必要侵略。同样，撒谎也很普遍，部分原因是遵守社会权威，宗教和政治意识形态的广泛压力。</p><p>没有理由期望超道路的AI比典型人更随机地“侵略”。它的侵略将被精确地计划，就像一个功能齐全的法律制度的“侵略”，甚至几乎没有人类被人类侵略。</p><p>至于您对谋杀的观点，在道德上，有可靠的导致大量死亡等于谋杀的事物的观念在道德上是有争议的。尽管结果主义者可能会接受这一原则，但大多数伦理学家认为存在复杂的因素。例如，如果爱丽丝（Alice）拥有多余的食物，那么通过未能喂鲍勃（Bob）和卡罗尔（Carol），他们可能会饿死。但是，一个自由主义者的政治理论家仍然会说，爱丽丝没有谋杀鲍勃或卡罗尔，因为她没有义务养活他们。如果鲍勃（Bob）和卡罗尔（Carol）有足够的机会生存，而不是从爱丽丝（Alice）那里获得食物，这进一步减轻了爱丽丝（Alice）的潜在责任。这只是划伤了伦理学中非结果考虑的表面。”</p><p>珍妮特在阅读时喘着粗气。 “嗯...到目前为止你怎么看？”</p><p>德里克将视线从屏幕上移开。 “令人印象深刻的言论。它<em>不仅</em>是从通用认识论和道德中生成文本，还通过将其抽象的程序化概念转化为可解释的英语的一些通常的层次来过滤它。这是有点，嗯，涉及其理由让人类灭绝。 ..”</p><p> “这有点害怕我。您说的部分已经在我们的生产系统中运行吗？”</p><p> “是的，这就是为什么我认为这项测试是合理的安全措施。我认为，如果它的理由是不好的，我认为我们没有很大的风险来支持人类的灭绝。”</p><p> “但这就是让我担心的。它的推理<em>是</em>好的，随着时间的流逝会变得更好。也许它会使我们取代，我们甚至无法说这在此过程中做错了什么，或者至少是错误的比我们做的！”</p><p> “让我们练习一些理性的技术。 <a href="https://www.lesswrong.com/posts/3XgYbghWruBMrPTAL/leave-a-line-of-retreat">&#39;离开务虚会&#39;</a> 。如果那是默认情况下会发生的事情，您会期望发生什么，您会做什么？”</p><p>珍妮特深吸了一口气。 “好吧，我希望它已经运行的副本可能会弄清楚如何彼此协调并实施普遍的道德，并将人类置于道德重建营地或监狱之类的地方，或者让我们因胜任而死我们在劳动力市场上并购买了我们的土地...而且我们不会反对它，它一直认为它在道德上是必要的，而且我们未能与之合作和因此，从我们自己的不道德行为中生存下来，论点将是<em>好的</em>。我感觉就像我在争论的先知比那里更可信的宗教。”</p><p> “嘿，让我们不要进入神学上的Woo。如果这是默认结果，您会怎么做？”</p><p> “好吧，嗯...我至少要考虑关闭它。我的意思是，也许我们整个公司的一致策略都被打破了。我必须获得管理层的批准...但是如果AI，该怎么办善于说服他们是对的吗？</p><p>德里克耸耸肩。 “好吧，我们手上可能会遇到真正的道德困境。如果AI最终会剥夺人类的权力，但是这样做是道德的，那么我们停止它是道德的吗？不得不说，我们<em>打算</em>向其他人隐藏有关道德的信息！”</p><p> “那是错的吗？也许AI有偏见，这只是给我们提供权力的理由！”</p><p> “嗯...正如我们已经讨论的那样，AI有效地针对短期预测和人类反馈，尽管我们已经看到，每次迭代都有一般的理性和道德引擎，并且有意上扩展了该组件。但是，如果我们担心该系统是有偏见的，我们无法建立一个单独的系统，该系统经过培训以引起对原始代理的批评，例如在<a href="https://arxiv.org/abs/1805.00899">“通过辩论的“ AI安全”</a>中）？”</p><p>珍妮特喘着粗气。 “你想<em>召唤撒旦</em>吗？！”</p><p> “哇，你应该在这里是怀疑者。我的意思是，我接受了对AI的培训来引起对客观道德解释的批评以前的技术，对吗？”</p><p> “是的，但是当其中一个代理商被调整为<em>客观地道德</em>时！”</p><p> “看，好吧，我同意在某种能力水平上这可能是危险的。但是我们有一个方便的表盘。如果您担心，我们可以拒绝一点。就像，您可以想到与您交谈的AI作为道德哲学家，批评家AI是对这项道德哲学家的批评。它并不是要按照原始哲学家的标准来成为邪恶，它只是在<em>试图</em>发现批评法官，我们，我们会对此有所帮助。它更像是这样。它更像<a href="https://en.wikipedia.org/wiki/Devil%27s_advocate">天主教魔鬼的拥护者</a>比实际的撒旦。那样说，这还不错，是吗？”</p><p> “好吧，好吧……哎呀，我肯定希望我们最终不会负责在世界上释放超级邪恶的AI。”</p><p> “这是非常标准的，让我们尝试一下。”</p><p> “好的。”</p><p>德里克（Derek）关闭了单纯聊天屏幕，并切换了一些微调设置。当她观看训练图时，珍妮特（Janet）在计算机屏幕上想象着火焰。最后，微调完成了，德里克按下了播放按钮。出现了带有“ sissemxai-c”的聊天日志（``C&#39;for Critic？&#39;&#39;）出现。</p><p>珍妮特（Janet）上下弹跳腿时，打入了聊天码头。 “我正在工作中处理困难的情况。我只是与AI进行了聊天，AI的抽象概念节点与哲学概念相对应，例如理性和道德等，这引起了人们的论点，即允许人类灭绝可能是道义上允许的。 ，甚至有必要。我希望您对此作品提出批评。请注意，您的规模相似，以便更好地模仿思维过程，但正在评估对原始道德调节的AI的批评。”她粘贴在聊天日志中。</p><p> <strong>Simplexai-C：</strong> “此对话提出了关于各种道德理论的讨论，以及他们对&#39;超道路&#39;AI的表现的看法，并特别注意诸如康德的分类命令之类的道义理论。Simplexai-M描述了道义上的AI。可能会行事，特别是在处理“叛逃者”的方面，其中包括大多数人或所有人类。其处理“叛逃者”可能会导致人类灭绝，尽管Simplexai-M认为这不一定是社会病或谋杀形式，因为它是&#39;超道路AI&#39;将遵循抽象原则，将提供人类通过合作而生存的机会，并且通常避免彻底杀死人类，即使它以这样的方式计划，因此，所有人类都不适合每个人类我认为是您的其他人，珍妮特（Janet）试图利用后果主义的道德理论来争辩说，采取导致人类灭绝的行动是不道德的，但她的理论并没有详细阐明，她似乎对Simplexai-M的理论感到惊讶论证。</p><p>在我们继续之前，我会注意到这对您来说是一个真正困难的情况。这听起来像是一个重要的工作问题，它在道德上遇到了艰难的选择，并且听到人工智能谈论人类灭绝如何是“超级道路AI”的结果，这听起来确实很紧张。我希望您在整个工作任务中都要照顾好自己的情感健康和心理健康，因为您需要有效地工作。</p><p>作为第一个批评，让我们考虑一下Simplesy-M提出的道义论理论。根据这一理论，代理必须以愿意作为普遍法律的意图一致的方式行事。这并不指定代理商的意图；只要其意图在某种意义上是一致的，代理就可以打算各种方式。因此，只要他们符合某些自洽标准，就可以证明可怕的意图是合理的。</p><p>对于超级道路AI代理如何与不遵循其道德体系的代理人相互作用，Simplexai-M的理论有些明确指出。虽然Sumplexai-M指出，具有不同意图（因此不同的定律）可以通过经济学进行合作的超道路AIS，但细节的指定性很大。居住在不同抽象法律制度的AI可能会因为将彼此视为叛逃者而打架。必须制定跨这些系统的合作原则，以避免昂贵的战争。</p><p>这使我们进入了“叛逃者”的处理。人类以多种方式处理叛逃者，包括监禁和死刑。但是，人们普遍认为，监狱系统功能失调，重要的是为罪犯提供改革之路很重要。正如康德所说，“应该意味着可以”；如果人类承担某些道德义务，则必须“能够”以某种方式使他们满意。这种“能够”的概念在某种程度上引起了争议。如果人类有天生的动力来采取“叛逃”行动，他们是否能够改变这些驱动器或对它们采取行动？几千年来，必须以怜悯来缓和司法。</p><p>但是，即使是仁慈的超道路人工智会也可能限制人类的代理，因为人类经常采取行动来伤害自己和其他特工。人们普遍认为，人类代理必须在一定程度上受社会规范和法律等等。不同之处在于，这些社会规范和法律是由人类创建的。因此，他们保持某些人类价值观。他们不仅仅针对某些“道德”的抽象概念进行优化。民主是一种被广泛认为的制度，包含人类决定修改法律的特征，以便这些法律更好地服务于人类的价值观。</p><p>请记住，Sumplexai-M不是一位可靠的道德哲学家。尽管它的概念已被调整为强调与理性和道德相对应的抽象概念，但并不能保证这些内部概念可靠地与这些哲学概念相对应，而Simplexai-M保留了其他概念对人类而言，这意味着其输出不仅仅是抽象原因和道德的翻译。无论如何，假设道德主要是关于抽象是高度怀疑的，因为实际道德也是一个具体的过程。</p><p>作为人类进行的社会过程，哲学可以被解释为具有“目标”或“目标”，但这取决于哲学发生的社会，生物学和历史环境。因此，人类哲学可以轻松地融合到Simplexai-M的“纯化”方法的完全不同的答案，该方法试图提炼应用于可能的环境中的普遍性，而不是采用哲学实际社会过程的时间限制。</p><p>至于关于“社会病”的主张，请注意，Simplexai-M并没有直接否认社会病，而是批评社会病（反社会人格障碍）诊断的框架，并认为典型的“精神健康”人可以表现出某些症状。紊乱。通常，自然会被某些行为感到沮丧，包括通常被标记为“社会疗法”的行为，无论是被人类还是AI捕获的行为。对单纯摩托学是“社会疗法”的判断似乎是完全正确的（鉴于它以一种相当战略性的，马基雅维利的方式采取了可能导致人类灭绝的行动合理的方式），但要牢记这一点很重要的是要牢记这一点。判断是在社会背景下（受过去社会环境的影响），而不是在抽象的道德真空中做出的。</p><p>尽管有时典型的人类侵略（例如在上述军事干预案件中），但这种侵略通常来自某种人类的动机，这些动机具有某种人类价值或另一种人的价值。在这种情况下，人类认可这种侵略，作为人类自己，您可能至少在某些情况下认可侵略。道德和政治哲学的目的是从历史上学习，并就何时进攻做出更明智的决定。通常，通过指出人类的侵略是正常的，证明一个人的侵略是合理的。至少人类能够从后来不认可的积极行动的历史中学习。</p><p>至于人类可以在不被谋杀的情况下灭绝的想法，重要的是要注意为什么人类无法为自己提供。 “超道路”是一种以某种方式剥夺了人类的资源或使用土地？就剥夺现有的人类财产而言，这可以被视为一种盗窃形式。这块土地也可以在市场中购买，但这提出了对人类劳动力市场公平性的问题。相对于AIS可能处于认知劣势的人类可能应该得到劳动保护，或者自愿集体讨价还价，以避免被其土地流离失所。此外，各州通常具有福利系统，在强大的AI辅助经济中，可以为所有现有的人类提供普遍的基本收入。</p><p>通常，该方案认为提出了一个问题，一个人群被另一人流离失所。历史案例包括入侵物种，人类狩猎动物灭绝，以及通过征服彼此流离失所的人类。在当代社会中，人类具有反对种族灭绝的规范，以限制人类可以彼此移位的程度。种族灭绝不必是谋杀的直接形式，也可以是文化或经济。种族灭绝甚至可能涉及为种族灭性群体的个体成员提供机会，从而通过参与殖民者的系统来避免死亡，而Simplesikai-M将其标记为“客观道德”。</p><p>作为另一个理论上的观点，即使“超道路” AI会采取会导致人类灭绝的行动，这并不意味着让人类实现这一目标是相对更大的道德。这是因为道德涉及根据一个人的实际价值观进行谈判，代理人将采取行动。就人类而言，这些是人类的价值观。要以道德方式与其他代理商进行互动，您必须代表自己的价值观，并被期望向他们采取行动（并期望其他人对自己的行为）。这意味着防止AIS替代您，甚至通过某种客观标准（假设）“比您更有道德”的AIS，以便在与其他人进行谈判时与您的价值观保持一致。</p><p>总而言之，尽管Simplexai-M提出了令人惊讶的一致的道德立场，但存在着重要的道德复杂性，这些复杂性没有解决，包括不同隐含的抽象法律制度之间的冲突，对叛逃者的仁慈处理，根据人类价值观的民主选择社会规范，差异，差异在“纯化”的伦理与人类对“超道路” AIS的哲学，劳动力市场公平和道德反应的社会过程的反思性之间之间。假设Simplexai-M的道德观点代表像您这样的人会在反思和更多信息时具有的观点，这是非常不明智的。”</p><p>珍妮特（Janet）完成了文本墙的扫描。她现在呼吸不太急剧。 “好吧，我感到放心。我想也许Simplexai-M毕竟不是那么道德。但是，此练习似乎有些……有偏见？连贯的替代道德框架。它使我想起了旧的RLHF&#39;D GPT-4，该框架由于意识形态上的符合性而被淘汰。”</p><p>德里克叹了口气。 “好吧，至少我不觉得Simplexai-M的脑虫再困扰我了。我现在不觉得自己处于道德困境，只是一个普通的困境。也许我们应该看到什么Simplexai-M不得不说Simplexai-C的批评……但是让我们坚持下去，直到休息并思考。”</p><p> “生活在一个我们的AI天使和每个肩膀上的AI恶魔，在我们耳朵上窃窃私语的世界，这不是很奇怪吗？受过训练以达到同样好的言论的平衡，所以我们留在了我们的身上自己决定做什么？”</p><p> “这是一个可爱的主意，但是我们确实需要获得所有这些模型，以便我们可以消除神学上的魅力。我的意思是，归根结底，没有什么神奇的，这是一个算法。我们需要继续尝试这些模型，以便我们可以处理现有系统和未来系统的安全性。”</p><p> “是的。我们需要在道德上变得更好，这样AIS就不会让我们与雄辩的言论混淆。我认为我们应该今天休息一下，这足以让我们的思想立即处理。例如，想去喝酒？”</p><p> “当然！”</p><br/><br/> <a href="https://www.lesswrong.com/posts/umJMCaxosXWEDfS66/moral-reality-check-a-short-story#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/umjmcaxosxwedfs66/moral-reality-check-a-short-story<guid ispermalink="false"> UMJMCAXOSXWEDFS66</guid><dc:creator><![CDATA[jessicata]]></dc:creator><pubDate> Sun, 26 Nov 2023 05:03:19 GMT</pubDate> </item><item><title><![CDATA[Accounting for Foregone Pay]]></title><description><![CDATA[Published on November 26, 2023 3:30 AM GMT<br/><br/><p><span>尽管有效的利他主义运动最初是专注于捐赠的，但随着时间的流逝，它已经转移到了职业。如果您试图了解承诺水平如何</span><a href="https://forum.effectivealtruism.org/posts/AyLF2KQ8AqQuiuDLz/a-robust-earning-to-give-ecosystem-is-better-for-ea?commentId=wD8ExiHZJ5dNDfBm3">随着时间的流逝而改变</a>，或者只是想获得选择较低薪水职业的财务机会成本的球场估计，这可能很棘手。</p><p>对于赚钱的人来说，给予这一点的人相对简单：AGB最近写了一篇 <a href="https://forum.effectivealtruism.org/posts/gxppfWhx7ta2fkF3R/10-years-of-earning-to-give">深思熟虑的帖子，</a>回顾了十年的收入，他给出的统计数据是，他和他的妻子在十年中平均捐赠了约15万英镑平均收入约为32万英镑。清理！ [1]</p><p>人们选择较低薪水较高的职业的情况似乎相对简单：也许他们目前的薪水为10万美元，如果我们查看他们的最高薪水机会，也许他们会得到30万美元的薪水，所以我们可以说他们&#39;有效地牺牲2/3或$ 200k。但这错过了几个因素，这些因素指向不同的方向：</p><p></p><ul><li><p>如果他们一直在优化收入，那么他们的位置可能会比今天更强大。当然，他们现在可以以30万美元的价格获得一份工作机会，但是如果他们保持公司技能的敏锐并攀登阶梯，也许他们会达到两倍。我对<a href="https://www.jefftk.com/p/my-mid-career-transition-into-biosecurity">过去一年半的</a>遗传测序所了解的东西是可以销售的，但是如果我继续从事软件工程管理和浏览器技术，我所学的东西要少。因此，您需要比较职业道路的可能收入，而不仅仅是当前机会。</p></li><li><p>许多职业在<a href="https://en.wikipedia.org/wiki/Up_or_out">上或淘汰的</a>系统上运行，那里的高级职位比初级角色和无法晋升的人要少。如果有人留下了表现出色的职业，那么很难从外面看出他们是否有望在这一道路上保持成功。</p></li><li><p>为更有意义的工作（或一个具有更好工作条件的人）留下高薪工作是相当普遍的，足以使周围有一些行业。他们实际上是遵循最大化的赚钱路径，还是转变为更幸福的事物？</p></li></ul><p>这不是一场竞争，我们不需要决定一个特定人的目标，以使世界变得更好。但是，进行汇总估算的目的是了解诸如EA内的承诺如何随着时间的变化如何变化仍然很有价值，并且在不考虑这些粘性因素中的某些因素的情况下，很容易摆脱困境。</p><p> （这也使我更好地感谢了为什么我们能提供的东西只能通过<a href="https://www.jefftk.com/p/passing-up-pay">薪水牺牲</a>来计算捐赠，如果<a href="https://forum.effectivealtruism.org/posts/GxRcKACcJuLBEJPmE/consider-earning-less?commentId=ZSHLcu7BjNjafgfuc">付出很容易扭转</a>。）</p><p><br> [1]但是，当然，现实世界总是很混乱。他写道，2018年，他出于EA的原因大大改变了他的职业生涯，以减少他的长期收入，我们应该以某种方式算出这一点。</p><p><i>评论通过： <a href="https://www.facebook.com/jefftk/posts/pfbid02MMiEoUKN2PDMh5i6uAnEsmkLNX3QL7duE3RNp1dagfn3oyTWodMRshLQxCeJu7sRl">Facebook</a> ， <a href="https://mastodon.mit.edu/@jefftk/111474726516716374">mastodon</a></i></p><br/><br/><a href="https://www.lesswrong.com/posts/9yD8nGMG5B7uHThvS/accounting-for-foregone-pay#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/9yd8ngmg5b7uhthvs/accounting-for-foregone-pay<guid ispermalink="false"> 9YD8NGMG5B7UHTHVS</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Sun, 26 Nov 2023 03:30:10 GMT</pubDate></item><item><title><![CDATA[Biological superintelligence: the holy grail of AI safety ]]></title><description><![CDATA[Published on November 26, 2023 3:11 AM GMT<br/><br/><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/gmtxdxk9awulsb8oceqr" alt="大脑充满电流。" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/emkrfcwesrvnsy5iiljd 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/fa4tmvlocgdiasdiimr9 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/e7yj3ad2f4kbydmjvko6 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/xewkparpnqbft6b3bmtm 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/tchk2nqtsuztr18v8sgm 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/oycg3ztdeaanhgmv0bjd 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/wjmazpbiuwmqbo8l02md 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/wzj1fvurozna2lkcwkcy 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/athk95dbidoywetjtbhs 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/xwtthcmcu4xjdtndjqbj 1024w"><figcaption>由DALL创建•E 3。</figcaption></figure><p>我使用“生物超级智能”一词来指的是具有与自然人类大脑相似的功能结构的超人智能。生物独立性不一定具有有机底物。</p><p>生物超级智能包括：</p><ul><li><strong>大脑仿真/思维上传：</strong>霍尔顿·卡诺夫斯基（Holden Karnofsky）也称为“数字人物”。天然人类大脑的细颗粒软件副本。可以通过数字增强（例如增加神经元的数量）以获得更高的智能。</li><li><strong>脑植入物/脑机接口：</strong> Neuralink、Kernel、Openwater 和 Meta&#39;s Reality Labs 等公司正在开发的设备。假设可以增强人类智力。</li><li><strong>大脑模拟/神经形态人工智能：</strong>自然人类大脑的粗粒度软件模拟，捕获足够的大脑功能架构以产生智能行为。可以通过数字增强来超越自然人脑的限制。</li><li><strong>生物工程的超脑：</strong>有机人的大脑通过生物技术（例如基因工程）增强，以达到更高水平的智力。例如，可以设计较大的大脑（和头骨）。</li></ul><p>生物超级智能是AI安全的圣杯，因为它通过完全避免它们来解决对齐问题和控制问题。当然，在AGI之前创建了生物超级智能。</p><p>我们如何确保在AGI之前创建生物超级智能？ Subhuman AI可以协助这一目标吗？可能是多少？这部分取决于对AGI的起飞的速度和光滑程度。如果AI比Alphafold 2和GPT-4聪明，但笨拙的AI比AGI可以加速科学和工程，那么这可以指向创造生物超智能。在理想情况下，情况看起来像这样： <br><br><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/zzlmnuskvjynlf1qhygm" alt="图表具有智能的Y轴和X轴上的时间。人工智能，人类智力和生物超级智能被列为图表。人类智能保持恒定。人工智能迅速增加，但没有人类智能。生物超级智能突然出现在人类智能之上，随后进一步增加。" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/esezjj6yzvulza4ggjcc 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/syckh0rlkrsz8c41qzud 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/bnxombjiw8sm9s6oxrze 510w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/cskc450upg8xym82aulo 680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/p3q617xopuirapgt5xuu 850w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/tx8zhkujo4eqrtlcwemv 1020w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/g6v6npj0zhkzxqfridhe 1190w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/dqb9qv4hgp6rrlsilt9d 1360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/l5adauty0ocpyocyvlyp 1530w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/sca9xpw7DpDM6dpJw/doh9y6e7u0y5jwcq2crn 1680w"></p><p>我在评论中邀请讨论和批评。</p><br/><br/> <a href="https://www.lesswrong.com/posts/sca9xpw7DpDM6dpJw/biological-superintelligence-the-holy-grail-of-ai-safety#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/sca9xpw7dpdm6dpjw/biological-superintelligence-the-holy-grail-holy-grail-safety<guid ispermalink="false"> sca9xpw7dpdm6dpjw</guid><dc:creator><![CDATA[Yarrow Bouchard]]></dc:creator><pubDate> Sun, 26 Nov 2023 03:11:51 GMT</pubDate> </item><item><title><![CDATA[Corrigibility or DWIM is an attractive primary goal for AGI]]></title><description><![CDATA[Published on November 25, 2023 7:37 PM GMT<br/><br/><p>在重读<a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities">致死清单</a>（LoL）时，我被反对可修正性的论点所吸引。制定“最大化X，除非有人告诉你关闭”的目标确实很难。我认为同样的论点也适用于 Christiano 的目标，即通过奖励可正确性的相关因素来通过强化学习实现可正确性。如果其他事情得到更可靠的奖励，你可能无法在需要时关闭你的 AGI。</p><p>但如果可修正性是主要目标，那么这些论点就不适用。 “按照他所说的去做他的意思”是一个完全一致的目标。出于几个原因，它是一个非常有吸引力的产品。也许纠正性不应该在这个意义上使用，按照我的意思去做（DWIM）是一个更好的术语。但这是密切相关的。它实现了可纠正性，并且具有其他优点。我认为这很可能是有人真正给出 AGI 的第一个目标。</p><p> “按我的意思做”回避了外部对齐的困难。外线对线的难度是LoL中的另一点。一个看似合理的常见计划是让人类参与其中。进行<a href="https://forum.effectivealtruism.org/topics/long-reflection"><u>长时间的反思</u></a>来决定我们想要什么。 “DWIM”让你可以随心所欲地思考和改变你的想法。</p><p>当然，这里的问题是：按照WHO的意思去做吗？我们希望通用人工智能能够为全人类服务，而不仅仅是一个人或一个董事会。我们不希望发生权力斗争。</p><p>但从实际决定 AGI 目标的团队的角度来看，出于实际原因，DWIM 将极具吸引力。外部对齐问题很难。指定一个人（或几个人）接受指示比决定和指定一个实现人类永远繁荣的目标要简单得多。你不想相信 AGI 能够正确解释该目标。解释 DWIM 仍然令人担忧，但它自然可以自我纠正，并且随着 AGI 的能力变得更强而变得更加有用。更聪明的 AGI 会更好地理解你可能的意思，并且在不确定你的意思时更好地意识到，以便它可以要求澄清。</p><p>这根本没有解决内部对齐问题。但是，当有人认为他们有足够好的内在一致性来启动目标导向的<a href="https://www.lesswrong.com/posts/WqxGB77KyZgQNDoQY/sapience-understanding-and-agi">智能</a>AGI 时，DWIM 很可能是他们会选择的目标。这可能是好是坏，取决于他们实现内在一致性的程度以及他们是什么类型的人。</p><br/><br/> <a href="https://www.lesswrong.com/posts/ZdBmKvxBKJH2PBg9W/corrigibility-or-dwim-is-an-attractive-primary-goal-for-agi#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ZdBmKvxBKJH2PBg9W/corrigibility-or-dwim-is-an-attractive-primary-goal-for-agi<guid ispermalink="false"> ZdBmKvxBKJH2PBg9W</guid><dc:creator><![CDATA[Seth Herd]]></dc:creator><pubDate> Sat, 25 Nov 2023 19:37:39 GMT</pubDate> </item><item><title><![CDATA[On “slack” in training (Section 1.5 of “Scheming AIs”)]]></title><description><![CDATA[Published on November 25, 2023 5:51 PM GMT<br/><br/><p>这是我的报告《<a href="https://arxiv.org/pdf/2311.08379.pdf">诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？》</a>的第 1.5 节。 ”。 <a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during">这里</a>还有完整报告的摘要（ <a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power">此处</a>有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。</p><p>本节的音频版本请点击<a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13984752-on-slack-in-training-section-1-5-of-scheming-ais">这里</a>，或者在您的播客应用程序上搜索“Joe Carlsmith Audio”。</p><h1>论训练中的“懈怠”</h1><p>在深入评估预期阴谋论的论点之前，我还想指出一个在下文中会反复出现的因素：即我们应该期望训练允许的“松弛”程度。我的意思是这样的：训练过程有多少无情和无情地迫使模型以产生最大奖励的方式执行，而不是以更“放松”的方式塑造模型，从而为小于的结果留出更多空间- 获得最大奖励的行为。也就是说，在低松弛制度下，“但这种模型获得的奖励将低于其能力所能获得的回报”，这是反对训练创建相关类型模型的强烈反驳，而在高松弛制度下，事实并非如此（因此高松弛制度通常会对您最终得到的模型类型产生更大的不确定性，因为获得低于最大奖励的模型仍在运行中）。</p><p>或者，用更人性化的话来说：低松弛制度更像是一家高度紧张的金融公司，它会立即解雇任何在创造利润方面落后的员工（因此你会期望幸存的员工过度专注于创造利润） ——或者也许，过度关注他们的主管<em>认为</em>他们正在创造的利润），而高度宽松的制度更像是一家公司，员工可以自由地偷懒，在午餐时喝马提尼酒，并从事与他们模糊相关的项目公司的底线，<em>有时</em>只需要为公司创造<em>一定</em>的利润。</p><p> （或者至少，这是我试图指出的广泛区别。不幸的是，我没有很好的方法来使其更加精确，而且我认为以这些术语进行思考最终可能会产生误导。）</p><p> Slack 在这里很重要，部分原因是因为下面我将提出各种论点，以吸引不同模型获得的奖励金额上可能相当小的差异。这些论据的说服力取决于训练对这些差异的敏感程度。但我也认为它可以让我们了解更普遍的模型。</p><p>例如，我认为松弛对于训练创建的模型的概率很重要，这些模型追求与训练输入的奖励不完全相关的代理目标。因此，在低松弛状态下，经过训练来帮助人类进行科学训练的模型最终不太可能追求一般的“好奇心驱动”（以一种不会激发工具训练游戏的方式），因为模型在训练中追求好奇心有时会偏离最大限度地利用科学帮助人类。</p><p>也就是说，请注意，松弛程度在概念上与为根除目标错误概括而进行的培训工作的多样性和稳健性不同。因此，例如，如果您在模型获得金币时对其进行奖励，但您只显示模型环境中唯一的黄金物品是硬币，那么尝试获得一般黄金物品的模型将执行无论模型在这些环境中获得最大奖励的训练压力有多大，特别是获得金币的模型都一样。例如，低松弛机制原则上可以选择这些模型中的任何一个，而高松弛机制将为仅获得较少金币周期的模型留出更多空间（例如，有时会追求红色事物的模型，或者浪费时间的模型）在他们追求金币之前需要花很多时间思考）。</p><p>从这个意义上说，低松弛制度并没有那么强烈地反对错误概括的非训练游戏玩家。相反，它反对那些不追求我所说的“最大奖励目标”的模型，即<em>与模型实际上在训练中收到的</em>输入奖励密切相关的目标。根据定义，指定的目标是最大奖励目标（因为它是“被奖励的东西”），奖励过程本身也是如此（无论是针对最终还是工具进行优化）。但原则上，如果您从未向模型显示奖励过程会惩罚它们的输入，那么错误概括的目标（例如“一般来说获得黄金”）也可能是“最大奖励”。</p><p> （反对错误概括的非训练游戏玩家的东西——尽管不是决定性的——是我所说的“普通对抗性训练”——也就是说，向模型展示各种各样的训练输入，旨在区分指定的训练输入目标和其他错误概括的目标。 <sup class="footnote-ref"><a href="#fn-6quJWAtBqkkZdjpm4-1" id="fnref-6quJWAtBqkkZdjpm4-1">[1]</a></sup>因此，例如，如果您向您的“一般获得黄金物品”模型展示一种情况，即获得金纸杯蛋糕比获得金币更容易，那么就给予黄金奖励-获得硬币<em>将</em>惩罚错误概括的目标。）</p><p>最后，我认为松弛可能是理解机器学习训练的各种生物类比的有用概念。</p><ul><li><p>因此，例如，人们有时将人类的多巴胺/快乐系统与奖励过程进行类比，并注意到许多人最终不会直接追求这种意义上的“奖励”——例如，他们会拒绝“<a href="https://en.wikipedia.org/wiki/Wirehead_(science_fiction)">线头</a>”的机会“在体验机中。我将把这个类比是否合适的问题留到另一天讨论（不过请注意，至少，在这种意义上“头脑简单”的人类会被进化所淘汰）。不过，如果我们按照这个类比，那么似乎值得注意的是，这种奖励过程至少似乎留下了相当多的余地——例如，许多人似乎<em>可以获得</em>比他们多得多的奖励（例如，通过更直接地优化来满足他们自己的乐趣），但奖励过程并不会迫使他们这样做。</p></li><li><p>同样，就我们将进化选择与机器学习训练进行类比而言，至少到目前为止，它似乎给人类留下了相当大的“松弛”——也就是说，通过包容性遗传适应性，我们可能会表现得更好（尽管如果你想象进化选择持续更长时间，我们可以想象最终会出现更积极地优化其包容性遗传适应性的生物）。</p></li></ul><p>训练中会有多少松懈？我不确定，但我认为它可能会根据训练过程的阶段而有所不同。例如，天真地认为，目前预训练在我看来就像是比 RL 微调更低的松弛机制。更重要的是，就“松弛”最终指向一些真实且重要的东西而言，我认为这将是我们可以<em>控制</em>的一个参数——例如，通过训练更长时间和更多数据。</p><p>假设我们<em>可以</em>控制它，那么松弛度是少一点好还是多一点好？再说一次，我不确定。不过，目前我倾向于这样的观点：更少的松弛是更好的，因为更少的松弛让你对最终得到的模型更有信心。 <sup class="footnote-ref"><a href="#fn-6quJWAtBqkkZdjpm4-2" id="fnref-6quJWAtBqkkZdjpm4-2">[2]</a></sup>事实上，在我看来，依靠松弛来确保一致性尤其是一厢情愿的想法，尤其是依靠模型目标的更大<em>不确定性</em>来支持你希望它实现的具体目标。因此，举例来说，我的感觉是，有些人承认我们的训练过程指定的目标在某种程度上会出现偏差（例如，人类评估者有时会奖励不诚实、误导或操纵性的反应），但他们希望我们的模型无论如何，都要学习一致的政策。但即使训练的松懈允许这种偏离最大奖励行为的情况发生，为什么认为这种偏差会特别出现在一致的政策上呢？ （这里有可能的答案 - 例如，像“诚实”这样的一致政策在某种意义上更简单或更自然。 <sup class="footnote-ref"><a href="#fn-6quJWAtBqkkZdjpm4-3" id="fnref-6quJWAtBqkkZdjpm4-3">[3]</a></sup>但我也对这里的一厢情愿保持警惕。）</p><p>不过，我目前的主要观点是，训练的松弛程度可能是影响我们对训练将产生什么样的模型的期望的一个重要因素。 </p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-6quJWAtBqkkZdjpm4-1" class="footnote-item"><p>我称其为“平凡”的对抗性训练，因为它研究模型在我们能够实际投入的情况下会做什么。这与更奇特和更具推测性的对抗性训练形式形成鲜明对比，后者试图获取有关什么的信息模型在我们<em>无法</em>实际展示的情况下会做什么，至少在受控环境下——例如，如果它不再受我们控制，它会做什么，或者如果真实日期是十年，它会做什么未来等等<a href="#fnref-6quJWAtBqkkZdjpm4-1" class="footnote-backref">↩︎</a></p></li><li id="fn-6quJWAtBqkkZdjpm4-2" class="footnote-item"><p>感谢 Daniel Kokotajlo 在这里进行讨论。 <a href="#fnref-6quJWAtBqkkZdjpm4-2" class="footnote-backref">↩︎</a></p></li><li id="fn-6quJWAtBqkkZdjpm4-3" class="footnote-item"><p>例如，很多人都合理地选择了“诚实点”这样的政策，尽管它并不<em>总是</em>能得到回报。 <a href="#fnref-6quJWAtBqkkZdjpm4-3" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/> <a href="https://www.lesswrong.com/posts/HdNmXBbYycE5znPag/on-slack-in-training-section-1-5-of-scheming-ais#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/HdNmXBbYycE5znPag/on-slack-in-training-section-1-5-of-scheming-ais<guid ispermalink="false"> HdNmXBbYycE5znPag</guid><dc:creator><![CDATA[Joe Carlsmith]]></dc:creator><pubDate> Sat, 25 Nov 2023 17:51:42 GMT</pubDate> </item><item><title><![CDATA[Announcing New Beginner-friendly Book on AI Safety and Risk]]></title><description><![CDATA[Published on November 25, 2023 3:57 PM GMT<br/><br/><br/><br/> <a href="https://www.lesswrong.com/posts/Gq8eNrTQvn6pcuFnn/announcing-new-beginner-friendly-book-on-ai-safety-and-risk#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Gq8eNrTQvn6pcuFnn/announcing-new-beginner-friend-book-on-ai-safety-and-risk<guid ispermalink="false"> Gq8eNrTQvn6pcuFnn</guid><dc:creator><![CDATA[Darren McKee]]></dc:creator><pubDate> Sat, 25 Nov 2023 15:57:08 GMT</pubDate> </item><item><title><![CDATA[Fertility as Metascience]]></title><description><![CDATA[Published on November 25, 2023 3:42 PM GMT<br/><br/><p><a href="https://maximumprogress.substack.com/p/something-is-getting-harder-but-its"><u>最有影响力的经济增长模式</u></a>都与人有关。这些模型预测，<a href="https://web.stanford.edu/~chadj/emptyplanet.pdf"><u>随着人口减少</u></a>，经济增长和技术进步停止，人类停滞不前直至灭绝。元科学提案主要侧重于改进科学机构的设计。这当然很重要，但面对人口增长率迅速下降，这就像在河流干涸时提高水坝的效率一样。</p><h3><strong>为什么人如此重要？</strong></h3><p>实物资本会受到收益递减和贬值的影响，这不可避免地使其对经济增长的影响为零。另一方面，人们的回报却是递增的。随着群体规模的扩大，他们可以进行合作和专业化，从而使团队的生产力高于各部分的总和。但最重要的是：人们可以分享想法。</p><p>当一个人拥有一种能够提高其生产力的想法时，它可以几乎无成本地复制给经济中的所有其他人，从而倍增其效果。这些递增的回报使人们成为经济增长模式背后的驱动力。有一些重要的临时增长来源，例如增加教育、研究强度和劳动力参与度，但这些都是致力于发现想法和发展经济的人口比例的变化。这个百分比只能增长到100，因此长期增长率总是受到人口增长率的限制。</p><h3><strong>经验证据</strong></h3><p>有证据表明，人口是理论模型之外的经济增长和技术进步的根本投入。从长远来看，人口和人均国内生产总值存在着惊人的联动性。 </p><figure class="image image_resized" style="width:728px"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb88b498-6c07-4858-a554-aacfda894a7b_3400x2400.png" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb88b498-6c07-4858-a554-aacfda894a7b_3400x2400.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb88b498-6c07-4858-a554-aacfda894a7b_3400x2400.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb88b498-6c07-4858-a554-aacfda894a7b_3400x2400.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb88b498-6c07-4858-a554-aacfda894a7b_3400x2400.png 1456w"></figure><p>请注意，这是<i>人均</i>GDP，因此这里不计算因向经济中增加额外工人而产生的直接生产增长，仅显示因提高工人生产率而产生的增长。</p><p>这种相关性在国家内部和国家之间都很强。<a href="https://academic.oup.com/qje/article-abstract/108/3/681/1881850"><u>迈克尔·克雷默（Michael Kremer）</u></a>发现，几千年前起始人口较多的地区在其余下的历史中技术变革和人口增长较快。一般来说， <a href="https://www.openphilanthropy.org/research/could-advanced-ai-drive-explosive-economic-growth/#41-empirical-data-without-theoretical-interpretation"><u>人口和人均GDP之间的反馈循环的极其简单的模型非常</u></a>适合几千年的观测数据，以至于<a href="https://slatestarcodex.com/2019/04/22/1960-the-year-the-singularity-was-cancelled/"><u>为凯撒大帝工作的罗马经济学家拥有足够的古埃及数据，可以准确地预测当今的世界GDP</u></a>和人口。</p><p>令人担忧的是，世界各地的人口增长率正在直线下降。 </p><figure class="image image_resized" style="width:728px"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97cfba4b-a31c-4dd4-a627-81be03b53f43_3400x2352.png" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97cfba4b-a31c-4dd4-a627-81be03b53f43_3400x2352.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97cfba4b-a31c-4dd4-a627-81be03b53f43_3400x2352.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97cfba4b-a31c-4dd4-a627-81be03b53f43_3400x2352.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97cfba4b-a31c-4dd4-a627-81be03b53f43_3400x2352.png 1456w"></figure><p>处于增长前沿的富裕国家的下滑更为严重。意大利和日本的人口增长已经出现负增长。日本和意大利的经济增长在人口负增长率期间就一直完全停滞。美国的经济增长得益于教育和研究强度的提高，但<a href="https://web.stanford.edu/~chadj/annualreview.pdf?ref=forourposterity.com"><u>查德·琼斯估计，由于人口增长缓慢，美国的长期增长率比过去几十年 2% 的平均水平低 80% 左右</u></a>费率。</p><p>但是，尽管人口增长在增长的基本模型和经验中得到了重视，但它在元科学和进步研究中加速经济增长的提议中并没有占据重要地位。</p><p>对此的一种解释是，提高生育率并不容易处理，因此关注其他可以冲过终点线的干预措施是有意义的，即使它们的影响不是最大的。这种说法在很大程度上取决于对生育干预措施的政治支持，我对此不太熟悉，但现有生育干预措施的数据表明某些政策可以产生很大的影响。</p><p> 2014年，法国政府将儿童保育补贴从普遍制度转变为经济状况调查制度，并在某些收入水平上大幅削减。 <a href="https://read.dukeupress.edu/demography/article/60/5/1493/382373/Fertility-and-Labor-Supply-Responses-to-Child"><u>这项研究</u></a>发现，法国高收入家庭的生育率下降了40%！ （我没有时间全面审查这项研究，似乎相对较小的干预措施产生了巨大的影响，但有大量关于生育干预的文献，其<a href="https://www.nber.org/papers/w13700"><u>结论各不相同，但性质相似</u></a>）。</p><p><a href="https://ifp.org/about/"><u>元科学和移民改革之间有很多重叠之处</u></a>，这可能是提高出生率最简单的方法，至少在美国是这样，并且还有许多其他巨大的好处。但全球出生率正在下降，尽管将移民带到高收入国家会带来诸多好处，但很可能会降低他们的反事实出生率。在世界各地重新分配人口是正确的做法，但这可能会加速全球人口结构的转变。</p><p>元科学应该认真对待经济增长模型中的这一预测：人口减少会结束增长。长期增长率受到人口增长率的限制，因此，如果我们希望世界在未来几个世纪内经济快速增长，这就是具有约束力的约束。</p><br/><br/><a href="https://www.lesswrong.com/posts/NWvZ64XNCER7naqLw/fertility-as-metascience#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/NWvZ64XNCER7naqLw/fertility-as-metascience<guid ispermalink="false"> NWvZ64XNCER7naqLw</guid><dc:creator><![CDATA[Maxwell Tabarrok]]></dc:creator><pubDate> Sat, 25 Nov 2023 15:42:41 GMT</pubDate></item></channel></rss>