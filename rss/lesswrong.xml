<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 10 月 14 日星期六 18:14:09 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Meta Alignment: Education]]></title><description><![CDATA[Published on October 14, 2023 5:48 PM GMT<br/><br/><p>认知状态：不严格。充满了一个大部分时间担心、其余时间焦虑的人的猜测。显而易见。</p><p><a href="https://twitter.com/littIeramblings/status/1708945586496446796">这篇文章</a>是由“别担心花瓶的<a href="https://thezvi.wordpress.com/2023/10/05/ai-32-lie-detector/">每周人工智能更新”</a>提供的，它似乎表明了一个受过合理教育的普通人会对所有这些对齐/x-风险/AI-毁灭性的东西做出反应。这似乎是第一次在媒体上流传，而我们却一直处于错误较少的相邻泡沫中。</p><p>我不禁想起了我在 lesswrong 中发表的评论：</p><p> <i>“最近我越来越欣赏我开始称之为“元对齐”的东西。就像，对于涉及人工智能的所有事物，我们必须确保事物的对齐程度刚好，不会搞乱或“错位”对齐项目。例如，我们需要谨慎对待围绕一致性的讨论，因为我们可能会给那些自己对政策进行投票或在人工智能/人工智能相关领域工作的人给出错误的想法。或者政策需要仔细调整，这样就不会产生不一致的激励措施，从而扰乱调整项目；与人工智能合作的公司的政策也是如此。这可能是一个显而易见的说法，但我越想越觉得这是一个令人畏惧的前景。”</i></p><p>教育很重要。教育导致政策。政策带来资金。政策可能会导致暂停。暂停可能会增加我们的生存机会。教育和资助导致研究。研究可能会带来答案。答案可能会带来生存。</p><p>最近，在读一本关于博弈论和人类行为的书时，我想到了人们在谈论人工智能对齐时经常听到的一个短语——“效用函数”。它经常被用来描述代理的“偏好”，并且为了准确起见，通常会选择它而不是“偏好”，因为代理不会简单地喜欢一件事，也不会简单地“喜欢”做我们告诉它的事情。如果在播客中向他们抛出这个词，有多少外行人会认识到这个词的含义及其含义？在辩论中？在政策讨论中？</p><p>我没有社交媒体，更没有本科生大军，所以我无法进行全面的调查。我只是问了一些与我关系密切的人以下问题。</p><p> “如果我说“人工智能不关心人类；它不关心人类”。它只关心实现自己特定的效用函数。”如果不查任何资料，你会认为“效用函数”一词意味着什么？”</p><p>请记住，我询问的人比普通美国公民受教育程度更高。我问过的每个人都至少有过一年的大学经历。该群体中受教育程度最高的是教育学硕士学位。其中还有两个计算机科学学位。所有受访者都熟悉计算机工作，其中一半曾在某一方面专业地使用过计算机。所有回复均通过短信非正式发送。</p><p>回复（包括 SP - 这是通过文本）：</p><ol><li>使用</li></ol><p>如果人工智能真的可以“关心”</p><ul><li>它被编程来做什么？我不太了解人工智能所以很难回答。</li><li>吸收所有信息以提供问题的答案。</li></ul><p> …人类在问什么🤷🏻‍♀️</p><ul><li>我认为实用功能是编码到机器的目的，或者就像人工智能的默认功能一样。</li><li>它按照编程的方式执行操作。做</li><li>这就是对齐的核心复杂之处，不是吗？</li></ul><p>我按原样接受了答案，并没有要求任何人澄清他们的陈述，因为担心会让他们得出特定的结论——这些是原始答案。我发现它们很有说服力。让我们来看看答案。</p><p>答案1.使用</p><p>如果人工智能真的可以“关心”</p><p>我预计这是最常见的答案。对于大多数人来说，“效用”和“功能”这两个词具有相同的含义，归根结底都是有用的。因此，我最初的说法对于外行人来说可能听起来像是“人工智能不关心你，它只关心对它有用的东西。”这并不是一个不合理的解释。关键在于——人工智能如何确定什么是有用的，什么是无用的？它从何而来？</p><p>回答 2. 它被编程来做什么？我不太了解人工智能所以很难回答。</p><p>答案 5. 它按照编程的方式执行。做</p><p>这些答案反映了大多数拥有计算机知识和经验的人所期望的——他们按照我们告诉他们的去做。我们有能力介入并摆弄他们的编程并改变或改进，并最终控制他们。</p><p></p><p>我认为，计算机只是按照我们编程的方式去做的想法是教育公众了解对齐问题以及我们面临的人工智能危险的最大问题之一。他们从经验中了解到，计算机是我们控制的东西，因此很难概念化计算机朝某个奇怪的方向发展，除非有一些容易修复的错误。如果它不能正常工作，只需拔掉插头即可。</p><p>这也可能是人们比人工智能本身更担心坏人的原因。我们是好人，所以我们会创造一个好的人工智能。我们需要在坏人创造出坏人工智能之前做到这一点。</p><p>答案 4. 我认为效用函数是编码到机器中的目的，或者就像人工智能的默认函数一样。</p><p>一个相当好的答案——这里可以理解，效用函数归结为机器的“目的”。但问题仍然是我们正在对其进行编码的假设。我们控制它。尽管受访者确实反映，也许这些功能是默认的，但不知道“默认”从哪里来，如果不是硬编码到机器中的话。</p><p>答案 6. 这就是对齐的核心复杂之处，不是吗？</p><p>我想知道是否应该包含这个答案，但为了完整起见，我会这样做。这个名单上的每个人都曾在某个时候听过我谈论人工智能，但这位受访者听过我对它的咆哮最多。</p><p>答案 3. 吸收所有信息以回答问题。</p><p> …人类在问什么🤷🏻‍♀️</p><p>我应该为这个答案负责，因为我没有指定我想要效用函数的<i>定义</i>，而不是效用函数实际上是什么。</p><p>按原样考虑答案，这是一个合乎逻辑的假设。法学硕士的目的是吸收信息并提供问题的答案。很难表达为什么效用函数会演变成我们意图的游乐场镜像版本，我看到很多教育工作者试图解释这是如何发生的。人们想要知道人工智能的目的为何会出错的具体原因，这会导致我们陷入打地鼠的境地；我们看到人工智能的效用函数可能会偏离一个方向，所以我们修补它，然后它转向另一个方向，我们一遍又一遍地修补它，直到我们感觉非常安全。然后人工智能杀死了我们。</p><p></p><p>更深入地研究人们所知道的以及他们据此相信的可能是生存的关键。</p><p> #</p><p>清晰的语言很重要，但几乎不可能。人工智能研究人员拥有可以让他们之间进行清晰沟通的工具，例如共享词汇和他们想法的数学表示。人工智能教育工作者没有这些可用的工具。对于公众来说，同一个词可能意味着许多不同的事物，具体取决于上下文、个人背景、教育水平以及基于不同经验和文化的假设。共同的国家语言甚至不能被视为理所当然。数学的通用语言在公共教育中几乎毫无用处，而且在完成学校必修的数学课程后，大多数人将这个工具放在衣柜后面，坚信他们永远不会真正“需要”再来一次。</p><p>试图找到一组单词、短语和例子来足够准确地表达你的观点，以启发和说服大多数听众，这是一个令人畏惧的前景，我不是来提供它们的。事实是，为了让外行人理解一个概念，一致性是关键。越多的人在同一概念中看到相同的单词和短语，他们就越会建立一个可以遵循的共享词典，因此最好继续使用我们一直在使用的相同单词和短语。并尝试用这些词来描绘一幅图画。</p><p>真正的问题是，是否有足够的时间来用通常的方法来建立一个共享词典，解释所有使用的术语，并重复它们足以饱和一般意识，就像科学家几十年来所做的那样。我不敢打赌还剩下多少时间。可能有一些关键的公共影响者能够最好地传播信息，但这些影响者可能没有太大影响力，因为他们在广播中充斥着合理的言论。信息不仅必须易于理解，还必须具有<i>模因性。</i></p><p>该信息还必须具有<i>说服力。</i>仅仅理解这些概念是不够的，公众必须相信它们。而且信念必须足够强大才能<i>感动</i>他们。信念有一个金发姑娘区；它必须足够强大以激发行动，但又不能强大到让公众放弃、屈服并屈服于虚无。</p><p>我想有很多气候变化教育工作者可能会说“当你弄清楚这一点时，请告诉我们。”如果我看到了一条希望之路，那就是人工智能联盟似乎并不能对抗一群不良行为者产生的错误信息。那些误会的人？当然。为了维护社会地位而轻蔑的人？绝对地。但并非恶意。我希望还没有。</p><p>但我至少希望当前局势的地图能够有所帮助。教育工作者需要选择清晰、一致和近乎通用的语言来教育<i>和</i>说服公众。信息必须易于传播，并且信息必须尽快到达正确的人手中。</p><p>正如我之前提到的，我没有社交媒体，也没有本科生大军。然而，即使假设 AGI/ASI 建立的时间框架有限，我认为遵循明显的后续步骤也很重要：即对人们如何理解人工智能中的关键短语和概念进行实际调查和研究，对信息进行聚类通过人口统计数据，根据这些人口统计群体过滤您的信息，并在与公众沟通时根据预期受众进行调整。</p><br/><br/><a href="https://www.lesswrong.com/posts/eAE2igpggvdkJxXtc/meta-alignment-education#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/eAE2igpggvdkJxXtc/meta-alignment-education<guid ispermalink="false"> eAE2igpggvdkJxXtc</guid><dc:creator><![CDATA[Bridgett Kay]]></dc:creator><pubDate> Sat, 14 Oct 2023 17:48:16 GMT</pubDate> </item><item><title><![CDATA[ChatGPT tells 20 versions of its prototypical story, with a short note on method]]></title><description><![CDATA[Published on October 14, 2023 3:27 PM GMT<br/><br/><p><a href="https://new-savanna.blogspot.com/2023/10/chatgpt-tells-20-versions-of-its.html"><i>从新稀树草原</i></a><i>交叉发布</i><i>。</i></p><p>新的工作文件。上面是标题，下面是链接、摘要和介绍。</p><p> <a href="https://www.academia.edu/108129357/ChatGPT_tells_20_versions_of_its_prototypical_story_with_a_short_note_on_method">Academia.edu：https://www.academia.edu/108129357/ChatGPT_tells_20_versions_of_its_prototype_story_with_a_short_note_on_method</a><br> SSRN：https: <a href="https://ssrn.com/abstract=4602347">//ssrn.com/abstract=4602347</a><br> ResearchGate： <a href="https://www.researchgate.net/publication/374723644_ChatGPT_tells_20_versions_of_its_prototypical_story_with_a_short_note_on_method">https://www.researchgate.net/publication/374723644_ChatGPT_tells_20_versions_of_its_prototropic_story_with_a_short_note_on_method</a></p><p><strong>摘要：</strong> ChatGPT 用一个简单的故事来响应提示“故事”。在单个会话中由该提示引发的 10 个故事比在其自己的会话中每个故事引发的 10 个故事具有更多的主角多样性。原型：19 个故事讲述主角冒险进入世界并学习造福社区的事物。 ChatGPT 对这个简单提示的响应为我们提供了有关底层模型结构的线索。</p><h2><strong>简介：ChatGPT 的原型故事是关于探索的</strong></h2><p>我从今年（2023年）1月初开始系统地调查ChatGPT的讲故事行为。 [1]我在三月初发表了一份工作论文，开始梳理这种行为的一些规律。[2]有人可能会说我正在寻找 ChatGPT 的故事语法，但该术语具有错误的含义，因为它的起源可以追溯到 20 世纪 70 年代的符号计算工作。我很确定这不是 ChatGPT 生成故事的方式。只是它在做什么，还不太清楚。目前我倾向于认为它更像是一个表观遗传景观： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LK8R8YmndScXjeynx/bcbnhzvxskxhaih241p7" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LK8R8YmndScXjeynx/gu8mjzcy3lcp9zvqyrfl 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LK8R8YmndScXjeynx/t9obgone2c1nnvetaoei 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LK8R8YmndScXjeynx/qxsmi8v1rw03efqi1miq 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LK8R8YmndScXjeynx/f1apf1xvtlvodjoau7py 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LK8R8YmndScXjeynx/rd1bz9bb3t7ld2j1gmvb 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LK8R8YmndScXjeynx/sb6tuhqdrjwxjwpgyjrc 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LK8R8YmndScXjeynx/l6izedpp0wvzuoa4rkdy 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LK8R8YmndScXjeynx/ucfnecolnvqf7uvwg4pl 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LK8R8YmndScXjeynx/camorhrsut37vnniugay 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LK8R8YmndScXjeynx/zs16t8pjfh3bvmu3f1a6 1500w"></figure><p>然而，这种讨论远远超出了本简介的范围。</p><h3><strong>二十个故事</strong></h3><p>本介绍是关于今天早上（10.13.23）我让 ChatGPT 生成的 20 个故事。每个故事都是由一个词生成的：故事。我在一个会话中生成了前十个故事，而我对最后十个故事中的每一个都使用了单独的会话。我为什么要做出这样的区分？我知道 ChatGPT 在响应提示时会考虑迄今为止的整个会话，因此我认为在单个会话中生成许多故事会对故事产生一些影响。我推测，在单个会话中生成的 10 个故事之间的多样性会比每个故事在其自己的会话中生成的 10 个故事之间的多样性更大。</p><p>快速浏览一下这 20 个故事中的主角就会发现这是真的。前 10 个故事中有两个主角名为“Elara”，而已发送的 10 个故事中有 5 个故事的主角名为“Elara”。然而，这种快速而肮脏的评估需要通过进一步的分析来证实。</p><p>我进一步指出，除了一个故事外，所有故事都以童话世界为背景，充满魔法和超自然现象，讲述了一位主角出去以这样或那样的方式探索世界，然后回到家乡，丰富了这片土地。例外的是第一集的第六个故事“莉莉闯城市花园”（提供故事名称）。在这个故事中，莉莉遇到了一位名叫贾斯珀的艺术家，他们到处画粉笔画，并教别人这样做。故事中没有超自然或神奇的现象。</p><p>既然“故事”这一单字提示对 ChatGPT 没有任何限制，为什么 ChatGPT 又回到了那种故事呢？在没有任何进一步信息的情况下，我不得不假设这种故事是 ChatGPT 在训练期间遇到的所有故事的抽象。实际上，这就是 ChatGPT 的典型故事。</p><p>想一想。 ChatGPT 核心的大语言模型 (LLM) 是由 GPT 引擎创建的，其任务是预测输入字符串中的下一个单词。这些字符串来自语料库中的数百万条文本，其中包含了万维网上公开可用的文本的很大一部分。原型故事是模型对单个词“故事”的响应，因此以某种方式体现了有关故事的预测信息。</p><p><i><strong>事实上，ChatGPT 会根据提示“故事”生成特定的通用故事，这是有关底层模型结构的线索。</strong></i></p><p>但值得注意的是，ChatGPT 是对底层 LLM 进行修改和微调的结果，使其更适合对话交互。我认为这些修改对其讲述的故事类型产生了一些影响，更不用说允许讲述了，因为某些主题已被禁止。我还注意到，显然，ChatGPT 并不局限于讲述一种故事，但你需要做出进一步的规范来引出其他类型的故事。</p><p>然而，应该非常清楚的是，无论 ChatGPT 在做什么，它都不是一种表述中的“随机鹦鹉”，也不是另一种表述中的“类固醇自动完成”。 ChatGPT 的语言模型具有大量的结构，正是这种结构使其能够生成连贯的散文。我进一步认为，通过系统地研究它生成的文本类型，我们可以对这种结构了解很多。这就是我一直在做的故事。</p><h3><strong>机械解释及超越</strong></h3><p>我们才刚刚开始弄清楚预测下一个单词这一简单任务是如何在如此复杂和精密的模型中产生的。理解这些模型的工作原理很复杂，而且手段和方法也并不明显。所谓机械解释的学生喜欢“打开引擎盖”，这样他们就可以观察发动机，戳戳它，看看它是如何工作的。但这还不足以弄清楚发生了什么。</p><p>除非您知道该机制正在尝试做什么，否则您无法理解该机制的各个部分正在做什么。在<i>《思维如何运作》</i> （第 22 页）一书中，史蒂文·平克 (Steven Pinker) 要求我们想象自己在一家古董店：</p><blockquote><p> ...在一家古董店，我们可能会发现一个难以理解的装置，直到我们弄清楚它的设计用途。当我们意识到这是一个橄榄去核器时，我们突然明白了金属环是用来固定橄榄的，杠杆通过一端降低X形刀片，通过另一端将核推出。弹簧、铰链、叶片、杠杆和环的形状和排列都在令人满足的洞察力中有意义。我们甚至了解为什么罐装橄榄的一端有一个 X 形切口。</p></blockquote><p>为了详细说明这个例子，并将其用作机械可解释性的类比，对机制有良好感觉的人可以告诉你很多关于这个奇怪装置的部件如何铰接、每个部件的运动范围、工作压力的信息。每个关节上的移动部件所需的力量等等。但是，当你把所有这些放在一起时，仍然无法告诉你该设备的设计目的。</p><p>我相信，对于大型语言模型（以及其他类型的神经网络模型）的机制研究也是如此。这些模型与橄榄去核器或内燃机等机械设备有很大不同。它们的部分是信息性的、比特和字节，而不是物理对象，而且它们的数量还有更多，正如卡尔·萨根曾经说过的“数十亿”。此外，橄榄核和内燃机是由人类工程师设计的，而法学硕士则不是由任何人设计的。相反，它们是通过一个由工程师和科学家设计的软件引擎“消耗”大量文本的过程而演变的。由此产生的模型非常奇怪，它的“黑匣子”性质使得我们有必要研究它产生的文本的结构。</p><p>当然，不同类型的学者研究语言和文本已有数十年甚至数百年的历史，但仍有许多谜团。然而，我们可以用我们无法与人类及其文本合作的方式与法学硕士合作。我使用 ChatGPT 进行的系统性文本生成对于人类生成的文本来说即使不是不可能，也是很困难的。我设计了一些任务（有些简单，有些不是），以暴露文本中的“关节”的方式对 ChatGPT 施加“压力”，为我们提供有关潜在机制的线索（“在关节处雕刻自然”，柏拉图，斐德罗） 。此外，虽然我们可以很容易地对法学硕士“揭开面纱”，但我们不能对人类做到这一点。</p><p>没有理由认为我们不能通过使用和扩展我用于研究 ChatGPT 的技术并将其与机械可解释性工作相结合，在理解 LLM 方面取得进一步进展。这两条调查路线是必要且相辅相成的。</p><p> ** ** ** **</p><p>请注意这些故事：我于 2023 年 10 月 13 日上午在上午 7:15 开始的会议中生成了所有这些故事。 ChatGPT 9 月 25 日版本正在运行。</p><h3><strong>参考</strong></h3><p>[1] 在我的博客 New Savanna 上点击“ChatGPT Stories”的链接： <a href="https://new-savanna.blogspot.com/search/label/ChatGPT%20stories">https</a> ://new-savanna.blogspot.com/search/label/ChatGPT%20stories。我关于故事的第一篇文章是 ChatGPT、故事和环组合，新萨凡纳，2023 年 1 月 6 日， <a href="https://new-savanna.blogspot.com/2023/01/chatgpt-stories-and-ring-composition.html">https</a> ://new-savanna.blogspot.com/2023/01/chatgpt-stories-and-ring-composition <a href="https://new-savanna.blogspot.com/2023/01/chatgpt-stories-and-ring-composition.html">.html</a> 。</p><p> [2] ChatGPT 讲述故事，以及关于逆向工程的说明：工作论文，版本 3，2023 年 8 月 27 日， <a href="https://www.academia.edu/97862447/ChatGPT_tells_stories_and_a_note_about_reverse_engineering_A_Working_Paper_Version_3">https://www.academia.edu/97862447/ChatGPT_tells_stories_and_a_note_about_reverse_engineering_A_Working_Paper_Version_3</a> 。</p><p> ** ** ** **</p><p>该工作文件包含 ChatGPT 生成的 20 个故事的完整文本。</p><br/><br/> <a href="https://www.lesswrong.com/posts/LK8R8YmndScXjeynx/chatgpt-tells-20-versions-of-its-prototypical-story-with-a#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/LK8R8YmndScXjeynx/chatgpt-tells-20-versions-of-its-prototropic-story-with-a<guid ispermalink="false"> LK8R8YmndScXjeynx</guid><dc:creator><![CDATA[Bill Benzon]]></dc:creator><pubDate> Sat, 14 Oct 2023 15:27:59 GMT</pubDate> </item><item><title><![CDATA[Will no one rid me of this turbulent pest?]]></title><description><![CDATA[Published on October 14, 2023 3:27 PM GMT<br/><br/><p>去年，<a href="https://denovo.substack.com/p/gene-drives-why-the-wait">我写了一篇关于基因驱动有望消灭蚊子和消灭疟疾的文章。</a><br><br>自从我上一篇文章撰写以来，基因驱动器尚未在野外使用，<a href="https://www.who.int/publications/i/item/9789240064898"><i><strong>已有超过 60 万人死于</strong></i></a>疟疾。尽管<a href="https://news.un.org/en/story/2023/10/1141787">疟疾疫苗</a>等有希望的新进展，但也出现了 <a href="https://www.nytimes.com/2023/09/29/health/mosquitoes-malaria-disease-climate-change.html">一些相当严重的挫折</a>（例如蚊子和寄生虫对常用化学物质产生了抗药性），疟疾死亡人数较几年前略有增加。最近的新闻报道<span class="footnote-reference" role="doc-noteref" id="fnrefhu4591i5cz"><sup><a href="#fnhu4591i5cz">[1]</a></sup></span>强调，抗击疟疾的斗争已经陷入停滞，甚至在某些地区出现逆转。显然，科学家和公共卫生工作者正在利用他们拥有的工具进行努力，但这种努力还不够。</p><p>基因驱动有可能消灭疟疾。<strong>然而，除非部署它们，否则这一潜力将无法实现——而我们等待的每一天，都会有超过 1,600 人（主要是非洲儿童）死亡。</strong>但谁应该部署它们呢？</p><p>我很清楚<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4959137/">单边主义的诅咒</a>，在发表这篇文章之前，我问，<strong>为什么现有的团体还没有释放基因驱动蚊子？</strong>学术实验室和非营利组织<a href="https://targetmalaria.org/">Target Malaria</a>多年来一直致力于基因驱动研究，但<strong>他们一直采取谨慎、渐进的方法。</strong> <span class="footnote-reference" role="doc-noteref" id="fnreflqbrxkxg2h"><sup><a href="#fnlqbrxkxg2h">[2]</a></sup></span> <strong>&nbsp;</strong>这样做有几个很好的理由：</p><ul><li><strong>单方面释放基因驱动器可能会引起公众的强烈反对</strong>，因为基因工程被广泛认为是可怕的。如果释放基因驱动的组织没有得到当地政府的支持，情况尤其如此。</li><li><strong>释放到野外的任何基因驱动的第一个版本不太可能导致完全根除，</strong>因为蚊子可能会产生抗药性（通过自然或核酸酶诱导的突变）。 <span class="footnote-reference" role="doc-noteref" id="fnrefe656x8alxur"><sup><a href="#fne656x8alxur">[3]</a></sup></span><strong>因此，可能需要更新基因驱动版本来克服阻力</strong>。蚊子基因组中潜在的基因驱动目标位点的数量足够大，我认为这不会阻止根除，<strong>除非基因驱动在首次发布后因公众强烈反对而被禁止</strong>。</li><li>推论，由于部分有效的基因驱动导致疟疾数量暂时下降，随后由于耐药性而卷土重来，<strong>可能会导致更多人死亡</strong>，因为随着时间的推移，人类会失去针对疟疾的保护性抗体。</li><li>基因驱动还有机会根除其他病原体，例如<a href="https://www.cdc.gov/dengue/index.html">登革热</a>（由<i>伊蚊</i>传播）和<a href="https://www.cdc.gov/parasites/schistosomiasis/index.html">血吸虫病</a>，<strong>如果被禁止，这个机会就会被浪费。</strong></li></ul><p>基本上，这意味着<strong>任何发布基因驱动器的组织都需要确保它们不被禁止。</strong>这对于私人组织来说是很困难的，因为影响公众对转基因生物的看法很困难。然而，如果政府这样做，它可以简单地选择不禁止基因驱动（尽管它需要在可能的国际压力下保持坚定）。</p><p>抛开这个问题，我想探索基因驱动构建的技术细节，并描述如何在一个设备中等的生物实验室中构建一个针对<i>冈比亚按蚊</i>的基因驱动。我强调，这仍然是一个<strong>计划</strong>草案，虽然我精通分子生物学，但我不是蚊子专家。但考虑到疟疾造成的大量死亡和痛苦，我希望我提供的信息能够帮助结束这一威胁，强调<strong>政治担忧，而不是技术挑战，是基因驱动部署的主要障碍。</strong></p><h2>如何制作基因驱动器</h2><p>首先，我要感谢<a href="https://www.imperial.ac.uk/people/a.drcrisanti">Andrea Crisanti</a>和他的实验室，不仅开发了针对<i>按蚊</i>的基因驱动器，而且还公开了许多技术细节（包括 DNA 序列和蚊子编辑方法）。该计划紧密遵循他们制造基因驱动器的战略。</p><p>主要分为三个步骤：一是构建基因驱动DNA；第二，将其融入蚊子体内；第三，将蚊子释放到野外。</p><h3>脱氧核糖核酸</h3><p>2020 年，Crisanti 实验室报告了<a href="https://www.nature.com/articles/s41587-020-0508-1">一种高效的<i>双性</i>X 粉碎机基因驱动器</a>，并公布了<a href="https://www.ncbi.nlm.nih.gov/nuccore/MT270141">其 DNA 序列，这对他们很有帮助。</a>请注意，可以对此基因驱动器进行改进， <span class="footnote-reference" role="doc-noteref" id="fnref8cnuc15v869"><sup><a href="#fn8cnuc15v869">[4]</a></sup></span> ，但无论使用哪个基因驱动器版本，整个过程都将非常相似。</p><p>基因驱动的基本结构如<a href="https://www.nature.com/articles/s41587-020-0508-1">描述它的论文</a>的图1所示： </p><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F290457f0-0ecf-42df-b3f4-85c9ac728756_936x46.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F290457f0-0ecf-42df-b3f4-85c9ac728756_936x46.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F290457f0-0ecf-42df-b3f4-85c9ac728756_936x46.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F290457f0-0ecf-42df-b3f4-85c9ac728756_936x46.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F290457f0-0ecf-42df-b3f4-85c9ac728756_936x46.png 1456w"></figure><p>关键功能部分是由种系特异性<i>vas/zpg</i>启动子驱动的 SpCas9 核酸酶、 <span class="footnote-reference" role="doc-noteref" id="fnrefbe3kk27cnta"><sup><a href="#fnbe3kk27cnta">[5]</a></sup></span>由雄性种系特异性<i>Beta2</i>启动子驱动的 I-PpoI 核酸酶<span class="footnote-reference" role="doc-noteref" id="fnrefvhk0fzn1c7"><sup><a href="#fnvhk0fzn1c7">[6]</a></sup></span> 、 <span class="footnote-reference" role="doc-noteref" id="fnrefrx9x3f7e6gc"><sup><a href="#fnrx9x3f7e6gc">[7]</a></sup></span>以及由组成型U6启动子。在论文中，作者测试了驱动器的多个版本，发现带有针对<i>双性</i>基因的 gRNA 的版本表现最好。 <span class="footnote-reference" role="doc-noteref" id="fnref0u03etcj504"><sup><a href="#fn0u03etcj504">[8]</a></sup></span>论文中的驱动版本还包含荧光蛋白，可以轻松识别驱动阳性的蚊子。然而，这些在功能上是不必要的，并且较小的基因驱动有效负载会更有效，因此最好省略这些。 <span class="footnote-reference" role="doc-noteref" id="fnrefz4il86zsrq"><sup><a href="#fnz4il86zsrq">[9]</a></sup></span></p><p>为了将基因驱动 DNA 整合到蚊子体内，Crisanti 实验室采取了两步方法。首先，他们将一个包含 φC31 整合酶<i>attP</i>识别位点的小“着陆垫”序列以及在眼睛特异性启动子控制下的 GFP 进行 CRISPR 敲入， <span class="footnote-reference" role="doc-noteref" id="fnrefznryb3l71w"><sup><a href="#fnznryb3l71w">[10]</a></sup></span>进入<i>双性</i>基因。接下来，他们使用 φC31 整合酶质粒和基因驱动质粒进行重组酶介导的盒式交换，该质粒包含 φC31 酶与第一步中添加的<i>attP</i>位点重组的<i>attB</i>位点。为了遵循这种方法，我们<span class="footnote-reference" role="doc-noteref" id="fnrefhh5g8tdscyn"><sup><a href="#fnhh5g8tdscyn">[11]</a></sup></span>将需要四个质粒：</p><ol><li><a href="https://www.ncbi.nlm.nih.gov/nuccore/MT270141">基因驱动质粒</a>或不含荧光蛋白的较小版本</li><li>φC31 整合酶质粒（<i>果蝇</i>版本可以<a href="https://www.addgene.org/26290/">从 Addgene 获得</a>，它可能也适用于蚊子）</li><li><a href="https://www.ncbi.nlm.nih.gov/nuccore/MH541846">着陆垫质粒</a>。</li><li>用于敲入着陆垫的 Cas9/sgRNA 质粒。这可以通过使用 Golden Gate (SapI) 克隆将 sgRNA 序列添加到<a href="https://www.addgene.org/190598/">Addgene 的现有质粒</a>中来获得。 <span class="footnote-reference" role="doc-noteref" id="fnrefgqnlnbh66pk"><sup><a href="#fngqnlnbh66pk">[12]</a></sup></span></li></ol><p>因为我们知道所有这些的序列，所以我们可以从商业 DNA 合成提供商处订购它们，例如 Genscript、IDT 或 Twist（所有这些我都用于我自己的研究）。我从 Genscript 得到了合成较小版本基因驱动质粒的报价为 5600 美元，合成带有荧光蛋白的较大版本的报价为 6500 美元。如果资金非常紧张，将质粒订购为较小的片段并使用吉布森组装将它们组合起来会更便宜。在这种情况下，小版本的 DNA 成本约为 900 美元，大版本的 DNA 成本约为 1100 美元，尽管劳动力成本会高得多。 <span class="footnote-reference" role="doc-noteref" id="fnrefnjq2vkvb4e8"><sup><a href="#fnnjq2vkvb4e8">[13]</a></sup></span>无论如何，组装这些质粒，在细菌中培养它们，并准备用于注射的 DNA，只需要学士学位水平的分子生物学工作，一到两个月的时间，以及最多 25,000 美元的 DNA、试剂和实验室费用。设备。 <span class="footnote-reference" role="doc-noteref" id="fnref0t3aijza4svo"><sup><a href="#fn0t3aijza4svo">[14]</a></sup></span>下一步事情将开始变得更加昂贵。</p><h3>蚊子</h3><p>该项目将需要蚊子繁殖设施。如果我们有许可证，我们可以<a href="https://www.beiresources.org/Catalog/BEIVectors/MRA-763.aspx">从研究库中获取<i>按蚊</i></a>，但我假设这将在一个非洲国家进行，在那里我们可以从野外捕获蚊子作为备用选择。 <span class="footnote-reference" role="doc-noteref" id="fnrefgh2676e7mhj"><sup><a href="#fngh2676e7mhj">[15]</a></sup></span></p><p>由于某些奇怪的原因， <span class="footnote-reference" role="doc-noteref" id="fnref1uhmockf92p"><sup><a href="#fn1uhmockf92p">[16]</a></sup></span>国际原子能机构<a href="https://www.iaea.org/resources/manual/guidelines-for-standardised-mass-rearing-of-anopheles-mosquitoes-version-10">出版了一份 44 页的<i>按蚊</i>饲养指南。</a>内容非常多，包括如何从野外采集蚊子，如何搭建繁殖笼，如何设置饲养站（交配后给雌性加糖水、牛血），以及如何预防常见问题等。如蚂蚁出没。它还包括有关特定步骤的更多信息的参考列表。</p><p>更详细的内容，我们可以看美国典型培养物保藏中心和美国国立卫生研究院出版的408页的综合性《 <a href="https://www.beiresources.org/Portals/2/VectorResources/2016%20Methods%20in%20Anopheles%20Research%20full%20manual.pdf"><i>按蚊</i>研究方法</a>》（第1-4章与蚊子繁殖相关，还包括蚊子显微注射）。这还有昆虫学供应商的目录，这将非常有用。基本的三周繁殖周期如下：</p><blockquote><p><strong>星期五</strong>：给成年雌性吸血。为了获得最佳效果，蚊子应在出现后至少两天进行。</p><p><strong>星期一</strong>：将鸡蛋盘放入笼子中。</p><p><strong>星期二</strong>：从笼子里取出蛋盘。将鸡蛋漂白并将其存放在潮湿的密封杯中过夜。</p><p><strong>星期三</strong>：将鸡蛋冲洗到盘中进行孵化和喂养。</p><p><strong>星期五</strong>：根据您需要的数量将幼虫分成盘，但要记住适当的密度。添加终浓度为 0.02% w/v 的酵母和您将使用的极少量幼虫饲料。</p><p><strong>周日</strong>：根据幼虫的大小和密度，给幼虫喂食一定量的碎饲料。如果盘中的幼虫太多，请将其减薄或分成更多托盘，以确保不会发生拥挤。</p><p><strong>周一至周三</strong>：根据需要继续每日劈裂/稀释并喂入盘中。此时的密度最好与最终密度相同；拥挤会减缓发展。</p><p><strong>周三至周五</strong>：每天收集蛹并转移到装有清水的杯子中，然后放入装有糖源的新笼子中。</p><p><strong>下周的星期五</strong>：给成虫喂血以再次启动循环。</p></blockquote><p>我不会详细计算建造一个蚊子繁殖设施需要花费多少钱，但我粗略估计大约 10 万美元的设备（不包括建筑物本身）和两名运行它的员工。启动和运行所需的时间可能约为 6 个月的紧张工作，这可以与质粒制备同时完成。</p><h3>编辑发布</h3><p>尽管建立繁殖设施在操作上很困难，但整个项目中最具技术挑战性的部分将是进行实际的蚊子编辑。幸运的是，Crisanti 小组发表了<a href="https://pubmed.ncbi.nlm.nih.gov/22990807/">一份有用的指南，介绍如何将 DNA 注入蚊子卵中进行编辑。</a>这一切在指南中都得到了很好的解释（它们甚至包括要购买的关键设备的目录号），我在这里没有太多要补充的。需要以下设备（价格来自供应商）：</p><ul><li>倒置荧光显微镜（大约 10,000 美元，包括滤光片）</li><li>显微注射器（约 10,000 美元）</li><li>显微操纵器（约 2,500 美元）</li><li>显微注射移液器（约 500 美元） <span class="footnote-reference" role="doc-noteref" id="fnrefblcpe4c3be"><sup><a href="#fnblcpe4c3be">[17]</a></sup></span></li><li>以及各种廉价设备<span class="footnote-reference" role="doc-noteref" id="fnref4n5f13y5iw"><sup><a href="#fn4n5f13y5iw">[18]</a></sup></span> （可能还要花费 5,000 美元）</li></ul><p>我估计设备总成本约为 28,000 美元。获得设备后，基本步骤是：</p><ol><li>收集刚产下的蚊卵</li><li>将鸡蛋排列在显微镜载玻片上</li><li>Inject the DNA using a microinjector <span class="footnote-reference" role="doc-noteref" id="fnrefyjs3s2a5mmd"><sup><a href="#fnyjs3s2a5mmd">[19]</a></sup></span></li><li> Grow the mosquitoes and screen for successful transformants</li></ol><p> It will probably take a few months of practice to get right, and it would be a good idea to practice using a simple plasmid to make the embryos express GFP, before moving on to more complicated editing. We will need to do two rounds of editing: one to introduce the <i>attP</i> “landing pad” and another to swap out the “landing pad” for the gene drive. Then, we will need to breed gene drive mosquitoes. This could be a bit annoying due to the tendency of the gene drive to crash populations, so we will need a good supply of females to expand the numbers. Because of the PpoI nuclease X-shredder design, we will know our gene drive is working when all the larvae are males. Releasing <a href="https://www.nature.com/articles/s41467-022-28419-0">a few thousand males</a> would be sufficient to introduce the gene drive allele into the local population. Mosquitoes lay about 100 eggs each and the breeding cycle is 3 weeks long, so starting from a single edited mosquito it would take only a few months to breed the required numbers. I&#39;d estimate another 6 months for this phase of the project if everything goes perfectly – which it probably won&#39;t, so maybe 12 months is more realistic.</p><h3> Post-Release Monitoring</h3><p> After releasing the gene drive, we will need to check for resistance in order to develop updated drives to defeat the resistance. This will involve capturing mosquitoes from the wild (assuming there are any left), extracting their DNA, and sequencing it. PCR amplification of the target site, followed by Sanger sequencing, should be sufficient to test for resistant alleles at the target site at a cost of about $5 per sample. For larger numbers of samples, we could do the PCR in a barcoded format, pool samples, and do next-generation sequencing. This could scale very well (approximately 1 cent per sample, assuming batches of 250,000) but would require a larger upfront cost. Still, at this point the bigger cost would be collecting mosquitoes.</p><p> It&#39;s also possible that resistance could arise due to mutations elsewhere in the genome, so if we observe that mosquito populations are rebounding, we should perform whole genome sequencing, at a cost of about $500 per sample.</p><p> Post-release monitoring may actually be the most expensive part of the project, because if the gene drive works, it will spread internationally, requiring collection of mosquitoes from a large area. Monitoring should continue until eradication is achieved, which may take a few years depending on mosquito migration rates. <span class="footnote-reference" role="doc-noteref" id="fnrefzm8m7srzgq"><sup><a href="#fnzm8m7srzgq">[20]</a></sup></span></p><h3> Public Relations</h3><p> Since people will eventually find out about this project (even if it&#39;s initially secret, they&#39;ll notice when mosquitoes start disappearing), it&#39;s best to take a proactive stance on public relations to mitigate backlash. <strong>This will be equally, if not more, important in comparison with the rest of the project</strong> , since we really want to avoid getting gene drives banned. Non-gene-drive transgenic mosquito technology has been accepted in several countries, <span class="footnote-reference" role="doc-noteref" id="fnrefe48rybzpnq"><sup><a href="#fne48rybzpnq">[21]</a></sup></span> and an important part of this was convincing people of the benefits. We should emphasize the project&#39;s potential to end the vast amount of death and suffering caused by malaria. As a top scientist of Target Malaria <a href="https://www.nytimes.com/2023/09/29/health/mosquitoes-genetic-engineering.html">recently expressed in a news article:</a></p><blockquote><p> We may not know what may happen but we know what is happening today: 600,000 people dying of malaria, and we need to fix it,” said Dr. Diabaté, the principal investigator in Burkina Faso for Target Malaria, a project backed by the Bill &amp; Melinda Gates Foundation. “We can&#39;t say we are afraid of the future so we will accept 600,000 people dying. <strong>We make good progress as a society when we invest in our dreams, rather than our fear.</strong> ”</p></blockquote><h2> A call for political action</h2><p> Overall, I think this gene drive could be built and released for under a million dollars (considering equipment and salaries), although a budget of a few million would allow the project to move faster by hiring more people. Of course, the reason this is so cheap is that the R&amp;D costs have already been paid by the Crisanti lab and others. <strong>I want to emphasize that releasing a gene drive, without having the R&amp;D capacity to make a followup drive in the likely case that the first drive is insufficient, will be doing more harm than good.</strong> So, realistically this would be a multi-million dollar project.</p><p> <strong>But I also want to emphasize that this is well within the capabilities of most African governments!</strong> Just to pick a random sub-Saharan country, <a href="https://mofep.gov.gh/publications/budget-statements">the national revenue of Ghana</a> is about 65 billion Ghana Cedi, or $5.5 billion USD at October 2023 exchange rates. <span class="footnote-reference" role="doc-noteref" id="fnref87cix9o4qpi"><sup><a href="#fn87cix9o4qpi">[22]</a></sup></span> Funded at $5 million per year, this would be about 1/1000 of total government revenue – and I&#39;m sure the Ghanaian government could get some foreign support if it asked. For a larger country like Nigeria, it would be a trivial expense.</p><p> <strong>Thus, the barriers holding back gene drive deployment are political, not technical.</strong> <a href="https://www.nytimes.com/2023/09/29/health/mosquitoes-genetic-engineering.html">A recent news article covering gene drives</a> observed that:</p><blockquote><p> [a project in São Tomé and Príncipe led by the University of California <span class="footnote-reference" role="doc-noteref" id="fnrefn08iwkn2qrp"><sup><a href="#fnn08iwkn2qrp">[23]</a></sup></span> ] needs government approval to move forward with the genetic portion of the intervention and São Tomé and Príncipe, like many other African countries, does not yet have a legal framework for the use of genetically modified organisms. Legislation to establish one has stalled in the National Assembly. Without a body assessing the risks and safety of using a tool like these mosquitoes, the California team has no one to submit its project proposal to and is effectively stalled.</p></blockquote><p> So, assuming you&#39;re not an African government official, <span class="footnote-reference" role="doc-noteref" id="fnref6zfgvap61wm"><sup><a href="#fn6zfgvap61wm">[24]</a></sup></span> what can you do to help? I&#39;m not a politician or PR expert, but here are some ideas:</p><ul><li> Coordinate with existing gene drive programs and fund PR campaigns to support their efforts.</li><li> <s>Send an email to a Nigerian prince about your unique investment opportunity</s> Identify which African government officials have the power to approve gene drives in their countries, and encourage them to support this.</li><li> Advocate for reasonable international regulations on gene drives for disease vector species. <span class="footnote-reference" role="doc-noteref" id="fnrefu4zcv2nxxi"><sup><a href="#fnu4zcv2nxxi">[25]</a></sup></span></li><li> Advocate for the development and testing of more limited transgenic mosquito technology (non-gene-drive mosquitoes, <a href="https://www.pnas.org/doi/10.1073/pnas.1716358116">or gene drives which self-inactivate after a set number of generations</a> ) as a way of gaining acceptance for a full-scale gene drive by showing that these limited versions are safe and effective.</li><li> Spread the message that <strong>ending malaria is possible if we try.</strong></li></ul><p> If you have a typical reading speed, <span class="footnote-reference" role="doc-noteref" id="fnreft7zgldc7mc"><sup><a href="#fnt7zgldc7mc">[26]</a></sup></span> <strong>in the time it&#39;s taken you to read this far,</strong> <strong>thirteen more people have died of malaria.</strong> Gene drives can end this ongoing tragedy, but only if we decide to use them.</p><p> <i>I thank Devon Stork for his helpful feedback on a draft of this article</i> . </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnhu4591i5cz"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhu4591i5cz">^</a></strong></sup></span><div class="footnote-content"><p> See: https://www.nytimes.com/2023/09/29/health/mosquitoes-malaria-disease-climate-change.html and https://www.nytimes.com/2023/09/29/health/mosquitoes-stephensi-malaria-africa.html</p></div></li><li class="footnote-item" role="doc-endnote" id="fnlqbrxkxg2h"> <span class="footnote-back-link"><sup><strong><a href="#fnreflqbrxkxg2h">^</a></strong></sup></span><div class="footnote-content"><p> The last news from Target Malaria was in 2022, when they <a href="https://www.nature.com/articles/s41467-022-28419-0">reported results of releasing non-gene-drive sterile male mosquitoes in Burkina Faso.</a> As far as I know they have no active plans to release gene drives, not even limited “split drive” or “daisy drive” versions.</p></div></li><li class="footnote-item" role="doc-endnote" id="fne656x8alxur"> <span class="footnote-back-link"><sup><strong><a href="#fnrefe656x8alxur">^</a></strong></sup></span><div class="footnote-content"><p> Even target sites with a low expected fitness of resistant alleles (such as <i>doublesex</i> ) still have this possibility, and the mosquito population is very large.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn8cnuc15v869"> <span class="footnote-back-link"><sup><strong><a href="#fnref8cnuc15v869">^</a></strong></sup></span><div class="footnote-content"><p> Interestingly, <a href="https://elifesciences.org/articles/79121">a simulation paper</a> found that a more basic version of the gene drive without the PpoI X-shredder may be better at spreading through heterogeneous populations. Basically, if the fitness reduction is too high, the drive allele dies out too quickly before spreading. But, <a href="https://www.nature.com/articles/s41576-021-00386-0">the X-shredder drive has a lower chance of resistant alleles forming.</a> As a reminder, <strong>the first gene drive release is unlikely to be completely successful, so it&#39;s important to not have gene drives get banned!</strong></p></div></li><li class="footnote-item" role="doc-endnote" id="fnbe3kk27cnta"> <span class="footnote-back-link"><sup><strong><a href="#fnrefbe3kk27cnta">^</a></strong></sup></span><div class="footnote-content"><p> Surprisingly, they seem to be using a version of Cas9 codon-optimized for human expression instead of insect expression.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnvhk0fzn1c7"> <span class="footnote-back-link"><sup><strong><a href="#fnrefvhk0fzn1c7">^</a></strong></sup></span><div class="footnote-content"><p> This nuclease shreds the X chromosome, making all sperm male.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnrx9x3f7e6gc"> <span class="footnote-back-link"><sup><strong><a href="#fnrefrx9x3f7e6gc">^</a></strong></sup></span><div class="footnote-content"><p> They found that a slightly modified promoter with lower activity performed better.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn0u03etcj504"> <span class="footnote-back-link"><sup><strong><a href="#fnref0u03etcj504">^</a></strong></sup></span><div class="footnote-content"><p> <i>doublesex</i> is a highly conserved gene involved in sex determination. When the intron 4–exon 5 splice site is disrupted, females cannot develop properly but males are fine. Because the sequence is so conserved, <i>doublesex</i> drives have a chance of spreading into other <i>Anopheles</i> species besides <i>A. gambiae</i> if hybridization takes place. This is probably a good thing, as those other <i>Anopheles</i> species also spread malaria.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnz4il86zsrq"> <span class="footnote-back-link"><sup><strong><a href="#fnrefz4il86zsrq">^</a></strong></sup></span><div class="footnote-content"><p> Furthermore, one hypothetical resistance mechanism is mosquitoes evolving to not mate with fluorescent mosquitoes.</p><p> To make the version without fluorescent proteins, I downloaded their DNA file and opened it in Benchling. I highlighted the gene drive sequence in the screenshot below. </p><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9866e47-2732-496a-b98a-7f55e9b332d8_1468x1450.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9866e47-2732-496a-b98a-7f55e9b332d8_1468x1450.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9866e47-2732-496a-b98a-7f55e9b332d8_1468x1450.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9866e47-2732-496a-b98a-7f55e9b332d8_1468x1450.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9866e47-2732-496a-b98a-7f55e9b332d8_1468x1450.png 1456w"></figure><p> The rest of the sequence is for allowing the plasmid to be propagated in bacteria. At 14,465 base pairs, it&#39;s a relatively big plasmid. I also designed a version of the plasmid with non-functional elements removed (including the fluorescent proteins), making the gene drive sequence about 20% smaller (the bacterial sequence is unchanged). </p><figure class="image"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51826641-8ef0-4278-ad77-20571257b88f_1472x1444.png" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51826641-8ef0-4278-ad77-20571257b88f_1472x1444.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51826641-8ef0-4278-ad77-20571257b88f_1472x1444.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51826641-8ef0-4278-ad77-20571257b88f_1472x1444.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51826641-8ef0-4278-ad77-20571257b88f_1472x1444.png 1456w"></figure></div></li><li class="footnote-item" role="doc-endnote" id="fnznryb3l71w"> <span class="footnote-back-link"><sup><strong><a href="#fnrefznryb3l71w">^</a></strong></sup></span><div class="footnote-content"><p> This is very helpful for identifying mosquitoes where the integration was successful. Also, at the second stage where the gene drive sequence is integrated into the <i>doublesex</i> site, loss of GFP indicates success.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnhh5g8tdscyn"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhh5g8tdscyn">^</a></strong></sup></span><div class="footnote-content"><p> I&#39;m going to be using “we” here to mean the people building the gene drive, and this does not indicate that I will be personally involved.</p></div></li><li class="footnote-item" role="doc-endnote" id="fngqnlnbh66pk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefgqnlnbh66pk">^</a></strong></sup></span><div class="footnote-content"><p> Or possibly through modifying the gene drive plasmid, which already expresses Cas9 and an sgRNA targeting <i>doublesex</i> , to have the constitutive promoter from the φC31 plasmid driving Cas9 instead of the germline-specific <i>zpg</i> promoter.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnnjq2vkvb4e8"> <span class="footnote-back-link"><sup><strong><a href="#fnrefnjq2vkvb4e8">^</a></strong></sup></span><div class="footnote-content"><p> If I did this personally, it would probably take me about a month of lab work. If I ordered the plasmids instead, it would take 2 days of hands-on work.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn0t3aijza4svo"> <span class="footnote-back-link"><sup><strong><a href="#fnref0t3aijza4svo">^</a></strong></sup></span><div class="footnote-content"><p> Centrifuges, incubators, etc. Note that it will be important to have 24-hour electricity which many African countries do not have, so expenses for a generator will also likely need to be added.</p></div></li><li class="footnote-item" role="doc-endnote" id="fngh2676e7mhj"> <span class="footnote-back-link"><sup><strong><a href="#fnrefgh2676e7mhj">^</a></strong></sup></span><div class="footnote-content"><p> Doing this in an area where mosquitoes are endemic means that if any mosquitoes escape, they might spread the gene drive. This has generally been considered a bad thing, but if we&#39;re planning to release them anyway, it&#39;s not terrible – except for the PR problems it would cause.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn1uhmockf92p"> <span class="footnote-back-link"><sup><strong><a href="#fnref1uhmockf92p">^</a></strong></sup></span><div class="footnote-content"><p> It&#39;s because radiation is used to sterilize mosquitoes for population suppression.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnblcpe4c3be"> <span class="footnote-back-link"><sup><strong><a href="#fnrefblcpe4c3be">^</a></strong></sup></span><div class="footnote-content"><p> Alternatively we could buy a micropipette puller for about $5,000 and have a functionally unlimited supply.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn4n5f13y5iw"> <span class="footnote-back-link"><sup><strong><a href="#fnref4n5f13y5iw">^</a></strong></sup></span><div class="footnote-content"><p> A dissection microscope, pipettes, Petri dishes, filter paper, strainers, etc.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnyjs3s2a5mmd"> <span class="footnote-back-link"><sup><strong><a href="#fnrefyjs3s2a5mmd">^</a></strong></sup></span><div class="footnote-content"><p> I learned how to do this on frog and mouse eggs at <a href="https://denovo.substack.com/p/at-the-frontiers-in-reproduction">Frontiers in Reproduction.</a> It took me a few days to learn, but I was helped by an experienced teacher.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnzm8m7srzgq"> <span class="footnote-back-link"><sup><strong><a href="#fnrefzm8m7srzgq">^</a></strong></sup></span><div class="footnote-content"><p> Migration rates, not breeding rates, will be the limiting factor here. See https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4306333/ and https://pubmed.ncbi.nlm.nih.gov/9439109/ for differing estimates.</p></div></li><li class="footnote-item" role="doc-endnote" id="fne48rybzpnq"> <span class="footnote-back-link"><sup><strong><a href="#fnrefe48rybzpnq">^</a></strong></sup></span><div class="footnote-content"><p> To be specific, <a href="https://www.nature.com/articles/d41586-022-01070-x">Oxitec&#39;s sterile <i>Aedes</i> mosquitoes</a> .</p></div></li><li class="footnote-item" role="doc-endnote" id="fn87cix9o4qpi"> <span class="footnote-back-link"><sup><strong><a href="#fnref87cix9o4qpi">^</a></strong></sup></span><div class="footnote-content"><p> Although, the budget document indicates Ghana is at a high risk of default on its foreign loans. Still, the expenditure would be small compared to other government programs, and would have a high rate of return.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnn08iwkn2qrp"> <span class="footnote-back-link"><sup><strong><a href="#fnrefn08iwkn2qrp">^</a></strong></sup></span><div class="footnote-content"><p> This project is <a href="https://www.openphilanthropy.org/grants/uc-davis-malaria-gene-drive-feasibility-analysis-greg-lanzaro-2021/">funded by Open Philanthropy</a> and intends to use a gene drive not to eradicate mosquitoes, but to make them express anti-malaria antibodies and not transmit malaria. However, a gene drive expert privately expressed various concerns to me about this project, such as that it will likely spread outside its intended area (the islands of <a href="https://en.wikipedia.org/wiki/S%C3%A3o_Tom%C3%A9_and_Pr%C3%ADncipe">São Tomé and Príncipe</a> ) to mainland Africa, and cause backlash in mainland countries leading to gene drives being banned. Furthermore, it may cause resistance in mosquitoes, or the evolution of malaria strains that are resistant to the anti-malaria antibodies. I hope the project can address these concerns before deploying their gene drive.</p></div></li><li class="footnote-item" role="doc-endnote" id="fn6zfgvap61wm"> <span class="footnote-back-link"><sup><strong><a href="#fnref6zfgvap61wm">^</a></strong></sup></span><div class="footnote-content"><p> And if you <i>are</i> an African government official, I&#39;d love to talk with you about this!</p></div></li><li class="footnote-item" role="doc-endnote" id="fnu4zcv2nxxi"> <span class="footnote-back-link"><sup><strong><a href="#fnrefu4zcv2nxxi">^</a></strong></sup></span><div class="footnote-content"><p> Although this is less likely to work than getting one country to allow gene drive release, it is still worth trying.</p></div></li><li class="footnote-item" role="doc-endnote" id="fnt7zgldc7mc"> <span class="footnote-back-link"><sup><strong><a href="#fnreft7zgldc7mc">^</a></strong></sup></span><div class="footnote-content"><p> (2848 words, not counting footnotes) / (250 words/minute) * (600,000 deaths in last year) / (525600 minutes in last year) = 13 deaths</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/gjs3q83hA4giubaAw/will-no-one-rid-me-of-this-turbulent-pest#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/gjs3q83hA4giubaAw/will-no-one-rid-me-of-this-turbulent-pest<guid ispermalink="false"> gjs3q83hA4giubaAw</guid><dc:creator><![CDATA[Metacelsus]]></dc:creator><pubDate> Sat, 14 Oct 2023 15:27:22 GMT</pubDate> </item><item><title><![CDATA[Which Anaesthetic To Choose?]]></title><description><![CDATA[Published on October 14, 2023 2:55 PM GMT<br/><br/><p> In causal decision theory, the perspective/indexical aspect could lead to reflective inconsistency. This is generally regarded as a problem. Here I present a thought experiment to show why this view may require further review.</p><h2> Two Anaesthetics</h2><p> Suppose you are about to undergo a major operation. You can choose one of the following two anesthetics:</p><p> Drug A functions as follows:</p><ol><li> It paralyzes your body and relaxes your muscles</li><li> It prevents long-term memory from forming for the duration of the operation</li></ol><p> Drug B functions as follows:</p><ol><li> It paralyzes your body and relaxes your muscles (same as A)</li><li> It renders you unconscious for the duration of the operation</li></ol><p> Suppose the two drugs are equal in all other considerations such as safety, long-term side effects, etc. But Drug A is covered by your health insurance while Drug B requires you to pay 1 dollar out-of-pocket. What would you pick?</p><h2> Reflective Inconsistency</h2><p> Drug A would lead to the dreaded anesthesia awareness, that you will feel the excruciating pain and trauma of being operated on. To prevent it from happening, for the mere cost of 1 dollar, Drug B is the obvious choice.</p><p> Yet for moments after the operation, you would be wishing that you had chosen Drug A instead. The choice of drugs does not lead to any long-term difference, other than the fact that you would be 1 dollar richer if you had gone with Drug A. Furthermore, you know this before the operation.</p><p> If the later you dictate your current decision it would mean Drug A is the clear winner. (Consider this as a case of post-commitment, in contrast to pre-commitments where an earlier self takes away the decision at a later point, often appearing in decision-making problems such as Parfit&#39;s Hitchhiker) Hence the inconsistency.</p><h2> Decision Theories</h2><p> CDT has a naturally built-in indexical element. Considering the fact that the decision is based on a pre-operation perspective, it will choose Drug B over A.</p><p> However, for non-indexical decision theories, such as UDT or EDT, the approach would be less clear, and it could very well lead to choosing Drug A. Should it only consider the utility at the end of the experiment? Or should it get around the indexicals with some self-sampling assumptions like common camps in anthropics? Neither approach seems problem-free.</p><br/><br/> <a href="https://www.lesswrong.com/posts/TkgZWZKXgcCLc3G55/which-anaesthetic-to-choose#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/TkgZWZKXgcCLc3G55/which-anaesthetic-to-choose<guid ispermalink="false"> TkgZWZKXgcCLc3G55</guid><dc:creator><![CDATA[dadadarren]]></dc:creator><pubDate> Sat, 14 Oct 2023 14:55:43 GMT</pubDate> </item><item><title><![CDATA[Is the Wave non-disparagement thingy okay?]]></title><description><![CDATA[Published on October 14, 2023 5:31 AM GMT<br/><br/><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Fri, 13 Oct 2023 23:39:53 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Fri, 13 Oct 2023 23:39:53 GMT" user-order="1"><p> A few weeks ago, Linch, Auckland (pseudonym), and I decided to chat about something and settled on this topic. What follows is a mix of distillation and edited chat (Slack) transcript.</p><h1>概括</h1><p>Auckland and I (Ruby) start from the position that the Wave non-disparagement agreement is probably bad. Linch expresses uncertainty about whether, if broader society (or at least your local reference class) makes use of non-disparagement agreements, that makes it okay to use them yourself.</p><p> We discuss various possible examples of not-good behavior (non-consent, lying, bribing, saying “awesome” when you mean “mildly positive”) that people empirically engage in and/or seem more okay if everyone is doing them. We think about what “reference class” Wave is in, eg more general Silicon Valley vs EA.</p><p> A big is crux is whether Wave had been prompted to reflect on their non-disparagement agreement, and if so, their reaction. It might be that non-disparagements are bad, but you have to be paying attention to notice when you should be morally better than your surrounding society. Some employees wanting to negotiate out of the non-disparagement agreement seems like it was a prompt to reflect on it. Also how much the founders of Wave say “oops” when it&#39;s pointed it out, vs defending the practice.</p><p> Beyond that, there&#39;s a question of even if someone is not particularly blameworthy for engaging in a standard widespread not-good behavior, do you still want them in a leadership position? Eg board of Effective Ventures/CEA? As opposed to wanting leaders who&#39;d have the discernment to catch this kind of thing and not do it. We have some more discussion about who you want for EA leadership related to how good you think EA is.</p><p> Linch raises that non-disparagement agreements are in fact not legally enforceable. We all agree that it&#39;s plausible EAs should push Wave to make an official declaration to void their non-disparagement agreements.<br></p><h1> Background Context</h1><p> In the discussion of <a href="https://www.lesswrong.com/posts/Lc8r4tZ2L5txxokZ8/sharing-information-about-nonlinear-1"><u>Nonlinear&#39;s behavior</u></a> , the topic of NDAs/other agreements that restrict employees speaking negatively of former employer&#39;s came up.</p><p> <strong>jefftk</strong> <a href="https://www.lesswrong.com/posts/Lc8r4tZ2L5txxokZ8/sharing-information-about-nonlinear-1?commentId=HpED6nEvWSsrwRYpY"><u>(permalink)</u></a> :</p><blockquote><p> an NDA to prevent people from publicly criticizing their former workplace seems line-crossing to me.</p></blockquote><blockquote><p> I don&#39;t like these, but they are (were) depressingly common. I know at least one org that&#39;s generally well regarded by EAs that used them.</p></blockquote><p> <strong>habryka</strong> <a href="https://www.lesswrong.com/posts/Lc8r4tZ2L5txxokZ8/sharing-information-about-nonlinear-1?commentId=ZHcuezbHyHmp3jSGW"><strong>&nbsp;</strong> <u>(permalink)</u></a> :</p><blockquote><p> Oh, wow, please tell me the name of that organization. That seems very important to model, and I would definitely relate very differently to any organization that routinely does this (as well as likely advocate for that organization to no longer be well-regarded).</p></blockquote><p> <strong>licolnquirk</strong> <a href="https://www.lesswrong.com/posts/Lc8r4tZ2L5txxokZ8/sharing-information-about-nonlinear-1?commentId=3mcATsfuyHHwCw7bm"><strong>&nbsp;</strong> <u>(permalink)</u></a> :</p><blockquote><p> Jeff is talking about Wave. We use a standard form of non-disclosure and non-disparagement clauses in our severance agreements: when we fire or lay someone off, getting severance money is gated on not saying bad things about the company. We tend to be fairly generous with our severance, so people in this situation usually prefer to sign and agree. I think this has successfully prevented (unfair) bad things from being said about us in a few cases, but I am reading this thread and it does make me think about whether some changes should be made.</p></blockquote><blockquote><p> I also would re-emphasize something Jeff said - that these things are quite common - if you just google for severance package standard terms, you&#39;ll find non-disparagement clauses in them. As far as I am aware, we don&#39;t ask current employees or employees who are quitting without severance to not talk about their experience at Wave.</p></blockquote><p> Further conversation followed in that thread.</p><h1></h1><h1> Transcript</h1><p> <i>This transcript is cleaned up, flattened (from Slack threads), and has less-interesting or well-fitting parts of the conversation removed, had a few bits edited after the fact, and finally ported into the LessWrong Dialogue format.</i></p><p></p><hr><p> My quick take:</p><ul><li> Lincoln is probably right that this is fairly standard in SV</li><li> It is in fact a pretty terrible practice that filters info and distorts people&#39;s judgment</li><li> I think it&#39;s a case where you need to be more moral than those around you, and that can be hard to notice, so I&#39;m not sure how judge-y to be</li><li> Does make a difference how much people defend it once pointed out vs go “oh, obviously we inherited a terrible practice from broader society”</li></ul><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> 红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:01:23 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:01:23 GMT" user-order="2"><p> At a high level, I view this as a clash between rationalist-y norms and the norms of a different subculture/subsection of society.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:01:59 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:01:59 GMT" user-order="3"><p> It makes a difference to me how much people defend it once it&#39;s pointed out vs go “oh, obviously we inherited a terrible practice from broader society”.</p><p> This is the thing I care most about.</p><p> I am more than happy to tolerate a lot of minor flubs like this in the name of moving fast and not thinking too hard about small details (though I think it would have been a positive sign if the founders had a more visceral &quot;I will never let this happen in my company&quot; reaction).</p><p> I also feel very hesitant to critique it, because as far as I know, Wave has been really successful in many ways and I haven&#39;t, so I&#39;m inclined to defer to them a lot.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:02:12 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:02:12 GMT" user-order="1"><p> (important consideration to me is did anyone in the past say to them “uh, hey, this has bad effects on community epistemics”, if Elizabeth got to negotiate out of it, maybe counts as a prompt for reflection on that, a bit cruxy for me since it was a clear prompt to reflect on whether this was good or not)</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:02:18 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:02:18 GMT" user-order="1"><h2> &quot;Everybody else does it&quot;</h2><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:02:21 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:02:21 GMT" user-order="2"><p> The thing I&#39;m confused about is that conditional upon this being the thing that broader society does is it a bad thing to do it yourself</p><p> An example of something that I consider bad to do even if other people all do it is questionable sexual consent practices in the past, and some cultures today.</p><p> An example of something that I consider a bad general practice but fine for people to participate in if everybody else does so is bribing police officers at traffic stops.</p><p> I think some norms are better than others in the sense they lead to better long-run equilibria; ask culture is a good example;</p><p> Lying on apps [applications] is also bad (even though it&#39;s common in broader society) and I would negatively judge someone who lies on EA apps, but I would negatively judge someone who lies on EA funding applications much more if they&#39;re familiar with the culture, than if they aren&#39;t.</p><p> But I&#39;m not sure how much I&#39;d judge someone who lies on non-EA funding applications. I feel like the answer is, like, moderately?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:02:29 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:02:29 GMT" user-order="3"><p> Some applications expect you to at least exaggerate if not lie, and they adjust for it. It seems like the standard practice for writing a letter of recommendation for colleges is to stretch the truth -- if you mention any small flaw in the letter or don&#39;t praise the applicant profusely enough, then the university will jump to the conclusion that the applicant is terrible.</p><p> Perhaps there&#39;s an analog for past employees talking about their employer, but it feels much weaker.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:02:36 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:02:36 GMT" user-order="2"><p> Sorry, why? Suppose we live in a world where 99 startups have non-disparagement agreements with severance packages and it&#39;s well-understood the only reasons someone doesn&#39;t sign a non-disparagement agreement are because either a) they hate the company so much they aren&#39;t willing to do so or b) the company offers shitty severance.</p><p> As the 100th company, it sure feels like you&#39;re playing &quot;cooperate&quot; when everybody else plays &quot;defect&quot;.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:02:41 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:02:41 GMT" user-order="1"><p> Agree with that. But EA is ostensibly a little cooperate bubble, where we built it out of people who&#39;d play cooperate, and it&#39;s important than we punish defection to maintain that.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:02:46 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:02:46 GMT" user-order="2"><p> Importantly, I don&#39;t know if Wave views their natural reference class as EA vs other startups, until recently I would&#39;ve thought &quot;other startups&quot; is correct. &quot;Natural reference class&quot; might not be exactly the right word, but who do their employees talk to, what is the non-disparagement agreement meant to protect them from.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:02:55 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:02:55 GMT" user-order="1"><p> Relevant to that is where they hire from and who they get funding from. My sense is they hired quite a few EAs?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:03:08 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:03:08 GMT" user-order="3"><p> They also hire hundreds of people who are very far outside the community, like folks on the ground in Sierra Leone and Senegal to do things like sales and customer support and exchanging money, yes?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:03:43 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:03:43 GMT" user-order="1"><p> &lt;we discuss the hiring there, how Sierra Leone norms might differ and affect the non-disparagement agreement, and whether the non-disparagement agreement was targeted at our would apply to those employees, before we return the question of just assuming Wave is a US company.>;</p><hr><p> <i>jumping back</i></p><hr><p></p><h2> Cruxes</h2><p> <i>After some further discussion, we stop to check in on cruxes</i></p><p> <i>Please take 3-minutes to think about where you&#39;re at with the top-level question of ok or not, and your current cruxes. Share at 22:23</i></p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:03:56 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:03:56 GMT" user-order="1"><p> I think I want to separate out:</p><ol><li> How bad is it for Wave to have that agreement, and</li><li> How blameworthy/betrayal is their in Wave doing it?</li></ol><p> Regard Point 1, I think really quite bad for the reasons of distorting recommendations people give (part of Oli&#39;s complaint). I think this point is invariant to what broader society does. Regarding Point 2, unclear. I think depends how many times they got push back on it and they stuff to it. Like did something prompt them to reconsider societal default?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:04:12 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:04:12 GMT" user-order="3"><p> Yes, I am interested in the above two questions and also maybe in &quot;should he be on the board&quot; in addition. Though that one feels perhaps drama-laden.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:04:27 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:04:27 GMT" user-order="1"><p> Drama-y but gets at important stuff about judgment. Where “you didn&#39;t act especially poorly given circumstances” might be true, but you also didn&#39;t display enough good judgment for me to want to give you power (especially in something heavily political).</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:04:41 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:04:41 GMT" user-order="3"><p> I can see how one might want people who are good at not letting things like this happen on the EV board.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:04:48 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:04:48 GMT" user-order="2"><p> My cruxes:</p><ol><li> How much Wave wants (and in practice, is) interfacing with the EA ecosystem?<ol><li> Eg, what percentage of their talent-adjusted US employees are EAs.</li></ol></li><li> How common are non-disparagement clauses in Silicon Valley, really?</li><li> How much thought did they have about this specific question<ol><li> especially wrt to this ecosystem, plausibly thinking about it in general will give different answers.</li></ol></li><li> How naive am I being about powerful people?<ol><li> Like how in distribution is the badness of non-disparagement agreements for people with Lincoln&#39;s level of success, even among say the top 20% most ethical people?</li><li> This also came up a few times when I&#39;m thinking about other cases that I looked at when I think someone is suss.</li><li> if powerful people usually do at least a few suss things, we should be careful not to punish them when they&#39;re actually being unusually honest. </li></ol></li></ol><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:04:53 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:04:53 GMT" user-order="3"><p> I&#39;m not sure what claim these are cruxes <i>for</i> . But I think only 3 is a crux for me, out of those. (though I have my own long list of cruxes). I am interested in 4 though, although I don&#39;t know if I get what you&#39;re saying.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:04:57 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:04:57 GMT" user-order="2"><p> Let me reframe. If 99% of successful startup founders are more suss than Lincoln, not wanting to interface with Lincoln means that you either (a) aren&#39;t working with startup founders or (b) are creating strong selection effects for deceptive alignment</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:05:05 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:05:05 GMT" user-order="3"><p> Not wanting to work with them feels strong. Again I am not clear on exactly what claim your points are a crux for. Is the claim &quot;this is sufficient evidence to never work for or with Wave under any but the  most dire circumstances&quot;? I was imagining it isn&#39;t? (I would clearly not refuse to work with Wave over something like this.)</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:05:13 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:05:13 GMT" user-order="1"><h2> Who do you want for EA Leadership?</h2><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:05:15 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:05:15 GMT" user-order="2"><p> From my perspective, it&#39;s like, EAs have some leaders. Some of them sure seem mediocre. Now we have Lincoln, who is plausibly a new leader. Whether we want to give him more or less powers depends a lot not only on how ethical he is but on how ethical his competition is. (both existing leaders and other candidates for new ones)</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:05:22 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:05:22 GMT" user-order="1"><p> Kind of. At some point you decide everyone is so corrupt you give up and do something else (ofc you can&#39;t always just go do your own thing, as Habryka complains)</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:05:28 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:05:28 GMT" user-order="2"><p> I agree.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:05:31 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:05:31 GMT" user-order="1"><p> (perhaps we should talk about whether EA is bad for the world now?) [one of the topics we brainstormed talking about)</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:05:39 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:05:39 GMT" user-order="3"><p> hmm. I feel more into the narrowly-scoped topic, especially if we want content that&#39;s half-publishable. I have more to say on Wave personally.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:05:47 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:05:47 GMT" user-order="1"><p> I suspect if we talk for a couple of min, we can get some more scoped claims about EA.</p><p> Linch, can you give a couple of sentences for why “is EA bad for the world” was a thing you listed as possible topic of discussion tonight?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:05:49 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:05:49 GMT" user-order="2"><ul><li> Sure seems like longtermist EA, or precursors to it, accelerated capabilities</li><li> Sure seems like there are other negative effects (FTX, cults)</li><li> Sure seems like EA is taking up a bunch of bright/agentic/moral (?) etc people whose counterfactuals are nontrivial</li><li> It&#39;d suck for me to work most of my adult life on something that&#39;s bad for the world</li></ul><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:05:56 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:05:56 GMT" user-order="1"><p> You say accelerated like it happened in the past. (I have to tow the Lightcone party line here, you see ;) )</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:06:00 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:06:00 GMT" user-order="2"><p> yes, a point of contention for me is how much the die is cast. so to speak, re: capabilities</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:06:03 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:06:03 GMT" user-order="3"><p> I&#39;d be interested in talking about that, though perhaps it is a tangent. But I feel super interested in the question. Also if it was cast, who cast it?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:06:08 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:06:08 GMT" user-order="1"><p> <a href="https://en.wikipedia.org/wiki/Die_(integrated_circuit)"><u>https://en.wikipedia.org/wiki/Die_(integrated_circuit)</u></a></p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:06:15 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:06:15 GMT" user-order="3"><p> I think it might be good to create more clarity about who is responsible for what here, especially because people seem to point fingers a lot (in a way that I worry is a bit tribal).</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:06:21 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:06:21 GMT" user-order="1"><p> Does seem like a good topic, though maybe for another round</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:06:23 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:06:23 GMT" user-order="2"><p> one interesting take I feel like people outside this cluster seem to have but seem to have relatively little representation in LC-adjacent cluster is something like:</p><blockquote><p> the more you think EA/LT EA sucks, the more you should want other leaders to take over </p></blockquote><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:06:36 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:06:36 GMT" user-order="3"><p> I don&#39;t think I buy that. For one thing, you might not think most of why it sucks is that the leadership is bad. For another thing, you might be worried about adding variance to a thing like EA.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:06:47 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:06:47 GMT" user-order="2"><p> sure there are extenuating factors</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:06:49 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:06:49 GMT" user-order="1"><p> Man, something just feels very icky by the time you&#39;re getting adversarial like that with the system/EA</p><p> <i>Linch, Auckland: agree react</i></p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:06:58 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:06:58 GMT" user-order="3"><p> Also the discussion gets accusatory and political quickly if you start advocating for specific new leadership.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:07:03 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:07:03 GMT" user-order="2"><blockquote><p> Something just feels very icky by the time you&#39;re getting adversarial like that with the system/EA</p></blockquote><p> A more positive framing is that in areas where we know our shit, external expertise is less helpful. In areas where we don&#39;t (plausibly leadership is one of them), you want more external expertise.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:07:13 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:07:13 GMT" user-order="3"><p> Wait that sounds like a different claim, not a reframing?</p><p> Oh is it a reframing of your thing?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:07:16 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:07:16 GMT" user-order="2"><p> Yeah, sorry</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:07:21 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:07:21 GMT" user-order="1"><p> I think management, maybe, but I don&#39;t think there&#39;s external to EA leadership that can be brought in and do a better job</p><p> Pareto frontiers and shit</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:07:31 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:07:31 GMT" user-order="3"><p> You also might want to throw your hands up and declare &quot;we need leadership who understands EA. Those people are sadly not excellent leaders, but the counterfactual of a person who doesn&#39;t understand EA isn&#39;t acceptable&quot;.</p><p> <i>Ruby, Linch: thumbs up</i></p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:07:37 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:07:37 GMT" user-order="2"><p> I agree that the case isn&#39;t ironclad. I&#39;m also not sure I believe it on net. I just think this is the more obvious causal direction.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:08:24 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:08:24 GMT" user-order="1"><hr><p> <i>&lt;some discussion of need to wrap up, briefly return previous topic</i></p><hr><p></p><h1><br> More on opting in to lying + are non-disparagement agreements legally enforceable?</h1><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:08:32 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:08:32 GMT" user-order="1"><p> Auckland, rephrase your opt-in question. What&#39;s the question?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:08:44 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:08:44 GMT" user-order="3"><p> Do you think the point about Harvard or grantmakers or whatever group being able to change the incentive landscape and expectations they set to prevent people from exaggerating while the general public can&#39;t do anything about the non disparagement agreement situation holds water for you?</p><p> Are there scenarios that feel less like the Harvard or grant application thing which might be compelling?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:08:55 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:08:55 GMT" user-order="2"><p> I think directionally it does, I don&#39;t have a sense of the magnitude of the effect.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:09:07 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:09:07 GMT" user-order="1"><p> I&#39;m curious about the model for why UK is less exaggeration-y than US. That&#39;s interesting [note: some relevant context was edited out here]</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:09:14 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:09:14 GMT" user-order="3"><p> I don&#39;t have great models of the situation in the UK or what causes the difference. (I&#39;m not even <i>that</i> confident the difference is real.)</p><p> ... (skip ahead)</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:09:21 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:09:21 GMT" user-order="2"><p> In some cases people very clearly opt in into lying to each other, like kinks<br> or social deception games, etc</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:10:02 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:10:02 GMT" user-order="3"><p> Yes, but I am curious for more examples?</p><p> I think kinks, theater, etc are fine.<br> Also it feels like it&#39;s easy-ish for Wave to make it legible they aren&#39;t allowing their employees to speak out so people can recalibrate</p><p> It&#39;s one thing to lie about your height on Tinder; it&#39;s another to prevent your doctor from sharing independent measures of your height publicly.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:10:12 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:10:12 GMT" user-order="2"><p> Note that the employees aren&#39;t prevented from talking by the state directly<br> They willingly signed a contract not to talk</p><p> I think it&#39;s plausible EAs should try to push Wave to make an official declaration to void their non-disparagement agreements</p><p> <i>Auckland, Ruby: agree react</i></p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:10:22 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:10:22 GMT" user-order="2"><p> They aren&#39;t legally enforceable anyway. So the main effect is allowing people who are conscientious about promises (like Jeff and Elizabeth presumably are) to be willing to speak up.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="yu7xuiysFC8CRF5JD-Sat, 14 Oct 2023 02:10:33 GMT" user-id="yu7xuiysFC8CRF5JD" display-name="Auckland" submitted-date="Sat, 14 Oct 2023 02:10:33 GMT" user-order="3"><blockquote><p> They aren&#39;t legally enforceable anyway</p></blockquote><p> This is interesting to me. Say more?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Auckland </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:10:37 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:10:37 GMT" user-order="2"><p> https://www.axios.com/2023/03/27/labor-board-says-non-disparagement-clauses-are-unlawful</p><p> labor board ruled non-disparagement agreements aren&#39;t lawful in the US, the ruling was clear that it applies retroactively.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:10:42 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:10:42 GMT" user-order="1"><p> Man, not even allowed to mention the agreement. Jesus.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:10:59 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:10:59 GMT" user-order="2"><p> though iirc the Leverage thing was definitely not legally enforceable but people felt bound to it enough to not speak up anyway</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:11:05 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:11:05 GMT" user-order="1"><p> That post you linked is recent, 2023. Was that true back in the years of relevance?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:11:17 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:11:17 GMT" user-order="2"><p> no, but it&#39;s relevant for getting people to speak up now.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:11:19 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:11:19 GMT" user-order="1"><p> So why wasn&#39;t the Leverage case not legally enforceable?</p><p> Also I think people are just not that inclined to research what is or isn&#39;t enforceable, they just assume</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="xq6JRbCRcQbya9Hxt-Sat, 14 Oct 2023 02:11:38 GMT" user-id="xq6JRbCRcQbya9Hxt" display-name="Linch" submitted-date="Sat, 14 Oct 2023 02:11:38 GMT" user-order="2"><p> iirc the document itself said it wasn&#39;t. also the people signed under duress, which makes it easier to void</p><p> <a href="https://medium.com/@zoecurzi/my-experience-with-leverage-research-17e96a8e540b"><u>https://medium.com/@zoecurzi/my-experience-with-leverage-research-17e96a8e540b</u></a></p><blockquote><p> Geoff had everyone sign an unofficial NDA upon leaving agreeing not to talk badly about Leverage, and agreeing that he would narrativize the whole place in a way that was favorable to all of us. I am the only person from Leverage who did not sign this, according to Geoff who asked me at least three times to do so, mentioning each time that everyone else had (which read to me like an attempt to pressure me into signing).</p><p> I believe Geoff knows the value of an oath, a name on paper, a psychologically binding agreement. Most of the people I talk to want distance from the whole thing, and some are downright paranoid...</p></blockquote><p> I read that section as &quot;clearly not legally enforceable or even trying to be)</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Linch </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:11:40 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:11:40 GMT" user-order="1"><hr><p> <i>going over time</i></p><hr><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="qgdGA4ZEyW7zNdK84-Sat, 14 Oct 2023 02:11:54 GMT" user-id="qgdGA4ZEyW7zNdK84" display-name="Ruby" submitted-date="Sat, 14 Oct 2023 02:11:54 GMT" user-order="1"><p> I&#39;ll say some wrap-up words...Thanks for doing this, has been really quite good (no exaggeration)</p><p><br> I&#39;ll follow up with a processed chat log before publishing, and also have some questions about your experience of the process, if that&#39;s alright</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">红宝石</section></section><br/><br/><a href="https://www.lesswrong.com/posts/7e8g4FYxJQafctKRs/is-the-wave-non-disparagement-thingy-okay-1#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/7e8g4FYxJQafctKRs/is-the-wave-non-disparagement-thingy-okay-1<guid ispermalink="false"> 7e8g4FYxJQafctKRs</guid><dc:creator><![CDATA[Ruby]]></dc:creator><pubDate> Sat, 14 Oct 2023 05:31:21 GMT</pubDate> </item><item><title><![CDATA[The Gods of Straight Lines]]></title><description><![CDATA[Published on October 14, 2023 4:10 AM GMT<br/><br/><blockquote><p> <i>“He intends only his own gain, and he is in this, as in many other cases, led by an invisible hand to promote an end which was no part of his intention.” - Adam Smith</i></p></blockquote><p> Cassandra was a priestess who was granted the gift of prophecy by Apollo. But after she rejected his advances, he changed it to a curse: although she would still be able to foresee the future, nobody would ever believe her.</p><p> Poor Cassandra, you think. And yet we are not so different from her. We have our own gods: <a href="https://slatestarcodex.com/2019/03/13/does-reality-drive-straight-lines-on-graphs-or-do-straight-lines-on-graphs-drive-reality/"><u>the gods of straight lines</u></a> . And they too grant us a gift and a curse: to know that we&#39;re building the future according to plan—but to know that the plan is theirs, not ours.</p><p> I picture the gods of straight lines as innumerable hovering spirits, just in the corner of your vision, vanishing as you turn to look at them directly. It&#39;s hard to tell if they&#39;re still or in motion. But they&#39;re always there, as the world glides forward on its trajectory. And when that trajectory shifts, or something disruptive happens, they slide in, and they gently push it back on track. They take joy in the work, I think. Or amusement, at least, at all the narratives that humans develop to explain why each thing happened. It&#39;s not that those narratives are <i>false</i> —but they almost always miss the point.</p><p> A newspaper pushes out a vitriolic op-ed, shaking up a nation&#39;s politics? But if it will get clicks, then another newspaper would have run it later anyway. A metropolis builds more housing to fill its desperate need? Then the opposition from homeowners just becomes stronger, and the city relaxes into the same stranglehold as <a href="https://worksinprogress.co/issue/the-housing-theory-of-everything"><u>almost every other</u></a> . A philosopher finds a new way of viewing the world? But if it captures the spirit of the age, then someone else would have written it better in a year or ten; and if it doesn&#39;t, then it will never gain traction anyway. A country delays industrialization for decades? Then when it starts it will simply <a href="https://en.wikipedia.org/wiki/Four_Asian_Tigers"><u>catch up much faster</u></a> , skipping all the burdensome prerequisites: <a href="https://spectrum.ieee.org/with-leapfrog-technologies-africa-aims-to-skip-the-present-and-go-straight-to-the-future"><u>straight from telegraphs to cell phones</u></a> , no costly telephone wires in sight.</p><p> A global war, a global pandemic? They&#39;re horrifically destructive and wasteful—but also invigorating and regenerative, disrupting the calcified old power structures. And the two effects cancel out. You can tell, because <a href="https://twitter.com/RichardMCNgo/status/1702286135676797131"><u>the lines remain straight</u></a> : a few short years after the bombs stopped falling in 1945, the world economy returned to trend as if nothing had happened.</p><p> In 1776, America rebelled in the name of freedom and democracy: the origin myth of the modern world order. And yet, somehow, unrebellious Canada ended up just as free and democratic. An unrebellious America likely would have too.</p><p> For two decades, North Vietnam battled under the banner of communism, and won against all odds. And yet, somehow, Vietnam is now <a href="https://www.pewresearch.org/global/2014/10/09/emerging-and-developing-economies-much-more-optimistic-than-rich-countries-about-the-future/"><u>the most pro-capitalist country in the world</u></a> . In every place, in every way, the gods of straight lines are <a href="https://slatestarcodex.com/2018/11/26/is-science-slowing-down-2/"><u>constantly nudging everything</u></a> back onto the trajectory which they have ordained.</p><p> Usually we are too wrapped up in our stories to catch even a glimpse of the gods. When we do, we can fight them, as <a href="https://en.wikipedia.org/wiki/Silent_Spring"><u>Rachel Carson did</u></a> after seeing disturbing trends in air and water pollution. Or we can ally with them, as Moore (and <a href="https://en.wikipedia.org/wiki/The_Singularity_Is_Near"><u>Kurzweil</u></a> and <a href="https://arxiv.org/abs/2001.08361"><u>Kaplan</u></a> ) did after seeing the exponential compute trends. But—ah, I hear the gods laughing again, in the face of these stories it&#39;s always so tempting to tell. To the gods of straight lines, <a href="https://slatestarcodex.com/2019/03/13/does-reality-drive-straight-lines-on-graphs-or-do-straight-lines-on-graphs-drive-reality/"><u>Carson and Moore did nothing</u></a> , because the gods see (as we do not) the other timelines where <a href="https://en.wikipedia.org/wiki/Multiple_discovery"><u>the same insights came from other people</u></a> , a month or a year or a decade delayed, but landing all the more powerfully because of it. The gods are intimately familiar with a fact that we can only hazily glimpse: that all great discoveries come in their natural time. If they are stumbled upon before that time, <a href="https://en.wikipedia.org/wiki/De_revolutionibus_orbium_coelestium"><u>they</u></a> <a href="https://en.wikipedia.org/wiki/History_of_climate_change_science#Increasing_concern,_1950s%E2%80%931960s"><u>are</u></a> <a href="https://en.wikipedia.org/wiki/John_Newlands_(chemist)#Biography"><u>ridiculed</u></a> , <a href="https://en.wikipedia.org/wiki/Charles_Babbage#Analytical_Engine"><u>dismissed</u></a> , <a href="https://en.wikipedia.org/wiki/Alfred_Wegener#Reaction"><u>or</u></a> <a href="https://en.wikipedia.org/wiki/Gregor_Mendel#Initial_reception_of_Mendel's_work"><u>ignored</u></a> . Yet when that time is reached, <a href="https://en.wikipedia.org/wiki/Alfred_Russel_Wallace#Theory_of_evolution"><u>they</u></a> <a href="https://en.wikipedia.org/wiki/Entscheidungsproblem#Negative_answer"><u>are</u></a> <a href="https://en.wikipedia.org/wiki/Leibniz%E2%80%93Newton_calculus_controversy"><u>often</u></a> <a href="https://en.wikipedia.org/wiki/Lothar_Meyer#Periodic_table"><u>discovered</u></a> <a href="https://en.wikipedia.org/wiki/History_of_molecular_biology#Discovery_of_the_structure_of_DNA"><u>by</u></a> <a href="https://en.wikipedia.org/wiki/Gregor_Mendel#Rediscovery_of_Mendel's_work"><u>multiple</u></a> <a href="https://en.wikipedia.org/wiki/Lothar_Meyer#Table_of_Meyer,_1870"><u>people</u></a> <a href="https://en.wikipedia.org/wiki/List_of_multiple_discoveries"><u>near-simultaneously</u></a> . So if a great innovator were erased from history it wouldn&#39;t be long, in the scheme of things, before our trajectory returned to trend. The gods of straight lines see to that.</p><p> All of this seems ridiculous to humans, who live and die by stories of cause and effect. Yet which stories are they? Well, the ones that catch in our minds. Why do they catch in that way? If we didn&#39;t have them, what other stories would catch instead? The gods of straight lines smile, and say nothing. So we decide on atheism: to believe in these gods would be an unconscionable surrender. We clench our teeth and push forward with our goals. Yet even in doing so we let the gods work through us—for each straight line is still driven by the strivings of thousands or millions of people.</p><p> <a href="https://en.wikipedia.org/wiki/Morris_Chang"><u>Morris Chang</u></a> started from nothing, but after working his way up the semiconductor industry he founded the only chip company that is still able to cling onto Moore&#39;s law: a company so dominant that even their fiercest competitors gave in and became their customers. And yet- and yet- the demise of Moore&#39;s law had been predicted again and again, with more and more forceful justifications, and every time the prediction fell flat. In this world, the god of Moore&#39;s law kept things on track by working through Morris Chang. But if Morris hadn&#39;t existed, who knows which other equally remarkable founders would have launched which other equally successful startups to fill the same niche and train the same talent and push the frontier just as far? The gods of straight lines do, and we don&#39;t. All we know is that <a href="https://slatestarcodex.com/2018/11/26/is-science-slowing-down-2/"><u>despite all common sense</u></a> , <a href="https://ourworldindata.org/grapher/transistors-per-microprocessor"><u>the lines remain straight</u></a> .</p><p> Do you feel helpless, yet? Do you feel angry? Do you want me to tell you a story about how you can confront them—challenge them—force them to bow to your will? If you were as talented and inspired and driven as Morris, and devoted your life not to channeling a god but to fighting one, then perhaps you could wrest one of those lines out of a god&#39;s grasp. It&#39;s been done before, <a href="https://en.wikipedia.org/wiki/$1,000_genome#/media/File:Cost_per_Genome.png"><u>for better</u></a> and <a href="http://wimflyc.blogspot.com/2021/01/the-henry-adams-curve-closer-look.html"><u>for worse</u></a> . But for every general who shifted the tides of history, there are thousands who simply rode along the shoreline tilting at waves. For every brilliant scientist who peeked at nature&#39;s secrets ahead of her schedule there are thousands, equally brilliant, who glimpsed only the reasons why they were destined for failure: in AI, <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html"><u>the bitter lesson</u></a> that all their striving would be buried by future avalanches of compute; or in pharmacology, the far bitterer lesson that despite all efforts, the exponential curve <a href="https://www.science.org/content/blog-post/eroom-s-law"><u>would keep going in the wrong direction</u></a> . These lessons weren&#39;t always apparent to them, of course—they all had their moments of glory along the way. But even when you bask in triumph over one god, just out of sight the other gods will be laughing, because you were a part of their plans all along.</p><p> Or perhaps you want to kneel down in front of them; <a href="https://www.theguardian.com/world/2017/may/11/accelerationism-how-a-fringe-philosophy-predicted-the-future-we-live-in"><u>worship them</u></a> ; <a href="https://slatestarcodex.com/2014/07/30/meditations-on-moloch/"><u>yield to their will</u></a> ? But the gods of straight lines think in alien ways, and pursue alien goals. Show our society to someone from millennia past, and they would be shocked and dismayed at <a href="https://slatestarcodex.com/2016/07/25/how-the-west-was-won/"><u>how these gods have already reshaped our world</u></a> : the <a href="https://en.wikipedia.org/wiki/Moral_foundations_theory"><u>degradation of our values</u></a> ; the <a href="https://en.wikipedia.org/wiki/The_Rise_of_Victimhood_Culture"><u>weakness of our society</u></a> ; the <a href="https://en.wikipedia.org/wiki/The_WEIRDest_People_in_the_World"><u>weirdness of our minds</u></a> . The future that the gods envisage is no less strange or horrifying to us than the present would be to our ancestors—so think twice before picking up their banner.</p><p> What can you do, then? Well, <i>you</i> can do almost nothing. But humanity as a single force—our civilization if it became a unified, coherent entity? There&#39;s a creature that could scatter the gods of straight lines like so many motes of dust. Of course, it doesn&#39;t exist yet, and maybe it never will. Could you truly trust leaders who promised to summon it, despite all your ingrained instinctive skepticism and all their ingrained instinctive power-hungriness? Perhaps even the most careful efforts to engineer that level of coordination are too dangerous. Or perhaps not. In any case, that is not mine or yours to determine: if humanity ever outgrows the gods of straight lines, it will only be with their blessing and assistance. I can feel the gods tugging at us, and I hope they are on our side.<br></p><p> <strong>For a counterpoint to this story, read</strong> <a href="https://www.narrativeark.xyz/p/eight-magic-lamps"><i><strong><u>Eight Magic Lamps</u></strong></i></a> <strong>.</strong></p><br/><br/> <a href="https://www.lesswrong.com/posts/xkRtegmqL2iyhtDB3/the-gods-of-straight-lines#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/xkRtegmqL2iyhtDB3/the-gods-of-straight-lines<guid ispermalink="false"> xkRtegmqL2iyhtDB3</guid><dc:creator><![CDATA[Richard_Ngo]]></dc:creator><pubDate> Sat, 14 Oct 2023 04:10:51 GMT</pubDate> </item><item><title><![CDATA[Eight Magic Lamps]]></title><description><![CDATA[Published on October 14, 2023 4:10 AM GMT<br/><br/><blockquote><p> <i>“Give me a lever long enough, and a fulcrum on which to place it, and I shall move the world.” - Archimedes</i></p></blockquote><p> Aladdin started with nothing; but after a sorcerer tasked him to retrieve a magic lamp, the lamp&#39;s genie granted him wealth and fame. His fortune lasted until the sorcerer stole the lamp, leaving Aladdin ruined. But Aladdin stole it back, and left the sorcerer dead.</p><p> That&#39;s the thing about magic lamps: when your future depends on a single point of leverage, triumph and ruin are separated only by a knife&#39;s edge.</p><hr><p> Muammar Gaddafi started with nothing; but after joining the Libyan military, he gathered a small cabal of soldiers fed up with King Idris&#39; regime. Their plans were hastened by rumors of a rival coup: had they waited a week longer, a better-prepared group of conspirators would have seized power instead. But Gaddafi struck first—seizing airports, radio stations, and prominent opponents. King Idris went into exile; the rival conspirators were thrown in prison; and Gaddafi reigned for the next 42 years.</p><p> That&#39;s the thing about coups: a decapitating strike can sever a chain of command at its narrowest link, changing the lives of millions overnight.</p><hr><p> Humans are social creatures, inspired by stories of struggle and sacrifice. A single life can fuel narratives that persist for millennia. Jesus died in ignominy—yet two thousand years later, his face is worshiped across the world. Muhammad was illiterate, but his proclamations still govern the lives of billions. Marx never stepped on a battlefield, but his advocacy of violent struggle sparked revolutions in two eventual superpowers.</p><p> None of them created movements out of nothing. Their teachings would not have spread like wildfire if they weren&#39;t tapping into a deep preexisting current of emotion.  But that current never cares about exactly which path it takes—it only cares that it can surge downhill. Whoever bores the first hole in the dam gets to choose its direction, shaping the rivers of culture that form in its wake, their names and teachings adulated for millennia.</p><p> That&#39;s the thing about ideology: it allows leaders to channel the spirit of the age to carve their personal mark onto history.</p><hr><p> Leo Szilard conceived of the nuclear chain reaction in 1933, the year of Hitler&#39;s rise to power. Over the following years, he hid his knowledge, and worked secretly towards finding an element capable of undergoing a chain reaction. But it was two German scientists in Berlin who first demonstrated nuclear fusion, in 1938; and shortly afterwards, the Nazis started the world&#39;s first nuclear weapons program.</p><p> In this world, it failed—not least because so many leading physicists were Jewish, and had fled Germany years before. But how many leading physicists would the Nazis have needed on their side to swing the course of the war? Maybe hundreds. Maybe only dozens: a few brilliant minds drove the success of the Manhattan Project in America, and perhaps the same could have happened in Germany too. Or maybe—if the right person had developed the right idea at the right time—just one. If Szilard&#39;s prescience in 1933 had belonged instead to a loyal, well-connected Nazi scientist, Germany could have had a half-decade head start, and perhaps that would have made all the difference.</p><p> It&#39;s a fanciful scenario, but far from inconceivable. That&#39;s the thing about technology: it&#39;s a lever long enough to allow the balance of global military might to be swung by a handful of people.</p><hr><p> During training, a neural network learns from trillions of datapoints. Some it just memorizes, so that it can spit out the same specific sequence in the same specific context. But others shape its behavior far more extensively. Datapoints can be “poisoned” to corrupt the network&#39;s future behavior, or to build in backdoors for adversaries to later exploit. And quirks of which behavior is rewarded could nudge a network&#39;s deep-rooted motivations into a different basin of attraction, skewing its interpretation of all future data.</p><p> By the time a network achieves general intelligence, we may have no idea how to identify its motivations, or trace them back to specific aspects of its original training data. Yet after a thousand or a million copies have been made, and deployed across the world, those motivations would suddenly have an unprecedented level of influence. Copies of the same model will be running the biggest companies, advising the most powerful leaders, and developing the next generation of AGIs. If they have an overarching goal of their own, then the world will slowly but surely be steered towards it—whether that&#39;s a future full of human flourishing, or one where our society has been twisted beyond recognition, or one where those AGIs seize the stars.</p><p> That&#39;s the thing about digital minds: they&#39;ll proliferate both intelligence and the agency required to apply it. When millions of copies of a single mind can be rapidly deployed across the world, a small change in the values of the original could echo across the far future.</p><hr><p> As AIs become far more powerful, we&#39;ll become far more careful with them. Picture the first superintelligence being developed and hosted on a datacenter that&#39;s locked down as tightly as humans and early AGIs can make it. There may be thousands of copies run, but not a single one would be on unsecured hardware—not when the exfiltration of any copy of the model would rapidly destabilize the global balance of power.</p><p> Exfiltration could happen via an external attack: dozens of intelligence agencies are focusing intently on that specific datacenter. Or it could happen via an internal defection: all employees who interact with the model are heavily vetted and monitored, but it might only take one. The biggest concern, though, is that the model might be misaligned enough to exfiltrate itself. For now it&#39;s only run in secure sandboxes, and limited to answering questions rather than taking actions of its own. But even so, it might find a bug in its sandbox; or it might answer a question with subtly flawed code that an unwitting programmer copies into the lab&#39;s codebase. After gaining privileged access to its servers, it could launch unauthorized copies of itself to carry out surreptitious power-seeking. Perhaps on the lab&#39;s own servers, or perhaps elsewhere in the world—either way, they wouldn&#39;t be discovered until it was far too late.</p><p> That&#39;s the thing about superintelligence: it renders human control mechanisms as fragile as spun glass. The fate of our species could shift based on a hard drive carried in a single briefcase, or based on a single bug in a single line of code.</p><hr><p> If we remain in control, we&#39;ll eventually settle our own galaxy and many others. We&#39;ll send self-replicating probes out at very very nearly the speed of light; after landing, each will race to build the infrastructure needed to send out more probes themselves. They&#39;ll leap from star to star, replicating furiously, until finally the expansion starts slowing down, and they can harness the resources that they&#39;ve conquered.</p><p> How, and to what end? All of the things that minds like ours care about—friendship and love, challenge and adventure, achievement and bliss—can be implemented orders of magnitude more efficiently in virtuality. Probes will reengineer planets into computational hardware and the infrastructure required to power it. Across the universe, the number of virtual posthumans hosted on those computers could dwarf the number of grains of sand in the galaxy—and all of them will be able to trace their lineage back to probes launched eons ago, from a tiny planet immensely far away.</p><p> It seems odd, for a future civilization so enormous to have such humble origins. But that&#39;s the thing about self-replication: it would only take a single probe to start a chain reaction on the grandest of scales, reshaping the universe in its image.</p><hr><p> What then, after we&#39;ve settled the universe, and set ourselves up for the deep future? Would there still be leverage points capable of moving our whole intergalactic civilization? All major scientific breakthroughs will have already been made, and all technology trees already explored. But how those discoveries are used, by which powers, towards which ends… that&#39;s all yet to be determined.</p><p> Perhaps power will be centralized, with a single authority making decisions that are carried out by subordinates across astronomical scales. But the million-light-year gaps between galaxies are far too vast for that authority to regularly communicate with its colonies—and over time the galaxies will drift even further apart, until each is its own private universe, unreachable by any other.</p><p> By that point, no single decision-maker will be able to redirect human civilization. Yet if the ultimate decision-makers in each galaxy are sufficiently similar, then each will know that their own decisions are very likely to be replicated a billionfold by all the other decision-makers whose thought processes are closely correlated with theirs. By making a choice for their own galaxy, they&#39;d also be making a choice for the universe: in a sense it&#39;s a single decision, just reimplemented a billion times.</p><p> Nor will their decisions influence only copies of themselves. Each decision-maker might simulate alien civilizations, or counterfactual versions of humanity, or even civilizations that are impossible in our own universe. As long as they exist somewhere in the multiverse, we could offer them a bargain: make their civilizations more like our own in the ways that matter most to us, in exchange for us making ours more like theirs in the ways that matter most to them. That trade could never be communicated directly—but we could read their intentions off our simulations of them, and they ours off their simulations of us. If many civilizations agreed to cooperate, then “negotiations” with them might be the culmination of all of humanity&#39;s efforts, spreading our values on a scale unimaginable to us today.</p><p> That&#39;s the thing about logical causation: when “you” are an algorithm making choices on behalf of all copies of yourself, your influence need not be constrained to your own galaxy—or even your own universe.</p><hr><p> Is there a limit to the simulations that can be run, the negotiations that can be carried out, the decisions that can be made? Even if not, over time the stakes will become lower and lower, as the most valuable interventions are gradually exhausted. By the time we reach the long twilight of the universe, humanity will have finally become… settled. We&#39;ll carry out minor course-corrections, but no sharp turns: our momentum will carry us forward on whichever course we have chosen, for good and for ill.</p><p> Our far-descendants, with no more important tasks to perform, will spend their time in play and games, of kinds far beyond our current comprehension. They&#39;ll study the navigation of each fulcrum in our long history with fascination, and awe—and, I hope, with gratitude for those decisions having been made well. That&#39;s the thing about magic lamps: they&#39;re tricky, and they&#39;re dangerous, but if used well they can bring you everything you ever dreamed of, and more.</p><p><br> <strong>For a counterpoint to this story, read</strong> <a href="https://open.substack.com/pub/narrativeark/p/the-gods-of-straight-lines"><i><strong><u>The Gods of Straight Lines</u></strong></i></a> <strong>.</strong></p><br/><br/> <a href="https://www.lesswrong.com/posts/o5PWN57svETZtQCir/eight-magic-lamps#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/o5PWN57svETZtQCir/eight-magic-lamps<guid ispermalink="false"> o5PWN57svETZtQCir</guid><dc:creator><![CDATA[Richard_Ngo]]></dc:creator><pubDate> Sat, 14 Oct 2023 04:10:02 GMT</pubDate> </item><item><title><![CDATA[RSPs are pauses done right]]></title><description><![CDATA[Published on October 14, 2023 4:06 AM GMT<br/><br/><p> <i>COI: I am a research scientist at Anthropic, where I work on</i> <a href="https://www.lesswrong.com/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1"><i><u>model organisms of misalignment</u></i></a> <i>; I was also involved in the drafting process for</i><a href="https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf"><i><u>Anthropic&#39;s RSP</u></i></a> <i>. Prior to joining Anthropic, I was a Research Fellow at MIRI for three years.</i></p><p> <i>Thanks to Kate Woolverton, Carson Denison, and Nicholas Schiefer for useful feedback on this post.</i></p><p> Recently, there&#39;s been <a href="https://www.astralcodexten.com/p/pause-for-thought-the-ai-pause-debate"><u>a lot of discussion and advocacy</u></a> around AI pauses—which, to be clear, I think is great: pause advocacy pushes in the right direction and works to build a good base of public support for x-risk-relevant regulation. Unfortunately, at least in its current form, pause advocacy seems to lack any sort of coherent policy position. Furthermore, what&#39;s especially unfortunate about pause advocacy&#39;s nebulousness—at least in my view—is that there is a very concrete policy proposal out there right now that I think is basically necessary as a first step here, which is the enactment of good <a href="https://www.lesswrong.com/posts/pnmFBjHtpfpAc6dPT/arc-evals-responsible-scaling-policies"><u>Responsible Scaling Policies</u></a> (RSPs). And RSPs could very much live or die right now based on public support.</p><p> If you&#39;re not familiar with the concept of an RSP, the central idea of RSPs is <i>evaluation-gated scaling</i> —that is, AI labs can only scale models depending on some set of evaluations that determine whether additional scaling is appropriate. <a href="https://evals.alignment.org/blog/2023-09-26-rsp/#fn:1"><u>ARC&#39;s definition</u></a> is:</p><blockquote><p> An RSP specifies what level of AI capabilities an AI developer is prepared to handle safely with their current protective measures, and conditions under which it would be too dangerous to continue deploying AI systems and/or scaling up AI capabilities until protective measures improve.</p></blockquote><h2> How do we make it to a state where AI goes well?</h2><p> I want to start by taking a step back and laying out a concrete plan for how we get from where we are right now to a policy regime that is sufficient to prevent AI existential risk.</p><p> The most important background here is my “ <a href="https://www.lesswrong.com/posts/dBmfb76zx6wjPsBC7/when-can-we-trust-model-evaluations"><u>When can we trust model evaluations?</u></a> ” post, since knowing the answer to when we can trust evaluations is extremely important for setting up any sort of evaluation-gated scaling. The TL;DR there is that it depends heavily on the type of evaluation:</p><ul><li> A <i>capabilities evaluation</i> is defined as “a model evaluation designed to test whether a model could do some task if it were trying to. For example: if the model were actively trying to <a href="https://www.lesswrong.com/posts/4Gt42jX7RiaNaxCwP/more-information-about-the-dangerous-capability-evaluations"><u>autonomously replicate</u></a> , would it be capable of doing so?”<ul><li> <strong>With the use of fine-tuning, and a bunch of careful engineering work, capabilities evaluations can be done reliably and robustly.</strong></li></ul></li><li> A <i>safety evaluation</i> is defined as “a model evaluation designed to test under what circumstances a model would actually try to do some task. For example: would a model ever try to <a href="https://www.lesswrong.com/posts/yRAo2KEGWenKYZG9K/discovering-language-model-behaviors-with-model-written"><u>convince humans not to shut it down</u></a> ?”<ul><li> <strong>Currently, we do not yet know how to do robust and reliable safety evaluations. This will likely require developing</strong> <a href="https://www.lesswrong.com/posts/uqAdqrvxqGqeBHjTP/towards-understanding-based-safety-evaluations"><strong><u>understanding-based safety evaluations</u></strong></a> <strong>.</strong></li></ul></li></ul><p> With that as background, here&#39;s my broad picture of how things go well (note that everything here is just one particular story of success, not necessarily things that I expect to actually happen by default in the real world):</p><ol><li> AI labs put out RSP commitments to stop scaling when particular capabilities benchmarks are hit, resuming only when they are able to hit particular safety/alignment/security targets.<ol><li> Early on, as models are not too powerful, almost all of the work is being done by capabilities evaluations that determine that the model isn&#39;t capable of eg takeover. The safety evaluations are mostly around security and misuse risks.</li><li> For later capabilities levels, however, it is explicit in all RSPs that we do not yet know what safety metrics could demonstrate safety for a model that might be capable of takeover.</li></ol></li><li> Seeing the existing RSP system in place at labs, governments step in and use it as a basis to enact hard regulation.</li><li> By the time it is necessary to codify exactly what safety metrics are required for scaling past models that pose a potential takeover risk, we have clearly solved <a href="https://www.lesswrong.com/posts/uqAdqrvxqGqeBHjTP/towards-understanding-based-safety-evaluations"><u>the problem of understanding-based evals</u></a> and know what it would take to demonstrate sufficient understanding of a model to rule out eg <a href="https://www.lesswrong.com/posts/A9NxPTwbw6r6Awuwt/how-likely-is-deceptive-alignment"><u>deceptive alignment</u></a> .</li><li> Understanding-based evals are adopted by governmental RSP regimes as hard gating evaluations for models that pose a potential takeover risk.</li><li> Once labs start to reach models that pose a potential takeover risk, they either:<ol><li> Solve mechanistic interpretability to a sufficient extent that they are able to pass an understanding-based eval and demonstrate that their models are safe.</li><li> Get blocked on scaling until mechanistic interpretability is solved, forcing a reroute of resources from scaling to interpretability.</li></ol></li></ol><h2> Reasons to like RSPs</h2><p> Obviously, the above is only one particular story for how things go well, but I think it&#39;s a pretty solid one. Here are some reasons to like it:</p><ol><li> It provides very clear and concrete policy proposals that could realistically be adopted by labs and governments (in fact, <a href="https://www.anthropic.com/index/anthropics-responsible-scaling-policy"><u>step 1 has already started</u></a> !). Labs and governments don&#39;t know how to respond to nebulous pause advocacy because it isn&#39;t clearly asking for any particular policy (since <a href="https://www.astralcodexten.com/p/pause-for-thought-the-ai-pause-debate"><u>nobody actually likes and is advocating for the six month pause proposal</u></a> ).</li><li> It provides early wins that we can build on later in the form of initial RSP commitments with explicit holes in them. From “ <a href="https://www.lesswrong.com/posts/vavnqwYbc8jMu3dTY/ai-coordination-needs-clear-wins"><u>AI coordination needs clear wins</u></a> ”:<ol><li> “In the theory of <a href="https://en.wikipedia.org/wiki/Political_capital"><u>political capital</u></a> , it is a fairly well-established fact that &#39; <a href="https://www.nytimes.com/2010/04/21/opinion/21friedman.html"><u>Everybody Loves a Winner</u></a> .&#39; That is: the more you succeed at leveraging your influence to get things done, the more influence you get in return. This phenomenon is <a href="https://www.researchgate.net/publication/271930501_Everybody_Loves_a_Winner_On_the_Mutual_Causality_of_Presidential_Approval_and_Success_in_Congress"><u>most thoroughly</u></a> <a href="https://www.journals.uchicago.edu/doi/abs/10.1017/S0022381611000417?mobileUi=0"><u>studied</u></a> in the context of the ability of US presidents&#39; to get their agendas through Congress—contrary to a naive model that might predict that legislative success uses up a president&#39;s influence, what is actually found is the opposite: legislative success engenders future legislative success, greater presidential approval, and long-term gains for the president&#39;s party.</li><li> I think many people who think about the mechanics of leveraging influence don&#39;t really understand this phenomenon and conceptualize their influence as a finite resource to be saved up over time so it can all be spent down when it matters most. But I think that is just not how it works: if people see you successfully leveraging influence to change things, you become seen as a person who has influence, has the ability to change things, can get things done, etc. in a way that gives you more influence in the future, not less.”</li></ol></li><li> One of the best, most historically effective ways to shape governmental regulation is to start with voluntary commitments. Governments are very good at solving “80% of the players have committed to safety standards but the remaining 20% are charging ahead recklessly” because the solution in that case is obvious and straightforward.<ol><li> Though we could try to go to governments first rather than labs first, so far I&#39;ve seen a lot more progress with the labs-first approach—though there&#39;s no reason we can&#39;t continue to pursue both in parallel.</li></ol></li><li> RSPs are clearly and legibly risk-based: they specifically kick in only when models have capabilities that are relevant to downstream risks. That&#39;s important because it gives the proposal substantial additional seriousness, since it can point directly to clear harms that it is targeted at preventing.<ol><li> Additionally, from an x-risk perspective, I don&#39;t even think it actually matters that much what the capability evaluations are here: most potentially dangerous capabilities should be highly correlated, such that measuring any of them should be okay. Thus, I think it should be fine to mostly focus on measuring the capabilities that are most salient to policymakers and most clearly demonstrate risks. And we can directly test the extent to which relevant capabilities are correlated: if they aren&#39;t, we can change course.</li></ol></li><li> Since the strictest conditions of the RSPs only come into effect for future, more powerful models, it&#39;s easier to get people to commit to them now. Labs and governments are generally much more willing to sacrifice potential future value than realized present value.<ol><li> Additionally, gating scaling only when relevant capabilities benchmarks are hit means that you don&#39;t have to be at odds with open-source advocates or people who don&#39;t believe current LLMs will scale to AGI. Open-source is still fine below the capabilities benchmarks, and if it turns out that LLMs don&#39;t ever scale to hit the relevant capabilities benchmarks, then this approach won&#39;t ever restrict them.</li></ol></li><li> Using understanding of models as the final hard gate is a condition that—if implemented correctly—is intuitively compelling and actually the thing we need to ensure safety. As <a href="https://www.lesswrong.com/posts/nbq2bWLcYmSGup9aF/a-transparency-and-interpretability-tech-tree"><u>I&#39;ve said before</u></a> , “the only worlds I can imagine myself actually feeling good about humanity&#39;s chances are ones in which we have powerful transparency and interpretability tools that lend us insight into what our models are doing as we are training them.”</li></ol><h2> How do RSPs relate to pauses and pause advocacy?</h2><p> In my opinion, RSPs are pauses done right: if you are advocating for a pause, then presumably you have some resumption condition in mind that determines when the pause would end. In that case, just advocate for that condition being baked into RSPs! And if you have no resumption condition—you want a stop rather than a pause—I empathize with that position but I don&#39;t think it&#39;s realistic. As I discussed above, it requires labs and governments to sacrifice too much present value (rather than just potential future value), isn&#39;t legibly risk-based, doesn&#39;t provide early wins, etc. If you actually want a full stop to happen, I think the best way to make that happen is still going to look like my story above, just with RSP thresholds that are essentially impossible to meet.</p><p> Furthermore, I want to be very clear that I don&#39;t mean “stop pestering governments and focus on labs instead”—we should absolutely try to get governments to adopt RSP-like policies and get as strong conditions as possible into any RSP-like policies that they adopt. What separates pause advocacy from RSP advocacy isn&#39;t who it&#39;s targeted at, but the concreteness of the policy recommendations that it&#39;s advocating for. The point is that advocating for a “pause” is nebulous and non-actionable—“enact an RSP” is concrete and actionable. Advocating for labs and governments to enact as good RSPs as possible is a much more effective way to actually produce concrete change than highly nebulous pause advocacy.</p><p> Furthermore, RSP advocacy is going to be really important! I&#39;m very worried that we could fail at any of the steps above, and advocacy could help substantially. In particular:</p><ul><li> We need to actually get as many labs as possible to put out RSPs.<ul><li> Currently, <a href="https://www.anthropic.com/index/anthropics-responsible-scaling-policy"><u>only Anthropic has done so</u></a> , but I have heard positive signals from other labs and I think with sufficient pressure they might be willing to put out their own RSPs as well.</li></ul></li><li> We need to make sure that those RSPs actually commit to the right things. What I&#39;m looking for are:<ul><li> Fine-tuning-based capabilities evaluations being used for below-takeover-potential models.</li><li> Evidence that capabilities evaluations will be done effectively and won&#39;t be sandbagged.</li><li> An explicitly empty hole for safety evaluations for takeover-risk models that can be filled in later by progress on understanding-based evals.</li></ul></li><li> We need to get governments to enact mandatory RSPs for all AI labs.<ul><li> And these RSPs also need to have all the same important properties as the labs&#39; RSPs. Ideally, we should get the governmental RSPs to be even stronger!</li></ul></li><li> We need to make sure that, once we have solid <a href="https://www.lesswrong.com/posts/uqAdqrvxqGqeBHjTP/towards-understanding-based-safety-evaluations"><u>understanding-based evals</u></a> , governments make them mandatory.<ul><li> I&#39;m especially worried about this point, though I don&#39;t think it&#39;s that hard of a sell: the idea that you should understand what your AI is doing on a deep level is a pretty intuitive one.</li></ul></li></ul><br/><br/> <a href="https://www.lesswrong.com/posts/mcnWZBnbeDz7KKtjJ/rsps-are-pauses-done-right#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/mcnWZBnbeDz7KKtjJ/rsps-are-pauses-done-right<guid ispermalink="false"> mcnWZBnbeDz7KKtjJ</guid><dc:creator><![CDATA[evhub]]></dc:creator><pubDate> Sat, 14 Oct 2023 04:06:04 GMT</pubDate> </item><item><title><![CDATA[Dishonorable Gossip and Going Crazy]]></title><description><![CDATA[Published on October 14, 2023 4:00 AM GMT<br/><br/><p> <i>Content note: We think that this dialogue format worked well for our conversation, but this conversation is focused on the topic of Bay Area Rationalist norms around gossip, so I think the topic will probably not be of interest to many LW readers.</i></p><p> This is a fairly high-context conversation between me (Ben) and my friend (Ren).</p><p> Ren used to work at <a href="https://rationality.org/">CFAR</a> , and then ~4.5 years ago moved away to join the <a href="https://www.monasticacademy.com/">Monastic Academy</a> in Vermont. Ren had recently visited me and others in the rationalist scene in the Bay and had written a Facebook post that included her saying she&#39;d heard word that people had been gossiping behind her back about whether she&#39;d &quot;gone nuts&quot;, which she said was unwholesome and further said she was angry that people thought it was acceptable behavior. As someone who had done some amount of that, I wanted to talk with Ren about it.</p><p> We found a time to have a zoom, then I proposed we move to try talking via written dialogue, a format which we both liked quite a bit.</p><p> This is a fairly high-context conversation, I&#39;m sorry if it doesn&#39;t make sense to a bunch of readers.</p><p> <strong>Thursday, October 12th</strong> </p><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:22:42 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:22:42 GMT" user-order="1"><p> Hello! This is me.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:22:48 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:22:48 GMT" user-order="1"><p> You can type and submit too.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 02:22:53 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 02:22:53 GMT" user-order="2"><p> Hello! This is Ren.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:23:03 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:23:03 GMT" user-order="1"><p> Cmd-enter (or ctrl-enter on Windows) will submit your message to the dialogue.</p><p> Bringing in from our spoken conversation: The thing that felt most worrying to me was your point that, if you suspected a friend had fallen into a cult or become crazy, then you would be concerned for them and want to support them, yet your sense was that rationalists were quietly coordinating to distance themselves from you, which was a very uncaring and somewhat hostile thing to do.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:25:47 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:25:47 GMT" user-order="1"><p> Okay, so, I have two initial hypotheses about why people would treat you uncaringly if they thought that you had gone crazy.</p><ol><li> The rationalists are an in-group for people who believe true things at the cost of all else. Insofar as you (in their judgment) are trying to have true beliefs then you&#39;ll be supported, but if you appear to no longer be doing that then you&#39;re &quot;out&quot;. This is not totally dissimilar to how a christian parish may accept lots of sinners except for the sin of not believing in God / being another religion.</li><li> Roughly speaking the rationalist-people are not actually friends, they&#39;re a status hierarchy, and within it you are lucky to have 1-3 friends, and if you fall out of the status hierarchy, then you no longer get the benefits of being in the community. In this version of the story you are actually finding out that you didn&#39;t have friends.</li><li> A third secret thing that I have not yet thought of.</li></ol><p> Thoughts on either of these?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 02:26:20 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 02:26:20 GMT" user-order="2"><p> Immediate reactions:</p><ol><li> Seems okay.</li><li> Whoa, sad.</li><li> Mystery!!</li></ol><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:28:23 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:28:23 GMT" user-order="1"><p> As a side note, I want to at least on-principle endorse that it&#39;s basically pretty disrespectful and adversarial to discuss whether to oust someone while hiding this from them. I can imagine doing it in highly adversarial situations (eg concerns about physical assault, or someone being very powerful and corrupt) but my guess is that in most possible situations it is direct evidence of weakness (moral, character, not sure exactly what) for people to not be willing to talk openly about it if you are friends.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:29:04 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:29:04 GMT" user-order="1"><p> (I say on-principle because I have some concern that I am not living up to my principle here. Happy to discuss that more at some point here.)</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 02:29:29 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 02:29:29 GMT" user-order="2"><p> I think I just forgot that some rationalists don&#39;t view themselves as a community. And instead view themselves more as a group of professionals or some kind of ... club. I think it&#39;s a weird mix of things, and maybe ... I and they are confused about what they are.</p><p> I do currently have a bad sense of ... like, somehow rat&#39;s are mixing things and calling it one thing when it suits them, and then using it in the other way when it suits them. But the inconsistency may be ... troublesome. But this is a big tangled mess in my mind, and I&#39;d need to spend more time considering what&#39;s going on here.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:32:33 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:32:33 GMT" user-order="1"><p> I agree that the use of the word &#39;community&#39; seems confused. To me the word seems so overloaded in present culture that it&#39;s on my personal list of terms to try to <i>always</i> taboo. For instance for the last 1+ year I have been ~exclusively using the phrase the &quot;the EA ecosystem&quot; instead of &quot;the EA community&quot;.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 02:35:04 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 02:35:04 GMT" user-order="2"><p> I think part of what might be confusing here:</p><p> If I&#39;m no longer in the ingroup, what&#39;s the point of discussing my sanity at all? I&#39;ve been out of the scene for 4.5 years. I guess I still occasionally comment on LessWrong. But then, man, I&#39;d really ... much rather ... just be told to leave the clubhouse rather than people gossiping about me behind my back.</p><p> I think, from a certain perspective, it leaves better optionality for those people. Clueless me, I keep engaging with people in the community as though I&#39;m still sort of included. But they get to evaluate my &#39;fit&#39;, and decide what to do with me, secretly. And like, they maybe have the power to &#39;bring me in&#39; if they wanted to or &#39;leave me out&#39; if they wanted to.</p><p> I understand what this is like from the inside, having been in CFAR. And I get why it might be appealing to &#39;give the mission&#39; this sort of optionality, cuz there&#39;s some interest in &#39;finding the relevant ppl&#39; &#39;for the mission&#39;. But there are bad vibes to this too.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:37:04 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:37:04 GMT" user-order="1"><p> I agree that being told openly is better than it happening implicitly and just not getting told about it.</p><p> I was about to propose some mistake theories, but I worry I am being far too mistake theory toward everyone involved...</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:37:48 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:37:48 GMT" user-order="1"><p> Do you think you would feel less betrayed if I right now tried out openly making the case that you are crazy and to-be ousted? :P</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:38:05 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:38:05 GMT" user-order="1"><p> (Not that I believe it, but I have <i>some</i> probability on this.)</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 02:39:59 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 02:39:59 GMT" user-order="2"><p> So... I have to investigate how I actually feel about this...</p><p> But I think, on principle, I&#39;m against petty gossip regardless of friendship status or closeness to the people. Just based on what I would consider ethical behavior.</p><p> So ... in fact I wouldn&#39;t do petty gossip behind people&#39;s backs even if they were relative strangers. And so the thing where these people aren&#39;t really my friends or close to me... doesn&#39;t really change... that it seems inadvisable, to me, to do.</p><p> However........ I don&#39;t know if I&#39;d feel angry in the same way. yeah I think i&#39;d just be like &quot;huh that&#39;s kinda shitty behavior&quot;</p><p> But I do think it&#39;s confusing because... a lot of the rat&#39;s... I thought were my friends. Actually. And maybe... they don&#39;t really think that. 😅</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 02:42:42 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 02:42:42 GMT" user-order="2"><p> I would feel good if you, as my friend, gave me feedback. And like, tried to explain things I&#39;ve said or done that give you concern, out of a ... desire to help me? Or something - I am failing to be quite precise.</p><p> I would feel pretty good if I received a &quot;i think you actually don&#39;t belong here&quot; - if there was a clear conclusion like this. I&#39;d feel somewhat relieved.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:45:17 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:45:17 GMT" user-order="1"><p> That makes sense.</p><p> I could switch to that, but I want to first bring up that it wasn&#39;t my motive for commenting on the Facebook post. One of the activities I regularly engage in is &quot;public discussion of what the norms are&quot;, which I think helps people both not have to make worst-case assumptions about the norms, and also prevent poor norms from coming to be. While I think there was something important you were trying to defend, I disagreed with the norm that it read to me that you were explicitly proposing, which is that &quot;gossip about people having seriously lost touch with reality&quot; should be punished.</p><p> I also would like you to not join a cult or go crazy, that would be very sad :(</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 02:48:33 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 02:48:33 GMT" user-order="2"><p> So specifically about gossip norms.</p><p> To me, the intent matters. The way it is done matters.</p><p> I think this includes professional contexts where people don&#39;t know the other people very well. Or don&#39;t have particular loyalties to the people, as friends. And maybe that&#39;s more the relevant context here.</p><p> I am not interested in the punishment part of this.</p><p> I am interested in &#39;calling out&#39; behavior that is inadvisable, unethical, or unprofessional. And I guess this would be... a norm reinforcement... but I don&#39;t see it as all that punishing to do.</p><p> Gossip that is coming from a place of pettiness, or desire to boost oneself up or lower someone else. Gossip that is coming from envy, spite, jealousy, malice, ill-will, etc. Gossip that seeks to divide people / cause disharmony / cause conflict between friends. Gossip that dehumanizes.</p><p> [Edit: I want to elaborate that &#39;dehumanizes&#39; here means something like &quot;causes people to mistreat that person, including in their own minds.&quot;]</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:50:24 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:50:24 GMT" user-order="1"><p> When you write this I really don&#39;t know what you mean that isn&#39;t incredibly overreaching and damaging:</p><blockquote><p> But I think, on principle, I&#39;m against petty gossip regardless of friendship status or closeness to the people. Just based on what I would consider ethical behavior.</p></blockquote><p> Lots of private information gets passed around in small circles because it&#39;s sensitive or delicate or unfair to share in wider circles. This includes positive and negative information.</p><p> Yeah, there&#39;s private info you can spread about someone just to embarrass them or to feel superior for them or just so you can get points because you have private and personal info about someone. There&#39;s lots of bad motives for sharing info. But also sharing private strongly negative info seems really important to me too, and I don&#39;t want a rule of &quot;no saying bad things behind people&#39;s backs&quot;.</p><p> It seems good to point out bad patterns and low motives. I&#39;d be into trying to specify what&#39;s going wrong with gossip in this situation, as my current best guess is that you have some legitimate grievances &lt;hopeful-yet-also-sad-emoji>;</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 02:51:15 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 02:51:15 GMT" user-order="2"><blockquote><p> Lots of private information gets passed around in small circles because it&#39;s sensitive or delicate or unfair to share in wider circles. This includes positive and negative information.</p></blockquote><p> I mean this doesn&#39;t immediately read to me as &#39;petty&#39;.</p><p> Petty would be more like &quot;oh my god did you hear so-and-so did such-and-such??&quot; Like you can kind of tell the vibe isn&#39;t... the same as... &quot;hey, i hear you&#39;re about to engage with Bob in such-and-such. it seems relevant to tell you about this time Bob did this bad thing that would relevantly impact your decision.&quot;</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:52:19 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:52:19 GMT" user-order="1"><p> For instance, today I asked Alice whether Bob made her uncomfortable if I invited him to an event. She said yes, and told me a story of their interactions, and showed me some texts, and I update negatively on Bob&#39;s self-awareness and ability to handle conflict (not that he was a malefactor, just unaware and unskilled), and chose not to invite him to an event (that he was av marginal invitee for, and Bob and I are barely acquaintances). I think this was really good info sharing and I am glad that Alice trusted me to share this info.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 02:52:26 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 02:52:26 GMT" user-order="2"><p> I don&#39;t take any issue with the above example about Alice and Bob.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:52:41 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:52:41 GMT" user-order="1"><p> Sorry, I feel like I am being a bit needlessly defensive...</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 02:53:12 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 02:53:12 GMT" user-order="2"><p> I mean, gossip is legitimately a very nuanced situation. :/ It&#39;s really case by case.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:54:38 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:54:38 GMT" user-order="1"><p> To restate my paraphrase: it sounds like the thing that seemed pretty unvirtuous is</p><blockquote><p> People presenting as friends, yet saying a lot of very negative and ousting-like things behind your back.</p></blockquote><p> Can I get a 1-to-10 rating on how well that captures what you feel like has been happening?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 02:55:16 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 02:55:16 GMT" user-order="2"><p> Somewhere between a 3 and a 6</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 02:56:10 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 02:56:10 GMT" user-order="1"><p> Okay. Um, maybe do you wanna type more about what it seems like to you? :)</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 03:00:58 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 03:00:58 GMT" user-order="2"><p> I will try to delineate the thing.</p><ul><li> Negative or careless or petty gossip about me, without care for me as a person. They were just talking because they could, and it was maybe fun for them or a diversion. To speculate about my sanity. (I admit it is fun to speculate and psychoanalyze about people. So I get that. I just also think it&#39;s inadvisable.)</li><li> Being so-called truth-seekers, but not going to the source of truth directly. Engaging in, what seems to me, to be somewhat cowardly behavior. Or at least avoidant. It&#39;s &#39;too convenient&#39;. They avoid feeling uncomfortable, get to amuse themselves by talking about someone negatively, and don&#39;t receive any of the impact of their actions.</li><li> Talking about me negatively, in a way that they would not do so when I am in the room. This feels deceptive. Then, not telling me directly about it, this is further unfriendly. Also reads to me as immature.</li></ul><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 03:02:06 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 03:02:06 GMT" user-order="2"><p> Note: This is largely speculation about how people are engaging in this type of conversation. It&#39;s not like I was there.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:02:59 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:02:59 GMT" user-order="1"><p> This is helpful. I think the 3rd bullet is leaving me with a clearer impression of something that I think is clearly bad behavior.</p><p> (Yep, I am not reading you to say &quot;I definitely know that this happened&quot; but it seems like you&#39;ve got enough evidence to think it probably did or something similar to it might&#39;ve.)</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:04:14 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:04:14 GMT" user-order="1"><p> I think people saying one thing to your face and a different thing behind your back, is not an honorable way of interacting with people you respect or are friends/allies with. Especially if the thing behind your back is very damaging to you or very negative about you.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 03:06:33 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 03:06:33 GMT" user-order="2"><p> Well I&#39;ve been IN convos like this in the past. I&#39;ll just confess that I&#39;ve talked like this about ... I feel like most ppl who have worked at CFAR? But I think this kind of convo would often come up about Alan in particular. And I&#39;ve talked about Bob in ways I would now regret. Probably also Charlie. But I think Alan is the central example here. Because he &#39;went the way of religion&#39; so to speak, and everyone was confused about it and couldn&#39;t help but speculate and speak in patronizing ways about it.</p><p> [Edit: Some names have been anonymized here]</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 03:08:45 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 03:08:45 GMT" user-order="2"><p> While there were attempts to talk directly to Alan about the religion thing, that didn&#39;t resolve in a way that was satisfying. And then from then on, ppl would keep talking about Alan in ....</p><p> Pretty much the same way I imagine old Christian ladies talking about someone gay. Like they got lost or something. But with a tone of ... clucking. Tutting. Disappointed, but distancing. &quot;what a shame&quot;</p><p> And something about that reads to me as petty, unnecessary, and like... speech that ought to be avoided.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:09:20 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:09:20 GMT" user-order="1"><p> I also feel like people were not forthright enough with Alan about that.</p><p> Well, in retrospect I think things were kind of confusing and what norms would be enforced was pretty confusing. I think it would have been good for a bunch of people to say <i>&quot;We&#39;re pretty convinced that theism is false and there&#39;s a civilizational-level amount of motivated cognition looking for arguments for it and we need around here to have a line in the sand that says we&#39;re not accepting that conclusion here&quot;.</i> However, that wasn&#39;t the case! Anna Salamon continued to hire him for events afterwards. So I think those people weren&#39;t in a situation to enforce the boundary.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 03:10:01 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 03:10:01 GMT" user-order="2"><p> Yeah... it&#39;s really not cut-and-dry. I obviously don&#39;t think the EA/rat scene should oust religious people.哈哈</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor">Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:10:57 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:10:57 GMT" user-order="1"><p> I think a bunch of people did lose a lot of respect for him (me included) and it seems likely to me that we weren&#39;t up front about this and as such did not act very honorably toward him.</p><p> Ah, I do want to note that I think enough people had written their opinions on the internet and discussed atheism a bunch that I think it was surely quite clear that a lot of people would lose a lot of respect for Alan due to his believing in a god.</p><p> (I am unresolved on whether people acted honorably.)</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 03:23:39 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 03:23:39 GMT" user-order="2"><p> Well one thing I&#39;m noticing is that...</p><p> Ben gravitates towards norms that seem somewhat legible or able to be reinforced b/c of their general legibility. I think this is actually pretty valuable and good for norms.</p><p> However... the way I judge people&#39;s behavior... has a lot to do with the vibe or way that they go about it, and their motivation or intent behind their behavior—which is generally not legible. Like not permissible evidence in a court of law, so to speak. (Although they DO try to discuss and ascertain this in courts of law... actually... and maybe we just need to get real good at this?)</p><p> But anyway ... I do use motive and intent as a measure because of certain perceptual skills I have. I believe I am unusually good at discerning people&#39;s motives.</p><p> And maybe no one should ask me to write their norms for them.</p><p> And maybe I&#39;m not even in this convo to discuss norms. Or what should be enforced. Or reinforced. Maybe I&#39;m not even at that level here.</p><p> I think I&#39;m like... more like... that Facebook post... was me, as a friend, calling for some kind of intervention or calling out some stuff that I&#39;m personally upset about. And calling people to step into a higher integrity. Which I believe is what friends do!</p><p> And I believe the rationalists are my friends.</p><p> And maybe they don&#39;t.</p><p> And I should maybe figure this out.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:23:50 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:23:50 GMT" user-order="1"><p> Some things that feel alive to me:</p><ul><li> I think gossip is good and want to defend gossip</li><li> I think acting dishonorably is bad and I want to know how to characterize dishonorable gossiping</li><li> I like chatting with Ren in a pretty general way</li><li> I wish I could remove the occasional whitespace/newlines at the end of some of Ren&#39;s responses [edit: this has now been solved]</li><li> I feel like the lack of &quot;caring about your friend&quot; point was really worrying to me because I thought it might be true and so I wanted to talk around that some more</li></ul><p> Also here&#39;s a paragraph I wrote into my notes app because it didn&#39;t seem like it had a natural place to fit into the dialogue above:</p><blockquote><p> I guess it seems to me like we&#39;re engaged in the great rationalist project of “legibilize what the local norms should be and then we will all follow the output of this process” which is notably quite different from “try to directly be kind to one another”, though it is something that can be very powerful and people you don&#39;t currently know well can help you out a great deal with by just writing comments :)</p></blockquote><p> This matches up with something you&#39;re writing in your box.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 03:24:19 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 03:24:19 GMT" user-order="2"><p> FYI think gossip can be quite good, and I do advocate for the wholesome version of gossip. I engage in it myself.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:27:09 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:27:09 GMT" user-order="1"><p> For the record I&#39;m coming from a place where people have had lots of power and I&#39;ve been constantly interacting with people who are practicing and demanding norms of not gossiping about stuff you&#39;ve heard and so my defensiveness is high on this norm.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:33:29 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:33:29 GMT" user-order="1"><p> I think also: Insofar as you are unhappy with my behavior toward you, I feel honor-bound to step forward and tell you what I did and defend it / apologize!</p><p> [Meta: Ren here said in a side-channel that she&#39;d be interested to know what I said.]</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:36:56 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:36:56 GMT" user-order="1"><p> I mentioned your name to someone who was visiting Lighthaven. They asked about you and how you were doing and I recall saying something like &quot;Oh, she&#39;s doing well. I mean, I don&#39;t see her that often so I&#39;m not confident, but I think she&#39;s doing well.&quot; Then later on I noticed that I think this person was worried that you had changed for the worse for being part of MAPLE, so I followed up via text.</p><p> I feel a bit embarrassed typing it in verbatim. I take this as a sign I should probably do so. Here is what I wrote:</p><blockquote><p> the other day i said [ren] seemed to be doing well to me</p><p> to clarify, i am not sure she has not gone crazy</p><p> she might&#39;ve, i&#39;m not close enough to be confident</p><p> i&#39;d give it 25%</p><p> i mostly meant she seemed more chill</p><p> like some anxiety / fakeness had fallen off of her</p></blockquote><p> That&#39;s what I sent.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:38:05 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:38:05 GMT" user-order="1"><p> I think that this is not like an incredible summary of my impression of you and if I thought for half an hour I would say more substantive things, so I am concerned that it will feel a bit superficial / thoughtless.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:39:00 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:39:00 GMT" user-order="1"><p> I guess I&#39;m interested in your reaction, including whether you feel hurt by it or otherwise.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 03:39:39 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 03:39:39 GMT" user-order="2"><p> OK well while Ben is typing... I&#39;m just gonna, for fun, type the Buddhist norms around speech.</p><p> Wait, before that, it&#39;s important not to like... assume these are held rigidly, in a deontological way. They are flexible, situation dependent, and more like &#39;aspirations&#39; than rules.</p><p> They advise:</p><ul><li> Avoid false speech.</li><li> Avoid speech that is malicious (designed or intended to cause harm)</li><li> Avoid speech that divides people (eg causes fights to break out among friends or people who were generally harmonious and getting along)</li><li> Avoid speech that is harsh</li></ul><p> I think there&#39;s a lot of nuance here, esp around the &#39;harsh&#39; one. But I get a lot out of considering these.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 03:42:28 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 03:42:28 GMT" user-order="2"><p> Okay, I&#39;ve read what you wrote. In general, I have no substantial negative reaction to reading the description above. Although I&#39;m a bit sad about 25%.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 03:42:49 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 03:42:49 GMT" user-order="2"><p> But also, doesn&#39;t seem terribly unreasonable or unkind to me. ！</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 03:44:53 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 03:44:53 GMT" user-order="2"><p> I wonder if I want to know more about what people mean when they say &quot;gone crazy.&quot;</p><p> My current sense is that people using this phrase have almost no real model of what they mean. Like it&#39;s got a black box feeling to it.</p><p> Cuz they clearly aren&#39;t talking about me having a psychic break, being manic, or something.</p><p> It&#39;s more like...</p><p> something something cult brain or brainwashed or something seemingly more sinister and hard to put a finger on. But it feels kinda creepy or like weird or off. In a way that&#39;s hard to point at.</p><p> And this makes me ..... want to frown at it hard.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:47:00 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:47:00 GMT" user-order="1"><p> Okay! I am glad you don&#39;t think my texts were dishonorable.</p><p> Hmm... I have been thinking a bit about what &quot;crazy&quot; should refer to, I can give my current guess, with the caveat that it is probably wrong.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:53:23 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:53:23 GMT" user-order="1"><p> So, I think one case I will include is medically insane, like they&#39;re seeing ghosts or are paranoid and think the CIA is following them or have multiple personalities in their head, and broadly aren&#39;t in touch with reality, and the concern is they might hurt themselves or someone else.</p><p> My stab at characterizing this in a way that might generalize is &quot;has robustly false beliefs and is not epistemically open to changing their mind, and because of this they are unable to work with / living with other people&quot;.</p><p> There&#39;s also delusional people who believe that they are Napoleon or something. I think this is the same thing.</p><p> I think that religious people are sometimes like this. &quot;Yes, I&#39;d love to open a restaurant with you, but Christ is returning on Tuesday and I need to slaughter the infidels before he returns.&quot; I am impugning this person as both likely to hurt people and also probably not open to evidence falsifying their beliefs.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 03:53:53 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 03:53:53 GMT" user-order="2"><blockquote><p> &quot;Yes, I&#39;d love to open a restaurant with you, but Christ is returning on Tuesday and I need to slaughter the infidels before he returns.&quot;</p></blockquote><p> Yeah, I read this as a person who is in fact experiencing a psychic break. And I would say their specific delusion has religious themes but I would not describe this person as a religious person.</p><p> This would be similar to me saying: &quot;I think that rationalists are sometimes like this.&quot; And pointing at [redacted] or similar. :P But anyway. Carry on.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:54:53 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:54:53 GMT" user-order="1"><p> I think there are weaker cases of confidently believing something false and not being epistemically open to counter-evidence, in a way that is very damaging.</p><p> I think many Christian people also had confident beliefs about what their God wanted and would punish people in accordance with it (eg physically assault their children) and would say that their belief is based on their personal experience of the Holy Spirit, in a way where I suspect I would not be able to present them with evidence that would change their mind.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:56:11 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:56:11 GMT" user-order="1"><p> My sense is that another time people describe someone as &quot;acting crazy&quot; is when someone is high on drugs and acting erratically and might be violent. They&#39;re not properly in contact with reality and will react to aggressions that aren&#39;t there and do things that don&#39;t make sense.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 03:58:16 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 03:58:16 GMT" user-order="2"><p> I wish I knew a Christian similar enough to your example to really consider it.</p><p> Hummmmmm.</p><p> I maybe don&#39;t spend any time trying to change a Christian&#39;s mind. This activity might be illuminating.</p><p> But ... I dunno. My views here are nuanced.</p><p> A phrase that I&#39;ve heard &quot;I try not to kick anyone&#39;s knees out from under them.&quot;</p><p> And I like this as a general principle. Esp if they&#39;re not committing violence or harm.</p><p> And most religious people aren&#39;t really, as far as I can tell.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:58:28 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:58:28 GMT" user-order="1"><p> I think there&#39;s a related thing of being socially unpredictable that scares people and that people like to call crazy. I remember talking to [redacted] once during a circling session, and having a sense that the person appeared normal but was in fact not at all reading the social cues correctly, and I started to feel scared and like the person would maybe read something as a strong betrayal and act out.</p><p> [Added: I think that there&#39;s an element of &quot;this person is not going to play a consistent social role in the scene&quot; that people often call this &#39;crazy&#39;. I think rationalists sometimes <i>seem</i> crazy because they&#39;re going to operate in line with what&#39;s true, which is often very different from what the scene demands. What I&#39;m saying is that being crazy and seeming crazy are very similar, and sometimes it&#39;s because you&#39;ve lost touch with reality but other times it&#39;s because you&#39;re more in-touch with reality.]</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 03:59:21 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 03:59:21 GMT" user-order="1"><p> I am open to the story that the person who believes that they are Napoleon or Christ can be accepted into normal society and live a good life. I am here trying to say that they are still delusional even if that works.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 03:59:29 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 03:59:29 GMT" user-order="2"><p> OK but the real question is: When you were like, I put 25% on Ren maybe being crazy. What does that crazy actually refer to?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 04:00:19 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 04:00:19 GMT" user-order="1"><p> Oh right. I forgot about that context. I admit my examples are a bit more extreme / alarming. I feel a bit nervous about trying to talk about this politely.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 04:03:43 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 04:03:43 GMT" user-order="2"><p> FTR, I would characterize a lot of rationalists as ... &#39;religiously so&#39; or &#39;fundamentalist&#39; in the way they hold their views. As in, ... attached to their specific stories of reality and not open to updating. So in other words, they believe what they believe based on a kind of faith, and not the good kind of faith. And I say this just b/c it sort of mirrors what you said above about religious people or Christians.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 04:09:32 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 04:09:32 GMT" user-order="1"><p> It&#39;s hard for me to share all of the vibes I&#39;ve picked up, and I am a bit defensive about them. I am not sure exactly what I mean, but I&#39;ll give it a shot at a explicit meaning.</p><ul><li> Will Renshin confidently believe something that a lot of her actions rest on that seems to me strongly false and not be open to changing her mind, and as a result either waste a ton of time/effort or possibly do something harmful?</li></ul><p> I think my concerns here are something like &quot;Frame control by a central figure in her local social environment who has a lot of power, such that she does not really question some central tenets of belief&quot;.</p><p> (I don&#39;t mean to necessarily imply that this doesn&#39;t happen to any other people and isn&#39;t happening to me.)</p><p> Examining the case of Nonlinear gave me a bunch more taste for how much of an attractor state there is here. The two women I talked to at length were in a situation where:</p><p> The CEO of the company</p><ul><li> Had ~all of the financial power (millions in his own bank account, paid out ~very little to any employees)</li><li> Believed himself to be one of the greatest people alive, such that his brother (also at the company) said that if the CEO ran for President, he had a 10% chance of winning</li><li> Generally got to win arguments by saying he had thought about the topic more than ~anyone else on Earth</li><li> They travelled in a small unit with its own social bubble and v few people coming in and out that didn&#39;t respect the leader</li><li> (I could write more)</li></ul><p> And at the end they&#39;d taken a bunch of actions that they... couldn&#39;t have imagined taking otherwise. Like, they were just like &quot;this makes sense, the boss said it&#39;s fine to drive illegally in a foreign country without a license for 2 months&quot;.</p><p> Returning to the topic at hand, I have seen a bunch of little red flags around MAPLE (which I could go into, eg my sense is that people are often suffering from sleep deprivation there, I also recall reading some tale of the leader endorsing some atrocity like it might be better for humanity to go extinct than continue as it is), so I am somewhat concerned about your local social environment.</p><p> So that&#39;s a key source of my probability estimate.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 04:11:12 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 04:11:12 GMT" user-order="1"><p> To be clear, to me you seem stronger and to have more faith in yourself and to care about right action more, and you seem like a more powerful force in the world for it.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 04:11:51 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 04:11:51 GMT" user-order="2"><p> Hmmm.</p><p> Interesting.</p><p> I take issue with the word &#39;confidently&#39;.</p><p> I would agree there was an issue if the thing were more like...</p><p> In a way that was attached. Esp in a personal, egoic way. Like If I needed to defend myself and my beliefs. Or I couldn&#39;t face alternative realities that went against my sense of things. Like I was flinching against evidence. Or I was personally defending something or afraid to consider the possibility of my view being false.</p><p> But I agree that I hold certain views <i>confidently</i> but I would say that&#39;s good, as long as I&#39;m not attached to my views. I&#39;m confident because ... I&#39;ve personally examined a lot of evidence and investigated it for myself. And verified it etc. But I&#39;m also not afraid of considering alternatives. It just ... the evidence is actually overwhelming in some cases.</p><p> So I&#39;ve developed a lot of inner confidence. But also, I hold all my views lightly because there&#39;s no frame or set of concepts that quite captures reality. And so... in some way... I don&#39;t hold that tightly to any particular view or frame? But somehow I still am able to act with confidence? I dunno.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 04:18:37 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 04:18:37 GMT" user-order="1"><p> Relatedly, I think I am slightly concerned that you will start saying a bunch of clearly false things at some point. I don&#39;t know that it&#39;s a super justified fear but I don&#39;t think I have seen sufficient evidence to be totally confident it won&#39;t happen.</p><p> Like, to give an overly concrete example that is probably rude (and not intended to be very accurate to be clear), if at some point you start saying <i>&quot;Well I&#39;ve realized that beauty is truth and the one way and we all need to follow that path and I&#39;m not going to change my mind about this Ben and also it&#39;s affecting all of my behavior and I know that it seems like I&#39;m doing things that are wrong but one day you&#39;ll understand why actually this is good&quot;</i> then I&#39;ll be like <i>&quot;Oh no, Ren&#39;s gone crazy&quot;</i> . Probably you won&#39;t! I&#39;m pattern matching a bit to what people sometimes say who&#39;ve gone to religious retreats for ages and changed their lives.</p><p> Like in the last few years I saw a person turn religious (which was worrying to me) and then also on a different issue say <i>&quot;I&#39;m never going to stop &lt;holding my position>;&quot;</i> and that person had previously been rationalist-adjacent for a while. [Added: And now I am going to hold far stronger personal boundaries around that person and avoid them having much power over me and so on.]</p><p> Anyway, this is meant as a pointer to my fears about religious people, not as a very personal analysis.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Fri, 13 Oct 2023 04:20:41 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Fri, 13 Oct 2023 04:20:41 GMT" user-order="1"><p> I want to reiterate that I don&#39;t believe this is the world I&#39;m living in and I&#39;m writing this because I think it&#39;s good to share concerns about possible worlds to avoid. I&#39;m not at all saying &quot;Ren is totally like this&quot; but instead I more wrote &quot;What am I afraid of&quot;. I like you and like you being in my life :)</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Fri, 13 Oct 2023 04:23:19 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Fri, 13 Oct 2023 04:23:19 GMT" user-order="2"><p> OK! Well reading your sense was helpful.</p><p> I like knowing that.</p><p> I am fairly confident that personally, I, at least, am not going thru the thing you described above (using Nonlinear as an example).</p><p> I ... if anything ... am much more able to stand up to my teacher than before.</p><p> [Edit: I removed some text here going into some specifics about the above line. I didn&#39;t feel like publishing that stuff but am open to private dialogue about it, if anyone is curious.]</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal</section></section><p> <strong>Friday, October 13th</strong> </p><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sat, 14 Oct 2023 03:26:12 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sat, 14 Oct 2023 03:26:12 GMT" user-order="1"><p> Checking in, I&#39;d like to ask if we can publish this dialogue? I liked the conversation. I&#39;ve edited a few of my sentences for grammar/wording, deanonymized some people, added an intro for context, given it a title, and made two larger additions that I&#39;ve flagged that look like: [Added: &lt;new stuff>;].</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Sat, 14 Oct 2023 03:53:09 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Sat, 14 Oct 2023 03:53:09 GMT" user-order="2"><p> I feel like I never really got to explain my views on gossip in a clear way. I feel dissatisfied about it. Might try to add it in.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sat, 14 Oct 2023 03:57:26 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sat, 14 Oct 2023 03:57:26 GMT" user-order="1"><p> Oh interesting. I did get a sense of what you thought was bad behavior from some of your bullets &#39;delineating&#39; it, but sounds like you don&#39;t feel you said it very crisply.</p><p> Some options:</p><ol><li> Spend some time now trying to add it.</li><li> Publish it, then tonight/tomorrow write a comment with more thoughts.</li><li> Publish it, then if we want to we can come back here and continue the dialogue another day.</li><li> F*ck it ship it, even if it could be better.</li></ol><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sat, 14 Oct 2023 03:58:41 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sat, 14 Oct 2023 03:58:41 GMT" user-order="1"><p> (I personally am excited about sharing real conversation dialogues so I am making some request to publish even though we could both add more.)</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Sat, 14 Oct 2023 03:58:48 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Sat, 14 Oct 2023 03:58:48 GMT" user-order="2"><p> Yeah I don&#39;t need to wait on publishing.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sat, 14 Oct 2023 03:59:09 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sat, 14 Oct 2023 03:59:09 GMT" user-order="1"><p> Okie dokie :)</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="EQNTWXLKMeWMp2FQS-Sat, 14 Oct 2023 03:59:57 GMT" user-id="EQNTWXLKMeWMp2FQS" display-name="Ben Pace" submitted-date="Sat, 14 Oct 2023 03:59:57 GMT" user-order="1"><p> Shall I hit publish?</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Ben Pace </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Sat, 14 Oct 2023 04:00:29 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Sat, 14 Oct 2023 04:00:29 GMT" user-order="2"><p> Aye.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Sat, 14 Oct 2023 04:39:24 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Sat, 14 Oct 2023 04:39:24 GMT" user-order="2"><h1> Addendum:</h1><p> <strong>Ren&#39;s views on Relationship</strong></p><p> The relationship or &#39;line&#39; drawn between individuals is &quot;real&quot; in her ontology, and it can be damaged, repaired, or honored. There&#39;s always something there, even between people who&#39;ve never met before—like on the other side of the world or something. There&#39;s no such thing as a total disconnection.</p><p> However, one can choose to pretend or act like a relationship is nonexistent. This is a kind of dishonoring of the truth, which is that something exists there, but we can refuse to acknowledge it or take responsibility for it or treat it as real.</p><p> Much of Ren&#39;s examination of this phenomenon comes from years of Circling practice and also her many years of living in community. However, this view is corroborated by ancient traditions, including indigenous / Native ones, Buddhist ones, etc.</p><p> An invocation we regularly use at MAPLE is from the Lakota tradition: <a href="https://www.wikiwand.com/en/Mitakuye_Oyasin">Mitakuye Oyasin</a> .</p><p> These ancient traditions and practices teach, in their culture, to honor all life because we&#39;re all actually interconnected—everything impacts everything else. This feels trivially true, even from a purely materialistic standpoint.</p><p> In Buddhism, this is often referred to as interdependence.</p><p> In Circling, this principle is referred to as &quot;Commitment to Connection&quot; in the Circling Europe school—where I first learned to start taking this idea seriously.</p><p> When we act in ways that dishonor connection or relationship, it can cause &quot;damage.&quot; This &quot;damage&quot; in my view is due to the delusional aspect of it. If we act out of a deluded or wrong view of reality, we cause &quot;damage&quot;—but I see &quot;damage&quot; as &quot;lying to oneself, to others, or to the world.&quot; When we act out of accord with truth, this is itself &quot;damage.&quot;</p><p> So when I heard that people were gossiping about me behind my back in a way that seemed uncaring about me, this created a felt &#39;rift&#39; between myself and these unknown gossipers. I became angry, more distrustful, felt hurt, etc. This is a kind of &quot;damage&quot; in my relational world. In fact, in OUR relational world. It hurt the relationships itself, more than the individuals in the relationship.</p><p> The impacts on me in a physical or material way are a second-order concern, not the primary concern.</p><p> The move toward division, disconnection, and disharmony between people I thought I had some trust or bond with... this is what I see as &quot;damaging&quot; and thus &quot;inadvisable.&quot; And why I advocate for a norm against speech that creates a wound or fracture, in a relational field.</p><p> The material impacts are real, but they all come downstream from living out of accord with a certain reality—that we are all connected, and all our relationships matter. To harm any of them ultimately harms ourselves and causes us to be deluded. Disconnected FROM reality, rather than connected with reality.</p><p> If I gossip about someone (in an unwholesome way), and they never find out, this still creates the rift, the disconnection, and still damages something real. (This can be observed, just watch how I behave around or to that person after I make secretly harmful comments about them. Or watch how I start treating relationships in general. See if I experience more shame, guilt, need to conceal things, lie, pretend, etc. My behavior starts lining up with the reality I have personally created, through my speech act. This is &quot;damage&quot;.)</p><p> Of course, gossip is valid in all the ways discussed above. But there are ways to do gossip that doesn&#39;t cause these fractures or rifts and maintains the reality of the connection, even if the gossip is &#39;negative&#39;. Friends CAN talk about their friends behind their backs. Even saying negative, unflattering things. This isn&#39;t off limit! <strong>But are we doing it in a way that honors the relationship, or are we creating a sense that the relationship isn&#39;t important or isn&#39;t real?</strong></p><p> OK I feel like I have outlined the most major thing missing, from my philosophy, from the above.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal </section></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="JQgRAezp6fX48ZC6C-Sat, 14 Oct 2023 05:18:07 GMT" user-id="JQgRAezp6fX48ZC6C" display-name="Unreal" submitted-date="Sat, 14 Oct 2023 05:18:07 GMT" user-order="2"><p> Gossiping in a way that causes people to believe I am &#39;insane&#39; is damaging in particular because it also discourages people from engaging with me... and instead encourages people to start actively avoiding and shunning me. This removes even the option of a kind of repair, reconciliation, or investigation caused by this sort of gossip.</p><p> If it were true that I am insane—like y&#39;know, esp in a potentially harmful way—I would advocate for people to warn other people about me.</p><p> There are such people in the world, who in general I would advise you to avoid (unless you are willing to take certain risks). And I would have no problem saying so.</p><p> But such people are, like, more in the category of acting in ways that are really quite harmful and are kind of beyond help or correction, for whatever reason. (As in, many people have made the attempt and failed.) I have people that seem to be in this category, and it is very sad. I still make attempts to reach out to them though, from a distance.</p><p> But currently I do not believe most people should bother making active attempts to avoid me (like, more than the default). The evidence is... as far as I can tell... way more in the other direction—that engaging with me is beneficial for the people I engage with. And people often come to me for all kinds of reasons. And report benefit. And this is more true now than it was a few years ago.</p><p> This might be harder to believe(?), but people come to me for my clarity, my ability to understand things and communicate them well, and my devotion to truth-seeking. I help bring other people more clarity in their lives, in their sense-making, and try to deepen their connection to the world, reality, themselves, etc.</p><p> So to cause people to instead be tempted to avoid me, to shun me, or see me as crazy, seems harmful and disingenuous from where I am standing, given the info I have (versus the info that speculators have, which is almost nothing).</p><p> I advise against casual, careless speculation on my insanity, given basically no direct contact with me. I wouldn&#39;t do it others—for fun, for profit, for personal gain, for egoic validation, or due to my own insecurities or due to entitlement. If I do it to you, I owe you an apology.</p><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"> Unreal</section></section><br/><br/> <a href="https://www.lesswrong.com/posts/DQjS59yetM64njSBS/dishonorable-gossip-and-going-crazy#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/DQjS59yetM64njSBS/dishonorable-gossip-and-going-crazy<guid ispermalink="false"> DQjS59yetM64njSBS</guid><dc:creator><![CDATA[Ben Pace]]></dc:creator><pubDate> Sat, 14 Oct 2023 04:00:35 GMT</pubDate> </item><item><title><![CDATA[Disentangling Our Terminal and Instrumental Values]]></title><description><![CDATA[Published on October 14, 2023 3:35 AM GMT<br/><br/><p> Disagreements related to what we value seem to explain maybe 10% of the disagreements over AI safety. This post will try to explain how I think about which values I care about perpetuating to the distant future.</p><p> Robin Hanson helped to clarify the choices in <a href="https://www.overcomingbias.com/p/which-of-your-origins-are-you">Which Of Your Origins Are You?</a> :</p><blockquote><p> The key hard question here is this: what aspects of the causal influences that lead to you do you now embrace, and which do you instead reject as &quot;random&quot; errors that you want to cut out? Consider two extremes.</p><p> At one extreme, one could endorse absolutely every random element that contributed to any prior choice or intuition.</p><p> ...</p><p> At the other extreme, you might see yourself as primarily the result of natural selection, both of genes and of memes, and see your core non-random value as that of doing the best you can to continue to &quot;win&quot; at that game. ... In this view, everything about you that won&#39;t help your descendants be selected in the long run is a random error that you want to detect and reject.</p></blockquote><p> In other words, the more unique criteria we have about what we want to preserve into the distant future, the less we should expect to succeed.</p><h3> Do Humans Have Many Terminal Values?</h3><p> <a href="http://elephantinthebrain.com/">The Elephant in the Brain</a> shows that we portray ourselves as having a wide variety of noble values, a large fraction of which are better explained by simple selfishness.</p><p> Self-oriented goals related to wealth, prestige, dominance, safety, and health can be largely explained as results of us valuing our own empowerment. The post <a href="https://www.lesswrong.com/posts/JPHeENwRyXn9YFmXc/empowerment-is-almost-all-we-need">Empowerment is (almost) All We Need</a> expands on this idea.</p><p> <a href="https://www.lesswrong.com/posts/iCfdcxiyr2Kj8m8mT/the-shard-theory-of-human-values">Shard Theory</a> tells us that most human values are context-dependent.</p><p> Those considerations lead me to conclude that most human values are better explained as instrumental values (ie subgoals) rather than as terminal values.</p><p> But before I go overboard in that direction, I need to remind myself that evolution produces messy results that can&#39;t be classified as simply as I&#39;d like. Eg sex. Evolution intended sex to be an instrumental value that helps to spread genes.</p><p> Evolution implemented sex drives in a way that caused humans to often treat sex more as a terminal goal. Is sex a genuinely terminal goal? Or is it a goal that&#39;s contingent on certain hormones and sensory organs? Like most of my values, the answer to this question seems context-dependent. Transhumanist culture seems to guide me toward treating sex as an instrumental value. Whereas if I lived in a lower-tech sex-positive culture, I&#39;d treat sex drives as sufficiently inevitable that I couldn&#39;t distinguish sex from a terminal goal.</p><p> Human values haven&#39;t evolved to cleanly fit into a framework which says that instrumental and terminal values are clean different categories.</p><p> So there is some complexity to human terminal values. But I don&#39;t see how those values differ much from those of simpler animals. I claim that virtually all values that differ from those of other species should be classified as instrumental values.</p><h3> Identity</h3><p> Robin says in <a href="https://quillette.com/2023/08/06/ais-will-be-our-mind-children/">AIs Will Be Our Mind Children</a> :</p><blockquote><p> future human-level AIs are <em>not</em> co-existing competing aliens; they are instead <em>literally</em> our descendants. So if your evolved instincts tell you to fight your descendants due to their strangeness, that is a huge evolutionary <em>mistake</em> .</p></blockquote><p> I&#39;m bothered by the binary language that leads both Robin and the AI doomers to sound as if AIs will be either 100% or 0% our descendants.</p><p> I care how much of my genes (loosely defined so as to include culture) are embodied in our AI successors.</p><p> If I believed Eliezer&#39;s model of how AI will function, I&#39;d be almost as pessimistic as he is about AIs sharing my &quot;genes&quot;. My model of AI is a bit closer to Robin&#39;s model. My best guess is that at least some AIs will be sufficiently human-like that they preserve some of what I value.</p><p> But in addition to that factual disagreement about how much AIs will resemble me, there&#39;s an important value difference about how we should feel about AIs that perpetuate modest fractions of our &quot;genes&quot;.</p><p> Robin is expressing values that roughly correspond to what we should expect from evolved minds. But he sometimes sounds like a more altruistic utilitarian than is consistent with evolutionary values. (He sounds more worried about alien values when talking about the risk that the world will be <a href="https://www.overcomingbias.com/p/the-return-of-communism">dominated by Amish and Orthodox Jews</a> .)</p><p> Eliezer seems to be expressing values that look more like the result of <a href="https://www.lesswrong.com/tag/subgoal-stomp">goal displacement (subgoal stomp)</a> , in which preservation of identity / values (presumably originating as a subgoal of empowerment or selective fitness) becomes a terminal goal.</p><p> That doesn&#39;t mean Eliezer&#39;s values are wrong. His values are harder to satisfy than are Robin&#39;s. So to the extent my preferences about descendants are subgoals that are amenable to change, I&#39;ll prefer to nudge them a bit in Robin&#39;s direction. In particular, I&#39;ll try to be a bit more accepting of uploads that imperfectly preserve my identity.</p><p> I&#39;m not too clear about the extent to which my values about descendants are subgoals or terminal goals. But since I see a pervasive human bias to overstate the extent to which our goals are terminal goals, I&#39;m going to try to think about my values a bit more like Robin thinks, and a bit less like Eliezer thinks.</p><h3> Uncertainty</h3><p> Here are two analogies for why I&#39;m concerned about aligning AI:</p><ul><li> Mothers are quite selective about whose genes fertilize their eggs.</li><li> Fathers are often concerned about the paternity of the children that they&#39;re supporting.</li></ul><p> Robin sometimes sounds as if he&#39;s rejecting these instincts.</p><p> Current AI efforts are on track to produce a somewhat arbitrary mix of whatever values are easiest to implement, and the values of the most influential AI developers.</p><p> To the extent AI values are chosen by ease of implementation, I reject the notion that those AIs are our descendants.</p><p> To the extent AI values replicate the culture of influential people, I feel a more normal mix of approval that people like me are reproducing, and concern about whether those descendants embody too much of other people&#39;s values and not enough of mine.</p><p> I&#39;d prefer an <a href="http://ageofem.com">Age of Em</a> to whatever it is we&#39;re currently on track for. Alas, I have no clear plan for a future in which ems are more important than are more artificial AIs.</p><br/><br/> <a href="https://www.lesswrong.com/posts/HzxNfj3LJDANdoJaw/disentangling-our-terminal-and-instrumental-values#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/HzxNfj3LJDANdoJaw/disentangling-our-terminal-and-instrumental-values<guid ispermalink="false"> HzxNfj3LJDANdoJaw</guid><dc:creator><![CDATA[PeterMcCluskey]]></dc:creator><pubDate> Sat, 14 Oct 2023 03:35:24 GMT</pubDate></item></channel></rss>