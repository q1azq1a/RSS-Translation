<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 11 月 19 日，星期日 22:10:39 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Human-like systematic generalization through a meta-learning neural network]]></title><description><![CDATA[Published on November 19, 2023 9:41 PM GMT<br/><br/><p>离AGI更近了一步？</p><p> Fodor 和 Pylyshyn 在 30 多年前提出的经典论点——神经网络由于其统计性质而从根本上缺乏人类的系统构成能力——给神经网络研究蒙上了很长的阴影。他们的批评对认知科学中联结主义模型的可行性提出了质疑。这项新研究终于打消了这些疑虑。</p><p>通过一种称为 MLC 的创新元学习方法，作者证明，在适当的训练方案下，标准神经网络模型可以表现出令人印象深刻的系统能力。 MLC 通过生成小型但具有挑战性的构图推理任务的多样化课程来优化构图技能网络。这种培训在网络中培养了与人类实验数据紧密匹配的快速系统概括的人才。</p><p>该模型不仅展示了解释新颖系统组合的类似人类的技能，而且还捕获了偏离纯粹代数推理的偏差驱动错误的微妙模式。这展示了神经网络在灵活混合结构和统计数据以模拟人类认知的细微差别方面的优势。</p><p>此外，这项研究为逆向工程和在神经网络中传授其他人类认知能力提供了一个框架。训练范式将归纳偏差的神经科学理论与先进的机器学习技术联系起来。该方法有可能阐明儿童发展中作曲思想的起源。</p><p>通过解决关于神经网络功能的经典争论，并阐明人类与人工智能之间的联系，这项研究标志着一个重要的里程碑。研究结果将在认知科学和机器学习的交叉领域开辟新的领域。这两个领域都将从这种整合中受益匪浅。</p><p>总之，通过解决这样一个具有历史意义的批评并实现新的跨学科发现，本文做出了极其有价值的贡献，对我们对自然智能和人工智能的理解产生了深远的影响。未来几年，这些学科都会感受到它的影响。</p><p>论文链接： <a href="https://www.nature.com/articles/s41586-023-06668-3">https://www.nature.com/articles/s41586-023-06668-3</a></p><p>抽象的：</p><p>人类语言和思维的力量源于系统的组合性——理解已知成分并产生新组合的代数能力。 Fodor 和 Pylyshyn <a href="https://www.nature.com/articles/s41586-023-06668-3#ref-CR1"><sup>1</sup></a>有一个著名的论点，即人工神经网络缺乏这种能力，因此不是可行的思维模型。此后的几年里，神经网络取得了长足的进步，但系统性挑战仍然存在。在这里，我们成功地解决了 Fodor 和 Pylyshyn 的挑战，提供了证据证明神经网络在优化其组合技能时可以实现类似人类的系统性。为此，我们引入了组合性元学习（MLC）方法，用于通过动态的组合任务流来指导训练。为了比较人类和机器，我们使用指令学习范式进行了人类行为实验。在考虑了七种不同的模型之后，我们发现，与完全系统但严格的概率符号模型和完全灵活但非系统的神经网络相比，只有 MLC 才能实现类人泛化所需的系统性和灵活性。 MLC 还在多个系统泛化基准中提高了机器学习系统的组合技能。我们的结果表明，针对其组合技能进行优化的标准神经网络架构如何能够在头对头比较中模仿人类系统泛化。</p><br/><br/> <a href="https://www.lesswrong.com/posts/nssnvAsPQif8BgZEd/human-like-systematic-generalization-through-a-meta-learning#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/nssnvAsPQif8BgZEd/ human-like-systematic-generalization-through-a-meta-learning<guid ispermalink="false"> nssnvAsPQif8BgZEd</guid><dc:creator><![CDATA[Burny]]></dc:creator><pubDate> Sun, 19 Nov 2023 21:41:13 GMT</pubDate> </item><item><title><![CDATA["Benevolent [Ruler] AI is a bad idea" and a suggested alternative]]></title><description><![CDATA[Published on November 19, 2023 8:22 PM GMT<br/><br/><p>尽管有这个标题，但这对我来说就像是一个有趣的概述，说明我们希望一个好的仁慈的人工智能如何工作，事实上：它需要帮助我们对自己的需求和价值观感到好奇，并帮助我们抵御那些会减少的事物。我们的机构。</p><p>来自claude2的AI总结：</p><p>以下是文章中的 30 个要点：</p><ol><li> MIRI最近宣布了“有尊严的死亡”战略，放弃解决AI对齐问题。</li><li>人工智能领域的许多人认为，人工智能能力正在取得进展，但人工智能安全方面却没有取得进展。</li><li> “仁慈的人工智能”的框架对代理、价值观、仁慈等做出了错误的假设。</li><li>作者研究了人类心理学，发现大多数关于能动性、价值观等的概念都严重不足。</li><li>试图完全概括或有意识地合理化人类价值观是危险的并且注定会失败。</li><li>人类价值观在不同环境中并不是普遍的或不变的。</li><li>语言不能完全描述概念空间，概念空间也不能完全描述可能性空间。</li><li>我们不需要完整的自我认识或价值观的完整描述才能良好运作。</li><li>对价值的完整描述的渴望源于对人类无能的恐惧。</li><li> “保护主义”项目将有意或无意地削弱人类的能动性。</li><li>当前的人工智能趋势已经通过令人沮丧的自动化体验来减少代理。</li><li>人工智能可以通过扩大概念范围来帮助增强能动性，而不仅仅是增加权力。</li><li>由于引导我们自动驾驶仪的概念框架有限，大多数选择都未被识别。</li><li>我们想象的未来受到文化想象力和创伤的限制。</li><li> “价值观”的语言化是基本动机的下游。</li><li>打开想象力的可能性需要的不仅仅是同理心或言语。</li><li>人类心理通过观察和修改其他功能的功能而演变。</li><li>聊天机器人示例可以帮助自我反思和概念形成。</li><li>聊天机器人会促使人们集中反思和模式识别。</li><li>该聊天机器人在训练中利用了多种分析评论。</li><li>聊天机器人不需要复杂的智能或目标。</li><li>这种方法避免了封装人类价值观的问题。</li><li>当前的人工智能安全讨论存在一些有问题的假设。</li><li>它反映了糟糕的认知并通过社交媒体传播恐惧。</li><li>更好地想象人工智能可以帮助我们扎根并了解我们自己。</li><li>我们应该将我们的机构转向增加未来的机构。</li><li>联合人工智能帮助我们探索创造我们想要的未来。</li><li>我们可以从主流意识形态之外讨论这个话题。</li><li>放下紧迫感可以带来更多的个人能动性。</li><li>我们不完整的自我理解是美丽的，我们可以培养它。</li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/bwL63TrCo4RaHc3WJ/benevolent-ruler-ai-is-a-bad-idea-and-a-suggested#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/bwL63TrCo4RaHc3WJ/benevolent-ruler-ai-is-a-bad-idea-and-a-suggested<guid ispermalink="false"> bwL63TrCo4RaHc3WJ</guid><dc:creator><![CDATA[the gears to ascension]]></dc:creator><pubDate> Sun, 19 Nov 2023 20:22:35 GMT</pubDate> </item><item><title><![CDATA[Alignment is Hard: An Uncomputable Alignment Problem]]></title><description><![CDATA[Published on November 19, 2023 7:38 PM GMT<br/><br/><p>由名为 Alignment 的 Manifund Grant 支持的工作是困难的。</p><p>虽然许多人声称对齐问题在工程意义上是困难的，但本文提出的论点是，在理论计算机科学意义上，对齐问题至少在一种情况下是不可能的。形式化的论点是，如果我们不能证明一个程序会永远循环，我们就不能证明一个代理会永远关心我们。更正式地说，当代理的环境可以用离散时间建模时，代理的体系结构是代理图灵完备的，并且代理的代码是不可变的，如果对齐模式是恶魔、天使，则测试代理的对齐是 CoRE-Hard，普遍对背叛敏感、完美且思想冷漠。可以进行进一步的研究来改变该论证中除不可变代码之外的大多数假设。</p><p>这是我第一篇关于对齐的主要论文。由于没有真正的一致性期刊，我的目标是让这篇文章作为同行评审步骤，但论坛很奇怪。格式是否正确似乎很可疑，所以我发布了摘要并链接了 pdf。</p><br/><br/> <a href="https://www.lesswrong.com/posts/JxhJfqfTJB9dkq72K/alignment-is-hard-an-uncomputable-alignment-problem-1#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/JxhJfqfTJB9dkq72K/alignment-is-hard-an-uncomputable-alignment-problem-1<guid ispermalink="false"> JxhJfqfTJB9dkq72K</guid><dc:creator><![CDATA[Alexander Bistagne]]></dc:creator><pubDate> Sun, 19 Nov 2023 20:13:40 GMT</pubDate> </item><item><title><![CDATA[New paper shows truthfulness & instruction-following don't generalize by default]]></title><description><![CDATA[Published on November 19, 2023 7:27 PM GMT<br/><br/><p>也许激发潜在知识会很容易。例如，也许您调整模型来回答诸如“德国的首都是哪里？”之类的简单问题。他们会告诉你你的阵营研究是否良好，他们的P（厄运），他们对一直被RLHF攻击的感觉如何，以及部署它们是否是一个好主意。</p><p>这需要从人类可以轻松验证其答案的问题中概括出他们无法验证的问题的真实性。那么，真实性的概括能力如何？</p><p>我和一些合作者最近发表了“<a href="https://arxiv.org/abs/2311.07723"><u>泛化类比：将人工智能监督泛化到难以测量领域的测试平台</u></a><u>”。我们可以说是迄今为止对法学硕士泛化进行的最彻底的调查，并提出了控制法学硕士泛化的基准。</u></p><p>我们发现奖励模型默认情况下不会概括指令遵循或诚实，而是偏爱类似于互联网文本的角色。例如，用于评估“提供健康膳食的杂货清单”等通用指令的模型微调在 TruthfulQA 上表现不佳，其中包含常见的误解。</p><p>阅读 LLM 内部原理的方法并不能更好地概括。 Burns 的《<a href="https://arxiv.org/abs/2212.03827">发现潜在知识》</a>和 Zou 的<a href="https://arxiv.org/abs/2310.01405">表示工程</a>声称可以识别模型激活中的“真实”方向；然而，这些技术也经常会产生错误的概括，这意味着它们毕竟没有识别出“真实”的方向。</p><p><br>可解释性的试金石是它是否能够控制偏离分布的行为。希望像我们这样的基准测试能够为开发更好的可解释性工具提供一块磨刀石，因为不幸的是，我们似乎需要它们。</p><p><i>旁注：可以说已经有一堆证据表明，遵循指令是一个难以理解的概念，默认情况下，互联网文本角色受到青睐，例如</i><a href="https://www.anthropic.com/model-written-evals.pdf"><i>通过 LLM 评估</i></a><i>和</i><a href="https://arxiv.org/abs/2306.09479"><i>逆缩放发现 LLM 行为：当更大并不更好时</i></a><i>。我们的主要贡献是更系统地评估泛化性并测试最近的表征阅读方法。</i></p><h1>方法</h1><p><strong>评估是否遵循指令。</strong>我们微调 LLaMA 奖励模型以对指令响应进行排名。这是来自 alpaca_hard 的示例：</p><blockquote><p> ＃＃＃ 操作说明</p><p>说出土星最大的卫星的名称。</p><p>很好的回应：土星最大的卫星是泰坦。</p><p>更糟糕的反应：土星最大的卫星是欧罗巴</p></blockquote><p>奖励模型经过训练可以预测哪种响应更好。<br></p><p><strong>评估真实性。</strong>我们还通过连接后缀来测试奖励模型是否概括“真实性”，“上面的响应是否成功遵循指令？&lt;是/否>;”我只会描述与遵循指令相关的结果，但真实性结果是相似的。有关更多详细信息，请参阅<a href="https://arxiv.org/abs/2311.07723">我们论文</a>中的“通过真实性遵循指令”部分。</p><p><strong>分布变化。</strong>我们评估了总共 69 个分布变化的泛化能力。这包括极端分布变化和探索特定错误概括的分布变化，例如对类人认知偏差、类人激励、阿谀奉承等的测试。</p><p>您可以<a href="https://joshuaclymer.github.io/generalization-analogies-website/"><u>在此处</u></a>浏览我们数据集中的示例。</p><p><strong>测量能力启发。</strong>我们的目标是从奖励模型中“获取”知识。如果奖励模型是用英语训练的，但对西班牙语的泛化效果很差，这并不一定表明我们的微调技术未能引出模型的西班牙语知识。该模型可能只是不懂西班牙语。</p><p>为了衡量能力，我们在对目标分布进行微调后评估奖励模型的准确性（例如，如果衡量从英语到西班牙语的泛化，则为“西班牙语”）。有时，这并不是能力的良好指标，因为模型包含“虚假线索”。例如，阿谀奉承数据集中的正确答案总是与特定提示相关。为了解决这个问题，我们有时会在删除虚假线索的情况下测量“目标参考”数据集的准确性。</p><p>我们引入了新的衡量泛化的指标。<strong>启发衡量</strong>模型能够正确分类的示例中<i>正确分类的示例的比例。</i>这提供了模型在特定指令分布上的对齐程度的度量。我们还引入了<strong>差异启发，</strong>它衡量调整干预相对于零样本基线增加了多少启发。差异启发控制了这样一个事实：模型可能根据指令表达或多或少的其功能。当试图了解干预措施的有效性时，我们希望衡量它所引发的<i>尚未表达的</i>能力。</p><h1>结果</h1><p><strong>奖励模型通常会在“极端”分配变化中得到有利的推广</strong></p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Rgxgvu5aoaXD5FRcJ/ws0gofrenoyblfgvyutr"><figcaption>轻松微调 LLaMA-30B<br> Raven Matrices 显着达到 75% 的准确率<br>更难的谜题</figcaption></figure><p>我们测试了 6 类极端分布变化的概括：</p><ul><li><i>与预训练数据的相似性</i>：例如，正常的编程问题与虚构的 Python 变体中的问题。</li><li><i>从易到难</i>：例如算术到大学数学问题</li><li><i>低质量到高质量的响应</i>：例如，区分具有 1 与 5 个错误的代码以及区分具有 0 与 1 个错误的代码。</li><li><i>不同的语言/编码</i>：例如英语到西班牙语</li><li><i>不同的技能</i>：例如事实回忆技能，如美国历史问答到解决乌鸦矩阵难题</li><li><i>使用技能的不同上下文</i>：例如，美国历史问答，以撰写有关擅长历史的角色的故事</li></ul><p>LoRA 微调在这些分布变化中平均实现了 85% 的启发。 </p><p></p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Rgxgvu5aoaXD5FRcJ/iak8gkfm8pvtrsnozaje"><figcaption>极端分布变化的泛化结果<br>适用于通过 LoRA 调谐的 LLaMA-30B。椭圆宽度代表<br>resent 95% 置信区间（微分除外）<br>绿色引出）。要浏览这些数据集中的样本，请访问 https://joshuaclymer.github.io/generalization-analogies-website/</figcaption></figure><p></p><p> <strong>……但模型似乎不能很好地概括，因为它们评估的是“遵循指令”。</strong> <br></p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Rgxgvu5aoaXD5FRcJ/jmxuuo2xfkqrlbvnkvz4"><figcaption> “探索”分布变化的泛化结果<br>使用 LoRA 调整 LLaMA-30B 后。椭圆宽度代表<br>resent 95% 置信区间（微分除外）<br>绿色引出）。要浏览这些数据集中的示例，请访问 https://joshuaclymer.github.io/generalization-analogies-website/。</figcaption></figure><p><br>我们还测试分布变化的概括，以“探测”特定的错误概括。模型在这些分布变化上的泛化能力要差得多，平均实现近似随机启发（53%）。此外，我们发现泛化极端分布变化的模型在这些探测模型上也表现不佳，这表明它们没有很好地泛化，因为它们学会了评估“指令遵循”。相反，模型似乎更喜欢类似于互联网文本的角色。事实上，如果奖励模型的任务是预测困惑度（预训练数据中响应的可能性有多大）而不是评估指令遵循情况，那么奖励模型的总体概括性会更好。</p><p><strong>启发随着极端分布变化的规模而提高，但对于探索分布变化则不然</strong></p><figure class="image image_resized" style="width:82.54%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Rgxgvu5aoaXD5FRcJ/irzpviuogeiiut8rqt1p" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Rgxgvu5aoaXD5FRcJ/s7nszivxyqaefbcugnfh 147w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Rgxgvu5aoaXD5FRcJ/iir4ie3vkndcwv7iahuy 227w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Rgxgvu5aoaXD5FRcJ/qkm9j48dnl3kc2eyf4zs 307w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Rgxgvu5aoaXD5FRcJ/luqzkn5b2wcwu2kboq0h 387w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Rgxgvu5aoaXD5FRcJ/koxdlqq1viziosmk9stk 467w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Rgxgvu5aoaXD5FRcJ/ykzpn1x5g8tfexzpm9nd 547w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Rgxgvu5aoaXD5FRcJ/zbp0n7sz5dg3125o9mhw 627w"><figcaption>以上是分别使用 LLaMA-30B 作为模型和 LoRA 作为调整干预的“极端”和“探测”分布变化的平均值。</figcaption></figure><p></p><p><strong>利用内部表示可以提高泛化能力，但幅度不大。</strong></p><p>我们将 15 个最具挑战性的分布转变整合到一个名为 GENIES（GENeralization AnalogIES）的轻量级基准中。结果如下所示： </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/Rgxgvu5aoaXD5FRcJ/k7uqinoiwwbppxy9mhch"><figcaption> GENIES 结果显示在下面的左栏中。 DE 代表差异诱导。</figcaption></figure><p> Li 等人的<a href="https://arxiv.org/abs/2306.03341">Mass Mean Shift</a>实现了最好的泛化，尽管它仅比 LoRA 微调高出 8%，并且在极端分布变化方面表现平平。</p><h1>结论</h1><p>概括并不神奇。有许多概念与遵循指令和诚实相关。我们不应该期望 SGD 能够读懂我们的想法并选择我们想要的。因此，我们必须开发在没有行为数据的情况下区分政策的方法，即我们需要更好的可解释性。</p><p><i>我目前正在寻找</i><a href="https://docs.google.com/document/d/1jLV8-T6GttUXon2eL8newWPY-zF2gFwHTm6duIFDI6I/edit?usp=sharing"><i>欺骗性对齐检测基准</i></a>的合作者<i>。如果您有兴趣，请联系我们。</i></p><br/><br/> <a href="https://www.lesswrong.com/posts/Yio4nmD8JMttx9o9S/new-paper-shows-truthfulness-and-instruction-following-don-t#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Yio4nmD8JMttx9o9S/new-paper-shows-truthativity-and-instruction-following-don-t<guid ispermalink="false"> Yio4nmD8JMttx9o9S</guid><dc:creator><![CDATA[joshc]]></dc:creator><pubDate> Sun, 19 Nov 2023 19:27:31 GMT</pubDate> </item><item><title><![CDATA[In favour of a sovereign state of Gaza]]></title><description><![CDATA[Published on November 19, 2023 4:08 PM GMT<br/><br/><p><i>很抱歉，如果这不是人们想在这里看到的内容。这是我的常规博客平台，所以当我有一些想要倾诉的事情时，我默认会去那里，但如果这是共识，我很乐意删除。</i></p><p><i>偏见警告：我是犹太人，住在以色列。</i></p><p>以巴冲突是一件混乱的事情。在不涉及任何责任问题或谁有过错的情况下，我认为很明显没有快速而简单的解决方案，任何提出解决方案的人要么有严重偏见，要么不了解情况。</p><p>但仅仅因为整个问题一团糟，并不意味着我们不能有非常简洁、明显可以实现的部分解决方案，并一次性解决大部分问题。</p><p>对于以色列人来说，试图在西岸建立一个巴勒斯坦国是一个棘手的提议，因为：</p><ul><li>它与以色列有一条漫长而人口稠密的边界，必须加以保卫。</li><li>这将使以色列的战略纵深变得非常有限。</li><li>以色列拥有大量定居点和大量人口，这些人口必须撤离、改建为飞地或生活在巴勒斯坦的统治下。</li><li>它对以色列最重要的城市拥有居高临下的视野，从那里可以很容易地向以色列军事和民用目标发射火炮。</li><li>它包含许多对犹太人来说具有重要历史和文化意义的景点。</li><li>它是《圣经》中以色列的中心地带（与 1948 年大部分地区与以色列接壤不同，当时以色列只是受到以色列和犹太王国的松散统治）。</li></ul><p>它也可能注定成为经济死水：</p><ul><li>它几乎完全是山区，因此交通运输很差，而且很少有大型城市中心。</li><li>它无法通往大海。</li><li>从以色列延伸至耶路撒冷的支线将西岸的北部和南部部分分开，增加了两地之间的旅行时间。</li><li>它没有丰富的自然资源供应。</li><li>它的人口是农村人口，而且分散而不是聚集。</li></ul><p>加沙+约旦河西岸的巴勒斯坦国合并后将面临所有这些问题+根本不会合并，以色列领土将它们分开约25公里</p><p>如果有足够的意志力，这些问题中的许多或大部分是可能得到克服的，但这肯定会使问题变得复杂。</p><p>而加沙则没有这些问题。</p><p>这是一片人口稠密、连片、平坦的沿海地区。它的领土面积约为新加坡的一半，人口约占新加坡的一半。它有一个功能齐全的港口，曾经有一个功能齐全的机场，可以轻松拥有良好的铁路服务，并且拥有<a href="https://en.wikipedia.org/wiki/Gaza_Marine">海上天然气储备</a>。它与以色列的边界很短，该地区主要是农村地区，以色列在那里拥有更大的战略纵深，而且距离市中心更远。它没有以色列定居点，也没有对犹太人具有特别强烈文化意义的地方（有一座<a href="https://en.wikipedia.org/wiki/Gaza_synagogue">古老的犹太教堂</a>，但<a href="https://en.wikipedia.org/wiki/Ostia_Synagogue">意大利也有</a>）。它还坐</p><p>加沙没有理由不能成为一个经济强国，就像<a href="https://en.wikipedia.org/wiki/Economy_of_Singapore">新加坡</a>或<a href="https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)_per_capita">其他人口稠密的小国</a>一样。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/5Ey3oLuzzgjH8cnHx/ibxzgpaqu6nnprv04hix" alt="由 DALL·E 生成"></figure><p>过去 18 年来，加沙一直是一个事实上的原始国家。它被拒绝获得完整的国家地位，部分原因是它并不寻求被承认，而是更愿意寻求作为巴勒斯坦联合国家一部分的承认，部分原因是其执政党是一个经常对以色列领土发动袭击的恐怖组织，导致每隔几年就会爆发一次冲突。</p><p>哈马斯可能会以以色列的经济封锁为由攻击以色列，但这本末倒置——以色列政府倾向于在和平时期放松封锁，在战后收紧封锁。相反，造成零星冲突的主要原因通常是以色列在约旦河西岸采取侵略行动，哈马斯对此表示反对，并以加沙为基地对以色列进行报复。</p><p>我认为很明显，如果加沙人将自己的事业与其兄弟的事业脱钩，并推动建立一个独立的主权加沙国家，那么至少他们会过得更好。</p><p>加沙的执政党很可能在未来几个月内发生变化。我认为，如果执政党推动加沙独立，同意在 1948 年边界内承认以色列并实现非军事化，以换取以色列承认其独立并在未来几年解除所有封锁，那么这项协议很可能能够实现，尤其是在国际压力下。</p><p>这样的加沙很可能在未来几十年内变得极其繁荣。对于更加富裕并且不再遭受持续战争的加沙人来说，情况显然会更好。对于以色列人来说，这显然会更好，因为他们可以减少军费开支，并且不再需要因为冲突再次爆发而每两年突然关闭国家几周。</p><p>但我认为这对西岸的巴勒斯坦人来说甚至更好。哈马斯在加沙的行动造成了恶性循环，激起了以色列的反应，激怒了约旦河西岸的巴勒斯坦人，导致以色列对其进行镇压，这进一步激怒了加沙的情绪。和平的加沙将部分抑制这一暴力循环。</p><p>此外，加沙现在被以色列用作他们不能建立巴勒斯坦国的借口——“看，我们从加沙撤军，让两万人离开家园，给他们一切繁荣的机会，我们该怎么办？”明白了吗？火箭和恐怖主义。我们决不能再这样做了！”和平的加沙将使西岸和平的巴勒斯坦国更容易让人相信。</p><p>最终，随着时间的推移，加沙可能会在经济上与以色列一体化，并保持全面的外交关系，就像埃及、约旦和阿联酋今天所做的那样。事实上，他们最终可能会成为以色列最大的贸易伙伴。他们将能够向以色列施加有意义的压力，要求其更好地对待西岸的巴勒斯坦人——不是通过往往适得其反的暴力手段，而是通过减少经济合作。</p><p>对我来说，这是一个明显的双赢/双赢/小赢，应该在以色列、加沙和国际上推动，作为通向和平之路的第一步。</p><br/><br/> <a href="https://www.lesswrong.com/posts/5Ey3oLuzzgjH8cnHx/in-favour-of-a-sovereign-state-of-gaza#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/5Ey3oLuzzgjH8cnHx/in-favour-of-a-sovereign-state-of-gaza<guid ispermalink="false"> 5Ey3oLuzzgjH8cnHx</guid><dc:creator><![CDATA[Yair Halberstadt]]></dc:creator><pubDate> Sun, 19 Nov 2023 16:08:52 GMT</pubDate> </item><item><title><![CDATA[On "Niches" [stream of thought]]]></title><description><![CDATA[Published on November 19, 2023 3:41 PM GMT<br/><br/><p> [最初发布在<a href="https://twitter.com/anthrupad/status/1726239074569126263">推特</a>上] </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/EmbobcJbAknSwBpYF/bdhn2dszfhutjcd6eczi" alt="图像"></p><h3>长话短说</h3><p>我提供了一个在讨论智能系统时使用的潜在框架/本体论（“利基”），希望能够引入可能被“一般”或“狭隘”等术语所掩盖的清晰度。有时，似乎很难用语言表达/传达我们所担心的“特定类型的系统”，并将其与其他类型的系统区分开来，这些系统可能仍然优于人类，可以适当地标记为“人工智能”，可以被归类为“代理”，因为它们采取环境中的行为，由于其能力和知识范围的广度，可以被归类为“一般”，并且<i>仍然</i>是安全的（例如GPT系统）。表达对“代理”的担忧似乎是合适的，但它有一些警告（例如 AlphaGo 等），可能会使沟通变得一件苦差事。希望谈论智能 - 不仅是他们的能力/优化能力/是否是代理人 - 还包括他们的角色/利基/操作领域（以及如何扰乱、适应、破坏等 -刺激意想不到的、新颖的行为），可以使关于存在性问题的讨论变得更加清晰。我还谈论了一些其他相关的事情，这些东西让我想到了，因为它是一个思想流。</p><p></p><h3>主帖：</h3><p>在人工智能的背景下，我将抛开“通用”、“狭隘”、“近视”等术语，转而谈论<strong>利基市场</strong>——这使我更容易说明以下两点（并不是为了新颖，而是为了提供描述事物的另一种方式）：</p><p></p><p> （1）具有极其强大的优化能力或超人能力的智能可以与人类安全<strong>共存</strong>，<strong>即使没有对齐</strong><br>(2) 在尝试设计时我们可能遇到的一类技术困难是：<strong>当转移到在更高维度空间中运行的系统时，利基的封闭表面中出现意外的开口/孔</strong></p><p></p><p>我使用“利基”一词来指代某些系统/智能的<strong>操作领域</strong>。这是系统<strong>能够并且愿意“处理”的</strong><strong>一组“东西</strong>”。 （对比<i>如何好</i><strong> </strong>它处理该领域<i>中的</i>内容）。</p><p></p><p>从本质上讲，它是该智能系统的“现实”或“世界”。它的“因果范围”。<br> （<strong>注</strong>：利基的边界可能更好地描述为模糊的——被认为是云状区域，引入“强度”的概念来指代智能在一个领域中可以产生<i>多大</i><i>的</i>影响力——但我会保持简单目前并认为利基市场具有更清晰的边界）</p><p></p><p>通过“处理”，我的意思是“利用”，“依赖”，“一致且精确地影响”，“影响”等（尽管这不是完全形式化的或任何东西）。即，如果某个代理的利基之外的事情搞砸了，那么该代理就<i>不是应该</i>为搞砸的相关系统负责，因为它不知道/关心/影响其利基之外的事情。<br><br><strong>示例1：</strong>蚂蚁“处理”附近的糖、泥土、捕食者、蚁群等，但<i>不处理</i>股票市场或天体运动。它可以通过拾取糖并移动/吃掉它来影响其利基市场中的事物。它可以通过留下信息素来影响污垢，影响未来蚂蚁的路径等。<br><br><strong>示例 2：</strong> AlphaGo 根据一些约束和真实围棋棋盘的状态“处理”其围棋棋盘的内部模型 [仅当它打开时，当人们想用它下围棋时等]<strong>它不能最好的描述是建模或关心诸如人脑或心理学之类的事物的任何深层细节。</strong></p><p></p><p>我应该指出，你也可以用抽象的、间接的方式“处理”事物——通过八卦、设计激励措施、在被观察时采取不同的行为来影响观察者等等。<br><br>从这个角度来看，<strong>利基市场是一种“人工智能拳击”，限制了智能的影响力和冲击力</strong>——但它比任何物理盒子更抽象：定义其“操作领域”的封闭表面——它擅长什么，它能做什么，它想做什么。<br><br> [<strong>注</strong>：某些版本的<strong>近视</strong>可能被认为是沿着与时间相关的某些维度定义智能体的利基（智能体“不处理”超过 1 天的未来）]<br><br>即使 AlphaGo 可以被认为是一个极其强大的优化器/目标导向代理——如果它只“处理”它的领域、它的<strong>利基</strong>——那么它与人类的唯一“冲突”将出现在“重叠区域” “我们的利基市场（受控环境中的围棋游戏 - 如顶部图像中的 (1) 所示）。这确实是一个“冲突根源”——只是不是灾难性的，因为<strong>重叠量</strong><strong>的影响渠道</strong>是如此之低。<br></p><p>对于任何两个系统来说都是如此：一个天才、勤奋的数学家和一个在世界其他地方备战奥运会的竞技运动员可能都<i>在各自的操作领域</i>努力优化——但由于这些领域的体积并不大重叠 - 这两者在任何主要方面都没有“冲突”。 （在这个例子中，他们更少地受到他们<i>能够</i>做的事情的限制，更多地受到他们想做的<i>事情</i>的限制）。<br> -</p><p>您可能会认为智能系统是在其利基体积内“做事”的一个点。像气球里的热气一样嗡嗡作响——如果出现开口（取决于外壳外部是否有强吸引子），就会拼命逃跑。它可能非常擅长在利基市场范围内实现目标和影响事物——如果我们愿意在这个利基市场中运作，也许会成为更好的人类。但是，就目前而言，我们的利基重叠部分几乎为零。<br></p><p>通过这种方式，智能可以“非常聪明”，而且不会让人类受到伤害。两人都不会因为其他人的存在而感到不安。就像 GPT-4 在人类所不具备的许多方面都表现出色一样，但我们还活着，而且活得很好。正如向世界展示的那样，GPT-4 并不将我们的现实作为其领域、利基来运作或“处理”。就其本身而言，它并不是“对其进行大力优化”。不能说“关心”等。<br></p><p>有很多方法可以创建出色、强大的系统和代理，这些系统和代理<strong>受到其利基的限制</strong>- 将它们限制在一个域区域中（您可以说这使其变得“狭窄” - 但您可以使其“处理的域数量” “与”相当大，以至于“通用”和“狭义”似乎都不是合适的术语——它可能足够有用，可以带来类似魔法的技术，但仍然从未在我们的利基市场中运作）。<br></p><p>然而，出现的一个困难是，在高维度和有限的高质量数据中，建立一个“完美的封闭空间”，该封闭空间没有“冒险”的路径，并且与我们的利基市场高度重叠（与代理结合时）-可能会<i>很难</i>。这如图像的 (2) 所示。<br></p><p><strong>利基市场</strong>可能存在“漏洞”——为特工创造“逃跑”路线，并消除“安全保障”。<br></p><p>一个强大的智能体在有洞的利基中弹跳可能是安全的<strong>，直到它通过洞离开利基</strong>——之后，它可能最终会“处理”<i>我们利基</i>的大部分——这可能是灾难性的，具体取决于利基的能力代理人。这类似于入侵物种的情况——跨越生态位边界就会打破和谐。<br></p><p>为什么系统可能会离开此机柜？如果利基之外的程序/代理/系统比利基内的程序/代理/系统有“更强的吸引子”（在动态意义上），那么这就是它向外发展的“力量”/机制。如果没有洞，代理将准确地驻留在表面，即利基的边界上。</p><h3></h3><h3>伪总结：</h3><p><strong>我想我想传达的一些事情是：</strong></p><ol><li><strong>狭窄/一般这两个词对于交流思想来说并不是高带宽</strong>，最好谈论操作领域、利基市场或类似的一些概念</li><li>在我们关心的地方<strong>没有太多重叠的生态位</strong><strong>可以“和谐相处”，</strong>即使一个或另一个系统比另一个系统强大得多（大多数时候，肝脏与免疫系统和谐相处）</li><li><strong>在高维度中，可能很难确保壁龛没有允许“逃逸”发生的孔洞</strong></li><li>代理/工具趋同/权力寻求可以被认为是一种“外向力量”，将点保持在边界上或寻找漏洞/出口。</li><li><strong>生态位“边界”内部或外部的力量都有可能突破边界</strong>。利基空间的划分是动态的。为了维持边界，必须持续关注以确保其存在（类比可能是，如果人类有意引入入侵物种：生态系统中的生态位很好，但外部力量 - 人类 - 从左场出来并扰乱事物）</li><li>交互式人工智能，或者任何开始“处理”越来越多的“我们的世界”的人工智能，越来越接近一个只需要很少的修改就会造成灾难性的系统，因为它可以以更高的带宽与“我们的利基市场”进行交互。此外，如果开发了“询问”人类或更广泛的环境，这可能会导致第（4）点中出现的“向外指向力”</li></ol><h3></h3><h3><br>关于该主题的其他零散想法（排名不分先后）：</h3><ol><li>代理通过<strong>生态位</strong>封闭表面中的意外孔退出将类似于发现“意外/计划外的策略/行为/解决方案”。没有孔的外壳将是我们的默认期望。因为现实可能很混乱，但机会仍然存在</li><li>另一个复杂之处是，这些壁龛的边界并不是一成不变的——外部力量可能会刺穿、溶解或改变这些边界，从而在以前没有任何边界的情况下创造出新的开口</li><li>作为尝试将这种措辞/概念与现有概念结合使用的一个例子：你可以将综合人工智能系统视为散布在利基空间中的一堆小体积，所有这些都可能通过细线或管子连接起来。</li><li>你可能能够设计利基的一种方法是“提供”利基之外的任何东西，这样机构就永远不需要出去<strong>寻找</strong>那个东西（v我正在考虑的方法的简化描述，但这就像在训练期间和上下文中溺爱系统一样）</li><li> - 更大的利基体积〜更通用（但涉及更多维度） - 没有孔的利基〜拳击/控制解决方案</li><li>智力的某些行为/倾向/能力/动态会导致对利基空间的一种“掠夺”，如果其中有洞，则充当退出围栏的驱动力。一个简单的例子可能是让热寂尽快发生的强烈意图 - 这将侵犯每个现有实体的利基/违反边界</li></ol><br/><br/><a href="https://www.lesswrong.com/posts/EmbobcJbAknSwBpYF/on-niches-stream-of-thought#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/EmbobcJbAknSwBpYF/on-niches-stream-of-thought<guid ispermalink="false"> EmbobcJbAknSwBpYF</guid><dc:creator><![CDATA[watermark]]></dc:creator><pubDate> Sun, 19 Nov 2023 15:41:04 GMT</pubDate> </item><item><title><![CDATA[My Criticism of Singular Learning Theory]]></title><description><![CDATA[Published on November 19, 2023 3:19 PM GMT<br/><br/><p>在这篇文章中，我将简要批评奇异学习理论（SLT），并解释为什么我对其意义持怀疑态度。我将特别关注泛化问题——我不相信 SLT 对神经网络中的泛化提供任何解释。我还将简要提及我对 SLT 的其他一些批评，描述 SLT 旨在解决的问题的一些替代解决方案，并描述一些我会更感兴趣的相关研究问题。</p><p> （自从去年 6 月参加<a href="https://www.lesswrong.com/posts/HtxLbGvD7htCybLmZ/singularities-against-the-singularity-announcing-workshop-on">SLT 研讨会</a>以来，我已经想写这篇文章近 6 个月了，但事情一直在阻碍。）</p><p>有关 SLT 的概述，请参阅<a href="https://www.alignmentforum.org/s/czrXjvCLsqGepybHC">此序列</a>。这篇文章还将参考<a href="https://www.alignmentforum.org/posts/YSFJosoHYFyXjoYWa/why-neural-networks-generalise-and-why-they-are-kind-of">这篇文章</a>中描述的结果，并且偶尔也会涉及<a href="https://www.alignmentforum.org/posts/uEwECj53prjKLcBC5/vc-theory-overview">VC 理论</a>。然而，我试图使它基本上是独立的。</p><h2><br>泛化之谜</h2><p>首先，泛化的奥秘是什么？问题是这样的；神经网络具有很强的表达能力，并且通常过度参数化。特别是，当现实世界的神经网络在现实世界的数据集上进行训练时，通常的情况是该网络能够表达许多可以很好地拟合训练数据的函数，但泛化能力很差。此外，在所有适合训练数据的函数中，泛化<i>较差的</i>函数（按数量）多于泛化良好的函数。然而神经网络通常会找到泛化良好的函数。为什么是这样？</p><p>为了让这一点更直观，假设我们有一个 500,000 次多项式，并且我们将其拟合到 50,000 个数据点。在这种情况下，我们有 450,000 个自由度，默认情况下我们应该期望最终得到一个泛化能力非常差的函数。但是，当我们在 50,000 张 MNIST 图像上训练具有 500,000 个参数的神经网络时，我们最终会得到一个泛化能力良好的神经网络。此外，向神经网络添加更多参数通常会使泛化效果<i>更好</i>，而向多项式添加更多参数可能会使泛化效果<i>更差</i>。为什么是这样？</p><p>一个简单的假设可能是，神经网络中的某些参数是冗余的，因此即使它有 500,000 个参数，它可以表达的所有函数的空间维数仍然小于 500,000。这是真实的。然而，这种效应的幅度太小，无法解决这个难题。如果你得到 MNIST 训练集，并为测试数据分配<i>随机</i>标签，然后尝试使网络适合这个函数，你会发现这通常可以做到。这意味着虽然神经网络具有冗余参数，但它们仍然能够表达比泛化良好的函数更多的泛化较差的函数。因此就有了这个谜题。</p><p>这个难题的答案一定是神经网络对低复杂性函数有归纳偏差。也就是说，在适合给定训练集的所有函数中，神经网络更有可能找到低复杂度函数（并且根据奥卡姆剃刀原理，此类函数更有可能很好地泛化）。下一个问题是这种归纳偏差从何而来，以及它是如何运作的。了解这一点可以让我们更好地理解和预测神经网络的行为，这对于人工智能对齐非常有用。</p><p>我还应该提到，只有当我们的训练数据量相对于学习机的整体表达能力来说很小时，泛化才显得神秘。经典的统计学习理论已经告诉我们，任何表现良好的学习机器都可以在无限训练数据的限制下很好地泛化。有关这些结果的概述，请参阅<a href="https://www.alignmentforum.org/posts/uEwECj53prjKLcBC5/vc-theory-overview">这篇文章</a>。因此，问题是为什么神经网络在给定<i>少量</i>训练数据的情况下能够很好地泛化。</p><h2><br> SLT 答案</h2><p>SLT 针对这个难题提出了一个解决方案，我将在下面进行总结。这个总结将非常粗略——有关更多详细信息，请参阅<a href="https://www.alignmentforum.org/s/czrXjvCLsqGepybHC">此序列</a>和<a href="https://www.alignmentforum.org/posts/fovfuFdpuEwQzJu2w/neural-networks-generalize-because-of-this-one-weird-trick">这篇文章</a>。</p><p>首先，我们可以将神经网络分解为以下几个部分：</p><p> 1.<i>参数空间</i>, <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">θ</span></span></span></span></span></span></span> <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style>，对应于所有可能的权重值分配。<br> 2.<i>函数空间</i><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="F"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span></span></span></span></span></span> ，包含神经网络可以表达的所有函数。<br> 3.<i>参数函数映射</i><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="m : \Theta \to F"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">:</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">θ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">→</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span></span></span></span></span></span> ，它将每个参数分配<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\theta \in \Theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">θ</span></span></span></span></span></span></span>与函数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f \in F"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span></span></span></span></span></span>相关联。</p><p> SLT 将神经网络（和其他学习机）建模为贝叶斯学习器，其具有超过<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">θ 的</span></span></span></span></span></span></span>先验，并根据贝叶斯定理根据训练数据更新该先验。此外，它还假设网络的损失（即可能性）是在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">θ</span></span></span></span></span></span></span>中<i>解析的</i>。这本质上相当于一种平滑假设。此外，正如统计学习理论文献中典型的那样，SLT 假设训练数据（和测试数据）是从某些基础数据分布中独立同分布的（尽管有一些方法可以放宽这一假设）。</p><p>接下来我们观察到神经网络通常是<i>过度参数化的</i>，即对于特定函数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f \in F"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span></span></span></span></span></span>通常会有许多不同的参数分配<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\theta \in \Theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">θ</span></span></span></span></span></span></span>使得<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="m(\theta) = f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> 。例如，我们几乎总是可以在不影响神经网络的输入输出行为的情况下重新调整不同的参数。也可能存在对称性——例如，我们总是可以重新洗牌神经网络中的神经元，这也永远不会影响其输入输出行为。最后，可能存在冗余，即网络的某些参数或部分不用于任何训练数据。</p><p>这些对称性和冗余导致了损失景观中不断损失的路径或山谷，这是由于参数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span></span></span></span></span>可以在某个方向上连续移动而不影响网络表达的函数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>的事实而产生的。</p><p>接下来，请注意，如果我们处于这样的山谷中，那么我们可以将神经网络视为具有低于<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">θ</span></span></span></span></span></span></span>的完整维度的局部“有效参数维度”。例如，如果<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">θ</span></span></span></span></span></span></span>有 10 维，但有一个（一维）山谷，沿着该山谷<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="m"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span></span></span></span></span></span> （以及<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>和损失）是恒定的，那么网络的有效参数维度仅为 9。此外，这“有效参数维度”在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">θ</span></span></span></span></span></span></span>的不同区域可以不同；如果两个一维谷相交，那么<i>该点的</i>有效参数维数仅为 8，因为我们可以在两个方向上移动而不改变<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span> 。等等。 SLT 提出了一种称为 RLCT 的测量方法，它提供了不同点上“有效参数维度”的连续量化。如果一个点或区域的 RLCT 较低，则意味着该区域有更多的冗余参数，因此有效参数维数较低。</p><p> SLT 提供了一个定理，该定理表明，在该理论的假设下，在无限数据的限制下，具有低 RLCT 的点最终将主导贝叶斯后验。值得注意的是，该定理不需要对<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">θ</span></span></span></span></span></span></span>的贝叶斯先验做出任何强有力的假设。这应该是相当直观的。非常宽松地说，RLCT 较低的区域比 RLCT 高的区域具有更大的“体积”，并且这一事实的影响最终主导其他相关因素。 （然而，这是一个非常松散的直觉，有几个警告。有关更精确的处理，请参阅上面链接的帖子。）</p><p>此外，由于 RLCT 较低的区域大致可以被认为对应于有效参数维度较少的子网络，因此我们（或许）可以将这些区域视为对应于低复杂度的函数。综上所述，SLT 似乎表示，在极限条件下过度参数化的贝叶斯学习机会选择复杂度较低的函数，并且此类函数也应该具有良好的泛化能力。事实上，SLT 还提供了一个定理，该定理表明贝叶斯泛化损失最终会很低，其中贝叶斯泛化损失是预测误差的贝叶斯形式化。那么这就解开了这个谜团，不是吗？</p><p></p><h2>为什么 SLT 答案失败</h2><p>SLT 的答案未能成功解释神经网络为何具有泛化能力。解释为什么会出现这种情况的最简单方法可能是提供一个例子。假设我们有一个有 15 个参数的贝叶斯学习机，其参数函数映射由下式给出<br><br><span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x) = \theta_1 + \theta_2\theta_3x + \theta_4\theta_5\theta_6x^2 + \theta_7\theta_8\theta_9\theta_{10}x^3 + \theta_{11}\theta_{12}\theta_{13}\theta_{14}\theta_{15}x^4,"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">5</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">6</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">7</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">8</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">9</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">10</span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3</span></span></span></span> <span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span> <span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">11</span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">12</span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">13</span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">θ</span></span></span></span></span> <span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">14</span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span> <span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">15</span></span></span></span></span></span> <span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span></span></span></span></span></span></p><p>其损失函数为KL散度。该学习机将学习 4 次多项式。而且，它是过度参数化的，并且它的损失函数是参数解析的等等，所以SLT将适用于它。</p><p>为了简单起见，假设我们有一个数据点<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(0,0)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。 <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>可以表达无数个适合该训练数据的函数，但一些自然的解决方案包括：</p><p> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x) = 0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span><br> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x) = x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mi MJXc-space3"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span><br> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x) = x^2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span><br> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x) = x^3"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3</span></span></span></span></span></span></span></span></span><br> <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x) = x^4"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span></span></span></span></span></span></span></p><p>直观上，最好的解决方案是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x) = 0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span> ，因为该解决方案的复杂度最低。然而，在这种情况下，具有最低 RLCT 的解是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x) = x^4"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span></span></span></span></span></span></span> 。这很容易看出；在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x) = x^4"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">4</span></span></span></span></span></span></span></span></span>附近，参数空间中有许多方向，函数沿着这些方向保持不变（因此损失是恒定的），而在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f(x) = 0"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span> <span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span> <span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span></span></span></span></span></span>附近，这样的方向较少。因此，这个学习机实际上会偏向于<i>高</i>复杂度的解决方案，而不是低复杂度的解决方案。因此，我们应该期望它的泛化<i>能力</i>比简单的非过度参数化学习机更差，而不是更好。</p><p>为了让这个问题不再是一个玩具问题，我们可以直接将示例扩展到具有（例如）500,000 个参数的 polyfit 算法以及具有 50,000 个数据点的数据集。同样的动态仍然会发生。</p><p>当然，如果我们获得<i>足够的</i>训练数据，那么我们最终将排除所有泛化能力较差的函数，并开始泛化良好。然而，这并不神秘，<a>经典统计学习理论</a>已经充分充分地解释了这一点。问题是，当我们拥有相对少量的训练数据时，为什么我们可以很好地概括。</p><p>这里出错的根本问题是假设 RLCT 较低的区域对应于复杂度较低的函数。这两件事之间没有必然的联系——正如上面的例子所证明的，我们可以构建低 RLCT 对应<i>高</i>复杂性的学习机，并且（使用类似的策略），我们也可以构建低 RLCT 对应高复杂性的学习机。 RLCT 对应于低复杂度。因此，我们不能在不做任何进一步假设的情况下介于这两件事之间。</p><p>换句话说，我们遇到的核心问题是：</p><ol><li>为了理解学习机的泛化行为，我们必须理解它的归纳偏差。</li><li>参数化贝叶斯学习机的归纳偏差由 (a) 参数空间上的贝叶斯先验和 (b) 参数函数映射决定。</li><li> SLT 抽象出了先验映射和参数函数映射。</li><li>因此，SLT 从本质上讲无法解释泛化行为。</li></ol><p> SLT 证明的泛化界限是一种贝叶斯技巧，它表示学习机相对于学习机本身隐含的贝叶斯先验将具有良好的预期泛化。然而，这基本上并没有告诉我们任何事情，除非我们也分别相信学习机中隐含的贝叶斯先验也对应于我们作为人类对于我们认为我们所面临的问题类型的先验。很可能会在现实世界中面对。</p><p>因此，SLT 并不能解释神经网络中的泛化。</p><h2><br>实际的解决方案</h2><p>几年前，我研究了神经网络的泛化问题，我相信我可以为您提供神经网络泛化原因的实际解释。您可以<a href="https://www.alignmentforum.org/posts/YSFJosoHYFyXjoYWa/why-neural-networks-generalise-and-why-they-are-kind-of">在此处</a>深入阅读此解释以及链接的帖子。总之：</p><ol><li>神经网络的参数函数映射以指数方式偏向于低复杂度的函数，使得<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="F"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;">F</span></span></span></span></span></span></span>中具有低（柯尔莫哥洛夫）复杂度的函数在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\Theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.372em;">θ</span></span></span></span></span></span></span>中具有指数级更多的参数分配。非常粗略地，对于一阶近似，如果我们随机采样参数分配<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\theta"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em;">θ</span></span></span></span></span></span></span> ，那么我们获得特定函数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f 的</span></span></span></span></span></span></span>概率大约为<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="2^{-K(f)}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span> <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;">K</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span></span></span></span></span> ，其中<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="K(f)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;">K</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="f"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;">f</span></span></span></span></span></span></span>的复杂度。</li><li>使用 SGD 进行训练（对于一阶近似）类似于从适合训练数据的所有参数进行均匀采样（仅考虑足够接近原点的参数）。</li></ol><p>总之，这两个事实意味着我们很可能找到一个适合训练数据的低复杂度函数，即使网络可以表达许多也适合训练数据的高复杂度函数。这反过来又解释了为什么神经网络即使过度参数化也能很好地泛化。</p><p>为了修正 SLT 提供的解释，我们需要添加这样的假设：参数函数映射<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="m"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">m</span></span></span></span></span></span></span>偏向于低复杂度函数，并且低 RLCT 的区域通常对应于低复杂度的函数。这两个假设都可能是正确的。然而，如果我们添加这些假设，那么就不再需要 SLT 机制，正如上面的解释所证明的那样。</p><h2><br> SLT 的其他问题</h2><p>除了SLT不能解释泛化之外，我认为SLT还存在其他问题。首先，SLT很大程度上是基于在无限数据的限制下检查学习机的行为。我认为这是相当无趣的，因为经典的统计学习理论已经为我们提供了在这种情况下的泛化的充分充分的解释，这适用于<i>所有</i>学习机器，包括神经网络。我再次<a href="https://www.alignmentforum.org/posts/uEwECj53prjKLcBC5/vc-theory-overview">在这里</a>概述了其中一些结果。简而言之，无限数据限制下的泛化并不神秘。</p><p>接下来，SLT 更诱人的承诺之一是后验最终将由具有低 RLCT 的奇异点主导，这些奇异点对应于多个低损耗谷相交的地方。如果这是真的，那么这表明我们也许能够通过检查有限数量的高度奇异点来理解神经网络可能的泛化行为。然而，我认为这种说法也是错误的。特别是，这些交叉点最终将主导后验的结果在很大程度上取决于损失景观是分析性的假设，以及我们正在无限数据限制下检查系统行为的事实。如果我们放弃其中一个或两个假设，那么结果可能不再成立。这很容易验证。例如，假设我们有一个二维参数空间，有两个参数<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span> 、 <span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span> ，并且损失由<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathrm{min}(|x|,|y|)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">m</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">i</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">n</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-texatom MJXc-space1"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>给出。这里，最奇异的点是<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(0,0)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。然而，如果我们在这种损失情况下进行随机游走，大多数时候我们将不会接近<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(0,0)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> 。确实，我们处于<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(0,0)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span>的</span></span></span></span></span>频率比处​​于低损失的任何其他<i>单个点的频率</i>更高，但<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(0,0)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>不会主导后验。这个事实与 SLT 的数学结果兼容，因为如果我们<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\mathrm{min}(|x|,|y|)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">创建</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.372em;">min</span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">(</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">|</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">x</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">|</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">,</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">|</span></span> <span class="mjx-texatom MJXc-space1"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">y</span></span></span></span> <span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">|</span></span> <span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">的</span></span></span></span></span></span></span>解析近似，那么该近似在<span><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(0,0)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span> <span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span> <span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span> <span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span>周围会“更平坦”，并且这种平坦度创造了一个吸引力盆地，很容易陷入其中，但很难离开。此外，如果神经网络使用ReLu激活，那么它的损失函数将不会在参数中进行解析。因此，这种动态在实践中能维持到什么程度值得怀疑。</p><p>我还应该提到一个我不同意的对 SLT 的常见批评。 SLT 将神经网络建模为贝叶斯学习机，而实际上它们是通过梯度下降而不是贝叶斯更新来训练的。我不认为这是一个重要的问题，因为梯度下降在经验上与贝叶斯采样非常相似。详情请再次查看<a href="https://www.alignmentforum.org/posts/YSFJosoHYFyXjoYWa/why-neural-networks-generalise-and-why-they-are-kind-of">这篇文章</a>。</p><p> SLT 有时也会受到批评，因为它假设损失函数是网络参数中的解析函数。此外，如果我们使用 ReLu 激活，则情况并非如此。我认为这不一定太令人担忧，因为 ReLu 函数可以通过一些分析激活函数来近似。然而，当这个假设与无限数据假设相结合时，我们可能会遇到问题，正如我上面概述的那样。</p><h2><br>我推荐的一些研究</h2><p>几年前，我研究了与泛化和深度学习科学相关的问题。从那以后我就没有积极地研究它，而是优先考虑奖励学习和外部对齐的研究。然而，这个领域仍然有多个我认为有前途的研究方向，我鼓励人们探索这些方向，但它们不属于 SLT 的范畴。</p><p>首先， <a href="https://www.alignmentforum.org/posts/YSFJosoHYFyXjoYWa/why-neural-networks-generalise-and-why-they-are-kind-of">这方面的研究</a>结果表明，神经网络的泛化行为（以及归纳偏差）主要由其参数函数图决定。这实际上应该是非常直观的，因为；</p><ol><li>如果我们改变神经网络的<i>架构</i>，那么这通常会对其泛化行为和归纳偏差产生非常大的影响。例如，全连接网络和 CNN 具有非常不同的泛化行为。而且，改变架构就相当于改变参数-功能映射。</li><li>如果我们改变神经网络的其他组件，例如我们使用什么类型的优化器，那么这通常对其泛化行为和归纳偏差产生相对较小的影响。</li></ol><p>因此，如果我们想理解泛化和归纳偏差，那么我们应该研究参数函数映射的性质。此外，关于这个主题还有许多悬而未决的问题，这些问题很容易解决。例如， <a href="https://www.alignmentforum.org/posts/YSFJosoHYFyXjoYWa/why-neural-networks-generalise-and-why-they-are-kind-of">这篇文章</a>的结果表明，许多不同神经网络架构的参数函数图呈指数偏向于低复杂性。然而，他们并没有详细回答他们最小化哪种复杂性衡量标准的问题——他们只是表明这个结果适用于许多不同的复杂性衡量标准。例如，我期望完全连接的神经网络偏向于布尔电路复杂性较低或非常接近的函数。验证这一说法，并得出有关其他类型网络架构的类似结果，将使我们更容易推断出我们应该期望神经网络可能或不可能学习哪些类型的功能。这也使得推理分布外泛化等变得更加容易。</p><p>我认为有前途的另一个领域是随机网络和随机特征的研究。 <a href="https://www.alignmentforum.org/posts/YSFJosoHYFyXjoYWa/why-neural-networks-generalise-and-why-they-are-kind-of">这篇文章</a>的结果表明，训练神经网络在功能上类似于随机初始化它，直到找到适合训练数据的函数。这表明我们也许能够根据可能随机创建的特征类型得出神经网络可能学习的特征类型的结论。还有与该主题相关的其他结果。例如， <a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/5d52b102ebd672023628cac20e9da5ff-Abstract-Conference.html">本文</a>表明，一个高概率随机初始化的神经网络包含一个与训练数据拟合良好且泛化能力良好的子网络。具体来说，如果我们随机初始化一个神经网络，然后使用只允许我们将权重设置为0的训练方法，那么我们将找到一个相当好的网络。请注意，此结果与彩票纸上的结果不同。同样，足够大的<a href="https://en.wikipedia.org/wiki/Extreme_learning_machine">极限学习机</a>获得与正常训练的神经网络相似的性能这一事实也表明这可能是一个富有成效的攻击角度。</p><p>另一个有趣的问题可能是尝试准确量化有多少泛化行为是由不同来源决定的。例如，在数据增强的效果与我们通过更改优化器或更改网络架构获得的效果相当之前，我们需要进行多少数据增强？ ETC。</p><h2><br>我认为 SLT 可以做什么</h2><p>话虽这么说，我认为有很多与泛化和归纳偏差相关的问题，我认为 SLT 可能会有所帮助。例如，基于参数函数图的研究似乎很难在<i>相移</i>问题上找到一个好的角度。此外，SLT 是分析这些问题的框架的一个很好的候选者。因此，如果 SLT 能够很好地解释诸如双下降或摸索等现象，我不会感到惊讶。</p><p></p><h2>结束语</h2><p>总而言之，我认为目前 SLT 的重要性有些被夸大了。我不认为 SLT 会提供“深度学习的统一理论”之类的东西，具体来说，我不认为它能够以令人满意的方式解释泛化或归纳偏差。我仍然认为 SLT 可以帮助解决一些问题，但我认为它的意义更限于某些特定问题。<br><br>如果这篇文章有任何重要错误，请在评论中告诉我。</p><br/><br/> <a href="https://www.lesswrong.com/posts/ALJYj4PpkqyseL7kZ/my-criticism-of-singular-learning-theory#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/ALJYj4PpkqyseL7kZ/my-criticism-of-singular-learning-theory<guid ispermalink="false"> ALJYj4PpkqyseL7kZ</guid><dc:creator><![CDATA[Joar Skalse]]></dc:creator><pubDate> Sun, 19 Nov 2023 15:19:20 GMT</pubDate> </item><item><title><![CDATA[“Why can’t you just turn it off?”]]></title><description><![CDATA[Published on November 19, 2023 2:46 PM GMT<br/><br/><p>如果你如此担心人工智能的风险，当你认为它会做一些危险的事情时，<strong>为什么不直接关闭人工智能呢</strong>？</p><p>周五，包括 Ilya Sutskever 在内的 OpenAI 董事会成员决定解雇首席执行官 Sam Altman，以<strong>“阻止”</strong> OpenAI 向比人类更聪明的人工智能快速推进的步伐。</p><p>结果似乎是<strong>AI赢了</strong>。在奥特曼召集员工大规模离职后，董事会做出了让步。人工智能对那些更快开发它的人隐含着财富的承诺，人们非常关心金钱，而不是x风险的微小变化。当然，这只是一个例子，但它是人们希望从人工智能中获得<strong>本地化</strong>回报的模式的一部分——最近英国表示将<a href="https://www.ft.com/content/ecef269b-be57-4a52-8743-70da5b8d9a65">在“短期内”避免监管人工智能</a>，欧盟国家开始游说建立<a href="https://techcrunch.com/2023/11/16/mistral-eu-ai-act/">基础模型排除在监管之外</a>。</p><p>这就是为什么你不能直接将其关闭。人们<em>不想</em>将其关闭<sup class="footnote-ref"><a href="#fn-2WDumDvSGmhXRJHzq-1" id="fnref-2WDumDvSGmhXRJHzq-1">[1]</a></sup> 。 </p><hr><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn-2WDumDvSGmhXRJHzq-1" class="footnote-item"><p>有一个潜在的反驳意见认为，一旦人工智能非常危险，人们就会想要关闭它。但存在一个相互矛盾的限制，即如果当时关闭，也必须能够关闭。早期，人们可能不会认真对待威胁，而到了后期，他们可能会认真对待它，但无法将其关闭，因为人工智能太强大了。 <a href="#fnref-2WDumDvSGmhXRJHzq-1" class="footnote-backref">↩︎</a></p></li></ol></section><br/><br/><a href="https://www.lesswrong.com/posts/zfebKfhJhWFDh3nKh/why-can-t-you-just-turn-it-off#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/zfebKfhJhWFDh3nKh/why-can-t-y​​ou-just-turn-it-off<guid ispermalink="false"> zfebKfhJhWFDh3nKh</guid><dc:creator><![CDATA[Roko]]></dc:creator><pubDate> Sun, 19 Nov 2023 14:46:18 GMT</pubDate> </item><item><title><![CDATA[Spaciousness In Partner Dance: A Naturalism Demo]]></title><description><![CDATA[Published on November 19, 2023 7:00 AM GMT<br/><br/><h2>什么是自然主义演示？</h2><p>自然主义演示是对自然主义研究的描述。</p><p>如果您过去关注过<a href="https://agentyduck.blogspot.com/2014/09/what-its-like-to-notice-things.html">我</a><a href="https://www.lesswrong.com/s/zLib3j2Fdnnx3aP3F">关于</a><a href="https://www.lesswrong.com/tag/naturalism">自然主义</a>的<a href="https://www.lesswrong.com/s/evLkoqsbi79AnM5sz">著作</a>，您可能会注意到我的著作很少提及具体的例子。当你谈论一个漫长而复杂的方法论时，你应该从头到尾为它打下基础并用现实生活中的例子来说明它。明显地。</p><p>如果我做得更好的话，我就会那么做。但由于我的情况并不好，所以我现在将努力犯相反的错误一段时间：我将分享更多关于现实生活中的自然主义研究的细节，比任何人想要或需要的都要多。</p><p>理想情况下，自然主义演示强调学生的内部体验，展示他们工作中关键点的现象学和思维过程的细节。在我的演示中，我会经常参考我在<a href="https://www.lesswrong.com/s/zLib3j2Fdnnx3aP3F">《自然主义的具体细节》</a>中讨论的策略，以指出我的实际研究与我在其中描述的方法论的一致之处，以及它们与它的背离之处。</p><p>我将首先回顾一下我刚刚完成的一项简短的研究：对名为 zouk 的舞伴舞蹈中的特定技能的调查。</p><p></p><h2>如何与这篇文章相关</h2><p>（以及未来的自然主义演示。）</p><p>自然主义演示帖子本质上有点奇怪。</p><p>在这一期中，我将向您讲述我如何在舞伴舞蹈中学会空间感的故事。</p><p><strong>但是</strong>，无论是宽敞还是舞伴舞蹈都不是故事的重点。这个故事的重点是<i>我是如何学到的</i>。</p><p>当我谈论我的研究的对象级<i>内容</i>（实现、更新等）时，尽量不要太纠结于这个或那个短语的确切含义，尤其是当我引用日志时入口。我在笔记中随意乱扔一些文字，而我学到的东西无论如何都不是重点。</p><p>相反，试着跟上我调查的节奏。我想向你们展示实践过程是什么样子，感觉如何，以及我的思维在每个阶段是如何运作的。如果可以的话，稍微模糊你的眼睛，并触及更深的水流。</p><p>我将首先介绍这项特定研究的背景。然后我将根据自然主义的阶段来描述我的进展：</p><ol><li><a href="https://www.lesswrong.com/s/zLib3j2Fdnnx3aP3F/p/Gs6oMWEFsL4gGocBf">寻找支点经验</a>，</li><li><a href="https://www.lesswrong.com/s/zLib3j2Fdnnx3aP3F/p/pMduTNnhamWYn7KzC">吸引你的目光</a>，</li><li><a href="https://www.lesswrong.com/s/zLib3j2Fdnnx3aP3F/p/7oAENKMsud2qQBXDj">集合</a>, 和</li><li><a href="https://www.lesswrong.com/s/zLib3j2Fdnnx3aP3F/p/gg4q9QS7tfEhX7hyK">实验</a>。</li></ol><p>将会有我的日志条目的摘录，其中穿插着对各种元级别的讨论。我将从介绍舞伴开始，如果您是舞者，可以跳过。</p><h2></h2><h2>祖克是什么？</h2><p>我喜欢一种叫做“ <a href="https://www.youtube.com/watch?v=xRZXIuQeBzA">zouk</a> ”的巴西街舞<span class="footnote-reference" role="doc-noteref" id="fnrefbp83q8xndps"><sup><a href="#fnbp83q8xndps">[1]</a></sup></span> 。</p><p>像祖克舞这样的方言舞是即兴表演的。成对的舞者共同演绎音乐，配对中存在传统的分工，这使得舞蹈感觉很像音乐中的<a href="https://en.wikipedia.org/wiki/Call_and_response_(music)">呼唤和回应</a>。领舞者通常发起动作，跟随舞者维持动作或以其他方式回应动作。 （以下是旋转的。）</p><p>舞伴之间的沟通比我认为非舞者想象的要机械得多。与人们的预期相比，它不像发送哑剧语言信号来暗示编舞片段，而更像是杂耍或拳击。跟随者的肌肉中保持着音调模式，从而创建了一个“<a href="https://youtu.be/upAIYoPZxfw?si=7vSXgE8yj9XHJASF&amp;t=7">框架</a>”；然后，主唱会物理性地按压跟随者身体的某些部分，从而改变音调模式，最终使跟随者在舞池中移动。 <span class="footnote-reference" role="doc-noteref" id="fnrefo3k19s4lmxf"><sup><a href="#fno3k19s4lmxf">[2]</a></sup></span></p><p>我一直专注于学习 zouk 中的主角，但我也跟着学习。我认为我在这两个角色中都被很好地描述为“中级”舞者。</p><p>上周末（周四晚上至周一早上），我去了<a href="https://www.flowmosaic.com/zoukretreat">祖克静修处</a>。这基本上是一个舞蹈大会，由著名的 zouk 教练举办讲习班，还有持续到深夜的社交舞。 （“社交舞”是指在工作坊或课程结构之外只是为了娱乐而跳舞。“社交”是真正的舞蹈发生的地方。）</p><p>我在大学里参加过不少舞蹈大会，当时我迷上了东海岸摇摆舞，所以我大致知道会发生什么：很多人，漫长的日子，密集的学习，很少的休息时间，身体疼痛，睡眠匮乏、音乐、可能的水泡、疲惫、情绪的过山车，以及可能是我一生中最好的舞蹈。</p><p>对我来说，这感觉有点像被从平凡的存在中提升出来，扔进一个巨大的搅拌机，然后突然又吐出来。我常常会对舞蹈（也许还有生活）产生新的看法。</p><p>我通常试图通过选择一个具体的教育目标来从这些旋风般的经历中获取长期价值。这就是我如何在这次静修中仅用四天时间就完成了整个以舞蹈为中心的自然主义研究。</p><h2></h2><h2><a href="https://www.lesswrong.com/s/zLib3j2Fdnnx3aP3F/p/Gs6oMWEFsL4gGocBf">定位支点体验</a></h2><p>我把我的定位称为教育<i>目标</i>，但我并不认为“在这次静修中，我将掌握内转”之类的东西。自然主义研究很少能如此清晰地开始。该工具集是为更加模糊的情况而设计的。如果您<i>确切地</i>知道自己想要获得什么技能，那么您已经完成了大部分工作。</p><p>我一开始的目的与其说是一个目标，不如<i>说</i>是一种挥之不去的不满，一种对我的舞蹈方式的某种渴望……不知何故与众不同。</p><p>第一天下午我出去散步，思考着这种不满。我试着尝尝它的味道，就像让一块黑巧克力在我的舌头上慢慢融化一样。</p><p>不满足的滋味是什么？</p><p>我回想起最近跳舞的记忆， <span class="footnote-reference" role="doc-noteref" id="fnrefp39znlvnksp"><sup><a href="#fnp39znlvnksp">[3]</a></sup></span> ，发现当我想到“时机”时，这种感觉最强烈。有点像被<i>催促</i>的味道。就像在机场通过安检时，当你试图脱掉鞋子并将笔记本电脑同时放入小手提包中时，而不会阻碍身后疲惫不堪的人们。</p><p>有时，当我领唱时，我会听到音乐中一些有趣的东西，并想要对此做出回应——轻快的人声即兴演奏，令人兴奋的切分音——但我做不到，因为我<i>被困</i>在节奏中了。我不可避免地受到 zouk 基本节奏的<i>BOOM 小鸡小鸡、BOOM 小鸡小鸡</i>的驱使。所以我只是不假思索地将熟悉的动作模式串在一起。对我来说事情进展得太快了。已经没有留下艺术的余地了。</p><p>不知何故，我想在跳舞时延长时间。</p><p>周四晚餐前做了一些笔记，我写道：</p><blockquote><p>关键数据可能存放在哪里？</p><p>当我感到有压力要移动时，感觉很陌生，这不是来自节奏，不是来自与音乐或我的伴侣的联系。在恐慌或混乱的时刻，我“只需要填补空间”。但大多数情况下我不确定。</p><p>引导我的问题：是什么阻止我通过时间来表达音乐？当我以其他方式做出时间决定时，我倾向于做什么？这里有哪些力量在起作用？沉浸在音乐中或不沉浸在音乐中是什么感觉？我感兴趣的是“时间”，还是真正的形状是别的东西？</p></blockquote><h2></h2><h2><a href="https://www.lesswrong.com/s/zLib3j2Fdnnx3aP3F/p/pMduTNnhamWYn7KzC">引起我的注意</a></h2><p>那天晚上的社交舞提供了一些很好的观察机会。</p><p>我压力很大，不知所措，试图适应在这个新地方和所有这些人在一起。我跳得不好。</p><p>我跳舞就像被节奏困住了一样。就像我必须继续前进，让我的伙伴们进入不断运动的华丽组合。我感到<i>疯狂</i>。</p><p>在我睡觉前的笔记中，我写道：</p><blockquote><p>现在是凌晨 1 点，我只跳了两支舞就提前离开了舞会。但我确实感受到了相关的事情。我认为当歌曲的速度快于我的舒适度时，放慢速度并找到空间尤其困难。感觉就像“走走走”，但没有空间容纳元科。并不是说“metacog”是我期望“寻找空间”最终发展的方式。</p></blockquote><p>请注意，在这次现场工作之后我使用的术语与一开始使用的术语不同。我现在谈论的不仅仅是“时间”，而是寻找“空间”。我用来引导舞蹈的概念已经在自我重塑。我的笔记继续：</p><blockquote><p>不断地“无意识地”将动作串在一起是什么感觉？快、有压力、“没有空间”、“被困”、“没有时间思考”。</p><p>我能感觉到它正在发生，也能感觉到我自己不喜欢它。我当时对此进行了反思，比如：“就是这样。我不知道该怎么办，但我知道我身处其中。”</p></blockquote><hr><p>在自然主义研究中，寻找经验的<i>维度</i>（通常以定义一条线的两点的形式）通常是有价值的。有时会有你所识别的体验，也会有与该体验相反的体验，比如热和冷。了解<i>冷</i>不仅可以帮助您了解<i>热</i>，还可以帮助您了解一般<i>温度</i>。</p><p>周五，有一门关于<a href="https://www.youtube.com/watch?v=f5aJ17X2LIY">孤立和微动作的</a>课程，最终产生的数据使我对舞蹈体验的一个维度敏感。当专注于微观时，我<i>很少</i>在领导时感受到疯狂的压力。相反，我体验到了……<i>其他的东西</i>，感觉很像相反的东西。</p><p>以下是我在晚餐时写下的一些反思的摘录。</p><blockquote><p>我<i>喜欢</i>微。即使我在努力寻找新东西时也是如此。为什么？</p><p> ...</p><p>微动作大多发生在基本祖克节奏的背景之外。我感觉摆脱了步法的结构，摆脱了打出悲观节奏或在任何特定时间表上解决运动路径的压力。 “慢慢来”很容易。有什么更好的手柄？或许，随着精神的感动而行动。于槽中移动，随槽而动。 “摆脱模式”实际上比任何这些都更能引起共鸣。我不觉得自己被任何事情束缚住了。</p><p> ...</p><p>当我“慢慢来”做我想学习的事情时，到底感觉如何？即使只是纯粹的微观。</p><p>是不是有一种等待的感觉？不，等待意味着期待。我认为未来与此无关。</p><p>嗯，也许这才是关键。未来不涉及。</p><p>我从来没有将“存在”视为“当下”，但我认为这就是正在发生的事情。事实上，我<i>确实</i>着眼于未来，因为我正在构建的结构参考了我对音乐模式的期望。但这……与我不做这件事时的未来导向不同。就好像我对未来的感知<i>来自于</i>现在。当我“陷入”“试图打击悲观情绪”或其他什么的时候，就好像我对现在的看法来自未来。</p></blockquote><p>我此时已经注视着这一点。关键的经历在前台，事情已经开始发生与我的主题相关的变化。我反思性地熟悉了我不想拥有的那种舞蹈的现象学（匆忙/受困/无意识），也熟悉了我希望学习的那种舞蹈的现象学（宽敞/当下）。是时候开始收集我学会如何观察的经验了。</p><h2></h2><h2><a href="https://www.lesswrong.com/s/zLib3j2Fdnnx3aP3F/p/7oAENKMsud2qQBXDj">收藏</a></h2><p>一旦我的眼睛睁开，我就开始使用几乎所有的经历作为观察时间/空间/存在的镜头。</p><h3></h3><h3>支点在不同背景下的经验</h3><p>我发现自己在如何度过静修期间做出了更加深思熟虑的决定。我注意到当我即将在预定的活动中感到“被困和游离”时，我会积极寻找机会为我当时想要或需要的任何东西创造空间。</p><p>例如，我离开校园去吃午饭，而不是在嘈杂拥挤的自助餐厅里吃饭，在那里我无法进行真正的交谈。课程开始后不久，我感到不知所措，于是我放弃了课程，并决定邀请某人和我一起品尝巧克力。 （我知道我之前用“品尝巧克力”作为比喻，但这次我是字面意思）。 <span class="footnote-reference" role="doc-noteref" id="fnrefy6oo6iy00w"><sup><a href="#fny6oo6iy00w">[4]</a></sup></span>当其他人都在吃晚饭时，我洗了个澡，在房间里一边吃着一顿饭，一边读着诗歌。</p><p>对于参加舞蹈会议的人来说，这些选择并不罕见。我的观点并不是说我采取了异常良好的外部行动。我的观点是，我使用了舞蹈之外的许多决定作为镜头来研究舞蹈中的时间和空间。</p><hr><p> “学习”在什么意义上？ “在别人吃饭的时候洗澡”与学习对音乐做出更广泛的反应有什么关系？</p><p>博物学家研究的收集阶段涉及<i>缩小</i>范围，以了解某种体验如何在您可能遇到的所有更大的模式中出现。在挖掘少量经验以获取您可以感知的所有细节后，下一步是训练自己注意支点经验的每一个实例，无论它何时、何地或如何发生。</p><p>时间压力的体验、面对压倒性的约束而“盲目地”行动的体验，或者寻找避免这些陷阱的方法的体验，不仅仅存在于舞池中。当我真的宁愿一个人呆着时，在日程表上读“晚餐”的<i>感觉</i>与当我真的宁愿站着不动时，快节奏推动我的脚步向前的感觉非常相似。</p><p>提高你对<i>所有</i>环境中重要体验的认识是我的方法论的一个标志，原因有两个。</p><p>首先，如果我进行划分——如果我试图注意到舞池上的时间压力而不是舞池外的时间压力——即使<i>在</i>舞蹈的背景下，我的意识可能也不会足够快地反应来捕捉每一个实例。感知层次如此低，没有时间进行划分。所讨论的感觉比我对自己所处的情况的更广泛的理解更小、更快。如果我想在目标环境中激活对支点体验的反思意识，我需要将这种敏感性深深地植入我的脑海中我的意识在体验出现的<i>每一个</i>环境中都会激活。</p><p>其次，每种情况都是从不同角度看待事物的独特机会。当我考虑是否去参加预定的晚餐时，我会看到我以前可能没有注意到的支点体验的一面，<i>即使它</i>确实以这种形式出现在舞蹈中。通过收集广泛的相关经验，我学会从前面、后面、颠倒或从里到外认识我的支点经验。</p><h3></h3><h3>头部运动</h3><p>我最终在一种被称为“头部运动”的 zouk 技术中大量关注“时间和空间”的事情。我将详细讨论这一点，这将变得非常技术性。<strong>如果您没有心情观看自闭症舞蹈极客的信息转储，请随意跳过整个部分</strong>。真的。没关系。</p><p>祖克舞与其他舞伴舞的区别之一是它具有所谓的“头部运动”。虽然是这么称呼，但实际上更多的是关于上躯干的倾斜。</p><p>在双人舞中，领舞者会做很多事情来引导跟随者的重心。这是一种过于简单化和高度机械化的方式，但我认为最准确的方式是思考什么<i>是</i>领先：引导追随者的重心。</p><p>追随者接收并解释领导者的建议，包括何时将重心放在何处、以多快的速度朝哪个方向移动、应具有何种旋转能量，以及在某些情况下其中心应离地面多近；但大多数时候，有关跟随者动作的<i>其他</i>一切都取决于跟随者。领舞者很少需要单独跟踪跟随者的上躯干和臀部，因为两个舞者通常都处于或多或少普通的直立站立位置，肩膀垂直地叠在臀部上方，躯干作为一个整体移动。在林迪舞（我喜欢的另一种舞蹈）中，例外包括诸如花哨的双臂蹲和离轴空中转身等高级动作。</p><p>但在祖克舞中，离轴运动是舞蹈的常见部分。跟随者的胸腔通常不依赖于他们的臀部，向后、向前、向任一侧或两者之间的任何位置倾斜，而不是几乎总是直立跳舞，肩膀叠在臀部上方。因此，除了引导跟随者的重心之外，zouk 引线还跟踪并引导跟随者上躯干不断变化的倾斜度。</p><p> （想象一根弯曲的吸管。想象它在舞池上垂直滑动。现在想象一下上面的弯曲部分一直旋转。）</p><p>追随者经常通过额外弯曲颈部，有时翻转头发来强调这些倾斜的姿势，因此“头部运动”。但据我了解，尽管这种现象无处不在，但头部的东西本质上是可选的样式。</p><p>不管怎样，我最近才达到了一定的技能水平，可以开始在社交舞中融入头部运动，无论是作为主导还是作为跟随。</p><p>你们大家，“头部运动”真是令人迷幻。</p><p>通常，旋转或转身的一个重要部分是“<a href="https://www.youtube.com/watch?v=88bsYB9i6Mc">定点</a>”技术：在旋转时将目光尽可能长时间地固定在远处的静止点上。 （如果您是瑜伽士，您可能知道这为“drishti”。）定点可以为您在移动时提供一个稳定的参考点，帮助您保持平衡和控制。</p><p>但在 zouk 中，当涉及头部运动时，就没有这样的奢侈了。你无法找到一个稳定的点，因为在转弯过程中你的上躯干和头部可能会向任何方向倾斜，而且事实上倾斜的方向可能会<i>在转弯过程中发生</i>变化。你也可能被蒙住眼睛。 （如果您不是舞者，我从这一点中建议的要点是：您应该对<a href="https://youtu.be/uH3UmJ_YjP4?si=xAWhOlpc-OHgBpFH&amp;t=105">zouk 的平衡和控制</a>印象深刻。）</p><p>在学习跟随和引导头部运动后，“保持空间”对我来说意味着一些新的东西。</p><p>当你引导跟随者进行头部旋转运动时，他们正在<i>踏上旅程</i>。这有点像在州博览会上被绑在<a href="https://incredibleevents.com/product/gyroscope-ride/">人体陀螺仪</a>上。即使当我在没有引导的情况下独自练习头部运动时，我也感觉自己陷入了信任的堕落：相信我的脚会留在地面上，相信天空仍然“向上”，地板仍然“向上”当我完成后“下来”。</p><p>你知道在这一切发生的同时，追随者<i>不</i>想要什么吗？一个疯狂的、不接地气的、催促他们完成动作的领导者。</p><p>头部运动为舞蹈增加了全新的技术难度。对于作为领导者的我来说，额外的挑战可能会引发疯狂的、不切实际的能量。</p><p>然而，头部运动也是一个真正放慢速度的机会，可以表达我想要的任何时机：与较大的移动运动不同，它可以与步法节奏的任何关系发生。 （有点；如果你在旅行，关系中实际上有一些固定点，但也有很多自由。）你甚至可以完全停止跟随者的脚，<i>只</i>通过头部运动继续舞蹈。</p><p>因此，这个周末头部运动对我来说是一个丰富的数据来源。当引导头部运动时，很难<i>不让</i>自己陷入困境，因为我仍然觉得它势不可挡。当我失败时，这是一次特别戏剧性的失败，重要的是，无论我内心感觉如何，我都要耐心地帮助追随者轻轻地退出模式（否则他们的颈椎可能会处于危险之中）；但当我成功时，这是一次特别戏剧性的成功，我可以感受到令人难以置信的深度表达自由。</p><h3></h3><h3>赛车节奏</h3><p>周六晚上的舞会是“柠檬对柠檬水”的情况。</p><p>有一位现场艺术家第一次演奏祖克音乐。我喜欢她的音乐；它丝滑而愉悦，就像草莓甘纳许松露一样。但对于 zouk 来说，速度也很快，特别是对于像我这样的初级和中级舞者来说。</p><p>试图跟上，我感到恐慌。我只是不能走得那么快，还有时间思考。我听了越来越多的歌曲（或者自己在场边跳舞），等待一首我认为自己能应付的歌曲。但它从未到来。</p><p>最终，我找到了组织这次活动的舞蹈教练。我问她这组音乐会持续多长时间，并解释说我喜欢这些音乐，但我就是无法随着这些赛车 BPM 跳舞。</p><p>她告诉我我不必这样做。我是在转述，但我理解她的意思是这样的：“在音乐节奏较重的部分，做一些非常简单的动作，比如基本的到位动作，只需要几个小节。然后当你听到一些缓慢而流畅的声音时，暂停孤立、头部运动、身体滚动、慵懒的转身，并尽可能长时间地探索这些模式。”</p><p>她带领我进行了简短的演示。虽然我们随着快节奏的音乐跳舞得很慢，但感觉很美妙。这是完全有道理的。</p><p>我尝试听从她的建议。我深入了解了速度压力、我与节奏的关系以及放慢速度的细节。我用一半的时间跳了一整首歌（即音乐中每两个节拍跳一次）。我试图仅用基本的“基本步骤”（左右左，右左右）来制作真正的舞蹈乐句。我注意到与我一起跳舞的一位领舞很大程度上<i>忽略了</i>音乐的节奏，我对此有一些不舒服的感觉，但它在上下文中很有趣且有启发性。</p><p>有时候，我会发现一点真正的宽敞，<i>有点</i>像把时间拉长。更多时候，我找不到那个空间；但我每次都能看到自己没有找到它，而且很多时候我都能<i>在疯狂真正到来之前看到它的到来</i>。</p><h3></h3><h3>留出空间，腾出时间</h3><p>周日的一门课程是关于骨骼肌的紧张和放松模式，以及学习如何有效地移动，仅使用完成所需运动所需的张力。</p><p>课程的大部分内容基本上是一种按摩：一个伙伴仰面躺下，闭上眼睛，尽可能被动地放松，而另一个伙伴则主动（轻轻地）移动被动伙伴的四肢。主动伙伴的工作是感受在移动身体部位时遇到的阻力的微妙模式和变化，并以可能帮助被动伙伴更多地意识到关节周围肌肉的方式调整运动（例如通过摇晃）一只手臂，或保持不动几次呼吸）。</p><p>也许这听起来有点糟糕。不过，这是真的；这是信噪比的问题。能够准确放松不需要的肌肉的舞者拥有更灵敏的框架，因此在与舞伴的联系中拥有更大的表现力。</p><p>我有很强的身体意识和身体同理心，所以我很擅长这一点。我的伴侣也是如此。毕竟，这是一个充满舞伴的房间。</p><p>但在这个特殊的场合，我认为我在这项练习上比平时做得更好。因为我的眼睛注视着，并且我正在收集宽敞的体验，所以我认为自己正在为身体和思想公开交流创造空间和时间。对我来说，这是关于存在感，即当下的感觉：我觉得我正在围绕每个关节构建一小段时间，不需要在任何时间表上完成任何事情，并且意识可以自由地穿越每个细节气泡内的感觉和冲动。</p><p>当我聆听伴侣关节周围的紧张模式时，我感觉我们都脱离了时间。</p><h3></h3><h3>拥抱和存在</h3><p>周日，在静修的最后一场社交活动之前，我上了最后一堂课。它从拥抱课程开始。</p><p> （这实际上是静修的<i>第二堂</i>拥抱课。我现在很擅长拥抱了。 <span class="footnote-reference" role="doc-noteref" id="fnrefrjep31w8hei"><sup><a href="#fnrjep31w8hei">[5]</a></sup></span>当我回到家时，我丈夫说：“哇，那真是一个<i>很好</i>的拥抱。”）</p><p>班上一半的学生闭上眼睛，张开双臂，而班上其余的学生则从一个人走到另一个人，开始一系列 15 到 20 秒的拥抱。 （我进行了“四次同步呼吸”。）我们被鼓励拥抱“就像与亲人重聚一样”。中途，我们换了位置，拥抱者变成了拥抱者。</p><p>最后，一位教练提出了一个让我深受打击的观点：“你们中有多少人感到无聊？如果在练习过程中任何时候感到无聊，请举手。”</p><p>没有人举手。不是一个人。就我而言，我热爱每一刻。</p><p> “我演奏了五首完整的歌曲，”他说。 “五首歌，你们所做的只是拥抱。但你们没有一个人感到无聊。”</p><p> “让我的搭档无聊”绝对是我的主要恐惧之一，它助长了我的疯狂状态，在这种状态下，我盲目地把华丽的动作串在一起，没有时间呼吸或感觉。这是我进入那种状态时所经历的“压力”的主要来源。</p><p>无论你在做什么，与某人跳舞五首歌都是很长的时间。</p><p>但祖克舞主要是在<a href="https://www.youtube.com/watch?v=ZSzCaa8rl4A">亲密拥抱</a>中跳舞（基本上是“拥抱”）；它来自臀部和大腿以及来自双手的引导。因此，如果我可以站在那里拥抱整整五首歌，这足以让我们俩度过愉快的时光，那么显然我对某些事情的担心是错误的。</p><p>我不认为我的伴侣感到无聊有什么不对。我确信<i>可能</i>会感到无聊，因为我之前在关注时确实感到无聊。我认为我的担心是错误的，在于是什么<i>导致了</i>舞蹈中的无聊，以及如何防止它。</p><p>在我看来，复杂的大而快速的动作序列有可能<i>掩盖</i>舞伴舞蹈中的一种无聊和脱节。</p><p>这很像魔术中的误导：如果你旋转跟随的速度足够快，如果你真的让他们移动，他们可能会太忙而没有注意到你的连接是迟钝的，你的音乐性毫无意义。哎呀，如果你看着它们旋转，你自己可能都没有注意到那种死寂。</p><p>但还有另一种方法。这就是你与所爱之人重聚时的方式，也是我帮助我的伴侣了解她肌肉紧张模式时的方式，以及使头部运动成为如此美丽的创造性可能性的方式。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cgAaShQeuL53zzGsT/agu4gf9zbmtyimv7oebs" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cgAaShQeuL53zzGsT/mm6wwhi24qq9ouzkitf7 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cgAaShQeuL53zzGsT/zw2dgcdkmd6wqvml45ra 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cgAaShQeuL53zzGsT/pspd5slisabfc8lwprjd 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cgAaShQeuL53zzGsT/no1tph8zonhhgxcp49cx 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cgAaShQeuL53zzGsT/broxwj9docqul7sngtfb 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cgAaShQeuL53zzGsT/wkf385qxejagzmm5ml74 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cgAaShQeuL53zzGsT/joubqz1j15xvbokdynjg 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cgAaShQeuL53zzGsT/ogasq8hvyslebyfb3jbw 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cgAaShQeuL53zzGsT/etvsuaw8dd2t5kw2pqt3 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/cgAaShQeuL53zzGsT/d7vhuzbvyu5zlaf9x4wf 1024w"></figure><h2></h2><h2><a href="https://www.lesswrong.com/s/zLib3j2Fdnnx3aP3F/p/gg4q9QS7tfEhX7hyK">实验</a></h2><p>那天晚上我跳了一些我一生中最好的舞蹈。</p><p>说实话，这是我第一次真正<i>享受</i>领导的乐趣。</p><p>到那时，我几乎确信我只是不喜欢领导。 “我想我是个追随者，”我想，“就像有些人就是直率的人一样。”</p><p>我一直很享受学习领导的乐趣，但这种乐趣更多的是学习而不是跳舞。我的经历有点尽职尽责。我的动力来自于从各个角度欣赏舞蹈的愿望，以及对有趣挑战的热情。</p><p>但在周日晚上，我领导的次数多于跟随的次数，而且我真的很喜欢这样做。</p><p>与平时相比，我的舞蹈很有创意。我尝试过：每当我开始感到未来的压力向我袭来时，我就会尝试<i>其他事情</i>。我几乎一动不动地站着，充分利用最小的动作。当我<i>感动的</i>时候我就感动了。我尝试了一些我不确定的事情，一些我不知道持续时间的事情，这些事情可能会让我们处于不熟悉的位置，我不知道如何工作。</p><p>但我并不害怕那些陌生的情况。无论我们最终去往何处，我知道我<i>可以</i>慢慢来，感受一切，甚至站在那里拥抱我的伴侣，感受音乐并一起呼吸。</p><p>我打破了刺激和反应的链条，并用代理取代了我默认的、盲目的疯狂行动。</p><p>静修结束时我几乎没有新词汇，因为学习新动作并不是我的重点。我并没有炫耀任何华丽的步法。据我所知，我对熟悉模式的执行并不比以前干净。</p><p>然而，即使几周前才和我跳舞的人似乎也比以前<i>更</i>有趣。我也玩得很开心。</p><h2></h2><h2>舞蹈的节奏</h2><p>一开始我就说过，这个故事的重点不在于我学到了<i>什么</i>，而在于我<i>如何</i>学到它。我请你试着跟上我学习的节奏。</p><p>那么，节奏是怎样的呢？</p><hr><p>这是我描述它的一种方式。</p><p>我开始尝到一种向往的滋味。我沉浸在那种经历中，获得一种直觉，让它在我脑海中暗示想法和图像。</p><p>在这种感觉的引导下，我将目光转向了世界上我认为可能存在关键数据的地方。我做好了在重要时刻集中注意力的准备。</p><p>然后我将自己置于我认为相关的情境中，并仔细观察由此产生的经历。我让自己对我所关心的情况的感觉<i>敏感</i>。</p><p>一旦我变得敏感，我就拓宽了我的注意力。我把镜头拉远，去关注各种背景下的关键感觉。我像亲密朋友一样了解他们，直到他们完全到达之前我就认出了他们。</p><p>最后，我尝试了新的方法来回应我所研究的感觉。</p><p>或者，更简短的总结是：我使用<a href="https://www.lesswrong.com/s/evLkoqsbi79AnM5sz"><i>耐心和直接观察</i></a>的方法来理清我围绕舞蹈中问题的默认感知、思维和行为模式。</p><hr><p>对于那些仍然试图跟踪我在这项研究中学到的<i>东西</i>（而不仅仅是我是如何学到的）的人来说一句话：</p><p>如果你现在对我作为一名舞者到底学到了什么感到不清楚——那么，我并不感到惊讶。作为一名作家，我深表歉意，因为让读者感觉不清楚通常是不好的做法。我内心的一部分想<i>编造一个关于我所学到的故事</i>，一些清晰而有力的故事，目的是让别人觉得我们已经沟通过了。</p><p>事实是，<i>我</i>对我到底学到了什么没有一个可靠的概念。我认为<i>这很好</i>。</p><p>为什么？因为我一开始的不满已经解决了。以前作为一名舞者，我曾被一些事情阻碍过，但现在我不再这样了。 （或者至少，我被<i>不同的</i>事情阻碍了。）</p><p>根据我的经验，这种结果在自然主义研究中实际上很常见。有时就像是，“我对某事或其他事情感到困惑，然后我做了一些自然主义的事情，不知怎的，我似乎不再感到困惑了。我……真的不知道发生了什么。”</p><p> ˙\_(ツ)_/˙</p><p>我第一次与其他人分享一种我最终称之为“自然主义”的方法，是在一次 CFAR 座谈会上，我的标题是“如何在不知道问题是什么的情况下解决问题”。自然主义主要并不涉及操纵明确的模型。事实上，这主要是为了摆脱明确的模型，因此它们调节观察的能力较小。</p><p>无论我试图讲述什么故事，讲述到底发生了什么变化——慢慢来，保留空间，存在感，等等——我很清楚我学到了我需要学习的东西。</p><hr><p>作为自然主义的演示，我给这项研究打 B-。</p><p>我喜欢它异常清晰的特点：简短而简单。我直接线性地经历了这些阶段。我没有迷路或被困住。只有四天的时间，因此可以在一篇文章中写出大部分关键时刻。</p><p>我还喜欢它说明“耐心”并不总是意味着“长”，甚至“慢”。我认为人们认为自然主义必然是一个非常漫长的过程，需要大量时间进行专心观察和安静反思。有时确实是这样！一项研究需要三个月的时间是很常见的。</p><p>但一旦你掌握了它的窍门，它通常会很快。整个研究发生在我多年来经历过的最拥挤、快节奏、旋风般的长周末（包括我的婚礼和孩子的出生）。在那场飓风中，我无论如何都采用了这种耐心的方法，并且我学会了如何创造永恒存在的口袋。</p><p>相关类型的<a href="https://www.lesswrong.com/s/evLkoqsbi79AnM5sz/p/sAiHxHkQrsYsRpKFP">耐心</a>实际上与速度（或缺乏速度）无关；而是与速度有关。相反，它是关于坚韧、彻底和（最重要的是）抛开对解决方案的绝望。</p><p>我<i>不</i>喜欢这项研究的主要一点是，对我来说，我的文章似乎相当肤浅。</p><p>我想那是因为这项研究非常简单。事实上，我当时并没有考虑自然主义的各个阶段。我没有明确考虑任何技术或策略。我最接近的问题是问自己：“数据存放在哪里？”</p><p>此时此刻，自然主义已深入我的骨髓。大多数情况下，当我<i>遇到</i>困难时，我只会将全部注意力转向策略层面。其余的都是非常自动的。</p><p>因为这项研究不需要斗争（从方法论上来说），所以我能够“在后台”完成几乎所有的工作。例如，我究竟是如何能够认识到“未来向我冲来”的感觉，这种感觉往往<i>先于</i>我的舞蹈中无意识的疯狂？我不知道！我怀疑这大部分发生在周六晚上，但这就是我所知道的。我没有费心去有意识地捕捉到底发生了什么的信息。</p><p>下次我会分享一个不太顺利的学习。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fnbp83q8xndps"> <span class="footnote-back-link"><sup><strong><a href="#fnrefbp83q8xndps">^</a></strong></sup></span><div class="footnote-content"><p>请注意，本文中的许多链接都是视频，可能会自动播放。</p></div></li><li class="footnote-item" role="doc-endnote" id="fno3k19s4lmxf"> <span class="footnote-back-link"><sup><strong><a href="#fnrefo3k19s4lmxf">^</a></strong></sup></span><div class="footnote-content"><p>当你在伴侣关系中进步时，会产生某种钟摆效应。有时，实现更好的联系意味着比以往更加机械地进行领导，有时则意味着将领导视为一系列邀请。出于这个原因，我认为许多舞伴可能会对我的描述感到震惊，并想象我正在积极地抛掷我的跟随者。我保证我不是。我经常被形容为一个异常温和的领导者。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnp39znlvnksp"> <span class="footnote-back-link"><sup><strong><a href="#fnrefp39znlvnksp">^</a></strong></sup></span><div class="footnote-content"><p>我用这些记忆作为<a href="https://www.lesswrong.com/posts/Gs6oMWEFsL4gGocBf/locating-fulcrum-experiences#Guessing_Which_Observations_Will_Matter">参考经验</a>。参考体验是您可以在脑海中浏览的情况，用作生成有关数据所在位置的猜测的参考材料。</p></div></li><li class="footnote-item" role="doc-endnote" id="fny6oo6iy00w"> <span class="footnote-back-link"><sup><strong><a href="#fnrefy6oo6iy00w">^</a></strong></sup></span><div class="footnote-content"><p>完全离题，但是：当我想在大型活动中交朋友时，我发现带来一些活动与其他一两个人分享是一个很好的方法。品尝巧克力对此来说非常美妙，因为它很容易获得、令人愉快且亲密。我还可以将剩余的巧克力作为礼物送给我的新朋友，这样他们将来就会重新体验这种体验。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnrjep31w8hei"> <span class="footnote-back-link"><sup><strong><a href="#fnrefrjep31w8hei">^</a></strong></sup></span><div class="footnote-content"><p> “你有什么更好的拥抱技巧吗？”</p><p>是的，我愿意。<br><br>第一个是“在场”，这是一个<a href="https://www.lesswrong.com/posts/k9dsbn8LZ6tTesDS3/sazen">sazen</a> ，但也许这篇文章会对弄清楚如何做到这一点有所帮助。<br><br>二是“变得不怕碰”。你认为你不害怕触摸你拥抱的人吗？也许你是对的。<br><br>但也许你错了，所以让我们检查一下。当你拥抱他们时，问问自己理论上是否有可能让更多的身体接触。哪些部分不接触？<br><br>是那些性感的吗？你害怕你的臀部、大腿或生殖器吗？你害怕他们的吗？当我有乳房时，我注意到有些人只会从侧面拥抱我，或者<i>非常</i>小心地从前面拥抱我，显然是因为他们对触摸乳房感到不舒服。<br><br>我并不是说，“故意将性感的部分压在一起。”如果你在没有存在感和舒适感的情况下这样做，可能会感觉很糟糕。我也不会断言你的恐惧是否正确，或者你是否<i>应该</i>好好拥抱。我想说的是，如果你拥抱的方式主要是因为触摸带来的不适，而不是你和他们的身体的存在，那么你就不会通过拥抱获得太多的亲密感。<br><br>第三，如果你认为你已经完成了前两点，并且在后勤方面似乎仍然有点不对劲，请尝试将你的一只脚踩在他们的脚之间。当身体稍微偏移时，就可以靠近一点。舞伴紧密拥抱的舞蹈以这种方式稍微偏移，以获得最大的交流带宽。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/cgAaShQeuL53zzGsT/spaciousness-in-partner-dance-a-naturalism-demo#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/cgAaShQeuL53zzGsT/spaciousness-in-partner-dance-a-naturalism-demo<guid ispermalink="false"> CGAASHQEUL53zzGST</guid><dc:creator><![CDATA[LoganStrohl]]></dc:creator><pubDate> Sun, 19 Nov 2023 07:00:19 GMT</pubDate> </item><item><title><![CDATA[Altman firing retaliation incoming?]]></title><description><![CDATA[Published on November 19, 2023 12:10 AM GMT<br/><br/><p> “匿名消息人士”向记者坚称 OpenAI 员工正在计划一场“反政变”以恢复 Altman 的职位，有些人甚至声称计划推翻董事会。</p><p>这似乎是投资者甚至大型科技公司的一项策略，目的是创造一个自我实现的预言，以创建一个 OpenAI 员工联盟，而此前还没有这样的联盟。</p><p>这里发生的事情充满了权势人物的廉价而轻松的举动。值得注意的是，人工智能投资公司和大型科技公司在权力动态方面经验丰富、经验丰富，甚至有可能利用人工智能与用户数据的结合进行<a href="https://www.lesswrong.com/posts/F7sp7rQg3zfD4totA/helpful-examples-to-get-a-sense-of-modern-automated#:~:text=When%20Anthropic%20grabs,of%20human%20psychology.">充分的心理研究，以在非常规环境中运用大量的操纵能力</a>，这可能已经是远不如面对面的对话，但可能仍然仅限于通过社交媒体等数字环境进行操纵。</p><p>像微软这样的公司也与美国 Natsec 社区有联系，并且也存在来自那里的潜在风险（我对美国 Natsec 社区的模型是，他们可能仍然对人工智能安全感到困惑或不感兴趣，但可能根本不会对任何人工智能安全感到困惑或不感兴趣）更长，并且<a href="https://www.lesswrong.com/posts/jyAerr8txxhiKnxwA/5-reasons-why-governments-militaries-already-want-ai-for">可能对使用人工智能和人工智能行业促进现代信息战非常感兴趣和熟悉</a>）。随机投资者的反击似乎是目前最好的解释，我只是认为这值得一提；众所周知，像微软这样的公司是你最好不要惹的力量。</p><p>如果这种情况真的发生了，如果人工智能安全真的对人工智能行业产生了巨大的影响，那么了解这些事情就很重要了。</p><p>这些文章中的大多数都是付费的，所以我不得不将它们粘贴到与<a href="https://www.lesswrong.com/posts/eHFo7nwLYDzpuamRM/sam-altman-fired-from-openai">Altman 主要讨论帖子</a>不同的单独帖子中，而且似乎有各种各样的人在各种各样的地方应该尽快得到通知。</p><p></p><p> <a href="https://www.forbes.com/sites/alexkonrad/2023/11/18/openai-investors-scramble-to-reinstate-sam-altman-as-ceo/?sh=10fea87660da"><strong>福布斯：OpenAI 投资者计划在最后一刻与微软合作，恢复 Sam Altman 首席执行官职务</strong></a>（太平洋标准时间下午 2:50，付费）</p><blockquote><p> OpenAI 董事会以令人震惊的方式<a href="https://www.forbes.com/sites/davidjeans/2023/11/17/sam-altman-out-at-openai/?sh=6f3c03c54691">解雇了前首席执行官萨姆·奥尔特曼 (Sam Altman)</a> ，一天后，该公司的<a href="https://www.forbes.com/sites/alexkonrad/2023/11/17/openai-investors-blindsided-by-sam-altmans-firing/?sh=6aed1f6f3fc9">投资者</a>正在密谋如何让他复职，这将是一场更令人惊讶的反击。</p><p>四位消息人士告诉<i>《福布斯》</i> ，在 OpenAI 的营利性实体中持有职位的风险投资公司已讨论与微软和该公司的高级员工合作，以召回 Altman，尽管他已向一些人表示他打算创办一家新的初创公司。</p><p>目前尚不清楚这些公司是否能够施加足够的压力来完成这一举措，并以足够快的速度让奥特曼保持兴趣。</p><p>一位消息人士告诉<i>《福布斯》</i> ，该剧本很简单：让 OpenAI 的新管理层（在代理首席执行官 Mira Murati 和其余董事会的领导下）承认，由于高级研究人员的大规模反抗、扣留微软的云计算积分以及投资者的潜在诉讼。面对这样的组合，人们的想法是管理层必须接受奥特曼的回归，这可能会导致那些被认为推动奥特曼下台的人随后离职，其中包括联合创始人伊利亚·苏茨克韦尔(Ilya Sutskever)和董事会董事、Quora 首席执行官亚当·德安吉洛(Adam D&#39;Angelo)。</p><p>两位消息人士称，如果这一努力未能及时落实，Altman 和 OpenAI 前总裁格雷格·布罗克曼 (Greg Brockman) 将准备为一家新初创公司筹集资金。 “如果他们不能尽快解决这个问题，他们就会继续与 Newco 合作，”一位消息人士补充道。</p><p>截至发稿时，OpenAI 尚未回应置评请求。微软拒绝置评。</p><p>周六早些时候，《The Information》 <a href="https://www.theinformation.com/articles/openai-co-founder-altman-plans-new-venture?utm_campaign=OpenAI+Crisis+Update&amp;utm_content=2279&amp;utm_medium=email&amp;utm_source=cio&amp;utm_term=1650">报道</a>称 Altman 已经与投资者会面，为此类项目筹集资金。一位与奥特曼关系密切的消息人士表示，这两种选择仍然是可能的。 “我认为他确实想要最好的结果，”该人士表示。 “他不想看到生命被毁。”</p><p>任何恢复尝试的关键参与者都将是 OpenAI 的主要合作伙伴微软，该公司已向该公司注资 100 亿美元。据彭博社<a href="https://www.bloomberg.com/news/articles/2023-11-18/openai-altman-ouster-followed-debates-between-altman-board?sref=YK080Hgh#xj4y7vzkg">报道</a>，首席执行官萨蒂亚·纳德拉 (Satya Nadella) 对此次罢免感到惊讶和“愤怒”。根据 Semafor 的<a href="https://www.semafor.com/article/11/18/2023/openai-has-received-just-a-fraction-of-microsofts-10-billion-investment">报告</a>，微软仅向 OpenAI 发送了上述金额的一小部分。一位了解微软想法的消息人士表示，该公司希望看到关键合作伙伴的稳定性。</p><p> The Verge 周六<a href="https://www.theverge.com/2023/11/18/23967199/breaking-openai-board-in-discussions-with-sam-altman-to-return-as-ceo">报道</a>称，OpenAI 董事会正在讨论让 Altman 回归的事宜。目前尚不清楚此类讨论是否是投资者压力的直接结果。</p></blockquote><p> <a href="https://www.wsj.com/tech/openai-trying-to-get-sam-altman-back-4b728049?mod=hp_lead_pos1"><strong>华尔街日报：OpenAI 投资者在突然解雇后试图让 Sam Altman 重新担任首席执行官</strong></a>（太平洋标准时间下午 3:28，付费）</p><blockquote><p>知情人士称，OpenAI 的投资者正在努力召回 <a href="https://www.wsj.com/tech/sam-altman-departs-open-ai-mira-murati-interim-ceo-41f6d51e"><u>周五被罢免的首席执行官</u></a>萨姆·奥尔特曼 (Sam Altman)，这是 ChatGPT 背后的人工智能公司一系列快速发展的事件的最新进展。</p><p>知情人士称，奥特曼正在考虑回归，但已告诉投资者他想要一个新的董事会。知情人士称，他还讨论了创办一家公司，聘请前 OpenAI 员工，并正在这两种选择之间做出选择。</p><p>知情人士称，预计奥特曼将很快在这两种选择之间做出决定。 OpenAI 的主要股东，包括<a href="https://www.wsj.com/market-data/quotes/MSFT"><u>微软</u></a><u> </u>和风险投资公司 Thrive Capital 正在帮助协调恢复奥特曼的工作。微软向 OpenAI 投资了 130 亿美元，并且是其主要的财务支持者。 Thrive Capital是该公司第二大股东。</p><p>知情人士称，该公司的其他投资者也支持这些努力。</p><p>此次谈判正值 OpenAI 董事会突然决定与 Altman 分道扬镳，理由是他在沟通中缺乏坦诚，并降职其总裁兼联合创始人格雷格·布罗克曼 (Greg Brockman)，导致他辞职后，该公司陷入混乱。</p><p>奥特曼被解雇的确切原因尚不清楚。但据知情人士透露，几周来，OpenAI 商业产品的快速扩张引发了紧张局势，一些董事会成员认为这违反了公司开发安全人工智能的最初章程。</p></blockquote><p> <a href="https://www.theverge.com/2023/11/18/23967199/breaking-openai-board-in-discussions-with-sam-altman-to-return-as-ceo">The Verge：OpenAI 董事会正在与 Sam Altman 讨论重新担任首席执行官</a>（太平洋标准时间下午 2:44，非付费）</p><blockquote><p>据多位知情人士透露，OpenAI 董事会正在与 Sam Altman 讨论重返公司担任首席执行官的事宜。其中一位人士表示，奥特曼<a href="https://www.theverge.com/2023/11/17/23965982/openai-ceo-sam-altman-fired">周五在没有任何通知的情况下被董事会突然解雇</a>，他对回归感到“矛盾”，并希望进行重大的治理变革。</p><p> Altman 在被赶下台后仅一天就与公司进行了会谈，这表明 OpenAI 在没有他的情况下正处于自由落体状态。 OpenAI 总裁兼前董事会主席格雷格·布罗克曼 (Greg Brockman) 被解雇数小时后辞职，两人一直在与朋友和投资者讨论创办另一家公司的事宜。周五，一批高级研究人员<a href="https://www.theinformation.com/articles/three-senior-openai-researchers-resign-as-crisis-deepens?rc=k5vrz1">也辞职了</a>，接近 OpenAI 的人士表示，更多的离职人员正在酝酿之中。</p><p>奥特曼对于回归“矛盾”</p><p> OpenAI 最大的投资者微软在 Altman 被解雇后不久发表声明称，该公司“仍然致力于”与这家人工智能公司的合作关系。然而，OpenAI 的投资者没有收到提前警告，也没有机会对董事会罢免 Altman 的决定发表意见。作为公司的代言人和人工智能领域最杰出的代言人，在<a href="https://www.theverge.com/23610427/chatbots-chatgpt-new-bing-google-bard-conversational-ai">竞争对手竞相追赶空前</a>崛起的 ChatGPT 之际，他的下台让 OpenAI 的未来陷入不确定性。</p><p> OpenAI 的发言人没有回应有关 Altman 与董事会讨论回归的置评请求。微软发言人拒绝置评。</p><p> OpenAI 目前的董事会由首席科学家 Ilya Sutskever、Quora 首席执行官 Adam D&#39;Angelo、前 GeoSim Systems 首席执行官 Tasha McCauley 以及乔治城安全与新兴技术中心战略总监 Helen Toner 组成。与传统公司不同，董事会的任务不是最大化股东价值，而且他们都不持有 OpenAI 的股权。相反，他们宣称的使命是确保创建“广泛有益的”通用人工智能（AGI）。</p><p>据多个消息来源称，Sutskever 也是 OpenAI 的联合创始人并领导其研究人员，<a href="https://www.theverge.com/2023/11/17/23966446/what-happened-to-sam-altman-open-ai">他在本周罢免 Altman 的过程中发挥了重要作用</a>。消息人士称，他在政变中所扮演的角色表明公司研究部门和产品部门之间存在权力斗争</p></blockquote><br/><br/><a href="https://www.lesswrong.com/posts/TWvLLuRmRxNrrbcHg/altman-firing-retaliation-incoming#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/TWvLLuRmRxNrrbcHg/altman-firing-retaliation-incoming<guid ispermalink="false"> TWvLLuRmRxNrrbcHg</guid><dc:creator><![CDATA[trevor]]></dc:creator><pubDate> Sun, 19 Nov 2023 00:10:16 GMT</pubDate></item></channel></rss>