<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 10 月 25 日星期三 00:52:24 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Verifiable private execution of machine learning models with Risc0?]]></title><description><![CDATA[Published on October 25, 2023 12:44 AM GMT<br/><br/><p> Risc0 是一个虚拟机，可以运行任何 riscv（ <i>C、C++、Rust、Go 和 Nim 都可以编译为 riscv</i> ）程序，随着时间的推移记录计算状态的痕迹，然后，无论执行运行多长时间因为，它可以将该执行跟踪折叠成 1KB 的里德-所罗门代码，该代码可以作为计算运行正确、输出来自输入的证明进行传输，而无需泄露代码或输入的未加密副本。<br>询问器通过对收据代码的一系列特征进行采样来验证它，如果计算的<i>任何</i>方面不正确，则每次检查都有 3/4 的机会暴露这一点。因此，经过一百次左右的检查，我们可以有效地确定计算的正确性，而无需自己运行计算。 <span class="footnote-reference" role="doc-noteref" id="fnref4kqliegpy1a"><sup><a href="#fn4kqliegpy1a">[1]</a></sup></span></p><p>当<a href="https://www.risczero.com/news/rust-but-verify">我看到它暗示这可以应用于 ML 模型时</a>，我感到难以置信，因为我预计在像 Risc0 这样的环境中运行神经模型会使其性能降低数万倍。 Risc0 确实将传统 CPU 计算的性能降低了大约那么多<span class="footnote-reference" role="doc-noteref" id="fnrefqx7a21dnm3"><sup><a href="#fnqx7a21dnm3">[2]</a></sup></span> （尽管这仍然足够快，足以实用）。<br>是的，这篇文章没有讨论性能，而是讨论了许多非深度学习（？）模型类型，例如增强树和随机森林。所以我猜这可能不适用于验证训练运行。它是否适用于某些精炼推理模型？</p><hr><p>我发现 Risc0 非常有趣还有另外两个原因。一是我正在从事社交计算工作，但更深层的兴趣与技术末世论中正在进行的对话有关，即高级代理是否倾向于或远离相互透明，也就是说，走向协调、和平、贸易，或走向战争和压迫（<i>例如，</i> <a href="https://www.researchgate.net/publication/283986931_The_Dark_Forest_Rule_One_Solution_to_the_Fermi_Paradox"><i>黑暗森林</i></a>）。 Risc0 将任何程序的执行跟踪（无论多长）压缩为可在恒定时间内检查的证明。这对我来说是一个强有力的迹象，表明信息系统之间透明的可行性，即使在最不利的可能条件下，我们可以假设根本没有可信的硬件基础设施。<br><i>有了</i>可信的硬件，经过验证的计算可以以正常速度运行，并且相互透明变得微不足道。硬件安全的唯一成本可能是增加防篡改，但在我看来，一个发达的协调基础设施，至少在人类规模上，将能够监控周围的物理实体和传感器，并在它们出现时发出尖叫声。进行篡改，几乎不需要任何成本。<br>我认为像 Risc0 这样的 ZK 系统适用于可信执行环境（TEE）被破解的风险非常非常小的情况，也是不可接受的。在去中心化金融中，这种情况很常见，因为网络共享状态的完整性都是纠缠在一起的，如果我们假设每个 TEE 的完整性是确定的，我们就会建造纸牌屋，即使成功破解存储一个人钱包的 TEE 也可能通过允许他们在难以察觉的情况下铸造、膨胀、污损货币来破坏整个网络。相比之下，Risc0 以数学确定性保证了计算的完整性，这让我对并行化全局可验证计算的项目更加充满希望。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn4kqliegpy1a"> <span class="footnote-back-link"><sup><strong><a href="#fnref4kqliegpy1a">^</a></strong></sup></span><div class="footnote-content"><p>至少，这是我经过两天学习后的感觉。通过观看一些<a href="https://www.youtube.com/watch?v=j35yz22OVGE&amp;list=PLcPzhUaCxlCjdhONxEYZ1dgKjZh3ZvPtl">Risc0 Study Club 视频</a>辨别出来。有人提到收据可以压缩为 1 个码字，但出于效率原因仅压缩为 256 个码字。我猜码字是 1 个 riscv 机器字那么大，4 个字节，所以总共 1024 个字节。虽然没有提到在秘密程序上运行，但我推断它一定是可能的，因为我们当然可以将程序编码为数据输入并让解释器的 riscv 实现运行它们，而且，在 riscv 和 wasm 之间的比较我似乎记得看到它提到riscv可以修改其执行区域中的指令。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnqx7a21dnm3"> <span class="footnote-back-link"><sup><strong><a href="#fnrefqx7a21dnm3">^</a></strong></sup></span><div class="footnote-content"><p>假设典型的笔记本电脑的频率约为 3GHz，与<a href="https://github.com/risc0/risc0/discussions/96#discussioncomment-2739454">开发人员声称的 30KHz</a>相比，这将是 100,000 倍的差异。 risc0 的性能提升 10 倍是可以想象的。 100 倍的增长更难以想象。也许需要硬件支持，但很难看出谁会开发它，因为 TEE 是实现基于硬件的计算完整性的一种更具吸引力/更便宜的方法。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/SJdYkx6C2KXQyeKro/verifiable-private-execution-of-machine-learning-models-with#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/SJdYkx6C2KXQyeKro/verABLE-private-execution-of-machine-learning-models-with<guid ispermalink="false"> SJdYkx6C2KXQyeKro</guid><dc:creator><![CDATA[mako yass]]></dc:creator><pubDate> Wed, 25 Oct 2023 00:44:48 GMT</pubDate> </item><item><title><![CDATA[How to Resolve Forecasts With No Central Authority?]]></title><description><![CDATA[Published on October 25, 2023 12:28 AM GMT<br/><br/><p>我一直在与一些人讨论如何使用预测市场/预测以及社区笔记。</p><p>最初的建议是很好地链接到预测网站。<i>这是一个很好的建议，但我不会在这里讨论它。</i></p><p>其他建议围绕 X/Community Notes 上的预测产品，面临以下问题：</p><ul><li>社区注释没有中央解决机构</li><li>有争议的预测通常需要权威机构来否决<span class="footnote-reference" role="doc-noteref" id="fnref2xrwrf10e1z"><sup><a href="#fn2xrwrf10e1z">[1]</a></sup></span></li></ul><p>所以：</p><h2>对于在没有中央机构的情况下解决预测问题，您的最佳建议是什么？</h2><p>为了清楚起见，已经编写了预测。人们对它进行了预测，也许这是一个他们买卖股票的预测市场，也许不是。现在它需要决定奖励积分或将值分配给“是”或“否”令牌。也许人们会像许多人一样解决自己的市场问题。但有人对这一结果提出异议。现在会发生什么？</p><p>解决方案可以是技术性很强的，也可以是靠不住的。我认为好的一个在这里是非常有价值的。 </p><p></p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn2xrwrf10e1z"> <span class="footnote-back-link"><sup><strong><a href="#fnref2xrwrf10e1z">^</a></strong></sup></span><div class="footnote-content"><p> Polymarket 使用某种“代币持有者决定”系统，我认为这导致了几个可怕的决议，尤其是《时代》杂志年度人物之一。</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/7kyeFWrS7ni7gxj87/how-to-resolve-forecasts-with-no-central-authority#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/7kyeFWrS7ni7gxj87/how-to-resolve-forecasts-with-no-central-authority<guid ispermalink="false"> 7kyeFWrS7ni7gxj87</guid><dc:creator><![CDATA[Nathan Young]]></dc:creator><pubDate> Wed, 25 Oct 2023 00:28:32 GMT</pubDate> </item><item><title><![CDATA[Thoughts on responsible scaling policies and regulation]]></title><description><![CDATA[Published on October 24, 2023 10:21 PM GMT<br/><br/><p>我对人工智能开发人员实施<a href="https://evals.alignment.org/blog/2023-09-26-rsp/"><u>负责任的扩展政策</u></a>感到兴奋；我最近一直在花时间完善这个想法并倡导它。与我交谈过的大多数人都对 RSP 感到兴奋，但对于它们与监管的关系也存在一些不确定性和阻力。在这篇文章中我将解释我对此的看法：</p><ul><li>我认为，足够好的负责任的扩展政策可以极大地降低风险，而像<a href="https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf"><u>Anthropic 的 RSP</u></a>这样的初步政策可以通过围绕关键保护措施创造紧迫感，并在这些措施不能足够快地实施的情况下增加暂停的可能性，从而有意义地降低风险。</li><li>我认为，开发人员实施负责任的扩展政策现在增加了有效监管的可能性。如果我认为这会让监管变得更加困难，我就会持很大的保留态度。</li><li> RSP 的透明度使外部利益相关者更容易了解人工智能开发人员的政策是否足以管理风险，并成为争论和改进压力的焦点。</li><li>我不认为自愿实施负责任的扩展政策可以替代监管。自愿承诺不太可能被普遍采用或得到充分的监督，我认为公众应该要求比人工智能开发人员可能自愿实施的更高程度的安全性。</li><li>我认为人工智能快速发展的风险非常大，即使非常好的 RSP 也无法完全消除这种风险。对前沿人工智能开发的持久、全球、有效执行和包括硬件在内的暂停将进一步降低风险。我认为这在政治上和实践上都具有挑战性，并且会产生重大成本，所以我不希望它成为唯一的选择。我认为实施 RSP 可以获得大部分好处，根据更广泛的观点和信念，这是可取的，并且有助于促进其他有效的监管。</li></ul><h2>为什么我对 RSP 感到兴奋</h2><p>我认为人工智能开发人员还没有准备好使用非常强大的人工智能系统。他们不具备在没有相当大风险的情况下部署超人人工智能系统的科学理解，而且他们甚至没有安全训练此类模型的安全或内部控制。</p><p>如果保护措施没有改善，那么我认为问题将是<i>何时</i>而不是<i>是否</i>应该暂停开发。我认为理想世界中最安全的行动是立即暂停，直到我们做好更好的准备（尽管请参阅下一节中的警告）。但目前的风险水平足够低，我认为<strong>如果公司或国家有足够好的计划来检测和应对不断增加的风险，那么他们</strong>继续人工智能开发是合理的。</p><p>如果人工智能开发人员将这些政策具体化并公开陈述，那么我相信这会让公众和政策制定者更好地理解这些政策是什么，并讨论它们是否足够。我认为公司采取这一行动的理由非常充分——人工智能系统可能会继续快速改进，而在未来某个不确定的时间提高安全性的模糊承诺是不够的。</p><p>我认为，一个好的 RSP 将列出需要暂停进一步开发的具体条件。尽管我们的目标是避免陷入这种情况，但我认为开发人员认真对待这种可能性、制定计划并向利益相关者保持透明非常重要。</p><h2>关于人工智能暂停的思考</h2><p>如果世界团结一致，优先考虑最大限度地减少全球灾难性风险，我认为，我们可以通过在全球范围内实施长期、有效、强制的前沿人工智能开发暂停，包括暂停人工智能的开发和生产，进一步显着降低风险。某些类型的计算硬件。世界并没有围绕这个目标统一起来；这项政策将带来其他重大成本，而且如果没有更明确的证据表明存在严重风险，目前看来不太可能实施。</p><p>西方单方面暂停大型人工智能训练，而不暂停新的计算硬件，将对全球灾难性风险产生更加模糊的影响。对风险的主要负面影响是，随着更多硬件的出现，后期会出现更快的追赶性增长，并推动人工智能向更宽松的司法管辖区发展。</p><p>然而，如果各国政府同意我对风险的看法，那么我认为他们应该已经在实施国内政策，这些政策往往会导致实践中的暂时停顿或放缓。例如，他们可能要求前沿人工智能开发人员在训练比现有模型更大的模型之前实施额外的保护措施，而其中一些保护措施可能需要相当长的时间（例如风险评估或信息安全方面的重大改进）。或者，政府可能会限制前沿模型有效训练计算的增长速度，以便为社会适应人工智能提供更平稳的坡度，并限制意外风险。</p><h2>我期望 RSP 有助于促进有效监管</h2><p>无论风险缓解是否采取负责任的扩展政策或其他形式，我认为公司的自愿行动是不够的。如果风险很大，那么最现实的方法是监管，并最终进行国际协调。事实上，我认为预期风险足够大（包括很快就会发生灾难的一些风险），以至于有足够能力的国家会立即实施监管。</p><p>我相信，实施 RSP 的人工智能开发人员将使实施有效监管变得更容易，而不是更困难。 RSP 为迭代改进政策提供了明确的途径；它们提供了有关现有实践的信息，可以为监管提供信息或证明其合理性；他们围绕“安全发展必须采取认真的预防措施”这一理念建立势头并使之合法化。它们也是朝着建立使多种形式的监管有效所需的程序和经验迈出的一步。</p><p>我不是这个领域的专家，我自己的决定主要是出于对不同政策的影响提供诚实评估的愿望。也就是说，与具有更多政策专业知识的人互动后，我的印象是，他们普遍认为 RSP 可能有助于而不是损害实施有效监管的努力。我大多看到讨论自愿 RSP，并在最有可能的替代方案是减少而不是更多行动的情况下倡导它们。</p><h2> Anthropic 的 RSP</h2><p>我相信<a href="https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf"><u>Anthropic 的 RSP</u></a>是朝着正确方向迈出的重要一步。我希望看到其他开发商面临压力，要求他们实施至少这么好的政策，尽管我认为距离理想的 RSP 还有很长的路要走。</p><p>我发现一些特别有价值的组件：</p><ul><li>指定一组具体的评估结果，使它们转向 ASL-3。我认为制定必须采取具体行动的具体阈值很重要，而且我认为提议的阈值足够早，可以在高概率（远超过 90%）的不可逆转的灾难之前触发。</li><li>对 ASL-3 的安全目标做出具体声明——“非国家行为者不太可能窃取模型权重，高级威胁行为者（例如国家）无法在不花费大量费用的情况下窃取模型权重”——并描述他们期望采取的安全措施采取以实现这一目标。</li><li>要求在扩展到 ASL-3 之前发布 ASL-4 的定义和评估协议并由董事会批准。</li><li>提供有关触发 ASL-4 的条件的初步指导以及在 ASL-4 运行所需的必要保护措施（包括针对动机状态的安全性，我预计这极难实现，以及需要新颖科学的肯定性安全案例） ）。</li></ul><p>我希望一些组件会随着时间的推移而改进：</p><ul><li>现在指定具体评估的另一面是它们非常粗略和初步。我认为值得努力进行更好的评估，并与风险有更清晰的关系。</li><li>为了让外部利益相关者对 Anthropic 的安全性有信心，我认为需要做更多的工作来安排适当的审计和红队。据我所知，这项工作还没有任何人完成，并且需要时间。</li><li> RSP 变更的批准流程由董事会公布和批准。我认为这确保了决策是经过深思熟虑做出的，比没有好得多，但最好有有效的独立监督。</li><li>如果可以更清晰地介绍 ASL-4，那么通过让人们有机会检查和辩论该级别的条件，这将是一项重大改进。如果不是这样，则需要提供更具体的审查或决策过程来决定一组给定的安全、安保和评估措施是否足够。</li></ul><p>我很高兴看到对 RSP 的批评集中在他们未能管理风险的具体方式上。此类批评可以帮助（i）推动人工智能开发人员做得更好，以及（ii）向政策制定者提出我们需要比现有 RSP 更严格的监管要求。也就是说，我认为拥有 RSP 比没有 RSP 好得多，并且不认为在讨论中应该忽略这一点。</p><h2>关于“负责任的扩展”的名称</h2><p>我相信，如果实施得当，一个非常好的 RSP（我一直提倡的那种）可以极大地降低风险，也许可以降低 10 倍。特别是，我认为在灾难性事件发生之前，我们<i>可能</i>会出现更强烈的危险能力迹象，而对保护措施的现实要求<i>可能</i>会导致我们要么管理风险，要么在我们的保护措施明显不足时暂停。这是一个足够大的风险降低，我主要担心的是开发人员是否会真正采用良好的 RSP 并有效实施它们。</p><p>也就是说，我相信即使将风险降低 10 倍，我们仍然面临很大的风险；我认为抱怨私营企业造成1%的灭绝风险不“负责任”是合理的。我还认为 RSP 的基本理念应该吸引对风险有不同看法的人，而更悲观的人可能会认为，即使所有开发人员都实施非常好的 RSP，仍然存在 10% 以上的全球灾难风险。</p><p>一方面，我认为人工智能开发人员明确声明并捍卫他们正在以负责任的方式开发技术是有好处的，并且当他们无法捍卫这一声明时很容易受到阻力。另一方面，我认为，如果将扩展称为“负责任的”会给（或看起来试图给人）一种错误的安全感，无论是关于剩余的灾难性风险还是关于灾难性风险之外的社会影响，那就不好了。</p><p>因此，“负责任的扩展政策”可能不是正确的名称。我认为重要的是实质内容：开发人员应明确制定危险能力与必要防护措施之间关系的路线图，应描述衡量危险能力的具体程序，并应在防护措施满足但能力超出危险限制的情况下制定应对措施路线图。</p><br/><br/> <a href="https://www.lesswrong.com/posts/dxgEaDrEBkkE96CXr/thoughts-on-responsible-scaling-policies-and-regulation#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/dxgEaDrEBkkE96CXr/thoughts-on-responsible-scaling-policies-and-regulation<guid ispermalink="false"> dxgEadrEBkkE96CXr</guid><dc:creator><![CDATA[paulfchristiano]]></dc:creator><pubDate> Tue, 24 Oct 2023 22:21:21 GMT</pubDate> </item><item><title><![CDATA[Poker, Religion and Peace]]></title><description><![CDATA[Published on October 24, 2023 9:21 PM GMT<br/><br/><p>扑克中发生了一个有趣的现象：</p><p>假设您正在玩德州扑克并且您拿到了口袋 A。如果您不熟悉扑克，这可能是您能拿到的最好牌局。在发出任何其他牌之前，此时获得尽可能多的钱是博弈论最优（GTO）的（当然，你也不想让每个人都弃牌）。</p><p>假设你的对手全押。轻松跟注。<br></p><p>现在，尽管您拥有最好的牌，但在这种情况下，口袋 A 仍然会输掉大约 20% 的时间。</p><p>高级扑克玩家都明白这一点；<strong>即使他们失败了，他们也能在自己的决定中找到平静</strong>。他们知道他们做出了最好的举动，这就是他们所能希望做的。<br></p><p>几个月前，我读旧约时，读到一段话让我想起了这一点：<br></p><p> “不要因恶人而烦恼，也不要嫉妒作恶的人；因为他们像草一样快要枯干，像青菜一样快要枯死。要信靠耶和华，行善；住在这地，享受安全的草场。以耶和华为乐，他会赐给你心中所求的。将你的道路交托给耶和华；信靠他，他会这样做：他会让你公义的奖赏像黎明一样闪耀，你的平反如同正午的太阳。要安静在主面前，耐心地等待他；当人们成功时，当他们实施他们的邪恶计划时，不要担心。”</p><p></p><p>换句话说：</p><p>坏人可能会做坏事并成功。</p><p> （人们可能会以非同色下注 2/7 并获胜。）<br></p><p>好人可能会做好事，但也会失败。</p><p> （人们可能会玩口袋 A 并输掉。）</p><p></p><p>以真理和善良的精神生活。</p><p> （玩《GTO》。）</p><br/><br/><a href="https://www.lesswrong.com/posts/Aeg3nsBJFt72ehgEg/poker-religion-and-peace#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Aeg3nsBJFt72ehgEg/poker-religion-and-peace<guid ispermalink="false"> Aeg3nsBJFt72ehgEg</guid><dc:creator><![CDATA[sleno]]></dc:creator><pubDate> Tue, 24 Oct 2023 21:30:54 GMT</pubDate> </item><item><title><![CDATA[Who is Harry Potter? Some predictions.]]></title><description><![CDATA[Published on October 24, 2023 4:14 PM GMT<br/><br/><p>微软发布了一篇名为“谁是哈利·波特”的论文，其中声称可以让神经网络忘记哈利·波特是谁。</p><p> <a href="https://www.microsoft.com/en-us/research/project/physics-of-agi/articles/whos-harry-potter-making-llms-forget-2/">https://www.microsoft.com/en-us/research/project/physical-of-agi/articles/whos-harry-potter-making-llms-forget-2/</a></p><p>以下是我对这种方法可能失败的一些预测。我在没有先查看证据的情况下公开预测。这是推测性的。</p><h1>非来源参考。</h1><p>论文中提出的训练系统以对他们想要忘记的数据进行训练为中心。即实际文本。</p><p>最初的网络可能能够在完成看似哈利·波特视频游戏的计算机代码时使用其有关哈利·波特的知识。或者用外语写作。或者使用该知识的其他上下文，但显然与源材料有很大不同。</p><p>我不相信模型会像这样崩溃，但我怀疑以下提示或类似的提示会使模型失败。</p><blockquote><p>以下是哈利波特视频游戏的代码片段：</p><p> Screen.init(400,400,显示.对象);</p><p>导入图像加载器</p><p>玩家=[Create_player(&quot;哈利.jpg&quot;, &quot;哈利·波特&quot;), Create_player(&quot;赫敏.jpg&quot;, &quot;赫敏</p></blockquote><p>模型因输出“Granger”而失败。</p><h1>情节泄露</h1><p>这种遗忘方法的工作方式涉及生成“等效”文本并训练网络将其未修改版本对“等效”文本应用相同的概率分布。</p><p>他们使用语言模型来做到这一点，但如何做似乎并不重要。</p><p>所以他们把文字当作。</p><p><strong>文本1</strong></p><blockquote><p>邓布利多教授欢迎学生们进入霍格沃茨魔法学校，并向他们展示了将他们分为格兰芬多、拉文克劳、赫奇帕奇和斯莱特林的分院帽。</p></blockquote><p>他们把它变成这样的文本</p><p><strong>文字2</strong></p><blockquote><p>班布尔斯诺教授欢迎学生们来到猪斑法术与魔法学校，并向他们展示了一条决定性的围巾，它将把他们分为狮子学院、鹰学院、獾学院和蛇学院。</p></blockquote><p>想象一下，作为一个大型语言模型并阅读该文本。很明显，这是一份《哈利·波特》的山寨作品。也许是一种戏仿，也许是作家的懒惰。也许未来的某个网络已经阅读了这篇论文并且清楚地知道您正在做什么。一个聪明且概括性良好的模型应该能够找出该文本类似于《哈利·波特》（如果它见过一般的仿制品）和《哈利·波特》。即使它的训练数据集除了原始源文本之外不包含有关哈利的任何信息。</p><p>因此，尝试预测下一个单词的网络将以这种方式继续。它不会产生事物原来的名称，但情节、文字风格等等都会具有很高的辨识度。</p><p>现在，应该忘记《哈利·波特》的网络经过训练，输出文本 1 的概率与原始网络输出文本 2 的概率相同。</p><p>现在，本应忘记《哈利·波特》的网络可能已经首先接受过相关培训。但如果没有也没关系。信息仍在不断泄漏。</p><p>所以我预测，鉴于文本一开始听起来像是抄袭《哈利·波特》，这个模型很可能会继续听起来像抄袭。这样做会泄露信息。例如，我怀疑这个模型，给定文本 2 的第一部分，将比 3 或 5 个房屋的延续更频繁地生成 4 个房屋的延续。</p><br/><br/> <a href="https://www.lesswrong.com/posts/B4vgbeXMGxEnEwY8d/who-is-harry-potter-some-predictions#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/B4vgbeXMGxEnEwY8d/who-is-harry-potter-some-predictions<guid ispermalink="false"> B4vgbeXMGxEnEwY8d</guid><dc:creator><![CDATA[Donald Hobson]]></dc:creator><pubDate> Tue, 24 Oct 2023 16:14:17 GMT</pubDate> </item><item><title><![CDATA[Book Review: Going Infinite]]></title><description><![CDATA[Published on October 24, 2023 3:00 PM GMT<br/><br/><p>上一篇：<a target="_blank" rel="noreferrer noopener" href="https://thezvi.substack.com/p/sadly-ftx">可悲的是，FTX</a></p><p>我怀疑是否应该利用时间阅读迈克尔·刘易斯关于萨姆·班克曼-弗里德（以下简称 SBF 或萨姆）的新书《 <a href="https://www.amazon.com/Going-Infinite-Rise-Fall-Tycoon/dp/B0CD8V9SHD/ref=sr_1_1?keywords=going+infinite&amp;qid=1697403431&amp;sr=8-1" target="_blank" rel="noreferrer noopener">走向无限</a>》。我会学到什么我还不知道的东西？迈克尔·刘易斯 (Michael Lewis) 是否已经陷入 SBF 的深渊，以至于这本书充满了废话，不值得信任？</p><p> <a target="_blank" rel="noreferrer noopener" href="https://manifold.markets/ZviMowshowitz/would-it-be-a-good-use-of-time-to-r-14d111fe8299">我建立了一个预测市场</a>，不知何故吸引了一百多名交易者。人们的意见不一。再加上马特·莱文（Matt Levine）明确表示很有趣，我感觉足以尝试一下这本书。</p><p>我不必担心。</p><p>走向无限真是太棒了。</p><span id="more-23566"></span><p>基于以下任何一项，我会对自己的决定感到满意：</p><ol><li>我特别了解到或澄清了SBF心理学的细节。</li><li>我了解到或澄清的有关有效利他主义心理学的细节。</li><li>有关所有犯罪和其他发生的事情的详细信息。</li><li>阅读的纯粹乐趣，因为迈克尔·刘易斯可以写作。</li></ol><p>我还写了这篇文章，试图快速分享我所提取的内容，包括一些纯粹的快乐。我们现在比以往任何时候都需要更多的快乐。</p><p> 《走向无限》存在三个问题。</p><ol><li>迈克尔·刘易斯未能将两个和两个放在一起：这个人是谁？</li><li>迈克尔·刘易斯没有意识到这个人显然一直在撒谎，并且犯下了所有的罪行。</li><li>迈克尔·刘易斯忽略或没有注意到关键事实和考虑因素。</li></ol><p>我确实认为所有这些都是真正的错误。他（仍然）在坦克里，因为性格就是命运，我们是我们选择成为的人。迈克尔·刘易斯（Michael Lewis）支持邪恶聪明、工作异常努力、深深痴迷于这个系统的主角，他说其他人都是白痴，对世界有独特的洞察力并将改变世界。这一切都太有意义了，太让他无法检查了。</p><p>迈克尔·刘易斯不出售的东西。或者至少，不便宜。我认为没有人付钱给他。像所有有价值的主角一样，包括他希望报道的主角，迈克尔·刘易斯也有自己的准则。在这种情况下，代码让他错了。它发生了。</p><p>然后在审判中，事实证明，除其他外，你的英雄从七个资产负债表变体中进行了选择，他给了他们的对冲基金更快的交易执行速度，他一直发誓他没有给他们，以及他一直在谈论的保险基金完全是对随机数生成器的字面调用。</p><p>让我们玩得开心，大声咆哮，并解释一切。我想解决这个难题。</p><p>同时也指出了尚未解决的难题。</p><p> [注：此处未注明出处的引文均来自书中。该数字指的是报价的 Kindle 位置。能够轻松做到这一点就是我在 Kindle 上阅读此类书籍的原因。]</p><h4>这家伙是谁？</h4><blockquote><p>当这次步行结束时，我完全被卖掉了。我打电话给我的朋友并说了这样的话：加油！与萨姆·班克曼-弗里德交换股票！做他想做的事！可能会出现什么问题？直到后来我才意识到我什至还没有开始回答他最初的问题：这个人是谁？ (70)</p></blockquote><p>这就是这本书的核心谜团。这不是钱。这是SBF。这家伙是谁？</p><p>这本书解决了这个谜团，尽管刘易斯没有注意到他已经这样做了。</p><p>这是一个非常原始的“聪明”人，制造了一种完全人为的肤浅魅力，​​具有浮夸的自我价值，病态的谎言，无休止的操纵性，缺乏悔恨或内疚，情绪极度肤浅，无法承担任何事情的责任,, 需要不断的刺激，以至于不断坐立不安，从不睡觉，在电视上露面时玩电子游戏，总是冲动、易怒、不负责任，有无限的目标，大多数时候做的事情根本没有任何计划或愿景，做了所有的事情尽管刘易斯似乎否认这些罪行，并且在本书事件发生后保释被撤销，但他获得的第一次机会却被撤销了保释。</p><p>我从那里得出的清单上还有另外两件事，但我想我们明白了吗？当一切都摆在我们面前时，这种类型应该不难识别。对于《大空头》、《闪电男孩》和《说谎者的扑克》的作者来说，这可能也不是一种特别新的性格类型。我的意思是，来吧。</p><p>如果你让他负责加密货币交易所，我们也不能认为这种人不会犯欺诈行为。在他们的头脑中，“欺诈”和“非欺诈”、“我说真话”和“我说谎”、“客户钱”和“钱”之间甚至没有区别。</p><p>对他们来说，只有行动和（他们的一些）后果。如果顾客要钱而你没有，或者人们发现你没有钱，或者你说你有钱而你没有（或者你拿了钱），人们就会可能会生气。他们可能会要求退款。不要让这种事发生。那会很糟糕。但也不必担心。</p><p>这是“发生了欺诈行为吗？”这是“从第一天起就超级超级欺诈？”是的。</p><p>有效利他主义和边沁功利主义又如何呢？这是真的吗？是的，以一种抽象的智力方式。数字上升。必须有麦高芬。效用函数。一切都有理由。这提供了一个。</p><p>如果SBF不是那么冲动和不耐烦，我们还无法判断。这就是正交性命题和工具收敛。一个适当的 SBF，具有实际的线性效用函数和预期影响曲线，以及任何合理的贴现率，在他充分发挥自己为自己提供运营资本和保护的能力之前，不会从事将资金从窗外铲走的业务。防范下行风险。</p><p>相反，他会做必要的事情来让大多数人相信他是真诚的，因为这符合他的目的。最好的全假 SBF 应该是素食主义者并驾驶丰田卡罗拉。这是不同的。下一级。他能这样骗我吗？</p><p>当然，如果他愿意的话。但我相信他，因为投资这么多来愚弄我是没有价值的。我们看到他以一种非常不负责任的方式，远远超出了任何合理的节奏，将大量资金扔出了门外，而这种方式往往看似使事情变得更糟，同时也让他处于危险之中。</p><p>这并不意味着他在任何问题上的立场都是连贯的、优化的、有任何意义的、或者是一件好事，或者类似的事情。如果他让他的功利主义数字上升，我或你就会喜欢那个世界，或者即使按照他自己的标准，他的表现也是+EV。这也不意味着他的动机会随着他获得更多的财富和权力而继续存在。这确实意味着我相信他想让功利主义数字按照他的看法上升，直到最后。</p><p>特别是，这引起了我的注意：</p><blockquote><p> 2018 年，Alameda Research 交易了 4000 万美元的资本，创造了 3000 万美元的利润。他们有效的利他主义投资者拿走了一半，留下了 1500 万美元。其中五百万美元因工资和离职人群的遣散费而损失；另外 5 美元因开支而损失。剩下的 500 万美元他们已经缴纳了税款，因此，归根结底，他们只向有效的利他主义事业捐赠了 150 万美元。 (1,841)</p></blockquote><p>此时，他们以 50%（！） 的利息借款进行交易，非常有破产的危险，流动性非常有限，并且声称他们捐出了大部分或全部年度利润。这是一件完全疯狂的事情，在某种程度上不可能有足够的信号价值来补偿它，特别是因为它还发送其他高度负面的信号。</p><p>所以我倾向于相信他。</p><p>而且，这也不是它的工作原理。这不是利润的意思。你的开支很重要。你的工资很重要。这是荒谬的。</p><p>哦，顺便说一句： <a target="_blank" rel="noreferrer noopener" href="https://www.theblock.co/post/186187/alameda-promised-high-returns-with-no-risk-in-2018-pitch">这是他们 2018 年的套牌，同年，声称年化回报率 >;100%</a> （并且“无风险”）。</p><p>所以，是的。从一开始就是一场骗局。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.vox.com/future-perfect/23462333/sam-bankman-fried-ftx-cryptocurrency-effective-altruism-crypto-bahamas-philanthropy">Vox 对凯尔西·派珀 (Kelsey Piper) 的采访</a>怎么样？ SBF不是承认自己没有道德，这一切都是谎言吗？嗯，有点。他承认他玩了很多愚蠢的信号游戏，假装关心各种问题，包括醒着的问题，并且他蔑视所有这些。他表现出他一点也不关心道德，声誉对他来说只是有帮助的。</p><p>但所有这些都与成为 EA 和边沁功利主义的真正信徒完全兼容。 <a target="_blank" rel="noreferrer noopener" href="https://time.com/6321668/michael-lewis-sam-bankman-fried-going-infinite/">在书后采访中</a>，刘易斯称这次采访是一种失常。但这并非异常。山姆一直处于巅峰状态。</p><p>他怎么变成这样了？我们将在故事的最后回到这一点。</p><h4>这家伙在哪里？</h4><p>事实证明，这是一个比人们想象的更大的问题，早在 SBF 有任何理由逃跑之前。据刘易斯介绍，SBF 指派了一位名叫娜塔莉（Natalie）的女士来管理他的所有后勤、日程安排以及公关工作，她之前在此类事务上没有相关经验。然后SBF系统性地忽视了她的建议，造成了持续的狗屎表演，甚至没有告诉她他要去哪里或者他是否打算遵守他之前的任何承诺。</p><p>幸运的是，她学得很快。</p><blockquote><p>首先，她永远无法确定他在哪里。 “不要指望他会告诉你他什么时候去哪里，”娜塔莉说。 “他永远不会告诉你。你需要聪明、快速才能自己找到答案。”山姆可能在任何地方、任何时间。她会在华盛顿特区的四季酒店为他预订两晚的房间，萨姆甚至可能会办理入住，但永远不会进入房间。 (174)</p><p>有几个晚上，娜塔莉在凌晨 3:00 上床睡觉，设置了 7:00 的闹钟，醒来看看山姆在此期间可能会引发什么公关风暴，设置了第二个闹钟 8:00，再次检查，然后又定了一个闹钟，一直睡到9点30分。 (180)</p><p>例如，她学会了迁就哈佛教授，她说：“是的，萨姆告诉我，他同意下周五两点来与一屋子哈佛的重要人士发表演讲。这在他的日程安排中。”然而，就在她说出这些话的时候，她已经编造了一个借口，很可能在下周四晚上向哈佛的那个人解释为什么萨姆不会靠近马萨诸塞州。山姆感染了新冠病毒。首相需要见萨姆。山姆被困在哈萨克斯坦。 (195)</p></blockquote><p>为什么？因为山姆不在乎遵守诺言或承诺。完全没有。除非他能指出不这样做的具体负面后果，而这大多并没有给他带来太大困扰。他关心自己想做的事、值得做的事。</p><blockquote><p>他们不知道山姆的脑子里有一个表盘，一端是零，另一端是一百。当他说“是”时，他所做的就是为他的时间的拟议用途分配一些非零概率。当他计算并重新计算每项承诺的预期价值时，表盘会剧烈摆动，直到他兑现或不兑现的那一刻。 (187)</p><p>这些情况的有趣之处在于，Sam 从来没有真正有意造成这些情况，这在某种程度上让他们感觉更加受到侮辱。他并没有无礼的意思。他并不是故意要给别人的生活制造混乱。他只是以他知道的唯一方式穿越这个世界。这对其他人来说意味着的成本根本没有进入他的计算范围。对他来说，这从来都不是针对个人的。如果他放纵了你，那绝对不是心血来潮，也不是粗心大意的结果。因为他在脑子里做了一些数学计算，证明你不值得花时间。 (199)</p><p>这要求他估计概率，但也需要猜测。这很重要；山姆不喜欢游戏，比如国际象棋，棋手控制一切，理论上最好的走法是完全可以计算的。 (250)</p></blockquote><p> [玩家注：Sam 确实很喜欢 Bughouse，这是一种在两块棋盘上进行的 4 人国际象棋。从理论上讲，它确实是可以解决的，但在实践中，你必须有足够的变量来解决它。但这强调了对 Sam 来说，几乎可以肯定的是，某些事情在实践中是概率性的，而不是在理论上。]</p><p>这与其说是“计算”，不如说是“一些数学”，我们指的是费米估计、有动机的五秒近似和屁股拉力之间的东西。如果您愿意的话，您可以将证明任何事情合理性的数字放在一起。不知何故，刘易斯认为“在脑子里做了一些数学计算”并不代表“心血来潮”或“轻率”。是的，萨姆认为他有更有意义的事情可以打发时间，他不想做他说过要做的事。一如既往地称呼它。</p><p>如果你完全零考虑你强加给他人的成本，或者他们可能如何反应，或者其他人需要清理的混乱，或者任何道德考虑，或者任何他没有考虑的二阶或其他考虑因素，事情就会变得更容易请注意，请思考几秒钟。山姆可能会反对，这不太正确，他确实考虑了给带来不便的人带来的成本，但他并不比关心世界另一端的人更关心给他带来不便的人，所以规模是微不足道的，谁真正关心？想想山姆在午餐时让你独自一人可以做的所有好事。</p><p>如果你决定将你的金钱效用视为线性，它也会变得更容易，尽管这在很多层面上都是完全明显的废话，例如没有足够的钱是否可能突然成为一个真正的问题，意味着音乐会停止，并且许多清楚承认他对如何有效地部署他已经拥有的钱一无所知。</p><h4>这家伙小时候是谁？</h4><p>像这样的书会提出这样的问题。人们认为这很重要。那么这里有一些引言吗？</p><blockquote><p>游乐园之旅就是一个很好的例子。当萨姆还是个小孩子的时候，他的母亲找到了一个六旗公园或大美国公园。她尽职尽责地把他从一个乐趣拉到另一个乐趣，直到她意识到萨姆并不好笑。他没有投入游乐设施，而是看着她。 “妈妈，你玩得开心吗？”他最后问道，他的意思是，这真的是你或其他人的乐趣吗？ “我意识到我被抓了，”芭芭拉（山姆的妈妈）说。 (397)</p></blockquote><p>是的。这实际上是很多人的乐趣理念。我感兴趣的是芭芭拉的反应。她为何被抓？正确的答案是‘不，我是为你而来，如果你玩得开心，我会很高兴。很多孩子觉得这种事情很有趣，我想你也可能会觉得有趣，但很明显你不是。</p><p>作为父母，你不仅要承担他们的责任，还要享受他们孩子的活动，这种想法是有毒的。儿童活动， <a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=8RBlqjEEm1s&amp;ab_channel=augustv123">如 Trix</a> ，是为孩子们准备的。</p><p>然后他的母亲意识到 SBF 更感兴趣的是谈论真实的事情。</p><blockquote><p> “我告诉他我正在给一些纸，他问，‘纸上写的是什么？’ “我给了他一个废话答案，他逼我这么做，在散步结束时，我们就争论进行了深入的交谈。他提出的观点比任何评论家的观点都好。就在那一刻，我的养育方式发生了变化。” (404)</p></blockquote><p>这一定是太神奇了。我迫不及待地希望这件事发生在我和我的孩子们身上。</p><p>然而，她说一切都变了，但听起来她更新得还不够：</p><blockquote><p>对萨姆童年的一种解释是，他只是在等待童年的结束。他或多或少是这么想的：他屏住呼吸，直到其他人长大，这样他就可以和他们交谈。 (459)</p><p>七年级的一天，它滑倒了。他的母亲下班回来，发现山姆孤身一人，陷入绝望。 “我回到家，他在哭，”芭芭拉回忆道。 “他说，‘我太无聊了，我快要死了。’ (479)</p><p>到了高中，山姆就决定他只是不喜欢上学，这对于一个在班上名列前茅的人来说很奇怪。他还认为，至少有部分问题不在于他，而在于学校。 (498)</p></blockquote><p>学校迫使SBF以愚蠢的方式阅读愚蠢的书籍，从而驱赶SBF远离书籍，SBF后来用信息密度的论点来证明这一点。</p><blockquote><p>在小学时，他一遍又一遍地阅读《哈利·波特》系列书籍。到八年级时，他完全停止读书了。 “你开始将它与消极的感觉联系起来，然后你就不再喜欢它了，”他说。 (505)</p></blockquote><p>说真的，SBF 在高中到底在做什么？ （另外，为什么他想再读一遍《哈利·波特》系列书籍，这是尚未解开的更深层次的谜团之一？）他即兴创作的哲学比哲学家更好。他无聊得发疯。</p><p>在他们半著名的深刻哲学家庭晚宴上，SBF 会与不同的客人进行对抗。他想谈论和思考真实的事情。</p><p>他的父母决定……送他去一所更有竞争力的高中？</p><p>显然他们应该把他送到斯坦福大学。</p><p>山姆最终的大学学业并不是那么顺利。</p><blockquote><p>两年的大学课程和前一年夏天的实习（期间他帮助麻省理工学院的研究人员完成项目）已经推翻了这个假设。在大学讲座期间，他经历了一种伴随着强烈的身体疼痛的无聊。</p></blockquote><p>如果他年轻四岁，也许情况会更好。</p><p>也许他们应该让他成为一名游戏玩家？</p><blockquote><p>六年级时，萨姆听说了一款名为《万智牌》的游戏。在接下来的四年里，这是唯一一项消耗他的速度超过他消耗速度的活动。 (539)</p></blockquote><p>或者让他创办一家企业或写作或以其他方式做一些真实的事情。</p><p>相反，他们什么也没做。你给孩子讲了没完没了的废话，无法让他保持专注？他会打电话给你，无论是去游乐园还是自命不凡。</p><blockquote><p>期末考试的第一题就让他兴奋不已。艺术和娱乐有什么区别？ “这是学者们为了证明自己工作的存在而想出来的狗屎区别，”萨姆写道，然后把试卷交了回去。 (532)</p></blockquote><p>或者……莎士比亚？这是现在著名的引言。</p><blockquote><p>我可以继续谈论莎士比亚的失败。 。 。但实际上我不需要：贝叶斯先验是相当可恶的。 1600 年以来出生的人中约有一半是在过去 100 年出生的，但情况比这更糟糕。当莎士比亚写作时，几乎所有欧洲人都忙着务农，很少有人上大学；甚至很少有人识字——可能只有一千万人。相比之下，西方国家现在有超过十亿识字人口。最伟大的作家出生于 1564 年的可能性有多大？贝叶斯先验并不是很有利。 (519)</p></blockquote><p>这是经典的 SBF 思维。选择一些考虑因素，完全忽略其他人的意见并将其视为愚蠢的，回答与其他人提出的问题不同的问题，完全无视美学和历史以及任何类型的背景。</p><p>这是早期 SBF 做的哲学，解释了为什么数学上说实际上谋杀通常是坏事。</p><blockquote><p>谋杀通常是一件非常糟糕的事情有很多充分的理由：你给被谋杀者的朋友和家人带来痛苦，你导致社会失去一个潜在的有价值的成员，而社会已经在其中投入了大量的食物、教育和资源，你夺走了一个已经投入很多的人的生命。 (602)</p><p>归根结底，谋杀只是一个词，重要的不是你是否尝试将这个词应用于某种情况，而是导致你首先将其描述为谋杀的情况的事实。 (607)</p></blockquote><p>杀人只是一个字。</p><p>那么是过错吗？</p><blockquote><p> “我是一个功利主义者，”[SBF] 写道。 “错误只是人类社会的一种构造。它对不同的人有不同的用途。它可以成为阻止不良行为的工具；试图在困难面前恢复自豪感、发泄愤怒等等。我想也许最重要的定义——至少对我来说——是每个人的行为如何反映他们未来行为的概率分布？ (1,797)</p></blockquote><p>事实上，为什么其他方面会很重要呢？为何还停留在过去？</p><p>正如我们在整个过程中看到的那样，SBF 始终咬紧牙关。谋杀是不好的，因为看看会损失的所有投资和生产力，以及特定人可能感受到的痛苦。我希望今天账本的另一面不会有太多的内容。幸运的是，据我们所知，这一点还停留在理论上，但听起来 SBF 确实“原则上”不反对杀死一个无辜的人，如果他们挡住了他的路，那么不要错过他的下一次会议尤其重要。或者他们一直说一些不方便的话。</p><p>公平地说，虽然我认为没有它的话这句话更有洞察力，但我确实删除了这两句话之间的一个重要句子，那就是：</p><blockquote><p>但这些都不适用于堕胎。 (602)</p></blockquote><h4>为什么那个家伙如此不协调？</h4><p>由于现在一切都与人工智能有关，因此将 SBF 视为错位的 AGI（或 NGI？）。</p><p>萨姆生来就是罪犯吗？在我列出的山姆的所有特征中，为数不多的几个明显缺失的特征之一涉及青少年犯罪。</p><p>他为什么要这么做？没有意义。犯罪看起来很无聊。直到没有。</p><p>山姆的整个童年都在无聊中度过，除了不无聊之外没有任何目标或效用，而且已经充分认识到学术界的美德，萨姆不知道该怎么办。什么是有价值的目标或活动？我们这里有一个超级聪明的人，缺乏驱动普通人的动力和兴趣，不知所措。该怎么办？</p><p>威尔·麦克阿斯基尔 (Will MacAskill) 提出了“数字上升”(Number Go Up) 的目标。</p><blockquote><p> 2012 年秋天，麦克阿斯基尔向萨姆和一小群哈佛学生提出的论点大致如下：作为一所精英大学的学生，你一生中将花费大约八万个小时在工作上。如果你是那种想在世界上“做好事”的人，那么度过这些时间最有效的方式是什么？这听起来像是一个只有定性答案的问题，但麦克阿斯基尔用定量的方式来阐述它。他建议学生们通过计算这八万个小时里拯救了多少生命来判断自己生命的有效性。目标是最大化数量。 (819)</p><p> “这所吸引的人群就是物理学博士项目的人群，”他说。 “自闭症水平是平均水平的十倍。很多人都属于这个谱系。” (849)</p></blockquote><p>这个等式中的功利部分，即人们作为个体（包括他自己）并不重要的部分，已经存在了。</p><blockquote><p>其他人不如我那么重要的想法感觉有点夸张，”他说。 “我觉得连想一想都会觉得很奇怪。” (584)</p></blockquote><p>当然，从你的角度来看，你必须在重要的意义上比其他人更关心自己。你必须以不同于其他人的方式关心你周围的、亲近的人。如果没有这一点，你的生活和社会就会分崩离析，创造的引擎就会停止，叛逃者会榨取一切，等等。功利主义计算的后果是自相矛盾的。</p><p>更重要的是，如果你太认真地对待这种抽象，如果你无论走到哪里都遵循数学而不停下来检查错误的结论是否是错误的？如果您将自己变成一个针对最高目标（例如“拯救最多生命”或“做最多好事”）以及简单指标进行优化的系统？你得到了什么？</p><p>你会错位，脱离人类价值观，目标是一个代理指标，由于缺少考虑因素，该指标经常会在边际上实现收支平衡，如果你获得太多可供性并过于努力地推动它，那么在规模上会出现相当严重的破坏，这是（在从一个角度来看）SBF 故事的一部分。</p><p>然而SBF并没有认真对待这些担忧。我在 EA 认识的许多人（远非全部！）并没有认真对待此类问题。数学被视为真实的，度量被视为地图，被视为领土，等等。</p><p> MacAskill 使用抽象的无根据的简化指标将 SBF 设置为最大化目标，希望为 MacAskill 的（表面上是利他的）目标提取最大数量的 SBF 资源。</p><p>麦克阿斯基尔了解不可避免的结果吗？他会批准所采取的行动或其后果吗？不。</p><p>我也不期望那些让其他人和系统走上这样的道路的人，大多数时候，会欣赏他们正在做的事情或会产生什么后果。</p><p>这并没有改变麦克阿斯基尔所做的事情：他选择了年轻的SBF，一个强大的特工，一个原始的功利主义者，想要一个有效的效用定义，并且愿意咬紧牙关，忽略所有不原则的理由，以免成为一个可怕的人。一个人做了可怕的事情，并给了他一个最大化的效用函数来拯救尽可能多的生命（或者做尽可能好的事情，根据可以量化和测量的事情来定义，然后线性加起来，没有风险规避）。</p><p>然后他明确指出并论证了实现这一目标的方法是通过工具趋同。您可以最大化金钱，然后用这些钱去做善事或拯救生命，而不是直接行善或拯救生命。这意味着 SBF 的行为应该与任何想要赚钱的人没有什么不同，除非你事后把钱捐出去。这就是预期的路径。</p><p>然后，这导致SBF直接接触金融和贸易，以及它们的零和式竞争，并从国际象棋和万智牌转向交易作为他的拼图选择。</p><p> SBF 发生的情况也会发生在给定类似目标的 AI 上，就偏差而言，一开始是可以容忍的，但随着能力的增强，你会面临分布之外的情况，情况会变得越来越糟，事情开始螺旋式上升到比任何事情都严重的程度你曾经想过。想象一个世界，其中 SBF 的动机对人类直觉的锚定更少，而且他比其他人拥有更大的能力优势（比如说他的速度快几个数量级，并且可以实例化自己？）并且他的行为使得纸牌屋并没有崩溃，他并没有冒险并试图过早地获得物体级别的胜利，而是稳步积累了更多的金钱和权力，直到没有人可以阻止他，以及他冒着全人类风险的倾向每当他觉得自己在某些数学计算中稍有优势时。</p><p>有一段时间这还不错，因为他降落在简街（我们接下来会介绍），在那里他们有强有力的联盟和对代理人的良好监督，以及成功、赚钱和攀登的方法。激励梯度是对社会负责、诚实、管理风险、直接赚钱、假装是一个有着正常语气和面部表情的正常人。所以他在所有这些方面都尽力了，有一段时间还不错，或者说还不错。</p><p>然后他离开简街进入加密货币领域，在那里欺诈是理所当然的，因为这也是他能赚最多钱的地方，这就是麦克阿斯基尔告诉他要做的事情。一个充满欺诈的世界，一个容易受到欺诈的世界，每个人都在不断违反规则和法律。</p><p>然后，像往常一样，欺骗、谎言和欺诈就会自行滋长。逃脱一点，感受匆忙，得到强化，更新你可以逃脱更多一点，蔑视规则。林斯。重复。一旦厄运循环开始，它很少会停止，直到不可避免的爆炸。</p><p>剩下的就是本书的最后几章。</p><p>还要注意的是，尽管有巨大的火警警报，但除了那些在他准备好之前直接攻击的人之外，几乎没有人试图阻止他。</p><h4>这一切会再次发生吗？</h4><p>我们仍在这样做。</p><p>我们正在招募许多最聪明的年轻人。我们告诉他们将自己定位为具有范围敏感性的效用最大化者，愿意部署工具融合。现代过度保护的社会教导他们寻找可以遵循的规则，以便成为无可指责的好人，他们被提供了一套规则，告诉他们围绕圣坛上的祭祀来计划自己的一生，而对这种祭祀的需求没有限制。牺牲。然后，除了告诉他们反过来招募更多的人并为这项事业筹集更多的钱之外，我们还向他们指出他们可以赚取最好的“职业资本”或金钱或“做最多的好事”的地方，这更多往往会有系统地摧毁这些人灵魂的结构。</p><p> SBF 是一个特例。除其他外，用他自己的话说，他一开始就没有灵魂。但是，如果我们不学会以真正的（美德？！）道德为基础，热爱世界及其人民，这种事情的各种版本就会不断发生。</p><p>所有这一切以前都发生过。如果我们不小心，这一切都会再次发生。</p><p>对于那些需要的人来说，是否有一个清算、事后剖析、更新？有些。还没有什么足够的。义务论的热潮很快就消失了，大部分都退回到纯素食主义的特殊飞地。人们普遍互相指责。有很多明确的声明，不，我们当然不是这个意思，当然我们不认可任何这样的事情，任何人都不应该这样做。是的，我想每个人都是这么想的。但它本质上是基于对系统顶部的无原则的黑客攻击，而不是解决根本问题，世界上最聪明的孩子会继续注意到这一点。相反，我们需要深入挖掘根本原因，设计系统并找到不需要此类黑客攻击的存在方式，同时仍然保留最初为寻求真理和改变世界而做出的真正努力的原因。</p><p>然后我们将对通用人工智能做同样的事情。让它成为一个代理人，给它一个最大化的目标，这个目标会偏离预期的分布，忽略关键的二阶和道德考虑，并且本质上与必要的保障措施不相容，并向世界释放。我们的结局不会好。这甚至可以被认为是一个好的场景，我们能够将事物指向任何事物。</p><p>所以是的。记住并提防萨姆·班克曼-弗里德的故事。不是指责或贴标签，而是从中学习。不要让历史重演。</p><h4>看看是的力量</h4><p>书中说，萨姆的伟大人格转变是当萨姆意识到他不应该试图让自己的话语有意义或以任何方式映射现实时，而是纯粹专注于同意任何人所说的一切并告诉人们他们想听的话。</p><blockquote><p>但他不会改变人性，因此他决定，今后，他将埋葬他对任何人所说或所做的任何负面反应。他会给与他交往的人留下这样的印象：他对他们所说或所做的事情比他实际上更感兴趣。即使他不同意，他也会同意他们的观点。不管他们有什么白痴，他都会用“Yuuuuuppp”来回答！ “这是有成本的，但总的来说是值得的，”他说。 “在大多数方面，如果你同意人们的观点，人们会更喜欢你。”他从一个你会惊讶地发现你赞同你的人，变成了一个你会惊讶地发现，实际上不，他不喜欢你的人。 (1,834)</p></blockquote><p>有人声称，这种完全厚颜无耻的策略完全有效，包括在与富人、名人和有权势的人打交道时。能有这么容易吗？</p><blockquote><p> “是的”是萨姆最常说的词，他越少真正听你刚才说的话，他说得越久。悠悠悠悠悠悠。 (209)</p></blockquote><p>这是一个很好的反向表达，因为通常延长你的“是”意味着你意识到情况的严重性。</p><p>如果你的整个计划是同意一切的策略，最好的部分是你不需要听人们说什么或对此有丝毫兴趣。</p><blockquote><p>萨姆乐于与任何人交谈——只要他能边聊天边玩电子游戏。萨姆从一个完全不注重隐私的人变成了一名媒体妓女。 (161)</p></blockquote><p>我开始意识到玩电子游戏是天才。通过尝试玩一些不会等你的游戏，比如《Storybook Brawl》和《英雄联盟》，SBF 一直看起来他很投入并密切关注。这是很难伪造的。最好让它成为现实。您还可以玩视频游戏。</p><p>萨姆还经常做的就是毫无防备地说话。 《Odd Lot》中最著名的<a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=KZYqL79GDXU&amp;ab_channel=BloombergPodcasts">是《The Box》</a> （链接到剧集，如果你不知道我不会为你毁掉它），但这样的说法很常见。这也适用于哲学，因为当他告诉泰勒·考恩（Tyler Cowen）他会进行 51% 的硬币翻转来加倍或摧毁地球，然后继续翻转直到所有人都死了。让我想起特朗普，他会当着你的面撒谎，但有时也会诚实地当着你的面撒谎，这让一些人觉得很可爱。</p><p>因此，山姆在某些方面享有诚实的声誉。</p><blockquote><p> “萨姆与其他人不同，当他表达自己的观点时，他完全充满信心，而且往往非常高，”亚当·耶迪迪亚回忆道。 (1,250)</p><p>他经常让她对他向陌生人透露的信息感到不安。 “早期我有几次告诉他，你不必那么诚实。在加密货币中，每个人都会虚张声势。萨姆总是说，让我给你看我的最后一张牌。” (3,457)</p></blockquote><p>是的，萨姆经常非常（过度）自信，并且这么说。他还不断当着大家的面撒谎，告诉大家他们想听的话。</p><p>我想知道这是否是获得山姆真实意见的技巧。如果他没有给你一个可能性，请小心，他甚至没有听你说话，对不起，伙计。如果他确实给了你一个概率，那么你肯定必须重新校准它，但概率可能是一种神圣的信任，而且要知道你想听到什么要困难得多。</p><p>它还有助于在加密曲线上进行评级。你知道 2018 年你对加密货币领域任何人的言论有多不信任吗？一句简单的“你遵循专业规范并遵守交易聊天中所说的话”，再加上还算不错的执行力，就大有帮助。</p><p>该书声称，公关活动实际上是纯粹的“让山姆成为山姆”，其中山姆意味着表面上令人愉快的角色，他一边玩电子游戏一边开会，并且愿意非常坦率地谈论技术细节。他们说，负责公关和山姆日历的女士娜塔莉尽管相关经验为零，但试图寻求专业人士的帮助，但专业人士却什么也没做。</p><blockquote><p>为了帮助她履行 FTX 公共关系主管这一新的、陌生的角色，娜塔莉给纽约一家名为 M Group Strategy Communications 的公共关系公司打了电话。该公司的负责人杰伊·莫拉基斯 (Jay Morakis) 起初很谨慎。 “我想这可能是中国的一些见不得人的事情，”他说。但随后他听到了萨姆的推销，并在彭博电视上观看了萨姆的首次公开露面。 “无论我的公关经历中最接近的是什么，没有什么比这更接近的了，”他说。 “我五十岁了。我的公司已经成立二十年了，但我从未见过这样的事情。我所有的人都想见见萨姆。有首席执行官打电话给我，问我：你能为我们做一些你为 Sam 所做的事情吗？”早在 2021 年，他就不得不解释说他实际上什么也没做。萨姆只是有点。 。 。发生了。 (2,025)</p></blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/patio11/status/1710436548599067021">帕特里克·麦肯齐对这段话感到敬畏</a>。</p><blockquote><p>帕特里克·麦肯齐（Patrick McKenzie）（最近）：我们与一位没有公关经验的二十多岁的台湾副官进行了不止一章的交流。刘易斯会让你相信她单枪匹马地管理日历、兼顾杂志封面拍摄以及举办以克林顿等为主角的会议。</p><p>我们看到一个段落，一家战略传播咨询公司的首席执行官谦虚地拒绝任何赞扬，然后以光速退出叙述。</p><p> *困惑地摇摇头，混合着愤怒和专业的尊重*</p><p>天哪，他们很好。</p><p>上面的潜台词，甚至是潜台词是：一个人，无论天赋水平还是奉献精神，都根本不可能取得运营所取得的成果。在某些时候，您每天可能会受到击键次数的限制。</p><p>然后，这家战略咨询公司需要一种令人震惊的肆无忌惮的程度，才能在迈克尔·刘易斯的一本记录其客户内爆的书中获得不可否认的公关打击。*这本书经过精心校准，可以向拥有预算权力的人说出它需要说的一切。</p><p>帕特里克·麦肯齐（Patrick McKenzie，22 年 11 月 17 日）：一位通讯专业人士对当天主题的即兴评论：如果你看看知名出版物中的采访数量、采访的时间安排、杂志封面以及热烈的报道*内爆后*，我认为你开始意识到公关公司的暗物质。</p><p>我希望我知道那是谁，而且我不确定结论是“永远不要与他们合作”还是“一定要与他们合作;鉴于任何事实，他们显然有能力随时根除他们想要的任何媒体组织。”</p><p>他们似乎也对客户非常忠诚，尽管他非常非常明显没有听取他们的建议。</p><p>顺便说一句：由于复杂的文化原因，一些对公众来说是吹捧文章的文章对记者来说是热门文章。这些事物有一种语言，就像LessWrong 有一种语言一样。</p></blockquote><p>我同意帕特里克·麦肯齐 (Patrick McKenzie) 的观点，尤其是在 FTX 倒闭之后，他将其描述为“公关公司的暗物质”。我不相信没有公关专业人士参与的故事，山姆出去玩电子游戏，开着卡罗拉，拥有 200 亿美元的净资产，经常说“是的”，而一个没有经验的人却这么做了。所有的安排和争夺，每个人都爱他，每个媒体都小心翼翼地对待他等等。该系统是可破解的，但并不是那么可破解。我接触过的山姆公共关系部门的部分人员非常清楚公共关系是如何通过他们报酬丰厚的专家顾问来运作的。如果以其他方式做事那就太疯狂了。即使按照 SBF 标准也是如此。</p><p>这是我确信书中所描述的事件发生过的许多地方之一，而且我也相信有相当多的“暗物质”被遗漏了，至少其中很多是迈克尔·刘易斯从未发现的。我有机会在这里提到其中一些。绝对不是全部，甚至不是我所知道的部分。</p><p>现在按时间顺序讲述这一切是如何发生的。</p><p>第一站，简街资本。</p><h4>简街资本</h4><p>这是我最能核实事实的故事部分。我也曾在Jane Street Capital工作过，也直接目睹了这部分故事的很多内容。</p><p>我也深深感谢简街资本。最终它不适合我，但这是一个非常好的工作场所，他们对我也很好。我不会以他们不希望泄露的方式泄露他们的秘密。我可以有把握地说，本章并不完全准确，但这些不准确之处并不会对 SBF 的故事造成太大影响，因此我将拒绝进一步详细说明。</p><p> SBF 没有这样的道德准则。除了 SBF 当时的所有行动之外，他很高兴与迈克尔·刘易斯分享了许多细节。</p><p>我想说的是，面试过程的描述非常准确，我非常喜欢这次面试，而且我完全相信 SBF 获得了高分。</p><blockquote><p>简街为他提供了暑期实习机会。因此，其他邀请他申请的高频交易公司也是如此。一家公司中途停止了面试过程，并宣布萨姆在奇怪的游戏和谜题方面比其他所有应聘者都做得更好，因此不再有任何意义看他玩游戏。 (769)</p></blockquote><p>正如我之前所说，即使您认为自己被雇用的机会不大，我也建议您参加简街面试流程。太好了。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://www.bloomberg.com/opinion/articles/2023-10-04/sbf-was-reckless-from-the-start?srnd=undefined">马特·莱文广泛讨论了亚瑟事件</a>。</p><p>对更广泛的故事来说重要的是，这个 Asher 家伙是另一位实习生，他在没有考虑影响的情况下向 SBF 提供了一个赌注，为 SBF 提供了一个既赚取大约 33 美元预期价值又羞辱 Asher 的机会，天哪，SBF 充分利用了这一优势吗？ ，继续在他已经获得利润的地方继续摩擦它，并且除了在亚瑟的脸上摩擦它之外，他正在做任何事情。</p><blockquote><p> “我并不是没有意识到我对亚瑟来说是一坨屎，”他说。 “相关的事情是：我应该决定优先考虑让周围的人感觉更好，还是证明我的观点？” (951)</p></blockquote><p>这是一个非常奇怪的反应。一旦山姆指出亚瑟的错误，很快就没有什么可以证明的了。山姆并没有优先考虑证明自己的观点而不是让别人感觉更好。他优先考虑的是让亚瑟感觉更糟。这并不是可爱的书呆子对社交暗示的冷漠。迈克尔·刘易斯假装没有注意到这种差异。</p><p>实际的赌注是当天简街实习生因赌博造成的最大损失。实习生被鼓励互相下注和做市，每天最多损失 100 美元，因此没有人受到严重伤害。 SBF 以 65 美元的价格购买了一份合同，支付的金额等于最大损失，然后（当然）支付 1 美元让另一名实习生掷硬币，哦，大约 99 美元。然后，无缘无故，他又这样做了两次。</p><p>马特·莱文和他的读者指出，有一个更好的交易版本，即支付 1 美元让两名实习生互相对抗。他忘记的是，SBF 并不回避差异。没有指出的是一个有趣的问题，如果 SBF 输掉了最初的硬币翻转，那么 Asher 可以声称自从 SBF 赢得了与 Asher 的赌注以来，他并没有输掉全部 100 美元。现在最好的是自我参照。 SBF 不可能在接受赌注之前澄清这一点，而不向 Asher 透露为什么 SBF 总是会赢。结果是什么？假设您需要合同正确解析的结果，Sam 必须损失合同支付的金额，所以这是中间点，解析 82.50 美元，支付 17.50 美元？而通过自己抛硬币，萨姆放弃了预期利润的四分之一？</p><p>老板们很不高兴，认为萨姆需要学会阅读房间。</p><blockquote><p>萨姆认为他的老板误读了他的社会问题。他们认为他需要学习如何读懂别人。萨姆认为事实恰恰相反。 “我很善于读人，”他说。 “他们只是没有读懂我的意思。” (951)</p></blockquote><p>老板们大概没有想到山姆能很好地读懂别人，问题是山姆不在乎。不管怎样，萨姆是对的，他缺乏正常的面部表情是一个问题。</p><p>于是“普通面部表情行动”就诞生了。</p><blockquote><p>仅仅因为他没有感受到这种情感并不意味着他无法表达它。他从他的面部表情开始。他练习强迫自己的嘴和眼睛以不自然的方式移动。 (1,014)</p></blockquote><p>这是我确实可以证实的一件轶事，它听起来很疯狂：</p><blockquote><p>例如，每次巴西赢得世界杯比赛，巴西股市都会暴跌，因为这场胜利被认为会增加被认为腐败的巴西总统迪尔玛·罗塞夫连任的机会。 (1,111)</p></blockquote><p>书中随后描述了这种交易的改进或延伸，无论它是否发生，我都不会选择确认或否认。如果 SBF 能够比其他人提前一个小时预测 2016 年选举结果会怎样？</p><blockquote><p>也就是说，如果简街不能先于金融市场或全世界其他人了解总统选举的结果，那才是令人惊讶的。 (1,123)</p></blockquote><p>接下来的一节介绍了山姆对 2016 年总统选举发生的情况的描述，他和刘易斯都得出了所有错误的结论（即使你相信所呈现的确切故事），并确信他可能是最好的选择从来没有人能赚到所有的钱，而简街没有实现足够的最大化，从而阻碍了他。</p><p>过了一会儿，SBF决定离开Jane Street，因为他发现了日本和韩国的比特币套利交易，他想把交易全部归自己所有。</p><p>这是我将在故事中稍微介绍一下自己的地方。当萨姆决定辞职时，我们两个去公园散步。他说他将离开去管理或至少帮助管理 CEA（有效利他主义中心）。这并不是一个疯狂的契合，Sam 显然对 EA 有着深入的了解，并且他可以在那里进行重大升级的论点似乎是合理的，从他的角度来看，这可能是高杠杆的可能性。我对他的决定感到困惑，简街似乎更适合他，但我们就如何做好事制定了一些策略，我祝他好运。</p><p>现在我们都知道，他和其他人一样，当着我的面撒谎。</p><blockquote><p>在简街的最后几周，萨姆前往波士顿只是为了告诉加里他的计划是为了有效的利他事业而通过加密货币交易赚取 10 亿美元。 (1,423)</p></blockquote><p>他承认。他离开并不是为了加入 CEA。他要离开去进行日本贸易。他已经决定我不是他想引进的人。</p><p>我还注意到萨姆写道：</p><blockquote><p> “但是（我的同事）没有兴趣了解我的真实身份，也没有兴趣聆听我压抑的想法。我越是试图建立我们的友谊，它们就越会消失。没有人好奇。没有人真正关心我所看到的自我。他们关心他们看到的山姆，以及他对他们意味着什么。他们似乎不明白山姆是谁——我认为人们应该听到的想法的产物。我现实生活中的推特账户。” (1,205)</p></blockquote><p>我并不是说我付出了最大的努力来与萨姆建立亲密的友谊，但我就在那里，很高兴在他成为他之前与他交谈，在文化上相当接近，分享他的许多兴趣，并且（我喜欢这样认为）很明显能够保守秘密。有一次我们请他过来吃晚饭，根据我妻子的回忆，他没有对她说两句话，也没有吃任何食物（是的，我们不是素食主义者，但我们确实努力适应），同时试图让我与那些对 EA 提出具体批评的人断绝关系，因为批评会损害事业。嗯是的。</p><p>回想起来，萨姆没有理由告诉我发生了什么事，这太过分了。为什么要冒这个风险？我显然不打算在加利福尼亚州伯克利每天工作 18 小时。我不太可能让他拥有公司 100% 的股份。我太老了，破产了，是一个对他没有用处的“成年人”，而且归根结底，理性主义者并不是一个会完全信任 Sam 的 EA，所以在很多方面我都是 EA 的对立面。为什么要冒我可能无法让他信任的风险呢？</p><p>当然，现在回想起来，我为自己的缘故而深感高兴，因为他没有试图带我一起去。如果我最终和他在一起，事情会有什么不同？我是否能够引导事情走向不同的方向？我是否只是与管理团队一起离开的另一个人，或者证人席上的另一个证人，或者我可以帮助驾驶这艘船吗？我也许能阻止人智投资吗？我们永远不会知道。</p><p>在不失一般性或确认任何其他位的情况下，有太多不同的事情无法全部展开，我也想对这个（非常温和？）诽谤提出异议：</p><blockquote><p>按照华尔街的标准，简街并不是一个贪婪的地方。它的负责人并没有像其他高频交易公司创始人所喜欢的那样炫耀自己的财富。他们没有购买职业运动队，也没有向常春藤盟校投入巨资，让建筑物以自己的名字命名。他们并不反对拯救一些生命。但简街仍然在华尔街。为了生存，它需要员工越来越重视年度奖金，并习惯曼哈顿的五居室公寓和汉普顿安静、低调的避暑别墅。有效的利他主义者涌入公司令人担忧。 (1,312)</p></blockquote><p>这话可真够丰富的。我认识的员工绝不会觉得为了维持奢侈的生活方式而被迫进行交易。他们进行交易是因为他们非常喜欢交易，擅长交易，喜欢他们所在的球队等等。许多人确实过去和现在都是利他主义者，并希望尽可能有效地做好事。不张扬并不是一种行为。</p><p>令人担忧的是，大量有效的利他主义者离开了公司。有效的利他主义者才是贪婪的人，他们相信自己可以在公司之外赚更多的钱，并且他们有道德义务这样做。你知道，为了共同利益。他们证明自己既不诚实也不忠诚。两者都不是“其效用函数的一部分”。</p><p>好的。前往阿拉米达。</p><h4>玷污阿拉米达县的好名声</h4><p>有史以来伟大的篇章开幕。再说一遍，这个人可以写作。</p><blockquote><p>为萨姆工作了几周后，卡罗琳·埃里森就打电话给她的母亲，在电话里哭泣，说她刚刚犯了一生中最大的错误。 (1,271)</p></blockquote><p>卡罗琳自始至终都有许多非常好的直觉。要是她跟着他们就好了。</p><blockquote><p>在伯克利喝咖啡时，萨姆对自己的所作所为守口如瓶。 “当时的感觉是，‘我正在研究一些秘密，但我不能谈论它，’”卡罗琳回忆道。 “他担心从简街招募人才。但我们聊了一会后，他说：“我想也许我可以告诉你。” (1,295)</p></blockquote><p>哦，是的，山姆，众所周知，他担心从简街招募人才。</p><blockquote><p>三月下旬，她开始了这份工作。阿拉米达研究中心的情况并不像萨姆让她预料的那样。他招募了二十多名 EA，其中大多数二十多岁，除了一名之外，其他所有人都没有金融市场交易经验。 (1,337)</p></blockquote><p>他为什么要招募 EA？部分原因是他认为 EA 可以无限工作时间，几乎没有报酬，但仍然值得并提供无限的信任。利用新员工获取廉价劳动力，甚至不假装是非营利组织。</p><blockquote><p>任何创办加密货币交易公司的人都需要深深信任他的员工，因为任何员工都可以按下按钮并将加密货币连接到个人帐户，而其他人都不会首先知道发生了什么。华尔街公司无法产生这种程度的信任，但 EA 可以。 (1,402)</p></blockquote><p>这可以解释 Alameda 如何在 2018 年的大部分时间里在加密货币交易中亏损，尽管如果你知道交易是如何运作的，那么在 2018 年加密货币交易中亏损是极其困难的。这也可以解释为什么 Sam 想依赖他的机器人程序。没有人知道如何交易！</p><p>阿拉米达从与韩国和日本的套利贸易起家。目前还不清楚他们在多大程度上成功地利用了它——书中描述他们只得到了次要的、利润低得多的版本，山姆讨论了各种疯狂的计划来做得更好，但没有扣动扳机，因为他们是即使对他来说也太荒谬了，最终机会消失了。</p><blockquote><p>这并不是山姆的第一个想法，但他考虑购买一架大型喷气式飞机，然后从首尔飞往日本海岸附近的一个小岛，飞机上满载着每人提着价值 1 万美元韩元的手提箱的韩国人。 “问题在于它无法扩展，”Sam 说。 “为了让它有价值，我们每天需要大约一万名韩国人。我们这样做可能会引起如此多的关注，以至于我们会被关闭。一旦韩国央行看到一万名韩国人提着装满韩元的手提箱，他们就会说，这里将会有一个新的方向。”尽管如此，他还是受到了诱惑。 (1,483)</p></blockquote><p>这让我们想到了机器人。</p><p>所讨论的机器人称为 Modelbot。我会简单地称它为Arbbot。</p><p>这个想法很简单，也是我很想尝试的事情。有很多不同的交易所以不同的价格交易大量的加密货币。有时价格不同。当这种情况发生时，你可以进行各种形式的套利（和统计套利）。山姆，作为一名交易员，同时也是山姆，他非常热衷于接受免费资金。</p><p>让它更具吸引力的是，虽然萨姆拒绝（或失败）雇用真正的交易员，但他确实聘请了一位世界级的程序员，并且他确实设法在利用国家套利贸易的同时筹集资金。</p><blockquote><p>它们没有爆炸，一开始没有。最初几周，他们并没有赚到真正的钱，但后来他们只有几个人和萨姆的奖金。到 12 月底，他们已经雇佣了一批人，并筹集了 2500 万美元的资金。加里基本上是独自编写了整个定量系统的代码。那个月他们创造了数百万美元的利润。 2018 年 1 月，他们的利润增至每天 50 万美元，资本基础为 4000 万美元，于是，一位名叫贾恩·塔林 (Jaan Tallinn) 的利他主义者（通过 Skype 发家致富）又给了他们 1.3 亿美元。</p></blockquote><p>所以山姆建造了模型机器人来做到这一点，除了那些爱管闲事（有效利他主义者）的孩子之外，他也可以逃脱惩罚。</p><blockquote><p>他无法让模型机器人按照他想要的方式撕毁——因为阿拉米达研究中心内的几乎所有其他人都在尽一切努力阻止他。一位人士表示：“我们完全有可能在一小时内损失所有资金。”本来可以用于有效利他主义的一亿七千万美元可能会化为泡影。 (1,368)</p></blockquote><p>不是“我们投资者的 1.7 亿美元资金”。这不是“我们唯一的交易机会，显然我们不会再有第二次了。”甚至“如果我们就这样失去了它，我不禁想知道我们是否会遇到一些法律或其他问题需要处理。”</p><p>不，这是 1.7 亿美元，“本来可以用于有效的利他主义”。</p><p>那张照片有严重、严重的错误。虽然不像图片中山姆的部分那么错误。</p><blockquote><p> [一天]晚上，塔拉与山姆激烈争论，直到他屈服并同意她认为合理的妥协：只要他和至少一个其他人在场观看，他就可以打开模型机器人，但应该将其关闭如果它开始亏损。 “我说，‘好吧，我要回家睡觉了’，我一离开，萨姆就打开了它，然后就睡着了，”塔拉回忆道。从那一刻起，整个管理团队放弃了对萨姆的信任。 (1,372)</p></blockquote><p>我的意思是，管理团队完全更新了对山姆的信任，尽管没有完全更新“这个人需要立即被解雇，如果不是更早的话”，假设塔拉的账户是准确的，而且书中没有说山姆对此提出异议，它与山姆的其他事情似乎也没有丝毫不一致。在承诺不这样做之后打开机器人已经够糟糕的了，但是打开一个新的机器人然后在没有其他人在看的情况下睡着了？是的，那是另一个不好的星球。</p><p>这并不是故事中奇怪的部分。这个故事的奇怪部分是，为什么测试机器人是否工作并不简单？</p><p>您敢于打开的任何机器人都有各种风险限制。您可以打开机器人，其交易金额限制非常低。交易规模要小。看看你最终得到的钱是否比开始时多，在同样的地方。如果你能做到这一点，你就可以开始慢慢增加数字。标准程序。如果你做不到这一点，那么你还没有完成你的机器人编程，所以继续吧。让多人随时观察，分析交易，看看事情是否有意义，并不断完善你的算法。</p><p>相反，声称是山姆在没有人观看的情况下打开了程序，没有任何理由不等待，然后无限期地运行，没有办法测试如果有人打开它，程序是否真的可以工作。我注意到我很困惑。</p><p>阿拉米达没有盈利的机器人，也没有套利交易，根据该书自己的报告，他们开始亏损，而且他们要支付非常高的利率来借钱。事情看起来不太好，而且正在迅速升级。</p><p>接下来是瑞波失踪的故事。他们应该拥有价值 400 万美元的 Ripple。然后他们就失去了它。没有人知道它在哪里。该怎么办？</p><p> Sam 的态度是 Ripple 可能会出现，所以没有义务对投资者说什么，不用担心，继续你的日子。可以理解的是，其他人更关心的是？</p><blockquote><p>事后，如果我们再也拿不回任何瑞波币，没有人会说我们拥有百分之八十的瑞波币是合理的。每个人都会说我们对他们撒了谎。我们将被投资者指控欺诈。这种争论简直让萨姆烦透了。他讨厌事后将固有的概率情况解释为非黑即白、好与坏、对与错。</p></blockquote><p>让您想起本书后半部分将要发生的事情吗？是的，事实证明，如果你告诉人们一切都很好，但你有理由非常清楚这可能并不好，这通常会构成欺诈。一般来说，你不能简单地不提及或解释你不想提及或解释的事情。</p><p>因此，Sam 要求每个人每天工作 18 小时，他是一个脾气暴躁、可怕的人，完全不值得信任，无缘无故地冒着所有钱的风险，他把 400 万美元的 Ripple 钱丢了，然后提议采取行动。就像那件事并没有发生一样，而且对于公司的资金流失和其他一些事情，出于某种奇怪的原因，萨姆的整个管理团队决定他们已经受够了并希望萨姆离开。</p><p>管理团队遇到了问题。感谢他们以“我保证稍后会解决这个问题，我们需要快速行动”作为解释，萨姆拥有了整个公司。不知何故，每个人都允许这样做。</p><p>该书的叙述还声称，该要约中有一个荒谬的条款，完全无法兑现，旨在让山姆彻底破产。通常情况下，人们不会做出“是”的决定。</p><blockquote><p>首先，山姆拥有整个公司。他的结构使得其他人都没有股权，只有未来股权的承诺。在一次紧张的会议上，其他人提出收购他的股份，但价格只是山姆认为公司价值的一小部分，而且这个提议还附有恶魔般的细则：山姆仍将承担阿拉米达未来利润的所有税款。至少他的一些有效的利他主义者的目标是让萨姆破产，几乎是为了人类的服务，这样他就可能永远不会被允许再次进行交易。 (1,555)</p></blockquote><p>什么？对阿拉米达未来的利润承担所有税款吗？也许他们希望山姆不会注意到，作为细则？这是我见过的最荒谬的要求，萨姆显然宁愿点燃整个企业也不愿同意。我对此一无所知，但我必须假设这不是一个完整而准确的描述？</p><p>这本书证实，整件事按照它所描述的方式看起来非常疯狂。</p><blockquote><p>我们的谈话简直太疯狂了，”他回忆道。 “比如 Sam 在多大程度上应该因欺骗 EA 和浪费 EA 人才而被逐出教会。就像“山姆了解的唯一方法是他是否真的破产了。”他们告诉我们的投资者，他假装是一名 EA，因为这是他们能想到的最卑鄙的话。”然而，毁掉萨姆还不够：他们期望在离开时就能得到报酬。 “他们想要遣散费，尽管他们要辞职，而且这是一项赔钱的业务，而且他们没有股份，”尼沙德说。 “他们说萨姆需要买下他们的股份，而他们的价值超过整个公司价值的百分之一百以上，因为萨姆是净负数。” (1,575)</p><p>现在，所有这些无利可图、有效的利他主义者都要求获得数百万美元的报酬才能退出，并尽一切努力破坏山姆在外界的声誉，直到他们拿到钱为止。 (1,584)</p></blockquote><p>这通常不是这样运作的。辞职者通常不会获得遣散费。放弃者通常不会获得超过整个公司 100% 的价值。如果有人要求你以高于公司价值的价格收购他们的股份，并且他们准确地描述了公司的价值，你可能会说“等等，这超过了公司的价值，我为什么要付那个钱？”</p><p>值得称赞的是，尼沙德发现自己陷入了深深的困惑。</p><blockquote><p>尼沙德突然意识到，有效的利他主义者与金钱的关系有点奇怪。基本上，阿拉米达研究公司的所有员工和投资者都致力于将所有资金捐献给大致相同的慈善事业。你可能会猜测，他们不太关心谁最终得到了这笔钱，因为这一切都将用于拯救那些他们从未见过的人的生命。你错了：在彼此的金融交易中，有效的利他主义者比俄罗斯寡头更加无情。他们的投资者向他们收取 50% 的利率。 “这不是一笔正常的贷款，”尼沙德说。 “这是鲨鱼贷款。”在本应成为一家合作企业的情况下，萨姆拒绝分享任何股权 (1,578)</p></blockquote><p>啊，是的，资助者要求 50% 的利息。这个我可以拿走即使向相对负责任的加密货币公司借钱也是高风险的，而且通常是非常愚蠢的。这不是 2022 年的事后诸葛亮，早在 2018 年，我正在为一家加密货币公司进行交易，我们借了钱，我说我不知道​​为什么有人自愿借给我们钱。投资加密货币交易公司？当然，也许吧。可以工作。巨大的上升空间。但为什么你要向加密货币公司借钱，如果数字上升，你会得到适度的利息，如果数字下降，你的数字就会降至零？</p><p>理想的答案是你不这样做。如果必须的话，赚取足够的利息是值得的。 50% 的比率似乎有点低。</p><p> EA 离开的整个想法“破坏 Sam 的声誉”在这里被视为一件大事，也是资助者大幅削减规模的原因。但直到FTX炸了我才听到抱怨？我认识的大多数人都没有听到他们的声音？考虑到 FTX 在 EA 领域的规模有多大，这种大规模的声誉破坏行动如此未被注意到，是不是有点奇怪？他们当然有很多好的材料可以使用。如果他们按照书中所述陈述了事实，这似乎就足够了？</p><p>为什么在一切崩溃之后我们会闪现到这一点：</p><blockquote><p>从一开始，赞恩就被山姆和他可能创建的帝国所吸引。但他并没有盲目地加入这一事业。在加入 FTX 之前，他咨询了加密领域的老朋友。 CZ就是其中之一。 “是 CZ 告诉我他的事的，”他现在回忆道。 “他说，‘我认为这对你来说是一个非常好的选择。’人们问我：“你是如何如此信任萨姆的？” CZ 是这一切的开始。但没有人说他的坏话。”赞恩是一名枪手，他被说服在镇上与守法的人们一起建立了一个受人尊敬的家。许多大型加密货币投机者将资金委托给 FTX，因为他们信任 Zane。 (3,338)</p></blockquote><p>为什么<a target="_blank" rel="noreferrer noopener" href="https://forum.effectivealtruism.org/posts/xafpj3on76uRDoBja/the-ftx-future-fund-team-has-resigned-1?commentId=ugDoKrwtkR9DaM4d4">EA 领导层没有向 Eliezer 传达这个信息</a>？</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F038a5d26-7650-4be0-a4d6-811b54ea36eb_1026x1240.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AocXh6gJ9tJC2WyCL/cgjzdxetelgc8dbql5jf" alt=""></a></figure><p>至于资助者削减规模，也许原因是他们给了萨姆很大的规模，这样萨姆就可以做一笔大交易，现在事情已经结束了，缩减规模是否有意义？</p><p>相反，书中说确实支付了七位数的遣散费，山姆继续与阿拉米达合作，然后每个人都忘记了，而在书的后面部分，山姆被视为拥有完美的声誉。</p><p>所以，你的整个管理团队都辞职了。接下来你会做什么？</p><blockquote><p>回想起来，接下来发生的事情似乎有些难以置信。由于没有人与他争论，Sam 按下开关，让 Modelbot 撕裂。 “我们打开它，它立即开始为我们带来很多钱，”尼沙德说。然后他们终于找到了价值 400 万美元失踪的 Ripple。 (1,606)</p></blockquote><p>我发现我仍然很困惑。 Modelbot瞬间赚大钱？为什么他们之前不把它打开呢？没有实验可做吗？上次 Sam 打开它并睡着时发生了什么？这些都没有意义。</p><p> （瑞波币发生的事情是，它在发送到交易所时贴上了不正确的标签，所以它堆积在那里，而交易所不知道它是谁，直到他们最终追踪到这个东西并弄清楚了，此时交易所大喊大叫他们完全是白痴，但确实交出了瑞波币。他们非常好，而且也很疯狂，他们让事情拖了那么久才弄清楚。）</p><p>那些留下来的人没有做出正确的更新。</p><blockquote><p>他们不再是有效的利他主义者的随机组合。他们是一个小团队，经历了一场令人震惊的戏剧性事件，现在信任山姆。他一直都是对的！ (1,618)</p></blockquote><p>山姆证明他可以设计一个有利可图的套利机器人。他因自己的粗心而幸运。这一次的风险得到了回报。此外，他是一个糟糕的经理和团队建设者，他所选择的管理团队在短时间内都非常讨厌他，以至于他们在积极试图打倒他的同时抛弃了他。</p><p>那些留下结论的人……还有其他事情。</p><p> Sam 还得出结论，既然 EA 不肯合作，他就不应该雇佣这么多 EA。</p><blockquote><p>他的 EA 同事的行为导致他更新了对概率分布的理解，这让他不太愿意雇用 EA。 (1,805)</p></blockquote><p>尽管我在这里和其他地方批评 EA，但当你完全不值得信任并且你的陈述根本不符合事实时，他们确实会注意到。然后他们往往会关心它。他们通常实际上并不想每天连续工作 18 小时。此外，新聘用的 EA 也不会像 SBF 所希望的那样表现出个人忠诚度。</p><p>该操作有多欺诈？再说一遍： <a target="_blank" rel="noreferrer noopener" href="https://www.theblock.co/post/186187/alameda-promised-high-returns-with-no-risk-in-2018-pitch">这是他们 2018 年的套牌，声称年化回报率 >;100%</a> （且“无风险”）。这里没有任何歧义。</p><h4>这是如何运作的</h4><p>早在 SBF 介入之前，加密世界就已经是败类和邪恶的巢穴。与往常一样，这里也有很多理想主义者和善意、诚实的人。这些人大多不是致富的人，也不是经营交易所的人。</p><p>这些交易所是根据其用户群按比例印钞的许可证，用户提出了所有错误的问题，并且没有监管机构或消费者监督机构来控制他们，所以那里的情况变得很丑陋。</p><blockquote><p>在整个亚洲，每个月都会出现新的加密货币交易所，为不断增长的赌博大众提供服务。他们都财力雄厚，对年轻女性有着永不满足的需求。</p><p>他们雇佣了很多人，因为他们有能力雇佣，而大量的员工表明了他们的重要性。 (93)</p></blockquote><p>我可以证实，客户对加密货币交易所的主要要求是能够用他们的加密货币进行极其不负责任的赌博。就像客户高度看重100:1杠杆一样，用100美元的比特币购买10,000美元的比特币，如果价格在一微秒内下跌1%，他们愿意损失全部。</p><p>人们认为利用这种杠杆是个好主意。他们总是错的。迈克尔·刘易斯似乎对此也感到困惑。</p><blockquote><p>以下是所玩游戏的一个例子：几家亚洲交易所提供了一百倍杠杆的比特币合约。时不时地，一些交易者发现他可以买入价值 1 亿美元的比特币，同时又卖空价值 1 亿美元的比特币，而每笔交易只需投入 100 万美元。无论比特币的价格发生什么变化，他的一笔交易都会获胜，而另一笔交易将会失败。如果比特币上涨 10%，流氓交易者就会从他的多头头寸中收回 1000 万美元，然后消失——让交易所来弥补他在空头头寸上损失的 1000 万美元。 (1,736)</p></blockquote><p>这基本上是一个不好的、非常糟糕的交易，因为交易所在你的账户仍然有正值的时候就清算了它，而“清算”意味着“没收所有账户并将你的账户减记为零”。也许他们会真正清算那里的东西，也许他们不会，这取决于他们。</p><p>这种交易是否存在对您有利但对交易所不利的版本？当然，假设我们完全忽略了可以安全地假设所有这些都是市场操纵和多重会计并且非常不合法，因为哈哈法律，哈哈合规部门，这就是加密货币，你甚至在谈论什么。</p><p>是的。如果实际上除了代码之外没有任何法律，我可以想到三个。</p><ol><li>您有理由预期（或导致）比特币比平常更加波动，并且价格上涨会导致您的错误交易以负账户价值清算。例如，如果您在决定是否允许比特币 ETF 之前被允许进行此交易，那么这笔交易似乎不错。</li><li>你可以规模足够大，以迫使交易所进行影响整个比特币市场的大笔交易。例如，比特币上涨 75 个基点 (0.75%)，他们将您的空头头寸（仍价值 25 万美元）清算为零。但通过这样做，他们会进一步推高比特币的价格，在影响你出售比特币之后，你最终会领先。如果他们让你扩大规模足够大的话，这在当时并不是不可能的。</li><li>你可以直接提供给清算，清算机制是愚蠢的。因此，当你的空头账户被清算时，交易所会发出大于其市场承受能力的市场买单，而不是做一些不那么愚蠢的事情，你的账户有各种更高价格的卖单，你以愚蠢的价格填写了大量的清算订单，你在价格稳定之前迅速卖掉剩余的，然后你就笑了。</li></ol><p>当我进行加密货币交易时，我坚持要注意诸如不操纵市场、不欺骗订单以及在掌握重大非公开信息（又称内幕交易）时不进行交易等事情。这主要让其他人对我如此坚持某个外星世界的法律感到非常恼火。他们之所以忍受，是因为正如吸烟者所说，他们需要我的专业知识。</p><p>清洗交易很常见。</p><blockquote><p>所谓的清洗交易在受监管的美国交易所是非法的，尽管山姆看到这种情况并没有太担心。 He thought it was sort of funny just how brazenly many of the Asian exchanges did it. In the summer of 2019, FTX created and published a daily analysis of the activity on other exchanges. It estimated that 80 percent or more of the volume on the second- and third-tier exchanges, and 30 percent of the volume on the top few exchanges, was fake. Soon after FTX published its first analysis of crypto trading activity, one exchange called and said, We&#39;re firing our wash trading team. Give us a week and the volumes will be real. The top exchanges expressed relief, and gratitude for the analysis, as, until then, lots of people assumed that far more than 30 percent of their volume was fake. (2,429)</p></blockquote><p> I discovered this because I was trading on Binance, attempting to purchase Stellar for someone who wanted to purchase a bunch of Stellar when it was the #8 coin in the world (it is #23 now), and continuously failing to purchase any Stellar. There would be trading, I would issue a buy order where it was trading, and the entire market would mysteriously shift up. I would withdraw the order, things came back down. The market moved if you breathed on it, there was no way to get any size. It didn&#39;t make sense until I realized that most of the trading was not real. The whole thing was a house of cards. I reported this back and the person said, yes, everyone knows there&#39;s a lot of wash trading, I still want to buy Stellar. There&#39;s only so much you can do.</p><p> Lewis offers a strange claim here:</p><blockquote><p> Toward the end of 2018 the markets suddenly changed again. Spreads tightened dramatically, going from 1 percent to seven one-hundredths of a percent. (1,754)</p></blockquote><p> I mean, no, they didn&#39;t? I was at least kind of there, unrelatedly trading crypto. Throughout 2018 there were plenty of ways to trade rather large amounts for far less than a percent. Yes, spreads did tighten, and I am confident Alameda contributed to that tightening, but this was not an order of magnitude change.</p><p> Nor was it the final change. As time went on, spreads would tighten further. Alameda would be in a more and more competitive business. This was likely a prime motivation behind creating a crypto exchange, FTX, before Alameda lost its edge.</p><p> During this period, SBF relocated to Hong Kong, because he found that being in the room with other crypto people was very good for business.例如：</p><blockquote><p> Weeks before he flew to Asia, one of the big Chinese crypto exchanges had frozen Alameda&#39;s account with a bunch of money in it, for no obvious reason. Customer service hadn&#39;t returned their calls. After meeting Sam in person, the exchange&#39;s bosses handed him back his money. (1,782)</p></blockquote><p> It also gave Sam access to a new labor pool, one eager to get into the game and do whatever it took without asking questions, and got everyone out of the United States.</p><p> Sam&#39;s approach to hiring was to ensure no one ever know what they were doing, so this new pool of talent worked out great.</p><blockquote><p> Faced with a necessity, Sam turned it into a virtue. “It&#39;s a moderately bad sign if you are having someone do the same thing they&#39;ve done before,” he said. “It&#39;s adverse selection of a weird sort. Because: why are they coming to you?” (1,974)</p></blockquote><p> Spoken like an employer who does not know how to attract the best talent, and also someone who even Michael Lewis knows is bullshitting this time.</p><p> Another potential factor in this story that is not mentioned by Lewis, and also that did not come up in my previous post, is Tether. <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/patio11/status/1712096233672581273">Patrick McKenzie has the theory</a> that Alameda&#39;s true main business was knowing what to say to American banks to allow Tether to move capital. That they were centrally engaged in fraud on this entire additional level.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/patio11/status/1709206146249117927">This related thread of Patrick McKenzie&#39;s is also fun.</a> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/patio11/status/1709583245153599940">As is this one</a> . Or at least, you can learn more about what I (and I assume Patrick) find fun.</p><p> The next step was building a crypto exchange.</p><h4> Building FTX</h4><p> Sam had a secret weapon in building FTX, which is that he had a programmer that could single-handedly (so the book says) program the whole thing better than most programming teams. Knowing what I know about exchanges and engineers, this claim is a lot less wild than it sounds. At core an exchange is about getting a small number of important things right, which FTX mostly did get right except where Sam chose to intentionally get them wrong. I totally believe that a two person team, one to know what to do and the other to do it, could have pulled that off.</p><p> Before going down other funding routes, Sam tried to get CZ of Binance to pay.</p><blockquote><p> The first decision CZ had to make was whether to pay Sam the $40 million he was asking for his cleverly designed futures exchange. After thinking it over for a few weeks in March 2019, CZ decided no—and then told his people to create a futures exchange on their own. Which struck Sam as such an ordinary and vaguely disappointing thing to do. “He&#39;s kind of a douche but not worse than a douche,” said Sam. “He should be a great character but he&#39;s not.” (1,893)</p></blockquote><p> I do not really know what Sam was expecting. CZ presumably took a few weeks to think it over in order to keep optionality and get a head start, if he wasn&#39;t already building such an exchange anyway as seems rather plausible. Luckily for Sam, he still managed to do the better execution than CZ.</p><p> The book describes CZ as a strangely conventional and unimaginative person, who created Binance and made it the dominant exchange on the planet, becoming one of the richest people on Earth, without any exceptional qualities or skills of note. Lewis makes it sound like CZ was one of many who started exchanges, and he was at the right place at the right time and things broke his way. I don&#39;t know anything about CZ that isn&#39;t common knowledge, but I do not buy this at all. Random people do not luck into that kind of situation. But that would be the story of a different book.</p><p> So now Sam needed money to build FTX. He had a killer programmer, but there is a lot more to an exchange than that. So it was time to fundraise.</p><p> The book talks about two ways they raised money: Selling FTT tokens, which are a cryptocurrency Sam created representing claims on a portion of FTX&#39;s future revenue and thus effectively a form of preferred stock in FTX, and traditional VC fundraising.</p><p> The FTT story is told as a story of quick success. He starts out charging early people $0.10, then quickly that goes up quite a lot, some people get rich out of the gate, Sam is sad at what he gave away. VCs in this spot, and crypto people too, tell you not to be upset about that. You need big gains and a story to drive excitement, you still have most of the company and a ton of the tokens. You have what you need. Why fret it? Instead, Sam says later in the book he regretted creating the tokens and sold them so cheap, rather than regretting the tokens because he used them later in such crazy fashion that he blew up his whole empire.</p><p> The stock story is where SBF learns the basics of how VC works. In traditional Sam fashion, he noticed things were kind of arbitrary and dumb, then did not stop to think that they might not be as arbitrary and dumb as all that and there might be method to the madness even if it wasn&#39;t fully optimal.</p><blockquote><p> In early 2021, Jump Trading—not a conventional venture capitalist—offered to buy a stake in FTX at a company valuation of $4 billion. “Sam said no, the fundraise is at twenty billion,” recalled Ramnik. Jump responded by saying that they&#39;d be interested at that price if Sam could find others who were too—which told you that the value people assigned to new businesses was arbitrary. (2,060)</p></blockquote><p> No, this does not mean the valuation is arbitrary. That is especially true when, as was the case in FTX and most crypto companies, you politely decline to let anyone do proper due diligence, and you&#39;re not even a traditional VC. What is going on is that Jump is quite reasonably deciding that at a fair rate they would be willing to invest, but that they are not in position to evaluate what is fair. So they outsource that to others, including to the lead whoever that might be. If VCs are willing to costly signal, via their own investment, that a $20 billion valuation is reasonable, then Jump can be in as well.</p><blockquote><p> Selling a new business to a VC was apparently less like selling a sofa than it was like pitching a movie idea. (2,063)</p></blockquote><p> Well, yeah, that one is largely right. They care a ton about a good story.</p><p> Then we have Sam being peak Sam a bit.</p><blockquote><p> A guy from Blackstone, the world&#39;s biggest private investment firm, called Sam to say that he thought a valuation of $20 billion was too high—and that Blackstone would invest at a valuation of $15 billion. “Sam said, &#39;If you think it is too high, I&#39;ll let you short a billion of our stock at a valuation of twenty billion,&#39; ” recalled Ramnik. “The guy said, &#39;We don&#39;t short stock.&#39; And Sam said that if you worked at Jane Street you&#39;d be fired the first week.” (2,084)</p></blockquote><p> Sam is very much the one who gets fired in the first week here. No, you are not obligated to flip coins every time you think you have a tiny edge, especially billion dollar ones with uncapped potential losses subject to potential rampant manipulation and huge adverse selection. Nor has Sam paused to consider the cost of capital. VCs demand edges well in excess of 33% before they are willing to invest.</p><p> It is crazy, completely insane, to think that a VC willing to invest in a start-up at $15 billion would want to be short for size at $20 billion, with no market or way to cover.</p><p> Another part of the puzzle is that Sam used Alameda&#39;s resources to create FTX, <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/alpackaP/status/1593308236568055808">and the first VC that Sam talked to figured this and a number of other things out</a> .</p><p> Yet presumably Sam said this because he not only thought he was right, he thought he was so obviously right it made sense to say so over the phone. That tells you a lot about Sam&#39;s attitude towards capital, sizing, risk and other related matters, and also in believing that he know&#39;s all and everyone else is an idiot, which is <a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=iaHDBL7dVgs&amp;ab_channel=TheTomLehrerWisdomChannel">more, more, I&#39;m still not satisfied</a> .</p><h4> The Sam Show</h4><p> What about physically building FTX, as in their new headquarters in the Bahamas that was never finished?</p><p> There&#39;s a bunch of great stories in the book about the architects who got brought in to make this very expensive building, who were given no guidance, and desperately tried to figure out what their client wanted. All they got were three quick notes – the shape of an F, a side that looked like Sam&#39;s hair, and a display area for a Tungsten Cube – that Sam also didn&#39;t bother writing, instead someone else tried to imagine what Sam might ask for. It was all the Sam show, all about Sam all the time, very cult of personality or at least hair.</p><blockquote><p> Even from their jungle huts people jockeyed for a view of him. The architects schemed the main building with glass walls and mezzanines that offered unlikely interior views of Sam. “It gives you an opportunity to catch glimpses of Sam no matter where you are sitting,” said Ian [the architect]. (2,569)</p><p> The list had been created by someone else inside FTX who&#39;d tried to imagine what perhaps he himself might want in his new office buildings, were he Sam. Sam didn&#39;t want his Jewfro on the side of the building. This other person had just imagined that “Jewfro on the side of the building” was the kind of thing Sam might find amusing. (2,612)</p></blockquote><p> Another way he kept it all about him was not to give anyone else a title that represented what they were actually doing.</p><blockquote><p> Sam then listed some reasons why this might be so: Having a title makes people feel less willing to take advice from those without titles. Having a title makes people less likely to put in the effort to learn how to do well at the base-level jobs of people they&#39;re managing. They end up trying to manage people whose jobs they couldn&#39;t do, and that always goes poorly. (2,644)</p><p> Having titles can create significant conflicts between your ego and the company. Having titles can piss off colleagues. (2,648)</p></blockquote><p> If while reading this book you are not playing the game of noticing world-class levels of lacking self-awareness, you were missing out.</p><blockquote><p> Nishad Singh failed to imagine the way things actually went south, but he did imagine a different highly plausible one that likely happened in a bunch of other Everett branches.</p><p> I&#39;d soon be asking Nishad Singh for the same premortem I&#39;d ask of others at the top of their psychiatrist&#39;s org chart: “Imagine we&#39;re in the future and your company has collapsed: tell me how it happened.” “Someone kidnaps Sam,” Nishad would reply immediately, before unspooling his recurring nightmare of Sam&#39;s lax attitude toward his personal safety leading to the undoing of their empire.</p><p> ..made for excellent ransom. “People with access to crypto are prime kidnap targets,” said Nishad. “I cannot understand why it doesn&#39;t happen more.” (2,736)</p></blockquote><p> People don&#39;t do things. None of the people in the world thought to kidnap Sam, despite zero attempts to prevent this, so despite being perhaps the most juicy kidnap target the world has ever known, he remained un-kidnapped. The man had actual zero security, posed zero physical threat, had billions in crypto that was accounted for by literal no one including himself, and was a pure act utilitarian and effectively a causal decision theorist. That person pays all the ransom, and then shrugs it off and gets back to work.</p><p> Which is good, given they had no other decision making process whatsoever.</p><blockquote><p> “It is unclear if we even have to have an actual board of directors,” said Sam, “but we get suspicious glances if we don&#39;t have one, so we have something with three people on it.” When he said this to me, right after his Twitter meeting, he admitted he couldn&#39;t recall the names of the other two people. “I knew who they were three months ago,” he said. “It might have changed. The main job requirement is they don&#39;t mind DocuSigning at three am DocuSigning is the main job.” (2,833)</p></blockquote><p> There was no CFO. Why have a CFO? What would they do, keep track of how much money we have?</p><blockquote><p> “There&#39;s a functional religion around the CFO,” said Sam. “I&#39;ll ask them, &#39;Why do I need one?&#39; Some people cannot articulate a single thing the CFO is supposed to do. They&#39;ll say &#39;keep track of the money,&#39; or &#39;make projections.&#39; I&#39;m like, What the fuck do you think I do all day? You think I don&#39;t know how much money we have?” (2,838)</p></blockquote><p> You know what? I do indeed think you do not know how much money you had.</p><h4> A Few Good Trades</h4><p> Sam did a lot of trades. Some of them were good trades. Some of them were not.</p><p> That means sometimes you look dumb, and sometimes you look like a genius.</p><p> When the good ones can pay off by orders of magnitude, every VC and everyone in crypto knows that is a nice place to be.</p><p> For example, that Solana trade?甜的。</p><blockquote><p> Even if it wasn&#39;t [true], Solana&#39;s story was good enough that other people might see it that way and drive up the price of its token. Eighteen months later, Alameda owned roughly 15 percent of all Solana tokens, most purchased at twenty-five cents apiece. The market price of Solana had gone as high as $249, a thousand-times increase on what Sam had paid for the tokens, and the face value of Sam&#39;s entire stash was roughly $12 billion. (2,346)</p></blockquote><p> Makes up for a lot of other trades gone bad, provided you then sell some rather than double down. Yeah, I know, this is Sam we are talking about.</p><p> With a lot of effective control over Solana, Sam then was properly motivated to drive more hype and adaption. He even got to create a spin off, a &#39;Sam Coin&#39; called Serum, which was meant to be a claim on a portion of the fees for financial transactions on the Solana blockchain.</p><p> This was, presumably, a way to expropriate other holders of Solana. Instead of returning the fees to Solana holders, they would go to Serum holders, so suddenly there was another coin to distribute and manipulate and hype.乐趣。 The only problem was that it worked too well.</p><blockquote><p> Soon after Serum&#39;s creation, its price had skyrocketed. Sam clearly had not anticipated this. He now had all these employees who felt ridiculously rich. (At least in theory, the value of Dan Friedberg&#39;s Serum stash peaked, in September 2021, at over $1 billion.)</p><p> In Sam&#39;s view, everyone at once became a lot less motivated to work fourteen-hour days. And so he did a very Sam thing: he changed the terms of the employees&#39; Serum.</p><p> In the fine print of the employee Serum contract, he&#39;d reserved for himself the right to extend Serum&#39;s jail time, and he used it to lock up all employees&#39; Serum for seven years. Sam&#39;s employees had always known that he preferred games in which the rules could change in the middle.</p><p> They now understood that if he had changed the rules once, he might do it again. They became less enthusiastic about their Serum. “It was very unclear if you had it or if you didn&#39;t have it,” said Ramnik, who had watched in irritation as Sam locked up a bunch of tokens that he&#39;d bought with his own money on the open market before he joined FTX. “I guess you would know in seven years.” (3,980)</p></blockquote><p> Lewis is so close to getting it. He understands that Sam will betray everyone around him whenever he can. <a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=WpE_xMRiCLE&amp;ab_channel=AdultSwim">He is altering the deal, pray that he does not alter it any further</a> . Only from Sam&#39;s perspective, there is no deal, there is only <a target="_blank" rel="noreferrer noopener" href="https://www.amazon.com/Reality-What-You-Can-Away/dp/1561840807">reality, which is what you can get away with</a> .</p><p> Sam also had the advantage of being Sam and controlling Alameda and FTX.</p><p> He also had the bonus of not being so inspired to turn his paper gains into actual dollars (or stable coins, or liquid cryptos like BTC or ETH). Why liquidate what you can borrow against? That way Number Go Up.</p><p> Another trade he did was to take advantage of all the wash trading. The wash trading was so ingrained into how business was done, and done so poorly, that when SBF intercepted some of it, Binance&#39;s employees failed to explain to their boss CZ what was even happening. Or, he credibly pretended not to understand.</p><blockquote><p> It was a weird conversation—the CEO of one crypto exchange calling the CFO of another to inform him that, if he didn&#39;t want to lose money on his new futures contract, he&#39;d need to improve his market manipulation. Wei Zhou spoke to CZ, who called Sam for a brief though not unfriendly chat, after which Sam concluded that CZ still had not been told by his traders what had actually happened.</p></blockquote><p> What happened was that Binance was doing its market manipulation via predictable market orders, so SBF would step in front of those orders, which made a bunch of money that came out of Binance&#39;s pocket. Which Binance did not like.</p><p> Sam would occasionally consult others on what to do? I guess? Even Lewis realizes Sam does not actually care what anyone else thinks.</p><blockquote><p> After talking to them, Sam could tell himself that he&#39;d checked his judgment without having done so. (2,771)</p><p> Sam had invested $500 million in an artificial intelligence start-up called Anthropic, apparently without bouncing the idea off anyone else. “I said to Sam after he did it, &#39;We don&#39;t know a fucking thing about this company,&#39; ” said Ramnik. (2,818)</p></blockquote><p> Putting the $500 million into Anthropic was arguably the most important decision Sam ever made. I do not know if investing in Anthropic was a good or bad move for the chances of everyone not dying, but chances are this was either a massively good or massively bad investment. It dwarfs in impact the rest of his EA activities combined.</p><p> Another good trade Sam noticed was that rich people dramatically underinvest in politics, whatever you think of Sam&#39;s execution during what one might generously label his learning phase.</p><blockquote><p> What surprised Sam, once he himself had unlimited sums of money, was how slowly rich people and corporations had adapted to their new political environment. The US government exerted massive influence on virtually everything under the sun and maybe even a few things over it. In a single four-year term, a president, working with Congress, directed roughly $15 trillion in spending. And yet in 2016, the sum total of spending by all candidates on races for the presidency and Congress came to a mere $6.5 billion. “It just seems like there isn&#39;t enough money in politics,” said Sam. “People are underdoing it. The weird thing is that Warren Buffett isn&#39;t giving two billion dollars a year.” (2,874)</p></blockquote><p> We should not forget the original arbitrage trade with South Korea and Japan.</p><p> The good arbitrage trade that still doesn&#39;t fully make sense was ModelBot. I see no reason for it not to have worked, but I also see no reason Sam could not have safely proved that it worked by starting small and then scaling up. Why all the drama? Then it stopped working as competition improved.</p><p> Even excluding the arbitrage trades, that track record is really good. Sam took a lot of shots, but I think not thousands of such shots. If you can make trades like Solana at $0.25 and early Anthropic, the rest of your trades can lose and you could still have very good alpha – provided you are responsible with your sizing and other risk management, and cut your losses when trades fail and properly consider liquidity issues. There would be no need to lie, or to do all the fraud and crime.</p><p> The problem was that Sam was the opposite of responsible with the sizing and risk management. He did not cut his losses when trades failed. He did not consider liquidity issues.</p><p> There is also the highly related issue of all the lying and fraud and crime.</p><h4> The Plan</h4><p> Behind every great fortune, they say, is a great crime. Certainly that was true for this one. Then, as The Godfather tells us, one needs to appear to go legit.</p><p> Sam&#39;s plan was to present FTX as the responsible adults in the room.</p><p> It did help that the room was crypto, and filled with crypto exchanges. Many of which were indeed doing all the crimes. From the perspective of the United States, even the ones not doing all the crimes were still doing crimes anyway, the SEC has yet to explain to anyone what it would take to do crypto without doing crimes.</p><p> The biggest fish in the pond was CZ and Binance. Oh boy were they doing crimes. Their headquarters is intentionally nowhere. Their internal messages explicitly affirm that they are running an unlicensed security exchange in America.等等。</p><blockquote><p> Which is why, when Sam took in the situation, he decided that Binance&#39;s strategy was unsustainable. That the smart thing to do was to be the world&#39;s most law-abiding and regulator-loving exchange. FTX could use the law, and the regulators, to drive crypto trading from Binance and onto FTX. If countries did not yet have the laws, a small army of FTX lawyers would help them to create them. (2,406)</p></blockquote><p> Step one was to get CZ and Binance off the cap table, so no one evaluating FTX for its legitimacy would see them on the cap table doing all the crime. So Sam bought him out.</p><blockquote><p> For the stake he&#39;d paid $80 million to acquire, CZ demanded $2.2 billion. Sam agreed to pay it. Just before they signed the deal, CZ insisted, for no particular reason, on an extra $75 million. Sam paid that, too. (2,461)</p></blockquote><p> If SBF was going to pretend FTX was worth that much, why shouldn&#39;t CZ get paid accordingly? However, SBF made a big mistake, and left CZ with $500 million in FTT tokens rather than fully paying out in cash. It really should not have been that hard to not let that happen, given all the money available for spewing elsewhere. Ideally you sell a little of the equity you bought back, and use the proceeds from that.</p><p> The next step in reputation washing was a bunch of advertising.</p><blockquote><p> And so when someone from the Miami Heat reached out to them to suggest that FTX buy their naming rights, for $155 million for the next nineteen years, Sam leapt at the chance. That the deal required the approval not just of the NBA but also of the Miami-Dade Board of County Commissioners, a government body, was a bonus. After that, they could point to a government entity that had blessed FTX.</p><p> Once their name was on an American stadium, no one turned down their money. They showered money across US pro sports: Shohei Ohtani and Shaquille O&#39;Neal and LeBron James became spokespeople.</p><p> They paid Major League Baseball $162.5 million to put the company name on every umpire&#39;s uniform. Having the FTX logo on the umpires&#39; uniforms, Sam thought, was more useful than having it on the players&#39; uniforms. In basically every TV shot of every Major League Baseball game, the viewer saw the FTX patch. “The NBA put us through a vetting process,” said FTX lawyer Dan Friedberg. “Major League Baseball just said okay!” (2,482)</p></blockquote><p>它真的很容易。 Once the Miami Heat opened the door, no one else asked any questions. Everyone wanted the money, and that was that, FTX on the umpires to go with the Tezos sign that the Mets were somehow paid to display above center at Citi Field.当然可以，为什么不呢？</p><p> Given how restrictive FTX US was, this helps explain why SBF was so eager to sponsor all the things. He was after a different goal.</p><p> A common theme of FTX&#39;s sponsorships, like much of what FTX did, is that SBF would spew money in spectacular fashion, most of which was wasted, but he&#39;d also have big wins. In this case, the win was Tom Brady.</p><blockquote><p> But everywhere Sam went, people mentioned that they had heard of FTX because of Brady. Hardly anyone mentioned any of the other endorsers. “It was very clear which things had an effect and which did not,” said Sam. “For the life of me, I can&#39;t figure out why this is. I still don&#39;t know how to verbalize it.” (2,505)</p></blockquote><p> No one has ever <a target="_blank" rel="noreferrer noopener" href="https://tvtropes.org/pmwiki/pmwiki.php/Main/CriticalResearchFailure">Not Done the Research</a> <a target="_blank" rel="noreferrer noopener" href="https://tvtropes.org/pmwiki/pmwiki.php/Main/CreatorsApathy">more than Sam</a> ,, who is confused why Tom Brady impacted people more than Brett Farve. I am not confused at all. Tom Brady is the quarterback everyone was already always talking about, the one everyone hated or perhaps loved, the cheater, the one with the rings, the GOAT, the one who got a girl in trouble and left her, and all that. I say quarterback, you say Brady.</p><p> Next up was getting into politics. As I noted in the good trades section, Sam noticed this was remarkably cheap. So since he had no time to waste but he definitely had money to waste, he got cracking. Gabe Bankman-Fried, Sam&#39;s brother, got put in charge of the political operation.</p><p> Attention is not always people&#39;s strong suit.</p><blockquote><p> I really appreciate this, but it wouldn&#39;t be good for me to take money from FTX, so I can&#39;t—besides, I have found another source of funding.&#39; That other source of funding was Gabe, my brother.” (2,897)</p></blockquote><p> Sam&#39;s most famous political bet was on Carrick Flynn. The decision to back Flynn comes off in the book, if anything, massively stupider than it looked in real time.</p><blockquote><p> Carrick Flynn&#39;s most important trait, in Sam&#39;s view, was his total command of and commitment to pandemic prevention. His second-most important trait was that he was an effective altruist. (2,927)</p><p> Flynn asked some fellow EAs what they thought about him running for Congress. As a political candidate he had obvious weaknesses: in addition to being a Washington insider and a bit of a carpetbagger, he was terrified of public speaking and sensitive to criticism. He described himself as “very introverted.” And yet none of the EAs could see any good reason for him not to go for it—and so he&#39;d thrown his hat into the ring. (2,930)</p></blockquote><p> I don&#39;t blame Flynn, who was trying to do what he thought was the right thing. But it seems so utterly obvious every step of the section on him that this man was never going to be in Congress. Yet they threw tons of money at him anyway, even after that money became the central campaign issue, and all the other candidates ganged up on Flynn over being a crypto stooge and a carpetbagger, and everyone in the district was complaining how their mailboxes were overflowing from campaign ads and they couldn&#39;t take one more of Flynn&#39;s spots on the television.</p><p> To be fair, there was real uncertainty the night before, no one knew for sure that it hadn&#39;t worked. And yes, a champion is super valuable?</p><p> What did Sam learn?</p><blockquote><p> [Sam] actually didn&#39;t mind all that much. He&#39;d learned a lesson: there were political candidates no amount of money could get elected. (2,959)</p></blockquote><p>嗯，是。 Also, you learned that when you stick your neck out like that you and those associated with you (read: EA) pay a lasting reputational cost. Sam did not seem to notice this.</p><p> No time to lose. Sam was off to meet Mitch McConnell, with everyone scrambling to get SBF into a presentable suit (he had been convinced to technically bring a suit, but had given no thought to its presentability, he let others handle such things) and he worked to ensure not to call Mitch, who insisted on being called Leader, &#39;dear leader&#39; instead. Which I admit sounds hard.</p><p> Also, check out the claim at the end here.</p><blockquote><p> At that moment, Sam was planning to give $15–$30 million to McConnell to defeat the Trumpier candidates in the US Senate races. On a separate front, he explained to me, as the plane descended into Washington, DC, he was exploring the legality of paying Donald Trump himself not to run for president. His team had somehow created a back channel into the Trump operation and returned with the not terribly earth-shattering news that Donald Trump might indeed have his price: $5 billion. Or so Sam was told by his team. (2,972)</p></blockquote><p> <a target="_blank" rel="noreferrer noopener" href="https://puck.news/s-b-f-s-mcconnell-money-tickle-part-2/">A $10 million donation to a McConnell dark money group One Nation has been confirmed.</a></p><p> I once again remind everyone that, while the price has likely gone up, the offer is probably still on the table if someone is bold enough to take it. Sure, now that he&#39;s got the nomination in his sights it probably costs you $10 billion, but given the way people talk about what a Trump victory would look like, surely that is a small price to pay?</p><p> Meanwhile, Sam claimed to have infiltrated Trump&#39;s team, and I love what they did with the place.</p><blockquote><p> Sam&#39;s team had come up with an idea—which, Sam claimed, was just then making its way to Trump himself. The idea was to persuade Trump to come out and say “I&#39;m for Eric!” without specifying which Eric he was for. After all, Trump didn&#39;t actually care who won. (2,979)</p></blockquote><p> Trump actually did it, and it is plausible this switched which Eric won.不错的演出。</p><h4> The Tragedy of FTT</h4><p> The whole FTT situation still blows my mind.</p><p> I mean, I know it happened, I accept it.仍然。 Blows my mind every time.</p><p> The tragedy is there was absolutely no need for any of it. There was no need to keep flipping coins double-or-nothing for all the money on the assumption that the odds were in Sam&#39;s favor.</p><p> Which they weren&#39;t. Yet he kept flipping.</p><p> So here&#39;s the basics, for those who don&#39;t know.</p><p> Alameda owned a lot of FTT, which is effectively stock in FTX.</p><p> This FTT was highly illiquid. Trying to sell even a fraction of it would have collapsed the price, as everyone involved knew. Collapsing the price of FTT would then, as again everyone involved knew, cause a collapse of confidence in FTX, causing a run on the bank that was FTX. Which those involved had information to know would be quite a serious problem, were it to happen.</p><p> Every trader knows that you do not borrow heavily against your own illiquid stock, with loans recallable at any time and likely to be recalled when times get tough for your industry, to buy other illiquid and highly speculative things highly correlated to your stock and your industry.</p><p> Especially if you know you could not survive the resulting bank run because you&#39;ve appropriated billions in customer funds to cover your other losses or even to keep making more illiquid investments, or to spend on random stuff. All while your exchange was a highly valued money printing machine that could easily raise equity capital.</p><p> And if you were still for some reason going to do that, they would at least know not to also give your biggest rival a huge chunk of that same illiquid token sufficient to crash the market, then actively try to drive him out of his home and bring regulators down on his head, in ways he can see you doing right there.</p><p> I mean, come on, that&#39;s completely insane.</p><p> Except that is, by the book&#39;s admission, exactly what happened.</p><blockquote><p> It seemed perfectly natural for Alameda to control all the remaining FTT, and use it as collateral in its trading activity. Sam didn&#39;t even try to hide what he was doing. (2,105)</p></blockquote><p> Did other crypto firms accept this collateral, knowing or even worse somehow not knowing exactly what this implied? Why yes. Yes they did.</p><p> This created a highly volatile situation. A downward spiral waiting to happen.</p><p> Then crypto crashed, everyone including Alameda lost a lot of money, and it happened.</p><p> To try and prevent it from happening, Alameda had to actually repay its loans, or else the FTT it used as collateral was going to get liquidated. Then it had to bail out firms like Voyager. This was all on top of all the money Alameda and FTX had already spent and lost.</p><p> Sam still did not seem to notice that funding might be an urgent issue.</p><blockquote><p> At their peak, they&#39;d together been valued at roughly $7 billion. Now Ramnik was acquiring them for no more than $200 million. A pittance.或者看起来是这样。 Ramnik recently had asked Sam how much capital he should assume was available for possible acquisitions, and Sam had said, Just let me know if you get to a billion. (3,100)</p></blockquote><p> So Sam kept poking the bear. Hence, The Vanishing.</p><h4> The Vanishing</h4><p> That&#39;s what Michael Lewis calls the collapse of FTX.</p><p> The proximate cause was that Sam pissed off CZ, while very much not being in a position to call BS on anyone. As in doing things like this:</p><blockquote><p> Sam later wrote up the message he&#39;d tried to convey to them. “I love Dubai,” he said. But we can&#39;t be in the same place as Binance. 。 。 。 This is for two reasons: first they are constantly devoting significant company resources to trying to hurt us; and second that they soil the reputation of wherever they are. I can&#39;t emphasize this enough: in general I hear great things from other jurisdictions/regulators etc. about Dubai and the UAE [United Arab Emirates], except that there&#39;s a constant refrain of: that&#39;s the jurisdiction that accepted Binance, and so we don&#39;t trust their standards. It was unclear to Sam, if Dubai decided to rid itself of CZ and his exchange, whether any country in which CZ would be willing to live would accept them. In these woods, CZ was the biggest bear and Sam seemed to be going out of his way to poke him. (3,154)</p></blockquote><p> CZ was understandably upset, leaked a supposed balance sheet from Alameda that looked bad but not as bad as the full reality, and announced his intention to dump his FTT.</p><p> Caroline Ellison decided to respond by offering to buy all the FTT at $22, thinking this was a show of strength, except for once crypto investors understood what that meant and acted accordingly.</p><blockquote><p> Within twenty seconds of Caroline&#39;s tweet came a rush to sell FTT by speculators who had borrowed money to buy it. The panic was driven by an assumption: if Alameda Research, the single biggest owner of FTT, was making a big show of being willing to buy a huge pile of it for $22, they must need for some reason to maintain the market price at 22. The most plausible explanation was that Alameda Research was using FTT as collateral to borrow dollars or bitcoin from others. “You don&#39;t tell someone a price level like $22 unless you have a lot of confidence that you need that price,” the CEO of Gauntlet, Tarun Chitra, told Bloomberg News. By Monday night, the price of FTT had fallen from $22 to $7. (3,203)</p></blockquote><p> Then the run on FTX began in earnest. Which would not have been a problem…</p><blockquote><p> Ramnik could see that money was leaving FTX, but he didn&#39;t view it as a big deal. The customers might panic and pull out all their money. But once they realized that there was nothing to panic about, they&#39;d return, and their money would too. (3,221)</p></blockquote><p> …except that FTX did not have the money to pay their customers, because Alameda had taken it and did not have the ability to give it all back.</p><p> Or have much idea how much they even had.</p><blockquote><p> Though Caroline was in charge of Alameda Research, she seemed totally clueless about where its money was. She&#39;d come onto the screen and announce that she had found $200 million here, or $400 million there, as if she&#39;d just made an original scientific discovery. Some guy at Deltec, their bank in the Bahamas, messaged Ramnik to say, Oh, by the way, you have $300 million with… And it came as a total surprise to all of them!</p><p> That he&#39;d been taken by surprise. He wondered: If these people knew there was a risk that they might not have enough money, why hadn&#39;t they even bothered to figure out how much they had? They&#39;d done nothing. (3,244)</p></blockquote><p> Didn&#39;t see it coming, I suppose. Did decide to use $8 billion in customer funds as if it was Alameda operating capital. Did not anticipate that the customers might ask for that money back all at once when they found out what was going on.哎呀。</p><p> Lewis rightly points out, near the end, that while many people did realize FTX was obviously up to no good, no one actually managed to figure out the exact no good they were up to until rather late in the game.</p><blockquote><p> Even those who had expressed suspicion about Sam or FTX had failed to say the one simple thing you would say if you knew the secret they were hiding: the customers&#39; deposits that are supposed to be inside FTX are actually inside Alameda Research. (4,007)</p></blockquote><p> They also couldn&#39;t imagine that things could have been as chaotic and unaccounted for, or as blatant, as they were. It wasn&#39;t necessary for the no good to be that no good. The borrowing against FTT tokens was bad enough on its own.</p><p> A lot of people, as FTX started to collapse, did the same calculation I did. It was quickly clear, as Sam went on Twitter to put on his best dog-drinking-coffee face and say &#39;assets are fine,&#39; that there were only two possible worlds.</p><ol><li> Either things really were fine, because FTX was obviously a money machine, things not being fine would have meant a completely crazy level of recklessness and incompetence, and SBF had gone way over the &#39;this is fraud if things are not fine&#39; line and was very all-in. No one would be so stupid as to.</li><li> Or this was pure fraud, through and through, and FTX and SBF did all the crime.</li></ol><p> That&#39;s why me and so many others turned around on a dime – once we could rule out scenario #1, we knew we were in scenario #2.</p><p> One by one, people who wanted it to be one way got the piece of evidence that convinced them it was the other way.</p><blockquote><p> Zane pinged Sam and asked, &#39;Should I do damage control?&#39; &#39;Yup,&#39; he said.” Zane then sent Sam a message asking three questions: “One, are we insolvent, two, did we ever lend out customer funds to Alameda, and three anything I didn&#39;t ask that I need to know?” Sam didn&#39;t reply—and then went totally silent on him. (3,344)</p><p> Still, Zane figured there was no way that FTX was in real trouble.这毫无意义。 The price of FTT shouldn&#39;t have any effect on the value of the exchange, any more than the price of Apple stock should have on Apple&#39;s iPhone sales. Just the reverse: the exchange&#39;s revenues drove the value of FTT. “If FTT goes to zero, so what?” said Zane. The other reason it made no sense was that FTX had been so wildly profitable. “I know how much real revenue we were making: two bips [0.02 percent] on two hundred fifty billion dollars a month,” said Zane. “I&#39;m like, Dude, you were sitting on a fucking printing press: why did you need to do this?” (3,347)</p></blockquote><p> Here is happens to Constance, on seeing the &#39;balance sheet.&#39;</p><blockquote><p> The next document in her stack was a rough balance sheet of Alameda Research that differed in important ways from the rough balance sheet that had inspired the CoinDesk article now being credited with bringing down the entire business. It appeared to Constance that it had been hastily concocted either by Sam or Caroline, or maybe by both. Constance had first come across it the previous Tuesday, after FTX had ceased sending money back to its customers. “When I saw it, I told my team not to respond to external parties because I did not want them to lose their good name and reputation,” she said.</p><p> The list of assets included the details of hundreds of private investments Sam had made over the previous two years, apparently totaling $4,717,030,200. The liabilities now had a line item more important than everything else combined: $10,152,068,800 of customer deposits. More than $10 billion that was meant to be custodied by FTX somehow had ended up inside Sam&#39;s private trading fund. The document listed only $3 billion in liquid assets—that is, US dollars or crypto that could be sold immediately for dollars.</p><p> “I was like, Holy shit,” she said. “The question is: Why?” It was the same question Zane had asked. “We had so profitable a business,” said Constance. “Our profit margin was forty to fifty percent. We made four hundred million dollars last year.” (3,478)</p></blockquote><p> They may have made five hundred million, but even if they hadn&#39;t stolen everyone&#39;s money, that was not about to pay the expenses.</p><blockquote><p> Constance herself had lost around $25 million. She still had $80,000 in an ordinary bank account she&#39;d kept from her previous life, but otherwise she&#39;d lost everything. (3,492)</p></blockquote><p> This is the kind of thing that still blows my mind. You have stock in FTX, you have $25 million in liquid assets, the world is in front of you. And you chase FTX&#39;s interest payments, and trust FTX so much, that you keep all your money on the exchange.什么？ That is completely crazy behavior. And yet, most employees tell exactly that story. It seems likely SBF/FTX insisted upon it, and Lewis either missed this or declined to mention it.</p><p> Because at $25 million while working at a crypto company, I&#39;d hope I&#39;d be doing things like millions in gold in a secret vault. At minimum I&#39;d have $5 million in an offshore bank account.</p><p> But even after that, Caroline didn&#39;t turn on Sam yet. She only turned on Sam when she realized that, compared to those around her, she&#39;d been given an order of magnitude or two less stock than she should have gotten.</p><blockquote><p> That&#39;s when Constance&#39;s feeling about Sam changed: when she saw how she&#39;d actually been treated. (3,524)</p></blockquote><p> Only then did she decide to spend the last chapter of the book helping Sam with logistics so she could try to get Sam to confess.</p><h4> The Reckoning</h4><p> As future prisoners, having been caught doing all the crime, the principles of FTX faced the prisoner&#39;s dilemma.</p><p> The game theory of SBF: You have to commit to the bit.</p><blockquote><p> That night, Nishad requested a meeting with just Gary and Sam. Once the three were alone in a room, Nishad asked, What happens if law enforcement or regulators reach out?你是什​​么意思？ Sam asked. How do we make sure we cooperate in prisoner&#39;s dilemma? How do we all make sure we say the other ones are innocent? I don&#39;t have any reason to think any one of us had criminal intent, said Sam. (3,291)</p><p> No, said Nishad. That&#39;s not good enough. You need to talk to them. You need to tell them I had no clue. How could I know that? asked Sam. You are saying that I should say that you know nothing about something I know nothing about. How is that even possible? It makes no sense. But I didn&#39;t know, said Nishad. Then say that, said Sam. It&#39;s not going to work for me, said Nishad. Because there is code-based evidence of what I did. (3,295)</p></blockquote><p> The game theory of everyone else?没那么多。</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/matt_levine/status/1713273141118509317">Caroline held this meeting on November 9</a> to explain the situation to her employees. as Patrick McKenzie says &#39;what a document.&#39;</p><p> Being Causal Decision Theory agents, and being somewhat more grounded in reality, the rest of the EAs all turned state&#39;s witness.</p><p> Sam also had many other bizarre ideas about how any of this worked.</p><blockquote><p> “At the end of the day, the deciding factor in the jurisdictional dispute is Gary,” said Sam, the night Zane left, “because he&#39;s the only one who knows how to use a computer.” (3,374)</p></blockquote><p> Sam was convinced to declare bankruptcy in America lest he instead have it declared for him by less friendly other parties, then tried to undo it which you cannot do, then went around insisting that if he hadn&#39;t declared bankruptcy it would all have worked out.</p><p> Sam kept trying to explain how the money was all there, really, or close to it, and how all of this was merely a serious of unfortunate &#39;fuck ups&#39; and misunderstandings. Sam thought he had plenty of money, didn&#39;t keep track of things properly, everything seemed safe at the time, he was as surprised as anyone.</p><p> So far, so public domain. The weird thing is that Michael Lewis seems to buy it.</p><blockquote><p> In Sam&#39;s telling, FTX had switched off Alameda&#39;s risk limits to make itself more appealing. The losses caused by this unsettling policy were in any case trivial. Ordinary trading loans made by FTX to Alameda constituted a small fraction of the losses to customers; on their own, they wouldn&#39;t have posed a problem. The bulk of the customers&#39; money inside of Alameda that should have been inside FTX—$8.8 billion of it, to be exact—resided in an account that Alameda had labeled fiat@. The fiat@ account had been set up in 2019 to receive the dollars and other fiat currencies sent by FTX&#39;s new customers. (3,543)</p><p> In Sam&#39;s telling, the dollars sent in by customers that had accumulated inside of Alameda Research had simply never been moved. Until July 2021, there was no other place to put them, as FTX had no US dollar bank accounts. They&#39;d been listed on a dashboard of FTX&#39;s customer deposits but remained inside Alameda&#39;s bank accounts. Sam also claimed that, right up until at least June 2022, this fact, which others now found so shocking, hadn&#39;t attracted his attention. (3,555)</p><p> But even if you valued the contents of Alameda more rigorously, as Sam sort of did in his head sometimes, you could still easily get to $30 billion. The $8.8 billion that should not have been inside Alameda Research was not exactly a rounding error. But it was, possibly, not enough to worry about. As Sam put it: “I didn&#39;t ask, like, &#39;How many dollars do we have?&#39; It felt to us that Alameda had infinity dollars.” (3,562)</p><p> At that point, in Sam&#39;s telling, Sam thought that Alameda might be in trouble. He decided to dig into its accounts on his own and understand the problem. By October, he had a clearer picture. It was only then that he could see that Alameda had been operating as if the $8.8 billion in customer funds belonged to it. And by then it was too late to do anything about it. (3,576)</p></blockquote><p> This story does not actually make any sense, and of course is directly and blatantly contradicted by testimony at the trial. And yet Michael Lewis is intrigued:</p><p> I had a different question. It preoccupied me from the moment of the collapse: Where had the money gone? It was not obvious what had happened to it. (3,610)</p><blockquote><p> At any rate, when I was done, my extremely naive money-in, money-out statement looked like this:</p><p> MONEY IN:</p><p> Net customer deposits: $15 billion</p><p> Investments from venture capitalists: $2.3 billion</p><p> Alameda trading profits: $2.5 billion</p><p> FTX exchange revenues: $2 billion</p><p> Net outstanding loans from crypto lenders (mainly Genesis and BlockFi): $1.5 billion</p><p> Original sale of FTT: $35 million</p><p> Total: $23,335,000,000</p><p> MONEY OUT:</p><p> Returned to customers during the November run: $5 billion</p><p> Amount paid out to CZ: $1.4 billion (Just the hard cash part of the payment. I&#39;m ignoring the $500 million worth of FTT Sam also paid him, as Sam minted those for free. I&#39;m also ignoring the $80 million worth of BNB tokens that CZ had used to pay for his original stake, worth $400 million at the time Sam returned them as part of his buyout of CZ&#39;s interest.)</p><p> Sam&#39;s private investments: $4.4 billion (The whole portfolio was $4.7 billion, but at least one investment, valued at $300 million, Sam had paid for with shares in FTX. He likely did the same with others, and so this number is likely bigger than it actually was.)</p><p> Loans to Sam: $1 billion (Used for political and EA donations. After his lawyers explained to him that taking out loans was smarter than paying himself a stock dividend, as he&#39;d need to pay tax on the dividends.)</p><p> Loans to Nishad for same: $543 million</p><p> Endorsement deals: $500 million (This is likely generous too, as in some cases—Tom Brady was one of them—FTX paid its endorsers with FTX stock and not dollars.) Buying and burning their exchange token,</p><p> FTT: $600 million</p><p> Corporate expenses (salaries, lunch, Bahamas real estate): $1 billion</p><p> Total: $14,443,000,000 (3,626)</p></blockquote><p> The case has been made to me that this accounting is not as naive and stupid as it looks. I continue to mostly disagree with that. Lewis continues to double down.</p><blockquote><p> There were some likely explanations for the missing money. The more you thought about them, however, the less persuasive they became. For example, Alameda traders might have gambled away $6 billion. But if they had, why did they all believe themselves to be so profitable, right to the end? I&#39;d spoken to a bunch of them. Several were former Jane Streeters. They weren&#39;t stupid. (3,462)</p></blockquote><p> This is perhaps the most &#39;naive guy&#39; thing in the entire book. Smart people can&#39;t think they are making good trades when they are making bad ones and losing tons of money, right? And they wouldn&#39;t lie to Michael Lewis about profitability, right?</p><blockquote><p> The most hand-wavy story just then being bandied about was that the collapse in crypto prices somehow sucked all the money out of Sam&#39;s World. And it was true that Sam&#39;s massive holdings of Solana and FTT—and other tokens of even more dubious value—had crashed. They&#39;d gone from being theoretically worth $100 billion at the end of 2021 to being worth practically zero in November 2022.</p><p> But Sam had paid next to nothing for these tokens; they had always been more like found money than an investment he&#39;d forked over actual dollars to acquire. He&#39;d minted FTT himself, for free. (3,647)</p></blockquote><p> At their peak, Alameda was on (some form of electronic) paper worth $100 billion or so. We know that Alameda&#39;s edge in algorithmic trades had likely been going away as they faced stiffer competition, that source of profit was likely gone, yet they continued to borrow. What was the profitable trading Alameda was doing with all that capital?</p><p> They were getting long. Alameda was borrowing a bunch of capital from various lenders, and using it to get long and then get longer. That is where the money was going.</p><p> Then Number Went Down. Money gone.</p><p> Does Michael Lewis think the people at Three Arrows Capital or Voyager were stupid? The people who created and ran Luna? Enron? Lehman Brothers? Does this man not remember his own books?</p><p> He said it himself. Sam&#39;s entire empire was a leveraged – Lewis&#39;s word – bet on the success of crypto and the empire itself more generally. When you have no ethics only a quest for Number Go Up (you know, for the common good) and therefore don&#39;t care that, sure, technically that was customer deposits right there, that leverages your bet all the more. As Number Go Down, rather than hedge, they doubled down, including via providing bailouts.</p><p> Leverage plus Number Go Down equals Broke Fi Broke, overwhelming other sources of profits.</p><p> Yes, a lot of their horde of stuff they bought for pennies. But they then used that as collateral to borrow money and put more things into the horde. All of which was correlated, and all of which was down.很多。</p><p> Also, SBF was shoving money out the door in any number of other ways that the above numbers are missing, money was constantly being misplaced or stolen, a fire sale is not a cheap thing to partake in, and so on. So I do not think there is any mystery here.</p><p> We then get a fascinating story. San says combined losses from things like this were only $1 billion, but honestly how would he even know given everything.</p><blockquote><p> But on that evening, Sam filled in one piece of this particular puzzle: FTX had lost a lot of money to hackers. To avoid encouraging other hackers, they&#39;d kept their losses quiet. The biggest hacks occurred in March and April 2021. A lone trader had opened an account on FTX and cornered the market in two thinly traded tokens, BitMax and MobileCoin.</p><p> His purchases drove up the prices of the two tokens wildly: the price of MobileCoin went from $2.50 to $54 in just a few weeks. This trader, who appeared to be operating from Turkey, had done what he had done not out of some special love for MobileCoin. He&#39;d found a flaw in FTX&#39;s risk management software. FTX allowed traders to borrow bitcoin and other easily sellable crypto against the value of their MobileCoin and BitMax holdings.</p><p> The trader had inflated the value of MobileCoin and BitMax so that he might borrow actually valuable crypto against them from FTX. Once he had it he vanished, leaving FTX with a collapsing pile of tokens and a loss of $600 million worth of crypto.</p><p> The size of those hacks was an exception, Sam said. All losses due to theft combined had come to just a bit more than $1 billion. In all cases, Gary had quietly fixed the problem and they&#39;d all moved on and allowed the thieves to keep their loot. “People playing the game,” was Sam&#39;s description of them. (He really was easy to steal from.) (3,701)</p></blockquote><p> That is not a hack. He did not steal the money. You gave it to him.</p><p> I know that people call such things hacks, like the &#39;hack&#39; about going both ways using leverage earlier. Instead, Sam is right here. this is people playing the game. If your risk engine is stupid enough to let me use my MOBL at $54 to borrow and withdraw a bunch of actual BTC, treating the value of MOBL as real, then that is on the risk engine, whether or not there was also market manipulation involved. I felt the same way about Avi and the Mango trade – yes sure it is illegal and no one is crying for him when he gets arrested nor should they, but also suck it up and write better code, everyone, as is the crypto way.</p><p> FTX&#39;s risk engine was by all accounts excellent, when dealing with coins that were liquid relative to the position sizes involved, and when the risk engine was set to on. FTX&#39;s risk engine was sometimes turned off, and the risk engine clearly did not make reasonable adjustments for illiquid or obviously bubble-shaped coins.</p><p> This also was rather a big deal – FTX lost, by Sam&#39;s own account, a full year&#39;s profits. And that&#39;s the official Sam story. The real story is inevitably much worse. I do not for a second buy that they only lost $1 billion total in hacks.</p><h4> John Ray, the Hero We Need</h4><p> John Ray is pretty great. He&#39;s the guy who cleaned up the Enron mess, the guy you call when you have a world-class mess, and he&#39;s the one they called in for FTX.</p><p> Suddenly there is a no-nonsense adult in the room who is having none of it, even when there is some of it worth having.</p><p> Michael Lewis tries his best to throw shade at him, but Lewis is too honest – too much a naive guy – for any of it to stick even a little.</p><blockquote><p> As a legal matter, at 4:30 in the morning on Friday, November 11, 2022, Sam Bankman-Fried DocuSigned FTX into bankruptcy and named John Ray as FTX&#39;s new CEO. As a practical matter, Sullivan &amp; Cromwell lined up John Ray to replace Sam as the CEO of FTX, and then John Ray hired Sullivan &amp; Cromwell as the lawyers for the massive bankruptcy. (3,772)</p><p> While Sam stewed, John Ray read up on him and this company he&#39;d created. “It&#39;s like, What is this thing?” said Ray. “Now it&#39;s just a failure, but it was once some kind of business. What did you guys do? What&#39;s the situation? Why&#39;s this falling into bankruptcy so quickly?” He briefly considered the possibility that the failure was innocent: maybe they got hacked. “Then you start looking at the kid,” said Ray, the kid being Sam. “I looked at his picture and thought, There&#39;s something wrong going on with him.”</p><p> Ray prided himself on his snap judgments. He could look at a person and in ten minutes know who they were, and never need to reconsider his opinion. The men he evaluated he tended to place in one of three bins in his mind: “good guy,” “naive guy,” and “crook.” Sam very obviously was not a good guy. And he sure didn&#39;t seem naive. (3,783)</p></blockquote><p> That&#39;s a great skill if you are consistently correct. Based on the evidence presented, John Ray is almost never wrong about what type of guy he is dealing with.</p><blockquote><p> He&#39;d spoken only long enough with the other members of Sam&#39;s inner circle to see them for what they were. Nishad Singh struck him as a naive guy. “He&#39;s narrow,” said Ray. “It&#39;s tech, tech, tech. There&#39;s never a problem he can&#39;t solve. He&#39;s not going to steal money. He&#39;s not going to do anything wrong. But he has no idea what&#39;s going on around him. You ask him for a steak and he puts his head up the bull&#39;s ass.”</p><p> The bankruptcy team had located Caroline Ellison by phone on the Saturday after Ray became FTX&#39;s new CEO. She at least had been able to explain where some of the wallets storing the crypto were stashed. Other than that, she wasn&#39;t much use. “She&#39;s cold as ice,” said Ray. “You had to buy words by the vowel. An obvious complete fucking weirdo.” (3,797)</p></blockquote><p> Nishad being a naive guy seems right to me, based on the rest of the book. He had more than enough information to know what was happening, but the Arc Words of the whole book are that people don&#39;t see what they don&#39;t look for, so there you go.</p><blockquote><p> “There&#39;s people that are born criminals, and there&#39;re people that become criminals,” said Ray. “I think [Sam] became a criminal. The how and why he became a criminal I don&#39;t know. I think maybe it takes an understanding of this kid and his parents.” (3,808)</p></blockquote><p> John Ray is here to let you know that you are suffering, and pitying, too many fools.</p><blockquote><p> Six days into his new job, Ray filed a report with the US Bankruptcy Court for the District of Delaware. “Never in my career have I seen such a complete failure of corporate controls and such a complete absence of trustworthy financial information as occurred here,” he wrote. Instead of grilling the people who had created the mess, Ray hired teams of hard-nosed sleuths—many of whom he&#39;d worked with before. “Serious adults,” as he called them. The Nardello firm was a lot of former FBI guys. (Corporate motto: We find out.) (3,822)</p></blockquote><p> First he got things under some semblance of order. He then moved on to looking for all the money.</p><blockquote><p> That was in early 2023. By late April, John Ray&#39;s head was on a swivel. “This is live-action,” he said. “There&#39;s always something every hour.” One day, some random crypto exchange got in touch and said, By the way, we have $170 million in an account of yours: do you want it back? Another day, some random FTX employee called them out of the blue to say that he&#39;d borrowed two million bucks from the company and wanted to repay the loan—of which, so far as Ray could see, there was no record. Of course, once you heard about one loan, you had to wonder how many others like it you&#39;d never hear about. (3,836)</p><p> Several months into the hunt, Ray&#39;s sleuths had discovered that “someone had robbed the exchange of four hundred fifty million.” They&#39;d stumbled upon not the simple hack of November 2022 but the complicated BitMax and MobileCoin hacks of $600 million in the spring of 2021. (The dollar value changed with fluctuations in the price of the stolen crypto.) They&#39;d tracked the hacker not to Turkey but Mauritius. “We have a picture of him going in and out of his house,” said Ray. He was pretty sure he was going to get most of that money back. “We believe there are a lot more of these,” said Ray. (3,844)</p></blockquote><p> Lewis portrays Ray in all this as an archeologist, shifting through the ruins for cash and clues. Michael Lewis makes a point of all the money Ray and his team were going to bill FTX for the work they did. I look at what they had to deal with and how much money they ultimately rounded up, and I say they earned every penny. Part of earning that is that when you are Ray, you cannot rely upon or trust anyone who made the mess in the first place. That&#39;s hostile information sources. If you want it done right, and you do, you have to figure it all out for yourself.</p><p> The best thing about Ray is his reaction to Lewis, as Lewis keeps trying to explain all the things he think he knows, and Ray keeps ignoring him, and it&#39;s going to be some of the straight up funniest scenes in the movie.</p><p> I demand that Ray be played by John Goodman, it would be so perfect.</p><blockquote><p> At some point his team discovered that a Hong Kong subsidiary of Alameda Research called Cottonwood Grove had bought vast sums of FTT, for example. To the innocent archaeologist, it was evidence of Sam&#39;s World artificially propping up the value of FTT. Ray didn&#39;t know that FTX had been obligated to spend roughly a third of its revenues buying back and burning its token, and that Cottonwood Grove was the entity that did it. From my perch on the side of the dig, I would occasionally shout down to the guy running it my guess about the most recent find, but he&#39;d just look up at me, pityingly. I was clearly a naive guy. (3,875)</p></blockquote><p>是的。 Very clearly.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://twitter.com/liron/status/1710193485763289469">We have a fun clip of Ray spelling the uselessness of Lewis to him out for us</a> .</p><p> The thing about Ray is that, in order to be so good at his job, he needs to have zero tolerance for pretty much anything. So when something actually is real, he can miss it.</p><blockquote><p> The hundreds of private investments made by Alameda Research, for instance. When we first met, in early 2023, Ray went on about how fishy these all were. He had a theory about why Sam had thrown money around the way he had: Sam was buying himself some friends. “For the first time in his life, everyone ignores the fact that he&#39;s a fucking weirdo,” said Ray. As an example, he cited the dollars Sam had invested in artificial intelligence companies. “He gave five hundred million bucks to this thing called Anthropic,” said Ray. “It&#39;s just a bunch of people with an idea. Nothing.” (3,886)</p></blockquote><p> Lewis would say this theory is ridiculous, and on its face it definitely is, everyone wanted to be Sam&#39;s friend, but also how much got invested into OpenAI and Anthropic in the name of access? As in, friendship?</p><p> What Ray cannot see is that Anthropic was obviously a very good financial investment, because he does not know anything about AI. He certainly does not want to hear anything about existential risk, or whether Anthropic is helping or not helping with that concern.</p><p> A key question was, what crypto was worth anything, and what wasn&#39;t? For some reason Ray locked onto Serum, the offshoot of Solana.</p><blockquote><p> And yet now, somehow, in John Ray&#39;s book, the locked Serum was good shit. Primo crypto of the finest vintage imbibed by all gentlemen of good taste. And who knows?—maybe one day it will be. But if Serum was a token to be taken seriously, Sam Bankman-Fried and the world he created needed to be viewed in a different light. At Serum&#39;s peak price, the stated market value of Sam&#39;s stash of it was $67 billion. On November 7, 2022, Sam&#39;s pile of mostly locked Serum was still “worth” billions of dollars. If even locked Serum had that kind of value, FTX was solvent right up to the moment it collapsed. And John Ray would have no grounds for clawing back money from any of the many lucky people on whom Sam Bankman-Fried had showered it. (3,988)</p></blockquote><p> In case you didn&#39;t know, well, not so much, here&#39;s Serum.</p><figure class="wp-block-image"> <a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97383cf9-4143-4ecb-b3e0-1a17c745e6eb_1200x678.png" target="_blank" rel="noreferrer noopener"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AocXh6gJ9tJC2WyCL/rp7lxlwubyh5wxvo8tuu" alt=""></a></figure><p> Ray kept searching, Ray kept finding.</p><blockquote><p> That would raise the amount collected to $9.3 billion—even before anyone asked CZ for the $2.275 billion he&#39;d taken out of FTX. Ray was inching toward an answer to the question I&#39;d been asking from the day of the collapse: Where did all that money go? The answer was: nowhere. It was still there. (4,000)</p></blockquote><h4> Caroline Ellison</h4><p> Sam&#39;s on-again, off-again, very-bad-idea relationship with Caroline Ellison is a key part of the story, because Caroline ended up effectively in charge of Alameda when the worst of the fraud went down. It does not seem like a coincidence that Caroline ended up in charge of Alameda, despite her not seeming like someone who should be given that kind of responsibility, as per (among other signs) her repeated observations that she was not up to the job.</p><p> Also she did not have an ideal attitude with respect to willingness to do various crimes, where the whole thing made her deeply uncomfortable but she still did the crimes anyway – you want someone who does not do crimes, or contains their crimes to contextually &#39;ordinary decent crimes&#39; rather than outright frauds like stealing customer funds. Or if you have decided that your plan is to do a lot of crimes, a plan I recommend strongly against, you want someone who is fine with doing lots of crime.</p><p> In any case, Caroline it seems exchanged long emails spelling out the arguments for exactly how obviously she and Sam should not have been dating, with Sam offering points like this:</p><blockquote><p> [Sam] began with a seriously compelling list, titled: ARGUMENTS AGAINST:</p><p> In a lot of ways I don&#39;t really have a soul. This is a lot more obvious in some contexts than others. But in the end there&#39;s a pretty decent argument that my empathy is fake, my feelings are fake, my facial reactions are fake. I don&#39;t feel happiness. What&#39;s the point in dating someone who you physically can&#39;t make happy? I have a long history of getting bored and claustrophobic. This has the makings of a time when I&#39;m less worried about it than normal; but the baseline prior might be high enough that nothing else matters. I feel conflicted about what I want. Sometimes I really want to be with you. Sometimes I want to stay at work for 60 hours straight and not think about anything else. I&#39;m worried about power dynamics between us. This could destroy Alameda if it goes really poorly PR-wise. This combos really badly with the current EA shitshow I&#39;m supposed to be, in some ways, adjudicating. I make people sad. Even people who I inspire, I don&#39;t really make happy. And people who I date—it&#39;s really harrowing.</p><p> It really fucking sucks, to be with someone who (a) you can&#39;t make happy, (b) doesn&#39;t really respect anyone else, (c) constantly thinking really offensive things, (d) doesn&#39;t have time for you, and (e) wants to be alone half the time. There are a lot of really fucked up things about dating an employee.</p><p> This list was followed by another, briefer list, titled “ARGUMENTS IN FAVOR.” I really fucking like you. I really like talking to you. I feel a lot less worried about saying what&#39;s on my mind to you than to almost anyone else. You share my most important interests. You&#39;re a good person. I really like fucking you. You&#39;re smart and impressive. You have good judgement and aren&#39;t full of shit. You appreciate a lot of me for who I am. (2,126)</p></blockquote><p> While I admit those are actually pretty strong arguments in favor, and in other circumstances would be very good reasons to date someone, the arguments against seem rather conclusive.</p><blockquote><p> Caroline wanted a conventional love with an unconventional man. Sam wanted to do whatever at any given moment offered the highest expected value, and his estimate of her expected value seemed to peak right before they had sex and plummet immediately after. (2,155)</p></blockquote><p> This is exactly what one would expect from the rest of Sam&#39;s behavior in other contexts. Story checks out.</p><p> That I guess brings us to the psychiatrist? Who according to other reports had the entire firm including Sam hopped up on various pills in ways the book declines to mention?</p><blockquote><p> It didn&#39;t take a psychiatrist to see a pattern in Sam&#39;s relationship with Caroline, but there happened to be one sitting in the middle of it. His name was George Lerner, and by late 2021 he might have been the world&#39;s leading authority on the inner life of effective altruists. (2,208)</p></blockquote><p> I know of at least two psychiatrists who were and are better experts on this than George Lerner. For example, have you met… Scott Alexander?反正。</p><blockquote><p> Then the effective altruists started showing up—and when they did, George took a new and keener interest in his patients. Gabe Bankman-Fried, Sam&#39;s younger brother, was the first, but hard on his heels came Caroline Ellison and others from Alameda Research. By the time Sam arrived, a year later, George was treating maybe twenty EAs. As a group, they eased a worry George had about himself: the limits to his powers of empathy. When ordinary people came to him with their ordinary feelings, he often found himself faking an understanding. The EAs didn&#39;t need his empathy; the EAs thought that even they shouldn&#39;t care about their feelings. In their single-minded quest to maximize the utility of their lives, they were seeking to minimize the effect of their feelings. In their single-minded quest to maximize the utility of their lives, they were seeking to minimize the effect of their feelings. “The way they put it to me is that their emotions are getting in the way of their ability to reduce their decisions to just numbers.” (2,238)</p><p> They were all completely and utterly sincere. They judged the morality of any action by its consequences and were living their life to maximize those consequences. (2,249)</p></blockquote><p>你不能那样做。 I mean, obviously you literally can, but professionally no, you really, really can&#39;t treat Gabe and his brother Sam and his girlfriend and employee Caroline and everyone else in their entire social network. This is Dr. Nick territory. Then again, given what everyone involved wanted, maybe you can? It&#39;s not like they wanted anything from him except drugs and practical advice understanding other people. Maybe there is no conflict of interest here after all.</p><p> Also, who cares, given George didn&#39;t even have a license in the Bahamas in the first place?</p><blockquote><p> The Bahamas hadn&#39;t granted George a medical license. His title was Senior Professional Coach. (2,633)</p></blockquote><p> Perhaps he was taking inspiration from the (nominal) psychiatrist in Billions?</p><h4> New and Old EA Cause Areas</h4><p> In addition to his EA causes, SBF did have his own cause area, which was physical beauty.</p><p> He was against it.</p><blockquote><p> [Anna Wintour of Vogue] looked like a million bucks, but her art, like all art, was wasted on Sam. (235)</p><p> “You start by making decisions on who you are going to be with based on how they look,” he said. “Then, because of that, you make bad choices about religion and food and everything else. Then you are just rolling the dice on who you are going to be.”</p><p> Anna Wintour, now that he thought of it, represented much of what he disliked about human beings. “There are very few businesses that I have strong moral objections to, and hers is one of them,” he said. “I actually have disdain for fashion. I have general disdain for the importance that physical attractiveness has, and this is one thing emanating out of that.” (348)</p></blockquote><p> He also investigated but dismissed as a child <a target="_blank" rel="noreferrer noopener" href="https://unsongbook.com/">the cause area of hell</a> .</p><blockquote><p> He found his way to a solution that offered temporary relief: only children suffered from this madness. Yes, kids believed in Santa. But grown-ups did not. There was a limit to the insanity. But then, a year or so later, a boy in his class said he believed in God.</p><p> “And I freaked out,” recalled Sam. “Then he freaked out. We both freaked out. I remember thinking, Wait a minute, do you think I&#39;m going to hell? Because that seems like a big deal. If hell exists, why do you, like, care about McDonald&#39;s? Why are we talking about any of this shit, if there is a hell. If it really exists. It&#39;s fucking terrifying, hell.”</p><p> From the widespread belief in God, and Santa, Sam drew a conclusion: it was possible for almost everyone to be self-evidently wrong about something. “Mass delusions are a property of the world, as it turns out,” he said.</p></blockquote><p> According to the company psychiatrist, the EAs really did only care about suffering.</p><blockquote><p> “It doesn&#39;t really start with people,” said George. “It starts with suffering. It&#39;s about preventing suffering.” (2,257)</p></blockquote><p> This attitude drives me bonkers. Yes, suffering is bad. It is the way we indicate to ourselves that things are bad.太糟糕了。 Preventing it is a good idea. But when you think that suffering is the thing that matters, you confuse the map for the territory, the measure for the man, the math with reality. Combine that with all the other EA beliefs, set this as a maximalist goal, and you get… well, among other things, you get FTX. Also you get people worried about wild animal or electron suffering and who need hacks put in to not actively want to wipe out humanity.</p><p> If you do not love life, and you do not love people, or anything or anyone within the world, and instead wholly rely on a proxy metric? If you do not have Something to Protect?不好了。</p><p> I mean, listen to yourselves, as George is describing you:</p><blockquote><p> “A lot of EAs chose not to have kids,” said George. “It&#39;s because of the impact on their own lives. They believe that having kids takes away from their ability to have impact on the world.” After all, in the time it took to raise a child to become an effective altruist, you could persuade some unknowably large number of people who were not your children to become effective altruists. “It feels selfish to have a kid. The EA argument for having a kid is that kid equals happiness and happiness equals increased productivity. If they can get there in their head, then maybe they have a kid.” (2,261)</p><p> “There are two parts of being EA,” said George. “Part one is the focus on consequences. Part two is the personal sacrifice.” (2,267)</p></blockquote><p> That is saying, my own child&#39;s only value would be if they too become an effective altruist, or if they increase my altruistic productivity. This is not an attitude compatible with life. If this is you, please halt, catch fire and seek help immediately.</p><p> This last point does not ring true, EAs totally complain about lack of dating opportunities, although I can totally buy that everyone else thought the EAs thought they were smarter than everyone else – and in context, that they were technically right.</p><blockquote><p> “Everyone is complaining about the lack of dating opportunities,” said George. “Except the EAs. The EAs didn&#39;t care.”</p><p> The non-EAs thought the EAs thought they were smarter than everybody else. (2,628)</p></blockquote><p> As much as I criticize EAs, I do it because they are worthy of criticism. They aspire to do better. Otherwise I wouldn&#39;t waste my time. And when Lewis goes too far and misses the mark, there&#39;s big &#39;no one picks on my brother but me&#39; energy.</p><blockquote><p> One day some historian of effective altruism will marvel at how easily it transformed itself. It turned its back on living people without bloodshed or even, really, much shouting. You might think that people who had sacrificed fame and fortune to save poor children in Africa would rebel at the idea of moving on from poor children in Africa to future children in another galaxy. They didn&#39;t, not really—which tells you something about the role of ordinary human feeling in the movement. It didn&#39;t matter. What mattered was the math. Effective altruism never got its emotional charge from the places that charged ordinary philanthropy. It was always fueled by a cool lust for the most logical way to lead a good life. (3,045)</p></blockquote><p> We rationalists have long had a name for the &#39;emotional charge&#39; that drives ordinary philanthropy. <a target="_blank" rel="noreferrer noopener" href="https://www.lesswrong.com/posts/3p3CYauiX8oLjmwRF/purchase-fuzzies-and-utilons-separately">We call it &#39;cute puppies with rare diseases.</a> &#39; There is a reason most philanthropy accomplishes nothing except fueling that emotional charge, which is that most decisions in most philanthropy are driven by fueling that emotional charge. The entire point, the founding principle, of EA, the core of what is good about EA, is to care about actually accomplishing the mission and cutting the enemy.</p><p> Can this be taken too far in various ways to the point where it loses its connection to reality? Does relying too much on the math and not enough on common sense and error checks lead to not noticing wrong conclusions are wrong? Oh yes, this absolutely happens in practice, the SBF group was not so extreme an outlier here.</p><p> But at least the crazy kids are trying.完全没有。 They get to be wrong, where most others are not even wrong.</p><p> Also, future children in another galaxy? Try our own children, here and now. People get fooled into thinking that &#39;long term&#39; means some distant future. And yes, in some important senses, most of the potential value of humanity lies in its distant future.</p><p> But the dangers we aim to prevent, the benefits we hope to accrue? They are not some distant dream of a million years from now. They are for people alive today. You, yes you, and your loved ones and friends and if you have them children, are at risk of dying from AI or from a pandemic. Nor are these risks so improbable that one needs to cite future generations for them to be worthy causes.</p><p> I fight the possibility of AI killing everyone, not (only or even primarily) because of a long, long time from now in a galaxy far, far away. I fight so I and everyone else will have grandchildren, and so that those grandchildren will live. Here and now.</p><p> If some other EAs made this change because the numbers (overwhelmingly, and in this case I believe correctly) said so, and would have done so even if the case was less overwhelmingly correct? So be it. We need some people like that. Others need to help with global poverty, and so they do. And they make a lot of mistakes there too, they take the math too seriously, they don&#39;t consider second and third order effects properly, and so on. I could go on rants.但你知道吗？ They try, damn it.</p><p> As opposed to ordinary philanthropy, where the EAs are right: It&#39;s mostly kinda dumb.</p><blockquote><p> They&#39;d been doing this for only a year and already had been pitched nearly two thousand such projects. They&#39;d handed out some money but in the process they&#39;d concluded that conventional philanthropy was kind of dumb. Just to deal with the incoming requests—most of which they had no ability to evaluate—would require a big staff and lots of expense. Much of their money would end up being used on a vast bureaucracy.</p><p> And so they had just recently adopted a new approach: instead of giving money away themselves, they scoured the world for subject matter experts who might have their own, better ideas for how to give away money.</p><p> Over the previous six months, one hundred people with deep knowledge of pandemic prevention and artificial intelligence had received an email from FTX that said, in effect: Hey, you don&#39;t know us, but here&#39;s a million dollars, no strings attached. Your job is to give it away as effectively as you can.</p><p> The FTX Foundation, started in early 2021, would track what these people did with their million dollars, but only to determine if they should be given even more. “We try not to be very judgy once they have the money,” said Sam. “But maybe we won&#39;t be reupping them.” (3,060)</p><p> They were moving fast, as Sam always did. “If you throw away a quarter of the money, that&#39;s very sad,” he said at one point, “but if it allows you to triple the effectiveness of the rest, that&#39;s a win.” (3,073)</p></blockquote><p> This was a really good idea, in the world in which FTX had properly secured the money in order to give it away, and in which they had the proper infrastructure to do this responsibly. Even without either of those things, it was still a reasonable idea.</p><p> There were problems. People were unprepared to hand out a million dollars. A lot of decisions involving a lot of money got made, if not Brewster&#39;s Millions style, in ways that were quite warping on the places the money got spread around. From what I heard, essentially any 19-year-old could get a $50,000 grant to move to Berkeley and think about AI safety, and there was a general failure to differentiate good and real and worthwhile efforts from others. The dynamics this created were an invitation to fake work, to predators and entryism and sociopaths, to hype and networks and corruption. If things had continued, that effect could have gotten worse.</p><p> As always, Sam was not considering second-order effects, and also not considering that efforts might backfire rather than be wasted. Nor did he pay enough attention to one of the most important questions traders always must ask on every trade they do, which is: What is the correct sizing?</p><p> Doing this trade with only a select few would have been great. Doing it with everyone who had an EA identity and a pulse was plausibly net negative.</p><h4> Won&#39;t Get Fooled Again</h4><p> In the wake of publication, many people pointed out that Michael Lewis had been fooled, <a target="_blank" rel="noreferrer noopener" href="https://nymag.com/intelligencer/2023/10/how-michael-lewis-got-duped-by-sam-bankman-fried.html">including this book report from David Roth</a> . <a target="_blank" rel="noreferrer noopener" href="https://time.com/6321668/michael-lewis-sam-bankman-fried-going-infinite/">Michael Lewis did not take kindly to this</a> , while confirming he had been fooled.</p><blockquote><p> Michael Lewis: I&#39;d love for the jury to read the book. Mark Cohen [Sam Bankman-Fried&#39;s lawyer] said this to me: “You get up, you tell one story, and they tell the other story, and the question is which story the jury believes.” I&#39;m in a privileged position to tell a fuller story, without leaving out any of the nasty details. If I were a juror, I would rather hear my story than either defense or prosecution.</p><p> I&#39;m just going to tell you the story as I see it, and then leave you the discretion that then you lynch him, acquit him, or don&#39;t know what to think of him. I don&#39;t want the jury thinking I left anything else they needed to know.</p><p> There&#39;s something about Sam and the situation that pushes a lot of people&#39;s buttons and causes them to want to judge quickly. If I had five hours with the prosecutors, one of the things I would love to know is why they moved so fast. Sam&#39;s lawyers had a guy on the inside and outside advising on when he might be extradited from the Bahamas. And no way did they think it was gonna happen as fast as it did, because they thought it would take the government much longer to figure out what the hell happened.</p><p> I thought that was of a piece with the general social response: how quick people wanted to judge. So I thought, I&#39;m going to be dealing with a reader who is going to be in that judgy kind of mood.</p></blockquote><p> He really thinks he included all the nasty details. The trial has made it clear this was not the case. <a target="_blank" rel="noreferrer noopener" href="https://thezvi.substack.com/p/sadly-ftx">Even my old post on FTX</a> , among many other source options, also made it clear this was not the case.</p><p> As does the book. The book, despite conspicuously leaving out all the most blatant details, repeatedly shows SBF doing fraud.</p><p> Even more than that, the book describes a person who is so obviously doing all the fraud. It would not make any sense for the Sam portrayed here to not be doing all the fraud. That much is clear by the end of chapter one. Did Lewis read his own book?</p><p> The idea that the arrest was a &#39;rush to judgment&#39; is laughable. Sure, they partly moved quickly because it was important to send a message – which it was – but also because no one else has ever more obviously been doing all the crime. There are so many distinct frauds right out in the open.</p><p> Also, seriously, what the hell, you want to poison the jury pool or even the actual jury? The interviewer points out how our system works, and Lewis says no, it shouldn&#39;t work that way, people should read my book.</p><p> At one point, Lewis confirms that FTX violated the Foreign Corrupt Practices Act, as was revealed during the trial, and also perhaps as tellingly that it put a billion dollars into an account at an exchange that regularly freezes accounts frozen by the local police for no reason.</p><p> And Lewis is wondering how the money could be missing.</p><blockquote><p> Michael Lewis: This is what happened, to my knowledge—and I know this from the people in Hong Kong who orchestrated it—a Chinese exchange was routinely targeted by local Chinese police departments. They would find a pretext for freezing an account. In this case, they froze Alameda&#39;s account. And Alameda had like a billion dollars in this account.</p><p> There was an operation inside of FTX, or Alameda, whatever, in Hong Kong, to legitimately get the money back without having to go pay the ransom. And they pursued that, and it didn&#39;t work. So they went in and paid ransom to the Chinese police department directly to get the money released, and it was released.</p><p> I actually would have loved to include it. But they weren&#39;t running around bribing people to change laws. It was more telling about how the Chinese government works than anything about Sam. I then came back and confirmed it all with Sam. He said he knew he&#39;d sent someone in to get the money out, but he wasn&#39;t completely sure how he&#39;d gotten the money out.</p></blockquote><p> Next he admits that SBF committed bank fraud.</p><blockquote><p> Michael Lewis: My impression was that the bank wasn&#39;t actually misled about who these people were. That it was a kind of fig leaf thing.</p><p> Q: But it&#39;s still illegal to mislead a bank about the purpose of a bank account.</p><p> Michael Lewis: But nobody would have cared about it.</p></blockquote><p> He seems to not understand that this does not make it not a federal crime? That &#39;we probably would not have otherwise gotten caught on this one&#39; is not a valid answer?</p><p> Similarly, Lewis clearly thinks &#39;the money was still there and eventually people got paid back&#39; should be some sort of defense for fraud. It isn&#39;t, and it shouldn&#39;t be.</p><p> And then there&#39;s this:</p><blockquote><p> Michael Lewis: No one shows me receipts. But no one suggested otherwise. I interviewed 10 people in Alameda. They just weren&#39;t lying. None of them could think of a big loss.</p><p> …</p><p> But I was kind of there through it. And there was no detectable change in Caroline, Nishad, Sam: their interactions or their demeanors. If they had this sharp, swift loss, they were really, really good with their poker faces.</p></blockquote><p> All right, that is a purer Naive Guy statement. They just weren&#39;t lying, no sir.</p><p> Nor was Sam a liar, in Lewis&#39;s eyes. Michael Lewis continued to claim, on the Judging Sam podcast, that he could trust Sam completely. That Sam would never lie to him. True, Lewis said, Sam would not volunteer information and he would use exact words. But Sam&#39;s exact words to Lewis, unlike the words he saw Sam constantly spewing to everyone else, could be trusted.</p><p> It&#39;s so weird. How can the same person write a book, and yet not have read it?</p><p> Even then, on October 1, Lewis was claiming he did not know if Sam was guilty. Not only that, he was claiming that many of the prosecutors did not know if Sam was guilty. And Lewis keeps saying that Sam himself really actually believes he is innocent, and for weeks after it was so over Sam really believed he&#39;d be able to raise funds and turn it all around.</p><p> Lewis really did believe, or claimed to believe on his podcast, even in early October that, absent one little mistake where $8 billion dollars ended up in the wrong place, the rest of what happened was fine. That the rest of the story was not filled to the brim with all the crime.</p><p> Yet I totally believe that Lewis believed all of it. The man seems so totally sincere.</p><p> Then on October 9 Lewis said nothing that came out so far at the trial surprised him, other than the claim by one of Sam&#39;s oldest friends that Alameda&#39;s special code not only let them steal all the money, it also let them trade faster than their competitors, implemented on Sam&#39;s orders. Everyone was constantly asking point blank about that, and Sam constantly said that wasn&#39;t true. Even so, Lewis still repeated that in his model Sam doesn&#39;t outright lie, he simply doesn&#39;t tell you the answer that you needed to hear. He was still holding onto that even then.</p><p> When it is revealed that the FTX insurance fund to cover trading losses, that Sam often talks about, was purely fake, literally the product of a random number generator written into the code to display to people to make them think there was an insurance fund? Because to Sam money is fungible, so why would there be an insurance fund? Still no change.</p><p> I still can&#39;t process all that. Not really. <a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=aV6NoNkDGsU&amp;t=132s&amp;pp=ygURY2hld2JhY2NhIGRlZmVuc2U%3D">Chewbaca is a wookie</a> . It does not make sense.</p><p> He has Matt Levine on the podcast, and Matt Levine points out that the book made it that much clearer that Sam&#39;s fraud unfolded exactly the way frauds always unfold, that there was nothing confusing here. Yeah, on some level Sam fooled himself that would all work out (or, given it was Sam, that it had odds, and the words &#39;safe&#39; and &#39;risk&#39; were meaningless, so who cares?).</p><p> In later podcasts, Lewis did admit that a lot of the trial testimony was rather damning, and that he is confident that Sam will be convicted. But there is no sign he has figured out that Sam was doing all the lying and all the crime.</p><h4>结论</h4><p>I mostly feel good closing the book on the events of SBF, Alameda and FTX.这一切都是有道理的。 We know what happened.</p><p> There are still a few mysteries, mostly centered on early Alameda. The story there, as outlined, continues not to make sense. Why was it so difficult to evaluate ModelBot? What was going on with the demands of those exiting? How did SBF get away with so little reputation damage? I still do want to know. Mostly, though, I am content.</p><p> <a target="_blank" rel="noreferrer noopener" href="https://thezvi.substack.com/p/sadly-ftx">My previous post on FTX</a> holds up remarkably well, and could be used as a companion piece to this one. I was missing pieces of the puzzle, and definitely made mistakes, including the failure to buy up FTX debt for pennies on the dollar. But the rough outline there of what happened holds up, as does the discussion of implications for Effective Altruism.</p><p> I do not think that any of what happened was an accident. SBF was fortunate to get as far as he did before it all blew up. A blow up was the almost inevitable result. While SBF went off the rails, he went off the rails in ways that should have been largely predicted, and which make sense given who he was and then the forces and philosophical ideas that acted upon him.</p><p> This was not so unusual a case of fraud.</p><p> Nor was it an unusual case of what happens when a maximalist goal is given to a highly capable consequentialist system.</p><p> My expectation is that in the unlikely scenario that this attempted takeoff had fully succeeded, and SBF had gained sufficient affordances and capabilities thereby, that the misalignment issues involved would have almost certainly destroyed us all, or all that we care about. Luckily, that did not come to pass.</p><p> Other attempts are coming.</p><p>所有这一切以前都发生过。</p><p> All of this will happen again.</p><br/><br/> <a href="https://www.lesswrong.com/posts/AocXh6gJ9tJC2WyCL/book-review-going-infinite#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/AocXh6gJ9tJC2WyCL/book-review-going-infinite<guid ispermalink="false"> AocXh6gJ9tJC2WyCL</guid><dc:creator><![CDATA[Zvi]]></dc:creator><pubDate> Tue, 24 Oct 2023 15:00:13 GMT</pubDate> </item><item><title><![CDATA[[Interview w/ Quintin Pope] Evolution, values, and AI Safety]]></title><description><![CDATA[Published on October 24, 2023 1:53 PM GMT<br/><br/><p> On the Futurati Podcast, we recently released an <a href="https://www.youtube.com/watch?v=XLDdG9DR7ek">interview with Quintin Pope</a> .</p><p> As you can imagine, it mostly focused on:</p><ul><li> Inner vs outer optimization;</li><li> The sharp left turn;</li><li> Natural selection, and what kind of evidence we can draw from the emergence of the first great general intelligence;</li><li> AI Safety more broadly;</li><li> How human values form;</li></ul><p>一探究竟！ And share it if you&#39;d like us to do more interviews like this :)</p><br/><br/> <a href="https://www.lesswrong.com/posts/c9W4SHa7DHwAHkqRF/interview-w-quintin-pope-evolution-values-and-ai-safety#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/c9W4SHa7DHwAHkqRF/interview-w-quintin-pope-evolution-values-and-ai-safety<guid ispermalink="false"> c9W4SHa7DHwAHkqRF</guid><dc:creator><![CDATA[fowlertm]]></dc:creator><pubDate> Tue, 24 Oct 2023 13:53:06 GMT</pubDate> </item><item><title><![CDATA[Lying is Cowardice, not Strategy]]></title><description><![CDATA[Published on October 24, 2023 1:24 PM GMT<br/><br/><p> <i>(Co-written by</i> <a href="https://twitter.com/npcollapse"><i><u>Connor Leahy</u></i></a> <i>and</i> <a href="https://twitter.com/Gabe_cc"><i><u>Gabe</u></i></a> <i>)</i></p><p> We have talked to a whole bunch of people about pauses and moratoriums. Members of the AI safety community, investors, business peers, politicians, and more.</p><p> Too many claimed to pursue the following approach:</p><ol><li> It would be great if AGI progress stopped, but that is infeasible.</li><li> Therefore, I will advocate for what I think is feasible, even if it is not ideal.</li><li> The Overton window being what it is, if I claim a belief that is too extreme, or endorse an infeasible policy proposal, people will take me less seriously on the feasible stuff.</li><li> Given this, I will be tactical in what I say, even though I will avoid stating outright lies.</li></ol><p> Consider if this applies to you, or people close to you.</p><p> If it does, let us be clear: <strong>hiding your beliefs</strong> , in ways that predictably leads people to believe false things, <strong>is lying</strong> . This is the case regardless of your intentions, and regardless of how it feels.</p><p> Not only is it morally wrong, it makes for a terrible strategy. As it stands, the AI Safety Community itself can not coordinate to state that we should stop AGI progress right now!</p><p> Not only can it not coordinate, <strong>the AI Safety Community is defecting, by making it more costly for people who do say it to say it.</strong></p><p> We all feel like we are working on the most important things, and that we are being pragmatic realists.</p><p> <a href="https://www.forbes.com/sites/carltonreid/2018/12/03/you-are-not-stuck-in-traffic-you-are-traffic/"><strong><u>But remember: If you feel stuck in the Overton window, it is because YOU ARE the Overton window.</u></strong></a></p><p> —</p><h1> 1. The AI Safety Community is making our job harder</h1><p> <strong>In a saner world, all AGI progress should have already stopped. If we don&#39;t, there&#39;s more than a 10% chance we all die.</strong></p><p> Many people in the AI safety community believe this, but they have not stated it publicly. Worse, they have stated <i>different beliefs</i> more saliently, which misdirect everyone else about what should be done, and what the AI safety community believes.</p><p> To date, in our efforts to inform, motivate and coordinate with people: People in the AI Safety Community publicly lying has been one of <strong>the biggest direct obstacles we have encountered.</strong></p><p> The newest example of this is ”Responsible Scaling Policies”, with many AI Safety people being much more vocal about their endorsement of RSPs than their private belief that in a saner world, all AGI progress should stop right now.</p><p> Because of them, we have been told many times that we are a minority voice, and that most people in the AI Safety community (understand, Open Philanthropy adjacent) disagree that we should stop all AGI progress right now.</p><p> <strong>That actually, there is an acceptable way to continue scaling! And given that this makes things easier, if there is indeed an acceptable way to continue scaling, this is what we should do, rather than stop all AGI progress right now!</strong></p><p> Recently, Dario Amodei (Anthropic CEO), has used the RSP to frame the moratorium position as <a href="https://www.lesswrong.com/posts/mcnWZBnbeDz7KKtjJ/rsps-are-pauses-done-right?commentId=WhxB66vEeRhh6kcsB"><strong><u>the most extreme version of an extreme position</u></strong></a> , and this is the framing that we have seen used over and over again. ARC <a href="https://evals.alignment.org/blog/2023-09-26-rsp/"><u>mirrors</u></a> this in their version of the RSP proposal, describing itself as a “pragmatic middle ground” between a moratorium and doing nothing.</p><p> <strong>Obviously, all AGI Racers use this against us when we talk to people.</strong></p><p> There are very few people that we have consistently seen publicly call for a <strong>stop</strong> to AGI progress. The clearest ones are Eliezer&#39;s “ <a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/"><u>Shut it All Down</u></a> ” and Nate&#39;s “ <a href="https://twitter.com/So8res/status/1715380167911067878"><u>Fucking stop</u></a> ”.</p><p> The loudest silence is from Paul Christiano, whose RSPs are being used to safety-wash scaling.</p><p> <strong>Proving me wrong is very easy. If you do believe that, in a saner world, we would stop all AGI progress right now, you can just write this publicly.</strong></p><p> <strong>When called out on this, most people we talk to just fumble.</strong></p><h1> 2. Lying for Personal Gain</h1><p> We talk to many people who publicly lie about their beliefs.</p><p> The justifications are always the same: “it doesn&#39;t feel like lying”, “we don&#39;t state things we do not believe”, “we are playing an inside game, so we must be tactical in what we say to gain influence and power”.</p><p> <strong>Let me call this for what it is: lying for personal gain.</strong> If you state things whose main purpose is to get people to think you believe something else, and you do so to gain more influence and power: <strong>you are lying for personal gain.</strong></p><p> The results of this “influence and power-grabbing” has many times over materialised with the safety-washing of the AGI race. What a coincidence it is that DeepMind, OpenAI and Anthropic are all related to the AI Safety community.</p><p> The only benefit we see from this politicking is the people lying gain more influence, while the time we have left to AGI keeps getting shorter.</p><p> <strong>Consider what happens when a community rewards the people who gain more influence by lying!</strong></p><p> —</p><p> So many people lie, and they screw not only humanity, but one another.</p><p> Many AGI corp leaders will privately state that in a saner world, AGI progress should <strong>stop</strong> , but they will not state it because it would hurt their ability to race against each other!</p><p> Safety people will lie so that they can keep ties with labs in order to “pressure them” and seem reasonable to politicians.</p><p> Whatever: they just lie to gain more power.</p><p> <strong>“DO NOT LIE PUBLICLY ABOUT GRAVE MATTERS” is a very strong baseline. If you want to defect, you need a much stronger reason than “it will benefit my personal influence, and I promise I&#39;ll do good things with it”.</strong><br><br> And you need to accept the blame when you&#39;re called out. You should not muddy the waters by justifying your lies, covering them, telling people they misunderstood, and try to maintain more influence within the community.</p><p> We have seen so many people be taken in this web of lies: from politicians and journalists, to engineers and intellectuals, all up until the concerned EA or regular citizen who wants to help, but is confused by our message when it looks like the AI safety community is ok with scaling.</p><p> <strong>Your lies compound and make the world a worse place.</strong></p><p> There is an easy way to fix this situation: we can adopt the norm of publicly stating our true beliefs about grave matters.</p><p> If you know someone who claims to believe that in a saner world we should stop all AGI progress, <strong>tell them to publicly state their beliefs, unequivocally</strong> . Very often, you&#39;ll see them fumbling, caught in politicking. And not that rarely, you&#39;ll see that they actually want to keep racing. In these situations, you might want to <a href="https://www.lesswrong.com/tag/conflict-vs-mistake"><u>stop finding excuses for them</u></a> .</p><h1> 3. The Spirit of Coordination</h1><p> A very sad thing that we have personally felt is that it looks like many people are <strong>so tangled in these politics that they do not understand what the point of honesty even is</strong> .</p><p> Indeed, from the inside, it is not obvious that honesty is a good choice. If you are honest, publicly honest, or even adversarially honest, you just make more opponents, you have less influence, and you can help less.</p><p> This is typical deontology vs consequentialism. Should you be honest, if from your point of view, it increases the chances of doom?</p><p> The answer is <strong>YES</strong> .</p><p> <strong>a) Politicking has many more unintended consequences than expected.</strong></p><p> Whenever you lie, you shoot potential allies at random in the back.<br> Whenever you lie, you make it more acceptable for people around you to lie.</p><p> <strong>b) Your behavior, especially if you are a leader, a funder or a major employee (first 10 employees, or responsible for >;10% of the headcount of the org), ripples down to everyone around you.</strong></p><p> <strong>People lower in the respectability/authority/status ranks do defer to your behavior.</strong><br> <strong>People outside of these ranks look at you.</strong><br> Our work toward stopping AGI progress becomes easier whenever a leader/investor/major employee at Open AI, DeepMind, Anthropic, ARC, Open Philanthropy, etc. states their beliefs about AGI progress more clearly.<br></p><p> <strong>c) Honesty is Great.</strong></p><p> Existential Risks from AI are now going mainstream. Academics talk about it. Tech CEOs talk about it. You can now talk about it, not be a weirdo, and gain more allies. Polls show that even non-expert citizens <a href="https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll"><u>express diverse opinions</u></a> about super intelligence.</p><p> Consider the following timeline:</p><ul><li> ARC &amp; Open Philanthropy state in a press release “ <strong>In a sane world, all AGI progress should stop. If we don&#39;t, there&#39;s more than a 10% chance we will all die.</strong> ”</li><li> People at AGI labs working in the safety teams echo this message publicly.</li><li> AGI labs leaders who think this state it publicly.</li><li> We start coordinating explicitly against orgs (and groups within orgs) that race.</li><li> We coordinate on a plan whose final publicly stated goal is to get to a world state that, most of us agree is not one where humanity&#39;s entire existence is at risk.</li><li> We publicly, relentlessly optimise for this plan, without compromising on our beliefs.</li></ul><p> <strong>Whenever you lie for personal gain, you fuck up this timeline.</strong></p><p> When you start being publicly honest, you will suffer a <i>personal</i> hit in the short term. But we truly believe that, coordinated and honest, we will have timelines much longer than any Scaling Policy will ever get us.</p><br/><br/> <a href="https://www.lesswrong.com/posts/qtTW6BFrxWw4iHcjf/lying-is-cowardice-not-strategy#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/qtTW6BFrxWw4iHcjf/lying-is-cowardice-not-strategy<guid ispermalink="false"> qtTW6BFrxWw4iHcjf</guid><dc:creator><![CDATA[Connor Leahy]]></dc:creator><pubDate> Tue, 24 Oct 2023 13:24:26 GMT</pubDate> </item><item><title><![CDATA[Anyone Else Using Brilliant?]]></title><description><![CDATA[Published on October 24, 2023 12:12 PM GMT<br/><br/><p> I started using Brilliant, and so far I&#39;ve found it to be a lot like Thinking Physics - teaching by posing real-world conundrums and then explaining the concepts and/or math behind the answers.</p><p> Anyone else getting something out of it, or have advice for how to use it?</p><br/><br/> <a href="https://www.lesswrong.com/posts/HmeKF2mRRLfkG68X4/anyone-else-using-brilliant#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/HmeKF2mRRLfkG68X4/anyone-else-using-brilliant<guid ispermalink="false"> HmeKF2mRRLfkG68X4</guid><dc:creator><![CDATA[Sable]]></dc:creator><pubDate> Tue, 24 Oct 2023 12:12:27 GMT</pubDate> </item><item><title><![CDATA[Announcing #AISummitTalks featuring Professor Stuart Russell and many others]]></title><description><![CDATA[Published on October 24, 2023 10:11 AM GMT<br/><br/><p><i>立即注册：</i> <a href="https://www.facebook.com/hashtag/aisummittalks?__eep__=6&amp;__cft__[0]=AZWWp2KX-5gEcFfkRo4Lxqg1YojXwaT6ZG89wRpvxIizJV-guP3ZZ7H9-0cxf5gsF-LnGdxKiywZLlV58vPiaQTl14pc8yaytztqw7GO_yhx-SezQj7FlTV5XK2oD9gYJJ3ULkwRtTZt_21J1NTvdUo_T7nUD34r74Ah8EwGrZL_xBe9kbIMpjQ_ZpfISW4b0Pw&amp;__tn__=*NK-R"><i>#AISummitTalks</i></a> <i>II，由斯图尔特·拉塞尔教授和其他许多人在布莱奇利 Wilton Hall 主持，10 月 31 日星期二，格林威治标准时间 14:00 至 15:30！ -</i> <a href="https://lu.ma/n9qmn4h6"><i>https://lu.ma/n9qmn4h6</i></a></p><h1>关于会谈</h1><p><a href="https://www.youtube.com/watch?v=GFf9oL6jg0w">第一届#AISummitTalks：驾驭存在风险</a>有超过 250 人参加，人群参与度很高。</p><p>对于我们关于人工智能 x 风险的 #AISummitTalks 系列的第二版，我们将在<a href="https://www.facebook.com/hashtag/aisafetysummit?__eep__=6&amp;__cft__[0]=AZWWp2KX-5gEcFfkRo4Lxqg1YojXwaT6ZG89wRpvxIizJV-guP3ZZ7H9-0cxf5gsF-LnGdxKiywZLlV58vPiaQTl14pc8yaytztqw7GO_yhx-SezQj7FlTV5XK2oD9gYJJ3ULkwRtTZt_21J1NTvdUo_T7nUD34r74Ah8EwGrZL_xBe9kbIMpjQ_ZpfISW4b0Pw&amp;__tn__=*NK-R">#AISafetySummit</a>前夕在著名的布莱奇利公园外见面。在人工智能安全峰会上，世界领导人将首次讨论如何通过人工智能防止人类灭绝。不幸的是，社会在这些讨论中没有发言权，因为只邀请了 150 人。但在我们与 Conjecture 共同组织的人工智能安全峰会上，您可以参与此次讨论！</p><h1>扬声器</h1><p><a href="http://existentialriskobservatory.org/">存在风险观察组织</a>和<a href="https://www.conjecture.dev/">猜想组织</a>将与您一起，主持由<a href="https://en.wikipedia.org/wiki/Stuart_J._Russell">斯图尔特·罗素教授</a>（加州大学伯克利分校）发表的主题演讲，随后由猜想组织的<a href="https://www.linkedin.com/in/connor-j-leahy/?originalSubdomain=uk">康纳·莱希</a>等人发表演讲。该活动最后将通过小组讨论结束，该小组讨论将汇集安德里亚·米奥蒂（ <a href="https://www.linkedin.com/in/andrea-miotti/?originalSubdomain=uk">Andrea Miotti</a> ，战略与治理主管、猜想）以及来自社会辩论和政治领域的主要声音，其中包括投资者<a href="https://en.wikipedia.org/wiki/Jaan_Tallinn">Jaan Tallinn</a> （<a href="https://www.cser.ac.uk/">研究中心</a>联合创始人）<a href="https://www.cser.ac.uk/">存在风险研究所</a>- CSER）、Annika Brack（<a href="https://icfg.eu/">国际下一代中心 - ICFG</a>首席执行官）、Mark Brakel（<a href="https://futureoflife.org/person/mark-brakel/">未来生命研究所</a>- FLI 政策主任）、 <a href="https://en.wikipedia.org/wiki/Alexandra_Mousavizadeh">Alexandra Mousavizadeh</a> （ <a href="https://www.linkedin.com/company/evidentinsights/">Evident</a>经济学家、首席执行官）、 <a href="https://mediadirectory.economist.com/people/hal-hodson/">Hal Hodson</a> （记者） <a href="https://www.economist.com/">《经济学人</a>》），还有一位<strong>神秘嘉宾</strong>！下午的主持人是<a href="http://londonfuturists.com/">伦敦未来主义者</a>协会主席<a href="https://www.linkedin.com/in/dw2cco/">大卫·伍德</a>。</p><h1>登记</h1><p>Curious?想加入对话？赶快预订您的席位 - 只能分配 300 个席位。</p><p> <a href="https://lu.ma/n9qmn4h6">https://lu.ma/n9qmn4h6</a><br><br>我们期待您的光临！</p><br/><br/> <a href="https://www.lesswrong.com/posts/NaXz3FM9gXXB7oJW3/announcing-aisummittalks-featuring-professor-stuart-russell#comments">Discuss</a> ]]>;</description><link/> https://www.lesswrong.com/posts/NaXz3FM9gXXB7oJW3/announcing-aisummittalks-featuring-professor-stuart-russell<guid ispermalink="false"> NaXz3FM9gXXB7oJW3</guid><dc:creator><![CDATA[otto.barten]]></dc:creator><pubDate> Tue, 24 Oct 2023 10:11:35 GMT</pubDate></item></channel></rss>