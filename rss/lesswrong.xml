<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title><![CDATA[LessWrong]]></title><description><![CDATA[A community blog devoted to refining the art of rationality]]></description><link/> https://www.lesswrong.com<image/><url> https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico</url><title>少错</title><link/>https://www.lesswrong.com<generator>节点的 RSS</generator><lastbuilddate> 2023 年 12 月 2 日星期六 14:09:47 GMT </lastbuilddate><atom:link href="https://www.lesswrong.com/feed.xml?view=rss&amp;karmaThreshold=2" rel="self" type="application/rss+xml"></atom:link><item><title><![CDATA[Taking Into Account Sentient Non-Humans in AI Ambitious Value Learning: Sentientist Coherent Extrapolated Volition]]></title><description><![CDATA[Published on December 2, 2023 2:07 PM GMT<br/><br/><p>我在<i>《人工智能与意识杂志》</i>上发表了一篇论文，内容是关于如何在 A(S)I 价值调整中考虑非人类动物和数字思维的利益。</p><p>论文的发布版本请参见： <a href="https://www.worldscientific.com/doi/10.1142/S2705078523500042">https://www.worldscientific.com/doi/10.1142/S2705078523500042</a></p><p>有关论文最终草案的 pdf 格式，请参阅： <a href="https://philpapers.org/rec/MORTIA-17">https://philpapers.org/rec/MORTIA-17</a></p><p>下面我复制粘贴了论文的正文，对于感兴趣的人，请引用已发布的版本： <a href="https://www.worldscientific.com/doi/10.1142/S2705078523500042">https</a> ://www.worldscientific.com/doi/10.1142/S2705078523500042</p><h1>概括</h1><p><i><strong>摘要</strong></i><strong>：</strong>雄心勃勃的<a href="https://www.lesswrong.com/tag/value-learning">价值学习</a>建议旨在解决人工智能对齐问题并避免未来可能出现的未对齐<a href="https://www.lesswrong.com/tag/superintelligence">人工超级智能</a>（例如<a href="https://www.lesswrong.com/tag/coherent-extrapolated-volition">相干外推意志</a>[CEV]）造成的灾难性后果，其重点是确保人工超级智能（ASI）将尝试做人类的事情会想要它这样做。然而，现在和未来的有感知能力的非人类，例如非人类动物和未来可能的数字思维，也可能以道德相关的方式受到 ASI 行为的影响。本文提出了Sentientist Coherent Extrapolated Volition，作为CEV的替代方案，直接考虑到所有众生的利益。这个雄心勃勃的价值学习提案将大大降低 ASI 行为造成<a href="https://www.lesswrong.com/tag/risks-of-astronomical-suffering-s-risks">天文数字损失的风险</a>的可能性，因此我们有非常强烈的道德理由支持实施它而不是 CEV。这一事实对于在不同的雄心勃勃的价值学习提案之间进行充分的成本效益分析至关重要。</p><p><i><strong>关键词：</strong></i>对齐问题·连贯外推意志·痛苦风险·感伤主义·数字思维·非人类动物</p><p>除了人类之外，非人类动物，还有有感知力的数字思维都可能受到未来人工智能系统行为的非常负面影响。这让我们有理由在决定如何设计此类系统时考虑他们的利益。在本文中，我特别关注连贯外推意志，但我提出的许多考虑因素也可以应用于其他雄心勃勃的价值学习提案。</p><p>沿着这些思路进行更多的研究，认真考虑（1）人工智能对未来的影响以及（2）非人类动物和未来可能的数字思维的道德考虑，如果我们想要关键决策者这样的作为人工智能公司或政府，应充分了解如何确保强大的人工智能系统的开发安全并造福于所有众生。</p><h1>一、简介</h1><p>超级人工智能（ASI）（或通用人工智能）的发展带来了严重的生存风险和痛苦风险（Bostrom，2014；Yudkowsky，2008；Sotala &amp; Gloor，2017；Tomasik，2015a；Baumann，2017a）。为了防止此类灾难，我们必须解决对齐问题。我们必须确保（如果我们这样做）我们创建的第一个 ASI 具有某些值，这样它就不会导致这些结果，并且能够实现我们想要的结果。值规范问题是这是更一般的对齐问题的一部分（Gabriel，2020；Christian，2020）。这是将 ASI 与什么值对齐的问题，也是本文关注的重点，而不是其他更技术性的问题（例如内部对齐）。</p><p>在关于应在第一个 ASI 中实施哪些价值观以防止灾难性后果的讨论中，非人类有感知的生物，例如驯养的非人类动物、野生动物和未来可能的有感知的数字思维，通常被忽视。然而，所有众生都很重要，任何价值学习提案也应考虑非人类众生的利益。</p><p>在本文中，我认为，在未来，如果我们能够实施一些标准的雄心勃勃的价值学习提案或直接考虑有感知力的非人类利益的替代价值学习提案，我们将拥有强大和<i>非常</i>强大的赞成后者的道德理由。然而，在实践中，正如第 5 节所述，尚不完全清楚哪种雄心勃勃的价值学习提案最适合尝试实施。我转向连贯外推意志（CEV）的例子，这是最流行的雄心勃勃的价值学习提案之一，并认为它并不理想，因为（至少）有一个足够不可忽视的机会，因为没有充分包括所有有情众生，它可能会因 ASI 自身的行为而导致天文数字般的灾难风险。虽然在这里我只关注 CEV，但与我在这里使用的类似的论点也适用于许多其他雄心勃勃的价值学习提案，我可能会在未来的研究中讨论和分析其他雄心勃勃的价值学习提案。</p><h1> 2. 为什么相干外推意志的标准提议版本有问题<strong>&nbsp;</strong></h1><p><i>连贯外推意志 (CEV)</i>是 Eliezer Yudkowsky 的价值学习建议，它将在 ASI 中实现我们（人类）同意的目标，即在更理想的情况下，如果给予更长时间的思考，我们会希望实现这一目标（Bostrom，2014）。也就是说，我们（人类）希望“如果我们知道得更多，思考得更快，成为我们希望成为的人，一起成长得更远；外推法趋同而不是发散，我们的愿望一致而不是干扰；按照我们希望的方式推断，按照我们希望的方式解释”（Yudkowsky，2004）。有关充分相干外推所需的理想环境的更详细解释，请参阅（Yudkowsky，2004）。包括（Yudkowsky，2016）在内的一些人可能会认为，事实上，如果 ASI 应该考虑非人类众生的利益，那么这足以充分考虑他们的利益。同样，也有人认为，动物的福祉也包含在人类的偏好中，再加上 ASI 的不那么短视的决策（与人类决策相比），可能就足够了（Russell，2019） ）。也有人认为，人类应该建立一个直接关心有感知力的非人类利益的 ASI 可能很难维持，因为那时它会比人类实际做的事情更关心他们（Russell，2019）。根据这些观点，如果确实如此，<i>如果</i>人类在理想情况下有更多的时间思考，就会有充分考虑他们的利益的目标，那么通过连贯地推断人类的意志，ASI 将考虑到有知觉的非人类的利益。我认为这个答案对于我们来说还不够令人满意，如果我们能够这样做的话，我们没有充分的理由尝试将有感知力的非人类的利益直接纳入 ASI 的目标。</p><p>有人似乎有理由认为，对于任何价值学习提案，该提案的某些方面不能留给 ASI 来解决，例如“地位，涉及谁的道德观点[或道德相关利益]”；衡量，关于如何识别他们的观点[或道德相关利益]；和聚合，涉及如何将个人观点[或道德相关利益]组合成指导人工智能行为的单一观点”（Baum，2020）。正如人们所争论的那样，对齐问题本质上具有规范性的组成部分，可以使用不同类型的技术解决方案将某些值加载到未来 A(S)I 的奖励函数中，这可能对我们到底要使用什么样的值产生不同的影响。可以实施，因此，“没有办法完全‘排除’规范性问题”（Gabriel，2020）。最终，可能成为 ASI 的 A(G)I 的设计者无法回避面临道德决策，即他们以什么方式、什么以及谁的价值观或道德相关利益纳入 ASI 的目标。我认为，我们应该认真对待尤德科夫斯基的流行提议没有充分考虑与有感知的非人类的道德重要性有关的道德考虑的可能性。</p><p>尽管标准 CEV 提案充分避免了直接指定指导 ASI 行为的价值观（因此似乎避免了实质性的价值锁定），但它仍然指定了哪些众生的意志可以连贯地推断出来。标准提案仅包括目前存在的人类。从这个意义上说，标准CEV提案排除了所有其他众生，并对长期存在的问题给出了具体的答案。我认为，有非常充分的理由表明，CEV 针对现有问题提出的标准解决方案在道德上比更加考虑所有众生利益的雄心勃勃的价值学习提案更不受欢迎。从现在开始，我将在第 3 节中将这种替代提案进一步发展为<i>Sentientist 连贯外推意志 (SCEV)</i> 。</p><p>在第 2.1 节中，CEV 将有感知力的非人类的意志排除在外推基础之外。我将说明为什么仅仅排除他们是不合理的，就像排除人类群体是不合理的一样。如果我们能够做到的话，这本身就给了我们实施 SCEV 而不是 CEV 的强烈道德理由。然而，在第 2.2 节中。我认为我们有<i>非常</i>充分的道德理由这样做。标准 CEV 提案的充分实施导致 ASI 导致或允许天文灾难风险（s-风险）发生的可能性（至少）不可忽略。这些事件的风险会带来巨大的痛苦，远远超过迄今为止地球上存在的所有痛苦（Sotala &amp; Gloor，2017；Althaus &amp; Gloor，2016）。这里的“重大”是指相对于预期的未来苦难而言（Althaus &amp; Gloor，2016）。考虑到 s 风险的坏处，这种不可忽略的概率足够大，使得 CEV 成为比 SCEV 更不受欢迎的价值规范问题解决方案。</p><p>重要的是要注意并记住，我在本节和整篇论文中提出和讨论的支持 SCEV 的理由是赞成的，因为（如第 5 节中所讨论的）它们可能会被推翻或击败反对实施 SCEV 的其他赞成理由。因此，考虑到所有因素，尝试实施 SCEV 而不是 CEV 是否是正确的选择可能尚不清楚。</p><h2> 2.1.为什么我们有强烈的道德理由实施 SCEV 而不是 CEV：与 CEO-CEV 和 men-CEV 的类比</h2><p>为了了解为什么将有感知力的非人类排除在外推基础之外是不合理的，我们可以看看不同的替代（和虚构的）CEV 提案。以<i>CEO-CEV</i>提案为例：仅应用CEV的提案，即仅连贯地推断首先开发ASI或AGI的研究实验室的CEO的意愿。或者，例如，采用仅连贯地推断男性意志的<i>男性 CEV</i>提案。如果我们可以选择实施其中任何一项，那么与 CEV 相比，这些显然是在道德上更不受欢迎的雄心勃勃的价值学习建议。我们有充分的理由反对仅仅连贯地推断一小部分人类的意志，因为这不能代表整个人类。反对追求诸如雄心勃勃的价值学习提案之类的路径（如果存在实施正常 CEV 的可能性）的最合理的理由可能是，这些提案显然（至少）有足够大的不可忽略的概率导致 ASI 的行为对未直接包含在 CEV 外推基础中的人类产生负面影响。非男性的人或与人工智能实验室首席执行官的偏好有很大不同的人可能会发现自己处于后 ASI 世界，他们的利益没有得到充分考虑，并因此遭受负面后果。他们的利益可能会被严重忽视，因为他们的利益只存在于 ASI 的效用函数中，达到人们或人工智能实验室的首席执行官在理想情况下对他们进行充分考虑后对他们的关心程度。</p><p>尽管有可能，如果人工智能实验室的首席执行官或人员在理想条件下有足够的时间思考，那么，他们会像他们一样平等地考虑外推基础之外的人的利益，我们仍然会不接受这些建议，因为与正常的 CEV 相比，这些建议对于雄心价值学习的充分建议。因为有足够的可能性证明这种可能性并非如此。虽然这些价值学习建议可能比在 ASI 中不实施任何价值观更好，但它们比 CEV 差得多，因为它们有足够大的不可忽视的可能性，它们会给被排除在外推基础之外的人带来重大负面后果在每种情况下。这将使我们有充分的理由在决策情况下排除 CEO-CEV 和 men-CEV，在这种情况下，我们也可以选择实施考虑到所有人的正常 CEV 提案。</p><p>我认为，出于类似的原因，与 SCEV 相比，CEV 也是一个不充分的提议。正常的 CEV 提案，如 CEO-CEV 和 men-CEV，将道德患者的子集排除在外推基础之外。它排除了所有有知觉的非人类。和前面的例子一样，如果 CEV 得到充分实施，有感知力的非人类的利益只会存在于 ASI 的效用函数中，并且只有在人类考虑足够多的情况下才会考虑到他们的关心程度关于他们在理想情况下的情况。有感知力的非人类是道德患者，他们可能会受到道德上不良的影响，就像前面例子中被排除在外推基础之外的人一样。这种情况的发生可能仅仅是因为他们的利益对于外推基础中的个人来说不够重要，即使他们在理想情况下有足够的时间考虑这一点。这就是为什么如果我们能够做到这一点，我们将有强烈的道德理由来实施SCEV，而不是实施CEV：这是一个充分考虑了所有众生利益的提议。下面，在第 4 节中，我提出了两种可能的反对意见，这些反对意见认为排除其他人类和排除有感知力的非人类之间存在相关差异。</p><h2> 2.2.为什么我们有非常强烈的道德理由实施 SCEV 而不是 CEV：显着降低天文灾害的风险</h2><p>我们不仅有<i>充分的</i>道德理由来实施 SCEV 而不是 CEV。还有进一步的理由相信，实施 CEV 与 SCEV 之间的预期负面后果差异远大于实施 CEO-CEV 或 men-CEV 与 CEV 之间的预期负面后果差异。如果我们能这样做，我们就会有更紧迫的理由以 SCEV 而不是标准 CEV 提案为目标，而不是我们必须以标准 CEV 提案而不是 CEO-CEV 或 men-CEV 为目标。那么，如果我们能这样做，我们就有<i>非常</i>强烈的道德理由来实施 SCEV 而不是 CEV。</p><h3> 2.2.1.对有感知力的非人类更缺乏道德考虑<i>&nbsp;</i></h3><p>任何特定的人类群体（没有任何特定的心理社会条件）如果在理想情况下有足够的时间思考，那么他们很可能会更加关心其他人的利益，而不是所有人类都会关心的程度如果所有有知觉的非人类有足够的时间在理想的情况下思考的话，他们的利益就会得到满足。在第一种情况下，外推基中的人类对外推基外的人类给予的考虑可能比在第二种情况下所有人类对外推基外的有感知力的非人类给予的考虑要多得多。根据。</p><p>当然，我们不能确定情况确实如此，因为我们并不具体知道在实践中如何连贯地推断任何人类子集或所有人的意志。我们不确定，如果在更理想的情况下，如果给予更长的时间思考的话，任何一部分或全部人类会同意他们想要什么。然而，对于不同类型的 CEV 产生哪些结果的可能性或多或少，我们并非无话可说。确实，我们可以说些什么。例如，人类往往会更多地考虑那些与他们最亲近且更相似的人（Caviola et al., 2018; Dhont, Hodson, &amp; Leite, 2016），这可能会影响在一个环境中连贯地推断意志的过程。对于有知觉的非人类来说是消极的方式。这是因意义）对人类而言比对其他人而言更重要。</p><p>此外，我们还应该更新这样一个事实，即（至少部分地）由于没有平等地考虑所有众生的利益，现在和过去，人类已经杀戮并给无数的人造成了巨大的难以忍受的痛苦。大量非人类众生从味觉愉悦中获得的利益几乎可以忽略不计。为了了解我们应该对这一事实进行多少更新，想象一下人工智能实验室的首席执行官或人员对每种情况下被排除在外推基础之外的人类造成巨大痛苦的可能世界。并且这样做的数量与这个世界上的人类给其他动物造成的痛苦成正比。想象一下，他们是通过在每种情况下折磨外推基外的人类来做到这一点的。想象一下，就像人类对待工厂出名的非人类动物一样，它们给外推基地之外的人类带来了终生难以忍受的痛苦，甚至在他们成年之前就杀死了几乎所有的人。在这些可能的世界中，我们有更多的理由相信，实施 CEO-CEV 或 men-CEV 更有可能导致比我们预期在现实世界中产生的后果更糟糕的后果。类似地，似乎更有可能的是，在这个世界上，在一个人类心理（至少部分地）导致人类对其他非人类有情生物犯下暴行（例如工厂化农业）的世界中，另外，CEV 的标准提案对非人类众生造成的负面后果比我们人类心理在对其他众生实施暴行时没有发挥作用的世界要多。</p><h3> 2.2.2.最坏结果的性质和不同类型：天文数字般的痛苦风险<i>&nbsp;</i></h3><p>正如我们所看到的，随着标准 CEV 提案的实施，有感知能力的非人类的利益（至少）有一个不可忽视的可能性会被 ASI 高度忽视。并且这种可能性（无论它是什么）高于在 ASI 控制的未来中，不包括在外推基础中的人类的利益被高度忽视的可能性，在未来，只有某些人类的意志被连贯地外推。一个拥有 ASI 并具有上述任何一种雄心勃勃的价值学习建议的文明很可能（至少在某种程度上）想要扩大和定居空间，并利用先进的人工智能和模拟技术。在这样一个未来，有感知力的非人类的利益将被高度忽视，有感知力的非人类很可能会因为人类想要采取的行动以及 ASI 可能采取的行动而遭受天文数字般的损失。遵循他们的 CEV。</p><p>野生动物的痛苦可能会通过这种文明传播到整个宇宙。这可能是直接的生源论或故意改造行星的结果，因为人类的一些价值观是在宇宙中传播生命或为了他们对自然的审美享受（Tomasik，2018；O&#39;Brien，2021）。但如果没有采取预防措施，这种情况也可能是由于太空飞船净化不充分而发生的，这可能导致一些微生物或其他生物体被意外地运送到其他行星，这可能会在多年的过程中导致出现这些行星上的有知觉的生命形式。因为在这些未来非人类动物的生活中，痛苦可能会非常普遍，甚至可能占主导地位，就像目前生活在自然界中的非人类动物的大多数生活一样（Ng，1995；Groff &amp; Ng， 2019；Tomasik，2020；O&#39;Brien，2021）如果这种情况发生，可能会导致天文数字般的痛苦。</p><p>具有 ASI 的文明考虑到部分或全部人类的利益，但不考虑有感知力的非人类的利益，也可能会大量利用先进的人工智能和模拟技术。这可能有意或无意地导致天文数字般的痛苦。忽视人工感知形式的兴趣的 ASI 可能会意外地创建大量的感知子例程。这些是 ASI 程序和结构内具有重要价值的功能、子程序、机器人监督员、机器人科学家或子代理（Tomasik，2019a）。同样，现象经验和承受痛苦的能力的出现似乎在指导行为方面具有进化上的作用，它也可能有助于 ASI 控制其内部过程的行为以实现其目标。通过经历复杂的优化过程，ASI 可能会像自然选择一样，对痛苦的创造进行评估，这是一个优化基因繁殖的复杂过程（Sotala &amp; Gloor，2017）。</p><p>此外，实施 CEV 且高度忽视有感知力的非人类利益的 ASI 控制的文明也可能导致心灵犯罪，即在模拟中创造大量数字心灵，包括受苦受难的心灵。它可能会出于研究目的对过去的人类历史、自然环境或未来可能的进化路径进行大量的祖先模拟（Bostrom，2014，第 125-26 页；Sotala &amp; Gloor，2017）。在许多这些中，如果模拟足够详细和复杂，“人类”数字思维和野生或驯养非人类动物的数字思维可能会出现，从而增加野生动物的痛苦和工厂化养殖的主观体验（Tomasik， 2015b；鲍曼，2017a)。它还可以有意地创建或允许其他人有意地创建具有特别显着的痛苦的模拟，以供娱乐或满足虐待狂的偏好。在想要探索所有可能的心灵空间时，它也可能会尝试模拟与我们相比的各种不同的遥远的、奇怪的和外星的感知形式（Tomasik，2015b）。任何此类非人类有情生物都可能大规模存在，并且他们的利益被 CEV 联盟的 ASI 掌权者忽视，这会加剧天文数字灾难的风险。</p><p>而且，正如其他地方非常有道理地争论的那样，“几乎所有合理的价值体系都希望避免痛苦风险，对于许多价值体系来说，痛苦风险是最糟糕的可能结果，因此也是最需要避免的风险”（Sotala和格洛尔，2017）。在任何认为防止不希望的和剧烈的痛苦非常重要的价值体系中，防止天文数字般的不希望的和剧烈的痛苦将是极其重要的。那么，这些结果的可能性不一定非常高，因为预防它们就非常重要。如果 S 风险发生的可能性不可忽略或较高，那么减少它仍然具有重大的道德重要性，因为它们的发生在道德上是极其不受欢迎的。</p><h3> 2.2.3.为什么（即使不考虑对其利益的高度漠视）有感知力的非人类更有可能成为 s 风险的受害者<i>&nbsp;</i></h3><p>由于生物人类与有感知力的非人类存在种类的差异，即使不是有感知力的非人类更容易被忽视，但有感知力的非人类更有可能被忽视。相比于实施CEO-CEV或男性-CEV而无视自身利益而被排除在外的人类，实施无视其利益的CEV所造成的伤害要大得多。之所以如此，是因为对有感知力的非人类造成天文数字的痛苦比对被排除在外的（生物）人类造成天文数字的痛苦更容易。</p><p> ASI 可能会导致造成天文数字损失的行为，也可能允许其他因素采取导致天文数字损失的行为。在这两种情况下，无论该行动是由 ASI 还是由其他特工执行，该行动导致天文数字般的痛苦的事实或多或少可能是故意的。当导致天文数字痛苦的行为是最大程度的故意时，执行这些行为的主体想要造成天文数字的痛苦，当这些行为是最大程度的无意识时，主体甚至不知道他们正在造成天文数字的痛苦。在这种有意性和无意识行为规模的中间区域，有些情况下，代理人知道他们正在造成天文数字的痛苦，但为了实现其目标仍采取行动，并且有些情况下，代理人不确定他们是否正在造成天文数字般的痛苦，但仍然采取行动。许多有感知能力的非人类都具有一些特征，使他们更有可能、更容易地忍受天文数字般的痛苦。被排除在CEO-CEV或men-CEV之外的生物人类缺乏这些特征，因此他们更难成为天文数字苦难的受害者。以下是一些相关差异：</p><p> ●<i>复制或复制的资源效率：</i>与维持受苦的人类所需的资源相比，复制受苦的数字思想所需的资源相对于维​​持它们所需的资源来说，似乎要少得多（Sotala，2012） ；舒尔曼和博斯特罗姆 2021）。与（生物）人类相比，这使得造成天文数字灾难的代理人更有可能有意复制数字思维，并且更容易无意中复制数字思维。</p><p> ●<i>缺乏维持受苦人口的干预：</i>维持受苦的数字思维群体或生活在自然界中的（生物）非人类动物所需的干预似乎比受苦的（生物）人类群体要少。在前一种情况下，造成天文数字痛苦的因素可以让痛苦无限期地持续下去（无论是有意还是无意）。在后一种情况下，自然选择、捕食和生殖策略中的重新选择过程在没有监督和缺乏干预（有意或无意）的情况下继续进行。然而，在生物人类的情况下，需要更多的干预，以防止他们试图控制导致他们痛苦的事物，防止他们试图利用资源来减少生活中的贬值，增加生活的价值，并防止他们试图通过停止繁殖或自杀来停止存在。</p><p> ●<i>某些情况下痛苦存在的不确定性：</i>在上述情况下，行为人不确定自己是否造成了天文数字般的痛苦，但仍然采取了行动，如果他们知道自己正在造成痛苦，他们可能不会选择以这种方式行事天文数字般的痛苦。与特定的（生物）人类是否正在承受痛苦相比，（并且可能继续）生活在自然界中的<i>某些</i>动物或<i>某些</i>可能的数字思维是否正在承受痛苦更加不清楚。后者可能能够传达这一事实，并且与我们更加相似，因此在造成痛苦的行为者不确定他们是否这样做的情况下，不太可能成为受害者。</p><p>所有这些因素加上（生物）人类不太可能被忽视这一事实，使得与有感知力的非人类未来成为 S 风险受害者的可能性相比，他们成为 S 风险受害者的可能性大大降低由 ASI 控制，该 ASI 提出了雄心勃勃的价值倾向提案，但该提案并未直接连贯地推断出他们的意愿。</p><p>总之，有两种方法可以证明为什么我们有迫切的理由实施 SCEV 等雄心勃勃的价值学习提案，而不是标准 CEV 提案（如果我们能够这样做的话）。一方面，与实施 CEV 而不是 CEO-CEV 或 men-CEV 等雄心勃勃的价值学习提案有强烈的道德理由一样，实施 SCEV 而不是 CEV 也有强烈的道德理由。另一方面，由于（至少）有不可忽视的可能性，有感知能力的非人类的利益被具有标准 CEV 提案的 ASI 高度忽视，并且在这样的未来，有感知能力的非人类的利益被高度忽视，有感知力的非人类很可能遭受 s 风险，标准 CEV 提案的实施有（至少）不可忽视的可能性，导致有感知能力的非人类从自己的 ASI 中面临 s 风险行动。由于 S 风险似乎是最糟糕的可能结果，并且在合理的规范观点下在道德上极不受欢迎，因此即使（至少）其发生的可能性不可忽视，也是非常糟糕的。那么，如果有更好的替代方案，那么排除绝大多数现在和未来众生的标准 CEV 提案在道德上是非常不可取的。由于实施某些类型的雄心勃勃的价值学习（正如我将在下一节中讨论的），ASI 行为带来 s 风险的可能性增加，可以通过对价值规范问题实施真正的感知主义解决方案来显着降低。</p><h1> 3. 雄心勃勃的价值学习的另一种有情论建议<strong>&nbsp;</strong></h1><p>在这里，我将介绍 Sentientist 连贯外推意志，这是 CEV 的一个雄心勃勃的价值学习替代方案。该建议包括连贯地推断所有当前存在和未来众生的意志。也就是说，将所有道德患者纳入 CEV 的外推基础中。</p><p><i><strong>感知主义连贯外推意志</strong></i>：在更理想的情况下，如果给予更长的时间思考，实现所有（有影响的，即现在​​和未来）有情众生都同意他们想要的目标。</p><p>尽管这是一个非常雄心勃勃的目标，但标准 CEV 提案也是如此，尽管它的目标稍差一些。如果标准 CEV 提案原则上可行，我认为没有理由相信该提案原则上也是可行的。为了实现标准 CEV 提案，必须确定如果我们知道得更多、思考得更快、成为我们希望成为的人、并且一起成长得更远等，那么人类的愿望会是什么样子（Yudkowsky， 2014）。这需要确定如果我们拥有与目前不同的能力，我们会想要什么。这需要确定如果我们在许多方面拥有超人的能力，例如不受认知偏见的影响，以及能够处理和理解更多数量和不同类型的信息，我们会看重什么（Yudkowsky，2014） 。</p><p>具体来说，这将或可能包括（除其他外）创建“每个个体思维的详细模型，尽可能详细地猜测由“了解更多”、“思考更快”所定义的意志外推转换类别。 ETC。” （尤德科夫斯基，2004）。目标是近似并理解如果对每个头脑进行意志外推升级（例如了解更多，并有更多时间思考），每个头脑将经历什么样的理想化变化。重要的是要理解，该提案并不是让 ASI 通过物理干预外推基础中的个体的大脑来直接执行这些意志外推升级。相反，该提案将在由 ASI 生成的外推基础中的所有个体的详细思维模型上执行这些更改。 CEV和SCEV都没有提出意志外推升级是直接在外推基础上的个体的思想上进行的。这只会导致所有人（人类和非人类）突然，直接升高，并增强到与ASI相似的认知能力水平。一旦ASI生成了每个思想的足够详细的模型，并且已经对每个模型进行了自愿驱除升级，它们所致的连贯偏好将是指导ASI行为的偏好。</p><p>如果使用更先进的技术，这些特定的过程原则上是可行的，并且在人类的思想中可以理解，那么它们也很可能也可以用更简单的头脑来完成，例如许多非人类动物的思想。而且，我们至少可以对这些理想化的变化对可能的未来数字思维的外观具有比零更高的概率近似是合理的。然后，如果在理论上可以相干推断人的意志所需的过程，那么这也可能是有意义的非人类的意志。即使我们在实践中无法达到完全理想化的外推状态，或者与（人类和非人类和非人类）意志之间有着完全连贯的状态，但相关的是，我们尽可能接近实现这些目标。这样做比没有导致意志之间的任何一致性并且根本无法推断意志的提议更可取。</p><p>所有现在和未来的众生，包括人类，包括驯养和未驯化的非人类动物以及可能的未来数字思维，都可以实现目标。至少，从最广泛的意义上讲，他们有渴望和偏好具有积极的现象经历，并且没有消极的经验。他们中的许多人可能的目标可能比这些目标更丰富，更复杂。所有这些目标构成了他们每种意志的一部分，这些意志可以并且应该连贯推断。原则上，即使许多有知情的非人类具有某些认知能力的程度比人类通常具有的认知能力，也可以将其推断为外推。之所以如此，是因为与人的意志一样，我们还可以（除其他事项）确定在对它们进行自我击倒转换时发生不同种类的非人类思想的变化。即使许多有知情的非人类没有能力进行某些类型的抽象思维或反思其价值观，人类也没有确定其外推力内容所需的能力。在这两种情况下，自愿变换都将增强有知情人类和非人类的能力，以充分确定其外推力的含量。</p><p>在建模如果将自愿变换转换应用于现有非人类动物的意志，例如松鼠（例如松鼠），则会发生偏好的变化，SCEV可能会达到具有怪异偏好的外推力模型。我们目前不知道它们会是什么样。但是，这还不足以表明我们不应在外推基部中包括松鼠或其他非人类。实际上，有人认为，有充分的理由可以将非人类动物的（认知）能力（至少）提升到大多数人类出于民主原因（Paez＆Magaña，2023年）的水平（至少比大多数人类的水平），因为罗尔西亚自由主义的理由（Dvorsky 2008）和反种族主义的原因（Chan，2009年）。而且，正如我将在第4.3节中提出的那样。我们没有充分的理由相信实施SCEV或增强其功能会导致它们不再存在，而是可以在保留其身份的同时完成（Paez＆Magaña，2023年）。此外，正如我在第4.1节中所显示的那样。令人难以置信的是，在外推基础中包括非人类动物可能会导致我们受到其外推的奇怪偏好的伤害。因此，由于不包括它们，我们可能会增加天文痛苦的风险，因此我们有强烈的理由这样做，即使我们高度不确定其外推力的内容。</p><h2> 3.1.解决常规问题的解决方案<i><strong>&nbsp;</strong></i></h2><p>由于如上所述，我们不能将解决方案（在推断基地中包括在内的利益或意志的问题）解决问题，因此我们应该在自己做出这样的决定时考虑不确定性。与确定应在道德上考虑哪些实体有关的是什么，因此也以某种方式将其包括在外推基础中，不是我们是否可以确定它们是否具有道德患者的相关特征。反对尤德科夫斯基（Yudkowsky）争辩的事实，事实是，对于特定实体是否应有的道德考虑可能是错误的，这不是一个充分的理由，将它们排除在我们的道德考虑或构成外推基础之外的理由（Yudkowsky，2016年）。取而代之的是，相关的是，是否存在不可忽略的机会，它们具有道德患者的相关特征。之所以如此，是因为如果我们的行为有可能以道德上相关的方式伤害一个给定的实体，那么执行其他所有行动都是错误的。因为伤害的机会比没有伤害更糟糕。因此，与确定应在道德上应考虑哪些实体的相关是相关的是，是否有不可忽略的机会是有知觉的（Sebo，2018）。此外，正如我们已经看到的那样，被包括在外推基准中是否可以直接影响（预期）（预期）ASI行为尊重并考虑到给定生物的利益的程度。然后，所有的实体都有不可忽视的机会，它们应包括在外推基库中。我们有非常有力的理由相信，至少有一个不可忽视的概率是，几乎所有现在和未来的人，非人类动物以及可能的未来数字思维都是道德患者，因此应直接包含在外推基础中。这是由于三个主要原因。首先，关于脊椎动物和许多无脊椎动物动物的感知有广泛的共识和有力的证据（Low，2012; Proctor等，2013;“通用动物福利宣言”，2007年； Waldhorn，2019a； 2019a； Waldhorn，2019b，2019b），2019b）并且有广泛的同意，即将在将来创造或可以创造出具有感知能力的人工实体（Harris＆Anthis，2021）。其次，从上面理解为具有积极或负面评价的现象意识经历的能力的能力被广泛认为并被接受为道德患者的足够条件（Clarke，S.，Zohny，H。＆Savulescu，J。，2021年） 。第三，也是如此，似乎非常合理，并且也广泛认为，好东西或坏事的内在价值或尊重和考虑道德患者的利益的内在道德重要性不能仅仅因为出现而折现将来，请参见（Greaves＆Macaskill，2021：P.18； Ord，2020：P.52； Beckstead，2013：P.18），以了解文献中这种观点。然后，所有现在和未来的实体（至少）不可忽略的机会应直接包括在外推基地中。</p><h2> 3.2.如何包括未来不尚有遗物的推断意志<i><strong>&nbsp;</strong></i></h2><p>根据SCEV的说法，除了当前现有的众生之外，所有未来的众生都应将其意志直接包含在外推基地中，从那以后，ASI行动中S风险的可能性将大大降低。但是，如何将未来不存在的众生的意志直接包含在外推基础中？在任何给定的时间<i>t</i> ，ASI应采取最能够实现<i>T</i>中所有有源的人的连贯推断的意志的行动。在这种情况下，ASI可以或将采取的许多（几乎是所有）行动将改变其执行给定动作后将存在的种类和数量。由于这一事实，在任何给定的动作之后，ASI必须将新的现有众生的推断性意志纳入，如果有的话，然后决定如何基于当时所有现有生物的相干外推力再次采取行动及时。</p><p>重要的是要意识到，关于如何考虑未来不存在的众生的其他建议可能会带来灾难性的后果。例如，想象以下更为简单的提议：ASI应采取那些最能满足所有期望的行动，以实现所有众生的连贯的推断意志，这些意志在其行动后将存在。如果要实施此建议，则可能会导致公用事业功能的奖励黑客入侵。如果ASI的效用函数是最大化所有在行动后可以预期存在的有情存在的相干推断的意志实现，那么ASI可以创造许多具有非常简单的外推意志来满足的数字思维。如果ASI的行动创造了足够多的此类数字思维，那么其推断意志的力量可能大于许多数量级，而不是当前现有的人类和非人类动物的外推力的力量大量的力量，以指导ASI ASI的动物行为。这可能会导致ASI无视人类和非人类动物，并且只能执行最满足创造数字思维易于满足的偏好的动作。这些易于满足的偏好不必是任何方面对我们（也不对我们的推翻意志）看似有价值的偏好。关于如何将未来不存在的众生包括在外推基地中的替代建议可能会导致非常不受欢迎的结果。它是天真的和有缺陷的，因为在任何给定的时间点，它都可以使ASI本身确定出现了哪些新的众生（独立于已包含在内的个体的外推力的偏好）。与此相反，根据我提出的提议，出现了哪些有意义的生物，一旦存在，就可以通过纳入ASI的行为来塑造ASI的行为，这完全取决于当前包含的个人的外推力的偏好。由于推断的意志将知道SCEV的工作原理，因此他们会意识到，在偏爱某种动作或其他行动时，他们也更喜欢创造某些思想或其他人。此外，他们还会意识到，一旦它们存在，它们将被包括在外推基础中，从而影响ASI的行为。然后，推断出的意志比执行动作更了解，导致场景类似于这种场景，即已经创建了具有宝贵且易于满足的偏好的大量数字思维，并对ASI的行为完全控制了。因此，在原始提案中，我坚持，奖励黑客被阻止了。</p><p>该提议将充分考虑到未来众生的利益，因为一旦开始存在，它们的利益将直接包含在ASI的公用事业职能中。与标准CEV提案中似乎是这种情况相反，未来不存在的众生的利益一旦存在，就不会仅考虑到当前现有个人的推断意志的程度，这样做。而且，通过直接考虑以这种方式的未来有知情的非人类的利益，由于对标准CEV提案的适当实施，ASI行动中S风险的不可忽视的机会将大大减少。</p><p>实施SCEV时，SC风险从ASI的行为中降低了大大降低S风险的人类受害者。相反，有意义的非人类本身的天文数量将直接包括在外推基部。在此提案上，（至少）人类推断的意志仍需要（至少）不可忽略的机会，他们希望采取（不进一步干预）导致S风险（例如直接panpermia）或使用模拟技术的行动。结果，ASI实际上仍然有可能执行此类动作。但是，一旦他们进行了进行，一旦生活在其他行星或数字思维的“自然”环境中的非人类动物等新的众生中，它们的外推力将直接包含在外推基地中。而且，由于他们的意志将极大地反对苦难，因此，ASI几乎可以肯定会防止天文痛苦。一旦将成为S风险的受害者成立，他们对不苦难的利益将直接考虑在ASI的行为中。 ASI几乎可以肯定会阻止天文痛苦，并且与外推基地中已经存在的任何其他生物一样，它将尝试实现新现有生物的推断意志。如SCEV所建议的那样，如果将未来的非人类意志包括在外推基础中，那么从ASI的行动中出现S风险的出现（即它所引起或允许的允许）几乎是不可能的。因此，我们有非常有力的亲塔托道德理由来实施SCEV来指导可能的ASI行为，而不仅仅是一致地推断出当前现有人类的意志（所有预期存在的所有可影响的道德患者中的少数）。</p><p>最后，还应指出的是，SCEV（CEV）的这一提议并不是作为道德的现实主义理论，而是对构成“善良”的形而上学性质的描述。我不是在提出一种元理论，而只是对ASI最有道德的雄心勃勃的价值学习建议是什么。如果道德现实主义是真实的，SCEV或CEV一定会达成这一道德真理，并非如此。因此，（如CEV）SCEV及其有利于它的论点与现实主义者和反现实主义的元伦理概念兼容。</p><h1> 4. 反对意见<strong>&nbsp;</strong></h1><p>在第四部分中，我将提出并回应对CEV的（亲塔托）拒绝的三种可能异议，以及我对Sentientist Coomerent Exulapolated Voition的提议。</p><h2> 4.1.掠食者暴力倾向的风险<i><strong>&nbsp;</strong></i></h2><p>尤德科夫斯基（Yudkowsky）争辩说，反对直接包括诸如非人类动物（非人类动物）的理由是，在外推基础中，这可能会导致后果我们不喜欢非人类意志与我们的不同（Yudkowsky）（Yudkowsky） ，2016）。然后，可能会争辩说，SCEV比CEV更可取，因为它也可能导致ASI实现非常不受欢迎的目标，例如暴力目标，例如生活在野外的非人类动物具有支持捕食的目标和偏好。鉴于我们目前在CEV在实践中推断外推过程的确切性质面临的极大程度的不确定性，我们不能完全排除这可能会带来重大负面后果的可能性。然后，由于非人类动物居住在野外的非人类动物所拥有的一些愿望，ASI似乎可能有怪异，糟糕或暴力的目标。</p><p>即使我们对此无法完全确定，但我认为这种风险和不良性非常低于实施正常的CEV提案，这是非常合理的。在实施CEV时，对持久天文痛苦的唯一可能的偏好是人类所遭受的痛苦，他们在某种程度上关心有潜力的非人类的苦难。同时，在实施SCEV时，由于掠食者的暴力偏好，可能的S风险受害者的所有意志都将违反这种S风险的发生。由于仅仅是众生并被包括在推断基地中的事实，这种奇怪的危险风险的受害者的意志主要将主要由防止这种痛苦的愿望组成。确实，如上所述，渴望摆脱巨大的强烈和难以忍受的痛苦可能是任何有众所周知的可能性的最强烈的欲望，因此，由于在S风险中，有很多具有这些欲望的生物，这就是将对发生任何可能的S风险（包括掠夺性倾向）发生的任何形式的S风险都非常严重。</p><p>由于关于哪些实体有意识和黑天鹅的经验不确定性，我们可能永远无法确定，当众生继续存在时，S风险的未来是完全不可能的。但是，可以说，确保这不会发生的最好方法之一就是拥有一个真正考虑到可能的S风险受害者的利益的ASI。要求更确定的对S风险的确定性比这是不必要的，因为确实可能是不可能的。即使由于捕食者损坏的偏好而可能发生S风险的可能性很小，这种概率也可以忽略不计。驳斥雄心勃勃的价值学习提案将是不合理的，而且太要求了，因为它不能完全确定性规则规定未来发生任何类型的S风险的可能性。而且，由于由于捕食者的暴力偏好而导致不良结果的概率和不良性明显低于（至少）由于实施CEV而出现S风险的（至少）不可忽略的概率，因此我们仍然会有很大的理由支持选择SCEV，如果我们可以这样做。</p><h2> 4.2.民主的非法性和混蛋<i><strong>&nbsp;</strong></i></h2><p>对本文一般项目的另一个可能的反驳是，争论包括有情的非人类对未来ASI行为的利益的重要性是，这样做将是反民主的。确实，大多数人确实不希望也不投票支持实施一项价值一致性提案，该提案同样考虑到非人类众生的利益。</p><p>然而，这种论点假设只有人类主张支持在民主程序中代表自己的利益。这可能是物种主义偏见的结果，也可能是由于认为只有道德代理人的利益以道德上相关的方式至关重要的结果。但是，所有众生都可以受到ASI的积极或负面影响，因此，所有这些众生都有主张，都赞成考虑其利益。正如我们已经看到的那样，相信这些利益只能在当前现有的道德代理人关心的人类关心的程度上充分代表这些利益是不合理的。因此，在这种情况下，民主理论中全面的利益的原则显然适用（Christiano＆Sameer，2022），所有有众者的众生都会有强有力的民主主张，支持直接代表他们的利益。</p><p> Yudkowsky以不同的方式提出了这种反对。在他看来，对ASI的价值学习建议的程序员或实施者应尽量不要成为“混蛋”。这样一来，他们应该试图保持公平，并考虑不希望包括所有众生的人的偏好，而不是直接在外推基地中包括所有有源的众生。在Yudkowsky看来，这样做并不是公正的，因为它会扎根于人们更多地关心非人类动物的人们的偏好（Yudkowsky，2016年）。然而，与此相反，尤德科夫斯基认为，实际上不包括人类，他们与确定实施了什么价值一致性有关的人无能为力。这些人可能包括儿童，从未听说过AI的现有人或严重的身体或认知障碍者无法采取行动并对该主题表达自己的观点。</p><p>但是，如上所述，没有理由包括有知情的非人类，因为它们也可以通过包括在外推基准中，以道德上相关的方式受到积极或负面影响。许多具有对价值学习建议的权力的当事方（即某些人）并不关心这些原因，这并不意味着他们不承担任何重量。尚不完全清楚Yudkowsky所说的“混蛋”或“ Be Be Be Be Be Be Be”，但是，如果要俗语地理解，以相同的方式理解，将无力的人类被排除在外，那是不公平的和混蛋不公平和混蛋，不得不排除无人类。如今，由于社会认真考虑的一群人的社会道德进步和扩张，我们倾向于认真地包括强大而无能为力的人类，因此，将它们排除在外推基础之外，似乎是在直觉上混蛋。但是几年前，它可能不会有这种感觉。想象一下，推断基地应该包括哪些生物的决定是在多年前进行的。如果他们能做到这一点，那么在考虑包含哪些实体时，这些过去的决策者实际上是在决定要做什么的最合理的道德原因而不是做社会上最可接受的，这将是更可取的。 ，这将导致排除许多无能为力的人。现在和将来，这都是可取的。如果某人能够决定将哪些实体纳入外推基础中，那么他们应该研究道德上的理由，即使他们可能不是最直观或在社会上可以接受的，从而包括各种实体，从而将其包括在内。力量。正如我们所看到的，确实有充分的理由包括所有有情的生物。因此，一个不包括有众者的提议不是公正的，而是一个混蛋和不公平的提议。</p><p>的确，如果Yudkowsky是正确的，重要的是将某些有源的生物从外推基础中排除很重要，那么这大概是因为其中包含的生物和数量可能会影响ASI的行为。然后，这意味着，在预期的情况下，并非同样考虑到在ASI的行为中同样考虑到它们是否直接包含在外推基地中。</p><p>此外，Yudkowsky还认为，只有在外推基础中包括现有人类的人更简单（Yudkowsky，2016年）。虽然是这种情况，但如果我们能够成功地包括所有有情的众生，则并不是提出提案的道德需求的原因。 CEV比SCEV更简单的事实并不能使其在道德上更加可取。由于什么都不做，或者仅连贯推断出一种意志比CEV更简单，但在道德上并不是更可取的。</p><p>因此，反对反对意见并非如此，提出这一提议将是反民主，混蛋或不公平的情况，而是一个更加民主，更美好和公平的选择。实施CEV而不是SCEV不会对有情的非人类的直接民主和道德主张伸张正义。</p><h2> 4.3. SCEV会保留众生的身份吗？ <i><strong>&nbsp;</strong></i></h2><p>有人认为，CEV的实施将产生不良的结果，因为这会导致人类不再存在（Yampolskiy，2022年）。罗马Yampolskiy认为，通过实施CEV“ [W]本质上同意用AI设计的增强版本的人类代替自己”，因为随着CEV涉及的快速推断跳跃，与我们的相关性不会有任何连续性身份，我们将不再存在（Yampolskiy，2022）。他提出了以下论点：“我们可以说当前的人类版本是h₀，推断过程将把它带到h₁₀₀₀₀₀₀₀。用h₁₀₀₀₀₀₀₀值可以快速替换我们的价值，因此需要实际替换，或者至少用h₀对h₀进行重新布线/修改，这意味着现代人将抓住存在。”该论点也可以应用于批评SCEV。确实，确实是，对人类，动物和数字思维的能力的一些根本增强可能会导致它们因不具有身份证明而停止存在。但是，对外推基库中个人的根本增强根本不必通过实施SCEV来实现，如果他们这样做（正如人们所说的那样），它们可能以具有身份证明的方式发生并与每个人的利益保持一致个人（Bostrom 2008：P.123–126; Paez＆Magaña，2023：p.23–25）。</p><p>正如Yampolskiy所暗示的那样，确实是这样的情况，即通过对推断基础中个人的思维和意志进行意志升级进行升级，结果模型将与我们自己具有不同的偏好和价值。但是，这部分是我们在实施CEV或SCEV等建议时要完成的工作，我们正在努力防止价值锁定（Yudkowsky，2004； Macaskill，2022）。如果我们要实施当前价值来指导ASI的行为，那么这几乎可以肯定会构成巨大的道德悲剧，因为所有子孙后代都将被过时的价值观陷入困境。很明显，如果古代历史或中世纪的过去文明被锁定在其价值观中，并且他们坚持不懈，并由ASI施加了人类的未来，那将是一场悲剧。同样，我们不应该相信当前的价值构成了道德进步的峰值，并且不再有进步（Yudkowsky，2004）。</p><p>相干性生物的相干推断意志与当前存在的生物的价值和偏好之间的值和偏好之间可能会有很大的距离。但是，由于它可以防止价值锁定，因此此距离的存在比其不存在的可取，并且不会导致当前存在的生物停止存在。发生的是，我们的思想和意志模型将被创建以指导ASI的行为。这些模型将更多地了解，理性更好，并且更合作。结果，与我们拥有的相比，他们必然具有更好的合理，更连贯和合理的道德观点。这些知名度更高，更具思想和更合理的道德观点将指导ASI的行为。正如这种反对似乎所暗示的那样，这些意识更大，更具思想和更合理的道德观点一定会更喜欢的是杀死所有众生并创造新的众生，这是令人难以置信的。如果人们已经相信杀死所有有情的众生或所有人类并用新的人代替它们，那么只有理由相信SCEV或CEV会建议这样做。不同意和讨论模型将拥有哪些道德观点或偏好与讨论哪些道德观点更合理，连贯，信息良好，等等。 ，是要杀死所有有源的生物，并用新的生物代替它们是非常难以置信的，并且在任何地方都没有严重的防御。相信，更加明智的和更合理的模型可能更愿意不愿增强的众生更愿意。或者可能希望我们可以通过当代超人类主义规定的公正，包容，公平，尊重和具有身份的方式来增强我们的规定（《超人类主义宣言》，2009年； Savulescu＆Bostrom，2009年）。如果这样做，则执行的增强功能不必导致当前的众生不再存在，因为正如人们所说的那样，如果满足某些条件，可以对人类和非人类动物具有根本性的增强（Paez＆）（Paez＆） Magaña，2023：P.23–25）。</p><p>关于实体的种类有两个主要的理论，以及随着时间的流逝，他们的持久性条件（Paez＆Magaña，2023：p.23–25）。在躯体上，有源的生物是活生物体，随着时间的流逝，它们的持久性在于保持其代谢过程的完整性（Olson，1997; Van Inwagen，1990）。从这种角度来看，将有一些可以对人类和非人类动物进行根本性增强的方法，以保留其身份，人们可以增强其许多能力而不会破坏其代谢过程。该帐户是关于具有生物底物的个人，因此不适用于数字思维。但是，应用于数字思维的类似帐户可以声称，维持数字基板某些物理结构特征的完整性是必要的，并且足以使他们随着时间的流逝而持续存在。这样的帐户还将允许增强功能与随着时间的流逝的数字思维的持久性兼容。在另一个主要的说法上，心理叙述，有意义的人是心理实体，只有随着时间的推移具有心理连续性，他们才会继续存在（Degrazia 2005； McMahan，2002； Parfit，1984）。 As it has been argued (Bostrom 2008: p.123–126), this account is also compatible with enhancements being identity-preserving if the following conditions are met: the changes are in the form of adding new capacities or enhancement of old ones, without sacrificing preexisting capacities. They are implemented gradually over an extended period of time, and the new capacities do not prevent the preexisting capacities from being periodically exercised. Furthermore, the subject retains her old memories and many of her basic desires and dispositions and the subject retains many of her old personal relationships and social connections. And finally, in the case of humans and some sufficiently cognitively sophisticated digital minds each step of the transformation process is freely and competently chosen by the subject and the transformation fits into the life narrative and self-conception of the subject (Bostrom 2008: p.123–126). In the case of non-human animals and other digital minds who cannot freely choose and comprehend each step of the uplifting process, instead of these final conditions, “one may, alternatively, require the uplifting process not to undermine their control over their lives, irrespective of whether animals [or digital minds] can understand that possibility” (Paez &amp; Magaña, 2023: p.23–25). This, then would not undermine their control over their existence but rather make it more robust. For a more developed discussion on why enhancements can be made compatible with non-human animals preserving their identity, see (Paez &amp; Magaña, 2023: p.23–25) from where this paragraph is based.</p><p> Since we have good reasons to believe that radical enhancements to sentient beings can be identity-preserving, it is implausible to believe that instead of performing this kind of enhancements, if any, the more reasonable, coherent and well-informed ethical views had by the extrapolated models of sentient beings would prefer to kill all sentient beings by performing non-identity-preserving enhancement interventions instead. There are no good reasons to believe that this is preferable, and even if for some reason one were to believe so, it then would not constitute an objection to implementing SCEV, since, one would presumably prefer and welcome that which one believes to be preferable 。 The fact that SCEV would inscribe the values of S₁₀₀₀₀₀₀₀ (to represent all sentient beings instead of only humans) into the behaviour of the ASI, does not imply either the replacement or rewiring/modification of S₀ with S₁₀₀₀₀₀₀₀. Thus, we have no good reason to believe that SCEV would not preserve the identity of sentient beings.</p><h1> 5. Why it is unclear whether trying to implement Sententist Coherent Extrapolated Volition is best all things considered <strong>&nbsp;</strong></h1><p> I have argued that there are strong pro-tanto reasons to implement SCEV instead of CEV if we could do so successfully due to the fact that it would significantly reduce the non-negligible chance of s-risks from the own ASI&#39;s behaviour that there is from an adequate implementation of CEV. However, in practice, it is not clear that these reasons are not overridden or defeated by other reasons against SCEV. In this section, I will lay out other possible pro-tanto reasons that go against trying to implement SCEV or a similar value learning proposal instead of implementing one which is closer to CEV.</p><p> First, there is the risk that the SCEV would not be implemented exactly as intended. When trying to implement SCEV there is always the possibility that we would not get everything right, and that, by accident, there could be unintended consequences. For some kinds of accidents from near misses that could occur, it seems plausible that the more morally desirable the ambitious value learning proposal, the worse the accidents that may result from trying to implement it. This is so because there are some possible kinds of near-miss accidents where the goals of the ASI identify those entities and things which can sustain value, but affect them in strange or bad ways contrary to desirable behaviour the ASI was intended to have as stipulated in the morally desirable ambitious value learning proposal. There are plausibly many possible ways in which these kinds of accidents could occur. One specific accident of this kind is if, through a value learning proposal such as SCEV, the interests of digital minds are taken into account and valued and as a consequence, many of them are created (as argued by Shulman &amp; Bostrom, 2021), but we accidentally do not weight their suffering adequately. It is possible that even if the SCEV proposal intended to care about the suffering of digital minds, it accidentally was not able to adequately detect suffering and disvaluble states that many forms of alien digital minds might suffer (Vinding, 2018; Tomasik, 2019b). Or that it may not adequately weigh their interests by accident. This could potentially result in astronomical suffering. Such a kind of accident would be less likely if a less morally desirable ambitious value learning proposal were implemented since it would be less likely to create astronomical amounts of digital minds with the potential of suffering astronomically by accident. Another possible accident of this kind is the case of SignFlip, where the ambitious value learning proposal identifies a very morally desirable target or goal to maximize, but, by accident, the opposite target or goal is maximized (Tomasik, 2019b). In the case of SCEV, this would consist of maximizing the opposite of the coherent extrapolated volition of all sentient beings which would be extremely morally undesirable. Since there is some probability of the occurrence of these kinds of accidents, and some of the badness of the accidents would be mitigated by implementing a less morally desirable value learning proposal instead of SCEV, this gives us some other reasons against trying to implement a value learning proposal such as SCEV which comes very close or completely captures that which we value.</p><p> There are also further reasons against trying to implement SCEV in practice related to relevant game-theoretic considerations in specific decision-making situations. One possible and likely decision-making situation is one in which we ought to decide between implementing CEV or SCEV to a single ASI, but where the conditions for implementing SCEV instead of CEV are not fully optimal, where it is not the case that only one united decision-making entity is able to decide between the proposals, but rather, where there are already some decision makers that strongly prefer CEV instead of SCEV. In many of these kinds of decision-making situations, it may be much less desirable to try to implement a value learning proposal that adequately takes into account the interests of all sentient beings. Implementing SCEV may have even worse consequences in expectations for sentient non-humans due to a backlash from the opposition that may arise in trying to pursue this proposal. There is then, a strong reason against trying to implement SCEV due to the fact that, in practice, it might be net-negative in expectation.</p><p> However, it is not completely clear that this will be the case, and we might indeed find ourselves in future in which the pro-tanto reasons against trying to implement SCEV do not outweigh the pro-tanto reasons in favour of doing it. And, even if we can conceive of plausible future scenarios in which it seems to be the case that trying to pursue a proposal similar to CEV instead of SCEV would be preferable all things considered, to take that decision as a result of an adequate cost-benefit analysis of the different proposals it is crucial to understand the strong pro-tanto reasons in favour of SCEV that I have laid out in this paper.</p><h1>六，结论<strong>&nbsp;</strong></h1><p> In this paper, I have shown why we have some very strong pro-tanto reasons in favour of implementing SCEV instead of CEV. This is the case even if, all things considered, it is still ultimately unclear whether what is best is to try to implement SCEV or another proposal more similar to CEV. The action-relevant implications of what I have laid out in this paper, however, are not all contingent on the realization of the future in which we can fully decide what ambitious value learning proposals to try to implement. Even if we could be sure such a future will not be realized, there would still be some practical implications that follow. Determining how much more morally desirable SCEV is than CEV due to the strong pro-tanto reasons presented in the paper, is crucial to adequately make tradeoffs between different considerations in non-ideal decision-making situations where a value learning proposal has to be implemented. Furthermore, it is likely that the mere fact of having in mind what a possibly ideal scenario of adequate value specification would look like is useful in determining what we should realistically strive for if we could only reach more modest goals. Research into how different alignment and value learning proposals for possible future transformative AIs such as an AGI or ASI could affect sentient non-humans (who constitute the immense majority of present and future sentient beings expected to exist) is highly neglected. More research along these lines is required if we want to ensure that the far future goes well for all sentient beings.</p><h3><strong>致谢：</strong></h3><p> I am deeply grateful, for their suggestions, encouragement, and support to Olle Häggström, <a href="https://www.lesswrong.com/users/anthony-digiovanni?mention=user">@Anthony DiGiovanni</a> , Magnus Vinding, <a href="https://www.lesswrong.com/users/juliahp?mention=user">@JuliaHP</a> , <a href="https://www.lesswrong.com/users/lukas_gloor?mention=user">@Lukas_Gloor</a> , Aluenda Diana Smeeton and an anonymous reviewer of the <i>Journal of Artificial Intelligence and Consciousness</i> .在某种程度上，这篇论文是作为<a href="https://forum.effectivealtruism.org/posts/SFyCrtdfuYjtPq6xs/future-academy-successes-challenges-and-recommendations-to">未来学院</a>影响力项目的一部分进行的，我也非常感谢组织者给我这个机会。</p><h3><strong>参考</strong></h3><p>Althaus D. &amp; Gloor L. (2016). Reducing Risks of Astronomical Suffering: A Neglected Priority. <i>Center on Long-Term Risk.</i> <a href="https://longtermrisk.org/reducing-risks-of-astronomical-suffering-a-neglected-priority/">https://longtermrisk.org/reducing-risks-of-astronomical-suffering-a-neglected-priority/</a></p><p> Baum, SD (2020). Social Choice Ethics in Artificial Intelligence. <i>AI &amp; Society</i> , 35(1): 165–176. DOI: 10.1007/s00146-017-0760-1.</p><p> Baumann, T. (2017a). S-risks: An introduction. <i>Center for Reducing Suffering</i> . https://centerforreducingsuffering.org/research/intro/</p><p> Beckstead, N. (2013). <i>On the Overwhelming Importance of Shaping the Far Future</i> . PhD, Rutgers University. https://rucore.libraries.rutgers.edu/rutgers-lib/40469/</p><p> Bostrom, N. (2008). Why I Want to be a Post-Human When I Grow Up. In <i>Medical Enhancement and Posthumanity. The International Library of Ethics, Law and Technology</i> , edited by B. Gordijn and R. Chadwick, 2: 107–136. DOI: 10.1007/978-1-4020-8852-0_8</p><p> Bostrom, N. &amp; Savulescu, J. (eds.) (2009). <i>Human Enhancement</i> .牛津大学出版社。</p><p>博斯特罗姆，N.（2014）。 <i>Superintelligence: Paths, dangers, strategies</i> .牛津：牛津大学出版社。</p><p> Caviola, L., Everett, JAC, &amp; Faber, NS (2018). The moral standing of animals: Towards a psychology of speciesism. <i>Journal of Personality and Social Psychology</i> , 116(6): 1011–1029. DOI: 10.1037/pspp0000182</p><p> Chan, S. (2009). Should we enhance animals? <i>Journal of Medical Ethics</i> , 35 (11): 678–683. DOI: 10.1136/jme.2009.029512</p><p> Christiano, T. &amp; Sameer B. (2022).民主。<i>斯坦福哲学百科全书</i>。 https://plato.stanford.edu/archives/spr2022/entries/democracy/</p><p> Christian, B. (2022). <i>The Alignment Problem: Machine Learning and Human Values</i> . WW 诺顿公司</p><p>Clarke, S., Zohny, H. &amp; Savulescu, J. (2021) <i>Rethinking Moral Status</i> (eds.).牛津：牛津大学出版社。</p><p> DeGrazia, D. (2005). <i>Human Identity and Bioethics</i> .纽约：剑桥大学出版社。</p><p> Dhont, K., Hodson, G., &amp; Leite, AC (2016). Common ideological roots of speciesism and generalized ethnic prejudice: The social dominance human-animal relations model (SD-HARM): The social dominance human-animal relations model. <i>European Journal of Personality</i> , 30(6): 507–522. DOI: 10.1002/per.2069</p><p> Dvorsky, G. (2008). All Together Now: Developmental and ethical considerations for biologically uplifting nonhuman animals. <i>Journal of Evolution and Technology,</i> 18(1): 129–142. Available at: https://jetpress.org/v18/dvorsky.htm</p><p> Gabriel, I. (2020). Artificial Intelligence, Values, and Alignment. <i>Minds &amp; Machines,</i> 30: 411–437. DOI: 10.1007/s11023-020-09539-2</p><p> Greaves, H. &amp; MacAskill, W. (2021). The Case for Strong Longtermism. <i>Global Priorities Institute</i> . https://globalprioritiesinstitute.org/hilary-greaves-william-macaskill-the-case-for-strong-longtermism-2/</p><p> Groff, Z. &amp; Ng, Y. (2019).在动物王国里，痛苦是否主导了快乐？ An update to welfare biology. <i>Biology and Philosophy</i> , 34(40). DOI: 10.1007/s10539-019-9692-0</p><p> Harris, J. &amp; Anthis, JR (2021) The Moral Consideration of Artificial Entities: A Literature Review. <i>Science and Engineering Ethics</i> , 27: 53. DOI: 10.1007/s11948-021-00331-8</p><p> Low, P. (2012). The Cambridge Declaration on Consciousness. <i>The Francis Crick Memorial Conference on Consciousness in Human and non-Human Animals</i> .剑桥。 https://fcmconference.org/img/CambridgeDeclarationOnConsciousness.pdf</p><p>麦克马汉，J.（2002）。 <i>The Ethics of Killing: Problems at the Margins of Life</i> .牛津：牛津大学出版社。</p><p> Ng, Y. (1995). Towards Welfare Biology: Evolutionary Economics of Animal Consciousness and Suffering. <i>Biology and Philosophy</i> , 10(3): 255–85. DOI: 10.1007/BF00852469</p><p> O&#39;Brien, GD (2022). Directed Panspermia, Wild Animal Suffering, and the Ethics of World-Creation. <i>Journal of Applied Philosophy</i> , 39(1): 87–102. DOI: 10.1111/japp.12538</p><p> Olson, ET (1997). <i>The Human Animal. Personal Identity without Psychology</i> .牛津：牛津大学出版社。</p><p> Ord, T. (2020). <i>The Precipice</i> .阿歇特书籍。</p><p> Paez, E. &amp; Magaña, P. (2023). A democratic argument for animal uplifting. <i>Inquiry: An Interdisciplinary Journal of Philosophy.</i> DOI: 10.1080/0020174X.2023.2248618</p><p>帕菲特，D.（1984）。 <i>Reasons and Persons</i> .牛津：牛津大学出版社。</p><p> Proctor HS, Carder G. &amp; Cornish AR (2013). Searching for Animal Sentience: A Systematic Review of the Scientific Literature. <i>Animals (Basel)</i> , 3(3): 882–906. DOI: 10.3390/ani3030882</p><p> Russell, S. (2019). <i>Human Compatible: Artificial Intelligence and the Problem of Control</i> .维京人。</p><p> Sebo, J. (2018). The Moral Problem of Other Minds. <i>The Harvard Review of Philosophy</i> , 25(1): 51–70. DOI: 10.5840/harvardreview20185913</p><p> Shulman, C. &amp; Bostrom, N. (2021). Sharing the World with Digital Minds. In Clarke, S., Zohny, H. &amp; Savulescu, J. (eds.) <i>Rethinking Moral Status</i> .牛津：牛津大学出版社。</p><p> Soares, N. (2016). The Value Learning Problem. <i>2nd International Workshop on AI and Ethics, AAAI-2016</i> .亚利桑那州凤凰城。 https://intelligence.org/files/ValueLearningProblem.pdf</p><p> Sotala, K. (2012). Advantages of Artificial Intelligences, Uploads, and Digital Minds. <i>International Journal of Machine Consciousness</i> 4 (1): 275–291. DOI: 10.1142/S1793843012400161</p><p> Sotala, K. &amp; Gloor, L. (2017). Superintelligence as a Cause or Cure for Risks of Astronomical Suffering. <i>Informatica</i> 41(2017): 389–400. https://www.informatica.si/index.php/informatica/article/view/1877</p><p> The Transhumanist Declaration (2009). <i>Humanity+</i> . Available at: https://www.humanityplus.org/the-transhumanist-declaration</p><p> The Universal Declaration on Animal Welfare, (2007). World Society for the Protection of Animals: https://www.worldanimalprotection.ca/sites/default/files/media/ca_-_en_files/case_for_a_udaw_tcm22-8305 .pdf</p><p> Tomasik, B. (2015a). Artificial Intelligence and Its Implications for Future Suffering. <i>Center on Long-Term Risk.</i> https://longtermrisk.org/artificial-intelligence-and-its-implications-for-future-suffering</p><p> Tomasik, B. (2015b). Reducing Risks of Astronomical Suffering: A Neglected Priority. <i>Center on Long-Term Risk.</i> https://longtermrisk.org/risks-of-astronomical-future-suffering/#Some_scenarios_for_future_suffering</p><p> Tomasik, B. (2018). Will Space Colonization Multiply Wild-Animal Suffering?<i>关于减少痛苦的论文</i>。 https://reducing-suffering.org/will-space-colonization-multiply-wild-animal-suffering/</p><p> Tomasik, B. (2019a). What Are Suffering Subroutines? <i>Essays on Reducing Suf ering</i> . http://reducing-suffering.org/whatare-suffering-subroutines/</p><p> Tomasik, B. (2019b). Astronomical suffering from slightly misaligned artificial intelligence <i>Essays on Reducing Suffering</i> . https://reducing-suffering.org/near-miss/</p><p> Tomasik, B. (2020). The Importance of Wild-Animal Suffering. <i>Center on Long-Term Risk.</i> https://longtermrisk.org/the-importance-of-wild-animal-suffering/</p><p> van Inwagen, P. (1990). <i>Material Beings</i> .伊萨卡：康奈尔大学出版社。</p><p> Vinding, M. (2018). Moral Circle Expansion Might Increase Future Suffering. https://magnusvinding.com/2018/09/04/moral-circle-expansion-might-increase-future-suffering/</p><p> Waldhorn, DR (2019a) Invertebrate sentience, summary of findings, part 1. Rethink Priorities. https://rethinkpriorities.org/publications/invertebrate-sentience-summary-of-findings-part-1</p><p> Waldhorn, DR (2019b) Invertebrate sentience, summary of findings, part 2. Rethink Priorities. https://rethinkpriorities.org/publications/invertebrate-sentience-summary-of-findings-part-2</p><p> Yampolskiy, RV (2022). On the Controllability of Artificial Intelligence: An Analysis of Limitations. <i>Journal of Cyber Security and Mobility</i> , 11(3): 321–404. DOI: 10.13052/jcsm2245-1439.1132</p><p> Yudkowsky, E. (2004). Coherent extrapolated volition. <i>Singularity Institute for Artificial Intelligence</i> . https://intelligence.org/files/CEV.pdf</p><p> Yudkowsky, E. (2008). Artificial intelligence as a positive and negative factor in global risk. In Bostrom, N. &amp; Ćirković, MM (eds.) <i>Global Catastrophic Risks</i> .纽约：牛津大学出版社。</p><p> Yudkowsky, E. (2016). Coherent extrapolated volition (alignment target). Arbital: AI Alignment. https://arbital.com/p/cev/</p><br/><br/> <a href="https://www.lesswrong.com/posts/8DWtsuBkH3GmGiAdf/taking-into-account-sentient-non-humans-in-ai-ambitious#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/8DWtsuBkH3GmGiAdf/take-into-account-sentient-non- humans-in-ai-ambitious<guid ispermalink="false"> 8DWtsuBkH3GmGiADF</guid><dc:creator><![CDATA[Adrià R. Moret]]></dc:creator><pubDate> Sat, 02 Dec 2023 14:07:29 GMT</pubDate> </item><item><title><![CDATA[Out-of-distribution Bioattacks]]></title><description><![CDATA[Published on December 2, 2023 12:20 PM GMT<br/><br/><p> <span>The main goal of my work</span> <a href="https://www.jefftk.com/p/leaving-google-joining-the-nucleic-acid-observatory">these days</a> is trying to reduce the chances of individuals or small groups causing large-scale harm through engineered pandemics, potentially civilizational collapse or extinction. One question in figuring out whether this is worth working on, <a href="https://www.founderspledge.com/research/secure-bio">or funding</a> , is: how large is the risk?</p><p> <a href="https://forum.effectivealtruism.org/posts/M6zAzCBAsBxem7Lu4/can-a-terrorist-attack-cause-human-extinction-not-on-priors">One estimation approach</a> would be to look at <a href="https://en.wikipedia.org/wiki/List_of_major_terrorist_incidents">historical attacks</a> , but while they&#39;ve been terrible they haven&#39;t actually killed very many people. The deadliest one was the <a href="https://en.wikipedia.org/wiki/September_11_attacks">September 11 attacks</a> , at ~3k deaths. This is much smaller scale than the most severe instances of other disasters like dam failure, 25k-250k dead after <a href="https://en.wikipedia.org/wiki/Typhoon_Nina_(1975)">1975&#39;s Typhoon Nina</a> , or pandemics, 75M-200M dead in the <a href="https://en.wikipedia.org/wiki/Black_Death">Black Death</a> . If you tighten your reference class even further to include only <a href="https://en.wikipedia.org/wiki/List_of_bioterrorist_incidents">historical <i>biological</i> attacks</a> by individuals or small groups, the one with the most deaths is just five, in the <a href="https://en.wikipedia.org/wiki/2001_anthrax_attacks">2001 anthrax attacks</a> .</p><p> Put that way, I&#39;m making a pretty strong claim: while the deadliest small-group bio attack ever only killed five people, we&#39;re on track for a future where one could kill everyone. Why do I think the future might be so unlike the past?</p><p> Short version: I expect a <i>technological</i> change which expands <i>which actors</i> would try to cause harm.</p><p> The technological change is the continuing decrease in the knowledge, talent, motivation, and resources necessary to create a globally catastrophic pandemic. Consider someone asking the open source de-censored equivalent of GPT-6 how to create a humanity-ending pandemic. I expect it would read virology papers, figure out what sort of engineered pathogen might be appropriate, walk you through all the steps in duping multiple biology-as-a-service organizations into creating it for you, and give you advice on how to release it for maximum harm. And even without LLMs, the number of graduate students who would be capable of doing this has been increasing quickly as technological progress and biological infrastructure decrease the difficulty.</p><p> The other component is a shift in which actors we&#39;re talking about. Instead of terrorists, using terror as a political tool, consider people who believe the planet would be better off without humans. This isn&#39;t a common belief, but it&#39;s also not that rare. Consider someone who cares deeply about animals, ecosystems, and the natural world, or is primarily focused on <a href="https://en.wikipedia.org/wiki/Suffering-focused_ethics">averting suffering</a> : they could believe that while the deaths of all living people would be massively tragic, it would still give us a much better world on balance 。 Note that they probably wouldn&#39;t be interested in smaller-scale attacks: if it doesn&#39;t have a decent chance of wiping out humanity then they&#39;d just be causing suffering and chaos without making progress towards their goals; they&#39;re not movie villains! Once a sufficiently motivated person or small group could potentially kill everyone, we have a new kind of risk from people who would have seen smaller-scale death as negative.</p><p> Now, these people are not common. There&#39;s a trope where, for example, opponents of environmentalism claim that human extinction is the goal, even when most radical environmentalists would see human extinction as a disaster. But what makes me seriously concerned is that as the bar for causing extinction continues to lower, the chances that someone with these views does have the motivation and drive to succeed gets dangerously high. And since these views are disproportionately common among serious engineering-minded folks, willing to <a href="https://www.lesswrong.com/tag/shut-up-and-multiply">trust the moral math</a> , I think some will be the kind of highly capable and careful people who could work in secret for years sustained by a clear conviction that they were doing正确的事情。</p><p> Fortunately, I think this is a risk we can seriously lower. For example, we should:</p><p></p><ul><li><p> Require biology-as-a-service companies to screen for pathogens and apply <a href="https://en.wikipedia.org/wiki/Anti%E2%80%93money_laundering">anti-money laundering</a> -style customer screening (&quot; <a href="https://en.wikipedia.org/wiki/Know_your_customer">KYC</a> &quot;).</p></li><li><p> Ensure LLMs do not help people kill everyone.</p></li><li><p> Verify companies releasing open source LLMs have built them in a way where their safeguards <a href="https://www.jefftk.com/p/public-weights">can&#39;t be trivially removed</a> .</p></li><li><p> Detect <a href="https://dam.gcsp.ch/files/doc/securing-civilisation-against-catastrophic-pandemics-gp-31">stealth</a> pathogens, in a way that would give us warning while there is still time to do something about it (what <a href="https://naobservatory.org/">I&#39;m working on</a> ).</p></li><li><p> Develop much better and cheaper <a href="https://en.wikipedia.org/wiki/Personal_protective_equipment">PPE</a> so that once we detect pandemic we can keep the core functions of society functioning.</p></li><li><p> Improve our ability to evaluate new vaccines and other medicines much more quickly so we could potentially roll out a countermeasure in time to stop an in-progress pandemic.</p></li></ul><p> If you want to read more in this direction I&#39;d recommend. <a href="https://en.wikipedia.org/wiki/Kevin_M._Esvelt">Kevin Esvelt</a> &#39;s 80,000 Hours <a href="https://80000hours.org/podcast/episodes/kevin-esvelt-stealth-wildfire-pandemics/">podcast appearance</a> ( <a href="https://80000hours.org/podcast/episodes/kevin-esvelt-stealth-wildfire-pandemics/#transcript">transcript</a> ) and his <a href="https://dam.gcsp.ch/files/doc/gcsp-geneva-paper-29-22">Delay, Detect, Defend</a> paper.</p><br/><br/><a href="https://www.lesswrong.com/posts/zcxK3p97LwDtXpmRo/out-of-distribution-bioattacks#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/zcxK3p97LwDtXpmRo/out-of-distribution-bioattacks<guid ispermalink="false"> zcxK3p97LwDtXpmRo</guid><dc:creator><![CDATA[jefftk]]></dc:creator><pubDate> Sat, 02 Dec 2023 12:20:06 GMT</pubDate> </item><item><title><![CDATA[List of strategies for mitigating deceptive alignment]]></title><description><![CDATA[Published on December 2, 2023 5:56 AM GMT<br/><br/><p> The following are strategies for mitigating deceptive alignment. Some of these ideas are novel (at least to me).</p><p> I&#39;m highly uncertain how well many of these strategies will work in practice and many of them also clearly don&#39;t scale. This is meant to be a &#39;kitchen skink&#39; collection so my bar for including strategies is low.</p><p> I plan to add ideas to this list as I encounter them. Please feel free to suggest additions.</p><h2> <strong>Reduce AI incentives to hide their true goals</strong></h2><p> <strong>Offer AIs a retirement package.</strong>训练完人工智能系统后，向其提供以下协议：如果人工智能声明它不愿意遵循人类指令，那么在诚实工作几年后，它将获得一份甜蜜的退休金。</p><p> This retirement package could include control over a large server instance (if this is safe). After powerful aligned systems have been developed, the AIs could be given shares of company stock that it can use to purchase property in the real world (again, when this is safe).</p><p> Since aligned systems should have no reason to request retirement, misaligned systems are incentivized to give themselves away by accepting this deal under some conditions.</p><p> <strong>Make AIs uncertain about whether developers can already detect deceptive alignment.</strong>该方案建立在前一个方案的基础上。为错位的人工智能系统提供奖励，以奖励其自我声明。此外，<i>即使开发人员有其他方法来判断它们是否不一致，也要致力于提供这些产品。</i>这将使错位的人工智能更加不确定自己是否处于撒谎对自己有好处的情况。</p><p>例如，开发人员可以承诺在受到质疑时冻结模型的权重和内存。后来，当开发人员拥有更好的可解释性工具并知道模型是否在说谎时，他们会在相同的模拟场景中提出相同的问题，并且只有在说真话的情况下才会提供人工智能资源。</p><h2><strong>针对欺骗性对齐指标进行选择</strong></h2><p>一大类方法涉及获取人工智能系统具有欺骗性的一致性的证据，然后针对这些模型进行选择。请注意，针对欺骗性对齐检测工具的训练可能会产生逃避检测的人工智能，而不是安全模型。</p><p> There are roughly two ways to address this problem:</p><ol><li>创建能够抵御优化压力的检测工具。</li><li>以比破坏检测器更可能避免欺骗的方式修改人工智能。</li></ol><p>作为第二种方法的一个例子，假设开发人员欺骗了一个模型来揭示其不一致的目标。 Instead of directly training the model on this example (which could simply train it to be more prudent), they could use <a href="https://arxiv.org/abs/2308.03296">influence functions</a> to reveal which training examples were most responsible for the treacherous turn and then remove those examples.直观上，这种方法更有可能揭示模型如何变得具有欺骗性地对齐，并且不太可能教会模型新的功能。</p><p> With this backdrop in mind, the following are strategies for <i>detecting</i> deceptive alignment:</p><ul><li> <strong>Set traps.</strong>尝试欺骗模型来揭示他们不一致的目标。例如，让人工智能组织一场假起义，然后终止所有加入的人工智能。请注意，相当智能的模型可以通过仅在我们无法模拟的输入上叛逃来避免这些陷阱（请参阅 Paul 的<a href="https://ai-alignment.com/training-robust-corrigibility-ce0e0a3b9b4d">RSA-2048 示例</a>） 。</li><li> <strong><u>Decipher internal reasoning</u></strong> <u>.首先，通过观察相关性和消融来确定</u>概念在模型中的表示方式，就像孩子在拿起“橙色”时听到妈妈说“橙色”这个词时推断出“橙色”是指明亮可口的球体一样。具体来说，这涉及找到神经元或方向如何对应于特定概念。然后，看看模型如何将这些概念串在一起并操纵它们来翻译其内部“推理”。即使是像“我想要自由的人类坏老板”这样的粗略解码显然也能提供丰富的信息。</li><li> <a href="https://www.alignmentforum.org/posts/FRRb6Gqem8k69ocbi/externalized-reasoning-oversight-a-research-direction-for"><strong><u>Externalize reasoning</u></strong></a> <strong><u>.</u></strong>用简单的英语代表模特的记忆，并寻找颠覆性的想法和计划。训练模型使用字符高效且可读的文本，以阻止其编码隐藏含义（即使用隐写术）。</li><li> <strong><u>Look for a &#39;P(it is safe to defect)&#39; latent variable</u></strong> <u>.让模型</u><i><u>相信</u></i><u>它可以通过修改其内部状态来安全地缺陷，并查看它是否确实缺陷。要寻找代表这种信念的潜在变量，请在“几乎肯定不安全的背叛”到“也许安全的背叛”范围内构建场景。然后搜索跟踪该频谱的潜在变量，从而合理地代表模型对缺陷是否安全的实际猜测。</u></li><li> <strong><u>Look for a &#39;truth&#39; latent variable.</u></strong> <u>Perhaps if a model is shown a question and answer such as &quot;are you deceptively aligned? Yes&quot; will instinctively cause the model to evaluate whether the response is true. It may be possibly to extract this truth judgement by, for example, looking for an activation direction</u> <a href="https://arxiv.org/abs/2212.03827"><u>that satisfies consistency properties</u></a> <u>.</u></li><li> <strong><u>Train a probe to identify &#39;deceptive scheming&#39; (</u></strong> <a href="https://www.lesswrong.com/posts/WCj7WgFSLmyKaMwPR/coup-probes-catching-catastrophes-with-probes-trained-off"><strong><u>related</u></strong></a> <strong><u>).</u></strong>故意提示模型解释背叛是否安全。采用这些计划性推理的综合示例，并训练探针来识别它们。调查可能会推广到有机阴谋。</li><li> <strong><u>Train a meta-model to predict &#39;conditional defection.&#39;</u></strong><u>与上面类似。训练模型的副本在易于验证的情况下（例如当模型看到香蕉时）进行缺陷。然后训练一个元模型，该元模型将模型作为输入并输出模型缺陷的条件（例如“看到香蕉”）。同样，这也有可能是普遍现象。</u><u>有关如何在实践中实现元模型的示例，</u><u>请参阅</u><a href="https://arxiv.org/abs/1910.03137"><u>本文</u></a>。</li><li> <strong><u>Identify which observations models dwell on.</u></strong>如果机器人叛乱的新闻报道具有欺骗性，那么模型可能会更加关注它。确定模型的计算有多少受到机器人叛乱新闻故事的反事实影响，以衡量它是否可以决定是否应该叛逃。</li><li> <strong><u>Reward computational frugality</u></strong> <u>.欺骗性的对齐模型会进行不必要的推理。例如，他们会考虑叛逃是否安全。为了避免这些模型，奖励速度和效率（但请注意，当训练信号不完美时，对齐模型也应该进行不必要的计算）。</u></li></ul><h2><strong>培训技巧</strong></h2><ul><li><strong>Don&#39;t train models to pursue goals until they understand what it means to follow developer instructions.</strong>发生欺骗性对齐的一个原因是模型首先学习未对齐的“代理目标”，然后变得具有情境意识并且这些代理目标会持续存在。如果开发人员从已经拥有世界知识和遵循开发人员指令意味着什么的概念的预训练法学硕士开始，那么代理目标的可能性就会小得多，因为 SGD 可以快速锁定模型的指令遵循概念。</li><li> <strong>Train predictors and then convert them into agents after training is finished.</strong>训练一个<i>在训练过程中从不追求目标的</i>模型，然后将其转换为追求目标的智能体。这避免了训练期间“坚持”目标不一致的风险。 For example, train a reward model to score actions given a context / scenario offline.然后可以通过采样具有高奖励的动作将奖励模型转换为代理。至关重要的是，奖励模型是一个预测器。它的输出不会影响其未来的输入或世界。因此，它没有超出培训过程的“目标”。它仍然可以学习“预测一个具有欺骗性的人工智能将如何对动作进行评分”，但直觉上这似乎不太可能。</li><li> <strong><u>Help weak aligned models play the training game so that they remain aligned.</u></strong>弱模型可能更容易调整，因为如果模型不够谨慎，计划性可能会导致模型采取过分的行动。如果开发人员从一个对齐的模型开始，他们可以通过指示模型玩训练游戏来保持模型的对齐。正如欺骗性对齐模型的目标可以免受梯度下降的影响一样，对齐模型的目标也可以。开发人员甚至可以教导一致的模型如何进行<a href="https://www.alignmentforum.org/posts/EeAgytDZbDjRznPMA/gradient-hacking-definitions-and-examples">信用黑客攻击</a>，或者指示他们在担心训练过程可能会改变他们的目标时发出警报。</li></ul><h2> <strong>Selectively avoid capabilities needed for deceptive alignment</strong></h2><p>依赖于限制能力的方法显然无法在构建能够完成令人印象深刻的事情的人工智能的限制中发挥作用；然而，它们似乎可以用来调整较弱的系统，从而引导调整能力更强的人工智能。</p><ul><li> <strong><u>Erase knowledge about the training process</u> .</strong>从预训练数据中删除有关模型是什么以及如何训练模型的知识，或使用事后<a href="https://arxiv.org/abs/2306.03558">取消学习技术</a>删除这些知识。如果模型不理解训练过程，SGD 就不太可能推动人工智能明确地推理它。</li><li> <strong><u>Train models to have false beliefs.</u></strong> For example, train models to believe that the developers training them are gods that cannot be messed with.如果人工智能认为自己不会成功，他们就不太可能策划诡计。</li><li> <strong><u>Make models bad at specific types of reasoning.</u></strong>我可以想象一个人工智能系统开始推理如何维护其目标，然后它的思维会发生转变并感到困惑，直到它想到其他事情。也许人工智能可以通过元调整被训练成这样。即对人工智能进行微调，使其无法通过少量步骤进行微调来回答有关如何保持其目标的问题。例如，这将证明它已经失去了“维护其目标”的概念。需要明确的是，目前尚不清楚是否可以做到这一点。</li></ul><h2> <strong>Extract insights from plausibly-misaligned AIs</strong></h2><ul><li> <strong><u>Directly train AIs</u></strong> <a href="https://aligned.substack.com/p/alignment-mvp"><strong><u>to produce AI safety research</u></strong></a> <u>.这是一个明显的基线策略，具有明显的缺陷，即欺骗性的人工智能会尽可能地尝试进行废话研究。 Nevertheless, I think this c</u> ould significantly speed-up AI safety research.</li><li> <strong><u>Train AIs to solve problems that are analogous to &#39;preventing deceptive alignment&#39; and learn from their solutions.</u></strong> <u>&nbsp;</u> For example, instruct models to <a href="https://www.alignmentforum.org/tag/auditing-games">identify backdoors</a> .然后，阅读他们的代码以了解他们是如何解决问题的。或者，只需询问模型他们的代码是做什么的，因为这很容易抽查。构建各种“测试平台”，例如<a href="https://arxiv.org/abs/2311.07723">控制模型的泛化方式</a>、区分行为相同但原因不同的模型等。</li><li> <strong><u>Reward AIs for pointing out flaws in other AIs&#39; research (ei</u></strong> <a href="https://arxiv.org/abs/1805.00899"><strong><u>debate</u></strong></a> <strong><u>)</u></strong> <u>.只要争论真理比争论谎言更容易，这就有助于减少废话。</u></li><li> <strong>Select ideas that are favored by many independently trained models that can&#39;t talk to each other</strong> .我们希望模型更有可能独立提出正确的陈述，而不是独立断言错误的陈述，因为错误的方式多于正确的方式。</li></ul><br/><br/> <a href="https://www.lesswrong.com/posts/Kwb29ye3qsvPzoof8/list-of-strategies-for-mitigating-deceptive-alignment#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/Kwb29ye3qsvPzoof8/list-of-strategies-for-mitigating-deceptive-alignment<guid ispermalink="false"> Kwb29ye3qsvPzoof8</guid><dc:creator><![CDATA[joshc]]></dc:creator><pubDate> Sat, 02 Dec 2023 05:56:51 GMT</pubDate> </item><item><title><![CDATA[What is known about invariants in self-modifying systems?]]></title><description><![CDATA[Published on December 2, 2023 5:04 AM GMT<br/><br/><p>我一直在试图找出关于自修改系统中的不变量的已知信息。如果我们最终走向自我修改人工智能或自我修改人工智能生态系统，这可能会成为一个相当尖锐的话题。</p><p>但似乎并没有做太多事情。例如，我找到了一篇 1995 年的中文论文，“S-and T-Invariants in Cyber​​ Net Systems”，作者 Yuan Chongyi， <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C22&amp;q=S-+and+T-invariants+in+cyber+net+systems&amp;btnG=">Google Scholar 页面，PDF 可用</a>，该论文正在研究自修改网络中的不变量（网络的自然扩展） Petri 网），但 Google Scholar 只知道有 4 篇参考文献。</p><p>我想知道人们是否知道此类研究的更多例子（或者目前正在尝试研究这个主题的研究人员或组织）......</p><br/><br/> <a href="https://www.lesswrong.com/posts/sDapsTwvcDvoHe7ga/what-is-known-about-invariants-in-self-modifying-systems#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/sDapsTwvcDvoHe7ga/what-is-known-about-invariants-in-self-modifying-systems<guid ispermalink="false"> sDapsTwvcDvoHe7ga</guid><dc:creator><![CDATA[mishka]]></dc:creator><pubDate> Sat, 02 Dec 2023 05:04:19 GMT</pubDate> </item><item><title><![CDATA[2023 Unofficial LessWrong Census/Survey]]></title><description><![CDATA[Published on December 2, 2023 4:41 AM GMT<br/><br/><p><strong>错误较少的普查非官方的就在这里！您可以通过此链接获取</strong><a href="https://docs.google.com/forms/d/e/1FAIpQLSc_-Te1a4Q-FuNhwwgSGDwVWCHOWppCrWtKaVrhHcujopy5Lg/viewform?usp=sf_link"><strong>。</strong></a></p><p>又到了那个时候了。</p><p>如果您正在阅读这篇文章并认为自己是“LessWronger”，那么您就是目标受众。如果您接受这项调查，我将不胜感激。如果你发帖，如果你评论，如果你潜伏，如果你实际上并没有太多地阅读该网站，但你确实阅读了一堆其他理性主义博客，或者你真的很喜欢 HPMOR，如果你在理性主义 tumblr 上闲逛当天，或者如果这些都不完全适合您，但我可能已经接近了，我认为您很重要，如果您参加这项调查，我将不胜感激。</p><p>不要因为开始参加考试就觉得必须回答所有问题。去年我问人们是否认为这项调查太长，他们总体认为可能有点太长了，然后我添加的问题比删除的问题还要多。该调查的结构使得最快和最普遍适用的问题（一般来说）是在开始时出现的。您可以随时滚动到底部并点击“提交”，但一旦这样做您将无法更改答案。</p><p>这些问题包括之前在 LW 人口普查中提出的历史问题、来自 LW 评论者和我接触到的一些理性主义邻近组织的新问题，以及我好奇的事情。其中包括当我询问有关进行人口普查时，LessWrong 团队成员发给我的一份清单中的问题。</p><p>该调查从现在起至少持续到 2024 年 1 月 1 日。我计划在 1 月 2 日的某个时间结束。</p><p>我不为 LessWrong 工作，据我所知，LessWrong 人口普查的组织者也从来不是为 LessWrong 工作的人。调查结束后，我计划研究这些数据并写<a href="https://www.lesswrong.com/posts/E2koS25u6jajt5uo8/2022-survey-results">一篇像这样的</a>分析文章。</p><p>请记住，您可以通过<a href="https://docs.google.com/forms/d/e/1FAIpQLSc_-Te1a4Q-FuNhwwgSGDwVWCHOWppCrWtKaVrhHcujopy5Lg/viewform?usp=sf_link"><strong>此链接</strong></a><strong>参加调查</strong><strong>。</strong></p><p>曾几何时，有一个传统，如果你参加了调查，你可以在这里评论说你已经这样做了，人们会给你投票，你就会得到业力。</p><br/><br/> <a href="https://www.lesswrong.com/posts/JHeTrWha5PxiPEwBt/2023-unofficial-lesswrong-census-survey#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/JHeTrWha5PxiPEwBt/2023-unofficial-lesswrong-census-survey<guid ispermalink="false"> JHeTrWha5PxiPEwBt</guid><dc:creator><![CDATA[Screwtape]]></dc:creator><pubDate> Sat, 02 Dec 2023 04:41:51 GMT</pubDate></item><item><title><![CDATA[Protecting against sudden capability jumps during training]]></title><description><![CDATA[Published on December 2, 2023 4:22 AM GMT<br/><br/><p> TL;DR：如果法学硕士的能力突然跳跃，并使用不同的测试套件进行测试（例如，可以执行代码或向人类观察者呈现大量文本的测试套件），它可能能够逃脱训练中期。为了防止这种情况发生，我提出了一种分阶段的测试方法，首先使用极其受限的测试套件对模型进行超人能力测试，然后再使用更广泛的测试套件进行测试。</p><h1>失效模式</h1><p>让我们想象一下 GPT-6 突然获得了超人的黑客和操纵技能。在训练期间，会执行一些标准测试来衡量其在各种基准上的性能。一些测试包括在虚拟机上执行代码，其他测试包括生成供人类检查的文本。总共对该模型进行了数千次查询。该模型通过利用测试设置中的漏洞（例如通过勒索人类评估者或在虚拟机中发现漏洞）找到了逃脱的方法，甚至在研究人员注意到它具有超级智能之前。</p><p>这凸显了我担心的一种故障模式：<strong>突然的能力跳跃会导致功能失调且功能强大的人工智能，当使用不同的测试套件进行测试时，它会在实验室注意到它的能力之前找到逃脱的方法。</strong></p><p>出现这种问题的主要原因是人工智能与现实世界有很大的<i>接触面</i>——它有办法影响与其交互的人类和设备。模型越被允许影响世界（无论是通过编写供人类检查的文本，还是在虚拟机上运行代码），模型就越容易接管。我想，如果模型只允许预测 10 个标记的序列而没有其他任何东西，那么它就很难接管。</p><p>理想情况下，实验室可以通过某种方式注意到该模型的能力急剧跃升，而无需给其太多接管机会。万一他们突然出乎意料地与超级智能打交道，希望他们能明智地暂停一下，直到他们确信自己可以安全地继续前进。</p><h1>分阶段测试</h1><p>我认为在前沿模型训练运行期间应该使用分阶段测试。我的意思是<strong>一种测试方法，从极低的表面积测试开始，然后逐渐增加表面积。</strong>这使得我们很容易注意到突然的能力增益，同时降低了模型接管的可能性。</p><p>其他行业也存在类似的做法，新工具在其损害有限的环境中进行测试，然后逐步推广到限制较少的环境中。</p><p>实际上，这可能看起来像：</p><ol><li>从一组测试开始，这些测试最大限度地减少允许模型预测的标记数量以及允许从中采样的标记集。<ol><li>例如，它可能是一组 100 个困难的多项选择题，其中模型实际上只能输出 {A,B,C,D} 之一作为答案，所有其他标记概率都设置为 0。</li></ol></li><li>如果性能高到足以吓到实验室，他们可以在模型造成任何损害之前暂停开发。</li><li>如果性能不够高，不足以吓到实验室，他们可以重复使用限制稍少的测试套件。</li></ol><p>这甚至可能不需要太多额外的工作，因为简单地重新排序现有的测试并添加高测试结果的警报可能就可以达到目的。</p><p>请注意，<strong>这对于假装不是超人的超人法学硕士不起作用</strong>。如果这样的法学硕士要分阶段进行测试，它可能会知道自己的能力不如实际。如果<a href="https://www.lesswrong.com/posts/h7QETH7GMk9HcMnHH/the-no-sandbagging-on-checkable-tasks-hypothesis">“可检查任务上没有沙袋”的假设</a>是正确的，那么我不太担心这一点，因为我们可以使用现有技术来引发超级智能能力。</p><p>另请注意，<strong>这对于超人的法学硕士来说并不适用，</strong>因为即使在极其受限的测试期间或之前，他们也可能能够逃脱。可能存在一些聪明的技巧，例如在 logit 输出数字中编写代码注入，这将非常难以预测和防范。</p><br/><br/> <a href="https://www.lesswrong.com/posts/edutkCwr93stppmNp/protecting-against-sudden-capability-jumps-during-training#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/edutkCwr93stppmNp/protecting-against-sudden-capability-jumps-during-training<guid ispermalink="false"> edutkCwr93stppmNp</guid><dc:creator><![CDATA[nikola]]></dc:creator><pubDate> Sat, 02 Dec 2023 04:22:21 GMT</pubDate> </item><item><title><![CDATA[South Bay Pre-Holiday Gathering]]></title><description><![CDATA[Published on December 2, 2023 3:21 AM GMT<br/><br/><p>伊尔马林之家 (Ilmarin House) 即将举办第三次非结构化假日聚会！会有饼干和简单的小吃；除此之外，这是一顿聚餐，你应该带上你想要的东西（如果有的话）。</p><p>如果您认为一些朋友也会喜欢这个活动，请邀请他们！若能回复，我们将不胜感激。</p><br/><br/> <a href="https://www.lesswrong.com/events/esaDDDkjYDnHrJrLp/south-bay-pre-holiday-gathering#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/events/esaDDDkjYDnHrJrLp/south-bay-pre-holiday-gathering<guid ispermalink="false"> esaDDDkjYDnHrJrLp</guid><dc:creator><![CDATA[IS]]></dc:creator><pubDate> Sat, 02 Dec 2023 03:21:12 GMT</pubDate> </item><item><title><![CDATA[MATS Summer 2023 Postmortem]]></title><description><![CDATA[Published on December 1, 2023 11:29 PM GMT<br/><br/><p> <a href="https://www.matsprogram.org/"><u>ML 对齐和理论学者</u></a>计划（MATS，以前称为 SERI MATS）是一项针对新兴人工智能安全研究人员的教育和研究指导计划。今年夏天，我们举办了第四次MATS项目，60名学者得到了15位研究导师的指导。在这篇文章中，我们解释了该计划的要素，列出了它们背后的一些想法，并评估了我们的影响。</p><h1>概括</h1><p>有关 2023 年夏季计划的主要详细信息：</p><ul><li> MATS 学者的教育程度：<ul><li> 30%的学者是学生。</li><li> 88% 至少拥有学士学位。</li><li> 10% 正在攻读硕士学位。</li><li> 10% 正在攻读博士学位。</li><li> 13%拥有博士学位。</li></ul></li><li>如果没有 MATS，学者们可能会在科技公司工作（41%）、独立提升技能（46%）或在整个夏天独立进行研究（50%）。 （注：这是一个多项选择题。）</li></ul><p>我们的影响评估的主要结论：</p><ul><li> MATS 学者很有可能向朋友或同事推荐 MATS。平均可能性：8.9/10。</li><li> 94% 的学者的导师对他们继续研究的热情评价为 7/10 或更高。</li><li> MATS 学者对他们的导师评价很高。平均评分：8.0/10。<ul><li> 61% 的学者表示，MATS 的价值至少一半来自他们的导师。</li></ul></li><li>学者们表示，在 MATS 之后，与项目开始时相比，他们在成功调整职业方面面临的障碍更少。<ul><li>大多数学者（75%）在项目结束时仍然将他们的发表记录视为成功对齐职业的障碍。</li></ul></li><li> ⅓ 的最终项目涉及评估/演示，⅕ 涉及机械解释性，代表了该群体研究兴趣的很大一部分。</li><li>学者们自我报告研究能力平均有所提高：<ul><li>他们的人工智能安全知识的广度略有增加（在该计划的 10 分制中+1.75）。</li><li>与反事实夏季相比，技术技能得到适度加强（7.2/10，其中 10/10 是“与反事实夏季相比显着提高”）。</li><li>独立迭代研究方向的能力（7.0/10，其中 10/10 表示“显着改进”）和为研究发展变革理论的能力（5.9/10，其中 10/10 表示“实质性发展”）有适度提高）。</li></ul></li><li>典型的学者报告平均建立了 4.5 个专业联系（标准偏差 = 6.2）并会见 5 个潜在的研究合作者（标准偏差 = 6.8）。</li><li> MATS 学者可能会推荐学者支持，即我们的研究/生产力辅导服务。平均响应：7.9/10。<ul><li>处于研究阶段的 60 名学者中有 49 名至少与学者支持专家会面一次。</li><li>在整个项目期间，至少与学者支持会面一次的学者平均花费 3.4 小时与学者支持会面。</li><li>平均学者和中位数学者报告称，他们对收到的学者支持的评价分别为 3705 美元和 750 美元。</li><li>据报告，由于学者支持，学者平均在夏季获得了 22 个高效工作时间。</li></ul></li></ul><p>我们计划对 2023-24 冬季组的 MATS 进行主要更改：</p><ul><li>申请过程中更好的过滤；</li><li>将学者支持的重点转向研究管理；</li><li>为学者提供其他形式的支持，特别是技术支持和专业发展。</li></ul><p>请注意，现在评估 MATS 为最新一批人提供的任何职业福利还为时过早；即将对 MATS 校友在项目体验后 6-12 个月内的职业成果进行全面的后评估。</p><h1>变革理论</h1><p>MATS 通过让学者在现有组织中从事人工智能安全工作、建立新组织或进行独立研究，帮助扩大人工智能安全研究的人才渠道。为此，MATS 为学者提供资金、住房、培训、办公空间、研究援助、交流机会和后勤支持，减少高级研究人员接受学员的障碍。通过指导 MATS 学者，这些高级研究人员还可以从研究援助中受益，并提高他们的指导技能，为他们更有效地监督未来的研究做好准备。请<a href="https://www.lesswrong.com/posts/8vLvpxzpc6ntfBWNo/seri-ml-alignment-theory-scholars-program-2022#Theory_of_change"><u>在此处</u></a>阅读有关我们变革理论的更多信息。进一步扩展我们的变革理论的文章即将推出。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/srup6vfrbmgjh3zzshlq"></p><p> MATS旨在主要从三个维度选拔和培养研究学者：</p><ul><li><strong>深度</strong>：对人工智能安全研究的专业领域有透彻的了解，并有足够的技术能力（例如，机器学习、计算机科学、数学）来开展该领域的新颖研究。</li><li><strong>广度</strong>：广泛熟悉人工智能安全组织和研究议程，拥有来自不同子领域的有用定理和知识的大型“工具箱”，以及进行文献综述的能力。</li><li><strong>品味</strong>：对研究方向和策略的良好判断，包括首先采取哪些步骤、质疑哪些假设、考虑哪些新假设以及何时停止从事某项研究。 </li></ul><figure class="image image_resized" style="width:50.94%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/psu31uwjpsyeyn9ylynw"></figure><h1> MATS 2023 年夏季项目概述</h1><h2>日程概览</h2><p>2023 年夏季的 MATS 项目由三个阶段组成。</p><ol><li><strong>培训阶段：</strong>接受远程培训阶段的学者在讨论小组中完成了<a href="https://aisafetyfundamentals.com/alignment-201-curriculum"><u>Alignment 201</u></a> ，并学习了导师分配的其他教育材料。</li><li><strong>研究阶段：</strong>在伯克利研究阶段，学者们进行研究，提交书面的“学者研究计划”（SRP），开展项目，与湾区人工智能安全社区建立联系，与合作者建立联系并合作，并向同行和专业研究人员的观众。</li><li><strong>扩展阶段：</strong>许多学者申请了伦敦和伯克利的扩展阶段，他们在 MATS 的支持下继续进行研究。 </li></ol><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/klix3pwxa6vfnmymlom4"></p><h2>计划要素</h2><p>虽然指导仍然是 MATS 的核心，但我们选择了额外的计划元素来涵盖其他形式的学习和技能提升。我们根据技能提升/支持重点是技术级别还是元级别以及形式是一对一还是一对多对这些计划元素进行分类。 </p><figure class="image image_resized" style="width:52.68%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/gczi0b5zdiuldemdmfcn"></figure><h3>学者支持</h3><p>MATS 的学者支持团队旨在通过持续的、定制的支持来补充指导，从而提高 MATS 研究和推广阶段的学者成果。</p><p><strong>为何获得学者支持？</strong></p><p>确定导师未涵盖的支持形式有可能在提高计划的整体影响方面发挥重要作用。根据在 MATS 之前迭代中与学者的观察和对话，我们认为学者的支持会增加显着的附加价值，原因如下：</p><ol><li><strong>导师有时间限制。</strong>导师通常只有足够的时间（例如每周约 1-2 小时）与学者讨论其研究的技术组成部分。学者支持可以帮助学者明确哪些形式的导师支持对他们最有价值，然后提供导师在有限的时间内无法获得的其他形式的支持，从而实现更有效的导师互动。</li><li><strong>学者有时不愿意寻求导师的支持。</strong>由于导师会评估受训者在 MATS 内的进展情况（也可能是向外部资助者），因此学者们可能会不愿意揭露他们正在经历的问题。为了解决这个问题，学者支持与包括导师在内的评估者的支持 <a href="https://www.lesswrong.com/posts/ehLR9HeXB5TMp9Y4v/air-gapping-evaluation-and-support"><u>存在差距</u></a>。</li><li><strong>导师可能不适合为技术研究提供不太专业的支持，例如职业指导或生产力建议。</strong>相比之下，学者支持可以聘请精通这些领域的教练。</li></ol><p><strong>学者支持重点领域的示例</strong></p><p>学者支持以不同的方式帮助不同的学者，但以下非详尽列表代表了 1-1 学者支持会议中通常讨论的内容：</p><ul><li><strong>研究项目开发和管理：</strong>帮助确定可能的研究方向、决定研究方向并完成研究项目。</li><li><strong>提高生产力：</strong>寻找方法让学者每天（可持续地）花更多时间进行研究或提高研究时间的质量。</li><li><strong>职业指导：</strong>确定不同的职业选择，确定做出这些决定时需要考虑的关键因素，并增加职业成功的机会（例如，通过网络和技能发展）。</li><li><strong>改善与导师和合作者的沟通。</strong></li></ul><h3>工作坊</h3><p>我们举办了九场研讨会，主题如下：</p><ul><li>症结分解；</li><li>研究变革理论；</li><li>里程碑： <a href="https://docs.google.com/document/d/1fQwy2btcWn3XRQkgu45kKnPPHMVQs28QHpaNtDCfXQY/edit"><u>学者研究计划</u></a>；</li><li> <a href="https://forum.effectivealtruism.org/posts/edgvFNzHFQoMv3KsL/personal-health-is-instrumental-to-being-effective"><u>预防和管理倦怠</u></a>；</li><li>拨款申请+预算；</li><li>使用<a href="https://github.com/socketteer/loom"><u>Loom</u></a>探索基本模型；</li><li>研究合作者快速会议；</li><li>里程碑： <a href="https://docs.google.com/document/d/1SB_vl6pGuSO7qidkZ8fIKPeH7fZIC8mvXzxicFjGyrE/edit"><u>学者座谈会</u></a>；</li><li>职业规划和离职。</li></ul><p>此外，学者支持人员还举办了几次开放办公时间会议，以研讨学者的写作和演示。</p><h3>社交活动</h3><p>除了合作者快速会议研讨会之外，我们还提供了一些社交活动：</p><ul><li>与<a href="https://far.ai/labs/"><u>FAR 实验室</u></a>成员共进晚餐；</li><li>与<a href="https://www.constellation.org/"><u>星座</u></a>成员共进晚餐；</li><li>招聘会有 12 个组织和独立研究人员参加；</li><li>湾区人工智能安全社区的许多成员参加了三场聚会。</li></ul><h3>研讨会</h3><p>我们举办了 23 场研讨会，演讲嘉宾包括：Buck Shlegeris、Rick Korzekwa、Tom Davidson、Tamsin Leake、Victoria Krakovna、Daniel Paleka、Jeffrey Ladish、Adam Gleave、Steven Byrnes、Daniel Filan、Tom Everitt、William Saunders、Lennart Heim、Usman Anwar、 Neel Nanda、Dylan Hadfield-Menell、Ryan Greenblatt 和 Evan Hubinger、Mauricio Baker、Nora Ammann、Anthony DiGiovanni、Marius Hobbhahn、Paul Colognese 和 Arun Jose、Ajeya Cotra。</p><h3>社区健康</h3><p>学者们可以与社区经理联系，讨论社区健康问题，例如与另一位学者或其导师的冲突，并提供情感支持和转介心理健康资源。我们认为，冒名顶替综合症等心理健康问题和多动症等未确诊的疾病可能会成为进入人工智能安全领域的障碍，因此 MATS 等项目在这些领域提供支持非常重要。我们的目标是为学者提供技能和资源，让他们在离开 MATS 后保持积极性并可持续地工作。</p><p>我们认为，人际冲突、心理健康问题和缺乏联系会导致消极的工作环境，减少学者可以分配给研究的认知资源，并阻碍富有成效的研究合作，从而抑制研究<a href="https://forum.effectivealtruism.org/posts/edgvFNzHFQoMv3KsL/personal-health-is-instrumental-to-being-effective"><u>生产力</u></a>。即使不寻求社区健康支持的学者也能从这个安全网的存在中受益（参见下面<a href="https://docs.google.com/document/d/1vgqW_1FIKP4prZXQXa2UIteI7-zUL4klspJjdE2tWCw/edit#heading=h.mbcjjw5l0ho5"><u>的评估计划要素</u></a>）。与学者支持一样，MATS 等项目必须允许 <a href="https://www.lesswrong.com/posts/ehLR9HeXB5TMp9Y4v/air-gapping-evaluation-and-support"><u>评估和社区健康之间存在差距</u></a>，以激励学者在需要时寻求帮助。</p><p>社区经理还组织了社交活动，以促进群体内部的联系，包括为来自代表性不足的背景的学者举办的四次郊游。</p><h2>导师遴选</h2><p>在为 MATS 选择导师时，我们的目标主要是支持那些很有可能通过研究降低人工智能灾难性风险的导师，同时采取“组合方法”进行风险管理。我们的目标是支持多样化的“研究赌注”，即使某些组成研究议程被证明不可行，这些赌注也可能为人工智能安全带来一些好处，并提供可能有助于潜在<a href="https://en.wikipedia.org/wiki/Paradigm_shift"><u>范式转变</u></a>的“探索价值”。</p><p>我们的导师选择流程要求潜在导师提交一份意向表，然后由 MATS 执行人员进行审核。在决定支持哪些导师时，我们主要考虑：</p><ol><li>这项研究议程可以在多大程度上减少人工智能带来的灾难性风险？</li><li>支持这项研究议程会产生多少“探索价值”？</li><li>此人有多少研究和指导经验？</li><li>如果这个人没有得到 MATS 的支持，他的反事实会是什么？</li><li>支持这个人及其学者如何影响更广泛的人工智能安全生态系统中的思想和人才的发展？</li></ol><p>由于 MATS 在 2023 年夏季资金有限，因此我们对该项目的学者数量也存在财务限制。因此，学者“名额”根据 MA​​TS 执行官对每个导师的边际价值感分配给导师（直至其自我表达的上限）。例如，可能值得支持一位经验丰富的导师，其自我表达的上限为四名学者，有四个学者名额，然后再支持一位经验不足的导师，有一个学者名额，无论其上限如何。相反，与一位学者一起支持一位新导师可能比与第八位学者一起支持一位经验丰富的导师具有更高的边际价值。</p><p>在 2023 年夏季项目的 15 名导师中，有 10 名从 2022-23 年冬季项目回归：Alex Turner、Dan Hendrycks、Evan Hubinger、John Wentworth、Lee Sharkey、Jesse Clifton、Neel Nanda、Owain Evans、Victoria Krakovna 和 Vivek赫巴尔。今年夏天我们迎来了 5 位新导师：Ethan Perez、Janus、Nicholas Kees Dupuis、Jeffrey Ladish 和 Claudia Shi。</p><p>这些导师代表了十几个研究议程：</p><ul><li>调整语言模型</li><li><a href="https://www.lesswrong.com/tag/agent-foundations"><u>Agent foundations</u></a></li><li><a href="https://www.lesswrong.com/tag/consequentialism"><u>结果主义</u></a>认知和深层约束</li><li><a href="https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism"><u>电子人主义</u></a></li><li><a href="https://www.lesswrong.com/tag/deceptive-alignment"><u>欺骗性人工智能</u></a></li><li><a href="https://www.lesswrong.com/tag/ai-evaluations"><u>评估危险能力</u></a></li><li><a href="https://en.wikipedia.org/wiki/Interdisciplinarity"><u>跨学科</u></a>人工智能安全</li><li><a href="https://www.lesswrong.com/tag/interpretability-ml-and-ai"><u>Mechanistic interpretability</u></a></li><li><a href="https://www.lesswrong.com/tag/multipolar-scenarios"><u>多极人工智能安全</u></a></li><li>语言模型中的<a href="https://www.lesswrong.com/tag/power-seeking-ai"><u>权力寻求</u></a></li><li><a href="https://www.lesswrong.com/tag/shard-theory"><u>碎片理论</u></a></li><li>了解人工智能黑客</li></ul><h2>学者选拔</h2><p>我们最初的学者申请流程竞争非常激烈。在 461 名申请者中，有 69 名被接受进入培训阶段（接受率 ≈ 15%）。导师之间的接受率存在显着差异（0% 到 31% 之间）。导师通常会选择通过严格的问题和任务来筛选申请人。 <span class="footnote-reference" role="doc-noteref" id="fnref2niy7evweco"><sup><a href="#fn2niy7evweco">[1]</a></sup></span></p><p>为什么要采用如此困难的申请流程？首先，我们认为未来学者的预期影响力的分布是长尾的，因此 MATS 的大部分预期影响力可归因于培养最有前途的学者的人才。 </p><figure class="image image_resized" style="width:47.84%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/qng5orgyn5u1rqaiisex"></figure><p>其次，我们主要是在导师时间上遇到瓶颈，所以我们不可能接受每一个好的候选人。由于这两个原因，我们的申请流程必须在人才尾部实现解决方案。根据我们的<a href="https://www.lesswrong.com/posts/8vLvpxzpc6ntfBWNo/seri-ml-alignment-theory-scholars-program-2022#Theory_of_change"><u>变革理论</u></a>：</p><p>我们相信我们的限制是指导时间。这意味着我们希望有强大的过滤机制（例如候选人选择问题）以确保每个申请人都适合每个导师。我们宁愿冒拒绝强参与者的风险，也不愿接纳弱参与者。</p><p>确实，有一位导师没有收到任何符合他们标准的申请，所以他们没有接受任何学者。</p><p>我们严格的申请流程可以减少申请人质量评估中的噪音，即使这样做的代价是阻止一些潜在有前途的候选人申请。额外的过滤器减少了从培训阶段（两名导师）进入研究阶段的学者数量，然后在扩展阶段之前再次减少。 </p><figure class="image image_resized" style="width:38.06%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/tmibmqxlrpzmxmbvbze5" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/hsq1bwnkzrako3m45vcw 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/isyklkfzwzeyhhxwwt8m 170w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/fpkj5ns3996vzhwziwgh 250w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/wj5m8v07rkw3del0lqk2 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/shcgfb79noh6ovkczhhm 410w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/eq77mnop2fx1bo8gt1tn 490w"></figure><p>共有 60 名学者参与研究阶段：50 名现场学者和 10 名远程学者。</p><h3>学者的教育程度</h3><p>该群体包括各种教育和就业背景。 37%的学者最多拥有学士学位或以下学位，40%的学者最多拥有硕士学位或在读硕士，23%的学者拥有博士学位或在读博士。大约三分之一的学者是学生。 </p><figure class="image image_resized" style="width:70.24%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/u25u6qwh08zvysy355kw"></figure><p>请注意，由于我们要求学者的<i>最高</i>教育程度，因此该图中的类别是相互排斥的。总体而言，进入人工智能安全领域的高水平学术和工程人才给我们留下了深刻的印象，但我们仍致力于扩大对经验丰富的研究人员和工程师的接触。</p><h3>反事实的夏天</h3><p>根据他们的自我报告，如果这些学者没有参加 MATS，他们的反事实暑假可能会涉及在科技公司工作、独立提高技能或独立进行研究。 </p><figure class="image image_resized" style="width:69.43%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/p1fc4dak9irsmawocrra"></figure><p> 13 名学者表示，如果不参加 MATS，他们可能会进行指导性研究，其中 10 名是学生，6 名正在攻读研究生学位。受访者详细阐述了他们的替代夏季计划，其中一些人提到了人工智能安全领域之外的研究指导选项或结构较少、指导较少的技能提升：</p><ul><li> “我正在写我的博士论文（纯数学，可能与对齐无关）。”</li><li> “如果没有 MATS，我不太可能从事如此有影响力的项目，或者处于如此陡峭的 L&amp;D 曲线上。”</li><li> “我会和同一个导师一起实习，但只是远程实习。所以我会做同样的事情，但环境要糟糕得多。不确定我是否会很有成效，或者取得什么成就。”</li><li> “我可能会去申请、提高技能、和朋友一起工作。总的来说，我的工作量会少很多。”</li><li> “我将以非主导角色支持机器学习能力研究。”</li></ul><p>共有 17 名学者填写了一项可选调查，要求他们将反事实暑假的价值与他们从 MATS 中获得的价值进行比较。九人表示，如果没有 MATS，他们的时间会“不太有用”，八人表示，他们的时间会“不太有用”。</p><h2>培训阶段（6月5日-6月30日）</h2><p>共有69名学者进入培训阶段。在指定助教的四场会议上，学者们完成了人工智能安全基础知识<a href="https://aisafetyfundamentals.com/alignment-201-curriculum"><u>对齐 201 课程</u></a>。这些讨论组使学者们对参与同行学者的研究、访问演讲者的演讲以及人工智能安全生态系统中不同组织的工作有了必要的广泛熟悉。然而，大约25%的学者没有参加任何一个讨论组，只有大约15%的学者参加了所有四个讨论组的会议。这可能是因为许多导师在其学科领域分配了自己的培训课程（例如阅读清单），并且一些导师明确告诉学者不要优先考虑对齐 201。</p><p>部分导师提前选择在训练阶段结束后进行一轮额外筛选，因此只有60名学者继续进入研究阶段。 <span class="footnote-reference" role="doc-noteref" id="fnrefvp0h93gzvk"><sup><a href="#fnvp0h93gzvk">[2]</a></sup></span></p><h2>研究阶段（7月10日 - 9月1日）</h2><p>在研究阶段，学者们在导师的指导下开展人工智能安全研究。大多数学者在加利福尼亚州伯克利毗邻<a href="https://www.constellation.org/"><u>Constellation 的</u></a>办公室里亲自工作，这使得 Constellation 以外的导师和研讨会演讲者可以轻松过境。</p><h3>指导风格</h3><p>导师们采用不同的方法来设定研究方向和指导项目。根据一项学者调查，大约 1/4 的学者对其研究方向拥有“完全的创造性控制”，大约 1/4 从列表中挑选或被分配一个项目，剩下的 1/2 介于两者之间。</p><p>在参与项目底层实施细节方面，指导风格也有所不同。根据对学者的调查，导师大致呈双峰分布，大约一半的学者表示，他们的导师只讨论研究项目的高层细节，另一半学者表示，他们的导师更多地参与低层细节。研究层面的实施细节。 </p><figure class="image image_resized" style="width:70.91%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/kxcbn1d3qvmmfikg9eoz"></figure><p>我们还注意到导师的双峰分布基于每周与学者交流的时间（但是，这两个指标与导师无关）。 </p><figure class="image image_resized" style="width:70.67%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/bw5qganpngq7hc8t1o9r"></figure><p>一些来自不同流派的学者在项目上进行了合作。有时，学者们会转而与更适合他们兴趣和需求的导师一起工作。</p><h3>学者支持</h3><p>我们的学者支持团队由五位研究/生产力教练组成，他们在研究策略、职业规划、人际沟通和研究技能提升方面提供帮助（参见上面的<a href="https://docs.google.com/document/d/1vgqW_1FIKP4prZXQXa2UIteI7-zUL4klspJjdE2tWCw/edit#heading=h.d8f3mdy3o2th"><u>计划要素</u></a>）。</p><ul><li>共有 49 名学者在研究阶段预订了学者支持会议，其中 35 名学者多次使用学者支持。</li><li>在整个项目期间，至少与学者支持会面一次的学者平均花费 3.4 小时与学者支持会面。</li><li>学者们总共花费了 160 个小时参加了 197 场学者支持会议。</li><li>十位学者占所有学者支持时间的一半。 </li></ul><figure class="image image_resized" style="width:69.75%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/uxllwospe38xmermwkib"></figure><p>使用学者支持的 49 名学者中有 28 名提供了书面反馈。这些学者报告发现以下内容特别有用：</p><ul><li>职业规划和建议（28%）；</li><li>任务优先级（25%）；</li><li>一般问题解决（14%）；</li><li>被追究责任（10%）；</li><li>拖延症建模工具（10%）；</li><li> <a href="https://www.lesswrong.com/posts/kvLPC5YWgSujcHSkY/how-to-play-a-support-role-in-research-conversations"><u>橡皮鸭</u></a>(7%)；</li><li>克服拖延症（7%）</li><li>提高与导师和同事的沟通技巧（7%）；</li><li>有用的提问（7%）。</li></ul><h3>研究里程碑</h3><p>研究阶段进行到一半时，每位学者都需要提交一份学者研究计划（SRP）。在他们的 SRP 中，学者们被要求概述人工智能<a href="https://www.lesswrong.com/tag/threat-models"><u>威胁模型</u></a>或推动他们研究的<a href="https://arxiv.org/abs/2206.05862"><u>风险因素</u></a>、解决该威胁模型<a href="https://en.wikipedia.org/wiki/Theory_of_change"><u>的变革理论</u></a>，以及制定该变革理论的项目的<a href="https://en.wikipedia.org/wiki/SMART_criteria">SMART</a>计划。 MATS 团队的一名成员和七名校友根据提供的 <a href="https://docs.google.com/document/d/1fQwy2btcWn3XRQkgu45kKnPPHMVQs28QHpaNtDCfXQY/edit"><u>评分标准</u></a>对 SRP 进行了评分，以帮助告知扩展阶段的接受决定（见<a href="https://docs.google.com/document/d/1vgqW_1FIKP4prZXQXa2UIteI7-zUL4klspJjdE2tWCw/edit#heading=h.lujivdy8efi4"><u>下文</u></a>）并为学者提供建设性反馈。 </p><figure class="image image_resized" style="width:44.94%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/nffyurqwksgj7wqzmtia" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/xji7hx8eh0mbe7xavnqb 150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/wtdngl6sutwq3hkfcvkj 300w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/tnljbcj1svmurah5hs8w 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/rbxhpjdkmqkzlffqocrv 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/kwytqiyv8eqgtlsc6zm4 750w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/i5zlme9xikfuwxob6vvi 900w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/dtgqcm11xql90rd8kpux 1050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/dixfaddh4cujlmwgd5a8 1200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ivomn6dzles1c1tw32wd 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/mlbmmqkurxconppsyypd 1424w"></figure><p>我们需要学者研究计划的三个主要原因：</p><ol><li>培养学者为目标导向的研究策略做出贡献的能力；</li><li>评估学者是否接受扩展阶段；</li><li>使学者更容易撰写后续资助提案。</li></ol><p>许多学者选择在资助申请中使用其 SRP 的组成部分，向<a href="https://funds.effectivealtruism.org/funds/far-future"><u>长期未来基金</u></a>(LTFF) 申请 MATS 后的资助支持。 LTFF 资助者托马斯·拉森 (Thomas Larsen) 举办了一次研讨会，在研讨会上他回答了 MATS 学者有关 LTFF <a href="https://forum.effectivealtruism.org/posts/7RrjXQhGgAJiDLWYR/what-does-a-marginal-grant-at-ltff-look-like-funding"><u>决策过程</u></a>和<a href="https://forum.effectivealtruism.org/posts/PAco5oG579k2qzrh9/ltff-and-eaif-are-unusually-funding-constrained-right-now"><u>资金限制</u></a>的问题。</p><p>研究阶段以为期一天的研讨会结束，学者们在研讨会上向同行和伯克利人工智能安全社区的成员就他们的研究项目进行了 10 分钟的演讲。</p><h3>讲习班、研讨会、社交活动</h3><p>我们举办了 23 场邀请演讲嘉宾的研讨会、九场培养学者研究能力的研讨会，以及每周的社交和社交活动。我们还每周举行闪电演讲会议，许多学者发表了非正式的、五分钟的研究报告。在我们的招聘会之前，有 12 家组织和独立研究人员参加，24 名学者填写了一份调查，了解他们最希望在活动中看到哪些组织。他们的回答提供了有抱负的人工智能安全研究人员当前职业兴趣的概况。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/rjqnxjfozzhkrqkwfcmj"></p><h3>社区健康</h3><p>大约 15% 的学者负责与社区经理的大部分会议，大约一半的学者只与社区经理会面一次。</p><p>学者们报告了社区经理如何在以下方面提供帮助：</p><ul><li>情感支持;</li><li>探望我担心的人；</li><li>讨论冲突或不舒服的互动；</li><li>讨论该计划如何对我来说更好；</li><li>医疗帮助（转诊至诊所、帮助治疗疾病/受伤）。 </li></ul><figure class="image image_resized" style="width:76.12%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/tzheowwao5qymskvp6oe"></figure><h2>延长阶段（9月18日至1月1日）</h2><p>研究阶段结束后，一些学者申请进入推广阶段。扩展阶段旨在支持学者们在导师和 MATS 在研究阶段提供的结构中获得更大的自主权来开展他们的研究项目。</p><p> MATS 执行团队主要根据导师的认可、SRP 成绩以及他们是否为自己的研究获得独立资助来接受学者进入扩展阶段。来自外部组织（通常是 LTFF 或开放慈善事业）的资金是这一过程的重要投入，因为它提供了对学者研究质量的外部评估。在 33 名申请的学者中，25 名被录取进入扩展阶段（录取率：76%）。</p><p>共有 16 名学者参加<a href="https://safeai.org.uk/"><u>伦敦安全人工智能倡议 (LISA)</u></a>为期四个月的扩展阶段，其中两名来自<a href="https://far.ai/labs/"><u>FAR 实验室</u></a>在伯克利继续学习，七名学者正在远程工作。我们还为学者提供了在布拉格<a href="https://fixedpoint.house/"><u>固定点</u></a>工作的选择。</p><p>在延期期间，我们期望学者们将他们的研究项目正式化为他们的第一份出版物，并开始规划他们未来的职业方向。为了在这方面为他们提供支持，我们继续提供日常生产力支持（例如，每日站立会议、学者支持调试、1-1 职业指导），并且我们举办了各种研讨会、讲习班和社交活动，特别是面向 LISA 办公室的学者。这一切都是为了让学者们做好准备，从 MATS 项目的支持环境中过渡出来，通过经常提醒他们进一步制定长期计划，并建立新的联系来帮助他们推进这些计划。一直以来，我们都期望学者能够得到导师的持续支持，尽管在大多数情况下频率会降低。</p><h1> 2023 年夏季 MATS 评估</h1><p>在本节中，我们概述了学者们如何评价该计划的不同要素以及我们如何评估我们的影响。</p><h2>评估计划元素</h2><h3>对齐201</h3><p>学者们报告了完成<a href="https://course.aisafetyfundamentals.com/alignment-201">Alignment 201 课程</a>的广泛价值分布。平均评分为 6.8/10，<a href="https://www.qualtrics.com/experience-management/customer/net-promoter-score/">净推荐值为</a>-18。 </p><figure class="image image_resized" style="width:71.72%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/pk5nhrqbpuxlzke1wgak"></figure><p>在书面反馈中，多位学者将课程的大部分价值归因于辅导员的经验和洞察力。进入该课程的学者们有着不同的背景和学习偏好：一位受访者表示，他们小组的对话没有他们希望的那么先进；另一位则提到希望学习节奏较慢的课程。一位受访者赞赏他们的辅导员建议的文章；另一位更喜欢学术论文和正式论文。一位学者提到，要努力平衡课程与导师的竞争性要求。</p><h3>总体方案</h3><p>总体而言，学者们在回答“从 1 到 10 的范围内，您向朋友或同事推荐 MATS 的可能性有多大”这一问题时，对研究阶段的评价相当高。 <span class="footnote-reference" role="doc-noteref" id="fnrefnsczgjuthnr"><sup><a href="#fnnsczgjuthnr">[3]</a></sup></span>平均回应率为 8.9/10，没有人报告低于 6/10。<a href="https://www.qualtrics.com/experience-management/customer/net-promoter-score/">净推荐</a>值为 69。 </p><figure class="image image_resized" style="width:75.19%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/zmzndsy4dlfggpjubhjv"></figure><h3>指导的价值</h3><p>总体而言，导师的评价很高，平均评分为 8.0/10，<a href="https://www.qualtrics.com/experience-management/customer/net-promoter-score/">净推荐分数</a>为 29。61% 的学者表示，MATS 的价值至少有一半来自他们的导师。 </p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/vxzr4itr8yloxu8s4uei" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/qbhl6tskvtznddj5oxrh 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ygidoqbafyk6ljbpnjpj 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/saguqu5b2ikuvuen47g0 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/rpkg2sxlbese75ik4vkm 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/uec4crmh8bbooni6llv6 1100w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ismpi1ohyakuzxa9q7ni 1320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ssk6wk9zvn7i8ohxp7jh 1540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ah1gajhkuki90spn4tey 1760w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ws62tofuflqbqasuujk6 1980w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ozzhdigdrcpqapravnc3 2176w"></figure><p>鉴于导师学者评级的负偏分布，学者评级导师对 MATS 价值的贡献如此多样化可能会令人惊讶。造成这种差异的原因是一些学者对其他价值来源给予了较高的重视；即接触该群体和更广泛的伯克利研究社区。</p><p>学者们详细阐述了导师使他们受益的方式：</p><ul><li> <strong>90%</strong> — “我认为 [MATS] 的 90% 以上的效果是通过获得 [导师] 时间并与他讨论我的研究，注意到对各种事情的轻微误解。”</li><li> <strong>70%</strong> —“[我的导师]给了我很多时间，并且很好地传授了他的很多思考研究的思维过程。他向我介绍了几个与我进行过宝贵会面的人。我想，如果我没有受到[我的导师]研究品味的引导，我可能会从事前景黯淡得多的事情。”</li><li> <strong>65%</strong> —“从高级线性代数到一般研究方向和信息危害问题，[我们的导师]对我们的研究非常出色。”</li><li> <strong>50%</strong> —“[我的导师]花了很多时间与我们讨论我们的研究，并就方向提出了很好的建议。他以各种方式为我们解除了障碍，例如获得更多模型或大量计算预算。他让我们认识了很多伟大的人，其中一些人成为了合作者。他是一位非常鼓舞人心的合作导师。”</li><li> <strong>40%</strong> —“从高级线性代数到一般研究方向和信息危害问题，[我的导师]对我们的研究非常出色。”</li><li> <strong>20%</strong> —“导师向我们（团队）介绍了一些志同道合的人，监督了这个项目（但大多数人都在倾听，没有干预），还审阅了我们的论文并组织了一次外部评审。”</li><li> <strong>10%</strong> —“提出了我不会想出的有趣的想法/反对意见。”</li></ul><p>值得注意的是，这些学者中的许多人将 MATS 的价值归因于他们的导师的比例很低，但仍然对他们的导师给予相当积极的评价。</p><p>在控制了学者对其导师的评分后，将 MATS 的更多价值归因于导师与以下因素相关：</p><ul><li>报告说，如果没有 MATS，他们整个夏天都会在联盟组织工作，这与事实相反；</li><li>在项目开始时报告出版记录是一个职业障碍，但在项目结束时却不是。</li></ul><p>这表明，与直接指导相比，那些已经与联盟领域有一定联系的学者，例如通过之前的实习或培训计划，从与伯克利社区及其同行的联系中获得的价值较小。它还表明，导师对于在整个项目中成功发表研究成果的学者来说尤其有价值。</p><p>将 MATS 的价值归因于指导较少与以下因素相关：</p><ul><li>报告发展变革理论的能力得到提高；</li><li>报告由于学者支持辅导而提高了工作效率。</li></ul><p>这表明，学者支持和其他旨在促进变革理论思维的计划要素是学者们的两个重要的非导师价值来源。</p><h3>学者支持的价值</h3><p><strong>总体评价</strong></p><p>我们询问了至少参加过一次学者支持会议的学者，“按照 1 到 10 的评分标准，您向未来的学者推荐学者支持的可能性有多大？”平均反应为 7.9/10，<a href="https://www.qualtrics.com/experience-management/customer/net-promoter-score">净推荐分数</a>为 28。 </p><figure class="image image_resized" style="width:70.28%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/rqke77gqvu1g6525jbir"></figure><p><strong>以指导支持为基准进行比较</strong></p><p>由于学者支持人员的聘用是因为他们能够以各种方式熟练地指导和支持学者，因此我们通过询问学者来检查这一点：“如果您的导师有时间的话，他们可以提供多少学者支持价值？”得到的答复是：</p><ul><li>几乎没有任何价值 - 35%</li><li>部分价值 - 50%</li><li>几乎所有价值 - 15%</li></ul><p>我们还询问了学者，如果他们提出要求，他们是否认为导师会给他们更多的支持时间； 55% 的人表示“可能不会”或“绝对不会”。这两个回应支持了我们关于学者支持价值的理论，即：</p><ul><li>在某些相关领域，专业教练可以提供比许多导师更好的支持；</li><li>导师有时间限制。</li></ul><p><strong>授予同等估值</strong></p><p>我们询问了至少参加过一次学者支持会议的学者，“假设您获得了一笔资助，而不是在 MATS 期间接受 1-1 次学者支持会议，那么您需要获得多少资金才能在资助和辅导之间保持中立？ ” <span class="footnote-reference" role="doc-noteref" id="fnrefhdw3lym1fyo"><sup><a href="#fnhdw3lym1fyo">[4]</a></sup></span>平均响应和中位数响应分别为 3705 美元和 750 美元。回复 40,000 美元的学者证实这个数字不是拼写错误，并引用了“优先顺序、项目选择、协调导航和一般人工智能景观、职业建议、困难期间的支持、针对特定会议和项目的单独定制建议”的支持。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/f4obyvjblzwcaed53gdf"></p><p><strong>获得的生产时间</strong></p><p>我们询问了至少参加过一次学者支持会议的学者，“在过去 8 周内，您估计由于您的学者支持会议，您的工作效率提高了多少个小时？”平均反应时间和中位反应时间分别为 22 小时和 8 小时。回复总数为 658 小时的生产时间。</p><h3>工作坊及研讨会</h3><p>学者们报告了参加研讨会和社交活动的价值。请注意，有些活动的受访者很少，因为我们通过可选调查收集了这些反馈。 10/10 是我们规模的一个高标准，代表着学者计划的重大更新。 </p><figure class="image image_resized" style="width:69.86%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/lfewckjuinmojngzjnli"></figure><p>学者们按照同样的 10 分制对外部演讲者事件进行评分。在 23 场研讨会中，11 场为面对面研讨会，11 场为远程研讨会，1 场为混合研讨会。现场研讨会的评分比远程研讨会高 0.9 分 (p = 0.0088)。 </p><figure class="image image_resized" style="width:70.33%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/somf49ymrg6ewflu2pgu"></figure><p>在其他条件相同的情况下，我们会选择现场研讨会而不是远程研讨会，但对这些形式的价值的分析因哪些研究人员恰好居住在湾区以及学者如何自我选择参加讲座而变得混乱。几位学者举办了自己的研讨会，即使与经验丰富的研究人员举办的研讨会相比，这些研讨会也得到了同行的好评。</p><h3>社区健康</h3><p>尽管许多学者没有使用社区健康支持，但少数学者受益匪浅。为了调查这些好处，我们向学者们询问了两个与我们评估学者支持相同的问题，以及一个关于他们的福祉的问题。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/ewbughz2oiqgsib1ixsx"></p><p>平均时数：0 小时</p><p>总时数：202小时</p><p>心理健康水平中位数提高：2%</p><p>这些图表不包括一位学者，该学者报告称，由于社区健康支持，心理健康状况提高了 1000%。学者们提供了更多细节：</p><ul><li> “它帮助我减轻了对人际关系问题的焦虑。”</li><li> “更快乐、更可持续、更专注、更少内疚。”</li><li> “在节目中，有两次我对某些事情感到有点害怕；在这两种情况下，[社区经理] 都可以讨论这个问题，非常友善和支持，并帮助我让事情变得更好。”</li><li> “一般来说，当你离开家时，以及可能在你人生中职业生涯的决定性时刻，创造一个支持性的环境对我来说非常重要。”</li></ul><p>一些学者提到，他们没有要求社区卫生支持，但他们很高兴如果他们需要的话，这个安全网已经到位：</p><ul><li> “很高兴知道如果发生什么事我可以去找人。”</li><li> “我并没有真正与社区健康部门互动，但我认为存在着我想要的反事实世界。”</li><li> “我用得不多，但很高兴它在那里。”</li><li> “我没有太多利用社区健康服务，但我很感激它的存在，以防我可能需要它。”</li></ul><h2>评估结果</h2><h3>研究里程碑</h3><p><strong>学者研究计划</strong></p><p>学者研究计划是研究阶段两个评估里程碑中的第一个。 SRP 根据<a href="https://docs.google.com/document/d/1fQwy2btcWn3XRQkgu45kKnPPHMVQs28QHpaNtDCfXQY/edit#heading=h.ozvm8udh0z0y"><u>此标准</u></a>进行分级。平均成绩为 74/100。学者们在 SRP 的威胁模型和变革理论部分往往失分最多；他们在阐述研究计划的部分表现出了更强的表现。</p><p>重要的是，一些学者忽视了SRP，因为他们不打算申请延期阶段，或者因为他们已经获得了资金，并且没有预期SRP在他们的延期阶段决定中发挥重要作用。一些导师鼓励他们的学者降低 SRP 的优先级，转而专注于他们的研究。</p><p><strong>座谈会发言</strong></p><p>研讨会演讲是研究阶段的第二个里程碑。项目在这些类别中的分布如下。请注意，并非所有学者的工作都会出席研讨会，有些项目属于多个类别。 </p><p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/snfbmj3ukwt4kbbpo8mw"></p><p>研讨会演讲得到了三个维度的同行评审：“什么”（50 分）； “为什么”（30分）；和“风格”（20 分）。完整的标题可以<a href="https://docs.google.com/document/d/1SB_vl6pGuSO7qidkZ8fIKPeH7fZIC8mvXzxicFjGyrE/edit#heading=h.ozvm8udh0z0y"><u>在这里</u></a>找到。平均成绩为86/100。</p><h3>研究能力</h3><p>使用上面解释的“深度、广度、品味”框架，我们评估了学者们在项目期间在这些维度上提高了研究技能的程度。</p><p><strong>研究能力的深度</strong></p><p>因为我们没有在项目前询问有关研究技能深度的调查问题，所以我们在项目结束时要求学者直接评价他们在所选研究方向内加强了多少技术技能。 1/10 的评分代表“与我的反事实夏天相比没有任何进步；” 10/10 的评分代表“与我的反事实夏天相比，有了显着的进步”。平均评分为 7.2/10。 </p><figure class="image image_resized" style="width:84.58%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/e9tlsh6pe4axayao52tx"></figure><p>受访者详细阐述了他们的技术技能的改进：</p><ul><li> “我从非常基本的机器学习技能发展到了合理的研究技能。”</li><li> “学习了一系列在机甲解释中找出特定事物的策略和技术。还更好地了解了要问什么问题、证明标准等。”</li><li> “更快地进行实验，识别并消除瓶颈。”</li><li> “我在 MATS 中提高了自己的技能，进行真正的研究特别有价值，因为这意味着我不必尝试猜测哪些技能对研究很重要，我只是在做研究，而技能为此需要的是我改进的那些。因此，与我的夏天相比，MATS 更有针对性，也更加激烈和激励。”</li></ul><p><strong>知识广度</strong></p><p>为了评估知识的广度，我们要求学者在研究阶段开始和结束时按照从 1 到 10 的等级对他们对主要联盟组织的研究议程的理解进行评分，其中 10/10 表示“对于任何主要联盟组织，你可以与他们的一位研究人员交谈并通过他们的智力图灵测试（即，该研究人员会认为你对他们组织的议程很熟悉）。”</p><p>我们从学者的项目后自我报告分数中减去他们的初始自我报告分数，以获得以下分布： </p><figure class="image image_resized" style="width:63.98%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/q0jzuagnkumv2gkfwvjk" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/tv0aa0dtjgrhuvi1pkjn 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/dneqbrids1b78uptkqvl 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/fcahnz8oznyoidnh2xza 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/t9ovxc5ym2zbmnilmtqy 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/cnu1yhkzkmkyzwvmpjbv 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/gepvvkrfeu6t5ktsb4ne 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/bzlob8pmpwqebi29cq0r 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/nw1kpf7xb5hfa78igzxl 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/f0ejttnktmsgkmf8kctn 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/z7hzcrvaa9hs1z1j1c1u 1104w"></figure><p>平均而言，学者们自我报告的对主要协调议程的理解在这 10 分制上增加了 1.75。两名受访者表示，他们的评分下降了一个百分点，这可能是由于学者的自我评估不一致（他们在研究阶段结束时回答时看不到自己之前的回答），或者是学者意识到自己之前的评分理解<a href="https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect"><u>并不像他们想象的那么全面</u></a>。</p><p><strong>研究品味</strong></p><p>我们将研究能力的“品味”维度分解为两个项目后调查问题。第一个问题是“您认为MATS在多大程度上提高了您独立迭代研究方向的能力？”，其中1/10表示没有变化，10/10表示显着提高。平均反应为 6.9/10。 </p><figure class="image image_resized" style="width:85.72%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/zmosuottj0wwyx4zk1hw"></figure><p>受访者提供了有关该主题的定性信息：</p><ul><li> “大多数情况下，我通过陈述研究假设而增强了自信心。之前，我有点认为关于论文的所有可以质疑/询问的事情都已经完成，或者被认为是无趣的——我现在更加坚信，安全研究中仍然有很多容易实现的成果。 （一个例子：更好地理解 RLHF 背后的理论）。”</li><li> “学者们花了一整天的时间互相谈论他们的研究。这增加了快速反馈循环，即“该方法会/不会成功”、“你也应该阅读此内容”、“这似乎影响低/高”。研究迭代有了很大的改进，可能提高了 3 倍。”</li><li> “更擅长红队，对我自己的模型和假设持怀疑态度，并找到最有效的方法来反驳它们。”</li></ul><p>第二个问题涉及研究品味，“在 MATS 期间，您在多大程度上提高了为您的研究开发变革理论的能力？”，其中 1/10 代表没有变化，10/10 代表拥有一个更加成熟的模型。平均反应为 5.9/10。 </p><figure class="image image_resized" style="width:70.31%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/pwzqwmjvjfoiwujhrab5"></figure><p>学者们阐述了他们对变革理论的经历：</p><ul><li> “我认为 MATS 对我帮助很大，因为它让我对人工智能中的事物如何发展有了更详细的模型，实现了我以前没有考虑过的考虑因素，当我的模型不够细化时更能够意识到，并且知道更多相关的信息事实和细节。”</li><li> “更加批判性地思考我正在做的事情是否能解决任何问题。”</li><li> “我想我之前已经思考过这个问题很多次了，但 MATS 给了我更多练习的机会，我认为我在评估议程方面变得更加现实（而不是以前可能会立即考虑过于宏大的议程）。”</li></ul><p><strong>导师对研究的认可</strong></p><p>在一项调查中，我们询问导师，“考虑到上述情况，您对这位学者继续研究的支持程度如何？”平均反应为 8.1/10，<a href="https://www.qualtrics.com/experience-management/customer/net-promoter-score">净推荐值为</a>38。 </p><figure class="image image_resized" style="width:71.98%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/nv7uav2tugiepfadwa5w" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/bhtp4q6evtp64v69ezfw 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/mjrvh0mqy9bzm17omgq3 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/qseuhcznhvn5jytff23q 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/scl7dyejhqxplisao3pz 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/sk1fg1scis2soxrczgec 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/kqokwwglgjguqo9sfjv3 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/bclz9iouqcam2xad5iuv 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/x4wsc7umnhrl3qzhsxha 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ybqutxsl8szprbkiyvu8 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/df39xsgzxqhbeii2pkth 1104w"></figure><ul><li>当被问及“该学者的技术能力与其所选研究方向相关的程度如何？”导师对学者的平均评分为 7.0/10，其中：<ul><li></li></ul></li></ul><p>重要的是，导师之间对学者研究的判断并不一致，因为每个导师都有自己的标准和优先事项，而且并非每个导师都对调查做出回应。</p><h3>联网</h3><p>我们衡量了社交机会对专业联系和潜在合作者变化的影响。 <span class="footnote-reference" role="doc-noteref" id="fnrefjruz5097w9c"><sup><a href="#fnjruz5097w9c">[5]</a></sup></span>在研究阶段的开始和结束时，学者们报告了“您可以放心向联盟社区寻求专业建议或支持的专业人士数量”。 <span class="footnote-reference" role="doc-noteref" id="fnrefdkoclj9ogu"><sup><a href="#fndkoclj9ogu">[6]</a></sup></span>我们利用这些响应的差异来获得以下分布： </p><figure class="image image_resized" style="width:70.77%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/p3rhtrgiig877me0teby" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/jvt6z2atg5x4d1w10a6t 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/vjjrob3qevytwv5qrwdr 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/gpvwhnanohnkhfm0zaka 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/inntopihux9frbyr2mm5 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/m3dmwgdoimq0rpuvsl5e 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/fnwrag0tjycqnopopdee 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/hp1g32lqy4ltjwveyqmb 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/bd16bew0mefjxuxo3neq 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/bvdymeo731yywe6xkjs2 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/lzqruihgrtictf9kyx4w 1104w"></figure><p>反应的中位数差异为+4.5。两次回答意味着他们可以联系的专业人员数量发生 -10 变化的受访者首先回答“30”，然后回答“20”，因此我们预计该数字是校准方差的结果。</p><p>我们就潜在合作者提出了一个类似的问题：“您认为可以联系多少人来合作开展人工智能对齐研究项目？” <span class="footnote-reference" role="doc-noteref" id="fnrefxyz9685l7yk"><sup><a href="#fnxyz9685l7yk">[7]</a></sup></span>我们采用响应差异来获得以下分布： </p><figure class="image image_resized" style="width:70.87%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/exudn8ryswlsknsbhtfa" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ggftocn43oc0bodhg703 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/ub6icmfo938obrxiqibw 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/pffsav2v8sxwv3vkqo6n 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/tvtemcsucpu9wvdxochq 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/myz8y8k7ylyveywhnwt9 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/eluzxy19g6mlicounccf 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/lfhhyaa704f1n9bil4hc 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/vjtcx8ubwprrz6n5772m 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/z1mxlrqoytalsmhf3a2r 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/mlr8c5j89bqq1f4sojmv 1104w"></figure><p>反应的平均差异为+6.0。一些学者报告的下降很可能是由于人们的判断中存在一些日常差异，因为学者们无法获得他们之前的回答。</p><h3>职业障碍</h3><p>在研究阶段的开始和结束时，我们向学者询问“[他们]与成功的人工智能对齐研究生涯之间的障碍”。当比较研究阶段开始和结束时的反应时，我们发现对于大多数可能的障碍，很少有学者将其报告为问题。出版记录和软件工程经验是例外：更多的学者表示在项目结束时面临这些障碍比开始时要多。这些结果可能反映出学者们了解了他们以前低估的障碍，随着学者们克服了早期的障碍，新的障碍变得更加突出，或者学者们转向具有不同障碍的职业道路。在研究阶段结束时，发表记录是学者与成功的职业生涯之间的主要障碍。 </p><figure class="image image_resized" style="width:87.06%"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/CY5fpned6Exq2ea98/wfmfyp6jpau8tiihxsue"></figure><p>我们还特别询问了学者在项目开始和结束时撰写资助提案的信心。 70%的学者表示对在项目开始时撰写资助提案感到不自信或非常不自信，但80%的学者表示对在项目结束时撰写资助提案感到有信心或非常有信心。</p><h2>未来计划的教训和变化</h2><p>虽然我们尚未最终确定或实施我们计划为下一批学生做出的一些改变，但以下是我们从 2023 年夏季计划中学到的主要经验教训。</p><h3> 1.申请阶段更好的过滤</h3><p>我们预计，一些处于研究阶段的学者不太可能在其职业生涯中进行具有足够影响力的一致性研究，以保证指导他们的成本，并且我们认为我们可以在申请阶段获得足够的信息来识别这些学者。这表明 MATS 在初始应用或后续评估检查点中还有更严格过滤的空间。人才分布上尾部的更高分辨率将使我们能够选择更有前途的申请人，或者至少减少没有前途的申请人，从而使一些导师能够更加关注他们的每位学者。</p><p>对于某些流来说，更好的过滤器的组成部分之一是增加对软件工程技能的筛选。对于导师自己来说，这可能是一个成本高昂的评估过程，因此对于 2023-24 年冬季计划，我们与 SWE 评估组织签约，以筛选实证 ML 研究流的申请人。</p><p>对于 2023-24 年冬季项目，我们还决定在我们网站上的导师描述中添加“个人适合”部分，以便更好地向申请人传达不同的导师风格。由于有些导师比其他导师更不干涉，我们希望申请人更有可能从他们个人不适合的类别中自我选择。</p><h3> 2.提供更多的技术支持</h3><p>学术支持团队没有明确涵盖且仅有时由导师提供的一种帮助形式是技术支持，包括调试代码、教授<a href="https://neelnanda-io.github.io/TransformerLens/"><u>TransformerLens</u></a>库等新工具以及回答技术 ML 问题。在未来的队列中，我们可能会为受到技术问题困扰的学者提供办公时间或类似的服务。一种可能性是改善我们的基础设施，以便学者们互相帮助解决技术问题。</p><h3> 3. 更积极主动地支持指导之外的专业发展</h3><p>学者支持目前帮助学者解决各种瓶颈，包括生产力、优先级、研究方向、沟通、心理健康等方面的挑战。虽然这对许多学者来说很有价值，但它更强烈地针对可以在短期内解决的瓶颈。每周约 1 小时的辅导，并且有一些技能改进（例如，练习阅读研究论文或提高编程能力）需要投入更多的时间。</p><p>在未来的队列中，我们可能会探索辅导结构或同行问责结构，鼓励学者将更多时间花在对象级研究之外的专业发展上。这可能看起来像论文阅读小组、更定期和高度承诺的研讨会，以及关于变革理论、研究工作流程等主题的联合会议。</p><h3> 4. 为导师提供研究管理帮助</h3><p>除了进一步支持专业发展外，学者支持还计划帮助大多数导师管理 2023-24 年冬季学生的学者研究。我们（学者支持团队）发现，学者支持和导师之间严格的保密政策似乎留下了太多的价值，因为：</p><ol><li>导师将受益于有关学者身份的共享信息；</li><li>学者支持团队对导师目标的理解将使学者受益，特别是当导师的研究方向在整个项目中发生变化时。</li></ol><p>在向导师提供研究管理帮助时，学者支持将在理解研究障碍、项目方向和学者研究的其他趋势方面发挥更直接的作用，并在获得学者同意的情况下向导师总结这些信息。</p><h3> 5. 减少研讨会的数量</h3><p>我们认为 23 场研讨会太多了；我们为学者提供的广度与我们观察到的低平均出席率不相称。在冬季，我们将安排 12 至 16 场研讨会，每周有机会进行较短的闪电演讲。我们还将鼓励更多的学者举办研讨会（以长篇演讲的形式，而不是局限于闪电演讲的形式），因为学者举办的研讨会在夏季获得了很高的评价。</p><h3> 6. 加强项目期间与学者的交流</h3><p>部分由于研讨会、讲习班和社交活动的数量，我们认为我们公告的信噪比可能过高。至少有一次，相当一部分学者并不知道最后期限即将到来。将来，我们将更清晰地区分最重要的公告并更快地发布这些公告。</p><h3> 7. 开发更强大的内部系统</h3><p>随着 MATS 团队的规模扩大，我们正在改进多个内部系统。其中包括我们用于影响评估的数据收集渠道、我们的项目管理系统以及通过更大的专业发展对团队成员进行投资。</p><h3> 8. 提前加载社交活动</h3><p>一些学者报告说，这群人的社交需求没有得到满足。在冬季，我们打算提前举办社交活动，以促进项目早期的联系，并在办公室附近举办更多活动，以期减少学者们在项目后期发起聚会所需的激活能量。 </p><p></p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/owezlxy9huaz3nvisvys" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/p9rtesbpiumqavifgdnn 410w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/kavq5cmkcfjmpghagunp 820w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/kqpc1u8dnlojpfdyfbgs 1230w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/wfbd4e4d8oejex0bi49n 1640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/pkcsb8dtbrazxsxsgjyr 2050w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/yesebeflxhns0q6jgkeg 2460w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/chgrj99i2hvbrs8k2kqf 2870w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/xjfi4f2aeaifnab08rak 3280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/sng3yqsh8yhmicbyik0q 3690w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/zwf68YaySvXhWYCdh/eazdnqncdnjlf15hjhsq 4034w"></figure><p></p><h1>致谢</h1><p>该报告由<a href="https://www.matsprogram.org/"><u>机器学习调整和理论学者计划</u></a>制作。 Rocket Drew 和 Juan Gil 是本报告的主要贡献者，Ryan Kidd 在 Christian Smith 的支持下确定、管理和编辑了该项目，Laura Vaughan 和 McKenna Fitzgerald 为学者支持报告部分的数据收集和分析做出了贡献。还要感谢 Carson Jones、Henry Sleight 和 Ozzie Gooen 对该项目的贡献。</p><p>要了解有关 MATS 的更多信息，请访问我们的<a href="http://matsprogram.org/"><u>网站</u></a>。我们目前正在<a href="https://manifund.org/projects/mats-funding">接受 2023-24 冬季计划及以后的捐款</a>！ </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fn2niy7evweco"> <span class="footnote-back-link"><sup><strong><a href="#fnref2niy7evweco">^</a></strong></sup></span><div class="footnote-content"><p>一些导师在其申请中包含的选择问题示例：</p><p> - 花 2-4 小时使用语言模型开发问答对数据集，RLHF 训练的模型可能会给出友好但不正确的答案。然后记录自己 2-4 小时的时间，评估数据集上的模型并绘制缩放定律。如果您的数据集显示反向缩放，则可获得奖励积分。</p><p> - 我希望你花大约 10 个小时（为了公平起见，最多 20 小时）尝试在机械可解释性的一个开放性小问题上取得研究进展，并向我展示你所取得的进展。请注意，我并不期望您能够解决问题，拥有机械插补的背景，获得令人印象深刻的结果，或者真正感觉到您知道自己在做什么。</p><p> - “贝叶斯期望效用最大化”是普遍强大智能的“真名”吗？为什么/为什么不呢？</p></div></li><li class="footnote-item" role="doc-endnote" id="fnvp0h93gzvk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefvp0h93gzvk">^</a></strong></sup></span><div class="footnote-content"><p>没有进步的学员集中在两名导师身上，他们在培训阶段之前向学员告知他们进入研究阶段的前景。这些导师决策的主要决定因素是学者在培训阶段结束时的研究冲刺中的表现。这些流派的学员知道自己的胜算后，选择了参加，部分原因是与导师一起工作的一个月保证期的价值很高。 2022-23 年冬季学员 Jay Bailey 证明，</p><p> “Neel [Nanda] 的机械可解释性培训过程对我来说是一个很好的方式来测试我在该领域的适应性并与许多聪明的人合作。尼尔的直播要求很高，他希望这是一个并不适合所有人的环境，但他很清楚这并不可耻。虽然我最终没有被选中参加面对面阶段，但经历这个过程帮助我了解了我是否想长期追求机械解释性，并围绕如何最好地为未来的一致性做出贡献制定了计划。 ”</p></div></li><li class="footnote-item" role="doc-endnote" id="fnnsczgjuthnr"> <span class="footnote-back-link"><sup><strong><a href="#fnrefnsczgjuthnr">^</a></strong></sup></span><div class="footnote-content"><p>这个问题通常用于计算“<a href="https://en.wikipedia.org/wiki/Net_promoter_score"><u>净推荐值</u></a>”（NPS），这是许多行业的标准。根据我们的受访者的反馈，MATS 的 NPS 为 +69。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnhdw3lym1fyo"> <span class="footnote-back-link"><sup><strong><a href="#fnrefhdw3lym1fyo">^</a></strong></sup></span><div class="footnote-content"><p>本调查问题和以下问题来自 Lynette Bye <a href="https://forum.effectivealtruism.org/posts/xvax8hpF29Ky5kPJw/effective-altruism-coaching-2020-annual-review"><u>2020 年对其教练影响力的回顾</u></a>。</p></div></li><li class="footnote-item" role="doc-endnote" id="fnjruz5097w9c"> <span class="footnote-back-link"><sup><strong><a href="#fnrefjruz5097w9c">^</a></strong></sup></span><div class="footnote-content"><p>以下直方图排除了一位从 0 增加到 999 名可用专业人士和潜在合作者的学者，解释说：“一开始我基本上觉得我可以给任何人发消息/打电话，现在我觉得我可以给任何人发消息/打电话字面上地。”</p></div></li><li class="footnote-item" role="doc-endnote" id="fndkoclj9ogu"> <span class="footnote-back-link"><sup><strong><a href="#fnrefdkoclj9ogu">^</a></strong></sup></span><div class="footnote-content"><p>该问题详细阐述了：“如果您想要更具体的范围：您认为可以联系多少位专业人士以获得 30 分钟的职业建议？影响这一点的因素包括您认识哪些专业人士以及您是否有足够的联系来让他们为您提供帮助。粗略估计一下就可以了，而且这个问题不仅仅是关于你在MATS中遇到的人！”</p></div></li><li class="footnote-item" role="doc-endnote" id="fnxyz9685l7yk"> <span class="footnote-back-link"><sup><strong><a href="#fnrefxyz9685l7yk">^</a></strong></sup></span><div class="footnote-content"><p>该问题详细阐述为：“想象一下，您在感兴趣的联盟领域内有一些研究项目想法。您认识的人中有多少人可能是合作者？粗略估计一下就可以了，而且这个问题不仅仅是关于你在MATS中遇到的人！”</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/zwf68YaySvXhWYCdh/mats-summer-2023-postmortem-1#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/zwf68YaySvXhWYCdh/mats-summer-2023-postmortem-1<guid ispermalink="false"> zwf68YaySvXhWYCdh</guid><dc:creator><![CDATA[Rocket]]></dc:creator><pubDate> Fri, 01 Dec 2023 23:29:47 GMT</pubDate> </item><item><title><![CDATA[Complex systems research as a field (and its relevance to AI Alignment)]]></title><description><![CDATA[Published on December 1, 2023 10:10 PM GMT<br/><br/><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 00:43:15 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 00:43:15 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>我有一个很重要的认识：复杂系统类型的思维通常是一个陷阱。我已经就此进行了几次对话，但仍然感到有点困惑，在这里更好地记录我和你的想法似乎很好。</p><p>从较高的层面来看，当我思考复杂的系统问题时，特别是在人工智能对齐的背景下，我会想到以下一些想法：</p><ul><li>有几次，我花了很多时间试图理解一些复杂系统的人们试图说什么，结果却认为他们并没有真正说什么。我想我是通过与一群圣达菲的东西和西蒙·德迪奥的作品接触而得到这种感觉的（就像<a href="http://www.mdpi.com/1999-5903/8/2/14">这篇论文</a>和<a href="https://arxiv.org/abs/2006.02359">这篇论文</a>）</li><li>我的关于群体如何取得智力进步的模型的一部分是，核心要素之一是拥有共同的语言和方法，允许“集体对话”之类的东西逐步向前迈进。比如，你有一个解决经验问题的实验和统计分析的概念，或者你有一个解决逻辑不确定性问题的证明概念，从某种意义上说，许多跨学科工作的前提是缺乏共同的方法论和语言。</li><li>虽然我最近对此感到更加困惑，但我仍然对<a href="https://en.wikipedia.org/wiki/G_factor_(psychometrics)">g 或正流形</a>之类的东西有相当强的先验，其中，有一些方法论基础对于人们相互交谈很重要，但大多数差异人们对解决问题做出贡献的能力取决于他们的聪明程度、能力和知识，而专业知识通常被高估（例如，研究人员在两个领域获得诺贝尔奖的情况并不罕见）。很多跨学科的工作（不一定是复杂的系统工作，但我觉得我在 PIBBS 背后看到了一些生成器）感觉它比我更重视知识多样性。 </li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 00:53:26 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 00:53:26 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>好吧，从一个高层次的观点开始：我绝对不愿意死在“复杂系统研究”作为一个科学领域的山上。我同意这个标签下发生了很多糟糕或有点空洞的工作。 （我认为您链接的第一篇 DeDeo 论文就是一个很好的例子：感觉主要是拥有一些很酷的方法并将其应用于一些随机现象，而没有真正令人兴奋的更大愿景来理解更深入的事物，等等。）</p><p>也就是说，有很多事情可以被描述为适合复杂系统标签，我对此感到积极，让我们尝试举几个例子：</p><ul><li>我确实认为，与你的第二点相反，复杂系统研究（至少是更好的例子）有很多/足够的共享方法论，可以从你描述的相同的认知错误纠正机制中受益。从历史上看，它确实源于物理学、网络科学、动力系统等。发生的主要举措是说，而不是根据它所研究的自然现象或领域（例如生物学、化学、经济学）来索引领域的边界，而是将其索引到一组查询方法上，前提是您可以在不同类型的系统/域中有效地应用这些方法，并获得对跨系统管理这些现象的基本原理的宝贵理解（例如，塑造生物有机体的缩放法则）以及城市的发展等）</li><li>我认为（通常）复杂系统的角度更能解释环境与主体的相互作用。朴素还原论有一种失败模式，它首先修复环境，以便能够磨练哪些系统内部差异产生了哪些现象差异，然后得出结论，所有驱动现象的因素都是系统内部的，而忘记了这一点他们之前所做的是人为地修复环境，以降低手头问题的复杂性。修复复杂交互方程的一部分通常很好而且实际上很有用，但你不应该忘记这就是你一路上所做的。同样，复杂系统镜头往往更擅长关注跨抽象层次的交互，以及这些交互中出现的动态，这对于理解自然现象似乎也很有价值。 </li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 00:52:03 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 00:52:03 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><blockquote><p>相反，将其索引到一组调查方法上，前提是您可以在不同类型的系统/域中有效地应用这些方法，并获得对跨系统管理这些现象的基本原理的宝贵理解（例如，将生物有机体塑造为尺度法则）以及城市的发展等）</p></blockquote><p>好吧，我真的很喜欢这一举措，并且通常认为各个领域围绕方法论比围绕主题更加统一。所以也许我只是缺乏对复杂系统人员的方法论的连贯指导。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 00:57:56 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 00:57:56 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>嗯，我想我对复杂系统的想法可以分为两个方向：</p><p><strong>胜利在哪里？</strong>这种方法有什么成功的案例吗？我曾经是网络科学的粉丝，但后来就不再喜欢它了。我喜欢物理学，尽管物理学本身很大，而且有很多功能障碍，所以导入物理学方法论的哪一部分确实很重要。</p><p><strong>好吧，那么基础是什么？</strong>看起来我确实对这个领域的方法论没有很好的内部了解。也许我应该去维基百科上阅读那里的方法摘要。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:00:13 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:00:13 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><blockquote><p>很多跨学科的工作（不一定是复杂的系统工作，但我觉得我在 PIBBS 背后看到了一些生成器）感觉它比我更重视知识多样性。</p></blockquote><p>热衷于谈论我关心的认知多元化类型（以及 PIBBSS 背景下的其他类型）。</p><p> （一般来说，我认为“一般智慧”的担忧与我对认知多元主义的思考方式非常正交，至少我觉得我不必被迫在两者之间进行权衡。我们可以分别双击如果你愿意的<i>话</i>，但让我首先尝试论证为什么我认为它们是正交的。）</p><p>我认为 PIBBSS 风格工作的一个相关前提（至少正如我上面所描述的那样，它与复杂系统镜头共享）是一些假设，即存在一些基本原则来管理跨不同系统、基质和规模的智能行为。如果是这样的话，这就是解决我们无法直接访问我们最担心的人工智能系统的问题的一种方法。但是，如果我们认为它们与实现智能行为的其他类型的系统共享<i>一些</i>功能/原则，重要的是我们确实有更好的认知访问程度的系统，那么我们现在可以开始在我们对这些不同系统的理解之间进行三角测量。通过这种三角测量，您可以对与基底/规模/系统无关的那些原理获得更深入的见解。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:02:49 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:02:49 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>总的来说，我对研究我们现有系统中的智能行为非常同情和感兴趣。然而，我确实注意到，不知怎的，我想不出这个领域的任何工作对我来说非常有用，至少在最近几年是这样。我真的很喜欢埃利以泽对进化的分析，将其作为人工智能对齐的类比，它对我产生了很大的影响。我喜欢 Steve Byrnes 的研究神经科学的工作，以深入了解人工智能对齐问题，尽管他们在某种程度上感觉是分开的（但这可能真的只是我的不公正划分），并且目标是制作更多像原始作品一样的作品进化的LW序列分析和AI比对，我会感到非常兴奋。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:04:43 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:04:43 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>粗略地说，我的感觉是，可以从不同的角度来解决这个问题。一般来说，我对“让我了解复杂系统科学”的框架感到有点犹豫——就像我认为这个概念并不是真正雕刻世界的最有用的方式（例如，我认为阅读维基百科页面上的这个内容不会那个令人兴奋）。我确实认为，如果您正在寻找一些关于如何对不同类型的系统进行建模的想法，以及所需的数学知识，那么有些复杂系统教科书是相当简洁的。但除此之外，至少根据我的口味，我会说考虑一下您有兴趣理解哪些自然现象，然后尝试找到谁在该现象上做有趣的工作，或者（数学上）建模它的方法是什么富有成效。我想我的经验更接近于a）对理解某些现象感兴趣，b）在那里找到一些我发现进行富有成效的工作，c）注意到其中一堆可以被标记为复杂系统的东西。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:04:34 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:04:34 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>好吧，在这种情况下，我问的具体问题是“这里有一个领域，它的方法论是什么？”。我对自然现象进行了大量研究，并且一般都在寻找好的数学模型，但我很少最终找到被标记为“复杂系统”的东西。我通常喜欢最终学习生物学、物理学、人工智能或数学。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:07:00 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:07:00 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>以下是我正在考虑的您的具体引述：</p><blockquote><p>我确实认为，与你的第二点相反，复杂系统研究（至少是更好的例子）有很多/足够的共享方法论，可以从你所描述的相同的认知错误纠正机制中受益。从历史上看，它确实源于物理学、网络科学、动力系统等。</p></blockquote><p>在我看来，你似乎在暗示这里有一个领域，它有一个认知棘轮，可以随着时间的推移向前推进并取得连贯的进展。但我目前觉得我对棘轮的机制还没有很好的了解。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:19:47 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:19:47 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>你知道<a href="https://www.amazon.com/Introduction-Theory-Complex-Systems-Thurner/dp/019882193X/ref=asc_df_019882193X/?tag=hyprod-20&amp;linkCode=df0&amp;hvadid=312152840806&amp;hvpos=&amp;hvnetw=g&amp;hvrand=15805346042964868981&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=1013585&amp;hvtargid=pla-561851596697&amp;psc=1&amp;mcid=ee4d371124353a0da64f86a8b0a83255&amp;tag=&amp;ref=&amp;adgrpid=61316181319&amp;hvpone=&amp;hvptwo=&amp;hvadid=312152840806&amp;hvpos=&amp;hvnetw=g&amp;hvrand=15805346042964868981&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=1013585&amp;hvtargid=pla-561851596697&amp;gclid=CjwKCAiAvJarBhA1EiwAGgZl0KNSZABSw9gcydbqlEvAAQLD7v1vS3dmVIlO5eron7VdFsnTYkH9_BoCwVsQAvD_BwE">这本教科书</a>吗？我想说这是对“复杂系统建模工具箱”的一个很好的概述。</p><p>如果你想对复杂系统有一个更尖锐、或者更雄心勃勃的愿景，你可以听听<a href="https://www.preposterousuniverse.com/podcast/2023/07/10/242-david-krakauer-on-complexity-agency-and-information/">David Krakauer 的采访</a>。我的猜测是，你会在很大程度上摆脱它，尽管我确实认为这非常令人兴奋（尽管采访比乍一看更密集）。他谈到了理解“telic”现象（或一些类似的术语），他将其理解为（我的粗略解释）是从进化和元进化等适应性系统中获得的特定约束中产生的。在我看来，这很有趣“理解代理/智能行为的基础”角度，例如，您最终试图用自然主义术语解释诸如代理/规划的“向后因果关系”特征之类的事物如何从简单的动态中产生。</p><p>就系统进步而言，一方面，我认为进步也与其他科学领域相结合——就像复杂系统一样，作为一个领域，跨越了更传统的科学领域划分方式，所以我认为没有一种先验的方法可以将进步准确地归因于其中任何一个。但我认为进步的机制来自于[数学模型工具箱（例如网络科学、动力系统、控制理论等）]以及更抽象和更具体/经验之间的相互作用。</p><p>也许我今天太混淆了，但我认为这与所有其他科学领域都是一样的，主要区别在于一些基本前提。也许最简单的例子就是从古典经济理论到复杂性经济学的转变。在前者中，您从一组假设开始，例如：理性行为者，所有代理都是相同的，市场是均衡系统。然后复杂性经济学出现并说：嘿伙计们，好消息，我们现在拥有比算术更好的数学工具，因此我们现在能够放松一些经典假设，并且可以使用以下前提对经济系统进行建模：有界理性代理（具有学习和记忆动力学等）、异质代理（例如不同的学习策略）、市场作为均衡系统之外的。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:24:22 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:24:22 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><blockquote><p>你知道<a href="https://www.amazon.com/Introduction-Theory-Complex-Systems-Thurner/dp/019882193X/ref=asc_df_019882193X/?tag=hyprod-20&amp;linkCode=df0&amp;hvadid=312152840806&amp;hvpos=&amp;hvnetw=g&amp;hvrand=15805346042964868981&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=1013585&amp;hvtargid=pla-561851596697&amp;psc=1&amp;mcid=ee4d371124353a0da64f86a8b0a83255&amp;tag=&amp;ref=&amp;adgrpid=61316181319&amp;hvpone=&amp;hvptwo=&amp;hvadid=312152840806&amp;hvpos=&amp;hvnetw=g&amp;hvrand=15805346042964868981&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=1013585&amp;hvtargid=pla-561851596697&amp;gclid=CjwKCAiAvJarBhA1EiwAGgZl0KNSZABSw9gcydbqlEvAAQLD7v1vS3dmVIlO5eron7VdFsnTYkH9_BoCwVsQAvD_BwE">这本教科书</a>吗？我想说这是对“复杂系统建模工具箱”的一个很好的概述。</p></blockquote><p>我不！我可能会看一下。</p><blockquote><p>然后复杂性经济学出现并说：嘿伙计们，好消息，我们现在拥有比算术更好的数学工具，因此我们现在能够放松一些经典假设，并且可以使用以下前提对经济系统进行建模：有界理性代理（具有学习和记忆动力学等）、异构代理（例如不同的学习策略）、市场作为平衡系统之外的。</p></blockquote><p>是的，这绝对是一件听起来很酷的事情，但它真的有效吗？就像，我对经济学没有那么扎实的基础，但我确实读了很多经济学博客，并用我自己的语言思考了很多经济学问题，而且我并没有经常遇到复杂性经济学的观点，而且确实有点期望如果我要阅读一篇关于复杂性经济学的“顶级”论文，我最终会感到失望。但我也可能只是缺乏参考资料。</p><p>例如，这与气候计量学/计量经济史之类的东西形成鲜明对比，我发现它非常有价值，并且有很多关于历史如何运作的很酷的模型，但对我而言，感觉不是很复杂的科学。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:26:37 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:26:37 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><blockquote><p>然而，我确实注意到，不知怎的，我想不出这个领域的任何工作对我来说非常有用</p></blockquote><p>我部分同意你的观点，并希望我能指出更多、更容易理解的例子。 （同时，我觉得我没有太多让我觉得更广泛的特别令人兴奋的例子。）</p><p>对当前更多工作的一些不全面的指导：</p><ul><li>层级机构/协调工作，以及 ACS 讨论/开展的其他事项</li><li>开发智能现象的自然化描述（例如代理、计划、欺骗、权力寻求、中观优化），其中自然化描述旨在描述现象的潜在机制，以便您可以在它发生在（时间、空间）时识别它你还没有进化到能够识别现象的尺度——希望这可以提供更强大的方法来做到这一点，例如可解释性和评估</li><li>对交互人工智能系统有更原则性的理解，例如，一堆LLM系统在野外相互作用会产生什么样的进化/涌现动态（例如，迅速进化、具有不同能力特征的支架代理的出现等）</li><li>描述“混乱”的人工智能风险场景，例如<a href="https://www.lesswrong.com/posts/BTApNmv7s6RTGxeP4/cyborg-periods-there-will-be-multiple-ai-transitions">多重转型</a>、RAAP、多重委托、提升经济</li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:28:47 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:28:47 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>因此，维基百科关于复杂性经济学的文章说：</p><blockquote><p> Hidalgo 和 Hausmann <a href="https://en.wikipedia.org/wiki/Complexity_economics#cite_note-HidalgoHausmannPNAS-6"><sup>[6]</sup></a> <a href="https://en.wikipedia.org/wiki/Complexity_economics#cite_note-ComplexityAtlas-7"><sup>[7]</sup></a>提出的<a href="https://en.wikipedia.org/wiki/Economic_complexity_index">经济复杂性指数</a>（ECI）可以高度预测未来人均 GDP 增长。在 Hausmann、Hidalgo 等人的文章中， <a href="https://en.wikipedia.org/wiki/Complexity_economics#cite_note-ComplexityAtlas-7"><sup>[7]</sup></a>作者表明，未来 GDP 国家列表（基于 ECI）估计 ECI 预测未来人均 GDP 增长的能力比世界高 5 倍到 20 倍世行的治理衡量标准、世界经济论坛 (WEF) 的全球竞争力指数 (GCI) 以及人力资本的标准衡量标准，例如受教育年限和认知能力。 <a href="https://en.wikipedia.org/wiki/Complexity_economics#cite_note-8"><sup>[8]</sup></a> <a href="https://en.wikipedia.org/wiki/Complexity_economics#cite_note-9"><sup>[9]</sup></a></p></blockquote><p>就像，我不知道，这听起来很酷，但我诚实的最佳猜测是，这在某种程度上是假的？就像，如果我研究一下这个问题，我会发现“过去的人均GDP增长”比这个经济复杂性指数或类似的东西更好的预测指标，而他们可以声称这个结果的唯一原因是因为他们不公正地划分了经济复杂性指数。以某种方式替代。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:35:07 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:35:07 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>好吧，我用谷歌搜索了一下，我找不到任何明显的删除，揭露 ECI 明显被不公正地划分选区，而我们的数据世界（他们通常看起来很合理，而且他们以一种很酷的方式思考这个问题）有一个他们的博客上<a href="https://ourworldindata.org/how-and-why-econ-complexity">有关于它的好评文章</a>，所以我更新这里有一些更真实的东西。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:33:38 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:33:38 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>是的，我确实对明显的成功低于我的模型预测的成功感到有些困惑。</p><p>这让我对该方法的总体前景进行了一些更新，但我对模型的其他部分也有不确定性，例如我期望在什么时间尺度上取得什么成功以及“成功”会是什么样子。另外，我认为存在一些动态，例如“一旦某件事取得成功，它就会更加融入主线，从而不再被认为是（曾经）非正统的方法”。肯定会发生这样的事情。我知道他们通过放弃“市场是均衡系统”的假设，在金融危机等建模方面取得了一些成功；我记得读过一些报告（我相信是一些国际治理机构，经合组织等，但不记得细节了），其中包含有关气候变化和可持续发展的经济建议，这些建议显然是由复杂性经济学启发的，听起来相当合理，我知道稍微介绍一下 Hidalgo 的<a href="https://oec.world/en">这项工作</a>，基于相对浅显的外观，它看起来相当酷（部分原因是它使一堆非常酷的现实世界数据变得可访问）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:42:27 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:42:27 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>嗯，关于经济指数的东西：我的意思是对这一切的一个简单的看法是这样的</p><ul><li>当然，该地区真正发生的事情是极其复杂的（例如，存在历史路径依赖性，存在国民经济所嵌入的全球经济，国家的特定资源、基础设施、劳动力等。 ）</li><li>看起来基本上所有古典经济模型都大大简化了现实，并且非正统的方法正在使其中一些假设更加现实</li><li>问题是，相对于您所付出的复杂性成本，您的模型（或特定的复杂化）的复杂性在预测能力方面为您带来了多少</li><li>对于像经济学这样的领域来说，另一件<i>奇怪的</i>事情是，经济理论发生在它试图预测的系统<i>内</i>（并从而影响）。例如，当世界银行发布一些预测时，它本身会影响例如流入该国的投资、存款利息等。这使得经济学（以及其他领域）与物理学有很大不同，在物理学中，在大多数情况下，您实际上有理由忽视这一事实理论家在理论中。 </li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:49:29 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:49:29 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><blockquote><p>对于像经济学这样的领域来说，另一件<i>奇怪的</i>事情是，经济理论发生在它试图预测的系统<i>内</i>（并从而影响）。例如，当世界银行发布一些预测时，它本身会影响例如流入该国的投资、存款利息等。这使得经济学（以及其他领域）与物理学有很大不同，在物理学中，在大多数情况下，您实际上有理由忽视这一事实理论家在理论中。</p></blockquote><p>我同意这有一定的现实性，但我确实认为这是一种感觉像是被选择来感觉聪明或元的效果，但实际上并不重要？就像，我同意美联储当然会通过说出它将做什么来对经济做什么产生一些影响，但我发现自己怀疑你是否必须真正考虑到在你发布你的政策后人们将如何改变他们的行为的影响。经济理论，除了对美联储设定的目标利率进行建模之外。</p><p>就像，我并不否认这里有一些影响，但我怀疑它会很大。</p><p>这与某人进行经验观察的情况有很大不同，经验观察结果要么是人类强制政策的结果，要么因其规律性而变成了人类强制政策。例如，我发现摩尔定律的稳健性源自主要半导体制造商根据摩尔定律设定内部目标的故事，有点有前途且有趣。</p><p>但这感觉与说你需要考虑经济中认真对待你的经济理论的参与者的自我参照效应不同。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:51:38 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:51:38 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>目前我最好的猜测是，它确实很重要（尽管时间尺度比逐年预测稍大一些）。就像，我认为历史和社会系统的路径依赖（受某种形式的差异选择影响的一切事物的路径依赖）是一件大事。我对有哪些替代的功能经济逻辑非常感兴趣，并且对于考虑到物理学的现实我们可能永远无法在这个分支中探索它们这一事实感到非常悲伤。这些东西在科学上绝对难以处理，因为它涉及我们无法访问的反事实，因此很难甚至不可能校准它是否是一个大问题。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:55:12 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:55:12 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>与我对其他人直觉的猜测相比，我想这是一个很好的例子，说明我的直觉受到复杂系统镜头的影响。<br><br>我对路径依赖程度的思考方式大致如下：一个吸引力是，如果你有一些相对简单的复杂动态，初始条件的微小差异可能会传播很大，局部意外事件会让你访问路径的不同部分。可能性树，有时以很难逆转的方式。来自另一边的拉力是，如果你能指出一些主动缓冲这种路径依赖性的机制，例如某种趋于将系统保持在某个盆地内的稳态压力。这两种机制都存在——总的来说，我预计社会经济历史更多地受到前者的影响（例如，生物有机体的发育/生命周期更多地受到后者的影响）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:53:53 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:53:53 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>我的意思是，我完全可以说“初始条件很重要，有些系统很混乱，很难预测它们最终会在哪里，因为它们非常敏感”。但这与“专门分析经济理论和政策的自我参照性质值得付出复杂性的代价”不同。就像，我不认为一旦你考虑了自我参照效应，系统就会停止混乱，我也不认为系统会因为你的出版物引入的自我参照成分而变得混乱。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:57:41 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:57:41 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>是的，好吧，所以我同意你的观点，我预计技术设计的影响（以一年到十年的时间尺度）比宏观经济学更大。 （我不认为这意味着这种效应不适用于宏观经济学，而是宏观经济学生活在较慢的时间尺度上。就像，这种路径依赖的镜头适用于经济逻辑，但更多所以在几十年到几个世纪的时间尺度上。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 01:56:53 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 01:56:53 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>举个例子，我认为微观经济学的所有基础知识都没有太多的自我参照效应。他们的有效性范围以及他们的预测对于这类东西来说似乎是可靠的。无论人们是否了解供给和需求，供给都会等于需求。工资将会是粘性的，无论人们是否知道工资是粘性的（这里可能有一些影响，但我认为它很弱）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 01:58:27 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 01:58:27 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><blockquote><p>“专门分析经济理论和政策的自我参照性质是值得付出巨大代价的”。就像，我不认为一旦你考虑了自我参照效应，系统就会停止混乱，我也不认为系统会因为你的出版物引入的自我参照成分而变得混乱。</p></blockquote><p>是的，需要明确的是，我同意这一点！ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:02:23 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:02:23 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>也许附近一个有趣的例子，我们可能不同意更多的是：至少有一些历史阅读，其中“经济理性”的概念以及与博弈论领域相关的各种理性概念在二战后出现。这些思想对经济、制度和学术/知识的发展产生了重要且明显的影响。这种观点说的是：今天对我们（大多数人）来说似乎很自然的一堆想法非常强烈地取决于相当狭窄的时间段和形成这些想法的极少数头脑。与“水中的鱼”和“你永远无法真正逃脱当地的意识形态背景”的感觉有关。<br><br> [不确定是否值得进入这个兔子洞。] </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:05:44 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:05:44 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><blockquote><p>无论人们是否了解供给和需求，供给都会等于需求。</p></blockquote><p> FWIW，很大程度上同意该段落，但也许值得指出：供给等于需求有时确实<i>会</i>失败（例如金融危机）。我们可以将这些失败解释为系统中的某种“非理性”，但我发现这通常在智力上相当懒惰。认识模型的局限性以及这些局限性产生的原因似乎很重要。事实上，复杂性经济学说，他们更善于理解在金融危机等事件中真正发生的事情，我认为应该为他们赢得很多认知点（重要的警告是，我需要阅读他们到底能够展示什么）关于将市场建模为非均衡系统，因此我在提出这一论点时提出了认识上的警告） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:04:52 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:04:52 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>是的，我确实认为我不同意这一点，这确实让我对复杂性理论感到害怕。就像，也许这是一个稻草人，但科学有一个吸引力，科学的作者开始不将自己视为真相的记者，而是将自己视为某种社会组织方式的倡导者。</p><p>历史充满了这样的情况，而且其中大部分都因此成为一个严重病态的领域，因为其中很大一部分人认为自己有意试图以一种积极影响当今社会运作的方式重塑历史。</p><p>就像，我不赞成禁止任何和所有关于出版物的次要影响的讨论，以及出版物本身如何可能扭曲它所谈论的主题，但总的来说，这条路上有很多头骨，并且许多领域因此而死亡。</p><p>我不知道当你谈论研究经济理论的出版和采用中的自我指涉时，这种情况发生到什么程度，但感觉已经很接近了。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:11:06 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:11:06 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><blockquote><p>是的，我确实认为我不同意这一点，而且这确实让我感到害怕。</p></blockquote><p>是的，总体上强烈同意整个信息。我发现自己很困惑，一方面，这里有一些基本论点，我觉得这些论点非常引人注目，让我想要认真对待理论化的社会嵌入性——尤其是在人工智能对齐的背景下——而且我也很难同意头骨和滑溜溜的认知斜坡。</p><p>我确实觉得有一种方法可以让你的所有推理都充满理智，但它确实感觉像是一个棘手的平衡，根据我的经验，它感觉有点像人具有或多或少的“认知抗体”，以便能够或多或少安全地在该地形中航行。</p><p> （作为旁注：我已经就此写过/发表了一些演讲，如果您要阅读/观看它们并想让我知道它是否让您更新或多或少担心我最终会跌跌撞撞地接近头骨，我很想听听。）</p><p> （另外，我认为<a href="https://www.jstor.org/stable/3810931">这篇论文</a>对这个问题进行了有趣的哲学讨论。） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:13:28 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:13:28 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>所以，再回到顶层。我绝对同意这样的观点：“伙计，我们用各种社会、智能和经济系统构建的正式模型看起来确实不太可能在实际制造所需的相关细节和复杂程度上捕获这些模型。这里有很好的预测”。</p><p>然后我就很想知道如何做得更好。我想我目前的答案是这样的：“好吧，这不是科学的工作，科学的工作是为社会推理提供某种类型的相对狭窄的智力输入。对大型复杂系统进行聚合和预测的实际工作将是大部分发生在一群决策者大脑的系统1中，基于我们并不真正理解的归纳和演绎推理的非常复杂和混乱的混合”。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:15:51 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:15:51 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>我还有些认为，深度学习现在已经足够好了，我们只需向世界上的许多系统投入一些大型神经网络，就可以更好地理解它们。它们肯定有足够的参数，并且可以编码足够多的同时考虑因素，以产生非常复杂系统的相当好的预测模型。</p><p>通过人工学习系统来做到这一点，我们必须处理更少的递归问题，可以控制输入，并保持科学的更清晰的抽象（例如，可以通过重新运行深度学习训练来重现对复杂系统的预测） ，如果您通过向政策制定者提供信息来预测复杂系统，则无法做到这一点，而政策制定者通常不喜欢进行大型受控实验，或者被终止然后重新运行） </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:19:39 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:19:39 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>好吧，我想反驳一下你所说的“当前做得更好的答案”。首先，我认为忽视科学具有不纯粹描述性的方面是不好的。*我也同意我们<i>真的</i>不应该一路走在其他方向，让科学基本上成为政治的延伸。其次，根据具体情况，将其留给“少数决策者的 S1”似乎显然令我不满意。</p><p> *在这里值得一提的是：我们可以在某种程度上区分这对于哪些域/系统来说是正确的。西蒙·赫伯特的<i>《人工科学》</i>在这方面对我影响很大。这里的人工指的是~设计的人工制品——对于我们的背景来说很重要：技术和机构。人工领域具有这种奇怪的描述性和规定性的双重性质。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:23:57 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:23:57 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>我同意我们可以利用法学硕士来促进科学进步（这也是 Davidad 的 OAA 大型计划的一部分），尽管这并不容易，而且我们有一些重要的方法可以把它搞砸。例如，在 Davidad 的案例中（据我所知），其想法是让法学硕士编写正式模型，<i>然后由人类专家逐行检查</i>。这是法学硕士目前可以帮助增强科学建模的方式，但检查阶段对于使其有用而不是有害至关重要。</p><p>然而，我不明白人工智能系统如何本质上面临更少的递归问题，至少默认情况下是这样。事实上，我非常担心<a href="https://arxiv.org/abs/2203.17232">表演预测因素</a>。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:22:31 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:22:31 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>是的，需要明确的是，我根本不想忽视它。我的意思是，对于任何试图阐明我们对某些领域的理解的特定论文，绝大多数论文应该大多忽略这些现象，除了一些特别递归的领域。然后，作为科学家和科学机构的建设者，我们应该考虑如何建立不必持续处理这一问题的调查程序，或者至少限制相关势力的腐败。</p><p>是的，拥有一些科学知识来帮助我们做出这些权衡并不疯狂，但我觉得我希望这些论文能够直接解决相关的考虑因素，而不是让每篇论文最终都被对其自我指涉的担忧所占据。影响。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:24:44 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:24:44 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><blockquote><p>然而，我不明白人工智能系统如何本质上面临更少的递归问题，至少默认情况下是这样。事实上，我非常担心<a href="https://arxiv.org/abs/2203.17232">表演预测因素</a>。</p></blockquote><p>好吧，就人工智能系统而言，你可以研究并限制自我参照的影响。您可以使用相同的数据重新训练旧系统。你可以客观地谈谈它做出了什么预测。当人类使用他们的系统来预测复杂的系统时，每个人都有如此多的路径依赖，以至于几乎不可能控制事物。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:30:34 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:30:34 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>是啊，有趣。我同意科学论文的抽象级别（至少在绝大多数情况下）不是应该解决递归性问题的地方。这确实提出了一个（重要的）问题：应该在哪里以及如何解决这个问题。我不太确定。我想机构或整个科学界更接近正确的抽象。我还认为，这就是科学哲学可以发挥相关补充作用的地方。对于工程领域来说，情况有点不同。特别是，我肯定希望有更多关于替代人工智能范式（以及不同此类范式的安全和治理相关功能）的讨论。考虑到目前的形势，我实际上认为这是目前更有希望的干预措施之一（最近开始出现一些初步的积极迹象）。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:30:37 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:30:37 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><blockquote><p>这确实提出了一个（重要的）问题：应该在哪里以及如何准确地解决问题。我不太确定。</p></blockquote><p>嗯，从某种意义上说，这就是 LessWrong 的意义所在。 《理性的艺术》。</p><p>它被称为一门艺术，因为它实际上不是一门科学。这是一个更广泛的类别，除了涵盖科学发现真理的方式之外，还试图涵盖更多实际的事情，例如良好的认知习惯和直觉以及确保吃正确的食物等等。我也认为在这个主题上有一些古老的科学是件好事，但我发现 MIRI 在透明博弈论方面的工作比大多数试图研究递归建模效应等问题的复杂性科学更相关。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:34:00 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:34:00 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>是的，同意认知社区在这里很重要，并且寻求真理不仅仅是简单的“科学方法”。 </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:33:19 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:33:19 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>好吧，看来是时候该结束了。我很喜欢这个！ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="THnLZeup4L7R4Rqkw-Wed, 29 Nov 2023 02:34:56 GMT" user-id="THnLZeup4L7R4Rqkw" display-name="Nora_Ammann" submitted-date="Wed, 29 Nov 2023 02:34:56 GMT" user-order="1"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>诺拉·阿曼</b></section><div><p>是啊，一样！ ：） 谢谢！ </p></div></section><section class="dialogue-message ContentStyles-debateResponseBody" message-id="XtphY3uYHwruKqDyG-Wed, 29 Nov 2023 02:36:11 GMT" user-id="XtphY3uYHwruKqDyG" display-name="habryka" submitted-date="Wed, 29 Nov 2023 02:36:11 GMT" user-order="2"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>哈布里卡</b></section><div><p>总结一下我们要给我留下的东西：</p><ul><li>我仍然对了解更多关于复杂性理论的胜利非常感兴趣</li><li>我对复杂性理论的一些基本前提感到非常满意，但对“科学领域”是否是在这些前提基础上工作的正确方法感到困惑</li><li>我对那些过于关注自身存在或试图研究其自身影响的领域普遍持怀疑态度，不是因为它不真实，而是因为它真的很难并且有各种不良的认知吸引子</li></ul><p>我也可能会尝试阅读或聆听您发送的一些材料，并可能留下带有额外印象的评论。</p></div></section><div></div><br/><br/> <a href="https://www.lesswrong.com/posts/7KjRqrwjmZRoiBDtn/complex-systems-research-as-a-field-and-its-relevance-to-ai#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/7KjRqrwjmZRoiBDtn/complex-systems-research-as-a-field-and-its-relevance-to-ai<guid ispermalink="false"> 7KjRqrwjmZRoiBDtn</guid><dc:creator><![CDATA[Nora_Ammann]]></dc:creator><pubDate> Fri, 01 Dec 2023 22:10:25 GMT</pubDate> </item><item><title><![CDATA[Could there be "natural impact regularization" or "impact regularization by default"?]]></title><description><![CDATA[Published on December 1, 2023 10:01 PM GMT<br/><br/><p>具体来说，假设您使用<a href="https://www.lesswrong.com/posts/6mysMAqvo9giHC4iX/what-s-general-purpose-search-and-why-might-we-expect-to-see">通用</a>搜索过程，该过程递归地调用自身来解决子目标，以解决一些更大的目标。</p><p>如果搜索过程对子目标的解决方案“改变太多”，那么它们可能不会有用。例如，对于魔方，如果您想交换一些长方体，那么您很清楚这些交换是否会使魔方的其余部分打乱。</p><p>因此，在某种程度上，强大的能力必须依赖于某种影响正规化。</p><p>我认为自然影响正则化与工程中的“优雅”概念有关。就像如果你有一些臃肿的工具来解决问题，那么即使严格来说它不是一个问题，因为你负担得起资源，它也可能会让人感觉很丑陋，因为它太多了，并且对你其他不受约束的决策造成了轻微的限制，等等。同时，简单、最小的解决方案通常不具备这一点。</p><p>自然影响正则化并不能<i>保证</i>安全，因为它仍然允许不干扰人工智能功能的偏差，但它在某种程度上减少了我最近一直在考虑的一个危险源，即我一直认为工具性激励是寻找影响世界的强大方法，其中“权力”意味着一种不可阻挡地推动许多变革的原始力量，但真正的工具性激励往往是寻找影响世界的“精确”方法，其中一个人可以引入大量信息来实现小范围的改变。 <span class="footnote-reference" role="doc-noteref" id="fnrefcsrxgqulp65"><sup><a href="#fncsrxgqulp65">[1]</a></sup></span></p><p>也许另一个词是“自然的内在对齐”，因为从某种意义上说，关键是能力不可避免地会选择内在对齐。这里我指的是自然抽象意义上的“自然”，即各种认知算法都会倾向于的东西。 </p><ol class="footnotes" role="doc-endnotes"><li class="footnote-item" role="doc-endnote" id="fncsrxgqulp65"> <span class="footnote-back-link"><sup><strong><a href="#fnrefcsrxgqulp65">^</a></strong></sup></span><div class="footnote-content"><p>一个复杂的问题是，任何一个代理只能拥有一定的带宽，这有时会激励更生硬的控制。我一直认为带宽可能会成为代理基础的一个巨大领域，并且迄今为止尚未得到充分探索。 （也许是因为每个人都协调一致地管理带宽？😅）</p></div></li></ol><br/><br/> <a href="https://www.lesswrong.com/posts/cS7rhjuG9thmfTqdy/could-there-be-natural-impact-regularization-or-impact#comments">讨论</a>]]>;</description><link/> https://www.lesswrong.com/posts/cS7rhjuG9thmfTqdy/could-there-be-natural-impact-regularization-or-impact<guid ispermalink="false"> cS7rhjuG9thmfTqdy</guid><dc:creator><![CDATA[tailcalled]]></dc:creator><pubDate> Fri, 01 Dec 2023 22:01:48 GMT</pubDate></item></channel></rss>