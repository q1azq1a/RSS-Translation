<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>麻省理工学院斯隆管理评论</title><atom:link href="http://sloanreview.mit.edu/feed/" rel="self" type="application/rss+xml"></atom:link><link/> https://sloanreview.mit.edu<description>可持续创新</description><lastbuilddate>2023 年 9 月 5 日，星期二 15:12:30 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.2.2</generator><item><title>与人工智能和智能 KPI 进行战略协调</title><link/>https://sloanreview.mit.edu/article/strategic-alignment-with-ai-and-smart-kpis/<comments> https://sloanreview.mit.edu/article/strategic-alignment-with-ai-and-smart-kpis/#respond</comments><pubDate> Tue, 05 Sep 2023 11:00:55 +0000</pubDate> <dc:creator><![CDATA[David Kiron, Michael Schrage, François Candelon, Shervin Khodabandeh, and Michael Chu. <p class="mt20"><strong>David Kiron</strong>是<cite>《麻省理工学院斯隆管理评论》</cite>研究部编辑主任，也是其<a href="https://sloanreview.mit.edu/big-ideas/">“大创意”研究计划的</a>项目负责人。</p><p class="mt20"><strong>迈克尔·施拉格 (Michael Schrage)</strong>是麻省理工学院斯隆管理学院数字经济倡议的研究员。他的研究、写作和咨询工作重点关注数字媒体、模型和指标的行为经济学，作为管理创新机会和风险的战略资源。</p><p class="mt20"> <strong>François Candelon</strong>是波士顿咨询集团 (BCG) 的高级合伙人兼董事总经理，也是 BCG 亨德森研究所的全球总监，他的研究重点是技术对商业和社会的影响。您可以通过<a href= "mailto:candelon.francois@bcg.com">candelon.francois@bcg.com</a>联系他。</p><p class="mt20"> <strong>Shervin Khodabandeh</strong>是 BCG 的高级合伙人兼董事总经理，也是 BCG 北美人工智能业务的联席领导者。他是 BCG X 的领导者，在推动人工智能和数字化业务影响方面拥有 20 多年的经验。您可以通过<a href="mailto:shervin@bcg.com">shervin@bcg.com</a>联系他。</p><p class="mt20"> <strong>Michael Chu</strong>是 BCG 合伙人兼副总监，专注于将人工智能和机器学习应用于商业职能中的业务问题，包括优化定价、促销、销售和营销。您可以通过<a href= "mailto:chu.michael@bcg.com">chu.michael@bcg.com</a>联系他。</p> ]]>; </dc:creator><category><![CDATA[Analytics and Performance]]></category><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Metrics]]></category><category><![CDATA[Prediction Tools]]></category><category><![CDATA[Smart Technology]]></category><category><![CDATA[Analytics & Business Intelligence]]></category><category><![CDATA[Data, AI, & Machine Learning]]></category><category><![CDATA[Operations]]></category><category><![CDATA[Quality & Service]]></category><category><![CDATA[Supply Chains & Logistics]]></category><category><![CDATA[Artificial Intelligence and Business Strategy]]></category><description><![CDATA[About the Research This article series presents findings from the seventh annual global research study on artificial intelligence and business strategy by MIT Sloan Management Review and Boston Consulting Group. In spring 2023, we fielded a global survey and subsequently analyzed records from 3,043 respondents representing more than 25 industries and 100 countries. We also [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/AI-BusinessStrategy_Article03_1290x860.jpg" alt="" /><br /></figure><aside class="callout-info"><h4>关于研究</h4><p>本系列文章介绍了<cite>麻省理工学院斯隆管理评论</cite>和波士顿咨询集团第七次年度人工智能和商业战略全球研究的结果。 2023 年春季，我们开展了一项全球调查，随后分析了来自 25 个行业和 100 个国家/地区的 3,043 名受访者的记录。我们还采访了 17 名在金融服务、媒体和娱乐、零售、旅游和运输以及生命科学等众多公司和行业领导人工智能计划的高管。</p><p>我们的研究探讨了管理者和领导者如何使用人工智能来增强战略衡量，以推进战略成果。它探讨了组织如何利用人工智能调整甚至生成新的 KPI 来定义和提供可衡量的更好绩效。</p></aside><p>使运营与战略保持一致是一项关键的领导任务。动荡的市场环境、敏捷的竞争对手以及对运营和流程进行数字化升级的持续需求，使得战略调整的管理更具挑战性。精通数字化的领导者正在通过改进他们使用和开发 KPI 的方式来应对一致性挑战。</p><p>根据对 3,000 多名经理的全球调查和 17 名高管访谈，我们发现各个业务领域的领导者都在使用人工智能来增强 KPI 的优先级、组织和共享方式。这些增强功能对加强战略协调具有直接、可衡量的影响。这些领导者还部署人工智能来提高 KPI 本身的准确性、细节和预测能力。这些单独和集体的改进产生了更强的态势感知能力，并改善了公司职能部门协同工作以实现战略成果的方式。</p><p></p><p>领导者承认，他们需要新的衡量能力和改进的指标，以更好地预测和应对战略机遇和威胁。 <a id="reflink1" class="reflink" href="#ref1">1</a>他们认识到，基于人工智能的新测量能力可以提供新的绩效见解和指标、加强一致性并改善结果。我们的研究结果明确、一致地呼吁领导者采取行动，创建更具前瞻性和相互关联的 KPI 综合系统。</p><p>这些富含人工智能的 KPI（或<em>智能</em>KPI）可以有效地充当企业 GPS，为人们提供有关他们在哪里、他们需要去哪里以及如何最好地到达那里的建议。这些智能 KPI 可以更详细、更准确地描述业务中正在发生的情况，更深入地预测可能发生的情况，并且在某些情况下，为经理应采取的行动提供更主动的建议。更智能、更具前瞻性的 KPI 可以改善由于时间和执行惰性而导致不协调和不受挑战的传统 KPI。</p><p>我们讨论来自多个行业的示例，这些示例说明了领导者如何使用这些新功能来实现其战略目标，并提供使用人工智能丰富 KPI 和推进战略调整的具体建议。</p><div class="callout-highlight"><aside class="l-content-wrap"><article><h4></h4><p>智能 KPI 是由人工智能提供的前瞻性且相互关联的 KPI。</p></article></aside></div><h3>加强与人工智能的战略对接</h3><p>KPI 始终旨在成为使组织行为与战略目标保持一致的机制。然而，大多数管理者并不认为他们的关键绩效指标<em>在实践中</em>反映了战略愿望；他们认识到他们的 KPI 需要改进。 <a id="reflink2" class="reflink" href="#ref2">2</a>我们的研究表明，利用人工智能丰富 KPI 的领导者更有可能看到一致性的好处，例如改善跨职能协调。他们能够更有效地确定 KPI 的优先级、识别和建立 KPI 之间的关系以及跨团队共享 KPI 相关数据。他们更多地将 KPI 视为需要改进的资产，而不是需要实现的目标。</p><h4>利用 AI 确定 KPI 的优先级</h4><p>决定强调和优先考虑哪些 KPI 是战略调整的一个众所周知的挑战：“我们需要更好地调整我们的 KPI”是我们定性研究中的常见说法。受访者普遍认为高管的直觉是 KPI 分歧的一个关键根源。受访者表示，他们的公司已使用人工智能来确定 KPI 的优先级，他们看到职能之间更好协调的可能性是未使用人工智能的受访者的 4.3 倍。通过 AI 确定 KPI 的优先级可以改善数据驱动的决策，并为更强有力的战略协调奠定基础。</p><p>丹麦运输、航运和物流公司马士基利用人工智能重新评估和定义了如何衡量其遍布全球港口、运输和仓库的 65 个资产网络的吞吐量和生产力。一线管理人员必须决定关键绩效的最佳定义是通过尽快装卸船舶或卡车（最大化吞吐量），还是通过管理装载流程，以便运输能够可靠地按计划出发。正确的 KPI 是速度还是进度可靠性？</p><p></p><p>这一决定将对企业产生巨大的实际影响。在<a href="https://www.apmterminals.com/en/about/our-company">APM码头</a>使用更多设备进行装卸会增加吞吐量，但会增加短期成本（额外的设备意味着额外的费用）。相比之下，仅使用足够的设备来确保准时出发会降低成本，但会限制吞吐量。根据经验，现场一线管理人员认为，速度——尽快装卸船舶——是正确的绩效衡量标准。</p><p>为了检验这一假设，马士基的数据科学团队开发了数字孪生——人工智能驱动的模型——来代表每种方法并评估它们在整个价值链中的影响。他们的结论是，使用较少的装载设备可以避免转运点或与公路和铁路等其他运输方式连接时出现的瓶颈。</p><p>他们还发现，一个港口的速度加快会导致其他地方的速度减慢。遵守可靠的时间表还可以降低成本并提高准时到达率。马士基首席数据官霍莉·兰德里 (Holly Landry) 表示，放慢速度是“一个违反直觉的指标”。 “在供应链中使用数字孪生既可以解释又可以证明使用更少的设备是合理的。仅在一台终端上就节省了数百万美元。”</p><p>现在，该公司正在其价值链中推出数字孪生。借助人工智能，马士基优先考虑正确的 KPI，从而在整个企业内实现更高效、更一致的绩效，并通过可靠的交付提高客户满意度。</p><h4>将 KPI 与 AI 集成</h4><p>通过 AI 发现 KPI 之间的相互依赖关系，有助于创建 KPI“整体”，将不同但相互关联的业务活动的不同 KPI 捆绑在一起。 KPI 集合的示例包括员工生产力和客户参与度、利润率和市场份额以及质量制造产出和资产回报率。人工智能在识别将一个 KPI 与另一个 KPI 联系起来的其他隐藏模式方面发挥着关键作用。由于这些模式通常跨越多个职能和利益相关者，KPI 整体可以打破孤岛并增加不同利益相关者之间的协作，从而增强组织一致性。</p><p>价值 100 亿美元的全球烈酒公司保乐力加 (Pernod Ricard) 使用人工智能来描述和加深其两个最重要的 KPI 之间的联系：利润率和市场份额。过去，这些 KPI 是孤立且分离的，每个指标都有自己的一套衡量标准。 （财务职能侧重于盈利能力，而销售和营销侧重于市场份额。）该公司现在部署人工智能来深入了解可提高利润的商业和营销投资（例如媒体或店内激活）如何影响市场份额目标反之亦然。该烈酒制造商现在不再寻求最大化每个单独的 KPI，而是寻求相互协调地优化两个 KPI。</p><p> “如果您可以想象在市场份额优化目标和利润优化目标之间移动光标，”保乐力加首席数字官 Pierre-Yves Calloc&#39;h 表示，“您需要了解实现这些目标所需的投资如何变化。人工智能将为你提供这些信息。借助人工智能，我们可以更好地调整市场份额 KPI、利润 KPI 以及实现这些目标所需的投资。”这种能力改变了保乐力加领导层分配资本以及平衡其对盈利能力和市场份额的渴望的方式。</p><p></p><h4>使 KPI 共享、可见且可信</h4><p>从广义上讲，共享 KPI 意味着共享责任、共享信息或两者兼而有之。分担 KPI 责任通常是领导层的决定。共享性能信息取决于技术和数据访问。我们的研究确定了人工智能增强 KPI 信息共享并促进组织不同部门之间协作的几种方式。</p><p>使用人工智能共享 KPI 可以提供特定的好处，可以加强战略一致性。与不使用 AI 共享 KPI 的组织相比，使用 AI 共享 KPI 的公司改善职能一致性的可能性高出五倍，敏捷性和响应能力提高的可能性高出三倍。正如一位高管所说：“我们需要采取更多措施来共享 KPI。 ......应该分享哪些正确的 KPI，才能让我们确保一件事不会适得其反地压倒另一件事？”通过适当的数据和人工智能应用程序，提高对全公司 KPI 结果和绩效驱动因素的可见性，增强管理者分享、讨论和应对 KPI 之间紧张关系的能力。</p><p>在赛诺菲，人工智能汇集了驱动制药公司综合业务计划 (IBP) 的数据——对于过去 50 年来进行了 300 次收购的企业来说，这是一项艰巨的任务。 2019 年，即将上任的首席执行官 Paul Hudson 倡导数据民主化，这需要新的数据质量和治理标准，以及新的处理和分发技术基础设施。主要 IBP 指标的绩效数据最终通过名为 Plai 的智能新型数字界面（因其易于访问、易于使用、人工智能驱动的功能）进行整合并与全球 10,000 名高管共享。</p><p></p><p>这种平易近人的人工智能工具，也被其开发人员称为“零食人工智能”，它提供了公司范围绩效的可见性，并使管理人员能够就绩效进行建设性讨论。赛诺菲全球财务运营和转型主管斯蒂芬妮·安德罗斯基 (Stephanie Androski) 表示，这些对话在以前是不可能的，不是因为数据不可用，而是因为算法引入了一定程度的客观性，使决策和对话更加有机、可信和有效。</p><p> “我们现在有一个数字落后于我们的销售预测，并且它是多个其他 KPI 的中心点。如果我们预测某种产品可能出现缺货情况，我们不仅能够说，‘哦，等一下，人工智能还预测我们该产品可能会在四年内缺货。几个月。这是真的吗？我们能超越它吗？它还使我们能够作为财务人员提出这样的问题：“对于该产品来说，销售是否过于雄心勃勃？”我们会失去市场份额吗？或“这对总体预测有何影响？”因为一切都更加公开，而且因为你可以看到它，所以它确实有助于增加对话和生产力。”</p><p>领导力的基本要点是，利用人工智能组织和共享 KPI 数据可以为协作和协调提供有价值、值得信赖的平台。</p><h3>三种类型的智能 KPI</h3><p>随着 KPI 的发展，它们对战略调整的贡献也在不断发展。我们的研究表明，人工智能丰富的 KPI 可通过三种方式改进仅跟踪绩效的指标。这些智能 KPI 可以更好地描述世界的现状（当前和过去的绩效），并更好地预测世界可能的情况（未来的绩效）。在某些情况下，智能 KPI 还表明可以或应该采取哪些措施来促进更好的结果。例如，执行仪表板通常对 KPI 进行颜色编码：红色表示性能下降，绿色表示性能达到/超出预期。这种编码是传统 KPI 和仪表板提供的一种简单的号召性用语类型。智能 KPI 更进一步：它们可以就后续步骤提出更详细、更具体的建议，并诊断对其他 KPI 的影响。</p><p>因此，智能 KPI 在三个重叠的意义上改进了传统 KPI：它们更好地描述和<em>预测</em>绩效，并<em>提供</em>更详细和更有价值的建议。这三种类型的智能 KPI 映射到描述性分析、预测性分析和规范性分析之间众所周知的区别。下面更详细地解释了这种 KPI 类型。</p><p> <strong>1. 智能描述性 KPI。</strong>这些 KPI 综合了历史和当前数据，以提供有关<em>已发生</em>或<em>正在发生的情况</em>的见解。它们可以更深入地了解绩效差距及其原因，从而更好地创建 KPI 或更好地理解 KPI 关系。赛诺菲的零食人工智能工具就是一个例子，它通过揭示不同 KPI 之间的关键相互依赖性来增强态势感知。</p><p> <strong>2. 智能预测 KPI。</strong>这些关键绩效指标通过产生可靠的领先指标来预测未来的绩效。它们提供了对潜在结果的可见性，从而能够采取先发制人的行动来减轻风险或利用机会。例如，通用电气已将其关键绩效指标 (KPI) 转变为关注领先指标。例如，该公司正在使用人工智能，通过将订单与产品和服务的安装基础进行比较来分析订单渠道。这些详细的比较有助于准确地识别增加未来订单的机会，从而推动更强劲的收入和利润。正如通用电气高级财务副总裁兼前首席财务官 Carolina Dybeck Happe 所指出的那样，“利用领先指标可以在战略与战略实施之间建立更快、更紧密的联系。”</p><p> <strong>3. 智能的规定性 KPI。</strong>除了描述和预测之外，规范性 KPI 还通过人工智能推荐操作来丰富。它们不仅指出绩效差距，还提出纠正措施。例如，赛诺菲的智能 KPI 通过根据供应链绩效建议调整销售 KPI，从而协调运营和销售。</p><p>利用 AI 丰富关键绩效指标 (KPI)，使关键指标能够推动正确的绩效并加强战略协调。通过将 KPI 转变为智能的描述性、预测性和规范性工具，精通数字化的组织可以利用它们来增强态势感知、更有效的决策和改进绩效管理。</p><h3>领导力要点</h3><p>根据我们的研究，以下行动将帮助领导者使用人工智能来改善他们使用和开发 KPI 的方式以及他们如何使运营与战略保持一致。</p><p><strong>将 KPI 视为资产。</strong>当 KPI 被视为资产和指标时，它们会带来更加深思熟虑和有目的的投资。哪些 KPI 应该通过人工智能来丰富或改进？哪些 KPI 可以变得更具预测性和前瞻性？为了加强 KPI 之间的关系并增强战略一致性，需要对人工智能、数据和人员进行哪些投资？就像组织识别、培养、培训和培养员工以获得更大的责任和决策权一样，领导者也应该识别、培养、培训和发展他们的 KPI，以提供可行的见解和建议。</p><p><strong>鼓励提高绩效衡量的可见性和透明度。</strong>使 KPI 更加明显可以明确问责制和责任，鼓励讨论并培养共同的目标感。赛诺菲的案例说明，创建一个对高层领导者可共享且可见的绩效单一事实来源有利于协调一致。增加对 KPI 的跨职能访问可以鼓励增强态势感知和自我意识。民主化获取可信且透明的绩效数据可以帮助人们了解自己所处的位置以及需要去往的地方。最高管理层应致力于人工智能相关资源，以提高 KPI 的可见性和透明度。</p><p><strong>映射 KPI 关系和联系。</strong>整个企业的人员应该能够了解关键绩效者、关键绩效和关键绩效指标之间的相互关系。可见性和可视化动画化了组织协调的运作方式。施耐德电气首席治理官兼秘书长 Hervé Coureil 表示，数据驱动型领导者可以使用人工智能来绘制、建模和管理他们的绩效驱动因素和 KPI 优先事项。 Coureil 指出，描述和代表公司的“KPI 生态系统”可能是劳动力和资源密集型的第一步。这些地图和模型都可以识别和阐明哪些 KPI 应该共享或集成。例如，以客户为中心的组织可能会优先考虑围绕客户体验和客户生命周期价值指标的共享和集成 KPI。更好的映射和建模使 KPI 成为更好的资产。</p><p></p><h3>结论</h3><p>我们的研究发现，改善战略一致性不仅取决于正确定义最重要的指标，还取决于利用人工智能和更好的数据不断开发这些指标。但在更根本的层面上，我们的研究强调，人工智能正在承担曾经属于高管专属领域的任务，例如确定优先级、整合和共享 KPI。人工智能和 KPI 的融合正在重新定义 KPI 的使用方式以及 KPI 如何促进战略协调。对于数据驱动型领导者来说，不断将战略转化为更智能、更有组织性和更有价值的指标是一项日益重要的活动。</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/strategic-alignment-with-ai-and-smart-kpis/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>自动化时代的采购</title><link/>https://sloanreview.mit.edu/article/procurement-in-the-age-of-automation/<comments> https://sloanreview.mit.edu/article/procurement-in-the-age-of-automation/#respond</comments><pubDate> Thu, 31 Aug 2023 11:00:01 +0000</pubDate> <dc:creator><![CDATA[Remko Van Hoek and Mary Lacity. <p>Remko Van Hoek 是阿肯色大学山姆沃尔顿商学院的供应链管理教授。他此前曾担任华特迪士尼公司的首席采购官，并在耐克和普华永道等其他几家公司担任采购主管职务。玛丽·莱西蒂 (Mary Lacity) 是沃尔顿商学院信息系统学的杰出教授。</p> ]]>; </dc:creator><category><![CDATA[Automation]]></category><category><![CDATA[Change Management]]></category><category><![CDATA[Negotiations]]></category><category><![CDATA[Procurement]]></category><category><![CDATA[Supply Chain Strategy]]></category><category><![CDATA[Data, AI, & Machine Learning]]></category><category><![CDATA[Leadership]]></category><category><![CDATA[Leading Change]]></category><category><![CDATA[Operations]]></category><category><![CDATA[Supply Chains & Logistics]]></category><description><![CDATA[Kotryna Zukauskaite/theispot.com The Research The authors have been studying procurement and automation for two decades.i Mary Lacity has conducted more than 50 case studies on enterprise use of automation technologies. Remko Van Hoek and Lacity have been studying early adopters of procurement technologies for three years, including companies using e-auctions, artificial intelligence, and other emerging [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/2023FALL-VanHoek_1290x860.jpg" alt="" /><figcaption><p class="attribution"> Kotryna Zukauskaite/theispot.com</p></figcaption></figure><aside class="callout-info"><h4>这个调查</h4><p>作者二十年来一直在研究采购和自动化。 Mary Lacity<a id="reflinki" class="reflink" href="#refi">就</a>企业使用自动化技术进行了 50 多个案例研究。 Remko Van Hoek 和 Lacity 三年来一直在研究采购技术的早期采用者，包括使用电子拍卖、人工智能和区块链等其他新兴技术的公司。在这篇文章中，他们采访了高级管理人员、业务部门领导、采购卓越中心的经理、数十家公司的买家、供应商和自动谈判软件供应商。</p></aside><p>高管们常常对自动化采购流程持怀疑态度，特别是当涉及谈判时，但自动化谈判工具为所有利益相关者提供了相当大的价值，并且可以在许多企业中有效使用。</p><p>在过去的三年里，我们研究了数十家组织的现代自动化采购实践。我们研究了已经存在一段时间但尚未广泛采用的技术，例如电子拍卖技术，以及较新的技术，例如人工智能聊天机器人。在我们的研究中，与进行传统的面对面谈判的公司相比，采用自动化采购谈判的公司始终能够节省资金，并通过识别更多合格的供应商来提高供应链的弹性。自动化谈判还提高了买家的生产力，使买家能够在现在由软件处理的任务上花费更少的时间和精力。供应商受益于明确的评估方式、更短的销售周期、对其当前地位的实时反馈，以及即使在涉及根深蒂固的现有供应商的情况下，他们也会受到公平对待的信心。</p><p></p><p>然而，实施新的采购模式和不同的关系方法并不容易。利益相关者通常有合理的担忧。支付商品和服务费用的业务部门负责人担心，自动化谈判将使他们成为最便宜的供应商（仅根据成本选择），从而使他们面临质量低劣、服务质量差和供应商关系破裂的问题。买家经常拒绝自动化工具，因为他们将谈判视为自己的专长，并担心被边缘化甚至被取代。供应商希望有机会在价格以外的方面脱颖而出；非现有供应商常常怀疑买家使用自动谈判只是为了迫使现有供应商降低价格，因此担心他们没有赢得业务的合法机会。</p><p>在本文中，我们详细介绍了组织从自动化谈判中获得的实质性好处、如何说服利益相关者使用该技术以及如何将自动化纳入采购流程。</p><h3>获得自动化谈判的好处</h3><p>我们研究中的大中型公司都通过自动化谈判实现了显着的节省。丹麦全球航运公司马士基每年使用各种自动化谈判支出达 10 亿美元，与人工谈判相比，过去几年节省了 7% 至 8%。沃尔玛国际公司对价值超过 70 亿美元的支出进行了自动化谈判，与传统谈判相比，获得了 5% 或更多的附加价值。谷歌从其大规模电子拍卖计划中看到了良好的效果，并将该技术嵌入到其采购工具包和流程中。</p><p>小公司也节省了开支。 Walker&#39;s Shortbread 是苏格兰的一家家族烘焙食品制造商，每年购买价值 8000 万英镑（1.05 亿美元）的原料和包装材料。 2023 年上半年，该公司 90% 的原材料支出都采用了自动谈判，根据类别节省了 1.5% 到 7% 之间。总部位于墨西哥的另一家家族食品制造商 Grupo Herdez 一直在使用电子拍卖来支付其年度原材料采购的一小部分，在香料和种子等商品上节省了约 8% 的费用。该公司计划今年将电子拍卖扩展到其他采购类别。</p><p>沃尔玛、马士基和谷歌已经扩大了跨采购类别的自动化谈判，包括营销媒体、船员食品、运输服务、总承包商服务、电子商务小包裹递送、供应链设备，甚至营销代理服务。截至 2023 年 6 月，马士基已进行了 10,000 多次电子拍卖。 2022年，沃尔玛将电子拍卖应用于其间接支出总额的65%。虽然与马士基或沃尔玛相比，Walker&#39;s Shortbread 进行的拍卖数量微乎其微，但其默认采购选项现在是电子拍卖。</p><p>自动化谈判极大地增加了公司可以包括的供应商数量和谈判回合数，同时显着减少了流程所需的时间。在种类繁多的电子拍卖中，沃尔玛有多达150家供应商同时参与，在大约两个小时内进行了多轮谈判。沃尔玛负责战略采购的副总裁迈克尔·德威特 (Michael DeWitt) 表示：“买家需要几个月的时间才能亲自完成这样的谈判。”</p><p>这种效率使各种规模的公司受益。 “电子拍卖执行的速度推动了价值的增长，”Walker&#39;s Shortbread 的采购主管 Kees Bressers 说道。</p><p></p><p>扩大自动化谈判规模的公司已将特定支出类别和市场条件的采购策略与最佳自动化流程和工具相匹配。 （请参阅“自动谈判的工作原理”。）他们致力于通过促进各自获得的利益来赢得三个利益相关群体（业务部门负责人、买家和供应商）的成员的支持。</p><div class="callout-highlight"><aside class="l-content-wrap"><article><h4>自动谈判如何运作</h4><p>有许多细致入微的自动谈判流程和工具，但从较高的层次来看，它们可以分为两类：一个买家和多个供应商，或者一个买家和一个供应商。在这两种情况下，人类买家都会为谈判事件准备软件。事件部署后，人类买家仍处于观望状态，而软件则与代表供应商的人类进行交互。</p><h4 style="color:black;">一个买家，多个供应商</h4><p>电子拍卖（沃尔玛称之为交互式投标）是一种实时在线谈判，通过提高时间和流程效率，利用竞争来实现真正的市场价值。 <a id="reflinkii" class="reflink" href="#refii">ii</a>与买家处于中间位置的传统谈判相比，电子拍卖允许买家退出流程，让供应商直接相互竞争，如下图所示。 </p><aside class="l-content-wrap"><article style="border-bottom-width:3px;border-bottom-style:solid;border-bottom-color:#00e0ff;margin-bottom:20px"><h4>传统与多个供应商的自动化</h4><p class="caption">在自动谈判中，买方仍然对流程和定义规则负责。 </p><p><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/MAG_VanHoek_Fig1.png" alt="传统与多个供应商的自动化" /><br /></article></aside><p>这个过程让市场发挥其作用，而不会出现潜在买家的偏见，例如偏向现有供应商。当至少有两家合格供应商愿意参与时，采购团队可以考虑进行电子拍卖。</p><div class="callout-toggle"><p>自动电子拍卖主要分为三种类型：</p><p><strong>英国反向拍卖。</strong>供应商实时竞争，成为最低出价者。供应商可以看到每个人的出价，并且可以重复输入更低的价格。在活动结束前提交最低价格的供应商将获得买方的业务。</p><p>英国反向拍卖适合在有大量竞争对手的市场中采购商品和服务。这种形式刺激了竞争性投标，并往往会在拍卖的最后阶段将投标人之间的定价推向一个狭窄的范围。该格式可用于一次招标中的多个批次，并且可以容纳许多轮次和投标人。</p><p>英式反向拍卖是最常用的形式，但买家应注意不要总是默认使用它们，而应考虑其他选择。</p><p><strong>荷兰反向拍卖。</strong>在这里，买家以低价进行竞争。如果没有供应商对初始价格出价，买方的软件就会逐步提高价格。该过程不断重复，直到供应商出价或买方达到其愿意支付的上限。第一个接受当前价格的供应商将获得买方的业务。</p><p>荷兰逆向拍卖采用赢者通吃的奖励策略，适合在供应商市场上采购商品和服务，因为供应商对达成协议有很大兴趣。大量的供应商是没有必要的。然而，该格式无法像英国反向拍卖那样实现价格发现。</p><p><strong>日本逆向拍卖。</strong>通过这种方式，买方以高价进行竞争。所有愿意接受此价格的供应商都将继续谈判。接下来，软件降低价格，所有愿意接受这个价格的供应商都可以继续竞争。该过程不断重复，直到供应商接受当前价格，然后获得买方的业务。</p><p>在投标人数量有限的市场中，日本反向拍卖是英国反向拍卖的良好替代方案。该格式确保供应商明确选择加入，这可以增强买家对报价的信心。</p><p>这种格式不太常用，买家和供应商可能不太熟悉。存在拍卖提前结束的风险，其价格高于买家期望的价格，因为只需一次增量出价即可赢得胜利。</p><h4 style="color:black;">一位买家，一位供应商</h4><p>即使只有一个供应商，买家也可以应用自动谈判。同样，需要考虑各种流程和工具。</p><p>人工智能驱动的聊天机器人会自动协商条款和条件，例如付款计划、终止条款和增长机会。聊天机器人被编程为产生确定性结果，并且不会协商买方未预先批准的任何条款。</p><p>动态报价请求工具掩盖了买方对逐项商品或服务的目标价格，等待人工供应商输入建议价格，然后提供有关协议水平的即时反馈。 </p><aside class="l-content-wrap"><article style="border-bottom-width:3px;border-bottom-style:solid;border-bottom-color:#00e0ff;margin-bottom:20px"><h4>传统与单一供应商的自动化</h4><p class="caption">自动化工具甚至可以用于与单个供应商进行谈判。 </p><p><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/MAG_VanHoek_Fig2.png" alt="传统与单一供应商的自动化" /><br /></article></aside></div></article></aside></div><ul><li><em>业务部门负责人</em>可以以最优惠的价格接触到更多合格供应商。他们继续定义需求、期望的条款和条件以及预算，因此他们的角色不会改变。然而，他们必须接受他们最喜欢的现有供应商可能会被取代的事实。</li><li><em>买家</em>并没有被淘汰，而是被淘汰了。相反，他们的职责扩大了，并且更有战略性地运用自己的专业知识。他们将考虑更多的采购选择，将业务部门负责人的需求正式化为模板或记分卡，寻找更多合格的供应商，并利用新的自动化工具。买家不再与供应商进行面对面谈判，而是组织并限定供应商参加自动谈判活动。</li><li><em>供应商</em>需要接受新的自动化工具和流程的培训。他们受益于提高公平性的规则、投标竞争力的实时反馈以及减轻的管理负担。与与买家面对面谈判的经验相比，供应商花更多的时间规划自动化活动，但谈判的时间却少得多，从而缩短了整体销售周期。</li></ul><p>通过研究已经成功过渡到自动化谈判的公司，我们确定了六种关键实践，可以帮助领导者克服利益相关者的阻力并创造价值。</p><p></p><p> <strong>1. 强制考虑，而不是使用。</strong>虽然高管们可能会倾向于强制采用自动化采购，但这通常是获得业务部门负责人和买家支持的糟糕方法。相反，大型采购组织的高管可能会要求买家<em>考虑</em>参与自动谈判。这种做法允许买家利用他们的主题专业知识以及与业务部门负责人的关系来确定最佳的自动化机会，这有助于利益相关者的支持并优化自动化的有效性。</p><p> 2009 年航运业处境艰难，因此马士基认为削减成本对于确保其市场竞争力至关重要。当时的首席采购官（CPO）要求买家<em>考虑</em>采用电子拍卖，并为每个买家设定最低年度目标，作为其年度绩效评估的一部分。 CPO 认识到不使用电子拍卖可能有正当理由，例如投标人数量不足，因此业务部门负责人和买家选择最适合自动谈判的交易来实现目标。</p><p>与马士基一样，沃尔玛要求所有买家考虑实现所有谈判的自动化。最初，采购负责人与业务部门负责人和买家进行路演，以传达潜在价值，并明确买家可以通过记录其理由来选择退出。</p><p> “通过将拍卖作为首选默认方式，它迫使我们制定更好的采购策略，”沃尔玛的德威特说。 “它鼓励买家跳出框框思考并寻找更多供应商，无论他们是否进行拍卖，这最终都会使企业受益。”</p><p>采购业务规模较小的公司的高管可能会发现没有必要强制执行。例如，Walker&#39;s Shortbread 整个公司只有五名全职采购专家，而且他们都在同一个办公室工作，因此 Bressers 能够直接与他们讨论策略。这种方法帮助他获得了一家公司对数字采购的认可，该公司几十年来一直通过电话和电子邮件管理流程。</p><p></p><p>同样，Grupo Herdez 也没有强制考虑或使用电子拍卖。 COVID-19 大流行引发的经济危机使成本合理化成为生存的要求。采购团队向业务部门所有者、买家和供应商传达了使用自动谈判来降低成本的必要性。业务部门所有者和供应商的看法最有说服力，因为该公司已经使用了一些相同的供应商长达 40 年或更长时间。为了让现有供应商同意参与电子拍卖，Grupo Herdez 的采购经理向供应商的高级领导解释了通过竞争来削减成本的经济需要。 “尽管他们中的许多人因为规模比我们大而在关系中拥有更大的权力，但他们理解并接受我们的需求，”战略供应经理 Felipe Díaz Mojica 说。</p><p> <strong>2. 让成功看得见。</strong>虽然强制考虑电子拍卖有助于全球企业起步，但让整个公司都能看到早期的成功可以让业务部门负责人和买家兴奋不已——尤其是当领导者将买家的作用归功于买家时。谷歌在员工通讯中展示了他们的成功，并根据员工通过自动谈判进行的活动数量提供奖励。</p><p>在马士基自动化之旅的早期阶段，首席采购官在大屏幕上直播谈判，并对领导电子拍卖的业务部门负责人和买家表示祝贺。由于每次电子拍卖都能节省两位数的成本，这些成功打破了利益相关者的自满情绪。马士基采购总监 Nikolaj Jessen-Klixbüll 表示：“自动化谈判的‘推动’策略很快就演变成需求‘拉动’。”</p><p></p><p>在沃尔玛，来自一个国家的业务部门负责人对自动谈判的价值特别怀疑，因此采购负责人邀请他们观看礼堂大屏幕上的现场拍卖。德威特回忆说，这些非信徒最初坐在后面，双臂交叉。</p><p> “看起来没有人高兴，”他说。 “然后拍卖开始了，价格开始下跌。竞争非常激烈，你可以看到房间里的气氛发生了变化。人们开始微笑。最后，他们互相击掌，也向我们击掌。从那以后，他们成为了我们最好的冠军。”</p><p>沃尔玛每月颁发奖项，表彰那些在新支出类别、大型活动或新地区使用自动谈判的买家。该奖项的目的之一是向整个公司发出信号，虽然软件可以实现自动谈判，但运行它们的是买家。</p><p>在 Walker&#39;s Shortbread，业务部门负责人需要了解供应商在批准新采购模式之前如何提交投标。 “企业主很紧张，”布雷瑟斯说。 “我们是一家拥有 125 年历史的公司，交易是通过握手和采购订单完成的。”在进行现场直播之前，他通过在沙盒环境中演示电子拍卖赢得了他们的支持。然后，他邀请主要业务部门负责人和采购团队参加前几次现场拍卖，拍卖会在大屏幕上显示。企业领导观摩招标过程后，认为招标过程公平，对较低的价格感到非常满意。</p><p>这些早期成功的发生只是因为这些公司仔细规划了自动化活动，包括审查供应商。</p><p> <strong>3. 对供应商进行资格预审。</strong>采购团队应在自动谈判活动之前招募并预先批准供应商。这种做法确保只有有能力的供应商才能获得业务。采购团队可能还需要收集初步建议，以增加合格供应商的数量。</p><p>马士基的买家与业务部门负责人合作以确定他们的需求。这些要求被转换为供应商分数，用于根据最低要求对供应商进行资格预审，并在谈判开始前根据其比较地位对他们进行排名。例如，碳足迹较低的供应商将比碳足迹较高的同等供应商更受青睐。 <a id="reflink1" class="reflink" href="#ref1">1</a></p><p> Jessen-Klixbüll 表示：“为了取得成功，企业主必须明确他们的先决条件。” “他们知道，如果企业不相信供应商能够提供服务，我们就不会邀请任何供应商参与。”</p><p>在电子拍卖之前，如果市场上供应商有限或供应商之间的价格差异较大，马士基会使用自动动态报价请求 (RFQ)。动态询价流程旨在缩小定价差距并使更多供应商有资格参加电子拍卖。当市场上不存在其他可行的供应商时，马士基还使用此流程与单个供应商谈判交易。</p><p>业务部门负责人和买家根据市场评估、需求和预算商定目标价格。活动期间，马士基的软件显示空白的单项价格表，但未透露公司的目标价格。供应商提交建议价格后，动态询价系统会自动反馈供应商报价的竞争力，使用红绿灯比喻：绿色表示出价具有竞争力，琥珀色表示出价接近竞争性，红色表示出价接近竞争性。表明该投标不具有竞争力。</p><p>与时间限制较短的电子拍卖不同，动态询价活动会持续几天，以便供应商有时间与下级供应商合作进一步折扣，然后输入新的、更具竞争力的出价。</p><p>沃尔玛使用记分卡来评估业务部门负责人对质量、服务、安全、可持续性、成本和其他标准的加权要求。供应商经过资格预审，并根据其记分卡分配初始排名。记分卡嵌入交互式投标软件中，因此供应商可以看到他们的排名。如果业务部门负责人非常重视成本，那么供应商就会通过出价较低来提高排名。如果非价格因素的权重很大，降低价格不会大幅提高供应商的排名。</p><p>沃尔玛采购转型和卓越中心 (COE) 总监 Bayan A. Hariri Sr. 表示：“需要做好前期工作，让企业和买家利益相关者制定记分卡。” “但这使得活动结束后奖励供应商变得更加容易。”</p><p>在采用自动谈判之前，Walker&#39;s Shortbread 的买家联系现有供应商和一两个其他供应商以确定市场价格，然后利用该信息与现有供应商重新协商价格。现在，随着自动化谈判的实施，买家首先邀请供应商回复询价，以确定供应商的能力并了解当前的市场价格。然后，Walker&#39;s Shortbread 使用此信息对供应商进行电子拍卖资格预审。现有企业现在正在争夺这项业务。某些采购类别的合格供应商数量增加了一倍，竞争加剧。</p><p> <strong>4. 公平对待非现有供应商。</strong>在自动谈判开始之前，采购团队必须向供应商传达价值、流程和奖励标准。谷歌全球采购经理 Lily Han 表示：“与供应商沟通非常重要，通过电子拍卖，供应商可以更好、更实时地了解自己在投标中的地位。” “他们还可以非常直接地控制自己的竞争地位；更多的事情掌握在他们手中。” Grupo Herdez 的 Díaz Mojica 表示，与此同时，供应商需要确保其他供应商不会知道谁在参加该活动。</p><p>正如大多数采购专业人士所证明的那样，业务部门负责人和买家更喜欢现有供应商，因为变革会带来更多的工作和潜在的运营风险。公司应坚持严格的政策，即赢得谈判的供应商应获得业务。事后不应进行任何谈判；现有供应商不应能够通过事后提供大幅折扣来推翻自动谈判的结果。马士基、沃尔玛和 Walker&#39;s Shortbread 都遵守这一黄金法则。 Walker&#39;s Shortbread 根据技术和成本标准的加权平均值选出获胜者。</p><p>为了增加公平性并避免对流程和目的的误解，沃尔玛还为每个供应商在参与自动化谈判之前提供个性化培训。买家解释拍卖设计和奖励标准，并确保供应商了解如何使用该技术。</p><p>供应商对培训的反馈是积极的，但衡量供应商价值的更好指标是重复参与，德威特表示：“供应商一次又一次地回来。”</p><p> <strong>5. 释放人工智能的力量，改善与尾端供应商的交易。</strong>通常，采购组织只与主要供应商进行谈判，这些供应商通常占公司供应商的 20%，但占公司采购预算的 80%。买家通常会向终端供应商提供不可协商的千篇一律的交易。然而，最近，沃尔玛、马士基等公司已经找到了使用人工智能聊天机器人来改善与尾端供应商的交易的方法。</p><p>与电子拍卖技术一样，人工智能聊天机器人可以每周 7 天、每天 24 小时同时进行 2,000 项谈判，同时在需要时为供应商提供准备投标的时间。 Jessen-Klixbüll 表示：“同时进行大量谈判并能够在多种情况下扩展谈判的能力具有令人难以置信的价值。”</p><p>扩大聊天机器人的规模提高了马士基和沃尔玛的生产力，因为该软件可以从每次谈判中学习，从而减少新采购类别的设置时间。</p><p>当使用人工智能驱动的聊天机器人时，业务部门负责人和买家首先确定要接触的供应商，并定义可接受的权衡，这些权衡将成为编程的一部分。例如，业务部门负责人可能更喜欢价格折扣，以换取提前向供应商付款。或者，他们可能倾向于向供应商提供 60 天的书面终止通知，而不是便利终止条款，或者希望通过增加产品组合和销量来为供应商提供增长机会。</p><p>与许多产生概率结果的人工智能工具不同，人工智能驱动的自动化采购工具产生确定性结果，从而消除了意外结果的可能性。一旦部署了工具，买家就会退出流程，聊天机器人会向代表供应商的人员提供替代方案。</p><p>马士基开始将人工智能驱动的聊天机器人主要用于内陆运输，因为内陆运输的数量和流量太有限，无法证明全面拍卖的合理性。马士基预先授予特定地区的供应商，当需要供应商时，人工智能聊天机器人主导谈判。</p><p>沃尔玛首先使用其人工智能聊天机器人与一个国家的尾端供应商进行合同重新谈判，后来扩展到中端供应商和多个国家。其平均节省幅度为 7% 至 10%。作为回报，供应商获得了更好的终止条件、提前付款和/或增长机会。</p><p>大部分尾端供应商都对首次与沃尔玛积极洽谈的机会表示欢迎。在后续调查中，67% 的供应商表示，他们发现该系统易于使用，83% 的供应商喜欢还价功能。 <a id="reflink2" class="reflink" href="#ref2">2</a></p><p>小公司也可以从人工智能聊天机器人中获益。 Genuine Cable Group (GCG) 是一家拥有 1,200 名员工的美国公司，目前正在不同场景下训练其聊天机器人，计划于 2023 年第四季度推出。GCG 拥有数万家供应商，有些交易金额小至 10,000 美元在每年的支出中。首席执行官史蒂夫·毛切里 (Steve Maucieri) 表示，聊天机器人将使 GCG 能够比过去接触更多的供应商。该项目风险较低，因为软件提供商提供了收益分享模式，其中费用是从所产生的节省中支付的。 Maucieri 还预计，未来他的许多客户将使用人工智能驱动的聊天机器人与公司谈判交易。</p><p> <strong>6. 创建正式的支持结构。</strong>正式的支持结构，例如 COE，可以帮助扩大跨地域、业务部门和支出类别的自动化谈判。</p><p>马士基开始意识到，如果它想在全球范围内嵌入成熟的采购流程，就需要让采购团队更靠近其业务。它创建了一个由区域支持代表组成的全球 COE。巴拿马巴拿马城的球队；北卡罗来纳州夏洛特；南非开普敦；荷兰鹿特丹；迪拜，阿拉伯联合酋长国;和上海分别支持拉丁美洲、北美、非洲、欧洲、中东和亚洲。</p><p> COE 代表不会剥夺买家的谈判权。相反，他们提供工具专业知识并支持买家与业务利益相关者互动、考虑谈判类型以及使用模板设计自动化谈判的努力。 COE 还注重供应商体验，以便自动化谈判也减轻供应商的负担。</p><p> Jessen-Klixbüll 表示：“我们不想让谈判变得过于复杂、难以实施或官僚主义，因为买家和供应商最终都会离开。”</p><p>沃尔玛还拥有一个 COE，拥有专门的超级用户团队，为买家和供应商提供支持。沃尔玛的采购领导层将公司采购策略和能力的成熟视为自动化谈判的最大好处之一。 COE 不断更新其模板，以指导买家采用最佳采购方法。 “我们始终将自动化谈判定位为一种策略，可以增强谈判作为采购流程的一部分，而不是取代采购流程本身，”德威特说。</p><p>对于马士基和沃尔玛来说，鉴于新员工和供应商不断入职，自动化选项和谈判类型也在不断发展，买家和供应商培训正在进行中。</p><p></p><p>较小的公司可以利用外包提供商的服务来创建正式的结构。例如，Walker&#39;s Shortbread 聘请了一家电子拍卖软件提供商来管理基础设施和电子拍卖。</p><p></p><p>最终，自动化谈判与技术无关；而是与技术有关。它是通过关注采购策略使买家变得更加高效和有效。通过用明确定义的自动谈判活动取代高压的人对人谈判，供应商受益，并且销售周期不再停滞。业务部门负责人受益于可衡量的节省和扩大的合格供应商池。为了获得这些好处，管理人员应该减少对技术的关注，而更多地关注有效的采购策略、部署和变更管理。好消息是，我们所描述的实践在公司和行业之间具有高度的可移植性，并且有可能使许多人受益。</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/procurement-in-the-age-of-automation/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>万事达卡的生成式人工智能：治理占据中心舞台</title><link/>https://sloanreview.mit.edu/article/generative-ai-at-mastercard-governance-takes-center-stage/<comments> https://sloanreview.mit.edu/article/generative-ai-at-mastercard-governance-takes-center-stage/#respond</comments><pubDate> Wed, 30 Aug 2023 11:00:30 +0000</pubDate> <dc:creator><![CDATA[Thomas H. Davenport and Randy Bean. <p>Thomas H. Davenport ( <a href="https://twitter.com/tdav">@tdav</a> ) 是巴布森学院信息技术与管理学校长杰出教授、牛津大学赛德商学院客座教授以及麻省理工学院数字经济项目研究员。他是<cite>《Working With AI: Real Stories of Human-Machine Collaboration》</cite> （麻省理工学院出版社，2022 年）一书的合著者。 Randy Bean ( <a href="https://twitter.com/randybeannvp">@randybeannvp</a> ) 是一位行业思想领袖、作家、创始人兼首席执行官，目前担任全球咨询公司 Wavestone 的创新研究员、数据战略部门。他是<cite>《快速失败，更快学习：颠覆、大数据和人工智能时代数据驱动领导力的教训》一书</cite>的作者（Wiley，2021 年）。</p> ]]>; </dc:creator><category><![CDATA[AI Strategy]]></category><category><![CDATA[Analytics & Organizational Culture]]></category><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Generative AI]]></category><category><![CDATA[AI & Machine Learning]]></category><category><![CDATA[Data, AI, & Machine Learning]]></category><category><![CDATA[IT Governance & Leadership]]></category><category><![CDATA[Managing Technology]]></category><description><![CDATA[If you saw the action-adventure movie Everything Everywhere All at Once, you might have had the same reaction we did. Impressive and exciting? No doubt — that’s one reason why it won seven Academy Awards. A portent of the future? Perhaps — as scientists explore the idea of a multiverse, the film provides one vision [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/Davenport-1290x860-1.jpg" alt="" /><br /></figure><p>如果你看过动作冒险电影<cite>《一切都同时发生》</cite> ，你可能会有和我们一样的反应。令人印象深刻且令人兴奋吗？毫无疑问，这就是它赢得七项奥斯卡奖的原因之一。未来的预兆？也许——当科学家们探索<a href="https://www.forbes.com/sites/jamiecartereurope/2023/03/12/is-the-multiverse-real-the-science-behind-everything-everywhere-all-at-once/?sh=4a4837583475">多元宇宙的想法</a>时，这部电影提供了一种关于它可能是什么样子的愿景。有点奇怪和令人困惑？好吧，无论如何对我们来说。</p><p>直到最近担任万事达卡首席数据官的乔安·斯托尼尔 (JoAnn Stonier) 在<a href="https://venturebeat.com/ai/generative-ai-is-everything-everywhere-all-at-once-in-the-enterprise-says-mastercard-cdo/">最近的一次小组</a>讨论中对这部电影和生成式人工智能进行了恰当的比较。 “一切无处不在”是描述这项技术的好方法——令人兴奋、令人困惑，但同时又很重要。我们之前曾<a href="https://www.forbes.com/sites/tomdavenport/2020/04/13/joann-stonier-of-mastercard-a-unique-take-on-the-cdo-role/?sh=4dea1d172ac6">写过有关</a>斯托尼尔的文章，以及她作为少数多年来一直高度关注数据道德的 CDO 之一的不同寻常的地位。我们在她担任 CDO 的最后几天采访了她；此后，她成为了万事达卡会员，但仍将致力于数据和人工智能道德问题。</p><p></p><p>采访结束后，我们如您一样松了一口气，因为我们发现斯托尼尔和万事达卡在生成人工智能方面仍在摸索中。许多公司都是如此。 VentureBeat 最近的一项调查显示，超过一半的受访者表示他们的组织正在试验人工智能，但<a href="https://venturebeat.com/ai/more-than-70-of-companies-are-experimenting-with-generative-ai-but-few-are-willing-to-commit-more-spending/">其中只有 18% 的公司已经开始实施</a>。同样比例的人表示，他们预计明年会在该技术上投入更多资金。</p><p>当然，万事达卡是数据、分析和人工智能方面的老手：我们一年前写过它为成为“<a href="https://sloanreview.mit.edu/article/becoming-an-ai-powerhouse-means-going-all-in/">人工智能强国</a>”所做的努力，斯托尼尔在<cite>麻省理工学院斯隆管理评论</cite>播客<cite>《我，我自己》</cite>中<a href="https://sloanreview.mit.edu/audio/designing-a-better-future-mastercards-joann-stonier/">讨论了该公司对人工智能的使用</a><cite>和人工智能</cite>。万事达卡涉足人工智能领域已有十多年，最重要的是在网络安全领域。一位在人工智能方面经验丰富的领导者和公司仍在努力制定生成式人工智能战略的细节，这应该会让许多其他公司和管理者感到欣慰。</p><p></p><h3>什么已经清楚</h3><p>万事达卡在以前的人工智能形式方面拥有丰富的经验，这使其建立了强大的方法论和治理流程。在较高层面上，此过程涉及理解数据、理解模型以及审查输出和相关结果。</p><p>这些步骤中的每一个都将进入评估生成模型的过程，但它们可能有不同的风格。当然，万事达卡并不缺乏结构化数字数据，但生成式人工智能处理的数据通常是图像和结构较少的文本。考虑到生成模型的复杂性和规模，准确理解给定的输入如何产生特定的输出是非常具有挑战性的。这使得审查结果的步骤变得更加重要，需要评估结果的事实准确性、偏见或有毒语言、对用户的价值，以及结果可能对个人、组织和生态系统造成的意外后果。操作。</p><p>尽管该技术存在固有的不确定性，但万事达卡已经制定了一些关于生成人工智能的政策。 2022 年 11 月推出 ChatGPT 后不久，公司就制定了指导方针，以确保员工利用新技术进行负责任的创新。这鼓励内部探索其供应商提供的模型，同时保护公司机密信息。</p><p>一些公司甚至禁止员工使用 ChatGPT 和其他大型语言模型，但万事达卡并没有这么做。 “有些用例比其他用例更有创意，但到目前为止我们还没有遇到任何问题，”斯托尼尔说。也许这是因为，正如她所指出的，“公司中的每个人现在都更加了解并参与数字化工作，他们将治理视为每个人工作的一部分。”</p><p>我们认为，几乎每家公司都应该对其高级管理人员和董事会成员进行有关生成式人工智能的教育，而万事达卡在这方面的表现正如预料的那样积极。它为高级管理团队和董事会成员举行了多次会议，讨论该技术的不同方面，包括其提供的机会、其所需的监管以及公司在实施该技术时应遵循的流程。许多外部专家参加了这些简报会，斯托尼尔指出，有几位精通技术的董事会成员已经非常了解这项技术。</p><p>万事达卡成立了一个由来自各个业务领域的人工智能领导者组成的委员会，该委员会在部署人工智能用例之前对其进行评估，并且在经过审查的用例中添加了生成式人工智能用例。迄今为止开发的一些用例涉及欺诈检测、内部知识管理和个性化等领域。更多用例正处于实验阶段，尚未用于生产部署。</p><p></p><p>尽管美国尚未发布针对生成式人工智能的详细政府政策，但斯托尼尔表示，很明显，针对生成式人工智能的许多不同功能将会有不同的政策。例如，由于万事达卡严重依赖可靠的信息系统，因此使用生成式人工智能开发编程代码将与使用它来创建营销文案受到不同的对待。</p><p>很明显，万事达卡需要采用跨学科和跨职能的方法来管理生成人工智能。律师、人力资源专业人员、系统和数据工程师以及架构师已经开始参与开发公司的技术方法。随着用例变得更加以客户为导向（现在主要是内部用例），组织的更多部分可能会参与其中。外部监管机构将希望了解该公司如何构建“黑匣子”模型，其中模型所基于的逻辑和数据源对用户来说不容易可见。斯托尼尔表示，考虑到所涉及的组织的所有可能的用例和方面，生成式人工智能的治理是一个挑战。她预计，与之前的人工智能开发流程一致，治理不仅要解决该技术的用户试图实现的目标，还要解决最可能的结果是什么。</p><h3>仍在发展中的事情</h3><p>斯托尼尔表示，生成式人工智能的许多方面仍在讨论中，这是理所应当的。对于公司及其员工来说，这是一段试验时期，斯托尼尔指出，只要遵循<a href="https://www.mastercard.us/en-us/vision/corp-responsibility/data-responsibility.html">公司的数据责任原则，</a>就没有人愿意阻止它。万事达卡希望利用生成式人工智能作为学习的机会，并最终从中受益，就像在减少欺诈和网络安全举措中从传统人工智能中获得的收益一样。</p><p>目前，实现的主要好处是公司自身流程的内部生产力提高。万事达卡客户（包括接受万事达卡的商家）的用例将在稍后提供。未来有可能为客户提供高度个性化的数据分析和消息。</p><p>万事达卡已经拥有一套明确的流程来推出数据和数据产品，甚至还有一个业务部门（汤姆几年前<a href="https://www.forbes.com/sites/tomdavenport/2021/01/13/data-exhaust-turbocharges-mastercard/?sh=451638f887df">写过的</a>数据与服务）来将它们提供给客户。斯托尼尔认为，数据与服务以及公司的网络与智能业务将是未来最有可能实施基于生成式人工智能的产品，从而丰富现有的人工智能解决方案。她相信这些生成式人工智能的使用将采用多种类型的语言模型，并且它们将在循环中广泛使用人类，也许是通过人类反馈的强化学习。她说，将会进行广泛的测试，以确保产品中不存在实质性的幻觉或其他有问题的输出。我们认为这很重要；如果机器学习就像类固醇的分析，那么生成式人工智能就像迷幻剂的机器学习。这抓住了该技术不可预测的方面。</p><p>生成式人工智能模型的具体架构也尚未确定。斯托尼尔认为肯定会有多个模型，但她不确定它们是否会堆叠在一起（组合为一个用例）或排列起来，由前端系统确定哪个模型最适合上下文。</p><p></p><p>我们询问斯托尼尔，她是否认为生成式人工智能是一种增量技术或具有巨大变革性的技术。 “到目前为止，它是渐进式的，但最终可能会带来变革，”她说。 “但任何转变都不会是一个大爆炸时刻——它会随着时间的推移而发生。运营效率的提升会相对较快，但产品和服务的改变则需要更长的时间。”</p><p>如果您的公司正在努力解决如何治理和充分利用生成式人工智能的问题，那么万事达卡的经验应该会让您感到更加轻松。这项技术可能会也可能不会改变您的业务，但它肯定会带来许多新问题和机遇。它们并不需要一夜之间就全部弄清楚。</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/generative-ai-at-mastercard-governance-takes-center-stage/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>保护社会免受人工智能危害：国际特赦组织的 Matt Mahmoudi 和 Damini Satija（第 1 部分）</title><link/> https://sloanreview.mit.edu/audio/protecting-society-from-ai-harms-amnesty-internationals-matt-mahmoudi-and-damini-satija-part-1/<comments> https://sloanreview.mit.edu/audio/protecting-society-from-ai-harms-amnesty-internationals-matt-mahmoudi-and-damini-satija-part-1/#respond</comments><pubDate> Tue, 29 Aug 2023 11:00:47 +0000</pubDate> <dc:creator><![CDATA[Sam Ransbotham and Shervin Khodabandeh. <p>Sam Ransbotham ( <a href="https://twitter.com/ransbotham">@ransbotham</a> ) 是波士顿学院卡罗尔管理学院信息系统系教授，也是<cite>《麻省理工学院斯隆管理评论</cite>》人工智能和商业战略大创意计划的客座编辑。 Shervin Khodabandeh 是 BCG 的高级合伙人兼董事总经理，也是北美 BCG GAMMA（BCG 人工智能业务）的联合领导者。您可以通过<a href="mailto:shervin@bcg.com">shervin@bcg.com</a>联系他。</p><p class="mt20"> <cite>《我、我自己和人工智能》</cite>是<cite>麻省理工学院斯隆管理评论</cite>和波士顿咨询集团合作推出的播客，由 Sam Ransbotham 和 Shervin Khodabandeh 主持。我们的工程师是 David Lishansky，协调制作人是 Allison Ryder 和 Sophie Rüdinger。</p> ]]>; </dc:creator><category><![CDATA[Ethics]]></category><category><![CDATA[Information Sharing]]></category><category><![CDATA[Public Policy]]></category><category><![CDATA[Social Justice]]></category><category><![CDATA[Data, AI, & Machine Learning]]></category><category><![CDATA[Equality]]></category><category><![CDATA[Managing Technology]]></category><category><![CDATA[Security & Privacy]]></category><category><![CDATA[Social Responsibility]]></category><category><![CDATA[Artificial Intelligence and Business Strategy]]></category><description><![CDATA[Amnesty International brings together more than 10 million staff members and volunteers worldwide to advocate for social justice. Damini Satija and Matt Mahmoudi work with Amnesty Tech, a division of the human rights organization that focuses on the role of government, Big Tech, and technologies like artificial intelligence in areas like surveillance, discrimination, and bias. [&#8230;]]]></description><content:encoded><![CDATA[<p></p><p>国际特赦组织汇集了全球超过 1000 万员工和志愿者，致力于倡导社会正义。达米尼·萨蒂亚 (Damini Satija) 和马特·马哈茂迪 (Matt Mahmoudi) 与国际特赦组织合作，该组织是人权组织的一个部门，专注于政府、大型科技公司以及人工智能等技术在监视、歧视和偏见等领域的作用。</p><p>在本期<cite>“我、我自己和人工智能</cite>”播客中，马特和达米尼与主持人 Sam Ransbotham 和 Shervin Khodabandeh 一起重点介绍了人工智能工具可能使人权面临风险的场景，例如当政府和公共部门机构使用面部识别系统时跟踪社会活动家或算法，以做出有关公共住房使用和儿童福利的自动决策。达米尼和马特警告说，人工智能技术无法解决偏见、歧视和不平等等人类问题；这将需要人为干预和公共政策的改变。</p><p>有关组织可以采取哪些措施来应对因使用自动化技术而产生的意外负面后果的更多信息，请收看我们与 Matt 和 Damini 对话的下一集，即 2023 年 9 月 13 日播出的第二部分。 </p><aside class="callout-info"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/07/MMAI-S7-E7-E8-Mahmoudi-Satija-Amnesty-International-headshot-3000-scaled.jpg" alt="马特·马哈茂迪和达米尼·萨蒂亚"></p><h4>国际特赦组织的马特·马哈茂迪和达米尼·萨蒂亚</h4><p>马特·马哈茂迪 (Matt Mahmoudi) 是一名讲师、研究员和组织者。他一直在领导国际特赦组织的研究和宣传工作，禁止面部识别技术，并揭露从纽约市到巴勒斯坦被占领土的种族化社区使用这些技术的情况。他是乔·考克斯博士学位的首任获得者。 scholarship at the University of Cambridge, where he studied digital urban infrastructures as new frontiers for racial capitalism and remains an affiliated lecturer in sociology. His work has appeared in the journals <cite>The Sociological Review</cite> and <cite>International Political Sociology</cite> and the book <cite>Digital Witness</cite> (Oxford University Press, 2020). His forthcoming book is <cite>Migrants in the Digital Periphery: New Urban Frontiers of Control</cite> (University of California Press, 2023).</p><p> Damini Satija is a human rights and public policy expert working on data and artificial intelligence, with a focus on algorithmic discrimination, welfare automation, government surveillance, and tech equity. She is head of the Algorithmic Accountability Lab and a deputy director at Amnesty Tech. She previously worked as an adviser to the UK government on data and AI ethics and represented the UK as a policy expert on AI and human rights at the Council of Europe. She has a master&#39;s degree in public administration from Columbia University&#39;s School of International and Public Affairs.</p></aside><aside class="callout-info fl mobile-fn mt40"><h5> AI for Leaders on LinkedIn<br /></h5><p style="font-size:1.4rem;"> If you&#39;re enjoying the <cite>Me, Myself, and AI</cite> podcast, continue the conversation with us on LinkedIn. Join the <a href="https://www.linkedin.com/groups/13977401/" class="marketing-click" id="AI_for_leaders_link[MMAI]">AI for Leaders</a> group today.</p><p class="is-button mt20"> <a href="https://www.linkedin.com/groups/13977401/" class="marketing-click" id="AI_for_leaders_link[MMAI]">Join now »</a></p></aside><p> Subscribe to <cite>Me, Myself, and AI</cite> on <a href="https://podcasts.apple.com/us/podcast/me-myself-and-ai/id1533115958">Apple Podcasts</a> , <a href="https://open.spotify.com/show/7ysPBcYtOPVgI6W5an6lup">Spotify</a> , or <a href="https://podcasts.google.com/feed/aHR0cHM6Ly9tZW15c2VsZmFuZGFpLmxpYnN5bi5jb20vcnNz">Google Podcasts</a> .</p><h4> Transcript</h4><p> <strong>Shervin Khodabandeh:</strong> Many of our guests aim to use AI for good in their organizations. On today&#39;s episode, we speak with two researchers who focus on protecting human rights when artificial intelligence tools are used.</p><p> <strong>Damini Satija:</strong> I&#39;m Damini Satija …</p><p> <strong>Matt Mahmoudi:</strong> … and I&#39;m Matt Mahmoudi from Amnesty International …</p><p> <strong>Damini Satija:</strong> … and you&#39;re listening to <cite>Me, Myself, and AI</cite> .</p><p> <strong>Sam Ransbotham:</strong> Welcome to <cite>Me, Myself, and AI</cite> , a podcast on artificial intelligence in business. Each episode, we introduce you to someone innovating with AI. I&#39;m Sam Ransbotham, professor of analytics at Boston College. I&#39;m also the AI and business strategy guest editor at <cite>MIT Sloan Management Review</cite> .</p><p> <strong>Shervin Khodabandeh:</strong> And I&#39;m Shervin Khodabandeh, senior partner with BCG and one of the leaders of our AI business. Together, <cite>MIT SMR</cite> and BCG have been researching and publishing on AI since 2017, interviewing hundreds of practitioners and surveying thousands of companies on what it takes to build and to deploy and scale AI capabilities and really transform the way organizations operate.</p><p> Welcome. Today, Sam and I are excited to be talking with Matt Mahmoudi and Damini Satija from Amnesty International. Matt, Damini, thanks for joining us today.让我们开始吧。 Matt, tell us a little bit about your role at Amnesty.</p><p> <strong>Matt Mahmoudi:</strong> Absolutely. And, yeah, thanks so much for having us. I am an adviser and researcher on artificial intelligence and human rights at Amnesty&#39;s tech program. My role has been focusing on how certain AI technologies and, in particular, AI-driven surveillance are taken up by policing agencies [and] developed by companies, ostensibly for efficiency but often leading to discriminatory outcomes, inequalities of various forms, and affecting some of the most historically marginalized communities. So over the past couple of years in particular, I&#39;ve been tracing facial recognition deployments, the companies involved, as well as where police are using the tools.</p><p> We&#39;ve looked at facial recognition in places such as New York City, Hyderabad City in India, and the occupied Palestinian territories and [are] really paying attention to the ways in which these technologies that promised greater efficiency and promised to be sort of smarter ways of moving people from A to B or ensuring their safety are actually leading to the erosion of their rights.</p><p> <strong>Sam Ransbotham:</strong> Matt, tell us a little bit about what Amnesty International does, what the structure is, [and] how [its] technology practices got started.</p><p> <strong>Matt Mahmoudi:</strong> Amnesty International is a movement of over 10 million people worldwide who work together via, for example, volunteering or through doing research and advocacy and campaigning to mobilize around key human rights issues of the day.</p><p> As far as the technology and human rights program is concerned, also known as Amnesty Tech, we&#39;re a collective of technologists, researchers, advocates, legal scholars, and more who work together on trying to hold both companies and states to account on their usage and development of technologies that really put those fundamental human rights at risk. So our work is to investigate and expose the ways in which those configurations of technologies are being used to erode those rights and, where possible, to advocate for stronger safeguards and regulations and human rights practices that enable us to enjoy those rights even as we continue to live through a rapidly changing world.</p><p> <strong>Shervin Khodabandeh:</strong> Damini, tell us a little bit about what the Algorithmic Accountability Lab does.</p><p> <strong>Damini Satija:</strong> Yeah, thank you so much for having us here today. I work in the tech program, and I head up a team called the Algorithmic Accountability Lab, a relatively new team within Amnesty Tech. We look specifically at the increasing use of automation and AI technologies in the public sector and, within that, specifically in welfare contexts and social protection contexts. So we look at how governments and public-sector agencies are using automation to determine who gets access to basic essential services like housing, education, health care benefits, and so on. And our particular interest is in investigating and understanding how these tools have discriminatory impact or disproportionate impact on already marginalized groups, which is something we&#39;ve already seen evidence of in public sector automation or automation of welfare.</p><p> And the team itself is a multidisciplinary team of seven individuals: data scientists, human rights researchers, advocacy, legal expertise — a whole range … to support the vision that we will take a holistic view in interrogating and understanding these systems&#39; impacts on society.</p><p> <strong>Shervin Khodabandeh:</strong> Thank you for that. This is quite interesting, Sam, because when most of our guests are talking to us about how they use AI, [it&#39;s] to create more profits or more revenues or reduce costs or do good, but generally, right? It seems like your role is to make sure we don&#39;t do bad stuff with AI, right?</p><p> And so in that context, given your background and expertise in AI, what do you think some of the guiding principles are, and how is it different? Like, when you&#39;re looking for bad actors, I have to imagine that it&#39;s fundamentally a bit different than looking to do good. I&#39;m going to start with you, Matt. How do you go about doing this?</p><p> <strong>Matt Mahmoudi:</strong> Well, oftentimes, we learn about some cases involving a particular person that has faced a form of discrimination. In the context of New York City, for example, we were put in touch with an activist called Derrick Ingram, who has founded a collective known as the Warriors in the Garden but was also a prominent activist within the Black Lives Matter community. And he had been subject to harassment [by the police], who showed up at his doorstep and effectively harassed him for four hours for something that he didn&#39;t realize he&#39;d done and, really, there was no clear answer to why they were there.</p><p> And as it turns out, given the presence of certain journalists around his home as he was being harassed, they figured out that the police had printed out a facial recognition identification report, which was present at the scene — which then, [it] turns out, had identified him as one of the only protestors identifiable at the particular protest, which was a Black Lives Matter protest protesting the murder of George Floyd. And in this context, we found out that, really, the police had simply identified this one prominent protestor with a megaphone and, as a result of being able to identify him, saw it as within their remit, even without a warrant, to show up at his door and try to question him and try to harass him.</p><p> The police eventually went on to come up with sort of a bogus charge in which they accused him of holding a megaphone too closely to an officer&#39;s ear, but this was all happening all the while Amnesty was investigating what other community members the NYPD had been targeting with this software and who was developing [and] providing the software that they were using. And the NYPD was not particularly forthcoming.</p><p> So our work has usually revolved around both conventional approaches, such as Freedom of Information Act requests or <a href=" https://opengovernment.ny.gov/freedom-information-law">Freedom of Information Law</a> requests, but it has also involved using, for example, Google Street View imagery to tag cameras that are run by the NYPD to give us a sense of how widely exposed New Yorkers, for example, are to network camera systems and, in particular, network camera systems with facial recognition. And that gives you a sense of how widely spread the risk is.</p><p> <strong>Sam Ransbotham:</strong> So something that bothers me when people talk about artificial intelligence is this tendency, I think, to use anthropomorphic language. It&#39;s tempting to use phrases like “AI does X” or “AI does Y,” and it&#39;s striking already [that] in talking to you both, neither of you has used <em>AI</em> as an actor. It&#39;s a tool, and you seem to be very focused on who&#39;s the actor. So the difficult thing there is that if a tool can amplify good and amplify bad, how do we promote a message to the actual actors? How do you get actors to use a tool that <em>can</em> be used for good and <em>can</em> be used for bad, to use it for good or bad? And even good or bad is tough to draw a line between.</p><p> <strong>Damini Satija:</strong> Yeah, and if I could use that to also piggyback to an earlier question where you asked about bad actors, I think that&#39;s very revealing in itself because we are very focused on the actor, and it&#39;s not just the AI. It&#39;s also who has designed the AI, the way the AI&#39;s been designed, who&#39;s deploying it, what context it&#39;s being deployed in. And we have to be really careful not to focus on what is wrong with the AI because then that can also lead us down the trap of “There is a technical fix to this problem.”</p><p> But often, the artificial intelligence tools we&#39;re looking at are also operationalizing a certain environment that we&#39;re concerned with, right? So, for instance, if we&#39;re looking at a tool being used in an immigration context, and the prevailing narrative is xenophobic or anti-immigrant, it will operationalize policies that fit into that category. So it very much is not just only about the technology, as you&#39;re saying, but also about the environment in which these are being developed, procured, and deployed.</p><p> And so that means that we&#39;re not always looking at bad <em>actors</em> as such, but bad use, to put it very simply. But I think that is just as much a guiding factor for us in looking for the cases we need to investigate, as is also, as Matt said, looking for discriminatory impact. I think another example that springs to mind here where a tool wasn&#39;t deployed specifically for negative consequence but it ended up having a negative consequence is a <a href=" https://www.codastory.com/authoritarian-tech/san-francisco-homeless-algorithm">case of a housing algorithm</a> that was used in San Francisco. And there was a story out on this a year or so ago.</p><p> There was a tool that was developed for social workers to use in allocating public housing. And the intent behind developing that tool was to provide something that allows social workers to have a more informed conversation with the individuals they&#39;re working with who need housing assistance. And the tool specifically would help them build a sort of vulnerability or risk assessment of the person to then determine how much housing assistance they needed. That tool was meant to help facilitate conversations. The way it was used, [however,] social workers were making yes and no decisions based on what the tool was spitting out on who should get housing assistance and who shouldn&#39;t.</p><p> So that … I mean you could argue that&#39;s bad use, but it&#39;s also kind of unintended use of the tool. So there are all kinds of realities that we&#39;re looking at that aren&#39;t as easy — it&#39;s just never easy to say that the issue is in the AI itself, which doesn&#39;t answer your original question but was some context that I wanted to add on the kind of bad actors question.</p><p> <strong>Shervin Khodabandeh:</strong> It also highlights what you&#39;re saying — the criticality of AI and human [interaction], and not just one versus the other, or one <em>or</em> the other. Because in all of these examples, there are examples of unintended or unanticipated use, or maybe because of lack of training, or where the underlying narrative isn&#39;t that you start with intending to do harm; you just did not know or you did not anticipate that “Oh, I&#39;m supposed to just use it as an input versus as an indication.”</p><p> The one question I have … you alluded to it, but you went in a different direction than I thought you were going to go, because you said, “We&#39;re not talking about what&#39;s wrong with the technology, because the implication would be there&#39;s a technological fix.” But I&#39;d like to challenge that because why wouldn&#39;t part of the fix, at least, be technological?</p><p> <strong>Damini Satija:</strong> Yes, there are technical fixes when it comes to bias, and there are people out there who&#39;ve put out ways of de-biasing tools. I think the reason we don&#39;t want to be completely confined to that is because of what I outlined — that we need to take a more holistic approach to understanding these technologies&#39; impacts because, as we say, it&#39;s not only about the way the tool is designed, although, yes, that is really important as well. It&#39;s also about the human interaction with the tools and how humans use them.</p><p> And I think the other problem is that the technical-fix route can make us take a very siloed approach to what the problem is. So, for instance, in the AI ethics algorithmic fairness world, there&#39;ve been a lot of de-biasing solutions put forward, and that implies that bias, in a very technical way within the algorithmic or AI system, is the only problem. But I think it&#39;s very possible that we could solve that from a technical perspective, but there are still myriad other problems with the tools that we&#39;re looking at. A, they can still be used in discriminatory ways, even if there&#39;s been a technical fix. There are surveillance concerns; these are data-intensive technologies.</p><p> We also worry often about sort of second- and third-order impacts of what these technologies incur. So, for instance, to take the housing example again, if a tool is used to deny someone housing or to deny someone access to Social Security benefits and then they&#39;re unable to pay rent or buy food for their family, those are effects that have happened two or three degrees of separation away from the tool, and it&#39;s still happening even if you reverse or take the algorithm out of the picture. That impact still exists and has still happened.</p><p> I think the emphasis, from our perspective, is maintaining that holistic understanding of the social consequences — political, economic — as well as technical. I don&#39;t know if Matt maybe wants to add anything on that.</p><p> <strong>Matt Mahmoudi:</strong> I&#39;d love to build on that a little bit further, in particular, because of the housing example and other examples like it. Also, risk indicator algorithms that are used by children&#39;s protective services in order to make determinations about whether to remove a child from foster care or even put them in foster care. Especially <a href=" https://www.technologyreview.com/2018/01/26/104816/algorithms-are-making-american-inequality-worse/">work by Virginia Eubanks</a> will outline how the social workers that are faced with this algorithm make determinations according to a light-based indicator that gives them sort of a red signal if it looks like there&#39;s been too many unsolicited reports of the child&#39;s welfare being in danger. And really, what that tells you is that the system in and of itself, the technology in and of itself, is not as easily fixed as, you know, to say, “Oh, well, then get rid of the indicators and turn them into more of a descriptive form of text.” Because what you&#39;re dealing with is a technology that extends far beyond the actual code itself, which is what Damini is getting to here as well. It&#39;s an entire sociotechnical system.</p><p> You can&#39;t hold that AI is a thing without also holding that there is human-computer interaction that gives animation to how that system functions and what it does. So, what is written in the code — I&#39;ve sort of taken the position — is somewhat irrelevant. What it does and what it ends up doing in the world, without using too much academic lingo here, but phenomenologically, is what really matters and what tells us about what the system actually is.</p><p> So by decentering ourselves from the notion that de-biasing is a virtue when it comes to AI technologies, and by decentering ourselves from the idea there&#39;s a technical fix from the system and instead holding that actually, these systems all ought to be tested and understood from what possible impacts they could have on society at large and on people&#39;s human rights before they&#39;re even entertained as being rolled out — that might lead us to the application and deployment of “better technologies.” As for how we can use technologies to identify certain <em>harmful</em> technologies: An example that I brought up before was how we were using street mapping tools to get a sense of where cameras were. Just to be clear, we didn&#39;t use an image recognition algorithm there. It was all people.</p><p> This allowed us to scale our volunteering efforts to some 7,500 people across the globe who helped us tag every intersection in New York City with cameras. That&#39;s a pretty, I think, compelling model for how you can scale activism and work that is moving the lever toward what might look like some form of justice and equity when it comes to technology, and certainly what an intervention that could promote greater respect for the right to protest might look like.</p><p> <strong>Shervin Khodabandeh:</strong> This is, I think … My point was about technology. It wasn&#39;t to say, “Let technology fix the problem it&#39;s created,” because the problem is created by the usage of it, as you said. And, of course, when you&#39;re talking about a powerful technology being used by institutions that have power to make policy, power to make law, power to make arrests or make war … of course the actor and the motivation of the actor and the use takes far more precedence [than] a technological fix. But I also have to believe that AI isn&#39;t going anywhere and the technology will only get improved.</p><p> And so I wonder … all of the deficiencies that your teams are finding, in terms of … I mean, in your example, you did not rely on image recognition to identify cameras, because you thought humans would be more accurate. Well, that is feedback to the algorithms and to the instrumentation that does image recognition. And in the example, Damini, that you talked about with housing, I wonder if there could be safeguards or additional prompts or additional data feeds that would actually make it almost impossible for that technology that was making the choice on what to do for a human to rely on the technological choice. So I must believe that as users and as agencies that are monitoring the use, that there is some feedback to the developer community that is building these tools. Not to say bias is the central problem, but that … I mean, you&#39;ve highlighted so many different areas where technological artifacts could help advance the very cause that you&#39;re talking about.</p><p> <strong>Damini Satija:</strong> Yeah. I mean, in terms of safeguards, there are many we could go into in terms of what we call for as a human rights community in regulation. I think Matt has already alluded to the No. 1 safeguard, which is clear questioning at the outset in the very conceptualization of these technologies as to whether they are required and whether automation is actually necessary in a certain context, and in doing that interrogating and scrutinizing, what that rights-violating or disproportionate impact could be of this technology. And I think in doing that, and what comes up for us again and again in our work is, which voices are being heard? Whose articulation of problems that need to be solved using technology are heard in that conceptualization phase?</p><p> And what we&#39;re often up against in our work is that there are certain sets of pretty powerful voices, which you&#39;ve just mentioned yourself as well. You know, policy makers, big technology companies, those who have funding to develop new technology, those who are funding new technology. Those who have the power to really dictate the trajectory of AI are the ones whose voices are also heard in what AI is being developed and then deployed, whereas those who are then impacted by the use of these systems, and especially the communities that we look at, often say … We&#39;ve mentioned racialized impacts. Often, Black and Brown communities are really negatively impacted and harmed by these systems. Those are not the voices that are then feeding into what the problems are that need to be solved through this technology, which, as you say, is here and the development of AI is happening very quickly. But it&#39;s that power imbalance that really concerns us in terms of whose voice is being heard [and] what should be conceptualized. And that is an intangible safeguard but a very, very important one for us in our work.</p><p> <strong>Shervin Khodabandeh:</strong> Very well said.</p><p> <strong>Sam Ransbotham:</strong> It&#39;s interesting you mentioned the social work example. My mother was a social worker and in [the] foster care [field]. And that is a highly understaffed, overworked world. And so when you gave that example, I have to say, part of me still finds it appealing that we could help those people improve. It may not be perfectly correct, it may not perfectly do prediction, but given so much of what else goes on, it may be a better solution. So how do we get a better solution in place without opening up this Pandora&#39;s box of difficulties to a point that we can improve it and can get experience over time? How does that happen?</p><p> <strong>Matt Mahmoudi:</strong> So if I could jump in here, Sam, I think staying with the social worker example and just staying with a particular program that Virginia Eubanks looks at, it&#39;s an interesting one because the state ends up spending more money on trying to hold up a failed technology than it would have spent just trying to equip the social workers with more resources, to be able to hire more social workers to be able to carry out their work more adequately and in line with the demand.</p><p> So I think, just drawing from the page of a piece of reading that I like to always assign to a class I&#39;m teaching on science and technology studies, which is sort of a drawing from Chellis Glendinning&#39;s “ <a href=" https://theanarchistlibrary.org/library/chellis-glendinning-notes-toward-a-neo-luddite-manifesto">Notes Toward a Neo-Luddite Manifesto</a> ,” I will say I&#39;m not anti-technology, and neo-Luddites aren&#39;t either, and I think that&#39;s kind of the crucial point here: that, A, neo-Luddites aren&#39;t anti-technology; they&#39;re worried about the ways in which technology creates numbers out of people and leads toward a hyperrationality that takes out these important questions of harm.</p><p> And then, secondly — and this is a really important one — all technologies are political. We have to understand, what are the forms of politics and policies that are undergirding the particular deployment of a technology instead of, say, investing in the particular social programs that are required? So the kinds of examples that Damini has been bringing up all along and that we&#39;ve been talking through really show that there is an insistence on investing in the tool of technology under the auspices that it&#39;s going to lead to some cost saving in the future, when the reality is that oftentimes states end up having to spend much more money either trying to hold the companies to account on what they promised but couldn&#39;t deliver or facing lawsuits by individuals, whether they&#39;re class action suits or whatever, given the harms that they would&#39;ve incurred on people who have been subject to these mass forms of idealized technologies. Which I think goes to the point of, try and uncover what the politics that underlie it is and see if there is a social-political-economic fix that might actually be more sustainable than trying to get out of our way and go into this fantasy land of “AI will solve everything” — sort of technochauvinistic ideology that <a href=" https://www.publicbooks.org/letting-go-of-technochauvinism/">Meredith Broussard talks about</a> — and get away from that a little bit, and thinking about what kinds of investment our society needs outside of these technologies.</p><p> I think, importantly, with tools such as your GPT-based chatbot models and what have you, you&#39;re dealing with systems that appear to be in perpetual beta, and so they can constantly make the claim that they&#39;re not working the way they should just quite [yet] and they may have unintended consequences because they haven&#39;t crunched enough data or quite gotten the model right. And you can sit on that narrative for a very, very, very long time.</p><p> But the question is, when do we, as a civil society, and when do we, as people who form a constituency on lawmakers that can speak on our behalf and regulate on our behalf, pump the brakes and say, “No, these are products that are out in the open. They&#39;re having an impact, and, therefore, they should be subject to regulation.” It doesn&#39;t matter how large the language model is. It doesn&#39;t matter how much larger it needs to be to reach a saturation point at which it&#39;ll operate according to some prescribed fantasy of efficiency.</p><p> We have to get to a point — and that point, I think, was yesterday — in which we say, “We need regulation.” I think [the European Union&#39;s] AI Act, which Damini is working on extensively as well, is a really good first attempt at trying to create a regional-level legislation that has an understanding of the kinds of consequences we&#39;re dealing with and the kinds of impacts that these technologies can have on our rights and our ability to engage in the kinds of liberties that we have today.</p><p> <strong>Shervin Khodabandeh:</strong> Damini, Matt, thank you so much for a very enlightening discussion.</p><p> <strong>Damini Satija:</strong> Thank you.</p><p> <strong>Shervin Khodabandeh:</strong> Thanks for listening. Please join us next time, when we bring Matt and Damini back to continue the discussion about AI regulation, including what others can do to help limit harms stemming from the use of technology tools.</p><p> <strong>Allison Ryder:</strong> Thanks for listening to <cite>Me, Myself, and AI</cite> . We believe, like you, that the conversation about AI implementation doesn&#39;t start and stop with this podcast. That&#39;s why we&#39;ve created a group on LinkedIn specifically for listeners like you. It&#39;s called AI for Leaders, and if you join us, you can chat with show creators and hosts, ask your own questions, share your insights, and gain access to valuable resources about AI implementation from <cite>MIT SMR</cite> and BCG. You can access it by visiting <a href="https://mitsmr.com/AIforLeaders">mitsmr.com/AIforLeaders</a> . We&#39;ll put that link in the show notes, and we hope to see you there.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/audio/protecting-society-from-ai-harms-amnesty-internationals-matt-mahmoudi-and-damini-satija-part-1/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> Why the Power of Technology Rarely Goes to the People</title><link/> https://sloanreview.mit.edu/article/why-the-power-of-technology-rarely-goes-to-the-people/<comments> https://sloanreview.mit.edu/article/why-the-power-of-technology-rarely-goes-to-the-people/#respond</comments><pubDate> Mon, 28 Aug 2023 11:00:16 +0000</pubDate> <dc:creator><![CDATA[Daron Acemoglu and Simon Johnson, interviewed by Kaushik Viswanath. <p>Daron Acemoglu is an economist and an MIT Institute Professor, the university&#39;s highest faculty honor. Simon Johnson is the Kurtz Professor of Entrepreneurship at MIT and a former chief economist to the International Monetary Fund. They are the authors of <cite>Power and Progress: Our 1,000-Year Struggle Over Technology and Prosperity</cite> (PublicAffairs, 2023). Kaushik Viswanath is features editor at <cite>MIT Sloan Management Review</cite> .</p> ]]>;</dc:creator><category><![CDATA[Equity]]></category><category><![CDATA[Labor]]></category><category><![CDATA[Technology]]></category><category><![CDATA[Technology Implementation]]></category><category><![CDATA[Managing Technology]]></category><category><![CDATA[Technology Innovation Strategy]]></category><description><![CDATA[Taylor Callery/theispot.com In a new book, economists Daron Acemoglu and Simon Johnson provide a sweeping historical overview of just how unevenly the spoils and costs of technological change have been distributed. Power and Progress: Our 1,000-Year Struggle Over Technology and Prosperity reminds us that technology is not itself a force but rather a tool that [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/2023FALL-Acemoglu_1290x860.jpg" alt="" /><figcaption><p class="attribution"> Taylor Callery/theispot.com</p></figcaption></figure><p> In a new book, economists Daron Acemoglu and Simon Johnson provide a sweeping historical overview of just how unevenly the spoils and costs of technological change have been distributed. <cite>Power and Progress: Our 1,000-Year Struggle Over Technology and Prosperity</cite> reminds us that technology is not itself a force but rather a tool that is developed to support the agendas of the people and institutions who hold power in society. Claiming a fair share of technology&#39;s benefits for the rest of society — that is, for most of humanity — requires that that power be challenged. Acemoglu and Johnson chatted with features editor Kaushik Viswanath about what lessons the past holds for how we should develop and implement technology today and in the future. This conversation has been edited for length and clarity.</p><p></p><h6> Kaushik Viswanath: What&#39;s the central argument you&#39;re making in <cite>Power and Progress</cite> , and what motivated you to write it?</h6><p> <strong>Daron Acemoglu:</strong> This is a critical time to be thinking about the future of technology. A lot of decisions of great import are being hampered by the fact that there is “techno-optimism” in academia, the tech world, and the policy world. Techno-optimism is the notion that impressive technological change will automatically lead to better outcomes for society, especially for workers via the labor market, even if there are some transition costs.</p><p> Our understanding of the relevant economic theory and history has led us to believe this isn&#39;t right. Throughout history, deliberate decisions have had a bearing on who gained and lost from a particular technology, whether it brought anything approaching shared prosperity, or even whether it helped or destroyed democracy. So our purpose in writing <cite>Power and Progress</cite> was to dispel the notion that in the history of technology, everything has always worked out OK. There are similar choices and struggles over technology today as we&#39;ve had in the past.</p><p></p><h6> One of the key concepts you discuss is the productivity bandwagon. What is this, and how does it create winners and losers whenever we have technological change?</h6><p> <strong>Simon Johnson:</strong> The productivity bandwagon is the notion that when technology improves, you get higher wages, more opportunity, and better health, and everybody gains from it eventually. Our key problem with that notion is the “eventually.” “Eventually,” from the beginning of the Industrial Revolution, was 120 years. The 1720s to the 1840s saw a lot of new technology, but we know that in the 1840s, children as young as 6 were still pushing coal carts deep underground with their heads. Conditions improved for more people in the second half of the 19th century but as a result of a lot of effort, not through any kind of automatic economic or political process.</p><p> <strong>Acemoglu:</strong> The perspective that Simon and I bring to the British Industrial Revolution is that it was really a revolution of vision. A new class of ambitious people emerged who wanted to apply technology to improve how people control their environment and the production process. They weren&#39;t doing it out of altruism; they were preoccupied with making money, wanted to rise within the British hierarchy, and didn&#39;t have much sympathy for the people who were below them in that hierarchy, whether in Britain or the rest of the world.</p><p> This is an illustration of what ambition does unless it is countered by institutions and other groups that have alternative visions of how society should be organized. It also illustrates the weaknesses of the productivity bandwagon. People were left behind in the early phases of the Industrial Revolution for two reasons. First, most of the technology was used for automation, not increasing workers&#39; productivity contributions. When technology displaces workers, it doesn&#39;t increase their contribution to production or create a powerful reason for employers to go out and pay higher wages to workers. Second, this was all embedded in an institutional setup, both because of the vision of the entrepreneurs and because trade unions were banned and heavily prosecuted, and Britain was very far from a democracy at the time.</p><p> The working class did not have any rights or protections. That&#39;s why, even as many people made fabulous amounts of money, workers&#39; real incomes stagnated or even declined. Sharing the gains of technology required a complete change in the institutional fabric of British society, which the elites and upper middle classes resisted. It required a change in the direction of technology, too — for example, it was necessary to invest in urban infrastructure to improve sanitation and bring infectious diseases under control. Until then, urban life was horrible for working people.</p><p></p><h6> Fast-forwarding to post-World War II in the US, you describe how this period saw a more equitable distribution of the productivity gains from technology. How did this happen?</h6><p> <strong>Acemoglu:</strong> That episode illustrates how the factors that worked against shared prosperity during the Industrial Revolution were turned in favor of shared prosperity in the 20th century, especially in the decades that followed World War II.</p><p> Its origins can be traced to the American system of manufacturing, because this was a key part of a general effort to make unskilled labor more productive using machinery. That, in turn, was critical for less-skilled workers to earn a high and rising wage. In this period, workers&#39; contributions to the production process could be bolstered by training. This was facilitated by a combination of technologies that didn&#39;t simply automate work but created new and more technical tasks, more maintenance tasks, and more advanced machining tasks for workers. And it was in the context of institutions that provided countervailing powers to the most powerful firms — in particular, a secure democracy by historical standards, a labor movement that had become much stronger after the New Deal and during World War II, and a supportive regulatory environment by the US government that encouraged technological change but also brought limits to what the largest companies could do, for example, through antitrust enforcement.</p><h6> You also write that the US labor movement during this period actually encouraged the mechanization of the industries in which they worked. Why did they do this?</h6><p> <strong>Johnson:</strong> The key was in their insistence that their workers get trained to use the machines. They realized that mechanization was coming whether they liked it or not. They couldn&#39;t simply ask for higher wages, because that would lead to more automation. So [labor unions] asked for their workers to acquire the necessary skills and be compensated appropriately. Unions are much weaker today, so that kind of countervailing power is missing, which means the benefits of automation will go to whoever has social power — which means relatively few people.</p><p> <strong>Acemoglu:</strong> We are not against automation. Blocking automation would not just be infeasible, but to the extent that it&#39;s tried, would be hugely costly. In its best moments, the labor movement, both in the United States and in Europe, encouraged the introduction of advanced automated machinery but at the same time negotiated the creation of better, more advanced tasks for workers to operate and inspect these machines. Where workers didn&#39;t have those skills, employers would have to train them. So it was the combination of new tasks and training that unions advocated for. Today the question is, can we still encourage the right type of automation?</p><p></p><h6> What is the role of business leaders in determining the direction of technological advancement and distributing its gains?</h6><p> <strong>Acemoglu:</strong> The future of technology is inseparable from the vision of powerful actors. It&#39;s not something we can all democratically vote on. The same is true of how CEOs decide to split profits between different stakeholders. Do they see labor as one of those stakeholders? That is a question that is entangled with the future of technology.</p><p> Over time, business leaders have shifted toward just serving the interests of the shareholders. Labor is viewed as troublesome and costly, so they try to eliminate it as much as possible. And that has synergized with the vision of the tech community to develop machines that can automate as much as possible.</p><p> But nothing in the laws of capitalism makes that necessary. During other periods, in other contexts, businesses have prioritized increasing worker productivity. They have found ways of rewarding their shareholders while giving raises to their workers when the company is doing well, and investing in technologies that increase worker productivity. A new vision among business leaders would be feasible and highly useful for the kinds of futures of work that we&#39;re talking about. But that won&#39;t emerge by itself. It will require pressure from institutions, civil society, and the media, as well as some amount of organized labor.</p><h6> You describe how the doctrine of maximizing shareholder value became consensus in management schools and then management consultancies, ending an era of widely shared gains from technology. Do you see that changing?</h6><p> <strong>Acemoglu:</strong> I have a <a href="https://www.nber.org/papers/w29874">paper with Alex He and Daniel le Maire</a> where we find that CEOs with business degrees from the top MBA programs in the United States don&#39;t increase productivity, exports, or investment, but they reduce wage growth and labor share. But the CEOs in our sample are all from the 1970s, &#39;80s, and &#39;90s. Today, the same schools have a somewhat different air. Students seem to care much more about broader aspects of business. Faculty don&#39;t just talk about increasing shareholder value and creating lean corporations by eliminating labor. So I already sense some change in that direction. How effective it is, we don&#39;t know yet.</p><p> <strong>Johnson:</strong> There&#39;s a lot more progress to be made. The curriculum and the core ideas that are imprinted on students still lean a lot more toward <a href="https://sloanreview.mit.edu/strategy-forum/has-strategic-management-overlooked-the-role-of-purpose-what-experts-say/">Milton Friedman</a> than toward Acemoglu-Johnson or any other view.</p><p> If you consider the pressure from financial markets and look at the language used by analysts, it reinforces that narrow view, which is, I think, not ultimately good for business.</p><h6> Turning to the tech that&#39;s on everyone&#39;s minds these days: Where do you think AI — and generative AI, specifically — is headed?</h6><p> <strong>Acemoglu:</strong> These are phenomenally interesting and impressive technologies. That only raises the stakes of getting the direction of this technology right and setting up the right regulatory structure.</p><p> But the two polar views that are most loudly heard in the media are both unhelpful: On one end are techno-optimists, who say, “Everybody will benefit. Yes, a few people might lose their jobs. But you&#39;ll get more massage therapists, even if you don&#39;t have enough white-collar workers.” On the other end is the view that killer robots are coming and we have to worry about existential risk.</p><p> Neither of these views addresses the right concerns. AI can do a lot to help workers and society. It could go along the lines of the platforms that Taiwan introduced, for example, to facilitate more democratic participation; those have worked reasonably well. Or it can go in the direction of automation that deepens inequalities, delivers more misinformation, disinformation, manipulation of users — what we&#39;ve seen with social media, especially platforms like Facebook.</p><p> We really worry about that direction, and that&#39;s where our leaders are asleep at the wheel. Society is not worrying enough about these things. There isn&#39;t even the right set of aspirations that have been articulated about what we should want from this technology.</p><p> <strong>Johnson:</strong> I&#39;ve heard the view that people are complaining now because it&#39;s cognitive tasks that are being replaced by a machine, whereas before it was manual work. What we say in our book is that what&#39;s actually vulnerable here are all routine cognitive tasks. Wendy&#39;s, for example, has said it&#39;s going to use chatbots to take orders at drive-throughs. They&#39;ll still use humans to flip the burgers. Is your ordering of a burger going to be any better with this machine? Are they going to be paying the burger flipper any more money? No, they&#39;re just doing this so they can have fewer workers.</p><p></p><p> We call it <em>so-so automation</em> . It&#39;s a way to tilt power against the workers. You&#39;re replacing people who are quirky and sometimes difficult to manage with machines that are designed for mediocrity. Where&#39;s the productivity breakthrough? Where&#39;s the big positive benefit?</p><p> <strong>Acemoglu:</strong> In productivity revolutions of the past, like at the Ford Motor Company, automation was critical, but only when combined with new products, new tasks, new ways of using machinery, new creativity. The Ford factory would not have done anything of note if it took exactly the cars that other companies were producing and made them with a bit more automation.</p><p> This is why we prefer to emphasize machine usefulness rather than machine intelligence. We should be using machines to make humans better. Generative AI is so promising because it has that capability. It could help with the retrieval and filtering of information so that human decision makers make better decisions. But that&#39;s very different from automating a few more McDonald&#39;s kiosks.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/why-the-power-of-technology-rarely-goes-to-the-people/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> How to Deliver Career Development for All</title><link/> https://sloanreview.mit.edu/article/how-to-deliver-career-development-for-all/<comments> https://sloanreview.mit.edu/article/how-to-deliver-career-development-for-all/#respond</comments><pubDate> Thu, 24 Aug 2023 11:00:15 +0000</pubDate> <dc:creator><![CDATA[George Westerman and Tony Gigliotti. <p>George Westerman is a senior lecturer at the MIT Sloan School of Management and founder of MIT&#39;s Global Opportunity Forum (formerly known as the Global Opportunity Initiative). Tony Gigliotti is the senior director of talent management and organizational development at UPMC, a health care provider and insurer based in Pittsburgh.</p> ]]>; </dc:creator><category><![CDATA[Career Change]]></category><category><![CDATA[Talent Acquisition and Management]]></category><category><![CDATA[Talent Development]]></category><category><![CDATA[Leadership]]></category><category><![CDATA[Organizational Behavior]]></category><category><![CDATA[Talent Management]]></category><category><![CDATA[Workplace, Teams, & Culture]]></category><description><![CDATA[To be competitive in today’s tough labor markets, companies need to expand career development beyond those employees who are considered “high potential.” Helping all workers build rewarding job paths benefits both individuals and organizations. But broadening the reach of career development is not simple. Traditional development programs don’t easily scale, and most managers aren’t equipped [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/W23-QA05_1290x860.jpg" alt="" /><br /></figure><p> To be competitive in today&#39;s tough labor markets, companies need to expand career development beyond those employees who are considered “high potential.” Helping all workers build rewarding job paths benefits both individuals and organizations. But broadening the reach of career development is not simple. Traditional development programs don&#39;t easily scale, and most managers aren&#39;t equipped to be good career counselors.</p><p> Forward-leaning companies understand the imperative. During <a href="https://sloanreview.mit.edu/series/work-23-the-big-shift/">Work/23</a> , an <cite>MIT Sloan Management Review</cite> symposium held in May 2023, MIT Sloan&#39;s George Westerman noted that in a <a href="https://sloanreview.mit.edu/article/why-companies-should-help-every-employee-chart-a-career-path/">survey of 1,016 employees</a> , two-thirds said they want to advance — but “half of them said they were being held back by lack of good career advice.” A majority of those who changed jobs in 2021 cited a lack of advancement opportunities as the cause.</p><p></p><p></p><p> Westerman said managers can&#39;t be fully responsible for developing employees&#39; careers; many leaders don&#39;t want or know how to help, and many don&#39;t have the incentive to. But organizations shouldn&#39;t think that employees can completely own their career paths. “If you believe this story, then when an employee doesn&#39;t advance, you tend to blame the employee and not the system,” he said.</p><p> Instead, companies that are successfully broadening who gets career help are making opportunities and pathways visible, providing opportunities to learn and practice new skills, and delivering rich feedback and coaching. Providing autonomous routes to this information is especially important because not all employees have the psychological safety to discuss job options with their managers.</p><p> Lani Montoya, the chief human resources officer at Pernod Ricard North America and a presenter on the panel with Westerman, said that at the premium spirits and wine company, a global job-rating process allows all 18,500 employees to see positions at their level as well as above and below it. “They can see how teams are structured, and if they&#39;re interested in a role, they can see how it sits within what team,” she said.</p><p></p><p> Tony Gigliotti, the senior director of talent management and organizational development at UPMC, who was also on the panel, said that his organization is working toward similar transparency around career paths and job opportunities. The Pittsburgh-based health care provider and insurer has 95,000 employees in its hospitals and outpatient offices. A career resource site on UPMC&#39;s intranet offers access to assessments and skill-building opportunities, and a feature within its human capital management system shows job postings, job descriptions, and career paths within and outside an employee&#39;s job family.</p><p> “Now they have at their fingertips a lot of information,” Gigliotti said. “That will empower more employees.”</p><p> Below, Westerman and Gigliotti answer some of the questions from Work/23 attendees that they weren&#39;t able to get to during the event. (Questions and answers have been lightly edited for clarity.)</p><h6> How do you see career development working for employees who really enjoy their jobs, are individual contributors, and don&#39;t want to become managers?</h6><p> <strong>George Westerman:</strong> Many workers don&#39;t want to advance in their careers but can still benefit from development opportunities. Take teachers, for example. Very few want to become principals, but all can benefit from professional development opportunities. Most doctors may not want to move into management, but it&#39;s good for them (and their patients) that they engage in continuing medical education every year.</p><p> <strong>Tony Gigliotti:</strong> It is important to define career development beyond vertical promotion into leadership positions. Otherwise, a portion of your productive and reliable employee population might feel that they do not have opportunities for professional growth, and this may lead to their disengagement.</p><p> Our resources for leaders at UPMC take a more holistic approach to career development by referencing the many interventions that support professional growth and development. These include training and learning paths, mentoring, coaching, job enhancement/enrichment, stretch assignments, cross-functional work teams and committees, conferences, and community involvement.</p><p></p><p> Additionally, our talent-review programs normalize situations where solid performers are content in their current role. Part of that consideration must include the employees&#39; own intentions. In these cases, we explore ways to develop the employee in place.</p><p> Finally, we remind leaders that career aspirations can and often do change over time, so they must seek feedback and listen to their employees as their career needs and preferences evolve.</p><h6> What criteria work best when considering people for internal transfers for their career development? It seems like transfers could be a problem when the needs of the company and the needs of the individual conflict.</h6><p> <strong>Westerman:</strong> If you decide that the needs of the company outweigh an employee&#39;s desire to move to a new role, you&#39;re inviting them to leave the company. They&#39;ll move to another employer instead, leaving you without an employee and with less chance to conduct a smooth transition.</p><p></p><p> To encourage hiring from within, you may not need special criteria or incentives. Just make the opportunities known to internal candidates, and make the candidates known to the hiring manager. However, you can also try other changes to improve incentives, such as opening a position to internal candidates before listing it externally, or asking the manager to share in the costs of external hiring.</p><h6> How can companies manage talent hoarding and deal with managers who are resistant to sharing career paths openly?</h6><p> <strong>Gigliotti:</strong> There are several ways that our organization addresses leaders who hoard talent and do not focus on their employees&#39; career growth within the organization. Our organization transparently shares all career paths, including job descriptions, with all employees. So despite some leaders&#39; penchant for talent hoarding, employees still have access to the resources needed to understand their own (and others&#39;) career paths. This approach is consumer-driven — that is, our employees have expressed a need for this information so that they can navigate their own careers within the organization.</p><p></p><p> In addition, our organizational talent reviews are designed to identify emerging talent and ready-now talent. The outcomes from talent-review discussions across the organization are compiled and then transparently shared with HR leaders. This information empowers HR to identify potential internal talent who may be interested in and ready for available positions within the organization.</p><p> And growth is a key dimension in our employee engagement model. If a leader is not developing their employees, sharing career resources with them, or encouraging their career growth within the organization, then that leader&#39;s employee engagement scores (particularly in the growth dimension) will suffer. Low scores raise a red flag to that leader&#39;s supervisor and the local HR team, who then may intervene. Part of that intervention is to align the leader to our organizational values of responsibility and integrity, which, in part, expect leaders to “support their staff&#39;s … professional growth and development.”</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/how-to-deliver-career-development-for-all/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> Ask Sanyin: Why Can&#39;t We Get Meetings Right?</title><link/> https://sloanreview.mit.edu/article/ask-sanyin-why-cant-we-get-meetings-right/<comments> https://sloanreview.mit.edu/article/ask-sanyin-why-cant-we-get-meetings-right/#respond</comments><pubDate> Wed, 23 Aug 2023 11:00:36 +0000</pubDate> <dc:creator><![CDATA[Sanyin Siang. <p>Sanyin Siang is a CEO coach and leads the Fuqua/Coach K Center on Leadership &amp; Ethics (COLE) at Duke University. Need advice? Send an <a href="mailto:asksanyin@mit.edu">email to Sanyin</a> .</p> ]]>; </dc:creator><category><![CDATA[Employee Engagement]]></category><category><![CDATA[Leadership Advice]]></category><category><![CDATA[Leadership Development]]></category><category><![CDATA[Team Building]]></category><category><![CDATA[Trust]]></category><category><![CDATA[Leadership]]></category><category><![CDATA[Leadership Skills]]></category><category><![CDATA[Managing Your Career]]></category><description><![CDATA[As a senior leader in my company, I find meetings are crucial for keeping tabs on what’s going on and making decisions. But we seem to accomplish little, people are frequently unprepared, and they gripe about the time cost. How can I shift people’s attitudes and run more effective meetings? We’ve all been there: We [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/AskSanyin-featured-column4-1290x860-1.jpg" alt="" /><figcaption><p class="attribution"></figcaption></figure><p class="article-body-question"> As a senior leader in my company, I find meetings are crucial for keeping tabs on what&#39;s going on and making decisions. But we seem to accomplish little, people are frequently unprepared, and they gripe about the time cost. How can I shift people&#39;s attitudes and run more effective meetings?</p><p> We&#39;ve all been there: We sit through an hour of conversation, and somehow, there&#39;s less clarity at the end of the meeting than there was at the beginning. We walk out, lamenting the wasted time and lack of progress.</p><p> In an era of hyperproductivity, an endless list of to-do items, and personal exhaustion, your team probably sees meetings as an obstacle to getting back to their work rather than something purposeful. Shifting that attitude toward one of enthusiastic engagement means rethinking what you&#39;re trying to accomplish with meetings. With the widespread move to remote work, opportunities to engage with our teams in real time have become rarer and more valuable. How can we use this time to deepen relationships? What if we make trust-building a key aim of every type of meeting?</p><p></p><p> The decision-making meeting is usually about a commitment to a course of action. Here, you can also discuss the emotional consequences of the decisions for your people and the best ways to communicate a change. A deep discussion of these questions provides insight into others&#39; values and approaches.</p><p> Brainstorming and problem-solving meetings benefit enormously from explicit consideration of trust-building. Everyone needs to feel comfortable sharing their ideas while resisting the urge to judge. Here, you want to encourage vulnerability, because when we say “I don&#39;t know,” we acknowledge our limits and interdependencies within the greater team.</p><p> There&#39;s also an opportunity to transform the sometimes-routine information-sharing meeting into a richer venue for connection. Try setting the expectation that these are opportunities to learn more about one another&#39;s challenges and strategies, and encourage questions. These meetings also provide the opportunity to celebrate wins or invite help from another department. Use the time to help team members build connections with one another — a matrix — instead of hub-and-spoke connections with you at the center as the go-to problem solver.</p><p></p><p> Finally, try to include a time for collective reflection in a regular team meeting. Tarang Amin, CEO of elf Beauty, which posted 17 quarters of consecutive growth as of May 2023, begins every executive leadership team meeting with time for open sharing and reflection. “It&#39;s where execs can talk about what&#39;s going on in their personal lives, … their state of mind, what are important initiatives, what are things they&#39;re hearing in the organization,” he says.</p><p> Remember, it&#39;s typically not a lack of action items that hinders progress. It&#39;s more often misinterpretation of intent, misalignment of understanding, and the emotional toll of change that holds us back. And what solves those problems are trusting relationships that enable good communication. So instead of diving into the <em>what</em> of the next meeting you plan, begin with the <em>who</em> and the relationships among them. Your team just might rediscover the energy and joy that come with engaging with one another — and even begin to look forward to meetings.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/ask-sanyin-why-cant-we-get-meetings-right/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> Using Federated Machine Learning to Overcome the AI Scale Disadvantage</title><link/> https://sloanreview.mit.edu/article/using-federated-machine-learning-to-overcome-the-ai-scale-disadvantage/<comments> https://sloanreview.mit.edu/article/using-federated-machine-learning-to-overcome-the-ai-scale-disadvantage/#respond</comments><pubDate> Tue, 22 Aug 2023 11:00:10 +0000</pubDate> <dc:creator><![CDATA[Yannick Bammens and Paul Hünermund. <p>Yannick Bammens is professor of strategy and innovation at Hasselt University in Belgium, where he coleads the AI4Business initiative. Paul Hünermund is assistant professor of strategy and innovation at Copenhagen Business School in Denmark, where he co-organizes the yearly Causal Data Science Meeting.</p> ]]>; </dc:creator><category><![CDATA[AI]]></category><category><![CDATA[Big Data]]></category><category><![CDATA[Collaboration]]></category><category><![CDATA[Data & Analytics]]></category><category><![CDATA[Machine Learning]]></category><category><![CDATA[AI & Machine Learning]]></category><category><![CDATA[Data & Data Culture]]></category><category><![CDATA[Data, AI, & Machine Learning]]></category><description><![CDATA[Jing Jing Tsong/theispot.com Deep pockets, access to talent, and massive investments in computing infrastructure only partly explain why most major breakthroughs in artificial intelligence have come from a select group of Big Tech companies that includes Amazon, Google, and Microsoft. What sets the tech giants apart from the many other businesses seeking to gain an [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/2023FALL-Bammens_1290x860.jpg" alt="" /><figcaption><p class="attribution"> Jing Jing Tsong/theispot.com</p></figcaption></figure><p> Deep pockets, access to talent, and massive investments in computing infrastructure only partly explain why most major breakthroughs in artificial intelligence have come from a select group of Big Tech companies that includes Amazon, Google, and Microsoft. What sets the tech giants apart from the many other businesses seeking to gain an edge from AI are the vast amounts of data they collect as platform operators. Amazon alone processes millions of transactions each month on its platform. All of that big data is a rich strategic resource that can be used to develop and train complex machine learning algorithms — but it&#39;s a resource that is out of reach for most enterprises.</p><p> Access to big data allows for more sophisticated and better-performing AI and machine learning models, but many companies must make do with much smaller data sets. For smaller companies and those operating in traditional sectors like health care, manufacturing, or construction, a lack of data is the biggest impediment to venturing into AI. The digital divide between big and small-data organizations is a serious concern due to self-reinforcing data network effects, where more data leads to better AI tools, which help attract more customers who generate more data, and so forth. <a id="reflink1" class="reflink" href="#ref1">1</a> This gives bigger companies a strong competitive AI advantage, with small and midsize organizations struggling to keep up.</p><p></p><p> The idea of multiple small-scale companies pooling their data in a jointly controlled central repository has been around for a while, but concerns about data privacy may quash such initiatives. <a id="reflink2" class="reflink" href="#ref2">2</a> Federated machine learning (FedML) is a recent innovative technology that overcomes this problem by means of privacy-preserving collaborative AI that uses decentralized data. FedML might turn out to be a game changer in addressing the digital divide between companies with and without big data and enabling a larger part of the economy to reap the benefits of AI. It&#39;s a technology that doesn&#39;t just sound promising in theory — it has already been successfully implemented in industry, as we&#39;ll detail below. But first, we&#39;ll explain how it works.</p><h3> Small Data and Federated Machine Learning</h3><p> FedML is an approach that allows small-data organizations to train and use sophisticated machine learning models. The definition of <em>small data</em> depends on the complexity of the problem being addressed by AI. In pharma, for example, having access to a million annotated molecules for drug discovery is relatively small in view of the vast chemical space. Other factors to consider include the sophistication of the machine learning technique, ranging from a simple logistic regression to a much more data-hungry neural network, as well as the accuracy needed for an application: For some AI applications (such as making a medical diagnosis), getting things right is simply more critical than for others (such as suggesting emojis when someone is typing). All else being equal, smaller organizations and those operating in traditional nondigital sectors are confronted with more serious data-related scale disadvantages.</p><p></p><p> A few useful tactics and techniques have already been conceived to help companies struggling with this problem, such as cross-firm data pooling, transfer learning (repurposing previously trained models), and self-supervised learning (training a model on an artificial data set). <a id="reflink3" class="reflink" href="#ref3">3</a> Yet the centralized approach of data pooling may not be suitable in several situations, such as when there are legal constraints prohibiting data transfers or strategic concerns regarding sensitive data that should be kept private. Likewise, transfer learning and self-supervised learning are viable approaches only when a company can build on earlier insights from machine learning models performing tasks in related domains, which may not always be feasible. FedML can be a powerful extra instrument in a small-data company&#39;s AI toolkit and serve as a critical complement to other small-data techniques.</p><p> In a federated learning setup, a machine learning model is trained on multiple decentralized servers controlled by different organizations, each with its own local data. They communicate with a central orchestrator that aggregates the individual model updates and coordinates the training process. (See “An Overview of Federated Machine Learning.”) In the simplest case, the learning objective would be to obtain basic descriptive facts of the data distribution, such as means or variances. Each company could, for example, compute the average failure rate of a certain manufacturing process at one of its plants and submit it to the orchestrator, which would then combine those individual contributions to form a more accurate joint estimate.</p><div class="callout-highlight"><aside class="l-content-wrap"><article><h4> An Overview of Federated Machine Learning</h4><p class="caption"> In a federated learning setup, a machine learning model is trained on multiple decentralized servers controlled by different organizations, each with its own local data. They communicate with a central orchestrator that aggregates the individual model updates and coordinates the training process. </p><p><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/MAG_Bammens_Fig1.png" alt="An Overview of Federated Machine Learning" /><br /></article></aside></div><p></p><p> FedML is a distributed machine learning technique that can be used for a variety of algorithms. For example, the weights or gradients of a neural network can be averaged across organizations in a similar manner. The orchestrator is responsible for setting up the initial model architecture and coordinating the training process, which typically takes place over multiple iterations. As a result, companies can train complex machine learning models with a large number of parameters that would otherwise be beyond their reach, given that the constraints of their local data would lead to suboptimal model accuracy.</p><p> Importantly, raw company data stays private, and only statistical data, like estimated weights and other parameters, are shared and aggregated when FedML is applied. This way, 10 collaborating small-data companies that each have access to <em>x</em> data points could achieve roughly similar predictive power with their AI/machine learning applications as one much bigger company with access to 10 times <em>x</em> data points, without compromising data privacy.</p><h3> FedML in Pharma</h3><p> Innovation in pharma is very expensive and time consuming. The <a href="https://www2.deloitte.com/us/en/pages/about-deloitte/articles/press-releases/deloittes-thirteenth-annual-pharmaceutical-innovation-report-pharma-r-and-d-return-on-investment-falls-in-post-pandemic-market.html">average cost</a> to bring a new drug to market is around $2.3 billion as of 2022, and the process can take more than 10 years. One of the key difficulties in drug discovery involves the extremely high number of possible molecules (an order of magnitude of 10 <sup>60</sup> ) and the associated challenge of finding molecules with promising qualities in that vast chemical space. Against the backdrop of such steep costs and the sheer number of molecular possibilities, high-performing predictive machine learning models are the keystone of pharma&#39;s AI-driven drug-discovery agenda. Pharma companies are also facing pressure as <a href="https://www.cbinsights.com/research/report/famga-big-tech-pharma/">Big Tech</a> players like Alphabet use their profound expertise in AI and machine learning to venture into drug discovery.</p><p> Cognizant of the reluctance to share drug discovery data, but also of the great potential of collaborative AI to boost efficiencies in drug discovery, Hugo Ceulemans, the scientific director at Janssen Pharmaceutica, began floating the FedML idea and initiating talks with peers around 2016. His efforts eventually contributed to the formation of the Melloddy consortium by 10 pharma companies in 2019. In a blog post, Ceulemans noted that while pharmaceutical companies had previously pooled data to support predictive efforts, the scope of collaboration had been limited, given that data is an expensive competitive asset. <a id="reflink4" class="reflink" href="#ref4">4</a> Because the new FedML consortium would allow the underlying data contributions to remain under the control of the respective data owners and not be shared, a much more ambitious scope would be possible, he explained.</p><p> Melloddy, a term named for <em>machine learning ledger orchestration for drug discovery</em> , was a three-year pilot project aimed at testing FedML for feasibility and effectiveness. The project was cofunded by the European Union; the European Commission considered Melloddy to be a test case for generating insights for business sectors beyond pharma. Participating companies included AstraZeneca, Bayer, GSK, Janssen Pharmaceutica, Merck, and Novartis, among others. These companies were supported by technology and academic partners, including Owkin (an AI biotech venture) and KU Leuven (a university with expertise in AI-driven drug discovery).</p><p> By leveraging one another&#39;s data without actually sharing it, the participating pharma companies could train their machine learning models on the world&#39;s largest drug-discovery data set, which enabled more accurate predictions on promising molecules and boosted efficiencies in the drug discovery process. In a blog post, Mathieu Galtier, chief product officer at Owkin, explained that thanks to Melloddy&#39;s use of federated learning, data never left the infrastructure of any pharma partner. The machine learning process occurred locally at each participating pharmaceutical company, and only the models were shared. “An important research effort is devoted to guaranteeing that only statistical information is shared between partners,” he wrote. <a id="reflink5" class="reflink" href="#ref5">5</a></p><p> The results of the Melloddy pilot project, which concluded in 2022, revealed that creating a secure multiparty platform for collaborative AI using decentralized data is feasible and that the performance of machine learning models is indeed enhanced by using a FedML approach.</p><h3> Strategic Considerations for FedML Consortia</h3><p> When setting up a FedML consortium, those involved in the planning process must carefully consider the optimal approach for orchestrating the technology and incentivizing partners. The selected orchestrator assumes a pivotal role in effectively managing the FedML process. Leaders of small-data organizations are sometimes reluctant to team up with Big Tech companies because they can maintain greater strategic control and build closer ties with smaller tech partners that operate on an equal footing. And some even fear that Big Tech companies will themselves move into their sector, as is happening in pharma.</p><p> In the case of Melloddy, pharma companies chose Owkin, a startup, to take on the responsibility of orchestrating the consortium&#39;s FedML platform. This may be a good approach for many FedML initiatives, but it can be risky, given the high failure rate of startups: A consortium might crumble if the startup fails. There is also a potential risk that the startup might raise funding from a competitor that is not participating in the consortium; it&#39;s an awkward situation, but not unlikely. Therefore, if a startup venture is chosen as the prime technology orchestrator, the consortium partners should seriously consider the option of investing corporate venture capital (CVC). <a id="reflink6" class="reflink" href="#ref6">6</a> When the partners have a sizable joint CVC stake in the startup, with rights of first refusal, they have much stronger control over the length of the tech startup&#39;s runway and its future trajectory.</p><p></p><p> FedML can give rise to an incentive problem, wherein some participants fail to use all relevant local data or neglect to invest in the necessary data infrastructure to improve the accuracy of their local models. They may choose not to put in the effort while relying on the data contributions made by other consortium partners. This free-riding behavior then undermines the motivation and participation of well-intentioned participants. To preempt this problem, the FedML consortium can agree on appropriate partner commitments in terms of the quantity and coverage of data contributed and specify them upfront in a contractual agreement. Local model updates can also be monitored by the orchestrator in terms of their contribution to the overall accuracy of the joint model, and the payment of a FedML service fee can be made proportionate to each partner&#39;s contribution to the federated learning process.</p><p></p><p> When taking first steps toward assembling a FedML consortium, securing partner buy-in is vital. Partners should therefore be involved in defining the consortium&#39;s objectives in exchange for their data commitments. The AI Canvas is a decision-making tool that can be useful in identifying and discussing machine learning use cases and required training data. <a id="reflink7" class="reflink" href="#ref7">7</a> When approaching partners, keep in mind that effective model updates in most FedML applications require access to local data on all relevant model variables. As a result, suitable partners are often found within the same industry, sharing similar business processes and data. Working with indirect competitors, such as those serving other geographic markets, instead of with direct competitors could be advantageous here to minimize potential conflicts. For small-data organizations venturing into FedML, it&#39;s advisable to start with achievable machine learning projects to establish momentum and build trust among partners before embarking on more ambitious projects.</p><p> FedML is still a young AI approach, developed in 2016 by a group of Google engineers. <a id="reflink8" class="reflink" href="#ref8">8</a> But progress in this field is fast paced, and we can expect a surge in its adoption across a range of business sectors. Forward-thinking leaders of small-data organizations who incorporate FedML into their strategic visions are better positioned to harness the transformative power of AI to shape their future success.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/using-federated-machine-learning-to-overcome-the-ai-scale-disadvantage/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> Who Should Price a Gig?</title><link/> https://sloanreview.mit.edu/article/who-should-price-a-gig/<comments> https://sloanreview.mit.edu/article/who-should-price-a-gig/#respond</comments><pubDate> Mon, 21 Aug 2023 11:00:28 +0000</pubDate> <dc:creator><![CDATA[Jovana Karanovic, Elizabeth J. Altman, and Carmelo Cennamo. <p>Jovana Karanovic is an assistant professor at the Rotterdam School of Management at Erasmus University and the founder of the Reshaping Work foundation. Elizabeth J. Altman is an associate professor of management at the Manning School of Business at the University of Massachusetts Lowell; guest editor for <cite>MIT Sloan Management Review</cite> &#39;s Future of the Workforce initiative; and coauthor of <cite>Workforce Ecosystems: Reaching Strategic Goals With People, Partners, and Technologies</cite> (MIT Press, 2023). Carmelo Cennamo is a professor of strategy and entrepreneurship at Copenhagen Business School, director of the Digital Markets Competition Forum, and affiliate professor and director of the Platform Economy &amp; Regulation Monitor at SDA Bocconi School of Management.</p> ]]>; </dc:creator><category><![CDATA[Platforms]]></category><category><![CDATA[Pricing]]></category><category><![CDATA[Platforms & Ecosystems]]></category><category><![CDATA[Strategy]]></category><description><![CDATA[Daniel Hertzberg/theispot.com The Research The authors conducted interviews with platform executives at four platform businesses — Malt, Ring Twice, Temper, and Wolt — that represent different industry sectors and price-setting models. They also conducted archival web-based research studying platform-based businesses in various regions of the world and evaluated their pricing models. They were provided with [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/2023FALL-Karanovic_1290x860.png" alt="" /><figcaption><p class="attribution"> Daniel Hertzberg/theispot.com</p></figcaption></figure><aside class="callout-info"><h4>这个调查</h4><ul><li>The authors conducted interviews with platform executives at four platform businesses — Malt, Ring Twice, Temper, and Wolt — that represent different industry sectors and price-setting models.</li><li> They also conducted archival web-based research studying platform-based businesses in various regions of the world and evaluated their pricing models.</li><li> They were provided with and analyzed data from a service platform that switched from a platform-controlled price setting to allowing service providers to set prices. This data is part of an ongoing research project by Jovana Karanovic, Hakan Özalp, Carmelo Cennamo, and Mark Boons.</li></ul></aside><p> Arriving at Boston&#39;s Logan International Airport after a tiring journey, Mia opened the Uber app to find a ride home. Her relief at seeing the message “Your Uber driver is arriving in 3 minutes” was short-lived because the driver canceled. In the next 30 minutes, half a dozen Uber drivers accepted her ride request, then canceled, before one eventually arrived. What was happening?</p><p> Uber, like many platform companies, needs to efficiently match service providers (drivers) and customers (riders). To do so, it must ensure that pricing is competitive enough for riders to choose the service and for drivers to have the incentive to deliver it. Mia struggled to get a ride because Uber had started providing more earnings transparency for drivers by allowing them to see their expected compensation and route destinations before picking up riders. A change intended to benefit drivers had a significant downside for riders: More drivers began canceling rides they deemed unprofitable.</p><p></p><p> The question of who sets prices, and what discretion other parties in the transaction have to alter them in order to achieve mutually beneficial outcomes, is complex and nuanced for platform operators. In the case of Uber, the platform sets the price for the ride, and though drivers can opt out if their earning potential is unattractive, both drivers and riders have no flexibility for proposing different pricing. It&#39;s one of the drawbacks to having the locus of control primarily in the hands of the platform provider.</p><p> While algorithmically determined prices set by the platform operator are common among ride-hailing and food delivery services, other kinds of platform businesses allow service providers or customers to set prices. Fiverr, an online marketplace that matches high-skilled service providers with customers for tasks such as programming or graphic design, lets freelancers name their rates. In contrast, Temper, a Dutch platform for shift work in hospitality, retail, and logistics, lets customers (such as restaurants and shops) determine what the gig pays.</p><p> Controlling all pricing can lead to unintended consequences for a platform, as the Uber example shows, but allowing other stakeholders to set prices can also have drawbacks. For example, Ring Twice, a Belgian platform business that offers a variety of household services, such as gardening and babysitting, assigned pricing control to customers. It turned out that customers knew what they wanted — but not necessarily how much time and effort a specific task would take. Allowing customers to set prices resulted in fewer matches because many customers offered lower payments than service providers were willing to accept. Fewer successful job matches meant lost revenue for the platform.</p><p> Granting price-setting control is a major strategic decision that ultimately determines value creation and capture and establishes the power dynamics between the platforms themselves, service providers, and customers. Creating a scenario where all three stakeholders find the pricing model sustainable and beneficial is the key challenge that platform leaders face. To help leaders work through this decision, we offer a framework for understanding the key trade-offs of different platform price-setting approaches. Beyond economic considerations, we emphasize the need for managers to anticipate power dynamics and adopt hybrid approaches to mitigate them. (See “Pricing Dynamics on Gig Platforms.”)</p><div class="callout-highlight callout"><aside class="l-content-wrap"><article><h4> Pricing Dynamics on Gig Platforms</h4><p class="caption"> Platform operators must understand the key trade-offs of handing pricing power to different stakeholders; sharing that power through hybrid approaches is often the most sustainable option. </p><table id="Chart#" class="chart-grouped-rows no-mobile"><thead><tr><th style="line-height:1.5;width:25%"> Who Controls Pricing</th><th style="width:25%">好处</th><th style="width:25%">Risks</th><th style="line-height:1.5;width:25%"> Hybrid Solution</th></tr></thead><tbody><tr><td><p> <strong>PLATFORM</strong></p></td><td><p> Algorithmic pricing based on capturing market data can maximize efficiency in markets for standardized services.</p></td><td><p> Real-time price adjustments can disadvantage either providers or customers. Lack of predictability can damage trust.</p></td><td><p> <span class="blue">•</span> Set a base rate and enable providers to adjust prices upward or customers to make offers.</p><p> <span class="blue">•</span> Provide price guarantees in line with living wages.</p></td></tr><tr><td><p><strong>供应商</strong></p></td><td><p>The service provider&#39;s ability to set prices incentivizes high-quality providers to join. More variability on a platform serves long-tail demand.</p></td><td><p> Underpricing can drive down the perceived value of services across the platform. Overpricing can drive away customers and limit platform growth.</p></td><td><p> <span class="blue">•</span> Allow for price and contractual negotiations between customers and providers.</p><p> <span class="blue">•</span> Give price recommendations and share market data with providers.</p></td></tr><tr><td><p> <strong>CUSTOMER</strong></p></td><td><p> Customers can control their own costs, which may increase engagement with and perceived value of the platform to customers.</p></td><td><p> Offering pay rates that are too low can drive away providers, thus limiting platform growth.</p></td><td><p> <span class="blue">•</span> Set minimum price thresholds in line with living wages.</p><p> <span class="blue">•</span> Assist customers by sharing market data and/or giving price recommendations. </p></td></tr></tbody></table><p><!--IMAGE FALLBACK FOR MOBILE BELOW --><br /><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/MAG_Karanovic_table-1.png" alt="Pricing Dynamics on Gig Platforms" class="no-desktop"></p></article></aside></div><h3> When Platforms Call the Shots</h3><p> A platform can benefit from numerous advantages by retaining price-setting control, especially in certain segments. The practice is prevalent in ride-hailing, food delivery, and parcel delivery, where services are fairly standardized, volume is high, and logistics rapidly gain complexity with scale.</p><p> By retaining control, platforms can optimize for efficiency, particularly when they serve a large number of customers with similar needs. To set optimal prices, platforms leverage the large amount of transaction data they collect. Consider the Finnish platform Wolt, recently acquired by DoorDash, which offers food delivery, among other services. Wolt relies on parameters such as a courier&#39;s distance from the restaurant, food preparation time, and distance from the customer. Using this information, it advises couriers on the best routes to take and provides relevant extra information (for example, building entrance locations) to ensure swift delivery — and time savings. As a Wolt manager explained to us, the platform&#39;s interest in efficiency aligns with the couriers&#39; desire to take the optimal route, hence standardizing the delivery process as well as prices makes sense.</p><p> Controlling prices also allows the platform to maximize revenue by making quick adjustments based on market conditions: When demand is high, ride-hailing and delivery platforms commonly increase prices in real time. Platforms can also experiment with different pricing strategies.</p><p></p><p> Finally, by controlling the price, a platform provider can offer discounts and promotions to attract and retain customers. It may choose to offer personalized pricing based on customer behavior, preferences, and purchase history. Amazon, for example, utilizes such data to set dynamic pricing for certain items. When a customer views a product on Amazon, they may see a price that is different from what another customer might see for the same product. This is because Amazon&#39;s pricing algorithms take into account the customer&#39;s browsing and purchasing history, their location, and other variables to determine an individualized price that maximizes the likelihood of a purchase.</p><p> However, there are trade-offs to platforms retaining pricing control, particularly when it comes to the impact on power dynamics between stakeholders. In particular, service providers may decline to accept jobs if prices are set too low by the platform, or they may struggle to attract customers if their prices are set too high. In both cases, the service provider has less incentive to engage with the platform. A study examining posts to a forum for Uber drivers in US cities found that they discussed intentionally turning off their apps to appear unavailable in order to get the algorithm to implement higher surge pricing designed to incentivize drivers to get on the road. <a id="reflink1" class="reflink" href="#ref1">1</a> The drivers essentially had to game the system to get the prices they wanted, reflecting — and exacerbating — a lack of trust between providers and the platform.</p><p> Platform-controlled pricing also goes hand in hand with a standardized menu of services that might not adequately meet some customers&#39; needs. They may use the platform for finding a service provider and then arrange subsequent interactions off the platform. A recent study indeed found that providers&#39; dissatisfaction with platform rules and fees, as well as customers&#39; desires for more personalized services, are among the main factors contributing to disintermediation. <a id="reflink2" class="reflink" href="#ref2">2</a> When customers and providers are dissatisfied with platform-imposed rules, they are less likely to transact on the platform (lowering revenues), and the platform&#39;s reputation may suffer among all disaffected stakeholder groups.</p><p></p><h3> Putting Service Providers in Control</h3><p> There are also advantages when service providers are in control of price setting — common practice on freelance marketplaces such as Upwork, Toptal, and Malt. Granting this autonomy provides a competitive and flexible pricing environment, which is particularly advantageous for customers seeking specific capabilities for unique project needs. Similarly, providers can more effectively monetize their skills or unusual talents.</p><p> When providers set prices for a project, they can account for their costs, the effort they are willing to exert, and the service quality they can offer — information that the platform doesn&#39;t have but needs in order to set an adequate price. Price setting also lets service providers exercise their entrepreneurial freedom and adjust prices based on intangible factors such as their personal interest in a particular project. For example, they might charge less to land an assignment that will help them build valuable expertise, according to a manager at Malt, a European platform for services such as consulting and software development.</p><p> When service providers are able to set their own pricing and offer differentiated services, the platform can meet long-tail demand for niche offerings. Helpling, a platform for housecleaning services in Germany, France, Switzerland, England, Ireland, Italy, and Singapore, provides a case in point. The platform initially had a model where, within a given market, it set a standard price per hour for recurring cleaning jobs. (The slightly higher price for one-off jobs was also standardized within markets.) However, after a few years, Helpling changed its approach to let providers set their own prices. Our research shows that prices for some jobs subsequently increased as providers became willing to do different kinds of jobs (for example, after-party cleanups) for a higher fee. <a id="reflink3" class="reflink" href="#ref3">3</a> The platform&#39;s policy change apparently revealed unmet demand for additional services.</p><p> Allowing service providers to set prices also improves the customer experience in categories where the quality of service is more likely to vary by provider. Different quality levels for comparable services can create uncertainty and diminish satisfaction. Lower quality is often due to providers lacking incentive to exert the required effort when customers pay a standard price set by the platform business. If providers get to set their own prices that reflect their true value, they can reap the rewards of their greater efforts and deliver higher customer satisfaction.</p><p></p><p> This approach does have downsides. When platform operators relinquish price-setting control and providers overcharge, that can lower overall matching and transaction volumes; if providers undercharge, that can leave money on the table. At Malt, where service providers have full control of price setting, they tend to underprice themselves despite deep knowledge of what&#39;s required to perform tasks and their level of expertise. But that can be a vicious circle, according to the Malt manager we interviewed: Clients who are attracted to low-cost providers may be less discerning. Without a way for customers to differentiate between high- and low-quality providers listed on the platform, there&#39;s a risk that low prices will increasingly attract clients looking for more basic, lower-quality services. This drives out high-quality providers and potentially downgrades the brand equity and reputation of the platform. It might also lead to a race to the bottom, with providers consistently lowering prices to outcompete one another, reducing the platform&#39;s margins and providers&#39; earnings (and their willingness to remain on the platform).</p><p> For customers, provider pricing puts other dynamics into play. Providers that choose to focus on lucrative niches may leave some demand unmet. And the greater variability in provider-set pricing makes it more difficult for customers to fairly compare prices and find the best value for their money. If selecting a service provider becomes too time-consuming, customers may abandon the platform altogether.</p><h3> Customers Name Their Price</h3><p> Temper, the Dutch shift-work platform, allows customers to decide what they are willing to pay and matches skilled workers, such as baristas, with venues, such as restaurants. This approach is most appropriate when customers are businesses that have precise requirements for the services they need and the amount they are willing to pay.</p><p> Under this model, customers can set prices that reflect their budget and desired level of service, and service providers can choose to accept or reject offers based on their own pricing policies and cost structures. At Temper, restaurants looking for shift workers have different cost structures — for example, those in a city center pay higher rents. They also vary by service quality (for example, fine dining versus fast-casual), which affects the skills profiles they need and therefore the pay they will offer to attract workers. Customers can control their costs but also have flexibility to adapt to the competitive environment — for example, by offering higher compensation for weekend shifts. The platform exposes the going rate that other businesses are offering for the same services, which can also inform pricing decisions.</p><p> Finally, customers may be more motivated to use a platform if they have greater control over the pricing process. If they are given the power to determine the value they place on the service, they may feel more satisfied as well as invested in the transaction. Being more in control on the platform may deepen a sense of ownership and increase engagement and loyalty.</p><p> Naturally, customer-set pricing has trade-offs that can affect platform operators and providers. If customers set prices too low, service providers may be unwilling to take the task or they may be incentivized to cut corners to maintain profitability. This in turn could lead to a decline in the overall quality of products or services, reducing the platform&#39;s attractiveness and growth potential. Similarly, customers may not have access to complete information about the market dynamics, costs, and competitive landscape, leading to suboptimal outcomes for both providers and customers.</p><h3> Strike a Balance With Hybrid Approaches</h3><p> Whether pricing is controlled by the platform, service provider, or customer, under appropriate circumstances each choice has the potential to maximize value creation and efficiency. Nonetheless, dynamics that unfold among platforms&#39; different stakeholders may outweigh some of these benefits and lead to unintended consequences. To ensure long-term sustainability and enhance a platform business&#39;s financial performance, platform managers may want to share some control over pricing.</p><p> Platform providers can consider hybrid approaches to do this. For instance, TaskRabbit sets standard prices for different types of tasks based on factors such as complexity, duration, and market rates. These standard prices are initially determined by the platform to provide consistency and guidance to both customers and gig workers. However, TaskRabbit also allows service providers to adjust prices based on their own preferences and circumstances, and set a price that can be higher or lower than the platform&#39;s standard prices. The European Union has a proposed platform work directive that considers the right to set one&#39;s own rate a distinguishing factor between freelancers and employees; if adopted, it may push ride-hailing and food delivery platforms, which currently determine prices, to share this control with providers.</p><p> Platforms that control pricing can mitigate the power imbalance by being transparent with service providers about how prices are determined and whether they can do anything to increase earnings. They should also provide a mechanism for hearing providers&#39; concerns and enable them to appeal algorithmically determined decisions that affect their earnings on the platform.</p><p> While allowing service providers to set prices makes sense in some cases, it does not always lead to optimal pricing for them or the platform. For example, providers who have established high ratings and show a high number of completed tasks may have more pricing power compared with new providers. This is not beneficial for platforms, because new service providers quickly disengage if it takes too long to acquire work, limiting platform growth. Malt handles this discrepancy by boosting new providers&#39; visibility in search results.</p><p> Platforms can also assist providers with price setting, especially for offerings that are prone to demand fluctuations. A study of Airbnb found that only professional hosts (those with multiple properties) set prices skillfully; most others set suboptimal prices. <a id="reflink4" class="reflink" href="#ref4">4</a> Airbnb introduced price recommendations, alerting hosts to events and time periods when demand is high and prompting them to increase prices. <a id="reflink5" class="reflink" href="#ref5">5</a> Moreover, it lets hosts opt for automatic price adjustments, which essentially brings the price-setting power back to the platform, even in this service provider-controlled model.</p><p> When customers set prices, as we have seen, they may make lowball offers to service providers, especially during unfavorable market conditions. Platforms can prevent exploitation of service providers by setting minimum price thresholds that, for example, correspond to minimum or living wages. For instance, Temper sets a minimum price threshold for each service category that is in line with minimum wages, although it is not required to do so under Dutch law. In addition, it allows providers to negotiate. In 2022, 10% of all transactions on Temper were negotiated upward compared with initial prices set by customers, one of the company&#39;s cofounders told us. Such proactive initiatives from platforms may anticipate increasing regulations aimed at curtailing their power. New York City already has imposed a minimum wage for Uber and Lyft drivers and recently announced the same for workers on food delivery apps. The European Union is going a step further: Its proposed directive will presume gig workers are employees of platforms if certain criteria do not apply, such as a worker&#39;s right to adjust platform-determined rates as they see fit. In other words, if a platform sets upper limits for pay, it may be viewed as an employer.</p><p></p><p> As we have noted, customers may not always be fully informed, or they may have very specific preferences, in which case platforms can assist them with making provider selections. For example, on freelance marketplace Upwork, customers post desired tasks they need accomplished such as “logo design” or “report writing,” with detailed descriptions of what they are looking for and the price they are willing to pay. This price-setting model works well when customers have specific preferences and need a specific kind of provider for the job. However, Upwork eventually realized that not all customers have clear preferences; some just want the service done and would rather select it from a menu of offerings. This led to the launch of Upwork&#39;s Project Catalog, a website offering predefined projects that customers can browse and select, such as “A 500-word SEO-optimized blog article in under 24 hours” for $50. Instead of customers detailing the job, providers post what they can offer for a set price. This makes it easier for customers to find the right provider for their needs and gives providers more opportunities to win work.</p><p></p><p> A platform&#39;s need to control its marketplace to maximize returns isn&#39;t going away, but the approach it takes will determine its long-term sustainability. Platform leaders must realize that a platform is not a unilateral, hierarchically managed entity but rather a web of economic and social relationships. To manage it successfully and ensure satisfaction for all parties, they must share some aspects of control with other stakeholders, allow for compromise, and step in to support their workforce when needed. When control is shared more equitably among all parties in the platform relationship, the platform model can cater more beneficially to all.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/who-should-price-a-gig/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> Rethinking Governance for Digital Innovation</title><link/> https://sloanreview.mit.edu/article/rethinking-governance-for-digital-innovation/<comments> https://sloanreview.mit.edu/article/rethinking-governance-for-digital-innovation/#respond</comments><pubDate> Wed, 16 Aug 2023 11:00:16 +0000</pubDate> <dc:creator><![CDATA[David L. Rogers. <p>David L. Rogers is faculty director of Columbia Business School&#39;s executive education programs on digital business strategy and leading digital transformation. He is the author of <cite>The Digital Transformation Roadmap: Rebuild Your Organization for Continuous Change</cite> (Columbia Business School Publishing, 2023), from which this article is adapted, as well as the bestselling <cite>The Digital Transformation Playbook</cite> (2016).</p> ]]>; </dc:creator><category><![CDATA[Digital Innovation]]></category><category><![CDATA[Innovation Management]]></category><category><![CDATA[Innovation Process]]></category><category><![CDATA[Innovation]]></category><category><![CDATA[Organizational Transformation]]></category><description><![CDATA[Patrick George When global chemical company BASF launched its Onono lab in São Paulo, Brazil, its mission was to accelerate innovation through rapid collaboration with local partners and startups. But Onono’s director, Antonio Lacerda, faced an immediate hurdle from corporate governance: He was told that his lab would have to follow the same corporate data [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/2023FALL-Rogers_1290x860.png" alt="" /><figcaption><p class="attribution"> Patrick George</p></figcaption></figure><p> When global chemical company BASF launched its Onono lab in São Paulo, Brazil, its mission was to accelerate innovation through rapid collaboration with local partners and startups. But Onono&#39;s director, Antonio Lacerda, faced an immediate hurdle from corporate governance: He was told that his lab would have to follow the same corporate data policies used to secure BASF&#39;s entire cloud infrastructure — which would have made it impossible to partner quickly and nimbly with new startups. Lacerda postponed the launch until he was able, with significant political capital, to arrange an exception: a “sandbox” of separate data for his team, with special permission to share that data through APIs with new partners.</p><p> Lacerda&#39;s experience, and that of so many innovation champions, points to a fundamental problem for digital transformation: In large companies, innovation teams are left to fight for waivers in the face of business rules that contradict their own mandate for change. But innovation will never happen at scale as long as it relies on ad hoc exceptions approved by senior leaders. Instead, we must rethink our approach to governance and design new management practices for innovation at the speed of digital.</p><p></p><p> Designing repeatable processes for innovation is essential for growth in the digital era, yet it is incredibly hard. In too many organizations, new ventures are green-lit based on a single executive sponsor. Once started, ventures move slowly, managed by teams that sit in traditional silos. Resource allocation is slow too, as promising projects wait weeks or months for their next round of approvals. Because each project is backed by an influential executive, no one wants to shut it down, even if it shows little promise.</p><p> Meanwhile, risk aversion leads businesses to fund only their low-hanging fruit — incremental improvements in the core that bring a guaranteed, quick ROI. This path will never lead to transformation. Instead, you need governance that embraces uncertainty and supports growth both within and beyond the core. (See “How Governance Helps or Hinders Innovation.”)</p><div class="callout-highlight callout"><aside class="l-content-wrap"><article><h4> How Governance Helps or Hinders Innovation </h4><p class="caption"><table id="Chart#" class="chart-grouped-rows no-mobile"><thead><tr><th style="width:50%"> Signs of <em>Poor</em> Governance</th><th style="width:50%"> Signs of <em>Good</em> Governance</th></tr></thead><tbody><tr><td><p> <span class="blue">•</span> A top executive must personally approve any new innovation.</p></td><td><p> <span class="blue">•</span> Established structures provide resources and governance for innovation.</p></td></tr><tr><td><p> <span class="blue">•</span> New ventures move slowly, led by traditional teams in functional silos.</p></td><td><p> <span class="blue">•</span> New ventures move fast, led by highly independent, multifunctional teams.</p></td></tr><tr><td><p> <span class="blue">•</span> Allocating resources to new ventures is slowed by the annual budgeting cycle.</p></td><td><p> <span class="blue">•</span> Resource allocation happens quickly through iterative funding.</p></td></tr><tr><td><p> <span class="blue">•</span> Innovation is limited to a few big projects, which are hard to shut down once they are started.</p></td><td><p> <span class="blue">•</span> A steady pipeline of innovations is managed with smart shutdowns to free up resources.</p></td></tr><tr><td><p> <span class="blue">•</span> The only ventures to gain support are low-risk innovations in the core business.</p></td><td><p> <span class="blue">•</span> Governance supports ventures with low and high uncertainty, both in the core and beyond. </p></td></tr></tbody></table><p><!--IMAGE FALLBACK FOR MOBILE BELOW --><br /><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/MAG_Rogers_table-1.png" alt="How Governance Helps or Hinders Innovation" class="no-desktop"></p></article></aside></div><p> Digital transformation requires that governance be carefully designed to address several issues. The first is <em>oversight</em> . Who approves new projects? To whom do they report? And who shuts them down? Next is <em>funding</em> . How will you allocate resources across a portfolio of ventures to maximize opportunities for success? Equally critical are <em>people</em> . Who will staff new ventures, whether inside or outside your organization? How will teams be formed with the right mix of skills? Governance must also include <em>metrics</em> . How will you measure the progress of new ventures? And, crucially, how can you bring discipline to regularly <em>shutting down</em> ventures, a practice so often neglected at large enterprises?</p><p> In this article, we will discuss how to design governance models to drive digital innovation across any enterprise, by focusing on two critical work groups: the people engaged in building new ventures and those overseeing and assessing their work. We&#39;ll delve into the top governance issues for managing growth at scale, including how venture teams and supervisory boards work together. And we will explore how to manage ongoing decisions to green-light new ventures, grant additional funding to those that merit it, and shut down others to free up resources.</p><h3> Design Teams to Drive Innovation</h3><p> Decades of experience have shown us that, in established businesses and small startups, meaningful new growth always starts in one place: small teams, effectively empowered. These teams do the work of rapid, iterative experimentation, which is at the heart of every modern approach to innovation — whether agile, design thinking, lean startup, or product management. Every innovation team&#39;s job is to take a proposed new venture and rapidly test every facet of its business model to validate what will or will not work in the market.</p><p> Within any established enterprise, the rules governing innovation teams are critical to their success. Many readers will be familiar with the idea of small multifunctional teams. But size and composition are only part of what matters for team success. By studying innovation in digital natives like Amazon and Google, and digital transformers like Walmart and Mastercard, I have identified five essential pillars of team governance. Great innovation teams are:</p><p><strong>小的。</strong> Research has shown that small teams communicate, coordinate, and make decisions much faster than large ones. <a id="reflink1" class="reflink" href="#ref1">1</a> Small teams are foundational to agile methods, which use a rapid cadence of short sprints in which every team must deliver new working code, test and learn, and adjust priorities. At Amazon, innovation teams are called two-pizza teams because each one should be small enough to be fed by two pizzas (a maximum of eight people).</p><p> <strong>Multifunctional.</strong> Great innovation teams have diverse members who cut across functional silos (for example, marketing, engineering, and design). The goal is for each team to have members who can provide all the essential skills needed to do its work. Instead of constantly waiting for another department&#39;s input before taking the next step in its project, a multifunctional team is able to push ahead entirely on its own.</p><p> <strong>Single-threaded.</strong> The best innovation teams have all members dedicated full time to the team&#39;s work. At a minimum, the innovation team&#39;s leader must be single-threaded, meaning they cannot be splitting their workweek between the team&#39;s new venture and other projects. Leading the team is their full responsibility.</p><p> <strong>Autonomous.</strong> Successful innovation teams have clear decision rights that give them the authority to work under their own direction. They should not need to get approval on their work from anyone outside the team — whether it is on product design, what tests to run next, or which customers to pursue. Autonomy also means there are no prohibitions on contracting resources from outside the company.</p><p> <strong>Accountable.</strong> Autonomy is possible only if the team is also clearly accountable for the results of its work. Here, good governance demands a clear definition of success, which is defined in terms of outcomes, not deliverables. That definition may include quantitative metrics as well as qualitative principles, and it must be agreed on with leadership before the team&#39;s work begins. Effective accountability also requires transparency: At any time, the team&#39;s results must be visible to anyone inside or outside the team. Every test run, every MVP built, and every metric tracked should be visible to anyone in the company.</p><h3> Establish Oversight With Growth Boards</h3><p> Innovation teams&#39; most critical partners are the managers who will allocate funds and oversee and support their work. In my experience, the most successful model for sponsoring corporate innovation is the board. In the board model, a small group regularly convenes and deliberates to decide whether to sponsor various possible innovation ventures — much like a group of VC investors listening to pitches from startups. One innovation board will sponsor and support multiple teams working in parallel.</p><p> This approach contrasts with what I have found to be all too common: organizations where new ventures are approved by a single sponsor. In these companies, one or more executives may use their clout within the organization to sponsor a new digital venture they deem strategically important and promising. This model is inherently ad hoc, with decisions based on the instincts and judgment of different individuals. And once a sponsor puts their name and reputation behind a project, it is very hard for them to let it die, no matter what market validation shows about its prospects. By contrast, the board model — with its greater diversity and impartiality of decision-making — is inherently better for managing innovation at scale.</p><p> Effective corporate innovation boards — also known variously as growth boards, venture boards, or growth councils — should number no more than eight people. They should include members with topical expertise and knowledge of the market. A board should be able to challenge company orthodoxy, advocate a long-term view, and bring in ideas from outside the industry. The best boards combine internal stakeholders from different divisions and at least one member with an external perspective. Members should be senior enough to have real clout in the organization but not so senior that they can&#39;t make board work a priority.</p><p> The job of the board is to regularly meet to green-light new ventures, provide strategic guidance to teams, decide on each stage of additional funding, and make disciplined decisions about when to shut down ventures. Here again, decision rights are critical. The innovation board must have complete funding authority for each team in its portfolio. Its decisions should be informed by open and lively debate with the team, but the decisions remain with the board. Other senior executives, including the CEO, may advise and provide input on ventures, but they cannot vote on or overrule the board&#39;s investment decisions.</p><p></p><h3> Green-Light New Projects</h3><p> The first process where boards and teams must work together is green-lighting — that is, approving new ventures to start work. When a board green-lights a new venture, it should allocate just enough resources (in the form of time, money, and people) for the team to conduct a first round of testing to validate the initial questions about the business model. The key to effective green-lighting is to <em>minimize</em> the initial investment made in each team and <em>maximize</em> the number of ideas that are approved to be tested.</p><p> This approach may seem counterintuitive — it certainly contrasts with the tendency to try to “pick a winner and bet big,” seen at so many organizations with poor innovation governance. In fact, it is important for boards to resist the urge to try to pick the best ideas among those submitted. First, the board has truly no way of knowing which ideas will work. That knowledge can be gained only through testing and validation. Second, successful ventures often emerge from ideas that are initially flawed but evolve in response to testing, feedback, and iterative design. Instead of trying to evaluate the likelihood of success, I recommend that boards judge new venture pitches based on their problem definition, strategic fit, and team mindset.</p><p></p><p> To green-light many innovation ideas, it is essential to build a fast, cheap, and effective validation process. This means bringing in the voice of the customer to rapidly test whether the venture is focused on solving a genuine problem. At Citibank, new ventures often begin with a two- or three-day workshop in which employees explore a problem/opportunity statement and have a chance to develop their own innovation ideas in a rapid, iterative fashion with actual customers. As you increase the speed and drive down the cost of your first stage of validation, your business can afford to approve more venture teams to test and pursue more possible ideas for growth.</p><h3> Manage Resources With Iterative Funding</h3><p> The next critical process for managing innovation is iterative funding, which is how boards allocate resources to teams after their ventures have been green-lit. Iterative funding is designed to be extremely agile, based on the VC approach to financing startups. At each board review (typically every 30, 60, or 90 days), the board will review each team&#39;s progress, including new data from its tests in the market, and decide whether to release the next tranche of resources to that team.</p><p> Iterative funding is a dramatically different process from traditional budgeting in large enterprises. Here&#39;s why it&#39;s a better approach for managing investments in new innovation:</p><p> <strong>Get off to a faster start.</strong> In a traditional budgeting process, a new project will be granted a large initial sum that reflects commitment to the project. But that happens only after a long period of analysis that strives (misguidedly) to assess the chances of an uncertain new venture through benchmarks and third-party data. Iterative funding, in contrast, gives ventures a small initial budget but allows teams to get started fast, if the opportunity they are pursuing is well defined and strategically relevant.</p><p> <strong>Be more agile with shorter funding cycles.</strong> Corporate budgets are typically set annually, with projects and departments funded through a complex process that takes months. A promising new venture can wind up waiting over a year to get resources for a four-week test. In contrast, when boards meet frequently and funding rounds provide teams with just one to three months of resources, decision-making is much more agile.</p><p> <strong>Invest based on real-world data.</strong> Many leaders will overcommit funds to an untested new venture because they have a personal conviction that the strategy is right or because they are swayed by the persuasive talents of the team. With an iterative funding process, the board decides on each round of resources based entirely on real-world data. Every time they meet, the board and the team must agree on what data the team needs to bring to its next review meeting. Those metrics — typically three to six key variables — will shift over time, depending on the biggest sources of uncertainty still facing the new venture. They capture what the venture team has learned so far and what it needs to learn next.</p><p> <strong>Scale fast to drive exponential growth.</strong> In traditional budgeting, when funding is renewed, any increase is only incremental from the previous budget. With iterative funding, if validation is successful and a venture moves ahead, the size of each investment round should grow exponentially. Allocation of human resources should increase as well. This means that innovation teams that uncover meaningful growth opportunities can scale quickly to make a measurable impact on the company&#39;s bottom line.</p><p> Clearly, iterative funding requires that boards be ready to ramp up investment quickly in ventures that prove themselves in the market. That means the enterprise must fund a pool of resources in advance, for the board to allocate over the course of a year and across a portfolio of projects.</p><p> Within each portfolio, similar innovations (for example, a portfolio of high-risk innovations within a single business unit) should compete for funds. Don&#39;t let apples compete with oranges. First fund the portfolio for a specific class of innovations, and then let the board iteratively fund the various ventures.</p><h3> Make a Habit of Smart Shutdowns</h3><p> Of course, not every team review will conclude with a decision to continue funding. One of the classic problems that bedevil corporate innovation is that companies learn how to start new projects but not how to stop them. For innovation to deliver results, companies must be ready to exit projects that prove unsuccessful or are insufficiently aligned with strategy.</p><p> Shutting down ventures systematically and regularly is a critical job for growth boards. Every time a board meets for an iterative funding review, the question must be, “Do we fund this venture further or shut it down?”</p><p></p><p> At legacy companies, the biggest barrier to shutting down innovation projects is often an aversion to admitting failure and an irrational feeling that any kind of failure poses too much risk. But the cost of failures is minimal when they are shut down early, through iterative funding. In contrast, there are very real costs to the company if your teams do not shut down ventures quickly and smartly. Without this discipline, your innovation will lack focus, your resources will be spread too thin, and you will run out of bandwidth for new experiments. You will be stuck with <em>zombie projects</em> — unsuccessful ventures that never shut down and continue siphoning off resources. At Johnson &amp; Johnson, an entire new series of innovations was funded by evaluating the existing portfolio and shutting down projects that no longer matched the company&#39;s updated strategy. <a id="reflink2" class="reflink" href="#ref2">2</a></p><p> Halting projects will become easier only if you make it a routine decision, and here innovation boards with a regular calendar of funding reviews will make a huge difference. In GE&#39;s oil and gas division, projects were rarely shut down before its board was instituted. As soon as the board began, it easily shut down 20% of existing projects in its first 90-day cycle. As the board and teams became focused on aligning to strategy, this rose to 50% of new ventures shutting down within 60 days. <a id="reflink3" class="reflink" href="#ref3">3</a> At media giant Schibsted, the goal is to remove one venture whenever adding something new to the development pipeline. When a project comes up for review, set a high bar for yourself by asking, “Why shouldn&#39;t we shut this venture down?”</p><p> The following five practices are essential to achieving smart shutdowns in any organization:</p><p> <strong>Plan a pipeline with survival rates.</strong> Innovation at scale requires planning for most new ventures to be shut down. Only a third to a half of bright, shiny new ideas typically survive their first funding review after they&#39;ve had contact with real customers. Survival rates typically increase in subsequent rounds. Understanding your survival rates at different stages of validation will allow you to plan a pipeline for the future. For example, if a board is expected to help bring three or four new ventures to market within a year, it needs to plant enough seeds at the start to have good odds for success.</p><p> <strong>Use a venture backlog to reassign swiftly.</strong> An innovation board should maintain a ranked list of ideas for ventures that have been approved but not yet begun. Using this backlog in your review process will make shutdowns much easier. The point is no longer simply to kill a failing idea but to free the team and its resources to work on a more promising idea from the backlog. So, when you shutter a project, quickly reassign members to the best next idea. In many cases, that may just mean refocusing that team on a different solution to the same problem.</p><p> <strong>Extract value from shutdowns.</strong> When you decide to shut down a project, look to extract as much value as possible. In some cases, a company may be able to sell the venture to another business. When Walmart&#39;s Vudu streaming video service was no longer a strong strategic fit, Walmart spun it off to media giant Comcast. Sometimes a venture is promising but not yet workable; by shrinking your investment, you may maintain your future options. After Google Glass failed as a consumer product, the company shrank the project to an enterprise-only device focused on applications on factory floors. <a id="reflink4" class="reflink" href="#ref4">4</a> Sometimes only a full shutdown makes sense, and the key value to extract is the learning gained from experimentation. When Amazon shut down its Amazon Auctions and zShops services, it applied the lessons it learned for the subsequent launch of Amazon Marketplace to great success.</p><p> <strong>Share learning widely.</strong> Sharing what you learn from failed ventures is one of the hardest principles to follow. Most companies prefer to look away from projects that didn&#39;t work out. In a 2014 internal report on its early digital transformation efforts, The New York Times Co. admitted, “When we do shut down projects, the decisions are made quietly and rarely discussed, to protect the reputations of the people who ran them. As a result, lessons are forgotten, and the staffers involved become more risk averse.” <a id="reflink5" class="reflink" href="#ref5">5</a> Overcoming this reluctance was essential to the ultimate turnaround of The New York Times Co. and its business model. The German affiliate of Fédération Internationale de l&#39;Automobile (FIA) ran an innovation lab where eight of 10 projects were killed in a single year. Its biggest win? Sharing those results with other FIA affiliates around the world that were struggling with the same challenges in their own markets.</p><p> <strong>Distinguish people from projects.</strong> This is a final critical piece to building a culture that accepts and learns from innovation failures. A strong board review process will hold teams accountable for their results. But you should be careful not to associate a failed project with the merit of the individuals who worked on it. Those same team members could achieve tremendous success for you in their next project. Be sure to encourage your innovators to keep working on their next idea.</p><p> If your process for shutdowns is truly working, you will begin to see volunteering. When teams are truly focused on validating growth opportunities through experimentation, they will often suggest their own shutdown to the board, reporting, “Here&#39;s what we have learned and why we recommend shutting down now.” Don&#39;t be surprised when those same employees soon return to their board with another venture idea. It could be your next big breakthrough.</p><p></p><p></p><p> For digital transformation to deliver real growth and value to any organization, it must involve more than isolated pockets of innovation from teams struggling under the yoke of ill-suited management. Without new governance models to manage new ventures, the potential for digital innovation will always fall short.</p><p> Innovation governance requires three key building blocks: (1) Teams must be empowered to move fast and experiment to discover what works in the marketplace; (2) boards must be empowered to oversee and advise portfolios of teams, allocating resources where most needed; and (3) both must follow regular processes for green-lighting new ventures, funding them iteratively, and shutting them down to free up resources for the next emerging opportunity.</p><p> With the right governance in place, established companies of every kind can unlock the potential in their own employees to drive transformation and growth at every level of their business.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/rethinking-governance-for-digital-innovation/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> Images and Inspiration With AI: Pinterest&#39;s Jeremy King</title><link/> https://sloanreview.mit.edu/audio/images-and-inspiration-with-ai-pinterests-jeremy-king/<comments> https://sloanreview.mit.edu/audio/images-and-inspiration-with-ai-pinterests-jeremy-king/#respond</comments><pubDate> Tue, 15 Aug 2023 11:00:07 +0000</pubDate> <dc:creator><![CDATA[Sam Ransbotham and Shervin Khodabandeh. <p>Sam Ransbotham ( <a href="https://twitter.com/ransbotham">@ransbotham</a> ) is a professor in the information systems department at the Carroll School of Management at Boston College, as well as guest editor for <cite>MIT Sloan Management Review</cite> &#39;s Artificial Intelligence and Business Strategy Big Ideas initiative. Shervin Khodabandeh is a senior partner and managing director at BCG and the coleader of BCG GAMMA (BCG&#39;s AI practice) in North America.您可以通过<a href="mailto:shervin@bcg.com">shervin@bcg.com</a>联系他。</p><p class="mt20"> <cite>Me, Myself, and AI</cite> is a collaborative podcast from <cite>MIT Sloan Management Review</cite> and Boston Consulting Group and is hosted by Sam Ransbotham and Shervin Khodabandeh. Our engineer is David Lishansky, and the coordinating producers are Allison Ryder and Sophie Rüdinger.</p> ]]>; </dc:creator><category><![CDATA[Customer Behavior]]></category><category><![CDATA[Customer Engagement]]></category><category><![CDATA[Generative AI]]></category><category><![CDATA[Machine Learning]]></category><category><![CDATA[Technology Platforms]]></category><category><![CDATA[AI & Machine Learning]]></category><category><![CDATA[Data, AI, & Machine Learning]]></category><category><![CDATA[New Product Development]]></category><category><![CDATA[Artificial Intelligence and Business Strategy]]></category><description><![CDATA[Jeremy King leads a team of 1,400 passionate engineers working on the continuous improvement of Pinterest’s image-driven platform. With a background that includes heading up a translation team at eBay and overseeing the technology behind Walmart’s U.S. retail stores and e-commerce business, Jeremy is now responsible for technology operations at Pinterest. To support the company’s [&#8230;]]]></description><content:encoded><![CDATA[<p></p><p> Jeremy King leads a team of 1,400 passionate engineers working on the continuous improvement of Pinterest&#39;s image-driven platform. With a background that includes heading up a translation team at eBay and overseeing the technology behind Walmart&#39;s US retail stores and e-commerce business, Jeremy is now responsible for technology operations at Pinterest. To support the company&#39;s mission to inspire people to “create a life that they love,” he and his team rely on advanced AI, machine learning, and a graph database to index and build a network of images so that users can find inspiration — particularly when they aren&#39;t completely sure what they&#39;re looking for.</p><p> On this episode of the <cite>Me, Myself, and AI</cite> podcast, Jeremy joins hosts Sam Ransbotham and Shervin Khodabandeh to talk about some recent advances Pinterest has made in the image-recognition space and shares his views on how generative AI will transform image-based content like Pinterest&#39;s. </p><aside class="callout-info"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/07/MMAI-S7-E6-King-Pinterest-headshot-3000-scaled.jpg" alt="杰里米·金"></p><h4> Jeremy King, Pinterest</h4><p> Jeremy King is senior vice president of technology at Pinterest, where he leads the company&#39;s technical vision and the engineering organization responsible for building and scaling a visual discovery engine.</p><p> Before joining Pinterest, he was CTO and senior vice president at Walmart, where he led the team responsible for the technology behind US retail stores and e-commerce for Walmart and Jet, and oversaw customer, merchant, and supply chain technologies across cloud and data platforms. King has also held executive-level technology roles at Walmart Labs, LiveOps, and eBay.</p></aside><aside class="callout-info fl mobile-fn mt40"><h5> AI for Leaders on LinkedIn<br /></h5><p style="font-size:1.4rem;"> If you&#39;re enjoying the <cite>Me, Myself, and AI</cite> podcast, continue the conversation with us on LinkedIn. Join the <a href="https://www.linkedin.com/groups/13977401/" class="marketing-click" id="AI_for_leaders_link[MMAI]">AI for Leaders</a> group today.</p><p class="is-button mt20"> <a href="https://www.linkedin.com/groups/13977401/" class="marketing-click" id="AI_for_leaders_link[MMAI]">Join now »</a></p></aside><p> Subscribe to <cite>Me, Myself, and AI</cite> on <a href="https://podcasts.apple.com/us/podcast/me-myself-and-ai/id1533115958">Apple Podcasts</a> , <a href="https://open.spotify.com/show/7ysPBcYtOPVgI6W5an6lup">Spotify</a> , or <a href="https://podcasts.google.com/feed/aHR0cHM6Ly9tZW15c2VsZmFuZGFpLmxpYnN5bi5jb20vcnNz">Google Podcasts</a> .</p><div id="toolkit-hardoon"></div><h4> Transcript</h4><p> <strong>Shervin Khodabandeh:</strong> How does an AI-based platform use generative AI to engage users? Find out on today&#39;s episode.</p><p> <strong>Jeremy King:</strong> I&#39;m Jeremy King from Pinterest, and you&#39;re listening to <cite>Me, Myself, and AI</cite> .</p><p> <strong>Sam Ransbotham:</strong> Welcome to <cite>Me, Myself, and AI</cite> , a podcast on artificial intelligence in business. Each episode, we introduce you to someone innovating with AI. I&#39;m Sam Ransbotham, professor of analytics at Boston College. I&#39;m also the AI and business strategy guest editor at <cite>MIT Sloan Management Review</cite> .</p><p> <strong>Shervin Khodabandeh:</strong> And I&#39;m Shervin Khodabandeh, senior partner with BCG and one of the leaders of our AI business. Together, <cite>MIT SMR</cite> and BCG have been researching and publishing on AI since 2017, interviewing hundreds of practitioners and surveying thousands of companies on what it takes to build and to deploy and scale AI capabilities and really transform the way organizations operate.</p><p> <strong>Sam Ransbotham:</strong> Welcome. Our guest today is Jeremy King, head of engineering at Pinterest. Jeremy, thanks for taking the time to talk with us.</p><p> <strong>Jeremy King:</strong> It&#39;s great to be here.非常感谢。</p><p> <strong>Sam Ransbotham:</strong> It&#39;s always good to start with an overview; maybe tell us a bit about what Pinterest does and what you do at Pinterest.</p><p> <strong>Jeremy King:</strong> Pinterest is, we like to say, the destination on the internet for inspiration. We have hundreds of millions of people that come to us every day to figure out what they want to wear, what they want to do this afternoon, or what they want to make for dinner, or how to decorate their kid&#39;s cake or remodel their kitchen. And so we want to build a platform that allows anyone to create a life that they love.</p><p> It&#39;s a great place to work with that kind of mission, and I have a lot of people who, when I tell them where I work, get pretty elated about their own Pinterest boards and what&#39;s going on in the world.</p><p> <strong>Sam Ransbotham:</strong> Great. Tell us more about working at Pinterest.</p><p> <strong>Jeremy King:</strong> I&#39;ve been at Pinterest now, the head of engineering, for just over four years. And just like any leader, I&#39;m trying to figure out how to unblock my team and hire great people. I tell people all the time that when I came to Pinterest, I was just so impressed with the level of talent. It&#39;s a relatively small team. We have 4,500 employees in the world and about 1,400 engineers. And as a result, competing against some of the biggest companies in the world, this team has to be extremely high caliber. We have some of the best graph database people in the world; we have the best computer vision people in the world. These people are really fun to work with.</p><p> <strong>Sam Ransbotham:</strong> None of that, so far, mentioned artificial intelligence, so, what role does artificial intelligence play with those 1,400 engineers?</p><p> <strong>Jeremy King:</strong> Yeah, that&#39;s an excellent point. One of the things that is true at Pinterest and now at many other companies is Pinterest was actually born with machine learning and AI from the base. It doesn&#39;t exist without it. So talking about AI and ML separately from Pinterest is almost like a misnomer; it really doesn&#39;t happen without it. Nearly everything that we do touches our machine learning systems. We do millions of inferences every second. Every single request comes all the way back to the graph and publishes back out a very specific use case to every single person.</p><p> It&#39;s not cached. … Every person has a specific result. I mentioned that we have about 1,400 engineers. We have about 350 machine learning engineers. As a percentage, when I tell other CTOs … they&#39;re like, “That&#39;s a really high percentage of machine learning people compared to my company.” That&#39;s true also on the data platform side; we have a wonderful leader, Dave Burgess, who runs our data platform. And you can imagine our data platform is about as important as any other part of our capabilities. And so I mentioned the graph, but it&#39;s also, you know, the sort of normal SQL databases and the real-time systems that keep this thing running.</p><p> <strong>Shervin Khodabandeh:</strong> Jeremy, you said “graphs” a couple of times. What&#39;s a graph?</p><p> <strong>Jeremy King:</strong> Essentially what a graph is, is if you take an entity, an object, and you say, “What&#39;s related to that object?” — so, in this case, we&#39;re using a nearest neighbor graph, which we&#39;ve written lots of documents on, which is saying, “Hey, I have an image, in this case, and I have another image that&#39;s related to this image.” So that allows me to build this sort of network of images. And the reason the graph works at Pinterest is because every pin is essentially added to a board, which essentially makes it a node in a graph, and so it continues to increase the graph.</p><p> So it allows you to … unlike a SQL database or a relational database, where you have to sort of tag indexes and indices, the graph can be indexed. Essentially any image could be indexed to any other image. It allows you to do searches on things that are related incredibly efficiently. That&#39;s the power of Pinterest.</p><p> <strong>Shervin Khodabandeh:</strong> Jeremy, you mentioned AI has been part and parcel of Pinterest&#39;s journey and has been ingrained in Pinterest&#39;s tech stack from its very early inception, so it must be that generative AI is all over the map for you guys as well, and I&#39;m sure it&#39;s on everybody&#39;s mind these days. So maybe tell us a bit about what you are doing there.</p><p> <strong>Jeremy King:</strong> We have a state-of-the-art machine learning environment that interconnects these data sets across all the surfaces. We call it the “home feed,” the search system, the related things that drive personalization and recommendations and engagement across Pinterest. [And] we&#39;re growing really fast from monthly active users. … Gen Z is growing even the fastest. We added 13 million monthly active users, so we&#39;re really focused on how to increase engagement.</p><p> And not surprisingly, a lot of the improvements in machine learning, even in the last two years, have been driving that engagement. We have, of course, built new features [that] allow Pinterest to become more shoppable. But as we&#39;re seeing the capabilities of the machine learning models getting effectively 10 or a hundred times bigger, which is relatively common today, we&#39;re seeing that give an outsize increase in our results as the result gets more specific.</p><p> And frankly, Pinterest is also about looking at [vastly] different things. So it&#39;s not [that] every single item is about “What do you want to cook for dinner tonight?” It&#39;s also “I know you were looking at birthday cakes last week” or “New Year&#39;s is coming up,” and we&#39;re going to interplay some of that. So we&#39;ve been taking advantage of some of the advanced AI capabilities that have only come to life over the last couple years. And that includes GPU [graphics processing unit] work and all the things that make it cost-effective to do these things.</p><p> So tying back to your question of generative AI, not surprisingly, given that we&#39;re an image platform, generative AI is very interesting to us, and I typically break it up into three buckets. When we&#39;re thinking about large language models — LLMs — we talk about, No. 1, how do I make my team more productive? We&#39;ve got a couple of pilots running. We haven&#39;t decided exactly which way to go yet, but it&#39;s looking really promising, and, like lots of other CTOs, we&#39;re really excited about that.</p><p> <strong>Shervin Khodabandeh:</strong> That&#39;s interesting. Tell us how generative AI increases efficiency.</p><p> <strong>Jeremy King:</strong> I was talking to a number of CTOs, and one thing I thought was really interesting is, this one particular CTO was saying that, in general, it&#39;s increased productivity by 10% to 15%, but there is a small set of users where it&#39;s increased their productivity by 50%.</p><p> <strong>Shervin Khodabandeh:</strong> That&#39;s fantastic. I was just going to say, it also feels like, if you go back a decade ago, there were lots of images and unstructured text and that kind of stuff that, for AI to train on that data and make sense of it, human intervention was needed, both to tag the content but also to make sure that the outputs made sense. And it feels like now, with gen AI, that a lot of those humanlike judgment calls are going to be made more and more with gen AI, particularly with lots of unstructured text and images and video and that kind of content. Is that right, or am I going too far?</p><p> <strong>Jeremy King:</strong> I think it&#39;s right. I mean, Pinterest&#39;s system is built on embedding, so you take an image or a piece of text and you essentially tag it — essentially, to your point, this is what Pinterest has really been great at. You take our computer vision technology and effectively build these embeddings to detect people or content or couches or birthday cakes.</p><p> We&#39;ve been really good at that and have really led the industry for a long time on this. And you&#39;re not wrong that what happens is, it just gets better; it gets more accurate, more specific. In the old days, I could say, “Hey, I know this is a lamp, and I know it&#39;s got pendants, and it&#39;s made of crystal, and it&#39;s gold,” and that sort of thing. But now I can say, “I know exactly how many tines it has on it; I know what kind of light bulbs they are; I know probably who manufactured it,” and these sorts of things. I can get way more specific.</p><p> And at Pinterest, we really think about these as two different things. People come to Pinterest because they don&#39;t know exactly what they want. And this is where Pinterest thrives, and I think why we have a long-term differentiation in the market. Because if you know what you want, you can always go to Amazon or Home Depot or Wayfair to go buy it, but if you don&#39;t know what you want, you start with Pinterest or do a million different searches because [you] don&#39;t know how to describe, you know, “classic barnyard kitchen” — [you] don&#39;t know those words.</p><p> So even putting it in something like ChatGPT, I don&#39;t know how to say that — you know what I mean? I&#39;m sure that&#39;ll get better over time, but a lot of it will be image-based, too, as well.</p><p> <strong>Shervin Khodabandeh:</strong> Are you finding that the foundational models that are available do it for you, or you&#39;re building your own domain-specific models?</p><p> <strong>Jeremy King:</strong> Both, I guess, is the answer. What we&#39;re finding — and it&#39;s still relatively early — in sort of the generative imagery, what we&#39;re finding is that the smaller models actually are much more specific, and so I think that&#39;s what&#39;s going to happen. And my CTO friends are saying the same thing, which is, each one of these models is going to be very specific to the use case, and that helps it not only be more accurate but also makes it much, much cheaper to implement as well.</p><p> <strong>Sam Ransbotham:</strong> I think it&#39;s interesting that you mentioned cakes several times, because decorating cakes is, I think, practically my only use of Pinterest. And it ties to Shervin&#39;s comment about generative, because I deeply suspect that those cakes that I see there, no human could create. I certainly can&#39;t create them. So to what degree are … people putting [up] images that don&#39;t really exist or products that don&#39;t exist? What&#39;s Pinterest&#39;s perspective on that?</p><p> <strong>Jeremy King:</strong> Excellent point. I think, yes, and we see this a lot [in] one of our biggest categories we call “art.” Art includes a whole bunch of things, including things that you would traditionally put on walls, and paintings, and that sort of thing. But it also includes things like body art, and we have tattoos and these sorts of things. And again, lots of those are great cases where people need a little bit of inspiration, and it can be generative, right? It may not exist in the world, but you want to see what it looks like on a human.</p><p> You can see this coming, where you&#39;ll be able to print out something that&#39;s generative. And this is already happening, right?</p><p> <strong>Sam Ransbotham:</strong> Yeah. That really aligns with the idea of inspiration.</p><p> <strong>Jeremy King:</strong> Yeah, absolutely. And things like cakes and that sort of thing are very interesting. One of the harder parts is, I&#39;ve seen lots of work for home and home improvement, but what it&#39;s doing is it&#39;s generating a whole bunch of ideas that can&#39;t be realized, where I can say, “Hey, people have yet to really break out the camera and take a picture of their room.” People do that, but we call it a 1% feature. Like, how do you get people to actually engage the phone or the phone camera?</p><p> But if you can upload an image — I&#39;ve seen some beautiful renderings of, like, “Here&#39;s what my room is. Rearrange the furniture in my room, the furniture I already have,” and things like that become really interesting. Or you say, “I want to replace this couch with this couch from Wayfair. I want to replace this lamp [with] some other lamp,” and here&#39;s 20 different combinations, and you can kind of click through it.</p><p> Those are like you&#39;re taking a virtual experience, almost AR-like [augmented reality-like], but you&#39;re putting real products in there versus them being generated products. But it allows you to build user experiences that are much more enhancing.</p><p> Last year, we built <a href="https://help.pinterest.com/en/article/try-on">AR Try On</a> , which allows you to try on makeup, and what we&#39;re seeing, again, while it doesn&#39;t get a ton of usage, the people that do use it are 60% more likely to buy something. It&#39;s amazingly engaging when people actually get there.</p><p> <strong>Sam Ransbotham:</strong> What&#39;s tough at Pinterest? You mentioned a lot of good use cases, where you&#39;re doing lots of things with these technologies. Certainly, [it] can&#39;t all be wonderful. What&#39;s hard?</p><p> <strong>Jeremy King:</strong> We spend a lot of time on inclusive search and results. In 2021, we launched hair-pattern search. It was kind of this first of technology: When you&#39;re searching for hairstyles, how do you identify hair that looks like yours? This is hugely important in order to refine what you&#39;re looking for.</p><p> We had these same kinds of problems with skin tone, where originally we were trying to use the early models for skin tone detection. And what we found is, it was more on face detection. And so our team had done some great work doing skin detection — it could be a side shot or a back shot or ear shot or a hand shot. You have no idea what kind of skin. So how do I detect what skin is? And then you can detect what kind of tone you&#39;re looking for.</p><p> Same thing had to be applied to hair. And we&#39;ve got all kinds of hair: We have shaved/bald, we have straight, we have wavy, we have curly, we have coily, we have protective, and these kinds of things make the results dramatically better.</p><p> You can save your hair pattern and your skin tone, and then we&#39;ll tailor your results to that. And as you can imagine, this is a complex problem. It&#39;s not just a USA thing; every different country has different types of hair patterns and skin tones and different kinds of fashion, and so these kinds of things are really hard, but they&#39;re the great projects to work on.</p><p> And we&#39;ve had a wonderful team. The advanced technology group here, in particular — we&#39;ve been working on inclusive technology and all these advanced models, and they&#39;re definitely hard, but they&#39;re wonderful when you get them right.</p><p> <strong>Shervin Khodabandeh:</strong> We have a segment here: five rapid questions. I&#39;ll just ask you a bunch of rapid-fire questions. Just tell me the first thing that comes to your mind. What&#39;s your proudest AI moment?</p><p> <strong>Jeremy King:</strong> The inclusive product feature, and actually, hair pattern was my proudest one, because not only was I involved [with] the product from the beginning, but it&#39;s also first in the industry. And the amount of response that we got from our pinners was incredible. So, yeah, it was a really good one.</p><p> <strong>Shervin Khodabandeh:</strong> What worries you about AI, aside from bias and some of the ethical issues?</p><p> <strong>Jeremy King:</strong> It&#39;s funny. It&#39;s on every single forum. It says, “Hey, are you worried about bias?”让我们来看看。 What worries me about AI?唔。 Yeah, I&#39;m not worried. I don&#39;t worry about too many things, but that&#39;s a CTO ...</p><p> <strong>Shervin Khodabandeh:</strong> That&#39;s good. That&#39;s a good thing though, right?</p><p> <strong>Jeremy King:</strong> That&#39;s a longtime CTO&#39;s thing. If you worry about too much, you can&#39;t survive in this job.</p><p> <strong>Shervin Khodabandeh:</strong> What&#39;s your favorite activity that does not involve technology?</p><p> <strong>Jeremy King:</strong> Mountain biking.</p><p> <strong>Shervin Khodabandeh:</strong> Very cool.</p><p> <strong>Jeremy King:</strong> I try and go at least two times a week. I go with a crew of Silicon Valley tech [colleagues] on Friday mornings and then usually on the weekends with my brother and a few other people.</p><p> <strong>Shervin Khodabandeh:</strong> The first career you wanted: What did you want to be when you grew up?</p><p> <strong>Jeremy King:</strong> I think my 5-year-old baby book says fireman, but both my grandfather and my father were engineers, so I actually thought I would build houses, because I loved working with my hands outside. So that&#39;s where I thought I was going to go — architecture or house-building.</p><p> <strong>Shervin Khodabandeh:</strong> What do you wish AI could do that it currently can&#39;t?</p><p> <strong>Jeremy King:</strong> Teleportation: Get me through the security line faster! Maybe that&#39;s coming. I&#39;ve always been super excited about translation. I took over the translation team at eBay way back when, and there were some wonderful people that were working on this. And I&#39;ve always thought about a universal translator as something that would just be so amazing. And it&#39;s getting so close, but it still seems like so far away before there&#39;ll be a consumer version of this device.</p><p> <strong>Shervin Khodabandeh:</strong> But why do you think that is? Because we&#39;ve got LLMs now, and we&#39;ve had, for a long time, audio to text. What&#39;s the limiting factor here?</p><p> <strong>Jeremy King:</strong> I think it&#39;s form factor; like, how do I get out my phone, hit “translate from Spanish to English” — you know, that kind of thing. I don&#39;t know; if I&#39;m walking up to a vendor in the street in San Francisco and I don&#39;t speak the same language, and I want something. … It&#39;s got to be close, but it&#39;s a form factor thing. But I think it&#39;ll come shortly.</p><p> <strong>Sam Ransbotham:</strong> Seems solvable.</p><p> <strong>Jeremy King:</strong> Yeah, solvable.</p><p> <strong>Sam Ransbotham:</strong> Jeremy, we really appreciate you taking the time to talk with us. It&#39;s been very interesting to learn, sort of behind the scenes, what&#39;s happening between all those images that we see but maybe didn&#39;t appreciate all that goes into making something that looks as easy as Pinterest work. And it&#39;s been pretty fascinating to see how much artificial intelligence and machine learning is behind that. Thanks for joining us.</p><p> <strong>Jeremy King:</strong> Of course. It&#39;s been wonderful.</p><p> <strong>Shervin Khodabandeh:</strong> Thanks for listening today. On our next episode, Sam and I meet with Damini Satija and Matt Mahmoudi from Amnesty International. Please join us.</p><p> <strong>Allison Ryder:</strong> Thanks for listening to <cite>Me, Myself, and AI</cite> . We believe, like you, that the conversation about AI implementation doesn&#39;t start and stop with this podcast. That&#39;s why we&#39;ve created a group on LinkedIn specifically for listeners like you. It&#39;s called AI for Leaders, and if you join us, you can chat with show creators and hosts, ask your own questions, share your insights, and gain access to valuable resources about AI implementation from <cite>MIT SMR</cite> and BCG. You can access it by visiting <a href="https://mitsmr.com/AIforLeaders">mitsmr.com/AIforLeaders</a> . We&#39;ll put that link in the show notes, and we hope to see you there.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/audio/images-and-inspiration-with-ai-pinterests-jeremy-king/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item></channel></rss>