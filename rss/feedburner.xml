<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>麻省理工学院斯隆管理评论</title><atom:link href="http://sloanreview.mit.edu/feed/" rel="self" type="application/rss+xml"></atom:link><link/> https://sloanreview.mit.edu<description>可持续创新</description><lastbuilddate>2023 年 11 月 20 日星期一 12:00:47 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.4.1</generator><item><title>如何明智地利用人才市场</title><link/>https://sloanreview.mit.edu/article/how-to-start-smart-with-a-talent-marketplace/<comments> https://sloanreview.mit.edu/article/how-to-start-smart-with-a-talent-marketplace/#respond</comments><pubDate> Mon, 20 Nov 2023 12:00:47 +0000</pubDate> <dc:creator><![CDATA[Jeff Williamson and Donncha Carroll. <p>杰夫·威廉姆森 (Jeff Williamson) 是博思艾伦 (Booz Allen) 的人力资源主管。在 2019 年加入公司之前，他曾担任美国邮政服务首席人力资源官兼执行副总裁。 Donncha Carroll 是 Lotis Blue Consulting 的合伙人，也是该公司的数据科学负责人。他拥有近30年的咨询经验。</p> ]]>; </dc:creator><category><![CDATA[Employee Development]]></category><category><![CDATA[Employee Networks]]></category><category><![CDATA[Talent]]></category><category><![CDATA[Talent Development]]></category><category><![CDATA[Culture]]></category><category><![CDATA[Leadership]]></category><category><![CDATA[Skills & Learning]]></category><category><![CDATA[Talent Management]]></category><category><![CDATA[Workplace, Teams, & Culture]]></category><description><![CDATA[Carolyn Geason-Beissel/MIT SMR Many leaders can now make a strong case for establishing an internal talent marketplace, but getting one off the ground remains difficult. At Booz Allen, we experienced that truth during the first year after launching our pilot project. Here, we’ll examine some of the challenges we faced, how we overcame them, and [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/11/Williamson-1290x860-1.jpg" alt="" /><figcaption><p class="attribution">卡罗琳·吉森-贝塞尔/麻省理工学院 SMR</p></figcaption></figure><p>现在，许多领导者可以为建立内部人才市场提供强有力的理由，但要启动这个市场仍然很困难。在博思艾伦，我们在启动试点项目后的第一年就经历了这一事实。在这里，我们将研究我们面临的一些挑战、我们如何克服这些挑战，以及我们对变革管理和人才市场的了解。</p><p>拥有人才市场对博思艾伦来说是一个重要的变化。多年来，我们一直通过非正式的内部网络来部署专业员工，这些网络的运作基于您认识的人和您信任的人。但这条道路限制了我们利用现有资源以及将合适的人才与合适的工作相匹配的灵活性。更重要的是，它限制了我们的员工对自己职业道路的控制，从而损害了敬业度和保留率。</p><p></p><p>为了测试更好的方法，博思艾伦于 2022 年 1 月与 Lotis Blue Consulting 合作启动了人才市场试点项目。通过该试点项目，我们寻求解决人才管理挑战，这些挑战限制了增长并损害了我们向员工提供令人信服的价值主张的能力——即招聘、部署、人才发展、技术及其采用以及文化变革方面的问题。我们希望系统地、整体地解决这些问题，而不是引入单点解决方案，因为单点解决方案往往无法复合价值。</p><p>但激活和运营人才市场所需的文化转型水平是巨大的。解决一些人类行为和感知驱动的问题需要持续的努力，而克服这些问题是成功的关键。</p><h3>人才市场之路</h3><p>博思艾伦希望结束对以客户或团队为中心的传统招聘网络的依赖。这些高度本地化的网络使得很难在组织的其他部分找到满足企业、区域或本地需求的资源。相比之下，市场建立了一种集中的方法来评估需求并在整个企业范围内寻找人才（通过外部招聘、内部部署或技能提升），并创建了在整个组织中部署人员的能力。</p><p></p><p>市场试点的重点是技能而不是网络。这为员工提供了在整个企业中打开机会的新视野，也为管理者提供了对能够胜任工作的人才的新见解。这种对工作和发展机会的高分辨率视图极大地扩展了人们可以探索的范围，提高了员工敬业度并提供了更高水平的个人和企业绩效。该试点项目使试点人群空缺职位的内部填补率翻了一番，并获得了员工对透明度和寻求新机会的便利性的积极反馈。此外，这种基于技能的方法为代表性不足的候选人提供了更多在技术领域与公共部门客户合作的机会。</p><p>在试点的最初几个月，我们需要克服一些重要的挑战来激发兴趣和兴奋。最重要的是，我们需要为市场提供足够数量的高质量机会和可用人才，以吸引员工和经理。在此过程中，我们学到了一些重要的经验教训——尤其是在变革管理方面。</p><h4>第 1 课：进行游戏化。</h4><p>随着客户的环境和需求不断变化，我们的工作性质也在不断变化，我们看到需求技能组合正在迅速变化。我们的技术人才完成客户任务的能力取决于他们学习和适应的速度。</p><p>为了解决这个问题，博思艾伦的战略人才发展负责人 Jim Hemgen 及其学习与发展 (L&amp;D) 团队在市场试点的同时设计并启动了徽章计划。该计划旨在通过阐明不同的职业道路和获得不同机会所需的技能来发展战略企业能力。为了获得徽章，员工需要获得证书并让经理验证他们在工作中应用了该技能。这种游戏化的学习方式为那些投资于自身发展的员工提供了认可和奖励。</p><p> L&amp;D 团队让公司的大部分技术人员通过内部徽章和外部认证的结合来构建战略能力。去年，员工获得了 4,000 多枚对企业未来至关重要的徽章或认证。</p><p></p><h4>第 2 课：数据目标必须与个人职业目标相关。</h4><p>我们遇到了与试点相关的几个技术挑战，包括数据结构（建立正确的职位架构）、数据质量（例如确保技能数据完整）和算法设计（如何最好地执行人才和开放的推荐流程）。职位）。</p><p>为了获得完整的技能数据，我们需要广泛采用。事实上，采用率与用户期望从平台获取的价值密切相关。当员工和经理探索功能和好处时，我们起步缓慢。</p><p> 2023 年 1 月，市场运营负责人 John Grumbine 帮助推出了内部网络应用程序 Career Hub，情况发生了变化。该应用程序为员工提供了一站式服务，帮助他们在以下领域寻找工作、培训和发展、导师和社区。基于他们的技能和偏好的人才市场。现在，员工对保持自己的技能和偏好处于最新状态符合既得利益，因为这些信息可以推动他们获得机会、培训和导师的建议；此外，它还推动了寻求填补职位空缺的项目经理如何发现或识别他们。</p><p> Career Hub 应用程序的推出导致人才市场采用率大幅增加。截至 2023 年 9 月，超过 50% 的博思艾伦员工已加入职业中心，并获得工作、学习和指导机会。</p><h4>教训 3：即使是变革管理也需要改变。</h4><p>在文化转型领域，试点启动后，我们很快遇到了四个关键挑战。 （参见“需要克服的四大文化挑战。”）</p><div class="callout-highlight"><aside class="l-content-wrap"><article><h4>需要克服的四大文化挑战</h4><p class="caption">当您领导与人才市场相关的文化变革时，您可能会遇到以下问题：</p><table id="Chart#" class="no-mobile"><thead><tr><th>挑战</th><th>商业影响</th></tr></thead><tbody><tr><td><p><strong>管理者希望保留最好的资源，或者担心成为开放市场上的人才净输出者。</strong><p></td><td><p>高绩效人才不是离开团队，而是离开组织。</p></td></tr><tr><td><p><strong>员工不愿意公开寻求调动，因为担心他们会显得对现任主管不忠诚。</strong><p></td><td><p>随着时间的推移，被俘员工的敬业度和绩效会下降。</p></td></tr><tr><td><p><strong>项目经理不愿意接受他们个人不了解的资源，也不愿意相信来自他们个人网络之外的经理的建议。</strong></p></td><td><p>为每个项目组建合适的团队更具挑战性。招聘过程需要更长的时间，并且更容易受到招聘经理的偏见的影响。</p></td></tr><tr><td><p><strong>招聘经理会拒绝那些不太完美的申请人，因为他们通常只需要少量投资即可缩小技能差距。</strong></p></td><td><p>员工的参与度会降低，工作绩效也会因与个人兴趣不一致而下降。 </p></td></tr></tbody></table><p><!--IMAGE FALLBACK FOR MOBILE BELOW --><br /><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/11/Williamson_Talent_Essay_Table.png" alt="需要克服的四大文化挑战" class="no-desktop" /><br /></article></aside></div><p>这些挑战导致了很多问题。作为回应，我们的团队优先考虑了几项重要行动来推动我们所需的文化变革：</p><ul><li>建立、完善和制定基于技能的人才档案，以更清晰地了解人们可以或已经完成的工作。</li><li> （最初）关注大量需求的工作资料，以在系统中创造足够的流动性，使参与者有机会流动。</li><li>组建一个小型、敏捷、以行动为导向的运营团队，在出现不同挑战时与主题专家（例如来自业务领导和人才招聘的专家）进行协作。</li><li>以市场导航员的形式提供以人为本的支持——专门负责帮助所有参与者（员工和经理）遵循市场规则和指南并从平台获得最大价值的人员。</li></ul><p>所有这些步骤都可以纳入人才市场的启动计划中。</p><h4>第 4 课：势头、动机和衡量标准非常重要。</h4><p>从较高层面来看，同时推出集成人才管理系统的多项服务非常重要，以便超出预期并建立采用势头。</p><p>为了实现行为改变，领导者必须深入了解不同人员的动机，以及他们所做的改变将如何满足人们的需求。该试点项目提供了有关市场效用的宝贵反馈，帮助确定增强功能的优先级，并建立了支持设计发展和扩展所需的变更管理水平。</p><p></p><p>监控和衡量市场绩效帮助我们的团队尝试新事物、快速失败并不断提高市场对参与者的价值。更具体地说，我们的指标包括发布的机会数量、这些机会的趋势、按发布类型划分的员工兴趣的水平和广度、老化机会（长期空缺的机会）的百分比以及职位的百分比填充。这些数据帮助我们评估平台的健康状况和强度，并让我们深入了解系统调整如何影响性能。</p><h3>致力于持续改进</h3><p></p><p>通过人才市场和我们的其他人才系统投资，我们正在提供更好的员工价值主张。试点后，我们的员工保留率提高了 4% 以上。然而，这个旅程永远不会结束。对不断发展的人才以及解决方案的持续投资对于企业的成功至关重要。</p><p>解决沿途出现的障碍是整个旅程的一部分，最终会带来更好的设计和更好的结果。人才市场在当今不断发展的劳动力市场中提供了重要的好处：通过优先考虑员工的流动性和发展，公司可以更好地适应不断变化的技能要求，并在员工队伍中实现更高水平的创新、协作和灵活性。</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/how-to-start-smart-with-a-talent-marketplace/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>在转型过程中平衡变化和连续性</title><link/>https://sloanreview.mit.edu/video/balancing-change-and-continuity-during-a-transformation/<comments> https://sloanreview.mit.edu/video/balancing-change-and-continuity-during-a-transformation/#respond</comments><pubDate> Thu, 16 Nov 2023 15:03:53 +0000</pubDate> <dc:creator><![CDATA[Carsten Lund Pedersen and Laurianne McLaughlin. <p>Carsten Lund Pedersen 是丹麦哥本哈根信息技术大学的副教授。 Laurianne McLaughlin 是<cite>《麻省理工斯隆管理评论》</cite>的数字高级编辑。她主持了会议。</p> ]]>; </dc:creator><category><![CDATA[Change Management]]></category><category><![CDATA[Organizational Culture]]></category><category><![CDATA[Organizational Learning]]></category><category><![CDATA[Culture]]></category><category><![CDATA[Skills & Learning]]></category><category><![CDATA[Workplace, Teams, & Culture]]></category><description><![CDATA[Related Reading C.L. Pedersen, &#8220;Cracking the Culture Code for Successful Digital Transformation,&#8221; MIT Sloan Management Review, April 6, 2022. As digital transformation work unfolds, many companies find cultural barriers insurmountable. Why? Because leaders often fail to strike the right balance between continuity and change, creating cultural chaos that stalls progress. Carsten Lund Pedersen, associate professor [&#8230;]]]></description><content:encoded><![CDATA[<p></p><aside class="callout-info"><h5 style="margin-top:0">相关阅读</h5><p>CL Pedersen，“ <a href="https://sloanreview.mit.edu/article/cracking-the-culture-code-for-successful-digital-transformation/" class="marketing-click" id="Sidebar_callout[WebinarArchive]">破解成功数字化转型的文化密码”</a> ，《<em>麻省理工学院斯隆管理评论》</em> ，2022 年 4 月 6 日。</p></aside><p>随着数字化转型工作的展开，许多公司发现文化障碍难以克服。为什么？因为领导者往往无法在连续性和变革之间取得适当的平衡，从而造成文化混乱，阻碍进步。</p><p>丹麦哥本哈根 IT 大学数字化转型副教授 Carsten Lund Pedersen 帮助组织找到这种平衡。</p><p>在本次网络研讨会中，您将了解到：</p><ul><li>为什么许多组织在数字化转型过程中遭遇身份危机。</li><li>为什么领导者需要表现<em>出</em>对变革的开放态度和对现有文化的尊重。</li><li>如何使用矩阵工具和成功实现支持真正转型的文化转变的公司的示例来平衡变革和连续性。</li></ul><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/video/balancing-change-and-continuity-during-a-transformation/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>营销预算平均值的终结</title><link/>https://sloanreview.mit.edu/article/the-end-of-averages-for-marketing-budgets/<comments> https://sloanreview.mit.edu/article/the-end-of-averages-for-marketing-budgets/#respond</comments><pubDate> Thu, 16 Nov 2023 12:00:31 +0000</pubDate> <dc:creator><![CDATA[Nader Tavassoli and Christine Moorman. <p>纳德·塔瓦索利 (Nader Tavassoli) 是伦敦商学院市场营销学教授兼领导力学院联席学术主任。他还是 CMO 调查的英国主管。 Christine Moorman 是杜克大学福卡商学院 T. Austin Finch 工商管理高级教授。她是《CMO Survey》的创始人和主任，也是<cite>《营销杂志》</cite>的前主编。</p> ]]>; </dc:creator><category><![CDATA[Financial Strategy]]></category><category><![CDATA[Resource Allocation]]></category><category><![CDATA[Digital Marketing]]></category><category><![CDATA[Marketing]]></category><category><![CDATA[Marketing Strategy]]></category><description><![CDATA[Carolyn Geason-Beissel/MIT SMR In his 2015 book The End of Average, Todd Rose warns against “averagarians” designing systems based on the mean or judging success in terms of the deviation from the mean. He highlights Gilbert Daniels, an anti-averager hero, whose research in the 1950s led the U.S. Air Force to design planes with personalized [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/11/Moorman-1290x860-1.jpg" alt="" /><figcaption><p class="attribution">卡罗琳·吉森-贝塞尔/麻省理工学院 SMR</p></figcaption></figure><p>托德·罗斯 (Todd Rose) 在其 2015 年<cite>出版的《平均的终结》</cite>一书中警告说，不要“平均主义者”根据平均值设计系统或根据与平均值的偏差来判断成功。他重点介绍了吉尔伯特·丹尼尔斯 (Gilbert Daniels)，一位反平均英雄，他在 20 世纪 50 年代的研究引领美国空军设计了具有个性化驾驶舱功能的飞机，以适应各种体型和体型的飞行员，而不仅仅是普通的男性飞行员——这一创新极大地提高了安全性记录。</p><p>营销策略还取决于差异化原则。考虑细分：营销人员往往不会为普通消费者设计产品或服务。事实上，像红牛这样两极分化的品牌都以这样的观念为荣：讨厌他们的产品的人和喜欢它的人一样多。</p><p>然而，在营销预算方面，一种常见但有缺陷的做法是使用善意研究人员吹捧的平均数字。两项最成熟的检查营销预算的 CMO 调查是杜克大学每两年进行一次的 CMO 调查（自 2008 年起由本文的第二作者开展）和 Gartner 的年度 CMO 支出和策略调查。 CMO 调查发现，2023 年营销预算平均占美国收入的 11%，Gartner 发现 2023 年预算占北美和欧洲部分地区公司总收入的 9.1%。 <a id="reflink1" class="reflink" href="#ref1">1</a></p><p>我们从经验中知道，这些平均值常常被视为表面价值。当预算低于平均水平时，首席营销官不可避免地会抱怨需要更多的消费能力。当它们高于平均水平时，首席财务官可以找到理由收紧财务管理。</p><p>然而，我们认为，平均营销预算对于规划目的可能会产生很大的误导。 CMO 应该留意 Monty Python 的电影<cite>《布莱恩的一生</cite>》——“你们都是独立的个体。 ……你们都得自己想办法！” ——并选择适当的同行基准。为了帮助领导者做到这一点，我们通过新的视角分析了营销预算数据。</p><p></p><h3>关键区别：CMO 的控制范围</h3><p>那么，如果平均营销预算不正确，哪个尺寸合适呢？这得看情况。首先，平均数掩盖了系统性部门差异。例如，CMO 调查显示，B2C 营销预算平均占收入的 13.9%，往往高于 B2B 预算（平均占收入的 9.3%）。从不同的角度来看，产品品牌的营销预算往往更高，占收入的 11.4%，而服务品牌则占 10.3%。销售额为 1000 万美元或以下的公司拥有最大的预算（占收入的 16.8%），但对于销售额为 100 亿美元或以上的公司，这一数字下降至 9.5%。同样，员工人数为 50 人或以下的公司的预算超过 17%，但员工人数为 10,000 人或以上的公司则降至 9.8%。</p><p>但为什么公司规模很重要，为什么 B2C 和产品品牌预算高于 B2B 和服务品牌预算？为了研究这个问题，CMO 调查向 314 名营销领导者询问了他们的战略职责的广度。我们发现，影响营销预算的一个重要因素是 CMO 对不同类型公司的控制范围。结果突显了基于这些职责的营销预算的显着偏差，并完全考虑了基于公司规模的变化。事实上，我们下面提到的营销责任占部门之间差异的 71% 以上。换句话说，虽然同行基准预算方法可能很有吸引力，但它也具有误导性。</p><p></p><p>我们的研究表明，在 28% 的受访公司中，营销人员的工作描述并未超出沟通范围，延伸至销售或电子商务等运营职责。对于那些“仅限通信”的公司，营销预算大约是平均水平的一半，为 5.6%。 （沟通活动几乎普遍包括定位、品牌广告、数字品牌推广、公关、社交媒体和/或潜在客户开发。）在仅限 B2B 沟通的公司中，营销预算为 5.9%，不到三分之二。行业平均水平，而在 B2C 公司中，这一比例仅为区区 4%，不到行业平均水平的三分之一。服务（6.1%）和产品品牌（5.1%）的比较也讲述了类似的故事。令人惊讶的是，对于这些仅限通信的品牌，B2B 和服务公司的预算实际上比 B2C 和产品品牌的预算要大——这与我们在平均分析中看到的相反。</p><h3>战略营销人员拥有最大的预算</h3><p>在营销不仅负责沟通而且还负责至少一项关键<em>运营</em>活动（例如销售、分销、客户服务和体验、电子商务或客户关系管理）的公司中，平均预算较高，约为 7.6%的收入。</p><p>与纯通信组织一样，B2B 预算 (8.1%) 高于 B2C 预算 (5.7%)。然而，在这些营销加运营的公司中，产品品牌的预算（8.6%）重新高于服务品牌的预算（6.8%），考虑到前者的渠道成本可能更高，这是有道理的。话虽如此，即使在更广泛的控制范围内，预算仍然低于平均水平，即使在部门层面也是如此。</p><p>真正的改变者是在公司的营销职责中增加至少一项<em>战略</em>活动，例如新产品和创新、市场选择和进入、定价或增长。其中一些领域传统上是商学院作为营销职能教授的，但在许多公司中并不属于营销的范畴。各公司负责沟通、运营和战略的营销职能的平均预算为 13.4%。其中，B2C 品牌（15%）现在高于 B2B 品牌（11.8%），因为 B2C 营销人员往往比 B2B 营销人员拥有更广泛的控制范围。有趣的是，这些公司的服务预算（14.5%）也高于产品品牌预算（12.8%），这可能是由于客户体验支出。</p><p>可以考虑更多的控制领域。当营销除了上述更传统的营销功能之外还负责隐私时，总体预算将跃升至收入的 17.7%。如果加上人才管理，营销预算占收入的比例高达 23%。然而，这里的比较变得不可靠，特别是在行业层面，因为营销负责人才（11.5%）或隐私（9%）等领域的公司相对较少。</p><p></p><p></p><p>这个故事的寓意是什么？如果您的预算制定过程依赖于平均值作为基准或人群的智慧，请确保您使用正确的人群作为同行比较。这需要确定一个与您公司的责任概况相匹配的基准。我们的首席营销官调查分析现在提供了一种方法来做到这一点。虽然上述数字没有提供个性化基准，但它们比研究报告和大众媒体中通常提出的广泛平均值更有意义。</p><p>首席营销官的最后一个想法是，这不仅仅是钱的问题。高于平均水平的预算伴随着高于平均水平的责任。这就是组织设计的一个主题：选择适合公司战略和营销能力的职责分配。</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/the-end-of-averages-for-marketing-budgets/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>联合利华的人工智能道德：从政策到流程</title><link/>https://sloanreview.mit.edu/article/ai-ethics-at-unilever-from-policy-to-process/<comments> https://sloanreview.mit.edu/article/ai-ethics-at-unilever-from-policy-to-process/#respond</comments><pubDate> Wed, 15 Nov 2023 18:00:20 +0000</pubDate> <dc:creator><![CDATA[Thomas H. Davenport and Randy Bean. <p>Thomas H. Davenport ( <a href="https://twitter.com/tdav">@tdav</a> ) 是巴布森学院信息技术与管理学校长杰出教授、牛津大学赛德商学院客座教授以及麻省理工学院数字经济项目研究员。他是<cite>《Working With AI: Real Stories of Human-Machine Collaboration》</cite> （麻省理工学院出版社，2022 年）一书的合著者。 Randy Bean ( <a href="https://twitter.com/randybeannvp">@randybeannvp</a> ) 是一位行业思想领袖、作家、创始人兼首席执行官，目前担任全球咨询公司 Wavestone 的创新研究员、数据战略部门。他是<cite>《快速失败，更快学习：颠覆、大数据和人工智能时代数据驱动领导力的教训》一书</cite>的作者（Wiley，2021 年）。</p> ]]>; </dc:creator><category><![CDATA[AI Strategy]]></category><category><![CDATA[Analytics & Organizational Culture]]></category><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Ethics]]></category><category><![CDATA[AI & Machine Learning]]></category><category><![CDATA[Data, AI, & Machine Learning]]></category><category><![CDATA[IT Governance & Leadership]]></category><category><![CDATA[Managing Technology]]></category><description><![CDATA[Carolyn Geason-Beissel/MIT SMR &#124; Getty Images Many large companies today — most surveys suggest over 70% globally — have determined that artificial intelligence is important to their future and are building AI applications in various parts of their businesses. Most also realize that AI has an ethical dimension and that they need to ensure that [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/11/Davenport-1290x860-1.jpg" alt="" /><figcaption><p class="attribution">卡洛琳·吉森-贝塞尔/麻省理工学院 SMR |盖蒂图片社</p></figcaption></figure><p>如今，许多大公司（大多数调查显示全球超过 70% 的公司）已经确定人工智能对其未来很重要，并正在其业务的各个部分构建人工智能应用程序。大多数人还意识到人工智能具有道德维度，他们需要确保他们构建或实施的人工智能系统是透明、公正和公平的。</p><p>到目前为止，许多追求道德人工智能的公司仍处于解决这个问题的早期阶段。他们可能会劝告员工采取符合道德的方法来开发和使用人工智能，或者起草一套初步的人工智能治理政策。大多数人连这一点都没有做到。在<a href="https://www.conversica.com/conversation-automation-resources/report/ai-ethics-survey/">最近的一项调查</a>中，73% 的美国高级领导人表示，他们认为人工智能道德准则很重要，但只有 6% 的人制定了这些准则。</p><p></p><p>我们看到人工智能道德流程的五个阶段：<em>传福音</em>，公司代表谈论人工智能道德的重要性；<em>制定政策</em>，公司审议并批准围绕人工智能道德方法的公司政策；<em>记录</em>，公司收集每个人工智能用例或应用程序的数据（使用<a href="https://www.forbes.com/sites/tomdavenport/2021/05/27/the-future-of-work-now-ethical-ai-at-salesforce/?sh=312432713eb6">模型卡</a>等方法）；<em>审查</em>，公司对每个用例进行系统分析（或将其外包给合作伙伴公司），以确定该案例是否符合公司的人工智能道德标准；和<em>行动</em>，公司要么按原样接受用例，要么将其发送回提议所有者进行修改，要么拒绝它。</p><p>只有在更高级别的阶段（审查和行动），公司才能真正确定其人工智能应用程序是否符合其制定的透明度、偏见和公平标准。为了使这些阶段到位，它必须拥有大量用于收集信息的人工智能项目、流程和系统，以及用于对特定应用程序做出决策的治理结构。许多公司尚未具备这些先决条件，但随着公司表现出更大的人工智能成熟度和重视度，这些先决条件将是必要的。</p><h3>联合利华的早期政策</h3><p>联合利华是英国消费品包装公司，旗下品牌包括多芬 (Dove)、第七代 (Seventh Generation) 和本杰瑞 (Ben &amp; Jerry&#39;s)，长期以来一直注重企业社会责任和环境可持续发展。最近，该公司已将人工智能作为一种显着改善其全球业务运营和决策的手段。联合利华的企业数据执行官（一个治理委员会）认识到，公司可以通过将人工智能的负责任和合乎道德的使用嵌入到公司的数据战略中，建立强大的隐私、安全和治理控制。目标是利用人工智能驱动的数字创新，最大限度地发挥公司的能力，并促进社会更加公平和公正。成立了一个多功能团队，其任务是探索这在实践中意味着什么，并制定行动计划来实现该目标。</p><p>联合利华现在已经实施了上述所有五个阶段，但回顾过去，其第一步是制定一套政策。例如，一项政策规定，任何会对个人生活产生重大影响的决定不应完全自动化，而应最终由人类做出。其他采用的特定于人工智能的原则包括“我们永远不会责怪系统；我们永远不会责怪系统”的法令。必须有联合利华所有者负责”并且“我们将尽最大努力系统地监控模型和人工智能的性能，以确保其保持其有效性。”</p><p>委员会成员很快意识到，仅制定广泛的政策不足以确保人工智能的负责任发展。为了建立对人工智能采用的信心并真正释放其全部潜力，他们需要开发一个强大的工具、服务和人力资源生态系统，以确保人工智能系统能够按预期工作。</p><p></p><p>委员会成员还知道，联合利华的许多人工智能和分析系统是与外部软件和服务供应商合作开发的。例如，该公司的广告代理商经常使用程序化购买软件，该软件使用人工智能来决定在网络和移动网站上放置哪些数字广告。该团队的结论是，其人工智能道德方法需要包括对外部来源能力的关注。</p><p></p><h3>开发强大的人工智能保障流程</h3><p>在联合利华使用人工智能的早期，该公司的数据和人工智能领导者注意到，该技术的一些问题根本不涉及道德——它们涉及的系统在完成预期任务时效率低下。联合利华全球数据科学总监 Giles Pavey 主要负责人工智能道德规范，他知道这是人工智能用例的重要组成部分。 “例如，预测现金流的系统可能不涉及公平或偏见风险，但可能存在一些无效的风险，”他说。 “我们决定将功效风险与我们评估的道德风险一起纳入其中。”该公司开始使用<em>“人工智能保证”</em>一词来广泛涵盖其对工具有效性和道德规范的概述。</p><p>联合利华人工智能保证合规流程背后的基本理念是检查每个新的人工智能应用程序，以确定其在有效性和道德方面的内在风险有多大。该公司已经制定了明确的信息安全和数据隐私方法，目标是采用类似的方法，确保人工智能应用程序在未经审查和批准的情况下不会投入生产。将合规流程整合到联合利华已有的合规领域（例如隐私风险评估、信息安全和采购政策）将是成功的最终标志。</p><p> Debbie Cartledge 担任公司数据和人工智能道德战略负责人，她解释了团队采用的流程：</p><blockquote><p>当规划新的人工智能解决方案时，联合利华员工或供应商会在开发之前提出概述的用例和方法。这是内部审查的，更复杂的案例则由外部专家手动评估。然后，提议者被告知潜在的道德和功效风险以及需要考虑的缓解措施。人工智能应用程序开发完成后，联合利华或外部方会进行统计测试，以确定是否存在偏见或公平问题，并检查系统实现其目标的有效性。随着时间的推移，我们预计大多数案例都可以根据项目提案人提供的项目信息进行全面自动评估。</p></blockquote><p>根据系统在公司内部的使用位置，系统还可能需要遵守当地法规。例如，所有简历检查现在都是由人工审核员完成。如果简历检查完全自动化，审查可能会得出这样的结论：系统需要有人参与其中，以做出是否让候选人参加面试的最终决定。如果存在无法缓解的严重风险，人工智能保证流程将拒绝该申请，理由是联合利华的价值观禁止这样做。人工智能用例的最终决定由高级执行委员会做出，其中包括来自法律、人力资源、数据和技术部门的代表。</p><p>举个例子：该公司在百货商店设有销售其化妆品品牌的区域。开发了一个项目，利用计算机视觉人工智能通过日常自拍照自动记录销售代理的出勤情况，其延伸目标是查看代理的外表是否合适。由于人工智能保证流程，项目团队拓宽了他们的思维范围，超越了法规、合法性和有效性，还考虑了全自动系统的潜在影响。他们认为需要人工监督来检查标记为不合规的照片，并对任何后续行动负责。</p><h3>与外部合作伙伴合作，整体人工智能</h3><p>联合利华在人工智能保证流程中的外部合作伙伴是总部位于伦敦的 Holistic AI 公司。创始人 Emre Kazim 和 Adriano Koshiyama 自 2020 年以来一直与联合利华 AI 团队合作，Holistic AI 于 2021 年成为 AI 风险评估的正式合作伙伴。</p><p> Holistic AI 创建了一个平台来管理 AI 保证审查流程。在这种情况下，“人工智能”是一个广泛的类别，涵盖任何类型的预测或自动化；甚至用于对人力资源候选人进行评分的 Excel 电子表格也将包含在该流程中。联合利华的数据道德团队使用该平台审查人工智能项目的状态，并可以查看哪些新用例已提交；信息是否完整；以及他们收到的风险级别评估，编码为红色、黄色（在英国称为“琥珀色”）或绿色。</p><p>交通信号灯状态在三个点进行评估：分类时、进一步分析后以及最终缓解和保证后。最后一点，评级有以下解释： 红色评级表示人工智能系统不符合联合利华标准，不应部署；黄色表示人工智能系统存在一些可接受的风险，企业主有责任了解并承担责任；绿色意味着人工智能系统不会给流程带来任何风险。迄今为止，联合利华的数百个用例中只有少数获得了红色评级，包括上述化妆品。所有提交者都能够解决其用例中的问题，并将其提高到黄色评级。</p><p>对于AI项目的领导者，该平台是开始审核过程的地方。他们提交了拟议的用例，其中包括其目的，业务案例，联合利华公司内的项目所有权，团队组成，所使用的数据，所采用的AI技术类型，无论是在内部开发还是由外部供应商，自治程度，等等。该平台使用该信息根据其潜在风险来评分应用程序。风险领域包括解释性，鲁棒性，功效，偏见和隐私。机器学习算法会自动分析，以确定它们是否偏向任何特定组。</p><p></p><p>整体AI平台中评估的比例越来越多，是基于欧盟提议的AI法案，该法案还将AI用例列为三类风险（不可接受，高且不足以受到监管）。该法案正在欧盟国家进行谈判，希望在2023年底之前达成协议。Kazim和Koshiyama表示，即使该法案仅适用于欧洲企业，联合利华和其他公司可能会像全球那样采用它，就像与他们一起采用。欧盟的一般数据保护法规。</p><p></p><p> Kazim和Koshiyama希望整体AI能够在将来跨公司汇总数据，并在未来进行基准测试。该软件可以评估福利与成本，同一用例的不同外部提供商的功效以及最有效的AI采购方法。 Kazim和Koshiyama还考虑在某些情况下公开将风险评级公开，并与保险公司合作，以确保AI用例使用某些类型的风险。</p><p>我们仍处于<a href="https://sloanreview.mit.edu/big-ideas/responsible-ai/">确保公司对AI采取道德方法</a>的早期阶段，但这并不意味着足以发出没有牙齿的声明和政策。 AI是否是道德的，将通过用例确定用例。联合利华的AI保证过程及其与整体AI的合作伙伴关系，以评估每个用例有关其道德风险水平，是确保AI系统与人类利益和福祉保持一致的唯一方法。</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/AI-ETHICS-ETHICS-AT--NILEVER-FROM-POLICY-POLICET-TO-PROCESS/FEED/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>中国出境禁令和劫持人质事件的兴起</title><link/>https://sloanreview.mit.edu/article/the-rise-of-exit-bans-and-bans-and-hostage-taking-in-china/<comments> https://sloanreview.mit.edu/article/the-rise-of-exit-bans-and-bans-and-hostage-taking-in-in-china/#respond</comments><pubDate> Wed, 15 Nov 2023 12:00:18 +0000</pubDate> <dc:creator><![CDATA[Jack Wroldsen and Chris Carr. <p>杰克·沃尔德森（Jack Wroldsen）是加利福尼亚州圣路易斯·奥比斯波（San Luis Obispo）的Orfalea商学院商业法和公共政策助理教授。他是智利的NSEP学者，还在阿根廷和墨西哥学习和工作。克里斯·卡尔（Chris Carr）是圣路易斯·奥比斯波（San Luis Obispo）奥尔法利亚商学院的商业法和公共政策教授。他还是四届富布赖特奖获得者（意大利，突尼斯，巴基斯坦和蒙古）。</p> ]]>; </dc:creator><category><![CDATA[China]]></category><category><![CDATA[Crisis Management]]></category><category><![CDATA[Global Business]]></category><category><![CDATA[International Business]]></category><category><![CDATA[Leadership]]></category><category><![CDATA[Frontiers]]></category><description><![CDATA[Michael Austin/theispot.com Foreign entities doing business in China are facing increasingly grave risks. On top of the high-level geopolitical and economic risks to consider, the growing incidence of exit bans, which prevent foreign executives from leaving China if their company becomes involved in a dispute, imposes a very individual human risk. While there has been [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/11/2024WINTER-Carr_1290x860.jpg" alt="" /><figcaption><p class="attribution">迈克尔·奥斯汀/theispot.com</p></figcaption></figure><p>在中国开展业务的外国实体面临着越来越严重的风险。除了要考虑的高层地缘政治风险和经济风险外，出口禁令的发生率的日益增长，如果他们的公司参与争议，则防止外国高管离开中国，还施加了非常个体的人类风险。尽管媒体广泛报道了几个案件，但美国调查公司Mintz Group的新加坡高管进行了退出禁令，并<a href="https://www.bbc.com/news/world-asia-china-65061116">拘留了五名中国雇员</a>；对在加拿大被捕的华为高管提出的对美国欺诈指控进行报复的<a href="https://www.nbcnews.com/news/world/huawei-s-meng-wanzhou-2-michaels-what-next-china-u-n1280229">加拿大商人的案件拘留</a>，这是许多国际运作的公司，以相对晦涩难懂的现实和商业人质的现实。</p><p>这种风险正在增加，不太可能很快减轻。与公司高管或国外员工的拘留相比，在普通业务过程中，几乎没有什么破坏性或动荡的。在中国开展业务的公司应提前为这些潜在的情况做准备。</p><p></p><p>退出禁令可能是由民事企业纠纷以及更严重的法律纠缠引起的。 <a href="https://www.wsj.com/articles/new-chinese-law-raises-risks-for-american-firms-in-china-u-s-officials-say-cf62c1a0">最近对中国反临时法律的修正案</a>，包括关于拥有“与国家安全有关的文件，数据，材料或物品”的开放式禁令，可以轻松地涵盖任何行业中的日常业务活动，使外国高管面临更大的逮捕风险。 <a href="https://travel.state.gov/content/travel/en/traveladvisories/traveladvisories/china-travel-advisory.html">美国国务院最近警告说</a>，中国政府“任意执行当地法律，包括对其他国家的美国公民和公民发出退出禁令，没有法律规定的公平和透明的程序。”</p><p>出于商业原因而受到退出禁令的人通常不会在阻止在机场登机国际航班之前收到任何提前通知。该人通常会受到询问，但没有提供有关退出禁令或如何竞争的信息。</p><p>在业务纠纷的情况下，退出禁令通常只有在外国人加入中国对手的要求之后才能取消禁令，这会通过限制个人的个人自由来获得巨大的争议杠杆作用。即使外国人愿意花费必要的时间和金钱在被困在中国的同时在法庭上提起诉讼，中国法院也不太可能裁定有利于外国政党。</p><p></p><p>考虑一下亨利·凯（Henry Cai），他是中国人，他在1980年代与妻子一起移居加利福尼亚，并成为美国公民。 2012年，CAI投资了一家中国技术初创公司以获得8％的股份，并担任公司董事。几年后，当创业公司面临现金流问题并拖欠贷款时，CAI多次前往中国来应对这种情况。然后，在2017年，CAI在机场停了下来，并否认从中国退出，当时他意识到自己已与债权人提起的诉讼有关。六年后，他仍然<a href="https://www.wsj.com/articles/china-us-exit-ban-diplomacy-11668357015">陷入中国</a>，无法支付数百万美元要求取消退出禁令的费用。在中国以及他的妻子和他们在加利福尼亚的两个孩子中，人类，情感和经济上的伤害很高。</p><p></p><p>另一个例子是加利福尼亚商人布莱恩·霍洛维茨（Brian Horowitz），他从中国制造商那里购买了汽油供电的搅拌机。由于搅拌机未能达到加利福尼亚的空中质量标准，霍洛维茨出现了合同纠纷之后，霍洛维茨前往中国与供应商会面。当他试图返回家园时，他被<a href="https://www.latimes.com/archives/la-xpm-2011-jan-28-la-fi-china-horowitz-20110128-story.html">拘留在上海机场</a>。供应商已经对他的公司提出了合同索赔，法院在不知情的情况下实施了退出禁令。两周后，他的妻子向中国供应商开了25万美元，以允许她的丈夫回家。</p><p>在中国的商业纠纷中，出口禁令是合法的，但外国高管也有遇到非法商业人质情况的受害者的风险。在这种情况下，它们可能被限制在酒店房间或办公室或工厂等公司设施中。持有商业人质可处以最高三年的监禁。但是，实际上，除非发生暴力事件，否则中国<a href="https://foreignpolicy.com/2017/08/08/chinas-police-think-hostages-arent-their-problem/">执法部门通常拒绝</a>干预这些情况。</p><p>在一个案例中，一家美国珠宝公司的高级主管前往中国与制造商就产品订单和<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3692138">65万美元的付款</a>讨论争议。高管进入制造商的工厂后，她的钱包和护照被没收。然后，她被带回她的酒店，并由制造商的员工守卫五天。她在美国律师流利的中国律师的帮助下逃脱了，他们前往中国，帮助她逃避了警卫，并将她带到了大使馆。</p><p>当一家美国公司派遣两名中层高管参观为其生产商品的中国工厂时，发生了另一个案件。美国公司已经向制造商支付了商品，但其高管得知工厂工人拒绝释放产品，因为工资已经好几个月了。工人将高管锁定在工厂内，并要求付款以释放。为了释放人质并获取货物，美国公司必须同时向制造公司和工人付款。</p><p>商业人质的情况通常在几天或几周内解决，而出口禁令可能不会在数月或数年内取消。这两种情况都没有正式跟踪，商人经常将其困境保密。尽管如此，根据六个国家（美国，加拿大，英国，德国，荷兰和澳大利亚）的政府的数据，以及媒体报道，我们记录了过去<a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/tie.22261">100多个业务退出禁令和商业人质情况</a>十年。鉴于政府关于这一现象的文件并不全面，并且并非每一个案件都会受到媒体的关注，这可能是一个重大的低估。</p><h3>采用多方面的方法为最糟糕的情况做准备</h3><p>这些情况的敏锐个人性质和地缘政治动态使它们在计划和解决方面特别具有挑战性。您应该付出多少钱来释放同事（或您自己）被拘留人质？您如何与员工的配偶谈论伴侣被拘留的原因以及您的计划以返回的计划？与媒体互动以造成政治压力以释放雇员是您工作的一部分吗？</p><p>为了为这种情况做准备，至关重要的是，企业领导者承认这一危险会给他们的员工带来前往中国的雇员的风险，此外还可以通过与其他经历过的人进行对话来了解这一点。他们还应在公司运营，美国和州政府领导人，地方和国家媒体的成员以及适用的行业团体（例如美国 - 中国商业委员会。</p><p>公司应预先组装危机团队，并制定一项行动计划，该计划将特定责任分配给中国及其祖国的主要员工和顾问。该计划应包括外部沟通，例如使用社交媒体提请注意被困员工的困境。公司应咨询其商业保险公司，以找出是否可以使用任何相关的保险范围来减轻退出禁令或商业人质情况的财务影响。</p><p>在中国拥有商业利益的高管还应密切关注应付账款，合同义务以及业务关系的基调，以确定潜在的冲突或分歧来源。他们应该尝试在出现问题之前预见问题，并应特别警惕任何已交付产品的未偿债务或情况，但出于任何原因，尚未完全付款。</p><p></p><p>如果已或怀疑已诉讼或欠中国实体的任何债务，公司应避免雇员前往中国。如果不可避免地这样的旅行，员工应该保持频繁的沟通，以便其他人知道自己的下落和时间表，并且应该避免独自旅行。如果存在争议但尚未涉及诉讼，并且员工必须前往中国，请考虑在美国提起诉讼，假设美国法院对中国业务具有管辖权。例如，如果美国公司指控在美国法院违反合同，则该雇员应随身携带美国诉讼的文件，并在国外转化为中文。</p><p></p><p>领导者还必须准备支持和帮助员工及其家人。提前建立的危机团队应该制定一个计划，以诚实和敏感地与被困在国外，家人以及整个公司的员工进行诚实和敏感的沟通。证明你在乎。要透明和诚实。这些情况在情感上耗尽，迷失方向和令人恐惧。它们也是建立信任，团结和护理文化的机会。它更多的是关于人而不是金钱。</p><p>当然，重要的是要坚持以切实的方式帮助受影响的员工及其家人。安排向受影响家庭提供个性化护理套餐；参观他们的家，并与他们面对面。在可能的情况下，还将护理套餐发送给被困在国外的员工，并促进与家人的电话。</p><p>诸如退出禁令和商业人质情况之类的场景是人权和地缘政治问题，也是个人业务挑战。商业领导者明智的做法是通过开发全面的战略方法来为这些挑战做准备。</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/the-rise-of-exit-bans-and-bans-and-hostage-taking-in-in-china/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> RAI 项目是否为第三方和生成式人工智能做好了准备？</title><link/> https://sloanreview.mit.edu/article/are-rai-programs-pregred-for-third-party-party-and-generative-ai/<comments> https://sloanreview.mit.edu/article/are-rai-programs-pregred-for-third-party-party-and-generative-ai/#respond</comments><pubDate> Tue, 14 Nov 2023 12:00:11 +0000</pubDate> <dc:creator><![CDATA[David Kiron and Steven Mills. ]]></dc:creator><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Infographic]]></category><category><![CDATA[Policy Making]]></category><category><![CDATA[Risk Mitigation]]></category><category><![CDATA[AI & Machine Learning]]></category><category><![CDATA[Data, AI, & Machine Learning]]></category><category><![CDATA[IT Governance & Leadership]]></category><category><![CDATA[Managing Technology]]></category><category><![CDATA[Responsible AI]]></category><description><![CDATA[In 2023, MIT Sloan Management Review and BCG completed their second year of researching responsible AI (RAI). In addition to producing a series of articles that draw on insights from an expert panel and a survey-based research report, the team has highlighted its key findings in this infographic. Although many organizations are prioritizing RAI and [&#8230;]]]></description><content:encoded><![CDATA[<p></p><p> 2023年，<cite>麻省理工学院的斯隆管理评论</cite>和BCG完成了<a href="https://sloanreview.mit.edu/big-ideas/responsible-ai/">研究负责人AI</a> （RAI）的第二年。除了制作一系列文章，这些文章借鉴了专家小组的见解和基于调查的研究报告，该团队还强调了其在此信息图中的关键发现。</p><p>尽管许多组织都在优先考虑RAI和制定计划以负责任地管理人工智能工具的计划，但大多数公司都依靠第三方AI工具（他们购买，访问或许可的工具，包括Chatgpt和Bard等生成AI工具） - 有重大风险。显然，大多数组织都不准备解决这些新风险，但是我们的研究使我们能够制定一套建议，以帮助他们正确地实现RAI。</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/are-rai-programs-pregared-for-third-party-party-and-party-and-generative-ai/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>如何在棘手的话题上有效地表达不同意见</title><link/>https://sloanreview.mit.edu/article/how-to-productively-disagree-on-tough-topics/<comments> https://sloanreview.mit.edu/article/how-to-productiverively-disagree-on-tough-topics/#comments</comments><pubDate> Mon, 13 Nov 2023 12:00:22 +0000</pubDate> <dc:creator><![CDATA[Kenji Yoshino and David Glasgow. <p>Kenji Yoshino（ <a href="https://twitter.com/kenji_yoshino">@kenji_yoshino</a> ）是纽约大学法学院宪法法教授，梅尔策多样性，包容和归属中心主任。大卫·格拉斯哥（David Glasgow）（ <a href="https://twitter.com/dvglasgow">@Dvglasgow</a> ）是梅尔策多样性，包容和归属中心的执行董事，也是纽约大学法学院的兼职教授。他们是<cite>说正确的话的合着者：如何谈论身份，多样性和正义</cite>（Atria Books，2023），本文所基于的。</p> ]]>; </dc:creator><category><![CDATA[Communication]]></category><category><![CDATA[Cultural Differences]]></category><category><![CDATA[Diversity]]></category><category><![CDATA[Employee Communication]]></category><category><![CDATA[Diversity & Inclusion]]></category><category><![CDATA[Organizational Behavior]]></category><category><![CDATA[Skills & Learning]]></category><category><![CDATA[Workplace, Teams, & Culture]]></category><description><![CDATA[Neil Webb/theispot.com &#160; Conversations about identity, diversity, and justice are some of the thorniest human interactions of our time. Consider Uber’s head of diversity, who hosted a workplace event titled “Don’t Call Me Karen” to highlight the “spectrum of the American White woman’s experience” and foster an “open and honest conversation about race.” Following backlash [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/10/2024WINTER-Yoshino_1290x860.jpg" alt="" /><figcaption><p class="attribution"> Neil Webb/theispot.com</p></figcaption></figure><p></p><p>关于身份，多样性和正义的对话是我们时代最棘手的人类互动。考虑到Uber的多样性负责人，他举办了一个名为“ Do not Call Me Karen”的工作场所活动，以突出“美国白人妇女的经历”，并促进了“关于种族的开放，诚实的对话”。在有色员工的强烈反对之后，她被安置在休假中。 <a id="reflink1" class="reflink" href="#ref1">1</a></p><p>或考虑斯坦福法学院的多样性副院长，他们在保守党法官凯尔·邓肯（Kyle Duncan）的讲话中试图“降级”学生抗议活动。院长试图安抚学生，他们对法官的反LGBTQ+观点感到愤怒，同时为法官提供了完成他演讲的空间。但是她的干预导致了公众的愤怒，因为她认为她优先考虑学生对法官言论自由权的感受。她也被放假。 <a id="reflink2" class="reflink" href="#ref2">2</a></p><p></p><p>如果这些对话阻碍了高级多样性，公平和包容性（DEI）专业人士，那么普通领导人有什么希望？比你想象的还要多。</p><p>我们在纽约大学法学院领导一个研究中心，致力于多样性，包容性和归属感。我们共同教授了各行各业的成千上万个人，在他们的差异之间进行更有意义和有效的对话。我们将努力集中在指导人们担任权力方面的指导，因为他们有最大的机会来改变这些互动的动态 - 促进同理心，而不是引起恐惧和分裂。</p><p>尽管我们教练的人在许多类型的身份对话中挣扎，但分歧通常是最痛苦的。当您和其他人保持一致时，参与身份对话相对容易。当您不同意时，您可能会被焦虑和自我怀疑所淹没。您可能想知道：<em>我像我想的那样开明吗？人们会受到我的伤害或背叛吗？</em></p><p>您可能会通过屈服于您的对话伙伴所说的任何内容来回应这种焦虑。然而，这种方法通常是不可取的，因为它会损害您的尊严和真实性。我们认为，即使在当今两极分化和过热的政治气候中，仍然有可能在身份问题上不同意。关键是要尊重。就是这样。</p><h3>在争议范围内找到对话</h3><p>我们俩都处于同性关系中 - 肯吉（Kenji）于2009年与他的丈夫结婚，并于2014年与他的丈夫结婚 - 我们在许多论坛上都参加了有关同性婚姻的辩论。我们从来没有喜欢这些讨论，但是我们发现它们的一个特征非常糟糕：我们的对手很少承认辩论对我们或其他LGBTQ+人意味着什么。</p><p>在一项反对婚姻平等的著名工作中，作者坚持认为，人们可以拒绝同性婚姻“而不必贬低同性的人，也可以忽略他们的需求。” <a id="reflink3" class="reflink" href="#ref3">3</a>他们在实时对话中也占据了相同的立场。在一场有关同性婚姻的电视辩论中，主持人要求其中一位作者瑞安·安德森（Ryan Anderson）向财务顾问苏兹·奥曼（Suze Orman）解释“她怎么了”。 “我认为你没有什么错，”安德森告诉奥尔曼。 “问题是，婚姻是什么？我认为婚姻本质上是……一个男人和女人的结合。” <a id="reflink4" class="reflink" href="#ref4">4</a></p><p>尽管这听起来是外交的，但这种回应并没有意识到，从许多同性恋者的角度来看，安德森对同性婚姻的反对在逻辑上意味着他认为奥尔曼是二等公民。然而，在我们关于这个话题的无数对话中，我们可以指望对方一方认识到我们可能会对他们的基本人类罢工的看法。这种方法并不需要他们改变意见。它只是要求他们承认该意见如何降落在另一边。</p><p>在某种程度上，由于这种挫败感，我们制定了一个争议量表，该规模沿着直线绘制了分歧的主题。左边是最安全的主题，期望甚至庆祝分歧。右边是最有争议的主题，在这里，对话最有可能变得丑陋。</p><div class="callout-highlight"><aside class="l-content-wrap"><article><h4>如何表达不同意见</h4><p class="caption">在此争议范围内找到对话的话题可以帮助您在更有可能的讨论的水平上构建一个困难的话题。 </p><p><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/10/MAG_Yoshino_Essay_Winter_2024_Figure-1.png" alt="如何表达不同意见" /></p><p class="attribution"></article></aside></div><p>关于个人品味的分歧通常是温暖而善良的。当朋友嘲笑我们对垃圾电视节目的热爱时，这些分歧可以加强而不是削弱关系。关于事实的不同意也相对舒适，只要这确实是关于事实的辩论（例如谁，什么，什么，何时，何时何地或如何），而不是关于价值观的稀疏辩论（构成了“替代事实”或“假新闻” ）。当主题在争议范围内进一步向右流动时，真正的危险就会出现。最激烈的对话是一个或双方都认为他们的平等人性受到质疑的对话。</p><p>想象一下，您是工作场所多样性和包容性倡议的拉丁支持者，而您正在辩论一个反对该计划的非女同事。我们认为您会发现不舒服，但可以讨论该计划是否成功地推进了工作场所（事实）的拉丁语代表。您会发现，是否应该将多样性考虑因素纳入晋升决策（政策）更困难。您会发现，辩论心理学家理查德·赫恩斯坦（Richard Herrnstein）和政治科学家查尔斯·默里（Charles Murray）臭名昭著的假设是智商在种族和族裔群体（同等人类）中有所不同，这是令人难以置信的。 <a id="reflink5" class="reflink" href="#ref5">5</a></p><p>身份分歧的麻烦在于，比较少的特权量表，更多的特权对话伙伴几乎总是以争议量表的不同位置定位问题。如果您认为您的公司过多地关注反种族主义，那么您可能会将争议视为有关组织如何优先考虑其使命不同方面的政策辩论。您的对话伙伴是亚裔美国人的同事，可能会认为您在使她在公司中的归属感变得琐碎。毕竟，她是必须与工作场所中的反亚洲偏见抗衡的人。您将问题在“政策”中的争议量表中间定位。她将其定位在“平等人类”的右极端。</p><p></p><p>您可能会发现，在认识到对方处于争议范围的位置之后，您将重新评估分歧的本质，将问题移近他们定位的位置。但是您可能不会，我们不会敦促您这样做。我们要问的是，您明​​确承认对应方的立场。在谈话开始时，您可能会说：“对我来说，这是一场政策辩论，但是我看到它对您来说是一个深刻的个人辩论，当分享我的观点时，我会尽力尊重这一现实。 ”在谈话期间或之后，您可能会有一些时间，您意识到自己将这个话题视为纯粹的智力练习，并且需要认识到讨论可能对另一个人的影响：“我一直在将政策论据带到桌子上，但是，我能问一下您是如何经历这个讨论的人，因为这个问题可能会更直接地影响这个问题吗？”</p><p>我们认为，您会感到震惊的是，您的相对主题位置可能会受到分歧的伤害或加热。即使这些职位对双方都显而易见，这也是如此。通常，需要的不是更多的知识，而是更多地认识共享知识。</p><p></p><h3>找到不常见的共同点</h3><p>在1987年的电影<cite>《掠夺者》</cite>中，荷兰人的角色（由阿诺德·施瓦辛格（Arnold Schwarzenegger）扮演）和狄龙（Carl Weathers）的角色互相迎接，彼此迎接史诗般的握手。 “狄龙，你是个bit子的儿子，”荷兰人说，当他们互相走向，并用笨拙的手臂与V型形状紧握，就像他们要摔跤一样。他们拒绝放开彼此的手。然后，握手变成了实际的手臂摔跤比赛。这几乎是过度男性气质的戏po虫展示。</p><p>现场可能已经被遗忘了，但病毒模因。当社交媒体用户想向两个看似无关的人，群体或具有令人惊讶的共同点的概念展示时，他们就会发布荷兰语和狄龙握手的照片。他们在荷兰的手臂上放了一个标签，另一个标签在狄龙的手臂上，以及中间的共同点。在一个例子中，复仇和冰淇淋握手在“最好的冷”一词上。史诗般的握手还催生了其他尝试使用Venn图突出显示不可预测的重叠的尝试。我们了解到，银行抢劫犯，DJ和传教士分享“举手”。这些图像帮助我们看到了每场手臂摔跤比赛中隐藏的握手。</p><p>这种能力至关重要，培养它比看起来要难。传统的智慧是，在与某人不同意时，提供共识点是一种有效的策略。但是，正如哲学家丹尼尔·丹内特（Daniel Dennett）指出的那样，找到“一般或普遍同意的问题”的观点特别有用。 <a id="reflink6" class="reflink" href="#ref6">6</a>这个想法是找到罕见的共同点，使您摆脱默认值。人们常常会为那些感觉像是空虚的手势的平淡无奇的人安顿下来。这就像发布银行抢劫犯，DJ和传教士模因，并使共性“职业”。</p><p>取而代之的是，尝试找到可以解放您以及您的对话伙伴的罕见共同点，并有助于使最容易讨论的主题的发炎。近年来，成群的有关父母通常涌入通常困倦的市政厅会议，以表达有关在孩子们教室中举行的种族的对话的愤怒。这样的父母是巴特·格拉斯哥（Bart Glasgow）（与佐治亚州坎顿的保守派福音派的基督教白人戴维（David）无关），他在学校董事会会议上讲话，反对在当地地区雇用DEI管理员。</p><p></p><p>巴特和他的妻子科利决定就种族主题与四名专家交谈。其中一位是埃默里大学（Emory University）的非裔美国人研究教授兼主席卡罗尔·安德森（Carol Anderson），还有几本书的作者，包括<cite>怀特·愤怒（White Rage）</cite> 。从表面上看，安德森和格拉斯因几乎没有共同点。然而，在他们长达一个小时的对话中，双方都付出了巨大的努力来找到联系点。 <a id="reflink7" class="reflink" href="#ref7">7</a>巴特·格拉斯哥（Bart Glasgow）指出，他写了关于公民抗命话题的高级学院论文，研究了亨利·戴维·梭罗（Henry David Thoreau），圣雄甘地（Mahatma Gandhi）和小马丁·路德·金（Martin Luther King Jr.）等人物。 “要采取圣经的原则，即当仇恨向您展示时，转过另一个脸颊并表现出爱。”安德森（Anderson）指出，她的父亲是“职业军事”，并描述在教堂和“敬畏上帝”社区中长大。他们都在与世界上的<cite>《百科全书》以及将他们带到伍兹德的父母中的经验，他们与世界书籍百科全书</cite>成长的经验保持联系。他们继续分享在教育环境中在少数群体中的经验。黑人的安德森（Anderson）谈到要乘坐大多数白人高中。白人的科利·格拉斯哥（Coley Glasgow）分享说，她在两所历史悠久的黑人大学完成了高等教育。</p><p>探索共同基础有偿股息。随着谈话的继续，他们播出了分歧。巴特·格拉斯哥（Bart Glasgow）反对着重于系统性种族主义。安德森不同意。后来，巴特倡导学校凭证，这将使父母能够将孩子搬出表现不佳的当地学校，安德森再次不同意。然而，这些分歧是非常民事的。谈话结束时，巴特对安德森说：“我可以和你说话了几个小时。我真的可以。”安德森回答说：“非常感谢您在这里，问了这些精彩的问题并参与了这次精彩的对话。谢谢。我喜欢它。”</p><p>下次您面对分歧时，请尝试问自己与对话伙伴有什么共同点，这可能会让他们感到惊讶。如果您正在辩论同性婚姻，您可能会指出，许多人（直率和同性恋）认为婚姻是一个过时的机构。因此，尽管有所不同，但你们俩都相信婚姻作为机构的重要性。发现这些不常见的共同点需要一些独创性，有时可能会感到纳税。但是回报很大：找到他们可以使你们俩都摆脱反思性和无意识的感觉，即您是对话中的对手。</p><h3>展示你的作品</h3><p>在我们启动梅尔策多样性，包容和归属中心后不久，我们收到了一位受人尊敬的同事的令人不安的电子邮件。她要求我们将我们的平台用作多样性和包容性学者，以倡导那些不完全接种自己或孩子的人。在她看来，将违反疫苗授权的人排除在学校和工作场所中，对多样性，包容性和归属感的价值观具有“令人不安的”影响。她邀请我们与她讨论这个问题，因此可以在大学范围内解决。</p><p>在Covid-19-19大流行将疫苗变成白热问题之前，我们收到了这一要求。即便如此，我们知道这次对话可能很困难。我们热情地不同意她的观点，但我们担心既不承认她在争议量表上的立场，也不是提供史诗般的握手就足够了。</p><p>因此，我们深入分享了我们的推理。我们礼貌地说，我们不相信反对疫苗适合我们中心工作范围的反对。我们解释说，该中心的主要功能是解决对有色人种或女性等边缘化社会群体的偏见。我们承认，某些群体，例如宗教少数群体，由于他们的信仰而不是由于其身体特征而受到虐待。但是，特别是作为一个新成立的中心，我们并不渴望将边缘化群体的定义扩展到由他们对单个问题的看法所定义的人们。我们还指出，疫苗犹豫的话题在我们的专业知识之外提出了复杂的医疗，道德和公共卫生问题。</p><p>我们没有幻想这种方法会改变同事的想法。但这表明我们对她的观点进行了真正的考虑，这也为她提供了一个机会，可以指出我们可能错的地方。她感谢我们的回应的周到，指出她完全了解我们的立场，并邀请我们参加一个单独的主题的活动。</p><p>我们对同事的询问的方法就是展示您的作品的一个例子 - 也就是说，在尽可能详细地解释了分歧，以向其他人仔细思考这个主题。强调分歧要点的建议似乎与我们以前的重点是寻找共同基础的一步不一致。但是，您可以并且应该同时做 - 寻找一致性和详细分歧点的份额。描绘了您基于分歧的事实和价值观的完整图片，任何已经告知您当前思维的研究和对话以及您持有的任何剩余疑问或不确定性。在您的对话伙伴的一生中，他们可能遇到了许多基于伪劣或不完整的工作反对自己的观点的人。展示您所做的努力将使您与这些对手区分开。这将帮助他们回应您，而不是对过去的所有声音。</p><p>注意：在展示您的作品时，请勿在立即驳回反对论点之前提供对反对论点的摘要。作家莫伊拉·韦格尔（Moira Weigel）将这个错误比作高中文章的“最后一段的第一句话”：“我已经想到了另一边。不要指责我没有想到另一方！” <a id="reflink8" class="reflink" href="#ref8">8</a> Rather than taking that cursory approach, take the time to research and understand the opposing view, and then share that understanding generously before you explain why you continue to see the issue differently. Show your work to show your respect.</p><h3> Manage Expectations</h3><p> Many people have a low tolerance for disagreement in general. If a contentious identity issue comes up at a conference room table, they immediately change the subject. If they have an argument with someone, they replay the conversation in their mind for weeks. David, unfortunately, is one such person. He&#39;ll run away from voicing a disagreement to avoid conflict, then stew alone in frustration that the other person doesn&#39;t agree with him. For whatever reason, he seems to have an unrealistic expectation that identity conversations should always end in a group hug.</p><p> People sometimes ask us anguished questions along these lines: “I&#39;m an atheist and staunch liberal, but a colleague on my team at work is a conservative evangelical Christian. How can we work together despite our disagreements?” Our answer: Lower your expectations. We admit this advice probably won&#39;t make its way onto a motivational poster. But we think it&#39;s completely appropriate to scale the intensity of the passion you bring into the disagreement to the intensity of the relationship.</p><p></p><p> A cartoon by Randall Munroe shows a stick figure furiously tapping away at a computer keyboard while a voice from the other room calls out, “Are you coming to bed?” The stick figure responds, “I can&#39;t.这个很重要。 Someone is <em>wrong</em> on the internet.” <a id="reflink9" class="reflink" href="#ref9">9</a> Most people have enough perspective not to care fiercely about disagreements with random internet trolls. But it&#39;s worth cultivating that healthy instinct in other situations, too. Each of us would struggle if we had a major disagreement with our spouse about issues of identity. Nevertheless, we&#39;ve both supervised and advanced the careers of students who disagree with us, because the teacher-student relationship is less intense than the marital one. The same goes for colleagues, neighbors, and acquaintances. When the relationship isn&#39;t as close, the need for agreement should be lower.</p><p> You can also manage your expectations of what can be achieved in a single conversation. As with any dispute over a heavy subject, identity conflicts often aren&#39;t neatly resolved in one encounter. The first conversation might go poorly, but the second might go better and the third better still. You might need to take multiple off-ramps and on-ramps to and from a conversation before you make progress.</p><p></p><p> When people engage in conversations about identity, diversity, and justice with someone who has opposing views, we encourage them to practice the four strategies we&#39;ve described:</p><ul><li> Locate the conversation on the controversy scale. To you, the conversation might be a factual or policy debate, but to the other person, it might be a debate over their equal humanity.</li><li> Find uncommon commonalities — points of agreement that are not matters of widespread agreement.</li><li> Show your work on the remaining disagreements to demonstrate that you&#39;ve thought carefully about the subject.</li><li> Manage your expectations. Scale the intensity with which you care about the disagreement to the intensity of the relationship.</li></ul><p> Despite the examples we&#39;ve shared, you might think we&#39;re being unrealistic about your ability to disagree agreeably on matters of identity by practicing these strategies. It&#39;s true that they can&#39;t ensure positive outcomes in all conversations. But we&#39;re confident that you&#39;ll see an immediate improvement in the quality of your conversations if you follow these guidelines.</p><p></p><p> Sometimes, of course, the rift between you and the other person will be too wide. Sometimes an attempt at conversation will end without a resolution. Sometimes the relationship itself will end. As awful as that outcome can feel, it&#39;s sometimes a necessary one. We&#39;re not here to guarantee that every disagreement will end happily. Rather, we want to help you ensure that a divide is truly unbridgeable before you walk away from it.</p><p> Other times, of course, you might be surprised in a positive way. Few, if any, meaningful relationships are devoid of conflict. When handled well, moments of tension can deepen a bond. Rather than nodding along insincerely or offering fake opinions, sharing a thoughtful difference of opinion can show the other person that you value them enough to be honest with them. Moreover, by modeling how to productively disagree, you can set the tone for how others throughout your organization can navigate today&#39;s thorniest conversations.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/how-to-productively-disagree-on-tough-topics/feed/</wfw:commentrss><slash:comments> 1</slash:comments></item><item><title> The Real Measure of Presentation Success</title><link/> https://sloanreview.mit.edu/article/the-real-measure-of-presentation-success/<comments> https://sloanreview.mit.edu/article/the-real-measure-of-presentation-success/#respond</comments><pubDate> Thu, 09 Nov 2023 12:00:21 +0000</pubDate> <dc:creator><![CDATA[Nancy Duarte. <p><a href="https://www.linkedin.com/in/nancyduarte/">Nancy Duarte</a> is the CEO of <a href="https://www.duarte.com/">Duarte Inc.</a> , a communication company in the Silicon Valley. She&#39;s the author of six books, including <cite>DataStory: Explain Data and Inspire Action Through Story</cite> (Ideapress Publishing, 2019).</p> ]]>; </dc:creator><category><![CDATA[Communication]]></category><category><![CDATA[Employee Communication]]></category><category><![CDATA[Leadership]]></category><category><![CDATA[Leadership Skills]]></category><category><![CDATA[Skills & Learning]]></category><category><![CDATA[Workplace, Teams, & Culture]]></category><description><![CDATA[Carolyn Geason-Beissel/MIT SMR &#124; Getty Images Historically, it’s been tough to quantify the success of events, presentations, and speeches. We’ve long known that the spoken word is a powerful tool for influence and action, but how do you measure that power? When many organizations flipped from in-person to virtual and hybrid meetings and events, presentation [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/11/Duarte-1290x860-1.jpg" alt="" /><figcaption><p class="attribution"> Carolyn Geason-Beissel/MIT SMR |盖蒂图片社</p></figcaption></figure><p>Historically, it&#39;s been tough to quantify the success of events, presentations, and speeches. We&#39;ve long known that the spoken word is a powerful tool for influence and action, but how do you measure that power?</p><p> When many organizations flipped from in-person to virtual and hybrid meetings and events, presentation analytics became a whole new ballgame. Speakers used to measure impact largely by surveying people and reading the literal room. While those forms of feedback still provide useful information about whether and how a message is landing, presenters now have many other metrics they can use.</p><p></p><p> Here&#39;s a quick example: For decades, my firm built all the decks for a large company&#39;s annual software developer conference. When the conference went remote because of COVID-19, we reworked all the content — each of the breakout sessions, as well as the keynotes — for a virtual audience. After that conference, the organizers stack-ranked the most popular sessions and realized they&#39;d put the same amount of energy into creating a session that garnered 40 views as they&#39;d put into creating sessions that earned hundreds of thousands of views. The organizers also got data on the percentages of participants actively engaging with the sessions, along with related numbers on downloads and shares. Combined with the substance of attendee comments, these insights told the conference folks which topics were resonating both broadly and deeply, helped them manage their time investments, and shaped their choice to keep the conference mostly virtual.</p><p> That&#39;s just one of many ways you can slice, dice, and analyze. But to gauge a presentation&#39;s success, what should you measure <em>for</em> ? In the example above, a key organizational goal was for developers to learn and build new software features into products, so the conference folks were looking specifically at how long each attendee stayed in the critical sessions, how active they were in the learning sessions, which tools they downloaded, and, after the event, how many applications the developers rolled out. Once the event team knew which sessions had turned out to be the most useful, they could create better-targeted content for the next conference.</p><p> All of these yardsticks measured some form of action. And really, that&#39;s what all presenters should be looking for: evidence that they&#39;ve moved people to <em>do</em> something, whether it&#39;s learning a new skill, adopting a new approach to organizational culture, changing a deeply ingrained process or behavior, or treating customers differently 。</p><p> To measure a presentation&#39;s success, you need to assess your audience members&#39; feelings and actions before you speak, while you speak, and after you&#39;re done.</p><p></p><h3> Before Your Talk</h3><p> To define what baseline result you&#39;re after — that is, what action you want people to take after they walk away from your talk — it helps to know your audience. In studying hundreds of powerful speeches (and even checking out business speeches from the Stanford University library all the way back to the 1950s), I found that most of their <a href="https://www.duarte.com/how-to-write-a-call-to-action-in-a-persuasive-speech/#:~:text=Who's%20in%20Your%20Audience%2C%20and,they%20bring%20to%20the%20table.">calls to action</a> targeted one of four audience types: <em>doers</em> , who could instigate activity and get things moving in the organization; <em>suppliers</em> , who could provide resources and other types of support needed to achieve a desired goal; <em>influencers</em> , who could mobilize others to adopt a new idea or approach; or <em>innovators</em> , who could generate new ideas and apply their smarts to solve a problem or seize an opportunity.</p><p> Which type of audience will you address in your talk? Once you&#39;ve sorted out that critical “who,” you can analyze the “what” and the “how” of getting people to adopt and implement your idea. Specifically, you can take one of the following approaches.</p><p> <strong>Delve into your audience&#39;s thoughts and feelings.</strong> Ask yourself about the people you want to reach: <em>What</em> do they think about your idea now? If it&#39;s not on their radar yet, <em>how</em> will they feel about it when they hear what you have to say? And how do you want their thoughts and feelings to <em>change</em> as a result of your talk?</p><p></p><p> This isn&#39;t just a hypothetical stepping-into-their-shoes exercise. Gathering that information in advance — and articulating the points of view you want to move people <em>from</em> and <em>to</em> — will determine the way you frame an issue and possible responses to it. That could mean doing some research or surveying the audience to assess what people currently know about your topic and how they feel about it. For example, you might interview the people closest to your customers or culture. Are they excited about your idea, or skeptical of it? What questions do they have about it? Not only will you figure out what baseline you&#39;re starting from — you&#39;re also likely to gain insights about your audience that will help you <a href="https://sloanreview.mit.edu/article/four-storytelling-techniques-to-bring-your-data-to-life/">craft your message</a> . You can also identify a benchmark to measure against later on, after your presentation — say, one of your organization&#39;s KPIs or an important talent-recruitment metric.</p><p> <strong>Anticipate emotional sticking points.</strong> The bigger the transformation you&#39;re trying to trigger in your audience, the more difficult it can be to quantify, especially if it&#39;s an emotional shift. As you research what&#39;s currently going on in your audience members&#39; heads, consider their hearts as well. What&#39;s going to be the hardest part of your message for people to accept or process, no matter how logical the argument or solid the evidence? What sources of potential resistance can you identify? If you do win over people&#39;s heads, how will you know when you&#39;ve won over their hearts, too?</p><p> Emotional change often won&#39;t show up on a dashboard. Even technologies that allow organizations to <a href="https://sloanreview.mit.edu/article/employee-emotions-arent-noise-theyre-data/">track customer or employee sentiment</a> won&#39;t collect data on everything you need to know. Sometimes you&#39;ll know you&#39;ve overcome emotional resistance only when you see it later in new behaviors — when employees stop pushing back on important initiatives, for example, or when customers change their minds and buy the new release of your product.</p><h3> During Your Talk</h3><p> You can gauge your talk&#39;s likelihood of success as it&#39;s happening. To do this, you&#39;ll measure audience reactions in a few ways.</p><p> <strong>Observe audience behavior in the room or online.</strong> The most immediate form of measurement is to watch how people respond to a presentation in real time. When everyone takes out their phones to snap pictures of slides, you know something&#39;s grabbing their attention. Notice, too, when people laugh, gasp, or applaud — these basic behavioral cues signal <a href="https://sloanreview.mit.edu/article/make-your-data-insights-visually-consumable/">which moments in your talk are resonating</a> . Tech comes in really handy here. If your talk (whether delivered in person or remotely) is recorded, you can easily go back and look for places where the audience visibly or audibly responded.</p><p> <strong>Look at the number of attendees.</strong> If you&#39;re addressing a crowd at a big event such as an industry gathering, another useful metric is the number of people who showed up to hear you speak when they could have attended other sessions instead. If you&#39;ve packed a physical or virtual room, that means you&#39;ve teed up your talk effectively before even opening your mouth. When I spoke this year at Dreamforce, a Salesforce conference, most of my audience members skewed young and weren&#39;t familiar with my work, but the talk was still oversubscribed, with overflow attendees clustered in the doorway. My name wasn&#39;t the draw — rather, it&#39;s the way I&#39;d titled and framed the message that hit a nerve. When attendees rated the talk, the data showed that it had lived up to the promise in the title and program description.</p><p> <strong>Spark and track social engagement.</strong> If your talk is getting everyone buzzing, especially at a large event, they might share quotes or images from your presentation in real time on social channels. Be sure to add your social handles and event-specific hashtags to your slides so it&#39;s easier for your audience to tag you and for you to track the ideas they&#39;re engaging with most. (Those posts, comments, likes, reshares, and other in-the-moment social reactions can later be captured in a post-event report.) You can also accelerate and measure the spread of ideas by providing repackaged presentation content in easily shared formats like infographics or <a href="https://www.duarte.com/resources/books/slidedocs/">Slidedocs</a> (slides that have more text because they are meant to be read by the audience rather than simply presented by the speaker). One of our tech customers has us build their keynote speeches into skimmable e-books with the script and slide visuals as well as trackable links to additional material.</p><h3> After Your Talk</h3><p> Your post-talk metrics can track both satisfaction with the presentation and some of the steps audience members have taken to implement the ideas.</p><p> <strong>Use surveys to assess audience satisfaction.</strong> Many speakers use surveys to measure audience sentiment after a presentation. If you surveyed people before you spoke as well, you&#39;ll be able to see whether your talk has moved the doers, suppliers, influencers, or innovators in the audience any closer to your point of view. One Fortune 100 tech company we work with also uses audience ratings as a management tool to motivate speakers to perform well. Everyone wants to get the highest possible score, and those who don&#39;t score well are likely to work hard to raise their score the next time they speak — or not be invited back.</p><p> <strong>Examine the speaker&#39;s own satisfaction.</strong> In companies without a strong measurement culture, sometimes one of the most telling signs of success is how the speakers themselves think their presentations went. That might seem like navel-gazing, but it&#39;s a bigger deal than most people assume. If a leader who consistently works on their skills and performance as a communicator and is sensitive to cues from the audience feels that they&#39;ve delivered an effective presentation, chances are actually pretty good that they have. And, hey, when your CEO wants to feel like a rock star, and they walk off the stage feeling like one, I call that a win.</p><p></p><p> <strong>Quantify actions taken.</strong> This is where you come back to that baseline result you&#39;ve defined — the audience behavior you wanted to elicit or change when you developed your presentation. While reactions like satisfaction and buy-in matter, actions matter more. The whole point of giving a presentation is to persuade people to adopt and implement your ideas. So look at the traction that your initiative gained as a result of your talk. Did your employees complete the enrollment forms your HR team mentioned in the benefits presentation? Did your sales team download the new corporate overview deck you launched at kickoff? How many deals closed as a result? I embed QR codes in my slide decks — most people know how to use them — and share my slides. This allows attendees to do a deeper “double-click” on a concept. My marketing team can track all that activity for post-talk analysis.</p><p></p><p> If you&#39;re trying to prevent certain actions, it&#39;s important to measure those, too. One year, a company hired my team to help them deliver news of a planned reorganization, one of the most difficult presentations to deliver. Executives worried about two kinds of fallout in particular: highly valued employees leaving their jobs in frustration, and a decline in productivity. So they decided to track two data points after the announcement: the number of resignations over the next several months, and any productivity dip as reflected in customer relationship management data over the next several weeks. With those reports in, they were relieved to see that both numbers were much better than company leaders had anticipated. In this situation, measuring success meant tracking a <em>lack</em> of (that is, negative) action after delivering a sensitively crafted message.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/the-real-measure-of-presentation-success/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> The Looming Challenge of Chemical Disclosures</title><link/> https://sloanreview.mit.edu/article/the-looming-challenge-of-chemical-disclosures/<comments> https://sloanreview.mit.edu/article/the-looming-challenge-of-chemical-disclosures/#respond</comments><pubDate> Wed, 08 Nov 2023 12:00:11 +0000</pubDate> <dc:creator><![CDATA[Lori Bestervelt, Colleen McLoughlin, and Jillian Stacy. <p>Lori Bestervelt, Ph.D., is the former global operations lead, and Colleen McLoughlin, Ph.D., DABT, ERT, is the director of toxicology at Enhesa Sustainable Chemistry. Jillian Stacy is the business manager of Enhesa Sustainable Chemistry.</p> ]]>; </dc:creator><category><![CDATA[Manufacturing]]></category><category><![CDATA[Product Life Cycle]]></category><category><![CDATA[Supply Chain Management]]></category><category><![CDATA[Sustainable Business Practices]]></category><category><![CDATA[Operations]]></category><category><![CDATA[Social Responsibility]]></category><category><![CDATA[Supply Chains & Logistics]]></category><category><![CDATA[Sustainability]]></category><category><![CDATA[Frontiers]]></category><description><![CDATA[Sam Falconer/theispot.com New and emerging rules in the U.S. and Europe that make companies responsible for the environmental impacts of products through their entire life cycles are forcing brands to confront a striking knowledge gap: their often inadequate understanding of the chemicals found in their supply chains. The European Green Deal’s Circular Economy Action Plan, [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/10/2024WINTER-Bestervelt_1290x860.jpg" alt="" /><figcaption><p class="attribution"> Sam Falconer/theispot.com</p></figcaption></figure><p> New and emerging rules in the US and Europe that make companies responsible for the environmental impacts of products through their entire life cycles are forcing brands to confront a striking knowledge gap: their often inadequate understanding of the chemicals found in their supply chains.</p><p> The <a href="https://environment.ec.europa.eu/strategy/circular-economy-action-plan_en">European Green Deal&#39;s Circular Economy Action Plan</a> , which was adopted in March 2020; newly proposed <a href="https://wwd.com/sustainability/business/legislation-moves-in-the-eu-new-laws-in-france-germany-and-the-netherlands-1235458823/">eco-design rules</a> affecting fashion and textiles; and the proposed <a href="https://commission.europa.eu/business-economy-euro/doing-business-eu/corporate-sustainability-due-diligence_en">Corporate Sustainability Due Diligence Directive</a> will require companies to disclose any risks to human rights and the environment. They apply throughout the product life cycle, from the formulation of ingredients and materials to product manufacturing, packaging and distribution, and recycling and disposal. In the US, four states — California, Colorado, Maine, and Oregon — have adopted <a href="https://www.packworld.com/news/sustainability/article/22419036/four-states-enact-packaging-epr-laws">extended producer responsibility laws aimed at packaging materials</a> , and the issue will be a focal point of the US Securities and Exchange Commission&#39;s eventual <a href="https://www.sec.gov/news/press-release/2022-46">Scope 3 supply chain requirements</a> . On top of such legislation, a host of new regulatory actions focused on <a href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202120220SB54">materials sourcing and disposal</a> , <a href="https://www.nysenate.gov/legislation/bills/2021/S8922">safety in global supply chains</a> , and the protection of employee safety and human rights are rolling out in jurisdictions around the world.</p><p></p><p> These rules pose a challenge for many of the brands that manufacture, market, and sell the clothes we wear, the cosmetics we apply, and the toys our kids play with, because their companies have very little visibility into the detailed chemical composition of their products 。</p><p> In the face of regulatory developments, fashion brands have had to reconsider their use of materials, dyes, and a host of chemicals that have been linked to deforestation and pollution. They also need to be able to trace these compounds through every link in the supply chain.</p><p> Tracing the chemical composition of a piece of clothing is no easy task, given that the many dozens of substances and materials that go into a single garment are sourced from various suppliers and are incorporated into the product at different stages. A basic clothing item like a pair of jeans will be made up of fabric combinations, dyes, softeners, fading enzymes, biocides, and preservatives from dozens of different suppliers in different formulations that need to be applied using different techniques. All of these elements can create environmental hazards at various points in the supply chain and the full product life cycle.</p><p></p><h3> Beyond Safety Data Sheets</h3><p> Marquee brands that sell consumer products face the greatest pressure from regulators to clean up their supply chains. While many have made <a href="https://www.wsj.com/articles/companies-rush-to-trace-sprawling-supply-chains-as-sustainability-rules-loom-11674512050">public commitments</a> to improve their sustainability, gaining needed cooperation from suppliers and partners has been a challenge. Most brands have relied on safety data sheets (SDSs) provided by their suppliers for information on product chemical composition. However, these documents are designed primarily to disclose information on chemicals and chemical compounds that could harm workers or others in the supply chain. They don&#39;t provide detailed information on the chemical composition of every material used in a product or offer any meaningful insight into its impact on recycling and disposal.</p><p> In our work conducting chemical hazard assessments and product toxicology analyses for some of the world&#39;s largest brands, approximately one-third of the SDSs we reviewed contained incomplete or inaccurate information on the chemical makeup of the products and materials they covered. Whether that is a result of suppliers intentionally omitting information or a reflection of the limitations of the SDS as a disclosure tool, the end result is that the brands responsible for these products are often in the dark about what&#39;s inside them.</p><p> Filling in the gap between the basic information provided in SDSs and the detailed disclosures that will soon be required by global authorities has become a source of conflict and confusion for many brands. Some suppliers are reluctant to share detailed chemical formulations to protect trade secrets, and many brands have been unwilling (or unable) to invest in costly chemistry assessments.</p><p></p><p> We expect that this problem will be addressed in two ways. First, the market will likely shift to suppliers that can attest to the safety of their products and processes. We&#39;ve already begun to see this in the fashion industry: Brands like Gucci, H&amp;M, Stella McCartney, and Zara recently committed to <a href="https://www.wsj.com/articles/fashion-giants-vow-to-buy-more-recycled-fibers-in-boost-to-sustainable-textile-mills-11668451031">buying more recycled materials</a> from sustainable textile mills. Second, companies will have to invest in detailed chemical screening to provide more comprehensive hazard assessments and full formulation disclosures. This approach has also been gaining in popularity as brands seek certainty and an objective means of evaluating their suppliers.</p><p> In both cases, the key objective for the big brands at the center of this shift to sustainability will be transparency. Brands need to start having candid conversations with suppliers about what exactly is in their products and what&#39;s expected in terms of regular reporting and disclosures. They might need to staff up in order to have sufficient resources to engage with suppliers, especially in seeking to extend working relationships beyond the first tier. Brands might also have to coordinate requests for information across multiple parts of the organization to get buy-in. Engaging the full supply chain can be tedious and hard work.</p><p></p><p> And these are not always easy conversations. The most common communication roadblocks we see here are confidentiality concerns, suppliers saying they are just too busy to deal with a litany of chemical composition questions from customers, and misunderstandings over what&#39;s being asked and why. Brands don&#39;t necessarily know what to ask for from their suppliers. They also don&#39;t know how to assess the impact of chemicals when they do get the information. Brands might also have to manage multiple internal chemical inventory systems and harmonize data from suppliers across different platforms.</p><p> To get to a place where all parties are on the same page, brands need to standardize a process for determining what questions to ask, whom to ask, and how to manage the information gathered. Brands also need to explain to suppliers why this information is important to the business and how they will use it, to allay privacy concerns.</p><h3> Evaluating Chemical Risk by the Numbers</h3><p> As we&#39;ve noted, we expect more brands to produce their own hard evidence of the chemical composition of their products when they are unable to get reliable information from their supply chain partners.</p><p> The only way to deliver objective certainty on the chemical risk of products is by performing chemical hazard assessments, which identify the specific chemical components used in the production of a product and screen them against comprehensive lists of known toxins to provide a hazard score. They are not cheap, though. Companies can expect to spend anywhere from $3,000 to $10,000 per substance for each assessment; the cost is at the higher end of that range for substances on which there is a great deal of scientific literature that must be carefully reviewed. Because even the most basic apparel, cosmetics, toys, and consumer products contain dozens of individual chemicals, the costs can mount quickly.</p><p> Add to those costs the challenges of retooling and replacing toxic substances in the production process once they&#39;re found, and it starts to become clear how looming deadlines like the European Green Deal&#39;s Net Zero by 2050 target are much closer than they appear.</p><p></p><p> The critical first step in the process of removing toxic substances from a supply chain is systematically identifying them. For example, we recently worked on a project with a global footwear brand that had a companywide mission to make its rubber supply chain more environmentally sustainable. It began by building a comprehensive database of its current chemical inventory and checking all entries against a list of known toxins and regulated chemicals in each jurisdiction in which it operates. Only then could it start the process of transitioning to safer chemicals.</p><p> As they make progress, brands need to build this institutional knowledge into their sourcing and product development processes to mitigate or eliminate the harmful chemical impacts of future products throughout their life cycles.</p><p> In the long run, these initiatives will result in safer, more sustainable consumer products. In the near term, however, expect to see a great deal of disruption and reshuffling of supply chains as more brands start to recognize that the tried-and-true methods of manufacturing and distribution are no longer sufficient in today&#39;s sustainability-oriented economy.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/the-looming-challenge-of-chemical-disclosures/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> How to Engage People on Reskilling: A Language Lesson</title><link/> https://sloanreview.mit.edu/article/how-to-engage-people-on-reskilling-a-language-lesson/<comments> https://sloanreview.mit.edu/article/how-to-engage-people-on-reskilling-a-language-lesson/#respond</comments><pubDate> Tue, 07 Nov 2023 18:00:49 +0000</pubDate> <dc:creator><![CDATA[Carl Clarke, Zsófia Belovai, Michelle Davies, Nicha Surawattananon, and James Elfer. <p>Carl Clarke is the director of talent, learning, leadership, skills, and people performance at Vodafone. Zsófia Belovai is the behavioral science lead at MoreThanNow. Michelle Davies is the head of learning, performance, and reskilling strategy at Vodafone. Nicha Surawattananon is a behavioral scientist at MoreThanNow. James Elfer is founder and CEO of MoreThanNow.</p> ]]>; </dc:creator><category><![CDATA[Corporate Learning]]></category><category><![CDATA[Talent]]></category><category><![CDATA[Talent Development]]></category><category><![CDATA[Skills & Learning]]></category><category><![CDATA[Workplace, Teams, & Culture]]></category><description><![CDATA[Carolyn Geason-Beissel/MIT SMR &#124; Getty Images Reskilling has become an imperative rather than merely a growth opportunity. Technology advancements like generative AI have led the World Economic Forum to project that 44% of employees will experience skill disruptions in 2023. On the surface, organizations seem to be rising to this challenge: Thirty-four percent of Fortune [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/10/Belovai-1290x860-1.jpg" alt="" /><figcaption><p class="attribution"> Carolyn Geason-Beissel/MIT SMR |盖蒂图片社</p></figcaption></figure><p>Reskilling has become an imperative rather than merely a growth opportunity. Technology advancements like <a href="https://www.ilo.org/global/about-the-ilo/newsroom/news/WCMS_890740/lang--en/index.htm">generative AI</a> have led the <a href="https://www.weforum.org/agenda/2023/05/future-of-jobs-2023-skills/">World Economic Forum to project</a> that 44% of employees will experience skill disruptions in 2023. On the surface, organizations seem to be rising to this challenge: Thirty-four percent of Fortune 50 companies have made reskilling and upskilling top strategic priorities and have designated a hefty 1.5% of their annual budgets to support them, according to research from Boston Consulting Group.</p><p> However, despite the level of investment in reskilling infrastructure, such as learning programs and talent technology platforms, we find that organizations are undervaluing the need to <em>change employee behavior</em> through effective engagement strategies. Having a well-designed reskilling program doesn&#39;t help an organization if people don&#39;t sign on to participate in it. To achieve a shift, leaders must understand how to connect people with reskilling initiatives in ways that encourage them to take up learning.</p><p></p><p> In an experiment conducted by a team of behavioral scientists from consultancy MoreThanNow and global telecommunications company Vodafone, we found that while most leaders talk about reskilling as an opportunity for <em>individual</em> progress and/or a means to achieving company strategy, a more frank, assertive message about keeping their skills relevant in a digital future drove more people to act. We present this evidence on how to change behaviors to help leaders connect their employees with the vast organizational investments being made in reskilling and upskilling.</p><p></p><h3> Career Relevancy Resonates</h3><p> Our randomized, controlled experiment, which included a global sample of 800 Vodafone employees, aimed to identify the language and motives that would best engage people to explore Vodafone&#39;s case for change. We compared four different message types that introduced the company&#39;s learning offering and why employees should sign up for it:</p><p> <strong>1. Individual progression:</strong> You&#39;ll invest in your career path and thrive in a digital future.<br /> <strong>2. Company strategy:</strong> You&#39;ll help transform Vodafone into a technology company for a digital future.<br /> <strong>3. Learning enjoyment:</strong> You&#39;ll put the joy of learning into your work as you discover new skills and capabilities every day.<br /> <strong>4. Career relevancy and security:</strong> You&#39;ll develop skills and competencies for the digital future.</p><p> While most leaders and organizations tend to use messages 1 and 2 when talking about reskilling, we found that No. 4&#39;s more direct “career relevancy and security” message had the highest positive impact on attitudes toward reskilling into technology-focused roles. The employees who received that message were, on average, 4.7% more open to broader career options and 4.9% more likely to consider reskilling compared with employees who had received the other messages — despite the time and effort the program would require. While these numbers might seem small in magnitude, they are statistically significant, come from a cost-free change in language, and are scalable.</p><p> Perhaps more notably, the experiment showed that people who received the “career relevancy” message were more likely — by 14.7% — to explore reskilling opportunities on Vodafone&#39;s internal site, which provides a tangible way to measure how Vodafone&#39;s employees actually invest their time in developing他们的技能。</p><h3> Three Reskilling Communication Tips for Leaders</h3><p> Message 4 made more of an impact with the open, honest, and clear message about the necessity to reskill.</p><p> Decades of research show why losses loom larger than gains and how this can be used as an effective language tool to change minds and behaviors. For example, when people are asked to rate the emotional effect of losing or gaining money, they systematically <a href="https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=e89e139fc94470c62f0904b69c229816bba4c2ba">rate losses as having a greater impact</a> . Similarly, in a <a href="https://www.ssoar.info/ssoar/bitstream/handle/document/28311/ssoar-jebo-2009-3-gachter_et_al-are_experimental_economists_prone_to.pdf?sequence=1">field experiment</a> conducted with economists, a message telling participants that they would be fined for late conference registrations was significantly more effective than a message offering a discount for early registration.</p><p> That body of research and our own study yielded the following three tips to help managers talk more effectively with their employees about reskilling amid the rise of disruptive technologies like artificial intelligence and generative AI.</p><p> <strong>Set the context: Be reassuring but transparent about emerging technologies&#39; potential impact on employees&#39; careers.</strong> Be honest about the uncertainties around the possible effects of AI and other technologies on job roles rather than communicating only the upsides. Employees often fear that AI will steal their jobs, but it is more likely to change and augment their jobs. Talk about staying proactive to these changes and engaging with upskilling and reskilling opportunities in order to ride the wave of change. This can lead to more active attempts by employees to explore the benefits of increasing their technical knowledge and evolving their roles accordingly.</p><p> <strong>Make it relevant: Give personal, specific examples.</strong> Talk about the impact of new technologies on the person&#39;s specific work area and outline what might change for the team. Perhaps the way your team develops presentations, processes data, or takes action on customer feedback will change. Identifying specific scenarios will help both you and your employees think about the skills necessary in the evolving tech landscape and create a tangible plan of action.</p><p> <strong>Make it real: Offer the best options for the future.</strong> Be well informed and open. Talk about training programs employees need to consider as skills for the future rather than as a nice-to-have benefit. It&#39;s easy for employees to get lost in a sea of reskilling program information, and as a manager, you have a responsibility to guide them toward the best future career options that your company has to offer. For example, instead of saying, “I want you to consider a training program to grow your career,” say, “I want you to consider a training program; there&#39;s a possibility that some parts of your role will be automated in the future, so we need to make sure your skills keep evolving.&quot;</p><p></p><p></p><p> Vodafone&#39;s experiment resulted in successful action: Company leaders changed their language from communicating “individual progression” benefits to a more candid “career relevancy and security” message. When Vodafone launched the first cohort of its reskilling program, it successfully engaged 4,000 employees in Italy using this upfront communication style. Some 300 people have now been successfully reskilled and redeployed from contact centers to other internal functions. In total, one million learning hours have been completed by Vodafone employees.</p><p> We encourage leaders to follow Vodafone&#39;s lead and talk about reskilling with their employees in a more open and direct manner. Your digital future — and the ability of your employees to successfully navigate a changed world — might depend on it.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/how-to-engage-people-on-reskilling-a-language-lesson/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> Marketing With Generative AI: Harvard Business School&#39;s Ayelet Israeli</title><link/> https://sloanreview.mit.edu/audio/marketing-with-generative-ai-harvard-business-schools-ayelet-israeli/<comments> https://sloanreview.mit.edu/audio/marketing-with-generative-ai-harvard-business-schools-ayelet-israeli/#respond</comments><pubDate> Tue, 07 Nov 2023 12:00:48 +0000</pubDate> <dc:creator><![CDATA[Sam Ransbotham and Shervin Khodabandeh. <p>Sam Ransbotham ( <a href="https://twitter.com/ransbotham">@ransbotham</a> ) is a professor in the information systems department at the Carroll School of Management at Boston College, as well as guest editor for <cite>MIT Sloan Management Review</cite> &#39;s Artificial Intelligence and Business Strategy Big Ideas initiative. Shervin Khodabandeh is a senior partner and managing director at BCG and the coleader of BCG GAMMA (BCG&#39;s AI practice) in North America. He can be contacted at <a href="mailto:shervin@bcg.com">shervin@bcg.com</a> .</p><p class="mt20"> <cite>Me, Myself, and AI</cite> is a collaborative podcast from <cite>MIT Sloan Management Review</cite> and Boston Consulting Group and is hosted by Sam Ransbotham and Shervin Khodabandeh. Our engineer is David Lishansky, and the coordinating producers are Allison Ryder and Sophie Rüdinger.</p> ]]>; </dc:creator><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Customer Data]]></category><category><![CDATA[Generative AI]]></category><category><![CDATA[Market Strategy]]></category><category><![CDATA[Marketing Approach]]></category><category><![CDATA[AI & Machine Learning]]></category><category><![CDATA[Customers]]></category><category><![CDATA[Data, AI, & Machine Learning]]></category><category><![CDATA[Marketing]]></category><category><![CDATA[Marketing Strategy]]></category><category><![CDATA[Artificial Intelligence and Business Strategy]]></category><description><![CDATA[As an associate professor at Harvard Business School and cofounder of the Customer Intelligence Lab at the school’s Digital Data Design Institute, Ayelet Israeli’s work is focused on how data and technology can inform marketing strategy, as well as how generative AI can be a useful tool in eliminating algorithmic bias. One of the products [&#8230;]]]></description><content:encoded><![CDATA[<p></p><p> As an associate professor at Harvard Business School and cofounder of the Customer Intelligence Lab at the school&#39;s Digital Data Design Institute, Ayelet Israeli&#39;s work is focused on how data and technology can inform marketing strategy, as well as how generative AI can be a useful tool in eliminating algorithmic bias. One of the products of her recent work is a <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4395751">paper</a> she coauthored with two Microsoft economists and researchers on how generative AI could be used to simulate focus groups and surveys to determine customer preferences.</p><p> Ayelet joins the <cite>Me, Myself, and AI</cite> podcast to discuss the opportunities and limitations of generative AI in market research. She details how the research was conducted and how artificial intelligence technology could help marketers reduce the time, cost, and complexity associated with traditional customer research methods. </p><aside class="callout-info"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/11/MMAI-S8-E3-Israeli-HBS-headshot-3000-scaled.jpg" alt="Ayelet Israeli"></p><h4> Ayelet Israeli, Harvard Business School</h4><p> Ayelet Israeli is the Marvin Bower Associate Professor of Business Administration in Harvard Business School&#39;s Marketing Unit. She is also the cofounder of the school&#39;s Customer Intelligence Lab at the Digital Data Design Institute. Her research focuses on data-driven marketing, with an emphasis on how businesses can leverage their internal data, customer data, and market data to improve outcomes. Her research interests include retail, pricing strategy, channel management, marketing analytics, and algorithmic bias. Israeli has a Ph.D. in marketing from the Kellogg School of Management at Northwestern University.</p></aside><aside class="callout-info fl mobile-fn mt40"><h5> AI for Leaders on LinkedIn<br /></h5><p style="font-size:1.4rem;"> If you&#39;re enjoying the <cite>Me, Myself, and AI</cite> podcast, continue the conversation with us on LinkedIn. Join the <a href="https://www.linkedin.com/groups/13977401/" class="marketing-click" id="AI_for_leaders_link[MMAI]">AI for Leaders</a> group today.</p><p class="is-button mt20"> <a href="https://www.linkedin.com/groups/13977401/" class="marketing-click" id="AI_for_leaders_link[MMAI]">Join now »</a></p></aside><p> Subscribe to <cite>Me, Myself, and AI</cite> on <a href="https://podcasts.apple.com/us/podcast/me-myself-and-ai/id1533115958">Apple Podcasts</a> , <a href="https://open.spotify.com/show/7ysPBcYtOPVgI6W5an6lup">Spotify</a> , or <a href="https://podcasts.google.com/feed/aHR0cHM6Ly9tZW15c2VsZmFuZGFpLmxpYnN5bi5jb20vcnNz">Google Podcasts</a> .</p><h4>成绩单</h4><p><strong>Sam Ransbotham:</strong> How can using generative AI help us understand consumer preferences? On today&#39;s episode, hear from a professor about her market research study.</p><p> <strong>Ayelet Israeli:</strong> My name is Ayelet Israeli from Harvard Business School, and you&#39;re listening to <cite>Me, Myself, and AI</cite> .</p><p> <strong>Sam Ransbotham:</strong> Welcome to <cite>Me, Myself, and AI</cite> , a podcast on artificial intelligence in business. Each episode, we introduce you to someone innovating with AI. I&#39;m Sam Ransbotham, professor of analytics at Boston College. I&#39;m also the AI and business strategy guest editor at <cite>MIT Sloan Management Review</cite> .</p><p> <strong>Shervin Khodabandeh:</strong> And I&#39;m Shervin Khodabandeh, senior partner with BCG and one of the leaders of our AI business. Together, <cite>MIT SMR</cite> and BCG have been researching and publishing on AI since 2017, interviewing hundreds of practitioners and surveying thousands of companies on what it takes to build and to deploy and scale AI capabilities and really transform the way organizations operate.</p><p> <strong>Sam Ransbotham:</strong> Hi, everyone. Today, Shervin and I are thrilled to be joined by Ayelet Israeli. She&#39;s associate professor and cofounder of the Customer Intelligence Lab at the Digital Data Design Institute at Harvard Business School. Ayelet, thanks for taking the time to talk with us.让我们开始吧。</p><p> <strong>Ayelet Israeli:</strong> Thank you so much for having me.</p><p> <strong>Sam Ransbotham:</strong> Often, we begin by asking guests their professions. But what&#39;s nice about being a professor is that people kind of have an idea of what that means. But I still think it&#39;d be nice to hear a little bit about your background and bio. So can you take a minute and introduce yourself and tell us what you&#39;re interested in?</p><p> <strong>Ayelet Israeli:</strong> All right. I&#39;m a marketing professor at Harvard Business School. I&#39;m really interested in how we can better leverage data and AI for better outcomes, if it&#39;s outcomes for the firms, for customers, for society at large. Some of the work I&#39;m working on is around gen AI and how firms can use that to gain better access to consumer information and preferences. In other work I do, I think about how we can eliminate algorithmic bias in our decision-making.</p><p> <strong>Sam Ransbotham:</strong> I saw your talk a few months ago about using generative AI, and it really struck me as interesting because lots of people are talking about generative AI, but we don&#39;t have a lot of evidence yet.</p><p> <strong>Ayelet Israeli:</strong> Mm-hmm.</p><p> <strong>Sam Ransbotham:</strong> The evidence … is not saying it&#39;s not there, but it&#39;s just forthcoming. But you&#39;re starting to get some evidence through this research that you&#39;re doing. What can we do with GPT and generative in market research?</p><p> <strong>Ayelet Israeli:</strong> Me and two of my colleagues that are at Microsoft, Donald Ngwe and James Brand, started thinking around, can we actually use GPT for market research? The idea was, some people have shown that you can replicate very well-known experiments, including the famous Milgram experiment, using GPT by just asking it questions. And we were thinking, “We work so much as researchers and as practitioners to better understand customer preferences; maybe we can use GPT to actually extract these kinds of preferences.”</p><p> For large language models, the idea is that they will give you the most likely next word. That&#39;s how language is produced. And we were thinking, “Maybe if we ask GPT or induce it to make a choice between two things, maybe the response, which is kind of the most likely next word, will actually reflect the most likely responses in the population. And in that sense, we will essentially query GPT but get kind of the underlying distribution of preferences that we see in the population.” And we started playing around with that idea. We focused on consumer products — because we assumed that the data that GPT is aware of is mostly around consumer products, maybe from review websites or things like that — to see, can this idea actually work?</p><p> <strong>Shervin Khodabandeh:</strong> And does it?</p><p> <strong>Ayelet Israeli:</strong> Kind of!</p><p> <strong>Shervin Khodabandeh:</strong> That&#39;s wonderful. So tell us more.</p><p> <strong>Ayelet Israeli:</strong> Our first rush was like, “OK, let&#39;s see if it can generate very basic things we expect from economics. Like, when the price is higher, does it know to reject an offer? Does it know to make this trade-off between price and choice?” And we do see kind of a downward-sloping demand curve, which is what you would expect to see when we query GPT thousands of times to get answers. We also see things like, “Oh, we can tell it something about its income, and it reacts to that.” When it has higher income, it&#39;s less price-sensitive, which makes sense — it&#39;s what we expect from people as well.</p><p> We also see that it can react to information about itself: “Oh, last time you bought in this category, you bought this particular brand” makes it much more likely to pick up this brand in the future. So those are kind of our tests of “Does it actually react in a way that humans would in surveys?” And then we took it one step further, and we were trying to get willingness to pay for products or for certain attributes. And then we basically compared the distribution of prices to distribution of prices we see in the marketplace, which is pretty consistent.</p><p> And a really interesting and exciting thing for us was the ability to look at willingness to pay for attributes, because it&#39;s something that we all, as marketers, want to find. In our example, it&#39;s toothpaste, and we&#39;re trying to figure out how much people are willing to pay for fluoride, which is something that is difficult for us to think about. If someone would ask you that — “I don&#39;t know.” I do know that I prefer to buy this toothpaste, but I don&#39;t know what is the number. So it made us more curious to see if GPT can provide us this number in the same way that we ask consumers. And the way that the researchers have shown over years, the best way to ask these questions is through conjoint studies. Essentially, you provide people with 10 to 15 choices, and through their different choices, you are able to understand the trade-offs that they&#39;re making and actually quantify the difference that they&#39;re willing to pay.</p><p> We essentially did that. We did a conjoint-type analysis with GPT, and we compared the outcomes to human studies that a forthcoming paper just ran and got pretty similar results, so we were very excited about that. Of course, the results are not identical. We need to do a lot more to figure out where some of the issues are and how much does this generalize, but just the fact that we were able to get it is incredibly exciting.</p><p> <strong>Sam Ransbotham:</strong> So it seems exciting for firms because I&#39;m guessing that the cost of doing a market study on a lot of people is much more than doing it just through a bunch of API calls with ChatGPT. That has to be the appeal. Are there other appeals?</p><p> <strong>Ayelet Israeli:</strong> Basically, these types of studies are time-consuming, costly, and complex. Ideally, you would like to ask people to make a lot of trade-offs, but you&#39;re limited by the human ability to do that. With GPT, you can query it a lot of times. But at this point, I&#39;m not going to tell anyone, “Replace all your human studies with GPT or with another LLM,” because there is a lot more work to be done to figure out how to do that right.</p><p> One of the things around GPT is that it&#39;s pretrained. It will give me preferences, but these preferences are relevant for the time period in which it was pretrained. And a firm wants to know, “What are the customers interested in right now?” So that&#39;s kind of a limitation.</p><p> What we&#39;re testing now is, maybe we still have to query people, but less people than you would normally have to. So usually when you run these studies, you need thousands of users to get something that would be robust and statistically significant from an academic or statistical standpoint. We&#39;re trying to look at, maybe I can collect information from much fewer humans and combine it with LLM through fine-tuning and generate something useful. But really, a big advantage would be cost savings and time savings.</p><p> <strong>Sam Ransbotham:</strong> The time was a big one.</p><p> <strong>Ayelet Israeli:</strong> Yeah. And we&#39;re talking so far about consumer products, but you can think about business-to-business type surveys, which are way more expensive and harder to do. So perhaps there is potential there as well. We haven&#39;t tested that yet.</p><p> <strong>Shervin Khodabandeh:</strong> I love the idea. I mean, when you think about most use cases for generative AI, there&#39;s a lot about taking drudgery out of the work or creating images and content and summarizing text. And then there&#39;s more-advanced ones around planning and inventory management. But the one you&#39;re talking about is literally replacing humans with this, right? I mean, that&#39;s basically what it is.</p><p> And it&#39;s a beginning of something that could be quite interesting, because you&#39;ve proven, at least, that it&#39;s sort of rational, right? I mean, you&#39;re asking it all these questions, and it is economically, I guess, rational. But then, as a marketer [like] you are yourself, not all marketing strategies are based on rationality. In fact, many of them are based on completely irrational desires.</p><p> <strong>Ayelet Israeli:</strong> Right.</p><p> <strong>Shervin Khodabandeh:</strong> What are your thoughts on the nonrational choices that many people make that create these big brands and $20,000 handbags and all kinds of stuff like that? How do you tap into that?</p><p> <strong>Ayelet Israeli:</strong> Before I answer your question, the first thing I was nervous about as an academic is when you used the word <em>proven</em> .</p><p> <strong>Sam Ransbotham:</strong> Prove — I heard it!</p><p> <strong>Ayelet Israeli:</strong> I see Sam is ...</p><p> <strong>Shervin Khodabandeh:</strong> I smiled when I said it.</p><p> <strong>Ayelet Israeli:</strong> I would say we showed evidence consistent with that. And we also know that these models are still evolving, and maybe something we showed a month ago will not be relevant in a month from now, which is also a reason why you shouldn&#39;t just go and implement it without testing.所以我想对此小心。</p><p> <strong>Shervin Khodabandeh:</strong> Yes.</p><p> <strong>Ayelet Israeli:</strong> So you know there is the more rational view of what is a product, but brands have value that is created that is kind of not measurable to us and hard to quantify. But that&#39;s almost like the example I gave with fluoride. Like, we don&#39;t know how to quantify fluoride. We might find it difficult if I would ask you, “Oh, how much are you willing to pay for a brand name like Colgate versus a toothpaste that I just made up?”</p><p> Actually, the same model of conjoint study will be able to infer those differences. And we see preferences, for example, for Mac over a different computer type. So it&#39;s already embedded in there, in a way.</p><p> Now how accurate it is — it&#39;s an empirical question.</p><p> <strong>Shervin Khodabandeh:</strong> Yeah, no, you&#39;re so right because as I heard you respond to this question, I also realized that my assumption that what you showed some evidence for, vis-à-vis proven, isn&#39;t necessarily rationality. It&#39;s that it&#39;s got an ability to sort of encapsulate what most people do — or what many people do — which is embedded in stuff that it was trained on. So then my second question is, how do you get this to be more segmented or more specific or more nuanced? Because when you do focus groups, you&#39;re looking maybe for a particular flavor/particular nuance mix.</p><p> <strong>Ayelet Israeli:</strong> Yes, and also, a lot of the uses that we have seen when GPT and other LLMs were just introduced, a lot of the excitement was, “I&#39;m an engineer. I can just ask it a question. It gives me the most common thing. That&#39;s exactly what I want.” And actually, what we are doing is the other side of that. We don&#39;t want the most common thing. We want to understand the distribution.</p><p> That&#39;s why when we query GPT, we ask it every question many, many times — because we want to get many, many different consumers. In our analysis, we only varied income and what you bought before. But we can, in the same way, vary gender, race, anything else that you want … age. And I&#39;ve seen other researchers do that. ……</p><p> There is a really interesting paper by colleagues at Columbia and Berkeley that used GPT to create perceptual maps — how close two brands are to each other. And they also showed differences by gender and age and things like that around cars, which is a market where we expect to see these differences. So you can definitely do that, too, in a similar way. And it was also shown in political science for politics. I can give someone an ideology, and their voting behavior makes sense, their text generation on different topics makes sense. That&#39;s also very exciting as a marketer who cares about heterogeneity and understanding the differences between different consumers.</p><p> <strong>Shervin Khodabandeh:</strong> Yeah. If only we could use this for clinical trials.</p><p> <strong>Ayelet Israeli:</strong> I saw some paper on better bedside manner of LLMs relative to doctors, so maybe there&#39;s still something there. [笑。]</p><p> <strong>Sam Ransbotham:</strong> That&#39;s GPT-5, maybe.</p><p> <strong>Ayelet Israeli:</strong> Yeah.</p><p> <strong>Sam Ransbotham:</strong> As you&#39;re saying that, though, I think about the way these work is a probabilistic estimate of the most likely next word, the most likely next ... and you&#39;ve segmented out “Given that you are low income, high income, given that you are this attribute, that attribute …” That&#39;s interesting, but where do we come up with the weirdness, then? If everything is based off the “most probables,” particularly from predefined [parameters] — not that you&#39;re not brilliant about coming up with a nice search space, but how are we going to find the things we don&#39;t know, then ？ Isn&#39;t that something that comes out of market research and focus groups?</p><p> <strong>Ayelet Israeli:</strong> Certainly, and that&#39;s part of the challenge. Obviously, GPT learns some kind of distribution, but there are people that, you know … let&#39;s say all that it learns is from reviews. There might be a lot of very extreme consumers that don&#39;t write reviews online or don&#39;t have access to the internet but have these interesting extreme ideas. And even if I tell GPT, “I want [as much] randomness as possible, very high variation,” I will not get to those people. So that will definitely be a problem.</p><p> I know already of some startups that are trying to solve this issue and identify these extreme consumers and then take them to the next level by using LLMs to maybe predict what they will do in another case. But at the same time, there has been some work on [the] creativity of GPT and that it creates very creative ideas, which, you know, is not exactly what you&#39;re asking for.</p><p> <strong>Sam Ransbotham:</strong> Some of those creative ideas are unconstrained by reality. I think we&#39;ve all seen some of it, [like] the way that it plays chess and decides that that rule is a little bit too confining.</p><p> <strong>Ayelet Israeli:</strong> Right. So that&#39;s also the problem of hallucinations, which should be tested in different contexts. But I think the way that we induce it to make a choice is less prone to hallucination problems because it provides a choice and you&#39;re not asking for facts or something like that. I&#39;m not trying to say that GPT will outperform any customer survey or anything like this. All I want to see is if it is as good as humans.</p><p> And even with human customers that we talk to, we have to work really hard to find people to do these surveys, and sometimes we miss them. We might be able to get the distribution of some people but still have to work hard on the extremes without AI but with just human conversation.</p><p> <strong>Shervin Khodabandeh:</strong> What I find really interesting here is, you said something like, “It&#39;s not as good as a consumer survey,” and now I want to challenge that. Because what I find interesting in this idea that you have is that when you think about other AI or gen AI use cases, there is a sort of burden of proof that you say, “OK, so I&#39;m a human.我是个工程师。 I have a task. Let&#39;s ask GPT,” or any generative AI system, whether it&#39;s, let&#39;s say, knowledge kind of work, whether it could do it as well as a human does.太好了。 Or can it code better than a human does? Or can it create a video or a document or something that you would read and you&#39;d say, “Wow, this is nice. So then <em>you</em> could do it. I don&#39;t need to do it.”正确的？ So that sort of a burden of proof is very clear.</p><p> On this one, I&#39;m not so sure that you even <em>have to</em> have a burden of proof, because in many ways we&#39;re assuming that a focus group of 500 or a thousand people, or any survey — I mean, there&#39;s no focus group that big that I know of — but a survey of that kind is somehow gospel or, like, that&#39;s like what GPT or whoever, whatever —</p><p> <strong>Ayelet Israeli:</strong> Can you talk to the reviewers of our paper? [笑。]</p><p> <strong>Shervin Khodabandeh:</strong> Because the reality of it is, if you think about it, it&#39;s that if the only way to know ... so go back. Because, look: Your premise here is like, “We are going to save so much money on all this market research by augmenting this with that,” which is a true premise, and for sure it is. But I also find the burden is lower. And even if you don&#39;t stop a single human-based market research or survey, you&#39;ve still added a ton of value by broadening the universe of responses and options.</p><p> Because I would argue, how do you know 1,000 people or 2,000 people are representative <em>at all</em> or that they have all those nuances? And so this thing is actually bringing in signals that for a fact exist because otherwise you wouldn&#39;t be there. And I find that actually quite inspiring to a marketer. I&#39;m happy to talk to your reviewers.</p><p> <strong>Ayelet Israeli:</strong> I think as academics, we are used to a certain level of rigor and robustness and ability to say, like, oh, to actually prove things, and the fact that this tool can provide a simulation of something is nice, but “Can it actually replace humans?” is a higher burden because of this question of, is it actually giving me meaningful, updated responses? Will it match something? And you&#39;re saying, “Well, maybe humans aren&#39;t that great in the first place, so why do we try to … ?”</p><p> <strong>Shervin Khodabandeh:</strong> No, I&#39;m actually making a different point. I was trained as a scientist, and I get the burden of proof is much higher in science and in academia. And I wasn&#39;t trying to argue that you&#39;ve proven that this replaces humans. I don&#39;t think it&#39;s replacing humans. But what I was trying to say is, the value of this is that it dramatically augments the signals and insights and ideas available to a marketer and because there is no survey or focus group that by definition isn&#39;t limited, and this isn&#39;t limited because it&#39;s got everything that&#39;s there. So my point simply is not that the burden of proof has been met but that I don&#39;t even know if there should be that kind of a burden of proof, because it is addressing a limitation of focus groups and traditional research. So it doesn&#39;t necessarily need to replace it. They&#39;re not perfect to begin with. Nobody would argue with that.</p><p> <strong>Ayelet Israeli:</strong> Yeah. I think, at the very least, I feel comfortable saying that we showed that it could be very informative about preferences and what is going on, at least within the data it&#39;s trained on. And that could already change a lot for a lot of firms, given the type of research and the problems with market research and access to humans and all of that.一定。</p><p> <strong>Sam Ransbotham:</strong> So there&#39;s multiple different signals coming in here, and I think we&#39;ve addressed this first from the idea of, does this signal replace the other signal from a focus group? But the dependent variable here might be, do people actually buy a product? Do people buy the fluoride? Do they buy the [fake] product?</p><p> <strong>Ayelet Israeli:</strong> Right.</p><p> <strong>Sam Ransbotham:</strong> And if this signal adds some information to that prediction, then we&#39;ve got a new information source. If it completely supplants it, then we have a different thing.</p><p> <strong>Ayelet Israeli:</strong> Right. And now we&#39;re going to the problem of these surveys of stated preferences versus revealed preferences that are actually based on what people do. Now, I would argue that GPT might have less [of a] problem than humans because it&#39;s not subject to things like experimenter bias or trying to appease me. So it&#39;s probably giving me something closer, but it&#39;s still giving me something likely closer to stated preferences if it brings the data from review sites or market research and not necessarily [giving me] what people would actually buy. But that is also true about the focus groups and the surveys.</p><p> <strong>Sam Ransbotham:</strong> So we think about this as a new source of signal — that there are lots of different signals out there, and it has some overlap, perhaps, with one signal. And I think that itself is fascinating, but it may also have a new signal.</p><p> <strong>Ayelet Israeli:</strong> Yeah.</p><p> <strong>Shervin Khodabandeh:</strong> The other thing that I find fascinating here is that AI solutions have been trained on data, and then, when they&#39;re put in production, they are then trained on data or they get feedback from data in production, and they get更好的。 With generative AI, so much of that feedback also needs to be human-driven versus data-driven, right? Like, this is what it tells you to do.它引起你的共鸣吗？ Yes, no, etc. So it also feels like this kind of a technology, where generative AI can be a user of another generative AI&#39;s output.</p><p> So let&#39;s go to the paradigm of, look, it&#39;s replacing a human in the focus group, or we can also replace a human in a company that&#39;s a marketer dealing with a response from generative AI on, like, “How do you design a campaign为了这？”</p><p> <strong>Ayelet Israeli:</strong> Mm-hmm.</p><p> <strong>Shervin Khodabandeh:</strong> And so this idea of maybe multiple generative AI agents going at each other to improve the overall quality — what do you think about that?</p><p> <strong>Ayelet Israeli:</strong> I think it&#39;s an interesting idea. But I also think that the <a href="http://john-joseph-horton.com/papers/llm_ask.pdf">evidence so far</a> suggests that you still need, at some point, at least one human in the loop …</p><p> <strong>Shervin Khodabandeh:</strong> For sure.</p><p> <strong>Ayelet Israeli:</strong> ... because of all of these hallucinations, unrealistic things that come out. But certainly, if these models are getting better and better, more efficient, higher quality, then why not? As we implement these type of things in our organizations, we also need to think about how do we — I don&#39;t know if the word is exactly <em>validate</em> , but how do we ensure that the process still makes sense and that we&#39;re not just wasting everyone&#39;s time with these agents talking to each other?</p><p> <strong>Shervin Khodabandeh:</strong> No, for sure. You&#39;re 100% right. You need humans in the loop and probably for many decades at least. But you may not need so many of them. You know, if you have some kind of an output that is supposed to be helping, let&#39;s say, a group of 20,000 customer service reps, and it&#39;s going to get better based on the feedback, based on their usage in a pilot of, let&#39;s say, three months, maybe you don&#39;t need to pilot this to 5,000 people. Maybe you could pilot it to a hundred people plus two or three different gen AI agents so that you dramatically accelerate the adoption time.</p><p> <strong>Ayelet Israeli:</strong> Yeah, that&#39;s cool.</p><p> <strong>Sam Ransbotham:</strong> Although I have to say, when I heard you saying that, Shervin, what it made me think of is when people hold a microphone too close to a speaker and we get these feedback loops — amplifying feedback loops. I do worry that if the two sources of data are too, co-aligned, we&#39;ll get squelched.</p><p> <strong>Shervin Khodabandeh:</strong> That&#39;s true.</p><p> <strong>Sam Ransbotham:</strong> We won&#39;t get craziness. Skip to the back of the chapter here: Give us the answers. People are listening to this, and they&#39;re working in companies, and they have these tools available right now, not 20 years from now, like we&#39;re thinking as an academic. What should people be doing right now with these tools?</p><p> <strong>Ayelet Israeli:</strong> Play around with them. Figure out … what do you want to know about your customers? We provide in our paper a whole list of prompts of exactly how to prompt for these types of things and start getting this information. And like Shervin said earlier, what is it exactly? We&#39;re not sure, but it&#39;s a signal. There is information there that we can start finding out, right?</p><p> <strong>Sam Ransbotham:</strong> And so by playing with it, that helps people discover what information is there?</p><p> <strong>Ayelet Israeli:</strong> I think testing and discovering. But starting with a concrete question is really helpful because you will just get down so many rabbit holes. You can have these conversations forever.</p><p> <strong>Shervin Khodabandeh:</strong> Ayelet Israeli, you&#39;re the only guest we&#39;ve had that has the “AI” initials, which nicely fits into <em>Me, Myself, and Ayelet Israeli</em> , which is <em>Me, Myself, and Myself</em> .</p><p> <strong>Ayelet Israeli:</strong> [Laughs.]</p><p> <strong>Shervin Khodabandeh:</strong> But tell us more about yourself and your background and how you ended up where you are and what got you interested in all this stuff.</p><p> <strong>Ayelet Israeli:</strong> Sure. I&#39;m originally — as my last name might indicate — I&#39;m originally from Israel. Israel is known to be “ <a href="https://www.cfr.org/book/start-nation">Startup Nation</a> .” And when I came through to think about what I want to study in university, there was a special program that was geared toward improving Startup Nation by giving people kind of managerial tools. So it was a bachelor&#39;s in computer science and an MBA combined program in five years.</p><p> And I started doing that, and I like computer science. I actually majored in finance and marketing, but I especially was interested in marketing and, particularly, making sense of a lot of data in this context that is so kind of fun and applied. And then I decided to get a Ph.D.在营销方面。</p><p> Over the years, I figured that consumer products or things around customers and transactions are interesting to me. It&#39;s just a fascinating world. You have a lot of data around that because as we move more to online and digital, we can see more and more data. And then the question is, “How can we actually leverage that data more efficiently and also in a responsible manner?” which a part of my research is about as well.</p><p> <strong>Sam Ransbotham:</strong> So we have a segment where we&#39;ll ask you a series of rapid-fire questions to put you on the spot. Just answer the first thing that comes to your mind.</p><p> <strong>Ayelet Israeli:</strong> OK.</p><p> <strong>Sam Ransbotham:</strong> What&#39;s the biggest opportunity for artificial intelligence right now?</p><p> <strong>Ayelet Israeli:</strong> Biggest opportunity. This is not rapid.</p><p> <strong>Shervin Khodabandeh:</strong> Next question.</p><p> <strong>Ayelet Israeli:</strong> Yeah, next question.</p><p> <strong>Sam Ransbotham:</strong> Oh, OK.</p><p> <strong>Ayelet Israeli:</strong> I&#39;ll think about it.</p><p> <strong>Shervin Khodabandeh:</strong> Pass.</p><p> <strong>Sam Ransbotham:</strong> Pass. What&#39;s the biggest misconception that you think people have about artificial intelligence right now?</p><p> <strong>Ayelet Israeli:</strong> I tend to be around people that work in this and understand this, that it is just a model, but a lot of people still don&#39;t and still envision robots and this magical thing that happens. And that&#39;s why I like to explain very clearly, “Oh, it&#39;s predicting the likelihood of the next word and choosing them on distribution, and that&#39;s all that is happening.” So I think we&#39;re still maybe not as bad as it used to be 10 years ago, but it&#39;s still this magical, artificial thing that happens, and it&#39;s not. It&#39;s still magical, I guess.</p><p> <strong>Sam Ransbotham:</strong> It&#39;s pretty amazing — or can be. What was the first career that you wanted?</p><p> <strong>Ayelet Israeli:</strong> I don&#39;t know. In Israel, you go into the military. I was in the military; I was a lieutenant in intelligence. I don&#39;t think it&#39;s a career I necessarily wanted. It&#39;s something I did.</p><p> <strong>Sam Ransbotham:</strong> There&#39;s a lot of discussion and excitement about artificial intelligence. Where are people overusing it? Where are people using it where it doesn&#39;t apply?</p><p> <strong>Ayelet Israeli:</strong> I think one of the challenges I&#39;ve seen is actually using it to ask it factual questions, because that&#39;s not what it&#39;s about. It&#39;s not a truth-finding mechanism, and that&#39;s just a wrong usage.</p><p> <strong>Sam Ransbotham:</strong> OK. Is there something that you wish that artificial intelligence could do right now that it can&#39;t do? What&#39;s the next exciting thing? What announcement tomorrow would make you happy?</p><p> <strong>Ayelet Israeli:</strong> I&#39;ll take that question slightly differently. I think what excites me about AI in terms of my research on responsible use of data and algorithmic bias is that, yes, a lot of people have shown that AI can generate biased outcomes. We also have known for many years that humans generate biased outcomes. And what excites me about AI is that it&#39;s much easier to fix biased outcomes by a machine and to generate processes that will eliminate bias, and it&#39;s so much more difficult with humans. And that&#39;s something that I&#39;m really excited about.</p><p> <strong>Sam Ransbotham:</strong> I love that point because we&#39;ve got all this bias and misogyny in our world, not by the machines. The machines are not the people who put us in this situation in the first place. And the fact that they maybe do a little bit of that at the beginning, before we&#39;ve trained them, we shouldn&#39;t just throw them out for starting down that path, because we can adjust the weights in models. We can give feedback to models to improve those in a way that we can&#39;t with bazillions of people.</p><p> <strong>Ayelet Israeli:</strong> Right.</p><p> <strong>Sam Ransbotham:</strong> So I think that&#39;s a huge point.</p><p> <strong>Ayelet Israeli:</strong> And we&#39;ve seen the first models of gen AI images. If you say “doctor,” we&#39;re only [seeing] photos of men or things like that. And over time, this has improved a lot. So that&#39;s really exciting, right? We can try to think about how we fix some societal problems using these things because, yes, machines can be manipulated more easily than humans. Of course, that&#39;s a risk, but that&#39;s for some sci-fi podcast, not for this one.</p><p> <strong>Sam Ransbotham:</strong> The example of the doctor in the image is spot-on because I think so many people were fascinated by how accurate these models are because they felt right. They confirmed our stereotypes. You ask for this image, and it gives you exactly what you think of as that image, but that&#39;s just feeding into the problem again. And that&#39;s going to perpetuate it if we don&#39;t [stop it]. But, like you say, there has been improvement there.</p><p> <strong>Shervin Khodabandeh:</strong> Ayelet, thank you so much. This has been really insightful and quite interesting. Thank you for being on the show.</p><p> <strong>Ayelet Israeli:</strong> Thank you so much for having me.这很有趣。</p><p> <strong>Sam Ransbotham:</strong> Thanks for joining us today. On our next episode, Shervin and I speak with Miqdad Jaffer, chief product officer at Shopify. Before you do your holiday shopping, please join us to learn how little bits of AI everywhere can add up to big value for all of us.</p><p> <strong>Allison Ryder:</strong> Thanks for listening to <cite>Me, Myself, and AI</cite> . We believe, like you, that the conversation about AI implementation doesn&#39;t start and stop with this podcast. That&#39;s why we&#39;ve created a group on LinkedIn specifically for listeners like you. It&#39;s called AI for Leaders, and if you join us, you can chat with show creators and hosts, ask your own questions, share your insights, and gain access to valuable resources about AI implementation from <cite>MIT SMR</cite> and BCG. You can access it by visiting <a href="https://mitsmr.com/AIforLeaders">mitsmr.com/AIforLeaders</a> . We&#39;ll put that link in the show notes, and we hope to see you there.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/audio/marketing-with-generative-ai-harvard-business-schools-ayelet-israeli/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item></channel></rss>