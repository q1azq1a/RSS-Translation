<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/"><channel><title>麻省理工学院斯隆管理评论</title><atom:link href="http://sloanreview.mit.edu/feed/" rel="self" type="application/rss+xml"></atom:link><link/> https://sloanreview.mit.edu<description>可持续创新</description><lastbuilddate>2023 年 9 月 7 日星期四 12:08:12 +0000</lastbuilddate><language> en-US</language><sy:updateperiod>每小时</sy:updateperiod><sy:updatefrequency>1</sy:updatefrequency><generator> https://wordpress.org/?v=6.2.2</generator><item><title>基于技能的人才实践的原因、内容和方式</title><link/>https://sloanreview.mit.edu/article/the-why-what-and-how-of-skills-based-talent-practices/<comments> https://sloanreview.mit.edu/article/the-why-what-and-how-of-skills-based-talent-practices/#respond</comments><pubDate> Thu, 07 Sep 2023 11:00:11 +0000</pubDate> <dc:creator><![CDATA[Beth Berwick. <p>Beth Berwick 是 Grads of Life 的合伙人，该公司是波士顿非营利组织 Year Up 的子公司。</p> ]]>; </dc:creator><category><![CDATA[Diversity]]></category><category><![CDATA[Equity]]></category><category><![CDATA[Hiring]]></category><category><![CDATA[Talent Acquisition and Management]]></category><category><![CDATA[Talent Development]]></category><category><![CDATA[Diversity & Inclusion]]></category><category><![CDATA[Leadership]]></category><category><![CDATA[Organizational Behavior]]></category><category><![CDATA[Performance Management]]></category><category><![CDATA[Skills & Learning]]></category><category><![CDATA[Talent Management]]></category><category><![CDATA[Workplace, Teams, & Culture]]></category><description><![CDATA[More jobs than ever require a four-year college degree, including many that never did in the past. Beth Berwick is among those calling for a retreat. “You have to take that requirement off of job descriptions,” she said. “It’s excluding 64% of the population — including 76% of Black Americans and 80% of Latinos.” Instead, [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/W23-QA06_1290x860.jpg" alt="" /><br /></figure><p>比以往任何时候都多的工作需要四年制大学学位，其中包括许多以前从未要求过的工作。贝丝·贝威克 (Beth Berwick) 是呼吁撤退的人之一。 “你必须把这个要求从职位描述中删除，”她说。 “这排除了 64% 的人口，包括 76% 的美国黑人和 80% 的拉丁裔。”相反，她坚持认为，组织应该根据他们需要的技能来招聘。</p><p> Berwick 在 2023 年 5 月举行的<cite>麻省理工斯隆管理评论</cite>研讨会<a href="https://sloanreview.mit.edu/series/work-23-the-big-shift/">Work/23</a>上发表了评论。Berwick 是 Grads of Life 的合伙人，该组织帮助公司建立包容性人才实践。它是 Year Up 的子公司，Year Up 是一家总部位于波士顿的非营利组织，致力于为所有年轻人提供公平的经济机会。</p><p></p><p>学位并不总是能力的默认代表。 Grads for Life、哈佛商学院和埃森哲于 2017 年进行的研究揭示了学位膨胀的问题。 “过去不需要四年制学位的职位突然需要四年制学位，”伯威克说。</p><p></p><p>她解释说，建立基于技能的招聘和人才发展方法与建立更公平的组织密切相关。这意味着重新制定工作描述，实施持续的技能培训以提高保留率并建立晋升途径，并不断鼓励重视包容性的新思维方式。走上这条道路的公司可能会对他们能走多远感到惊讶：伯威克说，许多组织已经取消了大部分职位的四年制学位要求。</p><p>伯威克描述了 Grads of Life 与克利夫兰诊所的合作，旨在将技能优先的做法用于招募和留住长期被忽视的黑人社区成员。该卫生组织重写了 2000 多个职位的 260 份职位描述，并取消了 90% 的四年制学位要求。随后，该公司雇佣或晋升了 1,019 名黑人员工，他们的工资足以维持家庭的生活。伯威克指出，该项目被克利夫兰诊所的高级领导者（“特别是他们的首席执行官”）列为关键优先事项，这赢得了整个组织的支持。</p><p> Berwick 无法回答 Work/23 活动期间与会者提出的所有问题，因此她在下面回答了其中一些问题。 （为了清晰起见，问题和答案已进行了轻微编辑。）</p><h6>您如何建议公司制定公正的招聘评估？</h6><p></p><p>我们进行了广泛的研究，以确定具有强有力的有效性证据基础的做法。在开发我们的工具之一“机会标识符”的过程中，我们审阅了 100 多篇学术论文，该工具帮助客户突出显示可以投资的领域，以推进其多元化、公平性和包容性之旅，并将他们的进展与同行和竞争对手进行比较。并确定了 300 多个最佳实践。</p><p>进行公正的候选人评估的最佳做法之一是在审查之前从提交的申请材料中删除候选人姓名。名字可以暗示候选人身份的不同要素，包括种族、性别和民族背景。为了避免偏见的影响，在不知道候选人姓名的情况下评估候选人的提交内容是有帮助的。</p><p></p><p>另一个最佳实践是使用工作样本测试来模拟候选人将在工作中执行的任务类型，并使用标准评分标准对其进行评估。这种做法的重点是评估候选人执行工作的能力，而不是他们的专业或教育背景。我们经常与客户密切合作，制定反映主管、同事和专家确定的相关技能的标准。</p><p>我们还通过经理培训计划帮助雇主减少员工评估中的偏见。这些课程专门为管理者提供知识和工具来支持、指导和评估不同背景的员工而设计。</p><h6>基于技能的招聘是否意味着即使是入门级工作，候选人也对所需技能有一定程度的熟练程度？您如何评估经验在确定合适度方面的价值？</h6><p>对于入门级工作，所需技能列表通常相对较短，尽管工作可能有首选技能。 （它们可能被定义为“很高兴拥有但不是必需的”或一旦进入该角色即可获得的技能。）</p><p>特定技能所需的熟练程度也可能因工作级别而异。例如，入门级行政助理角色可能需要基本的写作技能，例如撰写没有语法和拼写错误的通信的能力。更高级别的角色可能还需要写作技能，但需要更高的熟练程度，例如，候选人能够简洁而有说服力地传达想法，可以为不同的受众定制书面材料，并可以解释复杂的概念。</p><p>现在，经验如何影响入门级角色和技能？嗯，获得技能的方法有很多，包括在专业环境之外。例如，在社区花园做志愿者可以教授协作技能；组织教会的活动可以教授活动策划技巧；照顾家庭成员可能涉及时间管理、组织和许多其他技能。雇主应继续关注技能，而不是专业经验和教育程度等其他因素。熟练人才可能来自您最意想不到的来源。</p><h6>是否存在基于技能的实践可能最成功或最不成功的典型角色或职业道路？</h6><p>最佳方法是在组织中的<em>所有</em>角色中一致应用基于技能的策略。原因是，在最好的情况下，基于技能的就业是一种文化转变，不仅仅是取消特定职位的学位要求。整体方法对于促进公平非常重要，因为它用相同的标准来衡量每个人，而不是创建一个单独的员工类别（即定期雇用与基于技能的雇用）。</p><p>话虽如此，公司在首次过渡到基于技能的文化时优先考虑某些角色可能会有所帮助。确定正确的起始位置需要几个因素的作用。首先，领导层致力于基于技能的战略的部门或部门是一个自然的起点，因为坚定的拥护者可以帮助领导成功所需的变革管理流程。另一个常见的视角是关注公司难以获得人才的职位。基于技能的实践通常会扩大特定角色的人才库（针对公司内部和外部的员工），因此它可能是解决人才稀缺问题的好方法。</p><p></p><p>为基于技能的战略确定角色优先级的另一个好方法是确定劳动力市场已经表现出势头的领域。例如，在为客户分析劳动力市场数据时，如果我们发现当前担任某个职位的大量员工没有大学学位，那么就有充分理由停止要求此类职位拥有学位。同样，如果大多数招聘该职位的竞争对手不需要大学学位，那么其他公司最好放弃学位要求以保持雇主的竞争力。这些通常是中​​等技能的工作，需要零到五年的经验。</p><p>最后，由于基于技能的就业是建立更公平组织的一种手段，领导者应重点关注扩大获得好工作的机会，并提供足以养家糊口的工资和晋升机会。</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/the-why-what-and-how-of-skills-based-talent-practices/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>决策中捷径的效力</title><link/>https://sloanreview.mit.edu/article/the-potency-of-shortcuts-in-decision-making/<comments> https://sloanreview.mit.edu/article/the-potency-of-shortcuts-in-decision-making/#respond</comments><pubDate> Wed, 06 Sep 2023 11:00:43 +0000</pubDate> <dc:creator><![CDATA[Sebastian Kruse, David Bendig, and Malte Brettel. <p>Sebastian Kruse 是德国亚琛工业大学 TIME 研究领域创新与创业 (WIN) 小组的助理教授。大卫·本迪格（David Bendig）是德国明斯特大学商业与经济学院的教授。 Malte Brettel 是 WIN 的正教授和 WHU-Otto Beisheim 管理学院的创业学兼职教授。</p> ]]>; </dc:creator><category><![CDATA[Decision-Making]]></category><category><![CDATA[Leadership]]></category><category><![CDATA[New Product Development]]></category><category><![CDATA[Product Development]]></category><category><![CDATA[Product Strategy]]></category><category><![CDATA[Leadership Skills]]></category><category><![CDATA[Frontiers]]></category><description><![CDATA[Michael Glenwood Gibbs/theispot.com How do CEOs make good decisions? At a time when senior leaders have access to more data and sophisticated analytics tools than ever before, the central challenge of making good decisions about hiring, product development, and resource allocation is increasingly not a lack of information. Rather, it is knowing how much information [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/2023FALL-Kruse-1290x860-1.jpg" alt="" /><figcaption><p class="attribution">迈克尔·格伦伍德·吉布斯/theispot.com</p></figcaption></figure><p> CEO如何做出正确的决策？如今，高层领导者比以往任何时候都可以获得更多的数据和复杂的分析工具，在招聘、产品开发和资源分配方面做出正确决策的核心挑战越来越不再是缺乏信息。相反，它是知道有多少信息就足够了，以及如何使用它。</p><p>决策学者长期以来一直<a href="https://onlinelibrary.wiley.com/doi/10.1111/j.1467-6486.1993.tb00317.x">建议</a>首席执行官和经理在做出选择之前收集和分析全面的信息。该建议基于两个假设：（1）更多信息可以更好地理解手头的决策和可能的后果，（2）强调收集信息而不是主要依赖自己的知识可能会减少有害的偏见。</p><p></p><p>然而，越来越多的<a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-psych-120709-145346">研究</a>表明，首席执行官们最好更加信任被称为启发法的简单经验法则。这些通常源自领导者的直接经验，经过精心应用，并且经常会产生出色的决策结果。我们最近发表在<cite>《管理研究杂志》</cite>上的<a href="https://onlinelibrary.wiley.com/doi/full/10.1111/joms.12913">研究</a>表明，在决策中使用更多启发式方法的首席执行官可以加快组织中新产品开发的速度，并实现更高的整体业务绩效。 Christopher Bingham 等人的另一项<a href="https://onlinelibrary.wiley.com/doi/10.1002/sej.1">研究</a>。在<cite>《战略创业杂志》</cite>中，建议使用启发式方法进行国际扩张决策可以通过这些举措带来更高的销售额和收入增长。</p><h3>何时（以及为何）启发式</h3><p>研究发现启发式方法在三种条件下效果最佳。</p><p><strong>当决策环境嘈杂时。</strong>在这样的环境中，更多的信息不太可能导致对特定决策问题的更好理解。例如，当高管根据估计的市场规模、可行性或时间表来选择投资哪些创新项目时，这些数据点通常反映了潜在项目领导者的主观评价，而不是客观事实。在这种情况下使用启发式方法可以过滤掉决策过程中的噪音。</p><p></p><p>研究表明，简单的启发式方法，例如“投资于最有优势的项目”或“投资于最有经验的团队成员喜欢的项目”，可以像综合决策一样<a href="https://onlinelibrary.wiley.com/doi/pdf/10.1002/mar.21397">准确地</a>选择成功的创新项目，同时还能加速创新项目的落地。决策的速度。</p><p><strong>当决策者面临高度动态的环境时。</strong>在这种情况下，信息很快就会过时，而使用过时的信息会降低决策质量。例如，在为新的营销活动选择目标客户时，使用简单的启发式方法可能比依赖过去的、可能过时的客户数据更有效。与基于大量旧数据训练的复杂模型相比，“目标客户在过去六个月内从我们这里购买过产品”这个简单的规则可以更<a href="https://journals.sagepub.com/doi/10.1509/jmkg.72.3.082">准确地</a>预测未来的购买行为。</p><p><strong>当获取大量信息很困难时。</strong>例如，在招聘的情况下，获取每个潜在候选人的广泛信息是不切实际或成本高昂的。相反，雇主必须依赖一些信息，例如候选人的简历以及他们对候选人面试表现的印象。</p><p>研究<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4014970">表明</a>，在这种情况下使用启发式方法可以比分析结构化面试中获得的详细信息更准确地预测未来的工作表现。例如，管理者在考虑求职者时可能会问自己三个简单的<a href="https://www.cnbc.com/2020/10/20/jeff-bezos-3-question-rule-for-hiring-new-amazon-employees.html">问题</a>：该求职者是否具有出色的能力？我钦佩候选人的往绩吗？候选人会提高团队的绩效水平吗？只有当所有三个问题的答案都是“是”时，他们才可能选择雇用候选人。然而，招聘中使用的启发法必须关注与绩效相关的标准，并且不能产生不公平歧视个人或强化社会偏见的效果。</p><p>简而言之，启发式方法在嘈杂、动态且信息稀缺的环境中效果最佳。</p><p></p><h3>启发式如何澄清思维</h3><p>为了了解如何使用启发式方法在实践中提供帮助，让我们考虑一下它们如何帮助领导者解决新产品开发中的四个基本问题。</p><p><strong>新产品开发应重点关注哪些机遇？</strong>这方面的全面决策将涉及指导开发团队分析各种细分市场和技术，以确定最有前途的机会。或者，首席执行官可以使用启发式方法将精力集中在某些客户类型（“仅为最终客户开发产品”）或特定产品类型（“仅开发软件产品”）上。这种启发式方法可以缩小新产品开发的关注范围，并提高产生更多创新<a href="https://journals.sagepub.com/doi/10.2307/2666981">想法</a>的可能性。 CEO 还可以使用启发式方法来限制可以并行开发的项目数量，确保每个项目都有足够的资源可用。</p><p><strong>我们如何在竞争项目中进行选择？</strong>启发式方法还可以帮助首席执行官在指定搜索领域内的项目中进行有效选择。许多因素会影响新项目的吸引力，例如未来盈利能力、风险、产品优势、可行性、市场规模、竞争和投资回收期长短。在进行综合决策时，首席执行官会仔细分析和权衡这些因素。然而，在决定推进哪些项目和放弃哪些项目时，简单的启发式方法通常更快、更有效。 CEO 可以为每个项目的每个因素分配正分和负分 (+1 / -1)，统计这些分数，然后选择总分最高的项目。或者，他们可以消除所有在他们认为最重要的因素上得分较低的项目，这种启发式称为<em>按方面消除</em>。研究<a href="https://www.researchgate.net/publication/264437916_Fast_and_frugal_heuristics_for_new_product_screening_-_Is_managerial_judgment_'good_enough'">表明</a>，这两种启发法可以识别在绝大多数情况下哪些项目可能会失败，哪些项目可能会成功。</p><p><strong>新产品开发的正确节奏是怎样的？</strong>启发法可以帮助首席执行官和经理建立新产品开发的节奏感和节奏感。例如，苹果公司使用“每 24 个月发布新版本 iPhone”的简单规则来构建其开发活动。这一规则通过为员工提供持续且可预测的紧迫感来提高效率，促进外部供应商的整合，并使员工从一个项目顺利过渡到下一个项目。同样，一些<a href="https://www.jstor.org/stable/2393807">CEO</a>规定所有新产品项目必须在18个月内完成，以提供稳定的节奏和节奏。其他<a href="https://hbr.org/2001/01/strategy-as-simple-rules">首席执行官</a>制定了新的 B2B 产品发布必须与客户发布周期同步的规则，迫使开发团队缩小项目范围，以便在客户期限内交付项目。</p><p><strong>如何平衡效率和灵活性？</strong>开发团队必须高效（即在时间和资源限制下简化流程以交付产品），并且还必须具有探索和实验的灵活性，但专注于其中一个往往会以牺牲另一个为代价。启发式方法可以帮助首席执行官有效地平衡这种权衡。例如，3M 著名的经验法则是，所有开发人员都可以将 15% 的<a href="https://www.3m.co.uk/3M/en_GB/careers/culture/15-percent-culture/">时间</a>用于基于自己想法的项目。这个简单的规则通过确定可用于独立探索的时间来平衡效率和灵活性，以便在有效管理资源的同时促进创新。同样，首席执行官可以选择规定特定数量的项目必须进行高度实验（例如“所有项目的五分之一应该是彻底创新的”），或者对每年分配给全新项目的资源设置限制（“10 % 的预算预留给新奇想法”）。研究<a href="https://pubsonline.informs.org/doi/10.1287/mnsc.44.6.743">表明</a>，这种简单的规则可以使公司在资源有限的情况下开发出高度创新的产品。</p><h3>从经验法则中获得最大价值</h3><p>为了获得利用启发式方法加快决策速度的优势并保持决策质量，使用启发式方法的首席执行官应考虑采取以下行动：</p><p><strong>在正确的上下文中使用启发式方法。</strong>启发式方法在嘈杂、动态且难以获取信息的环境中有效，而综合决策在容易获得大量客观信息的稳定环境中更为有效。因此，首席执行官应该根据环境的特点调整自己的决策风格。</p><p>例如，在决定收购成熟市场中的哪些公司时，综合决策可能是有效的，因为收购目标的客观信息很容易获得。相比之下，当首席执行官在技术快速发展的高度动态市场中收购公司时，启发式方法可能更有效，因为更多信息通常并不一定能更好地预测目标公司的价值。</p><p><strong>开发并完善您自己的启发法。</strong>有效的启发法不是任意的——它们是通过仔细反思和对困难业务问题的理解而形成的。当启发式在简单规则中捕获因果规律时，它们是可靠的，但当它们没有捕获因果联系时，它们可能会引入<a href="https://onlinelibrary.wiley.com/doi/full/10.1111/joms.12891">偏差</a>。因此，对于首席执行官来说，在生成启发式方法时留出仔细思考的空间可能是值得的。</p><p></p><p>开发自己的启发法至关重要，因为在其他人开发的启发法中捕获的见解可能不会转移到不同的决策环境中。当首席执行官将启发法付诸实践、观察其结果并随着时间的推移对其进行完善时，启发法也会变得更加<a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/sej.1312">有效</a>。研究发现，制药行业供应商国际扩张的简单启发式，例如“进入有大量制药活动的国家”，根据经验，可以细化为更复杂和有效的启发式“进入有大量制药活动的国家”。有很多制药活动，并且是一家大型制药公司的总部所在地。”</p><p></p><p><strong>分享并解释启发式背后的故事。</strong>首席执行官制定的启发法将作为组织中许多成员的决策指南，他们自己将应用规则，例如定义可能感兴趣的国际市场类型或要追求的开发项目类型的规则。然而，由于启发式本质上非常简短且简单，因此它们无法传达其背后的逻辑。分享关于为什么创建启发式的故事可以增加员工记住和应用它的<a href="https://onlinelibrary.wiley.com/doi/10.1111/joms.12808?af=R">机会</a>。</p><p></p><p>数据分析的最新进展——以及许多组织成功地从这些工具中获得有用的见解——表明使用复杂算法分析大量信息可能是最有效的决策方式。然而，许多管理决策需要在嘈杂和动态的环境中做出，在这种环境中，质量信息很难获取和评估。在这种环境中，与基于大量信息的复杂分析相比，简单的经验法则可以带来更快、更好的选择。我们鼓励首席执行官和经理了解启发法的价值，并学习如何开发和使用它们作为决策中彻底信息收集和分析的补充。</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/the-potency-of-shortcuts-in-decision-making/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>与人工智能和智能 KPI 进行战略协调</title><link/>https://sloanreview.mit.edu/article/strategic-alignment-with-ai-and-smart-kpis/<comments> https://sloanreview.mit.edu/article/strategic-alignment-with-ai-and-smart-kpis/#respond</comments><pubDate> Tue, 05 Sep 2023 11:00:55 +0000</pubDate> <dc:creator><![CDATA[David Kiron, Michael Schrage, François Candelon, Shervin Khodabandeh, and Michael Chu. <p class="mt20"><strong>David Kiron</strong>是<cite>《麻省理工学院斯隆管理评论》</cite>研究部编辑主任，也是其<a href="https://sloanreview.mit.edu/big-ideas/">“大创意”研究计划的</a>项目负责人。</p><p class="mt20"><strong>迈克尔·施拉格 (Michael Schrage)</strong>是麻省理工学院斯隆管理学院数字经济倡议的研究员。他的研究、写作和咨询工作重点关注数字媒体、模型和指标的行为经济学，作为管理创新机会和风险的战略资源。</p><p class="mt20"> <strong>François Candelon</strong>是波士顿咨询集团 (BCG) 的高级合伙人兼董事总经理，也是 BCG 亨德森研究所的全球总监，他的研究重点是技术对商业和社会的影响。您可以通过<a href= "mailto:candelon.francois@bcg.com">candelon.francois@bcg.com</a>联系他。</p><p class="mt20"> <strong>Shervin Khodabandeh</strong>是 BCG 的高级合伙人兼董事总经理，也是 BCG 北美人工智能业务的联席领导者。他是 BCG X 的领导者，在推动人工智能和数字化业务影响方面拥有 20 多年的经验。您可以通过<a href="mailto:shervin@bcg.com">shervin@bcg.com</a>联系他。</p><p class="mt20"> <strong>Michael Chu</strong>是 BCG 合伙人兼副总监，专注于将人工智能和机器学习应用于商业职能中的业务问题，包括优化定价、促销、销售和营销。您可以通过<a href= "mailto:chu.michael@bcg.com">chu.michael@bcg.com</a>联系他。</p> ]]>; </dc:creator><category><![CDATA[Analytics and Performance]]></category><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Metrics]]></category><category><![CDATA[Prediction Tools]]></category><category><![CDATA[Smart Technology]]></category><category><![CDATA[Analytics & Business Intelligence]]></category><category><![CDATA[Data, AI, & Machine Learning]]></category><category><![CDATA[Operations]]></category><category><![CDATA[Quality & Service]]></category><category><![CDATA[Supply Chains & Logistics]]></category><category><![CDATA[Artificial Intelligence and Business Strategy]]></category><description><![CDATA[About the Research This article series presents findings from the seventh annual global research study on artificial intelligence and business strategy by MIT Sloan Management Review and Boston Consulting Group. In spring 2023, we fielded a global survey and subsequently analyzed records from 3,043 respondents representing more than 25 industries and 100 countries. We also [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/AI-BusinessStrategy_Article03_1290x860.jpg" alt="" /><br /></figure><aside class="callout-info"><h4>关于研究</h4><p>本系列文章介绍了<cite>麻省理工学院斯隆管理评论</cite>和波士顿咨询集团第七次年度人工智能和商业战略全球研究的结果。 2023 年春季，我们开展了一项全球调查，随后分析了来自 25 个行业和 100 个国家/地区的 3,043 名受访者的记录。我们还采访了 17 名在金融服务、媒体和娱乐、零售、旅游和运输以及生命科学等众多公司和行业领导人工智能计划的高管。</p><p>我们的研究探讨了管理者和领导者如何使用人工智能来增强战略衡量，以推进战略成果。它探讨了组织如何利用人工智能调整甚至生成新的 KPI 来定义和提供可衡量的更好绩效。</p></aside><p>使运营与战略保持一致是一项关键的领导任务。动荡的市场环境、敏捷的竞争对手以及对运营和流程进行数字化升级的持续需求，使得战略调整的管理更具挑战性。精通数字化的领导者正在通过改进他们使用和开发 KPI 的方式来应对一致性挑战。</p><p>根据对 3,000 多名经理的全球调查和 17 名高管访谈，我们发现各个业务领域的领导者都在使用人工智能来增强 KPI 的优先级、组织和共享方式。这些增强功能对加强战略协调具有直接、可衡量的影响。这些领导者还部署人工智能来提高 KPI 本身的准确性、细节和预测能力。这些单独和集体的改进产生了更强的态势感知能力，并改善了公司职能部门协同工作以实现战略成果的方式。</p><p></p><p>领导者承认，他们需要新的衡量能力和改进的指标，以更好地预测和应对战略机遇和威胁。 <a id="reflink1" class="reflink" href="#ref1">1</a>他们认识到，基于人工智能的新测量能力可以提供新的绩效见解和指标、加强一致性并改善结果。我们的研究结果明确、一致地呼吁领导者采取行动，创建更具前瞻性和相互关联的 KPI 综合系统。</p><p>这些富含人工智能的 KPI（或<em>智能</em>KPI）可以有效地充当企业 GPS，为人们提供有关他们在哪里、他们需要去哪里以及如何最好地到达那里的建议。这些智能 KPI 可以更详细、更准确地描述业务中正在发生的情况，更深入地预测可能发生的情况，并且在某些情况下，为经理应采取的行动提供更主动的建议。更智能、更具前瞻性的 KPI 可以改善由于时间和执行惰性而导致不协调和不受挑战的传统 KPI。</p><p>我们讨论来自多个行业的示例，这些示例说明了领导者如何使用这些新功能来实现其战略目标，并提供使用人工智能丰富 KPI 和推进战略调整的具体建议。</p><div class="callout-highlight"><aside class="l-content-wrap"><article><h4></h4><p>智能 KPI 是由人工智能提供的前瞻性且相互关联的 KPI。</p></article></aside></div><h3>加强与人工智能的战略对接</h3><p>KPI 始终旨在成为使组织行为与战略目标保持一致的机制。然而，大多数管理者并不认为他们的关键绩效指标<em>在实践中</em>反映了战略愿望；他们认识到他们的 KPI 需要改进。 <a id="reflink2" class="reflink" href="#ref2">2</a>我们的研究表明，利用人工智能丰富 KPI 的领导者更有可能看到一致性的好处，例如改善跨职能协调。他们能够更有效地确定 KPI 的优先级、识别和建立 KPI 之间的关系以及跨团队共享 KPI 相关数据。他们更多地将 KPI 视为需要改进的资产，而不是需要实现的目标。</p><h4>利用 AI 确定 KPI 的优先级</h4><p>决定强调和优先考虑哪些 KPI 是战略调整的一个众所周知的挑战：“我们需要更好地调整我们的 KPI”是我们定性研究中的常见说法。受访者普遍认为高管的直觉是 KPI 分歧的一个关键根源。报告称其公司已使用人工智能来确定 KPI 优先级的受访者看到职能之间更好协调的可能性是未使用人工智能的受访者的 4.3 倍。通过 AI 确定 KPI 的优先级可以改善数据驱动的决策，并为更强有力的战略协调奠定基础。</p><p>丹麦运输、航运和物流公司马士基利用人工智能重新评估和定义了如何衡量其遍布全球港口、运输和仓库的 65 个资产网络的吞吐量和生产力。一线管理人员必须决定关键绩效的最佳定义是通过尽快装卸船舶或卡车（最大化吞吐量），还是通过管理装载流程，以便运输能够可靠地按计划出发。正确的 KPI 是速度还是进度可靠性？</p><p></p><p>这一决定将对企业产生巨大的实际影响。在<a href="https://www.apmterminals.com/en/about/our-company">APM码头</a>使用更多设备进行装卸会增加吞吐量，但会增加短期成本（额外的设备意味着额外的费用）。相比之下，仅使用足够的设备来确保准时出发会降低成本，但会限制吞吐量。根据经验，现场一线管理人员认为，速度——尽快装卸船舶——是正确的绩效衡量标准。</p><p>为了检验这一假设，马士基的数据科学团队开发了数字孪生——人工智能驱动的模型——来代表每种方法并评估它们在整个价值链中的影响。他们的结论是，使用较少的装载设备可以避免转运点或与公路和铁路等其他运输方式连接时出现的瓶颈。</p><p>他们还发现，一个港口的速度加快会导致其他地方的速度减慢。遵守可靠的时间表还可以降低成本并提高准时到达率。马士基首席数据官霍莉·兰德里 (Holly Landry) 表示，放慢速度是“一个违反直觉的指标”。 “在供应链中使用数字孪生既可以解释又可以证明使用更少的设备是合理的。仅在一台终端上就节省了数百万美元。”</p><p>现在，该公司正在其价值链中推出数字孪生。借助人工智能，马士基优先考虑正确的 KPI，从而在整个企业内实现更高效、更一致的绩效，并通过可靠的交付提高客户满意度。</p><h4>将 KPI 与 AI 集成</h4><p>通过 AI 发现 KPI 之间的相互依赖关系，有助于创建 KPI“整体”，将不同但相互关联的业务活动的不同 KPI 捆绑在一起。 KPI 集合的示例包括员工生产力和客户参与度、利润率和市场份额以及质量制造产出和资产回报率。人工智能在识别将一个 KPI 与另一个 KPI 联系起来的其他隐藏模式方面发挥着关键作用。由于这些模式通常跨越多个职能和利益相关者，KPI 整体可以打破孤岛并增加不同利益相关者之间的协作，从而增强组织一致性。</p><p>价值 100 亿美元的全球烈酒公司保乐力加 (Pernod Ricard) 使用人工智能来描述和加深其两个最重要的 KPI 之间的联系：利润率和市场份额。过去，这些 KPI 是孤立且分离的，每个指标都有自己的一套衡量标准。 （财务职能侧重于盈利能力，而销售和营销侧重于市场份额。）该公司现在部署人工智能来深入了解可提高利润的商业和营销投资（例如媒体或店内激活）如何影响市场份额目标反之亦然。该烈酒制造商现在不再寻求最大化每个单独的 KPI，而是寻求相互协调地优化两个 KPI。</p><p> “如果您可以想象在市场份额优化目标和利润优化目标之间移动光标，”保乐力加首席数字官 Pierre-Yves Calloc&#39;h 表示，“您需要了解实现这些目标所需的投资如何变化。人工智能将为你提供这些信息。借助人工智能，我们可以更好地调整市场份额 KPI、利润 KPI 以及实现这些目标所需的投资。”这种能力改变了保乐力加领导层分配资本以及平衡其对盈利能力和市场份额的渴望的方式。</p><p></p><h4>使 KPI 共享、可见且可信</h4><p>从广义上讲，共享 KPI 意味着共享责任、共享信息或两者兼而有之。分担 KPI 责任通常是领导层的决定。共享性能信息取决于技术和数据访问。我们的研究确定了人工智能增强 KPI 信息共享并促进组织不同部门之间协作的几种方式。</p><p>使用人工智能共享 KPI 可以提供特定的好处，可以加强战略一致性。与不使用 AI 共享 KPI 的组织相比，使用 AI 共享 KPI 的公司改善职能一致性的可能性高出五倍，敏捷性和响应能力提高的可能性高出三倍。正如一位高管所说：“我们需要采取更多措施来共享 KPI。 ......应该分享哪些正确的 KPI，才能让我们确保一件事不会适得其反地压倒另一件事？”通过适当的数据和人工智能应用程序，提高对全公司 KPI 结果和绩效驱动因素的可见性，增强管理者分享、讨论和应对 KPI 之间紧张关系的能力。</p><p>在赛诺菲，人工智能汇集了驱动制药公司综合业务计划 (IBP) 的数据——对于过去 50 年来进行了 300 次收购的企业来说，这是一项艰巨的任务。 2019 年，即将上任的首席执行官 Paul Hudson 倡导数据民主化，这需要新的数据质量和治理标准，以及新的处理和分发技术基础设施。主要 IBP 指标的绩效数据最终通过名为 Plai 的智能新型数字界面（因其易于访问、易于使用、人工智能驱动的功能）进行整合并与全球 10,000 名高管共享。</p><p></p><p>这种平易近人的人工智能工具，也被其开发人员称为“零食人工智能”，它提供了公司范围绩效的可见性，并使管理人员能够就绩效进行建设性讨论。赛诺菲全球财务运营和转型主管斯蒂芬妮·安德罗斯基 (Stephanie Androski) 表示，这些对话在以前是不可能的，不是因为数据不可用，而是因为算法引入了一定程度的客观性，使决策和对话更加有机、可信和有效。</p><p> “我们现在有一个数字落后于我们的销售预测，并且它是多个其他 KPI 的中心点。如果我们预测某种产品可能出现缺货情况，我们不仅能够说，‘哦，等一下，人工智能还预测我们该产品可能会在四年内缺货。几个月。这是真的吗？我们能超越它吗？它还使我们能够作为财务人员提出这样的问题：“对于该产品来说，销售是否过于雄心勃勃？”我们会失去市场份额吗？或“这对总体预测有何影响？”因为一切都更加公开，而且因为你可以看到它，所以它确实有助于增加对话和生产力。”</p><p>领导力的基本要点是，利用人工智能组织和共享 KPI 数据可以为协作和协调提供有价值、值得信赖的平台。</p><h3>三种类型的智能 KPI</h3><p>随着 KPI 的发展，它们对战略调整的贡献也在不断发展。我们的研究表明，人工智能丰富的 KPI 可通过三种方式改进仅跟踪绩效的指标。这些智能 KPI 可以更好地描述世界的现状（当前和过去的绩效），并更好地预测世界可能的情况（未来的绩效）。在某些情况下，智能 KPI 还表明可以或应该采取哪些措施来促进更好的结果。例如，执行仪表板通常对 KPI 进行颜色编码：红色表示性能下降，绿色表示性能达到/超出预期。这种编码是传统 KPI 和仪表板提供的一种简单的号召性用语类型。智能 KPI 更进一步：它们可以就后续步骤提出更详细、更具体的建议，并诊断对其他 KPI 的影响。</p><p>因此，智能 KPI 在三个重叠的意义上改进了传统 KPI：它们更好地描述和<em>预测</em>绩效，并<em>提供</em>更详细和更有价值的建议。这三种类型的智能 KPI 映射到描述性分析、预测性分析和规范性分析之间众所周知的区别。下面更详细地解释了这种 KPI 类型。</p><p> <strong>1. 智能描述性 KPI。</strong>这些 KPI 综合了历史和当前数据，以提供有关<em>已发生</em>或<em>正在发生的情况</em>的见解。它们可以更深入地了解绩效差距及其原因，从而更好地创建 KPI 或更好地理解 KPI 关系。赛诺菲的零食人工智能工具就是一个例子，它通过揭示不同 KPI 之间的关键相互依赖性来增强态势感知。</p><p> <strong>2. 智能预测 KPI。</strong>这些关键绩效指标通过产生可靠的领先指标来预测未来的绩效。它们提供了对潜在结果的可见性，从而能够采取先发制人的行动来减轻风险或利用机会。例如，通用电气已将其关键绩效指标 (KPI) 转变为关注领先指标。例如，该公司正在使用人工智能，通过将订单与产品和服务的安装基础进行比较来分析订单管道。这些详细的比较有助于准确地识别增加未来订单的机会，从而推动更强劲的收入和利润。正如通用电气高级财务副总裁兼前首席财务官 Carolina Dybeck Happe 所指出的那样，“利用领先指标可以在战略与战略实施之间建立更快、更紧密的联系。”</p><p> <strong>3. 智能的规定性 KPI。</strong>除了描述和预测之外，规范性 KPI 还通过人工智能推荐操作来丰富。它们不仅指出绩效差距，还提出纠正措施。例如，赛诺菲的智能 KPI 通过根据供应链绩效建议调整销售 KPI，从而协调运营和销售。</p><p>利用 AI 丰富关键绩效指标 (KPI)，使关键指标能够推动正确的绩效并加强战略协调。通过将 KPI 转变为智能的描述性、预测性和规范性工具，精通数字化的组织可以利用它们来增强态势感知、更有效的决策和改进绩效管理。</p><h3>领导力要点</h3><p>根据我们的研究，以下行动将帮助领导者使用人工智能来改善他们使用和开发 KPI 的方式以及他们如何使运营与战略保持一致。</p><p><strong>将 KPI 视为资产。</strong>当 KPI 被视为资产和指标时，它们会带来更加深思熟虑和有目的的投资。哪些 KPI 应该通过人工智能来丰富或改进？哪些 KPI 可以变得更具预测性和前瞻性？为了加强 KPI 之间的关系并增强战略一致性，需要对人工智能、数据和人员进行哪些投资？就像组织识别、培养、培训和培养员工以获得更大的责任和决策权一样，领导者也应该识别、培养、培训和发展他们的 KPI，以提供可行的见解和建议。</p><p><strong>鼓励提高绩效衡量的可见性和透明度。</strong>使 KPI 更加明显可以明确问责制和责任，鼓励讨论并培养共同的目标感。赛诺菲的案例说明，创建一个对高层领导者可共享且可见的绩效单一事实来源有利于协调一致。增加对 KPI 的跨职能访问可以鼓励增强态势感知和自我意识。民主化获取可信且透明的绩效数据可以帮助人们了解自己所处的位置以及需要去往的地方。最高管理层应致力于人工智能相关资源，以提高 KPI 的可见性和透明度。</p><p><strong>映射 KPI 关系和联系。</strong>整个企业的人员应该能够了解关键绩效者、关键绩效和关键绩效指标之间的相互关系。可见性和可视化动画化了组织协调的运作方式。施耐德电气首席治理官兼秘书长 Hervé Coureil 表示，数据驱动型领导者可以使用人工智能来绘制、建模和管理他们的绩效驱动因素和 KPI 优先事项。 Coureil 指出，描述和代表公司的“KPI 生态系统”可能是劳动力和资源密集型的第一步。这些地图和模型都可以识别和阐明哪些 KPI 应该共享或集成。例如，以客户为中心的组织可能会优先考虑围绕客户体验和客户生命周期价值指标的共享和集成 KPI。更好的映射和建模使 KPI 成为更好的资产。</p><p></p><h3>结论</h3><p>我们的研究发现，改善战略一致性不仅取决于正确定义最重要的指标，还取决于利用人工智能和更好的数据不断开发这些指标。但在更根本的层面上，我们的研究强调，人工智能正在承担曾经属于高管专属领域的任务，例如确定优先级、整合和共享 KPI。人工智能和 KPI 的融合正在重新定义 KPI 的使用方式以及 KPI 如何促进战略协调。对于数据驱动型领导者来说，不断将战略转化为更智能、更有组织性和更有价值的指标是一项日益重要的活动。</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/strategic-alignment-with-ai-and-smart-kpis/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title>自动化时代的采购</title><link/>https://sloanreview.mit.edu/article/procurement-in-the-age-of-automation/<comments> https://sloanreview.mit.edu/article/procurement-in-the-age-of-automation/#respond</comments><pubDate> Thu, 31 Aug 2023 11:00:01 +0000</pubDate> <dc:creator><![CDATA[Remko Van Hoek and Mary Lacity. <p>Remko Van Hoek 是阿肯色大学山姆沃尔顿商学院的供应链管理教授。他此前曾担任华特迪士尼公司的首席采购官，并在耐克和普华永道等其他几家公司担任采购主管职务。玛丽·莱西蒂 (Mary Lacity) 是沃尔顿商学院信息系统学的杰出教授。</p> ]]>; </dc:creator><category><![CDATA[Automation]]></category><category><![CDATA[Change Management]]></category><category><![CDATA[Negotiations]]></category><category><![CDATA[Procurement]]></category><category><![CDATA[Supply Chain Strategy]]></category><category><![CDATA[Data, AI, & Machine Learning]]></category><category><![CDATA[Leadership]]></category><category><![CDATA[Leading Change]]></category><category><![CDATA[Operations]]></category><category><![CDATA[Supply Chains & Logistics]]></category><description><![CDATA[Kotryna Zukauskaite/theispot.com The Research The authors have been studying procurement and automation for two decades.i Mary Lacity has conducted more than 50 case studies on enterprise use of automation technologies. Remko Van Hoek and Lacity have been studying early adopters of procurement technologies for three years, including companies using e-auctions, artificial intelligence, and other emerging [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/2023FALL-VanHoek_1290x860.jpg" alt="" /><figcaption><p class="attribution"> Kotryna Zukauskaite/theispot.com</p></figcaption></figure><aside class="callout-info"><h4>这个调查</h4><p>作者二十年来一直在研究采购和自动化。 Mary Lacity<a id="reflinki" class="reflink" href="#refi">就</a>企业使用自动化技术进行了 50 多个案例研究。 Remko Van Hoek 和 Lacity 三年来一直在研究采购技术的早期采用者，包括使用电子拍卖、人工智能和区块链等其他新兴技术的公司。在这篇文章中，他们采访了高级管理人员、业务部门领导、采购卓越中心的经理、数十家公司的买家、供应商和自动谈判软件供应商。</p></aside><p>高管们常常对自动化采购流程持怀疑态度，特别是当涉及谈判时，但自动化谈判工具为所有利益相关者提供了相当大的价值，并且可以在许多企业中有效使用。</p><p>在过去的三年里，我们研究了数十家组织的现代自动化采购实践。我们研究了已经存在一段时间但尚未广泛采用的技术，例如电子拍卖技术，以及较新的技术，例如人工智能聊天机器人。在我们的研究中，与进行传统的面对面谈判的公司相比，采用自动化采购谈判的公司始终能够节省资金，并通过识别更多合格的供应商来提高供应链的弹性。自动化谈判还提高了买家的生产力，使买家能够在现在由软件处理的任务上花费更少的时间和精力。供应商受益于明确的评估方式、更短的销售周期、对其当前地位的实时反馈，以及即使在涉及根深蒂固的现有供应商的情况下，他们也会受到公平对待的信心。</p><p></p><p>然而，实施新的采购模式和不同的关系方法并不容易。利益相关者通常有合理的担忧。支付商品和服务费用的业务部门负责人担心，自动化谈判将使他们成为最便宜的供应商（仅根据成本选择），从而使他们面临质量低劣、服务质量差和供应商关系破裂的问题。买家经常拒绝自动化工具，因为他们将谈判视为自己的专长，并担心被边缘化甚至被取代。供应商希望有机会在价格以外的方面脱颖而出；非现有供应商常常怀疑买家使用自动谈判只是为了迫使现有供应商降低价格，因此担心他们没有赢得业务的合法机会。</p><p>在本文中，我们详细介绍了组织从自动化谈判中获得的实质性好处、如何说服利益相关者使用该技术以及如何将自动化纳入采购流程。</p><h3>获得自动化谈判的好处</h3><p>我们研究中的大中型公司都通过自动化谈判实现了显着的节省。丹麦全球航运公司马士基每年使用各种自动化谈判支出达 10 亿美元，与人工谈判相比，过去几年节省了 7% 至 8%。沃尔玛国际公司对价值超过 70 亿美元的支出进行了自动化谈判，与传统谈判相比，获得了 5% 或更多的附加价值。谷歌从其大规模电子拍卖计划中看到了良好的效果，并将该技术嵌入到其采购工具包和流程中。</p><p>小公司也节省了开支。 Walker&#39;s Shortbread 是苏格兰的一家家族烘焙食品制造商，每年购买价值 8000 万英镑（1.05 亿美元）的原料和包装材料。 2023 年上半年，该公司 90% 的原材料支出都采用了自动谈判，根据类别节省了 1.5% 到 7% 之间。总部位于墨西哥的另一家家族食品制造商 Grupo Herdez 一直在使用电子拍卖来支付其年度原材料采购的一小部分，在香料和种子等商品上节省了约 8% 的费用。该公司计划今年将电子拍卖扩展到其他采购类别。</p><p>沃尔玛、马士基和谷歌已经扩大了跨采购类别的自动化谈判，包括营销媒体、船员食品、运输服务、总承包商服务、电子商务小包裹递送、供应链设备，甚至营销代理服务。截至 2023 年 6 月，马士基已进行了 10,000 多次电子拍卖。 2022年，沃尔玛将电子拍卖应用于其间接支出总额的65%。虽然与马士基或沃尔玛相比，Walker&#39;s Shortbread 进行的拍卖数量微乎其微，但其默认采购选项现在是电子拍卖。</p><p>自动化谈判极大地增加了公司可以包括的供应商数量和谈判回合数，同时显着减少了流程所需的时间。在种类繁多的电子拍卖中，沃尔玛有多达150家供应商同时参与，在大约两个小时内进行了多轮谈判。沃尔玛负责战略采购的副总裁迈克尔·德威特 (Michael DeWitt) 表示：“买家需要几个月的时间才能亲自完成这样的谈判。”</p><p>这种效率使各种规模的公司受益。 “电子拍卖执行的速度推动了价值的增长，”Walker&#39;s Shortbread 的采购主管 Kees Bressers 说道。</p><p></p><p>扩大自动化谈判规模的公司已将特定支出类别和市场条件的采购策略与最佳自动化流程和工具相匹配。 （请参阅“自动谈判的工作原理”。）他们致力于通过促进各自获得的利益来赢得三个利益相关群体（业务部门负责人、买家和供应商）的成员的支持。</p><div class="callout-highlight"><aside class="l-content-wrap"><article><h4>自动谈判如何运作</h4><p>有许多细致入微的自动谈判流程和工具，但从较高的层次来看，它们可以分为两类：一个买家和多个供应商，或者一个买家和一个供应商。在这两种情况下，人类买家都会为谈判事件准备软件。事件部署后，人类买家仍处于观望状态，而软件则与代表供应商的人类进行交互。</p><h4 style="color:black;">一个买家，多个供应商</h4><p>电子拍卖（沃尔玛称之为交互式投标）是一种实时在线谈判，通过提高时间和流程效率，利用竞争来实现真正的市场价值。 <a id="reflinkii" class="reflink" href="#refii">ii</a>与买家处于中间位置的传统谈判相比，电子拍卖允许买家退出流程，让供应商直接相互竞争，如下图所示。 </p><aside class="l-content-wrap"><article style="border-bottom-width:3px;border-bottom-style:solid;border-bottom-color:#00e0ff;margin-bottom:20px"><h4>传统与多个供应商的自动化</h4><p class="caption">在自动谈判中，买方仍然对流程和定义规则负责。 </p><p><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/MAG_VanHoek_Fig1.png" alt="传统与多个供应商的自动化" /><br /></article></aside><p>这个过程让市场发挥其作用，而不会出现潜在买家的偏见，例如偏向现有供应商。当至少有两家合格供应商愿意参与时，采购团队可以考虑进行电子拍卖。</p><div class="callout-toggle"><p>自动电子拍卖主要分为三种类型：</p><p><strong>英国反向拍卖。</strong>供应商实时竞争，成为最低出价者。供应商可以看到每个人的出价，并且可以重复输入更低的价格。在活动结束前提交最低价格的供应商将获得买方的业务。</p><p>英国反向拍卖适合在有大量竞争对手的市场中采购商品和服务。这种形式刺激了竞争性投标，并往往会在拍卖的最后阶段将投标人之间的定价推向一个狭窄的范围。该格式可用于一次招标中的多个批次，并且可以容纳许多轮次和投标人。</p><p>英式反向拍卖是最常用的形式，但买家应注意不要总是默认使用它们，而应考虑其他选择。</p><p><strong>荷兰反向拍卖。</strong>在这里，买家以低价进行竞争。如果没有供应商对初始价格出价，买方的软件就会逐步提高价格。该过程不断重复，直到供应商出价或买方达到其愿意支付的上限。第一个接受当前价格的供应商将获得买方的业务。</p><p>荷兰逆向拍卖采用赢者通吃的奖励策略，适合在供应商市场上采购商品和服务，因为供应商对达成协议有很大兴趣。大量的供应商是没有必要的。然而，该格式无法像英国反向拍卖那样实现价格发现。</p><p><strong>日本逆向拍卖。</strong>通过这种方式，买方以高价进行竞争。所有愿意接受此价格的供应商都将继续谈判。接下来，软件降低价格，所有愿意接受这个价格的供应商都可以继续竞争。该过程不断重复，直到供应商接受当前价格，然后获得买方的业务。</p><p>在投标人数量有限的市场中，日本反向拍卖是英国反向拍卖的良好替代方案。该格式确保供应商明确选择加入，这可以增强买家对报价的信心。</p><p>这种格式不太常用，买家和供应商可能不太熟悉。存在拍卖提前结束的风险，其价格高于买家期望的价格，因为只需一次增量出价即可赢得胜利。</p><h4 style="color:black;">一位买家，一位供应商</h4><p>即使只有一个供应商，买家也可以应用自动谈判。同样，需要考虑各种流程和工具。</p><p>人工智能驱动的聊天机器人会自动协商条款和条件，例如付款计划、终止条款和增长机会。聊天机器人被编程为产生确定性结果，并且不会协商买方未预先批准的任何条款。</p><p>动态报价请求工具掩盖了买方对逐项商品或服务的目标价格，等待人工供应商输入建议价格，然后提供有关协议水平的即时反馈。 </p><aside class="l-content-wrap"><article style="border-bottom-width:3px;border-bottom-style:solid;border-bottom-color:#00e0ff;margin-bottom:20px"><h4>传统与单一供应商的自动化</h4><p class="caption">自动化工具甚至可以用于与单个供应商进行谈判。 </p><p><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/MAG_VanHoek_Fig2.png" alt="传统与单一供应商的自动化" /><br /></article></aside></div></article></aside></div><ul><li><em>业务部门负责人</em>可以以最优惠的价格接触到更多合格供应商。他们继续定义需求、期望的条款和条件以及预算，因此他们的角色不会改变。然而，他们必须接受他们最喜欢的现有供应商可能会被取代的事实。</li><li><em>买家</em>并没有被淘汰，而是被淘汰了。相反，他们的职责扩大了，并且更有战略性地运用自己的专业知识。他们将考虑更多的采购选择，将业务部门负责人的需求正式化为模板或记分卡，寻找更多合格的供应商，并利用新的自动化工具。买家不再与供应商进行面对面谈判，而是组织并限定供应商参加自动谈判活动。</li><li><em>供应商</em>需要接受新的自动化工具和流程的培训。他们受益于提高公平性的规则、投标竞争力的实时反馈以及减轻的管理负担。与与买家面对面谈判的经验相比，供应商花更多的时间规划自动化活动，但谈判的时间却少得多，从而缩短了整体销售周期。</li></ul><p>通过研究已经成功过渡到自动化谈判的公司，我们确定了六种关键实践，可以帮助领导者克服利益相关者的阻力并创造价值。</p><p></p><p> <strong>1. 强制考虑，而不是使用。</strong>虽然高管们可能会倾向于强制采用自动化采购，但这通常是获得业务部门负责人和买家支持的糟糕方法。相反，大型采购组织的高管可能会要求买家<em>考虑</em>参与自动谈判。这种做法允许买家利用他们的主题专业知识以及与业务部门负责人的关系来确定最佳的自动化机会，这有助于利益相关者的支持并优化自动化的有效性。</p><p> 2009 年航运业处境艰难，因此马士基认为削减成本对于确保其市场竞争力至关重要。当时的首席采购官（CPO）要求买家<em>考虑</em>采用电子拍卖，并为每个买家设定最低年度目标，作为其年度绩效评估的一部分。 CPO 认识到不使用电子拍卖可能有正当理由，例如投标人数量不足，因此业务部门负责人和买家选择最适合自动谈判的交易来实现目标。</p><p>与马士基一样，沃尔玛要求所有买家考虑实现所有谈判的自动化。最初，采购负责人与业务部门负责人和买家进行路演，以传达潜在价值，并明确买家可以通过记录其理由来选择退出。</p><p> “通过将拍卖作为首选默认方式，它迫使我们制定更好的采购策略，”沃尔玛的德威特说。 “它鼓励买家跳出框框思考并寻找更多供应商，无论他们是否进行拍卖，这最终都会使企业受益。”</p><p>采购业务规模较小的公司的高管可能会发现没有必要强制执行。例如，Walker&#39;s Shortbread 整个公司只有五名全职采购专家，而且他们都在同一个办公室工作，因此 Bressers 能够直接与他们讨论策略。这种方法帮助他获得了一家公司对数字采购的认可，该公司几十年来一直通过电话和电子邮件管理流程。</p><p></p><p>同样，Grupo Herdez 也没有强制考虑或使用电子拍卖。 COVID-19 大流行引发的经济危机使成本合理化成为生存的要求。采购团队向业务部门所有者、买家和供应商传达了使用自动谈判来降低成本的必要性。业务部门所有者和供应商的观点最有说服力，因为该公司已经使用了一些相同的供应商长达 40 年或更长时间。为了让现有供应商同意参与电子拍卖，Grupo Herdez 的采购经理向供应商的高级领导解释了通过竞争来削减成本的经济需要。 “尽管他们中的许多人因为规模比我们大而在关系中拥有更大的权力，但他们理解并接受我们的需求，”战略供应经理 Felipe Díaz Mojica 说。</p><p> <strong>2. 让成功看得见。</strong>虽然强制考虑电子拍卖有助于全球企业起步，但让整个公司都能看到早期的成功可以让业务部门负责人和买家兴奋不已——尤其是当领导者将买家的作用归功于买家时。谷歌在员工通讯中展示了他们的成功，并根据员工通过自动谈判进行的活动数量提供奖励。</p><p>在马士基自动化之旅的早期阶段，首席采购官在大屏幕上直播谈判，并对领导电子拍卖的业务部门负责人和买家表示祝贺。由于每次电子拍卖都能节省两位数的成本，这些成功打破了利益相关者的自满情绪。马士基采购总监 Nikolaj Jessen-Klixbüll 表示：“自动化谈判的‘推动’策略很快就演变成需求‘拉动’。”</p><p></p><p>在沃尔玛，来自一个国家的业务部门负责人对自动谈判的价值特别怀疑，因此采购负责人邀请他们观看礼堂大屏幕上的现场拍卖。德威特回忆说，这些非信徒最初坐在后面，双臂交叉。</p><p> “看起来没有人高兴，”他说。 “然后拍卖开始了，价格开始下跌。竞争非常激烈，你可以看到房间里的气氛发生了变化。人们开始微笑。最后，他们互相击掌，也向我们击掌。从那以后，他们成为了我们最好的冠军。”</p><p>沃尔玛每月颁发奖项，表彰那些在新支出类别、大型活动或新地区使用自动谈判的买家。该奖项的目的之一是向整个公司发出信号，虽然软件可以实现自动谈判，但运行它们的是买家。</p><p>在 Walker&#39;s Shortbread，业务部门负责人需要了解供应商在批准新采购模式之前如何提交投标。 “企业主很紧张，”布雷瑟斯说。 “我们是一家拥有 125 年历史的公司，交易是通过握手和采购订单完成的。”在进行现场直播之前，他通过在沙盒环境中演示电子拍卖赢得了他们的支持。然后，他邀请主要业务部门负责人和采购团队参加前几次现场拍卖，拍卖会在大屏幕上显示。企业领导观摩招标过程后，认为招标过程公平，对较低的价格感到非常满意。</p><p>这些早期成功的发生只是因为这些公司仔细规划了自动化活动，包括审查供应商。</p><p> <strong>3. 对供应商进行资格预审。</strong>采购团队应在自动谈判活动之前招募并预先批准供应商。这种做法确保只有有能力的供应商才能获得业务。采购团队可能还需要收集初步建议，以增加合格供应商的数量。</p><p>马士基的买家与业务部门负责人合作以确定他们的需求。这些要求被转换为供应商分数，用于根据最低要求对供应商进行资格预审，并在谈判开始前根据其比较地位对他们进行排名。例如，碳足迹较低的供应商将比碳足迹较高的同等供应商更受青睐。 <a id="reflink1" class="reflink" href="#ref1">1</a></p><p> Jessen-Klixbüll 表示：“为了取得成功，企业主必须明确他们的先决条件。” “他们知道，如果企业不相信供应商能够提供服务，我们就不会邀请任何供应商参与。”</p><p>在电子拍卖之前，如果市场上供应商有限或供应商之间的价格差异较大，马士基会使用自动动态报价请求 (RFQ)。动态询价流程旨在缩小定价差距并使更多供应商有资格参加电子拍卖。当市场上不存在其他可行的供应商时，马士基还使用此流程与单个供应商谈判交易。</p><p>业务部门负责人和买家根据市场评估、需求和预算商定目标价格。活动期间，马士基的软件显示空白的单项价格表，但未透露公司的目标价格。供应商提交建议价格后，动态询价系统会自动反馈供应商报价的竞争力，使用红绿灯比喻：绿色表示出价具有竞争力，琥珀色表示出价接近竞争性，红色表示出价接近竞争性。表明该投标不具有竞争力。</p><p>与时间限制较短的电子拍卖不同，动态询价活动会持续几天，以便供应商有时间与下级供应商合作进一步折扣，然后输入新的、更具竞争力的出价。</p><p>沃尔玛使用记分卡来评估业务部门负责人对质量、服务、安全、可持续性、成本和其他标准的加权要求。供应商经过资格预审，并根据其记分卡分配初始排名。记分卡嵌入交互式投标软件中，因此供应商可以看到他们的排名。如果业务部门负责人非常重视成本，那么供应商就会通过出价较低来提高排名。如果非价格因素的权重很大，降低价格不会大幅提高供应商的排名。</p><p>沃尔玛采购转型和卓越中心 (COE) 总监 Bayan A. Hariri Sr. 表示：“需要做好前期工作，让企业和买家利益相关者制定记分卡。” “但这使得活动结束后奖励供应商变得更加容易。”</p><p>在采用自动谈判之前，Walker&#39;s Shortbread 的买家联系现有供应商和一两个其他供应商以确定市场价格，然后利用该信息与现有供应商重新协商价格。现在，随着自动化谈判的实施，买家首先邀请供应商回复询价，以确定供应商的能力并了解当前的市场价格。然后，Walker&#39;s Shortbread 使用此信息对供应商进行电子拍卖资格预审。现有企业现在正在争夺这项业务。某些采购类别的合格供应商数量增加了一倍，竞争加剧。</p><p> <strong>4. 公平对待非现有供应商。</strong>在自动谈判开始之前，采购团队必须向供应商传达价值、流程和奖励标准。谷歌全球采购经理 Lily Han 表示：“重要的是要与供应商沟通，通过电子拍卖，供应商可以更好、更实时地了解自己在投标中的地位。” “他们还可以非常直接地控制自己的竞争地位；更多的事情掌握在他们手中。” At the same time, suppliers need to be assured that the other suppliers will not know who is competing in the event, said Grupo Herdez&#39;s Díaz Mojica.</p><p> As most procurement professionals will attest, business unit heads and buyers prefer incumbent suppliers because change creates more work and potential operational risks. Companies should adhere to a strict policy that the supplier that wins the negotiation should be awarded the business. There should be no negotiations after the event; incumbent suppliers should not be able to overturn the results of automated negotiations with offers of big discounts afterward. Maersk, Walmart, and Walker&#39;s Shortbread adhere to this golden rule. Walker&#39;s Shortbread selects the winner based on a weighted average of technical and cost criteria.</p><p> To increase fairness and avoid misunderstandings about process and purpose, Walmart also provides every supplier with personalized training before they participate in automated negotiations. Buyers explain the auction design and award criteria and ensure that suppliers understand how to use the technology.</p><p> Supplier feedback on the training has been positive, but a better indicator of supplier value is repeat participation, according to DeWitt: “Suppliers come back again and again.”</p><p> <strong>5. Unleash the power of AI to improve deals with tail-end suppliers.</strong> Normally, procurement organizations negotiate only with their major suppliers, which typically represent 20% of a company&#39;s suppliers but 80% of its procurement budget. Buyers generally offer tail-end suppliers cookie-cutter deals that are nonnegotiable. Recently, however, companies like Walmart, Maersk, and others have found ways to improve deals with tail-end suppliers using AI-powered chatbots.</p><p> Like e-auction technology, an AI chatbot can run 2,000 negotiations simultaneously, 24-7, while allowing suppliers time for bid preparation if needed. “The ability to take on a massive amount of negotiations simultaneously and to be able to scale that across a number of scenarios is of incredible value,” said Jessen-Klixbüll.</p><p> Scaling the chatbots has increased productivity for both Maersk and Walmart because the software learns from every negotiation, reducing the setup time for new procurement categories.</p><p> When using AI-powered chatbots, business unit heads and buyers start by identifying the suppliers to approach and defining acceptable trade-offs that will become part of the programming. For example, business unit heads might prefer a price discount in exchange for paying the supplier earlier. Or they may favor offering suppliers a 60-day written termination notice rather than a termination-for-convenience clause, or want to offer the supplier opportunities for growth by increasing their product mix and sales volumes.</p><p> Unlike the many AI tools that produce probabilistic outcomes, AI-driven automated procurement tools produce deterministic outcomes, thus eliminating the possibility of surprise results. Once the tools are deployed, the buyer steps out of the process and the chatbot presents alternatives to a human representing the supplier.</p><p> Maersk began using an AI-powered chatbot predominantly for inland transportation, where volume and traffic are too limited to justify a full-blown auction. Maersk pre-awards a supplier for a specific region, and when the supplier is needed, the AI chatbot leads the negotiation.</p><p> Walmart first used its AI chatbot for contract renegotiations with tail-end suppliers in one country and has since expanded to midtier suppliers and multiple countries. Its average savings range from 7% to 10%. In return, suppliers have gained better termination conditions, early payments, and/or growth opportunities.</p><p> Most tail-end suppliers welcomed the opportunity to actively negotiate with Walmart for the first time. In follow-up surveys, 67% of suppliers said that they found the system easy to use and 83% liked the ability to counteroffer. <a id="reflink2" class="reflink" href="#ref2">2</a></p><p> Smaller companies also can gain benefits from AI chatbots. Genuine Cable Group (GCG), a US company with 1,200 employees, is currently training its chatbot on different scenarios, with plans to launch it in the fourth quarter of 2023. GCG has tens of thousands of suppliers, with some deals as small as $10,000 in spending per year. The chatbot will allow GCG to engage with more suppliers than it had been able to in the past, according to CEO Steve Maucieri. The project is low risk because the software provider offers a gain-sharing model in which its fees are paid from the savings generated. Maucieri also anticipates a future in which his many customers will use AI-powered chatbots to negotiate deals with the company.</p><p> <strong>6. Create a formal support structure.</strong> Formal support structures, such as COEs, can help to scale automated negotiations across geographies, business units, and spending categories.</p><p> Maersk came to realize that if it wanted to embed mature procurement processes across the globe, it needed to have procurement teams located closer to its businesses. It created a global COE with regional support representatives. Teams in Panama City, Panama; Charlotte, NC; Cape Town, South Africa; Rotterdam, The Netherlands; Dubai, United Arab Emirates; and Shanghai support Latin America, North America, Africa, Europe, the Middle East, and Asia, respectively.</p><p> The COE representatives don&#39;t take negotiations away from buyers. Instead, they provide tool expertise and support buyers&#39; efforts to engage business stakeholders, consider negotiation types, and design automated negotiations using templates. The COE also focuses on supplier experience so that the automated negotiations ease suppliers&#39; burdens too.</p><p> “We don&#39;t want to make the negotiation too complex, difficult to use, or bureaucratic, because buyers and suppliers will eventually walk away,” said Jessen-Klixbüll.</p><p> Walmart also has a COE with a dedicated team of super users who support buyers and suppliers. Walmart&#39;s procurement leadership views the maturation of the company&#39;s procurement strategy and capability as one of the biggest benefits of automating negotiations. The COE continually updates its templates to guide buyers to the optimal sourcing approach. “We always position automated negotiations as a strategy that enhances the negotiation as part of the sourcing process, and not as a replacement of the sourcing process itself,” DeWitt said.</p><p> For both Maersk and Walmart, buyer and supplier training is ongoing, given that new employees and suppliers are constantly onboarding and automation options and negotiation types are evolving.</p><p></p><p> Smaller companies can engage the services of an outsourcing provider to create formal structures. Walker&#39;s Shortbread, for example, hired an e-auction software provider to manage the infrastructure and e-auctions.</p><p></p><p> Ultimately, automating negotiations is not about the technologies; it&#39;s about enabling buyers to be more efficient and effective by focusing on procurement strategy. Suppliers benefit by replacing high-pressure person-to-person negotiations with clearly defined automated negotiation events, and sales cycles no longer languish. Business unit heads benefit from measurable savings and from expanded pools of qualified suppliers. To capture these benefits, executives should focus less on technology and more on effective procurement strategy, deployment, and change management. The good news is that the practices we&#39;ve described are highly transferable across companies and industries and have the potential to benefit many.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/procurement-in-the-age-of-automation/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> Generative AI at Mastercard: Governance Takes Center Stage</title><link/> https://sloanreview.mit.edu/article/generative-ai-at-mastercard-governance-takes-center-stage/<comments> https://sloanreview.mit.edu/article/generative-ai-at-mastercard-governance-takes-center-stage/#respond</comments><pubDate> Wed, 30 Aug 2023 11:00:30 +0000</pubDate> <dc:creator><![CDATA[Thomas H. Davenport and Randy Bean. <p>Thomas H. Davenport ( <a href="https://twitter.com/tdav">@tdav</a> ) is the President&#39;s Distinguished Professor of Information Technology and Management at Babson College, a visiting professor at Oxford&#39;s Saïd Business School, and a fellow of the MIT Initiative on the Digital Economy. He is coauthor of <cite>Working With AI: Real Stories of Human-Machine Collaboration</cite> (MIT Press, 2022). Randy Bean ( <a href="https://twitter.com/randybeannvp">@randybeannvp</a> ) is an industry thought leader, author, founder, and CEO and currently serves as innovation fellow, data strategy, for global consultancy Wavestone. He is the author of <cite>Fail Fast, Learn Faster: Lessons in Data-Driven Leadership in an Age of Disruption, Big Data, and AI</cite> (Wiley, 2021).</p> ]]>; </dc:creator><category><![CDATA[AI Strategy]]></category><category><![CDATA[Analytics & Organizational Culture]]></category><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Generative AI]]></category><category><![CDATA[AI & Machine Learning]]></category><category><![CDATA[Data, AI, & Machine Learning]]></category><category><![CDATA[IT Governance & Leadership]]></category><category><![CDATA[Managing Technology]]></category><description><![CDATA[If you saw the action-adventure movie Everything Everywhere All at Once, you might have had the same reaction we did. Impressive and exciting? No doubt — that’s one reason why it won seven Academy Awards. A portent of the future? Perhaps — as scientists explore the idea of a multiverse, the film provides one vision [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/Davenport-1290x860-1.jpg" alt="" /><br /></figure><p> If you saw the action-adventure movie <cite>Everything Everywhere All at Once</cite> , you might have had the same reaction we did. Impressive and exciting? No doubt — that&#39;s one reason why it won seven Academy Awards. A portent of the future? Perhaps — as scientists explore the <a href="https://www.forbes.com/sites/jamiecartereurope/2023/03/12/is-the-multiverse-real-the-science-behind-everything-everywhere-all-at-once/?sh=4a4837583475">idea of a multiverse</a> , the film provides one vision of what it might look like. Somewhat bizarre and confusing? Well, to us anyway.</p><p> JoAnn Stonier, until recently Mastercard&#39;s chief data officer, made an apt comparison between the movie and generative AI when she appeared on a <a href="https://venturebeat.com/ai/generative-ai-is-everything-everywhere-all-at-once-in-the-enterprise-says-mastercard-cdo/">recent panel</a> . “Everything everywhere” is a good way to characterize the technology — exciting, confusing, and important all at the same time. We have previously <a href="https://www.forbes.com/sites/tomdavenport/2020/04/13/joann-stonier-of-mastercard-a-unique-take-on-the-cdo-role/?sh=4dea1d172ac6">written about</a> Stonier and her unusual position as one of the few CDOs who has been heavily focused on data ethics for many years. We interviewed her on one of her last days as CDO; she&#39;s since become a Mastercard fellow but will still work on data and AI ethics issues.</p><p></p><p> After the interview, we were somewhat relieved, as you might be, to find out that Stonier and Mastercard are still feeling their way with regard to generative AI. That&#39;s true of many companies. More than half of the respondents to a recent VentureBeat survey said their organizations are experimenting with AI, but only <a href="https://venturebeat.com/ai/more-than-70-of-companies-are-experimenting-with-generative-ai-but-few-are-willing-to-commit-more-spending/">18% of those companies have begun implementing it</a> . The same percentage said they expect to spend more on the technology in the coming year.</p><p> Of course, Mastercard is an old hand at data, analytics, and AI: We wrote about its efforts toward becoming an “ <a href="https://sloanreview.mit.edu/article/becoming-an-ai-powerhouse-means-going-all-in/">AI powerhouse</a> ” a year ago, and Stonier <a href="https://sloanreview.mit.edu/audio/designing-a-better-future-mastercards-joann-stonier/">discussed the company&#39;s use of AI</a> on the <cite>MIT Sloan Management Review</cite> podcast <cite>Me, Myself, and AI</cite> . Mastercard has been in the AI space for more than a decade, most significantly in the cybersecurity realm. That a leader and company so experienced with AI is still trying to work out the details of a generative AI strategy should be comforting to many other companies and managers.</p><p></p><h3> What&#39;s Already Clear</h3><p> Mastercard&#39;s extensive experience with previous forms of AI led it to build a robust methodology and governance process. At a high level, this process involves understanding the data, understanding the models, and reviewing the output and the related outcomes.</p><p> Each of those steps will come into the process for evaluating generative models, but they are likely to have a different flavor. Mastercard has no shortage of structured numerical data, of course, but the data that generative AI processes are often images and less-structured text. Given the complexity and size of generative models, understanding exactly how a given input produces a specific output is very challenging. That places even more importance on the step of reviewing outcomes, which need to be assessed for factual accuracy, biased or toxic language, and value to the user, as well as unintended consequences to individuals, organizations, and the ecosystems in which the outcomes might operate.</p><p> Despite the uncertainties inherent in the technology, Mastercard has already established some policies with regard to generative AI. Shortly after the introduction of ChatGPT in November 2022, the company put guidelines in place to ensure that employees innovate responsibly with the new technology. This encourages internal exploration of the models its vendor provides while safeguarding confidential company information.</p><p> Some companies have gone so far as to ban ChatGPT and the use of other large language models by employees, but Mastercard hasn&#39;t been tempted to do so. “Some of the use cases have been more creative than others, but we haven&#39;t had any problems thus far,” Stonier said. Perhaps that&#39;s because, as she noted, “everybody in the company is more aware and digitally engaged now, and they see governance as part of everyone&#39;s job.”</p><p> We think that virtually every company should be educating its senior executives and board members about generative AI, and Mastercard has been predictably active in that regard. It has held multiple sessions for the senior executive team and board members to address different aspects of the technology, including the opportunities it provides, the regulation it needs, and the process the company should follow in implementing it. Numerous outside experts have participated in these briefings, and Stonier noted that there are several tech-savvy board members who already understood the technology well.</p><p> Mastercard has an established council of AI-informed leaders from all areas of the business that evaluates AI use cases before their deployment, and it has added generative AI use cases to those that are reviewed. Some of the use cases developed so far involve areas like fraud detection, internal knowledge management, and personalization. Even more use cases are in the experimentation phase and are not yet intended for production deployment.</p><p></p><p> Although detailed government policies for generative AI haven&#39;t been issued yet for the US, Stonier said that it&#39;s already clear that there will be different policies for the many different capabilities of generative AI. Because Mastercard depends heavily on reliable information systems, for example, using generative AI to develop programming code will be treated differently than using it to create marketing copy.</p><p> It&#39;s also clear that an interdisciplinary and cross-functional approach will be required to manage generative AI at Mastercard. Already, lawyers, HR professionals, and systems and data engineers and architects are engaged in developing the company&#39;s approach to the technology. As use cases become more customer-oriented (they are primarily internal now), it&#39;s likely that more parts of the organization will become involved. External regulators will want to see how the company built any “black box” models, where the logic and data sources the models are built on aren&#39;t readily visible to users. Stonier said that governance of generative AI is a challenge, given all of the possible use cases and aspects of the organization that are involved. She expects that, consistent with the previous AI development process, governance will have to address not only what the users of the technology are trying to achieve but also what the most likely outcomes will be.</p><h3> What&#39;s Still Evolving</h3><p> Stonier said that many aspects of generative AI are still being discussed, as they should be. This is a period of experimentation for the company and its employees, and Stonier noted that no one wants to dampen it as long as <a href="https://www.mastercard.us/en-us/vision/corp-responsibility/data-responsibility.html">the company&#39;s data responsibility principles</a> are being followed. Mastercard wants to use generative AI as an opportunity for learning and to eventually benefit from it as much as it has gained from conventional AI in its fraud-reduction and cybersecurity initiatives.</p><p> At the moment, the primary benefits being realized are internal productivity gains for the company&#39;s own processes. Use cases for Mastercard&#39;s customers, including merchants who accept Mastercard, will come later. There is the potential for highly personalized data analysis and messages for customers in the future.</p><p> Mastercard already has a well-defined process for rolling out data and data products and even a business unit — called Data &amp; Services, which Tom <a href="https://www.forbes.com/sites/tomdavenport/2021/01/13/data-exhaust-turbocharges-mastercard/?sh=451638f887df">wrote about</a> a couple of years ago — for making them available to customers. Stonier believes that Data &amp; Services and the company&#39;s Cyber &amp; Intelligence business will be the most likely to implement generative AI-based products in the future, adding to a wide array of existing AI solutions. She is confident that these generative AI uses will employ multiple types of language models and that they will make extensive use of humans in the loop, perhaps through reinforcement learning with human feedback. There will be extensive testing, she said, to ensure that there are no substantial hallucinations or other problematic outputs in the products. We think this is important; if machine learning is like analytics on steroids, generative AI is like machine learning on LSD. That captures the unpredictable aspect of the technology.</p><p> The specific architectures for generative AI models have also yet to be determined. Stonier feels that there will definitely be multiple models, but she&#39;s not sure whether they will be stacked — combined for one use case — or arrayed, with a front-end system determining which is most appropriate for the context.</p><p></p><p> We asked Stonier whether she feels that generative AI is an incremental or hugely transformative technology. “It&#39;s been incremental so far, but eventually it may be transformative,” she said. “But any transformation won&#39;t be a big-bang moment — it will take place over time. Improvements in operating efficiency will come relatively quickly, but changes in products and services will take longer.”</p><p> If your company is wrestling with how to govern and fully take advantage of generative AI, Mastercard&#39;s experience should make you feel somewhat more relaxed. This technology may or may not transform your business, but it certainly raises many new issues and opportunities. They don&#39;t all need to be figured out overnight.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/generative-ai-at-mastercard-governance-takes-center-stage/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> Protecting Society From AI Harms: Amnesty International&#39;s Matt Mahmoudi and Damini Satija (Part 1)</title><link/> https://sloanreview.mit.edu/audio/protecting-society-from-ai-harms-amnesty-internationals-matt-mahmoudi-and-damini-satija-part-1/<comments> https://sloanreview.mit.edu/audio/protecting-society-from-ai-harms-amnesty-internationals-matt-mahmoudi-and-damini-satija-part-1/#respond</comments><pubDate> Tue, 29 Aug 2023 11:00:47 +0000</pubDate> <dc:creator><![CDATA[Sam Ransbotham and Shervin Khodabandeh. <p>Sam Ransbotham ( <a href="https://twitter.com/ransbotham">@ransbotham</a> ) is a professor in the information systems department at the Carroll School of Management at Boston College, as well as guest editor for <cite>MIT Sloan Management Review</cite> &#39;s Artificial Intelligence and Business Strategy Big Ideas initiative. Shervin Khodabandeh is a senior partner and managing director at BCG and the coleader of BCG GAMMA (BCG&#39;s AI practice) in North America.您可以通过<a href="mailto:shervin@bcg.com">shervin@bcg.com</a>联系他。</p><p class="mt20"> <cite>Me, Myself, and AI</cite> is a collaborative podcast from <cite>MIT Sloan Management Review</cite> and Boston Consulting Group and is hosted by Sam Ransbotham and Shervin Khodabandeh. Our engineer is David Lishansky, and the coordinating producers are Allison Ryder and Sophie Rüdinger.</p> ]]>; </dc:creator><category><![CDATA[Ethics]]></category><category><![CDATA[Information Sharing]]></category><category><![CDATA[Public Policy]]></category><category><![CDATA[Social Justice]]></category><category><![CDATA[Data, AI, & Machine Learning]]></category><category><![CDATA[Equality]]></category><category><![CDATA[Managing Technology]]></category><category><![CDATA[Security & Privacy]]></category><category><![CDATA[Social Responsibility]]></category><category><![CDATA[Artificial Intelligence and Business Strategy]]></category><description><![CDATA[Amnesty International brings together more than 10 million staff members and volunteers worldwide to advocate for social justice. Damini Satija and Matt Mahmoudi work with Amnesty Tech, a division of the human rights organization that focuses on the role of government, Big Tech, and technologies like artificial intelligence in areas like surveillance, discrimination, and bias. [&#8230;]]]></description><content:encoded><![CDATA[<p></p><p> Amnesty International brings together more than 10 million staff members and volunteers worldwide to advocate for social justice. Damini Satija and Matt Mahmoudi work with Amnesty Tech, a division of the human rights organization that focuses on the role of government, Big Tech, and technologies like artificial intelligence in areas like surveillance, discrimination, and bias.</p><p> On this episode of the <cite>Me, Myself, and AI</cite> podcast, Matt and Damini join hosts Sam Ransbotham and Shervin Khodabandeh to highlight scenarios in which AI tools can put human rights at risk, such as when governments and public-sector agencies use facial recognition systems to track social activists or algorithms to make automated decisions about public housing access and child welfare. Damini and Matt caution that AI technology cannot fix human problems like bias, discrimination, and inequality; that will take human intervention and changes to public policy.</p><p> For more on what organizations can do to combat the unintended negative consequences arising from the use of automated technologies, tune in to our next episode, Part 2 of our conversation with Matt and Damini, airing Sept. 13, 2023. </p><aside class="callout-info"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/07/MMAI-S7-E7-E8-Mahmoudi-Satija-Amnesty-International-headshot-3000-scaled.jpg" alt="Matt Mahmoudi and Damini Satija"></p><h4> Matt Mahmoudi and Damini Satija, Amnesty International</h4><p> Matt Mahmoudi is a lecturer, researcher, and organizer. He&#39;s been leading Amnesty International&#39;s research and advocacy efforts on banning facial recognition technologies and exposing their uses against racialized communities, from New York City to the occupied Palestinian territories. He was the inaugural recipient of the Jo Cox Ph.D. scholarship at the University of Cambridge, where he studied digital urban infrastructures as new frontiers for racial capitalism and remains an affiliated lecturer in sociology. His work has appeared in the journals <cite>The Sociological Review</cite> and <cite>International Political Sociology</cite> and the book <cite>Digital Witness</cite> (Oxford University Press, 2020). His forthcoming book is <cite>Migrants in the Digital Periphery: New Urban Frontiers of Control</cite> (University of California Press, 2023).</p><p> Damini Satija is a human rights and public policy expert working on data and artificial intelligence, with a focus on algorithmic discrimination, welfare automation, government surveillance, and tech equity. She is head of the Algorithmic Accountability Lab and a deputy director at Amnesty Tech. She previously worked as an adviser to the UK government on data and AI ethics and represented the UK as a policy expert on AI and human rights at the Council of Europe. She has a master&#39;s degree in public administration from Columbia University&#39;s School of International and Public Affairs.</p></aside><aside class="callout-info fl mobile-fn mt40"><h5> AI for Leaders on LinkedIn<br /></h5><p style="font-size:1.4rem;"> If you&#39;re enjoying the <cite>Me, Myself, and AI</cite> podcast, continue the conversation with us on LinkedIn. Join the <a href="https://www.linkedin.com/groups/13977401/" class="marketing-click" id="AI_for_leaders_link[MMAI]">AI for Leaders</a> group today.</p><p class="is-button mt20"> <a href="https://www.linkedin.com/groups/13977401/" class="marketing-click" id="AI_for_leaders_link[MMAI]">Join now »</a></p></aside><p> Subscribe to <cite>Me, Myself, and AI</cite> on <a href="https://podcasts.apple.com/us/podcast/me-myself-and-ai/id1533115958">Apple Podcasts</a> , <a href="https://open.spotify.com/show/7ysPBcYtOPVgI6W5an6lup">Spotify</a> , or <a href="https://podcasts.google.com/feed/aHR0cHM6Ly9tZW15c2VsZmFuZGFpLmxpYnN5bi5jb20vcnNz">Google Podcasts</a> .</p><h4> Transcript</h4><p> <strong>Shervin Khodabandeh:</strong> Many of our guests aim to use AI for good in their organizations. On today&#39;s episode, we speak with two researchers who focus on protecting human rights when artificial intelligence tools are used.</p><p> <strong>Damini Satija:</strong> I&#39;m Damini Satija …</p><p> <strong>Matt Mahmoudi:</strong> … and I&#39;m Matt Mahmoudi from Amnesty International …</p><p> <strong>Damini Satija:</strong> … and you&#39;re listening to <cite>Me, Myself, and AI</cite> .</p><p> <strong>Sam Ransbotham:</strong> Welcome to <cite>Me, Myself, and AI</cite> , a podcast on artificial intelligence in business. Each episode, we introduce you to someone innovating with AI. I&#39;m Sam Ransbotham, professor of analytics at Boston College. I&#39;m also the AI and business strategy guest editor at <cite>MIT Sloan Management Review</cite> .</p><p> <strong>Shervin Khodabandeh:</strong> And I&#39;m Shervin Khodabandeh, senior partner with BCG and one of the leaders of our AI business. Together, <cite>MIT SMR</cite> and BCG have been researching and publishing on AI since 2017, interviewing hundreds of practitioners and surveying thousands of companies on what it takes to build and to deploy and scale AI capabilities and really transform the way organizations operate.</p><p> Welcome. Today, Sam and I are excited to be talking with Matt Mahmoudi and Damini Satija from Amnesty International. Matt, Damini, thanks for joining us today.让我们开始吧。 Matt, tell us a little bit about your role at Amnesty.</p><p> <strong>Matt Mahmoudi:</strong> Absolutely. And, yeah, thanks so much for having us. I am an adviser and researcher on artificial intelligence and human rights at Amnesty&#39;s tech program. My role has been focusing on how certain AI technologies and, in particular, AI-driven surveillance are taken up by policing agencies [and] developed by companies, ostensibly for efficiency but often leading to discriminatory outcomes, inequalities of various forms, and affecting some of the most historically marginalized communities. So over the past couple of years in particular, I&#39;ve been tracing facial recognition deployments, the companies involved, as well as where police are using the tools.</p><p> We&#39;ve looked at facial recognition in places such as New York City, Hyderabad City in India, and the occupied Palestinian territories and [are] really paying attention to the ways in which these technologies that promised greater efficiency and promised to be sort of smarter ways of moving people from A to B or ensuring their safety are actually leading to the erosion of their rights.</p><p> <strong>Sam Ransbotham:</strong> Matt, tell us a little bit about what Amnesty International does, what the structure is, [and] how [its] technology practices got started.</p><p> <strong>Matt Mahmoudi:</strong> Amnesty International is a movement of over 10 million people worldwide who work together via, for example, volunteering or through doing research and advocacy and campaigning to mobilize around key human rights issues of the day.</p><p> As far as the technology and human rights program is concerned, also known as Amnesty Tech, we&#39;re a collective of technologists, researchers, advocates, legal scholars, and more who work together on trying to hold both companies and states to account on their usage and development of technologies that really put those fundamental human rights at risk. So our work is to investigate and expose the ways in which those configurations of technologies are being used to erode those rights and, where possible, to advocate for stronger safeguards and regulations and human rights practices that enable us to enjoy those rights even as we continue to live through a rapidly changing world.</p><p> <strong>Shervin Khodabandeh:</strong> Damini, tell us a little bit about what the Algorithmic Accountability Lab does.</p><p> <strong>Damini Satija:</strong> Yeah, thank you so much for having us here today. I work in the tech program, and I head up a team called the Algorithmic Accountability Lab, a relatively new team within Amnesty Tech. We look specifically at the increasing use of automation and AI technologies in the public sector and, within that, specifically in welfare contexts and social protection contexts. So we look at how governments and public-sector agencies are using automation to determine who gets access to basic essential services like housing, education, health care benefits, and so on. And our particular interest is in investigating and understanding how these tools have discriminatory impact or disproportionate impact on already marginalized groups, which is something we&#39;ve already seen evidence of in public sector automation or automation of welfare.</p><p> And the team itself is a multidisciplinary team of seven individuals: data scientists, human rights researchers, advocacy, legal expertise — a whole range … to support the vision that we will take a holistic view in interrogating and understanding these systems&#39; impacts on society.</p><p> <strong>Shervin Khodabandeh:</strong> Thank you for that. This is quite interesting, Sam, because when most of our guests are talking to us about how they use AI, [it&#39;s] to create more profits or more revenues or reduce costs or do good, but generally, right? It seems like your role is to make sure we don&#39;t do bad stuff with AI, right?</p><p> And so in that context, given your background and expertise in AI, what do you think some of the guiding principles are, and how is it different? Like, when you&#39;re looking for bad actors, I have to imagine that it&#39;s fundamentally a bit different than looking to do good. I&#39;m going to start with you, Matt. How do you go about doing this?</p><p> <strong>Matt Mahmoudi:</strong> Well, oftentimes, we learn about some cases involving a particular person that has faced a form of discrimination. In the context of New York City, for example, we were put in touch with an activist called Derrick Ingram, who has founded a collective known as the Warriors in the Garden but was also a prominent activist within the Black Lives Matter community. And he had been subject to harassment [by the police], who showed up at his doorstep and effectively harassed him for four hours for something that he didn&#39;t realize he&#39;d done and, really, there was no clear answer to why they were there.</p><p> And as it turns out, given the presence of certain journalists around his home as he was being harassed, they figured out that the police had printed out a facial recognition identification report, which was present at the scene — which then, [it] turns out, had identified him as one of the only protestors identifiable at the particular protest, which was a Black Lives Matter protest protesting the murder of George Floyd. And in this context, we found out that, really, the police had simply identified this one prominent protestor with a megaphone and, as a result of being able to identify him, saw it as within their remit, even without a warrant, to show up at his door and try to question him and try to harass him.</p><p> The police eventually went on to come up with sort of a bogus charge in which they accused him of holding a megaphone too closely to an officer&#39;s ear, but this was all happening all the while Amnesty was investigating what other community members the NYPD had been targeting with this software and who was developing [and] providing the software that they were using. And the NYPD was not particularly forthcoming.</p><p> So our work has usually revolved around both conventional approaches, such as Freedom of Information Act requests or <a href=" https://opengovernment.ny.gov/freedom-information-law">Freedom of Information Law</a> requests, but it has also involved using, for example, Google Street View imagery to tag cameras that are run by the NYPD to give us a sense of how widely exposed New Yorkers, for example, are to network camera systems and, in particular, network camera systems with facial recognition. And that gives you a sense of how widely spread the risk is.</p><p> <strong>Sam Ransbotham:</strong> So something that bothers me when people talk about artificial intelligence is this tendency, I think, to use anthropomorphic language. It&#39;s tempting to use phrases like “AI does X” or “AI does Y,” and it&#39;s striking already [that] in talking to you both, neither of you has used <em>AI</em> as an actor. It&#39;s a tool, and you seem to be very focused on who&#39;s the actor. So the difficult thing there is that if a tool can amplify good and amplify bad, how do we promote a message to the actual actors? How do you get actors to use a tool that <em>can</em> be used for good and <em>can</em> be used for bad, to use it for good or bad? And even good or bad is tough to draw a line between.</p><p> <strong>Damini Satija:</strong> Yeah, and if I could use that to also piggyback to an earlier question where you asked about bad actors, I think that&#39;s very revealing in itself because we are very focused on the actor, and it&#39;s not just the AI. It&#39;s also who has designed the AI, the way the AI&#39;s been designed, who&#39;s deploying it, what context it&#39;s being deployed in. And we have to be really careful not to focus on what is wrong with the AI because then that can also lead us down the trap of “There is a technical fix to this problem.”</p><p> But often, the artificial intelligence tools we&#39;re looking at are also operationalizing a certain environment that we&#39;re concerned with, right? So, for instance, if we&#39;re looking at a tool being used in an immigration context, and the prevailing narrative is xenophobic or anti-immigrant, it will operationalize policies that fit into that category. So it very much is not just only about the technology, as you&#39;re saying, but also about the environment in which these are being developed, procured, and deployed.</p><p> And so that means that we&#39;re not always looking at bad <em>actors</em> as such, but bad use, to put it very simply. But I think that is just as much a guiding factor for us in looking for the cases we need to investigate, as is also, as Matt said, looking for discriminatory impact. I think another example that springs to mind here where a tool wasn&#39;t deployed specifically for negative consequence but it ended up having a negative consequence is a <a href=" https://www.codastory.com/authoritarian-tech/san-francisco-homeless-algorithm">case of a housing algorithm</a> that was used in San Francisco. And there was a story out on this a year or so ago.</p><p> There was a tool that was developed for social workers to use in allocating public housing. And the intent behind developing that tool was to provide something that allows social workers to have a more informed conversation with the individuals they&#39;re working with who need housing assistance. And the tool specifically would help them build a sort of vulnerability or risk assessment of the person to then determine how much housing assistance they needed. That tool was meant to help facilitate conversations. The way it was used, [however,] social workers were making yes and no decisions based on what the tool was spitting out on who should get housing assistance and who shouldn&#39;t.</p><p> So that … I mean you could argue that&#39;s bad use, but it&#39;s also kind of unintended use of the tool. So there are all kinds of realities that we&#39;re looking at that aren&#39;t as easy — it&#39;s just never easy to say that the issue is in the AI itself, which doesn&#39;t answer your original question but was some context that I wanted to add on the kind of bad actors question.</p><p> <strong>Shervin Khodabandeh:</strong> It also highlights what you&#39;re saying — the criticality of AI and human [interaction], and not just one versus the other, or one <em>or</em> the other. Because in all of these examples, there are examples of unintended or unanticipated use, or maybe because of lack of training, or where the underlying narrative isn&#39;t that you start with intending to do harm; you just did not know or you did not anticipate that “Oh, I&#39;m supposed to just use it as an input versus as an indication.”</p><p> The one question I have … you alluded to it, but you went in a different direction than I thought you were going to go, because you said, “We&#39;re not talking about what&#39;s wrong with the technology, because the implication would be there&#39;s a technological fix.” But I&#39;d like to challenge that because why wouldn&#39;t part of the fix, at least, be technological?</p><p> <strong>Damini Satija:</strong> Yes, there are technical fixes when it comes to bias, and there are people out there who&#39;ve put out ways of de-biasing tools. I think the reason we don&#39;t want to be completely confined to that is because of what I outlined — that we need to take a more holistic approach to understanding these technologies&#39; impacts because, as we say, it&#39;s not only about the way the tool is designed, although, yes, that is really important as well. It&#39;s also about the human interaction with the tools and how humans use them.</p><p> And I think the other problem is that the technical-fix route can make us take a very siloed approach to what the problem is. So, for instance, in the AI ethics algorithmic fairness world, there&#39;ve been a lot of de-biasing solutions put forward, and that implies that bias, in a very technical way within the algorithmic or AI system, is the only problem. But I think it&#39;s very possible that we could solve that from a technical perspective, but there are still myriad other problems with the tools that we&#39;re looking at. A, they can still be used in discriminatory ways, even if there&#39;s been a technical fix. There are surveillance concerns; these are data-intensive technologies.</p><p> We also worry often about sort of second- and third-order impacts of what these technologies incur. So, for instance, to take the housing example again, if a tool is used to deny someone housing or to deny someone access to Social Security benefits and then they&#39;re unable to pay rent or buy food for their family, those are effects that have happened two or three degrees of separation away from the tool, and it&#39;s still happening even if you reverse or take the algorithm out of the picture. That impact still exists and has still happened.</p><p> I think the emphasis, from our perspective, is maintaining that holistic understanding of the social consequences — political, economic — as well as technical. I don&#39;t know if Matt maybe wants to add anything on that.</p><p> <strong>Matt Mahmoudi:</strong> I&#39;d love to build on that a little bit further, in particular, because of the housing example and other examples like it. Also, risk indicator algorithms that are used by children&#39;s protective services in order to make determinations about whether to remove a child from foster care or even put them in foster care. Especially <a href=" https://www.technologyreview.com/2018/01/26/104816/algorithms-are-making-american-inequality-worse/">work by Virginia Eubanks</a> will outline how the social workers that are faced with this algorithm make determinations according to a light-based indicator that gives them sort of a red signal if it looks like there&#39;s been too many unsolicited reports of the child&#39;s welfare being in danger. And really, what that tells you is that the system in and of itself, the technology in and of itself, is not as easily fixed as, you know, to say, “Oh, well, then get rid of the indicators and turn them into more of a descriptive form of text.” Because what you&#39;re dealing with is a technology that extends far beyond the actual code itself, which is what Damini is getting to here as well. It&#39;s an entire sociotechnical system.</p><p> You can&#39;t hold that AI is a thing without also holding that there is human-computer interaction that gives animation to how that system functions and what it does. So, what is written in the code — I&#39;ve sort of taken the position — is somewhat irrelevant. What it does and what it ends up doing in the world, without using too much academic lingo here, but phenomenologically, is what really matters and what tells us about what the system actually is.</p><p> So by decentering ourselves from the notion that de-biasing is a virtue when it comes to AI technologies, and by decentering ourselves from the idea there&#39;s a technical fix from the system and instead holding that actually, these systems all ought to be tested and understood from what possible impacts they could have on society at large and on people&#39;s human rights before they&#39;re even entertained as being rolled out — that might lead us to the application and deployment of “better technologies.” As for how we can use technologies to identify certain <em>harmful</em> technologies: An example that I brought up before was how we were using street mapping tools to get a sense of where cameras were. Just to be clear, we didn&#39;t use an image recognition algorithm there. It was all people.</p><p> This allowed us to scale our volunteering efforts to some 7,500 people across the globe who helped us tag every intersection in New York City with cameras. That&#39;s a pretty, I think, compelling model for how you can scale activism and work that is moving the lever toward what might look like some form of justice and equity when it comes to technology, and certainly what an intervention that could promote greater respect for the right to protest might look like.</p><p> <strong>Shervin Khodabandeh:</strong> This is, I think … My point was about technology. It wasn&#39;t to say, “Let technology fix the problem it&#39;s created,” because the problem is created by the usage of it, as you said. And, of course, when you&#39;re talking about a powerful technology being used by institutions that have power to make policy, power to make law, power to make arrests or make war … of course the actor and the motivation of the actor and the use takes far more precedence [than] a technological fix. But I also have to believe that AI isn&#39;t going anywhere and the technology will only get improved.</p><p> And so I wonder … all of the deficiencies that your teams are finding, in terms of … I mean, in your example, you did not rely on image recognition to identify cameras, because you thought humans would be more accurate. Well, that is feedback to the algorithms and to the instrumentation that does image recognition. And in the example, Damini, that you talked about with housing, I wonder if there could be safeguards or additional prompts or additional data feeds that would actually make it almost impossible for that technology that was making the choice on what to do for a human to rely on the technological choice. So I must believe that as users and as agencies that are monitoring the use, that there is some feedback to the developer community that is building these tools. Not to say bias is the central problem, but that … I mean, you&#39;ve highlighted so many different areas where technological artifacts could help advance the very cause that you&#39;re talking about.</p><p> <strong>Damini Satija:</strong> Yeah. I mean, in terms of safeguards, there are many we could go into in terms of what we call for as a human rights community in regulation. I think Matt has already alluded to the No. 1 safeguard, which is clear questioning at the outset in the very conceptualization of these technologies as to whether they are required and whether automation is actually necessary in a certain context, and in doing that interrogating and scrutinizing, what that rights-violating or disproportionate impact could be of this technology. And I think in doing that, and what comes up for us again and again in our work is, which voices are being heard? Whose articulation of problems that need to be solved using technology are heard in that conceptualization phase?</p><p> And what we&#39;re often up against in our work is that there are certain sets of pretty powerful voices, which you&#39;ve just mentioned yourself as well. You know, policy makers, big technology companies, those who have funding to develop new technology, those who are funding new technology. Those who have the power to really dictate the trajectory of AI are the ones whose voices are also heard in what AI is being developed and then deployed, whereas those who are then impacted by the use of these systems, and especially the communities that we look at, often say … We&#39;ve mentioned racialized impacts. Often, Black and Brown communities are really negatively impacted and harmed by these systems. Those are not the voices that are then feeding into what the problems are that need to be solved through this technology, which, as you say, is here and the development of AI is happening very quickly. But it&#39;s that power imbalance that really concerns us in terms of whose voice is being heard [and] what should be conceptualized. And that is an intangible safeguard but a very, very important one for us in our work.</p><p> <strong>Shervin Khodabandeh:</strong> Very well said.</p><p> <strong>Sam Ransbotham:</strong> It&#39;s interesting you mentioned the social work example. My mother was a social worker and in [the] foster care [field]. And that is a highly understaffed, overworked world. And so when you gave that example, I have to say, part of me still finds it appealing that we could help those people improve. It may not be perfectly correct, it may not perfectly do prediction, but given so much of what else goes on, it may be a better solution. So how do we get a better solution in place without opening up this Pandora&#39;s box of difficulties to a point that we can improve it and can get experience over time? How does that happen?</p><p> <strong>Matt Mahmoudi:</strong> So if I could jump in here, Sam, I think staying with the social worker example and just staying with a particular program that Virginia Eubanks looks at, it&#39;s an interesting one because the state ends up spending more money on trying to hold up a failed technology than it would have spent just trying to equip the social workers with more resources, to be able to hire more social workers to be able to carry out their work more adequately and in line with the demand.</p><p> So I think, just drawing from the page of a piece of reading that I like to always assign to a class I&#39;m teaching on science and technology studies, which is sort of a drawing from Chellis Glendinning&#39;s “ <a href=" https://theanarchistlibrary.org/library/chellis-glendinning-notes-toward-a-neo-luddite-manifesto">Notes Toward a Neo-Luddite Manifesto</a> ,” I will say I&#39;m not anti-technology, and neo-Luddites aren&#39;t either, and I think that&#39;s kind of the crucial point here: that, A, neo-Luddites aren&#39;t anti-technology; they&#39;re worried about the ways in which technology creates numbers out of people and leads toward a hyperrationality that takes out these important questions of harm.</p><p> And then, secondly — and this is a really important one — all technologies are political. We have to understand, what are the forms of politics and policies that are undergirding the particular deployment of a technology instead of, say, investing in the particular social programs that are required? So the kinds of examples that Damini has been bringing up all along and that we&#39;ve been talking through really show that there is an insistence on investing in the tool of technology under the auspices that it&#39;s going to lead to some cost saving in the future, when the reality is that oftentimes states end up having to spend much more money either trying to hold the companies to account on what they promised but couldn&#39;t deliver or facing lawsuits by individuals, whether they&#39;re class action suits or whatever, given the harms that they would&#39;ve incurred on people who have been subject to these mass forms of idealized technologies. Which I think goes to the point of, try and uncover what the politics that underlie it is and see if there is a social-political-economic fix that might actually be more sustainable than trying to get out of our way and go into this fantasy land of “AI will solve everything” — sort of technochauvinistic ideology that <a href=" https://www.publicbooks.org/letting-go-of-technochauvinism/">Meredith Broussard talks about</a> — and get away from that a little bit, and thinking about what kinds of investment our society needs outside of these technologies.</p><p> I think, importantly, with tools such as your GPT-based chatbot models and what have you, you&#39;re dealing with systems that appear to be in perpetual beta, and so they can constantly make the claim that they&#39;re not working the way they should just quite [yet] and they may have unintended consequences because they haven&#39;t crunched enough data or quite gotten the model right. And you can sit on that narrative for a very, very, very long time.</p><p> But the question is, when do we, as a civil society, and when do we, as people who form a constituency on lawmakers that can speak on our behalf and regulate on our behalf, pump the brakes and say, “No, these are products that are out in the open. They&#39;re having an impact, and, therefore, they should be subject to regulation.” It doesn&#39;t matter how large the language model is. It doesn&#39;t matter how much larger it needs to be to reach a saturation point at which it&#39;ll operate according to some prescribed fantasy of efficiency.</p><p> We have to get to a point — and that point, I think, was yesterday — in which we say, “We need regulation.” I think [the European Union&#39;s] AI Act, which Damini is working on extensively as well, is a really good first attempt at trying to create a regional-level legislation that has an understanding of the kinds of consequences we&#39;re dealing with and the kinds of impacts that these technologies can have on our rights and our ability to engage in the kinds of liberties that we have today.</p><p> <strong>Shervin Khodabandeh:</strong> Damini, Matt, thank you so much for a very enlightening discussion.</p><p> <strong>Damini Satija:</strong> Thank you.</p><p> <strong>Shervin Khodabandeh:</strong> Thanks for listening. Please join us next time, when we bring Matt and Damini back to continue the discussion about AI regulation, including what others can do to help limit harms stemming from the use of technology tools.</p><p> <strong>Allison Ryder:</strong> Thanks for listening to <cite>Me, Myself, and AI</cite> . We believe, like you, that the conversation about AI implementation doesn&#39;t start and stop with this podcast. That&#39;s why we&#39;ve created a group on LinkedIn specifically for listeners like you. It&#39;s called AI for Leaders, and if you join us, you can chat with show creators and hosts, ask your own questions, share your insights, and gain access to valuable resources about AI implementation from <cite>MIT SMR</cite> and BCG. You can access it by visiting <a href="https://mitsmr.com/AIforLeaders">mitsmr.com/AIforLeaders</a> . We&#39;ll put that link in the show notes, and we hope to see you there.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/audio/protecting-society-from-ai-harms-amnesty-internationals-matt-mahmoudi-and-damini-satija-part-1/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> Why the Power of Technology Rarely Goes to the People</title><link/> https://sloanreview.mit.edu/article/why-the-power-of-technology-rarely-goes-to-the-people/<comments> https://sloanreview.mit.edu/article/why-the-power-of-technology-rarely-goes-to-the-people/#respond</comments><pubDate> Mon, 28 Aug 2023 11:00:16 +0000</pubDate> <dc:creator><![CDATA[Daron Acemoglu and Simon Johnson, interviewed by Kaushik Viswanath. <p>Daron Acemoglu is an economist and an MIT Institute Professor, the university&#39;s highest faculty honor. Simon Johnson is the Kurtz Professor of Entrepreneurship at MIT and a former chief economist to the International Monetary Fund. They are the authors of <cite>Power and Progress: Our 1,000-Year Struggle Over Technology and Prosperity</cite> (PublicAffairs, 2023). Kaushik Viswanath is features editor at <cite>MIT Sloan Management Review</cite> .</p> ]]>;</dc:creator><category><![CDATA[Equity]]></category><category><![CDATA[Labor]]></category><category><![CDATA[Technology]]></category><category><![CDATA[Technology Implementation]]></category><category><![CDATA[Managing Technology]]></category><category><![CDATA[Technology Innovation Strategy]]></category><description><![CDATA[Taylor Callery/theispot.com In a new book, economists Daron Acemoglu and Simon Johnson provide a sweeping historical overview of just how unevenly the spoils and costs of technological change have been distributed. Power and Progress: Our 1,000-Year Struggle Over Technology and Prosperity reminds us that technology is not itself a force but rather a tool that [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/2023FALL-Acemoglu_1290x860.jpg" alt="" /><figcaption><p class="attribution"> Taylor Callery/theispot.com</p></figcaption></figure><p> In a new book, economists Daron Acemoglu and Simon Johnson provide a sweeping historical overview of just how unevenly the spoils and costs of technological change have been distributed. <cite>Power and Progress: Our 1,000-Year Struggle Over Technology and Prosperity</cite> reminds us that technology is not itself a force but rather a tool that is developed to support the agendas of the people and institutions who hold power in society. Claiming a fair share of technology&#39;s benefits for the rest of society — that is, for most of humanity — requires that that power be challenged. Acemoglu and Johnson chatted with features editor Kaushik Viswanath about what lessons the past holds for how we should develop and implement technology today and in the future. This conversation has been edited for length and clarity.</p><p></p><h6> Kaushik Viswanath: What&#39;s the central argument you&#39;re making in <cite>Power and Progress</cite> , and what motivated you to write it?</h6><p> <strong>Daron Acemoglu:</strong> This is a critical time to be thinking about the future of technology. A lot of decisions of great import are being hampered by the fact that there is “techno-optimism” in academia, the tech world, and the policy world. Techno-optimism is the notion that impressive technological change will automatically lead to better outcomes for society, especially for workers via the labor market, even if there are some transition costs.</p><p> Our understanding of the relevant economic theory and history has led us to believe this isn&#39;t right. Throughout history, deliberate decisions have had a bearing on who gained and lost from a particular technology, whether it brought anything approaching shared prosperity, or even whether it helped or destroyed democracy. So our purpose in writing <cite>Power and Progress</cite> was to dispel the notion that in the history of technology, everything has always worked out OK. There are similar choices and struggles over technology today as we&#39;ve had in the past.</p><p></p><h6> One of the key concepts you discuss is the productivity bandwagon. What is this, and how does it create winners and losers whenever we have technological change?</h6><p> <strong>Simon Johnson:</strong> The productivity bandwagon is the notion that when technology improves, you get higher wages, more opportunity, and better health, and everybody gains from it eventually. Our key problem with that notion is the “eventually.” “Eventually,” from the beginning of the Industrial Revolution, was 120 years. The 1720s to the 1840s saw a lot of new technology, but we know that in the 1840s, children as young as 6 were still pushing coal carts deep underground with their heads. Conditions improved for more people in the second half of the 19th century but as a result of a lot of effort, not through any kind of automatic economic or political process.</p><p> <strong>Acemoglu:</strong> The perspective that Simon and I bring to the British Industrial Revolution is that it was really a revolution of vision. A new class of ambitious people emerged who wanted to apply technology to improve how people control their environment and the production process. They weren&#39;t doing it out of altruism; they were preoccupied with making money, wanted to rise within the British hierarchy, and didn&#39;t have much sympathy for the people who were below them in that hierarchy, whether in Britain or the rest of the world.</p><p> This is an illustration of what ambition does unless it is countered by institutions and other groups that have alternative visions of how society should be organized. It also illustrates the weaknesses of the productivity bandwagon. People were left behind in the early phases of the Industrial Revolution for two reasons. First, most of the technology was used for automation, not increasing workers&#39; productivity contributions. When technology displaces workers, it doesn&#39;t increase their contribution to production or create a powerful reason for employers to go out and pay higher wages to workers. Second, this was all embedded in an institutional setup, both because of the vision of the entrepreneurs and because trade unions were banned and heavily prosecuted, and Britain was very far from a democracy at the time.</p><p> The working class did not have any rights or protections. That&#39;s why, even as many people made fabulous amounts of money, workers&#39; real incomes stagnated or even declined. Sharing the gains of technology required a complete change in the institutional fabric of British society, which the elites and upper middle classes resisted. It required a change in the direction of technology, too — for example, it was necessary to invest in urban infrastructure to improve sanitation and bring infectious diseases under control. Until then, urban life was horrible for working people.</p><p></p><h6> Fast-forwarding to post-World War II in the US, you describe how this period saw a more equitable distribution of the productivity gains from technology. How did this happen?</h6><p> <strong>Acemoglu:</strong> That episode illustrates how the factors that worked against shared prosperity during the Industrial Revolution were turned in favor of shared prosperity in the 20th century, especially in the decades that followed World War II.</p><p> Its origins can be traced to the American system of manufacturing, because this was a key part of a general effort to make unskilled labor more productive using machinery. That, in turn, was critical for less-skilled workers to earn a high and rising wage. In this period, workers&#39; contributions to the production process could be bolstered by training. This was facilitated by a combination of technologies that didn&#39;t simply automate work but created new and more technical tasks, more maintenance tasks, and more advanced machining tasks for workers. And it was in the context of institutions that provided countervailing powers to the most powerful firms — in particular, a secure democracy by historical standards, a labor movement that had become much stronger after the New Deal and during World War II, and a supportive regulatory environment by the US government that encouraged technological change but also brought limits to what the largest companies could do, for example, through antitrust enforcement.</p><h6> You also write that the US labor movement during this period actually encouraged the mechanization of the industries in which they worked. Why did they do this?</h6><p> <strong>Johnson:</strong> The key was in their insistence that their workers get trained to use the machines. They realized that mechanization was coming whether they liked it or not. They couldn&#39;t simply ask for higher wages, because that would lead to more automation. So [labor unions] asked for their workers to acquire the necessary skills and be compensated appropriately. Unions are much weaker today, so that kind of countervailing power is missing, which means the benefits of automation will go to whoever has social power — which means relatively few people.</p><p> <strong>Acemoglu:</strong> We are not against automation. Blocking automation would not just be infeasible, but to the extent that it&#39;s tried, would be hugely costly. In its best moments, the labor movement, both in the United States and in Europe, encouraged the introduction of advanced automated machinery but at the same time negotiated the creation of better, more advanced tasks for workers to operate and inspect these machines. Where workers didn&#39;t have those skills, employers would have to train them. So it was the combination of new tasks and training that unions advocated for. Today the question is, can we still encourage the right type of automation?</p><p></p><h6> What is the role of business leaders in determining the direction of technological advancement and distributing its gains?</h6><p> <strong>Acemoglu:</strong> The future of technology is inseparable from the vision of powerful actors. It&#39;s not something we can all democratically vote on. The same is true of how CEOs decide to split profits between different stakeholders. Do they see labor as one of those stakeholders? That is a question that is entangled with the future of technology.</p><p> Over time, business leaders have shifted toward just serving the interests of the shareholders. Labor is viewed as troublesome and costly, so they try to eliminate it as much as possible. And that has synergized with the vision of the tech community to develop machines that can automate as much as possible.</p><p> But nothing in the laws of capitalism makes that necessary. During other periods, in other contexts, businesses have prioritized increasing worker productivity. They have found ways of rewarding their shareholders while giving raises to their workers when the company is doing well, and investing in technologies that increase worker productivity. A new vision among business leaders would be feasible and highly useful for the kinds of futures of work that we&#39;re talking about. But that won&#39;t emerge by itself. It will require pressure from institutions, civil society, and the media, as well as some amount of organized labor.</p><h6> You describe how the doctrine of maximizing shareholder value became consensus in management schools and then management consultancies, ending an era of widely shared gains from technology. Do you see that changing?</h6><p> <strong>Acemoglu:</strong> I have a <a href="https://www.nber.org/papers/w29874">paper with Alex He and Daniel le Maire</a> where we find that CEOs with business degrees from the top MBA programs in the United States don&#39;t increase productivity, exports, or investment, but they reduce wage growth and labor share. But the CEOs in our sample are all from the 1970s, &#39;80s, and &#39;90s. Today, the same schools have a somewhat different air. Students seem to care much more about broader aspects of business. Faculty don&#39;t just talk about increasing shareholder value and creating lean corporations by eliminating labor. So I already sense some change in that direction. How effective it is, we don&#39;t know yet.</p><p> <strong>Johnson:</strong> There&#39;s a lot more progress to be made. The curriculum and the core ideas that are imprinted on students still lean a lot more toward <a href="https://sloanreview.mit.edu/strategy-forum/has-strategic-management-overlooked-the-role-of-purpose-what-experts-say/">Milton Friedman</a> than toward Acemoglu-Johnson or any other view.</p><p> If you consider the pressure from financial markets and look at the language used by analysts, it reinforces that narrow view, which is, I think, not ultimately good for business.</p><h6> Turning to the tech that&#39;s on everyone&#39;s minds these days: Where do you think AI — and generative AI, specifically — is headed?</h6><p> <strong>Acemoglu:</strong> These are phenomenally interesting and impressive technologies. That only raises the stakes of getting the direction of this technology right and setting up the right regulatory structure.</p><p> But the two polar views that are most loudly heard in the media are both unhelpful: On one end are techno-optimists, who say, “Everybody will benefit. Yes, a few people might lose their jobs. But you&#39;ll get more massage therapists, even if you don&#39;t have enough white-collar workers.” On the other end is the view that killer robots are coming and we have to worry about existential risk.</p><p> Neither of these views addresses the right concerns. AI can do a lot to help workers and society. It could go along the lines of the platforms that Taiwan introduced, for example, to facilitate more democratic participation; those have worked reasonably well. Or it can go in the direction of automation that deepens inequalities, delivers more misinformation, disinformation, manipulation of users — what we&#39;ve seen with social media, especially platforms like Facebook.</p><p> We really worry about that direction, and that&#39;s where our leaders are asleep at the wheel. Society is not worrying enough about these things. There isn&#39;t even the right set of aspirations that have been articulated about what we should want from this technology.</p><p> <strong>Johnson:</strong> I&#39;ve heard the view that people are complaining now because it&#39;s cognitive tasks that are being replaced by a machine, whereas before it was manual work. What we say in our book is that what&#39;s actually vulnerable here are all routine cognitive tasks. Wendy&#39;s, for example, has said it&#39;s going to use chatbots to take orders at drive-throughs. They&#39;ll still use humans to flip the burgers. Is your ordering of a burger going to be any better with this machine? Are they going to be paying the burger flipper any more money? No, they&#39;re just doing this so they can have fewer workers.</p><p></p><p> We call it <em>so-so automation</em> . It&#39;s a way to tilt power against the workers. You&#39;re replacing people who are quirky and sometimes difficult to manage with machines that are designed for mediocrity. Where&#39;s the productivity breakthrough? Where&#39;s the big positive benefit?</p><p> <strong>Acemoglu:</strong> In productivity revolutions of the past, like at the Ford Motor Company, automation was critical, but only when combined with new products, new tasks, new ways of using machinery, new creativity. The Ford factory would not have done anything of note if it took exactly the cars that other companies were producing and made them with a bit more automation.</p><p> This is why we prefer to emphasize machine usefulness rather than machine intelligence. We should be using machines to make humans better. Generative AI is so promising because it has that capability. It could help with the retrieval and filtering of information so that human decision makers make better decisions. But that&#39;s very different from automating a few more McDonald&#39;s kiosks.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/why-the-power-of-technology-rarely-goes-to-the-people/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> How to Deliver Career Development for All</title><link/> https://sloanreview.mit.edu/article/how-to-deliver-career-development-for-all/<comments> https://sloanreview.mit.edu/article/how-to-deliver-career-development-for-all/#respond</comments><pubDate> Thu, 24 Aug 2023 11:00:15 +0000</pubDate> <dc:creator><![CDATA[George Westerman and Tony Gigliotti. <p>George Westerman is a senior lecturer at the MIT Sloan School of Management and founder of MIT&#39;s Global Opportunity Forum (formerly known as the Global Opportunity Initiative). Tony Gigliotti is the senior director of talent management and organizational development at UPMC, a health care provider and insurer based in Pittsburgh.</p> ]]>; </dc:creator><category><![CDATA[Career Change]]></category><category><![CDATA[Talent Acquisition and Management]]></category><category><![CDATA[Talent Development]]></category><category><![CDATA[Leadership]]></category><category><![CDATA[Organizational Behavior]]></category><category><![CDATA[Talent Management]]></category><category><![CDATA[Workplace, Teams, & Culture]]></category><description><![CDATA[To be competitive in today’s tough labor markets, companies need to expand career development beyond those employees who are considered “high potential.” Helping all workers build rewarding job paths benefits both individuals and organizations. But broadening the reach of career development is not simple. Traditional development programs don’t easily scale, and most managers aren’t equipped [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/W23-QA05_1290x860.jpg" alt="" /><br /></figure><p> To be competitive in today&#39;s tough labor markets, companies need to expand career development beyond those employees who are considered “high potential.” Helping all workers build rewarding job paths benefits both individuals and organizations. But broadening the reach of career development is not simple. Traditional development programs don&#39;t easily scale, and most managers aren&#39;t equipped to be good career counselors.</p><p> Forward-leaning companies understand the imperative. During <a href="https://sloanreview.mit.edu/series/work-23-the-big-shift/">Work/23</a> , an <cite>MIT Sloan Management Review</cite> symposium held in May 2023, MIT Sloan&#39;s George Westerman noted that in a <a href="https://sloanreview.mit.edu/article/why-companies-should-help-every-employee-chart-a-career-path/">survey of 1,016 employees</a> , two-thirds said they want to advance — but “half of them said they were being held back by lack of good career advice.” A majority of those who changed jobs in 2021 cited a lack of advancement opportunities as the cause.</p><p></p><p></p><p> Westerman said managers can&#39;t be fully responsible for developing employees&#39; careers; many leaders don&#39;t want or know how to help, and many don&#39;t have the incentive to. But organizations shouldn&#39;t think that employees can completely own their career paths. “If you believe this story, then when an employee doesn&#39;t advance, you tend to blame the employee and not the system,” he said.</p><p> Instead, companies that are successfully broadening who gets career help are making opportunities and pathways visible, providing opportunities to learn and practice new skills, and delivering rich feedback and coaching. Providing autonomous routes to this information is especially important because not all employees have the psychological safety to discuss job options with their managers.</p><p> Lani Montoya, the chief human resources officer at Pernod Ricard North America and a presenter on the panel with Westerman, said that at the premium spirits and wine company, a global job-rating process allows all 18,500 employees to see positions at their level as well as above and below it. “They can see how teams are structured, and if they&#39;re interested in a role, they can see how it sits within what team,” she said.</p><p></p><p> Tony Gigliotti, the senior director of talent management and organizational development at UPMC, who was also on the panel, said that his organization is working toward similar transparency around career paths and job opportunities. The Pittsburgh-based health care provider and insurer has 95,000 employees in its hospitals and outpatient offices. A career resource site on UPMC&#39;s intranet offers access to assessments and skill-building opportunities, and a feature within its human capital management system shows job postings, job descriptions, and career paths within and outside an employee&#39;s job family.</p><p> “Now they have at their fingertips a lot of information,” Gigliotti said. “That will empower more employees.”</p><p> Below, Westerman and Gigliotti answer some of the questions from Work/23 attendees that they weren&#39;t able to get to during the event. (Questions and answers have been lightly edited for clarity.)</p><h6> How do you see career development working for employees who really enjoy their jobs, are individual contributors, and don&#39;t want to become managers?</h6><p> <strong>George Westerman:</strong> Many workers don&#39;t want to advance in their careers but can still benefit from development opportunities. Take teachers, for example. Very few want to become principals, but all can benefit from professional development opportunities. Most doctors may not want to move into management, but it&#39;s good for them (and their patients) that they engage in continuing medical education every year.</p><p> <strong>Tony Gigliotti:</strong> It is important to define career development beyond vertical promotion into leadership positions. Otherwise, a portion of your productive and reliable employee population might feel that they do not have opportunities for professional growth, and this may lead to their disengagement.</p><p> Our resources for leaders at UPMC take a more holistic approach to career development by referencing the many interventions that support professional growth and development. These include training and learning paths, mentoring, coaching, job enhancement/enrichment, stretch assignments, cross-functional work teams and committees, conferences, and community involvement.</p><p></p><p> Additionally, our talent-review programs normalize situations where solid performers are content in their current role. Part of that consideration must include the employees&#39; own intentions. In these cases, we explore ways to develop the employee in place.</p><p> Finally, we remind leaders that career aspirations can and often do change over time, so they must seek feedback and listen to their employees as their career needs and preferences evolve.</p><h6> What criteria work best when considering people for internal transfers for their career development? It seems like transfers could be a problem when the needs of the company and the needs of the individual conflict.</h6><p> <strong>Westerman:</strong> If you decide that the needs of the company outweigh an employee&#39;s desire to move to a new role, you&#39;re inviting them to leave the company. They&#39;ll move to another employer instead, leaving you without an employee and with less chance to conduct a smooth transition.</p><p></p><p> To encourage hiring from within, you may not need special criteria or incentives. Just make the opportunities known to internal candidates, and make the candidates known to the hiring manager. However, you can also try other changes to improve incentives, such as opening a position to internal candidates before listing it externally, or asking the manager to share in the costs of external hiring.</p><h6> How can companies manage talent hoarding and deal with managers who are resistant to sharing career paths openly?</h6><p> <strong>Gigliotti:</strong> There are several ways that our organization addresses leaders who hoard talent and do not focus on their employees&#39; career growth within the organization. Our organization transparently shares all career paths, including job descriptions, with all employees. So despite some leaders&#39; penchant for talent hoarding, employees still have access to the resources needed to understand their own (and others&#39;) career paths. This approach is consumer-driven — that is, our employees have expressed a need for this information so that they can navigate their own careers within the organization.</p><p></p><p> In addition, our organizational talent reviews are designed to identify emerging talent and ready-now talent. The outcomes from talent-review discussions across the organization are compiled and then transparently shared with HR leaders. This information empowers HR to identify potential internal talent who may be interested in and ready for available positions within the organization.</p><p> And growth is a key dimension in our employee engagement model. If a leader is not developing their employees, sharing career resources with them, or encouraging their career growth within the organization, then that leader&#39;s employee engagement scores (particularly in the growth dimension) will suffer. Low scores raise a red flag to that leader&#39;s supervisor and the local HR team, who then may intervene. Part of that intervention is to align the leader to our organizational values of responsibility and integrity, which, in part, expect leaders to “support their staff&#39;s … professional growth and development.”</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/how-to-deliver-career-development-for-all/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> Ask Sanyin: Why Can&#39;t We Get Meetings Right?</title><link/> https://sloanreview.mit.edu/article/ask-sanyin-why-cant-we-get-meetings-right/<comments> https://sloanreview.mit.edu/article/ask-sanyin-why-cant-we-get-meetings-right/#respond</comments><pubDate> Wed, 23 Aug 2023 11:00:36 +0000</pubDate> <dc:creator><![CDATA[Sanyin Siang. <p>Sanyin Siang is a CEO coach and leads the Fuqua/Coach K Center on Leadership &amp; Ethics (COLE) at Duke University. Need advice? Send an <a href="mailto:asksanyin@mit.edu">email to Sanyin</a> .</p> ]]>; </dc:creator><category><![CDATA[Employee Engagement]]></category><category><![CDATA[Leadership Advice]]></category><category><![CDATA[Leadership Development]]></category><category><![CDATA[Team Building]]></category><category><![CDATA[Trust]]></category><category><![CDATA[Leadership]]></category><category><![CDATA[Leadership Skills]]></category><category><![CDATA[Managing Your Career]]></category><description><![CDATA[As a senior leader in my company, I find meetings are crucial for keeping tabs on what’s going on and making decisions. But we seem to accomplish little, people are frequently unprepared, and they gripe about the time cost. How can I shift people’s attitudes and run more effective meetings? We’ve all been there: We [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/AskSanyin-featured-column4-1290x860-1.jpg" alt="" /><figcaption><p class="attribution"></figcaption></figure><p class="article-body-question"> As a senior leader in my company, I find meetings are crucial for keeping tabs on what&#39;s going on and making decisions. But we seem to accomplish little, people are frequently unprepared, and they gripe about the time cost. How can I shift people&#39;s attitudes and run more effective meetings?</p><p> We&#39;ve all been there: We sit through an hour of conversation, and somehow, there&#39;s less clarity at the end of the meeting than there was at the beginning. We walk out, lamenting the wasted time and lack of progress.</p><p> In an era of hyperproductivity, an endless list of to-do items, and personal exhaustion, your team probably sees meetings as an obstacle to getting back to their work rather than something purposeful. Shifting that attitude toward one of enthusiastic engagement means rethinking what you&#39;re trying to accomplish with meetings. With the widespread move to remote work, opportunities to engage with our teams in real time have become rarer and more valuable. How can we use this time to deepen relationships? What if we make trust-building a key aim of every type of meeting?</p><p></p><p> The decision-making meeting is usually about a commitment to a course of action. Here, you can also discuss the emotional consequences of the decisions for your people and the best ways to communicate a change. A deep discussion of these questions provides insight into others&#39; values and approaches.</p><p> Brainstorming and problem-solving meetings benefit enormously from explicit consideration of trust-building. Everyone needs to feel comfortable sharing their ideas while resisting the urge to judge. Here, you want to encourage vulnerability, because when we say “I don&#39;t know,” we acknowledge our limits and interdependencies within the greater team.</p><p> There&#39;s also an opportunity to transform the sometimes-routine information-sharing meeting into a richer venue for connection. Try setting the expectation that these are opportunities to learn more about one another&#39;s challenges and strategies, and encourage questions. These meetings also provide the opportunity to celebrate wins or invite help from another department. Use the time to help team members build connections with one another — a matrix — instead of hub-and-spoke connections with you at the center as the go-to problem solver.</p><p></p><p> Finally, try to include a time for collective reflection in a regular team meeting. Tarang Amin, CEO of elf Beauty, which posted 17 quarters of consecutive growth as of May 2023, begins every executive leadership team meeting with time for open sharing and reflection. “It&#39;s where execs can talk about what&#39;s going on in their personal lives, … their state of mind, what are important initiatives, what are things they&#39;re hearing in the organization,” he says.</p><p> Remember, it&#39;s typically not a lack of action items that hinders progress. It&#39;s more often misinterpretation of intent, misalignment of understanding, and the emotional toll of change that holds us back. And what solves those problems are trusting relationships that enable good communication. So instead of diving into the <em>what</em> of the next meeting you plan, begin with the <em>who</em> and the relationships among them. Your team just might rediscover the energy and joy that come with engaging with one another — and even begin to look forward to meetings.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/ask-sanyin-why-cant-we-get-meetings-right/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> Using Federated Machine Learning to Overcome the AI Scale Disadvantage</title><link/> https://sloanreview.mit.edu/article/using-federated-machine-learning-to-overcome-the-ai-scale-disadvantage/<comments> https://sloanreview.mit.edu/article/using-federated-machine-learning-to-overcome-the-ai-scale-disadvantage/#respond</comments><pubDate> Tue, 22 Aug 2023 11:00:10 +0000</pubDate> <dc:creator><![CDATA[Yannick Bammens and Paul Hünermund. <p>Yannick Bammens is professor of strategy and innovation at Hasselt University in Belgium, where he coleads the AI4Business initiative. Paul Hünermund is assistant professor of strategy and innovation at Copenhagen Business School in Denmark, where he co-organizes the yearly Causal Data Science Meeting.</p> ]]>; </dc:creator><category><![CDATA[Artificial Intelligence]]></category><category><![CDATA[Big Data]]></category><category><![CDATA[Collaboration]]></category><category><![CDATA[Data & Analytics]]></category><category><![CDATA[Machine Learning]]></category><category><![CDATA[AI & Machine Learning]]></category><category><![CDATA[Data & Data Culture]]></category><category><![CDATA[Data, AI, & Machine Learning]]></category><description><![CDATA[Jing Jing Tsong/theispot.com Deep pockets, access to talent, and massive investments in computing infrastructure only partly explain why most major breakthroughs in artificial intelligence have come from a select group of Big Tech companies that includes Amazon, Google, and Microsoft. What sets the tech giants apart from the many other businesses seeking to gain an [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/2023FALL-Bammens_1290x860.jpg" alt="" /><figcaption><p class="attribution"> Jing Jing Tsong/theispot.com</p></figcaption></figure><p> Deep pockets, access to talent, and massive investments in computing infrastructure only partly explain why most major breakthroughs in artificial intelligence have come from a select group of Big Tech companies that includes Amazon, Google, and Microsoft. What sets the tech giants apart from the many other businesses seeking to gain an edge from AI are the vast amounts of data they collect as platform operators. Amazon alone processes millions of transactions each month on its platform. All of that big data is a rich strategic resource that can be used to develop and train complex machine learning algorithms — but it&#39;s a resource that is out of reach for most enterprises.</p><p> Access to big data allows for more sophisticated and better-performing AI and machine learning models, but many companies must make do with much smaller data sets. For smaller companies and those operating in traditional sectors like health care, manufacturing, or construction, a lack of data is the biggest impediment to venturing into AI. The digital divide between big and small-data organizations is a serious concern due to self-reinforcing data network effects, where more data leads to better AI tools, which help attract more customers who generate more data, and so forth. <a id="reflink1" class="reflink" href="#ref1">1</a> This gives bigger companies a strong competitive AI advantage, with small and midsize organizations struggling to keep up.</p><p></p><p> The idea of multiple small-scale companies pooling their data in a jointly controlled central repository has been around for a while, but concerns about data privacy may quash such initiatives. <a id="reflink2" class="reflink" href="#ref2">2</a> Federated machine learning (FedML) is a recent innovative technology that overcomes this problem by means of privacy-preserving collaborative AI that uses decentralized data. FedML might turn out to be a game changer in addressing the digital divide between companies with and without big data and enabling a larger part of the economy to reap the benefits of AI. It&#39;s a technology that doesn&#39;t just sound promising in theory — it has already been successfully implemented in industry, as we&#39;ll detail below. But first, we&#39;ll explain how it works.</p><h3> Small Data and Federated Machine Learning</h3><p> FedML is an approach that allows small-data organizations to train and use sophisticated machine learning models. The definition of <em>small data</em> depends on the complexity of the problem being addressed by AI. In pharma, for example, having access to a million annotated molecules for drug discovery is relatively small in view of the vast chemical space. Other factors to consider include the sophistication of the machine learning technique, ranging from a simple logistic regression to a much more data-hungry neural network, as well as the accuracy needed for an application: For some AI applications (such as making a medical diagnosis), getting things right is simply more critical than for others (such as suggesting emojis when someone is typing). All else being equal, smaller organizations and those operating in traditional nondigital sectors are confronted with more serious data-related scale disadvantages.</p><p></p><p> A few useful tactics and techniques have already been conceived to help companies struggling with this problem, such as cross-firm data pooling, transfer learning (repurposing previously trained models), and self-supervised learning (training a model on an artificial data set). <a id="reflink3" class="reflink" href="#ref3">3</a> Yet the centralized approach of data pooling may not be suitable in several situations, such as when there are legal constraints prohibiting data transfers or strategic concerns regarding sensitive data that should be kept private. Likewise, transfer learning and self-supervised learning are viable approaches only when a company can build on earlier insights from machine learning models performing tasks in related domains, which may not always be feasible. FedML can be a powerful extra instrument in a small-data company&#39;s AI toolkit and serve as a critical complement to other small-data techniques.</p><p> In a federated learning setup, a machine learning model is trained on multiple decentralized servers controlled by different organizations, each with its own local data. They communicate with a central orchestrator that aggregates the individual model updates and coordinates the training process. (See “An Overview of Federated Machine Learning.”) In the simplest case, the learning objective would be to obtain basic descriptive facts of the data distribution, such as means or variances. Each company could, for example, compute the average failure rate of a certain manufacturing process at one of its plants and submit it to the orchestrator, which would then combine those individual contributions to form a more accurate joint estimate.</p><div class="callout-highlight"><aside class="l-content-wrap"><article><h4> An Overview of Federated Machine Learning</h4><p class="caption"> In a federated learning setup, a machine learning model is trained on multiple decentralized servers controlled by different organizations, each with its own local data. They communicate with a central orchestrator that aggregates the individual model updates and coordinates the training process. </p><p><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/MAG_Bammens_Fig1.png" alt="An Overview of Federated Machine Learning" /><br /></article></aside></div><p></p><p> FedML is a distributed machine learning technique that can be used for a variety of algorithms. For example, the weights or gradients of a neural network can be averaged across organizations in a similar manner. The orchestrator is responsible for setting up the initial model architecture and coordinating the training process, which typically takes place over multiple iterations. As a result, companies can train complex machine learning models with a large number of parameters that would otherwise be beyond their reach, given that the constraints of their local data would lead to suboptimal model accuracy.</p><p> Importantly, raw company data stays private, and only statistical data, like estimated weights and other parameters, are shared and aggregated when FedML is applied. This way, 10 collaborating small-data companies that each have access to <em>x</em> data points could achieve roughly similar predictive power with their AI/machine learning applications as one much bigger company with access to 10 times <em>x</em> data points, without compromising data privacy.</p><h3> FedML in Pharma</h3><p> Innovation in pharma is very expensive and time consuming. The <a href="https://www2.deloitte.com/us/en/pages/about-deloitte/articles/press-releases/deloittes-thirteenth-annual-pharmaceutical-innovation-report-pharma-r-and-d-return-on-investment-falls-in-post-pandemic-market.html">average cost</a> to bring a new drug to market is around $2.3 billion as of 2022, and the process can take more than 10 years. One of the key difficulties in drug discovery involves the extremely high number of possible molecules (an order of magnitude of 10 <sup>60</sup> ) and the associated challenge of finding molecules with promising qualities in that vast chemical space. Against the backdrop of such steep costs and the sheer number of molecular possibilities, high-performing predictive machine learning models are the keystone of pharma&#39;s AI-driven drug-discovery agenda. Pharma companies are also facing pressure as <a href="https://www.cbinsights.com/research/report/famga-big-tech-pharma/">Big Tech</a> players like Alphabet use their profound expertise in AI and machine learning to venture into drug discovery.</p><p> Cognizant of the reluctance to share drug discovery data, but also of the great potential of collaborative AI to boost efficiencies in drug discovery, Hugo Ceulemans, the scientific director at Janssen Pharmaceutica, began floating the FedML idea and initiating talks with peers around 2016. His efforts eventually contributed to the formation of the Melloddy consortium by 10 pharma companies in 2019. In a blog post, Ceulemans noted that while pharmaceutical companies had previously pooled data to support predictive efforts, the scope of collaboration had been limited, given that data is an expensive competitive asset. <a id="reflink4" class="reflink" href="#ref4">4</a> Because the new FedML consortium would allow the underlying data contributions to remain under the control of the respective data owners and not be shared, a much more ambitious scope would be possible, he explained.</p><p> Melloddy, a term named for <em>machine learning ledger orchestration for drug discovery</em> , was a three-year pilot project aimed at testing FedML for feasibility and effectiveness. The project was cofunded by the European Union; the European Commission considered Melloddy to be a test case for generating insights for business sectors beyond pharma. Participating companies included AstraZeneca, Bayer, GSK, Janssen Pharmaceutica, Merck, and Novartis, among others. These companies were supported by technology and academic partners, including Owkin (an AI biotech venture) and KU Leuven (a university with expertise in AI-driven drug discovery).</p><p> By leveraging one another&#39;s data without actually sharing it, the participating pharma companies could train their machine learning models on the world&#39;s largest drug-discovery data set, which enabled more accurate predictions on promising molecules and boosted efficiencies in the drug discovery process. In a blog post, Mathieu Galtier, chief product officer at Owkin, explained that thanks to Melloddy&#39;s use of federated learning, data never left the infrastructure of any pharma partner. The machine learning process occurred locally at each participating pharmaceutical company, and only the models were shared. “An important research effort is devoted to guaranteeing that only statistical information is shared between partners,” he wrote. <a id="reflink5" class="reflink" href="#ref5">5</a></p><p> The results of the Melloddy pilot project, which concluded in 2022, revealed that creating a secure multiparty platform for collaborative AI using decentralized data is feasible and that the performance of machine learning models is indeed enhanced by using a FedML approach.</p><h3> Strategic Considerations for FedML Consortia</h3><p> When setting up a FedML consortium, those involved in the planning process must carefully consider the optimal approach for orchestrating the technology and incentivizing partners. The selected orchestrator assumes a pivotal role in effectively managing the FedML process. Leaders of small-data organizations are sometimes reluctant to team up with Big Tech companies because they can maintain greater strategic control and build closer ties with smaller tech partners that operate on an equal footing. And some even fear that Big Tech companies will themselves move into their sector, as is happening in pharma.</p><p> In the case of Melloddy, pharma companies chose Owkin, a startup, to take on the responsibility of orchestrating the consortium&#39;s FedML platform. This may be a good approach for many FedML initiatives, but it can be risky, given the high failure rate of startups: A consortium might crumble if the startup fails. There is also a potential risk that the startup might raise funding from a competitor that is not participating in the consortium; it&#39;s an awkward situation, but not unlikely. Therefore, if a startup venture is chosen as the prime technology orchestrator, the consortium partners should seriously consider the option of investing corporate venture capital (CVC). <a id="reflink6" class="reflink" href="#ref6">6</a> When the partners have a sizable joint CVC stake in the startup, with rights of first refusal, they have much stronger control over the length of the tech startup&#39;s runway and its future trajectory.</p><p></p><p> FedML can give rise to an incentive problem, wherein some participants fail to use all relevant local data or neglect to invest in the necessary data infrastructure to improve the accuracy of their local models. They may choose not to put in the effort while relying on the data contributions made by other consortium partners. This free-riding behavior then undermines the motivation and participation of well-intentioned participants. To preempt this problem, the FedML consortium can agree on appropriate partner commitments in terms of the quantity and coverage of data contributed and specify them upfront in a contractual agreement. Local model updates can also be monitored by the orchestrator in terms of their contribution to the overall accuracy of the joint model, and the payment of a FedML service fee can be made proportionate to each partner&#39;s contribution to the federated learning process.</p><p></p><p> When taking first steps toward assembling a FedML consortium, securing partner buy-in is vital. Partners should therefore be involved in defining the consortium&#39;s objectives in exchange for their data commitments. The AI Canvas is a decision-making tool that can be useful in identifying and discussing machine learning use cases and required training data. <a id="reflink7" class="reflink" href="#ref7">7</a> When approaching partners, keep in mind that effective model updates in most FedML applications require access to local data on all relevant model variables. As a result, suitable partners are often found within the same industry, sharing similar business processes and data. Working with indirect competitors, such as those serving other geographic markets, instead of with direct competitors could be advantageous here to minimize potential conflicts. For small-data organizations venturing into FedML, it&#39;s advisable to start with achievable machine learning projects to establish momentum and build trust among partners before embarking on more ambitious projects.</p><p> FedML is still a young AI approach, developed in 2016 by a group of Google engineers. <a id="reflink8" class="reflink" href="#ref8">8</a> But progress in this field is fast paced, and we can expect a surge in its adoption across a range of business sectors. Forward-thinking leaders of small-data organizations who incorporate FedML into their strategic visions are better positioned to harness the transformative power of AI to shape their future success.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/using-federated-machine-learning-to-overcome-the-ai-scale-disadvantage/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item><item><title> Who Should Price a Gig?</title><link/> https://sloanreview.mit.edu/article/who-should-price-a-gig/<comments> https://sloanreview.mit.edu/article/who-should-price-a-gig/#respond</comments><pubDate> Mon, 21 Aug 2023 11:00:28 +0000</pubDate> <dc:creator><![CDATA[Jovana Karanovic, Elizabeth J. Altman, and Carmelo Cennamo. <p>Jovana Karanovic is an assistant professor at the Rotterdam School of Management at Erasmus University and the founder of the Reshaping Work foundation. Elizabeth J. Altman is an associate professor of management at the Manning School of Business at the University of Massachusetts Lowell; guest editor for <cite>MIT Sloan Management Review</cite> &#39;s Future of the Workforce initiative; and coauthor of <cite>Workforce Ecosystems: Reaching Strategic Goals With People, Partners, and Technologies</cite> (MIT Press, 2023). Carmelo Cennamo is a professor of strategy and entrepreneurship at Copenhagen Business School, director of the Digital Markets Competition Forum, and affiliate professor and director of the Platform Economy &amp; Regulation Monitor at SDA Bocconi School of Management.</p> ]]>; </dc:creator><category><![CDATA[Platforms]]></category><category><![CDATA[Pricing]]></category><category><![CDATA[Platforms & Ecosystems]]></category><category><![CDATA[Strategy]]></category><description><![CDATA[Daniel Hertzberg/theispot.com The Research The authors conducted interviews with platform executives at four platform businesses — Malt, Ring Twice, Temper, and Wolt — that represent different industry sectors and price-setting models. They also conducted archival web-based research studying platform-based businesses in various regions of the world and evaluated their pricing models. They were provided with [&#8230;]]]></description><content:encoded><![CDATA[<p></p><figure class="article-inline"><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/2023FALL-Karanovic_1290x860.png" alt="" /><figcaption><p class="attribution"> Daniel Hertzberg/theispot.com</p></figcaption></figure><aside class="callout-info"><h4>这个调查</h4><ul><li>The authors conducted interviews with platform executives at four platform businesses — Malt, Ring Twice, Temper, and Wolt — that represent different industry sectors and price-setting models.</li><li> They also conducted archival web-based research studying platform-based businesses in various regions of the world and evaluated their pricing models.</li><li> They were provided with and analyzed data from a service platform that switched from a platform-controlled price setting to allowing service providers to set prices. This data is part of an ongoing research project by Jovana Karanovic, Hakan Özalp, Carmelo Cennamo, and Mark Boons.</li></ul></aside><p> Arriving at Boston&#39;s Logan International Airport after a tiring journey, Mia opened the Uber app to find a ride home. Her relief at seeing the message “Your Uber driver is arriving in 3 minutes” was short-lived because the driver canceled. In the next 30 minutes, half a dozen Uber drivers accepted her ride request, then canceled, before one eventually arrived. What was happening?</p><p> Uber, like many platform companies, needs to efficiently match service providers (drivers) and customers (riders). To do so, it must ensure that pricing is competitive enough for riders to choose the service and for drivers to have the incentive to deliver it. Mia struggled to get a ride because Uber had started providing more earnings transparency for drivers by allowing them to see their expected compensation and route destinations before picking up riders. A change intended to benefit drivers had a significant downside for riders: More drivers began canceling rides they deemed unprofitable.</p><p></p><p> The question of who sets prices, and what discretion other parties in the transaction have to alter them in order to achieve mutually beneficial outcomes, is complex and nuanced for platform operators. In the case of Uber, the platform sets the price for the ride, and though drivers can opt out if their earning potential is unattractive, both drivers and riders have no flexibility for proposing different pricing. It&#39;s one of the drawbacks to having the locus of control primarily in the hands of the platform provider.</p><p> While algorithmically determined prices set by the platform operator are common among ride-hailing and food delivery services, other kinds of platform businesses allow service providers or customers to set prices. Fiverr, an online marketplace that matches high-skilled service providers with customers for tasks such as programming or graphic design, lets freelancers name their rates. In contrast, Temper, a Dutch platform for shift work in hospitality, retail, and logistics, lets customers (such as restaurants and shops) determine what the gig pays.</p><p> Controlling all pricing can lead to unintended consequences for a platform, as the Uber example shows, but allowing other stakeholders to set prices can also have drawbacks. For example, Ring Twice, a Belgian platform business that offers a variety of household services, such as gardening and babysitting, assigned pricing control to customers. It turned out that customers knew what they wanted — but not necessarily how much time and effort a specific task would take. Allowing customers to set prices resulted in fewer matches because many customers offered lower payments than service providers were willing to accept. Fewer successful job matches meant lost revenue for the platform.</p><p> Granting price-setting control is a major strategic decision that ultimately determines value creation and capture and establishes the power dynamics between the platforms themselves, service providers, and customers. Creating a scenario where all three stakeholders find the pricing model sustainable and beneficial is the key challenge that platform leaders face. To help leaders work through this decision, we offer a framework for understanding the key trade-offs of different platform price-setting approaches. Beyond economic considerations, we emphasize the need for managers to anticipate power dynamics and adopt hybrid approaches to mitigate them. (See “Pricing Dynamics on Gig Platforms.”)</p><div class="callout-highlight callout"><aside class="l-content-wrap"><article><h4> Pricing Dynamics on Gig Platforms</h4><p class="caption"> Platform operators must understand the key trade-offs of handing pricing power to different stakeholders; sharing that power through hybrid approaches is often the most sustainable option. </p><table id="Chart#" class="chart-grouped-rows no-mobile"><thead><tr><th style="line-height:1.5;width:25%"> Who Controls Pricing</th><th style="width:25%"> Benefits</th><th style="width:25%"> Risks</th><th style="line-height:1.5;width:25%"> Hybrid Solution</th></tr></thead><tbody><tr><td><p> <strong>PLATFORM</strong></p></td><td><p> Algorithmic pricing based on capturing market data can maximize efficiency in markets for standardized services.</p></td><td><p> Real-time price adjustments can disadvantage either providers or customers. Lack of predictability can damage trust.</p></td><td><p> <span class="blue">•</span> Set a base rate and enable providers to adjust prices upward or customers to make offers.</p><p> <span class="blue">•</span> Provide price guarantees in line with living wages.</p></td></tr><tr><td><p> <strong>PROVIDER</strong></p></td><td><p> The service provider&#39;s ability to set prices incentivizes high-quality providers to join. More variability on a platform serves long-tail demand.</p></td><td><p> Underpricing can drive down the perceived value of services across the platform. Overpricing can drive away customers and limit platform growth.</p></td><td><p> <span class="blue">•</span> Allow for price and contractual negotiations between customers and providers.</p><p> <span class="blue">•</span> Give price recommendations and share market data with providers.</p></td></tr><tr><td><p><strong>顾客</strong></p></td><td><p>Customers can control their own costs, which may increase engagement with and perceived value of the platform to customers.</p></td><td><p> Offering pay rates that are too low can drive away providers, thus limiting platform growth.</p></td><td><p> <span class="blue">•</span> Set minimum price thresholds in line with living wages.</p><p> <span class="blue">•</span> Assist customers by sharing market data and/or giving price recommendations. </p></td></tr></tbody></table><p><!--IMAGE FALLBACK FOR MOBILE BELOW --><br /><img src="https://sloanreview.mit.edu/wp-content/uploads/2023/08/MAG_Karanovic_table-1.png" alt="Pricing Dynamics on Gig Platforms" class="no-desktop"></p></article></aside></div><h3> When Platforms Call the Shots</h3><p> A platform can benefit from numerous advantages by retaining price-setting control, especially in certain segments. The practice is prevalent in ride-hailing, food delivery, and parcel delivery, where services are fairly standardized, volume is high, and logistics rapidly gain complexity with scale.</p><p> By retaining control, platforms can optimize for efficiency, particularly when they serve a large number of customers with similar needs. To set optimal prices, platforms leverage the large amount of transaction data they collect. Consider the Finnish platform Wolt, recently acquired by DoorDash, which offers food delivery, among other services. Wolt relies on parameters such as a courier&#39;s distance from the restaurant, food preparation time, and distance from the customer. Using this information, it advises couriers on the best routes to take and provides relevant extra information (for example, building entrance locations) to ensure swift delivery — and time savings. As a Wolt manager explained to us, the platform&#39;s interest in efficiency aligns with the couriers&#39; desire to take the optimal route, hence standardizing the delivery process as well as prices makes sense.</p><p> Controlling prices also allows the platform to maximize revenue by making quick adjustments based on market conditions: When demand is high, ride-hailing and delivery platforms commonly increase prices in real time. Platforms can also experiment with different pricing strategies.</p><p></p><p> Finally, by controlling the price, a platform provider can offer discounts and promotions to attract and retain customers. It may choose to offer personalized pricing based on customer behavior, preferences, and purchase history. Amazon, for example, utilizes such data to set dynamic pricing for certain items. When a customer views a product on Amazon, they may see a price that is different from what another customer might see for the same product. This is because Amazon&#39;s pricing algorithms take into account the customer&#39;s browsing and purchasing history, their location, and other variables to determine an individualized price that maximizes the likelihood of a purchase.</p><p> However, there are trade-offs to platforms retaining pricing control, particularly when it comes to the impact on power dynamics between stakeholders. In particular, service providers may decline to accept jobs if prices are set too low by the platform, or they may struggle to attract customers if their prices are set too high. In both cases, the service provider has less incentive to engage with the platform. A study examining posts to a forum for Uber drivers in US cities found that they discussed intentionally turning off their apps to appear unavailable in order to get the algorithm to implement higher surge pricing designed to incentivize drivers to get on the road. <a id="reflink1" class="reflink" href="#ref1">1</a> The drivers essentially had to game the system to get the prices they wanted, reflecting — and exacerbating — a lack of trust between providers and the platform.</p><p> Platform-controlled pricing also goes hand in hand with a standardized menu of services that might not adequately meet some customers&#39; needs. They may use the platform for finding a service provider and then arrange subsequent interactions off the platform. A recent study indeed found that providers&#39; dissatisfaction with platform rules and fees, as well as customers&#39; desires for more personalized services, are among the main factors contributing to disintermediation. <a id="reflink2" class="reflink" href="#ref2">2</a> When customers and providers are dissatisfied with platform-imposed rules, they are less likely to transact on the platform (lowering revenues), and the platform&#39;s reputation may suffer among all disaffected stakeholder groups.</p><p></p><h3> Putting Service Providers in Control</h3><p> There are also advantages when service providers are in control of price setting — common practice on freelance marketplaces such as Upwork, Toptal, and Malt. Granting this autonomy provides a competitive and flexible pricing environment, which is particularly advantageous for customers seeking specific capabilities for unique project needs. Similarly, providers can more effectively monetize their skills or unusual talents.</p><p> When providers set prices for a project, they can account for their costs, the effort they are willing to exert, and the service quality they can offer — information that the platform doesn&#39;t have but needs in order to set an adequate price. Price setting also lets service providers exercise their entrepreneurial freedom and adjust prices based on intangible factors such as their personal interest in a particular project. For example, they might charge less to land an assignment that will help them build valuable expertise, according to a manager at Malt, a European platform for services such as consulting and software development.</p><p> When service providers are able to set their own pricing and offer differentiated services, the platform can meet long-tail demand for niche offerings. Helpling, a platform for housecleaning services in Germany, France, Switzerland, England, Ireland, Italy, and Singapore, provides a case in point. The platform initially had a model where, within a given market, it set a standard price per hour for recurring cleaning jobs. (The slightly higher price for one-off jobs was also standardized within markets.) However, after a few years, Helpling changed its approach to let providers set their own prices. Our research shows that prices for some jobs subsequently increased as providers became willing to do different kinds of jobs (for example, after-party cleanups) for a higher fee. <a id="reflink3" class="reflink" href="#ref3">3</a> The platform&#39;s policy change apparently revealed unmet demand for additional services.</p><p> Allowing service providers to set prices also improves the customer experience in categories where the quality of service is more likely to vary by provider. Different quality levels for comparable services can create uncertainty and diminish satisfaction. Lower quality is often due to providers lacking incentive to exert the required effort when customers pay a standard price set by the platform business. If providers get to set their own prices that reflect their true value, they can reap the rewards of their greater efforts and deliver higher customer satisfaction.</p><p></p><p> This approach does have downsides. When platform operators relinquish price-setting control and providers overcharge, that can lower overall matching and transaction volumes; if providers undercharge, that can leave money on the table. At Malt, where service providers have full control of price setting, they tend to underprice themselves despite deep knowledge of what&#39;s required to perform tasks and their level of expertise. But that can be a vicious circle, according to the Malt manager we interviewed: Clients who are attracted to low-cost providers may be less discerning. Without a way for customers to differentiate between high- and low-quality providers listed on the platform, there&#39;s a risk that low prices will increasingly attract clients looking for more basic, lower-quality services. This drives out high-quality providers and potentially downgrades the brand equity and reputation of the platform. It might also lead to a race to the bottom, with providers consistently lowering prices to outcompete one another, reducing the platform&#39;s margins and providers&#39; earnings (and their willingness to remain on the platform).</p><p> For customers, provider pricing puts other dynamics into play. Providers that choose to focus on lucrative niches may leave some demand unmet. And the greater variability in provider-set pricing makes it more difficult for customers to fairly compare prices and find the best value for their money. If selecting a service provider becomes too time-consuming, customers may abandon the platform altogether.</p><h3> Customers Name Their Price</h3><p> Temper, the Dutch shift-work platform, allows customers to decide what they are willing to pay and matches skilled workers, such as baristas, with venues, such as restaurants. This approach is most appropriate when customers are businesses that have precise requirements for the services they need and the amount they are willing to pay.</p><p> Under this model, customers can set prices that reflect their budget and desired level of service, and service providers can choose to accept or reject offers based on their own pricing policies and cost structures. At Temper, restaurants looking for shift workers have different cost structures — for example, those in a city center pay higher rents. They also vary by service quality (for example, fine dining versus fast-casual), which affects the skills profiles they need and therefore the pay they will offer to attract workers. Customers can control their costs but also have flexibility to adapt to the competitive environment — for example, by offering higher compensation for weekend shifts. The platform exposes the going rate that other businesses are offering for the same services, which can also inform pricing decisions.</p><p> Finally, customers may be more motivated to use a platform if they have greater control over the pricing process. If they are given the power to determine the value they place on the service, they may feel more satisfied as well as invested in the transaction. Being more in control on the platform may deepen a sense of ownership and increase engagement and loyalty.</p><p> Naturally, customer-set pricing has trade-offs that can affect platform operators and providers. If customers set prices too low, service providers may be unwilling to take the task or they may be incentivized to cut corners to maintain profitability. This in turn could lead to a decline in the overall quality of products or services, reducing the platform&#39;s attractiveness and growth potential. Similarly, customers may not have access to complete information about the market dynamics, costs, and competitive landscape, leading to suboptimal outcomes for both providers and customers.</p><h3> Strike a Balance With Hybrid Approaches</h3><p> Whether pricing is controlled by the platform, service provider, or customer, under appropriate circumstances each choice has the potential to maximize value creation and efficiency. Nonetheless, dynamics that unfold among platforms&#39; different stakeholders may outweigh some of these benefits and lead to unintended consequences. To ensure long-term sustainability and enhance a platform business&#39;s financial performance, platform managers may want to share some control over pricing.</p><p> Platform providers can consider hybrid approaches to do this. For instance, TaskRabbit sets standard prices for different types of tasks based on factors such as complexity, duration, and market rates. These standard prices are initially determined by the platform to provide consistency and guidance to both customers and gig workers. However, TaskRabbit also allows service providers to adjust prices based on their own preferences and circumstances, and set a price that can be higher or lower than the platform&#39;s standard prices. The European Union has a proposed platform work directive that considers the right to set one&#39;s own rate a distinguishing factor between freelancers and employees; if adopted, it may push ride-hailing and food delivery platforms, which currently determine prices, to share this control with providers.</p><p> Platforms that control pricing can mitigate the power imbalance by being transparent with service providers about how prices are determined and whether they can do anything to increase earnings. They should also provide a mechanism for hearing providers&#39; concerns and enable them to appeal algorithmically determined decisions that affect their earnings on the platform.</p><p> While allowing service providers to set prices makes sense in some cases, it does not always lead to optimal pricing for them or the platform. For example, providers who have established high ratings and show a high number of completed tasks may have more pricing power compared with new providers. This is not beneficial for platforms, because new service providers quickly disengage if it takes too long to acquire work, limiting platform growth. Malt handles this discrepancy by boosting new providers&#39; visibility in search results.</p><p> Platforms can also assist providers with price setting, especially for offerings that are prone to demand fluctuations. A study of Airbnb found that only professional hosts (those with multiple properties) set prices skillfully; most others set suboptimal prices. <a id="reflink4" class="reflink" href="#ref4">4</a> Airbnb introduced price recommendations, alerting hosts to events and time periods when demand is high and prompting them to increase prices. <a id="reflink5" class="reflink" href="#ref5">5</a> Moreover, it lets hosts opt for automatic price adjustments, which essentially brings the price-setting power back to the platform, even in this service provider-controlled model.</p><p> When customers set prices, as we have seen, they may make lowball offers to service providers, especially during unfavorable market conditions. Platforms can prevent exploitation of service providers by setting minimum price thresholds that, for example, correspond to minimum or living wages. For instance, Temper sets a minimum price threshold for each service category that is in line with minimum wages, although it is not required to do so under Dutch law. In addition, it allows providers to negotiate. In 2022, 10% of all transactions on Temper were negotiated upward compared with initial prices set by customers, one of the company&#39;s cofounders told us. Such proactive initiatives from platforms may anticipate increasing regulations aimed at curtailing their power. New York City already has imposed a minimum wage for Uber and Lyft drivers and recently announced the same for workers on food delivery apps. The European Union is going a step further: Its proposed directive will presume gig workers are employees of platforms if certain criteria do not apply, such as a worker&#39;s right to adjust platform-determined rates as they see fit. In other words, if a platform sets upper limits for pay, it may be viewed as an employer.</p><p></p><p> As we have noted, customers may not always be fully informed, or they may have very specific preferences, in which case platforms can assist them with making provider selections. For example, on freelance marketplace Upwork, customers post desired tasks they need accomplished such as “logo design” or “report writing,” with detailed descriptions of what they are looking for and the price they are willing to pay. This price-setting model works well when customers have specific preferences and need a specific kind of provider for the job. However, Upwork eventually realized that not all customers have clear preferences; some just want the service done and would rather select it from a menu of offerings. This led to the launch of Upwork&#39;s Project Catalog, a website offering predefined projects that customers can browse and select, such as “A 500-word SEO-optimized blog article in under 24 hours” for $50. Instead of customers detailing the job, providers post what they can offer for a set price. This makes it easier for customers to find the right provider for their needs and gives providers more opportunities to win work.</p><p></p><p> A platform&#39;s need to control its marketplace to maximize returns isn&#39;t going away, but the approach it takes will determine its long-term sustainability. Platform leaders must realize that a platform is not a unilateral, hierarchically managed entity but rather a web of economic and social relationships. To manage it successfully and ensure satisfaction for all parties, they must share some aspects of control with other stakeholders, allow for compromise, and step in to support their workforce when needed. When control is shared more equitably among all parties in the platform relationship, the platform model can cater more beneficially to all.</p><p></p> ]]>;</content:encoded><wfw:commentrss> https://sloanreview.mit.edu/article/who-should-price-a-gig/feed/</wfw:commentrss><slash:comments> 0</slash:comments></item></channel></rss>